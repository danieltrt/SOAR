file_path,api_count,code
graph_optimization/graphColouring_greedyAlgorithm.py,2,"b'""""""\n@author: Vincent Bonnet\n@description : Graph optimization (Greedy colouring algorithm)\n""""""\n\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n\'\'\'\n Global Parameters\n\'\'\'\nNUM_NODES = 100\nNODE_SEARCH_RADIUS = 0.2\n\ndef get_graph():\n    return nx.random_geometric_graph(NUM_NODES, NODE_SEARCH_RADIUS, seed=5)\n\ndef compute_groups(graph):\n    \'\'\'\n    greedy colouring algorithm\n    \'\'\'\n    nx.set_node_attributes(graph, -1, ""group"")\n    group_ids = nx.get_node_attributes(graph, ""group"")\n\n    for node, adjacencies in graph.adjacency():\n        # get group ids from adjacencies\n        adjacency_groups = []\n        for adj in adjacencies:\n            adjacency_groups.append(group_ids[adj])\n\n        # search for unassigned group id\n        group_id = 0\n        while group_id in adjacency_groups:\n            group_id += 1\n\n        group_ids[node] = group_id\n\n    return group_ids\n\ndef show(graph):\n    num_nodes = graph.number_of_nodes()\n    colours = np.zeros(graph.number_of_nodes())\n    # colour from groups\n    group_ids = compute_groups(graph)\n    #group_ids = nx.coloring.greedy_color(graph) # to compare with own implementation\n    for i in range(num_nodes):\n        colours[i] = group_ids[i]\n\n    # display the graph\n    # Only support up to 20 difference colours (see cmap=plt.cm.tab20)\n    fig, ax = plt.subplots(figsize=(6,6))\n    ax.axis(\'equal\')\n\n    pos = nx.get_node_attributes(graph, ""pos"")\n    nx.draw_networkx_nodes(graph, pos, node_color=colours, cmap=plt.cm.tab20, node_size = 20, ax=ax)\n    nx.draw_networkx_edges(graph, pos, alpha=0.4, ax=ax)\n\n    font = {\'family\': \'serif\',\n            \'color\':  \'darkblue\',\n            \'weight\': \'normal\',\n            \'size\': 14 }\n    num_colours = np.max(list(group_ids.values()))\n    plt.title((\'Greedy Coloring Algorithm (%d colours)\'%num_colours), fontdict=font)\n    # plt.legend(bbox_to_anchor=(1, 1), loc=2)\n    plt.axis(\'off\')\n\n\nif __name__ == \'__main__\':\n    graph = get_graph()\n    show(graph)\n\n'"
interpolation_regression/polynomialRegression.py,15,"b'""""""\n@author: Vincent Bonnet\n@description : Polynomial Linear Regression on 1D data set\n""""""\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\'\'\'\n Global Parameters\n\'\'\'\ndef FUNCTION_1D(x):\n    return np.sin(x) * np.cos((x+1)*1.1) * 2\nMIN_RANGE = 0.0\nMAX_RANGE = 10.0\nNUM_SAMPLES = 20\nPOLYNOMIAL_DEGREE = 11\n\n\'\'\'\n Create random point from the polygon\n\'\'\'\ndef random_sample_from_function_1D(function, min_range, max_range, num_samples):\n    samples = np.zeros((num_samples, 2))\n    samples_x = np.linspace(min_range, max_range, num_samples, endpoint=True)\n    #random_offset_y = (np.random.rand(num_samples) * 0.5) - 0.25 # for jittering\n    random_offset_y = np.zeros(num_samples)\n\n    for i in range(0, num_samples):\n        samples[i] = (samples_x[i], function(samples_x[i]) + random_offset_y[i])\n\n    return samples\n\n\'\'\'\n Drawing Method\n\'\'\'\ndef draw_function_1D(ax, function, min_range, max_range, draw_step):\n    t = np.linspace(min_range, max_range, int((max_range - min_range) / draw_step), endpoint=True)\n    plt.plot(t, function(t), \'-\', color=\'green\', label=\'Reference function\')\n\ndef draw_samples(ax, samples):\n    x, y = zip(*samples)\n    plt.plot(x, y, \'.\', color=\'red\', label=\'Samples\')\n\ndef draw_poly_function(ax, poly_weights, min_range, max_range, draw_step):\n    x = np.linspace(min_range, max_range, int((max_range - min_range) / draw_step), endpoint=True)\n    poly_degree = np.size(poly_weights)\n    num_samples = np.size(x)\n\n    y = np.zeros(num_samples)\n    for i in range(num_samples):\n        for exponent_id in range(poly_degree):\n            y[i] += (x[i]**(exponent_id) * poly_weights[exponent_id])\n\n    plt.plot(x, y, \'-\', linestyle=\'dotted\', color=\'blue\', label=\'Polynomial regression\')\n\n\'\'\'\nPolynomial Regression\nSolves y = Xb + error where\ny is the vector of observed values [y0, y1, y2, ...] of size(num sample,1)\nX is the Vandermonde matrix of size(num_sample, poly_degree)\n|1 x0 x0^2 x0^3 .|\n|1 x1 x1^2 x1^3 .|\n|1 x2 x2^2 x2^3 .|\n|. .. .... .... .|\nb is the unknown weights [b0, b1, b2, ...] (poly_degree, 1)\ne is the error vector [e0, e1, e2, ...] (num_sample, 1)\n\'\'\'\ndef polynomial_regression_weights(samples, poly_degree):\n    sample_x, sample_y = zip(*samples)\n    num_sample = np.size(sample_y)\n\n    y = np.reshape(np.asarray(sample_y), (num_sample,1))\n    X = np.matrix(np.vander(sample_x, poly_degree, increasing=True))\n\n    # Solve with the pseudo inverse\n    pseudo_inverse = X.transpose() * X\n    pseudo_inverse = np.linalg.inv(pseudo_inverse)\n    pseudo_inverse = pseudo_inverse * X.transpose()\n\n    b = np.matmul(pseudo_inverse, y)\n\n    return b\n\n\'\'\'\n Execute\n\'\'\'\nfig, ax = plt.subplots()\nax.grid()\nax.axis(\'equal\')\n\nsamples = random_sample_from_function_1D(FUNCTION_1D, MIN_RANGE, MAX_RANGE, NUM_SAMPLES)\ndraw_function_1D(ax, FUNCTION_1D, MIN_RANGE, MAX_RANGE, draw_step = 0.1)\ndraw_samples(ax, samples)\n\npoly_weights = polynomial_regression_weights(samples, POLYNOMIAL_DEGREE)\n\nsample_x, unused_y = zip(*samples)\ndraw_poly_function(ax, poly_weights, MIN_RANGE, MAX_RANGE, draw_step = 0.1)\n\n# display\nfont = {\'family\': \'arial\',\n        \'color\':  \'darkblue\',\n        \'weight\': \'normal\',\n        \'size\': 16 }\nplt.title(\'Polynomial Regression\', fontdict=font)\nplt.xlabel(\'x\')\nplt.ylabel(\'f(x)\')\nplt.legend(bbox_to_anchor=(1, 1), loc=2)\nplt.show()'"
interpolation_regression/scatteredDataInterpolation_radialBasisFunction.py,14,"b'""""""\n@author: Vincent Bonnet\n@description : interpolation of 1D function with Radial Basis Functions\n""""""\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\'\'\'\n Global Parameters\n\'\'\'\ndef FUNCTION_1D(x):\n    return np.sin(x) * np.cos((x+1)*2) * 2\nMIN_RANGE = 0.0\nMAX_RANGE = 10.0\nNUM_SAMPLES = 15\n\n\'\'\'\n Create random point from the polygon\n\'\'\'\ndef randomSampleFromFunction1D(function, minRange, maxRange, numSamples):\n    result = []\n    samples_x = np.linspace(minRange, maxRange, numSamples, endpoint=True)\n\n    for i in range(0,numSamples):\n        result.append((samples_x[i], function(samples_x[i])))\n\n    return result\n\n\'\'\'\n RBF\'s kernels\n  .r parameter is the euclidean distance\n  .kernelParameter is currently hardcoded\n Multiquadric kernel is not used because it is not positive defined\n\'\'\'\nkernelParameter = 1.5\ndef gaussianKernel(r):\n    return np.exp(-np.square((r * kernelParameter)))\n\ndef inverseQuadraticKernel(r):\n    return 1.0 / (1.0 + np.square(r * kernelParameter))\n\ndef inverseMultiQuadraticKernel(r):\n    return 1.0 / np.sqrt(1.0 + np.square(r * kernelParameter))\n\n\'\'\'\n we should solve the system below\n Aw = b where\n\n b are the sampled points [y0, y1, y2]\n\n A is the interpolation matrix :\n  | k(x0-x0) k(x0-x1) k(x0-x2) ... |\n  | k(x1-x0) k(x1-x1) k(x1-x2) ... |\n  | k(x2-x0) k(x2-x1) k(x2-x2) ... |\n  |   ...      ...      ...    ... |\n\n w are the weights [w0, w1, w2] - unknown\n\'\'\'\ndef computeRBF_weights(points, kernel):\n    numSamples = np.size(points,0)\n    interpolationMatrix = np.zeros(shape=(numSamples,numSamples))\n    for i in range(numSamples):\n        for j in range(numSamples):\n            interpolationMatrix[i,j] = kernel(points[j][0]-points[i][0])\n\n    samplePoints = np.zeros(shape=(numSamples, 1))\n    for i in range(numSamples):\n        samplePoints[i]  = points[i][1]\n\n    inverseInterpolationMatrix = np.linalg.inv(interpolationMatrix)\n    weights = np.matmul(inverseInterpolationMatrix, samplePoints)\n\n    return weights\n\n\'\'\'\n Evaluate the RBF\n\'\'\'\ndef radialBasisFunction(points, rfbWeights, kernel, x):\n    numSamples = np.size(points,0)\n    result = 0.0\n    for i in range(numSamples):\n        result += kernel(x - points[i][0]) * rfbWeights[i]\n\n    return result\n\n\'\'\'\n Drawing Methods\n\'\'\'\ndef drawFunction1D(function1D, minRange, maxRange, step):\n    # prepare figure\n    fig, ax = plt.subplots()\n    ax.grid()\n    ax.axis(\'equal\')\n    # draw\n    t = np.linspace(minRange, maxRange, int((maxRange - minRange) / step), endpoint=True)\n    plt.plot(t, function1D(t), \'-\', color=""blue"")\n    # display\n    plt.tight_layout()\n    plt.show()\n\ndef drawRBF_1D(points, weights, kernel, referenceFunction, minRange, maxRange, step):\n    # prepare figure\n    fig, ax = plt.subplots()\n    ax.grid()\n    ax.axis(\'equal\')\n    # draw reference function\n    t = np.linspace(minRange, maxRange, int((maxRange - minRange) / step), endpoint=True)\n    plt.plot(t, referenceFunction(t), linestyle=\'solid\', color=""green"", label=""Reference function"")\n    # draw rbf\n    t = np.linspace(minRange, maxRange, int((maxRange - minRange) / step), endpoint=True)\n    plt.plot(t, radialBasisFunction(points, weights, kernel, t), linestyle=\'dotted\', color=""blue"", label=""RBF interpolation"")\n    # draw points\n    x, y = zip(*points)\n    plt.plot(x, y, \'.\', color=\'red\', label=""Samples"")\n    # display\n    font = {\'family\': \'arial\',\n            \'color\':  \'darkblue\',\n            \'weight\': \'normal\',\n            \'size\': 16 }\n    plt.title(\'RBF Interpolation\', fontdict=font)\n    plt.xlabel(\'x\')\n    plt.ylabel(\'f(x)\')\n    plt.legend(bbox_to_anchor=(1, 1), loc=2)\n    plt.show()\n\n\'\'\'\n Execute\n\'\'\'\n# sample the 1D function and compute the RBF weights\npoints = randomSampleFromFunction1D(FUNCTION_1D, MIN_RANGE, MAX_RANGE, NUM_SAMPLES)\nweights = computeRBF_weights(points, gaussianKernel)\n\n# display RBF\ndrawRBF_1D(points, weights, gaussianKernel, FUNCTION_1D, MIN_RANGE,MAX_RANGE, 0.1)\n\n# Debugging of the RBF kernels\n#drawFunction1D(gaussianKernel, -4.0, 4.0, 0.05)\n#drawFunction1D(inverseQuadraticKernel, -4.0, 4.0, 0.05)\n#drawFunction1D(inverseMultiQuadraticKernel, -4.0, 4.0, 0.05)\n\n'"
markov_chain/markov_chain.py,2,"b'""""""\n@author: Vincent Bonnet\n@description : Markov Chain\n""""""\n\nimport re\nimport pandas as pd\nimport numpy as np\nimport random\nimport os\n\nORDER = 2\n\ndef prepare_string(txt):\n    # not perfect but good enough\n    return re.sub(\'[^A-Za-z0-9]+\', \' \', txt)\n\ndef load_names_from_poetry_foundations():\n    # from https://www.kaggle.com/tgdivy/poetry-foundation-poems  should be downloaded\n    filename = os.path.join(os.getcwd(), ""kaggle_poem_dataset.csv"")\n    data = pd.read_csv(filename)\n    first_names = set()\n    family_names = set()\n    num_rows = len(data[\'Author\'])\n    for txt in data[\'Author\']:\n        split_text = prepare_string(txt).split()\n        if len(split_text) == 2:\n            first_names.add(split_text[0])\n            family_names.add(split_text[1])\n\n    return list(first_names), list(family_names)\n\ndef create_transition_matrix(names):\n    # create transition matrix from first names\n    transition = {}\n    possible_values = set()\n    for name in names:\n        for i in range(0, len(name) - ORDER):\n            key = tuple(name[i:i+ORDER])\n            values = transition.get(key, [])\n            values.append(name[i+ORDER])\n            transition[key] = values\n            possible_values.add(name[i+ORDER])\n\n    # compute the probabilities and transition matrix\n    transition_matrix = {}\n    possible_values = list(possible_values)\n    for key, values in transition.items():\n        propability_row = np.zeros(len(possible_values))\n        for value in values:\n            index = possible_values.index(value)\n            propability_row[index] += 1.0\n\n        propability_row /= len(values)\n        transition_matrix[key] = propability_row\n\n    return transition_matrix, possible_values\n\n\ndef generate_txt(start_key, transition_matrix, possible_values, num_words):\n    txt = []\n    for i in range(len(start_key)):\n        txt.append(start_key[i])\n\n    for i in range(num_words):\n        key = tuple(txt[-ORDER:])\n        probabilities = transition_matrix.get(key, None)\n        if not probabilities is None:\n            value = np.random.choice(possible_values,replace=True,p=probabilities)\n            txt.append(value)\n        else:\n            break\n\n    print(\'\'.join(txt))\n\ndef main():\n    random.seed()\n    first_names, family_names = load_names_from_poetry_foundations()\n    # generate first name\n    start_key = random.choice(first_names)[:ORDER]\n    transition_matrix, possible_values = create_transition_matrix(first_names)\n    generate_txt(start_key, transition_matrix, possible_values, 5)\n    # generate family name\n    start_key = random.choice(first_names)[:ORDER]\n    transition_matrix, possible_values = create_transition_matrix(family_names)\n    generate_txt(start_key, transition_matrix, possible_values, 5)\n\nif __name__ == \'__main__\':\n    main()\n'"
miscellaneous/inverseKinematics_withJacobian.py,24,"b'""""""\n@author: Vincent Bonnet\n@description : solve inverse kinematics problem with pseudo-inverse and damped least square\n""""""\n\nimport numpy as np\nfrom render_helper import RenderHelper\n\n\'\'\'\n Global Constants\n\'\'\'\nNUM_SEGMENTS = 10\nINITIAL_ANGLE_RANGE = 0.0 #  [-angle, angle] in degrees for initial segment angle\nINITIAL_SEGMENT_LENGTH = 1000.0 # length each segment\nTARGET_POS = (-500.0, 2000.0)\n\nDAMPING_CONSTANT = 1.0 # used when INVERSE_METHOD == \'damped_least_square\'\nNUM_ITERATIONS = 100\nMAX_STEP_SIZE = 100\nTHRESHOLD = 1.0 # acceptable distance between the last vertex and target position\n\nclass Chain:\n    def __init__(self):\n        self.angles = np.ones(NUM_SEGMENTS) * INITIAL_ANGLE_RANGE\n        self.lengths = np.ones(NUM_SEGMENTS) * INITIAL_SEGMENT_LENGTH\n        self.numSegments = NUM_SEGMENTS\n\n    def compute_positions(self):\n        rootPos = [0., 0.]\n        totalPos = rootPos\n        totalAngle = 0.\n\n        positions = []\n        positions.append(np.copy(rootPos))\n\n        for i in range(chain.numSegments):\n            totalAngle += chain.angles[i]\n            x = np.cos(np.deg2rad(totalAngle + 90)) * chain.lengths[i]\n            y = np.sin(np.deg2rad(totalAngle + 90)) * chain.lengths[i]\n            totalPos[0] += x\n            totalPos[1] += y\n            positions.append(np.copy(totalPos))\n\n        return positions\n\nclass RenderChain(RenderHelper):\n    def __init__(self, min_x, max_x, min_y, max_y):\n        RenderHelper.__init__(self, min_x, max_x, min_y, max_y)\n\n    def draw(self, chain):\n        pos = chain.compute_positions()\n        x, y = zip(*pos)\n\n        # draw chain\n        self.ax.plot(x, y, ""b-"", markersize=2) # draw blue segments\n        self.ax.plot(x, y, \'go\') # draw green points\n        self.ax.plot(TARGET_POS[0], TARGET_POS[1], \'ro\') # draw red target\n\n\'\'\'\n# Jacobian Helper functions\nLayout of the partial differential matrix of size(m x n)\n\'m\' is the number of DOF for the end effector (only translate XY)\n\'n\' is the number of joints multiplied by the number of joint DOF\n    joint0      joint1     joint2\n    [angle0]   [angle1]   [angle2]\nx :  dx/da0     dx/da1     dx/da2\ny :  dy/da0     dy/da1     dy/da2\n\'\'\'\n#  Use central difference to approximate the differentiation\ndef computeNumericalJacobian(chain):\n    jacobian = np.zeros(shape=(2,chain.numSegments))\n    angleDt = 0.01\n    for i in range(chain.numSegments):\n        keepAngle = chain.angles[i]\n        # compute the derivative\n        chain.angles[i] = keepAngle + (angleDt * 0.5)\n        forwardPositions = chain.compute_positions()\n        chain.angles[i] = keepAngle - (angleDt * 0.5)\n        backwardPositions = chain.compute_positions()\n        dpda = (forwardPositions[chain.numSegments] - backwardPositions[chain.numSegments]) / angleDt\n        jacobian[0, i] = dpda[0]\n        jacobian[1, i] = dpda[1]\n        # resort angle\n        chain.angles[i] = keepAngle\n    return np.matrix(jacobian)\n\ndef computeAnalyticJacobian(chain):\n    positions = chain.compute_positions()\n    jacobian = np.zeros(shape=(2,chain.numSegments))\n    for i in range(chain.numSegments):\n        vec = np.subtract(positions[chain.numSegments],  positions[i])\n        x = vec[0]\n        y = vec[1]\n        # compute the derivative\n        # sin(np.deg2rad(1.0)) is the angular velocity\n        # x = norm(vec) * cos(angle) and x\' = norm(vec) * -sin(angle)\n        # y = norm(vec) * sin(angle) and y\' = norm(vec) * cos(angle)\n        # hence x\' = y * -1 and y\' = x\n        jacobian[0, i] = y * -1 * np.sin(np.deg2rad(1.0))\n        jacobian[1, i] = x * np.sin(np.deg2rad(1.0))\n\n    return np.matrix(jacobian)\n\n\'\'\'\nCompute the Inverse of the Jacobians\n\'\'\'\ndef computePseudoInverse(jacobian):\n    # pseudo-inverse from numpy to validate our implementation below\n    #return np.linalg.pinv(jacobian)\n\n    jacobiantInv = jacobian * jacobian.transpose()\n    jacobiantInv = np.linalg.inv(jacobiantInv)\n    return(jacobian.transpose() * jacobiantInv)\n\ndef computeDampedLeastSquare(jacobian):\n    damping_matrix_constant = np.identity(2) * DAMPING_CONSTANT\n\n    jacobiantInv = jacobian * jacobian.transpose()\n    jacobiantInv += damping_matrix_constant\n    jacobiantInv = np.linalg.inv(jacobiantInv)\n    return(jacobian.transpose() * jacobiantInv)\n\n\ndef print_singluar_values(matrix):\n    \'\'\'\n    Singular values analysis (for debugging)\n    Print the singular values to indicate whether the matrix inversion is stable\n    Large singular values would make it unstable\n    matrix is decompose into U.E.Vt\n    where U and V are othogonal and E is the diagonal matrix containing singular values\n    hence its inverse is V.1/E.Ut\n    \'\'\'\n    singular_values = np.linalg.svd(matrix, compute_uv = False)\n    print(""-- singular_values --"")\n    print(singular_values)\n\n\ndef inverseKinematic(chain, jacobian_method, inverse_methd):\n    \'\'\'\n    Solve inverse kinematic problem\n    \'\'\'\n    positions = chain.compute_positions()\n    vec = np.subtract(TARGET_POS, positions[chain.numSegments])\n    vecNorm = np.linalg.norm(vec)\n    if (vecNorm > MAX_STEP_SIZE):\n        vec /= vecNorm\n        vec *= MAX_STEP_SIZE\n\n    jacobian = jacobian_method(chain)\n    pseudoInverse = inverse_methd(jacobian)\n\n    # Debugging\n    #print_singluar_values(pseudoInverse)\n\n    deltaAngles = np.matmul(pseudoInverse, np.reshape(vec, (2,1)))\n    for i in range(chain.numSegments):\n        chain.angles[i] += deltaAngles[i]\n\ndef hasReachTarget(chain):\n    \'\'\'\n    Return true if an \'acceptable\' solution has been reached\n    \'\'\'\n    positions = chain.compute_positions()\n    diff = np.subtract(TARGET_POS, positions[chain.numSegments])\n    if (np.linalg.norm(diff) <= THRESHOLD):\n        return True\n    return False\n\nif __name__ == \'__main__\':\n    render = RenderChain(-5000., 5000., 0., 10000.)\n    chain = Chain()\n    render.prepare_figure()\n    render.show_figure(chain)\n    # run inverse kinematic algorithm until convergence\n    iterations = 1\n    while iterations <= NUM_ITERATIONS and not hasReachTarget(chain):\n        inverseKinematic(chain, computeAnalyticJacobian, computeDampedLeastSquare)\n        print(""IK : Iteration"", iterations, ""/"", NUM_ITERATIONS )\n        render.prepare_figure()\n        render.show_figure(chain)\n        iterations += 1\n'"
miscellaneous/optimalTransformation_covarianceMatrix.py,21,"b'""""""\n@author: Vincent Bonnet\n@description : find optimal rigid transformation by using Principal component analysis\n""""""\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n\'\'\'\n Global Constants\n\'\'\'\nNUM_POINTS = 1000\nROTATION = 39.0\nSCALE = [11.0, 4.0]\nTRANSLATE = [2.5, 1]\n\n\'\'\'\n Transform point\n\'\'\'\ndef transformPoints(pointData, angle, scale, translate):\n    cosAngle = np.cos(np.deg2rad(angle))\n    sinAngle = np.sin(np.deg2rad(angle))\n\n    # create scale-rotation matrix\n    scaleRotationMat = np.matrix([[cosAngle * scale[0],  -sinAngle * scale[1]],\n                                  [sinAngle * scale[0],  cosAngle * scale[1]]])\n\n    # Non vectorized code\n    #for i in range(NUM_POINTS):\n    #    pointData[i] = np.matmul(scaleRotationMat, pointData[i])\n    #    pointData[i] += translate\n\n    transformedPoint = np.matmul(scaleRotationMat, pointData.T)\n    np.copyto(pointData, transformedPoint.T)\n    pointData += translate\n\n\'\'\'\n Utility functions\n\'\'\'\ndef computeCentroid(pointData):\n    return np.sum(pointData, axis=0) / np.size(pointData,0)\n\ndef covariance(pointArray, index0, index1):\n    # Non vectorized code\n    #cov = 0\n    #for p in pointArray:\n    #    cov += p[index0] * p[index1]\n\n    cov = np.sum(pointArray[:,index0] * pointArray[:,index1])\n\n    return cov / np.size(pointArray,0)\n\ndef computeBestRotation(pointData, centroid):\n    # get direction\n    localPoint = np.copy(pointData)\n    np.subtract(localPoint, centroid, out=localPoint)\n    # compute covariance matrix\n    # cov(X,X) cov(X,Y)\n    # cov(Y,X) cov(Y,Y)\n    covXX = covariance(localPoint,0,0)\n    covYY = covariance(localPoint,1,1)\n    covXY = covariance(localPoint,0,1)\n    covarianceMatrix = np.matrix([[covXX, covXY],\n                                  [covXY, covYY]])\n    # covariance decomposition\n    w, v = np.linalg.eig(covarianceMatrix)\n    rotationMatrix = v\n    det = np.linalg.det(rotationMatrix)\n    if det < 0.0:\n        # from reflection matrix to rotation matrix\n        rotationMatrix *= -1.0\n    return rotationMatrix\n\ndef draw(pointData, centroid, rotationMatrix):\n    \'\'\'\n     Draw point, frames, box\n    \'\'\'\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.set_aspect(\'equal\')\n    ax.set_xlim(-10,10)\n    ax.set_ylim(-10,10)\n\n    transformedPointData = np.copy(pointData)\n    transformedPointData -= centroid\n    inverseRotationMatrix = rotationMatrix.T\n    transformedPointData = np.asarray(np.matmul(inverseRotationMatrix, transformedPointData.T).T)\n    boxMin = np.min(transformedPointData, axis=0)\n    boxMax = np.max(transformedPointData, axis=0)\n\n    # draw the local frame\n    # in ax.arrow(...)  vec.y and vec.x are reversed !\n    vec0x = rotationMatrix.item(0,0)\n    vec0y = rotationMatrix.item(0,1)\n    vec1x = rotationMatrix.item(1,0)\n    vec1y = rotationMatrix.item(1,1)\n    ax.arrow(centroid[0], centroid[1], vec0y, vec0x, head_width=1.0, facecolor=\'red\', edgecolor=\'black\')\n    ax.arrow(centroid[0], centroid[1], vec1y, vec1x, head_width=1.0, facecolor=\'green\', edgecolor=\'black\')\n\n    # draw points\n    x, y = zip(*pointData)\n    ax.scatter(x, y,s=0.5)\n\n    # draw box\n    vertex = np.asarray([(boxMin[0], boxMin[1]), (boxMin[0], boxMax[1]),\n                         (boxMax[0], boxMax[1]), (boxMax[0], boxMin[1])])\n    vertex = np.asarray(np.matmul(rotationMatrix, vertex.T).T)\n    vertex += centroid\n    polygon = patches.Polygon(vertex, closed=True,ec=\'darkgreen\',lw=2,fill=False)\n    ax.add_patch(polygon)\n\n    # show result\n    plt.show()\n\nif __name__ == \'__main__\':\n    pointData = np.array(np.random.rand(NUM_POINTS, 2) - 0.5)  # positions [-0.5, -0.5] [0.5, 0.5]\n    transformPoints(pointData, ROTATION, SCALE, TRANSLATE)\n\n    # compute best transform (rotation, centroid)\n    centroid = computeCentroid(pointData)\n    rotationMatrix = computeBestRotation(pointData, centroid)\n\n    draw(pointData, centroid, rotationMatrix)\n'"
miscellaneous/render_helper.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : render helper\n""""""\n\nimport matplotlib.pyplot as plt\n\nclass RenderHelper:\n\n    def __init__(self, min_x, max_x, min_y, max_y):\n        plt.xkcd()\n        self.fig = plt.figure()\n        self.font = {\'family\': \'serif\',\n                     \'color\':  \'darkred\',\n                     \'weight\': \'normal\',\n                     \'size\': 12}\n        self.output_folder = """"\n        self.ax = None\n        self.min_x = min_x\n        self.max_x = max_x\n        self.min_y = min_y\n        self.max_y = max_y\n\n    def set_output_folder(self, folder):\n        self.output_folder = folder\n\n    def draw(self, data):\n        raise NotImplementedError(type(self).__name__ + "" needs to implement the method \'draw\'"")\n\n    def prepare_figure(self):\n        self.fig = plt.figure()\n        self.fig.clear()\n        self.ax = self.fig.add_subplot(1, 1, 1)\n        #self.ax.axis(\'equal\') # FIXME - causes problem\n        self.ax.set_xlim(self.min_x, self.max_x)\n        self.ax.set_ylim(self.min_y, self.max_y)\n\n    def show_figure(self, data):\n        self.draw(data)\n        plt.show()\n\n    def export_figure(self, filename):\n        if len(filename) > 0 and len(self.output_folder) > 0:\n            self.fig.savefig(self.output_folder + ""/"" + filename)\n'"
miscellaneous/spring1D_integrator.py,8,"b'""""""\n@author: Vincent Bonnet\n@description : solve a 1D spring - aka damped harmonic oscillator\n""""""\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom enum import IntEnum\nfrom dataclasses import dataclass\n\n\'\'\'\n Global Constants\n\'\'\'\nSPRING_STIFFNESS = 1.0  # Newtons per meters\nSPRING_DAMPING = 0.2   # Netwons per meters per second\nINITIAL_POSITION = 2.0 # particle initial position in meters\nINITIAL_VELOCITY = 0.0 # particle initial velocity in meters per second\nMASS = 1.0  # particle mass in kg\n\n# time constant\nTIME_START = 0.0  # in Second\nTIME_END = 30.0   # in Second\nDT = 0.1         # in Second\nN = round((TIME_END - TIME_START) / DT)\n\n\'\'\'\n Helper Classes (State, Derivate, Particle)\n\'\'\'\n@dataclass\nclass State:\n    x : float = 0.0 # position in Meters\n    v : float = 0.0 # velocity in Metres per second\n\n@dataclass\nclass Derivative:\n    dx : float = 0.0 # derivative of x - change in position\n    dv : float = 0.0 # derivative of v - change in velocity\n\n    def __add__(self, other):\n        result = Derivative();\n        result.dx = self.dx + other.dx\n        result.dv = self.dv + other.dv\n        return result\n\n    def __truediv__(self, other):\n        result = Derivative();\n        result.dx = self.dx / other\n        result.dv = self.dv / other\n        return result\n\n@dataclass\nclass Particle:\n    mass : float = 1.0 # Kilograms\n    state = State()\n\n\'\'\'\n Helper Functions\n Derivative Functions\n\'\'\'\n# internal spring force\ndef acceleration(state, mass):\n    attachement = 0.0\n    spring_force = -1.0 * (state.x - attachement) * SPRING_STIFFNESS  # spring force\n    spring_force += -1.0 * (state.v * SPRING_DAMPING)  # spring damping\n    acceleration = spring_force / mass\n    return acceleration\n\n# derivative of x - change in position\ndef dx(state):\n    return state.v\n\n# derivative of v - change in velocity\ndef dv(state, mass):\n    return acceleration(state, mass)\n\n# forward integration - return a new state\ndef integrate(state, derivative, dt):\n    result_state = State()\n    result_state.x = state.x + derivative.dx * dt\n    result_state.v = state.v + derivative.dv * dt\n    return result_state\n\n# compute derivate at the state\ndef derivate(state, mass):\n    result_derivate = Derivative()\n    result_derivate.dx = dx(state)\n    result_derivate.dv = dv(state, mass)\n    return result_derivate\n\n\'\'\'\n Integrators\n\'\'\'\nclass Integrators(IntEnum):\n    EXPLICIT_EULER = 0\n    RK2 = 1\n    RK4 = 2\n    SEMI_IMPLICIT_EULER_V1 = 3\n    SEMI_IMPLICIT_EULER_V2 = 4\n    LEAP_FROG = 5\n    ANALYTIC = 6\n\n\'\'\'\n Integration Functions\n\'\'\'\ndef forwardEulerStep(particle, time, dt):\n    k = derivate(particle.state, particle.mass)\n    particle.state = integrate(particle.state, k, DT)\n\ndef RK2Step(particle, time, dt):\n    s1 = particle.state\n    k1 = derivate(s1, particle.mass)\n    s2 = integrate(s1, k1, DT * 0.5)\n    k2 = derivate(s2, particle.mass)\n    particle.state = integrate(particle.state, k2, DT)\n\ndef RK4Step(particle, time, dt):\n    s1 = particle.state\n    k1 = derivate(s1, particle.mass)\n    s2 = integrate(s1, k1, DT * 0.5)\n    k2 = derivate(s2, particle.mass)\n    s3 = integrate(s1, k2, DT * 0.5)\n    k3 = derivate(s3, particle.mass)\n    s4 = integrate(s1, k3, DT)\n    k4 = derivate(s4, particle.mass)\n    particle.state = integrate(particle.state, k1 / 6 + k2 / 3 + k3 / 3 + k4 / 6 , DT)\n\ndef semiImplicitEulerV1(particle, time, dt):\n    particle.state.v += dv(particle.state, particle.mass) * DT\n    particle.state.x += dx(particle.state) * DT\n\ndef semiImplicitEulerV2(particle, time, dt):\n    particle.state.x += dx(particle.state) * DT\n    particle.state.v += dv(particle.state, particle.mass) * DT\n\ndef leapFrog(particle, time, dt):\n    if (time == TIME_START):\n        # compute the velocity at half step which will cause the velocity to be half-step ahead of position\n        particle.state.v += dv(particle.state, particle.mass) * DT * 0.5\n    particle.state.x += particle.state.v * DT\n    particle.state.v += dv(particle.state, particle.mass) * DT\n\ndef analyticSolution(particle, time, dt):\n    if(SPRING_DAMPING==0.0):\n        w = np.sqrt(SPRING_STIFFNESS/particle.mass)\n        particle.state.x = (INITIAL_POSITION * np.cos(w * time)) + (INITIAL_VELOCITY / w * np.sin(w * time));\n    else:\n        if (INITIAL_VELOCITY!=0.0):\n            print(""no analytic solution with damping and initial velocity .. TODO"")\n        else:\n            w0 = np.sqrt(SPRING_STIFFNESS/particle.mass)\n            y = SPRING_DAMPING / (2 * particle.mass)\n            w = np.sqrt(w0 * w0 - y * y)\n            a = np.exp(-1.0 * y * time)\n            particle.state.x = (INITIAL_POSITION * a * np.cos(w * time));\n\n\'\'\'\n Integrator Info\n\'\'\'\nintegratorFunctions = [forwardEulerStep, # EXPLICIT_EULER\n                       RK2Step, # RK2\n                       RK4Step, # RK4\n                       semiImplicitEulerV1, # SEMI_IMPLICIT_EULER_V1\n                       semiImplicitEulerV2, # SEMI_IMPLICIT_EULER_V2\n                       leapFrog, # LEAP_FROG\n                       analyticSolution] # ANALYTIC\n\nintegratorColours = [""xkcd:aqua"", # EXPLICIT_EULER\n                     ""xkcd:plum"", # RK2\n                     ""xkcd:teal"", # RK4\n                     ""xkcd:chartreuse"", # SEMI_IMPLICIT_EULER_V1\n                     ""xkcd:olive"", # SEMI_IMPLICIT_EULER_V2\n                     ""xkcd:green"", # LEAP_FROG\n                     ""xkcd:red""]  # ANALYTIC\n\nintegratorNames = [""explicit euler"", # EXPLICIT_EULER\n                   ""rk2"", # RK2\n                   ""rk4"", # RK4\n                   ""semi implicit euler v1"", # SEMI_IMPLICIT_EULER_V1\n                   ""semi implicit euler v2"", # SEMI_IMPLICIT_EULER_V2\n                   ""leap frog"", # LEAP_FROG\n                   ""analytic""]  # ANALYTIC\n\nintegratorDisplay = [True, # EXPLICIT_EULER\n                     True, # RK2\n                     True, # RK4\n                     True, # SEMI_IMPLICIT_EULER_V1\n                     True, # SEMI_IMPLICIT_EULER_V1\n                     True, # LEAP_FROG\n                     True] # ANALYTIC\n\ndef main():\n        # Initialize Display\n    font = {\'family\': \'serif\',\n            \'color\':  \'darkred\',\n            \'weight\': \'normal\',\n            \'size\': 16,\n            }\n    mpl.style.use(""seaborn"")\n    plt.title(\'Single Damped Harmonic Oscillator\', fontdict=font)\n    plt.xlabel(\'time(t)\')\n    plt.ylabel(\'position(x)\')\n\n    # integrators Loop\n    for integrator in Integrators:\n\n        # initialize particle state\n        particle = Particle();\n        particle.mass = 1.0\n        particle.state = State(INITIAL_POSITION, INITIAL_VELOCITY)\n\n        # initialize time and positions samples\n        time_samples = np.zeros(N)\n        position_samples = np.zeros(N)\n\n        # simulation Loop\n        plot_colour = integratorColours[integrator]\n        time = TIME_START\n        for i in range(0,N):\n\n            time_samples[i] = time\n            position_samples[i] = particle.state.x\n\n            function = integratorFunctions[integrator]\n            function(particle, time, DT)\n\n            time += DT\n\n        if (integratorDisplay[integrator]):\n            plt.plot(time_samples, position_samples, color=plot_colour, label=integratorNames[integrator])\n\n    # display result\n    plt.legend(bbox_to_anchor=(1, 1), loc=2)\n    plt.show()\n\nif __name__ == \'__main__\':\n    main()\n'"
optimizations/convexFunctions.py,24,"b'""""""\n@author: Vincent Bonnet\n@description : test functions for optimization with convex functions\n""""""\n\nimport numpy as np\n\n\'\'\'\n BohachevskyN1 function\n\'\'\'\nclass BohachevskyN1:\n    def guess():\n        return np.array([-50.,-50.])\n\n    def value(X):\n        result = X[0]**2 + 2*X[1]**2\n        result -= 0.3*np.cos(3*np.pi*X[0])\n        result -= 0.4*np.cos(4*np.pi*X[1])\n        result += 0.7\n        return result\n\n    def gradient(X):\n        dfdx = 2.*X[0] + (0.3*3.*np.pi*np.sin(3*np.pi*X[0]))\n        dfdy = 4.*X[1] + (0.4*4.*np.pi*np.sin(4*np.pi*X[1]))\n        return np.array([dfdx, dfdy])\n\n    def inv_hessian(X):\n        dfdxx = 2.+((3.*np.pi)**2)*0.3*np.cos(3*np.pi*X[0])\n        dfdyy = 4.+((4.*np.pi)**2)*0.4*np.cos(4*np.pi*X[1])\n        dfdxy = 0\n        hessian = np.zeros((2,2))\n        hessian[0][0] = dfdxx\n        hessian[1][1] = dfdyy\n        hessian[0][1] = dfdxy\n        hessian[1][0] = dfdxy\n        return np.linalg.inv(hessian)\n\n    def ranges():\n        return (-100, -100), (100, 100)\n\nclass McCormick:\n    def guess():\n        return np.array([4.0,-2.0])\n\n    def value(X):\n        result = np.sin(X[0]+X[1])\n        result += (X[0]-X[1])**2.0\n        result += -1.5*X[0] + 2.5*X[1] + 1.0\n        return result\n\n    def gradient(X):\n        dfdx = np.cos(X[0]+X[1]) + 2*(X[0]-X[1]) - 1.5\n        dfdy = np.cos(X[0]+X[1]) - 2*(X[0]-X[1]) + 2.5\n        return np.array([dfdx, dfdy])\n\n    def inv_hessian(X):\n        dfdxx = -1.*np.sin(X[0]+X[1]) + 2\n        dfdyy = -1.*np.sin(X[0]+X[1]) + 2\n        dfdxy = -1.*np.sin(X[0]+X[1]) - 2\n        hessian = np.zeros((2,2))\n        hessian[0][0] = dfdxx\n        hessian[1][1] = dfdyy\n        hessian[0][1] = dfdxy\n        hessian[1][0] = dfdxy\n        return np.linalg.inv(hessian)\n\n    def ranges():\n        return (-1.5, -3.), (4., 3.)\n\nclass Booth:\n    def guess():\n        return np.array([-10.0,-10.0])\n\n    def value(X):\n        a = X[0] + 2*X[1] - 7\n        b = 2*X[0] + X[1] - 5\n        result = a**2 + b**2\n        return result\n\n    def gradient(X):\n        dfdx = 10*X[0] + 8*X[1] - 34\n        dfdy = 8*X[0] + 10*X[1] - 38\n        return np.array([dfdx, dfdy])\n\n    def inv_hessian(X):\n        dfdxx = 10.\n        dfdyy = 10.\n        dfdxy = 8.\n        hessian = np.zeros((2,2))\n        hessian[0][0] = dfdxx\n        hessian[1][1] = dfdyy\n        hessian[0][1] = dfdxy\n        hessian[1][0] = dfdxy\n        return np.linalg.inv(hessian)\n\n    def ranges():\n        return (-10, -10), (10, 10)\n\n'"
optimizations/linesearch.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : line search algorithms\n""""""\n\ndef linesearch_placeholder():\n    pass\n'"
optimizations/main.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : multivariable optimizations - gradient descent\n""""""\n\nimport convexFunctions\nimport nonConvexFunctions\nimport render\nimport optimizer\nimport linesearch\n\ndef main():\n    # Step parameter\n    optimizer.NORMALIZED_STEP = False  # Only Gradient Descent\n    optimizer.SCALE_STEP = 0.1\n    # Termination condition\n    optimizer.MAX_ITERATIONS = 200\n    optimizer.THRESHOLD = 1e-04\n\n    # Multivariable non-convex functions\n    render.draw2D(nonConvexFunctions.trigonometry2D, optimizer.GradientDescent)\n    render.draw2D(nonConvexFunctions.trigonometry2D, optimizer.NewtonRaphson)\n    render.draw2D(nonConvexFunctions.trigonometry2D, optimizer.QuasiNewtonRaphson_BFGS)\n\n    # Multivariable convex functions\n    #render.draw2D(convexFunctions.BohachevskyN1, optimizer.GradientDescent)\n    #render.draw2D(convexFunctions.BohachevskyN1, optimizer.NewtonRaphson)\n    #render.draw2D(convexFunctions.BohachevskyN1, optimizer.QuasiNewtonRaphson_BFGS)\n    render.draw2D(convexFunctions.McCormick, optimizer.GradientDescent)\n    render.draw2D(convexFunctions.McCormick, optimizer.NewtonRaphson)\n    render.draw2D(convexFunctions.McCormick, optimizer.QuasiNewtonRaphson_BFGS)\n    render.draw2D(convexFunctions.Booth, optimizer.GradientDescent)\n    render.draw2D(convexFunctions.Booth, optimizer.NewtonRaphson)\n    render.draw2D(convexFunctions.Booth, optimizer.QuasiNewtonRaphson_BFGS)\n\nif __name__ == \'__main__\':\n    main()\n'"
optimizations/nonConvexFunctions.py,7,"b'""""""\n@author: Vincent Bonnet\n@description : test functions for optimization with non-convex functions\n""""""\n\nimport numpy as np\n\n\'\'\'\n 2D Function For Example\n\'\'\'\nclass trigonometry2D:\n    def guess():\n        return np.array([0.5,0.6])\n\n    def value(X):\n        exp = np.exp(-X[0]**2-X[1]**2)\n        return 0.75 * X[0] * exp\n\n    def gradient(X):\n        exp = np.exp(-X[0]**2-X[1]**2)\n        dfdx = 0.75 * (exp - 2*exp*X[0]**2)\n        dfdy = -1.5 * exp * X[0] * X[1]\n        return np.array([dfdx, dfdy])\n\n    def inv_hessian(X):\n        exp = np.exp(-X[0]**2-X[1]**2)\n        dfdxx = 0.75 * (4*exp*X[0]**3 - 6*exp*X[0])\n        dfdxy = 0.75 * (-2*exp*X[1] + 4*exp*X[0]**2*X[1])\n        dfdyy = -1.5 * X[0] * (-2*exp*X[1]**2 + exp)\n        hessian = np.zeros((2,2))\n        hessian[0][0] = dfdxx\n        hessian[1][1] = dfdyy\n        hessian[0][1] = dfdxy\n        hessian[1][0] = dfdxy\n        return np.linalg.inv(hessian)\n\n    def ranges():\n        return (-2.1, -2.1), (2.1, 2.1)\n'"
optimizations/optimizer.py,21,"b'""""""\n@author: Vincent Bonnet\n@description : multivariable optimizers\n""""""\n\nimport numpy as np\n\n# Step parameter\nNORMALIZED_STEP = True  # Only Gradient Descent\nSCALE_STEP = 0.02 # Newton Method and Gradient Descent\n# Termination condition\nMAX_ITERATIONS = 200\nTHRESHOLD = 1e-07\n\n\'\'\'\n Gradient Descent\n\'\'\'\ndef GradientDescent(function):\n    results = []\n    guess = function.guess()\n    results.append(np.copy(guess))\n\n    terminate = False\n    num_iterations = 0\n\n    while not terminate:\n        gradient = function.gradient(guess)\n\n        step = -gradient\n        if NORMALIZED_STEP:\n            step /= np.linalg.norm(step)\n        step *= SCALE_STEP\n\n        guess += step\n\n        # test termination conditions\n        num_iterations += 1\n        if np.linalg.norm(gradient) < THRESHOLD or num_iterations > MAX_ITERATIONS:\n            terminate = True\n\n        # store result\n        results.append(np.copy(guess))\n\n    return results\n\n\'\'\'\n QuasiNewton optimization\n\'\'\'\ndef QuasiNewtonRaphson_BFGS(function):\n    results = []\n    guess = function.guess()\n    results.append(np.copy(guess))\n\n    terminate = False\n    num_iterations = 0\n    I = np.identity(2)\n    H = np.identity(2) # approximate inverse hessian\n    y = np.zeros(2) # gradient@x+1 - gradient@x\n\n    while not terminate:\n        gradient = function.gradient(guess)\n\n        step = -H.dot(gradient)\n        step *= SCALE_STEP\n\n        guess += step\n\n        # test termination conditions\n        num_iterations += 1\n        if np.linalg.norm(gradient) < THRESHOLD or num_iterations > MAX_ITERATIONS:\n            terminate = True\n\n        # update the inverse hessian matrix\n        next_gradient = function.gradient(guess)\n        y = next_gradient - gradient\n        ys = np.inner(y, step) # scalar\n\n        # early version\n        #next_H = (I - np.outer(step, y) / ys)\n        #next_H *= H\n        #next_H *= (I - np.outer(y, step) / ys)\n        #next_H += (np.outer(step, step) / ys)\n\n        #optimized version\n        Hy = np.dot(H, y) # vector\n        yHy = np.inner(y, Hy) # scalar\n        next_H = H\n        next_H += ((ys+yHy) * np.outer(step, step) / ys ** 2)\n        next_H -= (np.outer(Hy, step) + np.outer(step, Hy)) / ys\n\n        H = next_H\n\n        # store result\n        results.append(np.copy(guess))\n\n    return results\n\n\'\'\'\n Newton Iteration optimization\n Newton\'s method for unconstrained optimization finds local extrema (minima or maxima)\n\'\'\'\ndef NewtonRaphson(function):\n    results = []\n    guess = function.guess()\n    results.append(np.copy(guess))\n\n    terminate = False\n    num_iterations = 0\n\n    while not terminate:\n        gradient = function.gradient(guess)\n\n        step = -function.inv_hessian(guess).dot(gradient)\n        step *= SCALE_STEP\n\n        guess += step\n\n        # test termination conditions\n        num_iterations += 1\n        if np.linalg.norm(gradient) < THRESHOLD or num_iterations > MAX_ITERATIONS:\n            terminate = True\n\n        # store result\n        results.append(np.copy(guess))\n\n    return results\n\n'"
optimizations/render.py,6,"b'""""""\n@author: Vincent Bonnet\n@description : render functions\n""""""\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\n\nFONT = {\'family\': \'serif\',\n        \'color\':  \'darkblue\',\n        \'weight\': \'normal\',\n        \'size\': 14,\n        }\n\ndef draw2D(function, optimiser):\n\n    interface2D = lambda x, y : function.value([x, y])\n\n    fig = plt.figure()\n    ax = Axes3D(fig)\n    ax.view_init(65, 60)\n\n    # display function\n    subdivisions = 40\n    min_arg, max_arg = function.ranges()\n    X = np.linspace(min_arg[0], max_arg[0], subdivisions)\n    Y = np.linspace(min_arg[1], max_arg[1], subdivisions)\n    X, Y = np.meshgrid(X, Y)\n    Z = interface2D(X, Y)\n    ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=\'winter\', alpha=0.5)\n    ax.contour(X, Y, Z, 20, colors=\'black\')\n\n    title = function.__name__\n    # display optimizer result\n    if optimiser:\n        results = np.asarray(optimiser(function))\n        X, Y = results[:,0],results[:,1]\n        Z = function.value(np.asarray([X,Y]))\n        color = np.linspace([1,0,0], [0,1,0], num=len(results))\n        ax.scatter3D(X, Y, Z, c=color, alpha=1.0, s=3)\n        title += \' - \' + optimiser.__name__\n        title += \' - iter(\' + str(len(results)-1) + \')\'\n\n    plt.title(title, fontdict=FONT)\n    ax.set_xlabel(\'x\')\n    ax.set_ylabel(\'y\')\n    ax.set_zlabel(\'f(x,y)\')\n    plt.show()'"
path_tracing/common.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : useful functions\n""""""\n\nimport functools\nimport time\n\ndef timeit(method):\n    @functools.wraps(method)\n    def execute(*args, **kwargs):\n        start_time = time.time()\n        result = method(*args, **kwargs)\n        elapsed_time = time.time() - start_time\n        print(\'timeit : %s %.3f sec\' % (method.__name__, elapsed_time))\n        return result\n\n    return execute\n\n'"
path_tracing/geometry.py,23,"b'""""""\n@author: Vincent Bonnet\n@description : functions to create geometry\n""""""\n\nimport numpy as np\nfrom jit import maths as jit_maths\n\ndef create_polygon_soup(num_triangles):\n    tv = np.zeros((num_triangles, 3, 3), dtype=float) # triangle vertices\n    tn = np.zeros((num_triangles, 3), dtype=float) # triangle normal\n    return tv, tn\n\ndef create_test_triangle(z_axis):\n    tv, tn = create_polygon_soup(1)\n    np.copyto(tv[0][0], [1,0,z_axis])\n    np.copyto(tv[0][1], [0,1,z_axis])\n    np.copyto(tv[0][2], [-1,0,z_axis])\n    np.copyto(tn[0], [0,0,1])\n    return tv, tn\n\ndef create_tri_quad(quad_corners):\n    tv, tn = create_polygon_soup(2)\n    np.copyto(tv[0][0], quad_corners[0])\n    np.copyto(tv[0][1], quad_corners[1])\n    np.copyto(tv[0][2], quad_corners[2])\n    np.copyto(tv[1][0], quad_corners[0])\n    np.copyto(tv[1][1], quad_corners[2])\n    np.copyto(tv[1][2], quad_corners[3])\n    n0 = jit_maths.cross(tv[0][2]-tv[0][0], tv[0][1]-tv[0][0])\n    n1 = jit_maths.cross(tv[1][2]-tv[1][0], tv[1][1]-tv[1][0])\n    jit_maths.normalize(n0)\n    jit_maths.normalize(n1)\n    np.copyto(tn[0], n0)\n    np.copyto(tn[1], n1)\n    return tv, tn\n\ndef create_quad(quad_corners):\n    tv, tn = create_polygon_soup(1)\n    np.copyto(tv[0][0], quad_corners[0])\n    np.copyto(tv[0][1], quad_corners[1])\n    np.copyto(tv[0][2], quad_corners[3])\n    n0 = jit_maths.cross(tv[0][2]-tv[0][0], tv[0][1]-tv[0][0])\n    jit_maths.normalize(n0)\n    np.copyto(tn[0], n0)\n    return tv, tn\n\ndef load_obj(path):\n    # this is not a fully functional obj-reader !\n    with open(path) as f:\n        content = f.readlines()\n\n    # gather vertices/normals/faces\n    vertices = []\n    normals = []\n    tri_vertex_ids = []\n    tri_normal_ids = []\n    for line in content:\n        tokens = line.split()\n        if len(tokens) == 0:\n            continue\n\n        if tokens[0]==\'v\': # x y z w\n            values = np.asarray([float(v) for v in tokens[1:4]])\n            vertices.append(values)\n        elif tokens[0]==\'vn\': # x y z\n            values = [float(v) for v in tokens[1:4]]\n            normals.append(values)\n        elif tokens[0]==\'f\': # f  v1/vt1/vn1   v2/vt2/vn2   v3/vt3/vn3 . . .\n            nVertexPerFace = len(tokens) - 1\n            validFace = (nVertexPerFace==3 or nVertexPerFace==4)\n            assert validFace, ""face should be tri/quad""\n\n            \'\'\'\n            if nVertexPerFace==4:\n                pass\n                # triangulation code\n                # https://notes.underscorediscovery.com/obj-parser-easy-parse-time-triangulation/\n            \'\'\'\n            nTriPerFace = nVertexPerFace - 2\n            for t in range(nTriPerFace):\n                tv = []\n                tn = []\n                vtx_ids = [0,1+t,2+t]\n                for vtx in vtx_ids:\n                    v_vt_vn = tokens[vtx+1].split(\'/\')\n                    tv.append(int(v_vt_vn[0]))\n                    tn.append(int(v_vt_vn[2]))\n\n                tri_vertex_ids.append(tv)\n                tri_normal_ids.append(tn)\n\n    # rescale and center the vertices\n    vertices = np.asarray(vertices)\n    min_v = np.min(vertices, axis=0)\n    max_v = np.max(vertices, axis=0)\n    # center\n    offset = (max_v + min_v)*-0.5\n    vertices += offset\n    # rescale\n    vertices /= 1000.0\n\n    # create the triangles\n    num_triangles = len(tri_vertex_ids)\n    tv, tn = create_polygon_soup(num_triangles)\n    for i in range(num_triangles):\n        tn[i] = np.asarray([0.,0.,0.])\n        for vtx in range(3):\n            tv[i][vtx] = vertices[tri_vertex_ids[i][vtx]]\n            tn[i] += normals[tri_normal_ids[i][vtx]]\n\n        jit_maths.normalize(tn[i])\n\n    return tv, tn\n'"
path_tracing/main.py,2,"b'""""""\n@author: Vincent Bonnet\n@description : Pathtracer with Python+Numba\n""""""\n\nimport IPython.display\n\nimport numpy as np\nimport io\nimport PIL\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\n\nimport common\nfrom scene import Scene\nimport jit.pathtracer as pathtracer\n\n@common.timeit\ndef force_jit(image, camera, details):\n    # jit compilation by calling a tiny scene\n    width, height = camera.width, camera.height\n    camera.set_resolution(2, 2)\n    pathtracer.render(image, camera, details, time.time())\n    camera.set_resolution(width, height)\n\n@common.timeit\ndef render(image, camera, details):\n    futures = []\n    with ThreadPoolExecutor(max_workers=pathtracer.CPU_COUNT) as executor:\n        start_time = time.time()\n        for thread_id in range(pathtracer.CPU_COUNT):\n            future = executor.submit(pathtracer.render, image, camera,\n                                     details, start_time, thread_id)\n            futures.append(future)\n\n    total_intersections = 0\n    for future in futures:\n        total_intersections += future.result()\n    print(\'Total intersections : %d\' % total_intersections)\n\n@common.timeit\ndef show(image):\n    buffer = io.BytesIO()\n    PIL.Image.fromarray(np.uint8(image*255)).save(buffer, \'png\')\n    IPython.display.display(IPython.display.Image(data=buffer.getvalue()))\n\ndef main():\n    pathtracer.MAX_DEPTH = 10 # max ray bounces\n    pathtracer.NUM_SAMPLES = 50 # number of sample per pixel\n    pathtracer.RANDOM_SEED = 10\n    pathtracer.SUPERSAMPLING = 2\n    pathtracer.CPU_COUNT = 6\n\n    scene = Scene()\n    #scene.load_cornell_box()\n    scene.load_teapot_scene()\n    details = scene.tri_details()\n\n    camera = scene.camera\n    camera.set_resolution(512, 512)\n    camera.set_supersampling(pathtracer.SUPERSAMPLING)\n    image = np.zeros((camera.height, camera.width, 3))\n\n    # Make sure the pathtracer.CONSTANTS are set before calling jitted functions\n    force_jit(image, camera, details)\n    render(image, camera, details)\n    show(image)\n\nif __name__ == \'__main__\':\n    main()\n'"
path_tracing/scene.py,11,"b'""""""\n@author: Vincent Bonnet\n@description : objects to describe a scene\n""""""\n\nimport math\nimport numpy as np\nimport geometry\nfrom jit import core as jit_core\nfrom jit import maths as jit_math\n\nclass Material:\n    def __init__(self, material = [1,1,1], mtype=0):\n        self.material = np.asarray(material)\n        self.materialtype = mtype # 0 reflectance, 1 : emittance\n\nclass TriangleSoup():\n    def __init__(self, triangle_vertices, normals, material):\n        self.tv = triangle_vertices\n        self.n = normals  # triangle normals\n        self.t = None # triangle tangents\n        self.b = None # triangle binormals\n        self.material = material\n\n    def num_triangles(self):\n        return len(self.n)\n\nclass Scene:\n    def __init__(self):\n        self.objects = []\n        self.camera = jit_core.Camera(320, 240)\n\n    def load_cornell_box(self):\n        # From http://www.graphics.cornell.edu/online/box/data.html\n        quad_v = [] # quad vertices\n        quad_m = [] # quad material\n        white = [1,1,1]\n        red = [0.57,0.025,0.025]\n        green = [0.025,0.236,0.025]\n        blue = [0,0,1]\n        black = [0,0,0]\n        light_intensity = 10.0\n        light_colour = [1*light_intensity,0.73*light_intensity,0.4*light_intensity]\n        # floor\n        quad_v.append([[552.8,0,0],[0,0,0],[0,0,559.2],[549.6,0,559.2]])\n        quad_m.append([white, 0])\n        # left wall\n        quad_v.append([[552.8,0,0],[549.6,0,559.2],[556,548.8,559.2],[556,548.8,0]])\n        quad_m.append([red, 0])\n        # right wall\n        quad_v.append([[0,0,559.2],[0,0,0],[0,548.8,0],[0,548.8,559.2]])\n        quad_m.append([green, 0])\n        # back wall\n        quad_v.append([[549.6,0,559.2],[0,0,559.2],[0,548.8,559.2],[556,548.8,559.2]])\n        quad_m.append([white, 0])\n        # ceiling (large light)\n        quad_v.append([[556,548.8,0],[556,548.8,559.2],[0,548.8,559.2],[0,548.8,0]])\n        quad_m.append([white, 0])\n        # short block\n        quad_v.append([[130,165,65],[82,165,225],[240,165,272],[290,165,114]])\n        quad_m.append([white, 0])\n        quad_v.append([[290,0,114],[290,165,114],[240,165,272],[240,0,272]])\n        quad_m.append([white, 0])\n        quad_v.append([[130,0,65],[130,165,65],[290,165,114],[290,0,114]])\n        quad_m.append([white, 0])\n        quad_v.append([[82,0,225],[82,165,225],[130,165,65],[130,0,65]])\n        quad_m.append([white, 0])\n        quad_v.append([[240,0,272],[240,165,272],[82,165,225],[82,0,225]])\n        quad_m.append([white, 0])\n        # tall block\n        quad_v.append([[423,330,247],[265,330,296],[314,330,456],[472,330,406]])\n        quad_m.append([white, 0])\n        quad_v.append([[423,0,247],[423,330,247],[472,330,406],[472,0,406]])\n        quad_m.append([white, 0])\n        quad_v.append([[472,0,406],[472,330,406],[314,330,456],[314,0,456]])\n        quad_m.append([white, 0])\n        quad_v.append([[314,0,456],[314,330,456],[265,330,296],[265,0,296]])\n        quad_m.append([white, 0])\n        quad_v.append([[265,0,296],[265,330,296],[423,330,247],[423,0,247]])\n        quad_m.append([white, 0])\n        # small light\n        # added an offset from the cornell box from 548.8 to 548\n        quad_v.append([[343,548.79,227],[343,548.79,332],[213,548.79,332],[213,548.79,227]])\n        quad_m.append([light_colour, 1])\n\n        # add quads\n        for i in range(len(quad_v)):\n            tv, n = geometry.create_tri_quad(quad_v[i])\n            material = Material(quad_m[i][0], quad_m[i][1])\n            self.objects.append(TriangleSoup(tv, n, material))\n        # set camera\n        np.copyto(self.camera.origin, [278, 273, -800])\n        self.camera.dir_z = 1.0\n        focal_length = 35 # in mm\n        sensor_size = 25 # in mm (sensor width and height)\n        self.camera.fovx = math.atan(sensor_size*0.5/focal_length) * 2\n\n    def load_teapot_scene(self):\n        # teapot\n        green = [0.025,0.236,0.025]\n        blue = [0.44,0.57,0.745]\n        tv, tn = geometry.load_obj(\'models/teapot.obj\')\n        self.objects.append(TriangleSoup(tv, tn, Material(green, 0)))\n        floor = [[-50,-34.29,-50],[-50,-34.29,50],[50,-34.29,50],[50,-34.29,-50]]\n        tv, tn = geometry.create_tri_quad(floor)\n        self.objects.append(TriangleSoup(tv, tn, Material(blue, 0)))\n        # light\n        light_intensity = 1.0\n        light_colour = [0*light_intensity,0.63*light_intensity,0.909*light_intensity]\n        light_quad = [[-1000,80,-1000],[-1000,80,1000],[1000,80,1000],[1000,80,-1000]]\n        tv, tn = geometry.create_tri_quad(light_quad)\n        self.objects.append(TriangleSoup(tv, tn, Material(light_colour, 1)))\n        # set camera\n        np.copyto(self.camera.origin, [0, 0, 100])\n        self.camera.dir_z = -1.0\n        self.camera.fovx = np.pi / 2.5\n\n\n\n    def tri_details(self):\n        # gather triangles and materials\n        num_triangles = 0\n        for obj in self.objects:\n            num_triangles += obj.num_triangles()\n\n        # numpy dtype to store structure of array\n        dtype_dict = {}\n        dtype_dict[\'names\'] = [\'tri_vertices\', \'tri_normals\', \'tri_tangents\',\n                               \'tri_binormals\', \'tri_materials\', \'tri_materialtype\']\n        dtype_dict[\'formats\'] = []\n        dtype_dict[\'formats\'].append((np.float32, (num_triangles,3,3)))\n        dtype_dict[\'formats\'].append((np.float32, (num_triangles,3)))\n        dtype_dict[\'formats\'].append((np.float32, (num_triangles,3)))\n        dtype_dict[\'formats\'].append((np.float32, (num_triangles,3)))\n        dtype_dict[\'formats\'].append((np.float32, (num_triangles,3)))\n        dtype_dict[\'formats\'].append((np.int32, num_triangles))\n        tri_data = np.zeros(1, dtype=np.dtype(dtype_dict, align=True))\n\n        # consolidate triangles in contiguous numpy array\n        index = 0\n        for tri in self.objects:\n            data = tri_data[0]\n            for i in range(len(tri.tv)):\n                data[\'tri_vertices\'][index] = tri.tv[i]\n                data[\'tri_normals\'][index] = tri.n[i]\n                data[\'tri_materialtype\'][index] = tri.material.materialtype\n                data[\'tri_materials\'][index] = tri.material.material\n                index += 1\n\n        jit_math.compute_tangents_binormals(tri_data[0][\'tri_normals\'],\n                                            tri_data[0][\'tri_tangents\'],\n                                            tri_data[0][\'tri_binormals\'])\n\n        print(\'num_triangles \' , num_triangles)\n\n        return tri_data\n'"
performance/performance_tests_array.py,4,"b'""""""\n@author: Vincent Bonnet\n@description : Evaluate CPU and stuff\n""""""\n\nimport time\nimport math\nimport sys\nimport numpy as np\nfrom numba import njit\nimport numba\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\ndef create_data(N):\n    \'\'\'\n    Create random numbers\n    \'\'\'\n    return np.random.rand(N)\n\n@njit\ndef function(value):\n    \'\'\'\n    Operation on a single value\n    \'\'\'\n    return math.sqrt(math.tan(value) * value * math.cos(value))\n\n\'\'\'\nAlgorithms\n - Pure Python Loop\n - Numpy Vectorized\n - Numba Single Thread\n\'\'\'\ndef python_loop(array):\n    for i in range(array.shape[0]):\n        array[i] = function(array[i])\n    return array\n\nvectorized_function = np.vectorize(function)\n\n@njit\ndef numba_loop(array):\n    for i in numba.prange(array.shape[0]):\n        array[i] = function(array[i])\n    return array\n\n@njit(parallel=True)\ndef numba_loop_threaded(array):\n    for i in numba.prange(array.shape[0]):\n        array[i] = function(array[i])\n    return array\n\n\'\'\'\nTest Algorithms\n\'\'\'\nprint(""Python Distribution"")\nprint(sys.version)\n\n# Prepare plot\nfont = {\'color\':  \'darkblue\',\n         \'weight\': \'normal\',\n         \'size\': 18}\nmpl.style.use(""seaborn"")\nplt.title(\'Python performance tests - array\', fontdict=font)\nplt.xlabel(\'array size\')\nplt.ylabel(\'time (s)\')\n\nplot_colours = [""xkcd:aqua"",\n            ""xkcd:plum"",\n            ""xkcd:teal"",\n            ""xkcd:chartreuse"",\n            ""xkcd:olive"",\n            ""xkcd:green"",\n            ""xkcd:red""]\n\n# Run Tests\narray_sizes = [1e4, 1e5, 1e6, 1e7]\nalgorithms = [python_loop, vectorized_function, numba_loop, numba_loop_threaded]\nalgorithm_names = [\'Pure Python\', \'Numpy.Vectorized\', \'Numba Single Thread\', \'Numba Threaded\' ]\n\nfor algo_id in range(len(algorithms)):\n\n    algorithm = algorithms[algo_id]\n    algorithm_name = algorithm_names[algo_id]\n\n    time_values = np.zeros(len(array_sizes))\n\n    for size_id in range(len(array_sizes)):\n\n        array = create_data(int(array_sizes[size_id]))\n\n        # the line below is only to compile function in jit mode\n        dummy_array = np.random.rand(1)\n        algorithm(dummy_array)\n\n        start_time = time.time()\n        algorithm(array)\n        end_time = time.time()\n        computationTime = end_time - start_time\n        time_values[size_id] = computationTime\n        \n        log = algorithm_name + \' %f sec\' % (computationTime)\n        print(log)\n\n    print(array_sizes)\n    plt.plot(array_sizes, time_values, color=plot_colours[algo_id], label=algorithm_name)\n\n# Complete plot\nplt.legend(bbox_to_anchor=(1, 1), loc=2)\nplt.show()\n'"
skinning/dual_quaternion.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : Dual quaternion class\n""""""\n# TODO'"
skinning/geometry.py,6,"b'""""""\n@author: Vincent Bonnet\n@description : Geometry\n""""""\n\nimport numpy as np\n\ndef create_beam_mesh(min_x, min_y, max_x, max_y, cell_x, cell_y):\n    \'\'\'\n    Creates a mesh as a beam\n    Example of beam with cell_x(3) and cell_y(2):\n        |8 .. 9 .. 10 .. 11\n        |4 .. 5 .. 6  .. 7\n        |0 .. 1 .. 2  .. 3\n    \'\'\'\n    num_vertices = (cell_x + 1) * (cell_y + 1)\n    vertex_buffer = np.zeros((num_vertices,2))\n\n    # Set Points\n    vertex_id = 0\n    axisx = np.linspace(min_x, max_x, num=cell_x+1, endpoint=True)\n    axisy = np.linspace(min_y, max_y, num=cell_y+1, endpoint=True)\n\n    for j in range(cell_y+1):\n        for i in range(cell_x+1):\n            vertex_buffer[vertex_id] = (axisx[i], axisy[j])\n            vertex_id += 1\n\n    # Set Edge Indices\n    cell_to_ids = lambda i, j: i + (j*(cell_x+1))\n    edge_indices = []\n    for j in range(cell_y):\n        ids = [cell_to_ids(0, j), cell_to_ids(0, j+1)]\n        edge_indices.append(ids)\n        ids = [cell_to_ids(cell_x, j), cell_to_ids(cell_x, j+1)]\n        edge_indices.append(ids)\n\n    for i in range(cell_x):\n        ids = [cell_to_ids(i, 0), cell_to_ids(i+1, 0)]\n        edge_indices.append(ids)\n        ids = [cell_to_ids(i, cell_y), cell_to_ids(i+1, cell_y)]\n        edge_indices.append(ids)\n\n    index_buffer = np.array(edge_indices, dtype=int)\n\n    return Mesh(vertex_buffer, index_buffer)\n\nclass Mesh:\n    \'\'\'\n    Mesh contains a vertex buffer, index buffer and weights map for binding\n    \'\'\'\n    def __init__(self, vertex_buffer, index_buffer):\n        self.vertex_buffer = np.asarray(vertex_buffer)\n        self.index_buffer = np.asarray(index_buffer)\n\n    def get_boundary_segments(self):\n        segments = []\n\n        for vertex_ids in self.index_buffer:\n            segments.append([self.vertex_buffer[vertex_ids[0]],\n                             self.vertex_buffer[vertex_ids[1]]])\n\n        return segments\n'"
skinning/hierarchy.py,17,"b'""""""\n@author: Vincent Bonnet\n@description : Skeleton and Bone class\n""""""\n\n# TODO - see bone_children[0] : add support for multiple children per bone\n\nimport numpy as np\n\ndef create_skeleton_with_4_bones():\n    \'\'\'\n    Create a skeleton object\n    \'\'\'\n    root_bone = Bone(length = 3.0, rotation = 0.0)\n    bone1 = Bone(length = 3.0, rotation = 0.0)\n    bone2 = Bone(length = 3.0, rotation = 0.0)\n    bone3 = Bone(length = 3.0, rotation = 0.0)\n\n    root_bone.rotation_animation = lambda time : np.sin(time / 2.0 * np.pi) * 20.0\n    bone1.rotation_animation = lambda time : np.sin(time / 2.0 * np.pi) * 24.0\n    bone2.rotation_animation = lambda time : np.sin(time / 2.0 * np.pi) * 32.0\n    bone3.rotation_animation = lambda time : np.sin(time / 2.0 * np.pi) * 36.0\n\n    skeleton = Skeleton([-6.0, 0.0], root_bone)\n    skeleton.add_bone(root_bone)\n    skeleton.add_bone(bone1, root_bone)\n    skeleton.add_bone(bone2, bone1)\n    skeleton.add_bone(bone3, bone2)\n\n    return skeleton\n\ndef create_skeleton_with_2_bones():\n    \'\'\'\n    Create a skeleton object\n    \'\'\'\n    root_bone = Bone(length = 6.0, rotation = 0.0)\n    bone1 = Bone(length = 6.0, rotation = 0.0)\n\n    root_bone.rotation_animation = lambda time : np.sin(time / 2.0 * np.pi) * 0\n    bone1.rotation_animation = lambda time : np.sin(time / 2.0 * np.pi) * 90\n\n    skeleton = Skeleton([-6.0, 0.0], root_bone)\n    skeleton.add_bone(root_bone)\n    skeleton.add_bone(bone1, root_bone)\n\n    return skeleton\n\n\nclass Bone:\n    def __init__(self, length = 1.0, rotation = 0.0):\n        self.length = length\n        self.rotation = rotation # in degrees\n        self.rotation_animation = lambda time : rotation\n        # hirerarchy info\n        self.bone_parent = None\n        self.bone_children = []\n\n    def get_homogenous_transform(self):\n        \'\'\'\n        3x3 Matrix combining rotation and displacement\n        where R is 2x2 rotation matrix\n        and d is 2d vector\n        | R  d |\n        | 0  1 |\n        \'\'\'\n        H = np.zeros((3,3))\n        cos = np.cos(np.deg2rad(self.rotation))\n        sin = np.sin(np.deg2rad(self.rotation))\n        H[0, 0] = cos\n        H[1, 1] = cos\n        H[0, 1] = -sin\n        H[1, 0] = sin\n        H[0, 2] = cos * self.length\n        H[1, 2] = sin * self.length\n        H[2, 2] = 1.0\n        return H\n\n    def animate(self, time):\n        self.rotation = self.rotation_animation(time)\n\nclass Skeleton:\n    def __init__(self, root_position, root_bone):\n        self.root_position = np.asarray(root_position)\n        self.root_bone = root_bone\n        self.bones = []\n\n    def add_bone(self, bone, bone_parent = None):\n        self.bones.append(bone)\n        if bone_parent is not None:\n            bone.bone_parent = bone_parent\n            bone_parent.bone_children.append(bone)\n\n    def get_homogenous_transform(self):\n        H = np.identity(3)\n        H[0, 2] = self.root_position[0]\n        H[1, 2] = self.root_position[1]\n        return H\n\n    def get_relative_rotations(self):\n        num_bones = len(self.bones)\n        relative_rotations = np.zeros(num_bones)\n\n        bone_id = 0\n\n        bone = self.root_bone\n        while bone is not None:\n\n            relative_rotation = 0.0\n            if bone.bone_parent:\n                relative_rotation = bone.rotation - bone.bone_parent.rotation\n\n            # Go to the children\n            if len(bone.bone_children) > 0:\n                bone = bone.bone_children[0]\n            else:\n                bone = None\n\n            relative_rotations[bone_id] = relative_rotation\n            bone_id += 1\n\n        return relative_rotations\n\n\n    def get_bone_homogenous_transforms(self):\n        \'\'\'\n        Returns the world space transform of each bones\n        \'\'\'\n        num_bones = len(self.bones)\n        bone_transforms = np.zeros((num_bones,3,3))\n\n        H = self.get_homogenous_transform()\n        bone_id = 0\n\n        bone = self.root_bone\n        while bone is not None:\n            # Concatenate transformation matrice\n            bone_H = bone.get_homogenous_transform()\n            H = np.matmul(H, bone_H)\n\n            # Go to the children\n            if len(bone.bone_children) > 0:\n                bone = bone.bone_children[0]\n            else:\n                bone = None\n\n            bone_transforms[bone_id] = H\n            bone_id += 1\n\n        return bone_transforms\n\n    def get_bone_segments(self):\n        homogenous_coordinate = np.asarray([0.0, 0.0, 1.0])\n        bone_transforms = self.get_bone_homogenous_transforms()\n\n        segments = []\n\n        H = self.get_homogenous_transform()\n\n        prev_pos = np.matmul(H, homogenous_coordinate)\n\n        for bone_id, bone_H in enumerate(bone_transforms):\n\n            next_pos = np.matmul(bone_H, homogenous_coordinate)\n            segments.append([prev_pos[0:2], next_pos[0:2]])\n            prev_pos = next_pos\n\n        return segments\n\n    def animate(self, time):\n        for bone in self.bones:\n            bone.animate(time)\n'"
skinning/linear_blend_skinning.py,20,"b'""""""\n@author: Vincent Bonnet\n@description : Linear blend skinning algorithm\n""""""\n\nimport numpy as np\n\ndef distance_from_segment(p, seg_p1, seg_p2):\n    \'\'\'\n    Distance from segment [seg_p1, seg_p2] and point p\n    \'\'\'\n    d = seg_p2 - seg_p1\n    d_norm = np.linalg.norm(d)\n    d_normalized = d / d_norm\n    t = np.dot(p - seg_p1, d_normalized)\n    t = min(max(t, 0.0), d_norm)\n    projected_p = seg_p1 + d_normalized * t\n    return np.linalg.norm(p - projected_p)\n\nclass LinearBlendSkinning:\n\n    def __init__(self, mesh, skeleton):\n        self.mesh = mesh\n        self.skeleton = skeleton\n        num_vertices = len(self.mesh.vertex_buffer)\n        num_bones = len(self.skeleton.bones)\n        self.weights_map = np.zeros((num_bones, num_vertices))\n        self.local_homogenous_vertices = np.zeros((num_vertices, 3))\n        self.local_inv_homogeneous_transforms = np.zeros((num_bones,3,3))\n\n    def attach_mesh(self, max_influences, kernel_func):\n        num_bones = len(self.skeleton.bones)\n        bone_segments = self.skeleton.get_bone_segments()\n\n        # Compute weights per bone per vertices (weights map) from kernel function\n        for vertex_id, vertex in enumerate(self.mesh.vertex_buffer):\n            for bone_id, bone_seg in enumerate (bone_segments):\n                distance = distance_from_segment(vertex, bone_seg[0], bone_seg[1])\n                self.weights_map[bone_id][vertex_id] = kernel_func(distance)\n\n        # Updates the weights map by limiting ...\n        # the number of influences from the n closest vertices\n        num_influences = min(num_bones, max_influences)\n        for vertex_id, vertex in enumerate(self.mesh.vertex_buffer):\n            vertex_weights = np.zeros(num_bones)\n            for bone_id, bone_seg in enumerate (bone_segments):\n                vertex_weights[bone_id] = self.weights_map[bone_id][vertex_id]\n\n            vertex_weigths_sorted_index = np.argsort(vertex_weights)\n            for vtx_id in range(num_bones - num_influences):\n                vertex_weights[vertex_weigths_sorted_index[vtx_id]] = 0.0\n\n            vertex_weights /= np.sum(vertex_weights)\n            for bone_id, bone_seg in enumerate (bone_segments):\n                self.weights_map[bone_id][vertex_id] = vertex_weights[bone_id]\n\n        # Store the local inverse homogeneous transform and local homogeneous vector\n        bone_transforms = self.skeleton.get_bone_homogenous_transforms()\n        for bone_id, bone_transform in enumerate(bone_transforms):\n            self.local_inv_homogeneous_transforms[bone_id] = np.linalg.inv(bone_transform)\n\n        for vertex_id, vertex in enumerate(self.mesh.vertex_buffer):\n            local_vertex_homogenous = np.ones(3)\n            local_vertex_homogenous[0:2] = vertex\n            self.local_homogenous_vertices[vertex_id] = local_vertex_homogenous\n\n        # Update the world space vertices from the local_homogenous_vertex\n        # It should not modify the current configuration and only used for debugging\n        self.update_mesh()\n\n    def update_mesh(self):\n        world_homogenous_vertices = self.local_to_world(self.local_homogenous_vertices)\n        for vertex_id, vertex in enumerate(world_homogenous_vertices):\n            self.mesh.vertex_buffer[vertex_id][0:2] = vertex[0:2]\n\n    def local_to_world(self, local_homogenous_vertices):\n        \'\'\'\n        Convert homogenous vertices from local to world space\n        local_homogenous_vertices should be the size of the self.mesh.vertex_buffer\n        \'\'\'\n        assert(len(local_homogenous_vertices) == len(self.local_homogenous_vertices))\n        world_homogenous_vertices = np.zeros((len(local_homogenous_vertices), 3))\n\n        bone_transforms = self.skeleton.get_bone_homogenous_transforms()\n        for vertex_id, local_homogenous_vertex in enumerate(local_homogenous_vertices):\n            # Compute total transform matrix\n            total_transform = np.zeros((3,3))\n            for bone_id, bone_transform in enumerate(bone_transforms):\n                weight = self.weights_map[bone_id][vertex_id]\n                invT0 = self.local_inv_homogeneous_transforms[bone_id]\n                T = (bone_transforms[bone_id])\n                total_transform += np.matmul(T * weight, invT0)\n\n            # Transform mesh vertex\n            world_homogenous_vertex = np.matmul(total_transform, local_homogenous_vertex)\n            world_homogenous_vertices[vertex_id] = world_homogenous_vertex\n\n        return world_homogenous_vertices\n\n    def world_to_local(self, world_homogenous_vertices):\n        \'\'\'\n        Convert homogenous vertices from world to local space\n        world_homogenous_vertices should be the size of the self.mesh.vertex_buffer\n        \'\'\'\n        assert(len(world_homogenous_vertices) == len(self.local_homogenous_vertices))\n        local_homogenous_vertices = np.zeros((len(world_homogenous_vertices), 3))\n\n        bone_transforms = self.skeleton.get_bone_homogenous_transforms()\n        for vertex_id, world_homogenous_vertex in enumerate(world_homogenous_vertices):\n            # Compute total transform matrix\n            total_transform = np.zeros((3,3))\n            for bone_id, bone_transform in enumerate(bone_transforms):\n                weight = self.weights_map[bone_id][vertex_id]\n                invT0 = self.local_inv_homogeneous_transforms[bone_id]\n                T = (bone_transforms[bone_id])\n                total_transform += np.matmul(T * weight, invT0)\n\n            # Transform mesh vertex\n            inv_total_transform = np.linalg.inv(bone_transform)\n            local_homogenous_vertex = np.matmul(inv_total_transform, world_homogenous_vertex)\n            local_homogenous_vertices[vertex_id] = local_homogenous_vertex\n\n        return local_homogenous_vertices\n\n'"
skinning/main.py,1,"b'""""""\n@author: Vincent Bonnet\n@description :Skinning Main\n""""""\n\nimport hierarchy\nimport geometry\nimport render\nfrom linear_blend_skinning import LinearBlendSkinning\nfrom pose_space_deformer import PoseSpaceDeformer\nimport pose_space_deformer\nimport numpy as np\n\n\'\'\'\nUser Parameters\n\'\'\'\n# Sequence settings\nNUM_FRAMES = 97\nFRAME_TIME_STEP = 1.0 / 24.0\n\n# Geometry settings\nBEAM_MIN_X = -7.0\nBEAM_MIN_Y = -1.0\nBEAM_MAX_X = 7.0\nBEAM_MAX_Y = 1.0\nBEAM_CELL_X = 20\nBEAM_CELL_Y = 2\n\n# Weight function settings\nKERNEL_PARAMETER = 1.0\nKERNEL_FUNCTION = lambda v : np.exp(-np.square((v * KERNEL_PARAMETER)))\nBIDDING_MAX_INFLUENCES = 2\n\n# Pose Space Deformation\nNUM_POSES = 10\n\n# Folder output\nRENDER_FOLDER_PATH = """" # specify a folder to export png files\n# Used command  ""magick -loop 0 -delay 4 *.png out.gif""  to convert from png to animated gif\n\ndef linear_blend_skinning():\n    \'\'\'\n    Linear blend skinning main (or Smooth skinning)\n    \'\'\'\n    mesh = geometry.create_beam_mesh(BEAM_MIN_X, BEAM_MIN_Y, BEAM_MAX_X, BEAM_MAX_Y, BEAM_CELL_X, BEAM_CELL_Y)\n    skeleton = hierarchy.create_skeleton_with_2_bones()\n\n    linear_blend_skinning = LinearBlendSkinning(mesh, skeleton)\n    linear_blend_skinning.attach_mesh(max_influences = BIDDING_MAX_INFLUENCES, kernel_func = KERNEL_FUNCTION)\n\n    for frame_id in range(NUM_FRAMES):\n        skeleton.animate(frame_id * FRAME_TIME_STEP)\n        linear_blend_skinning.update_mesh()\n        render.draw(mesh, skeleton, linear_blend_skinning.weights_map, None, frame_id, RENDER_FOLDER_PATH)\n\ndef pose_based_deformation():\n    \'\'\'\n    PSD main\n    \'\'\'\n    smooth_mesh = geometry.create_beam_mesh(BEAM_MIN_X, BEAM_MIN_Y, BEAM_MAX_X, BEAM_MAX_Y, BEAM_CELL_X, BEAM_CELL_Y)\n    rigid_mesh = geometry.create_beam_mesh(BEAM_MIN_X, BEAM_MIN_Y, BEAM_MAX_X, BEAM_MAX_Y, BEAM_CELL_X, BEAM_CELL_Y)\n    skeleton = hierarchy.create_skeleton_with_2_bones()\n    pose_deformers = PoseSpaceDeformer()\n\n    # Training Part\n    # Create poses from a SmoothSkinning (max_influences > 1) and RigidSkinning (max_influences = 1)\n    smooth_skinning = LinearBlendSkinning(smooth_mesh, skeleton)\n    smooth_skinning.attach_mesh(max_influences = 4, kernel_func = KERNEL_FUNCTION)\n    rigid_skinning = LinearBlendSkinning(rigid_mesh, skeleton)\n    rigid_skinning.attach_mesh(max_influences = 1, kernel_func = KERNEL_FUNCTION)\n\n    for pose_id in range(NUM_POSES):\n        # create a new pose\n        frame_id = pose_id * (NUM_FRAMES / NUM_POSES)\n        skeleton.animate(frame_id * FRAME_TIME_STEP)\n        smooth_skinning.update_mesh()\n        rigid_skinning.update_mesh()\n\n        # record the new feature and mesh from the pose\n        feature = pose_space_deformer.feature_from_skeleton(skeleton)\n        psd_target = smooth_skinning.mesh.vertex_buffer\n        underlying_surface = rigid_skinning.mesh.vertex_buffer\n\n        pose_deformers.add_pose(feature, underlying_surface, psd_target)\n        last_displacement = pose_deformers.displacements[-1]\n        render.draw(rigid_mesh, skeleton, smooth_skinning.weights_map, last_displacement, frame_id, RENDER_FOLDER_PATH)\n\ndef main():\n    \'\'\'\n    Main\n    \'\'\'\n    pose_based_deformation();\n\nif __name__ == \'__main__\':\n    main()\n\n'"
skinning/pose_space_deformer.py,1,"b""'''\n@author: Vincent Bonnet\n@description : Pose Space Deformer\n'''\n\nimport numpy as np\n\n'''\nPoseSpaceDeformer decouples animation control from target geometry\nIt maps features with PSD target\na feature can be the angle between two bones\na PSD target is the final geometry or the displacement relative to an existing underlying skinning\nThis version of PoseSpaceDeformer compute the displacement on top of underlying skinning\n'''\n\ndef feature_from_skeleton(skeleton):\n    return skeleton.get_relative_rotations()\n\nclass PoseSpaceDeformer:\n    def __init__(self):\n        self.features = []\n        self.underlying_surfaces = []\n        self.psd_targets = []\n        self.displacements = []\n\n    def add_pose(self, feature, underlying_surface, psd_target):\n        self.features.append(feature)\n        self.underlying_surfaces.append(underlying_surface)\n        self.psd_targets.append(psd_target)\n        self.displacements.append(np.subtract(psd_target, underlying_surface))\n\n    def compute_displacement(feature):\n        # TODO\n        pass\n"""
skinning/render.py,3,"b'""""""\n@author: Vincent Bonnet\n@description : Render Skinning\n""""""\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.collections import LineCollection\nfrom matplotlib import colors as mcolors\n\ndef draw(mesh, skeleton, weights_map, displacement, frame_id, render_folder_path = """"):\n    \'\'\'\n    Drawing function to display the mesh and skeleton\n    \'\'\'\n    fig = plt.figure()\n    font = {\'color\':  \'darkblue\',\n                 \'weight\': \'normal\',\n                 \'size\': 18}\n    ax = fig.add_subplot(111)\n    ax.axis(\'equal\')\n    ax.set_xlim(-16, 16)\n    ax.set_ylim(-16, 16)\n    plt.title(\'Linear Skinning\', fontdict = font)\n\n    colors_template = [mcolors.to_rgba(c)\n          for c in plt.rcParams[\'axes.prop_cycle\'].by_key()[\'color\']]\n\n    # Draw mesh (points and edges)\n    x, y = zip(*mesh.vertex_buffer)\n    point_colors = np.ones((len(mesh.vertex_buffer), 4))\n\n    num_bones = len(skeleton.bones)\n    num_vertices = len(mesh.vertex_buffer)\n    for vertex_id in range(num_vertices):\n        point_color = np.zeros(3)\n\n        for bone_id in range(num_bones):\n            weight = weights_map[bone_id][vertex_id]\n            point_color += (np.asarray(colors_template[bone_id])[0:3] * weight)\n\n        point_colors[vertex_id][0:3] = point_color\n\n    ax.scatter(x, y, color=point_colors, s=3.0)\n\n    segments = mesh.get_boundary_segments()\n    line_segments = LineCollection(segments,\n                               linewidths=1.0,\n                               colors=\'orange\',\n                               linestyles=\'-\',\n                               alpha=1.0)\n    ax.add_collection(line_segments)\n\n    # Draw displacement\n    if displacement is not None:\n        segments = []\n        for vertex_id, vertex in enumerate(mesh.vertex_buffer):\n            segments.append([vertex, vertex+displacement[vertex_id]])\n\n        line_segments = LineCollection(segments,\n                               linewidths=1.0,\n                               colors=\'green\',\n                               linestyles=\'-\',\n                               alpha=1.0)\n\n        ax.add_collection(line_segments)\n\n\n\n    # Draw skeleton\n    segments = skeleton.get_bone_segments()\n    line_segments = LineCollection(segments,\n                                   linewidths=3.0,\n                                   colors=colors_template,\n                                   linestyles=\'-\',\n                                   alpha=1.0)\n\n    ax.add_collection(line_segments)\n    plt.show()\n\n    # Export figure into a png file\n    if len(render_folder_path) > 0:\n        filename = str(frame_id).zfill(4) + "" .png""\n        fig.savefig(render_folder_path + ""/"" + filename)\n'"
stencil_codes/convolution_matrix.py,7,"b'""""""\n@author: Vincent Bonnet\n@description : convolution matrix on GPU\n""""""\n\nimport numpy as np\nimport numba\nimport math\nimport skimage\nimport img_utils\n\n@numba.vectorize([\'float32(float32, float32)\'], target=\'cuda\')\ndef combine_images(a, b):\n    return max(min(a+b, 1.0), 0.0)\n\n@numba.cuda.jit\ndef apply_kernel(image, imageResult, Gx):\n    #x = numba.cuda.threadIdx.x + (cuda.blockIdx.x * cuda.blockDim.x)\n    #y = numba.cuda.threadIdx.y + (cuda.blockIdx.y * cuda.blockDim.y)\n    x, y = numba.cuda.grid(2)\n    value = 0.0\n    for i in range(-1, 2):\n        for j in range(-1, 2):\n            xi = x + i\n            yi = y + j\n            if xi >= 0 and yi >= 0 and xi < image.shape[0] and yi < image.shape[1]:\n                value += (image[xi, yi] * Gx[i, j])\n\n    imageResult[x, y] = value\n\ndef image_processing(image, kernels):\n    # Setup images\n    images = [None, None]\n    images[0] = image.copy()\n    images[1] = image.copy()\n\n    # Setup blocks\n    threadsPerBlock = (16, 16)\n    blocksPerGridX = math.ceil(images[0].shape[0] / threadsPerBlock[0])\n    blocksPerGridY = math.ceil(images[0].shape[1] / threadsPerBlock[1])\n    blocksPerGrid = (blocksPerGridX, blocksPerGridY)\n\n    # Run kernel on Cuda\n    apply_kernel[blocksPerGrid, threadsPerBlock](images[0], images[1], kernels[0])\n    apply_kernel[blocksPerGrid, threadsPerBlock](images[1], images[0], kernels[1])\n\n    # Show Result\n    skimage.io.imshow(combine_images(image, images[0]))\n\nif __name__ == \'__main__\':\n    # create image\n    image = skimage.img_as_float(skimage.color.rgb2gray(skimage.data.chelsea())).astype(np.float32)\n    image = img_utils.resize_image_and_keep_ratio(image, 512, 512)\n    # Common Kernels\n    sobelYKernel = np.array([[1.0, 2.0, 1.0], [0.0, 0.0, 0.0], [-1.0, -2.0, -1.0]])\n    gaussianBlurKernel = np.array([[1.0, 2.0, 1.0], [2.0, 4.0, 2.0], [1.0, 2.0, 1.0]]) / 16\n    \'\'\'\n    sobelXKernel = np.array([[-1.0, 0.0, 1.0], [-2.0, 0.0, 2.0], [-1.0, 0.0, 1.0]])\n    identityKernel = np.array([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 0.0]])\n    sharpenKernel = np.array([[0.0, -1.0, 0.0], [-1.0, 5.0, -1.0], [0.0, -1.0, 0.0]])\n    embossKernel = np.array([[-2.0, -1.0, 0.0], [-1.0, 1.0, 1.0], [0.0, 1.0, 2.0]])\n    \'\'\'\n    # Execute\n    image_processing(image, [sobelYKernel, gaussianBlurKernel])\n\n'"
stencil_codes/game_of_life.py,1,"b'""""""\n@author: Vincent Bonnet\n@description : Game of life on GPU\n""""""\n\nimport math\nimport numpy as np\nfrom numba import cuda\nfrom skimage import data, io, color, feature\nimport skimage as skimage\nimport matplotlib.pyplot as plt\nimport img_utils\n\nRENDER_FOLDER = """"\n\n@cuda.jit\ndef apply_cellular_automata_rules(image, imageResult):\n    #x = cuda.threadIdx.x + (cuda.blockId x.x * cuda.blockDim.x)\n    #y = cuda.threadIdx.y + (cuda.blockIdx.y * cuda.blockDim.y)\n    x, y = cuda.grid(2)\n    numNeighbours = 0\n    for i in range(-1, 2):\n        for j in range(-1, 2):\n            if i != 0 or j != 0:\n                xi = x + i\n                yi = y + j\n                if xi >= 0 and yi >= 0 and xi < image.shape[0] and yi < image.shape[1] and image[xi, yi] == 1.0:\n                    numNeighbours += 1\n\n    imageResult[x, y] = image[x, y]\n    if imageResult[x, y] == 1.0: # live cell ...\n        if numNeighbours < 2: # under population.\n            imageResult[x, y] = 0.0\n        elif numNeighbours > 3: # overpopulation\n            imageResult[x, y] = 0.0\n    else: # dead cell ...\n        if numNeighbours == 3: # reproduction\n            imageResult[x, y] = 1.0\n\n\ndef conways_game_of_life(image, iterations):\n    # Setup images\n    images = [None, None]\n    images[0] = image\n    images[0] = feature.canny(images[0], sigma=1)\n    images[1] = images[0].copy()\n\n    # Setup blocks\n    threadsPerBlock = (16, 16)\n    blocksPerGridX = math.ceil(images[0].shape[0] / threadsPerBlock[0])\n    blocksPerGridY = math.ceil(images[0].shape[1] / threadsPerBlock[1])\n    blocksPerGrid = (blocksPerGridX, blocksPerGridY)\n\n    # Run kernel on Cuda and show results\n    id0 = True\n\n    for i in range(1, iterations):\n        id0 = not id0 # buffer id to process\n        id1 = not id0 # buffer id to hold the result\n        fig = plt.figure()\n        io.imshow(images[id0])\n        if i > 10:\n            apply_cellular_automata_rules[blocksPerGrid, threadsPerBlock](images[int(id0)], images[int(id1)])\n        if (len(RENDER_FOLDER)):\n            filename = str(i).zfill(4) + "" .png""\n            fig.savefig(RENDER_FOLDER + ""/"" + filename)\n\nif __name__ == \'__main__\':\n    image = skimage.img_as_float(color.rgb2gray(data.chelsea())).astype(np.float32)\n    image = img_utils.resize_image_and_keep_ratio(image, 128, 128)\n\n    conways_game_of_life(image, 50)\n'"
stencil_codes/img_utils.py,5,"b'""""""\n@author: Vincent Bonnet\n@description : useful image functions\n""""""\n\nimport numpy as np\nimport skimage\n\ndef resize_image_and_keep_ratio(image, width, height):\n    \'\'\'\n    Resize an image while keeping its ratio\n    \'\'\'\n    out = np.zeros((width, height), dtype=np.float32)\n    scaleX = image.shape[0] / width\n    scaleY = image.shape[1] / height\n    maxScale = max(scaleX, scaleY)\n    newWidth = np.int(image.shape[0] / maxScale)\n    newHeight = np.int(image.shape[1] / maxScale)\n    tmpImage = skimage.transform.resize(image, (newWidth, newHeight))\n    offsetX = np.int((width - tmpImage.shape[0]) / 2)\n    offsetY = np.int((height - tmpImage.shape[1]) / 2)\n    out[offsetX:offsetX+tmpImage.shape[0], offsetY:offsetY+tmpImage.shape[1]] = tmpImage\n    return out\n'"
stencil_codes/laplace_inpainting.py,7,"b'""""""\n@author: Vincent Bonnet\n@description : Image recovery by solving Laplace\'s Equation on CPU\n    Jacobi method solves Ax=b where\n    A contains the coefficient of the discrete laplace operator\n    0 -1  0\n    -1 4 -1\n    0 -1  0\n    x is the unknown discretized function (array)\n    b is equal to zero\n    By definition, The jacobi iteration is :\n    xi(k+1) = 1/aii * (bi - sum(aij * xj(k)) \'where j!=i\')\n    because b is a zero array and aii reference the coefficient 4\n    xi(k+1) = 1/4 * (- sum(aij * xj(k)) \'for j!=i\')\n    and aij are -1 for j!=i\n    => xi(k+1) = 1/4 * (sum(xj(k)) \'for j!=i\')\n""""""\n\nimport numba\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport skimage\n\n\'\'\'\n Global Parameters\n\'\'\'\nNUM_NODES = 128 # For GPU should be a multiplier of TPB\nJACOBI_ITERATIONS = 10000\nTPB = 16 # Thread per block\nGPU_SHARED_MEMORY_SIZE = TPB + 2 # +2 because the stencil requires -1 and +1\n\ndef create_domain(num_nodes=64):\n    \'\'\'\n    Returns domain nodes along x, y and grid values\n    The values come from an image\n    \'\'\'\n    # Convert image to greyscale numpy 2D-array\n    image = skimage.img_as_float(skimage.color.rgb2gray(skimage.data.chelsea())).astype(np.float32)\n    # Resize the image to (num_nodes, num_nodes) shape\n    image = skimage.transform.resize(image, output_shape=(num_nodes, num_nodes), anti_aliasing=True)\n    # Flip the image upside-down\n    image = np.flipud(image)\n    # Finally, turn the image into a single memory block to be used by Cuda\n    image = np.ascontiguousarray(image, dtype=np.float32)\n\n    return image\n\ndef create_mask(num_nodes=64):\n    values = np.random.rand(num_nodes, num_nodes)\n    ratio_of_zero = 0.4 # 10 % dark area\n    values[values > ratio_of_zero] = 1.0\n    values[values <= ratio_of_zero] = 0.0\n    values[0][:] = 1.0 # top row\n    values[-1][:] = 1.0 # bottom row\n    values[:,0] = 1.0 # left column\n    values[:,-1] = 1.0 # right column\n    values[40:54, 40:50]= 0.0 # extra dark area for some reasons\n    values[80:95, 65:75]= 0.0 # extra dark area for no reason\n\n    return values\n\n@numba.njit(parallel=True)\ndef numba_jacobi_solver_with_mask(x, next_x, mask_indices):\n    num_mask_indices = len(mask_indices)\n\n    for it in numba.prange(num_mask_indices):\n        mask_index = mask_indices[it]\n        i = mask_index[0]\n        j = mask_index[1]\n        next_x[i][j] = (x[i-1][j] + x[i+1][j] + x[i][j-1] + x[i][j+1]) * 0.25\n\ndef laplace_inpainting(domain, mask, num_iterations):\n    buffers = [domain, np.copy(domain)]\n    for iteration in range(num_iterations):\n        numba_jacobi_solver_with_mask(buffers[0], buffers[1], mask_indices)\n        buffers[0], buffers[1] = buffers[1], buffers[0] # swap buffers\n\n    # show result\n    fig, ax = plt.subplots()\n    domain_points = np.linspace(0, 10, num=NUM_NODES, endpoint=True)\n    im = ax.pcolormesh(domain_points, domain_points, buffers[0], cmap=""gist_gray"", antialiased=True, shading=""gouraud"")\n    fig.colorbar(im)\n    #fig.savefig(""test.png"")\n\nif __name__ == \'__main__\':\n    # create domain\n    domain = create_domain(NUM_NODES)\n    mask_values = create_mask(NUM_NODES)\n    domain *= mask_values\n    mask_indices = np.argwhere(mask_values == 0)\n    laplace_inpainting(domain, mask_indices, JACOBI_ITERATIONS)\n\n\n\n'"
stencil_codes/poisson_solver.py,3,"b'""""""\n@author: Vincent Bonnet\n@description : Solve Laplace\'s Equation on CPU and GPU using Jacobi Method\n    Jacobi method solves Ax=b where\n    A contains the coefficient of the discrete laplace operator\n    0 -1  0\n    -1 4 -1\n    0 -1  0\n    x is the unknown discretized function (array)\n    b is equal to zero\n    By definition, The jacobi iteration is :\n    xi(k+1) = 1/aii * (bi - sum(aij * xj(k)) \'where j!=i\')\n    because b is a zero array and aii reference the coefficient 4\n    xi(k+1) = 1/4 * (- sum(aij * xj(k)) \'for j!=i\')\n    and aij are -1 for j!=i\n    => xi(k+1) = 1/4 * (sum(xj(k)) \'for j!=i\')\n""""""\n\nimport math\nimport numba\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport skimage\n\nNUM_NODES = 128 # For GPU should be a multiplier of TPB\nJACOBI_ITERATIONS = 10000\nTPB = 16 # Thread per block\nGPU_SHARED_MEMORY_SIZE = TPB + 2 # +2 because the stencil requires -1 and +1\n\ndef create_domain(num_nodes=64):\n    \'\'\'\n    Returns domain nodes along x, y and grid values\n    \'\'\'\n    values = np.zeros((num_nodes, num_nodes), np.float) # unknown function\n    values[num_nodes-1:num_nodes] = 1000.0\n\n    return values\n\n@numba.cuda.jit\ndef jacobi_kernel(x, next_x):\n    # jacobi solver with an attempt of shared memory\n    #i = cuda.threadIdx.x + (cuda.blockIdx.x * cuda.blockDim.x)\n    #j = cuda.threadIdx.y + (cuda.blockIdx.y * cuda.blockDim.y)\n    i, j = numba.cuda.grid(2)\n    if i <= 0 or i >= x.shape[0]-1 or j <= 0 or j >= x.shape[1]-1:\n        return\n\n    # Preload data into shared memory\n    # TODO - make sure all threads are involved in the data preloading and no duplicate exists\n    shared_x = numba.cuda.shared.array(shape=(GPU_SHARED_MEMORY_SIZE, GPU_SHARED_MEMORY_SIZE), dtype=numba.float32)\n\n    tx = numba.cuda.threadIdx.x\n    ty = numba.cuda.threadIdx.y\n    for idx in range(-1, 2):\n        for idy in range(-1, 2):\n            shared_x[idx+tx+1, idy+ty+1] = x[i+idx, j+idy]\n\n    numba.cuda.syncthreads()  # Wait for all threads to finish\n\n    # Resources\n    si = numba.cuda.threadIdx.x + 1\n    sj = numba.cuda.threadIdx.y + 1\n    result = (shared_x[si-1, sj] + shared_x[si+1, sj] + shared_x[si, sj-1] + shared_x[si, sj+1]) * 0.25\n    next_x[i, j] = result\n\ndef poisson_solver(domain, num_iterations):\n    # Compute blocks\n    threadsPerBlock = (TPB, TPB)\n    blocksPerGridX = math.ceil(domain.shape[0] / threadsPerBlock[0])\n    blocksPerGridY = math.ceil(domain.shape[1] / threadsPerBlock[1])\n    blocksPerGrid = (blocksPerGridX, blocksPerGridY)\n\n    # Create array on GPU\n    buffers = [None, None]\n    buffers[0] = numba.cuda.to_device(domain)\n    buffers[1] = numba.cuda.to_device(np.copy(domain))\n\n    for iteration in range(num_iterations):\n        jacobi_kernel[blocksPerGrid, threadsPerBlock](buffers[0], buffers[1])\n        buffers[0], buffers[1] = buffers[1], buffers[0] # swap buffers\n\n    # copy gpu data back to\n    buffers[0].copy_to_host(domain)\n\n    # show result\n    fig, ax = plt.subplots()\n    domain_points = np.linspace(0, 10, num=NUM_NODES, endpoint=True)\n    im = ax.pcolormesh(domain_points, domain_points, buffers[0], cmap=""rainbow"", antialiased=True, shading=""gouraud"")\n    fig.colorbar(im)\n    #fig.savefig(""test.png"")\n\n\nif __name__ == \'__main__\':\n    domain = create_domain(NUM_NODES)\n    poisson_solver(domain, JACOBI_ITERATIONS)\n\n'"
implicit_solver/examples/__init__.py,0,b'# in __init__.py\n\n'
implicit_solver/examples/beam_scene.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : example scene with single wire\n""""""\nimport logic\nimport math\nimport lib.objects as objects\nfrom . import common\n\nBEAM_POS = [-4.0, 0.0] # in meters\nBEAM_WIDTH = 8.0 # in meters\nBEAM_HEIGHT = 1.0 # in meters\nBEAM_CELL_X = 6 # number of cells along x\nBEAM_CELL_Y = 4 # number of cells along y\n\nNODE_MASS = 0.001 # in Kg\n\nGRAVITY = (0.0, -9.81) # in meters per second^2\n\ndef assemble(dispatcher, render):\n    \'\'\'\n    Initalizes a scene with a beam and a wire\n    \'\'\'\n    dispatcher.run(\'reset\')\n    context = dispatcher.run(\'get_context\')\n    # beam shape\n    beam_shape = logic.BeamShape(BEAM_POS, BEAM_WIDTH, BEAM_HEIGHT, BEAM_CELL_X, BEAM_CELL_Y)\n\n    # wire shape\n    wire_start_pos = [BEAM_POS[0], BEAM_POS[1] + BEAM_HEIGHT]\n    wire_end_pos = [BEAM_POS[0] + BEAM_WIDTH, BEAM_POS[1] + BEAM_HEIGHT]\n    wire_shape = logic.WireShape(wire_start_pos, wire_end_pos, BEAM_CELL_X * 8)\n\n    # left anchor shape and animation\n    left_anchor_shape = logic.RectangleShape(BEAM_POS[0] - 0.5, BEAM_POS[1],\n                                            BEAM_POS[0], BEAM_POS[1] + BEAM_HEIGHT)\n    l_pos, l_rot = left_anchor_shape.compute_best_transform()\n    func = lambda time: [[l_pos[0] + math.sin(2.0 * time) * 0.1, l_pos[1] + math.sin(time * 4.0)], l_rot]\n    l_animator = objects.Animator(func, context)\n\n    # right anchor shape and animation\n    right_anchor_shape = logic.RectangleShape(BEAM_POS[0] + BEAM_WIDTH, BEAM_POS[1],\n                                             BEAM_POS[0] + BEAM_WIDTH + 0.5, BEAM_POS[1] + BEAM_HEIGHT)\n    r_pos, r_rot = right_anchor_shape.compute_best_transform()\n    func = lambda time: [[r_pos[0] + math.sin(2.0 * time) * -0.1, r_pos[1]], r_rot]\n    r_animator = objects.Animator(func, context)\n\n    # Populate Scene with data and conditions\n    beam_handle = dispatcher.run(\'add_dynamic\', shape = beam_shape, node_mass = NODE_MASS)\n    wire_handle = dispatcher.run(\'add_dynamic\', shape = wire_shape, node_mass = NODE_MASS)\n\n    left_anchor_handle = dispatcher.run(\'add_kinematic\', shape = left_anchor_shape,\n                                                         position = l_pos,\n                                                         rotation = l_rot,\n                                                         animator = l_animator)\n\n    right_anchor_handle = dispatcher.run(\'add_kinematic\', shape = right_anchor_shape,\n                                                          position = r_pos,\n                                                          rotation = r_rot,\n                                                          animator = r_animator)\n\n    beam_edge_condition_handle = dispatcher.run(\'add_edge_constraint\', dynamic = beam_handle,\n                                                                       stiffness = 20.0, damping = 0.0)\n\n    wire_edge_condition_handle = dispatcher.run(\'add_edge_constraint\', dynamic = wire_handle,\n                                                                       stiffness = 10.0, damping = 0.0)\n\n    dispatcher.run(\'add_face_constraint\', dynamic = beam_handle,\n                                           stiffness = 20.0, damping = 0.0)\n\n    dispatcher.run(\'add_kinematic_attachment\', dynamic = beam_handle, kinematic = left_anchor_handle,\n                                               stiffness = 100.0, damping = 0.0, distance = 0.1)\n\n    dispatcher.run(\'add_kinematic_attachment\', dynamic = beam_handle, kinematic = right_anchor_handle,\n                                               stiffness = 100.0, damping = 0.0, distance = 0.1)\n\n    dispatcher.run(\'add_dynamic_attachment\', dynamic0 = beam_handle, dynamic1 = wire_handle,\n                                              stiffness = 100.0, damping = 0.0, distance = 0.001)\n\n    dispatcher.run(\'add_gravity\', gravity = GRAVITY)\n\n    # Set render preferences\n    dispatcher.run(\'set_render_prefs\', obj = beam_handle,\n                                       prefs = common.meta_data_render(1.0, \'grey\', \'solid\'))\n    dispatcher.run(\'set_render_prefs\', obj = beam_edge_condition_handle,\n                                       prefs = common.meta_data_render(1.0, \'blue\', \'solid\'))\n\n    dispatcher.run(\'set_render_prefs\', obj = wire_handle,\n                                       prefs = common.meta_data_render(1.0, \'grey\', \'solid\'))\n    dispatcher.run(\'set_render_prefs\', obj = wire_edge_condition_handle,\n                                       prefs = common.meta_data_render(1.0, \'green\', \'solid\'))\n    dispatcher.run(\'set_render_prefs\', obj = left_anchor_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n    dispatcher.run(\'set_render_prefs\', obj = right_anchor_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n\n    render.set_viewport_limit(-3.5, -3.5, 3.5, 3.5)\n\n'"
implicit_solver/examples/cat_scene.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : example scene with a cat ! \n""""""\nimport os\nimport logic\nfrom . import common\nimport host_app.rpc.shape_io as io_utils\n\nNODE_MASS = 0.001 # in Kg\n\nGRAVITY = (0.0, -9.81) # in meters per second^2\n\ndef assemble(dispatcher, render):\n    \'\'\'\n    Initalizes a scene including a cat shape created by the Maya/mesh_converter.py\n    Latest Maya/Houdini doesn\'t support Python 3.x hence cannot use client.py to send data\n    \'\'\'\n    file_path = \'cat.npz\'\n    dispatcher.run(\'reset\')\n\n    # Load Data from file\n    filename = os.path.join(common.get_resources_folder(),file_path)\n    shape = io_utils.create_shape_from_npz_file(filename)\n\n    # Create collider 0\n    anchor0_shape = logic.RectangleShape(min_x=-5.0, min_y=4.0, max_x=4.5, max_y=5.0)\n    anchor0_position, anchor_rotation = anchor0_shape.compute_best_transform()\n    anchor0_position[0] = -7\n    anchor0_position[1] = -13\n    anchor0_rotation = 30\n\n    # Create collider 1\n    anchor1_shape = logic.RectangleShape(min_x=-5.0, min_y=4.0, max_x=5.0, max_y=5.0)\n    anchor1_position, anchor_rotation = anchor1_shape.compute_best_transform()\n    anchor1_position[0] = 13\n    anchor1_position[1] = -20\n    anchor1_rotation = -45\n\n    # Create collider 2\n    anchor2_shape = logic.RectangleShape(min_x=-5.0, min_y=4.0, max_x=5.0, max_y=5.0)\n    anchor2_position, anchor_rotation = anchor2_shape.compute_best_transform()\n    anchor2_position[0] = 0\n    anchor2_position[1] = -30\n    anchor2_rotation = 45\n\n    # Add objects to the solver\n    collider0_handle = dispatcher.run(\'add_kinematic\', shape = anchor0_shape,\n                                                         position = anchor0_position,\n                                                         rotation = anchor0_rotation)\n\n    collider1_handle = dispatcher.run(\'add_kinematic\', shape = anchor1_shape,\n                                                         position = anchor1_position,\n                                                         rotation = anchor1_rotation)\n\n    collider2_handle = dispatcher.run(\'add_kinematic\', shape = anchor2_shape,\n                                                         position = anchor2_position,\n                                                         rotation = anchor2_rotation)\n\n    mesh_handle = dispatcher.run(\'add_dynamic\', shape = shape, node_mass = NODE_MASS)\n\n    edge_condition_handle = dispatcher.run(\'add_edge_constraint\', dynamic = mesh_handle,\n                                                           stiffness = 100.0, damping = 0.0)\n\n    dispatcher.run(\'add_kinematic_collision\', dynamic = mesh_handle, kinematic = collider0_handle,\n                                               stiffness = 10000.0, damping = 0.0)\n\n    dispatcher.run(\'add_kinematic_collision\', dynamic = mesh_handle, kinematic = collider1_handle,\n                                               stiffness = 10000.0, damping = 0.0)\n\n    dispatcher.run(\'add_kinematic_collision\', dynamic = mesh_handle, kinematic = collider2_handle,\n                                               stiffness = 10000.0, damping = 0.0)\n\n    dispatcher.run(\'add_gravity\', gravity = GRAVITY)\n\n    # Set render preferences\n    dispatcher.run(\'set_render_prefs\', obj = mesh_handle,\n                                       prefs = common.meta_data_render(1.0, \'grey\', \'solid\'))\n    dispatcher.run(\'set_render_prefs\', obj = edge_condition_handle,\n                                       prefs = common.meta_data_render(1.0, \'blue\', \'solid\'))\n    dispatcher.run(\'set_render_prefs\', obj = collider0_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n    dispatcher.run(\'set_render_prefs\', obj = collider1_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n    dispatcher.run(\'set_render_prefs\', obj = collider2_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n\n\n    render.set_viewport_limit(-20.0, -40.0, 20.0, 0.0)\n\n'"
implicit_solver/examples/common.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : common functions for scenes\n""""""\n\nimport os\n\ndef get_resources_folder():\n    return os.path.join(os.path.dirname(__file__), ""resources"")\n\ndef meta_data_render(width=1.0, color=\'grey\', style=\'solid\', alpha = 1.0):\n    return {\'width\':width, \'color\':color, \'style\':style, \'alpha\' : alpha}\n\n'"
implicit_solver/examples/multiwire_scene.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : example scene with multiwire\n""""""\nimport logic\nimport lib.objects as objects\nfrom . import common\n\nWIRE_ROOT_POS = [0.0, 2.0] # in meters\nWIRE_END_POS = [0.0, -2.0] # in meters\nWIRE_NUM_SEGMENTS = 30\n\nNODE_MASS = 0.001 # in Kg\n\nGRAVITY = (0.0, -9.81) # in meters per second^2\n\ndef assemble(dispatcher, render):\n    \'\'\'\n    Initalizes a scene with multiple wire attached to a kinematic object\n    \'\'\'\n    dispatcher.run(\'reset\')\n    context = dispatcher.run(\'get_context\')\n    # wire shape\n    wire_shapes = []\n    for i in range(6):\n        x = -2.0 + (i * 0.25)\n        wire_shape = logic.WireShape([x, 1.5], [x, -1.5] , WIRE_NUM_SEGMENTS)\n        wire_shapes.append(wire_shape)\n\n    # anchor shape and animation\n    moving_anchor_shape = logic.RectangleShape(min_x = -2.0, min_y = 1.5,\n                                              max_x = 0.0, max_y =2.0)\n    moving_anchor_position, moving_anchor_rotation = moving_anchor_shape.compute_best_transform()\n    func = lambda time: [[moving_anchor_position[0] + time,\n                          moving_anchor_position[1]], 0.0]\n\n    moving_anchor_animator = objects.Animator(func, context)\n\n    # collider shape\n    collider_shape = logic.RectangleShape(WIRE_ROOT_POS[0], WIRE_ROOT_POS[1] - 3,\n                                       WIRE_ROOT_POS[0] + 0.5, WIRE_ROOT_POS[1] - 2)\n    collider_position, collider_rotation = moving_anchor_shape.compute_best_transform()\n    collider_rotation = 45.0\n\n    # Populate Scene with data and conditions\n    moving_anchor_handle = dispatcher.run(\'add_kinematic\', shape = moving_anchor_shape,\n                                                          position = moving_anchor_position,\n                                                          rotation = moving_anchor_rotation,\n                                                          animator =moving_anchor_animator)\n\n    collider_handle = dispatcher.run(\'add_kinematic\', shape = collider_shape,\n                                                        position = collider_position,\n                                                        rotation = collider_rotation)\n\n    for wire_shape in wire_shapes:\n        wire_handle = dispatcher.run(\'add_dynamic\', shape = wire_shape, node_mass = NODE_MASS)\n\n        edge_condition_handle = dispatcher.run(\'add_edge_constraint\', dynamic = wire_handle,\n                                                               stiffness = 100.0, damping = 0.0)\n\n        dispatcher.run(\'add_wire_bending_constraint\', dynamic= wire_handle,\n                                                       stiffness = 0.15, damping = 0.0)\n\n        dispatcher.run(\'add_kinematic_attachment\', dynamic = wire_handle, kinematic = moving_anchor_handle,\n                                                   stiffness = 100.0, damping = 0.0, distance = 0.1)\n\n        dispatcher.run(\'add_kinematic_collision\', dynamic = wire_handle, kinematic = collider_handle,\n                                                   stiffness = 10000.0, damping = 0.0)\n\n        dispatcher.run(\'set_render_prefs\', obj = wire_handle,\n                                           prefs = common.meta_data_render(1.0, \'blue\', \'solid\'))\n        dispatcher.run(\'set_render_prefs\', obj = edge_condition_handle,\n                                           prefs = common.meta_data_render(1.0, \'green\', \'solid\'))\n\n    dispatcher.run(\'add_gravity\', gravity = GRAVITY)\n\n    # Set render preferences\n    dispatcher.run(\'set_render_prefs\', obj = moving_anchor_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n    dispatcher.run(\'set_render_prefs\', obj = collider_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n\n    render.set_viewport_limit(-2.5, -2.5, 2.5, 2.5)\n\n'"
implicit_solver/examples/rabbit_cat_scene.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : example scene with a rabbit and a cat !\n""""""\nimport os\nfrom . import common\nimport host_app.rpc.shape_io as io_utils\n\nNODE_MASS = 0.001 # in Kg\n\nGRAVITY = (0.0, -9.81) # in meters per second^2\n\ndef assemble(dispatcher, render):\n    \'\'\'\n    Initalizes a scene including a cat shape created by the Maya/mesh_converter.py\n    Latest Maya/Houdini doesn\'t support Python 3.x hence cannot use client.py to send data\n    \'\'\'\n    dispatcher.run(\'reset\')\n\n    # Load Data from file\n    filename = os.path.join(common.get_resources_folder(), \'rabbit.npz\')\n    rabbit_shape = io_utils.create_shape_from_npz_file(filename)\n\n    filename = os.path.join(common.get_resources_folder(), \'cat.npz\')\n    cat_shape = io_utils.create_shape_from_npz_file(filename)\n    cat_position, cat_rotation = cat_shape.compute_best_transform()\n    cat_position[0] = -10\n    cat_position[1] = -20\n    cat_rotation = 30\n\n    # Add objects to the solver\n    collider_handle = dispatcher.run(\'add_kinematic\', shape = cat_shape,\n                                     position=cat_position, rotation=cat_rotation)\n\n\n    mesh_handle = dispatcher.run(\'add_dynamic\', shape = rabbit_shape, node_mass = NODE_MASS)\n\n    edge_condition_handle = dispatcher.run(\'add_edge_constraint\', dynamic = mesh_handle,\n                                                           stiffness = 100.0, damping = 0.0)\n\n    dispatcher.run(\'add_kinematic_collision\', dynamic = mesh_handle, kinematic = collider_handle,\n                                               stiffness = 50000.0, damping = 0.0)\n\n    dispatcher.run(\'add_gravity\', gravity = GRAVITY)\n\n    # Set render preferences\n    dispatcher.run(\'set_render_prefs\', obj = mesh_handle,\n                                       prefs = common.meta_data_render(1.0, \'grey\', \'solid\'))\n    dispatcher.run(\'set_render_prefs\', obj = edge_condition_handle,\n                                       prefs = common.meta_data_render(1.0, \'blue\', \'solid\'))\n    dispatcher.run(\'set_render_prefs\', obj = collider_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n\n\n    render.set_viewport_limit(-20.0, -40.0, 20.0, 0.0)\n\n'"
implicit_solver/examples/rabbit_scene.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : example scene with a rabbit !\n""""""\nimport os\nimport logic\nfrom . import common\nimport host_app.rpc.shape_io as io_utils\n\nNODE_MASS = 0.001 # in Kg\n\nGRAVITY = (0.0, -9.81) # in meters per second^2\n\ndef assemble(dispatcher, render):\n    \'\'\'\n    Initalizes a scene including a cat shape created by the Maya/mesh_converter.py\n    Latest Maya/Houdini doesn\'t support Python 3.x hence cannot use client.py to send data\n    \'\'\'\n    file_path = \'rabbit.npz\'\n    dispatcher.run(\'reset\')\n\n    # Load Data from file\n    filename = os.path.join(common.get_resources_folder(),file_path)\n    shape = io_utils.create_shape_from_npz_file(filename)\n\n    # Create collider 0\n    anchor0_shape = logic.RectangleShape(min_x=-5.0, min_y=4.0, max_x=4.5, max_y=5.0)\n    anchor0_position, anchor_rotation = anchor0_shape.compute_best_transform()\n    anchor0_position[0] = -7\n    anchor0_position[1] = -13\n    anchor0_rotation = 30\n\n    # Create collider 1\n    anchor1_shape = logic.RectangleShape(min_x=-5.0, min_y=4.0, max_x=5.0, max_y=5.0)\n    anchor1_position, anchor_rotation = anchor1_shape.compute_best_transform()\n    anchor1_position[0] = 13\n    anchor1_position[1] = -20\n    anchor1_rotation = -45\n\n    # Create collider 2\n    anchor2_shape = logic.RectangleShape(min_x=-5.0, min_y=4.0, max_x=5.0, max_y=5.0)\n    anchor2_position, anchor_rotation = anchor2_shape.compute_best_transform()\n    anchor2_position[0] = -5\n    anchor2_position[1] = -30\n    anchor2_rotation = 70\n\n    # Add objects to the solver\n    collider0_handle = dispatcher.run(\'add_kinematic\', shape = anchor0_shape,\n                                                         position = anchor0_position,\n                                                         rotation = anchor0_rotation)\n\n    collider1_handle = dispatcher.run(\'add_kinematic\', shape = anchor1_shape,\n                                                         position = anchor1_position,\n                                                         rotation = anchor1_rotation)\n\n    collider2_handle = dispatcher.run(\'add_kinematic\', shape = anchor2_shape,\n                                                         position = anchor2_position,\n                                                         rotation = anchor2_rotation)\n\n    mesh_handle = dispatcher.run(\'add_dynamic\', shape = shape, node_mass = NODE_MASS)\n\n    edge_condition_handle = dispatcher.run(\'add_edge_constraint\', dynamic = mesh_handle,\n                                                           stiffness = 100.0, damping = 0.0)\n\n    dispatcher.run(\'add_kinematic_collision\', dynamic = mesh_handle, kinematic = collider0_handle,\n                                               stiffness = 10000.0, damping = 0.0)\n\n    dispatcher.run(\'add_kinematic_collision\', dynamic = mesh_handle, kinematic = collider1_handle,\n                                               stiffness = 10000.0, damping = 0.0)\n\n    dispatcher.run(\'add_kinematic_collision\', dynamic = mesh_handle, kinematic = collider2_handle,\n                                               stiffness = 10000.0, damping = 0.0)\n\n    dispatcher.run(\'add_gravity\', gravity = GRAVITY)\n\n    # Set render preferences\n    dispatcher.run(\'set_render_prefs\', obj = mesh_handle,\n                                       prefs = common.meta_data_render(1.0, \'grey\', \'solid\'))\n    dispatcher.run(\'set_render_prefs\', obj = edge_condition_handle,\n                                       prefs = common.meta_data_render(1.0, \'blue\', \'solid\'))\n    dispatcher.run(\'set_render_prefs\', obj = collider0_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n    dispatcher.run(\'set_render_prefs\', obj = collider1_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n    dispatcher.run(\'set_render_prefs\', obj = collider2_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n\n\n    render.set_viewport_limit(-35.0, -55.0, 35.0, -5.0)\n\n'"
implicit_solver/examples/wire_scene.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : example scene with single wire\n""""""\nimport logic\nimport math\nimport lib.objects as objects\nfrom . import common\n\nWIRE_ROOT_POS = [0.0, 2.0] # in meters\nWIRE_END_POS = [0.0, -2.0] # in meters\nWIRE_NUM_SEGMENTS = 30\n\nNODE_MASS = 0.001 # in Kg\n\nGRAVITY = (0.0, -9.81) # in meters per second^2\n\ndef assemble(dispatcher, render):\n    \'\'\'\n    Initalizes a scene with a wire attached to a kinematic object\n    \'\'\'\n    dispatcher.run(\'reset\')\n    context = dispatcher.run(\'get_context\')\n    # wire shape\n    wire_shape = logic.WireShape(WIRE_ROOT_POS, WIRE_END_POS, WIRE_NUM_SEGMENTS)\n\n    # collider shape\n    collider_shape = logic.RectangleShape(WIRE_ROOT_POS[0], WIRE_ROOT_POS[1] - 3.5,\n                                    WIRE_ROOT_POS[0] + 0.5, WIRE_ROOT_POS[1] - 2)\n\n    # anchor shape and animation\n    moving_anchor_shape = logic.RectangleShape(WIRE_ROOT_POS[0], WIRE_ROOT_POS[1] - 0.5,\n                                              WIRE_ROOT_POS[0] + 0.25, WIRE_ROOT_POS[1])\n\n    moving_anchor_position, moving_anchor_rotation = moving_anchor_shape.compute_best_transform()\n    decay_rate = 0.5\n    func = lambda time: [[moving_anchor_position[0] + math.sin(time * 10.0) * math.pow(1.0-decay_rate, time),\n                          moving_anchor_position[1]], math.sin(time * 10.0) * 90.0 * math.pow(1.0-decay_rate, time)]\n    moving_anchor_animator = objects.Animator(func, context)\n\n    # Populate scene with commands\n    wire_handle = dispatcher.run(\'add_dynamic\', shape = wire_shape, node_mass = NODE_MASS)\n    collider_handle = dispatcher.run(\'add_kinematic\', shape = collider_shape)\n\n    moving_anchor_handle = dispatcher.run(\'add_kinematic\', shape = moving_anchor_shape,\n                                                          position = moving_anchor_position,\n                                                          rotation = moving_anchor_rotation,\n                                                          animator =moving_anchor_animator)\n\n    edge_condition_handle = dispatcher.run(\'add_edge_constraint\', dynamic = wire_handle,\n                                                                   stiffness = 100.0, damping = 0.0)\n    dispatcher.run(\'add_wire_bending_constraint\', dynamic= wire_handle,\n                                                   stiffness = 0.2, damping = 0.0)\n    dispatcher.run(\'add_kinematic_attachment\', dynamic = wire_handle, kinematic = moving_anchor_handle,\n                                               stiffness = 100.0, damping = 0.0, distance = 0.1)\n    dispatcher.run(\'add_kinematic_collision\', dynamic = wire_handle, kinematic = collider_handle,\n                                               stiffness = 1000.0, damping = 0.0)\n    dispatcher.run(\'add_gravity\', gravity = GRAVITY)\n\n    # Set render preferences\n    dispatcher.run(\'set_render_prefs\', obj = wire_handle,\n                                       prefs = common.meta_data_render(1.0, \'blue\', \'solid\'))\n    dispatcher.run(\'set_render_prefs\', obj = edge_condition_handle,\n                                       prefs = common.meta_data_render(1.0, \'green\', \'solid\'))\n    dispatcher.run(\'set_render_prefs\', obj = collider_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n    dispatcher.run(\'set_render_prefs\', obj = moving_anchor_handle,\n                                       prefs = common.meta_data_render(1.0, \'orange\', \'solid\', 0.8))\n\n    render.set_viewport_limit(-2.5, -2.5, 2.5, 2.5)'"
implicit_solver/lib/__init__.py,0,b'# in __init__.py\n\nimport lib.system\nimport lib.objects\nimport lib.common\n'
implicit_solver/logic/__init__.py,0,"b'# in __init__.py\n\nfrom logic.condition_subclass import KinematicCollisionCondition\nfrom logic.condition_subclass import KinematicAttachmentCondition, DynamicAttachmentCondition\nfrom logic.condition_subclass import EdgeCondition, AreaCondition, WireBendingCondition\nfrom logic.force_subclass import Gravity\nfrom logic.shape_subclass import WireShape, RectangleShape, BeamShape\n'"
implicit_solver/logic/commands_lib.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : commands to setup objects and run simulation\n""""""\n\nimport lib.objects as objects\nimport lib.common as cm\nimport lib.common.jit.node_accessor as na\n\ndef set_render_prefs(obj, prefs):\n    \'\'\'\n    Render preferences used by render.py\n    \'\'\'\n    obj.meta_data[\'render_prefs\'] = prefs\n\ndef add_kinematic(scene, details, shape, position = (0., 0.), rotation = 0., animator = None):\n    \'\'\'\n    Add a Kinematic object\n    \'\'\'\n    kinematic = objects.Kinematic(details, shape, position, rotation)\n    scene.add_kinematic(kinematic, animator)\n    return kinematic\n\ndef add_dynamic(scene, details, shape, node_mass):\n    \'\'\'\n    Add a Dynamic object\n    \'\'\'\n    dynamic = objects.Dynamic(details, shape, node_mass)\n    scene.add_dynamic(dynamic)\n    return dynamic\n\n@cm.timeit\ndef solve_to_next_frame(scene, solver, details, context):\n    \'\'\'\n    Solve the scene and move to the next frame\n    \'\'\'\n    for _ in range(context.num_substep):\n        context.time += context.dt\n        solver.solve_step(scene, details, context)\n\ndef initialize(scene, solver, details, context):\n    \'\'\'\n    Initialize the solver\n    \'\'\'\n    solver.initialize(scene, details, context)\n\ndef get_nodes_from_dynamic(scene, index, details):\n    \'\'\'\n    Get node position from dynamic object\n    \'\'\'\n    dynamic = scene.dynamics[index]\n    return details.node.flatten(\'x\', dynamic.block_handles)\n\ndef get_shape_from_kinematic(scene, index, details):\n    \'\'\'\n    Get shape from kinematic\n    \'\'\'\n    kinematic = scene.kinematics[index]\n    return kinematic.get_as_shape(details)\n\ndef get_normals_from_kinematic(scene, index, details, normal_scale=0.2):\n    \'\'\'\n    Get normals from kinematic\n    \'\'\'\n    segs = []\n    kinematic = scene.kinematics[index]\n    normals = details.edge.flatten(\'normal\', kinematic.edge_handles)\n    point_IDs = details.edge.flatten(\'point_IDs\', kinematic.edge_handles)\n    num_normals = len(normals)\n\n    for i in range(num_normals):\n        x0 = na.node_x(details.point.blocks, point_IDs[i][0])\n        x1 = na.node_x(details.point.blocks, point_IDs[i][1])\n        points = [None, None]\n        points[0] = (x0+x1)*0.5\n        points[1] = points[0]+(normals[i]*normal_scale)\n        segs.append(points)\n\n    return segs\n\ndef get_segments_from_constraint(scene, index, details):\n    \'\'\'\n    Get position from constraint object\n    \'\'\'\n    segs = []\n\n    condition = scene.conditions[index]\n    condition_data = details.block_from_datatype(condition.constraint_type)\n\n    node_ids = condition_data.flatten(\'node_IDs\', condition.block_handles)\n    num_constraints = len(node_ids)\n    for ct_index in range(num_constraints):\n        num_nodes = len(node_ids[ct_index])\n        if num_nodes == 2:\n            points = []\n            for node_index in range (num_nodes):\n                x = na.node_x(details.node.blocks, node_ids[ct_index][node_index])\n                points.append(x)\n            segs.append(points)\n\n    return segs\n'"
implicit_solver/logic/commands_subclass.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : commands to use implementation of condition (condition_subclass)\n""""""\n\nimport logic\nfrom lib.objects import Condition, Force\n\ndef add_wire_bending_constraint(scene, dynamic, stiffness, damping) -> Condition:\n    condition = logic.WireBendingCondition([dynamic], stiffness, damping)\n    scene.add_condition(condition)\n    return condition\n\ndef add_edge_constraint(scene, dynamic, stiffness, damping) -> Condition:\n    condition = logic.EdgeCondition([dynamic], stiffness, damping)\n    scene.add_condition(condition)\n    return condition\n\ndef add_face_constraint(scene, dynamic, stiffness, damping) -> Condition:\n    condition = logic.AreaCondition([dynamic], stiffness, damping)\n    scene.add_condition(condition)\n    return condition\n\ndef add_kinematic_attachment(scene, dynamic, kinematic, stiffness, damping, distance) -> Condition:\n    condition = logic.KinematicAttachmentCondition(dynamic, kinematic, stiffness, damping, distance)\n    scene.add_condition(condition)\n    return condition\n\ndef add_dynamic_attachment(scene, dynamic0, dynamic1, stiffness, damping, distance) -> Condition:\n    condition = logic.DynamicAttachmentCondition(dynamic0, dynamic1, stiffness, damping, distance)\n    scene.add_condition(condition)\n    return condition\n\ndef add_kinematic_collision(scene, dynamic, kinematic, stiffness, damping) -> Condition:\n    condition = logic.KinematicCollisionCondition(dynamic, kinematic, stiffness, damping)\n    scene.add_condition(condition)\n    return condition\n\ndef add_gravity(scene, gravity) -> Force:\n    force = logic.Gravity(gravity)\n    scene.add_force(force)\n    return force\n'"
implicit_solver/logic/condition_subclass.py,13,"b'""""""\n@author: Vincent Bonnet\n@description : Subclasses of the Condition class\n""""""\n\nimport numpy as np\n\nimport lib.objects.jit as cpn\nfrom lib.objects import Condition\nimport lib.common as common\nimport lib.common.jit.block_utils as block_utils\nimport lib.common.jit.geometry_2d as geo2d_lib\n\ndef initialize_condition_from_aos(condition, array_of_struct, details):\n    data = details.block_from_datatype(condition.constraint_type)\n\n    # disable previous allocated blocks\n    num_constraints = len(array_of_struct)\n    condition.total_constraints = num_constraints\n\n    data.set_active(False, condition.block_handles)\n    condition.block_handles = block_utils.empty_block_handles()\n\n    # early exit if there is no constraints\n    if (num_constraints == 0):\n        return False\n\n    # allocate\n    block_handles = data.append_empty(num_constraints, reuse_inactive_block=True)\n    condition.block_handles = block_handles\n\n    # copy to datablock\n    num_elements = len(array_of_struct)\n    for field_name, value in array_of_struct[0].__dict__.items():\n        # create contiguous array\n        data_type = None\n        data_shape = None\n        if np.isscalar(value):\n            # (num_elements, ) guarantees to be array and not single value\n            data_type = type(value)\n            data_shape = (num_elements,)\n        else:\n            data_type = value.dtype.type\n            list_shape = list(value.shape)\n            list_shape.insert(0, num_elements)\n            data_shape = tuple(list_shape)\n\n        new_array = np.zeros(shape=data_shape, dtype=data_type)\n\n        # set contiguous array\n        for element_id, element in enumerate(array_of_struct):\n            new_array[element_id] = getattr(element, field_name)\n\n        # set datbablock\n        data.copyto(field_name, new_array, condition.block_handles)\n\n    # compute constraint rest\n    condition.compute_rest(details)\n\n    return True\n\n\nclass KinematicCollisionCondition(Condition):\n    \'\'\'\n    Creates collision constraint between one kinematic and one dynamic object\n    \'\'\'\n    def __init__(self, dynamic, kinematic, stiffness, damping):\n        Condition.__init__(self, stiffness, damping, cpn.AnchorSpring)\n        self.dynamic_handles = dynamic.block_handles\n        self.triangle_handles = kinematic.triangle_handles\n        self.edge_handles = kinematic.edge_handles\n\n    def is_static(self):\n        \'\'\'\n        Returns False because collision constraints are dynamics\n        \'\'\'\n        return False\n\n    def init_constraints(self, details):\n        \'\'\'\n        Add zero-length springs into anchor spring details\n        \'\'\'\n        springs = []\n\n        data_x = details.node.flatten(\'x\', self.dynamic_handles)\n        data_v = details.node.flatten(\'v\', self.dynamic_handles)\n        data_node_id = details.node.flatten(\'ID\', self.dynamic_handles)\n\n        result = geo2d_lib.IsInsideResult()\n        for i in range(len(data_x)):\n            node_pos = data_x[i]\n            node_vel = data_v[i]\n            node_ids = [data_node_id[i]]\n\n            result.isInside = False\n            cpn.simplex.is_inside(details.triangle,\n                                  details.point,\n                                  node_pos,\n                                  result,\n                                  self.triangle_handles)\n\n            if (result.isInside):\n                closest_param = geo2d_lib.ClosestResult()\n                cpn.simplex.get_closest_param(details.edge,\n                                              details.point, node_pos,\n                                              closest_param,\n                                              self.edge_handles)\n\n                if (np.dot(closest_param.normal, node_vel) < 0.0):\n                    # add spring\n                    spring = cpn.AnchorSpring()\n                    spring.kinematic_component_IDs =  closest_param.points\n                    spring.kinematic_component_param = np.float64(closest_param.t)\n                    spring.kinematic_component_pos = closest_param.position\n                    spring.node_IDs = np.copy(node_ids)\n                    spring.stiffness = self.stiffness\n                    spring.damping = self.damping\n                    springs.append(spring)\n\n        initialize_condition_from_aos(self, springs, details)\n\n    def update_constraints(self, details):\n        self.init_constraints(details)\n\nclass KinematicAttachmentCondition(Condition):\n    \'\'\'\n    Creates attachment constraint between one kinematic and one dynamic object\n    \'\'\'\n    def __init__(self, dynamic, kinematic, stiffness, damping, distance):\n       Condition.__init__(self, stiffness, damping, cpn.AnchorSpring)\n       self.distance = distance\n       self.dynamic_handles = dynamic.block_handles\n       self.edge_handles = kinematic.edge_handles\n\n    def init_constraints(self, details):\n        \'\'\'\n        Add springs into the anchor spring details\n        \'\'\'\n        springs = []\n\n        data_x = details.node.flatten(\'x\', self.dynamic_handles)\n        data_node_id = details.node.flatten(\'ID\', self.dynamic_handles)\n\n        # Linear search => it will be inefficient for dynamic objects with many nodes\n        distance2 = self.distance * self.distance\n        for i in range(len(data_x)):\n            node_pos = data_x[i]\n            node_ids = [data_node_id[i]]\n\n            closest_param = geo2d_lib.ClosestResult()\n            cpn.simplex.get_closest_param(details.edge,\n                                          details.point, node_pos,\n                                          closest_param,\n                                          self.edge_handles)\n\n            if closest_param.squared_distance < distance2:\n                # add spring\n                spring = cpn.AnchorSpring()\n                spring.kinematic_component_IDs = closest_param.points\n                spring.kinematic_component_param = np.float64(closest_param.t)\n                spring.kinematic_component_pos = closest_param.position\n                spring.node_IDs = np.copy(node_ids)\n                spring.stiffness = self.stiffness\n                spring.damping = self.damping\n                springs.append(spring)\n\n        initialize_condition_from_aos(self, springs, details)\n\n\nclass DynamicAttachmentCondition(Condition):\n    \'\'\'\n    Creates attachment constraint between two dynamic objects\n    \'\'\'\n    def __init__(self, dynamic0, dynamic1, stiffness, damping, distance):\n       Condition.__init__(self, stiffness, damping, cpn.Spring)\n       self.distance = distance\n       self.dynamic0_handles = dynamic0.block_handles\n       self.dynamic1_handles = dynamic1.block_handles\n\n    def init_constraints(self, details):\n        \'\'\'\n        Add springs into the spring details\n        \'\'\'\n        springs = []\n        distance2 = self.distance * self.distance\n\n        data_x0 = details.node.flatten(\'x\', self.dynamic0_handles)\n        data_node_id0 = details.node.flatten(\'ID\', self.dynamic0_handles)\n        data_x1 = details.node.flatten(\'x\', self.dynamic1_handles)\n        data_node_id1 = details.node.flatten(\'ID\', self.dynamic1_handles)\n\n        for i in range(len(data_x0)):\n            for j in range(len(data_x1)):\n                x0 = data_x0[i]\n                x1 = data_x1[j]\n                direction = (x0 - x1)\n                dist2 = np.inner(direction, direction)\n                if dist2 < distance2:\n                    node_id0 = data_node_id0[i]\n                    node_id1 = data_node_id1[j]\n                    node_ids = [node_id0, node_id1]\n\n                    # add spring\n                    spring = cpn.Spring()\n                    spring.node_IDs = np.copy(node_ids)\n                    spring.stiffness = self.stiffness\n                    spring.damping = self.damping\n                    springs.append(spring)\n\n        initialize_condition_from_aos(self, springs, details)\n\nclass EdgeCondition(Condition):\n    \'\'\'\n    Creates Spring constraints\n    Replaces edges with Spring constraints\n    \'\'\'\n    def __init__(self, dynamics, stiffness, damping):\n       Condition.__init__(self, stiffness, damping, cpn.Spring)\n       self.dynamics = dynamics.copy()\n\n    def init_constraints(self, details):\n        springs = []\n        for dynamic in self.dynamics:\n            for vertex_index in dynamic.edge_ids:\n                node_ids = [None, None]\n                node_ids[0] = dynamic.get_node_id(vertex_index[0])\n                node_ids[1] = dynamic.get_node_id(vertex_index[1])\n\n                # add spring\n                spring = cpn.Spring()\n                spring.node_IDs = np.copy(node_ids)\n                spring.stiffness = self.stiffness\n                spring.damping = self.damping\n                springs.append(spring)\n\n        initialize_condition_from_aos(self, springs, details)\n\nclass AreaCondition(Condition):\n    \'\'\'\n    Creates Area constraints\n    Replaces triangle with Area constraints\n    \'\'\'\n    def __init__(self, dynamics, stiffness, damping):\n       Condition.__init__(self, stiffness, damping, cpn.Area)\n       self.dynamics = dynamics.copy()\n\n    def init_constraints(self, details):\n        constraints = []\n\n        for dynamic in self.dynamics:\n            for vertex_index in dynamic.face_ids:\n                node_ids = [None, None, None]\n                node_ids[0] = dynamic.get_node_id(vertex_index[0])\n                node_ids[1] = dynamic.get_node_id(vertex_index[1])\n                node_ids[2] = dynamic.get_node_id(vertex_index[2])\n\n                # add area constraint\n                constraint = cpn.Area()\n                constraint.node_IDs = np.copy(node_ids)\n                constraint.stiffness = self.stiffness\n                constraint.damping = self.damping\n                constraints.append(constraint)\n\n        initialize_condition_from_aos(self, constraints, details)\n\nclass WireBendingCondition(Condition):\n    \'\'\'\n    Creates Wire Bending constraints\n    \'\'\'\n    def __init__(self, dynamics, stiffness, damping):\n       Condition.__init__(self, stiffness, damping, cpn.Bending)\n       self.dynamics = dynamics.copy()\n       self.node_ids = []\n       for dynamic in self.dynamics:\n           vtx_edges_dict = common.shape.vertex_ids_neighbours(dynamic.edge_ids)\n           for vtx_index, vtx_neighbour_index in vtx_edges_dict.items():\n               if (len(vtx_neighbour_index) == 2):\n                        node_ids = [dynamic.get_node_id(vtx_neighbour_index[0]),\n                                    dynamic.get_node_id(vtx_index),\n                                    dynamic.get_node_id(vtx_neighbour_index[1])]\n                        self.node_ids.append(node_ids)\n\n       self.node_ids = np.asarray(self.node_ids)\n\n    def init_constraints(self, details):\n        constraints = []\n\n        for node_ids in self.node_ids:\n            # add bending constraint\n            constraint = cpn.Bending()\n            constraint.node_IDs = np.copy(node_ids)\n            constraint.stiffness = self.stiffness\n            constraint.damping = self.damping\n            constraints.append(constraint)\n\n        initialize_condition_from_aos(self, constraints, details)\n'"
implicit_solver/logic/force_subclass.py,1,"b'""""""\n@author: Vincent Bonnet\n@description : Subclasses of the Force class\n""""""\n\nimport numpy as np\nimport numba # required by lib.common.code_gen\n\nfrom lib.objects import Force\nimport lib.objects.jit as cpn\nimport lib.common.code_gen as generate\n\n@generate.as_vectorized\ndef apply_gravity(node : cpn.Node, gravity):\n    node.f += gravity * node.m\n\nclass Gravity(Force):\n    \'\'\'\n    Base to describe gravity\n    \'\'\'\n    def __init__(self, gravity):\n        self.gravity = np.array(gravity)\n\n    def apply_forces(self, nodes):\n        apply_gravity(nodes, self.gravity)\n'"
implicit_solver/logic/shape_subclass.py,7,"b'""""""\n@author: Vincent Bonnet\n@description : Subclasses of the Shape class\n""""""\n\nfrom lib.common import Shape\nimport numpy as np\n\nclass WireShape(Shape):\n    \'\'\'\n    Creates a wire shape\n    \'\'\'\n    def __init__(self, startPoint, endPoint, num_edges):\n        Shape.__init__(self, num_edges+1, num_edges, 0)\n\n        axisx = np.linspace(startPoint[0], endPoint[0], num=num_edges+1, endpoint=True)\n        axisy = np.linspace(startPoint[1], endPoint[1], num=num_edges+1, endpoint=True)\n\n        for i in range(num_edges+1):\n            self.vertex[i] = (axisx[i], axisy[i])\n\n        # Set Edge Indices\n        vertex_indices = []\n        for i in range(num_edges):\n            vertex_indices.append((i, i+1))\n\n        self.edge = np.array(vertex_indices, dtype=int)\n\nclass RectangleShape(Shape):\n    \'\'\'\n    Creates a rectangle\n    \'\'\'\n    def __init__(self, min_x, min_y, max_x, max_y):\n        Shape.__init__(self, num_vertices=4, num_edges=5, num_faces=2)\n        # Set vertex positions\n        self.vertex[:] = ((min_x, min_y), (min_x, max_y),\n                          (max_x, max_y), (max_x, min_y))\n        # Set connectivities (edge and face)\n        self.edge[:] = ((0, 1),(1,2),(2, 0),(2, 3),(3,0))\n        self.face[:] = ((0, 1, 2),(0, 2, 3))\n\nclass BeamShape(Shape):\n    \'\'\'\n    Creates a beam shape\n    \'\'\'\n    def __init__(self, position, width, height, cell_x, cell_y):\n        Shape.__init__(self, (cell_x+1)*(cell_y+1))\n\n        # Set Vertex position\n        # 8 .. 9 .. 10 .. 11\n        # 4 .. 5 .. 6  .. 7\n        # 0 .. 1 .. 2  .. 3\n        vertex_id = 0\n        axisx = np.linspace(position[0], position[0]+width, num=cell_x+1, endpoint=True)\n        axisy = np.linspace(position[1], position[1]+height, num=cell_y+1, endpoint=True)\n\n        for j in range(cell_y+1):\n            for i in range(cell_x+1):\n                self.vertex[vertex_id] = (axisx[i], axisy[j])\n                vertex_id += 1\n\n        # Lambda function to get node indices from cell coordinates\n        cell_to_pids = lambda i, j: [i + (j*(cell_x+1)),\n                                     i + (j*(cell_x+1)) + 1,\n                                     i + ((j+1)*(cell_x+1)),\n                                     i + ((j+1)*(cell_x+1)) + 1]\n\n        # Set Edge Indices\n        vertex_indices = []\n        for j in range(cell_y):\n            for i in range(cell_x):\n                pids = cell_to_pids(i, j)\n\n                vertex_indices.append((pids[1], pids[3]))\n                if i == 0:\n                    vertex_indices.append((pids[0], pids[2]))\n\n                vertex_indices.append((pids[2], pids[3]))\n                if j == 0:\n                    vertex_indices.append((pids[0], pids[1]))\n\n\n        self.edge = np.array(vertex_indices, dtype=int)\n\n        # Set Face Indices\n        face_indices = []\n        for j in range(cell_y):\n            for i in range(cell_x):\n                pids = cell_to_pids(i, j)\n\n                face_indices.append((pids[0], pids[1], pids[2]))\n                face_indices.append((pids[1], pids[2], pids[3]))\n\n        self.face = np.array(face_indices, dtype=int)\n'"
path_tracing/jit/__init__.py,0,b''
path_tracing/jit/core.py,20,"b'""""""\n@author: Vincent Bonnet\n@description : core objects not used to describe a scene\n""""""\n\nimport math\nimport numpy as np\nimport numba\nfrom jit.maths import normalize\nimport random\n\n# A per-thread fixed memory pool to prevent memory allocation  and contains\n# . pre-allocated arrays\n# . pre-allocated ray (origin, direction)\n# . pre_allocated hits\n@numba.jitclass([(\'v\', numba.float64[:,:]),\n                 (\'ray_o\', numba.float64[:]),\n                 (\'ray_d\', numba.float64[:]),\n                 (\'depth\', numba.int32),\n                 (\'total_intersection\', numba.int64),\n                 (\'result\', numba.float64[:]), # result of trace\n                 # hit data are stored for each hit (depth)\n                 (\'hit_t\', numba.float64[:]),  # ray distance as double\n                 (\'hit_p\', numba.float64[:,:]), # hit positon\n                 (\'hit_n\', numba.float64[:,:]), # hit normal\n                 (\'hit_tn\', numba.float64[:,:]), # hit tangent\n                 (\'hit_bn\', numba.float64[:,:]), # hit binormal\n                 (\'hit_face_id\', numba.int32[:]), # hit face id\n                 (\'hit_material\', numba.float64[:,:]), # emittance/reflectance as np.empty(3)\n                 (\'hit_materialtype\', numba.int32[:])]) # material type\n\nclass MemoryPool:\n    def __init__(self, num_samples):\n        self.v = np.empty((3,3)) # pool of vectors\n        self.ray_o = np.empty(3) # used for ray origin\n        self.ray_d = np.empty(3) # used for ray direction\n        self.depth = -1         # depth counter\n        self.total_intersection = 0    # total number ray vs element intersection\n        self.result = np.empty(3)\n        # hit\n        self.hit_t = np.empty(num_samples)\n        self.hit_p = np.empty((num_samples, 3))\n        self.hit_n = np.empty((num_samples, 3))\n        self.hit_tn = np.empty((num_samples, 3))\n        self.hit_bn = np.empty((num_samples, 3))\n        self.hit_face_id = np.empty(num_samples, np.int32)\n        self.hit_material = np.empty((num_samples, 3))\n        self.hit_materialtype = np.empty(num_samples, np.int32)\n\n    def valid_hit(self):\n        if self.hit_t[self.depth] >= 0.0:\n            return True\n        return False\n\n    def next_hit(self):\n        self.depth += 1\n        self.hit_t[self.depth] = -1 # make the hit invalid\n\n@numba.jitclass([(\'t\', numba.float64), # ray distance as double\n                 (\'p\', numba.float64[:]),\n                 (\'n\', numba.float64[:]), # hit normal as np.empty(3)\n                 (\'tn\', numba.float64[:]), # hit tangent as np.empty(3)\n                 (\'bn\', numba.float64[:]), # hit binormal as np.empty(3)\n                 (\'face_id\', numba.int32), # face id\n                 (\'reflectance\', numba.float64[:]), # reflectance as np.empty(3)\n                 (\'emittance\', numba.float64[:])]) # emittance as np.empty(3)\nclass Hit:\n    def __init__(self):\n        self.t = -1.0 # ray distance\n        self.face_id = -1\n\n    def valid(self):\n        if self.t >= 0.0:\n            return True\n        return False\n\n@numba.jitclass([(\'origin\', numba.float64[:]),\n                 (\'width\', numba.int32),\n                 (\'height\', numba.int32),\n                 (\'fovx\', numba.float64),\n                 (\'fovy\', numba.float64),\n                 (\'tan_fovx\', numba.float64),\n                 (\'tan_fovy\', numba.float64),\n                 (\'dir_z\', numba.float64),\n                 (\'supersampling\', numba.int32)])\nclass Camera:\n    def __init__(self, width : int, height : int):\n        self.origin = np.zeros(3)\n        self.fovx = np.pi / 2\n        self.dir_z = -1.0\n        self.set_resolution(width, height)\n        self.set_supersampling(1)\n\n    def set_resolution(self, width : int, height : int):\n        self.width = width\n        self.height = height\n        self.fovy = float(self.height) / float(self.width) * self.fovx\n        self.tan_fovx = math.tan(self.fovx*0.5)\n        self.tan_fovy = math.tan(self.fovy*0.5)\n\n    def set_supersampling(self, supersampling):\n        self.supersampling = supersampling\n\n    def get_ray(self, i : int, j : int, sx : int, sy : int, mempool):\n        # i, j : pixel position in the image\n        # sx, sy : subpixel location\n        # Jitter sampling\n        dx = ((random.random() + sx) / self.supersampling) - 0.5\n        dy = ((random.random() + sy) / self.supersampling) - 0.5\n        x = (2.0 * i - (self.width-1) + dx) / (self.width-1) * self.tan_fovx\n        y = (2.0 * j - (self.height-1) + dy) / (self.height-1) * self.tan_fovy\n        mempool.ray_o[0] = self.origin[0]\n        mempool.ray_o[1] = self.origin[1]\n        mempool.ray_o[2] = self.origin[2]\n        mempool.ray_d[0] = x\n        mempool.ray_d[1] = y\n        mempool.ray_d[2] = self.dir_z\n        mempool.depth = -1 # no hit\n        normalize(mempool.ray_d)\n'"
path_tracing/jit/intersect.py,2,"b'""""""\n@author: Vincent Bonnet\n@description : intersection routines\n""""""\n\nimport math\nimport numba\nimport numpy as np\nfrom .maths import dot, isclose, triple_product\nfrom .maths import asub\n\n@numba.njit(inline=\'always\')\ndef ray_triangle(mempool, tv):\n    # Moller-Trumbore intersection algorithm\n    asub(tv[1], tv[0], mempool.v[0]) # e1\n    asub(tv[2], tv[0], mempool.v[1]) # e2\n    asub(mempool.ray_o, tv[0], mempool.v[2]) # ed\n\n    # explicit linear system (Ax=b) for debugging\n    #e1 = tv[1] - tv[0]\n    #e2 = tv[2] - tv[0]\n    #ed = ray_o - tv[0]\n    #x = [t, u, v]\n    #b = ray_o - tv[0]\n    #A = np.zeros((3, 3), dtype=float)\n    #A[:,0] = -ray_d\n    #A[:,1] = e1\n    #A[:,2] = e2\n    # solve the system with Cramer\'s rule\n    # det(A) = dot(-ray_d, cross(e1,e2)) = tripleProduct(-ray_d, e1, e2)\n    # also det(A) = tripleProduct(ray_d, e1, e2) = -tripleProduct(-ray_d, e1, e2)\n    detA = -triple_product(mempool.ray_d, mempool.v[0], mempool.v[1])\n    if isclose(detA, 0.0):\n        # ray is parallel to the triangle\n        return -1.0\n\n    invDetA = 1.0 / detA\n\n    u = -triple_product(mempool.ray_d, mempool.v[2], mempool.v[1]) * invDetA\n    if (u < 0.0 or u > 1.0):\n        return -1.0\n\n    v = -triple_product(mempool.ray_d, mempool.v[0], mempool.v[2]) * invDetA\n    if (v < 0.0 or u + v > 1.0):\n        return -1.0\n\n    return triple_product(mempool.v[2], mempool.v[0], mempool.v[1]) * invDetA # t\n\n@numba.njit(inline=\'always\')\ndef ray_quad(mempool, tv):\n    # Moller-Trumbore intersection algorithm\n    # same than ray_triangle but different condition on v\n    asub(tv[1], tv[0], mempool.v[0]) # e1\n    asub(tv[2], tv[0], mempool.v[1]) # e2\n    asub(mempool.ray_o, tv[0], mempool.v[2]) # ed\n\n    detA = -triple_product(mempool.ray_d, mempool.v[0], mempool.v[1])\n    if isclose(detA, 0.0):\n        # ray is parallel to the triangle\n        return -1.0\n\n    invDetA = 1.0 / detA\n\n    u = -triple_product(mempool.ray_d, mempool.v[2], mempool.v[1]) * invDetA\n    if (u < 0.0 or u > 1.0):\n        return -1.0\n\n    v = -triple_product(mempool.ray_d, mempool.v[0], mempool.v[2]) * invDetA\n    if (v < 0.0 or v > 1.0):\n        return -1.0\n\n    return triple_product(mempool.v[2], mempool.v[0], mempool.v[1]) * invDetA # t\n\n@numba.njit(inline=\'always\')\ndef ray_sphere(mempool, sphere_c, sphere_r):\n    o = mempool.ray_o - sphere_c\n    a = dot(mempool.ray_d, mempool.ray_d)\n    b = dot(mempool.ray_d, o) * 2.0\n    c = dot(o, o) - sphere_r**2\n    # solve ax**2 + bx + c = 0\n    dis = b**2 - 4*a*c  # discriminant\n\n    if dis < 0.0:\n        # no solution\n        return -1.0\n\n    if isclose(dis, 0.0):\n        # one solution\n        return -b / 2 * a\n\n    # two solution\n    sq = math.sqrt(dis)\n    s1 = (-b-sq) / 2*a  # first solution\n    s2 = (-b+sq) / 2*a # second solution\n\n    if s1 < 0.0 and s2 < 0.0:\n        return False\n\n    t = s2\n    if s1 > 0.0 and s2 > 0.0:\n        t = np.minimum(s1, s2)\n    elif s1 > 0.0:\n        t = s1\n\n    return t'"
path_tracing/jit/maths.py,3,"b'""""""\n@author: Vincent Bonnet\n@description : jitted utilities\n""""""\n\nimport numpy as np\nimport numba\nimport math\n\n@numba.njit(inline=\'always\')\ndef clamp(colour):\n    for i in range(3):\n        if colour[i] > 1.0:\n            colour[i] = 1.0\n        elif colour[i] < 0.0:\n            colour[i] = 0.0\n\n@numba.njit(inline=\'always\')\ndef gamma_correction(colour):\n    #standard encoding gamma is 1/2.2\n    clamp(colour)\n    for i in range(3):\n        colour[i] = math.pow(colour[i], 1/2.2)\n\n@numba.njit(inline=\'always\')\ndef asub(a, b, out):\n    # squeeze some performance by skipping the generic np.subtract\n    out[0] = a[0] - b[0]\n    out[1] = a[1] - b[1]\n    out[2] = a[2] - b[2]\n\n@numba.njit(inline=\'always\')\ndef axpy(a, x, y, out):\n    out[0] = y[0] + (x[0] * a)\n    out[1] = y[1] + (x[1] * a)\n    out[2] = y[2] + (x[2] * a)\n\n@numba.njit(inline=\'always\')\ndef copy(x, y):\n    x[0] = y[0]\n    x[1] = y[1]\n    x[2] = y[2]\n\n@numba.njit(inline=\'always\')\ndef triple_product(a, b, c):\n    return (a[0] * (b[1]*c[2]-b[2]*c[1]) +\n            a[1] * (b[2]*c[0]-b[0]*c[2]) +\n            a[2] * (b[0]*c[1]-b[1]*c[0]))\n\n@numba.njit(inline=\'always\')\ndef isclose(a, b, tol=1.e-8):\n    return math.fabs(a - b) < tol\n\n@numba.njit(inline=\'always\')\ndef cross(a, b):\n    result = [a[1]*b[2]-a[2]*b[1],\n              a[2]*b[0]-a[0]*b[2],\n              a[0]*b[1]-a[1]*b[0]]\n    return np.asarray(result)\n\n@numba.njit(inline=\'always\')\ndef dot(a, b):\n    return a[0]*b[0]+a[1]*b[1]+a[2]*b[2]\n\n@numba.njit(inline=\'always\')\ndef normalize(v):\n    invnorm = 1.0 / math.sqrt(dot(v,v))\n    v[0] *= invnorm\n    v[1] *= invnorm\n    v[2] *= invnorm\n\n@numba.njit(inline=\'always\')\ndef compute_tangent(n):\n    tangent = [0.0,0.0,0.0]\n    if abs(n[0]) > abs(n[1]):\n        ntdot = n[0]**2+n[2]**2\n        tangent[0] = n[2]/ntdot\n        tangent[2] = -n[0]/ntdot\n    else:\n        ntdot = n[1]**2+n[2]**2\n        tangent[1] = -n[2]/ntdot\n        tangent[2] = n[1]/ntdot\n    return np.asarray(tangent)\n\n@numba.njit(inline=\'always\')\ndef compute_tangents_binormals(normals, tangents, binormals):\n    for i in range(len(normals)):\n        tangents[i] = compute_tangent(normals[i])\n        binormals[i] = cross(normals[i], tangents[i])\n'"
path_tracing/jit/pathtracer.py,4,"b'""""""\n@author: Vincent Bonnet\n@description : basic render routines\n""""""\n\nimport time\nimport math\nimport random\nimport numba\nimport numpy as np\nfrom . import core as jit_core\nfrom .maths import dot, copy, axpy, gamma_correction, clamp\nfrom . import intersect\n\n# pathtracer settings\nBLACK = np.zeros(3)\nWHITE = np.ones(3)\nMAX_DEPTH = 1 # max hit\nNUM_SAMPLES = 1 # number of sample per pixel\nRANDOM_SEED = 10\nINV_PDF = 2.0 * math.pi; # inverse of probability density function\nINV_PI = 1.0 / math.pi\nSUPERSAMPLING = 2 # supersampling 2x2\nCPU_COUNT = 4 # number of cpu\n\n@numba.njit(inline=\'always\')\ndef update_ray_from_uniform_distribution(mempool):\n    i = mempool.depth\n    copy(mempool.ray_o, mempool.hit_p[i])\n    # Find ray direction from uniform around hemisphere\n    # Unit hemisphere from spherical coordinates\n    # the unit  hemisphere is at origin and y is the up vector\n    # theta [0, 2*PI) and phi [0, PI/2]\n    # px = cos(theta)*sin(phi)\n    # py = sin(theta)*sin(phi)\n    # pz = cos(phi)\n    # A uniform distribution (avoid more samples at the pole)\n    # theta = 2*PI*rand()\n    # phi = acos(rand())  not phi = PI/2*rand() !\n    # Optimization\n    # cos(phi) = cos(acos(rand())) = rand()\n    # sin(phi) = sin(acos(rand())) = sqrt(1 - rand()^2)\n    theta = 2*math.pi*random.random()\n    cos_phi = random.random()\n    sin_phi = math.sqrt(1.0 - cos_phi**2)\n    v0 = math.cos(theta)*sin_phi\n    v1 = cos_phi\n    v2 = math.sin(theta)*sin_phi\n    # compute the world sample\n    mempool.ray_d[0] = v0*mempool.hit_bn[i][0] + v1*mempool.hit_n[i][0] + v2*mempool.hit_tn[i][0]\n    mempool.ray_d[1] = v0*mempool.hit_bn[i][1] + v1*mempool.hit_n[i][1] + v2*mempool.hit_tn[i][1]\n    mempool.ray_d[2] = v0*mempool.hit_bn[i][2] + v1*mempool.hit_n[i][2] + v2*mempool.hit_tn[i][2]\n\n@numba.njit\ndef ray_tri_details(details, mempool):\n    # details from Scene.tri_details()\n    skip_face_id = -1\n    if mempool.depth >= 0: # skip face based on previous hit\n        skip_face_id = mempool.hit_face_id[mempool.depth]\n    mempool.next_hit() # use the next allocated hit\n    min_t = np.finfo(numba.float64).max\n    data = details[0]\n    tri_vertices = data.tri_vertices\n    hit_id = -1\n    # intersection test with triangles\n    num_triangles = len(tri_vertices)\n    for i in range(num_triangles):\n        if i == skip_face_id:\n            continue\n        t = intersect.ray_triangle(mempool, tri_vertices[i])\n        mempool.total_intersection += 1\n        if t > 0.0 and t < min_t:\n            min_t = t\n            hit_id = i\n\n    if hit_id >= 0:\n        i = mempool.depth\n        mempool.hit_t[i] = min_t\n        axpy(min_t, mempool.ray_d, mempool.ray_o, mempool.hit_p[i])\n        copy(mempool.hit_n[i], data.tri_normals[hit_id])\n        copy(mempool.hit_tn[i], data.tri_tangents[hit_id])\n        copy(mempool.hit_bn[i], data.tri_binormals[hit_id])\n        mempool.hit_face_id[i] = hit_id\n        copy(mempool.hit_material[i], data.tri_materials[hit_id])\n        mempool.hit_materialtype[i] = data.tri_materialtype[hit_id]\n\n        # two-sided intersection\n        if dot(mempool.ray_d, mempool.hit_n[i]) > 0:\n            mempool.hit_n[i][0] *= -1\n            mempool.hit_n[i][1] *= -1\n            mempool.hit_n[i][2] *= -1\n\n@numba.njit\ndef rendering_equation(details, mempool):\n    # update ray and compute weakening factor\n    update_ray_from_uniform_distribution(mempool)\n    weakening_factor = dot(mempool.ray_d, mempool.hit_n[mempool.depth])\n\n    # rendering equation : emittance + (BRDF * incoming * cos_theta / pdf);\n    mempool.result *= mempool.hit_material[mempool.depth]\n    mempool.result *= INV_PI * weakening_factor * INV_PDF\n    recursive_trace(details, mempool)\n\n@numba.njit\ndef recursive_trace(details, mempool):\n    if mempool.depth + 1 >= MAX_DEPTH: # can another hit be allocated ?\n        copy(mempool.result, BLACK)\n        return\n\n    ray_tri_details(details, mempool)\n    if not mempool.valid_hit():\n        copy(mempool.result, BLACK)\n        return\n\n    if mempool.hit_materialtype[mempool.depth]==1: # light\n        mempool.result *= mempool.hit_material[mempool.depth]\n        return\n\n    rendering_equation(details, mempool)\n\n@numba.njit\ndef start_trace(details, mempool):\n    ray_tri_details(details, mempool)\n    if not mempool.valid_hit():\n        copy(mempool.result, BLACK)\n        return\n\n    if MAX_DEPTH == 0 or mempool.hit_materialtype[0]==1: # light\n        copy(mempool.result, mempool.hit_material[0])\n        return\n\n    copy(mempool.result, WHITE)\n\n    rendering_equation(details, mempool)\n\n@numba.njit(nogil=True)\ndef render(image, camera, details, start_time, thread_id=0):\n    mempool = jit_core.MemoryPool(NUM_SAMPLES)\n    random.seed(RANDOM_SEED)\n    row_step = CPU_COUNT\n    row_start = thread_id\n\n    for j in range(row_start, camera.height,row_step):\n        for i in range(camera.width):\n            jj = camera.height-1-j\n            ii = camera.width-1-i\n\n            for sx in range(SUPERSAMPLING):\n                for sy in range(SUPERSAMPLING):\n\n                    # compute shade\n                    c = np.zeros(3)\n                    for _ in range(NUM_SAMPLES):\n                        mempool.result[0:3] = 0.0\n                        camera.get_ray(i, j, sx, sy, mempool)\n                        start_trace(details, mempool)\n                        mempool.result /= NUM_SAMPLES\n                        c += mempool.result\n                    clamp(c)\n                    c /= (SUPERSAMPLING * SUPERSAMPLING)\n                    image[jj, ii] += c\n\n            gamma_correction(image[jj, ii])\n\n        with numba.objmode():\n            p = (j+1) / camera.height\n            print(\'. completed : %.2f\' % (p * 100.0), \' %\')\n            if time.time() != start_time:\n                t = time.time() - start_time\n                estimated_time_left = (1.0 - p) / p * t\n                print(\'    estimated time left: %.2f sec (threadId %d)\' % (estimated_time_left, thread_id))\n\n    with numba.objmode():\n        print(\'Total intersections : %d (threadId %d)\' % (mempool.total_intersection, thread_id))\n\n    return mempool.total_intersection'"
implicit_solver/examples/demos/demo_march_2019.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : Demo file to init the solver\n""""""\nimport lib\nimport host_app.rpc as rpc\nfrom host_app.Ipython.render import Render\nfrom logic import scene_examples, RectangleShape\n\nimport time\n\n\'\'\'\n Global Constants\n\'\'\'\nSTART_TIME = 0\nFRAME_TIMESTEP = 1.0/24.0 # in seconds\nNUM_SUBSTEP = 10 # number of substep per frame\nNUM_FRAMES = 100 # number of simulated frame (doesn\'t include initial frame)\n\ng_render = Render()\ng_frame_id = 0\ncontext = lib.system.SolverContext(time = START_TIME, frame_dt = FRAME_TIMESTEP,\n                     num_substep = NUM_SUBSTEP, num_frames = NUM_FRAMES)\n\ndef get_dispatcher(name):\n    cmd_dispatcher = rpc.Client(name)\n    if not cmd_dispatcher.connect_to_server(ip=\'127.0.0.1\', port=8013):\n        print(\'Cannot connect to server\')\n    return cmd_dispatcher\n\ndef stage_init_wire_scene(client_name):\n    \'\'\'\n    Initialize the remote solver with wire\n    \'\'\'\n    cmd_dispatcher = get_dispatcher(client_name)\n\n    cmd_dispatcher.run(\'set_context\', context = context)\n    scene_examples.init_wire_example(cmd_dispatcher, g_render)\n\n    cmd_dispatcher.run(\'initialize\')\n    g_render.show_current_frame(cmd_dispatcher, g_frame_id)\n    print(\'\')\n\ndef stage_simulate_frames(num_frames, client_name):\n    global g_frame_id\n    cmd_dispatcher = get_dispatcher(client_name)\n    for i in range(num_frames):\n        g_frame_id += 1\n        cmd_dispatcher.run(\'solve_to_next_frame\')\n        g_render.show_current_frame(cmd_dispatcher, g_frame_id)\n        print(\'\')\n\ndef stage_add_collider(client_name):\n    global g_frame_id\n    cmd_dispatcher = get_dispatcher(client_name)\n\n    # anchor shape and animation\n    rectangle_shape = RectangleShape(min_x = 0.2, min_y = 0.3, max_x = 1.5, max_y = 0.7)\n    rectangle_position, rectangle_rotation = rectangle_shape.compute_best_transform()\n    func = lambda time: [[rectangle_position[0],\n                          rectangle_position[1]], -5.0]\n\n    rectangle_animator = lib.objects.Animator(func, context)\n\n    rectangle_handle = cmd_dispatcher.run(\'add_kinematic\', shape = rectangle_shape,\n                                                          position = rectangle_position,\n                                                          rotation = rectangle_rotation,\n                                                          animator = rectangle_animator)\n\n    dynamic_handles = cmd_dispatcher.run(\'get_dynamic_handles\')\n\n    cmd_dispatcher.run(\'add_kinematic_collision\', dynamic = dynamic_handles[0], kinematic = rectangle_handle,\n                                               stiffness = 1000.0, damping = 0.0)\n\n\ndef stage_close(client_name):\n    cmd_dispatcher = get_dispatcher(client_name)\n    cmd_dispatcher.disconnect_from_server()\n\n\nif __name__ == \'__main__\':\n    time.sleep(3)\n    stage_init_wire_scene(\'My3DApp\')\n    stage_simulate_frames(20, \'My3DAppTwo\')\n    stage_add_collider(\'My3DAppThree\')\n    time.sleep(3)\n    stage_simulate_frames(150, \'My3DAppAgain\')\n    stage_close(\'Spyder\')\n\n'"
implicit_solver/host_app/Ipython/main.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : main\n""""""\n\nimport render as rn\nimport lib.common as common\nimport host_app.rpc as rpc\nfrom examples import wire_scene, beam_scene, multiwire_scene\nfrom examples import cat_scene, rabbit_scene, rabbit_cat_scene\n\n\'\'\'\n Global Constants\n\'\'\'\nSTART_TIME = 0\nFRAME_TIMESTEP = 1.0/24.0 # in seconds\nNUM_SUBSTEP = 12 # number of substep per frame\nNUM_FRAMES = 100  # number of simulated frame (doesn\'t include initial frame)\nRENDER_FOLDER_PATH = """" # specify a folder to export png files\nUSE_REMOTE_SERVER = False # run the program locally or connect to a server\n# Used command  ""magick -loop 0 -delay 4 *.png out.gif""  to convert from png to animated gif\n\ndef get_command_dispatcher():\n    if USE_REMOTE_SERVER:\n        cmd_dispatcher = rpc.Client(""Spyder"")\n        cmd_dispatcher.connect_to_server()\n        return cmd_dispatcher\n\n    cmd_dispatcher = rpc.CommandSolverDispatcher()\n    return cmd_dispatcher\n\ndef main():\n    # Creates render and profiler\n    render = rn.Render()\n    render.set_render_folder_path(RENDER_FOLDER_PATH)\n    profiler = common.Profiler()\n\n    # Creates command dispatcher (local or remote)\n    cmd_dispatcher= get_command_dispatcher()\n\n    # Initialize dispatcher (context and scene)\n    cmd_dispatcher.run(""set_context"", time = START_TIME, frame_dt = FRAME_TIMESTEP,\n                         num_substep = NUM_SUBSTEP, num_frames = NUM_FRAMES)\n\n    #rabbit_scene.assemble(cmd_dispatcher, render)\n    #cat_scene.assemble(cmd_dispatcher, render)\n    #multiwire_scene.assemble(cmd_dispatcher, render)\n    #beam_scene.assemble(cmd_dispatcher, render)\n    #wire_scene.assemble(cmd_dispatcher, render)\n    rabbit_cat_scene.assemble(cmd_dispatcher, render)\n\n    # Simulate frames\n    for frame_id in range(NUM_FRAMES+1):\n        profiler.clear_logs()\n\n        if frame_id == 0:\n            cmd_dispatcher.run(""initialize"")\n        else:\n            cmd_dispatcher.run(""solve_to_next_frame"")\n\n        render.show_current_frame(cmd_dispatcher, frame_id)\n        render.export_current_frame(str(frame_id).zfill(4) + "" .png"")\n\n\n        profiler.print_logs()\n\n    # Disconnect client from server\n    if USE_REMOTE_SERVER:\n        cmd_dispatcher.disconnect_from_server()\n\nif __name__ == \'__main__\':\n    main()\n'"
implicit_solver/host_app/Ipython/render.py,1,"b'""""""\n@author: Vincent Bonnet\n@description : Routine to display objects and constraints\n""""""\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.collections as collections\n\nimport lib.common as cm\nfrom lib.system import Scene\n\nimport numpy as np\n\nclass Render:\n\n    def __init__(self):\n        \'\'\'\n        Initialize Render\n        \'\'\'\n        self.fig = plt.figure()\n        self.font = {\'color\':  \'darkblue\',\n                     \'weight\': \'normal\',\n                     \'size\': 18}\n        self.render_folder_path = """"\n        self.ax = None\n        self.min = [-5.0, -5.0]\n        self.max = [5.0, 5.0]\n\n    def set_viewport_limit(self, min_x, min_y, max_x, max_y):\n        \'\'\'\n        Specify the viewport limit\n        \'\'\'\n        self.min[0] = min_x\n        self.min[1] = min_y\n        self.max[0] = max_x\n        self.max[1] = max_y\n\n    def set_render_folder_path(self, path):\n        \'\'\'\n        Set the folder location to store image files\n        \'\'\'\n        self.render_folder_path = path\n\n    def render_scene(self, dispatcher, scene : Scene, frame_id):\n        \'\'\'\n        Render the scene into a figue\n        \'\'\'\n        # Reset figure and create subplot\n        self.fig.clear()\n        self.ax = self.fig.add_subplot(111)\n        #self.ax.axis(\'equal\') # do not use : it resizes the viewport during simulation\n        self.ax.margins(0.05)\n        #self.ax.set_aspect(\'equal\') # break\n        self.ax.autoscale(enable=False)\n        fig_size = self.fig.get_size_inches()\n        ratio = fig_size[0] / fig_size[1]\n        width = self.max[0]-self.min[0]\n        height = self.max[1]-self.min[1]\n        expected_width = height * ratio\n        offset = (expected_width - width) / 2\n        self.ax.set_xlim(self.min[0]-offset, self.max[0]+offset)\n        self.ax.set_ylim(self.min[1], self.max[1])\n        # Statistics for legend\n        stats_total_constraints = 0\n        stats_total_nodes = 0\n        stats_avg_block_per_objects = 0\n        stats_avg_block_per_constraints = 0\n\n        # Set label\n        plt.title(\'Implicit Solver - frame \' + str(frame_id), fontdict = self.font)\n        #plt.xlabel(\'x (m)\')\n        #plt.ylabel(\'y (m)\')\n\n        # Draw constraints\n        for condition_id, condition in enumerate(scene.conditions):\n            stats_total_constraints += condition.num_constraints()\n            stats_avg_block_per_constraints += condition.num_blocks()\n            render_prefs = condition.meta_data.get(""render_prefs"" , None)\n            if render_prefs is None:\n                continue\n\n            segs = dispatcher.run(\'get_segments_from_constraint\', index=condition_id)\n            line_segments = collections.LineCollection(segs,\n                                           linewidths=render_prefs[\'width\'],\n                                           colors=render_prefs[\'color\'],\n                                           linestyles=render_prefs[\'style\'],\n                                           alpha=render_prefs[\'alpha\'])\n\n            self.ax.add_collection(line_segments)\n\n        if stats_avg_block_per_constraints > 0:\n            stats_avg_block_per_constraints /= len(scene.conditions)\n            stats_avg_block_per_constraints = round(stats_avg_block_per_constraints, 2)\n\n        # Draw nodes\n        for dynamic_id, dynamic in enumerate(scene.dynamics):\n            stats_total_nodes += dynamic.num_nodes()\n            stats_avg_block_per_objects += dynamic.num_blocks()\n\n            render_prefs = dynamic.meta_data.get(""render_prefs"" , None)\n            if render_prefs is None:\n                continue\n\n            dynamic_data = dispatcher.run(\'get_nodes_from_dynamic\', index=dynamic_id)\n            x, y = zip(*dynamic_data)\n            self.ax.plot(x, y, \'.\', alpha=render_prefs[\'alpha\'],\n                                     color=render_prefs[\'color\'],\n                                     markersize = render_prefs[\'width\'])\n\n        stats_avg_block_per_objects /= len(scene.dynamics)\n        stats_avg_block_per_objects = round(stats_avg_block_per_objects, 2)\n\n        # Draw kinematics\n        for kinematic_id, kinematic in enumerate(scene.kinematics):\n            render_prefs = kinematic.meta_data.get(""render_prefs"" , None)\n            if render_prefs is None:\n                continue\n\n            normals = dispatcher.run(\'get_normals_from_kinematic\', index=kinematic_id)\n            line_normals = collections.LineCollection(normals,\n                                           linewidths=1,\n                                           colors=render_prefs[\'color\'],\n                                           alpha=render_prefs[\'alpha\'])\n\n            self.ax.add_collection(line_normals)\n\n            triangles = []\n            shape = dispatcher.run(\'get_shape_from_kinematic\', index=kinematic_id)\n            for face_id in shape.face:\n                v0 = shape.vertex[face_id[0]]\n                v1 = shape.vertex[face_id[1]]\n                v2 = shape.vertex[face_id[2]]\n                triangles.append([v0, v1, v2])\n\n            collec = collections.PolyCollection(triangles, facecolors=render_prefs[\'color\'],\n                                                            edgecolors=render_prefs[\'color\'],\n                                                            alpha=render_prefs[\'alpha\'])\n            self.ax.add_collection(collec)\n\n        # Add Legend\n        red_patch = patches.Patch(color=\'red\', label=str(stats_total_nodes) + \' nodes\')\n        blue_patch = patches.Patch(color=\'blue\', label=str(stats_total_constraints) + \' constraints\')\n        green_patch = patches.Patch(color=\'green\', label=str(stats_avg_block_per_objects) + \' avg block/obj\')\n        lgreen_patch = patches.Patch(color=\'lightgreen\', label=str(stats_avg_block_per_constraints) + \' avg block/cts\')\n        plt.legend(handles=[red_patch, blue_patch, green_patch, lgreen_patch], loc=\'lower left\')\n        plt.show()\n\n    def render_sparse_matrix(self, solver, frameId):\n        \'\'\'\n        Render the sparse matrix\n        \'\'\'\n        if (solver.A is not None):\n            dense_A = np.abs(solver.A.todense())\n            plt.imshow(dense_A, interpolation=\'none\', cmap=\'binary\')\n            plt.colorbar()\n        plt.show()\n\n    @cm.timeit\n    def show_current_frame(self, dispatcher, frame_id):\n        \'\'\'\n        Display the current frame\n        \'\'\'\n        #self.fig = plt.figure(figsize=(7, 4), dpi=200) # to export higher resolution images\n        scene = dispatcher.run(""get_scene"")\n        self.fig = plt.figure()\n        self.render_scene(dispatcher, scene, frame_id)\n        #self.render_sparse_matrix(solver, frameId)\n\n    @cm.timeit\n    def export_current_frame(self, filename):\n        \'\'\'\n        Export current frame into an image file\n        \'\'\'\n        if len(filename) > 0 and len(self.render_folder_path) > 0:\n            self.fig.savefig(self.render_folder_path + ""/"" + filename)\n'"
implicit_solver/host_app/houdini/houdini_sop.py,4,"b'""""""\n@author: Vincent Bonnet\n@description : Python code to bridge Houdini Data to the solver\nThis code should be pasted inside a Houdini Python geometry node\n""""""\n\nimport numpy as np\n\ndef fetch_mesh_data(geo):\n    pos_array = None\n    edge_array = None\n    triangle_array = None\n\n    # get points and primitives\n    edges = geo.globEdges(""*"")\n    primitives = geo.prims()\n    num_edges = len(edges)\n    num_triangles = len(primitives)\n\n    # Collect points\n    pos_array = np.array(geo.pointFloatAttribValues(\'P\'))\n    num_vertices = len(pos_array) / 3\n    pos_array = pos_array.reshape((num_vertices, 3))\n    pos_array = pos_array[:,0:2]\n\n    # Collect Edges\n    edge_array = np.zeros((num_edges, 2), dtype=int)\n    for i, edge in enumerate(edges):\n        points = edge.points()\n        edge_array[i] = [points[0].number(), points[1].number()]\n\n    # Collect Polygon (Triangles)\n    triangle_array = np.zeros((num_triangles, 3), dtype=int)\n    for i, primitive in enumerate(primitives):\n        points = primitive.points()\n        if len(points) == 3:\n            triangle_array[i] = [points[0].number(), points[1].number(), points[2].number()]\n\n    return pos_array, edge_array, triangle_array\n\n# from host_app.rpc.shape_io\ndef write_shape_to_npz_file(filename, pos, edge_vtx_ids, face_vtx_ids):\n    np.savez(filename, positions = pos, edge_vertex_ids = edge_vtx_ids, face_vertex_ids = face_vtx_ids)\n\n\n# Input Data\ntime = hou.time()\nnode = hou.pwd()\ngeo = node.geometry()\nfilename = \'\' # e.g c:/folder/folder2/file.npz\n\n# Export Geo\npos_array, edge_array, tri_array = fetch_mesh_data(geo)\nwrite_shape_to_npz_file(filename, pos_array, edge_array, tri_array)\n\n\n\n'"
implicit_solver/host_app/maya/mesh_converter.py,3,"b'""""""\n@author: Vincent Bonnet\n@description : Python code to bridge Maya Data to the solver\nThis code should be run from Maya Python Script Editor\nDEPRECATED - custom file format no longer supported => use numpy directly for serialization\n""""""\n\nimport maya.api.OpenMaya as om\nimport numpy as np\nimport pickle\n\nFILENAME = """" # ADD FILE\n\ndef write_to_file(points, edge_ids, face_ids, filename):\n    out_file = open(filename,\'wb\')\n    out_dict = {\'points\' : points, \'edge_ids\' : edge_ids, \'face_ids\' : face_ids }\n    pickle.dump(out_dict, out_file)\n    out_file.close()\n\ndef read_from_file(filename):\n    in_file = open(filename,\'rb\')\n    in_dict = pickle.load(in_file)\n    in_file.close()\n    points = in_dict[\'points\']\n    edge_ids = in_dict[\'edge_ids\']\n    face_ids = in_dict[\'face_ids\']\n    positions = np.array(points, copy=True, dtype=float)\n    edge_vertex_ids = np.array(edge_ids, copy=True, dtype=int)\n    face_vertex_ids = np.array(face_ids, copy=True, dtype=int)\n    return positions, edge_vertex_ids, face_vertex_ids\n\ndef extract_tri_mesh_data(points, edge_ids, face_ids):\n    # get selected mesh\n    selection = om.MSelectionList()\n    selection = om.MGlobal.getActiveSelectionList()\n    iter_sel = om.MItSelectionList(selection, om.MFn.kMesh)\n\n    if iter_sel.isDone():\n        print(""no mesh selected"")\n        return\n\n    dag_path = iter_sel.getDagPath()\n    fn_mesh = om.MFnMesh(dag_path)\n\n    # get vertices\n    pts = fn_mesh.getPoints(om.MSpace.kWorld)\n    for i in range(len(pts)) :\n        points.append((pts[i].x, pts[i].z))\n\n    # get edge indices\n    edge_iter = om.MItMeshEdge(dag_path)\n    while not edge_iter.isDone():\n        v0 = edge_iter.vertexId(0)\n        v1 = edge_iter.vertexId(1)\n        edge_ids.append((v0, v1))\n        edge_iter.next()\n\n    # get faces\n    polygon_iter = om.MItMeshPolygon(dag_path)\n    while not polygon_iter.isDone():\n        v0 = polygon_iter.vertexIndex(0)\n        v1 = polygon_iter.vertexIndex(1)\n        v2 = polygon_iter.vertexIndex(2)\n        face_ids.append((v0, v1, v2))\n        polygon_iter.next(0)\n\npoints = []\nedge_ids = []\nface_ids = []\nextract_tri_mesh_data(points, edge_ids, face_ids)\n\nwrite_to_file(points, edge_ids, face_ids, FILENAME)\n\n'"
implicit_solver/host_app/rpc/__init__.py,0,"b'# in __init__.py\n\nfrom host_app.rpc.client import Client\nfrom host_app.rpc.dispatcher import CommandDispatcher, CommandSolverDispatcher\n'"
implicit_solver/host_app/rpc/client.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : Client implementation to communicates with the server\n""""""\n\nfrom multiprocessing.managers import SyncManager\nfrom multiprocessing import Queue\n\nclass ServerQueueManager(SyncManager):\n    pass\n\nServerQueueManager.register(\'get_job_queue\')\nServerQueueManager.register(\'get_result_queue\')\n\n\nclass Client:\n    \'\'\'\n    Client to connect and dispatch commands to a Server\n    \'\'\'\n    def __init__(self, name = ""noname""):\n        self._manager = None\n        self._job_queue = None\n        self._result_queue = None\n        self._name = name # name of the client for server log\n\n    def is_connected(self):\n        return self._manager is not None\n\n    def connect_to_server(self, ip=""127.0.0.1"", port=8013, authkey=\'12345\'):\n        try:\n            self._manager = ServerQueueManager(address=(ip, port), authkey=bytes(authkey,encoding=\'utf8\'))\n            self._manager.connect()\n            self._job_queue = self._manager.get_job_queue()\n            self._result_queue = self._manager.get_result_queue()\n            print(\'Client connected to %s:%s\' % (ip, port))\n            return True\n        except Exception as e:\n            self._manager = None\n            self._job_queue = None\n            self._result_queue = None\n            print(\'Exception raised by client : \' + str(e))\n            return False\n\n    def run(self, command_name, **kwargs):\n        if self.is_connected():\n            self._job_queue.put((command_name, self._name, kwargs))\n            result = self._result_queue.get(block=True)\n            return result\n\n    def disconnect_from_server(self):\n        if self.is_connected():\n            self._job_queue.put((\'close_server\', self._name))\n\n'"
implicit_solver/host_app/rpc/dispatcher.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : Run command and bundle scene/solver/context together\n""""""\n\n# import for CommandDispatcher\nimport inspect\n\n# import for CommandSolverDispatcher\nimport uuid\nimport lib.system as system\nimport lib.objects as lib_objects\nimport logic.commands_lib as sim_cmds\nimport logic.commands_subclass as subclass_cmds\n\nclass CommandDispatcher:\n    \'\'\'\n    Base class to developer command dispatcher\n    \'\'\'\n    def __init__(self):\n        # list of registered commands\n        self._commands = {}\n\n    def register_cmd(self, cmd, cmd_name = None):\n        if cmd_name:\n            self._commands[cmd_name] = cmd\n        else:\n            self._commands[cmd.__name__] = cmd\n\n    def run(self, command_name, **kwargs):\n        # use registered command\n        if command_name in self._commands:\n            function = self._commands[command_name]\n            function_signature = inspect.signature(function)\n            # error if an argument is not matching the function signature\n            for args in kwargs:\n                if not args in function_signature.parameters:\n                    raise ValueError(""The argument \'"" + args +\n                                     ""\' doesn\'t match the function signature from \'""  + command_name + ""\'"")\n\n            # prepare function arguments\n            function_args = {}\n            for param_name in function_signature.parameters:\n                #param_obj = function_signature.parameters[param_name]\n                param_value = self._convert_parameter(param_name, kwargs)\n                if param_value is not None:\n                    function_args[param_name] = param_value\n\n            # call function\n            function_result = function(**function_args)\n            return self._process_result(function_result)\n\n        raise ValueError(""The command  "" + command_name + "" is not recognized.\'"")\n\n    def _convert_parameter(self, parameter_name, kwargs):\n        # parameter provided by user\n        if parameter_name in kwargs:\n            return kwargs[parameter_name]\n        return None\n\n    def _process_result(self, result):\n        return result\n\n\nclass CommandSolverDispatcher(CommandDispatcher):\n    \'\'\'\n    Dispatch commands to manage objects (animators, conditions, dynamics, kinematics, forces)\n    \'\'\'\n    # reserved argument names\n    SCENE_PARAMETER = \'scene\'\n    SOLVER_PARAMETER = \'solver\'\n    CONTEXT_PARAMETER = \'context\'\n    DETAILS_PARAMETER = \'details\'\n\n    def __init__(self):\n        CommandDispatcher.__init__(self)\n        # data\n        self._scene = system.Scene()\n        self._solver = system.Solver(system.ImplicitSolver())\n        self._details = system.SolverDetails()\n        self._context = system.SolverContext()\n        # map hash_value with objects (dynamic, kinematic, condition, force)\n        self._object_dict = {}\n        self._dynamic_handles = {}\n        self._kinematic_handles = {}\n        self._conditions_handles = {}\n        self._force_handles = {}\n\n        # register\n        self.register_cmd(self._set_context, \'set_context\')\n        self.register_cmd(self._get_context, \'get_context\')\n        self.register_cmd(self._get_scene, \'get_scene\')\n        self.register_cmd(self._get_dynamic_handles, \'get_dynamic_handles\')\n        self.register_cmd(self._reset, \'reset\')\n        self.register_cmd(sim_cmds.initialize)\n        self.register_cmd(sim_cmds.add_dynamic)\n        self.register_cmd(sim_cmds.add_kinematic)\n        self.register_cmd(sim_cmds.solve_to_next_frame)\n        self.register_cmd(sim_cmds.get_nodes_from_dynamic)\n        self.register_cmd(sim_cmds.get_shape_from_kinematic)\n        self.register_cmd(sim_cmds.get_normals_from_kinematic)\n        self.register_cmd(sim_cmds.get_segments_from_constraint)\n        self.register_cmd(sim_cmds.set_render_prefs)\n        self.register_cmd(subclass_cmds.add_gravity)\n        self.register_cmd(subclass_cmds.add_edge_constraint)\n        self.register_cmd(subclass_cmds.add_wire_bending_constraint)\n        self.register_cmd(subclass_cmds.add_face_constraint)\n        self.register_cmd(subclass_cmds.add_kinematic_attachment)\n        self.register_cmd(subclass_cmds.add_kinematic_collision)\n        self.register_cmd(subclass_cmds.add_dynamic_attachment)\n\n    def _add_object(self, obj):\n        unique_id = uuid.uuid4()\n\n        if isinstance(obj, lib_objects.Dynamic):\n            self._dynamic_handles[unique_id] = obj\n            self._object_dict[unique_id] = obj\n        elif isinstance(obj, lib_objects.Kinematic):\n            self._kinematic_handles[unique_id] = obj\n            self._object_dict[unique_id] = obj\n        elif isinstance(obj, lib_objects.Condition):\n            self._conditions_handles[unique_id] = obj\n            self._object_dict[unique_id] = obj\n        elif isinstance(obj, lib_objects.Force):\n            self._force_handles[unique_id] = obj\n            self._object_dict[unique_id] = obj\n        else:\n            assert False, \'_add_object(..) only supports lib.Dynamic, lib.Kinematic, lib.Condition and lib.Force\'\n\n        return unique_id\n\n    def _convert_parameter(self, parameter_name, kwargs):\n        # parameter provided by the dispatcher\n        if parameter_name == CommandSolverDispatcher.SCENE_PARAMETER:\n            return self._scene\n        elif parameter_name == CommandSolverDispatcher.SOLVER_PARAMETER:\n            return self._solver\n        elif parameter_name == CommandSolverDispatcher.CONTEXT_PARAMETER:\n            return self._context\n        elif parameter_name == CommandSolverDispatcher.DETAILS_PARAMETER:\n            return self._details\n\n        # parameter provided by user\n        if parameter_name in kwargs:\n            arg_object = kwargs[parameter_name]\n            if isinstance(arg_object, uuid.UUID):\n                return self._object_dict[arg_object]\n\n            return kwargs[parameter_name]\n\n        return None\n\n    def _process_result(self, result):\n        # convert the result object\n        if isinstance(result, (lib_objects.Dynamic,\n                               lib_objects.Kinematic,\n                               lib_objects.Condition,\n                               lib_objects.Force)):\n            return self._add_object(result)\n\n        return result\n\n    def _set_context(self, time : float, frame_dt : float, num_substep : int, num_frames : int):\n        self._context = system.SolverContext(time, frame_dt, num_substep, num_frames)\n\n    def _get_context(self):\n        return self._context\n\n    def _get_scene(self):\n        return self._scene\n\n    def _get_dynamic_handles(self):\n        handles = []\n        for handle in self._dynamic_handles:\n            handles.append(handle)\n        return handles\n\n    def _reset(self):\n        self._scene = system.Scene()\n        self._details = system.SolverDetails()\n'"
implicit_solver/host_app/rpc/server.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : Run Server to be executed on another process\n""""""\n\n\'\'\'\n Development under Spyder IDE\n The sys.path is not set at the project level but where the file is execute\n Append the parent of the parent folder to be able to import modules\n\'\'\'\nimport os\nimport sys\nparentdir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))\nsys.path.append(parentdir)\n\nimport host_app.rpc as rpc\nfrom multiprocessing.managers import SyncManager\nfrom multiprocessing import Queue\n\n\'\'\'\n Custom SyncManager and register global job/result queue\n\'\'\'\nclass JobQueueManager(SyncManager):\n    pass\nglobal_job_queue = Queue()\nglobal_result_queue = Queue()\ndef function_job_queue():\n   return global_job_queue\ndef function_result_queue():\n    return global_result_queue\n\nJobQueueManager.register(\'get_job_queue\', callable=function_job_queue)\nJobQueueManager.register(\'get_result_queue\', callable=function_result_queue)\n\n\'\'\'\n Global Dispatcher\n\'\'\'\nglobal_dispatcher = rpc.CommandSolverDispatcher();\n\ndef execute_server(print_log = True, port=8013, authkey=\'12345\'):\n    \'\'\'\n    Launch Server\n    \'\'\'\n    manager = JobQueueManager(address=(\'localhost\', port), authkey = bytes(authkey,encoding=\'utf8\'))\n    manager.start()\n    print(\'Server started at port %s\' % port)\n    exit_solver = False\n    job_queue = manager.get_job_queue()\n    result_queue = manager.get_result_queue()\n\n    while not exit_solver:\n        # Collect a job\n        job = job_queue.get(block=True)\n\n        # Run the command from client.py and return result\n        result = None\n        log = """"\n        if isinstance(job, tuple):\n            command_name = job[0]\n            client_name = job[1]\n            if command_name == \'close_server\':\n                exit_solver = True\n                result = \'server_exit\'\n            else:\n                kwargs = job[2]\n                result = global_dispatcher.run(command_name, **kwargs)\n\n            log = ""client{%s} runs command{%s}"" % (client_name , command_name)\n\n        else:\n            log = \'Command not recognized (SyntaxError)\'\n            result = ""SyntaxError""\n\n        # Print Log\n        if print_log:\n            print(log)\n\n        # Add result to result_queue\n        result_queue.put(result)\n\n    return manager\n\nif __name__ == \'__main__\':\n    server_manager = execute_server()\n    input(""Press Enter to exit server..."")\n    server_manager.shutdown()\n'"
implicit_solver/host_app/rpc/shape_io.py,5,"b'""""""\n@author: Vincent Bonnet\n@description : This file contains serializer and deserializer of shapes\n""""""\n\nimport lib.common as common\nimport numpy as np\n\ndef write_shape_to_npz_file(filename, pos, edge_vtx_ids, face_vtx_ids):\n    np.savez(filename, positions = pos, edge_vertex_ids = edge_vtx_ids, face_vertex_ids = face_vtx_ids)\n\ndef create_shape_from_npz_file(filename):\n    npzfile = np.load(filename)\n    positions = npzfile[\'positions\']\n    edge_vertex_ids = npzfile[\'edge_vertex_ids\']\n    face_vertex_ids = npzfile[\'face_vertex_ids\']\n    num_vertices = len(positions)\n    num_edges = len(edge_vertex_ids)\n    num_faces = len(face_vertex_ids)\n\n    shape = common.Shape(num_vertices, num_edges, num_faces)\n\n    np.copyto(shape.vertex, positions)\n    np.copyto(shape.edge, edge_vertex_ids)\n    np.copyto(shape.face, face_vertex_ids)\n\n    return shape\n'"
implicit_solver/lib/common/__init__.py,0,"b'# in __init__.py\n\nfrom lib.common.shape import Shape\nfrom lib.common.data_block import DataBlock\nfrom lib.common.profiler import Profiler, timeit\n'"
implicit_solver/lib/common/data_block.py,11,"b'""""""\n@author: Vincent Bonnet\n@description : Array of Structures of Arrays (AoSoA)\n\nSingle Block Memory Layout (with x, v, b as channels)\n|-----------------------------|\n| x[block_size](np.float)     |\n| v[block_size](np.float)     |\n| b[block_size](np.int)       |\n|-----------------------------|\n|blockInfo_numElements (int64)|\n|blockInfo_active     (bool)  |\n|-----------------------------|\n\nblockInfo_numElements is the number of set elements in the Block\nblockInfo_active defines whether or not the Block is active\n\nDatablock is a list of Blocks\n""""""\n\nimport numba\nimport numpy as np\nimport keyword\nimport lib.common.jit.block_utils as block_utils\n\nclass DataBlock:\n\n    def __init__(self, class_type, block_size = 100):\n        # Data\n        self.blocks = numba.typed.List()\n        # Data type : (x, y, ...)\n        self.dtype_dict = {}\n        self.dtype_dict[\'names\'] = [] # list of names\n        self.dtype_dict[\'formats\'] = [] # list of tuples (data_type, data_shape)\n        self.dtype_value = None\n        # Aosoa data type : (x, y, ...) becomes (self.block_size, x, y, ...)\n        self.dtype_block_dict = {}\n        self.dtype_block_dict[\'names\'] = []\n        self.dtype_block_dict[\'formats\'] = []\n        self.dtype_block = None\n        # Default values\n        self.defaults = () #  heterogeneous tuple storing defaults value\n        # Block size\n        self.block_size = block_size\n        # class has an ID\n        self.hasID = False\n        # Set class\n        self.__set_dtype(class_type)\n        self.clear()\n\n    def num_blocks(self):\n        return len(self.blocks)\n\n    def block(self, block_index):\n        # [0] because the self.blocks[block_index] is an array with one element\n        return self.blocks[block_index][0]\n\n    def clear(self):\n        \'\'\'\n        Clear the data on the datablock (it doesn\'t reset the datatype)\n        \'\'\'\n        self.blocks = numba.typed.List()\n        # append inactive block\n        # it prevents to have empty list which would break the JIT compile to work\n        block_dtype = self.get_block_dtype()\n        block = block_utils.empty_block(block_dtype)\n        self.blocks.append(block)\n\n    def __check_before_add(self, name):\n        \'\'\'\n        Raise exception if \'name\' cannot be added\n        \'\'\'\n        if name in [\'blockInfo_numElements\', \'blockInfo_active\']:\n            raise ValueError(""field name "" + name + "" is reserved "")\n\n        if keyword.iskeyword(name):\n            raise ValueError(""field name cannot be a keyword: "" + name)\n\n        if name in self.dtype_dict[\'names\']:\n            raise ValueError(""field name already used : "" + name)\n\n    def __set_dtype(self, class_type):\n        \'\'\'\n        Set data type from the class type\n        \'\'\'\n        inst = class_type()\n\n        default_values = []\n        for name, value in inst.__dict__.items():\n            self.__check_before_add(name)\n\n            self.dtype_block_dict[\'names\'].append(name)\n            self.dtype_dict[\'names\'].append(name)\n            default_values.append(value)\n\n            if name == \'ID\':\n                self.hasID = True\n\n            if np.isscalar(value):\n                data_type = type(value)\n                self.dtype_dict[\'formats\'].append(data_type)\n                # The coma after (self.block_size,) is essential\n                # In case field_shape == self.block_size == 1,\n                # it guarantees an array will be produced and not a single value\n                aosoa_field_shape = (self.block_size,)\n                self.dtype_block_dict[\'formats\'].append((data_type, aosoa_field_shape))\n            else:\n                data_type = value.dtype.type\n                data_shape = value.shape\n                self.dtype_dict[\'formats\'].append((data_type, data_shape))\n                aosoa_field_shape = ([self.block_size] + list(data_shape))\n                self.dtype_block_dict[\'formats\'].append((data_type, aosoa_field_shape))\n\n        self.defaults = tuple(default_values)\n\n        # add block info\n        self.dtype_block_dict[\'names\'].append(\'blockInfo_numElements\')\n        self.dtype_block_dict[\'names\'].append(\'blockInfo_active\')\n        self.dtype_block_dict[\'formats\'].append(np.int64)\n        self.dtype_block_dict[\'formats\'].append(np.bool)\n\n        # create datatype\n        self.dtype_block = np.dtype(self.dtype_block_dict, align=True)\n        self.dtype_value = np.dtype(self.dtype_dict, align=True)\n\n    def get_block_dtype(self):\n        \'\'\'\n        Returns the the dtype of a block\n        \'\'\'\n        return self.dtype_block\n\n    def get_scalar_dtype(self):\n        \'\'\'\n        Returns the value dtype of the datablock\n        \'\'\'\n        return self.dtype_value\n\n    def initialize(self, num_elements):\n        \'\'\'\n        Initialize blocks and return new block ids\n        \'\'\'\n        self.clear()\n        return self.append(num_elements, True)\n\n    def append(self, num_elements : int, reuse_inactive_block : bool = False):\n        \'\'\'\n        Return a list of new blocks\n        Initialize with default values\n        \'\'\'\n        block_dtype = self.get_block_dtype()\n        block_handles = None\n\n        if self.hasID:\n            block_handles = block_utils.append_blocks_with_ID(self.blocks, block_dtype,\n                                                      reuse_inactive_block,\n                                                      num_elements, self.block_size)\n        else:\n            block_handles = block_utils.append_blocks(self.blocks, block_dtype,\n                                                      reuse_inactive_block,\n                                                      num_elements, self.block_size)\n\n        # set default values exept for the reserved attribute ID\n        for block_handle in block_handles:\n            block_container = self.blocks[block_handle]\n            for field_id, default_value in enumerate(self.defaults):\n                if self.dtype_block_dict[\'names\'][field_id] != \'ID\':\n                    block_container[0][field_id][:] = default_value\n\n        return block_handles\n\n\n    def append_empty(self, num_elements : int, reuse_inactive_block : bool = False):\n        \'\'\'\n        Return a list of uninitialized blocks\n        \'\'\'\n        block_dtype = self.get_block_dtype()\n\n        if self.hasID:\n            return block_utils.append_blocks_with_ID(self.blocks, block_dtype,\n                                                      reuse_inactive_block,\n                                                      num_elements, self.block_size)\n\n        return block_utils.append_blocks(self.blocks, block_dtype,\n                                         reuse_inactive_block,\n                                         num_elements, self.block_size)\n\n    \'\'\'\n    DISABLE FOR NOW - NEED FIX\n    def remove(self, block_handles = None):\n        if block_handles is None:\n            return\n\n        if \'ID\' in self.dtype_dict[\'names\']:\n            raise ValueError(""ID channel used by this datablock. Another datablock might references this one => cannot delete"")\n\n        for block_handle in sorted(block_handles, reverse=True):\n            del(self.blocks[block_handle])\n    \'\'\'\n\n    def is_empty(self):\n        return len(self.blocks)==0\n\n    def __len__(self):\n        return len(self.blocks)\n\n    \'\'\'\n    Vectorize Functions on blocks\n    \'\'\'\n    def __take_with_id(self, block_handles = []):\n        for block_handle in block_handles:\n            block_container = self.blocks[block_handle]\n            block_data = block_container[0]\n            if block_data[\'blockInfo_active\']:\n                yield block_container\n\n    def __take(self):\n        for block_container in self.blocks:\n            block_data = block_container[0]\n            if block_data[\'blockInfo_active\']:\n                yield block_container\n\n    def get_blocks(self, block_handles = None):\n        if block_handles is None:\n            return self.__take()\n\n        return self.__take_with_id(block_handles)\n\n    def compute_num_elements(self, block_handles = None):\n        return block_utils.compute_num_elements(self.blocks, block_handles)\n\n    def copyto(self, field_name, values, block_handles = None):\n        num_elements = 0\n\n        for block_container in self.get_blocks(block_handles):\n            block_data = block_container[0]\n            begin_index = num_elements\n            block_n_elements = block_data[\'blockInfo_numElements\']\n            num_elements += block_n_elements\n            end_index = num_elements\n            np.copyto(block_data[field_name][0:block_n_elements], values[begin_index:end_index])\n\n    def fill(self, field_name, value, block_handles = None):\n        for block_container in self.get_blocks(block_handles):\n            block_data = block_container[0]\n            block_data[field_name].fill(value)\n\n    def flatten(self, field_name, block_handles = None):\n        \'\'\'\n        Convert block of array into a single array\n        \'\'\'\n        field_id = self.dtype_dict[\'names\'].index(field_name)\n        field_dtype = self.dtype_dict[\'formats\'][field_id]\n\n        num_elements = self.compute_num_elements(block_handles)\n        result = np.empty(num_elements, field_dtype)\n\n        num_elements = 0\n        for block_container in self.get_blocks(block_handles):\n            block_data = block_container[0]\n            begin_index = num_elements\n            block_n_elements = block_data[\'blockInfo_numElements\']\n            num_elements += block_n_elements\n            end_index = num_elements\n            np.copyto(result[begin_index:end_index], block_data[field_id][0:block_n_elements])\n\n        return result\n\n    def set_active(self, active, block_handles = None):\n        for block_container in self.get_blocks(block_handles):\n            block_data = block_container[0]\n            block_data[\'blockInfo_active\'] = active\n'"
implicit_solver/lib/common/profiler.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : Simple profiler to benchmark code\n""""""\n\nimport functools\nimport time\n\nclass Profiler(object):\n    \'\'\'\n    Profiler Singleton\n    \'\'\'\n    class Log:\n        def __init__(self, function_name, call_depth):\n            self.function_name = function_name\n            self.call_depth = call_depth\n            self.elapsed_time = 0\n            self.start_time = time.time()\n\n        def __str__(self):\n            result_log = \'%r %2.3f sec\' % (self.function_name, self.elapsed_time)\n            num_spaces = self.call_depth * 3\n            result_log = result_log.rjust(len(result_log) + num_spaces, \' \')\n            return result_log\n\n    class __Profiler:\n        def __init__(self):\n            self.logs = []\n            self.call_depth_counter = 0\n\n        def push_log(self, function_name):\n            log = Profiler.Log(function_name, self.call_depth_counter)\n            self.logs.append(log)\n            self.call_depth_counter += 1\n            return log\n\n        def pop_log(self, log):\n            log.elapsed_time = time.time() - log.start_time\n            self.call_depth_counter -= 1\n\n        def clear_logs(self):\n            self.logs.clear()\n            self.call_depth_counter = 0\n\n        def print_logs(self):\n            print(""--- Statistics ---"")\n            for log in self.logs:\n                print(log)\n\n    instance = None\n\n    def __new__(cls):\n        if not Profiler.instance:\n            Profiler.instance = Profiler.__Profiler()\n        return Profiler.instance\n\ndef timeit(method):\n    \'\'\'\n    timeit decorator\n    \'\'\'\n    @functools.wraps(method)\n    def execute(*args, **kwargs):\n        profiler = Profiler()\n        log = profiler.push_log(method.__name__)\n        result = method(*args, **kwargs)\n        profiler.pop_log(log)\n        return result\n\n    return execute\n\n'"
implicit_solver/lib/common/shape.py,8,"b'""""""\n@author: Vincent Bonnet\n@description : Shape description\n""""""\n\nimport numpy as np\nimport lib.common.jit.math_2d as math2D\n\ndef vertex_ids_neighbours(vertex_ids):\n    result = {}\n    for component_id, vtx_ids in enumerate(vertex_ids):\n        for vtx_id0 in vtx_ids:\n            for vtx_id1 in vtx_ids:\n                if vtx_id0 != vtx_id1:\n                    result.setdefault(vtx_id0, []).append(vtx_id1)\n    return result\n\nclass Shape:\n    \'\'\'\n    Shape contains a flat list of vertices and connectivities (edge,face)\n    \'\'\'\n    def __init__(self, num_vertices, num_edges=0, num_faces=0):\n        self.vertex = np.zeros((num_vertices, 2), dtype=float)\n        self.edge = np.zeros((num_edges, 2), dtype=int)\n        self.face = np.zeros((num_faces, 3), dtype=int)\n\n    def compute_best_transform(self):\n        \'\'\'\n        Returns the \'optimal\' position and modify the shape vertices from world space to local space\n        Optimal rotation is not computed yet\n        \'\'\'\n        position = np.average(self.vertex, axis=0)\n        np.subtract(self.vertex, position, out=self.vertex)\n        rotation = 0.0\n\n        return position, rotation\n\n    def num_vertices(self):\n        return len(self.vertex)\n\n    def num_edges(self):\n        return len(self.edge)\n\n    def num_faces(self):\n        return len(self.face)\n\n    def get_edge_surface_data(self):\n        \'\'\'\n        Returns the edge ids on the surface and associated normals\n        \'\'\'\n        edges_map = dict()\n\n        for face_vtx in self.face:\n            for i in range(3): # loop around the edges\n                vtx0 = face_vtx[i]\n                vtx1 = face_vtx[(i+1)%3]\n                vtx2 = face_vtx[(i+2)%3]\n\n                # create a edge_key\n                edge_key = tuple([vtx0,vtx1])\n                if edge_key[0] > edge_key[1]:\n                    edge_key = tuple([vtx1,vtx0])\n\n                # add normal\n                edge1_dir = self.vertex[vtx1] - self.vertex[vtx0]\n                edge2_dir = self.vertex[vtx2] - self.vertex[vtx0]\n                edge1_dir /= math2D.norm(edge1_dir)\n                edge_normal = np.asarray([-edge1_dir[1], edge1_dir[0]])\n                if math2D.dot(edge2_dir, edge_normal) > 0:\n                    edge_normal = np.asarray([edge1_dir[1], -edge1_dir[0]])\n\n                info = edges_map.get(edge_key, [0, (0.0, 0.0)])\n                info[0] += 1\n                info[1] = edge_normal\n                edges_map[edge_key] = info\n\n        # retrieve the surface edges\n        surface_edge_normals = []\n        surface_edge_ids = []\n\n        for k, v in edges_map.items():\n            if v[0] == 1:\n                surface_edge_normals.append(v[1])\n                surface_edge_ids.append(k)\n\n        return np.asarray(surface_edge_ids), np.asarray(surface_edge_normals)\n\n'"
implicit_solver/lib/common/symbolic.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : usage symbolic python to derive the constraint functions\n""""""\n\nfrom sympy.physics.vector import ReferenceFrame\nfrom sympy import symbols, diff, simplify, latex\nfrom sympy.matrices import Matrix\nimport sympy\n\ndef bending_energy_derivation():\n    \'\'\'\n    Symbolic derivation of bending energy\n    \'\'\'\n    # Create three positions (X0, x1, x2)\n    stiffness = symbols(""stiffness"",real=True)\n    rest_angle = symbols(""rest_angle"",real=True)\n    px0,px1,px2=symbols(""px0 px1 px2"",real=True)\n    py0,py1,py2=symbols(""py0 py1 py2"",real=True)\n    x0=Matrix([px0, py0])\n    x1=Matrix([px1, py1])\n    x2=Matrix([px2, py2])\n\n    # Angle formula\n    t01 = x1 - x0\n    t12 = x2 - x1\n    det = t01[0]*t12[1] - t01[1]*t12[0]\n    dot = t01[0]*t12[0] + t01[1]*t12[1]\n    angle = sympy.atan2(det, dot)\n\n    # Arc Length\n    arc_length = (t01.norm() + t12.norm()) * 0.5\n\n    # Bending Energy\n    bending_energy = 0.5 * stiffness * ((angle - rest_angle)**2) * arc_length\n\n    # Derivatives\n    dEdx0 = [simplify(diff(bending_energy, px0)), simplify(diff(bending_energy, py0))]\n    dEdx2 = [simplify(diff(bending_energy, px2)), simplify(diff(bending_energy, py2))]\n    #dEdx1 = - dEdx0 - dEdx2\n\ndef area_energy_derivation():\n    \'\'\'\n    Symbolic derivation of area energy\n    \'\'\'\n    # Create three positions (X0, x1, x2)\n    stiffness = symbols(""stiffness"",real=True)\n    rest_area = symbols(""rest_area"",real=True)\n    px0,px1,px2=symbols(""px0 px1 px2"",real=True)\n    py0,py1,py2=symbols(""py0 py1 py2"",real=True)\n    x0=Matrix([px0, py0])\n    x1=Matrix([px1, py1])\n    x2=Matrix([px2, py2])\n\n    # Area\n    u = x1 - x0\n    v = x2 - x0\n\n    det = u[0]*v[1]-v[0]*u[1] # cross product\n    area = sympy.Abs(det)  * 0.5\n\n    # Area Energy\n    area_energy = 0.5 * stiffness * ((area - rest_area)**2)\n\n    # Derivatives\n    dEdx0 = [simplify(diff(area_energy, px0)), simplify(diff(area_energy, py0))]\n    dEdx2 = [simplify(diff(area_energy, px2)), simplify(diff(area_energy, py2))]\n    #dEdx1 = - dEdx0 - dEdx2\n'"
implicit_solver/lib/objects/__init__.py,0,b'# in __init__.py\n\nfrom lib.objects.dynamic import Dynamic\nfrom lib.objects.kinematic import Kinematic\nfrom lib.objects.force import Force\nfrom lib.objects.animator import Animator\nfrom lib.objects.condition import Condition\n\n'
implicit_solver/lib/objects/animator.py,3,"b'""""""\n@author: Vincent Bonnet\n@description : Animator stores the position and rotation per frame\n""""""\nimport numpy as np\nimport math\n\nclass Animator:\n    \'\'\'\n    Animator class to store the position and rotation per frame\n    \'\'\'\n    def __init__(self, lambda_func, context):\n        self.num_frames = context.num_frames # simulated frame\n        self.num_baked_frames = self.num_frames + 1 # include initial frame\n        self.start_time = context.start_time\n        self.end_time = context.end_time\n        self.frame_dt = context.frame_dt\n        self.positions = np.zeros((self.num_baked_frames, 2), dtype=float)\n        self.rotations = np.zeros(self.num_baked_frames, dtype=float)\n        self.times = np.linspace(self.start_time, self.end_time, num=self.num_baked_frames, dtype=float)\n\n        for frame_id in range(self.num_baked_frames):\n            time = self.times[frame_id]\n            position, rotation = lambda_func(time)\n            self.positions[frame_id] = position\n            self.rotations[frame_id] = rotation\n\n    def get_value(self, time):\n        # Compute the frame ids contributing to the current time\n        # Instead of implementing a search on self.times, the frame_dt is used\n        relative_frame = (time - self.start_time) * self.num_frames\n        relative_frame /= (self.end_time - self.start_time)\n        relative_frame = min(self.num_frames, max(0, relative_frame))\n        frame_ids = (math.floor(relative_frame), math.ceil(relative_frame))\n\n        # Compute the animated values (position / rotation)\n        # Special case when landing on a baked frame\n        if (frame_ids[0] == frame_ids[1]):\n            i = frame_ids[0]\n            return (self.positions[i], self.rotations[i])\n\n        # Linear interpolation of the values (position / rotation)\n        times = (self.times[frame_ids[0]], self.times[frame_ids[1]])\n        assert(time >= times[0] and time <= times[1])\n        weight = (time - times[0]) / (times[1] - times[0])\n\n        position = self.positions[frame_ids[1]] * weight\n        position += self.positions[frame_ids[0]] * (1.0 - weight)\n        rotation = self.rotations[frame_ids[1]] * weight\n        rotation += self.rotations[frame_ids[0]] * (1.0 - weight)\n\n        return (position, rotation)\n'"
implicit_solver/lib/objects/condition.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : conditions create a list of constraints from a list of objects\n""""""\n\nimport lib.common.jit.block_utils as block_utils\n\nclass Condition:\n    \'\'\'\n    Base of a condition\n    \'\'\'\n    def __init__(self, stiffness, damping, constraint_type):\n        self.block_handles = block_utils.empty_block_handles()\n        self.constraint_type = constraint_type\n        # Parameters\n        self.stiffness = stiffness\n        self.damping = damping\n        # Metadata\n        self.meta_data = {}\n        self.total_constraints = 0\n\n    def num_constraints(self) -> int:\n        return self.total_constraints\n\n    def num_blocks(self) -> int:\n        return len(self.block_handles)\n\n    def is_static(self) -> bool:\n        \'\'\'\n        Returns whether or not the created constraints are dynamic or static\n        Dynamic constraints are recreated every substep\n        Static constraints are created at initialisation and valid for the whole simulation\n        \'\'\'\n        return True\n\n    def init_constraints(self, details):\n        raise NotImplementedError(type(self).__name__ + "" needs to implement the method \'init_constraints\'"")\n\n    def update_constraints(self, details):\n        pass\n\n    def __call_func(self, func, details, use_point = False):\n        if func and len(self.block_handles)>0:\n            data = details.block_from_datatype(self.constraint_type)\n            if use_point:\n                func(data, details.node, details.point, self.block_handles)\n            else:\n                func(data, details.node, self.block_handles)\n\n    def pre_compute(self, details):\n        self.__call_func(self.constraint_type.pre_compute(), details, use_point=True)\n\n    def compute_rest(self, details):\n        self.__call_func(self.constraint_type.compute_rest(), details)\n\n    def compute_gradients(self, details):\n        self.__call_func(self.constraint_type.compute_gradients(), details)\n\n    def compute_hessians(self, details):\n        self.__call_func(self.constraint_type.compute_hessians(), details)\n\n'"
implicit_solver/lib/objects/dynamic.py,4,"b'""""""\n@author: Vincent Bonnet\n@description : Dynamic object describes simulated objects\n""""""\n\nimport numpy as np\nimport lib.common as common\n\nclass Dynamic:\n    \'\'\'\n    Dynamic describes a simulated object\n    \'\'\'\n    def __init__(self, details, shape, node_mass):\n        # Allocate node data\n        self.total_nodes = shape.num_vertices()\n        self.block_handles = details.node.append_empty(self.total_nodes)\n        self.node_ids = details.node.flatten(\'ID\', self.block_handles)\n\n        # Set node data\n        details.node.copyto(\'x\', shape.vertex, self.block_handles)\n        details.node.fill(\'v\', 0.0, self.block_handles)\n        details.node.fill(\'m\', node_mass, self.block_handles)\n        details.node.fill(\'im\', 1.0 / node_mass, self.block_handles)\n        details.node.fill(\'f\', 0.0, self.block_handles)\n\n        # Initialize node connectivities\n        self.edge_ids = np.copy(shape.edge)\n        self.face_ids = np.copy(shape.face)\n        # Metadata\n        self.meta_data = {}\n\n    def num_nodes(self) -> int:\n        return self.total_nodes\n\n    def num_blocks(self) -> int:\n        return len(self.block_handles)\n\n    def get_node_id(self, vertex_index) -> int:\n        return self.node_ids[vertex_index]\n\n    def get_as_shape(self, details):\n        \'\'\'\n        Create a simple shape from the dynamic datablock and\n        node connectivities\n        \'\'\'\n        num_vertices = self.num_nodes()\n        num_edges = len(self.edge_ids)\n        num_faces = len(self.face_ids)\n        shape = common.Shape(num_vertices, num_edges, num_faces)\n        shape.vertex = details.node.flatten(\'x\', self.block_handles)\n        shape.edge = np.copy(self.edge_ids)\n        shape.face = np.copy(self.face_ids)\n\n        return shape\n\n'"
implicit_solver/lib/objects/force.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : External forces\n""""""\n\nclass Force:\n    \'\'\'\n    Base to describe a global external force\n    \'\'\'\n    def __init__(self):\n        pass\n\n    def apply_forces(self, nodes):\n        pass\n'"
implicit_solver/lib/objects/kinematic.py,15,"b'""""""\n@author: Vincent Bonnet\n@description : Kinematic object describes animated objects\n""""""\n\nimport math\nimport numpy as np\nfrom lib.common import Shape\nimport lib.objects.jit as cpn\n\nclass Kinematic:\n    \'\'\'\n    Kinematic describes an animated object\n    \'\'\'\n    class State:\n        # State of a kinematic object\n        def __init__(self, position, rotation):\n            self.position = np.zeros(2)\n            self.rotation = np.float(0.0)\n            self.linear_velocity = np.zeros(2)\n            self.angular_velocity = np.float(0.0)\n            self.update(position, rotation)\n\n        def update(self, position = (0.0, 0.0), rotation = 0.0, dt = 0.0):\n            # Updates linear and angular velocity\n            if dt > 0.0:\n                inv_dt = 1.0 / dt\n                self.linear_velocity = np.subtract(position, self.position) * inv_dt\n                shortest_angle = (rotation - self.rotation) % 360.0\n                if (math.fabs(shortest_angle) > 180.0):\n                    shortest_angle -= 360.0\n                    self.angular_velocity = shortest_angle * inv_dt\n\n            # update position and rotation\n            self.position = np.asarray(position)\n            self.rotation = np.float(rotation)\n\n    def __init__(self, details, shape, position = (0., 0.), rotation = 0.):\n        self.state = Kinematic.State(position = position, rotation = rotation)\n        # append points\n        self.point_handles =  details.point.append_empty(len(shape.vertex))\n        details.point.copyto(\'local_x\', shape.vertex, self.point_handles)\n        details.point.copyto(\'x\', shape.vertex, self.point_handles)\n        point_ids = details.point.flatten(\'ID\', self.point_handles)\n        # append edges\n        surface_edge_ids, surface_edge_normals = shape.get_edge_surface_data()\n        edge_pids = np.take(point_ids, surface_edge_ids, axis=0)\n        self.edge_handles = details.edge.append_empty(len(surface_edge_ids))\n        details.edge.copyto(\'local_normal\', surface_edge_normals, self.edge_handles)\n        details.edge.copyto(\'normal\', surface_edge_normals, self.edge_handles)\n        details.edge.copyto(\'point_IDs\', edge_pids, self.edge_handles)\n        # append triangles\n        self.face_ids = np.copy(shape.face)\n        triangle_pids = np.take(point_ids, self.face_ids, axis=0)\n        self.triangle_handles = details.triangle.append_empty(len(self.face_ids))\n        details.triangle.copyto(\'point_IDs\', triangle_pids, self.triangle_handles)\n        # update vertices\n        self.update(details, position, rotation)\n        # metadata\n        self.meta_data = {}\n\n    def get_as_shape(self, details):\n        x = details.point.flatten(\'x\', self.point_handles)\n        shape = Shape(len(x), 0, len(self.face_ids))\n        np.copyto(shape.vertex, x)\n        np.copyto(shape.face, self.face_ids)\n        return shape\n\n    def update(self, details, position, rotation, dt = 0.0):\n        # update state\n        self.state.update(position, rotation, dt)\n        # compute rotation matarix\n        theta = np.radians(self.state.rotation)\n        c, s = np.cos(theta), np.sin(theta)\n        rotation_matrix = np.array(((c, -s), (s, c)))\n        # update kinematic\n        cpn.simplex.transform_point(details.point,\n                                   rotation_matrix,\n                                   self.state.position,\n                                   self.point_handles)\n\n        cpn.simplex.transform_normal(details.edge,\n                                   rotation_matrix,\n                                   self.edge_handles)\n'"
implicit_solver/lib/system/__init__.py,0,"b'# in __init__.py\n\nfrom lib.system.scene import Scene\nfrom lib.system.solver import Solver, SolverContext, SolverDetails\nfrom lib.system.time_integrators import ImplicitSolver\n\n'"
implicit_solver/lib/system/scene.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : a scene contains objects/constraints/kinematics\nThe scene stores data in SI unit which are used by the solver\n""""""\n\nclass Scene:\n    def __init__(self):\n        self.dynamics = [] # dynamic objects\n        self.kinematics = [] # kinematic objects\n        self.animators = [] # animators for kinematic objects\n        self.conditions = [] # create static or dynamic constraints\n        self.forces = []\n\n    # Data Functions #\n    def add_dynamic(self, dynamic):\n        self.dynamics.append(dynamic)\n\n    def add_kinematic(self, kinematic, animator = None):\n        self.kinematics.append(kinematic)\n        self.animators.append(animator)\n\n    def init_kinematics(self, details, start_time):\n        self.update_kinematics(details, start_time, dt = 0.0)\n\n    def update_kinematics(self, details, time, dt):\n        for index, kinematic in enumerate(self.kinematics):\n            animation = self.animators[index]\n            if animation:\n                position, rotation = animation.get_value(time)\n                kinematic.update(details, position, rotation, dt)\n\n    def num_nodes(self):\n        num_nodes = 0\n        for dynamic in self.dynamics:\n            num_nodes += dynamic.num_nodes()\n        return num_nodes\n\n    # Constraint Functions #\n    def add_condition(self, condition):\n        self.conditions.append(condition)\n\n    def init_conditions(self, details):\n        for condition in self.conditions:\n            condition.init_constraints(details)\n\n    def update_conditions(self, details):\n        for condition in self.conditions:\n            # Only update the dynamic condition\n            if condition.is_static() is False:\n                condition.update_constraints(details)\n\n    # Force Functions #\n    def add_force(self, force):\n        self.forces.append(force)\n'"
implicit_solver/lib/system/solver.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : Solver to orchestrate the step of a solver\n""""""\n\nimport lib.common as cm\nimport lib.objects.jit as cpn\nfrom lib.system import Scene\n\nclass SolverContext:\n    \'\'\'\n    SolverContext to store time, time stepping, etc.\n    \'\'\'\n    def __init__(self, time = 0.0, frame_dt = 1.0/24.0, num_substep = 4, num_frames = 1):\n        self.time = time # current time (in seconds)\n        self.start_time = time # start time (in seconds)\n        self.end_time = time + (num_frames * frame_dt) # end time (in seconds)\n        self.frame_dt = frame_dt # time step on a single frame (in seconds)\n        self.num_substep = num_substep # number of substep per frame\n        self.dt = frame_dt / num_substep # simulation substep (in seconds)\n        self.num_frames = num_frames # number of simulated frame (doesn\'t include initial frame)\n\nclass SolverDetails:\n    \'\'\'\n    List of datablocks\n    \'\'\'\n    def __init__(self):\n        block_size = 100\n        # dynamics\n        self.node = cm.DataBlock(cpn.Node, block_size) # nodes\n        # constraints\n        self.area = cm.DataBlock(cpn.Area, block_size) # area\n        self.bending = cm.DataBlock(cpn.Bending, block_size) # bending rod\n        self.spring = cm.DataBlock(cpn.Spring, block_size) # spring\n        self.anchorSpring = cm.DataBlock(cpn.AnchorSpring, block_size) # anchor spring\n        # kinematics\n        self.point = cm.DataBlock(cpn.Point, block_size) # point\n        self.edge = cm.DataBlock(cpn.Edge, block_size) # edge\n        self.triangle = cm.DataBlock(cpn.Triangle, block_size) # triangle\n        self.tetrahedron = cm.DataBlock(cpn.Tetrahedron, block_size) # tetrahedron\n\n    def block_from_datatype(self, datatype):\n        blocks = [self.node, self.area, self.bending, self.spring, self.anchorSpring]\n        blocks += [self.point, self.edge, self.triangle, self.tetrahedron]\n        datatypes = [cpn.Node, cpn.Area, cpn.Bending, cpn.Spring, cpn.AnchorSpring]\n        datatypes += [cpn.Point, cpn.Edge, cpn.Triangle, cpn.Tetrahedron]\n        index = datatypes.index(datatype)\n        return blocks[index]\n\n    def dynamics(self):\n        return [self.node]\n\n    def conditions(self):\n        return [self.area, self.bending, self.spring, self.anchorSpring]\n\nclass Solver:\n    \'\'\'\n    Base Solver\n    \'\'\'\n    def __init__(self, time_integrator = None):\n        self.time_integrator = time_integrator\n\n    def initialize(self, scene : Scene, details : SolverDetails, context : SolverContext):\n        \'\'\'\n        Initialize the scene\n        \'\'\'\n        scene.init_kinematics(details, context.start_time)\n        scene.init_conditions(details)\n\n    @cm.timeit\n    def solve_step(self, scene : Scene, details : SolverDetails, context : SolverContext):\n        \'\'\'\n        Solve a single step (pre/step/post)\n        \'\'\'\n        self._pre_step(scene, details, context)\n        self._step(scene, details, context)\n        self._post_step(scene, details, context)\n\n    @cm.timeit\n    def _pre_step(self, scene : Scene, details : SolverDetails, context : SolverContext):\n        scene.update_kinematics(details, context.time, context.dt)\n        scene.update_conditions(details) # allocate dynamically new conditions\n\n    @cm.timeit\n    def _step(self, scene : Scene, details : SolverDetails, context : SolverContext):\n        if self.time_integrator:\n            self.time_integrator.prepare_system(scene, details, context.dt)\n            self.time_integrator.assemble_system(details, context.dt)\n            self.time_integrator.solve_system(details, context.dt)\n\n    @cm.timeit\n    def _post_step(self, scene, details, context):\n        pass\n'"
implicit_solver/lib/system/time_integrators.py,3,"b'""""""\n@author: Vincent Bonnet\n@description : symplectic and backward Euler integrators\n""""""\n\nimport numpy as np\nimport scipy\nimport scipy.sparse\nimport scipy.sparse.linalg\n\nimport lib.common as cm\nimport lib.system.jit.integrator_lib as integrator_lib\nimport lib.system.jit.sparse_matrix_lib as sparse_lib\n\nclass TimeIntegrator:\n    \'\'\'\n    Base class for time integrator\n    \'\'\'\n    def prepare_system(self, scene, details, dt):\n        raise NotImplementedError(type(self).__name__ + "" needs to implement the method \'prepare_system\'"")\n\n    def assemble_system(self, details, dt):\n        raise NotImplementedError(type(self).__name__ + "" needs to implement the method \'assemble_system\'"")\n\n    def solve_system(self, details, dt):\n        raise NotImplementedError(type(self).__name__ + "" needs to implement the method \'solve_system\'"")\n\n\nclass ImplicitSolver(TimeIntegrator):\n    \'\'\'\n     Implicit Step\n     Solve :\n         (M - h * df/dv - h^2 * df/dx) * deltaV = h * (f0 + h * df/dx * v0)\n           A = (M - h^2 * df/dx)\n           b = h * (f0 + h * df/dx * v0)\n         => A * deltaV = b <=> deltaV = A^-1 * b\n         deltaX = (v0 + deltaV) * h\n         v = v + deltaV\n         x = x + deltaX\n    \'\'\'\n    def __init__(self):\n        TimeIntegrator.__init__(self)\n        # used to store system Ax=b\n        self.A = None\n        self.b = None\n        self.num_nodes = 0\n\n    @cm.timeit\n    def prepare_system(self, scene, details, dt):\n        \'\'\'\n        Compute external and constraint forces\n        \'\'\'\n        # Reset forces on dynamics\n        details.node.fill(\'f\', 0.0)\n\n        # Compute constraint forces and jacobians\n        for condition in scene.conditions:\n            condition.pre_compute(details)\n            condition.compute_gradients(details)\n            condition.compute_hessians(details)\n\n        # Add forces to dynamics\n        integrator_lib.apply_external_forces_to_nodes(details.dynamics(), scene.forces)\n        integrator_lib.apply_constraint_forces_to_nodes(details.conditions(), details.node)\n\n        # Store number of nodes\n        self.num_nodes = details.node.compute_num_elements()\n\n    @cm.timeit\n    def assemble_system(self, details, dt):\n        \'\'\'\n        Assemble the system (Ax=b) where x is the unknow change of velocity\n        \'\'\'\n        if (self.num_nodes == 0):\n            return\n\n        self._assemble_A(details, dt)\n        self._assemble_b(details, dt)\n\n    @cm.timeit\n    def solve_system(self, details, dt):\n        \'\'\'\n        Solve the assembled linear system (Ax=b)\n        \'\'\'\n        if (self.num_nodes == 0):\n            return\n\n        # Solve the system (Ax=b) and reshape the conjugate gradient result\n        # In this case, the reshape operation is not causing any reallocation\n        b = self.b.reshape(self.num_nodes * 2)\n        cg_result = scipy.sparse.linalg.cg(self.A, b)\n        delta_v = cg_result[0].reshape(self.num_nodes, 2)\n        # Advect\n        self._advect(details, delta_v, dt)\n\n    @cm.timeit\n    def _assemble_A(self, details, dt):\n        \'\'\'\n        Assemble A = (M - (h * df/dv + h^2 * df/dx))\n        \'\'\'\n        # create empty sparse matrix A\n        num_rows = self.num_nodes\n\n        # TODO : SuperUgly but issue when using Numba 0.48.0 to lower details class\n        node_blocks = details.node.blocks\n        area_blocks = details.area.blocks\n        bending_blocks = details.bending.blocks\n        spring_blocks = details.spring.blocks\n        anchorSpring_blocks = details.anchorSpring.blocks\n\n        num_entries_per_row, column_indices, data = integrator_lib.assemble_A(node_blocks,\n                                                   area_blocks,\n                                                   bending_blocks,\n                                                   spring_blocks,\n                                                   anchorSpring_blocks,\n                                                   num_rows,\n                                                   dt,\n                                                   integrator_lib.assemble_mass_matrix_to_A.function,\n                                                   integrator_lib.assemble_constraint_forces_to_A.function)\n\n        # allocate row indices\n        row_indptr = np.zeros(num_rows+1, dtype=np.int32)\n        row_indptr[0] = 0 # minimum entry exists at [0,0] due to mass matrix\n        np.add.accumulate(num_entries_per_row, out=row_indptr[1:num_rows+1])\n\n        self.A = scipy.sparse.bsr_matrix((data, column_indices, row_indptr))\n\n    @cm.timeit\n    def _assemble_b(self, details, dt):\n        \'\'\'\n        Assemble b = h *( f0 + h * df/dx * v0)\n                 b = (f0 * h) + (h^2 * df/dx * v0)\n        \'\'\'\n        # create b vector\n        self.b = np.zeros((self.num_nodes, 2))\n\n        # set (f0 * h)\n        integrator_lib.assemble_fo_h_to_b(details.dynamics(), dt, self.b)\n\n        # add (df/dx * v0 * h * h)\n        integrator_lib.assemble_dfdx_v0_h2_to_b(details.conditions(), details.node, dt, self.b)\n\n    @cm.timeit\n    def _advect(self, details, delta_v, dt):\n        integrator_lib.advect(details.dynamics(), delta_v, dt)\n\n\'\'\'\nNEED TO RE-IMPLEMENT\nclass SemiImplicitSolver(TimeIntegrator):\n    def __init__(self):\n        Solver.__init__(self)\n\n    @cm.timeit\n    def prepare_system(self, scene, details, dt):\n        # Reset forces\n        for dynamic in scene.dynamics:\n            dynamic.data.fill(\'f\', 0.0)\n\n        # Apply external forces\n        for force in scene.forces:\n            force.apply_forces(scene.dynamics)\n\n        # Apply internal forces\n        for condition in scene.conditions:\n            condition.compute_gradients(scene)\n\n        apply_constraint_forces_to_nodes(details.conditions(), details.node)\n\n    @cm.timeit\n    def assemble_system(self, details, dt):\n        pass\n\n    @cm.timeit\n    def solve_system(self, details, dt):\n        # Integrator\n        for dynamic in scene.dynamics:\n            for i in range(dynamic.num_nodes()):\n                dynamic.v[i] += dynamic.f[i] * dynamic.im[i] * dt\n                dynamic.x[i] += dynamic.v[i] * dt\n\'\'\'\n'"
implicit_solver/lib/tests/all_tests.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : Run all tests\n""""""\n\nimport unittest\n\nimport code_gen_tests as gen_tests\nimport datablock_tests as db_tests\nimport geometry_tests as geo_tests\nimport numba_tests as numba_tests\n\nif __name__ == \'__main__\':\n    unittest.main(gen_tests.Tests())\n    unittest.main(db_tests.Tests())\n    unittest.main(geo_tests.Tests())\n    unittest.main(numba_tests.Tests())\n'"
implicit_solver/lib/tests/code_gen_tests.py,1,"b'""""""\n@author: Vincent Bonnet\n@description : Evaluation of Abstract Syntax Trees\n""""""\n\nimport numba # required by lib.common.code_gen\nimport lib.common.code_gen as generate\nimport lib.common as common\nimport numpy as np\nimport unittest\n\n\'\'\'\nDatablock Functions\n\'\'\'\nclass Vertex:\n    def __init__(self):\n        self.x = np.ones((2,3)) * 2.1\n        self.y = 1.5\n\nclass Container:\n    def __init__(self, datablock):\n        self.data = datablock\n\ndef create_datablock(num_elements=10):\n    datablock = common.DataBlock(Vertex, block_size = 100)\n    datablock.initialize(num_elements)\n    return datablock\n\n\'\'\'\nFunctions to vectorize\n\'\'\'\n@generate.as_vectorized\ndef add_values(v0 : Vertex, v1 : Vertex, other_value):\n    v0.x += v1.x + other_value\n    v0.y += v1.y + other_value\n\n@generate.as_vectorized(njit=False)\ndef add_values_to_list(v0 : Vertex, v1 : Vertex, out_list):\n    out_list.append(v0.x + v1.x)\n\n\'\'\'\nTests for code generation\n\'\'\'\nclass Tests(unittest.TestCase):\n\n    def test_generated_function_with_numpy_input(self):\n        datablock0 = create_datablock()\n        datablock1 = create_datablock()\n        add_values(datablock0, datablock1, 1.0)\n        self.assertEqual(datablock0.block(0)[\'x\'][0][0][0], 5.2)\n        self.assertEqual(datablock0.block(0)[\'y\'][0], 4.0)\n\n    def test_generated_function_with_datablock_input(self):\n        datablock0 = create_datablock()\n        datablock1 = create_datablock()\n        add_values(datablock0, datablock1, 1.0)\n        self.assertEqual(datablock0.block(0)[\'x\'][0][0][0], 5.2)\n        self.assertEqual(datablock0.block(0)[\'y\'][0], 4.0)\n\n    def test_function_generated_once(self):\n        datablock0 = create_datablock()\n        datablock1 = create_datablock()\n        add_values(datablock0, datablock1, 1.0)\n        function0 = add_values.function\n        source0 = add_values.source\n        add_values(datablock0, datablock1, 1.0)\n        function1 = add_values.function\n        source1 = add_values.source\n        self.assertEqual(function0, function1)\n        self.assertEqual(source0, source1)\n        self.assertEqual(add_values.options.njit, True)\n        self.assertEqual(function0.__module__, function1.__module__)\n\n    def test_function_without_njit(self):\n        datablock0 = create_datablock(15)\n        datablock1 = create_datablock(15)\n        result_list = []\n        add_values_to_list(datablock0, datablock1, result_list)\n        self.assertEqual(len(result_list), 15)\n        self.assertEqual(result_list[0][0][0], 4.2)\n\n    def setUp(self):\n        print("" CodeGeneration Test:"", self._testMethodName)\n\nif __name__ == \'__main__\':\n    unittest.main(Tests())\n'"
implicit_solver/lib/tests/datablock_tests.py,3,"b'""""""\n@author: Vincent Bonnet\n@description : Unit tests for datablock\n""""""\n\nimport unittest\nimport lib.common as common\nimport numpy as np\n\n\'\'\'\nDatablock Functions\n\'\'\'\nclass ComponentTest:\n\n    def __init__(self):\n        self.field_0 = np.float64(0.6)\n        self.field_1 = np.ones((2, 2), dtype = np.int64) * 0.5\n\ndef create_datablock(num_elements, block_size = 100):\n    datablock = common.DataBlock(ComponentTest, block_size)\n    datablock.initialize(num_elements)\n    return datablock\n\n\'\'\'\nTests for datablock\n\'\'\'\nclass Tests(unittest.TestCase):\n\n    def test_datatype(self):\n        datablock = create_datablock(num_elements=10)\n        datablock_type = np.dtype(datablock.block(0))\n        self.assertEqual(\'field_0\' in datablock_type.names, True)\n        self.assertEqual(\'field_1\' in datablock_type.names, True)\n        self.assertEqual(\'field_c\' in datablock_type.names, False)\n        self.assertEqual(datablock_type.isalignedstruct, True)\n        self.assertEqual(datablock_type.itemsize, 4016)\n\n    def test_default_values(self):\n        datablock = create_datablock(num_elements=10)\n        block0 = datablock.block(0)\n        self.assertEqual(block0[\'field_0\'][0], 0.6)\n        self.assertTrue((block0[\'field_1\'][0] == [[0.5, 0.5], [0.5, 0.5]]).all())\n        self.assertEqual(block0[\'field_1\'][0][0][0], 0.5)\n\n    def test_fill(self):\n        datablock = create_datablock(num_elements=10)\n        datablock.fill(\'field_0\', 1.5)\n        datablock.fill(\'field_1\', 2.5)\n        block0 = datablock.block(0)\n        self.assertEqual(block0[\'field_0\'][0], 1.5)\n        self.assertTrue((block0[\'field_1\'][0] == [[2.5, 2.5], [2.5, 2.5]]).all())\n\n    def test_create_blocks(self):\n        num_elements = 10\n        datablock = create_datablock(num_elements, block_size=3)\n        datablock.copyto(\'field_0\', range(num_elements))\n\n        self.assertEqual(len(datablock.blocks), 4)\n        self.assertEqual(datablock.block(0)[\'blockInfo_numElements\'], 3)\n        self.assertEqual(datablock.block(3)[\'blockInfo_numElements\'], 1)\n        self.assertEqual(datablock.block(0)[\'blockInfo_active\'], True)\n        self.assertEqual(datablock.block(3)[\'blockInfo_active\'], True)\n        self.assertTrue((datablock.block(0)[\'field_0\'] == [0.,1.,2.]).all())\n        self.assertTrue((datablock.block(1)[\'field_0\'] == [3.,4.,5.]).all())\n        self.assertTrue((datablock.block(2)[\'field_0\'] == [6.,7.,8.]).all())\n        self.assertTrue((datablock.block(3)[\'field_0\'] == [9.,0.6,0.6]).all())\n\n    \'\'\'\n    DISABLE FOR NOW - NEED FIX\n    def test_remove_blocks(self):\n        num_elements = 10\n        datablock = create_datablock(num_elements, block_size=3)\n        datablock.copyto(\'field_0\', range(num_elements))\n\n        datablock.remove([1,2]) # remove block 1 and 2\n        flat_array = datablock.flatten(\'field_0\')\n        self.assertTrue((flat_array == [0.0,1.0,2.0,9.0]).all())\n    \'\'\'\n\n    def test_inactive_block(self):\n        num_elements = 10\n        datablock = create_datablock(num_elements, block_size=3)\n        datablock.copyto(\'field_0\', range(num_elements))\n        datablock.set_active(False, [1,3])\n        self.assertEqual(datablock.block(0)[\'blockInfo_active\'], True)\n        self.assertEqual(datablock.block(1)[\'blockInfo_active\'], False)\n        self.assertEqual(datablock.block(2)[\'blockInfo_active\'], True)\n        self.assertEqual(datablock.block(3)[\'blockInfo_active\'], False)\n        self.assertEqual(datablock.compute_num_elements(), 6)\n\n    def test_reuse_inactive_block(self):\n        num_elements = 10\n        datablock = create_datablock(num_elements, block_size=3)\n        self.assertEqual(len(datablock.blocks), 4)\n\n        # disable two blocks [1, 2] and reuse those blocks\n        datablock.set_active(False, [1,2])\n        datablock.append(num_elements = 6, reuse_inactive_block=True)\n        self.assertEqual(len(datablock.blocks), 4)\n\n        # check all the blocks are active\n        self.assertEqual(datablock.block(0)[\'blockInfo_active\'], True)\n        self.assertEqual(datablock.block(1)[\'blockInfo_active\'], True)\n        self.assertEqual(datablock.block(2)[\'blockInfo_active\'], True)\n        self.assertEqual(datablock.block(3)[\'blockInfo_active\'], True)\n\n    def setUp(self):\n        print("" DataBlock Test:"", self._testMethodName)\n\nif __name__ == \'__main__\':\n    unittest.main(Tests())\n'"
implicit_solver/lib/tests/geometry_tests.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : Unit tests for geometry functions\n""""""\n\nimport unittest\nimport lib.common as common\n\n\'\'\'\nTests for geometry functions\n\'\'\'\ndef createTriangulatedSquareShape():\n    shape = common.Shape(num_vertices=4, num_edges=5, num_faces=2)\n    shape.vertex[:] = ((-1.0, -1.0),(-1.0, 1.0),(1.0, 1.0),(1.0, -1.0))\n    shape.edge[:] = ((0, 1),(1,2),(2, 0),(2, 3),(3,0))\n    shape.face[:] = ((0, 1, 2),(0, 2, 3))\n    return shape\n\nclass Tests(unittest.TestCase):\n    def test_edges_on_surface(self):\n        shape = createTriangulatedSquareShape()\n        edges_ids, edge_normals = shape.get_edge_surface_data()\n        self.assertEqual(len(edges_ids), 4)\n        self.assertEqual(len(edge_normals), 4)\n\n    def setUp(self):\n        print("" Geometry Test:"", self._testMethodName)\n\nif __name__ == \'__main__\':\n    unittest.main(Tests())\n'"
implicit_solver/lib/tests/numba_tests.py,7,"b'""""""\n@author: Vincent Bonnet\n@description : Unit tests to evaluate Numba capabilities\n""""""\n\nimport numba\nimport unittest\nimport numpy as np\nimport lib.common as common\n\nclass ComponentTest:\n\n    def __init__(self):\n        self.field_0 = np.float64(0.5)\n        self.field_1 = np.ones((2, 2), dtype = np.int64)\n\ndef get_block_dtype(block_size = 100):\n    datablock = common.DataBlock(ComponentTest, block_size)\n    return datablock.get_block_dtype()\n\n@numba.njit\ndef create_block(block_dtype):\n    block_data = np.zeros(1, dtype=block_dtype)\n    return block_data\n\n@numba.njit\ndef set_block(block_data, num_elements, active=True):\n    item = block_data[0]\n    item.field_0[:] = np.float64(0.5)\n    item.field_1[:] = np.ones((2, 2), dtype = np.int64)\n    item[\'blockInfo_numElements\'] = num_elements\n    item[\'blockInfo_active\'] = active\n\n@numba.njit\ndef append_block(array, block_data):\n    array.append(block_data)\n\n@numba.njit\ndef get_inactive_block_indices(array):\n    indices = numba.typed.List.empty_list(numba.types.int64)\n    for block_index in range(len(array)):\n        item = array[block_index][0]\n        if not item[\'blockInfo_active\']:\n            indices.append(block_index)\n    return indices\n\n@numba.njit\ndef create_typed_list(block_dtype, num_blocks):\n    array = numba.typed.List()\n    # add dummy/inactive block\n    block_data = create_block(block_dtype)\n    set_block(block_data, num_elements=0, active=False)\n    array.append(block_data)\n\n    # add active blocks\n    for _ in range(num_blocks):\n        block_data = create_block(block_dtype)\n        set_block(block_data, num_elements=10, active=True)\n        append_block(array, block_data)\n    return array\n\n@numba.njit(parallel=False)\ndef iterate_on_typed_list(array):\n    num_blocks = len(array)\n    for block_index in numba.prange(num_blocks):\n        block_container = array[block_index]\n        block_data = block_container[0]\n        block_data[\'blockInfo_numElements\'] = 11\n\n@numba.njit\ndef take(values, indices = None):\n    result = 0\n    if indices is None:\n        for value in values:\n            result += value\n    else:\n        for index in indices:\n            result += values[index]\n\n    return result\n\nclass Tests(unittest.TestCase):\n    def test_typed_list(self):\n        block_dtype = get_block_dtype(block_size = 100)\n        blocks = create_typed_list(block_dtype, num_blocks = 15)\n        self.assertEqual(len(blocks), 16) # include inactive block\n        # Test dummy/inactive block\n        block_container = blocks[0]\n        block_data = block_container[0]\n        self.assertEqual(block_data[\'blockInfo_numElements\'], 0)\n        self.assertEqual(block_data[\'blockInfo_active\'], False)\n\n        # Test first active block\n        block_container = blocks[1]\n        block_data = block_container[0]\n        componentTest = ComponentTest()\n        self.assertEqual(block_data[\'blockInfo_numElements\'], 10)\n        self.assertEqual(block_data[\'blockInfo_active\'], True)\n        self.assertTrue(block_data[\'field_0\'][0] == componentTest.field_0)\n        self.assertTrue((block_data[\'field_1\'][0] == componentTest.field_1).all())\n\n    def test_inactive(self):\n        block_dtype = get_block_dtype(block_size = 100)\n        blocks = create_typed_list(block_dtype, num_blocks = 15)\n        block_indices = get_inactive_block_indices(blocks)\n        self.assertTrue(len(block_indices) == 1)\n\n    def test_iteration(self):\n        block_dtype = get_block_dtype(block_size = 100)\n        blocks = create_typed_list(block_dtype, num_blocks = 15)\n        iterate_on_typed_list(blocks)\n        block_container = blocks[1]\n        block_data = block_container[0]\n        self.assertEqual(block_data[\'blockInfo_numElements\'], 11)\n\n    def test_overload(self):\n        values = np.ones(10) * 1.5\n        indices = np.asarray([1,2,3])\n        self.assertEqual(take(values), 15.0)\n        self.assertEqual(take(values, indices), 4.5)\n\n    def setUp(self):\n        print("" Numba Test:"", self._testMethodName)\n\nif __name__ == \'__main__\':\n    unittest.main(Tests())\n'"
implicit_solver/lib/common/code_gen/__init__.py,0,b'# in __init__.py\n\nfrom lib.common.code_gen.gen_vectorize import as_vectorized\n'
implicit_solver/lib/common/code_gen/code_gen_helper.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : Code Generation Helper\n""""""\nimport inspect\nimport re\n\nclass CodeGenOptions:\n    def __init__(self, options):\n        self.njit = options.get(\'njit\', True)\n        self.parallel = options.get(\'parallel\', False)\n        self.debug = options.get(\'debug\', False)\n        self.fastmath = options.get(\'fastmath\', False)\n        self.block_handles = options.get(\'block_handles\', False)\n\n    def __str__(self):\n        result = \'njit \' + str(self.njit) + \'\\n\'\n        result += \'parallel \' + str(self.parallel) + \'\\n\'\n        result += \'debug \' + str(self.debug) + \'\\n\'\n        result += \'block_handles \' + str(self.block_handles)\n\n        return result\n\nclass CodeGenWriter:\n    def __init__(self, indent_size = 4):\n        self.code_lines = []\n        self.indent = 0\n        self._indent_size = indent_size # space per indentation\n\n    def append(self, code_line):\n        if not code_line:\n            self.code_lines.append(code_line)\n            return\n\n        indent_str = \' \' * self.indent * self._indent_size\n        self.code_lines.append(indent_str + code_line)\n\n    def source(self):\n        return \'\\n\'.join(self.code_lines)\n\nclass CodeGenHelper:\n\n    def __init__(self, options : CodeGenOptions):\n        # Generated function\n        self.generated_function_name = \'\'\n        self.generated_function_source = \'\'\n        # Arguments\n        self.obj_attrs_map = {} # dictionnary to map object with all attributes\n        self.variable_remap = {} # dictionnary mapping \'object.attr\' with \'object_attr\'\n        self.functions_args = [] # original functions arguments\n        # Options\n        self.options = options\n        # Test whether or not it makes sense\n        if (not options.njit) and (options.parallel or options.debug):\n            raise ValueError(""Cannot use the flags {parallel, debug} when njit=False "")\n\n    def generate_vectorized_function_source(self, function):\n        \'\'\'\n        Generate the source code of the function as a vectorized function\n        \'\'\'\n        generated_function_name = \'generated_\' + function.__name__\n\n        # Get code\n        function_source = inspect.getsource(function)\n        function_signature = inspect.signature(function)\n\n        # Check arguments\n        self.__prepare_arguments(function_source, function_signature)\n\n        # Generate source code\n        code_lines = function_source.splitlines()\n        writer = CodeGenWriter()\n\n        for code in code_lines:\n\n            # empty line\n            if not code:\n                writer.append(code)\n                continue\n\n            # remove decorators\n            if code[0] == \'@\':\n                continue\n\n            if code[0:4] == \'def \':\n                # add njit\n                if self.options.njit:\n                    numba_arguments = (\'parallel\',\'fastmath\', \'debug\')\n                    numba_default_options = (False, False, False)\n                    codegen_options = (self.options.parallel,\n                                       self.options.fastmath,\n                                       self.options.debug)\n\n                    args = []\n                    for i in range(len(codegen_options)):\n                        if numba_default_options[i] != codegen_options[i]:\n                            arg = numba_arguments[i]+\'=\'+str(codegen_options[i])\n                            args.append(arg)\n\n                    if len(args)>0:\n                        arg = \',\'.join(args)\n                        writer.append(\'@numba.njit(\'+arg+\')\')\n                    else:\n                        writer.append(\'@numba.njit\')\n\n                # rename the function arguments associated with an object\n                new_functions_args = self.functions_args.copy()\n                for argId, arg in enumerate(new_functions_args):\n                    if arg in self.obj_attrs_map:\n                        new_functions_args[argId] += \'_blocks\'\n\n                # replace function\n                if self.options.block_handles:\n                    writer.append(\'def \'+generated_function_name+\'(\'+ \', \'.join(new_functions_args) +\', block_handles):\')\n                else:\n                    writer.append(\'def \'+generated_function_name+\'(\'+ \', \'.join(new_functions_args) +\'):\')\n\n                # loop over the blocks (list/tuple of numpy array)\n                writer.indent += 1\n                if self.options.block_handles:\n                    writer.append(\'_num_blocks = len(block_handles)\' )\n                else:\n                    writer.append(\'_num_blocks = len(\' + new_functions_args[0]  + \')\' )\n\n                if self.options.parallel:\n                    writer.append(\'for _j in numba.prange(_num_blocks):\')\n                else:\n                    writer.append(\'for _j in range(_num_blocks):\')\n\n                writer.indent += 1\n                if self.options.block_handles:\n                    writer.append(\'_handle = block_handles[_j]\')\n                else:\n                    writer.append(\'_handle = _j\')\n\n                # add variable to access block info\n                master_argument = self.functions_args[0]\n                master_variable_name = master_argument + \'_blocks[_handle][0][\\\'blockInfo_numElements\\\']\'\n                writer.append(\'_num_elements = \' + master_variable_name)\n                master_variable_name = master_argument + \'_blocks[_handle][0][\\\'blockInfo_active\\\']\'\n                writer.append(\'_active = \' + master_variable_name)\n                writer.append(\'if not _active:\')\n                writer.indent += 1\n                writer.append(\'continue\')\n                writer.indent -= 1\n\n                # add variable to access block data\n                for obj, attrs in self.obj_attrs_map.items():\n                    for attr in attrs:\n                        variable_name = \'_\' + obj + \'_\' + attr\n                        variable_accessor = obj +\'_blocks[_handle][0][\\\'\' + attr + \'\\\']\'\n                        variable_code = variable_name + \' = \' + variable_accessor\n                        writer.append(variable_code)\n\n                # loop over the elements (numpy array)\n                writer.append(\'for _i in range(_num_elements):\')\n\n                # generate the variable remap\n                self.variable_remap = {}\n                for obj, attrs in self.obj_attrs_map.items():\n                    for attr in attrs:\n                        original_name = obj + \'.\' + attr\n                        variable_name = \'_\' + obj + \'_\' + attr\n                        self.variable_remap[original_name] = variable_name\n            else:\n                # prevent certain variables - cheap solution for now but could be improved\n                if \'block_handles\' in code:\n                    raise ValueError(""Cannot use the reserved \'block_handles\' variables"")\n\n                for key, value in self.variable_remap.items():\n                    code = code.replace(key, value+\'[_i]\')\n\n                writer.append(code)\n\n        # Set generated function name and source\n\n        self.generated_function_name = generated_function_name\n        self.generated_function_source = writer.source()\n\n    def __prepare_arguments(self, function_source, function_signature):\n        self.obj_attrs_map = {}\n        self.functions_args = []\n        recorded_params = []\n\n        for param_name in function_signature.parameters:\n\n            # A function argument is considered as a datablock\n            # when it is associated to an annotation (such as cpn.Node, cpn.ConstraintBased ...)\n            # it is not generic, but the code generation works with this assumption for now (december 2019)\n            annotation_type = function_signature.parameters[param_name].annotation\n            if annotation_type is not inspect._empty:\n                # regular expression to check whether the argument has a format object.attr\n                param_attrs = re.findall(param_name+\'[.][a-zA-Z0-9_]*\', function_source)\n                for param_attr in param_attrs:\n                    if param_attr in recorded_params:\n                        continue\n\n                    recorded_params.append(param_attr)\n\n                    obj, attr = param_attr.split(\'.\')\n                    attrs = self.obj_attrs_map.get(obj, [])\n                    attrs.append(attr)\n                    self.obj_attrs_map[obj] = attrs\n\n            self.functions_args.append(param_name)\n'"
implicit_solver/lib/common/code_gen/gen_vectorize.py,0,"b'""""""\n@author: Vincent Bonnet\n@description : Code Generation to convert function into numba friendly function\n""""""\n\n# Package used by gen_vectorize.py\nimport inspect\nimport functools\nimport numpy\nimport numba\n\nimport lib.common as common\nimport lib.common.code_gen.code_gen_helper as gen\n\ndef generate_vectorize_function(function, options : gen.CodeGenOptions):\n    \'\'\'\n    Returns a tuple (source code, function object)\n    \'\'\'\n    func_module = inspect.getmodule(function)\n    # Generate code\n    helper = gen.CodeGenHelper(options)\n    helper.generate_vectorized_function_source(function)\n\n    # Compile code\n    generated_function_object = compile(helper.generated_function_source, \'\', \'exec\')\n    exec(generated_function_object, func_module.__dict__)\n\n    return helper.generated_function_source, getattr(func_module, helper.generated_function_name)\n\ndef convert_argument(arg):\n    \'\'\'\n    From DataBlock to DataBlock.blocks\n    \'\'\'\n    if isinstance(arg, common.DataBlock):\n        if isinstance(arg.blocks, numba.typed.List):\n            return arg.blocks\n        else:\n            raise ValueError(""The blocks should be in a numba.Typed.List."")\n\n    return arg\n\ndef as_vectorized(function=None, local={} , **options):\n    \'\'\'\n    Decorator with arguments to vectorize a function\n    \'\'\'\n    gen_options = gen.CodeGenOptions(options)\n    if function is None:\n        return functools.partial(as_vectorized, **options)\n\n    def isDatablock(value):\n        \'\'\'\n        Returns whether the argument \'arg\' is a datablock\n        a list/tuple of numpy.void (array of complex datatypes) is also consider as a datablock\n        \'\'\'\n        if isinstance(value, common.DataBlock):\n            return True\n\n        if isinstance(value,(list, tuple)):\n            return isinstance(value[0], numpy.void)\n\n        return False\n\n    @functools.wraps(function)\n    def execute(*args):\n        \'\'\'\n        Execute the function. At least one argument is expected\n        From Book : Beazley, David, and Brian K. Jones. Python Cookbook: Recipes for Mastering Python 3. "" O\'Reilly Media, Inc."", 2013.\n        In Section : 9.6. Defining a Decorator That Takes an Optional Argument\n        \'\'\'\n        # Fetch numpy array from common.DataBlock\n        arg_list = list(args)\n        for arg_id , arg in enumerate(arg_list):\n            arg_list[arg_id] = convert_argument(arg)\n\n        # Call function\n        first_argument = args[0] # argument to vectorize\n        if isDatablock(first_argument):\n            if len(first_argument) > 0:\n                execute.function(*arg_list)\n        elif isinstance(first_argument, (list, tuple)):\n            for datablock in first_argument:\n                if isDatablock(datablock):\n                    if len(datablock) > 0:\n                        arg_list[0] = convert_argument(datablock)\n                        execute.function(*arg_list)\n                else:\n                    raise ValueError(""The first argument should be a datablock"")\n        else:\n            raise ValueError(""The first argument should be a datablock or a list of datablocks"")\n\n        return True\n\n    source, function = generate_vectorize_function(function, gen_options)\n\n    execute.options = gen_options\n    execute.source = source\n    execute.function = function\n\n    return execute\n\n\n'"
implicit_solver/lib/common/jit/__init__.py,0,b'#'
implicit_solver/lib/common/jit/block_utils.py,1,"b'""""""\n@author: Vincent Bonnet\n@description : Datablock jitted utility methods\n""""""\n\nimport math\nimport numba\nimport numpy as np\nimport lib.common.jit.node_accessor as na\n\n@numba.njit\ndef empty_block_handles():\n    return numba.typed.List.empty_list(numba.int32)\n\n@numba.njit\ndef empty_block(block_dtype):\n    block = np.empty(1, dtype=block_dtype)\n    block[0][\'blockInfo_active\'] = False\n    block[0][\'blockInfo_numElements\'] = 0\n    return block\n\n@numba.njit\ndef get_inactive_block_handles(blocks):\n    handles = empty_block_handles()\n    for block_index in range(len(blocks)):\n        if blocks[block_index][0][\'blockInfo_active\'] == False:\n            handles.append(block_index)\n    return handles\n\n@numba.njit\ndef compute_num_elements(blocks, block_handles = None):\n    num_elements = 0\n\n    if block_handles is None:\n        for block_container in blocks:\n            block_data = block_container[0]\n            if block_data[\'blockInfo_active\']:\n                num_elements += block_data[\'blockInfo_numElements\']\n    else:\n        for block_handle in block_handles:\n            block_container = blocks[block_handle]\n            block_data = block_container[0]\n            if block_data[\'blockInfo_active\']:\n                num_elements += block_data[\'blockInfo_numElements\']\n\n    return num_elements\n\n@numba.njit\ndef append_blocks(blocks, block_dtype, reuse_inactive_block, num_elements, block_size):\n    inactive_block_handles = empty_block_handles()\n    block_handles = empty_block_handles()\n\n    # collect inactive block ids\n    if reuse_inactive_block:\n        inactive_block_handles = get_inactive_block_handles(blocks)\n\n    # append blocks\n    n_blocks = math.ceil(num_elements / block_size)\n    for block_index in range(n_blocks):\n\n        block_handle = -1\n        block_container = None\n\n        if reuse_inactive_block and len(inactive_block_handles) > 0:\n            # reuse blocks\n            block_handle = inactive_block_handles.pop(0)\n            block_container = blocks[block_handle]\n        else:\n            # allocate a new block\n            block_handle = len(blocks)\n            block_container = empty_block(block_dtype)\n            blocks.append(block_container)\n\n        begin_index = block_index * block_size\n        block_n_elements = min(block_size, num_elements-begin_index)\n        block_container[0][\'blockInfo_numElements\'] = block_n_elements\n        block_container[0][\'blockInfo_active\'] = True\n\n        # add block id to result\n        block_handles.append(block_handle)\n\n    return block_handles\n\n@numba.njit\ndef append_blocks_with_ID(blocks, block_dtype, reuse_inactive_block, num_elements, block_size):\n    global_element_id = compute_num_elements(blocks)\n\n    block_handles = append_blocks(blocks, block_dtype, reuse_inactive_block, num_elements, block_size)\n\n    num_blocks = len(block_handles)\n    for i in range(num_blocks):\n        block_handle = block_handles[i]\n        block_container = blocks[block_handle]\n        block_data_ID = block_container[0][\'ID\']\n        block_n_elements = block_container[0][\'blockInfo_numElements\']\n\n        for block_node_id in range(block_n_elements):\n            na.set_node_id(block_data_ID[block_node_id],\n                           global_element_id,\n                           block_handle,\n                           block_node_id)\n            global_element_id += 1\n\n    return block_handles\n'"
implicit_solver/lib/common/jit/geometry_2d.py,3,"b'""""""\n@author: Vincent Bonnet\n@description : Geometry methods\n""""""\n\nimport numba\nimport numpy as np\nimport lib.common.jit.node_accessor as na\n\nclosestResultSpec = [(\'points\', numba.int32[:,:]), # two points\n                  (\'t\', numba.float32), # parametric value\n                  (\'position\', numba.float64[:]),  # position\n                  (\'normal\', numba.float64[:]),# normal\n                  (\'squared_distance\', numba.float64)] # parametric value\n@numba.jitclass(closestResultSpec)\nclass ClosestResult(object):\n    def __init__(self):\n        self.points = na.empty_node_ids(2)\n        self.t = 0.0\n        self.position = np.zeros(2, dtype=np.float64)\n        self.normal = np.zeros(2, dtype=np.float64)\n        self.squared_distance = np.finfo(np.float64).max\n\ninsideResultSpec = [(\'isInside\', numba.boolean)]\n@numba.jitclass(insideResultSpec)\nclass IsInsideResult(object):\n    def __init__(self):\n        self.isInside = False\n'"
implicit_solver/lib/common/jit/math_2d.py,6,"b'""""""\n@author: Vincent Bonnet\n@description : Maths methods\n""""""\nimport math\nimport numba\nimport numpy as np\n\n@numba.njit(inline=\'always\')\ndef dot(u, v):\n    \'\'\'\n    Returns the dotproduct of a 2D vector\n    np.dot is generic and fast for array but slow for a single for scalar\n    Therefore, it is replaced by a less generic norm\n    \'\'\'\n    return (u[0] * v[0]) + (u[1] * v[1])\n\n@numba.njit(inline=\'always\')\ndef det(u, v):\n    \'\'\'\n    Returns the determinant of the matrix formed from the column vectors u and v\n    \'\'\'\n    return (u[0] * v[1]) - (u[1] * v[0])\n\n@numba.njit(inline=\'always\')\ndef norm(v):\n    \'\'\'\n    Returns the norm of a 2D vector\n    np.linalg.norm is generic and fast for array but slow for a single for scalar\n    Therefore, it is replaced by a less generic norm\n    \'\'\'\n    dot = (v[0] * v[0]) + (v[1] * v[1])\n    return math.sqrt(dot)\n\n@numba.njit(inline=\'always\')\ndef is_close(v0, v1, tol=1.e-8):\n    \'\'\'\n    Returns whether two scalar are similar\n    np.isclose is generic and fast for array but slow for a single for scalar\n    Therefore, it is replaced by a less generic norm\n    \'\'\'\n    return math.fabs(v0 - v1) < tol\n\n@numba.njit(inline=\'always\')\ndef distance(x0, x1):\n    \'\'\'\n    Returns distance between x0 and x1\n    \'\'\'\n    distance = norm(x0 - x1)\n    return distance\n\n@numba.njit(inline=\'always\')\ndef area(x0, x1, x2):\n    \'\'\'\n    Returns the area of the 2D triangle from x0, x1, x2\n    \'\'\'\n    u = x1 - x0 # np.subtract(x1, x0)\n    v = x2 - x0 # np.subtract(x2, x0)\n    area = math.fabs(u[0]*v[1]-v[0]*u[1]) * 0.5\n    return area\n\n@numba.njit(inline=\'always\')\ndef angle(x0, x1, x2):\n    \'\'\'\n    Returns the angle between the segment x0-x1 and x1-x2\n    The range is [-pi, pi]\n      x1\n      /\\\n     /  \\\n    x0  x2\n    \'\'\'\n    u = x0 - x1\n    v = x1 - x2\n\n    # Discrete angle\n    det = u[0]*v[1] - u[1]*v[0]      # determinant\n    dot = u[0]*v[0] + u[1]*v[1]      # dot product\n    angle = math.atan2(det,dot)  # atan2 return range [-pi, pi]\n    return angle\n\n@numba.njit(inline=\'always\')\ndef curvature(x0, x1, x2):\n    \'\'\'\n    Connect three points :\n      x1\n      /\\\n     /  \\\n    x0  x2\n    Compute the curvature : |dT/ds| where T is the tangent and s the surface\n    The curvature at any point along a two-dimensional curve is defined as\n    the rate of change in tangent direction \xce\xb8 as a function of arc length s.\n    With :\n    t01 = x1 - x0 and t12 = x2 - x1\n    Discrete curvature formula : angle(t12,t01) / ((norm(t01) + norm(t12)) * 0.5)\n    \'\'\'\n    t01 = x1 - x0\n    t01norm = norm(t01)\n    t01 /= t01norm\n    t12 = x2 - x1\n    t12norm =  norm(t12)\n    t12 /= t12norm\n\n    # Discrete curvature\n    det = t01[0]*t12[1] - t01[1]*t12[0]      # determinant\n    dot = t01[0]*t12[0] + t01[1]*t12[1]      # dot product\n    angle = math.atan2(det,dot)  # atan2 return range [-pi, pi]\n    curvature = angle / ((t01norm + t12norm) * 0.5)\n\n    return curvature\n\n@numba.njit(inline=\'always\')\ndef copy(v):\n    \'\'\'\n    Fast copy of v\n    \'\'\'\n    v_copy = np.zeros(2)\n    v_copy[0] = v[0]\n    v_copy[1] = v[1]\n    return v_copy\n'"
implicit_solver/lib/common/jit/node_accessor.py,2,"b'""""""\n@author: Vincent Bonnet\n@description : This class provides a mapping between node identifiers and datablock layout\nFormat : [global_node_id, block_handle, block_node_id]\n""""""\n\nimport numba\nimport numpy as np\n\nID_SIZE = 3\n\n@numba.njit\ndef empty_node_ids(num_nodes):\n    return np.empty((num_nodes, ID_SIZE), dtype=np.int32)\n\n@numba.njit\ndef emtpy_node_id():\n    return np.empty(ID_SIZE, dtype=np.int32)\n\n@numba.njit\ndef set_node_id(node_id, global_node_id, block_handle, block_node_id):\n    node_id[0] = global_node_id\n    node_id[1] = block_handle\n    node_id[2] = block_node_id\n\n@numba.njit\ndef node_global_index(node_id):\n    return node_id[0]\n\n@numba.njit\ndef node_x(node_blocks, node_id):\n    block_handle = node_id[1]\n    block_node_id = node_id[2]\n    return node_blocks[block_handle][0][\'x\'][block_node_id]\n\n@numba.njit\ndef node_v(node_blocks, node_id):\n    block_handle = node_id[1]\n    block_node_id = node_id[2]\n    return node_blocks[block_handle][0][\'v\'][block_node_id]\n\n@numba.njit\ndef node_xv(node_blocks, node_id):\n    block_handle = node_id[1]\n    block_node_id = node_id[2]\n\n    x = node_blocks[block_handle][0][\'x\'][block_node_id]\n    v = node_blocks[block_handle][0][\'v\'][block_node_id]\n    return (x, v)\n\n@numba.njit\ndef node_add_f(node_blocks, node_id, force):\n    block_handle = node_id[1]\n    block_node_id = node_id[2]\n\n    f = node_blocks[block_handle][0][\'f\'][block_node_id]\n    f += force\n'"
implicit_solver/lib/objects/jit/__init__.py,0,"b'# in __init__.py\n\nfrom lib.objects.jit.base import ConstraintBase\nfrom lib.objects.jit.spring import Spring, AnchorSpring\nfrom lib.objects.jit.bending import Bending\nfrom lib.objects.jit.area import Area\nfrom lib.objects.jit.node import Node\nfrom lib.objects.jit.simplex import Point, Edge, Triangle, Tetrahedron\n\n'"
implicit_solver/lib/objects/jit/area.py,2,"b'""""""\n@author: Vincent Bonnet\n@description : Constraint base for the implicit solver\n""""""\n\nimport numpy as np\nimport numba # required by lib.common.code_gen\n\nimport lib.common.jit.math_2d as math2D\nimport lib.common.jit.node_accessor as na\nimport lib.common.code_gen as generate\nimport lib.objects.jit.utils.area_lib as area_lib\nimport lib.objects.jit as cpn\n\nclass Area(cpn.ConstraintBase):\n    \'\'\'\n    Describes a 2D area constraint between three nodes\n    \'\'\'\n    def __init__(self):\n        cpn.ConstraintBase.__init__(self, num_nodes = 3)\n        self.rest_area = np.float64(0.0)\n\n    @classmethod\n    def pre_compute(cls):\n        return None\n\n    @classmethod\n    def compute_rest(cls):\n        return compute_area_rest\n\n    @classmethod\n    def compute_gradients(cls):\n        return compute_area_forces\n\n    @classmethod\n    def compute_hessians(cls):\n        return compute_area_jacobians\n\n@generate.as_vectorized(block_handles=True)\ndef compute_area_rest(area : Area, detail_nodes):\n    x0 = na.node_x(detail_nodes, area.node_IDs[0])\n    x1 = na.node_x(detail_nodes, area.node_IDs[1])\n    x2 = na.node_x(detail_nodes, area.node_IDs[2])\n    area.rest_area = np.float64(math2D.area(x0, x1, x2))\n\n@generate.as_vectorized(block_handles=True)\ndef compute_area_forces(area : Area, detail_nodes):\n    x0 = na.node_x(detail_nodes, area.node_IDs[0])\n    x1 = na.node_x(detail_nodes, area.node_IDs[1])\n    x2 = na.node_x(detail_nodes, area.node_IDs[2])\n    forces = area_lib.elastic_area_forces(x0, x1, x2, area.rest_area, area.stiffness, (True, True, True))\n    area.f[0] = forces[0]\n    area.f[1] = forces[1]\n    area.f[2] = forces[2]\n\n@generate.as_vectorized(block_handles=True)\ndef compute_area_jacobians(area : Area, detail_nodes):\n    x0 = na.node_x(detail_nodes, area.node_IDs[0])\n    x1 = na.node_x(detail_nodes, area.node_IDs[1])\n    x2 = na.node_x(detail_nodes, area.node_IDs[2])\n    jacobians = area_lib.elastic_area_numerical_jacobians(x0, x1, x2, area.rest_area, area.stiffness)\n    area.dfdx[0][0] = jacobians[0]\n    area.dfdx[1][1] = jacobians[1]\n    area.dfdx[2][2] = jacobians[2]\n    area.dfdx[0][1] = area.dfdx[1][0] = jacobians[3]\n    area.dfdx[0][2] = area.dfdx[2][0] = jacobians[4]\n    area.dfdx[1][2] = area.dfdx[2][1] = jacobians[5]\n'"
implicit_solver/lib/objects/jit/base.py,5,"b'""""""\n@author: Vincent Bonnet\n@description : Constraint base for the implicit solver\n""""""\n\nimport numpy as np\n\nimport lib.common.jit.node_accessor as na\n\nclass ConstraintBase:\n    \'\'\'\n    Describes the constraint base\n    \'\'\'\n    def __init__(self, num_nodes : int):\n\n        # Constraint Property\n        self.stiffness = np.float64(0.0)\n        self.damping = np.float64(0.0)\n\n        # Node ids involved in the constraint\n        self.node_IDs = na.empty_node_ids(num_nodes)\n\n        # Precomputed forces/jacobians.\n        self.f = np.zeros((num_nodes, 2), dtype = np.float64)\n        self.dfdx = np.zeros((num_nodes, num_nodes, 2, 2), dtype = np.float64)\n        self.dfdv = np.zeros((num_nodes, num_nodes, 2, 2), dtype = np.float64)\n'"
implicit_solver/lib/objects/jit/bending.py,2,"b'""""""\n@author: Vincent Bonnet\n@description : Bending Constraint for the implicit solver\n""""""\n\nimport numpy as np\nimport numba # required by lib.common.code_gen\n\nimport lib.common.jit.math_2d as math2D\nimport lib.common.jit.node_accessor as na\nimport lib.common.code_gen as generate\nimport lib.objects.jit.utils.bending_lib as bending_lib\nimport lib.objects.jit as cpn\n\nclass Bending(cpn.ConstraintBase):\n    \'\'\'\n    Describes a 2D bending constraint of a thin inextensible wire\n    between three nodes.\n    This bending is NOT the proper bending formulation and uses angle instead of curvature\n    Some instabilities when using the curvature => Need to investigate\n    \'\'\'\n    def __init__(self):\n        \'\'\'\n        Constraint three nodes to maintain angle between\n        node_ids[0] - node_ids[1] - node_ids[2]\n        \'\'\'\n        cpn.ConstraintBase.__init__(self, num_nodes = 3)\n        self.rest_angle = np.float64(0.0)\n\n    @classmethod\n    def pre_compute(cls):\n        return None\n\n    @classmethod\n    def compute_rest(cls):\n        return compute_bending_rest\n\n    @classmethod\n    def compute_gradients(cls):\n        return compute_bending_forces\n\n    @classmethod\n    def compute_hessians(cls):\n        return compute_bending_jacobians\n\n@generate.as_vectorized(block_handles=True)\ndef compute_bending_rest(bending : Bending, detail_nodes):\n    x0 = na.node_x(detail_nodes, bending.node_IDs[0])\n    x1 = na.node_x(detail_nodes, bending.node_IDs[1])\n    x2 = na.node_x(detail_nodes, bending.node_IDs[2])\n    bending.rest_angle = np.float64(math2D.angle(x0, x1, x2))\n\n@generate.as_vectorized(block_handles=True)\ndef compute_bending_forces(bending : Bending, detail_nodes):\n    x0 = na.node_x(detail_nodes, bending.node_IDs[0])\n    x1 = na.node_x(detail_nodes, bending.node_IDs[1])\n    x2 = na.node_x(detail_nodes, bending.node_IDs[2])\n    forces = bending_lib.elastic_bending_forces(x0, x1, x2, bending.rest_angle, bending.stiffness, (True, True, True))\n    bending.f[0] = forces[0]\n    bending.f[1] = forces[1]\n    bending.f[2] = forces[2]\n\n@generate.as_vectorized(block_handles=True)\ndef compute_bending_jacobians(bending : Bending, detail_nodes):\n    x0 = na.node_x(detail_nodes, bending.node_IDs[0])\n    x1 = na.node_x(detail_nodes, bending.node_IDs[1])\n    x2 = na.node_x(detail_nodes, bending.node_IDs[2])\n    dfdx = bending_lib.elastic_bending_numerical_jacobians(x0, x1, x2, bending.rest_angle, bending.stiffness)\n    bending.dfdx[0][0] = dfdx[0]\n    bending.dfdx[1][1] = dfdx[1]\n    bending.dfdx[2][2] = dfdx[2]\n    bending.dfdx[0][1] = bending.dfdx[1][0] = dfdx[3]\n    bending.dfdx[0][2] = bending.dfdx[2][0] = dfdx[4]\n    bending.dfdx[1][2] = bending.dfdx[2][1] = dfdx[5]\n'"
implicit_solver/lib/objects/jit/node.py,5,"b'""""""\n@author: Vincent Bonnet\n@description : Node data type for dynamic object\n""""""\n\nimport numpy as np\nimport lib.common.jit.node_accessor as na\n\nclass Node:\n    def __init__(self):\n        self.x = np.zeros(2, dtype = np.float64)\n        self.v = np.zeros(2, dtype = np.float64)\n        self.f = np.zeros(2, dtype = np.float64)\n        self.m = np.float64(0.0)\n        self.im = np.float64(0.0)\n        self.ID = na.emtpy_node_id()\n'"
implicit_solver/lib/objects/jit/simplex.py,7,"b'""""""\n@author: Vincent Bonnet\n@description : Simplices to store point, edge, triangle, tetrahedron\n""""""\n\nimport numpy as np\nimport numba # required by lib.common.code_gen\n\nimport lib.common.jit.math_2d as math2D\nimport lib.common.jit.node_accessor as na\nimport lib.common.code_gen as generate\n\nclass Point:\n    def __init__(self):\n        self.local_x = np.zeros(2, dtype = np.float64)\n        self.x = np.zeros(2, dtype = np.float64)\n        self.ID = na.emtpy_node_id()\n\nclass Edge:\n    def __init__(self):\n        self.point_IDs = na.empty_node_ids(2)\n        self.local_normal = np.zeros(2, dtype = np.float64)\n        self.normal = np.zeros(2, dtype = np.float64)\n\nclass Triangle:\n    def __init__(self):\n        self.point_IDs = na.empty_node_ids(3)\n\nclass Tetrahedron:\n    def __init__(self):\n        self.point_IDs = na.empty_node_ids(4)\n\n@generate.as_vectorized(block_handles=True)\ndef transform_point(point : Point, rotation_matrix, translate):\n    #np.dot(point.x, rotation_matrix, out=point.x) #  not working with Numba0.45.1\n    point.x = np.dot(point.local_x, rotation_matrix)\n    point.x += translate\n\n@generate.as_vectorized(block_handles=True)\ndef transform_normal(edge : Edge, rotation_matrix):\n    edge.normal = np.dot(edge.local_normal, rotation_matrix)\n\n@generate.as_vectorized(block_handles=True)\ndef get_closest_param(edge : Edge, points, position, o_param):\n    # o_param = ClosestResult()\n    x0 = na.node_x(points, edge.point_IDs[0])\n    x1 = na.node_x(points, edge.point_IDs[1])\n\n    edge_dir = x1 - x0 # could be precomputed\n    edge_dir_square = math2D.dot(edge_dir, edge_dir) # could be precomputed\n    proj_p = math2D.dot(position - x0, edge_dir)\n    t = proj_p / edge_dir_square\n    t = max(min(t, 1.0), 0.0)\n    projected_point = x0 + edge_dir * t # correct the project point\n    vector_distance = (position - projected_point)\n    squared_distance = math2D.dot(vector_distance, vector_distance)\n    # update the minimum distance\n    if squared_distance < o_param.squared_distance:\n        o_param.points = edge.point_IDs\n        o_param.t = t\n        o_param.squared_distance = squared_distance\n        o_param.position = x0 * (1.0 - t) + x1 * t\n        o_param.normal = edge.normal\n\n@generate.as_vectorized(block_handles=True)\ndef is_inside(face : Triangle, points, position, o_result):\n    # result = IsInsideResult()\n    x0 = na.node_x(points, face.point_IDs[0])\n    x1 = na.node_x(points, face.point_IDs[1])\n    x2 = na.node_x(points, face.point_IDs[2])\n    v0 = x2 - x0\n    v1 = x1 - x0\n    v2 = position - x0\n\n    dot00 = math2D.dot(v0, v0)\n    dot01 = math2D.dot(v0, v1)\n    dot02 = math2D.dot(v0, v2)\n    dot11 = math2D.dot(v1, v1)\n    dot12 = math2D.dot(v1, v2)\n\n    inv = 1.0 / (dot00 * dot11 - dot01 * dot01)\n    a = (dot11 * dot02 - dot01 * dot12) * inv\n    b = (dot00 * dot12 - dot01 * dot02) * inv\n    if a>=0 and b>=0 and a+b<=1:\n        o_result.isInside = True\n        return\n'"
implicit_solver/lib/objects/jit/spring.py,8,"b'""""""\n@author: Vincent Bonnet\n@description : Constraint base for the implicit solver\n""""""\n\nimport numpy as np\nimport numba # required by lib.common.code_gen\n\nimport lib.common.jit.math_2d as math2D\nimport lib.common.jit.node_accessor as na\nimport lib.common.code_gen as generate\nimport lib.objects.jit.utils.spring_lib as spring_lib\nimport lib.objects.jit as cpn\n\nclass AnchorSpring(cpn.ConstraintBase):\n    \'\'\'\n    Describes a 2D spring constraint between a node and point\n    \'\'\'\n    def __init__(self):\n        cpn.ConstraintBase.__init__(self, num_nodes = 1)\n        self.rest_length = np.float64(0.0)\n        self.kinematic_component_IDs = na.empty_node_ids(2) # Point ids\n        self.kinematic_component_param = np.float64(0.0)\n        self.kinematic_component_pos = np.zeros(2, dtype = np.float64)\n\n    @classmethod\n    def pre_compute(cls):\n        return pre_compute_anchor_spring\n\n    @classmethod\n    def compute_rest(cls):\n        return compute_anchor_spring_rest\n\n    @classmethod\n    def compute_gradients(cls):\n        return compute_anchor_spring_forces\n\n    @classmethod\n    def compute_hessians(cls):\n        return compute_anchor_spring_jacobians\n\nclass Spring(cpn.ConstraintBase):\n    \'\'\'\n    Describes a 2D spring constraint between two nodes\n    \'\'\'\n    def __init__(self):\n        cpn.ConstraintBase.__init__(self, num_nodes = 2)\n        self.rest_length = np.float64(0.0)\n\n    @classmethod\n    def pre_compute(cls):\n        return None\n\n    @classmethod\n    def compute_rest(cls):\n        return compute_spring_rest\n\n    @classmethod\n    def compute_gradients(cls):\n        return compute_spring_forces\n\n    @classmethod\n    def compute_hessians(cls):\n        return compute_spring_jacobians\n\n\'\'\'\nAnchorSpring compute functions\n\'\'\'\n@generate.as_vectorized(block_handles=True)\ndef pre_compute_anchor_spring(anchor_spring : AnchorSpring, detail_nodes, details_points):\n    t = anchor_spring.kinematic_component_param\n    x0 = na.node_x(details_points, anchor_spring.kinematic_component_IDs[0])\n    x1 = na.node_x(details_points, anchor_spring.kinematic_component_IDs[1])\n    anchor_spring.kinematic_component_pos = x0 * (1.0 - t) + x1 * t\n\n@generate.as_vectorized(block_handles=True)\ndef compute_anchor_spring_rest(anchor_spring : AnchorSpring, detail_nodes):\n    x = na.node_x(detail_nodes, anchor_spring.node_IDs[0])\n    anchor_spring.rest_length = np.float64(math2D.distance(anchor_spring.kinematic_component_pos, x))\n\n@generate.as_vectorized(block_handles=True)\ndef compute_anchor_spring_forces(anchor_spring : AnchorSpring, detail_nodes):\n    x, v = na.node_xv(detail_nodes, anchor_spring.node_IDs[0])\n    kinematic_vel = np.zeros(2)\n    target_pos = anchor_spring.kinematic_component_pos\n    force = spring_lib.spring_stretch_force(x, target_pos, anchor_spring.rest_length, anchor_spring.stiffness)\n    force += spring_lib.spring_damping_force(x, target_pos, v, kinematic_vel, anchor_spring.damping)\n    anchor_spring.f = force\n\n@generate.as_vectorized(block_handles=True)\ndef compute_anchor_spring_jacobians(anchor_spring : AnchorSpring, detail_nodes):\n    x, v = na.node_xv(detail_nodes, anchor_spring.node_IDs[0])\n    kinematic_vel = np.zeros(2)\n    target_pos = anchor_spring.kinematic_component_pos\n    dfdx = spring_lib.spring_stretch_jacobian(x, target_pos, anchor_spring.rest_length, anchor_spring.stiffness)\n    dfdv = spring_lib.spring_damping_jacobian(x, target_pos, v, kinematic_vel, anchor_spring.damping)\n    anchor_spring.dfdx[0][0] = dfdx\n    anchor_spring.dfdv[0][0] = dfdv\n\n\'\'\'\nSpring compute functions\n\'\'\'\n@generate.as_vectorized(block_handles=True)\ndef compute_spring_rest(spring : Spring, detail_nodes):\n    x0 = na.node_x(detail_nodes, spring.node_IDs[0])\n    x1 = na.node_x(detail_nodes, spring.node_IDs[1])\n    spring.rest_length = np.float64(math2D.distance(x0, x1))\n\n@generate.as_vectorized(block_handles=True)\ndef compute_spring_forces(spring : Spring, detail_nodes):\n    x0, v0 = na.node_xv(detail_nodes, spring.node_IDs[0])\n    x1, v1 = na.node_xv(detail_nodes, spring.node_IDs[1])\n    force = spring_lib.spring_stretch_force(x0, x1, spring.rest_length, spring.stiffness)\n    force += spring_lib.spring_damping_force(x0, x1, v0, v1, spring.damping)\n    spring.f[0] = force\n    spring.f[1] = force * -1.0\n\n@generate.as_vectorized(block_handles=True)\ndef compute_spring_jacobians(spring : Spring, detail_nodes):\n    x0, v0 = na.node_xv(detail_nodes, spring.node_IDs[0])\n    x1, v1 = na.node_xv(detail_nodes, spring.node_IDs[1])\n    dfdx = spring_lib.spring_stretch_jacobian(x0, x1, spring.rest_length, spring.stiffness)\n    dfdv = spring_lib.spring_damping_jacobian(x0, x1, v0, v1, spring.damping)\n    spring.dfdx[0][0] = spring.dfdx[1][1] = dfdx\n    spring.dfdx[0][1] = spring.dfdx[1][0] = dfdx * -1\n    spring.dfdv[0][0] = spring.dfdv[1][1] = dfdv\n    spring.dfdv[0][1] = spring.dfdv[1][0] = dfdv * -1\n\n'"
implicit_solver/lib/system/jit/__init__.py,0,b'#'
implicit_solver/lib/system/jit/integrator_lib.py,7,"b'""""""\n@author: Vincent Bonnet\n@description : Helper functions for time integrators\n""""""\nimport numba # required by lib.common.code_gen\nimport numpy as np\n\nimport lib.common.jit.node_accessor as na\nimport lib.common.code_gen as generate\nimport lib.objects.jit as cpn\nfrom . import sparse_matrix_lib as sparse_lib\n\ndef apply_external_forces_to_nodes(dynamics, forces):\n    # this function is not vectorized but forces.apply_forces are vectorized\n    for force in forces:\n        force.apply_forces(dynamics)\n\n@generate.as_vectorized\ndef apply_constraint_forces_to_nodes(constraint : cpn.ConstraintBase, detail_nodes):\n    # Cannot be threaded yet to prevent different threads to write on the same node\n    num_nodes = len(constraint.node_IDs)\n    for i in range(num_nodes):\n        na.node_add_f(detail_nodes,  constraint.node_IDs[i], constraint.f[i])\n\n@generate.as_vectorized\ndef advect(node : cpn.Node, delta_v, dt):\n    # Can be threaded\n    node_index = na.node_global_index(node.ID)\n    node.v += delta_v[node_index]\n    node.x += node.v * dt\n\n@generate.as_vectorized\ndef assemble_fo_h_to_b(node : cpn.Node, dt, b):\n    # Can be threaded\n    node_index = na.node_global_index(node.ID)\n    b[node_index] += node.f * dt\n\n@generate.as_vectorized\ndef assemble_dfdx_v0_h2_to_b(constraint : cpn.ConstraintBase, detail_nodes, dt, b):\n    # Cannot be threaded yet\n    num_nodes = len(constraint.node_IDs)\n    for fi in range(num_nodes):\n        node_index = na.node_global_index(constraint.node_IDs[fi])\n        for xi in range(num_nodes):\n            Jx = constraint.dfdx[fi][xi]\n            v = na.node_v(detail_nodes, constraint.node_IDs[xi])\n            b[node_index] += np.dot(v, Jx) * dt * dt\n\n@generate.as_vectorized\ndef assemble_mass_matrix_to_A(node : cpn.Node, A):\n    # Can be threaded\n    node_index = na.node_global_index(node.ID)\n    mass_matrix = np.zeros((2,2))\n    np.fill_diagonal(mass_matrix, node.m)\n    sparse_lib.add(A, node_index, node_index, mass_matrix)\n\n@generate.as_vectorized\ndef assemble_constraint_forces_to_A(constraint : cpn.ConstraintBase, dt, A):\n    # Substract (h * df/dv + h^2 * df/dx)\n    # Cannot be threaded yet\n    num_nodes = len(constraint.node_IDs)\n    for fi in range(num_nodes):\n        for j in range(num_nodes):\n            Jv = constraint.dfdv[fi][j]\n            Jx = constraint.dfdx[fi][j]\n            global_fi_id = na.node_global_index(constraint.node_IDs[fi])\n            global_j_id = na.node_global_index(constraint.node_IDs[j])\n            sparse_lib.add(A, global_fi_id, global_j_id, ((Jv * dt) + (Jx * dt * dt)) * -1.0)\n\n@numba.njit\ndef assemble_A(node_blocks,\n               area_blocks,\n               bending_blocks,\n               spring_blocks,\n               anchorSpring_blocks,\n               num_rows,\n               dt,\n               mass_matrix_assembly_func,\n               constraint_matrix_assembly_func):\n\n    sub_size=2 # submatrix size\n\n    # create mass matrix\n    A = sparse_lib.create_empty_sparse_matrix(num_rows, sub_size)\n    mass_matrix_assembly_func(node_blocks, A)\n\n    # assemble constraint in matrix\n    constraint_matrix_assembly_func(area_blocks, dt, A)\n    constraint_matrix_assembly_func(bending_blocks, dt, A)\n    constraint_matrix_assembly_func(spring_blocks, dt, A)\n    constraint_matrix_assembly_func(anchorSpring_blocks, dt, A)\n\n    # allocate and set number of entries per row\n    num_entries_per_row = np.zeros(num_rows, dtype=np.int32)\n    for row_id in range(num_rows):\n        num_entries_per_row[row_id] = len(A[row_id])\n\n    # allocate column indices and array of matrix\n    total_entries = np.sum(num_entries_per_row)\n    data = np.zeros((total_entries, sub_size, sub_size))\n    column_indices = np.zeros(total_entries, dtype=np.int32)\n\n    # set column indices and array of matrix\n    idx = 0\n    for row_id in range(num_rows):\n        # numba-0.0.47 use return an array of key when sorting a dictionnary\n        # it should be fix in later version\n        sortedA = sorted(A[row_id])\n        for column_id in sortedA:\n            matrix = A[row_id][column_id]\n            column_indices[idx] = column_id\n            data[idx] = matrix\n            idx += 1\n\n    return num_entries_per_row, column_indices, data\n\n'"
implicit_solver/lib/system/jit/sparse_matrix_lib.py,1,"b'""""""\n@author: Vincent Bonnet\n@description : Helper functions for sparse matrix assembly\n""""""\n\nimport numba\nimport numpy as np\n\n@numba.njit\ndef create_empty_sparse_matrix(num_rows, block_size):\n    A = []\n    for i in range(num_rows):\n        A.append({i:np.zeros((block_size,block_size))})\n    return A\n\n@numba.njit\ndef add(A, i, j, data):\n    if j in A[i]:\n        A[i][j] += data\n    else:\n        A[i][j] = data\n'"
implicit_solver/lib/objects/jit/utils/__init__.py,0,b'#'
implicit_solver/lib/objects/jit/utils/area_lib.py,4,"b'""""""\n@author: Vincent Bonnet\n@description : Area constraint helper functions\n""""""\n\nimport numpy as np\nimport numba\nimport lib.common.jit.math_2d as math2D\n\n@numba.njit\ndef elastic_area_anergy(x0, x1, x2, rest_area, stiffness):\n    area = math2D.area(x0, x1, x2)\n    return 0.5 * stiffness * ((area - rest_area)**2)\n\n@numba.njit\ndef elastic_area_forces(x0, x1, x2, rest_area, stiffness, enable_force = (True, True, True)):\n    forces = np.zeros((3, 2))\n\n    u = x0 - x1\n    v = x1 - x2\n    w = x0 - x2\n    det = u[0]*w[1] - w[0]*u[1]\n\n    if enable_force[0] or enable_force[1]:\n        forces[0][0] = v[1]\n        forces[0][1] = v[0] * -1.0\n        forces[0] *= 0.5*stiffness*(rest_area - 0.5*np.abs(det))*np.sign(det)\n\n    if enable_force[2] or enable_force[1]:\n        forces[2][0] = u[1]\n        forces[2][1] = u[0] * -1.0\n        forces[2] *= 0.5*stiffness*(rest_area - 0.5*np.abs(det))*np.sign(det)\n\n    if enable_force[1]:\n        forces[1] -= (forces[0] + forces[2])\n\n    return forces\n\n@numba.njit\ndef elastic_area_numerical_jacobians(x0, x1, x2, rest_area, stiffness):\n    \'\'\'\n    Returns the six jacobians matrices in the following order\n    df0dx0, df1dx1, df2dx2, df0dx1, df0dx2, df1dx2\n    dfdx01 is the derivative of f0 relative to x1\n    etc.\n    \'\'\'\n    jacobians = np.zeros(shape=(6, 2, 2))\n    STENCIL_SIZE = 1e-6\n\n    # derivate of f0 relative to x0\n    for g_id in range(2):\n        x0_ = math2D.copy(x0)\n        x0_[g_id] = x0[g_id]+STENCIL_SIZE\n        forces = elastic_area_forces(x0_, x1, x2, rest_area, stiffness, (True, False, False))\n        grad_f0_x0 = forces[0]\n        x0_[g_id] = x0[g_id]-STENCIL_SIZE\n        forces = elastic_area_forces(x0_, x1, x2, rest_area, stiffness, (True, False, False))\n        grad_f0_x0 -= forces[0]\n        grad_f0_x0 /= (2.0 * STENCIL_SIZE)\n        jacobians[0, 0:2, g_id] = grad_f0_x0\n\n    # derivate of f0, f1 relative to x1\n    for g_id in range(2):\n        x1_ = math2D.copy(x1)\n        x1_[g_id] = x1[g_id]+STENCIL_SIZE\n        forces = elastic_area_forces(x0, x1_, x2, rest_area, stiffness, (True, True, False))\n        grad_f0_x1 = forces[0]\n        grad_f1_x1 = forces[1]\n        x1_[g_id] = x1[g_id]-STENCIL_SIZE\n        forces = elastic_area_forces(x0, x1_, x2, rest_area, stiffness, (True, True, False))\n        grad_f0_x1 -= forces[0]\n        grad_f1_x1 -= forces[1]\n        jacobians[1, 0:2, g_id] = grad_f1_x1 / (2.0 * STENCIL_SIZE)\n        jacobians[3, 0:2, g_id] = grad_f0_x1 / (2.0 * STENCIL_SIZE)\n\n    # derivate of f0, f1, f2 relative to x2\n    for g_id in range(2):\n        x2_ = math2D.copy(x2)\n        x2_[g_id] = x2[g_id]+STENCIL_SIZE\n        forces = elastic_area_forces(x0, x1, x2_, rest_area, stiffness, (True, True, True))\n        grad_f0_x2 = forces[0]\n        grad_f1_x2 = forces[1]\n        grad_f2_x2 = forces[2]\n        x2_[g_id] = x2[g_id]-STENCIL_SIZE\n        forces = elastic_area_forces(x0, x1, x2_, rest_area, stiffness, (True, True, True))\n        grad_f0_x2 -= forces[0]\n        grad_f1_x2 -= forces[1]\n        grad_f2_x2 -= forces[2]\n        jacobians[4, 0:2, g_id] = grad_f0_x2 / (2.0 * STENCIL_SIZE)\n        jacobians[5, 0:2, g_id] = grad_f1_x2 / (2.0 * STENCIL_SIZE)\n        jacobians[2, 0:2, g_id] = grad_f2_x2 / (2.0 * STENCIL_SIZE)\n\n    return jacobians\n'"
implicit_solver/lib/objects/jit/utils/bending_lib.py,2,"b'""""""\n@author: Vincent Bonnet\n@description : Bending constraint helper functions\n""""""\n\nimport math\nimport numpy as np\nimport numba\nimport lib.common.jit.math_2d as math2D\n\n@numba.njit\ndef elastic_bending_energy(x0, x1, x2, rest_angle, stiffness):\n    angle = math2D.angle(x0, x1, x2)\n    arc_length = (math2D.norm(x1 - x0) + math2D.norm(x2 - x1)) * 0.5\n    return 0.5 * stiffness * ((angle - rest_angle)**2) * arc_length\n\n@numba.njit\ndef elastic_bending_forces(x0, x1, x2, rest_angle, stiffness, enable_force = (True, True, True)):\n    forces = np.zeros((3, 2))\n\n    u = x0 - x1\n    v = x1 - x2\n    det = u[0]*v[1] - v[0]*u[1]\n    dot = u[0]*v[0] + u[1]*v[1]\n\n    norm_u = math.sqrt(u[0]**2 + u[1]**2)\n    norm_v = math.sqrt(v[0]**2 + v[1]**2)\n\n    diff_angle = rest_angle - math.atan2(det, dot)\n\n    if enable_force[0] or enable_force[1]:\n        forces[0][0] = v[0]*det - v[1]*dot\n        forces[0][1] = v[0]*dot + v[1]*det\n\n        forces[0] *= 0.5*(norm_u + norm_v)/(dot**2 + det**2)\n        forces[0] += 0.25*u*diff_angle/norm_u\n\n        forces[0] *= stiffness*diff_angle*-1.0\n\n    if enable_force[2] or enable_force[1]:\n        forces[2][0] = -(u[0]*det + u[1]*dot)\n        forces[2][1] = u[0]*dot - u[1]*det\n\n        forces[2] *= 0.5*(norm_u + norm_v)/(dot**2 + det**2)\n        forces[2] += -0.25*v*diff_angle/norm_v\n\n        forces[2] *= stiffness*diff_angle*-1.0\n\n    if enable_force[1]:\n        forces[1] -= (forces[0] + forces[2])\n\n    return forces\n\n@numba.njit\ndef elastic_bending_numerical_jacobians(x0, x1, x2, rest_angle, stiffness):\n    \'\'\'\n    Returns the six jacobians matrices in the following order\n    df0dx0, df1dx1, df2dx2, df0dx1, df0dx2, df1dx2\n    dfdx01 is the derivative of f0 relative to x1\n    etc.\n    \'\'\'\n    jacobians = np.zeros(shape=(6, 2, 2))\n    STENCIL_SIZE = 1e-6\n\n    # derivate of f0 relative to x0\n    for g_id in range(2):\n        x0_ = math2D.copy(x0)\n        x0_[g_id] = x0[g_id]+STENCIL_SIZE\n        forces = elastic_bending_forces(x0_, x1, x2, rest_angle, stiffness, (True, False, False))\n        grad_f0_x0 = forces[0]\n        x0_[g_id] = x0[g_id]-STENCIL_SIZE\n        forces = elastic_bending_forces(x0_, x1, x2, rest_angle, stiffness, (True, False, False))\n        grad_f0_x0 -= forces[0]\n        grad_f0_x0 /= (2.0 * STENCIL_SIZE)\n        jacobians[0, 0:2, g_id] = grad_f0_x0\n\n    # derivate of f0, f1 relative to x1\n    for g_id in range(2):\n        x1_ = math2D.copy(x1)\n        x1_[g_id] = x1[g_id]+STENCIL_SIZE\n        forces = elastic_bending_forces(x0, x1_, x2, rest_angle, stiffness, (True, True, False))\n        grad_f0_x1 = forces[0]\n        grad_f1_x1 = forces[1]\n        x1_[g_id] = x1[g_id]-STENCIL_SIZE\n        forces = elastic_bending_forces(x0, x1_, x2, rest_angle, stiffness, (True, True, False))\n        grad_f0_x1 -= forces[0]\n        grad_f1_x1 -= forces[1]\n        jacobians[1, 0:2, g_id] = grad_f1_x1 / (2.0 * STENCIL_SIZE)\n        jacobians[3, 0:2, g_id] = grad_f0_x1 / (2.0 * STENCIL_SIZE)\n\n    # derivate of f0, f1, f2 relative to x2\n    for g_id in range(2):\n        x2_ = math2D.copy(x2)\n        x2_[g_id] = x2[g_id]+STENCIL_SIZE\n        forces = elastic_bending_forces(x0, x1, x2_, rest_angle, stiffness, (True, True, True))\n        grad_f0_x2 = forces[0]\n        grad_f1_x2 = forces[1]\n        grad_f2_x2 = forces[2]\n        x2_[g_id] = x2[g_id]-STENCIL_SIZE\n        forces = elastic_bending_forces(x0, x1, x2_, rest_angle, stiffness, (True, True, True))\n        grad_f0_x2 -= forces[0]\n        grad_f1_x2 -= forces[1]\n        grad_f2_x2 -= forces[2]\n        jacobians[4, 0:2, g_id] = grad_f0_x2 / (2.0 * STENCIL_SIZE)\n        jacobians[5, 0:2, g_id] = grad_f1_x2 / (2.0 * STENCIL_SIZE)\n        jacobians[2, 0:2, g_id] = grad_f2_x2 / (2.0 * STENCIL_SIZE)\n\n    return jacobians\n'"
implicit_solver/lib/objects/jit/utils/spring_lib.py,5,"b'""""""\n@author: Vincent Bonnet\n@description : Spring constraint helper functions\n""""""\n\nimport numpy as np\nimport numba\nimport lib.common.jit.math_2d as math2D\n\n\'\'\'\nAnchorSpring/Spring helper functions\n\'\'\'\n@numba.njit\ndef spring_stretch_jacobian(x0, x1, rest, stiffness):\n    direction = x0 - x1\n    stretch = math2D.norm(direction)\n    I = np.identity(2)\n    if not math2D.is_close(stretch, 0.0):\n        direction /= stretch\n        A = np.outer(direction, direction)\n        return -1.0 * stiffness * ((1 - (rest / stretch)) * (I - A) + A)\n\n    return -1.0 * stiffness * I\n\n@numba.njit\ndef spring_damping_jacobian(x0, x1, v0, v1, damping):\n    jacobian = np.zeros(shape=(2, 2))\n    direction = x1 - x0\n    stretch = math2D.norm(direction)\n    if not math2D.is_close(stretch, 0.0):\n        direction /= stretch\n        A = np.outer(direction, direction)\n        jacobian = -1.0 * damping * A\n\n    return jacobian\n\n@numba.njit\ndef spring_stretch_force(x0, x1, rest, stiffness):\n    direction = x1 - x0\n    stretch = math2D.norm(direction)\n    if not math2D.is_close(stretch, 0.0):\n        direction /= stretch\n    return direction * ((stretch - rest) * stiffness)\n\n@numba.njit\ndef spring_damping_force(x0, x1, v0, v1, damping):\n    direction = x1 - x0\n    stretch = math2D.norm(direction)\n    if not math2D.is_close(stretch, 0.0):\n        direction /= stretch\n    relativeVelocity = v1 - v0\n    return direction * (np.dot(relativeVelocity, direction) * damping)\n\n@numba.njit\ndef elastic_spring_energy(x0, x1, rest, stiffness):\n    stretch = math2D.distance(x0, x1)\n    return 0.5 * stiffness * ((stretch - rest)**2)\n'"
