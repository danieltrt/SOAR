file_path,api_count,code
demo.py,0,"b'#| # anesthetic plot gallery\n#| This functions as both some examples of plots that can be produced, and a tutorial.\n#| Any difficulties/issues/requests should be posted as a [GitHub issue](https://github.com/williamjameshandley/anesthetic/issues)\n\n#--------------------------\n\n#| ## Download example data\n#| Download some example data from github (or alternatively use your own chains files)\n#|\n#| This downloads the PLA chains for the planck baseline cosmology,\n#| and the equivalent nested sampling chains:\n\nimport requests\nimport tarfile\n\nfor filename in [""plikHM_TTTEEE_lowl_lowE_lensing.tar.gz"",""plikHM_TTTEEE_lowl_lowE_lensing_NS.tar.gz""]:\n    github_url = ""https://github.com/williamjameshandley/cosmo_example/raw/master/""\n    url = github_url + filename\n    open(filename, \'wb\').write(requests.get(url).content)\n    tarfile.open(filename).extractall()\n\n\n#| ## Marginalised posterior plotting\n#| Import anesthetic and load the MCMC samples:\n\n%matplotlib notebook\nfrom anesthetic import MCMCSamples\nmcmc_root = \'plikHM_TTTEEE_lowl_lowE_lensing/base_plikHM_TTTEEE_lowl_lowE_lensing\'\nmcmc = MCMCSamples(root=mcmc_root)\n\n#| We have plotting tools for 1D plots ...\n\nfig, axes = mcmc.plot_1d(\'omegabh2\') ;\n\n#| ... multiple 1D plots ...\n\nfig, axes = mcmc.plot_1d([\'omegabh2\',\'omegach2\',\'H0\',\'tau\',\'logA\',\'ns\']);\nfig.tight_layout()\n\n#| ... triangle plots ...\n\nmcmc.plot_2d([\'omegabh2\',\'omegach2\',\'H0\'], types={\'lower\':\'kde\',\'diagonal\':\'kde\'});\n\n#| ... triangle plots (with the equivalent scatter plot filling up the left hand side) ...\n\nmcmc.plot_2d([\'omegabh2\',\'omegach2\',\'H0\']);\n\n#| ... and rectangle plots.\n\nmcmc.plot_2d([[\'omegabh2\',\'omegach2\',\'H0\'], [\'logA\', \'ns\']]);\n\n#| Rectangle plots are pretty flexible with what they can do:\n\nmcmc.plot_2d([[\'omegabh2\',\'omegach2\',\'H0\'], [\'H0\',\'omegach2\']]);\n\n#| ## Defining new parameters\n#|\n#| You can see that samples are stored as a pandas array\n\nmcmc[:6]\n\n#| Since it\'s a (weighted) pandas array, we compute things like the mean and variance \n#| of samples\n\nmcmc.mean()\n\n#| We can define new parameters with relative ease.\n#| For example, the default cosmoMC setup does not include omegab, only omegabh2:\n\n\'omegab\' in mcmc\n\n#| However, this is pretty trivial to recompute:\n\nh = mcmc[\'H0\']/100\nmcmc[\'omegab\'] = mcmc[\'omegabh2\']/h**2\nmcmc.tex[\'omegab\'] = \'$\\Omega_b$\'\nmcmc.plot_1d(\'omegab\');\n\n#| ## Nested sampling plotting\n#| Anethestic really comes to the fore for nested sampling. We can do all of\n#| the above, and more with the power that NS chains provide\n\nfrom anesthetic import NestedSamples\nnested_root = \'plikHM_TTTEEE_lowl_lowE_lensing_NS/NS_plikHM_TTTEEE_lowl_lowE_lensing\'\nnested = NestedSamples(root=nested_root)\n\n#| We can infer the evidence, KL divergence and Bayesian model dimensionality:\n\nns_output = nested.ns_output()\n\n#| This is a set of ``MCMCSamples``, with columns yielding the log of the Bayesian evidence \n#| (logZ), the Kullback-Leibler divergence (D) and the Bayesian model dimensionality (d).\n\nns_output[:6]\n\n#| The evidence, KL divergence and Bayesian model dimensionality, with their corresponding errors, are:\n\nfor x in ns_output:\n    print(\'%10s = %9.2f +/- %4.2f\' % (x, ns_output[x].mean(), ns_output[x].std()))\n\n#| Since ``ns_output`` is a set of ``MCMCSamples``, it may be plotted as usual. \n#| Here we illustrate slightly more fine-grained control of the axes construction \n#| (demanding three columns)\n\nfrom anesthetic import make_1d_axes\nfig, axes = make_1d_axes([\'logZ\', \'D\', \'d\'], ncols=3, tex=ns_output.tex)\nns_output.plot_1d(axes);\n\n#| We can also inspect the correlation between these inferences:\n\nns_output.plot_2d([\'logZ\',\'D\']);\n\n#| Here is a comparison of the base and NS output\n\nh = nested[\'H0\']/100\nnested[\'omegab\'] = nested[\'omegabh2\']/h**2\nnested.tex[\'omegab\'] = \'$\\Omega_b$\'\n\nfig, axes = mcmc.plot_2d([\'sigma8\',\'omegab\'])\nnested.plot_2d(axes=axes);\n\n#| With nested samples, we can plot the prior (or any temperature), by\n#| passing beta=0. We also introduce here the helper function ``get_legend_proxy``\n#| for creating figure legends.\n\nprior = nested.set_beta(0)\nfig, axes = prior.plot_2d([\'ns\',\'tau\'], label=\'prior\')\nnested.plot_2d(axes=axes, label=\'posterior\')\nhandles, labels = axes[\'ns\'][\'tau\'].get_legend_handles_labels()\nleg = fig.legend(handles, labels)\nfig.tight_layout()\n\n#| We can also set up an interactive plot, which allows us to replay a nested\n#| sampling run after the fact.\n\nnested.gui()\n'"
setup.py,0,"b""#!/usr/bin/env python3\nfrom setuptools import setup, find_packages\n\n\ndef readme(short=False):\n    with open('README.rst') as f:\n        if short:\n            return f.readlines()[1].strip()\n        else:\n            return f.read()\n\n\ndef get_version(short=False):\n    with open('README.rst') as f:\n        for line in f:\n            if ':Version:' in line:\n                ver = line.split(':')[2].strip()\n                if short:\n                    subver = ver.split('.')\n                    return '%s.%s' % tuple(subver[:2])\n                else:\n                    return ver\n\n\nsetup(name='anesthetic',\n      version=get_version(),\n      description=readme(short=True),\n      long_description=readme(),\n      author='Will Handley',\n      author_email='wh260@cam.ac.uk',\n      url='https://github.com/williamjameshandley/anesthetic',\n      packages=find_packages(),\n      scripts=['scripts/anesthetic'],\n      install_requires=['numpy', 'scipy', 'pandas', 'matplotlib'],\n      setup_requires=['pytest-runner'],\n      extras_require={\n          'docs': ['sphinx', 'sphinx_rtd_theme', 'numpydoc'],\n          'automated bins calculation': ['astropy'],\n          'fast kernel density estimation': ['fastkde'],\n          },\n      tests_require=['pytest'],\n      include_package_data=True,\n      license='MIT',\n      classifiers=[\n                   'Development Status :: 5 - Production/Stable',\n                   'Intended Audience :: Developers',\n                   'Intended Audience :: Science/Research',\n                   'Natural Language :: English',\n                   'License :: OSI Approved :: MIT License',\n                   'Programming Language :: Python :: 3.6',\n                   'Programming Language :: Python :: 3.7',\n                   'Programming Language :: Python :: 3.8',\n                   'Topic :: Scientific/Engineering',\n                   'Topic :: Scientific/Engineering :: Astronomy',\n                   'Topic :: Scientific/Engineering :: Physics',\n                   'Topic :: Scientific/Engineering :: Visualization',\n                   'Topic :: Scientific/Engineering :: Information Analysis',\n                   'Topic :: Scientific/Engineering :: Mathematics',\n      ],\n      )\n"""
anesthetic/__init__.py,0,"b'""""""Anesthetic: nested sampling post-processing.\n\nKey routines:\n\n- ``MCMCSamples.build``\n- ``MCMCSamples.read``\n- ``NestedSamples.build``\n- ``NestedSamples.read``\n\n""""""\nimport anesthetic.samples\nimport anesthetic.plot\n\n\nMCMCSamples = anesthetic.samples.MCMCSamples\nNestedSamples = anesthetic.samples.NestedSamples\nmake_2d_axes = anesthetic.plot.make_2d_axes\nmake_1d_axes = anesthetic.plot.make_1d_axes\nget_legend_proxy = anesthetic.plot.get_legend_proxy\n'"
anesthetic/boundary.py,8,"b'""""""Boundary correction utilities.""""""\n\nimport numpy as np\nfrom scipy.special import erf\n\n\ndef cut_and_normalise_gaussian(x, p, sigma, xmin=None, xmax=None):\n    """"""Cut and normalise boundary correction for a Gaussian kernel.\n\n    Parameters\n    ----------\n    x: np.array\n        locations for normalisation correction\n\n    p: np.array\n        probability densities for normalisation correction\n\n    sigma: float\n        bandwidth of KDE\n\n    xmin, xmax: float\n        lower/upper prior bound\n        optional, default None\n\n    Returns\n    -------\n    p: np.array\n        corrected probabilities\n\n    """"""\n    correction = np.ones_like(x)\n\n    if xmin is not None:\n        correction *= 0.5*(1 + erf((x - xmin)/sigma/np.sqrt(2)))\n        correction[x < xmin] = np.inf\n    if xmax is not None:\n        correction *= 0.5*(1 + erf((xmax - x)/sigma/np.sqrt(2)))\n        correction[x > xmax] = np.inf\n    return p/correction\n'"
anesthetic/kde.py,6,"b'""""""Kernel density estimation tools.\n\nThese act as a wrapper around fastKDE, but could be replaced in future by\nalternative kernel density estimators\n""""""\nimport warnings\nfrom fastkde import fastKDE\nfrom anesthetic.utils import check_bounds, mirror_1d, mirror_2d\n\n\ndef fastkde_1d(d, xmin=None, xmax=None):\n    """"""Perform a one-dimensional kernel density estimation.\n\n    Wrapper round fastkde.fastKDE. Boundary corrections implemented by\n    reflecting boundary conditions.\n\n    Parameters\n    ----------\n    d: np.array\n        Data to perform kde on\n\n    xmin, xmax: float\n        lower/upper prior bounds\n        optional, default None\n\n    Returns\n    -------\n    x: np.array\n        x-coordinates of kernel density estimates\n    p: np.array\n        kernel density estimates\n\n    """"""\n    xmin, xmax = check_bounds(d, xmin, xmax)\n    f = xmax is None or xmin is None\n    d_ = mirror_1d(d, xmin, xmax)\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        p, x = fastKDE.pdf(d_, axisExpansionFactor=f,\n                           numPointsPerSigma=10*(2-f))\n    p *= 2-f\n\n    if xmin is not None:\n        p = p[x >= xmin]\n        x = x[x >= xmin]\n\n    if xmax is not None:\n        p = p[x <= xmax]\n        x = x[x <= xmax]\n\n    return x, p\n\n\ndef fastkde_2d(d_x, d_y, xmin=None, xmax=None, ymin=None, ymax=None):\n    """"""Perform a two-dimensional kernel density estimation.\n\n    Wrapper round fastkde.fastKDE. Boundary corrections implemented by\n    reflecting boundary conditions.\n\n    Parameters\n    ----------\n    d_x, d_y: np.array\n        x/y coordinates of data to perform kde on\n\n    xmin, xmax, ymin, ymax: float\n        lower/upper prior bounds in x/y coordinates\n        optional, default None\n\n    Returns\n    -------\n    x,y: np.array\n        x/y-coordinates of kernel density estimates. One-dimensional array\n    p: np.array\n        kernel density estimates. Two-dimensional array\n\n    """"""\n    xmin, xmax = check_bounds(d_x, xmin, xmax)\n    ymin, ymax = check_bounds(d_y, ymin, ymax)\n    f = [xmax is None or xmin is None,\n         ymax is None or ymin is None]\n    d_x_, d_y_ = mirror_2d(d_x, d_y, xmin, xmax, ymin, ymax)\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        p, (x, y) = fastKDE.pdf(d_x_, d_y_, axisExpansionFactor=f,\n                                numPointsPerSigma=10*(2-f[0])*(2-f[1]))\n\n    p *= (2-f[0])\n    p *= (2-f[1])\n    if xmin is not None:\n        p = p[:, x >= xmin]\n        x = x[x >= xmin]\n\n    if xmax is not None:\n        p = p[:, x <= xmax]\n        x = x[x <= xmax]\n\n    if ymin is not None:\n        p = p[y >= ymin, :]\n        y = y[y >= ymin]\n\n    if ymax is not None:\n        p = p[y <= ymax, :]\n        y = y[y <= ymax]\n\n    return x, y, p\n'"
anesthetic/plot.py,42,"b'""""""Lower-level plotting tools.\n\nRoutines that may be of use to users wishing for more fine-grained control may\nwish to use.\n\n- ``make_1d_axes``\n- ``make_2d_axes``\n- ``get_legend_proxy``\n\nto create a set of axes and legend proxies.\n\n""""""\nimport sys\nimport numpy as np\nimport pandas\nimport matplotlib.pyplot as plt\nfrom scipy.stats import gaussian_kde\nfrom matplotlib.gridspec import GridSpec as GS, GridSpecFromSubplotSpec as SGS\ntry:\n    from astropy.visualization import hist\nexcept ImportError:\n    pass\ntry:\n    from anesthetic.kde import fastkde_1d, fastkde_2d\nexcept ImportError:\n    pass\nimport matplotlib.cbook as cbook\nimport matplotlib.lines as mlines\nfrom matplotlib.ticker import MaxNLocator\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom matplotlib.collections import LineCollection\nfrom matplotlib.transforms import Affine2D\nfrom anesthetic.utils import check_bounds, nest_level, unique\nfrom anesthetic.utils import (sample_compression_1d, quantile,\n                              triangular_sample_compression_2d,\n                              iso_probability_contours,\n                              iso_probability_contours_from_samples,\n                              scaled_triangulation)\nfrom anesthetic.boundary import cut_and_normalise_gaussian\n\n\ndef make_1d_axes(params, **kwargs):\n    """"""Create a set of axes for plotting 1D marginalised posteriors.\n\n    Parameters\n    ----------\n        params: list(str)\n            names of parameters.\n\n        tex: dict(str:str), optional\n            Dictionary mapping params to tex plot labels.\n\n        fig: matplotlib.figure.Figure, optional\n            Figure to plot on.\n            Default: matplotlib.pyplot.figure()\n\n        ncols: int\n            Number of columns in the plot\n            option, default ceil(sqrt(num_params))\n\n        subplot_spec: matplotlib.gridspec.GridSpec, optional\n            gridspec to plot array as part of a subfigure\n            Default: None\n\n    Returns\n    -------\n    fig: matplotlib.figure.Figure\n        New or original (if supplied) figure object\n\n    axes: pandas.Series(matplotlib.axes.Axes)\n        Pandas array of axes objects\n\n    """"""\n    axes = pandas.Series(index=np.atleast_1d(params), dtype=object)\n    axes[:] = None\n    tex = kwargs.pop(\'tex\', {})\n    fig = kwargs.pop(\'fig\') if \'fig\' in kwargs else plt.figure()\n    ncols = kwargs.pop(\'ncols\', int(np.ceil(np.sqrt(len(axes)))))\n    nrows = int(np.ceil(len(axes)/float(ncols)))\n    if \'subplot_spec\' in kwargs:\n        grid = SGS(nrows, ncols, wspace=0,\n                   subplot_spec=kwargs.pop(\'subplot_spec\'))\n    else:\n        grid = GS(nrows, ncols, wspace=0)\n\n    if kwargs:\n        raise TypeError(\'Unexpected **kwargs: %r\' % kwargs)\n\n    tex = {p: tex[p] if p in tex else p for p in axes.index}\n\n    for p, g in zip(axes.index, grid):\n        axes[p] = ax = fig.add_subplot(g)\n        ax.set_xlabel(tex[p])\n        ax.set_yticks([])\n\n    for x, ax in axes.dropna().iteritems():\n        ax.xaxis.set_major_locator(MaxNLocator(2, integer=True))\n\n    return fig, axes\n\n\ndef make_2d_axes(params, **kwargs):\n    """"""Create a set of axes for plotting 2D marginalised posteriors.\n\n    Parameters\n    ----------\n        params: lists of parameters\n            Can be either:\n            * list(str) if the x and y axes are the same\n            * [list(str),list(str)] if the x and y axes are different\n            Strings indicate the names of the parameters\n\n        tex: dict(str:str), optional\n            Dictionary mapping params to tex plot labels.\n            Default: params\n\n        upper, lower, diagonal: logical, optional\n            Whether to create 2D marginalised plots above or below the\n            diagonal, or to create a 1D marginalised plot on the diagonal.\n            Default: True\n\n        fig: matplotlib.figure.Figure, optional\n            Figure to plot on.\n            Default: matplotlib.pyplot.figure()\n\n        subplot_spec: matplotlib.gridspec.GridSpec, optional\n            gridspec to plot array as part of a subfigure.\n            Default: None\n\n    Returns\n    -------\n    fig: matplotlib.figure.Figure\n        New or original (if supplied) figure object\n\n    axes: pandas.DataFrame(matplotlib.axes.Axes)\n        Pandas array of axes objects\n\n    """"""\n    if nest_level(params) == 2:\n        xparams, yparams = params\n    else:\n        xparams = yparams = params\n\n    upper = kwargs.pop(\'upper\', True)\n    lower = kwargs.pop(\'lower\', True)\n    diagonal = kwargs.pop(\'diagonal\', True)\n\n    axes = pandas.DataFrame(index=np.atleast_1d(yparams),\n                            columns=np.atleast_1d(xparams),\n                            dtype=object)\n    axes[:][:] = None\n    all_params = list(axes.columns) + list(axes.index)\n\n    for j, y in enumerate(axes.index):\n        for i, x in enumerate(axes.columns):\n            if all_params.index(x) < all_params.index(y):\n                if lower:\n                    axes[x][y] = -1\n            elif all_params.index(x) > all_params.index(y):\n                if upper:\n                    axes[x][y] = +1\n            elif diagonal:\n                axes[x][y] = 0\n\n    axes.dropna(axis=0, how=\'all\', inplace=True)\n    axes.dropna(axis=1, how=\'all\', inplace=True)\n\n    tex = kwargs.pop(\'tex\', {})\n    tex = {p: tex[p] if p in tex else p for p in all_params}\n    fig = kwargs.pop(\'fig\') if \'fig\' in kwargs else plt.figure()\n    if \'subplot_spec\' in kwargs:\n        grid = SGS(*axes.shape, hspace=0, wspace=0,\n                   subplot_spec=kwargs.pop(\'subplot_spec\'))\n    else:\n        grid = GS(*axes.shape, hspace=0, wspace=0)\n\n    if kwargs:\n        raise TypeError(\'Unexpected **kwargs: %r\' % kwargs)\n\n    if axes.size == 0:\n        return fig, axes\n    position = axes.copy()\n    axes[:][:] = None\n    for j, y in enumerate(axes.index):\n        for i, x in enumerate(axes.columns):\n            if position[x][y] is not None:\n                sx = list(axes[x].dropna())\n                sx = sx[0] if sx else None\n                sy = list(axes.T[y].dropna())\n                sy = sy[0] if sy else None\n                axes[x][y] = fig.add_subplot(grid[j, i],\n                                             sharex=sx, sharey=sy)\n\n                if position[x][y] == 0:\n                    axes[x][y].twin = axes[x][y].twinx()\n                    axes[x][y].twin.set_yticks([])\n                    axes[x][y].twin.set_ylim(0, 1.1)\n                    axes[x][y].set_zorder(axes[x][y].twin.get_zorder() + 1)\n                    axes[x][y].lines = axes[x][y].twin.lines\n                    axes[x][y].patches = axes[x][y].twin.patches\n                    axes[x][y].collections = axes[x][y].twin.collections\n                    axes[x][y].containers = axes[x][y].twin.containers\n                    make_diagonal(axes[x][y])\n                    axes[x][y].position = \'diagonal\'\n                elif position[x][y] == 1:\n                    axes[x][y].position = \'upper\'\n                elif position[x][y] == -1:\n                    axes[x][y].position = \'lower\'\n\n    for y, ax in axes.bfill(axis=1).iloc[:, 0].dropna().iteritems():\n        ax.set_ylabel(tex[y])\n\n    for x, ax in axes.ffill(axis=0).iloc[-1, :].dropna().iteritems():\n        ax.set_xlabel(tex[x])\n\n    for y, ax in axes.iterrows():\n        ax_ = ax.dropna()\n        if len(ax_):\n            for a in ax_[1:]:\n                a.tick_params(\'y\', left=False, labelleft=False)\n\n    for x, ax in axes.iteritems():\n        ax_ = ax.dropna()\n        if len(ax_):\n            for a in ax_[:-1]:\n                a.tick_params(\'x\', bottom=False, labelbottom=False)\n\n    for y, ax in axes.bfill(axis=1).iloc[:, 0].dropna().iteritems():\n        ax.yaxis.set_major_locator(MaxNLocator(3, prune=\'both\'))\n\n    for x, ax in axes.ffill(axis=0).iloc[-1, :].dropna().iteritems():\n        ax.xaxis.set_major_locator(MaxNLocator(3, prune=\'both\'))\n\n    return fig, axes\n\n\ndef fastkde_plot_1d(ax, data, *args, **kwargs):\n    """"""Plot a 1d marginalised distribution.\n\n    This functions as a wrapper around matplotlib.axes.Axes.plot, with a kernel\n    density estimation computation provided by the package fastkde in between.\n    All remaining keyword arguments are passed onwards.\n\n    Parameters\n    ----------\n    ax: matplotlib.axes.Axes\n        axis object to plot on\n\n    data: np.array\n        Uniformly weighted samples to generate kernel density estimator.\n\n    xmin, xmax: float\n        lower/upper prior bound\n        optional, default None\n\n    Returns\n    -------\n    lines: matplotlib.lines.Line2D\n        A list of line objects representing the plotted data (same as\n        matplotlib matplotlib.axes.Axes.plot command)\n\n    """"""\n    if len(data) == 0:\n        return np.zeros(0), np.zeros(0)\n\n    if data.max()-data.min() <= 0:\n        return\n\n    xmin = kwargs.pop(\'xmin\', None)\n    xmax = kwargs.pop(\'xmax\', None)\n\n    try:\n        x, p = fastkde_1d(data, xmin, xmax)\n    except NameError:\n        raise ImportError(""You need to install fastkde to use fastkde"")\n    p /= p.max()\n    i = (x < quantile(x, 0.99, p)) & (x > quantile(x, 0.01, p)) | (p > 0.1)\n\n    ans = ax.plot(x[i], p[i], *args, **kwargs)\n    ax.set_xlim(*check_bounds(x[i], xmin, xmax), auto=True)\n    return ans\n\n\ndef kde_plot_1d(ax, data, *args, **kwargs):\n    """"""Plot a 1d marginalised distribution.\n\n    This functions as a wrapper around matplotlib.axes.Axes.plot, with a kernel\n    density estimation computation provided by scipy.stats.gaussian_kde in\n    between. All remaining keyword arguments are passed onwards.\n\n    Parameters\n    ----------\n    ax: matplotlib.axes.Axes\n        axis object to plot on.\n\n    data: np.array\n        Samples to generate kernel density estimator.\n\n    weights: np.array, optional\n        Sample weights.\n\n    ncompress: int, optional\n        Degree of compression. Default 1000\n\n    xmin, xmax: float\n        lower/upper prior bound.\n        optional, default None\n\n    Returns\n    -------\n    lines: matplotlib.lines.Line2D\n        A list of line objects representing the plotted data (same as\n        matplotlib matplotlib.axes.Axes.plot command)\n\n    """"""\n    if len(data) == 0:\n        return np.zeros(0), np.zeros(0)\n\n    if data.max()-data.min() <= 0:\n        return\n\n    xmin = kwargs.pop(\'xmin\', None)\n    xmax = kwargs.pop(\'xmax\', None)\n    weights = kwargs.pop(\'weights\', None)\n    ncompress = kwargs.pop(\'ncompress\', 1000)\n    x, w = sample_compression_1d(data, weights, ncompress)\n    kde = gaussian_kde(x, weights=w)\n    p = kde(x)\n    p /= p.max()\n    i = ((x < quantile(x, 0.999, w)) & (x > quantile(x, 0.001, w))) | (p > 0.1)\n    if xmin is not None:\n        i = i & (x > xmin)\n    if xmax is not None:\n        i = i & (x < xmax)\n    sigma = np.sqrt(kde.covariance[0, 0])\n    pp = cut_and_normalise_gaussian(x[i], p[i], sigma, xmin, xmax)\n    pp /= pp.max()\n    ans = ax.plot(x[i], pp, *args, **kwargs)\n    ax.set_xlim(*check_bounds(x[i], xmin, xmax), auto=True)\n    return ans\n\n\ndef hist_plot_1d(ax, data, *args, **kwargs):\n    """"""Plot a 1d histogram.\n\n    This functions is a wrapper around matplotlib.axes.Axes.hist. All remaining\n    keyword arguments are passed onwards.\n\n    Parameters\n    ----------\n    ax: matplotlib.axes.Axes\n        axis object to plot on\n\n    data: np.array\n        Samples to generate histogram from\n\n    weights: np.array, optional\n        Sample weights.\n\n    xmin, xmax: float\n        lower/upper prior bound.\n        optional, default data.min() and data.max()\n        cannot be None (reverts to default in that case)\n\n    Returns\n    -------\n    patches : list or list of lists\n        Silent list of individual patches used to create the histogram\n        or list of such list if multiple input datasets.\n\n    Other Parameters\n    ----------------\n    **kwargs : `~matplotlib.axes.Axes.hist` properties\n\n    """"""\n    if data.max()-data.min() <= 0:\n        return\n\n    xmin = kwargs.pop(\'xmin\', None)\n    xmax = kwargs.pop(\'xmax\', None)\n    plotter = kwargs.pop(\'plotter\', \'\')\n    weights = kwargs.pop(\'weights\', None)\n    if xmin is None or not np.isfinite(xmin):\n        xmin = quantile(data, 0.01, weights)\n    if xmax is None or not np.isfinite(xmax):\n        xmax = quantile(data, 0.99, weights)\n    range = kwargs.pop(\'range\', (xmin, xmax))\n    histtype = kwargs.pop(\'histtype\', \'bar\')\n\n    if plotter == \'astropyhist\':\n        try:\n            h, edges, bars = hist(data, ax=ax, range=range,\n                                  histtype=histtype, *args, **kwargs)\n        except NameError:\n            raise ImportError(""You need to install astropy to use astropyhist"")\n    else:\n        h, edges, bars = ax.hist(data, range=range, histtype=histtype,\n                                 weights=weights, *args, **kwargs)\n\n    if histtype == \'bar\':\n        for b in bars:\n            b.set_height(b.get_height() / h.max())\n    elif histtype == \'step\' or histtype == \'stepfilled\':\n        trans = Affine2D().scale(sx=1, sy=1./h.max()) + ax.transData\n        bars[0].set_transform(trans)\n\n    ax.set_xlim(*check_bounds(edges, xmin, xmax), auto=True)\n    ax.set_ylim(0, 1.1)\n    return bars\n\n\ndef fastkde_contour_plot_2d(ax, data_x, data_y, *args, **kwargs):\n    """"""Plot a 2d marginalised distribution as contours.\n\n    This functions as a wrapper around matplotlib.axes.Axes.contour, and\n    matplotlib.axes.Axes.contourf with a kernel density estimation computation\n    in between. All remaining keyword arguments are passed onwards to both\n    functions.\n\n    Parameters\n    ----------\n    ax: matplotlib.axes.Axes\n        axis object to plot on\n\n    data_x, data_y: np.array\n        x and y coordinates of uniformly weighted samples to generate kernel\n        density estimator.\n\n    levels: list\n        amount of mass within each iso-probability contour.\n        optional, default [0.68, 0.95]\n\n    xmin, xmax, ymin, ymax: float\n        lower/upper prior bounds in x/y coordinates\n        optional, default None\n\n    Returns\n    -------\n    c: matplotlib.contour.QuadContourSet\n        A set of contourlines or filled regions\n\n    """"""\n    xmin = kwargs.pop(\'xmin\', None)\n    xmax = kwargs.pop(\'xmax\', None)\n    ymin = kwargs.pop(\'ymin\', None)\n    ymax = kwargs.pop(\'ymax\', None)\n    label = kwargs.pop(\'label\', None)\n    zorder = kwargs.pop(\'zorder\', 1)\n    linewidths = kwargs.pop(\'linewidths\', 0.5)\n    levels = kwargs.pop(\'levels\', [0.68, 0.95])\n    color = kwargs.pop(\'color\', next(ax._get_lines.prop_cycler)[\'color\'])\n\n    if len(data_x) == 0 or len(data_y) == 0:\n        return np.zeros(0), np.zeros(0), np.zeros((0, 0))\n\n    try:\n        x, y, pdf = fastkde_2d(data_x, data_y,\n                               xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax)\n    except NameError:\n        raise ImportError(""You need to install fastkde to use fastkde"")\n\n    levels = iso_probability_contours(pdf, contours=levels)\n    cmap = kwargs.pop(\'cmap\', basic_cmap(color))\n\n    i = (pdf >= levels[0]*0.5).any(axis=0)\n    j = (pdf >= levels[0]*0.5).any(axis=1)\n\n    cbar = ax.contourf(x[i], y[j], pdf[np.ix_(j, i)], levels, cmap=cmap,\n                       zorder=zorder, vmin=0, vmax=pdf.max(), *args, **kwargs)\n    for c in cbar.collections:\n        c.set_cmap(cmap)\n\n    ax.contour(x[i], y[j], pdf[np.ix_(j, i)], levels, zorder=zorder,\n               vmin=0, vmax=pdf.max(), linewidths=linewidths, colors=\'k\',\n               *args, **kwargs)\n    ax.patches += [plt.Rectangle((0, 0), 1, 1, fc=cmap(0.999), ec=cmap(0.32),\n                                 lw=2, label=label)]\n\n    ax.set_xlim(*check_bounds(x[i], xmin, xmax), auto=True)\n    ax.set_ylim(*check_bounds(y[j], ymin, ymax), auto=True)\n    return cbar\n\n\ndef kde_contour_plot_2d(ax, data_x, data_y, *args, **kwargs):\n    """"""Plot a 2d marginalised distribution as contours.\n\n    This functions as a wrapper around matplotlib.axes.Axes.tricontour, and\n    matplotlib.axes.Axes.tricontourf with a kernel density estimation\n    computation provided by scipy.stats.gaussian_kde in between. All remaining\n    keyword arguments are passed onwards to both functions.\n\n    Parameters\n    ----------\n    ax: matplotlib.axes.Axes\n        axis object to plot on.\n\n    data_x, data_y: np.array\n        x and y coordinates of uniformly weighted samples to generate kernel\n        density estimator.\n\n    weights: np.array, optional\n        Sample weights.\n\n    ncompress: int, optional\n        Degree of compression.\n        optional, Default 1000\n\n    xmin, xmax, ymin, ymax: float\n        lower/upper prior bounds in x/y coordinates.\n        optional, default None\n\n    Returns\n    -------\n    c: matplotlib.contour.QuadContourSet\n        A set of contourlines or filled regions\n\n    """"""\n    xmin = kwargs.pop(\'xmin\', None)\n    xmax = kwargs.pop(\'xmax\', None)\n    ymin = kwargs.pop(\'ymin\', None)\n    ymax = kwargs.pop(\'ymax\', None)\n    weights = kwargs.pop(\'weights\', None)\n    ncompress = kwargs.pop(\'ncompress\', 1000)\n    label = kwargs.pop(\'label\', None)\n    zorder = kwargs.pop(\'zorder\', 1)\n    linewidths = kwargs.pop(\'linewidths\', 0.5)\n    color = kwargs.pop(\'color\', next(ax._get_lines.prop_cycler)[\'color\'])\n\n    if len(data_x) == 0 or len(data_y) == 0:\n        return np.zeros(0), np.zeros(0), np.zeros((0, 0))\n\n    cov = np.cov(data_x, data_y, aweights=weights)\n    tri, w = triangular_sample_compression_2d(data_x, data_y, cov,\n                                              weights, ncompress)\n    kde = gaussian_kde([tri.x, tri.y], weights=w)\n\n    x, y = kde.resample(ncompress)\n    x = np.concatenate([tri.x, x])\n    y = np.concatenate([tri.y, y])\n    w = np.concatenate([w, np.zeros(ncompress)])\n    tri = scaled_triangulation(x, y, cov)\n\n    p = kde([tri.x, tri.y])\n\n    sigmax = np.sqrt(kde.covariance[0, 0])\n    p = cut_and_normalise_gaussian(tri.x, p, sigmax, xmin, xmax)\n    sigmay = np.sqrt(kde.covariance[1, 1])\n    p = cut_and_normalise_gaussian(tri.y, p, sigmay, ymin, ymax)\n\n    contours = iso_probability_contours_from_samples(p, weights=w)\n\n    cmap = kwargs.pop(\'cmap\', basic_cmap(color))\n\n    cbar = ax.tricontourf(tri, p, contours, cmap=cmap,\n                          zorder=zorder, vmin=0, vmax=p.max(), *args, **kwargs)\n    for c in cbar.collections:\n        c.set_cmap(cmap)\n\n    ax.tricontour(tri, p, contours, zorder=zorder,\n                  vmin=0, vmax=p.max(), linewidths=linewidths, colors=\'k\',\n                  *args, **kwargs)\n    ax.patches += [plt.Rectangle((0, 0), 1, 1, fc=cmap(0.999), ec=cmap(0.32),\n                                 lw=2, label=label)]\n\n    ax.set_xlim(*check_bounds(tri.x, xmin, xmax), auto=True)\n    ax.set_ylim(*check_bounds(tri.y, ymin, ymax), auto=True)\n    return cbar\n\n\ndef hist_plot_2d(ax, data_x, data_y, *args, **kwargs):\n    """"""Plot a 2d marginalised distribution as a histogram.\n\n    This functions as a wrapper around matplotlib.axes.Axes.hist2d\n\n    Parameters\n    ----------\n    ax: matplotlib.axes.Axes\n        axis object to plot on\n\n    data_x, data_y: np.array\n        x and y coordinates of uniformly weighted samples to generate kernel\n        density estimator.\n\n    xmin, xmax, ymin, ymax: float\n        lower/upper prior bounds in x/y coordinates\n        optional, default None\n\n    levels: list\n        Shade iso-probability contours containing these levels of probability\n        mass. If None defaults to usual matplotlib.axes.Axes.hist2d colouring.\n        optional, default None\n\n    Returns\n    -------\n    c: matplotlib.collections.QuadMesh\n        A set of colors\n\n    """"""\n    xmin = kwargs.pop(\'xmin\', None)\n    xmax = kwargs.pop(\'xmax\', None)\n    ymin = kwargs.pop(\'ymin\', None)\n    ymax = kwargs.pop(\'ymax\', None)\n    label = kwargs.pop(\'label\', None)\n    levels = kwargs.pop(\'levels\', None)\n    color = kwargs.pop(\'color\', next(ax._get_lines.prop_cycler)[\'color\'])\n    weights = kwargs.pop(\'weights\', None)\n\n    if xmin is None or not np.isfinite(xmin):\n        xmin = quantile(data_x, 0.01, weights)\n    if xmax is None or not np.isfinite(xmax):\n        xmax = quantile(data_x, 0.99, weights)\n    if ymin is None or not np.isfinite(ymin):\n        ymin = quantile(data_y, 0.01, weights)\n    if ymax is None or not np.isfinite(ymax):\n        ymax = quantile(data_y, 0.99, weights)\n\n    range = kwargs.pop(\'range\', ((xmin, xmax), (ymin, ymax)))\n\n    if len(data_x) == 0 or len(data_y) == 0:\n        return np.zeros(0), np.zeros(0), np.zeros((0, 0))\n\n    cmap = kwargs.pop(\'cmap\', basic_cmap(color))\n\n    if levels is None:\n        pdf, x, y, image = ax.hist2d(data_x, data_y, weights=weights,\n                                     cmap=cmap, range=range,\n                                     *args, **kwargs)\n    else:\n        bins = kwargs.pop(\'bins\', 10)\n        density = kwargs.pop(\'density\', False)\n        cmin = kwargs.pop(\'cmin\', None)\n        cmax = kwargs.pop(\'cmax\', None)\n        pdf, x, y = np.histogram2d(data_x, data_y, bins, range,\n                                   density, weights)\n        levels = iso_probability_contours(pdf, levels)\n        pdf = np.digitize(pdf, levels, right=True)\n        pdf = np.array(levels)[pdf]\n        pdf = np.ma.masked_array(pdf, pdf < levels[1])\n        if cmin is not None:\n            pdf[pdf < cmin] = np.ma.masked\n        if cmax is not None:\n            pdf[pdf > cmax] = np.ma.masked\n        image = ax.pcolormesh(x, y, pdf.T, cmap=cmap, vmin=0, vmax=pdf.max(),\n                              *args, **kwargs)\n\n    ax.patches += [plt.Rectangle((0, 0), 1, 1, fc=cmap(0.999), ec=cmap(0.32),\n                                 lw=2, label=label)]\n\n    ax.set_xlim(*check_bounds(x, xmin, xmax), auto=True)\n    ax.set_ylim(*check_bounds(y, ymin, ymax), auto=True)\n    return image\n\n\ndef scatter_plot_2d(ax, data_x, data_y, *args, **kwargs):\n    """"""Plot samples from a 2d marginalised distribution.\n\n    This functions as a wrapper around matplotlib.axes.Axes.plot, enforcing any\n    prior bounds. All remaining keyword arguments are passed onwards.\n\n    Parameters\n    ----------\n    ax: matplotlib.axes.Axes\n        axis object to plot on\n\n    data_x, data_y: np.array\n        x and y coordinates of uniformly weighted samples to plot.\n\n    xmin, xmax, ymin, ymax: float\n        lower/upper prior bounds in x/y coordinates\n        optional, default None\n\n    Returns\n    -------\n    lines: matplotlib.lines.Line2D\n        A list of line objects representing the plotted data (same as\n        matplotlib matplotlib.axes.Axes.plot command)\n\n    """"""\n    xmin = kwargs.pop(\'xmin\', None)\n    xmax = kwargs.pop(\'xmax\', None)\n    ymin = kwargs.pop(\'ymin\', None)\n    ymax = kwargs.pop(\'ymax\', None)\n    kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n    markersize = kwargs.pop(\'markersize\', 1)\n\n    points = ax.plot(data_x, data_y, \'o\', markersize=markersize,\n                     *args, **kwargs)\n    ax.set_xlim(*check_bounds(data_x, xmin, xmax), auto=True)\n    ax.set_ylim(*check_bounds(data_y, ymin, ymax), auto=True)\n    return points\n\n\ndef get_legend_proxy(fig):\n    """"""Extract a proxy for plotting onto a legend.\n\n    Example usage:\n        >>> fig, axes = modelA.plot_2d()\n        >>> modelB.plot_2d(axes)\n        >>> proxy = get_legend_proxy(fig)\n        >>> fig.legend(proxy, [\'A\', \'B\']\n\n    Parameters\n    ----------\n        fig: matplotlib.figure.Figure\n            Figure to extract colors from.\n\n    """"""\n    from warnings import warn\n    warn(""`get_legend_proxy` is deprecated and might be deleted in the ""\n         ""future. You can now simply use `axes[x][y].legend()` or do ""\n         ""`handles, labels = axes[x][y].get_legend_handles_labels()` ""\n         ""and pass the handles and labels to the figure legend ""\n         ""`fig.legend(handles, labels)`."", FutureWarning)\n    cmaps = [coll.get_cmap() for ax in fig.axes for coll in ax.collections\n             if isinstance(coll.get_cmap(), LinearSegmentedColormap)]\n    cmaps = unique(cmaps)\n\n    if not cmaps:\n        colors = [line.get_color() for ax in fig.axes for line in ax.lines]\n        colors = unique(colors)\n        cmaps = [basic_cmap(color) for color in colors]\n\n    proxy = [plt.Rectangle((0, 0), 1, 1, facecolor=cmap(0.999),\n                           edgecolor=cmap(0.32), linewidth=2)\n             for cmap in cmaps]\n\n    if not cmaps:\n        colors = [coll.get_ec()[0]\n                  for ax in fig.axes\n                  for coll in ax.collections\n                  if isinstance(coll, LineCollection)]\n        colors = np.unique(colors, axis=0)\n        cmaps = [basic_cmap(color) for color in colors]\n        proxy = [plt.Rectangle((0, 0), 1, 1, facecolor=cmap(0.0),\n                               edgecolor=cmap(0.999), linewidth=1)\n                 for cmap in cmaps]\n\n    return proxy\n\n\ndef basic_cmap(color):\n    """"""Construct basic colormap a single color.""""""\n    return LinearSegmentedColormap.from_list(color, [\'#ffffff\', color])\n\n\nif sys.version_info > (3, 0):\n    def make_diagonal(ax):\n        """"""Link x and y axes limits.""""""\n        class DiagonalAxes(type(ax)):\n            def set_xlim(self, left=None, right=None, emit=True, auto=False,\n                         xmin=None, xmax=None):\n                super(type(ax), self).set_ylim(bottom=left, top=right,\n                                               emit=True, auto=auto,\n                                               ymin=xmin, ymax=xmax)\n                return super(type(ax), self).set_xlim(left=left, right=right,\n                                                      emit=emit, auto=auto,\n                                                      xmin=xmin, xmax=xmax)\n\n            def set_ylim(self, bottom=None, top=None, emit=True, auto=False,\n                         ymin=None, ymax=None):\n                super(type(ax), self).set_xlim(left=bottom, right=top,\n                                               emit=True, auto=auto,\n                                               xmin=ymin, xmax=ymax)\n                return super(type(ax), self).set_ylim(bottom=bottom, top=top,\n                                                      emit=emit, auto=auto,\n                                                      ymin=ymin, ymax=ymax)\n        ax.__class__ = DiagonalAxes\nelse:\n    def make_diagonal(ax):\n        """"""Link x and y axes limits.""""""\n        class DiagonalAxes(type(ax)):\n            def set_xlim(self, left=None, right=None, emit=True, auto=False,\n                         **kwargs):\n                super(type(ax), self).set_ylim(bottom=left, top=right,\n                                               emit=True, auto=auto,\n                                               **kwargs)\n                return super(type(ax), self).set_xlim(left=left, right=right,\n                                                      emit=emit, auto=auto,\n                                                      **kwargs)\n\n            def set_ylim(self, bottom=None, top=None, emit=True, auto=False,\n                         **kwargs):\n                super(type(ax), self).set_xlim(left=bottom, right=top,\n                                               emit=True, auto=auto,\n                                               **kwargs)\n                return super(type(ax), self).set_ylim(bottom=bottom, top=top,\n                                                      emit=emit, auto=auto,\n                                                      **kwargs)\n        ax.__class__ = DiagonalAxes\n'"
anesthetic/samples.py,25,"b'""""""Main classes for the anesthetic module.\n\n- ``MCMCSamples``\n- ``NestedSamples``\n""""""\nimport os\nimport numpy as np\nimport pandas\nfrom anesthetic.plot import (make_1d_axes, make_2d_axes, fastkde_plot_1d,\n                             kde_plot_1d, hist_plot_1d, scatter_plot_2d,\n                             fastkde_contour_plot_2d,\n                             kde_contour_plot_2d, hist_plot_2d)\nfrom anesthetic.read.samplereader import SampleReader\nfrom anesthetic.utils import compute_nlive, is_int, logsumexp\nfrom anesthetic.gui.plot import RunPlotter\nfrom anesthetic.weighted_pandas import WeightedDataFrame, WeightedSeries\n\n\nclass MCMCSamples(WeightedDataFrame):\n    """"""Storage and plotting tools for MCMC samples.\n\n    Extends the pandas.DataFrame by providing plotting methods and\n    standardising sample storage.\n\n    Example plotting commands include\n        - ``mcmc.plot_1d([\'paramA\', \'paramB\'])``\n        - ``mcmc.plot_2d([\'paramA\', \'paramB\'])``\n        - ``mcmc.plot_2d([[\'paramA\', \'paramB\'], [\'paramC\', \'paramD\']])``\n\n    Parameters\n    ----------\n    root: str, optional\n        root for reading chains from file. Overrides all other arguments.\n\n    data: np.array\n        Coordinates of samples. shape = (nsamples, ndims).\n\n    columns: list(str)\n        reference names of parameters\n\n    w: np.array\n        weights of samples.\n\n    logL: np.array\n        loglikelihoods of samples.\n\n    tex: dict\n        mapping from columns to tex labels for plotting\n\n    limits: dict\n        mapping from columns to prior limits\n\n    label: str\n        Legend label\n\n    logzero: float\n        The threshold for `log(0)` values assigned to rejected sample points.\n        Anything equal or below this value is set to `-np.inf`.\n        default: -1e30\n\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        root = kwargs.pop(\'root\', None)\n        if root is not None:\n            reader = SampleReader(root)\n            if hasattr(reader, \'birth_file\') or hasattr(reader, \'ev_file\'):\n                raise ValueError(""The file root %s seems to point to a Nested ""\n                                 ""Sampling chain. Please use NestedSamples ""\n                                 ""instead which has the same features as ""\n                                 ""MCMCSamples and more. MCMCSamples should be ""\n                                 ""used for MCMC chains only."" % root)\n            w, logL, samples = reader.samples()\n            params, tex = reader.paramnames()\n            columns = kwargs.pop(\'columns\', params)\n            limits = reader.limits()\n            kwargs[\'label\'] = kwargs.get(\'label\', os.path.basename(root))\n            self.__init__(data=samples, columns=columns, w=w, logL=logL,\n                          tex=tex, limits=limits, *args, **kwargs)\n            self.root = root\n        else:\n            logzero = kwargs.pop(\'logzero\', -1e30)\n            logL = kwargs.pop(\'logL\', None)\n            if logL is not None:\n                logL = np.where(logL <= logzero, -np.inf, logL)\n            self.tex = kwargs.pop(\'tex\', {})\n            self.limits = kwargs.pop(\'limits\', {})\n            self.label = kwargs.pop(\'label\', None)\n            self.root = None\n            super(MCMCSamples, self).__init__(*args, **kwargs)\n\n            if logL is not None:\n                self[\'logL\'] = logL\n                self.tex[\'logL\'] = r\'$\\log\\mathcal{L}$\'\n\n            if self._weight is not None:\n                self[\'weight\'] = self.weight\n                self.tex[\'weight\'] = r\'MCMC weight\'\n\n            self._set_automatic_limits()\n\n    def _set_automatic_limits(self):\n        """"""Set all unassigned limits to min and max of sample.""""""\n        for param in self.columns:\n            if param not in self.limits:\n                self.limits[param] = (self[param].min(), self[param].max())\n\n    def plot(self, ax, paramname_x, paramname_y=None, *args, **kwargs):\n        """"""Interface for 2D and 1D plotting routines.\n\n        Produces a single 1D or 2D plot on an axis.\n\n        Parameters\n        ----------\n        ax: matplotlib.axes.Axes\n            Axes to plot on\n\n        paramname_x: str\n            Choice of parameter to plot on x-coordinate from self.columns.\n\n        paramname_y: str\n            Choice of parameter to plot on y-coordinate from self.columns.\n            optional, if not provided, or the same as paramname_x, then 1D plot\n            produced.\n\n        plot_type: str\n            Must be in {\'kde\', \'scatter\', \'hist\', \'fastkde\'} for 2D plots and\n            in {\'kde\', \'hist\', \'fastkde\', \'astropyhist\'} for 1D plots.\n            optional, (Default: \'kde\')\n\n        ncompress: int\n            Number of samples to use in plotting routines.\n            optional, Default dynamically chosen\n\n        Returns\n        -------\n        fig: matplotlib.figure.Figure\n            New or original (if supplied) figure object\n\n        axes: pandas.DataFrame or pandas.Series of matplotlib.axes.Axes\n            Pandas array of axes objects\n\n        """"""\n        plot_type = kwargs.pop(\'plot_type\', \'kde\')\n        do_1d_plot = paramname_y is None or paramname_x == paramname_y\n        kwargs[\'label\'] = kwargs.get(\'label\', self.label)\n        ncompress = kwargs.pop(\'ncompress\', None)\n\n        if do_1d_plot:\n            if paramname_x in self and plot_type is not None:\n                xmin, xmax = self._limits(paramname_x)\n                if plot_type == \'kde\':\n                    if ncompress is None:\n                        ncompress = 1000\n                    return kde_plot_1d(ax, self[paramname_x],\n                                       weights=self.weight,\n                                       ncompress=ncompress,\n                                       xmin=xmin, xmax=xmax,\n                                       *args, **kwargs)\n                elif plot_type == \'fastkde\':\n                    x = self[paramname_x].compress(ncompress)\n                    return fastkde_plot_1d(ax, x, xmin=xmin, xmax=xmax,\n                                           *args, **kwargs)\n                elif plot_type == \'hist\':\n                    return hist_plot_1d(ax, self[paramname_x],\n                                        weights=self.weight,\n                                        xmin=xmin, xmax=xmax, *args, **kwargs)\n                elif plot_type == \'astropyhist\':\n                    x = self[paramname_x].compress(ncompress)\n                    return hist_plot_1d(ax, x, plotter=\'astropyhist\',\n                                        xmin=xmin, xmax=xmax, *args, **kwargs)\n                else:\n                    raise NotImplementedError(""plot_type is \'%s\', but must be""\n                                              "" one of {\'kde\', \'fastkde\', ""\n                                              ""\'hist\', \'astropyhist\'}.""\n                                              % plot_type)\n            else:\n                ax.plot([], [])\n\n        else:\n            if (paramname_x in self and paramname_y in self\n                    and plot_type is not None):\n                xmin, xmax = self._limits(paramname_x)\n                ymin, ymax = self._limits(paramname_y)\n                if plot_type == \'kde\':\n                    if ncompress is None:\n                        ncompress = 1000\n                    x = self[paramname_x]\n                    y = self[paramname_y]\n                    return kde_contour_plot_2d(ax, x, y, weights=self.weight,\n                                               xmin=xmin, xmax=xmax,\n                                               ymin=ymin, ymax=ymax,\n                                               ncompress=ncompress,\n                                               *args, **kwargs)\n                elif plot_type == \'fastkde\':\n                    x = self[paramname_x].compress(ncompress)\n                    y = self[paramname_y].compress(ncompress)\n                    return fastkde_contour_plot_2d(ax, x, y,\n                                                   xmin=xmin, xmax=xmax,\n                                                   ymin=ymin, ymax=ymax,\n                                                   *args, **kwargs)\n                elif plot_type == \'scatter\':\n                    if ncompress is None:\n                        ncompress = 500\n                    x = self[paramname_x].compress(ncompress)\n                    y = self[paramname_y].compress(ncompress)\n                    return scatter_plot_2d(ax, x, y, xmin=xmin, xmax=xmax,\n                                           ymin=ymin, ymax=ymax,\n                                           *args, **kwargs)\n                elif plot_type == \'hist\':\n                    x = self[paramname_x]\n                    y = self[paramname_y]\n                    return hist_plot_2d(ax, x, y, weights=self.weight,\n                                        xmin=xmin, xmax=xmax,\n                                        ymin=ymin, ymax=ymax,\n                                        *args, **kwargs)\n                else:\n                    raise NotImplementedError(""plot_type is \'%s\', but must be""\n                                              ""in {\'kde\', \'fastkde\',""\n                                              ""\'scatter\', \'hist\'}.""\n                                              % plot_type)\n\n            else:\n                ax.plot([], [])\n\n    def plot_1d(self, axes, *args, **kwargs):\n        """"""Create an array of 1D plots.\n\n        Parameters\n        ----------\n        axes: plotting axes\n            Can be:\n                - list(str) or str\n                - pandas.Series(matplotlib.axes.Axes)\n            If a pandas.Series is provided as an existing set of axes, then\n            this is used for creating the plot. Otherwise a new set of axes are\n            created using the list or lists of strings.\n\n        Returns\n        -------\n        fig: matplotlib.figure.Figure\n            New or original (if supplied) figure object\n\n        axes: pandas.Series of matplotlib.axes.Axes\n            Pandas array of axes objects\n\n        """"""\n        if not isinstance(axes, pandas.Series):\n            fig, axes = make_1d_axes(axes, tex=self.tex)\n        else:\n            fig = axes.values[~axes.isna()][0].figure\n\n        for x, ax in axes.iteritems():\n            self.plot(ax, x, *args, **kwargs)\n\n        return fig, axes\n\n    def plot_2d(self, axes, *args, **kwargs):\n        """"""Create an array of 2D plots.\n\n        To avoid intefering with y-axis sharing, one-dimensional plots are\n        created on a separate axis, which is monkey-patched onto the argument\n        ax as the attribute ax.twin.\n\n        Parameters\n        ----------\n        axes: plotting axes\n            Can be:\n                - list(str) if the x and y axes are the same\n                - [list(str),list(str)] if the x and y axes are different\n                - pandas.DataFrame(matplotlib.axes.Axes)\n            If a pandas.DataFrame is provided as an existing set of axes, then\n            this is used for creating the plot. Otherwise a new set of axes are\n            created using the list or lists of strings.\n\n        types: dict, optional\n            What type (or types) of plots to produce. Takes the keys \'diagonal\'\n            for the 1D plots and \'lower\' and \'upper\' for the 2D plots.\n            The options for \'diagonal are:\n                - \'kde\'\n                - \'hist\'\n                - \'astropyhist\'\n            The options for \'lower\' and \'upper\' are:\n                - \'kde\'\n                - \'scatter\'\n                - \'hist\'\n                - \'fastkde\'\n            Default: {\'diagonal\': \'kde\', \'lower\': \'kde\', \'upper\':\'scatter\'}\n\n        diagonal_kwargs, lower_kwargs, upper_kwargs: dict, optional\n            kwargs for the diagonal (1D)/lower or upper (2D) plots. This is\n            useful when there is a conflict of kwargs for different types of\n            plots.  Note that any kwargs directly passed to plot_2d will\n            overwrite any kwarg with the same key passed to <sub>_kwargs.\n            Default: {}\n\n        Returns\n        -------\n        fig: matplotlib.figure.Figure\n            New or original (if supplied) figure object\n\n        axes: pandas.DataFrame of matplotlib.axes.Axes\n            Pandas array of axes objects\n\n        """"""\n        default_types = {\'diagonal\': \'kde\', \'lower\': \'kde\', \'upper\': \'scatter\'}\n        types = kwargs.pop(\'types\', default_types)\n        diagonal = kwargs.pop(\'diagonal\', True)\n        if isinstance(types, list) or isinstance(types, str):\n            from warnings import warn\n            warn(""MCMCSamples.plot_2d\'s argument \'types\' might stop accepting ""\n                 ""str or list(str) as input in the future. It takes a ""\n                 ""dictionary as input, now, with keys \'diagonal\' for the 1D ""\n                 ""plots and \'lower\' and \'upper\' for the 2D plots. \'diagonal\' ""\n                 ""accepts the values \'kde\' or \'hist\' and both \'lower\' and ""\n                 ""\'upper\' accept the values \'kde\' or \'scatter\'. ""\n                 ""Default: {\'diagonal\': \'kde\', \'lower\': \'kde\'}."",\n                 FutureWarning)\n\n            if isinstance(types, str):\n                types = {\'lower\': types}\n                if diagonal:\n                    types[\'diagonal\'] = types[\'lower\']\n            elif isinstance(types, list):\n                types = {\'lower\': types[0], \'upper\': types[-1]}\n                if diagonal:\n                    types[\'diagonal\'] = types[\'lower\']\n\n        local_kwargs = {pos: kwargs.pop(\'%s_kwargs\' % pos, {})\n                        for pos in default_types}\n\n        for pos in local_kwargs:\n            local_kwargs[pos].update(kwargs)\n\n        if not isinstance(axes, pandas.DataFrame):\n            fig, axes = make_2d_axes(axes, tex=self.tex,\n                                     upper=(\'upper\' in types),\n                                     lower=(\'lower\' in types),\n                                     diagonal=(\'diagonal\' in types))\n        else:\n            fig = axes.values[~axes.isna()][0].figure\n\n        for y, row in axes.iterrows():\n            for x, ax in row.iteritems():\n                if ax is not None:\n                    pos = ax.position\n                    ax_ = ax.twin if x == y else ax\n                    plot_type = types.get(pos, None)\n                    lkwargs = local_kwargs.get(pos, {})\n                    self.plot(ax_, x, y, plot_type=plot_type, *args, **lkwargs)\n\n        return fig, axes\n\n    def _limits(self, paramname):\n        return self.limits.get(paramname, (None, None))\n\n    def _reload_data(self):\n        self.__init__(root=self.root)\n        return self\n\n    _metadata = WeightedDataFrame._metadata + [\'tex\', \'limits\',\n                                               \'root\', \'label\']\n\n    @property\n    def _constructor(self):\n        return MCMCSamples\n\n\nclass NestedSamples(MCMCSamples):\n    """"""Storage and plotting tools for Nested Sampling samples.\n\n    We extend the MCMCSamples class with the additional methods:\n\n    * ``self.ns_output()``\n    * ``self.live_points(logL)``\n    * ``self.posterior_points(beta)``\n\n    Parameters\n    ----------\n    root: str, optional\n        root for reading chains from file. Overrides all other arguments.\n\n    data: np.array\n        Coordinates of samples. shape = (nsamples, ndims).\n\n    columns: list(str)\n        reference names of parameters\n\n    logL: np.array\n        loglikelihoods of samples.\n\n    logL_birth: np.array or int\n        birth loglikelihoods, or number of live points.\n\n    tex: dict\n        mapping from columns to tex labels for plotting\n\n    limits: dict\n        mapping from columns to prior limits\n\n    label: str\n        Legend label\n\n    beta: float\n        thermodynamic temperature\n\n    logzero: float\n        The threshold for `log(0)` values assigned to rejected sample points.\n        Anything equal or below this value is set to `-np.inf`.\n        default: -1e30\n\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        root = kwargs.pop(\'root\', None)\n        if root is not None:\n            reader = SampleReader(root)\n            samples, logL, logL_birth = reader.samples()\n            params, tex = reader.paramnames()\n            columns = kwargs.pop(\'columns\', params)\n            limits = reader.limits()\n            kwargs[\'label\'] = kwargs.get(\'label\', os.path.basename(root))\n            self.__init__(data=samples, columns=columns,\n                          logL=logL, logL_birth=logL_birth,\n                          tex=tex, limits=limits, *args, **kwargs)\n            self.root = root\n        else:\n            logzero = kwargs.pop(\'logzero\', -1e30)\n            self._beta = kwargs.pop(\'beta\', 1.)\n            logL_birth = kwargs.pop(\'logL_birth\', None)\n            if not isinstance(logL_birth, int) and logL_birth is not None:\n                logL_birth = np.where(logL_birth <= logzero, -np.inf,\n                                      logL_birth)\n\n            super(NestedSamples, self).__init__(logzero=logzero,\n                                                *args, **kwargs)\n            if logL_birth is not None:\n                self._compute_nlive(logL_birth)\n\n            self._set_automatic_limits()\n\n    @property\n    def beta(self):\n        """"""Thermodynamic inverse temperature.""""""\n        return self._beta\n\n    @beta.setter\n    def beta(self, beta):\n        self._beta = beta\n        logw = self.dlogX() + np.where(self.logL == -np.inf, -np.inf,\n                                       self.beta * self.logL)\n        self._weight = np.exp(logw - logw.max())\n\n        if self._weight is not None:\n            self[\'weight\'] = self.weight\n            self.tex[\'weight\'] = r\'MCMC weight\'\n\n    def set_beta(self, beta, inplace=False):\n        """"""Change the inverse temperature.\n\n        Parameters\n        ----------\n        beta: float\n            Temperature to set\n\n        inplace: bool, optional\n            Indicates whether to modify the existing array, or return a copy\n            with the temperature changed. Default: False\n\n        """"""\n        if inplace:\n            self.beta = beta\n        else:\n            data = self.copy()\n            data.beta = beta\n            return data\n\n    def ns_output(self, nsamples=200):\n        """"""Compute Bayesian global quantities.\n\n        Using nested sampling we can compute the evidence (logZ),\n        Kullback-Leibler divergence (D) and Bayesian model dimensionality (d).\n        More precisely, we can infer these quantities via their probability\n        distribution.\n\n        Parameters\n        ----------\n        nsamples: int, optional\n            number of samples to generate (Default: 100)\n\n        Returns\n        -------\n        pandas.DataFrame\n            Samples from the P(logZ, D, d) distribution\n\n        """"""\n        dlogX = self.dlogX(nsamples)\n        samples = MCMCSamples(index=dlogX.columns)\n        samples[\'logZ\'] = self.logZ(dlogX)\n\n        logw = dlogX.add(self.beta * self.logL, axis=0)\n        logw -= samples.logZ\n        S = (dlogX*0).add(self.beta * self.logL, axis=0) - samples.logZ\n\n        samples[\'D\'] = np.exp(logsumexp(logw, b=S, axis=0))\n        samples[\'d\'] = np.exp(logsumexp(logw, b=(S-samples.D)**2, axis=0))*2\n\n        samples.tex = {\'logZ\': r\'$\\log\\mathcal{Z}$\',\n                       \'D\': r\'$\\mathcal{D}$\',\n                       \'d\': r\'$d$\'}\n        samples.label = self.label\n        return samples\n\n    def logZ(self, nsamples=None):\n        """"""Log-Evidence.\n\n        - If nsamples is not supplied, return mean log evidence\n        - If nsamples is integer, return nsamples from the distribution\n        - If nsamples is array, use nsamples as volumes of evidence shells\n\n        """"""\n        dlogX = self.dlogX(nsamples)\n        logw = dlogX.add(self.beta * self.logL, axis=0)\n        return logsumexp(logw, axis=0)\n\n    def D(self, nsamples=None):\n        """"""Kullback-Leibler divergence.\n\n        - If nsamples is not supplied, return mean KL divergence\n        - If nsamples is integer, return nsamples from the distribution\n        - If nsamples is array, use nsamples as volumes of evidence shells\n\n        """"""\n        dlogX = self.dlogX(nsamples)\n        logZ = self.logZ(dlogX)\n        logw = dlogX.add(self.beta * self.logL, axis=0) - logZ\n        S = (dlogX*0).add(self.beta * self.logL, axis=0) - logZ\n        return np.exp(logsumexp(logw, b=S, axis=0))\n\n    def d(self, nsamples=None):\n        """"""Bayesian model dimensionality.\n\n        - If nsamples is not supplied, return mean BMD\n        - If nsamples is integer, return nsamples from the distribution\n        - If nsamples is array, use nsamples as volumes of evidence shells\n\n        """"""\n        dlogX = self.dlogX(nsamples)\n        logZ = self.logZ(dlogX)\n        D = self.D(dlogX)\n        logw = dlogX.add(self.beta * self.logL, axis=0) - logZ\n        S = (dlogX*0).add(self.beta * self.logL, axis=0) - logZ\n        return np.exp(logsumexp(logw, b=(S-D)**2, axis=0))*2\n\n    def live_points(self, logL=None):\n        """"""Get the live points within logL.\n\n        Parameters\n        ----------\n        logL: float or int, optional\n            Loglikelihood or iteration number to return live points.\n            If not provided, return the last set of active live points.\n\n        Returns\n        -------\n        live_points: NestedSamples\n            Live points at either:\n                - contour logL (if input is float)\n                - ith contour (if input is integer)\n                - last generation contour if logL not provided\n        """"""\n        if logL is None:\n            logL = self.logL_birth.max()\n        elif is_int(logL):\n            logL = self.logL[logL]\n\n        return self[(self.logL > logL) & (self.logL_birth <= logL)]\n\n    def posterior_points(self, beta=1):\n        """"""Get equally weighted posterior points at temperature beta.""""""\n        return self.set_beta(beta).compress(-1)\n\n    def gui(self, params=None):\n        """"""Construct a graphical user interface for viewing samples.""""""\n        return RunPlotter(self, params)\n\n    def dlogX(self, nsamples=None):\n        """"""Compute volume of shell of loglikelihood.\n\n        Parameters\n        ----------\n        nsamples: int, optional\n            Number of samples to generate. optional. If None, then compute the\n            statistical average. If integer, generate samples from the\n            distribution. (Default: None)\n\n        """"""\n        with np.errstate(divide=\'ignore\'):\n            if np.ndim(nsamples) > 0:\n                return nsamples\n            elif nsamples is None:\n                t = np.log(self.nlive/(self.nlive+1)).to_frame()\n            else:\n                r = np.log(np.random.rand(len(self), nsamples))\n                t = pandas.DataFrame(r, self.index).divide(self.nlive, axis=0)\n\n        logX = t.cumsum()\n        logXp = logX.shift(1, fill_value=0)\n        logXm = logX.shift(-1, fill_value=-np.inf)\n        dlogX = logsumexp([logXp.values, logXm.values],\n                          b=[np.ones_like(logXp), -np.ones_like(logXm)],\n                          axis=0) - np.log(2)\n\n        if nsamples is None:\n            dlogX = np.squeeze(dlogX)\n            return WeightedSeries(dlogX, self.index, w=self.weight)\n        else:\n            return WeightedDataFrame(dlogX, self.index, w=self.weight)\n\n    def _compute_nlive(self, logL_birth):\n        if is_int(logL_birth):\n            nlive = logL_birth\n            self[\'nlive\'] = nlive\n            descending = np.arange(nlive, 0, -1)\n            self.loc[len(self)-nlive:, \'nlive\'] = descending\n        else:\n            self[\'logL_birth\'] = logL_birth\n            self.tex[\'logL_birth\'] = r\'$\\log\\mathcal{L}_{\\rm birth}$\'\n            self[\'nlive\'] = compute_nlive(self.logL, self.logL_birth)\n\n        self.tex[\'nlive\'] = r\'$n_{\\rm live}$\'\n        self.beta = self._beta\n\n    _metadata = MCMCSamples._metadata + [\'_beta\']\n\n    @property\n    def _constructor(self):\n        return NestedSamples\n\n\ndef merge_nested_samples(runs):\n    """"""Merge two or more nested sampling runs.\n\n    Parameters\n    ----------\n    runs: list(NestedSamples)\n        list or array-like of nested sampling runs.\n\n    Returns\n    -------\n    samples: NestedSamples\n        Merged run.\n    """"""\n    samples = pandas.concat(runs, ignore_index=True)\n    samples = samples.sort_values(\'logL\').reset_index(drop=True)\n    samples._compute_nlive(samples.logL_birth)\n    return samples\n'"
anesthetic/utils.py,56,"b'""""""Data-processing utility functions.""""""\nimport numpy as np\nimport pandas\nfrom scipy import special\nfrom scipy.interpolate import interp1d\nfrom matplotlib.tri import Triangulation\n\n\ndef logsumexp(a, axis=None, b=None, keepdims=False, return_sign=False):\n    r""""""Compute the log of the sum of exponentials of input elements.\n\n    This function has the same call signature as `scipy.special.logsumexp`\n    and mirrors scipy\'s behaviour except for `-np.inf` input. If a and b\n    are both -inf then scipy\'s function will output `nan` whereas here we use:\n\n    .. math::\n\n        \\lim_{x \\to -\\infty} x \\exp(x) = 0\n\n    Thus, if a=-inf in `log(sum(b * exp(a))` then we can set b=0 such that\n    that term is ignored in the sum.\n    """"""\n    if b is None:\n        b = np.ones_like(a)\n    b = np.where(a == -np.inf, 0, b)\n    return special.logsumexp(a, axis=axis, b=b, keepdims=keepdims,\n                             return_sign=return_sign)\n\n\ndef channel_capacity(w):\n    r""""""Channel capacity (effective sample size).\n\n    .. math::\n\n        H = \\sum_i p_i \\log p_i\n\n        p_i = \\frac{w_i}{\\sum_j w_j}\n\n        N = e^{-H}\n    """"""\n    with np.errstate(divide=\'ignore\', invalid=\'ignore\'):\n        W = np.array(w)/sum(w)\n        H = np.nansum(np.log(W)*W)\n        return np.exp(-H)\n\n\ndef compress_weights(w, u=None, nsamples=None):\n    """"""Compresses weights to their approximate channel capacity.""""""\n    if u is None:\n        u = np.random.rand(len(w))\n\n    if w is None:\n        w = np.ones_like(u)\n\n    if nsamples is None:\n        nsamples = channel_capacity(w)\n\n    if nsamples <= 0:\n        W = w/w.max()\n    else:\n        W = w * nsamples / w.sum()\n\n    fraction, integer = np.modf(W)\n    extra = (u < fraction).astype(int)\n    return (integer + extra).astype(int)\n\n\ndef quantile(a, q, w=None):\n    """"""Compute the weighted quantile for a one dimensional array.""""""\n    if w is None:\n        w = np.ones_like(a)\n    a = np.array(list(a))  # Necessary to convert pandas arrays\n    w = np.array(list(w))  # Necessary to convert pandas arrays\n    i = np.argsort(a)\n    c = np.cumsum(w[i[1:]]+w[i[:-1]])\n    c /= c[-1]\n    c = np.concatenate(([0.], c))\n    icdf = interp1d(c, a[i])\n    quant = icdf(q)\n    if isinstance(q, float):\n        quant = float(quant)\n    return quant\n\n\ndef check_bounds(d, xmin=None, xmax=None):\n    """"""Check if we need to apply strict bounds.""""""\n    if len(d) > 0:\n        if xmin is not None and (d.min() - xmin) > 1e-2*(d.max()-d.min()):\n            xmin = None\n        if xmax is not None and (xmax - d.max()) > 1e-2*(d.max()-d.min()):\n            xmax = None\n    return xmin, xmax\n\n\ndef mirror_1d(d, xmin=None, xmax=None):\n    """"""If necessary apply reflecting boundary conditions.""""""\n    if xmin is not None and xmax is not None:\n        xmed = (xmin+xmax)/2\n        return np.concatenate((2*xmin-d[d < xmed], d, 2*xmax-d[d >= xmed]))\n    elif xmin is not None:\n        return np.concatenate((2*xmin-d, d))\n    elif xmax is not None:\n        return np.concatenate((d, 2*xmax-d))\n    else:\n        return d\n\n\ndef mirror_2d(d_x_, d_y_, xmin=None, xmax=None, ymin=None, ymax=None):\n    """"""If necessary apply reflecting boundary conditions.""""""\n    d_x = d_x_.copy()\n    d_y = d_y_.copy()\n\n    if xmin is not None and xmax is not None:\n        xmed = (xmin+xmax)/2\n        d_y = np.concatenate((d_y[d_x < xmed], d_y, d_y[d_x >= xmed]))\n        d_x = np.concatenate((2*xmin-d_x[d_x < xmed], d_x,\n                              2*xmax-d_x[d_x >= xmed]))\n    elif xmin is not None:\n        d_y = np.concatenate((d_y, d_y))\n        d_x = np.concatenate((2*xmin-d_x, d_x))\n    elif xmax is not None:\n        d_y = np.concatenate((d_y, d_y))\n        d_x = np.concatenate((d_x, 2*xmax-d_x))\n\n    if ymin is not None and ymax is not None:\n        ymed = (ymin+ymax)/2\n        d_x = np.concatenate((d_x[d_y < ymed], d_x, d_x[d_y >= ymed]))\n        d_y = np.concatenate((2*ymin-d_y[d_y < ymed], d_y,\n                              2*ymax-d_y[d_y >= ymed]))\n    elif ymin is not None:\n        d_x = np.concatenate((d_x, d_x))\n        d_y = np.concatenate((2*ymin-d_y, d_y))\n    elif ymax is not None:\n        d_x = np.concatenate((d_x, d_x))\n        d_y = np.concatenate((d_y, 2*ymax-d_y))\n\n    return d_x, d_y\n\n\ndef nest_level(lst):\n    """"""Calculate the nesting level of a list.""""""\n    if not isinstance(lst, list):\n        return 0\n    if not lst:\n        return 1\n    return max(nest_level(item) for item in lst) + 1\n\n\ndef histogram(a, **kwargs):\n    """"""Produce a histogram for path-based plotting.\n\n    This is a cheap histogram. Necessary if one wants to update the histogram\n    dynamically, and redrawing and filling is very expensive.\n\n    This has the same arguments and keywords as np.histogram, but is\n    normalised to 1.\n    """"""\n    hist, bin_edges = np.histogram(a, **kwargs)\n    xpath, ypath = np.empty((2, 4*len(hist)))\n    ypath[0::4] = ypath[3::4] = 0\n    ypath[1::4] = ypath[2::4] = hist\n    xpath[0::4] = xpath[1::4] = bin_edges[:-1]\n    xpath[2::4] = xpath[3::4] = bin_edges[1:]\n    mx = max(ypath)\n    if mx:\n        ypath /= max(ypath)\n    return xpath, ypath\n\n\ndef compute_nlive(death, birth):\n    """"""Compute number of live points from birth and death contours.\n\n    Parameters\n    ----------\n    death, birth : array-like\n        list of birth and death contours\n\n    Returns\n    -------\n    nlive: np.array\n        number of live points at each contour\n    """"""\n    birth_index = death.searchsorted(birth)\n    births = pandas.Series(+1, index=birth_index).sort_index()\n    index = np.arange(death.size)\n    deaths = pandas.Series(-1, index=index)\n    nlive = pandas.concat([births, deaths]).sort_index()\n    nlive = nlive.groupby(nlive.index).sum().cumsum()\n    return nlive.values\n\n\ndef unique(a):\n    """"""Find unique elements, retaining order.""""""\n    b = []\n    for x in a:\n        if x not in b:\n            b.append(x)\n    return b\n\n\ndef iso_probability_contours(pdf, contours=[0.68, 0.95]):\n    """"""Compute the iso-probability contour values.""""""\n    contours = [1-p for p in reversed(contours)]\n    p = np.sort(np.array(pdf).flatten())\n    m = np.cumsum(p)\n    m /= m[-1]\n    interp = interp1d([0]+list(m), [0]+list(p))\n    c = list(interp(contours))+[max(p)]\n\n    # Correct level sets\n    for i in range(1, len(c)):\n        if c[i-1] == c[i]:\n            for j in range(i):\n                c[j] = c[j] - 1e-5\n\n    return c\n\n\ndef iso_probability_contours_from_samples(pdf, contours=[0.68, 0.95],\n                                          weights=None):\n    """"""Compute the iso-probability contour values.""""""\n    if weights is None:\n        weights = np.ones_like(pdf)\n    contours = [1-p for p in reversed(contours)]\n    i = np.argsort(pdf)\n    m = np.cumsum(weights[i])\n    m /= m[-1]\n    interp = interp1d([0]+list(m), [0]+list(pdf[i]))\n    c = list(interp(contours))+[max(pdf)]\n\n    # Correct level sets\n    for i in range(1, len(c)):\n        if c[i-1] == c[i]:\n            for j in range(i):\n                c[j] = c[j] - 1e-5\n\n    return c\n\n\ndef scaled_triangulation(x, y, cov):\n    """"""Triangulation scaled by a covariance matrix.\n\n    Parameters\n    ----------\n    x, y: array-like\n        x and y coordinates of samples\n\n    cov: array-like, 2d\n        Covariance matrix for scaling\n\n    Returns\n    -------\n    matplotlib.tri.Triangulation\n        Triangulation with the appropriate scaling\n    """"""\n    L = np.linalg.cholesky(cov)\n    Linv = np.linalg.inv(L)\n    x_, y_ = Linv.dot([x, y])\n    tri = Triangulation(x_, y_)\n    return Triangulation(x, y, tri.triangles)\n\n\ndef triangular_sample_compression_2d(x, y, cov, w=None, n=1000):\n    """"""Histogram a 2D set of weighted samples via triangulation.\n\n    This defines bins via a triangulation of the subsamples and sums weights\n    within triangles surrounding each point\n\n    Parameters\n    ----------\n    x, y: array-like\n        x and y coordinates of samples for compressing\n\n    cov: array-like, 2d\n        Covariance matrix for scaling\n\n    w: pandas.Series, optional\n        weights of samples\n\n    n: int, optional\n        number of samples returned. Default 1000\n\n    Returns\n    -------\n    tri:\n        matplotlib.tri.Triangulation with an appropriate scaling\n\n    w: array-like\n        Compressed samples and weights\n    """"""\n    x = pandas.Series(x)\n    if w is None:\n        w = pandas.Series(index=x.index, data=np.ones_like(x))\n\n    # Select samples for triangulation\n    if (w != 0).sum() < n:\n        i = x.index\n    else:\n        i = np.random.choice(x.index, size=n, replace=False, p=w/w.sum())\n\n    # Generate triangulation\n    tri = scaled_triangulation(x[i], y[i], cov)\n\n    # For each point find corresponding triangles\n    trifinder = tri.get_trifinder()\n    j = trifinder(x, y)\n    k = tri.triangles[j[j != -1]]\n\n    # Compute mass in each triangle, and add it to each corner\n    w_ = np.zeros(len(i))\n    for i in range(3):\n        np.add.at(w_, k[:, i], w[j != -1]/3)\n\n    return tri, w_\n\n\ndef sample_compression_1d(x, w=None, n=1000):\n    """"""Histogram a 1D set of weighted samples via subsampling.\n\n    This compresses the number of samples, combining weights.\n\n    Parameters\n    ----------\n    x: array-like\n        x coordinate of samples for compressing\n\n    w: pandas.Series, optional\n        weights of samples\n\n    n: int, optional\n        number of samples returned. Default 1000\n\n    Returns\n    -------\n    x, w, array-like\n        Compressed samples and weights\n    """"""\n    x = pandas.Series(x)\n    if w is None:\n        w = pandas.Series(index=x.index, data=np.ones_like(x))\n\n    # Select inner samples for triangulation\n    if sum(w != 0) < n:\n        i = w.index\n    else:\n        i = np.random.choice(w.index, size=n, replace=False, p=w/w.sum())\n\n    # Define sub-samples\n    x_ = np.sort(x[i])\n\n    # Compress mass onto these subsamples\n    j1 = np.digitize(x, x_) - 1\n    k1 = (j1 > -1) & (j1 < n)\n    j2 = np.digitize(x, x_, right=True) - 1\n    k2 = (j2 > -1) & (j2 < n)\n\n    w_ = np.zeros_like(x_)\n    np.add.at(w_, j1[k1], w[k1])\n    np.add.at(w_, j2[k2], w[k2])\n\n    return x_, w_\n\n\ndef is_int(x):\n    """"""Test whether x is an integer.""""""\n    return isinstance(x, int) or isinstance(x, np.integer)\n'"
anesthetic/weighted_pandas.py,11,"b'""""""Pandas DataFrame and Series with weighted samples.""""""\n\nimport numpy as np\nimport pandas\nfrom anesthetic.utils import compress_weights, channel_capacity, quantile\n\n\nclass _WeightedObject(object):\n    @property\n    def weight(self):\n        """"""Sample weights.""""""\n        if self._weight is None:\n            return pandas.Series(index=self.index, data=1.)\n        else:\n            return self._weight[self.index]\n\n    @property\n    def _rand(self):\n        """"""Random number for consistent compression.""""""\n        return self._rand_[self.index]\n\n    def _construct_weights(self, w):\n        if w is not None:\n            self._weight = pandas.Series(index=self.index, data=w)\n        else:\n            self._weight = None\n        rand = np.random.rand(len(self))\n        self._rand_ = pandas.Series(index=self.index, data=rand)\n\n    def std(self):\n        """"""Weighted standard deviation of the sampled distribution.""""""\n        return np.sqrt(self.var())\n\n    def median(self):\n        """"""Weighted median of the sampled distribution.""""""\n        return self.quantile()\n\n    def neff(self):\n        """"""Effective number of samples.""""""\n        return channel_capacity(self.weight)\n\n\nclass WeightedSeries(_WeightedObject, pandas.Series):\n    """"""Weighted version of pandas.Series.""""""\n\n    def __init__(self, *args, **kwargs):\n        w = kwargs.pop(\'w\', None)\n        super(WeightedSeries, self).__init__(*args, **kwargs)\n        self._construct_weights(w)\n\n    def mean(self):\n        """"""Weighted mean of the sampled distribution.""""""\n        return np.average(self, weights=self.weight)\n\n    def var(self):\n        """"""Weighted variance of the sampled distribution.""""""\n        return np.average((self-self.mean())**2, weights=self.weight)\n\n    def quantile(self, q=0.5):\n        """"""Weighted quantile of the sampled distribution.""""""\n        return quantile(self.values, q, self.weight.values)\n\n    def hist(self, *args, **kwargs):\n        """"""Weighted histogram of the sampled distribution.""""""\n        return super(WeightedSeries, self).hist(weights=self.weight,\n                                                *args, **kwargs)\n\n    def compress(self, nsamples=None):\n        """"""Reduce the number of samples by discarding low-weights.\n\n        Parameters\n        ----------\n        neff: int, optional\n            effective number of samples after compression. If not supplied,\n            then reduce to the channel capacity (theoretical optimum\n            compression). If <=0, then compress so that all weights are unity.\n\n        """"""\n        i = compress_weights(self.weight, self._rand, nsamples)\n        return self.repeat(i)\n\n    _metadata = [\'_weight\', \'_rand_\']\n\n    @property\n    def _constructor(self):\n        return WeightedSeries\n\n    @property\n    def _constructor_expanddim(self):\n        def __constructor_expanddim(*args, **kwargs):\n            frame = WeightedDataFrame(*args, w=self._weight, **kwargs)\n            frame._rand_ = self._rand_\n            return frame\n        return __constructor_expanddim\n\n\nclass WeightedDataFrame(_WeightedObject, pandas.DataFrame):\n    """"""Weighted version of pandas.DataFrame.""""""\n\n    def __init__(self, *args, **kwargs):\n        w = kwargs.pop(\'w\', None)\n        super(WeightedDataFrame, self).__init__(*args, **kwargs)\n        self._construct_weights(w)\n\n    def mean(self):\n        """"""Weighted mean of the sampled distribution.""""""\n        return pandas.Series(np.average(self, weights=self.weight, axis=0),\n                             index=self.columns)\n\n    def var(self):\n        """"""Weighted variance of the sampled distribution.""""""\n        return pandas.Series(np.average((self-self.mean())**2,\n                                        weights=self.weight, axis=0),\n                             index=self.columns)\n\n    def cov(self):\n        """"""Weighted covariance of the sampled distribution.""""""\n        return pandas.DataFrame(np.cov(self.T, aweights=self.weight),\n                                index=self.columns, columns=self.columns)\n\n    def quantile(self, q=0.5):\n        """"""Weighted quantile of the sampled distribution.""""""\n        data = np.array([c.quantile(q) for _, c in self.iteritems()])\n        if np.isscalar(q):\n            return pandas.Series(data, index=self.columns)\n        else:\n            return pandas.DataFrame(data.T, columns=self.columns, index=q)\n\n    def hist(self, *args, **kwargs):\n        """"""Weighted histogram of the sampled distribution.""""""\n        return super(WeightedDataFrame, self).hist(weights=self.weight,\n                                                   *args, **kwargs)\n\n    def compress(self, nsamples=None):\n        """"""Reduce the number of samples by discarding low-weights.\n\n        Parameters\n        ----------\n        neff: int, optional\n            effective number of samples after compression. If not supplied,\n            then reduce to the channel capacity (theoretical optimum\n            compression). If <=0, then compress so that all weights are unity.\n\n        """"""\n        i = compress_weights(self.weight, self._rand, nsamples)\n        data = np.repeat(self.values, i, axis=0)\n        index = np.repeat(self.index.values, i)\n        df = pandas.DataFrame(data=data, index=index, columns=self.columns)\n        if \'weight\' in self:\n            return df.drop(columns=\'weight\')\n        else:\n            return df\n\n    _metadata = [\'_weight\', \'_rand_\']\n\n    @property\n    def _constructor_sliced(self):\n        def __constructor_sliced(*args, **kwargs):\n            series = WeightedSeries(*args, w=self._weight, **kwargs)\n            series._rand_ = self._rand_\n            return series\n        return __constructor_sliced\n\n    @property\n    def _constructor(self):\n        return WeightedDataFrame\n'"
bin/gen_data.py,15,"b'import numpy as np \nfrom anesthetic import MCMCSamples, NestedSamples\nimport tqdm\n\ndef loglikelihood(x):\n    """"""Example non-trivial loglikelihood\n\n    - Constrained zero-centered correlated parameters x0 and x1,\n    - half-constrained x2 (exponential).\n    - unconstrained x3 between 0 and 1\n    - x4 is a slanted top-hat distribution between 2 and 4\n\n    """"""\n   \n    x0, x1, x2, x3, x4 = x[:]\n    sigma0, sigma1 = 0.1, 0.1 \n    eps = 0.9                     # x0 and x1 parameters\n    sigma2 = 0.1                  # x2 parameter\n    a, b, m = 2., 4., 0.5         # x4 parameters\n    if x2 < 0 or x3 > 1 or x3 < 0 or x4 < a or x4 > b:\n        return -np.inf\n    x0 /= sigma0\n    x1 /= sigma1\n\n    logl = 0\n    logl -= np.log(2*np.pi*sigma0*sigma1*(1-eps**2)**0.5)\n    logl -= (x0**2 - 2*eps*x0*x1 + x1**2)/(1-eps**2)/2\n\n    logl -= np.log(sigma2) \n    logl -= x2/sigma2\n\n    logl += np.log(1/(b-a) + m * (x4-(b+a)/2.))\n    return logl\n\n\nndims = 5\ncolumns = [\'x%i\' % i for i in range(ndims)]\ntex = {p: \'$x_%i$\' % i  for i, p in enumerate(columns)}\nroots = []\n\n# MCMC\n# ----\ndef mcmc_sim(ndims=5):\n    """""" Simple Metropolis Hastings algorithm. """"""\n    x = [np.array([0, 0, 0.1, 0.5, 3])]\n    l = [loglikelihood(x[-1])]\n    w = [1]\n\n    while len(x) < 10000:\n        x1 = x[-1] + np.random.randn(ndims)*0.1\n        l1 = loglikelihood(x1)\n        if np.random.rand() < np.exp(l1-l[-1]):\n            x.append(x1)\n            l.append(l1)\n            w.append(1)\n        else:\n            w[-1]+=1\n    return np.array(x), np.array(l), np.array(w)\n\n\nnp.random.seed(0)\ndata, logL, w = mcmc_sim()\nmcmc = MCMCSamples(data=data, columns=columns, logL=logL, w=w, tex=tex)\nmcmc[\'chi2\'] = -2*mcmc.logL\n\n\n# MCMC multiple files\nroot = \'./tests/example_data/gd\'\nroots.append(root)\nmcmc[[\'weight\', \'chi2\'] + columns][:len(mcmc)//2].to_csv(root + \'_1.txt\', sep=\' \', index=False, header=False)\nmcmc[[\'weight\', \'chi2\'] + columns][len(mcmc)//2:].to_csv(root + \'_2.txt\', sep=\' \', index=False, header=False)\n\n# MCMC single file\nroot = \'./tests/example_data/gd_single\'\nroots.append(root)\nmcmc[[\'weight\', \'chi2\'] + columns].to_csv(root + \'.txt\', sep=\' \', index=False, header=False)\n\n\n# NS\n# --\n\ndef ns_sim(ndims=5, nlive=125):\n    """"""Brute force Nested Sampling run""""""\n    low=(-1,-1,0,0,2)\n    high=(1,1,1,1,4)\n    live_points = np.random.uniform(low=low, high=high, size=(nlive, ndims))\n    live_likes = np.array([loglikelihood(x) for x in live_points])\n    live_birth_likes = np.ones(nlive) * -np.inf\n\n    dead_points = []\n    dead_likes = []\n    birth_likes = []\n    for _ in tqdm.tqdm(range(nlive*11)):\n        i = np.argmin(live_likes)\n        Lmin = live_likes[i]\n        dead_points.append(live_points[i].copy())\n        dead_likes.append(live_likes[i])\n        birth_likes.append(live_birth_likes[i])\n        live_birth_likes[i] = Lmin\n        while live_likes[i] <= Lmin:\n            live_points[i, :] = np.random.uniform(low=low, high=high, size=ndims) \n            live_likes[i] = loglikelihood(live_points[i])\n    return dead_points, dead_likes, birth_likes, live_points, live_likes, live_birth_likes\n\nnp.random.seed(0)\ndata, logL, logL_birth, live, live_logL, live_logL_birth = ns_sim()\n\nns = NestedSamples(data=data, columns=columns, logL=logL, logL_birth=logL_birth, tex=tex)\nlive_ns = NestedSamples(data=live, columns=columns, logL=live_logL, logL_birth=live_logL_birth, tex=tex)\n\n# Dead file for polychord\nroot = \'./tests/example_data/pc\'\nroots.append(root)\n\nns[columns + [\'logL\', \'logL_birth\']].to_csv(root + \'_dead-birth.txt\', sep=\' \', index=False, header=False)\nlive_ns[columns + [\'logL\', \'logL_birth\']].to_csv(root + \'_phys_live-birth.txt\', sep=\' \', index=False, header=False)\n\n# Dead file for multinest\nns[\'cluster\'] = 1\nlive_ns[\'cluster\']=1\nroot = \'./tests/example_data/mn\'\nroots.append(root)\nns[\'dlogX\'] = ns.dlogX()\nns[columns + [\'logL\', \'logL_birth\', \'dlogX\', \'cluster\']].to_csv(root + \'dead-birth.txt\', sep=\' \', index=False, header=False)\nlive_ns[columns + [\'logL\', \'logL_birth\', \'cluster\']].to_csv(root + \'phys_live-birth.txt\', sep=\' \', index=False, header=False)\nns[columns + [\'logL\', \'dlogX\', \'cluster\']].to_csv(root + \'ev.dat\', sep=\' \', index=False, header=False)\nlive_ns[columns + [\'logL\', \'cluster\']].to_csv(root + \'phys_live.points\', sep=\' \', index=False, header=False)\n\n\n# Dead file for old multinest\nroot = \'./tests/example_data/mn_old\'\nroots.append(root)\n\nns[columns + [\'logL\', \'dlogX\', \'cluster\']].to_csv(root + \'ev.dat\', sep=\' \', index=False, header=False)\nns[columns + [\'logL\', \'cluster\']].to_csv(root + \'phys_live.points\', sep=\' \', index=False, header=False)\n\n\n# Second run with different live points\ndata, logL, logL_birth, live, live_logL, live_logL_birth = ns_sim(nlive=250)\nns = NestedSamples(data=data, columns=columns, logL=logL, logL_birth=logL_birth, tex=tex)\nlive_ns = NestedSamples(data=live, columns=columns, logL=live_logL, logL_birth=live_logL_birth, tex=tex)\n\n# Dead file for polychord\nroot = \'./tests/example_data/pc_250\'\nroots.append(root)\n\nns[columns + [\'logL\', \'logL_birth\']].to_csv(root + \'_dead-birth.txt\', sep=\' \', index=False, header=False)\nlive_ns[columns + [\'logL\', \'logL_birth\']].to_csv(root + \'_phys_live-birth.txt\', sep=\' \', index=False, header=False)\n\n\nfor root in roots:\n    # paramnames file\n    with open(root + \'.paramnames\', \'w\') as f:\n        for p in columns:\n            f.write(\'%s\\t%s\\n\' % (p, tex[p].replace(\'$\',\'\')))\n\n    # ranges file\n    with open(root + \'.ranges\', \'w\') as f:\n        f.write(\'%s\\tNone\\tNone\\n\' % columns[0])\n        f.write(\'%s\\tNone\\tNone\\n\' % columns[1])\n        f.write(\'%s\\t0\\tNone\\n\' % columns[2])\n        f.write(\'%s\\t0\\t1\\n\' % columns[3])\n\n\n'"
bin/plot.py,36,"b""from anesthetic import NestedSamples\nimport numpy as np\nns = NestedSamples(root='./tests/example_data/pc')\nfig, axes = ns.plot_2d(['x0', 'x1', 'x2', 'x3', 'x4'])\n\nsigma0, sigma1 = 0.1, 0.1 \neps = 0.9                     # x0 and x1 parameters\nsigma2 = 0.1                  # x2 parameter\na, b, m = 2., 4., 0.5         # x4 parameters\n\nn = 1000\nls = 'k--'\n\nx = np.linspace(-0.4,0.4,n)\np = np.exp(-x**2/sigma0**2/2)/np.sqrt(2*np.pi)/sigma0\naxes['x0']['x0'].twin.plot(x, p/p.max(), ls)\n\nx = np.linspace(-0.4,0.4,n)\np = np.exp(-x**2/sigma1**2/2)/np.sqrt(2*np.pi)/sigma1\naxes['x1']['x1'].twin.plot(x, p/p.max(), ls)\n\nx = np.linspace(-0.1,0.6,n)\np = np.exp(-x/sigma2)/sigma2 * (x>0)\naxes['x2']['x2'].twin.plot(x, p/p.max(), ls)\n\nx = np.linspace(-0.1,1.1,n)\np = (x<1) & (x>0)\naxes['x3']['x3'].twin.plot(x, p/p.max(), ls)\n\nx = np.linspace(a-0.1,b+0.1,n)\np = ((x<b) & (x>a)) * (1/(b-a) + m * (x-(b+a)/2.))\naxes['x4']['x4'].twin.plot(x, p/p.max(), ls)\n\n\n\nx3 = np.linspace(0,1,n)\nx0 = np.ones_like(x3) * sigma0\naxes['x0']['x3'].plot(2*x0, x3, ls)\naxes['x0']['x3'].plot(x0, x3, ls)\naxes['x0']['x3'].plot(-x0, x3, ls)\naxes['x0']['x3'].plot(-2*x0, x3, ls)\n\naxes['x1']['x3'].plot(2*x0, x3, ls)\naxes['x1']['x3'].plot(x0, x3, ls)\naxes['x1']['x3'].plot(-x0, x3, ls)\naxes['x1']['x3'].plot(-2*x0, x3, ls)\n\nfor p in [0.66, 0.95]:\n    axes['x2']['x3'].plot(-np.log(1-p)*x0, x3, ls)\n\nfrom scipy.optimize import root\nfrom scipy.special import erf\n\nfor p in [0.66, 0.95]:\n    k = root(lambda k: -2*np.exp(-k)*np.sqrt(k/np.pi) + erf(np.sqrt(k)) - p, 1).x[0]\n    x = np.linspace(-np.sqrt(2*k), np.sqrt(2*k), n)\n    y = k - x**2/2\n    axes['x0']['x2'].plot(x*sigma0, y*sigma2, ls)\n    axes['x1']['x2'].plot(x*sigma1, y*sigma2, ls)\n\nt = np.linspace(0, 2*np.pi, n)\nx0 = sigma1*eps*np.cos(t) + sigma0 * np.sin(t)\nx1 = np.sqrt(1-eps**2) * sigma1 * np.cos(t)\n\n\nx0 = sigma0 * np.sin(t)\nx1 = sigma1 * (np.sqrt(1-eps**2) * np.cos(t)  + eps*np.sin(t))\nfor p in [0.66, 0.95]:\n    r = np.sqrt(-2*np.log(1-p))\n    axes['x0']['x1'].plot(r*x1, r*x0, ls)\n\nx3 = np.linspace(0,1,n)\nfor p in [0.66, 0.95]:\n    x4 = 1/(a-b)/m + (a+b)/2 + (((m*(a-b)**2+2)/(a-b))**2 - 8*m*p)**0.5/2/m\n    x4 = x4 * np.ones_like(x3)\n    axes['x3']['x4'].plot(x3, x4, ls)\n\naxes['x3']['x4'].plot(x3, np.ones_like(x3)*b, ls)\n\naxes['x3']['x4'].plot(x3[0] * np.ones(n), np.linspace(x4[0],b,n), ls)\naxes['x3']['x4'].plot(x3[-1] * np.ones(n), np.linspace(x4[0],b,n), ls)\n\nx4 = np.linspace(a,b,n)\nfor p in [0.66, 0.95]:\n    k = 1/(b-a) + m/2 * (b-a - np.sqrt(8*p/m))\n    x4 = np.linspace((a+b)/2+(k/m + 1/(a-b)/m), b,n)\n    x2 = sigma2*(-np.log(k) + np.log(1/(b-a) + m * (x4-(b+a)/2)))\n    axes['x2']['x4'].plot(x2, x4, ls)\n\naxes['x2']['x4'].plot(np.zeros_like(x4), x4, ls)\naxes['x2']['x4'].plot(x2, b*np.ones_like(x2), ls)\n\nfrom scipy.special import erf, erfi\nfrom scipy.optimize import root\n\nfor p in [0.66, 0.95]:\n    k = root(lambda k: (1/(b-a)**2*(2+(b-a)**2*m)**2*erf(np.sqrt(np.log((2+(b-a)**2*m)/2/(b-a)/k))) - 4*k**2*erfi(np.sqrt(np.log((2+(b-a)**2*m)/2/(b-a)/k))))/8/m-p, 0.5).x[0]\n    x1 = np.sqrt(2*np.log((2+(a-b)**2*m)/2/(b-a)/k))\n    x1 = np.linspace(-x1,x1,n)\n    x4 = (a+b)/2 + np.exp(x1**2/2)*k/m - 1/(b-a)/m\n    x1 *= sigma1\n    axes['x1']['x4'].plot(x1, x4, ls)\n\n    axes['x0']['x4'].plot(x1, x4, ls)\n\naxes['x1']['x4'].plot(x1, b*np.ones_like(x1), ls)\naxes['x0']['x4'].plot(x1, b*np.ones_like(x1), ls)\n"""
images/animate.py,1,"b""from matplotlib.animation import FuncAnimation\nfrom anesthetic import NestedSamples\nroot = 'plikHM_TTTEEE_lowl_lowE_lensing_NS/NS_plikHM_TTTEEE_lowl_lowE_lensing'\nnested = NestedSamples.read(root=root)\n\nplotter = nested.gui(['omegam', 'H0', 'sigma8'])\nplotter.param_choice.buttons.set_active(1)\nplotter.param_choice.buttons.set_active(2)\nplotter.fig.set_size_inches(5, 6)\nplotter.fig.tight_layout()\n\n\ndef update(i):\n    print(i)\n    plotter.evolution.slider.set_val(i)\n    plotter.update(None)\n\n\nframes = np.arange(plotter.evolution.slider.valmin, 50000, 2000)\nanim = FuncAnimation(plotter.fig, update, frames=frames)\nanim.save('images/anim.gif', writer='imagemagick')\n"""
tests/matplotlib_agg.py,0,"b""import matplotlib\nmatplotlib.use('Agg')\n"""
tests/test_gui.py,0,"b""import matplotlib_agg  # noqa: F401\nfrom anesthetic import NestedSamples\n\n\ndef test_gui():\n    plotter = NestedSamples(root='./tests/example_data/pc').gui()\n\n    # Type buttons\n    plotter.type.buttons.set_active(0)\n    assert(plotter.type() == 'live')\n    plotter.type.buttons.set_active(1)\n    assert(plotter.type() == 'posterior')\n\n    # Parameter choice buttons\n    plotter.param_choice.buttons.set_active(1)\n    assert(len(plotter.triangle.ax) == 2)\n    plotter.param_choice.buttons.set_active(0)\n    assert(len(plotter.triangle.ax) == 1)\n    plotter.param_choice.buttons.set_active(0)\n    plotter.param_choice.buttons.set_active(2)\n    plotter.param_choice.buttons.set_active(3)\n    assert(len(plotter.triangle.ax) == 4)\n\n    # Sliders\n    plotter.evolution.slider.set_val(100)\n    assert(plotter.evolution() == 100)\n    plotter.type.buttons.set_active(1)\n    plotter.temperature.slider.set_val(0)\n    assert(plotter.temperature() == 1)\n\n    plotter.temperature.slider.set_val(1)\n    assert(plotter.temperature() == 10)\n    plotter.temperature.slider.set_val(2)\n    assert(plotter.temperature() == 100)\n    plotter.type.buttons.set_active(0)\n"""
tests/test_plot.py,34,"b'import matplotlib_agg  # noqa: F401\nimport pytest\nimport numpy as np\nimport sys\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gs\nfrom anesthetic.plot import (make_1d_axes, make_2d_axes, kde_plot_1d,\n                             fastkde_plot_1d, hist_plot_1d, hist_plot_2d,\n                             fastkde_contour_plot_2d, kde_contour_plot_2d,\n                             scatter_plot_2d)\nfrom numpy.testing import assert_array_equal\n\nfrom matplotlib.contour import QuadContourSet\nfrom matplotlib.tri import TriContourSet\nfrom matplotlib.lines import Line2D\nfrom matplotlib.patches import Patch, Polygon\nfrom matplotlib.colors import ColorConverter\nfrom matplotlib.figure import Figure\nfrom pandas.core.series import Series\nfrom pandas.core.frame import DataFrame\n\n\ndef test_make_1d_axes():\n    paramnames = [\'A\', \'B\', \'C\', \'D\', \'E\']\n    tex = {\'A\': \'tA\', \'B\': \'tB\', \'C\': \'tC\', \'D\': \'tD\', \'E\': \'tE\'}\n\n    # Check no optional arguments\n    fig, axes = make_1d_axes(paramnames)\n    assert(isinstance(fig, Figure))\n    assert(isinstance(axes, Series))\n    assert_array_equal(axes.index, paramnames)\n    for p, ax in axes.iteritems():\n        assert(ax.get_xlabel() == p)\n\n    # Check tex argument\n    fig, axes = make_1d_axes(paramnames, tex=tex)\n    for t in tex:\n        assert(axes[t].get_xlabel() != t)\n        assert(axes[t].get_xlabel() == tex[t])\n\n    # Check fig argument\n    fig0 = plt.figure()\n    fig0.suptitle(\'hi there\')\n    fig, axes = make_1d_axes(paramnames)\n    assert(fig is not fig0)\n    fig, axes = make_1d_axes(paramnames, fig=fig0)\n    assert(fig is fig0)\n\n    # Check ncols argument\n    fig, axes = make_1d_axes(paramnames, ncols=2)\n    nrows, ncols = axes[0].get_subplotspec().get_gridspec().get_geometry()\n    assert(ncols == 2)\n\n    # Check gridspec argument\n    grid = gs.GridSpec(2, 2, width_ratios=[3, 1], height_ratios=[3, 1])\n    g00 = grid[0, 0]\n    fig, axes = make_1d_axes(paramnames, subplot_spec=g00)\n    assert(g00 is axes[0].get_subplotspec().get_topmost_subplotspec())\n\n    # Check unexpected kwargs\n    with pytest.raises(TypeError):\n        make_1d_axes(paramnames, foo=\'bar\')\n    plt.close(""all"")\n\n\ndef test_make_2d_axes_inputs_outputs():\n    paramnames_x = [\'A\', \'B\', \'C\', \'D\']\n    paramnames_y = [\'B\', \'A\', \'D\', \'E\']\n\n    # 2D axes\n    fig, axes = make_2d_axes([paramnames_x, paramnames_y])\n    assert(isinstance(fig, Figure))\n    assert(isinstance(axes, DataFrame))\n    assert_array_equal(axes.index, paramnames_y)\n    assert_array_equal(axes.columns, paramnames_x)\n\n    # Axes labels\n    for p, ax in axes.iloc[:, 0].iteritems():\n        assert(ax.get_ylabel() == p)\n\n    for p, ax in axes.iloc[-1].iteritems():\n        assert(ax.get_xlabel() == p)\n\n    for ax in axes.iloc[:-1, 1:].values.flatten():\n        assert(ax.get_xlabel() == \'\')\n        assert(ax.get_ylabel() == \'\')\n\n    # Check fig argument\n    fig0 = plt.figure()\n    fig, axes = make_2d_axes(paramnames_x)\n    assert(fig is not fig0)\n    fig, axes = make_2d_axes(paramnames_x, fig=fig0)\n    assert(fig is fig0)\n    plt.close(""all"")\n\n    # Check gridspec argument\n    grid = gs.GridSpec(2, 2, width_ratios=[3, 1], height_ratios=[3, 1])\n    g00 = grid[0, 0]\n    fig, axes = make_2d_axes(paramnames_x, subplot_spec=g00)\n    assert(g00 is axes.iloc[0, 0].get_subplotspec().get_topmost_subplotspec())\n\n    # Check unexpected kwargs\n    with pytest.raises(TypeError):\n        make_2d_axes(paramnames_x, foo=\'bar\')\n\n\ndef test_make_2d_axes_behaviour():\n    np.random.seed(0)\n\n    def calc_n(axes):\n        """"""Compute the number of upper, lower and diagonal plots.""""""\n        n = {\'upper\': 0, \'lower\': 0, \'diagonal\': 0}\n        for y, row in axes.iterrows():\n            for x, ax in row.iteritems():\n                if ax is not None:\n                    n[ax.position] += 1\n        return n\n\n    # Check for only paramnames_x\n    paramnames_x = [\'A\', \'B\', \'C\', \'D\']\n    nx = len(paramnames_x)\n    for upper in [True, False]:\n        for lower in [True, False]:\n            for diagonal in [True, False]:\n                fig, axes = make_2d_axes(paramnames_x,\n                                         upper=upper,\n                                         lower=lower,\n                                         diagonal=diagonal)\n                ns = calc_n(axes)\n                assert(ns[\'upper\'] == upper * nx*(nx-1)//2)\n                assert(ns[\'lower\'] == lower * nx*(nx-1)//2)\n                assert(ns[\'diagonal\'] == diagonal * nx)\n\n    plt.close(""all"")\n\n    for paramnames_y in [[\'A\', \'B\', \'C\', \'D\'],\n                         [\'A\', \'C\', \'B\', \'D\'],\n                         [\'D\', \'C\', \'B\', \'A\'],\n                         [\'C\', \'B\', \'A\'],\n                         [\'E\', \'F\', \'G\', \'H\'],\n                         [\'A\', \'B\', \'E\', \'F\'],\n                         [\'B\', \'E\', \'A\', \'F\'],\n                         [\'B\', \'F\', \'A\', \'H\', \'G\'],\n                         [\'B\', \'A\', \'H\', \'G\']]:\n        params = [paramnames_x, paramnames_y]\n        all_params = paramnames_x + paramnames_y\n\n        nu, nl, nd = 0, 0, 0\n        for x in paramnames_x:\n            for y in paramnames_y:\n                if x == y:\n                    nd += 1\n                elif all_params.index(x) < all_params.index(y):\n                    nl += 1\n                elif all_params.index(x) > all_params.index(y):\n                    nu += 1\n\n        for upper in [True, False]:\n            for lower in [True, False]:\n                for diagonal in [True, False]:\n                    fig, axes = make_2d_axes(params,\n                                             upper=upper,\n                                             lower=lower,\n                                             diagonal=diagonal)\n                    ns = calc_n(axes)\n                    assert(ns[\'upper\'] == upper * nu)\n                    assert(ns[\'lower\'] == lower * nl)\n                    assert(ns[\'diagonal\'] == diagonal * nd)\n        plt.close(""all"")\n\n\ndef test_2d_axes_limits():\n    np.random.seed(0)\n    paramnames = [\'A\', \'B\', \'C\', \'D\']\n    fig, axes = make_2d_axes(paramnames)\n    for x in paramnames:\n        for y in paramnames:\n            a, b, c, d = np.random.rand(4)\n            axes[x][y].set_xlim(a, b)\n            for z in paramnames:\n                assert(axes[x][z].get_xlim() == (a, b))\n                assert(axes[z][x].get_ylim() == (a, b))\n\n            axes[x][y].set_ylim(c, d)\n            for z in paramnames:\n                assert(axes[y][z].get_xlim() == (c, d))\n                assert(axes[z][y].get_ylim() == (c, d))\n\n\ndef test_kde_plot_1d():\n    fig, ax = plt.subplots()\n    np.random.seed(0)\n    data = np.random.randn(1000)\n\n    for plot_1d in [kde_plot_1d, fastkde_plot_1d]:\n        try:\n            # Check height\n            line, = plot_1d(ax, data)\n            assert(isinstance(line, Line2D))\n            assert(line.get_ydata().max() <= 1)\n\n            # Check arguments are passed onward to underlying function\n            line, = plot_1d(ax, data, color=\'r\')\n            assert(line.get_color() == \'r\')\n\n            # Check xmin\n            xmin = -0.5\n            line, = plot_1d(ax, data, xmin=xmin)\n            assert((line.get_xdata() >= xmin).all())\n\n            # Check xmax\n            xmax = 0.5\n            line, = plot_1d(ax, data, xmax=xmax)\n            assert((line.get_xdata() <= xmax).all())\n\n            # Check xmin and xmax\n            line, = plot_1d(ax, data, xmin=xmin, xmax=xmax)\n            assert((line.get_xdata() <= xmax).all())\n            assert((line.get_xdata() >= xmin).all())\n            plt.close(""all"")\n        except ImportError:\n            if \'fastkde\' not in sys.modules:\n                pass\n\n\ndef test_hist_plot_1d():\n    fig, ax = plt.subplots()\n    np.random.seed(0)\n    data = np.random.randn(1000)\n    for p in [\'\', \'astropyhist\']:\n        try:\n            # Check heights for histtype \'bar\'\n            bars = hist_plot_1d(ax, data, histtype=\'bar\', plotter=p)\n            assert(np.all([isinstance(b, Patch) for b in bars]))\n            assert(max([b.get_height() for b in bars]) == 1.)\n            assert(np.all(np.array([b.get_height() for b in bars]) <= 1.))\n\n            # Check heights for histtype \'step\'\n            polygon, = hist_plot_1d(ax, data, histtype=\'step\', plotter=p)\n            assert(isinstance(polygon, Polygon))\n            trans = polygon.get_transform() - ax.transData\n            assert(np.isclose(trans.transform(polygon.xy)[:, -1].max(), 1.,\n                              rtol=1e-10, atol=1e-10))\n            assert(np.all(trans.transform(polygon.xy)[:, -1] <= 1.))\n\n            # Check heights for histtype \'stepfilled\'\n            polygon, = hist_plot_1d(ax, data, histtype=\'stepfilled\', plotter=p)\n            assert(isinstance(polygon, Polygon))\n            trans = polygon.get_transform() - ax.transData\n            assert(np.isclose(trans.transform(polygon.xy)[:, -1].max(), 1.,\n                              rtol=1e-10, atol=1e-10))\n            assert(np.all(trans.transform(polygon.xy)[:, -1] <= 1.))\n\n            # Check arguments are passed onward to underlying function\n            bars = hist_plot_1d(ax, data, histtype=\'bar\',\n                                color=\'r\', alpha=0.5, plotter=p)\n            cc = ColorConverter.to_rgba(\'r\', alpha=0.5)\n            assert(np.all([b.get_fc() == cc for b in bars]))\n            polygon, = hist_plot_1d(ax, data, histtype=\'step\',\n                                    color=\'r\', alpha=0.5, plotter=p)\n            assert(polygon.get_ec() == ColorConverter.to_rgba(\'r\', alpha=0.5))\n\n            # Check xmin\n            for xmin in [-np.inf, -0.5]:\n                bars = hist_plot_1d(ax, data, histtype=\'bar\',\n                                    xmin=xmin, plotter=p)\n                assert((np.array([b.xy[0] for b in bars]) >= xmin).all())\n                polygon, = hist_plot_1d(ax, data, histtype=\'step\', xmin=xmin)\n                assert((polygon.xy[:, 0] >= xmin).all())\n\n            # Check xmax\n            for xmax in [np.inf, 0.5]:\n                bars = hist_plot_1d(ax, data, histtype=\'bar\',\n                                    xmax=xmax, plotter=p)\n                assert((np.array([b.xy[-1] for b in bars]) <= xmax).all())\n                polygon, = hist_plot_1d(ax, data, histtype=\'step\',\n                                        xmax=xmax, plotter=p)\n                assert((polygon.xy[:, 0] <= xmax).all())\n\n            # Check xmin and xmax\n            bars = hist_plot_1d(ax, data, histtype=\'bar\',\n                                xmin=xmin, xmax=xmax, plotter=p)\n            assert((np.array([b.xy[0] for b in bars]) >= -0.5).all())\n            assert((np.array([b.xy[-1] for b in bars]) <= 0.5).all())\n            polygon, = hist_plot_1d(ax, data, histtype=\'step\',\n                                    xmin=xmin, xmax=xmax, plotter=p)\n            assert((polygon.xy[:, 0] >= -0.5).all())\n            assert((polygon.xy[:, 0] <= 0.5).all())\n            plt.close(""all"")\n        except ImportError:\n            if p == \'astropyhist\' and \'astropy\' not in sys.modules:\n                pass\n\n\ndef test_hist_plot_2d():\n    fig, ax = plt.subplots()\n    np.random.seed(0)\n    data_x, data_y = np.random.randn(2, 10000)\n    hist_plot_2d(ax, data_x, data_y)\n    xmin, xmax = ax.get_xlim()\n    ymin, ymax = ax.get_ylim()\n    assert xmin > -3 and xmax < 3 and ymin > -3 and ymax < 3\n\n    hist_plot_2d(ax, data_x, data_y, xmin=-np.inf)\n    hist_plot_2d(ax, data_x, data_y, xmax=np.inf)\n    hist_plot_2d(ax, data_x, data_y, ymin=-np.inf)\n    hist_plot_2d(ax, data_x, data_y, ymax=np.inf)\n    assert xmin > -3 and xmax < 3 and ymin > -3 and ymax < 3\n\n    data_x, data_y = np.random.uniform(-10, 10, (2, 1000000))\n    weights = np.exp(-(data_x**2 + data_y**2)/2)\n    hist_plot_2d(ax, data_x, data_y, weights=weights, bins=30)\n    xmin, xmax = ax.get_xlim()\n    ymin, ymax = ax.get_ylim()\n    assert xmin > -3 and xmax < 3 and ymin > -3 and ymax < 3\n\n\ndef test_contour_plot_2d():\n    for contour_plot_2d in [kde_contour_plot_2d, fastkde_contour_plot_2d]:\n        try:\n            ax = plt.gca()\n            np.random.seed(1)\n            data_x = np.random.randn(1000)\n            data_y = np.random.randn(1000)\n            c = contour_plot_2d(ax, data_x, data_y)\n            if contour_plot_2d is fastkde_contour_plot_2d:\n                assert(isinstance(c, QuadContourSet))\n            elif contour_plot_2d is kde_contour_plot_2d:\n                assert(isinstance(c, TriContourSet))\n\n            xmin, xmax, ymin, ymax = -0.5, 0.5, -0.5, 0.5\n\n            # Check xmin\n            ax = plt.gca()\n            contour_plot_2d(ax, data_x, data_y, xmin=xmin)\n            assert(ax.get_xlim()[0] >= xmin)\n            plt.close()\n\n            # Check xmax\n            ax = plt.gca()\n            contour_plot_2d(ax, data_x, data_y, xmax=xmax)\n            assert(ax.get_xlim()[1] <= xmax)\n            plt.close()\n\n            # Check xmin and xmax\n            ax = plt.gca()\n            contour_plot_2d(ax, data_x, data_y, xmin=xmin, xmax=xmax)\n            assert(ax.get_xlim()[1] <= xmax)\n            assert(ax.get_xlim()[0] >= xmin)\n            plt.close()\n\n            # Check ymin\n            ax = plt.gca()\n            contour_plot_2d(ax, data_x, data_y, ymin=ymin)\n            assert(ax.get_ylim()[0] >= ymin)\n            plt.close()\n\n            # Check ymax\n            ax = plt.gca()\n            contour_plot_2d(ax, data_x, data_y, ymax=ymax)\n            assert(ax.get_ylim()[1] <= ymax)\n            plt.close()\n\n            # Check ymin and ymax\n            ax = plt.gca()\n            contour_plot_2d(ax, data_x, data_y, ymin=ymin, ymax=ymax)\n            assert(ax.get_ylim()[1] <= ymax)\n            assert(ax.get_ylim()[0] >= ymin)\n            plt.close()\n        except ImportError:\n            if \'fastkde\' not in sys.modules:\n                pass\n\n\ndef test_scatter_plot_2d():\n    fig, ax = plt.subplots()\n    np.random.seed(2)\n    data_x = np.random.randn(1000)\n    data_y = np.random.randn(1000)\n    lines, = scatter_plot_2d(ax, data_x, data_y)\n    assert(isinstance(lines, Line2D))\n\n    xmin, xmax, ymin, ymax = -0.5, 0.5, -0.5, 0.5\n    ax = plt.gca()\n    scatter_plot_2d(ax, data_x, data_y, xmin=xmin)\n    assert(ax.get_xlim()[0] >= xmin)\n    plt.close()\n\n    ax = plt.gca()\n    scatter_plot_2d(ax, data_x, data_y, xmax=xmax)\n    assert(ax.get_xlim()[1] <= xmax)\n    plt.close()\n\n    ax = plt.gca()\n    scatter_plot_2d(ax, data_x, data_y, ymin=ymin)\n    assert(ax.get_ylim()[0] >= ymin)\n    plt.close()\n\n    ax = plt.gca()\n    scatter_plot_2d(ax, data_x, data_y, ymax=ymax)\n    assert(ax.get_ylim()[1] <= ymax)\n    plt.close()\n'"
tests/test_samples.py,43,"b'import matplotlib_agg  # noqa: F401\nimport os\nimport sys\nimport pytest\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nfrom matplotlib.patches import Rectangle\nfrom anesthetic import MCMCSamples, NestedSamples, make_1d_axes, make_2d_axes\nfrom anesthetic.samples import merge_nested_samples\nfrom numpy.testing import assert_array_equal, assert_array_almost_equal\nfrom matplotlib.colors import to_hex\nfrom scipy.stats import ks_2samp\ntry:\n    import montepython  # noqa: F401\nexcept ImportError:\n    pass\n\n\ndef test_build_mcmc():\n    np.random.seed(3)\n    nsamps = 1000\n    ndims = 3\n    samples = np.random.randn(nsamps, ndims)\n    logL = np.random.rand(nsamps)\n    w = np.random.randint(1, 20, size=nsamps)\n    params = [\'A\', \'B\', \'C\']\n    tex = {\'A\': \'$A$\', \'B\': \'$B$\', \'C\': \'$C$\'}\n    limits = {\'A\': (-1, 1), \'B\': (-2, 2), \'C\': (-3, 3)}\n\n    mcmc = MCMCSamples(data=samples)\n    assert(len(mcmc) == nsamps)\n    assert_array_equal(mcmc.columns, np.array([0, 1, 2], dtype=object))\n\n    mcmc = MCMCSamples(data=samples, logL=logL)\n    assert(len(mcmc) == nsamps)\n    assert_array_equal(mcmc.columns, np.array([0, 1, 2, \'logL\'], dtype=object))\n\n    mcmc = MCMCSamples(data=samples, w=w)\n    assert(len(mcmc) == nsamps)\n    assert_array_equal(mcmc.columns, np.array([0, 1, 2, \'weight\'],\n                                              dtype=object))\n\n    mcmc = MCMCSamples(data=samples, w=w, logL=logL)\n    assert(len(mcmc) == nsamps)\n    assert_array_equal(mcmc.columns, np.array([0, 1, 2, \'logL\', \'weight\'],\n                                              dtype=object))\n\n    mcmc = MCMCSamples(data=samples, columns=params)\n    assert(len(mcmc) == nsamps)\n    assert_array_equal(mcmc.columns, [\'A\', \'B\', \'C\'])\n\n    mcmc = MCMCSamples(data=samples, tex=tex)\n    for p in params:\n        assert(mcmc.tex[p] == tex[p])\n\n    mcmc = MCMCSamples(data=samples, limits=limits)\n    for p in params:\n        assert(mcmc.limits[p] == limits[p])\n\n    ns = NestedSamples(data=samples, logL=logL, w=w)\n    assert(len(ns) == nsamps)\n    assert(np.all(np.isfinite(ns.logL)))\n    logL[:10] = -1e300\n    w[:10] = 0.\n    mcmc = MCMCSamples(data=samples, logL=logL, w=w, logzero=-1e29)\n    ns = NestedSamples(data=samples, logL=logL, w=w, logzero=-1e29)\n    assert_array_equal(mcmc.columns, np.array([0, 1, 2, \'logL\', \'weight\'],\n                                              dtype=object))\n    assert_array_equal(ns.columns, np.array([0, 1, 2, \'logL\', \'weight\'],\n                                            dtype=object))\n    assert(np.all(mcmc.logL[:10] == -np.inf))\n    assert(np.all(ns.logL[:10] == -np.inf))\n    assert(np.all(mcmc.logL[10:] == logL[10:]))\n    assert(np.all(ns.logL[10:] == logL[10:]))\n\n    mcmc = MCMCSamples(data=samples, logL=logL, w=w, logzero=-1e301)\n    ns = NestedSamples(data=samples, logL=logL, w=w, logzero=-1e301)\n    assert(np.all(np.isfinite(mcmc.logL)))\n    assert(np.all(np.isfinite(ns.logL)))\n    assert(np.all(mcmc.logL == logL))\n    assert(np.all(ns.logL == logL))\n\n    assert(mcmc.root is None)\n\n\ndef test_read_getdist():\n    np.random.seed(3)\n    mcmc = MCMCSamples(root=\'./tests/example_data/gd\')\n    mcmc.plot_2d([\'x0\', \'x1\', \'x2\', \'x3\'])\n    mcmc.plot_1d([\'x0\', \'x1\', \'x2\', \'x3\'])\n\n    mcmc = MCMCSamples(root=\'./tests/example_data/gd_single\')\n    mcmc.plot_2d([\'x0\', \'x1\', \'x2\', \'x3\'])\n    mcmc.plot_1d([\'x0\', \'x1\', \'x2\', \'x3\'])\n    plt.close(""all"")\n\n\n@pytest.mark.xfail(\'montepython\' not in sys.modules,\n                   raises=ImportError,\n                   reason=""requires montepython package"")\ndef test_read_montepython():\n    np.random.seed(3)\n    mcmc = MCMCSamples(root=\'./tests/example_data/mp\')\n    mcmc.plot_2d([\'x0\', \'x1\', \'x2\', \'x3\'])\n    mcmc.plot_1d([\'x0\', \'x1\', \'x2\', \'x3\'])\n    plt.close(""all"")\n\n\ndef test_read_multinest():\n    np.random.seed(3)\n    ns = NestedSamples(root=\'./tests/example_data/mn\')\n    ns.plot_2d([\'x0\', \'x1\', \'x2\', \'x3\'])\n    ns.plot_1d([\'x0\', \'x1\', \'x2\', \'x3\'])\n\n    ns = NestedSamples(root=\'./tests/example_data/mn_old\')\n    ns.plot_2d([\'x0\', \'x1\', \'x2\', \'x3\'])\n    ns.plot_1d([\'x0\', \'x1\', \'x2\', \'x3\'])\n    plt.close(""all"")\n\n\ndef test_read_polychord():\n    np.random.seed(3)\n    ns = NestedSamples(root=\'./tests/example_data/pc\')\n    ns.plot_2d([\'x0\', \'x1\', \'x2\', \'x3\'])\n    ns.plot_1d([\'x0\', \'x1\', \'x2\', \'x3\'])\n    plt.close(""all"")\n\n    os.rename(\'./tests/example_data/pc_phys_live-birth.txt\',\n              \'./tests/example_data/pc_phys_live-birth.txt_\')\n    ns_nolive = NestedSamples(root=\'./tests/example_data/pc\')\n    os.rename(\'./tests/example_data/pc_phys_live-birth.txt_\',\n              \'./tests/example_data/pc_phys_live-birth.txt\')\n\n    cols = [\'x0\', \'x1\', \'x2\', \'x3\', \'x4\', \'logL\', \'logL_birth\']\n    assert_array_equal(ns_nolive[cols], ns[cols][:ns_nolive.shape[0]])\n\n\ndef test_NS_input_fails_in_MCMCSamples():\n    with pytest.raises(ValueError) as excinfo:\n        MCMCSamples(root=\'./tests/example_data/pc\')\n    assert ""Please use NestedSamples instead which has the same features as "" \\\n           ""MCMCSamples and more. MCMCSamples should be used for MCMC "" \\\n           ""chains only."" in str(excinfo.value)\n\n\ndef test_different_parameters():\n    np.random.seed(3)\n    params_x = [\'x0\', \'x1\', \'x2\', \'x3\', \'x4\']\n    params_y = [\'x0\', \'x1\', \'x2\']\n    fig, axes = make_1d_axes(params_x)\n    ns = NestedSamples(root=\'./tests/example_data/pc\')\n    ns.plot_1d(axes)\n    fig, axes = make_2d_axes(params_y)\n    ns.plot_2d(axes)\n    fig, axes = make_2d_axes(params_x)\n    ns.plot_2d(axes)\n    fig, axes = make_2d_axes([params_x, params_y])\n    ns.plot_2d(axes)\n    plt.close(\'all\')\n\n\ndef test_manual_columns():\n    old_params = [\'x0\', \'x1\', \'x2\', \'x3\', \'x4\']\n    mcmc_params = [\'logL\', \'weight\']\n    ns_params = [\'logL\', \'logL_birth\', \'nlive\', \'weight\']\n    mcmc = MCMCSamples(root=\'./tests/example_data/gd\')\n    ns = NestedSamples(root=\'./tests/example_data/pc\')\n    assert_array_equal(mcmc.columns, old_params + mcmc_params)\n    assert_array_equal(ns.columns, old_params + ns_params)\n\n    new_params = [\'y0\', \'y1\', \'y2\', \'y3\', \'y4\']\n    mcmc = MCMCSamples(root=\'./tests/example_data/gd\', columns=new_params)\n    ns = NestedSamples(root=\'./tests/example_data/pc\', columns=new_params)\n    assert_array_equal(mcmc.columns, new_params + mcmc_params)\n    assert_array_equal(ns.columns, new_params + ns_params)\n\n\ndef test_plot_2d_types():\n    np.random.seed(3)\n    ns = NestedSamples(root=\'./tests/example_data/pc\')\n    params_x = [\'x0\', \'x1\', \'x2\', \'x3\']\n    params_y = [\'x0\', \'x1\', \'x2\']\n    params = [params_x, params_y]\n    # Test old interface\n    fig, axes = ns.plot_2d(params, types=[\'kde\', \'scatter\'])\n    assert((~axes.isnull()).sum().sum() == 12)\n\n    fig, axes = ns.plot_2d(params, types=\'kde\')\n    assert((~axes.isnull()).sum().sum() == 6)\n\n    fig, axes = ns.plot_2d(params, types=\'kde\', diagonal=False)\n    assert((~axes.isnull()).sum().sum() == 3)\n\n    # Test new interface\n    fig, axes = ns.plot_2d(params, types={\'lower\': \'kde\'})\n    assert((~axes.isnull()).sum().sum() == 3)\n\n    fig, axes = ns.plot_2d(params, types={\'upper\': \'scatter\'})\n    assert((~axes.isnull()).sum().sum() == 6)\n\n    fig, axes = ns.plot_2d(params, types={\'upper\': \'kde\', \'diagonal\': \'kde\'})\n    assert((~axes.isnull()).sum().sum() == 9)\n\n    fig, axes = ns.plot_2d(params, types={\'lower\': \'kde\', \'diagonal\': \'kde\'})\n    assert((~axes.isnull()).sum().sum() == 6)\n\n    fig, axes = ns.plot_2d(params, types={\'lower\': \'kde\', \'diagonal\': \'kde\',\n                                          \'upper\': \'scatter\'})\n    assert((~axes.isnull()).sum().sum() == 12)\n    plt.close(""all"")\n\n\ndef test_plot_2d_types_multiple_calls():\n    np.random.seed(3)\n    ns = NestedSamples(root=\'./tests/example_data/pc\')\n    params = [\'x0\', \'x1\', \'x2\', \'x3\']\n\n    fig, axes = ns.plot_2d(params, types={\'diagonal\': \'kde\',\n                                          \'lower\': \'kde\',\n                                          \'upper\': \'scatter\'})\n    ns.plot_2d(axes, types={\'diagonal\': \'hist\'})\n\n    fig, axes = ns.plot_2d(params, types={\'diagonal\': \'hist\'})\n    ns.plot_2d(axes, types={\'diagonal\': \'kde\',\n                            \'lower\': \'kde\',\n                            \'upper\': \'scatter\'})\n    plt.close(\'all\')\n\n\ndef test_root_and_label():\n    np.random.seed(3)\n    ns = NestedSamples(root=\'./tests/example_data/pc\')\n    assert(ns.root == \'./tests/example_data/pc\')\n    assert(ns.label == \'pc\')\n\n    ns = NestedSamples()\n    assert(ns.root is None)\n    assert(ns.label is None)\n\n    mc = MCMCSamples(root=\'./tests/example_data/gd\')\n    assert (mc.root == \'./tests/example_data/gd\')\n    assert(mc.label == \'gd\')\n\n    mc = MCMCSamples()\n    assert(mc.root is None)\n    assert(mc.label is None)\n\n\ndef test_plot_2d_legend():\n    np.random.seed(3)\n    ns = NestedSamples(root=\'./tests/example_data/pc\')\n    mc = MCMCSamples(root=\'./tests/example_data/gd\')\n    params = [\'x0\', \'x1\', \'x2\', \'x3\']\n\n    # Test label kwarg for kde\n    fig, axes = make_2d_axes(params, upper=False)\n    ns.plot_2d(axes, label=\'l1\', types=dict(diagonal=\'kde\', lower=\'kde\'))\n    mc.plot_2d(axes, label=\'l2\', types=dict(diagonal=\'kde\', lower=\'kde\'))\n\n    for y, row in axes.iterrows():\n        for x, ax in row.iteritems():\n            if ax is not None:\n                handles, labels = ax.get_legend_handles_labels()\n                assert(labels == [\'l1\', \'l2\'])\n                if x == y:\n                    assert(all([isinstance(h, Line2D) for h in handles]))\n                else:\n                    assert(all([isinstance(h, Rectangle) for h in handles]))\n    plt.close(\'all\')\n\n    # Test label kwarg for hist and scatter\n    fig, axes = make_2d_axes(params, lower=False)\n    ns.plot_2d(axes, label=\'l1\', types=dict(diagonal=\'hist\', upper=\'scatter\'))\n    mc.plot_2d(axes, label=\'l2\', types=dict(diagonal=\'hist\', upper=\'scatter\'))\n\n    for y, row in axes.iterrows():\n        for x, ax in row.iteritems():\n            if ax is not None:\n                handles, labels = ax.get_legend_handles_labels()\n                assert(labels == [\'l1\', \'l2\'])\n                if x == y:\n                    assert(all([isinstance(h, Rectangle) for h in handles]))\n                else:\n                    assert(all([isinstance(h, Line2D)\n                                for h in handles]))\n    plt.close(\'all\')\n\n    # test default labelling\n    fig, axes = make_2d_axes(params, upper=False)\n    ns.plot_2d(axes)\n    mc.plot_2d(axes)\n\n    for y, row in axes.iterrows():\n        for x, ax in row.iteritems():\n            if ax is not None:\n                handles, labels = ax.get_legend_handles_labels()\n                assert(labels == [\'pc\', \'gd\'])\n    plt.close(\'all\')\n\n    # Test label kwarg to constructors\n    ns = NestedSamples(root=\'./tests/example_data/pc\', label=\'l1\')\n    mc = MCMCSamples(root=\'./tests/example_data/gd\', label=\'l2\')\n    params = [\'x0\', \'x1\', \'x2\', \'x3\']\n\n    fig, axes = make_2d_axes(params, upper=False)\n    ns.plot_2d(axes)\n    mc.plot_2d(axes)\n\n    for y, row in axes.iterrows():\n        for x, ax in row.iteritems():\n            if ax is not None:\n                handles, labels = ax.get_legend_handles_labels()\n                assert(labels == [\'l1\', \'l2\'])\n    plt.close(\'all\')\n\n\ndef test_plot_2d_colours():\n    np.random.seed(3)\n    gd = MCMCSamples(root=""./tests/example_data/gd"")\n    gd.drop(columns=\'x3\', inplace=True)\n    pc = NestedSamples(root=""./tests/example_data/pc"")\n    pc.drop(columns=\'x4\', inplace=True)\n    mn = NestedSamples(root=""./tests/example_data/mn"")\n    mn.drop(columns=\'x2\', inplace=True)\n\n    plot_types = [\'kde\', \'hist\']\n    if \'fastkde\' in sys.modules:\n        plot_types += [\'fastkde\']\n\n    for types in plot_types:\n        fig = plt.figure()\n        fig, axes = make_2d_axes([\'x0\', \'x1\', \'x2\', \'x3\', \'x4\'], fig=fig)\n        types = {\'diagonal\': types, \'lower\': types, \'upper\': \'scatter\'}\n        gd.plot_2d(axes, types=types, label=""gd"")\n        pc.plot_2d(axes, types=types, label=""pc"")\n        mn.plot_2d(axes, types=types, label=""mn"")\n        gd_colors = []\n        pc_colors = []\n        mn_colors = []\n        for y, rows in axes.iterrows():\n            for x, ax in rows.iteritems():\n                handles, labels = ax.get_legend_handles_labels()\n                for handle, label in zip(handles, labels):\n                    if isinstance(handle, Rectangle):\n                        color = to_hex(handle.get_facecolor())\n                    else:\n                        color = handle.get_color()\n\n                    if label == \'gd\':\n                        gd_colors.append(color)\n                    elif label == \'pc\':\n                        pc_colors.append(color)\n                    elif label == \'mn\':\n                        mn_colors.append(color)\n\n        assert(len(set(gd_colors)) == 1)\n        assert(len(set(mn_colors)) == 1)\n        assert(len(set(pc_colors)) == 1)\n        plt.close(""all"")\n\n\ndef test_plot_1d_colours():\n    np.random.seed(3)\n    gd = MCMCSamples(root=""./tests/example_data/gd"")\n    gd.drop(columns=\'x3\', inplace=True)\n    pc = NestedSamples(root=""./tests/example_data/pc"")\n    pc.drop(columns=\'x4\', inplace=True)\n    mn = NestedSamples(root=""./tests/example_data/mn"")\n    mn.drop(columns=\'x2\', inplace=True)\n\n    plot_types = [\'kde\', \'hist\']\n    if \'astropy\' in sys.modules:\n        plot_types += [\'astropyhist\']\n    if \'fastkde\' in sys.modules:\n        plot_types += [\'fastkde\']\n\n    for plot_type in plot_types:\n        fig = plt.figure()\n        fig, axes = make_1d_axes([\'x0\', \'x1\', \'x2\', \'x3\', \'x4\'], fig=fig)\n        gd.plot_1d(axes, plot_type=plot_type, label=""gd"")\n        pc.plot_1d(axes, plot_type=plot_type, label=""pc"")\n        mn.plot_1d(axes, plot_type=plot_type, label=""mn"")\n        gd_colors = []\n        pc_colors = []\n        mn_colors = []\n        for x, ax in axes.iteritems():\n            handles, labels = ax.get_legend_handles_labels()\n            for handle, label in zip(handles, labels):\n                if isinstance(handle, Rectangle):\n                    color = to_hex(handle.get_facecolor())\n                else:\n                    color = handle.get_color()\n\n                if label == \'gd\':\n                    gd_colors.append(color)\n                elif label == \'pc\':\n                    pc_colors.append(color)\n                elif label == \'mn\':\n                    mn_colors.append(color)\n\n        assert(len(set(gd_colors)) == 1)\n        assert(len(set(mn_colors)) == 1)\n        assert(len(set(pc_colors)) == 1)\n        plt.close(""all"")\n\n\n@pytest.mark.xfail(\'astropy\' not in sys.modules,\n                   raises=ImportError,\n                   reason=""requires astropy package"")\ndef test_astropyhist():\n    np.random.seed(3)\n    mcmc = NestedSamples(root=\'./tests/example_data/pc\')\n    mcmc.plot_2d([\'x0\', \'x1\', \'x2\', \'x3\'], types={\'diagonal\': \'astropyhist\'})\n    mcmc.plot_1d([\'x0\', \'x1\', \'x2\', \'x3\'], plot_type=\'astropyhist\')\n    plt.close(""all"")\n\n\ndef test_hist_levels():\n    np.random.seed(3)\n    mcmc = NestedSamples(root=\'./tests/example_data/pc\')\n    mcmc.plot_2d([\'x0\', \'x1\', \'x2\', \'x3\'], types={\'lower\': \'hist\'},\n                 levels=[0.68, 0.95], bins=20)\n    plt.close(""all"")\n\n\ndef test_ns_output():\n    np.random.seed(3)\n    pc = NestedSamples(root=\'./tests/example_data/pc\')\n    for beta in [1., 0., 0.5]:\n        pc.beta = beta\n        n = 1000\n        PC = pc.ns_output(n)\n        assert abs(pc.logZ() - PC[\'logZ\'].mean()) < PC[\'logZ\'].std()\n        assert PC[\'d\'].mean() < 5\n        assert PC.cov()[\'D\'][\'logZ\'] < 0\n        assert(abs(PC.logZ.mean() - pc.logZ()) < PC.logZ.std() * n**0.5 * 2)\n        assert(abs(PC.D.mean() - pc.D()) < PC.D.std() * n**0.5 * 2)\n        assert(abs(PC.d.mean() - pc.d()) < PC.d.std() * n**0.5 * 2)\n\n        n = 100\n        assert(ks_2samp(pc.logZ(n), PC.logZ).pvalue > 0.05)\n        assert(ks_2samp(pc.D(n), PC.D).pvalue > 0.05)\n        assert(ks_2samp(pc.d(n), PC.d).pvalue > 0.05)\n\n    assert abs(pc.set_beta(0.0).logZ()) < 1e-2\n    assert pc.set_beta(0.9).logZ() < pc.set_beta(1.0).logZ()\n\n\ndef test_masking():\n    pc = NestedSamples(root=""./tests/example_data/pc"")\n    mask = pc[\'x0\'] > 0\n\n    plot_types = [\'kde\', \'hist\']\n    if \'fastkde\' in sys.modules:\n        plot_types += [\'fastkde\']\n\n    for ptype in plot_types:\n        fig, axes = make_1d_axes([\'x0\', \'x1\', \'x2\'])\n        pc[mask].plot_1d(axes=axes, plot_type=ptype)\n\n    for ptype in plot_types + [\'scatter\']:\n        fig, axes = make_2d_axes([\'x0\', \'x1\', \'x2\'], upper=False)\n        pc[mask].plot_2d(axes=axes, types=dict(lower=ptype, diagonal=\'hist\'))\n\n\ndef test_merging():\n    np.random.seed(3)\n    samples_1 = NestedSamples(root=\'./tests/example_data/pc\')\n    samples_2 = NestedSamples(root=\'./tests/example_data/pc_250\')\n    samples = merge_nested_samples([samples_1, samples_2])\n    nlive_1 = samples_1.nlive.mode()[0]\n    nlive_2 = samples_2.nlive.mode()[0]\n    nlive = samples.nlive.mode()[0]\n    assert nlive_1 == 125\n    assert nlive_2 == 250\n    assert nlive == nlive_1 + nlive_2\n    assert (samples.logZ() < samples_1.logZ()\n            and samples.logZ() > samples_2.logZ()\n            or samples.logZ() > samples_1.logZ()\n            and samples.logZ() < samples_2.logZ())\n\n\ndef test_beta():\n    pc = NestedSamples(root=""./tests/example_data/pc"")\n    weight = pc.weight\n    assert_array_equal(pc[\'weight\'], pc.weight)\n    assert pc.beta == 1\n\n    prior = pc.set_beta(0)\n    assert prior.beta == 0\n    assert_array_equal(prior[\'weight\'], prior.weight)\n    assert pc.beta == 1\n    assert_array_equal(pc[\'weight\'], pc.weight)\n    assert_array_almost_equal(sorted(prior.weight, reverse=True), prior.weight)\n\n    for beta in np.linspace(0, 2, 10):\n        pc.set_beta(beta, inplace=True)\n        assert pc.beta == beta\n        assert_array_equal(pc[\'weight\'], pc.weight)\n        assert not np.array_equal(pc[\'weight\'], weight)\n\n    for beta in np.linspace(0, 2, 10):\n        pc.beta = beta\n        assert pc.beta == beta\n        assert_array_equal(pc[\'weight\'], pc.weight)\n        assert not np.array_equal(pc[\'weight\'], weight)\n\n\ndef test_beta_with_logL_infinities():\n    ns = NestedSamples(root=""./tests/example_data/pc"")\n    for i in range(10):\n        ns.loc[i, \'logL\'] = -np.inf\n    prior = ns.set_beta(0)\n    assert np.all(prior.logL[:10] == -np.inf)\n    assert np.all(prior.weight[:10] == 0)\n    ns.plot_1d([\'x0\', \'x1\'])\n\n\ndef test_live_points():\n    np.random.seed(4)\n    pc = NestedSamples(root=""./tests/example_data/pc"")\n\n    for i, logL in pc.logL.iteritems():\n        live_points = pc.live_points(logL)\n        assert len(live_points) == pc.nlive[i]\n\n        live_points_from_int = pc.live_points(i)\n        assert_array_equal(live_points_from_int, live_points)\n\n    last_live_points = pc.live_points()\n    logL = pc.logL_birth.max()\n    assert (last_live_points.logL > logL).all()\n    assert len(last_live_points) == pc.nlive.mode()[0]\n\n\ndef test_limit_assignment():\n    np.random.seed(3)\n    ns = NestedSamples(root=\'./tests/example_data/pc\')\n    # `None` in .ranges file:\n    assert ns.limits[\'x0\'][0] is None\n    assert ns.limits[\'x0\'][1] is None\n    # parameter not listed in .ranges file:\n    assert ns.limits[\'x1\'][0] == ns.x1.min()\n    assert ns.limits[\'x1\'][1] == ns.x1.max()\n    # `None` for only one limit in .ranges file:\n    assert ns.limits[\'x2\'][0] == 0\n    assert ns.limits[\'x2\'][1] is None\n    # both limits specified in .ranges file:\n    assert ns.limits[\'x3\'][0] == 0\n    assert ns.limits[\'x3\'][1] == 1\n    # limits for logL, weight, nlive\n    assert ns.limits[\'logL\'][0] == -777.0115456428716\n    assert ns.limits[\'logL\'][1] == 5.748335384373301\n    assert ns.limits[\'weight\'][0] == 0\n    assert ns.limits[\'weight\'][1] == 1\n    assert ns.limits[\'nlive\'][0] == 0\n    assert ns.limits[\'nlive\'][1] == 125\n'"
tests/test_utils.py,19,"b""import warnings\nimport numpy as np\nfrom scipy import special as sp\nfrom numpy.testing import assert_array_equal\nfrom anesthetic.utils import (nest_level, compute_nlive, unique, is_int,\n                              triangular_sample_compression_2d,\n                              logsumexp)\n\n\ndef test_nest_level():\n    assert(nest_level(0) == 0)\n    assert(nest_level([]) == 1)\n    assert(nest_level(['a']) == 1)\n    assert(nest_level(['a', 'b']) == 1)\n    assert(nest_level([['a'], 'b']) == 2)\n    assert(nest_level(['a', ['b']]) == 2)\n    assert(nest_level([['a'], ['b']]) == 2)\n\n\ndef test_compute_nlive():\n    # Generate a 'pure' nested sampling run\n    np.random.seed(0)\n    nlive = 500\n    ncompress = 100\n    logL = np.cumsum(np.random.rand(nlive, ncompress), axis=1)\n    logL_birth = np.concatenate((np.ones((nlive, 1))*-1e30, logL[:, :-1]),\n                                axis=1)\n    i = np.argsort(logL.flatten())\n    logL = logL.flatten()[i]\n    logL_birth = logL_birth.flatten()[i]\n\n    # Compute nlive\n    nlives = compute_nlive(logL, logL_birth)\n\n    # Check the first half are constant\n    assert_array_equal(nlives[:len(nlives)//2], nlive)\n\n    # Check no points at the end\n    assert(nlives[-1] == 0)\n\n    # Check never more than nlive\n    assert(nlives.max() <= nlive)\n\n\ndef test_unique():\n    assert(unique([3, 2, 1, 4, 1, 3]) == [3, 2, 1, 4])\n\n\ndef test_triangular_sample_compression_2d():\n    np.random.seed(0)\n    n = 5000\n    x = np.random.rand(n)\n    y = np.random.rand(n)\n    w = np.random.rand(n)\n    cov = np.identity(2)\n    tri, W = triangular_sample_compression_2d(x, y, cov, w)\n    assert len(W) == 1000\n    assert np.isclose(sum(W), sum(w), rtol=1e-1)\n\n\ndef test_is_int():\n    assert is_int(1)\n    assert is_int(np.int64(1))\n    assert not is_int(1.)\n    assert not is_int(np.float64(1.))\n\n\ndef test_logsumexpinf():\n    a = np.random.rand(10)\n    b = np.random.rand(10)\n    assert logsumexp(-np.inf, b=[-np.inf]) == -np.inf\n    assert logsumexp(a, b=b) == sp.logsumexp(a, b=b)\n    a[0] = -np.inf\n    assert logsumexp(a, b=b) == sp.logsumexp(a, b=b)\n    b[0] = -np.inf\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore',\n                                'invalid value encountered in multiply',\n                                RuntimeWarning)\n        assert np.isnan(sp.logsumexp(a, b=b))\n    assert np.isfinite(logsumexp(a, b=b))\n"""
tests/test_weighted_pandas.py,15,"b""from anesthetic.weighted_pandas import WeightedDataFrame, WeightedSeries\nfrom pandas import Series, DataFrame\nimport numpy as np\nfrom numpy.testing import assert_array_equal, assert_allclose\n\n\ndef test_WeightedSeries_constructor():\n    np.random.seed(0)\n    N = 100000\n    data = np.random.rand(N)\n\n    series = WeightedSeries(data)\n    assert_array_equal(series.weight, 1)\n    assert_array_equal(series, data)\n\n    series = WeightedSeries(data, w=None)\n    assert_array_equal(series.weight, 1)\n    assert_array_equal(series, data)\n\n    weights = np.random.rand(N)\n    series = WeightedSeries(data, w=weights)\n    assert_array_equal(series, data)\n\n    assert series.weight.shape == (N,)\n    assert series.shape == (N,)\n    assert isinstance(series.weight, Series)\n    assert_array_equal(series, data)\n    assert_array_equal(series.weight, weights)\n    assert isinstance(series.to_frame(), WeightedDataFrame)\n    assert_array_equal(series.to_frame().weight, weights)\n\n    return series\n\n\ndef test_WeightedDataFrame_constructor():\n    np.random.seed(0)\n    N = 100000\n    m = 3\n    data = np.random.rand(N, m)\n    cols = ['A', 'B', 'C']\n\n    df = WeightedDataFrame(data, columns=cols)\n    assert_array_equal(df.weight, 1)\n    assert_array_equal(df, data)\n\n    df = WeightedDataFrame(data, w=None, columns=cols)\n    assert_array_equal(df.weight, 1)\n    assert_array_equal(df, data)\n\n    weights = np.random.rand(N)\n    df = WeightedDataFrame(data, w=weights, columns=cols)\n\n    assert df.weight.shape == (N,)\n    assert df.shape == (N, m)\n    assert isinstance(df.weight, Series)\n    assert_array_equal(df, data)\n    assert_array_equal(df.weight, weights)\n    assert_array_equal(df.columns, cols)\n    return df\n\n\ndef test_WeightedDataFrame_slice():\n    df = test_WeightedDataFrame_constructor()\n    assert isinstance(df['A'], WeightedSeries)\n    assert df[:10].shape == (10, 3)\n    assert df[:10].weight.shape == (10,)\n    assert df[:10]._rand.shape == (10,)\n\n\ndef test_WeightedDataFrame_mean():\n    df = test_WeightedDataFrame_constructor()\n    mean = df.mean()\n    assert isinstance(mean, Series)\n    assert_allclose(mean, 0.5, atol=1e-2)\n\n\ndef test_WeightedDataFrame_std():\n    df = test_WeightedDataFrame_constructor()\n    std = df.std()\n    assert isinstance(std, Series)\n    assert_allclose(std, (1./12)**0.5, atol=1e-2)\n\n\ndef test_WeightedDataFrame_cov():\n    df = test_WeightedDataFrame_constructor()\n    cov = df.cov()\n    assert isinstance(cov, DataFrame)\n    assert_allclose(cov, (1./12)*np.identity(3), atol=1e-2)\n\n\ndef test_WeightedDataFrame_median():\n    df = test_WeightedDataFrame_constructor()\n    median = df.median()\n    assert isinstance(median, Series)\n    assert_allclose(median, 0.5, atol=1e-2)\n\n\ndef test_WeightedDataFrame_quantile():\n    df = test_WeightedDataFrame_constructor()\n    for q in np.linspace(0, 1, 10):\n        quantile = df.quantile(q)\n        assert isinstance(quantile, Series)\n        assert_allclose(quantile, q, atol=1e-2)\n\n\ndef test_WeightedDataFrame_neff():\n    df = test_WeightedDataFrame_constructor()\n    neff = df.neff()\n    assert isinstance(neff, float)\n    assert neff < len(df)\n    assert neff > len(df) * np.exp(-0.25)\n\n\ndef test_WeightedDataFrame_compress():\n    df = test_WeightedDataFrame_constructor()\n    assert_allclose(df.neff(), len(df.compress()), rtol=1e-2)\n    for i in np.logspace(3, 5, 10):\n        assert_allclose(i, len(df.compress(i)), rtol=1e-1)\n    unit_weights = df.compress(0)\n    assert(len(np.unique(unit_weights.index)) == len(unit_weights))\n\n\ndef test_WeightedSeries_mean():\n    series = test_WeightedSeries_constructor()\n    mean = series.mean()\n    assert isinstance(mean, float)\n    assert_allclose(mean, 0.5, atol=1e-2)\n\n\ndef test_WeightedSeries_std():\n    series = test_WeightedSeries_constructor()\n    std = series.std()\n    assert isinstance(std, float)\n    assert_allclose(std, (1./12)**0.5, atol=1e-2)\n\n\ndef test_WeightedSeries_median():\n    series = test_WeightedSeries_constructor()\n    median = series.median()\n    assert isinstance(median, float)\n    assert_allclose(median, 0.5, atol=1e-2)\n\n\ndef test_WeightedSeries_quantile():\n    series = test_WeightedSeries_constructor()\n    for q in np.linspace(0, 1, 10):\n        quantile = series.quantile(q)\n        assert isinstance(quantile, float)\n        assert_allclose(quantile, q, atol=1e-2)\n\n\ndef test_WeightedSeries_neff():\n    series = test_WeightedSeries_constructor()\n    neff = series.neff()\n    assert isinstance(neff, float)\n    assert neff < len(series)\n    assert neff > len(series) * np.exp(-0.25)\n\n\ndef test_WeightedSeries_compress():\n    series = test_WeightedSeries_constructor()\n    assert_allclose(series.neff(), len(series.compress()), rtol=1e-2)\n    for i in np.logspace(3, 5, 10):\n        assert_allclose(i, len(series.compress(i)), rtol=1e-1)\n    unit_weights = series.compress(0)\n    assert(len(np.unique(unit_weights.index)) == len(unit_weights))\n"""
anesthetic/gui/__init__.py,0,"b'""""""Graphical user interface for inspecting nested sampling runs.""""""\n'"
anesthetic/gui/plot.py,6,"b'""""""Main plotting tools.""""""\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import (GridSpec as GS,\n                                 GridSpecFromSubplotSpec as sGS)\nfrom anesthetic.gui.widgets import (Widget, Slider, Button,\n                                    RadioButtons, TrianglePlot, CheckButtons)\n\n\nclass Higson(Widget):\n    """"""Higson plot as shown in https://arxiv.org/abs/1703.09701 .\n\n    Attributes\n    ----------\n        curve: matplotlib.lines.Line2D\n            points currently plotted as a curve.\n\n        point: matplotlib.lines.Line2D\n            large indicator point currently plotted on the curve.\n\n    """"""\n\n    def __init__(self, fig, gridspec):\n        super(Higson, self).__init__(fig, gridspec)\n        self.ax.set_yticks([])\n        self.ax.set_ylim(-0.1, 1.1)\n        self.ax.set_ylabel(r\'$LX$\')\n        self.ax.set_xlabel(r\'$\\log X$\')\n\n        self.curve, = self.ax.plot([None], [None], \'k-\')\n        self.point, = self.ax.plot([None], [None], \'ko\')\n\n    def update(self, logX, LX, i):\n        """"""Update the line and the point in the higson plot.\n\n        Parameters\n        ----------\n            logX: array-like\n                log-volume compression values to plot\n\n            LX: array-like\n                Likelihood * volume compression\n\n            i: int\n                Current location of higson point\n\n        """"""\n        self.point.set_xdata(logX[i])\n        self.point.set_ydata(LX[i])\n        self.curve.set_xdata(logX)\n        self.curve.set_ydata(LX)\n\n    def reset_range(self):\n        """"""Reset the ranges of the higson plot.""""""\n        xdata = self.curve.get_xdata()\n        xdata = xdata[np.isfinite(xdata)]\n        self.ax.set_xlim(xdata.max(), xdata.min())\n\n\nclass Evolution(Slider):\n    """"""Slider controlling the evolution stage of the live points.""""""\n\n    def __init__(self, fig, gridspec, action, valmax):\n        super(Evolution, self).__init__(fig, gridspec, action, \'\',\n                                        0, valmax, 0, \'horizontal\')\n        self.slider.valtext.set_horizontalalignment(\'right\')\n        self.slider.valtext.set_position((0.98, 0.5))\n\n    def __call__(self):\n        """"""Return the current iteration as an integer.""""""\n        mx = self.slider.valmax-1\n        val = int(super(Evolution, self).__call__())\n        return min(val, mx)\n\n    def set_text(self, logL, n):\n        """"""Set the text at end of slider.\n\n        Parameters\n        ----------\n            logL: float\n                Current loglikelihood of evolution stage\n\n            n: int\n                Current number of live points of evolution stage\n\n        """"""\n        text = r\'$\\log L$: %.6g, $n_\\mathrm{live}$: %i\' % (logL, n)\n        return super(Evolution, self).set_text(text)\n\n\nclass Temperature(Slider):\n    """"""Logarithmic slider controlling temperature of the posterior points.""""""\n\n    def __init__(self, fig, gridspec, action):\n        super(Temperature, self).__init__(fig, gridspec, action, r\'$kT$\',\n                                          -1, 5, 0, \'vertical\')\n\n    def __call__(self):\n        """"""Return the current temperature.""""""\n        return 10**super(Temperature, self).__call__()\n\n    def set_text(self, kT):\n        """"""Set the text at end of slider.\n\n        Parameters\n        ----------\n            kT: float\n                Current temperature of posterior points stage\n\n        """"""\n        text = r\'%.2g\' % kT\n        return super(Temperature, self).set_text(text)\n\n\nclass RunPlotter(object):\n    """"""Construct a control panel of information on a nested sampling run.\n\n    Parameters\n    ----------\n        samples: anesthetic.samples.NestedSamples\n            The root string for the chains files to be used, or a set of nested\n            samples.\n\n    Attributes\n    ----------\n        samples: anesthetic.samples.NestedSamples\n            Object for extracting nested sampling data from chains files.\n\n        fig: matplotlib.figure.Figure\n            Reference to the underlying figure\n\n        triangle: anesthetic.gui.widgets.TrianglePlot\n            Corner plot of live or posterior samples.\n\n        temperature: anesthetic.gui.plot.Temperature\n            Slider selecting the posterior temperature.\n\n        evolution: anesthetic.gui.plot.Evolution\n            Slider selecting the live iteration.\n\n        higson: anesthetic.gui.plot.Higson\n            Higson plot of posterior weights.\n\n        reset: anesthetic.gui.widgets.Button\n            Button that resets the parameter ranges.\n\n        reload: anesthetic.gui.widgets.Button\n            Button that reloads the files.\n\n        type: anesthetic.gui.widgets.RadioButtons\n            Radio buttons that selects whether to plot live or posteriors.\n\n        param_choice: anesthetic.gui.widgets.CheckButtons\n            Checkbox that selects which parameters to plot.\n\n    """"""\n\n    def __init__(self, samples, params=None):\n        self.samples = samples\n\n        if params:\n            self.params = np.array(params)\n        else:\n            self.params = np.array(self.samples.columns[:10])\n\n        self.fig = plt.figure()\n        self._set_up()\n        self.redraw(None)\n\n    def _set_up(self):\n        """"""Draw the control panel.\n\n        We implement the control panel using sequential recursive gridspecs.\n\n        +----------------------------------------------+------+\n        |                                              |      |\n        |                  gs0[0]                      |gs0[1]|\n        |                                              |      |\n        |                                              |      |\n        |                                              |      |\n        |                                              |      |\n        |                                              |      |\n        |                                              |      |\n        +-------------------------+-----------------+--+------+\n        |                         |    gs11[0]      |         |\n        |         gs10[0]         +-----------------+  gs1[2] |\n        +-------------------------+    gs11[1]      |         |\n        |                         +-----------------+         |\n        |         gs10[1]         |    gs11[2]      |         |\n        +-------------------------+-----------------+---------+\n\n        These variable names are included in the __init__ function, and are\n        named with an intuitive Huffman coding.\n\n        """"""\n        gs = GS(2, 1, height_ratios=[3, 1])\n        gs0 = sGS(1, 2, width_ratios=[19, 1], subplot_spec=gs[0])\n        gs1 = sGS(1, 3, width_ratios=[4, 1, 1], subplot_spec=gs[1])\n        gs10 = sGS(2, 1, height_ratios=[1, 4], subplot_spec=gs1[0])\n        gs11 = sGS(3, 1, height_ratios=[1, 1, 2], subplot_spec=gs1[1])\n\n        self.triangle = TrianglePlot(self.fig, gs0[0])\n        self.temperature = Temperature(self.fig, gs0[1], self.update)\n        self.evolution = Evolution(self.fig, gs10[0],\n                                   self.update, len(self.samples))\n        self.higson = Higson(self.fig, gs10[1])\n        self.reset = Button(self.fig, gs11[0],\n                            self.reset_range, \'Reset Range\')\n        self.reload = Button(self.fig, gs11[1],\n                             self.reload_file, \'Reload File\')\n        self.type = RadioButtons(self.fig, gs11[2],\n                                 (\'live\', \'posterior\'), self.update)\n        self.param_choice = CheckButtons(self.fig, gs1[2],\n                                         self.params, self.redraw)\n\n    def redraw(self, _):\n        """"""Redraw the triangle plot upon parameter updating.""""""\n        self.triangle.draw(self.param_choice(), self.samples.tex)\n        self.update(None)\n        self.reset_range(None)\n        self.fig.tight_layout()\n        self.fig.canvas.draw()\n\n    def points(self, label):\n        """"""Get sample coordinates from nested sampling samples.\n\n        Parameters\n        ----------\n            label: str\n                label indicating the coordinate to extract.\n\n        Returns\n        -------\n            array-like:\n                sample \'label\'-coordinates.\n\n        """"""\n        if self.type() == \'posterior\':\n            kT = self.temperature()\n            return self.samples.posterior_points(1/kT)[label]\n        else:\n            i = self.evolution()\n            logL = self.samples.logL.iloc[i]\n            return self.samples.live_points(logL)[label]\n\n    def update(self, _):\n        """"""Update all the plots upon slider changes.""""""\n        with np.errstate(divide=\'ignore\'):\n            logX = np.log(self.samples.nlive / (self.samples.nlive+1)).cumsum()\n        kT = self.temperature()\n        LX = self.samples.logL/kT + logX\n        LX = np.exp(LX-LX.max())\n        i = self.evolution()\n        logL = self.samples.logL.iloc[i]\n        try:\n            n = self.samples.nlive.iloc[i]\n        except IndexError:\n            n = 0\n\n        self.triangle.update(self.points)\n\n        self.evolution.set_text(logL, n)\n        self.temperature.set_text(kT)\n\n        self.higson.update(logX, LX, i)\n        self.fig.canvas.draw()\n\n    def reload_file(self, _):\n        """"""Reload the data from file.""""""\n        self.samples._reload_data()\n        self.evolution.reset_range(valmax=len(self.samples))\n        self.update(None)\n\n    def reset_range(self, _):\n        """"""Reset the parameter ranges.""""""\n        self.triangle.reset_range()\n        self.higson.reset_range()\n        self.fig.canvas.draw()\n'"
anesthetic/gui/widgets.py,0,"b'""""""Widget wrappers to matplotlib.\n\nThese extend the matplotlib widgets by plotting themselves onto an axis and\nstoring a reference to both the widget object and the axis on which they are\nplotted.\n\n""""""\n\nfrom matplotlib.widgets import Button as mplButton\nfrom matplotlib.widgets import CheckButtons as mplCheckButtons\nfrom matplotlib.widgets import RadioButtons as mplRadioButtons\nfrom matplotlib.widgets import Slider as mplSlider\nfrom anesthetic.utils import histogram\nfrom anesthetic.plot import make_2d_axes\n\n\nclass Widget(object):\n    """"""Base class for anesthetic gui widgets.\n\n    Stores a reference to the underlying figure, the gridspec that the\n    widget is placed at and the axes of the widget.\n\n    Parameters\n    ----------\n        fig: matplotlib.figure.Figure\n            Figure for drawing widget on.\n\n        gridspec: matplotlib.gridspec.GridSpec\n            Specification for where to draw in the figure.\n            Technically could be any argument that can be passed to\n            matplotlib.figure.Figure.add_subplot.\n\n    Attributes\n    ----------\n        fig: (matplotlib.figure.Figure\n            Figure for drawing widget on.\n\n        gridspec: matplotlib.gridspec.GridSpec\n            Specification for where to draw in the figure.\n            Technically could be any argument that can be passed to\n            matplotlib.figure.Figure.add_subplot.\n\n        ax: matplotlib.axes.Axes\n            Axes of widget.\n\n    """"""\n\n    def __init__(self, fig, gridspec):\n        self.fig = fig\n        self.gridspec = gridspec\n        self.ax = self.fig.add_subplot(self.gridspec)\n\n\nclass LabelsWidget(Widget):\n    """"""Widget with labels to choose from.\n\n    Parameters\n    ----------\n        labels: list(str)\n            Set of labels to be tied to Widget.\n\n    Attributes\n    ----------\n        labels: list(str)\n            Set of labels on Widget.\n\n    """"""\n\n    def __init__(self, fig, gridspec, labels):\n        super(LabelsWidget, self).__init__(fig, gridspec)\n        self.labels = labels\n\n\nclass Button(Widget):\n    """"""Push button that performs an action.\n\n    Parameters\n    ----------\n        action: func\n            What should be run upon clicking the button.\n\n        text: str\n            Overlay text on the button.\n\n    Attributes\n    ----------\n        button: matplotlib.widgets.Button\n            matplotlib Button.\n\n    """"""\n\n    def __init__(self, fig, gridspec, action, text):\n        super(Button, self).__init__(fig, gridspec)\n        self.button = mplButton(self.ax, text)\n        self.button.on_clicked(action)\n\n\nclass CheckButtons(LabelsWidget):\n    """"""Set of checkboxes.\n\n    Defaults to choosing the only the first label at start.\n\n    Parameters\n    ----------\n        action: func\n            What should be done upon checking the box.\n\n    Attributes\n    ----------\n        buttons: matplotlib.widgets.CheckButtons\n            matplotlib CheckButtons.\n\n    """"""\n\n    def __init__(self, fig, gridspec, labels, action):\n        super(CheckButtons, self).__init__(fig, gridspec, labels)\n        default = [i == 0 for i, _ in enumerate(self.labels)]\n        self.buttons = mplCheckButtons(self.ax, self.labels, default)\n        self.buttons.on_clicked(action)\n\n    def __call__(self):\n        """"""Get current status of the check boxes.""""""\n        return self.labels[list(self.buttons.get_status())]\n\n\nclass RadioButtons(LabelsWidget):\n    """"""Set of radio selection choices.\n\n    Parameters\n    ----------\n        labels: list(str))\n\n    Attributes\n    ----------\n        buttons: matplotlib.widgets.RadioButtons\n            matplotlib RadioButtons.\n\n    """"""\n\n    def __init__(self, fig, gridspec, labels, action):\n        super(RadioButtons, self).__init__(fig, gridspec, labels)\n        self.buttons = mplRadioButtons(self.ax, self.labels)\n        self.buttons.on_clicked(action)\n\n    def __call__(self):\n        """"""Get current selection string.""""""\n        return self.buttons.value_selected\n\n\nclass Slider(Widget):\n    """"""Choose a parameter via a slider widget.\n\n    Parameters\n    ----------\n        action: func\n            What should be done upon altering the slider.\n\n        text: str\n            Text at the start of the slider.\n\n        valmin, valmax, valinit: float\n            Range and initial value for the slider.\n\n        orientation: str\n            Orientation for slider (\'horizontal\' or \'vertical\').\n\n    Attributes\n    ----------\n        slider: matplotlib.widgets.Slider\n            matplotlib Slider.\n\n    """"""\n\n    def __init__(self, fig, gridspec, action, text,\n                 valmin, valmax, valinit, orientation):\n        super(Slider, self).__init__(fig, gridspec)\n        self.slider = mplSlider(self.ax, text, valmin, valmax, valinit=valinit,\n                                orientation=orientation)\n        self.slider.on_changed(action)\n\n    def set_text(self, text):\n        """"""Set the text at the end of the slider.\n\n        Parameters\n        ----------\n            text: str\n                Text to be chosen\n\n        """"""\n        self.slider.valtext.set_text(text)\n\n    def reset_range(self, valmin=None, valmax=None):\n        """"""Reset the range of the slider.\n\n        Kwargs:\n            valmin, valmax: (float), optional:\n                The new limits to the slider.\n\n        """"""\n        if valmax is not None:\n            self.slider.valmax = valmax\n        if valmin is not None:\n            self.slider.valmin = valmin\n        self.slider.ax.set_xlim(self.slider.valmin, self.slider.valmax)\n\n    def __call__(self):\n        """"""Return the float value in the slider.""""""\n        return self.slider.val\n\n\nclass TrianglePlot(Widget):\n    """"""Triangle plot widget as exemplified by getdist and corner.py.\n\n    For other examples of these plots, see:\n    https://getdist.readthedocs.io\n    https://corner.readthedocs.io\n\n    Attributes\n    ----------\n        ax: pandas.DataFrame(matplotlib.axes.Axes)\n            Mapping from pairs of parameters to axes for plotting.\n    """"""\n\n    def __init__(self, fig, gridspec):\n        super(TrianglePlot, self).__init__(fig, gridspec)\n        self.fig.delaxes(self.ax)\n        _, self.ax = make_2d_axes([], fig=self.fig, subplot_spec=self.gridspec)\n\n    def draw(self, labels, tex={}):\n        """"""Draw a new triangular grid for list of parameters labels.\n\n        Parameters\n        ----------\n            labels: list(str)\n                labels for the triangular grid.\n\n        """"""\n        # Remove any existing axes\n        for y, row in self.ax.iterrows():\n            for x, ax in row.iteritems():\n                if ax is not None:\n                    if x == y:\n                        self.fig.delaxes(ax.twin)\n                    self.fig.delaxes(ax)\n\n        # Set up the axes\n        _, self.ax = make_2d_axes(labels, upper=False, tex=tex,\n                                  fig=self.fig, subplot_spec=self.gridspec)\n\n        # Plot no points  points.\n        for y, row in self.ax.iterrows():\n            for x, ax in row.iteritems():\n                if ax is not None:\n                    if x == y:\n                        ax.twin.plot([None], [None], \'k-\')\n                    else:\n                        ax.plot([None], [None], \'k.\')\n\n    def update(self, f):\n        """"""Update the points in the triangle plot using f function.\n\n        Parameters\n        ----------\n            f: func: str -> array(float)\n                this function should take in a parameter label i, and return an\n                array-like object of the i-coordinate of the samples\n\n        """"""\n        for y, row in self.ax.iterrows():\n            for x, ax in row.iteritems():\n                if ax is not None:\n                    if x == y:\n                        datx, daty = histogram(f(x), bins=\'auto\')\n                        ax.twin.lines[0].set_xdata(datx)\n                        ax.twin.lines[0].set_ydata(daty)\n                    else:\n                        ax.lines[0].set_xdata(f(x))\n                        ax.lines[0].set_ydata(f(y))\n\n    def reset_range(self):\n        """"""Reset the range of each grid.""""""\n        for y, row in self.ax.iterrows():\n            for x, ax in row.iteritems():\n                if ax is not None:\n                    if x == y:\n                        ax.twin.relim()\n                        ax.twin.autoscale_view()\n                    ax.relim()\n                    ax.autoscale_view()\n'"
anesthetic/read/__init__.py,0,"b'""""""Module for reading samples from file.""""""\n'"
anesthetic/read/chainreader.py,0,"b'""""""Tools for reading from chains files.""""""\n\n\nclass ChainReader(object):\n    """"""Base class for reading chains files.""""""\n\n    def __init__(self, root):\n        self.root = root\n\n    def paramnames(self):\n        """"""Parameter names mapping.""""""\n        return None, {}\n\n    def limits(self):\n        """"""Parameter limits mapping.""""""\n        return {}\n\n    def samples(self):\n        """"""Read samples from file.""""""\n        raise NotImplementedError\n'"
anesthetic/read/getdistreader.py,2,"b'""""""Tools for reading from getdist chains files.""""""\nimport numpy as np\nimport glob\nfrom anesthetic.read.chainreader import ChainReader\n\n\nclass GetDistReader(ChainReader):\n    """"""Read getdist files.""""""\n\n    def paramnames(self):\n        r""""""Read <root>.paramnames in getdist format.\n\n        This file should contain one or two columns. The first column indicates\n        a reference name for the sample, used as labels in the pandas array.\n        The second optional column should include the equivalent axis label,\n        possibly in tex, with the understanding that it will be surrounded by\n        dollar signs, for example\n\n        <root.paramnames>\n\n        a1     a_1\n        a2     a_2\n        omega  \\omega\n        """"""\n        try:\n            with open(self.paramnames_file, \'r\') as f:\n                paramnames = []\n                tex = {}\n                for line in f:\n                    line = line.strip().split()\n                    paramname = line[0].replace(\'*\', \'\')\n                    paramnames.append(paramname)\n                    if len(line) > 1:\n                        tex[paramname] = \'$\' + \' \'.join(line[1:]) + \'$\'\n                return paramnames, tex\n        except IOError:\n            return super(GetDistReader, self).paramnames()\n\n    def limits(self):\n        """"""Read <root>.ranges in getdist format.""""""\n        try:\n            with open(self.ranges_file, \'r\') as f:\n                limits = {}\n                for line in f:\n                    line = line.strip().split()\n                    paramname = line[0]\n                    try:\n                        xmin = float(line[1])\n                    except ValueError:\n                        xmin = None\n                    try:\n                        xmax = float(line[2])\n                    except ValueError:\n                        xmax = None\n                    limits[paramname] = (xmin, xmax)\n                return limits\n        except IOError:\n            return super(GetDistReader, self).limits()\n\n    def samples(self):\n        """"""Read <root>_1.txt in getdist format.""""""\n        data = np.concatenate([np.loadtxt(chains_file)\n                               for chains_file in self.chains_files])\n        weights, chi2, samples = np.split(data, [1, 2], axis=1)\n        logL = chi2/-2.\n        return weights.flatten(), logL.flatten(), samples\n\n    @property\n    def paramnames_file(self):\n        """"""File containing parameter names.""""""\n        return self.root + \'.paramnames\'\n\n    @property\n    def ranges_file(self):\n        """"""File containing parameter names.""""""\n        return self.root + \'.ranges\'\n\n    @property\n    def chains_files(self):\n        """"""File containing parameter names.""""""\n        files = glob.glob(self.root + \'_[0-9].txt\')\n        if not files:\n            files = [self.root + \'.txt\']\n\n        return files\n'"
anesthetic/read/montepythonreader.py,6,"b'""""""Tools for reading from MontePython chains files.""""""\nimport sys\nimport os\nimport glob\nimport warnings\nimport numpy as np\nfrom anesthetic.read.chainreader import ChainReader\ntry:\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        from montepython import analyze\nexcept ImportError:\n    pass\n\n\nclass MontePythonReader(ChainReader):\n    """"""Read and process MontePython chain files using `montepython.analyze`.""""""\n\n    def __init__(self, root):\n        """"""Initialise MontePythonReader.\n\n        Note how MontePython takes the _folder_ to the chain files as root,\n        different from the root for GetDist.\n\n        Parameters\n        ----------\n        root: str\n            Path to _folder_ containing the MontePython .txt chain files.\n            E.g. for the following two chain files:\n            /path/to/chains/Planck2015_TTlowP/2019-04-29_100000__1.txt\n                                              2019-04-29_100000__2.txt\n            you should pass the string ""/path/to/chains/Planck2015_TTlowP"".\n            No trailing \'/\'.\n\n        """"""\n        super(MontePythonReader, self).__init__(root)\n\n    @property\n    def log_param_file(self):\n        """"""File containing input parameter info.""""""\n        return self.root + \'/log.param\'\n\n    @property\n    def paramnames_file(self):\n        """"""File containing parameter names.""""""\n        return glob.glob(self.root + \'/*_.paramnames\')[-1]\n\n    @property\n    def log_file(self):\n        """"""File containing MontePython log data.""""""\n        return self.root + \'/\' + os.path.basename(self.root) + \'.log\'\n\n    def _init(self):\n        """"""Prepare MontePython data.\n\n        Uses MontePython\'s `analyze` module to prepare the data:\n            * Extracts parameter names from MontePython\'s log.param file.\n            * Removes burn-in and non-markovian points from the data.\n            * Extract tex names.\n            * Extracts parameter limits from MontePython\'s log.param file.\n\n        """"""\n        if \'montepython\' not in sys.modules:\n            raise ImportError(\n                ""`montepython` not installed, but `MontePythonReader` needs ""\n                ""the `montepython` package as an extra requirement in order ""\n                ""to read the data folder. Alternatively you can pass the root ""\n                ""to the actual chain _files_ into `MCMCSamples` (omitting ""\n                ""_1.txt, _2.txt, etc.) in which case the files will be read ""\n                ""by the `GetDistReader` (with less functionality, though, ""\n                ""e.g. won\'t automatically detect limits)."")\n        # The variable and function names used here correspond to the ones\n        # used in MontePython\'s analyze.py module.\n        command_line = Namespace(files=[self.root])\n        self.info = analyze.Information(command_line)\n        analyze.prepare(files=command_line.files, info=self.info)\n        analyze.extract_parameter_names(info=self.info)\n        analyze.find_maximum_of_likelihood(info=self.info)\n        data_per_chain = analyze.remove_bad_points(info=self.info)\n        self.data = np.concatenate(data_per_chain, axis=0)\n\n    def paramnames(self):\n        """"""Return parameter labels and corresponding tex signs.\n\n        Returns\n        -------\n        params: np.ndarray\n            reference name for the sample, used as labels in the pandas array\n\n        tex: np.ndarray\n            axis labels, possibly in tex, with the understanding that it will\n            be surrounded by dollar signs\n\n        """"""\n        params = self.info.ref_names\n        tex = dict(zip(self.info.ref_names, self.info.tex_names))\n        return params, tex\n\n    def samples(self):\n        """"""Return weights, loglikelihood and samples.\n\n        Thew weights and samples are the ones after removal of burn-in points\n        and of non-markovian points as performed by MontePython\'s `analyze`\n        module.\n\n        Returns\n        -------\n        weights: np.ndarray\n            weights of each step in the sample\n\n        logL: np.ndarray\n            loglikelihood of each step in the sample\n\n        samples: np.ndarray\n            MontePython MCMC samples\n\n        """"""\n        weights = self.data[:, 0]\n        logL = -self.data[:, 1]\n        samples = self.data[:, 2:]\n        return weights, logL, samples\n\n    def limits(self):\n        """"""Return param limits as specified in MontePython\'s log.param file.""""""\n        limits = dict(zip(self.info.ref_names, self.info.boundaries))\n        return limits\n\n\nclass Namespace(object):\n    """"""Input class for MontePython analyze module.\n\n    Essentially none of this will be needed for anesthetic, however, in order\n    to use MontePython\'s function `remove_bad_points` an instance of this\n    class is required as input.\n    """"""\n\n    def __init__(self, files):\n        self.bins = 20\n        self.center_fisher = False\n        self.contours_only = False\n        self.decimal = 3\n        self.extension = \'pdf\'\n        self.files = files\n        self.fontsize = 16\n        self.gaussian_smoothing = 0.5\n        self.interpolation_smoothing = 4\n        self.keep_fraction = 1.0\n        self.legend_style = \'sides\'\n        self.line_width = 4\n        self.markovian = True\n        self.mean_likelihood = True\n        self.minimal = False\n        self.num_columns_1d = None\n        self.only_markovian = False\n        self.optional_plot_file = \'\'\n        self.plot = False\n        self.plot_2d = False\n        self.plot_fisher = False\n        self.posterior_smoothing = 5\n        self.short_title_1d = False\n        self.silent = False\n        self.subparser_name = \'info\'\n        self.subplot = False\n        self.temperature = 1.0\n        self.ticknumber = 3\n        self.ticksize = 14\n        self.verbose = True\n        self.want_covmat = False\n'"
anesthetic/read/multinestreader.py,21,"b'""""""Tools for reading from multinest chains files.""""""\nimport numpy as np\nfrom anesthetic.read.getdistreader import GetDistReader\n\n\nclass MultiNestReader(GetDistReader):\n    """"""Read multinest files.""""""\n\n    def samples(self):\n        """"""Read <root>ev.dat and <root>phys_live.points in multinest format.""""""\n        try:\n            data = np.loadtxt(self.birth_file)\n            samples, logL, logL_birth, _ = np.split(data, [-4, -3, -2], axis=1)\n            logL = np.squeeze(logL)\n            logL_birth = np.squeeze(logL_birth)\n\n            data = np.loadtxt(self.phys_live_birth_file)\n            (live_samples, live_logL,\n             live_logL_birth, _) = np.split(data, [-3, -2, -1], axis=1)\n            live_logL = np.squeeze(live_logL)\n            live_logL_birth = np.squeeze(live_logL_birth)\n            i = np.argsort(live_logL)\n            samples = np.concatenate((samples, live_samples[i]), axis=0)\n            logL = np.concatenate((logL, live_logL[i]))\n            logL_birth = np.concatenate((logL_birth, live_logL_birth[i]))\n            return samples, logL, logL_birth\n\n        except IOError:\n            data = np.loadtxt(self.ev_file)\n            samples, logL, _ = np.split(data, [-3, -2], axis=1)\n            logL = np.squeeze(logL)\n\n            data = np.loadtxt(self.phys_live_file)\n            live_samples, live_logL, _ = np.split(data, [-2, -1], axis=1)\n            live_logL = np.squeeze(live_logL)\n            i = np.argsort(live_logL)\n            nlive = len(live_logL)\n            samples = np.concatenate((samples, live_samples[i]), axis=0)\n            logL = np.concatenate((logL, live_logL[i]))\n            return samples, logL, nlive\n\n    @property\n    def ev_file(self):\n        """"""File containing discarded points.""""""\n        return self.root + \'ev.dat\'\n\n    @property\n    def birth_file(self):\n        """"""File containing discarded points.""""""\n        return self.root + \'dead-birth.txt\'\n\n    @property\n    def phys_live_file(self):\n        """"""File containing physical live points.""""""\n        return self.root + \'phys_live.points\'\n\n    @property\n    def phys_live_birth_file(self):\n        """"""File containing physical live points.""""""\n        return self.root + \'phys_live-birth.txt\'\n'"
anesthetic/read/polychordreader.py,6,"b'""""""Tools for reading from polychord chains files.""""""\nimport numpy as np\nfrom anesthetic.read.getdistreader import GetDistReader\n\n\nclass PolyChordReader(GetDistReader):\n    """"""Read polychord files.""""""\n\n    def samples(self):\n        """"""Read ``<root>_dead-birth.txt`` in polychord format.""""""\n        data = np.loadtxt(self.birth_file)\n        try:\n            _data = np.loadtxt(self.phys_live_birth_file)\n            data = np.concatenate([data, _data])\n            data = np.unique(data, axis=0)\n            i = np.argsort(data[:, -2])\n            data = data[i, :]\n        except (OSError, IOError):\n            pass\n        samples, logL, logL_birth = np.split(data, [-2, -1], axis=1)\n        return samples, logL.flatten(), logL_birth.flatten()\n\n    @property\n    def birth_file(self):\n        """"""File containing dead and birth contours.""""""\n        return self.root + \'_dead-birth.txt\'\n\n    @property\n    def phys_live_birth_file(self):\n        """"""File containing physical live points.""""""\n        return self.root + \'_phys_live-birth.txt\'\n'"
anesthetic/read/samplereader.py,0,"b'""""""Generic sampling reading tools.""""""\nimport os\nfrom anesthetic.read.getdistreader import GetDistReader\nfrom anesthetic.read.montepythonreader import MontePythonReader\nfrom anesthetic.read.polychordreader import PolyChordReader\nfrom anesthetic.read.multinestreader import MultiNestReader\n\n\ndef SampleReader(root):\n    """"""Read from a variety of sampling chains.""""""\n    mn = MultiNestReader(root)\n    if os.path.isfile(mn.ev_file) and os.path.isfile(mn.phys_live_file):\n        return mn\n\n    pc = PolyChordReader(root)\n    if os.path.isfile(pc.birth_file):\n        return pc\n\n    gd = GetDistReader(root)\n    if (os.path.isfile(gd.paramnames_file)\n            and os.path.isfile(gd.chains_files[0])\n            and os.path.isfile(gd.chains_files[-1])):\n        return gd\n\n    mp = MontePythonReader(root)\n    if (os.path.isfile(mp.log_param_file)\n            and os.path.isfile(mp.log_file)\n            and os.path.isfile(mp.paramnames_file)):\n        mp._init()\n        return mp\n\n    errstr = ""Could not find MCMC sampling chains with root %s"" % root\n    try:\n        raise FileNotFoundError(errstr)\n    except NameError:\n        raise IOError(errstr)\n'"
docs/source/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\nimport sys\nimport os\nsys.path.append(os.path.abspath(\'../../\'))\n\ndef get_version(short=False):\n    with open(\'../../README.rst\') as f:\n        for line in f:\n            if \':Version:\' in line:\n                ver = line.split(\':\')[2].strip()\n                if short:\n                    subver = ver.split(\'.\')\n                    return \'%s.%s\' % tuple(subver[:2])\n                else:\n                    return ver\n\n# -- Project information -----------------------------------------------------\n\nproject = \'anesthetic\'\ncopyright = \'2019, Will Handley\'\nauthor = \'Will Handley\'\n\n# The short X.Y version\nversion = get_version(True)\n# The full version, including alpha/beta/rc tags\nrelease = get_version()\n\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.doctest\',\n    \'sphinx.ext.intersphinx\',\n    \'sphinx.ext.todo\',\n    \'sphinx.ext.coverage\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.ifconfig\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.githubpages\',\n    \'sphinx.ext.imgconverter\',\n    \'numpydoc\',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = []\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don\'t match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``[\'localtoc.html\', \'relations.html\', \'sourcelink.html\',\n# \'searchbox.html\']``.\n#\n# html_sidebars = {}\n\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'anestheticdoc\'\n\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'anesthetic.tex\', \'anesthetic Documentation\',\n     \'Will Handley\', \'manual\'),\n]\n\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'anesthetic\', \'anesthetic Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'anesthetic\', \'anesthetic Documentation\',\n     author, \'anesthetic\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n\n# -- Options for Epub output -------------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = project\nepub_author = author\nepub_publisher = author\nepub_copyright = copyright\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#\n# epub_identifier = \'\'\n\n# A unique identification for the text.\n#\n# epub_uid = \'\'\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [\'search.html\']\n\n\n# -- Extension configuration -------------------------------------------------\n\n# -- Options for intersphinx extension ---------------------------------------\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {\n        \'numpy\':(\'http://docs.scipy.org/doc/numpy/\', None),\n        \'scipy\':(\'http://docs.scipy.org/doc/scipy/reference\', None),\n        \'matplotlib\':(\'http://matplotlib.org\', None)\n        }\n\n# -- Options for todo extension ----------------------------------------------\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n'"
