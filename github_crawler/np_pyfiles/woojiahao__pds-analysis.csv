file_path,api_count,code
config.py,0,"b""import os\nclass Config:\n\tDATABASE_CONNECTION_STRING = os.getenv('DATABASE_URL') or 'postgresql://postgres:root@localhost:5432/pds'"""
website.py,0,"b""from app import app, db\nfrom database.database_manager import Manager\nfrom plotting.plot_loader import PlotLoader\n\n\n@app.shell_context_processor\ndef make_shell_context():\n\treturn {\n\t\t'db_manager': Manager(),\n\t\t'plot_loader': PlotLoader(db.engine)\n\t}\n\n\nif __name__ == '__main__':\n\tapp.run(debug=True)\n"""
app/__init__.py,0,"b""from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\n\nfrom config import Config\n\napp = Flask(__name__)\napp.config['TEMPLATES_AUTO_RELOAD'] = True\napp.config['SQLALCHEMY_DATABASE_URI'] = Config.DATABASE_CONNECTION_STRING\napp.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\ndb = SQLAlchemy(app)\n\nfrom app import routes\n"""
app/routes.py,0,"b""from flask import render_template, url_for\n\nfrom app import app\n\n\n@app.route('/')\n@app.route('/home')\ndef home():\n\treturn render_template(\n\t\t'home.html',\n\t\tpage='Introduction',\n\t\tnext=url_for('effects'))\n\n\n@app.route('/effects')\ndef effects():\n\treturn render_template(\n\t\t'effects.html',\n\t\tpage='Effects of declining birth rate',\n\t\tback=url_for('home'),\n\t\tnext=url_for('hypothesis'))\n\n\n@app.route('/hypothesis')\ndef hypothesis():\n\treturn render_template(\n\t\t'hypothesis.html',\n\t\tpage='Hypothesis',\n\t\tback=url_for('effects'),\n\t\tnext=url_for('live_births_rate'))\n\n\n@app.route('/live-births-rate')\ndef live_births_rate():\n\treturn render_template(\n\t\t'live_births.html',\n\t\tpage='Live Births Rate',\n\t\tback=url_for('hypothesis'),\n\t\tnext=url_for('correlation_live_birth_enrolment'))\n\n\n@app.route('/correlation_live_birth_enrolment')\ndef correlation_live_birth_enrolment():\n\treturn render_template(\n\t\t'correlation_live_birth_enrolment.html',\n\t\tpage='Correlation between live birth rate and primary enrolment',\n\t\tback=url_for('live_births_rate'),\n\t\tnext=url_for('causes'))\n\n\n@app.route('/causes')\ndef causes():\n\treturn render_template(\n\t\t'causes.html',\n\t\tpage='Potential causes of a declining birth rate',\n\t\tback=url_for('correlation_live_birth_enrolment'),\n\t\tnext=url_for('occupation')\n\t)\n\n\n@app.route('/occupation')\ndef occupation():\n\treturn render_template(\n\t\t'occupation.html',\n\t\tpage='Mother\\'s Occupation',\n\t\tback=url_for('causes'),\n\t\tnext=url_for('cost_of_living'))\n\n\n@app.route('/cost_of_living')\ndef cost_of_living():\n\treturn render_template(\n\t\t'cost_of_living.html',\n\t\tpage='Cost of living',\n\t\tback=url_for('occupation'),\n\t\tnext=url_for('conclusion'))\n\n\n@app.route('/conclusion')\ndef conclusion():\n\treturn render_template(\n\t\t'conclusion.html',\n\t\tpage='Conclusion',\n\t\tback=url_for('cost_of_living')\n\t)\n\n\n@app.route('/setup')\ndef setup():\n\treturn render_template('setup.html', page='Setup')\n\n\n@app.route('/about')\ndef about():\n\treturn render_template('about.html', page='About')\n"""
database/__init__.py,0,b''
database/alchemy_manager.py,0,"b'from numpy.core.multiarray import ndarray\nfrom pandas import DataFrame\nfrom sqlalchemy.engine import Engine\nfrom sqlalchemy.ext.declarative import declarative_base\n\nfrom app import db\n\n\nclass AlchemyManager:\n\tdef __init__(self):\n\t\tself.engine: Engine = db.engine\n\t\tself.Base = declarative_base(bind=self.engine)\n\t\tself.metadata = self.Base.metadata\n\n\tdef has_table(self, tablename: str):\n\t\tself.metadata.reflect(bind=self.engine)\n\t\ttry:\n\t\t\tself.metadata.tables[tablename]\n\t\texcept KeyError:\n\t\t\treturn False\n\t\treturn True\n\n\tdef create_table(self, attr_dict: dict):\n\t\ttable = type(attr_dict[\'__tablename__\'], (self.Base,), attr_dict)\n\t\ttable.extend_existing = True\n\t\tself.metadata.create_all(bind=self.engine)\n\t\tdb.session.commit()\n\t\tprint(f\'{attr_dict[""__tablename__""]} has been created\')\n\n\tdef populate_table(self, data_frame: DataFrame, tablename: str):\n\t\tself.metadata.reflect(bind=self.engine)\n\t\ttable = self.metadata.tables[tablename]\n\t\twith self.engine.connect() as conn:\n\t\t\tfor row in data_frame.values:\n\t\t\t\tprint(row)\n\t\t\t\tins = table.insert(values=ndarray.tolist(row))\n\t\t\t\tconn.execute(ins)\n'"
database/data_types.py,0,"b""class DataTypes:\n\tINT64 = 'int64'\n\tSTR = 'object'\n\tFLOAT64 = 'float64'\n\tDATETIME = 'datetime64'\n\tBOOLEAN = 'bool'"""
database/database_manager.py,0,"b""from config import Config\nfrom database.data_types import DataTypes\nfrom entities.entity import Entity\nfrom entities.entity_loader import EntityLoader\n\n\nclass Manager:\n\tdef __init__(self):\n\t\tprint(Config.DATABASE_CONNECTION_STRING)\n\t\tself.entity_loader = EntityLoader()\n\t\tself.entities = []\n\n\tdef load_data(self):\n\t\tself.__load_entities__()\n\t\tif not self.__has_database__():\n\t\t\tprint('Data not loaded yet, loading now')\n\t\t\tself.entity_loader.add_entities(self.entities)\n\t\t\tself.entity_loader.load_all()\n\t\t\tprint('Data loaded')\n\n\tdef __has_database__(self):\n\t\thas_table = True\n\t\tfor entity in self.entities:\n\t\t\thas_table &= self.entity_loader.alchemy_manager.has_table(entity.tablename)\n\n\t\treturn has_table\n\n\tdef __load_entities__(self):\n\t\tlive_births = Entity(\n\t\t\ttablename='live_births',\n\t\t\tfile_name='data/live-births.csv',\n\t\t\tattrs={\n\t\t\t\t'year': {\n\t\t\t\t\t'dtype': DataTypes.INT64,\n\t\t\t\t\t'primary_key': True\n\t\t\t\t},\n\t\t\t\t'type': {\n\t\t\t\t\t'dtype': DataTypes.STR,\n\t\t\t\t\t'primary_key': True,\n\t\t\t\t\t'backing': 'level_1'\n\t\t\t\t},\n\t\t\t\t'total': {\n\t\t\t\t\t'dtype': DataTypes.INT64,\n\t\t\t\t\t'primary_key': False,\n\t\t\t\t\t'backing': 'value'\n\t\t\t\t}\n\t\t\t},\n\t\t\treplace_vals=['na'],\n\t\t\tfill_val=0\n\t\t)\n\n\t\toccupations = Entity(\n\t\t\ttablename='mothers_occupations',\n\t\t\tfile_name='data/live-births-by-occupation-of-mother-and-birth-order.csv',\n\t\t\tattrs={\n\t\t\t\t'month': {\n\t\t\t\t\t'dtype': DataTypes.DATETIME,\n\t\t\t\t\t'primary_key': True\n\t\t\t\t},\n\t\t\t\t'occupation': {\n\t\t\t\t\t'dtype': DataTypes.STR,\n\t\t\t\t\t'primary_key': True,\n\t\t\t\t\t'backing': 'mother_occupation'\n\t\t\t\t},\n\t\t\t\t'order': {\n\t\t\t\t\t'dtype': DataTypes.STR,\n\t\t\t\t\t'primary_key': True\n\t\t\t\t},\n\t\t\t\t'birth_count': {\n\t\t\t\t\t'dtype': DataTypes.INT64,\n\t\t\t\t\t'primary_key': False,\n\t\t\t\t}\n\t\t\t}\n\t\t)\n\n\t\tenrolment = Entity(\n\t\t\ttablename='enrolment',\n\t\t\tfile_name='data/primary-enrolment-by-age.csv',\n\t\t\tattrs={\n\t\t\t\t'year': {\n\t\t\t\t\t'dtype': DataTypes.INT64,\n\t\t\t\t\t'primary_key': True\n\t\t\t\t},\n\t\t\t\t'age': {\n\t\t\t\t\t'dtype': DataTypes.STR,\n\t\t\t\t\t'primary_key': True\n\t\t\t\t},\n\t\t\t\t'sex': {\n\t\t\t\t\t'dtype': DataTypes.STR,\n\t\t\t\t\t'size': 2,\n\t\t\t\t\t'primary_key': True\n\t\t\t\t},\n\t\t\t\t'enrolment': {\n\t\t\t\t\t'dtype': DataTypes.INT64,\n\t\t\t\t\t'primary_key': False,\n\t\t\t\t\t'backing': 'enrolment_primary'\n\t\t\t\t}\n\t\t\t}\n\t\t)\n\n\t\tresale_price = Entity(\n\t\t\ttablename='resale_price',\n\t\t\tfile_name='data/median-resale-prices-for-registered-applications-by-town-and-flat-type.csv',\n\t\t\tattrs={\n\t\t\t\t'quarter': {\n\t\t\t\t\t'dtype': DataTypes.STR,\n\t\t\t\t\t'primary_key': True\n\t\t\t\t},\n\t\t\t\t'town': {\n\t\t\t\t\t'dtype': DataTypes.STR,\n\t\t\t\t\t'primary_key': True\n\t\t\t\t},\n\t\t\t\t'flat_type': {\n\t\t\t\t\t'dtype': DataTypes.STR,\n\t\t\t\t\t'primary_key': True\n\t\t\t\t},\n\t\t\t\t'price': {\n\t\t\t\t\t'dtype': DataTypes.FLOAT64,\n\t\t\t\t\t'primary_key': False\n\t\t\t\t}\n\t\t\t},\n\t\t\treplace_vals=['na', '-'],\n\t\t\tfill_val=0\n\t\t)\n\n\t\tvacancy = Entity(\n\t\t\ttablename='job_vacancy',\n\t\t\tfile_name='data/job-vacancy-rate-topline.csv',\n\t\t\tattrs={\n\t\t\t\t'quarter': {\n\t\t\t\t\t'dtype': DataTypes.STR,\n\t\t\t\t\t'primary_key': True\n\t\t\t\t},\n\t\t\t\t'job_vacancy_rate': {\n\t\t\t\t\t'dtype': DataTypes.FLOAT64,\n\t\t\t\t\t'primary_key': False\n\t\t\t\t}\n\t\t\t}\n\t\t)\n\n\t\tself.entities.extend([enrolment, live_births, occupations, resale_price, vacancy])\n"""
database/writer.py,0,"b'import pandas as pd\nfrom pandas import DataFrame\nfrom sqlalchemy import *\n\nfrom database.alchemy_manager import AlchemyManager\nfrom database.data_types import DataTypes\n\n\n# todo: introduce more date formats\nclass Writer:\n\tdef __init__(self, alchemy_manager: AlchemyManager):\n\t\tself.alchemy_manager = alchemy_manager\n\n\tdef write(self, tablename: str, data_frame: DataFrame, primary_keys: tuple = None, attrs: dict = None):\n\t\tif attrs is None and primary_keys is None:\n\t\t\traise Exception(\'Specify the primary keys if you are not specifying the attributes\')\n\n\t\tif self.alchemy_manager.has_table(tablename):\n\t\t\traise Exception(f\'{tablename} already exists in the database, please pick another table name\')\n\n\t\tif attrs is not None:\n\t\t\tnum_cols = data_frame.shape[1]\n\t\t\tif len(attrs) != num_cols:\n\t\t\t\traise Exception(\n\t\t\t\t\tf\'Invalid number of columns, data frame requires {num_cols} columns, was given {len(attrs)} columns\')\n\n\t\t\tself.__check_attrs__(data_frame, attrs)\n\n\t\t\tdata_frame = self.__match_attr__(data_frame, attrs)\n\n\t\t\tvalid_pk, primary_keys = self.__is_valid_pk__(data_frame, attrs=attrs)\n\t\t\tif not valid_pk:\n\t\t\t\traise Exception(f\'Primary keys chosen for {attrs} is not valid\')\n\t\telse:\n\t\t\tif not self.__is_valid_pk__(data_frame, primary_keys=primary_keys)[0]:\n\t\t\t\traise Exception(f\'Primary keys chosen {primary_keys} is not valid\')\n\n\t\tdata_frame, attr_dict = self.__generate_attr_dict__(tablename, data_frame, primary_keys, attrs)\n\n\t\tself.alchemy_manager.create_table(attr_dict)\n\t\tself.alchemy_manager.populate_table(data_frame, attr_dict[\'__tablename__\'])\n\n\t\tprint(f\'Success: Created table: {tablename}\')\n\n\tdef __generate_attr_dict__(self, tablename: str, data_frame: DataFrame, primary_keys: tuple,\n\t\t\t\t\t\t\t   attrs: dict = None):\n\t\tattr_dict = { \'__tablename__\': tablename }\n\n\t\tif attrs is None:\n\t\t\tfor columm_name, data_type in data_frame.dtypes.items():\n\t\t\t\tdtype = None\n\t\t\t\tif data_type == DataTypes.INT64:\n\t\t\t\t\tdtype = Integer\n\t\t\t\telif data_type == DataTypes.STR:\n\t\t\t\t\tdtype = String(data_frame[columm_name].map(len).max())\n\t\t\t\telif data_type == DataTypes.BOOLEAN:\n\t\t\t\t\tdtype = Boolean\n\t\t\t\telif data_type == DataTypes.DATETIME:\n\t\t\t\t\tdtype = Date\n\t\t\t\telif data_type == DataTypes.FLOAT64:\n\t\t\t\t\tdtype = Float\n\n\t\t\t\tattr_dict[columm_name] = Column(dtype, primary_key=columm_name in primary_keys)\n\t\telse:\n\t\t\tfor column_name, attributes in attrs.items():\n\t\t\t\tdtype = None\n\t\t\t\tdata_type = attributes[\'dtype\']\n\t\t\t\tif data_type == DataTypes.INT64:\n\t\t\t\t\tdata_frame[column_name] = pd.to_numeric(data_frame[column_name], downcast=\'integer\')\n\t\t\t\t\tdtype = Integer\n\t\t\t\telif data_type == DataTypes.STR:\n\t\t\t\t\tdata_frame[column_name] = data_frame[column_name].astype(str)\n\t\t\t\t\tmax_length = data_frame[column_name].map(len).max()\n\t\t\t\t\tdtype = String(max_length if \'size\' not in attributes else attributes[\'size\'])\n\t\t\t\telif data_type == DataTypes.FLOAT64:\n\t\t\t\t\tdata_frame[column_name] = pd.to_numeric(data_frame[column_name], downcast=\'float\')\n\t\t\t\t\tdtype = Float\n\t\t\t\telif data_type == DataTypes.DATETIME:\n\t\t\t\t\tdata_frame[column_name] = pd.to_datetime(data_frame[column_name])\n\t\t\t\t\tdtype = Date\n\t\t\t\telif data_type == DataTypes.BOOLEAN:\n\t\t\t\t\tdata_frame[column_name] = data_frame[column_name].astype(bool)\n\t\t\t\t\tdtype = Boolean\n\n\t\t\t\tattr_dict[column_name] = Column(dtype, primary_key=attributes[\'primary_key\'])\n\n\t\treturn data_frame, attr_dict\n\n\tdef __is_valid_pk__(self, data_frame: DataFrame, primary_keys: tuple = None, attrs: dict = None):\n\t\tif primary_keys is None:\n\t\t\tprimary_keys = [column_name for column_name, attributes in attrs.items()\n\t\t\t\t\t\t\tif attributes[\'primary_key\']]\n\t\telse:\n\t\t\tfor primary_key in primary_keys:\n\t\t\t\tif primary_key not in data_frame.columns:\n\t\t\t\t\traise Exception(f\'Primary key: {primary_key} is not a valid column name\')\n\n\t\tif len(primary_keys) == 0:\n\t\t\traise Exception(\'No primary keys selected\')\n\n\t\tfiltered = data_frame[primary_keys[0]].map(str)\n\n\t\tfor i in range(1, len(primary_keys)):\n\t\t\tfiltered += data_frame[primary_keys[i]].map(str)\n\n\t\treturn len(filtered) == len(set(filtered)), primary_keys\n\n\tdef __match_attr__(self, data_frame: DataFrame, attrs: dict):\n\t\tcol_names = { }\n\t\tfor column_name, attributes in attrs.items():\n\t\t\tif column_name not in data_frame.columns:\n\t\t\t\tcol_names[attributes[\'backing\']] = column_name\n\t\t\telse:\n\t\t\t\tcol_names[column_name] = column_name\n\n\t\treturn data_frame.rename(columns=col_names)\n\n\tdef __check_attrs__(self, data_frame: DataFrame, attrs: dict):\n\t\t""""""\n\t\tIdeal attr_dict structure:\n\t\tkey: column name\n\t\tvalue: dictionary of attributes\n\t\t+ dtype -> datatype\n\t\t+ primary_key -> True/False\n\t\t+ size -> Applicable for STR only\n\t\t+ backing -> if the column name does not match up with the df column, refer to this field\n\n\t\tSample:\n\t\tattrs = {\n\t\t\t\'year\': {\n\t\t\t\t\'dtype\': DataTypes.INT64,\n\t\t\t\t\'primary_key\': True\n\t\t\t},\n\t\t\t\'cost\': {\n\t\t\t\t\'dtype\': DataTypes.FLOAT64,\n\t\t\t\t\'primary_key\': False,\n\t\t\t\t\'backing\': \'value\'\n\t\t\t}\n\t\t}\n\t\t""""""\n\t\tfor column_name, attributes in attrs.items():\n\t\t\tif \'dtype\' not in attributes:\n\t\t\t\traise Exception(f\'Data type of column: {column_name} not specified\')\n\t\t\tif \'primary_key\' not in attributes:\n\t\t\t\traise Exception(f\'Primary key of column: {column_name} not specified\')\n\t\t\tif column_name not in data_frame.columns and \'backing\' not in attributes:\n\t\t\t\traise Exception(f\'Changing a column: {column_name} will require a \\\'backing\\\' field to be declared\')\n'"
entities/__init__.py,0,b''
entities/entity.py,1,"b""import numpy as np\nimport pandas as pd\n\nfrom database.writer import Writer\n\n\nclass Entity:\n\tdef __init__(self, tablename: str, file_name: str, attrs: dict = None, primary_keys: list = None,\n\t\t\t\t replace_vals: list = None, fill_val: object = None):\n\t\tself.file_name = file_name\n\t\tself.tablename = tablename\n\t\tself.replace_vals = replace_vals\n\t\tself.fill_val = fill_val\n\t\tself.primary_keys = primary_keys\n\t\tself.attrs = attrs\n\n\tdef set_writer(self, writer: Writer):\n\t\tself.writer = writer\n\n\tdef load(self):\n\t\tdf = pd.read_csv(self.file_name)\n\t\tif self.replace_vals is not None:\n\t\t\tif self.fill_val is None:\n\t\t\t\traise Exception(f'Specify a fill value for replacing: {self.replace_vals}')\n\t\t\telse:\n\t\t\t\tdf = df.replace(self.replace_vals, np.NaN).fillna(self.fill_val)\n\n\t\tself.writer.write(self.tablename, df, primary_keys=self.primary_keys, attrs=self.attrs)\n"""
entities/entity_loader.py,0,"b'from database.alchemy_manager import AlchemyManager\nfrom database.writer import Writer\nfrom entities.entity import Entity\n\n\nclass EntityLoader:\n\tdef __init__(self):\n\t\tself.entities = None\n\t\tself.alchemy_manager = AlchemyManager()\n\t\tself.writer = Writer(self.alchemy_manager)\n\n\tdef add_entity(self, entity: Entity):\n\t\tif self.entities is None:\n\t\t\tself.entities = []\n\n\t\tentity.set_writer(self.writer)\n\t\tself.entities.append(entity)\n\n\tdef add_entities(self, entities: list):\n\t\tif self.entities is None:\n\t\t\tself.entities = []\n\n\t\tfor entity in entities:\n\t\t\tself.add_entity(entity)\n\n\tdef load_all(self):\n\t\tfor entity in self.entities:\n\t\t\tentity.load()\n'"
plotting/__init__.py,0,b''
plotting/custom_styles.py,0,"b""from pygal.style import Style\n\nstyle = Style(\n\tfont_family='googlefont:Source+Code+Pro')\n"""
plotting/enrolment.py,1,"b'import numpy as np\nimport pygal as pygal\nfrom sqlalchemy.engine import Engine\n\nfrom plotting.custom_styles import style\nfrom plotting.plot import Plot\n\n\nclass Genders:\n\tMALE = {\n\t\t\'title\': \'Male\',\n\t\t\'value\': \'MF\'\n\t}\n\tFEMALE = {\n\t\t\'title\': \'Female\',\n\t\t\'value\': \'F\'\n\t}\n\tBOTH = {\n\t\t\'title\': \'Both\'\n\t}\n\n\nclass Enrolment:\n\tdef __init__(self, engine: Engine):\n\t\tself.engine = engine\n\t\tself.age_group = [\n\t\t\t\'UNDER 7 YRS\', \'7 YRS\', \'8 YRS\', \'9 YRS\', \'10 YRS\',\n\t\t\t\'11 YRS\', \'12 YRS\', \'13 YRS\', \'14 YRS & OVER\'\n\t\t]\n\t\tself.year_range = Plot.get_year_range(self.engine, \'year\', \'enrolment\')\n\n\t@staticmethod\n\tdef generate_title(gender):\n\t\treturn f\'Primary Enrolment {gender[""title""]} - By Age\'\n\n\tdef plot_line_graph(self, gender):\n\t\tline_chart = pygal.Line(x_label_rotation=270, style=style)\n\t\tline_chart.title = self.generate_title(gender)\n\t\tline_chart.x_labels = map(str, np.arange(self.year_range[\'min\'], self.year_range[\'max\'] + 1))\n\t\tages = self.query_data(gender)\n\t\tfor age, data in ages.items():\n\t\t\tline_chart.add(age, data)\n\n\t\tline_chart.render_to_file(Plot.generate_plot_name(f\'enrolment_{gender[""title""].lower()}\'))\n\n\tdef query_data(self, gender):\n\t\tages = { }\n\t\tfor age in self.age_group:\n\t\t\tages[age] = []\n\n\t\t\tif gender == Genders.BOTH:\n\t\t\t\tquery = f\'SELECT year, age, sum(enrolment.enrolment) AS enrolment FROM enrolment WHERE age=\\\'{age}\\\' GROUP BY year, age ORDER BY year;\'\n\t\t\telse:\n\t\t\t\tquery = f\'SELECT * FROM enrolment WHERE sex=\\\'{gender[""value""]}\\\' AND age=\\\'{age}\\\';\'\n\n\t\t\tresult = self.engine.execute(query)\n\t\t\tfor row in result:\n\t\t\t\tages[age].append(row[\'enrolment\'])\n\t\treturn ages'"
plotting/enrolment_live_birth.py,0,"b""import pygal\n\nfrom plotting.custom_styles import style\nfrom plotting.plot import Plot\n\n\nclass EnrolmentLiveBirth:\n\tdef __init__(self, engine):\n\t\tself.engine = engine\n\n\tdef plot_wrong_scatter(self):\n\t\tscatter_plot = pygal.XY(\n\t\t\tstroke=False,\n\t\t\tstyle=style,\n\t\t\tshow_legend=False,\n\t\t\tx_title='Live Birth Rate',\n\t\t\ty_title='Primary Enrolment')\n\t\tscatter_plot.title = 'Correlation between Primary Enrolment and Live Birth Rate'\n\t\tscatter_plot.add('Correlation', self.query_data('wrong'))\n\t\tscatter_plot.render_to_file(Plot.generate_plot_name('correlation_enrolment_live_birth_wrong'))\n\n\tdef plot_right_scatter(self):\n\t\tscatter_plot = pygal.XY(\n\t\t\tstroke=False,\n\t\t\tstyle=style,\n\t\t\tshow_legend=False,\n\t\t\tx_title='Live Birth Rate',\n\t\t\ty_title='Primary Enrolment')\n\t\tscatter_plot.title = 'Correlation between Primary Enrolment and Live Birth Rate'\n\t\tscatter_plot.add('Correlation', self.query_data('right'))\n\t\tscatter_plot.render_to_file(Plot.generate_plot_name('correlation_enrolment_live_birth_right'))\n\n\tdef query_data(self, version):\n\t\tif version == 'wrong':\n\t\t\tquery = 'SELECT e.year, lb.total, SUM(e.enrolment) ' \\\n\t\t\t\t\t'FROM enrolment AS e, live_births AS lb ' \\\n\t\t\t\t\t'WHERE e.year = lb.year AND lb.type=\\'Total Live-births\\' ' \\\n\t\t\t\t\t'GROUP BY e.year, lb.total ' \\\n\t\t\t\t\t'ORDER BY year;'\n\t\telse:\n\t\t\tquery = 'SELECT e.year, lb.total, SUM(e.enrolment) ' \\\n\t\t\t\t\t'FROM enrolment AS e, live_births AS lb ' \\\n\t\t\t\t\t'WHERE e.year = lb.year + 6 AND lb.type=\\'Total Live-births\\' ' \\\n\t\t\t\t\t'GROUP BY e.year, lb.total ' \\\n\t\t\t\t\t'ORDER BY year;'\n\n\t\tprint(query)\n\t\tresult = self.engine.execute(query)\n\t\treturn [(row['total'], row['sum']) for row in result]\n"""
plotting/job_vacancy.py,0,"b""import pygal\n\nfrom plotting.custom_styles import style\nfrom plotting.plot import Plot\n\n\nclass JobVacancy:\n\tdef __init__(self, engine):\n\t\tself.engine = engine\n\n\tdef plot_line_graph(self):\n\t\tdata = self.query_data()\n\t\tline_graph = pygal.Line(\n\t\t\tshow_legend=False,\n\t\t\tstyle=style,\n\t\t\tx_label_rotation=270,\n\t\t\tshow_minor_x_labels=False)\n\t\tline_graph.title = 'Job Vacancy Rate'\n\t\tline_graph.x_labels = [key for key in data.keys()]\n\t\tline_graph.x_labels_major = [key for key in data.keys() if key[key.rfind('-') + 1:] == 'Q1']\n\t\tline_graph.add('Job Vacancy', [d for d in data.values()])\n\t\tline_graph.render_to_file(Plot.generate_plot_name('job_vacancy_rate'))\n\n\tdef query_data(self):\n\t\tquery = 'SELECT * FROM job_vacancy;'\n\t\tresults = self.engine.execute(query)\n\t\treturn { row['quarter']: row['job_vacancy_rate'] for row in results }"""
plotting/live_birth_rates.py,1,"b""import numpy as np\nimport pygal\n\nfrom plotting.custom_styles import style\nfrom plotting.plot import Plot\n\n\nclass LiveBirthRate:\n\tdef __init__(self, engine):\n\t\tself.engine = engine\n\t\tself.year_range = Plot.get_year_range(self.engine, 'year', 'live_births')\n\t\tself.years_xlabels = np.arange(self.year_range['min'], self.year_range['max'] + 1).tolist()\n\t\tself.data = self.query_data()\n\n\tdef plot_line_graph(self):\n\t\tline_chart = pygal.Line(show_legend=False, x_label_rotation=270, style=style)\n\t\tline_chart.title = 'Live Births'\n\t\tline_chart.x_labels = self.years_xlabels\n\t\tline_chart.add('Live Births', self.data)\n\t\tline_chart.render_to_file(Plot.generate_plot_name('live_birth_line'))\n\n\tdef plot_bar_graph(self):\n\t\tbar_graph = pygal.Bar(show_legend=False, x_label_rotation=270, style=style)\n\t\tbar_graph.title = 'Live Births'\n\t\tprint(self.years_xlabels)\n\t\tbar_graph.x_labels = self.years_xlabels\n\t\tbar_graph.add('Live Births', self.data)\n\t\tbar_graph.render_to_file(Plot.generate_plot_name('live_birth_bar'))\n\n\tdef query_data(self):\n\t\tquery = 'SELECT * FROM live_births WHERE type=\\'Total Live-births\\';'\n\t\tresult = self.engine.execute(query)\n\t\treturn [row['total'] for row in result]"""
plotting/occupation.py,0,"b'import collections\nimport pygal\n\nfrom plotting.custom_styles import style\nfrom plotting.plot import Plot\n\n\nclass Jobs:\n\tUNCLASSIFIED = \'WKRS NOT CLASSIFIABLE BY OCCUPATION\'\n\tPROFESSIONAL = \'PROFESSIONALS\'\n\tUNEMPLOYED = \'PERSONS NOT ECONOMICALLY ACTIVE\'\n\tTECHNICIANS = \'TECHNICIANS & ASSOCIATE PROFS\'\n\tPRODUCTION = \'PRODUCTION CRAFTSMEN & REL WORKERS\'\n\tLEGISLATORS = \'LEGISLATORS, SNR OFFICIALS & MGRS\'\n\tCLEANERS = \'CLEANERS, LABOURERS & REL WORKERS\'\n\tCLERKS = \'CLERICAL WORKERS\'\n\tFARMERS = \'AGRICULTURAL & FISHERY WORKERS\'\n\tRETAIL = \'SERVICE WKRS, SHOP, MARKET SALES WKRS\'\n\tFACTORY = \'PLANT/MACHINE OPERATORS & ASSEMBLERS\'\n\n\nclass Occupation:\n\tdef __init__(self, engine):\n\t\tself.engine = engine\n\n\tdef plot_line_graph(self):\n\t\tdata = self.query_collection_data()\n\t\tline_graph = pygal.Line(x_label_rotation=270, style=style)\n\t\tline_graph.title = \'Live births by Working and Non-Working women\'\n\t\tline_graph.add(\'Working\', [dist[\'working\'] for dist in data.values()])\n\t\tline_graph.add(\'Non-Working\', [dist[\'non_working\'] for dist in data.values()])\n\t\tline_graph.x_labels = [str(key) for key in data.keys()]\n\t\tline_graph.render_to_file(Plot.generate_plot_name(\'working_non_working_live_births\'))\n\n\tdef plot_bar_graph(self):\n\t\tdata = self.query_distribution_data()\n\t\tbar_graph = pygal.Bar(\n\t\t\tshow_legend=False,\n\t\t\tx_label_rotation=270,\n\t\t\tstyle=style,\n\t\t\ttruncate_label=max(map(len, list(data.keys()))))\n\t\tbar_graph.title = \'Live Births By Mother\\\'s Occupation\'\n\t\tbar_graph.x_labels = [key for key in data.keys()]\n\t\tbar_graph.add(\'Live Births\', [val for val in data.values()])\n\t\tbar_graph.render_to_file(Plot.generate_plot_name(\'occupation_bar\'))\n\n\tdef query_collection_data(self):\n\t\tdata = { }\n\t\tquery = \'select working.month, working.working_bc as ""Working"", nonworking.nonworking_bc as ""Non Working"" \' \\\n\t\t\t\t\'from (select month, sum(birth_count) as working_bc from mothers_occupations where occupation not in (\\\'PERSONS NOT ECONOMICALLY ACTIVE\\\', \\\'WKRS NOT CLASSIFIABLE BY OCCUPATION\\\') group by month order by month) as working,\' \\\n\t\t\t\t\'(select month, sum(birth_count) as nonworking_bc from mothers_occupations where occupation in (\\\'PERSONS NOT ECONOMICALLY ACTIVE\\\', \\\'WKRS NOT CLASSIFIABLE BY OCCUPATION\\\') group by month order by month) as nonworking \' \\\n\t\t\t\t\'where working.month = nonworking.month \' \\\n\t\t\t\t\'order by working.month;\'\n\t\tresults = self.engine.execute(query)\n\t\tfor row in results:\n\t\t\tmonth = str(row[\'month\'])\n\t\t\tdata[month[:month.rfind(\'-\')]] = {\n\t\t\t\t\'working\': row[\'Working\'],\n\t\t\t\t\'non_working\': row[\'Non Working\']\n\t\t\t}\n\t\treturn data\n\n\tdef query_distribution_data(self):\n\t\tquery = \'SELECT occupation, SUM(birth_count) \' \\\n\t\t\t\t\'FROM mothers_occupations \' \\\n\t\t\t\t\'GROUP BY occupation \' \\\n\t\t\t\t\'ORDER BY occupation;\'\n\t\tresult = self.engine.execute(query)\n\t\treturn { row[\'occupation\']: row[\'sum\'] for row in result }\n'"
plotting/plot.py,0,"b'import os\n\nfrom sqlalchemy.engine import Engine\n\nfrom config import Config\n\n\nclass Plot:\n\t@staticmethod\n\tdef generate_plot_name(plot_name: str):\n\t\tif os.getenv(\'DATABASE_URL\') is None:\n\t\t\tplot_path = f\'app/static/images/plots/{plot_name}.svg\'\n\t\telse:\n\t\t\tplot_path = f\'/app/static/images/plots/{plot_name}.svg\'\n\t\tprint(plot_path)\n\t\treturn plot_path\n\n\t@staticmethod\n\tdef get_year_range(engine: Engine, year_col: str, table_name: str):\n\t\tquery = f\'SELECT MIN(DISTINCT({year_col})) AS ""min_year"", MAX(DISTINCT({year_col})) AS ""max_year"" \' \\\n\t\t\t\tf\'FROM {table_name};\'\n\t\tresult = engine.execute(query)\n\t\tyears = { }\n\t\tfor row in result:\n\t\t\tyears[\'min\'] = row[0]\n\t\t\tyears[\'max\'] = row[1]\n\t\treturn years\n'"
plotting/plot_loader.py,0,"b'from plotting.enrolment import Enrolment, Genders\nfrom plotting.enrolment_live_birth import EnrolmentLiveBirth\nfrom plotting.job_vacancy import JobVacancy\nfrom plotting.live_birth_rates import LiveBirthRate\nfrom plotting.occupation import Occupation\nfrom plotting.resale_price import ResalePrice, FlatType\n\n\nclass PlotLoader():\n\tdef __init__(self, engine):\n\t\tself.engine = engine\n\n\tdef load_plots(self):\n\t\tenrolment = Enrolment(self.engine)\n\t\tenrolment.plot_line_graph(Genders.MALE)\n\t\tenrolment.plot_line_graph(Genders.FEMALE)\n\t\tenrolment.plot_line_graph(Genders.BOTH)\n\n\t\tlive_births = LiveBirthRate(self.engine)\n\t\tlive_births.plot_line_graph()\n\t\tlive_births.plot_bar_graph()\n\n\t\tcorrelation = EnrolmentLiveBirth(self.engine)\n\t\tcorrelation.plot_wrong_scatter()\n\t\tcorrelation.plot_right_scatter()\n\n\t\toccupation = Occupation(self.engine)\n\t\toccupation.plot_line_graph()\n\t\toccupation.plot_bar_graph()\n\n\t\tjob_vacancy = JobVacancy(self.engine)\n\t\tjob_vacancy.plot_line_graph()\n\n\t\tresale_price = ResalePrice(self.engine)\n\t\tresale_price.plot_histogram(FlatType.FOUR_ROOM, 2015)\n\t\tresale_price.plot_box_plot([FlatType.THREE_ROOM, FlatType.FOUR_ROOM, FlatType.FIVE_ROOM, FlatType.EXECUTIVE], 1)\n\t\tresale_price.plot_line_graph([FlatType.THREE_ROOM, FlatType.FOUR_ROOM, FlatType.FIVE_ROOM, FlatType.EXECUTIVE])\n'"
plotting/resale_price.py,0,"b'import collections\nimport pygal\n\nfrom plotting.custom_styles import style\nfrom plotting.plot import Plot\n\n\nclass FlatType:\n\tONE_ROOM = \'1-room\'\n\tTWO_ROOM = \'2-room\'\n\tTHREE_ROOM = \'3-room\'\n\tFOUR_ROOM = \'4-room\'\n\tFIVE_ROOM = \'5-room\'\n\tEXECUTIVE = \'Executive\'\n\n\nclass ResalePrice:\n\tdef __init__(self, engine):\n\t\tself.engine = engine\n\t\tself.quarters = self.get_quarters()\n\n\tdef plot_histogram(self, flat_type, year):\n\t\tinterval = 50000\n\n\t\tdata = self.query_price_data(flat_type, year)\n\t\tprint(data)\n\n\t\tfiltered = self.filter(data, interval)\n\t\thistogram = pygal.Histogram(\n\t\t\tshow_legend=False,\n\t\t\tstyle=style,\n\t\t\tx_label_rotation=270\n\t\t)\n\t\thistogram.title = f\'Distribution of resale price - {flat_type} in {year}\'\n\t\thistogram.x_labels = [int(key) for key in filtered.keys()]\n\t\thistogram.add(f\'{flat_type}\', self.create_values(self.filter(data, interval), interval))\n\t\thistogram.render_to_file(Plot.generate_plot_name(f\'resale_price_distribution_{flat_type}_{year}\'))\n\n\tdef plot_box_plot(self, flats, quarter):\n\t\tdata = self.query_distribution_data(flats, quarter)\n\n\t\tbox_plot = pygal.Box(box_mode=""stdev"", style=style)\n\t\tbox_plot.title = f\'Distribution of median resale prices in the Q{quarter} (All Time)\'\n\t\tbox_plot.x_labels = flats\n\t\tfor flat in flats:\n\t\t\tbox_plot.add(flat, data[flat])\n\n\t\tbox_plot.render_to_file(Plot.generate_plot_name(f\'resale_price_distribution_box_Q{quarter}_all_time\'))\n\n\tdef plot_line_graph(self, flats):\n\t\tdata = self.query_trend_data(flats)\n\t\tline_graph = pygal.Line(\n\t\t\tstyle=style,\n\t\t\tx_label_rotation=270\n\t\t)\n\t\tline_graph.x_labels = self.quarters\n\t\tline_graph.title = \'Trend of resale prices (All time)\'\n\t\tfor flat in flats:\n\t\t\tline_graph.add(flat, data[flat])\n\t\tline_graph.render_to_file(Plot.generate_plot_name(\'resale_price_trend\'))\n\n\tdef query_trend_data(self, flats):\n\t\tdata = collections.OrderedDict()\n\t\tfor flat in flats:\n\t\t\tquery = f\'SELECT quarter, SUM(price) \' \\\n\t\t\t\t\tf\'FROM resale_price \' \\\n\t\t\t\t\tf\'WHERE flat_type = \\\'{flat}\\\' \' \\\n\t\t\t\t\tf\'GROUP BY quarter \' \\\n\t\t\t\t\tf\'ORDER BY quarter;\'\n\t\t\tresults = self.engine.execute(query)\n\t\t\tdata[flat] = [row[\'sum\'] for row in results]\n\n\t\treturn data\n\n\tdef query_distribution_data(self, flats, quarter):\n\t\tdata = { }\n\t\tfor flat in flats:\n\t\t\tquery = f\'SELECT price FROM resale_price WHERE flat_type=\\\'{flat}\\\' AND quarter like \\\'%%Q{quarter}\\\'\'\n\t\t\tresults = self.engine.execute(query)\n\t\t\tdata[flat] = sorted([row[\'price\'] for row in results if row[\'price\'] > 0])\n\n\t\treturn data\n\n\tdef query_price_data(self, flat_type, year):\n\t\tquery = f\'SELECT * FROM resale_price WHERE quarter LIKE \\\'{year}%%\\\' AND flat_type=\\\'{flat_type}\\\';\'\n\t\tresults = self.engine.execute(query)\n\t\treturn sorted([row[\'price\'] for row in results if row[\'price\'] > 0])\n\n\tdef get_quarters(self):\n\t\tquery = \'SELECT DISTINCT quarter FROM resale_price ORDER BY quarter;\'\n\t\tresults = self.engine.execute(query)\n\t\treturn [row[\'quarter\'] for row in results]\n\n\tdef create_values(self, data, interval):\n\t\treturn [(len(value), int(key), int(key) + interval) for key, value in data.items()]\n\n\tdef filter(self, data, interval):\n\t\tfiltered = collections.OrderedDict()\n\t\tlower_lim, upper_lim = self.find_limit(data[0], data[len(data) - 1], interval)\n\t\tfor i in range(lower_lim, upper_lim + 1, interval):\n\t\t\tfiltered[str(i)] = [value for value in data if i <= value < i + interval]\n\n\t\treturn filtered\n\n\tdef find_limit(self, lower, upper, interval):\n\t\tlower_copy, lower_counter = self.break_up(lower)\n\t\tupper_copy, upper_counter = self.break_up(upper)\n\n\t\tlower_lim = int(lower_copy) * pow(10, lower_counter)\n\t\twhile lower_lim + interval < lower:\n\t\t\tlower_lim += interval\n\n\t\tupper_lim = int(upper_copy) * pow(10, upper_counter)\n\t\twhile True:\n\t\t\tupper_lim += interval\n\t\t\tif upper_lim > upper:\n\t\t\t\tbreak\n\n\t\treturn lower_lim, upper_lim\n\n\tdef break_up(self, val):\n\t\tcounter = 0\n\t\tcopy = val\n\t\twhile copy > 10:\n\t\t\tcopy /= 10\n\t\t\tcounter += 1\n\t\treturn copy, counter\n'"
