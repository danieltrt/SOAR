file_path,api_count,code
priv/jun_enc_dec.py,4,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport pandas as pd\nimport numpy as np\nfrom erlport.erlterms import Atom, List\nfrom erlport.erlang import set_encoder, set_decoder\n\ndef setup_dtype():\n    set_encoder(dtype_encoder)\n    set_decoder(dtype_decoder)\n    return Atom(b\'ok\')\n\ndef dtype_encoder(value):\n    if isinstance(value, np.int64):\n        return np.asscalar(value)\n    elif isinstance(value, np.float64):\n        return np.asscalar(value)\n    elif isinstance(value, str):\n        try:\n            return value.encode(\'utf-8\') # to express as binary() instead of string() on erlang side\n        except:\n            return value\n    elif isinstance(value, list):\n        return [dtype_encoder(v) for v in value]\n    elif isinstance(value, tuple):\n        nvalue = ()\n        for v in value:\n            nvalue = nvalue + (dtype_encoder(v),)\n        return nvalue\n    else:\n        try:\n            return value.encode(\'utf-8\')\n        except:\n            return value\n\ndef dtype_decoder(value):\n    try:\n        if isinstance(value, List):\n            return [dtype_decoder(v) for v in value]\n        elif isinstance(value, tuple):\n            nvalue = ()\n            for v in value:\n                nvalue = nvalue + (dtype_decoder(v),)\n            return nvalue\n        elif isinstance(value, str):\n            return value\n        else:\n            return value.decode(""utf-8"")\n    except:\n        return value\n'"
priv/jun_pandas.py,18,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sys\nimport scipy as sp\nimport numpy as np\nimport matplotlib as mpl\nimport pandas as pd\nimport sklearn as skl\nimport operator as opt\nimport pyodbc as pyodbc\nfrom io import StringIO\nfrom dateutil.parser import parse\nmpl.use(\'Agg\')\nopers = {\'<\': opt.lt,\n         \'>\': opt.gt,\n         \'<=\': opt.le,\n         \'>=\': opt.ge,\n         \'==\': opt.eq,\n         \'!=\': opt.ne}\nsql = [ \'dsn\', \'username\', \'password\', \'database\']\n\n# simple return sys version\ndef version():\n    return sys.version\n\n# descriptive stats over a dataframe\n# this is used with a dynamical assignment since\n# data frame will hold by erlang process and the\n# syntax to apply functions over data will be complex\ndef jun_dataframe(df, fn, args, axis=\'None\', keywords=[]):\n    if ( isinstance(df, pd.core.frame.DataFrame) | isinstance(df, pd.core.groupby.DataFrameGroupBy) ):\n        args = [ islambda_from_erl(arg) for arg in args ]\n        if axis != \'None\':\n            fun = getattr(df[axis], fn)\n        else:\n            fun = getattr(df, fn)\n        # make dict from keywords even if empty!\n        kwargs = dict([ (k, isexpression_from_erl(v)) for (k, v) in keywords ])\n        # explicity execute the fun\n        if len(args) == 0:\n            value = fun(**kwargs)\n        else:\n            value = fun(*args, **kwargs)\n        # check for instance of int64 and return as scalar\n        if isinstance(value, np.int64): \n            return np.asscalar(value)\n        elif isinstance(value, np.float64):\n            return np.asscalar(value)\n        elif isinstance(value, pd.core.frame.DataFrame):\n            return (\'pandas.core.frame.DataFrame\', value)\n        elif isinstance(value, pd.core.groupby.DataFrameGroupBy):\n            return (\'pandas.core.groupby.DataFrameGroupBy\', value)\n        elif isinstance(value, pd.core.frame.Series):\n            return (\'pandas.core.frame.Series\', value)\n        elif isinstance(value, np.ndarray):\n            return \',\'.join(_fix(v) for v in value)\n        elif value is None: # commonly when fun applies over callable object\n            return (\'pandas.core.frame.DataFrame\', df)\n        elif pd.isnull(value):\n            return np.nan_to_num(value)\n        else:\n            return value\n    else:\n        return \'error_format_data_frame_invalid\'\n\n# a common function to decode the pandas dataframe into\n# a readable erlang term\ndef to_erl(value):\n    if isinstance(value, pd.core.frame.DataFrame):\n        # fill NaN as default since term cannot back to py\n        jundataframe = value.fillna(\'NaN\').values.tolist()\n        columns = list(value)\n        return (\'pandas.core.frame.DataFrame\', columns, jundataframe)\n    else:\n        return \'error_formar_data_frame_invalid\'\n\n# working with columns are a important feature, but the main\n# function cannot deal with that, so just add a specific fn to that\n# When using multiIndex ensure index names!\ndef columns(df):\n    if isinstance(df, pd.core.frame.DataFrame):\n        if isinstance(df.index, pd.core.index.MultiIndex):\n            columns = list(df) + list(df.index.names)\n        else:\n            columns = list(df)\n        columns_as_str = \',\'.join(columns)\n        return columns_as_str\n    else:\n        return \'error_format_data_frame_invalid\'\n\n# len columns helper\ndef len_columns(df):\n    if isinstance(df, pd.core.frame.DataFrame):\n        return len(df.columns)                    \n    else:\n        return \'error_format_data_frame_invalid\'\n\n# len index helper\ndef len_index(df):\n    if isinstance(df, pd.core.frame.DataFrame):\n        return len(df.index)\n    else:\n        return \'error_format_data_frame_invalid\'\n\n# memory usage helper\ndef memory_usage(df):\n    if isinstance(df, pd.core.frame.DataFrame):\n        num = df.memory_usage(index=True, deep=True).sum()\n        return _sizeof_fmt(num)\n    else:\n        return \'error_format_data_frame_invalid\'\n\n# columns description (in a csv format) helper\ndef info_columns(df):\n    if isinstance(df, pd.core.frame.DataFrame):\n        lines = """"\n        counts = df.count() # for non-null values\n        for i, column in enumerate(df.columns):\n            dtype = df.dtypes.iloc[i]\n            nonnull = counts.iloc[i]\n            lines = lines + ""%s,%s,%s\\n"" % (column, dtype, nonnull)\n        return lines\n    else:\n        return \'error_format_data_frame_invalid\'\n\n# size into human readable, taken from:\n# https://github.com/pandas-dev/pandas/blob/master/pandas/core/frame.py\ndef _sizeof_fmt(num):\n    # returns size in human readable format\n    for x in [\'bytes\', \'KB\', \'MB\', \'GB\', \'TB\']:\n        if num < 1024.0:\n            return ""%3.1f%s %s"" % (num, \'+\', x)\n        num /= 1024.0\n    return ""%3.1f%s %s"" % (num, \'+\', \'PB\')\n\n# common helper for plotting functions, wrapped over\n# erlang, declare if outputs goes to a path (image) or\n# only holds into memory as a single py dtype\ndef jun_dataframe_plot(df, save=\'None\', keywords=[]):\n    if ( isinstance(df, pd.core.frame.DataFrame) ):\n        # make dict from keywords even if empty!\n        kwargs = dict([ (k, isexpression_from_erl(v)) for (k, v) in keywords ])\n        # IMPORTANT: check if columns has the x and y, otherwise remove to plot\n        x = kwargs.get(\'x\', \'None\')\n        y = kwargs.get(\'y\', \'None\')\n        columns = list(df)\n        if x not in columns and x != \'None\':\n          del kwargs[\'x\']\n        if y not in columns and y != \'None\':\n          del kwargs[\'y\']\n        # explicity execute the fun\n        plot = df.plot(**kwargs)\n        if save != \'None\':\n            fig = plot.get_figure()\n            fig.savefig(save, bbox_inches=\'tight\') # save contains path\n            return \'matplotlib.AxesSubplot\'\n        else:\n            return (\'matplotlib.AxesSubplot\', plot) # this is correct? because can be confusing with opaque df\n    else:\n        return \'error_format_data_frame_invalid\'\n\n# common selection of columns (slicing)\n# this can be acomplished using loc but it\'s better\n# using a single syntax such as accesing data from dataframe\ndef selection(df, columns):\n    if ( isinstance(df, pd.core.frame.DataFrame) ):\n        return (\'pandas.core.frame.DataFrame\', df[list(columns)])\n    else:\n        return \'error_format_data_frame_invalid\'\n\n# since query function cannot evaluate columns\n# with spaces in it (or even values) just use the legacy query\n# as a single filter, check for strings comparison as contains\ndef legacy_query(df, column, operand, value):\n    if ( isinstance(df, pd.core.frame.DataFrame) | isinstance(df, pd.core.groupby.DataFrameGroupBy) ):\n        operation = opers[operand]\n        if isinstance(value, str):\n            try:\n                parse(value, False)\n                newdf = df[operation(df[column], value)]\n            except ValueError:\n                if operand == \'!=\':\n                    newdf = df[~df[column].str.contains(value, na=False)]\n                elif operand == \'==\':\n                    newdf = df[df[column].str.contains(value, na=False)] # since str cannot be evaluated with \'==\'\n                else:\n                    return \'error_string_operand_invalid\'\n        else:\n            newdf = df[operation(df[column], value)]\n\n        if isinstance(newdf, pd.core.frame.DataFrame):\n            return (\'pandas.core.frame.DataFrame\', newdf)\n        elif isinstance(newdf, pd.core.groupby.DataFrameGroupBy):\n            return (\'pandas.core.groupby.DataFrameGroupBy\', newdf)\n        else:\n            return newdf\n    else:\n        return \'error_format_data_frame_invalid\'\n\n# simple receiver for a lambda in string mode and pass\n# back to opaque term, it means a valid evaluated lambda\n# into py environment\ndef islambda_from_erl(fn):\n    try:\n        fn0 = eval(fn)\n        if ( callable(fn0) and fn0.__name__ == \'<lambda>\' ):\n            return fn0\n        else:\n            raise Exception(\'err.invalid.jun.Lambda\', \'not a lambda valid function from erl instance\')\n    except:\n        return fn # return fn safetly, same as passed\n\n# simple assignment for a serie to a dataframe as column or\n# even other assignments, but do it from here since cannot be evaluated\n# outside due to py syntax\ndef legacy_assignment(df, column, value):\n    if ( isinstance(df, pd.core.frame.DataFrame) | isinstance(df, pd.core.groupby.DataFrameGroupBy) ):\n        df[column] = value\n        if isinstance(df, pd.core.frame.DataFrame):\n            return (\'pandas.core.frame.DataFrame\', df)\n        elif isinstance(df, pd.core.groupby.DataFrameGroupBy):\n            return (\'pandas.core.groupby.DataFrameGroupBy\', df)\n        else:\n            return df\n    else:\n        return \'error_format_data_frame_invalid\'\n\n# descriptive stats over a series\n# this is used with a dynamical assignment since\n# series will hold by erlang process and the\n# syntax to apply functions over data will be complex\ndef jun_series(series, fn, args, axis=\'None\', keywords=[]):\n    if ( isinstance(series, pd.core.frame.Series) ):\n        args = [ islambda_from_erl(arg) for arg in args ]\n        keywords = [ (k, islambda_from_erl(v)) for (k, v) in keywords ]\n        # for complete integration also check for keywords with lambdas\n        # keywords = [ islambda_from_erl(keyword) for keyword in keywords ]\n        if axis != \'None\':\n            fun = getattr(series[axis], fn)\n        else:\n            fun = getattr(series, fn)\n        # make dict from keywords even if empty!\n        kwargs = dict([ (k, isexpression_from_erl(v)) for (k, v) in keywords ])\n        # explicity execute the fun\n        if len(args) == 0:\n            value = fun(**kwargs)\n        else:\n            value = fun(*args, **kwargs)\n        # check for instance of int64 and return as scalar\n        if isinstance(value, np.int64):\n            return np.asscalar(value)\n        elif isinstance(value, np.float64):\n            return np.asscalar(value)\n        elif isinstance(value, pd.core.frame.Series):\n            return (\'pandas.core.frame.Series\', value)\n        elif isinstance(value, np.ndarray):\n            return \',\'.join(_fix(v) for v in value)\n        elif pd.isnull(value):\n            return np.nan_to_num(value)\n        else:\n            return value\n    else:\n        return \'error_format_series_invalid\'\n\n# in keywords we cannot assing so easily the data comming from\n# erlang, since protocol buffers keep keywords as single strings\n# in key and value, eval each value so we can check if some of them\n# must be evaluated as an expression\ndef isexpression_from_erl(expression):\n    try:\n        return eval(expression)\n    except:\n        return expression # return fn safetly, same as passed\n\n# this is used to apply functions to a\n# single dataframe but instead of getting functions to apply\n# based on the DataFrame class, use directly pandas implementation\ndef jun_pandas(fn, args, keywords=[]):\n    args = [ islambda_from_erl(arg) for arg in args ]\n    fun = getattr(pd, fn)\n    # we need to check the conn if using `read_sql` since conn\n    # cannot be pickled :-(\n    if fn == \'read_sql\':\n        keywords.extend([(\'con\', conn(keywords, sql))])\n    # make dict from keywords even if empty!\n    kwargs = dict([ (k, isexpression_from_erl(v)) for (k, v) in keywords if not k in sql])\n    # explicity execute the fun\n    if len(args) == 0:\n        value = fun(**kwargs)\n    else:\n        value = fun(*args, **kwargs)\n    # check for instance of int64 and return as scalar\n    if isinstance(value, np.int64):\n        return np.asscalar(value)\n    elif isinstance(value, np.float64):\n        return np.asscalar(value)\n    elif isinstance(value, pd.core.frame.DataFrame):\n       return (\'pandas.core.frame.DataFrame\', value)\n    elif isinstance(value, pd.core.groupby.DataFrameGroupBy):\n        return (\'pandas.core.groupby.DataFrameGroupBy\', value)\n    elif isinstance(value, pd.core.frame.Series):\n        return (\'pandas.core.frame.Series\', value)\n    elif isinstance(value, np.ndarray):\n        return \',\'.join(_fix(v) for v in value)\n    elif pd.isnull(value):\n        return np.nan_to_num(value)\n    else:\n        return value\n\n# single selection of a column, return a series data\n# since this are now supported by jun core\ndef single_selection(df, column):\n    if ( isinstance(df, pd.core.frame.DataFrame) ):\n        return (\'pandas.core.frame.Series\', df[column])\n    else:\n        return \'error_format_data_frame_invalid\'\n\n# timedelta operations\ndef jun_timedelta(series, fn, axis=\'None\', keywords=[]):\n    if isinstance(series, pd.core.frame.Series):\n        fun = getattr(series, \'dt\')\n        value = getattr(fun, fn)\n        if isinstance(value, pd.core.frame.Series):\n            return (\'pandas.core.frame.Series\', value)\n        else:\n            return value\n    else:\n        return \'error_format_data_frame_or_serie_invalid\'\n\n# make a valid connection for sql using\n# pyodbc, this will return an opaque connection\n# to erlang, but the jun_pandas module will use that\n# to use related functions using such connection.\ndef conn(keywords, sql):\n    # ensure that ini file exists to generate the connection\n    for (k, v) in keywords:\n        if k in sql:\n            if k == \'dsn\':\n                dsn = \'DSN=\' + v\n            elif k == \'username\':\n                username = \'UID=\' + v\n            elif k == \'password\':\n                password = \'PWD=\' + v\n            elif k == \'database\':\n                database = \'DATABASE=\' + v\n    setup_conn = ( dsn, username, password, database )\n    conn = pyodbc.connect(\';\'.join(str(arg) for arg in setup_conn))\n    return conn\n\n# custom fun to treat string as a new dataframe\n# this from python is a custom code so JUN implements directly from\n# its API\ndef read_string(string, keywords):\n    try:\n        string = string.decode(\'utf-8\')\n    except:\n        string = string\n    args = [StringIO(string)]\n    fun = getattr(pd, \'read_csv\')\n    kwargs = dict(keywords)\n    # explicity execute the fun\n    value = fun(*args, **kwargs)\n    return (\'pandas.core.frame.DataFrame\', value)\n\ndef _fix(v):\n    if pd.isnull(v):\n        return \'nan\'\n    elif isinstance(v, str):\n        return v\n    else:\n        try:\n            if isinstance(v, unicode):\n                return v.encode(\'utf-8\')\n            else:\n                return v\n        except:\n            return str(v)\n'"
priv/jun_plotly.py,0,"b""#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sys\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nimport chart_studio.plotly as py\nimport cufflinks as cf\n\n# define a global dict to store items that not working pickled\npickling = {}\n\n# simple return sys version\ndef version():\n    return sys.version\n\n# common helper for plotting functions in plotly\n# using cufflinks, wrapped over erlang,\n# return the url holding the plot to use in the client \ndef jun_iplot_dataframe(df, key, keywords=[]):\n    if ( isinstance(df, pd.core.frame.DataFrame) ):\n        # make dict from keywords even if empty!\n        kwargs = dict(keywords)\n        # IMPORTANT: check if columns has the x and y, otherwise remove to plot\n        x = kwargs.get('x')\n        y = kwargs.get('y')\n        columns = list(df)\n        if x not in columns:\n          del kwargs['x']\n        if y not in columns:\n          del kwargs['y']\n        # explicity execute the fun\n        iplot = df.iplot(**kwargs)\n        pickling[key] = iplot\n        # use get data since this should be achive as figure\n        return ('plotly.iplot', key)\n    else:\n        return 'error_format_data_frame_invalid'\n\ndef jun_iplot_plot(iplot, filename, keywords=[]):\n    iplot = pickling[iplot]\n    url = py.plot(iplot, filename=filename, auto_open=False)\n    return url\n\ndef jun_iplot_extend(iplot_x, iplot_y, keywords=[]):\n    iplot_yy = pickling[iplot_y]\n    iplot_xx = pickling[iplot_x]\n    iplot_yy.add_trace(iplot_xx['data'][0])\n    pickling[iplot_y] = iplot_yy\n    return ('plotly.iplot', iplot_y)\n\ndef jun_iplot_get_figure(url, key, keywords=[]):\n    iplot = py.get_figure(url)\n    pickling[key] = iplot\n    return ('plotly.iplot', key)\n"""
priv/jun_seaborn.py,0,"b""#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sys\nimport scipy as sp\nimport numpy as np\nimport matplotlib as mpl\nimport pandas as pd\nimport sklearn as skl\nmpl.use('Agg')\nimport seaborn as sns\n\n# common helper for dataframe plot using seaborn,\n# trying to return a file instead a raw opaque item\ndef jun_dataframe_plot(df, fn, save='None', keywords=[]):\n    if ( isinstance(df, pd.core.frame.DataFrame) ):\n        # clean before any plot\n        mpl.pyplot.figure()\n        # make dict from keywords even if empty!\n        kwargs = dict(keywords)\n        # get the fun from seaborn directly since we want a dynamic call\n        fun = getattr(sns, fn)\n        plot = fun(**kwargs)\n        if ( plot.__class__.__name__ == 'AxesSubplot' ):\n            plot_class = 'matplotlib.AxesSubplot'\n        else:\n            plot_class = 'seaborn.axisgrid.*'\n        if save != 'None':\n            # if figure comes from seaborn use fig, otherwise get_figure\n            if ( plot_class == 'matplotlib.AxesSubplot' ):\n                fig = plot.get_figure()\n            else:             \n                fig = plot.fig\n            fig.savefig(save, bbox_inches='tight') # save contains path\n            return plot_class\n        else:\n            return (plot_class, plot) # this is correct? because can be confusing with opaque df\n    else:\n        return 'error_format_data_frame_invalid'\n"""
