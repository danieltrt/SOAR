file_path,api_count,code
src/beautifulsoup/main.py,0,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/10/17\n""""""\n\nimport urllib\nfrom bs4 import BeautifulSoup\n\n\nfor i in range(111, 601):\n    f = open(""file1.txt"", ""a"")\n    url = """" + str(i)\n    page = urllib.request.urlopen(url)\n    soup = BeautifulSoup(page, ""html.parser"")\n    soup = str(soup)\n    f.write(soup)\n    print(\'save \' + url + \'!\')\n    f.close()\n\nf.close()\n'"
src/bilinear_interpolation/main.py,1,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/10/17\n""""""\n\nimport cv2\nimport numpy as np\n\n\ndef bilinear(img, m, n):\n    height, width, channels = img.shape\n    emptyImage = np.zeros((m, n, channels), np.uint8)\n    value = [0, 0, 0]\n    sh = m / height\n    sw = n / width\n\n    for i in range(m):\n        for j in range(n):\n            x = i / sh\n            y = j / sw\n            p = (i + 0.0) / sh - x\n            q = (j + 0.0) / sw - y\n            x = int(x) - 1\n            y = int(y) - 1\n            for k in range(3):\n                if x + 1 < m and y + 1 < n:\n                    value[k] = int(\n                        img[x, y][k] * (1 - p) * (1 - q) + img[x, y + 1][k] * q * (1 - p) + img[x + 1, y][k] * (\n                                    1 - q) * p + img[x + 1, y + 1][k] * p * q)\n            emptyImage[i, j] = (value[0], value[1], value[2])\n\n    return emptyImage\n\n\nimg = cv2.imread(""2.jpg"")\n# print(img.shape)\nif img.shape[0] < img.shape[1] < 256:\n    target1 = 256\n    target2 = img.shape[1] / img.shape[0] * 256\n    target2 = int(target2)\n\n    print(\'warning: image with size ({0}, {1}) is too small!\'.format(img.shape[0], img.shape[1]))\nelif img.shape[1] <= img.shape[0] < 256:\n    target2 = 256\n    target1 = img.shape[0] / img.shape[1] * 256\n    target1 = int(target1)\n    print(\'warning: image with size ({0}, {1}) is too small!\'.format(img.shape[0], img.shape[1]))\n\nresult = bilinear(img, target1, target2)\ncv2.imwrite(\'256.jpg\', result)\n'"
src/image_similarity/new_ssim.py,0,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/10/17\n""""""\n\nimport skimage.measure as skm\nimport cv2\nimport os.path as osp\nimport os\nimport pdb\nfrom math import sqrt\n\n\ndef my_ssim(x, y):\n    # pdb.set_trace()\n    # h = y.shape[0]\n    # w = y.shape[1]\n    # x = x[:h, :w, :]\n    K1 = 0.01; K2 = 0.03; L = 255\n    C1 = pow(K1 * L, 2); C2 = pow(K2 * L, 2); C3 = C2 / 2\n\n    mx = x.mean()\n    my = y.mean()\n    oxx = sqrt(variance(x, x))\n    oyy = sqrt(variance(y, y))\n    oxy = variance(x, y)\n\n    L = (2*mx*my + C1) / (pow(mx, 2) + pow(my, 2) + C1)\n    C = (2*oxx*oyy + C2) / (pow(oxx, 2) + pow(oyy, 2) + C2)\n    S = (oxy + C3) / (oxx*oyy + C3)\n\n    file = open(\'result.txt\', \'a\')\n    file.write(\'L: {0}\\nC: {1}\\nS: {2}\\n\\n\'.format(L, C, S))\n\n    return L*C*S\n\ndef variance(x ,y):\n    mx = x.mean()\n    my = y.mean()\n    h = y.shape[0]\n    w = y.shape[1]\n    c = 3\n    sum = 0\n\n    for i in range(h):\n        for j in range(w):\n            for k in range(3):\n                sum += (x[i, j, k] - mx) * (y[i, j, k] - my)\n\n    sum /= h*w*c - 1\n\n    return sum\n\ndef ssim(x, y):\n    # y = y[60:70, 60:70, :]\n    # x = x[60:70, 60:70, :]\n    h = y.shape[0]\n    w = y.shape[1]\n    x = x[:h, :w, :]\n\n    # print(pytorch_ssim.ssim(x, y))\n    return skm.compare_ssim(x, y, multichannel=True)\n\n\nif __name__ == \'__main__\':\n    pathX = \'pic\\sketch_cycle\'\n    pathY = \'pic\\sketch_p2p\'\n\n    fileX = os.listdir(pathX)\n    fileY = os.listdir(pathY)\n    result = []\n    count = 0\n\n    for imageX, imageY in zip(fileX, fileY):\n        count += 1\n        imageX = osp.join(pathX, imageX)\n        imageY = osp.join(pathY, imageY)\n        x = cv2.imread(imageX)\n        y = cv2.imread(imageY)\n        # x = cv2.resize(x, (250, 250), interpolation=cv2.INTER_LANCZOS4)\n\n        result.append(my_ssim(x, y))\n\n        if count % 10 == 0:\n            print(\'{0} pairs done\'.format(count))\n\n    print(sum(result) / len(result))\n'"
src/image_similarity/ssim.py,0,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/10/17\n""""""\n\nimport cv2\nfrom skimage.measure import compare_ssim\nimport os\nimport os.path as osp\n\n\ndef save_image(X):\n    image_root = \'pic\'\n    file = open(osp.join(image_root, \'pixel.txt\'), \'a\')\n\n    for pixel in X:\n        file.write(str(list(pixel)))\n        file.write(\'\\n\')\n\n    file.close()\n\n\ndef get_ssim(X, Y):\n    w = Y.shape[0]\n    h = Y.shape[1]\n    X = X[:w, :h, :]\n    # save_image(Y)\n    # input()\n\n    return compare_ssim(X, Y, multichannel=True)\n\n\ndef black2white(X):\n    count = 0\n\n    for i in X:\n        for j in i:\n            if j[0] == 0 and j[1] == 0 and j[2] == 0:\n                count += 1\n                for k in range(3):\n                    j[k] = 0\n\n    print(count)\n    return X\n\n\nif __name__ == \'__main__\':\n    image_root = \'pic\'\n    save_root = \'new\'\n    X_root = osp.join(image_root, \'sketch_p2p\')\n    Y_root = osp.join(image_root, \'sketch_real\')\n\n    X_images = os.listdir(X_root)\n    Y_images = os.listdir(Y_root)\n    ssim = []\n\n    for X_image, Y_image in zip(X_images, Y_images):\n        print(\'{0} vs {1}\'.format(X_image, Y_image))\n        X = cv2.imread(osp.join(X_root, X_image))\n        Y = cv2.imread(osp.join(Y_root, Y_image))\n        X = cv2.resize(X, (250, 250), interpolation=cv2.INTER_LANCZOS4)\n        result = get_ssim(X, Y)\n        print(result)\n        ssim.append(float(result))\n        # process images\n        # X = cv2.imread(osp.join(X_root, X_image))\n        # Y = cv2.imread(osp.join(Y_root, Y_image))\n        # X = black2white(X)\n        # print(X.shape)\n        # cv2.imwrite(osp.join(save_root, X_image), X)\n\n    print(\'average: %f\' % (sum(ssim) / len(ssim)))\n    print(\'done\')\n'"
src/lfw_txt/main.py,0,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/10/17\n""""""\n\nimport sys\n\ndef get_all_images(filename):\n    file = open(filename)\n    lines = file.readlines()\n    list = []\n    for line in lines:\n        line_split = line.strip(\'\\n\').split(\'\\t\')\n        if(len(line_split)) == 3:\n            line_split[-1] = line_split[-1].zfill(4)\n            line_split[-2] = line_split[-2].zfill(4)\n        if(len(line_split)) == 4:\n            line_split[-1] = line_split[-1].zfill(4)\n            line_split[-3] = line_split[-3].zfill(4)\n        list.append(line_split)\n    file.close()\n    return list\n\ndef save2labelfile(list):\n    file = open(\'label.txt\', \'w\')\n    labellines = []\n    for i in range(len(list)):\n        if len(list[i]) == 3:\n            labelline = list[i][0] + \'/\' + list[i][0] + \'_\' + list[i][1] + \'.jpg\' + \'\\t\' + list[i][0] + \'/\' + list[i][0] + \'_\' +list[i][2] + \'.jpg\' + \'\\t\' + \'1\\n\'\n            labellines.append(labelline)\n        elif len(list[i]) == 4:\n            labelline = list[i][0] + \'/\' + list[i][0] + \'_\' + list[i][1] + \'.jpg\' + \'\\t\' + list[i][2] + \'/\' + list[i][2] + \'_\' + list[i][3] + \'.jpg\' + \'\\t\' + \'0\\n\'\n            labellines.append(labelline)\n    file.writelines(labellines)\n    file.close()\n\n\nif __name__ == ""__main__"":\n    if len(sys.argv) != 2:\n        print(""Format Error! Usuage: python %s pairs.txt"" % (sys.argv[0]))\n        sys.exit()\n\n    list = get_all_images(""pairs.txt"")\n    save2labelfile(list)\n    print(""Done!"")'"
src/mat/main.py,2,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/10/17\n""""""\n\nfrom scipy.io import loadmat, savemat\nimport timeit\nimport os\nimport numpy as np\n\nDEBUG = True\n\n\ndef readMat(mat_file):\n    data = loadmat(mat_file)\n    for key in data.keys():\n        if key == \'Img\':\n            return data\n        if not key.startswith(\'__\'):\n            return data[key]\n\n    print(\'no data!\')\n    return 0\n\n\ndef writeMat(data, save_path=\'result.mat\'):\n    start = timeit.default_timer()\n\n    if os.path.exists(save_path):\n        os.remove(save_path)\n\n    print(\'Start saving\')\n    savemat(save_path, data)\n\n    print(\'OK\')\n    end = timeit.default_timer()\n    print(\'Use time {0:.2f}s\'.format(end - start))\n\n\ndef task(test, images):\n    test_images_name = []\n    test_images_count = 0\n    for i in test:\n        test_images_name.append(i[0][0])\n        test_images_count += 1\n\n    print(\'found {0} test images!\'.format(test_images_count))\n\n    processed_count = 0\n    test_index = []\n    all_size = []\n\n    for i in images[\'Img\'][0]:\n        processed_count += 1\n        if i[0][0] in test_images_name:\n            test_index.append(processed_count - 1)\n\n            boxes_count = 0\n            size = []\n            deleted_count = 0\n\n            for box in i[2][0]:\n                # print(box)\n                box_size = int(box[0][0][2]) * int(box[0][0][3])\n                size.append(box_size)\n                all_size.append(box_size)\n\n                if box_size > 10000:\n                    # print(test_index[-1], \'.\', boxes_count - deleted_count, \'.\', boxes_count, \'.\', deleted_count)\n                    np.delete(images[\'Img\'][0][test_index[-1]][2][0], boxes_count - deleted_count, axis=0)\n                    deleted_count += 1\n\n                boxes_count += 1\n\n    print(\'Processed {0} test images! {1} boxes\'.format(processed_count, len(all_size)))\n    return images\n\n\ndef cal_ratio(test, images):\n    test_images_name = []\n    test_images_count = 0\n    for i in test:\n        test_images_name.append(i[0][0])\n        test_images_count += 1\n\n    print(\'found {0} test images!\'.format(test_images_count))\n\n    w = []\n    h = []\n    size = []\n    count = 0\n    for i in images[\'Img\'][0]:\n        if i[0][0] in test_images_name:\n            count += 1\n            for box in i[2][0]:\n                w.append(int(box[0][0][2]))\n                h.append(int(box[0][0][3]))\n                size.append(int(box[0][0][2]) * int(box[0][0][3]))\n\n            if count % 1000 == 0:\n                print(""proceeded {0} images."".format(count))\n\n    return sum(w) / sum(h), size\n\n\ndef le(size, threshold):\n    size = np.array(size)\n    return sum(size < threshold)\n\n\nif __name__ == \'__main__\':\n    test_path = ""pool.mat""\n    image_path = ""Images.mat""\n    test = readMat(test_path)\n    images = readMat(image_path)\n    _, size = cal_ratio(test, images)\n    while 1:\n        x = int(input(\'x = \'))\n        p2 = le(size, x * x)\n        p3 = le(size, x * x * 4) - p2\n        p4 = le(size, x * x * 16) - p2 - p3\n        p5 = le(size, x * x * 64) - p2 - p3 - p4\n        print((p2 - 0.0) / (p2 + p3 + p4 + p5))\n        print((p3 - 0.0) / (p2 + p3 + p4 + p5))\n        print((p4 - 0.0) / (p2 + p3 + p4 + p5))\n        print((p5 - 0.0) / (p2 + p3 + p4 + p5))\n'"
src/optical_flow/main.py,1,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/10/17\n""""""\n\nimport cv2\nimport numpy as np\nimport copy\nINF = 255\n\n\ndef is_empty(x, y, u):\n    if u[x][y][0] == INF and u[x][y][1] == INF:\n        return True\n\n    return False\n\n\ndef image_add(It, x, y, I0, x0, y0, I1, x1, y1):\n    for i in range(3):\n        It[x][y][i] = I0[x0][y0][i] / 2 + I1[x1][y1][i] / 2\n\n    return It\n\n\ndef position_is_legal(x, y, height, width):\n    if height > x >= 0 and width > y >= 0:\n        return True\n\n    return False\n\n\n# Compute optical flow in time t(=0.5)\ndef compute_flow(u0):\n    ut = copy.deepcopy(u0)\n    height = u0.shape[0]\n    width = u0.shape[1]\n\n    for x in range(height):\n        for y in range(width):\n            ut[x][y][0] = INF\n            ut[x][y][1] = INF\n\n    for x in range(height):\n        for y in range(width):\n            x_new = int(round(x + u0[x][y][0]))\n            y_new = int(round(y + u0[x][y][1]))\n            if position_is_legal(x_new, y_new, height, width):\n                ut[x_new][y_new] = u0[x][y]\n\n    x_splats = [-1, 0, 1]\n    y_splats = [-1, 0, 1]\n    count, x_sum, y_sum = 0, 0, 0\n    for x in range(height):\n        for y in range(width):\n            if is_empty(x, y, ut):\n                for x_splat in x_splats:\n                    for y_splat in y_splats:\n                        x_new = int(round(x + x_splat))\n                        y_new = int(round(y + y_splat))\n                        if position_is_legal(x_new, y_new, height, width):\n                            if not is_empty(x_new, y_new, ut):\n                                x_sum += ut[x_new][y_new][0]\n                                y_sum += ut[x_new][y_new][1]\n                                count = count + 1\n\n                if count == 0:\n                    ut[x][y][0], ut[x][y][1] = 0, 0\n                else:\n                    ut[x][y][0], ut[x][y][1] = x_sum / count, y_sum / count\n\n    return ut\n\n\n# Splat optical flow to keep photo consistency\ndef splat_flow(u, I0, I1):\n    height = u0.shape[0]\n    width = u0.shape[1]\n    x_splats = [-1, 0, 1]\n    y_splats = [-1, 0, 1]\n\n    for x in range(height):\n        for y in range(width):\n            min_dis = INF\n            best_u = copy.deepcopy(u[x][y])\n\n            for x_splat in x_splats:\n                for y_splat in y_splats:\n                    if position_is_legal(x + x_splat, y + y_splat, height, width):\n                        temp = u[x+x_splat][y+y_splat]\n                        x_new = int(round(x + temp[0] / 2))\n                        y_new = int(round(y + temp[1] / 2))\n                        if position_is_legal(x_new, y_new, height, width):\n                            if abs(I0[x][y] - I1[x_new][y_new]) < min_dis:\n                                best_u = temp\n\n            u[x][y] = best_u\n\n    return u\n\n\n# Compute the colors of the interpolated pixels\ndef interpolate(I0, I1, ut):\n    height = u0.shape[0]\n    width = u0.shape[1]\n    It = copy.deepcopy(I0)\n\n    for x in range(height):\n        for y in range(width):\n            It[x][y] = 0\n\n    for x in range(height):\n        for y in range(width):\n            x0 = int(round(x - ut[x][y][0] / 2))\n            y0 = int(round(y - ut[x][y][1] / 2))\n            x1 = int(round(x + ut[x][y][0] / 2))\n            y1 = int(round(y + ut[x][y][1] / 2))\n            if position_is_legal(x0, y0, height, width):\n                if position_is_legal(x1, y1, height, width):\n                    It = image_add(It, x, y, I0, x0, y0, I1, x1, y1)\n                else:\n                    It = image_add(It, x, y, I0, x0, y0, I0, x0, y0)\n            else:\n                if position_is_legal(x1, y1, height, width):\n                    It = image_add(It, x, y, I1, x1, y1, I1, x1, y1)\n\n    return It\n\n\nif __name__ == \'__main__\':\n    file_index = np.linspace(399, 541, 72)\n    for index in file_index:\n        file1 = int(index)\n        file2 = int(index + 2)\n        file_out = int(index + 1)\n        print(\'interpolate frame {0}\'.format(file_out))\n        if file2 > file_index[-1]:\n            break\n\n        str_first = \'./images/\' + str(file1) + \'.jpg\'\n        str_second = \'./images/\' + str(file2) + \'.jpg\'\n        str_out = str(file_out) + \'.jpg\'\n\n        frame1 = cv2.imread(str_first)\n        frame2 = cv2.imread(str_second)\n        prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n        next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n\n        u0 = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n        u0 = splat_flow(u0, prvs, next)\n        ut = compute_flow(u0)\n        It = interpolate(frame1, frame2, ut)\n        cv2.imwrite(str_out, It)\n'"
src/plot_caffe_log_file/main.py,0,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/10/17\n""""""\n\n# usage: python line_chart.py path/to/log\n\n\nimport os\nimport sys\nimport matplotlib\nmatplotlib.use(\'Agg\')\nimport matplotlib.pyplot as plt\n\nsys.path.append(\'..\')\n\nfrom usage_of_matplotlib.main import plot_xyy\n\n\ndef parse_log(filepath):\n    print(""locate in %s""%filepath)\n    log = open(filepath)\n\n    x = []\n    y = []\n\n    lines = log.readlines()\n    last_epoch = 120\n    y1, y2, y3 = [], [], []\n    loss_tri, loss_xent, misclassify = [], [], []\n\n    for line in lines:\n        if line.find(\'loss_tri\') != -1:\n            start = line.find(\'e:\') + 2\n            end = start+3\n            epoch = int(line[start:end])\n            if epoch != last_epoch:\n                # print(epoch)\n                last_epoch = epoch\n                y1.append(sum(loss_tri) / len(loss_tri))\n                y2.append(sum(loss_xent) / len(loss_xent))\n                y3.append(sum(misclassify) / len(misclassify))\n                loss_tri, loss_xent, misclassify = [], [], []\n            # print(epoch)\n\n            start = line.find(\'loss_tri\') + 9\n            end = line.find(\'loss_weight_decay\') - 1\n            loss_tri.append(float(line[start:end]))\n            # print(loss_tri)\n\n            start = line.find(\'loss_xent\') + 10\n            end = line.find(\'misclassify\') - 1\n            loss_xent.append(float(line[start:end]))\n            # print(loss_xent)\n\n            start = line.find(\'misclassify\') + 12\n            misclassify.append(float(line[start:]))\n            # print(misclassify)\n\n    y1.append(sum(loss_tri) / len(loss_tri))\n    y2.append(sum(loss_xent) / len(loss_xent))\n    y3.append(sum(misclassify) / len(misclassify))\n\n    return y1, y2, y3\n\n\ndef plot_log(x, y, output_dir):\n    plt.plot(x, y)\n    plt.title(\'loss curve\')\n    plt.xlabel(\'Iteration\')\n    plt.ylabel(\'loss\')\n\n    # plt.show()\n    save_path = os.path.join(output_dir, ""loss_curve.jpg"")\n    plt.savefig(save_path)\n    print(""save as %s""%save_path)\n\n\nif __name__ == \'__main__\':\n        path_to_logs = [\'worklog.txt\', \'fine.txt\']\n        baseline_tri, baseline_xent, baseline_mis = parse_log(path_to_logs[0])\n        fine_tri, fine_xent, fine_mis = parse_log(path_to_logs[1])\n        x = [i for i in range(120, 301)]\n        plot_xyy(x, baseline_tri, fine_tri, labely=\'triplet_loss\', output_name=\'tri.eps\')\n        plot_xyy(x, baseline_xent, fine_xent, labely=\'xent_loss\', output_name=\'xent.eps\')\n        plot_xyy(x, baseline_mis, fine_mis, labely=\'misclassify\', output_name=\'misclassify.eps\')\n'"
src/plot_dirtribution/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/10/17\n""""""'"
src/plot_dirtribution/main.py,2,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/10/17\n""""""\n\nfrom __future__ import print_function, absolute_import\nimport os\nimport argparse\nimport sys\nsys.path.append(\'..\')\n\n\nfrom quick_restore.main import readPickle\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\'Agg\')\nimport matplotlib.pyplot as plt\n\n\nparser = argparse.ArgumentParser(description=\'Plot data distribution with line chart.\')\nparser.add_argument(\'--data\', type=str, default=\'data.pkl\', help=""path to data (.pkl)"")\nparser.add_argument(\'-i\', \'--interval\', type=int, default=1, help=""The extend of each data point (default: 1%)"")\nparser.add_argument(\'-f\', \'--format\', type=str, default=\'eps\', help=\'file format (eps, jpg, png)\', choices=[\'eps\', \'jpg\', \'png\'])\nparser.add_argument(\'-o\', \'--output\', type=str, default=\'output\', help=\'output floder\')\n\nargs = parser.parse_args()\n\n\ndef plotDistribution(data, save_path):\n    maximum = data.max()\n    minimum = data.min()\n    range = maximum - minimum\n\n    counter = np.zeros((100 % args.interval))\n\n    for item in data:\n        index = int((item - minimum) / (range * args.interval / 100))\n        counter[index] += 1\n\n    x = np.linspace(0, 100 % args.interval, 100 % args.interval, endpoint=False)\n    plt.plot(x, counter, linewidth=\'2\')\n    plt.savefig(save_path, dpi=300)\n\n\ndef main():\n    if not os.path.exists(args.data):\n        raise Exception(""No such file: {}"".format(args.data))\n\n    print(\'Load pkl file...\')\n    all_data = readPickle(args.data)\n\n    if 100 >= args.interval > 0 and 100 % args.interval == 0:\n        if len(all_data) == 1:\n            plotDistribution(all_data, os.path.join(args.output, \'result.{}\'.format(args.format)))\n        else:\n            for i, data in enumerate(all_data):\n                plotDistribution(data, os.path.join(args.output, \'result{}.{}\'.format(i, args.format)))\n    else:\n        raise Exception(\'Interval is invalid!\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
src/quick_restore/__init__.py,0,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/10/17\n""""""'"
src/quick_restore/main.py,0,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/11/03\n""""""\n\nimport pickle\nimport torch\nimport sys\n\n\ndef readPickle(input, from_python_type=\'3\'):\n    now_ver = sys.version[0]\n\n    if from_python_type == now_ver:\n        with open(input, \'rb\') as f:\n            return pickle.loads(f.read())\n\n    if from_python_type == \'2\' and now_ver == \'3\':\n        with open(input, \'rb\') as f:\n            return pickle.load(f, encoding=\'latin1\')\n\n    if from_python_type == \'3\' and now_ver == \'2\':\n        raise Exception(\'You should save the pkl file by protocol=2 in Python3 firstly!\')\n\n\ndef writePickle(data, save_path, to_python_type=\'3\'):\n    now_ver = sys.version[0]\n\n    if now_ver == 2 or to_python_type == now_ver:\n        with open(save_path, \'wb\') as f:\n            f.write(pickle.dumps(data))\n\n    if to_python_type == \'2\' and now_ver == \'3\':\n        with open(save_path, \'wb\') as f:\n            f.write(pickle.dumps(data, protocol=2))\n\n\ndef main():\n    a_dict = {1: {1: 2, 3: 4}, 2: {3: 4, 4: 5}}\n    a_list = [a_dict, a_dict, 0]\n    a_tensor = torch.Tensor([1, 2, 3])\n\n    # save\n    save_path = [\'dict.pkl\', \'list.pkl\', \'tensor.pkl\']\n    writePickle(a_dict, save_path[0])\n    writePickle(a_list, save_path[1])\n    writePickle(a_tensor, save_path[2])\n\n    # read\n    print(readPickle(save_path[0]))\n    print(readPickle(save_path[1]))\n    print(readPickle(save_path[2]))\n'"
src/usage_of_matplotlib/function_curve.py,3,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2020/03/19\n@last modified: 2020/03/19\n""""""\n\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\'Agg\')\nimport matplotlib.pyplot as plt\nmatplotlib.rcParams[\'font.family\'] = \'Times New Roman\'\n\n\ndef InitPlot():\n    plt.clf()\n    plt.figure(figsize=(5, 3))\n\n\ndef PlotFunction(x, y, label=\'func\'):\n    plt.plot(x, y, label=label, linewidth=\'2\')\n\n\ndef SaveFigure(labelx=\'probability of ground truth class\', labely=\'weight\', output_name=None):\n    plt.xlabel(labelx, fontsize=16)\n    plt.ylabel(labely, fontsize=16)\n\n    plt.legend(loc=\'upper right\', fontsize=16)\n    plt.tick_params(labelsize=16)\n    plt.grid()\n    plt.tight_layout()\n\n    if output_name == None:\n        filename = \'loss.eps\'\n    else:\n        filename = output_name\n\n    plt.savefig(filename, dpi=300)\n\n\nif __name__ == \'__main__\':\n    InitPlot()\n    x = np.linspace(0.0001, 1, 1000)\n    y = - 0.25 * (1 - x) ** 2 * np.log(x)\n    PlotFunction(x, y, \'focal loss\')\n\n    T = 0.3\n    y = np.exp((1-x)/T) / 12\n    PlotFunction(x, y, \'hardness\')\n\n    SaveFigure()\n'"
src/usage_of_matplotlib/line_chart.py,1,"b'# encoding: utf-8\n""""""\n@author: Cheng Wang\n@date: 2019/10/17\n@last modified: 2019/10/17\n""""""\n\nimport os\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\'Agg\')\nimport matplotlib.pyplot as plt\nfrom openpyxl import load_workbook\nmatplotlib.rcParams[\'font.family\'] = \'Times New Roman\'\n\n\ndef plot_xyy(x, y1, y2, labelx=\'Epoch\', labely=\'Loss\', output_name=None):\n    plt.figure(figsize=(6, 3))\n\n    plt.plot(x, y1, label=\'baseline\', linewidth=\'2\')\n    plt.plot(x, y2, label=\'hard-fine\', linewidth=\'2\')\n    if output_name == None:\n        filename = \'loss.eps\'\n    else:\n        filename = output_name\n\n    plt.xlabel(labelx, fontsize=16)\n    plt.ylabel(labely, fontsize=16)\n    plt.legend(loc=\'upper right\', fontsize=16)\n    plt.tick_params(labelsize=16)\n    # plt.xlim((0, 9))\n    plt.grid()\n    plt.tight_layout()\n    plt.savefig(filename, dpi=300)\n\n\ndef plot_xy(x, y_list, output_dir=None):\n    plt.figure(figsize=(7, 5))\n    labels = [\'TCTS\', \'Reid_driven\', \'OIM\', \'NPSM\', \'MGTS\']\n    shapes = [\'rv-\', \'*-\', \'x-\', \'d-\', \'bo-\']\n    for y, shape, this_label in zip(y_list, shapes, labels):\n        plt.plot(x, y, shape, label=this_label, linewidth=\'2\')\n\n    if output_dir == None:\n        filename = \'gallery_size.eps\'\n    else:\n        filename = os.path.join(output_dir, \'gallery_size.eps\')\n\n    plt.xlabel(\'Gallery Size\', fontsize=17)\n    plt.ylabel(\'mAP(%)\', fontsize=17)\n    plt.legend(loc=\'best\', fontsize=17, framealpha=0.5)\n    plt.tick_params(labelsize=17)\n    plt.ylim((30, 100))\n    plt.grid()\n    plt.tight_layout()\n    plt.savefig(filename, dpi=300)\n\n\ndef plot_9(x, y_list, output_dir=None):\n    plt.figure(figsize=(7, 3))\n    labels = [\'Resnet50\', \'Resnet50-FLGC\', \'Resnet50-SGC\']\n    shapes = [\'o-\', \'*-\', \'x-\']\n    for y, shape, this_label in zip(y_list, shapes, labels):\n        plt.plot(x, y, shape, label=this_label, linewidth=\'2\')\n\n    if output_dir == None:\n        filename = \'9.eps\'\n    else:\n        filename = os.path.join(output_dir, \'9.eps\')\n\n    plt.xlabel(\'Group Number\', fontsize=17)\n    plt.ylabel(\'Accuracy(%)\', fontsize=17)\n    plt.legend(loc=\'lower left\', fontsize=17)\n    plt.tick_params(labelsize=17)\n    plt.grid()\n    plt.tight_layout()\n    plt.savefig(filename, dpi=300)\n\n\ndef plot_decision(x, y_list, output_dir=None):\n    plt.figure(figsize=(7, 3))\n    labels = [\'$2x_2=x_1$\', \'$2x_2=1-x_1$\']\n    for y, this_label in zip(y_list, labels):\n        plt.plot(x, y, label=this_label, linewidth=\'2\')\n\n    plt.plot([0.5, 0.5], [-0.5, 1], label=\'$x_1=1/2$\', linewidth=\'2\')\n\n    if output_dir == None:\n        filename = \'decision.eps\'\n    else:\n        filename = os.path.join(output_dir, \'decision.eps\')\n\n    plt.legend(loc=\'upper right\', fontsize=15)\n    plt.tick_params(labelsize=17)\n    plt.xlim((-1, 4))\n    plt.grid()\n    plt.tight_layout()\n    plt.savefig(filename, dpi=300)\n\n\ndef input_data():\n    wb = load_workbook(\'500.xlsx\')\n    print(wb.get_sheet_names())\n    sheet = wb.active\n\n    x, y1, y2 = [], [], []\n    var_list = [\'x\', \'y1\', \'y2\']\n    i = 0\n\n    for column in sheet.columns:\n        for cell in column:\n            eval(var_list[i]).append(cell.value)\n        i = i + 1\n\n    return x, y1, y2\n\n\ndef input_data2():\n    x = [\'50\', \'100\', \'500\', \'1000\', \'2000\', \'4000\']\n    y1 = [94.5, 93.9, 90.8, 89.3, 86.7, 84.3]\n    y2 = [94.0, 93.2, 89.7, 87.7, 85.1, 82.9]\n    y3 = [79.4, 75.5, 65.7, 60.8, 56.5, 51.3]\n    y4 = [81.6, 77.9, 68, 63.6, 58.3, 53.5]\n    y5 = [84.8, 83, 76.9, 73.9, 70.2, 66.3]\n\n    return x, [y1, y2, y3, y4, y5]\n\n\ndef input_data3():\n    x = [2, 4, 8]\n    y1 = [98.82, 98.82, 98.82]\n    y2 = [98.82, 98.82, 98.73]\n    y3 = [98.81, 98.78, 98.3]\n\n    return x, [y1, y2, y3]\n\n\ndef input_data4():\n    x = np.arange(-1, 2.5, 0.5)\n    y1 = x/2\n    y2 = (1-x)/2\n\n    return x, [y1, y2]\n\n\nif __name__ == \'__main__\':\n    # x, y1, y2 = input_data()\n    # plot_xyy(x, y1, y2)\n\n    m, n = input_data2()\n    plot_xy(m, n)\n\n    # x, y = input_data3()\n    # plot_9(x, y)\n\n    # plot_decision_boundary\n    # x, y = input_data4()\n    # plot_decision(x, y)\n'"
src/image_similarity/pic/real/test.py,0,"b""from PIL import Image\n\n\nimg = Image.open('00001.jpg')\nprint(img)\nimg.close()\n"""
