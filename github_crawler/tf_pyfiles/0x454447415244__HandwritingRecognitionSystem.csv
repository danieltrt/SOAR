file_path,api_count,code
cnn.py,11,"b""###\n# Copyright 2018 Edgard Chammas. All Rights Reserved.\n# Licensed under the Creative Commons Attribution-NonCommercial International Public License, Version 4.0.\n# You may obtain a copy of the License at https://creativecommons.org/licenses/by-nc/4.0/legalcode\n###\n\n#!/usr/bin/python\n\nimport tensorflow as tf\nimport math\n\nfrom config import cfg\nfrom util import batch_norm_conv\nfrom util import weight_variable\nfrom util import conv2d\nfrom util import max_pool\n\n####################################################################\n#CNN-specific architecture configuration\n####################################################################\nWND_HEIGHT = 64 \t\t#Extraction window height\nWND_WIDTH = 64\t\t\t#Extraction window width\nWND_SHIFT = WND_WIDTH - 2\t#Window shift\n\nMPoolLayers_ALL = 5\t#Nbr of all maxpool layers\nMPoolLayers_H = 2\t#Nbr of maxpool in horizontal dimension\nLastFilters = 512\t#Nbr of feature maps at the last conv layer\n####################################################################\n\nFV = int(WND_HEIGHT / math.pow(2, MPoolLayers_ALL))\n\nNFeatures = FV * LastFilters\n\ndef CNNLight(X, Training, Scope):\n\n\twith tf.variable_scope(Scope):\n\n\t\tConvLayer1 = ConvLayer(X, 1, 64, Training, 'ConvLayer1')\n\n\t\tMPool1 = max_pool(ConvLayer1, ksize=(2, 2), stride=(2, 2))\n\n\t\tConvLayer2 = ConvLayer(MPool1, 64, 128, Training, 'ConvLayer2')\n\n\t\tMPool2 = max_pool(ConvLayer2, ksize=(2, 2), stride=(2, 2))\n\n\t\tConvLayer3 = ConvLayer(MPool2, 128, 256, Training, 'ConvLayer3')\n\n\t\tConvLayer4 = ConvLayer(ConvLayer3, 256, 256, Training, 'ConvLayer4')\n\n\t\tMPool4 = max_pool(ConvLayer4, ksize=(2, 1), stride=(2, 1))\n\n\t\tConvLayer5 = ConvLayer(MPool4, 256, 512, Training, 'ConvLayer5')\n\n\t\tConvLayer6 = ConvLayer(ConvLayer5, 512, 512, Training, 'ConvLayer6')\n\n\t\tMPool6 = max_pool(ConvLayer6, ksize=(2, 1), stride=(2, 1))\n\n\t\tConvLayer7 = ConvLayer(MPool6, 512, 512, Training, 'ConvLayer7')\n\n\t\tMPool7 = max_pool(ConvLayer7, ksize=(2, 1), stride=(2, 1))\n\n\t\tMPool7_T = tf.transpose(MPool7, perm=[0,2,1,3])\n\n\t\tMPool7_T_RSH = tf.reshape(MPool7_T, [-1, FV, LastFilters])\n\n\t\treturn tf.reshape(MPool7_T_RSH, [-1, NFeatures])\n\n\ndef CNN(X, Training, Scope):\n\n\twith tf.variable_scope(Scope):\n\n\t\tConvLayer1 = ConvLayer(X, 1, 64, Training, 'ConvLayer1')\n\n\t\tConvLayer2 = ConvLayer(ConvLayer1, 64, 64, Training, 'ConvLayer2')\n\n\t\tMPool2 = max_pool(ConvLayer2, ksize=(2, 2), stride=(2, 2))\n\n\t\tConvLayer3 = ConvLayer(MPool2, 64, 128, Training, 'ConvLayer3')\n\n\t\tConvLayer4 = ConvLayer(ConvLayer3, 128, 128, Training, 'ConvLayer4')\n\n\t\tMPool4 = max_pool(ConvLayer4, ksize=(2, 2), stride=(2, 2))\n\n\t\tConvLayer5 = ConvLayer(MPool4, 128, 256, Training, 'ConvLayer5')\n\n\t\tConvLayer6 = ConvLayer(ConvLayer5, 256, 256, Training, 'ConvLayer6')\n\n\t\tConvLayer7 = ConvLayer(ConvLayer6, 256, 256, Training, 'ConvLayer7')\n\n\t\tMPool7 = max_pool(ConvLayer7, ksize=(2, 1), stride=(2, 1))\n\n\t\tConvLayer8 = ConvLayer(MPool7, 256, 512, Training, 'ConvLayer8')\n\n\t\tConvLayer9 = ConvLayer(ConvLayer8, 512, 512, Training, 'ConvLayer9')\n\n\t\tConvLayer10 = ConvLayer(ConvLayer9, 512, 512, Training, 'ConvLayer10')\n\n\t\tMPool10 = max_pool(ConvLayer10, ksize=(2, 1), stride=(2, 1))\n\n\t\tConvLayer11 = ConvLayer(MPool10, 512, 512, Training, 'ConvLayer11')\n\n\t\tConvLayer12 = ConvLayer(ConvLayer11, 512, 512, Training, 'ConvLayer12')\n\n\t\tConvLayer13 = ConvLayer(ConvLayer12, 512, LastFilters, Training, 'ConvLayer13')\n\n\t\tMPool13 = max_pool(ConvLayer13, ksize=(2, 1), stride=(2, 1))\n\n\t\tMPool13_T = tf.transpose(MPool13, perm=[0,2,1,3])\n\n\t\tMPool13_T_RSH = tf.reshape(MPool13_T, [-1, FV, LastFilters])\n\n\t\treturn tf.reshape(MPool13_T_RSH, [-1, NFeatures])\n\ndef ConvLayer(Input, FilterIn, FilterOut, Training, Scope):\n\n\twith tf.variable_scope(Scope):\n\n\t\tWeight = weight_variable([3, 3, FilterIn, FilterOut])\n\n\t\tif cfg.LeakyReLU == True:\n\n\t\t\treturn tf.nn.leaky_relu(batch_norm_conv(conv2d(Input, Weight), FilterOut, Training))\n\t\telse:\n\t\t\treturn tf.nn.relu(batch_norm_conv(conv2d(Input, Weight), FilterOut, Training))\n\n"""
compute_probs.py,8,"b'###\n# Copyright 2018 Edgard Chammas. All Rights Reserved.\n# Licensed under the Creative Commons Attribution-NonCommercial International Public License, Version 4.0.\n# You may obtain a copy of the License at https://creativecommons.org/licenses/by-nc/4.0/legalcode\n###\n\n#!/usr/bin/python\n\nimport tensorflow as tf\nimport sys\nimport os\nimport cv2\nimport numpy as np\nimport codecs\nimport math\n\nfrom config import cfg\nfrom util import LoadClasses\nfrom util import LoadModel\nfrom util import ReadData\nfrom util import LoadList\nfrom cnn import CNN\nfrom cnn import WND_HEIGHT\nfrom cnn import WND_WIDTH\nfrom cnn import MPoolLayers_H\nfrom rnn import RNN\n\nif (os.path.exists(cfg.Probs) == False): os.makedirs(cfg.Probs)\n\nClasses = LoadClasses(cfg.CHAR_LIST)\n\nNClasses = len(Classes)\n\nFilesList = LoadList(cfg.TEST_LIST)\n\nWND_SHIFT = WND_WIDTH - 2\n\nVEC_PER_WND = WND_WIDTH / math.pow(2, MPoolLayers_H)\n\nphase_train = tf.Variable(True, name=\'phase_train\')\n\nx = tf.placeholder(tf.float32, shape=[None, WND_HEIGHT, WND_WIDTH])\n\nSeqLens = tf.placeholder(shape=[cfg.BatchSize], dtype=tf.int32)\n\nx_expanded = tf.expand_dims(x, 3)\n\nInputs = CNN(x_expanded, phase_train, \'CNN_1\')\n\nlogits = RNN(Inputs, SeqLens, \'RNN_1\')\n\nlogits = tf.nn.softmax(logits, dim=-1, name=None)\n\n#Reading test data...\nInputListTest, SeqLensTest, _ = ReadData(cfg.TEST_LOCATION, cfg.TEST_LIST, cfg.TEST_NB, WND_HEIGHT, WND_WIDTH, WND_SHIFT, VEC_PER_WND, \'\')\n\nprint(\'Initializing...\')\n\nsession = tf.Session()\n\nsession.run(tf.global_variables_initializer())\n\nLoadModel(session, cfg.SaveDir+\'/\')\n\ntry:\n\tsession.run(tf.assign(phase_train, False))\n\n\trandIxs = range(0, len(InputListTest))\n\n\tstart, end = (0, cfg.BatchSize)\n\n\tbatch = 0\n\twhile end <= len(InputListTest):\n\t\tbatchInputs = []\n\t\tbatchSeqLengths = []\n\t\tfor batchI, origI in enumerate(randIxs[start:end]):\n\t\t\tbatchInputs.extend(InputListTest[origI])\n\t\t\tbatchSeqLengths.append(SeqLensTest[origI])\n\n\t\tfeed = {x: batchInputs, SeqLens: batchSeqLengths}\n\t\tdel batchInputs, batchSeqLengths\n\n\t\tLogits = session.run([logits], feed_dict=feed)\n\t\tdel feed\n\n\t\t_,sLen,_,_ = np.shape(Logits)\n\n\t\tfor i in range(0, cfg.BatchSize):\n\n\t\t\tfileIndex = cfg.BatchSize * batch + i\n\t\t\tfilename = ""./""+cfg.Probs+""/"" + os.path.basename(FilesList[fileIndex].strip()) + "".txt""\n\n\t\t\tfile = codecs.open(filename, ""a"", ""utf-8"")\n\n\t\t\tfor seqn in range(0, sLen):\n\n\t\t\t\tseq = Logits[0][seqn][i]\n\n\t\t\t\tfile.write(str(seq[NClasses-1]))\n\t\t\t\tfile.write("" "")\n\n\t\t\t\tfor c in range(0, NClasses-1):\n\t\t\t\t\tval = seq[c]\n\t\t\t\t\tfile.write(str(val))\n\t\t\t\t\tfile.write("" "")\n\n\t\t\t\tfile.write(""\\n"")\n\n\t\t\tfile.close\n\n\t\tstart += cfg.BatchSize\n\t\tend += cfg.BatchSize\n\t\tbatch += 1\n\nexcept (KeyboardInterrupt, SystemExit, Exception) as e:\n\tprint(""[Error/Interruption] %s"" % str(e))\n\tprint(""Clossing TF Session..."")\n\tsession.close()\n\tprint(""Terminating Program..."")\n\tsys.exit(0)\n\n\n'"
config.py,1,"b""###\n# Copyright 2018 Edgard Chammas. All Rights Reserved.\n# Licensed under the Creative Commons Attribution-NonCommercial International Public License, Version 4.0.\n# You may obtain a copy of the License at https://creativecommons.org/licenses/by-nc/4.0/legalcode\n###\n\n#!/usr/bin/python\n\nimport tensorflow as tf\nimport os\n\nflags = tf.app.flags\n\n######################################\n#Images and labels file type\nflags.DEFINE_string('ImageFileType', '.png', 'The file type of images')\nflags.DEFINE_string('LabelFileType', '.tru', 'The extension of the file holding the ground-truth labels')\n\n######################################\n#Training data configuration\nflags.DEFINE_integer('TRAIN_NB', 20, 'Number of training images to process')\nflags.DEFINE_string('TRAIN_LIST', './samples/list', 'List of training data without file extension.')\nflags.DEFINE_string('TRAIN_LOCATION', './samples/Images/', 'Location of training data. Could be included in the data list.')\nflags.DEFINE_string('TRAIN_TRANS', './samples/Labels/', 'Location of training data transcriptions')\n\n######################################\n#Validation data configuration\nflags.DEFINE_integer('VAL_NB', 20, 'Number of validation images to process')\nflags.DEFINE_string('VAL_LIST', './samples/list',\t'List of validation data without file extension.')\nflags.DEFINE_string('VAL_LOCATION', './samples/Images/', 'Location of validation data. Could be included in the data list.')\nflags.DEFINE_string('VAL_TRANS', './samples/Labels/', 'Location of validation data transcriptions')\n\n######################################\n#Test data configuration\nflags.DEFINE_integer('TEST_NB', 20, 'Number of test images to process')\nflags.DEFINE_string('TEST_LIST', './samples/list', 'List of test data without file extension.')\nflags.DEFINE_string('TEST_LOCATION', './samples/Images/', 'Location of test data. Could be included in the data list.')\nflags.DEFINE_boolean('WriteDecodedToFile', True, 'Write the decoded text to file or stdout?')\n\n######################################\n#Classes information\nflags.DEFINE_string('CHAR_LIST', './samples/CHAR_LIST', 'Sorted list of classes/characters. First one must be <SPACE>')\n\n######################################\n#Model and logs files and directories\nflags.DEFINE_string('SaveDir', './model', 'Directory where model checkpoints are saved')\nflags.DEFINE_string('ModelName', 'model.ckpt', 'Name of the model checkpoints')\nflags.DEFINE_string('LogFile', './log', 'Log file')\nflags.DEFINE_string('LogDir', './summary', 'Directory to store Tensorflow summary information')\nflags.DEFINE_string('Probs', './Probs', 'Directory to store posteriors for WFST decoder')\n\n######################################\n#CNN parameters\nflags.DEFINE_boolean('LeakyReLU', True, 'Use Leaky ReLU or ReLU')\n\n######################################\n#RNN parameters\nflags.DEFINE_integer('NUnits', 256, 'Number of LSTM units per forward/backward layer')\nflags.DEFINE_integer('NLayers', 3, 'Number of BLSTM layers')\n\n######################################\n#Training parameters\nflags.DEFINE_integer('StartingEpoch', 0, 'The epoch number to start training from') # = 0 to train from scratch, != 0 to resume from the latest checkpoint\nflags.DEFINE_float('LearningRate', 0.0005, 'Learning rate')\nflags.DEFINE_integer('BatchSize', 10, 'Batch size') #This is actually the number of images to process each iteration\nflags.DEFINE_boolean('RandomBatches', True, 'Randomize the order of batches each epoch')\nflags.DEFINE_integer('MaxGradientNorm', 5, 'Maximum gradient norm')\nflags.DEFINE_integer('SaveEachNEpochs', 1, 'Save model each n epochs')\nflags.DEFINE_integer('NEpochs', 1000000, 'Run the training for n epochs')\nflags.DEFINE_integer('TrainThreshold', 20, 'Stop the training after n epochs with no improvement on validation')\n\ncfg = flags.FLAGS\n\nif (os.path.exists(cfg.SaveDir) == False): os.makedirs(cfg.SaveDir)\nif (os.path.exists(cfg.LogDir) == False): os.makedirs(cfg.LogDir)\n\n"""
rnn.py,38,"b'###\n# Copyright 2018 Edgard Chammas. All Rights Reserved.\n# Licensed under the Creative Commons Attribution-NonCommercial International Public License, Version 4.0.\n# You may obtain a copy of the License at https://creativecommons.org/licenses/by-nc/4.0/legalcode\n###\n\n#!/usr/bin/python\n\nimport tensorflow as tf\nimport numpy as np\nimport math\n\nfrom config import cfg\nfrom util import LoadClasses\nfrom cnn import FV\nfrom cnn import NFeatures\n\nClasses = LoadClasses(cfg.CHAR_LIST)\n\nNClasses = len(Classes)\n\ndef RNN(Inputs, SeqLens, Scope):\n\n\twith tf.variable_scope(Scope):\n\n\t\t################################################################\n\t\t#Construct batch sequences for LSTM\n\n\t\tmaxLen = tf.reduce_max(SeqLens, 0)\n\n\t\tn = 0; offset = 0\n\t\tndxs = tf.reshape(tf.range(offset, SeqLens[n] + offset), [SeqLens[n], 1])\n\t\tres = tf.gather_nd(Inputs, [ndxs])\n\t\tres = tf.reshape(res, [-1])\n\t\tzero_padding = tf.zeros([NFeatures * maxLen] - tf.shape(res), dtype=res.dtype)\n\t\ta_padded = tf.concat([res, zero_padding], 0)\n\t\tresult = tf.reshape(a_padded, [maxLen, NFeatures])\n\t\tInputs2 = result\n\n\t\tfor n in range(1, cfg.BatchSize):\n\t\t\toffset = tf.cumsum(SeqLens)[n-1]\n\t\t\tndxs = tf.reshape(tf.range(offset, SeqLens[n]+offset), [SeqLens[n], 1])\n\t\t\tres = tf.gather_nd(Inputs, [ndxs])\n\t\t\tres = tf.reshape(res, [-1])\n\t\t\tzero_padding = tf.zeros([NFeatures * maxLen] - tf.shape(res), dtype=res.dtype)\n\t\t\ta_padded = tf.concat([res, zero_padding], 0)\n\t\t\tresult = tf.reshape(a_padded, [maxLen, NFeatures])\n\t\t\tInputs2 = tf.concat([Inputs2, result], 0)\n\n\t\tn = 0\n\t\tndxs = tf.reshape(tf.range(n, cfg.BatchSize * maxLen, maxLen), [cfg.BatchSize, 1])\n\t\tInputs = tf.gather_nd(Inputs2, [ndxs])\n\n\t\ti = tf.constant(1)\n\n\t\tdef condition(i, prev): return tf.less(i, maxLen)\n\n\t\tdef body(i, prev):\n\t\t\tndxs = tf.reshape(tf.range(i, cfg.BatchSize * maxLen, maxLen), [cfg.BatchSize, 1])\n\t\t\tresult = tf.gather_nd(Inputs2, [ndxs])\n\t\t\tnext = tf.concat([prev, result], 0)\n\t\t\treturn [tf.add(i, 1), next]\n\n\t\ti, Inputs = tf.while_loop(condition, body, [i, Inputs], shape_invariants=[i.get_shape(), tf.TensorShape([None, cfg.BatchSize, NFeatures])])\n\t\t\n\t\t###############################################################\n\t\t#Construct LSTM layers\n\n\t\tinitializer = tf.contrib.layers.xavier_initializer()\n\n\t\tstacked_rnn_forward = []\n\t\tfor i in range(cfg.NLayers):\n\t\t\tstacked_rnn_forward.append(tf.nn.rnn_cell.LSTMCell(num_units=cfg.NUnits, initializer=initializer, use_peepholes=True, state_is_tuple=True))\n\t\tforward = tf.nn.rnn_cell.MultiRNNCell(stacked_rnn_forward, state_is_tuple=True)\n\n\t\tstacked_rnn_backward = []\n\t\tfor i in range(cfg.NLayers):\n\t\t\tstacked_rnn_backward.append(tf.nn.rnn_cell.LSTMCell(num_units=cfg.NUnits, initializer=initializer, use_peepholes=True, state_is_tuple=True))\n\t\tbackward = tf.nn.rnn_cell.MultiRNNCell(stacked_rnn_backward, state_is_tuple=True)\n\n\t\t[fw_out, bw_out], _ = tf.nn.bidirectional_dynamic_rnn(cell_fw=forward, cell_bw=backward, inputs=Inputs, time_major=True, dtype=tf.float32,sequence_length=tf.cast(SeqLens, tf.int64))\n\n\t\t# Reshaping forward, and backward outputs for affine transformation\n\t\tfw_out = tf.reshape(fw_out,[-1, cfg.NUnits])\n\t\tbw_out = tf.reshape(bw_out,[-1, cfg.NUnits])\n\n\t\t# Linear Layer params\n\t\tW_fw = tf.Variable(tf.truncated_normal(shape=[cfg.NUnits, NClasses], stddev=np.sqrt(2.0 / cfg.NUnits), dtype=tf.float32), dtype=tf.float32)\n\t\tW_bw = tf.Variable(tf.truncated_normal(shape=[cfg.NUnits, NClasses], stddev=np.sqrt(2.0 / cfg.NUnits), dtype=tf.float32), dtype=tf.float32)\n\t\tb_out = tf.constant(0.1,shape=[NClasses], dtype=tf.float32)\n\n\t\t# Perform an affine transformation\n\t\tlogits =  tf.add( tf.add( tf.matmul(fw_out,W_fw), tf.matmul(bw_out,W_bw) ), b_out )\n\t\t\n\t\treturn tf.reshape(logits, [-1, cfg.BatchSize, NClasses])\n\n'"
test.py,9,"b'from __future__ import print_function\n###\n# Copyright 2018 Edgard Chammas. All Rights Reserved.\n# Licensed under the Creative Commons Attribution-NonCommercial International Public License, Version 4.0.\n# You may obtain a copy of the License at https://creativecommons.org/licenses/by-nc/4.0/legalcode\n###\n\n#!/usr/bin/python\n\nimport tensorflow as tf\nimport sys\nimport os\nimport cv2\nimport numpy as np\nimport codecs\nimport math\n\ntry:\n\treload(sys)  # Python 2\n\tsys.setdefaultencoding(\'utf8\')\nexcept NameError:\n\tpass         # Python 3\n\nfrom config import cfg\nfrom util import LoadClasses\nfrom util import LoadModel\nfrom util import ReadData\nfrom util import LoadList\nfrom cnn import CNN\nfrom cnn import WND_HEIGHT\nfrom cnn import WND_WIDTH\nfrom cnn import MPoolLayers_H\nfrom rnn import RNN\n\n\nif cfg.WriteDecodedToFile == True:\n\tDecodeLog = codecs.open(""decoded.txt"", ""w"", ""utf-8"")\n\nClasses = LoadClasses(cfg.CHAR_LIST)\n\nNClasses = len(Classes)\n\nFilesList = LoadList(cfg.TEST_LIST)\n\nWND_SHIFT = WND_WIDTH - 2\n\nVEC_PER_WND = WND_WIDTH / math.pow(2, MPoolLayers_H)\n\nphase_train = tf.Variable(True, name=\'phase_train\')\n\nx = tf.placeholder(tf.float32, shape=[None, WND_HEIGHT, WND_WIDTH])\n\nSeqLens = tf.placeholder(shape=[cfg.BatchSize], dtype=tf.int32)\n\nx_expanded = tf.expand_dims(x, 3)\n\nInputs = CNN(x_expanded, phase_train, \'CNN_1\')\n\nlogits = RNN(Inputs, SeqLens, \'RNN_1\')\n\n# CTC Beam Search Decoder to decode pred string from the prob map\ndecoded, log_prob = tf.nn.ctc_beam_search_decoder(logits, SeqLens)\n\n#Reading test data...\nInputListTest, SeqLensTest, _ = ReadData(cfg.TEST_LOCATION, cfg.TEST_LIST, cfg.TEST_NB, WND_HEIGHT, WND_WIDTH, WND_SHIFT, VEC_PER_WND, \'\')\n\nprint(\'Initializing...\')\n\nsession = tf.Session()\n\nsession.run(tf.global_variables_initializer())\n\nLoadModel(session, cfg.SaveDir+\'/\')\n\ntry:\n\tsession.run(tf.assign(phase_train, False))\n\n\trandIxs = range(0, len(InputListTest))\n\n\tstart, end = (0, cfg.BatchSize)\n\n\tbatch = 0\n\twhile end <= len(InputListTest):\n\t\tbatchInputs = []\n\t\tbatchSeqLengths = []\n\t\tfor batchI, origI in enumerate(randIxs[start:end]):\n\t\t\tbatchInputs.extend(InputListTest[origI])\n\t\t\tbatchSeqLengths.append(SeqLensTest[origI])\n\n\t\tfeed = {x: batchInputs, SeqLens: batchSeqLengths}\n\t\tdel batchInputs, batchSeqLengths\n\n\t\tDecoded = session.run([decoded], feed_dict=feed)[0]\n\t\tdel feed\n\n\t\ttrans = session.run(tf.sparse_tensor_to_dense(Decoded[0]))\n\n\t\tfor i in range(0, cfg.BatchSize):\n\n\t\t\tfileIndex = cfg.BatchSize * batch + i\n\t\t\tfilename = FilesList[fileIndex].strip()\n\t\t\tdecodedStr = "" ""\n\t\t\t\n\t\t\tfor j in range(0, len(trans[i])):\n\t\t\t\tif trans[i][j] == 0:\t\t\t\t\t\n\t\t\t\t\tif (j != (len(trans[i]) - 1)):\n\t\t\t\t\t\tif trans[i][j+1] == 0: break\n\t\t\t\t\t\telse: decodedStr = ""%s%s"" % (decodedStr, Classes[trans[i][j]])\n\t\t\t\t\telse:\n\t\t\t\t\t\tbreak\n\t\t\t\telse:\t\n\t\t\t\t\tif trans[i][j] == (NClasses - 2):\n\t\t\t\t\t\tif (j != 0): decodedStr = ""%s "" % (decodedStr)\n\t\t\t\t\t\telse: continue\n\t\t\t\t\telse:\n\t\t\t\t\t\tdecodedStr = ""%s%s"" % (decodedStr, Classes[trans[i][j]])\n\n\t\t\tdecodedStr = decodedStr.replace(""<SPACE>"", "" "")\n\n\t\t\tdecodedStr = filename + decodedStr[:] + ""\\n""\n\t\t\tif cfg.WriteDecodedToFile == True: DecodeLog.write(decodedStr)\n\t\t\telse: print(decodedStr, end=\' \')\n\n\t\tstart += cfg.BatchSize\n\t\tend += cfg.BatchSize\n\t\tbatch += 1\n\n\tDecodeLog.close()\n\nexcept (KeyboardInterrupt, SystemExit, Exception) as e:\n\tprint(""[Error/Interruption] %s"" % str(e))\n\tprint(""Clossing TF Session..."")\n\tsession.close()\n\tprint(""Terminating Program..."")\n\tsys.exit(0)\n\n\n'"
train.py,33,"b'###\n# Copyright 2018 Edgard Chammas. All Rights Reserved.\n# Licensed under the Creative Commons Attribution-NonCommercial International Public License, Version 4.0.\n# You may obtain a copy of the License at https://creativecommons.org/licenses/by-nc/4.0/legalcode\n###\n\n#!/usr/bin/python\n\nimport tensorflow as tf\nimport sys\nimport cv2\nimport numpy as np\nimport codecs\nimport math\n\nfrom config import cfg\nfrom util import LoadModel\nfrom util import SaveModel\nfrom util import ReadData\nfrom util import target_list_to_sparse_tensor\nfrom cnn import CNN\nfrom cnn import CNNLight\nfrom cnn import WND_HEIGHT\nfrom cnn import WND_WIDTH\nfrom cnn import WND_SHIFT\nfrom cnn import MPoolLayers_H\nfrom rnn import RNN\n\nVEC_PER_WND = WND_WIDTH / math.pow(2, MPoolLayers_H)\n\nnTimesNoProgress = 0\n\ncurrTrainLoss = 1e6; currValLoss = 1e6\n\ntotalIter = cfg.TRAIN_NB / cfg.BatchSize\n\nLogFile = codecs.open(cfg.LogFile, ""a"")\n\nphase_train = tf.Variable(True, name=\'phase_train\')\n\nx = tf.placeholder(tf.float32, shape=[None, WND_HEIGHT, WND_WIDTH])\n\nSeqLens = tf.placeholder(shape=[cfg.BatchSize], dtype=tf.int32)\n\nx_expanded = tf.expand_dims(x, 3)\n\n#Inputs = CNNLight(x_expanded, phase_train, \'CNN_1\')\nInputs = CNN(x_expanded, phase_train, \'CNN_1\')\n\nlogits = RNN(Inputs, SeqLens, \'RNN_1\')\n\n# Target params\nindices = tf.placeholder(dtype=tf.int64, shape=[None, 2])\nvalues = tf.placeholder(dtype=tf.int32, shape=[None])\nshape = tf.placeholder(dtype=tf.int64,shape=[2])\n\n# Make targets\ntargets = tf.SparseTensor(indices, values, shape)\n\n# Compute Loss\nlosses = tf.nn.ctc_loss(targets, logits, SeqLens)\n\nloss = tf.reduce_mean(losses)\n\nTrainLoss_s = tf.summary.scalar(\'TrainLoss\', loss)\n\n# CTC Beam Search Decoder to decode pred string from the prob map\ndecoded, log_prob = tf.nn.ctc_beam_search_decoder(logits, SeqLens)\n\npredicted = tf.to_int32(decoded[0])\n\nerror_rate = tf.reduce_sum(tf.edit_distance(predicted, targets, normalize=False)) / tf.to_float(tf.size(targets.values))    \n\nTrainError_s = tf.summary.scalar(\'TrainError\', error_rate)\n\ntvars = tf.trainable_variables()\n\ngrad, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), cfg.MaxGradientNorm)\n\noptimizer = tf.train.AdamOptimizer(learning_rate=cfg.LearningRate)\n\ntrain_step = optimizer.apply_gradients(zip(grad, tvars))\n\n#These values are used to draw performance graphs. Updated after each epoch.\nOverallTrainingLoss = tf.Variable(0, name=\'OverallTrainingLoss\', dtype=tf.float32)\nOverallTrainingError = tf.Variable(0, name=\'OverallTrainingError\', dtype=tf.float32)\nOverallValidationLoss = tf.Variable(0, name=\'OverallValidationLoss\', dtype=tf.float32)\nOverallValidationError = tf.Variable(0, name=\'OverallValidationError\', dtype=tf.float32)\nOverallTrainingLoss_s = tf.summary.scalar(\'OverallTrainingLoss\', OverallTrainingLoss)\nOverallTrainingError_s = tf.summary.scalar(\'OverallTrainingError\', OverallTrainingError)\nOverallValidationLoss_s = tf.summary.scalar(\'OverallValidationLoss\', OverallValidationLoss)\nOverallValidationError_s = tf.summary.scalar(\'OverallValidationError\', OverallValidationError)\n\n#Reading training data...\ninputList, seqLens, targetList = ReadData(cfg.TRAIN_LOCATION, cfg.TRAIN_LIST, cfg.TRAIN_NB, WND_HEIGHT, WND_WIDTH, WND_SHIFT, VEC_PER_WND, cfg.TRAIN_TRANS)\n\n#Reading validation data...\nif (cfg.VAL_NB > 0): inputListVal, seqLensVal, targetListVal = ReadData(cfg.VAL_LOCATION, cfg.VAL_LIST, cfg.VAL_NB, WND_HEIGHT, WND_WIDTH, WND_SHIFT, VEC_PER_WND, cfg.VAL_TRANS)\n\n# Starting everything...\nLogFile.write(""Initializing...\\n\\n"")\n\nsession = tf.Session()\n\nsession.run(tf.global_variables_initializer())\n\nLocalTrainSummary = tf.summary.merge([TrainLoss_s, TrainError_s])\n\nOverallSummary = tf.summary.merge([OverallTrainingLoss_s, OverallTrainingError_s, OverallValidationLoss_s, OverallValidationError_s])\n\nSummaryWriter = tf.summary.FileWriter(cfg.LogDir, session.graph)\n\nif cfg.StartingEpoch != 0: LoadModel(session, cfg.SaveDir+\'/\')\n\ntry:\n\tfor epoch in range(cfg.StartingEpoch, cfg.NEpochs):\n\t\t\n\t\tLogFile.write(""######################################################\\n"")\n\t\tLogFile.write(""Training Data\\n"")\n\n\t\tTrainingLoss = []\n\t\tTrainingError = []\n\n\t\tif cfg.RandomBatches == True: randIxs = np.random.permutation(len(inputList))\n\t\telse: randIxs = range(0, len(inputList))\n\n\t\tstart, end = (0, cfg.BatchSize)\n\n\t\tsession.run(tf.assign(phase_train, True))\n\n\t\tbatch = 0\n\t\twhile end <= len(inputList):\n\n\t\t\tbatchInputs = []\n\t\t\tbatchTargetList = []\n\t\t\tbatchSeqLengths = []\n\n\t\t\tfor batchI, origI in enumerate(randIxs[start:end]):\n\t\t\t\tbatchInputs.extend(inputList[origI])\n\t\t\t\tbatchTargetList.append(targetList[origI])\n\t\t\t\tbatchSeqLengths.append(seqLens[origI])\n\n\t\t\tbatchTargetSparse = target_list_to_sparse_tensor(batchTargetList)\n\t\t\tbatchTargetIxs, batchTargetVals, batchTargetShape = batchTargetSparse\n\n\t\t\tfeed = {x: batchInputs, SeqLens: batchSeqLengths, indices: batchTargetIxs, values: batchTargetVals, shape: batchTargetShape}\n\t\t\tdel batchInputs, batchTargetIxs, batchTargetVals, batchTargetShape, batchSeqLengths\n\n\t\t\t_, summary, Losses, Loss, Error = session.run([train_step, LocalTrainSummary, losses, loss, error_rate], feed_dict=feed)\n\t\t\tdel feed\n\n\t\t\tSummaryWriter.add_summary(summary, epoch*totalIter + batch)\n\t\t\t\n\t\t\tnumberOfInfElements = np.count_nonzero(np.isinf(Losses))\n\t\t\tif numberOfInfElements > 0:\n\t\t\t\tLogFile.write(""WARNING: INF VALUE(S) FOUND!\\n"")\n\t\t\t\tLogFile.write(""%s\\n"" % (batchTargetList[np.where(np.isinf(Losses)==True)[0][0]]))\n\t\t\t\tLogFile.write(""Losses\\n"")\n\t\t\t\tLosses = filter(lambda v: ~np.isinf(v), Losses)\n\t\t\t\tLoss = np.mean(Losses)\t\t\n\n\t\t\tTrainingLoss.append(Loss)\n\t\t\tTrainingError.append(Error)\n\n\t\t\tLogFile.write(""Epoch %d, Batch: %d, Loss: %.6f, Error: %.6f, "" % (epoch, batch, Loss, Error))\n\n\t\t\tif currTrainLoss < Loss: LogFile.write(""Bad\\n"")\n\t\t\telse: LogFile.write(""Good\\n"")\n\n\t\t\tstart += cfg.BatchSize\n\t\t\tend += cfg.BatchSize\n\t\t\tbatch += 1\n\n\t\tTrainingLoss = np.mean(TrainingLoss)\n\t\tTrainingError = np.mean(TrainingError)\n\n\t\tLogFile.write(""Training loss: %.6f, Training error: %.6f\\n"" % (TrainingLoss, TrainingError) )\n\n\t\tif TrainingLoss < currTrainLoss:\n\t\t\tcurrTrainLoss = TrainingLoss\n\t\t\tLogFile.write(""Training imporving.\\n"")\n\t\telse:\n\t\t\tLogFile.write(""Training not imporving.\\n"")\n\n\t\tif (epoch + 1) % cfg.SaveEachNEpochs == 0:\n\t\t\tSaveModel(session, cfg.SaveDir+\'/\'+cfg.ModelName, epoch)\n\n\t\tif (cfg.VAL_NB > 0):\n\n\t\t\tLogFile.write(""\\nValidation Data\\n"");\n\n\t\t\tsession.run(tf.assign(phase_train, False))\n\n\t\t\tValidationError = []\t\n\t\t\tValidationLoss = []\n\n\t\t\trandIxs = range(0, len(inputListVal))\n\t\t\tstart, end = (0, cfg.BatchSize)\n\n\t\t\tbatch = 0\n\t\t\twhile end <= len(inputListVal):\n\n\t\t\t\tbatchInputs = []\n\t\t\t\tbatchTargetList = []\n\t\t\t\tbatchSeqLengths = []\n\n\t\t\t\tfor batchI, origI in enumerate(randIxs[start:end]):\n\t\t\t\t\tbatchInputs.extend(inputListVal[origI])\n\t\t\t\t\tbatchTargetList.append(targetListVal[origI])\n\t\t\t\t\tbatchSeqLengths.append(seqLensVal[origI])\n\n\t\t\t\tbatchTargetSparse = target_list_to_sparse_tensor(batchTargetList)\n\t\t\t\tbatchTargetIxs, batchTargetVals, batchTargetShape = batchTargetSparse\n\t\t\t\n\t\t\t\tfeed = {x: batchInputs, SeqLens: batchSeqLengths, indices: batchTargetIxs, values: batchTargetVals, shape: batchTargetShape}\n\t\t\t\tdel batchInputs, batchTargetIxs, batchTargetVals, batchTargetShape, batchSeqLengths\n\n\t\t\t\tLoss, Error = session.run([loss, error_rate], feed_dict=feed)\n\t\t\t\tdel feed\n\n\t\t\t\tValidationError.append(Error)\n\t\t\t\tValidationLoss.append(Loss)\n\n\t\t\t\tLogFile.write(""Batch: %d, Loss: %.6f, Error: %.6f\\n"" % (batch, Loss, Error))\n\n\t\t\t\tstart += cfg.BatchSize\n\t\t\t\tend += cfg.BatchSize\n\t\t\t\tbatch += 1\n\n\t\t\tValidationLoss = np.mean(ValidationLoss)\n\t\t\tValidationError = np.mean(ValidationError)\n\n\t\t\tLogFile.write(""Validation loss: %.6f, Validation error: %.6f\\n"" % (ValidationLoss, ValidationError))\n\n\t\t\tfeed = {OverallTrainingLoss: TrainingLoss, OverallTrainingError: TrainingError, OverallValidationLoss: ValidationLoss, OverallValidationError: ValidationError}\n\t  \t\t\n\t\t\tSummaryWriter.add_summary(session.run([OverallSummary], feed_dict = feed)[0], epoch)\n\t\t\tdel feed\n\n\t\t\tif ValidationLoss < currValLoss:\n\t\t\t\tLogFile.write(""Validation improving.\\n"")\n\t\t\t\tnTimesNoProgress = 0\n\t\t\t\tcurrValLoss = ValidationLoss\n\t\t\telse:\n\t\t\t\tLogFile.write(""Validation not improving.\\n"")\n\t\t\t\tnTimesNoProgress = nTimesNoProgress + 1\n\t\t\t\tif nTimesNoProgress == cfg.TrainThreshold:\n\t\t\t\t\tsession.close()\n\t\t\t\t\tLogFile.write(""No progress on validation. Terminating program.\\n"")\n\t\t\t\t\tsys.exit(0)\n\n\t\t\tLogFile.write(""######################################################\\n\\n"")\n\nexcept (KeyboardInterrupt, SystemExit, Exception) as e:\n\tprint(""[Error/Interruption] %s\\n"" % str(e))\n\tLogFile.write(""[Error/Interruption] %s\\n"" % str(e))\n\tLogFile.write(""Clossing TF Session...\\n"")\n\tsession.close()\n\tLogFile.write(""Terminating Program...\\n"")\n\tLogFile.close()\n\tsys.exit(0)\n\n'"
util.py,16,"b'###\n# Copyright 2018 Edgard Chammas. All Rights Reserved.\n# Licensed under the Creative Commons Attribution-NonCommercial International Public License, Version 4.0.\n# You may obtain a copy of the License at https://creativecommons.org/licenses/by-nc/4.0/legalcode\n###\n\n#!/usr/bin/python\n\nimport tensorflow as tf\nimport numpy as np\nimport cv2\nimport math\nimport os\nimport codecs\nfrom config import cfg\n\ndef LoadList(path):\n    with open(path) as vlist:\n        return vlist.readlines()\n\n#Ref: https://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\ndef batch_norm_conv(x, n_out, phase_train):\n    with tf.variable_scope(\'bn\'):\n        beta = tf.Variable(tf.constant(0.0, shape=[n_out]), name=\'beta\', trainable=True)\n        gamma = tf.Variable(tf.constant(1.0, shape=[n_out]), name=\'gamma\', trainable=True)\n        batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name=\'moments\')\n        ema = tf.train.ExponentialMovingAverage(decay=0.5)\n\n        def mean_var_with_update():\n            ema_apply_op = ema.apply([batch_mean, batch_var])\n            with tf.control_dependencies([ema_apply_op]):\n                return tf.identity(batch_mean), tf.identity(batch_var)\n\n        mean, var = tf.cond(phase_train, mean_var_with_update,\n                            lambda: (ema.average(batch_mean), ema.average(batch_var)))\n        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n    return normed\n\ndef weight_variable(shape):\n  initial = tf.truncated_normal(shape, stddev=0.1)\n  return tf.Variable(initial)\n\ndef conv2d(x, W, stride=(1, 1), padding=\'SAME\'):\n  return tf.nn.conv2d(x, W, strides=[1, stride[0], stride[1], 1], padding=padding)\n\ndef max_pool(x, ksize=(2, 2), stride=(2, 2)):\n  return tf.nn.max_pool(x, ksize=[1, ksize[0], ksize[1], 1], strides=[1, stride[0], stride[1], 1], padding=\'SAME\')\n\n#Ref: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/ctc/ctc_loss_op_test.py\ndef target_list_to_sparse_tensor(targetList):\n    indices = []\n    vals = []\n\n    for tI, target in enumerate(targetList):\n        for seqI, val in enumerate(target):\n            indices.append([tI, seqI])\n            vals.append(val)\n    shape = [len(targetList), np.asarray(indices).max(0)[1]+1]\n    return (np.array(indices), np.array(vals), np.array(shape))\n\ndef LoadClasses(path):\n    data = {}\n    with codecs.open(path, \'r\', encoding=\'utf-8\') as cF:\n\t    data = cF.read().split(\'\\n\')\n    return data\n\ndef LoadList(path):\n    with open(path) as vlist:\n\treturn vlist.readlines()\n\ndef LoadModel(session, path):\n    saver = tf.train.Saver()\n    ckpt = tf.train.get_checkpoint_state(path)\n\n    if ckpt and ckpt.model_checkpoint_path:\n        saver.restore(session, ckpt.model_checkpoint_path)\n        print(\'Checkpoint restored\')\n    else:\n        print(\'No checkpoint found\')\n        exit()\n\ndef SaveModel(session, filename, epoch):\n    saver = tf.train.Saver()\n    saver.save(session, filename, global_step=epoch)\n\ndef ReadData(filesLocation, filesList, numberOfFiles, WND_HEIGHT, WND_WIDTH, WND_SHIFT, VEC_PER_WND, transDir=\'\'):\n\n\tseqLens = []\n\tinputList = []\n\ttargetList = []\n\n\twith open(filesList) as listHandler:\n\n\t\timgNbr = 0\n\t\timageFiles = listHandler.readlines()[0:numberOfFiles]\n\n\t\tfor imageFile in imageFiles:\n\n\t\t\tif filesLocation != \'\': tfile = imageFile.strip(\'\\n\')\n\t\t\telse: tfile = os.path.basename(imageFile.strip(\'\\n\'))\n\n\t\t\t################################################################\n\t\t\t# Adding transcriptions\n\n\t\t\tif transDir != \'\':\n\n\t\t\t    targetFile = transDir + ""/"" + tfile + cfg.LabelFileType\n\n\t\t\t    with open(targetFile) as f:\n\n\t\t\t\t    data = f.readlines()\n\n\t\t\t\t    if len(data) == 0:\n\t\t\t\t\t    targetList.append([])\n\t\t\t\t    else:\n\t\t\t\t\t    for i in range(len(data)):\n\t\t\t\t\t\t    targetData = np.fromstring(data[i], dtype=np.uint16, sep=\' \')\n\t\t\t\t\t\t    targetList.append(targetData)\n\n\t\t\t################################################################\n\t\t\t# Gathering the length of each sequence\n\n\t\t\tif filesLocation != \'\': imageFilePath = filesLocation + ""/"" + tfile + cfg.ImageFileType\n\t\t\telse: imageFilePath = imageFile.strip(\'\\n\') + cfg.ImageFileType\n\n\t\t\tprint ""Reading "" + imageFilePath\n\n\t\t\timage = cv2.imread(imageFilePath, cv2.IMREAD_GRAYSCALE)\n\n\t\t\th, w = np.shape(image)\n\n\t\t\tif(h > WND_HEIGHT): factor = WND_HEIGHT/float(h)\n\t\t\telse: factor = 1.0\n\n\t\t\timage = cv2.resize(image, None, fx=factor, fy=factor, interpolation = cv2.INTER_CUBIC)\n\n\t\t\th, w = np.shape(image)\n\n\t\t\twinId = 0\n\t\t\twpd = 0\n\t\t\twhile True:\n\n\t\t\t\ts = (winId * WND_SHIFT)\n\t\t\t\te = s + WND_WIDTH\n\n\t\t\t\tif e > w:\n\t\t\t\t\tsl = (winId+1) * VEC_PER_WND\n\n\t\t\t\t\tif transDir != \'\':\n\t\t\t\t\t    #Fix for small sequences\n\t\t\t\t\t    if(len(targetList[imgNbr]) > sl):\n\t\t\t\t\t\t    diff = len(targetList[imgNbr]) - sl\n\t\t\t\t\t\t    wpd = int(math.ceil(float(diff) / VEC_PER_WND))\n\t\t\t\t\t\t    sl = sl + wpd * VEC_PER_WND\n\n\t\t\t\t\tseqLens.append(sl)\n\n\t\t\t\t\tbreak\n\n\t\t\t\twinId = winId + 1\n\n\t\t\t################################################################\n\t\t\t# Adding features\n\n\t\t\tfeaturesSet = []\n\n\t\t\twinId = 0\n\t\t\twhile True:\n\n\t\t\t\ts = (winId * WND_SHIFT)\n\t\t\t\te = s + WND_WIDTH\n\n\t\t\t\tif e > w:\n\t\t\t\t\tpad = np.ones((h, (e - w)), np.uint8)*255\n\t\t\t\t\twnd = image[:h,s:w]\n\t\t\t\t\twnd = np.append(wnd, pad, axis=1)\n\n\t\t\t\t\tif h < WND_HEIGHT:\n\t\t\t\t\t\tpad = np.ones(((WND_HEIGHT - h), WND_WIDTH), np.uint8)*255\n\t\t\t\t\t\twnd = np.append(pad, wnd, axis=0)\n\n\t\t\t\t\tfeaturesSet.append(wnd)\n\n\t\t\t\t\t#Fix for small sequences\n\t\t\t\t\tpad = np.ones((WND_HEIGHT, WND_WIDTH), np.uint8)*255\n\n\t\t\t\t\tfor i in range(wpd): featuresSet.append(pad)\n\n\t\t\t\t\tbreak\n\n\t\t\t\twnd = image[:h,s:e]\n\n\t\t\t\tif h < WND_HEIGHT:\n\t\t\t\t\tpad = np.ones(((WND_HEIGHT - h), WND_WIDTH), np.uint8)*255\n\t\t\t\t\twnd = np.append(pad, wnd, axis=0)\n\n\t\t\t\tfeaturesSet.append(wnd)\n\t\t\t\twinId = winId + 1\n\n\t\t\t################################################################\n\t\t\tinputList.append(featuresSet)\n\n\t\t\timgNbr = imgNbr + 1\n\t\t\t################################################################\n\n\tif transDir != \'\':\n\t    assert len(inputList) == len(targetList)\n\n\treturn inputList, seqLens, targetList\n\n'"
