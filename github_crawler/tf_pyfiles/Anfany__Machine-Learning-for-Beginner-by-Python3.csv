file_path,api_count,code
Blending/BP_Regression.py,15,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe9\x80\x82\xe7\x94\xa8\xe4\xba\x8e\xe5\xa4\x9a\xe7\xbb\xb4\xe8\xbe\x93\xe5\x87\xba\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n'''\xe5\x9f\xba\xe4\xba\x8eTensorFlow\xe6\x9e\x84\xe5\xbb\xba\xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0'''\r\n# \xe5\x88\x9b\xe5\xbb\xba\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\ndef activate(input_layer, weights, biases, actfunc):\r\n    layer = tf.add(tf.matmul(input_layer, weights), biases)\r\n    if actfunc == 'relu':\r\n        return tf.nn.relu(layer)\r\n    elif actfunc == 'tanh':\r\n        return tf.nn.tanh(layer)\r\n    elif actfunc == 'sigmoid':\r\n        return tf.nn.sigmoid(layer)\r\n# \xe6\x9d\x83\xe9\x87\x8d\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe5\x92\x8c\xe5\x88\xa9\xe7\x94\xa8\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\xe5\xbe\x88\xe5\xa4\xa7\r\n# sigmoid: xavir  tanh: xavir    relu: he\r\n\r\n#  \xe6\x9e\x84\xe5\xbb\xba\xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Ten_train(xdata, ydata, prexdata, preydata, hiddenlayers=3, hiddennodes=100, \\\r\n              learn_rate=0.05, itertimes=100000, batch_size=200, activate_func='sigmoid', break_error=0.0043):\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe6\x90\xad\xe5\xbb\xba\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\r\n    Input_Dimen = len(xdata[0])\r\n    Unit_Layers = [Input_Dimen] + [hiddennodes] * hiddenlayers + [len(ydata[0])]  # \xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84\xe7\xbb\xb4\xe6\x95\xb0\xef\xbc\x8c\xe9\x9a\x90\xe5\xb1\x82\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe6\x95\xb0\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\xb4\xe6\x95\xb01\r\n\r\n    # \xe5\x88\x9b\xe5\xbb\xba\xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\r\n    x_data = tf.placeholder(shape=[None, Input_Dimen], dtype=tf.float32, name='x_data')\r\n    y_target = tf.placeholder(shape=[None, len(ydata[0])], dtype=tf.float32)\r\n\r\n    # \xe5\xae\x9e\xe7\x8e\xb0\xe5\x8a\xa8\xe6\x80\x81\xe5\x91\xbd\xe5\x90\x8d\xe5\x8f\x98\xe9\x87\x8f\r\n    VAR_NAME = locals()\r\n\r\n    for jj in range(hiddenlayers + 1):\r\n        VAR_NAME['weight%s' % jj] = tf.Variable(np.random.rand(Unit_Layers[jj], Unit_Layers[jj + 1]), dtype=tf.float32,\\\r\n                                                name='weight%s' % jj) / np.sqrt(Unit_Layers[jj])  # sigmoid  tanh\r\n        # VAR_NAME['weight%s'%jj] = tf.Variable(np.random.rand(Unit_Layers[jj], Unit_Layers[jj + 1]), dtype=tf.float32,name='weight%s' % jj) \\/ np.sqrt(Unit_Layers[jj] / 2)  # relu\r\n        VAR_NAME['bias%s' % jj] = tf.Variable(tf.random_normal([Unit_Layers[jj + 1]], stddev=10, name='bias%s' % jj),\r\n                                              dtype=tf.float32)\r\n        if jj == 0:\r\n            VAR_NAME['ooutda%s' % jj] = activate(x_data, eval('weight%s' % jj), eval('bias%s' % jj), actfunc=activate_func)\r\n        else:\r\n            VAR_NAME['ooutda%s' % jj] = activate(eval('ooutda%s' % (jj - 1)), eval('weight%s' % jj), \\\r\n                                                 eval('bias%s' % jj), actfunc=activate_func)\r\n\r\n    # \xe5\x9d\x87\xe6\x96\xb9\xe8\xaf\xaf\xe5\xb7\xae\r\n    loss = tf.reduce_mean(tf.reduce_sum(tf.square(y_target - eval('ooutda%s' % (hiddenlayers))), reduction_indices=[1]))\r\n\r\n    # \xe4\xbc\x98\xe5\x8c\x96\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\r\n    my_opt = tf.train.AdamOptimizer(learn_rate)\r\n    train_step = my_opt.minimize(loss)\r\n\r\n    # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n    init = tf.global_variables_initializer()\r\n\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    accudict = {}\r\n\r\n    loss_vec = []  # \xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\r\n\r\n    loss_pre = []  # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe8\xaf\xaf\xe5\xb7\xae\r\n    accunum = np.inf\r\n    with tf.Session() as sess:\r\n        saver = tf.train.Saver()\r\n        sess.run(init)\r\n        for i in range(itertimes):\r\n            rand_index = np.random.choice(len(xdata), size=batch_size, replace=False)\r\n            rand_x = xdata[rand_index]\r\n            rand_y = ydata[rand_index]\r\n\r\n            sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\r\n\r\n            temp_loss = sess.run(loss, feed_dict={x_data: xdata, y_target: ydata})\r\n\r\n            temmp_losspre = sess.run(loss, feed_dict={x_data: prexdata, y_target: preydata})\r\n\r\n            loss_vec.append(temp_loss)\r\n            loss_pre.append(temmp_losspre)\r\n\r\n            accudict[i] = [temp_loss, temmp_losspre]\r\n\r\n            # \xe6\xa0\xb9\xe6\x8d\xae\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x8c\xe5\x88\xa4\xe6\x96\xad\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe6\x83\x85\xe5\x86\xb5\r\n            if (i + 1) % 20 == 0:\r\n                print('Generation: ' + str(i + 1) + '. \xe5\xbd\x92\xe4\xb8\x80\xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9aLoss = ' + str(temp_loss) +\r\n                      '. \xe5\xbd\x92\xe4\xb8\x80\xe9\xaa\x8c\xe8\xaf\x81\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9aLoss = ' + str(temmp_losspre))\r\n\r\n            # \xe6\x8f\x90\xe5\x89\x8d\xe9\x80\x80\xe5\x87\xba\xe7\x9a\x84\xe5\x88\xa4\xe6\x96\xad\r\n            if temp_loss < break_error:  # \xe6\xa0\xb9\xe6\x8d\xae\xe7\xbb\x8f\xe9\xaa\x8c\xe8\x8e\xb7\xe5\xbe\x97\xe6\xad\xa4\xe6\x95\xb0\xe5\x80\xbc, \xe5\x9b\xa0\xe4\xb8\xba\xe9\x87\x87\xe7\x94\xa8\xe7\x9a\x84\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe4\xb8\x8b\xe9\x99\x8d\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9c\xa8\xe5\x89\x8d\xe6\x9c\x9f\xe5\x8f\xaf\xe8\x83\xbd\xe5\x87\xba\xe7\x8e\xb0\xe6\xb5\xae\xe5\x8a\xa8\r\n                break\r\n\r\n            # \xe5\x9c\xa8\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\xbe\xaa\xe7\x8e\xaf\xe6\xac\xa1\xe6\x95\xb0\xe4\xb8\xad\xef\xbc\x8c\xe6\x89\xbe\xe5\x88\xb0\xe7\xbb\xbc\xe5\x90\x88\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9c\x80\xe4\xbd\x8e\xe7\x9a\x84\xe4\xb8\x80\xe6\xac\xa1\xef\xbc\x8c\xe4\xbf\x9d\xe5\xad\x98\xe5\x8f\x82\xe6\x95\xb0\r\n            zongheaccu = 0.01 * temp_loss + 0.99 * temmp_losspre\r\n            if zongheaccu < accunum:\r\n                accunum = zongheaccu\r\n                # \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\r\n                saver.save(sess, './pm25', global_step=i)  # \xe6\xb3\xa8\xe6\x84\x8f\xe8\xb7\xaf\xe5\xbe\x84\r\n\r\n        sign = min(accudict.items(), key=lambda d: 0.01 * d[1][0] + 0.99 * d[1][1])[0]\r\n\r\n        # \xe8\xbf\x94\xe5\x9b\x9e\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe8\xaf\xaf\xe5\xb7\xae\r\n        xunlian_error, adderror = loss_vec[sign], loss_pre[sign]\r\n\r\n        return sign, hiddenlayers, xunlian_error, adderror\r\n\r\n\r\n\r\n\r\n"""
Blending/Blending_Classify_adult.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe4\xb8\xa4\xe5\xb1\x82\xe7\x9a\x84Blending\xe5\x88\x86\xe7\xb1\xbb\r\n\r\n#  \xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x826\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xef\xbc\x8cAdaBoost\xef\xbc\x8cGBDT\xef\xbc\x8cLightGBM\xef\xbc\x8cXGBoost\xef\xbc\x8cCatBoost\r\n#  \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\r\nimport adult_Blending_Data as adult\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe7\xbb\x98\xe5\x9b\xbe\xe5\xba\x93\xe5\x8c\x85\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nfrom matplotlib.ticker import MultipleLocator, FormatStrFormatter\r\n# \xe8\xae\xbe\xe7\xbd\xae\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x88\xbb\xe5\xba\xa6\xe4\xb8\x8e\xe5\xad\x90\xe5\x88\xbb\xe5\xba\xa6\r\ny_toge = MultipleLocator(0.02)  # \xe5\xb0\x86y\xe8\xbd\xb4\xe4\xb8\xbb\xe5\x88\xbb\xe5\xba\xa6\xe6\xa0\x87\xe7\xad\xbe\xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xba0.1\xe7\x9a\x84\xe5\x80\x8d\xe6\x95\xb0\r\ny_son = MultipleLocator(0.01)  # \xe5\xb0\x86\xe6\xad\xa4y\xe8\xbd\xb4\xe6\xac\xa1\xe5\x88\xbb\xe5\xba\xa6\xe6\xa0\x87\xe7\xad\xbe\xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xba0.01\xe7\x9a\x84\xe5\x80\x8d\xe6\x95\xb0\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe9\x9c\x80\xe8\xa6\x81\xe7\x94\xa8\xe5\x88\xb0\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\xba\x93\xe5\x8c\x85\r\n# \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\r\nfrom sklearn.ensemble import RandomForestClassifier as RF\r\n# AdaBoost\r\nfrom sklearn.ensemble import AdaBoostClassifier\r\nfrom sklearn.tree import DecisionTreeClassifier\r\n# GBDT\r\nfrom sklearn.ensemble import GradientBoostingClassifier\r\n# XGBoost\r\nimport xgboost as xgb\r\n# LightGBM\r\nimport lightgbm as lgbm\r\n# CatBoost\r\nimport catboost as cb\r\n# \xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\r\nimport LR\r\n\r\n# \xe5\x85\xb6\xe4\xbb\x96\xe5\xba\x93\xe5\x8c\x85\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom collections import OrderedDict  # python\xe5\xad\x97\xe5\x85\xb8\xe6\x98\xaf\xe6\x97\xa0\xe5\xba\x8f\xe7\x9a\x84\xef\xbc\x8c\xe6\xad\xa4\xe5\x8c\x85\xe6\x98\xaf\xe6\x9c\x89\xe5\xba\x8f\xe7\x9a\x84\r\n# \xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable as PT\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe6\xa8\xa1\xe5\x9e\x8b\r\n\'\'\'\r\n\r\nclass DATA:\r\n\r\n    def __init__(self, datadict=adult.data_dict, mubiao=\'Money\'):\r\n        self.data = datadict\r\n        self.k = 0.3  # \xe5\x92\x8cStacking\xe4\xb8\x8d\xe5\x90\x8c\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x98\xaf\xe5\x9b\xba\xe5\xae\x9a\xe7\x9a\x84\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe8\xae\xbe\xe7\xbd\xae\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\r\n\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n        self.chidata = self.data[\'train\']\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\n        self.nodata = self.data[\'predict\']\r\n\r\n        # \xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\xbc\x96\xe5\x8f\xb7\r\n        self.catsign = self.Sign()\r\n\r\n        # \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\r\n        self.ziduan = mubiao\r\n\r\n        # \xe5\xaf\xb9\xe4\xba\x8eCatBoost\xe8\x80\x8c\xe8\xa8\x80\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xef\xbc\x8c\xe8\xbd\xac\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe7\xbb\x93\xe6\x9e\x9c\xe4\xb8\xad\xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe8\xbf\x99\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x90\x8d\xe7\xa7\xb0\r\n        self.typedict = self.TransType()\r\n\r\n\r\n    # \xe5\x9b\xa0\xe4\xb8\xba\xe5\xaf\xb9\xe4\xba\x8eCatBoost\xe8\x80\x8c\xe8\xa8\x80\xef\xbc\x8c\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe9\x9c\x80\xe8\xa6\x81\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe6\xa0\x87\xe5\x8f\xb7\r\n    def Sign(self):\r\n        sign = []\r\n        numlist = self.chidata.values[0][: -1]  # \xe4\xb8\x8d\xe5\x8c\x85\xe6\x8b\xac\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\r\n        for jj in range(len(numlist)):\r\n            try:\r\n                numlist[jj] + 9\r\n            except TypeError:\r\n                sign.append(jj)\r\n        return sign\r\n\r\n    # \xe5\xaf\xb9\xe4\xba\x8eCatBoost\xe8\x80\x8c\xe8\xa8\x80\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe5\xaf\xb9\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\r\n    def TransType(self):\r\n        tdict = {}\r\n        nulist = sorted(list(set(list(self.chidata[self.ziduan]))))\r\n        for jj in nulist:\r\n            tdict[jj] = nulist.index(jj)\r\n        return tdict\r\n\r\n    # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97(CatBoost)\r\n    def TargetoDi(self):\r\n        # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x8c\x89\xe7\x85\xa7\xe5\xad\x97\xe5\x85\xb8\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f\xe8\xbd\xac\xe5\x8f\x98\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97\r\n        self.chidata[self.ziduan] = [self.typedict[jj] for jj in self.chidata[self.ziduan]]\r\n        return print(\'CatBoost\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\xbd\xac\xe5\x8c\x96\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe5\xad\x97\xe6\xa0\x87\xe7\xad\xbe\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\r\n    def CAtoDI(self):\r\n        # \xe5\xa6\x82\xe6\x9e\x9c\xe7\x89\xb9\xe5\xbe\x81\xe5\x80\xbc\xe4\xb8\x8d\xe8\x83\xbd\xe6\x89\xa7\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe5\x8a\xa0\xe6\xb3\x95\xe8\xbf\x90\xe7\xae\x97\xef\xbc\x8c\xe5\x88\x99\xe8\xa7\x86\xe4\xb8\xba\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\r\n        for tezheng in self.chidata:\r\n            try:\r\n                self.chidata[tezheng].values[0] + 1\r\n            except TypeError:\r\n                numlist = sorted(list(set(list(self.chidata[tezheng]))))\r\n                self.chidata[tezheng] = [numlist.index(hh) for hh in self.chidata[tezheng]]\r\n                try:\r\n                    self.nodata[tezheng] = [numlist.index(ss) for ss in self.nodata[tezheng]]\r\n                except ValueError:\r\n                    print(\'\xe7\x89\xb9\xe5\xbe\x81%s\xef\xbc\x9a\xe9\xa2\x84\xe6\xb5\x8b\xe6\xaf\x94\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xa4\x9a\xe4\xba\x86\xe5\x80\xbc\' % (tezheng))\r\n        return print(\'\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\r\n    def Normal(self):\r\n        # \xe5\x9c\xa8\xe6\xad\xa4\xe4\xb9\x8b\xe5\x89\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\x8a\x8a\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe6\xa0\x87\xe7\xad\xbe\xe5\x8e\xbb\xe6\x8e\x89,\xe5\x90\xa6\xe5\x88\x99\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99\r\n        for tezheng in self.chidata:\r\n            maxnum = max(list(self.chidata[tezheng]))\r\n            minum = min(list(self.chidata[tezheng]))\r\n            if maxnum == minum:\r\n                self.chidata[tezheng] = [1 for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [1 for ss in self.nodata[tezheng]]\r\n            else:\r\n                self.chidata[tezheng] = [(hh - minum) / (maxnum - minum) for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [(ss - minum) / (maxnum - minum) for ss in self.nodata[tezheng]]\r\n        return print(\'\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\r\n    def Stand(self):\r\n        # \xe5\x9c\xa8\xe6\xad\xa4\xe4\xb9\x8b\xe5\x89\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\x8a\x8a\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe6\xa0\x87\xe7\xad\xbe\xe5\x8e\xbb\xe6\x8e\x89,\xe5\x90\xa6\xe5\x88\x99\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99\r\n        for tezheng in self.chidata:\r\n            standnum = np.std(np.array(list(self.chidata[tezheng])), ddof=1)  # \xe8\xae\xa1\xe7\xae\x97\xe6\x9c\x89\xe5\x81\x8f\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\r\n            meanum = np.mean(np.array(list(self.chidata[tezheng])))\r\n\r\n            if meanum == 0:\r\n                self.chidata[tezheng] = [1 for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [1 for ss in self.nodata[tezheng]]\r\n            else:\r\n                self.chidata[tezheng] = [(hh - standnum) / meanum for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [(ss - standnum) / meanum for ss in self.nodata[tezheng]]\r\n        return print(\'\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe5\xae\x9a\xe4\xb9\x89\xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x8c\x89\xe7\x85\xa7\xe6\xaf\x94\xe4\xbe\x8b\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\x8d\xe5\x90\x8c\xe7\x94\xa8\xe9\x80\x94\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\r\n    def Kfold(self):\r\n        # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe5\x90\x88\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe9\x9b\x86\xe6\x88\x90\xe8\xb5\xb7\xe6\x9d\xa5\xef\xbc\x8c\xe4\xb8\xba\xe4\xba\x86\xe6\x96\xb9\xe4\xbe\xbf\xe8\xb5\xb7\xe8\xa7\x81\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe5\x9b\xba\xe5\xae\x9a\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe6\x95\xb0\xe4\xb8\xad\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\r\n        datanum = self.chidata.values\r\n        # \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n        length = len(datanum)\r\n        alist = np.arange(length)\r\n        np.random.seed(1990)\r\n        np.random.shuffle(alist)  # \xe9\x9a\x8f\xe6\x9c\xba\xe6\x89\x93\xe4\xb9\xb1\xe6\x95\xb0\xe6\x8d\xae\xe5\xaf\xb9BPNN,SVM\xe8\x80\x8c\xe8\xa8\x80\xe6\x98\xaf\xe6\x9c\x89\xe7\x9b\x8a\xe5\xa4\x84\xe7\x9a\x84\xef\xbc\x8c\xe8\x80\x8c\xe5\xaf\xb9\xe4\xba\x8e\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe4\xb9\x8b\xe7\xb1\xbb\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe8\x80\x8c\xe8\xa8\x80\xe6\xb2\xa1\xe6\x9c\x89\xe5\xbd\xb1\xe5\x93\x8d\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\r\n        yanlem = int(length * self.k)\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        datai = {}\r\n        datai[\'predict\'] = self.nodata.values\r\n\r\n        # \xe9\x80\x89\xe4\xb8\xad\xe7\x9a\x84\xe4\xbd\x9c\xe4\xb8\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xb4\xa2\xe5\xbc\x95\xe5\xba\x8f\xe5\x88\x97\r\n        np.random.seed(2000)\r\n        yanlis = np.random.choice(alist, yanlem, replace=False)\r\n\r\n        # \xe6\xb2\xa1\xe6\x9c\x89\xe8\xa2\xab\xe9\x80\x89\xe4\xb8\xad\xe7\x9a\x84\xe4\xbd\x9c\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xb4\xa2\xe5\xbc\x95\xe5\xba\x8f\xe5\x88\x97\r\n        trainlis = [ki for ki in alist if ki not in yanlis]\r\n\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n        datai[\'train\'] = datanum[trainlis]\r\n\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n        datai[\'test\'] = datanum[yanlis]\r\n\r\n        # \xe8\xbf\x94\xe5\x9b\x9e\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\xbd\xa2\xe5\xbc\x8f{\'train\':data, \'test\':data, \'predict\':data}\r\n        print(\'\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe5\x89\xb2\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n        return datai\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xbf\x90\xe8\xa1\x8c\xe9\x98\xb6\xe6\xae\xb5\r\n\'\'\'\r\n# \xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbb\xbb\xe6\x84\x8f\xe6\xb7\xbb\xe5\x8a\xa0\xe6\xa8\xa1\xe5\x9e\x8b\r\nclass MODELONE:\r\n\r\n    def __init__(self, exdict, zidan=\'Money\'):\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_pr = []\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_real = []\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.predi = []\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe5\xa7\x90\xe5\xa4\xab\xe5\x93\xa6\r\n        self.preal = []\r\n\r\n        # \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\xe7\xa7\xb0\r\n        self.zi = zidan\r\n\r\n        # \xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe5\x92\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe7\xb1\xbb\xe7\x9a\x84\xe4\xbf\x9d\xe6\x8c\x81\xe4\xb8\x80\xe8\x87\xb4\xef\xbc\x8c\xe8\xa6\x81\xe6\x8a\x8a\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x90\x88\xe4\xba\x8c\xe4\xb8\xba\xe4\xb8\x80\r\n        self.datai = {}\r\n\r\n        # \xe8\xae\xb0\xe5\xbd\x95\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x9c\x80\xe7\xbb\x88\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        self.error_dict = OrderedDict()\r\n\r\n        # \xe6\x95\xb0\xe5\xad\x97\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\x8e\xe6\xad\xa3\xe5\xb8\xb8\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\xaf\xb9\xe5\xba\x94\xe5\xad\x97\xe5\x85\xb8\r\n        self.tydict = exdict\r\n\r\n    # \xe5\xb0\x86\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba\xe4\xbd\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe5\xa4\x84\xe7\x90\x86\xe7\xb1\xbb\xe4\xb8\xad\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    #  \xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf{\'train\':dataframe, \'predict\':dataframe}\xe6\xa0\xb7\xe5\xbc\x8f\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    def DataStru(self):\r\n        self.datai[\'train\'] = np.row_stack((np.array(self.yanzhneg_pr), np.array(self.yanzhneg_real)))  # \xe6\xad\xa4\xe5\xa4\x84\xe6\xb7\xbb\xe5\x8a\xa0\xe8\xa1\x8c\r\n        self.datai[\'predict\'] = np.row_stack((np.array(self.predi), np.array(self.preal)))\r\n        # \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe7\xbd\xae\r\n        datapst = self.datai[\'train\'].T\r\n        # \xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xae\x9a\xe4\xb9\x89DataFrame\xe7\x9a\x84\xe5\x88\x97\xe5\x90\x8d\r\n        mingcheng = [\'\xe7\xac\xac%s\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x88\x97\' % str(dd) for dd in list(range(len(self.datai[\'train\']) - 1))] + [self.zi]\r\n        self.datai[\'train\'] = pd.DataFrame(datapst, columns=mingcheng)\r\n\r\n        # \xe5\xb0\x86\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe7\xbd\xae\r\n        dapst = self.datai[\'predict\'].T\r\n        # \xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xae\x9a\xe4\xb9\x89DataFrame\xe7\x9a\x84\xe5\x88\x97\xe5\x90\x8d\r\n        mingche= [\'\xe7\xac\xac%s\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x88\x97\' % str(dd) for dd in list(range(len(self.datai[\'predict\']) - 1))] + [self.zi]\r\n        self.datai[\'predict\'] = pd.DataFrame(dapst, columns=mingche)\r\n        return print(\'\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe5\x88\x9b\xe5\xbb\xba\xe5\xb0\x86\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe5\xa4\x9a\xe7\xbb\xb4\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe7\xb1\xbb\xe5\x88\xab\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe4\xb8\x80\xe7\xbb\xb4\xe5\x8e\x9f\xe5\xa7\x8b\xe5\x90\x8d\xe7\xa7\xb0\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def AntiTae(self, relist):\r\n        huhuan = {self.tydict[ll]: ll for ll in self.tydict}\r\n        return [huhuan[dd] for dd in relist]\r\n\r\n    # \xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def Tom(self, reallist, prelist):\r\n        \'\'\'\r\n        :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n        :param prelist:  \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n        :return: \xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\xba\xe6\x89\x80\xe6\x9c\x89\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe5\x85\xb8\r\n        \'\'\'\r\n        coundict = {}\r\n        for jj in list(set(reallist)):\r\n            coundict[jj] = {}\r\n            for hh in list(set(reallist)):\r\n                coundict[jj][hh] = len([i for i, j in zip(reallist, prelist) if i == jj and j == hh])\r\n        return coundict\r\n\r\n    # \xe5\xae\x9a\xe4\xb9\x89\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def ConfuseMatrix(self, reallist, prelist):\r\n        \'\'\'\r\n        :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n        :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n        :return: \xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n        \'\'\'\r\n        zidian = self.Tom(reallist, prelist)\r\n        lieming = sorted(zidian.keys())\r\n        table = PT([\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\'] + [\'\xe9\xa2\x84\xe6\xb5\x8b%s\' % d for d in lieming])\r\n        for jj in lieming:\r\n            table.add_row([\'\xe5\xae\x9e\xe9\x99\x85%s\' % jj] + [zidian[jj][kk] for kk in lieming])\r\n        return table\r\n\r\n    # \xe5\xae\x9a\xe4\xb9\x89\xe8\xae\xa1\xe7\xae\x97F1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def F1(self, realist, prelist):\r\n        \'\'\'\r\n        :param realist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n        :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n        :return: F1\xe5\xba\xa6\xe9\x87\x8f\r\n        \'\'\'\r\n        condict = self.Tom(realist, prelist)\r\n        zongshu = 0\r\n        zhengque = 0\r\n        zhao_cu = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n        for cu in condict:\r\n            zq = 0\r\n            zs = 0\r\n            for hh in condict[cu]:\r\n                geshu = condict[cu][hh]\r\n                if cu == hh:\r\n                    zhengque += geshu\r\n                    zq = geshu\r\n                zongshu += geshu\r\n                zs += geshu\r\n            zhao_cu.append(zq / zs)\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\r\n        jingque = zhengque / zongshu\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe5\x88\xab\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n        zhaohui = np.mean(np.array(zhao_cu))\r\n        # f1\xe5\xba\xa6\xe9\x87\x8f\r\n        f_degree = 2 * jingque * zhaohui / (jingque + zhaohui)\r\n        return f_degree\r\n\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\r\n    def RF_First(self, data, n_estimators=800, max_features=\'sqrt\'):\r\n        # \xe5\xaf\xb9\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe8\xbf\x94\xe5\x9b\x9e\xe6\xa8\xa1\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        model = RF(n_estimators=n_estimators, max_features=max_features)\r\n        model.fit(data[\'train\'][:, :-1], data[\'train\'][:, -1])\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        xul = model.predict(data[\'train\'][:, :-1])\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanre = model.predict(data[\'test\'][:, :-1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prer = model.predict(data[\'predict\'][:, :-1])\r\n\r\n        # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        xx = self.F1(xul, data[\'train\'][:, -1])\r\n\r\n        yy = self.F1(yanre, data[\'test\'][:, -1])\r\n\r\n        pp = self.F1(prer, data[\'predict\'][:, -1])\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanre)\r\n        self.yanzhneg_real = data[\'test\'][:, -1]\r\n        self.predi.append(prer)\r\n        self.preal = data[\'predict\'][:, -1]\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\'] = [xx, yy, pp]\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # AdaBoost\r\n    def Adaboost_First(self, data, max_depth=5, n_estimators=300):\r\n        model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=max_depth),\r\n                                   algorithm=""SAMME"",\r\n                                   n_estimators=n_estimators, learning_rate=0.8)\r\n        model.fit(data[\'train\'][:, :-1], data[\'train\'][:, -1])\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        xul = model.predict(data[\'train\'][:, :-1])\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanre = model.predict(data[\'test\'][:, :-1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prer = model.predict(data[\'predict\'][:, :-1])\r\n\r\n        # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        xx = self.F1(xul, data[\'train\'][:, -1])\r\n\r\n        yy = self.F1(yanre, data[\'test\'][:, -1])\r\n\r\n        pp = self.F1(prer, data[\'predict\'][:, -1])\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanre)\r\n        self.yanzhneg_real = data[\'test\'][:, -1]\r\n        self.predi.append(prer)\r\n        self.preal = data[\'predict\'][:, -1]\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'AdaBoost\'] = [xx, yy, pp]\r\n\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84AdaBoost\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # GBDT\r\n    def GBDT_First(self, data, max_depth=5, n_estimators=320):\r\n        model = GradientBoostingClassifier(loss=\'deviance\', n_estimators=n_estimators, max_depth=max_depth,\r\n                                           learning_rate=0.1, max_features=\'sqrt\')\r\n        model.fit(data[\'train\'][:, :-1], data[\'train\'][:, -1])\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        xul = model.predict(data[\'train\'][:, :-1])\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanre = model.predict(data[\'test\'][:, :-1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prer = model.predict(data[\'predict\'][:, :-1])\r\n\r\n        # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        xx = self.F1(xul, data[\'train\'][:, -1])\r\n\r\n        yy = self.F1(yanre, data[\'test\'][:, -1])\r\n\r\n        pp = self.F1(prer, data[\'predict\'][:, -1])\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanre)\r\n        self.yanzhneg_real = data[\'test\'][:, -1]\r\n        self.predi.append(prer)\r\n        self.preal = data[\'predict\'][:, -1]\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'GBDT\'] = [xx, yy, pp]\r\n\r\n\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84GBDT\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # LightGBM\r\n    def LightGBM_First(self, data, max_depth=5, n_estimators=400):\r\n        model = lgbm.LGBMClassifier(boosting_type=\'gbdt\', objective=\'binary\', num_leaves=200,\r\n                                    learning_rate=0.1, n_estimators=n_estimators, max_depth=max_depth,\r\n                                    bagging_fraction=0.9, feature_fraction=0.9, reg_lambda=0.2)\r\n        model.fit(data[\'train\'][:, :-1], data[\'train\'][:, -1])\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        xul = model.predict(data[\'train\'][:, :-1])\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanre = model.predict(data[\'test\'][:, :-1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prer = model.predict(data[\'predict\'][:, :-1])\r\n\r\n        # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        xx = self.F1(xul, data[\'train\'][:, -1])\r\n\r\n        yy = self.F1(yanre, data[\'test\'][:, -1])\r\n\r\n        pp = self.F1(prer, data[\'predict\'][:, -1])\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanre)\r\n        self.yanzhneg_real = data[\'test\'][:, -1]\r\n        self.predi.append(prer)\r\n        self.preal = data[\'predict\'][:, -1]\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'LightGBM\'] = [xx, yy, pp]\r\n\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84LightGBM\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # XGBoost\r\n    def XGBoost_First(self, data, max_depth=8, n_estimators=220):\r\n        model = xgb.XGBClassifier(max_depth=max_depth, learning_rate=0.1, n_estimators=n_estimators,\r\n                                  silent=True, objective=\'binary:logistic\', booster=\'gbtree\')\r\n        model.fit(data[\'train\'][:, :-1], data[\'train\'][:, -1])\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        xul = model.predict(data[\'train\'][:, :-1])\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanre = model.predict(data[\'test\'][:, :-1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prer = model.predict(data[\'predict\'][:, :-1])\r\n\r\n        # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        xx = self.F1(xul, data[\'train\'][:, -1])\r\n\r\n        yy = self.F1(yanre, data[\'test\'][:, -1])\r\n\r\n        pp = self.F1(prer, data[\'predict\'][:, -1])\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanre)\r\n        self.yanzhneg_real = data[\'test\'][:, -1]\r\n        self.predi.append(prer)\r\n        self.preal = data[\'predict\'][:, -1]\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'XGBoost\'] = [xx, yy, pp]\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84XGBoost\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # CatBoost\r\n    def CatBoost_First(self, data, catsign, depth=5, iterations=200):\r\n\r\n        model = cb.CatBoostClassifier(iterations=iterations, depth=depth, learning_rate=0.5,\r\n                                      loss_function=\'Logloss\', logging_level=\'Verbose\')\r\n\r\n        model.fit(data[\'train\'][:, :-1], data[\'train\'][:, -1], cat_features=catsign)\r\n        # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        xul = model.predict(data[\'train\'][:, :-1])\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanre = model.predict(data[\'test\'][:, :-1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prer = model.predict(data[\'predict\'][:, :-1])\r\n\r\n        # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        xx = self.F1(xul, data[\'train\'][:, -1])\r\n\r\n        yy = self.F1(yanre, data[\'test\'][:, -1])\r\n\r\n        pp = self.F1(prer, data[\'predict\'][:, -1])\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanre)\r\n        self.yanzhneg_real = data[\'test\'][:, -1]\r\n        self.predi.append(prer)\r\n        self.preal = data[\'predict\'][:, -1]\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'CatBoost\'] = [xx, yy, pp]\r\n\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84CatBoost\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xbf\x90\xe8\xa1\x8c\xe9\x98\xb6\xe6\xae\xb5 \xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbb\xbb\xe6\x84\x8f\xe6\x9b\xb4\xe6\x8d\xa2\xe6\xa8\xa1\xe5\x9e\x8b\r\n\'\'\'\r\nclass MODETWO:\r\n\r\n    def __init__(self, in_tr_data, out_tr_data, in_pre_data):\r\n        self.xdata = in_tr_data\r\n        self.ydata = out_tr_data\r\n\r\n        self.xdatapre = in_pre_data\r\n\r\n\r\n    # \xe5\xae\x9a\xe4\xb9\x89\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def Lr(self, learn_rate=0.5, iter_tiems=40000, error=1e-9, con=\'L2\'):\r\n        losserr, preout = LR.trans_tf(self.xdata, self.ydata, self.xdatapre,\r\n                                      learn_rate=learn_rate, iter_tiems=iter_tiems,\r\n                                      error=error, con=con)\r\n        return losserr, preout\r\n\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\xef\xbc\x8c\xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe5\x90\x84\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x8c\r\n\xe4\xbb\xa5\xe5\x8f\x8a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n\'\'\'\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84F1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8b\xe8\xaf\x84\xe5\x88\x86\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\ndef Plot_RMSE_ONE_Blending(exdict, kaudu=0.2):\r\n    \'\'\'\r\n    :param exdict: \xe4\xb8\x8d\xe5\x90\x8c\xe6\xa8\xa1\xe5\x9e\x8bF1\xe5\xba\xa6\xe9\x87\x8f\r\n    :return: \xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    \'\'\'\r\n    # \xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe5\x88\x97\xe8\xa1\xa8\r\n    palist = exdict.keys()\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    trsore = [exdict[hh][0] for hh in palist]\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    tesore = [exdict[hh][1] for hh in palist]\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    presore = [exdict[hh][2] for hh in palist]\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x88\xb6\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    fig, ax = plt.subplots()\r\n    # \xe6\x9f\xb1\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\n    ind = np.array(list(range(len(trsore))))\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x9f\xb1\xe7\x8a\xb6\r\n    ax.bar(ind - kaudu, trsore, kaudu, color=\'SkyBlue\', label=\'\xe8\xae\xad\xe7\xbb\x83\')\r\n    ax.bar(ind, tesore, kaudu, color=\'IndianRed\', label=\'\xe6\xb5\x8b\xe8\xaf\x95\')\r\n    ax.bar(ind + kaudu, presore, kaudu, color=\'slateblue\', label=\'\xe9\xa2\x84\xe6\xb5\x8b\')\r\n    # xy\xe8\xbd\xb4\xe7\x9a\x84\xe6\xa0\x87\xe7\xad\xbe\r\n    ax.set_ylabel(\'f1\xe5\xba\xa6\xe9\x87\x8f\')\r\n    ax.set_xlabel(\'Blending\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\')\r\n    # \xe8\xae\xbe\xe7\xbd\xae\xe5\x88\xbb\xe5\xba\xa6\r\n    ax.set_xticks(ind)\r\n    ax.set_xticklabels(palist)\r\n\r\n    leg = ax.legend(loc=\'best\', ncol=3, shadow=True, fancybox=True)\r\n    leg.get_frame().set_alpha(0.8)\r\n\r\n    plt.title(\'Blending\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\xad\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84f1\xe5\xba\xa6\xe9\x87\x8f\')\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\Blending_adult.jpg\')\r\n    return print(\'\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\x8d\xe5\x90\x8c\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xaf\xb9\xe6\xaf\x94\')\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xef\xbc\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\xaf\xb9\xe6\xaf\x94\xe6\x8a\x98\xe7\xba\xbf\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe4\xb8\x8e\xe4\xb8\xa4\xe5\x80\xbc\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\ndef recspre(yzhenshide):\r\n    plt.figure()\r\n    #  \xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\r\n    plt.plot(list(range(len(yzhenshide))), yzhenshide, lw=2, color=\'blue\', marker=\'*\')\r\n    plt.title(\'\xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\')\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\Blending_duibi.jpg\')\r\n    return \'\xe5\xae\x8c\xe6\xaf\x95\'\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xba\x94\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9aBlending\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\'\'\'\r\n\r\nif __name__ == ""__main__"":\r\n    #  \xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x826\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xef\xbc\x8cAdaBoost\xef\xbc\x8cGBDT\xef\xbc\x8cLightGBM\xef\xbc\x8cXGBoost\xef\xbc\x8cCatBoost\r\n\r\n    # \xe4\xb8\x8b\xe9\x9d\xa2\xe4\xbe\x9d\xe6\xac\xa1\xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xbb\xba\xe7\xab\x8b\xe6\x95\xb0\xe6\x8d\xae\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe3\x80\x81AdaBoost\xef\xbc\x8cGBDT\xef\xbc\x8cLIghtGNM\xef\xbc\x8cXGBoost\xe9\x83\xbd\xe6\x98\xaf\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\r\n    rf_data = DATA()\r\n    rf_data.CAtoDI()  # \xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\r\n    data_rf = rf_data.Kfold()  # \xe6\x8a\x98\xe6\x95\xb0\r\n\r\n\r\n    # CatBoost\r\n    cat_data = DATA()  # \xe4\xb8\x8d\xe7\x94\xa8\xe5\xa4\x84\xe7\x90\x86\r\n    cat_data.TargetoDi()   # \xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\r\n    data_cat = cat_data.Kfold()  # \xe6\x8a\x98\xe6\x95\xb0\r\n\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe5\xbb\xba\xe7\xab\x8bBlending\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\r\n    one_stacking = MODELONE(exdict=rf_data.typedict)\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\r\n    one_stacking.RF_First(data_rf)\r\n    # AdaBoost\r\n    one_stacking.Adaboost_First(data_rf)\r\n    # GBDT\r\n    one_stacking.GBDT_First(data_rf)\r\n    # LightGBM\r\n    one_stacking.LightGBM_First(data_rf)\r\n    # XGBoost\r\n    one_stacking.XGBoost_First(data_rf)\r\n    # CatBoost\r\n    one_stacking.CatBoost_First(data_cat, cat_data.catsign)\r\n\r\n    # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\r\n    one_stacking.DataStru()\r\n    data_two = one_stacking.datai\r\n\r\n    # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\r\n    erce_data = DATA(datadict=data_two)\r\n    erce_data.CAtoDI()  # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe9\x83\xbd\xe6\x98\xaf\xe7\xb1\xbb\xe5\x88\xab\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe6\xa0\x87\xe7\xad\xbe\xe5\x8c\x96\r\n    erce_data.Normal()\r\n    erce_data.k = 0  # # \xe4\xb8\x8d\xe5\x86\x8d\xe8\xae\xbe\xe7\xbd\xae\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    bpdatadict = erce_data.Kfold()\r\n\r\n    # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe5\xbb\xba\xe6\xa8\xa1,\r\n    stacking_two = MODETWO(bpdatadict[\'train\'][:, :-1],\r\n                           np.array([bpdatadict[\'train\'][:, -1]]).T,\r\n                           bpdatadict[\'predict\'][:, :-1])\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc, \xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe8\xbf\xad\xe4\xbb\xa3\xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n    error_acc, preoutput = stacking_two.Lr()\r\n\r\n    #  \xe5\xb0\x86\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe8\xbd\xac\xe5\x8f\x98\xe4\xb8\xba\xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n    bp_out_type = one_stacking.AntiTae(np.array(preoutput).T[0])\r\n    bp_real_type = one_stacking.AntiTae(bpdatadict[\'predict\'][:, -1])\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\xad\xe5\x90\x84\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9b\xbe\r\n    Plot_RMSE_ONE_Blending(one_stacking.error_dict)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe8\xbf\x87\xe7\xa8\x8b\xe4\xb8\xad\xe7\x9a\x84\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe4\xb8\x8b\xe9\x99\x8d\r\n    recspre(error_acc)\r\n    fru = one_stacking.ConfuseMatrix(bp_real_type, bp_out_type)\r\n    print(fru)\r\n    print(one_stacking.F1(bp_real_type, bp_out_type))\r\n\r\n\r\n\r\n'"
Blending/Blending_Regression_pm25.py,5,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe4\xb8\xa4\xe5\xb1\x82\xe7\x9a\x84Blending\xe5\x9b\x9e\xe5\xbd\x92\r\n\r\n#  \xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x827\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xef\xbc\x8cAdaBoost\xef\xbc\x8cGBDT\xef\xbc\x8cLightGBM\xef\xbc\x8cXGBoost\xef\xbc\x8cCatBoost\xef\xbc\x8cBPNN\xe5\x9b\x9e\xe5\xbd\x92\r\n#  \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\r\nimport pm25_Blending_data as pm25\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe7\xbb\x98\xe5\x9b\xbe\xe5\xba\x93\xe5\x8c\x85\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe9\x9c\x80\xe8\xa6\x81\xe7\x94\xa8\xe5\x88\xb0\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\xba\x93\xe5\x8c\x85\r\n# \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\r\nfrom sklearn.ensemble import RandomForestRegressor as RF\r\n# AdaBoost\r\nfrom sklearn.ensemble import AdaBoostRegressor\r\nfrom sklearn.tree import DecisionTreeRegressor\r\n# GBDT\r\nfrom sklearn.ensemble import GradientBoostingRegressor\r\n# XGBoost\r\nimport xgboost as xgb\r\n# LightGBM\r\nimport lightgbm as lgbm\r\n# CatBoost\r\nimport catboost as cb\r\n# BP\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x9b\x9e\xe5\xbd\x92\r\nimport BP_Regression as bp\r\n\r\n# \xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\r\nimport Linear_Regression as linear\r\n\r\n# \xe5\x85\xb6\xe4\xbb\x96\xe5\xba\x93\xe5\x8c\x85\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom collections import OrderedDict  # python\xe5\xad\x97\xe5\x85\xb8\xe6\x98\xaf\xe6\x97\xa0\xe5\xba\x8f\xe7\x9a\x84\xef\xbc\x8c\xe6\xad\xa4\xe5\x8c\x85\xe6\x98\xaf\xe6\x9c\x89\xe5\xba\x8f\xe7\x9a\x84\r\nimport os\r\nos.chdir(r\'E:\\tensorflow_Learn\\Blending\\pm25\')\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe6\xa8\xa1\xe5\x9e\x8b\r\n\'\'\'\r\n\r\nclass DATA:\r\n\r\n    def __init__(self, datadict=pm25.data_dict, mubiao=\'pm2.5\'):\r\n        self.data = datadict\r\n        self.k = 0.3  # \xe5\x9c\xa8Blending\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe6\x89\x80\xe5\x8d\xa0\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\r\n\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n        self.chidata = self.data[\'train\']\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\n        self.nodata = self.data[\'predict\']\r\n\r\n        # \xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\xbc\x96\xe5\x8f\xb7\r\n        self.catsign = self.Sign()\r\n\r\n        # \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\r\n        self.ziduan = mubiao\r\n\r\n        # \xe5\xaf\xb9\xe4\xba\x8e\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x8c\x96\xe5\x92\x8c\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xb0\xe5\xbd\x95\xe8\xbd\xac\xe5\x8c\x96\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe5\xb0\x862\xe8\x80\x85\xe7\xbb\x9f\xe4\xb8\x80\xe3\x80\x82\xe5\x8f\x8d\xe5\xa4\x84\xe7\x90\x86\xe6\x97\xb6\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe9\x9c\x80\xe8\xa6\x81\xe4\xb9\x98\xe4\xbb\xa5self.fenmu \xe5\x8a\xa0\xe4\xb8\x8aself.cha\r\n        self.fenmu = 1  # \xe7\x9b\xb8\xe5\xbd\x93\xe4\xba\x8e\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae, \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xe5\x87\x8f\xe5\x8e\xbb\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\r\n        self.cha = 0   # \xe7\x9b\xb8\xe5\xbd\x93\xe4\xba\x8e\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe7\x9a\x84\xe5\xb9\xb3\xe5\x9d\x87\xe5\x80\xbc, \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe7\x9a\x84\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\r\n\r\n    # \xe5\x9b\xa0\xe4\xb8\xba\xe5\xaf\xb9\xe4\xba\x8eCatBoost\xe8\x80\x8c\xe8\xa8\x80\xef\xbc\x8c\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe9\x9c\x80\xe8\xa6\x81\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe6\xa0\x87\xe5\x8f\xb7\r\n    def Sign(self):\r\n        sign = []\r\n        numlist = self.chidata.values[0][: -1]  # \xe4\xb8\x8d\xe5\x8c\x85\xe6\x8b\xac\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\r\n        for jj in range(len(numlist)):\r\n            try:\r\n                numlist[jj] + 9\r\n            except TypeError:\r\n                sign.append(jj)\r\n        return sign\r\n\r\n    # \xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe5\xad\x97\xe6\xa0\x87\xe7\xad\xbe\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\r\n    def CAtoDI(self):\r\n        # \xe5\xa6\x82\xe6\x9e\x9c\xe7\x89\xb9\xe5\xbe\x81\xe5\x80\xbc\xe4\xb8\x8d\xe8\x83\xbd\xe6\x89\xa7\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe5\x8a\xa0\xe6\xb3\x95\xe8\xbf\x90\xe7\xae\x97\xef\xbc\x8c\xe5\x88\x99\xe8\xa7\x86\xe4\xb8\xba\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\r\n        for tezheng in self.chidata:\r\n            try:\r\n                self.chidata[tezheng].values[0] + 1\r\n            except TypeError:\r\n                numlist = sorted(list(set(list(self.chidata[tezheng]))))\r\n                self.chidata[tezheng] = [numlist.index(hh) for hh in self.chidata[tezheng]]\r\n                try:\r\n                    self.nodata[tezheng] = [numlist.index(ss) for ss in self.nodata[tezheng]]\r\n                except ValueError:\r\n                    print(\'\xe7\x89\xb9\xe5\xbe\x81%s\xef\xbc\x9a\xe9\xa2\x84\xe6\xb5\x8b\xe6\xaf\x94\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xa4\x9a\xe4\xba\x86\xe5\x80\xbc\' % (tezheng))\r\n        return print(\'\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe5\xaf\xb9\xe4\xba\x8e\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x92\x8c\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xb0\xe5\xbd\x95\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe7\x9a\x84\xe8\xbd\xac\xe5\x8c\x96\xe5\x80\xbc\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x8f\x8d\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\r\n\r\n    # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\r\n    def Normal(self):\r\n        # \xe5\x9c\xa8\xe6\xad\xa4\xe4\xb9\x8b\xe5\x89\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\x8a\x8a\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe6\xa0\x87\xe7\xad\xbe\xe5\x8e\xbb\xe6\x8e\x89,\xe5\x90\xa6\xe5\x88\x99\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99\r\n        for tezheng in self.chidata:\r\n            maxnum = max(list(self.chidata[tezheng]))\r\n            minum = min(list(self.chidata[tezheng]))\r\n            if maxnum == minum:\r\n                self.chidata[tezheng] = [1 for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [1 for ss in self.nodata[tezheng]]\r\n            else:\r\n                self.chidata[tezheng] = [(hh - minum) / (maxnum - minum) for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [(ss - minum) / (maxnum - minum) for ss in self.nodata[tezheng]]\r\n                if tezheng == self.ziduan:\r\n                    self.fenmu = maxnum - minum\r\n                    self.cha = minum\r\n        return print(\'\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\r\n    def Stand(self):\r\n        # \xe5\x9c\xa8\xe6\xad\xa4\xe4\xb9\x8b\xe5\x89\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\x8a\x8a\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe6\xa0\x87\xe7\xad\xbe\xe5\x8e\xbb\xe6\x8e\x89,\xe5\x90\xa6\xe5\x88\x99\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99\r\n        for tezheng in self.chidata:\r\n            standnum = np.std(np.array(list(self.chidata[tezheng])), ddof=1)  # \xe8\xae\xa1\xe7\xae\x97\xe6\x9c\x89\xe5\x81\x8f\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\r\n            meanum = np.mean(np.array(list(self.chidata[tezheng])))\r\n\r\n            if meanum == 0:\r\n                self.chidata[tezheng] = [1 for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [1 for ss in self.nodata[tezheng]]\r\n            else:\r\n                self.chidata[tezheng] = [(hh - standnum) / meanum for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [(ss - standnum) / meanum for ss in self.nodata[tezheng]]\r\n                if tezheng == self.ziduan:\r\n                    self.fenmu = standnum\r\n                    self.cha = meanum\r\n        return print(\'\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe6\x8c\x89\xe7\x85\xa7\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b,\xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe4\xb8\xba\xe9\xaa\x8c\xe8\xaf\x81\xe5\x92\x8c\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    def Kfold(self):\r\n        # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe4\xbf\x9d\xe8\xaf\x81\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe6\x98\xaf\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\xef\xbc\x8c\r\n        datanum = self.chidata.values\r\n        # \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n        length = len(datanum)\r\n        alist = np.arange(length)\r\n        np.random.seed(1990)\r\n        np.random.shuffle(alist)  # \xe9\x9a\x8f\xe6\x9c\xba\xe6\x89\x93\xe4\xb9\xb1\xe6\x95\xb0\xe6\x8d\xae\xe5\xaf\xb9BPNN,SVM\xe8\x80\x8c\xe8\xa8\x80\xe6\x98\xaf\xe6\x9c\x89\xe7\x9b\x8a\xe5\xa4\x84\xe7\x9a\x84\xef\xbc\x8c\xe8\x80\x8c\xe5\xaf\xb9\xe4\xba\x8e\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe4\xb9\x8b\xe7\xb1\xbb\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe8\x80\x8c\xe8\xa8\x80\xe6\xb2\xa1\xe6\x9c\x89\xe5\xbd\xb1\xe5\x93\x8d\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\r\n        yanlem = int(length * self.k)\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        datai = {}\r\n        datai[\'predict\'] = self.nodata.values\r\n\r\n        # \xe9\x80\x89\xe4\xb8\xad\xe7\x9a\x84\xe4\xbd\x9c\xe4\xb8\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xb4\xa2\xe5\xbc\x95\xe5\xba\x8f\xe5\x88\x97\r\n        np.random.seed(2000)\r\n        yanlis = np.random.choice(alist, yanlem, replace=False)\r\n\r\n        # \xe6\xb2\xa1\xe6\x9c\x89\xe8\xa2\xab\xe9\x80\x89\xe4\xb8\xad\xe7\x9a\x84\xe4\xbd\x9c\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xb4\xa2\xe5\xbc\x95\xe5\xba\x8f\xe5\x88\x97\r\n        trainlis = [ki for ki in alist if ki not in yanlis]\r\n\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n        datai[\'train\'] = datanum[trainlis]\r\n\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n        datai[\'test\'] = datanum[yanlis]\r\n\r\n        # \xe8\xbf\x94\xe5\x9b\x9e\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\xbd\xa2\xe5\xbc\x8f{\'train\':data, \'test\':data, \'predict\':data}\r\n        print(\'\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe5\x89\xb2\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n        return datai\r\n\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xbf\x90\xe8\xa1\x8c\xe9\x98\xb6\xe6\xae\xb5\r\n\'\'\'\r\n# \xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbb\xbb\xe6\x84\x8f\xe6\xb7\xbb\xe5\x8a\xa0\xe6\xa8\xa1\xe5\x9e\x8b\r\nclass MODELONE:\r\n\r\n    def __init__(self, fenmu, cha, zidan=\'pm2.5\'):\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_pr = []\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.predi = []\r\n\r\n        # \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\xe7\xa7\xb0\r\n        self.zi = zidan\r\n\r\n        # \xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe5\x92\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe7\xb1\xbb\xe7\x9a\x84\xe4\xbf\x9d\xe6\x8c\x81\xe4\xb8\x80\xe8\x87\xb4\xef\xbc\x8c\xe8\xa6\x81\xe6\x8a\x8a\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x90\x88\xe4\xba\x8c\xe4\xb8\xba\xe4\xb8\x80\r\n        self.datai = {}\r\n\r\n        # \xe8\xae\xb0\xe5\xbd\x95\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x9c\x80\xe7\xbb\x88\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        self.error_dict = OrderedDict()\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_real = []\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.preal = []\r\n\r\n        #  \xe9\x92\x88\xe5\xaf\xb9BPnn\xef\xbc\x8c\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe6\x95\xb0\xe6\x8d\xae\xe8\xa6\x81\xe5\x8f\x8d\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\r\n        self.fen = fenmu\r\n        self.cha = cha\r\n\r\n    # \xe5\xb0\x86\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba\xe4\xbd\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe5\xa4\x84\xe7\x90\x86\xe7\xb1\xbb\xe4\xb8\xad\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    #  \xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf{\'train\':dataframe, \'predict\':dataframe}\xe6\xa0\xb7\xe5\xbc\x8f\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    def DataStru(self):\r\n        self.datai[\'train\'] = np.row_stack((np.array(self.yanzhneg_pr), np.array(self.yanzhneg_real)))  # \xe6\xad\xa4\xe5\xa4\x84\xe6\xb7\xbb\xe5\x8a\xa0\xe8\xa1\x8c\r\n        self.datai[\'predict\'] = np.row_stack((np.array(self.predi), np.array(self.preal)))\r\n        # \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe7\xbd\xae\r\n        datapst = self.datai[\'train\'].T\r\n        # \xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xae\x9a\xe4\xb9\x89DataFrame\xe7\x9a\x84\xe5\x88\x97\xe5\x90\x8d\r\n        mingcheng = [\'\xe7\xac\xac%s\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x88\x97\' % str(dd) for dd in list(range(len(self.datai[\'train\']) - 1))] + [self.zi]\r\n        self.datai[\'train\'] = pd.DataFrame(datapst, columns=mingcheng)\r\n\r\n        # \xe5\xb0\x86\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe7\xbd\xae\r\n        dapst = self.datai[\'predict\'].T\r\n        # \xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xae\x9a\xe4\xb9\x89DataFrame\xe7\x9a\x84\xe5\x88\x97\xe5\x90\x8d\r\n        mingche= [\'\xe7\xac\xac%s\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x88\x97\' % str(dd) for dd in list(range(len(self.datai[\'predict\']) - 1))] + [self.zi]\r\n        self.datai[\'predict\'] = pd.DataFrame(dapst, columns=mingche)\r\n        return print(\'\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe5\xae\x9a\xe4\xb9\x89\xe5\x9d\x87\xe6\x96\xb9\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def RMSE(self, data1, data2):\r\n        data1, data2 = np.array(data1), np.array(data2)\r\n        subdata = np.power(data1 - data2, 2)\r\n        return np.sqrt(np.sum(subdata) / len(subdata - 1))\r\n\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\r\n    def RF_First(self, data, n_estimators=400, max_features=\'auto\'):\r\n        # \xe5\xaf\xb9\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe8\xbf\x94\xe5\x9b\x9e\xe6\xa8\xa1\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        model = RF(n_estimators=n_estimators, max_features=max_features)\r\n        model.fit(data[\'train\'][:, :-1], data[\'train\'][:, -1])\r\n        # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        xul = model.predict(data[\'train\'][:, :-1])\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanre = model.predict(data[\'test\'][:, :-1])\r\n        #\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prer = model.predict(data[\'predict\'][:, :-1])\r\n        # \xe5\x82\xa8\xe5\xad\x98\r\n        self.yanzhneg_pr.append(yanre)\r\n        self.predi.append(prer)\r\n        # \xe5\x88\x86\xe5\x88\xab\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        xx = self.RMSE(xul, data[\'train\'][:, -1])\r\n        yy = self.RMSE(yanre, data[\'test\'][:, -1])\r\n        pp = self.RMSE(prer, data[\'predict\'][:, -1])\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\'] = [xx, yy, pp]\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_real = data[\'test\'][:, -1]\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.preal = data[\'predict\'][:, -1]\r\n\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # AdaBoost\r\n    def Adaboost_First(self, data, max_depth=5, n_estimators=320):\r\n        model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=max_depth),\r\n                                  n_estimators=n_estimators, learning_rate=0.8)\r\n        model.fit(data[\'train\'][:, :-1], data[\'train\'][:, -1])\r\n        # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        xul = model.predict(data[\'train\'][:, :-1])\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanre = model.predict(data[\'test\'][:, :-1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prer = model.predict(data[\'predict\'][:, :-1])\r\n        # \xe5\x82\xa8\xe5\xad\x98\r\n        self.yanzhneg_pr.append(yanre)\r\n        self.predi.append(prer)\r\n        # \xe5\x88\x86\xe5\x88\xab\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        xx = self.RMSE(xul, data[\'train\'][:, -1])\r\n        yy = self.RMSE(yanre, data[\'test\'][:, -1])\r\n        pp = self.RMSE(prer, data[\'predict\'][:, -1])\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'AdaBoost\'] = [xx, yy, pp]\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_real = data[\'test\'][:, -1]\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.preal = data[\'predict\'][:, -1]\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84AdaBoost\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # GBDT\r\n    def GBDT_First(self, data, max_depth=17, n_estimators=57):\r\n        model = GradientBoostingRegressor(loss=\'ls\', n_estimators=n_estimators, max_depth=max_depth,\r\n                                          learning_rate=0.12, subsample=0.8)\r\n        model.fit(data[\'train\'][:, :-1], data[\'train\'][:, -1])\r\n        # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        xul = model.predict(data[\'train\'][:, :-1])\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanre = model.predict(data[\'test\'][:, :-1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prer = model.predict(data[\'predict\'][:, :-1])\r\n        # \xe5\x82\xa8\xe5\xad\x98\r\n        self.yanzhneg_pr.append(yanre)\r\n        self.predi.append(prer)\r\n        # \xe5\x88\x86\xe5\x88\xab\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        xx = self.RMSE(xul, data[\'train\'][:, -1])\r\n        yy = self.RMSE(yanre, data[\'test\'][:, -1])\r\n        pp = self.RMSE(prer, data[\'predict\'][:, -1])\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'GBDT\'] = [xx, yy, pp]\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_real = data[\'test\'][:, -1]\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.preal = data[\'predict\'][:, -1]\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84GBDT\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # LightGBM\r\n    def LightGBM_First(self, data, max_depth=9, n_estimators=380):\r\n        model = lgbm.LGBMRegressor(boosting_type=\'gbdt\', objective=\'regression\', num_leaves=1200,\r\n                                   learning_rate=0.17, n_estimators=n_estimators, max_depth=max_depth,\r\n                                   metric=\'rmse\', bagging_fraction=0.8, feature_fraction=0.8, reg_lambda=0.9)\r\n        model.fit(data[\'train\'][:, :-1], data[\'train\'][:, -1])\r\n        # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        xul = model.predict(data[\'train\'][:, :-1])\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanre = model.predict(data[\'test\'][:, :-1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prer = model.predict(data[\'predict\'][:, :-1])\r\n        # \xe5\x82\xa8\xe5\xad\x98\r\n        self.yanzhneg_pr.append(yanre)\r\n        self.predi.append(prer)\r\n        # \xe5\x88\x86\xe5\x88\xab\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        xx = self.RMSE(xul, data[\'train\'][:, -1])\r\n        yy = self.RMSE(yanre, data[\'test\'][:, -1])\r\n        pp = self.RMSE(prer, data[\'predict\'][:, -1])\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'LightGBM\'] = [xx, yy, pp]\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_real = data[\'test\'][:, -1]\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.preal = data[\'predict\'][:, -1]\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84LightGBM\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # XGBoost\r\n    def XGBoost_First(self, data, max_depth=5, n_estimators=320):\r\n        model = xgb.XGBRegressor(max_depth=max_depth, learning_rate=0.1, n_estimators=n_estimators,\r\n                                 silent=True, objective=\'reg:gamma\')\r\n        model.fit(data[\'train\'][:, :-1], data[\'train\'][:, -1])\r\n        # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        xul = model.predict(data[\'train\'][:, :-1])\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanre = model.predict(data[\'test\'][:, :-1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prer = model.predict(data[\'predict\'][:, :-1])\r\n        # \xe5\x82\xa8\xe5\xad\x98\r\n        self.yanzhneg_pr.append(yanre)\r\n        self.predi.append(prer)\r\n        # \xe5\x88\x86\xe5\x88\xab\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        xx = self.RMSE(xul, data[\'train\'][:, -1])\r\n        yy = self.RMSE(yanre, data[\'test\'][:, -1])\r\n        pp = self.RMSE(prer, data[\'predict\'][:, -1])\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'XGBoost\'] = [xx, yy, pp]\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_real = data[\'test\'][:, -1]\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.preal = data[\'predict\'][:, -1]\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84XGBoost\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # CatBoost\r\n    def CatBoost_First(self, data, catsign, depth=8, iterations=80000):\r\n        model = cb.CatBoostRegressor(iterations=iterations, depth=depth, learning_rate=0.8, loss_function=\'RMSE\')\r\n        model.fit(data[\'train\'][:, :-1], data[\'train\'][:, -1], cat_features=catsign)\r\n        # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        xul = model.predict(data[\'train\'][:, :-1])\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanre = model.predict(data[\'test\'][:, :-1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prer = model.predict(data[\'predict\'][:, :-1])\r\n        # \xe5\x82\xa8\xe5\xad\x98\r\n        self.yanzhneg_pr.append(yanre)\r\n        self.predi.append(prer)\r\n        # \xe5\x88\x86\xe5\x88\xab\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        xx = self.RMSE(xul, data[\'train\'][:, -1])\r\n        yy = self.RMSE(yanre, data[\'test\'][:, -1])\r\n        pp = self.RMSE(prer, data[\'predict\'][:, -1])\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'CatBoost\'] = [xx, yy, pp]\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_real = data[\'test\'][:, -1]\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.preal = data[\'predict\'][:, -1]\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84CatBoost\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n\r\n    # BPNN\xe5\x9b\x9e\xe5\xbd\x92\r\n    def BPnn(self, data, hiddenlayers=3, hiddennodes=100, learn_rate=0.05, itertimes=10000,\r\n             batch_size=200, activate_func=\'sigmoid\', break_error=0.00000043):\r\n        sign, fir, trer, ader = bp.Ten_train(data[\'train\'][:, :-1], np.array([data[\'train\'][:, -1]]).T,\r\n                                 data[\'test\'][:, :-1], np.array([data[\'test\'][:, -1]]).T,\r\n                                 hiddenlayers=hiddenlayers, hiddennodes=hiddennodes,\r\n                                 learn_rate=learn_rate, itertimes=itertimes,\r\n                                 batch_size=batch_size, activate_func=activate_func,\r\n                                 break_error=break_error)\r\n\r\n        # \xe8\xbf\x99\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9c\xa8\xe5\x90\x8e\xe6\x96\x87\xe6\xb7\xbb\xe5\x8a\xa0\xe4\xb8\x8a\r\n        return sign, fir, trer, ader\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xbf\x90\xe8\xa1\x8c\xe9\x98\xb6\xe6\xae\xb5 \xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbb\xbb\xe6\x84\x8f\xe6\x9b\xb4\xe6\x8d\xa2\xe6\xa8\xa1\xe5\x9e\x8b\r\n\'\'\'\r\nclass MODETWO:\r\n\r\n    def __init__(self, in_tr_data, out_tr_data, in_pre_data):\r\n        self.xdata = in_tr_data\r\n        self.ydata = out_tr_data\r\n\r\n        self.in_pre_data = in_pre_data\r\n\r\n\r\n    # \xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\r\n    def Lin_Gr(self, learn_rate=0.00000003, iter_times=80000, error=1e-9):\r\n        model = linear.LinearRegression(learn_rate=learn_rate, iter_times=iter_times, error=error)\r\n        # \xe4\xb8\xa4\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\r\n        model.Gradient(self.xdata, self.ydata)\r\n        outpre = model.predict(self.in_pre_data)\r\n        return outpre\r\n\r\n    # \xe5\x85\xac\xe5\xbc\x8f\xe6\xb3\x95\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\r\n    def Lin_Fo(self):\r\n        model = linear.LinearRegression()\r\n        # \xe4\xb8\xa4\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\r\n        model.Formula(self.xdata, self.ydata)\r\n        outpre = model.predict(self.in_pre_data)\r\n        return outpre\r\n\r\n\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\xef\xbc\x8c\xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe5\x90\x84\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x8c\r\n\xe4\xbb\xa5\xe5\x8f\x8a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n\'\'\'\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8b\xe8\xaf\x84\xe5\x88\x86\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\ndef Plot_RMSE_ONE_Blending(exdict, kaudu=0.2):\r\n    \'\'\'\r\n    :param exdict: \xe4\xb8\x8d\xe5\x90\x8c\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84RMSE \xe6\x9c\x80\xe5\xb0\x8f\xe4\xba\x8c\xe4\xb9\x98\xe5\x9b\x9e\xe5\xbd\x92\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\xb9\xb3\xe6\x96\xb9\xe6\xa0\xb9\r\n    :return: \xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    \'\'\'\r\n    # \xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe5\x88\x97\xe8\xa1\xa8\r\n    palist = exdict.keys()\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    trsore = [exdict[hh][0] for hh in palist]\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    tesore = [exdict[hh][1] for hh in palist]\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    presore = [exdict[hh][2] for hh in palist]\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x88\xb6\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    fig, ax = plt.subplots()\r\n    # \xe6\x9f\xb1\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\n    ind = np.array(list(range(len(trsore))))\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x9f\xb1\xe7\x8a\xb6\r\n    ax.bar(ind - kaudu, trsore, kaudu, color=\'SkyBlue\', label=\'\xe8\xae\xad\xe7\xbb\x83\')\r\n    ax.bar(ind, tesore, kaudu, color=\'IndianRed\', label=\'\xe6\xb5\x8b\xe8\xaf\x95\')\r\n    ax.bar(ind + kaudu, presore, kaudu, color=\'slateblue\', label=\'\xe9\xa2\x84\xe6\xb5\x8b\')\r\n    # xy\xe8\xbd\xb4\xe7\x9a\x84\xe6\xa0\x87\xe7\xad\xbe\r\n    ax.set_ylabel(\'RMSE\')\r\n    ax.set_xlabel(\'Blending\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\')\r\n    # \xe8\xae\xbe\xe7\xbd\xae\xe5\x88\xbb\xe5\xba\xa6\r\n    ax.set_xticks(ind)\r\n    ax.set_xticklabels(palist)\r\n\r\n    ax.grid()\r\n\r\n    leg = ax.legend(loc=\'best\', ncol=3, shadow=True, fancybox=True)\r\n    leg.get_frame().set_alpha(0.8)\r\n    plt.title(\'Blending\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\xad\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84RMSE\')\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\Blending_pm25.jpg\')\r\n    return \'\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\x8d\xe5\x90\x8c\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xaf\xb9\xe6\xaf\x94\'\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n# \xe6\x8c\x89\xe7\x85\xa7\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\xe4\xbb\x8e\xe5\xb0\x8f\xe5\x88\xb0\xe5\xa4\xa7\xe6\x8e\x92\xe5\x88\x97\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\ndef Pailie(realr, modelout, count=90):\r\n    \'\'\'\r\n    :param real: \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    :param modelout: \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc\r\n    :param count: \xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\xaf\xb9\xe6\xaf\x94\xe7\x9a\x84\xe6\x9d\xa1\xe6\x95\xb0\r\n    :return: \xe6\x8c\x89\xe7\x85\xa7\xe5\xb7\xae\xe5\x80\xbc\xe4\xbb\x8e\xe5\xb0\x8f\xe5\x88\xb0\xe5\xa4\xa7\xe6\x8e\x92\xe5\x88\x97\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    \'\'\'\r\n    relal_num = np.array(realr)\r\n    modelout_num = np.array(modelout)\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96\r\n    np.random.seed(200)\r\n    fu = np.random.choice(list(range(len(realr))), count, replace=False)\r\n    show_real, show_model = relal_num[fu], modelout_num[fu]\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe5\xb7\xae\xe5\x80\xbc\r\n    sunnum = show_real - show_model\r\n    # \xe9\xa6\x96\xe5\x85\x88\xe7\xbb\x84\xe5\x90\x88\xe4\xb8\x89\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x97\xe8\xa1\xa8\xe4\xb8\xba\xe5\xad\x97\xe5\x85\xb8\r\n    zuhedict = {ii: [show_real[ii], show_model[ii], sunnum[ii]] for ii in range(len(show_model))}\r\n    # \xe5\xad\x97\xe5\x85\xb8\xe6\x8c\x89\xe7\x9d\x80\xe5\x80\xbc\xe6\x8e\x92\xe5\xba\x8f\r\n    zhenshi = []\r\n    yucede = []\r\n    chazhi = []\r\n    # \xe6\x8c\x89\xe7\x9d\x80\xe5\xb7\xae\xe5\x80\xbc\xe4\xbb\x8e\xe5\xa4\xa7\xe5\x88\xb0\xe5\xb0\x8f\r\n    for jj in sorted(zuhedict.items(), key=lambda gy: gy[1][2]):\r\n        zhenshi.append(jj[1][0])\r\n        yucede.append(jj[1][1])\r\n        chazhi.append(jj[1][2])\r\n    return zhenshi, yucede, chazhi\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xef\xbc\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\xaf\xb9\xe6\xaf\x94\xe6\x8a\x98\xe7\xba\xbf\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe4\xb8\x8e\xe4\xb8\xa4\xe5\x80\xbc\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\ndef recspre(yzhenshide, yyucede, title=\'\xe5\x85\xac\xe5\xbc\x8f\xe6\xb3\x95\'):\r\n    #  \xe8\x8e\xb7\xe5\xbe\x97\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    yreal, ypre, cha = Pailie(yzhenshide, yyucede)\r\n    plt.figure()\r\n    ax = plt.subplot(111)\r\n    plt.grid()\r\n    dign = np.arange(len(yreal))\r\n    #  \xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\r\n    ax.scatter(dign, yreal, label=\'\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\', lw=2, color=\'blue\', marker=\'*\')\r\n    #  \xe7\xbb\x98\xe5\x88\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    ax.plot(dign, ypre, label=\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\', lw=2, color=\'red\', linestyle=\'--\', marker=\'.\')\r\n    #  \xe7\xbb\x98\xe5\x88\xb6\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    ax.bar(dign, cha, 0.1, label=\'\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x87\x8f\xe5\x8e\xbb\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\', color=\'k\')\r\n    # \xe7\xbb\x98\xe5\x88\xb60\xe7\xba\xbf\r\n    ax.plot(dign, [0] * len(dign), lw=2, color=\'k\')\r\n\r\n    ax.set_ylim((int(min(cha)) - 1, int(max([max(yreal), max(ypre)]))))\r\n    ax.set_xlim((0, len(dign)))\r\n\r\n    ax.legend(loc=\'best\')\r\n    ax.set_title(\'%s:\xe5\x8c\x97\xe4\xba\xac\xe5\xb8\x82Pm2.5\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94\' % title)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\Blending_duibi_%s.jpg\' % title)\r\n\r\n    return \'\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xba\x94\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9aBlending\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\'\'\'\r\n\r\nif __name__ == ""__main__"":\r\n    #  \xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x827\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xef\xbc\x8cAdaBoost\xef\xbc\x8cGBDT\xef\xbc\x8cLightGBM\xef\xbc\x8cXGBoost\xef\xbc\x8cCatBoost\xef\xbc\x8cBPNN\r\n\r\n    # \xe4\xb8\x8b\xe9\x9d\xa2\xe4\xbe\x9d\xe6\xac\xa1\xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xbb\xba\xe7\xab\x8b\xe6\x95\xb0\xe6\x8d\xae\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe3\x80\x81AdaBoost\xef\xbc\x8cGBDT\xef\xbc\x8cLIghtGNM\xef\xbc\x8cXGBoost\xe9\x83\xbd\xe6\x98\xaf\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\r\n    rf_data = DATA()\r\n    rf_data.CAtoDI()  # \xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\r\n    data_rf = rf_data.Kfold()  # \xe5\x88\x86\xe5\x89\xb2\xe6\x95\xb0\xe6\x8d\xae\r\n\r\n    # CatBoost\r\n    cat_data = DATA()  # \xe4\xb8\x8d\xe7\x94\xa8\xe5\xa4\x84\xe7\x90\x86\r\n    data_cat = cat_data.Kfold()  # \xe5\x88\x86\xe5\x89\xb2\xe6\x95\xb0\xe6\x8d\xae\r\n\r\n\r\n    # BPnn\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\r\n    bp_data = DATA()\r\n    bp_data.CAtoDI()  # \xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\r\n    bp_data.Stand()   # \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\n    data_bp = bp_data.Kfold()  # \xe5\x88\x86\xe5\x89\xb2\xe6\x95\xb0\xe6\x8d\xae\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe5\xbb\xba\xe7\xab\x8bBlending\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\r\n    one_stacking = MODELONE(bp_data.fenmu, bp_data.cha)\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\r\n    one_stacking.RF_First(data_rf)\r\n    # AdaBoost\r\n    one_stacking.Adaboost_First(data_rf)\r\n    # GBDT\r\n    one_stacking.GBDT_First(data_rf)\r\n    # LightGBM\r\n    one_stacking.LightGBM_First(data_rf)\r\n    # XGBoost\r\n    one_stacking.XGBoost_First(data_rf)\r\n    # CatBoost\r\n    one_stacking.CatBoost_First(data_cat, cat_data.catsign)\r\n\r\n    # BPnn\r\n    signi, gir, trarm, adder = one_stacking.BPnn(data_bp)\r\n    # \xe6\xad\xa4\xe5\xa4\x84\xe8\xa6\x81\xe4\xb8\x8b\xe8\xbd\xbd\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84BPnn\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n    # \xe8\xae\xad\xe7\xbb\x83\xe5\xae\x8c\xe6\x88\x90\xe5\x90\x8e\xe8\xaf\xbb\xe5\x8f\x96\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe5\x9c\xa8\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n    graph = tf.train.import_meta_graph(""./pm25-%s.meta"" % signi)\r\n    ses = tf.Session()\r\n    graph.restore(ses, tf.train.latest_checkpoint(\'./\'))\r\n    op_to_restore = tf.get_default_graph().get_tensor_by_name(""Sigmoid_%s:0"" % gir)  # \xe8\xbf\x99\xe4\xb8\xaatensor\xe7\x9a\x84\xe5\x90\x8d\xe7\xa7\xb0\xe5\x92\x8c\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\xe6\x9c\x89\xe5\x85\xb3\xe7\xb3\xbb\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe5\x8e\xbbBP\xe7\x9a\x84\xe7\xa8\x8b\xe5\xba\x8f\xe4\xb8\xad\xe8\x8e\xb7\xe5\xbe\x97\r\n    w1 = tf.get_default_graph().get_tensor_by_name(""x_data:0"")\r\n    feed_dict = {w1: data_bp[\'predict\'][:, :-1]}\r\n    dgsio = ses.run(op_to_restore, feed_dict)\r\n\r\n    preout = bp_data.fenmu * dgsio.T[0] + bp_data.cha\r\n\r\n    # \xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe9\x9c\x80\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n    prerror = one_stacking.RMSE(preout, data_bp[\'predict\'][:, -1] * bp_data.fenmu + bp_data.cha)\r\n\r\n    one_stacking.error_dict[\'BPNN\'] = [trarm * bp_data.fenmu, adder * bp_data.fenmu, prerror]  # \xe5\x9b\xa0\xe4\xb8\xbaBPNN\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe6\x98\xaf\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\xad\xe5\x90\x84\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9b\xbe\r\n    Plot_RMSE_ONE_Blending(one_stacking.error_dict)\r\n\r\n    feed_dict_add = {w1: data_bp[\'test\'][:, :-1]}\r\n    dgsio_add = ses.run(op_to_restore, feed_dict_add)\r\n    adderout = bp_data.fenmu * dgsio_add.T[0] + bp_data.cha\r\n\r\n    # \xe6\xb7\xbb\xe5\x8a\xa0BPNN\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\x93\xe6\x9e\x9c\r\n    one_stacking.yanzhneg_pr.append(adderout)\r\n    one_stacking.predi.append(preout)\r\n\r\n\r\n    # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\r\n    one_stacking.DataStru()\r\n    data_two = one_stacking.datai\r\n\r\n    # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\r\n    erce_data = DATA(datadict=data_two)\r\n    #  \xe5\x9b\xa0\xe4\xb8\xba\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe6\x98\xaf\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x8f\x96\xe5\x88\xb0\xe6\x9c\x80\xe4\xbc\x98\xe5\x80\xbc\xe7\x9a\x84\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe5\x9c\xa8\xe9\x87\x8c\xe4\xb8\x8d\xe5\x9c\xa8\xe8\xae\xbe\xe7\xbd\xae\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    erce_data.k = 0\r\n    redata = erce_data.Kfold()\r\n\r\n    # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe5\xbb\xba\xe6\xa8\xa1\r\n    stacking_two = MODETWO(np.array(redata[\'train\'][:, :-1]),\r\n                           np.array([redata[\'train\'][:, -1]]).T,\r\n                           np.array(redata[\'predict\'][:, :-1]))\r\n\r\n    # \xe4\xb8\xa4\xe7\xa7\x8d\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe7\x9a\x84\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92:\xe5\x85\xac\xe5\xbc\x8f\xe6\xb3\x95\r\n    outlist_Fo = stacking_two.Lin_Fo()\r\n\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\n    recspre(redata[\'predict\'][:, -1], outlist_Fo.T[0], title=\'\xe5\x85\xac\xe5\xbc\x8f\xe6\xb3\x95\')\r\n\r\n\r\n    # \xe4\xb8\xa4\xe7\xa7\x8d\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe7\x9a\x84\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92:\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\r\n    outlist_Gr = stacking_two.Lin_Gr()\r\n\r\n\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\n    recspre(redata[\'predict\'][:, -1], outlist_Gr.T[0], title=\'\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\')\r\n'"
Blending/LR.py,16,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport tensorflow as tf\r\nsess = tf.Session()\r\n\r\n# \xe6\x9e\x84\xe5\xbb\xba\xe5\x87\xbd\xe6\x95\xb0\r\ndef trans_tf(datax, datay, prea, learn_rate=0.5, iter_tiems=40000, error=1e-9, con='L2'):\r\n    # \xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\r\n    x_data = tf.placeholder(shape=[None, len(datax[0])], dtype=tf.float32)\r\n    y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\r\n    # \xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe5\x8f\x82\xe6\x95\xb0\r\n    Weight = tf.Variable(tf.random_normal(shape=[len(datax[0]), 1]), dtype=tf.float32)\r\n    Bias = tf.Variable(tf.random_normal(shape=[1, 1]), dtype=tf.float32)\r\n\r\n    model_output = tf.add(tf.matmul(x_data, Weight), Bias)\r\n\r\n    tf.add_to_collection(tf.GraphKeys.WEIGHTS, Weight)\r\n    regularizer = tf.contrib.layers.l2_regularizer(scale=2 / 2000)\r\n    reg_term = tf.contrib.layers.apply_regularization(regularizer)\r\n\r\n    # \xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\r\n    if con == 'L2':\r\n        # \xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\r\n        costfunc = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output, labels=y_target)) + reg_term\r\n    else:\r\n        costfunc = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output, labels=y_target))\r\n\r\n    # \xe5\x88\xa9\xe7\x94\xa8\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\r\n    #optimizer = tf.train.GradientDescentOptimizer(learn_rate) # \xe6\xa2\xaf\xe5\xba\xa6\r\n    #optimizer = tf.train.MomentumOptimizer(learning_rate=learn_rate, momentum=0.9) # \xe5\x8a\xa8\xe9\x87\x8f\xe6\xb3\x95\r\n    #optimizer = tf.train.AdadeltaOptimizer(learning_rate=learn_rate, rho=0.55, epsilon=1e-08)\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=learn_rate, beta1=0.9, beta2=0.99, epsilon=1e-08)\r\n    trainstep = optimizer.minimize(costfunc)\r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n\r\n    loss_vec = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n    for i in range(iter_tiems):\r\n        sess.run(trainstep, feed_dict={x_data: datax, y_target: datay})\r\n        temp_loss = sess.run(costfunc, feed_dict={x_data: datax, y_target: datay})\r\n        loss_vec.append(temp_loss)\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\r\n        if len(loss_vec) > 2:\r\n            if loss_vec[-2] - loss_vec[-1] >= 0 and (loss_vec[-2] - loss_vec[-1]) <= error:\r\n                break\r\n\r\n    predata = sess.run(model_output, feed_dict={x_data: prea})\r\n\r\n    #\xe8\xbd\xac\xe5\x8c\x96\r\n    trans_predata = [[1] if jj[0] >= 0 else [0] for jj in predata]\r\n\r\n    return loss_vec, trans_predata\r\n"""
Blending/Linear_Regression.py,0,"b'#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe6\xa8\xa1\xe5\x9e\x8b\r\nimport numpy as np\r\n\r\n\r\n#\xe5\x88\x9b\xe5\xbb\xba\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe7\xb1\xbb\r\nclass LinearRegression:\r\n    #w\xe5\x92\x8cb\xe5\x90\x88\xe4\xb8\xba\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xafx\xe6\x9c\x80\xe5\x90\x8e\xe5\x8a\xa0\xe4\xb8\x8a\xe4\xb8\x80\xe5\x88\x97\xe5\x85\xa8\xe4\xb8\xba1\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n\r\n    def __init__(self, learn_rate=0.0000002, iter_times=200000, error=1e-9):\r\n        self.learn_rate = learn_rate\r\n        self.iter_times = iter_times\r\n        self.error = error\r\n\r\n    def Trans(self, xdata):\r\n        one1 = np.ones(len(xdata))\r\n        xta = np.append(xdata, one1.reshape(-1, 1), axis=1)\r\n        return xta\r\n\r\n    #\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\r\n    def Gradient(self, xdata, ydata):\r\n        xdata = self.Trans(xdata)\r\n        #\xe7\xb3\xbb\xe6\x95\xb0w,b\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n        self.weights = np.zeros((len(xdata[0]), 1))\r\n        #\xe5\xad\x98\xe5\x82\xa8\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\r\n        cost_function = []\r\n\r\n        for i in range(self.iter_times):\r\n            #\xe5\xbe\x97\xe5\x88\xb0\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe5\x80\xbc\r\n            y_predict = np.dot(xdata, self.weights)\r\n\r\n            # \xe6\x9c\x80\xe5\xb0\x8f\xe4\xba\x8c\xe4\xb9\x98\xe6\xb3\x95\xe8\xae\xa1\xe7\xae\x97\xe8\xaf\xaf\xe5\xb7\xae\r\n            cost = np.sum((y_predict - ydata) ** 2) / len(xdata)\r\n            cost_function.append(cost)\r\n\r\n            #\xe8\xae\xa1\xe7\xae\x97\xe6\xa2\xaf\xe5\xba\xa6\r\n            dJ_dw = 2 * np.dot(xdata.T, (y_predict - ydata)) / len(xdata)\r\n\r\n            #\xe6\x9b\xb4\xe6\x96\xb0\xe7\xb3\xbb\xe6\x95\xb0w,b\xe7\x9a\x84\xe5\x80\xbc\r\n            self.weights = self.weights - self.learn_rate * dJ_dw\r\n\r\n            #\xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\xe5\xbe\xaa\xe7\x8e\xaf\xe7\x9a\x84\xe6\x9c\xba\xe5\x88\xb6\r\n            if len(cost_function) > 1:\r\n                if 0 < cost_function[-2] - cost_function[-1] < self.error:\r\n                    break\r\n\r\n        return self.weights, cost_function\r\n\r\n\r\n    #\xe6\xa0\xb9\xe6\x8d\xae\xe5\x85\xac\xe5\xbc\x8f\r\n    def Formula(self, xdata, ydata):\r\n        xdata = self.Trans(xdata)\r\n        self.weights = np.dot(np.dot(np.linalg.inv(np.dot(xdata.T, xdata)), xdata.T), ydata)\r\n        y_predict = np.dot(xdata, self.weights)\r\n        cost = [np.sum((ydata - np.mean(ydata)) ** 2) / len(xdata)]  # \xe5\xbc\x80\xe5\xa7\x8b\xe6\x98\xaf\xe4\xbb\xa5y\xe5\x80\xbc\xe5\xbe\x97\xe5\xb9\xb3\xe5\x9d\x87\xe5\x80\xbc\xe4\xbd\x9c\xe4\xb8\xba\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe8\xae\xa1\xe7\xae\x97cost\r\n        cost += [np.sum((y_predict - ydata) ** 2) / len(xdata)]  # \xe5\x88\xa9\xe7\x94\xa8\xe5\x85\xac\xe5\xbc\x8f\xef\xbc\x8c\xe4\xb8\x80\xe6\xac\xa1\xe8\xae\xa1\xe7\xae\x97\xe4\xbe\xbf\xe5\xbe\x97\xe5\x88\xb0\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\xad\xe4\xbb\xa3\xe3\x80\x82\r\n        return self.weights, cost  # \xe5\x8c\x85\xe6\x8b\xac2\xe4\xb8\xaa\xe5\x80\xbc\r\n\r\n    #\xe9\xa2\x84\xe6\xb5\x8b\r\n    def predict(self, xdata):\r\n        return np.dot(self.Trans(xdata), self.weights)\r\n\r\n\r\n\r\n'"
Blending/adult_Blending_Data.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n#  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\ntrain_path = \'C:/Users/GWT9\\Desktop/Adult_Train.csv\'\r\n\r\n#  \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\npre_path = \'C:/Users/GWT9\\Desktop/Adult_Test.csv\'\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe5\xb9\xb6\xe4\xb8\x94\xe5\xa4\x84\xe7\x90\x86\xe7\xa1\xae\xe7\xbc\xba\xe5\xa4\xb1\xe6\x95\xb0\xe6\x8d\xae\r\ndef ReadHandle(filepath, miss=\'fill\'):  # \xe5\xae\x9a\xe4\xb9\x89\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    data = pd.read_csv(r\'%s\' % filepath)\r\n    data = data.replace(\'?\', np.nan)\r\n    #  \xe5\xa4\x84\xe7\x90\x86\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if miss == \'del\':  # \xe5\x88\xa0\xe9\x99\xa4\xe6\x8e\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n        miss_data = data.dropna(how=\'any\')\r\n    else:\r\n        miss_data = data.fillna(method=\'ffill\')\r\n    return miss_data\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nread_trai = ReadHandle(train_path)\r\nread_pr = ReadHandle(pre_path)\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xba\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5""Money""\xe4\xb8\xad\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe8\xbe\x83\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x9a\xe4\xba\x86\xe4\xb8\x80\xe4\xb8\xaa\xe7\x82\xb9\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe5\xa4\x84\xe7\x90\x86\r\nread_pr[""Money""] = [ii[:-1] for ii in read_pr[""Money""]]\r\n\r\n\r\n# \xe7\x94\xa8\xe5\xad\x97\xe5\x85\xb8\xe5\x82\xa8\xe5\xad\x98\xe6\x95\xb0\xe6\x8d\xae\r\ndata_dict = {}\r\ndata_dict[\'train\'] = read_trai\r\ndata_dict[\'predict\'] = read_pr'"
Blending/pm25_Blending_data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\PRSA_data_2010.1.1-2014.12.31.csv')\r\n\r\n\r\n'''\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86'''\r\n#  \xe5\x9b\xa0\xe4\xb8\xbaPm2.5\xe6\x98\xaf\xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9b\xb4\xe6\x8e\xa5\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xb8\x80\xe6\x9d\xa1\xe8\xae\xb0\xe5\xbd\x95\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe7\x9b\xae\xe6\xa0\x87\xe5\x80\xbc\xe4\xb8\xba\xe7\xa9\xba\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c, \xe5\x85\xb6\xe4\xbb\x96\xe5\x88\x97\xe4\xb8\xba\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe5\x88\x99\xe8\x87\xaa\xe5\x8a\xa8\xe5\xa1\xab\xe5\x85\x85,\xe5\xb9\xb6\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\x8f\x98\xe9\x87\x8f\xe6\x94\xbe\xe7\xbd\xae\xe5\x9c\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\x88\x97\r\ndef DeleteTargetNan(exdata, targetstr):\r\n    '''\r\n    :param exdata: dataframe\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    :param targetstr: \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\xe7\xa7\xb0\r\n    :return: \xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe7\x9a\x84dataframe\xe6\xa0\xbc\xe5\xbc\x8f\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    '''\r\n    #  \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if exdata[targetstr].isnull().any():\r\n        #  \xe9\xa6\x96\xe5\x85\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe6\x95\xb0\r\n        loc = exdata[targetstr][data[targetstr].isnull().values == True].index.tolist()\r\n        #  \xe7\x84\xb6\xe5\x90\x8e\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xba\x9b\xe8\xa1\x8c\r\n        exdata = exdata.drop(loc)\r\n    # \xe5\x87\xa1\xe6\x98\xaf\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\x86\x8d\xe4\xb8\x80\xe8\xb5\xb7\xe5\x88\xa9\xe7\x94\xa8\xe6\xad\xa4\xe8\xa1\x8c\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\xe5\xa1\xab\xe5\x85\x85\r\n    exdata = exdata.fillna(exdata.mean())\r\n    # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\x87\xb3\xe6\x94\xbe\xe5\x9c\xa8\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe4\xb8\x80\xe5\x88\x97\r\n    targetnum = exdata[targetstr].copy()\r\n    del exdata[targetstr]\r\n    exdata[targetstr] = targetnum\r\n    return exdata\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\r\ndef Shanchu(exdata, aiduan=['No']):\r\n    for ai in aiduan:\r\n        if ai in exdata.keys():\r\n            del exdata[ai]\r\n    return exdata\r\n\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\nfirst = DeleteTargetNan(data, 'pm2.5')\r\n# \xe5\x8e\xbb\xe9\x99\xa4\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8e\r\ntwo = Shanchu(first)\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xba\xe6\xad\xa4\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\xb2\xa1\xe6\x9c\x89\xe6\x8f\x90\xe4\xbe\x9b\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe5\x9c\xa8\xe6\x80\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\xe4\xb8\xad\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe6\x8b\xa9\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xe4\xbd\x9c\xe4\xb8\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n# \xe5\xaf\xb9\xe4\xba\x8eStacking\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe9\x9c\x80\xe8\xa6\x81\xe4\xbf\x9d\xe8\xaf\x81\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x98\xaf\xe5\x9b\xba\xe5\xae\x9a\xe7\x9a\x84\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe5\x9b\xba\xe5\xae\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe7\xa7\x8d\xe5\xad\x90\xef\xbc\x8c\xe4\xbf\x9d\xe8\xaf\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x98\xaf\xe5\x9b\xba\xe5\xae\x9a\xe7\x9a\x84\r\n# \xe5\xaf\xb9\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84k\xe6\x8a\x98\xe5\xa4\x84\xe7\x90\x86\xe4\xbb\xa5\xe5\x8f\x8a\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe6\x94\xbe\xe5\x9c\xa8\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe4\xb8\xad\r\n\r\ndef fenge(exdata, per=0.2):\r\n    '''\r\n    :param exdata: \xe6\x80\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86DataFrame\xe6\xa0\xbc\xe5\xbc\x8f\r\n    :param per: \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe5\x8d\xa0\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\r\n    :return: \xe8\xbf\x94\xe5\x9b\x9e{'train':dataframe, 'predict':dataframe}\xe6\xa0\xb7\xe5\xbc\x8f\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    '''\r\n\r\n    np.random.seed(1000)\r\n    df_predict = exdata.sample(frac=per)\r\n\r\n    rowlist = []\r\n    for indexs in df_predict.index:\r\n        rowlist.append(indexs)\r\n    df_train = exdata.drop(rowlist, axis=0)\r\n\r\n    # \xe4\xbf\x9d\xe5\xad\x98\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    datict = {}\r\n    datict['train'] = df_train\r\n    datict['predict'] = df_predict\r\n\r\n    return datict\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\r\ndata_dict = fenge(two)\r\n\r\n\r\n\r\n\r\n\r\n"""
CNN/mnist_to_fig.py,0,"b'#  # -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n#  \xe5\xb0\x86mnist\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x88\x96\xe8\x80\x85Fashion-MNIST\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba\xe5\x9b\xbe\xe7\x89\x87\r\n#  \xe5\x9b\xa0\xe4\xb8\xba\xe4\xb8\xa4\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xa0\xbc\xe5\xbc\x8f\xe6\x98\xaf\xe5\xae\x8c\xe5\x85\xa8\xe4\xb8\x80\xe8\x87\xb4\xe7\x9a\x84\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe7\xa8\x8b\xe5\xba\x8f\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x85\xb1\xe7\x94\xa8\r\n\r\nimport struct\r\nfrom PIL import Image\r\nimport numpy as np\r\nimport os\r\n\r\nPath = r\'C:\\Users\\GWT9\\Desktop\'  # \xe5\xad\x98\xe5\x82\xa8\xe4\xb8\x8b\xe9\x9d\xa24\xe4\xb8\xaa\xe6\x96\x87\xe4\xbb\xb6\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\r\nos.chdir(Path)   # \xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xba\xe5\xbd\x93\xe5\x89\x8d\xe7\x9a\x84\xe5\xb7\xa5\xe4\xbd\x9c\xe8\xb7\xaf\xe5\xbe\x84\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x9b\xbe\xe7\x89\x87\xe6\x96\x87\xe4\xbb\xb6\r\ntrain_images = \'train-images-idx3-ubyte\'   # \xe6\xb3\xa8\xe6\x84\x8fMnist\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\xadimages.idx3\xef\xbc\x8c\xe4\xb8\xad\xe6\x98\xaf\xe7\x82\xb9\'.\'\xef\xbc\x8c\xe8\x80\x8cFashion-MNIST\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\xad\xe6\x98\xaf\'-\'\r\n# \xe8\xae\xad\xe7\xbb\x83\xe6\xa0\x87\xe7\xad\xbe\xe6\x96\x87\xe4\xbb\xb6\r\ntrain_labels = \'train-labels-idx1-ubyte\'\r\n\r\n# \xe6\xb5\x8b\xe8\xaf\x95\xe5\x9b\xbe\xe7\x89\x87\xe6\x96\x87\xe4\xbb\xb6\r\ntest_images = \'t10k-images-idx3-ubyte\'\r\n# \xe6\xb5\x8b\xe8\xaf\x95\xe6\xa0\x87\xe7\xad\xbe\xe6\x96\x87\xe4\xbb\xb6\r\ntest_labels = \'t10k-labels-idx1-ubyte\'\r\n\r\n\r\n# \xe8\x8e\xb7\xe5\x8f\x96\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe6\x8d\xae\r\ndef get_image(image_file):\r\n    # \xe8\xaf\xbb\xe5\x8f\x96\xe4\xba\x8c\xe8\xbf\x9b\xe5\x88\xb6\xe6\x95\xb0\xe6\x8d\xae\r\n    bin_data = open(image_file, \'rb\').read()\r\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb4\xe4\xbf\xa1\xe6\x81\xaf\xef\xbc\x8c\xe4\xbe\x9d\xe6\xac\xa1\xe4\xb8\xba\xe9\xad\x94\xe6\x95\xb0\xe3\x80\x81\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe9\x87\x8f\xe3\x80\x81\xe6\xaf\x8f\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xe9\xab\x98\xe3\x80\x81\xe6\xaf\x8f\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xe5\xae\xbd\r\n    offset = 0\r\n    fmt_header = \'>iiii\'\r\n    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)\r\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    image_size = num_rows * num_cols\r\n    offset += struct.calcsize(fmt_header)\r\n    fmt_image = \'>\' + str(image_size) + \'B\'\r\n    images = np.empty((num_images, num_rows, num_cols))\r\n    for i in range(num_images):\r\n        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))\r\n        offset += struct.calcsize(fmt_image)\r\n    return images\r\n\r\n\r\n# \xe8\x8e\xb7\xe5\x8f\x96\xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\xe6\x8d\xae\r\ndef get_label(label_file):\r\n    # \xe8\xaf\xbb\xe5\x8f\x96\xe4\xba\x8c\xe8\xbf\x9b\xe5\x88\xb6\xe6\x95\xb0\xe6\x8d\xae\r\n    bin_data = open(label_file, \'rb\').read()\r\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb4\xe4\xbf\xa1\xe6\x81\xaf\xef\xbc\x8c\xe4\xbe\x9d\xe6\xac\xa1\xe4\xb8\xba\xe9\xad\x94\xe6\x95\xb0\xe5\x92\x8c\xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\r\n    offset = 0\r\n    fmt_header = \'>ii\'\r\n    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)\r\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    offset += struct.calcsize(fmt_header)\r\n    fmt_image = \'>B\'\r\n    labels = np.empty(num_images)\r\n    for i in range(num_images):\r\n        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]\r\n        offset += struct.calcsize(fmt_image)\r\n    return labels\r\n\r\n\r\n# \xe5\xb0\x86\xe7\x94\xa8\xe7\x9f\xa9\xe9\x98\xb5\xe8\xa1\xa8\xe7\xa4\xba\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe4\xbf\xa1\xe6\x81\xaf\xe8\xbd\xac\xe5\x8f\x98\xe4\xb8\xba\xe5\x9b\xbe\xe7\x89\x87\xef\xbc\x8c\xe5\x90\x8d\xe5\xad\x97\xe4\xb8\xba\xe6\xa0\x87\xe7\xad\xbe\r\ndef matrix_to_fig(matrix_data, fig_title, file_name):\r\n    """"""\r\n    \xe5\xb0\x86\xe7\x94\xa8\xe7\x9f\xa9\xe9\x98\xb5\xe8\xa1\xa8\xe7\xa4\xba\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe4\xbf\xa1\xe6\x81\xaf\xe8\xbd\xac\xe5\x8f\x98\xe4\xb8\xba\xe5\x9b\xbe\xe7\x89\x87\xef\xbc\x8c\xe5\x90\x8d\xe5\xad\x97\xe4\xb8\xba\xe6\xa0\x87\xe7\xad\xbe\r\n    :param matrix_data: \xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xe6\x95\xb0\xe6\x8d\xae\r\n    :param fig_title: \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe6\xa0\x87\xe7\xad\xbe\r\n    :param file_name: \xe5\xad\x98\xe5\x82\xa8\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe6\x9e\x81\xe5\xa4\xb9\xe7\x9a\x84\xe5\x90\x8d\xe7\xa7\xb0\r\n    :return: \xe5\xad\x98\xe5\x82\xa8\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb9\r\n    """"""\r\n    sign_dict = {}\r\n    for image, label in zip(matrix_data, fig_title):\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe8\x8e\xb7\xe5\x8f\x96\xe5\x90\x8c\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\x87\xe7\xad\xbe\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe7\xbc\x96\xe5\x8f\xb7\xef\xbc\x8c\xe4\xbb\x8e1\xe5\xbc\x80\xe5\xa7\x8b\r\n        if label not in sign_dict:\r\n            cc = 1\r\n        else:\r\n            cc = sign_dict[label] + 1\r\n        sign_dict[label] = cc\r\n        # \xe8\x8e\xb7\xe5\x8f\x96\xe5\x9b\xbe\xe7\x89\x87\r\n        get_image = Image.fromarray(np.uint8(image))  # \xe8\xbd\xac\xe4\xb8\xbauint8\xe7\x9a\x84\xe6\xa0\xbc\xe5\xbc\x8f\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe5\x9b\xbe\xe7\x89\x87\r\n        get_image.save(r"".\\%s\\%s_%d.png"" % (file_name, int(label), cc))\r\n    print(sign_dict)  # \xe6\x9f\xa5\xe7\x9c\x8b\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa0\x87\xe7\xad\xbe\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\n    return print(\'\xe8\xbd\xac\xe6\x8d\xa2\xe5\xae\x8c\xe6\x88\x90\')\r\n\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    #  \xe8\x8e\xb7\xe5\x8f\x96\xe8\xae\xad\xe7\xbb\x83\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\xe4\xbf\xa1\xe6\x81\xaf\xe5\x92\x8c\xe6\xa0\x87\xe7\xad\xbe\xe4\xbf\xa1\xe6\x81\xaf\r\n    train_fig_data = get_image(train_images)\r\n    train_fig_label = get_label(train_labels)\r\n    #  \xe8\x8e\xb7\xe5\x8f\x96\xe6\xb5\x8b\xe8\xaf\x95\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\xe4\xbf\xa1\xe6\x81\xaf\xe5\x92\x8c\xe6\xa0\x87\xe7\xad\xbe\xe4\xbf\xa1\xe6\x81\xaf\r\n    test_fig_data = get_image(test_images)\r\n    test_fig_label = get_label(test_labels)\r\n\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb9\xe5\xad\x90\xe7\x9a\x84\xe5\x90\x8d\xe7\xa7\xb0\r\n    New_File_Name = \'MNIST_DATA\'\r\n\r\n    # \xe5\xa6\x82\xe6\x9e\x9c\xe6\xb2\xa1\xe6\x9c\x89\xe5\x90\x8d\xe7\xa7\xb0\xe4\xb8\xba\xe8\xaf\xa5\xe5\x90\x8d\xe5\xad\x97\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb9\xe5\xb0\xb1\xe6\x96\xb0\xe5\xbb\xba\r\n    if not os.path.isdir(\'%s\' % New_File_Name):\r\n        os.mkdir(\'%s\' % New_File_Name)\r\n    # \xe6\x8a\x8a\xe8\xbf\x99\xe4\xb8\xaa\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb9\xe4\xbd\x9c\xe4\xb8\xba\xe5\xb7\xa5\xe4\xbd\x9c\xe8\xb7\xaf\xe5\xbe\x84\r\n    os.chdir(r\'%s\\%s\' % (Path, New_File_Name))\r\n\r\n    # \xe9\x9c\x80\xe8\xa6\x81\xe5\x9c\xa8\xe8\xbf\x99\xe4\xb8\xaa\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb9\xe5\xad\x90\xe4\xb8\x8b\xe9\x9d\xa2\xe5\xbb\xba\xe7\xab\x8b2\xe4\xb8\xaa\xe5\xad\x90\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb9train\xef\xbc\x8ctest\xef\xbc\x8c\xe5\x88\x86\xe5\x88\xab\xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe6\x8d\xae\r\n    if not os.path.isdir(\'train\'):\r\n        os.mkdir(\'train\')\r\n    if not os.path.isdir(\'test\'):\r\n        os.mkdir(\'test\')\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xbd\xac\xe6\x8d\xa2\r\n    matrix_to_fig(train_fig_data, train_fig_label, \'train\')\r\n    # \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xbd\xac\xe6\x8d\xa2\r\n    matrix_to_fig(test_fig_data, test_fig_label, \'test\')\r\n\r\n'"
Kmeans Cluster/Kmeans_AnFany.py,0,"b'#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n#\xe8\x8e\xb7\xe5\xbe\x97\xe6\x95\xb0\xe6\x8d\xae\r\nfrom Wine_Data import DATA\r\nimport numpy as np\r\n\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\xac\xa7\xe5\x87\xa0\xe9\x87\x8c\xe5\xbe\x97\xe8\xb7\x9d\xe7\xa6\xbb\r\ndef dis(sample, center):\r\n    cen = np.array([center])\r\n    sample = np.array(sample)\r\n    if len(sample) != 0:\r\n        usb = np.sum((sample - cen) ** 2, axis=1) ** 0.5\r\n        return usb\r\n    else:\r\n        return 0\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\xa0\xb9\xe6\x8d\xae\xe8\xb7\x9d\xe7\xa6\xbb\xe5\x88\x97\xe8\xa1\xa8\xef\xbc\x8c\xe6\xa6\x82\xe7\x8e\x87\xe8\xbe\x83\xe5\xa4\xa7\xe7\x9a\x84\xe8\xa2\xab\xe9\x80\x89\xe4\xb8\xad\r\ndef selec(dislist):\r\n    #\xe9\xa6\x96\xe5\x85\x88\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe6\x95\xb0\xe5\x80\xbc\xe9\x99\xa4\xe4\xbb\xa5\xe8\xb7\x9d\xe7\xa6\xbb\xe5\x92\x8c\r\n    divided = dislist / np.sum(dislist)\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x960-1\xe4\xb9\x8b\xe5\x86\x85\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\r\n    num = np.random.random()\r\n    for hh in range(len(divided)):\r\n        num -= divided[hh]\r\n        if num < 0:\r\n            return hh\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe7\x94\x9f\xe6\x88\x90\xe5\x88\x9d\xe5\xa7\x8b\xe7\x9a\x84\xe8\x81\x9a\xe7\xb1\xbb\xe4\xb8\xad\xe5\xbf\x83\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef gencenter(sample, type):\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe6\x8b\xa9\xe5\x88\x9d\xe5\xa7\x8b\xe7\x9a\x84\xe6\xa0\xb7\xe6\x9c\xac\xe7\xbc\x96\xe5\x8f\xb7\r\n    sign = np.random.choice(list(range(len(sample))), 1)[0]\r\n    #\xe5\xad\x98\xe5\x82\xa8\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xad\xe5\xbf\x83\xe7\x9a\x84\xe6\x95\xb0\xe7\xbb\x84\r\n    centerlist = [sample[sign]]\r\n    while len(centerlist) < type:\r\n        # \xe6\xb7\xbb\xe5\x8a\xa0\xe6\x96\xb0\xe7\x9a\x84\r\n        distance = dis(sample, centerlist[-1])  # \xe5\x92\x8c\xe5\x88\x9a\xe6\xb7\xbb\xe5\x8a\xa0\xe7\x9a\x84\xe4\xb8\xad\xe5\xbf\x83\xe8\xae\xa1\xe7\xae\x97\xe8\xb7\x9d\xe7\xa6\xbb\r\n        newsign = selec(distance)\r\n        centerlist.append(sample[newsign])\r\n    return np.array(centerlist)\r\n\r\n# Kmeans++\xe8\x81\x9a\xe7\xb1\xbb\xe7\xae\x97\xe6\xb3\x95\r\ndef kmeans(samp, maxtimes, costerror, countcenter):\r\n    # kmeans++ \xe4\xba\xa7\xe7\x94\x9f\xe5\x87\xba\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xad\xe5\xbf\x83\r\n    center = gencenter(samp, type=countcenter)\r\n\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\r\n    costfunc = []\r\n\r\n    iter = 0\r\n\r\n    while iter < maxtimes:\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xa0\xb9\xe6\x8d\xae\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xad\xe5\xbf\x83\xe5\x8c\xb9\xe9\x85\x8d\xe8\xb7\x9d\xe7\xa6\xbb\r\n        samdict  = {}\r\n        signdict = {}\r\n        # \xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab \xe5\xae\x9a\xe4\xb9\x89\xe6\x88\x90\xe4\xb8\x80\xe4\xb8\xaa\xe9\x9b\x86\xe5\x90\x88\r\n        for jj in range(len(center)):\r\n            samdict[jj] = [] # \xe5\xad\x98\xe5\x82\xa8\xe6\xa0\xb7\xe6\x9c\xac\r\n            signdict[jj] = [] # \xe5\xad\x98\xe5\x82\xa8\xe6\xa0\xb7\xe6\x9c\xac\xe7\xbc\x96\xe5\x8f\xb7\r\n        # \xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe5\x88\xab\r\n        dictgn = 0\r\n        for hg in samp:\r\n            ddis = dis(center, hg) #\xe8\xae\xa1\xe7\xae\x97\xe6\xa0\xb7\xe6\x9c\xac\xe4\xb8\x8e\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xad\xe5\xbf\x83\xe7\x9a\x84\xe8\xb7\x9d\xe7\xa6\xbb\r\n            # \xe6\x89\xbe\xe5\x88\xb0\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\r\n            minsign = ddis.argmin()\r\n            samdict[minsign].append(hg)  # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\xb0\xe8\xaf\xa5\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe6\xa0\xb7\xe6\x9c\xac\xe9\x9b\x86\xe5\x90\x88\xe4\xb8\xad\r\n            signdict[minsign].append(dictgn)\r\n            dictgn += 1\r\n\r\n\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe6\xad\xa4\xe6\x97\xb6\xe5\x88\x86\xe7\xb1\xbb\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84cost\r\n        cost = 0\r\n        for cc in samdict:\r\n            cost += np.sum(dis(samdict[cc], center[cc]))\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8cost\r\n        costfunc.append(cost)\r\n\r\n        # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe5\x90\xa6\xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\xe8\xbf\xad\xe4\xbb\xa3\r\n        if len(costfunc) > 2:\r\n            if 0 <= costfunc[-2] - costfunc[-1] < costerror:\r\n                break\r\n\r\n         # \xe6\x9b\xb4\xe6\x96\xb0\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xad\xe5\xbf\x83\r\n        for kk in samdict:\r\n            if len(signdict[kk]) != 0:\r\n                center[kk] = np.mean(samdict[kk], axis=0)  # \xe5\x9d\x87\xe5\x80\xbc\r\n\r\n        iter += 1\r\n\r\n    return center, costfunc, signdict\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xbaKmeans \xe7\xae\x97\xe6\xb3\x95\xe4\xb8\x8d\xe4\xbf\x9d\xe8\xaf\x81\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe9\x83\xbd\xe5\x8f\x96\xe5\xbe\x97\xe6\x9c\x80\xe4\xbc\x98\xe5\x80\xbc\xe3\x80\x82\xe5\x9b\xa0\xe6\xad\xa4\xe5\xae\x9a\xe4\xb9\x89\xe8\xbf\x90\xe8\xa1\x8c\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0\xef\xbc\x8c\xe9\x80\x89\xe6\x8b\xa9cost\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\r\ndef op_kmeans(saple, maxti=1000, costerr=1e-19, countcen=3, maxtimes=90):\r\n    times = 0\r\n    # \xe5\xad\x98\xe5\x82\xa8cost\r\n    costff = [1e9]\r\n\r\n    #\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9clastre\r\n    lastre = 0\r\n    while times < maxtimes:\r\n        step = kmeans(saple, maxtimes=maxti, costerror=costerr, countcenter=countcen)\r\n        if len(costff) != 0:\r\n            if costff[0] > step[1][-1]:\r\n                lastre = step\r\n                costff = [step[1][-1]]\r\n        else:\r\n            costff = [step[1][-1]]\r\n        times += 1\r\n    return lastre\r\n\r\n\r\n# \xe7\xbb\x93\xe6\x9e\x9c\xe9\xaa\x8c\xe8\xaf\x81\r\n\r\n# \xe9\xa6\x96\xe5\x85\x88\xe5\xbe\x97\xe5\x87\xba\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe7\xbc\x96\xe5\x8f\xb7\r\n\r\ndef get_start(ydata):\r\n    in_class = {}\r\n    classtype = sorted(list(set(list(ydata))))\r\n    for du in range(len(classtype)):\r\n        in_class[du+1] = np.arange(len(ydata))[ydata == classtype[du]]\r\n    return in_class\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xba\xe7\xae\x97\xe6\xb3\x95\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x92\x8c\xe5\x8e\x9f\xe5\xa7\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\xaf\xb9\xe5\xba\x94\xe5\x85\xb3\xe7\xb3\xbb\xe4\xb8\x8d\xe7\x9f\xa5\xef\xbc\x8c\xe4\xb8\x8b\xe9\x9d\xa2\xe6\x8c\x89\xe7\x85\xa7\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe9\x87\x8d\xe5\xa4\x8d\xe6\xaf\x94\xe6\x9d\xa5\xe4\xb8\x80\xe4\xb8\x80\xe7\xa1\xae\xe8\xae\xa4\r\ndef judge(starclass, endclass, ydata):\r\n    newclass = {} #\xe5\xad\x98\xe5\x82\xa8\xe5\x88\xa4\xe6\x96\xad\xe5\x87\xba\xe7\xb1\xbb\xe5\x88\xab\xe5\x90\x8e\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    clasdict = {} # \xe5\xad\x98\xe5\x82\xa8\xe7\xae\x97\xe6\xb3\x95\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\xaf\xb9\xe5\xba\x94\xe5\x85\xb3\xe7\xb3\xbb\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    for ekey in endclass:\r\n        judg = []\r\n        for skey in starclass:\r\n            # \xe5\x88\xa4\xe6\x96\xad\xe5\x92\x8c\xe5\x8e\x9f\xe5\xa7\x8b\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xad\xe7\x9a\x84\xe5\x93\xaa\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe9\x87\x8d\xe5\xa4\x8d\xe6\xaf\x94\xe6\x9c\x80\xe9\xab\x98\r\n            repeat = [len([val for val in endclass[ekey] if val in starclass[skey]]), skey]\r\n            judg.append(repeat)\r\n        # \xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe6\x95\xb0\xef\xbc\x8c\xe7\xa1\xae\xe5\xae\x9a\xe7\xb1\xbb\xe5\x88\xab\r\n        judg = np.array(judg)\r\n        du = judg[judg.argmax(axis=0)[0]][1]  #\xe5\x88\xa4\xe6\x96\xad\xe5\x87\xba\xe6\x9d\xa5\xe5\xb1\x9e\xe4\xba\x8e\xe5\x93\xaa\xe4\xb8\x80\xe7\xb1\xbb\r\n        clasdict[ekey] = du # \xe7\xae\x97\xe6\xb3\x95\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xef\xbc\x9a\xe5\x8e\x9f\xe5\xa7\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\r\n        newclass[du] = endclass[ekey]\r\n    # \xe6\x8c\x89\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe5\xba\x8f\xe5\x8f\xb7\xe8\xbe\x93\xe5\x87\xba\xe5\x85\xb6\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\r\n    newdata = np.ones(len(ydata))\r\n    for fgh in newclass:\r\n        for hu in newclass[fgh]:\r\n            newdata[hu] = fgh\r\n    return newdata, clasdict\r\n\r\n# \xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n#\xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable\r\ndef confusion(realy, outy, method=\'AnFany\'):\r\n    mix = PrettyTable()\r\n    type = sorted(list(set(realy.T[0])), reverse=True)\r\n    mix.field_names = [method] + [\'\xe9\xa2\x84\xe6\xb5\x8b:%d\xe7\xb1\xbb\'%si for si in type]\r\n    # \xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f\xe5\xad\x98\xe5\x82\xa8\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe6\x95\xb0\xe6\x8d\xae\r\n    cmdict = {}\r\n    for jkj in type:\r\n        cmdict[jkj] = []\r\n        for hh in type:\r\n            hu = len([\'0\' for jj in range(len(realy)) if realy[jj][0] == jkj and outy[jj][0] == hh])\r\n            cmdict[jkj].append(hu)\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe8\xa1\xa8\xe6\xa0\xbc\r\n    for fu in type:\r\n        mix.add_row([\'\xe7\x9c\x9f\xe5\xae\x9e:%d\xe7\xb1\xbb\'%fu] + cmdict[fu])\r\n    return mix\r\n\r\n#  \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe7\xa8\x8b\xe5\xba\x8f\r\nif __name__ == ""__main__"":\r\n    init_class = get_start(DATA[1])\r\n    kresult = op_kmeans(DATA[0])\r\n    newy = judge(init_class, kresult[2], DATA[1])\r\n\r\n    # #\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n    print(\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n\', confusion(np.array([DATA[1]]).T, np.array([newy[0]]).T))\r\n\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe6\x9c\x80\xe5\x90\x8e\xe8\xae\xa1\xe7\xae\x97\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xad\xe5\xbf\x83\r\n    for real in kresult[2]:\r\n        print(\'\xe7\xb1\xbb\xe5\x88\xab%s\xe7\x9a\x84\xe4\xb8\xad\xe5\xbf\x83\xe4\xb8\xba\xef\xbc\x9a\\n%s\' % (newy[1][real], kresult[0][real]))\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\xbe\r\n    import matplotlib.pyplot as plt\r\n    from pylab import mpl  # \xe4\xbd\x9c\xe5\x9b\xbe\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\n\r\n    mpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe6\x96\xb0\xe5\xae\x8b\xe4\xbd\x93\r\n    mpl.rcParams[\'axes.unicode_minus\'] = False\r\n    plt.plot(list(range(len(kresult[1]))), kresult[1], \'-\', linewidth=5)\r\n    plt.title(\'\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\xbe\')\r\n    plt.ylabel(\'Cost \xe5\x80\xbc\')\r\n    plt.xlabel(\'\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\')\r\n    plt.show()\r\n\r\n'"
Kmeans Cluster/Kmeans_Compare.py,0,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x96\xb9\xe6\xb3\x95\r\nimport Kmeans_AnFany as K_Af  # AnFany\r\nimport Kmeans_Sklearn as K_Sk  # Sklearn\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl  # \xe4\xbd\x9c\xe5\x9b\xbe\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe6\x96\xb0\xe5\xae\x8b\xe4\xbd\x93\r\nmpl.rcParams['axes.unicode_minus'] = False\r\nimport numpy as np\r\n\r\n# \xe5\x88\xa9\xe7\x94\xa8sklearn\xe7\x94\x9f\xe6\x88\x90\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\nfrom sklearn.datasets import make_blobs\r\nX, Y = make_blobs(n_samples=600, centers=6, n_features=2)\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\r\ndef fig_scatter(exdata, eydata, titl='\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe', co=['r', 'g', 'k', 'b', 'y', 'm'], marker=['o','^','H','v','d','>']):\r\n    typeclass = sorted(list(set(eydata)))\r\n    for ii in range(len(typeclass)):\r\n        datax = exdata[eydata == typeclass[ii]]\r\n        plt.scatter(datax[:, 0], datax[:, -1], c=co[ii], s=50, marker=marker[ii])\r\n    plt.title(titl)\r\n    #plt.legend(['%d\xe7\xb1\xbb'%i for i in typeclass], bbox_to_anchor=(1.2, 0.9))\r\n    plt.xlabel('\xe7\x89\xb9\xe5\xbe\x811')\r\n    plt.ylabel('\xe7\x89\xb9\xe5\xbe\x812')\r\n\r\n# \xe8\xb0\x83\xe7\x94\xa8\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\r\n\r\n# AnFany\r\nkresult = K_Af.op_kmeans(X, countcen=6)\r\n\r\n\r\n# Sklearn\r\nsk = K_Sk.KMeans(init='k-means++', n_clusters=6, n_init=10)\r\n\r\ntrain = sk.fit(X)\r\nresult = sk.predict(X)\r\nskru = K_Sk.trans(result)\r\n\r\n\r\n\r\n#\xe7\xbb\x98\xe5\x88\xb6\xe7\xae\x97\xe6\xb3\x95\xe5\x90\x8e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\r\ndef sca(Xdata, Center, signdict, co=['r', 'g', 'y', 'b', 'c', 'm'], marker=['o','^','H','s','d','*'], titl = 'AnFany \xe7\xbb\x93\xe6\x9e\x9c'):\r\n    du = 1\r\n    for jj in signdict:\r\n        xdata = Xdata[signdict[jj]]\r\n        plt.scatter(xdata[:, 0], xdata[:, -1], c=co[jj], s=50, marker=marker[jj], label='%d\xe7\xb1\xbb' % jj)  # \xe7\xbb\x98\xe5\x88\xb6\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\r\n    for ss in Center:\r\n        if du:\r\n            plt.scatter(ss[0], ss[1], c='k', s=100, marker='8', label='\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xad\xe5\xbf\x83') #\xe7\xbb\x98\xe5\x88\xb6\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xad\xe5\xbf\x83\xe7\x82\xb9\r\n            du = 0\r\n        else:\r\n            plt.scatter(ss[0], ss[1], c='k', s=100, marker='8')  # \xe7\xbb\x98\xe5\x88\xb6\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xad\xe5\xbf\x83\xe7\x82\xb9\r\n\r\n    plt.legend(bbox_to_anchor=(1.2, 1))\r\n    plt.title(titl)\r\n    plt.xlabel('\xe7\x89\xb9\xe5\xbe\x811')\r\n    plt.ylabel('\xe7\x89\xb9\xe5\xbe\x812')\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\xac\xa7\xe5\x87\xa0\xe9\x87\x8c\xe5\xbe\x97\xe8\xb7\x9d\xe7\xa6\xbb\r\ndef dis(sample, center):\r\n    cen = np.array([center])\r\n    sample = np.array(sample)\r\n    if len(sample) != 0:\r\n        usb = np.sum((sample - cen) ** 2, axis=1) ** 0.5\r\n        return usb\r\n    else:\r\n        return 0\r\n# \xe8\xae\xa1\xe7\xae\x97\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe5\x88\x86\xe7\xb1\xbb\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe6\x88\x90\xe6\x9c\xac\xe5\x80\xbc\r\ndef Cost(Xdata, typedict):\r\n    center = {}\r\n    for kk in typedict:\r\n        center[kk] = np.mean(Xdata[typedict[kk]], axis=0) # \xe5\x9d\x87\xe5\x80\xbc\r\n    cio = 0\r\n    for cc in typedict:\r\n        cio += np.sum(dis(Xdata[typedict[cc]], center[cc]))\r\n    return cio\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\r\nplt.subplot(2, 2, 1)\r\nfig_scatter(X, Y)\r\n\r\nplt.subplot(2, 2, 2)\r\nsca(X, kresult[0], kresult[2])\r\n\r\nplt.subplot(2, 2, 3)\r\nsca(X, train.cluster_centers_, skru, titl='Sklearn \xe7\xbb\x93\xe6\x9e\x9c')\r\n\r\nplt.subplot(2, 2, 4)\r\nplt.axis('off')\r\nplt.text(0.3, 0.6, 'AnFany \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe5\x88\x86\xe7\xb1\xbb\xe6\x88\x90\xe6\x9c\xac\xe5\x80\xbc\xe4\xb8\xba\xef\xbc\x9a%.5f'%Cost(X, kresult[2]))\r\nplt.text(0.3, 0.3, 'Sklearn \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe5\x88\x86\xe7\xb1\xbb\xe6\x88\x90\xe6\x9c\xac\xe5\x80\xbc\xe4\xb8\xba\xef\xbc\x9a%.5f'%Cost(X, skru))\r\n\r\nplt.show()\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"""
Kmeans Cluster/Kmeans_Sklearn.py,0,"b'#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n#\xe8\x8e\xb7\xe5\xbe\x97\xe6\x95\xb0\xe6\x8d\xae\r\nfrom Wine_Data import DATA\r\nimport  numpy as np\r\nfrom sklearn.cluster import KMeans\r\n\r\n\r\n# \xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe7\xae\x97\xe6\xb3\x95\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba\xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\r\n\r\n# \xe9\xa6\x96\xe5\x85\x88\xe5\xbe\x97\xe5\x87\xba\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe7\xbc\x96\xe5\x8f\xb7\r\ndef get_start(ydata):\r\n    in_class = {}\r\n    classtype = sorted(list(set(list(ydata))))\r\n    for du in range(len(classtype)):\r\n        in_class[du+1] = np.arange(len(ydata))[ydata == classtype[du]]\r\n    return in_class\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xba\xe7\xae\x97\xe6\xb3\x95\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x92\x8c\xe5\x8e\x9f\xe5\xa7\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\xaf\xb9\xe5\xba\x94\xe5\x85\xb3\xe7\xb3\xbb\xe4\xb8\x8d\xe7\x9f\xa5\xef\xbc\x8c\xe4\xb8\x8b\xe9\x9d\xa2\xe6\x8c\x89\xe7\x85\xa7\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe9\x87\x8d\xe5\xa4\x8d\xe6\xaf\x94\xe6\x9d\xa5\xe4\xb8\x80\xe4\xb8\x80\xe7\xa1\xae\xe8\xae\xa4\r\ndef judge(starclass, endclass, ydata):\r\n    newclass = {} #\xe5\xad\x98\xe5\x82\xa8\xe5\x88\xa4\xe6\x96\xad\xe5\x87\xba\xe7\xb1\xbb\xe5\x88\xab\xe5\x90\x8e\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    clasdict = {} # \xe5\xad\x98\xe5\x82\xa8\xe7\xae\x97\xe6\xb3\x95\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\xaf\xb9\xe5\xba\x94\xe5\x85\xb3\xe7\xb3\xbb\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    for ekey in endclass:\r\n        judg = []\r\n        for skey in starclass:\r\n            # \xe5\x88\xa4\xe6\x96\xad\xe5\x92\x8c\xe5\x8e\x9f\xe5\xa7\x8b\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xad\xe7\x9a\x84\xe5\x93\xaa\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe9\x87\x8d\xe5\xa4\x8d\xe6\xaf\x94\xe6\x9c\x80\xe9\xab\x98\r\n            repeat = [len([val for val in endclass[ekey] if val in starclass[skey]]), skey]\r\n            judg.append(repeat)\r\n        # \xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe6\x95\xb0\xef\xbc\x8c\xe7\xa1\xae\xe5\xae\x9a\xe7\xb1\xbb\xe5\x88\xab\r\n        judg = np.array(judg)\r\n        du = judg[judg.argmax(axis=0)[0]][1]  #\xe5\x88\xa4\xe6\x96\xad\xe5\x87\xba\xe6\x9d\xa5\xe5\xb1\x9e\xe4\xba\x8e\xe5\x93\xaa\xe4\xb8\x80\xe7\xb1\xbb\r\n        clasdict[ekey] = du # \xe7\xae\x97\xe6\xb3\x95\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xef\xbc\x9a\xe5\x8e\x9f\xe5\xa7\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\r\n        newclass[du] = endclass[ekey]\r\n    # \xe6\x8c\x89\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe5\xba\x8f\xe5\x8f\xb7\xe8\xbe\x93\xe5\x87\xba\xe5\x85\xb6\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\r\n    newdata = np.ones(len(ydata))\r\n    for fgh in newclass:\r\n        for hu in newclass[fgh]:\r\n            newdata[hu] = fgh\r\n    return newdata, clasdict\r\n\r\n# \xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n#\xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable\r\ndef confusion(realy, outy, method=\'Sklearn\'):\r\n    mix = PrettyTable()\r\n    type = sorted(list(set(realy.T[0])), reverse=True)\r\n    mix.field_names = [method] + [\'\xe9\xa2\x84\xe6\xb5\x8b:%d\xe7\xb1\xbb\'%si for si in type]\r\n    # \xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f\xe5\xad\x98\xe5\x82\xa8\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe6\x95\xb0\xe6\x8d\xae\r\n    cmdict = {}\r\n    for jkj in type:\r\n        cmdict[jkj] = []\r\n        for hh in type:\r\n            hu = len([\'0\' for jj in range(len(realy)) if realy[jj][0] == jkj and outy[jj][0] == hh])\r\n            cmdict[jkj].append(hu)\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe8\xa1\xa8\xe6\xa0\xbc\r\n    for fu in type:\r\n        mix.add_row([\'\xe7\x9c\x9f\xe5\xae\x9e:%d\xe7\xb1\xbb\'%fu] + cmdict[fu])\r\n    return mix\r\n\r\n# \xe5\xb0\x86sklearn\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\x8f\x98\xe4\xb8\xba\xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f\r\ndef trans(resu):\r\n    redict = {}\r\n    for ire in range(len(resu)):\r\n        try:\r\n            redict[resu[ire]].append(ire)\r\n        except KeyError:\r\n            redict[resu[ire]] = [ire]\r\n    return redict\r\n\r\n#  \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe7\xa8\x8b\xe5\xba\x8f\r\nif __name__ == ""__main__"":\r\n    sk = KMeans(init=\'k-means++\', n_clusters=3, n_init=10)\r\n\r\n    train = sk.fit(DATA[0])\r\n    result = sk.predict(DATA[0])\r\n\r\n    init_class = get_start(DATA[1])\r\n    kresult = trans(result)\r\n\r\n    newy = judge(init_class, kresult, DATA[1])\r\n\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n    print(\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n\', confusion(np.array([DATA[1]]).T, np.array([newy[0]]).T))\r\n\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xad\xe5\xbf\x83\r\n    print(train.cluster_centers_)\r\n\r\n'"
Kmeans Cluster/Wine_Data.py,0,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\n\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\Wine.csv')\r\n\r\n# y\xe5\x80\xbcSoftmax\r\ny_data = data['Wine Type'].values\r\n# x\xe5\x80\xbc\r\nxdata = data.iloc[:, 1:].values\r\n\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\r\nimport numpy as np\r\n\r\n# x\xe6\x95\xb0\xe6\x8d\xae\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\nx_data = (xdata - np.mean(xdata, axis=0)) / np.std(xdata, axis=0)\r\n\r\n\r\nDATA = [x_data, y_data]\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n# x_data.shape = (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0, \xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0)\r\n# y_data.shape = (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0,)\r\n\r\n\r\n"""
Kmeans Cluster/Wine_Spyder.py,0,"b'#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nfrom bs4 import BeautifulSoup as bs\r\nimport urllib\r\n\r\nhtml = urllib.request.urlopen(""http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data"")\r\nbsObj = bs(html.read(), ""html5lib"")\r\nnamest = str(bsObj.body.get_text())\r\n\r\n\r\n# \xe5\xb1\x9e\xe6\x80\xa7\xe5\x90\x8d\xe7\xa7\xb0\r\natt_name = [\'Wine Type\', \'Alcohol\', \'Malic acid\', \'Ash\', \'Alcalinity of ash\', \'Magnesium\', \\\r\n            \'Total phenols\', \'Flavanoids\', \'Nonflavanoid phenols\', \'Proanthocyanins\',\\\r\n            \'Color intensity\', \'Hue\', \'OD280/OD315\', \'Proline\']\r\n\r\n# \xe6\x9e\x84\xe5\xbb\xba\xe5\xad\x97\xe5\x85\xb8\r\n# \xe6\x9c\x89\xe5\xba\x8f\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f,\xe6\x8c\x89\xe6\xb7\xbb\xe5\x8a\xa0\xe7\x9a\x84\xe5\xba\x8f\xe5\x88\x97\xe8\xbe\x93\xe5\x87\xba\r\nfrom collections import OrderedDict\r\ndatadict=OrderedDict({})\r\nfor keyname in att_name:\r\n    datadict[keyname] = []\r\n\r\n# \xe6\xb7\xbb\xe5\x8a\xa0\xe6\x95\xb0\xe6\x8d\xae\r\nfor hh in namest.split(\'\\n\'):\r\n    sample = hh.split(\',\')\r\n    if len(sample) > 1:\r\n        for hhh in range(len(sample)):\r\n            if hhh == 0:\r\n                datadict[att_name[hhh]].append(int(sample[hhh]))\r\n            else:\r\n                datadict[att_name[hhh]].append(float(sample[hhh]))\r\n    else:\r\n        break\r\n\r\n# \xe5\x86\x99\xe5\x85\xa5\xe6\x96\x87\xe4\xbb\xb6\r\nimport pandas as pd\r\ndf = pd.DataFrame(datadict)\r\ndf.to_csv(r\'C:\\Users\\GWT9\\Desktop\\Wine.csv\', index=False)\r\nprint(\'\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n\r\n\r\n'"
Linear Regression/Boston_Data.py,0,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\n\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\Boston.csv')\r\n\r\n#y\xe5\x80\xbc\r\ny_data = data['MEDV']\r\n#x\xe5\x80\xbc\r\nx_data = data.drop('MEDV', axis=1).values\r\n\r\n#\xe5\xa6\x82\xe6\x9e\x9cx\xe5\x80\xbc\xe5\x8f\xaa\xe6\x9c\x89\xe4\xb8\x80\xe4\xb8\xaa\xe7\x89\xb9\xe5\xbe\x81\r\n#x_data= data.drop('MEDV', axis=1).values.reshape(-1,1)\r\n\r\n#\xe5\xaf\xb9x\xe5\x80\xbc\xe8\xbf\x9b\xe8\xa1\x8c[0,1]\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\r\nfrom sklearn import preprocessing as spp #\xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe7\x9a\x84\xe5\xba\x93\r\nscaler_01 = spp.MinMaxScaler()\r\n\r\n#\xe5\xbd\x92\xe4\xb8\x80\xe7\x9a\x84x\xe5\x80\xbc\r\nx_pre_data = scaler_01.fit_transform(x_data)\r\n\r\n#\xe5\xbd\x92\xe4\xb8\x80\xe7\x9a\x84x\xe5\x80\xbc\xef\xbc\x8cy\xe5\x80\xbc\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\nimport numpy as np\r\ndef divided(xdata, ydata, percent=0.1):\r\n    sign_list = list(range(len(xdata)))\r\n    #\xe7\x94\xa8\xe4\xba\x8e\xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84\xe5\xba\x8f\xe5\x8f\xb7\r\n    select_sign = sorted(np.random.choice(sign_list, int(len(xdata)*percent), replace=False))\r\n\r\n    #\xe7\x94\xa8\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xba\x8f\xe5\x8f\xb7\r\n    no_select_sign = [isign for isign in sign_list if isign not in select_sign]\r\n\r\n    #\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\n    x_predict_data = xdata[select_sign]\r\n    y_predict_data = ydata[select_sign].values.reshape(len(select_sign),1)#\xe8\xbd\xac\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n\r\n    #\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n    x_train_data = xdata[no_select_sign]\r\n    y_train_data = ydata[no_select_sign].values.reshape(len(no_select_sign),1)#\xe8\xbd\xac\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n\r\n    return x_train_data, y_train_data, x_predict_data, y_predict_data #\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84x\xef\xbc\x8cy;  \xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84x\xef\xbc\x8cy\r\n\r\n#\xe5\x8f\xaf\xe7\x94\xa8\xe4\xba\x8e\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nmodel_data = divided(x_pre_data, y_data)\r\n\r\n\r\n#\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n#x_train_data.shape = (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0)\r\n#y_train_data.shape= (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c1)\r\n\r\n\r\n\r\n"""
Linear Regression/Boston_Spyder.py,0,"b'#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nfrom bs4 import BeautifulSoup as bs\r\nimport urllib\r\n\r\nhtml = urllib.request.urlopen(""http://lib.stat.cmu.edu/datasets/boston"")\r\nbsObj = bs(html.read(), ""html5lib"")\r\nnamest = str(bsObj.body.get_text())\r\n\r\n\r\nsign = 0\r\nname = []\r\nfor hh in namest.split(\'\\n\'):\r\n    if 6< sign < 21:\r\n        #\xe8\x8e\xb7\xe5\x8f\x96\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\xe5\xad\x97\r\n        name.append(hh[:7].replace(\' \',\'\'))\r\n\r\n    if sign == 21:\r\n        for nam in name:\r\n            exec(\'%s = []\'%nam)\r\n\r\n    if sign > 21:\r\n        #\xe8\x8e\xb7\xe5\xbe\x97\xe5\xad\x97\xe6\xae\xb5\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n        datalist = [data for data in hh.split(\' \') if data !=\'\']\r\n        if sign % 2 ==0:\r\n            for i in range(len(datalist)):\r\n                eval(name[i]).append(datalist[i])\r\n        else:\r\n            for i in range(len(datalist)):\r\n                eval(name[11+i]).append(datalist[i])\r\n    sign += 1\r\n\r\n#\xe6\x9c\x89\xe5\xba\x8f\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f,\xe6\x8c\x89\xe6\xb7\xbb\xe5\x8a\xa0\xe7\x9a\x84\xe5\xba\x8f\xe5\x88\x97\xe8\xbe\x93\xe5\x87\xba\r\nfrom collections import OrderedDict\r\ndatadict=OrderedDict({})\r\n\r\nfor keyname in name:\r\n    datadict[keyname] = eval(keyname)\r\n\r\n\r\n#\xe5\x86\x99\xe5\x85\xa5\xe6\x96\x87\xe4\xbb\xb6\r\nimport pandas as pd\r\ndf = pd.DataFrame(datadict)\r\ndf.to_csv(r\'C:\\Users\\GWT9\\Desktop\\Boston.csv\', index=False)\r\nprint(\'\xe5\xae\x8c\xe6\xaf\x95\')\r\n'"
Linear Regression/Linear_Regression_AnFany.py,0,"b'#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n#\xe8\x8e\xb7\xe5\xbe\x97\xe6\x95\xb0\xe6\x8d\xae\r\nfrom Boston_Data import model_data as lrdata\r\nimport numpy as np\r\n\r\n#\xe5\x88\x9b\xe5\xbb\xba\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe7\xb1\xbb\r\nclass LinearRegression:\r\n    #w\xe5\x92\x8cb\xe5\x90\x88\xe4\xb8\xba\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xafx\xe6\x9c\x80\xe5\x90\x8e\xe5\x8a\xa0\xe4\xb8\x8a\xe4\xb8\x80\xe5\x88\x97\xe5\x85\xa8\xe4\xb8\xba1\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n\r\n    def __init__(self, learn_rate=0.2, iter_times=200000, error=1e-9):\r\n        self.learn_rate = learn_rate\r\n        self.iter_times = iter_times\r\n        self.error = error\r\n\r\n    def Trans(self, xdata):\r\n        one1 = np.ones(len(xdata))\r\n        xta = np.append(xdata, one1.reshape(-1, 1), axis=1)\r\n        return xta\r\n\r\n    #\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\r\n    def Gradient(self, xdata, ydata):\r\n        xdata = self.Trans(xdata)\r\n        #\xe7\xb3\xbb\xe6\x95\xb0w,b\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n        self.weights = np.zeros((len(xdata[0]), 1))\r\n        #\xe5\xad\x98\xe5\x82\xa8\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\r\n        cost_function = []\r\n\r\n        for i in range(self.iter_times):\r\n            #\xe5\xbe\x97\xe5\x88\xb0\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe5\x80\xbc\r\n            y_predict = np.dot(xdata, self.weights)\r\n\r\n            # \xe6\x9c\x80\xe5\xb0\x8f\xe4\xba\x8c\xe4\xb9\x98\xe6\xb3\x95\xe8\xae\xa1\xe7\xae\x97\xe8\xaf\xaf\xe5\xb7\xae\r\n            cost = np.sum((y_predict - ydata) ** 2) / len(xdata)\r\n            cost_function.append(cost)\r\n\r\n            #\xe8\xae\xa1\xe7\xae\x97\xe6\xa2\xaf\xe5\xba\xa6\r\n            dJ_dw = 2 * np.dot(xdata.T, (y_predict - ydata)) / len(xdata)\r\n\r\n            #\xe6\x9b\xb4\xe6\x96\xb0\xe7\xb3\xbb\xe6\x95\xb0w,b\xe7\x9a\x84\xe5\x80\xbc\r\n            self.weights = self.weights - self.learn_rate * dJ_dw\r\n\r\n            #\xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\xe5\xbe\xaa\xe7\x8e\xaf\xe7\x9a\x84\xe6\x9c\xba\xe5\x88\xb6\r\n            if len(cost_function) > 1:\r\n                if 0 < cost_function[-2] - cost_function[-1] < self.error:\r\n                    break\r\n\r\n        return self.weights, cost_function\r\n\r\n\r\n    #\xe6\xa0\xb9\xe6\x8d\xae\xe5\x85\xac\xe5\xbc\x8f\r\n    def Formula(self, xdata, ydata):\r\n        xdata = self.Trans(xdata)\r\n        self.weights = np.dot(np.dot(np.linalg.inv(np.dot(xdata.T, xdata)), xdata.T), ydata)\r\n        y_predict = np.dot(xdata, self.weights)\r\n        cost = [np.sum((ydata - np.mean(ydata)) ** 2) / len(xdata)]  # \xe5\xbc\x80\xe5\xa7\x8b\xe6\x98\xaf\xe4\xbb\xa5y\xe5\x80\xbc\xe5\xbe\x97\xe5\xb9\xb3\xe5\x9d\x87\xe5\x80\xbc\xe4\xbd\x9c\xe4\xb8\xba\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe8\xae\xa1\xe7\xae\x97cost\r\n        cost += [np.sum((y_predict - ydata) ** 2) / len(xdata)]  # \xe5\x88\xa9\xe7\x94\xa8\xe5\x85\xac\xe5\xbc\x8f\xef\xbc\x8c\xe4\xb8\x80\xe6\xac\xa1\xe8\xae\xa1\xe7\xae\x97\xe4\xbe\xbf\xe5\xbe\x97\xe5\x88\xb0\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\xad\xe4\xbb\xa3\xe3\x80\x82\r\n        return self.weights, cost  # \xe5\x8c\x85\xe6\x8b\xac2\xe4\xb8\xaa\xe5\x80\xbc\r\n\r\n    #\xe9\xa2\x84\xe6\xb5\x8b\r\n    def predict(self, xdata):\r\n        return np.dot(self.Trans(xdata), self.weights)\r\n\r\n#\xe7\xbb\x98\xe5\x9b\xbe\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl  # \xe4\xbd\x9c\xe5\x9b\xbe\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'font.sans-serif\'] = [\'SimHei\']  # \xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\r\nmpl.rcParams[\'axes.unicode_minus\'] = False\r\n\r\n\r\ndef figure(title, *datalist):\r\n    for jj in datalist:\r\n        plt.plot(jj[0], \'-\', label=jj[1], linewidth=2)\r\n        plt.plot(jj[0], \'o\')\r\n    plt.grid()\r\n    plt.title(title)\r\n    plt.legend()\r\n    plt.show()\r\n\r\n#\xe8\xae\xa1\xe7\xae\x97R2\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef getR(ydata_tr, ydata_pre):\r\n    sum_error = np.sum(((ydata_tr - np.mean(ydata_tr)) ** 2))\r\n    inexplicable = np.sum(((ydata_tr - ydata_pre) ** 2))\r\n    return 1 - inexplicable / sum_error\r\n\r\n#  \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe7\xa8\x8b\xe5\xba\x8f\r\nif __name__ == ""__main__"":\r\n    regressor = LinearRegression()\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n    train_error = regressor.Gradient(lrdata[0], lrdata[1])\r\n\r\n    # \xe7\x94\xa8\xe4\xba\x8e\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    predict_result = regressor.predict(lrdata[2])\r\n    # \xe7\x94\xa8\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_pre_result = regressor.predict(lrdata[0])\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9b\xbe\r\n    figure(\'\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9b\xbe \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84MSE = %.4f\' % (train_error[1][-1]), [train_error[1], \'error\'])\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe4\xb8\x8e\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x9b\xbe\r\n    figure(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe4\xb8\x8e\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x9b\xbe \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\' + r\'$R^2=%.4f$\' % (getR(lrdata[1], train_pre_result)), [predict_result, \'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\'],\r\n           [lrdata[3], \'\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\'])\r\n    plt.show()\r\n\r\n    # \xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\r\n    print(\'\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe7\xb3\xbb\xe6\x95\xb0\xe4\xb8\xba:\\n w = %s, \\nb= %s\' % (train_error[0][:-1], train_error[0][-1]))\r\n\r\n\r\n\r\n\r\n\r\n'"
Linear Regression/Linear_Regression_Compare.py,1,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n#\xe7\x94\x9f\xe6\x88\x90\xe6\x95\xb0\xe6\x8d\xae\r\nimport numpy as np\r\nX_DATA = np.random.randint(12,39,20)\r\nY_DATA = 2 * X_DATA + np.random.random((1,20))[0] * 10\r\n\r\n#\xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b\r\nimport linear_regression_AnFany as lr_af   # AnFany\r\nimport linear_regression_sklearn as lr_sk  # Sklearn\r\nimport TensorFlow_rewrite as lr_tf  # TensorFlow\r\n\r\n\r\n#\xe7\xbb\x98\xe5\x9b\xbe\xe5\xaf\xb9\xe6\xaf\x94\xe5\xb1\x95\xe7\xa4\xba\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl  # \xe4\xbd\x9c\xe5\x9b\xbe\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams['font.sans-serif'] = ['SimHei']  # \xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams['axes.unicode_minus'] = False   # \xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n#\xe6\x95\xb0\xe6\x8d\xae\xe6\xa0\xbc\xe5\xbc\x8f\xe8\xbd\xac\xe6\x8d\xa2\r\nXDATA= X_DATA.reshape(-1, 1)\r\nYDATA= Y_DATA.reshape(-1, 1)\r\n\r\nplt.subplot(2, 2, 1)\r\nplt.plot(X_DATA, Y_DATA, 'o', label='\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae' )\r\n\r\n#\xe7\xbb\x98\xe5\x88\xb6AnFany \xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\nresulr_G = lr_af.LinearRegression(0.0002, 90000, 1e-10)#\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\x8d\xe5\xbd\x92\xe4\xb8\x80\xe7\x9a\x84\xe8\xaf\x9d\xe9\x9c\x80\xe8\xa6\x81\xe8\xae\xbe\xe7\xbd\xae\xe8\xbe\x83\xe5\xb0\x8f\xe7\x9a\x84\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\r\nresulr_G.Gradient(XDATA, YDATA)\r\nYDATA_G = resulr_G.predict(XDATA)\r\nplt.plot(XDATA, YDATA_G, '-', label='\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d',linewidth=2)\r\n\r\n\r\n#\xe7\xbb\x98\xe5\x88\xb6AnFany \xe5\x85\xac\xe5\xbc\x8f\xe6\xb3\x95\xe7\x9a\x84\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\nresulr_F = lr_af.LinearRegression()\r\nresulr_F.Formula(XDATA, YDATA)\r\nYDATA_F = resulr_F.predict(XDATA)\r\nplt.plot(XDATA, YDATA_F, '^', label='\xe5\x85\xac\xe5\xbc\x8f\xe6\xb3\x95', alpha=10)\r\nplt.legend(loc='upper left')\r\nplt.title('\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8dVS\xe5\x85\xac\xe5\xbc\x8f\xe6\xb3\x95')\r\n\r\n\r\n\r\n\r\n#\xe7\xbb\x98\xe5\x88\xb6Sklearn\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\nplt.subplot(2, 2, 2)\r\nplt.plot(X_DATA, Y_DATA, 'o', label='\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae')\r\nlr_sk.reg.fit(XDATA, YDATA)\r\nYDATA_sk = lr_sk.reg.predict(XDATA)\r\nplt.plot(XDATA, YDATA_sk, '-', label='Sklearn', linewidth=2)\r\nplt.legend(loc='upper left')\r\nplt.title('\xe5\x9f\xba\xe4\xba\x8eSklearn')\r\n\r\n\r\n\r\n#\xe7\xbb\x98\xe5\x88\xb6TensorFlow\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\nplt.subplot(2, 2, 3)\r\nplt.plot(X_DATA, Y_DATA, 'o', label='\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae')\r\n\r\nYDATA_tf = lr_tf.train_tf(XDATA, YDATA, 0.0002, 90000, 1e-10)\r\nplt.plot(XDATA, YDATA_tf[0], '-', label='TensorFlow', linewidth=2)\r\nplt.legend(loc='upper left')\r\nplt.title('\xe5\x9f\xba\xe4\xba\x8eTensorFlow')\r\n\r\n#\xe8\xae\xa1\xe7\xae\x97MSE\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Mse(y1, y2):\r\n    return np.sum((y1 - y2) ** 2) / len(y1)\r\n\r\n\r\n#\xe8\xbe\x93\xe5\x87\xba\xe5\x90\x84\xe8\x87\xaa\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\x96\xb9\xe7\xa8\x8b\r\nplt.subplot(2, 2, 4)\r\nplt.grid('off')# \xe5\x85\xb3\xe9\x97\xad\xe7\xbd\x91\xe6\xa0\xbc\r\nplt.text(0.1, 0.7, '\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\xef\xbc\x9ay = %.5f * x + %.5f  MSE = %.7f'%(resulr_G.weights[0], resulr_G.weights[1], Mse(YDATA_G, YDATA)))\r\nplt.text(0.1, 0.6, '\xe5\x85\xac\xe5\xbc\x8f\xe6\xb3\x95\xef\xbc\x9ay = %.5f * x + %.5f  MSE = %.7f'%(resulr_F.weights[0], resulr_F.weights[1], Mse(YDATA_F, YDATA)))\r\n\r\nplt.text(0.1, 0.4, 'Sklearn\xef\xbc\x9ay = %.5f * x + %.5f  MSE = %.7f'%(lr_sk.reg.coef_[0], lr_sk.reg.intercept_[0], Mse(YDATA_sk, YDATA)))\r\n\r\nplt.text(0.1, 0.2, 'Tensorflow\xef\xbc\x9ay = %.5f * x + %.5f  MSE = %.7f'%(YDATA_tf[1][0], YDATA_tf[2][0], Mse(YDATA_tf[0], YDATA)))\r\nplt.axis('off')# \xe5\x85\xb3\xe9\x97\xad\xe5\x9d\x90\xe6\xa0\x87\xe8\xbd\xb4\r\nplt.text(0.5, 0.9, '\xe5\x9b\x9b\xe7\xa7\x8d\xe6\x96\xb9\xe5\xbc\x8f\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94', fontsize=18)\r\n\r\nplt.show()\r\n"""
Linear Regression/Linear_Regression_Sklearn.py,0,"b'#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n#\xe8\x8e\xb7\xe5\xbe\x97\xe6\x95\xb0\xe6\x8d\xae\r\nfrom Boston_Data import model_data as lrdata\r\n\r\n#\xe5\xbc\x95\xe5\x85\xa5\xe5\x8c\x85\r\nimport numpy as np\r\nfrom sklearn import linear_model\r\nfrom sklearn.metrics import mean_squared_error, r2_score\r\n\r\n\r\n\r\n#\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xaex\r\nx_train_data = lrdata[0]\r\n#\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xaex\r\nx_predict_data = lrdata[2]\r\n\r\n\r\n#y\xe6\x95\xb0\xe6\x8d\xaeshape\xe8\xbd\xac\xe6\x8d\xa2(\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c1)==> (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c)\r\ny_train_data = lrdata[1].T[0]\r\ny_predict_data = lrdata[3].T[0]\r\n\r\n\r\nimport matplotlib.pyplot as plt # \xe7\xbb\x98\xe5\x9b\xbe\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'SimHei\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\r\nmpl.rcParams[\'axes.unicode_minus\'] = False # \xe8\xb4\x9f\xe5\x8f\xb7\r\n# \xe7\xbb\x98\xe5\x9b\xbe\xe5\x87\xbd\xe6\x95\xb0\r\ndef figure(title, *datalist):\r\n    for jj in datalist:\r\n        plt.plot(jj[0], \'-\', label=jj[1], linewidth=2)\r\n        plt.plot(jj[0], \'o\')\r\n    plt.grid()\r\n    plt.title(title)\r\n    plt.legend()\r\n    plt.show()\r\n\r\nreg = linear_model.LinearRegression()\r\n#  \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe7\xa8\x8b\xe5\xba\x8f\r\nif __name__ == ""__main__"":\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n    reg.fit(x_train_data, y_train_data)\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    predict_result = reg.predict(x_predict_data)\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_pre_result = reg.predict(x_train_data)\r\n\r\n    train_error = [mean_squared_error(y_train_data, [np.mean(y_train_data)] * len(y_train_data)),\r\n                   mean_squared_error(y_train_data, train_pre_result)]\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9b\xbe\r\n    figure(\'\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9b\xbe \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84MSE = %.4f\' % (train_error[-1]), [train_error, \'error\'])\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe4\xb8\x8e\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x9b\xbe\r\n    figure(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe4\xb8\x8e\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x9b\xbe \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\' + r\'$R^2=%.4f$\' % (r2_score(train_pre_result, y_train_data)), [predict_result, \'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\'],\r\n           [y_predict_data, \'\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\'])\r\n    plt.show()\r\n\r\n    # \xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\r\n    print(\'\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe7\xb3\xbb\xe6\x95\xb0\xe4\xb8\xba:\\n w = %s \\n b = %s\' % (reg.coef_, reg.intercept_))\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n'"
Linear Regression/Linear_Regression_TensorFlow.py,12,"b'#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n#\xe8\x8e\xb7\xe5\xbe\x97\xe6\x95\xb0\xe6\x8d\xae\r\nfrom Boston_Data import model_data as lrdata\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xaex\r\nx_train_data = lrdata[0]\r\n#\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xaex\r\nx_predict_data = lrdata[2]\r\n\r\n# y\xe6\x95\xb0\xe6\x8d\xae(\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c1)\r\ny_train_data = lrdata[1]\r\ny_predict_data = lrdata[3]\r\n\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe5\xba\x93\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n# \xe5\x8f\x82\xe6\x95\xb0\r\nlearn_rate = 0.2\r\niter_times = 9000000\r\nerror = 1e-12\r\n\r\n# \xe9\xa2\x84\xe5\x85\x88\xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nx_data = tf.placeholder(shape=[None, len(x_train_data[0])], dtype=tf.float32)\r\ny_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\r\n\r\n# \xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe5\x8f\x82\xe6\x95\xb0\r\nWeight = tf.Variable(tf.random_normal(shape=[len(x_train_data[0]), 1]))\r\nBias = tf.Variable(tf.random_normal(shape=[1, 1]))\r\ny_out = tf.add(tf.matmul(x_data, Weight), Bias)\r\n\r\n#L2\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\r\n\'\'\'\r\ntf.add_to_collection(tf.GraphKeys.WEIGHTS, Weight)\r\nregularizer = tf.contrib.layers.l2_regularizer(scale=5.0 / 6000)\r\nreg_term = tf.contrib.layers.apply_regularization(regularizer)\r\n\'\'\'\r\n\r\n# \xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\r\ncost = tf.reduce_mean(tf.square(y_out - y_data)) #+ reg_term\r\n\r\n# \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\nsess = tf.Session()\r\ninit = tf.global_variables_initializer()\r\nsess.run(init)\r\noptimizer = tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)\r\n\r\n\r\n#\xe8\xaf\xaf\xe5\xb7\xae\xe5\xad\x98\xe5\x82\xa8\r\ncostfunc = []\r\n\r\n\r\n#\xe8\xae\xad\xe7\xbb\x83\xe8\xbf\x87\xe7\xa8\x8b\r\ndef train(xxdata=x_train_data, yydata=y_train_data):\r\n    for i in range(iter_times):\r\n\r\n        sess.run(optimizer, feed_dict={x_data: xxdata, y_data: yydata})\r\n\r\n        y_step_out = sess.run(y_out, feed_dict={x_data: xxdata})\r\n\r\n        loss = sess.run(cost, feed_dict={y_out: y_step_out, y_data: yydata})\r\n\r\n        costfunc.append(loss)\r\n\r\n        # \xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\xe5\xbe\xaa\xe7\x8e\xaf\xe7\x9a\x84\xe6\x9c\xba\xe5\x88\xb6\r\n        if len(costfunc) > 1:\r\n            if 0 < costfunc[-2] - costfunc[-1] < error:\r\n                break\r\n\r\n\r\nimport matplotlib.pyplot as plt#\xe7\xbb\x98\xe5\x9b\xbe\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'SimHei\']  # \xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\r\nmpl.rcParams[\'axes.unicode_minus\'] = False   #\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n# \xe7\xbb\x98\xe5\x9b\xbe\xe5\x87\xbd\xe6\x95\xb0\r\ndef figure(title, *datalist):\r\n    for jj in datalist:\r\n        plt.plot(jj[0], \'-\', label=jj[1], linewidth=2)\r\n        plt.plot(jj[0], \'o\')\r\n    plt.grid()\r\n    plt.title(title)\r\n    plt.legend()\r\n    plt.show()\r\n\r\n#\xe8\xae\xa1\xe7\xae\x97R2\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef getR(ydata_tr, ydata_pre):\r\n    sum_error = np.sum(((ydata_tr - np.mean(ydata_tr)) ** 2))\r\n    inexplicable = np.sum(((ydata_tr - ydata_pre) ** 2))\r\n    return 1 - inexplicable / sum_error\r\n\r\n#  \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe7\xa8\x8b\xe5\xba\x8f\r\nif __name__ == ""__main__"":\r\n    train()\r\n    # \xe7\x94\xa8\xe4\xba\x8e\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    predict_result = sess.run(y_out, feed_dict={x_data: x_predict_data})\r\n    # \xe7\x94\xa8\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_pre_result = sess.run(y_out, feed_dict={x_data: x_train_data})\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9b\xbe\r\n    figure(\'\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9b\xbe \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84MSE = %.4f\' % (costfunc[-1]), [costfunc, \'error\'])\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe4\xb8\x8e\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x9b\xbe\r\n    figure(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe4\xb8\x8e\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x9b\xbe \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\' + r\'$R^2=%.4f$\' % (getR(y_train_data, train_pre_result)), [predict_result, \'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\'],\r\n           [y_predict_data, \'\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\'])\r\n    plt.show()\r\n\r\n    # \xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\r\n    print(\'\xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe7\xb3\xbb\xe6\x95\xb0\xe4\xb8\xba:\\n w = %s, \\nb= %s\' % (Weight.eval(session=sess), Bias.eval(session=sess)))\r\n\r\n\r\n\r\n\r\n\r\n'"
Linear Regression/TensorFlow_rewrite.py,9,"b'#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe5\xba\x93\r\nimport tensorflow as tf\r\n\r\n# \xe5\x8f\x82\xe6\x95\xb0\r\n#\xe5\xaf\xb9\xe4\xba\x8e\xe6\xb2\xa1\xe6\x9c\x89\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe4\xb8\x80\xe8\x88\xac\xe8\xa6\x81\xe8\xae\xbe\xe7\xbd\xae\xe8\xbe\x83\xe5\xb0\x8f\xe7\x9a\x84\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\r\ndef train_tf(xxdata, yydata, learn_rate=0.00002, iter_times=6000, error=1e-9):\r\n    #\xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\r\n    # \xe9\xa2\x84\xe5\x85\x88\xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    x_data = tf.placeholder(shape=[None, len(xxdata[0])], dtype=tf.float32)\r\n    y_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\r\n\r\n    # \xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\xe5\x8f\x82\xe6\x95\xb0\r\n    Weight = tf.Variable(tf.random_normal(shape=[len(xxdata[0]), 1]))\r\n    Bias = tf.Variable(tf.random_normal(shape=[1, 1]))\r\n    y_out = tf.add(tf.matmul(x_data, Weight), Bias)\r\n    # \xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\r\n    cost = tf.reduce_mean(tf.square(y_out - y_data)) #+ reg_term\r\n\r\n    # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n    sess = tf.Session()\r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n    optimizer = tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)\r\n\r\n    #\xe8\xaf\xaf\xe5\xb7\xae\xe5\xad\x98\xe5\x82\xa8\r\n    costfunc = []\r\n\r\n    for i in range(iter_times):\r\n\r\n        sess.run(optimizer, feed_dict={x_data: xxdata, y_data: yydata})\r\n\r\n        y_step_out = sess.run(y_out, feed_dict={x_data: xxdata})\r\n\r\n        loss = sess.run(cost, feed_dict={y_out: y_step_out, y_data: yydata})\r\n\r\n        costfunc.append(loss)\r\n\r\n        # \xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\xe5\xbe\xaa\xe7\x8e\xaf\xe7\x9a\x84\xe6\x9c\xba\xe5\x88\xb6\r\n        if len(costfunc) > 1:\r\n            if 0 < costfunc[-2] - costfunc[-1] < error:\r\n                break\r\n    predata = sess.run(y_out, feed_dict={x_data: xxdata})\r\n    return predata, Weight.eval(session=sess), Bias.eval(session=sess)\r\n\r\n\r\n\r\n\r\n\r\n\r\n'"
Logistic Regression/Heart_Data.py,0,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\Heart.csv')\r\n\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe8\xaf\xb4\xe6\x98\x8e\r\n# Attributes types\r\n# -----------------\r\n#\r\n# Real: 1,4,5,8,10,12\r\n# Ordered:11,\r\n# Binary: 2,6,9\r\n# Nominal:7,3,13\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe8\xaf\xb4\xe6\x98\x8e\r\n# Real, Ordered \xef\xbc\x9a \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\n# Nominal  \xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\r\n# Binary \xe4\xb8\x8d\xe5\x81\x9a\xe5\xa4\x84\xe7\x90\x86\r\n\r\n# Variable to be predicted\r\n# ------------------------\r\n# Absence (1) or presence (2) of heart disease\r\n# 0,1\xe7\xbc\x96\xe7\xa0\x81\r\n\r\n# \xe5\xbc\x80\xe5\xa7\x8b\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe3\x80\x90\xe6\xb2\xa1\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe3\x80\x91\r\nnormal = [1, 4, 5, 8, 10, 12, 11]  # \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\r\none_hot = [3, 7, 13] # one_hot\xe7\xbc\x96\xe7\xa0\x81\r\nbinary = [14]  # \xe5\x8e\x9f\xe5\xa7\x8b\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xba1\xe7\x9a\x84\xe4\xbe\x9d\xe7\x84\xb6\xe4\xb8\xba1\xe7\xb1\xbb\xef\xbc\x8c\xe5\x8e\x9f\xe5\xa7\x8b\xe4\xb8\xba2\xe7\x9a\x84\xe5\x8f\x98\xe4\xb8\xba0\xe7\xb1\xbb\r\n\r\n#\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\r\ndef trans(exdata, nor=normal, oh=one_hot, bin=binary):\r\n    keylist = exdata.keys()\r\n    newexdata = pd.DataFrame()\r\n    for ikey in range(len(keylist)):\r\n        if ikey + 1 in nor:\r\n            newexdata[keylist[ikey]] = (exdata[keylist[ikey]] - exdata[keylist[ikey]].mean()) / exdata[keylist[ikey]].std()\r\n        elif ikey + 1 in bin:\r\n            newexdata[keylist[ikey]] = [1 if inum == 1 else 0 for inum in exdata[keylist[ikey]]]\r\n        elif ikey + 1 in oh:\r\n            newdata = pd.get_dummies(exdata[keylist[ikey]], prefix=keylist[ikey])\r\n            newexdata = pd.concat([newexdata,newdata], axis=1)\r\n    return newexdata\r\n\r\nData = trans(data).values\r\nx_pre_data = Data[:, :-1]\r\ny_data = Data[:, -1].reshape(-1, 1)\r\n\r\n#\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe5\x8f\xaf\xe7\x94\xa8\xe4\xba\x8e\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nmodel_data = [x_pre_data, y_data]\r\n\r\n\r\n#\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n#x_pre_data.shape = (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0)\r\n#y_data.shape= (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c1)\r\n\r\n# \xe7\xb1\xbb\xe5\x88\xab\xe8\xaf\xb4\xe6\x98\x8e\r\n# Absence (1) 1\xe7\xb1\xbb\r\n# presence (2) 0\xe7\xb1\xbb\r\n\r\n"""
Logistic Regression/Heart_Spyder.py,0,"b'#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nfrom bs4 import BeautifulSoup as bs\r\nimport urllib\r\n\r\nhtml = urllib.request.urlopen(""http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat"")\r\nbsObj = bs(html.read(), ""html5lib"")\r\nnamest = str(bsObj.body.get_text())\r\n\r\n#\xe5\xb1\x9e\xe6\x80\xa7\xe5\x90\x8d\xe7\xa7\xb0\r\natt_name = [\'Age\',\'Sex\',\'Chest_Pain_Type\',\'Rest_Blood_pre\',\'Serum_Cho\',\'Fast_Blood_Sugar\',\\\r\n            \'Rest_Ele_Result\',\'Max_Heart_Rate\',\'Exercise_Angina\',\'OldPeak\',\'ST\',\'Major_Vess\',\\\r\n            \'Thal\']\r\n#\xe7\xb1\xbb\xe5\x88\xab\xe5\x90\x8d\xe7\xa7\xb0\r\ntype_name =\'Heart_Disease\'\r\n\r\n#\xe6\x9e\x84\xe5\xbb\xba\xe5\xad\x97\xe5\x85\xb8\r\n#\xe6\x9c\x89\xe5\xba\x8f\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f,\xe6\x8c\x89\xe6\xb7\xbb\xe5\x8a\xa0\xe7\x9a\x84\xe5\xba\x8f\xe5\x88\x97\xe8\xbe\x93\xe5\x87\xba\r\nfrom collections import OrderedDict\r\ndatadict=OrderedDict({})\r\nfor keyname in att_name:\r\n    datadict[keyname] = []\r\ndatadict[type_name] =[]\r\n\r\n#\xe6\xb7\xbb\xe5\x8a\xa0\xe6\x95\xb0\xe6\x8d\xae\r\nfor hh in namest.split(\'\\n\'):\r\n    sample = hh.split(\' \')\r\n    if len(sample) > 1:\r\n        for hhh in range(len(sample)):\r\n            try:\r\n                datadict[att_name[hhh]].append(float(sample[hhh]))\r\n            except IndexError:\r\n                datadict[type_name].append(sample[hhh])\r\n    else:\r\n        break\r\n\r\n#\xe5\x86\x99\xe5\x85\xa5\xe6\x96\x87\xe4\xbb\xb6\r\nimport pandas as pd\r\ndf = pd.DataFrame(datadict)\r\ndf.to_csv(r\'C:\\Users\\GWT9\\Desktop\\Heart.csv\', index=False)\r\nprint(\'\xe5\xae\x8c\xe6\xaf\x95\')\r\n'"
Logistic Regression/LR_AnFany.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nfrom Heart_Data import model_data  as H_Data\r\nimport numpy as np\r\n\r\n\r\n#\xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable\r\ndef confusion(realy, outy):\r\n    mix = PrettyTable()\r\n    type = sorted(list(set(realy.T[0])), reverse=True)\r\n    mix.field_names = [\' \'] + [\'\xe9\xa2\x84\xe6\xb5\x8b:%d\xe7\xb1\xbb\'%si for si in type]\r\n    # \xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f\xe5\xad\x98\xe5\x82\xa8\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe6\x95\xb0\xe6\x8d\xae\r\n    cmdict = {}\r\n    for jkj in type:\r\n        cmdict[jkj] = []\r\n        for hh in type:\r\n            hu = len([\'0\' for jj in range(len(realy)) if realy[jj][0] == jkj and outy[jj][0] == hh])\r\n            cmdict[jkj].append(hu)\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe8\xa1\xa8\xe6\xa0\xbc\r\n    for fu in type:\r\n        mix.add_row([\'\xe7\x9c\x9f\xe5\xae\x9e:%d\xe7\xb1\xbb\'%fu] + cmdict[fu])\r\n    return mix\r\n\r\n# \xe8\xbf\x94\xe5\x9b\x9e\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x94\xa8\xe5\x88\xb0\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xaeTP\xef\xbc\x8cTN\xef\xbc\x8cFP\xef\xbc\x8cFN\r\ndef getmatrix(realy, outy, possclass=1): # \xe9\xbb\x98\xe8\xae\xa4\xe7\xb1\xbb1 \xe4\xb8\xba\xe6\xad\xa3\xe7\xb1\xbb\r\n    TP = len([\'0\' for jj in range(len(realy)) if realy[jj][0] == possclass and outy[jj][0] == possclass]) # \xe5\xae\x9e\xe9\x99\x85\xe6\xad\xa3\xe9\xa2\x84\xe6\xb5\x8b\xe6\xad\xa3\r\n\r\n    TN = len([\'0\' for jj in range(len(realy)) if realy[jj][0] == 1 - possclass and outy[jj][0] == 1 - possclass])  # \xe5\xae\x9e\xe9\x99\x85\xe8\xb4\x9f\xe9\xa2\x84\xe6\xb5\x8b\xe8\xb4\x9f\r\n\r\n    FP = len([\'0\' for jj in range(len(realy)) if realy[jj][0] == 1- possclass and outy[jj][0] == possclass]) # \xe5\xae\x9e\xe9\x99\x85\xe8\xb4\x9f\xe9\xa2\x84\xe6\xb5\x8b\xe6\xad\xa3\r\n\r\n    FN = len([\'0\' for jj in range(len(realy)) if realy[jj][0] ==  possclass and outy[jj][0] == 1 - possclass])  # \xe5\xae\x9e\xe9\x99\x85\xe6\xad\xa3\xe9\xa2\x84\xe6\xb5\x8b\xe8\xb4\x9f\r\n\r\n    # \xe5\x81\x87\xe6\xad\xa3\xe7\x8e\x87\r\n    FPR = FP / (FP + TN)\r\n\r\n    # \xe7\x9c\x9f\xe6\xad\xa3\xe7\x8e\x87\r\n    TPR = TP / (TP + FN)\r\n\r\n    return [FPR, TPR]\r\n\r\nclass LRReg:\r\n    def __init__(self, learn_rate=0.5, iter_times=40000, error=1e-9, cpn=\'L2\'):\r\n        self.learn_rate = learn_rate\r\n        self.iter_times = iter_times\r\n        self.error = error\r\n        self.cpn = cpn\r\n\r\n    # w\xe5\x92\x8cb\xe5\x90\x88\xe4\xb8\xba\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xafx\xe6\x9c\x80\xe5\x90\x8e\xe5\x8a\xa0\xe4\xb8\x8a\xe4\xb8\x80\xe5\x88\x97\xe5\x85\xa8\xe4\xb8\xba1\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x82\r\n    def trans(self, xdata):\r\n        one1 = np.ones(len(xdata))\r\n        xta = np.append(xdata, one1.reshape(-1, 1), axis=1)\r\n        return xta\r\n\r\n    # \xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\r\n    def Gradient(self, xdata, ydata, func=trans):\r\n        xdata = func(self, xdata)\r\n        # \xe7\xb3\xbb\xe6\x95\xb0w,b\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n        self.weights = np.zeros((len(xdata[0]), 1))\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\r\n        cost_function = []\r\n\r\n        for i in range(self.iter_times):\r\n            # \xe5\xbe\x97\xe5\x88\xb0\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe5\x80\xbc\r\n            y_predict = np.dot(xdata, self.weights)\r\n\r\n            # Sigmoid\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\r\n            s_y_pre = 1/ (1 + np.exp(-y_predict))\r\n\r\n            # \xe8\xae\xa1\xe7\xae\x97\xe6\x9c\x80\xe5\xa4\xa7\xe4\xbc\xbc\xe7\x84\xb6\xe7\x9a\x84\xe5\x80\xbc\r\n            like = np.sum(np.dot(ydata.T, np.log(s_y_pre)) + np.dot((1 - ydata).T, np.log(1- s_y_pre)))\r\n\r\n            # \xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\r\n            if self.cpn == \'L2\':\r\n                # \xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xad\xe6\xb7\xbb\xe5\x8a\xa0\xe7\xb3\xbb\xe6\x95\xb0\xe7\x9a\x84L2\xe8\x8c\x83\xe6\x95\xb0\r\n                l2norm = np.sum(0.5 * np.dot(self.weights.T, self.weights) / len(xdata))\r\n                cost = -like / len(xdata) + l2norm\r\n\r\n                grad_W = np.dot(xdata.T, (s_y_pre - ydata)) / len(xdata) + 0.9 * self.weights / len(xdata)\r\n\r\n            else:\r\n                cost = -like / (len(xdata))\r\n                grad_W = np.dot(xdata.T, (s_y_pre - ydata)) / len(xdata)\r\n\r\n            cost_function.append(cost)\r\n            print(cost, like)\r\n\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\r\n            if len(cost_function) > 2:\r\n                if 0 <= cost_function[-1] - cost_function[-2] <= self.error:\r\n                    break\r\n\r\n            #\xe6\x9b\xb4\xe6\x96\xb0\r\n            self.weights = self.weights - self.learn_rate * grad_W\r\n\r\n        return self.weights, cost_function\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    def predict(self, xdata, func=trans, yuzhi=0.5):\r\n        pnum = np.dot(func(self, xdata), self.weights)\r\n        s_pnum = 1/ (1 + np.exp(-pnum))\r\n        latnum = [[1] if jj[0] >= yuzhi else [0] for jj in s_pnum]\r\n        return latnum\r\n\r\n\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\nif __name__ == ""__main__"":\r\n    lr_re = LRReg()\r\n\r\n    lf = lr_re.Gradient(H_Data[0], H_Data[1])\r\n\r\n    print(\'\xe7\xb3\xbb\xe6\x95\xb0\xe4\xb8\xba\xef\xbc\x9a\\n\', lr_re.weights)\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6ROC\xe6\x9b\xb2\xe7\xba\xbf\r\n    # \xe4\xbb\x8e0\xe5\x88\xb01\xe5\xae\x9a\xe4\xb9\x89\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe9\x98\x88\xe5\x80\xbc\r\n    yuzi = np.linspace(0, 1, 101)\r\n\r\n    # ROC \xe6\x9b\xb2\xe7\xba\xbf\xe6\x95\xb0\xe6\x8d\xae\r\n    roc = []\r\n    #  \xe5\xbc\x80\xe5\xa7\x8b\xe9\x81\x8d\xe5\x8e\x86\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe9\x98\x88\xe5\x80\xbc\r\n    for yy in yuzi:\r\n        fdatd = lr_re.predict(H_Data[0], yuzhi=yy)\r\n        if yy == 0.5:\r\n            print(\'\xe9\x98\x88\xe5\x80\xbc\xe4\xb8\xba%s\xe6\x97\xb6\xe7\x9a\x84\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n\' % yy, confusion(H_Data[1], fdatd))\r\n        roc.append(getmatrix(H_Data[1], fdatd))\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6ROC\xe6\x9b\xb2\xe7\xba\xbf\xe5\x9b\xbe\r\n    # \xe9\xa6\x96\xe7\xba\xbf\xe6\x98\xafFPR\xe6\x8c\x89\xe7\x9d\x80\xe4\xbb\x8e\xe5\xb0\x8f\xe5\x88\xb0\xe5\xa4\xa7\xe6\x8e\x92\xe5\x88\x97\r\n    fu = np.array(sorted(roc, key=lambda x: x[0]))\r\n\r\n\r\n    import matplotlib.pyplot as plt\r\n    from pylab import mpl  # \xe4\xbd\x9c\xe5\x9b\xbe\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\n    mpl.rcParams[\'font.sans-serif\'] = [\'Microsoft Yahei\']\r\n\r\n    #  \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x88\xb6ROC\xe6\x9b\xb2\xe7\xba\xbf\xe5\x9b\xbe\r\n    fig, ax1 = plt.subplots()\r\n    ax1.plot(list(fu[:, 0]), list(fu[:, 1]), \'.\', linewidth=4, color=\'r\')\r\n    ax1.plot([0, 1], \'--\', linewidth=4)\r\n    ax1.grid(\'on\')\r\n    ax1.legend([\'\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8\xe6\xa8\xa1\xe5\x9e\x8b\', \'\xe9\x9a\x8f\xe6\x9c\xba\xe5\x88\xa4\xe6\x96\xad\xe6\xa8\xa1\xe5\x9e\x8b\'], loc=\'lower right\', shadow=True, fontsize=\'medium\')\r\n    ax1.annotate(\'\xe5\xae\x8c\xe7\xbe\x8e\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8\', xy=(0, 1), xytext=(0.2, 0.7), color=\'#FF4589\', arrowprops=dict(facecolor=\'#FF67FF\'))\r\n\r\n    ax1.set_title(\'ROC\xe6\x9b\xb2\xe7\xba\xbf\', color=\'#123456\')\r\n    ax1.set_xlabel(\'False Positive Rate(FPR\xef\xbc\x8c\xe5\x81\x87\xe6\xad\xa3\xe7\x8e\x87)\', color=\'#123456\')\r\n    ax1.set_ylabel(\'True Positive Rate(TPR\xef\xbc\x8c\xe7\x9c\x9f\xe6\xad\xa3\xe7\x8e\x87)\', color=\'#123456\')\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\xbe\r\n    fig, ax2 = plt.subplots()\r\n    ax2.plot(list(range(len(lf[1]))), lf[1], \'-\', linewidth=5)\r\n    ax2.set_title(\'\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\xbe\')\r\n    ax2.set_ylabel(\'Cost \xe5\x80\xbc\')\r\n    ax2.set_xlabel(\'\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\')\r\n    plt.show()\r\n\r\n\r\n'"
Logistic Regression/LR_Compare.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe4\xb8\x89\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\r\nimport LR_AnFany as LR_A  # AnFany\r\nimport LR_Sklearn as LR_S # Sklearn\r\nimport LR_TensorFlow as LR_T # TensorFlow\r\nfrom pylab import mpl  # \xe4\xbd\x9c\xe5\x9b\xbe\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe6\x96\xb0\xe5\xae\x8b\xe4\xbd\x93\r\nmpl.rcParams[\'axes.unicode_minus\'] = False\r\n\r\n\r\nimport numpy as np\r\n#\xe9\x9a\x8f\xe6\x9c\xba\xe7\x94\x9f\xe6\x88\x90\xe4\xba\x8c\xe5\x85\x83\xe4\xba\x8c\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae: \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\xe4\xb8\xba6:4\xe3\x80\x82\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\x8d\xe8\x83\xbd\xe9\x87\x8d\xe6\x96\xb0\xe9\x9a\x8f\xe6\x9c\xba\xe7\x94\x9f\xe6\x88\x90\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe5\x88\x86\xe5\xb8\x83\xe4\xb8\x8d\xe5\x90\x8c\xe4\xba\x86\xe3\x80\x82\r\n#np.random.seed(828)\r\nx_data = np.random.random((900, 2))\r\ny_data = np.array([[1] if 0.3*a[0] + 0.6*a[1] + 0.55 >= 1 else [0] for a in x_data])\r\n\r\n#\xe6\x8b\x86\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\ndef divided(xdata, ydata, percent=0.4):\r\n    sign_list = list(range(len(xdata)))\r\n    #\xe7\x94\xa8\xe4\xba\x8e\xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84\xe5\xba\x8f\xe5\x8f\xb7\r\n    select_sign = sorted(np.random.choice(sign_list, int(len(xdata)*percent), replace=False))\r\n\r\n    #\xe7\x94\xa8\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xba\x8f\xe5\x8f\xb7\r\n    no_select_sign = [isign for isign in sign_list if isign not in select_sign]\r\n\r\n    #\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\n    x_predict_data = xdata[select_sign]\r\n    y_predict_data = ydata[select_sign].reshape(len(select_sign), 1)#\xe8\xbd\xac\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n\r\n    #\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n    x_train_data = xdata[no_select_sign]\r\n    y_train_data = ydata[no_select_sign].reshape(len(no_select_sign), 1)#\xe8\xbd\xac\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n\r\n    return x_train_data, y_train_data, x_predict_data, y_predict_data #\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84x\xef\xbc\x8cy;  \xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84x\xef\xbc\x8cy\r\n\r\n\r\nalldata = divided(x_data, y_data)\r\n\r\n\r\n#\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84Xdata\r\ntrain_x_data, train_y_data, pre_x_data, pre_y_data = alldata\r\n\r\n#########\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\xe8\xae\xad\xe7\xbb\x83\r\n\r\n#AnFany\r\nlr_re = LR_A.LRReg()\r\nlf = lr_re.Gradient(train_x_data, train_y_data)\r\ndatd = lr_re.predict(pre_x_data)\r\n# print(\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n\', LR_A.confusion(pre_y_data, datd))\r\n\r\n\r\n#Sklearn\r\nregre = LR_S.sklr.fit(train_x_data, train_y_data.T[0])\r\npfdata = LR_S.sklr.predict(pre_x_data)\r\nweig = regre.coef_.T\r\nweig = np.array([np.append(weig, regre.intercept_)]).T\r\ndm = LR_S.confusion_matrix(pre_y_data.T[0], pfdata)\r\n# print(\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n\', LR_S.confusion(dm))\r\n\r\n\r\n#TensorFlow\r\nypre = LR_T.trans_tf(train_x_data, train_y_data, pre_x_data)\r\ntfweib = np.vstack((ypre[2], ypre[3]))\r\n# print(\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n\', LR_A.confusion(pre_y_data, ypre[1]))\r\n\r\nLR_T.sess.close() # \xe4\xb8\x8d\xe5\x8a\xa0\xe8\xbf\x99\xe4\xb8\x80\xe5\x8f\xa5\xef\xbc\x8c\xe4\xb8\x80\xe5\xae\x9a\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99;\xe5\x8a\xa0\xe4\xba\x86\xef\xbc\x8c\xe5\x8f\xaf\xe8\x83\xbd\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99\xe3\x80\x82\xe6\x8a\xa5\xe9\x94\x99\xe4\xb8\x8d\xe5\xbd\xb1\xe5\x93\x8d\xe7\xbb\x93\xe6\x9e\x9c\r\n\r\n###############\xe7\xbb\x93\xe6\x9e\x9c\xe5\x9b\xbe\xe7\xa4\xba\xe8\xbe\x93\xe5\x87\xba\r\n\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe6\x95\xb0\xe6\x8d\xae\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\r\nimport matplotlib.pyplot as plt\r\ndef fir(datax, datay, nametotle=\'\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\'):\r\n    #\xe7\x94\x9f\xe6\x88\x90\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xb0\x86X\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe4\xb8\xba2\xe7\xb1\xbb\r\n    datax1 = datax[datay.T[0] == 1]\r\n    datax2 = datax[datay.T[0] == 0]\r\n\r\n    # \xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\r\n    plt.scatter(datax1[:, 0], datax1[:, -1], c=\'r\', s=28)\r\n    plt.scatter(datax2[:, 0], datax2[:, -1], marker=\'^\', c=\'b\', s=28)\r\n    plt.title(nametotle)\r\n    plt.xlabel(\'X1 \xe5\x80\xbc\')\r\n    plt.ylabel(\'X2 \xe5\x80\xbc\')\r\n\r\n#\xe8\xbe\x93\xe5\x87\xba\xe5\x88\x86\xe5\x89\xb2\xe7\xba\xbf\xe7\x9a\x84\xe8\xa1\xa8\xe8\xbe\xbe\xe5\xbc\x8f\r\ndef outexpre(weifgt, x=[\'x1\', \'x2\', \'\']):\r\n    expression = \'\'\r\n    for hh in range(len(weifgt)):\r\n        if hh == 0:\r\n            expression += \'%s%s\'%(weifgt[hh][0], x[hh])\r\n        else:\r\n            if weifgt[hh] > 0:\r\n                expression += \'+%s%s\'%(weifgt[hh][0], x[hh])\r\n            else:\r\n                expression += \'%s%s\'%(weifgt[hh][0], x[hh])\r\n    return expression\r\n\r\n\r\n#\xe4\xb8\x89\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe7\xb3\xbb\xe6\x95\xb0\xe5\x80\xbc\xe4\xb8\xbaw1,w2,b   \xe7\x9b\xb4\xe7\xba\xbf\xe6\x96\xb9\xe7\xa8\x8b\xe4\xb8\xbaw1*x1+w2*x2+b=0\r\n#\xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x89\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\xe5\x90\x84\xe8\x87\xaa\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe7\x9b\xb4\xe7\xba\xbf\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\ndef tnd_ydata(datdxx, weights):\r\n    dmin = datdxx[:, 0]\r\n    minm = dmin.min()\r\n    maxm = dmin.max()\r\n    xda =  np.linspace(minm - 0.2, maxm + 0.2, 1000)\r\n    yda = [(- weights[2][0] - hh * weights[0][0]) / weights[1][0] for hh in xda]\r\n    return xda, yda\r\n\r\n\r\nAf_data = tnd_ydata(train_x_data, lr_re.weights)\r\nSk_data = tnd_ydata(train_x_data, weig)\r\nTf_data = tnd_ydata(train_x_data, tfweib)\r\n#\xe9\xa6\x96\xe5\x85\x88\xe7\xbb\x98\xe5\x88\xb6 \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe4\xb8\x89\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe5\x88\x86\xe5\x89\xb2\xe7\xba\xbf\xe7\x9a\x84\xe6\x96\xb9\xe7\xa8\x8b\r\nplt.plot()\r\nfir(train_x_data, train_y_data) #\xe7\xbb\x98\xe5\x88\xb6\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\nplt.plot(Af_data[0], Af_data[1], \'-\', c=\'b\', linewidth=1)\r\nplt.plot(Sk_data[0], Sk_data[1], \'-\', c=\'r\', linewidth=1)\r\nplt.plot(Tf_data[0], Tf_data[1], \'-\', c=\'g\', linewidth=1)\r\nplt.title(\'\xe4\xb8\x89\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84""\xe5\x88\x86\xe5\x89\xb2\xe7\xba\xbf""\xe5\xaf\xb9\xe6\xaf\x94\')\r\nplt.legend([\'AnFany: %s\'%outexpre(lr_re.weights), \'Sklearn\xef\xbc\x9a%s\'%outexpre(weig), \'TensorFlow\xef\xbc\x9a%s\'%outexpre(tfweib),\'1\xe7\xb1\xbb\', \'0\xe7\xb1\xbb\'])\r\nplt.show()\r\n\r\nAf_data_pre = tnd_ydata(pre_x_data, lr_re.weights)\r\nSk_data_pre = tnd_ydata(pre_x_data, weig)\r\nTf_data_pre = tnd_ydata(pre_x_data, tfweib)\r\n#\xe5\x86\x8d\xe6\xac\xa1\xe7\xbb\x98\xe5\x88\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe4\xb8\x89\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\xe7\x9a\x84\xe8\xa1\xa8\xe7\x8e\xb0\r\nplt.subplot(2, 2, 1)\r\nfir(pre_x_data, pre_y_data, nametotle=\'\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\') #\xe7\xbb\x98\xe5\x88\xb6\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\nplt.plot(Af_data_pre[0], Af_data_pre[1], \'-\', c=\'b\', label=\'AnFany\', linewidth=1)\r\nplt.legend()\r\n\r\n\r\nplt.subplot(2, 2, 2)\r\nfir(pre_x_data, pre_y_data, nametotle=\'\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\') #\xe7\xbb\x98\xe5\x88\xb6\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\nplt.plot(Sk_data_pre[0], Sk_data_pre[1], \'-\', c=\'r\', label=\'Sklearn\', linewidth=1)\r\nplt.legend()\r\n\r\nplt.subplot(2, 2, 3)\r\nfir(pre_x_data, pre_y_data, nametotle=\'\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\') #\xe7\xbb\x98\xe5\x88\xb6\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\nplt.plot(Tf_data_pre[0], Tf_data_pre[1], \'-\', c=\'g\', label=\'TensorFlow\', linewidth=1)\r\nplt.legend()\r\n\r\nplt.subplot(2, 2, 4)\r\nplt.title(\'\xe4\xb8\x89\xe7\xa7\x8d\xe5\xae\x9e\xe7\x8e\xb0\xe6\x96\xb9\xe5\xbc\x8f\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe5\xaf\xb9\xe6\xaf\x94\')\r\nplt.text(0.3, 0.6, LR_A.confusion(pre_y_data, datd))\r\nplt.text(0.32, 0.8, \'AnFany\')\r\nplt.text(0.3, 0.3, LR_S.confusion(dm))\r\nplt.text(0.32, 0.5, \'Sklearn\')\r\nplt.text(0.3, 0.0, LR_A.confusion(pre_y_data, ypre[1]))\r\nplt.text(0.32, 0.2, \'TensorFlow\')\r\nplt.axis(\'off\')\r\n\r\n\r\n\r\nplt.show()\r\n'"
Logistic Regression/LR_Sklearn.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nfrom Heart_Data import model_data  as H_Data\r\nfrom sklearn.linear_model import LogisticRegression\r\nfrom sklearn.metrics import confusion_matrix\r\nsklr = LogisticRegression(penalty=\'l2\', tol=10, solver=\'lbfgs\',max_iter=9000)\r\n\r\n#\xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable\r\n\r\ndef confusion(ccmatrix):\r\n    mix = PrettyTable()\r\n    type = sorted(list(range(len(ccmatrix))), reverse=True)\r\n    mix.field_names = [\' \'] + [\'\xe9\xa2\x84\xe6\xb5\x8b:%d\xe7\xb1\xbb\'%si for si in type]\r\n    # \xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f\xe5\xad\x98\xe5\x82\xa8\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe6\x95\xb0\xe6\x8d\xae\r\n    for fu in type:\r\n        frru = [\'\xe7\x9c\x9f\xe5\xae\x9e:%d\xe7\xb1\xbb\'%fu] + list(ccmatrix[fu][::-1])\r\n        mix.add_row(frru)\r\n    return mix\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\nif __name__ == ""__main__"":\r\n    regre = sklr.fit(H_Data[0], H_Data[1].T[0])\r\n\r\n    predata = sklr.predict(H_Data[0])\r\n\r\n    cm = confusion_matrix(H_Data[1].T[0], predata)\r\n\r\n    print(\'\xe7\xb3\xbb\xe6\x95\xb0\xe4\xb8\xba\xef\xbc\x9a\\n\', sklr.coef_, \'\\n\', sklr.intercept_)\r\n\r\n    print(\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\xba\xef\xbc\x9a\\n\', confusion(cm))\r\n\r\n\r\n'"
Logistic Regression/LR_TensorFlow.py,16,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nfrom Heart_Data import model_data  as H_Data\r\nimport tensorflow as tf\r\nsess = tf.Session()\r\n#\xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable\r\ndef confusion(realy, outy):\r\n    mix = PrettyTable()\r\n    type = sorted(list(set(realy.T[0])), reverse=True)\r\n    mix.field_names = [\' \'] + [\'\xe9\xa2\x84\xe6\xb5\x8b:%d\xe7\xb1\xbb\'%si for si in type]\r\n    # \xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f\xe5\xad\x98\xe5\x82\xa8\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe6\x95\xb0\xe6\x8d\xae\r\n    cmdict = {}\r\n    for jkj in type:\r\n        cmdict[jkj] = []\r\n        for hh in type:\r\n            hu = len([\'0\' for jj in range(len(realy)) if realy[jj][0] == jkj and outy[jj][0] == hh])\r\n            cmdict[jkj].append(hu)\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe8\xa1\xa8\xe6\xa0\xbc\r\n    for fu in type:\r\n        mix.add_row([\'\xe7\x9c\x9f\xe5\xae\x9e:%d\xe7\xb1\xbb\'%fu] + cmdict[fu])\r\n    return mix\r\n\r\n# \xe6\x9e\x84\xe5\xbb\xba\xe5\x87\xbd\xe6\x95\xb0\r\ndef trans_tf(datax, datay, prea, learn_rate=0.5, iter_tiems=40000, error=1e-9, con=\'L2\'):\r\n    # \xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\r\n    x_data = tf.placeholder(shape=[None, len(datax[0])], dtype=tf.float32)\r\n    y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\r\n    # \xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe5\x8f\x82\xe6\x95\xb0\r\n    Weight = tf.Variable(tf.random_normal(shape=[len(datax[0]), 1]), dtype=tf.float32)\r\n    Bias = tf.Variable(tf.random_normal(shape=[1, 1]), dtype=tf.float32)\r\n\r\n\r\n    model_output = tf.add(tf.matmul(x_data, Weight), Bias)\r\n\r\n    tf.add_to_collection(tf.GraphKeys.WEIGHTS, Weight)\r\n    regularizer = tf.contrib.layers.l2_regularizer(scale=2 / 2000)\r\n    reg_term = tf.contrib.layers.apply_regularization(regularizer)\r\n\r\n    # \xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\r\n    if con == \'L2\':\r\n        # \xe6\x8d\x9f\xe5\xa4\xb1\xe5\x87\xbd\xe6\x95\xb0\r\n        costfunc = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output, labels=y_target)) + reg_term\r\n    else:\r\n        costfunc = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output, labels=y_target))\r\n\r\n    # \xe5\x88\xa9\xe7\x94\xa8\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\r\n    #optimizer = tf.train.GradientDescentOptimizer(learn_rate) # \xe6\xa2\xaf\xe5\xba\xa6\r\n    #optimizer = tf.train.MomentumOptimizer(learning_rate=learn_rate, momentum=0.9) # \xe5\x8a\xa8\xe9\x87\x8f\xe6\xb3\x95\r\n    #optimizer = tf.train.AdadeltaOptimizer(learning_rate=learn_rate, rho=0.55, epsilon=1e-08)\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=learn_rate, beta1=0.9, beta2=0.99, epsilon=1e-08)\r\n    trainstep = optimizer.minimize(costfunc)\r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n\r\n    loss_vec = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n    for i in range(iter_tiems):\r\n        sess.run(trainstep, feed_dict={x_data: datax, y_target: datay})\r\n        temp_loss = sess.run(costfunc, feed_dict={x_data: datax, y_target: datay})\r\n        loss_vec.append(temp_loss)\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\r\n        if len(loss_vec) > 2:\r\n            if loss_vec[-2] - loss_vec[-1] >= 0 and (loss_vec[-2] - loss_vec[-1]) <= error:\r\n                break\r\n\r\n    predata = sess.run(model_output, feed_dict={x_data: prea})\r\n\r\n    #\xe8\xbd\xac\xe5\x8c\x96\r\n    trans_predata = [[1] if jj[0] >= 0 else [0] for jj in predata]\r\n\r\n    return loss_vec, trans_predata, Weight.eval(session=sess), Bias.eval(session=sess)\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\nif __name__ == ""__main__"":\r\n    ypre = trans_tf(H_Data[0], H_Data[1], H_Data[0])\r\n\r\n    print(\'\xe7\xb3\xbb\xe6\x95\xb0\xe4\xb8\xba\xef\xbc\x9a\\n\', ypre[2], \'\\n\', ypre[3])\r\n\r\n    print(\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n\', confusion(H_Data[1], ypre[1]))\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\xbe\r\n    import matplotlib.pyplot as plt\r\n    from pylab import mpl  # \xe4\xbd\x9c\xe5\x9b\xbe\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\n\r\n    mpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe6\x96\xb0\xe5\xae\x8b\xe4\xbd\x93\r\n\r\n    plt.plot(list(range(len(ypre[0]))), ypre[0], \'-\', linewidth=5)\r\n    plt.title(\'\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\xbe\')\r\n    plt.ylabel(\'Cost \xe5\x80\xbc\')\r\n    plt.xlabel(\'\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\')\r\n    plt.grid(\'off\')\r\n    plt.show()\r\n\r\n'"
SVM/coor_de.py,0,"b""#  # -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\x9d\x90\xe6\xa0\x87\xe4\xb8\x8a\xe5\x8d\x87(\xe6\xb1\x82\xe6\x9e\x81\xe5\xa4\xa7\xe5\x80\xbc)/\xe4\xb8\x8b\xe9\x99\x8d(\xe6\xb1\x82\xe6\x9e\x81\xe5\xb0\x8f\xe5\x80\xbc)\xe6\xb3\x95\r\n\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom matplotlib import cm\r\nfrom mpl_toolkits.mplot3d import Axes3D\r\nfrom pylab import mpl\r\nmpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\nmpl.rcParams['axes.unicode_minus'] = False # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe7\x9b\xae\xe6\xa0\x87\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe5\xbf\x85\xe9\xa1\xbb\xe6\x98\xaf\xe5\x87\xb8\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe5\x90\xa6\xe5\x88\x99\xe5\x8f\xaa\xe8\x83\xbd\xe5\x88\xb0\xe8\xbe\xbe\xe5\xb1\x80\xe9\x83\xa8\xe6\x9c\x80\xe4\xbc\x98\xe5\x80\xbc\r\ndef tar(a, b):\r\n    return 3 * a ** 2 + 5 * b ** 2 + 4 * a * b + 14 * a - 6 * b - 45\r\n\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\r\nA = np.arange(-10, 10, 0.2)\r\nB = np.arange(-10, 10, 0.2)\r\nA, B = np.meshgrid(A, B)\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe4\xb8\x89\xe7\xbb\xb4\xe5\x9b\xbe\xe5\x83\x8f\r\nfig = plt.figure()\r\nax = Axes3D(fig)\r\nsur = ax.plot_surface(A, B, tar(A, B), rstride=10, cstride=10, cmap=cm.YlGnBu_r)\r\nfig.colorbar(sur, shrink=0.3)\r\n\r\n# \xe5\xbc\x80\xe5\xa7\x8b\xe5\x9d\x90\xe6\xa0\x87\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe5\x88\x9d\xe5\xa7\x8b\xe5\x80\xbc\r\nalist = [9]\r\nblist = [9]\r\n\r\nfunlist = [tar(alist[-1], blist[-1])]\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe7\xbb\x93\xe6\x9d\x9f\xe5\xbe\xaa\xe7\x8e\xaf\xe7\x9a\x84\xe6\x9d\xa1\xe4\xbb\xb6\r\n\r\nstop = 1\r\n\r\nwhile stop > 0.0000001:\r\n    # a\xe7\x9c\x8b\xe4\xbd\x9c\xe5\xb7\xb2\xe7\x9f\xa5\xe9\x87\x8f\xef\xbc\x8c\xe6\x9b\xb4\xe6\x96\xb0b\xe5\x80\xbc\r\n    b = (3 - 2 * alist[-1]) / 5\r\n    # b\xe7\x9c\x8b\xe4\xbd\x9c\xe5\xb7\xb2\xe7\x9f\xa5\xe9\x87\x8f\xef\xbc\x8c\xe6\x9b\xb4\xe6\x96\xb0a\xe5\x80\xbc\r\n    a = - (7 + 2 * blist[-1]) / 3\r\n\r\n    alist.append(a)\r\n    blist.append(b)\r\n    funlist.append(tar(a, b))\r\n\r\n    stop = abs(funlist[-1] - funlist[-2])\r\n\r\n# \xe7\xbb\x93\xe6\x9d\x9f\xe5\x90\x8e\xef\xbc\x8c\xe5\x9c\xa8\xe4\xb8\x89\xe7\xbb\xb4\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\xbe\xe5\x83\x8f\xe4\xb8\xad\xe6\xb7\xbb\xe5\x8a\xa0\xe8\xb7\xaf\xe5\xbe\x84\r\nax.plot(alist, blist, funlist, linewidth=4, color='#FFFFFF')\r\nax.set_xlabel('a\xe5\x80\xbc')\r\nax.set_ylabel('b\xe5\x80\xbc')\r\nax.set_zlabel('\xe7\x9b\xae\xe6\xa0\x87\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc')\r\nplt.title('\xe5\x9d\x90\xe6\xa0\x87\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\xe6\xb1\x82\xe5\xbe\x97\xe6\x9e\x81\xe5\xb0\x8f\xe5\x80\xbc\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84')\r\n\r\nplt.show()\r\n\r\n\r\n"""
Softmax Regression/Iris_Data.py,0,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\n\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\iris.csv')\r\n\r\n# y\xe5\x80\xbcSoftmax\r\nydata = data['Species'].values\r\n# x\xe5\x80\xbc\r\nxdata = data.iloc[:, 1:5].values\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\r\nimport numpy as np\r\n\r\n# x\xe6\x95\xb0\xe6\x8d\xae\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\nhandle_x_data = (xdata - np.mean(xdata, axis=0)) / np.std(xdata, axis=0)\r\n\r\n# y\xe6\x95\xb0\xe6\x8d\xae\xe7\x8b\xac\xe7\x83\xad\xe5\x8c\x96\r\nydata = pd.get_dummies(data['Species']).values\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xba\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe7\xb1\xbb\xe5\x88\xab\xe6\xaf\x94\xe8\xbe\x83\xe9\x9b\x86\xe4\xb8\xad\xef\xbc\x8c\xe4\xb8\x8d\xe6\x98\x93\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe6\x89\x93\xe4\xb9\xb1\xe6\x95\xb0\xe6\x8d\xae\r\n\r\n# \xe9\xa6\x96\xe5\x85\x88\xe5\xb0\x86x\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8cy\xe6\x95\xb0\xe6\x8d\xae\xe5\x90\x88\xe5\x9c\xa8\xe4\xb8\x80\xe8\xb5\xb7\r\nxydata = np.hstack((handle_x_data, ydata))\r\n# \xe6\x89\x93\xe4\xb9\xb1\xe9\xa1\xba\xe5\xba\x8f\r\nnp.random.shuffle(xydata)\r\n\r\n# \xe5\x88\x86\xe7\xa6\xbb\xe6\x95\xb0\xe6\x8d\xae\r\n\r\nX_DATA = xydata[:, :4]\r\n\r\nY_DATA = xydata[:, 4:]\r\n\r\nData = [X_DATA, Y_DATA]\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n\r\n# X_DATA.shape = (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0, \xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0)\r\n# Y_DATA.shape = (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0, \xe7\xb1\xbb\xe5\x88\xab\xe6\x95\xb0)\r\n\r\n# \xe7\xb1\xbb\xe5\x88\xab\r\n# setosa  [1,0,0]\r\n# versicolor [0,1,0]\r\n# virginica  [0,0,1]\r\n\r\n\r\n\r\n"""
Softmax Regression/Iris_Spyder.py,0,"b'#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nfrom bs4 import BeautifulSoup as bs\r\nimport urllib\r\n\r\n\r\nhtml = urllib.request.urlopen(""https://en.wikipedia.org/wiki/Iris_flower_data_set#Data_set"")\r\n\r\nbsObj = bs(html.read(), ""html5lib"")\r\n\r\n\r\n# \xe5\xad\x97\xe6\xae\xb5\xe5\x88\x97\xe8\xa1\xa8\r\nziduan = []\r\nfor hh in bsObj.find_all(\'table\', class_=\'wikitable sortable mw-collapsible mw-collapsed\'):\r\n    for ii in hh.find_all(\'th\'):\r\n        fu = ii.get_text().split()\r\n        zi = (\'_\').join(fu)\r\n        exec(\'%s = []\' % zi)\r\n        ziduan.append(zi)\r\n    fu = 0\r\n    for jj in hh.find_all(\'td\'):\r\n        ty = jj.get_text().split()\r\n        try:\r\n            float(ty[0])\r\n            exec(\'%s.append(%.2f)\' % (ziduan[fu % 6], float(ty[0])))\r\n        except ValueError:\r\n            exec(\'%s.append(""%s"")\' % (ziduan[fu % 6], str(ty[-1])))\r\n        fu += 1\r\n\r\n\r\n#\xe6\x9c\x89\xe5\xba\x8f\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f,\xe6\x8c\x89\xe6\xb7\xbb\xe5\x8a\xa0\xe7\x9a\x84\xe5\xba\x8f\xe5\x88\x97\xe8\xbe\x93\xe5\x87\xba\r\nfrom collections import OrderedDict\r\ndatadict=OrderedDict({})\r\n\r\nfor keyname in ziduan:\r\n    datadict[keyname] = eval(keyname)\r\n\r\n\r\n\r\n#\xe5\x86\x99\xe5\x85\xa5\xe6\x96\x87\xe4\xbb\xb6\r\nimport pandas as pd\r\ndf = pd.DataFrame(datadict)\r\ndf.to_csv(r\'C:\\Users\\GWT9\\Desktop\\Iris.csv\', index=False)\r\nprint(\'\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n'"
Softmax Regression/Softmax_AnFany.py,0,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nfrom Iris_Data import Data as smdata\r\nimport numpy as np\r\n\r\n\r\nclass LRReg:\r\n    def __init__(self, learn_rate=0.9, iter_times=40000, error=1e-17):\r\n        self.learn_rate = learn_rate\r\n        self.iter_times = iter_times\r\n        self.error = error\r\n\r\n    # w\xe5\x92\x8cb\xe5\x90\x88\xe4\xb8\xba\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xafx\xe6\x9c\x80\xe5\x90\x8e\xe5\x8a\xa0\xe4\xb8\x8a\xe4\xb8\x80\xe5\x88\x97\xe5\x85\xa8\xe4\xb8\xba1\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x82\r\n    def trans(self, xdata):\r\n        one1 = np.ones(len(xdata))\r\n        xta = np.append(xdata, one1.reshape(-1, 1), axis=1)\r\n        return xta\r\n\r\n    # \xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\r\n    def Gradient(self, xdata, ydata, func=trans):\r\n        xdata = func(self, xdata)\r\n        # \xe7\xb3\xbb\xe6\x95\xb0w,b\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n        self.weights = np.zeros((len(xdata[0]), len(ydata[0])))\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\r\n        cost_function = []\r\n\r\n        for i in range(self.iter_times):\r\n            # \xe8\xae\xa1\xe7\xae\x97np.exp(X.W)\xe7\x9a\x84\xe5\x80\xbc\r\n            exp_xw = np.exp(np.dot(xdata, self.weights))\r\n\r\n            #\xe8\xae\xa1\xe7\xae\x97y_predict\xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe7\x9a\x84\xe5\x92\x8c\xe5\x80\xbc\r\n            sumrow = np.sum(exp_xw, axis=1).reshape(-1, 1)\r\n\r\n            # \xe8\xae\xa1\xe7\xae\x97\xe9\x99\xa4\xe5\x8e\xbb\xe5\x92\x8c\xe5\x80\xbc\xe5\xbe\x97\xe5\x80\xbc\r\n            devi_sum = exp_xw / sumrow\r\n\r\n            # \xe8\xae\xa1\xe7\xae\x97\xe5\x87\x8f\xe6\xb3\x95\r\n            sub_y = ydata - devi_sum\r\n\r\n            # \xe5\xbe\x97\xe5\x88\xb0\xe6\xa2\xaf\xe5\xba\xa6\r\n            grad_W = -1 / len(xdata) * np.dot(xdata.T, sub_y)\r\n\r\n\r\n            # \xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\r\n            # \xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xad\xe6\xb7\xbb\xe5\x8a\xa0\xe7\xb3\xbb\xe6\x95\xb0\xe7\x9a\x84L2\xe8\x8c\x83\xe6\x95\xb0\r\n            l2norm = np.sum(0.5 * np.dot(self.weights.T, self.weights) / len(xdata))\r\n\r\n            last_grad_W = grad_W + 0.002 * self.weights / len(xdata)\r\n\r\n            # \xe8\xae\xa1\xe7\xae\x97\xe6\x9c\x80\xe5\xa4\xa7\xe4\xbc\xbc\xe7\x84\xb6\xe7\x9a\x84\xe5\xaf\xb9\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\r\n            likehood = np.sum(ydata * devi_sum)\r\n\r\n            cost = - likehood / len(xdata) + l2norm\r\n\r\n            cost_function.append(cost)\r\n\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\r\n            if len(cost_function) > 2:\r\n                if 0 <= cost_function[-2] - cost_function[-1] <= self.error:\r\n                    break\r\n\r\n            #\xe6\x9b\xb4\xe6\x96\xb0\r\n            self.weights = self.weights - self.learn_rate * last_grad_W\r\n\r\n        return self.weights, cost_function\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    def predict(self, xdata, func=trans):\r\n        pnum = np.dot(func(self, xdata), self.weights)\r\n        # \xe9\x80\x89\xe6\x8b\xa9\xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe4\xb8\xad\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe6\x95\xb0\xe7\x9a\x84index\r\n        maxnumber = np.max(pnum, axis=1)\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\r\n        y_pre_type =[]\r\n        for jj in range(len(maxnumber)):\r\n            fu = list(pnum[jj]).index(maxnumber[jj]) + 1\r\n            y_pre_type.append([fu])\r\n        return np.array(y_pre_type)\r\n\r\n# \xe5\xb0\x86\xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x8f\x98\xe4\xb8\xba\xe6\xa0\x87\xe8\xaf\x86\xe4\xb8\xba1\xef\xbc\x8c2\xef\xbc\x8c3\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\r\ndef transign(eydata):\r\n    ysign = []\r\n    for hh in eydata:\r\n        ysign.append([list(hh).index(1) + 1])\r\n    return np.array(ysign)\r\n\r\n#\xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable\r\ndef confusion(realy, outy, method='AnFany'):\r\n    mix = PrettyTable()\r\n    type = sorted(list(set(realy.T[0])), reverse=True)\r\n    mix.field_names = [method] + ['\xe9\xa2\x84\xe6\xb5\x8b:%d\xe7\xb1\xbb'%si for si in type]\r\n    # \xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f\xe5\xad\x98\xe5\x82\xa8\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe6\x95\xb0\xe6\x8d\xae\r\n    cmdict = {}\r\n    for jkj in type:\r\n        cmdict[jkj] = []\r\n        for hh in type:\r\n            hu = len(['0' for jj in range(len(realy)) if realy[jj][0] == jkj and outy[jj][0] == hh])\r\n            cmdict[jkj].append(hu)\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe8\xa1\xa8\xe6\xa0\xbc\r\n    for fu in type:\r\n        mix.add_row(['\xe7\x9c\x9f\xe5\xae\x9e:%d\xe7\xb1\xbb'%fu] + cmdict[fu])\r\n    return mix\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\nif __name__ == '__main__':\r\n    lr_re = LRReg()\r\n    lf = lr_re.Gradient(smdata[0], smdata[1])\r\n\r\n    y_calss_pre = lr_re.predict(smdata[0])\r\n    print('\xe7\xb3\xbb\xe6\x95\xb0\xef\xbc\x9a\\n', lr_re.weights)\r\n\r\n    print('\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n', confusion(transign(smdata[1]), y_calss_pre))\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\xbe\r\n    import matplotlib.pyplot as plt\r\n    from pylab import mpl  # \xe4\xbd\x9c\xe5\x9b\xbe\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\n\r\n    mpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe6\x96\xb0\xe5\xae\x8b\xe4\xbd\x93\r\n    mpl.rcParams['axes.unicode_minus'] = False\r\n\r\n    plt.plot(list(range(len(lf[1]))), lf[1], '-', linewidth=5)\r\n    plt.title('\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\xbe')\r\n    plt.ylabel('Cost \xe5\x80\xbc')\r\n    plt.xlabel('\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0')\r\n    plt.show()\r\n    \r\n"""
Softmax Regression/Softmax_Compare.py,0,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe4\xb8\x89\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\r\nimport Softmax_AnFany as SM_A  # \xe9\x9c\x80\xe8\xa6\x81\xe6\xb3\xa8\xe9\x87\x8a105\xe8\xa1\x8c\xe4\xbb\xa5\xe5\x90\x8e\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\r\nimport Softmax_Sklearn as SM_S # \xe9\x9c\x80\xe8\xa6\x81\xe6\xb3\xa8\xe9\x87\x8a37\xe8\xa1\x8c\xe4\xbb\xa5\xe5\x90\x8e\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\r\nimport Softmax_TensorFlow as SM_T # \xe9\x9c\x80\xe8\xa6\x81\xe6\xb3\xa8\xe9\x87\x8a86\xe8\xa1\x8c\xe4\xbb\xa5\xe5\x90\x8e\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl  # \xe4\xbd\x9c\xe5\x9b\xbe\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe6\x96\xb0\xe5\xae\x8b\xe4\xbd\x93\r\nmpl.rcParams['axes.unicode_minus'] = False\r\nimport numpy as np\r\n\r\n\r\n#\xe9\x9a\x8f\xe6\x9c\xba\xe7\x94\x9f\xe6\x88\x90\xe4\xba\x8c\xe5\x85\x83\xe4\xba\x8c\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae: \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\xe4\xb8\xba8:2\xe3\x80\x82\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\x8d\xe8\x83\xbd\xe9\x87\x8d\xe6\x96\xb0\xe9\x9a\x8f\xe6\x9c\xba\xe7\x94\x9f\xe6\x88\x90\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe5\x88\x86\xe5\xb8\x83\xe4\xb8\x8d\xe5\x90\x8c\xe4\xba\x86\xe3\x80\x82\r\n\r\nx_data = np.random.random((900, 2))\r\ny_data = []\r\n\r\n# \xe8\x8e\xb7\xe5\xbe\x97\xe7\xb1\xbb\xe5\x88\xab\xe6\x95\xb0\xe6\x8d\xae\r\nfor dat in x_data:\r\n    if dat[1] - 3 * dat[0] + 0.5 >= 0:\r\n        y_data.append([1, 0, 0])\r\n    elif dat[1] - 3 * dat[0] + 0.5 < 0 and dat[1] - 3 * dat[0] + 1.5 > 0 :\r\n        y_data.append([0, 1, 0])\r\n    elif dat[1] - 3 * dat[0] + 1.5 <= 0:\r\n        y_data.append([0, 0, 1])\r\n# \xe8\xbd\xac\xe6\x8d\xa2\xe6\x95\xb0\xe6\x8d\xae\xe5\xbd\xa2\xe5\xbc\x8f\r\ny_data = np.array(y_data)\r\n\r\n#\xe6\x8b\x86\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\ndef divided(xdata, ydata, percent=0.2):\r\n    sign_list = list(range(len(xdata)))\r\n    #\xe7\x94\xa8\xe4\xba\x8e\xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84\xe5\xba\x8f\xe5\x8f\xb7\r\n    select_sign = sorted(np.random.choice(sign_list, int(len(xdata)*percent), replace=False))\r\n\r\n    #\xe7\x94\xa8\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xba\x8f\xe5\x8f\xb7\r\n    no_select_sign = [isign for isign in sign_list if isign not in select_sign]\r\n\r\n    #\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\n    x_predict_data = xdata[select_sign]\r\n    y_predict_data = ydata[select_sign]#\xe8\xbd\xac\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n\r\n    #\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n    x_train_data = xdata[no_select_sign]\r\n    y_train_data = ydata[no_select_sign]#\xe8\xbd\xac\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n\r\n    return x_train_data, y_train_data, x_predict_data, y_predict_data #\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84x\xef\xbc\x8cy;  \xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84x\xef\xbc\x8cy\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\x90\x8d\xe7\xa7\xb0\r\nTrain_X, Train_Y, Predict_X, Predict_Y = divided(x_data, y_data)\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe\r\ndef fig_scatter(exdata, eydata, titl='\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x95\xa3\xe7\x82\xb9\xe5\x9b\xbe', co=['r', 'b', 'g'], marker=['o','*','^']):\r\n    for ii in range(len(eydata[0])):\r\n        datax = exdata[eydata[:, ii] == 1]\r\n        plt.scatter(datax[:, 0], datax[:, -1], c=co[ii], s=50, marker=marker[ii])\r\n    plt.title(titl)\r\n    plt.legend(['1\xe7\xb1\xbb', '2\xe7\xb1\xbb', '3\xe7\xb1\xbb'])\r\n    plt.xlabel('X1 \xe5\x80\xbc')\r\n    plt.ylabel('X2 \xe5\x80\xbc')\r\n\r\n\r\n# \xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n# AnFany\r\nlr_re = SM_A.LRReg()\r\nlf = lr_re.Gradient(Train_X, Train_Y)\r\nPre = lr_re.predict(Predict_X)\r\n#print('\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n', SM_A.confusion(SM_A.transign(Predict_Y), Pre))\r\n\r\n\r\n# Sklearn\r\nregre = SM_S.sklr.fit(Train_X, SM_S.transign(Train_Y).T[0])\r\npredata = np.array([SM_S.sklr.predict(Predict_X)]).T\r\n#print('\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n',SM_S.confusion(SM_S.transign(Predict_Y), predata))\r\n\r\n\r\n# TensorFlow\r\ntf_result = SM_T.trans_tf(Train_X, Train_Y, Predict_X)\r\n#print('\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n', SM_T.confusion(SM_T.transign(Predict_Y), tf_result[1]))\r\n\r\nSM_T.sess.close()\r\n\r\n\r\n# \xe8\xbe\x93\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n# \xe9\xa6\x96\xe5\x85\x88\xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\r\nplt.subplot(2, 1, 1)\r\nfig_scatter(Train_X, Train_Y)\r\n\r\n\r\nplt.subplot(2, 1, 2)\r\nplt.text(0.5, 0.9, '\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba', size='large', weight='extra bold')\r\nplt.axis('off')\r\nplt.text(0.00, 0.7, 'AnFany  \xe7\xb3\xbb\xe6\x95\xb0\\n%s'%lr_re.weights, size='large')\r\nplt.text(0.33, 0.5, 'Sklearn  \xe7\xb3\xbb\xe6\x95\xb0\\n%s'%np.hstack((SM_S.sklr.coef_, np.array([SM_S.sklr.intercept_]).T)).T, size='large')\r\nplt.text(0.66, 0.3, 'TensorFlow  \xe7\xb3\xbb\xe6\x95\xb0\\n%s'%np.vstack((tf_result[2], tf_result[3])), size='large')\r\n\r\nplt.show()\r\n\r\n# \xe8\xbe\x93\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n\r\n#\xe6\xa0\xb9\xe6\x8d\xae\xe4\xb8\x89\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe7\xb3\xbb\xe6\x95\xb0\xef\xbc\x8c\xe7\xbb\x98\xe5\x88\xb6\xe5\x88\x86\xe5\x89\xb2\xe7\xba\xbf\r\n#\xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x89\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\xe5\x90\x84\xe8\x87\xaa\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe7\x9b\xb4\xe7\xba\xbf\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\ndef tnd_ydata(datdxx, weights):\r\n    dmin = datdxx[:, 0]\r\n    x1da = np.linspace(datdxx[:, 0].min() - 0.2, datdxx[:, 0].max() + 0.2, 100)\r\n    x2da = np.linspace(datdxx[:, 1].min() - 0.2, datdxx[:, 1].max() + 0.2, 100)\r\n    X, Y = np.meshgrid(x1da, x2da)\r\n    ydaset = []\r\n    tw = weights.T\r\n    for hh in range(len(tw)):\r\n        yda = tw[hh][0] * X + tw[hh][1] * Y + tw[hh][2]\r\n        ydaset.append(yda)\r\n    return X, Y, ydaset\r\n\r\n\r\nfrom mpl_toolkits.mplot3d import Axes3D\r\nAf_data = tnd_ydata(Train_X, lr_re.weights)# AnFany\r\nSk_data = tnd_ydata(Train_X, np.hstack((SM_S.sklr.coef_, np.array([SM_S.sklr.intercept_]).T)).T) # Sklearn\r\nTf_data = tnd_ydata(Train_X, np.vstack((tf_result[2], tf_result[3]))) # TensorFlow\r\n\r\nfig = plt.figure()\r\nax = fig.add_subplot(2, 2, 1, projection='3d')\r\nfig_scatter(Train_X, Train_Y)\r\nax.plot_wireframe(Af_data[0], Af_data[1], Af_data[2][0], color='r')\r\nax.plot_wireframe(Af_data[0], Af_data[1], Af_data[2][1], color='b')\r\nax.plot_wireframe(Af_data[0], Af_data[1], Af_data[2][2], color='g')\r\nax.set_zlabel(r'$X_{i} \\dot W$')\r\nplt.title('AnFany\xe8\xae\xad\xe7\xbb\x83\xe5\xbe\x97\xe5\x87\xba\xe7\x9a\x84\xe5\x88\x86\xe5\x89\xb2\xe7\xbb\x93\xe6\x9e\x9c')\r\nax.set_yticks(np.linspace(-0.2, 1.4, 3))\r\nax.set_xticks(np.linspace(-0.2, 1.4, 3))\r\nplt.legend(['1\xe7\xb1\xbb', '2\xe7\xb1\xbb', '3\xe7\xb1\xbb', '1\xe7\xb1\xbb\xe5\x88\x86\xe5\x89\xb2\xe9\x9d\xa2', '2\xe7\xb1\xbb\xe5\x88\x86\xe5\x89\xb2\xe9\x9d\xa2', '3\xe7\xb1\xbb\xe5\x88\x86\xe5\x89\xb2\xe9\x9d\xa2'], bbox_to_anchor=(1.2, 0.9))\r\n\r\n\r\nax = fig.add_subplot(2, 2, 2, projection='3d')\r\nfig_scatter(Train_X, Train_Y)\r\nax.plot_wireframe(Sk_data[0], Sk_data[1], Sk_data[2][0], color='r')\r\nax.plot_wireframe(Sk_data[0], Sk_data[1], Sk_data[2][1], color='b')\r\nax.plot_wireframe(Sk_data[0], Sk_data[1], Sk_data[2][2], color='g')\r\nax.set_zlabel(r'$X_{i} \\dot W$')\r\nax.set_yticks(np.linspace(-0.2, 1.4, 3))\r\nax.set_xticks(np.linspace(-0.2, 1.4, 3))\r\nplt.title('Sklearn\xe8\xae\xad\xe7\xbb\x83\xe5\xbe\x97\xe5\x87\xba\xe7\x9a\x84\xe5\x88\x86\xe5\x89\xb2\xe7\xbb\x93\xe6\x9e\x9c')\r\nplt.legend(['1\xe7\xb1\xbb', '2\xe7\xb1\xbb', '3\xe7\xb1\xbb', '1\xe7\xb1\xbb\xe5\x88\x86\xe5\x89\xb2\xe9\x9d\xa2', '2\xe7\xb1\xbb\xe5\x88\x86\xe5\x89\xb2\xe9\x9d\xa2', '3\xe7\xb1\xbb\xe5\x88\x86\xe5\x89\xb2\xe9\x9d\xa2'], bbox_to_anchor=(1.2, 0.9))\r\n\r\n\r\n\r\nax = fig.add_subplot(2, 2, 3, projection='3d')\r\nfig_scatter(Train_X, Train_Y)\r\nax.plot_wireframe(Tf_data[0], Tf_data[1], Tf_data[2][0], color='r')\r\nax.plot_wireframe(Tf_data[0], Tf_data[1], Tf_data[2][1], color='b')\r\nax.plot_wireframe(Tf_data[0], Tf_data[1], Tf_data[2][2], color='g')\r\nax.set_zlabel(r'$X_{i} \\dot W$')\r\nax.set_yticks(np.linspace(-0.2, 1.4, 3))\r\nax.set_xticks(np.linspace(-0.2, 1.4, 3))\r\nplt.title('TensorFlow\xe8\xae\xad\xe7\xbb\x83\xe5\xbe\x97\xe5\x87\xba\xe7\x9a\x84\xe5\x88\x86\xe5\x89\xb2\xe7\xbb\x93\xe6\x9e\x9c')\r\nplt.legend(['1\xe7\xb1\xbb', '2\xe7\xb1\xbb', '3\xe7\xb1\xbb', '1\xe7\xb1\xbb\xe5\x88\x86\xe5\x89\xb2\xe9\x9d\xa2', '2\xe7\xb1\xbb\xe5\x88\x86\xe5\x89\xb2\xe9\x9d\xa2', '3\xe7\xb1\xbb\xe5\x88\x86\xe5\x89\xb2\xe9\x9d\xa2'], bbox_to_anchor=(1.2, 0.9))\r\n\r\n\r\n\r\nax = fig.add_subplot(2, 2, 4)\r\n\r\nplt.title('\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe4\xb8\x89\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\xe7\x9a\x84\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe5\xaf\xb9\xe6\xaf\x94')\r\n\r\nplt.text(0.2, 0.6, SM_A.confusion(SM_A.transign(Predict_Y), Pre))\r\nplt.text(0.2, 0.3, SM_S.confusion(SM_S.transign(Predict_Y), predata))\r\nplt.text(0.2, 0.0, SM_T.confusion(SM_T.transign(Predict_Y), tf_result[1]))\r\nplt.axis('off')\r\n\r\nplt.show()\r\n\r\n\r\n\r\n\r\n\r\n\r\n"""
Softmax Regression/Softmax_Sklearn.py,0,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport sklearn as sk\r\nfrom Iris_Data import Data as smdata\r\nimport numpy as np\r\n\r\nfrom sklearn.linear_model import LogisticRegression\r\n\r\nsklr = LogisticRegression(multi_class='multinomial', solver='sag', C=200, max_iter=10000)\r\n\r\n#\xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable\r\ndef confusion(realy, outy, method='Sklearn'):\r\n    mix = PrettyTable()\r\n    type = sorted(list(set(realy.T[0])), reverse=True)\r\n    mix.field_names = [method] + ['\xe9\xa2\x84\xe6\xb5\x8b:%d\xe7\xb1\xbb'%si for si in type]\r\n    # \xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f\xe5\xad\x98\xe5\x82\xa8\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe6\x95\xb0\xe6\x8d\xae\r\n    cmdict = {}\r\n    for jkj in type:\r\n        cmdict[jkj] = []\r\n        for hh in type:\r\n            hu = len(['0' for jj in range(len(realy)) if realy[jj][0] == jkj and outy[jj][0] == hh])\r\n            cmdict[jkj].append(hu)\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe8\xa1\xa8\xe6\xa0\xbc\r\n    for fu in type:\r\n        mix.add_row(['\xe7\x9c\x9f\xe5\xae\x9e:%d\xe7\xb1\xbb'%fu] + cmdict[fu])\r\n    return mix\r\n\r\n\r\n# \xe5\xb0\x86\xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x8f\x98\xe4\xb8\xba\xe6\xa0\x87\xe8\xaf\x86\xe4\xb8\xba1\xef\xbc\x8c2\xef\xbc\x8c3\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\r\ndef transign(eydata):\r\n    ysign = []\r\n    for hh in eydata:\r\n        ysign.append([list(hh).index(1) + 1])\r\n    return np.array(ysign)\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\nif __name__ == '__main__':\r\n    regre = sklr.fit(smdata[0], transign(smdata[1]).T[0])\r\n\r\n    predata = np.array([sklr.predict(smdata[0])]).T\r\n\r\n    print('\xe7\xb3\xbb\xe6\x95\xb0\xe4\xb8\xba\xef\xbc\x9a\\n', np.hstack((sklr.coef_, np.array([sklr.intercept_]).T)).T)\r\n\r\n    print('\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n', confusion(transign(smdata[1]), predata))\r\n\r\n"""
Softmax Regression/Softmax_TensorFlow.py,16,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport tensorflow as tf\r\nsess = tf.Session()\r\nfrom Iris_Data import Data as smdata\r\nimport numpy as np\r\n\r\n#\xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable\r\ndef confusion(realy, outy, method='TensorFlow'):\r\n    mix = PrettyTable()\r\n    type = sorted(list(set(realy.T[0])), reverse=True)\r\n    mix.field_names = [method] + ['\xe9\xa2\x84\xe6\xb5\x8b:%d\xe7\xb1\xbb'%si for si in type]\r\n    # \xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f\xe5\xad\x98\xe5\x82\xa8\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe6\x95\xb0\xe6\x8d\xae\r\n    cmdict = {}\r\n    for jkj in type:\r\n        cmdict[jkj] = []\r\n        for hh in type:\r\n            hu = len(['0' for jj in range(len(realy)) if realy[jj][0] == jkj and outy[jj][0] == hh])\r\n            cmdict[jkj].append(hu)\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe8\xa1\xa8\xe6\xa0\xbc\r\n    for fu in type:\r\n        mix.add_row(['\xe7\x9c\x9f\xe5\xae\x9e:%d\xe7\xb1\xbb'%fu] + cmdict[fu])\r\n    return mix\r\n# \xe5\xb0\x86\xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x8f\x98\xe4\xb8\xba\xe6\xa0\x87\xe8\xaf\x86\xe4\xb8\xba1\xef\xbc\x8c2\xef\xbc\x8c3\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\r\ndef transign(eydata):\r\n    ysign = []\r\n    for hh in eydata:\r\n        ysign.append([list(hh).index(1) + 1])\r\n    return np.array(ysign)\r\n\r\n# \xe6\x9e\x84\xe5\xbb\xba\xe5\x87\xbd\xe6\x95\xb0\r\ndef trans_tf(datax, datay, prea, learn_rate=0.8, iter_tiems=40000, error=1e-9):\r\n    # \xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\r\n    x_data = tf.placeholder(shape=[None, len(datax[0])], dtype=tf.float32)\r\n    y_target = tf.placeholder(shape=[None, len(datay[0])], dtype=tf.float32)\r\n    # \xe9\x80\xbb\xe8\xbe\x91\xe5\x9b\x9e\xe5\xbd\x92\xe5\x8f\x82\xe6\x95\xb0\r\n    Weight = tf.Variable(tf.random_normal(shape=[len(datax[0]), len(datay[0])]), dtype=tf.float32)\r\n    Bias = tf.Variable(tf.random_normal(shape=[1, len(datay[0])]), dtype=tf.float32)\r\n\r\n    model_output = tf.nn.softmax(tf.add(tf.matmul(x_data, Weight), Bias))\r\n\r\n    cross_entropy = tf.reduce_sum(y_target * tf.log(model_output))\r\n\r\n    # \xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\r\n    tf.add_to_collection(tf.GraphKeys.WEIGHTS, Weight)\r\n    regularizer = tf.contrib.layers.l2_regularizer(scale=2 / 20000)\r\n    reg_term = tf.contrib.layers.apply_regularization(regularizer)\r\n\r\n    costfunc = tf.add(-cross_entropy / len(datax), reg_term)\r\n\r\n    # \xe5\x88\xa9\xe7\x94\xa8\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\r\n    optimizer = tf.train.GradientDescentOptimizer(learn_rate) # \xe6\xa2\xaf\xe5\xba\xa6\r\n    #optimizer = tf.train.MomentumOptimizer(learning_rate=learn_rate, momentum=0.9) # \xe5\x8a\xa8\xe9\x87\x8f\xe6\xb3\x95\r\n    #optimizer = tf.train.AdadeltaOptimizer(learning_rate=learn_rate, rho=0.55, epsilon=1e-08)\r\n    #optimizer = tf.train.AdamOptimizer(learning_rate=learn_rate, beta1=0.9, beta2=0.99, epsilon=1e-08)\r\n    trainstep = optimizer.minimize(costfunc)\r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n\r\n    loss_vec = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n    for i in range(iter_tiems):\r\n        sess.run(trainstep, feed_dict={x_data: datax, y_target: datay})\r\n        temp_loss = sess.run(costfunc, feed_dict={x_data: datax, y_target: datay})\r\n        loss_vec.append(temp_loss)\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\r\n        if len(loss_vec) > 2:\r\n            if loss_vec[-2] - loss_vec[-1] >= 0 and (loss_vec[-2] - loss_vec[-1]) <= error:\r\n                break\r\n\r\n    predata = sess.run(model_output, feed_dict={x_data: prea})\r\n    #\xe8\xbd\xac\xe5\x8c\x96\r\n    # \xe9\x80\x89\xe6\x8b\xa9\xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe4\xb8\xad\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe6\x95\xb0\xe7\x9a\x84index\r\n    maxnumber = np.max(predata, axis=1)\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\r\n    y_pre_type = []\r\n    for jj in range(len(maxnumber)):\r\n        fu = list(predata[jj]).index(maxnumber[jj]) + 1\r\n        y_pre_type.append([fu])\r\n\r\n\r\n    return loss_vec, np.array(y_pre_type), Weight.eval(session=sess), Bias.eval(session=sess)\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\nif __name__ == '__main__':\r\n    tf_result = trans_tf(smdata[0], smdata[1], smdata[0])\r\n\r\n    print('\xe7\xb3\xbb\xe6\x95\xb0\xef\xbc\x9a\\n', np.vstack((tf_result[2], tf_result[3])))\r\n\r\n    print('\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x9a\\n', confusion(transign(smdata[1]), tf_result[1]))\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\xbe\r\n    import matplotlib.pyplot as plt\r\n    from pylab import mpl  # \xe4\xbd\x9c\xe5\x9b\xbe\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\n\r\n    mpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe6\x96\xb0\xe5\xae\x8b\xe4\xbd\x93\r\n    mpl.rcParams['axes.unicode_minus'] = False\r\n\r\n    plt.plot(list(range(len(tf_result[0]))), tf_result[0], '-', linewidth=5)\r\n    plt.title('\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\xbe')\r\n    plt.ylabel('Cost \xe5\x80\xbc')\r\n    plt.xlabel('\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0')\r\n    plt.show()\r\n    \r\n    \r\n"""
Stacking/BP_Regression.py,15,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe9\x80\x82\xe7\x94\xa8\xe4\xba\x8e\xe5\xa4\x9a\xe7\xbb\xb4\xe8\xbe\x93\xe5\x87\xba\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n'''\xe5\x9f\xba\xe4\xba\x8eTensorFlow\xe6\x9e\x84\xe5\xbb\xba\xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0'''\r\n# \xe5\x88\x9b\xe5\xbb\xba\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\ndef activate(input_layer, weights, biases, actfunc):\r\n    layer = tf.add(tf.matmul(input_layer, weights), biases)\r\n    if actfunc == 'relu':\r\n        return tf.nn.relu(layer)\r\n    elif actfunc == 'tanh':\r\n        return tf.nn.tanh(layer)\r\n    elif actfunc == 'sigmoid':\r\n        return tf.nn.sigmoid(layer)\r\n# \xe6\x9d\x83\xe9\x87\x8d\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe5\x92\x8c\xe5\x88\xa9\xe7\x94\xa8\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\xe5\xbe\x88\xe5\xa4\xa7\r\n# sigmoid: xavir  tanh: xavir    relu: he\r\n\r\n#  \xe6\x9e\x84\xe5\xbb\xba\xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Ten_train(xdata, ydata, prexdata, preydata, hiddenlayers=3, hiddennodes=100, \\\r\n              learn_rate=0.05, itertimes=100000, batch_size=200, activate_func='sigmoid', break_error=0.0043):\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe6\x90\xad\xe5\xbb\xba\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\r\n    Input_Dimen = len(xdata[0])\r\n    Unit_Layers = [Input_Dimen] + [hiddennodes] * hiddenlayers + [len(ydata[0])]  # \xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84\xe7\xbb\xb4\xe6\x95\xb0\xef\xbc\x8c\xe9\x9a\x90\xe5\xb1\x82\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe6\x95\xb0\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\xb4\xe6\x95\xb01\r\n\r\n    # \xe5\x88\x9b\xe5\xbb\xba\xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\r\n    x_data = tf.placeholder(shape=[None, Input_Dimen], dtype=tf.float32, name='x_data')\r\n    y_target = tf.placeholder(shape=[None, len(ydata[0])], dtype=tf.float32)\r\n\r\n    # \xe5\xae\x9e\xe7\x8e\xb0\xe5\x8a\xa8\xe6\x80\x81\xe5\x91\xbd\xe5\x90\x8d\xe5\x8f\x98\xe9\x87\x8f\r\n    VAR_NAME = locals()\r\n\r\n    for jj in range(hiddenlayers + 1):\r\n        VAR_NAME['weight%s' % jj] = tf.Variable(np.random.rand(Unit_Layers[jj], Unit_Layers[jj + 1]), dtype=tf.float32,\\\r\n                                                name='weight%s' % jj) / np.sqrt(Unit_Layers[jj])  # sigmoid  tanh\r\n        # VAR_NAME['weight%s'%jj] = tf.Variable(np.random.rand(Unit_Layers[jj], Unit_Layers[jj + 1]), dtype=tf.float32,name='weight%s' % jj) \\/ np.sqrt(Unit_Layers[jj] / 2)  # relu\r\n        VAR_NAME['bias%s' % jj] = tf.Variable(tf.random_normal([Unit_Layers[jj + 1]], stddev=10, name='bias%s' % jj),\r\n                                              dtype=tf.float32)\r\n        if jj == 0:\r\n            VAR_NAME['ooutda%s' % jj] = activate(x_data, eval('weight%s' % jj), eval('bias%s' % jj), actfunc=activate_func)\r\n        else:\r\n            VAR_NAME['ooutda%s' % jj] = activate(eval('ooutda%s' % (jj - 1)), eval('weight%s' % jj), \\\r\n                                                 eval('bias%s' % jj), actfunc=activate_func)\r\n\r\n    # \xe5\x9d\x87\xe6\x96\xb9\xe8\xaf\xaf\xe5\xb7\xae\r\n    loss = tf.reduce_mean(tf.reduce_sum(tf.square(y_target - eval('ooutda%s' % (hiddenlayers))), reduction_indices=[1]))\r\n\r\n    # \xe4\xbc\x98\xe5\x8c\x96\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\r\n    my_opt = tf.train.AdamOptimizer(learn_rate)\r\n    train_step = my_opt.minimize(loss)\r\n\r\n    # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n    init = tf.global_variables_initializer()\r\n\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    accudict = {}\r\n\r\n    loss_vec = []  # \xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\r\n\r\n    loss_pre = []  # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe8\xaf\xaf\xe5\xb7\xae\r\n    accunum = np.inf\r\n    with tf.Session() as sess:\r\n        saver = tf.train.Saver()\r\n        sess.run(init)\r\n        for i in range(itertimes):\r\n            rand_index = np.random.choice(len(xdata), size=batch_size, replace=False)\r\n            rand_x = xdata[rand_index]\r\n            rand_y = ydata[rand_index]\r\n\r\n            sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\r\n\r\n            temp_loss = sess.run(loss, feed_dict={x_data: xdata, y_target: ydata})\r\n\r\n            temmp_losspre = sess.run(loss, feed_dict={x_data: prexdata, y_target: preydata})\r\n\r\n            loss_vec.append(temp_loss)\r\n            loss_pre.append(temmp_losspre)\r\n\r\n            accudict[i] = [temp_loss, temmp_losspre]\r\n\r\n            # \xe6\xa0\xb9\xe6\x8d\xae\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x8c\xe5\x88\xa4\xe6\x96\xad\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe6\x83\x85\xe5\x86\xb5\r\n            if (i + 1) % 20 == 0:\r\n                print('Generation: ' + str(i + 1) + '. \xe5\xbd\x92\xe4\xb8\x80\xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9aLoss = ' + str(temp_loss) +\r\n                      '. \xe5\xbd\x92\xe4\xb8\x80\xe9\xaa\x8c\xe8\xaf\x81\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9aLoss = ' + str(temmp_losspre))\r\n\r\n            # \xe6\x8f\x90\xe5\x89\x8d\xe9\x80\x80\xe5\x87\xba\xe7\x9a\x84\xe5\x88\xa4\xe6\x96\xad\r\n            if temp_loss < break_error:  # \xe6\xa0\xb9\xe6\x8d\xae\xe7\xbb\x8f\xe9\xaa\x8c\xe8\x8e\xb7\xe5\xbe\x97\xe6\xad\xa4\xe6\x95\xb0\xe5\x80\xbc, \xe5\x9b\xa0\xe4\xb8\xba\xe9\x87\x87\xe7\x94\xa8\xe7\x9a\x84\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe4\xb8\x8b\xe9\x99\x8d\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9c\xa8\xe5\x89\x8d\xe6\x9c\x9f\xe5\x8f\xaf\xe8\x83\xbd\xe5\x87\xba\xe7\x8e\xb0\xe6\xb5\xae\xe5\x8a\xa8\r\n                break\r\n\r\n            # \xe5\x9c\xa8\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\xbe\xaa\xe7\x8e\xaf\xe6\xac\xa1\xe6\x95\xb0\xe4\xb8\xad\xef\xbc\x8c\xe6\x89\xbe\xe5\x88\xb0\xe7\xbb\xbc\xe5\x90\x88\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9c\x80\xe4\xbd\x8e\xe7\x9a\x84\xe4\xb8\x80\xe6\xac\xa1\xef\xbc\x8c\xe4\xbf\x9d\xe5\xad\x98\xe5\x8f\x82\xe6\x95\xb0\r\n            zongheaccu = 0.01 * temp_loss + 0.99 * temmp_losspre\r\n            if zongheaccu < accunum:\r\n                accunum = zongheaccu\r\n                # \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\r\n                saver.save(sess, './pm25', global_step=i)  # \xe6\xb3\xa8\xe6\x84\x8f\xe8\xb7\xaf\xe5\xbe\x84\r\n\r\n        sign = min(accudict.items(), key=lambda d: 0.01 * d[1][0] + 0.99 * d[1][1])[0]\r\n\r\n        return loss_vec, loss_pre, sign, hiddenlayers\r\n\r\n\r\n\r\n\r\n"""
Stacking/Stacking_Classify_adult.py,5,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe4\xb8\xa4\xe5\xb1\x82\xe7\x9a\x84Stacking\xe5\x88\x86\xe7\xb1\xbb\r\n\r\n\r\n#  \xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x826\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xef\xbc\x8cAdaBoost\xef\xbc\x8cGBDT\xef\xbc\x8cLightGBM\xef\xbc\x8cXGBoost\xef\xbc\x8cCatBoost\r\n#  \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9aBP\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x88\x86\xe7\xb1\xbb\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\r\nimport adult_Stacking_Data as adult\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe7\xbb\x98\xe5\x9b\xbe\xe5\xba\x93\xe5\x8c\x85\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nfrom matplotlib.ticker import MultipleLocator, FormatStrFormatter\r\n# \xe8\xae\xbe\xe7\xbd\xae\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x88\xbb\xe5\xba\xa6\xe4\xb8\x8e\xe5\xad\x90\xe5\x88\xbb\xe5\xba\xa6\r\ny_toge = MultipleLocator(0.02)  # \xe5\xb0\x86y\xe8\xbd\xb4\xe4\xb8\xbb\xe5\x88\xbb\xe5\xba\xa6\xe6\xa0\x87\xe7\xad\xbe\xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xba0.1\xe7\x9a\x84\xe5\x80\x8d\xe6\x95\xb0\r\ny_son = MultipleLocator(0.01)  # \xe5\xb0\x86\xe6\xad\xa4y\xe8\xbd\xb4\xe6\xac\xa1\xe5\x88\xbb\xe5\xba\xa6\xe6\xa0\x87\xe7\xad\xbe\xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xba0.01\xe7\x9a\x84\xe5\x80\x8d\xe6\x95\xb0\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe9\x9c\x80\xe8\xa6\x81\xe7\x94\xa8\xe5\x88\xb0\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\xba\x93\xe5\x8c\x85\r\n# \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\r\nfrom sklearn.ensemble import RandomForestClassifier as RF\r\n# AdaBoost\r\nfrom sklearn.ensemble import AdaBoostClassifier\r\nfrom sklearn.tree import DecisionTreeClassifier\r\n# GBDT\r\nfrom sklearn.ensemble import GradientBoostingClassifier\r\n# XGBoost\r\nimport xgboost as xgb\r\n# LightGBM\r\nimport lightgbm as lgbm\r\n# CatBoost\r\nimport catboost as cb\r\n# BP\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x88\x86\xe7\xb1\xbb\r\nimport tensorflow as tf\r\nimport bp_Classify as bp\r\n\r\n# \xe5\x85\xb6\xe4\xbb\x96\xe5\xba\x93\xe5\x8c\x85\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom collections import OrderedDict  # python\xe5\xad\x97\xe5\x85\xb8\xe6\x98\xaf\xe6\x97\xa0\xe5\xba\x8f\xe7\x9a\x84\xef\xbc\x8c\xe6\xad\xa4\xe5\x8c\x85\xe6\x98\xaf\xe6\x9c\x89\xe5\xba\x8f\xe7\x9a\x84\r\n# \xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable as PT\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe6\xa8\xa1\xe5\x9e\x8b\r\n\'\'\'\r\n\r\nclass DATA:\r\n\r\n    def __init__(self, datadict=adult.data_dict, mubiao=\'Money\'):\r\n        self.data = datadict\r\n        self.k = 8  # \xe5\x9b\xa0\xe4\xb8\xba\xe9\x9c\x80\xe8\xa6\x81\xe5\xaf\xb9\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x8d\x95\xe7\x8b\xac\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xbf\x99\xe4\xb8\xaa\xe6\x8a\x98\xe6\x95\xb0\xe5\xaf\xb9\xe4\xba\x8e\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe9\x83\xbd\xe5\xbf\x85\xe9\xa1\xbb\xe6\x98\xaf\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\r\n\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n        self.chidata = self.data[\'train\']\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\n        self.nodata = self.data[\'predict\']\r\n\r\n        # \xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\xbc\x96\xe5\x8f\xb7\r\n        self.catsign = self.Sign()\r\n\r\n        # \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\r\n        self.ziduan = mubiao\r\n\r\n        # \xe5\xaf\xb9\xe4\xba\x8e\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x8c\x96\xe5\x92\x8c\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xb0\xe5\xbd\x95\xe8\xbd\xac\xe5\x8c\x96\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe5\xb0\x862\xe8\x80\x85\xe7\xbb\x9f\xe4\xb8\x80\xe3\x80\x82\xe5\x8f\x8d\xe5\xa4\x84\xe7\x90\x86\xe6\x97\xb6\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe9\x9c\x80\xe8\xa6\x81\xe4\xb9\x98\xe4\xbb\xa5self.fenmu \xe5\x8a\xa0\xe4\xb8\x8aself.cha\r\n        # \xe5\x88\x86\xe7\xb1\xbb\xe9\x97\xae\xe9\xa2\x98\xe4\xb8\x8d\xe6\xb6\x89\xe5\x8f\x8a\xe5\x8f\x8d\xe5\xa4\x84\xe7\x90\x86\r\n        # \xe5\xaf\xb9\xe4\xba\x8eCatBoost\xe8\x80\x8c\xe8\xa8\x80\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xef\xbc\x8c\xe8\xbd\xac\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe7\xbb\x93\xe6\x9e\x9c\xe4\xb8\xad\xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe8\xbf\x99\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x90\x8d\xe7\xa7\xb0\r\n        self.typedict = self.TransType()\r\n\r\n        # \xe6\x9c\xac\xe7\xa8\x8b\xe5\xba\x8f\xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe9\x87\x87\xe7\x94\xa8BP\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x8c\xe4\xb8\xba\xe4\xba\x86\xe9\x80\x82\xe7\x94\xa8\xe4\xba\x8e\xe5\xa4\x9a\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\x83\x85\xe5\xbd\xa2\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe8\x8e\xb7\xe5\xbe\x97\xe7\xb1\xbb\xe5\x88\xab\xe6\x95\xb0\r\n        self.typecount = self.Getcount()\r\n\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe5\x88\xab\xe6\x95\xb0\r\n    def Getcount(self):\r\n        nulist = list(set(list(self.chidata[self.ziduan])))\r\n        return len(nulist)\r\n\r\n    # \xe5\x9b\xa0\xe4\xb8\xba\xe5\xaf\xb9\xe4\xba\x8eCatBoost\xe8\x80\x8c\xe8\xa8\x80\xef\xbc\x8c\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe9\x9c\x80\xe8\xa6\x81\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe6\xa0\x87\xe5\x8f\xb7\r\n    def Sign(self):\r\n        sign = []\r\n        numlist = self.chidata.values[0][: -1]  # \xe4\xb8\x8d\xe5\x8c\x85\xe6\x8b\xac\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\r\n        for jj in range(len(numlist)):\r\n            try:\r\n                numlist[jj] + 9\r\n            except TypeError:\r\n                sign.append(jj)\r\n        return sign\r\n    # \xe5\xaf\xb9\xe4\xba\x8eCatBoost\xe8\x80\x8c\xe8\xa8\x80\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe5\xaf\xb9\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\r\n    def TransType(self):\r\n        tdict = {}\r\n        nulist = sorted(list(set(list(self.chidata[self.ziduan]))))\r\n        for jj in nulist:\r\n            tdict[jj] = nulist.index(jj)\r\n        return tdict\r\n\r\n\r\n    # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97(CatBoost)\r\n    def TargetoDi(self):\r\n        # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x8c\x89\xe7\x85\xa7\xe5\xad\x97\xe5\x85\xb8\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f\xe8\xbd\xac\xe5\x8f\x98\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97\r\n        self.chidata[self.ziduan] = [self.typedict[jj] for jj in self.chidata[self.ziduan]]\r\n        return print(\'CatBoost\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\xbd\xac\xe5\x8c\x96\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe5\x9b\xa0\xe4\xb8\xba\xe5\xbc\x95\xe5\x85\xa5\xe7\x9a\x84BP\xe5\x88\x86\xe7\xb1\xbb\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\xe9\x9c\x80\xe8\xa6\x81\xe7\xbb\x8f\xe8\xbf\x87\xe7\x8b\xac\xe7\x83\xad\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\r\n    def OneH(self):\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe5\xae\x9a\xe4\xb9\x89\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\xa80\xe6\x95\xb0\xe7\xbb\x84\r\n        zero = [0] * self.typecount\r\n        # \xe5\xae\x9a\xe4\xb9\x89\xe4\xb8\x80\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe5\xba\x8f\xe5\x88\x97\r\n        typelist = zero.copy()\r\n        for jj in self.typedict:\r\n            typelist[self.typedict[jj]] = jj\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\x9b\xb4\xe6\x94\xb9\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n        newdata  = []\r\n        for jj in self.chidata[self.ziduan]:\r\n            ss = zero.copy()\r\n            ss[typelist.index(jj)] = 1\r\n            newdata.append(ss)\r\n\r\n        self.chidata[self.ziduan] = newdata\r\n\r\n        return \'\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe7\x8b\xac\xe7\x83\xad\xe5\x8c\x96\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n\r\n    # \xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe5\xad\x97\xe6\xa0\x87\xe7\xad\xbe\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\r\n    def CAtoDI(self):\r\n        # \xe5\xa6\x82\xe6\x9e\x9c\xe7\x89\xb9\xe5\xbe\x81\xe5\x80\xbc\xe4\xb8\x8d\xe8\x83\xbd\xe6\x89\xa7\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe5\x8a\xa0\xe6\xb3\x95\xe8\xbf\x90\xe7\xae\x97\xef\xbc\x8c\xe5\x88\x99\xe8\xa7\x86\xe4\xb8\xba\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\r\n        for tezheng in self.chidata:\r\n            try:\r\n                self.chidata[tezheng].values[0] + 1\r\n            except TypeError:\r\n                numlist = sorted(list(set(list(self.chidata[tezheng]))))\r\n                self.chidata[tezheng] = [numlist.index(hh) for hh in self.chidata[tezheng]]\r\n                try:\r\n                    self.nodata[tezheng] = [numlist.index(ss) for ss in self.nodata[tezheng]]\r\n                except ValueError:\r\n                    print(\'\xe7\x89\xb9\xe5\xbe\x81%s\xef\xbc\x9a\xe9\xa2\x84\xe6\xb5\x8b\xe6\xaf\x94\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xa4\x9a\xe4\xba\x86\xe5\x80\xbc\' % (tezheng))\r\n        return print(\'\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n\r\n    # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\r\n    def Normal(self):\r\n        # \xe5\x9c\xa8\xe6\xad\xa4\xe4\xb9\x8b\xe5\x89\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\x8a\x8a\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe6\xa0\x87\xe7\xad\xbe\xe5\x8e\xbb\xe6\x8e\x89,\xe5\x90\xa6\xe5\x88\x99\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99\r\n        for tezheng in self.chidata:\r\n            maxnum = max(list(self.chidata[tezheng]))\r\n            minum = min(list(self.chidata[tezheng]))\r\n            if maxnum == minum:\r\n                self.chidata[tezheng] = [1 for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [1 for ss in self.nodata[tezheng]]\r\n            else:\r\n                self.chidata[tezheng] = [(hh - minum) / (maxnum - minum) for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [(ss - minum) / (maxnum - minum) for ss in self.nodata[tezheng]]\r\n        return print(\'\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\r\n    def Stand(self):\r\n        # \xe5\x9c\xa8\xe6\xad\xa4\xe4\xb9\x8b\xe5\x89\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\x8a\x8a\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe6\xa0\x87\xe7\xad\xbe\xe5\x8e\xbb\xe6\x8e\x89,\xe5\x90\xa6\xe5\x88\x99\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99\r\n        for tezheng in self.chidata:\r\n            standnum = np.std(np.array(list(self.chidata[tezheng])), ddof=1)  # \xe8\xae\xa1\xe7\xae\x97\xe6\x9c\x89\xe5\x81\x8f\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\r\n            meanum = np.mean(np.array(list(self.chidata[tezheng])))\r\n\r\n            if meanum == 0:\r\n                self.chidata[tezheng] = [1 for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [1 for ss in self.nodata[tezheng]]\r\n            else:\r\n                self.chidata[tezheng] = [(hh - standnum) / meanum for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [(ss - standnum) / meanum for ss in self.nodata[tezheng]]\r\n        return print(\'\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe5\xae\x9a\xe4\xb9\x89Kfold\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe5\xb0\x86\xe5\x8e\x9f\xe5\xa7\x8b\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe4\xb8\xbak\xe5\xaf\xb9\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88\r\n    def Kfold(self):\r\n        # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe5\x90\x88\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe9\x9b\x86\xe6\x88\x90\xe8\xb5\xb7\xe6\x9d\xa5\xef\xbc\x8c\xe4\xb8\xba\xe4\xba\x86\xe6\x96\xb9\xe4\xbe\xbf\xe8\xb5\xb7\xe8\xa7\x81\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe5\x9b\xba\xe5\xae\x9a\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe6\x95\xb0\xe4\xb8\xad\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\r\n        datanum = self.chidata.values\r\n        # \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n        length = len(datanum)\r\n        alist = np.arange(length)\r\n        np.random.seed(1990)\r\n        np.random.shuffle(alist)  # \xe9\x9a\x8f\xe6\x9c\xba\xe6\x89\x93\xe4\xb9\xb1\xe6\x95\xb0\xe6\x8d\xae\xe5\xaf\xb9BPNN,SVM\xe8\x80\x8c\xe8\xa8\x80\xe6\x98\xaf\xe6\x9c\x89\xe7\x9b\x8a\xe5\xa4\x84\xe7\x9a\x84\xef\xbc\x8c\xe8\x80\x8c\xe5\xaf\xb9\xe4\xba\x8e\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe4\xb9\x8b\xe7\xb1\xbb\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe8\x80\x8c\xe8\xa8\x80\xe6\xb2\xa1\xe6\x9c\x89\xe5\xbd\xb1\xe5\x93\x8d\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\r\n        yanlem = int(length / self.k)\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        datai = {}\r\n        datai[\'predict\'] = self.nodata.values\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe5\xa4\x84\xe7\x90\x86Kfold\r\n        for kk in range(self.k):\r\n            datai[kk] = OrderedDict()\r\n            if kk == 0:\r\n                datai[kk][\'train\'] = datanum[alist[(kk + 1) * yanlem:]]\r\n                datai[kk][\'test\'] = datanum[alist[: (kk + 1) * yanlem]]\r\n            elif kk == self.k - 1:\r\n                datai[kk][\'train\'] = datanum[alist[: kk * yanlem]]\r\n                datai[kk][\'test\'] = datanum[alist[kk * yanlem:]]\r\n            else:\r\n                datai[kk][\'test\'] = datanum[alist[kk * yanlem: (kk + 1) * yanlem]]\r\n                signlist = list(alist[: kk * yanlem]) + list(alist[(kk + 1) * yanlem:])\r\n                datai[kk][\'train\'] = datanum[signlist]\r\n        # \xe8\xbf\x94\xe5\x9b\x9e\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\xbd\xa2\xe5\xbc\x8f{0\xef\xbc\x9a{\'train\':data, \'test\':data}\xef\xbc\x8c\xe2\x80\xa6\xe2\x80\xa6\xef\xbc\x8cself.k-1:{\'train\':data, \'test\':data}, \'predict\':data}\r\n        print(\'K\xe6\x8a\x98\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n        return datai\r\n\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xbf\x90\xe8\xa1\x8c\xe9\x98\xb6\xe6\xae\xb5\r\n\'\'\'\r\n# \xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbb\xbb\xe6\x84\x8f\xe6\xb7\xbb\xe5\x8a\xa0\xe6\xa8\xa1\xe5\x9e\x8b\r\nclass MODELONE:\r\n\r\n    def __init__(self, exdict, zidan=\'Money\'):\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_pr = []\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_real = []\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.predi = []\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe5\xa7\x90\xe5\xa4\xab\xe5\x93\xa6\r\n        self.preal = []\r\n\r\n        # \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\xe7\xa7\xb0\r\n        self.zi = zidan\r\n\r\n        # \xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe5\x92\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe7\xb1\xbb\xe7\x9a\x84\xe4\xbf\x9d\xe6\x8c\x81\xe4\xb8\x80\xe8\x87\xb4\xef\xbc\x8c\xe8\xa6\x81\xe6\x8a\x8a\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x90\x88\xe4\xba\x8c\xe4\xb8\xba\xe4\xb8\x80\r\n        self.datai = {}\r\n\r\n        # \xe8\xae\xb0\xe5\xbd\x95\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x9c\x80\xe7\xbb\x88\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        self.error_dict = OrderedDict()\r\n\r\n        # \xe6\x95\xb0\xe5\xad\x97\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\x8e\xe6\xad\xa3\xe5\xb8\xb8\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\xaf\xb9\xe5\xba\x94\xe5\xad\x97\xe5\x85\xb8\r\n        self.tydict = exdict\r\n\r\n    # \xe5\xb0\x86\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba\xe4\xbd\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe5\xa4\x84\xe7\x90\x86\xe7\xb1\xbb\xe4\xb8\xad\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    #  \xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf{\'train\':dataframe, \'predict\':dataframe}\xe6\xa0\xb7\xe5\xbc\x8f\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    def DataStru(self):\r\n        self.datai[\'train\'] = np.row_stack((np.array(self.yanzhneg_pr), np.array(self.yanzhneg_real)))  # \xe6\xad\xa4\xe5\xa4\x84\xe6\xb7\xbb\xe5\x8a\xa0\xe8\xa1\x8c\r\n        self.datai[\'predict\'] = np.row_stack((np.array(self.predi), np.array(self.preal)))\r\n        # \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe7\xbd\xae\r\n        datapst = self.datai[\'train\'].T\r\n        # \xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xae\x9a\xe4\xb9\x89DataFrame\xe7\x9a\x84\xe5\x88\x97\xe5\x90\x8d\r\n        mingcheng = [\'\xe7\xac\xac%s\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x88\x97\' % str(dd) for dd in list(range(len(self.datai[\'train\']) - 1))] + [self.zi]\r\n        self.datai[\'train\'] = pd.DataFrame(datapst, columns=mingcheng)\r\n\r\n        # \xe5\xb0\x86\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe7\xbd\xae\r\n        dapst = self.datai[\'predict\'].T\r\n        # \xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xae\x9a\xe4\xb9\x89DataFrame\xe7\x9a\x84\xe5\x88\x97\xe5\x90\x8d\r\n        mingche= [\'\xe7\xac\xac%s\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x88\x97\' % str(dd) for dd in list(range(len(self.datai[\'predict\']) - 1))] + [self.zi]\r\n        self.datai[\'predict\'] = pd.DataFrame(dapst, columns=mingche)\r\n        return print(\'\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe5\x88\x9b\xe5\xbb\xba\xe5\xb0\x86\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe5\xa4\x9a\xe7\xbb\xb4\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe7\xb1\xbb\xe5\x88\xab\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe4\xb8\x80\xe7\xbb\xb4\xe5\x8e\x9f\xe5\xa7\x8b\xe5\x90\x8d\xe7\xa7\xb0\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def AntiTae(self, relist):\r\n        huhuan = {self.tydict[ll]: ll for ll in self.tydict}\r\n        return [huhuan[dd] for dd in relist]\r\n\r\n    # \xe5\x88\x9b\xe5\xbb\xba\xe5\xb0\x86\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe5\xa4\x9a\xe7\xbb\xb4\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe7\xb1\xbb\xe5\x88\xab\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe4\xb8\x80\xe7\xbb\xb4\xe5\x8e\x9f\xe5\xa7\x8b\xe5\x90\x8d\xe7\xa7\xb0\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def MTae(self, relist):\r\n        yiwellist = []\r\n        for jj in relist:\r\n            yiwellist.append(list(jj).index(max(list(jj))))\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe5\xb0\x86\xe5\xad\x97\xe5\x85\xb8\xe9\x94\xae\xe5\x80\xbc\xe4\xba\x92\xe6\x8d\xa2\r\n        huhuan = {self.tydict[ll]: ll for ll in self.tydict}\r\n        return [huhuan[dd] for dd in yiwellist]\r\n\r\n    # \xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def Tom(self, reallist, prelist):\r\n        \'\'\'\r\n        :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n        :param prelist:  \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n        :return: \xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\xba\xe6\x89\x80\xe6\x9c\x89\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe5\x85\xb8\r\n        \'\'\'\r\n        coundict = {}\r\n        for jj in list(set(reallist)):\r\n            coundict[jj] = {}\r\n            for hh in list(set(reallist)):\r\n                coundict[jj][hh] = len([i for i, j in zip(reallist, prelist) if i == jj and j == hh])\r\n        return coundict\r\n\r\n    # \xe5\xae\x9a\xe4\xb9\x89\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def ConfuseMatrix(self, reallist, prelist):\r\n        \'\'\'\r\n        :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n        :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n        :return: \xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n        \'\'\'\r\n        zidian = self.Tom(reallist, prelist)\r\n        lieming = sorted(zidian.keys())\r\n        table = PT([\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\'] + [\'\xe9\xa2\x84\xe6\xb5\x8b%s\' % d for d in lieming])\r\n        for jj in lieming:\r\n            table.add_row([\'\xe5\xae\x9e\xe9\x99\x85%s\' % jj] + [zidian[jj][kk] for kk in lieming])\r\n        return table\r\n\r\n    # \xe5\xae\x9a\xe4\xb9\x89\xe8\xae\xa1\xe7\xae\x97F1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def F1(self, realist, prelist):\r\n        \'\'\'\r\n        :param realist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n        :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n        :return: F1\xe5\xba\xa6\xe9\x87\x8f\r\n        \'\'\'\r\n        condict = self.Tom(realist, prelist)\r\n        zongshu = 0\r\n        zhengque = 0\r\n        zhao_cu = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n        for cu in condict:\r\n            zq = 0\r\n            zs = 0\r\n            for hh in condict[cu]:\r\n                geshu = condict[cu][hh]\r\n                if cu == hh:\r\n                    zhengque += geshu\r\n                    zq = geshu\r\n                zongshu += geshu\r\n                zs += geshu\r\n            zhao_cu.append(zq / zs)\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\r\n        jingque = zhengque / zongshu\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe5\x88\xab\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n        zhaohui = np.mean(np.array(zhao_cu))\r\n        # f1\xe5\xba\xa6\xe9\x87\x8f\r\n        f_degree = 2 * jingque * zhaohui / (jingque + zhaohui)\r\n        return f_degree\r\n\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\r\n    def RF_First(self, data, n_estimators=1000, max_features=\'sqrt\'):\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist_real = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prelist = []\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        errorlsit = []\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83,\xe5\x9b\xa0\xe4\xb8\xba\xe8\xbf\x99\xe4\xb8\xaa\xe6\x8a\x98\xe6\x95\xb0\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\xe6\x98\xaf\xe6\x9c\x89\xe5\xba\x8f\xe7\x9a\x84,\xe5\x9b\xa0\xe6\xad\xa4\xe4\xb8\x8d\xe7\x94\xa8\xe8\x80\x83\xe8\x99\x91\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe9\xa1\xba\xe5\xba\x8f\xe3\x80\x82\r\n        for zhe in [zheshu for zheshu in data.keys() if zheshu != \'predict\']:\r\n            model = RF(n_estimators=n_estimators, max_features=max_features)\r\n            model.fit(data[zhe][\'train\'][:, :-1], data[zhe][\'train\'][:, -1])\r\n            # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            xul = model.predict(data[zhe][\'train\'][:, :-1])\r\n            # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            yanre = model.predict(data[zhe][\'test\'][:, :-1])\r\n            #\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            prer = model.predict(data[\'predict\'][:, :-1])\r\n\r\n            yanzhenglist += list(yanre)\r\n            yanzhenglist_real += list(data[zhe][\'test\'][:, -1])\r\n            prelist.append(prer)\r\n            # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            xx = self.F1(xul, data[zhe][\'train\'][:, -1])\r\n\r\n            yy = self.F1(yanre, data[zhe][\'test\'][:, -1])\r\n\r\n            pp = self.F1(prer, data[\'predict\'][:, -1])\r\n\r\n            errorlsit.append([xx, yy, pp])\r\n        # \xe9\x92\x88\xe5\xaf\xb9\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\r\n        meanPre = np.mean(np.array(prelist), axis=0)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanzhenglist)\r\n        self.yanzhneg_real = yanzhenglist_real\r\n        self.predi.append(meanPre)\r\n        self.preal = data[\'predict\'][:, -1]\r\n\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\'] = np.mean(np.array(errorlsit), axis=0)\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # AdaBoost\r\n    def Adaboost_First(self, data, max_depth=5, n_estimators=1000):\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist_real = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prelist = []\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        errorlsit = []\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\r\n        for zhe in [zheshu for zheshu in data.keys() if zheshu != \'predict\']:\r\n            model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=max_depth),\r\n                                       algorithm=""SAMME"",\r\n                                       n_estimators=n_estimators, learning_rate=0.8)\r\n            model.fit(data[zhe][\'train\'][:, :-1], data[zhe][\'train\'][:, -1])\r\n            # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            xul = model.predict(data[zhe][\'train\'][:, :-1])\r\n            # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            yanre = model.predict(data[zhe][\'test\'][:, :-1])\r\n            #\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            prer = model.predict(data[\'predict\'][:, :-1])\r\n            yanzhenglist += list(yanre)\r\n            yanzhenglist_real += list(data[zhe][\'test\'][:, -1])\r\n            prelist.append(prer)\r\n\r\n            # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            xx = self.F1(xul, data[zhe][\'train\'][:, -1])\r\n\r\n            yy = self.F1(yanre, data[zhe][\'test\'][:, -1])\r\n\r\n            pp = self.F1(prer, data[\'predict\'][:, -1])\r\n\r\n            errorlsit.append([xx, yy, pp])\r\n\r\n        # \xe9\x92\x88\xe5\xaf\xb9\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\r\n        meanPre = np.mean(np.array(prelist), axis=0)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanzhenglist)\r\n        self.yanzhneg_real = yanzhenglist_real\r\n        self.predi.append(meanPre)\r\n        self.preal = data[\'predict\'][:, -1]\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'AdaBoost\'] = np.mean(np.array(errorlsit), axis=0)\r\n\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84AdaBoost\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # GBDT\r\n    def GBDT_First(self, data, max_depth=5, n_estimators=280):\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist_real = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prelist = []\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        errorlsit = []\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\r\n        for zhe in [zheshu for zheshu in data.keys() if zheshu != \'predict\']:\r\n            model = GradientBoostingClassifier(loss=\'deviance\', n_estimators=n_estimators, max_depth=max_depth,\r\n                                               learning_rate=0.1, max_features=\'sqrt\')\r\n            model.fit(data[zhe][\'train\'][:, :-1], data[zhe][\'train\'][:, -1])\r\n            # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            xul = model.predict(data[zhe][\'train\'][:, :-1])\r\n            # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            yanre = model.predict(data[zhe][\'test\'][:, :-1])\r\n            # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            prer = model.predict(data[\'predict\'][:, :-1])\r\n            yanzhenglist += list(yanre)\r\n            yanzhenglist_real += list(data[zhe][\'test\'][:, -1])\r\n            prelist.append(prer)\r\n\r\n            # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            xx = self.F1(xul, data[zhe][\'train\'][:, -1])\r\n\r\n            yy = self.F1(yanre, data[zhe][\'test\'][:, -1])\r\n\r\n            pp = self.F1(prer, data[\'predict\'][:, -1])\r\n\r\n            errorlsit.append([xx, yy, pp])\r\n\r\n        # \xe9\x92\x88\xe5\xaf\xb9\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\r\n        meanPre = np.mean(np.array(prelist), axis=0)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanzhenglist)\r\n        self.yanzhneg_real = yanzhenglist_real\r\n        self.predi.append(meanPre)\r\n        self.preal = data[\'predict\'][:, -1]\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'GBDT\'] = np.mean(np.array(errorlsit), axis=0)\r\n\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84GBDT\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # LightGBM\r\n    def LightGBM_First(self, data, max_depth=5, n_estimators=235):\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist_real = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prelist = []\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        errorlsit = []\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\r\n        for zhe in [zheshu for zheshu in data.keys() if zheshu != \'predict\']:\r\n            model = lgbm.LGBMClassifier(boosting_type=\'gbdt\', objective=\'binary\', num_leaves=50,\r\n                                        learning_rate=0.1, n_estimators=n_estimators, max_depth=max_depth,\r\n                                        bagging_fraction=0.9, feature_fraction=0.9, reg_lambda=0.2)\r\n\r\n            model.fit(data[zhe][\'train\'][:, :-1], data[zhe][\'train\'][:, -1])\r\n            # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            xul = model.predict(data[zhe][\'train\'][:, :-1])\r\n            # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            yanre = model.predict(data[zhe][\'test\'][:, :-1])\r\n            # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            prer = model.predict(data[\'predict\'][:, :-1])\r\n            yanzhenglist += list(yanre)\r\n            yanzhenglist_real += list(data[zhe][\'test\'][:, -1])\r\n            prelist.append(prer)\r\n            # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            xx = self.F1(xul, data[zhe][\'train\'][:, -1])\r\n            yy = self.F1(yanre, data[zhe][\'test\'][:, -1])\r\n            pp = self.F1(prer, data[\'predict\'][:, -1])\r\n            errorlsit.append([xx, yy, pp])\r\n        # \xe9\x92\x88\xe5\xaf\xb9\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\r\n        meanPre = np.mean(np.array(prelist), axis=0)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanzhenglist)\r\n        self.yanzhneg_real = yanzhenglist_real\r\n        self.predi.append(meanPre)\r\n        self.preal = data[\'predict\'][:, -1]\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'LightGBM\'] = np.mean(np.array(errorlsit), axis=0)\r\n\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84LightGBM\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # XGBoost\r\n    def XGBoost_First(self, data, max_depth=5, n_estimators=320):\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist_real = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prelist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        errorlsit = []\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\r\n        for zhe in [zheshu for zheshu in data.keys() if zheshu != \'predict\']:\r\n            model = xgb.XGBClassifier(max_depth=max_depth, learning_rate=0.1, n_estimators=n_estimators,\r\n                                      silent=True, objective=\'binary:logistic\', booster=\'gbtree\')\r\n            model.fit(data[zhe][\'train\'][:, :-1], data[zhe][\'train\'][:, -1])\r\n            # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            xul = model.predict(data[zhe][\'train\'][:, :-1])\r\n            # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            yanre = model.predict(data[zhe][\'test\'][:, :-1])\r\n            # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            prer = model.predict(data[\'predict\'][:, :-1])\r\n            yanzhenglist += list(yanre)\r\n            yanzhenglist_real += list(data[zhe][\'test\'][:, -1])\r\n            prelist.append(prer)\r\n            # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            xx = self.F1(xul, data[zhe][\'train\'][:, -1])\r\n            yy = self.F1(yanre, data[zhe][\'test\'][:, -1])\r\n            pp = self.F1(prer, data[\'predict\'][:, -1])\r\n            errorlsit.append([xx, yy, pp])\r\n        # \xe9\x92\x88\xe5\xaf\xb9\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\r\n        meanPre = np.mean(np.array(prelist), axis=0)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanzhenglist)\r\n        self.yanzhneg_real = yanzhenglist_real\r\n        self.predi.append(meanPre)\r\n        self.preal = data[\'predict\'][:, -1]\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'XGBoost\'] = np.mean(np.array(errorlsit), axis=0)\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84XGBoost\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # CatBoost\r\n    def CatBoost_First(self, data, catsign, depth=7, iterations=200):\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist_real = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prelist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        errorlsit = []\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\r\n        for zhe in [zheshu for zheshu in data.keys() if zheshu != \'predict\']:\r\n            model = cb.CatBoostClassifier(iterations=iterations, depth=depth, learning_rate=0.5,\r\n                                          loss_function=\'Logloss\',\r\n                                          logging_level=\'Verbose\')\r\n\r\n            model.fit(data[zhe][\'train\'][:, :-1], data[zhe][\'train\'][:, -1], cat_features=catsign)\r\n            # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            xul = model.predict(data[zhe][\'train\'][:, :-1])\r\n            # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            yanre = model.predict(data[zhe][\'test\'][:, :-1])\r\n            # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            prer = model.predict(data[\'predict\'][:, :-1])\r\n            yanzhenglist += list(yanre)\r\n            yanzhenglist_real += list(data[zhe][\'test\'][:, -1])\r\n            prelist.append(prer)\r\n            # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            xx = self.F1(xul, data[zhe][\'train\'][:, -1])\r\n            yy = self.F1(yanre, data[zhe][\'test\'][:, -1])\r\n            pp = self.F1(prer, data[\'predict\'][:, -1])\r\n            errorlsit.append([xx, yy, pp])\r\n        # \xe9\x92\x88\xe5\xaf\xb9\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\r\n        meanPre = np.mean(np.array(prelist), axis=0)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanzhenglist)\r\n        self.yanzhneg_real = yanzhenglist_real\r\n        self.predi.append(meanPre)\r\n        self.preal = data[\'predict\'][:, -1]\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'CatBoost\'] = np.mean(np.array(errorlsit), axis=0)\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84CatBoost\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xbf\x90\xe8\xa1\x8c\xe9\x98\xb6\xe6\xae\xb5 \xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbb\xbb\xe6\x84\x8f\xe6\x9b\xb4\xe6\x8d\xa2\xe6\xa8\xa1\xe5\x9e\x8b\r\n\'\'\'\r\nclass MODETWO:\r\n\r\n    def __init__(self, in_tr_data, out_tr_data, in_pre_data, out_pre):\r\n        self.xdata = in_tr_data\r\n        self.ydata = out_tr_data\r\n\r\n        self.xdatapre = in_pre_data\r\n        self.ydapre = out_pre\r\n\r\n\r\n\r\n    # BP\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x9b\x9e\xe5\xbd\x92\r\n    def BP(self, hiddenlayers=3, hiddennodes=100, learn_rate=0.02,\r\n           itertimes=30000, batch_size=50, activate_func=\'tanh\'):\r\n        *guocheng, zuiyou, hiss = bp.Ten_train(self.xdata, self.ydata, self.xdatapre,\r\n                                               self.ydapre, hiddenlayers=hiddenlayers,\r\n                                               hiddennodes=hiddennodes, learn_rate=learn_rate,\r\n                                               itertimes=itertimes, batch_size=batch_size, activate_func=activate_func)\r\n\r\n        return guocheng, zuiyou, hiss\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\xef\xbc\x8c\xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe5\x90\x84\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x8c\r\n\xe4\xbb\xa5\xe5\x8f\x8a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n\'\'\'\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84F1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8b\xe8\xaf\x84\xe5\x88\x86\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\ndef Plot_RMSE_ONE_Stacking(exdict, kaudu=0.2):\r\n    \'\'\'\r\n    :param exdict: \xe4\xb8\x8d\xe5\x90\x8c\xe6\xa8\xa1\xe5\x9e\x8bF1\xe5\xba\xa6\xe9\x87\x8f\r\n    :return: \xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    \'\'\'\r\n    # \xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe5\x88\x97\xe8\xa1\xa8\r\n    palist = exdict.keys()\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    trsore = [exdict[hh][0] for hh in palist]\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    tesore = [exdict[hh][1] for hh in palist]\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    presore = [exdict[hh][2] for hh in palist]\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x88\xb6\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    fig, ax = plt.subplots()\r\n    # \xe6\x9f\xb1\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\n    ind = np.array(list(range(len(trsore))))\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x9f\xb1\xe7\x8a\xb6\r\n    ax.bar(ind - kaudu, trsore, kaudu, color=\'SkyBlue\', label=\'\xe8\xae\xad\xe7\xbb\x83\')\r\n    ax.bar(ind, tesore, kaudu, color=\'IndianRed\', label=\'\xe6\xb5\x8b\xe8\xaf\x95\')\r\n    ax.bar(ind + kaudu, presore, kaudu, color=\'slateblue\', label=\'\xe9\xa2\x84\xe6\xb5\x8b\')\r\n    # xy\xe8\xbd\xb4\xe7\x9a\x84\xe6\xa0\x87\xe7\xad\xbe\r\n    ax.set_ylabel(\'\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\')\r\n    ax.set_xlabel(\'Stacking\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\')\r\n    # \xe8\xae\xbe\xe7\xbd\xae\xe5\x88\xbb\xe5\xba\xa6\r\n    ax.set_xticks(ind)\r\n    ax.set_xticklabels(palist)\r\n\r\n    leg = ax.legend(loc=\'best\', ncol=3, shadow=True, fancybox=True)\r\n    leg.get_frame().set_alpha(0.8)\r\n\r\n    plt.title(\'Stacking\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\xad\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\')\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\Stacking_adult.jpg\')\r\n\r\n    return print(\'\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\x8d\xe5\x90\x8c\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xaf\xb9\xe6\xaf\x94\')\r\n\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe8\xbf\xad\xe4\xbb\xa3\xe8\xbf\x87\xe7\xa8\x8b\xe4\xb8\xad\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe4\xbb\xa5\xe5\x8f\x8a\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n\r\ndef plotcurve(bpnn):\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\x8e\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9b\xb2\xe7\xba\xbf\r\n    fig, ax1 = plt.subplots()\r\n    ax1.set_xlabel(\'\xe4\xbb\xa3\xe6\x95\xb0\')\r\n    ax1.set_ylabel(\'\xe8\xaf\xaf\xe5\xb7\xae\', color=\'r\')\r\n    plt.plot(list(range(len(bpnn[0]))), bpnn[0], label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'r\', marker=\'*\', linewidth=2)\r\n    plt.plot(list(range(len(bpnn[1]))), bpnn[1], label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'r\', marker=\'.\', linewidth=2)\r\n    ax1.tick_params(axis=\'y\', labelcolor=\'r\')\r\n    legend = ax1.legend(loc=\'upper center\', shadow=True, fontsize=\'x-large\')\r\n    legend.get_frame().set_facecolor(\'#F0F8FF\')\r\n    ax1.grid(True)\r\n\r\n    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\r\n\r\n    ax2.set_ylabel(\'\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\', color=\'b\')  # we already handled the x-label with ax1\r\n    plt.plot(list(range(len(bpnn[2]))), bpnn[2], label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'b\', marker=\'*\', linewidth=2)\r\n    plt.plot(list(range(len(bpnn[3]))), bpnn[3], label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'b\', marker=\'.\', linewidth=2)\r\n    ax2.tick_params(axis=\'y\', labelcolor=\'b\')\r\n    legen = ax2.legend(loc=\'lower center\', shadow=True, fontsize=\'x-large\')\r\n    legen.get_frame().set_facecolor(\'#FFFAFA\')\r\n    ax2.grid(True)\r\n    ax2.yaxis.set_major_locator(y_toge)\r\n    ax2.yaxis.set_minor_locator(y_son)\r\n\r\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\r\n    plt.title(\'\xe8\xae\xad\xe7\xbb\x83VS\xe9\xaa\x8c\xe8\xaf\x81\xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94\', fontsize=16)\r\n\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\stacking_guo.jpg\')\r\n\r\n\r\n    return print(\'\xe8\xbf\x87\xe7\xa8\x8b\xe7\xbb\x98\xe5\x9b\xbe\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xba\x94\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9aStacking\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\'\'\'\r\n\r\nif __name__ == ""__main__"":\r\n    #  \xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x826\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xef\xbc\x8cAdaBoost\xef\xbc\x8cGBDT\xef\xbc\x8cLightGBM\xef\xbc\x8cXGBoost\xef\xbc\x8cCatBoost\r\n\r\n    # \xe4\xb8\x8b\xe9\x9d\xa2\xe4\xbe\x9d\xe6\xac\xa1\xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xbb\xba\xe7\xab\x8b\xe6\x95\xb0\xe6\x8d\xae\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe3\x80\x81AdaBoost\xef\xbc\x8cGBDT\xef\xbc\x8cLIghtGNM\xef\xbc\x8cXGBoost\xe9\x83\xbd\xe6\x98\xaf\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\r\n    rf_data = DATA()\r\n    rf_data.CAtoDI()  # \xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\r\n    data_rf = rf_data.Kfold()  # \xe6\x8a\x98\xe6\x95\xb0\r\n\r\n\r\n    # CatBoost\r\n    cat_data = DATA()  # \xe4\xb8\x8d\xe7\x94\xa8\xe5\xa4\x84\xe7\x90\x86\r\n    cat_data.TargetoDi()   # \xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\r\n    data_cat = cat_data.Kfold()  # \xe6\x8a\x98\xe6\x95\xb0\r\n\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe5\xbb\xba\xe7\xab\x8bStacking\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\r\n    one_stacking = MODELONE(exdict=rf_data.typedict)\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\r\n    one_stacking.RF_First(data_rf)\r\n    # AdaBoost\r\n    one_stacking.Adaboost_First(data_rf)\r\n    # GBDT\r\n    one_stacking.GBDT_First(data_rf)\r\n    # LightGBM\r\n    one_stacking.LightGBM_First(data_rf)\r\n    # XGBoost\r\n    one_stacking.XGBoost_First(data_rf)\r\n    # CatBoost\r\n    one_stacking.CatBoost_First(data_cat, cat_data.catsign)\r\n\r\n    # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\r\n    one_stacking.DataStru()\r\n    data_two = one_stacking.datai\r\n\r\n    # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\r\n    erce_data = DATA(datadict=data_two)\r\n    erce_data.CAtoDI()  # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe9\x83\xbd\xe6\x98\xaf\xe7\xb1\xbb\xe5\x88\xab\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe6\xa0\x87\xe7\xad\xbe\xe5\x8c\x96\r\n    erce_data.Normal()\r\n    erce_data.OneH()  # \xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe7\x8b\xac\xe7\x83\xad\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\r\n    # \xe4\xb8\xba\xe4\xba\x86\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9b\xb4\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe8\xae\xbe\xe7\xbd\xae\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\r\n    bpdatadict = erce_data.Kfold()  # \xe4\xb8\xba\xe4\xba\x86\xe7\xae\x80\xe4\xbe\xbf\xef\xbc\x8c\xe4\xb8\x8d\xe5\x86\x8d\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\r\n\r\n    # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe5\xbb\xba\xe6\xa8\xa1,\r\n    stacking_two = MODETWO(bpdatadict[0][\'train\'][:, :-1],\r\n                           np.array(list(bpdatadict[0][\'train\'][:, -1])),\r\n                           bpdatadict[0][\'test\'][:, :-1],\r\n                           np.array(list(bpdatadict[0][\'test\'][:, -1])))\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc, \xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe8\xbf\xad\xe4\xbb\xa3\xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n    error_acc, signi, gir = stacking_two.BP()\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\xe5\xae\x8c\xe6\x88\x90\xe5\x90\x8e\xe8\xaf\xbb\xe5\x8f\x96\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe5\x9c\xa8\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n    graph = tf.train.import_meta_graph(r\'E:\\tensorflow_Learn\\Stacking\\adult\\model-%s.meta\' % signi)\r\n    ses = tf.Session()\r\n    graph.restore(ses, tf.train.latest_checkpoint(r\'E:\\tensorflow_Learn\\Stacking\\adult\'))\r\n    op_to_restore = tf.get_default_graph().get_tensor_by_name(""Add_%s:0"" % gir)\r\n    w1 = tf.get_default_graph().get_tensor_by_name(""x_data:0"")\r\n    feed_dict = {w1: bpdatadict[\'predict\'][:, :-1]}\r\n    dgsio = ses.run(op_to_restore, feed_dict)\r\n\r\n    #  \xe5\xb0\x86\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe8\xbd\xac\xe5\x8f\x98\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n    bp_out_type = one_stacking.MTae(bp.judge(dgsio))\r\n    bp_real_type = one_stacking.AntiTae(bpdatadict[\'predict\'][:, -1])\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\xad\xe5\x90\x84\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9b\xbe\r\n    Plot_RMSE_ONE_Stacking(one_stacking.error_dict)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe8\xaf\xaf\xe5\xb7\xae\r\n    plotcurve(error_acc)\r\n\r\n    fru = one_stacking.ConfuseMatrix(bp_real_type, bp_out_type)\r\n\r\n\r\n\r\n'"
Stacking/Stacking_Regression_pm25.py,5,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe4\xb8\xa4\xe5\xb1\x82\xe7\x9a\x84Stacking\xe5\x9b\x9e\xe5\xbd\x92\r\nfrom wxpy import *\r\nbot = Bot(cache_path=True)\r\n\r\n#  \xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x826\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xef\xbc\x8cAdaBoost\xef\xbc\x8cGBDT\xef\xbc\x8cLightGBM\xef\xbc\x8cXGBoost\xef\xbc\x8cCatBoost\r\n#  \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9aBP\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x9b\x9e\xe5\xbd\x92\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\r\nimport pm25_Stacking_Data as pm25\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe7\xbb\x98\xe5\x9b\xbe\xe5\xba\x93\xe5\x8c\x85\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe9\x9c\x80\xe8\xa6\x81\xe7\x94\xa8\xe5\x88\xb0\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\xba\x93\xe5\x8c\x85\r\n# \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\r\nfrom sklearn.ensemble import RandomForestRegressor as RF\r\n# AdaBoost\r\nfrom sklearn.ensemble import AdaBoostRegressor\r\nfrom sklearn.tree import DecisionTreeRegressor\r\n# GBDT\r\nfrom sklearn.ensemble import GradientBoostingRegressor\r\n# XGBoost\r\nimport xgboost as xgb\r\n# LightGBM\r\nimport lightgbm as lgbm\r\n# CatBoost\r\nimport catboost as cb\r\n# BP\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x9b\x9e\xe5\xbd\x92\r\nimport BP_Regression as bp\r\n\r\n# \xe5\x85\xb6\xe4\xbb\x96\xe5\xba\x93\xe5\x8c\x85\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom collections import OrderedDict  # python\xe5\xad\x97\xe5\x85\xb8\xe6\x98\xaf\xe6\x97\xa0\xe5\xba\x8f\xe7\x9a\x84\xef\xbc\x8c\xe6\xad\xa4\xe5\x8c\x85\xe6\x98\xaf\xe6\x9c\x89\xe5\xba\x8f\xe7\x9a\x84\r\nimport os\r\nos.chdir(r\'E:\\tensorflow_Learn\\Stacking\\pm25\')\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe6\xa8\xa1\xe5\x9e\x8b\r\n\'\'\'\r\n\r\nclass DATA:\r\n\r\n    def __init__(self, datadict=pm25.data_dict, mubiao=\'pm2.5\'):\r\n        self.data = datadict\r\n        self.k = 8  # \xe5\x9b\xa0\xe4\xb8\xba\xe9\x9c\x80\xe8\xa6\x81\xe5\xaf\xb9\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x8d\x95\xe7\x8b\xac\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xbf\x99\xe4\xb8\xaa\xe6\x8a\x98\xe6\x95\xb0\xe5\xaf\xb9\xe4\xba\x8e\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe9\x83\xbd\xe5\xbf\x85\xe9\xa1\xbb\xe6\x98\xaf\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\r\n\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n        self.chidata = self.data[\'train\']\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\n        self.nodata = self.data[\'predict\']\r\n\r\n        # \xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\xbc\x96\xe5\x8f\xb7\r\n        self.catsign = self.Sign()\r\n\r\n        # \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\r\n        self.ziduan = mubiao\r\n\r\n        # \xe5\xaf\xb9\xe4\xba\x8e\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x8c\x96\xe5\x92\x8c\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xb0\xe5\xbd\x95\xe8\xbd\xac\xe5\x8c\x96\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe5\xb0\x862\xe8\x80\x85\xe7\xbb\x9f\xe4\xb8\x80\xe3\x80\x82\xe5\x8f\x8d\xe5\xa4\x84\xe7\x90\x86\xe6\x97\xb6\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe9\x9c\x80\xe8\xa6\x81\xe4\xb9\x98\xe4\xbb\xa5self.fenmu \xe5\x8a\xa0\xe4\xb8\x8aself.cha\r\n        self.fenmu = 1  # \xe7\x9b\xb8\xe5\xbd\x93\xe4\xba\x8e\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae, \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xe5\x87\x8f\xe5\x8e\xbb\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\r\n        self.cha = 0   # \xe7\x9b\xb8\xe5\xbd\x93\xe4\xba\x8e\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe7\x9a\x84\xe5\xb9\xb3\xe5\x9d\x87\xe5\x80\xbc, \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe7\x9a\x84\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\r\n\r\n    # \xe5\x9b\xa0\xe4\xb8\xba\xe5\xaf\xb9\xe4\xba\x8eCatBoost\xe8\x80\x8c\xe8\xa8\x80\xef\xbc\x8c\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe9\x9c\x80\xe8\xa6\x81\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe6\xa0\x87\xe5\x8f\xb7\r\n    def Sign(self):\r\n        sign = []\r\n        numlist = self.chidata.values[0][: -1]  # \xe4\xb8\x8d\xe5\x8c\x85\xe6\x8b\xac\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\r\n        for jj in range(len(numlist)):\r\n            try:\r\n                numlist[jj] + 9\r\n            except TypeError:\r\n                sign.append(jj)\r\n        return sign\r\n\r\n    # \xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe5\xad\x97\xe6\xa0\x87\xe7\xad\xbe\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\r\n    def CAtoDI(self):\r\n        # \xe5\xa6\x82\xe6\x9e\x9c\xe7\x89\xb9\xe5\xbe\x81\xe5\x80\xbc\xe4\xb8\x8d\xe8\x83\xbd\xe6\x89\xa7\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe5\x8a\xa0\xe6\xb3\x95\xe8\xbf\x90\xe7\xae\x97\xef\xbc\x8c\xe5\x88\x99\xe8\xa7\x86\xe4\xb8\xba\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\r\n        for tezheng in self.chidata:\r\n            try:\r\n                self.chidata[tezheng].values[0] + 1\r\n            except TypeError:\r\n                numlist = sorted(list(set(list(self.chidata[tezheng]))))\r\n                self.chidata[tezheng] = [numlist.index(hh) for hh in self.chidata[tezheng]]\r\n                try:\r\n                    self.nodata[tezheng] = [numlist.index(ss) for ss in self.nodata[tezheng]]\r\n                except ValueError:\r\n                    print(\'\xe7\x89\xb9\xe5\xbe\x81%s\xef\xbc\x9a\xe9\xa2\x84\xe6\xb5\x8b\xe6\xaf\x94\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xa4\x9a\xe4\xba\x86\xe5\x80\xbc\' % (tezheng))\r\n        return print(\'\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe5\xaf\xb9\xe4\xba\x8e\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x92\x8c\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xb0\xe5\xbd\x95\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe7\x9a\x84\xe8\xbd\xac\xe5\x8c\x96\xe5\x80\xbc\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x8f\x8d\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\r\n\r\n    # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\r\n    def Normal(self):\r\n        # \xe5\x9c\xa8\xe6\xad\xa4\xe4\xb9\x8b\xe5\x89\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\x8a\x8a\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe6\xa0\x87\xe7\xad\xbe\xe5\x8e\xbb\xe6\x8e\x89,\xe5\x90\xa6\xe5\x88\x99\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99\r\n        for tezheng in self.chidata:\r\n            maxnum = max(list(self.chidata[tezheng]))\r\n            minum = min(list(self.chidata[tezheng]))\r\n            if maxnum == minum:\r\n                self.chidata[tezheng] = [1 for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [1 for ss in self.nodata[tezheng]]\r\n            else:\r\n                self.chidata[tezheng] = [(hh - minum) / (maxnum - minum) for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [(ss - minum) / (maxnum - minum) for ss in self.nodata[tezheng]]\r\n                if tezheng == self.ziduan:\r\n                    self.fenmu = maxnum - minum\r\n                    self.cha = minum\r\n        return print(\'\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\r\n    def Stand(self):\r\n        # \xe5\x9c\xa8\xe6\xad\xa4\xe4\xb9\x8b\xe5\x89\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\x8a\x8a\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe6\xa0\x87\xe7\xad\xbe\xe5\x8e\xbb\xe6\x8e\x89,\xe5\x90\xa6\xe5\x88\x99\xe4\xbc\x9a\xe6\x8a\xa5\xe9\x94\x99\r\n        for tezheng in self.chidata:\r\n            standnum = np.std(np.array(list(self.chidata[tezheng])), ddof=1)  # \xe8\xae\xa1\xe7\xae\x97\xe6\x9c\x89\xe5\x81\x8f\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\r\n            meanum = np.mean(np.array(list(self.chidata[tezheng])))\r\n\r\n            if meanum == 0:\r\n                self.chidata[tezheng] = [1 for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [1 for ss in self.nodata[tezheng]]\r\n            else:\r\n                self.chidata[tezheng] = [(hh - standnum) / meanum for hh in self.chidata[tezheng]]\r\n                self.nodata[tezheng] = [(ss - standnum) / meanum for ss in self.nodata[tezheng]]\r\n                if tezheng == self.ziduan:\r\n                    self.fenmu = standnum\r\n                    self.cha = meanum\r\n        return print(\'\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe5\xae\x9a\xe4\xb9\x89Kfold\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe5\xb0\x86\xe5\x8e\x9f\xe5\xa7\x8b\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe4\xb8\xbak\xe5\xaf\xb9\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88\r\n    def Kfold(self):\r\n        # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe5\x90\x88\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe9\x9b\x86\xe6\x88\x90\xe8\xb5\xb7\xe6\x9d\xa5\xef\xbc\x8c\xe4\xb8\xba\xe4\xba\x86\xe6\x96\xb9\xe4\xbe\xbf\xe8\xb5\xb7\xe8\xa7\x81\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe5\x9b\xba\xe5\xae\x9a\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe6\x95\xb0\xe4\xb8\xad\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\r\n        datanum = self.chidata.values\r\n        # \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n        length = len(datanum)\r\n        alist = np.arange(length)\r\n        np.random.seed(1990)\r\n        np.random.shuffle(alist)  # \xe9\x9a\x8f\xe6\x9c\xba\xe6\x89\x93\xe4\xb9\xb1\xe6\x95\xb0\xe6\x8d\xae\xe5\xaf\xb9BPNN,SVM\xe8\x80\x8c\xe8\xa8\x80\xe6\x98\xaf\xe6\x9c\x89\xe7\x9b\x8a\xe5\xa4\x84\xe7\x9a\x84\xef\xbc\x8c\xe8\x80\x8c\xe5\xaf\xb9\xe4\xba\x8e\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe4\xb9\x8b\xe7\xb1\xbb\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe8\x80\x8c\xe8\xa8\x80\xe6\xb2\xa1\xe6\x9c\x89\xe5\xbd\xb1\xe5\x93\x8d\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\r\n        yanlem = int(length / self.k)\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        datai = {}\r\n        datai[\'predict\'] = self.nodata.values\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe5\xa4\x84\xe7\x90\x86Kfold\r\n        for kk in range(self.k):\r\n            datai[kk] = OrderedDict()\r\n            if kk == 0:\r\n                datai[kk][\'train\'] = datanum[alist[(kk + 1) * yanlem:]]\r\n                datai[kk][\'test\'] = datanum[alist[: (kk + 1) * yanlem]]\r\n            elif kk == self.k - 1:\r\n                datai[kk][\'train\'] = datanum[alist[: kk * yanlem]]\r\n                datai[kk][\'test\'] = datanum[alist[kk * yanlem:]]\r\n            else:\r\n                datai[kk][\'test\'] = datanum[alist[kk * yanlem: (kk + 1) * yanlem]]\r\n                signlist = list(alist[: kk * yanlem]) + list(alist[(kk + 1) * yanlem:])\r\n                datai[kk][\'train\'] = datanum[signlist]\r\n        # \xe8\xbf\x94\xe5\x9b\x9e\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\xbd\xa2\xe5\xbc\x8f{0\xef\xbc\x9a{\'train\':data, \'test\':data}\xef\xbc\x8c\xe2\x80\xa6\xe2\x80\xa6\xef\xbc\x8cself.k-1:{\'train\':data, \'test\':data}, \'predict\':data}\r\n        print(\'K\xe6\x8a\x98\xe5\xa4\x84\xe7\x90\x86\xe5\xae\x8c\xe6\xaf\x95\')\r\n        return datai\r\n\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xbf\x90\xe8\xa1\x8c\xe9\x98\xb6\xe6\xae\xb5\r\n\'\'\'\r\n# \xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbb\xbb\xe6\x84\x8f\xe6\xb7\xbb\xe5\x8a\xa0\xe6\xa8\xa1\xe5\x9e\x8b\r\nclass MODELONE:\r\n\r\n    def __init__(self, zidan=\'pm2.5\'):\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_pr = []\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.yanzhneg_real = []\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.predi = []\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        self.preal = []\r\n\r\n        # \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\xe7\xa7\xb0\r\n        self.zi = zidan\r\n\r\n        # \xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe5\x92\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe7\xb1\xbb\xe7\x9a\x84\xe4\xbf\x9d\xe6\x8c\x81\xe4\xb8\x80\xe8\x87\xb4\xef\xbc\x8c\xe8\xa6\x81\xe6\x8a\x8a\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x90\x88\xe4\xba\x8c\xe4\xb8\xba\xe4\xb8\x80\r\n        self.datai = {}\r\n\r\n        # \xe8\xae\xb0\xe5\xbd\x95\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x9c\x80\xe7\xbb\x88\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        self.error_dict = OrderedDict()\r\n\r\n    # \xe5\xb0\x86\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba\xe4\xbd\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe5\xa4\x84\xe7\x90\x86\xe7\xb1\xbb\xe4\xb8\xad\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    #  \xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf{\'train\':dataframe, \'predict\':dataframe}\xe6\xa0\xb7\xe5\xbc\x8f\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    def DataStru(self):\r\n        self.datai[\'train\'] = np.row_stack((np.array(self.yanzhneg_pr), np.array(self.yanzhneg_real)))  # \xe6\xad\xa4\xe5\xa4\x84\xe6\xb7\xbb\xe5\x8a\xa0\xe8\xa1\x8c\r\n        self.datai[\'predict\'] = np.row_stack((np.array(self.predi), np.array(self.preal)))\r\n        # \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe7\xbd\xae\r\n        datapst = self.datai[\'train\'].T\r\n        # \xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xae\x9a\xe4\xb9\x89DataFrame\xe7\x9a\x84\xe5\x88\x97\xe5\x90\x8d\r\n        mingcheng = [\'\xe7\xac\xac%s\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x88\x97\' % str(dd) for dd in list(range(len(self.datai[\'train\']) - 1))] + [self.zi]\r\n        self.datai[\'train\'] = pd.DataFrame(datapst, columns=mingcheng)\r\n\r\n        # \xe5\xb0\x86\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe7\xbd\xae\r\n        dapst = self.datai[\'predict\'].T\r\n        # \xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xae\x9a\xe4\xb9\x89DataFrame\xe7\x9a\x84\xe5\x88\x97\xe5\x90\x8d\r\n        mingche= [\'\xe7\xac\xac%s\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x88\x97\' % str(dd) for dd in list(range(len(self.datai[\'predict\']) - 1))] + [self.zi]\r\n        self.datai[\'predict\'] = pd.DataFrame(dapst, columns=mingche)\r\n        return print(\'\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # \xe5\xae\x9a\xe4\xb9\x89\xe5\x9d\x87\xe6\x96\xb9\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def RMSE(self, data1, data2):\r\n        data1, data2 = np.array(data1), np.array(data2)\r\n        subdata = np.power(data1 - data2, 2)\r\n        return np.sqrt(np.sum(subdata) / len(subdata - 1))\r\n\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\r\n    def RF_First(self, data, n_estimators=4000, max_features=\'auto\'):\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist_real = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prelist = []\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        errorlsit = []\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83,\xe5\x9b\xa0\xe4\xb8\xba\xe8\xbf\x99\xe4\xb8\xaa\xe6\x8a\x98\xe6\x95\xb0\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\xe6\x98\xaf\xe6\x9c\x89\xe5\xba\x8f\xe7\x9a\x84,\xe5\x9b\xa0\xe6\xad\xa4\xe4\xb8\x8d\xe7\x94\xa8\xe8\x80\x83\xe8\x99\x91\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe9\xa1\xba\xe5\xba\x8f\xe3\x80\x82\r\n        for zhe in [zheshu for zheshu in data.keys() if zheshu != \'predict\']:\r\n            model = RF(n_estimators=n_estimators, max_features=max_features)\r\n            model.fit(data[zhe][\'train\'][:, :-1], data[zhe][\'train\'][:, -1])\r\n            # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            xul = model.predict(data[zhe][\'train\'][:, :-1])\r\n            # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            yanre = model.predict(data[zhe][\'test\'][:, :-1])\r\n            #\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            prer = model.predict(data[\'predict\'][:, :-1])\r\n\r\n            yanzhenglist += list(yanre)\r\n            yanzhenglist_real += list(data[zhe][\'test\'][:, -1])\r\n            prelist.append(prer)\r\n            # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            xx = self.RMSE(xul, data[zhe][\'train\'][:, -1])\r\n\r\n            yy = self.RMSE(yanre, data[zhe][\'test\'][:, -1])\r\n\r\n            pp = self.RMSE(prer, data[\'predict\'][:, -1])\r\n\r\n            errorlsit.append([xx, yy, pp])\r\n        # \xe9\x92\x88\xe5\xaf\xb9\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\r\n        meanPre = np.mean(np.array(prelist), axis=0)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanzhenglist)\r\n        self.yanzhneg_real = yanzhenglist_real\r\n        self.predi.append(meanPre)\r\n        self.preal = data[\'predict\'][:, -1]\r\n\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\'] = np.mean(np.array(errorlsit), axis=0)\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # AdaBoost\r\n    def Adaboost_First(self, data, max_depth=50, n_estimators=1000):\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist_real = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prelist = []\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        errorlsit = []\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\r\n        for zhe in [zheshu for zheshu in data.keys() if zheshu != \'predict\']:\r\n            model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=max_depth),\r\n                                      n_estimators=n_estimators, learning_rate=0.8)\r\n            model.fit(data[zhe][\'train\'][:, :-1], data[zhe][\'train\'][:, -1])\r\n            # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            xul = model.predict(data[zhe][\'train\'][:, :-1])\r\n            # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            yanre = model.predict(data[zhe][\'test\'][:, :-1])\r\n            #\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            prer = model.predict(data[\'predict\'][:, :-1])\r\n            yanzhenglist += list(yanre)\r\n            yanzhenglist_real += list(data[zhe][\'test\'][:, -1])\r\n            prelist.append(prer)\r\n\r\n            # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            xx = self.RMSE(xul, data[zhe][\'train\'][:, -1])\r\n\r\n            yy = self.RMSE(yanre, data[zhe][\'test\'][:, -1])\r\n\r\n            pp = self.RMSE(prer, data[\'predict\'][:, -1])\r\n\r\n            errorlsit.append([xx, yy, pp])\r\n\r\n        # \xe9\x92\x88\xe5\xaf\xb9\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\r\n        meanPre = np.mean(np.array(prelist), axis=0)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanzhenglist)\r\n        self.yanzhneg_real = yanzhenglist_real\r\n        self.predi.append(meanPre)\r\n        self.preal = data[\'predict\'][:, -1]\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'AdaBoost\'] = np.mean(np.array(errorlsit), axis=0)\r\n\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84AdaBoost\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # GBDT\r\n    def GBDT_First(self, data, max_depth=17, n_estimators=57):\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist_real = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prelist = []\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        errorlsit = []\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\r\n        for zhe in [zheshu for zheshu in data.keys() if zheshu != \'predict\']:\r\n            model = GradientBoostingRegressor(loss=\'ls\', n_estimators=n_estimators, max_depth=max_depth,\r\n                                              learning_rate=0.12, subsample=0.8)\r\n            model.fit(data[zhe][\'train\'][:, :-1], data[zhe][\'train\'][:, -1])\r\n            # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            xul = model.predict(data[zhe][\'train\'][:, :-1])\r\n            # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            yanre = model.predict(data[zhe][\'test\'][:, :-1])\r\n            # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            prer = model.predict(data[\'predict\'][:, :-1])\r\n            yanzhenglist += list(yanre)\r\n            yanzhenglist_real += list(data[zhe][\'test\'][:, -1])\r\n            prelist.append(prer)\r\n\r\n            # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            xx = self.RMSE(xul, data[zhe][\'train\'][:, -1])\r\n\r\n            yy = self.RMSE(yanre, data[zhe][\'test\'][:, -1])\r\n\r\n            pp = self.RMSE(prer, data[\'predict\'][:, -1])\r\n\r\n            errorlsit.append([xx, yy, pp])\r\n\r\n        # \xe9\x92\x88\xe5\xaf\xb9\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\r\n        meanPre = np.mean(np.array(prelist), axis=0)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanzhenglist)\r\n        self.yanzhneg_real = yanzhenglist_real\r\n        self.predi.append(meanPre)\r\n        self.preal = data[\'predict\'][:, -1]\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'GBDT\'] = np.mean(np.array(errorlsit), axis=0)\r\n\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84GBDT\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # LightGBM\r\n    def LightGBM_First(self, data, max_depth=9, n_estimators=380):\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist_real = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prelist = []\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        errorlsit = []\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\r\n        for zhe in [zheshu for zheshu in data.keys() if zheshu != \'predict\']:\r\n            model = lgbm.LGBMRegressor(boosting_type=\'gbdt\', objective=\'regression\', num_leaves=1200,\r\n                                       learning_rate=0.17, n_estimators=n_estimators, max_depth=max_depth,\r\n                                       metric=\'rmse\', bagging_fraction=0.8, feature_fraction=0.8, reg_lambda=0.9)\r\n\r\n            model.fit(data[zhe][\'train\'][:, :-1], data[zhe][\'train\'][:, -1])\r\n            # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            xul = model.predict(data[zhe][\'train\'][:, :-1])\r\n            # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            yanre = model.predict(data[zhe][\'test\'][:, :-1])\r\n            # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            prer = model.predict(data[\'predict\'][:, :-1])\r\n            yanzhenglist += list(yanre)\r\n            yanzhenglist_real += list(data[zhe][\'test\'][:, -1])\r\n            prelist.append(prer)\r\n            # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            xx = self.RMSE(xul, data[zhe][\'train\'][:, -1])\r\n            yy = self.RMSE(yanre, data[zhe][\'test\'][:, -1])\r\n            pp = self.RMSE(prer, data[\'predict\'][:, -1])\r\n            errorlsit.append([xx, yy, pp])\r\n        # \xe9\x92\x88\xe5\xaf\xb9\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\r\n        meanPre = np.mean(np.array(prelist), axis=0)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanzhenglist)\r\n        self.yanzhneg_real = yanzhenglist_real\r\n        self.predi.append(meanPre)\r\n        self.preal = data[\'predict\'][:, -1]\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'LightGBM\'] = np.mean(np.array(errorlsit), axis=0)\r\n\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84LightGBM\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # XGBoost\r\n    def XGBoost_First(self, data, max_depth=50, n_estimators=220):\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist_real = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prelist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        errorlsit = []\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\r\n        for zhe in [zheshu for zheshu in data.keys() if zheshu != \'predict\']:\r\n            model = xgb.XGBRegressor(max_depth=max_depth, learning_rate=0.1, n_estimators=n_estimators,\r\n                                     silent=True, objective=\'reg:gamma\')\r\n            model.fit(data[zhe][\'train\'][:, :-1], data[zhe][\'train\'][:, -1])\r\n            # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            xul = model.predict(data[zhe][\'train\'][:, :-1])\r\n            # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            yanre = model.predict(data[zhe][\'test\'][:, :-1])\r\n            # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            prer = model.predict(data[\'predict\'][:, :-1])\r\n            yanzhenglist += list(yanre)\r\n            yanzhenglist_real += list(data[zhe][\'test\'][:, -1])\r\n            prelist.append(prer)\r\n            # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            xx = self.RMSE(xul, data[zhe][\'train\'][:, -1])\r\n            yy = self.RMSE(yanre, data[zhe][\'test\'][:, -1])\r\n            pp = self.RMSE(prer, data[\'predict\'][:, -1])\r\n            errorlsit.append([xx, yy, pp])\r\n        # \xe9\x92\x88\xe5\xaf\xb9\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\r\n        meanPre = np.mean(np.array(prelist), axis=0)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanzhenglist)\r\n        self.yanzhneg_real = yanzhenglist_real\r\n        self.predi.append(meanPre)\r\n        self.preal = data[\'predict\'][:, -1]\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'XGBoost\'] = np.mean(np.array(errorlsit), axis=0)\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84XGBoost\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    # CatBoost\r\n    def CatBoost_First(self, data, catsign, depth=8, iterations=80000):\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\r\n        yanzhenglist_real = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xb8\xad\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n        prelist = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        errorlsit = []\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\r\n        for zhe in [zheshu for zheshu in data.keys() if zheshu != \'predict\']:\r\n            model = cb.CatBoostRegressor(iterations=iterations, depth=depth, learning_rate=0.8, loss_function=\'RMSE\')\r\n\r\n            model.fit(data[zhe][\'train\'][:, :-1], data[zhe][\'train\'][:, -1], cat_features=catsign)\r\n            # \xe6\xb3\xa8\xe6\x84\x8f\xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            xul = model.predict(data[zhe][\'train\'][:, :-1])\r\n            # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            yanre = model.predict(data[zhe][\'test\'][:, :-1])\r\n            # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n            prer = model.predict(data[\'predict\'][:, :-1])\r\n            yanzhenglist += list(yanre)\r\n            yanzhenglist_real += list(data[zhe][\'test\'][:, -1])\r\n            prelist.append(prer)\r\n            # \xe6\xaf\x8f\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe6\x8a\x98\xe5\x90\x8e\xef\xbc\x8c\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            xx = self.RMSE(xul, data[zhe][\'train\'][:, -1])\r\n            yy = self.RMSE(yanre, data[zhe][\'test\'][:, -1])\r\n            pp = self.RMSE(prer, data[\'predict\'][:, -1])\r\n            errorlsit.append([xx, yy, pp])\r\n        # \xe9\x92\x88\xe5\xaf\xb9\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe8\xae\xa1\xe7\xae\x97\xe5\x9d\x87\xe5\x80\xbc\r\n        meanPre = np.mean(np.array(prelist), axis=0)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x93\xe5\x90\x88\r\n        self.yanzhneg_pr.append(yanzhenglist)\r\n        self.yanzhneg_real = yanzhenglist_real\r\n        self.predi.append(meanPre)\r\n        self.preal = data[\'predict\'][:, -1]\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        self.error_dict[\'CatBoost\'] = np.mean(np.array(errorlsit), axis=0)\r\n        return print(\'1\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84CatBoost\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xbf\x90\xe8\xa1\x8c\xe9\x98\xb6\xe6\xae\xb5 \xe5\x8f\xaf\xe4\xbb\xa5\xe4\xbb\xbb\xe6\x84\x8f\xe6\x9b\xb4\xe6\x8d\xa2\xe6\xa8\xa1\xe5\x9e\x8b\r\n\'\'\'\r\nclass MODETWO:\r\n\r\n    def __init__(self, in_tr_data, out_tr_data, in_pre_data, out_pre, fenmu, cha):\r\n        self.xdata = in_tr_data\r\n        self.ydata = out_tr_data\r\n\r\n        self.xdatapre = in_pre_data\r\n        self.ydapre = out_pre\r\n\r\n        self.fen = fenmu\r\n\r\n        self.cha = cha\r\n        pass\r\n\r\n    # BP\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe5\x9b\x9e\xe5\xbd\x92\r\n    def BP(self, hiddenlayers=3, hiddennodes=100, learn_rate=0.05, itertimes=50000,\r\n           batch_size=200, activate_func=\'sigmoid\', break_error=0.00000043):\r\n        loss_trrr, loss_pree, sign, fir = bp.Ten_train(self.xdata, self.ydata, self.xdatapre, self.ydapre,\r\n                                                       hiddenlayers=hiddenlayers, hiddennodes=hiddennodes,\r\n                                                       learn_rate=learn_rate, itertimes=itertimes,\r\n                                                       batch_size=batch_size, activate_func=activate_func,\r\n                                                       break_error=break_error)\r\n        # \xe5\x9b\xa0\xe4\xb8\xba\xe4\xb8\x8a\xe9\x9d\xa2\xe7\x9a\x84\xe5\xbe\x97\xe5\x87\xba\xe7\x9a\x84RMSE\xe6\x98\xaf\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\x98\xe6\x8d\xa2\xe5\x90\x8e\xe7\x9a\x84\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe8\xbd\xac\xe6\x8d\xa2\xe5\x88\xb0\xe5\x8e\x9f\xe5\xa7\x8b\xe7\x9a\x84\xe7\xbb\xb4\xe5\xba\xa6\r\n        loss_trrr = np.array(loss_trrr) * self.fen\r\n\r\n        loss_pree = np.array(loss_pree) * self.fen\r\n\r\n        return loss_trrr, loss_pree, sign, fir\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\xef\xbc\x8c\xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe5\x90\x84\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x8c\r\n\xe4\xbb\xa5\xe5\x8f\x8a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n\'\'\'\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8b\xe8\xaf\x84\xe5\x88\x86\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\ndef Plot_RMSE_ONE_Stacking(exdict, kaudu=0.2):\r\n    \'\'\'\r\n    :param exdict: \xe4\xb8\x8d\xe5\x90\x8c\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84RMSE \xe6\x9c\x80\xe5\xb0\x8f\xe4\xba\x8c\xe4\xb9\x98\xe5\x9b\x9e\xe5\xbd\x92\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\xb9\xb3\xe6\x96\xb9\xe6\xa0\xb9\r\n    :return: \xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    \'\'\'\r\n    # \xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe5\x88\x97\xe8\xa1\xa8\r\n    palist = exdict.keys()\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    trsore = [exdict[hh][0] for hh in palist]\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    tesore = [exdict[hh][1] for hh in palist]\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    presore = [exdict[hh][2] for hh in palist]\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x88\xb6\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    fig, ax = plt.subplots()\r\n    # \xe6\x9f\xb1\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\n    ind = np.array(list(range(len(trsore))))\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x9f\xb1\xe7\x8a\xb6\r\n    ax.bar(ind - kaudu, trsore, kaudu, color=\'SkyBlue\', label=\'\xe8\xae\xad\xe7\xbb\x83\')\r\n    ax.bar(ind, tesore, kaudu, color=\'IndianRed\', label=\'\xe6\xb5\x8b\xe8\xaf\x95\')\r\n    ax.bar(ind + kaudu, presore, kaudu, color=\'slateblue\', label=\'\xe9\xa2\x84\xe6\xb5\x8b\')\r\n    # xy\xe8\xbd\xb4\xe7\x9a\x84\xe6\xa0\x87\xe7\xad\xbe\r\n    ax.set_ylabel(\'RMSE\')\r\n    ax.set_xlabel(\'Stacking\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\xad\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\')\r\n    # \xe8\xae\xbe\xe7\xbd\xae\xe5\x88\xbb\xe5\xba\xa6\r\n    ax.set_xticks(ind)\r\n    ax.set_xticklabels(palist)\r\n\r\n    ax.grid()\r\n\r\n    leg = ax.legend(loc=\'best\', ncol=3, shadow=True, fancybox=True)\r\n    leg.get_frame().set_alpha(0.8)\r\n    plt.title(\'Stacking\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\xad\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84RMSE\')\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\Stacking_pm25.jpg\')\r\n    bot.file_helper.send_image(r\'C:\\Users\\GWT9\\Desktop\\Stacking_pm25.jpg\')\r\n    return \'\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\x8d\xe5\x90\x8c\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xaf\xb9\xe6\xaf\x94\'\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n# \xe6\x8c\x89\xe7\x85\xa7\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\xe4\xbb\x8e\xe5\xb0\x8f\xe5\x88\xb0\xe5\xa4\xa7\xe6\x8e\x92\xe5\x88\x97\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\ndef Pailie(realr, modelout, count=90):\r\n    \'\'\'\r\n    :param real: \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    :param modelout: \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc\r\n    :param count: \xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\xaf\xb9\xe6\xaf\x94\xe7\x9a\x84\xe6\x9d\xa1\xe6\x95\xb0\r\n    :return: \xe6\x8c\x89\xe7\x85\xa7\xe5\xb7\xae\xe5\x80\xbc\xe4\xbb\x8e\xe5\xb0\x8f\xe5\x88\xb0\xe5\xa4\xa7\xe6\x8e\x92\xe5\x88\x97\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    \'\'\'\r\n    relal_num = np.array(realr)\r\n    modelout_num = np.array(modelout)\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96\r\n    fu = np.random.choice(list(range(len(realr))), count, replace=False)\r\n    show_real, show_model = relal_num[fu], modelout_num[fu]\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe5\xb7\xae\xe5\x80\xbc\r\n    sunnum = show_real - show_model\r\n    # \xe9\xa6\x96\xe5\x85\x88\xe7\xbb\x84\xe5\x90\x88\xe4\xb8\x89\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x97\xe8\xa1\xa8\xe4\xb8\xba\xe5\xad\x97\xe5\x85\xb8\r\n    zuhedict = {ii: [show_real[ii], show_model[ii], sunnum[ii]] for ii in range(len(show_model))}\r\n    # \xe5\xad\x97\xe5\x85\xb8\xe6\x8c\x89\xe7\x9d\x80\xe5\x80\xbc\xe6\x8e\x92\xe5\xba\x8f\r\n    zhenshi = []\r\n    yucede = []\r\n    chazhi = []\r\n    # \xe6\x8c\x89\xe7\x9d\x80\xe5\xb7\xae\xe5\x80\xbc\xe4\xbb\x8e\xe5\xa4\xa7\xe5\x88\xb0\xe5\xb0\x8f\r\n    for jj in sorted(zuhedict.items(), key=lambda gy: gy[1][2]):\r\n        zhenshi.append(jj[1][0])\r\n        yucede.append(jj[1][1])\r\n        chazhi.append(jj[1][2])\r\n    return zhenshi, yucede, chazhi\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xef\xbc\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\xaf\xb9\xe6\xaf\x94\xe6\x8a\x98\xe7\xba\xbf\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe4\xb8\x8e\xe4\xb8\xa4\xe5\x80\xbc\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\ndef recspre(yzhenshide, yyucede):\r\n    #  \xe8\x8e\xb7\xe5\xbe\x97\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    yreal, ypre, cha = Pailie(yzhenshide, yyucede)\r\n    plt.figure()\r\n    ax = plt.subplot(111)\r\n    plt.grid()\r\n    dign = np.arange(len(yreal))\r\n    #  \xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\r\n    ax.scatter(dign, yreal, label=\'\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\', lw=2, color=\'blue\', marker=\'*\')\r\n    #  \xe7\xbb\x98\xe5\x88\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    ax.plot(dign, ypre, label=\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\', lw=2, color=\'red\', linestyle=\'--\', marker=\'.\')\r\n    #  \xe7\xbb\x98\xe5\x88\xb6\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    ax.bar(dign, cha, 0.1, label=\'\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x87\x8f\xe5\x8e\xbb\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\', color=\'k\')\r\n    # \xe7\xbb\x98\xe5\x88\xb60\xe7\xba\xbf\r\n    ax.plot(dign, [0] * len(dign), lw=2, color=\'k\')\r\n\r\n    ax.set_ylim((int(min(cha)) - 1, int(max([max(yreal), max(ypre)]))))\r\n    ax.set_xlim((0, len(dign)))\r\n\r\n    ax.legend(loc=\'best\')\r\n    ax.set_title(\'\xe5\x8c\x97\xe4\xba\xac\xe5\xb8\x82Pm2.5\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94\')\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\Stacking_duibi.jpg\')\r\n    bot.file_helper.send_image(r\'C:\\Users\\GWT9\\Desktop\\Stacking_duibi.jpg\')\r\n    return \'\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb62\xe6\x9d\xa1\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\ndef plotcurve(trainone, pretwo):\r\n    fig, axs = plt.subplots(2, 1, sharex=True)\r\n    fig.subplots_adjust(hspace=0.1)\r\n    axs[0].plot(range(len(trainone)), trainone, label=\'\xe8\xae\xad\xe7\xbb\x83\', lw=3, color=\'maroon\')\r\n    axs[0].legend()\r\n    axs[1].plot(range(len(pretwo)), pretwo, label=\'\xe9\xaa\x8c\xe8\xaf\x81\', lw=3, color=\'sienna\')\r\n    axs[1].legend()\r\n    plt.xlabel(\'\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\')\r\n    axs[0].set_title(\'\xe7\xac\xac2\xe5\xb1\x82\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9aBPNN\xe4\xb8\xad\xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc\')\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\Stacking_errorr.jpg\')\r\n    bot.file_helper.send_image(r\'C:\\Users\\GWT9\\Desktop\\Stacking_errorr.jpg\')\r\n\r\n\'\'\'\r\n\xe7\xac\xac\xe4\xba\x94\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9aStacking\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\'\'\'\r\n\r\nif __name__ == ""__main__"":\r\n    #  \xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x826\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xef\xbc\x8cAdaBoost\xef\xbc\x8cGBDT\xef\xbc\x8cLightGBM\xef\xbc\x8cXGBoost\xef\xbc\x8cCatBoost\r\n\r\n    # \xe4\xb8\x8b\xe9\x9d\xa2\xe4\xbe\x9d\xe6\xac\xa1\xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xbb\xba\xe7\xab\x8b\xe6\x95\xb0\xe6\x8d\xae\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe3\x80\x81AdaBoost\xef\xbc\x8cGBDT\xef\xbc\x8cLIghtGNM\xef\xbc\x8cXGBoost\xe9\x83\xbd\xe6\x98\xaf\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\r\n    rf_data = DATA()\r\n    rf_data.CAtoDI()  # \xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\r\n    data_rf = rf_data.Kfold()  # \xe6\x8a\x98\xe6\x95\xb0\r\n\r\n    # CatBoost\r\n    cat_data = DATA()  # \xe4\xb8\x8d\xe7\x94\xa8\xe5\xa4\x84\xe7\x90\x86\r\n    data_cat = cat_data.Kfold()  # \xe6\x8a\x98\xe6\x95\xb0\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe5\xbb\xba\xe7\xab\x8bStacking\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\r\n    one_stacking = MODELONE()\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\r\n    one_stacking.RF_First(data_rf)\r\n    # AdaBoost\r\n    one_stacking.Adaboost_First(data_rf)\r\n    # GBDT\r\n    one_stacking.GBDT_First(data_rf)\r\n    # LightGBM\r\n    one_stacking.LightGBM_First(data_rf)\r\n    # XGBoost\r\n    one_stacking.XGBoost_First(data_rf)\r\n    # CatBoost\r\n    one_stacking.CatBoost_First(data_cat, cat_data.catsign)\r\n\r\n    # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\r\n    one_stacking.DataStru()\r\n    data_two = one_stacking.datai\r\n\r\n    # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\r\n    erce_data = DATA(datadict=data_two)\r\n    erce_data.Normal()\r\n    #  \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    redata = erce_data.Kfold()\r\n    #\r\n\r\n    # \xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe5\xbb\xba\xe6\xa8\xa1,\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe4\xb8\x8d\xe5\x9c\xa8\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe5\x8f\xaa\xe9\x80\x89\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    stacking_two = MODETWO(redata[0][\'train\'][:, :-1],\r\n                           np.array([redata[0][\'train\'][:, -1]]).T,\r\n                           redata[0][\'test\'][:, :-1],\r\n                           np.array([redata[0][\'test\'][:, -1]]).T,\r\n                           erce_data.fenmu, erce_data.cha)\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc, \xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe8\xbf\xad\xe4\xbb\xa3\xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n    lossrain, losspre, signi, gir = stacking_two.BP()\r\n\r\n\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\xe5\xae\x8c\xe6\x88\x90\xe5\x90\x8e\xe8\xaf\xbb\xe5\x8f\x96\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe5\x9c\xa8\xe8\xae\xa1\xe7\xae\x97\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\r\n    graph = tf.train.import_meta_graph(""./pm25-%s.meta"" % signi)\r\n    ses = tf.Session()\r\n    graph.restore(ses, tf.train.latest_checkpoint(\'./\'))\r\n    op_to_restore = tf.get_default_graph().get_tensor_by_name(""Sigmoid_%s:0"" % gir)  # \xe8\xbf\x99\xe4\xb8\xaatensor\xe7\x9a\x84\xe5\x90\x8d\xe7\xa7\xb0\xe5\x92\x8c\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\xe6\x9c\x89\xe5\x85\xb3\xe7\xb3\xbb\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe5\x8e\xbbBP\xe7\x9a\x84\xe7\xa8\x8b\xe5\xba\x8f\xe4\xb8\xad\xe8\x8e\xb7\xe5\xbe\x97\r\n    w1 = tf.get_default_graph().get_tensor_by_name(""x_data:0"")\r\n    feed_dict = {w1: redata[\'predict\'][:, :-1]}\r\n    dgsio = ses.run(op_to_restore, feed_dict)\r\n\r\n    preout = erce_data.fenmu * dgsio.T[0] + erce_data.cha\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xb8\x80\xe5\xb1\x82\xe4\xb8\xad\xe5\x90\x84\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9b\xbe\r\n    Plot_RMSE_ONE_Stacking(one_stacking.error_dict)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xef\xbc\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\xaf\xb9\xe6\xaf\x94\xe6\x8a\x98\xe7\xba\xbf\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe4\xb8\x8e\xe4\xb8\xa4\xe5\x80\xbc\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    recspre(erce_data.fenmu * erce_data.nodata.values[:, -1] + erce_data.cha, preout)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe7\xac\xac\xe4\xba\x8c\xe5\xb1\x82\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe8\xaf\xaf\xe5\xb7\xae\r\n    plotcurve(lossrain, losspre)'"
Stacking/adult_Stacking_Data.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n#  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\ntrain_path = r\'C:\\Users\\lenovo\\Desktop\\Adult_Train.csv\'\r\n\r\n#  \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\npre_path = r\'C:\\Users\\lenovo\\Desktop\\Adult_Test.csv\'\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe5\xb9\xb6\xe4\xb8\x94\xe5\xa4\x84\xe7\x90\x86\xe7\xa1\xae\xe7\xbc\xba\xe5\xa4\xb1\xe6\x95\xb0\xe6\x8d\xae\r\ndef ReadHandle(filepath, miss=\'fill\'):  # \xe5\xae\x9a\xe4\xb9\x89\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    data = pd.read_csv(r\'%s\' % filepath)\r\n    data = data.replace(\'?\', np.nan)\r\n    #  \xe5\xa4\x84\xe7\x90\x86\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if miss == \'del\':  # \xe5\x88\xa0\xe9\x99\xa4\xe6\x8e\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n        miss_data = data.dropna(how=\'any\')\r\n    else:\r\n        miss_data = data.fillna(method=\'ffill\')\r\n    return miss_data\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nread_trai = ReadHandle(train_path)\r\nread_pr = ReadHandle(pre_path)\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xba\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5""Money""\xe4\xb8\xad\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe8\xbe\x83\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x9a\xe4\xba\x86\xe4\xb8\x80\xe4\xb8\xaa\xe7\x82\xb9\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe5\xa4\x84\xe7\x90\x86\r\nread_pr[""Money""] = [ii[:-1] for ii in read_pr[""Money""]]\r\n\r\n\r\n# \xe5\x92\x8cStacking\xe5\x9b\x9e\xe5\xbd\x92\xe4\xb8\x80\xe6\xa0\xb7\xef\xbc\x8c\xe7\x94\xa8\xe5\xad\x97\xe5\x85\xb8\xe5\x82\xa8\xe5\xad\x98\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe4\xbf\x9d\xe8\xaf\x81\xe4\xba\x86\xe4\xbb\xa3\xe7\xa0\x81\xe7\x9a\x84\xe5\xa4\x8d\xe7\x94\xa8\r\ndata_dict = {}\r\ndata_dict[\'train\'] = read_trai\r\ndata_dict[\'predict\'] = read_pr'"
Stacking/bp_Classify.py,18,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n'''\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xba\x93'''\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n'''\xe5\x87\xbd\xe6\x95\xb0'''\r\n#  \xe6\xa0\xb9\xe6\x8d\xae\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\x88\xa4\xe6\x96\xad\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef judge(ydata):\r\n    maxnum = np.max(ydata, axis=1)\r\n    lastdata = []\r\n    for ii in range(len(ydata)):\r\n        maxindex = list(ydata[ii]).index(maxnum[ii])\r\n        fu = [0] * len(ydata[0])\r\n        fu[maxindex] = 1\r\n        lastdata.append(fu)\r\n    return np.array(lastdata)\r\n\r\n#  \xe6\xa0\xb9\xe6\x8d\xae\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe4\xbb\xa5\xe5\x8f\x8a\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\xe8\xbe\x93\xe5\x87\xba\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\x95\x88\xe6\x9e\x9c\r\ndef outvsreal(outdata, realdata):\r\n    subdata = outdata - realdata\r\n    sundata = np.sum(np.abs(subdata), axis=1)\r\n    correct = list(sundata).count(0)\r\n    return correct / len(outdata)\r\n\r\n\r\n'''\xe5\x9f\xba\xe4\xba\x8eTensorFlow\xe6\x9e\x84\xe5\xbb\xba\xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0'''\r\n# \xe5\x88\x9b\xe5\xbb\xba\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\ndef activate(input_layer, weights, biases, actfunc):\r\n    layer = tf.add(tf.matmul(input_layer, weights), biases)\r\n    if actfunc == 'relu':\r\n        return tf.nn.relu(layer)\r\n    elif actfunc == 'tanh':\r\n        return tf.nn.tanh(layer)\r\n    elif actfunc == 'sigmoid':\r\n        return tf.nn.sigmoid(layer)\r\n    elif actfunc == 'linear':\r\n        return layer\r\n\r\n\r\n# \xe6\x9d\x83\xe9\x87\x8d\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe5\x92\x8c\xe5\x88\xa9\xe7\x94\xa8\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\xe5\xbe\x88\xe5\xa4\xa7\r\n# sigmoid: xavir  tanh: xavir   relu: he\r\n\r\n#  \xe6\x9e\x84\xe5\xbb\xba\xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Ten_train(xdata, ydata, addxdata, addydata, hiddenlayers=3, hiddennodes=100, \\\r\n              learn_rate=0.02, itertimes=20, batch_size=200, activate_func='tanh'):\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe6\x90\xad\xe5\xbb\xba\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\r\n    Input_Dimen = len(xdata[0])\r\n    Unit_Layers = [Input_Dimen] + [hiddennodes] * hiddenlayers + [len(ydata[0])]  # \xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84\xe7\xbb\xb4\xe6\x95\xb0\xef\xbc\x8c\xe9\x9a\x90\xe5\xb1\x82\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe6\x95\xb0\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\xb4\xe6\x95\xb01\r\n\r\n    # \xe5\x88\x9b\xe5\xbb\xba\xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\r\n    x_data = tf.placeholder(shape=[None, Input_Dimen], dtype=tf.float32, name='x_data')\r\n\r\n    y_target = tf.placeholder(shape=[None, len(ydata[0])], dtype=tf.float32)\r\n\r\n    # \xe5\xae\x9e\xe7\x8e\xb0\xe5\x8a\xa8\xe6\x80\x81\xe5\x91\xbd\xe5\x90\x8d\xe5\x8f\x98\xe9\x87\x8f\r\n    VAR_NAME = locals()\r\n    for jj in range(hiddenlayers + 1):\r\n        VAR_NAME['weight%s' % jj] = tf.Variable(np.random.rand(Unit_Layers[jj], Unit_Layers[jj + 1]) / np.sqrt(Unit_Layers[jj]), \\\r\n                                                dtype=tf.float32, name='Weight%s' % jj)  # sigmoid  tanh\r\n        # VAR_NAME['weight%s'%jj] = tf.Variable(np.random.rand(Unit_Layers[jj], Unit_Layers[jj + 1]),dtype=tf.float32, \\name='weight%s' % jj) \\/ np.sqrt(Unit_Layers[jj] / 2)  # relu\r\n        VAR_NAME['bias%s' % jj] = tf.Variable(tf.random_normal([Unit_Layers[jj + 1]], stddev=10), dtype=tf.float32, name='Bias%s' % jj)\r\n        if jj == 0:\r\n            VAR_NAME['ooutda%s' % jj] = activate(x_data, eval('weight%s' % jj), eval('bias%s' % jj),\r\n                                                 actfunc=activate_func)\r\n        elif jj == hiddenlayers:\r\n            VAR_NAME['ooutda%s' % jj] = activate(eval('ooutda%s' % (jj - 1)), eval('weight%s' % jj),\\\r\n                                                 eval('bias%s' % jj), actfunc='linear')  # \xe5\x9b\xa0\xe6\xad\xa4\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\xb1\x82\xe9\x87\x87\xe7\x94\xa8\xe7\xba\xbf\xe6\x80\xa7\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n        else:\r\n            VAR_NAME['ooutda%s' % jj] = activate(eval('ooutda%s' % (jj - 1)), eval('weight%s' % jj),\\\r\n                                                 eval('bias%s' % jj), actfunc=activate_func)\r\n    #  \xe9\x9c\x80\xe8\xa6\x81\xe5\xaf\xb9\xe8\xbe\x93\xe5\x87\xba\xe8\xbf\x9b\xe8\xa1\x8csoftmax\xe8\xae\xa1\xe7\xae\x97\r\n    uuu = tf.nn.softmax(eval('ooutda%s' % (hiddenlayers)))\r\n\r\n    # \xe4\xba\xa4\xe5\x8f\x89\xe7\x86\xb5\xe5\x87\xbd\xe6\x95\xb0\r\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_target, logits=eval('ooutda%s' % (hiddenlayers))))\r\n\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\xe9\x9c\x80\xe8\xa6\x81\r\n\r\n    accu = eval('ooutda%s' % hiddenlayers)\r\n\r\n    # \xe4\xbc\x98\xe5\x8c\x96\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\r\n    # my_opt = tf.train.GradientDescentOptimizer(learn_rate)\r\n    my_opt = tf.train.AdamOptimizer(learn_rate)\r\n    train_step = my_opt.minimize(loss)\r\n\r\n    # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n    init = tf.global_variables_initializer()\r\n\r\n    loss_vec = []  # \xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\r\n\r\n    loss_vec_add = []  # \xe9\xaa\x8c\xe8\xaf\x81\xe8\xaf\xaf\xe5\xb7\xae\r\n\r\n    acc_vec = []  # \xe8\xae\xad\xe7\xbb\x83\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\r\n\r\n    acc_vec_add = []  # \xe9\xaa\x8c\xe8\xaf\x81\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\r\n\r\n    #  \xe9\x9c\x80\xe8\xa6\x81\xe4\xbf\x9d\xe5\xad\x98\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x81\x8f\xe7\xbd\xae\r\n    graph = tf.get_default_graph()\r\n    saver = tf.train.Saver(max_to_keep=1)\r\n    sess = tf.Session()\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    accudict = {}\r\n    accunum = 0\r\n    sess.run(init)\r\n    for i in range(itertimes):  # \xe5\x9c\xa8\xe6\x80\xbb\xe5\x85\xb1\xe7\x9a\x84\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe9\xab\x98\xe7\x9a\x84\xef\xbc\x88\xe9\xaa\x8c\xe8\xaf\x81\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87+\xe8\xae\xad\xe7\xbb\x83\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xef\xbc\x89\r\n        for jj in range(int(len(xdata) / batch_size)):\r\n            rand_index = np.random.choice(len(xdata), size=batch_size, replace=False)\r\n            rand_x = xdata[rand_index]\r\n            rand_y = ydata[rand_index]\r\n            #  \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n            sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\r\n\r\n        #  \xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\r\n        temp_loss = sess.run(loss, feed_dict={x_data: xdata, y_target: ydata})\r\n        #  \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\r\n        loss_vec.append(temp_loss)\r\n\r\n        #  \xe9\xaa\x8c\xe8\xaf\x81\xe8\xaf\xaf\xe5\xb7\xae\r\n        temp_loss_add = sess.run(loss, feed_dict={x_data: addxdata, y_target: addydata})\r\n        #  \xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe8\xaf\xaf\xe5\xb7\xae\r\n        loss_vec_add.append(temp_loss_add)\r\n\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\r\n        acc_ru = sess.run(accu, feed_dict={x_data: xdata})\r\n        acc_rughy_train = outvsreal(judge(acc_ru), ydata)\r\n        #  \xe5\xad\x98\xe5\x82\xa8\r\n        acc_vec.append(acc_rughy_train)\r\n        #  \xe9\xaa\x8c\xe8\xaf\x81\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\r\n        acu = sess.run(accu, feed_dict={x_data: addxdata})\r\n        acc_rughy = outvsreal(judge(acu), addydata)\r\n        # \xe5\xad\x98\xe5\x82\xa8\r\n        acc_vec_add.append(acc_rughy)\r\n\r\n        print('%s\xe4\xbb\xa3\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9a [\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x9a%.4f, \xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x9a%.4f], \xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xef\xbc\x9a [\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x9a%.4f, \xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x9a%.4f]' % (i, temp_loss,\r\n                                                                      temp_loss_add, acc_rughy_train, acc_rughy))\r\n        accudict[i] = [acc_rughy_train, acc_rughy]\r\n\r\n        #  \xe5\x9c\xa8\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\xbe\xaa\xe7\x8e\xaf\xe6\xac\xa1\xe6\x95\xb0\xe4\xb8\xad\xef\xbc\x8c\xe6\x89\xbe\xe5\x88\xb0\xe7\xbb\xbc\xe5\x90\x88\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\xe6\x9c\x80\xe9\xab\x98\xe7\x9a\x84\xe4\xb8\x80\xe6\xac\xa1\xef\xbc\x8c\xe4\xbf\x9d\xe5\xad\x98\xe5\x8f\x82\xe6\x95\xb0\r\n        zongheaccu = 0.1 * acc_rughy_train + 0.9 * acc_rughy\r\n        if zongheaccu > accunum:\r\n            accunum = zongheaccu\r\n            # \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\r\n            saver.save(sess, r'E:\\tensorflow_Learn\\Stacking\\adult\\model', global_step=i)  # \xe6\xb3\xa8\xe6\x84\x8f\xe8\xb7\xaf\xe5\xbe\x84\r\n\r\n    sign = max(accudict.items(), key=lambda d: 0.1 * d[1][0] + 0.9 * d[1][1])[0]\r\n    print('\xe6\x8a\x98\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\xef\xbc\x8c\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xb7\xb2\xe7\xbb\x8f\xe4\xbf\x9d\xe5\xad\x98\xef\xbc\x8c\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84\xe6\x98\xaf%s\xe4\xbb\xa3' % sign)\r\n    return loss_vec[: sign + 1], loss_vec_add[: sign + 1], acc_vec[: sign + 1], acc_vec_add[: sign + 1], sign, hiddenlayers\r\n\r\n\r\n"""
Stacking/pm25_Stacking_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\PRSA_data_2010.1.1-2014.12.31.csv')\r\n\r\n\r\n'''\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86'''\r\n#  \xe5\x9b\xa0\xe4\xb8\xbaPm2.5\xe6\x98\xaf\xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9b\xb4\xe6\x8e\xa5\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xb8\x80\xe6\x9d\xa1\xe8\xae\xb0\xe5\xbd\x95\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe7\x9b\xae\xe6\xa0\x87\xe5\x80\xbc\xe4\xb8\xba\xe7\xa9\xba\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c, \xe5\x85\xb6\xe4\xbb\x96\xe5\x88\x97\xe4\xb8\xba\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe5\x88\x99\xe8\x87\xaa\xe5\x8a\xa8\xe5\xa1\xab\xe5\x85\x85,\xe5\xb9\xb6\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\x8f\x98\xe9\x87\x8f\xe6\x94\xbe\xe7\xbd\xae\xe5\x9c\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\x88\x97\r\ndef DeleteTargetNan(exdata, targetstr):\r\n    '''\r\n    :param exdata: dataframe\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    :param targetstr: \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\xe7\xa7\xb0\r\n    :return: \xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe7\x9a\x84dataframe\xe6\xa0\xbc\xe5\xbc\x8f\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    '''\r\n    #  \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if exdata[targetstr].isnull().any():\r\n        #  \xe9\xa6\x96\xe5\x85\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe6\x95\xb0\r\n        loc = exdata[targetstr][data[targetstr].isnull().values == True].index.tolist()\r\n        #  \xe7\x84\xb6\xe5\x90\x8e\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xba\x9b\xe8\xa1\x8c\r\n        exdata = exdata.drop(loc)\r\n    # \xe5\x87\xa1\xe6\x98\xaf\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\x86\x8d\xe4\xb8\x80\xe8\xb5\xb7\xe5\x88\xa9\xe7\x94\xa8\xe6\xad\xa4\xe8\xa1\x8c\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\xe5\xa1\xab\xe5\x85\x85\r\n    exdata = exdata.fillna(exdata.mean())\r\n    # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\x87\xb3\xe6\x94\xbe\xe5\x9c\xa8\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe4\xb8\x80\xe5\x88\x97\r\n    targetnum = exdata[targetstr].copy()\r\n    del exdata[targetstr]\r\n    exdata[targetstr] = targetnum\r\n    return exdata\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\r\ndef Shanchu(exdata, aiduan=['No']):\r\n    for ai in aiduan:\r\n        if ai in exdata.keys():\r\n            del exdata[ai]\r\n    return exdata\r\n\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\nfirst = DeleteTargetNan(data, 'pm2.5')\r\n# \xe5\x8e\xbb\xe9\x99\xa4\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8e\r\ntwo = Shanchu(first)\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xba\xe6\xad\xa4\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\xb2\xa1\xe6\x9c\x89\xe6\x8f\x90\xe4\xbe\x9b\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe5\x9c\xa8\xe6\x80\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\xe4\xb8\xad\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe6\x8b\xa9\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xe4\xbd\x9c\xe4\xb8\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n# \xe5\xaf\xb9\xe4\xba\x8eStacking\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe9\x9c\x80\xe8\xa6\x81\xe4\xbf\x9d\xe8\xaf\x81\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x98\xaf\xe5\x9b\xba\xe5\xae\x9a\xe7\x9a\x84\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe5\x9b\xba\xe5\xae\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe7\xa7\x8d\xe5\xad\x90\xef\xbc\x8c\xe4\xbf\x9d\xe8\xaf\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x98\xaf\xe5\x9b\xba\xe5\xae\x9a\xe7\x9a\x84\r\n# \xe5\xaf\xb9\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84k\xe6\x8a\x98\xe5\xa4\x84\xe7\x90\x86\xe4\xbb\xa5\xe5\x8f\x8a\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe6\x94\xbe\xe5\x9c\xa8\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe4\xb8\xad\r\n\r\ndef fenge(exdata, per=0.2):\r\n    '''\r\n    :param exdata: \xe6\x80\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86DataFrame\xe6\xa0\xbc\xe5\xbc\x8f\r\n    :param per: \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe5\x8d\xa0\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\r\n    :return: \xe8\xbf\x94\xe5\x9b\x9e{'train':dataframe, 'predict':dataframe}\xe6\xa0\xb7\xe5\xbc\x8f\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    '''\r\n\r\n    np.random.seed(1000)\r\n    df_predict = exdata.sample(frac=per)\r\n\r\n    rowlist = []\r\n    for indexs in df_predict.index:\r\n        rowlist.append(indexs)\r\n    df_train = exdata.drop(rowlist, axis=0)\r\n\r\n    # \xe4\xbf\x9d\xe5\xad\x98\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    datict = {}\r\n    datict['train'] = df_train\r\n    datict['predict'] = df_predict\r\n\r\n    return datict\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\r\ndata_dict = fenge(two)\r\n\r\n\r\n\r\n\r\n\r\n"""
BPNN/BPNN_Classify/AnFany_BPNN_Classify.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xba\x93\'\'\'\r\n\r\n\r\nimport BPNN_Classify_Data as bpd\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\'] # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\nmpl.rcParams[\'axes.unicode_minus\'] = False # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n#  \xe5\x88\x86\xe7\xb1\xbb\xe6\x95\xb0\r\ncountclass = 2\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\x87\xbd\xe6\x95\xb0\'\'\'\r\n\r\n# \xe9\x9a\x90\xe5\xb1\x82\xe7\x9a\x84\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n# \xe6\xb3\xa8\xe6\x84\x8f\xef\xbc\x9a\xe7\xa8\x8b\xe5\xba\x8f\xe4\xb8\xad\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xad\xe7\x9a\x84\xe5\xaf\xbc\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xad\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xef\xbc\x8c\xe6\x98\xaf\xe6\x89\xa7\xe8\xa1\x8c\xe8\xbf\x87\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\xe5\x90\x8e\xe7\x9a\x84\xe5\x80\xbc\r\ndef Sigmoid(x):\r\n    s = 1 / (1 + np.exp(-x))\r\n    return s\r\n\r\ndef Sigmoid_der(s):\r\n    y = np.multiply(s, 1 - s)\r\n    return y\r\n\r\n\r\ndef Relu(x):\r\n    s = np.maximum(0, x)\r\n    return s\r\n\r\ndef Relu_der(s):\r\n    y = np.where(s > 0, np.ones(s.shape), np.zeros(s.shape))\r\n    return y\r\n\r\n\r\ndef Tanh(x):\r\n    s = np.tanh(x)\r\n    return s\r\n\r\ndef Tanh_der(s):\r\n    y = 1 - np.multiply(s, s)\r\n    return y\r\n\r\n\r\n#  \xe9\x98\xb2\xe6\xad\xa2\xe8\xad\xa6\xe5\x91\x8a\xef\xbc\x8c\xe5\xaf\xb9\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xbf\xae\xe6\xad\xa3\r\ndef right(exnup, minnum=0.00001, maxnum=0.9999):\r\n    xnup = np.where(exnup < minnum, np.array([minnum]), exnup)\r\n    nup = np.where(xnup > maxnum, np.array([maxnum]), xnup)\r\n    return nup\r\n\r\n# \xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\r\ndef cross_entropy(yreal, yout):  # yreal \xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc yout \xe7\xbd\x91\xe7\xbb\x9c\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc\r\n    yout = right(yout)\r\n    costnum = - (yreal * np.log(yout) + (1 - yreal) * np.log(1 - yout)).sum() / len(yreal)\r\n    return costnum\r\n\r\ndef cross_entropy_der(yreal, yout):\r\n    yout = right(yout)\r\n    return -(yreal - yout) / (yout * (1 - yout)) / len(yreal)\r\n\r\n\r\n# \xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe7\x9a\x84\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\ndef Linear(x):  # \xe7\xba\xbf\xe6\x80\xa7\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\x8c\x83\xe5\x9b\xb4\xe5\xb9\xb3\xe7\xa7\xbb\xc2\xb7\xc2\xb7\xe5\x88\xb0\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\x8c\x83\xe5\x9b\xb4\r\n    return x\r\n\r\n\r\ndef Linear_der(s):\r\n    y = np.zeros(shape=s.shape)\r\n    return y\r\n\r\n\r\n#  \xe6\xa0\xb9\xe6\x8d\xae\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\x88\xa4\xe6\x96\xad\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef judge(ydata):\r\n    maxnum = np.max(ydata, axis=1)\r\n    lastdata = []\r\n    for ii in range(len(ydata)):\r\n        maxindex = list(ydata[ii]).index(maxnum[ii])\r\n        fu = [0] * len(ydata[0])\r\n        fu[maxindex] = 1\r\n        lastdata.append(fu)\r\n    return np.array(lastdata)\r\n\r\n\r\n#  \xe6\xa0\xb9\xe6\x8d\xae\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe4\xbb\xa5\xe5\x8f\x8a\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\xe8\xbe\x93\xe5\x87\xba\xe5\x88\x86\xe7\xb1\xbb\xe8\xb5\xb7\xe7\x9a\x84\xe6\x95\x88\xe6\x9e\x9c\r\ndef outvsreal(outdata, realdata):\r\n    subdata = outdata - realdata\r\n    sundata = np.sum(np.abs(subdata), axis=1)\r\n    correct = list(sundata).count(0)\r\n    return correct / len(outdata)\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xae\x9e\xe7\x8e\xb0\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\'\'\'\r\n\r\n\r\nclass BPNN():\r\n    def __init__(self, train_in, train_out, add_in, add_out, learn_rate=0.003, son_samples=50 \\\r\n                 , iter_times=200000, hidden_layer=[100, 100, 100], middle_name=\'Sigmoid\' \\\r\n                 , last_name=\'Sigmoid\', cost_func=\'cross_entropy\', norr=0.00002, break_error=0.84):\r\n        self.train_in = train_in  # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbe\x93\xe5\x85\xa5\r\n        self.train_out = train_out  # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbe\x93\xe5\x87\xba\r\n\r\n        self.add_in = add_in\r\n        self.add_out = add_out\r\n\r\n        self.learn_rate = learn_rate  # \xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\r\n        self.son_samples = son_samples  # \xe5\xad\x90\xe6\xa0\xb7\xe6\x9c\xac\xe4\xb8\xaa\xe6\x95\xb0\r\n        self.iter_times = iter_times  # \xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\r\n\r\n        self.all_layer = [len(self.train_in[0])] + hidden_layer + [len(self.train_out[0])]  # \xe5\xae\x9a\xe4\xb9\x89\xe5\x90\x84\xe5\xb1\x82\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe5\x85\x83\xe4\xb8\xaa\xe6\x95\xb0\r\n        self.func_name = [middle_name] * len(hidden_layer) + [last_name]  # \xe5\xae\x9a\xe4\xb9\x89\xe5\x90\x84\xe5\xb1\x82\xe7\x9a\x84\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\n        #  \xe5\x8f\x82\xe6\x95\xb0\xe8\xae\xbe\xe7\xbd\xae\r\n        # self.weight = [np.array(np.random.randn(x, y) / np.sqrt(x) * 0.01, dtype=np.float64) \\\r\n        #                for x, y in zip(self.all_layer[:-1], self.all_layer[1:])]  # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe6\x9d\x83\xe9\x87\x8d\r\n\r\n        self.weight = [np.array(np.random.randn(x, y)) for x, y in\r\n                       zip(self.all_layer[:-1], self.all_layer[1:])]  # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe6\x9d\x83\xe9\x87\x8d\r\n\r\n        self.bias = [np.random.randn(1, y) * 0.01 for y in self.all_layer[1:]]  # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe5\x81\x8f\xe7\xbd\xae\r\n\r\n        self.cost_func = cost_func\r\n        self.norr = norr\r\n        self.break_error = break_error\r\n\r\n    # \xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\r\n    def train_gadient(self):\r\n        # \xe9\x87\x87\xe7\x94\xa8\xe9\x9a\x8f\xe6\x9c\xba\xe5\xb0\x8f\xe6\x89\xb9\xe9\x87\x8f\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe7\xbb\x93\xe5\x90\x88\xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\r\n        alldata = np.hstack((self.train_in, self.train_out))\r\n        np.random.shuffle(alldata)  # \xe6\x89\x93\xe4\xb9\xb1\xe9\xa1\xba\xe5\xba\x8f\r\n        # \xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe8\xbe\x93\xe5\x87\xba\xe5\x88\x86\xe5\xbc\x80\r\n        trin = alldata[:, :len(self.train_in[0])]  # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbe\x93\xe5\x85\xa5\r\n        trout = alldata[:, len(self.train_in[0]):]  # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbe\x93\xe5\x87\xba\r\n\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe6\x89\xb9\xe6\xac\xa1\xe6\x95\xb0\r\n        pici = int(len(alldata) / self.son_samples) + 1\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n        error_list = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n        error_list_add =[]\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n        xlcorr = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n        adcorr = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\x9d\x83\xe9\x87\x8d\xe5\x92\x8c\xe5\x81\x8f\xe7\xbd\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        sacewei = []\r\n        iter = 0\r\n\r\n        while iter < self.iter_times:\r\n            for times in range(pici):\r\n                in_train = trin[times * self.son_samples: (times + 1) * self.son_samples, :]\r\n                out_train = trout[times * self.son_samples: (times + 1) * self.son_samples, :]\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xad\xa5\xe5\x85\xa5\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\r\n\r\n                a = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe5\x92\x8c\xe5\x80\xbc\r\n                z = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n\r\n                a[0] = in_train.copy()  # \xe5\x92\x8c\xe5\x80\xbc\r\n                z[0] = in_train.copy()  # \xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x80\x90\xe5\xb1\x82\xe6\xad\xa3\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\r\n                for forward in range(1, len(self.all_layer)):  # 1,2,3\r\n                    a[forward] = np.dot(z[forward - 1], self.weight[forward - 1]) + self.bias[forward - 1]\r\n                    z[forward] = eval(self.func_name[forward - 1])(a[forward])\r\n\r\n                # \xe5\xae\x9a\xe4\xb9\x89\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe8\xaf\xaf\xe5\xb7\xae\r\n                ne = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n\r\n                qiaia = eval(self.cost_func + \'_der\')(out_train, z[-1])\r\n                hhou = eval(self.func_name[-1] + \'_der\')(z[-1])\r\n                ne[-1] = np.multiply(qiaia, hhou)\r\n\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x80\x90\xe5\xb1\x82\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\r\n                for backward in range(len(self.all_layer) - 1, 0, -1):\r\n                    qianzhe = np.dot(ne[backward], self.weight[backward - 1].T)\r\n                    houzhe = eval(self.func_name[backward - 1] + \'_der\')(z[backward - 1])\r\n                    ne[backward - 1] = np.multiply(qianzhe, houzhe)\r\n\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x80\x90\xe5\xb1\x82\xe8\xae\xa1\xe7\xae\x97\xe6\x9b\xb4\xe6\x94\xb9W\xe5\x92\x8cB\xe5\x80\xbc\r\n                dw = list(range(len(self.all_layer) - 1))\r\n                db = list(range(len(self.all_layer) - 1))\r\n\r\n                # L2\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\r\n                for iwb in range(len(self.all_layer) - 1):\r\n                    dw[iwb] = np.dot(a[iwb].T, ne[iwb + 1]) / self.son_samples + \\\r\n                              (self.norr / self.son_samples) * dw[iwb]\r\n\r\n                    db[iwb] = np.sum(ne[iwb + 1], axis=0, keepdims=True) / self.son_samples + \\\r\n                              (self.norr / self.son_samples) * db[iwb]\r\n\r\n                # \xe6\x9b\xb4\xe6\x94\xb9\xe6\x9d\x83\xe9\x87\x8d\r\n                for ich in range(len(self.all_layer) - 1):\r\n                    self.weight[ich] -= self.learn_rate * dw[ich]\r\n                    self.bias[ich] -= self.learn_rate * db[ich]\r\n\r\n            # \xe6\x95\xb4\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbf\xad\xe4\xbb\xa3\xe4\xb8\x80\xe6\xac\xa1\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            a[0] = trin.copy()  # \xe5\x92\x8c\xe5\x80\xbc\r\n            z[0] = trin.copy()  # \xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n            for forward in range(1, len(self.all_layer)):\r\n                a[forward] = np.dot(z[forward - 1], self.weight[forward - 1]) + self.bias[forward - 1]\r\n                z[forward] = eval(self.func_name[forward - 1])(a[forward])\r\n\r\n            # \xe6\x89\x93\xe5\x8d\xb0\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n            errortrain = eval(self.cost_func)(trout, z[-1])\r\n            train_corr = outvsreal(judge(z[-1]), trout)\r\n            print(\'\xe7\xac\xac%s\xe4\xbb\xa3\xe8\xae\xad\xe7\xbb\x83\xe6\xa0\xb7\xe6\x9c\xac\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9a%.9f, \xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xb8\xba%.5f\' % (iter, errortrain, train_corr))\r\n            error_list.append(errortrain)\r\n\r\n            # \xe6\x95\xb4\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbf\xad\xe4\xbb\xa3\xe4\xb8\x80\xe6\xac\xa1\xe8\xae\xa1\xe7\xae\x97\xe9\xaa\x8c\xe8\xaf\x81\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            a[0] = self.add_in.copy()  # \xe5\x92\x8c\xe5\x80\xbc\r\n            z[0] = self.add_in.copy()  # \xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n            for forward in range(1, len(self.all_layer)):\r\n                a[forward] = np.dot(z[forward - 1], self.weight[forward - 1]) + self.bias[forward - 1]\r\n                z[forward] = eval(self.func_name[forward - 1])(a[forward])\r\n\r\n            # \xe6\x89\x93\xe5\x8d\xb0\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n            erain = eval(self.cost_func)(self.add_out, z[-1])\r\n            add_correct = outvsreal(judge(z[-1]), self.add_out)\r\n            print(\'-----------------------\xe9\xaa\x8c\xe8\xaf\x81\xe6\xa0\xb7\xe6\x9c\xac\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9a%.9f, \xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xb8\xba%.5f\' % (erain, add_correct))\r\n            error_list_add.append(erain)\r\n\r\n            iter += 1\r\n            xlcorr.append(train_corr)\r\n            adcorr.append(add_correct)\r\n\r\n            # \xe5\xad\x98\xe5\x82\xa8\xe6\x9d\x83\xe9\x87\x8d\xe5\x92\x8c\xe5\x81\x8f\xe7\xbd\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n            if len(sacewei) == 4:\r\n                sacewei = sacewei[1:].copy()\r\n                sacewei.append([self.weight, self.bias])\r\n            else:\r\n                sacewei.append([self.weight, self.bias])\r\n\r\n            #  \xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\xe7\x9a\x84\xe5\x88\xa4\xe6\x96\xad(\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe7\xb1\xbb\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe8\xbf\x9e\xe7\xbb\xad\xe4\xb8\x8b\xe9\x99\x8d\xe4\xb8\x89\xe6\xac\xa1\xef\xbc\x8c\xe9\x80\x80\xe5\x87\xba\xe5\xbe\xaa\xe7\x8e\xaf, \xe5\xb9\xb6\xe4\xb8\x94\xe5\xad\x98\xe5\x82\xa8\xe7\xac\xac\xe4\xb8\x80\xe6\xac\xa1\xe4\xb8\x8b\xe9\x99\x8d\xe5\x89\x8d\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\xe5\x92\x8c\xe5\x81\x8f\xe7\xbd\xae\xef\xbc\x89\r\n            if len(adcorr) >= 4:\r\n                # \xe5\x88\xa4\xe6\x96\xad\xe8\xbf\x9e\xe7\xbb\xad\xe4\xb8\x89\xe6\xac\xa1\xe4\xb8\x8b\xe9\x99\x8d\r\n                edlist = adcorr[-4:-1]\r\n                delist = adcorr[-3:]\r\n                sublist = np.array(edlist) - np.array(delist)\r\n                if np.all(sublist > 0):\r\n                    self.weight, self.bias = sacewei[0]\r\n                    break\r\n\r\n        return self.weight, self.bias, error_list, xlcorr, adcorr, error_list_add\r\n\r\n    def train_adam(self, mom=0.9, prop=0.9):\r\n        # \xe9\x87\x87\xe7\x94\xa8\xe9\x9a\x8f\xe6\x9c\xba\xe5\xb0\x8f\xe6\x89\xb9\xe9\x87\x8f\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe7\xbb\x93\xe5\x90\x88\xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\r\n        alldata = np.hstack((self.train_in, self.train_out))\r\n        np.random.shuffle(alldata)  # \xe6\x89\x93\xe4\xb9\xb1\xe9\xa1\xba\xe5\xba\x8f\r\n        # \xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe8\xbe\x93\xe5\x87\xba\xe5\x88\x86\xe5\xbc\x80\r\n        trin = alldata[:, :len(self.train_in[0])]  # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbe\x93\xe5\x85\xa5\r\n        trout = alldata[:, len(self.train_in[0]):]  # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbe\x93\xe5\x87\xba\r\n\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe6\x89\xb9\xe6\xac\xa1\xe6\x95\xb0\r\n        pici = int(len(alldata) / self.son_samples) + 1\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n        error_list = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n        error_list_add =[]\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n        xlcorr = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n        adcorr = []\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe6\x9d\x83\xe9\x87\x8d\xe5\x92\x8c\xe5\x81\x8f\xe7\xbd\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        sacewei = []\r\n        iter = 0\r\n\r\n        while iter < self.iter_times:\r\n            for times in range(pici):\r\n                in_train = trin[times * self.son_samples: (times + 1) * self.son_samples, :]\r\n                out_train = trout[times * self.son_samples: (times + 1) * self.son_samples, :]\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xad\xa5\xe5\x85\xa5\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\r\n\r\n                a = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe5\x92\x8c\xe5\x80\xbc\r\n                z = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n\r\n                a[0] = in_train.copy()  # \xe5\x92\x8c\xe5\x80\xbc\r\n                z[0] = in_train.copy()  # \xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x80\x90\xe5\xb1\x82\xe6\xad\xa3\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\r\n                for forward in range(1, len(self.all_layer)):  # 1,2,3\r\n                    a[forward] = np.dot(z[forward - 1], self.weight[forward - 1]) + self.bias[forward - 1]\r\n                    z[forward] = eval(self.func_name[forward - 1])(a[forward])\r\n\r\n                # \xe5\xae\x9a\xe4\xb9\x89\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe8\xaf\xaf\xe5\xb7\xae\r\n                ne = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n\r\n                qiaia = eval(self.cost_func + \'_der\')(out_train, z[-1])\r\n                hhou = eval(self.func_name[-1] + \'_der\')(z[-1])\r\n                ne[-1] = np.multiply(qiaia, hhou)\r\n\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x80\x90\xe5\xb1\x82\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\r\n                for backward in range(len(self.all_layer) - 1, 0, -1):\r\n                    qianzhe = np.dot(ne[backward], self.weight[backward - 1].T)\r\n                    houzhe = eval(self.func_name[backward - 1] + \'_der\')(z[backward - 1])\r\n                    ne[backward - 1] = np.multiply(qianzhe, houzhe)\r\n\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x80\x90\xe5\xb1\x82\xe8\xae\xa1\xe7\xae\x97\xe6\x9b\xb4\xe6\x94\xb9W\xe5\x92\x8cB\xe5\x80\xbc\r\n                dw = list(range(len(self.all_layer) - 1))\r\n                db = list(range(len(self.all_layer) - 1))\r\n\r\n                # L2\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\r\n                for iwb in range(len(self.all_layer) - 1):\r\n                    dw[iwb] = np.dot(a[iwb].T, ne[iwb + 1]) / self.son_samples + \\\r\n                              (self.norr / self.son_samples) * dw[iwb]\r\n\r\n                    db[iwb] = np.sum(ne[iwb + 1], axis=0, keepdims=True) / self.son_samples + \\\r\n                              (self.norr / self.son_samples) * db[iwb]\r\n\r\n                try:\r\n                    for im in range(len(self.all_layer) - 1):\r\n                        vdw[im] = mom * vdw[im] + (1 - mom) * dw[im]\r\n                        vdb[im] = mom * vdb[im] + (1 - mom) * db[im]\r\n\r\n                        sdw[im] = mom * sdw[im] + (1 - mom) * (dw[im] ** 2)\r\n                        sdb[im] = mom * sdb[im] + (1 - mom) * (db[im] ** 2)\r\n                except NameError:\r\n                    vdw = [np.zeros(w.shape) for w in self.weight]\r\n                    vdb = [np.zeros(b.shape) for b in self.bias]\r\n\r\n                    sdw = [np.zeros(w.shape) for w in self.weight]\r\n                    sdb = [np.zeros(b.shape) for b in self.bias]\r\n\r\n                    for im in range(len(self.all_layer) - 1):\r\n                        vdw[im] = (1 - mom) * dw[im]\r\n                        vdb[im] = (1 - mom) * db[im]\r\n\r\n                        sdw[im] = (1 - prop) * (dw[im] ** 2)\r\n                        sdb[im] = (1 - prop) * (db[im] ** 2)\r\n                # \xe5\x88\x9d\xe5\xa7\x8b\xe9\x99\x90\xe5\x88\xb6\r\n                VDW = [np.zeros(w.shape) for w in self.weight]\r\n                VDB = [np.zeros(b.shape) for b in self.bias]\r\n                SDW = [np.zeros(w.shape) for w in self.weight]\r\n                SDB = [np.zeros(b.shape) for b in self.bias]\r\n                for slimit in range(len(self.all_layer) - 1):\r\n                    VDW[slimit] = vdw[slimit] / (1 - mom ** (iter + 1))\r\n                    VDB[slimit] = vdb[slimit] / (1 - mom ** (iter + 1))\r\n                    SDW[slimit] = sdw[slimit] / (1 - prop ** (iter + 1))\r\n                    SDB[slimit] = sdb[slimit] / (1 - prop ** (iter + 1))\r\n                # \xe6\x9b\xb4\xe6\x94\xb9\xe6\x9d\x83\xe9\x87\x8d\r\n                for ich in range(len(self.all_layer) - 1):\r\n                    self.weight[ich] -= self.learn_rate * (VDW[ich] / (SDW[ich] ** 0.5 + 1e-8))\r\n                    self.bias[ich] -= self.learn_rate * (VDB[ich] / (SDB[ich] ** 0.5 + 1e-8))\r\n\r\n            # \xe6\x95\xb4\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbf\xad\xe4\xbb\xa3\xe4\xb8\x80\xe6\xac\xa1\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe6\xa0\xb7\xe6\x9c\xac\xe5\xb7\xae\r\n            a[0] = trin.copy()  # \xe5\x92\x8c\xe5\x80\xbc\r\n            z[0] = trin.copy()  # \xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n            for forward in range(1, len(self.all_layer)):\r\n                a[forward] = np.dot(z[forward - 1], self.weight[forward - 1]) + self.bias[forward - 1]\r\n                z[forward] = eval(self.func_name[forward - 1])(a[forward])\r\n\r\n            # \xe6\x89\x93\xe5\x8d\xb0\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n            errortrain = eval(self.cost_func)(trout, z[-1])\r\n            train_corr = outvsreal(judge(z[-1]), trout)\r\n            print(\'\xe7\xac\xac%s\xe4\xbb\xa3\xe8\xae\xad\xe7\xbb\x83\xe6\xa0\xb7\xe6\x9c\xac\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9a%.9f, \xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xb8\xba%.5f\' % (iter, errortrain, train_corr))\r\n            error_list.append(errortrain)\r\n\r\n            # \xe6\x95\xb4\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbf\xad\xe4\xbb\xa3\xe4\xb8\x80\xe6\xac\xa1\xe8\xae\xa1\xe7\xae\x97\xe9\xaa\x8c\xe8\xaf\x81\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            a[0] = self.add_in.copy()  # \xe5\x92\x8c\xe5\x80\xbc\r\n            z[0] = self.add_in.copy()  # \xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n            for forward in range(1, len(self.all_layer)):\r\n                a[forward] = np.dot(z[forward - 1], self.weight[forward - 1]) + self.bias[forward - 1]\r\n                z[forward] = eval(self.func_name[forward - 1])(a[forward])\r\n\r\n            # \xe6\x89\x93\xe5\x8d\xb0\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n            erain = eval(self.cost_func)(self.add_out, z[-1])\r\n            add_correct = outvsreal(judge(z[-1]), self.add_out)\r\n            print(\'-----------------------\xe9\xaa\x8c\xe8\xaf\x81\xe6\xa0\xb7\xe6\x9c\xac\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9a%.9f, \xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xb8\xba%.5f\' % (erain, add_correct))\r\n            error_list_add.append(erain)\r\n\r\n            iter += 1\r\n            xlcorr.append(train_corr)\r\n            adcorr.append(add_correct)\r\n\r\n            # \xe5\xad\x98\xe5\x82\xa8\xe6\x9d\x83\xe9\x87\x8d\xe5\x92\x8c\xe5\x81\x8f\xe7\xbd\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n            if len(sacewei) == 4:\r\n                sacewei = sacewei[1:].copy()\r\n                sacewei.append([self.weight, self.bias])\r\n            else:\r\n                sacewei.append([self.weight, self.bias])\r\n\r\n            # \xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\xe7\x9a\x84\xe5\x88\xa4\xe6\x96\xad(\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe7\xb1\xbb\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe8\xbf\x9e\xe7\xbb\xad\xe4\xb8\x8b\xe9\x99\x8d\xe4\xb8\x89\xe6\xac\xa1\xef\xbc\x8c\xe9\x80\x80\xe5\x87\xba\xe5\xbe\xaa\xe7\x8e\xaf, \xe5\xb9\xb6\xe4\xb8\x94\xe5\xad\x98\xe5\x82\xa8\xe7\xac\xac\xe4\xb8\x80\xe6\xac\xa1\xe4\xb8\x8b\xe9\x99\x8d\xe5\x89\x8d\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\xe5\x92\x8c\xe5\x81\x8f\xe7\xbd\xae\xef\xbc\x89\r\n            if len(adcorr) >= 4:\r\n                # \xe5\x88\xa4\xe6\x96\xad\xe8\xbf\x9e\xe7\xbb\xad\xe4\xb8\x89\xe6\xac\xa1\xe4\xb8\x8b\xe9\x99\x8d\r\n                edlist = adcorr[-4:-1]\r\n                delist = adcorr[-3:]\r\n                sublist = np.array(edlist) - np.array(delist)\r\n                if np.all(sublist > 0):\r\n                    self.weight, self.bias = sacewei[0]\r\n                    break\r\n\r\n        return self.weight, self.bias, error_list, xlcorr, adcorr, error_list_add\r\n\r\n    def predict(self, pre_in_data):\r\n        pa = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe5\x92\x8c\xe5\x80\xbc\r\n        pz = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n        pa[0] = pre_in_data.copy()  # \xe5\x92\x8c\xe5\x80\xbc\r\n        pz[0] = pre_in_data.copy()  # \xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n        for forward in range(1, len(self.all_layer)):\r\n            pa[forward] = np.dot(pz[forward - 1], self.weight[forward - 1]) + self.bias[forward - 1]\r\n            pz[forward] = eval(self.func_name[forward - 1])(pa[forward])\r\n        return pz[-1]\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae\'\'\'\r\nDDatadict = bpd.kfold_train_datadict\r\n\r\n\r\n#  \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe4\xb8\xba\xe8\xbe\x93\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\r\ndef divided(data, cgu=countclass):\r\n    indata = data[:, :-cgu]\r\n    outdata = data[:, -cgu:]\r\n    return indata, outdata\r\n\r\n\r\n#  \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\x9a\x84\xe5\x80\xbc\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe8\xbe\x93\xe5\x85\xa5\xef\xbc\x8c\xe8\xae\xad\xe7\xbb\x83\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe8\xbe\x93\xe5\x85\xa5\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe8\xbe\x93\xe5\x87\xba\r\ndef transall(listdata, count=countclass):\r\n    trin, trout = divided(listdata[0], count)\r\n    yanin, yanout = divided(listdata[1], count)\r\n    return trin, trout, yanin, yanout\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xba\x94\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe8\xbf\x90\xe8\xa1\x8c\xe7\xa8\x8b\xe5\xba\x8f\'\'\'\r\nif __name__ == ""__main__"":\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87 \xe8\xae\xad\xe7\xbb\x83\r\n    corrsave_train = []\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87 \xe9\xaa\x8c\xe8\xaf\x81\r\n    corrsave_add = []\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe5\x90\x88\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n    corrsave_test = []\r\n    TEST_In, TEST_Out = divided(bpd.Test_data.values)\r\n    # \xe5\xbc\x80\xe5\xa7\x8bK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\r\n    for fold in DDatadict:\r\n        TRAIN_In, TRAIN_Out, ADD_In, ADD_Out = transall(DDatadict[fold])\r\n        bpnn = BPNN(TRAIN_In, TRAIN_Out, ADD_In, ADD_Out)\r\n        bpnn_train = bpnn.train_gadient()\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n        test_outdata = bpnn.predict(TEST_In)\r\n        teeee = outvsreal(judge(test_outdata), TEST_Out)\r\n        print(\'\xe7\xac\xac%s\xe6\xac\xa1\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xb8\xba%.4f\' % (fold, teeee))\r\n        # \xe5\xad\x98\xe5\x82\xa8K\xe6\x8a\x98\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n        corrsave_train.append(bpnn_train[3][-4])\r\n        corrsave_add.append(bpnn_train[4][-4])\r\n        corrsave_test.append(teeee)\r\n        # \xe7\xbb\x98\xe5\x88\xb6\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\x8e\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9b\xb2\xe7\xba\xbf\r\n        fig, ax1 = plt.subplots()\r\n        ax1.set_xlabel(\'\xe4\xbb\xa3\xe6\x95\xb0\')\r\n        ax1.set_ylabel(\'\xe8\xaf\xaf\xe5\xb7\xae\', color=\'r\')\r\n        plt.plot(list(range(len(bpnn_train[2]))), bpnn_train[2], label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'r\', marker=\'*\', linewidth=2)\r\n        plt.plot(list(range(len(bpnn_train[5]))), bpnn_train[5], label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'r\', marker=\'.\', linewidth=2)\r\n        ax1.tick_params(axis=\'y\', labelcolor=\'r\')\r\n        legend = ax1.legend(loc=\'upper center\', shadow=True, fontsize=\'x-large\')\r\n        legend.get_frame().set_facecolor(\'#F0F8FF\')\r\n        ax1.grid(True)\r\n\r\n        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\r\n\r\n        ax2.set_ylabel(\'\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\', color=\'b\')  # we already handled the x-label with ax1\r\n        plt.plot(list(range(len(bpnn_train[3][:-3]))), bpnn_train[3][:-3], label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'b\', marker=\'*\', linewidth=2)\r\n        plt.plot(list(range(len(bpnn_train[4][:-3]))), bpnn_train[4][:-3], label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'b\', marker=\'.\', linewidth=2)\r\n        ax2.tick_params(axis=\'y\', labelcolor=\'b\')\r\n        legen = ax2.legend(loc=\'lower center\', shadow=True, fontsize=\'x-large\')\r\n        legen.get_frame().set_facecolor(\'#FFFAFA\')\r\n        ax2.grid(True)\r\n\r\n        fig.tight_layout()  # otherwise the right y-label is slightly clipped\r\n        plt.title(\'%s\xe6\x8a\x98\xe8\xae\xad\xe7\xbb\x83VS\xe9\xaa\x8c\xe8\xaf\x81 \xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94\' % fold, fontsize=16)\r\n        plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\%s_fold.jpg\' % fold)\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6K\xe6\xac\xa1\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\r\n    plt.figure()\r\n    plt.plot(list(range(len(corrsave_train))), corrsave_train, label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'b\', marker=\'s\', linewidth=2)\r\n    plt.plot(list(range(len(corrsave_add))), corrsave_add, label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'r\', marker=\'8\', linewidth=2)\r\n    plt.plot(list(range(len(corrsave_test))), corrsave_test, label=\'\xe6\xb5\x8b\xe8\xaf\x95\', color=\'k\', marker=\'d\', linewidth=2)\r\n    plt.xlabel(\'\xe6\x8a\x98\xe6\x95\xb0\')\r\n    plt.ylabel(\'\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\')\r\n    plt.title(\'\xe7\xbb\x98\xe5\x88\xb6K\xe6\xac\xa1\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\', fontsize=16)\r\n    plt.grid(True)\r\n    plt.legend()\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\last_fold.jpg\')\r\n    plt.show()\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n'"
BPNN/BPNN_Classify/BPNN_AdultData_Spyder.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport urllib.request\r\nfrom collections import OrderedDict\r\nimport pandas as pd\r\n#\xe5\xb1\x9e\xe6\x80\xa7\xe5\x90\x8d\xe7\xa7\xb0\r\natt_name = [\'Age\', \'workclass\', \'fnlwgt\', \'education\', \'education-num\', \'marital-status\',\\\r\n            \'occupation\', \'relationship\', \'race\', \'sex\', \'capital-gain\', \'capital-loss\',\\\r\n            \'hours-per-week\', \'native-country\']\r\n\r\n#\xe7\xb1\xbb\xe5\x88\xab\xe5\x90\x8d\xe7\xa7\xb0\r\ntype_name =\'Money\'\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\xbd\x91\xe5\x9d\x80\r\ntrain_url = ""http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data""\r\n\r\n# \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\xbd\x91\xe5\x9d\x80\r\ntest_url = ""http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test""\r\n\r\n\r\n# \xe6\x9e\x84\xe5\xbb\xba\xe5\x87\xbd\xe6\x95\xb0\r\ndef spyderfunc(url, dataname, aname=att_name, tname=type_name):\r\n\r\n    # \xe6\x9c\x89\xe5\xba\x8f\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f,\xe6\x8c\x89\xe6\xb7\xbb\xe5\x8a\xa0\xe7\x9a\x84\xe5\xba\x8f\xe5\x88\x97\xe8\xbe\x93\xe5\x87\xba\r\n    datadict = OrderedDict({})\r\n    for keyname in aname:\r\n        datadict[keyname] = []\r\n    datadict[tname] = []\r\n\r\n    # \xe6\x89\x93\xe5\xbc\x80\xe7\xbd\x91\xe9\xa1\xb5\xef\xbc\x8c\xe8\xaf\xbb\xe5\x8f\x96\xe5\x86\x85\xe5\xae\xb9\r\n    html = urllib.request.urlopen(url)\r\n\r\n    namest = html.read().decode(\'utf-8\')\r\n    for hh in namest.split(\'\\n\'):\r\n        if len(hh) > 30:\r\n            hh = hh.replace(\' \', \'\')# \xe5\x8e\xbb\xe6\x8e\x89\xe7\xa9\xba\xe6\xa0\xbc\r\n            hang = hh.split(\',\')\r\n            for jjj in range(len(hang)):\r\n                try:\r\n                    datadict[att_name[jjj]].append(hang[jjj])\r\n                except IndexError:\r\n                    datadict[type_name].append(hang[jjj])\r\n        elif 6 < len(hh) < 30:\r\n            pass\r\n        else:\r\n            break\r\n    #\xe5\x86\x99\xe5\x85\xa5\xe6\x96\x87\xe4\xbb\xb6\r\n    df = pd.DataFrame(datadict)\r\n    df.to_csv(r\'C:\\Users\\GWT9\\Desktop\\Adult_%s.csv\'%dataname, index=False)\r\n    print(\'\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\nspyderfunc(train_url, \'Train\')\r\n\r\n# \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\nspyderfunc(test_url, \'Test\')\r\n'"
BPNN/BPNN_Classify/BPNN_Classify_Data.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n#  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\ntrain_path = \'C:/Users/GWT9\\Desktop/Adult_Train.csv\'\r\n\r\n#  \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\ntest_path = \'C:/Users/GWT9\\Desktop/Adult_Test.csv\'\r\n\r\n#  \xe5\x9b\xa0\xe4\xb8\xba\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xaenative-country\xe4\xb8\xad\xe4\xb8\x8d\xe5\xad\x98\xe5\x9c\xa8Holand-Netherlands\xef\xbc\x8c\xe4\xb8\x8d\xe4\xbe\xbf\xe4\xba\x8e\xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\xe3\x80\x82\r\n#  \xe5\x9b\xa0\xe6\xad\xa4\xe5\x9c\xa8\xe6\xb5\x8b\xe8\xaf\x95\xe6\x96\x87\xe4\xbb\xb6\xe4\xb8\xad\xe6\xb7\xbb\xe5\x8a\xa0\xe4\xb8\x80\xe4\xb8\xaanative-country\xe4\xb8\xbaHoland-Netherlands\xe7\x9a\x84\xe6\xa0\xb7\xe6\x9c\xac\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe5\x9c\xa8\xe5\x88\xa0\xe9\x99\xa4\xe5\x8d\xb3\xe5\x8f\xaf\r\n#  \xe4\xb8\xba\xe7\xae\x80\xe5\x8c\x96\xe7\xa8\x8b\xe5\xba\x8f\xef\xbc\x8c\xe6\x89\x8b\xe5\x8a\xa8\xe6\xb7\xbb\xe5\x8a\xa0\r\ndef handle_data(filepath, miss=\'fill\'):  # \xe5\xae\x9a\xe4\xb9\x89\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    data = pd.read_csv(r\'%s\'%filepath)\r\n    data = data.replace(\'?\', np.nan)\r\n    #  \xe5\xa4\x84\xe7\x90\x86\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if miss == \'del\':  # \xe5\x88\xa0\xe9\x99\xa4\xe6\x8e\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n        miss_data = data.dropna(how=\'any\')\r\n    else:\r\n        miss_data = data.fillna(method=\'ffill\')\r\n    #  \xe6\x96\xb0\xe5\xbb\xbaDataFrame\r\n    newdata = pd.DataFrame()\r\n    #  \xe7\x8b\xac\xe7\x83\xad\xe5\x8c\x96\xe7\xbc\x96\xe7\xa0\x81\r\n    for ikey in miss_data:\r\n        if miss_data[ikey].dtype == \'object\':  # \xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\r\n            onedata = pd.get_dummies(miss_data[ikey])\r\n            newdata = pd.concat([newdata, onedata], axis=1)\r\n        else:\r\n            newdata[ikey] = miss_data[ikey]\r\n    return newdata\r\n\r\n\r\ntrain_data = handle_data(train_path)\r\ntest_data = handle_data(test_path)\r\ntest_data = test_data.drop([len(test_data) - 1], inplace=False)  # \xe5\x88\xa0\xe9\x99\xa4\xe6\xb7\xbb\xe5\x8a\xa0\xe7\x9a\x84\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\r\n\r\n\r\n#  \xe6\x95\xb0\xe6\x8d\xae\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\n# \xe6\x89\x80\xe6\x9c\x89\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xef\xbc\x8c \xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae0-1\xe5\x8c\x96\r\ndef norm(trdata, tedata):\r\n    tr_da = pd.DataFrame()\r\n    te_da = pd.DataFrame()\r\n    for hh in trdata.columns:\r\n        if hh not in [\'<=50K\', \'>50K\']:\r\n            tr_da[hh] = (trdata[hh] - np.mean(trdata[hh])) / np.std(trdata[hh])  # \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\n            te_da[hh] = (tedata[hh] - np.mean(trdata[hh])) / np.std(trdata[hh])  # \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\n            #  tr_da[hh] = (trdata[hh] - np.min(trdata[hh])) / (np.max(trdata[hh]) - np.min(trdata[hh])) # 0-1\xe5\x8c\x96\r\n            #  te_da[hh] = (tedata[hh] - np.min(trdata[hh])) / (np.max(trdata[hh]) - np.min(trdata[hh]))  # 0-1\xe5\x8c\x96\r\n        else:\r\n            tr_da[hh] = trdata[hh].values\r\n            te_da[hh] = tedata[\'%s.\'%hh].values  # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84Money\xe5\xad\x97\xe6\xae\xb5\xe5\x86\x85\xe5\xae\xb9\xe4\xb8\x8d\xe5\x90\x8c\xe3\x80\x82\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xa4\x9a\xe4\xb8\xaa"".""\r\n    return tr_da, te_da\r\n\r\n\r\nTrain_data, Test_data = norm(train_data, test_data)\r\n\r\n#  \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xb9\xb3\xe5\x9d\x87\xe5\x88\x86\xe4\xb8\xban\xe4\xbb\xbd\xef\xbc\x8c\xe5\x88\xa9\xe7\x94\xa8K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe8\xae\xa1\xe7\xae\x97\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n#  \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\r\n\r\ndef kfold(trdata, k=10):\r\n    vadata = trdata.values\r\n    legth = len(vadata)\r\n    datadict = {}\r\n    signnuber = np.arange(legth)\r\n    for hh in range(k):\r\n        np.random.shuffle(vadata)\r\n        yanzhneg = np.random.choice(signnuber, int(legth / k), replace=False)\r\n        oneflod_yan = vadata[yanzhneg]\r\n        oneflod_xun = vadata[[hdd for hdd in signnuber if hdd not in yanzhneg]]\r\n        datadict[hh] = [oneflod_xun, oneflod_yan]\r\n    return datadict\r\n\r\n#  \xe5\xad\x98\xe5\x82\xa8K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\r\nkfold_train_datadict = kfold(Train_data)\r\n\r\n\r\n'"
BPNN/BPNN_Classify/Mnist_Compare.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n""""""\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xba\x93""""""\r\n\r\nimport AnFany_BPNN_Classify as AF\r\nimport Mnist_Data as DATA\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n""""""\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae""""""\r\n\r\nDDatadict = DATA.kfold(DATA.TRAIN)\r\n\r\n""""""\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe8\xae\xad\xe7\xbb\x83""""""\r\n\r\nif __name__ == ""__main__"":\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87 \xe8\xae\xad\xe7\xbb\x83\r\n    corrsave_train = []\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87 \xe9\xaa\x8c\xe8\xaf\x81\r\n    corrsave_add = []\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe5\x90\x88\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n    corrsave_test = []\r\n    TEST_In, TEST_Out = DATA.TestIN, DATA.TestOUT\r\n    # \xe5\xbc\x80\xe5\xa7\x8bK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\r\n    for fold in DDatadict:\r\n        TRAIN_In, TRAIN_Out, ADD_In, ADD_Out = AF.transall(DDatadict[fold], count=10)\r\n        bpnn = AF.BPNN(TRAIN_In, TRAIN_Out, ADD_In, ADD_Out)\r\n        bpnn_train = bpnn.train_adam()\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n        test_outdata = bpnn.predict(TEST_In)\r\n        teeee = AF.outvsreal(AF.judge(test_outdata), TEST_Out)\r\n        print(\'\xe7\xac\xac%s\xe6\xac\xa1\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xb8\xba%.4f\' % (fold, teeee))\r\n        # \xe5\xad\x98\xe5\x82\xa8K\xe6\x8a\x98\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n        corrsave_train.append(bpnn_train[3][-4])\r\n        corrsave_add.append(bpnn_train[4][-4])\r\n        corrsave_test.append(teeee)\r\n        # \xe7\xbb\x98\xe5\x88\xb6\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\x8e\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9b\xb2\xe7\xba\xbf\r\n        fig, ax1 = plt.subplots()\r\n        ax1.set_xlabel(\'\xe4\xbb\xa3\xe6\x95\xb0\')\r\n        ax1.set_ylabel(\'\xe8\xaf\xaf\xe5\xb7\xae\', color=\'r\')\r\n        plt.plot(list(range(len(bpnn_train[2]))), bpnn_train[2], label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'r\', marker=\'*\', linewidth=2)\r\n        plt.plot(list(range(len(bpnn_train[5]))), bpnn_train[5], label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'r\', marker=\'.\', linewidth=2)\r\n        ax1.tick_params(axis=\'y\', labelcolor=\'r\')\r\n        legend = ax1.legend(loc=\'upper center\', shadow=True, fontsize=\'x-large\')\r\n        legend.get_frame().set_facecolor(\'#F0F8FF\')\r\n        ax1.grid(True)\r\n\r\n        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\r\n\r\n        ax2.set_ylabel(\'\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\', color=\'b\')  # we already handled the x-label with ax1\r\n        plt.plot(list(range(len(bpnn_train[3][:-3]))), bpnn_train[3][:-3], label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'b\', marker=\'*\', linewidth=2)\r\n        plt.plot(list(range(len(bpnn_train[4][:-3]))), bpnn_train[4][:-3], label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'b\', marker=\'.\', linewidth=2)\r\n        ax2.tick_params(axis=\'y\', labelcolor=\'b\')\r\n        legen = ax2.legend(loc=\'lower center\', shadow=True, fontsize=\'x-large\')\r\n        legen.get_frame().set_facecolor(\'#FFFAFA\')\r\n        ax2.grid(True)\r\n\r\n        fig.tight_layout()  # otherwise the right y-label is slightly clipped\r\n        plt.title(\'%s\xe6\x8a\x98\xe8\xae\xad\xe7\xbb\x83VS\xe9\xaa\x8c\xe8\xaf\x81 \xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94\' % fold, fontsize=16)\r\n        plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\%s_foldui.jpg\' % fold)\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6K\xe6\xac\xa1\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\r\n    plt.figure()\r\n    plt.plot(list(range(len(corrsave_train))), corrsave_train, label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'b\', marker=\'s\', linewidth=2)\r\n    plt.plot(list(range(len(corrsave_add))), corrsave_add, label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'r\', marker=\'8\', linewidth=2)\r\n    plt.plot(list(range(len(corrsave_test))), corrsave_test, label=\'\xe6\xb5\x8b\xe8\xaf\x95\', color=\'k\', marker=\'d\', linewidth=2)\r\n    plt.xlabel(\'\xe6\x8a\x98\xe6\x95\xb0\')\r\n    plt.ylabel(\'\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\')\r\n    plt.title(\'\xe7\xbb\x98\xe5\x88\xb6K\xe6\xac\xa1\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\', fontsize=16)\r\n    plt.grid(True)\r\n    plt.legend()\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\last_foldui.jpg\')\r\n    plt.show()\r\n'"
BPNN/BPNN_Classify/Mnist_Data.py,0,"b""#  # -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport os\r\npath = r'C:\\Users\\GWT9\\Desktop'\r\nos.chdir(path)\r\n\r\nimport numpy as np\r\nimport struct\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x9b\xbe\xe7\x89\x87\xe6\x96\x87\xe4\xbb\xb6\r\ntrain_images = 'train-images.idx3-ubyte'\r\n# \xe8\xae\xad\xe7\xbb\x83\xe6\xa0\x87\xe7\xad\xbe\xe6\x96\x87\xe4\xbb\xb6\r\ntrain_labels = 'train-labels.idx1-ubyte'\r\n\r\n# \xe6\xb5\x8b\xe8\xaf\x95\xe5\x9b\xbe\xe7\x89\x87\xe6\x96\x87\xe4\xbb\xb6\r\ntest_images = 't10k-images.idx3-ubyte'\r\n# \xe6\xb5\x8b\xe8\xaf\x95\xe6\xa0\x87\xe7\xad\xbe\xe6\x96\x87\xe4\xbb\xb6\r\ntest_labels = 't10k-labels.idx1-ubyte'\r\n\r\n\r\ndef getimage(idx3_ubyte_file):\r\n    # \xe8\xaf\xbb\xe5\x8f\x96\xe4\xba\x8c\xe8\xbf\x9b\xe5\x88\xb6\xe6\x95\xb0\xe6\x8d\xae\r\n    bin_data = open(idx3_ubyte_file, 'rb').read()\r\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb4\xe4\xbf\xa1\xe6\x81\xaf\xef\xbc\x8c\xe4\xbe\x9d\xe6\xac\xa1\xe4\xb8\xba\xe9\xad\x94\xe6\x95\xb0\xe3\x80\x81\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe9\x87\x8f\xe3\x80\x81\xe6\xaf\x8f\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xe9\xab\x98\xe3\x80\x81\xe6\xaf\x8f\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xe5\xae\xbd\r\n    offset = 0\r\n    fmt_header = '>iiii'\r\n    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)\r\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    image_size = num_rows * num_cols\r\n    offset += struct.calcsize(fmt_header)\r\n    fmt_image = '>' + str(image_size) + 'B'\r\n    images = np.empty((num_images, num_rows, num_cols))\r\n    for i in range(num_images):\r\n        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))\r\n        offset += struct.calcsize(fmt_image)\r\n    return images\r\n\r\ndef getlabel(idx1_ubyte_file):\r\n    # \xe8\xaf\xbb\xe5\x8f\x96\xe4\xba\x8c\xe8\xbf\x9b\xe5\x88\xb6\xe6\x95\xb0\xe6\x8d\xae\r\n    bin_data = open(idx1_ubyte_file, 'rb').read()\r\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb4\xe4\xbf\xa1\xe6\x81\xaf\xef\xbc\x8c\xe4\xbe\x9d\xe6\xac\xa1\xe4\xb8\xba\xe9\xad\x94\xe6\x95\xb0\xe5\x92\x8c\xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\r\n    offset = 0\r\n    fmt_header = '>ii'\r\n    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)\r\n    # \xe8\xa7\xa3\xe6\x9e\x90\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    offset += struct.calcsize(fmt_header)\r\n    fmt_image = '>B'\r\n    labels = np.empty(num_images)\r\n    for i in range(num_images):\r\n        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]\r\n        offset += struct.calcsize(fmt_image)\r\n    return labels\r\n\r\n#  01\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\r\ndef stand(data):\r\n    futr = np.transpose(data)\r\n    for hh in range(len(futr)):\r\n        if np.all(futr[hh] == 0):\r\n            pass\r\n        else:\r\n            futr[hh]= (futr[hh] - np.min(futr[hh])) / (np.max(futr[hh]) - np.min(futr[hh]))\r\n    return np.transpose(futr)\r\n\r\n#  onehot\xe5\x87\xbd\xe6\x95\xb0\r\ndef onehot(exlist, count=9):\r\n    one = []\r\n    for jj in exlist:\r\n        gu = np.zeros(count + 1)\r\n        gu[int(jj[0])] = 1\r\n        one.append(gu)\r\n    return np.array(one)\r\n\r\n\r\ndef run():\r\n    trainimages = getimage(train_images)\r\n    trainlabels = getlabel(train_labels)\r\n    testimages = getimage(test_images)\r\n    testlabels = getlabel(test_labels)\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x965\xe4\xb8\xaa\xe5\x9b\xbe\xe7\x89\x87\xe5\x92\x8c\xe6\xa0\x87\xe7\xad\xbe\xef\xbc\x8c\xe7\x9c\x8b\xe6\x98\xaf\xe5\x90\xa6\xe5\xaf\xb9\xe5\xba\x94\r\n    # import matplotlib.pyplot as plt\r\n    # from pylab import mpl\r\n    # mpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\n    # mpl.rcParams['axes.unicode_minus'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n    # for hh in list(np.random.choice(list(range(len(trainimages))), 5)):\r\n    #     plt.imshow(trainimages[hh], cmap='gray')\r\n    #     plt.title('\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x9a\xe6\xa0\x87\xe7\xad\xbe\xe4\xb8\xba%s' % trainlabels[hh])\r\n    #     plt.show()\r\n    # # \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xef\xbc\x9a\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x965\xe4\xb8\xaa\xe5\x9b\xbe\xe7\x89\x87\xe5\x92\x8c\xe6\xa0\x87\xe7\xad\xbe\xef\xbc\x8c\xe7\x9c\x8b\xe6\x98\xaf\xe5\x90\xa6\xe5\xaf\xb9\xe5\xba\x94\r\n    # for hh in list(np.random.choice(list(range(len(testimages))), 5)):\r\n    #     plt.imshow(testimages[hh], cmap='gray')\r\n    #     plt.title('\xe6\xb5\x8b\xe8\xaf\x95\xef\xbc\x9a\xe6\xa0\x87\xe7\xad\xbe\xe4\xb8\xba%s' % testlabels[hh])\r\n    #     plt.show()\r\n\r\n    # \xe5\xb0\x86\xe8\xa1\xa8\xe7\xa4\xba\xe6\xaf\x8f\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x8428*28\xe7\x9a\x84\xe6\x95\xb0\xe7\xbb\x84\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba1*784\xe7\x9a\x84\xe6\x95\xb0\xe7\xbb\x84\r\n    Trainim = trainimages.reshape(60000, -1)\r\n    Testim = testimages.reshape(10000, -1)\r\n\r\n    Trainla = trainlabels.reshape(60000, -1)\r\n    Testla = testlabels.reshape(10000, -1)\r\n\r\n    #  \xe8\xbe\x93\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\n    intrain, intest = stand(Trainim), stand(Testim)\r\n\r\n    #  \xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\xe7\x8b\xac\xe7\x83\xad\xe5\x8c\x96\r\n    outtrain, outtest = onehot(Trainla), onehot(Testla)\r\n\r\n    return intrain, outtrain, intest, outtest\r\n\r\n\r\nTrainIN, TrainOUT, TestIN, TestOUT = run()\r\n\r\n# \xe9\xa6\x96\xe5\x85\x88\xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe8\xbe\x93\xe5\x87\xba\xe5\x90\x88\xe5\xb9\xb6\r\nTRAIN = np.hstack((TrainIN, TrainOUT))\r\n\r\n\r\n#  \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xb9\xb3\xe5\x9d\x87\xe5\x88\x86\xe4\xb8\xban\xe4\xbb\xbd\xef\xbc\x8c\xe5\x88\xa9\xe7\x94\xa8K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe8\xae\xa1\xe7\xae\x97\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n#  \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\r\n\r\ndef kfold(trdata, k=10):\r\n    legth = len(trdata)\r\n    datadict = {}\r\n    signnuber = np.arange(legth)\r\n    for hh in range(k):\r\n        np.random.shuffle(trdata)\r\n        yanzhneg = np.random.choice(signnuber, int(legth / k), replace=False)\r\n        oneflod_yan = trdata[yanzhneg]\r\n        oneflod_xun = trdata[[hdd for hdd in signnuber if hdd not in yanzhneg]]\r\n        datadict[hh] = [oneflod_xun, oneflod_yan]\r\n    return datadict\r\n"""
BPNN/BPNN_Classify/Mnist_TensorFlow.py,6,"b'# -*- coding\xef\xbc\x9autf-8 -*-\n# &Author  AnFany\n\n""""""\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xba\x93""""""\n\nimport tensorflow as tf\nimport TensorFlow_BPNN_Classify as TBC\nimport Mnist_Data as DATA\nimport matplotlib.pyplot as plt\nfrom pylab import mpl\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\nfrom matplotlib.ticker import MultipleLocator\n\n# \xe8\xae\xbe\xe7\xbd\xae\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x88\xbb\xe5\xba\xa6\xe4\xb8\x8e\xe5\xad\x90\xe5\x88\xbb\xe5\xba\xa6\ny_toge = MultipleLocator(0.1)  # \xe5\xb0\x86y\xe8\xbd\xb4\xe4\xb8\xbb\xe5\x88\xbb\xe5\xba\xa6\xe6\xa0\x87\xe7\xad\xbe\xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xba0.5\xe7\x9a\x84\xe5\x80\x8d\xe6\x95\xb0\ny_son = MultipleLocator(0.01)  # \xe5\xb0\x86\xe6\xad\xa4y\xe8\xbd\xb4\xe6\xac\xa1\xe5\x88\xbb\xe5\xba\xa6\xe6\xa0\x87\xe7\xad\xbe\xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xba0.1\xe7\x9a\x84\xe5\x80\x8d\xe6\x95\xb0\n\n\n""""""\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae""""""\n\nDDatadict = DATA.kfold(DATA.TRAIN)\n\n""""""\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe8\xae\xad\xe7\xbb\x83""""""\nif __name__ == ""__main__"":\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87 \xe8\xae\xad\xe7\xbb\x83\n    corrsave_train = []\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87 \xe9\xaa\x8c\xe8\xaf\x81\n    corrsave_add = []\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe5\x90\x88\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\n    corrsave_test = []\n    TEST_In, TEST_Out = DATA.TestIN, DATA.TestOUT\n    # \xe5\xbc\x80\xe5\xa7\x8bK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\n    for fold in DDatadict:\n        TRAIN_In, TRAIN_Out, ADD_In, ADD_Out = TBC.transall(DDatadict[fold], count=10)\n        while 1:\n            bpnn = TBC.Ten_train(TRAIN_In, TRAIN_Out, ADD_In, ADD_Out, fold, itertimes=200, hiddenlayers=5,\\\n                                 learn_rate=0.003, activate_func=\'tanh\')\n            if bpnn:\n                break\n         #  \xe4\xb8\x8b\xe8\xbd\xbd\xe5\x88\x9a\xe6\x89\x8d\xe5\xb7\xb2\xe7\xbb\x8f\xe4\xbf\x9d\xe5\xad\x98\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\n        graph = tf.train.import_meta_graph(""./gu/%smodel-%s.meta"" % (fold, bpnn[4]))\n        ses = tf.Session()\n        graph.restore(ses, tf.train.latest_checkpoint(\'./gu/\'))\n        op_to_restore = tf.get_default_graph().get_tensor_by_name(""Add_%s:0"" % bpnn[5])\n        w1 = tf.get_default_graph().get_tensor_by_name(""x_data:0"")\n        feed_dict = {w1: TEST_In}\n        dgsio = ses.run(op_to_restore, feed_dict)\n        #  \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\n        add_on_op = TBC.outvsreal(TBC.judge(dgsio), TEST_Out)\n        print(\'\xe7\xac\xac%s\xe6\x8a\x98\xe6\xb5\x8b\xe8\xaf\x95\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xb8\xba\' % fold, add_on_op)\n        #  \xe6\xb8\x85\xe7\xa9\xba\xe5\x9b\xbe\n        ses.close()\n        tf.reset_default_graph()\n        #  \xe6\xb5\x8b\xe8\xaf\x95\xe6\xb7\xbb\xe5\x8a\xa0\n        corrsave_test.append(add_on_op)\n        #  \xe8\xae\xad\xe7\xbb\x83\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe6\xb7\xbb\xe5\x8a\xa0\n        corrsave_train.append(bpnn[2][-1])\n\n        #  \xe9\xaa\x8c\xe8\xaf\x81\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe6\xb7\xbb\xe5\x8a\xa0\n        corrsave_add.append(bpnn[3][-1])\n\n        # \xe7\xbb\x98\xe5\x88\xb6\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\x8e\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9b\xb2\xe7\xba\xbf\n        fig, ax1 = plt.subplots()\n        ax1.set_xlabel(\'\xe4\xbb\xa3\xe6\x95\xb0\')\n        ax1.set_ylabel(\'\xe8\xaf\xaf\xe5\xb7\xae\', color=\'r\')\n        plt.plot(list(range(len(bpnn[0]))), bpnn[0], label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'r\', marker=\'*\', linewidth=2)\n        plt.plot(list(range(len(bpnn[1]))), bpnn[1], label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'r\', marker=\'.\', linewidth=2)\n        ax1.tick_params(axis=\'y\', labelcolor=\'r\')\n        legend = ax1.legend(loc=\'upper center\', shadow=True, fontsize=\'x-large\')\n        legend.get_frame().set_facecolor(\'#F0F8FF\')\n        ax1.grid(True)\n\n        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\n        ax2.set_ylabel(\'\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\', color=\'b\')  # we already handled the x-label with ax1\n        plt.plot(list(range(len(bpnn[2]))), bpnn[2], label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'b\', marker=\'*\', linewidth=2)\n        plt.plot(list(range(len(bpnn[3]))), bpnn[3], label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'b\', marker=\'.\', linewidth=2)\n        ax2.tick_params(axis=\'y\', labelcolor=\'b\')\n        legen = ax2.legend(loc=\'lower center\', shadow=True, fontsize=\'x-large\')\n        legen.get_frame().set_facecolor(\'#FFFAFA\')\n        ax2.grid(True)\n        ax2.yaxis.set_major_locator(y_toge)\n        ax2.yaxis.set_minor_locator(y_son)\n\n        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n        plt.title(\'%s\xe6\x8a\x98\xe8\xae\xad\xe7\xbb\x83VS\xe9\xaa\x8c\xe8\xaf\x81 \xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94\' % fold, fontsize=16)\n        plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\%s_fol8.jpg\' % fold)\n\n        # \xe7\xbb\x98\xe5\x88\xb6K\xe6\xac\xa1\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\n    plt.figure()\n    plt.plot(list(range(len(corrsave_train))), corrsave_train, label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'b\', marker=\'s\', linewidth=2)\n    plt.plot(list(range(len(corrsave_add))), corrsave_add, label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'r\', marker=\'8\', linewidth=2)\n    plt.plot(list(range(len(corrsave_test))), corrsave_test, label=\'\xe6\xb5\x8b\xe8\xaf\x95\', color=\'k\', marker=\'d\', linewidth=2)\n    plt.xlabel(\'\xe6\x8a\x98\xe6\x95\xb0\')\n    plt.ylabel(\'\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\')\n    plt.title(\'\xe7\xbb\x98\xe5\x88\xb6K\xe6\xac\xa1\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\', fontsize=16)\n    plt.grid(True)\n    plt.legend()\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\last_fol8.jpg\')\n    plt.show()\n'"
BPNN/BPNN_Classify/TensorFlow_BPNN_Classify.py,26,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xba\x93\'\'\'\r\nimport tensorflow as tf\r\nimport BPNN_Classify_Data as bpd\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nfrom matplotlib.ticker import MultipleLocator, FormatStrFormatter\r\n# \xe8\xae\xbe\xe7\xbd\xae\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x88\xbb\xe5\xba\xa6\xe4\xb8\x8e\xe5\xad\x90\xe5\x88\xbb\xe5\xba\xa6\r\ny_toge = MultipleLocator(0.02)  # \xe5\xb0\x86y\xe8\xbd\xb4\xe4\xb8\xbb\xe5\x88\xbb\xe5\xba\xa6\xe6\xa0\x87\xe7\xad\xbe\xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xba0.1\xe7\x9a\x84\xe5\x80\x8d\xe6\x95\xb0\r\ny_son = MultipleLocator(0.01)  # \xe5\xb0\x86\xe6\xad\xa4y\xe8\xbd\xb4\xe6\xac\xa1\xe5\x88\xbb\xe5\xba\xa6\xe6\xa0\x87\xe7\xad\xbe\xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xba0.01\xe7\x9a\x84\xe5\x80\x8d\xe6\x95\xb0\r\n#  \xe5\x88\x86\xe7\xb1\xbb\xe6\x95\xb0\r\ncountclass = 2\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xe5\x87\xbd\xe6\x95\xb0\'\'\'\r\n#  \xe6\xa0\xb9\xe6\x8d\xae\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\x88\xa4\xe6\x96\xad\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef judge(ydata):\r\n    maxnum = np.max(ydata, axis=1)\r\n    lastdata = []\r\n    for ii in range(len(ydata)):\r\n        maxindex = list(ydata[ii]).index(maxnum[ii])\r\n        fu = [0] * len(ydata[0])\r\n        fu[maxindex] = 1\r\n        lastdata.append(fu)\r\n    return np.array(lastdata)\r\n\r\n#  \xe6\xa0\xb9\xe6\x8d\xae\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe4\xbb\xa5\xe5\x8f\x8a\xe7\x9c\x9f\xe5\xae\x9e\xe7\xbb\x93\xe6\x9e\x9c\xe8\xbe\x93\xe5\x87\xba\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\x95\x88\xe6\x9e\x9c\r\ndef outvsreal(outdata, realdata):\r\n    subdata = outdata - realdata\r\n    sundata = np.sum(np.abs(subdata), axis=1)\r\n    correct = list(sundata).count(0)\r\n    return correct / len(outdata)\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a \xe5\x9f\xba\xe4\xba\x8eTensorFlow\xe6\x9e\x84\xe5\xbb\xba\xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\'\'\'\r\n# \xe5\x88\x9b\xe5\xbb\xba\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\ndef activate(input_layer, weights, biases, actfunc):\r\n    layer = tf.add(tf.matmul(input_layer, weights), biases)\r\n    if actfunc == \'relu\':\r\n        return tf.nn.relu(layer)\r\n    elif actfunc == \'tanh\':\r\n        return tf.nn.tanh(layer)\r\n    elif actfunc == \'sigmoid\':\r\n        return tf.nn.sigmoid(layer)\r\n    elif actfunc == \'linear\':\r\n        return layer\r\n\r\n\r\n# \xe6\x9d\x83\xe9\x87\x8d\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe5\x92\x8c\xe5\x88\xa9\xe7\x94\xa8\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\xe5\xbe\x88\xe5\xa4\xa7\r\n# sigmoid: xavir  tanh: xavir   relu: he\r\n\r\n#  \xe6\x9e\x84\xe5\xbb\xba\xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Ten_train(xdata, ydata, addxdata, addydata, kcount, hiddenlayers=3, hiddennodes=100, \\\r\n              learn_rate=0.02, itertimes=20, batch_size=200, activate_func=\'tanh\'):\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe6\x90\xad\xe5\xbb\xba\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\r\n    Input_Dimen = len(xdata[0])\r\n    Unit_Layers = [Input_Dimen] + [hiddennodes] * hiddenlayers + [len(ydata[0])]  # \xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84\xe7\xbb\xb4\xe6\x95\xb0\xef\xbc\x8c\xe9\x9a\x90\xe5\xb1\x82\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe6\x95\xb0\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\xb4\xe6\x95\xb01\r\n\r\n    # \xe5\x88\x9b\xe5\xbb\xba\xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\r\n    x_data = tf.placeholder(shape=[None, Input_Dimen], dtype=tf.float32, name=\'x_data\')\r\n\r\n    y_target = tf.placeholder(shape=[None, len(ydata[0])], dtype=tf.float32)\r\n\r\n    # \xe5\xae\x9e\xe7\x8e\xb0\xe5\x8a\xa8\xe6\x80\x81\xe5\x91\xbd\xe5\x90\x8d\xe5\x8f\x98\xe9\x87\x8f\r\n    VAR_NAME = locals()\r\n    for jj in range(hiddenlayers + 1):\r\n        VAR_NAME[\'weight%s\' % jj] = tf.Variable(np.random.rand(Unit_Layers[jj], Unit_Layers[jj + 1]) / np.sqrt(Unit_Layers[jj]), \\\r\n                                                dtype=tf.float32, name=\'Weight%s\' % jj)  # sigmoid  tanh\r\n        # VAR_NAME[\'weight%s\'%jj] = tf.Variable(np.random.rand(Unit_Layers[jj], Unit_Layers[jj + 1]),dtype=tf.float32, \\name=\'weight%s\' % jj) \\/ np.sqrt(Unit_Layers[jj] / 2)  # relu\r\n        VAR_NAME[\'bias%s\' % jj] = tf.Variable(tf.random_normal([Unit_Layers[jj + 1]], stddev=10), dtype=tf.float32, name=\'Bias%s\' % jj)\r\n        if jj == 0:\r\n            VAR_NAME[\'ooutda%s\' % jj] = activate(x_data, eval(\'weight%s\' % jj), eval(\'bias%s\' % jj),\r\n                                                 actfunc=activate_func)\r\n        elif jj == hiddenlayers:\r\n            VAR_NAME[\'ooutda%s\' % jj] = activate(eval(\'ooutda%s\' % (jj - 1)), eval(\'weight%s\' % jj),\\\r\n                                                 eval(\'bias%s\' % jj), actfunc=\'linear\')  # \xe5\x9b\xa0\xe6\xad\xa4\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\xb1\x82\xe9\x87\x87\xe7\x94\xa8\xe7\xba\xbf\xe6\x80\xa7\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n        else:\r\n            VAR_NAME[\'ooutda%s\' % jj] = activate(eval(\'ooutda%s\' % (jj - 1)), eval(\'weight%s\' % jj),\\\r\n                                                 eval(\'bias%s\' % jj), actfunc=activate_func)\r\n    #  \xe9\x9c\x80\xe8\xa6\x81\xe5\xaf\xb9\xe8\xbe\x93\xe5\x87\xba\xe8\xbf\x9b\xe8\xa1\x8csoftmax\xe8\xae\xa1\xe7\xae\x97\r\n    uuu = tf.nn.softmax(eval(\'ooutda%s\' % (hiddenlayers)))\r\n\r\n    # \xe4\xba\xa4\xe5\x8f\x89\xe7\x86\xb5\xe5\x87\xbd\xe6\x95\xb0\r\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_target, logits=eval(\'ooutda%s\' % (hiddenlayers))))\r\n\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\xe9\x9c\x80\xe8\xa6\x81\r\n\r\n    accu = eval(\'ooutda%s\' % hiddenlayers)\r\n\r\n\r\n\r\n    # \xe4\xbc\x98\xe5\x8c\x96\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\r\n    # my_opt = tf.train.GradientDescentOptimizer(learn_rate)\r\n    my_opt = tf.train.AdamOptimizer(learn_rate)\r\n    train_step = my_opt.minimize(loss)\r\n\r\n    # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n    init = tf.global_variables_initializer()\r\n\r\n    loss_vec = []  # \xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\r\n\r\n    loss_vec_add = []  # \xe9\xaa\x8c\xe8\xaf\x81\xe8\xaf\xaf\xe5\xb7\xae\r\n\r\n    acc_vec = []  # \xe8\xae\xad\xe7\xbb\x83\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\r\n\r\n    acc_vec_add = []  # \xe9\xaa\x8c\xe8\xaf\x81\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\r\n\r\n    #  \xe9\x9c\x80\xe8\xa6\x81\xe4\xbf\x9d\xe5\xad\x98\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x81\x8f\xe7\xbd\xae\r\n    graph = tf.get_default_graph()\r\n    saver = tf.train.Saver(max_to_keep=1)\r\n    sess = tf.Session()\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    accudict = {}\r\n    accunum = 0\r\n    sess.run(init)\r\n    for i in range(itertimes):  # \xe5\x9c\xa8\xe6\x80\xbb\xe5\x85\xb1\xe7\x9a\x84\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe9\xab\x98\xe7\x9a\x84\xef\xbc\x88\xe9\xaa\x8c\xe8\xaf\x81\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87+\xe8\xae\xad\xe7\xbb\x83\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xef\xbc\x89\r\n        for jj in range(int(len(xdata) / batch_size)):\r\n            rand_index = np.random.choice(len(xdata), size=batch_size, replace=False)\r\n            rand_x = xdata[rand_index]\r\n            rand_y = ydata[rand_index]\r\n            #  \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n            sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\r\n\r\n        #  \xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\r\n        temp_loss = sess.run(loss, feed_dict={x_data: xdata, y_target: ydata})\r\n        #  \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\r\n        loss_vec.append(temp_loss)\r\n\r\n        #  \xe9\xaa\x8c\xe8\xaf\x81\xe8\xaf\xaf\xe5\xb7\xae\r\n        temp_loss_add = sess.run(loss, feed_dict={x_data: addxdata, y_target: addydata})\r\n        #  \xe5\xad\x98\xe5\x82\xa8\xe9\xaa\x8c\xe8\xaf\x81\xe8\xaf\xaf\xe5\xb7\xae\r\n        loss_vec_add.append(temp_loss_add)\r\n\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\r\n        acc_ru = sess.run(accu, feed_dict={x_data: xdata})\r\n        acc_rughy_train = outvsreal(judge(acc_ru), ydata)\r\n        #  \xe5\xad\x98\xe5\x82\xa8\r\n        acc_vec.append(acc_rughy_train)\r\n        #  \xe9\xaa\x8c\xe8\xaf\x81\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\r\n        acu = sess.run(accu, feed_dict={x_data: addxdata})\r\n        acc_rughy = outvsreal(judge(acu), addydata)\r\n        # \xe5\xad\x98\xe5\x82\xa8\r\n        acc_vec_add.append(acc_rughy)\r\n\r\n        print(\'%s\xe4\xbb\xa3\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9a [\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x9a%.4f, \xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x9a%.4f], \xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xef\xbc\x9a [\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x9a%.4f, \xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x9a%.4f]\' % (i, temp_loss, temp_loss_add, \\\r\n                                                                       acc_rughy_train, acc_rughy))\r\n        accudict[i] = [acc_rughy_train, acc_rughy]\r\n        # # \xe5\x88\xa4\xe6\x96\xad\xe6\x8f\x90\xe5\x89\x8d\xe9\x80\x80\xe5\x87\xba \xef\xbc\x8c \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe8\xbf\x9e\xe7\xbb\xad\xe4\xb8\x89\xe4\xb8\x8b\xe9\x99\x8d\r\n        # if len(acc_vec_add) >= 4:\r\n        #     # \xe5\x88\xa4\xe6\x96\xad\xe8\xbf\x9e\xe7\xbb\xad\xe4\xb8\x89\xe6\xac\xa1\xe4\xb8\x8b\xe9\x99\x8d\r\n        #     edlist = acc_vec_add[-4:-1]\r\n        #     delist = acc_vec_add[-3:]\r\n        #     sublist = np.array(edlist) - np.array(delist)\r\n        #     if np.all(sublist > 0):\r\n        #         break\r\n\r\n        #  \xe4\xb8\xba\xe4\xba\x86\xe9\x81\xbf\xe5\x85\x8d\xef\xbc\x8c\xe9\x99\xb7\xe5\x85\xa5\xe5\xb1\x80\xe9\x83\xa8\xe5\xb0\x8f\xe5\x80\xbc\xef\xbc\x8c\xe5\xbd\x93\xe8\xbf\x90\xe8\xa1\x8c\xe4\xb8\x80\xe5\xae\x9a\xe4\xbb\xa3\xe6\x95\xb0\xe5\x90\x8e\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\xe6\x9c\xaa\xe8\xbe\xbe\xe5\x88\xb0\xe6\x9f\x90\xe5\x80\xbc\xef\xbc\x8c\xe5\x88\x99\xe9\x87\x8d\xe6\x96\xb0\xe8\xae\xad\xe7\xbb\x83\r\n        if i > 30 and max(acc_vec) - min(acc_vec) < 0.3:\r\n            tf.reset_default_graph()\r\n            sess.close()\r\n            return False\r\n\r\n        #  \xe5\x9c\xa8\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\xbe\xaa\xe7\x8e\xaf\xe6\xac\xa1\xe6\x95\xb0\xe4\xb8\xad\xef\xbc\x8c\xe6\x89\xbe\xe5\x88\xb0\xe7\xbb\xbc\xe5\x90\x88\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\xe6\x9c\x80\xe9\xab\x98\xe7\x9a\x84\xe4\xb8\x80\xe6\xac\xa1\xef\xbc\x8c\xe4\xbf\x9d\xe5\xad\x98\xe5\x8f\x82\xe6\x95\xb0\r\n        zongheaccu = 0.1 * acc_rughy_train + 0.9 * acc_rughy\r\n        if zongheaccu > accunum:\r\n            accunum = zongheaccu\r\n            # \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\r\n            saver.save(sess, \'./gu/%smodel\' % kcount, global_step=i)  #\xe6\xb3\xa8\xe6\x84\x8f\xe8\xb7\xaf\xe5\xbe\x84\r\n\r\n    sign = max(accudict.items(), key=lambda d: 0.1 * d[1][0] + 0.9 * d[1][1])[0]\r\n    print(\'%s \xe6\x8a\x98\xe8\xbf\x90\xe8\xa1\x8c\xe5\xae\x8c\xe6\xaf\x95\xef\xbc\x8c\xe6\xa8\xa1\xe5\x9e\x8b\xe5\xb7\xb2\xe7\xbb\x8f\xe4\xbf\x9d\xe5\xad\x98\xef\xbc\x8c\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84\xe6\x98\xaf%s\xe4\xbb\xa3\' % (kcount, sign))\r\n    return loss_vec[: sign + 1], loss_vec_add[: sign + 1], acc_vec[: sign + 1], acc_vec_add[: sign + 1], sign, hiddenlayers\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae\'\'\'\r\nDDatadict = bpd.kfold_train_datadict\r\n\r\n#  \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe4\xb8\xba\xe8\xbe\x93\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\r\ndef divided(data, cgu=countclass):\r\n    indata = data[:, :-cgu]\r\n    outdata = data[:, -cgu:]\r\n    return indata, outdata\r\n\r\n\r\n#  \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\x9a\x84\xe5\x80\xbc\xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe8\xbe\x93\xe5\x85\xa5\xef\xbc\x8c\xe8\xae\xad\xe7\xbb\x83\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe8\xbe\x93\xe5\x85\xa5\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe8\xbe\x93\xe5\x87\xba\r\ndef transall(listdata, count=countclass):\r\n    trin, trout = divided(listdata[0], count)\r\n    yanin, yanout = divided(listdata[1], count)\r\n    return trin, trout, yanin, yanout\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xba\x94\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe8\xbf\x90\xe8\xa1\x8c\xe7\xa8\x8b\xe5\xba\x8f\'\'\'\r\nif __name__ == ""__main__"":\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87 \xe8\xae\xad\xe7\xbb\x83\r\n    corrsave_train = []\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87 \xe9\xaa\x8c\xe8\xaf\x81\r\n    corrsave_add = []\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xb5\x8b\xe8\xaf\x95\xe9\x9b\x86\xe5\x90\x88\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n    corrsave_test = []\r\n    TEST_In, TEST_Out = divided(bpd.Test_data.values)\r\n    # \xe5\xbc\x80\xe5\xa7\x8bK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\r\n    for fold in DDatadict:\r\n        TRAIN_In, TRAIN_Out, ADD_In, ADD_Out = transall(DDatadict[fold])\r\n        while 1:\r\n            bpnn = Ten_train(TRAIN_In, TRAIN_Out, ADD_In, ADD_Out, fold)\r\n            if bpnn:\r\n                break\r\n        #  \xe4\xb8\x8b\xe8\xbd\xbd\xe5\x88\x9a\xe6\x89\x8d\xe5\xb7\xb2\xe7\xbb\x8f\xe4\xbf\x9d\xe5\xad\x98\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\r\n        #tf.reset_default_graph()\r\n        graph = tf.train.import_meta_graph(""./gu/%smodel-%s.meta"" % (fold, bpnn[4]))\r\n        ses = tf.Session()\r\n        graph.restore(ses, tf.train.latest_checkpoint(\'./\'))\r\n        op_to_restore = tf.get_default_graph().get_tensor_by_name(""Add_%s:0"" % bpnn[5])\r\n        w1 = tf.get_default_graph().get_tensor_by_name(""x_data:0"")\r\n        feed_dict = {w1: TEST_In}\r\n        dgsio = ses.run(op_to_restore, feed_dict)\r\n        #  \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n        add_on_op = outvsreal(judge(dgsio), TEST_Out)\r\n        print(\'\xe7\xac\xac%s\xe6\x8a\x98\xe6\xb5\x8b\xe8\xaf\x95\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xb8\xba\' % fold, add_on_op)\r\n        #  \xe6\xb8\x85\xe7\xa9\xba\xe5\x9b\xbe\r\n        ses.close()\r\n        tf.reset_default_graph()\r\n        #  \xe6\xb5\x8b\xe8\xaf\x95\xe6\xb7\xbb\xe5\x8a\xa0\r\n        corrsave_test.append(add_on_op)\r\n        #  \xe8\xae\xad\xe7\xbb\x83\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe6\xb7\xbb\xe5\x8a\xa0\r\n        corrsave_train.append(bpnn[2][-1])\r\n\r\n        #  \xe9\xaa\x8c\xe8\xaf\x81\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe6\xb7\xbb\xe5\x8a\xa0\r\n        corrsave_add.append(bpnn[3][-1])\r\n\r\n        # \xe7\xbb\x98\xe5\x88\xb6\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\x8e\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9b\xb2\xe7\xba\xbf\r\n        fig, ax1 = plt.subplots()\r\n        ax1.set_xlabel(\'\xe4\xbb\xa3\xe6\x95\xb0\')\r\n        ax1.set_ylabel(\'\xe8\xaf\xaf\xe5\xb7\xae\', color=\'r\')\r\n        plt.plot(list(range(len(bpnn[0]))), bpnn[0], label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'r\', marker=\'*\', linewidth=2)\r\n        plt.plot(list(range(len(bpnn[1]))), bpnn[1], label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'r\', marker=\'.\', linewidth=2)\r\n        ax1.tick_params(axis=\'y\', labelcolor=\'r\')\r\n        legend = ax1.legend(loc=\'upper center\', shadow=True, fontsize=\'x-large\')\r\n        legend.get_frame().set_facecolor(\'#F0F8FF\')\r\n        ax1.grid(True)\r\n\r\n        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\r\n\r\n        ax2.set_ylabel(\'\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\', color=\'b\')  # we already handled the x-label with ax1\r\n        plt.plot(list(range(len(bpnn[2]))), bpnn[2], label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'b\', marker=\'*\', linewidth=2)\r\n        plt.plot(list(range(len(bpnn[3]))), bpnn[3], label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'b\', marker=\'.\', linewidth=2)\r\n        ax2.tick_params(axis=\'y\', labelcolor=\'b\')\r\n        legen = ax2.legend(loc=\'lower center\', shadow=True, fontsize=\'x-large\')\r\n        legen.get_frame().set_facecolor(\'#FFFAFA\')\r\n        ax2.grid(True)\r\n        ax2.yaxis.set_major_locator(y_toge)\r\n        ax2.yaxis.set_minor_locator(y_son)\r\n\r\n        fig.tight_layout()  # otherwise the right y-label is slightly clipped\r\n        plt.title(\'%s\xe6\x8a\x98\xe8\xae\xad\xe7\xbb\x83VS\xe9\xaa\x8c\xe8\xaf\x81 \xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94\' % fold, fontsize=16)\r\n        plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\%s_fol8.jpg\' % fold)\r\n\r\n        # \xe7\xbb\x98\xe5\x88\xb6K\xe6\xac\xa1\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\r\n    plt.figure()\r\n    plt.plot(list(range(len(corrsave_train))), corrsave_train, label=\'\xe8\xae\xad\xe7\xbb\x83\', color=\'b\', marker=\'s\', linewidth=2)\r\n    plt.plot(list(range(len(corrsave_add))), corrsave_add, label=\'\xe9\xaa\x8c\xe8\xaf\x81\', color=\'r\', marker=\'8\', linewidth=2)\r\n    plt.plot(list(range(len(corrsave_test))), corrsave_test, label=\'\xe6\xb5\x8b\xe8\xaf\x95\', color=\'k\', marker=\'d\', linewidth=2)\r\n    plt.xlabel(\'\xe6\x8a\x98\xe6\x95\xb0\')\r\n    plt.ylabel(\'\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\')\r\n    plt.title(\'\xe7\xbb\x98\xe5\x88\xb6K\xe6\xac\xa1\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\', fontsize=16)\r\n    plt.grid(True)\r\n    plt.legend()\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\last_fol8.jpg\')\r\n    plt.show()\r\n\r\n\r\n'"
BPNN/BPNN_Regression/AnFany_BPNN_Regression.py,0,"b'#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe4\xb9\x9f\xe9\x80\x82\xe7\x94\xa8\xe4\xba\x8e\xe5\xa4\x9a\xe7\xbb\xb4\xe8\xbe\x93\xe5\x87\xba\r\nfrom BPNN_DATA_Reg import model_data as R_data\r\nimport numpy as np\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87\'\'\'\r\ntrain_x_data = R_data[0]  # \xe8\xae\xad\xe7\xbb\x83\xe8\xbe\x93\xe5\x85\xa5\r\ntrain_y_data = R_data[1]  # \xe8\xae\xad\xe7\xbb\x83\xe8\xbe\x93\xe5\x87\xba\r\n\r\npredict_x_data = R_data[2]  # \xe6\xb5\x8b\xe8\xaf\x95\xe8\xbe\x93\xe5\x85\xa5\r\npredict_y_data = R_data[3]  # \xe6\xb5\x8b\xe8\xaf\x95\xe8\xbe\x93\xe5\x87\xba\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\x87\xbd\xe6\x95\xb0\'\'\'\r\n\r\n# \xe9\x9a\x90\xe5\xb1\x82\xe7\x9a\x84\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n# \xe6\xb3\xa8\xe6\x84\x8f\xef\xbc\x9a\xe7\xa8\x8b\xe5\xba\x8f\xe4\xb8\xad\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xad\xe7\x9a\x84\xe5\xaf\xbc\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xad\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xef\xbc\x8c\xe6\x98\xaf\xe6\x89\xa7\xe8\xa1\x8c\xe8\xbf\x87\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\xe5\x90\x8e\xe7\x9a\x84\xe5\x80\xbc\r\ndef Sigmoid(x):\r\n    s = 1 / (1 + np.exp(-x))\r\n    return s\r\ndef Sigmoid_der(s):\r\n    y = np.multiply(s, 1 - s)\r\n    return y\r\n\r\n\r\ndef Relu(x):\r\n    s = np.maximum(0, x)\r\n    return s\r\ndef Relu_der(s):\r\n    y = np.where(s > 0, np.ones(s.shape), np.zeros(s.shape))\r\n    return y\r\n\r\ndef Tanh(x):\r\n    s = np.tanh(x)\r\n    return s\r\ndef Tanh_der(s):\r\n    y = 1 - np.multiply(s, s)\r\n    return y\r\n\r\n\r\n# \xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\r\ndef Lsm(yreal, yout):\r\n    costnum = (1 / 2) * np.sum((yreal - yout) ** 2) / len(yreal)\r\n    return costnum\r\ndef Lsm_der(yreal, yout):  # \xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\xaf\xbc\xe6\x95\xb0\xe4\xb8\xba\xe7\xbd\x91\xe7\xbb\x9c\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc\xe5\x87\x8f\xe5\x8e\xbb\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\r\n    return yout - yreal\r\n\r\n\r\n\r\n# \xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe7\x9a\x84\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\ndef Linear(x):#\xe7\xba\xbf\xe6\x80\xa7\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\x8c\x83\xe5\x9b\xb4\xe5\xb9\xb3\xe7\xa7\xbb\xc2\xb7\xc2\xb7\xe5\x88\xb0\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\x8c\x83\xe5\x9b\xb4\r\n    return x\r\n\r\ndef Linear_der(s):\r\n    y = np.zeros(shape=s.shape)\r\n    return y\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xae\x9e\xe7\x8e\xb0\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\'\'\'\r\n\r\nclass BPNN():\r\n\r\n    def __init__(self, train_in, train_out, learn_rate=0.03, son_samples=50, iter_times=10000, hidden_layer=[100,100],middle_name=\'Sigmoid\', last_name=\'Sigmoid\', cost_func=\'Lsm\', norr=0.00002, break_error=0.00003):\r\n        self.train_in = train_in  # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbe\x93\xe5\x85\xa5\r\n        self.train_out = train_out  # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbe\x93\xe5\x87\xba\r\n\r\n        self.learn_rate = learn_rate  # \xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\r\n        self.son_samples = son_samples  # \xe5\xad\x90\xe6\xa0\xb7\xe6\x9c\xac\xe4\xb8\xaa\xe6\x95\xb0\r\n        self.iter_times = iter_times  # \xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\r\n\r\n\r\n        self.all_layer = [len(self.train_in[0])] + hidden_layer + [len(self.train_out[0])] # \xe5\xae\x9a\xe4\xb9\x89\xe5\x90\x84\xe5\xb1\x82\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe5\x85\x83\xe4\xb8\xaa\xe6\x95\xb0\r\n        self.func_name = [middle_name] * len(hidden_layer) + [last_name] #\xe5\xae\x9a\xe4\xb9\x89\xe5\x90\x84\xe5\xb1\x82\xe7\x9a\x84\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\n\r\n        #  \xe5\x8f\x82\xe6\x95\xb0\xe8\xae\xbe\xe7\xbd\xae\r\n        # self.weight = [np.array(np.random.randn(x, y) / np.sqrt(x) * 0.01, dtype=np.float64) \\\r\n        #                for x, y in zip(self.all_layer[:-1], self.all_layer[1:])]  # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe6\x9d\x83\xe9\x87\x8d\r\n\r\n        self.weight = [np.array(np.random.randn(x, y)) for x, y in zip(self.all_layer[:-1], self.all_layer[1:])] #\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe6\x9d\x83\xe9\x87\x8d\r\n\r\n        self.bias = [np.random.randn(1, y) * 0.01 for y in self.all_layer[1:]]  # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe5\x81\x8f\xe7\xbd\xae\r\n\r\n\r\n        self.cost_func = cost_func\r\n        self.norr = norr\r\n        self.break_error = break_error\r\n\r\n    # \xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\xe6\xb3\x95\r\n    def train_gadient(self):\r\n        # \xe9\x87\x87\xe7\x94\xa8\xe9\x9a\x8f\xe6\x9c\xba\xe5\xb0\x8f\xe6\x89\xb9\xe9\x87\x8f\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe7\xbb\x93\xe5\x90\x88\xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\r\n        alldata = np.hstack((self.train_in, self.train_out))\r\n        np.random.shuffle(alldata)  # \xe6\x89\x93\xe4\xb9\xb1\xe9\xa1\xba\xe5\xba\x8f\r\n        # \xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe8\xbe\x93\xe5\x87\xba\xe5\x88\x86\xe5\xbc\x80\r\n        trin = alldata[:, :len(self.train_in[0])]  # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbe\x93\xe5\x85\xa5\r\n        trout = alldata[:, len(self.train_in[0]):]  # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbe\x93\xe5\x87\xba\r\n\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe6\x89\xb9\xe6\xac\xa1\xe6\x95\xb0\r\n        pici = int(len(alldata) / self.son_samples) + 1\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n        error_list = []\r\n        iter = 0\r\n\r\n        while iter < self.iter_times:\r\n            for times in range(pici):\r\n                in_train = trin[times * self.son_samples: (times + 1) * self.son_samples, :]\r\n                out_train = trout[times * self.son_samples: (times + 1) * self.son_samples, :]\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xad\xa5\xe5\x85\xa5\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\r\n\r\n                a = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe5\x92\x8c\xe5\x80\xbc\r\n                z = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n\r\n                a[0] = in_train.copy()  # \xe5\x92\x8c\xe5\x80\xbc\r\n                z[0] = in_train.copy()  # \xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x80\x90\xe5\xb1\x82\xe6\xad\xa3\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\r\n                for forward in range(1, len(self.all_layer)): # 1,2,3\r\n                    a[forward] = np.dot(z[forward - 1], self.weight[forward - 1]) + self.bias[forward - 1]\r\n                    z[forward] = eval(self.func_name[forward - 1])(a[forward])\r\n\r\n                # \xe5\xae\x9a\xe4\xb9\x89\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe8\xaf\xaf\xe5\xb7\xae\r\n                ne = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n\r\n                qiaia = eval(self.cost_func + \'_der\')(out_train, z[-1])\r\n                hhou = eval(self.func_name[-1] + \'_der\')(z[-1])\r\n                ne[-1] = np.multiply(qiaia, hhou)\r\n\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x80\x90\xe5\xb1\x82\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\r\n                for backward in range(len(self.all_layer) - 1, 0, -1):\r\n                    qianzhe = np.dot(ne[backward], self.weight[backward - 1].T)\r\n                    houzhe = eval(self.func_name[backward - 1] + \'_der\')(z[backward - 1])\r\n                    ne[backward - 1] = np.multiply(qianzhe, houzhe)\r\n\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x80\x90\xe5\xb1\x82\xe8\xae\xa1\xe7\xae\x97\xe6\x9b\xb4\xe6\x94\xb9W\xe5\x92\x8cB\xe5\x80\xbc\r\n                dw = list(range(len(self.all_layer) - 1))\r\n                db = list(range(len(self.all_layer) - 1))\r\n\r\n                # L2\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\r\n                for iwb in range(len(self.all_layer) - 1):\r\n                    dw[iwb] = np.dot(a[iwb].T, ne[iwb + 1]) / self.son_samples +\\\r\n                              (self.norr / self.son_samples) * dw[iwb]\r\n\r\n                    db[iwb] = np.sum(ne[iwb + 1], axis=0, keepdims=True) / self.son_samples + \\\r\n                              (self.norr / self.son_samples) * db[iwb]\r\n\r\n                # \xe6\x9b\xb4\xe6\x94\xb9\xe6\x9d\x83\xe9\x87\x8d\r\n                for ich in range(len(self.all_layer) - 1):\r\n                    self.weight[ich] -= self.learn_rate * dw[ich]\r\n                    self.bias[ich] -= self.learn_rate * db[ich]\r\n\r\n            # \xe6\x95\xb4\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbf\xad\xe4\xbb\xa3\xe4\xb8\x80\xe6\xac\xa1\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe6\xa0\xb7\xe6\x9c\xac\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n\r\n            a[0] = trin.copy()  # \xe5\x92\x8c\xe5\x80\xbc\r\n            z[0] = trin.copy()  # \xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n            for forward in range(1, len(self.all_layer)):\r\n                a[forward] = np.dot(z[forward - 1], self.weight[forward - 1]) + self.bias[forward - 1]\r\n                z[forward] = eval(self.func_name[forward - 1])(a[forward])\r\n\r\n            # \xe6\x89\x93\xe5\x8d\xb0\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n            errortrain = eval(self.cost_func)(trout, z[len(self.all_layer) - 1])\r\n            print(\'\xe7\xac\xac%s\xe4\xbb\xa3\xe6\x80\xbb\xe4\xbd\x93\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9a%.9f\' % (iter, errortrain))\r\n\r\n            error_list.append(errortrain)\r\n\r\n            iter += 1\r\n\r\n            #  \xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\xe7\x9a\x84\xe5\x88\xa4\xe6\x96\xad\r\n            if errortrain < self.break_error:\r\n                break\r\n\r\n        return self.weight, self.bias, error_list\r\n\r\n    def train_adam(self, mom=0.9, prop=0.9):\r\n        # \xe9\x87\x87\xe7\x94\xa8\xe9\x9a\x8f\xe6\x9c\xba\xe5\xb0\x8f\xe6\x89\xb9\xe9\x87\x8f\xe6\xa2\xaf\xe5\xba\xa6\xe4\xb8\x8b\xe9\x99\x8d\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe7\xbb\x93\xe5\x90\x88\xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\r\n        alldata = np.hstack((self.train_in, self.train_out))\r\n        np.random.shuffle(alldata)  # \xe6\x89\x93\xe4\xb9\xb1\xe9\xa1\xba\xe5\xba\x8f\r\n        # \xe8\xbe\x93\xe5\x85\xa5\xe5\x92\x8c\xe8\xbe\x93\xe5\x87\xba\xe5\x88\x86\xe5\xbc\x80\r\n        trin = alldata[:, :len(self.train_in[0])]  # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbe\x93\xe5\x85\xa5\r\n        trout = alldata[:, len(self.train_in[0]):]  # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbe\x93\xe5\x87\xba\r\n\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe6\x89\xb9\xe6\xac\xa1\xe6\x95\xb0\r\n        pici = int(len(alldata) / self.son_samples) + 1\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n        error_list = []\r\n        iter = 0\r\n\r\n        while iter < self.iter_times:\r\n            for times in range(pici):\r\n                in_train = trin[times * self.son_samples: (times + 1) * self.son_samples, :]\r\n                out_train = trout[times * self.son_samples: (times + 1) * self.son_samples, :]\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe6\xad\xa5\xe5\x85\xa5\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\r\n\r\n                a = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe5\x92\x8c\xe5\x80\xbc\r\n                z = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n\r\n                a[0] = in_train.copy()  # \xe5\x92\x8c\xe5\x80\xbc\r\n                z[0] = in_train.copy()  # \xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x80\x90\xe5\xb1\x82\xe6\xad\xa3\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\r\n                for forward in range(1, len(self.all_layer)): # 1,2,3\r\n                    a[forward] = np.dot(z[forward - 1], self.weight[forward - 1]) + self.bias[forward - 1]\r\n                    z[forward] = eval(self.func_name[forward - 1])(a[forward])\r\n\r\n                # \xe5\xae\x9a\xe4\xb9\x89\xe8\xbe\x93\xe5\x87\xba\xe5\xb1\x82\xe8\xaf\xaf\xe5\xb7\xae\r\n                ne = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n\r\n                qiaia = eval(self.cost_func + \'_der\')(out_train, z[-1])\r\n                hhou = eval(self.func_name[-1] + \'_der\')(z[-1])\r\n                ne[-1] = np.multiply(qiaia, hhou)\r\n\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x80\x90\xe5\xb1\x82\xe5\x8f\x8d\xe5\x90\x91\xe4\xbc\xa0\xe6\x92\xad\r\n                for backward in range(len(self.all_layer) - 1, 0, -1):\r\n                    qianzhe = np.dot(ne[backward], self.weight[backward - 1].T)\r\n                    houzhe = eval(self.func_name[backward - 1] + \'_der\')(z[backward - 1])\r\n                    ne[backward - 1] = np.multiply(qianzhe, houzhe)\r\n\r\n                # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x80\x90\xe5\xb1\x82\xe8\xae\xa1\xe7\xae\x97\xe6\x9b\xb4\xe6\x94\xb9W\xe5\x92\x8cB\xe5\x80\xbc\r\n                dw = list(range(len(self.all_layer) - 1))\r\n                db = list(range(len(self.all_layer) - 1))\r\n\r\n                # L2\xe6\xad\xa3\xe5\x88\x99\xe5\x8c\x96\r\n                for iwb in range(len(self.all_layer) - 1):\r\n                    dw[iwb] = np.dot(a[iwb].T, ne[iwb + 1]) / self.son_samples +\\\r\n                              (self.norr / self.son_samples) * dw[iwb]\r\n\r\n                    db[iwb] = np.sum(ne[iwb + 1], axis=0, keepdims=True) / self.son_samples + \\\r\n                              (self.norr / self.son_samples) * db[iwb]\r\n\r\n                try:\r\n                    for im in range(len(self.all_layer) - 1):\r\n                        vdw[im] = mom * vdw[im] + (1 - mom) * dw[im]\r\n                        vdb[im] = mom * vdb[im] + (1 - mom) * db[im]\r\n\r\n                        sdw[im] = mom * sdw[im] + (1 - mom) * (dw[im] ** 2)\r\n                        sdb[im] = mom * sdb[im] + (1 - mom) * (db[im] ** 2)\r\n                except NameError:\r\n                    vdw = [np.zeros(w.shape) for w in self.weight]\r\n                    vdb = [np.zeros(b.shape) for b in self.bias]\r\n\r\n                    sdw = [np.zeros(w.shape) for w in self.weight]\r\n                    sdb = [np.zeros(b.shape) for b in self.bias]\r\n\r\n                    for im in range(len(self.all_layer) - 1):\r\n                        vdw[im] = (1 - mom) * dw[im]\r\n                        vdb[im] = (1 - mom) * db[im]\r\n\r\n                        sdw[im] = (1 - prop) * (dw[im] ** 2)\r\n                        sdb[im] = (1 - prop) * (db[im] ** 2)\r\n                # \xe5\x88\x9d\xe5\xa7\x8b\xe9\x99\x90\xe5\x88\xb6\r\n                VDW = [np.zeros(w.shape) for w in self.weight]\r\n                VDB = [np.zeros(b.shape) for b in self.bias]\r\n                SDW = [np.zeros(w.shape) for w in self.weight]\r\n                SDB = [np.zeros(b.shape) for b in self.bias]\r\n                for slimit in range(len(self.all_layer) - 1):\r\n                    VDW[slimit] = vdw[slimit] / (1 - mom ** (iter + 1))\r\n                    VDB[slimit] = vdb[slimit] / (1 - mom ** (iter + 1))\r\n                    SDW[slimit] = sdw[slimit] / (1 - prop ** (iter + 1))\r\n                    SDB[slimit] = sdb[slimit] / (1 - prop ** (iter + 1))\r\n                # \xe6\x9b\xb4\xe6\x94\xb9\xe6\x9d\x83\xe9\x87\x8d\r\n                for ich in range(len(self.all_layer) - 1):\r\n                    self.weight[ich] -= self.learn_rate * (VDW[ich] / (SDW[ich] ** 0.5 + 1e-8))\r\n                    self.bias[ich] -= self.learn_rate * (VDB[ich] / (SDB[ich] ** 0.5 + 1e-8))\r\n\r\n            # \xe6\x95\xb4\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe8\xbf\xad\xe4\xbb\xa3\xe4\xb8\x80\xe6\xac\xa1\xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe6\xa0\xb7\xe6\x9c\xac\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            a[0] = trin.copy()  # \xe5\x92\x8c\xe5\x80\xbc\r\n            z[0] = trin.copy()  # \xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n            for forward in range(1, len(self.all_layer)):\r\n                a[forward] = np.dot(z[forward - 1], self.weight[forward - 1]) + self.bias[forward - 1]\r\n                z[forward] = eval(self.func_name[forward - 1])(a[forward])\r\n\r\n            # \xe6\x89\x93\xe5\x8d\xb0\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\r\n            errortrain = eval(self.cost_func)(trout, z[len(self.all_layer) - 1])\r\n            print(\'\xe7\xac\xac%s\xe4\xbb\xa3\xe6\x80\xbb\xe4\xbd\x93\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9a%.9f\' % (iter, errortrain))\r\n\r\n            error_list.append(errortrain)\r\n\r\n            iter += 1\r\n\r\n            #  \xe6\x8f\x90\xe5\x89\x8d\xe7\xbb\x93\xe6\x9d\x9f\xe7\x9a\x84\xe5\x88\xa4\xe6\x96\xad\r\n            if errortrain < self.break_error:\r\n                break\r\n\r\n        return self.weight, self.bias, error_list\r\n\r\n    def predict(self, pre_in_data):\r\n        pa = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe5\x92\x8c\xe5\x80\xbc\r\n        pz = list(range(len(self.all_layer)))  # \xe5\x82\xa8\xe5\xad\x98\xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n        pa[0] = pre_in_data.copy()  # \xe5\x92\x8c\xe5\x80\xbc\r\n        pz[0] = pre_in_data.copy()  # \xe6\xbf\x80\xe6\xb4\xbb\xe5\x80\xbc\r\n        for forward in range(1, len(self.all_layer)):\r\n            pa[forward] = np.dot(pz[forward - 1], self.weight[forward - 1]) + self.bias[forward - 1]\r\n            pz[forward] = eval(self.func_name[forward - 1])(pa[forward])\r\n        return pz[-1]\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a \xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\xe5\x87\xbd\xe6\x95\xb0\'\'\'\r\n\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl  # \xe4\xbd\x9c\xe5\x9b\xbe\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\'] # \xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe6\x96\xb0\xe5\xae\x8b\xe4\xbd\x93\r\nmpl.rcParams[\'axes.unicode_minus\'] = False\r\n#  \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\xe5\x83\x8f\r\ndef figure(real, net, le=\'\xe8\xae\xad\xe7\xbb\x83\', real_line=\'ko-\', net_line=\'r.-\', width=4):\r\n    length = len(real[0])\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xbb\xb4\xe5\xba\xa6\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe5\x9b\xbe\r\n    for iwe in range(length):\r\n        plt.subplot(length, 1, iwe+1)\r\n        plt.plot(list(range(len(real.T[iwe]))), real.T[iwe], real_line, linewidth=width)\r\n        plt.plot(list(range(len(net.T[iwe]))), net.T[iwe], net_line, linewidth=width)\r\n        plt.legend([\'%s\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\'%le, \'\xe7\xbd\x91\xe7\xbb\x9c\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc\'])\r\n        if length == 1:\r\n            plt.title(\'%s\xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94\'%le)\r\n        else:\r\n            if iwe == 0:\r\n                plt.title(\'%s\xe7\xbb\x93\xe6\x9e\x9c: %s\xe7\xbb\xb4\xe5\xba\xa6\xe5\xaf\xb9\xe6\xaf\x94\'%(le, iwe))\r\n            else:\r\n                plt.title(\'%s\xe7\xbb\xb4\xe5\xba\xa6\xe5\xaf\xb9\xe6\xaf\x94\'%iwe)\r\n    plt.show()\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe6\x9b\xb2\xe7\xba\xbf\xe5\x9b\xbe\r\ndef costfig(errlist, le=\'\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe6\x9b\xb2\xe7\xba\xbf\xe5\x9b\xbe\'):\r\n    plt.plot(list(range(len(errlist))), errlist, linewidth=5)\r\n    plt.title(le)\r\n    plt.xlabel(\'\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\')\r\n    plt.ylabel(\'\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc\')\r\n    plt.show()\r\n\r\n#  \xe5\x9b\xa0\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbe\x83\xe5\xa4\x9a\xef\xbc\x8c\xe4\xb8\xba\xe4\xba\x86\xe4\xb8\x8d\xe5\xbd\xb1\xe5\x93\x8d\xe5\xb1\x95\xe7\xa4\xba\xe6\x95\x88\xe6\x9e\x9c\xef\xbc\x8c\xe6\x8c\x89\xe5\xba\x8f\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96\xe4\xb8\x80\xe5\xae\x9a\xe6\x95\xb0\xe9\x87\x8f\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe4\xbe\xbf\xe4\xba\x8e\xe5\xb1\x95\xe7\xa4\xba\r\ndef select(datax, datay, count=2000):\r\n    sign = list(range(len(datax)))\r\n    selectr_sign = np.random.choice(sign, count, replace=False)\r\n    return datax[selectr_sign], datay[selectr_sign]\r\n\r\n# \xe5\xb0\x86\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe6\x8d\xa2\xe5\xb0\xba\xe5\xaf\xb8\xef\xbc\x8c\xe5\x8f\x98\xe4\xb8\xba\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xb0\xba\xe5\xaf\xb8\r\ndef trans(ydata, minumber=R_data[4][0], maxumber=R_data[4][1]):\r\n    return ydata * (maxumber - minumber) + minumber\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xba\x94\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe8\xbf\x90\xe8\xa1\x8c\xe7\xa8\x8b\xe5\xba\x8f\'\'\'\r\nif __name__ == ""__main__"":\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n    bpnn = BPNN(train_x_data, train_y_data)\r\n    bpnn_train = bpnn.train_adam()\r\n\r\n    train_y_data_tran = trans(train_y_data)\r\n\r\n    predict_y_data_tran = trans(predict_y_data)\r\n\r\n    # \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x9a\xe5\xbd\xb1\xe5\x93\x8d\xe5\xb1\x95\xe7\xa4\xba\xef\xbc\x8c\xe9\x9a\x8f\xe6\x9c\xba\xe6\x8c\x91\xe9\x80\x89100\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\r\n\r\n    random_train_x_data = select(train_x_data, train_y_data_tran, 200)\r\n\r\n    random_predict_x_data = select(predict_x_data, predict_y_data_tran, 100)\r\n\r\n    train_output = trans(bpnn.predict(random_train_x_data[0]))\r\n\r\n    predict_output = trans(bpnn.predict(random_predict_x_data[0]))\r\n\r\n    figure(random_train_x_data[1], train_output, le=\'\xe8\xae\xad\xe7\xbb\x83\')\r\n\r\n    figure(random_predict_x_data[1], predict_output, le=\'\xe9\xa2\x84\xe6\xb5\x8b\')\r\n\r\n    costfig(bpnn_train[2])\r\n\r\n\r\n\r\n\r\n\r\n\r\n'"
BPNN/BPNN_Regression/BPNN_Data_Reg.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\PRSA_data_2010.1.1-2014.12.31.csv')\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\r\n# \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xafpm2.5\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe5\x88\xa0\xe5\x8e\xbb\xe6\xad\xa4\xe5\x88\x97\xe4\xb8\xbaNaN\xe7\x9a\x84\xe8\xa1\x8c\r\ndata_nan = data[np.isfinite(data['pm2.5'])]\r\n\r\n# \xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xaf\xe5\xba\x8f\xe5\x8f\xb7\xe5\xad\x97\xe6\xae\xb5\xef\xbc\x8c\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\r\ndata_one = data_nan[data_nan.columns[1:]]\r\n\r\n# \xe5\xad\x97\xe6\xae\xb5'cbwd'\xef\xbc\x8c\xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\r\n\r\none_data = pd.get_dummies(data_one['cbwd'], prefix='cbwd')\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe5\x8e\x9f\xe6\x9d\xa5\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5'cbwd'\r\n\r\ndata_cw = data_one.drop(['cbwd'], axis=1)\r\n\r\n# \xe6\xb7\xbb\xe5\x8a\xa0\xe4\xb8\x8a\xe7\x8b\xac\xe7\x83\xad\xe4\xba\xa7\xe7\x94\x9f\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\ndata_hh = pd.concat([data_cw, one_data], axis=1)\r\n\r\n#  \xe8\x8e\xb7\xe5\xbe\x97\xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe4\xb8\x8e\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\xef\xbc\x8c\r\n\r\n\r\nymax = np.max(data_hh['pm2.5'].values, keepdims=True)\r\n\r\nymin = np.min(data_hh['pm2.5'].values, keepdims=True)\r\n\r\n\r\n# \xe6\x89\x80\xe6\x9c\x89\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xef\xbc\x8c \xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae0-1\xe5\x8c\x96\r\ndef norm(dat):\r\n    da = pd.DataFrame()\r\n    for hh in dat.columns:\r\n        if hh != 'pm2.5':\r\n            da[hh] = (dat[hh] - np.mean(dat[hh])) / np.std(dat[hh])  # \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\n            #  da[hh] = (dat[hh] - np.min(dat[hh])) / (np.max(dat[hh]) - np.min(dat[hh])) # 0-1\xe5\x8c\x96\r\n        else:\r\n            da[hh] = (dat[hh] - np.min(dat[hh])) / (np.max(dat[hh]) - np.min(dat[hh]))  # 0-1\xe5\x8c\x96\r\n    return da\r\n\r\ndatee = norm(data_hh)\r\n\r\n\r\n# \xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe7\xa6\xbb\r\n\r\nYdata = np.array(datee['pm2.5'].values).reshape(-1, 1)  # \xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\r\nXdata = datee.drop(['pm2.5'], axis=1).values  # \xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\r\n\r\n\r\n#  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe4\xb8\xba\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\ndef divided(xdata, ydata, percent=0.3):\r\n    sign_list = list(range(len(xdata)))\r\n    #  \xe7\x94\xa8\xe4\xba\x8e\xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84\xe5\xba\x8f\xe5\x8f\xb7\r\n    select_sign = np.random.choice(sign_list, int(len(xdata) * percent), replace=False)\r\n\r\n    #  \xe7\x94\xa8\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xba\x8f\xe5\x8f\xb7\r\n    no_select_sign = [isign for isign in sign_list if isign not in select_sign]\r\n\r\n    # \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\n    x_predict_data = xdata[select_sign]\r\n    y_predict_data = np.array(ydata[select_sign]).reshape(-1, len(ydata[0]))  # \xe8\xbd\xac\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n    x_train_data = xdata[no_select_sign]\r\n    y_train_data = np.array(ydata[no_select_sign]).reshape(-1, len(ydata[0]))  # \xe8\xbd\xac\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n\r\n    return x_train_data, y_train_data, x_predict_data, y_predict_data # \xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84x\xef\xbc\x8cy;  \xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84x\xef\xbc\x8cy;\r\n\r\n\r\n# \xe5\x8f\xaf\xe7\x94\xa8\xe4\xba\x8e\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nmodel_data = list(divided(Xdata, Ydata))\r\nmodel_data.append([ymax, ymin])\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n\r\n# \xe8\xbe\x93\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xef\xbc\x89\r\n# \xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe7\xbb\xb4\xe5\xba\xa6\xef\xbc\x89\r\n\r\n"""
BPNN/BPNN_Regression/Regre_Compare.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\x88\xa9\xe7\x94\xa8\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\xe6\x8b\x9f\xe5\x90\x88\xe5\x87\xbd\xe6\x95\xb0\r\n\r\n# \xe7\x94\x9f\xe6\x88\x90\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\nimport numpy as np\r\nimport BPNN_DATA_Reg as bp\r\n#  \xe8\xbe\x93\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nxdata = np.array(np.linspace(-80, 80, 500)).reshape(-1, 1)\r\n\r\n#  \xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\r\ny1data = (np.sin(xdata) + np.cos(xdata)) / 2\r\ny2data = (np.sin(xdata) - np.cos(xdata)) * xdata\r\n\r\n#  \xe4\xb8\xa4\xe4\xb8\xaa\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe4\xba\x8c\xe4\xb8\xba\xe4\xb8\x80\xef\xbc\x8c\r\nydata = np.hstack((y1data, y2data))\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\nxdata = (xdata - np.mean(xdata, axis=0)) / np.std(xdata, axis=0)\r\n\r\n# \xe6\x9c\x80\xe5\xa4\xa7\xe4\xb8\x8e\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\r\nmaxnum = np.max(ydata, axis=0, keepdims=True)\r\n\r\nminnum = np.min(ydata, axis=0, keepdims=True)\r\n\r\nnorm_ydata = (ydata - minnum) / (maxnum - minnum)\r\n\r\n# \xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\nmodel_data = bp.divided(xdata, norm_ydata, percent=0.1)\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe3\x80\x81\xe8\xbe\x93\xe5\x87\xba\r\ntrain_x_in = model_data[0]\r\ntrain_y_out = model_data[1]\r\n\r\n# \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\xe3\x80\x81\xe8\xbe\x93\xe5\x87\xba\r\npre_x_in = model_data[2]\r\npre_y_out = model_data[3]\r\n\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5AnFany\xe4\xbb\xa5\xe5\x8f\x8aTensorFlow\xe6\x96\xb9\xe6\xb3\x95\r\n\r\nimport AnFany_BPNN_Regression as An_Bpnn  \r\nimport TensorFlow_BPNN_Regression as Ten_Bpnn  \r\n\r\n\r\n# AnFany\xe6\x96\xb9\xe6\xb3\x95\r\n# # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\nbpnn = An_Bpnn.BPNN(train_x_in, train_y_out, learn_rate=0.002, son_samples=50, iter_times=100000000, \\\r\n                    hidden_layer=[190, 190, 190], break_error=0.005)\r\nbpnn_train = bpnn.train_adam()\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\r\ntrain_output = An_Bpnn.trans(bpnn.predict(train_x_in), minnum, maxnum)\r\nAn_Bpnn.figure(An_Bpnn.trans(train_y_out, minnum, maxnum), train_output, le='\xe8\xae\xad\xe7\xbb\x83', width=4)\r\n\r\npre_output = An_Bpnn.trans(bpnn.predict(pre_x_in), minnum, maxnum)\r\nAn_Bpnn.figure(An_Bpnn.trans(pre_y_out, minnum, maxnum), pre_output, le='\xe9\xa2\x84\xe6\xb5\x8b', width=2)\r\n\r\nAn_Bpnn.costfig(bpnn_train[2])\r\n\r\n\r\n# TensorFlow\xe6\x96\xb9\xe6\xb3\x95\r\n# \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\ntfrelu = Ten_Bpnn.Ten_train(train_x_in, train_y_out, pre_x_in, break_error=0.005, learn_rate=0.003,\\\r\n                            itertimes=100000000000, hiddennodes=120)\r\ntrain_output = Ten_Bpnn.trans(tfrelu[0], minnum, maxnum)\r\n\r\nAn_Bpnn.figure(Ten_Bpnn.trans(train_y_out, minnum, maxnum), train_output, le='\xe8\xae\xad\xe7\xbb\x83', width=4)\r\n\r\nAn_Bpnn.figure(Ten_Bpnn.trans(pre_y_out, minnum, maxnum), Ten_Bpnn.trans(tfrelu[1], minnum, maxnum), le='\xe9\xa2\x84\xe6\xb5\x8b', width=4)\r\n\r\n\r\nAn_Bpnn.costfig(tfrelu[2])\r\n\r\n\r\n"""
BPNN/BPNN_Regression/TensorFlow_BPNN_Regression.py,15,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe9\x80\x82\xe7\x94\xa8\xe4\xba\x8e\xe5\xa4\x9a\xe7\xbb\xb4\xe8\xbe\x93\xe5\x87\xba\r\nfrom BPNN_DATA_Reg import model_data as R_data\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\n'''\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae\xe5\x87\x86\xe5\xa4\x87'''\r\ntrain_x_data = R_data[0]  # \xe8\xae\xad\xe7\xbb\x83\xe8\xbe\x93\xe5\x85\xa5\r\ntrain_y_data = R_data[1]  # \xe8\xae\xad\xe7\xbb\x83\xe8\xbe\x93\xe5\x87\xba\r\n\r\npredict_x_data = R_data[2]  # \xe6\xb5\x8b\xe8\xaf\x95\xe8\xbe\x93\xe5\x85\xa5\r\npredict_y_data = R_data[3]  # \xe6\xb5\x8b\xe8\xaf\x95\xe8\xbe\x93\xe5\x87\xba\r\n\r\n'''\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a \xe5\x9f\xba\xe4\xba\x8eTensorFlow\xe6\x9e\x84\xe5\xbb\xba\xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0'''\r\n# \xe5\x88\x9b\xe5\xbb\xba\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\r\ndef activate(input_layer, weights, biases, actfunc):\r\n    layer = tf.add(tf.matmul(input_layer, weights), biases)\r\n    if actfunc == 'relu':\r\n        return tf.nn.relu(layer)\r\n    elif actfunc == 'tanh':\r\n        return tf.nn.tanh(layer)\r\n    elif actfunc == 'sigmoid':\r\n        return tf.nn.sigmoid(layer)\r\n# \xe6\x9d\x83\xe9\x87\x8d\xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe5\x92\x8c\xe5\x88\xa9\xe7\x94\xa8\xe6\xbf\x80\xe6\xb4\xbb\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\xe5\xbe\x88\xe5\xa4\xa7\r\n# sigmoid: xavir  tanh: xavir    relu: he\r\n\r\n#  \xe6\x9e\x84\xe5\xbb\xba\xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Ten_train(xdata, ydata, prexdata, hiddenlayers=3, hiddennodes=100, \\\r\n              learn_rate=0.05, itertimes=100000, batch_size=200, activate_func='sigmoid', break_error=0.0043):\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe6\x90\xad\xe5\xbb\xba\xe7\xa5\x9e\xe7\xbb\x8f\xe7\xbd\x91\xe7\xbb\x9c\r\n    Input_Dimen = len(xdata[0])\r\n    Unit_Layers = [Input_Dimen] + [hiddennodes] * hiddenlayers + [len(ydata[0])]  # \xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84\xe7\xbb\xb4\xe6\x95\xb0\xef\xbc\x8c\xe9\x9a\x90\xe5\xb1\x82\xe7\x9a\x84\xe7\xa5\x9e\xe7\xbb\x8f\xe6\x95\xb0\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\xb4\xe6\x95\xb01\r\n\r\n    # \xe5\x88\x9b\xe5\xbb\xba\xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\r\n    x_data = tf.placeholder(shape=[None, Input_Dimen], dtype=tf.float32)\r\n    y_target = tf.placeholder(shape=[None, len(ydata[0])], dtype=tf.float32)\r\n\r\n    # \xe5\xae\x9e\xe7\x8e\xb0\xe5\x8a\xa8\xe6\x80\x81\xe5\x91\xbd\xe5\x90\x8d\xe5\x8f\x98\xe9\x87\x8f\r\n    VAR_NAME = locals()\r\n\r\n    for jj in range(hiddenlayers + 1):\r\n        VAR_NAME['weight%s' % jj] = tf.Variable(np.random.rand(Unit_Layers[jj], Unit_Layers[jj + 1]), dtype=tf.float32,\\\r\n                                                name='weight%s' % jj) / np.sqrt(Unit_Layers[jj])  # sigmoid  tanh\r\n        # VAR_NAME['weight%s'%jj] = tf.Variable(np.random.rand(Unit_Layers[jj], Unit_Layers[jj + 1]), dtype=tf.float32,name='weight%s' % jj) \\/ np.sqrt(Unit_Layers[jj] / 2)  # relu\r\n        VAR_NAME['bias%s' % jj] = tf.Variable(tf.random_normal([Unit_Layers[jj + 1]], stddev=10, name='bias%s' % jj),\r\n                                              dtype=tf.float32)\r\n        if jj == 0:\r\n            VAR_NAME['ooutda%s' % jj] = activate(x_data, eval('weight%s' % jj), eval('bias%s' % jj), actfunc=activate_func)\r\n        else:\r\n            VAR_NAME['ooutda%s' % jj] = activate(eval('ooutda%s' % (jj - 1)), eval('weight%s' % jj), \\\r\n                                                 eval('bias%s' % jj), actfunc=activate_func)\r\n\r\n    # \xe5\x9d\x87\xe6\x96\xb9\xe8\xaf\xaf\xe5\xb7\xae\r\n    loss = tf.reduce_mean(tf.reduce_sum(tf.square(y_target - eval('ooutda%s' % (hiddenlayers))), reduction_indices=[1]))\r\n\r\n    # \xe4\xbc\x98\xe5\x8c\x96\xe7\x9a\x84\xe6\x96\xb9\xe6\xb3\x95\r\n    my_opt = tf.train.AdamOptimizer(learn_rate)\r\n    train_step = my_opt.minimize(loss)\r\n\r\n    # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\r\n    init = tf.global_variables_initializer()\r\n\r\n    loss_vec = []  # \xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\r\n\r\n    with tf.Session() as sess:\r\n        saver = tf.train.Saver()\r\n        sess.run(init)\r\n        for i in range(itertimes):\r\n            rand_index = np.random.choice(len(xdata), size=batch_size, replace=False)\r\n            rand_x = xdata[rand_index]\r\n            rand_y = ydata[rand_index]\r\n\r\n            sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\r\n\r\n            temp_loss = sess.run(loss, feed_dict={x_data: xdata, y_target: ydata})\r\n\r\n            loss_vec.append(temp_loss)\r\n\r\n            # \xe6\xa0\xb9\xe6\x8d\xae\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x8c\xe5\x88\xa4\xe6\x96\xad\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe6\x83\x85\xe5\x86\xb5\r\n            if (i + 1) % 25 == 0:\r\n                print('Generation: ' + str(i + 1) + '. \xe5\xbd\x92\xe4\xb8\x80\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x9aLoss = ' + str(temp_loss))\r\n\r\n            # \xe6\x8f\x90\xe5\x89\x8d\xe9\x80\x80\xe5\x87\xba\xe7\x9a\x84\xe5\x88\xa4\xe6\x96\xad\r\n            if temp_loss < break_error:  # \xe6\xa0\xb9\xe6\x8d\xae\xe7\xbb\x8f\xe9\xaa\x8c\xe8\x8e\xb7\xe5\xbe\x97\xe6\xad\xa4\xe6\x95\xb0\xe5\x80\xbc, \xe5\x9b\xa0\xe4\xb8\xba\xe9\x87\x87\xe7\x94\xa8\xe7\x9a\x84\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe4\xb8\x8b\xe9\x99\x8d\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xaf\xaf\xe5\xb7\xae\xe5\x9c\xa8\xe5\x89\x8d\xe6\x9c\x9f\xe5\x8f\xaf\xe8\x83\xbd\xe5\x87\xba\xe7\x8e\xb0\xe6\xb5\xae\xe5\x8a\xa8\r\n                break\r\n\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\r\n        pre_in_data0 = np.array(prexdata, dtype=np.float32)\r\n        for ipre in range(hiddenlayers + 1):\r\n            VAR_NAME['pre_in_data%s' % (ipre + 1)] = activate(eval('pre_in_data%s' % ipre), eval('weight%s' % ipre).eval(),\\\r\n                                                                 eval('bias%s' % ipre).eval(), actfunc=activate_func)\r\n\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\r\n        train_in_data0 = np.array(xdata, dtype=np.float32)\r\n        for ipre in range(hiddenlayers + 1):\r\n            VAR_NAME['train_in_data%s' % (ipre + 1)] = activate(eval('train_in_data%s' % ipre), eval('weight%s' % ipre).eval(),\\\r\n                                                                 eval('bias%s' % ipre).eval(), actfunc=activate_func)\r\n\r\n        return eval('train_in_data%s'%(hiddenlayers+1)).eval(), eval('pre_in_data%s'%(hiddenlayers+1)).eval(), loss_vec\r\n\r\n'''\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a \xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\xe5\x87\xbd\xe6\x95\xb0'''\r\n\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl  # \xe4\xbd\x9c\xe5\x9b\xbe\xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams['font.sans-serif'] = ['FangSong'] # \xe8\xae\xbe\xe7\xbd\xae\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe6\x96\xb0\xe5\xae\x8b\xe4\xbd\x93\r\n#  \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\xe5\x83\x8f\r\ndef figure(real, net, le='\xe8\xae\xad\xe7\xbb\x83', real_line='ko-', net_line='r.-', width=3):\r\n    length = len(real[0])\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xbb\xb4\xe5\xba\xa6\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe5\x9b\xbe\r\n    for iwe in range(length):\r\n        plt.subplot(length, 1, iwe+1)\r\n        plt.plot(list(range(len(real.T[iwe]))), real.T[iwe], real_line, linewidth=width)\r\n        plt.plot(list(range(len(net.T[iwe]))), net.T[iwe], net_line, linewidth=width - 1)\r\n        plt.legend(['%s\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc'%le, '\xe7\xbd\x91\xe7\xbb\x9c\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc'])\r\n        if length == 1:\r\n            plt.title('%s\xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94'%le)\r\n        else:\r\n            if iwe == 0:\r\n                plt.title('%s\xe7\xbb\x93\xe6\x9e\x9c: %s\xe7\xbb\xb4\xe5\xba\xa6\xe5\xaf\xb9\xe6\xaf\x94'%(le, iwe))\r\n            else:\r\n                plt.title('%s\xe7\xbb\xb4\xe5\xba\xa6\xe5\xaf\xb9\xe6\xaf\x94'%iwe)\r\n    plt.show()\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe6\x9b\xb2\xe7\xba\xbf\xe5\x9b\xbe\r\ndef costfig(errlist, le='\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe6\x9b\xb2\xe7\xba\xbf\xe5\x9b\xbe'):\r\n    plt.plot(list(range(len(errlist))), errlist, linewidth=3)\r\n    plt.title(le)\r\n    plt.xlabel('\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0')\r\n    plt.ylabel('\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc')\r\n    plt.show()\r\n\r\n#  \xe5\x9b\xa0\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbe\x83\xe5\xa4\x9a\xef\xbc\x8c\xe4\xb8\xba\xe4\xba\x86\xe4\xb8\x8d\xe5\xbd\xb1\xe5\x93\x8d\xe5\xb1\x95\xe7\xa4\xba\xe6\x95\x88\xe6\x9e\x9c\xef\xbc\x8c\xe6\x8c\x89\xe5\xba\x8f\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96\xe4\xb8\x80\xe5\xae\x9a\xe6\x95\xb0\xe9\x87\x8f\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe4\xbe\xbf\xe4\xba\x8e\xe5\xb1\x95\xe7\xa4\xba\r\ndef select(datax, datay, count=200):\r\n    sign = list(range(len(datax)))\r\n    selectr_sign = np.random.choice(sign, count, replace=False)\r\n    return datax[selectr_sign], datay[selectr_sign]\r\n\r\n# \xe5\xb0\x86\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe6\x8d\xa2\xe5\xb0\xba\xe5\xaf\xb8\xef\xbc\x8c\xe5\x8f\x98\xe4\xb8\xba\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xb0\xba\xe5\xaf\xb8\r\ndef trans(ydata, minumber=R_data[4][0], maxumber=R_data[4][1]):\r\n    return ydata * (maxumber - minumber) + minumber\r\n\r\n\r\nif __name__ == '__main__':\r\n    #  \xe8\xae\xad\xe7\xbb\x83\r\n    tfrelu = Ten_train(train_x_data, train_y_data, predict_x_data)\r\n\r\n\r\n    #  \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe6\x8d\xa2\xe5\xb0\xba\xe5\xaf\xb8\r\n    train_y_data_tran = trans(train_y_data)\r\n    predict_y_data_tran = trans(predict_y_data)\r\n\r\n\r\n    #  \xe7\xbd\x91\xe7\xbb\x9c\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe6\x8d\xa2\xe5\xb0\xba\xe5\xaf\xb8\r\n    train_output = trans(tfrelu[0])\r\n    predict_output = trans(tfrelu[1])\r\n\r\n    # \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x9a\xe5\xbd\xb1\xe5\x93\x8d\xe5\xb1\x95\xe7\xa4\xba\xef\xbc\x8c\xe9\x9a\x8f\xe6\x9c\xba\xe6\x8c\x91\xe9\x80\x89100\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\r\n    random_train_x_data = select(train_output, train_y_data_tran, 200)\r\n    random_predict_x_data = select(predict_output, predict_y_data_tran, 100)\r\n\r\n\r\n    figure(random_train_x_data[1], random_train_x_data[0], le='\xe8\xae\xad\xe7\xbb\x83')\r\n\r\n    figure(random_predict_x_data[1], random_predict_x_data[0], le='\xe9\xa2\x84\xe6\xb5\x8b')\r\n\r\n    costfig(tfrelu[2])\r\n\r\n\r\n\r\n"""
Bagging/Random_Forest/adult_RF_Classify.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport adult_RF_Data as data\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe5\x88\x86\xe7\xb1\xbb\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe6\x94\xaf\xe6\x8c\x81\xe5\xa4\x9a\xe7\xb1\xbb\xe5\x88\xab\r\nfrom sklearn.ensemble import RandomForestClassifier as RFC\r\nimport numpy as np\r\n\r\n# \xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable as PT\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8bF1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xaeK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x94\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\xbb\x99\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n\r\n# \xe5\xaf\xb9\xe4\xba\x8e\xe5\x9b\x9e\xe5\xbd\x92\xe8\x80\x8c\xe8\xa8\x80\xef\xbc\x8c\xe4\xb8\xbb\xe8\xa6\x81\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe5\xb0\xb1\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe4\xb8\xad\xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\x92\x8c\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0,\xe5\x85\xb6\xe4\xbb\x96\xe5\x8f\x82\xe6\x95\xb0\xe5\x9d\x87\xe4\xbd\xbf\xe7\x94\xa8\xe9\xbb\x98\xe8\xae\xa4\xe5\x80\xbc\r\n\r\n# \xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\ntrees = [100, 500, 1000, 2000]\r\n\r\n# \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe6\x8b\xa9\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe4\xb8\xaa\xe6\x95\xb0\r\ntezheng = [\'sqrt\']  #  \xe5\x88\x86\xe7\xb1\xbb\xe9\x97\xae\xe9\xa2\x98\xe4\xb8\x80\xe8\x88\xac\xe9\x80\x89\xe7\x94\xa8\xe5\xb9\xb3\xe6\x96\xb9\xe6\xa0\xb9\xe4\xb8\xaa\xe6\x95\xb0\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\r\n\r\n# \xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Tom(reallist, prelist):\r\n    \'\'\'\r\n    :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist:  \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: \xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\xba\xe6\x89\x80\xe6\x9c\x89\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe5\x85\xb8\r\n    \'\'\'\r\n    coundict = {}\r\n    for jj in list(set(reallist)):\r\n        coundict[jj] = {}\r\n        for hh in list(set(reallist)):\r\n            coundict[jj][hh] = len([i for i, j in zip(reallist, prelist) if i == jj and j == hh])\r\n    return coundict\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef ConfuseMatrix(reallist, prelist):\r\n    \'\'\'\r\n    :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: \xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n    \'\'\'\r\n    zidian = Tom(reallist, prelist)\r\n    lieming = sorted(zidian.keys())\r\n    table = PT([\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\'] + [\'\xe9\xa2\x84\xe6\xb5\x8b%s\'% d for d in lieming])\r\n    for jj in lieming:\r\n        table.add_row([\'\xe5\xae\x9e\xe9\x99\x85%s\' % jj] + [zidian[jj][kk] for kk in lieming])\r\n    return table\r\n\r\n#  \xe8\xae\xa1\xe7\xae\x97F1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef fmse(realist, prelist):  # \xe5\xaf\xb9\xe4\xba\x8e\xe5\xa4\x9a\xe7\xb1\xbb\xe5\x88\xab\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe9\x83\xbd\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    \'\'\'\r\n    :param realist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: F1\xe5\xba\xa6\xe9\x87\x8f\r\n    \'\'\'\r\n    condict = Tom(realist, prelist)\r\n    zongshu = 0\r\n    zhengque = 0\r\n    zhao_cu = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    for cu in condict:\r\n        zq = 0\r\n        zs = 0\r\n        for hh in condict[cu]:\r\n            geshu = condict[cu][hh]\r\n            if cu == hh:\r\n                zhengque += geshu\r\n                zq = geshu\r\n            zongshu += geshu\r\n            zs += geshu\r\n        zhao_cu.append(zq / zs)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\r\n    jingque = zhengque / zongshu\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe5\x88\xab\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    zhaohui = np.mean(np.array(zhao_cu))\r\n    # f1\xe5\xba\xa6\xe9\x87\x8f\r\n    f_degree = 2 * jingque * zhaohui / (jingque + zhaohui)\r\n    return f_degree, jingque, zhaohui\r\n\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Train(data, treecount, tezh, yanzhgdata):\r\n    model = RFC(n_estimators=treecount, max_features=tezh, class_weight=\'balanced\')\r\n    model.fit(data[:, :-1], data[:, -1])\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_out = model.predict(data[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    train_mse = fmse(data[:, -1], train_out)[0]\r\n\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    add_yan = model.predict(yanzhgdata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97f1\xe5\xba\xa6\xe9\x87\x8f\r\n    add_mse = fmse(yanzhgdata[:, -1], add_yan)[0]\r\n    print(train_mse, add_mse)\r\n    return train_mse, add_mse\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Zuhe(datadict, tre=trees, tezhen=tezheng):\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    savedict = {}\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    sacelist = {}\r\n    for t in tre:\r\n        for te in tezhen:\r\n            print(t, te)\r\n            sumlist = []\r\n            # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe6\x8a\x98\xe6\x95\xb0\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe6\x8c\x89\xe5\xba\x8f\xe5\xbc\x80\xe5\xa7\x8b\r\n            ordelist = sorted(list(datadict.keys()))\r\n            for jj in ordelist:\r\n                xun, ya = Train(datadict[jj][\'train\'], t, te, datadict[jj][\'test\'])\r\n                sumlist.append((xun + ya) / 2)\r\n            sacelist[\'%s-%s\' % (t, te)] = sumlist\r\n            savedict[\'%s-%s\' % (t, te)] = np.mean(np.array(sumlist))\r\n\r\n    # \xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\r\n    zuixao = sorted(savedict.items(), key=lambda fu: fu[1], reverse=True)[0][0]\r\n    # \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe9\x80\x89\xe5\x87\xba\xe6\xad\xa4\xe6\x96\xb9\xe6\xb3\x95\xe4\xb8\xad\xe5\x92\x8c\xe5\x80\xbc\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe6\x8a\x98\xe6\x95\xb0\r\n    xiao = sacelist[zuixao].index(max(sacelist[zuixao]))\r\n    return zuixao, xiao, sacelist\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe6\x9b\xb2\xe7\xba\xbf\r\ndef duibi(exdict, you):\r\n    plt.figure(figsize=(11, 7))\r\n    for ii in exdict:\r\n        plt.plot(list(range(len(exdict[ii]))), exdict[ii], \\\r\n                 label=\'%s%d\xe6\x8a\x98F1\xe5\x9d\x87\xe5\x80\xbc:%.3f\' % (ii, len(exdict[ii]), np.mean(np.array(exdict[ii]))), lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88F1\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf[\xe6\x9c\x80\xe4\xbc\x98\xef\xbc\x9a%s]\' % you)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\method_adult.jpg\')\r\n    return \'\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\ndef recspre(exstr, predata, datadict, zhe):\r\n    tree, te = exstr.split(\'-\')\r\n    model = RFC(n_estimators=int(tree), max_features=te)\r\n\r\n    model.fit(datadict[zhe][\'train\'][:, :-1], datadict[zhe][\'train\'][:, -1])\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yucede = model.predict(predata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n\r\n    print(ConfuseMatrix(predata[:, -1], yucede))\r\n\r\n    return fmse(predata[:, -1], yucede)\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    zijian, zhehsu, xulie = Zuhe(data.dt_data)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x96\xb9\xe6\xb3\x95\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\n    duibi(xulie, zijian)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84f1\xe5\xba\xa6\xe9\x87\x8f\xef\xbc\x8c\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    f1, jing, zhao = recspre(zijian, data.predict_data, data.dt_data, zhehsu)\r\n    print(\'F1\xe5\xba\xa6\xe9\x87\x8f\xef\xbc\x9a{}, \xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xef\xbc\x9a{}, \xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\xef\xbc\x9a{}\'.format(f1, jing, zhao))\r\n\r\n\r\n'"
Bagging/Random_Forest/adult_RF_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n#  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\ntrain_path = 'C:/Users/GWT9\\Desktop/Adult_Train.csv'\r\n\r\n#  \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\npre_path = 'C:/Users/GWT9\\Desktop/Adult_Test.csv'\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe5\xb9\xb6\xe4\xb8\x94\xe5\xa4\x84\xe7\x90\x86\xe7\xa1\xae\xe7\xbc\xba\xe5\xa4\xb1\xe6\x95\xb0\xe6\x8d\xae\r\ndef ReadHandle(filepath, miss='fill'):  # \xe5\xae\x9a\xe4\xb9\x89\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    data = pd.read_csv(r'%s' % filepath)\r\n    data = data.replace('?', np.nan)\r\n    #  \xe5\xa4\x84\xe7\x90\x86\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if miss == 'del':  # \xe5\x88\xa0\xe9\x99\xa4\xe6\x8e\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n        miss_data = data.dropna(how='any')\r\n    else:\r\n        miss_data = data.fillna(method='ffill')\r\n    return miss_data\r\n\r\n#  \xe5\xb0\x86\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\xad\x97\xe6\xae\xb5\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\xef\xbc\x8c\r\ndef Digitcode(traindata, predixdata):\r\n    #  \xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n    for ikey in traindata:\r\n        if traindata[ikey].dtype == 'object':  # \xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n            numb = sorted(list(set(list(traindata[ikey].values))))\r\n            exdict = {ji: numb.index(ji) for ji in numb}\r\n            if ikey == 'Money':  # \xe5\x9b\xa0\xe4\xb8\xbasklearn\xe6\x94\xaf\xe6\x8c\x81\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\xb1\xbb\xe5\x88\xab\r\n                predixdata[ikey] = ['%s' % gfi[:-1] for gfi in predixdata[ikey]]  # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe4\xb8\xadMoney\xe7\x9a\x84\xe5\x80\xbc\xe5\xa4\x9a\xe4\xb8\xaa\xe7\x82\xb9\r\n            else:\r\n                predixdata[ikey] = [exdict[fi] for fi in predixdata[ikey]]\r\n                traindata[ikey] = [exdict[fi] for fi in traindata[ikey]]\r\n    return traindata, predixdata.values\r\n\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nread_train = ReadHandle(train_path)\r\nread_pre = ReadHandle(pre_path)\r\n\r\n# \xe7\xbb\x8f\xe8\xbf\x87\xe5\xa4\x84\xe7\x90\x86\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nhan_train, predict_data = Digitcode(read_train, read_pre)\r\n\r\n\r\n#  \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8cK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x8c\xe6\xa0\xb9\xe6\x8d\xaeF1\xe5\xba\xa6\xe9\x87\x8f\xe7\xa1\xae\xe5\xae\x9a\xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\r\n#  \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xae\xa1\xe7\xae\x97\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe4\xbb\xa5\xe5\x8f\x8a\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe3\x80\x81\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\xef\xbc\x8cF1\xe5\xba\xa6\xe9\x87\x8f\r\n\r\ndef kfold(trdata, k=10):\r\n    vadata = trdata.values\r\n    legth = len(vadata)\r\n    datadict = {}\r\n    signnuber = np.arange(legth)\r\n    for hh in range(k):\r\n        datadict[hh] = {}\r\n        np.random.shuffle(vadata)\r\n        yanzhneg = np.random.choice(signnuber, int(legth / k), replace=False)\r\n        oneflod_yan = vadata[yanzhneg]\r\n        oneflod_xun = vadata[[hdd for hdd in signnuber if hdd not in yanzhneg]]\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\r\n        datadict[hh]['train'] = oneflod_xun\r\n        datadict[hh]['test'] = oneflod_yan\r\n    return datadict\r\n\r\n#  \xe5\xad\x98\xe5\x82\xa8K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\r\ndt_data = kfold(han_train)\r\n"""
Bagging/Random_Forest/pm25_RF_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\PRSA_data_2010.1.1-2014.12.31.csv')\r\n\r\n#  \xe5\x9b\xa0\xe4\xb8\xbaSklearn\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe4\xb8\x8d\xe8\x83\xbd\xe5\xa4\x84\xe7\x90\x86\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\xbd\xa2\xe5\xbc\x8f\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\r\n\r\n\r\n\r\n'''\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86'''\r\n#  \xe5\x9b\xa0\xe4\xb8\xbaPm2.5\xe6\x98\xaf\xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9b\xb4\xe6\x8e\xa5\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xb8\x80\xe6\x9d\xa1\xe8\xae\xb0\xe5\xbd\x95\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe7\x9b\xae\xe6\xa0\x87\xe5\x80\xbc\xe4\xb8\xba\xe7\xa9\xba\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0, \xe5\x85\xb6\xe4\xbb\x96\xe5\x88\x97\xe4\xb8\xba\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe5\x88\x99\xe8\x87\xaa\xe5\x8a\xa8\xe5\xa1\xab\xe5\x85\x85\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0,\xe5\xb9\xb6\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\x8f\x98\xe9\x87\x8f\xe6\x94\xbe\xe7\xbd\xae\xe5\x9c\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\x88\x97\r\ndef DeleteTargetNan(exdata, targetstr):\r\n    #  \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if exdata[targetstr].isnull().any():\r\n        #  \xe9\xa6\x96\xe5\x85\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe6\x95\xb0\r\n        loc = exdata[targetstr][data[targetstr].isnull().values == True].index.tolist()\r\n        #  \xe7\x84\xb6\xe5\x90\x8e\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xba\x9b\xe8\xa1\x8c\r\n        exdata = exdata.drop(loc)\r\n    # \xe5\x87\xa1\xe6\x98\xaf\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\x86\x8d\xe4\xb8\x80\xe8\xb5\xb7\xe5\x88\xa9\xe7\x94\xa8\xe6\xad\xa4\xe8\xa1\x8c\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\xe5\xa1\xab\xe5\x85\x85\r\n    exdata = exdata.fillna(exdata.mean())\r\n    # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\x87\xb3\xe6\x94\xbe\xe5\x9c\xa8\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe4\xb8\x80\xe5\x88\x97\r\n    targetnum = exdata[targetstr].copy()\r\n    del exdata[targetstr]\r\n    exdata[targetstr] = targetnum\r\n    return exdata\r\n\r\n\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\r\ndef Shanchu(exdata, aiduan=['No']):\r\n    for ai in aiduan:\r\n        if ai in exdata.keys():\r\n            del exdata[ai]\r\n    return exdata\r\n\r\n\r\n# \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe7\x9a\x84\xe5\xb1\x9e\xe6\x80\xa7\xe5\x80\xbc\xe4\xb8\xba\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\x9a\x84\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\xe5\xaf\xb9\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe8\x80\x8c\xe8\xa8\x80\xe4\xb8\x8d\xe9\x82\xa3\xe4\xb9\x88\xe9\x87\x8d\xe8\xa6\x81\r\ndef Digit(eadata):\r\n    # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\r\n    for jj in eadata:\r\n        try:\r\n            eadata[jj].values[0] + 1\r\n        except TypeError:\r\n            # \xe9\x9c\x80\xe8\xa6\x81\xe8\xbd\xac\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n            numlist = list(set(list(eadata[jj].values)))\r\n            zhuan = [numlist.index(jj) for jj in eadata[jj].values]\r\n            eadata[jj] = zhuan\r\n    return eadata\r\n\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n\r\nfirst = DeleteTargetNan(data, 'pm2.5')\r\ntwo = Shanchu(first)\r\nthird = Digit(two)\r\n\r\n# \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x8c\x89\xe7\x85\xa78:2\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe3\x80\x82\xe5\x85\xb6\xe4\xb8\xad\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x86\x8d\xe5\x88\x86\xe4\xb8\xbaK\xe4\xbb\xbd\xef\xbc\x8c\xe8\xbf\x9b\xe8\xa1\x8cK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\r\n\r\ndef fenge(exdata, k=10, per=[0.8, 0.2]):\r\n    # \xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n    lent = len(exdata)\r\n    alist = np.arange(lent)\r\n    np.random.shuffle(alist)\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\r\n    xunlian_sign = int(lent * per[0])\r\n\r\n    xunlian = np.random.choice(alist, xunlian_sign, replace=False)\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yuce = np.array([i for i in alist if i not in xunlian])\r\n\r\n    # \xe5\x86\x8d\xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe4\xb8\xbaK\xe6\x8a\x98\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xad\x97\xe5\x85\xb8\r\n    save_dict = {}\r\n    for jj in range(k):\r\n        save_dict[jj] = {}\r\n        length = len(xunlian)\r\n        # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\r\n        yuzhi = int(length / k)\r\n        yan = np.random.choice(xunlian, yuzhi, replace=False)\r\n        tt = np.array([i for i in xunlian if i not in yan])\r\n        save_dict[jj]['train'] = exdata[tt]\r\n        save_dict[jj]['test'] = exdata[yan]\r\n\r\n    return save_dict, exdata[yuce]\r\n\r\ndeeer = fenge(third.values)\r\n\r\n# K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\ndt_data = deeer[0]\r\n# \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\npredict_data = deeer[1]\r\n\r\n"""
Bagging/Random_Forest/pm25_RF_Regression.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport pm25_RF_Data as data\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b\r\nfrom sklearn.ensemble import  RandomForestRegressor as RF\r\nfrom sklearn.metrics import mean_squared_error as mse\r\nimport numpy as np\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8bMSE\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xaeK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x94\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\xbb\x99\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n\r\n# \xe5\xaf\xb9\xe4\xba\x8e\xe5\x9b\x9e\xe5\xbd\x92\xe8\x80\x8c\xe8\xa8\x80\xef\xbc\x8c\xe4\xb8\xbb\xe8\xa6\x81\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe5\xb0\xb1\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe4\xb8\xad\xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\x92\x8c\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0,\xe5\x85\xb6\xe4\xbb\x96\xe5\x8f\x82\xe6\x95\xb0\xe5\x9d\x87\xe4\xbd\xbf\xe7\x94\xa8\xe9\xbb\x98\xe8\xae\xa4\xe5\x80\xbc\r\n\r\n# \xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\ntrees = [50, 500, 1000, 2000, 4000, 7000]\r\n\r\n# \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe6\x8b\xa9\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe4\xb8\xaa\xe6\x95\xb0\r\ntezheng = [\'auto\']  #  \xe5\x9b\x9e\xe5\xbd\x92\xe9\x97\xae\xe9\xa2\x98\xe4\xb8\x80\xe8\x88\xac\xe9\x80\x89\xe7\x94\xa8\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Train(data, treecount, tezh, yanzhgdata):\r\n    model = RF(n_estimators=treecount, max_features=tezh)\r\n    model.fit(data[:, :-1], data[:, -1])\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_out = model.predict(data[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    train_mse = mse(data[:, -1], train_out)\r\n\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    add_yan = model.predict(yanzhgdata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    add_mse = mse(yanzhgdata[:, -1], add_yan)\r\n    print(train_mse, add_mse)\r\n    return train_mse, add_mse\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Zuhe(datadict, tre=trees, tezhen=tezheng):\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    savedict = {}\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    sacelist = {}\r\n    for t in tre:\r\n        for te in tezhen:\r\n            print(t, te)\r\n            sumlist = []\r\n            # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe6\x8a\x98\xe6\x95\xb0\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe6\x8c\x89\xe5\xba\x8f\xe5\xbc\x80\xe5\xa7\x8b\r\n            ordelist = sorted(list(datadict.keys()))\r\n            for jj in ordelist:\r\n                xun, ya = Train(datadict[jj][\'train\'], t, te, datadict[jj][\'test\'])\r\n                sumlist.append(xun + ya)\r\n            sacelist[\'%s-%s\' % (t, te)] = sumlist\r\n            savedict[\'%s-%s\' % (t, te)] = np.mean(np.array(sumlist))\r\n\r\n    # \xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\r\n    zuixao = sorted(savedict.items(), key=lambda fu: fu[1])[0][0]\r\n    # \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe9\x80\x89\xe5\x87\xba\xe6\xad\xa4\xe6\x96\xb9\xe6\xb3\x95\xe4\xb8\xad\xe5\x92\x8c\xe5\x80\xbc\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe6\x8a\x98\xe6\x95\xb0\r\n    xiao = sacelist[zuixao].index(min(sacelist[zuixao]))\r\n    return zuixao, xiao, sacelist\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe6\x9b\xb2\xe7\xba\xbf\r\ndef duibi(exdict, you):\r\n    plt.figure(figsize=(11, 7))\r\n    for ii in exdict:\r\n        plt.plot(list(range(len(exdict[ii]))), exdict[ii], \\\r\n                 label=\'%s%d\xe6\x8a\x98MSE\xe5\x9d\x87\xe5\x80\xbc:%.3f\' % (ii, len(exdict[ii]), np.mean(np.array(exdict[ii]))), lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88MSE\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf[\xe6\x9c\x80\xe4\xbc\x98\xef\xbc\x9a%s]\' % you)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\method.jpg\')\r\n    return \'\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\ndef recspre(exstr, predata, datadict, zhe):\r\n    tree, te = exstr.split(\'-\')\r\n    model = RF(n_estimators=int(tree), max_features=te)\r\n    model.fit(datadict[zhe][\'train\'][:, :-1], datadict[zhe][\'train\'][:, -1])\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yucede = model.predict(predata[:, :-1])\r\n    # \xe4\xb8\xba\xe4\xba\x86\xe4\xbe\xbf\xe4\xba\x8e\xe5\xb1\x95\xe7\xa4\xba\xef\xbc\x8c\xe9\x80\x89100\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xb1\x95\xe7\xa4\xba\r\n    zongleng = np.arange(len(yucede))\r\n    randomnum = np.random.choice(zongleng, 100, replace=False)\r\n\r\n    yucede_se = list(np.array(yucede)[randomnum])\r\n\r\n    yuce_re = list(np.array(predata[:, -1])[randomnum])\r\n\r\n    # \xe5\xaf\xb9\xe6\xaf\x94\r\n    plt.figure(figsize=(17, 9))\r\n    plt.subplot(2, 1, 1)\r\n    plt.plot(list(range(len(yucede_se))), yucede_se, c=\'r\', marker=\'*\', label=\'\xe9\xa2\x84\xe6\xb5\x8b\', lw=2)\r\n    plt.plot(list(range(len(yuce_re))), yuce_re, c=\'b\', marker=\'.\', label=\'\xe7\x9c\x9f\xe5\xae\x9e\', lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\xaf\xb9\xe6\xaf\x94[\xe6\x9c\x80\xe5\xa4\xa7\xe6\xa0\x91\xe6\x95\xb0%d]\' % int(tree))\r\n\r\n    plt.subplot(2, 1, 2)\r\n    plt.plot(list(range(len(yucede_se))), np.array(yuce_re) - np.array(yucede_se), \'k--\', marker=\'s\', label=\'\xe7\x9c\x9f\xe5\xae\x9e-\xe9\xa2\x84\xe6\xb5\x8b\', lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe7\x9b\xb8\xe5\xaf\xb9\xe8\xaf\xaf\xe5\xb7\xae\')\r\n\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\duibi.jpg\')\r\n    return \'\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9c\x9f\xe5\xae\x9e\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    zijian, zhehsu, xulie = Zuhe(data.dt_data)\r\n\r\n    duibi(xulie, zijian)\r\n    recspre(zijian, data.predict_data, data.dt_data, zhehsu)'"
Boosting/AdaBoost/AdaBoost_Classify.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport adult_AdaBoost_Data as data\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5AdaBoost\xe5\x88\x86\xe7\xb1\xbb\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe6\x94\xaf\xe6\x8c\x81\xe5\xa4\x9a\xe7\xb1\xbb\xe5\x88\xab\r\nfrom sklearn.ensemble import AdaBoostClassifier\r\nfrom sklearn.tree import DecisionTreeClassifier\r\nimport numpy as np\r\n\r\n# \xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable as PT\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8bF1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xaeK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x94\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\xbb\x99\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n\r\n# \xe4\xb8\xbb\xe8\xa6\x81\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe5\xb0\xb1\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe4\xb8\xad\xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\x92\x8c\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0,\xe5\x85\xb6\xe4\xbb\x96\xe5\x8f\x82\xe6\x95\xb0\xe5\x9d\x87\xe4\xbd\xbf\xe7\x94\xa8\xe9\xbb\x98\xe8\xae\xa4\xe5\x80\xbc\r\n\r\n# \xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe6\xa0\x91\xe7\x9a\x84\xe5\xb1\x82\xe6\x95\xb0\r\ncengs = [3, 5, 7]\r\n\r\n# \xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\nmodels = [1000, 2000, 5000]\r\n\r\n# \xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Tom(reallist, prelist):\r\n    \'\'\'\r\n    :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist:  \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: \xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\xba\xe6\x89\x80\xe6\x9c\x89\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe5\x85\xb8\r\n    \'\'\'\r\n    coundict = {}\r\n    for jj in list(set(reallist)):\r\n        coundict[jj] = {}\r\n        for hh in list(set(reallist)):\r\n            coundict[jj][hh] = len([i for i, j in zip(reallist, prelist) if i == jj and j == hh])\r\n    return coundict\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef ConfuseMatrix(reallist, prelist):\r\n    \'\'\'\r\n    :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: \xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n    \'\'\'\r\n    zidian = Tom(reallist, prelist)\r\n    lieming = sorted(zidian.keys())\r\n    table = PT([\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\'] + [\'\xe9\xa2\x84\xe6\xb5\x8b%s\'% d for d in lieming])\r\n    for jj in lieming:\r\n        table.add_row([\'\xe5\xae\x9e\xe9\x99\x85%s\' % jj] + [zidian[jj][kk] for kk in lieming])\r\n    return table\r\n\r\n#  \xe8\xae\xa1\xe7\xae\x97F1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef fmse(realist, prelist):  # \xe5\xaf\xb9\xe4\xba\x8e\xe5\xa4\x9a\xe7\xb1\xbb\xe5\x88\xab\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe9\x83\xbd\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    \'\'\'\r\n    :param realist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: F1\xe5\xba\xa6\xe9\x87\x8f\r\n    \'\'\'\r\n    condict = Tom(realist, prelist)\r\n    zongshu = 0\r\n    zhengque = 0\r\n    zhao_cu = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    for cu in condict:\r\n        zq = 0\r\n        zs = 0\r\n        for hh in condict[cu]:\r\n            geshu = condict[cu][hh]\r\n            if cu == hh:\r\n                zhengque += geshu\r\n                zq = geshu\r\n            zongshu += geshu\r\n            zs += geshu\r\n        zhao_cu.append(zq / zs)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\r\n    jingque = zhengque / zongshu\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe5\x88\xab\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    zhaohui = np.mean(np.array(zhao_cu))\r\n    # f1\xe5\xba\xa6\xe9\x87\x8f\r\n    f_degree = 2 * jingque * zhaohui / (jingque + zhaohui)\r\n    return f_degree, jingque, zhaohui\r\n\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Train(data, modelcount, censhu, yanzhgdata):\r\n    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=censhu),\r\n                               algorithm=""SAMME"",\r\n                               n_estimators=modelcount, learning_rate=0.8)\r\n\r\n    model.fit(data[:, :-1], data[:, -1])\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_out = model.predict(data[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    train_mse = fmse(data[:, -1], train_out)[0]\r\n\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    add_yan = model.predict(yanzhgdata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97f1\xe5\xba\xa6\xe9\x87\x8f\r\n    add_mse = fmse(yanzhgdata[:, -1], add_yan)[0]\r\n    print(train_mse, add_mse)\r\n    return train_mse, add_mse\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Zuhe(datadict, tre=models, ce=cengs):\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    savedict = {}\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    sacelist = {}\r\n    for t in tre:\r\n        for j in ce:\r\n            print(t, j)\r\n            sumlist = []\r\n            # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe6\x8a\x98\xe6\x95\xb0\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe6\x8c\x89\xe5\xba\x8f\xe5\xbc\x80\xe5\xa7\x8b\r\n            ordelist = sorted(list(datadict.keys()))\r\n            for jj in ordelist:\r\n                xun, ya = Train(datadict[jj][\'train\'], t, j, datadict[jj][\'test\'])\r\n                # \xe5\x8f\xaa\xe9\x80\x89\xe6\x8b\xa9\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe8\xbe\x83\xe5\xa4\xa7\xe7\x9a\x84\r\n\r\n                sumlist.append(ya)\r\n            sacelist[\'%s-%s\' % (t, j)] = sumlist\r\n            savedict[\'%s-%s\' % (t, j)] = np.mean(np.array(sumlist))\r\n\r\n    # \xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\r\n    zuixao = sorted(savedict.items(), key=lambda fu: fu[1], reverse=True)[0][0]\r\n    # \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe9\x80\x89\xe5\x87\xba\xe6\xad\xa4\xe6\x96\xb9\xe6\xb3\x95\xe4\xb8\xad\xe5\x92\x8c\xe5\x80\xbc\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe6\x8a\x98\xe6\x95\xb0\r\n    xiao = sacelist[zuixao].index(max(sacelist[zuixao]))\r\n    return zuixao, xiao, sacelist\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe6\x9b\xb2\xe7\xba\xbf\r\ndef duibi(exdict, you):\r\n    plt.figure(figsize=(11, 7))\r\n    for ii in exdict:\r\n        plt.plot(list(range(len(exdict[ii]))), exdict[ii], \\\r\n                 label=\'%s,%d\xe6\x8a\x98F1\xe5\x9d\x87\xe5\x80\xbc:%.4f\' % (ii, len(exdict[ii]), np.mean(np.array(exdict[ii]))), lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88F1\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf[\xe6\x9c\x80\xe4\xbc\x98\xef\xbc\x9a%s]\' % you)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\ada_adult.jpg\')\r\n    return \'\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\ndef recspre(estrs, predata, datadict, zhe):\r\n\r\n    mo, ze = estrs.split(\'-\')\r\n    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=int(ze)),\r\n                               algorithm=""SAMME"",\r\n                               n_estimators=int(mo), learning_rate=0.8)\r\n\r\n    model.fit(datadict[zhe][\'train\'][:, :-1], datadict[zhe][\'train\'][:, -1])\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yucede = model.predict(predata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n\r\n    print(ConfuseMatrix(predata[:, -1], yucede))\r\n\r\n    return fmse(predata[:, -1], yucede)\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    zijian, zhehsu, xulie = Zuhe(data.dt_data)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x96\xb9\xe6\xb3\x95\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\n    duibi(xulie, zijian)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84f1\xe5\xba\xa6\xe9\x87\x8f\xef\xbc\x8c\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    f1, jing, zhao = recspre(zijian, data.predict_data, data.dt_data, zhehsu)\r\n    print(\'F1\xe5\xba\xa6\xe9\x87\x8f\xef\xbc\x9a{}, \xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xef\xbc\x9a{}, \xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\xef\xbc\x9a{}\'.format(f1, jing, zhao))'"
Boosting/AdaBoost/AdaBoost_Regression.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport pm25_AdaBoost_Data as data\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5AdaBoost\xe5\x9b\x9e\xe5\xbd\x92\xe6\xa8\xa1\xe5\x9e\x8b\r\nfrom sklearn.ensemble import AdaBoostRegressor\r\nfrom sklearn.tree import DecisionTreeRegressor\r\nfrom sklearn.metrics import mean_squared_error as mse\r\nimport numpy as np\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8bMSE\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xaeK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x94\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\xbb\x99\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n\r\n# \xe6\x9b\xb4\xe6\x94\xb9\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x80\xe6\x98\xaf\xe6\xa1\x86\xe6\x9e\xb6\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe4\xba\x8c\xe6\x98\xaf\xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\r\n\r\n\r\n# \xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe6\xa0\x91\xe7\x9a\x84\xe5\xb1\x82\xe6\x95\xb0\r\ncengs = [20, 30, 50]\r\n\r\n# \xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\nmodels = [500, 1000, 3000]\r\n\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Train(data, modelcount, censhu, yanzhgdata):\r\n    model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=censhu),\r\n                              n_estimators=modelcount, learning_rate=0.8)\r\n\r\n    model.fit(data[:, :-1], data[:, -1])\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_out = model.predict(data[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    train_mse = mse(data[:, -1], train_out)\r\n\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    add_yan = model.predict(yanzhgdata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    add_mse = mse(yanzhgdata[:, -1], add_yan)\r\n    print(train_mse, add_mse)\r\n    return train_mse, add_mse\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Zuhe(datadict, tre=models, tezhen=cengs):\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    savedict = {}\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    sacelist = {}\r\n    for t in tre:\r\n        for te in tezhen:\r\n            print(t, te)\r\n            sumlist = []\r\n            # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe6\x8a\x98\xe6\x95\xb0\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe6\x8c\x89\xe5\xba\x8f\xe5\xbc\x80\xe5\xa7\x8b\r\n            ordelist = sorted(list(datadict.keys()))\r\n            for jj in ordelist:\r\n                xun, ya = Train(datadict[jj][\'train\'], t, te, datadict[jj][\'test\'])\r\n                # \xe6\xa0\xb9\xe6\x8d\xae\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe7\xa1\xae\xe5\xae\x9a\xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88\r\n                sumlist.append(ya)\r\n            sacelist[\'%s-%s\' % (t, te)] = sumlist\r\n            savedict[\'%s-%s\' % (t, te)] = np.mean(np.array(sumlist))\r\n\r\n    # \xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\r\n    zuixao = sorted(savedict.items(), key=lambda fu: fu[1])[0][0]\r\n    # \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe9\x80\x89\xe5\x87\xba\xe6\xad\xa4\xe6\x96\xb9\xe6\xb3\x95\xe4\xb8\xad\xe5\x92\x8c\xe5\x80\xbc\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe6\x8a\x98\xe6\x95\xb0\r\n    xiao = sacelist[zuixao].index(min(sacelist[zuixao]))\r\n    return zuixao, xiao, sacelist\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe6\x9b\xb2\xe7\xba\xbf\r\ndef duibi(exdict, you):\r\n    plt.figure(figsize=(11, 7))\r\n    for ii in exdict:\r\n        plt.plot(list(range(len(exdict[ii]))), exdict[ii], \\\r\n                 label=\'%s,%d\xe6\x8a\x98MSE\xe5\x9d\x87\xe5\x80\xbc:%.3f\' % (ii, len(exdict[ii]), np.mean(np.array(exdict[ii]))), lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88MSE\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf[\xe6\x9c\x80\xe4\xbc\x98\xef\xbc\x9a%s]\' % you)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\adaboost_pm25.jpg\')\r\n    return \'\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\ndef recspre(exstr, predata, datadict, zhe, count=100):\r\n    tree, te = exstr.split(\'-\')\r\n    model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=int(te)),\r\n                              n_estimators=int(tree), learning_rate=0.8)\r\n    model.fit(datadict[zhe][\'train\'][:, :-1], datadict[zhe][\'train\'][:, -1])\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yucede = model.predict(predata[:, :-1])\r\n    # \xe4\xb8\xba\xe4\xba\x86\xe4\xbe\xbf\xe4\xba\x8e\xe5\xb1\x95\xe7\xa4\xba\xef\xbc\x8c\xe9\x80\x89100\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xb1\x95\xe7\xa4\xba\r\n    zongleng = np.arange(len(yucede))\r\n    randomnum = np.random.choice(zongleng, count, replace=False)\r\n\r\n    yucede_se = list(np.array(yucede)[randomnum])\r\n\r\n    yuce_re = list(np.array(predata[:, -1])[randomnum])\r\n\r\n    # \xe5\xaf\xb9\xe6\xaf\x94\r\n    plt.figure(figsize=(17, 9))\r\n    plt.subplot(2, 1, 1)\r\n    plt.plot(list(range(len(yucede_se))), yucede_se, \'r--\', label=\'\xe9\xa2\x84\xe6\xb5\x8b\', lw=2)\r\n    plt.scatter(list(range(len(yuce_re))), yuce_re, c=\'b\', marker=\'.\', label=\'\xe7\x9c\x9f\xe5\xae\x9e\', lw=2)\r\n    plt.xlim(-1, count + 1)\r\n    plt.legend()\r\n    plt.title(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\xaf\xb9\xe6\xaf\x94[\xe6\x9c\x80\xe5\xa4\xa7\xe6\xa0\x91\xe6\x95\xb0%d]\' % int(tree))\r\n\r\n    plt.subplot(2, 1, 2)\r\n    plt.plot(list(range(len(yucede_se))), np.array(yuce_re) - np.array(yucede_se), \'k--\', marker=\'s\', label=\'\xe7\x9c\x9f\xe5\xae\x9e-\xe9\xa2\x84\xe6\xb5\x8b\', lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe7\x9b\xb8\xe5\xaf\xb9\xe8\xaf\xaf\xe5\xb7\xae\')\r\n\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\duibi.jpg\')\r\n    return \'\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9c\x9f\xe5\xae\x9e\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    zijian, zhehsu, xulie = Zuhe(data.dt_data)\r\n\r\n    duibi(xulie, zijian)\r\n    recspre(zijian, data.predict_data, data.dt_data, zhehsu)'"
Boosting/AdaBoost/adult_AdaBoost_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n#  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\ntrain_path = 'C:/Users/GWT9\\Desktop/Adult_Train.csv'\r\n\r\n#  \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\npre_path = 'C:/Users/GWT9\\Desktop/Adult_Test.csv'\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe5\xb9\xb6\xe4\xb8\x94\xe5\xa4\x84\xe7\x90\x86\xe7\xa1\xae\xe7\xbc\xba\xe5\xa4\xb1\xe6\x95\xb0\xe6\x8d\xae\r\ndef ReadHandle(filepath, miss='fill'):  # \xe5\xae\x9a\xe4\xb9\x89\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    data = pd.read_csv(r'%s' % filepath)\r\n    data = data.replace('?', np.nan)\r\n    #  \xe5\xa4\x84\xe7\x90\x86\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if miss == 'del':  # \xe5\x88\xa0\xe9\x99\xa4\xe6\x8e\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n        miss_data = data.dropna(how='any')\r\n    else:\r\n        miss_data = data.fillna(method='ffill')\r\n    return miss_data\r\n\r\n#  \xe5\xb0\x86\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\xad\x97\xe6\xae\xb5\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\xef\xbc\x8c\r\ndef Digitcode(traindata, predixdata):\r\n    #  \xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n    for ikey in traindata:\r\n        if traindata[ikey].dtype == 'object':  # \xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n            numb = sorted(list(set(list(traindata[ikey].values))))\r\n            exdict = {ji: numb.index(ji) for ji in numb}\r\n            if ikey == 'Money':  # \xe5\x9b\xa0\xe4\xb8\xbasklearn\xe6\x94\xaf\xe6\x8c\x81\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\xb1\xbb\xe5\x88\xab\r\n                predixdata[ikey] = ['%s' % gfi[:-1] for gfi in predixdata[ikey]]  # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe4\xb8\xadMoney\xe7\x9a\x84\xe5\x80\xbc\xe5\xa4\x9a\xe4\xb8\xaa\xe7\x82\xb9\r\n            else:\r\n                predixdata[ikey] = [exdict[fi] for fi in predixdata[ikey]]\r\n                traindata[ikey] = [exdict[fi] for fi in traindata[ikey]]\r\n    return traindata, predixdata.values\r\n\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nread_train = ReadHandle(train_path)\r\nread_pre = ReadHandle(pre_path)\r\n\r\n# \xe7\xbb\x8f\xe8\xbf\x87\xe5\xa4\x84\xe7\x90\x86\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nhan_train, predict_data = Digitcode(read_train, read_pre)\r\n\r\n\r\n#  \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8cK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x8c\xe6\xa0\xb9\xe6\x8d\xaeF1\xe5\xba\xa6\xe9\x87\x8f\xe7\xa1\xae\xe5\xae\x9a\xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\r\n#  \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xae\xa1\xe7\xae\x97\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe4\xbb\xa5\xe5\x8f\x8a\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe3\x80\x81\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\xef\xbc\x8cF1\xe5\xba\xa6\xe9\x87\x8f\r\n\r\ndef kfold(trdata, k=10):\r\n    vadata = trdata.values\r\n    legth = len(vadata)\r\n    datadict = {}\r\n    signnuber = np.arange(legth)\r\n    for hh in range(k):\r\n        datadict[hh] = {}\r\n        np.random.shuffle(vadata)\r\n        yanzhneg = np.random.choice(signnuber, int(legth / k), replace=False)\r\n        oneflod_yan = vadata[yanzhneg]\r\n        oneflod_xun = vadata[[hdd for hdd in signnuber if hdd not in yanzhneg]]\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\r\n        datadict[hh]['train'] = oneflod_xun\r\n        datadict[hh]['test'] = oneflod_yan\r\n    return datadict\r\n\r\n#  \xe5\xad\x98\xe5\x82\xa8K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\r\ndt_data = kfold(han_train)"""
Boosting/AdaBoost/pm25_AdaBoost_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\PRSA_data_2010.1.1-2014.12.31.csv')\r\n\r\n\r\n'''\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86'''\r\n#  \xe5\x9b\xa0\xe4\xb8\xbaPm2.5\xe6\x98\xaf\xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9b\xb4\xe6\x8e\xa5\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xb8\x80\xe6\x9d\xa1\xe8\xae\xb0\xe5\xbd\x95\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe7\x9b\xae\xe6\xa0\x87\xe5\x80\xbc\xe4\xb8\xba\xe7\xa9\xba\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0, \xe5\x85\xb6\xe4\xbb\x96\xe5\x88\x97\xe4\xb8\xba\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe5\x88\x99\xe8\x87\xaa\xe5\x8a\xa8\xe5\xa1\xab\xe5\x85\x85\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0,\xe5\xb9\xb6\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\x8f\x98\xe9\x87\x8f\xe6\x94\xbe\xe7\xbd\xae\xe5\x9c\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\x88\x97\r\ndef DeleteTargetNan(exdata, targetstr):\r\n    #  \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if exdata[targetstr].isnull().any():\r\n        #  \xe9\xa6\x96\xe5\x85\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe6\x95\xb0\r\n        loc = exdata[targetstr][data[targetstr].isnull().values == True].index.tolist()\r\n        #  \xe7\x84\xb6\xe5\x90\x8e\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xba\x9b\xe8\xa1\x8c\r\n        exdata = exdata.drop(loc)\r\n    # \xe5\x87\xa1\xe6\x98\xaf\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\x86\x8d\xe4\xb8\x80\xe8\xb5\xb7\xe5\x88\xa9\xe7\x94\xa8\xe6\xad\xa4\xe8\xa1\x8c\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\xe5\xa1\xab\xe5\x85\x85\r\n    exdata = exdata.fillna(exdata.mean())\r\n    # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\x87\xb3\xe6\x94\xbe\xe5\x9c\xa8\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe4\xb8\x80\xe5\x88\x97\r\n    targetnum = exdata[targetstr].copy()\r\n    del exdata[targetstr]\r\n    exdata[targetstr] = targetnum\r\n    return exdata\r\n\r\n\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\r\ndef Shanchu(exdata, aiduan=['No']):\r\n    for ai in aiduan:\r\n        if ai in exdata.keys():\r\n            del exdata[ai]\r\n    return exdata\r\n\r\n\r\n# \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe7\x9a\x84\xe5\xb1\x9e\xe6\x80\xa7\xe5\x80\xbc\xe4\xb8\xba\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\x9a\x84\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\xe5\xaf\xb9\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe8\x80\x8c\xe8\xa8\x80\xe4\xb8\x8d\xe9\x82\xa3\xe4\xb9\x88\xe9\x87\x8d\xe8\xa6\x81\r\ndef Digit(eadata):\r\n    # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\r\n    for jj in eadata:\r\n        try:\r\n            eadata[jj].values[0] + 1\r\n        except TypeError:\r\n            # \xe9\x9c\x80\xe8\xa6\x81\xe8\xbd\xac\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n            numlist = list(set(list(eadata[jj].values)))\r\n            zhuan = [numlist.index(jj) for jj in eadata[jj].values]\r\n            eadata[jj] = zhuan\r\n    return eadata\r\n\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n\r\nfirst = DeleteTargetNan(data, 'pm2.5')\r\ntwo = Shanchu(first)\r\nthird = Digit(two)\r\n\r\n# \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x8c\x89\xe7\x85\xa78:2\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe3\x80\x82\xe5\x85\xb6\xe4\xb8\xad\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x86\x8d\xe5\x88\x86\xe4\xb8\xbaK\xe4\xbb\xbd\xef\xbc\x8c\xe8\xbf\x9b\xe8\xa1\x8cK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\r\n\r\ndef fenge(exdata, k=10, per=[0.8, 0.2]):\r\n    # \xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n    lent = len(exdata)\r\n    alist = np.arange(lent)\r\n    np.random.shuffle(alist)\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\r\n    xunlian_sign = int(lent * per[0])\r\n\r\n    xunlian = np.random.choice(alist, xunlian_sign, replace=False)\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yuce = np.array([i for i in alist if i not in xunlian])\r\n\r\n    # \xe5\x86\x8d\xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe4\xb8\xbaK\xe6\x8a\x98\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xad\x97\xe5\x85\xb8\r\n    save_dict = {}\r\n    for jj in range(k):\r\n        save_dict[jj] = {}\r\n        length = len(xunlian)\r\n        # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\r\n        yuzhi = int(length / k)\r\n        yan = np.random.choice(xunlian, yuzhi, replace=False)\r\n        tt = np.array([i for i in xunlian if i not in yan])\r\n        save_dict[jj]['train'] = exdata[tt]\r\n        save_dict[jj]['test'] = exdata[yan]\r\n\r\n    return save_dict, exdata[yuce]\r\n\r\ndeeer = fenge(third.values)\r\n\r\n# K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\ndt_data = deeer[0]\r\n# \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\npredict_data = deeer[1]\r\n"""
Boosting/CatBoost/CatBoost_Classify_adult.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport adult_CatBoost_Data as data\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b\r\nimport catboost as cb\r\nimport numpy as np\r\nfrom collections import OrderedDict\r\n# \xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable as PT\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8bF1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\n# \xe4\xb8\xbb\xe8\xa6\x81\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe5\xb0\xb1\xe6\x98\xaf\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x8d\x95\xe4\xb8\xaa\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\r\n\r\n# \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\ncengs = [6, 7, 8]\r\n\r\n# \xe5\x8d\x95\xe4\xb8\xaa\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\r\nmodels = [100, 200, 300]\r\n\r\n# \xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Tom(reallist, prelist):\r\n    \'\'\'\r\n    :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist:  \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: \xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\xba\xe6\x89\x80\xe6\x9c\x89\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe5\x85\xb8\r\n    \'\'\'\r\n    coundict = {}\r\n    for jj in list(set(reallist)):\r\n        coundict[jj] = {}\r\n        for hh in list(set(reallist)):\r\n            coundict[jj][hh] = len([i for i, j in zip(reallist, prelist) if i == jj and j == hh])\r\n    return coundict\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0,\xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe7\xb1\xbb\xe5\x88\xab\xe5\x80\xbc\xe5\x92\x8c\xe5\x8e\x9f\xe5\xa7\x8b\xe7\x9a\x84\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xbd\xac\xe6\x8d\xa2\r\ndef ConfuseMatrix(reallist, prelist, dcix=data.exdixxt):\r\n    \'\'\'\r\n    :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: \xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n    \'\'\'\r\n\r\n    # \xe9\xa6\x96\xe5\x85\x88\xe5\xb0\x86\xe5\xad\x97\xe5\x85\xb8\xe7\x9a\x84\xe9\x94\xae\xe5\x80\xbc\xe4\xba\x92\xe6\x8d\xa2\r\n    ruid = {}\r\n    for jj in dcix:\r\n        ruid[dcix[jj]] = jj\r\n\r\n    zidian = Tom(reallist, prelist)\r\n    lieming = sorted(zidian.keys())\r\n    table = PT([\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\'] + [\'\xe9\xa2\x84\xe6\xb5\x8b%s\' % ruid[d] for d in lieming])\r\n    for jj in lieming:\r\n        table.add_row([\'\xe5\xae\x9e\xe9\x99\x85%s\' % ruid[jj]] + [zidian[jj][kk] for kk in lieming])\r\n    return table\r\n\r\n#  \xe8\xae\xa1\xe7\xae\x97F1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef fmse(realist, prelist):  # \xe5\xaf\xb9\xe4\xba\x8e\xe5\xa4\x9a\xe7\xb1\xbb\xe5\x88\xab\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe9\x83\xbd\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    \'\'\'\r\n    :param realist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: F1\xe5\xba\xa6\xe9\x87\x8f\r\n    \'\'\'\r\n    condict = Tom(realist, prelist)\r\n    zongshu = 0\r\n    zhengque = 0\r\n    zhao_cu = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    for cu in condict:\r\n        zq = 0\r\n        zs = 0\r\n        for hh in condict[cu]:\r\n            geshu = condict[cu][hh]\r\n            if cu == hh:\r\n                zhengque += geshu\r\n                zq = geshu\r\n            zongshu += geshu\r\n            zs += geshu\r\n        zhao_cu.append(zq / zs)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\r\n    jingque = zhengque / zongshu\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe5\x88\xab\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    zhaohui = np.mean(np.array(zhao_cu))\r\n    # f1\xe5\xba\xa6\xe9\x87\x8f\r\n    f_degree = 2 * jingque * zhaohui / (jingque + zhaohui)\r\n    return f_degree, jingque, zhaohui\r\n\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Train(data, modelcount, censhu, yanzhgdata, predata, cat=data.catind):\r\n    model = cb.CatBoostClassifier(iterations=modelcount, depth=censhu, learning_rate=0.5, loss_function=\'Logloss\',\r\n                                  logging_level=\'Verbose\')\r\n\r\n    model.fit(data[:, :-1], data[:, -1], cat_features=cat, eval_set=(yanzhgdata[:, :-1], yanzhgdata[:, -1]))\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x88\x86\xe6\x95\xb0\r\n    train_mse = model.score(data[:, :-1], data[:, -1])\r\n\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x88\x86\xe6\x95\xb0\r\n    add_mse = model.score(yanzhgdata[:, :-1], yanzhgdata[:, -1])\r\n    print(train_mse, add_mse)\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    preout = model.predict(predata[:, :-1])\r\n    return train_mse, add_mse, preout\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Zuhe(datadict, tre=models, tezhen=cengs):\r\n    \'\'\'\r\n    :param datadict: \xe5\xad\x98\xe5\x82\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    :param tre: \xe6\xa8\xa1\xe5\x9e\x8b\xe6\xa0\x91\xe7\x9a\x84\xe6\xa3\xb5\xe6\x95\xb0\r\n    :param tezhen: \xe6\xaf\x8f\xe6\xa3\xb5\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\r\n    :return: \xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\xe5\xad\x97\xe5\x85\xb8\r\n    \'\'\'\r\n\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\xef\xbc\x8c\xe6\x8c\x89\xe5\xba\x8f\xe7\x9a\x84\xe3\x80\x82\r\n    savedict = OrderedDict()\r\n\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\r\n    preresult = {}\r\n\r\n    for t in tre:\r\n        for te in tezhen:\r\n            print(t, te)\r\n            # \xe8\xae\xad\xe7\xbb\x83\r\n            xun, ya, psult = Train(datadict[\'train\'], t, te, datadict[\'test\'], datadict[\'predict\'])\r\n\r\n            # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\r\n            savedict[\'%s-%s\' % (t, te)] = [xun, ya]\r\n\r\n            preresult[\'%s-%s\' % (t, te)] = psult\r\n\r\n    # \xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\r\n    zuixao = max(savedict.items(), key=lambda fu: fu[1][1])[0]\r\n\r\n    return zuixao, savedict, preresult[zuixao]\r\n\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8b\xe8\xaf\x84\xe5\x88\x86\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\ndef duibi(exdict, you, kaudu=0.3):\r\n    \'\'\'\r\n    :param exdict: \xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe4\xb8\x8b\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    :param you: \xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\r\n    :return: \xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    \'\'\'\r\n    # \xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe5\x88\x97\xe8\xa1\xa8\r\n    palist = exdict.keys()\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    trsore = [exdict[hh][0] for hh in palist]\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    tesore = [exdict[hh][1] for hh in palist]\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x88\xb6\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    fig, ax = plt.subplots()\r\n    # \xe6\x9f\xb1\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\n    ind = np.array(list(range(len(trsore))))\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x9f\xb1\xe7\x8a\xb6\r\n    ax.bar(ind - kaudu, trsore, kaudu, color=\'SkyBlue\', label=\'\xe8\xae\xad\xe7\xbb\x83\')\r\n    ax.bar(ind, tesore, kaudu, color=\'IndianRed\', label=\'\xe6\xb5\x8b\xe8\xaf\x95\')\r\n    # xy\xe8\xbd\xb4\xe7\x9a\x84\xe6\xa0\x87\xe7\xad\xbe\r\n    ax.set_ylabel(\'\xe5\x88\x86\xe6\x95\xb0\')\r\n    ax.set_xlabel(\'\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\')\r\n    # \xe8\xae\xbe\xe7\xbd\xae\xe5\x88\xbb\xe5\xba\xa6\r\n    ax.set_xticks(ind)\r\n    ax.set_xticklabels(palist)\r\n\r\n    ax.set_ylim((0.8, 0.9))\r\n\r\n    ax.grid()\r\n\r\n    ax.legend()\r\n    plt.title(\'\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88RMSE\xe5\xaf\xb9\xe6\xaf\x94[\xe6\x9c\x80\xe4\xbc\x98\xef\xbc\x9a%s]\' % you)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\CatBoost_adult.jpg\')\r\n    return \'\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n\r\n\r\n# \xe8\xbe\x93\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x90\x84\xe7\xa7\x8d\xe6\x8c\x87\xe6\xa0\x87\r\ndef recspre(yzhenshide, yyucede):\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n    print(ConfuseMatrix(yzhenshide[\'predict\'][:, -1], yyucede))\r\n    return fmse(yzhenshide[\'predict\'][:, -1], yyucede)\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    zijian, fend, yunum = Zuhe(data.datt)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x96\xb9\xe6\xb3\x95\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\n    duibi(fend, zijian)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84f1\xe5\xba\xa6\xe9\x87\x8f\xef\xbc\x8c\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    f1, jing, zhao = recspre(data.datt, yunum)\r\n    print(\'F1\xe5\xba\xa6\xe9\x87\x8f\xef\xbc\x9a{}, \xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xef\xbc\x9a{}, \xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\xef\xbc\x9a{}\'.format(f1, jing, zhao))\r\n'"
Boosting/CatBoost/CatBoost_Regression_pm25.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport pm25_CatBoost_Data as data\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b\r\nimport catboost as cb\r\nimport numpy as np\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8bMSE\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\nfrom pylab import mpl\r\nfrom collections import OrderedDict\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nfrom pylab import *\r\n\'\'\'\r\n\xe6\xa8\xa1\xe5\x9e\x8b\xe9\x98\xb6\xe6\xae\xb5\r\n\'\'\'\r\n\r\n# \xe6\xa8\xa1\xe5\x9e\x8b(\xe6\xa0\x91)\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\nmodels = [50000, 80000]\r\n\r\n# \xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b(\xe6\xa0\x91)\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\r\ncengs = [6, 7, 8]\r\n\r\n# \xe8\xa7\x86\xe4\xb8\xba\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe7\x9a\x84\xe7\xb4\xa2\xe5\xbc\x95\r\nlabel = [7]\r\n\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Train(data, modelcount, censhu, yanzhgdata, predata, laidex=label):\r\n    \'\'\'\r\n    :param data: \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n    :param modelcount: \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\n    :param censhu: \xe6\xaf\x8f\xe4\xb8\xaa\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\r\n    :param yanzhgdata: \xe7\x94\xa8\xe4\xba\x8e\xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    :param predata: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    :param laidex: \xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x97\xe5\x8f\xb7\xe7\xb4\xa2\xe5\xbc\x95\r\n    :return: \xe5\xbd\x93\xe5\x89\x8d\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8b\xe8\xaf\xa5\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    \'\'\'\r\n\r\n    # \xe7\x94\xa8\xe4\xba\x8e\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\r\n    model = cb.CatBoostRegressor(iterations=modelcount, depth=censhu, learning_rate=0.8, loss_function=\'RMSE\')\r\n\r\n    #  \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n    model.fit(data[:, :-1], data[:, -1], cat_features=laidex, eval_set=(yanzhgdata[:, :-1], yanzhgdata[:, -1]))\r\n\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    train_mse = model.score(data[:, :-1], data[:, -1])\r\n\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    add_mse = model.score(yanzhgdata[:, :-1], yanzhgdata[:, -1])\r\n\r\n    print(train_mse, add_mse)\r\n    return train_mse, add_mse, model.predict(predata[:, :-1])\r\n\r\n# \xe6\x8c\x89\xe7\x85\xa7\xe8\xaf\xaf\xe5\xb7\xae\xe5\x80\xbc\xe4\xbb\x8e\xe5\xb0\x8f\xe5\x88\xb0\xe5\xa4\xa7\xe6\x8e\x92\xe5\x88\x97\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\ndef Pailie(realr, modelout, count=90):\r\n    \'\'\'\r\n    :param real: \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    :param modelout: \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc\r\n    :param count: \xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\xaf\xb9\xe6\xaf\x94\xe7\x9a\x84\xe6\x9d\xa1\xe6\x95\xb0\r\n    :return: \xe6\x8c\x89\xe7\x85\xa7\xe5\xb7\xae\xe5\x80\xbc\xe4\xbb\x8e\xe5\xb0\x8f\xe5\x88\xb0\xe5\xa4\xa7\xe6\x8e\x92\xe5\x88\x97\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    \'\'\'\r\n    relal_num = np.array(realr)\r\n    modelout_num = np.array(modelout)\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96\r\n    fu = np.random.choice(list(range(len(realr))), count, replace=False)\r\n    show_real, show_model = relal_num[fu], modelout_num[fu]\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe5\xb7\xae\xe5\x80\xbc\r\n    sunnum = show_real - show_model\r\n    # \xe9\xa6\x96\xe5\x85\x88\xe7\xbb\x84\xe5\x90\x88\xe4\xb8\x89\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x97\xe8\xa1\xa8\xe4\xb8\xba\xe5\xad\x97\xe5\x85\xb8\r\n    zuhedict = {ii: [show_real[ii], show_model[ii], sunnum[ii]] for ii in range(len(show_model))}\r\n    # \xe5\xad\x97\xe5\x85\xb8\xe6\x8c\x89\xe7\x9d\x80\xe5\x80\xbc\xe6\x8e\x92\xe5\xba\x8f\r\n    zhenshi = []\r\n    yucede = []\r\n    chazhi = []\r\n    # \xe6\x8c\x89\xe7\x9d\x80\xe5\xb7\xae\xe5\x80\xbc\xe4\xbb\x8e\xe5\xa4\xa7\xe5\x88\xb0\xe5\xb0\x8f\r\n    for jj in sorted(zuhedict.items(), key=lambda gy: gy[1][2]):\r\n        zhenshi.append(jj[1][0])\r\n        yucede.append(jj[1][1])\r\n        chazhi.append(jj[1][2])\r\n    return zhenshi, yucede, chazhi\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Zuhe(datadict, tre=models, tezhen=cengs):\r\n    \'\'\'\r\n    :param datadict: \xe5\xad\x98\xe5\x82\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    :param tre: \xe6\xa8\xa1\xe5\x9e\x8b\xe6\xa0\x91\xe7\x9a\x84\xe6\xa3\xb5\xe6\x95\xb0\r\n    :param tezhen: \xe6\xaf\x8f\xe6\xa3\xb5\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\r\n    :return: \xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe4\xb8\xaa\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\xe5\xad\x97\xe5\x85\xb8\r\n    \'\'\'\r\n\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\xef\xbc\x8c\xe6\x8c\x89\xe5\xba\x8f\xe7\x9a\x84\xe3\x80\x82\r\n    savedict = OrderedDict()\r\n\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\r\n    preresult = {}\r\n\r\n    for t in tre:\r\n        for te in tezhen:\r\n            print(t, te)\r\n            # \xe8\xae\xad\xe7\xbb\x83\r\n            xun, ya, psult = Train(datadict[\'train\'], t, te, datadict[\'test\'], datadict[\'predict\'])\r\n\r\n            # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\r\n            savedict[\'%s-%s\' % (t, te)] = [xun, ya]\r\n\r\n            preresult[\'%s-%s\' % (t, te)] = psult\r\n\r\n    # \xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\r\n    zuixao = min(savedict.items(), key=lambda fu: fu[1][1])[0]\r\n\r\n    return zuixao, savedict, preresult[zuixao]\r\n\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8b\xe8\xaf\x84\xe5\x88\x86\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\ndef duibi(exdict, you, kaudu=0.35):\r\n    \'\'\'\r\n    :param exdict: \xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe4\xb8\x8b\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    :param you: \xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\r\n    :return: \xe7\x9b\xb4\xe6\x96\xb9\xe5\x9b\xbe\r\n    \'\'\'\r\n    # \xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe5\x88\x97\xe8\xa1\xa8\r\n    palist = exdict.keys()\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    trsore = [exdict[hh][0] for hh in palist]\r\n    # \xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\x84\xe5\x88\x86\r\n    tesore = [exdict[hh][1] for hh in palist]\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x88\xb6\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    fig, ax = plt.subplots()\r\n    # \xe6\x9f\xb1\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\n    ind = np.array(list(range(len(trsore))))\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x9f\xb1\xe7\x8a\xb6\r\n    ax.bar(ind - kaudu, trsore, kaudu, color=\'SkyBlue\', label=\'\xe8\xae\xad\xe7\xbb\x83\')\r\n    ax.bar(ind, tesore, kaudu, color=\'IndianRed\', label=\'\xe6\xb5\x8b\xe8\xaf\x95\')\r\n    # xy\xe8\xbd\xb4\xe7\x9a\x84\xe6\xa0\x87\xe7\xad\xbe\r\n    ax.set_ylabel(\'RMSE\')\r\n    ax.set_xlabel(\'\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\')\r\n    # \xe8\xae\xbe\xe7\xbd\xae\xe5\x88\xbb\xe5\xba\xa6\r\n    ax.set_xticks(ind)\r\n    ax.set_xticklabels(palist)\r\n\r\n    ax.legend()\r\n    plt.title(\'\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88RMSE\xe5\xaf\xb9\xe6\xaf\x94[\xe6\x9c\x80\xe4\xbc\x98\xef\xbc\x9a%s]\' % you)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\CatBoost_pm25.jpg\')\r\n    return \'\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xef\xbc\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe4\xb8\x8e\xe4\xb8\xa4\xe5\x80\xbc\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\ndef recspre(yzhenshide, yyucede):\r\n    #  \xe8\x8e\xb7\xe5\xbe\x97\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\n    yreal, ypre, cha = Pailie(yzhenshide[\'predict\'][:, -1], yyucede)\r\n\r\n    plt.figure(figsize=(18, 10))\r\n    ax = plt.subplot(111)\r\n    plt.grid()\r\n    dign = np.arange(len(yreal))\r\n    #  \xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\r\n    ax.scatter(dign, yreal, label=\'\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\', lw=2, color=\'blue\', marker=\'*\')\r\n    #  \xe7\xbb\x98\xe5\x88\xb6\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    ax.plot(dign, ypre, label=\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\', lw=2, color=\'red\', linestyle=\'--\', marker=\'.\')\r\n    #  \xe7\xbb\x98\xe5\x88\xb6\xe8\xaf\xaf\xe5\xb7\xae\xe6\x9f\xb1\xe7\x8a\xb6\xe5\x9b\xbe\r\n    ax.bar(dign, cha, 0.1, label=\'\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x87\x8f\xe5\x8e\xbb\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\', color=\'k\')\r\n    # \xe7\xbb\x98\xe5\x88\xb60\xe7\xba\xbf\r\n    ax.plot(dign, [0] * len(dign), lw=2, color=\'k\')\r\n\r\n    ax.set_ylim((int(min(cha)) - 1, int(max([max(yreal), max(ypre)]))))\r\n    ax.set_xlim((0, len(dign)))\r\n\r\n    ax.legend(loc=\'upper center\')\r\n    ax.set_title(\'\xe5\x8c\x97\xe4\xba\xac\xe5\xb8\x82Pm2.5\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94\')\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\CatBoost_duibi.jpg\')\r\n\r\n    return \'\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n    \r\nif __name__ == ""__main__"":\r\n    zijian, sdict, yudd = Zuhe(data.data_dict)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\xe5\x83\x8f\r\n    duibi(sdict, zijian)\r\n    recspre(data.data_dict, yudd)\r\n'"
Boosting/CatBoost/adult_CatBoost_Data.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n#  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\ntrain_path = \'C:/Users/GWT9\\Desktop/Adult_Train.csv\'\r\n\r\n#  \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\npre_path = \'C:/Users/GWT9\\Desktop/Adult_Test.csv\'\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe5\xb9\xb6\xe4\xb8\x94\xe5\xa4\x84\xe7\x90\x86\xe7\xa1\xae\xe7\xbc\xba\xe5\xa4\xb1\xe6\x95\xb0\xe6\x8d\xae\r\ndef ReadHandle(filepath, miss=\'fill\'):  # \xe5\xae\x9a\xe4\xb9\x89\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    data = pd.read_csv(r\'%s\' % filepath)\r\n    data = data.replace(\'?\', np.nan)\r\n    #  \xe5\xa4\x84\xe7\x90\x86\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if miss == \'del\':  # \xe5\x88\xa0\xe9\x99\xa4\xe6\x8e\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n        miss_data = data.dropna(how=\'any\')\r\n    else:\r\n        miss_data = data.fillna(method=\'ffill\')\r\n    return miss_data\r\n\r\n#  \xe5\x9b\xa0\xe4\xb8\xbaCatBoost\xe6\x94\xaf\xe6\x8c\x81\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\x92\x8c\xe6\x95\xb0\xe5\xad\x97\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe5\x80\xbc\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nread_trai = ReadHandle(train_path)\r\nread_pr = ReadHandle(pre_path)\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xba\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5""Money""\xe4\xb8\xad\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe8\xbe\x83\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x9a\xe4\xba\x86\xe4\xb8\x80\xe4\xb8\xaa\xe7\x82\xb9\xef\xbc\x8c\xe9\x9c\x80\xe8\xa6\x81\xe5\xa4\x84\xe7\x90\x86\r\nread_pr[""Money""] = [ii[:-1] for ii in read_pr[""Money""]]\r\n\r\n\r\n# \xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5Money\xe4\xb8\xad\xe7\x9a\x84\xe5\x80\xbc\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba0\xe5\x92\x8c1\r\nexdixxt = {\'<=50K\': 0, \'>50K\': 1}\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe5\x80\xbc\xe6\x95\xb0\xe5\xad\x97\xe5\x8c\x96\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Tran(data, di=exdixxt):\r\n    data[\'Money\'] = [di[hh] for hh in data[\'Money\']]\r\n    return data\r\n\r\n\r\n# \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe5\x80\xbc\xe8\xbd\xac\xe6\x8d\xa2\r\nread_train = Tran(read_trai)\r\nread_pre = Tran(read_pr)\r\n\r\n\r\n# \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x8c\x89\xe7\x85\xa7\xe6\xaf\x94\xe4\xbe\x8b\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\r\ndef fenge(datd, bili=0.2): # 80%\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\x94\xa8\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c20%\xe7\x94\xa8\xe4\xba\x8e\xe9\xaa\x8c\xe8\xaf\x81\r\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe6\x89\x93\xe4\xb9\xb1\xe6\x95\xb0\xe6\x8d\xae\r\n    np.random.seed(1900)\r\n    np.random.shuffle(datd)\r\n    # \xe8\x8e\xb7\xe5\x8f\x96\xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n    leng = len(datd)\r\n    # \xe9\xaa\x8c\xe8\xaf\x81\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\r\n    yan_sign = int(leng * bili)\r\n\r\n    # \xe4\xb8\xba\xe4\xba\x86\xe4\xbe\xbf\xe4\xba\x8e\xe9\xaa\x8c\xe8\xaf\x81\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe9\x83\xbd\xe6\x98\xaf\xe5\x9b\xba\xe5\xae\x9a\xe7\x9a\x84\r\n    np.random.seed(100)\r\n    yan_list = np.random.choice(list(range(leng)), yan_sign, replace=False)\r\n\r\n    # \xe7\x94\xa8\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\r\n    xunlian_list = [gg for gg in list(range(leng)) if gg not in yan_list]\r\n\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    sadic = {}\r\n    sadic[\'train\'] = datd[xunlian_list]\r\n\r\n    sadic[\'test\'] = datd[yan_list]\r\n    return sadic\r\n\r\n# \xe8\x8e\xb7\xe5\xbe\x97\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe7\xb4\xa2\xe5\xbc\x95\r\ndef Catindex(data):\r\n    catlist = []\r\n    sign = 0\r\n    for jj in read_train:\r\n        if jj != \'Money\':\r\n            try:\r\n                read_train[jj][0] + 1\r\n            except TypeError:\r\n                catlist.append(sign)\r\n        sign += 1\r\n    return catlist\r\n\r\n\r\ndatt = fenge(read_train.values)\r\ndatt[\'predict\'] = read_pre.values\r\ncatind = Catindex(read_train)\r\n\r\n'"
Boosting/CatBoost/pm25_CatBoost_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\PRSA_data_2010.1.1-2014.12.31.csv')\r\n\r\n\r\n'''\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86'''\r\n#  \xe5\x9b\xa0\xe4\xb8\xbaPm2.5\xe6\x98\xaf\xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9b\xb4\xe6\x8e\xa5\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xb8\x80\xe6\x9d\xa1\xe8\xae\xb0\xe5\xbd\x95\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe7\x9b\xae\xe6\xa0\x87\xe5\x80\xbc\xe4\xb8\xba\xe7\xa9\xba\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c, \xe5\x85\xb6\xe4\xbb\x96\xe5\x88\x97\xe4\xb8\xba\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe5\x88\x99\xe8\x87\xaa\xe5\x8a\xa8\xe5\xa1\xab\xe5\x85\x85,\xe5\xb9\xb6\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\x8f\x98\xe9\x87\x8f\xe6\x94\xbe\xe7\xbd\xae\xe5\x9c\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\x88\x97\r\ndef DeleteTargetNan(exdata, targetstr):\r\n    '''\r\n    :param exdata: dataframe\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    :param targetstr: \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\xe7\xa7\xb0\r\n    :return: \xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe7\x9a\x84dataframe\xe6\xa0\xbc\xe5\xbc\x8f\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    '''\r\n    #  \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if exdata[targetstr].isnull().any():\r\n        #  \xe9\xa6\x96\xe5\x85\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe6\x95\xb0\r\n        loc = exdata[targetstr][data[targetstr].isnull().values == True].index.tolist()\r\n        #  \xe7\x84\xb6\xe5\x90\x8e\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xba\x9b\xe8\xa1\x8c\r\n        exdata = exdata.drop(loc)\r\n    # \xe5\x87\xa1\xe6\x98\xaf\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\x86\x8d\xe4\xb8\x80\xe8\xb5\xb7\xe5\x88\xa9\xe7\x94\xa8\xe6\xad\xa4\xe8\xa1\x8c\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\xe5\xa1\xab\xe5\x85\x85\r\n    exdata = exdata.fillna(exdata.mean())\r\n    # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\x87\xb3\xe6\x94\xbe\xe5\x9c\xa8\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe4\xb8\x80\xe5\x88\x97\r\n    targetnum = exdata[targetstr].copy()\r\n    del exdata[targetstr]\r\n    exdata[targetstr] = targetnum\r\n    return exdata\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\r\ndef Shanchu(exdata, aiduan=['No']):\r\n    for ai in aiduan:\r\n        if ai in exdata.keys():\r\n            del exdata[ai]\r\n    return exdata\r\n\r\n\r\n#  \xe5\x9b\xa0\xe4\xb8\xbaCatBoost\xe6\x94\xaf\xe6\x8c\x81\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xbb\xbb\xe4\xbd\x95\xe7\x9a\x84\xe7\xbc\x96\xe7\xa0\x81\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe9\x9c\x80\xe8\xa6\x81\xe6\x8f\x90\xe5\x89\x8d\xe5\xa3\xb0\xe6\x98\x8e\xe5\x93\xaa\xe4\xba\x9b\xe4\xb8\xaa\xe7\x89\xb9\xe5\xbe\x81\xe6\x98\xaf\xe7\xb1\xbb\xe5\x88\xab\xe5\x9e\x8b\xe7\x89\xb9\xe5\xbe\x81\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\nfirst = DeleteTargetNan(data, 'pm2.5')\r\n# \xe5\x8e\xbb\xe9\x99\xa4\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8e\r\ntwo = Shanchu(first)\r\n\r\n\r\n# \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x8c\x89\xe7\x85\xa78:2\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe3\x80\x82\r\n# \xe4\xb8\xba\xe4\xba\x86\xe4\xbe\xbf\xe4\xba\x8e\xe7\xa1\xae\xe5\xae\x9a\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe6\x8a\x8a\xe9\x9a\x8f\xe6\x9c\xba\xe7\x9a\x84\xe7\xa7\x8d\xe5\xad\x90\xe5\x9b\xba\xe5\xae\x9a\xe4\xb8\x8b\xe6\x9d\xa5\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xef\xbc\x8c\xe4\xbd\x9c\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x98\xaf\xe5\x9b\xba\xe5\xae\x9a\xe7\x9a\x84\r\n\r\ndef fenge(exdata, per=[0.7, 0.2]):\r\n    '''\r\n    :param exdata: \xe6\x80\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    :param per: \xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe6\x89\x80\xe5\x8d\xa0\xe6\xaf\x94\xe4\xbe\x8b\r\n    :return: \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\r\n    '''\r\n    # \xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n    lent = len(exdata)\r\n    alist = np.arange(lent)\r\n    np.random.seed(1900)\r\n    np.random.shuffle(alist)\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\r\n    xunlian_length = int(lent * per[0])\r\n    np.random.seed(2000)\r\n    xunlian = np.random.choice(alist, xunlian_length, replace=False)\r\n\r\n    # \xe5\x89\xa9\xe4\xb8\x8b\xe7\x9a\x84\r\n    shengxai_length = np.array([i for i in alist if i not in xunlian])\r\n\r\n    # \xe9\xaa\x8c\xe8\xaf\x81\r\n    yanzheng_length = int(lent * per[1])\r\n    np.random.seed(2200)\r\n    yanzheng = np.random.choice(shengxai_length, yanzheng_length, replace=False)\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yuce = np.array([i for i in alist if i not in xunlian or i not in yanzheng])\r\n\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xad\x97\xe5\x85\xb8\r\n    dataic = {}\r\n\r\n    dataic['train'] = exdata[xunlian]\r\n\r\n    dataic['test'] = exdata[yanzheng]\r\n\r\n    dataic['predict'] = exdata[yuce]\r\n    return dataic\r\n\r\ndata_dict = fenge(two.values)\r\n\r\n\r\n\r\n"""
Boosting/GBDT/GBDT_Classify_adult.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport adult_GBDT_Data as data\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5GBDT\xe5\x88\x86\xe7\xb1\xbb\xe6\xa8\xa1\xe5\x9e\x8b\r\nfrom sklearn.ensemble import GradientBoostingClassifier\r\n\r\nimport numpy as np\r\n\r\n# \xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable as PT\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8bF1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xaeK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x94\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\xbb\x99\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n\r\n# \xe4\xb8\xbb\xe8\xa6\x81\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe5\xb0\xb1\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe4\xb8\xad\xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\x92\x8c\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0,\xe5\x85\xb6\xe4\xbb\x96\xe5\x8f\x82\xe6\x95\xb0\xe5\x9d\x87\xe4\xbd\xbf\xe7\x94\xa8\xe9\xbb\x98\xe8\xae\xa4\xe5\x80\xbc\r\n\r\n# \xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe6\xa0\x91\xe7\x9a\x84\xe5\xb1\x82\xe6\x95\xb0\r\ncengs = [5, 7, 9]\r\n\r\n# \xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\nmodels = [120, 140, 280]\r\n\r\n# \xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Tom(reallist, prelist):\r\n    \'\'\'\r\n    :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist:  \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: \xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\xba\xe6\x89\x80\xe6\x9c\x89\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe5\x85\xb8\r\n    \'\'\'\r\n    coundict = {}\r\n    for jj in list(set(reallist)):\r\n        coundict[jj] = {}\r\n        for hh in list(set(reallist)):\r\n            coundict[jj][hh] = len([i for i, j in zip(reallist, prelist) if i == jj and j == hh])\r\n    return coundict\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef ConfuseMatrix(reallist, prelist):\r\n    \'\'\'\r\n    :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: \xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n    \'\'\'\r\n    zidian = Tom(reallist, prelist)\r\n    lieming = sorted(zidian.keys())\r\n    table = PT([\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\'] + [\'\xe9\xa2\x84\xe6\xb5\x8b%s\'% d for d in lieming])\r\n    for jj in lieming:\r\n        table.add_row([\'\xe5\xae\x9e\xe9\x99\x85%s\' % jj] + [zidian[jj][kk] for kk in lieming])\r\n    return table\r\n\r\n#  \xe8\xae\xa1\xe7\xae\x97F1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef fmse(realist, prelist):  # \xe5\xaf\xb9\xe4\xba\x8e\xe5\xa4\x9a\xe7\xb1\xbb\xe5\x88\xab\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe9\x83\xbd\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    \'\'\'\r\n    :param realist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: F1\xe5\xba\xa6\xe9\x87\x8f\r\n    \'\'\'\r\n    condict = Tom(realist, prelist)\r\n    zongshu = 0\r\n    zhengque = 0\r\n    zhao_cu = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    for cu in condict:\r\n        zq = 0\r\n        zs = 0\r\n        for hh in condict[cu]:\r\n            geshu = condict[cu][hh]\r\n            if cu == hh:\r\n                zhengque += geshu\r\n                zq = geshu\r\n            zongshu += geshu\r\n            zs += geshu\r\n        zhao_cu.append(zq / zs)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\r\n    jingque = zhengque / zongshu\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe5\x88\xab\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    zhaohui = np.mean(np.array(zhao_cu))\r\n    # f1\xe5\xba\xa6\xe9\x87\x8f\r\n    f_degree = 2 * jingque * zhaohui / (jingque + zhaohui)\r\n    return f_degree, jingque, zhaohui\r\n\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Train(data, modelcount, censhu, yanzhgdata):\r\n    model = GradientBoostingClassifier(loss=\'deviance\', n_estimators=modelcount, max_depth=censhu, learning_rate=0.1, max_features=\'sqrt\')\r\n\r\n    model.fit(data[:, :-1], data[:, -1])\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_out = model.predict(data[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    train_mse = fmse(data[:, -1], train_out)[0]\r\n\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    add_yan = model.predict(yanzhgdata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97f1\xe5\xba\xa6\xe9\x87\x8f\r\n    add_mse = fmse(yanzhgdata[:, -1], add_yan)[0]\r\n    print(train_mse, add_mse)\r\n    return train_mse, add_mse\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Zuhe(datadict, tre=models, ce=cengs):\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    savedict = {}\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    sacelist = {}\r\n    for t in tre:\r\n        for j in ce:\r\n            print(t, j)\r\n            sumlist = []\r\n            # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe6\x8a\x98\xe6\x95\xb0\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe6\x8c\x89\xe5\xba\x8f\xe5\xbc\x80\xe5\xa7\x8b\r\n            ordelist = sorted(list(datadict.keys()))\r\n            for jj in ordelist:\r\n                xun, ya = Train(datadict[jj][\'train\'], t, j, datadict[jj][\'test\'])\r\n                # \xe5\x8f\xaa\xe9\x80\x89\xe6\x8b\xa9\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe8\xbe\x83\xe5\xa4\xa7\xe7\x9a\x84\r\n\r\n                sumlist.append(ya)\r\n            sacelist[\'%s-%s\' % (t, j)] = sumlist\r\n            savedict[\'%s-%s\' % (t, j)] = np.mean(np.array(sumlist))\r\n\r\n    # \xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\r\n    zuixao = sorted(savedict.items(), key=lambda fu: fu[1], reverse=True)[0][0]\r\n    # \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe9\x80\x89\xe5\x87\xba\xe6\xad\xa4\xe6\x96\xb9\xe6\xb3\x95\xe4\xb8\xad\xe5\x92\x8c\xe5\x80\xbc\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe6\x8a\x98\xe6\x95\xb0\r\n    xiao = sacelist[zuixao].index(max(sacelist[zuixao]))\r\n    return zuixao, xiao, sacelist\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe6\x9b\xb2\xe7\xba\xbf\r\ndef duibi(exdict, you):\r\n    plt.figure(figsize=(11, 7))\r\n    for ii in exdict:\r\n        plt.plot(list(range(len(exdict[ii]))), exdict[ii], \\\r\n                 label=\'%s,%d\xe6\x8a\x98F1\xe5\x9d\x87\xe5\x80\xbc:%.4f\' % (ii, len(exdict[ii]), np.mean(np.array(exdict[ii]))), lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88F1\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf[\xe6\x9c\x80\xe4\xbc\x98\xef\xbc\x9a%s]\' % you)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\ada_adult.jpg\')\r\n    return \'\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\ndef recspre(estrs, predata, datadict, zhe):\r\n\r\n    mo, ze = estrs.split(\'-\')\r\n    model = GradientBoostingClassifier(loss=\'deviance\', n_estimators=int(mo), max_depth=int(ze), learning_rate=0.1)\r\n\r\n    model.fit(datadict[zhe][\'train\'][:, :-1], datadict[zhe][\'train\'][:, -1])\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yucede = model.predict(predata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n\r\n    print(ConfuseMatrix(predata[:, -1], yucede))\r\n\r\n    return fmse(predata[:, -1], yucede)\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    zijian, zhehsu, xulie = Zuhe(data.dt_data)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x96\xb9\xe6\xb3\x95\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\n    duibi(xulie, zijian)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84f1\xe5\xba\xa6\xe9\x87\x8f\xef\xbc\x8c\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    f1, jing, zhao = recspre(zijian, data.predict_data, data.dt_data, zhehsu)\r\n    print(\'F1\xe5\xba\xa6\xe9\x87\x8f\xef\xbc\x9a{}, \xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xef\xbc\x9a{}, \xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\xef\xbc\x9a{}\'.format(f1, jing, zhao))\r\n'"
Boosting/GBDT/GBDT_Regression_pm25.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport pm25_GBDT_Data as data\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5GBDT\xe5\x9b\x9e\xe5\xbd\x92\xe6\xa8\xa1\xe5\x9e\x8b\r\nfrom sklearn.ensemble import GradientBoostingRegressor\r\nfrom sklearn.metrics import mean_squared_error as mse\r\nimport numpy as np\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8bMSE\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xaeK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x94\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\xbb\x99\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n\r\n# \xe6\x9b\xb4\xe6\x94\xb9\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x80\xe6\x98\xaf\xe6\xa1\x86\xe6\x9e\xb6\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe4\xba\x8c\xe6\x98\xaf\xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\r\n\r\n\r\n# \xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe6\xa0\x91\xe7\x9a\x84\xe5\xb1\x82\xe6\x95\xb0\r\ncengs = [16, 17, 18]\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\nmodels = [55, 56, 57]\r\n\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Train(data, modelcount, censhu, yanzhgdata):\r\n    model = GradientBoostingRegressor(loss=\'ls\', n_estimators=modelcount, max_depth=censhu, learning_rate=0.12, subsample=0.8)\r\n\r\n    model.fit(data[:, :-1], data[:, -1])\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_out = model.predict(data[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    train_mse = mse(data[:, -1], train_out)\r\n\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    add_yan = model.predict(yanzhgdata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    add_mse = mse(yanzhgdata[:, -1], add_yan)\r\n    print(train_mse, add_mse)\r\n    return train_mse, add_mse\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Zuhe(datadict, tre=models, tezhen=cengs):\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    savedict = {}\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    sacelist = {}\r\n    for t in tre:\r\n        for te in tezhen:\r\n            print(t, te)\r\n            sumlist = []\r\n            # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe6\x8a\x98\xe6\x95\xb0\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe6\x8c\x89\xe5\xba\x8f\xe5\xbc\x80\xe5\xa7\x8b\r\n            ordelist = sorted(list(datadict.keys()))\r\n            for jj in ordelist:\r\n                xun, ya = Train(datadict[jj][\'train\'], t, te, datadict[jj][\'test\'])\r\n                # \xe6\xa0\xb9\xe6\x8d\xae\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe7\xa1\xae\xe5\xae\x9a\xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88\r\n                sumlist.append(ya)\r\n            sacelist[\'%s-%s\' % (t, te)] = sumlist\r\n            savedict[\'%s-%s\' % (t, te)] = np.mean(np.array(sumlist))\r\n\r\n    # \xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\r\n    zuixao = sorted(savedict.items(), key=lambda fu: fu[1])[0][0]\r\n    # \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe9\x80\x89\xe5\x87\xba\xe6\xad\xa4\xe6\x96\xb9\xe6\xb3\x95\xe4\xb8\xad\xe5\x92\x8c\xe5\x80\xbc\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe6\x8a\x98\xe6\x95\xb0\r\n    xiao = sacelist[zuixao].index(min(sacelist[zuixao]))\r\n    return zuixao, xiao, sacelist\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe6\x9b\xb2\xe7\xba\xbf\r\ndef duibi(exdict, you):\r\n    plt.figure(figsize=(11, 7))\r\n    for ii in exdict:\r\n        plt.plot(list(range(len(exdict[ii]))), exdict[ii], \\\r\n                 label=\'%s,%d\xe6\x8a\x98MSE\xe5\x9d\x87\xe5\x80\xbc:%.3f\' % (ii, len(exdict[ii]), np.mean(np.array(exdict[ii]))), lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88MSE\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf[\xe6\x9c\x80\xe4\xbc\x98\xef\xbc\x9a%s]\' % you)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\GBDT_pm25.jpg\')\r\n    return \'\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\ndef recspre(exstr, predata, datadict, zhe, count=100):\r\n    tree, te = exstr.split(\'-\')\r\n    model = GradientBoostingRegressor(loss=\'ls\', n_estimators=int(tree), max_depth=int(te), learning_rate=0.12, subsample=0.8)\r\n    model.fit(datadict[zhe][\'train\'][:, :-1], datadict[zhe][\'train\'][:, -1])\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yucede = model.predict(predata[:, :-1])\r\n    # \xe4\xb8\xba\xe4\xba\x86\xe4\xbe\xbf\xe4\xba\x8e\xe5\xb1\x95\xe7\xa4\xba\xef\xbc\x8c\xe9\x80\x89100\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xb1\x95\xe7\xa4\xba\r\n    zongleng = np.arange(len(yucede))\r\n    randomnum = np.random.choice(zongleng, count, replace=False)\r\n\r\n    yucede_se = list(np.array(yucede)[randomnum])\r\n\r\n    yuce_re = list(np.array(predata[:, -1])[randomnum])\r\n\r\n    # \xe5\xaf\xb9\xe6\xaf\x94\r\n    plt.figure(figsize=(17, 9))\r\n    plt.subplot(2, 1, 1)\r\n    plt.plot(list(range(len(yucede_se))), yucede_se, \'r--\', label=\'\xe9\xa2\x84\xe6\xb5\x8b\', lw=2)\r\n    plt.scatter(list(range(len(yuce_re))), yuce_re, c=\'b\', marker=\'.\', label=\'\xe7\x9c\x9f\xe5\xae\x9e\', lw=2)\r\n    plt.xlim(-1, count + 1)\r\n    plt.legend()\r\n    plt.title(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\xaf\xb9\xe6\xaf\x94[\xe6\x9c\x80\xe5\xa4\xa7\xe6\xa0\x91\xe6\x95\xb0%d]\' % int(tree))\r\n\r\n    plt.subplot(2, 1, 2)\r\n    plt.plot(list(range(len(yucede_se))), np.array(yuce_re) - np.array(yucede_se), \'k--\', marker=\'s\', label=\'\xe7\x9c\x9f\xe5\xae\x9e-\xe9\xa2\x84\xe6\xb5\x8b\', lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe7\x9b\xb8\xe5\xaf\xb9\xe8\xaf\xaf\xe5\xb7\xae\')\r\n\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\duibi.jpg\')\r\n    return \'\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9c\x9f\xe5\xae\x9e\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    zijian, zhehsu, xulie = Zuhe(data.dt_data)\r\n\r\n    duibi(xulie, zijian)\r\n    recspre(zijian, data.predict_data, data.dt_data, zhehsu)\r\n'"
Boosting/GBDT/adult_GBDT_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n#  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\ntrain_path = 'C:/Users/GWT9\\Desktop/Adult_Train.csv'\r\n\r\n#  \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\npre_path = 'C:/Users/GWT9\\Desktop/Adult_Test.csv'\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe5\xb9\xb6\xe4\xb8\x94\xe5\xa4\x84\xe7\x90\x86\xe7\xa1\xae\xe7\xbc\xba\xe5\xa4\xb1\xe6\x95\xb0\xe6\x8d\xae\r\ndef ReadHandle(filepath, miss='fill'):  # \xe5\xae\x9a\xe4\xb9\x89\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    data = pd.read_csv(r'%s' % filepath)\r\n    data = data.replace('?', np.nan)\r\n    #  \xe5\xa4\x84\xe7\x90\x86\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if miss == 'del':  # \xe5\x88\xa0\xe9\x99\xa4\xe6\x8e\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n        miss_data = data.dropna(how='any')\r\n    else:\r\n        miss_data = data.fillna(method='ffill')\r\n    return miss_data\r\n\r\n#  \xe5\xb0\x86\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\xad\x97\xe6\xae\xb5\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\xef\xbc\x8c\r\ndef Digitcode(traindata, predixdata):\r\n    #  \xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n    for ikey in traindata:\r\n        if traindata[ikey].dtype == 'object':  # \xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n            numb = sorted(list(set(list(traindata[ikey].values))))\r\n            exdict = {ji: numb.index(ji) for ji in numb}\r\n            if ikey == 'Money':  # \xe5\x9b\xa0\xe4\xb8\xbasklearn\xe6\x94\xaf\xe6\x8c\x81\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\xb1\xbb\xe5\x88\xab\r\n                predixdata[ikey] = ['%s' % gfi[:-1] for gfi in predixdata[ikey]]  # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe4\xb8\xadMoney\xe7\x9a\x84\xe5\x80\xbc\xe5\xa4\x9a\xe4\xb8\xaa\xe7\x82\xb9\r\n            else:\r\n                predixdata[ikey] = [exdict[fi] for fi in predixdata[ikey]]\r\n                traindata[ikey] = [exdict[fi] for fi in traindata[ikey]]\r\n    return traindata, predixdata.values\r\n\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nread_train = ReadHandle(train_path)\r\nread_pre = ReadHandle(pre_path)\r\n\r\n# \xe7\xbb\x8f\xe8\xbf\x87\xe5\xa4\x84\xe7\x90\x86\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nhan_train, predict_data = Digitcode(read_train, read_pre)\r\n\r\n\r\n#  \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8cK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x8c\xe6\xa0\xb9\xe6\x8d\xaeF1\xe5\xba\xa6\xe9\x87\x8f\xe7\xa1\xae\xe5\xae\x9a\xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\r\n#  \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xae\xa1\xe7\xae\x97\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe4\xbb\xa5\xe5\x8f\x8a\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe3\x80\x81\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\xef\xbc\x8cF1\xe5\xba\xa6\xe9\x87\x8f\r\n\r\ndef kfold(trdata, k=10):\r\n    vadata = trdata.values\r\n    legth = len(vadata)\r\n    datadict = {}\r\n    signnuber = np.arange(legth)\r\n    for hh in range(k):\r\n        datadict[hh] = {}\r\n        np.random.shuffle(vadata)\r\n        yanzhneg = np.random.choice(signnuber, int(legth / k), replace=False)\r\n        oneflod_yan = vadata[yanzhneg]\r\n        oneflod_xun = vadata[[hdd for hdd in signnuber if hdd not in yanzhneg]]\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\r\n        datadict[hh]['train'] = oneflod_xun\r\n        datadict[hh]['test'] = oneflod_yan\r\n    return datadict\r\n\r\n#  \xe5\xad\x98\xe5\x82\xa8K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\r\ndt_data = kfold(han_train)"""
Boosting/GBDT/pm25_GBDT_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\PRSA_data_2010.1.1-2014.12.31.csv')\r\n\r\n\r\n'''\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86'''\r\n#  \xe5\x9b\xa0\xe4\xb8\xbaPm2.5\xe6\x98\xaf\xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9b\xb4\xe6\x8e\xa5\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xb8\x80\xe6\x9d\xa1\xe8\xae\xb0\xe5\xbd\x95\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe7\x9b\xae\xe6\xa0\x87\xe5\x80\xbc\xe4\xb8\xba\xe7\xa9\xba\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0, \xe5\x85\xb6\xe4\xbb\x96\xe5\x88\x97\xe4\xb8\xba\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe5\x88\x99\xe8\x87\xaa\xe5\x8a\xa8\xe5\xa1\xab\xe5\x85\x85\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0,\xe5\xb9\xb6\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\x8f\x98\xe9\x87\x8f\xe6\x94\xbe\xe7\xbd\xae\xe5\x9c\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\x88\x97\r\ndef DeleteTargetNan(exdata, targetstr):\r\n    #  \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if exdata[targetstr].isnull().any():\r\n        #  \xe9\xa6\x96\xe5\x85\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe6\x95\xb0\r\n        loc = exdata[targetstr][data[targetstr].isnull().values == True].index.tolist()\r\n        #  \xe7\x84\xb6\xe5\x90\x8e\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xba\x9b\xe8\xa1\x8c\r\n        exdata = exdata.drop(loc)\r\n    # \xe5\x87\xa1\xe6\x98\xaf\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\x86\x8d\xe4\xb8\x80\xe8\xb5\xb7\xe5\x88\xa9\xe7\x94\xa8\xe6\xad\xa4\xe8\xa1\x8c\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\xe5\xa1\xab\xe5\x85\x85\r\n    exdata = exdata.fillna(exdata.mean())\r\n    # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\x87\xb3\xe6\x94\xbe\xe5\x9c\xa8\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe4\xb8\x80\xe5\x88\x97\r\n    targetnum = exdata[targetstr].copy()\r\n    del exdata[targetstr]\r\n    exdata[targetstr] = targetnum\r\n    return exdata\r\n\r\n\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\r\ndef Shanchu(exdata, aiduan=['No']):\r\n    for ai in aiduan:\r\n        if ai in exdata.keys():\r\n            del exdata[ai]\r\n    return exdata\r\n\r\n\r\n# \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe7\x9a\x84\xe5\xb1\x9e\xe6\x80\xa7\xe5\x80\xbc\xe4\xb8\xba\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\x9a\x84\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\xe5\xaf\xb9\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe8\x80\x8c\xe8\xa8\x80\xe4\xb8\x8d\xe9\x82\xa3\xe4\xb9\x88\xe9\x87\x8d\xe8\xa6\x81\r\ndef Digit(eadata):\r\n    # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\r\n    for jj in eadata:\r\n        try:\r\n            eadata[jj].values[0] + 1\r\n        except TypeError:\r\n            # \xe9\x9c\x80\xe8\xa6\x81\xe8\xbd\xac\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n            numlist = list(set(list(eadata[jj].values)))\r\n            zhuan = [numlist.index(jj) for jj in eadata[jj].values]\r\n            eadata[jj] = zhuan\r\n    return eadata\r\n\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n\r\nfirst = DeleteTargetNan(data, 'pm2.5')\r\ntwo = Shanchu(first)\r\nthird = Digit(two)\r\n\r\n# \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x8c\x89\xe7\x85\xa78:2\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe3\x80\x82\xe5\x85\xb6\xe4\xb8\xad\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x86\x8d\xe5\x88\x86\xe4\xb8\xbaK\xe4\xbb\xbd\xef\xbc\x8c\xe8\xbf\x9b\xe8\xa1\x8cK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\r\n\r\ndef fenge(exdata, k=10, per=[0.8, 0.2]):\r\n    # \xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n    lent = len(exdata)\r\n    alist = np.arange(lent)\r\n    np.random.shuffle(alist)\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\r\n    xunlian_sign = int(lent * per[0])\r\n\r\n    xunlian = np.random.choice(alist, xunlian_sign, replace=False)\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yuce = np.array([i for i in alist if i not in xunlian])\r\n\r\n    # \xe5\x86\x8d\xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe4\xb8\xbaK\xe6\x8a\x98\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xad\x97\xe5\x85\xb8\r\n    save_dict = {}\r\n    for jj in range(k):\r\n        save_dict[jj] = {}\r\n        length = len(xunlian)\r\n        # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\r\n        yuzhi = int(length / k)\r\n        yan = np.random.choice(xunlian, yuzhi, replace=False)\r\n        tt = np.array([i for i in xunlian if i not in yan])\r\n        save_dict[jj]['train'] = exdata[tt]\r\n        save_dict[jj]['test'] = exdata[yan]\r\n\r\n    return save_dict, exdata[yuce]\r\n\r\ndeeer = fenge(third.values)\r\n\r\n# K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\ndt_data = deeer[0]\r\n# \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\npredict_data = deeer[1]"""
Boosting/LightGBM/LightGBM_Classify_adult.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport adult_LightGBM_Data as data\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b\r\nimport lightgbm as lgbm\r\nimport numpy as np\r\n\r\n# \xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable as PT\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8bF1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xaeK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x94\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\xbb\x99\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n\r\n# \xe4\xb8\xbb\xe8\xa6\x81\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe5\xb0\xb1\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe4\xb8\xad\xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\x92\x8c\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0,\xe5\x85\xb6\xe4\xbb\x96\xe5\x8f\x82\xe6\x95\xb0\xe5\x9d\x87\xe4\xbd\xbf\xe7\x94\xa8\xe9\xbb\x98\xe8\xae\xa4\xe5\x80\xbc\r\n\r\n# \xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe6\xa0\x91\xe7\x9a\x84\xe5\xb1\x82\xe6\x95\xb0\r\ncengs = [4, 5, 6]\r\n\r\n# \xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\nmodels = [235, 250, 265]\r\n\r\n# \xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Tom(reallist, prelist):\r\n    \'\'\'\r\n    :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist:  \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: \xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\xba\xe6\x89\x80\xe6\x9c\x89\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe5\x85\xb8\r\n    \'\'\'\r\n    coundict = {}\r\n    for jj in list(set(reallist)):\r\n        coundict[jj] = {}\r\n        for hh in list(set(reallist)):\r\n            coundict[jj][hh] = len([i for i, j in zip(reallist, prelist) if i == jj and j == hh])\r\n    return coundict\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef ConfuseMatrix(reallist, prelist):\r\n    \'\'\'\r\n    :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: \xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n    \'\'\'\r\n    zidian = Tom(reallist, prelist)\r\n    lieming = sorted(zidian.keys())\r\n    table = PT([\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\'] + [\'\xe9\xa2\x84\xe6\xb5\x8b%s\'% d for d in lieming])\r\n    for jj in lieming:\r\n        table.add_row([\'\xe5\xae\x9e\xe9\x99\x85%s\' % jj] + [zidian[jj][kk] for kk in lieming])\r\n    return table\r\n\r\n#  \xe8\xae\xa1\xe7\xae\x97F1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef fmse(realist, prelist):  # \xe5\xaf\xb9\xe4\xba\x8e\xe5\xa4\x9a\xe7\xb1\xbb\xe5\x88\xab\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe9\x83\xbd\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    \'\'\'\r\n    :param realist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: F1\xe5\xba\xa6\xe9\x87\x8f\r\n    \'\'\'\r\n    condict = Tom(realist, prelist)\r\n    zongshu = 0\r\n    zhengque = 0\r\n    zhao_cu = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    for cu in condict:\r\n        zq = 0\r\n        zs = 0\r\n        for hh in condict[cu]:\r\n            geshu = condict[cu][hh]\r\n            if cu == hh:\r\n                zhengque += geshu\r\n                zq = geshu\r\n            zongshu += geshu\r\n            zs += geshu\r\n        zhao_cu.append(zq / zs)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\r\n    jingque = zhengque / zongshu\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe5\x88\xab\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    zhaohui = np.mean(np.array(zhao_cu))\r\n    # f1\xe5\xba\xa6\xe9\x87\x8f\r\n    f_degree = 2 * jingque * zhaohui / (jingque + zhaohui)\r\n    return f_degree, jingque, zhaohui\r\n\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Train(data, modelcount, censhu, yanzhgdata):\r\n    model = lgbm.LGBMClassifier(boosting_type=\'gbdt\', objective=\'binary\', num_leaves=50,\r\n                                learning_rate=0.1, n_estimators=modelcount, max_depth=censhu,\r\n                                bagging_fraction=0.9, feature_fraction=0.9, reg_lambda=0.2)\r\n\r\n    model.fit(data[:, :-1], data[:, -1])\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_out = model.predict(data[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97f1\xe5\xba\xa6\xe9\x87\x8f\r\n    train_mse = fmse(data[:, -1], train_out)[0]\r\n\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    add_yan = model.predict(yanzhgdata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97f1\xe5\xba\xa6\xe9\x87\x8f\r\n    add_mse = fmse(yanzhgdata[:, -1], add_yan)[0]\r\n    print(train_mse, add_mse)\r\n    return train_mse, add_mse\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Zuhe(datadict, tre=models, ce=cengs):\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    savedict = {}\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    sacelist = {}\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    adile = {}\r\n    for t in tre:\r\n        for j in ce:\r\n            print(t, j)\r\n            # \xe5\x8f\xaa\xe6\x98\xaf\xe5\xad\x98\xe5\x82\xa8\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\n            sumlist = []\r\n            # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\n            alli = []\r\n            # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe6\x8a\x98\xe6\x95\xb0\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe6\x8c\x89\xe5\xba\x8f\xe5\xbc\x80\xe5\xa7\x8b\r\n            ordelist = sorted(list(datadict.keys()))\r\n            for jj in ordelist:\r\n                xun, ya = Train(datadict[jj][\'train\'], t, j, datadict[jj][\'test\'])\r\n                # \xe5\x8f\xaa\xe9\x80\x89\xe6\x8b\xa9\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe8\xbe\x83\xe5\xa4\xa7\xe7\x9a\x84\r\n                alli.append(ya)\r\n                sumlist.append(ya)\r\n            sacelist[\'%s-%s\' % (t, j)] = sumlist\r\n            savedict[\'%s-%s\' % (t, j)] = np.mean(np.array(sumlist))\r\n            adile[\'%s-%s\' % (t, j)] = alli\r\n\r\n    # \xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\r\n    zuixao = sorted(savedict.items(), key=lambda fu: fu[1], reverse=True)[0][0]\r\n    # \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe9\x80\x89\xe5\x87\xba\xe6\xad\xa4\xe6\x96\xb9\xe6\xb3\x95\xe4\xb8\xad\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe4\xb9\x8b\xe5\x92\x8c\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\r\n    xiao = adile[zuixao].index(max(adile[zuixao]))\r\n    return zuixao, xiao, sacelist\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe6\x9b\xb2\xe7\xba\xbf\r\ndef duibi(exdict, you):\r\n    plt.figure(figsize=(11, 7))\r\n    for ii in exdict:\r\n        plt.plot(list(range(len(exdict[ii]))), exdict[ii], \\\r\n                 label=\'%s,%d\xe6\x8a\x98F1\xe5\x9d\x87\xe5\x80\xbc:%.4f\' % (ii, len(exdict[ii]), np.mean(np.array(exdict[ii]))), lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88F1\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf[\xe6\x9c\x80\xe4\xbc\x98\xef\xbc\x9a%s]\' % you)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\lightgbm_adult.jpg\')\r\n    return \'\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\ndef recspre(estrs, predata, datadict, zhe):\r\n\r\n    mo, ze = estrs.split(\'-\')\r\n    model = lgbm.LGBMClassifier(boosting_type=\'gbdt\', objective=\'binary\', num_leaves=50,\r\n                                learning_rate=0.1, n_estimators=int(mo), max_depth=int(ze),\r\n                                bagging_fraction=0.9, feature_fraction=0.9, reg_lambda=0.2)\r\n\r\n    model.fit(datadict[zhe][\'train\'][:, :-1], datadict[zhe][\'train\'][:, -1])\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yucede = model.predict(predata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n\r\n    print(ConfuseMatrix(predata[:, -1], yucede))\r\n\r\n    return fmse(predata[:, -1], yucede)\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    zijian, zhehsu, xulie = Zuhe(data.dt_data)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x96\xb9\xe6\xb3\x95\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\n    duibi(xulie, zijian)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84f1\xe5\xba\xa6\xe9\x87\x8f\xef\xbc\x8c\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    f1, jing, zhao = recspre(zijian, data.predict_data, data.dt_data, zhehsu)\r\n    print(\'F1\xe5\xba\xa6\xe9\x87\x8f\xef\xbc\x9a{}, \xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xef\xbc\x9a{}, \xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\xef\xbc\x9a{}\'.format(f1, jing, zhao))'"
Boosting/LightGBM/LightGBM_Regression_pm25.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport pm25_LightGBM_Data as data\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b\r\nimport lightgbm as lgbm\r\nfrom sklearn.metrics import mean_squared_error as mse\r\nimport numpy as np\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8bMSE\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xaeK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x94\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\xbb\x99\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n\r\n\r\n# \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\xb1\x82\xe6\x95\xb0\r\ncengs = [60, 90, 100]\r\n# \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\nmodels = [220, 300, 380]\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Train(data, modelcount, censhu, yanzhgdata):\r\n    model = lgbm.LGBMRegressor(boosting_type=\'gbdt\', objective=\'regression\', num_leaves=1200,\r\n                                learning_rate=0.17, n_estimators=modelcount, max_depth=censhu,\r\n                                metric=\'rmse\', bagging_fraction=0.8, feature_fraction=0.8, reg_lambda=0.9)\r\n\r\n    model.fit(data[:, :-1], data[:, -1])\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_out = model.predict(data[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    train_mse = mse(data[:, -1], train_out)\r\n\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    add_yan = model.predict(yanzhgdata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    add_mse = mse(yanzhgdata[:, -1], add_yan)\r\n    print(train_mse, add_mse)\r\n    return train_mse, add_mse\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Zuhe(datadict, tre=models, tezhen=cengs):\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    savedict = {}\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    sacelist = {}\r\n    for t in tre:\r\n        for te in tezhen:\r\n            print(t, te)\r\n            sumlist = []\r\n            # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe6\x8a\x98\xe6\x95\xb0\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe6\x8c\x89\xe5\xba\x8f\xe5\xbc\x80\xe5\xa7\x8b\r\n            ordelist = sorted(list(datadict.keys()))\r\n            for jj in ordelist:\r\n                xun, ya = Train(datadict[jj][\'train\'], t, te, datadict[jj][\'test\'])\r\n                # \xe6\xa0\xb9\xe6\x8d\xae\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe7\xa1\xae\xe5\xae\x9a\xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88\r\n                sumlist.append(ya)\r\n            sacelist[\'%s-%s\' % (t, te)] = sumlist\r\n            savedict[\'%s-%s\' % (t, te)] = np.mean(np.array(sumlist))\r\n\r\n    # \xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\r\n    zuixao = sorted(savedict.items(), key=lambda fu: fu[1])[0][0]\r\n    # \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe9\x80\x89\xe5\x87\xba\xe6\xad\xa4\xe6\x96\xb9\xe6\xb3\x95\xe4\xb8\xad\xe5\x92\x8c\xe5\x80\xbc\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe6\x8a\x98\xe6\x95\xb0\r\n    xiao = sacelist[zuixao].index(min(sacelist[zuixao]))\r\n    return zuixao, xiao, sacelist\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe6\x9b\xb2\xe7\xba\xbf\r\ndef duibi(exdict, you):\r\n    plt.figure(figsize=(11, 7))\r\n    for ii in exdict:\r\n        plt.plot(list(range(len(exdict[ii]))), exdict[ii], \\\r\n                 label=\'%s,%d\xe6\x8a\x98MSE\xe5\x9d\x87\xe5\x80\xbc:%.3f\' % (ii, len(exdict[ii]), np.mean(np.array(exdict[ii]))), lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88MSE\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf[\xe6\x9c\x80\xe4\xbc\x98\xef\xbc\x9a%s]\' % you)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\lightgbm_pm25.jpg\')\r\n    return \'\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\ndef recspre(exstr, predata, datadict, zhe, count=100):\r\n    tree, te = exstr.split(\'-\')\r\n    model = lgbm.LGBMRegressor(objective=\'regression\', learning_rate=0.15, num_leaves=1200,\r\n                               n_estimators=int(tree), max_depth=int(te),\r\n                               metric=\'rmse\', bagging_fraction=0.8, feature_fraction=0.8, reg_lambda=0.9)\r\n    model.fit(datadict[zhe][\'train\'][:, :-1], datadict[zhe][\'train\'][:, -1])\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yucede = model.predict(predata[:, :-1])\r\n    # \xe4\xb8\xba\xe4\xba\x86\xe4\xbe\xbf\xe4\xba\x8e\xe5\xb1\x95\xe7\xa4\xba\xef\xbc\x8c\xe9\x80\x89100\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xb1\x95\xe7\xa4\xba\r\n    zongleng = np.arange(len(yucede))\r\n    randomnum = np.random.choice(zongleng, count, replace=False)\r\n\r\n    yucede_se = list(np.array(yucede)[randomnum])\r\n\r\n    yuce_re = list(np.array(predata[:, -1])[randomnum])\r\n\r\n    # \xe5\xaf\xb9\xe6\xaf\x94\r\n    plt.figure(figsize=(17, 9))\r\n    plt.subplot(2, 1, 1)\r\n    plt.plot(list(range(len(yucede_se))), yucede_se, \'r--\', label=\'\xe9\xa2\x84\xe6\xb5\x8b\', lw=2)\r\n    plt.scatter(list(range(len(yuce_re))), yuce_re, c=\'b\', marker=\'.\', label=\'\xe7\x9c\x9f\xe5\xae\x9e\', lw=2)\r\n    plt.xlim(-1, count + 1)\r\n    plt.legend()\r\n    plt.title(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\xaf\xb9\xe6\xaf\x94[\xe6\x9c\x80\xe5\xa4\xa7\xe6\xa0\x91\xe6\x95\xb0%d]\' % int(tree))\r\n\r\n    plt.subplot(2, 1, 2)\r\n    plt.plot(list(range(len(yucede_se))), np.array(yuce_re) - np.array(yucede_se), \'k--\', marker=\'s\', label=\'\xe7\x9c\x9f\xe5\xae\x9e-\xe9\xa2\x84\xe6\xb5\x8b\', lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe7\x9b\xb8\xe5\xaf\xb9\xe8\xaf\xaf\xe5\xb7\xae\')\r\n\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\duibi_lightgbm.jpg\')\r\n    return \'\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9c\x9f\xe5\xae\x9e\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    zijian, zhehsu, xulie = Zuhe(data.dt_data)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\xe5\x83\x8f\r\n    duibi(xulie, zijian)\r\n    recspre(zijian, data.predict_data, data.dt_data, zhehsu)'"
Boosting/LightGBM/adult_LightGBM_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n#  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\ntrain_path = 'C:/Users/GWT9\\Desktop/Adult_Train.csv'\r\n\r\n#  \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\npre_path = 'C:/Users/GWT9\\Desktop/Adult_Test.csv'\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe5\xb9\xb6\xe4\xb8\x94\xe5\xa4\x84\xe7\x90\x86\xe7\xa1\xae\xe7\xbc\xba\xe5\xa4\xb1\xe6\x95\xb0\xe6\x8d\xae\r\ndef ReadHandle(filepath, miss='fill'):  # \xe5\xae\x9a\xe4\xb9\x89\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    data = pd.read_csv(r'%s' % filepath)\r\n    data = data.replace('?', np.nan)\r\n    #  \xe5\xa4\x84\xe7\x90\x86\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if miss == 'del':  # \xe5\x88\xa0\xe9\x99\xa4\xe6\x8e\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n        miss_data = data.dropna(how='any')\r\n    else:\r\n        miss_data = data.fillna(method='ffill')\r\n    return miss_data\r\n\r\n#  \xe5\xb0\x86\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\xad\x97\xe6\xae\xb5\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\xef\xbc\x8c\r\ndef Digitcode(traindata, predixdata):\r\n    #  \xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n    for ikey in traindata:\r\n        if traindata[ikey].dtype == 'object':  # \xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n            numb = sorted(list(set(list(traindata[ikey].values))))\r\n            exdict = {ji: numb.index(ji) for ji in numb}\r\n            if ikey == 'Money':\r\n                predixdata[ikey] = ['%s' % gfi[:-1] for gfi in predixdata[ikey]]  # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe4\xb8\xadMoney\xe7\x9a\x84\xe5\x80\xbc\xe5\xa4\x9a\xe4\xb8\xaa\xe7\x82\xb9\r\n            else:\r\n                predixdata[ikey] = [exdict[fi] for fi in predixdata[ikey]]\r\n                traindata[ikey] = [exdict[fi] for fi in traindata[ikey]]\r\n    return traindata, predixdata.values\r\n\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nread_train = ReadHandle(train_path)\r\nread_pre = ReadHandle(pre_path)\r\n\r\n# \xe7\xbb\x8f\xe8\xbf\x87\xe5\xa4\x84\xe7\x90\x86\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nhan_train, predict_data = Digitcode(read_train, read_pre)\r\n\r\n\r\n#  \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8cK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x8c\xe6\xa0\xb9\xe6\x8d\xaeF1\xe5\xba\xa6\xe9\x87\x8f\xe7\xa1\xae\xe5\xae\x9a\xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\r\n#  \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xae\xa1\xe7\xae\x97\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe4\xbb\xa5\xe5\x8f\x8a\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe3\x80\x81\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\xef\xbc\x8cF1\xe5\xba\xa6\xe9\x87\x8f\\\r\n#  \xe5\x9b\xa0\xe4\xb8\xba\xe9\x9c\x80\xe8\xa6\x81\xe9\x80\x89\xe6\x8b\xa9\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe4\xb8\xba\xe4\xba\x86\xe4\xbe\xbf\xe4\xba\x8e\xe5\x88\xa4\xe6\x96\xad\xef\xbc\x8c\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9c\x80\xe8\xa6\x81\xe6\x98\xaf\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\r\n\r\ndef kfold(trdata, k=10):\r\n    vadata = trdata.values\r\n    legth = len(vadata)\r\n    datadict = {}\r\n    signnuber = np.arange(legth)\r\n    for hh in range(k):\r\n        datadict[hh] = {}\r\n        np.random.seed(1000)\r\n        np.random.shuffle(vadata)\r\n        np.random.seed(hh)\r\n        yanzhneg = np.random.choice(signnuber, int(legth / k), replace=False)\r\n        oneflod_yan = vadata[yanzhneg]\r\n        oneflod_xun = vadata[[hdd for hdd in signnuber if hdd not in yanzhneg]]\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\r\n        datadict[hh]['train'] = oneflod_xun\r\n        datadict[hh]['test'] = oneflod_yan\r\n    return datadict\r\n\r\n#  \xe5\xad\x98\xe5\x82\xa8K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\r\ndt_data = kfold(han_train)"""
Boosting/LightGBM/pm25_LightGBM_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\PRSA_data_2010.1.1-2014.12.31.csv')\r\n\r\n\r\n'''\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86'''\r\n#  \xe5\x9b\xa0\xe4\xb8\xbaPm2.5\xe6\x98\xaf\xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9b\xb4\xe6\x8e\xa5\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xb8\x80\xe6\x9d\xa1\xe8\xae\xb0\xe5\xbd\x95\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe7\x9b\xae\xe6\xa0\x87\xe5\x80\xbc\xe4\xb8\xba\xe7\xa9\xba\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0, \xe5\x85\xb6\xe4\xbb\x96\xe5\x88\x97\xe4\xb8\xba\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe5\x88\x99\xe8\x87\xaa\xe5\x8a\xa8\xe5\xa1\xab\xe5\x85\x85\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0,\xe5\xb9\xb6\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\x8f\x98\xe9\x87\x8f\xe6\x94\xbe\xe7\xbd\xae\xe5\x9c\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\x88\x97\r\ndef DeleteTargetNan(exdata, targetstr):\r\n    #  \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if exdata[targetstr].isnull().any():\r\n        #  \xe9\xa6\x96\xe5\x85\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe6\x95\xb0\r\n        loc = exdata[targetstr][data[targetstr].isnull().values == True].index.tolist()\r\n        #  \xe7\x84\xb6\xe5\x90\x8e\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xba\x9b\xe8\xa1\x8c\r\n        exdata = exdata.drop(loc)\r\n    # \xe5\x87\xa1\xe6\x98\xaf\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\x86\x8d\xe4\xb8\x80\xe8\xb5\xb7\xe5\x88\xa9\xe7\x94\xa8\xe6\xad\xa4\xe8\xa1\x8c\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\xe5\xa1\xab\xe5\x85\x85\r\n    exdata = exdata.fillna(exdata.mean())\r\n    # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\x87\xb3\xe6\x94\xbe\xe5\x9c\xa8\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe4\xb8\x80\xe5\x88\x97\r\n    targetnum = exdata[targetstr].copy()\r\n    del exdata[targetstr]\r\n    exdata[targetstr] = targetnum\r\n    return exdata\r\n\r\n\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\r\ndef Shanchu(exdata, aiduan=['No']):\r\n    for ai in aiduan:\r\n        if ai in exdata.keys():\r\n            del exdata[ai]\r\n    return exdata\r\n\r\n\r\n# \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe7\x9a\x84\xe5\xb1\x9e\xe6\x80\xa7\xe5\x80\xbc\xe4\xb8\xba\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\x9a\x84\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\xe5\xaf\xb9\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe8\x80\x8c\xe8\xa8\x80\xe4\xb8\x8d\xe9\x82\xa3\xe4\xb9\x88\xe9\x87\x8d\xe8\xa6\x81\r\ndef Digit(eadata):\r\n    # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\r\n    for jj in eadata:\r\n        try:\r\n            eadata[jj].values[0] + 1\r\n        except TypeError:\r\n            # \xe9\x9c\x80\xe8\xa6\x81\xe8\xbd\xac\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n            numlist = list(set(list(eadata[jj].values)))\r\n            zhuan = [numlist.index(jj) for jj in eadata[jj].values]\r\n            eadata[jj] = zhuan\r\n    return eadata\r\n\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n\r\nfirst = DeleteTargetNan(data, 'pm2.5')\r\ntwo = Shanchu(first)\r\nthird = Digit(two)\r\n\r\n# \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x8c\x89\xe7\x85\xa78:2\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe3\x80\x82\xe5\x85\xb6\xe4\xb8\xad\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x86\x8d\xe5\x88\x86\xe4\xb8\xbaK\xe4\xbb\xbd\xef\xbc\x8c\xe8\xbf\x9b\xe8\xa1\x8cK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\r\n# \xe4\xb8\xba\xe4\xba\x86\xe4\xbe\xbf\xe4\xba\x8e\xe7\xa1\xae\xe5\xae\x9a\xe6\x9c\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe6\x8a\x8a\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x9b\xba\xe5\xae\x9a\xe4\xb8\x8b\xe6\x9d\xa5\xef\xbc\x8c\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xef\xbc\x8c\xe5\x93\xaa\xe4\xba\x9b\xe4\xbd\x9c\xe4\xb8\xba\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x98\xaf\xe5\x9b\xba\xe5\xae\x9a\xe7\x9a\x84\r\n\r\n# \xe6\xaf\x8f\xe4\xb8\x80\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\xad\xef\xbc\x8c\xe8\xae\xad\xe7\xbb\x83\xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb9\x9f\xe6\x98\xaf\xe7\xa1\xae\xe5\xae\x9a\xe7\x9a\x84\r\n\r\ndef fenge(exdata, k=10, per=[0.8, 0.2]):\r\n    # \xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n    lent = len(exdata)\r\n    alist = np.arange(lent)\r\n    np.random.seed(1900)\r\n    np.random.shuffle(alist)\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\r\n    xunlian_sign = int(lent * per[0])\r\n    np.random.seed(623)\r\n    xunlian = np.random.choice(alist, xunlian_sign, replace=False)\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yuce = np.array([i for i in alist if i not in xunlian])\r\n\r\n    # \xe5\x86\x8d\xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe4\xb8\xbaK\xe6\x8a\x98\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xad\x97\xe5\x85\xb8\r\n    save_dict = {}\r\n    for jj in range(k):\r\n        save_dict[jj] = {}\r\n        length = len(xunlian)\r\n        # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\r\n        yuzhi = int(length / k)\r\n        np.random.seed(jj)\r\n        yan = np.random.choice(xunlian, yuzhi, replace=False)\r\n        tt = np.array([i for i in xunlian if i not in yan])\r\n        save_dict[jj]['train'] = exdata[tt]\r\n        save_dict[jj]['test'] = exdata[yan]\r\n\r\n    return save_dict, exdata[yuce]\r\n\r\ndeeer = fenge(third.values)\r\n\r\n# K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\ndt_data = deeer[0]\r\n# \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\npredict_data = deeer[1]"""
Boosting/XGBoost/XGBoost_Classify_adult.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport adult_XGBoost_Data as data\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b\r\nimport xgboost as xgb\r\nimport numpy as np\r\n\r\n# \xe6\xa0\xbc\xe5\xbc\x8f\xe5\x8c\x96\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\nfrom prettytable import PrettyTable as PT\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8bF1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xaeK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x94\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\xbb\x99\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n\r\n# \xe4\xb8\xbb\xe8\xa6\x81\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe5\xb0\xb1\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe6\xa3\xae\xe6\x9e\x97\xe4\xb8\xad\xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\x92\x8c\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0,\xe5\x85\xb6\xe4\xbb\x96\xe5\x8f\x82\xe6\x95\xb0\xe5\x9d\x87\xe4\xbd\xbf\xe7\x94\xa8\xe9\xbb\x98\xe8\xae\xa4\xe5\x80\xbc\r\n\r\n# \xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe4\xb8\xad\xe6\xa0\x91\xe7\x9a\x84\xe5\xb1\x82\xe6\x95\xb0\r\ncengs = [4, 5, 6]\r\n\r\n# \xe5\xbc\xb1\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\nmodels = [280, 320, 340]\r\n\r\n# \xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Tom(reallist, prelist):\r\n    \'\'\'\r\n    :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist:  \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: \xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe9\xa2\x84\xe6\xb5\x8b\xe4\xb8\xba\xe6\x89\x80\xe6\x9c\x89\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe5\xad\x97\xe5\x85\xb8\r\n    \'\'\'\r\n    coundict = {}\r\n    for jj in list(set(reallist)):\r\n        coundict[jj] = {}\r\n        for hh in list(set(reallist)):\r\n            coundict[jj][hh] = len([i for i, j in zip(reallist, prelist) if i == jj and j == hh])\r\n    return coundict\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef ConfuseMatrix(reallist, prelist):\r\n    \'\'\'\r\n    :param reallist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: \xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n    \'\'\'\r\n    zidian = Tom(reallist, prelist)\r\n    lieming = sorted(zidian.keys())\r\n    table = PT([\'\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\'] + [\'\xe9\xa2\x84\xe6\xb5\x8b%s\'% d for d in lieming])\r\n    for jj in lieming:\r\n        table.add_row([\'\xe5\xae\x9e\xe9\x99\x85%s\' % jj] + [zidian[jj][kk] for kk in lieming])\r\n    return table\r\n\r\n#  \xe8\xae\xa1\xe7\xae\x97F1\xe5\xba\xa6\xe9\x87\x8f\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef fmse(realist, prelist):  # \xe5\xaf\xb9\xe4\xba\x8e\xe5\xa4\x9a\xe7\xb1\xbb\xe5\x88\xab\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe9\x83\xbd\xe8\xa6\x81\xe8\xae\xa1\xe7\xae\x97\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    \'\'\'\r\n    :param realist: \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :param prelist: \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe5\x88\x97\xe8\xa1\xa8\r\n    :return: F1\xe5\xba\xa6\xe9\x87\x8f\r\n    \'\'\'\r\n    condict = Tom(realist, prelist)\r\n    zongshu = 0\r\n    zhengque = 0\r\n    zhao_cu = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    for cu in condict:\r\n        zq = 0\r\n        zs = 0\r\n        for hh in condict[cu]:\r\n            geshu = condict[cu][hh]\r\n            if cu == hh:\r\n                zhengque += geshu\r\n                zq = geshu\r\n            zongshu += geshu\r\n            zs += geshu\r\n        zhao_cu.append(zq / zs)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\r\n    jingque = zhengque / zongshu\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe5\x88\xab\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    zhaohui = np.mean(np.array(zhao_cu))\r\n    # f1\xe5\xba\xa6\xe9\x87\x8f\r\n    f_degree = 2 * jingque * zhaohui / (jingque + zhaohui)\r\n    return f_degree, jingque, zhaohui\r\n\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Train(data, modelcount, censhu, yanzhgdata):\r\n    model = xgb.XGBClassifier(max_depth=censhu, learning_rate=0.1, n_estimators=modelcount,\r\n                              silent=True, objective=\'binary:logistic\', booster=\'gbtree\')\r\n\r\n    model.fit(data[:, :-1], data[:, -1])\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_out = model.predict(data[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    train_mse = fmse(data[:, -1], train_out)[0]\r\n\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    add_yan = model.predict(yanzhgdata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97f1\xe5\xba\xa6\xe9\x87\x8f\r\n    add_mse = fmse(yanzhgdata[:, -1], add_yan)[0]\r\n    print(train_mse, add_mse)\r\n    return train_mse, add_mse\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Zuhe(datadict, tre=models, ce=cengs):\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    savedict = {}\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    sacelist = {}\r\n    for t in tre:\r\n        for j in ce:\r\n            print(t, j)\r\n            sumlist = []\r\n            # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe6\x8a\x98\xe6\x95\xb0\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe6\x8c\x89\xe5\xba\x8f\xe5\xbc\x80\xe5\xa7\x8b\r\n            ordelist = sorted(list(datadict.keys()))\r\n            for jj in ordelist:\r\n                xun, ya = Train(datadict[jj][\'train\'], t, j, datadict[jj][\'test\'])\r\n                # \xe5\x8f\xaa\xe9\x80\x89\xe6\x8b\xa9\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe8\xbe\x83\xe5\xa4\xa7\xe7\x9a\x84\r\n\r\n                sumlist.append(ya)\r\n            sacelist[\'%s-%s\' % (t, j)] = sumlist\r\n            savedict[\'%s-%s\' % (t, j)] = np.mean(np.array(sumlist))\r\n\r\n    # \xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\r\n    zuixao = sorted(savedict.items(), key=lambda fu: fu[1], reverse=True)[0][0]\r\n    # \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe9\x80\x89\xe5\x87\xba\xe6\xad\xa4\xe6\x96\xb9\xe6\xb3\x95\xe4\xb8\xad\xe5\x92\x8c\xe5\x80\xbc\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe6\x8a\x98\xe6\x95\xb0\r\n    xiao = sacelist[zuixao].index(max(sacelist[zuixao]))\r\n    return zuixao, xiao, sacelist\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe6\x9b\xb2\xe7\xba\xbf\r\ndef duibi(exdict, you):\r\n    plt.figure(figsize=(11, 7))\r\n    for ii in exdict:\r\n        plt.plot(list(range(len(exdict[ii]))), exdict[ii], \\\r\n                 label=\'%s,%d\xe6\x8a\x98F1\xe5\x9d\x87\xe5\x80\xbc:%.4f\' % (ii, len(exdict[ii]), np.mean(np.array(exdict[ii]))), lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88F1\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf[\xe6\x9c\x80\xe4\xbc\x98\xef\xbc\x9a%s]\' % you)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\xgboost_adult.jpg\')\r\n    return \'\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\ndef recspre(estrs, predata, datadict, zhe):\r\n\r\n    mo, ze = estrs.split(\'-\')\r\n    model = xgb.XGBClassifier(max_depth=int(ze), learning_rate=0.1, n_estimators=int(mo),\r\n                              silent=True, objective=\'binary:logistic\', booster=\'gbtree\')\r\n\r\n    model.fit(datadict[zhe][\'train\'][:, :-1], datadict[zhe][\'train\'][:, -1])\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yucede = model.predict(predata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\r\n\r\n    print(ConfuseMatrix(predata[:, -1], yucede))\r\n\r\n    return fmse(predata[:, -1], yucede)\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    zijian, zhehsu, xulie = Zuhe(data.dt_data)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x96\xb9\xe6\xb3\x95\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\n    duibi(xulie, zijian)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84f1\xe5\xba\xa6\xe9\x87\x8f\xef\xbc\x8c\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\r\n    f1, jing, zhao = recspre(zijian, data.predict_data, data.dt_data, zhehsu)\r\n    print(\'F1\xe5\xba\xa6\xe9\x87\x8f\xef\xbc\x9a{}, \xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xef\xbc\x9a{}, \xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\xef\xbc\x9a{}\'.format(f1, jing, zhao))'"
Boosting/XGBoost/XGBoost_Regression_pm25.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport pm25_XGBoost_Data as data\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b\r\nimport xgboost as xgb\r\n\r\nfrom sklearn.metrics import mean_squared_error as mse\r\nimport numpy as np\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe4\xb8\x8bMSE\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xaeK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x94\xe8\xbe\x83\xe5\xa5\xbd\xe7\x9a\x84\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe7\xbb\x99\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n\r\n\r\n# \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\nmodels = [130, 150, 180]\r\n# \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\xb1\x82\xe6\x95\xb0\r\ncengs = [40, 45, 50]\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\ndef Train(data, modelcount, censhu, yanzhgdata):\r\n    model = xgb.XGBRegressor(max_depth=censhu, learning_rate=0.1, n_estimators=modelcount, silent=True, objective=\'reg:gamma\')\r\n\r\n    model.fit(data[:, :-1], data[:, -1])\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    train_out = model.predict(data[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    train_mse = mse(data[:, -1], train_out)\r\n\r\n    # \xe7\xbb\x99\xe5\x87\xba\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n    add_yan = model.predict(yanzhgdata[:, :-1])\r\n    # \xe8\xae\xa1\xe7\xae\x97MSE\r\n    add_mse = mse(yanzhgdata[:, -1], add_yan)\r\n    print(train_mse, add_mse)\r\n    return train_mse, add_mse\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbb\x84\xe5\x90\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef Zuhe(datadict, tre=models, tezhen=cengs):\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    savedict = {}\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xba\x8f\xe5\x88\x97\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    sacelist = {}\r\n    for t in tre:\r\n        for te in tezhen:\r\n            print(t, te)\r\n            sumlist = []\r\n            # \xe5\x9b\xa0\xe4\xb8\xba\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe6\x8a\x98\xe6\x95\xb0\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xa6\x81\xe6\x8c\x89\xe5\xba\x8f\xe5\xbc\x80\xe5\xa7\x8b\r\n            ordelist = sorted(list(datadict.keys()))\r\n            for jj in ordelist:\r\n                xun, ya = Train(datadict[jj][\'train\'], t, te, datadict[jj][\'test\'])\r\n                # \xe6\xa0\xb9\xe6\x8d\xae\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe7\xa1\xae\xe5\xae\x9a\xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88\r\n                sumlist.append(ya)\r\n            sacelist[\'%s-%s\' % (t, te)] = sumlist\r\n            savedict[\'%s-%s\' % (t, te)] = np.mean(np.array(sumlist))\r\n\r\n    # \xe5\x9c\xa8\xe7\xbb\x93\xe6\x9e\x9c\xe5\xad\x97\xe5\x85\xb8\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\r\n    zuixao = sorted(savedict.items(), key=lambda fu: fu[1])[0][0]\r\n    # \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe9\x80\x89\xe5\x87\xba\xe6\xad\xa4\xe6\x96\xb9\xe6\xb3\x95\xe4\xb8\xad\xe5\x92\x8c\xe5\x80\xbc\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe6\x8a\x98\xe6\x95\xb0\r\n    xiao = sacelist[zuixao].index(min(sacelist[zuixao]))\r\n    return zuixao, xiao, sacelist\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\xe7\xbb\x98\xe5\x88\xb6\xe6\x9b\xb2\xe7\xba\xbf\r\ndef duibi(exdict, you):\r\n    plt.figure(figsize=(11, 7))\r\n    for ii in exdict:\r\n        plt.plot(list(range(len(exdict[ii]))), exdict[ii], \\\r\n                 label=\'%s,%d\xe6\x8a\x98MSE\xe5\x9d\x87\xe5\x80\xbc:%.3f\' % (ii, len(exdict[ii]), np.mean(np.array(exdict[ii]))), lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88MSE\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf[\xe6\x9c\x80\xe4\xbc\x98\xef\xbc\x9a%s]\' % you)\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\xgboost_pm25.jpg\')\r\n    return \'\xe4\xb8\x8d\xe5\x90\x8c\xe6\x96\xb9\xe6\xb3\x95\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe6\x9c\x89\xe5\x8f\x82\xe6\x95\xb0\xe7\xbb\x84\xe5\x90\x88\xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\ndef recspre(exstr, predata, datadict, zhe, count=100):\r\n    tree, te = exstr.split(\'-\')\r\n    model = xgb.XGBRegressor(max_depth=int(te), learning_rate=0.1, n_estimators=int(tree), silent=True, objective=\'reg:gamma\')\r\n    model.fit(datadict[zhe][\'train\'][:, :-1], datadict[zhe][\'train\'][:, -1])\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yucede = model.predict(predata[:, :-1])\r\n    # \xe4\xb8\xba\xe4\xba\x86\xe4\xbe\xbf\xe4\xba\x8e\xe5\xb1\x95\xe7\xa4\xba\xef\xbc\x8c\xe9\x80\x89100\xe6\x9d\xa1\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xb1\x95\xe7\xa4\xba\r\n    zongleng = np.arange(len(yucede))\r\n    randomnum = np.random.choice(zongleng, count, replace=False)\r\n\r\n    yucede_se = list(np.array(yucede)[randomnum])\r\n\r\n    yuce_re = list(np.array(predata[:, -1])[randomnum])\r\n\r\n    # \xe5\xaf\xb9\xe6\xaf\x94\r\n    plt.figure(figsize=(17, 9))\r\n    plt.subplot(2, 1, 1)\r\n    plt.plot(list(range(len(yucede_se))), yucede_se, \'r--\', label=\'\xe9\xa2\x84\xe6\xb5\x8b\', lw=2)\r\n    plt.scatter(list(range(len(yuce_re))), yuce_re, c=\'b\', marker=\'.\', label=\'\xe7\x9c\x9f\xe5\xae\x9e\', lw=2)\r\n    plt.xlim(-1, count + 1)\r\n    plt.legend()\r\n    plt.title(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\xaf\xb9\xe6\xaf\x94[\xe6\x9c\x80\xe5\xa4\xa7\xe6\xa0\x91\xe6\x95\xb0%d]\' % int(tree))\r\n\r\n    plt.subplot(2, 1, 2)\r\n    plt.plot(list(range(len(yucede_se))), np.array(yuce_re) - np.array(yucede_se), \'k--\', marker=\'s\', label=\'\xe7\x9c\x9f\xe5\xae\x9e-\xe9\xa2\x84\xe6\xb5\x8b\', lw=2)\r\n    plt.legend()\r\n    plt.title(\'\xe9\xa2\x84\xe6\xb5\x8b\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe7\x9b\xb8\xe5\xaf\xb9\xe8\xaf\xaf\xe5\xb7\xae\')\r\n\r\n    plt.savefig(r\'C:\\Users\\GWT9\\Desktop\\duibi_xgb.jpg\')\r\n    return \'\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9c\x9f\xe5\xae\x9e\xe5\xaf\xb9\xe6\xaf\x94\xe5\xae\x8c\xe6\xaf\x95\'\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    zijian, zhehsu, xulie = Zuhe(data.dt_data)\r\n\r\n    duibi(xulie, zijian)\r\n    recspre(zijian, data.predict_data, data.dt_data, zhehsu)'"
Boosting/XGBoost/adult_XGBoost_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n#  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\ntrain_path = 'C:/Users/GWT9\\Desktop/Adult_Train.csv'\r\n\r\n#  \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\npre_path = 'C:/Users/GWT9\\Desktop/Adult_Test.csv'\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe5\xb9\xb6\xe4\xb8\x94\xe5\xa4\x84\xe7\x90\x86\xe7\xa1\xae\xe7\xbc\xba\xe5\xa4\xb1\xe6\x95\xb0\xe6\x8d\xae\r\ndef ReadHandle(filepath, miss='fill'):  # \xe5\xae\x9a\xe4\xb9\x89\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    data = pd.read_csv(r'%s' % filepath)\r\n    data = data.replace('?', np.nan)\r\n    #  \xe5\xa4\x84\xe7\x90\x86\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if miss == 'del':  # \xe5\x88\xa0\xe9\x99\xa4\xe6\x8e\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n        miss_data = data.dropna(how='any')\r\n    else:\r\n        miss_data = data.fillna(method='ffill')\r\n    return miss_data\r\n\r\n#  \xe5\xb0\x86\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\xad\x97\xe6\xae\xb5\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\xef\xbc\x8c\r\ndef Digitcode(traindata, predixdata):\r\n    #  \xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n    for ikey in traindata:\r\n        if traindata[ikey].dtype == 'object':  # \xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n            numb = sorted(list(set(list(traindata[ikey].values))))\r\n            exdict = {ji: numb.index(ji) for ji in numb}\r\n            if ikey == 'Money':\r\n                predixdata[ikey] = ['%s' % gfi[:-1] for gfi in predixdata[ikey]]  # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe4\xb8\xadMoney\xe7\x9a\x84\xe5\x80\xbc\xe5\xa4\x9a\xe4\xb8\xaa\xe7\x82\xb9\r\n            else:\r\n                predixdata[ikey] = [exdict[fi] for fi in predixdata[ikey]]\r\n                traindata[ikey] = [exdict[fi] for fi in traindata[ikey]]\r\n    return traindata, predixdata.values\r\n\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nread_train = ReadHandle(train_path)\r\nread_pre = ReadHandle(pre_path)\r\n\r\n# \xe7\xbb\x8f\xe8\xbf\x87\xe5\xa4\x84\xe7\x90\x86\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nhan_train, predict_data = Digitcode(read_train, read_pre)\r\n\r\n\r\n#  \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8cK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x8c\xe6\xa0\xb9\xe6\x8d\xaeF1\xe5\xba\xa6\xe9\x87\x8f\xe7\xa1\xae\xe5\xae\x9a\xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\r\n#  \xe7\x84\xb6\xe5\x90\x8e\xe5\x86\x8d\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xae\xa1\xe7\xae\x97\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\xb7\xb7\xe6\xb7\x86\xe7\x9f\xa9\xe9\x98\xb5\xe4\xbb\xa5\xe5\x8f\x8a\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe3\x80\x81\xe5\x8f\xac\xe5\x9b\x9e\xe7\x8e\x87\xef\xbc\x8cF1\xe5\xba\xa6\xe9\x87\x8f\r\n\r\ndef kfold(trdata, k=10):\r\n    vadata = trdata.values\r\n    legth = len(vadata)\r\n    datadict = {}\r\n    signnuber = np.arange(legth)\r\n    for hh in range(k):\r\n        datadict[hh] = {}\r\n        np.random.shuffle(vadata)\r\n        yanzhneg = np.random.choice(signnuber, int(legth / k), replace=False)\r\n        oneflod_yan = vadata[yanzhneg]\r\n        oneflod_xun = vadata[[hdd for hdd in signnuber if hdd not in yanzhneg]]\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\r\n        datadict[hh]['train'] = oneflod_xun\r\n        datadict[hh]['test'] = oneflod_yan\r\n    return datadict\r\n\r\n#  \xe5\xad\x98\xe5\x82\xa8K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\r\ndt_data = kfold(han_train)"""
Boosting/XGBoost/pm25_XGBoost_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\PRSA_data_2010.1.1-2014.12.31.csv')\r\n\r\n\r\n'''\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86'''\r\n#  \xe5\x9b\xa0\xe4\xb8\xbaPm2.5\xe6\x98\xaf\xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xa6\x82\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9b\xb4\xe6\x8e\xa5\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xb8\x80\xe6\x9d\xa1\xe8\xae\xb0\xe5\xbd\x95\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe7\x9b\xae\xe6\xa0\x87\xe5\x80\xbc\xe4\xb8\xba\xe7\xa9\xba\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0, \xe5\x85\xb6\xe4\xbb\x96\xe5\x88\x97\xe4\xb8\xba\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe5\x88\x99\xe8\x87\xaa\xe5\x8a\xa8\xe5\xa1\xab\xe5\x85\x85\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0,\xe5\xb9\xb6\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\x8f\x98\xe9\x87\x8f\xe6\x94\xbe\xe7\xbd\xae\xe5\x9c\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\x88\x97\r\ndef DeleteTargetNan(exdata, targetstr):\r\n    #  \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if exdata[targetstr].isnull().any():\r\n        #  \xe9\xa6\x96\xe5\x85\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe6\x95\xb0\r\n        loc = exdata[targetstr][data[targetstr].isnull().values == True].index.tolist()\r\n        #  \xe7\x84\xb6\xe5\x90\x8e\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xba\x9b\xe8\xa1\x8c\r\n        exdata = exdata.drop(loc)\r\n    # \xe5\x87\xa1\xe6\x98\xaf\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\x86\x8d\xe4\xb8\x80\xe8\xb5\xb7\xe5\x88\xa9\xe7\x94\xa8\xe6\xad\xa4\xe8\xa1\x8c\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\xe5\xa1\xab\xe5\x85\x85\r\n    exdata = exdata.fillna(exdata.mean())\r\n    # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\x87\xb3\xe6\x94\xbe\xe5\x9c\xa8\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe4\xb8\x80\xe5\x88\x97\r\n    targetnum = exdata[targetstr].copy()\r\n    del exdata[targetstr]\r\n    exdata[targetstr] = targetnum\r\n    return exdata\r\n\r\n\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\r\ndef Shanchu(exdata, aiduan=['No']):\r\n    for ai in aiduan:\r\n        if ai in exdata.keys():\r\n            del exdata[ai]\r\n    return exdata\r\n\r\n\r\n# \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe7\x9a\x84\xe5\xb1\x9e\xe6\x80\xa7\xe5\x80\xbc\xe4\xb8\xba\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\x9a\x84\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\xe5\xaf\xb9\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe8\x80\x8c\xe8\xa8\x80\xe4\xb8\x8d\xe9\x82\xa3\xe4\xb9\x88\xe9\x87\x8d\xe8\xa6\x81\r\ndef Digit(eadata):\r\n    # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\r\n    for jj in eadata:\r\n        try:\r\n            eadata[jj].values[0] + 1\r\n        except TypeError:\r\n            # \xe9\x9c\x80\xe8\xa6\x81\xe8\xbd\xac\xe4\xb8\xba\xe6\x95\xb0\xe5\xad\x97\xe7\xbc\x96\xe7\xa0\x81\r\n            numlist = list(set(list(eadata[jj].values)))\r\n            zhuan = [numlist.index(jj) for jj in eadata[jj].values]\r\n            eadata[jj] = zhuan\r\n    return eadata\r\n\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n\r\nfirst = DeleteTargetNan(data, 'pm2.5')\r\ntwo = Shanchu(first)\r\nthird = Digit(two)\r\n\r\n# \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x8c\x89\xe7\x85\xa78:2\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe3\x80\x82\xe5\x85\xb6\xe4\xb8\xad\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x86\x8d\xe5\x88\x86\xe4\xb8\xbaK\xe4\xbb\xbd\xef\xbc\x8c\xe8\xbf\x9b\xe8\xa1\x8cK\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\r\n\r\ndef fenge(exdata, k=10, per=[0.8, 0.2]):\r\n    # \xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n    lent = len(exdata)\r\n    alist = np.arange(lent)\r\n    np.random.shuffle(alist)\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\r\n    xunlian_sign = int(lent * per[0])\r\n\r\n    xunlian = np.random.choice(alist, xunlian_sign, replace=False)\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    yuce = np.array([i for i in alist if i not in xunlian])\r\n\r\n    # \xe5\x86\x8d\xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x88\x86\xe4\xb8\xbaK\xe6\x8a\x98\r\n    # \xe5\xad\x98\xe5\x82\xa8\xe5\xad\x97\xe5\x85\xb8\r\n    save_dict = {}\r\n    for jj in range(k):\r\n        save_dict[jj] = {}\r\n        length = len(xunlian)\r\n        # \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\r\n        yuzhi = int(length / k)\r\n        yan = np.random.choice(xunlian, yuzhi, replace=False)\r\n        tt = np.array([i for i in xunlian if i not in yan])\r\n        save_dict[jj]['train'] = exdata[tt]\r\n        save_dict[jj]['test'] = exdata[yan]\r\n\r\n    return save_dict, exdata[yuce]\r\n\r\ndeeer = fenge(third.values)\r\n\r\n# K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\ndt_data = deeer[0]\r\n# \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\npredict_data = deeer[1]\r\n"""
CNN/Convolution/convolution.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport numpy as np\r\n\r\nFig_matrix = np.array([[2, 6, 3, 8, 3], [1, 4, 4, 7, 7], [3, 4, 8, 4, 9], [7, 1, 5, 4, 8], [9, 3, 1, 2, 1], [9, 5, 2, 4, 9]])\r\n\r\nFilter_matrix = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]])\r\n\r\n\r\n# Valid\xe5\x8d\xb7\xe7\xa7\xaf\r\ndef valid_c(fig, filters):\r\n    """"""\r\n    \xe5\xae\x9e\xe7\x8e\xb0valid\xe5\x8d\xb7\xe7\xa7\xaf\r\n    :param fig:  \xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8cnumpy\xe6\x95\xb0\xe7\xbb\x84\xe5\xbd\xa2\xe5\xbc\x8f\r\n    :param filters: \xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8(\xe6\xbb\xa4\xe6\xb3\xa2\xe5\x99\xa8)\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8cnumpy\xe6\x95\xb0\xe7\xbb\x84\xe5\xbd\xa2\xe5\xbc\x8f\r\n    :return: \xe5\x8d\xb7\xe7\xa7\xaf\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    """"""\r\n    fig_row, fig_column = fig.shape\r\n    filter_row, filter_column = filters.shape\r\n\r\n    c_row = fig_row - filter_row + 1\r\n    c_column = fig_column - filter_column + 1\r\n    # \xe5\x8d\xb7\xe7\xa7\xaf\xe7\x9f\xa9\xe9\x98\xb5\r\n    c_matrix = np.zeros((c_row, c_column))\r\n\r\n    for r in range(c_row):\r\n        for c in range(c_column):\r\n            matrix_f = fig[r: r + filter_row, c: c + filter_column]\r\n            product = np.sum(matrix_f * filters)\r\n            c_matrix[r, c] = product\r\n\r\n    return c_matrix\r\n\r\n\r\n# Same\xe5\x8d\xb7\xe7\xa7\xaf\r\ndef same_c(fig, filters):\r\n    """"""\r\n    \xe5\xae\x9e\xe7\x8e\xb0same\xe5\x8d\xb7\xe7\xa7\xaf\r\n    :param fig:  \xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8cnumpy\xe6\x95\xb0\xe7\xbb\x84\xe5\xbd\xa2\xe5\xbc\x8f\r\n    :param filters: \xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8(\xe6\xbb\xa4\xe6\xb3\xa2\xe5\x99\xa8)\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8cnumpy\xe6\x95\xb0\xe7\xbb\x84\xe5\xbd\xa2\xe5\xbc\x8f\r\n    :return: \xe5\x8d\xb7\xe7\xa7\xaf\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    """"""\r\n    fig_row, fig_column = fig.shape\r\n    filter_row, filter_column = filters.shape\r\n\r\n    # \xe9\xa6\x96\xe5\x85\x88fig\xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\x8a\xe4\xb8\x8b\xe5\xa1\xab\xe5\x85\x85\xe8\xa1\x8c\r\n    row_padding = (filter_row - 1) // 2\r\n    c = np.zeros((row_padding, fig_column))\r\n    # \xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\x8a\xe4\xb8\x8b\xe7\x9a\x84\xe8\xa1\x8c\xe5\xa1\xab\xe5\x85\x85\r\n    fig = np.vstack((fig, c))\r\n    fig = np.vstack((c, fig))\r\n\r\n    # \xe5\xaf\xb9fig\xe7\x9f\xa9\xe9\x98\xb5\xe5\xb7\xa6\xe5\x8f\xb3\xe5\xa1\xab\xe5\x85\x85\xe5\x88\x97\r\n    column_padding = (filter_column - 1) // 2\r\n    b = np.zeros((fig_row + filter_row - 1, column_padding))\r\n    # \xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\x8a\xe4\xb8\x8b\xe7\x9a\x84\xe8\xa1\x8c\xe5\xa1\xab\xe5\x85\x85\r\n    fig = np.hstack((fig, b))\r\n    fig = np.hstack((b, fig))\r\n\r\n    # \xe5\x8d\xb7\xe7\xa7\xaf\xe7\x9f\xa9\xe9\x98\xb5\r\n    c_matrix = np.zeros((fig_row, fig_column))\r\n\r\n    for r in range(fig_row):\r\n        for c in range(fig_column):\r\n            matrix_f = fig[r: r + filter_row, c: c + filter_column]\r\n            product = np.sum(matrix_f * filters)\r\n            c_matrix[r, c] = product\r\n    return c_matrix\r\n\r\n\r\n# full\xe5\x8d\xb7\xe7\xa7\xaf\r\ndef full_c(fig, filters):\r\n    """"""\r\n    \xe5\xae\x9e\xe7\x8e\xb0full\xe5\x8d\xb7\xe7\xa7\xaf\r\n    :param fig:  \xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8cnumpy\xe6\x95\xb0\xe7\xbb\x84\xe5\xbd\xa2\xe5\xbc\x8f\r\n    :param filters: \xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8(\xe6\xbb\xa4\xe6\xb3\xa2\xe5\x99\xa8)\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8cnumpy\xe6\x95\xb0\xe7\xbb\x84\xe5\xbd\xa2\xe5\xbc\x8f\r\n    :return: \xe5\x8d\xb7\xe7\xa7\xaf\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    """"""\r\n    fig_row, fig_column = fig.shape\r\n    filter_row, filter_column = filters.shape\r\n\r\n    # \xe9\xa6\x96\xe5\x85\x88fig\xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\x8a\xe4\xb8\x8b\xe5\xa1\xab\xe5\x85\x85\xe8\xa1\x8c\r\n    row_padding = filter_row - 1\r\n    c = np.zeros((row_padding, fig_column))\r\n    # \xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\x8a\xe4\xb8\x8b\xe7\x9a\x84\xe8\xa1\x8c\xe5\xa1\xab\xe5\x85\x85\r\n    fig = np.vstack((fig, c))\r\n    fig = np.vstack((c, fig))\r\n\r\n    # \xe5\xaf\xb9fig\xe7\x9f\xa9\xe9\x98\xb5\xe5\xb7\xa6\xe5\x8f\xb3\xe5\xa1\xab\xe5\x85\x85\xe5\x88\x97\r\n    column_padding = filter_column - 1\r\n    b = np.zeros((fig_row + 2 * (filter_row - 1), column_padding))\r\n    # \xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\x8a\xe4\xb8\x8b\xe7\x9a\x84\xe8\xa1\x8c\xe5\xa1\xab\xe5\x85\x85\r\n    fig = np.hstack((fig, b))\r\n    fig = np.hstack((b, fig))\r\n\r\n    # \xe5\x8d\xb7\xe7\xa7\xaf\xe7\x9f\xa9\xe9\x98\xb5\r\n    c_matrix = np.zeros((fig_row + row_padding, fig_column + column_padding))\r\n\r\n    for r in range(fig_row + row_padding):\r\n        for c in range(fig_column + column_padding):\r\n            matrix_f = fig[r: r + filter_row, c: c + filter_column]\r\n            product = np.sum(matrix_f * filters)\r\n            c_matrix[r, c] = product\r\n    return c_matrix\r\n'"
CNN/Convolution/convolution_kernel.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nfrom skimage import io\r\nfrom PIL import Image\r\nimport numpy as np\r\n\r\n\r\n# Same\xe5\x8d\xb7\xe7\xa7\xaf\r\ndef same_c(fig, filters):\r\n    """"""\r\n    \xe5\xae\x9e\xe7\x8e\xb0same\xe5\x8d\xb7\xe7\xa7\xaf\r\n    :param fig:  \xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8cnumpy\xe6\x95\xb0\xe7\xbb\x84\xe5\xbd\xa2\xe5\xbc\x8f\r\n    :param filters: \xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8(\xe6\xbb\xa4\xe6\xb3\xa2\xe5\x99\xa8)\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8cnumpy\xe6\x95\xb0\xe7\xbb\x84\xe5\xbd\xa2\xe5\xbc\x8f\r\n    :return: \xe5\x8d\xb7\xe7\xa7\xaf\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    """"""\r\n    fig_row, fig_column = fig.shape\r\n    filter_row, filter_column = filters.shape\r\n\r\n    # \xe9\xa6\x96\xe5\x85\x88fig\xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\x8a\xe4\xb8\x8b\xe5\xa1\xab\xe5\x85\x85\xe8\xa1\x8c\r\n    row_padding = (filter_row - 1) // 2\r\n    c = np.zeros((row_padding, fig_column))\r\n    # \xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\x8a\xe4\xb8\x8b\xe7\x9a\x84\xe8\xa1\x8c\xe5\xa1\xab\xe5\x85\x85\r\n    fig = np.vstack((fig, c))\r\n    fig = np.vstack((c, fig))\r\n\r\n    # \xe5\xaf\xb9fig\xe7\x9f\xa9\xe9\x98\xb5\xe5\xb7\xa6\xe5\x8f\xb3\xe5\xa1\xab\xe5\x85\x85\xe5\x88\x97\r\n    column_padding = (filter_column - 1) // 2\r\n    b = np.zeros((fig_row + filter_row - 1, column_padding))\r\n    # \xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\x8a\xe4\xb8\x8b\xe7\x9a\x84\xe8\xa1\x8c\xe5\xa1\xab\xe5\x85\x85\r\n    fig = np.hstack((fig, b))\r\n    fig = np.hstack((b, fig))\r\n\r\n    # \xe5\x8d\xb7\xe7\xa7\xaf\xe7\x9f\xa9\xe9\x98\xb5\r\n    c_matrix = np.zeros((fig_row, fig_column))\r\n\r\n    for r in range(fig_row):\r\n        for c in range(fig_column):\r\n            matrix_f = fig[r: r + filter_row, c: c + filter_column]\r\n            product = np.sum(matrix_f * filters)\r\n            c_matrix[r, c] = product\r\n\r\n    return c_matrix\r\n\r\n\r\ndef generate_fig(fig, c, file):\r\n    """"""\r\n    # \xe9\xa6\x96\xe5\x85\x88\xe8\xaf\xbb\xe5\x8f\x96\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x84\xe4\xb8\x89\xe4\xb8\xaa\xe9\x80\x9a\xe9\x81\x93\xe5\x90\x84\xe8\x87\xaa\xe5\x92\x8c\xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x8d\xb7\xe7\xa7\xaf\xef\xbc\x8c\xe5\xb0\x86\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\x90\x88\xe6\x88\x90\xe4\xb8\xba\xe5\x9b\xbe\xe7\x89\x87\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8c\xe6\x9c\x80\xe5\x90\x8e\xe6\xa0\xb9\xe6\x8d\xae\xe7\x9f\xa9\xe9\x98\xb5\xe6\x98\xbe\xe7\xa4\xba\xe5\x9b\xbe\xe7\x89\x87\r\n    :param fig: \xe9\x9c\x80\xe8\xa6\x81\xe5\xa4\x84\xe7\x90\x86\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\r\n    :param c: \xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8\xe7\x9f\xa9\xe9\x98\xb5\r\n    :param file: \xe6\x9c\x80\xe5\x91\xa8\xe4\xbf\x9d\xe5\xad\x98\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\r\n    :return: \xe5\x9b\xbe\xe7\x89\x87\r\n    """"""\r\n    matrix = io.imread(fig)\r\n    # R\xe9\x80\x9a\xe9\x81\x93\r\n    R = matrix[:, :, 0]\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xbb\x8f\xe8\xbf\x87same\xe5\x8d\xb7\xe7\xa7\xaf\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    R = same_c(R, c)\r\n    # \xe9\x80\x9a\xe9\x81\x93\xe7\x9f\xa9\xe9\x98\xb5\xe5\x8f\x98\xe6\x8d\xa2\xe7\xbb\xb4\xe5\xba\xa6\r\n    R1 = R.reshape(-1, len(R[0]), 1)\r\n\r\n    # G\xe9\x80\x9a\xe9\x81\x93\r\n    G = matrix[:, :, 1]\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xbb\x8f\xe8\xbf\x87same\xe5\x8d\xb7\xe7\xa7\xaf\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    G = same_c(G, c)\r\n    # \xe9\x80\x9a\xe9\x81\x93\xe7\x9f\xa9\xe9\x98\xb5\xe5\x8f\x98\xe6\x8d\xa2\xe7\xbb\xb4\xe5\xba\xa6\r\n    G1 = G.reshape(-1, len(G[0]), 1)\r\n\r\n    # B\xe9\x80\x9a\xe9\x81\x93\r\n    B = matrix[:, :, 2]\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xbb\x8f\xe8\xbf\x87same\xe5\x8d\xb7\xe7\xa7\xaf\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    B = same_c(B, c)\r\n    # \xe9\x80\x9a\xe9\x81\x93\xe7\x9f\xa9\xe9\x98\xb5\xe5\x8f\x98\xe6\x8d\xa2\xe7\xbb\xb4\xe5\xba\xa6\r\n    B1 = B.reshape(-1, len(B[0]), 1)\r\n\r\n    my_matrix_original = np.concatenate([R1, G1, B1], 2)\r\n\r\n    # \xe5\xb0\x86\xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\xad\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe5\x8f\x96\xe6\x95\xb4\xef\xbc\x8c\xe5\xb0\x8f\xe4\xba\x8e0\xe7\x9a\x84\xe5\x8f\x98\xe4\xb8\xba0\xef\xbc\x8c\xe5\xa4\xa7\xe4\xba\x8e255\xe7\x9a\x84\xe5\x8f\x98\xe4\xb8\xba255\r\n    my_matrix_original.astype(np.int)\r\n    my_matrix_original[my_matrix_original < 0] = 0\r\n    my_matrix_original[my_matrix_original > 255] = 255\r\n\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe5\x9b\xbe\xe7\x89\x87\r\n    image = Image.fromarray(np.uint8(my_matrix_original))  # \xe8\xbd\xac\xe6\x8d\xa2uint8\xe6\xa0\xbc\xe5\xbc\x8f\r\n    image.show()\r\n    image.save(file)\r\n\r\n    return print(\'\xe5\x9b\xbe\xe7\x89\x87\xe7\x94\x9f\xe6\x88\x90\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    # \xe5\x8e\x9f\xe5\xa7\x8b\xe5\x9b\xbe\xe7\x89\x87\xe8\xb7\xaf\xe5\xbe\x84\r\n    fig_path = r\'C:\\Users\\GWT9\\Desktop\\lena.jpg\'\r\n    # \xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8\r\n    # c_matrix = np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]])  # \xe5\x8d\x95\xe4\xbd\x8d\xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8\r\n    # c_matrix = 1/9 * np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])  # \xe5\x9d\x87\xe5\x80\xbc\xe6\xa8\xa1\xe7\xb3\x8a\r\n    # c_matrix = 1 / 273 * np.array([[1, 4, 7, 4, 1], [4, 16, 26, 16, 4],\r\n    #                               [7, 26, 41, 26, 7], [4, 16, 26, 16, 4], [1, 4, 7, 4, 1]])  # \xe9\xab\x98\xe6\x96\xaf\xe6\xa8\xa1\xe7\xb3\x8a\r\n    c_matrix = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])  # \xe6\x8b\x89\xe6\x99\xae\xe6\x8b\x89\xe6\x96\xaf\xe5\x8d\xb7\xe7\xa7\xaf\xe6\xa0\xb8\xe3\x80\x82\xe8\xbe\xb9\xe7\xbc\x98\xe6\xa3\x80\xe6\xb5\x8b\xef\xbc\x8c\xe9\x94\x90\xe5\x8c\x96\r\n\r\n\r\n    # \xe4\xbf\x9d\xe5\xad\x98\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\r\n    save_fig = r\'C:\\Users\\GWT9\\Desktop\\lena_laplace.png\'\r\n    # \xe8\xbf\x90\xe8\xa1\x8c\xe5\x87\xbd\xe6\x95\xb0\r\n    generate_fig(fig_path, c_matrix, save_fig)\r\n\r\n\r\n\r\n'"
CNN/Pooling/cut_fig.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\n# \xe5\xae\x9e\xe7\x8e\xb0\xe5\x88\x87\xe5\x89\xb2\xe5\x9b\xbe\xe7\x89\x87\xef\xbc\x8c\xe5\xb9\xb6\xe8\xbf\x94\xe5\x9b\x9e\xe7\xa9\xba\xe9\x97\xb4\xe9\x87\x91\xe5\xad\x97\xe5\xa1\x94\xe6\xb1\xa0\xe5\x8c\x96\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n\r\nfrom skimage import io\r\nfrom PIL import Image\r\nimport numpy as np\r\n\r\n\r\nclass CutFig():\r\n\r\n    def __init__(self):\r\n        # \xe9\x9c\x80\xe8\xa6\x81\xe5\x88\x87\xe5\x89\xb2\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\r\n        self.fig_path = r""C:\\Users\\GWT9\\Desktop\\iris_1.jpg""   # \xe8\xa6\x81\xe5\xa4\x84\xe7\x90\x86\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe8\xb7\xaf\xe5\xbe\x84\r\n\r\n        # \xe5\x88\x87\xe5\x89\xb2\xe7\xba\xbf\xe7\x9a\x84\xe5\xae\xbd\xe5\xba\xa6\xe4\xb8\xba\xe5\xa4\x9a\xe5\xb0\x91\xe5\x83\x8f\xe7\xb4\xa0\r\n        self.cut_width = 3\r\n\r\n        # \xe5\x8f\xaf\xe4\xbb\xa5\xe8\x87\xaa\xe5\xae\x9a\xe4\xb9\x89\xe5\x88\x87\xe5\x89\xb2\xe7\xba\xbf\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\xe7\x9a\x84RGB\xe5\xad\x97\xe5\x85\xb8\r\n        self.cut_color_dict = {\'R\': 255, \'G\': 255, \'B\': 255}\r\n\r\n        # \xe8\xaf\xa5\xe5\x9b\xbe\xe7\x89\x873\xe4\xb8\xaa\xe9\x80\x9a\xe9\x81\x93\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\r\n        self.R, self.G, self.B = self.get_matrix()\r\n\r\n        # \xe7\xa9\xba\xe9\x97\xb4\xe9\x87\x91\xe5\xad\x97\xe5\xa1\x94\xe6\xb1\xa0\xe5\x8c\x96\xe7\x9a\x84\xe5\xb1\x82\xe6\x95\xb0\xe5\x88\x97\xe8\xa1\xa8\xef\xbc\x8c1\xe5\xb1\x82\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe5\x80\xbc\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe4\xb8\xba1\xef\xbc\x8c 2\xe5\xb1\x82\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe5\x80\xbc\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe4\xb8\xba4\xef\xbc\x8cn\xe5\xb1\x82\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe5\x80\xbc\xe5\xbe\x97\xe4\xb8\xaa\xe6\x95\xb0\xe4\xb8\xban^2\r\n        self.layer_list = [1, 2, 3, 4]\r\n\r\n        # \xe4\xbf\x9d\xe5\xad\x98\xe5\x88\x87\xe5\x89\xb2\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\r\n        self.cut_fig_path = r""C:\\Users\\GWT9\\Desktop""  # \xe4\xbf\x9d\xe5\xad\x98\xe7\x9a\x84\xe5\x88\x87\xe5\x89\xb2\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\r\n\r\n    # \xe8\x8e\xb7\xe5\xbe\x97\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe4\xb8\x89\xe4\xb8\xaa\xe9\x80\x9a\xe9\x81\x93\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\r\n    def get_matrix(self):\r\n        matrix = io.imread(self.fig_path)\r\n        R = matrix[:, :, 0]  # \xe8\x8e\xb7\xe5\x8f\x96R\xe9\x80\x9a\xe9\x81\x93\r\n        G = matrix[:, :, 1]  # \xe8\x8e\xb7\xe5\x8f\x96G\xe9\x80\x9a\xe9\x81\x93\r\n        B = matrix[:, :, 2]  # \xe8\x8e\xb7\xe5\x8f\x96B\xe9\x80\x9a\xe9\x81\x93\r\n        return R, G, B\r\n\r\n    # \xe4\xb8\x89\xe4\xb8\xaa\xe9\x80\x9a\xe9\x81\x93\xe5\x90\x88\xe6\x88\x90\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xe8\xbd\xac\xe5\x8f\x98\xe4\xb8\xba\xe5\x9b\xbe\xe7\x89\x87\r\n    def generate_fig(self, r, g, b, title, l):\r\n        """"""\r\n        :param r: R\xe9\x80\x9a\xe9\x81\x93\xe7\x9f\xa9\xe9\x98\xb5\r\n        :param g: G\xe9\x80\x9a\xe9\x81\x93\xe7\x9f\xa9\xe9\x98\xb5\r\n        :param b: B\xe9\x80\x9a\xe9\x81\x93\xe7\x9f\xa9\xe9\x98\xb5\r\n        :param title: \xe5\x9b\xbe\xe7\x89\x87\xe5\x9f\xba\xe7\xa1\x80\xe5\x90\x8d\xe7\xa7\xb0\r\n        :param l: \xe5\xb1\x82\xe6\xa0\x87\xe8\xaf\x86\r\n        :return: \xe4\xbb\xa5\xe5\x9b\xbe\xe7\x89\x87\xe5\x9f\xba\xe7\xa1\x80\xe5\x90\x8d\xe7\xa7\xb0_\xe5\xb1\x82\xe6\xa0\x87\xe8\xaf\x86\xe4\xb8\xba\xe5\x90\x8d\xe7\x9a\x84png\xe6\xa0\xbc\xe5\xbc\x8f\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\r\n        """"""\r\n        # \xe9\x80\x9a\xe9\x81\x93\xe7\x9f\xa9\xe9\x98\xb5\xe5\x8f\x98\xe6\x8d\xa2\xe7\xbb\xb4\xe5\xba\xa6\r\n        R = r.reshape(-1, len(r[0]), 1)\r\n        G = g.reshape(-1, len(g[0]), 1)\r\n        B = b.reshape(-1, len(b[0]), 1)\r\n        # \xe4\xb8\x89\xe4\xb8\xaa\xe7\x9f\xa9\xe9\x98\xb5\xe5\x90\x88\xe6\x88\x90\xe4\xb8\xba\xe4\xb8\x89\xe7\xbb\xb4\xe7\x9f\xa9\xe9\x98\xb5\r\n        fig_matrix = np.concatenate([R, G, B], 2)\r\n        image = Image.fromarray(np.uint8(fig_matrix))\r\n        image.show()\r\n        image.save(r""%s\\%s_%s.png"" % (self.cut_fig_path, title, l))\r\n        return print(\'\xe5\x9b\xbe\xe7\x89\x87\xe7\x94\x9f\xe6\x88\x90\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n    def ssp_pooling(self, channel_name, l):\r\n        """"""\r\n        \xe6\xa0\xb9\xe6\x8d\xae\xe5\xb1\x82\xe6\x95\xb0\xe6\x9d\xa5\xe5\xaf\xb9\xe5\x8d\x95\xe4\xb8\x80\xe9\x80\x9a\xe9\x81\x93\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\xe8\xbf\x9b\xe8\xa1\x8c\xe5\x88\x86\xe5\x89\xb2\xef\xbc\x8c\xe5\xb9\xb6\xe4\xb8\x94\xe8\xbf\x94\xe5\x9b\x9e\xe7\xa9\xba\xe9\x97\xb4\xe9\x87\x91\xe5\xad\x97\xe5\xa1\x94\xe6\xb1\xa0\xe5\x8c\x96\xe7\x9a\x84\xe6\x95\xb0\xe5\x80\xbc\r\n        :param channel_name: \xe5\x8d\x95\xe4\xb8\x80\xe9\x80\x9a\xe9\x81\x93\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\r\n        :param l: \xe5\xb1\x82\xe6\x95\xb0\r\n        :return: \xe5\x88\x86\xe5\x89\xb2\xe5\x90\x8e\xe7\x9a\x84\xe5\x8d\x95\xe9\x80\x9a\xe9\x81\x93\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\xe4\xbb\xa5\xe5\x8f\x8a\xe6\xb1\xa0\xe5\x8c\x96\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe5\x80\xbc\r\n        """"""\r\n        count = l\r\n        # \xe5\x88\x86\xe5\x89\xb2\xe9\x83\xbd\xe6\x98\xaf\xe5\x9d\x87\xe5\x88\x86\xef\xbc\x8c\xe5\xaf\xb9\xe4\xba\x8e\xe4\xb8\x8d\xe8\x83\xbd\xe5\x9d\x87\xe5\x88\x86\xe7\x9a\x84\xe6\x83\x85\xe5\x86\xb5\xef\xbc\x8c\xe4\xbe\x8b\xe5\xa6\x82\xe8\xa1\x8c\xe5\x88\x97\xe4\xb8\x8d\xe8\x83\xbd\xe8\xa2\xabcount\xe6\x95\xb4\xe9\x99\xa4\xe6\x97\xb6\xef\xbc\x8c\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe7\xa8\x8d\xe5\xbe\xae\xe5\xa4\xa7\xe4\xb8\x80\xe4\xba\x9b\r\n        # \xe5\xa6\x82\xe6\x9e\x9ccount \xe5\xa4\xa7\xe4\xba\x8e\xe8\xa1\x8c\xe6\x88\x96\xe8\x80\x85\xe5\x88\x97\xef\xbc\x8c\xe5\x88\x99\xe4\xb8\x8d\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xbb\xbb\xe4\xbd\x95\xe7\x9a\x84\xe6\x93\x8d\xe4\xbd\x9c\r\n        channel_matrix = eval(\'self.%s\' % channel_name)\r\n        if count == 1:\r\n            print(\'\xe7\xac\xac%s\xe5\xb1\x82\xe7\x9a\x84%s\xe9\x80\x9a\xe9\x81\x93ssp\xe7\xbb\x93\xe6\x9e\x9c:\' % (l, channel_name), np.max(channel_matrix))\r\n            return channel_matrix\r\n\r\n        else:\r\n            row, column = channel_matrix.shape\r\n\r\n            if count > row or count > column:\r\n                return print(\'\xe5\xb1\x82\xe6\x95\xb0\xe8\xbf\x87\xe5\xa4\xa7\')\r\n            else:\r\n                # \xe6\xaf\x8f\xe4\xb8\x80\xe5\x9d\x97\xe8\xa1\x8c\xe3\x80\x81\xe5\x88\x97\xe7\x9a\x84\xe5\x83\x8f\xe7\xb4\xa0\xe6\x95\xb0\r\n                row_length = row // count\r\n                column_length = column // count\r\n                # \xe5\x88\x86\xe5\x89\xb2\xe5\x90\x8e\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe5\xb0\xb1\xe6\x98\xaf\xe5\x85\x88\xe5\x9c\xa8\xe5\x8d\x95\xe9\x80\x9a\xe9\x81\x93\xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\x91\xa8\xe5\x9b\xb4\xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\x86\xe5\x89\xb2\xe7\xba\xbf\r\n                # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\x86\xe5\x89\xb2\xe7\xba\xbf\xe5\x90\x8e\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\xe7\x9a\x84\xe5\xb0\xba\xe5\xaf\xb8\xe5\xa4\xa7\xe5\xb0\x8f\xef\xbc\x8c\xe5\x88\x9d\xe5\xa7\x8b\xe7\x9a\x84\xe5\x80\xbc\xe5\xb0\xb1\xe8\xae\xbe\xe4\xb8\xba\xe5\x88\x86\xe5\x89\xb2\xe7\xba\xbf\xe5\xae\x9a\xe4\xb9\x89\xe7\x9a\x84\xe8\xaf\xa5\xe9\x80\x9a\xe9\x81\x93\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\r\n                cut_fig_channel_matrix = np.ones((row + (count - 1) * self.cut_width,\r\n                                                  column + (count - 1) * self.cut_width)) * \\\r\n                                         self.cut_color_dict[channel_name]\r\n\r\n                # \xe5\xad\x98\xe5\x82\xa8ssp\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n                ssp_result = []\r\n                for r in range(count):\r\n                    for c in range(count):\r\n                        # \xe8\xa1\x8c\xe7\x9a\x84\xe8\x8c\x83\xe5\x9b\xb4\r\n                        if row < (r + 2) * row_length:\r\n                            row_field = [r * row_length, (r + 2) * row_length]\r\n                        else:\r\n                            row_field = [r * row_length, (r + 1) * row_length]\r\n                        # \xe5\x88\x97\xe7\x9a\x84\xe8\x8c\x83\xe5\x9b\xb4\r\n                        if column < (c + 2) * column_length:\r\n                            column_field = [c * column_length, (c + 2) * column_length]\r\n                        else:\r\n                            column_field = [c * column_length, (c + 1) * column_length]\r\n                        # \xe8\x8e\xb7\xe5\x8f\x96\xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\xe5\x9d\x97\r\n                        group_matrix = channel_matrix[row_field[0]: row_field[1], column_field[0]: column_field[1]]\r\n\r\n                        # \xe8\x8e\xb7\xe5\x8f\x96\xe6\xb1\xa0\xe5\x8c\x96\xe7\xbb\x93\xe6\x9e\x9c\r\n                        ssp_result.append(np.max(group_matrix))\r\n\r\n                        # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\x86\xe5\x89\xb2\xe7\xba\xbf\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\xad\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe5\x80\xbc\xe5\xb7\xb2\xe7\xbb\x8f\xe5\xae\x9a\xe4\xb9\x89\xe5\xa5\xbd\xef\xbc\x8c\xe6\x8a\x8a\xe5\x9d\x97\xe9\x87\x8c\xe9\x9d\xa2\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe8\xa6\x86\xe7\x9b\x96\xe4\xb8\xba\xe5\x8e\x9f\xe5\xa7\x8b\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe5\x8d\xb3\xe5\x8f\xaf\r\n                        # \xe8\xa1\x8c\xe7\x9a\x84\xe8\x8c\x83\xe5\x9b\xb4\r\n                        if row < (r + 2) * row_length:\r\n                            cut_row_field = [r * row_length + r * self.cut_width,\r\n                                             (r + 2) * row_length + r * self.cut_width]\r\n                        else:\r\n                            cut_row_field = [r * row_length + r * self.cut_width,\r\n                                             (r + 1) * row_length + r * self.cut_width]\r\n                        # \xe5\x88\x97\xe7\x9a\x84\xe8\x8c\x83\xe5\x9b\xb4\r\n                        if column < (c + 2) * column_length:\r\n                            cut_column_field = [c * column_length + c * self.cut_width,\r\n                                                (c + 2) * column_length + c * self.cut_width]\r\n                        else:\r\n                            cut_column_field = [c * column_length + c * self.cut_width,\r\n                                                (c + 1) * column_length + c * self.cut_width]\r\n\r\n                        cut_fig_channel_matrix[cut_row_field[0]: cut_row_field[1], cut_column_field[0]: cut_column_field[1]] = group_matrix\r\n                print(\'\xe7\xac\xac%s\xe5\xb1\x82\xe7\x9a\x84%s\xe9\x80\x9a\xe9\x81\x93ssp\xe7\xbb\x93\xe6\x9e\x9c:\' % (l, channel_name), ssp_result)\r\n                return cut_fig_channel_matrix\r\n\r\n\r\n\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\nif __name__ == ""__main__"":\r\n\r\n    c_f_ssp = CutFig()\r\n    for l in c_f_ssp.layer_list:\r\n        # \xe8\x8e\xb7\xe5\x8f\x96R\xe9\x80\x9a\xe9\x81\x93\r\n        cut_r = c_f_ssp.ssp_pooling(\'R\', l)\r\n        # \xe8\x8e\xb7\xe5\x8f\x96G\xe9\x80\x9a\xe9\x81\x93\r\n        cut_g = c_f_ssp.ssp_pooling(\'G\', l)\r\n        # \xe8\x8e\xb7\xe5\x8f\x96B\xe9\x80\x9a\xe9\x81\x93\r\n        cut_b = c_f_ssp.ssp_pooling(\'B\', l)\r\n\r\n        # \xe7\x94\x9f\xe6\x88\x90\xe5\x9b\xbe\xe7\x89\x87\r\n        c_f_ssp.generate_fig(cut_r, cut_g, cut_b, \'horizontal_iris\', l)\r\n'"
CNN/Pooling/pooling.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\n# \xe5\xae\x9e\xe7\x8e\xb0\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xe6\xb1\xa0\xe5\x8c\x96\xe3\x80\x812\xe7\xa7\x8d\xe5\xbd\xa2\xe5\xbc\x8f\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\xe6\xb1\xa0\xe5\x8c\x96\r\n# \xe5\xaf\xb9\xe4\xba\x8e\xe8\xb6\x85\xe5\x87\xba\xe8\x8c\x83\xe5\x9b\xb4\xe7\x9a\x84\xe5\x8f\xaa\xe8\xae\xa1\xe7\xae\x97\xe8\x8c\x83\xe5\x9b\xb4\xe5\x86\x85\xe7\x9a\x84\r\n\r\nimport numpy as np\r\n\r\nFig_matrix = np.array([[-2, -6, -1, -2, 0, 8, 3],\r\n                       [-5, -16, -5, -7, -3, 23, 13],\r\n                       [-7, -18, -12, -8, -7, 26, 26],\r\n                       [-14, -13, -11, -6, -8, 19, 33],\r\n                       [-26, -9, 7, -5, -7, 14, 26],\r\n                       [-34, -12, 25, 0, -10, 12, 19],\r\n                       [-27, -13, 22, 3, -14, 10, 19],\r\n                       [-9, -5, 7, 1, -7, 4, 9]])\r\n\r\n\r\nclass Pool():\r\n\r\n    def __init__(self):\r\n        # \xe6\xb1\xa0\xe5\x8c\x96\xe7\xaa\x97\xe5\x8f\xa3\xe7\x9a\x84\xe5\xb0\xba\xe5\xaf\xb8\r\n        self.p_size = 2\r\n\r\n        # \xe6\xb1\xa0\xe5\x8c\x96\xe7\xaa\x97\xe5\x8f\xa3\xe7\x9a\x84\xe6\xad\xa5\xe9\x95\xbf\r\n        self.p_strides = 3\r\n\r\n        # \xe5\x9d\x87\xe5\x80\xbc\xe6\x96\xb9\xe6\xb3\x95\xef\xbc\x8c\xe6\x99\xae\xe9\x80\x9a\xe5\x9d\x87\xe5\x80\xbc\xe4\xb8\xba1\xef\xbc\x8c\xe5\x85\xb6\xe4\xbb\x96\xe4\xb8\xba\xe5\x8a\xa0\xe6\x9d\x83\xe5\x9d\x87\xe5\x80\xbc\r\n        self.method = 1\r\n\r\n    # \xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xe6\xb1\xa0\xe5\x8c\x96\r\n    def max_pooling(self, fig):\r\n        """"""\r\n        \xe5\xae\x9e\xe7\x8e\xb0\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xe6\xb1\xa0\xe5\x8c\x96\r\n        :param fig: \xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\r\n        :return: \xe6\xb1\xa0\xe5\x8c\x96\xe5\x90\x8e\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\r\n        """"""\r\n        row, column = fig.shape\r\n        pool_row = (row - 1) // self.p_strides + 1\r\n        pool_column = (column - 1) // self.p_strides + 1\r\n        pool_matrix = np.zeros((pool_row, pool_column))\r\n        for i in range(pool_row):\r\n            for j in range(pool_column):\r\n                pool_matrix[i, j] = np.max(\r\n                    fig[i * self.p_strides: i * self.p_strides + self.p_size,\r\n                    j * self.p_strides: j * self.p_strides + self.p_size])\r\n        return pool_matrix\r\n\r\n    # \xe5\x9d\x87\xe5\x80\xbc\xe6\xb1\xa0\xe5\x8c\x96\r\n    def mean_pooling(self, fig):\r\n        """"""\r\n        \xe5\xae\x9e\xe7\x8e\xb0\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xe6\xb1\xa0\xe5\x8c\x96\r\n        :param fig: \xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\r\n        :return: \xe6\xb1\xa0\xe5\x8c\x96\xe5\x90\x8e\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\r\n        """"""\r\n        row, column = fig.shape\r\n        pool_row = (row - 1) // self.p_strides + 1\r\n        pool_column = (column - 1) // self.p_strides + 1\r\n        pool_matrix = np.zeros((pool_row, pool_column))\r\n        # \xe6\x99\xae\xe9\x80\x9a\xe5\x9d\x87\xe5\x80\xbc\r\n        if self.method == 1:\r\n            for i in range(pool_row):\r\n                for j in range(pool_column):\r\n                    pool_matrix[i, j] = np.mean(\r\n                        fig[i * self.p_strides: i * self.p_strides + self.p_size,\r\n                        j * self.p_strides: j * self.p_strides + self.p_size])\r\n        else:\r\n            # \xe5\x8a\xa0\xe6\x9d\x83\xe5\x9d\x87\xe5\x80\xbc\r\n            for i in range(pool_row):\r\n                for j in range(pool_column):\r\n                    # \xe5\x9c\xa8\xe8\x8c\x83\xe5\x9b\xb4\xe5\x86\x85\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\r\n                    in_matrix = fig[i * self.p_strides: i * self.p_strides + self.p_size,\r\n                               j * self.p_strides: j * self.p_strides + self.p_size]\r\n                    # \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x88\xb001\xe4\xb9\x8b\xe9\x97\xb4\r\n                    norm_matrix = (in_matrix - np.min(in_matrix)) / (np.max(in_matrix) - np.min(in_matrix))\r\n                    # \xe8\xae\xa1\xe7\xae\x97\xe5\x90\x84\xe4\xb8\xaa\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\r\n                    norm_matrix = norm_matrix / np.sum(norm_matrix)\r\n                    # \xe7\x84\xb6\xe5\x90\x8e\xe8\xae\xa1\xe7\xae\x97\xe5\x8a\xa0\xe6\x9d\x83\xe5\x9d\x87\xe5\x80\xbc\r\n                    pool_matrix[i, j] = np.sum(in_matrix * norm_matrix)\r\n        return pool_matrix\r\n\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\nif __name__ == ""__main__"":\r\n    # \xe5\x8e\x9f\xe5\xa7\x8b\xe5\x9b\xbe\xe7\x89\x87\xe8\xb7\xaf\xe5\xbe\x84\r\n    p = Pool()\r\n    print(p.max_pooling(Fig_matrix))\r\n\r\n\r\n\r\n\r\n\r\n'"
CNN/Pooling/pooling_fig.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\n# \xe4\xb8\x8d\xe5\x90\x8c\xe6\xb1\xa0\xe5\x8c\x96\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe5\xaf\xb9\xe6\xaf\x94\r\n\r\nimport pooling as p\r\nfrom skimage import io\r\nfrom PIL import Image\r\nimport numpy as np\r\n\r\n\r\ndef generate_fig(fig, file, func):\r\n    """"""\r\n    # \xe9\xa6\x96\xe5\x85\x88\xe8\xaf\xbb\xe5\x8f\x96\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x84\xe4\xb8\x89\xe4\xb8\xaa\xe9\x80\x9a\xe9\x81\x93\xe5\x90\x84\xe8\x87\xaa\xe6\xb1\xa0\xe5\x8c\x96\xef\xbc\x8c\xe5\xb0\x86\xe5\xbe\x97\xe5\x88\xb0\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\x90\x88\xe6\x88\x90\xe4\xb8\xba\xe5\x9b\xbe\xe7\x89\x87\xe7\x9f\xa9\xe9\x98\xb5\xef\xbc\x8c\xe6\x9c\x80\xe5\x90\x8e\xe6\xa0\xb9\xe6\x8d\xae\xe7\x9f\xa9\xe9\x98\xb5\xe6\x98\xbe\xe7\xa4\xba\xe5\x9b\xbe\xe7\x89\x87\r\n    :param fig: \xe9\x9c\x80\xe8\xa6\x81\xe5\xa4\x84\xe7\x90\x86\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\r\n    :param file: \xe6\x9c\x80\xe5\x91\xa8\xe4\xbf\x9d\xe5\xad\x98\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe8\xb7\xaf\xe5\xbe\x84\r\n    :return: \xe5\x9b\xbe\xe7\x89\x87\r\n    """"""\r\n    matrix = io.imread(fig)\r\n    # R\xe9\x80\x9a\xe9\x81\x93\r\n    R = matrix[:, :, 0]\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xbb\x8f\xe8\xbf\x87\xe6\xb1\xa0\xe5\x8c\x96\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    R = func(R)\r\n    # \xe9\x80\x9a\xe9\x81\x93\xe7\x9f\xa9\xe9\x98\xb5\xe5\x8f\x98\xe6\x8d\xa2\xe7\xbb\xb4\xe5\xba\xa6\r\n    R1 = R.reshape(-1, len(R[0]), 1)\r\n\r\n    # G\xe9\x80\x9a\xe9\x81\x93\r\n    G = matrix[:, :, 1]\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xbb\x8f\xe8\xbf\x87\xe6\xb1\xa0\xe5\x8c\x96\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    G = func(G)\r\n    # \xe9\x80\x9a\xe9\x81\x93\xe7\x9f\xa9\xe9\x98\xb5\xe5\x8f\x98\xe6\x8d\xa2\xe7\xbb\xb4\xe5\xba\xa6\r\n    G1 = G.reshape(-1, len(G[0]), 1)\r\n\r\n    # B\xe9\x80\x9a\xe9\x81\x93\r\n    B = matrix[:, :, 2]\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe7\xbb\x8f\xe8\xbf\x87\xe6\xb1\xa0\xe5\x8c\x96\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    B = func(B)\r\n    # \xe9\x80\x9a\xe9\x81\x93\xe7\x9f\xa9\xe9\x98\xb5\xe5\x8f\x98\xe6\x8d\xa2\xe7\xbb\xb4\xe5\xba\xa6\r\n    B1 = B.reshape(-1, len(B[0]), 1)\r\n\r\n    my_matrix_original = np.concatenate([R1, G1, B1], 2)\r\n\r\n    # \xe5\xb0\x86\xe6\x95\xb0\xe5\xad\x97\xe7\x9f\xa9\xe9\x98\xb5\xe4\xb8\xad\xe7\x9a\x84\xe6\x95\xb0\xe5\xad\x97\xe5\x8f\x96\xe6\x95\xb4\xef\xbc\x8c\xe5\xb0\x8f\xe4\xba\x8e0\xe7\x9a\x84\xe5\x8f\x98\xe4\xb8\xba0\xef\xbc\x8c\xe5\xa4\xa7\xe4\xba\x8e255\xe7\x9a\x84\xe5\x8f\x98\xe4\xb8\xba255\r\n    my_matrix_original.astype(np.int)\r\n    my_matrix_original[my_matrix_original < 0] = 0\r\n    my_matrix_original[my_matrix_original > 255] = 255\r\n\r\n    # \xe8\xbe\x93\xe5\x87\xba\xe5\x9b\xbe\xe7\x89\x87\r\n    image = Image.fromarray(np.uint8(my_matrix_original))  # \xe8\xbd\xac\xe6\x8d\xa2uint8\xe6\xa0\xbc\xe5\xbc\x8f\r\n    image.show()\r\n    image.save(file)\r\n\r\n    return print(\'\xe5\x9b\xbe\xe7\x89\x87\xe7\x94\x9f\xe6\x88\x90\xe5\xae\x8c\xe6\xaf\x95\')\r\n\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nif __name__ == ""__main__"":\r\n    # \xe5\x8e\x9f\xe5\xa7\x8b\xe5\x9b\xbe\xe7\x89\x87\xe8\xb7\xaf\xe5\xbe\x84\r\n    fig_path = r\'C:\\Users\\GWT9\\Desktop\\lena.jpg\'\r\n    # \xe6\xb1\xa0\xe5\x8c\x96\r\n    func = p.Pool()\r\n    p.p_size = 8\r\n    p.p_strides = 10\r\n    p.method = 3\r\n    # \xe4\xbf\x9d\xe5\xad\x98\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\r\n    save_fig = r\'C:\\Users\\GWT9\\Desktop\\mean_weight.png\'\r\n    # \xe8\xbf\x90\xe8\xa1\x8c\xe5\x87\xbd\xe6\x95\xb0\r\n    generate_fig(fig_path, save_fig, func.mean_pooling)\r\n\r\n\r\n\r\n\r\n'"
Decision Tree/DT_Classify/AnFany_DT_Classify.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# CART\xe5\x88\x86\xe7\xb1\xbb\xe6\xa0\x91\xef\xbc\x9a\xe5\x8f\xaf\xe5\xa4\x84\xe7\x90\x86\xe8\xbf\x9e\xe7\xbb\xad\xe3\x80\x81\xe7\xa6\xbb\xe6\x95\xa3\xe7\x9a\x84\xe5\x8f\x98\xe9\x87\x8f\xef\xbc\x8c\xe6\x94\xaf\xe6\x8c\x81\xe5\xa4\x9a\xe5\x88\x86\xe7\xb1\xbb\r\n# \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe9\xa1\xba\xe5\xba\x8f\xe5\xbf\x85\xe9\xa1\xbb\xe4\xb8\x80\xe6\xa0\xb7\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe6\x9c\xac\xe7\xa8\x8b\xe5\xba\x8f\xe5\x9c\xa8\xe8\xae\xbe\xe5\xae\x9a\xe8\xa7\x84\xe5\x88\x99\xe6\x8c\x89\xe7\x9a\x84\xe6\x98\xaf\xe5\xad\x97\xe6\xae\xb5\xe7\x9a\x84\xe7\xbc\x96\xe5\x8f\xb7\xef\xbc\x8c\xe8\x80\x8c\xe4\xb8\x8d\xe6\x98\xaf\xe5\x90\x8d\xe5\xad\x97\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport DT_Classify_Data as dtda\r\n\r\nimport copy\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe5\x87\xbd\xe6\x95\xb0\r\nclass DT:\r\n    def __init__(self, train_dtdata=dtda.dt_data, pre_dtdata=dtda.test_data, tree_length=4):\r\n\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n        self.train_dtdata = train_dtdata[0]['train']\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\r\n        self.test_dtdata = train_dtdata[0]['test']\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\n        self.pre_dtdata = pre_dtdata\r\n\r\n        # \xe4\xb8\xad\xe9\x97\xb4\xe8\xbf\x87\xe7\xa8\x8b\xe5\x8f\x98\xe9\x87\x8f\r\n        self.node_shujuji = {'0': self.train_dtdata}  # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        self.fenlei_shujuji = {'0': self.train_dtdata}  # \xe5\xad\x98\xe5\x82\xa8\xe9\x9c\x80\xe8\xa6\x81\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n\r\n        # \xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe9\x9b\x86\xe5\x90\x88\r\n        self.leafnodes = []\r\n        # \xe8\x8a\x82\xe7\x82\xb9\xe5\x85\xb3\xe7\xb3\xbb\xe5\xad\x97\xe5\x85\xb8\r\n        self.noderela = {}\r\n        # \xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe8\xa7\x84\xe5\x88\x99\xe5\x85\xb3\xe7\xb3\xbb\r\n        self.node_rule = {'0': []}\r\n\r\n        # \xe9\x81\xbf\xe5\x85\x8d\xe6\xa0\x91\xe8\xbf\x87\xe5\xa4\xa7\xef\xbc\x8c\xe9\x87\x87\xe7\x94\xa8\xe9\x99\x90\xe5\x88\xb6\xe4\xb9\xa6\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\r\n        self.tree_length = tree_length\r\n\r\n\r\n    #  \xe6\xa0\xb9\xe6\x8d\xae\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe6\x95\xb0\xe7\xbb\x84\xe8\xae\xa1\xe7\xae\x97\xe5\x9f\xba\xe5\xb0\xbc\xe6\x8c\x87\xe6\x95\xb0\r\n    def jini_zhishu(self, exlist):\r\n        dnum = 0\r\n        leng = len(exlist)\r\n        for hh in list(set(exlist)):\r\n            dnum += (list(exlist).count(hh) / leng) ** 2\r\n        return 1 - dnum\r\n\r\n    #  \xe8\xae\xa1\xe7\xae\x97\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def jini_xishu(self, tezheng, leibie):  # \xe8\xbe\x93\xe5\x85\xa5\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe7\xb1\xbb\xe5\x88\xab\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe8\xbf\x94\xe5\x9b\x9e\xe6\x9c\x80\xe5\xb0\x8f\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x80\xbc\r\n        #  \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\xe6\x98\xaf\xe8\xbf\x9e\xe7\xbb\xad\xe3\x80\x81\xe6\x88\x96\xe8\x80\x85\xe6\x98\xaf\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\r\n        sign = 0\r\n        try:\r\n            tezheng[0] + 2\r\n            # \xe8\xaf\x81\xe6\x98\x8e\xe6\x98\xaf\xe8\xbf\x9e\xe7\xbb\xad\xe7\x9a\x84\r\n            sign = 1\r\n        except TypeError:\r\n            pass\r\n        if sign:  # \xe8\xbf\x9e\xe7\xbb\xad\xe5\x8f\x98\xe9\x87\x8f\r\n            # \xe5\x8e\xbb\xe9\x87\x8d\xe3\x80\x81\xe6\x8e\x92\xe5\xba\x8f\r\n            quzhong = np.array(sorted(list(set(tezheng))))\r\n            # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe4\xb8\x8d\xe6\x98\xaf\xe5\xb0\xb1\xe4\xb8\x80\xe4\xb8\xaa\xe5\x80\xbc\r\n            if len(quzhong) == 1:\r\n                return False\r\n            # \xe5\x8f\x96\xe4\xb8\xad\xe9\x97\xb4\xe5\x80\xbc\r\n            midd = (quzhong[:-1] + quzhong[1:]) / 2\r\n            # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x81\x8d\xe5\x8e\x86\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe4\xb8\xad\xe9\x97\xb4\xe5\x80\xbc\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\r\n            length = len(leibie)\r\n            # \xe5\xad\x98\xe5\x82\xa8\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\r\n            save_ji, jini = np.inf, 0\r\n            number = ''\r\n            for mi in midd:\r\n                #  \xe8\xae\xa1\xe7\xae\x97\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\r\n                onelist = leibie[tezheng <= mi]\r\n                twolist = leibie[tezheng > mi]\r\n                jini = (len(onelist) / length) * self.jini_zhishu(onelist) + (len(twolist) / length) * self.jini_zhishu(twolist)\r\n\r\n                if jini <= save_ji:\r\n                    save_ji = jini\r\n                    number = mi\r\n            return number, save_ji\r\n        else:  #\xe5\x88\x86\xe7\xb1\xbb\xe5\x8f\x98\xe9\x87\x8f\r\n            # \xe5\x8e\xbb\xe9\x87\x8d\xe3\x80\x81\xe6\x8e\x92\xe5\xba\x8f\r\n            quzhong = np.array(list(set(tezheng)))\r\n            # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe4\xb8\x8d\xe6\x98\xaf\xe5\xb0\xb1\xe4\xb8\x80\xe4\xb8\xaa\xe5\x80\xbc\r\n            if len(quzhong) == 1:\r\n                return False\r\n            # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x81\x8d\xe5\x8e\x86\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x80\xbc\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\r\n            length = len(leibie)\r\n            # \xe5\xad\x98\xe5\x82\xa8\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\r\n            jini, save_ji = 0, np.inf\r\n            number = ''\r\n            for mi in quzhong:\r\n                #  \xe8\xae\xa1\xe7\xae\x97\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\r\n                onelist = leibie[tezheng == mi]\r\n                twolist = leibie[tezheng != mi]\r\n                jini = (len(onelist) / length) * self.jini_zhishu(onelist) + (len(twolist) / length) * self.jini_zhishu(\r\n                    twolist)\r\n                if jini <= save_ji:\r\n                    save_ji = jini\r\n                    number = mi\r\n            return number, save_ji  # \xe8\xaf\xa5\xe7\x89\xb9\xe5\xbe\x81\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe5\x88\x86\xe5\x89\xb2\xe5\x80\xbc\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xaf\xa5\xe7\x89\xb9\xe5\xbe\x81\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\r\n\r\n\r\n    # \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xa1\xae\xe5\xae\x9a\xe5\x88\x86\xe7\xb1\xbb\xe7\x89\xb9\xe5\xbe\x81\xe4\xbb\xa5\xe5\x8f\x8a\xe5\xb1\x9e\xe6\x80\xa7\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def feature_zhi(self, datadist):  # \xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\xad\x97\xe5\x85\xb8\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe7\xbc\x96\xe5\x8f\xb7\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe8\xbf\x98\xe6\x9c\x89\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\r\n        tezhengsign = ''\r\n        number = np.inf\r\n        jini = ''\r\n        for jil in range(1, len(datadist[0])):\r\n            #  \xe8\x8e\xb7\xe5\x8f\x96\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe7\xb1\xbb\xe5\x88\xab\xe6\x95\xb0\xe6\x8d\xae\r\n            tezhen = datadist[:, (jil - 1): jil].T[0]\r\n            leib = datadist[:, -1:].T[0]\r\n            # \xe5\x9c\xa8\xe5\x85\xb6\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\r\n            cresu = self.jini_xishu(tezhen, leib)\r\n            # \xe5\x88\xa4\xe6\x96\xad\xe8\xbf\x99\xe4\xb8\xaa\xe7\x89\xb9\xe5\xbe\x81\xe5\x8f\xaf\xe4\xb8\x8d\xe5\x8f\xaf\xe5\x8f\x96\r\n            if cresu:\r\n                if cresu[1] <= number:\r\n                    number = cresu[1]\r\n                    tezhengsign = jil - 1\r\n                    jini = cresu[0]\r\n        if jini != '':\r\n            return tezhengsign, jini, number  # \xe7\x89\xb9\xe5\xbe\x81\xe7\xbc\x96\xe5\x8f\xb7, \xe8\xaf\xa5\xe7\x89\xb9\xe5\xbe\x81\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe5\x88\x86\xe5\x89\xb2\xe5\x80\xbc\xef\xbc\x8c\xe8\xaf\xa5\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\r\n        else:\r\n            return False  # \xe8\xbf\x99\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x97\xa0\xe6\xb3\x95\xe8\xa2\xab\xe5\x88\x86\xe8\xa3\x82\r\n\r\n    # \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\xe5\x88\x86\xe8\xa3\x82\r\n    def devided_shujuji(self, datadis):  # \xe8\xbe\x93\xe5\x85\xa5\xe7\x89\xb9\xe5\xbe\x81\xe7\xbc\x96\xe5\x8f\xb7\xef\xbc\x8c\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\xa4\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n        # \xe8\xbf\x90\xe7\xae\x97\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n        yuansuan = self.feature_zhi(datadis)\r\n        if yuansuan:\r\n            #  \xe9\x9c\x80\xe8\xa6\x81\xe5\x88\xa4\xe6\x96\xad\xe8\xbf\x99\xe4\xb8\xaa\xe8\xa2\xab\xe9\x80\x89\xe4\xb8\xad\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe6\x98\xaf\xe8\xbf\x9e\xe7\xbb\xad\xe8\xbf\x98\xe6\x98\xaf\xe7\xa6\xbb\xe6\x95\xa3\xe7\x9a\x84\r\n            try:\r\n                datadis[:, yuansuan[0]][0] + 2\r\n                oneshujui = datadis[datadis[:, yuansuan[0]] <= yuansuan[1]]\r\n                twoshujui = datadis[datadis[:, yuansuan[0]] > yuansuan[1]]\r\n            except TypeError:\r\n                oneshujui = datadis[datadis[:, yuansuan[0]] == yuansuan[1]]\r\n                twoshujui = datadis[datadis[:, yuansuan[0]] != yuansuan[1]]\r\n            return oneshujui, twoshujui, yuansuan\r\n        else:\r\n            return False\r\n\r\n    # \xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe5\x87\xbd\xe6\x95\xb0\r\n    def grow_tree(self):\r\n        while len(self.fenlei_shujuji) != 0:\r\n            # \xe9\x9c\x80\xe8\xa6\x81\xe5\xa4\x8d\xe5\x88\xb6\xe5\xad\x97\xe5\x85\xb8\r\n            copy_dict = copy.deepcopy(self.fenlei_shujuji)\r\n            # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x81\x8d\xe5\x8e\x86\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe9\x9c\x80\xe8\xa6\x81\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n            for hd in self.fenlei_shujuji:\r\n                #  \xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe9\x99\x90\xe5\x88\xb6\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\r\n                if len(hd) == self.tree_length + 1:\r\n                    # \xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe5\x9c\xa8\xe5\x88\x86\xe8\xa3\x82\r\n                    del copy_dict[hd]\r\n                    # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\xb0\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe9\x9b\x86\xe5\x90\x88\xe4\xb8\xad\r\n                    self.leafnodes.append(hd)\r\n                else:\r\n                    fenguo = self.devided_shujuji(copy_dict[hd])\r\n                    if fenguo:\r\n                        if len(set(fenguo[0][:, -1])) == 1:  # \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe5\xb0\xb1\xe4\xb8\x8d\xe5\x86\x8d\xe5\x88\x86\xe8\xa3\x82\r\n                            self.leafnodes.append('%sl' % hd)   # \xe6\x88\x90\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n                        else:\r\n                            copy_dict['%sl' % hd] = fenguo[0]  # \xe7\xbb\xa7\xe7\xbb\xad\xe5\x88\x86\xe8\xa3\x82\r\n\r\n                        self.node_shujuji['%sl' % hd] = fenguo[0]  # \xe6\x80\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n\r\n                        # \xe6\xb7\xbb\xe5\x8a\xa0\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe8\xa7\x84\xe5\x88\x99\r\n                        self.node_rule['%sl' % hd] = (self.node_rule[hd]).copy()\r\n                        self.node_rule['%sl' % hd].append(fenguo[2])\r\n\r\n\r\n                        if len(set(fenguo[1][:, -1])) == 1:\r\n                            self.leafnodes.append('%sr' % hd)\r\n                        else:\r\n                            copy_dict['%sr' % hd] = fenguo[1]\r\n\r\n                        self.node_shujuji['%sr' % hd] = fenguo[1]\r\n\r\n                        # \xe6\xb7\xbb\xe5\x8a\xa0\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe8\xa7\x84\xe5\x88\x99\r\n                        self.node_rule['%sr' % hd] = (self.node_rule[hd]).copy()\r\n                        self.node_rule['%sr' % hd].append(fenguo[2])\r\n\r\n                        # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\xb0\xe8\x8a\x82\xe7\x82\xb9\xe5\x85\xb3\xe7\xb3\xbb\xe5\xad\x97\xe5\x85\xb8\r\n                        self.noderela[hd] = ['%sl' % hd, '%sr' % hd]\r\n\r\n                    del copy_dict[hd]  # \xe9\x9c\x80\xe8\xa6\x81\xe5\x9c\xa8\xe5\x88\x86\xe8\xa3\x82\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xb8\x80\xe4\xb8\xaa\r\n\r\n            self.fenlei_shujuji = copy.deepcopy(copy_dict)\r\n\r\n            print('\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xef\xbc\x9a', len(self.fenlei_shujuji))\r\n            print('\xe9\x9c\x80\xe8\xa6\x81\xe5\x88\x86\xe8\xa3\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xef\xbc\x9a', len(self.node_shujuji))\r\n \r\n        return 'done'\r\n\r\n    # \xe6\xa0\xb9\xe6\x8d\xae\xe6\xa0\x91\xe5\xbe\x97\xe5\x87\xba\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    def jieguo_tree(self):\r\n        # \xe6\xa0\xb9\xe6\x8d\xae\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe5\xbe\x97\xe5\x88\xb0\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n        shujuji_jieguo = {}\r\n        for shuju in self.node_shujuji:\r\n            zuihang = self.node_shujuji[shuju][:, -1]\r\n            # \xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xa4\x9a\xe7\x9a\x84\r\n            duodict = {ik: list(zuihang).count(ik) for ik in set(list(zuihang))}\r\n            # \xe5\x9c\xa8\xe5\x85\xb6\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xa4\x9a\xe7\x9a\x84\r\n            shujuji_jieguo[shuju] = max(duodict.items(), key=lambda dw: dw[1])[0]\r\n\r\n        return shujuji_jieguo\r\n\r\n    # \xe8\xa6\x81\xe5\xbe\x97\xe5\x88\xb0\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe9\x9b\x86\xe5\x90\x88\r\n    def leafnodes_tree(self):\r\n        # \xe4\xb8\x8d\xe5\x9c\xa8\xe9\x94\xae\xe5\x80\xbc\xe4\xb8\xad\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\r\n        keynodes = list(self.noderela.keys())\r\n        zhin= list(self.noderela.values())\r\n        zhinodes = []\r\n        for hhu in zhin:\r\n            for fff in hhu:\r\n                zhinodes.append(fff)\r\n        leafnodes = [jj for jj in zhinodes if jj not in keynodes]\r\n        return leafnodes\r\n\r\n\r\n    # \xe5\xaf\xbb\xe6\x89\xbe\xe4\xbb\xbb\xe4\xbd\x95\xe4\xb8\x80\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n    def iner_leaf(self, exnode):\r\n        # \xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\r\n        inernodes = list(self.noderela.keys())\r\n        # \xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n        llnodes = []\r\n        # \xe5\x85\xa8\xe9\x83\xa8\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\r\n        ghunodes = list(self.noderela.values())\r\n\r\n        gugu = []\r\n\r\n        for hhdd in ghunodes:\r\n            for ghgh in hhdd:\r\n                gugu.append(ghgh)\r\n\r\n        for jj in gugu + ['0']:\r\n            if jj not in inernodes:\r\n                if len(jj) > len(exnode) and exnode in jj:\r\n                    llnodes.append(jj)\r\n        return llnodes\r\n\r\n    # \xe5\xaf\xbb\xe6\x89\xbe\xe4\xbb\xbb\xe4\xbd\x95\xe4\xb8\x80\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xb8\x8b\xe5\xb1\x9e\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\r\n    def xiashu_leaf(self, exnode):\r\n        # \xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n        xiashunodes = []\r\n        # \xe5\x85\xa8\xe9\x83\xa8\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\r\n        godes = list(self.noderela.values())\r\n\r\n        gug = []\r\n\r\n        for hhdd in godes:\r\n            for ghgh in hhdd:\r\n                gug.append(ghgh)\r\n\r\n        for jj in gug + ['0']:\r\n            if exnode in jj:\r\n                xiashunodes.append(jj)\r\n        return xiashunodes\r\n\r\n\r\n    # \xe5\x88\xa4\xe8\xaf\xbb\xe6\x95\xb0\xe6\x8d\xae\xe6\x98\xaf\xe5\x90\xa6\xe7\xac\xa6\xe5\x90\x88\xe8\xbf\x99\xe4\xb8\xaa\xe8\xa7\x84\xe7\x9f\xa9\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def judge_data(self, data, signstr, guize):\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9e\xe7\xbb\xad\xe6\x88\x96\xe8\x80\x85\xe6\x98\xaf\xe7\xa6\xbb\xe6\x95\xa3\r\n        fign = 0\r\n        try:\r\n            data[guize[0]] + 2\r\n            fign = 1\r\n        except TypeError:\r\n            pass\r\n        if fign == 1:  # \xe8\xbf\x9e\xe7\xbb\xad\r\n            if signstr == 'r':\r\n                if data[guize[0]] > guize[1]:\r\n                    return True\r\n                return False\r\n            elif signstr == 'l':\r\n                if data[guize[0]] <= guize[1]:\r\n                    return True\r\n                return False\r\n        elif fign == 0:  # \xe7\xa6\xbb\xe6\x95\xa3\r\n            if signstr == 'r':\r\n                if data[guize[0]] != guize[1]:\r\n                    return True\r\n                return False\r\n            elif signstr == 'l':\r\n                if data[guize[0]] == guize[1]:\r\n                    return True\r\n                return False\r\n\r\n\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0, \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\xe5\xad\x97\xe5\x85\xb8\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xa7\x84\xe5\x88\x99\xe3\x80\x81\xe6\xaf\x8f\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe8\x8e\xb7\xe5\xbe\x97\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    def pre_tree(self, predata):\r\n        # \xe6\xaf\x8f\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n        meire = self.jieguo_tree()\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\r\n        savresu = []\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe6\xa0\xb9\xe6\x8d\xae\xe8\x8a\x82\xe7\x82\xb9\xe5\x85\xb3\xe7\xb3\xbb\xe6\x89\xbe\xe5\x88\xb0\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n        yezinodes = self.leafnodes_tree()\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe5\x88\xa4\xe6\x96\xad\xe6\x95\xb0\xe6\x8d\xae\r\n        for jj in predata:\r\n            shuju = jj[: -1]\r\n            # \xe5\xbc\x80\xe5\xa7\x8b\xe5\x88\xa4\xe6\x96\xad\r\n            for yy in yezinodes:\r\n                gu = 1\r\n                guide = self.node_rule[yy]\r\n                for iu, ju in zip(yy[1:], guide):\r\n                    if not self.judge_data(shuju, iu, ju):\r\n                        gu = 0\r\n                        break\r\n                if gu == 1:\r\n                    savresu.append(meire[yy])\r\n        return savresu\r\n\r\n\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe5\x89\xaa\xe6\x9e\x9d\xe7\x9a\x84\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\r\n    def jianzhi_iner(self, exnode):\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe5\xbe\x97\xe5\x88\xb0\xe6\x95\xb4\xe4\xbd\x93\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\r\n        leng = len(self.train_dtdata)\r\n        # # \xe5\x9c\xa8\xe5\xbe\x97\xe5\x88\xb0\xe6\x9c\xac\xe8\x8a\x82\xe7\x82\xb9\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6,\xe6\xad\xa4\xe9\xa1\xb9\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xa2\xab\xe6\xb6\x88\xe5\x8e\xbb\r\n        # benleng = len(self.node_shujuji[exnode])\r\n\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe8\xa2\xab\xe9\x94\x99\xe8\xaf\xaf\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\x9d\xa1\xe6\x95\xb0\r\n        self.node_result = self.jieguo_tree()\r\n        cuowu_leng = len(self.node_shujuji[exnode][self.node_shujuji[exnode][:, -1] != self.node_result[exnode]])\r\n        # \xe8\xae\xa1\xe7\xae\x97\r\n        jinum = cuowu_leng / leng\r\n        return jinum\r\n\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xb8\x8b\xe5\xb1\x9e\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\xe4\xb9\x8b\xe5\x92\x8c\r\n    def iner_sum(self, ecnode):\r\n        jnum = 0\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe5\xbe\x97\xe5\x88\xb0\xe8\xbf\x99\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe4\xb8\x8b\xe5\xb1\x9e\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n        for hhh in self.iner_leaf(ecnode):\r\n            jnum += self.jianzhi_iner(hhh)\r\n        return jnum\r\n\r\n\r\n    # \xe6\xa0\x91\xe7\x9a\x84\xe5\x89\xaa\xe6\x9e\x9d\xef\xbc\x8c \xe6\xaf\x8f\xe4\xb8\x80\xe6\xa3\xb5\xe6\xa0\x91\xe9\x83\xbd\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f\xef\xbc\x88\xe8\x8a\x82\xe7\x82\xb9\xe5\x85\xb3\xe7\xb3\xbb\xe5\xb0\xb1\xe4\xbb\xa3\xe8\xa1\xa8\xe4\xb8\x80\xe6\xa3\xb5\xe5\xad\x90\xe6\xa0\x91\xef\xbc\x89\r\n    def prue_tree(self):\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe5\x89\xaa\xe6\x9e\x9d\r\n        tree_set = {}\r\n        # a\xe5\x80\xbc\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        adict = {}\r\n\r\n        # \xe7\xac\xac\xe4\xb8\x80\xe6\xa3\xb5\xe5\xae\x8c\xe5\x85\xa8\xe7\x94\x9f\xe9\x95\xbf\xe7\x9a\x84\xe6\xa0\x91\r\n        sign = 0\r\n        tree_set[sign] = self.noderela.copy()\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe5\x89\xaa\xe6\x9e\x9d\r\n        while len(list(self.noderela.keys())) != 0:\r\n            # \xe5\xa4\x8d\xe5\x88\xb6\xe5\xad\x97\xe5\x85\xb8\r\n            coppdict = self.noderela.copy()\r\n            # \xe5\xad\x98\xe5\x82\xa8\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe5\x89\xaa\xe6\x9e\x9d\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n            saveiner = {}\r\n            for jiner in list(self.noderela.keys()):\r\n                # \xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe8\xae\xa1\xe7\xae\x97\r\n                saveiner[jiner] = (self.jianzhi_iner(jiner) - self.iner_sum(jiner)) / (len(self.iner_leaf(jiner)) - 1)\r\n            # \xe9\x80\x89\xe6\x8b\xa9\xe5\x85\xb6\xe4\xb8\xad\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe6\x9c\x892\xe4\xb8\xaa\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe9\x95\xbf\xe7\x9a\x84\r\n            numm = np.inf\r\n            dd = ''\r\n            for hji in saveiner:\r\n                if numm > saveiner[hji]:\r\n                    dd = hji\r\n                    numm = saveiner[hji]\r\n                elif numm == saveiner[hji]:\r\n                    if len(dd) < len(hji):\r\n                        dd = hji\r\n            # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\xb0a\xe5\x80\xbc\r\n            adict[sign] = numm\r\n            # \xe9\x9c\x80\xe8\xa6\x81\xe5\x88\xa0\xe9\x99\xa4hji\xe8\xbf\x99\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\r\n            # \xe9\xa6\x96\xe9\x80\x89\xe5\xbe\x97\xe5\x88\xb0\xe8\xbf\x99\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\r\n            for hco in self.xiashu_leaf(dd):\r\n                if hco in coppdict:\r\n                    del coppdict[hco]\r\n            # \xe6\xa0\x91\xe5\x8a\xa01\r\n            sign += 1\r\n            self.noderela = coppdict.copy()\r\n            tree_set[sign] = self.noderela.copy()\r\n        return tree_set, adict\r\n\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def compuer_correct(self, exli_real, exli_pre):\r\n        if len(exli_pre) == 0:\r\n            return 0\r\n        else:\r\n            corr = np.array(exli_pre)[np.array(exli_pre) == np.array(exli_real)]\r\n            return len(corr) / len(exli_pre)\r\n\r\n    # \xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe5\x87\xbd\xe6\x95\xb0\r\n    def jiaocha_tree(self, treeset):  #\xe8\xbe\x93\xe5\x87\xba\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\xa0\x91\r\n        # \xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        correct = {}\r\n\r\n        # \xe9\x81\x8d\xe5\x8e\x86\xe6\xa0\x91\xe7\x9a\x84\xe9\x9b\x86\xe5\x90\x88\r\n        for jj in treeset:\r\n            self.noderela = treeset[jj]\r\n            yuce = self.pre_tree(self.test_dtdata)\r\n            # \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n            real = self.test_dtdata[:, -1]\r\n            # \xe8\xae\xa1\xe7\xae\x97\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n            correct[jj] = self.compuer_correct(real, yuce)\r\n        # \xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe6\x9c\x89\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84\xef\xbc\x8c\xe8\x8e\xb7\xe5\x8f\x96\xe6\x95\xb0\xe7\x9b\xae\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe9\x94\xae\r\n        num = 0\r\n        leys = ''\r\n        for jj in correct:\r\n            if correct[jj] > num:\r\n                num = correct[jj]\r\n                leys = jj\r\n            elif num == correct[jj]:\r\n                if jj < leys:\r\n                    leys = jj\r\n        return treeset[leys], num\r\n\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\nfrom pylab import mpl\r\nmpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams['axes.unicode_minus'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe3\x80\x82\xe7\x9c\x8b\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\r\nif __name__ == '__main__':\r\n    # \xe6\xa0\xb9\xe6\x8d\xae\xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6\xef\xbc\x8c\xe7\x9c\x8b\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\r\n    xunliande = []\r\n    yazhengde = []\r\n    yucede = []\r\n\r\n    for shendu in range(2, 13):\r\n\r\n        uu = DT(tree_length=shendu)\r\n        # \xe5\xae\x8c\xe5\x85\xa8\xe6\x88\x90\xe9\x95\xbf\xe7\x9a\x84\xe6\xa0\x91\r\n        uu.grow_tree()\r\n        # \xe5\x89\xaa\xe6\x9e\x9d\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\xa0\x91\xe7\x9a\x84\xe9\x9b\x86\r\n        gu = uu.prue_tree()\r\n        # \xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa0\x91\r\n        cc = uu.jiaocha_tree(gu[0])\r\n        # \xe6\xa0\xb9\xe6\x8d\xae\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa0\x91\xe9\xa2\x84\xe6\xb5\x8b\xe6\x96\xb0\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n        uu.noderela = cc[0]\r\n        prenum = uu.pre_tree(uu.pre_dtdata)\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\r\n        yazhengde.append(cc[1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\r\n        yucede.append(uu.compuer_correct(uu.pre_dtdata[:, -1], prenum))\r\n        # \xe8\xae\xad\xe7\xbb\x83\r\n        trainnum = uu.pre_tree(uu.train_dtdata)\r\n        xunliande.append(uu.compuer_correct(uu.train_dtdata[:, -1], trainnum))\r\n\r\n        print(xunliande, yazhengde, yucede)\r\n\r\n        print('dddddddddddddddddddd', shendu)\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\r\n    plt.plot(list(range(2, 13)), xunliande, 'o--', label='\xe8\xae\xad\xe7\xbb\x83', lw=2)\r\n    plt.plot(list(range(2, 13)), yazhengde, '*--', label='\xe9\xaa\x8c\xe8\xaf\x81', lw=2)\r\n    plt.plot(list(range(2, 13)), yucede, 's--', label='\xe9\xa2\x84\xe6\xb5\x8b', lw=2)\r\n    plt.xlabel('\xe6\xa0\x91\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6')\r\n    plt.xlim(1, 14)\r\n\r\n    plt.ylabel('\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87')\r\n    plt.legend(shadow=True, fancybox=True)\r\n    plt.show()\r\n"""
Decision Tree/DT_Classify/AnFany_DT_Iris.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport AnFany_DT_Classify as model\r\nimport Irisdata_DT_Anfany as dtda\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\nfrom pylab import mpl\r\nmpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams['axes.unicode_minus'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe3\x80\x82\xe7\x9c\x8b\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\r\nif __name__ == '__main__':\r\n    # \xe6\xa0\xb9\xe6\x8d\xae\xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6\xef\xbc\x8c\xe7\x9c\x8b\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\r\n    xunliande = []\r\n    yazhengde = []\r\n    yucede = []\r\n\r\n    for shendu in range(2, 13):\r\n\r\n        uu = model.DT(train_dtdata=dtda.dt_data, pre_dtdata=dtda.test_data, tree_length=shendu)\r\n        # \xe5\xae\x8c\xe5\x85\xa8\xe6\x88\x90\xe9\x95\xbf\xe7\x9a\x84\xe6\xa0\x91\r\n        uu.grow_tree()\r\n        # \xe5\x89\xaa\xe6\x9e\x9d\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\xa0\x91\xe7\x9a\x84\xe9\x9b\x86\r\n        gu = uu.prue_tree()\r\n        # \xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa0\x91\r\n        cc = uu.jiaocha_tree(gu[0])\r\n        # \xe6\xa0\xb9\xe6\x8d\xae\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa0\x91\xe9\xa2\x84\xe6\xb5\x8b\xe6\x96\xb0\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n        uu.noderela = cc[0]\r\n        prenum = uu.pre_tree(uu.pre_dtdata)\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\r\n        yazhengde.append(cc[1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\r\n        yucede.append(uu.compuer_correct(uu.pre_dtdata[:, -1], prenum))\r\n        # \xe8\xae\xad\xe7\xbb\x83\r\n        trainnum = uu.pre_tree(uu.train_dtdata)\r\n        xunliande.append(uu.compuer_correct(uu.train_dtdata[:, -1], trainnum))\r\n\r\n        print(xunliande, yazhengde, yucede)\r\n\r\n        print('dddddddddddddddddddd', shendu)\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\r\n    plt.plot(list(range(2, 13)), xunliande, 'o--', label='\xe8\xae\xad\xe7\xbb\x83', lw=3)\r\n    plt.plot(list(range(2, 13)), yazhengde, '*--', label='\xe9\xaa\x8c\xe8\xaf\x81', lw=3)\r\n    plt.plot(list(range(2, 13)), yucede, 's--', label='\xe9\xa2\x84\xe6\xb5\x8b', lw=3)\r\n    plt.xlabel('\xe6\xa0\x91\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6')\r\n    plt.xlim(1, 14)\r\n    plt.ylim(min([min(xunliande), min(yazhengde), min(yucede)]) - 0.1, max([max(xunliande), max(yazhengde), max(yucede)]) + 0.1)\r\n    plt.ylabel('\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87')\r\n    plt.grid()\r\n    plt.legend(shadow=True, fancybox=True)\r\n    plt.show()"""
Decision Tree/DT_Classify/AnFany_Show_Tree.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\n# \xe8\x87\xaa\xe9\x80\x82\xe5\xba\x94\xe4\xbc\x98\xe5\x8c\x96\xe7\xbb\x98\xe5\x88\xb6\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe7\xa8\x8b\xe5\xba\x8f\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x86\xb3\xe7\xad\x96\xe5\x9b\xbe\xe4\xb8\xbb\xe8\xa6\x81\xe5\x8c\x85\xe6\x8b\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\r\n# 1\xef\xbc\x8c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9(\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe5\xb1\x95\xe7\xa4\xba\xef\xbc\x8c\xe8\x8a\x82\xe7\x82\xb9\xe5\x90\x8d\xe7\xa7\xb0\xef\xbc\x8c\xe7\xb1\xbb\xe5\x88\xab\xe6\xaf\x94\xe4\xbe\x8b\xef\xbc\x8c\xe5\x88\x86\xe7\xb1\xbb\xe7\x89\xb9\xe5\xbe\x81\xef\xbc\x8c\xe6\x9c\xac\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c, \xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xe6\xb2\xa1\xe6\x9c\x89\xe5\x88\x86\xe7\xb1\xbb\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9)\r\n# 2\xef\xbc\x8c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\xef\xbc\x88\xe5\x9e\x82\xe7\x9b\xb4\xe6\x96\xb9\xe5\x90\x91\xe5\xb9\xb3\xe5\x9d\x87\xe5\x88\x86\xe9\x85\x8d\xef\xbc\x8c\xe6\xb0\xb4\xe5\xb9\xb3\xe6\x96\xb9\xe5\x90\x91\xe6\x8c\x89\xe7\x85\xa7\xe8\xbf\x99\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\xe4\xb8\xaa\xe6\x95\xb0\xe5\xb9\xb3\xe5\x9d\x87\xe5\x88\x86\xe9\x85\x8d\xef\xbc\x89\r\n# 3\xef\xbc\x8c\xe7\xa1\xae\xe5\xae\x9a\xe8\x8a\x82\xe7\x82\xb9\xe4\xb9\x8b\xe9\x97\xb4\xe7\x9a\x84\xe8\xbf\x9e\xe7\xba\xbf\r\n# 4\xef\xbc\x8c\xe5\xb1\x95\xe7\xa4\xba\xe8\xbf\x9e\xe7\xba\xbf\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x88\xe5\x88\x86\xe7\xb1\xbb\xe8\xa7\x84\xe5\x88\x99\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x88\x86\xe5\x88\x86\xe5\x89\xb2\xe5\x80\xbc\xef\xbc\x89\r\n# 5\xef\xbc\x8c\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x8c\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xe4\xbb\xa5\xe4\xb8\x8d\xe7\x94\xa8\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\xe5\xb1\x95\xe7\xa4\xba\xef\xbc\x8c\xe5\xaf\xb9\xe7\xbb\x99\xe5\x87\xba\xe5\x9b\xbe\xe4\xbe\x8b\r\n\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe3\x80\x81\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe3\x80\x81\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe8\xa7\x84\xe5\x88\x99\xe3\x80\x81\xe5\x89\xaa\xe6\x9e\x9d\xe5\x90\x8e\xe4\xbb\xa3\xe8\xa1\xa8\xe7\x9d\x80\xe6\xa0\x91\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\xe5\x85\xb3\xe7\xb3\xbb\xe7\xbb\x98\xe5\x88\xb6\xe6\xa0\x91\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe7\xbb\x98\xe5\x88\xb6\xe6\xa0\x91\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe4\xbf\xa1\xe6\x81\xaf\r\nimport AnFany_DT_Classify as tree\r\n\r\n# \xe8\x8e\xb7\xe5\xbe\x97\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\xe7\xa7\xb0\r\nziduan = [\'Age\', \'workclass\', \'fnlwgt\', \'education\', \'education-num\', \'marital-status\', \'occupation\', \'relationship\', \'race\', \'sex\',\\\r\n          \'capital-gain\', \'capital-loss\', \'hours-per-week\', \'native-country\']\r\n\r\n\'\'\'\xe5\x87\x86\xe5\xa4\x87\xe9\x83\xa8\xe5\x88\x86\'\'\'\r\n#  \xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\r\ndef allnodes(guanxi):\r\n    allnode = list(guanxi.keys())\r\n    for jj in guanxi:\r\n        for hhh in guanxi[jj]:\r\n            if hhh not in allnode:\r\n                allnode.append(hhh)\r\n    #  \xe4\xb9\x8b\xe6\x89\x80\xe4\xbb\xa5\xe8\xa6\x81\xe6\x8c\x89\xe9\xa1\xba\xe5\xba\x8f\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x8c\xe6\x98\xaf\xe5\x9b\xa0\xe4\xb8\xba\xe5\x85\x88\xe7\x94\xbb\xe7\x88\xb6\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x8c\xe5\x90\x8e\xe7\x94\xbb\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb0\x86\xe7\xae\xad\xe5\xa4\xb4\xe7\x9b\x96\xe4\xbd\x8f\xef\xbc\x8c\xe6\x9b\xb4\xe4\xb8\xba\xe7\xbe\x8e\xe8\xa7\x82\r\n    return sorted(allnode)\r\n\r\n# \xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\ndef leafnodes(guanxi):\r\n    allnode = list(guanxi.keys())\r\n    leafnode = []\r\n    for jj in guanxi:\r\n        for hhh in guanxi[jj]:\r\n            if hhh not in allnode:\r\n                leafnode.append(hhh)\r\n    return leafnode\r\n\r\n# \xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\r\ndef noye_node(guanxi):\r\n    return list(guanxi.keys())\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xb1\x95\xe7\xa4\xba\xe5\x86\x85\xe5\xae\xb9\'\'\'\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe8\xbe\x93\xe5\x87\xba\xe5\x90\x84\xe7\xb1\xbb\xe5\x88\xab\xe4\xb9\x8b\xe9\x97\xb4\xe7\x9a\x84\xe6\xaf\x94\xe5\x80\xbc\r\ndef output(shujuji, guanxi):\r\n    #  \xe5\xad\x97\xe5\x85\xb8\r\n    leibie = {}\r\n    for jjj in allnodes(guanxi):\r\n        leibie[jjj] = []\r\n        cu = list(shujuji[jjj][:, -1])\r\n        gu = sorted(list(set(list(shujuji[jjj][:, -1]))))\r\n        for du in gu:\r\n            leibie[jjj].append([du, cu.count(du)])  # \xe5\x90\x84\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe5\x8f\x8a\xe5\x85\xb6\xe6\x95\xb0\xe9\x87\x8f\r\n    return leibie\r\n\r\n# \xe8\x8a\x82\xe7\x82\xb9\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe3\x80\x81\xe8\x8a\x82\xe7\x82\xb9\xe7\xbb\x93\xe6\x9e\x9c\xe3\x80\x81\xe8\x8a\x82\xe7\x82\xb9\xe8\xa7\x84\xe5\x88\x99\xe7\xbb\x98\xe5\x88\xb6\xe6\xa0\x91\r\n# \xe5\x88\xb6\xe4\xbd\x9c\xe8\x8a\x82\xe7\x82\xb9\xe9\x87\x8c\xe9\x9d\xa2\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\r\ndef dingyistr(shujuji, reeult, guize, guanxi, zian):\r\n    # \xe8\xa7\x84\xe5\x88\x99\xe5\xad\x97\xe5\x85\xb8\r\n    guizezidian = {}\r\n    #  \xe7\xb1\xbb\xe5\x88\xab\xe5\xad\x97\xe5\x85\xb8\r\n    leibii = output(shujuji, guanxi)\r\n    # \xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\xad\x97\xe5\x85\xb8\r\n    strdict = {}\r\n    # \xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\r\n    nonode = noye_node(guanxi)\r\n    # \xe9\x81\x8d\xe5\x8e\x86\xe9\x9c\x80\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x8c\xe8\x8e\xb7\xe5\xbe\x97\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe9\x9c\x80\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\x86\x85\xe5\xae\xb9\r\n    for jjj in allnodes(guanxi):\r\n        # \xe4\xb8\xba\xe8\x8a\x82\xe7\x82\xb9\xe6\xb7\xbb\xe5\x8a\xa0\xe5\x90\x8d\xe7\xa7\xb0\r\n        strdict[jjj] = \'\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x9a%s \\n\' % jjj  # \xe5\x86\x85\xe5\xae\xb9\xe5\x88\x86\xe8\xa1\x8c\r\n        # \xe5\xa6\x82\xe6\x9e\x9c\xe4\xb8\x8d\xe6\x98\xaf\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x8c\xe5\x88\x99\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\xb7\xbb\xe5\x8a\xa0\xe7\x89\xb9\xe5\xbe\x81\xef\xbc\x8c\xe5\x8f\xaa\xe6\xb7\xbb\xe5\x8a\xa0\xe5\x90\x84\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\r\n        if jjj not in nonode:\r\n            hu = \'\xe5\x8d\xa0\xe6\xaf\x94\xef\xbc\x9a\'\r\n            for fu in leibii[jjj]:\r\n                hu += \'%d:\' % fu[1]\r\n            strdict[jjj] += \'%s \\n\' % hu[:-1]\r\n        #  \xe5\xaf\xb9\xe4\xba\x8e\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe9\x9c\x80\xe8\xa6\x81\xe5\xa4\x9a\xe5\xa1\xab\xe5\x8a\xa0\xe4\xb8\x80\xe4\xb8\xaa\xe5\x88\x86\xe7\xb1\xbb\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xe3\x80\x81\xe5\x92\x8c\xe8\xa7\x84\xe5\x88\x99\r\n        else:\r\n            hu = \'\xe5\x8d\xa0\xe6\xaf\x94\xef\xbc\x9a\'\r\n            for fu in leibii[jjj]:\r\n                hu += \'%d:\' % fu[1]\r\n            strdict[jjj] += \'%s \\n\' % hu[:-1]\r\n            # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\x86\xe7\xb1\xbb\xe7\x89\xb9\xe5\xbe\x81\r\n            strdict[jjj] += \'\xe7\x89\xb9\xe5\xbe\x81\xef\xbc\x9a%s \\n\' % zian[guize[\'%s\' % (jjj + \'r\')][-1][0]]\r\n\r\n            # \xe6\xb7\xbb\xe5\x8a\xa0\xe8\xa7\x84\xe5\x88\x99\r\n            sign = 0\r\n            try:\r\n                guize[\'%s\' % (jjj + \'r\')][-1][1] + 1\r\n                sign = 1\r\n            except TypeError:\r\n                pass\r\n            if sign == 0:\r\n                guizezidian[jjj + \'l\'] = \'\xe5\x80\xbc\xe4\xb8\xba\xef\xbc\x9a\\n %s\' % guize[\'%s\' % (jjj + \'r\')][-1][1]\r\n                guizezidian[jjj + \'r\'] = \'\xe5\x80\xbc\xe4\xb8\x8d\xe4\xb8\xba\xef\xbc\x9a\\n %s\' % guize[\'%s\' % (jjj + \'r\')][-1][1]\r\n            else:\r\n                guizezidian[jjj + \'l\'] = \'\xe5\x80\xbc\xe4\xb8\x8d\xe5\xa4\xa7\xe4\xba\x8e\xef\xbc\x9a\\n %s\' % guize[\'%s\' % (jjj + \'r\')][-1][1]\r\n                guizezidian[jjj + \'r\'] = \'\xe5\x80\xbc\xe5\xa4\xa7\xe4\xba\x8e\xef\xbc\x9a\\n %s\' % guize[\'%s\' % (jjj + \'r\')][-1][1]\r\n\r\n        # \xe4\xb8\xba\xe9\x9c\x80\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\xe6\xb7\xbb\xe5\x8a\xa0\xe7\xbb\x93\xe6\x9e\x9c\r\n        strdict[jjj] += \'\xe7\xbb\x93\xe6\x9e\x9c\xef\xbc\x9a%s \' % reeult[jjj]\r\n    return strdict, guizezidian  # \xe5\x88\x86\xe5\x88\xab\xe8\xbf\x94\xe5\x9b\x9e\xe8\x8a\x82\xe7\x82\xb9\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xe5\xad\x97\xe5\x85\xb8\xe3\x80\x81\xe8\xbf\x9e\xe7\xba\xbf\xe4\xb8\x8a\xe9\x9c\x80\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xe5\xad\x97\xe5\x85\xb8\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\'\'\'\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8a\x82\xe7\x82\xb9\xe5\x90\x8d\xe7\xa7\xb0\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe9\x95\xbf\xe5\xba\xa6\xef\xbc\x8c\xe7\xa1\xae\xe5\xae\x9a\xe7\x94\xbb\xe5\xb8\x83\xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f\r\ndef huabu(guanxi):\r\n    # \xe8\x8e\xb7\xe5\xbe\x97\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\r\n    suoyounodes = allnodes(guanxi)\r\n    # \xe8\x8e\xb7\xe5\x8f\x96\xe6\x9c\x80\xe9\x95\xbf\xe8\x8a\x82\xe7\x82\xb9\xe5\x90\x8d\xe7\xa7\xb0\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\xaa\xe9\x95\xbf\xe5\xba\xa6\xe5\x90\x8c\xe6\x97\xb6\xe4\xb9\x9f\xe6\x98\xaf\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe3\x80\x82\r\n    changdu = max(len(i) for i in suoyounodes)\r\n    # \xe8\xbf\x94\xe5\x9b\x9e\xe9\x95\xbf\xe5\xba\xa6\xe4\xbb\xa5\xe5\x8f\x8a\xe7\x94\xbb\xe5\xb8\x83\xe5\xa4\xa7\xe5\xb0\x8f\r\n    return changdu + 1, 2**max(6, changdu)\r\n\r\n\r\n# \xe6\xb0\xb4\xe5\xb9\xb3\xe6\x94\xbe\xe4\xb8\x8b\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\xef\xbc\x8c\xe6\x98\xaf\xe6\xa0\xb9\xe6\x8d\xae\xe8\xbf\x99\xe4\xb8\x80\xe5\xb1\x82\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe3\x80\x81\xe4\xbb\xa5\xe5\x8f\x8a\xe6\xad\xa4\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe9\xa1\xba\xe5\xba\x8f\xe7\xa1\xae\xe5\xae\x9a\xe7\x9a\x84\r\ndef getorder(exnode, guanxi):\r\n    fu = []\r\n    for jj in allnodes(guanxi):\r\n        if len(jj) == len(exnode):\r\n            fu.append(jj)\r\n    # \xe6\x8e\x92\xe5\xba\x8f\r\n    sfu = sorted(fu)\r\n    return len(sfu) + 1, sfu.index(exnode) + 1 #\xe5\x89\x8d\xe8\x80\x85\xe5\x8a\xa01\xe6\x98\xaf\xe8\xae\xa1\xe7\xae\x97\xe9\x97\xb4\xe9\x9a\x94\xef\xbc\x8c\xe5\x90\x8e\xe8\x80\x85\xe5\x8a\xa01\xe6\x98\xaf\xe5\x9b\xa0\xe4\xb8\xbaindex\xe4\xbb\x8e0\xe5\xbc\x80\xe5\xa7\x8b\r\n\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe7\x94\xbb\xe5\xb8\x83\xe5\xa4\xa7\xe5\xb0\x8f\xe5\xae\x9a\xe4\xb9\x89\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe6\xa8\xaa\xe7\xba\xb5\xe5\x9d\x90\xe6\xa0\x87\xe4\xbd\x8d\xe7\xbd\xae\r\ndef jiedian_location(guanxi):\r\n    # \xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xef\xbc\x8c\xe7\x94\xbb\xe5\xb8\x83\xe5\xa4\xa7\xe5\xb0\x8f\r\n    shushen, huahuabu = huabu(guanxi)\r\n\r\n    # \xe8\xbf\x94\xe5\x9b\x9e\xe6\xaf\x8f\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe5\x9d\x90\xe6\xa0\x87\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    loca = {}\r\n    # \xe9\xa6\x96\xe5\x85\x88\xe5\xb0\x86\xe8\x8a\x82\xe7\x82\xb9\xe5\x90\x8d\xe7\xa7\xb0\xe6\x8c\x89\xe7\x85\xa7\xe9\x95\xbf\xe5\xba\xa6\xe7\xbb\x84\xe6\x88\x90\xe5\xad\x97\xe5\x85\xb8\r\n    changdu = {}\r\n    for jj in allnodes(guanxi):\r\n        try:\r\n            changdu[len(jj)].append(jj)\r\n        except KeyError:\r\n            changdu[len(jj)] = [jj]\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xa1\xae\xe5\xae\x9a\xe9\x9c\x80\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\r\n    for fi in allnodes(guanxi):\r\n        if fi not in loca:\r\n            for gu in changdu[len(fi)]:  # \xe5\x90\x8c\xe5\xb1\x82\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x88\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe8\x8a\x82\xe7\x82\xb9\xe5\x90\x8d\xe7\xa7\xb0\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\xef\xbc\x89\xe4\xb8\x80\xe8\xb5\xb7\xe8\xae\xa1\xe7\xae\x97\r\n                number = getorder(gu, guanxi)\r\n                loca[gu] = [huahuabu / number[0] * number[1], huahuabu - (huahuabu / shushen) * len(gu)]\r\n    return loca\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\x87\x86\xe5\xa4\x87\xe5\xb7\xa5\xe4\xbd\x9c\xe7\xbb\x93\xe6\x9d\x9f\xef\xbc\x8c\xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x9b\xbe\'\'\'\r\n\r\n# \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x9b\xbe\r\ndef draw_tree(shujuji, result, guize, guanxi, zian=ziduan):\r\n    # \xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\x86\x85\xe5\xae\xb9\r\n    strziu = dingyistr(shujuji, result, guize, guanxi, zian)\r\n    # \xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\r\n    weihzi = jiedian_location(guanxi)\r\n\r\n    noyye = noye_node(guanxi)\r\n\r\n    # \xe7\x94\xbb\xe5\xb8\x83\xe7\x9a\x84\xe8\xae\xbe\xe7\xbd\xae\r\n    huab = huabu(guanxi)[1] + 2  # \xe4\xb8\x8a\xe4\xb8\x8b\xe5\xb7\xa6\xe5\x8f\xb3\xe9\xa2\x84\xe7\x95\x99\xe7\xa9\xba\xe9\x97\xb4\r\n\r\n    fig, ax = plt.subplots(figsize=(huab, huab))\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x88\xb6\r\n    for jj in allnodes(guanxi):\r\n        print(jj)\r\n        # \xe7\xbb\x98\xe5\x88\xb6\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\r\n        # \xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\r\n        if jj in noyye:\r\n            ax.text(weihzi[jj][0], weihzi[jj][1], strziu[0][jj], size=13, rotation=0.,\r\n                    ha=""center"", va=""center"",\r\n                    bbox=dict(boxstyle=""round"",\r\n                              ec=(0.6, 0.2, 0.6),\r\n                              fc=(0.3, 0.6, 0.3),\r\n                              )\r\n                    )\r\n        # \xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n        else:\r\n            ax.text(weihzi[jj][0], weihzi[jj][1], strziu[0][jj], size=13, rotation=0.,\r\n                    ha=""center"", va=""center"",\r\n                    bbox=dict(boxstyle=""round"",\r\n                              ec=(0.2, 0.5, 0.2),\r\n                              fc=(0.5, 0.2, 0.5),\r\n                              )\r\n                    )\r\n\r\n        # \xe5\x8f\xaa\xe5\xaf\xb9\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe7\xbb\x98\xe5\x88\xb6\xe7\xae\xad\xe5\xa4\xb4\xe5\x92\x8c\xe5\xb7\xa6\xe5\x8f\xb3\xe7\x9a\x84\xe5\x88\x86\xe7\xb1\xbb\xe8\xa7\x84\xe5\x88\x99\r\n        if jj in noyye:\r\n            # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\xb7\xa6\xe5\x8f\xb3\xe7\xae\xad\xe5\xa4\xb4\r\n\r\n            ax.annotate(\' \', xy=(weihzi[jj + \'r\'][0], weihzi[jj + \'r\'][1]), xytext=(weihzi[jj][0], weihzi[jj][1]), ha=""center"", va=""center"",\r\n                        arrowprops=dict(facecolor=\'darkred\', shrink=0.128))\r\n\r\n            ax.annotate(\' \', xy=(weihzi[jj + \'l\'][0], weihzi[jj + \'l\'][1]), xytext=(weihzi[jj][0], weihzi[jj][1]),\r\n                        ha=""center"", va=""center"", arrowprops=dict(facecolor=\'darkred\', shrink=0.128))\r\n\r\n\r\n            # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\xb7\xa6\xe5\x8f\xb3\xe8\xa7\x84\xe5\x88\x99\r\n            ax.text((weihzi[jj + \'l\'][0] + weihzi[jj][0]) / 2, \\\r\n                    (weihzi[jj + \'l\'][1] + weihzi[jj][1]) / 2 - 0.2, strziu[1][jj + \'l\'], fontsize=12, color=\'red\', weight=\'bold\')\r\n\r\n            ax.text((weihzi[jj + \'r\'][0] + weihzi[jj][0]) / 2, \\\r\n                    (weihzi[jj + \'r\'][1] + weihzi[jj][1]) / 2 - 0.2, strziu[1][jj + \'r\'], fontsize=12, color=\'red\', weight=\'bold\')\r\n\r\n    ax.set(xlim=(0, huab), ylim=(0, huab))\r\n\r\n    plt.show()\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe3\x80\x82\xe7\x9c\x8b\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\r\nif __name__ == \'__main__\':\r\n    # \xe8\x8e\xb7\xe5\xbe\x97\xe6\xa0\x91\xe7\x9a\x84\xe4\xbf\xa1\xe6\x81\xaf\r\n\r\n    decision_tree = tree.DT()\r\n    # \xe5\xae\x8c\xe5\x85\xa8\xe6\x88\x90\xe9\x95\xbf\xe7\x9a\x84\xe6\xa0\x91\r\n    decision_tree.grow_tree()\r\n    # \xe5\x89\xaa\xe6\x9e\x9d\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\xa0\x91\xe7\x9a\x84\xe9\x9b\x86\r\n    gu = decision_tree.prue_tree()\r\n    # \xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa0\x91\r\n    cc = decision_tree.jiaocha_tree(gu[0])\r\n    print(cc[0])\r\n    # \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    shuju = decision_tree.node_shujuji\r\n    # \xe7\xbb\x93\xe6\x9e\x9c\r\n    jieguo = decision_tree.jieguo_tree()\r\n    # \xe8\xa7\x84\xe5\x88\x99\r\n    rule = decision_tree.node_rule\r\n    draw_tree(shuju, jieguo, rule, cc[0])\r\n\r\n\r\n'"
Decision Tree/DT_Classify/DT_Classify_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n#  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\ntrain_path = 'C:/Users/GWT9\\Desktop/Adult_Train.csv'\r\n\r\n#  \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xb7\xaf\xe5\xbe\x84\r\ntest_path = 'C:/Users/GWT9\\Desktop/Adult_Test.csv'\r\n\r\n# \xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef handle_data(filepath, miss='fill'):  # \xe5\xae\x9a\xe4\xb9\x89\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    data = pd.read_csv(r'%s' % filepath)\r\n    data = data.replace('?', np.nan)\r\n    #  \xe5\xa4\x84\xe7\x90\x86\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if miss == 'del':  # \xe5\x88\xa0\xe9\x99\xa4\xe6\x8e\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n        miss_data = data.dropna(how='any')\r\n    else:\r\n        miss_data = data.fillna(method='ffill')\r\n    # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\xa0\x87\xe8\xaf\x86\xe6\x9c\x89\xe4\xba\x9b\xe8\xae\xb8\xe4\xb8\x8d\xe5\x90\x8c\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe7\xbb\x9f\xe4\xb8\x80\r\n    miss_data['Money'] = ['\xe4\xb8\x8d\xe9\xab\x98\xe4\xba\x8e50K' if '<=' in hh else '\xe9\xab\x98\xe4\xba\x8e50K' for hh in miss_data['Money']]\r\n    return miss_data\r\n\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\ntrain_data = handle_data(train_path).values\r\n\r\n\r\n\r\n\r\n# k\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xef\xbc\x8c\xe5\xbd\xa2\xe6\x88\x90\xe5\xad\x97\xe5\x85\xb8\r\ndef kfold(trdata, percent_test=0.2): # k\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\xe4\xb8\xba5\r\n    kfoldict = {}\r\n    length = len(trdata)\r\n    sign = int(length * percent_test)\r\n    # \xe7\x94\x9f\xe6\x88\x90\xe9\x9a\x8f\xe6\x9c\xba\xe6\x95\xb0\xe7\xbb\x84\r\n    random_list = np.arange(length)\r\n    np.random.shuffle(random_list)\r\n    kfoldict[0] = {}\r\n    kfoldict[0]['train'] = trdata[random_list[sign:]]\r\n    kfoldict[0]['test'] = trdata[random_list[:sign]]\r\n\r\n    return kfoldict\r\n\r\n# \xe7\xac\xac\xe4\xb8\x80\xe4\xbb\xa3\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\r\n\r\ndt_data = kfold(train_data)\r\n\r\n# \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\ntest_data = handle_data(test_path).values\r\n\r\n"""
Decision Tree/DT_Classify/Iris_tree.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport AnFany_DT_Classify as model  # \xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b\r\nimport Irisdata_DT_Anfany as dtda   # \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport AnFany_Show_Tree as tree     # \xe5\xbc\x95\xe5\x85\xa5\xe7\xbb\x98\xe5\x88\xb6\xe6\xa0\x91\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\nfrom pylab import mpl\r\nmpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams['axes.unicode_minus'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe3\x80\x82\xe7\x9c\x8b\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\r\nif __name__ == '__main__':\r\n    # \xe6\xa0\xb9\xe6\x8d\xae\xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6\xef\xbc\x8c\xe7\x9c\x8b\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\r\n    xunliande = []\r\n    yazhengde = []\r\n    yucede = []\r\n\r\n    for shendu in range(2, 13):\r\n\r\n        uu = model.DT(train_dtdata=dtda.dt_data, pre_dtdata=dtda.test_data, tree_length=shendu)\r\n        # \xe5\xae\x8c\xe5\x85\xa8\xe6\x88\x90\xe9\x95\xbf\xe7\x9a\x84\xe6\xa0\x91\r\n        uu.grow_tree()\r\n        # \xe5\x89\xaa\xe6\x9e\x9d\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\xa0\x91\xe7\x9a\x84\xe9\x9b\x86\r\n        gu = uu.prue_tree()\r\n        # \xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa0\x91\r\n        cc = uu.jiaocha_tree(gu[0])\r\n        # \xe6\xa0\xb9\xe6\x8d\xae\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa0\x91\xe9\xa2\x84\xe6\xb5\x8b\xe6\x96\xb0\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n        uu.noderela = cc[0]\r\n        prenum = uu.pre_tree(uu.pre_dtdata)\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\r\n        yazhengde.append(cc[1])\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\r\n        yucede.append(uu.compuer_correct(uu.pre_dtdata[:, -1], prenum))\r\n        # \xe8\xae\xad\xe7\xbb\x83\r\n        trainnum = uu.pre_tree(uu.train_dtdata)\r\n        xunliande.append(uu.compuer_correct(uu.train_dtdata[:, -1], trainnum))\r\n\r\n    # \xe5\x9c\xa8\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6\xe4\xb8\xad\xef\xbc\x8c\xe9\x80\x89\xe6\x8b\xa9\xe4\xb8\x89\xe8\x80\x85\xe7\x9a\x84\xe7\xbb\xbc\xe5\x90\x88\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe8\xbe\x83\xe9\xab\x98\xe7\x9a\x84\xe6\xa8\xa1\xe5\x9e\x8b\xef\xbc\x8c\xe4\xbd\x9c\xe4\xb8\xba\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe4\xbc\x98\xe5\x8c\x96\xe6\xa0\x91\xe3\x80\x82\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6\xe8\xb6\x8a\xe5\xb0\x8f\xe8\xb6\x8a\xe5\xa5\xbd\r\n\r\n    zonghe = [x + y + yu for x, y, yu in zip(xunliande, yazhengde, yucede)]\r\n\r\n\r\n    zuiyoushendu = zonghe.index(max(zonghe)) + 2\r\n\r\n    ww = model.DT(train_dtdata=dtda.dt_data, pre_dtdata=dtda.test_data, tree_length=zuiyoushendu)\r\n    # \xe5\xae\x8c\xe5\x85\xa8\xe6\x88\x90\xe9\x95\xbf\xe7\x9a\x84\xe6\xa0\x91\r\n    ww.grow_tree()\r\n    # \xe5\x89\xaa\xe6\x9e\x9d\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\xa0\x91\xe7\x9a\x84\xe9\x9b\x86\r\n    gu = ww.prue_tree()\r\n    # \xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa0\x91\r\n    cc = ww.jiaocha_tree(gu[0])\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x88\xb6\r\n    # \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    shuju = ww.node_shujuji\r\n    # \xe7\xbb\x93\xe6\x9e\x9c\r\n    jieguo = ww.jieguo_tree()\r\n    # \xe8\xa7\x84\xe5\x88\x99\r\n    rule = ww.node_rule\r\n    # \xe7\xbb\x98\xe5\x9b\xbe\r\n    tree.draw_tree(shuju, jieguo, rule, cc[0], zian=['Sepal_length', 'Sepal_width', 'Petal_length', 'Petal_width'\r\n])\r\n\r\n\r\n"""
Decision Tree/DT_Classify/Irisdata_DT_Anfany.py,0,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\iris.csv')\r\n\r\n# \xe7\x9b\xb4\xe6\x8e\xa5\xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe6\x8c\x897:2:1 \xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\n\r\ndef fenge(data, per=[0.2, 0.1]):\r\n    # \xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n    lent = len(data)\r\n    alist = np.arange(lent)\r\n    np.random.shuffle(alist)\r\n\r\n    # \xe9\xaa\x8c\xe8\xaf\x81\r\n    shu = int(lent * per[0])\r\n    yu = int(lent * per[1])\r\n\r\n    yanzheng = np.random.choice(alist, shu, replace=False)\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    shengxai = np.array([i for i in alist if i not in yanzheng])\r\n\r\n    yuce = np.random.choice(shengxai, yu)\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\r\n    train = np.array([j for j in alist if j not in yanzheng and j not in yuce])\r\n\r\n    # \xe8\xbf\x94\xe5\x9b\x9e\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    dadata = {}\r\n    dadata[0] = {}\r\n\r\n    dadata[0]['train'] = data[train]\r\n    dadata[0]['test'] = data[yanzheng]\r\n\r\n    return dadata, data[yuce]\r\n\r\ndeeer = fenge(data.values[:, 1:])\r\n\r\n# \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\ndt_data = deeer[0]\r\ntest_data = deeer[1]\r\n"""
Decision Tree/DT_Classify/Sklearn_DT_Classify.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\x8f\xaf\xe5\xa4\x84\xe7\x90\x86\xe5\xa4\x9a\xe5\x88\x86\xe7\xb1\xbb\xef\xbc\x8c \xe7\xa6\xbb\xe6\x95\xa3\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xbf\x9e\xe7\xbb\xad\xe7\x9a\x84\xe5\x8f\x98\xe9\x87\x8f\r\n\r\n\r\nfrom sklearn.tree import DecisionTreeClassifier as skdt  # \xe5\xbc\x95\xe5\x85\xa5Sklearn\xe4\xb8\xad\xe7\x9a\x84\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe6\xa8\xa1\xe5\x9e\x8b\r\nimport DT_Classify_Data as data  # \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nimport matplotlib.pyplot as plt  # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\r\nfrom pylab import mpl\r\nmpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams['axes.unicode_minus'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xbaSklearn\xe5\x8f\xaa\xe8\x83\xbd\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe5\x80\xbc\xe5\x9e\x8b\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe9\x9c\x80\xe8\xa6\x81\xe7\x88\xb8X\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe5\x80\xbc\xe4\xb8\xba\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\x9a\x84\xe5\x8f\x98\xe9\x87\x8f\xe8\xbd\xac\xe5\x8f\x98\xe4\xb8\xba\xe6\x95\xb0\xe5\x80\xbc\xe5\x9e\x8b\xe3\x80\x82\r\n# \xe8\xbf\x99\xe9\x87\x8c\xe6\x9c\xaa\xe9\x87\x87\xe7\x94\xa8\xe7\x8b\xac\xe7\x83\xad\xe5\x8c\x96\xe7\xbc\x96\xe7\xa0\x81\xef\xbc\x8c\xe4\xb8\x80\xe6\x98\xaf\xe8\x80\x83\xe8\x99\x91\xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x8f\xe4\xbc\x9a\xe9\x80\x92\xe5\xa2\x9e \xe4\xba\x8c\xe6\x98\xaf\xe4\xb8\xa4\xe8\x80\x85\xe7\x9a\x84\xe6\x95\x88\xe6\x9e\x9c\xe5\xba\x94\xe8\xaf\xa5\xe7\x9b\xb8\xe5\xb7\xae\xe4\xb8\x8d\xe5\xa4\xa7\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xaeX\r\nX_data = data.dt_data[0]['train'][:, :-1]\r\n# Y\r\nY_data = data.dt_data[0]['train'][:, -1:].T[0]\r\n\r\n# \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xaeX\r\nX_data_test = data.dt_data[0]['test'][:, :-1]\r\n# Y\r\nY_data_test = data.dt_data[0]['test'][:, -1:].T[0]\r\n\r\n\r\n# \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\nX_data_pre = data.test_data[:, :-1]\r\n# Y\r\nY_data_pre = data.test_data[:, -1:].T[0]\r\n\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\x9b\xb4\xe6\x94\xb9\xe6\x89\x80\xe6\x9c\x89\xe7\xa6\xbb\xe6\x95\xa3\xe5\x8f\x98\xe9\x87\x8f\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef LisanToLianxu(tdata, ydata, pdata):\r\n    for jj in range(len(tdata[0])):\r\n        try:\r\n            tdata[0][jj] + 2\r\n            pass\r\n        except TypeError:\r\n            # \xe8\xbf\x99\xe6\x98\xaf\xe7\xa6\xbb\xe6\x95\xa3\xe7\x9a\x84\xe9\x9c\x80\xe8\xa6\x81\xe5\xa4\x84\xe7\x90\x86\r\n            #  \xe9\xbb\x98\xe8\xae\xa4 \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe5\x8c\x85\xe6\x8b\xac\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe6\x9c\xac\xe5\x8f\x98\xe9\x87\x8f\xe7\x9a\x84\xe5\x80\xbc\r\n            zhiset = list(set(list(tdata[:, jj:(jj + 1)].T[0])))\r\n\r\n            # \xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x80\xbc\xe8\xb5\x8b\xe4\xba\x88\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\xb0\r\n\r\n            numdict = {i: zhiset.index(i) for i in zhiset}\r\n\r\n            # \xe5\xbc\x80\xe5\xa7\x8b\xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe7\x9a\x84\xe8\xbf\x99\xe4\xb8\x80\xe5\x88\x97\xe8\xb5\x8b\xe5\x80\xbc\r\n            def zhihuan(tdata, jj, exdict=numdict):\r\n                # \xe8\xbf\x99\xe9\x87\x8c\xe9\x9c\x80\xe8\xa6\x81\xe5\xbb\xba\xe7\xab\x8b\xe4\xb8\x80\xe4\xb8\xaaDataFrame\r\n                du = pd.DataFrame()\r\n\r\n                du['zhi'] = tdata[:, jj:(jj + 1)].T[0]\r\n\r\n                du['zhi'] = du['zhi'].map(exdict)\r\n\r\n                tdata[:, jj:(jj + 1)] = np.array([du['zhi'].values]).T\r\n                return tdata\r\n\r\n            tdata = zhihuan(tdata, jj)\r\n            ydata = zhihuan(ydata, jj)\r\n            pdata = zhihuan(pdata, jj)\r\n\r\n    return tdata, ydata, pdata\r\n\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe8\xae\xa1\xe7\xae\x97\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n\r\ndef CorrectRate(yuanshileibei, shuchuleibie):\r\n    npyuan = np.array(yuanshileibei)\r\n    noshu = np.array(shuchuleibie)\r\n    return len(noshu[noshu == npyuan]) / len(npyuan)\r\n\r\n\r\nX_data, X_data_test, X_data_pre = LisanToLianxu(X_data, X_data_test, X_data_pre)\r\n\r\n\r\n#  \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\nif __name__ == '__main__':\r\n    xunliande = []\r\n    yazhengde = []\r\n    yucede = []\r\n\r\n    #  \xe9\x92\x88\xe5\xaf\xb9\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n    for i in range(2, 13):\r\n        clf = skdt(max_depth=i).fit(X_data, Y_data)\r\n        # \xe8\xae\xad\xe7\xbb\x83\r\n        Y_data_shu = clf.predict(X_data)\r\n\r\n        xunliande.append(CorrectRate(Y_data, Y_data_shu))\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\r\n        Y_data_test_shu = clf.predict(X_data_test)\r\n\r\n        yazhengde.append(CorrectRate(Y_data_test, Y_data_test_shu))\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\r\n        Y_data_pre_shu = clf.predict(X_data_pre)\r\n\r\n        yucede.append(CorrectRate(Y_data_pre, Y_data_pre_shu))\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\r\n    plt.plot(list(range(2, 13)), xunliande, 'o--', label='\xe8\xae\xad\xe7\xbb\x83', lw=2)\r\n    plt.plot(list(range(2, 13)), yazhengde, '*--', label='\xe9\xaa\x8c\xe8\xaf\x81', lw=2)\r\n    plt.plot(list(range(2, 13)), yucede, 's--', label='\xe9\xa2\x84\xe6\xb5\x8b', lw=2)\r\n    plt.xlabel('\xe6\xa0\x91\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6')\r\n    plt.xlim(1, 14)\r\n    plt.grid()\r\n    plt.ylabel('\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87')\r\n    plt.legend(shadow=True, fancybox=True)\r\n    plt.show()\r\n\r\n\r\n\r\n\r\n\r\n"""
Decision Tree/DT_Regression/AnFany_DT_Regression.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# '''CART\xe5\x9b\x9e\xe5\xbd\x92\xe6\xa0\x91\xef\xbc\x9a\xe5\x8f\xaf\xe5\xa4\x84\xe7\x90\x86\xe8\xbf\x9e\xe7\xbb\xad\xe3\x80\x81\xe7\xa6\xbb\xe6\x95\xa3\xe7\x9a\x84\xe5\x8f\x98\xe9\x87\x8f\xef\xbc\x8c\xe4\xb8\x8d\xe6\x94\xaf\xe6\x8c\x81\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\xe6\x98\xaf\xe5\xa4\x9a\xe7\xbb\xb4\xe7\x9a\x84\xe3\x80\x82  \xe5\x8f\xaf\xe4\xbb\xa5\xe5\x88\xa9\xe7\x94\xa8\xe5\xa4\x9a\xe4\xb8\xaa\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe8\xa7\xa3\xe5\x86\xb3\xe5\xa4\x9a\xe7\xbb\xb4\xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe9\x97\xae\xe9\xa2\x98\r\n# \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe9\xa1\xba\xe5\xba\x8f\xe5\xbf\x85\xe9\xa1\xbb\xe4\xb8\x80\xe6\xa0\xb7\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe6\x9c\xac\xe7\xa8\x8b\xe5\xba\x8f\xe5\x9c\xa8\xe8\xae\xbe\xe5\xae\x9a\xe8\xa7\x84\xe5\x88\x99\xe6\x8c\x89\xe7\x9a\x84\xe6\x98\xaf\xe5\xad\x97\xe6\xae\xb5\xe7\x9a\x84\xe7\xbc\x96\xe5\x8f\xb7\xef\xbc\x8c\xe8\x80\x8c\xe4\xb8\x8d\xe6\x98\xaf\xe5\x90\x8d\xe5\xad\x97\r\n# \xe5\x9b\x9e\xe5\xbd\x92\xe6\xa0\x91\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xba\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\xe9\x97\xae\xe9\xa2\x98\xe3\x80\x82\xe4\xb8\x8d\xe8\xbf\x90\xe8\xa1\x8c\xe5\x89\xaa\xe6\x9e\x9d\xe8\xbf\x99\xe4\xb8\x80\xe7\x8e\xaf\xe8\x8a\x82\xef\xbc\x8c\xe5\xbd\x93\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84MSE\xe4\xb8\x8d\xe5\x86\x8d\xe9\x99\x8d\xe4\xbd\x8e\xe6\x97\xb6\xef\xbc\x8c\xe7\xa1\xae\xe5\xae\x9a\xe6\x9c\x80\xe4\xbd\xb3\xe7\x9a\x84\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\r\n# \xe5\x9b\x9e\xe5\xbd\x92\xe6\xa0\x91\xe9\xa6\x96\xe5\x85\x88\xe8\xa6\x81\xe9\x99\x8d\xe4\xbd\x8e\xe5\x81\x8f\xe5\xb7\xae\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe5\x81\x8f\xe5\xb7\xae\xe5\x8f\xaa\xe6\x9c\x89\xe5\xb0\x8f\xe5\x88\xb0\xe4\xb8\x80\xe5\xae\x9a\xe7\xa8\x8b\xe5\xba\xa6\xef\xbc\x8c\xe5\x86\x8d\xe9\x99\x8d\xe4\xbd\x8e\xe6\x96\xb9\xe5\xb7\xae\xe3\x80\x82\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\xe5\x8f\xaf\xe7\x9c\x8b\xe4\xbd\x9c\xe9\x99\x8d\xe4\xbd\x8e\xe5\x81\x8f\xe5\xb7\xae\xef\xbc\x8c\xe8\x80\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\xe5\x8f\xaf\xe7\x9c\x8b\xe4\xbd\x9c\xe9\x99\x8d\xe4\xbd\x8e\xe6\x96\xb9\xe5\xb7\xae\r\n# '''\r\n\r\n# print(__doc__)\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport Data_DT_Regression as dtda\r\nimport copy\r\nimport numpy as np\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe5\x87\xbd\xe6\x95\xb0\r\nclass DT:\r\n    def __init__(self, train_dtdata=dtda.dt_data, pre_dtdata=dtda.test_data, tree_length=5):\r\n\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n        self.train_dtdata = train_dtdata[0]['train']\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\r\n        self.test_dtdata = train_dtdata[0]['test']\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\n        self.pre_dtdata = pre_dtdata\r\n\r\n        # \xe4\xb8\xad\xe9\x97\xb4\xe8\xbf\x87\xe7\xa8\x8b\xe5\x8f\x98\xe9\x87\x8f\r\n        self.node_shujuji = {'0': self.train_dtdata}  # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        self.fenlei_shujuji = {'0': self.train_dtdata}  # \xe5\xad\x98\xe5\x82\xa8\xe9\x9c\x80\xe8\xa6\x81\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n\r\n        # \xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe9\x9b\x86\xe5\x90\x88\r\n        self.leafnodes = []\r\n        # \xe8\x8a\x82\xe7\x82\xb9\xe5\x85\xb3\xe7\xb3\xbb\xe5\xad\x97\xe5\x85\xb8\r\n        self.noderela = {}\r\n        # \xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe8\xa7\x84\xe5\x88\x99\xe5\x85\xb3\xe7\xb3\xbb\r\n        self.node_rule = {'0': []}\r\n\r\n        # \xe9\x81\xbf\xe5\x85\x8d\xe6\xa0\x91\xe8\xbf\x87\xe5\xa4\xa7\xef\xbc\x8c\xe9\x87\x87\xe7\x94\xa8\xe9\x99\x90\xe5\x88\xb6\xe4\xb9\xa6\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\r\n        self.tree_length = tree_length\r\n\r\n\r\n    # #  \xe6\xa0\xb9\xe6\x8d\xae\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe6\x95\xb0\xe7\xbb\x84\xe8\xae\xa1\xe7\xae\x97\xe5\x9f\xba\xe5\xb0\xbc\xe6\x8c\x87\xe6\x95\xb0\r\n    # def jini_zhishu(self, exlist):\r\n    #     dnum = 0\r\n    #     leng = len(exlist)\r\n    #     for hh in list(set(exlist)):\r\n    #         dnum += (list(exlist).count(hh) / leng) ** 2\r\n    #     return 1 - dnum\r\n\r\n\r\n    #  \xe6\xa0\xb9\xe6\x8d\xae\xe7\xb1\xbb\xe5\x88\xab\xe7\x9a\x84\xe6\x95\xb0\xe7\xbb\x84\xe8\xae\xa1\xe7\xae\x97\xe6\x95\xb0\xe7\xbb\x84\xe9\x97\xb4\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\r\n    def biaozhuncha(self, exlist):\r\n        exlist = np.array(exlist)\r\n        if len(exlist) <= 1:\r\n            return 0\r\n        else:\r\n            return np.std(exlist, ddof=1)  # ddof=1\xe8\xae\xa1\xe7\xae\x97\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\r\n\r\n    #  \xe8\xae\xa1\xe7\xae\x97\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def jini_xishu(self, tezheng, leibie):  # \xe8\xbe\x93\xe5\x85\xa5\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe7\xb1\xbb\xe5\x88\xab\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe8\xbf\x94\xe5\x9b\x9e\xe6\x9c\x80\xe5\xb0\x8f\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x80\xbc\r\n        #  \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\xe6\x98\xaf\xe8\xbf\x9e\xe7\xbb\xad\xe3\x80\x81\xe6\x88\x96\xe8\x80\x85\xe6\x98\xaf\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\r\n        sign = 0\r\n        try:\r\n            tezheng[0] + 2\r\n            # \xe8\xaf\x81\xe6\x98\x8e\xe6\x98\xaf\xe8\xbf\x9e\xe7\xbb\xad\xe7\x9a\x84\r\n            sign = 1\r\n        except TypeError:\r\n            pass\r\n        if sign:  # \xe8\xbf\x9e\xe7\xbb\xad\xe5\x8f\x98\xe9\x87\x8f\r\n            # \xe5\x8e\xbb\xe9\x87\x8d\xe3\x80\x81\xe6\x8e\x92\xe5\xba\x8f\r\n            quzhong = np.array(sorted(list(set(tezheng))))\r\n            # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe4\xb8\x8d\xe6\x98\xaf\xe5\xb0\xb1\xe4\xb8\x80\xe4\xb8\xaa\xe5\x80\xbc\r\n            if len(quzhong) == 1:\r\n                return False\r\n            # \xe5\x8f\x96\xe4\xb8\xad\xe9\x97\xb4\xe5\x80\xbc\r\n            midd = (quzhong[:-1] + quzhong[1:]) / 2\r\n            # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x81\x8d\xe5\x8e\x86\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe4\xb8\xad\xe9\x97\xb4\xe5\x80\xbc\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\r\n            length = len(leibie)\r\n            # \xe5\xad\x98\xe5\x82\xa8\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\xe7\x9a\x84\xe5\x80\xbc\r\n            save_ji, jini = np.inf, 0\r\n            number = ''\r\n            for mi in midd:\r\n                #  \xe8\xae\xa1\xe7\xae\x97\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\xe5\x92\x8c\r\n                onelist = leibie[tezheng <= mi]\r\n                twolist = leibie[tezheng > mi]\r\n                jini = (len(onelist) / length) * self.biaozhuncha(onelist) + (len(twolist) / length) * self.biaozhuncha(twolist)\r\n                if jini <= save_ji:\r\n                    save_ji = jini\r\n                    number = mi\r\n            return number, save_ji\r\n        else:  #\xe5\x88\x86\xe7\xb1\xbb\xe5\x8f\x98\xe9\x87\x8f\r\n            # \xe5\x8e\xbb\xe9\x87\x8d\xe3\x80\x81\xe6\x8e\x92\xe5\xba\x8f\r\n            quzhong = np.array(list(set(tezheng)))\r\n            # \xe5\x88\xa4\xe6\x96\xad\xe6\x98\xaf\xe4\xb8\x8d\xe6\x98\xaf\xe5\xb0\xb1\xe4\xb8\x80\xe4\xb8\xaa\xe5\x80\xbc\r\n            if len(quzhong) == 1:\r\n                return False\r\n            # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x81\x8d\xe5\x8e\x86\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x80\xbc\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\r\n            length = len(leibie)\r\n            # \xe5\xad\x98\xe5\x82\xa8\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\xe7\x9a\x84\xe5\x80\xbc\r\n            jini, save_ji = 0, np.inf\r\n            number = ''\r\n            for mi in quzhong:\r\n                #  \xe8\xae\xa1\xe7\xae\x97\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\xe5\x92\x8c\r\n                onelist = leibie[tezheng == mi]\r\n                twolist = leibie[tezheng != mi]\r\n                jini = (len(onelist) / length) * self.biaozhuncha(onelist) + (len(twolist) / length) * self.biaozhuncha(\r\n                     twolist)\r\n                if jini <= save_ji:\r\n                    save_ji = jini\r\n                    number = mi\r\n            return number, save_ji  # \xe8\xaf\xa5\xe7\x89\xb9\xe5\xbe\x81\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe5\x88\x86\xe5\x89\xb2\xe5\x80\xbc\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xaf\xa5\xe7\x89\xb9\xe5\xbe\x81\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\r\n\r\n\r\n    # \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\xa1\xae\xe5\xae\x9a\xe5\x88\x86\xe7\xb1\xbb\xe7\x89\xb9\xe5\xbe\x81\xe4\xbb\xa5\xe5\x8f\x8a\xe5\xb1\x9e\xe6\x80\xa7\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def feature_zhi(self, datadist):  # \xe8\xbe\x93\xe5\x85\xa5\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\xad\x97\xe5\x85\xb8\xef\xbc\x8c\xe8\xbe\x93\xe5\x87\xba\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe7\xbc\x96\xe5\x8f\xb7\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe8\xbf\x98\xe6\x9c\x89\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\r\n        tezhengsign = ''\r\n        number = np.inf\r\n        jini = ''\r\n        for jil in range(1, len(datadist[0])):\r\n            #  \xe8\x8e\xb7\xe5\x8f\x96\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe7\xb1\xbb\xe5\x88\xab\xe6\x95\xb0\xe6\x8d\xae\r\n            tezhen = datadist[:, (jil - 1): jil].T[0]\r\n            leib = datadist[:, -1:].T[0]\r\n            # \xe5\x9c\xa8\xe5\x85\xb6\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\r\n            cresu = self.jini_xishu(tezhen, leib)\r\n            # \xe5\x88\xa4\xe6\x96\xad\xe8\xbf\x99\xe4\xb8\xaa\xe7\x89\xb9\xe5\xbe\x81\xe5\x8f\xaf\xe4\xb8\x8d\xe5\x8f\xaf\xe5\x8f\x96\r\n            if cresu:\r\n                if cresu[1] <= number:\r\n                    number = cresu[1]\r\n                    tezhengsign = jil - 1\r\n                    jini = cresu[0]\r\n        if jini != '':\r\n            return tezhengsign, jini, number  # \xe7\x89\xb9\xe5\xbe\x81\xe7\xbc\x96\xe5\x8f\xb7, \xe8\xaf\xa5\xe7\x89\xb9\xe5\xbe\x81\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe5\x88\x86\xe5\x89\xb2\xe5\x80\xbc\xef\xbc\x8c\xe8\xaf\xa5\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\r\n        else:\r\n            return False  # \xe8\xbf\x99\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x97\xa0\xe6\xb3\x95\xe8\xa2\xab\xe5\x88\x86\xe8\xa3\x82\r\n\r\n    # \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\xe5\x88\x86\xe8\xa3\x82\r\n    def devided_shujuji(self, datadis):  # \xe8\xbe\x93\xe5\x85\xa5\xe7\x89\xb9\xe5\xbe\x81\xe7\xbc\x96\xe5\x8f\xb7\xef\xbc\x8c\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\xa4\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n        # \xe8\xbf\x90\xe7\xae\x97\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n        yuansuan = self.feature_zhi(datadis)\r\n        if yuansuan:\r\n            #  \xe9\x9c\x80\xe8\xa6\x81\xe5\x88\xa4\xe6\x96\xad\xe8\xbf\x99\xe4\xb8\xaa\xe8\xa2\xab\xe9\x80\x89\xe4\xb8\xad\xe7\x9a\x84\xe7\x89\xb9\xe5\xbe\x81\xe6\x98\xaf\xe8\xbf\x9e\xe7\xbb\xad\xe8\xbf\x98\xe6\x98\xaf\xe7\xa6\xbb\xe6\x95\xa3\xe7\x9a\x84\r\n            try:\r\n                datadis[:, yuansuan[0]][0] + 2\r\n                oneshujui = datadis[datadis[:, yuansuan[0]] <= yuansuan[1]]\r\n                twoshujui = datadis[datadis[:, yuansuan[0]] > yuansuan[1]]\r\n            except TypeError:\r\n                oneshujui = datadis[datadis[:, yuansuan[0]] == yuansuan[1]]\r\n                twoshujui = datadis[datadis[:, yuansuan[0]] != yuansuan[1]]\r\n            return oneshujui, twoshujui, yuansuan\r\n        else:\r\n            return False\r\n\r\n    # \xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe5\x87\xbd\xe6\x95\xb0\r\n    def grow_tree(self):\r\n        while len(self.fenlei_shujuji) != 0:\r\n            # \xe9\x9c\x80\xe8\xa6\x81\xe5\xa4\x8d\xe5\x88\xb6\xe5\xad\x97\xe5\x85\xb8\r\n            copy_dict = copy.deepcopy(self.fenlei_shujuji)\r\n            # \xe5\xbc\x80\xe5\xa7\x8b\xe9\x81\x8d\xe5\x8e\x86\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe9\x9c\x80\xe8\xa6\x81\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n            for hd in self.fenlei_shujuji:\r\n                #  \xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\xe9\x99\x90\xe5\x88\xb6\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\r\n                if len(hd) == self.tree_length + 1:\r\n                    # \xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe5\x9c\xa8\xe5\x88\x86\xe8\xa3\x82\r\n                    del copy_dict[hd]\r\n                    # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\xb0\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe9\x9b\x86\xe5\x90\x88\xe4\xb8\xad\r\n                    self.leafnodes.append(hd)\r\n                else:\r\n                    fenguo = self.devided_shujuji(copy_dict[hd])\r\n                    if fenguo:\r\n                        if len(set(fenguo[0][:, -1])) == 1:  # \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe7\xb1\xbb\xe5\x88\xab\xe5\xb0\xb1\xe4\xb8\x8d\xe5\x86\x8d\xe5\x88\x86\xe8\xa3\x82\r\n                            self.leafnodes.append('%sl' % hd)   # \xe6\x88\x90\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n                        else:\r\n                            copy_dict['%sl' % hd] = fenguo[0]  # \xe7\xbb\xa7\xe7\xbb\xad\xe5\x88\x86\xe8\xa3\x82\r\n\r\n                        self.node_shujuji['%sl' % hd] = fenguo[0]  # \xe6\x80\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n\r\n                        # \xe6\xb7\xbb\xe5\x8a\xa0\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe8\xa7\x84\xe5\x88\x99\r\n                        self.node_rule['%sl' % hd] = (self.node_rule[hd]).copy()\r\n                        self.node_rule['%sl' % hd].append(fenguo[2])\r\n\r\n\r\n                        if len(set(fenguo[1][:, -1])) == 1:\r\n                            self.leafnodes.append('%sr' % hd)\r\n                        else:\r\n                            copy_dict['%sr' % hd] = fenguo[1]\r\n\r\n                        self.node_shujuji['%sr' % hd] = fenguo[1]\r\n\r\n                        # \xe6\xb7\xbb\xe5\x8a\xa0\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe8\xa7\x84\xe5\x88\x99\r\n                        self.node_rule['%sr' % hd] = (self.node_rule[hd]).copy()\r\n                        self.node_rule['%sr' % hd].append(fenguo[2])\r\n\r\n                        # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\xb0\xe8\x8a\x82\xe7\x82\xb9\xe5\x85\xb3\xe7\xb3\xbb\xe5\xad\x97\xe5\x85\xb8\r\n                        self.noderela[hd] = ['%sl' % hd, '%sr' % hd]\r\n\r\n                    del copy_dict[hd]  # \xe9\x9c\x80\xe8\xa6\x81\xe5\x9c\xa8\xe5\x88\x86\xe8\xa3\x82\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xb8\x80\xe4\xb8\xaa\r\n\r\n            self.fenlei_shujuji = copy.deepcopy(copy_dict)\r\n\r\n            print('\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xef\xbc\x9a', len(self.fenlei_shujuji))\r\n            print('\xe9\x9c\x80\xe8\xa6\x81\xe5\x88\x86\xe8\xa3\x82\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xef\xbc\x9a', len(self.node_shujuji))\r\n\r\n        return 'done'\r\n\r\n    # \xe6\xa0\xb9\xe6\x8d\xae\xe6\xa0\x91\xe5\xbe\x97\xe5\x87\xba\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    def jieguo_tree(self):\r\n        # \xe6\xa0\xb9\xe6\x8d\xae\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe5\xbe\x97\xe5\x88\xb0\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n        shujuji_jieguo = {}\r\n        for shuju in self.node_shujuji:\r\n            zuihang = self.node_shujuji[shuju][:, -1]\r\n            #  \xe9\x80\x89\xe6\x8b\xa9\xe5\x9d\x87\xe5\x80\xbc\r\n            shujuji_jieguo[shuju] = round(np.mean(np.array(zuihang)), 1)\r\n\r\n        return shujuji_jieguo\r\n\r\n    # \xe8\xa6\x81\xe5\xbe\x97\xe5\x88\xb0\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe9\x9b\x86\xe5\x90\x88\r\n    def leafnodes_tree(self):\r\n        # \xe4\xb8\x8d\xe5\x9c\xa8\xe9\x94\xae\xe5\x80\xbc\xe4\xb8\xad\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\r\n        keynodes = list(self.noderela.keys())\r\n        zhin= list(self.noderela.values())\r\n        zhinodes = []\r\n        for hhu in zhin:\r\n            for fff in hhu:\r\n                zhinodes.append(fff)\r\n        leafnodes = [jj for jj in zhinodes if jj not in keynodes]\r\n        return leafnodes\r\n\r\n\r\n    # \xe5\xaf\xbb\xe6\x89\xbe\xe4\xbb\xbb\xe4\xbd\x95\xe4\xb8\x80\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n    def iner_leaf(self, exnode):\r\n        # \xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\r\n        inernodes = list(self.noderela.keys())\r\n        # \xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n        llnodes = []\r\n        # \xe5\x85\xa8\xe9\x83\xa8\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\r\n        ghunodes = list(self.noderela.values())\r\n\r\n        gugu = []\r\n\r\n        for hhdd in ghunodes:\r\n            for ghgh in hhdd:\r\n                gugu.append(ghgh)\r\n\r\n        for jj in gugu + ['0']:\r\n            if jj not in inernodes:\r\n                if len(jj) > len(exnode) and exnode in jj:\r\n                    llnodes.append(jj)\r\n        return llnodes\r\n\r\n    # \xe5\xaf\xbb\xe6\x89\xbe\xe4\xbb\xbb\xe4\xbd\x95\xe4\xb8\x80\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xb8\x8b\xe5\xb1\x9e\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\r\n    def xiashu_leaf(self, exnode):\r\n        # \xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n        xiashunodes = []\r\n        # \xe5\x85\xa8\xe9\x83\xa8\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\r\n        godes = list(self.noderela.values())\r\n        gug = []\r\n        for hhdd in godes:\r\n            for ghgh in hhdd:\r\n                gug.append(ghgh)\r\n\r\n        for jj in gug + ['0']:\r\n            if exnode in jj:\r\n                xiashunodes.append(jj)\r\n        return xiashunodes\r\n\r\n\r\n    # \xe5\x88\xa4\xe8\xaf\xbb\xe6\x95\xb0\xe6\x8d\xae\xe6\x98\xaf\xe5\x90\xa6\xe7\xac\xa6\xe5\x90\x88\xe8\xbf\x99\xe4\xb8\xaa\xe8\xa7\x84\xe5\x88\x99\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n    def judge_data(self, data, signstr, guize):\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9e\xe7\xbb\xad\xe6\x88\x96\xe8\x80\x85\xe6\x98\xaf\xe7\xa6\xbb\xe6\x95\xa3\r\n        fign = 0\r\n        try:\r\n            data[guize[0]] + 2\r\n            fign = 1\r\n        except TypeError:\r\n            pass\r\n        if fign == 1:  # \xe8\xbf\x9e\xe7\xbb\xad\r\n            if signstr == 'r':\r\n                if data[guize[0]] > guize[1]:\r\n                    return True\r\n                return False\r\n            elif signstr == 'l':\r\n                if data[guize[0]] <= guize[1]:\r\n                    return True\r\n                return False\r\n        elif fign == 0:  # \xe7\xa6\xbb\xe6\x95\xa3\r\n            if signstr == 'r':\r\n                if data[guize[0]] != guize[1]:\r\n                    return True\r\n                return False\r\n            elif signstr == 'l':\r\n                if data[guize[0]] == guize[1]:\r\n                    return True\r\n                return False\r\n\r\n\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0, \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe5\x85\xb3\xe7\xb3\xbb\xe5\xad\x97\xe5\x85\xb8\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xa7\x84\xe5\x88\x99\xe3\x80\x81\xe6\xaf\x8f\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe8\x8e\xb7\xe5\xbe\x97\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n    def pre_tree(self, predata):\r\n        # \xe6\xaf\x8f\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\x90\x88\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n        meire = self.jieguo_tree()\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe7\xbb\x93\xe6\x9e\x9c\r\n        savresu = []\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe6\xa0\xb9\xe6\x8d\xae\xe8\x8a\x82\xe7\x82\xb9\xe5\x85\xb3\xe7\xb3\xbb\xe6\x89\xbe\xe5\x88\xb0\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n        yezinodes = self.leafnodes_tree()\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe5\x88\xa4\xe6\x96\xad\xe6\x95\xb0\xe6\x8d\xae\r\n        for jj in predata:\r\n            shuju = jj[: -1]\r\n            # \xe5\xbc\x80\xe5\xa7\x8b\xe5\x88\xa4\xe6\x96\xad\r\n            for yy in yezinodes:\r\n                gu = 1\r\n                guide = self.node_rule[yy]\r\n                for iu, ju in zip(yy[1:], guide):\r\n                    if not self.judge_data(shuju, iu, ju):\r\n                        gu = 0\r\n                        break\r\n                if gu == 1:\r\n                    savresu.append(meire[yy])\r\n        return savresu\r\n\r\n\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe5\x89\xaa\xe6\x9e\x9d\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\r\n    def jianzhi_iner(self, exnode):\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe5\xbe\x97\xe5\x88\xb0\xe6\x95\xb4\xe4\xbd\x93\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\r\n        leng = len(self.train_dtdata)\r\n        # # \xe5\x9c\xa8\xe5\xbe\x97\xe5\x88\xb0\xe6\x9c\xac\xe8\x8a\x82\xe7\x82\xb9\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6,\xe6\xad\xa4\xe9\xa1\xb9\xe5\x8f\xaf\xe4\xbb\xa5\xe8\xa2\xab\xe6\xb6\x88\xe5\x8e\xbb\r\n        # benleng = len(self.node_shujuji[exnode])\r\n\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe8\xa2\xab\xe9\x94\x99\xe8\xaf\xaf\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\x9d\xa1\xe6\x95\xb0\r\n        self.node_result = self.jieguo_tree()\r\n        cuowu_leng = len(self.node_shujuji[exnode][self.node_shujuji[exnode][:, -1] != self.node_result[exnode]])\r\n        # \xe8\xae\xa1\xe7\xae\x97\r\n        jinum = cuowu_leng / leng\r\n        return jinum\r\n\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xb8\x8b\xe5\xb1\x9e\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\xe4\xb9\x8b\xe5\x92\x8c\r\n    def iner_sum(self, ecnode):\r\n        jnum = 0\r\n        # \xe9\xa6\x96\xe5\x85\x88\xe5\xbe\x97\xe5\x88\xb0\xe8\xbf\x99\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe4\xb8\x8b\xe5\xb1\x9e\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n        for hhh in self.iner_leaf(ecnode):\r\n            jnum += self.jianzhi_iner(hhh)\r\n        return jnum\r\n\r\n\r\n    # \xe6\xa0\x91\xe7\x9a\x84\xe5\x89\xaa\xe6\x9e\x9d\xef\xbc\x8c \xe6\xaf\x8f\xe4\xb8\x80\xe6\xa3\xb5\xe6\xa0\x91\xe9\x83\xbd\xe6\x98\xaf\xe4\xb8\x80\xe4\xb8\xaa\xe5\xad\x97\xe5\x85\xb8\xe5\xbd\xa2\xe5\xbc\x8f\xef\xbc\x88\xe8\x8a\x82\xe7\x82\xb9\xe5\x85\xb3\xe7\xb3\xbb\xe5\xb0\xb1\xe4\xbb\xa3\xe8\xa1\xa8\xe4\xb8\x80\xe6\xa3\xb5\xe5\xad\x90\xe6\xa0\x91\xef\xbc\x89\r\n    def prue_tree(self):\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe5\x89\xaa\xe6\x9e\x9d\r\n        tree_set = {}\r\n        # a\xe5\x80\xbc\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        adict = {}\r\n\r\n        # \xe7\xac\xac\xe4\xb8\x80\xe6\xa3\xb5\xe5\xae\x8c\xe5\x85\xa8\xe7\x94\x9f\xe9\x95\xbf\xe7\x9a\x84\xe6\xa0\x91\r\n        sign = 0\r\n        tree_set[sign] = self.noderela.copy()\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe5\x89\xaa\xe6\x9e\x9d\r\n        while len(list(self.noderela.keys())) != 0:\r\n            # \xe5\xa4\x8d\xe5\x88\xb6\xe5\xad\x97\xe5\x85\xb8\r\n            coppdict = self.noderela.copy()\r\n            # \xe5\xad\x98\xe5\x82\xa8\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe5\x89\xaa\xe6\x9e\x9d\xe6\xa0\x87\xe5\x87\x86\xe5\xb7\xae\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n            saveiner = {}\r\n            for jiner in list(self.noderela.keys()):\r\n                # \xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe8\xae\xa1\xe7\xae\x97\r\n                saveiner[jiner] = (self.jianzhi_iner(jiner) - self.iner_sum(jiner)) / (len(self.iner_leaf(jiner)) - 1)\r\n            # \xe9\x80\x89\xe6\x8b\xa9\xe5\x85\xb6\xe4\xb8\xad\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe6\x9c\x892\xe4\xb8\xaa\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe9\x95\xbf\xe7\x9a\x84\r\n            numm = np.inf\r\n            dd = ''\r\n            for hji in saveiner:\r\n                if numm > saveiner[hji]:\r\n                    dd = hji\r\n                    numm = saveiner[hji]\r\n                elif numm == saveiner[hji]:\r\n                    if len(dd) < len(hji):\r\n                        dd = hji\r\n            # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\xb0a\xe5\x80\xbc\r\n            adict[sign] = numm\r\n            # \xe9\x9c\x80\xe8\xa6\x81\xe5\x88\xa0\xe9\x99\xa4hji\xe8\xbf\x99\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\r\n            # \xe9\xa6\x96\xe9\x80\x89\xe5\xbe\x97\xe5\x88\xb0\xe8\xbf\x99\xe4\xb8\xaa\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\r\n            for hco in self.xiashu_leaf(dd):\r\n                if hco in coppdict:\r\n                    del coppdict[hco]\r\n            # \xe6\xa0\x91\xe5\x8a\xa01\r\n            sign += 1\r\n            self.noderela = coppdict.copy()\r\n            tree_set[sign] = self.noderela.copy()\r\n        return tree_set, adict\r\n\r\n\r\n    #  \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe5\x92\x8c\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe8\xaf\xaf\xe5\xb7\xae\xe5\xb9\xb3\xe6\x96\xb9\xe5\x92\x8c\r\n    def compuer_mse(self, exli_real, exli_pre):\r\n        if len(exli_pre) == 0:\r\n            return 0\r\n        else:\r\n            exli_pre = np.array(exli_pre)\r\n            exli_real = np.array(exli_real)\r\n            corr = exli_pre - exli_real\r\n            return np.sum(np.array([i ** 2 for i in corr])) / len(corr)\r\n\r\n    # \xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe5\x87\xbd\xe6\x95\xb0\r\n    def jiaocha_tree(self, treeset):  #\xe8\xbe\x93\xe5\x87\xba\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\xa0\x91\r\n        # \xe6\x9c\x80\xe5\xb0\x8fMSE\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n        correct = {}\r\n\r\n        # \xe9\x81\x8d\xe5\x8e\x86\xe6\xa0\x91\xe7\x9a\x84\xe9\x9b\x86\xe5\x90\x88\r\n        for jj in treeset:\r\n            self.noderela = treeset[jj]\r\n            yuce = self.pre_tree(self.test_dtdata)\r\n            # \xe7\x9c\x9f\xe5\xae\x9e\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n            real = self.test_dtdata[:, -1]\r\n            # \xe8\xae\xa1\xe7\xae\x97MSE\r\n            correct[jj] = self.compuer_mse(real, yuce)\r\n        # \xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xef\xbc\x8c\xe5\xa6\x82\xe6\x9e\x9c\xe6\x9c\x89\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84\xef\xbc\x8c\xe8\x8e\xb7\xe5\x8f\x96\xe6\x95\xb0\xe7\x9b\xae\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe9\x94\xae\r\n        num = 0\r\n        leys = ''\r\n        for jj in correct:\r\n            if correct[jj] > num:\r\n                num = correct[jj]\r\n                leys = jj\r\n            elif num == correct[jj]:\r\n                if jj < leys:\r\n                    leys = jj\r\n        return treeset[leys], num\r\n\r\n\r\n# \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\nfrom pylab import mpl\r\nmpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams['axes.unicode_minus'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\n#  \xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x8f\xe8\xbe\x83\xe5\xa4\xa7\xef\xbc\x8c\xe6\x8a\x98\xe7\xba\xbf\xe5\x9b\xbe\xe5\xaf\xb9\xe6\xaf\x94\xe4\xb8\x8d\xe5\xae\xb9\xe6\x98\x93\xe7\x9c\x8b\xe6\xb8\x85\xef\xbc\x8c\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96200\xe6\x9d\xa1\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96100\xe6\x9d\xa1\xe5\xb1\x95\xe7\xa4\xba\r\ndef selet(prdata, reda, count=200):\r\n    if len(reda) <= count:\r\n        return prdata, reda\r\n    fu = np.arange(len(reda))\r\n\r\n    du = np.random.choice(fu, count)\r\n\r\n    return np.array(prdata)[du], np.array(reda)[du]\r\n\r\n\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe3\x80\x82\xe7\x9c\x8b\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\r\nif __name__ == '__main__':\r\n    # \xe6\xa0\xb9\xe6\x8d\xae\xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6\xef\xbc\x8c\xe7\x9c\x8b\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\r\n    xunliande = []\r\n    yazhengde = []\r\n    yucede = []\r\n\r\n    for shendu in range(2, 25):\r\n\r\n        uu = DT(tree_length=shendu)\r\n        # \xe5\xae\x8c\xe5\x85\xa8\xe6\x88\x90\xe9\x95\xbf\xe7\x9a\x84\xe6\xa0\x91\r\n        uu.grow_tree()\r\n        #  \xe4\xb8\x8d\xe5\x86\x8d\xe4\xbf\x9d\xe7\x95\x99\xe5\x89\xaa\xe6\x9e\x9d\xe7\x9a\x84\xe8\xbf\x87\xe7\xa8\x8b\r\n        # # \xe5\x89\xaa\xe6\x9e\x9d\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\xa0\x91\xe7\x9a\x84\xe9\x9b\x86\r\n        # gu = uu.prue_tree()\r\n        # # \xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa0\x91\r\n        # cc = uu.jiaocha_tree(gu[0])\r\n        # # \xe6\xa0\xb9\xe6\x8d\xae\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa0\x91\xe9\xa2\x84\xe6\xb5\x8b\xe6\x96\xb0\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\r\n        # uu.noderela = cc[0]\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\r\n        yannum = uu.pre_tree(uu.test_dtdata)\r\n        yazhengde.append(uu.compuer_mse(uu.test_dtdata[:, -1], yannum))\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\r\n        prenum = uu.pre_tree(uu.pre_dtdata)\r\n        yucede.append(uu.compuer_mse(uu.pre_dtdata[:, -1], prenum))\r\n\r\n        # \xe8\xae\xad\xe7\xbb\x83\r\n        trainnum = uu.pre_tree(uu.train_dtdata)\r\n        xunliande.append(uu.compuer_mse(uu.train_dtdata[:, -1], trainnum))\r\n\r\n        print(xunliande, yazhengde, yucede)\r\n\r\n        print('\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6', shendu)\r\n\r\n\r\n    # \xe5\x9c\xa8\xe5\x85\xb6\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe7\xbb\xbc\xe5\x90\x88MSE\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xef\xbc\x8c\xe7\xbb\x98\xe5\x88\xb6\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xaf\xb9\xe6\xaf\x94\r\n    # \xe9\x9a\x8f\xe7\x9d\x80\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe7\x9a\x84\xe5\xa2\x9e\xe5\x8a\xa0\xef\xbc\x8c\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84MSE\xe4\xb8\x80\xe7\x9b\xb4\xe5\x9c\xa8\xe5\x87\x8f\xe5\xb0\x91\r\n    # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xb2\xa1\xe6\x9c\x89\xe4\xba\x86\xe5\x89\xaa\xe6\x9e\x9d\xe8\xbf\x99\xe4\xb8\x80\xe6\xad\xa5\xe9\xaa\xa4\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\x84\x8f\xe4\xb9\x89\xe6\x98\xaf\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\r\n    # \xe5\x9b\xa0\xe6\xad\xa4\xe5\xbd\x93\xe9\xaa\x8c\xe8\xaf\x81\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb2\xbe\xe5\xba\xa6\xe4\xb8\x8d\xe5\x86\x8d\xe9\x99\x8d\xe4\xbd\x8e\xe6\x97\xb6\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe6\x98\xaf\xe6\x9c\x80\xe4\xbc\x98\xe6\xb7\xb1\xe5\xba\xa6\r\n    zonghe = [j + k for j, k in zip(yazhengde, yucede)]\r\n    # \xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe5\x80\xbc,\r\n    zuiyoushendu = zonghe.index(min(zonghe)) + 2\r\n\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe7\x9a\x84MSE\xe5\xaf\xb9\xe6\xaf\x94\xe5\x9b\xbe\r\n    plt.plot(list(range(2, 25)), xunliande, 'o--', label='\xe8\xae\xad\xe7\xbb\x83', lw=2)\r\n    plt.plot(list(range(2, 25)), yazhengde, '*--', label='\xe9\xaa\x8c\xe8\xaf\x81', lw=2)\r\n    plt.plot(list(range(2, 25)), yucede, 's--', label='\xe9\xa2\x84\xe6\xb5\x8b', lw=2)\r\n    plt.xlabel('\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6')\r\n    plt.xlim(1, 25)\r\n    plt.title('\xe6\xa0\x91\xe7\x9a\x84\xe6\x9c\x80\xe4\xbd\xb3\xe6\xb7\xb1\xe5\xba\xa6\xe4\xb8\xba\xef\xbc\x9a%d' % zuiyoushendu)\r\n    plt.ylabel('MSE')\r\n    plt.legend(shadow=True, fancybox=True)\r\n    plt.show()\r\n\r\n\r\n    # \xe9\x87\x8d\xe6\x96\xb0\xe5\xbb\xba\xe7\xab\x8b\xe6\xa0\x91\r\n    reuu = DT(tree_length=zuiyoushendu)\r\n    # \xe5\xae\x8c\xe5\x85\xa8\xe6\x88\x90\xe9\x95\xbf\xe7\x9a\x84\xe6\xa0\x91\r\n    reuu.grow_tree()\r\n\r\n\r\n    # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\r\n    yannum = reuu.pre_tree(reuu.test_dtdata)\r\n\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\r\n    prenum = reuu.pre_tree(reuu.pre_dtdata)\r\n\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\r\n    trainnum = reuu.pre_tree(reuu.train_dtdata)\r\n\r\n\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe5\xbe\x97\xe6\x9b\xb2\xe7\xba\xbf\r\n    plt.subplot(211)\r\n    a, b = selet(trainnum, reuu.train_dtdata[:, -1])\r\n    plt.plot(list(range(len(a))), a, list(range(len(b))), b)\r\n\r\n    plt.legend(['\xe9\xa2\x84\xe6\xb5\x8b', '\xe7\x9c\x9f\xe5\xae\x9e'])\r\n    plt.title('\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae')\r\n\r\n\r\n    plt.subplot(223)\r\n    c, d = selet(yannum, reuu.test_dtdata[:, -1], count=100)\r\n    plt.plot(list(range(len(c))), c, list(range(len(d))), d)\r\n    plt.legend(['\xe9\xa2\x84\xe6\xb5\x8b', '\xe7\x9c\x9f\xe5\xae\x9e'])\r\n    plt.title('\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae')\r\n\r\n    plt.subplot(224)\r\n    e, f = selet(prenum, reuu.pre_dtdata[:, -1], count=100)\r\n    plt.plot(list(range(len(e))), c, list(range(len(d))), f)\r\n    plt.legend(['\xe9\xa2\x84\xe6\xb5\x8b', '\xe7\x9c\x9f\xe5\xae\x9e'])\r\n    plt.title('\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae')\r\n\r\n    plt.show()"""
Decision Tree/DT_Regression/AnFany_example_DT.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nfrom pylab import mpl\r\nmpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams['axes.unicode_minus'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nimport AnFany_DT_Regression as model # \xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe6\xa8\xa1\xe5\x9e\x8b\r\nimport Data_DT_Regression as datafunc\r\n\r\n# \xe5\x85\xa8\xe9\x83\xa8\xe6\x95\xb0\xe6\x8d\xae\r\nx1 = np.arange(10, 200, 0.5)\r\nx2 = np.arange(1, 20, 0.05)\r\ny = np.sin(x1) + np.cos(x2)\r\n\r\n\r\nXY = np.array([x1, x2, y]).T\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\ndata_shili = datafunc.fenge(XY)\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\r\ndt_data = data_shili[0]\r\ntest_data = data_shili[1]\r\n\r\n\r\n# \xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe3\x80\x82\xe7\x9c\x8b\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\r\nif __name__ == '__main__':\r\n    # \xe6\xa0\xb9\xe6\x8d\xae\xe6\xa0\x91\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6\xef\xbc\x8c\xe7\x9c\x8b\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\r\n    xunliande = []\r\n    yazhengde = []\r\n    yucede = []\r\n\r\n    for shendu in range(2, 25):\r\n\r\n        uu = model.DT(train_dtdata=dt_data, pre_dtdata=test_data, tree_length=shendu)\r\n        # \xe5\xae\x8c\xe5\x85\xa8\xe6\x88\x90\xe9\x95\xbf\xe7\x9a\x84\xe6\xa0\x91\r\n        uu.grow_tree()\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\r\n        yannum = uu.pre_tree(uu.test_dtdata)\r\n        yazhengde.append(uu.compuer_mse(uu.test_dtdata[:, -1], yannum))\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\r\n        prenum = uu.pre_tree(uu.pre_dtdata)\r\n        yucede.append(uu.compuer_mse(uu.pre_dtdata[:, -1], prenum))\r\n\r\n        # \xe8\xae\xad\xe7\xbb\x83\r\n        trainnum = uu.pre_tree(uu.train_dtdata)\r\n        xunliande.append(uu.compuer_mse(uu.train_dtdata[:, -1], trainnum))\r\n\r\n        print(xunliande, yazhengde, yucede)\r\n\r\n        print('\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6', shendu)\r\n\r\n\r\n    # \xe5\x9c\xa8\xe5\x85\xb6\xe4\xb8\xad\xe9\x80\x89\xe6\x8b\xa9\xe7\xbb\xbc\xe5\x90\x88MSE\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xef\xbc\x8c\xe7\xbb\x98\xe5\x88\xb6\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xaf\xb9\xe6\xaf\x94\r\n    # \xe9\x9a\x8f\xe7\x9d\x80\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe7\x9a\x84\xe5\xa2\x9e\xe5\x8a\xa0\xef\xbc\x8c\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84MSE\xe4\xb8\x80\xe7\x9b\xb4\xe5\x9c\xa8\xe5\x87\x8f\xe5\xb0\x91\r\n    # \xe5\x9b\xa0\xe4\xb8\xba\xe6\xb2\xa1\xe6\x9c\x89\xe4\xba\x86\xe5\x89\xaa\xe6\x9e\x9d\xe8\xbf\x99\xe4\xb8\x80\xe6\xad\xa5\xe9\xaa\xa4\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\x84\x8f\xe4\xb9\x89\xe6\x98\xaf\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\r\n    # \xe5\x9b\xa0\xe6\xad\xa4\xe5\xbd\x93\xe9\xaa\x8c\xe8\xaf\x81\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb2\xbe\xe5\xba\xa6\xe4\xb8\x8d\xe5\x86\x8d\xe9\x99\x8d\xe4\xbd\x8e\xe6\x97\xb6\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe6\x98\xaf\xe6\x9c\x80\xe4\xbc\x98\xe6\xb7\xb1\xe5\xba\xa6\r\n    zonghe = [j + k for j, k in zip(yazhengde, yucede)]\r\n    # \xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe5\x80\xbc,\r\n    zuiyoushendu = zonghe.index(min(zonghe)) + 2\r\n\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe4\xb8\x8d\xe5\x90\x8c\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe7\x9a\x84MSE\xe5\xaf\xb9\xe6\xaf\x94\xe5\x9b\xbe\r\n    plt.plot(list(range(2, 25)), xunliande, 'o--', label='\xe8\xae\xad\xe7\xbb\x83', lw=2)\r\n    plt.plot(list(range(2, 25)), yazhengde, '*--', label='\xe9\xaa\x8c\xe8\xaf\x81', lw=2)\r\n    plt.plot(list(range(2, 25)), yucede, 's--', label='\xe9\xa2\x84\xe6\xb5\x8b', lw=2)\r\n    plt.xlabel('\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6')\r\n    plt.xlim(1, 25)\r\n    plt.title('\xe6\xa0\x91\xe7\x9a\x84\xe6\x9c\x80\xe4\xbd\xb3\xe6\xb7\xb1\xe5\xba\xa6\xe4\xb8\xba\xef\xbc\x9a%d' % zuiyoushendu)\r\n    plt.ylabel('MSE')\r\n    plt.legend(shadow=True, fancybox=True)\r\n    plt.show()\r\n\r\n\r\n    # \xe9\x87\x8d\xe6\x96\xb0\xe5\xbb\xba\xe7\xab\x8b\xe6\xa0\x91\r\n    reuu = model.DT(train_dtdata=dt_data, pre_dtdata=test_data, tree_length=zuiyoushendu)\r\n    # \xe5\xae\x8c\xe5\x85\xa8\xe6\x88\x90\xe9\x95\xbf\xe7\x9a\x84\xe6\xa0\x91\r\n    reuu.grow_tree()\r\n\r\n\r\n    # \xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\r\n    yannum = reuu.pre_tree(reuu.test_dtdata)\r\n\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\r\n    prenum = reuu.pre_tree(reuu.pre_dtdata)\r\n\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\r\n    trainnum = reuu.pre_tree(reuu.train_dtdata)\r\n\r\n\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe5\xbe\x97\xe6\x9b\xb2\xe7\xba\xbf\r\n    plt.subplot(211)\r\n    a, b = model.selet(trainnum, reuu.train_dtdata[:, -1], count=100000000)\r\n    plt.plot(list(range(len(a))), a, 'o--', list(range(len(b))), b, '*-')\r\n\r\n    plt.legend(['\xe9\xa2\x84\xe6\xb5\x8b', '\xe7\x9c\x9f\xe5\xae\x9e'])\r\n    plt.title('\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae')\r\n\r\n\r\n    plt.subplot(223)\r\n    c, d = model.selet(yannum, reuu.test_dtdata[:, -1], count=100000000)\r\n    plt.plot(list(range(len(c))), c, 'o--', list(range(len(d))), d, '*-')\r\n    plt.legend(['\xe9\xa2\x84\xe6\xb5\x8b', '\xe7\x9c\x9f\xe5\xae\x9e'])\r\n    plt.title('\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae')\r\n\r\n    plt.subplot(224)\r\n    e, f = model.selet(prenum, reuu.pre_dtdata[:, -1], count=100000000)\r\n    plt.plot(list(range(len(e))), c, 'o--', list(range(len(d))), f, '*-')\r\n    plt.legend(['\xe9\xa2\x84\xe6\xb5\x8b', '\xe7\x9c\x9f\xe5\xae\x9e'])\r\n    plt.title('\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae')\r\n\r\n    plt.show()\r\n\r\n\r\n\r\n\r\n"""
Decision Tree/DT_Regression/AnFany_pm2.5_Tree.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\n# \xe8\x87\xaa\xe9\x80\x82\xe5\xba\x94\xe4\xbc\x98\xe5\x8c\x96\xe7\xbb\x98\xe5\x88\xb6\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe7\xa8\x8b\xe5\xba\x8f\r\n\r\n# \xe7\xbb\x98\xe5\x88\xb6\xe5\x86\xb3\xe7\xad\x96\xe5\x9b\xbe\xe4\xb8\xbb\xe8\xa6\x81\xe5\x8c\x85\xe6\x8b\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\r\n# 1\xef\xbc\x8c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9(\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe5\xb1\x95\xe7\xa4\xba\xef\xbc\x8c\xe8\x8a\x82\xe7\x82\xb9\xe5\x90\x8d\xe7\xa7\xb0\xef\xbc\x8cMSE\xef\xbc\x8c\xe5\x88\x86\xe7\xb1\xbb\xe7\x89\xb9\xe5\xbe\x81\xef\xbc\x8c\xe6\x9c\xac\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c, \xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xe6\xb2\xa1\xe6\x9c\x89\xe5\x88\x86\xe7\xb1\xbb\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9)\r\n# 2\xef\xbc\x8c\xe7\xa1\xae\xe5\xae\x9a\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\xef\xbc\x88\xe5\x9e\x82\xe7\x9b\xb4\xe6\x96\xb9\xe5\x90\x91\xe5\xb9\xb3\xe5\x9d\x87\xe5\x88\x86\xe9\x85\x8d\xef\xbc\x8c\xe6\xb0\xb4\xe5\xb9\xb3\xe6\x96\xb9\xe5\x90\x91\xe6\x8c\x89\xe7\x85\xa7\xe8\xbf\x99\xe4\xb8\x80\xe5\xb1\x82\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\xe4\xb8\xaa\xe6\x95\xb0\xe5\xb9\xb3\xe5\x9d\x87\xe5\x88\x86\xe9\x85\x8d\xef\xbc\x89\r\n# 3\xef\xbc\x8c\xe7\xa1\xae\xe5\xae\x9a\xe8\x8a\x82\xe7\x82\xb9\xe4\xb9\x8b\xe9\x97\xb4\xe7\x9a\x84\xe8\xbf\x9e\xe7\xba\xbf\r\n# 4\xef\xbc\x8c\xe5\xb1\x95\xe7\xa4\xba\xe8\xbf\x9e\xe7\xba\xbf\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xef\xbc\x88\xe5\x88\x86\xe7\xb1\xbb\xe8\xa7\x84\xe5\x88\x99\xe4\xbb\xa5\xe5\x8f\x8a\xe5\x88\x86\xe5\x88\x86\xe5\x89\xb2\xe5\x80\xbc\xef\xbc\x89\r\n# 5\xef\xbc\x8c\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x8c\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xe4\xbb\xa5\xe4\xb8\x8d\xe7\x94\xa8\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\xe5\xb1\x95\xe7\xa4\xba\xef\xbc\x8c\xe5\xaf\xb9\xe7\xbb\x99\xe5\x87\xba\xe5\x9b\xbe\xe4\xbe\x8b\r\n\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe3\x80\x81\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe3\x80\x81\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe8\xa7\x84\xe5\x88\x99\xe3\x80\x81\xe5\x89\xaa\xe6\x9e\x9d\xe5\x90\x8e\xe4\xbb\xa3\xe8\xa1\xa8\xe7\x9d\x80\xe6\xa0\x91\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\xe5\x85\xb3\xe7\xb3\xbb\xe7\xbb\x98\xe5\x88\xb6\xe6\xa0\x91\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe7\xbb\x98\xe5\x88\xb6\xe6\xa0\x91\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe4\xbf\xa1\xe6\x81\xaf\r\nimport AnFany_DT_Regression as tree\r\n\r\n# \xe8\x8e\xb7\xe5\xbe\x97\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\xe7\xa7\xb0\r\nziduan = [\'year\', \'month\', \'day\', \'hour\', \'DEWP\', \'TEMP\', \'PRES\', \'cbwd\', \'Iws\', \'Is\', \'Ir\']\r\n\r\n\r\n\'\'\'\xe5\x87\x86\xe5\xa4\x87\xe9\x83\xa8\xe5\x88\x86\'\'\'\r\n#  \xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\r\ndef allnodes(guanxi):\r\n    allnode = list(guanxi.keys())\r\n    for jj in guanxi:\r\n        for hhh in guanxi[jj]:\r\n            if hhh not in allnode:\r\n                allnode.append(hhh)\r\n    #  \xe4\xb9\x8b\xe6\x89\x80\xe4\xbb\xa5\xe8\xa6\x81\xe6\x8c\x89\xe9\xa1\xba\xe5\xba\x8f\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x8c\xe6\x98\xaf\xe5\x9b\xa0\xe4\xb8\xba\xe5\x85\x88\xe7\x94\xbb\xe7\x88\xb6\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x8c\xe5\x90\x8e\xe7\x94\xbb\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\xb0\x86\xe7\xae\xad\xe5\xa4\xb4\xe7\x9b\x96\xe4\xbd\x8f\xef\xbc\x8c\xe6\x9b\xb4\xe4\xb8\xba\xe7\xbe\x8e\xe8\xa7\x82\r\n    return sorted(allnode)\r\n\r\n# \xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\ndef leafnodes(guanxi):\r\n    allnode = list(guanxi.keys())\r\n    leafnode = []\r\n    for jj in guanxi:\r\n        for hhh in guanxi[jj]:\r\n            if hhh not in allnode:\r\n                leafnode.append(hhh)\r\n    return leafnode\r\n\r\n# \xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\r\ndef noye_node(guanxi):\r\n    return list(guanxi.keys())\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xb1\x95\xe7\xa4\xba\xe5\x86\x85\xe5\xae\xb9\'\'\'\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe8\xbe\x93\xe5\x87\xba \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe7\x9a\x84MSE:\r\ndef output(shujuji, guanxi):\r\n    #  \xe5\xad\x97\xe5\x85\xb8\r\n    leibie = {}\r\n    for jjj in allnodes(guanxi):\r\n        cha = np.array(shujuji[jjj][:, -1]) - np.mean(np.array(shujuji[jjj][:, -1]))\r\n        leibie[jjj] = round(np.sum([i ** 2 for i in cha]) / len(cha), 1)\r\n    return leibie\r\n\r\n# \xe8\x8a\x82\xe7\x82\xb9\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe3\x80\x81\xe8\x8a\x82\xe7\x82\xb9\xe7\xbb\x93\xe6\x9e\x9c\xe3\x80\x81\xe8\x8a\x82\xe7\x82\xb9\xe8\xa7\x84\xe5\x88\x99\xe7\xbb\x98\xe5\x88\xb6\xe6\xa0\x91\r\n# \xe5\x88\xb6\xe4\xbd\x9c\xe8\x8a\x82\xe7\x82\xb9\xe9\x87\x8c\xe9\x9d\xa2\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\r\ndef dingyistr(shujuji, reeult, guize, guanxi, zian):\r\n    # \xe8\xa7\x84\xe5\x88\x99\xe5\xad\x97\xe5\x85\xb8\r\n    guizezidian = {}\r\n    #  \xe7\xb1\xbb\xe5\x88\xab\xe5\xad\x97\xe5\x85\xb8\r\n    leibii = output(shujuji, guanxi)\r\n    # \xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\xad\x97\xe5\x85\xb8\r\n    strdict = {}\r\n    # \xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\r\n    nonode = noye_node(guanxi)\r\n    # \xe9\x81\x8d\xe5\x8e\x86\xe9\x9c\x80\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x8c\xe8\x8e\xb7\xe5\xbe\x97\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe9\x9c\x80\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\x86\x85\xe5\xae\xb9\r\n    for jjj in allnodes(guanxi):\r\n        # \xe4\xb8\xba\xe8\x8a\x82\xe7\x82\xb9\xe6\xb7\xbb\xe5\x8a\xa0\xe5\x90\x8d\xe7\xa7\xb0\r\n        strdict[jjj] = \'\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x9a%s \\n\' % jjj  # \xe5\x86\x85\xe5\xae\xb9\xe5\x88\x86\xe8\xa1\x8c\r\n        # \xe5\xa6\x82\xe6\x9e\x9c\xe4\xb8\x8d\xe6\x98\xaf\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x8c\xe5\x88\x99\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe6\xb7\xbb\xe5\x8a\xa0\xe7\x89\xb9\xe5\xbe\x81\xef\xbc\x8c\xe5\x8f\xaa\xe6\xb7\xbb\xe5\x8a\xa0\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\r\n        if jjj not in nonode:\r\n            strdict[jjj] = \'MSE\xef\xbc\x9a%d \\n\' % leibii[jjj]\r\n        #  \xe5\xaf\xb9\xe4\xba\x8e\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe9\x9c\x80\xe8\xa6\x81\xe5\xa4\x9a\xe5\xa1\xab\xe5\x8a\xa0\xe4\xb8\x80\xe4\xb8\xaa\xe5\x88\x86\xe7\xb1\xbb\xe7\x89\xb9\xe5\xbe\x81\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xe3\x80\x81\xe5\x92\x8c\xe8\xa7\x84\xe5\x88\x99\r\n        else:\r\n            strdict[jjj] += \'MSE\xef\xbc\x9a%d \\n\' % leibii[jjj]\r\n            # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x88\x86\xe7\xb1\xbb\xe7\x89\xb9\xe5\xbe\x81\r\n            strdict[jjj] += \'\xe7\x89\xb9\xe5\xbe\x81\xef\xbc\x9a%s \\n\' % zian[guize[\'%s\' % (jjj + \'r\')][-1][0]]\r\n\r\n            # \xe6\xb7\xbb\xe5\x8a\xa0\xe8\xa7\x84\xe5\x88\x99\r\n            sign = 0\r\n            try:\r\n                guize[\'%s\' % (jjj + \'r\')][-1][1] + 1\r\n                sign = 1\r\n            except TypeError:\r\n                pass\r\n            if sign == 0:\r\n                guizezidian[jjj + \'l\'] = \'\xe5\x80\xbc\xe4\xb8\xba\xef\xbc\x9a\\n %s\' % guize[\'%s\' % (jjj + \'r\')][-1][1]\r\n                guizezidian[jjj + \'r\'] = \'\xe5\x80\xbc\xe4\xb8\x8d\xe4\xb8\xba\xef\xbc\x9a\\n %s\' % guize[\'%s\' % (jjj + \'r\')][-1][1]\r\n            else:\r\n                guizezidian[jjj + \'l\'] = \'\xe5\x80\xbc\xe4\xb8\x8d\xe5\xa4\xa7\xe4\xba\x8e\xef\xbc\x9a\\n %s\' % guize[\'%s\' % (jjj + \'r\')][-1][1]\r\n                guizezidian[jjj + \'r\'] = \'\xe5\x80\xbc\xe5\xa4\xa7\xe4\xba\x8e\xef\xbc\x9a\\n %s\' % guize[\'%s\' % (jjj + \'r\')][-1][1]\r\n\r\n        # \xe4\xb8\xba\xe9\x9c\x80\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\xe6\xb7\xbb\xe5\x8a\xa0\xe7\xbb\x93\xe6\x9e\x9c\r\n        strdict[jjj] += \'\xe7\xbb\x93\xe6\x9e\x9c\xef\xbc\x9a%s \' % reeult[jjj]\r\n    return strdict, guizezidian  # \xe5\x88\x86\xe5\x88\xab\xe8\xbf\x94\xe5\x9b\x9e\xe8\x8a\x82\xe7\x82\xb9\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xe5\xad\x97\xe5\x85\xb8\xe3\x80\x81\xe8\xbf\x9e\xe7\xba\xbf\xe4\xb8\x8a\xe9\x9c\x80\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\xe5\xad\x97\xe5\x85\xb8\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\'\'\'\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe8\x8a\x82\xe7\x82\xb9\xe5\x90\x8d\xe7\xa7\xb0\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe9\x95\xbf\xe5\xba\xa6\xef\xbc\x8c\xe7\xa1\xae\xe5\xae\x9a\xe7\x94\xbb\xe5\xb8\x83\xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f\r\ndef huabu(guanxi):\r\n    # \xe8\x8e\xb7\xe5\xbe\x97\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\r\n    suoyounodes = allnodes(guanxi)\r\n    # \xe8\x8e\xb7\xe5\x8f\x96\xe6\x9c\x80\xe9\x95\xbf\xe8\x8a\x82\xe7\x82\xb9\xe5\x90\x8d\xe7\xa7\xb0\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\xaa\xe9\x95\xbf\xe5\xba\xa6\xe5\x90\x8c\xe6\x97\xb6\xe4\xb9\x9f\xe6\x98\xaf\xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe3\x80\x82\r\n    changdu = max(len(i) for i in suoyounodes)\r\n    # \xe8\xbf\x94\xe5\x9b\x9e\xe9\x95\xbf\xe5\xba\xa6\xe4\xbb\xa5\xe5\x8f\x8a\xe7\x94\xbb\xe5\xb8\x83\xe5\xa4\xa7\xe5\xb0\x8f\r\n    return changdu + 1, 2**max(6, changdu)\r\n\r\n\r\n# \xe6\xb0\xb4\xe5\xb9\xb3\xe6\x94\xbe\xe4\xb8\x8b\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\xef\xbc\x8c\xe6\x98\xaf\xe6\xa0\xb9\xe6\x8d\xae\xe8\xbf\x99\xe4\xb8\x80\xe5\xb1\x82\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe3\x80\x81\xe4\xbb\xa5\xe5\x8f\x8a\xe6\xad\xa4\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe9\xa1\xba\xe5\xba\x8f\xe7\xa1\xae\xe5\xae\x9a\xe7\x9a\x84\r\ndef getorder(exnode, guanxi):\r\n    fu = []\r\n    for jj in allnodes(guanxi):\r\n        if len(jj) == len(exnode):\r\n            fu.append(jj)\r\n    # \xe6\x8e\x92\xe5\xba\x8f\r\n    sfu = sorted(fu)\r\n    return len(sfu) + 1, sfu.index(exnode) + 1 #\xe5\x89\x8d\xe8\x80\x85\xe5\x8a\xa01\xe6\x98\xaf\xe8\xae\xa1\xe7\xae\x97\xe9\x97\xb4\xe9\x9a\x94\xef\xbc\x8c\xe5\x90\x8e\xe8\x80\x85\xe5\x8a\xa01\xe6\x98\xaf\xe5\x9b\xa0\xe4\xb8\xbaindex\xe4\xbb\x8e0\xe5\xbc\x80\xe5\xa7\x8b\r\n\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe7\x94\xbb\xe5\xb8\x83\xe5\xa4\xa7\xe5\xb0\x8f\xe5\xae\x9a\xe4\xb9\x89\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe6\xa8\xaa\xe7\xba\xb5\xe5\x9d\x90\xe6\xa0\x87\xe4\xbd\x8d\xe7\xbd\xae\r\ndef jiedian_location(guanxi):\r\n    # \xe6\xa0\x91\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xef\xbc\x8c\xe7\x94\xbb\xe5\xb8\x83\xe5\xa4\xa7\xe5\xb0\x8f\r\n    shushen, huahuabu = huabu(guanxi)\r\n\r\n    # \xe8\xbf\x94\xe5\x9b\x9e\xe6\xaf\x8f\xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9\xe5\x9d\x90\xe6\xa0\x87\xe7\x9a\x84\xe5\xad\x97\xe5\x85\xb8\r\n    loca = {}\r\n    # \xe9\xa6\x96\xe5\x85\x88\xe5\xb0\x86\xe8\x8a\x82\xe7\x82\xb9\xe5\x90\x8d\xe7\xa7\xb0\xe6\x8c\x89\xe7\x85\xa7\xe9\x95\xbf\xe5\xba\xa6\xe7\xbb\x84\xe6\x88\x90\xe5\xad\x97\xe5\x85\xb8\r\n    changdu = {}\r\n    for jj in allnodes(guanxi):\r\n        try:\r\n            changdu[len(jj)].append(jj)\r\n        except KeyError:\r\n            changdu[len(jj)] = [jj]\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xa1\xae\xe5\xae\x9a\xe9\x9c\x80\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\r\n    for fi in allnodes(guanxi):\r\n        if fi not in loca:\r\n            for gu in changdu[len(fi)]:  # \xe5\x90\x8c\xe5\xb1\x82\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x88\xe4\xb9\x9f\xe5\xb0\xb1\xe6\x98\xaf\xe8\x8a\x82\xe7\x82\xb9\xe5\x90\x8d\xe7\xa7\xb0\xe9\x95\xbf\xe5\xba\xa6\xe4\xb8\x80\xe6\xa0\xb7\xe7\x9a\x84\xef\xbc\x89\xe4\xb8\x80\xe8\xb5\xb7\xe8\xae\xa1\xe7\xae\x97\r\n                number = getorder(gu, guanxi)\r\n                loca[gu] = [huahuabu / number[0] * number[1], huahuabu - (huahuabu / shushen) * len(gu)]\r\n    return loca\r\n\r\n\'\'\'\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\x87\x86\xe5\xa4\x87\xe5\xb7\xa5\xe4\xbd\x9c\xe7\xbb\x93\xe6\x9d\x9f\xef\xbc\x8c\xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x9b\xbe\'\'\'\r\n\r\n# \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x9b\xbe\r\ndef draw_tree(shujuji, result, guize, guanxi, zian=ziduan):\r\n    # \xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe5\x86\x85\xe5\xae\xb9\r\n    strziu = dingyistr(shujuji, result, guize, guanxi, zian)\r\n    # \xe8\x8a\x82\xe7\x82\xb9\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\r\n    weihzi = jiedian_location(guanxi)\r\n\r\n    noyye = noye_node(guanxi)\r\n\r\n    # \xe7\x94\xbb\xe5\xb8\x83\xe7\x9a\x84\xe8\xae\xbe\xe7\xbd\xae\r\n    huab = huabu(guanxi)[1] + 2  # \xe4\xb8\x8a\xe4\xb8\x8b\xe5\xb7\xa6\xe5\x8f\xb3\xe9\xa2\x84\xe7\x95\x99\xe7\xa9\xba\xe9\x97\xb4\r\n\r\n    fig, ax = plt.subplots(figsize=(huab, huab))\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe7\xbb\x98\xe5\x88\xb6\r\n    for jj in allnodes(guanxi):\r\n        print(jj)\r\n        # \xe7\xbb\x98\xe5\x88\xb6\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe8\x8a\x82\xe7\x82\xb9\xe8\xa6\x81\xe5\xb1\x95\xe7\xa4\xba\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\r\n        # \xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\r\n        if jj in noyye:\r\n            ax.text(weihzi[jj][0], weihzi[jj][1], strziu[0][jj], size=13, rotation=0.,\r\n                    ha=""center"", va=""center"",\r\n                    bbox=dict(boxstyle=""round"",\r\n                              ec=(0.6, 0.2, 0.6),\r\n                              fc=(0.3, 0.6, 0.3),\r\n                              )\r\n                    )\r\n        # \xe5\x8f\xb6\xe5\xad\x90\xe8\x8a\x82\xe7\x82\xb9\r\n        else:\r\n            ax.text(weihzi[jj][0], weihzi[jj][1], strziu[0][jj], size=13, rotation=0.,\r\n                    ha=""center"", va=""center"",\r\n                    bbox=dict(boxstyle=""round"",\r\n                              ec=(0.2, 0.5, 0.2),\r\n                              fc=(0.5, 0.2, 0.5),\r\n                              )\r\n                    )\r\n\r\n        # \xe5\x8f\xaa\xe5\xaf\xb9\xe5\x86\x85\xe9\x83\xa8\xe8\x8a\x82\xe7\x82\xb9\xe7\xbb\x98\xe5\x88\xb6\xe7\xae\xad\xe5\xa4\xb4\xe5\x92\x8c\xe5\xb7\xa6\xe5\x8f\xb3\xe7\x9a\x84\xe5\x88\x86\xe7\xb1\xbb\xe8\xa7\x84\xe5\x88\x99\r\n        if jj in noyye:\r\n            # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\xb7\xa6\xe5\x8f\xb3\xe7\xae\xad\xe5\xa4\xb4\r\n\r\n            ax.annotate(\' \', xy=(weihzi[jj + \'r\'][0], weihzi[jj + \'r\'][1]), xytext=(weihzi[jj][0], weihzi[jj][1]), ha=""center"", va=""center"",\r\n                        arrowprops=dict(facecolor=\'darkred\', shrink=0.128))\r\n\r\n            ax.annotate(\' \', xy=(weihzi[jj + \'l\'][0], weihzi[jj + \'l\'][1]), xytext=(weihzi[jj][0], weihzi[jj][1]),\r\n                        ha=""center"", va=""center"", arrowprops=dict(facecolor=\'darkred\', shrink=0.128))\r\n\r\n\r\n            # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\xb7\xa6\xe5\x8f\xb3\xe8\xa7\x84\xe5\x88\x99\r\n            ax.text((weihzi[jj + \'l\'][0] + weihzi[jj][0]) / 2, \\\r\n                    (weihzi[jj + \'l\'][1] + weihzi[jj][1]) / 2 - 0.2, strziu[1][jj + \'l\'], fontsize=12, color=\'red\', weight=\'bold\')\r\n\r\n            ax.text((weihzi[jj + \'r\'][0] + weihzi[jj][0]) / 2, \\\r\n                    (weihzi[jj + \'r\'][1] + weihzi[jj][1]) / 2 - 0.2, strziu[1][jj + \'r\'], fontsize=12, color=\'red\', weight=\'bold\')\r\n\r\n    ax.set(xlim=(0, huab), ylim=(0, huab))\r\n\r\n    plt.show()\r\n\r\n# \xe6\xa0\xb9\xe6\x8d\xae\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\xe3\x80\x82\xe7\x9c\x8b\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x8f\x98\xe5\x8c\x96\r\nif __name__ == \'__main__\':\r\n    # \xe8\x8e\xb7\xe5\xbe\x97\xe6\xa0\x91\xe7\x9a\x84\xe4\xbf\xa1\xe6\x81\xaf\r\n\r\n    decision_tree = tree.DT(tree_length=4)\r\n    # \xe5\xae\x8c\xe5\x85\xa8\xe6\x88\x90\xe9\x95\xbf\xe7\x9a\x84\xe6\xa0\x91\r\n    decision_tree.grow_tree()\r\n    # # \xe5\x89\xaa\xe6\x9e\x9d\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\xa0\x91\xe7\x9a\x84\xe9\x9b\x86\r\n    # gu = decision_tree.prue_tree()\r\n    # # \xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe5\xbd\xa2\xe6\x88\x90\xe7\x9a\x84\xe6\x9c\x80\xe5\xa5\xbd\xe7\x9a\x84\xe6\xa0\x91\r\n    # cc = decision_tree.jiaocha_tree(gu[0])\r\n    # print(cc[0])\r\n    # \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    shuju = decision_tree.node_shujuji\r\n    # \xe7\xbb\x93\xe6\x9e\x9c\r\n    jieguo = decision_tree.jieguo_tree()\r\n    # \xe8\xa7\x84\xe5\x88\x99\r\n    rule = decision_tree.node_rule\r\n    draw_tree(shuju, jieguo, rule, decision_tree.noderela)\r\n\r\n\r\n'"
Decision Tree/DT_Regression/Data_DT_Regression.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\PRSA_data_2010.1.1-2014.12.31.csv')\r\n\r\n#  \xe5\x9b\xa0\xe4\xb8\xba\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe5\x9b\x9e\xe5\xbd\x92\xe5\x92\x8c\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe5\x88\x86\xe7\xb1\xbb\xe7\xa8\x8b\xe5\xba\x8f\xef\xbc\x8c\xe7\x9b\xb8\xe4\xbc\xbc\xe6\x80\xa7\xe5\xbe\x88\xe5\xa4\xa7\xef\xbc\x8c\xe5\x94\xaf\xe4\xb8\x80\xe7\x9a\x84\xe4\xb8\x8d\xe5\x90\x8c\xe5\x9c\xa8\xe4\xba\x8e\xe5\x88\x86\xe7\xb1\xbb\xe8\xae\xa1\xe7\xae\x97\xe5\x9f\xba\xe5\xb0\xbc\xe7\xb3\xbb\xe6\x95\xb0\xef\xbc\x8c\xe8\x80\x8c\xe5\x9b\x9e\xe5\xbd\x92\xe8\xae\xa1\xe7\xae\x97MSE\xe3\x80\x82\r\n#  \xe5\x9b\xa0\xe6\xad\xa4\xe5\x9b\x9e\xe5\xbd\x92\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe5\x9c\xa8\xe6\xad\xa4\xe5\xa4\x84\xe5\x92\x8c\xe5\x88\x86\xe7\xb1\xbb\xe7\x9a\x84\xe7\x9b\xb8\xe4\xbc\xbc\r\n\r\n#  \xe5\x9b\xa0\xe4\xb8\xba\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe6\x9c\x89\xe4\xba\x9b\xe5\x8f\x98\xe9\x87\x8f\xe7\x9a\x84\xe5\x80\xbc\xe6\x98\xaf\xe7\xa6\xbb\xe6\x95\xa3\xe7\x9a\x84\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe6\x98\xaf\xe6\x95\xb4\xe6\x95\xb0\xe8\xa1\xa8\xe7\xa4\xba\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe8\xbf\x99\xe9\x87\x8c\xe9\x9c\x80\xe8\xa6\x81\xe5\xb0\x86\xe5\x85\xb6\xe5\x8f\x98\xe4\xb8\xba\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xef\xbc\x8c\r\n#  \xe8\xbf\x99\xe4\xb8\xbb\xe8\xa6\x81\xe6\xb6\x89\xe5\x8f\x8a\xe7\x9a\x84\xe5\x8f\x98\xe9\x87\x8f\xe5\x8c\x85\xe6\x8b\xac\xef\xbc\x9ayear\tmonth\tday\thour\r\n\r\n'''\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86'''\r\n#  \xe5\x9b\xa0\xe4\xb8\xbaPm2.5\xe6\x98\xaf\xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xaf\xb9\xe4\xba\x8e\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9b\xb4\xe6\x8e\xa5\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xb8\x80\xe6\x9d\xa1\xe8\xae\xb0\xe5\xbd\x95\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe5\x88\xa0\xe9\x99\xa4\xe7\x9b\xae\xe6\xa0\x87\xe5\x80\xbc\xe4\xb8\xba\xe7\xa9\xba\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0, \xe5\x85\xb6\xe4\xbb\x96\xe5\x88\x97\xe4\xb8\xba\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe5\x88\x99\xe8\x87\xaa\xe5\x8a\xa8\xe5\xa1\xab\xe5\x85\x85\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0,\xe5\xb9\xb6\xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\x8f\x98\xe9\x87\x8f\xe6\x94\xbe\xe7\xbd\xae\xe5\x9c\xa8\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe5\x88\x97\r\ndef DeleteTargetNan(exdata, targetstr):\r\n    #  \xe9\xa6\x96\xe5\x85\x88\xe5\x88\xa4\xe6\x96\xad\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\r\n    if exdata[targetstr].isnull().any():\r\n        #  \xe9\xa6\x96\xe5\x85\x88\xe7\xa1\xae\xe5\xae\x9a\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe8\xa1\x8c\xe6\x95\xb0\r\n        loc = exdata[targetstr][data[targetstr].isnull().values == True].index.tolist()\r\n        #  \xe7\x84\xb6\xe5\x90\x8e\xe5\x88\xa0\xe9\x99\xa4\xe8\xbf\x99\xe4\xba\x9b\xe8\xa1\x8c\r\n        exdata = exdata.drop(loc)\r\n    # \xe5\x87\xa1\xe6\x98\xaf\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe7\x9a\x84\xe5\x86\x8d\xe4\xb8\x80\xe8\xb5\xb7\xe5\x88\xa9\xe7\x94\xa8\xe6\xad\xa4\xe8\xa1\x8c\xe7\x9a\x84\xe5\x9d\x87\xe5\x80\xbc\xe5\xa1\xab\xe5\x85\x85\r\n    exdata = exdata.fillna(exdata.mean())\r\n    # \xe5\xb0\x86\xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe8\x87\xb3\xe6\x94\xbe\xe5\x9c\xa8\xe6\x9c\x80\xe5\x90\x8e\xe7\x9a\x84\xe4\xb8\x80\xe5\x88\x97\r\n    targetnum = exdata[targetstr].copy()\r\n    del exdata[targetstr]\r\n    exdata[targetstr] = targetnum\r\n    return exdata\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xba\xe6\xad\xa4\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xb8\xad\xe7\x9a\x84year\xef\xbc\x8cmonth, day, hour\xe5\x9d\x87\xe4\xb8\xba\xe6\x95\xb4\xe6\x95\xb0\xe5\x9e\x8b\xef\xbc\x8c\xe5\x86\x8d\xe7\xa8\x8b\xe5\xba\x8f\xe4\xb8\xad\xe4\xbc\x9a\xe8\xa2\xab\xe5\xbd\x93\xe5\x81\x9a\xe8\xbf\x9e\xe7\xbb\xad\xe7\x9a\x84\xe5\x8f\x98\xe9\x87\x8f\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\r\ndef Shanchu(exdata, aiduan=['No']):\r\n    for ai in aiduan:\r\n        if ai in exdata.keys():\r\n            del exdata[ai]\r\n    return exdata\r\n\r\n\r\n# \xe5\x9b\xa0\xe6\xad\xa4\xe8\xbf\x99\xe9\x87\x8c\xe5\xb0\x86\xe8\xbf\x994\xe4\xb8\xaa\xe5\x8f\x98\xe9\x87\x8f\xe5\x8f\x98\xe4\xb8\xba\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\x9a\x84\xe5\xbd\xa2\xe5\xbc\x8f\r\ndef TeshuHandle(exdata, ziduan=['year', 'month', 'day', 'hour'], tianjiastr=['\xe5\xb9\xb4', '\xe6\x9c\x88', '\xe6\x97\xa5', '\xe6\x97\xb6']):\r\n    for j, k in zip(ziduan, tianjiastr):\r\n        if j in exdata.keys():\r\n            exdata[j] = ['%d%s' % (j, k) for j in exdata[j]]\r\n    return exdata\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n\r\nfirst = DeleteTargetNan(data, 'pm2.5')\r\ntwo = Shanchu(first)\r\nthird = TeshuHandle(two)\r\n\r\n# \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe6\x8c\x89\xe7\x85\xa77\xef\xbc\x9b1.5:1.5\xe7\x9a\x84\xe6\xaf\x94\xe4\xbe\x8b\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n\r\ndef fenge(exdata, per=[0.15, 0.15]):\r\n    # \xe6\x80\xbb\xe9\x95\xbf\xe5\xba\xa6\r\n    lent = len(exdata)\r\n    alist = np.arange(lent)\r\n    np.random.shuffle(alist)\r\n\r\n    # \xe9\xaa\x8c\xe8\xaf\x81\r\n    shu = int(lent * per[0])\r\n    yu = int(lent * per[1])\r\n\r\n    yanzheng = np.random.choice(alist, shu, replace=False)\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    shengxai = np.array([i for i in alist if i not in yanzheng])\r\n\r\n    yuce = np.random.choice(shengxai, yu, replace=False)\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\r\n    train = np.array([j for j in alist if j not in yanzheng and j not in yuce])\r\n\r\n    # \xe8\xbf\x94\xe5\x9b\x9e\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\n    dadata = {}\r\n    dadata[0] = {}\r\n\r\n    dadata[0]['train'] = exdata[train]\r\n    dadata[0]['test'] = exdata[yanzheng]\r\n\r\n    return dadata, exdata[yuce]\r\n\r\ndeeer = fenge(third.values)\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\r\ndt_data = deeer[0]\r\ntest_data = deeer[1]\r\n\r\n\r\n#  \xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\xe5\x92\x8c\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe5\x88\x86\xe7\xb1\xbb\xe6\x98\xaf\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84\xef\xbc\x8c\r\n"""
Decision Tree/DT_Regression/Sklearn_DT_Regression.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n# \xe5\x9b\x9e\xe5\xbd\x92\xe6\xa0\x91\xef\xbc\x8c \xe5\x8f\xaf\xe5\xa4\x84\xe7\x90\x86\xe7\xa6\xbb\xe6\x95\xa3\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xbf\x9e\xe7\xbb\xad\xe7\x9a\x84\xe5\x8f\x98\xe9\x87\x8f\r\n\r\n\r\nfrom sklearn.tree import DecisionTreeRegressor as skdt  # \xe5\xbc\x95\xe5\x85\xa5Sklearn\xe4\xb8\xad\xe7\x9a\x84\xe5\x86\xb3\xe7\xad\x96\xe6\xa0\x91\xe6\xa8\xa1\xe5\x9e\x8b\r\nimport Data_DT_Regression as data  # \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nimport matplotlib.pyplot as plt  # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\r\nfrom pylab import mpl\r\nmpl.rcParams['font.sans-serif'] = ['FangSong']  # \xe6\x98\xbe\xe7\xa4\xba\xe4\xb8\xad\xe6\x96\x87\r\nmpl.rcParams['axes.unicode_minus'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xbaSklearn\xe5\x8f\xaa\xe8\x83\xbd\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe5\x80\xbc\xe5\x9e\x8b\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe9\x9c\x80\xe8\xa6\x81\xe7\x88\xb8X\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe5\x80\xbc\xe4\xb8\xba\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe7\x9a\x84\xe5\x8f\x98\xe9\x87\x8f\xe8\xbd\xac\xe5\x8f\x98\xe4\xb8\xba\xe6\x95\xb0\xe5\x80\xbc\xe5\x9e\x8b\xe3\x80\x82\r\n# \xe8\xbf\x99\xe9\x87\x8c\xe6\x9c\xaa\xe9\x87\x87\xe7\x94\xa8\xe7\x8b\xac\xe7\x83\xad\xe5\x8c\x96\xe7\xbc\x96\xe7\xa0\x81\xef\xbc\x8c\xe4\xb8\x80\xe6\x98\xaf\xe8\x80\x83\xe8\x99\x91\xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x8f\xe4\xbc\x9a\xe9\x80\x92\xe5\xa2\x9e \xe4\xba\x8c\xe6\x98\xaf\xe4\xb8\xa4\xe8\x80\x85\xe7\x9a\x84\xe6\x95\x88\xe6\x9e\x9c\xe5\xba\x94\xe8\xaf\xa5\xe7\x9b\xb8\xe5\xb7\xae\xe4\xb8\x8d\xe5\xa4\xa7\r\n\r\n# \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xaeX\r\nX_data = data.dt_data[0]['train'][:, :-1]\r\n# Y\r\nY_data = data.dt_data[0]['train'][:, -1:].T[0]\r\n\r\n# \xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xaeX\r\nX_data_test = data.dt_data[0]['test'][:, :-1]\r\n# Y\r\nY_data_test = data.dt_data[0]['test'][:, -1:].T[0]\r\n\r\n\r\n# \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\nX_data_pre = data.test_data[:, :-1]\r\n# Y\r\nY_data_pre = data.test_data[:, -1:].T[0]\r\n\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe6\x9b\xb4\xe6\x94\xb9\xe6\x89\x80\xe6\x9c\x89\xe7\xa6\xbb\xe6\x95\xa3\xe5\x8f\x98\xe9\x87\x8f\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef LisanToLianxu(tdata, ydata, pdata):\r\n    for jj in range(len(tdata[0])):\r\n        try:\r\n            tdata[0][jj] + 2\r\n            pass\r\n        except TypeError:\r\n            # \xe8\xbf\x99\xe6\x98\xaf\xe7\xa6\xbb\xe6\x95\xa3\xe7\x9a\x84\xe9\x9c\x80\xe8\xa6\x81\xe5\xa4\x84\xe7\x90\x86\r\n            #  \xe9\xbb\x98\xe8\xae\xa4 \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe5\x8c\x85\xe6\x8b\xac\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe6\x9c\xac\xe5\x8f\x98\xe9\x87\x8f\xe7\x9a\x84\xe5\x80\xbc\r\n            zhiset = list(set(list(tdata[:, jj:(jj + 1)].T[0])))\r\n\r\n            # \xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x80\xbc\xe8\xb5\x8b\xe4\xba\x88\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\xb0\r\n\r\n            numdict = {i: zhiset.index(i) for i in zhiset}\r\n\r\n            # \xe5\xbc\x80\xe5\xa7\x8b\xe4\xb8\xba\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xad\xe7\x9a\x84\xe8\xbf\x99\xe4\xb8\x80\xe5\x88\x97\xe8\xb5\x8b\xe5\x80\xbc\r\n            def zhihuan(tdata, jj, exdict=numdict):\r\n                # \xe8\xbf\x99\xe9\x87\x8c\xe9\x9c\x80\xe8\xa6\x81\xe5\xbb\xba\xe7\xab\x8b\xe4\xb8\x80\xe4\xb8\xaaDataFrame\r\n                du = pd.DataFrame()\r\n\r\n                du['zhi'] = tdata[:, jj:(jj + 1)].T[0]\r\n\r\n                du['zhi'] = du['zhi'].map(exdict)\r\n\r\n                tdata[:, jj:(jj + 1)] = np.array([du['zhi'].values]).T\r\n                return tdata\r\n\r\n            tdata = zhihuan(tdata, jj)\r\n            ydata = zhihuan(ydata, jj)\r\n            pdata = zhihuan(pdata, jj)\r\n\r\n    return tdata, ydata, pdata\r\n\r\n\r\n# \xe5\xae\x9a\xe4\xb9\x89\xe8\xae\xa1\xe7\xae\x97\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n\r\ndef CorrectRate(yuanshileibei, shuchuleibie):\r\n    npyuan = np.array(yuanshileibei)\r\n    noshu = np.array(shuchuleibie)\r\n    cha = npyuan - noshu\r\n    return np.sum([i ** 2 for i in cha]) / len(npyuan)\r\n\r\n\r\nX_data, X_data_test, X_data_pre = LisanToLianxu(X_data, X_data_test, X_data_pre)\r\n\r\n\r\n\r\n#  \xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x8f\xe8\xbe\x83\xe5\xa4\xa7\xef\xbc\x8c\xe6\x8a\x98\xe7\xba\xbf\xe5\x9b\xbe\xe5\xaf\xb9\xe6\xaf\x94\xe4\xb8\x8d\xe5\xae\xb9\xe6\x98\x93\xe7\x9c\x8b\xe6\xb8\x85\xef\xbc\x8c\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96200\xe6\x9d\xa1\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96100\xe6\x9d\xa1\xe5\xb1\x95\xe7\xa4\xba\r\ndef selet(prdata, reda, count=200):\r\n    if len(reda) <= count:\r\n        return prdata, reda\r\n    fu = np.arange(len(reda))\r\n\r\n    du = np.random.choice(fu, count)\r\n\r\n    return np.array(prdata)[du], np.array(reda)[du]\r\n\r\n\r\n#  \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe4\xb8\xbb\xe5\x87\xbd\xe6\x95\xb0\r\nif __name__ == '__main__':\r\n    xunliande = []\r\n    yazhengde = []\r\n    yucede = []\r\n\r\n    #  \xe9\x92\x88\xe5\xaf\xb9\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n    for i in range(2, 25):\r\n        clf = skdt(max_depth=i).fit(X_data, Y_data)\r\n        # \xe8\xae\xad\xe7\xbb\x83\r\n        Y_data_shu = clf.predict(X_data)\r\n\r\n        xunliande.append(CorrectRate(Y_data, Y_data_shu))\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\r\n        Y_data_test_shu = clf.predict(X_data_test)\r\n\r\n        yazhengde.append(CorrectRate(Y_data_test, Y_data_test_shu))\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\r\n        Y_data_pre_shu = clf.predict(X_data_pre)\r\n\r\n        yucede.append(CorrectRate(Y_data_pre, Y_data_pre_shu))\r\n\r\n    # \xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe4\xbc\x98\xe7\x9a\x84\xe6\xb7\xb1\xe5\xba\xa6\r\n\r\n    zonghe = [j + k for j, k in zip(yazhengde, yucede)]\r\n    # \xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xb0\x8f\xe7\x9a\x84\xe5\x80\xbc,\r\n    zuiyoushendu = zonghe.index(min(zonghe)) + 2\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\r\n    plt.plot(list(range(2, 25)), xunliande, 'o--', label='\xe8\xae\xad\xe7\xbb\x83', lw=2)\r\n    plt.plot(list(range(2, 25)), yazhengde, '*--', label='\xe9\xaa\x8c\xe8\xaf\x81', lw=2)\r\n    plt.plot(list(range(2, 25)), yucede, 's--', label='\xe9\xa2\x84\xe6\xb5\x8b', lw=2)\r\n    plt.xlabel('\xe6\xa0\x91\xe7\x9a\x84\xe5\x88\x9d\xe5\xa7\x8b\xe6\xb7\xb1\xe5\xba\xa6')\r\n    plt.xlim(1, 25)\r\n    plt.grid()\r\n    plt.ylabel('MSE')\r\n    plt.legend(shadow=True, fancybox=True)\r\n    plt.title('\xe6\xa0\x91\xe7\x9a\x84\xe6\x9c\x80\xe4\xbd\xb3\xe6\xb7\xb1\xe5\xba\xa6\xef\xbc\x9a%d' % zuiyoushendu)\r\n    plt.show()\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe5\xbe\x97\xe5\xaf\xb9\xe6\xaf\x94\xe6\x9b\xb2\xe7\xba\xbf\r\n\r\n    clf = skdt(max_depth=zuiyoushendu).fit(X_data, Y_data)\r\n    # \xe8\xae\xad\xe7\xbb\x83\r\n    Y_data_shu = clf.predict(X_data)\r\n    # \xe9\xaa\x8c\xe8\xaf\x81\r\n    Y_data_test_shu = clf.predict(X_data_test)\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\r\n    Y_data_pre_shu = clf.predict(X_data_pre)\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe5\xbe\x97\xe6\x9b\xb2\xe7\xba\xbf\r\n    plt.subplot(211)\r\n    a, b = selet(Y_data_shu, Y_data)\r\n    plt.plot(list(range(len(a))), a, 'o--', list(range(len(b))), b, '8-')\r\n\r\n    plt.legend(['\xe9\xa2\x84\xe6\xb5\x8b', '\xe7\x9c\x9f\xe5\xae\x9e'])\r\n    plt.title('\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae')\r\n\r\n\r\n    plt.subplot(223)\r\n    c, d = selet(Y_data_test_shu, Y_data_test, count=100)\r\n    plt.plot(list(range(len(c))), c, 'o--', list(range(len(d))), d, '8-')\r\n    plt.legend(['\xe9\xa2\x84\xe6\xb5\x8b', '\xe7\x9c\x9f\xe5\xae\x9e'])\r\n    plt.title('\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae')\r\n\r\n    plt.subplot(224)\r\n    e, f = selet(Y_data_pre_shu, Y_data_pre, count=100)\r\n    plt.plot(list(range(len(e))), e, 'o--', list(range(len(f))), f, '8-')\r\n    plt.legend(['\xe9\xa2\x84\xe6\xb5\x8b', '\xe7\x9c\x9f\xe5\xae\x9e'])\r\n    plt.title('\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae')\r\n\r\n    plt.show()\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"""
SVM/SVM_Classify/AnFany_SVM_Classify.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author AnFany\r\n\r\n# SMO\xe7\xae\x97\xe6\xb3\x95\xe5\xae\x9e\xe7\x8e\xb0\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe4\xba\x8c\xe5\x88\x86\xe7\xb1\xbb\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xbc\x95\xe5\x85\xa5\xe5\xba\x93\r\n""""""\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9e\x84\xe5\xbb\xba\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe4\xbb\xa5\xe5\x8f\x8aSVM\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x84\r\n""""""\r\n\r\n#  \xe6\x9e\x84\xe5\xbb\xba\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\nclass KERNEL:\r\n    """"""\r\n    linear\xef\xbc\x9a\xe7\xba\xbf\xe6\x80\xa7   rbf\xef\xbc\x9a\xe9\xab\x98\xe6\x96\xaf  sigmoid\xef\xbc\x9aSigmoid\xe5\x9e\x8b  poly\xef\xbc\x9a\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\r\n    \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x9a\xe6\xb3\xa8\xe6\x84\x8f\xe8\xbe\x93\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84shape\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84shape\xe3\x80\x82\r\n    xVSy\xe5\x8c\x85\xe6\x8b\xac3\xe7\xa7\x8d\xe6\x83\x85\xe5\x86\xb5\xef\xbc\x9a\xe5\x8d\x95\xe6\xa0\xb7\xe6\x9c\xacVS\xe5\x8d\x95\xe6\xa0\xb7\xe6\x9c\xac  \xe5\x8d\x95\xe6\xa0\xb7\xe6\x9c\xacVS\xe5\xa4\x9a\xe6\xa0\xb7\xe6\x9c\xac  \xe5\xa4\x9a\xe6\xa0\xb7\xe6\x9c\xacVS\xe5\xa4\x9a\xe6\xa0\xb7\xe6\x9c\xac\r\n    """"""\r\n    def __init__(self, polyd=3, rbfsigma=0.2, tanhbeta=0.6, tanhtheta=-0.6):\r\n        self.polyd = polyd\r\n        self.rbfsigma = rbfsigma\r\n        self.tanhbeta = tanhbeta\r\n        self.tanhtheta = tanhtheta\r\n\r\n    def trans(self, x):\r\n        x = np.array(x)\r\n        if x.ndim == 1:\r\n            x = np.array([x])\r\n        return x\r\n    # \xe7\xba\xbf\xe6\x80\xa7\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n    def linear(self, x, y):  # \xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9cshape=(len(y), len(x))\r\n        x, y = self.trans(x), self.trans(y)\r\n        if len(x) == 1:\r\n            return (x * y).sum(axis=1, keepdims=True)\r\n        else:\r\n            sx = x.reshape(x.shape[0], -1, x.shape[1])\r\n            return (sx * y).sum(axis=2).T\r\n\r\n    # Singmoid\xe5\x9e\x8b\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n    def sigmoid(self, x, y):  # \xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9cshape=(len(y), len(x))\r\n        x, y = self.trans(x), self.trans(y)\r\n        if len(x) == 1:\r\n            return np.tanh(self.tanhbeta * ((x * y).sum(axis=1, keepdims=True)) + self.tanhtheta)\r\n        else:\r\n            sx = x.reshape(x.shape[0], -1, x.shape[1])\r\n            return np.tanh(self.tanhbeta * ((sx * y).sum(axis=2).T) + self.tanhtheta)\r\n\r\n    # \xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n    def poly(self, x, y):  # \xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9cshape=(len(y), len(x))\r\n        x, y = self.trans(x), self.trans(y)\r\n        if len(x) == 1:\r\n            return (x * y).sum(axis=1, keepdims=True) ** self.polyd\r\n        else:\r\n            sx = x.reshape(x.shape[0], -1, x.shape[1])\r\n            return (sx * y).sum(axis=2).T ** self.polyd\r\n\r\n    #  \xe9\xab\x98\xe6\x96\xaf\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n    def rbf(self, x, y):  # \xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9cshape=(len(y), len(x))\r\n        x, y = self.trans(x), self.trans(y)\r\n        if len(x) == 1 and len(y) == 1:\r\n            return np.exp(self.linear((x - y), (x - y)) / (-2 * self.rbfsigma ** 2))\r\n        elif len(x) == 1 and len(y) != 1:\r\n            return np.exp((np.power(x - y, 2)).sum(axis=1, keepdims=True) / (-2 * self.rbfsigma ** 2))\r\n        else:\r\n            sx = x.reshape(x.shape[0], -1, x.shape[1])\r\n            return np.exp((np.power(sx - y, 2)).sum(axis=2).T / (-2 * self.rbfsigma ** 2))\r\n\r\n\r\n#  \xe6\x9e\x84\xe5\xbb\xbaSVM\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x84\r\nclass SVM:\r\n    def __init__(self, feature, labels, kernel=\'rbf\', C=0.8, toler=0.001, times=100):\r\n        #  \xe8\xae\xad\xe7\xbb\x83\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe5\xb1\x9e\xe6\x80\xa7\xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x81\xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\xe6\x8d\xae\r\n        self.feature = feature\r\n        self.labels = labels\r\n\r\n\r\n        # SMO\xe7\xae\x97\xe6\xb3\x95\xe5\x8f\x98\xe9\x87\x8f\r\n        self.C = C\r\n        self.toler = toler\r\n        self.alphas = np.zeros(len(self.feature))\r\n        self.b = 0\r\n        self.eps = 0.0001  # \xe9\x80\x89\xe6\x8b\xa9\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\r\n\r\n        # \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n        self.kernel = eval(\'KERNEL().\' + kernel)\r\n\r\n        # \xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe8\xaf\xaf\xe5\xb7\xae\xe5\xba\x8f\xe5\x88\x97\r\n        self.errors = [self.get_error(i) for i in range(len(self.feature))]\r\n\r\n        #  \xe5\xbe\xaa\xe7\x8e\xaf\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe6\xac\xa1\xe6\x95\xb0\r\n        self.times = times\r\n\r\n\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe5\x88\x86\xe5\x89\xb2\xe7\xba\xbf\xe7\x9a\x84\xe5\x80\xbc\r\n    def line_num(self, x):\r\n        ks = self.kernel(x, self.feature)\r\n        wx = np.matrix(self.alphas * self.labels) * ks\r\n        num = wx + self.b\r\n        return num[0][0]\r\n\r\n    #  \xe8\x8e\xb7\xe5\xbe\x97\xe7\xbc\x96\xe5\x8f\xb7\xe4\xb8\xbai\xe7\x9a\x84\xe6\xa0\xb7\xe6\x9c\xac\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n    def get_error(self, i):\r\n        x, y = self.feature[i], self.labels[i]\r\n        error = self.line_num(x) - y\r\n        return error\r\n\r\n    #  \xe6\x9b\xb4\xe6\x94\xb9\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\xe5\x90\x8e\xef\xbc\x8c\xe6\x9b\xb4\xe6\x96\xb0\xe6\x89\x80\xe6\x9c\x89\xe6\xa0\xb7\xe6\x9c\xac\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n    def update_errors(self):\r\n        self.errors = [self.get_error(i) for i in range(len(self.feature))]\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9e\x84\xe5\xbb\xbaSMO\xe7\xae\x97\xe6\xb3\x95\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n""""""\r\n#  alpha\xe7\x9a\x84\xe5\x80\xbc\xe5\x88\xb0L\xe5\x92\x8cH\xe4\xb9\x8b\xe9\x97\xb4.\r\ndef clip(alpha, L, H):\r\n    if alpha < L:\r\n        return L\r\n    elif alpha > H:\r\n        return H\r\n    else:\r\n        return alpha\r\n\r\n#  \xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe6\x8b\xa9\xe4\xb8\x80\xe4\xb8\xaa\xe5\x92\x8c\xe5\xbd\x93\xe5\x89\x8d\xe5\x9b\xa0\xe5\xad\x90\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84\xe5\x9b\xa0\xe5\xad\x90\r\ndef select_j_rand(i, m):\r\n    \'\'\' \xe5\x9c\xa8m\xe4\xb8\xad\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe6\x8b\xa9\xe9\x99\xa4\xe4\xba\x86i\xe4\xb9\x8b\xe5\xa4\x96\xe5\x89\xa9\xe4\xbd\x99\xe7\x9a\x84\xe6\x95\xb0\r\n    \'\'\'\r\n    l = list(range(m))\r\n    seq = l[: i] + l[i + 1:]\r\n    return np.random.choice(seq)\r\n\r\n#  \xe5\x90\xaf\xe5\x8f\x91\xe5\xbc\x8f\xe9\x80\x89\xe6\x8b\xa9\xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe5\x9b\xa0\xe5\xad\x90\r\ndef select_j(i, svm):\r\n    errors = svm.errors\r\n    valid_indices = [i for i, a in enumerate(svm.alphas) if 0 < a < svm.C]\r\n    if len(valid_indices) > 1:\r\n        j = -1\r\n        max_delta = 0\r\n        for k in valid_indices:\r\n            if k == i:\r\n                continue\r\n            delta = abs(errors[i] - errors[j])\r\n            if delta > max_delta:\r\n                j = k\r\n                max_delta = delta\r\n    else:\r\n        j = select_j_rand(i, len(svm.feature))\r\n    return j\r\n\r\n#  \xe4\xbc\x98\xe5\x8c\x96\xe5\xb7\xb2\xe7\xbb\x8f\xe9\x80\x89\xe6\x8b\xa9\xe7\x9a\x84\xe4\xb8\x80\xe5\xaf\xb9\xe5\x9b\xa0\xe5\xad\x90\r\ndef take_step(i, j, svm):\r\n    #  \xe9\xa6\x96\xe5\x85\x88\xe8\x8e\xb7\xe5\xbe\x97\xe6\x9c\x80\xe6\x96\xb0\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\xe5\x88\x97\xe8\xa1\xa8\r\n    svm.update_errors()\r\n\r\n    #  \xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\xe5\x8f\x8a\xe5\x85\xb6\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe8\xaf\xaf\xe5\xb7\xae\r\n    a_i, x_i, y_i, e_i = svm.alphas[i], svm.feature[i], svm.labels[i], svm.errors[i]\r\n    a_j, x_j, y_j, e_j = svm.alphas[j], svm.feature[j], svm.labels[j], svm.errors[j]\r\n\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe5\x8d\x95\xe6\xa0\xb7\xe6\x9c\xac\xe4\xb9\x8b\xe9\x97\xb4\xe7\x9a\x84\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n    k_ii, k_jj, k_ij = svm.kernel(x_i, x_i), svm.kernel(x_j, x_j), svm.kernel(x_i, x_j)\r\n\r\n    eta = k_ii + k_jj - 2 * k_ij\r\n\r\n    if eta <= 0:\r\n        return 0\r\n\r\n    a_i_old, a_j_old = a_i, a_j\r\n    a_j_new = a_j_old + y_j * (e_i - e_j) / eta\r\n\r\n    # \xe5\xaf\xb9alpha\xe8\xbf\x9b\xe8\xa1\x8c\xe4\xbf\xae\xe5\x89\xaa\r\n    if y_i != y_j:\r\n        Lmax = max(0, a_j_old - a_i_old)\r\n        Hmin = min(svm.C, svm.C + a_j_old - a_i_old)\r\n    else:\r\n        Lmax = max(0, a_i_old + a_j_old - svm.C)\r\n        Hmin = min(svm.C, a_j_old + a_i_old)\r\n\r\n    a_j_new = clip(a_j_new, Lmax, Hmin)\r\n    a_i_new = a_i_old + y_i * y_j * (a_j_old - a_j_new)\r\n\r\n    if abs(a_j_new - a_j_old) < svm.eps:\r\n        return 0\r\n\r\n    #  \xe6\x9b\xb4\xe6\x96\xb0\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\r\n    svm.alphas[i], svm.alphas[j] = a_i_new, a_j_new\r\n    #  \xe6\x9b\xb4\xe6\x96\xb0\xe8\xaf\xaf\xe5\xb7\xae\r\n    svm.update_errors()\r\n\r\n    # \xe6\x9b\xb4\xe6\x96\xb0\xe9\x98\x88\xe5\x80\xbcb\r\n    b_i = -e_i - y_i * k_ii * (a_i_new - a_i_old) - y_j * k_ij * (a_j_new - a_j_old) + svm.b\r\n    b_j = -e_j - y_i * k_ij * (a_i_new - a_i_old) - y_j * k_jj * (a_j_new - a_j_old) + svm.b\r\n\r\n    if 0 < a_i_new < svm.C:\r\n        bnum = b_i\r\n    elif 0 < a_j_new < svm.C:\r\n        bnum = b_j\r\n    else:\r\n        bnum = (b_i + b_j) / 2\r\n\r\n    # \xe6\x9b\xb4\xe6\x96\xb0b\xe5\x80\xbc\r\n    svm.b = bnum\r\n\r\n    return 1\r\n\r\n\r\n# \xe7\xbb\x99\xe5\xae\x9a\xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaaalpha\xe5\x9b\xa0\xe5\xad\x90\xef\xbc\x8c \xe6\xa3\x80\xe6\xb5\x8b\xe5\xaf\xb9\xe5\xba\x94alpha\xe6\x98\xaf\xe5\x90\xa6\xe7\xac\xa6\xe5\x90\x88KKT\xe6\x9d\xa1\xe4\xbb\xb6\xe5\xb9\xb6\xe9\x80\x89\xe5\x8f\x96\xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaaalpha\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xbf\xad\xe4\xbb\xa3.\r\ndef examine_example(i, svm):\r\n\r\n    e_i, y_i, alpha = svm.errors[i], svm.labels[i], svm.alphas[i]\r\n    r = e_i * y_i\r\n\r\n    # \xe6\x98\xaf\xe5\x90\xa6\xe8\xbf\x9d\xe5\x8f\x8dKKT\xe6\x9d\xa1\xe4\xbb\xb6\r\n    if (r < -svm.toler and alpha < svm.C) or (r > svm.toler and alpha > 0):\r\n        #  \xe5\x90\xaf\xe5\x8f\x91\xe5\xbc\x8f\xe9\x80\x89\xe6\x8b\xa9\r\n        j = select_j(i, svm)\r\n        return take_step(i, j, svm)\r\n    else:\r\n        return 0\r\n\r\n\r\n# Platt SMO\xe7\xae\x97\xe6\xb3\x95\xe5\xae\x9e\xe7\x8e\xb0\r\ndef platt_smo(svm):\r\n    # \xe5\xbe\xaa\xe7\x8e\xaf\xe6\xac\xa1\xe6\x95\xb0\r\n    it = 0\r\n    # \xe9\x81\x8d\xe5\x8e\x86\xe6\x89\x80\xe6\x9c\x89alpha\xe7\x9a\x84\xe6\xa0\x87\xe8\xae\xb0\r\n    entire = True\r\n    pair_changed = 0\r\n    while it < svm.times and (pair_changed > 0 or entire):\r\n        pair_changed = 0\r\n        if entire:\r\n            for i in range(len(svm.feature)):\r\n                pair_changed += examine_example(i, svm)\r\n                print(\'\xe5\x85\xa8\xe9\x83\xa8\xe6\xa0\xb7\xe6\x9c\xac \xe6\x94\xb9\xe5\x8f\x98\xe7\x9a\x84\xe5\x9b\xa0\xe5\xad\x90\xe5\xaf\xb9\xe6\x95\xb0: %s\' % pair_changed)\r\n        else:\r\n            alphas = svm.alphas\r\n            non_bound_indices = [i for i in range(len(svm.feature)) if alphas[i] > 0 and alphas[i] < svm.C]\r\n            for i in non_bound_indices:\r\n                pair_changed += examine_example(i, svm)\r\n                print(\'\xe9\x9d\x9e\xe8\xbe\xb9\xe7\x95\x8c \xe6\x94\xb9\xe5\x8f\x98\xe7\x9a\x84\xe5\x9b\xa0\xe5\xad\x90\xe6\x95\xb0\xef\xbc\x9a%s\' %pair_changed)\r\n        #  \xe5\xbe\xaa\xe7\x8e\xaf\xe6\xac\xa1\xe6\x95\xb0\r\n        it += 1\r\n\r\n        #  \xe6\x9b\xb4\xe6\x94\xb9\xe8\xbe\xb9\xe7\x95\x8c\r\n        if entire:\r\n            entire = False\r\n        elif pair_changed == 0:\r\n            entire = True\r\n        print(\'\xe5\xa4\x96\xe5\xb1\x82\xe5\xbe\xaa\xe7\x8e\xaf\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0: %s\' % it)\r\n    return svm.alphas, svm.b\r\n\r\n\r\n#  \xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0\r\ndef predict(svm, prefeature):\r\n    prlt = np.array((np.array([svm.alphas]).reshape(-1, 1) * svm.kernel(prefeature, svm.feature) * np.array([svm.labels]).reshape(-1, 1)).sum(axis=0) + svm.b)\r\n    signre = np.sign(prlt[0])\r\n    return signre\r\n\r\n#  \xe8\x8e\xb7\xe5\xbe\x97\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe5\x87\xbd\xe6\x95\xb0\r\ndef getacc(svm, prefeature, prelabel):\r\n    predu = predict(svm, prefeature)\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n    sub = np.array(predu - prelabel)\r\n    print(sub)\r\n    acc = len(sub[sub == 0]) / len(prelabel)\r\n    print(acc)\r\n    return acc\r\n\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe5\xbf\x83\xe8\x84\x8f\xe7\x97\x85\xe6\x95\xb0\xe6\x8d\xae\r\nimport SVM_Classify_Data as sdata\r\n\r\n\r\n#  K\xe6\x8a\x98\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\xad\x97\xe5\x85\xb8\r\ndef result(datadict, he):\r\n    sign = []\r\n    trainacc, testacc, vec = [], [], []\r\n    resu = []\r\n    for jj in datadict:\r\n        #  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n        xd = datadict[jj][0][:, :-1]\r\n        yd = datadict[jj][0][:, -1]\r\n        #  \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\n        texd = datadict[jj][1][:, :-1]\r\n        teyd = datadict[jj][1][:, -1]\r\n\r\n        # \xe5\xbb\xba\xe7\xab\x8b\xe6\xa8\xa1\xe5\x9e\x8b\r\n        resu = SVM(feature=xd, labels=yd, kernel=he)\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n        platt_smo(resu)\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe5\xae\x8c\xef\xbc\x8c\xe5\x82\xa8\xe5\xad\x98\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\xe7\xbb\x93\xe6\x9e\x9c\r\n        traaa = getacc(resu, xd, yd)\r\n        teaaa = getacc(resu, texd, teyd)\r\n        trainacc.append(traaa)\r\n        testacc.append(teaaa)\r\n        # \xe4\xbf\x9d\xe5\xad\x98\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\n        count = len(resu.alphas > 0)\r\n        vec.append(count)\r\n        sign.append(jj)\r\n\r\n        print(traaa, teaaa, count)\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\xa4\x9ay\xe8\xbd\xb4\xe5\x9b\xbe\r\n    fig, host = plt.subplots()\r\n    # \xe7\x94\xa8\xe6\x9d\xa5\xe6\x8e\xa7\xe5\x88\xb6\xe5\xa4\x9ay\xe8\xbd\xb4\r\n    par1 = host.twinx()\r\n    #  \xe5\xa4\x9a\xe6\x9d\xa1\xe6\x9b\xb2\xe7\xba\xbf\r\n    p1, = host.plot(sign, trainacc, ""b-"", marker=\'8\', label=\'\xe8\xae\xad\xe7\xbb\x83\', linewidth=2)\r\n    pp, = host.plot(sign, testacc, ""b--"", marker=\'*\', label=\'\xe6\xb5\x8b\xe8\xaf\x95\', linewidth=2)\r\n    p2, = par1.plot(sign, vec, ""r-"", marker=\'8\', label=\'\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe4\xb8\xaa\xe6\x95\xb0\', linewidth=2)\r\n    #  \xe6\xaf\x8f\xe4\xb8\xaa\xe8\xbd\xb4\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\r\n    host.set_xlabel(""K\xe6\x8a\x98\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86"")\r\n    host.set_ylabel(""\xe5\x88\x86\xe7\xb1\xbb\xe5\x87\x86\xe7\xa1\xae\xe7\x8e\x87"")\r\n    par1.set_ylabel(""\xe4\xb8\xaa\xe6\x95\xb0"")\r\n    #  \xe6\x8e\xa7\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaay\xe8\xbd\xb4\xe5\x86\x85\xe5\xae\xb9\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\r\n    host.yaxis.label.set_color(p1.get_color())\r\n    par1.yaxis.label.set_color(p2.get_color())\r\n\r\n    #  \xe6\x8e\xa7\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaaY\xe8\xbd\xb4\xe5\x88\xbb\xe5\xba\xa6\xe6\x95\xb0\xe5\xad\x97\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\xe4\xbb\xa5\xe5\x8f\x8a\xe7\xba\xbf\xe7\xb2\x97\xe7\xbb\x86\r\n    tkw = dict(size=6, width=3)\r\n    host.tick_params(axis=\'y\', colors=p1.get_color(), **tkw)\r\n    par1.tick_params(axis=\'y\', colors=p2.get_color(), **tkw)\r\n\r\n    #  \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x9b\xbe\xe4\xbe\x8b\r\n    lines = [p1, pp, p2]\r\n    host.legend(lines, [l.get_label() for l in lines], loc=\'lower center\')\r\n\r\n    #  \xe6\xb7\xbb\xe5\x8a\xa0\xe6\xa0\x87\xe9\xa2\x98\r\n    plt.title(\'K\xe6\x8a\x98\xe5\xbf\x83\xe8\x84\x8f\xe7\x97\x85\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86SVM\xe5\x88\x86\xe7\xb1\xbb\xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94 \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x9a%s\' % he)\r\n\r\n    #  \xe6\x8e\xa7\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaaY\xe8\xbd\xb4\xe5\x88\xbb\xe5\xba\xa6\xe7\xba\xbf\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\r\n    ax = plt.gca()\r\n    ax.spines[\'left\'].set_color(\'blue\')\r\n    ax.spines[\'right\'].set_color(\'red\')\r\n\r\n    # \xe6\x98\xbe\xe7\xa4\xba\xe5\x9b\xbe\xe7\x89\x87\r\n    plt.show()\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe8\xbf\x90\xe8\xa1\x8c\xe7\xa8\x8b\xe5\xba\x8f\'\'\'\r\nif __name__ == ""__main__"":\r\n    # \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x8f\x82\xe6\x95\xb0\xe7\x9a\x84\xe9\x80\x89\xe6\x8b\xa9\xe5\xbe\x88\xe9\x87\x8d\xe8\xa6\x81\r\n    result(sdata.kfold_train_datadict, \'rbf\')\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n'"
SVM/SVM_Classify/SVM_Classify_Compare.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author AnFany\r\n\r\n#  AnFany\xe3\x80\x81Sklearn\xe3\x80\x81TensorFlow\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe7\x94\x9f\xe6\x88\x90\xe6\x95\xb0\xe6\x8d\xae\r\n""""""\r\nimport numpy as np\r\n\r\n#  \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe7\xb1\xbb, \xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xe5\xae\x9a\xe4\xb8\xba200\r\ndef fenlei(samples=200):\r\n    exdata = np.random.rand(900, 2)\r\n    feadata, ladata = [], []\r\n    for jj in exdata:\r\n        if jj[1] - jj[0] - 0.55 > 0:\r\n            feadata.append(jj)\r\n            ladata.append(1)\r\n        elif jj[1] - jj[0] - 0.45 < 0 and jj[1] - jj[0] - 0.05 > 0:\r\n            feadata.append(jj)\r\n            ladata.append(-1)\r\n        elif jj[1] - jj[0] + 0.05 < 0 and jj[1] - jj[0] + 0.45 > 0:\r\n            feadata.append(jj)\r\n            ladata.append(1)\r\n        elif jj[1] - jj[0] + 0.55 < 0:\r\n            feadata.append(jj)\r\n            ladata.append(-1)\r\n        else:\r\n            pass\r\n        if len(feadata) >= samples:\r\n            break\r\n    return np.array(feadata), np.array(ladata)\r\n\r\n\r\ntraindata = fenlei()\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9aSVM\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b\r\n""""""\r\n#  AnFany\r\nimport AnFany_SVM_Classify as An_svm\r\n#  Sklearn\r\nfrom sklearn import svm\r\n# TensorFlow\r\nimport Tensorflow_SVM_Classify as ten_svm\r\n\r\n\r\n# \xe5\xbe\x97\xe5\x88\xb0\xe7\xbb\x98\xe5\x88\xb6\xe5\x86\xb3\xe7\xad\x96\xe8\xbe\xb9\xe7\x95\x8c\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\ndef bound(featuredata, labeldata, mol, ke=\'rbf\'):\r\n    # \xe8\x8e\xb7\xe5\xbe\x97\xe5\xb1\x9e\xe6\x80\xa7\xe6\x95\xb0\xe6\x8d\xae2\xe4\xb8\xaa\xe7\xbb\xb4\xe5\xba\xa6\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe3\x80\x81\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\r\n    xmin, xmax = min(featuredata[:, :-1]) - 0.1, max(featuredata[:, :-1]) + 0.1\r\n    ymin, ymax = min(featuredata[:, :-1]) - 0.1, max(featuredata[:, :-1]) + 0.1\r\n\r\n    # \xe7\x94\x9f\xe6\x88\x90\xe7\xbd\x91\xe6\xa0\xbc\r\n    xx, yy = np.meshgrid(np.arange(xmin, xmax, 0.02),\r\n                         np.arange(ymin, ymax, 0.02))\r\n    grid_points = np.c_[xx.ravel(), yy.ravel()]\r\n\r\n    if mol == \'AnFany\':\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b rbfsigma=0.2\r\n        model = An_svm.SVM(feature=featuredata, labels=labeldata, kernel=ke, times=900)\r\n        #  \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n        An_svm.platt_smo(model)\r\n        # \xe8\xbf\x94\xe5\x9b\x9e\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\r\n        support = model.feature[model.alphas > 0]\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe9\xa2\x84\xe6\xb5\x8b\r\n        prepre = An_svm.predict(model, grid_points)\r\n    elif mol == \'Sklearn\':\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b\r\n        clf = svm.SVC(kernel=ke, max_iter=900, gamma=8)\r\n        #  \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n        clf.fit(featuredata, labeldata)\r\n        # \xe8\xbf\x94\xe5\x9b\x9e\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\r\n        support = clf.support_vectors_\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe9\xa2\x84\xe6\xb5\x8b\r\n        prepre = clf.predict(grid_points)\r\n    elif mol == \'TensorFlow\':\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe5\xbc\x95\xe5\x85\xa5\xe6\xa8\xa1\xe5\x9e\x8b\r\n        clf = ten_svm.SVM(maxtimes=300, kernel=ke, rbf_sigma=0.18)\r\n        #  \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n        rgg = clf.train_svm(featuredata, labeldata, grid_points)\r\n        prepre = rgg[2]\r\n        # \xe8\xbf\x94\xe5\x9b\x9e\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\r\n        support = featuredata[rgg[3] > 0]\r\n    else:\r\n        print(\'\xe6\x96\xb9\xe6\xb3\x95\xe9\x94\x99\xe8\xaf\xaf\')\r\n        prepre = 0\r\n        support = 0\r\n    return xx, yy, prepre, support\r\n\r\n\r\n# \xe7\xbb\x98\xe5\x9b\xbe\xe5\xba\x93\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl\r\nfrom matplotlib import cm\r\n\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n\r\n\r\n#  \xe7\xbb\x98\xe5\x88\xb6\xe5\x9b\xbe\r\ndef figdata(featuredata, labeldata, osel=\'Sklearn\'):\r\n    #  \xe9\xa6\x96\xe5\x85\x88\xe6\x98\xaf\xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe4\xb8\xba2\xe7\xb1\xbb\r\n    neg = featuredata[labeldata == 1]\r\n    pos = featuredata[labeldata == -1]\r\n\r\n    # \xe7\xbb\x98\xe5\x9b\xbe\r\n    fig, ax = plt.subplots()\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x86\xb3\xe7\xad\x96\xe8\xbe\xb9\xe7\x95\x8c\r\n    xx, yy, opre, suo = bound(featuredata, labeldata, mol=osel)\r\n\r\n    opr = opre.reshape(xx.shape)\r\n\r\n    ax.contourf(xx, yy, opr, alpha=0.8, cmap=cm.PuBu_r)\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe5\x9b\xbe\r\n    # \xe4\xb8\x80\xe7\xb1\xbb\r\n    ax.scatter(neg[:, :-1], neg[:, -1], c=\'r\', alpha=0.9, marker=\'8\', s=50)\r\n    # \xe8\xb4\x9f\xe4\xb8\x80\xe7\xb1\xbb\r\n    ax.scatter(pos[:, :-1], pos[:, -1], c=\'b\', alpha=0.9, marker=\'8\', s=50)\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\r\n    ax.scatter(suo[:, :-1], suo[:, -1], s=130, c=\'\', edgecolors=\'k\', alpha=0.9, label=\'\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f(%s\xe4\xb8\xaa)\' % len(suo), marker=\'s\')\r\n\r\n    # \xe5\x9b\xbe\xe4\xbe\x8b\r\n    plt.legend()\r\n\r\n    # \xe5\x9b\xbe\xe7\x9a\x84\xe8\xae\xbe\xe7\xbd\xae\r\n    plt.title(\'\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe5\x88\x86\xe7\xb1\xbb\xe7\xbb\x93\xe6\x9e\x9c\xe5\xb1\x95\xe7\xa4\xba\xef\xbc\x9a\xe6\x96\xb9\xe6\xb3\x95%s\' % osel)\r\n    plt.xlabel(\'\xe7\xac\xac\xe4\xb8\x80\xe7\xbb\xb4\')\r\n    plt.ylabel(\'\xe7\xac\xac\xe4\xba\x8c\xe7\xbb\xb4\')\r\n\r\n    # \xe6\x98\xbe\xe7\xa4\xba\xe5\x9b\xbe\r\n    plt.show()\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe8\xbf\x90\xe8\xa1\x8c\xe7\xa8\x8b\xe5\xba\x8f\'\'\'\r\nif __name__ == ""__main__"":\r\n    figdata(traindata[0], traindata[1], osel=\'TensorFlow\')\r\n    figdata(traindata[0], traindata[1], osel=\'Sklearn\')\r\n    figdata(traindata[0], traindata[1], osel=\'AnFany\')\r\n'"
SVM/SVM_Classify/SVM_Classify_Data.py,0,"b""#-*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\nimport pandas as pd\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\Heart.csv')\r\nimport numpy as np\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe8\xaf\xb4\xe6\x98\x8e\r\n# Attributes types\r\n# -----------------\r\n#\r\n# Real: 1,4,5,8,10,12\r\n# Ordered:11,\r\n# Binary: 2,6,9\r\n# Nominal:7,3,13\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe8\xaf\xb4\xe6\x98\x8e\r\n# Real, Ordered \xef\xbc\x9a \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\n# Nominal  \xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\r\n# Binary \xe4\xb8\x8d\xe5\x81\x9a\xe5\xa4\x84\xe7\x90\x86\r\n\r\n# Variable to be predicted\r\n# ------------------------\r\n# Absence (1) or presence (2) of heart disease\r\n# 0,1\xe7\xbc\x96\xe7\xa0\x81\r\n\r\n# \xe5\xbc\x80\xe5\xa7\x8b\xe8\xbf\x9b\xe8\xa1\x8c\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\xe3\x80\x90\xe6\xb2\xa1\xe6\x9c\x89\xe7\xbc\xba\xe5\xa4\xb1\xe5\x80\xbc\xe3\x80\x91\r\nnormal = [1, 4, 5, 8, 10, 12, 11]  # \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\r\none_hot = [3, 7, 13] # one_hot\xe7\xbc\x96\xe7\xa0\x81\r\nbinary = [14]  # \xe5\x8e\x9f\xe5\xa7\x8b\xe7\xb1\xbb\xe5\x88\xab\xe4\xb8\xba1\xe7\x9a\x84\xe4\xbe\x9d\xe7\x84\xb6\xe4\xb8\xba1\xe7\xb1\xbb\xef\xbc\x8c\xe5\x8e\x9f\xe5\xa7\x8b\xe4\xb8\xba2\xe7\x9a\x84\xe5\x8f\x98\xe4\xb8\xba0\xe7\xb1\xbb\r\n\r\n#\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\r\ndef trans(exdata, nor=normal, oh=one_hot, bin=binary):\r\n    keylist = exdata.keys()\r\n    newexdata = pd.DataFrame()\r\n    for ikey in range(len(keylist)):\r\n        if ikey + 1 in nor:\r\n            newexdata[keylist[ikey]] = (exdata[keylist[ikey]] - exdata[keylist[ikey]].mean()) / exdata[keylist[ikey]].std()\r\n        elif ikey + 1 in bin:\r\n            newexdata[keylist[ikey]] = [1 if inum == 1 else -1 for inum in exdata[keylist[ikey]]]\r\n        elif ikey + 1 in oh:\r\n            newdata = pd.get_dummies(exdata[keylist[ikey]], prefix=keylist[ikey])\r\n            newexdata = pd.concat([newexdata,newdata], axis=1)\r\n    return newexdata\r\n\r\n\r\n# \xe7\xb1\xbb\xe5\x88\xab\xe8\xaf\xb4\xe6\x98\x8e\r\n# Absence (1) 1\xe7\xb1\xbb\r\n# presence (2) -1\xe7\xb1\xbb\r\n\r\n#  \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xb9\xb3\xe5\x9d\x87\xe5\x88\x86\xe4\xb8\xban\xe4\xbb\xbd\xef\xbc\x8c\xe5\x88\xa9\xe7\x94\xa8K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe8\xae\xa1\xe7\xae\x97\xe6\xa8\xa1\xe5\x9e\x8b\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\r\n#  \xe5\xb0\x86\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe4\xb8\xba\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe6\x95\xb0\xe6\x8d\xae\r\n\r\ndef kfold(trdata, k=10):\r\n    vadata = trdata.values\r\n    legth = len(vadata)\r\n    datadict = {}\r\n    signnuber = np.arange(legth)\r\n    for hh in range(k):\r\n        np.random.shuffle(vadata)\r\n        yanzhneg = np.random.choice(signnuber, int(legth / k), replace=False)\r\n        oneflod_yan = vadata[yanzhneg]\r\n        oneflod_xun = vadata[[hdd for hdd in signnuber if hdd not in yanzhneg]]\r\n        datadict[hh] = [oneflod_xun, oneflod_yan]\r\n    return datadict\r\n\r\n#  \xe5\xad\x98\xe5\x82\xa8K\xe6\x8a\x98\xe4\xba\xa4\xe5\x8f\x89\xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x97\xe5\x85\xb8\r\nkfold_train_datadict = kfold(trans(data))\r\n\r\n\r\n\r\n"""
SVM/SVM_Classify/Sklearn_Classify_SVM.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author AnFany\r\n\r\n# \xe5\x88\xa9\xe7\x94\xa8Sklearn\xe5\x8c\x85\xe5\xae\x9e\xe7\x8e\xb0\xe6\x94\xaf\xe6\x8c\x81\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe4\xba\x8c\xe5\x88\x86\xe7\xb1\xbb\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xbc\x95\xe5\x85\xa5\xe5\xba\x93\r\n""""""\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe5\xbf\x83\xe8\x84\x8f\xe7\x97\x85\xe6\x95\xb0\xe6\x8d\xae\r\nimport SVM_Classify_Data as sdata\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe5\xba\x93\xe5\x8c\x85\r\nfrom sklearn import svm\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl\r\n\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9e\x84\xe5\xbb\xba\xe5\x87\xbd\xe6\x95\xb0\r\n""""""\r\n\r\n\r\n# \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\ndef sk_svm_train(intr, labeltr, inte, labelte, kener):\r\n    clf = svm.SVC(kernel=kener)\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n    clf.fit(intr, labeltr)\r\n    #  \xe7\xbb\x98\xe5\x9b\xbe\xe7\x9a\x84\xe6\xa0\x87\xe8\xaf\x86\r\n    figsign = kener\r\n    #  \xe8\xae\xad\xe7\xbb\x83\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\r\n    acc_train = clf.score(intr, labeltr)\r\n    #  \xe6\xb5\x8b\xe8\xaf\x95\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\r\n    acc_test = clf.score(inte, labelte)\r\n    #  \xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\r\n    vec_count = sum(clf.n_support_)\r\n    #  \xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\r\n    vectors = clf.support_vectors_\r\n\r\n    return acc_train, acc_test, vec_count, vectors, figsign\r\n\r\n\r\n# \xe7\xbb\x93\xe6\x9e\x9c\xe8\xbe\x93\xe5\x87\xba\xe5\x87\xbd\xe6\x95\xb0\r\n\'\'\'\r\n\xe2\x80\x98linear\xe2\x80\x99, \xe2\x80\x98poly\xe2\x80\x99, \xe2\x80\x98rbf\xe2\x80\x99, \xe2\x80\x98sigmoid\xe2\x80\x99\r\n\'\'\'\r\n#  K\xe6\x8a\x98\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\xad\x97\xe5\x85\xb8\r\ndef result(datadict, he=\'rbf\'):\r\n    sign = []\r\n    trainacc, testacc, vec = [], [], []\r\n    resu = []\r\n    for jj in datadict:\r\n        #  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n        xd = datadict[jj][0][:, :-1]\r\n        yd = datadict[jj][0][:, -1]\r\n        #  \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\n        texd = datadict[jj][1][:, :-1]\r\n        teyd = datadict[jj][1][:, -1]\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n        resu = sk_svm_train(xd, yd, texd, teyd, he)\r\n\r\n        # \xe5\x82\xa8\xe5\xad\x98\xe7\xbb\x93\xe6\x9e\x9c\r\n        trainacc.append(resu[0])\r\n        testacc.append(resu[1])\r\n        vec.append(resu[2])\r\n        sign.append(jj)\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\xa4\x9ay\xe8\xbd\xb4\xe5\x9b\xbe\r\n    fig, host = plt.subplots()\r\n    # \xe7\x94\xa8\xe6\x9d\xa5\xe6\x8e\xa7\xe5\x88\xb6\xe5\xa4\x9ay\xe8\xbd\xb4\r\n    par1 = host.twinx()\r\n    #  \xe5\xa4\x9a\xe6\x9d\xa1\xe6\x9b\xb2\xe7\xba\xbf\r\n    p1, = host.plot(sign, trainacc, ""b-"", marker=\'8\', label=\'\xe8\xae\xad\xe7\xbb\x83\', linewidth=2)\r\n    pp, = host.plot(sign, testacc, ""b--"", marker=\'*\', label=\'\xe6\xb5\x8b\xe8\xaf\x95\', linewidth=2)\r\n    p2, = par1.plot(sign, vec, ""r-"", marker=\'8\', label=\'\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe4\xb8\xaa\xe6\x95\xb0\', linewidth=2)\r\n    #  \xe6\xaf\x8f\xe4\xb8\xaa\xe8\xbd\xb4\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\r\n    host.set_xlabel(""K\xe6\x8a\x98\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86"")\r\n    host.set_ylabel(""\xe5\x88\x86\xe7\xb1\xbb\xe5\x87\x86\xe7\xa1\xae\xe7\x8e\x87"")\r\n    par1.set_ylabel(""\xe4\xb8\xaa\xe6\x95\xb0"")\r\n    #  \xe6\x8e\xa7\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaay\xe8\xbd\xb4\xe5\x86\x85\xe5\xae\xb9\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\r\n    host.yaxis.label.set_color(p1.get_color())\r\n    par1.yaxis.label.set_color(p2.get_color())\r\n\r\n    #  \xe6\x8e\xa7\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaaY\xe8\xbd\xb4\xe5\x88\xbb\xe5\xba\xa6\xe6\x95\xb0\xe5\xad\x97\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\xe4\xbb\xa5\xe5\x8f\x8a\xe7\xba\xbf\xe7\xb2\x97\xe7\xbb\x86\r\n    tkw = dict(size=6, width=3)\r\n    host.tick_params(axis=\'y\', colors=p1.get_color(), **tkw)\r\n    par1.tick_params(axis=\'y\', colors=p2.get_color(), **tkw)\r\n\r\n    #  \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x9b\xbe\xe4\xbe\x8b\r\n    lines = [p1, pp, p2]\r\n    host.legend(lines, [l.get_label() for l in lines], loc=\'lower center\')\r\n\r\n    #  \xe6\xb7\xbb\xe5\x8a\xa0\xe6\xa0\x87\xe9\xa2\x98\r\n    plt.title(\'K\xe6\x8a\x98\xe5\xbf\x83\xe8\x84\x8f\xe7\x97\x85\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86SVM\xe5\x88\x86\xe7\xb1\xbb\xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94 \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x9a%s\' % resu[-1])\r\n\r\n    #  \xe6\x8e\xa7\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaaY\xe8\xbd\xb4\xe5\x88\xbb\xe5\xba\xa6\xe7\xba\xbf\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\r\n    ax = plt.gca()\r\n    ax.spines[\'left\'].set_color(\'blue\')\r\n    ax.spines[\'right\'].set_color(\'red\')\r\n\r\n    # \xe6\x98\xbe\xe7\xa4\xba\xe5\x9b\xbe\xe7\x89\x87\r\n    plt.show()\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe8\xbf\x90\xe8\xa1\x8c\xe7\xa8\x8b\xe5\xba\x8f\'\'\'\r\nif __name__ == ""__main__"":\r\n    result(sdata.kfold_train_datadict, he=\'rbf\')\r\n'"
SVM/SVM_Classify/TensorFlow_SVM_Classify.py,36,"b'# -*- coding\xef\xbc\x9autf-8 -*-\n# &Author AnFany\n\n# \xe5\x9f\xba\xe4\xba\x8eTensorFlow\xe5\xae\x9e\xe7\x8e\xb0\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe4\xba\x8c\xe5\x88\x86\xe7\xb1\xbb\n# \xe9\x98\xb2\xe6\xad\xa2\xe7\xb2\xbe\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe4\xb8\x8d\xe7\xa8\xb3\xe5\xae\x9a\xe6\x80\xa7\xef\xbc\x8c\xe4\xb8\x8d\xe9\x87\x87\xe7\x94\xa8batchsize\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe8\xae\xad\xe7\xbb\x83\xe9\x83\xbd\xe6\x98\xaf\xe5\x85\xa8\xe9\x83\xa8\xe6\xa0\xb7\xe6\x9c\xac\n# \xe5\x9b\xa0\xe6\xad\xa4\xe4\xb8\x8d\xe9\x80\x82\xe7\x94\xa8\xe4\xba\x8e\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x8f\xe8\xbe\x83\xe5\xa4\xa7\xe7\x9a\x84\xe6\x83\x85\xe5\x86\xb5\n\n""""""\n\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xbc\x95\xe5\x85\xa5\xe5\xba\x93\n""""""\n\n# \xe5\xbc\x95\xe5\x85\xa5\xe5\xba\x93\xe5\x8c\x85\nimport numpy as np\n\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\nimport SVM_Classify_Data as sdata\n\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nops.reset_default_graph()\n\n# \xe7\xbb\x98\xe5\x9b\xbe\nimport matplotlib.pyplot as plt\nfrom pylab import mpl\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\n\n""""""\n\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9e\x84\xe9\x80\xa0\xe5\x87\xbd\xe6\x95\xb0\n""""""\n\n\n# keneral\xef\xbc\x9a \xe7\xba\xbf\xe6\x80\xa7\xe5\x8f\xaf\xe5\x88\x86lin1   \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x9a lin\xef\xbc\x9a\xe7\xba\xbf\xe6\x80\xa7\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0   poly\xef\xbc\x9a\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0   rbf\xef\xbc\x9a\xe9\xab\x98\xe6\x96\xaf\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0  sigmoid\xef\xbc\x9aSigmoid\xe5\x9e\x8b\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\n\nclass SVM:\n    def __init__(self, maxtimes=800, lin1_C=0.09, ploy_d=10.3, rbf_sigma=0.15, tanh_beta=0.9, tanh_theta=-0.6,\n                 kernel=\'rbf\'):  # \xe5\x8f\x82\xe6\x95\xb0\xe5\x9d\x87\xe4\xb8\xbafloat\xe5\xbd\xa2\xe5\xbc\x8f\n\n        self.maxtimes = maxtimes  # \xe5\xbe\xaa\xe7\x8e\xaf\xe6\x9c\x80\xe5\xa4\xa7\xe6\xac\xa1\xe6\x95\xb0\n\n        self.lin1_C = lin1_C  # \xe7\xba\xbf\xe6\x80\xa7\xe5\x8f\xaf\xe5\x88\x86\xe9\x97\xae\xe9\xa2\x98\xe8\xbd\xaf\xe9\x97\xb4\xe9\x9a\x94\n        self.ploy_d = ploy_d   # \xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x8f\x82\xe6\x95\xb0\n        self.rbf_sigma = rbf_sigma   # \xe9\xab\x98\xe6\x96\xaf\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x8f\x82\xe6\x95\xb0\n        self.tanh_beta = tanh_beta   # Sigmoid\xe5\x9e\x8b\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x8f\x82\xe6\x95\xb0\n        self.tanh_theta = tanh_theta\n\n        self.kernel = kernel  # \xe7\x94\xa8\xe5\x88\xb0\xe7\x9a\x84\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\n\n    #  \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\n    def train_svm(self, shuxing, biaoqian, ceshisx):\n\n        # \xe5\x88\x9b\xe5\xbb\xba\xe4\xbc\x9a\xe8\xaf\x9d\n        sess = tf.Session()\n\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\n        x_data = tf.placeholder(shape=[None, len(shuxing[0])], dtype=tf.float32)\n        y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\n        prexdata = tf.placeholder(shape=[None, len(shuxing[0])], dtype=tf.float32)\n\n        # \xe7\xba\xbf\xe6\x80\xa7\xe5\x8f\xaf\xe5\x88\x86\xe6\x83\x85\xe5\x86\xb5\n        if self.kernel == \'lin1\':\n            # \xe7\xba\xbf\xe6\x80\xa7\xe5\x8f\xaf\xe5\x88\x86\xef\xbc\x9a\xe5\x8f\x98\xe9\x87\x8f\n            W = tf.Variable(tf.random_normal(shape=[len(shuxing[0]), 1]), dtype=tf.float32)\n            b = tf.Variable(tf.random_normal(shape=[1, 1]), dtype=tf.float32)\n\n            # \xe5\x88\x86\xe5\x89\xb2\xe7\xba\xbf\xe7\x9a\x84\xe5\x80\xbc\n            model_output = tf.subtract(tf.matmul(x_data, W), b)\n\n            # L2\xe8\x8c\x83\xe6\x95\xb0\n            l2_term = tf.reduce_sum(tf.square(W))\n\n            # \xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\n            class_term = tf.reduce_mean(tf.maximum(0., tf.subtract(1., tf.multiply(model_output, y_target))))\n            loss = tf.add(class_term, tf.multiply(self.lin1_C, l2_term))\n\n            # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe5\x80\xbc\n            prediction = tf.squeeze(tf.sign(tf.subtract(tf.matmul(prexdata, W), b)))\n\n        # \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe6\x83\x85\xe5\x86\xb5\n        else:\n            # \xe5\x85\xb6\xe5\xae\x9e\xe5\xb0\xb1\xe6\x98\xaf\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\xe5\x8f\x98\xe9\x87\x8f\n            Lagrange = tf.Variable(tf.random_normal(shape=[1, len(shuxing)]))  # \xe5\x92\x8c\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe6\x98\xaf\xe4\xb8\x80\xe8\x87\xb4\xe7\x9a\x84\n\n            # linear \xe7\xba\xbf\xe6\x80\xa7\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\n            if self.kernel == \'linear\':\n                # \xe8\xae\xa1\xe7\xae\x97\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc\n                kernel_num = tf.matmul(x_data, tf.transpose(x_data))\n                # \xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0\n                pred_num = tf.matmul(x_data, tf.transpose(prexdata))\n\n            elif self.kernel == \'poly\':\n                # \xe8\xae\xa1\xe7\xae\x97\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc\n                kernel_num = tf.pow(tf.matmul(x_data, tf.transpose(x_data)), self.ploy_d)\n                # \xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0\n                pred_num = tf.pow(tf.matmul(x_data, tf.transpose(prexdata)), self.ploy_d)\n\n            elif self.kernel == \'sigmoid\':\n                # \xe8\xae\xa1\xe7\xae\x97\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc\n                kernel_num = tf.tanh(self.tanh_beta * tf.matmul(x_data, tf.transpose(x_data)) + self.tanh_theta)\n                # \xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0\n                pred_num = tf.tanh(self.tanh_beta * tf.matmul(x_data, tf.transpose(prexdata)) + self.tanh_theta)\n\n            elif self.kernel == \'rbf\':\n                # \xe8\xae\xa1\xe7\xae\x97\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe5\xb0\x86\xe6\xa8\xa1\xe7\x9a\x84\xe5\xb9\xb3\xe6\x96\xb9\xe5\xb1\x95\xe5\xbc\x80\xef\xbc\x9aa\xe6\x96\xb9+b\xe6\x96\xb9-2ab\n                xdatafang = tf.reshape(tf.reduce_sum(tf.square(x_data), 1), [-1, 1])\n                momo = tf.add(tf.subtract(xdatafang, tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))),\n                              tf.transpose(xdatafang))\n                kernel_num = tf.exp(tf.multiply((1/(-2 * tf.pow(self.rbf_sigma, 2))), tf.abs(momo)))\n\n                # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe5\xb0\x86\xe6\xa8\xa1\xe7\x9a\x84\xe5\xb9\xb3\xe6\x96\xb9\xe5\xb1\x95\xe5\xbc\x80\xef\xbc\x9aa\xe6\x96\xb9+b\xe6\x96\xb9-2ab\n                xfang = tf.reshape(tf.reduce_sum(tf.square(x_data), 1), [-1, 1])\n                prefang = tf.reshape(tf.reduce_sum(tf.square(prexdata), 1), [-1, 1])\n                mofang = tf.add(tf.subtract(xfang, tf.multiply(2., tf.matmul(x_data, tf.transpose(prexdata)))),\n                                tf.transpose(prefang))\n                pred_num = tf.exp(tf.multiply((1/(-2 * tf.pow(self.rbf_sigma, 2))), tf.abs(mofang)))\n            else:\n                print(\'\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x91\xbd\xe5\x90\x8d\xe9\x94\x99\xe8\xaf\xaf\')\n                kernel_num = 0\n                pred_num = 0\n                import time\n                time.sleep(1000)\n\n            # \xe8\xae\xa1\xe7\xae\x97\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\n            # \xe7\xac\xac\xe4\xb8\x80\xe9\xa1\xb9\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\xe7\x9a\x84\xe5\x92\x8c\n            sum_alpha = tf.reduce_sum(Lagrange)\n            # \xe8\xae\xa1\xe7\xae\x97\xe7\xac\xac\xe4\xba\x8c\xe9\xa1\xb9\n            la_la = tf.matmul(tf.transpose(Lagrange), Lagrange)\n            y_y = tf.matmul(y_target, tf.transpose(y_target))\n            second_term = tf.reduce_sum(tf.multiply(kernel_num, tf.multiply(la_la, y_y)))\n            # \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\n            loss = tf.negative(tf.subtract(sum_alpha, second_term))\n\n            # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xe4\xbb\xa5\xe5\x8f\x8a\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\n            prediction_output = tf.matmul(tf.multiply(tf.transpose(y_target), Lagrange), pred_num)\n            # \xe7\xb1\xbb\xe5\x88\xab\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x8cshape=\xef\xbc\x88\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0,\xef\xbc\x89\n            prediction = tf.squeeze(tf.sign(prediction_output))\n\n\n        # \xe8\xb0\x83\xe7\x94\xa8\xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8\n        my_opt = tf.train.GradientDescentOptimizer(0.004)  # \xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\n        train_step = my_opt.minimize(loss)\n\n        # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe5\x8f\x98\xe9\x87\x8f\n        init = tf.global_variables_initializer()\n        sess.run(init)\n\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\n        loss_vec = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\n\n        #  \xe5\xb1\x9e\xe6\x80\xa7\xe6\x95\xb0\xe6\x8d\xaeshape = (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c\xe5\x8d\x95\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0)\n        #  \xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\xe6\x8d\xaeshape = (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c1)\n        labely = biaoqian.reshape(-1, 1)  # \xe6\x9b\xb4\xe6\x94\xb9\xe7\xbb\xb4\xe5\xba\xa6\n        for i in range(self.maxtimes):\n            # \xe8\xae\xad\xe7\xbb\x83\n            sess.run(train_step, feed_dict={x_data: shuxing, y_target: labely})  # \xe5\x85\xa8\xe9\x83\xa8\xe6\xa0\xb7\xe6\x9c\xac\xe4\xb8\x80\xe9\xbd\x90\xe8\xae\xad\xe7\xbb\x83\n            # \xe8\x8e\xb7\xe5\xbe\x97\xe8\xaf\xaf\xe5\xb7\xae\n            temp_loss = sess.run(loss, feed_dict={x_data: shuxing, y_target: labely})\n            loss_vec.append(temp_loss)\n\n            # \xe8\x8e\xb7\xe5\xbe\x97\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\xe7\x9a\x84\xe5\x80\xbc\n            # \xe5\x9b\xa0\xe4\xb8\xba\xe5\xbd\x93kenerl\xe7\x9a\x84\xe5\x80\xbc\xe4\xb8\xbalin1\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe6\xb2\xa1\xe6\x9c\x89\xe5\xae\x9a\xe4\xb9\x89\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\n            try:\n                lan = Lagrange.eval(session=sess)\n            except UnboundLocalError:\n                pass\n\n        # \xe8\xbe\x93\xe5\x87\xba\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\n        trlas = sess.run(prediction, feed_dict={x_data: shuxing, y_target: labely, prexdata: shuxing})\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\n        prelas = sess.run(prediction, feed_dict={x_data: shuxing, y_target: labely, prexdata: ceshisx})\n\n\n        # \xe8\xbf\x94\xe5\x9b\x9e\xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x8c\xe8\xae\xad\xe7\xbb\x83\xe8\xbe\x93\xe5\x87\xba\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe8\xbe\x93\xe5\x87\xba\n        if self.kernel != \'lin1\':\n            return loss_vec, trlas, prelas, np.array(lan)[0]\n        else:\n            return loss_vec, trlas, prelas\n\n    # \xe8\xae\xa1\xe7\xae\x97\xe6\xad\xa3\xe7\xa1\xae\xe7\x8e\x87\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\n    def acc(self, reallabel, netlabel):  # shape=(\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c)\n        accua = np.array(reallabel)[np.array(reallabel) == np.array(netlabel)]\n        return len(accua) / len(netlabel)\n\n#  K\xe6\x8a\x98\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe5\xad\x97\xe5\x85\xb8\ndef result(datadict, he):\n    sign = []\n    trainacc, testacc, vec = [], [], []\n    resu = []\n    for jj in datadict:\n        #  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\n        xd = datadict[jj][0][:, :-1]\n        yd = datadict[jj][0][:, -1]\n        #  \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\n        texd = datadict[jj][1][:, :-1]\n        teyd = datadict[jj][1][:, -1]\n\n        # \xe5\xbb\xba\xe7\xab\x8b\xe6\xa8\xa1\xe5\x9e\x8b\n        resu = SVM(kernel=he)\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\n        lo, tracu, teacu, *vector = resu.train_svm(xd, yd, texd)\n        # \xe8\xae\xad\xe7\xbb\x83\xe5\xae\x8c\xef\xbc\x8c\xe5\x82\xa8\xe5\xad\x98\xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84\xe7\xb2\xbe\xe7\xa1\xae\xe5\xba\xa6\xe7\xbb\x93\xe6\x9e\x9c\n        trainacc.append(resu.acc(yd, tracu))\n        testacc.append(resu.acc(teyd, teacu))\n        if he != \'lin1\':\n            vec.append(len(np.array(vector)[np.array(vector) < 0]))\n        else:\n            vec.append(0)\n        sign.append(jj)\n\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\xa4\x9ay\xe8\xbd\xb4\xe5\x9b\xbe\n    fig, host = plt.subplots()\n    # \xe7\x94\xa8\xe6\x9d\xa5\xe6\x8e\xa7\xe5\x88\xb6\xe5\xa4\x9ay\xe8\xbd\xb4\n    par1 = host.twinx()\n    #  \xe5\xa4\x9a\xe6\x9d\xa1\xe6\x9b\xb2\xe7\xba\xbf\n    p1, = host.plot(sign, trainacc, ""b-"", marker=\'8\', label=\'\xe8\xae\xad\xe7\xbb\x83\', linewidth=2)\n    pp, = host.plot(sign, testacc, ""b--"", marker=\'*\', label=\'\xe6\xb5\x8b\xe8\xaf\x95\', linewidth=2)\n    if he == \'lin1\':\n        p2, = par1.plot(sign, vec, ""r-"", marker=\'8\', label=\'\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f[\xe6\x9c\xaa\xe5\xae\x9a\xe4\xb9\x89]\', linewidth=2)\n    else:\n        p2, = par1.plot(sign, vec, ""r-"", marker=\'8\', label=\'\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\', linewidth=2)\n    #  \xe6\xaf\x8f\xe4\xb8\xaa\xe8\xbd\xb4\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\n    host.set_xlabel(""K\xe6\x8a\x98\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86"")\n    host.set_ylabel(""\xe5\x88\x86\xe7\xb1\xbb\xe5\x87\x86\xe7\xa1\xae\xe7\x8e\x87"")\n    par1.set_ylabel(""\xe4\xb8\xaa\xe6\x95\xb0"")\n    #  \xe6\x8e\xa7\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaay\xe8\xbd\xb4\xe5\x86\x85\xe5\xae\xb9\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\n    host.yaxis.label.set_color(p1.get_color())\n    par1.yaxis.label.set_color(p2.get_color())\n\n    #  \xe6\x8e\xa7\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaaY\xe8\xbd\xb4\xe5\x88\xbb\xe5\xba\xa6\xe6\x95\xb0\xe5\xad\x97\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\xe4\xbb\xa5\xe5\x8f\x8a\xe7\xba\xbf\xe7\xb2\x97\xe7\xbb\x86\n    tkw = dict(size=6, width=3)\n    host.tick_params(axis=\'y\', colors=p1.get_color(), **tkw)\n    par1.tick_params(axis=\'y\', colors=p2.get_color(), **tkw)\n\n    #  \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x9b\xbe\xe4\xbe\x8b\n    lines = [p1, pp, p2]\n    host.legend(lines, [l.get_label() for l in lines], loc=\'lower center\')\n\n    #  \xe6\xb7\xbb\xe5\x8a\xa0\xe6\xa0\x87\xe9\xa2\x98\n    plt.title(\'K\xe6\x8a\x98\xe5\xbf\x83\xe8\x84\x8f\xe7\x97\x85\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86SVM\xe5\x88\x86\xe7\xb1\xbb\xe7\xbb\x93\xe6\x9e\x9c\xe5\xaf\xb9\xe6\xaf\x94 \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x9a%s\' % he)\n\n    #  \xe6\x8e\xa7\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaaY\xe8\xbd\xb4\xe5\x88\xbb\xe5\xba\xa6\xe7\xba\xbf\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\n    ax = plt.gca()\n    ax.spines[\'left\'].set_color(\'blue\')\n    ax.spines[\'right\'].set_color(\'red\')\n\n    # \xe6\x98\xbe\xe7\xa4\xba\xe5\x9b\xbe\xe7\x89\x87\n    plt.show()\n\n\n\'\'\'\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe8\xbf\x90\xe8\xa1\x8c\xe7\xa8\x8b\xe5\xba\x8f\'\'\'\nif __name__ == ""__main__"":\n    result(sdata.kfold_train_datadict, \'rbf\')\n\n\n\n'"
SVM/SVM_Regression/AnFany_SVM_Regression.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author AnFany\r\n\r\n# SMO\xe7\xae\x97\xe6\xb3\x95\xe5\xae\x9e\xe7\x8e\xb0\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe5\x9b\x9e\xe5\xbd\x92\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xbc\x95\xe5\x85\xa5\xe5\xba\x93\r\n""""""\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl\r\n\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\r\nimport SVM_Regression_Data as rdata\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9e\x84\xe5\xbb\xba\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe4\xbb\xa5\xe5\x8f\x8aSVM\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x84\r\n""""""\r\n\r\n#  \xe6\x9e\x84\xe5\xbb\xba\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\nclass KERNEL:\r\n    """"""\r\n    linear\xef\xbc\x9a\xe7\xba\xbf\xe6\x80\xa7   rbf\xef\xbc\x9a\xe9\xab\x98\xe6\x96\xaf  sigmoid\xef\xbc\x9aSigmoid\xe5\x9e\x8b  poly\xef\xbc\x9a\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\r\n    \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x9a\xe6\xb3\xa8\xe6\x84\x8f\xe8\xbe\x93\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84shape\xe4\xbb\xa5\xe5\x8f\x8a\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84shape\xe3\x80\x82\r\n    xVSy\xe5\x8c\x85\xe6\x8b\xac3\xe7\xa7\x8d\xe6\x83\x85\xe5\x86\xb5\xef\xbc\x9a\xe5\x8d\x95\xe6\xa0\xb7\xe6\x9c\xacVS\xe5\x8d\x95\xe6\xa0\xb7\xe6\x9c\xac  \xe5\x8d\x95\xe6\xa0\xb7\xe6\x9c\xacVS\xe5\xa4\x9a\xe6\xa0\xb7\xe6\x9c\xac  \xe5\xa4\x9a\xe6\xa0\xb7\xe6\x9c\xacVS\xe5\xa4\x9a\xe6\xa0\xb7\xe6\x9c\xac\r\n    """"""\r\n\r\n    def __init__(self, polyd=3, rbfsigma=0.2, tanhbeta=0.6, tanhtheta=-0.6):\r\n        self.polyd = polyd\r\n        self.rbfsigma = rbfsigma\r\n        self.tanhbeta = tanhbeta\r\n        self.tanhtheta = tanhtheta\r\n\r\n    def trans(self, x):\r\n        x = np.array(x)\r\n        if x.ndim == 1:\r\n            x = np.array([x])\r\n        return x\r\n\r\n    # \xe7\xba\xbf\xe6\x80\xa7\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n    def linear(self, x, y):  # \xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9cshape=(len(y), len(x))\r\n        x, y = self.trans(x), self.trans(y)\r\n        if len(x) == 1:\r\n            return (x * y).sum(axis=1, keepdims=True)\r\n        else:\r\n            sx = x.reshape(x.shape[0], -1, x.shape[1])\r\n            return (sx * y).sum(axis=2).T\r\n\r\n    # Singmoid\xe5\x9e\x8b\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n    def sigmoid(self, x, y):  # \xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9cshape=(len(y), len(x))\r\n        x, y = self.trans(x), self.trans(y)\r\n        if len(x) == 1:\r\n            return np.tanh(self.tanhbeta * ((x * y).sum(axis=1, keepdims=True)) + self.tanhtheta)\r\n        else:\r\n            sx = x.reshape(x.shape[0], -1, x.shape[1])\r\n            return np.tanh(self.tanhbeta * (sx * y).sum(axis=2).T + self.tanhtheta)\r\n\r\n    # \xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n    def poly(self, x, y):  # \xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9cshape=(len(y), len(x))\r\n        x, y = self.trans(x), self.trans(y)\r\n        if len(x) == 1:\r\n            return (x * y).sum(axis=1, keepdims=True) ** self.polyd\r\n        else:\r\n            sx = x.reshape(x.shape[0], -1, x.shape[1])\r\n            return (sx * y).sum(axis=2).T ** self.polyd\r\n\r\n    # \xe9\xab\x98\xe6\x96\xaf\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n    def rbf(self, x, y):  # \xe8\xbe\x93\xe5\x87\xba\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9cshape=(len(y), len(x))\r\n        x, y = self.trans(x), self.trans(y)\r\n        if len(x) == 1 and len(y) == 1:\r\n            return np.exp(self.linear((x - y), (x - y)) / (-2 * self.rbfsigma ** 2))\r\n        elif len(x) == 1 and len(y) != 1:\r\n            return np.exp((np.power(x - y, 2)).sum(axis=1, keepdims=True) / (-2 * self.rbfsigma ** 2))\r\n        else:\r\n            sx = x.reshape(x.shape[0], -1, x.shape[1])\r\n            return np.exp((np.power(sx - y, 2)).sum(axis=2).T / (-2 * self.rbfsigma ** 2))\r\n\r\n\r\n# \xe6\x9e\x84\xe5\xbb\xbaSVM\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x84\r\nclass SVR:\r\n    def __init__(self, feature, labels, kernel=\'rbf\', C=0.8, toler=0.001, epsilon=0.001, times=100, eps=0.0001):\r\n        #  \xe8\xae\xad\xe7\xbb\x83\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe5\xb1\x9e\xe6\x80\xa7\xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x81\xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\xe6\x8d\xae\r\n        self.feature = feature\r\n        self.labels = labels\r\n\r\n        # SMO\xe7\xae\x97\xe6\xb3\x95\xe5\x8f\x98\xe9\x87\x8f\r\n        self.C = C\r\n        self.toler = toler\r\n\r\n        self.alphas = np.zeros(len(self.feature))\r\n        self.alphas_star = np.zeros(len(self.feature))\r\n\r\n        self.b = 0\r\n        self.eps = eps  # \xe9\x80\x89\xe6\x8b\xa9\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\r\n        self.epsilon = epsilon\r\n\r\n        # \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n        self.kernel = eval(\'KERNEL().\' + kernel)\r\n\r\n        # \xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe8\xaf\xaf\xe5\xb7\xae\xe5\xba\x8f\xe5\x88\x97\r\n        self.errors = [self.get_error(i) for i in range(len(self.feature))]\r\n\r\n        #  \xe5\xbe\xaa\xe7\x8e\xaf\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe6\xac\xa1\xe6\x95\xb0\r\n        self.times = times\r\n\r\n    # \xe8\xae\xa1\xe7\xae\x97\xe5\x88\x86\xe5\x89\xb2\xe7\xba\xbf\xe7\x9a\x84\xe5\x80\xbc,x\xe4\xb8\xba\xe5\x8d\x95\xe6\xa0\xb7\xe6\x9c\xac\r\n    def line_num(self, x):\r\n        ks = self.kernel(x, self.feature)\r\n        wx = np.matrix(self.alphas - self.alphas_star) * ks\r\n        num = np.array(wx + self.b)\r\n        return num[0][0]\r\n\r\n    #  \xe8\x8e\xb7\xe5\xbe\x97\xe7\xbc\x96\xe5\x8f\xb7\xe4\xb8\xbai\xe7\x9a\x84\xe6\xa0\xb7\xe6\x9c\xac\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n    def get_error(self, i):\r\n        x, y = self.feature[i], self.labels[i]\r\n        error = self.line_num(x) - y\r\n        return error\r\n\r\n    #  \xe6\x9b\xb4\xe6\x94\xb9\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\xe5\x90\x8e\xef\xbc\x8c\xe6\x9b\xb4\xe6\x96\xb0\xe6\x89\x80\xe6\x9c\x89\xe6\xa0\xb7\xe6\x9c\xac\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n    def update_errors(self):\r\n        self.errors = [self.get_error(i) for i in range(len(self.feature))]\r\n\r\n\r\n    # \xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0\r\n    def predictall(self, prefeat):\r\n        ks = self.kernel(prefeat, self.feature)\r\n        wx = np.matrix(self.alphas - self.alphas_star) * ks\r\n        num = np.array(wx + self.b)\r\n        return num[0]\r\n\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xb8\x89\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9e\x84\xe5\xbb\xbaSMO\xe7\xae\x97\xe6\xb3\x95\xe9\x9c\x80\xe8\xa6\x81\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n""""""\r\n\r\n\r\ndef takestep(svr, i1, i2):\r\n    if i1 == i2:\r\n        return 0\r\n    alpha1, alphas1 = svr.alphas[i1], svr.alphas_star[i1]\r\n\r\n    alpha2, alphas2 = svr.alphas[i2], svr.alphas_star[i2]\r\n\r\n    phi1, phi2 = svr.errors[i1], svr.errors[i2]\r\n\r\n    x1, x2 = svr.feature[i1], svr.feature[i2]\r\n\r\n    y1, y2 = svr.labels[i1], svr.labels[i2]\r\n\r\n    k11, k12, k22 = svr.kernel(x1, x1)[0][0], svr.kernel(x1, x2)[0][0], svr.kernel(x2, x2)[0][0]\r\n\r\n    eta = 2 * k12 - k11 - k22\r\n\r\n    gamma = alpha1 - alphas1 + alpha2 - alphas2\r\n\r\n    case1 = case2 = case3 = case4 = finished = 0\r\n\r\n    a1old, a1olds = alpha1, alphas1\r\n\r\n    delta_phi = phi1 - phi2\r\n\r\n    while not finished:\r\n        if (case1 == 0) and (alpha1 > 0 or (alphas1 == 0 and delta_phi > 0)) \\\r\n                and (alpha2 > 0 or (alphas2 == 0 and delta_phi < 0)):\r\n            # \xe8\xae\xa1\xe7\xae\x97L\xe5\x92\x8cH (a1, a2)\r\n            L = max(0, gamma - svr.C)\r\n            H = min(svr.C, gamma)\r\n            if L < H:\r\n                if eta > 0:\r\n                    a2 = alpha2 - delta_phi / eta\r\n                    a2 = min(a2, H)\r\n                    a2 = max(L, a2)\r\n                    a1 = alpha1 - a2 + alpha2\r\n                else:\r\n                    a2 = L\r\n                    a1 = alpha1 - (a2 - alpha2)\r\n                    object1 = -0.5 * a1 * a1 * eta + a1 * (delta_phi + (a1old - a1olds) * eta)\r\n                    a2 = H\r\n                    a1 = alpha1 - (a2 - alpha2)\r\n                    object2 = -0.5 * a1 * a1 * eta + a1 * (delta_phi + (a1old - a1olds) * eta)\r\n                    if object1 > object2:\r\n                        a2 = L\r\n                    else:\r\n                        a2 = H\r\n                    a1 = alpha1 - (a2 - alpha2)\r\n                if abs(delta_phi - eta * (a1 - alpha1)) > svr.epsilon:\r\n                    svr.alphas[i1] = a1\r\n                    svr.alphas[i2] = a2\r\n            else:\r\n                finished = 1\r\n            case1 = 1\r\n\r\n        elif (case2 == 0) and (alpha1 > 0 or (alphas1 == 0 and delta_phi > 2 * svr.epsilon)) \\\r\n                and (alphas2 > 0 or (alpha2 == 0 and delta_phi > 2 * svr.epsilon)):\r\n            # \xe8\xae\xa1\xe7\xae\x97L\xe5\x92\x8cH (a1, a2*)\r\n            L = max(0, gamma)\r\n            H = min(svr.C, svr.C + gamma)\r\n\r\n            if L < H:\r\n                if eta > 0:\r\n                    a2 = alphas2 + (delta_phi - 2 * svr.epsilon) / eta\r\n                    a2 = min(a2, H)\r\n                    a2 = max(L, a2)\r\n                    a1 = alpha1 + a2 - alphas2\r\n                else:\r\n                    a2 = L\r\n                    a1 = alpha1 + (a2 - alphas2)\r\n                    object1 = -0.5 * a1 * a1 * eta - 2 * svr.epsilon * a1 + a1 * (delta_phi + (a1old - a1olds) * eta)\r\n                    a2 = H\r\n                    a1 = alpha1 + (a2 - alpha2)\r\n                    object2 = -0.5 * a1 * a1 * eta - 2 * svr.epsilon * a1 + a1 * (delta_phi + (a1old - a1olds) * eta)\r\n                    if object1 > object2:\r\n                        a2 = L\r\n                    else:\r\n                        a2 = H\r\n                    a1 = alpha1 + (a2 - alphas2)\r\n\r\n                # \xe5\x88\xa4\xe6\x96\xad\xe5\x8f\x98\xe5\x8c\x96\xe5\xa4\xa7\xe5\xb0\x8f\r\n                if abs(delta_phi - eta * (a1 - alpha1)) > svr.epsilon:\r\n                    svr.alphas[i1] = a1\r\n                    svr.alphas_star[i2] = a2\r\n            else:\r\n                finished = 1\r\n            case2 = 1\r\n\r\n\r\n        elif (case3 == 0) and (alphas1 > 0 or (alpha1 == 0 and delta_phi < 2 * svr.epsilon)) \\\r\n                and (alpha2 > 0 or (alphas2 == 0 and delta_phi < 2 * svr.epsilon)):\r\n            # \xe8\xae\xa1\xe7\xae\x97L\xe5\x92\x8cH (a1*, a2)\r\n            L = max(0, -gamma)\r\n            H = min(svr.C, svr.C - gamma)\r\n\r\n            if L < H:\r\n                if eta > 0:\r\n                    a2 = alpha2 - (delta_phi - 2 * svr.epsilon) / eta\r\n                    a2 = min(a2, H)\r\n                    a2 = max(L, a2)\r\n                    a1 = alphas1 + a2 - alpha2\r\n                else:\r\n                    a2 = L\r\n                    a1 = alphas1 + (a2 - alpha2)\r\n                    object1 = -0.5 * a1 * a1 * eta - 2 * svr.epsilon * a1 - a1 * (delta_phi + (a1old - a1olds) * eta)\r\n                    a2 = H\r\n                    a1 = alphas1 + (a2 - alpha2)\r\n                    object2 = -0.5 * a1 * a1 * eta - 2 * svr.epsilon * a1 - a1 * (delta_phi + (a1old - a1olds) * eta)\r\n                    if object1 > object2:\r\n                        a2 = L\r\n                    else:\r\n                        a2 = H\r\n                    a1 = alphas1 + (a2 - alpha2)\r\n\r\n                # \xe5\x88\xa4\xe6\x96\xad\xe5\x8f\x98\xe5\x8c\x96\xe5\xa4\xa7\xe5\xb0\x8f\r\n                if abs((delta_phi - eta * (-a1 + alphas1))) > svr.epsilon:\r\n                    svr.alphas_star[i1] = a1\r\n                    svr.alphas[i2] = a2\r\n            else:\r\n                finished = 1\r\n            case3 = 1\r\n\r\n\r\n        elif (case4 == 0) and (alphas1 > 0 or (alpha1 == 0 and delta_phi < 0)) \\\r\n                and (alphas2 > 0 or (alpha2 == 0 and delta_phi > 0)):\r\n            # \xe8\xae\xa1\xe7\xae\x97L\xe5\x92\x8cH (a1*, a2*)\r\n            L = max(0, -gamma - svr.C)\r\n            H = min(svr.C, - gamma)\r\n\r\n            if L < H:\r\n                if eta > 0:\r\n                    a2 = alphas2 + delta_phi / eta\r\n                    a2 = min(a2, H)\r\n                    a2 = max(L, a2)\r\n                    a1 = alphas1 - a2 + alphas2\r\n                else:\r\n                    a2 = L\r\n                    a1 = alphas1 - (a2 - alphas2)\r\n                    object1 = -0.5 * a1 * a1 * eta - a1 * (delta_phi + (a1old - a1olds) * eta)\r\n                    a2 = H\r\n                    a1 = alphas1 - (a2 - alphas2)\r\n                    object2 = -0.5 * a1 * a1 * eta - a1 * (delta_phi + (a1old - a1olds) * eta)\r\n                    if object1 > object2:\r\n                        a2 = L\r\n                    else:\r\n                        a2 = H\r\n                    a1 = alphas1 - (a2 - alphas2)\r\n                    # \xe5\x88\xa4\xe6\x96\xad\xe5\x8f\x98\xe5\x8c\x96\xe5\xa4\xa7\xe5\xb0\x8f\r\n                if abs((delta_phi - eta * (-a1 + alphas1))) > svr.epsilon:\r\n                    svr.alphas_star[i1] = a1\r\n                    svr.alphas_star[i2] = a2\r\n            else:\r\n                finished = 1\r\n            case4 = 1\r\n        else:\r\n            finished = 1\r\n\r\n        delta_phi = delta_phi - eta * ((alpha1 - alphas1) - (a1old - a1olds))\r\n\r\n\r\n    # \xe6\x9b\xb4\xe6\x96\xb0b\xe5\x80\xbc\r\n    b1, b2 = 0, 0\r\n    for ii in range(len(svr.feature)):\r\n        b1 += (svr.alphas[ii] - svr.alphas_star[ii]) * svr.kernel(svr.feature[ii], x1)[0][0]\r\n        b2 += (svr.alphas[ii] - svr.alphas_star[ii]) * svr.kernel(svr.feature[ii], x2)[0][0]\r\n\r\n    b1 = y1 - b1\r\n    b2 = y2 - b2\r\n\r\n    b12 = (b1 + b2) / 2\r\n    svr.b = b12\r\n\r\n\r\n    # \xe6\x9b\xb4\xe6\x96\xb0\xe8\xaf\xaf\xe5\xb7\xae\r\n    svr.update_errors()\r\n\r\n    if abs(delta_phi) > svr.epsilon:\r\n        return 1\r\n    else:\r\n        return 0\r\n\r\ndef examineExample(svr, i2):\r\n    alpha2 = svr.alphas[i2]\r\n    alphas2 = svr.alphas_star[i2]\r\n    phi2 = svr.errors[i2]\r\n\r\n    if (phi2 > svr.epsilon and alphas2 < svr.C) or (phi2 < svr.epsilon and alphas2 > 0) \\\r\n            or(-phi2 > svr.epsilon and alpha2 < svr.C) or (-phi2 > svr.epsilon and alpha2 > 0):\r\n        manzu = [io for io in range(len(svr.feature)) if svr.alphas[io] != 0 and svr.alphas[io] != svr.C]\r\n        if len(manzu) > 1:\r\n            delta_phi = 0\r\n            i1 = 0\r\n            for hi in range(len(svr.feature)):\r\n                # \xe9\x80\x89\xe6\x8b\xa9\xe6\x9c\x80\xe5\xa4\xa7\xe7\x9a\x84\xe5\x90\xaf\xe5\x8f\x91\xe5\xbc\x8f\xe9\x80\x89\xe6\x8b\xa9\r\n                yphi = svr.errors[hi]\r\n                if abs(yphi - phi2) > delta_phi:\r\n                    delta_phi = abs(yphi - phi2)\r\n                    i1 = hi\r\n            if takestep(svr, i1, i2):\r\n                return 1\r\n        # \xe9\x9a\x8f\xe6\x9c\xba\xe8\xbe\xb9\xe7\x95\x8c\xe6\xa0\xb7\xe6\x9c\xac\xe9\x80\x89\xe6\x8b\xa9\r\n        for jj in range(len(svr.feature)):\r\n            i1 = np.random.choice(np.arange(len(svr.feature)), 1)[0]\r\n            if svr.alphas[i1] != 0 and svr.alphas[i1] != svr.C:\r\n                if takestep(svr, i1, i2):\r\n                    return 1\r\n        # \xe9\x9a\x8f\xe6\x9c\xba\xe5\x85\xa8\xe9\x83\xa8\xe6\xa0\xb7\xe6\x9c\xac\xe9\x80\x89\xe6\x8b\xa9\r\n        for jj in range(len(svr.feature)):\r\n            i1 = np.random.choice(np.arange(len(svr.feature)), 1)[0]\r\n            if takestep(svr, i1, i2):\r\n                return 1\r\n    return 0\r\n\r\n\r\n\r\n# \xe4\xb8\xbb\xe8\xa6\x81\xe5\x87\xbd\xe6\x95\xb0\r\ndef mainfun(svr):\r\n    numChanged = 0\r\n    examineAll = 1\r\n    SigFig = -100\r\n    Loopcounter = 0\r\n\r\n    while ((numChanged > 0 or examineAll) or SigFig < 3) and Loopcounter < 10000:\r\n        Loopcounter += 1\r\n        numChanged = 0\r\n        if examineAll:\r\n            print(\'\xe5\x85\xa8\xe9\x83\xa8\xe6\xa0\xb7\xe6\x9c\xac\')\r\n            for ig in range(len(svr.feature)):\r\n                numChanged += examineExample(svr, ig)\r\n        else:\r\n            print(\'\xe8\xbe\xb9\xe7\x95\x8c\xe6\xa0\xb7\xe6\x9c\xac\')\r\n            manzu = [ipo for ipo in range(len(svr.feature)) if svr.alphas[ipo] != 0 and svr.alphas[ipo] != svr.C]\r\n            for gi in manzu:\r\n                numChanged += examineExample(svr, gi)\r\n\r\n        if Loopcounter % 2 == 0:\r\n            MinimumNumChanged = max(1, 0.1 * len(svr.alphas))\r\n        else:\r\n            MinimumNumChanged = 1\r\n\r\n        if examineAll == 1:\r\n            examineAll = 0\r\n        else:\r\n            if numChanged < MinimumNumChanged:\r\n                examineAll = 1\r\n        dobject = 0\r\n        pobject = 0\r\n\r\n        for ghi in range(len(svr.feature)):\r\n            p1 = svr.feature[ghi]\r\n            dobject += max(0, svr.line_num(p1) - svr.labels[ghi] - svr.epsilon) * (svr.C - svr.alphas_star[ghi])\r\n            dobject -= min(0, svr.line_num(p1) - svr.labels[ghi] - svr.epsilon) * svr.alphas_star[ghi]\r\n            dobject += min(0, svr.labels[ghi] - svr.epsilon - svr.line_num(p1)) * (svr.C - svr.alphas[ghi])\r\n            dobject -= max(0, svr.labels[ghi] - svr.epsilon - svr.line_num(p1)) * svr.alphas[ghi]\r\n\r\n\r\n            p1 = svr.feature[ghi]\r\n            pobject += (0.5 * (svr.alphas[ghi] - svr.alphas_star[ghi]) * (svr.line_num(p1) - svr.b))\r\n            pobject -= (svr.epsilon * (svr.alphas[ghi] + svr.alphas_star[ghi]))\r\n            pobject += (svr.labels[ghi] * (svr.alphas[ghi] - svr.alphas_star[ghi]))\r\n\r\n        print(\'gggggggggggggggggggggggggggggggggggg\', pobject, dobject)\r\n        pobject += dobject\r\n\r\n        SigFig = np.log10(dobject / (abs(pobject) + 1))\r\n        print(\'SigFig = %.9f\' % SigFig)\r\n\r\n    print(\'\xe7\xbb\x93\xe6\x9d\x9f\xe8\xae\xad\xe7\xbb\x83\')\r\n    return svr.alphas, svr.alphas_star, svr.b\r\n\r\n\r\n# \xe8\xbf\x94\xe5\x9b\x9e\xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xbe\x93\xe5\x87\xba\xe5\x80\xbc\r\ndef pl(trfe, trla, prfe, maxnum, minnum):\r\n    # \xe5\xbb\xba\xe7\xab\x8b\xe7\xbb\x93\xe6\x9e\x84\r\n    svre = SVR(feature=trfe, labels=trla)\r\n    mainfun(svre)\r\n    traiout = svre.predictall(trfe)\r\n    preout = svre.predictall(prfe)\r\n\r\n    # \xe9\xa6\x96\xe5\x85\x88\xe6\x98\xaf\xe6\x95\xb0\xe6\x8d\xae\xe8\xbd\xac\xe5\x8c\x96\xe8\x8c\x83\xe5\x9b\xb4\r\n    traiout = traiout * (maxnum - minnum) + minnum\r\n    preout = preout * (maxnum - minnum) + minnum\r\n\r\n    return traiout, preout\r\n\r\n\r\n# \xe7\xbb\x98\xe5\x9b\xbe\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef huitu(suout, shiout, c=[\'b\', \'k\'], sign=\'\xe8\xae\xad\xe7\xbb\x83\', cudu=3):\r\n    print(suout)\r\n    print(shiout)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n    plt.subplot(2, 1, 1)\r\n    plt.plot(list(range(len(suout))), suout, c=c[0], linewidth=cudu, label=\'%s\xef\xbc\x9a\xe7\xae\x97\xe6\xb3\x95\xe8\xbe\x93\xe5\x87\xba\' % sign)\r\n    plt.plot(list(range(len(shiout))), shiout, c=c[1], linewidth=cudu, label=\'%s\xef\xbc\x9a\xe5\xae\x9e\xe9\x99\x85\xe5\x80\xbc\' % sign)\r\n    plt.legend()\r\n    plt.title(\'\xe5\xaf\xb9\xe6\xaf\x94\')\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe8\xaf\xaf\xe5\xb7\xae\xe5\x92\x8c0\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe5\x9b\xbe\r\n    plt.subplot(2, 1, 2)\r\n    plt.plot(list(range(len(suout))), suout - shiout, c=\'r\', linewidth=cudu, label=\'%s\xef\xbc\x9a\xe8\xaf\xaf\xe5\xb7\xae\' % sign)\r\n    plt.plot(list(range(len(suout))), list(np.zeros(len(suout))), c=\'r\', linewidth=cudu, label=\'0\xe5\x80\xbc\')\r\n    plt.legend()\r\n    plt.title(\'\xe8\xaf\xaf\xe5\xb7\xae\')\r\n    # \xe9\x9c\x80\xe8\xa6\x81\xe6\xb7\xbb\xe5\x8a\xa0\xe4\xb8\x80\xe4\xb8\xaa\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\x88\x86\xe5\xb8\x83\xe5\x9b\xbe\r\n\r\n    # \xe6\x98\xbe\xe7\xa4\xba\r\n    plt.show()\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe8\xbf\x90\xe8\xa1\x8c\xe7\xa8\x8b\xe5\xba\x8f\'\'\'\r\nif __name__ == ""__main__"":\r\n    datasvr = rdata.model_data\r\n    outtri, poupre = pl(datasvr[0], datasvr[1].T[0], datasvr[2], datasvr[4][0], datasvr[4][1])\r\n\r\n    trii = datasvr[1].T[0] * (datasvr[4][0] - datasvr[4][1]) + datasvr[4][1]\r\n    huitu(outtri, trii, c=[\'b\', \'k\'], sign=\'\xe8\xae\xad\xe7\xbb\x83\', cudu=3)\r\n\r\n    prii = datasvr[3].T[0] * (datasvr[4][0] - datasvr[4][1]) + datasvr[4][1]\r\n    huitu(poupre, prii, c=[\'b\', \'k\'], sign=\'\xe9\xa2\x84\xe6\xb5\x8b\', cudu=3)\r\n'"
SVM/SVM_Regression/SVM_Regression_Data.py,0,"b""# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author  AnFany\r\n\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\ndata = pd.read_csv(r'C:\\Users\\GWT9\\Desktop\\PRSA_data_2010.1.1-2014.12.31.csv')\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\r\n# \xe7\x9b\xae\xe6\xa0\x87\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xafpm2.5\xef\xbc\x8c\xe5\x9b\xa0\xe6\xad\xa4\xe5\x88\xa0\xe5\x8e\xbb\xe6\xad\xa4\xe5\x88\x97\xe4\xb8\xbaNaN\xe7\x9a\x84\xe8\xa1\x8c\r\ndata_nan = data[np.isfinite(data['pm2.5'])]\r\n\r\n# \xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe5\xad\x97\xe6\xae\xb5\xe6\x98\xaf\xe5\xba\x8f\xe5\x8f\xb7\xe5\xad\x97\xe6\xae\xb5\xef\xbc\x8c\xe4\xb8\x8d\xe9\x9c\x80\xe8\xa6\x81\r\ndata_one = data_nan[data_nan.columns[1:]]\r\n\r\n# \xe5\xad\x97\xe6\xae\xb5'cbwd'\xef\xbc\x8c\xe7\x8b\xac\xe7\x83\xad\xe7\xbc\x96\xe7\xa0\x81\r\n\r\none_data = pd.get_dummies(data_one['cbwd'], prefix='cbwd')\r\n\r\n# \xe5\x88\xa0\xe9\x99\xa4\xe5\x8e\x9f\xe6\x9d\xa5\xe7\x9a\x84\xe5\xad\x97\xe6\xae\xb5'cbwd'\r\n\r\ndata_cw = data_one.drop(['cbwd'], axis=1)\r\n\r\n# \xe6\xb7\xbb\xe5\x8a\xa0\xe4\xb8\x8a\xe7\x8b\xac\xe7\x83\xad\xe4\xba\xa7\xe7\x94\x9f\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\ndata_hh = pd.concat([data_cw, one_data], axis=1)\r\n\r\n\r\n# \xe5\x9b\xa0\xe4\xb8\xba\xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x8f\xe7\x9a\x84\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c \xe5\x8f\xaa\xe6\x98\xaf\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96\xe9\x83\xa8\xe5\x88\x86\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xae\xad\xe7\xbb\x83\r\ndef serand(dafra, precent=0.01):\r\n    df2 = dafra.sample(frac=precent)\r\n    return df2\r\n\r\ndata_hh = serand(data_hh)\r\n\r\n\r\n#  \xe8\x8e\xb7\xe5\xbe\x97\xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe4\xb8\x8e\xe6\x9c\x80\xe5\xb0\x8f\xe5\x80\xbc\xef\xbc\x8c\r\n\r\nymax = np.max(data_hh['pm2.5'].values, keepdims=True)\r\n\r\nymin = np.min(data_hh['pm2.5'].values, keepdims=True)\r\n\r\n\r\n\r\n# \xe6\x89\x80\xe6\x9c\x89\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\xef\xbc\x8c \xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae0-1\xe5\x8c\x96\r\ndef norm(dat):\r\n    da = pd.DataFrame()\r\n    for hh in dat.columns:\r\n        if hh != 'pm2.5':\r\n            da[hh] = (dat[hh] - np.mean(dat[hh])) / np.std(dat[hh])  # \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\n            #  da[hh] = (dat[hh] - np.min(dat[hh])) / (np.max(dat[hh]) - np.min(dat[hh])) # 0-1\xe5\x8c\x96\r\n        else:\r\n            da[hh] = (dat[hh] - np.min(dat[hh])) / (np.max(dat[hh]) - np.min(dat[hh]))  # 0-1\xe5\x8c\x96\r\n    return da\r\n\r\ndatee = norm(data_hh)\r\n\r\n\r\n# \xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe7\xa6\xbb\r\n\r\nYdata = np.array(datee['pm2.5'].values).reshape(-1, 1)  # \xe7\x9b\xae\xe6\xa0\x87\xe6\x95\xb0\xe6\x8d\xae\r\nXdata = datee.drop(['pm2.5'], axis=1).values  # \xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0\xe6\x8d\xae\r\n\r\n\r\n#  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x88\x86\xe4\xb8\xba\xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\ndef divided(xdata, ydata, percent=0.3):\r\n    sign_list = list(range(len(xdata)))\r\n    #  \xe7\x94\xa8\xe4\xba\x8e\xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84\xe5\xba\x8f\xe5\x8f\xb7\r\n    select_sign = np.random.choice(sign_list, int(len(xdata) * percent), replace=False)\r\n\r\n    #  \xe7\x94\xa8\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe5\xba\x8f\xe5\x8f\xb7\r\n    no_select_sign = [isign for isign in sign_list if isign not in select_sign]\r\n\r\n    # \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\n    x_predict_data = xdata[select_sign]\r\n    y_predict_data = np.array(ydata[select_sign]).reshape(-1, len(ydata[0]))  # \xe8\xbd\xac\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n\r\n    # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n    x_train_data = xdata[no_select_sign]\r\n    y_train_data = np.array(ydata[no_select_sign]).reshape(-1, len(ydata[0]))  # \xe8\xbd\xac\xe5\x8c\x96\xe6\x95\xb0\xe6\x8d\xae\xe7\xbb\x93\xe6\x9e\x84\r\n\r\n    return x_train_data, y_train_data, x_predict_data, y_predict_data # \xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84x\xef\xbc\x8cy;  \xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84x\xef\xbc\x8cy;\r\n\r\n\r\n# \xe5\x8f\xaf\xe7\x94\xa8\xe4\xba\x8e\xe7\xae\x97\xe6\xb3\x95\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\r\nmodel_data = list(divided(Xdata, Ydata))\r\nmodel_data.append([ymax, ymin])\r\n\r\n"""
SVM/SVM_Regression/Sklearn_SVM_Regression.py,0,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author AnFany\r\n\r\n# \xe5\x88\xa9\xe7\x94\xa8Sklearn\xe5\x8c\x85\xe5\xae\x9e\xe7\x8e\xb0\xe6\x94\xaf\xe6\x8c\x81\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x9b\x9e\xe5\xbd\x92\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xbc\x95\xe5\x85\xa5\xe5\xba\x93\r\n""""""\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe9\x83\xa8\xe5\x88\x86\xe7\x9a\x84\xe5\x8c\x97\xe4\xba\xacPM2.5\xe6\x95\xb0\xe6\x8d\xae\r\nimport SVM_Regression_Data as rdata\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe5\xba\x93\xe5\x8c\x85\r\nfrom sklearn import svm\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl\r\n\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9e\x84\xe5\xbb\xba\xe5\x87\xbd\xe6\x95\xb0\r\n""""""\r\n\r\n\r\n# \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\ndef sk_svm_train(intr, labeltr, inte, kener):\r\n    clf = svm.SVR(kernel=kener)\r\n    #  \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n    clf.fit(intr, labeltr)\r\n    #  \xe8\xae\xad\xe7\xbb\x83\xe8\xbe\x93\xe5\x87\xba\r\n    tr = clf.predict(intr)\r\n    #  \xe9\xa2\x84\xe6\xb5\x8b\xe8\xbe\x93\xe5\x87\xba\r\n    pr = clf.predict(inte)\r\n\r\n    return tr, pr\r\n\r\n\r\n# \xe7\xbb\x93\xe6\x9e\x9c\xe8\xbe\x93\xe5\x87\xba\xe5\x87\xbd\xe6\x95\xb0\r\n\'\'\'\r\n\xe2\x80\x98linear\xe2\x80\x99, \xe2\x80\x98poly\xe2\x80\x99, \xe2\x80\x98rbf\xe2\x80\x99, \xe2\x80\x98sigmoid\xe2\x80\x99\r\n\'\'\'\r\n#  \xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\r\ndef result(data, he=\'rbf\'):\r\n    # \xe8\xae\xad\xe7\xbb\x83\xe3\x80\x81\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xbd\x91\xe7\xbb\x9c\xe8\xbe\x93\xe5\x87\xba\r\n    trainacc, testacc = [], []\r\n\r\n    xd = data[0]\r\n    yd = data[1].T[0]\r\n    #  \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\n    texd = data[2]\r\n    teyd = data[3].T[0]\r\n\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n    resu = sk_svm_train(xd, yd, texd, he)\r\n\r\n    tra = resu[0] * (data[4][1] - data[4][0]) + data[4][0]\r\n\r\n    pre = resu[1] * (data[4][1] - data[4][0]) + data[4][0]\r\n\r\n    ydd = data[1].T[0] * (data[4][1] - data[4][0]) + data[4][0]\r\n\r\n    teyd = data[3].T[0] * (data[4][1] - data[4][0]) + data[4][0]\r\n\r\n    return ydd, tra, teyd, pre\r\n\r\n\r\n# \xe7\xbb\x98\xe5\x9b\xbe\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef huitu(suout, shiout, c=[\'b\', \'k\'], sign=\'\xe8\xae\xad\xe7\xbb\x83\', cudu=3):\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n    plt.subplot(2, 1, 1)\r\n    plt.plot(list(range(len(suout))), suout, c=c[0], linewidth=cudu, label=\'%s\xef\xbc\x9a\xe7\xae\x97\xe6\xb3\x95\xe8\xbe\x93\xe5\x87\xba\' % sign)\r\n    plt.plot(list(range(len(shiout))), shiout, c=c[1], linewidth=cudu, label=\'%s\xef\xbc\x9a\xe5\xae\x9e\xe9\x99\x85\xe5\x80\xbc\' % sign)\r\n    plt.legend(loc=\'best\')\r\n    plt.title(\'\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\')\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe8\xaf\xaf\xe5\xb7\xae\xe5\x92\x8c0\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe5\x9b\xbe\r\n    plt.subplot(2, 2, 3)\r\n    plt.plot(list(range(len(suout))), suout - shiout, c=\'r\', linewidth=cudu, label=\'%s\xef\xbc\x9a\xe8\xaf\xaf\xe5\xb7\xae\' % sign)\r\n    plt.plot(list(range(len(suout))), list(np.zeros(len(suout))), c=\'k\', linewidth=cudu, label=\'0\xe5\x80\xbc\')\r\n    plt.legend(loc=\'best\')\r\n    plt.title(\'\xe8\xaf\xaf\xe5\xb7\xae\xe5\x92\x8c0\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\')\r\n    # \xe9\x9c\x80\xe8\xa6\x81\xe6\xb7\xbb\xe5\x8a\xa0\xe4\xb8\x80\xe4\xb8\xaa\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\x88\x86\xe5\xb8\x83\xe5\x9b\xbe\r\n    plt.subplot(2, 2, 4)\r\n    plt.hist(suout - shiout, 50, facecolor=\'g\', alpha=0.75)\r\n    plt.title(\'\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9b\xb4\xe6\x96\xb9\xe5\x9b\xbe\')\r\n    # \xe6\x98\xbe\xe7\xa4\xba\r\n    plt.show()\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe8\xbf\x90\xe8\xa1\x8c\xe7\xa8\x8b\xe5\xba\x8f\'\'\'\r\nif __name__ == ""__main__"":\r\n    datasvr = rdata.model_data\r\n    realtr, outtri, realpre, poupre = result(datasvr, he=\'rbf\')\r\n\r\n    huitu(realtr, outtri, c=[\'b\', \'k\'], sign=\'\xe8\xae\xad\xe7\xbb\x83\', cudu=1.5)\r\n\r\n    huitu(realpre, poupre, c=[\'b\', \'k\'], sign=\'\xe9\xa2\x84\xe6\xb5\x8b\', cudu=1.5)\r\n\r\n\r\n\r\n'"
SVM/SVM_Regression/TensorFlow_SVM_Regression.py,44,"b'# -*- coding\xef\xbc\x9autf-8 -*-\r\n# &Author AnFany\r\n\r\n# \xe5\x9f\xba\xe4\xba\x8eTensorFlow\xe5\xae\x9e\xe7\x8e\xb0\xe6\x94\xaf\xe6\x8c\x81\xe5\x90\x91\xe9\x87\x8f\xe6\x9c\xba\xe5\x9b\x9e\xe5\xbd\x92\r\n# \xe9\x98\xb2\xe6\xad\xa2\xe4\xb8\x8d\xe7\xa8\xb3\xe5\xae\x9a\xef\xbc\x8c\xe4\xb8\x8d\xe9\x87\x87\xe7\x94\xa8batchsize\xe7\x9a\x84\xe6\x96\xb9\xe5\xbc\x8f\xe8\xae\xad\xe7\xbb\x83\xef\xbc\x8c\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe8\xae\xad\xe7\xbb\x83\xe9\x83\xbd\xe6\x98\xaf\xe5\x85\xa8\xe9\x83\xa8\xe6\xa0\xb7\xe6\x9c\xac\r\n# \xe5\x9b\xa0\xe6\xad\xa4\xe4\xb8\x8d\xe9\x80\x82\xe7\x94\xa8\xe4\xba\x8e\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x8f\xe8\xbe\x83\xe5\xa4\xa7\xe7\x9a\x84\xe6\x83\x85\xe5\x86\xb5\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe6\x83\xa9\xe7\xbd\x9a\xe9\xa1\xb9\xe5\xae\x9e\xe7\x8e\xb0\xe5\xaf\xb9\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\xe7\x9a\x84\xe9\x99\x90\xe5\x88\xb6\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xb8\x80\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe5\xbc\x95\xe5\x85\xa5\xe5\xba\x93\r\n""""""\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe5\xba\x93\xe5\x8c\x85\r\nimport numpy as np\r\n\r\n# \xe5\xbc\x95\xe5\x85\xa5\xe9\x83\xa8\xe5\x88\x86\xe7\x9a\x84\xe5\x8c\x97\xe4\xba\xacPM2.5\xe6\x95\xb0\xe6\x8d\xae\r\nimport SVM_Regression_Data as rdata\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework import ops\r\nops.reset_default_graph()\r\n\r\n# \xe7\xbb\x98\xe5\x9b\xbe\r\nimport matplotlib.pyplot as plt\r\nfrom pylab import mpl\r\nmpl.rcParams[\'font.sans-serif\'] = [\'FangSong\']  # \xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe4\xbd\x93\xe5\x90\x8d\xe7\xa7\xb0\r\nmpl.rcParams[\'axes.unicode_minus\'] = False  # \xe6\x98\xbe\xe7\xa4\xba\xe8\xb4\x9f\xe5\x8f\xb7\r\n\r\n""""""\r\n\xe7\xac\xac\xe4\xba\x8c\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9e\x84\xe9\x80\xa0\xe5\x87\xbd\xe6\x95\xb0\r\n""""""\r\n\r\n\r\n# keneral\xef\xbc\x9a \xe7\xba\xbf\xe6\x80\xa7\xe5\x8f\xaf\xe5\x88\x86lin1   \xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x9a lin\xef\xbc\x9a\xe7\xba\xbf\xe6\x80\xa7\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0   poly\xef\xbc\x9a\xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0   rbf\xef\xbc\x9a\xe9\xab\x98\xe6\x96\xaf\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0  sigmoid\xef\xbc\x9aSigmoid\xe5\x9e\x8b\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n\r\nclass SVM:\r\n    def __init__(self, manum, minum, maxtimes=20000, C=0.09, ploy_d=6, rbf_sigma=0.15, tanh_beta=0.9, tanh_theta=-0.6,\r\n                 kernel=\'rbf\', epslion=0.5, beta=0, quj=100, ling=100):  # \xe5\x8f\x82\xe6\x95\xb0\xe5\x9d\x87\xe4\xb8\xbafloat\xe5\xbd\xa2\xe5\xbc\x8f\r\n\r\n        self.maxtimes = maxtimes  # \xe5\xbe\xaa\xe7\x8e\xaf\xe6\x9c\x80\xe5\xa4\xa7\xe6\xac\xa1\xe6\x95\xb0\r\n\r\n        self.C = C  # \xe8\xbd\xaf\xe9\x97\xb4\xe9\x9a\x94\r\n        self.ploy_d = ploy_d   # \xe5\xa4\x9a\xe9\xa1\xb9\xe5\xbc\x8f\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x8f\x82\xe6\x95\xb0\r\n        self.rbf_sigma = rbf_sigma   # \xe9\xab\x98\xe6\x96\xaf\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x8f\x82\xe6\x95\xb0\r\n        self.tanh_beta = tanh_beta   # Sigmoid\xe5\x9e\x8b\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x8f\x82\xe6\x95\xb0\r\n        self.tanh_theta = tanh_theta\r\n\r\n        self.kernel = kernel  # \xe7\x94\xa8\xe5\x88\xb0\xe7\x9a\x84\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n\r\n        self.epslion = epslion\r\n        self.beta = beta\r\n\r\n        self.manum = manum\r\n        self.minum = minum\r\n\r\n        self.quj = quj\r\n        self.ling = ling\r\n\r\n    # \xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x98\xe5\x8e\x9f\xe5\xb0\xba\xe5\xba\xa6\r\n    def reyuan(self, x):\r\n        hxx = x * (self.manum - self.minum) + self.minum\r\n        return hxx\r\n\r\n    #  \xe8\xae\xad\xe7\xbb\x83\xe5\x87\xbd\xe6\x95\xb0\r\n    def train_svm(self, shuxing, biaoqian, ceshisx, ceshibq):\r\n\r\n        # \xe5\x88\x9b\xe5\xbb\xba\xe4\xbc\x9a\xe8\xaf\x9d\r\n        sess = tf.Session()\r\n\r\n        # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\r\n        x_data = tf.placeholder(shape=[None, len(shuxing[0])], dtype=tf.float32)\r\n        y_target = tf.placeholder(shape=[1, None], dtype=tf.float32)\r\n\r\n        # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe5\x8d\xa0\xe4\xbd\x8d\xe7\xac\xa6\r\n        prexdata = tf.placeholder(shape=[None, len(shuxing[0])], dtype=tf.float32)\r\n\r\n\r\n        # \xe7\xba\xbf\xe6\x80\xa7\xe5\x9b\x9e\xe5\xbd\x92\r\n        if self.kernel == \'lin1\':\r\n            # \xe5\x9b\x9e\xe5\xbd\x92\xe7\xba\xbf\xe7\x9a\x84\xe5\x8f\x98\xe9\x87\x8f\r\n            W = tf.Variable(tf.random_normal(shape=[len(shuxing[0]), 1]), dtype=tf.float32)\r\n            b = tf.Variable(tf.random_normal(shape=[1, 1]), dtype=tf.float32)\r\n\r\n            # \xe5\x9b\x9e\xe5\xbd\x92\xe7\xba\xbf\xe5\x80\xbc\r\n            model_output = tf.transpose(tf.subtract(tf.matmul(x_data, W), b))\r\n\r\n            # L2\xe8\x8c\x83\xe6\x95\xb0\r\n            l2_term = tf.reduce_sum(tf.square(W))\r\n\r\n            # \xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\r\n            loss = tf.reduce_mean(\r\n                tf.maximum(0., tf.subtract(tf.abs(tf.subtract(model_output, y_target)), self.epslion))) + self.beta * l2_term\r\n\r\n            # \xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\n            predition_num = tf.transpose(tf.subtract(tf.matmul(prexdata, W), b))\r\n\r\n\r\n        else:\r\n            # \xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\xe5\x8f\x98\xe9\x87\x8f\r\n            Lagrange = tf.Variable(tf.random_normal(shape=[1, len(shuxing)]), dtype=tf.float32)  # \xe5\x92\x8c\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe6\x98\xaf\xe4\xb8\x80\xe8\x87\xb4\xe7\x9a\x84\r\n\r\n            Lagrange_Star = tf.Variable(tf.random_normal(shape=[1, len(shuxing)]), dtype=tf.float32)  # \xe5\x92\x8c\xe6\xa0\xb7\xe6\x9c\xac\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\xe6\x98\xaf\xe4\xb8\x80\xe8\x87\xb4\xe7\x9a\x84\r\n\r\n            b = tf.Variable(tf.random_normal(shape=[1, 1]), dtype=tf.float32)\r\n\r\n\r\n            # linear \xe7\xba\xbf\xe6\x80\xa7\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\r\n            if self.kernel == \'linear\':\r\n                # \xe8\xae\xa1\xe7\xae\x97\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc\r\n                kernel_num = tf.matmul(x_data, tf.transpose(x_data))\r\n                # \xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0\r\n                pred_num = tf.matmul(x_data, tf.transpose(prexdata))\r\n\r\n            elif self.kernel == \'poly\':\r\n                # \xe8\xae\xa1\xe7\xae\x97\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc\r\n                kernel_num = tf.pow(tf.matmul(x_data, tf.transpose(x_data)), self.ploy_d)\r\n                # \xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0\r\n                pred_num = tf.pow(tf.matmul(x_data, tf.transpose(prexdata)), self.ploy_d)\r\n\r\n            elif self.kernel == \'sigmoid\':\r\n                # \xe8\xae\xa1\xe7\xae\x97\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x80\xbc\r\n                kernel_num = tf.tanh(self.tanh_beta * tf.matmul(x_data, tf.transpose(x_data)) + self.tanh_theta)\r\n                # \xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0\r\n                pred_num = tf.tanh(self.tanh_beta * tf.matmul(x_data, tf.transpose(prexdata)) + self.tanh_theta)\r\n\r\n            elif self.kernel == \'rbf\':\r\n                # \xe8\xae\xa1\xe7\xae\x97\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe5\xb0\x86\xe6\xa8\xa1\xe7\x9a\x84\xe5\xb9\xb3\xe6\x96\xb9\xe5\xb1\x95\xe5\xbc\x80\xef\xbc\x9aa\xe6\x96\xb9+b\xe6\x96\xb9-2ab\r\n                xdatafang = tf.reshape(tf.reduce_sum(tf.square(x_data), 1), [-1, 1])\r\n                momo = tf.add(tf.subtract(xdatafang, tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))),\r\n                                tf.transpose(xdatafang))\r\n                kernel_num = tf.exp(tf.multiply((1/(-2 * tf.pow(self.rbf_sigma, 2))), tf.abs(momo)))\r\n\r\n                # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe5\x80\xbc\xef\xbc\x8c\xe5\xb0\x86\xe6\xa8\xa1\xe7\x9a\x84\xe5\xb9\xb3\xe6\x96\xb9\xe5\xb1\x95\xe5\xbc\x80\xef\xbc\x9aa\xe6\x96\xb9+b\xe6\x96\xb9-2ab\r\n                xfang = tf.reshape(tf.reduce_sum(tf.square(x_data), 1), [-1, 1])\r\n                prefang = tf.reshape(tf.reduce_sum(tf.square(prexdata), 1), [-1, 1])\r\n                mofang = tf.add(tf.subtract(xfang, tf.multiply(2., tf.matmul(x_data, tf.transpose(prexdata)))),\r\n                                tf.transpose(prefang))\r\n                pred_num = tf.exp(tf.multiply((1/(-2 * tf.pow(self.rbf_sigma, 2))), tf.abs(mofang)))\r\n            else:\r\n                print(\'\xe6\xa0\xb8\xe5\x87\xbd\xe6\x95\xb0\xe5\x91\xbd\xe5\x90\x8d\xe9\x94\x99\xe8\xaf\xaf\')\r\n                kernel_num = 0\r\n                pred_num = 0\r\n\r\n\r\n            # \xe8\xae\xa1\xe7\xae\x97\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\r\n            # \xe7\xac\xac\xe4\xb8\x80\xe9\xa1\xb9\r\n            la_la = tf.matmul(tf.transpose(tf.subtract(Lagrange, Lagrange_Star)), tf.subtract(Lagrange, Lagrange_Star))\r\n            first = -0.5 * tf.reduce_sum(tf.multiply(kernel_num, la_la))\r\n\r\n            # \xe7\xac\xac\xe4\xba\x8c\xe9\xa1\xb9\r\n            second = -self.epslion * (tf.reduce_sum(Lagrange) + tf.reduce_sum(Lagrange_Star))\r\n\r\n            # \xe7\xac\xac\xe4\xb8\x89\xe9\xa1\xb9\r\n            third = tf.reduce_sum(tf.multiply(tf.subtract(Lagrange, Lagrange_Star), y_target))\r\n\r\n            # \xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\r\n            sonloss = tf.negative(tf.add(tf.add(first, second), third))\r\n\r\n            # \xe5\x9b\xa0\xe4\xb8\xba\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x8f\x98\xe9\x87\x8f\xe6\x98\xaf\xe7\x94\xb1\xe9\x99\x90\xe5\x88\xb6\xe7\x9a\x84\xef\xbc\x8c\xe5\x9c\xa8tensorflow\xe4\xb8\xad\xef\xbc\x8c\xe5\x88\xa9\xe7\x94\xa8\xe6\x83\xa9\xe7\xbd\x9a\xe9\xa1\xb9\xe6\x9d\xa5\xe5\xae\x9e\xe7\x8e\xb0\xe5\xaf\xb9\xe5\x8f\x98\xe9\x87\x8f\xe5\x8f\x96\xe5\x80\xbc\xe7\x9a\x84\xe6\x8e\xa7\xe5\x88\xb6,\r\n            # \xe9\x80\x9a\xe8\xbf\x87\xe5\x8a\xa0\xe5\xa4\xa7\xe6\x83\xa9\xe7\xbd\x9a\xe9\xa1\xb9\xe7\x9a\x84\xe6\x9d\x83\xe9\x87\x8d\xe6\x9d\xa5\xe5\x8a\xa0\xe5\xbf\xab\xe8\x88\x8d\xe5\xbc\x83\xe4\xb8\x8d\xe7\xac\xa6\xe5\x90\x88\xe7\x9a\x84\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\r\n            #  \xe9\xa6\x96\xe5\x85\x88\xe6\x98\xaf\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\xba\x94\xe8\xaf\xa5\xe5\x9c\xa8[0, C] \xe4\xb9\x8b\xe9\x97\xb4\r\n\r\n            # \xe9\xa6\x96\xe5\x85\x88\xe6\x98\xaf\xe9\x92\x88\xe5\xaf\xb9\xe8\xb4\x9f\xe6\x95\xb0\r\n            qujian_fu = tf.reduce_sum(tf.nn.relu(tf.negative(Lagrange))) + tf.reduce_sum(tf.nn.relu(tf.negative(Lagrange_Star)))\r\n\r\n            # \xe9\x92\x88\xe5\xaf\xb9\xe8\xb6\x85C\xe5\x80\xbc\r\n            qujian_c = tf.reduce_sum(tf.nn.relu(tf.subtract(tf.abs(Lagrange), self.C))) + \\\r\n                       tf.reduce_sum(tf.nn.relu(tf.subtract(tf.abs(Lagrange_Star), self.C)))\r\n\r\n            # \xe7\xbb\x93\xe5\x90\x88\xe4\xb8\x8a\xe9\x9d\xa2\xe4\xb8\xa4\xe9\xa1\xb9\r\n            qujian = self.quj * tf.add(qujian_c, qujian_fu)\r\n\r\n            # \xe5\x86\x8d\xe8\x80\x85\xe6\x98\xaf\xe6\xa0\xb7\xe6\x9c\xac\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\xe7\x9a\x84\xe5\xb7\xae\xe7\x9a\x84\xe5\x92\x8c\xe6\x98\xaf0\r\n            cha = tf.abs(tf.reduce_sum(tf.subtract(Lagrange, Lagrange_Star)))\r\n            sub = self.ling * cha\r\n\r\n\r\n            # \xe5\xb8\xa6\xe6\x9c\x89\xe5\x8f\x98\xe9\x87\x8f\xe9\x99\x90\xe5\x88\xb6\xe7\x9a\x84\xe6\x8b\x89\xe6\xa0\xbc\xe6\x9c\x97\xe6\x97\xa5\xe5\x9b\xa0\xe5\xad\x90\xe6\x80\xbb\xe4\xbd\x93\xe7\x9a\x84\xe6\x88\x90\xe6\x9c\xac\r\n            loss = tf.add(tf.add(sonloss, qujian), sub)\r\n\r\n            # \xe8\xae\xa1\xe7\xae\x97\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe6\x95\xb0\xe5\x80\xbc\r\n            predition_num = tf.reduce_sum(tf.multiply(tf.transpose(tf.subtract(Lagrange, Lagrange_Star)), pred_num), 0)\r\n\r\n        # \xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe8\xbf\x98\xe5\x8e\x9f\xe4\xb8\xba\xe5\x8e\x9f\xe5\xa7\x8b\xe7\x9a\x84\xe5\xb0\xba\xe5\xba\xa6\r\n        predition = self.reyuan(predition_num)\r\n        yydata = self.reyuan(y_target)\r\n\r\n        # \xe8\xae\xa1\xe7\xae\x97\xe8\xaf\xaf\xe5\xb7\xae\r\n        error = tf.reduce_sum(tf.square(predition - yydata))\r\n\r\n\r\n        # \xe8\xb0\x83\xe7\x94\xa8\xe4\xbc\x98\xe5\x8c\x96\xe5\x99\xa8\r\n        my_opt = tf.train.GradientDescentOptimizer(0.000005)  # \xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\r\n        train_step = my_opt.minimize(loss)\r\n\r\n        # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe5\x8f\x98\xe9\x87\x8f\r\n        init = tf.global_variables_initializer()\r\n        sess.run(init)\r\n\r\n        # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n        loss_vec = []  # \xe5\xad\x98\xe5\x82\xa8\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n\r\n        # \xe5\xad\x98\xe5\x82\xa8\xe8\xae\xad\xe7\xbb\x83\xe6\x97\xb6\xe5\x80\x99\xe7\x9a\x84\xe6\x9c\x80\xe5\xb0\x8f\xe4\xba\x8c\xe4\xb9\x98\xe6\xb3\x95\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n        erc_train = []\r\n        erc_pre = []\r\n\r\n        #  \xe5\xb1\x9e\xe6\x80\xa7\xe6\x95\xb0\xe6\x8d\xaeshape = (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c\xe5\x8d\x95\xe4\xb8\xaa\xe6\xa0\xb7\xe6\x9c\xac\xe7\x89\xb9\xe5\xbe\x81\xe6\x95\xb0)\r\n        #  \xe6\xa0\x87\xe7\xad\xbe\xe6\x95\xb0\xe6\x8d\xaeshape = (\xe6\xa0\xb7\xe6\x9c\xac\xe6\x95\xb0\xef\xbc\x8c1)\r\n        for i in range(self.maxtimes):\r\n            # \xe8\xae\xad\xe7\xbb\x83\r\n            sess.run(train_step, feed_dict={x_data: shuxing, y_target: biaoqian, prexdata: shuxing})  # \xe5\x85\xa8\xe9\x83\xa8\xe6\xa0\xb7\xe6\x9c\xac\xe4\xb8\x80\xe9\xbd\x90\xe8\xae\xad\xe7\xbb\x83\r\n\r\n            # \xe8\x8e\xb7\xe5\xbe\x97\xe8\xaf\xaf\xe5\xb7\xae\r\n            temp_loss = sess.run(loss, feed_dict={x_data: shuxing, y_target: biaoqian, prexdata: shuxing})\r\n            loss_vec.append(temp_loss)\r\n\r\n\r\n            # \xe8\xbe\x93\xe5\x87\xba\xe6\x9c\x80\xe5\xb0\x8f\xe4\xba\x8c\xe4\xb9\x98\xe6\xb3\x95\xe7\x9a\x84\xe8\xaf\xaf\xe5\xb7\xae\r\n            # \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n            trlas = sess.run(error, feed_dict={x_data: shuxing, y_target: biaoqian, prexdata: shuxing})\r\n            # \xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\r\n            prelas = sess.run(error, feed_dict={x_data: shuxing, y_target: ceshibq, prexdata: ceshisx})\r\n\r\n            erc_train.append(trlas)\r\n            erc_pre.append(prelas)\r\n\r\n\r\n            print(temp_loss)\r\n\r\n\r\n            chahzi, chaha, lii = sess.run([qujian_fu, qujian_c, cha])\r\n\r\n            print(\'\xe8\xb4\x9f\xe6\x95\xb0\xef\xbc\x9a%.4f\' % chahzi, \'\xe8\xb6\x85C\xef\xbc\x9a%.4f\' % chaha, \'\xe5\x92\x8c\xe5\x80\xbc\xef\xbc\x9a%.4f\' % lii)\r\n\r\n\r\n            if temp_loss < 1:\r\n                break\r\n\r\n\r\n\r\n\r\n        # \xe8\xbf\x94\xe5\x9b\x9e\xe7\xbd\x91\xe7\xbb\x9c\xe7\x9a\x84\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\r\n        nettr = sess.run(predition, feed_dict={x_data: shuxing, prexdata: shuxing})\r\n\r\n        netpre = sess.run(predition, feed_dict={x_data: shuxing, prexdata: ceshisx})\r\n\r\n\r\n        du = sess.run(Lagrange_Star)\r\n\r\n        fu = sess.run(Lagrange)\r\n\r\n        print(fu)\r\n\r\n        print(du)\r\n\r\n\r\n        # \xe8\xbf\x94\xe5\x9b\x9e\xe8\xae\xad\xe7\xbb\x83\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x8c\xe8\xae\xad\xe7\xbb\x83\xe4\xba\x8c\xe4\xb9\x98\xe8\xaf\xaf\xe5\xb7\xae\xef\xbc\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe4\xba\x8c\xe4\xb9\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n        return loss_vec, erc_train, erc_pre, nettr, netpre\r\n\r\n\r\n#  \xe6\x95\xb0\xe6\x8d\xae\r\ndef result(data, he):\r\n    #  \xe8\xae\xad\xe7\xbb\x83\xe6\x95\xb0\xe6\x8d\xae\r\n    xd = data[0]\r\n    yd = data[1]\r\n    #  \xe6\xb5\x8b\xe8\xaf\x95\xe6\x95\xb0\xe6\x8d\xae\r\n    texd = data[2]\r\n    teyd = data[3]\r\n\r\n    # \xe5\xbb\xba\xe7\xab\x8b\xe6\xa8\xa1\xe5\x9e\x8b\r\n    resu = SVM(kernel=he, manum=data[4][0], minum=data[4][1])\r\n    # \xe5\xbc\x80\xe5\xa7\x8b\xe8\xae\xad\xe7\xbb\x83\r\n    lo, eetr, eepr, nettrr, netpree = resu.train_svm(xd, yd, texd, teyd)\r\n\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe6\x88\x90\xe6\x9c\xac\xe5\x87\xbd\xe6\x95\xb0\xe6\x9b\xb2\xe7\xba\xbf\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe4\xba\x8c\xe4\xb9\x98\xe8\xaf\xaf\xe5\xb7\xae\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe4\xba\x8c\xe4\xb9\x98\xe8\xaf\xaf\xe5\xb7\xae\r\n    fig, host = plt.subplots()\r\n    # \xe7\x94\xa8\xe6\x9d\xa5\xe6\x8e\xa7\xe5\x88\xb6\xe5\xa4\x9ay\xe8\xbd\xb4\r\n    par1 = host.twinx()\r\n    #  \xe5\xa4\x9a\xe6\x9d\xa1\xe6\x9b\xb2\xe7\xba\xbf\r\n    p1, = host.plot(list(range(len(eetr))), eetr, ""b*"", marker=\'*\', linewidth=2, label=\'\xe8\xae\xad\xe7\xbb\x83\')\r\n\r\n    p2, = par1.plot(list(range(len(eepr))), eepr, ""r--"", marker=\'8\', linewidth=2, label=\'\xe9\xa2\x84\xe6\xb5\x8b\')\r\n\r\n    #  \xe6\xaf\x8f\xe4\xb8\xaa\xe8\xbd\xb4\xe7\x9a\x84\xe5\x86\x85\xe5\xae\xb9\r\n\r\n    host.set_ylabel(""\xe8\xaf\xaf\xe5\xb7\xae"")\r\n    par1.set_ylabel(""\xe8\xaf\xaf\xe5\xb7\xae"")\r\n    host.set_xlabel(\'\xe8\xae\xad\xe7\xbb\x83\xe7\x9a\x84\xe6\xac\xa1\xe6\x95\xb0\')\r\n\r\n\r\n    #  \xe6\x8e\xa7\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaay\xe8\xbd\xb4\xe5\x86\x85\xe5\xae\xb9\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\r\n    host.yaxis.label.set_color(p1.get_color())\r\n    par1.yaxis.label.set_color(p2.get_color())\r\n\r\n\r\n\r\n    #  \xe6\x8e\xa7\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaaY\xe8\xbd\xb4\xe5\x88\xbb\xe5\xba\xa6\xe6\x95\xb0\xe5\xad\x97\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\xe4\xbb\xa5\xe5\x8f\x8a\xe7\xba\xbf\xe7\xb2\x97\xe7\xbb\x86\r\n    tkw = dict(size=6, width=3)\r\n    host.tick_params(axis=\'y\', colors=p1.get_color(), **tkw)\r\n    par1.tick_params(axis=\'y\', colors=p2.get_color(), **tkw)\r\n\r\n\r\n    #  \xe6\xb7\xbb\xe5\x8a\xa0\xe5\x9b\xbe\xe4\xbe\x8b\r\n    lines = [p1, p2]\r\n    host.legend(lines, [l.get_label() for l in lines], loc=\'best\')\r\n\r\n    #  \xe6\xb7\xbb\xe5\x8a\xa0\xe6\xa0\x87\xe9\xa2\x98\r\n    plt.title(\'\xe5\x8c\x97\xe4\xba\xacPm2.5\xe5\x9b\x9e\xe5\xbd\x92 \xe6\x96\xb9\xe6\xb3\x95\xef\xbc\x9a%s\' % he)\r\n\r\n    #  \xe6\x8e\xa7\xe5\x88\xb6\xe6\xaf\x8f\xe4\xb8\xaaY\xe8\xbd\xb4\xe5\x88\xbb\xe5\xba\xa6\xe7\xba\xbf\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\r\n    ax = plt.gca()\r\n    ax.spines[\'left\'].set_color(\'blue\')\r\n    ax.spines[\'right\'].set_color(\'red\')\r\n\r\n    # \xe6\x98\xbe\xe7\xa4\xba\xe5\x9b\xbe\xe7\x89\x87\r\n    plt.show()\r\n\r\n    return nettrr, netpree\r\n\r\n# \xe7\xbb\x98\xe5\x9b\xbe\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\r\ndef huitu(suout, shiout, c=[\'b\', \'k\'], sign=\'\xe8\xae\xad\xe7\xbb\x83\', cudu=3):\r\n    print(suout)\r\n    print(shiout)\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe5\x8e\x9f\xe5\xa7\x8b\xe6\x95\xb0\xe6\x8d\xae\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\r\n    plt.subplot(2, 1, 1)\r\n    plt.plot(list(range(len(suout))), suout, c=c[0], linewidth=cudu, label=\'%s\xef\xbc\x9a\xe7\xae\x97\xe6\xb3\x95\' % sign)\r\n    plt.plot(list(range(len(shiout))), shiout, c=c[1], linewidth=cudu, label=\'%s\xef\xbc\x9a\xe5\xae\x9e\xe9\x99\x85\' % sign)\r\n    plt.legend()\r\n    plt.title(\'\xe7\x9c\x9f\xe5\xae\x9e\xe4\xb8\x8e\xe7\xae\x97\xe6\xb3\x95\xe8\xbe\x93\xe5\x87\xba\xe6\x95\xb0\xe6\x8d\xae\xe5\xaf\xb9\xe6\xaf\x94\')\r\n\r\n    # \xe7\xbb\x98\xe5\x88\xb6\xe8\xaf\xaf\xe5\xb7\xae\xe5\x92\x8c0\xe7\x9a\x84\xe5\xaf\xb9\xe6\xaf\x94\xe5\x9b\xbe\r\n    plt.subplot(2, 1, 2)\r\n    plt.plot(list(range(len(suout))), suout - shiout, c=\'r\', linewidth=cudu, label=\'%s\xef\xbc\x9a\xe7\xae\x97\xe6\xb3\x95-\xe5\xae\x9e\xe9\x99\x85\' % sign)\r\n    plt.plot(list(range(len(suout))), list(np.zeros(len(suout))), c=\'r\', linewidth=cudu, label=\'0\xe5\x80\xbc\')\r\n    plt.legend()\r\n    plt.title(\'\xe8\xaf\xaf\xe5\xb7\xae VS 0\')\r\n    # \xe9\x9c\x80\xe8\xa6\x81\xe6\xb7\xbb\xe5\x8a\xa0\xe4\xb8\x80\xe4\xb8\xaa\xe8\xaf\xaf\xe5\xb7\xae\xe7\x9a\x84\xe5\x88\x86\xe5\xb8\x83\xe5\x9b\xbe\r\n\r\n    # \xe6\x98\xbe\xe7\xa4\xba\r\n    plt.show()\r\n\r\n\r\n\'\'\'\xe7\xac\xac\xe5\x9b\x9b\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x9a\xe6\x9c\x80\xe7\xbb\x88\xe7\x9a\x84\xe8\xbf\x90\xe8\xa1\x8c\xe7\xa8\x8b\xe5\xba\x8f\'\'\'\r\nif __name__ == ""__main__"":\r\n    datasvr = rdata.model_data\r\n    outtri, poupre = result(datasvr, he=\'rbf\')\r\n\r\n    trii = datasvr[1][0] * (datasvr[4][0] - datasvr[4][1]) + datasvr[4][1]\r\n    huitu(trii, outtri, c=[\'b\', \'k\'], sign=\'\xe8\xae\xad\xe7\xbb\x83\', cudu=1.5)\r\n\r\n    prii = datasvr[3][0] * (datasvr[4][0] - datasvr[4][1]) + datasvr[4][1]\r\n    huitu(prii, poupre, c=[\'b\', \'k\'], sign=\'\xe9\xa2\x84\xe6\xb5\x8b\', cudu=1.5)\r\n'"
