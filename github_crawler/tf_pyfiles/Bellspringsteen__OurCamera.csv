file_path,api_count,code
analyzeimages.py,5,"b'r""""""Analyze Traffic Images\n\nThis executable is used to annotate traffic images to highlight vehicle types and to produce stats\nand graphs for the amount of time bicycle lanes and bus stops are blocked by vehicles:\n\n\nExample usage:\n    ./analyzeimages \\\n        -path_images ./data/rawimages/\n        -path_labels_map data/car_label_map.pbtxt\n        -save_directory data/processedimages/\n""""""\n\nimport sys\n\nfrom matplotlib.ticker import FormatStrFormatter, FuncFormatter\n\nsys.path.append(\'./models-master/research/\')\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils as vis_util\n\nimport argparse\nfrom argparse import RawTextHelpFormatter\nimport time\nimport numpy as np\nimport os\nimport tensorflow as tf\nimport csv\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom collections import defaultdict\nfrom io import StringIO\n# from matplotlib import pyplot as plt\nimport matplotlib.path as mpltPath\n\nfrom PIL import Image\nimport scipy.misc\n\n\ndef processimages(path_images_dir, path_labels_map,save_directory):\n    pathcpkt = \'data/output_inference_graph.pb/frozen_inference_graph.pb\'\n    csv_file = \'data/csvfile.csv\'\n    num_classes = 6\n\n    detection_graph = tf.Graph()\n\n    with detection_graph.as_default():\n        od_graph_def = tf.GraphDef()\n        with tf.gfile.GFile(pathcpkt, \'rb\') as fid:\n            serialized_graph = fid.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name=\'\')\n\n    label_map = label_map_util.load_labelmap(path_labels_map)\n    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=num_classes,\n                                                                use_display_name=True)\n    category_index = label_map_util.create_category_index(categories)\n\n    f = open(csv_file, \'w\')\n    #f.write(\n    #    \'timestamp,number cars in bike lane, number trucks in bike lane, \'\n    #    \'number cars in bus stop, number trucks in bus stop\\n\')\n\n    def load_image_into_numpy_array(imageconvert):\n        (im_width, im_height) = imageconvert.size\n        try:\n            return np.array(imageconvert.getdata()).reshape(\n                (im_height, im_width, 3)).astype(np.uint8)\n        except ValueError:\n            return np.array([])\n\n    with detection_graph.as_default():\n        with tf.Session(graph=detection_graph) as sess:\n            # Definite input and output Tensors for detection_graph\n            image_tensor = detection_graph.get_tensor_by_name(\'image_tensor:0\')\n            # Each box represents a part of the image where a particular object was detected.\n            detection_boxes = detection_graph.get_tensor_by_name(\'detection_boxes:0\')\n            # Each score represent how level of confidence for each of the objects.\n            # Score is shown on the result image, together with the class label.\n            detection_scores = detection_graph.get_tensor_by_name(\'detection_scores:0\')\n            detection_classes = detection_graph.get_tensor_by_name(\'detection_classes:0\')\n            num_detections = detection_graph.get_tensor_by_name(\'num_detections:0\')\n\n            polygon_right_lane = [(178, 122), (188, 240), (231, 240), (187, 125)]\n            polygon_left_lane = [(108, 143), (0, 215), (0, 233), (123, 142), (108, 97)]\n            polygon_bus_lane = [(200, 155), (230, 240), (292, 240), (225, 157)]\n\n            pathrightlane = mpltPath.Path(polygon_right_lane)\n            pathleftlane = mpltPath.Path(polygon_left_lane)\n            pathbuslane = mpltPath.Path(polygon_bus_lane)\n            for testpath in os.listdir(path_images_dir):\n\n                start_time = time.time()\n                timestamp = testpath.split("".jpg"")[0]\n\n                try:\n                    image = Image.open(path_images_dir + \'/\' + testpath)\n                    image_np = load_image_into_numpy_array(image)\n                except IOError:\n                    print(""Issue opening ""+testpath)\n                    continue\n\n                if image_np.size == 0:\n                    print(""Skipping image ""+testpath)\n                    continue\n                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n                image_np_expanded = np.expand_dims(image_np, axis=0)\n                # Actual detection.\n                (boxes, scores, classes, num) = sess.run(\n                    [detection_boxes, detection_scores, detection_classes, num_detections],\n                    feed_dict={image_tensor: image_np_expanded})\n\n                # Visualization of the results of a detection.\n                vis_util.visualize_boxes_and_labels_on_image_array(\n                    image_np,\n                    np.squeeze(boxes),\n                    np.squeeze(classes).astype(np.int32),\n                    np.squeeze(scores),\n                    category_index,\n                    min_score_thresh=0.4,\n                    use_normalized_coordinates=True,\n                    line_thickness=2)\n                scores = np.squeeze(scores)\n                boxes = np.squeeze(boxes)\n                num_cars_in_bikelane, num_cars_in_bus_stop, num_trucks_in_bike_lane, num_trucks_in_bus_stop = 0, 0, 0, 0\n                for i in range(boxes.shape[0]):\n                    if scores[i] > .4:\n                        box = tuple(boxes[i].tolist())\n\n                        ymin, xmin, ymax, xmax = box\n\n                        center_x = (((xmax * 352) - (xmin * 352)) / 2) + (xmin * 352)\n                        center_y = (((ymax * 240) - (ymin * 240)) / 2) + (ymin * 240)\n                        classes = np.squeeze(classes).astype(np.int32)\n                        if classes[i] in category_index.keys():\n                            class_name = category_index[classes[i]][\'name\']\n                        else:\n                            class_name = \'N/A\'\n\n                        if class_name == \'car\':\n                            points = [(center_x, center_y)]\n                            if pathrightlane.contains_points(points) or pathleftlane.contains_points(points):\n                                num_cars_in_bikelane += 1\n                            elif pathbuslane.contains_points(points):\n                                num_cars_in_bus_stop += 1\n\n                        elif class_name == \'truck\' or class_name == \'police\' or class_name == \'ups\':\n                            points = [(center_x, center_y)]\n                            if pathrightlane.contains_points(points) or pathleftlane.contains_points(points):\n                                num_trucks_in_bike_lane += 1\n                            elif pathbuslane.contains_points(points):\n                                num_trucks_in_bus_stop += 1\n\n                # write to a csv file whenever there is a vehicle, how many and of what type with timestamp\n                f.write(timestamp + \',\' + str(num_cars_in_bikelane) + \',\' + str(num_trucks_in_bike_lane) + \',\' + str(\n                    num_cars_in_bus_stop) + \',\' + str(num_trucks_in_bus_stop) + \'\\n\')\n                print(""Process Time "" + str(time.time() - start_time))\n                scipy.misc.imsave(save_directory + testpath, image_np)\n\n        f.close()\n        return csv_file\n\n\ndef initialize_datastore():\n    blankarray = [0] * 24\n    alldata = [[list(blankarray), list(blankarray), list(blankarray)],\n               [list(blankarray), list(blankarray), list(blankarray)]]\n    # alldata [ [cars_blocking_bikelane[24],trucks_blocking_bikelane[24],eitherblockingbikelane[24]\n    #           [cars_blocking_buslane[24],trucks_blocking_buslane[24],eitherblockingbuslane[24]]\n\n    weekdaydata = [[list(blankarray), list(blankarray), list(blankarray)],\n                   [list(blankarray), list(blankarray), list(blankarray)]]\n    # same as alldata above but for weekdays, weekenddata same but for weekends\n    weekenddata = [[list(blankarray), list(blankarray), list(blankarray)],\n                   [list(blankarray), list(blankarray), list(blankarray)]]\n\n    return [alldata, weekdaydata, weekenddata]\n\n\ndef weekday(datevalue):\n    if datevalue.weekday() < 5:\n        return True\n    else:\n        return False\n\n\ndef incrementarray(array, blockagearray, delta_time):\n    timestamp_string = (blockagearray[0].split("".jpg""))[0]\n    datetime_object = datetime.strptime(timestamp_string, \'%Y-%m-%d %H:%M:%S.%f\')\n\n    hour = datetime_object.hour\n    num_cars_in_bike_lane = int(blockagearray[1])\n    num_trucks_in_bike_lane = int(blockagearray[2])\n    num_cars_in_bus_stop = int(blockagearray[3])\n    num_truck_in_bus_stop = int(blockagearray[4])\n\n    if num_cars_in_bike_lane > 0:\n        array[0][0][hour] += delta_time\n    if num_trucks_in_bike_lane > 0:\n        array[0][1][hour] += delta_time\n    if num_cars_in_bike_lane > 0 or num_trucks_in_bike_lane > 0:\n        array[0][2][hour] += delta_time\n    if num_cars_in_bus_stop > 0:\n        array[1][0][hour] += delta_time\n    if num_truck_in_bus_stop > 0:\n        array[1][1][hour] += delta_time\n    if num_cars_in_bus_stop > 0 or num_truck_in_bus_stop > 0:\n        array[1][2][hour] += delta_time\n\n\ndef incrementarrays(dataarrays, blockagearray, delta_time):\n    alldata = dataarrays[0]\n    weekdaydata = dataarrays[1]\n    weekenddata = dataarrays[2]\n\n    datetime_object = datetime.strptime((blockagearray[0].split("".jpg""))[0], \'%Y-%m-%d %H:%M:%S.%f\')\n\n    incrementarray(alldata, blockagearray, delta_time)\n    if weekday(datetime_object):\n        incrementarray(weekdaydata, blockagearray, delta_time)\n    else:\n        incrementarray(weekenddata, blockagearray, delta_time)\n\n    return [alldata, weekdaydata, weekenddata]\n\n\ndef buildsaveplot(list_to_graph, title):\n    label = [\'\', \'\', \'\', \'\', \'\', \'6 am\', \'\',\n             \'\', \'\', \'\', \'\', \'12 noon\', \'\', \'\', \'\', \'\', \'\', \'6 Pm\', \'\',\n             \'\',\n             \'\', \'\', \'\', \'Midnight\']\n    index = np.arange(len(label))\n    plt.bar(index, list_to_graph)\n    plt.xticks(index, label, fontsize=10, rotation=30)\n    plt.title(title)\n    plt.plot()\n\n    plt.ylim([0, 100.0])\n    ax = plt.gca()\n    ax.yaxis.set_major_formatter(FormatStrFormatter(\'%.0f%%\'))\n    plt.savefig(""output/""+title.replace("" "", """") + "".png"", bbox_inches=\'tight\')\n    plt.close()\n\n\ndef analyzeresults(csv_file):\n    total_time_secs, total_time_bike_lane_blocked_secs, total_time_bus_stop_blocked_secs = 0, 0, 0\n\n    weekdaytotalseconds = [1] * 24  # where we are going to store how many seconds worth of images there are\n    weekendtotalseconds = [1] * 24  # for each hour this is necessary beecause we may be missing images\n\n    previous_timestamp = 0\n    dataarrays = initialize_datastore()\n\n    data = csv.reader(open(csv_file, \'r\'))\n    data = sorted(data, key=lambda rowparse: datetime.strptime((rowparse[0].split("".jpg""))[0], \'%Y-%m-%d %H:%M:%S.%f\'))\n\n    for row in data:\n        datetime_object = datetime.strptime((row[0].split("".jpg""))[0], \'%Y-%m-%d %H:%M:%S.%f\')\n        timestamp = float(datetime_object.strftime(\'%s\'))\n        hour = datetime_object.hour\n\n        if previous_timestamp != 0:\n            delta_time = timestamp - previous_timestamp\n            if delta_time > 30:\n                print(""DELTA TIME LARGE"")\n                delta_time = 30\n\n            total_time_secs += delta_time\n            if weekday(datetime_object):\n                weekdaytotalseconds[hour] += delta_time  # necessary because there may be time stamps missing in images\n            else:\n                weekendtotalseconds[hour] += delta_time\n\n            dataarrays = incrementarrays(dataarrays, row, delta_time)\n        previous_timestamp = timestamp\n\n    weekendpercentageblocked = [[0] * 24, [0] * 24]  # bike lane first array and bus lane second\n    weekdaypercentageblocked = [[0] * 24, [0] * 24]\n\n    for hour in range(0, 24):\n        total_time_bike_lane_blocked_secs += dataarrays[0][0][2][hour]\n        total_time_bus_stop_blocked_secs += dataarrays[0][1][2][hour]\n        weekdaypercentageblocked[0][hour] = 100 * (dataarrays[1][0][2][hour] / weekdaytotalseconds[hour])\n        weekendpercentageblocked[0][hour] = 100 * (dataarrays[2][0][2][hour] / weekendtotalseconds[hour])\n        weekdaypercentageblocked[1][hour] = 100 * (dataarrays[1][1][2][hour] / weekdaytotalseconds[hour])\n        weekendpercentageblocked[1][hour] = 100 * (dataarrays[2][1][2][hour] / weekendtotalseconds[hour])\n\n    total_time_seven2seven, blockedbikelaneseven2seven, blockedbuslaneseven2seven = 0, 0, 0\n    for x in range(7, 19):\n        total_time_seven2seven += weekdaytotalseconds[x]\n        blockedbikelaneseven2seven += dataarrays[1][0][2][x]\n        blockedbuslaneseven2seven += dataarrays[1][1][2][x]\n\n    print(""RESULTS \\n Total Time "" + str(total_time_secs) + "" blocked bike lane time "" + str(\n        total_time_bike_lane_blocked_secs) + ""blocked truck lane time"" + str(total_time_bus_stop_blocked_secs))\n    print(""Bike lane blocked "" + str(100 * (total_time_bike_lane_blocked_secs / total_time_secs)) + ""% of the time"")\n    print(""Bus lane blocked "" + str(100 * (total_time_bus_stop_blocked_secs / total_time_secs)) + ""% of the time"")\n    print(""Bike lane blocked "" + str(\n        100 * (blockedbikelaneseven2seven / total_time_seven2seven)) + ""% of the time durring weekday from 7 am to 7pm"")\n    print(""Bus lane blocked "" + str(\n        100 * (blockedbuslaneseven2seven / total_time_seven2seven)) + ""% of the time durring weekday from 7 am to 7pm"")\n\n    buildsaveplot(weekdaypercentageblocked[0], \'Weekday Bike Lane Percentage Blocked by Hour\')\n    buildsaveplot(weekdaypercentageblocked[1], \'Weekday Bus Stop Percentage Blocked by Hour\')\n    buildsaveplot(weekendpercentageblocked[0], \'Weekend Bike Lane Percentage Blocked by Hour\')\n    buildsaveplot(weekendpercentageblocked[1], \'Weekend Bus Stop Percentage Blocked by Hour\')\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser(\n        description=\'Analyze traffic images to determine rate of blocking bike\'\n                    \'and bus lanes\', formatter_class=RawTextHelpFormatter)\n    parser.add_argument(\'-path_images\', help=\'the folder with all the downloaded images in it\')\n    parser.add_argument(\'-path_labels_map\', help=\'the file with the integer to label map\')\n    parser.add_argument(\'-save_directory\', help=\'the directory you want to save the annotated images to\')\n    args = parser.parse_args()\n    #csv_file = processimages(args.path_images,args.path_labels_map,args.save_directory)\n    analyzeresults(\'data/analysis10days.csv\')\n    analyzeresults(csv_file)'"
generate_tfrecord.py,4,"b'r""""""Processing Image and Annotation Dataset\n\nThis executable is used to convert the image and label dataset to test and train TF Records:\n\nA folder should be specified which contains folders labeled images/ and labels/\nEach jpg image file should contain a corresponding label file with the same name but with .xml extension\nA ratio of test to training should be specified i.e. .70\n\nExample usage:\n    ./generate_tfrecord \\\n        --folder=path/to/data_dir \\\n        --train_ratio=.70\n\n""""""\n\n\nfrom __future__ import absolute_import\nfrom PIL import Image\n\nimport random\nimport argparse\nfrom argparse import RawTextHelpFormatter\nimport os\nimport io\nimport tensorflow as tf\nimport sys\nimport xml.etree.ElementTree as eT\nsys.path.append(\'./models-master/research/\')\nfrom object_detection.utils import dataset_util\n\n\ndef class_text_to_int(row_label):\n    if row_label == \'car\':\n        return 1\n    elif row_label == \'truck\':\n        return 2\n    elif row_label == \'bus\':\n        return 3\n    elif row_label == \'ups\':\n        return 4\n    elif row_label == \'pedestrian\':\n        return 5\n    elif row_label == \'bicycle\':\n        return 6\n    elif row_label == \'bicycke\':\n        return 6\n    elif row_label == \'police\':\n        return 7\n    else:\n        raise ValueError(\'Unknown label found in data, label is \'+row_label)\n\n\ndef create_tf_example_from_jpg_xml(jpg_file, xml_file):\n\n    with tf.gfile.GFile(jpg_file, \'rb\') as fid:\n        encoded_jpg = fid.read()\n    encoded_jpg_io = io.BytesIO(encoded_jpg)\n    image = Image.open(encoded_jpg_io)\n    width, height = image.size\n\n    image_format = b\'jpg\'\n    xmins = []\n    xmaxs = []\n    ymins = []\n    ymaxs = []\n    classes_text = []\n    classes = []\n\n    tree = eT.parse(xml_file)\n    root = tree.getroot()\n    for member in root.findall(\'object\'):\n        xmins.append(int(member[4][0].text) / width)\n        xmaxs.append(int(member[4][2].text) / width)\n        ymins.append(int(member[4][1].text) / height)\n        ymaxs.append(int(member[4][3].text) / height)\n        classes_text.append(member[0].text)\n        classes.append(class_text_to_int(member[0].text))\n\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n        \'image/height\': dataset_util.int64_feature(height),\n        \'image/width\': dataset_util.int64_feature(width),\n        \'image/filename\': dataset_util.bytes_feature(jpg_file),\n        \'image/source_id\': dataset_util.bytes_feature(jpg_file),\n        \'image/encoded\': dataset_util.bytes_feature(encoded_jpg),\n        \'image/format\': dataset_util.bytes_feature(image_format),\n        \'image/object/bbox/xmin\': dataset_util.float_list_feature(xmins),\n        \'image/object/bbox/xmax\': dataset_util.float_list_feature(xmaxs),\n        \'image/object/bbox/ymin\': dataset_util.float_list_feature(ymins),\n        \'image/object/bbox/ymax\': dataset_util.float_list_feature(ymaxs),\n        \'image/object/class/text\': dataset_util.bytes_list_feature(classes_text),\n        \'image/object/class/label\': dataset_util.int64_list_feature(classes),\n    }))\n    return tf_example\n\n\ndef main(_):\n    parser = argparse.ArgumentParser(\n        description=\'Process a folder of jpg and xml training files into test and train tf records \\n\'\n                    \' assumes that in folder there are two folders images and labels \\n\'\n                    \' images contains jpg images and labels contain xml\', formatter_class=RawTextHelpFormatter)\n    parser.add_argument(\'-folder\', help=\'an integer for the accumulator\')\n    parser.add_argument(\'-train_ratio\', type=float,\n                        help=\'a float between 0 - 1.0 that sets the ratio of files that should be training vs testing\')\n    args = parser.parse_args()\n    print(""Running on "" + args.folder + "" with ratio "" + str(args.train_ratio))\n\n    images_path = args.folder+\'images/\'\n    labels_path = args.folder+\'labels/\'\n\n    arr = os.listdir(images_path)\n\n    random.shuffle(arr)\n\n    numberofimages = len(arr)\n\n    start_value = 0\n    end_value = int(numberofimages*args.train_ratio)\n    for i in [\'test\', \'train\']:\n\n        writer = tf.python_io.TFRecordWriter(args.folder+i + \'.record\')\n        for x in range(start_value, end_value):\n            if arr[x].endswith("".jpg""):\n                filename = os.path.splitext(arr[x])[0]\n                tf_example = create_tf_example_from_jpg_xml(images_path+filename+\'.jpg\', labels_path+filename+\'.xml\')\n                writer.write(tf_example.SerializeToString())\n        start_value = end_value + 1\n        end_value = numberofimages\n        writer.close()\n\n\nif __name__ == \'__main__\':\n    tf.app.run()\n\n'"
saveimages.py,0,"b'r""""""Download images from NYC DOT\n\nThis executable is used to download DOT images from http://dotsignals.org/:\n\nBy inspecting http://dotsignals.org/ you can determine the URL of the camera you are interested in for example\nhttp://207.251.86.238/cctv476.jpg?math=0.29640904121642864\n\n* the url\'s seem to be static over months.\n* DOT does seem to turn the cameras occasionally i.e. move it to cover a different street\n\n\nExample usage:\n    ./download_dot_files \\\n        --url=http://207.251.86.238/cctv476.jpg?math=0.29640904121642864 \\\n        --save_directory=path/to/data_dir\n""""""\n\nimport urllib\nimport threading\nimport datetime\nimport argparse\nfrom argparse import RawTextHelpFormatter\n\n\ndef download_dot_files(args):\n    now = datetime.datetime.now()\n    try:\n        urllib.urlretrieve(args.url, args.save_directory+str(now)+"".jpg"")\n        print(""Saved file to ""+args.save_directory+str(now)+"".jpg"")\n    except IOError:\n        pass\n\n    t = threading.Timer(1.0, download_dot_files,[args]).start()\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser(\n        description=\'Download images every second from dotsignals.org\', formatter_class=RawTextHelpFormatter)\n    parser.add_argument(\'-url\', help=\'the url for the image you want to download\')\n    parser.add_argument(\'-save_directory\', help=\'the directory you want to save the images to\')\n    args = parser.parse_args()\n    download_dot_files(args)\n'"
