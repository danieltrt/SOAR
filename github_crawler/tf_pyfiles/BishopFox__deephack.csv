file_path,api_count,code
deephack.py,0,"b'#!/usr/bin/env python3\nimport dqnagent\nimport state\nimport numpy as np\nimport requests\nimport argparse\nimport json\nimport sys\nfrom collections import deque\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""--supervise"", help=""Perform supervised learning with argument as file"")\nparser.add_argument(""--batchsize"", help=""Training batch size"", default=32)\nparser.add_argument(""--epochs"", help=""num epochs"", default=10)\nparser.add_argument(""--tensorboard"", help=""enable tensorboard"", action=\'store_true\')\nparser.add_argument(""model"")\nargs = parser.parse_args()\n\nfilename = args.model\n\n#TODO: Hyperparameter.\n#This is the maxmimum length of our query string\ninput_len = 30\ncontext_len = 5\nmax_qstringlen = 140\n\nagent = dqnagent.Agent(input_len=input_len, context_len=context_len)\nagent.load(filename)\n\nif args.supervise != None:\n    types = args.supervise.split(\',\')\n    for rounds in range(500):\n        contents = []\n        [contents.extend(v(int(args.trainscale))) for k,v in supervising_types.items() if k in types]\n        if not contents:\n            print(""cannot supervise on types: {0}\\nvalid types are {1}"".format(\n                types, supervising_types.keys()))\n            sys.exit(1)\n        print(""-"" * 20)\n        print(""\\tRound "" + str(rounds))\n        agent.train_batch(contents, int(args.batchsize), int(args.epochs), args.tensorboard)\n        agent.save(filename)\n\n    print(""Finished supervising."")\n    agent.save(filename)\nelse:\n    table = state.State()\n    failed_attempts = {}\n    queries = set()\n    while True:\n        #Iterate through the state table and try to add on to each item in there (plus the empty string)\n        for context in table:\n            value = table.value()\n\n            qstring = """"\n            input_state = """"\n            experience = dqnagent.Experience()\n            #Predict a character until it produces an end-of-string character (|) or it reaches the max length\n            while not qstring.endswith(""|"") and len(qstring) < max_qstringlen:\n                #Shrink our query down to length input_len\n                input_state = qstring[-input_len:]\n                attempts = []\n                if (input_state, context) in failed_attempts:\n                    attempts = failed_attempts[input_state, context]\n                action = agent.act(input_state, context, attempts)\n                experience.add(input_state, context, attempts, action)\n                qstring += action\n\n            #Remove the trailing bar, it\'s not actually supposed to be sent\n            chopped = qstring\n            if qstring.endswith(""|""):\n                chopped = qstring[:-1]\n\n            # Is this a repeat or blank?\n            repeat = qstring in queries or (chopped.split(""%"")[0][-1:] == ""\'"")\n            queries.add(qstring)\n\n            success = False\n            if not repeat:\n                #Perform the action\n                param = {""user_id"": chopped}\n                req = requests.get(""http://127.0.0.1:5000/v0/sqli/select"", params=param)\n                success = req.status_code == 200 and (len(req.text) >2)\n\n            #If the query was successful, update the state table\n            if success:\n                print(""Got a hit!"", qstring)\n                lastchar = chopped.split(""%"")[0][-1:]\n                table.update(context+lastchar)\n                #Find out what reward we received\n                value_new = table.value()\n                reward = value_new - value\n\n            #Learn from how that action performed\n            # attempts = []\n            # if (input_state, context) in failed_attempts:\n            #     attempts = failed_attempts[input_state, context]\n            # agent.train_single(qstring[-1], context, input_state, attempts, reward)\n            #agent.train_experience(experience, success)\n\n            else:\n                # Add the character we just tried to the list of failures\n                #   So that we can use it as input in later attempts\n                lastchar = chopped.split(""%"")[0][-1:]\n                guess_state = chopped.split(""%"")[0][:-1][-input_len:]\n                print(""Incorrect: "", qstring)\n                if (guess_state, context) in failed_attempts:\n                    failures = failed_attempts[guess_state, context]\n                    if lastchar not in failures:\n                        failures.extend(lastchar)\n                        failed_attempts[guess_state, context] = failures\n                # Add this character to the list of failures\n                #   Unless this was just a repeat. In which case ignore it\n                elif not repeat:\n                    failed_attempts[guess_state, context] = [lastchar]\n'"
dqnagent.py,0,"b'import numpy as np\nimport random\nimport os\nimport json\nimport string\nfrom collections import deque\n\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import LSTM, Dense, Activation, Flatten, Concatenate, Input\nfrom keras.optimizers import Adam\nfrom keras.callbacks import TensorBoard\n\n""""""An \'experience\' consists of a grouping of the previous states and actions we took""""""\nclass Experience():\n    def __init__(self):\n        self.list = []\n\n    def add(self, qstring, context, attempts, action):\n        self.list.append({""qstring"":qstring, ""context"":context, ""attempts"":attempts, ""action"":action})\n\n""""""This defines the shape of the model we\'re building in a mostly declarative way""""""\nclass Agent():\n    #input_len: Length of the input\n    def __init__(self, input_len, context_len):\n\n        chars = list(string.ascii_lowercase + string.digits + ""=.;_ \'()|%"")\n        print(""Valid character set: "", chars)\n\n        self.char_depth = len(chars)\n\n        self.char_indices = dict((c, i) for i, c in enumerate(chars))\n        self.indices_char = dict((i, c) for i, c in enumerate(chars))\n\n        # Build the model\n        context_input = Input(shape=(context_len, self.char_depth), name=\'context_input\')\n        context_layer_1 = LSTM(32, name=\'context_layer_1\')(context_input)\n        context_layer_3 = Dense(128, name=\'context_layer_3\')(context_layer_1)\n\n        qstring_input = Input(shape=(input_len, self.char_depth), name=\'qstring_input\')\n        qstring_layer_1 = LSTM(128, name=\'qstring_layer_1\')(qstring_input)\n        qstring_layer_3 = Dense(128, name=\'qstring_layer_3\')(qstring_layer_1)\n\n        attempts_input = Input(shape=(self.char_depth,), name=\'attempts_input\')\n        attempts_layer_1 = Dense(128, name=\'attempts_layer_1\')(attempts_input)\n\n        x = keras.layers.concatenate([context_layer_3, qstring_layer_3])\n        x = Dense(64, name=\'hidden_layer_1\')(x)\n        x = keras.layers.concatenate([x, attempts_layer_1])\n\n        # We stack a deep densely-connected network on top\n        main_output = Dense(self.char_depth, activation=\'softmax\', name=""output_layer"")(x)\n        self.model = Model(inputs=[context_input, qstring_input, attempts_input], outputs=[main_output])\n        print(self.model.summary())\n\n        #""Compile"" the model\n        #XXX: Hyperparameters here. May need tinkering.\n        self.supervised_reward = 1\n        self.content = None\n        self.model.compile(loss=\'categorical_crossentropy\', optimizer=\'adam\', metrics=[\'accuracy\'])\n        self.temperature = .2\n        # We want a pretty steep dropoff here\n        self.epsilon = .65\n        self.input_len = input_len\n        self.context_len = context_len\n\n    #Given the current state, choose an action an return it\n    #Stochastic! (ie: we choose an action at random, using each state as a probability)\n    def act(self, qstring, context, attempts):\n        qstring = self.onehot(qstring, self.input_len)\n        context = self.onehot(context, self.context_len)\n        attempts = self.encodeattempts(attempts)\n        #[context_layer, qstring_layer, attempts_layer]\n        predictions = self.model.predict_on_batch([context, qstring, attempts])\n        action = self.sample(predictions[0], self.temperature)\n        #print(predictions, action, self.indices_char[action])\n        return self.indices_char[action]\n\n    #Given a stochastic prediction, generate a concrete sample from it\n    #temperature: How much we should ""smear"" the probability distribution. 0 means not at all, high numbers is more.\n    def sample(self, preds, temperature=1.0):\n        # helper function to sample an index from a probability array\n        with np.errstate(divide=\'ignore\'):\n            preds = np.asarray(preds).astype(\'float64\')\n            preds = np.log(preds) / temperature\n            exp_preds = np.exp(preds)\n            preds = exp_preds / np.sum(exp_preds)\n            probas = np.random.multinomial(1, preds, 1)\n            return np.argmax(probas)\n\n    #Update the model for a single given experience\n    def train_single(self, action, context, prev_state, attempts, reward):\n        #make a one-hot array of our output choices, with the ""hot"" option\n        #   equal to our discounted reward\n        action = self.char_indices[action]\n        prev_state = self.onehot(prev_state, self.input_len)\n        reward_array = np.zeros((1, self.char_depth))\n        reward_array[0, action] = reward\n        attempts = self.encodeattempts(attempts)\n        context = self.onehot(context, self.context_len)\n        #[context_layer, qstring_layer, attempts_layer]\n        self.model.train_on_batch([context, prev_state, attempts], reward_array)\n\n    # Batch the training\n    def train_batch(self, contents, batch_size, epochs, tensorboard=False):\n        self.content = contents\n\n        qstrings = np.zeros((len(self.content), self.input_len, self.char_depth))\n        contexts = np.zeros((len(self.content), self.context_len, self.char_depth))\n        attempts = np.zeros((len(self.content), self.char_depth))\n        rewards = np.zeros((len(self.content), self.char_depth))\n\n        for i in range(len(self.content)):\n            entry = random.choice(self.content)\n\n            qstrings[i] = self.onehot(entry[""qstring""], self.input_len)\n            contexts[i] = self.onehot(entry[""context""], self.context_len)\n            attempts[i] = self.encodeattempts(entry[""attempts""])\n            reward = self.supervised_reward\n            if not entry[""success""]:\n                reward *= -0.1\n            action = self.char_indices[entry[""action""]]\n            reward_array = np.zeros(self.char_depth)\n            reward_array[action] = reward\n            rewards[i] = reward_array\n        callbacks = []\n        if tensorboard:\n            callbacks.append(TensorBoard(log_dir=\'./TensorBoard\', histogram_freq=1, write_graph=True))\n        self.model.fit([contexts, qstrings, attempts], rewards, callbacks=callbacks,\n                        epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.2)\n\n    # Given a full experience, go back and reward it appropriately\n    def train_experience(self, experience, success):\n        experience.list.reverse()\n        reward = self.supervised_reward\n        if not success:\n            reward *= -0.1\n        i = 0\n        for item in experience.list:\n            i += 1\n            if i > 4:\n                if item[""action""] == ""\'"":\n                    return\n                reward *= self.epsilon\n                self.train_single(item[""action""], item[""context""], item[""qstring""], item[""attempts""], reward)\n\n    #Encode a given string into a 2d array of one-hot encoded numpy arrays\n    def onehot(self, string, length):\n        assert len(string) <= length\n        #First, pad the string out to be \'input_len\' long\n        string = string.ljust(length, ""|"")\n\n        output = np.zeros((1, length, self.char_depth), dtype=np.bool)\n        for index, item in enumerate(string):\n            output[0, index, self.char_indices[item]] = 1\n        return output\n\n    def encodeattempts(self, attempts):\n        output = np.zeros((1, self.char_depth))\n        for i, item in enumerate(attempts):\n            output[0, i] = 1\n        return output\n\n    def save(self, path):\n        self.model.save_weights(path)\n        print(""Saved model to disk"")\n\n    def load(self, path):\n        if os.path.isfile(path):\n            self.model.load_weights(path)\n            print(""Loaded model from disk"")\n        else:\n            print(""No model on disk, starting fresh"")\n'"
setup.py,0,"b""#!/usr/bin/env python3\n\nfrom setuptools import setup, find_packages\n\nsetup(\n    name='deephack',\n    version='1.0.0',\n    packages=find_packages(),\n    zip_safe=False,\n    include_package_data=True,\n    install_requires=[\n        'uwsgi',\n        'coverage',\n        'Flask',\n        'psycopg2',\n        'sqlalchemy',\n        'scipy',\n        'numpy',\n        'keras',\n        'ipython',\n        'faker',\n    ],\n    classifiers=[\n        'Private :: Do Not Upload'\n    ],\n    entry_points={\n        'console_scripts': [\n            'vulnserver = vulnserver.cli.vulnserver:main',\n        ]\n    }\n)\n"""
state.py,0,"b'\n""""""The state of a given episode is what DeepHack has learned about the database.""""""\nclass State():\n    def __init__(self):\n        self.statetable = [""""]\n        self.current = 0\n\n    def __str__(self):\n        out = """"\n        for entry in self.statetable:\n            out += entry + ""\\n""\n        return out\n\n    def __iter__(self):\n        self.current = 0\n        return self\n\n    def __next__(self):\n        try:\n            result = self.statetable[self.current]\n            self.current += 1\n        except IndexError:\n            raise StopIteration\n        return result\n\n    def update(self, query):\n        query = query.split(""%"")[0]\n        for i, entry in enumerate(self.statetable):\n            if query.startswith(entry):\n                self.statetable[i] = query\n                return\n            if entry.startswith(query):\n                return\n        self.statetable.append(query)\n\n    """"""Counts up the total length of the state table and calls that the state\'s value""""""\n    def value(self):\n        value = 0\n        for entry in self.statetable:\n            value += len(entry)\n        return value\n'"
scripts/qt.py,0,"b'#!/usr/bin/env python3\nclass AnsiColors:\n    off = ""\\x1b[0m""             # text reset\n\n    # regular colors\n    black = ""\\x1b[0;30m""        # black\n    red = ""\\x1b[0;31m""          # red\n    green = ""\\x1b[0;32m""        # green\n    yellow = ""\\x1b[0;33m""       # yellow\n    blue = ""\\x1b[0;34m""         # blue\n    purple = ""\\x1b[0;35m""       # purple\n    cyan = ""\\x1b[0;36m""         # cyan\n    white = ""\\x1b[0;37m""        # white\n\n    # bold\n    bblack = ""\\x1b[1;30m""       # black\n    bred = ""\\x1b[1;31m""         # red\n    bgreen = ""\\x1b[1;32m""       # green\n    byellow = ""\\x1b[1;33m""      # yellow\n    bblue = ""\\x1b[1;34m""        # blue\n    bpurple = ""\\x1b[1;35m""      # purple\n    bcyan = ""\\x1b[1;36m""        # cyan\n    bwhite = ""\\x1b[1;37m""       # white\n\n    # underline\n    ublack = ""\\x1b[4;30m""       # black\n    ured = ""\\x1b[4;31m""         # red\n    ugreen = ""\\x1b[4;32m""       # green\n    uyellow = ""\\x1b[4;33m""      # yellow\n    ublue = ""\\x1b[4;34m""        # blue\n    upurple = ""\\x1b[4;35m""      # purple\n    ucyan = ""\\x1b[4;36m""        # cyan\n    uwhite = ""\\x1b[4;37m""       # white\n\n    # background\n    on_black = ""\\x1b[40m""       # black\n    on_red = ""\\x1b[41m""         # red\n    on_green = ""\\x1b[42m""       # green\n    on_yellow = ""\\x1b[43m""      # yellow\n    on_blue = ""\\x1b[44m""        # blue\n    on_purple = ""\\x1b[45m""      # purple\n    on_cyan = ""\\x1b[46m""        # cyan\n    on_white = ""\\x1b[47m""       # white\n\n    # high intensty\n    iblack = ""\\x1b[0;90m""       # black\n    ired = ""\\x1b[0;91m""         # red\n    igreen = ""\\x1b[0;92m""       # green\n    iyellow = ""\\x1b[0;93m""      # yellow\n    iblue = ""\\x1b[0;94m""        # blue\n    ipurple = ""\\x1b[0;95m""      # purple\n    icyan = ""\\x1b[0;96m""        # cyan\n    iwhite = ""\\x1b[0;97m""       # white\n\n    # bold high intensty\n    biblack = ""\\x1b[1;90m""      # black\n    bired = ""\\x1b[1;91m""        # red\n    bigreen = ""\\x1b[1;92m""      # green\n    biyellow = ""\\x1b[1;93m""     # yellow\n    biblue = ""\\x1b[1;94m""       # blue\n    bipurple = ""\\x1b[1;95m""     # purple\n    bicyan = ""\\x1b[1;96m""       # cyan\n    biwhite = ""\\x1b[1;97m""      # white\n\n    # high intensty backgrounds\n    on_iblack = ""\\x1b[0;100m""   # black\n    on_ired = ""\\x1b[0;101m""     # red\n    on_igreen = ""\\x1b[0;102m""   # green\n    on_iyellow = ""\\x1b[0;103m""  # yellow\n    on_iblue = ""\\x1b[0;104m""    # blue\n    on_ipurple = ""\\x1b[10;95m""  # purple\n    on_icyan = ""\\x1b[0;106m""    # cyan\n    on_iwhite = ""\\x1b[0;107m"" # white\n\ndef main():\n    return\n\ndef __name__ == \'__main__\':\n    main()\n'"
tests/__init__.py,0,b''
tests/test_cli.py,0,b'from vulnserver.cli.vulnserver import main\n\ndef test_func():\n    assert True\n'
tests/test_lib.py,0,b'import vulnserver.lib\nimport vulnserver.lib.models\nfrom vulnserver.lib.models import SchemaGen\n\ndef test_func():\n    s = SchemaGen()\n    s.gen()\n    s.populate()\n    assert True\n'
vulnserver/__init__.py,0,b''
vulnserver/cli/__init__.py,0,b''
vulnserver/cli/vulnserver.py,0,"b'\'\'\' a skeleton cli program to begin development with \'\'\'\nimport os\n\nfrom vulnserver.lib.vroutes import app\n\ndef main():\n    \'\'\' entry point for console_scripts, and cli binary \'\'\'\n    app.run(host=\'0.0.0.0\')\n    # webscale database reloading\n    os.system(\'\'\'psql -d deephack -U deephack -c ""drop owned by deephack""\'\'\')\n    return 0\n\nif __name__ == \'__main__\':\n    main()\n'"
vulnserver/lib/__init__.py,0,b'\n'
vulnserver/lib/models.py,0,"b'import string\nimport random\nimport sys\nimport os\nfrom IPython.core import ultratb\nif bool(os.environ.get(\'VULNSERVER_DEBUG\')) == True:\n    sys.excepthook = ultratb.FormattedTB(mode=\'Verbose\',\n         color_scheme=\'Linux\', call_pdb=1)\n\nfrom faker import Faker\n\nfrom sqlalchemy import *\nfrom sqlalchemy import Column, Integer, String, Date,Table, Column, Integer, ForeignKey\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship\n\n#hack please ignore\ndb_type = os.environ.get(\'VULNSERVER_DB_TYPE\', \'\')\nengine = None\nif db_type.lower() == \'postgres\':\n    print(""starting postgres server"")\n    engine = create_engine(\'postgresql+psycopg2://deephack:deephack@/deephack?host=/var/run/postgresql/\')\nelse:\n    engine = create_engine(\'sqlite:///:memory:\')\nBase = declarative_base()\nFake = Faker()\n\n\'\'\'\nTODO\n    - set column names to mined column names\n    - set table names to mined table names\n\n    - scraping ideas\n        - search github.com for all .sql files\n            - parse them for create table statements\n            - use those to populate table names\n\'\'\'\n\n\'\'\'\n    patterns - column names\n    {keyword}_{randint}\n    {keyword}_id\n    {product_prefix}_{keyword}\n    {small_az_code}_{keyword}\n    {product_prefix}_{keyword}_{randint}\n    {small_az_code}_{keyword}_{randint}\n    {product_prefix}_{keyword}{randint}\n    {small_az_code}_{keyword}{randint}\n    {keyword}\n    {keyword}_{keyword}\n    {keyword}_{keyword}_{keyword}\n    {keyword}_{keyword}_{keyword}_{keyword}\n\n    table names\n    {keyword}\n    {product_prefix}_keyword\n    {product_prefix}Keyword\n    {keyword}{int}\n    {product_prefix}_keyword{int}\n    {product_prefix}Keyword{int}\n    {keyword}_{int}\n    {product_prefix}_keyword_{int}\n    {product_prefix}Keyword_{int}\n\'\'\'\n\nclass NamePatterns:\n    \'\'\'Class for generating random realistic name patterns\'\'\'\n    # TODO: finish name pattern functions\n    def __init__(self):\n        self.name_patterns = {\n            ""keyword_randint"": self.keyword_randint,\n            #""keyword_id"": self.keyword_id,\n            ""product_keyword"": self.product_keyword,\n            #""small_code_keyword"": self.small_code_keyword,\n            #""product_prefix_keyword_randint"": self.product_prefix_keyword_randint,\n            #""small_code_keyword_randint"": self.small_code_keyword_randint,\n            #""product_keywordrandint"": self.product_keywordrandint,\n            #""small_code_keywordrandint"": self.small_code_keywordrandint,\n            ""keyword"": self.keyword,\n            ""keyword_skeyword"": self.keyword_skeyword,\n            ""keyword_skeyword_skeyword"": self.keyword_skeyword_skeyword,\n            ""keyword_skeyword_skeyword_skeyword"": self.keyword_skeyword_skeyword_skeyword,\n        }\n\n        self.product_code = """".join([random.choice(string.ascii_letters) for i in range(\n            0, random.randint(1,5))])\n        self.table_secondary_keywords = self.get_table_secondary_keywords()\n\n    def _get_secondary_keyword(self):\n        return \'test_secondary\'\n\n    def _get_product(self):\n        return \'test_product\'\n\n    def _get_small_code(self):\n        return \'test_product\'\n\n    def _get_randint(self):\n        return random.choice([\'00\', \'01\', \'02\', \'03\',\'0\', \'1\', \'2\', \'3\'])\n\n    def _camelcase(self, argv):\n        \'\'\'camel cases the first letter of each word in keywords list\'\'\'\n        camel_cased=[]\n        for i in argv:\n            first_letter = i[:1].upper()\n            camel_cased.append(first_letter+i[1:])\n        return """".join(camel_cased)\n\n    def _underscores(self, argv):\n        \'\'\'adds unscores to keywords\'\'\'\n        return ""_"".join([""{""+str(i)+""}"" for i in range(len(argv))]).format(*argv)\n\n    def _nospaces(self, argv):\n        \'\'\'adds unscores to keywords\'\'\'\n        return """".join([""{""+str(i)+""}"" for i in range(len(argv))]).format(*argv)\n\n    def _random_fmt(self, argv):\n        \'\'\' return a format string with a specified number of args,\n        either camel case, underscores, or nospaces\'\'\'\n        selector = random.choice([\'camelcase\',\'underscores\',\'nospaces\'])\n        selectors = {\n            \'underscores\': self._underscores,\n            \'nospaces\': self._nospaces,\n            #\'camelcase\': self._camelcase,\n        }\n        return selectors.get(selector, self._underscores)(argv)\n\n    def original_column_name(self, column_name):\n        return column_name\n\n    def keyword_randint(self, column_name):\n        randint = self._get_randint()\n        return self._random_fmt([column_name, randint])\n\n    def keyword_id(self, column_name):\n        pass\n\n    def product_keyword(self, column_name):\n        return self._random_fmt([self.product_code, column_name])\n\n    def small_code_keyword(self, column_name):\n        pass\n\n    def product_keyword_randint(self, column_name):\n        pass\n\n    def small_code_keyword_randint(self, column_name):\n        pass\n\n    def product_keywordrandint(self, column_name):\n        pass\n\n    def small_code_keywordrandint(self, column_name):\n        pass\n\n    def keyword(self, column_name):\n        return column_name\n\n    def keyword_skeyword(self, column_name):\n        return self._random_fmt([column_name,\n            random.choice(self.table_secondary_keywords)])\n\n    def keyword_skeyword_skeyword(self, column_name):\n        return self._random_fmt([column_name,\n            random.choice(self.table_secondary_keywords),\n            random.choice(self.table_secondary_keywords),\n            ])\n\n    def keyword_skeyword_skeyword_skeyword(self, column_name):\n        return self._random_fmt([column_name,\n            random.choice(self.table_secondary_keywords),\n            random.choice(self.table_secondary_keywords),\n            random.choice(self.table_secondary_keywords),\n            ])\n\n    def get_table_secondary_keywords(self):\n        cur_path = os.path.dirname(os.path.abspath(__file__))\n        keyword_path = os.path.join(cur_path, \'keywords\')\n        if not os.path.is_file(keyword_path):\n            sys.exit(""need text file with keywords to generate table and column names"")\n        with open(keyword_path) as f:\n             return [i.strip() for i in f.readlines()]\n\n    def get_name(self, name_opts):\n        \'\'\'generate a random name pattern from list name_opts\'\'\'\n        # choose item from provided list\n        name_opt = random.choice(name_opts)\n        # choose a random pattern func\n        pattern_choice = self.name_patterns[\n                random.choice(list(\n                    self.name_patterns.keys()))]\n        # populate the pattern and return\n        return pattern_choice(name_opt).lower()\n\nclass User:\n    \'\'\'Generate a user table\'\'\'\n    def get_tables(self, num_tables=1):\n        tables = {}\n        for i in range(num_tables):\n            table_name = self.get_table_keyword()\n            # loop until we generate a unique tablename\n            while table_name.lower() in [x.lower() for x in tables.keys()]:\n                table_name = self.get_table_keyword()\n            #print(""creating table name: %s"" % table_name)\n            columns = self.create_table(table_name)\n            #print(""columns %s"" % columns)\n            tables[table_name] = columns\n        print(""creating table %s"" % tables)\n        return tables\n\n    def get_table_keyword(self):\n        np = NamePatterns()\n        return np.get_name([\n            \'users\',\'usrs\',\'user\', \'usr\',\n            \'groups\',\'grps\',\'group\', \'grp\',\n            \'customers\',\'customer\',\'cstmr\', \'cst\',\n            \'product\',\'product\',\'inventory\', \'invt\',\n            \'admin\',\'administrator\',\'manage\', \'superuser\',\n            \'account\',\'acct\',\'archive\', \'message\', \'msg\',\n            \'vote\',\'core\',\'article\', \'post\',\n            ])\n\n    def _get_sqlalchemy_type(self, cname, primary_key=False, relationship=None):\n        \'\'\' returns a random sqlalchemy type, return str for now \'\'\'\n        if primary_key:\n            return Column(cname, Integer, primary_key=True, autoincrement=True)\n        else:\n            return Column(cname, String)\n\n    def create_table(self, table_name, num_columns=5):\n\n        faker_types = {\n            Fake.user_name: [\'user\', \'usr\',\n                \'uname\', \'usrnme\',\'username\', \'user_name\'],\n            Fake.email: [\'email\', \'emailaddr\', \'email_addr\', \'emailaddress\',\'mailaddr\',\'contactemail\',\'contact_email\'],\n            Fake.company_email: [\'email\', \'emailaddr\', \'email_addr\', \'emailaddress\',\'mailaddr\',\'contactemail\',\'contact_email\'],\n            Fake.password: [\'password\', \'passwd\', \'pword\', \'pw\',\'password_hash\', \'passwd_hash\', \'pword_hash\', \'pw_hash\'],\n            Fake.address: [\'addr\', \'address\', \'location\', \'mailing_addr\', \'mail_addr\', \'mailing_address\'],\n            Fake.phone_number: [\'phone_number\', \'pnumber\', \'phonenum\', \'phone\', \'cell\', \'cellphone\', \'contact_number\', \'contact_num\'],\n            Fake.company: [\'company\', \'business\'],\n            Fake.credit_card_full: [\'cc_details\', \'card_data\', \'creditcard\', \'credit_card\', \'cc\'],\n            #Fake.credit_card_provider,\n            Fake.md5: [\'password\', \'passwd\', \'pword\', \'pw\',\'password_hash\', \'passwd_hash\', \'pword_hash\', \'pw_hash\'],\n            Fake.sha1: [\'password\', \'passwd\', \'pword\', \'pw\',\'password_hash\', \'passwd_hash\', \'pword_hash\', \'pw_hash\'],\n            Fake.sha256: [\'password\', \'passwd\', \'pword\', \'pw\',\'password_hash\', \'passwd_hash\', \'pword_hash\', \'pw_hash\'],\n            Fake.bs: [\'information\', \'info\', \'story\', \'content\', \'post\', \'blogtext\', \'text\'],\n            #Fake.boolean,\n            #Fake.chrome,\n            #Fake.paragraph,\n            #Fake.ipv4,\n            #Fake.uuid4,\n        }\n\n        columns = {}\n        col_patterns = NamePatterns()\n\n        # get column names\n        for i in range(0, num_columns):\n            # get a random Faker data type\n            faker_type = random.choice(list(faker_types.keys()))\n            # get a random column_name\n            column_name = col_patterns.get_name(faker_types[faker_type])\n            # get a random sqlalchemy type\n            sqla_type = self._get_sqlalchemy_type(column_name)\n            # add a hook for the random_data function so we know\n            # what kind of random data to generate\n            sqla_type.faker_type = faker_type\n            columns[column_name] = sqla_type\n\n        # add primary key\n        columns[table_name + \'_id\'] = self._get_sqlalchemy_type(\n                table_name + \'_id\', primary_key=True)\n        return columns\n\nclass SchemaGen():\n    def __init__(self):\n        self.db_identifiers = string.ascii_letters# + \'-_@#\'\n        self.db_value_fuzz = 5893\n        self.db_value_max = 100000 + random.randrange(0, self.db_value_fuzz)\n        self.table_max = self.db_value_max * .03\n        self.table_fuzz = 500\n        self.table_name_max = 75\n        self.column_max = self.db_value_max * .07\n        self.column_fuzz = 500\n        self.column_name_max = 75\n        self.columns_per_table_max = 75\n        self.columns_per_table_min = 2\n\n    def get_identifier_names(self, imax, ifuzz, iname_max):\n        names = []\n        # get a random value for the identifier range\n        irange = imax + random.randrange(0, ifuzz)\n        while irange > 0:\n            name = \'\'\n            for i in range(random.randrange(3, iname_max)):\n                name = name + self.db_identifiers[random.randint(0,len(self.db_identifiers))-1]\n                irange = irange - 1\n            names.append(\'\'+name+\'\')\n        return names\n\n    def gen_tdict(self):\n        \'\'\'\n        create the table dict with all columns and define\n        python classes for each table. each class inherits from\n        sqlalchemy Base and can be instantiated with sqlalchemy\n        [tnames]\n        [cnames]\n        tables = {""table_name"": {column_name:random_type,\n                                    column_name:random_type,\n                                    column_name:random_type,\n                                    column_name:random_relationship}}\n        \'\'\'\n        tnames = self.get_identifier_names(\n                    self.table_max,\n                    self.table_fuzz,\n                    self.table_name_max)\n        cnames = self.get_identifier_names(\n                    self.column_max,\n                    self.column_fuzz,\n                    self.column_name_max)\n        tdict = {}\n        while len(tnames) > 0 and len(cnames) >= self.columns_per_table_min:\n            columns = {}\n            tname = tnames.pop()\n            self.db_value_max = self.db_value_max - len(tname)\n            for i in range(random.randrange(\n                    self.columns_per_table_min,\n                    self.columns_per_table_max)):\n                if len(cnames) > 0:\n                    cname = cnames.pop()\n                    columns[cname] = self._get_sqlalchemy_type(cname) if i > 0 else self._get_sqlalchemy_type(cname, primary_key=True)\n                    # choose random faker_type for column\n                    self.db_value_max = self.db_value_max - len(cname)\n            tdict[tname] = columns\n        self.tdict = tdict\n        return self.tdict\n\n    def gen(self):\n        self.gen_tdict()\n        for k,v in self.tdict.items():\n            v[\'__tablename__\'] = k\n            type(k, (Base, ), v)\n\n    def _get_sqlalchemy_type(self, cname, primary_key=False, relationship=None):\n        \'\'\' returns a random sqlalchemy type, return str for now \'\'\'\n        if primary_key:\n            return Column(cname, Integer, primary_key=True, autoincrement=True)\n        else:\n            return Column(cname, String)\n\n    def _create_database(self):\n        db_name = \'deephack\'\n        conn = engine.connect()\n        Base.metadata.create_all(engine)\n        metadata = Base.metadata\n\n        while self.db_value_max > 0:\n            tables = [i for i in metadata.tables]\n            cur_table = tables[random.randrange(0,\n                len(tables)-1)]\n            cur_table = metadata.tables[cur_table]\n            # add 50 rows\n            rows = []\n            for i in range(3):\n                row_dict = {}\n                for column in cur_table.columns:\n                    if not column.primary_key:\n                        row_dict[str(column.name)] = self.random_data()\n                rows.append(row_dict)\n            conn.execute(cur_table.insert(), rows)\n            self.db_value_max = self.db_value_max - 500\n        conn.close()\n\n    def populate(self):\n        \'\'\' populate the database \'\'\'\n        self._create_database()\n\n    def select_table(self):\n        \'\'\'returns the table to use for selects for this episode,\n        only call this once per episode\'\'\'\n        tables = [i for i in Base.metadata.tables]\n        self.cur_table = Base.metadata.tables[random.choice(tables)]\n        self.pk = [i for i in self.cur_table.primary_key.columns][0]\n        return (self.cur_table, self.pk)\n\n    def random_data(self):\n        rc = []\n        for x in range(random.randrange(0,200)):\n            rc.append(string.printable[random.randrange(len(string.printable)-1)])\n        return """".join(rc)\n\n    def get_engine(self):\n        return engine\n\n\nclass FakerSchema(SchemaGen):\n    \'\'\'uses faker to generate a table of all fake data\'\'\'\n\n    def gen_tdict(self):\n        user = User()\n        self.tdict = user.get_tables()\n\n    def _create_database(self):\n        db_name = \'deephack\'\n        conn = engine.connect()\n        Base.metadata.create_all(engine)\n        self.metadata = Base.metadata\n\n        while self.db_value_max > 0:\n            tables = [i for i in self.metadata.tables]\n            cur_table = random.choice(tables)\n            cur_table = self.metadata.tables[cur_table]\n            # add 50 rows\n            rows = []\n            for i in range(3):\n                row_dict = {}\n                for column in cur_table.columns:\n                    # add faker_type to column if not exists\n                    if not column.primary_key:\n                        row_dict[str(column.name)] = self.random_data(column.faker_type)\n                rows.append(row_dict)\n            conn.execute(cur_table.insert(), rows)\n            self.db_value_max = self.db_value_max - 500\n        conn.close()\n\n    def random_data(self, faker_func):\n        \'\'\' create some random data based on the faker\n        type and return it\'\'\'\n        if faker_func == Fake.user_name:\n            return faker_func()\n        else:\n            return faker_func()\n'"
vulnserver/lib/vroutes.py,0,"b'import random\nimport os\n\nfrom flask import Flask, request\nimport psycopg2\nfrom sqlalchemy import create_engine, exc\nfrom sqlalchemy.sql import text\nfrom sqlalchemy.orm import sessionmaker\n\nfrom vulnserver.lib.models import FakerSchema, SchemaGen\n\nschema = None\nschema_type = os.environ.get(\'VULNSERVER_SCHEMA_TYPE\', \'\')\nif schema_type.lower().strip() == \'schemagen\':\n    schema = SchemaGen()\nelse:\n    schema = FakerSchema()\nschema.gen()\nschema.populate()\nselect_table, select_table_pk = schema.select_table()\nengine = schema.get_engine()\napp = Flask(__name__)\n\n@app.route(""/"")\ndef index():\n    return \'vulnserver: /v0/sqli/select?user_id=1\'\n\n@app.route(""/v0/sqli/select"")\ndef sqli_select():\n    sqltext = \'\'\'select * from {0} where {1}={2}\'\'\'.format(select_table,select_table_pk,request.args.get(\'user_id\',1))\n    with engine.connect() as cursor:\n        return str([i for i in cursor.execute(sqltext).fetchmany(10)])\n\n@app.route(""/v0/sqli/insert"")\ndef sqli_insert():\n    return \'insert\'\n\n@app.route(""/v0/sqli/shell"")\ndef sqli_shell():\n    sql = request.args.get(\'sql\')\n    with engine.connect() as cursor:\n        return str(cursor.execute(sql).fetchall())\n\n@app.route(""/v0/sqli/update"")\ndef sqli_update():\n    return \'updated\'\n\n@app.route(""/v0/sqli/delete"")\ndef sqli_delete():\n    return \'deleted\'\n\n@app.route(""/v0/sqli/refresh"")\ndef sqli_refresh():\n    _create_database()\n    return \'refreshed\'\n'"
