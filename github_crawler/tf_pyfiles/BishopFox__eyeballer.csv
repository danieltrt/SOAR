file_path,api_count,code
eyeballer.py,0,"b'#!/usr/bin/env python3\n\nimport click\nimport csv\n\nfrom eyeballer.model import EyeballModel, DATA_LABELS\nfrom eyeballer.visualization import HeatMap\nfrom jinja2 import Template\n\n\n@click.group(invoke_without_command=True)\n@click.option(\'--weights\', default=None, type=click.Path(), help=""Weights file for input/output"")\n@click.option(\'--summary/--no-summary\', default=False, help=""Print model summary at start"")\n@click.option(\'--seed\', default=None, type=int, help=""RNG seed for data shuffling and transformations, defaults to random value"")\n@click.pass_context\ndef cli(ctx, weights, summary, seed):\n    model_kwargs = {""weights_file"": weights,\n                    ""print_summary"": summary,\n                    ""seed"": seed}\n\n    #  pass the model to subcommands\n    ctx.ensure_object(dict)\n    # We only pass the kwargs so we can be lazy and make the model later after the subcommand cli is parsed. This\n    # way, the user doesn\'t have to wait for tensorflow if they are just calling --help on a subcommand.\n    ctx.obj[\'model_kwargs\'] = model_kwargs\n\n\n@cli.command()\n@click.option(\'--graphs/--no-graphs\', default=False, help=""Save accuracy and loss graphs to file"")\n@click.option(\'--epochs\', default=20, type=int, help=""Number of epochs"")  # TODO better help string\n@click.option(\'--batchsize\', default=32, type=int, help=""Batch size"")  # TODO better help string\n@click.pass_context\ndef train(ctx, graphs, batchsize, epochs):\n    model = EyeballModel(**ctx.obj[\'model_kwargs\'])\n    model.train(print_graphs=graphs, batch_size=batchsize, epochs=epochs)\n\n\n@cli.command()\n@click.argument(\'screenshot\')\n@click.option(\'--heatmap\', default=False, is_flag=True, help=""Create a heatmap graphfor the prediction"")\n@click.option(\'--threshold\', default=.5, type=float, help=""Threshold confidence for labeling"")\n@click.pass_context\ndef predict(ctx, screenshot, heatmap, threshold):\n    model = EyeballModel(**ctx.obj[\'model_kwargs\'])\n    results = model.predict(screenshot)\n\n    if heatmap:\n        # Generate a heatmap\n        HeatMap(screenshot, model, threshold).generate()\n\n    if not results:\n        print(""Error: Input file does not exist"")\n    if len(results) == 1:\n        print(results)\n    else:\n        with open(""results.csv"", ""w"", newline="""") as csvfile:\n            fieldnames = [""filename"", ""custom404"", ""login"", ""homepage"", ""oldlooking""]\n            labelwriter = csv.DictWriter(csvfile, fieldnames=fieldnames)\n            labelwriter.writeheader()\n            labelwriter.writerows(results)\n\n        print(""Output written to results.csv"")\n        buildHTML(processResults(results, threshold))\n        print(""HTML written to results.html"")\n\n\ndef processResults(results, threshold):\n    \'\'\'Filter the initial results dictionary and reformat it for use in JS.\n\n        Keyword arguments:\n        results -- dictionary output from predict function\n\n    \'\'\'\n    jsResults = {}\n\n    for result in results:\n        positiveTags = []\n\n        for label, label_info in result.items():\n            if (label == \'filename\'):\n                pass\n            elif label_info > threshold:\n                positiveTags.append(label)\n\n        jsResults[result[\'filename\']] = positiveTags\n    return(jsResults)\n\n\ndef buildHTML(jsResults):\n    \'\'\'Build HTML around the JS Dictionary that is passed from processResults.\n\n        Keyword arguments:\n        jsResults -- dictionary output from processResults function\n    \'\'\'\n    html_output = """"\n    with open(""prediction_output_template.html"") as template_file:\n        template = Template(template_file.read())\n        html_output = template.render(jsResults=jsResults)\n\n    with open(\'results.html\', \'w\') as file:\n        file.write(html_output)\n\n\ndef pretty_print_evaluation(results):\n    """"""Print a human-readable summary of the evaluation""""""\n    # We use 4.2% to handle all the way from ""  0.00%"" (7chars) to ""100.00%"" (7chars)\n    for label in DATA_LABELS:\n        print(""{} Precision Score: {:4.2%}"".format(label, results[label][\'precision\']))\n        print(""{} Recall Score: {:4.2%}"".format(label, results[label][\'recall\']))\n    print(""\'None of the above\' Precision: {:4.2%}"".format(results[\'none_of_the_above_precision\']))\n    print(""\'None of the above\' Recall: {:4.2%}"".format(results[\'none_of_the_above_recall\']))\n    print(""All or nothing Accuracy: {:4.2%}"".format(results[\'all_or_nothing_accuracy\']))\n    print(""Overall Binary Accuracy: {:4.2%}"".format(results[\'total_binary_accuracy\']))\n    print(""Top 10 worst predictions: {}"".format(results[\'top_10_worst\'][1]))\n\n\n@cli.command()\n@click.option(\'--threshold\', default=.5, type=float, help=""Threshold confidence for labeling"")\n@click.pass_context\ndef evaluate(ctx, threshold):\n    model = EyeballModel(**ctx.obj[\'model_kwargs\'])\n    results = model.evaluate(threshold)\n    pretty_print_evaluation(results)\n\n\nif __name__ == \'__main__\':\n    cli()\n'"
eyeballer/__init__.py,0,b''
eyeballer/augmentation.py,0,"b""import numpy as np\n\nfrom Augmentor.Operations import Operation\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\n\nclass EyeballerAugmentation(Operation):\n    def __init__(self, probability=1):\n        Operation.__init__(self, probability)\n\n    # Class must implement the perform_operation method\n    def perform_operation(self, images):\n        return_list = []\n        for image in images:\n            image_array = np.array(image).astype('uint8')\n            image_array = preprocess_input(image_array)\n            return_list.append(image_array)\n        return return_list\n"""
eyeballer/model.py,15,"b'import os\nimport random\nimport sys\nimport progressbar\n\n# Prevent Tkinter Dependency\nimport matplotlib\nmatplotlib.use(\'agg\')  # noqa: E402\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport pandas as pd\nimport Augmentor\nimport tensorflow as tf\n\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\nfrom sklearn.metrics import classification_report, accuracy_score, hamming_loss\nfrom eyeballer.augmentation import EyeballerAugmentation\n\nDATA_LABELS = [""custom404"", ""login"", ""homepage"", ""oldlooking""]\n\n\nclass EyeballModel:\n    """"""The primary model class of Eyeballer.\n\n    Contains high-level functions for training, evaluating, and predicting.\n    """"""\n    graphs_directory = ""graphs/""\n    checkpoint_file = ""weights.h5""\n    image_dir = ""images/""\n    image_width, image_height = 224, 224\n    input_shape = (image_width, image_height, 3)\n\n    def __init__(self, weights_file, print_summary=False, seed=None, quiet=False):\n        """"""Constructor for model class.\n\n        Keyword arguments:\n        print_summary -- Whether or not to print to stdout the keras model summary, containing a detailed description of every model layer\n        weights_file -- A filename for where to load the model\'s weights.\n        seed -- PRNG seed, useful for repeating a previous run and using the same data. Training/Validation split is determined randomly.\n        """"""\n        # # Build the model\n        self.model = tf.keras.Sequential()\n        pretrained_layer = tf.keras.applications.mobilenet.MobileNet(weights=\'imagenet\', include_top=False, input_shape=self.input_shape)\n        self.model.add(pretrained_layer)\n        self.model.add(tf.keras.layers.GlobalAveragePooling2D())\n        self.model.add(tf.keras.layers.Dense(256, activation=""relu""))\n        self.model.add(tf.keras.layers.Dropout(0.5))\n        self.model.add(tf.keras.layers.Dense(128, activation=""relu""))\n        self.model.add(tf.keras.layers.Dropout(0.2))\n        self.model.add(tf.keras.layers.Dense(len(DATA_LABELS), activation=""sigmoid""))\n\n        self.model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),\n                           loss=""binary_crossentropy"",\n                           metrics=[""accuracy""])\n\n        # for layer in pretrained_layer.layers:\n        #     layer.trainable = False\n\n        if print_summary:\n            print(self.model.summary())\n\n        self.quiet = quiet\n\n        # Pull out our labels for use in generators later\n        data = pd.read_csv(""labels.csv"")\n        self.training_labels = data.loc[data[\'evaluation\'] == False]  # noqa: E712\n        self.evaluation_labels = data.loc[data[\'evaluation\'] == True]  # noqa: E712\n\n        # Shuffle the training labels\n        self.random_seed = False\n        self.seed = seed\n        if self.seed is None:\n            self.random_seed = True\n            self.seed = random.randint(0, 999999)\n            print(""No seed set, "", end=\'\')\n        print(""using seed: {}"".format(self.seed))\n        random.seed(self.seed)\n        self.training_labels = self.training_labels.sample(frac=1)\n\n        if weights_file is not None and os.path.isfile(weights_file):\n            try:\n                self.model.load_weights(weights_file)\n            except OSError:\n                print(""ERROR: Unable to open weights file \'{}\'"".foramt(weights_file))\n                sys.exit(-1)\n            print(""Loaded model from file."")\n        else:\n            if weights_file is not None:\n                raise FileNotFoundError\n            print(""WARN: No model loaded from file. Generating random model"")\n\n        # Data augmentation\n        augmentor = Augmentor.Pipeline()\n        augmentor.set_seed(self.seed)\n        augmentor.zoom(probability=0.75, min_factor=0.8, max_factor=1.2)\n        augmentor.random_color(probability=0.75, min_factor=0.5, max_factor=1.0)\n        augmentor.random_contrast(probability=0.75, min_factor=0.8, max_factor=1.0)\n        augmentor.random_brightness(probability=0.75, min_factor=0.8, max_factor=1.2)\n        augmentor.random_erasing(probability=0.75, rectangle_area=0.15)\n\n        # Finalizes the augmentation with a custom operation to prepare the image for the specific pretrained model we\'re using\n        training_augmentation = EyeballerAugmentation()\n        augmentor.add_operation(training_augmentation)\n        self.preprocess_training_function = augmentor.keras_preprocess_func()\n\n    def train(self, epochs=20, batch_size=32, print_graphs=False):\n        """"""Train the model, making a new weights file at each successfull checkpoint. You\'ll probably need a GPU for this to realistically run.\n\n        Keyword arguments:\n        epochs -- The number of epochs to train for. (An epoch is one pass-through of the dataset)\n        batch_size -- How many images to batch together when training. Generally speaking, the higher the better, until you run out of memory.\n        print_graphs --- Whether or not to create accuracy and loss graphs. If true, they\'ll be written to accuracy.png and loss.png\n        """"""\n        print(""Training with seed: "" + str(self.seed))\n\n        data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n            preprocessing_function=self.preprocess_training_function,\n            validation_split=0.2,\n            samplewise_center=True)\n\n        training_generator = data_generator.flow_from_dataframe(\n            self.training_labels,\n            directory=self.image_dir,\n            x_col=""filename"",\n            y_col=DATA_LABELS,\n            target_size=(self.image_width, self.image_height),\n            batch_size=batch_size,\n            subset=\'training\',\n            shuffle=True,\n            seed=self.seed,\n            class_mode=""other"")\n        validation_generator = data_generator.flow_from_dataframe(\n            self.training_labels,\n            directory=self.image_dir,\n            x_col=""filename"",\n            y_col=DATA_LABELS,\n            target_size=(self.image_width, self.image_height),\n            batch_size=batch_size,\n            subset=\'validation\',\n            shuffle=False,\n            seed=self.seed,\n            class_mode=""other"")\n\n        # Model checkpoint - Saves model weights when validation accuracy improves\n        callbacks = [tf.keras.callbacks.ModelCheckpoint(self.checkpoint_file,\n                     monitor=\'val_loss\',\n                     verbose=1,\n                     save_best_only=True,\n                     save_weights_only=True,\n                     mode=\'min\')]\n\n        history = self.model.fit_generator(\n            training_generator,\n            steps_per_epoch=len(training_generator.filenames) // batch_size,\n            epochs=epochs,\n            validation_data=validation_generator,\n            validation_steps=len(validation_generator.filenames) // batch_size,\n            callbacks=callbacks,\n            verbose=1)\n\n        if print_graphs:\n            if not os.path.exists(self.graphs_directory):\n                os.makedirs(self.graphs_directory)\n            # Plot training & validation accuracy values\n            plt.plot(history.history[\'acc\'])\n            plt.plot(history.history[\'val_acc\'])\n            plt.title(\'Model accuracy\')\n            plt.ylabel(\'Accuracy\')\n            plt.xlabel(\'Epoch\')\n            plt.legend([\'Train\', \'Validation\'], loc=\'upper left\')\n            plt.savefig(self.graphs_directory + ""accuracy.png"")\n            plt.clf()\n            plt.cla()\n            plt.close()\n\n            # Plot training & validation loss values\n            plt.plot(history.history[\'loss\'])\n            plt.plot(history.history[\'val_loss\'])\n            plt.title(\'Model loss\')\n            plt.ylabel(\'Loss\')\n            plt.xlabel(\'Epoch\')\n            plt.legend([\'Train\', \'Validation\'], loc=\'upper left\')\n            plt.savefig(self.graphs_directory + ""loss.png"")\n\n    def predict_on_array(self, image):\n        """"""Predict the labels for a single screenshot\n\n        Keyword arguments:\n        image -- The numpy array of the image to classify\n        """"""\n        img = np.expand_dims(image, axis=0)\n        img = preprocess_input(img)\n\n        prediction = self.model.predict(img, batch_size=1)\n        result = dict()\n        result[""filename""] = ""custom-image""\n        result[""custom404""] = prediction[0][0]\n        result[""login""] = prediction[0][1]\n        result[""homepage""] = prediction[0][2]\n        result[""oldlooking""] = prediction[0][3]\n        return result\n\n    def predict(self, path, threshold=0.5):\n        """"""Predict the labels for a single file or directory of files\n\n        Keyword arguments:\n        path -- The path to the file(s) that we\'ll be evaluating.\n        """"""\n        # Is this a single file, or a directory?\n        screenshots = []\n        if os.path.isfile(path):\n            screenshots = [path]\n        elif os.path.isdir(path):\n            screenshots = os.listdir(path)\n            screenshots = [os.path.join(path, s) for s in screenshots]\n        else:\n            raise FileNotFoundError\n\n        results = []\n        bar = progressbar.ProgressBar()\n        if self.quiet:\n            bar = progressbar.NullBar()\n        for screenshot in bar(screenshots):\n            # Load the image into memory\n            img = None\n            try:\n                img = tf.keras.preprocessing.image.load_img(screenshot, target_size=(self.image_width, self.image_height))\n                img = tf.keras.preprocessing.image.img_to_array(img)\n                img = np.expand_dims(img, axis=0)\n                img = preprocess_input(img)\n            except IsADirectoryError:\n                print(""\\nWARN: Skipping directory: "", screenshot)\n                continue\n            except OSError:\n                print(""\\nWARN: Skipping empty or corrupt file: "", screenshot)\n                continue\n\n            prediction = self.model.predict(img, batch_size=1)\n            result = dict()\n            result[""filename""] = screenshot\n            result[""custom404""] = prediction[0][0]\n            result[""login""] = prediction[0][1]\n            result[""homepage""] = prediction[0][2]\n            result[""oldlooking""] = prediction[0][3]\n            results.append(result)\n        return results\n\n    def evaluate(self, threshold=0.5):\n        """"""Evaluate performance against the persistent evaluation data set\n\n        Keyword arguments:\n        threshold -- Value between 0->1. The cutoff where the numerical prediction becomes boolean. Default: 0.5\n        """"""\n        # Prepare the data\n        data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n            preprocessing_function=preprocess_input)\n        evaluation_generator = data_generator.flow_from_dataframe(\n            self.evaluation_labels,\n            directory=self.image_dir,\n            x_col=""filename"",\n            y_col=DATA_LABELS,\n            target_size=(self.image_width, self.image_height),\n            shuffle=False,\n            batch_size=1,\n            class_mode=""other"")\n        # If a seed was selected, then also evaluate on the validation set for that seed\n        if not self.random_seed:\n            print(""Using validation set..."")\n            # Data augmentation\n            data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n                preprocessing_function=self.preprocess_training_function,\n                samplewise_center=True,\n                validation_split=0.2)\n            evaluation_generator = data_generator.flow_from_dataframe(\n                self.training_labels,\n                directory=self.image_dir,\n                x_col=""filename"",\n                y_col=DATA_LABELS,\n                target_size=(self.image_width, self.image_height),\n                batch_size=1,\n                subset=\'validation\',\n                shuffle=False,\n                seed=self.seed,\n                class_mode=""other"")\n        else:\n            print(""Using evaluation set..."")\n\n        predictions = self.model.predict_generator(\n            evaluation_generator,\n            verbose=1,\n            steps=len(evaluation_generator))\n\n        self._save_prediction_histograms(predictions)\n        predictions = predictions > threshold\n        ground_truth = self.evaluation_labels[DATA_LABELS].to_numpy()\n        filenames = self.evaluation_labels[[""filename""]].to_numpy()\n        stats = classification_report(ground_truth, predictions, target_names=DATA_LABELS, output_dict=True)\n        stats[""total_binary_accuracy""] = 1 - hamming_loss(ground_truth, predictions)\n        stats[""all_or_nothing_accuracy""] = accuracy_score(ground_truth, predictions)\n        stats[""top_10_best""] = self._top_images(filenames, ground_truth, predictions, best=True)\n        stats[""top_10_worst""] = self._top_images(filenames, ground_truth, predictions, best=False)\n        stats[""none_of_the_above_recall""] = self._none_of_the_above_recall(ground_truth, predictions)\n        stats[""none_of_the_above_precision""] = self._none_of_the_above_precision(ground_truth, predictions)\n        return stats\n\n    def _none_of_the_above_recall(self, labels, predictions):\n        """"""Returns the recall score for the \'none of the above\' images.\n        That means, all the images that don\'t have a category.\n        """"""\n        total_count = 0\n        correct_count = 0\n        for item in zip(labels.astype(int), predictions.astype(int)):\n            # Is this a none of the above?\n            if not item[0].any():\n                total_count += 1\n                if not item[1].any():\n                    correct_count += 1\n        if total_count == 0:\n            print(""WARNING: None of the Above Recall is NaN"")\n            return 0\n        return correct_count / total_count\n\n    def _none_of_the_above_precision(self, labels, predictions):\n        """"""Returns the precision score for the \'none of the above\' images.\n        That means, all the images that don\'t have a category.\n        """"""\n        total_count = 0\n        correct_count = 0\n        for item in zip(labels.astype(int), predictions.astype(int)):\n            # Is this a none of the above prediction?\n            if not item[1].any():\n                total_count += 1\n                if not item[0].any():\n                    correct_count += 1\n        if total_count == 0:\n            print(""WARNING: None of the Above Precision is NaN"")\n            return 0\n        return correct_count / total_count\n\n    def _top_images(self, filenames, ground_truth, predictions, top_k=10, best=False):\n        """"""Collect top-k best or top-k worst predicted images\n\n        Keyword arguments:\n        ground_truth -- The correct labels\n        predictions -- The numpy array of predictions\n        top_k -- Top k elements\n        best -- True/False. Calculate either the best or worst images\n\n        :Return -- Tuple of top-k indicies and top-k filenames\n        """"""\n        true_labels = np.array(ground_truth).astype(float)\n        predictions = predictions.astype(float)\n\n        differences = np.abs(predictions - true_labels).sum(axis=1)\n        indicies = np.argsort(differences, axis=0)\n\n        top_file_list = []\n\n        if not best:\n            # Reverse numpy array\n            indicies = np.flipud(indicies)\n\n        for i in indicies[:top_k]:\n            top_file_list.append(filenames[i][0])\n\n        return indicies[:top_k], top_file_list\n\n    def _save_prediction_histograms(self, predictions, buckets=50):\n        """"""Saves a series of histogram screenshots\n\n            Keyword arguments:\n            predictions -- The numpy array of predicted labels, ranging from 0->1.\n            buckets -- The number of buckets to divide the data into. Default: 50\n            :Returns -- Nothing""\n        """"""\n        figure, axes = plt.subplots(nrows=len(DATA_LABELS))\n        for i, label in enumerate(DATA_LABELS):\n            axes[i].hist(predictions[:, i], buckets, alpha=.75)\n            axes[i].set_xlabel(""Prediction"")\n            axes[i].set_ylabel(""Counts of Predictions"")\n            axes[i].set_title(label)\n            axes[i].grid(True)\n        figure.set_size_inches(5, 3*len(DATA_LABELS))\n        figure.tight_layout()\n        if not os.path.exists(self.graphs_directory):\n            os.makedirs(self.graphs_directory)\n        plt.savefig(self.graphs_directory + ""label_histograms.png"")\n'"
eyeballer/visualization.py,3,"b'import numpy as np\nimport math\nimport tensorflow as tf\n\nfrom copy import deepcopy\nfrom matplotlib import pyplot as plt\nfrom eyeballer.model import DATA_LABELS\n\n\nclass HeatMap():\n    def __init__(self, screenshot_path, model, threshold=0.5, boxsize=28, step=7):\n        self.model = model\n\n        img = tf.keras.preprocessing.image.load_img(screenshot_path, target_size=(self.model.image_width, self.model.image_height))\n        img = tf.keras.preprocessing.image.img_to_array(img)\n\n        self.screenshot = img\n        self.boxsize = boxsize\n        self.step = step\n        self.x = 0\n        self.y = 0\n        self.screenshot_path = screenshot_path\n        self.gamma = 3\n        self.threshold = threshold\n\n    def generate(self, output_file=""heatmap.png""):\n        """""" Make a single heatmap image and return it """"""\n        heatmaps = []\n        labels = []\n        results = self.model.predict(self.screenshot_path)\n        results = results[0]\n        for label in DATA_LABELS:\n            boxsize = self.boxsize\n            # Ignore this label if it didn\'t predict positively (true label)\n            if results[label] > self.threshold:\n                worst_score = 1\n                while worst_score > self.threshold:\n                    heatmap, worst_score = self._get_heatmap(label, boxsize)\n                    if worst_score > self.threshold:\n                        boxsize += 28\n                        print(""Didn\'t get a good image for {}. Trying again with a bigger boxsize: {}"".format(label, boxsize))\n                    else:\n                        heatmaps.append(heatmap)\n                        labels.append(label)\n\n        plt.figure()\n        screenshot_image = tf.keras.preprocessing.image.load_img(self.screenshot_path, target_size=(self.model.image_width, self.model.image_width))\n        _, subplots = plt.subplots(1, len(heatmaps))\n        # This is a little janky, but matplotlib returns a list above if there\'s multiple subplots, and just a single subplot if there\'s only one\n        #   it would have been easier if it was always a list. But alas\n        if not heatmaps:\n            print(""No heatmap made. The image did not have a True classification for any label"")\n            return\n        if len(heatmaps) > 1:\n            for i, heatmap in enumerate(heatmaps):\n                subplots[i].imshow(screenshot_image, cmap=\'binary\', interpolation=\'none\')\n                subplots[i].imshow(heatmap, alpha=0.5, interpolation=\'none\')\n                subplots[i].set_title(labels[i])\n        else:\n            subplots.imshow(screenshot_image, cmap=\'binary\', interpolation=\'none\')\n            subplots.imshow(heatmap, alpha=0.5, interpolation=\'none\')\n            subplots.set_title(labels[0])\n        plt.savefig(output_file)\n        print(""Heatmap image written to: {}"".format(output_file))\n\n    def _get_heatmap(self, label, boxsize):\n        worst_score = 1\n        self.x, self.y = 0, 0\n\n        heatmap = np.ones((self.model.image_width, self.model.image_height))\n        heatmap *= 255\n        while True:\n            # Occlude an image\n            occluded_image, x, y = self._occlude(boxsize)\n            if occluded_image is not None:\n                # Score the new occluded image\n                results = self.model.predict_on_array(occluded_image)\n                score = results[label]  # TODO\n                worst_score = min(worst_score, score)\n                # Scale the score up to pixel values\n                score = math.floor(score * 255)\n                # Anneal the scores as you go outward into the occlusion block\n                new_scores = np.ones((boxsize, boxsize))\n                new_scores *= score\n                new_scores = self._gamma_anneal(new_scores)\n\n                # For each pixel, update only where the new score is lower\n                original_scores = heatmap[x: x+boxsize, y: y+boxsize]\n\n                target_area = np.where(new_scores < original_scores, new_scores, original_scores)\n                heatmap[x: x+boxsize, y: y+boxsize] = target_area\n            else:\n                break\n\n        return heatmap, worst_score\n\n    def _gamma_anneal(self, occlusion_area):\n        """""" Get the annealed score based on centeredness of the occlusion area """"""\n        width, height = occlusion_area.shape\n\n        center_x = (width-1) / 2\n        center_y = (height-1) / 2\n\n        annealed_area = np.zeros(occlusion_area.shape)\n\n        for (x, y), score in np.ndenumerate(occlusion_area):\n            distance = math.sqrt((center_x - x)**2 + (center_y - y)**2)\n            annealed_area[x, y] = min(255, score + (self.gamma * distance))\n\n        return annealed_area\n\n    def _occlude(self, boxsize):\n        \'\'\' Return a single occluded image and its location \'\'\'\n        if self.x + boxsize > self.screenshot.shape[0]:\n            return None, None, None\n\n        retImg = np.copy(self.screenshot)\n        retImg[self.x:self.x+boxsize, self.y:self.y+boxsize] = 0.0\n\n        old_i = deepcopy(self.x)\n        old_j = deepcopy(self.y)\n\n        # update indices\n        self.y = self.y + self.step\n        if self.y+boxsize > self.screenshot.shape[1]:  # reached end\n            self.y = 0  # reset j\n            self.x = self.x + self.step  # go to next row\n\n        return retImg, old_i, old_j\n'"
tests/PredictTest.py,0,"b'import errno\nimport os\nimport unittest\nimport sys\n\nfrom eyeballer.model import EyeballModel\nfrom eyeballer.visualization import HeatMap\n\n\nclass PredictTest(unittest.TestCase):\n    def setUp(self):\n\n        class DummyFile(object):\n            def write(self, x): pass\n            def flush(self): pass\n\n        sys.stdout = DummyFile()\n        weights_file = ""tests/models/test_weights.h5""\n        if not os.path.isfile(weights_file):\n            print(""Error: Symlink the latest weights file to "" + weights_file)\n            raise FileNotFoundError(\n                errno.ENOENT,\n                os.strerror(errno.ENOENT),\n                weights_file)\n\n        model_kwargs = {\n            ""weights_file"": weights_file,\n            ""print_summary"": False,\n            ""seed"": None,\n            ""quiet"": True\n        }\n        self.model = EyeballModel(**model_kwargs)\n\n    def test_different_seed_predict(self):\n        model_kwargs = {\n            ""weights_file"": None,\n            ""print_summary"": False,\n            ""seed"": 12345678,\n            ""quiet"": True\n        }\n        same_seed_model = EyeballModel(**model_kwargs)\n\n        screenshot = ""tests/data/404.png""\n\n        results_one = self.model.predict(screenshot)\n        results_two = same_seed_model.predict(screenshot)\n\n        self.assertNotEqual(results_one, results_two)\n\n    def test_same_seed_predict(self):\n        model_kwargs = {\n            ""weights_file"": None,\n            ""print_summary"": False,\n            ""seed"": 12345678,\n            ""quiet"": True\n        }\n        same_seed_model = EyeballModel(**model_kwargs)\n\n        screenshot = ""tests/data/404.png""\n\n        results_one = same_seed_model.predict(screenshot)\n        results_two = same_seed_model.predict(screenshot)\n\n        self.assertEqual(results_one, results_two)\n\n    def test_predict_custom404(self):\n        screenshot = ""tests/data/404.png""\n        results = self.model.predict(screenshot)[0]\n        self.assertGreater(results[""custom404""], 0.5)\n\n    def test_predict_not_custom404(self):\n        screenshot = ""tests/data/nothing.png""\n        results = self.model.predict(screenshot)[0]\n        self.assertLess(results[""custom404""], 0.5)\n\n    def test_predict_login(self):\n        screenshot = ""tests/data/login.png""\n        results = self.model.predict(screenshot)[0]\n        self.assertGreater(results[""login""], 0.5)\n\n    def test_predict_not_login(self):\n        screenshot = ""tests/data/nothing.png""\n        results = self.model.predict(screenshot)[0]\n        print(screenshot, results)\n        self.assertLess(results[""login""], 0.5)\n\n    def test_predict_homepage(self):\n        screenshot = ""tests/data/homepage.png""\n        results = self.model.predict(screenshot)[0]\n        self.assertGreater(results[""homepage""], 0.5)\n\n    def test_predict_not_homepage(self):\n        screenshot = ""tests/data/nothing.png""\n        results = self.model.predict(screenshot)[0]\n        self.assertLess(results[""homepage""], 0.5)\n\n    def test_predict_oldlooking(self):\n        screenshot = ""tests/data/old-looking.png""\n        results = self.model.predict(screenshot)[0]\n        self.assertGreater(results[""oldlooking""], 0.5)\n\n    def test_predict_not_oldlooking(self):\n        screenshot = ""tests/data/nothing.png""\n        results = self.model.predict(screenshot)[0]\n        self.assertLess(results[""oldlooking""], 0.5)\n\n    def test_file_doesnt_exist(self):\n        screenshot = ""tests/data/doesnotexist.png""\n        try:\n            self.model.predict(screenshot)[0]\n            self.fail(""FileNotFoundError was expected but not found"")\n        except FileNotFoundError:\n            pass\n\n    def test_folder(self):\n        screenshots = ""tests/data/""\n        results = self.model.predict(screenshots)\n        self.assertEqual(len(results), 7)\n\n    def test_file_is_empty(self):\n        """"""\n        We\'re just testing that it doesn\'t crash, basically\n        """"""\n        screenshot = ""tests/data/empty.png""\n        self.model.predict(screenshot)\n\n    def test_file_is_invalid(self):\n        """"""\n        We\'re just testing that it doesn\'t crash, basically\n        """"""\n        screenshot = ""tests/data/invalid.png""\n        self.model.predict(screenshot)\n\n    def test_heatmap(self):\n        screenshot = ""tests/data/login.png""\n        HeatMap(screenshot, self.model, 0.5)\n\n        screenshot = ""tests/data/404.png""\n        HeatMap(screenshot, self.model, 0.5)\n\n        screenshot = ""tests/data/empty.png""\n        HeatMap(screenshot, self.model, 0.5)\n'"
tests/__init__.py,0,b'from tests.PredictTest import *  # noqa\n'
utils/labelbox_to_labels.py,0,"b'#!/usr/bin/env python3\n\nimport csv\nimport random\nimport json\n\nwith open(""newlabels.csv"", ""w"", newline="""") as csvfile:\n    # Open the old labels file\n    with open(""labelbox.csv"", newline="""") as oldfile:\n        # Get the header labels\n        csvreader = csv.DictReader(oldfile)\n        fieldnames = next(csvreader)\n        labelwriter = csv.DictWriter(csvfile, fieldnames=[""filename"", ""login"", ""custom404"", ""homepage"", ""oldlooking"", ""evaluation""])\n        labelwriter.writeheader()\n\n        # Loop through the file\n        rows = []\n        for row in csvreader:\n            filename = row[""External ID""]\n            print(row[""Label""])\n            labelstring = row[""Label""]\n            if row[""Label""] == ""Skip"":\n                labelstring = \'{""imageclassification"":[]}\'\n            labels = json.loads(labelstring)\n\n            newrow = dict()\n            newrow[""filename""] = filename\n            newrow[""oldlooking""] = True\n            newrow[""login""] = ""loginpage"" in labels[""imageclassification""]\n            newrow[""homepage""] = ""homepage"" in labels[""imageclassification""]\n            newrow[""custom404""] = ""custom404""in labels[""imageclassification""]\n\n            newrow[""evaluation""] = random.random() > 0.8\n\n            rows.append(newrow)\n        labelwriter.writerows(rows)\nprint(""Made new labels file: newlabels.csv"")\n'"
utils/reroll.py,0,"b'#!/usr/bin/env python3\n\nimport csv\nimport random\n\nwith open(""newlabels.csv"", ""w"", newline="""") as csvfile:\n    # Open the old labels file\n    with open(""labels.csv"", newline="""") as oldfile:\n        # Get the header labels\n        csvreader = csv.DictReader(oldfile)\n        fieldnames = next(csvreader)\n        labelwriter = csv.DictWriter(csvfile, fieldnames=fieldnames)\n        labelwriter.writeheader()\n\n        # Loop through the file\n        rows = []\n        for row in csvreader:\n            row[""evaluation""] = random.random() > 0.8\n            rows.append(row)\n        labelwriter.writerows(rows)\nprint(""Made new labels file: newlabels.csv"")\n'"
