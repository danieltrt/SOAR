file_path,api_count,code
GTA_Diversity_256p.py,28,"b'#This is a model trained on GTA5. Assume training images are 00000001.png,...,00012403.png and test images are 001000001,...,00106382.png.\nfrom __future__ import division\nimport os,cv2,helper,time,scipy.io\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nfrom tensorflow.contrib.layers.python.layers import initializers\nimport numpy as np\n\ndef lrelu(x):\n    return tf.maximum(0.2*x,x)\n\ndef build_net(ntype,nin,nwb=None,name=None):\n    if ntype==\'conv\':\n        return tf.nn.relu(tf.nn.conv2d(nin,nwb[0],strides=[1,1,1,1],padding=\'SAME\',name=name)+nwb[1])\n    elif ntype==\'pool\':\n        return tf.nn.avg_pool(nin,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\'SAME\')\n\ndef get_weight_bias(vgg_layers,i):\n    weights=vgg_layers[i][0][0][2][0][0]\n    weights=tf.constant(weights)\n    bias=vgg_layers[i][0][0][2][0][1]\n    bias=tf.constant(np.reshape(bias,(bias.size)))\n    return weights,bias\n\ndef build_vgg19(input,reuse=False):\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    net={}\n    vgg_rawnet=scipy.io.loadmat(\'VGG_Model/imagenet-vgg-verydeep-19.mat\')\n    vgg_layers=vgg_rawnet[\'layers\'][0]\n    net[\'input\']=input-np.array([123.6800, 116.7790, 103.9390]).reshape((1,1,1,3))\n    net[\'conv1_1\']=build_net(\'conv\',net[\'input\'],get_weight_bias(vgg_layers,0),name=\'vgg_conv1_1\')\n    net[\'conv1_2\']=build_net(\'conv\',net[\'conv1_1\'],get_weight_bias(vgg_layers,2),name=\'vgg_conv1_2\')\n    net[\'pool1\']=build_net(\'pool\',net[\'conv1_2\'])\n    net[\'conv2_1\']=build_net(\'conv\',net[\'pool1\'],get_weight_bias(vgg_layers,5),name=\'vgg_conv2_1\')\n    net[\'conv2_2\']=build_net(\'conv\',net[\'conv2_1\'],get_weight_bias(vgg_layers,7),name=\'vgg_conv2_2\')\n    net[\'pool2\']=build_net(\'pool\',net[\'conv2_2\'])\n    net[\'conv3_1\']=build_net(\'conv\',net[\'pool2\'],get_weight_bias(vgg_layers,10),name=\'vgg_conv3_1\')\n    net[\'conv3_2\']=build_net(\'conv\',net[\'conv3_1\'],get_weight_bias(vgg_layers,12),name=\'vgg_conv3_2\')\n    net[\'conv3_3\']=build_net(\'conv\',net[\'conv3_2\'],get_weight_bias(vgg_layers,14),name=\'vgg_conv3_3\')\n    net[\'conv3_4\']=build_net(\'conv\',net[\'conv3_3\'],get_weight_bias(vgg_layers,16),name=\'vgg_conv3_4\')\n    net[\'pool3\']=build_net(\'pool\',net[\'conv3_4\'])\n    net[\'conv4_1\']=build_net(\'conv\',net[\'pool3\'],get_weight_bias(vgg_layers,19),name=\'vgg_conv4_1\')\n    net[\'conv4_2\']=build_net(\'conv\',net[\'conv4_1\'],get_weight_bias(vgg_layers,21),name=\'vgg_conv4_2\')\n    net[\'conv4_3\']=build_net(\'conv\',net[\'conv4_2\'],get_weight_bias(vgg_layers,23),name=\'vgg_conv4_3\')\n    net[\'conv4_4\']=build_net(\'conv\',net[\'conv4_3\'],get_weight_bias(vgg_layers,25),name=\'vgg_conv4_4\')\n    net[\'pool4\']=build_net(\'pool\',net[\'conv4_4\'])\n    net[\'conv5_1\']=build_net(\'conv\',net[\'pool4\'],get_weight_bias(vgg_layers,28),name=\'vgg_conv5_1\')\n    net[\'conv5_2\']=build_net(\'conv\',net[\'conv5_1\'],get_weight_bias(vgg_layers,30),name=\'vgg_conv5_2\')\n    return net\n\ndef recursive_generator(label,sp):\n    dim=512 if sp>=128 else 1024\n    if sp==4:\n        input=label\n    else:\n        downsampled=tf.image.resize_area(label,(sp//2,sp),align_corners=False)\n        input=tf.concat([tf.image.resize_bilinear(recursive_generator(downsampled,sp//2),(sp,sp*2),align_corners=True),label],3)\n    net=slim.conv2d(input,dim,[3,3],rate=1,normalizer_fn=slim.layer_norm,activation_fn=lrelu,scope=\'g_\'+str(sp)+\'_conv1\')\n    net=slim.conv2d(net,dim,[3,3],rate=1,normalizer_fn=slim.layer_norm,activation_fn=lrelu,scope=\'g_\'+str(sp)+\'_conv2\')\n    if sp==256:\n        net=slim.conv2d(net,27,[1,1],rate=1,activation_fn=None,scope=\'g_\'+str(sp)+\'_conv100\')\n        net=(net+1.0)/2.0*255.0\n        split0,split1,split2=tf.split(tf.transpose(net,perm=[3,1,2,0]),num_or_size_splits=3,axis=0)\n        net=tf.concat([split0,split1,split2],3)\n    return net\n\ndef compute_error(real,fake,label):\n    return tf.reduce_mean(label*tf.expand_dims(tf.reduce_mean(tf.abs(fake-real),reduction_indices=[3]),-1),reduction_indices=[1,2])#diversity loss\n\n#os.system(\'nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp\')\n#os.environ[\'CUDA_VISIBLE_DEVICES\']=str(np.argmax([int(x.split()[2]) for x in open(\'tmp\',\'r\').readlines()]))\n#os.system(\'rm tmp\')\nsess=tf.Session()\nsp=256 #input resolution is 256x512\nis_training=False\nwith tf.variable_scope(tf.get_variable_scope()):\n    label=tf.placeholder(tf.float32,[None,None,None,20])\n    real_image=tf.placeholder(tf.float32,[None,None,None,3])\n    fake_image=tf.placeholder(tf.float32,[None,None,None,3])\n    generator=recursive_generator(label,sp)\n    weight=tf.placeholder(tf.float32)\n    vgg_real=build_vgg19(real_image)\n    vgg_fake=build_vgg19(generator,reuse=True)\n    p0=compute_error(vgg_real[\'input\'],vgg_fake[\'input\'],label)\n    p1=compute_error(vgg_real[\'conv1_2\'],vgg_fake[\'conv1_2\'],label)/1.4\n    p2=compute_error(vgg_real[\'conv2_2\'],vgg_fake[\'conv2_2\'],tf.image.resize_area(label,(sp//2,sp)))/1.8\n    p3=compute_error(vgg_real[\'conv3_2\'],vgg_fake[\'conv3_2\'],tf.image.resize_area(label,(sp//4,sp//2)))/1.3\n    p4=compute_error(vgg_real[\'conv4_2\'],vgg_fake[\'conv4_2\'],tf.image.resize_area(label,(sp//8,sp//4)))/2.2\n    p5=compute_error(vgg_real[\'conv5_2\'],vgg_fake[\'conv5_2\'],tf.image.resize_area(label,(sp//16,sp//8)))*10/0.62\n    content_loss=p0+p1+p2+p3+p4+p5\n    G_loss=tf.reduce_sum(tf.reduce_min(content_loss,reduction_indices=0))*0.999+tf.reduce_sum(tf.reduce_mean(content_loss,reduction_indices=0))*0.001\n    t_vars=tf.trainable_variables()\n    lr=tf.placeholder(tf.float32)\nG_opt=tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss,var_list=[var for var in t_vars if var.name.startswith(\'g_\')])\nsaver=tf.train.Saver(max_to_keep=1000)\nsess.run(tf.global_variables_initializer())\nckpt=tf.train.get_checkpoint_state(""result_GTA"")\nif ckpt:\n    print(\'loaded \'+ckpt.model_checkpoint_path)\n    saver.restore(sess,ckpt.model_checkpoint_path)\n\nif is_training:\n    input_images=[None]*20000\n    label_images=[None]*20000\n    for epoch in range(1,401):\n        if os.path.isdir(""result_GTA/%04d""%epoch):\n            continue\n        g_loss=np.zeros(20000,dtype=float)\n        cnt=0\n        for ind in np.random.permutation(12403)+1:\n            st=time.time()\n            cnt+=1\n            if input_images[ind] is None:\n                label_images[ind]=helper.get_semantic_map(""data/GTA/Label256Full/%08d.png""%ind)\n                input_images[ind]=np.expand_dims(np.float32(scipy.misc.imread(""data/GTA/RGB256Full/%08d.png""%ind)),axis=0)\n            _,G_current,l0,l1,l2,l3,l4,l5=sess.run([G_opt,G_loss,p0,p1,p2,p3,p4,p5],feed_dict={label:np.concatenate((label_images[ind],np.expand_dims(1-np.sum(label_images[ind],axis=3),axis=3)),axis=3),real_image:input_images[ind],lr:1e-4})\n            g_loss[ind]=G_current\n            print(""%d %d %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f""%(epoch,cnt,np.mean(g_loss[np.where(g_loss)]),np.mean(l0),np.mean(l1),np.mean(l2),np.mean(l3),np.mean(l4),np.mean(l5),time.time()-st))\n            if cnt>3000:\n                break\n        os.makedirs(""result_GTA/%04d""%epoch)#save models\n        target=open(""result_GTA/%04d/score.txt""%epoch,\'w\')\n        target.write(""%f""%np.mean(g_loss[np.where(g_loss)]))\n        target.close()\n        saver.save(sess,""result_GTA/model.ckpt"")\n        if epoch%100==0:\n            saver.save(sess,""result_GTA/%04d/model.ckpt""%epoch)\n        for ind in range(12403-49,12403+1)+range(100001,100051):#print intermediate results\n            semantic=helper.get_semantic_map(""data/GTA/Label256Full/%08d.png""%ind)\n            output=sess.run(generator,feed_dict={label:np.concatenate((semantic,np.expand_dims(1-np.sum(semantic,axis=1),axis=1)),axis=1).transpose([0,2,3,1])})\n            output=np.minimum(np.maximum(output,0.0),255.0)\n            upper=np.concatenate((output[0,:,:,:],output[1,:,:,:],output[2,:,:,:]),axis=1)\n            middle=np.concatenate((output[3,:,:,:],output[4,:,:,:],output[5,:,:,:]),axis=1)\n            bottom=np.concatenate((output[6,:,:,:],output[7,:,:,:],output[8,:,:,:]),axis=1)\n            scipy.misc.toimage(np.concatenate((upper,middle,bottom),axis=0),cmin=0,cmax=255).save(""result_GTA/%04d/%06d_output.jpg""%(epoch,ind))\n\nif not os.path.isdir(""result_GTA/final""):\n    os.makedirs(""result_GTA/final"")\nfor ind in range(100001,106383):\n    if not os.path.isfile(""data/GTA/Label256Full/%08d.png""%ind):#test label\n        continue    \n    semantic=helper.get_semantic_map(""data/GTA/Label256Full/%08d.png""%ind)\n    st=time.time()\n    output=sess.run(generator,feed_dict={label:np.concatenate((semantic,np.expand_dims(1-np.sum(semantic,axis=3),axis=3)),axis=3)})\n    print(time.time()-st)\n    output=np.minimum(np.maximum(output,0.0),255.0)\n    upper=np.concatenate((output[0,:,:,:],output[1,:,:,:],output[2,:,:,:]),axis=1)\n    middle=np.concatenate((output[3,:,:,:],output[4,:,:,:],output[5,:,:,:]),axis=1)\n    bottom=np.concatenate((output[6,:,:,:],output[7,:,:,:],output[8,:,:,:]),axis=1)\n    scipy.misc.toimage(np.concatenate((upper,middle,bottom),axis=0),cmin=0,cmax=255).save(""result_GTA/final/%06d_output.png""%ind)\n'"
demo_1024p.py,28,"b'from __future__ import division\nimport os,helper,time,scipy.io\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\ndef lrelu(x):\n    return tf.maximum(0.2*x,x)\n\ndef build_net(ntype,nin,nwb=None,name=None):\n    if ntype==\'conv\':\n        return tf.nn.relu(tf.nn.conv2d(nin,nwb[0],strides=[1,1,1,1],padding=\'SAME\',name=name)+nwb[1])\n    elif ntype==\'pool\':\n        return tf.nn.avg_pool(nin,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\'SAME\')\n\ndef get_weight_bias(vgg_layers,i):\n    weights=vgg_layers[i][0][0][2][0][0]\n    weights=tf.constant(weights)\n    bias=vgg_layers[i][0][0][2][0][1]\n    bias=tf.constant(np.reshape(bias,(bias.size)))\n    return weights,bias\n\ndef build_vgg19(input,reuse=False):\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    net={}\n    vgg_rawnet=scipy.io.loadmat(\'VGG_Model/imagenet-vgg-verydeep-19.mat\')\n    vgg_layers=vgg_rawnet[\'layers\'][0]\n    net[\'input\']=input-np.array([123.6800, 116.7790, 103.9390]).reshape((1,1,1,3))\n    net[\'conv1_1\']=build_net(\'conv\',net[\'input\'],get_weight_bias(vgg_layers,0),name=\'vgg_conv1_1\')\n    net[\'conv1_2\']=build_net(\'conv\',net[\'conv1_1\'],get_weight_bias(vgg_layers,2),name=\'vgg_conv1_2\')\n    net[\'pool1\']=build_net(\'pool\',net[\'conv1_2\'])\n    net[\'conv2_1\']=build_net(\'conv\',net[\'pool1\'],get_weight_bias(vgg_layers,5),name=\'vgg_conv2_1\')\n    net[\'conv2_2\']=build_net(\'conv\',net[\'conv2_1\'],get_weight_bias(vgg_layers,7),name=\'vgg_conv2_2\')\n    net[\'pool2\']=build_net(\'pool\',net[\'conv2_2\'])\n    net[\'conv3_1\']=build_net(\'conv\',net[\'pool2\'],get_weight_bias(vgg_layers,10),name=\'vgg_conv3_1\')\n    net[\'conv3_2\']=build_net(\'conv\',net[\'conv3_1\'],get_weight_bias(vgg_layers,12),name=\'vgg_conv3_2\')\n    net[\'conv3_3\']=build_net(\'conv\',net[\'conv3_2\'],get_weight_bias(vgg_layers,14),name=\'vgg_conv3_3\')\n    net[\'conv3_4\']=build_net(\'conv\',net[\'conv3_3\'],get_weight_bias(vgg_layers,16),name=\'vgg_conv3_4\')\n    net[\'pool3\']=build_net(\'pool\',net[\'conv3_4\'])\n    net[\'conv4_1\']=build_net(\'conv\',net[\'pool3\'],get_weight_bias(vgg_layers,19),name=\'vgg_conv4_1\')\n    net[\'conv4_2\']=build_net(\'conv\',net[\'conv4_1\'],get_weight_bias(vgg_layers,21),name=\'vgg_conv4_2\')\n    net[\'conv4_3\']=build_net(\'conv\',net[\'conv4_2\'],get_weight_bias(vgg_layers,23),name=\'vgg_conv4_3\')\n    net[\'conv4_4\']=build_net(\'conv\',net[\'conv4_3\'],get_weight_bias(vgg_layers,25),name=\'vgg_conv4_4\')\n    net[\'pool4\']=build_net(\'pool\',net[\'conv4_4\'])\n    net[\'conv5_1\']=build_net(\'conv\',net[\'pool4\'],get_weight_bias(vgg_layers,28),name=\'vgg_conv5_1\')\n    net[\'conv5_2\']=build_net(\'conv\',net[\'conv5_1\'],get_weight_bias(vgg_layers,30),name=\'vgg_conv5_2\')\n    return net\n\ndef recursive_generator(label,sp):\n    dim=512 if sp>=128 else 1024\n    if sp==512:\n        dim=128\n    if sp==1024:\n        dim=32\n    if sp==4:\n        input=label\n    else:\n        downsampled=tf.image.resize_area(label,(sp//2,sp),align_corners=False)\n        input=tf.concat([tf.image.resize_bilinear(recursive_generator(downsampled,sp//2),(sp,sp*2),align_corners=True),label],3)\n    net=slim.conv2d(input,dim,[3,3],rate=1,normalizer_fn=slim.layer_norm,activation_fn=lrelu,scope=\'g_\'+str(sp)+\'_conv1\')\n    net=slim.conv2d(net,dim,[3,3],rate=1,normalizer_fn=slim.layer_norm,activation_fn=lrelu,scope=\'g_\'+str(sp)+\'_conv2\')\n    if sp==1024:\n        net=slim.conv2d(net,3,[1,1],rate=1,activation_fn=None,scope=\'g_\'+str(sp)+\'_conv100\')\n        net=(net+1.0)/2.0*255.0\n    return net\n\ndef compute_error(real,fake,label):\n    #return tf.reduce_sum(tf.reduce_mean(label*tf.expand_dims(tf.reduce_mean(tf.abs(fake-real),reduction_indices=[3]),-1),reduction_indices=[1,2]))#diversity loss\n    return tf.reduce_mean(tf.abs(fake-real))#simple loss\n\n#os.system(\'nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp\')\n#os.environ[\'CUDA_VISIBLE_DEVICES\']=str(np.argmax([int(x.split()[2]) for x in open(\'tmp\',\'r\').readlines()]))#select a GPU with maximum available memory\n#os.system(\'rm tmp\')\nsess=tf.Session()\nis_training=False\nsp=1024#spatial resolution: 1024x2048\nwith tf.variable_scope(tf.get_variable_scope()):\n    label=tf.placeholder(tf.float32,[None,None,None,20])\n    real_image=tf.placeholder(tf.float32,[None,None,None,3])\n    fake_image=tf.placeholder(tf.float32,[None,None,None,3])\n    generator=recursive_generator(label,sp)\n    weight=tf.placeholder(tf.float32)\n    vgg_real=build_vgg19(real_image)\n    vgg_fake=build_vgg19(generator,reuse=True)\n    p0=compute_error(vgg_real[\'input\'],vgg_fake[\'input\'],label)\n    p1=compute_error(vgg_real[\'conv1_2\'],vgg_fake[\'conv1_2\'],label)/2.6\n    p2=compute_error(vgg_real[\'conv2_2\'],vgg_fake[\'conv2_2\'],tf.image.resize_area(label,(sp//2,sp)))/4.8\n    p3=compute_error(vgg_real[\'conv3_2\'],vgg_fake[\'conv3_2\'],tf.image.resize_area(label,(sp//4,sp//2)))/3.7\n    p4=compute_error(vgg_real[\'conv4_2\'],vgg_fake[\'conv4_2\'],tf.image.resize_area(label,(sp//8,sp//4)))/5.6\n    p5=compute_error(vgg_real[\'conv5_2\'],vgg_fake[\'conv5_2\'],tf.image.resize_area(label,(sp//16,sp//8)))*10/1.5\n    G_loss=p0+p1+p2+p3+p4+p5\nlr=tf.placeholder(tf.float32)\nG_opt=tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss,var_list=[var for var in tf.trainable_variables() if var.name.startswith(\'g_1024\') or var.name.startswith(\'g_512\')])#only fine-tune the last two refinement module due to memory limitation\nsess.run(tf.global_variables_initializer())\nckpt=tf.train.get_checkpoint_state(""result_1024p"")\nif ckpt:\n    print(\'loaded \'+ckpt.model_checkpoint_path)\n    saver=tf.train.Saver(var_list=[var for var in tf.trainable_variables() if var.name.startswith(\'g_\')])\n    saver.restore(sess,ckpt.model_checkpoint_path)\nelse:\n    ckpt_prev=tf.train.get_checkpoint_state(""result_512p"")\n    saver=tf.train.Saver(var_list=[var for var in tf.trainable_variables() if var.name.startswith(\'g_\') and not var.name.startswith(\'g_1024\')])\n    print(\'loaded \'+ckpt_prev.model_checkpoint_path)\n    saver.restore(sess,ckpt_prev.model_checkpoint_path)\nsaver=tf.train.Saver(max_to_keep=1000)\n\nif is_training:\n    g_loss=np.zeros(3000,dtype=float)\n    input_images=[None]*3000\n    label_images=[None]*3000\n    for epoch in range(1,6):\n        if os.path.isdir(""result_1024p/%04d""%epoch):\n            continue\n        cnt=0\n        for ind in np.random.permutation(2975)+1:\n            st=time.time()\n            cnt+=1\n            if input_images[ind] is None:\n                label_images[ind]=helper.get_semantic_map(""data/cityscapes/Label1024Full/%08d.png""%ind)#training label\n                input_images[ind]=np.expand_dims(np.float32(scipy.misc.imread(""data/cityscapes/RGB1024Full_vivid/%08d.png""%ind)),axis=0)#training image with vivid appearance. see ""optional_preprocessing""\n            _,G_current,l0,l1,l2,l3,l4,l5=sess.run([G_opt,G_loss,p0,p1,p2,p3,p4,p5],feed_dict={label:np.concatenate((label_images[ind],np.expand_dims(1-np.sum(label_images[ind],axis=3),axis=3)),axis=3),real_image:input_images[ind],lr:1e-4})\n            g_loss[ind]=G_current\n            print(""%d %d %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f""%(epoch,cnt,np.mean(g_loss[np.where(g_loss)]),np.mean(l0),np.mean(l1),np.mean(l2),np.mean(l3),np.mean(l4),np.mean(l5),time.time()-st))\n        os.makedirs(""result_1024p/%04d""%epoch)\n        target=open(""result_1024p/%04d/score.txt""%epoch,\'w\')\n        target.write(""%f""%np.mean(g_loss[np.where(g_loss)]))\n        target.close()\n        saver.save(sess,""result_1024p/model.ckpt"")\n        if epoch%20==0:\n            saver.save(sess,""result_1024p/%04d/model.ckpt""%epoch)\n        for ind in range(100001,100051):\n            if not os.path.isfile(""data/cityscapes/Label1024Full/%08d.png""%ind):#test label\n                continue            \n            semantic=helper.get_semantic_map(""data/cityscapes/Label1024Full/%08d.png""%ind)#test label\n            output=sess.run(generator,feed_dict={label:np.concatenate((semantic,np.expand_dims(1-np.sum(semantic,axis=3),axis=3)),axis=3)})\n            output=np.minimum(np.maximum(output,0.0),255.0)\n            scipy.misc.toimage(output[0,:,:,:],cmin=0,cmax=255).save(""result_1024p/%04d/%06d_output.jpg""%(epoch,ind))\n\nif not os.path.isdir(""result_1024p/final""):\n    os.makedirs(""result_1024p/final"")\nfor ind in range(100001,100501):\n    if not os.path.isfile(""data/cityscapes/Label1024Full/%08d.png""%ind):#test label\n        continue    \n    semantic=helper.get_semantic_map(""data/cityscapes/Label1024Full/%08d.png""%ind)#test label\n    output=sess.run(generator,feed_dict={label:np.concatenate((semantic,np.expand_dims(1-np.sum(semantic,axis=3),axis=3)),axis=3)})\n    output=np.minimum(np.maximum(output,0.0),255.0)\n    scipy.misc.toimage(output[0,:,:,:],cmin=0,cmax=255).save(""result_1024p/final/%06d_output.jpg""%ind)\n'"
demo_256p.py,27,"b'from __future__ import division\nimport os,helper,time,scipy.io\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\ndef lrelu(x):\n    return tf.maximum(0.2*x,x)\n\ndef build_net(ntype,nin,nwb=None,name=None):\n    if ntype==\'conv\':\n        return tf.nn.relu(tf.nn.conv2d(nin,nwb[0],strides=[1,1,1,1],padding=\'SAME\',name=name)+nwb[1])\n    elif ntype==\'pool\':\n        return tf.nn.avg_pool(nin,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\'SAME\')\n\ndef get_weight_bias(vgg_layers,i):\n    weights=vgg_layers[i][0][0][2][0][0]\n    weights=tf.constant(weights)\n    bias=vgg_layers[i][0][0][2][0][1]\n    bias=tf.constant(np.reshape(bias,(bias.size)))\n    return weights,bias\n\ndef build_vgg19(input,reuse=False):\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    net={}\n    vgg_rawnet=scipy.io.loadmat(\'VGG_Model/imagenet-vgg-verydeep-19.mat\')\n    vgg_layers=vgg_rawnet[\'layers\'][0]\n    net[\'input\']=input-np.array([123.6800, 116.7790, 103.9390]).reshape((1,1,1,3))\n    net[\'conv1_1\']=build_net(\'conv\',net[\'input\'],get_weight_bias(vgg_layers,0),name=\'vgg_conv1_1\')\n    net[\'conv1_2\']=build_net(\'conv\',net[\'conv1_1\'],get_weight_bias(vgg_layers,2),name=\'vgg_conv1_2\')\n    net[\'pool1\']=build_net(\'pool\',net[\'conv1_2\'])\n    net[\'conv2_1\']=build_net(\'conv\',net[\'pool1\'],get_weight_bias(vgg_layers,5),name=\'vgg_conv2_1\')\n    net[\'conv2_2\']=build_net(\'conv\',net[\'conv2_1\'],get_weight_bias(vgg_layers,7),name=\'vgg_conv2_2\')\n    net[\'pool2\']=build_net(\'pool\',net[\'conv2_2\'])\n    net[\'conv3_1\']=build_net(\'conv\',net[\'pool2\'],get_weight_bias(vgg_layers,10),name=\'vgg_conv3_1\')\n    net[\'conv3_2\']=build_net(\'conv\',net[\'conv3_1\'],get_weight_bias(vgg_layers,12),name=\'vgg_conv3_2\')\n    net[\'conv3_3\']=build_net(\'conv\',net[\'conv3_2\'],get_weight_bias(vgg_layers,14),name=\'vgg_conv3_3\')\n    net[\'conv3_4\']=build_net(\'conv\',net[\'conv3_3\'],get_weight_bias(vgg_layers,16),name=\'vgg_conv3_4\')\n    net[\'pool3\']=build_net(\'pool\',net[\'conv3_4\'])\n    net[\'conv4_1\']=build_net(\'conv\',net[\'pool3\'],get_weight_bias(vgg_layers,19),name=\'vgg_conv4_1\')\n    net[\'conv4_2\']=build_net(\'conv\',net[\'conv4_1\'],get_weight_bias(vgg_layers,21),name=\'vgg_conv4_2\')\n    net[\'conv4_3\']=build_net(\'conv\',net[\'conv4_2\'],get_weight_bias(vgg_layers,23),name=\'vgg_conv4_3\')\n    net[\'conv4_4\']=build_net(\'conv\',net[\'conv4_3\'],get_weight_bias(vgg_layers,25),name=\'vgg_conv4_4\')\n    net[\'pool4\']=build_net(\'pool\',net[\'conv4_4\'])\n    net[\'conv5_1\']=build_net(\'conv\',net[\'pool4\'],get_weight_bias(vgg_layers,28),name=\'vgg_conv5_1\')\n    net[\'conv5_2\']=build_net(\'conv\',net[\'conv5_1\'],get_weight_bias(vgg_layers,30),name=\'vgg_conv5_2\')\n    net[\'conv5_3\']=build_net(\'conv\',net[\'conv5_2\'],get_weight_bias(vgg_layers,32),name=\'vgg_conv5_3\')\n    net[\'conv5_4\']=build_net(\'conv\',net[\'conv5_3\'],get_weight_bias(vgg_layers,34),name=\'vgg_conv5_4\')\n    net[\'pool5\']=build_net(\'pool\',net[\'conv5_4\'])\n    return net\n\ndef recursive_generator(label,sp):\n    dim=512 if sp>=128 else 1024\n    if sp==4:\n        input=label\n    else:\n        downsampled=tf.image.resize_area(label,(sp//2,sp),align_corners=False)\n        input=tf.concat([tf.image.resize_bilinear(recursive_generator(downsampled,sp//2),(sp,sp*2),align_corners=True),label],3)\n    net=slim.conv2d(input,dim,[3,3],rate=1,normalizer_fn=slim.layer_norm,activation_fn=lrelu,scope=\'g_\'+str(sp)+\'_conv1\')\n    net=slim.conv2d(net,dim,[3,3],rate=1,normalizer_fn=slim.layer_norm,activation_fn=lrelu,scope=\'g_\'+str(sp)+\'_conv2\')\n    if sp==256:\n        net=slim.conv2d(net,27,[1,1],rate=1,activation_fn=None,scope=\'g_\'+str(sp)+\'_conv100\')\n        net=(net+1.0)/2.0*255.0\n        split0,split1,split2=tf.split(tf.transpose(net,perm=[3,1,2,0]),num_or_size_splits=3,axis=0)\n        net=tf.concat([split0,split1,split2],3)\n    return net\n\ndef compute_error(real,fake,label):\n    return tf.reduce_mean(label*tf.expand_dims(tf.reduce_mean(tf.abs(fake-real),reduction_indices=[3]),-1),reduction_indices=[1,2])#diversity loss\n\n#os.system(\'nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp\')\n#os.environ[\'CUDA_VISIBLE_DEVICES\']=str(np.argmax([int(x.split()[2]) for x in open(\'tmp\',\'r\').readlines()]))#select a GPU with maximum available memory\n#os.system(\'rm tmp\')\nsess=tf.Session()\nis_training=False\nsp=256#spatial resolution: 256x512\nwith tf.variable_scope(tf.get_variable_scope()):\n    label=tf.placeholder(tf.float32,[None,None,None,20])\n    real_image=tf.placeholder(tf.float32,[None,None,None,3])\n    fake_image=tf.placeholder(tf.float32,[None,None,None,3])\n    generator=recursive_generator(label,sp)\n    weight=tf.placeholder(tf.float32)\n    vgg_real=build_vgg19(real_image)\n    vgg_fake=build_vgg19(generator,reuse=True)\n    p0=compute_error(vgg_real[\'input\'],vgg_fake[\'input\'],label)\n    p1=compute_error(vgg_real[\'conv1_2\'],vgg_fake[\'conv1_2\'],label)/1.6\n    p2=compute_error(vgg_real[\'conv2_2\'],vgg_fake[\'conv2_2\'],tf.image.resize_area(label,(sp//2,sp)))/2.3\n    p3=compute_error(vgg_real[\'conv3_2\'],vgg_fake[\'conv3_2\'],tf.image.resize_area(label,(sp//4,sp//2)))/1.8\n    p4=compute_error(vgg_real[\'conv4_2\'],vgg_fake[\'conv4_2\'],tf.image.resize_area(label,(sp//8,sp//4)))/2.8\n    p5=compute_error(vgg_real[\'conv5_2\'],vgg_fake[\'conv5_2\'],tf.image.resize_area(label,(sp//16,sp//8)))*10/0.8#weights lambda are collected at 100th epoch\n    content_loss=p0+p1+p2+p3+p4+p5\n    G_loss=tf.reduce_sum(tf.reduce_min(content_loss,reduction_indices=0))*0.999+tf.reduce_sum(tf.reduce_mean(content_loss,reduction_indices=0))*0.001\nlr=tf.placeholder(tf.float32)\nG_opt=tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss,var_list=[var for var in tf.trainable_variables() if var.name.startswith(\'g_\')])\nsaver=tf.train.Saver(max_to_keep=1000)\nsess.run(tf.global_variables_initializer())\nckpt=tf.train.get_checkpoint_state(""result_256p"")\nif ckpt:\n    print(\'loaded \'+ckpt.model_checkpoint_path)\n    saver.restore(sess,ckpt.model_checkpoint_path)\n\nif is_training:\n    g_loss=np.zeros(3000,dtype=float)\n    input_images=[None]*3000\n    label_images=[None]*3000\n    for epoch in range(1,201):\n        if os.path.isdir(""result_256p/%04d""%epoch):\n            continue\n        cnt=0\n        for ind in np.random.permutation(2975)+1:\n            st=time.time()\n            cnt+=1\n            if input_images[ind] is None:\n                label_images[ind]=helper.get_semantic_map(""data/cityscapes/Label256Full/%08d.png""%ind)#training label\n                input_images[ind]=np.expand_dims(np.float32(scipy.misc.imread(""data/cityscapes/RGB256Full/%08d.png""%ind)),axis=0)#training image\n            _,G_current,l0,l1,l2,l3,l4,l5=sess.run([G_opt,G_loss,p0,p1,p2,p3,p4,p5],feed_dict={label:np.concatenate((label_images[ind],np.expand_dims(1-np.sum(label_images[ind],axis=3),axis=3)),axis=3),real_image:input_images[ind],lr:1e-4})#may try lr:min(1e-6*np.power(1.1,epoch-1),1e-4 if epoch>100 else 1e-3) in case lr:1e-4 is not good\n            g_loss[ind]=G_current\n            print(""%d %d %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f""%(epoch,cnt,np.mean(g_loss[np.where(g_loss)]),np.mean(l0),np.mean(l1),np.mean(l2),np.mean(l3),np.mean(l4),np.mean(l5),time.time()-st))\n        os.makedirs(""result_256p/%04d""%epoch)\n        target=open(""result_256p/%04d/score.txt""%epoch,\'w\')\n        target.write(""%f""%np.mean(g_loss[np.where(g_loss)]))\n        target.close()\n        saver.save(sess,""result_256p/model.ckpt"")\n        if epoch%20==0:\n            saver.save(sess,""result_256p/%04d/model.ckpt""%epoch)\n        for ind in range(100001,100051):\n            if not os.path.isfile(""data/cityscapes/Label256Full/%08d.png""%ind):#test label\n                continue\n            semantic=helper.get_semantic_map(""data/cityscapes/Label256Full/%08d.png""%ind)#test label\n            output=sess.run(generator,feed_dict={label:np.concatenate((semantic,np.expand_dims(1-np.sum(semantic,axis=3),axis=3)),axis=3)})\n            output=np.minimum(np.maximum(output,0.0),255.0)\n            upper=np.concatenate((output[0,:,:,:],output[1,:,:,:],output[2,:,:,:]),axis=1)\n            middle=np.concatenate((output[3,:,:,:],output[4,:,:,:],output[5,:,:,:]),axis=1)\n            bottom=np.concatenate((output[6,:,:,:],output[7,:,:,:],output[8,:,:,:]),axis=1)\n            scipy.misc.toimage(np.concatenate((upper,middle,bottom),axis=0),cmin=0,cmax=255).save(""result_256p/%04d/%06d_output.jpg""%(epoch,ind))\n\nif not os.path.isdir(""result_256p/final""):\n    os.makedirs(""result_256p/final"")\nfor ind in range(100001,100501):\n    if not os.path.isfile(""data/cityscapes/Label256Full/%08d.png""%ind):#test label\n        continue\n    semantic=helper.get_semantic_map(""data/cityscapes/Label256Full/%08d.png""%ind)#test label\n    output=sess.run(generator,feed_dict={label:np.concatenate((semantic,np.expand_dims(1-np.sum(semantic,axis=3),axis=3)),axis=3)})\n    output=np.minimum(np.maximum(output, 0.0), 255.0)\n    upper=np.concatenate((output[0,:,:,:],output[1,:,:,:],output[2,:,:,:]),axis=1)\n    middle=np.concatenate((output[3,:,:,:],output[4,:,:,:],output[5,:,:,:]),axis=1)\n    bottom=np.concatenate((output[6,:,:,:],output[7,:,:,:],output[8,:,:,:]),axis=1)\n    scipy.misc.toimage(np.concatenate((upper,middle,bottom),axis=0),cmin=0,cmax=255).save(""result_256p/final/%06d_output.jpg""%ind)\n'"
demo_512p.py,28,"b'from __future__ import division\nimport os,helper,time,scipy.io\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\nimport numpy as np\n\ndef lrelu(x):\n    return tf.maximum(0.2*x,x)\n\ndef build_net(ntype,nin,nwb=None,name=None):\n    if ntype==\'conv\':\n        return tf.nn.relu(tf.nn.conv2d(nin,nwb[0],strides=[1,1,1,1],padding=\'SAME\',name=name)+nwb[1])\n    elif ntype==\'pool\':\n        return tf.nn.avg_pool(nin,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\'SAME\')\n\ndef get_weight_bias(vgg_layers,i):\n    weights=vgg_layers[i][0][0][2][0][0]\n    weights=tf.constant(weights)\n    bias=vgg_layers[i][0][0][2][0][1]\n    bias=tf.constant(np.reshape(bias,(bias.size)))\n    return weights,bias\n\ndef build_vgg19(input,reuse=False):\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    net={}\n    vgg_rawnet=scipy.io.loadmat(\'VGG_Model/imagenet-vgg-verydeep-19.mat\')\n    vgg_layers=vgg_rawnet[\'layers\'][0]\n    net[\'input\']=input-np.array([123.6800, 116.7790, 103.9390]).reshape((1,1,1,3))\n    net[\'conv1_1\']=build_net(\'conv\',net[\'input\'],get_weight_bias(vgg_layers,0),name=\'vgg_conv1_1\')\n    net[\'conv1_2\']=build_net(\'conv\',net[\'conv1_1\'],get_weight_bias(vgg_layers,2),name=\'vgg_conv1_2\')\n    net[\'pool1\']=build_net(\'pool\',net[\'conv1_2\'])\n    net[\'conv2_1\']=build_net(\'conv\',net[\'pool1\'],get_weight_bias(vgg_layers,5),name=\'vgg_conv2_1\')\n    net[\'conv2_2\']=build_net(\'conv\',net[\'conv2_1\'],get_weight_bias(vgg_layers,7),name=\'vgg_conv2_2\')\n    net[\'pool2\']=build_net(\'pool\',net[\'conv2_2\'])\n    net[\'conv3_1\']=build_net(\'conv\',net[\'pool2\'],get_weight_bias(vgg_layers,10),name=\'vgg_conv3_1\')\n    net[\'conv3_2\']=build_net(\'conv\',net[\'conv3_1\'],get_weight_bias(vgg_layers,12),name=\'vgg_conv3_2\')\n    net[\'conv3_3\']=build_net(\'conv\',net[\'conv3_2\'],get_weight_bias(vgg_layers,14),name=\'vgg_conv3_3\')\n    net[\'conv3_4\']=build_net(\'conv\',net[\'conv3_3\'],get_weight_bias(vgg_layers,16),name=\'vgg_conv3_4\')\n    net[\'pool3\']=build_net(\'pool\',net[\'conv3_4\'])\n    net[\'conv4_1\']=build_net(\'conv\',net[\'pool3\'],get_weight_bias(vgg_layers,19),name=\'vgg_conv4_1\')\n    net[\'conv4_2\']=build_net(\'conv\',net[\'conv4_1\'],get_weight_bias(vgg_layers,21),name=\'vgg_conv4_2\')\n    net[\'conv4_3\']=build_net(\'conv\',net[\'conv4_2\'],get_weight_bias(vgg_layers,23),name=\'vgg_conv4_3\')\n    net[\'conv4_4\']=build_net(\'conv\',net[\'conv4_3\'],get_weight_bias(vgg_layers,25),name=\'vgg_conv4_4\')\n    net[\'pool4\']=build_net(\'pool\',net[\'conv4_4\'])\n    net[\'conv5_1\']=build_net(\'conv\',net[\'pool4\'],get_weight_bias(vgg_layers,28),name=\'vgg_conv5_1\')\n    net[\'conv5_2\']=build_net(\'conv\',net[\'conv5_1\'],get_weight_bias(vgg_layers,30),name=\'vgg_conv5_2\')\n    return net\n\ndef recursive_generator(label,sp):\n    dim=512 if sp>=128 else 1024\n    if sp==512:\n        dim=128\n    if sp==4:\n        input=label\n    else:\n        downsampled=tf.image.resize_area(label,(sp//2,sp),align_corners=False)\n        input=tf.concat([tf.image.resize_bilinear(recursive_generator(downsampled,sp//2),(sp,sp*2),align_corners=True),label],3)\n    net=slim.conv2d(input,dim,[3,3],rate=1,normalizer_fn=slim.layer_norm,activation_fn=lrelu,scope=\'g_\'+str(sp)+\'_conv1\')\n    net=slim.conv2d(net,dim,[3,3],rate=1,normalizer_fn=slim.layer_norm,activation_fn=lrelu,scope=\'g_\'+str(sp)+\'_conv2\')\n    if sp==512:\n        net=slim.conv2d(net,3,[1,1],rate=1,activation_fn=None,scope=\'g_\'+str(sp)+\'_conv100\')\n        net=(net+1.0)/2.0*255.0\n    return net\n\ndef compute_error(real,fake,label):\n    #return tf.reduce_sum(tf.reduce_mean(label*tf.expand_dims(tf.reduce_mean(tf.abs(fake-real),reduction_indices=[3]),-1),reduction_indices=[1,2]))#diversity loss\n    return tf.reduce_mean(tf.abs(fake-real))#simple loss\n\n#os.system(\'nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp\')\n#os.environ[\'CUDA_VISIBLE_DEVICES\']=str(np.argmax([int(x.split()[2]) for x in open(\'tmp\',\'r\').readlines()]))#select a GPU with maximum available memory\n#os.system(\'rm tmp\')\nsess=tf.Session()\nis_training=False\nsp=512#spatial resolution: 512x1024\nwith tf.variable_scope(tf.get_variable_scope()):\n    label=tf.placeholder(tf.float32,[None,None,None,20])\n    real_image=tf.placeholder(tf.float32,[None,None,None,3])\n    fake_image=tf.placeholder(tf.float32,[None,None,None,3])\n    generator=recursive_generator(label,sp)\n    weight=tf.placeholder(tf.float32)\n    vgg_real=build_vgg19(real_image)\n    vgg_fake=build_vgg19(generator,reuse=True)\n    p0=compute_error(vgg_real[\'input\'],vgg_fake[\'input\'],label)\n    p1=compute_error(vgg_real[\'conv1_2\'],vgg_fake[\'conv1_2\'],label)/2.6\n    p2=compute_error(vgg_real[\'conv2_2\'],vgg_fake[\'conv2_2\'],tf.image.resize_area(label,(sp//2,sp)))/4.8\n    p3=compute_error(vgg_real[\'conv3_2\'],vgg_fake[\'conv3_2\'],tf.image.resize_area(label,(sp//4,sp//2)))/3.7\n    p4=compute_error(vgg_real[\'conv4_2\'],vgg_fake[\'conv4_2\'],tf.image.resize_area(label,(sp//8,sp//4)))/5.6\n    p5=compute_error(vgg_real[\'conv5_2\'],vgg_fake[\'conv5_2\'],tf.image.resize_area(label,(sp//16,sp//8)))*10/1.5\n    G_loss=p0+p1+p2+p3+p4+p5\nlr=tf.placeholder(tf.float32)\nG_opt=tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss,var_list=[var for var in tf.trainable_variables()])\nsess.run(tf.global_variables_initializer())\nckpt=tf.train.get_checkpoint_state(""result_512p"")\nif ckpt:\n    print(\'loaded \'+ckpt.model_checkpoint_path)\n    saver=tf.train.Saver(var_list=[var for var in tf.trainable_variables() if var.name.startswith(\'g_\')])\n    saver.restore(sess,ckpt.model_checkpoint_path)\nelse:\n    ckpt_prev=tf.train.get_checkpoint_state(""result_256p"")\n    saver=tf.train.Saver(var_list=[var for var in tf.trainable_variables() if var.name.startswith(\'g_\') and not var.name.startswith(\'g_512\')])\n    print(\'loaded \'+ckpt_prev.model_checkpoint_path)\n    saver.restore(sess,ckpt_prev.model_checkpoint_path)\nsaver=tf.train.Saver(max_to_keep=1000)\n\nif is_training:\n    g_loss=np.zeros(3000,dtype=float)\n    input_images=[None]*3000\n    label_images=[None]*3000\n    for epoch in range(1,21):\n        if os.path.isdir(""result_512p/%04d""%epoch):\n            continue\n        cnt=0\n        for ind in np.random.permutation(2975)+1:\n            st=time.time()\n            cnt+=1\n            if input_images[ind] is None:\n                label_images[ind]=helper.get_semantic_map(""data/cityscapes/Label512Full/%08d.png""%ind)#training label\n                input_images[ind]=np.expand_dims(np.float32(scipy.misc.imread(""data/cityscapes/RGB512Full_vivid/%08d.png""%ind)),axis=0)#training image with vivid appearance. see ""optional_preprocessing""\n            _,G_current,l0,l1,l2,l3,l4,l5=sess.run([G_opt,G_loss,p0,p1,p2,p3,p4,p5],feed_dict={label:np.concatenate((label_images[ind],np.expand_dims(1-np.sum(label_images[ind],axis=3),axis=3)),axis=3),real_image:input_images[ind],lr:1e-4})\n            g_loss[ind]=G_current\n            print(""%d %d %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f""%(epoch,cnt,np.mean(g_loss[np.where(g_loss)]),np.mean(l0),np.mean(l1),np.mean(l2),np.mean(l3),np.mean(l4),np.mean(l5),time.time()-st))\n        os.makedirs(""result_512p/%04d""%epoch)\n        target=open(""result_512p/%04d/score.txt""%epoch,\'w\')\n        target.write(""%f""%np.mean(g_loss[np.where(g_loss)]))\n        target.close()\n        saver.save(sess,""result_512p/model.ckpt"")\n        if epoch%20==0:\n            saver.save(sess,""result_512p/%04d/model.ckpt""%epoch)\n        for ind in range(100001,100051):\n            if not os.path.isfile(""data/cityscapes/Label512Full/%08d.png""%ind):#test label\n                continue            \n            semantic=helper.get_semantic_map(""data/cityscapes/Label512Full/%08d.png""%ind)#test label\n            output=sess.run(generator,feed_dict={label:np.concatenate((semantic,np.expand_dims(1-np.sum(semantic,axis=3),axis=3)),axis=3)})\n            output=np.minimum(np.maximum(output,0.0),255.0)\n            scipy.misc.toimage(output[0,:,:,:],cmin=0,cmax=255).save(""result_512p/%04d/%06d_output.jpg""%(epoch,ind))\n\nif not os.path.isdir(""result_512p/final""):\n    os.makedirs(""result_512p/final"")\nfor ind in range(100001,100501):\n    if not os.path.isfile(""data/cityscapes/Label512Full/%08d.png""%ind):#test label\n        continue    \n    semantic=helper.get_semantic_map(""data/cityscapes/Label512Full/%08d.png""%ind)#test label\n    output=sess.run(generator,feed_dict={label:np.concatenate((semantic,np.expand_dims(1-np.sum(semantic,axis=3),axis=3)),axis=3)})\n    output=np.minimum(np.maximum(output,0.0),255.0)\n    scipy.misc.toimage(output[0,:,:,:],cmin=0,cmax=255).save(""result_512p/final/%06d_output.jpg""%ind)\n'"
download_models.py,0,"b'import requests\n\ndef download_file_from_google_drive(id, destination):\n    URL = ""https://docs.google.com/uc?export=download""\n\n    session = requests.Session()\n\n    response = session.get(URL, params = { \'id\' : id }, stream = True)\n    token = get_confirm_token(response)\n\n    if token:\n        params = { \'id\' : id, \'confirm\' : token }\n        response = session.get(URL, params = params, stream = True)\n\n    save_response_content(response, destination)    \n\ndef get_confirm_token(response):\n    for key, value in response.cookies.items():\n        if key.startswith(\'download_warning\'):\n            return value\n\n    return None\n\ndef save_response_content(response, destination):\n    CHUNK_SIZE = 32768\n\n    with open(destination, ""wb"") as f:\n        for chunk in response.iter_content(CHUNK_SIZE):\n            if chunk: # filter out keep-alive new chunks\n                f.write(chunk)\n\nprint(\'Dowloading VGG-19 Model (510Mb)\')\ndownload_file_from_google_drive(\'0B_B_FOgPxgFLRjdEdE9NNTlzUWc\', \'VGG_Model/imagenet-vgg-verydeep-19.mat\')\n\nprint(\'Dowloading CRN 1024p Model (500Mb)\')\ndownload_file_from_google_drive(\'0B_B_FOgPxgFLLXdaaU5yR0ZKaU0\', \'result_1024p/model.ckpt.data-00000-of-00001\')\ndownload_file_from_google_drive(\'0B_B_FOgPxgFLVlhkTmJUbDZNdDg\', \'result_1024p/model.ckpt.meta\')\n\nprint(\'Dowloading CRN 512p Model (1.2Gb)\')\ndownload_file_from_google_drive(\'0B_B_FOgPxgFLNjBMRjZWNjVyS1E\', \'result_512p/model.ckpt.data-00000-of-00001\')\ndownload_file_from_google_drive(\'0B_B_FOgPxgFLdENlSE9zbjJTbjg\', \'result_512p/model.ckpt.meta\')\n\nprint(\'Dowloading CRN 256p Model (1.2Gb)\')\ndownload_file_from_google_drive(\'0B_B_FOgPxgFLLUVQTEg0alRWNDQ\', \'result_256p/model.ckpt.data-00000-of-00001\')\ndownload_file_from_google_drive(\'0B_B_FOgPxgFLM0NjR2QxSUg5SWM\', \'result_256p/model.ckpt.meta\')\n\nprint(\'Downloading GTA 256p Model (1.2Gb)\')\ndownload_file_from_google_drive(\'0B_B_FOgPxgFLTVl2MWxpOGtzczA\',\'result_GTA/model.ckpt.data-00000-of-00001\')\ndownload_file_from_google_drive(\'0B_B_FOgPxgFLSThjb2hzSHM2Qzg\',\'result_GTA/model.ckpt.meta\')\n\nprint(\'Downloading GTA 256p Model (1.2Gb)\')\ndownload_file_from_google_drive(\'0B_B_FOgPxgFLTVl2MWxpOGtzczA\',\'result_GTA/model.ckpt.data-00000-of-00001\')\ndownload_file_from_google_drive(\'0B_B_FOgPxgFLSThjb2hzSHM2Qzg\',\'result_GTA/model.ckpt.meta\')\n\n'"
helper.py,0,"b""import os,numpy as np\nfrom os.path import dirname, exists, join, splitext\nimport json,scipy\nclass Dataset(object):\n    def __init__(self, dataset_name):\n        self.work_dir = dirname(os.path.realpath('__file__'))\n        info_path = join(self.work_dir, 'datasets', dataset_name + '.json')\n        with open(info_path, 'r') as fp:\n            info = json.load(fp)\n        self.palette = np.array(info['palette'], dtype=np.uint8)\n\n\ndef get_semantic_map(path):\n    dataset=Dataset('cityscapes')\n    semantic=scipy.misc.imread(path)\n    tmp=np.zeros((semantic.shape[0],semantic.shape[1],dataset.palette.shape[0]),dtype=np.float32)\n    for k in range(dataset.palette.shape[0]):\n        tmp[:,:,k]=np.float32((semantic[:,:,0]==dataset.palette[k,0])&(semantic[:,:,1]==dataset.palette[k,1])&(semantic[:,:,2]==dataset.palette[k,2]))\n    return tmp.reshape((1,)+tmp.shape)\n\ndef print_semantic_map(semantic,path):\n    dataset=Dataset('cityscapes')\n    semantic=semantic.transpose([1,2,3,0])\n    prediction=np.argmax(semantic,axis=2)\n    color_image=dataset.palette[prediction.ravel()].reshape((prediction.shape[0],prediction.shape[1],3))\n    row,col,dump=np.where(np.sum(semantic,axis=2)==0)\n    color_image[row,col,:]=0\n    scipy.misc.imsave(path,color_image)\n"""
