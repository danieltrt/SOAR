file_path,api_count,code
Tensorflow/TensorflowUtil.py,23,"b'#!/usr/bin/env python\n""""""\nCopyright (c) 2017, Ryan Dellana\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of Ryan Dellana nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL Ryan Dellana BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n""""""\n\n\nimport tensorflow as tf\nimport numpy as np\n\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\ndef bias_variable(shape):\n    initial = tf.constant(0.0, shape=shape)\n    return tf.Variable(initial)\n\ndef conv2d(x, W, stride):\n    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding=\'SAME\')\n\ndef conv_layer(x, conv=(3, 3), stride=1, n_filters=32, use_bias=False):\n    W = weight_variable([conv[0], conv[1], x.get_shape()[-1].value, n_filters])\n    if use_bias:\n        b = bias_variable([n_filters])\n        return (tf.nn.relu(conv2d(x, W, stride=stride) + b), W)\n    else:\n        return (tf.nn.relu(conv2d(x, W, stride=stride)), W)\n\ndef conv_layer_(x, conv=(3, 3), stride=1, n_filters=32, use_bias=False, weights=None):\n    return tf.nn.relu(conv2d(x, weights, stride=stride))\n\ndef fc_layer(x, n_neurons, activation=tf.tanh, use_bias=True, dropout=False):\n    W = weight_variable([x.get_shape()[-1].value, n_neurons])\n    h, b = None, None\n    if use_bias:\n        b = bias_variable([n_neurons])\n        h = activation(tf.matmul(x, W) + b)\n    else:\n        h = activation(tf.matmul(x, W))\n    if dropout:\n        keep_prob = tf.placeholder(tf.float32)\n        h_drop = tf.nn.dropout(h, keep_prob)\n        return (h_drop, W, b, keep_prob)\n    else:\n        return (h, W, b, None)\n\ndef fc_layer_(x, n_neurons, activation=tf.tanh, use_bias=True, dropout=False, weights=None, bias=None):\n    h = None\n    if use_bias and bias != None:\n        h = activation(tf.matmul(x, weights) + bias)\n    else:\n        h = activation(tf.matmul(x, weights))\n    return h\n\n# h_identity_in, W_in = identity_in(x)\ndef identity_in(x):\n    shp = x.get_shape()\n    W = tf.ones([shp[1].value, shp[2].value, shp[3].value])\n    return tf.mul(x, W), W\n\ndef flattened(x):\n    product = 1\n    for d in x.get_shape():\n        if d.value is not None:\n            product *= d.value\n    return tf.reshape(x, [-1, product])\n\n# Define negative log-likelihood and gradient\ndef normal_log(X, mu=np.float32(1), sigma=np.float32(1), left=-np.inf, right=np.inf):\n    val = -tf.log(tf.constant(np.sqrt(2 * np.pi), dtype=tf.float32) * sigma) - \\\n           tf.pow(X - mu, 2) / (tf.constant(2, dtype=tf.float32) * tf.pow(sigma, 2))\n    return val\n\ndef negative_log_likelihood(X):\n    return -tf.reduce_sum(normal_log(X))\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n'"
Tensorflow/car_cnn.py,4,"b'#!/usr/bin/env python\n""""""\nCopyright (c) 2017, Ryan Dellana\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of Ryan Dellana nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL Ryan Dellana BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n""""""\n\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport numpy as np\nimport cv2\nimport tensorflow as tf\nimport pickle\n\nfrom car_models import cnn_cccccfffff\n\nimport os\nimport cv2\nimport numpy as np\nimport time\n\ndef load_dataset(path, percent_testing=None):\n    assert percent_testing is None or (percent_testing >= 0.0 and percent_testing <= 1.0)\n    x, y, fnames = [], [], []\n    for i in os.walk(path):\n        (d, sub_dirs, files_) = i\n        fnames.extend(files_)\n    seq_fname = []\n    for fname in fnames:\n        seq = int(fname.split(\'_\')[0])\n        seq_fname.append((seq, fname))\n    seq_fname.sort()\n    for (seq, fname) in seq_fname:\n        #img = cv2.imread(path+\'/\'+fname, 1) for black and white\n        img = cv2.imread(path+\'/\'+fname)\n        img = cv2.resize(img, (200, 150), interpolation=cv2.INTER_CUBIC)\n        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for black and white\n        img = img[35:,:,:]\n        #img = img[35:,:] for black and white\n        #img = np.reshape(img, (115, 200, 1)) for black and white\n        x.append(img)\n        _, timestamp, throttle, steering = fname.split(\'_\')\n        timestamp, throttle, steering = long(timestamp), float(throttle), float(steering.split(\'.jpg\')[0])\n        print(\'(seq, timestamp, throttle, steering):\', seq, timestamp, throttle, steering)\n        y.append((steering, throttle))\n    train_x, train_y, test_x, test_y = [], [], [], []\n    if percent_testing is not None:\n        tst_strt = int(len(x)*(1.0-percent_testing))\n        train_x, train_y, test_x, test_y = x[:tst_strt], y[:tst_strt], x[tst_strt:], y[tst_strt:]\n    else:\n        train_x, train_y = x, y\n    return train_x, train_y, test_x, test_y\n\n\npath = \'/home/djtobias/Documents/Tensorflow/TrainingIMG\'\n\ntrain_x, train_y, test_x, test_y = load_dataset(path=path, percent_testing=0.20)\n\n\n\nnum_epochs = 100\nbatch_size = 100\n\n# Drop items from dataset so that it\'s divisible by batch_size\n\ntrain_x = train_x[0:-1*(len(train_x) % batch_size)]\ntrain_y = train_y[0:-1*(len(train_y) % batch_size)]\ntest_x = test_x[0:-1*(len(test_x) % batch_size)]\ntest_y = test_y[0:-1*(len(test_y) % batch_size)]\n\nprint(\'len(test_x) =\', len(test_x))\n\nbatches_per_epoch = int(len(train_x)/batch_size)\n\nsess = tf.InteractiveSession()\nmodel = cnn_cccccfffff()\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(model.loss)\nsaver = tf.train.Saver()\nsess.run(tf.initialize_all_variables())\n\nfor i in range(num_epochs):\n\n    for b in range(0, batches_per_epoch):\n        batch = [train_x[b*batch_size:b*batch_size+batch_size], train_y[b*batch_size:b*batch_size+batch_size]]\n        # --- normalize batch ---\n        batch_ = [[],[]]\n        for j in range(len(batch[0])):\n            batch_[0].append(batch[0][j].astype(dtype=np.float32)/255.0)\n            batch_[1].append(np.array([batch[1][j][0]], dtype=np.float32))\n        batch = batch_\n        # ------------------------\n        train_step.run(feed_dict={model.x:batch[0], model.y_:batch[1], model.keep_prob_fc1:0.8, model.keep_prob_fc2:0.8, model.keep_prob_fc3:0.8, model.keep_prob_fc4:0.8})\n        #train_error = model.loss.eval(feed_dict={model.x:batch[0], model.y_:batch[1], \n        #                                         model.keep_prob_fc1:1.0, model.keep_prob_fc2:1.0, \n        #                                         model.keep_prob_fc3:1.0, model.keep_prob_fc4:1.0})\n        #print(""epoch %d, training entropy %g""%(i, train_error))\n    print(\'epoch\', i, \'complete\')\n    if i % 5 == 0:\n        test_error = 0.0\n        for b in range(0, len(test_x), batch_size):\n            batch = [test_x[b:b+batch_size], test_y[b:b+batch_size]]\n            # --- normalize batch ---\n            batch_ = [[],[]]\n            for j in range(len(batch[0])):\n                batch_[0].append(batch[0][j].astype(dtype=np.float32)/255.0)\n                batch_[1].append(np.array([batch[1][j][0]], dtype=np.float32))\n            batch = batch_\n            #print(\'batch =\', len(batch[0]), len(batch[1]))\n            test_error_ = model.loss.eval(feed_dict={model.x:batch[0], model.y_:batch[1], \n                                                 model.keep_prob_fc1:1.0, model.keep_prob_fc2:1.0, \n                                                 model.keep_prob_fc3:1.0, model.keep_prob_fc4:1.0})\n            # -----------------------\n            test_error += test_error_\n        test_error /= len(test_x)/batch_size\n        test_accuracy = 1.0 - test_error\n        print(""test accuracy %g""%test_accuracy)\nfilename = saver.save(sess, \'/home/djtobias/Documents/Tensorflow/model.ckpt\')\n    \n\n\n'"
Tensorflow/car_models.py,8,"b'#!/usr/bin/env python\n""""""\nCopyright (c) 2017, Ryan Dellana\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of Ryan Dellana nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL Ryan Dellana BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n""""""\n""""""\nOriginal net from the paper had 1164 n_neurons on the first fully-connected layer instead of 512.  \nHalving the amount of neurons on the first FC layer reduced the size of trained model by half and sped up training.\n""""""\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom TensorflowUtil import weight_variable, bias_variable, conv2d, conv_layer\nfrom TensorflowUtil import conv_layer_, fc_layer, fc_layer_, identity_in, flattened\nfrom TensorflowUtil import normal_log, negative_log_likelihood, max_pool_2x2\n\n\n# 640 x 480\nclass cnn_cccccfffff(object):\n\n    def __init__(self):\n        self.x = tf.placeholder(tf.float32, [None, 115, 200, 3])\n        self.y_ = tf.placeholder(tf.float32, [None, 1])\n        (self.h_conv1, _) = conv_layer(self.x, conv=(5, 5), stride=2, n_filters=24, use_bias=True)\n        (self.h_conv2, _) = conv_layer(self.h_conv1, conv=(5, 5), stride=2, n_filters=36, use_bias=True)\n        (self.h_conv3, _) = conv_layer(self.h_conv2, conv=(5, 5), stride=2, n_filters=48, use_bias=True)\n        (self.h_conv4, _) = conv_layer(self.h_conv3, conv=(3, 3), stride=1, n_filters=64, use_bias=True)\n        (self.h_conv5, _) = conv_layer(self.h_conv4, conv=(3, 3), stride=1, n_filters=64, use_bias=True)\n        self.h_conv5_flat = flattened(self.h_conv5)\n        (self.h_fc1_drop, _, _, self.keep_prob_fc1) = fc_layer(x=self.h_conv5_flat, n_neurons=512, activation=tf.nn.relu, use_bias=True, dropout=True)\n        (self.h_fc2_drop, _, _, self.keep_prob_fc2) = fc_layer(self.h_fc1_drop, 100, tf.nn.relu, True, True)\n        (self.h_fc3_drop, _, _, self.keep_prob_fc3) = fc_layer(self.h_fc2_drop, 50, tf.nn.relu, True, True)\n        (self.h_fc4_drop, _, _, self.keep_prob_fc4) = fc_layer(self.h_fc3_drop, 10, tf.nn.relu, True, True)\n        W_fc5 = weight_variable([10, 1])\n        b_fc5 = bias_variable([1])\n        self.y_out = tf.matmul(self.h_fc4_drop, W_fc5) + b_fc5\n        self.loss = tf.reduce_mean(tf.abs(tf.sub(self.y_, self.y_out)))\n'"
car/scripts/SoundServer.py,0,"b'#! /usr/bin/python\n\n# Author: Ryan Dellana\n# Date Created: Feb. 16, 2014\n# Updated: December 20, 2016\n# Note: This version was created for Daniel Tobias\n\n""""""\nDependencies:\nsudo apt-get install python-pygame\nsudo apt-get install festlex-cmu\nsudo apt-get install ubuntu-restricted-extras\nsudo dpkg-reconfigure libdvd-pkg\n# restart computer\n\nmirage_sound_out provides a simple way of playing sounds that come from outside sources (mp3, 3rd party text-to-speech, etc.).\nmirage_sound_out was created as an alternative to the soundplay system that comes with ros hydro.\nUnlike soundplay, this node is not suitable for use by multiple clients (they\'ll step on each other).\n\nIf it recieves a new sound while one is still playing, it\'ll just play them concurrently on separate audio channels.\nUnless all 8 channels are already in use in which case it\'ll just drop the sound.\nThere is no queue.\nIn the future I\'d like to have timing info passed along with the sounds in a simlar way as motor commands are sent.\nSo you\'d pass it a schedule of sounds to play, consisting of a list of tuples each containing a sound and it\'s start time.\nWhen processing such a list, this node could look ahead to the synthesized text portions and start generating their files\nbefore the scheduled play time to reduce lag.\n\n        Useful pygame.mixer.Sound properties.\n        .play               -- begin sound playback\n        .stop               -- stop sound playback\n        .fadeout            -- stop sound playback after fading out\n        .set_volume         -- set the playback volume for this Sound\n        .get_volume         -- get the playback volume\n        .get_num_channels   -- count how many times this Sound is playing\n        .get_length         -- get the length of the Sound\n        .get_raw            -- return a bytestring copy of the Sound samples\n""""""\n\nimport sys, os, time, json, shutil, copy\nimport numpy\nimport pygame.mixer\nfrom pyfestival import Festival\nimport rospy\nfrom std_msgs.msg import String\n\nclass mirage_sound_out(object):\n\n    """""" festival_cache_path: folder where pre-synthesized mp3 files will be stored.\n        sound_effects_path: folder where you keep your sound effect files.\n    """"""\n    def __init__(self, festival_cache_path, sound_effects_path):\n        pygame.mixer.init(channels=6)   \n        self._festival_cache_path = festival_cache_path\n        self._festival_tmp_cache_path = ""/tmp/mirage_festival_tmp/""\n        if not os.path.exists(self._festival_tmp_cache_path):\n            os.makedirs(self._festival_tmp_cache_path)\n        self._sound_effects_path = sound_effects_path\n        self._sounds_preloaded = {} # TODO Not currently used.\n        self._fest = Festival()\n        self._load_cache()\n        self._timestamp = time.time()\n        self._get_runtime_ts()\n        self._enforce_consistency()\n        self._prune_cache()\n        self._save_cache()\n        print ""finished running self.__init__""\n\n    def shutdown(self):\n        print \'shutdown routine...\'\n        self._save_cache()\n        #pygame.mixer.stop()\n        shutil.rmtree(self._festival_tmp_cache_path)\n        pygame.mixer.quit()\n\n    """""" Automatically creates a cache file if there isn\'t already one. """"""\n    def _load_cache(self):\n        c_path = self._festival_cache_path + ""festival_cache_index.json""\n        if not os.path.exists(c_path): # create_cache\n            self._festival_cache_index = { \'cache\':{}, \'newest_cache_id\':0, \'cache_max_size\':100*1024, \'cache_size\':0,\n                                           \'save_cache_after_n_updates\':50, \'cache_updates_since_last_save\':0, \n                                           \'runtime_clock\':0, \'synth_max_chars\':150, \'prune_after\':24*60*60 }\n        else:\n            in_file = open(self._festival_cache_path + ""festival_cache_index.json"") # TODO error handling?\n            self._festival_cache_index = json.load(in_file)\n        \n\n    """""" Make sure that all files specified in index are present in cache and vice versa. """"""\n    # TODO Need to test this feature. Try removing some of the files from the cache and see if it adapts.\n    #   Also try manually corrupting the index by adding references to files that aren\'t there.\n    def _enforce_consistency(self):\n        print ""_enforce_consistency()""\n        cache_files = os.listdir(self._festival_cache_path)\n        ammended_cache = copy.deepcopy(self._festival_cache_index)\n        ammended_cache[\'cache\'] = {}\n        for k in self._festival_cache_index[\'cache\'].keys():\n            ammended_cache[\'cache\'][k] = copy.deepcopy(self._festival_cache_index[\'cache\'][k])\n            if ammended_cache[\'cache\'][k][\'fname\'] != """" and ammended_cache[\'cache\'][k][\'fname\'] not in cache_files:\n                print k, ""not found in cache. Removing from index.""\n                ammended_cache[\'cache\'][k][\'fname\'] = """"\n                ammended_cache[\'cache_size\'] -= ammended_cache[\'cache\'][k][\'size\']\n                ammended_cache[\'cache\'][k][\'size\'] = 0\n        self._festival_cache_index = ammended_cache\n        index_files = [self._festival_cache_index[\'cache\'][k][\'fname\'] for k in self._festival_cache_index[\'cache\'].keys()]\n        for f in cache_files:\n            if f not in index_files and f.count(""festival_cache_index"") == 0:\n                print f, ""not found in index. Removing from cache.""\n                try:\n                    os.remove(self._festival_cache_path + f)\n                except:\n                    print ""ERROR: os.remove("" + self._festival_cache_path + f + "")""\n                    pass\n\n    def _prune_cache(self):\n        for k in self._festival_cache_index[\'cache\'].keys():\n            item = self._festival_cache_index[\'cache\'][k]\n            if item[\'size\'] == 0 and (self._get_runtime_ts() - item[\'runtime_stamp\'] > self._festival_cache_index[\'prune_after\']):\n                del self._festival_cache_index[\'cache\'][k]\n                    \n    def _save_cache(self):\n        print ""_save_cache():"" #, self._festival_cache_index\n        output_file = open(self._festival_cache_path + ""festival_cache_index.json"", ""wb"")\n        if output_file is not None:\n            json.dump(self._festival_cache_index, output_file, indent=4)\n        else:\n            print ""ERROR: output_file is None""\n        output_file.close()\n\n    def say(self, txt):\n        print ""say("", txt, "")""\n        if len(txt) <= self._festival_cache_index[\'synth_max_chars\']:\n            cln_txt = self._clean_phrase(txt)\n            if cln_txt not in self._festival_cache_index[\'cache\'].keys(): # First time ever said.\n                self._festival_cache_index[\'cache\'][cln_txt] = { \'fname\':"""", \'size\':0.0, \'count\':0, \'runtime_stamp\':0, \'delete_score\':0 }\n            elif self._festival_cache_index[\'cache\'][cln_txt][\'fname\'] == """" and self._festival_cache_index[\'cache\'][cln_txt][\'count\'] >= 1: # Second time ever been said.\n                self._cache_phrase(txt)\n            return self._say(txt)\n        return 0.0\n\n    """""" updates cache index runtime_stamp and than returns it\'s new value """"""\n    def _get_runtime_ts(self):\n        current_time = time.time()\n        time_elapsed = current_time - self._timestamp\n        self._festival_cache_index[\'runtime_clock\'] = self._festival_cache_index[\'runtime_clock\'] + time_elapsed\n        self._timestamp = current_time\n        print ""runtime_clock:"", str(self._festival_cache_index[\'runtime_clock\'])\n        return self._festival_cache_index[\'runtime_clock\']\n\n    """""" Remove all chars other than number, letter, and space """"""\n    def _clean_phrase(self, txt):\n        phrase = txt.lower()\n        out = """"\n        for ch in phrase:\n            if (ord(ch) >= ord(\'a\') and ord(ch) <= ord(\'z\')) or (ord(ch) == ord(\' \')) or (ord(ch) >= ord(\'0\') and ord(ch) <= ord(\'9\')):\n                out += ch\n        return out\n\n    def _cache_phrase(self, txt):\n        print ""_cache_phrase("", txt, "")""\n        cache_id = self._festival_cache_index[\'newest_cache_id\'] + 1\n        cache_id_str = ""cid"" + str(cache_id) + "".wav""\n        _dest = self._festival_cache_path + cache_id_str\n        try:\n            self._fest.wave(text=txt, dest=_dest)\n        except:\n            print ""ERROR: text2wave. txt="", txt, ""dest="", _dest\n            return False\n        self._festival_cache_index[\'newest_cache_id\'] = cache_id\n        entry = self._festival_cache_index[\'cache\'][self._clean_phrase(txt)]\n        entry[\'fname\'] = cache_id_str\n        entry[\'size\'] = int(os.stat(_dest).st_size / 1024) # store size as truncated kilobytes.\n        self._festival_cache_index[\'cache_size\'] += entry[\'size\']\n        self._regulate_cache_size()\n        return True\n\n    def _regulate_cache_size(self):\n        print ""_regulate_cache_size()""\n        if self._festival_cache_index[\'cache_size\'] > self._festival_cache_index[\'cache_max_size\']:\n            print ""cache exceeded maximum size of"", self._festival_cache_index[\'cache_max_size\'], ""kilobytes. reducing...""\n            cached = []\n            for k in self._festival_cache_index[\'cache\'].keys(): # vvv This is going to get slow eventually.\n                if self._festival_cache_index[\'cache\'][k][\'size\'] != 0:\n                    cached.append(self._festival_cache_index[\'cache\'][k])\n            tstmps = [e[\'runtime_stamp\'] for e in cached]\n            sizes = [e[\'size\'] for e in cached]\n            counts = [e[\'count\'] for e in cached]\n            median_tstmp = numpy.median(tstmps)\n            print ""median_tstmp ="", median_tstmp\n            median_size = numpy.median(sizes)\n            print ""median_size ="", median_size\n            median_count = numpy.median(counts)\n            print ""median_count ="", median_count\n            std_dev_tstmp = numpy.std(tstmps)\n            print ""std_dev_tstmp ="", std_dev_tstmp\n            std_dev_size = numpy.std(sizes)\n            print ""std_dev_size ="", std_dev_size\n            std_dev_count = numpy.std(counts)\n            print ""std_dev_count ="", std_dev_count\n            for e in cached:\n                std_devs_before_med_tstmp = (median_tstmp - e[\'runtime_stamp\']) / std_dev_tstmp\n                std_devs_above_med_size = (e[\'size\'] - median_size) / std_dev_size\n                std_devs_below_med_count = (median_count - e[\'count\']) / std_dev_count\n                e[\'delete_score\'] = 0.75*std_devs_before_med_tstmp + 0.15*std_devs_above_med_size + 0.10*std_devs_below_med_count\n            cached_sorted = sorted(cached, key = lambda k: k[\'delete_score\'])\n            while (self._festival_cache_index[\'cache_size\'] > self._festival_cache_index[\'cache_max_size\']):\n                delete_me = cached_sorted[-1]\n                print ""deleting: fname ="", delete_me[\'fname\'], ""age ="", delete_me[\'runtime_stamp\'], ""size ="", delete_me[\'size\'], ""count ="", delete_me[\'count\']\n                try:\n                    os.remove(self._festival_cache_path + delete_me[\'fname\'])\n                except:\n                    print ""ERROR: os.remove("" + self._festival_cache_path + delete_me[\'fname\'] + "")""\n                    return False\n                self._festival_cache_index[\'cache_size\'] -= delete_me[\'size\']\n                delete_me[\'size\'] = 0\n                delete_me[\'fname\'] = """"\n                cached_sorted.remove(delete_me)\n        return True\n\n    def _say(self, txt):\n        cln_txt = self._clean_phrase(txt)\n        entry = self._festival_cache_index[\'cache\'][cln_txt]\n        entry[\'count\'] += 1\n        entry[\'runtime_stamp\'] = self._get_runtime_ts()\n        seconds = 0.0\n        if entry[\'fname\'] != """": # play from cache\n            print \'playing from cache\'\n            seconds = self.play(fname = entry[\'fname\'], cached_phrase = True, tmp_cache = False)\n        else: # slingshot through tmp directory (RAM)\n            print \'playing from RAM\'\n            _dest = self._festival_tmp_cache_path + ""tmp_sound.wav""\n            try:\n                self._fest.wave(text=txt, dest=_dest) # TODO I\'m assumming this will just overwrite any older tmp_sound.wav\n            except:\n                print ""ERROR: text2wave. txt="", txt, ""dest="", _dest\n                return\n            seconds = self.play(fname = ""tmp_sound.wav"", cached_phrase = True, tmp_cache = True)\n        self._festival_cache_index[\'cache_updates_since_last_save\'] += 1\n        if self._festival_cache_index[\'cache_updates_since_last_save\'] >= self._festival_cache_index[\'save_cache_after_n_updates\']:\n            self._festival_cache_index[\'cache_updates_since_last_save\'] = 0\n            self._save_cache()\n        return seconds\n\n    """""" plays a sound specified by fname. If cached_phrase is set to True, then\n        it expects a cacheid. If False, it assumes the sound to be in the sound_effects\n        folder. If other sound(s) are already playing, it\'ll just overlap with them by \n        playing on another open channel (unless all chanels are busy). """"""\n    def play(self, fname, cached_phrase=False, tmp_cache=False):\n        path = """"\n        if cached_phrase:\n            if tmp_cache:\n                path = self._festival_tmp_cache_path + fname\n            else:\n                path = self._festival_cache_path + fname\n        else: \n            path = self._sound_effects_path + fname\n        try:\n            #if path not in self._sounds_preloaded.keys():\n            #    self._sounds_preloaded[path] = pygame.mixer.Sound(path)\n            channel = pygame.mixer.find_channel()\n            if channel <> None:\n                #channel.play(self._sounds_preloaded[path])\n                #return self._sounds_preloaded[path].get_length()\n                sound = pygame.mixer.Sound(path)\n                channel.play(sound)\n                return sound.get_length()\n        except:\n            print ""ERROR: Failed to play: "" + path\n        return 0.0\n\n    def stop(self):\n        pygame.mixer.stop()\n\n    def pause(self):\n        pygame.mixer.pause()\n\n    def resume(self):\n        pygame.mixer.unpause()\n\n    \nclass SoundServer(object):\n\n    def __init__(self):\n        rospy.init_node(\'sound_server\', anonymous=False)\n        rospy.on_shutdown(self._shutdown)\n        while (rospy.get_rostime() == 0.0):\n            pass\n        rospy.Subscriber(""/sound_server/speech_synth"", String, self.cb_speech_synth)\n        rospy.Subscriber(""/sound_server/play_sound_file"", String, self.cb_play_sound_file)\n        self.pub_status = rospy.Publisher(""/sound_server/status"", String)\n        self.s = mirage_sound_out(festival_cache_path=""/home/ubuntu/Music/mirage_engrams/festival_cache/"", sound_effects_path=""/home/ubuntu/Music/mirage_engrams/sound_effects/"")\n        rospy.sleep(2.0) # Startup time.\n        rospy.loginfo(""mirage_sound_out ready"")\n        rospy.spin()\n\n    def _shutdown(self):\n        if self.s is not None:\n            self.s.shutdown()\n\n    def cb_speech_synth(self, data):\n        if data is not None and data.data != """": # TODO add more input validation.\n            sound_seconds = self.s.say(data.data)\n            self.pub_status.publish(String(str(sound_seconds)))\n        \n    def cb_play_sound_file(self, data):\n        if data is not None and data.data != """": # TODO add more input validation.\n            sound_seconds = self.s.play(data.data)\n            self.pub_status.publish(String(str(sound_seconds)))\n\nif __name__ == \'__main__\':\n    try:\n        server = SoundServer()\n    except rospy.ROSInterruptException:\n        pass\n\n'"
car/scripts/TensorflowUtil.py,23,"b'#!/usr/bin/env python\n""""""\nCopyright (c) 2017, Ryan Dellana\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of Ryan Dellana nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL Ryan Dellana BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n""""""\n\n\nimport tensorflow as tf\nimport numpy as np\n\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\ndef bias_variable(shape):\n    initial = tf.constant(0.0, shape=shape)\n    return tf.Variable(initial)\n\ndef conv2d(x, W, stride):\n    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding=\'SAME\')\n\ndef conv_layer(x, conv=(3, 3), stride=1, n_filters=32, use_bias=False):\n    W = weight_variable([conv[0], conv[1], x.get_shape()[-1].value, n_filters])\n    if use_bias:\n        b = bias_variable([n_filters])\n        return (tf.nn.relu(conv2d(x, W, stride=stride) + b), W)\n    else:\n        return (tf.nn.relu(conv2d(x, W, stride=stride)), W)\n\ndef conv_layer_(x, conv=(3, 3), stride=1, n_filters=32, use_bias=False, weights=None):\n    return tf.nn.relu(conv2d(x, weights, stride=stride))\n\ndef fc_layer(x, n_neurons, activation=tf.tanh, use_bias=True, dropout=False):\n    W = weight_variable([x.get_shape()[-1].value, n_neurons])\n    h, b = None, None\n    if use_bias:\n        b = bias_variable([n_neurons])\n        h = activation(tf.matmul(x, W) + b)\n    else:\n        h = activation(tf.matmul(x, W))\n    if dropout:\n        keep_prob = tf.placeholder(tf.float32)\n        h_drop = tf.nn.dropout(h, keep_prob)\n        return (h_drop, W, b, keep_prob)\n    else:\n        return (h, W, b, None)\n\ndef fc_layer_(x, n_neurons, activation=tf.tanh, use_bias=True, dropout=False, weights=None, bias=None):\n    h = None\n    if use_bias and bias != None:\n        h = activation(tf.matmul(x, weights) + bias)\n    else:\n        h = activation(tf.matmul(x, weights))\n    return h\n\n# h_identity_in, W_in = identity_in(x)\ndef identity_in(x):\n    shp = x.get_shape()\n    W = tf.ones([shp[1].value, shp[2].value, shp[3].value])\n    return tf.mul(x, W), W\n\ndef flattened(x):\n    product = 1\n    for d in x.get_shape():\n        if d.value is not None:\n            product *= d.value\n    return tf.reshape(x, [-1, product])\n\n# Define negative log-likelihood and gradient\ndef normal_log(X, mu=np.float32(1), sigma=np.float32(1), left=-np.inf, right=np.inf):\n    val = -tf.log(tf.constant(np.sqrt(2 * np.pi), dtype=tf.float32) * sigma) - \\\n           tf.pow(X - mu, 2) / (tf.constant(2, dtype=tf.float32) * tf.pow(sigma, 2))\n    return val\n\ndef negative_log_likelihood(X):\n    return -tf.reduce_sum(normal_log(X))\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n'"
car/scripts/Xbox360.py,0,"b'""""""\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\nAuthor: Ryan Dellana\nModify Date: 01/04/2017\nAbout:\nTakes raw ROS joy messages and generates events like \'X_pressed\', \'X_released\', etc.\nAlso converts X/Y format of sticks to theta and magnitude.\nUsage Example:\n# import class\nimport XBox360\n# Do this once in your main method.\ncontroller = XBox360()\n# Do this every time you receive a new joy message (let\'s call it \'msg\')\ncontroller.update(msg)\n# To get new button events use:\nevts = controller.buttonEvents()\n# evts should now contain a list of strings describing button events.\n# To respond to a specific event, you might do something like:\nif \'Y_pressed\' in evts:\n    # do something in response to event ...\n# To access the stick angles and magnitudes, use:\ncontroller.left_stick[\'angle\']\ncontroller.left_stick[\'magnitude\']\n""""""\n\nimport math, copy\n\nclass XBox360(object):\n\n    def __init__(self):\n        # XBOX 360\n        self.idx_2_btn = {0:\'A\',1:\'B\',2:\'X\',3:\'Y\',4:\'LB\',5:\'RB\',6:\'back\',7:\'start\',8:\'bigX\',9:\'LStick\',10:\'RStick\',11:\'ArrowL\',12:\'ArrowR\',13:\'ArrowU\',14:\'ArrowD\'}\n        self.btn_2_idx = {\'A\':0,\'B\':1,\'X\':2,\'Y\':3,\'LB\':4,\'RB\':5,\'back\':6,\'start\':7,\'bigX\':8,\'LStick\':9,\'RStick\':10,\'ArrowL\':11,\'ArrowR\':12,\'ArrowU\':13,\'ArrowD\':14}\n        # Logitech F310        \n        #self.idx_2_btn = {0:\'A\',1:\'B\',2:\'X\',3:\'Y\',4:\'LB\',5:\'RB\',6:\'back\',7:\'start\',8:\'bigX\',9:\'LStick\',10:\'RStick\'}\n        #self.btn_2_idx = {\'A\':0,\'B\':1,\'X\':2,\'Y\':3,\'LB\':4,\'RB\':5,\'back\':6,\'start\':7,\'bigX\':8,\'LStick\':9,\'RStick\':10}\n        self.btn_state_prev = {}\n        for k in self.btn_2_idx.keys():\n            self.btn_state_prev[k] = False\n        self.btn_state_curr = copy.deepcopy(self.btn_state_prev)\n        self.btn_events = []\n        self.left_stick = {\'angle\':0.0,\'magnitude\':0.0,\'X\':0.0,\'Y\':0.0}\n        self.right_stick = {\'angle\':0.0,\'magnitude\':0.0,\'X\':0.0,\'Y\':0.0}\n        self.left_trigger, self.right_trigger = 0.0, 0.0\n\n    def update(self, data):\n        axes = {\'LTrigger\':data.axes[2],\'RTrigger\':data.axes[5],\'LStickX\':data.axes[0],\n                \'LStickY\':data.axes[1],\'RStickX\':data.axes[3],\'RStickY\':data.axes[4]}\n        self.left_stick[\'X\'], self.left_stick[\'Y\'] = axes[\'LStickX\'], axes[\'LStickY\']\n        self.right_stick[\'X\'], self.right_stick[\'Y\'] = axes[\'RStickX\'], axes[\'RStickY\']\n        lstick_theta, lstick_mag = self.cartesian_2_polar(axes[\'LStickX\'],axes[\'LStickY\'])\n        rstick_theta, rstick_mag = self.cartesian_2_polar(axes[\'RStickX\'],axes[\'RStickY\'])\n        self.left_stick[\'angle\'], self.right_stick[\'angle\'] = lstick_theta, rstick_theta\n        self.left_stick[\'magnitude\'], self.right_stick[\'magnitude\'] = lstick_mag, rstick_mag\n        self.left_trigger, self.right_trigger = axes[\'LTrigger\'], axes[\'RTrigger\']\n        self.btn_events = self._get_btn_events(data)\n        \n    def buttonEvents(self):\n        tmp = self.btn_events\n        self.btn_events = []\n        return tmp\n\n    def leftStick(self):\n        return self.left_stick\n\n    def rightStick(self):\n        return self.right_stick\n\n    def leftTrigger(self):\n        return self.left_trigger\n\n    def rightTrigger(self):\n        return self.right_trigger\n\n    def cartesian_2_polar(self, x, y):\n        theta = math.atan2(y, x) * 180 / math.pi\n        mag = math.sqrt(x*x + y*y)\n        return theta, mag\n\n    def _get_btn_events(self, data):\n        btn_evts = []\n        for i in range(0, 11):\n            self.btn_state_prev[self.idx_2_btn[i]] = self.btn_state_curr[self.idx_2_btn[i]]\n            self.btn_state_curr[self.idx_2_btn[i]] = data.buttons[i]\n        for i in range(0, 11):\n            if self.btn_state_curr[self.idx_2_btn[i]] != self.btn_state_prev[self.idx_2_btn[i]]:\n                if self.btn_state_curr[self.idx_2_btn[i]] == True:\n                    btn_evts.append(self.idx_2_btn[i] + ""_pressed"")\n                else:\n                    btn_evts.append(self.idx_2_btn[i] + ""_released"")\n        return btn_evts\n'"
car/scripts/car_models.py,8,"b'#!/usr/bin/env python\n""""""\nCopyright (c) 2017, Ryan Dellana\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of Ryan Dellana nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL Ryan Dellana BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n""""""\n\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom TensorflowUtil import weight_variable, bias_variable, conv2d, conv_layer\nfrom TensorflowUtil import conv_layer_, fc_layer, fc_layer_, identity_in, flattened\nfrom TensorflowUtil import normal_log, negative_log_likelihood, max_pool_2x2\n\n\n# 640 x 480\nclass cnn_cccccfffff(object):\n\n    def __init__(self):\n        self.x = tf.placeholder(tf.float32, [None, 115, 200, 3])\n        self.y_ = tf.placeholder(tf.float32, [None, 1])\n        (self.h_conv1, _) = conv_layer(self.x, conv=(5, 5), stride=2, n_filters=24, use_bias=True)\n        (self.h_conv2, _) = conv_layer(self.h_conv1, conv=(5, 5), stride=2, n_filters=36, use_bias=True)\n        (self.h_conv3, _) = conv_layer(self.h_conv2, conv=(5, 5), stride=2, n_filters=48, use_bias=True)\n        (self.h_conv4, _) = conv_layer(self.h_conv3, conv=(3, 3), stride=1, n_filters=64, use_bias=True)\n        (self.h_conv5, _) = conv_layer(self.h_conv4, conv=(3, 3), stride=1, n_filters=64, use_bias=True)\n        self.h_conv5_flat = flattened(self.h_conv5)\n        (self.h_fc1_drop, _, _, self.keep_prob_fc1) = fc_layer(x=self.h_conv5_flat, n_neurons=512, activation=tf.nn.relu, use_bias=True, dropout=True)\n        (self.h_fc2_drop, _, _, self.keep_prob_fc2) = fc_layer(self.h_fc1_drop, 100, tf.nn.relu, True, True)\n        (self.h_fc3_drop, _, _, self.keep_prob_fc3) = fc_layer(self.h_fc2_drop, 50, tf.nn.relu, True, True)\n        (self.h_fc4_drop, _, _, self.keep_prob_fc4) = fc_layer(self.h_fc3_drop, 10, tf.nn.relu, True, True)\n        W_fc5 = weight_variable([10, 1])\n        b_fc5 = bias_variable([1])\n        self.y_out = tf.matmul(self.h_fc4_drop, W_fc5) + b_fc5\n        self.loss = tf.reduce_mean(tf.abs(tf.sub(self.y_, self.y_out)))\n'"
car/scripts/cmdControl.py,1,"b'#!/usr/bin/env python\n""""""\nCopyright (c) 2017 Daniel Tobias\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nimport rospy\nimport tf\nfrom geometry_msgs.msg import Twist, TwistStamped\nfrom geometry_msgs.msg import Quaternion\nfrom sensor_msgs.msg import Imu\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import Image\nfrom sensor_msgs.msg import Joy\n##import joinstates\nfrom Xbox360 import XBox360\nimport sys, os\nimport time\nfrom threading import Lock\n\n\n""""""\nThis node is a python implementation of the jetsoncar_joy.cpp with some added features and functionality  \nThis node takes in joystick, lidar twist, and neural twist and toggles the control between these inputs for\na final cmd_vel twist that get sent to the Teensy for steering and throttle\n\nNote:\n1. Y button trim left\n2. B button trim right\n3. X button is cruise control, it will read the current throttle value from the right trigger and repeat it until X is pressed again.\n4. right trigger must be pressed to once at start to initialize all other commands\n\nWIP\nAdd jointstate for URDF\n\n""""""\n\nclass twistControl(object):\n\n    def __init__(self):\n        self.throttleInitialized = False\n        self.joy_timeout = 2.0\n        self.lid_timeout = 0.30\n        self.cnn_timeout = 0.1\n        self.joy_time = time.time()\n        self.lid_time = time.time()\n        self.cnn_time = time.time()\n        self.controller = XBox360()\n        self.joy_cmd = TwistStamped()\n        self.lid_cmd = TwistStamped()\n        self.cnn_cmd = TwistStamped()\n        self.cruiseControl = False\n        self.cruiseThrottle = 0.5\n        self.steeringAngle = 0.5\n        self.throttle = 0.5\n        self.trim = 0.0\n        ##self.throttleLock = Lock()\n        print ""cmd_control""\n       \n        rospy.Subscriber(""/imu"", Imu, self.imuCB, queue_size=5)\n        rospy.Subscriber(""/lidar_twist"", TwistStamped, self.lidarTwistCB, queue_size=5)\n        rospy.Subscriber(""/neural_twist"", TwistStamped, self.neuralTwistCB, queue_size=5)\n        rospy.Subscriber(""/joy"", Joy, self.joyCB, queue_size=5)\n        self.vel_pub = rospy.Publisher(""/cmd_vel"", TwistStamped, queue_size = 1) \n        #self.state_pub = rospy.Publisher(""/joint_states"", JointState, queue_size=1)\n        self.sound = rospy.Publisher(""/sound_server/speech_synth"", String, queue_size=1)        \n        rospy.init_node (\'cmd_control\',anonymous=True)\n        rate = rospy.Rate(66)\n        while not rospy.is_shutdown():\n            self.cmdRouter()\n            rate.sleep()\n            \n\n    def imuCB(self, imu):\n        try: \n            quaternion = (imu.orientation.x, imu.orientation.y, imu.orientation.z, imu.orientation.w)\n            euler = tf.transformations.euler_from_quaternion(quaternion)\n            roll = euler[0]\n            pitch = euler[1]\n            yaw = euler[2]\n        except Exception as e:\n            print(e)\n            ##TODO update jointstate\n\n    def lidarTwistCB(self, lidarTwist):\n        try: \n            self.lid_cmd.twist = lidarTwist.twist\n            if self.cruiseControl == True:\n                \n                if lidarTwist.twist.linear.x == 0.5:\n                    self.lid_cmd.twist.linear.x = 0.5\n                else:\n                    self.lid_cmd.twist.linear.x = self.cruiseThrottle\n            else:\n                self.lid_cmd.twist.linear.x = self.throttle\n            self.lid_time = time.time()\n        except Exception as b:\n            print(b)\n\n\n    def neuralTwistCB(self, neuralTwist):\n        try:\n            self.cnn_cmd.twist = neuralTwist.twist\n            \n            if self.cruiseControl == True:\n                self.cnn_cmd.twist.linear.x = self.cruiseThrottle\n            else:\n                self.cnn_cmd.twist.linear.x = self.throttle\n            self.cnn_time = time.time()\n        except Exception as a:\n            print(a)\n        \n\n    def joyCB(self, joy):\n        try:\n            self.joystick = joy\n            self.controller.update(joy)\n            events = self.controller.buttonEvents()\n            if \'X_pressed\' in events:\n                self.cruiseControl = not self.cruiseControl ##toggle cruise control\n                self.cruiseThrottle = self.throttle   \n            if self.joystick.axes[5] != 0.0 and not self.throttleInitialized:\n                self.throttleInitialized = True  \n            if self.throttleInitialized:\n                self.steeringAngle = self.trim + (1-(((self.joystick.axes[0])/2.0)+0.5))  ## normed steering\n                self.joy_cmd.twist.angular.z = self.steeringAngle\n                self.throttle = (((1.0-((0.5*self.joystick.axes[5])+0.5))/2.0)+ 0.5)      ## normed throttle\n                self.joy_cmd.twist.linear.x = self.throttle         \n                if \'Y_pressed\' in events:\n                    self.trim = self.trim - 0.0025                ##trim left\n                if \'B_pressed\' in events:\n                    self.trim = self.trim + 0.0025                ##trim right\n                if \'X_pressed\' in events:\n                    self.cruiseControl = not self.cruiseControl   ##toggle cruise control\n                    self.cruiseThrottle = self.throttle           ##set throttle speed\n                if joy.buttons[0] == 1:                           ##Reverse, A button hit twice and hold down\n                    self.joy_cmd.twist.linear.z = 1\n                else: \n                    self.joy_cmd.twist.linear.z = 0\n                if self.cruiseControl == True: \n                    self.joy_cmd.twist.linear.x = self.cruiseThrottle\n                else: \n                    self.joy_cmd.twist.linear.x = self.throttle \n                rospy.loginfo(self.cruiseControl)\n                self.joy_time = time.time()\n                #rospy.loginfo(self.joy_time)\n                #self.vel_pub.publish(self.joy_cmd)\n            else:\n                pass\n            if \'X_pressed\' in events:\n                    self.cruiseControl = not self.cruiseControl ##toggle cruise control\n                    self.cruiseThrottle = self.throttle \n                \n        except Exception as f:\n            print(f)\n            \n\n    def cmdRouter(self):     \n        if self.joy_time+self.joy_timeout >= time.time():  ## If last joy message was recieved less than 2 seconds ago Joystick controlled      \n            rospy.loginfo(""Joy cmd"")\n            rospy.loginfo(self.joy_time+self.joy_timeout)\n            rospy.loginfo(time.time())\n            self.vel_pub.publish(self.joy_cmd) \n        elif self.lid_time+self.lid_timeout >= time.time(): ##else if last lidar twist was recieved less than 0.3 seconds ago lidar evasion controlled\n            self.vel_pub.publish(self.lid_cmd)  \n            rospy.loginfo(""LIDAR cmd"")\n        elif self.cnn_time+self.cnn_timeout >= time.time(): ## else if last neural twist was recieved less than 0.1 seconds ago neural net controlled\n            self.vel_pub.publish(self.cnn_cmd)\n            rospy.loginfo(""CNN cmd"")\n        else:                                               ##else if no command, neutral throttle and steering\n            self.joy_cmd.twist.linear.x = 0.5\n            self.joy_cmd.twist.angular.z = 0.5\n            self.vel_pub.publish(self.joy_cmd)\n            rospy.loginfo(""Joy cmd else"")\n\nif __name__ == \'__main__\':\n    try:\n        twistControl()\n    except rospy.ROSInterruptException:\n        pass\n'"
car/scripts/dataRecorder.py,0,"b'#!/usr/bin/env python\n""""""\nCopyright (c) 2017 Daniel Tobias\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n##import cPickle as pickle\nimport numpy as np\nimport rospy\nfrom geometry_msgs.msg import Twist, TwistStamped\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import Image\nfrom sensor_msgs.msg import Joy\nfrom sensor_msgs.msg import PointCloud2\nfrom cv_bridge import CvBridge, CvBridgeError\nimport message_filters\nimport sys\nimport gi\nfrom Xbox360 import XBox360\nimport cv2\nprint cv2.__version__\ngi.require_version(\'Gst\', \'1.0\')\nfrom gi.repository import GObject, Gst\nimport time\nfrom threading import Lock\n\n\n""""""\nThis node saves multiple image topics as pictures and encodes the filename with sequence,time,throttle,steering.\nI know what rosbag is.\n\nNote: \nThrottle values 0.0-0.5 = reverse and 0.5-1.0 = forward\nSteering values 0.0-0.5 = left and 0.5-1.0 = right, 0.5 is center position\nThis node is recieving the output topic of drop nodes that are dropping 2 out of 3 frames for the depth and rgb image topics.\nThe node struggles to record both rgb and depth topic at 30FPS with cv2.imwrite on the TX1 which is why messages are being dropped plus 30FPS seems to be unnecessary\nGstreamer could be used to create a similar function like cv2.imwrite that utilizes the onboard hardware encoders for jpg (nvjpg) this could allow for more FPS or image topics to be saved as jpg\nLocation of folders where images are saved are /home/ubuntu/DepthIMG/ /home/ubuntu/LidarIMG/ /home/ubuntu/TrainingIMG/\n\n      \n""""""\n\nclass dataRecorder(object):\n\n    def __init__(self):\n        print ""dataRecorder""\n        self.record = False\n        self.twist = None\n        self.twistLock = Lock()\n        self.bridge = CvBridge()\n        self.globaltime = None\n        self.controller = XBox360()\n        ##rospy.Subscriber(""/camera/depth/points"" , PointCloud2, self.ptcloudCB)\n        rospy.Subscriber(""/camera/depth/image_rect_raw_drop"", Image, self.depthCB)\n        rospy.Subscriber(""/camera/rgb/image_rect_color_drop"", Image, self.streamCB)\n        #rospy.Subscriber(""/camera/rgb/image_rect_mono_drop"", Image, self.streamCB)  ##for black and white images see run.launch and look at the drop fps nodes near the bottom\n        rospy.Subscriber(""/lidargrid"", Image, self.lidargridCB)\n        rospy.Subscriber(""/cmd_vel"", TwistStamped, self.cmd_velCB)\n        rospy.Subscriber(""/joy"", Joy ,self.joyCB)\n        self.sound = rospy.Publisher(""/sound_server/speech_synth"", String, queue_size=1)\n        rospy.init_node(\'dataRecorder\',anonymous=True)\n        rospy.spin()\n\n    """"""\n    Similar to the other functions except storing a pointcloud2 msg and pickleing it. It is relatively expensive to store a pointcloud2 topic in pickle format.\n    """"""\n    ## def ptcloudCB(self, cloud):\n    ##     if self.record == True:\n    ##         timestamp = str(time.time())\n    ##         fname = None\n    ##         with self.twistLock:\n    ##             fname = timestamp + \'_\' + str(round(self.twist.linear.x,8)) + \'_\' + str(round(self.twist.angular.z,8))        \n    ##             with open(\'/home/ubuntu/Clouds/\'+fname+\'.pickle\', \'wb\') as f:\n    ##                 pickle.dump(cloud,f,protocol=2)\n\n    """"""\n    Receives a Lidar Image and encodes the sequence,timestamp,throttle and steering values into the filename and saves it as a tiff which is lossless.\n    Important: Depth images are uint16 and when you imread you must pass it a -1. eg. imread(img,-1) \n    """"""\n    def depthCB(self, depth):\n        if self.record == True:\n            #rospy.loginfo(""depth image recieved"")\n            try:\n                grey = self.bridge.imgmsg_to_cv2(depth)\n                rospy.loginfo(grey.dtype)\n\n                if self.twist is not None:\n                    fnamedepth = None\n                    seq = str(depth.header.seq)\n                    timestamp = str(depth.header.stamp)\n                    with self.twistLock:\n                        fnamedepth = seq + \'_\' + timestamp + \'_\' + str(round(self.twist.linear.x,8)) + \'_\' + str(round(self.twist.angular.z,8))\n                    cv2.imwrite(""/home/ubuntu/DepthIMG/""+fnamedepth+"".tiff"",grey)\n            except CvBridgeError as x:\n                print(x)\n        else:\n            rospy.loginfo(""Not Recording Depth"")\n        \n    """"""\n    Receives a LIDAR image and encodes the sequence,timestamp,throttle and steering values into the filename and saves it as a jpg\n    Note: The modified neato_laser_publisher.cpp node is converting the LIDAR data from polar to cartesian coordinates then writing them as white pixels on a black image of size 100x100\n    """"""\n    def lidargridCB(self, grid):\n        if self.record == True:\n            #rospy.loginfo(""grid recieved"")\n            try:\n                cv2lidarImg = self.bridge.imgmsg_to_cv2(grid)\n                if self.twist is not None:\n                    fnamelidar = None\n                    timestamp = str(grid.header.stamp)\n                    seq = str(grid.header.seq)\n                    with self.twistLock:                  \n                        fnamelidar = seq + \'_\' + timestamp + \'_\' + str(round(self.twist.linear.x,8)) + \'_\' + str(round(self.twist.angular.z,8))\n                    cv2.imwrite(""/home/ubuntu/LidarIMG/""+fnamelidar+"".jpg"",cv2lidarImg)\n            except CvBridgeError as r:\n                print(r)\n        else:\n            rospy.loginfo(""Not Recording Lidar"")\n\n    """"""\n    Receives an Image message and encodes the sequence,timestamp,throttle and steering values into the filename and saves it as a jpg\n    """"""\n    def streamCB(self, pic):\n        if self.record == True:\n            #rospy.loginfo(""image recieved"")\n            try:\n                cv2image = self.bridge.imgmsg_to_cv2(pic)\n                if self.twist is not None:\n                    fname = None\n                    seq = str(pic.header.seq)\n                    timestamp = str(pic.header.stamp)\n                    with self.twistLock:\n                        fname = seq + \'_\' + timestamp + \'_\' + str(round(self.twist.linear.x,8)) + \'_\' + str(round(self.twist.angular.z,8))\n                    cv2.imwrite(""/home/ubuntu/TrainingIMG/""+fname+"".jpg"",cv2image)\n            except CvBridgeError as e:\n                print(e)\n        else:\n            rospy.loginfo(""Not Recording Webcam"")\n    \n    """"""\n    Receives a twist msg\n    """"""\n    def cmd_velCB(self, msg):\n        ##rospy.loginfo(""Linear: [%f, %f, %f]""%(msg.linear.x, msg.linear.y, msg.linear.z))\n        ##rospy.loginfo(""Angular: [%f, %f, %f]""%(msg.angular.x, msg.angular.y, msg.angular.z))\n        with self.twistLock:\n            self.twist = msg.twist\n\n    """"""\n    Toggle recording on or off with start button on the Xbox controller\n    """"""\n    def joyCB(self, joy):        \n        self.controller.update(joy)\n        events = self.controller.buttonEvents()\n        if \'start_pressed\' in events:\n            self.record = not self.record\n            if self.record == True:\n                self.sound.publish(""Recording Started"")\n            else:\n                self.sound.publish(""Recording Stopped"")\n\n\nif __name__ == \'__main__\':\n    try:\n        dataRecorder()\n    except rospy.ROSInterruptException:\n        pass\n'"
car/scripts/gCamera.py,0,"b'#!/usr/bin/env python\n""""""\nCopyright (c) 2017 Daniel Tobias, Ryan Dellana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nimport numpy as np\nimport rospy\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\nimport gi\nimport sys\nsys.path.insert(1, \'/usr/local/lib/python2.7/site-packages\')\nimport cv2\nprint cv2.__version__\ngi.require_version(\'Gst\', \'1.0\')\nfrom gi.repository import GObject, Gst\n\n""""""\nNode that publishes images from the C920 Logitech webcam using Gstreamer\n\nNote: Better performance using gstreamer than cv.capture\n      \n""""""\n\ndef gst_to_opencv(gst_buffer):\n    return np.ndarray((480,640,3), buffer=gst_buffer.extract_dup(0, gst_buffer.get_size()), dtype=np.uint8)\n\ndef gCamera():\n    print ""gstWebCam""\n    bridge = CvBridge()\n    video =""video4""\n    pub = rospy.Publisher(\'stream\', Image, queue_size=10)\n    rospy.init_node(\'GstWebCam\',anonymous=True)\n    Gst.init(None)\n    pipe = Gst.parse_launch(""""""v4l2src device=/dev/""""""+video+"""""" ! video/x-raw, width=640, height=480,format=(string)BGR ! appsink sync=false max-buffers=2 drop=true name=sink emit-signals=true"""""")\n    sink = pipe.get_by_name(\'sink\')\n    pipe.set_state(Gst.State.PLAYING)\n    while not rospy.is_shutdown():\n        sample = sink.emit(\'pull-sample\')    \n        img = gst_to_opencv(sample.get_buffer())\n        try:\n            pub.publish(bridge.cv2_to_imgmsg(img, ""bgr8""))\n        except CvBridgeError as e:\n            print(e)\n\nif __name__ == \'__main__\':\n    try:\n        gCamera()\n    except rospy.ROSInterruptException:\n        pass\n\n\n\n\n'"
car/scripts/lidarEvasion.py,0,"b'#!/usr/bin/env python\n""""""\nCopyright (c) 2017 Daniel Tobias, Ryan Dellana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\nimport numpy as np\nimport rospy\nfrom geometry_msgs.msg import Twist, TwistStamped\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import Image\nfrom sensor_msgs.msg import Joy\nfrom cv_bridge import CvBridge, CvBridgeError\nfrom Xbox360 import XBox360\nimport sys, os\nimport cv2\nprint cv2.__version__\nimport time\nfrom threading import Lock\n\n""""""\nThis node subscribes to the lidargrid image topic which is basicially a birds eye view of the Neato XV-11 LIDAR\'s /scan topic.  \nIt then uses the image and checks for white pixels(points) in predefined regions of the image. \nIf a region contains an white pixel it will publish a twist message with a steering angle or throttle value to try and avoid the object or stop.\nThis node\'s intention was to be used as a primitive layer to help prevent the car from crashing into a wall under the Neural Net\'s control.\n\nFuture plans:\nThis node is very simple currently but could be expanded upon with fusion of IMU data. The regions that are being defined to look for collision could be modeled based on current speed and steering angle as a sort of basic look ahead for obstacles function\nNote: \nThe region function is defined using the TF coordinates which is a right handed coordinate system see http://www.pirobot.org/blog/0018/ \nToggle on or off with select button on Xbox 360 controller   \n      \n""""""\n\nlidarRadius = 5.0  ##meters\n\nclass evasion(object):\n\n    def __init__(self):\n        self.evadeSet = False\n        self.controller = XBox360()\n        self.bridge = CvBridge()\n        self.throttle = 0\n        self.grid_img = None\n        ##self.throttleLock = Lock()\n        print ""evasion""\n        rospy.Subscriber(""/lidargrid"", Image, self.gridCB, queue_size=1)\n        rospy.Subscriber(""/cmd_vel"", TwistStamped , self.twistCB , queue_size = 1)\n        rospy.Subscriber(""/joy"", Joy, self.joyCB, queue_size=5)\n        self.pub_img = rospy.Publisher(""/steering_img"", Image)\n        self.pub_twist = rospy.Publisher(""/lidar_twist"", TwistStamped, queue_size=1)\n        self.sound = rospy.Publisher(""/sound_server/speech_synth"", String, queue_size=1)        \n        rospy.init_node (\'lidar_cmd\',anonymous=True)\n        rospy.spin()\n\n    def twistCB(self, cmd_vel):\n        if self.evadeSet == True:\n            try:\n                ##rospy.loginfo(""cmd_vel Recieved"")\n                self.throttle = cmd_vel.twist.linear.x\n                normed_throttle = (self.throttle*2.0)-1.0\n                front_max = 0.3 + 4.5*(normed_throttle**2.5)   ##front region scales with throttle value\n                rospy.loginfo(\'normed_throttle: \'+str(normed_throttle) + \' front_max: \'+str(front_max))\n                front = self.Occupancy(self.grid_img, 0.1, front_max, -0.2,  0.2)    ##(2,0.2)  to (0.5,-0.2)\n                right = self.Occupancy(self.grid_img, 0.0, 1, -0.7, -0.2)            ##(2,-0.2) to (0,-0.7)\n                left  = self.Occupancy(self.grid_img, 0.0, 1,  0.2,  0.7)            ##(2,0.7)  to (0,0.2)\n                everywhere = self.Occupancy(self.grid_img, -4.0, 4.0, -4.0, 4.0)\n                cmd = TwistStamped()\n                #rospy.loginfo(self.throttle)\n                cmd.twist.angular.z = 0.5\n                cmd.twist.linear.x = -1.0\n                if front:\n                    cmd.twist.linear.x = 0.5   ##stop\n                    self.pub_twist.publish(cmd)                   \n                    self.sound.publish(""Forward collision detected"")       \n                elif left:\n                    cmd.twist.angular.z = 0.7  ##turn right\n                    self.pub_twist.publish(cmd)           \n                    self.sound.publish(""Left collision detected"")                       \n                elif right:\n                    cmd.twist.angular.z = 0.3  ##turn left\n                    self.pub_twist.publish(cmd)\n                    self.sound.publish(""Right collision detected"")\n                else:\n                    #self.pub_twist.publish(cmd)\n                    pass \n            except Exception as f:\n                print(f)\n        else:\n            pass\n            ##rospy.loginfo(""Not using Evasion"")\n\n    def gridCB(self, grid):\n        rospy.loginfo(""Grid Recieved"")\n        try:\n            self.grid_img = self.bridge.imgmsg_to_cv2(grid)\n        except CvBridgeError as e:\n            print(e)\n\n    """"""\n    Toggle LIDAR evasion with select button on Xbox 360 Controller\n    """"""\n    def joyCB(self, joy):\n        self.controller.update(joy)\n        events = self.controller.buttonEvents()\n        if \'back_pressed\' in events:\n            self.evadeSet = not self.evadeSet\n            rospy.loginfo(self.evadeSet)\n\n    """"""\n    Converts TF to pixels(x1,y1),(x2,y2)\n    """"""\n    def Region(self, grid, xmin, xmax, ymin, ymax):\n        pixelwidth = grid.shape[0]\n        tfwidth = lidarRadius*2.0\n        endx = int( pixelwidth * ((xmin*-1.0+5.0)/tfwidth) )\n        endy = int( pixelwidth * ((ymin*-1.0+5.0)/tfwidth) )\n        startx = int( pixelwidth * ((xmax*-1.0+5.0)/tfwidth) )\n        starty = int( pixelwidth * ((ymax*-1.0+5.0)/tfwidth) )\n        startx, starty = max(0, startx), max(0, starty)\n        endx, endy = min(endx, pixelwidth), min(endy, pixelwidth)\n        return (startx, starty, endx, endy)\n    """"""\n    checks for occupancy in regions specified then returns a true or false from a sum\n    """"""\n    def Occupancy(self, grid, xmin, xmax, ymin, ymax):\n        (startx, starty, endx, endy) = self.Region(grid, xmin, xmax, ymin, ymax)\n        #rospy.loginfo(str(startx)+"" ""+str(starty)+"" ""+str(endx)+"" ""+str(endy))\n        region = grid[startx:endx,starty:endy]\n        #rospy.loginfo(str(region.shape))\n        sum_ = region.sum()\n        #rospy.loginfo(str(sum_))\n        if sum_ > 0:\n            return True\n        else:\n            return False\n    \nif __name__ == \'__main__\':\n    try:\n        evasion()\n    except rospy.ROSInterruptException:\n        pass\n'"
car/scripts/pyfestival.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2008 John Paulett\n# All rights reserved.\n#\n# This software is licensed as described in the file COPYING, which\n# you should have received as part of this distribution.\n\n""""""Python bindings for The Festival Speech Synthesis System.\n\nhttp://code.google.com/p/pyfestival/\nhttp://www.cstr.ed.ac.uk/projects/festival/\n""""""\n\n__version__ = ""0.2.0""\n__all__ = [\n    \'Festival\', \'FestivalServer\', \'FestivalClient\', \'say\'\n]\nimport os\nimport signal\nimport subprocess\nimport socket\n\nclass Festival(object):\n   \n    def __init__(self, port=None, language=None, heap=None):\n        self._server = None\n       \n        self._festival_bin = ""festival""\n        self._text2wave_bin = ""text2wave""\n        self._port = port\n        self._language = language\n       \n   \n    def open(self):\n        """"""Opens a connection to the server.\n       \n        Must be called before say() when using Festival in server mode.\n        Server mode creates extra overhead when opening the connection,\n        but is beneficial when making multiple calls to the festival engine.\n        """"""\n        if self._server != None:\n            # if an instance of the server already exists, close it\n            # before opening a new one\n            self.close()\n        self._server = FestivalServer()\n        self._server.start()\n       \n    def close(self):\n        """"""Stops the server and closes the connection.\n       \n        Should be called when finished using the program in order to free\n        the port the server is running on and\n        """"""\n        if self._server != None:\n            self._server.stop()\n            self._server = None\n       \n    def say(self, text):\n        """"""Orders Festival to speak the text provided.\n       \n        Action depends on whether the open() method was used prior\n        to calling say().  If a server connection was created (i.e. by\n        calling open()), then this method communicates with the server\n        instance.  If open() was not callled, say() uses a separate\n        instance for every invokation.\n        """"""\n        if self._server != None:\n            # speak to the server via sockets\n            self._say_server(text)\n        else:\n            # no server, so use a single instance of festival\n            self._say_single(text)\n       \n    def say_file(self, filename):\n        """"""Speaks the contents of a file.\n       \n        If there is an issue opening or reading the file, nothing will\n        be spoken.\n        """"""\n        text = self._read_file(filename)\n        if text != None:\n            self.say(text)\n       \n    def wave(self, text=None, source=None, dest=None,\n              wave_type=None, frequency=None, scale=None):\n        """"""Uses Festival\'s text2wave program to generate a wave file object.\n       \n        Must contain either a text or source_file input (if both are given,\n        text overrides the source_file.  Returns the stdout wav, unless a\n        dest_file is given, in which case it will return None and save the wav\n        in the dest_file.\n       \n        Options:\n        text - the text to be spoke in the wav\n        source - the file to be read in\n        dest - the output file, if not specificied, output is returned\n        wave_type - the output waveform type (alaw, ulaw, snd, aiff, riff,\n                    nist, etc.  Defaults to the programs default (which is\n                    riff).\n        frequency - the output frequency.  Defaults to program\'s default.\n        scale - the volume factor.  Defaults to program\'s default.\n        """"""\n        args = [self._text2wave_bin]\n        if text == None:\n            # check to make sure something will act as input\n            if source == None:\n                raise TooFewArgumentsError(""Need an input value."")\n            # have program read the source file\n            args.append(source)\n        else:\n            # tts mode\n            args.append(""-"")\n        # append optional arguments\n        if dest != None:\n            args.append(""-o ""+dest)\n        if wave_type != None:\n            args.append(""-mode ""+wave_tye)\n        if frequency != None:\n            args.append(""-F ""+frequency)\n        if scale != None:\n            args.append(""-scale ""+scale)\n        print args\n        # opena connection to the file\n        #p = subprocess.Popen( args,\n        #                      stdin = subprocess.PIPE,\n        #                      stdout = subprocess.PIPE,\n        #                      stderr = subprocess.PIPE,\n        #                      close_fds = True)\n        #stdout, stderr = p.communicate(text)\n        if dest <> None and text <> None:\n            subprocess.call(""echo \\"""" + text + ""\\"" | "" + self._text2wave_bin + "" -o "" + dest, shell=True)\n        # only return a value if the file is not saved.\n        if dest == None:\n            return stdout\n        else:\n            return None\n   \n    def version(self):\n        """"""Returns the version of Festival and of PyFestival.\n        """"""\n        args = [self._festival_bin, ""--version""]\n        p = subprocess.Popen( args,\n                              stdin = subprocess.PIPE,\n                              stdout = subprocess.PIPE,\n                              stderr = subprocess.PIPE,\n                              close_fds = True)\n        stdout, stderr = p.communicate()\n       \n        stdout += ""\\n""\n        stdout += ""PyFestival version: "" + __version__\n        return stdout\n   \n    def _save_file(self, filename, contents, mode=""w""):\n        """"""Saves the contents to the filename.\n       \n        Mode indicates the mode with which the file should\n        be opened (\'w\',\'wb\',\'a\', or \'ab\').  If an error occurs when\n        writing the file, a simple message is printed to stdout.\n        """"""\n        try:\n            f = open(filename, mode)\n            f.write(contents)\n            # clean up the resource\n            f.close()\n        except Exception:\n            print ""Execption: ""+filename+"" could not be saved.""\n       \n   \n    def _read_file(self, filename, mode=""r""):\n        """"""Reads the contents of a file.\n       \n        The contents are returned, unless there is an error reading\n        the file, in which case None is returned.  The mode specifies\n        the mode to read the file in--should be \'r\' or \'rb\'.\n        """"""\n        # default the return value\n        contents = None\n        try:\n            # open and read the file (asssumes that file will fit into memory""\n            f = open(filename, mode)\n            contents = f.read()\n            # clean up resources\n            f.close()\n        except Exception:\n            print ""Execption: ""+filename+"" could not be read.""\n        return contents\n           \n   \n    def _say_server(self, text):\n        """"""Uses the Festival server to speak the text.\n       \n        A connection to the server must be open.\n        """"""\n        if self._server == None:\n            raise ServerError(""No server started"")\n       \n           \n           \n    def _say_single(self, text):\n        """"""Uses Festival tts mode and the command line.\n       \n        Does not bother using the server connection.""""""\n        args = [self._festival_bin, ""--tts"", ""-""]\n       \n        p = subprocess.Popen( args,\n                              stdin = subprocess.PIPE,\n                              stdout = subprocess.PIPE,\n                              stderr = subprocess.PIPE,\n                              close_fds = True)\n        stdout, stderr = p.communicate(text)\n       \n\n\nclass FestivalServer(object):\n    def __init__(self):\n        # initialize the process\n        self._process = None\n        #self._festival_bin = ""festival"" # TODO Added this dellanar04\n        try:\n            self.start()\n        except ServerError, e:\n            pass\n\n    def start(self):\n        args = [self._festival_bin, ""--server""]\n        self._process = subprocess.Popen( args,\n                              stdin = subprocess.PIPE,\n                              stdout = subprocess.PIPE,\n                              stderr = subprocess.PIPE,\n                              close_fds = True)\n        stdout, stderr = self._process.communicate()\n       \n        if stderr.rstrip() == ""socket: bind failed"":\n            raise ServerError(stderr.rstrip())\n       \n        #self._pid = os.spawnlp(os.P_NOWAIT, ""festival"",""festival"", ""--server"")\n        #print self._pid\n           \n    def stop(self):\n        """"""Kill the instance of the festival server.\n       \n        """"""\n        if self.get_pid() != None:\n            try:\n                os.kill(self._pid, signal.SIGTERM)\n            except OSError:\n                print ""Error killing the festival server""\n        else:\n            print ""No festival server process to stop""\n           \n    def restart(self):\n        self.stop()\n        self.start()\n   \n    def get_pid(self):\n        if self._process != None:\n            return self._process.pid\n        else:\n            return None\n\nclass FestivalClient(object):\n    def __init__(self, port=1314, host=""localhost""):\n        self._host = host\n        self._port = port\n        self._sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n       \n    def open(self):\n        self._sock.connect((self._host, self._port))\n       \n    def close(self):\n        self._sock.close()\n       \n    def send(self, cmd):\n        self._sock.send(cmd)\n   \n    def recv(self):\n        data = self._sock.recv()\n        return None\n   \n    def say(self, text):\n        self.send(\'(SayText ""%s""\'%text)\n   \n   \nclass TooFewArgumentsError(Exception):\n    def __init__(self, value):\n        self.value = value\n    def __str__(self):\n        return repr(self.value)\nclass ServerError(Exception):\n    def __init__(self, value):\n        self.value = value\n    def __str__(self):\n        return repr(self.value)\n\n\ndef say(text):\n    """"""Quick access for the impatient.\n   \n    Speaks the provided text.\n    """"""\n    #create a single instance to say this one phrase\n    fest = Festival()\n    fest.say(text)\n    \n'"
car/scripts/runModel.py,2,"b'#!/usr/bin/env python\n\n""""""\nCopyright (c) 2017 Daniel Tobias, Ryan Dellana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nimport numpy as np\nimport rospy\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\nfrom geometry_msgs.msg import Twist, TwistStamped\nfrom std_msgs.msg import String\nfrom Xbox360 import XBox360\nimport cv2\nfrom subprocess import call\nfrom sensor_msgs.msg import Joy\nimport tensorflow as tf\nfrom car_models import cnn_cccccfffff\n\n""""""\nThis node restores a saved TF model that was trained on a host computer\n\nNote:\n1. Toggle the publishing of the twist msg with right bumper on the xbox 360 controller\n2. Steering output from the trained model is mapped from 0.0 to 1.0 where 0.0 is left, 1.0 is right and 0.5 is center\n""""""\nclass runCNN(object):\n\n    def __init__(self):\n        rospy.loginfo(""runner.__init__"")\n        # ----------------------------\n        self.sess = tf.InteractiveSession()\n        self.model = cnn_cccccfffff()\n        saver = tf.train.Saver()\n        saver.restore(self.sess, ""/home/ubuntu/catkin_ws/src/car/scripts/model.ckpt"")\n        rospy.loginfo(""runner.__init__: model restored"")\n        # ----------------------------\n        self.bridge = CvBridge()\n        self.netEnable = False\n        self.controller = XBox360()\n        rospy.Subscriber(""/camera/rgb/image_rect_color"", Image, self.runCB)\n        rospy.Subscriber(""/joy"", Joy ,self.joyCB)\n        self.pub_twist = rospy.Publisher(""/neural_twist"", TwistStamped, queue_size=1)\n        self.sound = rospy.Publisher(""/sound_server/speech_synth"", String, queue_size=1)\n        rospy.init_node(\'neural_cmd\',anonymous=True)\n        rospy.spin()\n\n\n    def runCB(self, pic):\n        rospy.loginfo(""image recieved"")\n        if self.netEnable == True: \n            cmd = TwistStamped()\n            cv2image = self.bridge.imgmsg_to_cv2(pic)\n            cv2image = cv2.resize(cv2image, (200,150), interpolation = cv2.INTER_CUBIC)\n            cv2image = cv2image[35:,:,:]\n            normed_img = cv2image.astype(dtype=np.float32)/255.0\n            #normed_img = np.reshape(normed_img, (115, 200, 1))\n            steer = self.model.y_out.eval(session=self.sess, feed_dict={self.model.x: [normed_img], \n                                              self.model.keep_prob_fc1:1.0, self.model.keep_prob_fc2:1.0, \n                                              self.model.keep_prob_fc3:1.0, self.model.keep_prob_fc4:1.0})\n            rospy.loginfo(""steering angle ="" + str((steer[0][0])))\n            cmd.twist.angular.z = steer[0][0]\n            rospy.loginfo(""steering angle ="" + str(cmd.twist.angular.z))\n            self.pub_twist.publish(cmd)\n            \n        \n    def joyCB(self, joy):        \n        self.controller.update(joy)\n        events = self.controller.buttonEvents()\n        if \'RB_pressed\' in events:\n            self.netEnable = not self.netEnable\n            if self.netEnable == True:\n                self.sound.publish(""Neural Network On"")\n            else:\n                self.sound.publish(""Neural Network Off"")\n\nif __name__ == \'__main__\':\n    try:\n        runCNN()\n    except rospy.ROSInterruptException:\n        pass\n'"
