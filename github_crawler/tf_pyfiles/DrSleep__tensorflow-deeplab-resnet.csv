file_path,api_count,code
convert.py,0,"b""#!/usr/bin/env python\n\n# This script belongs to https://github.com/ethereon/caffe-tensorflow\nimport os\nimport sys\nimport numpy as np\nimport argparse\nfrom kaffe import KaffeError, print_stderr\nfrom kaffe.tensorflow import TensorFlowTransformer\n\n\ndef fatal_error(msg):\n    print_stderr(msg)\n    exit(-1)\n\n\ndef validate_arguments(args):\n    if (args.data_output_path is not None) and (args.caffemodel is None):\n        fatal_error('No input data path provided.')\n    if (args.caffemodel is not None) and (args.data_output_path is None):\n        fatal_error('No output data path provided.')\n    if (args.code_output_path is None) and (args.data_output_path is None):\n        fatal_error('No output path specified.')\n\n\ndef convert(def_path, caffemodel_path, data_output_path, code_output_path, phase):\n    try:\n        transformer = TensorFlowTransformer(def_path, caffemodel_path, phase=phase)\n        print_stderr('Converting data...')\n        if caffemodel_path is not None:\n            data = transformer.transform_data()\n            print_stderr('Saving data...')\n            with open(data_output_path, 'wb') as data_out:\n                np.save(data_out, data)\n        if code_output_path:\n            print_stderr('Saving source...')\n            with open(code_output_path, 'wb') as src_out:\n                src_out.write(transformer.transform_source())\n        print_stderr('Done.')\n    except KaffeError as err:\n        fatal_error('Error encountered: {}'.format(err))\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('def_path', help='Model definition (.prototxt) path')\n    parser.add_argument('--caffemodel', help='Model data (.caffemodel) path')\n    parser.add_argument('--data-output-path', help='Converted data output path')\n    parser.add_argument('--code-output-path', help='Save generated source to this path')\n    parser.add_argument('-p',\n                        '--phase',\n                        default='test',\n                        help='The phase to convert: test (default) or train')\n    args = parser.parse_args()\n    validate_arguments(args)\n    convert(args.def_path, args.caffemodel, args.data_output_path, args.code_output_path,\n            args.phase)\n\n\nif __name__ == '__main__':\n    main()\n"""
evaluate.py,17,"b'""""""Evaluation script for the DeepLab-ResNet network on the validation subset\n   of PASCAL VOC dataset.\n\nThis script evaluates the model on 1449 validation images.\n""""""\n\nfrom __future__ import print_function\n\nimport argparse\nfrom datetime import datetime\nimport os\nimport sys\nimport time\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom deeplab_resnet import DeepLabResNetModel, ImageReader, prepare_label\n\nIMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n\nDATA_DIRECTORY = \'/home/VOCdevkit\'\nDATA_LIST_PATH = \'./dataset/val.txt\'\nIGNORE_LABEL = 255\nNUM_CLASSES = 21\nNUM_STEPS = 1449 # Number of images in the validation set.\nRESTORE_FROM = \'./deeplab_resnet.ckpt\'\n\ndef get_arguments():\n    """"""Parse all the arguments provided from the CLI.\n    \n    Returns:\n      A list of parsed arguments.\n    """"""\n    parser = argparse.ArgumentParser(description=""DeepLabLFOV Network"")\n    parser.add_argument(""--data-dir"", type=str, default=DATA_DIRECTORY,\n                        help=""Path to the directory containing the PASCAL VOC dataset."")\n    parser.add_argument(""--data-list"", type=str, default=DATA_LIST_PATH,\n                        help=""Path to the file listing the images in the dataset."")\n    parser.add_argument(""--ignore-label"", type=int, default=IGNORE_LABEL,\n                        help=""The index of the label to ignore during the training."")\n    parser.add_argument(""--num-classes"", type=int, default=NUM_CLASSES,\n                        help=""Number of classes to predict (including background)."")\n    parser.add_argument(""--num-steps"", type=int, default=NUM_STEPS,\n                        help=""Number of images in the validation set."")\n    parser.add_argument(""--restore-from"", type=str, default=RESTORE_FROM,\n                        help=""Where restore model parameters from."")\n    return parser.parse_args()\n\ndef load(saver, sess, ckpt_path):\n    \'\'\'Load trained weights.\n    \n    Args:\n      saver: TensorFlow saver object.\n      sess: TensorFlow session.\n      ckpt_path: path to checkpoint file with parameters.\n    \'\'\' \n    saver.restore(sess, ckpt_path)\n    print(""Restored model parameters from {}"".format(ckpt_path))\n\ndef main():\n    """"""Create the model and start the evaluation process.""""""\n    args = get_arguments()\n    \n    # Create queue coordinator.\n    coord = tf.train.Coordinator()\n    \n    # Load reader.\n    with tf.name_scope(""create_inputs""):\n        reader = ImageReader(\n            args.data_dir,\n            args.data_list,\n            None, # No defined input size.\n            False, # No random scale.\n            False, # No random mirror.\n            args.ignore_label,\n            IMG_MEAN,\n            coord)\n        image, label = reader.image, reader.label\n    image_batch, label_batch = tf.expand_dims(image, dim=0), tf.expand_dims(label, dim=0) # Add one batch dimension.\n\n    # Create network.\n    net = DeepLabResNetModel({\'data\': image_batch}, is_training=False, num_classes=args.num_classes)\n\n    # Which variables to load.\n    restore_var = tf.global_variables()\n    \n    # Predictions.\n    raw_output = net.layers[\'fc1_voc12\']\n    raw_output = tf.image.resize_bilinear(raw_output, tf.shape(image_batch)[1:3,])\n    raw_output = tf.argmax(raw_output, dimension=3)\n    pred = tf.expand_dims(raw_output, dim=3) # Create 4-d tensor.\n    \n    # mIoU\n    pred = tf.reshape(pred, [-1,])\n    gt = tf.reshape(label_batch, [-1,])\n    weights = tf.cast(tf.less_equal(gt, args.num_classes - 1), tf.int32) # Ignoring all labels greater than or equal to n_classes.\n    mIoU, update_op = tf.contrib.metrics.streaming_mean_iou(pred, gt, num_classes=args.num_classes, weights=weights)\n    \n    # Set up tf session and initialize variables. \n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    init = tf.global_variables_initializer()\n    \n    sess.run(init)\n    sess.run(tf.local_variables_initializer())\n    \n    # Load weights.\n    loader = tf.train.Saver(var_list=restore_var)\n    if args.restore_from is not None:\n        load(loader, sess, args.restore_from)\n    \n    # Start queue threads.\n    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n    \n    # Iterate over training steps.\n    for step in range(args.num_steps):\n        preds, _ = sess.run([pred, update_op])\n        if step % 100 == 0:\n            print(\'step {:d}\'.format(step))\n    print(\'Mean IoU: {:.3f}\'.format(mIoU.eval(session=sess)))\n    coord.request_stop()\n    coord.join(threads)\n    \nif __name__ == \'__main__\':\n    main()\n'"
evaluate_msc.py,26,"b'""""""Evaluation script for the DeepLab-ResNet network on the validation subset\n   of PASCAL VOC dataset.\n\nThis script evaluates the model on 1449 validation images.\n""""""\n\nfrom __future__ import print_function\n\nimport argparse\nfrom datetime import datetime\nimport os\nimport sys\nimport time\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom deeplab_resnet import DeepLabResNetModel, ImageReader, prepare_label\n\nIMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n\nDATA_DIRECTORY = \'/home/VOCdevkit\'\nDATA_LIST_PATH = \'./dataset/val.txt\'\nIGNORE_LABEL = 255\nNUM_CLASSES = 21\nNUM_STEPS = 1449 # Number of images in the validation set.\nRESTORE_FROM = \'./deeplab_resnet.ckpt\'\n\ndef get_arguments():\n    """"""Parse all the arguments provided from the CLI.\n    \n    Returns:\n      A list of parsed arguments.\n    """"""\n    parser = argparse.ArgumentParser(description=""DeepLabLFOV Network"")\n    parser.add_argument(""--data-dir"", type=str, default=DATA_DIRECTORY,\n                        help=""Path to the directory containing the PASCAL VOC dataset."")\n    parser.add_argument(""--data-list"", type=str, default=DATA_LIST_PATH,\n                        help=""Path to the file listing the images in the dataset."")\n    parser.add_argument(""--ignore-label"", type=int, default=IGNORE_LABEL,\n                        help=""The index of the label to ignore during the training."")\n    parser.add_argument(""--num-classes"", type=int, default=NUM_CLASSES,\n                        help=""Number of classes to predict (including background)."")\n    parser.add_argument(""--num-steps"", type=int, default=NUM_STEPS,\n                        help=""Number of images in the validation set."")\n    parser.add_argument(""--restore-from"", type=str, default=RESTORE_FROM,\n                        help=""Where restore model parameters from."")\n    return parser.parse_args()\n\ndef load(saver, sess, ckpt_path):\n    \'\'\'Load trained weights.\n    \n    Args:\n      saver: TensorFlow saver object.\n      sess: TensorFlow session.\n      ckpt_path: path to checkpoint file with parameters.\n    \'\'\' \n    saver.restore(sess, ckpt_path)\n    print(""Restored model parameters from {}"".format(ckpt_path))\n\ndef main():\n    """"""Create the model and start the evaluation process.""""""\n    args = get_arguments()\n    \n    # Create queue coordinator.\n    coord = tf.train.Coordinator()\n    \n    # Load reader.\n    with tf.name_scope(""create_inputs""):\n        reader = ImageReader(\n            args.data_dir,\n            args.data_list,\n            None, # No defined input size.\n            False, # No random scale.\n            False, # No random mirror.\n            args.ignore_label,\n            IMG_MEAN,\n            coord)\n        image, label = reader.image, reader.label\n\n    image_batch, label_batch = tf.expand_dims(image, dim=0), tf.expand_dims(label, dim=0) # Add one batch dimension.\n    h_orig, w_orig = tf.to_float(tf.shape(image_batch)[1]), tf.to_float(tf.shape(image_batch)[2])\n    image_batch075 = tf.image.resize_images(image_batch, tf.stack([tf.to_int32(tf.multiply(h_orig, 0.75)), tf.to_int32(tf.multiply(w_orig, 0.75))]))\n    image_batch05 = tf.image.resize_images(image_batch, tf.stack([tf.to_int32(tf.multiply(h_orig, 0.5)), tf.to_int32(tf.multiply(w_orig, 0.5))]))\n    \n    # Create network.\n    with tf.variable_scope(\'\', reuse=False):\n        net = DeepLabResNetModel({\'data\': image_batch}, is_training=False, num_classes=args.num_classes)\n    with tf.variable_scope(\'\', reuse=True):\n        net075 = DeepLabResNetModel({\'data\': image_batch075}, is_training=False, num_classes=args.num_classes)\n    with tf.variable_scope(\'\', reuse=True):\n        net05 = DeepLabResNetModel({\'data\': image_batch05}, is_training=False, num_classes=args.num_classes)\n\n    # Which variables to load.\n    restore_var = tf.global_variables()\n    \n    # Predictions.\n    raw_output100 = net.layers[\'fc1_voc12\']\n    raw_output075 = tf.image.resize_images(net075.layers[\'fc1_voc12\'], tf.shape(raw_output100)[1:3,])\n    raw_output05 = tf.image.resize_images(net05.layers[\'fc1_voc12\'], tf.shape(raw_output100)[1:3,])\n    \n    raw_output = tf.reduce_max(tf.stack([raw_output100, raw_output075, raw_output05]), axis=0)\n    raw_output = tf.image.resize_bilinear(raw_output, tf.shape(image_batch)[1:3,])\n    raw_output = tf.argmax(raw_output, dimension=3)\n    pred = tf.expand_dims(raw_output, dim=3) # Create 4-d tensor.\n    \n    # mIoU\n    pred = tf.reshape(pred, [-1,])\n    gt = tf.reshape(label_batch, [-1,])\n    weights = tf.cast(tf.less_equal(gt, args.num_classes - 1), tf.int32) # Ignoring all labels greater than or equal to n_classes.\n    mIoU, update_op = tf.contrib.metrics.streaming_mean_iou(pred, gt, num_classes=args.num_classes, weights=weights)\n    \n    # Set up tf session and initialize variables. \n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    init = tf.global_variables_initializer()\n    \n    sess.run(init)\n    sess.run(tf.local_variables_initializer())\n    \n    # Load weights.\n    loader = tf.train.Saver(var_list=restore_var)\n    if args.restore_from is not None:\n        load(loader, sess, args.restore_from)\n    \n    # Start queue threads.\n    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n    \n    # Iterate over training steps.\n    for step in range(args.num_steps):\n        preds, _ = sess.run([pred, update_op])\n        if step % 100 == 0:\n            print(\'step {:d}\'.format(step))\n    print(\'Mean IoU: {:.3f}\'.format(mIoU.eval(session=sess)))\n    coord.request_stop()\n    coord.join(threads)\n    \nif __name__ == \'__main__\':\n    main()\n'"
fine_tune.py,27,"b'""""""Training script for the DeepLab-ResNet network on the PASCAL VOC dataset\n   for semantic image segmentation.\n\nThis script fine-tunes the model using augmented PASCAL VOC,\nwhich contains approximately 10000 images for training and 1500 images for validation.\nOnly the last \'fc1_voc12\' layers are being trained.\n""""""\n\nfrom __future__ import print_function\n\nimport argparse\nfrom datetime import datetime\nimport os\nimport sys\nimport time\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom deeplab_resnet import DeepLabResNetModel, ImageReader, decode_labels, inv_preprocess, prepare_label\n\nIMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n\nBATCH_SIZE = 4\nDATA_DIRECTORY = \'/home/VOCdevkit\'\nDATA_LIST_PATH = \'./dataset/train.txt\'\nIGNORE_LABEL = 255\nINPUT_SIZE = \'321,321\'\nLEARNING_RATE = 1e-4\nNUM_CLASSES = 21\nNUM_STEPS = 20000\nRANDOM_SEED = 1234\nRESTORE_FROM = \'./deeplab_resnet.ckpt\'\nSAVE_NUM_IMAGES = 2\nSAVE_PRED_EVERY = 100\nSNAPSHOT_DIR = \'./snapshots_finetune/\'\n\ndef get_arguments():\n    """"""Parse all the arguments provided from the CLI.\n    \n    Returns:\n      A list of parsed arguments.\n    """"""\n    parser = argparse.ArgumentParser(description=""DeepLab-ResNet Network"")\n    parser.add_argument(""--batch-size"", type=int, default=BATCH_SIZE,\n                        help=""Number of images sent to the network in one step."")\n    parser.add_argument(""--data-dir"", type=str, default=DATA_DIRECTORY,\n                        help=""Path to the directory containing the PASCAL VOC dataset."")\n    parser.add_argument(""--data-list"", type=str, default=DATA_LIST_PATH,\n                        help=""Path to the file listing the images in the dataset."")\n    parser.add_argument(""--ignore-label"", type=int, default=IGNORE_LABEL,\n                        help=""The index of the label to ignore during the training."")\n    parser.add_argument(""--input-size"", type=str, default=INPUT_SIZE,\n                        help=""Comma-separated string with height and width of images."")\n    parser.add_argument(""--is-training"", action=""store_true"",\n                        help=""Whether to updates the running means and variances during the training."")\n    parser.add_argument(""--learning-rate"", type=float, default=LEARNING_RATE,\n                        help=""Learning rate for training."")\n    parser.add_argument(""--not-restore-last"", action=""store_true"",\n                        help=""Whether to not restore last (FC) layers."")\n    parser.add_argument(""--num-classes"", type=int, default=NUM_CLASSES,\n                        help=""Number of classes to predict (including background)."")\n    parser.add_argument(""--num-steps"", type=int, default=NUM_STEPS,\n                        help=""Number of training steps."")\n    parser.add_argument(""--random-mirror"", action=""store_true"",\n                        help=""Whether to randomly mirror the inputs during the training."")\n    parser.add_argument(""--random-scale"", action=""store_true"",\n                        help=""Whether to randomly scale the inputs during the training."")\n    parser.add_argument(""--random-seed"", type=int, default=RANDOM_SEED,\n                        help=""Random seed to have reproducible results."")\n    parser.add_argument(""--restore-from"", type=str, default=RESTORE_FROM,\n                        help=""Where restore model parameters from."")\n    parser.add_argument(""--save-num-images"", type=int, default=SAVE_NUM_IMAGES,\n                        help=""How many images to save."")\n    parser.add_argument(""--save-pred-every"", type=int, default=SAVE_PRED_EVERY,\n                        help=""Save summaries and checkpoint every often."")\n    parser.add_argument(""--snapshot-dir"", type=str, default=SNAPSHOT_DIR,\n                        help=""Where to save snapshots of the model."")\n    return parser.parse_args()\n\ndef save(saver, sess, logdir, step):\n    model_name = \'model.ckpt\'\n    checkpoint_path = os.path.join(logdir, model_name)\n    \n    if not os.path.exists(logdir):\n        os.makedirs(logdir)\n\n    saver.save(sess, checkpoint_path, global_step=step)\n    print(\'The checkpoint has been created.\')\n\ndef load(saver, sess, ckpt_path):\n    \'\'\'Load trained weights.\n    \n    Args:\n      saver: TensorFlow saver object.\n      sess: TensorFlow session.\n      ckpt_path: path to checkpoint file with parameters.\n    \'\'\' \n    saver.restore(sess, ckpt_path)\n    print(""Restored model parameters from {}"".format(ckpt_path))\n\ndef main():\n    """"""Create the model and start the training.""""""\n    args = get_arguments()\n    \n    h, w = map(int, args.input_size.split(\',\'))\n    input_size = (h, w)\n    \n    tf.set_random_seed(args.random_seed)\n    \n    # Create queue coordinator.\n    coord = tf.train.Coordinator()\n    \n    # Load reader.\n    with tf.name_scope(""create_inputs""):\n        reader = ImageReader(\n            args.data_dir,\n            args.data_list,\n            input_size,\n            args.random_scale,\n            args.random_mirror,\n            args.ignore_label,\n            IMG_MEAN,\n            coord)\n        image_batch, label_batch = reader.dequeue(args.batch_size)\n    \n    # Create network.\n    net = DeepLabResNetModel({\'data\': image_batch}, is_training=args.is_training, num_classes=args.num_classes)\n    # For a small batch size, it is better to keep \n    # the statistics of the BN layers (running means and variances)\n    # frozen, and to not update the values provided by the pre-trained model. \n    # If is_training=True, the statistics will be updated during the training.\n    # Note that is_training=False still updates BN parameters gamma (scale) and beta (offset)\n    # if they are presented in var_list of the optimiser definition.\n\n    # Predictions.\n    raw_output = net.layers[\'fc1_voc12\']\n    # Which variables to load. Running means and variances are not trainable,\n    # thus all_variables() should be restored.\n    # Restore all variables, or all except the last ones.\n    restore_var = [v for v in tf.global_variables() if \'fc\' not in v.name or not args.not_restore_last]\n    trainable = [v for v in tf.trainable_variables() if \'fc1_voc12\' in v.name] # Fine-tune only the last layers.\n    \n    prediction = tf.reshape(raw_output, [-1, args.num_classes])\n    label_proc = prepare_label(label_batch, tf.stack(raw_output.get_shape()[1:3]), num_classes=args.num_classes)\n    gt = tf.reshape(label_proc, [-1, args.num_classes])\n    \n    # Pixel-wise softmax loss.\n    loss = tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=gt)\n    reduced_loss = tf.reduce_mean(loss)\n    \n    # Processed predictions.\n    raw_output_up = tf.image.resize_bilinear(raw_output, tf.shape(image_batch)[1:3,])\n    raw_output_up = tf.argmax(raw_output_up, dimension=3)\n    pred = tf.expand_dims(raw_output_up, dim=3)\n    \n    # Image summary.\n    images_summary = tf.py_func(inv_preprocess, [image_batch, args.save_num_images, IMG_MEAN], tf.uint8)\n    labels_summary = tf.py_func(decode_labels, [label_batch, args.save_num_images, args.num_classes], tf.uint8)\n    preds_summary = tf.py_func(decode_labels, [pred, args.save_num_images, args.num_classes], tf.uint8)\n    \n    total_summary = tf.summary.image(\'images\', \n                                     tf.concat(axis=2, values=[images_summary, labels_summary, preds_summary]), \n                                     max_outputs=args.save_num_images) # Concatenate row-wise.\n    summary_writer = tf.summary.FileWriter(args.snapshot_dir,\n                                           graph=tf.get_default_graph())\n   \n    # Define loss and optimisation parameters.\n    optimiser = tf.train.AdamOptimizer(learning_rate=args.learning_rate)\n    optim = optimiser.minimize(reduced_loss, var_list=trainable)\n    \n    # Set up tf session and initialize variables. \n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    init = tf.global_variables_initializer()\n    \n    sess.run(init)\n    \n    # Saver for storing checkpoints of the model.\n    saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=40)\n    \n    # Load variables if the checkpoint is provided.\n    if args.restore_from is not None:\n        loader = tf.train.Saver(var_list=restore_var)\n        load(loader, sess, args.restore_from)\n    \n    # Start queue threads.\n    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n        \n    # Iterate over training steps.\n    for step in range(args.num_steps):\n        start_time = time.time()\n        \n        if step % args.save_pred_every == 0:\n            loss_value, images, labels, preds, summary, _ = sess.run([reduced_loss, image_batch, label_batch, pred, total_summary, optim])\n            summary_writer.add_summary(summary, step)\n            save(saver, sess, args.snapshot_dir, step)\n        else:\n            loss_value, _ = sess.run([reduced_loss, optim])\n        duration = time.time() - start_time\n        print(\'step {:d} \\t loss = {:.3f}, ({:.3f} sec/step)\'.format(step, loss_value, duration))\n    coord.request_stop()\n    coord.join(threads)\n    \nif __name__ == \'__main__\':\n    main()\n'"
inference.py,12,"b'""""""Run DeepLab-ResNet on a given image.\n\nThis script computes a segmentation mask for a given image.\n""""""\n\nfrom __future__ import print_function\n\nimport argparse\nfrom datetime import datetime\nimport os\nimport sys\nimport time\n\nfrom PIL import Image\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom deeplab_resnet import DeepLabResNetModel, ImageReader, decode_labels, prepare_label\n\nIMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n    \nNUM_CLASSES = 21\nSAVE_DIR = \'./output/\'\n\ndef get_arguments():\n    """"""Parse all the arguments provided from the CLI.\n    \n    Returns:\n      A list of parsed arguments.\n    """"""\n    parser = argparse.ArgumentParser(description=""DeepLabLFOV Network Inference."")\n    parser.add_argument(""img_path"", type=str,\n                        help=""Path to the RGB image file."")\n    parser.add_argument(""model_weights"", type=str,\n                        help=""Path to the file with model weights."")\n    parser.add_argument(""--num-classes"", type=int, default=NUM_CLASSES,\n                        help=""Number of classes to predict (including background)."")\n    parser.add_argument(""--save-dir"", type=str, default=SAVE_DIR,\n                        help=""Where to save predicted mask."")\n    return parser.parse_args()\n\ndef load(saver, sess, ckpt_path):\n    \'\'\'Load trained weights.\n    \n    Args:\n      saver: TensorFlow saver object.\n      sess: TensorFlow session.\n      ckpt_path: path to checkpoint file with parameters.\n    \'\'\' \n    saver.restore(sess, ckpt_path)\n    print(""Restored model parameters from {}"".format(ckpt_path))\n\ndef main():\n    """"""Create the model and start the evaluation process.""""""\n    args = get_arguments()\n    \n    # Prepare image.\n    img = tf.image.decode_jpeg(tf.read_file(args.img_path), channels=3)\n    # Convert RGB to BGR.\n    img_r, img_g, img_b = tf.split(axis=2, num_or_size_splits=3, value=img)\n    img = tf.cast(tf.concat(axis=2, values=[img_b, img_g, img_r]), dtype=tf.float32)\n    # Extract mean.\n    img -= IMG_MEAN \n    \n    # Create network.\n    net = DeepLabResNetModel({\'data\': tf.expand_dims(img, dim=0)}, is_training=False, num_classes=args.num_classes)\n\n    # Which variables to load.\n    restore_var = tf.global_variables()\n\n    # Predictions.\n    raw_output = net.layers[\'fc1_voc12\']\n    raw_output_up = tf.image.resize_bilinear(raw_output, tf.shape(img)[0:2,])\n    raw_output_up = tf.argmax(raw_output_up, dimension=3)\n    pred = tf.expand_dims(raw_output_up, dim=3)\n\n    \n    # Set up TF session and initialize variables. \n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    init = tf.global_variables_initializer()\n    \n    sess.run(init)\n    \n    # Load weights.\n    loader = tf.train.Saver(var_list=restore_var)\n    load(loader, sess, args.model_weights)\n    \n    # Perform inference.\n    preds = sess.run(pred)\n    \n    msk = decode_labels(preds, num_classes=args.num_classes)\n    im = Image.fromarray(msk[0])\n    if not os.path.exists(args.save_dir):\n        os.makedirs(args.save_dir)\n    im.save(args.save_dir + \'mask.png\')\n    \n    print(\'The output file has been saved to {}\'.format(args.save_dir + \'mask.png\'))\n\n    \nif __name__ == \'__main__\':\n    main()\n'"
npy2ckpt.py,6,"b'""""""Conversion of the .npy weights into the .ckpt ones.\n\nThis script converts the weights of the DeepLab-ResNet model\nfrom the numpy format into the TensorFlow one.\n""""""\n\nfrom __future__ import print_function\n\nimport argparse\nimport os\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom deeplab_resnet import DeepLabResNetModel\n\nSAVE_DIR = \'./\'\n\ndef get_arguments():\n    """"""Parse all the arguments provided from the CLI.\n    \n    Returns:\n      A list of parsed arguments.\n    """"""\n    parser = argparse.ArgumentParser(description=""NPY to CKPT converter."")\n    parser.add_argument(""npy_path"", type=str,\n                        help=""Path to the .npy file, which contains the weights."")\n    parser.add_argument(""--save-dir"", type=str, default=SAVE_DIR,\n                        help=""Where to save the converted .ckpt file."")\n    return parser.parse_args()\n\ndef save(saver, sess, logdir):\n    model_name = \'model.ckpt\'\n    checkpoint_path = os.path.join(logdir, model_name)\n    \n    if not os.path.exists(logdir):\n        os.makedirs(logdir)\n\n    saver.save(sess, checkpoint_path, write_meta_graph=False)\n    print(\'The weights have been converted to {}.\'.format(checkpoint_path))\n\n\ndef main():\n    """"""Create the model and start the training.""""""\n    args = get_arguments()\n    \n    # Default image.\n    image_batch = tf.constant(0, tf.float32, shape=[1, 321, 321, 3]) \n    # Create network.\n    net = DeepLabResNetModel({\'data\': image_batch})\n    var_list = tf.global_variables()\n          \n    # Set up tf session and initialize variables. \n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    \n    with tf.Session(config=config) as sess:\n          init = tf.global_variables_initializer()\n          sess.run(init)\n          \n          # Loading .npy weights.\n          net.load(args.npy_path, sess)\n          \n          # Saver for converting the loaded weights into .ckpt.\n          saver = tf.train.Saver(var_list=var_list, write_version=1)\n          save(saver, sess, args.save_dir)\n\nif __name__ == \'__main__\':\n    main()\n'"
train.py,38,"b'""""""Training script for the DeepLab-ResNet network on the PASCAL VOC dataset\n   for semantic image segmentation.\n\nThis script trains the model using augmented PASCAL VOC,\nwhich contains approximately 10000 images for training and 1500 images for validation.\n""""""\n\nfrom __future__ import print_function\n\nimport argparse\nfrom datetime import datetime\nimport os\nimport sys\nimport time\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom deeplab_resnet import DeepLabResNetModel, ImageReader, decode_labels, inv_preprocess, prepare_label\n\nIMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n\nBATCH_SIZE = 10\nDATA_DIRECTORY = \'/home/VOCdevkit\'\nDATA_LIST_PATH = \'./dataset/train.txt\'\nIGNORE_LABEL = 255\nINPUT_SIZE = \'321,321\'\nLEARNING_RATE = 2.5e-4\nMOMENTUM = 0.9\nNUM_CLASSES = 21\nNUM_STEPS = 20001\nPOWER = 0.9\nRANDOM_SEED = 1234\nRESTORE_FROM = \'./deeplab_resnet.ckpt\'\nSAVE_NUM_IMAGES = 2\nSAVE_PRED_EVERY = 1000\nSNAPSHOT_DIR = \'./snapshots/\'\nWEIGHT_DECAY = 0.0005\n\n\ndef get_arguments():\n    """"""Parse all the arguments provided from the CLI.\n    \n    Returns:\n      A list of parsed arguments.\n    """"""\n    parser = argparse.ArgumentParser(description=""DeepLab-ResNet Network"")\n    parser.add_argument(""--batch-size"", type=int, default=BATCH_SIZE,\n                        help=""Number of images sent to the network in one step."")\n    parser.add_argument(""--data-dir"", type=str, default=DATA_DIRECTORY,\n                        help=""Path to the directory containing the PASCAL VOC dataset."")\n    parser.add_argument(""--data-list"", type=str, default=DATA_LIST_PATH,\n                        help=""Path to the file listing the images in the dataset."")\n    parser.add_argument(""--ignore-label"", type=int, default=IGNORE_LABEL,\n                        help=""The index of the label to ignore during the training."")\n    parser.add_argument(""--input-size"", type=str, default=INPUT_SIZE,\n                        help=""Comma-separated string with height and width of images."")\n    parser.add_argument(""--is-training"", action=""store_true"",\n                        help=""Whether to updates the running means and variances during the training."")\n    parser.add_argument(""--learning-rate"", type=float, default=LEARNING_RATE,\n                        help=""Base learning rate for training with polynomial decay."")\n    parser.add_argument(""--momentum"", type=float, default=MOMENTUM,\n                        help=""Momentum component of the optimiser."")\n    parser.add_argument(""--not-restore-last"", action=""store_true"",\n                        help=""Whether to not restore last (FC) layers."")\n    parser.add_argument(""--num-classes"", type=int, default=NUM_CLASSES,\n                        help=""Number of classes to predict (including background)."")\n    parser.add_argument(""--num-steps"", type=int, default=NUM_STEPS,\n                        help=""Number of training steps."")\n    parser.add_argument(""--power"", type=float, default=POWER,\n                        help=""Decay parameter to compute the learning rate."")\n    parser.add_argument(""--random-mirror"", action=""store_true"",\n                        help=""Whether to randomly mirror the inputs during the training."")\n    parser.add_argument(""--random-scale"", action=""store_true"",\n                        help=""Whether to randomly scale the inputs during the training."")\n    parser.add_argument(""--random-seed"", type=int, default=RANDOM_SEED,\n                        help=""Random seed to have reproducible results."")\n    parser.add_argument(""--restore-from"", type=str, default=RESTORE_FROM,\n                        help=""Where restore model parameters from."")\n    parser.add_argument(""--save-num-images"", type=int, default=SAVE_NUM_IMAGES,\n                        help=""How many images to save."")\n    parser.add_argument(""--save-pred-every"", type=int, default=SAVE_PRED_EVERY,\n                        help=""Save summaries and checkpoint every often."")\n    parser.add_argument(""--snapshot-dir"", type=str, default=SNAPSHOT_DIR,\n                        help=""Where to save snapshots of the model."")\n    parser.add_argument(""--weight-decay"", type=float, default=WEIGHT_DECAY,\n                        help=""Regularisation parameter for L2-loss."")\n    return parser.parse_args()\n\ndef save(saver, sess, logdir, step):\n   \'\'\'Save weights.\n   \n   Args:\n     saver: TensorFlow Saver object.\n     sess: TensorFlow session.\n     logdir: path to the snapshots directory.\n     step: current training step.\n   \'\'\'\n   model_name = \'model.ckpt\'\n   checkpoint_path = os.path.join(logdir, model_name)\n    \n   if not os.path.exists(logdir):\n      os.makedirs(logdir)\n   saver.save(sess, checkpoint_path, global_step=step)\n   print(\'The checkpoint has been created.\')\n\ndef load(saver, sess, ckpt_path):\n    \'\'\'Load trained weights.\n    \n    Args:\n      saver: TensorFlow Saver object.\n      sess: TensorFlow session.\n      ckpt_path: path to checkpoint file with parameters.\n    \'\'\' \n    saver.restore(sess, ckpt_path)\n    print(""Restored model parameters from {}"".format(ckpt_path))\n\ndef main():\n    """"""Create the model and start the training.""""""\n    args = get_arguments()\n    \n    h, w = map(int, args.input_size.split(\',\'))\n    input_size = (h, w)\n    \n    tf.set_random_seed(args.random_seed)\n    \n    # Create queue coordinator.\n    coord = tf.train.Coordinator()\n    \n    # Load reader.\n    with tf.name_scope(""create_inputs""):\n        reader = ImageReader(\n            args.data_dir,\n            args.data_list,\n            input_size,\n            args.random_scale,\n            args.random_mirror,\n            args.ignore_label,\n            IMG_MEAN,\n            coord)\n        image_batch, label_batch = reader.dequeue(args.batch_size)\n    \n    # Create network.\n    net = DeepLabResNetModel({\'data\': image_batch}, is_training=args.is_training, num_classes=args.num_classes)\n    # For a small batch size, it is better to keep \n    # the statistics of the BN layers (running means and variances)\n    # frozen, and to not update the values provided by the pre-trained model. \n    # If is_training=True, the statistics will be updated during the training.\n    # Note that is_training=False still updates BN parameters gamma (scale) and beta (offset)\n    # if they are presented in var_list of the optimiser definition.\n\n    # Predictions.\n    raw_output = net.layers[\'fc1_voc12\']\n    # Which variables to load. Running means and variances are not trainable,\n    # thus all_variables() should be restored.\n    restore_var = [v for v in tf.global_variables() if \'fc\' not in v.name or not args.not_restore_last]\n    all_trainable = [v for v in tf.trainable_variables() if \'beta\' not in v.name and \'gamma\' not in v.name]\n    fc_trainable = [v for v in all_trainable if \'fc\' in v.name]\n    conv_trainable = [v for v in all_trainable if \'fc\' not in v.name] # lr * 1.0\n    fc_w_trainable = [v for v in fc_trainable if \'weights\' in v.name] # lr * 10.0\n    fc_b_trainable = [v for v in fc_trainable if \'biases\' in v.name] # lr * 20.0\n    assert(len(all_trainable) == len(fc_trainable) + len(conv_trainable))\n    assert(len(fc_trainable) == len(fc_w_trainable) + len(fc_b_trainable))\n    \n    \n    # Predictions: ignoring all predictions with labels greater or equal than n_classes\n    raw_prediction = tf.reshape(raw_output, [-1, args.num_classes])\n    label_proc = prepare_label(label_batch, tf.stack(raw_output.get_shape()[1:3]), num_classes=args.num_classes, one_hot=False) # [batch_size, h, w]\n    raw_gt = tf.reshape(label_proc, [-1,])\n    indices = tf.squeeze(tf.where(tf.less_equal(raw_gt, args.num_classes - 1)), 1)\n    gt = tf.cast(tf.gather(raw_gt, indices), tf.int32)\n    prediction = tf.gather(raw_prediction, indices)\n                                                  \n                                                  \n    # Pixel-wise softmax loss.\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction, labels=gt)\n    l2_losses = [args.weight_decay * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name]\n    reduced_loss = tf.reduce_mean(loss) + tf.add_n(l2_losses)\n    \n    # Processed predictions: for visualisation.\n    raw_output_up = tf.image.resize_bilinear(raw_output, tf.shape(image_batch)[1:3,])\n    raw_output_up = tf.argmax(raw_output_up, dimension=3)\n    pred = tf.expand_dims(raw_output_up, dim=3)\n    \n    # Image summary.\n    images_summary = tf.py_func(inv_preprocess, [image_batch, args.save_num_images, IMG_MEAN], tf.uint8)\n    labels_summary = tf.py_func(decode_labels, [label_batch, args.save_num_images, args.num_classes], tf.uint8)\n    preds_summary = tf.py_func(decode_labels, [pred, args.save_num_images, args.num_classes], tf.uint8)\n    \n    total_summary = tf.summary.image(\'images\', \n                                     tf.concat(axis=2, values=[images_summary, labels_summary, preds_summary]), \n                                     max_outputs=args.save_num_images) # Concatenate row-wise.\n    summary_writer = tf.summary.FileWriter(args.snapshot_dir,\n                                           graph=tf.get_default_graph())\n   \n    # Define loss and optimisation parameters.\n    base_lr = tf.constant(args.learning_rate)\n    step_ph = tf.placeholder(dtype=tf.float32, shape=())\n    learning_rate = tf.scalar_mul(base_lr, tf.pow((1 - step_ph / args.num_steps), args.power))\n    \n    opt_conv = tf.train.MomentumOptimizer(learning_rate, args.momentum)\n    opt_fc_w = tf.train.MomentumOptimizer(learning_rate * 10.0, args.momentum)\n    opt_fc_b = tf.train.MomentumOptimizer(learning_rate * 20.0, args.momentum)\n\n    grads = tf.gradients(reduced_loss, conv_trainable + fc_w_trainable + fc_b_trainable)\n    grads_conv = grads[:len(conv_trainable)]\n    grads_fc_w = grads[len(conv_trainable) : (len(conv_trainable) + len(fc_w_trainable))]\n    grads_fc_b = grads[(len(conv_trainable) + len(fc_w_trainable)):]\n\n    train_op_conv = opt_conv.apply_gradients(zip(grads_conv, conv_trainable))\n    train_op_fc_w = opt_fc_w.apply_gradients(zip(grads_fc_w, fc_w_trainable))\n    train_op_fc_b = opt_fc_b.apply_gradients(zip(grads_fc_b, fc_b_trainable))\n\n    train_op = tf.group(train_op_conv, train_op_fc_w, train_op_fc_b)\n    \n    \n    # Set up tf session and initialize variables. \n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    init = tf.global_variables_initializer()\n    \n    sess.run(init)\n    \n    # Saver for storing checkpoints of the model.\n    saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=10)\n    \n    # Load variables if the checkpoint is provided.\n    if args.restore_from is not None:\n        loader = tf.train.Saver(var_list=restore_var)\n        load(loader, sess, args.restore_from)\n    \n    # Start queue threads.\n    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n\n    # Iterate over training steps.\n    for step in range(args.num_steps):\n        start_time = time.time()\n        feed_dict = { step_ph : step }\n        \n        if step % args.save_pred_every == 0:\n            loss_value, images, labels, preds, summary, _ = sess.run([reduced_loss, image_batch, label_batch, pred, total_summary, train_op], feed_dict=feed_dict)\n            summary_writer.add_summary(summary, step)\n            save(saver, sess, args.snapshot_dir, step)\n        else:\n            loss_value, _ = sess.run([reduced_loss, train_op], feed_dict=feed_dict)\n        duration = time.time() - start_time\n        print(\'step {:d} \\t loss = {:.3f}, ({:.3f} sec/step)\'.format(step, loss_value, duration))\n    coord.request_stop()\n    coord.join(threads)\n    \nif __name__ == \'__main__\':\n    main()\n'"
train_msc.py,65,"b'""""""Training script with multi-scale inputs for the DeepLab-ResNet network on the PASCAL VOC dataset\n   for semantic image segmentation.\n\nThis script trains the model using augmented PASCAL VOC,\nwhich contains approximately 10000 images for training and 1500 images for validation.\n""""""\n\nfrom __future__ import print_function\n\nimport argparse\nfrom datetime import datetime\nimport os\nimport sys\nimport time\n\nimport tensorflow as tf\nimport numpy as np\n\nfrom deeplab_resnet import DeepLabResNetModel, ImageReader, decode_labels, inv_preprocess, prepare_label\n\nIMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n\nBATCH_SIZE = 1\nDATA_DIRECTORY = \'/home/VOCdevkit\'\nDATA_LIST_PATH = \'./dataset/train.txt\'\nGRAD_UPDATE_EVERY = 10\nIGNORE_LABEL = 255\nINPUT_SIZE = \'321,321\'\nLEARNING_RATE = 2.5e-4\nMOMENTUM = 0.9\nNUM_CLASSES = 21\nNUM_STEPS = 20001\nPOWER = 0.9\nRANDOM_SEED = 1234\nRESTORE_FROM = \'./deeplab_resnet.ckpt\'\nSAVE_NUM_IMAGES = 1\nSAVE_PRED_EVERY = 1000\nSNAPSHOT_DIR = \'./snapshots/\'\nWEIGHT_DECAY = 0.0005\n\n\ndef get_arguments():\n    """"""Parse all the arguments provided from the CLI.\n    \n    Returns:\n      A list of parsed arguments.\n    """"""\n    parser = argparse.ArgumentParser(description=""DeepLab-ResNet Network"")\n    parser.add_argument(""--batch-size"", type=int, default=BATCH_SIZE,\n                        help=""Number of images sent to the network in one step."")\n    parser.add_argument(""--data-dir"", type=str, default=DATA_DIRECTORY,\n                        help=""Path to the directory containing the PASCAL VOC dataset."")\n    parser.add_argument(""--data-list"", type=str, default=DATA_LIST_PATH,\n                        help=""Path to the file listing the images in the dataset."")\n    parser.add_argument(""--grad-update-every"", type=int, default=GRAD_UPDATE_EVERY,\n                        help=""Number of steps after which gradient update is applied."")\n    parser.add_argument(""--ignore-label"", type=int, default=IGNORE_LABEL,\n                        help=""The index of the label to ignore during the training."")\n    parser.add_argument(""--input-size"", type=str, default=INPUT_SIZE,\n                        help=""Comma-separated string with height and width of images."")\n    parser.add_argument(""--is-training"", action=""store_true"",\n                        help=""Whether to update the running means and variances during the training."")\n    parser.add_argument(""--learning-rate"", type=float, default=LEARNING_RATE,\n                        help=""Base learning rate for training with polynomial decay."")\n    parser.add_argument(""--momentum"", type=float, default=MOMENTUM,\n                        help=""Momentum component of the optimiser."")\n    parser.add_argument(""--not-restore-last"", action=""store_true"",\n                        help=""Whether to not restore last (FC) layers."")\n    parser.add_argument(""--num-classes"", type=int, default=NUM_CLASSES,\n                        help=""Number of classes to predict (including background)."")\n    parser.add_argument(""--num-steps"", type=int, default=NUM_STEPS,\n                        help=""Number of training steps."")\n    parser.add_argument(""--power"", type=float, default=POWER,\n                        help=""Decay parameter to compute the learning rate."")\n    parser.add_argument(""--random-mirror"", action=""store_true"",\n                        help=""Whether to randomly mirror the inputs during the training."")\n    parser.add_argument(""--random-scale"", action=""store_true"",\n                        help=""Whether to randomly scale the inputs during the training."")\n    parser.add_argument(""--random-seed"", type=int, default=RANDOM_SEED,\n                        help=""Random seed to have reproducible results."")\n    parser.add_argument(""--restore-from"", type=str, default=RESTORE_FROM,\n                        help=""Where restore model parameters from."")\n    parser.add_argument(""--save-num-images"", type=int, default=SAVE_NUM_IMAGES,\n                        help=""How many images to save."")\n    parser.add_argument(""--save-pred-every"", type=int, default=SAVE_PRED_EVERY,\n                        help=""Save summaries and checkpoint every often."")\n    parser.add_argument(""--snapshot-dir"", type=str, default=SNAPSHOT_DIR,\n                        help=""Where to save snapshots of the model."")\n    parser.add_argument(""--weight-decay"", type=float, default=WEIGHT_DECAY,\n                        help=""Regularisation parameter for L2-loss."")\n    return parser.parse_args()\n\ndef save(saver, sess, logdir, step):\n   \'\'\'Save weights.\n   \n   Args:\n     saver: TensorFlow Saver object.\n     sess: TensorFlow session.\n     logdir: path to the snapshots directory.\n     step: current training step.\n   \'\'\'\n   model_name = \'model.ckpt\'\n   checkpoint_path = os.path.join(logdir, model_name)\n    \n   if not os.path.exists(logdir):\n      os.makedirs(logdir)\n   saver.save(sess, checkpoint_path, global_step=step)\n   print(\'The checkpoint has been created.\')\n\ndef load(saver, sess, ckpt_path):\n    \'\'\'Load trained weights.\n    \n    Args:\n      saver: TensorFlow Saver object.\n      sess: TensorFlow session.\n      ckpt_path: path to checkpoint file with parameters.\n    \'\'\' \n    saver.restore(sess, ckpt_path)\n    print(""Restored model parameters from {}"".format(ckpt_path))\n\ndef main():\n    """"""Create the model and start the training.""""""\n    args = get_arguments()\n    \n    h, w = map(int, args.input_size.split(\',\'))\n    input_size = (h, w)\n    \n    tf.set_random_seed(args.random_seed)\n    \n    # Create queue coordinator.\n    coord = tf.train.Coordinator()\n    \n    # Load reader.\n    with tf.name_scope(""create_inputs""):\n        reader = ImageReader(\n            args.data_dir,\n            args.data_list,\n            input_size,\n            args.random_scale,\n            args.random_mirror,\n            args.ignore_label,\n            IMG_MEAN,\n            coord)\n        image_batch, label_batch = reader.dequeue(args.batch_size)\n        image_batch075 = tf.image.resize_images(image_batch, [int(h * 0.75), int(w * 0.75)])\n        image_batch05 = tf.image.resize_images(image_batch, [int(h * 0.5), int(w * 0.5)])\n    \n    # Create network.\n    with tf.variable_scope(\'\', reuse=False):\n        net = DeepLabResNetModel({\'data\': image_batch}, is_training=args.is_training, num_classes=args.num_classes)\n    with tf.variable_scope(\'\', reuse=True):\n        net075 = DeepLabResNetModel({\'data\': image_batch075}, is_training=args.is_training, num_classes=args.num_classes)\n    with tf.variable_scope(\'\', reuse=True):\n        net05 = DeepLabResNetModel({\'data\': image_batch05}, is_training=args.is_training, num_classes=args.num_classes)\n    # For a small batch size, it is better to keep \n    # the statistics of the BN layers (running means and variances)\n    # frozen, and to not update the values provided by the pre-trained model. \n    # If is_training=True, the statistics will be updated during the training.\n    # Note that is_training=False still updates BN parameters gamma (scale) and beta (offset)\n    # if they are presented in var_list of the optimiser definition.\n\n    # Predictions.\n    raw_output100 = net.layers[\'fc1_voc12\']\n    raw_output075 = net075.layers[\'fc1_voc12\']\n    raw_output05 = net05.layers[\'fc1_voc12\']\n    raw_output = tf.reduce_max(tf.stack([raw_output100,\n                                         tf.image.resize_images(raw_output075, tf.shape(raw_output100)[1:3,]),\n                                         tf.image.resize_images(raw_output05, tf.shape(raw_output100)[1:3,])]), axis=0)\n    # Which variables to load. Running means and variances are not trainable,\n    # thus all_variables() should be restored.\n    restore_var = [v for v in tf.global_variables() if \'fc\' not in v.name or not args.not_restore_last]\n    all_trainable = [v for v in tf.trainable_variables() if \'beta\' not in v.name and \'gamma\' not in v.name]\n    fc_trainable = [v for v in all_trainable if \'fc\' in v.name]\n    conv_trainable = [v for v in all_trainable if \'fc\' not in v.name] # lr * 1.0\n    fc_w_trainable = [v for v in fc_trainable if \'weights\' in v.name] # lr * 10.0\n    fc_b_trainable = [v for v in fc_trainable if \'biases\' in v.name] # lr * 20.0\n    assert(len(all_trainable) == len(fc_trainable) + len(conv_trainable))\n    assert(len(fc_trainable) == len(fc_w_trainable) + len(fc_b_trainable))\n    \n    \n    # Predictions: ignoring all predictions with labels greater or equal than n_classes\n    raw_prediction = tf.reshape(raw_output, [-1, args.num_classes])\n    raw_prediction100 = tf.reshape(raw_output100, [-1, args.num_classes])\n    raw_prediction075 = tf.reshape(raw_output075, [-1, args.num_classes])\n    raw_prediction05 = tf.reshape(raw_output05, [-1, args.num_classes])\n    \n    label_proc = prepare_label(label_batch, tf.stack(raw_output.get_shape()[1:3]), num_classes=args.num_classes, one_hot=False) # [batch_size, h, w]\n    label_proc075 = prepare_label(label_batch, tf.stack(raw_output075.get_shape()[1:3]), num_classes=args.num_classes, one_hot=False)\n    label_proc05 = prepare_label(label_batch, tf.stack(raw_output05.get_shape()[1:3]), num_classes=args.num_classes, one_hot=False)\n    \n    raw_gt = tf.reshape(label_proc, [-1,])\n    raw_gt075 = tf.reshape(label_proc075, [-1,])\n    raw_gt05 = tf.reshape(label_proc05, [-1,])\n    \n    indices = tf.squeeze(tf.where(tf.less_equal(raw_gt, args.num_classes - 1)), 1)\n    indices075 = tf.squeeze(tf.where(tf.less_equal(raw_gt075, args.num_classes - 1)), 1)\n    indices05 = tf.squeeze(tf.where(tf.less_equal(raw_gt05, args.num_classes - 1)), 1)\n    \n    gt = tf.cast(tf.gather(raw_gt, indices), tf.int32)\n    gt075 = tf.cast(tf.gather(raw_gt075, indices075), tf.int32)\n    gt05 = tf.cast(tf.gather(raw_gt05, indices05), tf.int32)\n    \n    prediction = tf.gather(raw_prediction, indices)\n    prediction100 = tf.gather(raw_prediction100, indices)\n    prediction075 = tf.gather(raw_prediction075, indices075)\n    prediction05 = tf.gather(raw_prediction05, indices05)\n                                                  \n                                                  \n    # Pixel-wise softmax loss.\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction, labels=gt)\n    loss100 = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction100, labels=gt)\n    loss075 = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction075, labels=gt075)\n    loss05 = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction05, labels=gt05)\n    l2_losses = [args.weight_decay * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name]\n    reduced_loss = tf.reduce_mean(loss) + tf.reduce_mean(loss100) + tf.reduce_mean(loss075) + tf.reduce_mean(loss05) + tf.add_n(l2_losses)\n    \n    # Processed predictions: for visualisation.\n    raw_output_up = tf.image.resize_bilinear(raw_output, tf.shape(image_batch)[1:3,])\n    raw_output_up = tf.argmax(raw_output_up, dimension=3)\n    pred = tf.expand_dims(raw_output_up, dim=3)\n    \n    # Image summary.\n    images_summary = tf.py_func(inv_preprocess, [image_batch, args.save_num_images, IMG_MEAN], tf.uint8)\n    labels_summary = tf.py_func(decode_labels, [label_batch, args.save_num_images, args.num_classes], tf.uint8)\n    preds_summary = tf.py_func(decode_labels, [pred, args.save_num_images, args.num_classes], tf.uint8)\n    \n    total_summary = tf.summary.image(\'images\', \n                                     tf.concat(axis=2, values=[images_summary, labels_summary, preds_summary]), \n                                     max_outputs=args.save_num_images) # Concatenate row-wise.\n    summary_writer = tf.summary.FileWriter(args.snapshot_dir,\n                                           graph=tf.get_default_graph())\n   \n    # Define loss and optimisation parameters.\n    base_lr = tf.constant(args.learning_rate)\n    step_ph = tf.placeholder(dtype=tf.float32, shape=())\n    learning_rate = tf.scalar_mul(base_lr, tf.pow((1 - step_ph / args.num_steps), args.power))\n    \n    opt_conv = tf.train.MomentumOptimizer(learning_rate, args.momentum)\n    opt_fc_w = tf.train.MomentumOptimizer(learning_rate * 10.0, args.momentum)\n    opt_fc_b = tf.train.MomentumOptimizer(learning_rate * 20.0, args.momentum)\n\n    # Define a variable to accumulate gradients.\n    accum_grads = [tf.Variable(tf.zeros_like(v.initialized_value()),\n                               trainable=False) for v in conv_trainable + fc_w_trainable + fc_b_trainable]\n\n    # Define an operation to clear the accumulated gradients for next batch.\n    zero_op = [v.assign(tf.zeros_like(v)) for v in accum_grads]\n\n    # Compute gradients.\n    grads = tf.gradients(reduced_loss, conv_trainable + fc_w_trainable + fc_b_trainable)\n   \n    # Accumulate and normalise the gradients.\n    accum_grads_op = [accum_grads[i].assign_add(grad / args.grad_update_every) for i, grad in\n                       enumerate(grads)]\n\n    grads_conv = accum_grads[:len(conv_trainable)]\n    grads_fc_w = accum_grads[len(conv_trainable) : (len(conv_trainable) + len(fc_w_trainable))]\n    grads_fc_b = accum_grads[(len(conv_trainable) + len(fc_w_trainable)):]\n\n    # Apply the gradients.\n    train_op_conv = opt_conv.apply_gradients(zip(grads_conv, conv_trainable))\n    train_op_fc_w = opt_fc_w.apply_gradients(zip(grads_fc_w, fc_w_trainable))\n    train_op_fc_b = opt_fc_b.apply_gradients(zip(grads_fc_b, fc_b_trainable))\n\n    train_op = tf.group(train_op_conv, train_op_fc_w, train_op_fc_b)\n    \n    \n    # Set up tf session and initialize variables. \n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    sess = tf.Session(config=config)\n    init = tf.global_variables_initializer()\n    \n    sess.run(init)\n    \n    # Saver for storing checkpoints of the model.\n    saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=10)\n    \n    # Load variables if the checkpoint is provided.\n    if args.restore_from is not None:\n        loader = tf.train.Saver(var_list=restore_var)\n        load(loader, sess, args.restore_from)\n    \n    # Start queue threads.\n    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n\n    # Iterate over training steps.\n    for step in range(args.num_steps):\n        start_time = time.time()\n        feed_dict = { step_ph : step }\n        loss_value = 0\n\n        # Clear the accumulated gradients.\n        sess.run(zero_op, feed_dict=feed_dict)\n       \n        # Accumulate gradients.\n        for i in range(args.grad_update_every):\n            _, l_val = sess.run([accum_grads_op, reduced_loss], feed_dict=feed_dict)\n            loss_value += l_val\n\n        # Normalise the loss.\n        loss_value /= args.grad_update_every\n\n        # Apply gradients.\n        if step % args.save_pred_every == 0:\n            images, labels, summary, _ = sess.run([image_batch, label_batch, total_summary, train_op], feed_dict=feed_dict)\n            summary_writer.add_summary(summary, step)\n            save(saver, sess, args.snapshot_dir, step)\n        else:\n            sess.run(train_op, feed_dict=feed_dict)\n\n        duration = time.time() - start_time\n        print(\'step {:d} \\t loss = {:.3f}, ({:.3f} sec/step)\'.format(step, loss_value, duration))\n    coord.request_stop()\n    coord.join(threads)\n    \nif __name__ == \'__main__\':\n    main()\n'"
deeplab_resnet/__init__.py,0,"b'from .model import DeepLabResNetModel\nfrom .image_reader import ImageReader\nfrom .utils import decode_labels, inv_preprocess, prepare_label\n'"
deeplab_resnet/image_reader.py,30,"b'import os\n\nimport numpy as np\nimport tensorflow as tf\n\ndef image_scaling(img, label):\n    """"""\n    Randomly scales the images between 0.5 to 1.5 times the original size.\n\n    Args:\n      img: Training image to scale.\n      label: Segmentation mask to scale.\n    """"""\n    \n    scale = tf.random_uniform([1], minval=0.5, maxval=1.5, dtype=tf.float32, seed=None)\n    h_new = tf.to_int32(tf.multiply(tf.to_float(tf.shape(img)[0]), scale))\n    w_new = tf.to_int32(tf.multiply(tf.to_float(tf.shape(img)[1]), scale))\n    new_shape = tf.squeeze(tf.stack([h_new, w_new]), squeeze_dims=[1])\n    img = tf.image.resize_images(img, new_shape)\n    label = tf.image.resize_nearest_neighbor(tf.expand_dims(label, 0), new_shape)\n    label = tf.squeeze(label, squeeze_dims=[0])\n   \n    return img, label\n\ndef image_mirroring(img, label):\n    """"""\n    Randomly mirrors the images.\n\n    Args:\n      img: Training image to mirror.\n      label: Segmentation mask to mirror.\n    """"""\n    \n    distort_left_right_random = tf.random_uniform([1], 0, 1.0, dtype=tf.float32)[0]\n    mirror = tf.less(tf.stack([1.0, distort_left_right_random, 1.0]), 0.5)\n    mirror = tf.boolean_mask([0, 1, 2], mirror)\n    img = tf.reverse(img, mirror)\n    label = tf.reverse(label, mirror)\n    return img, label\n\ndef random_crop_and_pad_image_and_labels(image, label, crop_h, crop_w, ignore_label=255):\n    """"""\n    Randomly crop and pads the input images.\n\n    Args:\n      image: Training image to crop/ pad.\n      label: Segmentation mask to crop/ pad.\n      crop_h: Height of cropped segment.\n      crop_w: Width of cropped segment.\n      ignore_label: Label to ignore during the training.\n    """"""\n\n    label = tf.cast(label, dtype=tf.float32)\n    label = label - ignore_label # Needs to be subtracted and later added due to 0 padding.\n    combined = tf.concat(axis=2, values=[image, label]) \n    image_shape = tf.shape(image)\n    combined_pad = tf.image.pad_to_bounding_box(combined, 0, 0, tf.maximum(crop_h, image_shape[0]), tf.maximum(crop_w, image_shape[1]))\n    \n    last_image_dim = tf.shape(image)[-1]\n    last_label_dim = tf.shape(label)[-1]\n    combined_crop = tf.random_crop(combined_pad, [crop_h,crop_w,4])\n    img_crop = combined_crop[:, :, :last_image_dim]\n    label_crop = combined_crop[:, :, last_image_dim:]\n    label_crop = label_crop + ignore_label\n    label_crop = tf.cast(label_crop, dtype=tf.uint8)\n    \n    # Set static shape so that tensorflow knows shape at compile time. \n    img_crop.set_shape((crop_h, crop_w, 3))\n    label_crop.set_shape((crop_h,crop_w, 1))\n    return img_crop, label_crop  \n\ndef read_labeled_image_list(data_dir, data_list):\n    """"""Reads txt file containing paths to images and ground truth masks.\n    \n    Args:\n      data_dir: path to the directory with images and masks.\n      data_list: path to the file with lines of the form \'/path/to/image /path/to/mask\'.\n       \n    Returns:\n      Two lists with all file names for images and masks, respectively.\n    """"""\n    f = open(data_list, \'r\')\n    images = []\n    masks = []\n    for line in f:\n        try:\n            image, mask = line.strip(""\\n"").split(\' \')\n        except ValueError: # Adhoc for test.\n            image = mask = line.strip(""\\n"")\n        images.append(data_dir + image)\n        masks.append(data_dir + mask)\n    return images, masks\n\ndef read_images_from_disk(input_queue, input_size, random_scale, random_mirror, ignore_label, img_mean): # optional pre-processing arguments\n    """"""Read one image and its corresponding mask with optional pre-processing.\n    \n    Args:\n      input_queue: tf queue with paths to the image and its mask.\n      input_size: a tuple with (height, width) values.\n                  If not given, return images of original size.\n      random_scale: whether to randomly scale the images prior\n                    to random crop.\n      random_mirror: whether to randomly mirror the images prior\n                    to random crop.\n      ignore_label: index of label to ignore during the training.\n      img_mean: vector of mean colour values.\n      \n    Returns:\n      Two tensors: the decoded image and its mask.\n    """"""\n\n    img_contents = tf.read_file(input_queue[0])\n    label_contents = tf.read_file(input_queue[1])\n    \n    img = tf.image.decode_jpeg(img_contents, channels=3)\n    img_r, img_g, img_b = tf.split(axis=2, num_or_size_splits=3, value=img)\n    img = tf.cast(tf.concat(axis=2, values=[img_b, img_g, img_r]), dtype=tf.float32)\n    # Extract mean.\n    img -= img_mean\n\n    label = tf.image.decode_png(label_contents, channels=1)\n\n    if input_size is not None:\n        h, w = input_size\n\n        # Randomly scale the images and labels.\n        if random_scale:\n            img, label = image_scaling(img, label)\n\n        # Randomly mirror the images and labels.\n        if random_mirror:\n            img, label = image_mirroring(img, label)\n\n        # Randomly crops the images and labels.\n        img, label = random_crop_and_pad_image_and_labels(img, label, h, w, ignore_label)\n\n    return img, label\n\nclass ImageReader(object):\n    \'\'\'Generic ImageReader which reads images and corresponding segmentation\n       masks from the disk, and enqueues them into a TensorFlow queue.\n    \'\'\'\n\n    def __init__(self, data_dir, data_list, input_size, \n                 random_scale, random_mirror, ignore_label, img_mean, coord):\n        \'\'\'Initialise an ImageReader.\n        \n        Args:\n          data_dir: path to the directory with images and masks.\n          data_list: path to the file with lines of the form \'/path/to/image /path/to/mask\'.\n          input_size: a tuple with (height, width) values, to which all the images will be resized.\n          random_scale: whether to randomly scale the images prior to random crop.\n          random_mirror: whether to randomly mirror the images prior to random crop.\n          ignore_label: index of label to ignore during the training.\n          img_mean: vector of mean colour values.\n          coord: TensorFlow queue coordinator.\n        \'\'\'\n        self.data_dir = data_dir\n        self.data_list = data_list\n        self.input_size = input_size\n        self.coord = coord\n        \n        self.image_list, self.label_list = read_labeled_image_list(self.data_dir, self.data_list)\n        self.images = tf.convert_to_tensor(self.image_list, dtype=tf.string)\n        self.labels = tf.convert_to_tensor(self.label_list, dtype=tf.string)\n        self.queue = tf.train.slice_input_producer([self.images, self.labels],\n                                                   shuffle=input_size is not None) # not shuffling if it is val\n        self.image, self.label = read_images_from_disk(self.queue, self.input_size, random_scale, random_mirror, ignore_label, img_mean) \n\n    def dequeue(self, num_elements):\n        \'\'\'Pack images and labels into a batch.\n        \n        Args:\n          num_elements: the batch size.\n          \n        Returns:\n          Two tensors of size (batch_size, h, w, {3, 1}) for images and masks.\'\'\'\n        image_batch, label_batch = tf.train.batch([self.image, self.label],\n                                                  num_elements)\n        return image_batch, label_batch\n'"
deeplab_resnet/model.py,67,"b""# Converted to TensorFlow .caffemodel\n# with the DeepLab-ResNet configuration.\n# The batch normalisation layer is provided by\n# the slim library (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim).\n\nfrom kaffe.tensorflow import Network\nimport tensorflow as tf\n\nclass DeepLabResNetModel(Network):\n    def setup(self, is_training, num_classes):\n        '''Network definition.\n        \n        Args:\n          is_training: whether to update the running mean and variance of the batch normalisation layer.\n                       If the batch size is small, it is better to keep the running mean and variance of \n                       the-pretrained model frozen.\n          num_classes: number of classes to predict (including background).\n        '''\n        (self.feed('data')\n             .conv(7, 7, 64, 2, 2, biased=False, relu=False, name='conv1')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn_conv1')\n             .max_pool(3, 3, 2, 2, name='pool1')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch1'))\n\n        (self.feed('pool1')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch2c'))\n\n        (self.feed('bn2a_branch1', \n                   'bn2a_branch2c')\n             .add(name='res2a')\n             .relu(name='res2a_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2b_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2b_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2b_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2b_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2b_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2b_branch2c'))\n\n        (self.feed('res2a_relu', \n                   'bn2b_branch2c')\n             .add(name='res2b')\n             .relu(name='res2b_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2c_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2c_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2c_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2c_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2c_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2c_branch2c'))\n\n        (self.feed('res2b_relu', \n                   'bn2c_branch2c')\n             .add(name='res2c')\n             .relu(name='res2c_relu')\n             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res3a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3a_branch1'))\n\n        (self.feed('res2c_relu')\n             .conv(1, 1, 128, 2, 2, biased=False, relu=False, name='res3a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3a_branch2c'))\n\n        (self.feed('bn3a_branch1', \n                   'bn3a_branch2c')\n             .add(name='res3a')\n             .relu(name='res3a_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b1_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b1_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b1_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b1_branch2c'))\n\n        (self.feed('res3a_relu', \n                   'bn3b1_branch2c')\n             .add(name='res3b1')\n             .relu(name='res3b1_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b2_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b2_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b2_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b2_branch2c'))\n\n        (self.feed('res3b1_relu', \n                   'bn3b2_branch2c')\n             .add(name='res3b2')\n             .relu(name='res3b2_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b3_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b3_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b3_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b3_branch2c'))\n\n        (self.feed('res3b2_relu', \n                   'bn3b3_branch2c')\n             .add(name='res3b3')\n             .relu(name='res3b3_relu')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4a_branch1'))\n\n        (self.feed('res3b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4a_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4a_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4a_branch2c'))\n\n        (self.feed('bn4a_branch1', \n                   'bn4a_branch2c')\n             .add(name='res4a')\n             .relu(name='res4a_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b1_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b1_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b1_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b1_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b1_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b1_branch2c'))\n\n        (self.feed('res4a_relu', \n                   'bn4b1_branch2c')\n             .add(name='res4b1')\n             .relu(name='res4b1_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b2_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b2_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b2_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b2_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b2_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b2_branch2c'))\n\n        (self.feed('res4b1_relu', \n                   'bn4b2_branch2c')\n             .add(name='res4b2')\n             .relu(name='res4b2_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b3_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b3_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b3_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b3_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b3_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b3_branch2c'))\n\n        (self.feed('res4b2_relu', \n                   'bn4b3_branch2c')\n             .add(name='res4b3')\n             .relu(name='res4b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b4_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b4_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b4_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b4_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b4_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b4_branch2c'))\n\n        (self.feed('res4b3_relu', \n                   'bn4b4_branch2c')\n             .add(name='res4b4')\n             .relu(name='res4b4_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b5_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b5_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b5_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b5_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b5_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b5_branch2c'))\n\n        (self.feed('res4b4_relu', \n                   'bn4b5_branch2c')\n             .add(name='res4b5')\n             .relu(name='res4b5_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b6_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b6_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b6_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b6_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b6_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b6_branch2c'))\n\n        (self.feed('res4b5_relu', \n                   'bn4b6_branch2c')\n             .add(name='res4b6')\n             .relu(name='res4b6_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b7_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b7_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b7_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b7_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b7_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b7_branch2c'))\n\n        (self.feed('res4b6_relu', \n                   'bn4b7_branch2c')\n             .add(name='res4b7')\n             .relu(name='res4b7_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b8_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b8_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b8_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b8_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b8_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b8_branch2c'))\n\n        (self.feed('res4b7_relu', \n                   'bn4b8_branch2c')\n             .add(name='res4b8')\n             .relu(name='res4b8_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b9_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b9_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b9_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b9_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b9_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b9_branch2c'))\n\n        (self.feed('res4b8_relu', \n                   'bn4b9_branch2c')\n             .add(name='res4b9')\n             .relu(name='res4b9_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b10_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b10_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b10_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b10_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b10_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b10_branch2c'))\n\n        (self.feed('res4b9_relu', \n                   'bn4b10_branch2c')\n             .add(name='res4b10')\n             .relu(name='res4b10_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b11_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b11_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b11_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b11_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b11_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b11_branch2c'))\n\n        (self.feed('res4b10_relu', \n                   'bn4b11_branch2c')\n             .add(name='res4b11')\n             .relu(name='res4b11_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b12_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b12_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b12_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b12_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b12_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b12_branch2c'))\n\n        (self.feed('res4b11_relu', \n                   'bn4b12_branch2c')\n             .add(name='res4b12')\n             .relu(name='res4b12_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b13_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b13_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b13_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b13_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b13_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b13_branch2c'))\n\n        (self.feed('res4b12_relu', \n                   'bn4b13_branch2c')\n             .add(name='res4b13')\n             .relu(name='res4b13_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b14_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b14_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b14_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b14_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b14_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b14_branch2c'))\n\n        (self.feed('res4b13_relu', \n                   'bn4b14_branch2c')\n             .add(name='res4b14')\n             .relu(name='res4b14_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b15_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b15_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b15_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b15_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b15_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b15_branch2c'))\n\n        (self.feed('res4b14_relu', \n                   'bn4b15_branch2c')\n             .add(name='res4b15')\n             .relu(name='res4b15_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b16_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b16_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b16_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b16_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b16_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b16_branch2c'))\n\n        (self.feed('res4b15_relu', \n                   'bn4b16_branch2c')\n             .add(name='res4b16')\n             .relu(name='res4b16_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b17_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b17_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b17_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b17_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b17_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b17_branch2c'))\n\n        (self.feed('res4b16_relu', \n                   'bn4b17_branch2c')\n             .add(name='res4b17')\n             .relu(name='res4b17_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b18_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b18_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b18_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b18_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b18_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b18_branch2c'))\n\n        (self.feed('res4b17_relu', \n                   'bn4b18_branch2c')\n             .add(name='res4b18')\n             .relu(name='res4b18_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b19_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b19_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b19_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b19_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b19_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b19_branch2c'))\n\n        (self.feed('res4b18_relu', \n                   'bn4b19_branch2c')\n             .add(name='res4b19')\n             .relu(name='res4b19_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b20_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b20_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b20_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b20_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b20_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b20_branch2c'))\n\n        (self.feed('res4b19_relu', \n                   'bn4b20_branch2c')\n             .add(name='res4b20')\n             .relu(name='res4b20_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b21_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b21_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b21_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b21_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b21_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b21_branch2c'))\n\n        (self.feed('res4b20_relu', \n                   'bn4b21_branch2c')\n             .add(name='res4b21')\n             .relu(name='res4b21_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b22_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b22_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b22_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b22_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b22_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b22_branch2c'))\n\n        (self.feed('res4b21_relu', \n                   'bn4b22_branch2c')\n             .add(name='res4b22')\n             .relu(name='res4b22_relu')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5a_branch1'))\n\n        (self.feed('res4b22_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5a_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5a_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5a_branch2c'))\n\n        (self.feed('bn5a_branch1', \n                   'bn5a_branch2c')\n             .add(name='res5a')\n             .relu(name='res5a_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5b_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5b_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5b_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5b_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5b_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5b_branch2c'))\n\n        (self.feed('res5a_relu', \n                   'bn5b_branch2c')\n             .add(name='res5b')\n             .relu(name='res5b_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5c_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5c_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5c_branch2b')\n             .batch_normalization(activation_fn=tf.nn.relu, name='bn5c_branch2b', is_training=is_training)\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5c_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5c_branch2c'))\n\n        (self.feed('res5b_relu', \n                   'bn5c_branch2c')\n             .add(name='res5c')\n             .relu(name='res5c_relu')\n             .atrous_conv(3, 3, num_classes, 6, padding='SAME', relu=False, name='fc1_voc12_c0'))\n\n        (self.feed('res5c_relu')\n             .atrous_conv(3, 3, num_classes, 12, padding='SAME', relu=False, name='fc1_voc12_c1'))\n\n        (self.feed('res5c_relu')\n             .atrous_conv(3, 3, num_classes, 18, padding='SAME', relu=False, name='fc1_voc12_c2'))\n\n        (self.feed('res5c_relu')\n             .atrous_conv(3, 3, num_classes, 24, padding='SAME', relu=False, name='fc1_voc12_c3'))\n\n        (self.feed('fc1_voc12_c0', \n                   'fc1_voc12_c1', \n                   'fc1_voc12_c2', \n                   'fc1_voc12_c3')\n             .add(name='fc1_voc12'))\n"""
deeplab_resnet/utils.py,4,"b'from PIL import Image\nimport numpy as np\nimport tensorflow as tf\n\n# colour map\nlabel_colours = [(0,0,0)\n                # 0=background\n                ,(128,0,0),(0,128,0),(128,128,0),(0,0,128),(128,0,128)\n                # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n                ,(0,128,128),(128,128,128),(64,0,0),(192,0,0),(64,128,0)\n                # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n                ,(192,128,0),(64,0,128),(192,0,128),(64,128,128),(192,128,128)\n                # 11=diningtable, 12=dog, 13=horse, 14=motorbike, 15=person\n                ,(0,64,0),(128,64,0),(0,192,0),(128,192,0),(0,64,128)]\n                # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n\ndef decode_labels(mask, num_images=1, num_classes=21):\n    """"""Decode batch of segmentation masks.\n    \n    Args:\n      mask: result of inference after taking argmax.\n      num_images: number of images to decode from the batch.\n      num_classes: number of classes to predict (including background).\n    \n    Returns:\n      A batch with num_images RGB images of the same size as the input. \n    """"""\n    n, h, w, c = mask.shape\n    assert(n >= num_images), \'Batch size %d should be greater or equal than number of images to save %d.\' % (n, num_images)\n    outputs = np.zeros((num_images, h, w, 3), dtype=np.uint8)\n    for i in range(num_images):\n      img = Image.new(\'RGB\', (len(mask[i, 0]), len(mask[i])))\n      pixels = img.load()\n      for j_, j in enumerate(mask[i, :, :, 0]):\n          for k_, k in enumerate(j):\n              if k < num_classes:\n                  pixels[k_,j_] = label_colours[k]\n      outputs[i] = np.array(img)\n    return outputs\n\ndef prepare_label(input_batch, new_size, num_classes, one_hot=True):\n    """"""Resize masks and perform one-hot encoding.\n\n    Args:\n      input_batch: input tensor of shape [batch_size H W 1].\n      new_size: a tensor with new height and width.\n      num_classes: number of classes to predict (including background).\n      one_hot: whether perform one-hot encoding.\n\n    Returns:\n      Outputs a tensor of shape [batch_size h w 21]\n      with last dimension comprised of 0\'s and 1\'s only.\n    """"""\n    with tf.name_scope(\'label_encode\'):\n        input_batch = tf.image.resize_nearest_neighbor(input_batch, new_size) # as labels are integer numbers, need to use NN interp.\n        input_batch = tf.squeeze(input_batch, squeeze_dims=[3]) # reducing the channel dimension.\n        if one_hot:\n            input_batch = tf.one_hot(input_batch, depth=num_classes)\n    return input_batch\n\ndef inv_preprocess(imgs, num_images, img_mean):\n    """"""Inverse preprocessing of the batch of images.\n       Add the mean vector and convert from BGR to RGB.\n       \n    Args:\n      imgs: batch of input images.\n      num_images: number of images to apply the inverse transformations on.\n      img_mean: vector of mean colour values.\n  \n    Returns:\n      The batch of the size num_images with the same spatial dimensions as the input.\n    """"""\n    n, h, w, c = imgs.shape\n    assert(n >= num_images), \'Batch size %d should be greater or equal than number of images to save %d.\' % (n, num_images)\n    outputs = np.zeros((num_images, h, w, c), dtype=np.uint8)\n    for i in range(num_images):\n        outputs[i] = (imgs[i] + img_mean)[:, :, ::-1].astype(np.uint8)\n    return outputs\n'"
kaffe/__init__.py,0,"b'from .graph import GraphBuilder, NodeMapper\nfrom .errors import KaffeError, print_stderr\n\nfrom . import tensorflow\n'"
kaffe/errors.py,0,"b""import sys\n\nclass KaffeError(Exception):\n    pass\n\ndef print_stderr(msg):\n    sys.stderr.write('%s\\n' % msg)\n"""
kaffe/graph.py,0,"b'from google.protobuf import text_format\n\nfrom .caffe import get_caffe_resolver\nfrom .errors import KaffeError, print_stderr\nfrom .layers import LayerAdapter, LayerType, NodeKind, NodeDispatch\nfrom .shapes import TensorShape\n\nclass Node(object):\n\n    def __init__(self, name, kind, layer=None):\n        self.name = name\n        self.kind = kind\n        self.layer = LayerAdapter(layer, kind) if layer else None\n        self.parents = []\n        self.children = []\n        self.data = None\n        self.output_shape = None\n        self.metadata = {}\n\n    def add_parent(self, parent_node):\n        assert parent_node not in self.parents\n        self.parents.append(parent_node)\n        if self not in parent_node.children:\n            parent_node.children.append(self)\n\n    def add_child(self, child_node):\n        assert child_node not in self.children\n        self.children.append(child_node)\n        if self not in child_node.parents:\n            child_node.parents.append(self)\n\n    def get_only_parent(self):\n        if len(self.parents) != 1:\n            raise KaffeError(\'Node (%s) expected to have 1 parent. Found %s.\' %\n                             (self, len(self.parents)))\n        return self.parents[0]\n\n    @property\n    def parameters(self):\n        if self.layer is not None:\n            return self.layer.parameters\n        return None\n\n    def __str__(self):\n        return \'[%s] %s\' % (self.kind, self.name)\n\n    def __repr__(self):\n        return \'%s (0x%x)\' % (self.name, id(self))\n\n\nclass Graph(object):\n\n    def __init__(self, nodes=None, name=None):\n        self.nodes = nodes or []\n        self.node_lut = {node.name: node for node in self.nodes}\n        self.name = name\n\n    def add_node(self, node):\n        self.nodes.append(node)\n        self.node_lut[node.name] = node\n\n    def get_node(self, name):\n        try:\n            return self.node_lut[name]\n        except KeyError:\n            raise KaffeError(\'Layer not found: %s\' % name)\n\n    def get_input_nodes(self):\n        return [node for node in self.nodes if len(node.parents) == 0]\n\n    def get_output_nodes(self):\n        return [node for node in self.nodes if len(node.children) == 0]\n\n    def topologically_sorted(self):\n        sorted_nodes = []\n        unsorted_nodes = list(self.nodes)\n        temp_marked = set()\n        perm_marked = set()\n\n        def visit(node):\n            if node in temp_marked:\n                raise KaffeError(\'Graph is not a DAG.\')\n            if node in perm_marked:\n                return\n            temp_marked.add(node)\n            for child in node.children:\n                visit(child)\n            perm_marked.add(node)\n            temp_marked.remove(node)\n            sorted_nodes.insert(0, node)\n\n        while len(unsorted_nodes):\n            visit(unsorted_nodes.pop())\n        return sorted_nodes\n\n    def compute_output_shapes(self):\n        sorted_nodes = self.topologically_sorted()\n        for node in sorted_nodes:\n            node.output_shape = TensorShape(*NodeKind.compute_output_shape(node))\n\n    def replaced(self, new_nodes):\n        return Graph(nodes=new_nodes, name=self.name)\n\n    def transformed(self, transformers):\n        graph = self\n        for transformer in transformers:\n            graph = transformer(graph)\n            if graph is None:\n                raise KaffeError(\'Transformer failed: {}\'.format(transformer))\n            assert isinstance(graph, Graph)\n        return graph\n\n    def __contains__(self, key):\n        return key in self.node_lut\n\n    def __str__(self):\n        hdr = \'{:<20} {:<30} {:>20} {:>20}\'.format(\'Type\', \'Name\', \'Param\', \'Output\')\n        s = [hdr, \'-\' * 94]\n        for node in self.topologically_sorted():\n            # If the node has learned parameters, display the first one\'s shape.\n            # In case of convolutions, this corresponds to the weights.\n            data_shape = node.data[0].shape if node.data else \'--\'\n            out_shape = node.output_shape or \'--\'\n            s.append(\'{:<20} {:<30} {:>20} {:>20}\'.format(node.kind, node.name, data_shape,\n                                                          tuple(out_shape)))\n        return \'\\n\'.join(s)\n\n\nclass GraphBuilder(object):\n    \'\'\'Constructs a model graph from a Caffe protocol buffer definition.\'\'\'\n\n    def __init__(self, def_path, phase=\'test\'):\n        \'\'\'\n        def_path: Path to the model definition (.prototxt)\n        data_path: Path to the model data (.caffemodel)\n        phase: Either \'test\' or \'train\'. Used for filtering phase-specific nodes.\n        \'\'\'\n        self.def_path = def_path\n        self.phase = phase\n        self.load()\n\n    def load(self):\n        \'\'\'Load the layer definitions from the prototxt.\'\'\'\n        self.params = get_caffe_resolver().NetParameter()\n        with open(self.def_path, \'rb\') as def_file:\n            text_format.Merge(def_file.read(), self.params)\n\n    def filter_layers(self, layers):\n        \'\'\'Filter out layers based on the current phase.\'\'\'\n        phase_map = {0: \'train\', 1: \'test\'}\n        filtered_layer_names = set()\n        filtered_layers = []\n        for layer in layers:\n            phase = self.phase\n            if len(layer.include):\n                phase = phase_map[layer.include[0].phase]\n            if len(layer.exclude):\n                phase = phase_map[1 - layer.include[0].phase]\n            exclude = (phase != self.phase)\n            # Dropout layers appear in a fair number of Caffe\n            # test-time networks. These are just ignored. We\'ll\n            # filter them out here.\n            if (not exclude) and (phase == \'test\'):\n                exclude = (layer.type == LayerType.Dropout)\n            if not exclude:\n                filtered_layers.append(layer)\n                # Guard against dupes.\n                assert layer.name not in filtered_layer_names\n                filtered_layer_names.add(layer.name)\n        return filtered_layers\n\n    def make_node(self, layer):\n        \'\'\'Create a graph node for the given layer.\'\'\'\n        kind = NodeKind.map_raw_kind(layer.type)\n        if kind is None:\n            raise KaffeError(\'Unknown layer type encountered: %s\' % layer.type)\n        # We want to use the layer\'s top names (the ""output"" names), rather than the\n        # name attribute, which is more of readability thing than a functional one.\n        # Other layers will refer to a node by its ""top name"".\n        return Node(layer.name, kind, layer=layer)\n\n    def make_input_nodes(self):\n        \'\'\'\n        Create data input nodes.\n\n        This method is for old-style inputs, where the input specification\n        was not treated as a first-class layer in the prototext.\n        Newer models use the ""Input layer"" type.\n        \'\'\'\n        nodes = [Node(name, NodeKind.Data) for name in self.params.input]\n        if len(nodes):\n            input_dim = map(int, self.params.input_dim)\n            if not input_dim:\n                if len(self.params.input_shape) > 0:\n                    input_dim = map(int, self.params.input_shape[0].dim)\n                else:\n                    raise KaffeError(\'Dimensions for input not specified.\')\n            for node in nodes:\n                node.output_shape = tuple(input_dim)\n        return nodes\n\n    def build(self):\n        \'\'\'\n        Builds the graph from the Caffe layer definitions.\n        \'\'\'\n        # Get the layers\n        layers = self.params.layers or self.params.layer\n        # Filter out phase-excluded layers\n        layers = self.filter_layers(layers)\n        # Get any separately-specified input layers\n        nodes = self.make_input_nodes()\n        nodes += [self.make_node(layer) for layer in layers]\n        # Initialize the graph\n        graph = Graph(nodes=nodes, name=self.params.name)\n        # Connect the nodes\n        #\n        # A note on layers and outputs:\n        # In Caffe, each layer can produce multiple outputs (""tops"") from a set of inputs\n        # (""bottoms""). The bottoms refer to other layers\' tops. The top can rewrite a bottom\n        # (in case of in-place operations). Note that the layer\'s name is not used for establishing\n        # any connectivity. It\'s only used for data association. By convention, a layer with a\n        # single top will often use the same name (although this is not required).\n        #\n        # The current implementation only supports single-output nodes (note that a node can still\n        # have multiple children, since multiple child nodes can refer to the single top\'s name).\n        node_outputs = {}\n        for layer in layers:\n            node = graph.get_node(layer.name)\n            for input_name in layer.bottom:\n                assert input_name != layer.name\n                parent_node = node_outputs.get(input_name)\n                if (parent_node is None) or (parent_node == node):\n                    parent_node = graph.get_node(input_name)\n                node.add_parent(parent_node)\n            if len(layer.top)>1:\n                raise KaffeError(\'Multiple top nodes are not supported.\')\n            for output_name in layer.top:\n                if output_name == layer.name:\n                    # Output is named the same as the node. No further action required.\n                    continue\n                # There are two possibilities here:\n                #\n                # Case 1: output_name refers to another node in the graph.\n                # This is an ""in-place operation"" that overwrites an existing node.\n                # This would create a cycle in the graph. We\'ll undo the in-placing\n                # by substituting this node wherever the overwritten node is referenced.\n                #\n                # Case 2: output_name violates the convention layer.name == output_name.\n                # Since we are working in the single-output regime, we will can rename it to\n                # match the layer name.\n                #\n                # For both cases, future references to this top re-routes to this node.\n                node_outputs[output_name] = node\n\n        graph.compute_output_shapes()\n        return graph\n\n\nclass NodeMapper(NodeDispatch):\n\n    def __init__(self, graph):\n        self.graph = graph\n\n    def map(self):\n        nodes = self.graph.topologically_sorted()\n        # Remove input nodes - we\'ll handle them separately.\n        input_nodes = self.graph.get_input_nodes()\n        nodes = [t for t in nodes if t not in input_nodes]\n        # Decompose DAG into chains.\n        chains = []\n        for node in nodes:\n            attach_to_chain = None\n            if len(node.parents) == 1:\n                parent = node.get_only_parent()\n                for chain in chains:\n                    if chain[-1] == parent:\n                        # Node is part of an existing chain.\n                        attach_to_chain = chain\n                        break\n            if attach_to_chain is None:\n                # Start a new chain for this node.\n                attach_to_chain = []\n                chains.append(attach_to_chain)\n            attach_to_chain.append(node)\n        # Map each chain.\n        mapped_chains = []\n        for chain in chains:\n            mapped_chains.append(self.map_chain(chain))\n        return self.commit(mapped_chains)\n\n    def map_chain(self, chain):\n        return [self.map_node(node) for node in chain]\n\n    def map_node(self, node):\n        map_func = self.get_handler(node.kind, \'map\')\n        mapped_node = map_func(node)\n        assert mapped_node is not None\n        mapped_node.node = node\n        return mapped_node\n\n    def commit(self, mapped_chains):\n        raise NotImplementedError(\'Must be implemented by subclass.\')\n'"
kaffe/layers.py,0,"b""import re\nimport numbers\nfrom collections import namedtuple\n\nfrom .shapes import *\n\nLAYER_DESCRIPTORS = {\n\n    # Caffe Types\n    'AbsVal': shape_identity,\n    'Accuracy': shape_scalar,\n    'ArgMax': shape_not_implemented,\n    'BatchNorm': shape_identity,\n    'BNLL': shape_not_implemented,\n    'Concat': shape_concat,\n    'ContrastiveLoss': shape_scalar,\n    'Convolution': shape_convolution,\n    'Deconvolution': shape_not_implemented,\n    'Data': shape_data,\n    'Dropout': shape_identity,\n    'DummyData': shape_data,\n    'EuclideanLoss': shape_scalar,\n    'Eltwise': shape_identity,\n    'Exp': shape_identity,\n    'Flatten': shape_not_implemented,\n    'HDF5Data': shape_data,\n    'HDF5Output': shape_identity,\n    'HingeLoss': shape_scalar,\n    'Im2col': shape_not_implemented,\n    'ImageData': shape_data,\n    'InfogainLoss': shape_scalar,\n    'InnerProduct': shape_inner_product,\n    'Input': shape_data,\n    'LRN': shape_identity,\n    'MemoryData': shape_mem_data,\n    'MultinomialLogisticLoss': shape_scalar,\n    'MVN': shape_not_implemented,\n    'Pooling': shape_pool,\n    'Power': shape_identity,\n    'ReLU': shape_identity,\n    'Scale': shape_identity,\n    'Sigmoid': shape_identity,\n    'SigmoidCrossEntropyLoss': shape_scalar,\n    'Silence': shape_not_implemented,\n    'Softmax': shape_identity,\n    'SoftmaxWithLoss': shape_scalar,\n    'Split': shape_not_implemented,\n    'Slice': shape_not_implemented,\n    'TanH': shape_identity,\n    'WindowData': shape_not_implemented,\n    'Threshold': shape_identity,\n}\n\nLAYER_TYPES = LAYER_DESCRIPTORS.keys()\n\nLayerType = type('LayerType', (), {t: t for t in LAYER_TYPES})\n\nclass NodeKind(LayerType):\n\n    @staticmethod\n    def map_raw_kind(kind):\n        if kind in LAYER_TYPES:\n            return kind\n        return None\n\n    @staticmethod\n    def compute_output_shape(node):\n        try:\n            val = LAYER_DESCRIPTORS[node.kind](node)\n            return val\n        except NotImplementedError:\n            raise KaffeError('Output shape computation not implemented for type: %s' % node.kind)\n\n\nclass NodeDispatchError(KaffeError):\n\n    pass\n\n\nclass NodeDispatch(object):\n\n    @staticmethod\n    def get_handler_name(node_kind):\n        if len(node_kind) <= 4:\n            # A catch-all for things like ReLU and tanh\n            return node_kind.lower()\n        # Convert from CamelCase to under_scored\n        name = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', node_kind)\n        return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', name).lower()\n\n    def get_handler(self, node_kind, prefix):\n        name = self.get_handler_name(node_kind)\n        name = '_'.join((prefix, name))\n        try:\n            return getattr(self, name)\n        except AttributeError:\n            raise NodeDispatchError('No handler found for node kind: %s (expected: %s)' %\n                                    (node_kind, name))\n\n\nclass LayerAdapter(object):\n\n    def __init__(self, layer, kind):\n        self.layer = layer\n        self.kind = kind\n\n    @property\n    def parameters(self):\n        name = NodeDispatch.get_handler_name(self.kind)\n        name = '_'.join((name, 'param'))\n        try:\n            return getattr(self.layer, name)\n        except AttributeError:\n            raise NodeDispatchError('Caffe parameters not found for layer kind: %s' % (self.kind))\n\n    @staticmethod\n    def get_kernel_value(scalar, repeated, idx, default=None):\n        if scalar:\n            return scalar\n        if repeated:\n            if isinstance(repeated, numbers.Number):\n                return repeated\n            if len(repeated) == 1:\n                # Same value applies to all spatial dimensions\n                return int(repeated[0])\n            assert idx < len(repeated)\n            # Extract the value for the given spatial dimension\n            return repeated[idx]\n        if default is None:\n            raise ValueError('Unable to determine kernel parameter!')\n        return default\n\n    @property\n    def kernel_parameters(self):\n        assert self.kind in (NodeKind.Convolution, NodeKind.Pooling)\n        params = self.parameters\n        k_h = self.get_kernel_value(params.kernel_h, params.kernel_size, 0)\n        k_w = self.get_kernel_value(params.kernel_w, params.kernel_size, 1)\n        s_h = self.get_kernel_value(params.stride_h, params.stride, 0, default=1)\n        s_w = self.get_kernel_value(params.stride_w, params.stride, 1, default=1)\n        p_h = self.get_kernel_value(params.pad_h, params.pad, 0, default=0)\n        p_w = self.get_kernel_value(params.pad_h, params.pad, 1, default=0)\n        return KernelParameters(k_h, k_w, s_h, s_w, p_h, p_w)\n\n\nKernelParameters = namedtuple('KernelParameters', ['kernel_h', 'kernel_w', 'stride_h', 'stride_w',\n                                                   'pad_h', 'pad_w'])\n"""
kaffe/shapes.py,0,"b'import math\nfrom collections import namedtuple\n\nfrom .errors import KaffeError\n\nTensorShape = namedtuple(\'TensorShape\', [\'batch_size\', \'channels\', \'height\', \'width\'])\n\n\ndef get_filter_output_shape(i_h, i_w, params, round_func):\n    o_h = (i_h + 2 * params.pad_h - params.kernel_h) / float(params.stride_h) + 1\n    o_w = (i_w + 2 * params.pad_w - params.kernel_w) / float(params.stride_w) + 1\n    return (int(round_func(o_h)), int(round_func(o_w)))\n\n\ndef get_strided_kernel_output_shape(node, round_func):\n    assert node.layer is not None\n    input_shape = node.get_only_parent().output_shape\n    o_h, o_w = get_filter_output_shape(input_shape.height, input_shape.width,\n                                       node.layer.kernel_parameters, round_func)\n    params = node.layer.parameters\n    has_c_o = hasattr(params, \'num_output\')\n    c = params.num_output if has_c_o else input_shape.channels\n    return TensorShape(input_shape.batch_size, c, o_h, o_w)\n\n\ndef shape_not_implemented(node):\n    raise NotImplementedError\n\n\ndef shape_identity(node):\n    assert len(node.parents) > 0\n    return node.parents[0].output_shape\n\n\ndef shape_scalar(node):\n    return TensorShape(1, 1, 1, 1)\n\n\ndef shape_data(node):\n    if node.output_shape:\n        # Old-style input specification\n        return node.output_shape\n    try:\n        # New-style input specification\n        return map(int, node.parameters.shape[0].dim)\n    except:\n        # We most likely have a data layer on our hands. The problem is,\n        # Caffe infers the dimensions of the data from the source (eg: LMDB).\n        # We want to avoid reading datasets here. Fail for now.\n        # This can be temporarily fixed by transforming the data layer to\n        # Caffe\'s ""input"" layer (as is usually used in the ""deploy"" version).\n        # TODO: Find a better solution for this.\n        raise KaffeError(\'Cannot determine dimensions of data layer.\\n\'\n                         \'See comments in function shape_data for more info.\')\n\n\ndef shape_mem_data(node):\n    params = node.parameters\n    return TensorShape(params.batch_size, params.channels, params.height, params.width)\n\n\ndef shape_concat(node):\n    axis = node.layer.parameters.axis\n    output_shape = None\n    for parent in node.parents:\n        if output_shape is None:\n            output_shape = list(parent.output_shape)\n        else:\n            output_shape[axis] += parent.output_shape[axis]\n    return tuple(output_shape)\n\n\ndef shape_convolution(node):\n    return get_strided_kernel_output_shape(node, math.floor)\n\n\ndef shape_pool(node):\n    return get_strided_kernel_output_shape(node, math.ceil)\n\n\ndef shape_inner_product(node):\n    input_shape = node.get_only_parent().output_shape\n    return TensorShape(input_shape.batch_size, node.layer.parameters.num_output, 1, 1)\n'"
kaffe/transformers.py,0,"b""'''\nA collection of graph transforms.\n\nA transformer is a callable that accepts a graph and returns a transformed version.\n'''\n\nimport numpy as np\n\nfrom .caffe import get_caffe_resolver, has_pycaffe\nfrom .errors import KaffeError, print_stderr\nfrom .layers import NodeKind\n\n\nclass DataInjector(object):\n    '''\n    Associates parameters loaded from a .caffemodel file with their corresponding nodes.\n    '''\n\n    def __init__(self, def_path, data_path):\n        # The .prototxt file defining the graph\n        self.def_path = def_path\n        # The .caffemodel file containing the learned parameters\n        self.data_path = data_path\n        # Set to true if the fallback protocol-buffer based backend was used\n        self.did_use_pb = False\n        # A list containing (layer name, parameters) tuples\n        self.params = None\n        # Load the parameters\n        self.load()\n\n    def load(self):\n        if has_pycaffe():\n            self.load_using_caffe()\n        else:\n            self.load_using_pb()\n\n    def load_using_caffe(self):\n        caffe = get_caffe_resolver().caffe\n        net = caffe.Net(self.def_path, self.data_path, caffe.TEST)\n        data = lambda blob: blob.data\n        self.params = [(k, map(data, v)) for k, v in net.params.items()]\n\n    def load_using_pb(self):\n        data = get_caffe_resolver().NetParameter()\n        data.MergeFromString(open(self.data_path, 'rb').read())\n        pair = lambda layer: (layer.name, self.normalize_pb_data(layer))\n        layers = data.layers or data.layer\n        self.params = [pair(layer) for layer in layers if layer.blobs]\n        self.did_use_pb = True\n\n    def normalize_pb_data(self, layer):\n        transformed = []\n        for blob in layer.blobs:\n            if len(blob.shape.dim):\n                dims = blob.shape.dim\n                c_o, c_i, h, w = map(int, [1] * (4 - len(dims)) + list(dims))\n            else:\n                c_o = blob.num\n                c_i = blob.channels\n                h = blob.height\n                w = blob.width\n            data = np.array(blob.data, dtype=np.float32).reshape(c_o, c_i, h, w)\n            transformed.append(data)\n        return transformed\n\n    def adjust_parameters(self, node, data):\n        if not self.did_use_pb:\n            return data\n        # When using the protobuf-backend, each parameter initially has four dimensions.\n        # In certain cases (like FC layers), we want to eliminate the singleton dimensions.\n        # This implementation takes care of the common cases. However, it does leave the\n        # potential for future issues.\n        # The Caffe-backend does not suffer from this problem.\n        data = list(data)\n        squeeze_indices = [1]  # Squeeze biases.\n        if node.kind == NodeKind.InnerProduct:\n            squeeze_indices.append(0)  # Squeeze FC.\n        for idx in squeeze_indices:\n            data[idx] = np.squeeze(data[idx])\n        return data\n\n    def __call__(self, graph):\n        for layer_name, data in self.params:\n            if layer_name in graph:\n                node = graph.get_node(layer_name)\n                node.data = self.adjust_parameters(node, data)\n            else:\n                print_stderr('Ignoring parameters for non-existent layer: %s' % layer_name)\n        return graph\n\n\nclass DataReshaper(object):\n\n    def __init__(self, mapping, replace=True):\n        # A dictionary mapping NodeKind to the transposed order.\n        self.mapping = mapping\n        # The node kinds eligible for reshaping\n        self.reshaped_node_types = self.mapping.keys()\n        # If true, the reshaped data will replace the old one.\n        # Otherwise, it's set to the reshaped_data attribute.\n        self.replace = replace\n\n    def has_spatial_parent(self, node):\n        try:\n            parent = node.get_only_parent()\n            s = parent.output_shape\n            return s.height > 1 or s.width > 1\n        except KaffeError:\n            return False\n\n    def map(self, node_kind):\n        try:\n            return self.mapping[node_kind]\n        except KeyError:\n            raise KaffeError('Ordering not found for node kind: {}'.format(node_kind))\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.data is None:\n                continue\n            if node.kind not in self.reshaped_node_types:\n                # Check for 2+ dimensional data\n                if any(len(tensor.shape) > 1 for tensor in node.data):\n                    print_stderr('Warning: parmaters not reshaped for node: {}'.format(node))\n                continue\n            transpose_order = self.map(node.kind)\n            weights = node.data[0]\n            if (node.kind == NodeKind.InnerProduct) and self.has_spatial_parent(node):\n                # The FC layer connected to the spatial layer needs to be\n                # re-wired to match the new spatial ordering.\n                in_shape = node.get_only_parent().output_shape\n                fc_shape = weights.shape\n                output_channels = fc_shape[0]\n                weights = weights.reshape((output_channels, in_shape.channels, in_shape.height,\n                                           in_shape.width))\n                weights = weights.transpose(self.map(NodeKind.Convolution))\n                node.reshaped_data = weights.reshape(fc_shape[transpose_order[0]],\n                                                     fc_shape[transpose_order[1]])\n            else:\n                node.reshaped_data = weights.transpose(transpose_order)\n\n        if self.replace:\n            for node in graph.nodes:\n                if hasattr(node, 'reshaped_data'):\n                    # Set the weights\n                    node.data[0] = node.reshaped_data\n                    del node.reshaped_data\n        return graph\n\n\nclass SubNodeFuser(object):\n    '''\n    An abstract helper for merging a single-child with its single-parent.\n    '''\n\n    def __call__(self, graph):\n        nodes = graph.nodes\n        fused_nodes = []\n        for node in nodes:\n            if len(node.parents) != 1:\n                # We're only fusing nodes with single parents\n                continue\n            parent = node.get_only_parent()\n            if len(parent.children) != 1:\n                # We can only fuse a node if its parent's\n                # value isn't used by any other node.\n                continue\n            if not self.is_eligible_pair(parent, node):\n                continue\n            # Rewrite the fused node's children to its parent.\n            for child in node.children:\n                child.parents.remove(node)\n                parent.add_child(child)\n            # Disconnect the fused node from the graph.\n            parent.children.remove(node)\n            fused_nodes.append(node)\n            # Let the sub-class merge the fused node in any arbitrary way.\n            self.merge(parent, node)\n        transformed_nodes = [node for node in nodes if node not in fused_nodes]\n        return graph.replaced(transformed_nodes)\n\n    def is_eligible_pair(self, parent, child):\n        '''Returns true if this parent/child pair is eligible for fusion.'''\n        raise NotImplementedError('Must be implemented by subclass.')\n\n    def merge(self, parent, child):\n        '''Merge the child node into the parent.'''\n        raise NotImplementedError('Must be implemented by subclass')\n\n\nclass ReLUFuser(SubNodeFuser):\n    '''\n    Fuses rectified linear units with their parent nodes.\n    '''\n\n    def __init__(self, allowed_parent_types=None):\n        # Fuse ReLUs when the parent node is one of the given types.\n        # If None, all node types are eligible.\n        self.allowed_parent_types = allowed_parent_types\n\n    def is_eligible_pair(self, parent, child):\n        return ((self.allowed_parent_types is None or parent.kind in self.allowed_parent_types) and\n                child.kind == NodeKind.ReLU)\n\n    def merge(self, parent, _):\n        parent.metadata['relu'] = True\n\n\nclass BatchNormScaleBiasFuser(SubNodeFuser):\n    '''\n    The original batch normalization paper includes two learned\n    parameters: a scaling factor \\gamma and a bias \\beta.\n    Caffe's implementation does not include these two. However, it is commonly\n    replicated by adding a scaling+bias layer immidiately after the batch norm.\n\n    This fuser merges the scaling+bias layer with the batch norm.\n    '''\n\n    def is_eligible_pair(self, parent, child):\n        return (parent.kind == NodeKind.BatchNorm and child.kind == NodeKind.Scale and\n                child.parameters.axis == 1 and child.parameters.bias_term == True)\n\n    def merge(self, parent, child):\n        parent.scale_bias_node = child\n\n\nclass BatchNormPreprocessor(object):\n    '''\n    Prescale batch normalization parameters.\n    Concatenate gamma (scale) and beta (bias) terms if set.\n    '''\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.kind != NodeKind.BatchNorm:\n                continue\n            assert node.data is not None\n            assert len(node.data) == 3\n            mean, variance, scale = node.data\n            # Prescale the stats\n            scaling_factor = 1.0 / scale if scale != 0 else 0\n            mean *= scaling_factor\n            variance *= scaling_factor\n            # Replace with the updated values\n            node.data = [mean, variance]\n            if hasattr(node, 'scale_bias_node'):\n                # Include the scale and bias terms\n                gamma, beta = node.scale_bias_node.data\n                node.data += [gamma, beta]\n        return graph\n\n\nclass NodeRenamer(object):\n    '''\n    Renames nodes in the graph using a given unary function that\n    accepts a node and returns its new name.\n    '''\n\n    def __init__(self, renamer):\n        self.renamer = renamer\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            node.name = self.renamer(node)\n        return graph\n\n\nclass ParameterNamer(object):\n    '''\n    Convert layer data arrays to a dictionary mapping parameter names to their values.\n    '''\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.data is None:\n                continue\n            if node.kind in (NodeKind.Convolution, NodeKind.InnerProduct):\n                names = ('weights',)\n                if node.parameters.bias_term:\n                    names += ('biases',)\n            elif node.kind == NodeKind.BatchNorm:\n                names = ('moving_mean', 'moving_variance')\n                if len(node.data) == 4:\n                    names += ('gamma', 'beta')\n            else:\n                print_stderr('WARNING: Unhandled parameters: {}'.format(node.kind))\n                continue\n            assert len(names) == len(node.data)\n            node.data = dict(zip(names, node.data))\n        return graph\n"""
kaffe/caffe/__init__.py,0,"b'from .resolver import get_caffe_resolver, has_pycaffe\n'"
kaffe/caffe/caffepb.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: caffe.proto\n\nfrom google.protobuf.internal import enum_type_wrapper\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import descriptor_pb2\n# @@protoc_insertion_point(imports)\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'caffe.proto\',\n  package=\'caffe\',\n  serialized_pb=\'\\n\\x0b\\x63\\x61\\x66\\x66\\x65.proto\\x12\\x05\\x63\\x61\\x66\\x66\\x65\\""\\x1c\\n\\tBlobShape\\x12\\x0f\\n\\x03\\x64im\\x18\\x01 \\x03(\\x03\\x42\\x02\\x10\\x01\\""\\xcc\\x01\\n\\tBlobProto\\x12\\x1f\\n\\x05shape\\x18\\x07 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x10\\n\\x04\\x64\\x61ta\\x18\\x05 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x10\\n\\x04\\x64iff\\x18\\x06 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_data\\x18\\x08 \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_diff\\x18\\t \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x0e\\n\\x03num\\x18\\x01 \\x01(\\x05:\\x01\\x30\\x12\\x13\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x11\\n\\x06height\\x18\\x03 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05width\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""2\\n\\x0f\\x42lobProtoVector\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\""\\x81\\x01\\n\\x05\\x44\\x61tum\\x12\\x10\\n\\x08\\x63hannels\\x18\\x01 \\x01(\\x05\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\x05\\x12\\r\\n\\x05width\\x18\\x03 \\x01(\\x05\\x12\\x0c\\n\\x04\\x64\\x61ta\\x18\\x04 \\x01(\\x0c\\x12\\r\\n\\x05label\\x18\\x05 \\x01(\\x05\\x12\\x12\\n\\nfloat_data\\x18\\x06 \\x03(\\x02\\x12\\x16\\n\\x07\\x65ncoded\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\x8a\\x02\\n\\x0f\\x46illerParameter\\x12\\x16\\n\\x04type\\x18\\x01 \\x01(\\t:\\x08\\x63onstant\\x12\\x10\\n\\x05value\\x18\\x02 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03min\\x18\\x03 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03max\\x18\\x04 \\x01(\\x02:\\x01\\x31\\x12\\x0f\\n\\x04mean\\x18\\x05 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03std\\x18\\x06 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x06sparse\\x18\\x07 \\x01(\\x05:\\x02-1\\x12\\x42\\n\\rvariance_norm\\x18\\x08 \\x01(\\x0e\\x32#.caffe.FillerParameter.VarianceNorm:\\x06\\x46\\x41N_IN\\""4\\n\\x0cVarianceNorm\\x12\\n\\n\\x06\\x46\\x41N_IN\\x10\\x00\\x12\\x0b\\n\\x07\\x46\\x41N_OUT\\x10\\x01\\x12\\x0b\\n\\x07\\x41VERAGE\\x10\\x02\\""\\x8e\\x02\\n\\x0cNetParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05input\\x18\\x03 \\x03(\\t\\x12%\\n\\x0binput_shape\\x18\\x08 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x11\\n\\tinput_dim\\x18\\x04 \\x03(\\x05\\x12\\x1d\\n\\x0e\\x66orce_backward\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1e\\n\\x05state\\x18\\x06 \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x19\\n\\ndebug_info\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\x12$\\n\\x05layer\\x18\\x64 \\x03(\\x0b\\x32\\x15.caffe.LayerParameter\\x12\\\'\\n\\x06layers\\x18\\x02 \\x03(\\x0b\\x32\\x17.caffe.V1LayerParameter\\""\\x9c\\n\\n\\x0fSolverParameter\\x12\\x0b\\n\\x03net\\x18\\x18 \\x01(\\t\\x12&\\n\\tnet_param\\x18\\x19 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12\\x11\\n\\ttrain_net\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x08test_net\\x18\\x02 \\x03(\\t\\x12,\\n\\x0ftrain_net_param\\x18\\x15 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12+\\n\\x0etest_net_param\\x18\\x16 \\x03(\\x0b\\x32\\x13.caffe.NetParameter\\x12$\\n\\x0btrain_state\\x18\\x1a \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12#\\n\\ntest_state\\x18\\x1b \\x03(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x11\\n\\ttest_iter\\x18\\x03 \\x03(\\x05\\x12\\x18\\n\\rtest_interval\\x18\\x04 \\x01(\\x05:\\x01\\x30\\x12 \\n\\x11test_compute_loss\\x18\\x13 \\x01(\\x08:\\x05\\x66\\x61lse\\x12!\\n\\x13test_initialization\\x18  \\x01(\\x08:\\x04true\\x12\\x0f\\n\\x07\\x62\\x61se_lr\\x18\\x05 \\x01(\\x02\\x12\\x0f\\n\\x07\\x64isplay\\x18\\x06 \\x01(\\x05\\x12\\x17\\n\\x0c\\x61verage_loss\\x18! \\x01(\\x05:\\x01\\x31\\x12\\x10\\n\\x08max_iter\\x18\\x07 \\x01(\\x05\\x12\\x14\\n\\titer_size\\x18$ \\x01(\\x05:\\x01\\x31\\x12\\x11\\n\\tlr_policy\\x18\\x08 \\x01(\\t\\x12\\r\\n\\x05gamma\\x18\\t \\x01(\\x02\\x12\\r\\n\\x05power\\x18\\n \\x01(\\x02\\x12\\x10\\n\\x08momentum\\x18\\x0b \\x01(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x0c \\x01(\\x02\\x12\\x1f\\n\\x13regularization_type\\x18\\x1d \\x01(\\t:\\x02L2\\x12\\x10\\n\\x08stepsize\\x18\\r \\x01(\\x05\\x12\\x11\\n\\tstepvalue\\x18\\"" \\x03(\\x05\\x12\\x1a\\n\\x0e\\x63lip_gradients\\x18# \\x01(\\x02:\\x02-1\\x12\\x13\\n\\x08snapshot\\x18\\x0e \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0fsnapshot_prefix\\x18\\x0f \\x01(\\t\\x12\\x1c\\n\\rsnapshot_diff\\x18\\x10 \\x01(\\x08:\\x05\\x66\\x61lse\\x12K\\n\\x0fsnapshot_format\\x18% \\x01(\\x0e\\x32%.caffe.SolverParameter.SnapshotFormat:\\x0b\\x42INARYPROTO\\x12;\\n\\x0bsolver_mode\\x18\\x11 \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverMode:\\x03GPU\\x12\\x14\\n\\tdevice_id\\x18\\x12 \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0brandom_seed\\x18\\x14 \\x01(\\x03:\\x02-1\\x12\\x11\\n\\x04type\\x18( \\x01(\\t:\\x03SGD\\x12\\x14\\n\\x05\\x64\\x65lta\\x18\\x1f \\x01(\\x02:\\x05\\x31\\x65-08\\x12\\x18\\n\\tmomentum2\\x18\\\' \\x01(\\x02:\\x05\\x30.999\\x12\\x11\\n\\trms_decay\\x18& \\x01(\\x02\\x12\\x19\\n\\ndebug_info\\x18\\x17 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x14snapshot_after_train\\x18\\x1c \\x01(\\x08:\\x04true\\x12;\\n\\x0bsolver_type\\x18\\x1e \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverType:\\x03SGD\\""+\\n\\x0eSnapshotFormat\\x12\\x08\\n\\x04HDF5\\x10\\x00\\x12\\x0f\\n\\x0b\\x42INARYPROTO\\x10\\x01\\""\\x1e\\n\\nSolverMode\\x12\\x07\\n\\x03\\x43PU\\x10\\x00\\x12\\x07\\n\\x03GPU\\x10\\x01\\""U\\n\\nSolverType\\x12\\x07\\n\\x03SGD\\x10\\x00\\x12\\x0c\\n\\x08NESTEROV\\x10\\x01\\x12\\x0b\\n\\x07\\x41\\x44\\x41GRAD\\x10\\x02\\x12\\x0b\\n\\x07RMSPROP\\x10\\x03\\x12\\x0c\\n\\x08\\x41\\x44\\x41\\x44\\x45LTA\\x10\\x04\\x12\\x08\\n\\x04\\x41\\x44\\x41M\\x10\\x05\\""l\\n\\x0bSolverState\\x12\\x0c\\n\\x04iter\\x18\\x01 \\x01(\\x05\\x12\\x13\\n\\x0blearned_net\\x18\\x02 \\x01(\\t\\x12!\\n\\x07history\\x18\\x03 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x17\\n\\x0c\\x63urrent_step\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""N\\n\\x08NetState\\x12!\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase:\\x04TEST\\x12\\x10\\n\\x05level\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\r\\n\\x05stage\\x18\\x03 \\x03(\\t\\""s\\n\\x0cNetStateRule\\x12\\x1b\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x11\\n\\tmin_level\\x18\\x02 \\x01(\\x05\\x12\\x11\\n\\tmax_level\\x18\\x03 \\x01(\\x05\\x12\\r\\n\\x05stage\\x18\\x04 \\x03(\\t\\x12\\x11\\n\\tnot_stage\\x18\\x05 \\x03(\\t\\""\\xa3\\x01\\n\\tParamSpec\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x31\\n\\nshare_mode\\x18\\x02 \\x01(\\x0e\\x32\\x1d.caffe.ParamSpec.DimCheckMode\\x12\\x12\\n\\x07lr_mult\\x18\\x03 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\ndecay_mult\\x18\\x04 \\x01(\\x02:\\x01\\x31\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\x98\\x13\\n\\x0eLayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x03 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x04 \\x03(\\t\\x12\\x1b\\n\\x05phase\\x18\\n \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x13\\n\\x0bloss_weight\\x18\\x05 \\x03(\\x02\\x12\\x1f\\n\\x05param\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.ParamSpec\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x07 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x16\\n\\x0epropagate_down\\x18\\x0b \\x03(\\x08\\x12$\\n\\x07include\\x18\\x08 \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18\\t \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12\\x37\\n\\x0ftransform_param\\x18\\x64 \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18\\x65 \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x66 \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18g \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12\\x34\\n\\x10\\x62\\x61tch_norm_param\\x18\\x8b\\x01 \\x01(\\x0b\\x32\\x19.caffe.BatchNormParameter\\x12)\\n\\nbias_param\\x18\\x8d\\x01 \\x01(\\x0b\\x32\\x14.caffe.BiasParameter\\x12,\\n\\x0c\\x63oncat_param\\x18h \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18i \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18j \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12)\\n\\ncrop_param\\x18\\x90\\x01 \\x01(\\x0b\\x32\\x14.caffe.CropParameter\\x12(\\n\\ndata_param\\x18k \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18l \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18m \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18n \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12\\\'\\n\\telu_param\\x18\\x8c\\x01 \\x01(\\x0b\\x32\\x13.caffe.ELUParameter\\x12+\\n\\x0b\\x65mbed_param\\x18\\x89\\x01 \\x01(\\x0b\\x32\\x15.caffe.EmbedParameter\\x12&\\n\\texp_param\\x18o \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12/\\n\\rflatten_param\\x18\\x87\\x01 \\x01(\\x0b\\x32\\x17.caffe.FlattenParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18p \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18q \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18r \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18s \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18t \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18u \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12+\\n\\x0binput_param\\x18\\x8f\\x01 \\x01(\\x0b\\x32\\x15.caffe.InputParameter\\x12\\\'\\n\\tlog_param\\x18\\x86\\x01 \\x01(\\x0b\\x32\\x13.caffe.LogParameter\\x12&\\n\\tlrn_param\\x18v \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18w \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18x \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18y \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18z \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12+\\n\\x0bprelu_param\\x18\\x83\\x01 \\x01(\\x0b\\x32\\x15.caffe.PReLUParameter\\x12-\\n\\x0cpython_param\\x18\\x82\\x01 \\x01(\\x0b\\x32\\x16.caffe.PythonParameter\\x12\\x33\\n\\x0freduction_param\\x18\\x88\\x01 \\x01(\\x0b\\x32\\x19.caffe.ReductionParameter\\x12(\\n\\nrelu_param\\x18{ \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12/\\n\\rreshape_param\\x18\\x85\\x01 \\x01(\\x0b\\x32\\x17.caffe.ReshapeParameter\\x12+\\n\\x0bscale_param\\x18\\x8e\\x01 \\x01(\\x0b\\x32\\x15.caffe.ScaleParameter\\x12.\\n\\rsigmoid_param\\x18| \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18} \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12\\\'\\n\\tspp_param\\x18\\x84\\x01 \\x01(\\x0b\\x32\\x13.caffe.SPPParameter\\x12*\\n\\x0bslice_param\\x18~ \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18\\x7f \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x33\\n\\x0fthreshold_param\\x18\\x80\\x01 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12)\\n\\ntile_param\\x18\\x8a\\x01 \\x01(\\x0b\\x32\\x14.caffe.TileParameter\\x12\\x36\\n\\x11window_data_param\\x18\\x81\\x01 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\""\\xb6\\x01\\n\\x17TransformationParameter\\x12\\x10\\n\\x05scale\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\x06mirror\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x14\\n\\tcrop_size\\x18\\x03 \\x01(\\r:\\x01\\x30\\x12\\x11\\n\\tmean_file\\x18\\x04 \\x01(\\t\\x12\\x12\\n\\nmean_value\\x18\\x05 \\x03(\\x02\\x12\\x1a\\n\\x0b\\x66orce_color\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\nforce_gray\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xc2\\x01\\n\\rLossParameter\\x12\\x14\\n\\x0cignore_label\\x18\\x01 \\x01(\\x05\\x12\\x44\\n\\rnormalization\\x18\\x03 \\x01(\\x0e\\x32&.caffe.LossParameter.NormalizationMode:\\x05VALID\\x12\\x11\\n\\tnormalize\\x18\\x02 \\x01(\\x08\\""B\\n\\x11NormalizationMode\\x12\\x08\\n\\x04\\x46ULL\\x10\\x00\\x12\\t\\n\\x05VALID\\x10\\x01\\x12\\x0e\\n\\nBATCH_SIZE\\x10\\x02\\x12\\x08\\n\\x04NONE\\x10\\x03\\""L\\n\\x11\\x41\\x63\\x63uracyParameter\\x12\\x10\\n\\x05top_k\\x18\\x01 \\x01(\\r:\\x01\\x31\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x0cignore_label\\x18\\x03 \\x01(\\x05\\""M\\n\\x0f\\x41rgMaxParameter\\x12\\x1a\\n\\x0bout_max_val\\x18\\x01 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x10\\n\\x05top_k\\x18\\x02 \\x01(\\r:\\x01\\x31\\x12\\x0c\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05\\""9\\n\\x0f\\x43oncatParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x15\\n\\nconcat_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""j\\n\\x12\\x42\\x61tchNormParameter\\x12\\x18\\n\\x10use_global_stats\\x18\\x01 \\x01(\\x08\\x12&\\n\\x17moving_average_fraction\\x18\\x02 \\x01(\\x02:\\x05\\x30.999\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-05\\""]\\n\\rBiasParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""L\\n\\x18\\x43ontrastiveLossParameter\\x12\\x11\\n\\x06margin\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x1d\\n\\x0elegacy_version\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xfc\\x03\\n\\x14\\x43onvolutionParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12\\x0b\\n\\x03pad\\x18\\x03 \\x03(\\r\\x12\\x13\\n\\x0bkernel_size\\x18\\x04 \\x03(\\r\\x12\\x0e\\n\\x06stride\\x18\\x06 \\x03(\\r\\x12\\x10\\n\\x08\\x64ilation\\x18\\x12 \\x03(\\r\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x08kernel_h\\x18\\x0b \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x0c \\x01(\\r\\x12\\x10\\n\\x08stride_h\\x18\\r \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x0e \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\x05 \\x01(\\r:\\x01\\x31\\x12-\\n\\rweight_filler\\x18\\x07 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x08 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12;\\n\\x06\\x65ngine\\x18\\x0f \\x01(\\x0e\\x32\\"".caffe.ConvolutionParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x10 \\x01(\\x05:\\x01\\x31\\x12\\x1e\\n\\x0f\\x66orce_nd_im2col\\x18\\x11 \\x01(\\x08:\\x05\\x66\\x61lse\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""0\\n\\rCropParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x32\\x12\\x0e\\n\\x06offset\\x18\\x02 \\x03(\\r\\""\\xa4\\x02\\n\\rDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x31\\n\\x07\\x62\\x61\\x63kend\\x18\\x08 \\x01(\\x0e\\x32\\x17.caffe.DataParameter.DB:\\x07LEVELDB\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x13\\x66orce_encoded_color\\x18\\t \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x13\\n\\x08prefetch\\x18\\n \\x01(\\r:\\x01\\x34\\""\\x1b\\n\\x02\\x44\\x42\\x12\\x0b\\n\\x07LEVELDB\\x10\\x00\\x12\\x08\\n\\x04LMDB\\x10\\x01\\"".\\n\\x10\\x44ropoutParameter\\x12\\x1a\\n\\rdropout_ratio\\x18\\x01 \\x01(\\x02:\\x03\\x30.5\\""\\xa0\\x01\\n\\x12\\x44ummyDataParameter\\x12+\\n\\x0b\\x64\\x61ta_filler\\x18\\x01 \\x03(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1f\\n\\x05shape\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0b\\n\\x03num\\x18\\x02 \\x03(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x03 \\x03(\\r\\x12\\x0e\\n\\x06height\\x18\\x04 \\x03(\\r\\x12\\r\\n\\x05width\\x18\\x05 \\x03(\\r\\""\\xa5\\x01\\n\\x10\\x45ltwiseParameter\\x12\\x39\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32!.caffe.EltwiseParameter.EltwiseOp:\\x03SUM\\x12\\r\\n\\x05\\x63oeff\\x18\\x02 \\x03(\\x02\\x12\\x1e\\n\\x10stable_prod_grad\\x18\\x03 \\x01(\\x08:\\x04true\\""\\\'\\n\\tEltwiseOp\\x12\\x08\\n\\x04PROD\\x10\\x00\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x07\\n\\x03MAX\\x10\\x02\\"" \\n\\x0c\\x45LUParameter\\x12\\x10\\n\\x05\\x61lpha\\x18\\x01 \\x01(\\x02:\\x01\\x31\\""\\xac\\x01\\n\\x0e\\x45mbedParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x11\\n\\tinput_dim\\x18\\x02 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x03 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""D\\n\\x0c\\x45xpParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""9\\n\\x10\\x46lattenParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x08\\x65nd_axis\\x18\\x02 \\x01(\\x05:\\x02-1\\""O\\n\\x11HDF5DataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x02 \\x01(\\r\\x12\\x16\\n\\x07shuffle\\x18\\x03 \\x01(\\x08:\\x05\\x66\\x61lse\\""(\\n\\x13HDF5OutputParameter\\x12\\x11\\n\\tfile_name\\x18\\x01 \\x01(\\t\\""^\\n\\x12HingeLossParameter\\x12\\x30\\n\\x04norm\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.HingeLossParameter.Norm:\\x02L1\\""\\x16\\n\\x04Norm\\x12\\x06\\n\\x02L1\\x10\\x01\\x12\\x06\\n\\x02L2\\x10\\x02\\""\\x97\\x02\\n\\x12ImageDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\nbatch_size\\x18\\x04 \\x01(\\r:\\x01\\x31\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x07shuffle\\x18\\x08 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nnew_height\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x08is_color\\x18\\x0b \\x01(\\x08:\\x04true\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\x0c \\x01(\\t:\\x00\\""\\\'\\n\\x15InfogainLossParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\""\\xcb\\x01\\n\\x15InnerProductParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x05 \\x01(\\x05:\\x01\\x31\\x12\\x18\\n\\ttranspose\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\""1\\n\\x0eInputParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\""D\\n\\x0cLogParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""\\xb8\\x02\\n\\x0cLRNParameter\\x12\\x15\\n\\nlocal_size\\x18\\x01 \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x03 \\x01(\\x02:\\x04\\x30.75\\x12\\x44\\n\\x0bnorm_region\\x18\\x04 \\x01(\\x0e\\x32\\x1e.caffe.LRNParameter.NormRegion:\\x0f\\x41\\x43ROSS_CHANNELS\\x12\\x0c\\n\\x01k\\x18\\x05 \\x01(\\x02:\\x01\\x31\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.LRNParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""5\\n\\nNormRegion\\x12\\x13\\n\\x0f\\x41\\x43ROSS_CHANNELS\\x10\\x00\\x12\\x12\\n\\x0eWITHIN_CHANNEL\\x10\\x01\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x13MemoryDataParameter\\x12\\x12\\n\\nbatch_size\\x18\\x01 \\x01(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x03 \\x01(\\r\\x12\\r\\n\\x05width\\x18\\x04 \\x01(\\r\\""d\\n\\x0cMVNParameter\\x12 \\n\\x12normalize_variance\\x18\\x01 \\x01(\\x08:\\x04true\\x12\\x1e\\n\\x0f\\x61\\x63ross_channels\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-09\\""\\xa2\\x03\\n\\x10PoolingParameter\\x12\\x35\\n\\x04pool\\x18\\x01 \\x01(\\x0e\\x32\\"".caffe.PoolingParameter.PoolMethod:\\x03MAX\\x12\\x0e\\n\\x03pad\\x18\\x04 \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x13\\n\\x0bkernel_size\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08kernel_h\\x18\\x05 \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x06 \\x01(\\r\\x12\\x11\\n\\x06stride\\x18\\x03 \\x01(\\r:\\x01\\x31\\x12\\x10\\n\\x08stride_h\\x18\\x07 \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x08 \\x01(\\r\\x12\\x37\\n\\x06\\x65ngine\\x18\\x0b \\x01(\\x0e\\x32\\x1e.caffe.PoolingParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x1d\\n\\x0eglobal_pooling\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""F\\n\\x0ePowerParameter\\x12\\x10\\n\\x05power\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""g\\n\\x0fPythonParameter\\x12\\x0e\\n\\x06module\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05layer\\x18\\x02 \\x01(\\t\\x12\\x13\\n\\tparam_str\\x18\\x03 \\x01(\\t:\\x00\\x12 \\n\\x11share_in_parallel\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xad\\x01\\n\\x12ReductionParameter\\x12=\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32%.caffe.ReductionParameter.ReductionOp:\\x03SUM\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05\\x63oeff\\x18\\x03 \\x01(\\x02:\\x01\\x31\\""5\\n\\x0bReductionOp\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x08\\n\\x04\\x41SUM\\x10\\x02\\x12\\t\\n\\x05SUMSQ\\x10\\x03\\x12\\x08\\n\\x04MEAN\\x10\\x04\\""\\x8d\\x01\\n\\rReLUParameter\\x12\\x19\\n\\x0enegative_slope\\x18\\x01 \\x01(\\x02:\\x01\\x30\\x12\\x34\\n\\x06\\x65ngine\\x18\\x02 \\x01(\\x0e\\x32\\x1b.caffe.ReLUParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x10ReshapeParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\x08num_axes\\x18\\x03 \\x01(\\x05:\\x02-1\\""\\xa5\\x01\\n\\x0eScaleParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x18\\n\\tbias_term\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""x\\n\\x10SigmoidParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SigmoidParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""L\\n\\x0eSliceParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x0bslice_point\\x18\\x02 \\x03(\\r\\x12\\x14\\n\\tslice_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""\\x89\\x01\\n\\x10SoftmaxParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SoftmaxParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""r\\n\\rTanHParameter\\x12\\x34\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1b.caffe.TanHParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""/\\n\\rTileParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\r\\n\\x05tiles\\x18\\x02 \\x01(\\x05\\""*\\n\\x12ThresholdParameter\\x12\\x14\\n\\tthreshold\\x18\\x01 \\x01(\\x02:\\x01\\x30\\""\\xc1\\x02\\n\\x13WindowDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\x0c\\x66g_threshold\\x18\\x07 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0c\\x62g_threshold\\x18\\x08 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0b\\x66g_fraction\\x18\\t \\x01(\\x02:\\x04\\x30.25\\x12\\x16\\n\\x0b\\x63ontext_pad\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x17\\n\\tcrop_mode\\x18\\x0b \\x01(\\t:\\x04warp\\x12\\x1b\\n\\x0c\\x63\\x61\\x63he_images\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\r \\x01(\\t:\\x00\\""\\xeb\\x01\\n\\x0cSPPParameter\\x12\\x16\\n\\x0epyramid_height\\x18\\x01 \\x01(\\r\\x12\\x31\\n\\x04pool\\x18\\x02 \\x01(\\x0e\\x32\\x1e.caffe.SPPParameter.PoolMethod:\\x03MAX\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.SPPParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""\\xe0\\x13\\n\\x10V1LayerParameter\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x02 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x03 \\x03(\\t\\x12\\x0c\\n\\x04name\\x18\\x04 \\x01(\\t\\x12$\\n\\x07include\\x18  \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18! \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12/\\n\\x04type\\x18\\x05 \\x01(\\x0e\\x32!.caffe.V1LayerParameter.LayerType\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x0e\\n\\x05param\\x18\\xe9\\x07 \\x03(\\t\\x12>\\n\\x0f\\x62lob_share_mode\\x18\\xea\\x07 \\x03(\\x0e\\x32$.caffe.V1LayerParameter.DimCheckMode\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x07 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x08 \\x03(\\x02\\x12\\x13\\n\\x0bloss_weight\\x18# \\x03(\\x02\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x1b \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18\\x17 \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12,\\n\\x0c\\x63oncat_param\\x18\\t \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18( \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18\\n \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12(\\n\\ndata_param\\x18\\x0b \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18\\x0c \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18\\x1a \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18\\x18 \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12&\\n\\texp_param\\x18) \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18\\r \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18\\x0e \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18\\x1d \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18\\x0f \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18\\x10 \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18\\x11 \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12&\\n\\tlrn_param\\x18\\x12 \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18\\x16 \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18\\"" \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18\\x13 \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18\\x15 \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12(\\n\\nrelu_param\\x18\\x1e \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12.\\n\\rsigmoid_param\\x18& \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18\\\' \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12*\\n\\x0bslice_param\\x18\\x1f \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18% \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x32\\n\\x0fthreshold_param\\x18\\x19 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12\\x35\\n\\x11window_data_param\\x18\\x14 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\x12\\x37\\n\\x0ftransform_param\\x18$ \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18* \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12&\\n\\x05layer\\x18\\x01 \\x01(\\x0b\\x32\\x17.caffe.V0LayerParameter\\""\\xd8\\x04\\n\\tLayerType\\x12\\x08\\n\\x04NONE\\x10\\x00\\x12\\n\\n\\x06\\x41\\x42SVAL\\x10#\\x12\\x0c\\n\\x08\\x41\\x43\\x43URACY\\x10\\x01\\x12\\n\\n\\x06\\x41RGMAX\\x10\\x1e\\x12\\x08\\n\\x04\\x42NLL\\x10\\x02\\x12\\n\\n\\x06\\x43ONCAT\\x10\\x03\\x12\\x14\\n\\x10\\x43ONTRASTIVE_LOSS\\x10%\\x12\\x0f\\n\\x0b\\x43ONVOLUTION\\x10\\x04\\x12\\x08\\n\\x04\\x44\\x41TA\\x10\\x05\\x12\\x11\\n\\rDECONVOLUTION\\x10\\\'\\x12\\x0b\\n\\x07\\x44ROPOUT\\x10\\x06\\x12\\x0e\\n\\nDUMMY_DATA\\x10 \\x12\\x12\\n\\x0e\\x45UCLIDEAN_LOSS\\x10\\x07\\x12\\x0b\\n\\x07\\x45LTWISE\\x10\\x19\\x12\\x07\\n\\x03\\x45XP\\x10&\\x12\\x0b\\n\\x07\\x46LATTEN\\x10\\x08\\x12\\r\\n\\tHDF5_DATA\\x10\\t\\x12\\x0f\\n\\x0bHDF5_OUTPUT\\x10\\n\\x12\\x0e\\n\\nHINGE_LOSS\\x10\\x1c\\x12\\n\\n\\x06IM2COL\\x10\\x0b\\x12\\x0e\\n\\nIMAGE_DATA\\x10\\x0c\\x12\\x11\\n\\rINFOGAIN_LOSS\\x10\\r\\x12\\x11\\n\\rINNER_PRODUCT\\x10\\x0e\\x12\\x07\\n\\x03LRN\\x10\\x0f\\x12\\x0f\\n\\x0bMEMORY_DATA\\x10\\x1d\\x12\\x1d\\n\\x19MULTINOMIAL_LOGISTIC_LOSS\\x10\\x10\\x12\\x07\\n\\x03MVN\\x10\\""\\x12\\x0b\\n\\x07POOLING\\x10\\x11\\x12\\t\\n\\x05POWER\\x10\\x1a\\x12\\x08\\n\\x04RELU\\x10\\x12\\x12\\x0b\\n\\x07SIGMOID\\x10\\x13\\x12\\x1e\\n\\x1aSIGMOID_CROSS_ENTROPY_LOSS\\x10\\x1b\\x12\\x0b\\n\\x07SILENCE\\x10$\\x12\\x0b\\n\\x07SOFTMAX\\x10\\x14\\x12\\x10\\n\\x0cSOFTMAX_LOSS\\x10\\x15\\x12\\t\\n\\x05SPLIT\\x10\\x16\\x12\\t\\n\\x05SLICE\\x10!\\x12\\x08\\n\\x04TANH\\x10\\x17\\x12\\x0f\\n\\x0bWINDOW_DATA\\x10\\x18\\x12\\r\\n\\tTHRESHOLD\\x10\\x1f\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\xfd\\x07\\n\\x10V0LayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x12\\n\\nnum_output\\x18\\x03 \\x01(\\r\\x12\\x16\\n\\x08\\x62iasterm\\x18\\x04 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x06 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0e\\n\\x03pad\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x12\\n\\nkernelsize\\x18\\x08 \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\t \\x01(\\r:\\x01\\x31\\x12\\x11\\n\\x06stride\\x18\\n \\x01(\\r:\\x01\\x31\\x12\\x35\\n\\x04pool\\x18\\x0b \\x01(\\x0e\\x32\\"".caffe.V0LayerParameter.PoolMethod:\\x03MAX\\x12\\x1a\\n\\rdropout_ratio\\x18\\x0c \\x01(\\x02:\\x03\\x30.5\\x12\\x15\\n\\nlocal_size\\x18\\r \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x0e \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x0f \\x01(\\x02:\\x04\\x30.75\\x12\\x0c\\n\\x01k\\x18\\x16 \\x01(\\x02:\\x01\\x31\\x12\\x0e\\n\\x06source\\x18\\x10 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x11 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x08meanfile\\x18\\x12 \\x01(\\t\\x12\\x11\\n\\tbatchsize\\x18\\x13 \\x01(\\r\\x12\\x13\\n\\x08\\x63ropsize\\x18\\x14 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x15 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x32 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x33 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x34 \\x03(\\x02\\x12\\x14\\n\\trand_skip\\x18\\x35 \\x01(\\r:\\x01\\x30\\x12\\x1d\\n\\x10\\x64\\x65t_fg_threshold\\x18\\x36 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x10\\x64\\x65t_bg_threshold\\x18\\x37 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x0f\\x64\\x65t_fg_fraction\\x18\\x38 \\x01(\\x02:\\x04\\x30.25\\x12\\x1a\\n\\x0f\\x64\\x65t_context_pad\\x18: \\x01(\\r:\\x01\\x30\\x12\\x1b\\n\\rdet_crop_mode\\x18; \\x01(\\t:\\x04warp\\x12\\x12\\n\\x07new_num\\x18< \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0cnew_channels\\x18= \\x01(\\x05:\\x01\\x30\\x12\\x15\\n\\nnew_height\\x18> \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18? \\x01(\\x05:\\x01\\x30\\x12\\x1d\\n\\x0eshuffle_images\\x18@ \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nconcat_dim\\x18\\x41 \\x01(\\r:\\x01\\x31\\x12\\x36\\n\\x11hdf5_output_param\\x18\\xe9\\x07 \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""W\\n\\x0ePReLUParameter\\x12&\\n\\x06\\x66iller\\x18\\x01 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1d\\n\\x0e\\x63hannel_shared\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse*\\x1c\\n\\x05Phase\\x12\\t\\n\\x05TRAIN\\x10\\x00\\x12\\x08\\n\\x04TEST\\x10\\x01\')\n\n_PHASE = _descriptor.EnumDescriptor(\n  name=\'Phase\',\n  full_name=\'caffe.Phase\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'TRAIN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TEST\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=14991,\n  serialized_end=15019,\n)\n\nPhase = enum_type_wrapper.EnumTypeWrapper(_PHASE)\nTRAIN = 0\nTEST = 1\n\n\n_FILLERPARAMETER_VARIANCENORM = _descriptor.EnumDescriptor(\n  name=\'VarianceNorm\',\n  full_name=\'caffe.FillerParameter.VarianceNorm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_IN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_OUT\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVERAGE\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=658,\n  serialized_end=710,\n)\n\n_SOLVERPARAMETER_SNAPSHOTFORMAT = _descriptor.EnumDescriptor(\n  name=\'SnapshotFormat\',\n  full_name=\'caffe.SolverParameter.SnapshotFormat\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BINARYPROTO\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2132,\n  serialized_end=2175,\n)\n\n_SOLVERPARAMETER_SOLVERMODE = _descriptor.EnumDescriptor(\n  name=\'SolverMode\',\n  full_name=\'caffe.SolverParameter.SolverMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'CPU\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'GPU\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2177,\n  serialized_end=2207,\n)\n\n_SOLVERPARAMETER_SOLVERTYPE = _descriptor.EnumDescriptor(\n  name=\'SolverType\',\n  full_name=\'caffe.SolverParameter.SolverType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SGD\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NESTEROV\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAGRAD\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RMSPROP\', index=3, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADADELTA\', index=4, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAM\', index=5, number=5,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2209,\n  serialized_end=2294,\n)\n\n_PARAMSPEC_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.ParamSpec.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2725,\n  serialized_end=2767,\n)\n\n_LOSSPARAMETER_NORMALIZATIONMODE = _descriptor.EnumDescriptor(\n  name=\'NormalizationMode\',\n  full_name=\'caffe.LossParameter.NormalizationMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FULL\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'VALID\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BATCH_SIZE\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=3, number=3,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=5542,\n  serialized_end=5608,\n)\n\n_CONVOLUTIONPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ConvolutionParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_DATAPARAMETER_DB = _descriptor.EnumDescriptor(\n  name=\'DB\',\n  full_name=\'caffe.DataParameter.DB\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'LEVELDB\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LMDB\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6934,\n  serialized_end=6961,\n)\n\n_ELTWISEPARAMETER_ELTWISEOP = _descriptor.EnumDescriptor(\n  name=\'EltwiseOp\',\n  full_name=\'caffe.EltwiseParameter.EltwiseOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'PROD\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7301,\n  serialized_end=7340,\n)\n\n_HINGELOSSPARAMETER_NORM = _descriptor.EnumDescriptor(\n  name=\'Norm\',\n  full_name=\'caffe.HingeLossParameter.Norm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'L1\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'L2\', index=1, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7875,\n  serialized_end=7897,\n)\n\n_LRNPARAMETER_NORMREGION = _descriptor.EnumDescriptor(\n  name=\'NormRegion\',\n  full_name=\'caffe.LRNParameter.NormRegion\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'ACROSS_CHANNELS\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WITHIN_CHANNEL\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=8764,\n  serialized_end=8817,\n)\n\n_LRNPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.LRNParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_POOLINGPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.PoolingParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9386,\n  serialized_end=9432,\n)\n\n_POOLINGPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.PoolingParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_REDUCTIONPARAMETER_REDUCTIONOP = _descriptor.EnumDescriptor(\n  name=\'ReductionOp\',\n  full_name=\'caffe.ReductionParameter.ReductionOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ASUM\', index=1, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUMSQ\', index=2, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEAN\', index=3, number=4,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9777,\n  serialized_end=9830,\n)\n\n_RELUPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ReLUParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_SIGMOIDPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SigmoidParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_SOFTMAXPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SoftmaxParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_TANHPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.TanHParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_SPPPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.SPPParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9386,\n  serialized_end=9432,\n)\n\n_SPPPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SPPParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_V1LAYERPARAMETER_LAYERTYPE = _descriptor.EnumDescriptor(\n  name=\'LayerType\',\n  full_name=\'caffe.V1LayerParameter.LayerType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ABSVAL\', index=1, number=35,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ACCURACY\', index=2, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ARGMAX\', index=3, number=30,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BNLL\', index=4, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONCAT\', index=5, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONTRASTIVE_LOSS\', index=6, number=37,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONVOLUTION\', index=7, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DATA\', index=8, number=5,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DECONVOLUTION\', index=9, number=39,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DROPOUT\', index=10, number=6,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DUMMY_DATA\', index=11, number=32,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EUCLIDEAN_LOSS\', index=12, number=7,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ELTWISE\', index=13, number=25,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EXP\', index=14, number=38,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FLATTEN\', index=15, number=8,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_DATA\', index=16, number=9,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_OUTPUT\', index=17, number=10,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HINGE_LOSS\', index=18, number=28,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IM2COL\', index=19, number=11,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IMAGE_DATA\', index=20, number=12,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INFOGAIN_LOSS\', index=21, number=13,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INNER_PRODUCT\', index=22, number=14,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LRN\', index=23, number=15,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEMORY_DATA\', index=24, number=29,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MULTINOMIAL_LOGISTIC_LOSS\', index=25, number=16,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MVN\', index=26, number=34,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POOLING\', index=27, number=17,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POWER\', index=28, number=26,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RELU\', index=29, number=18,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID\', index=30, number=19,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID_CROSS_ENTROPY_LOSS\', index=31, number=27,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SILENCE\', index=32, number=36,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX\', index=33, number=20,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX_LOSS\', index=34, number=21,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SPLIT\', index=35, number=22,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SLICE\', index=36, number=33,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TANH\', index=37, number=23,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WINDOW_DATA\', index=38, number=24,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'THRESHOLD\', index=39, number=31,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=13232,\n  serialized_end=13832,\n)\n\n_V1LAYERPARAMETER_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.V1LayerParameter.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2725,\n  serialized_end=2767,\n)\n\n_V0LAYERPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.V0LayerParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9386,\n  serialized_end=9432,\n)\n\n\n_BLOBSHAPE = _descriptor.Descriptor(\n  name=\'BlobShape\',\n  full_name=\'caffe.BlobShape\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dim\', full_name=\'caffe.BlobShape.dim\', index=0,\n      number=1, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=22,\n  serialized_end=50,\n)\n\n\n_BLOBPROTO = _descriptor.Descriptor(\n  name=\'BlobProto\',\n  full_name=\'caffe.BlobProto\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.BlobProto.shape\', index=0,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.BlobProto.data\', index=1,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'diff\', full_name=\'caffe.BlobProto.diff\', index=2,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'double_data\', full_name=\'caffe.BlobProto.double_data\', index=3,\n      number=8, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'double_diff\', full_name=\'caffe.BlobProto.double_diff\', index=4,\n      number=9, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.BlobProto.num\', index=5,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.BlobProto.channels\', index=6,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.BlobProto.height\', index=7,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.BlobProto.width\', index=8,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=53,\n  serialized_end=257,\n)\n\n\n_BLOBPROTOVECTOR = _descriptor.Descriptor(\n  name=\'BlobProtoVector\',\n  full_name=\'caffe.BlobProtoVector\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.BlobProtoVector.blobs\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=259,\n  serialized_end=309,\n)\n\n\n_DATUM = _descriptor.Descriptor(\n  name=\'Datum\',\n  full_name=\'caffe.Datum\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.Datum.channels\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.Datum.height\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.Datum.width\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.Datum.data\', index=3,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value="""",\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'label\', full_name=\'caffe.Datum.label\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'float_data\', full_name=\'caffe.Datum.float_data\', index=5,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'encoded\', full_name=\'caffe.Datum.encoded\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=312,\n  serialized_end=441,\n)\n\n\n_FILLERPARAMETER = _descriptor.Descriptor(\n  name=\'FillerParameter\',\n  full_name=\'caffe.FillerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.FillerParameter.type\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""constant"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'caffe.FillerParameter.value\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min\', full_name=\'caffe.FillerParameter.min\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max\', full_name=\'caffe.FillerParameter.max\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean\', full_name=\'caffe.FillerParameter.mean\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'std\', full_name=\'caffe.FillerParameter.std\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sparse\', full_name=\'caffe.FillerParameter.sparse\', index=6,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'variance_norm\', full_name=\'caffe.FillerParameter.variance_norm\', index=7,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _FILLERPARAMETER_VARIANCENORM,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=444,\n  serialized_end=710,\n)\n\n\n_NETPARAMETER = _descriptor.Descriptor(\n  name=\'NetParameter\',\n  full_name=\'caffe.NetParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.NetParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input\', full_name=\'caffe.NetParameter.input\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_shape\', full_name=\'caffe.NetParameter.input_shape\', index=2,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.NetParameter.input_dim\', index=3,\n      number=4, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_backward\', full_name=\'caffe.NetParameter.force_backward\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'state\', full_name=\'caffe.NetParameter.state\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.NetParameter.debug_info\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.NetParameter.layer\', index=7,\n      number=100, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layers\', full_name=\'caffe.NetParameter.layers\', index=8,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=713,\n  serialized_end=983,\n)\n\n\n_SOLVERPARAMETER = _descriptor.Descriptor(\n  name=\'SolverParameter\',\n  full_name=\'caffe.SolverParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'net\', full_name=\'caffe.SolverParameter.net\', index=0,\n      number=24, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'net_param\', full_name=\'caffe.SolverParameter.net_param\', index=1,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_net\', full_name=\'caffe.SolverParameter.train_net\', index=2,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_net\', full_name=\'caffe.SolverParameter.test_net\', index=3,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_net_param\', full_name=\'caffe.SolverParameter.train_net_param\', index=4,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_net_param\', full_name=\'caffe.SolverParameter.test_net_param\', index=5,\n      number=22, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_state\', full_name=\'caffe.SolverParameter.train_state\', index=6,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_state\', full_name=\'caffe.SolverParameter.test_state\', index=7,\n      number=27, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_iter\', full_name=\'caffe.SolverParameter.test_iter\', index=8,\n      number=3, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_interval\', full_name=\'caffe.SolverParameter.test_interval\', index=9,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_compute_loss\', full_name=\'caffe.SolverParameter.test_compute_loss\', index=10,\n      number=19, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_initialization\', full_name=\'caffe.SolverParameter.test_initialization\', index=11,\n      number=32, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'base_lr\', full_name=\'caffe.SolverParameter.base_lr\', index=12,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'display\', full_name=\'caffe.SolverParameter.display\', index=13,\n      number=6, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'average_loss\', full_name=\'caffe.SolverParameter.average_loss\', index=14,\n      number=33, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max_iter\', full_name=\'caffe.SolverParameter.max_iter\', index=15,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'iter_size\', full_name=\'caffe.SolverParameter.iter_size\', index=16,\n      number=36, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lr_policy\', full_name=\'caffe.SolverParameter.lr_policy\', index=17,\n      number=8, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'gamma\', full_name=\'caffe.SolverParameter.gamma\', index=18,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.SolverParameter.power\', index=19,\n      number=10, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum\', full_name=\'caffe.SolverParameter.momentum\', index=20,\n      number=11, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.SolverParameter.weight_decay\', index=21,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'regularization_type\', full_name=\'caffe.SolverParameter.regularization_type\', index=22,\n      number=29, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""L2"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stepsize\', full_name=\'caffe.SolverParameter.stepsize\', index=23,\n      number=13, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stepvalue\', full_name=\'caffe.SolverParameter.stepvalue\', index=24,\n      number=34, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'clip_gradients\', full_name=\'caffe.SolverParameter.clip_gradients\', index=25,\n      number=35, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot\', full_name=\'caffe.SolverParameter.snapshot\', index=26,\n      number=14, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_prefix\', full_name=\'caffe.SolverParameter.snapshot_prefix\', index=27,\n      number=15, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_diff\', full_name=\'caffe.SolverParameter.snapshot_diff\', index=28,\n      number=16, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_format\', full_name=\'caffe.SolverParameter.snapshot_format\', index=29,\n      number=37, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'solver_mode\', full_name=\'caffe.SolverParameter.solver_mode\', index=30,\n      number=17, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'device_id\', full_name=\'caffe.SolverParameter.device_id\', index=31,\n      number=18, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'random_seed\', full_name=\'caffe.SolverParameter.random_seed\', index=32,\n      number=20, type=3, cpp_type=2, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.SolverParameter.type\', index=33,\n      number=40, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""SGD"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'delta\', full_name=\'caffe.SolverParameter.delta\', index=34,\n      number=31, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1e-08,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum2\', full_name=\'caffe.SolverParameter.momentum2\', index=35,\n      number=39, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.999,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rms_decay\', full_name=\'caffe.SolverParameter.rms_decay\', index=36,\n      number=38, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.SolverParameter.debug_info\', index=37,\n      number=23, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_after_train\', full_name=\'caffe.SolverParameter.snapshot_after_train\', index=38,\n      number=28, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'solver_type\', full_name=\'caffe.SolverParameter.solver_type\', index=39,\n      number=30, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOLVERPARAMETER_SNAPSHOTFORMAT,\n    _SOLVERPARAMETER_SOLVERMODE,\n    _SOLVERPARAMETER_SOLVERTYPE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=986,\n  serialized_end=2294,\n)\n\n\n_SOLVERSTATE = _descriptor.Descriptor(\n  name=\'SolverState\',\n  full_name=\'caffe.SolverState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'iter\', full_name=\'caffe.SolverState.iter\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'learned_net\', full_name=\'caffe.SolverState.learned_net\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'history\', full_name=\'caffe.SolverState.history\', index=2,\n      number=3, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'current_step\', full_name=\'caffe.SolverState.current_step\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2296,\n  serialized_end=2404,\n)\n\n\n_NETSTATE = _descriptor.Descriptor(\n  name=\'NetState\',\n  full_name=\'caffe.NetState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetState.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'level\', full_name=\'caffe.NetState.level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetState.stage\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2406,\n  serialized_end=2484,\n)\n\n\n_NETSTATERULE = _descriptor.Descriptor(\n  name=\'NetStateRule\',\n  full_name=\'caffe.NetStateRule\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetStateRule.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min_level\', full_name=\'caffe.NetStateRule.min_level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max_level\', full_name=\'caffe.NetStateRule.max_level\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetStateRule.stage\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'not_stage\', full_name=\'caffe.NetStateRule.not_stage\', index=4,\n      number=5, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2486,\n  serialized_end=2601,\n)\n\n\n_PARAMSPEC = _descriptor.Descriptor(\n  name=\'ParamSpec\',\n  full_name=\'caffe.ParamSpec\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.ParamSpec.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'share_mode\', full_name=\'caffe.ParamSpec.share_mode\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lr_mult\', full_name=\'caffe.ParamSpec.lr_mult\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'decay_mult\', full_name=\'caffe.ParamSpec.decay_mult\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _PARAMSPEC_DIMCHECKMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2604,\n  serialized_end=2767,\n)\n\n\n_LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'LayerParameter\',\n  full_name=\'caffe.LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.LayerParameter.bottom\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.LayerParameter.top\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.LayerParameter.phase\', index=4,\n      number=10, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.LayerParameter.loss_weight\', index=5,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.LayerParameter.param\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.LayerParameter.blobs\', index=7,\n      number=7, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'propagate_down\', full_name=\'caffe.LayerParameter.propagate_down\', index=8,\n      number=11, type=8, cpp_type=7, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.LayerParameter.include\', index=9,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.LayerParameter.exclude\', index=10,\n      number=9, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.LayerParameter.transform_param\', index=11,\n      number=100, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.LayerParameter.loss_param\', index=12,\n      number=101, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.LayerParameter.accuracy_param\', index=13,\n      number=102, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.LayerParameter.argmax_param\', index=14,\n      number=103, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_norm_param\', full_name=\'caffe.LayerParameter.batch_norm_param\', index=15,\n      number=139, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_param\', full_name=\'caffe.LayerParameter.bias_param\', index=16,\n      number=141, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.LayerParameter.concat_param\', index=17,\n      number=104, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.LayerParameter.contrastive_loss_param\', index=18,\n      number=105, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.LayerParameter.convolution_param\', index=19,\n      number=106, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_param\', full_name=\'caffe.LayerParameter.crop_param\', index=20,\n      number=144, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.LayerParameter.data_param\', index=21,\n      number=107, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.LayerParameter.dropout_param\', index=22,\n      number=108, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.LayerParameter.dummy_data_param\', index=23,\n      number=109, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.LayerParameter.eltwise_param\', index=24,\n      number=110, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'elu_param\', full_name=\'caffe.LayerParameter.elu_param\', index=25,\n      number=140, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'embed_param\', full_name=\'caffe.LayerParameter.embed_param\', index=26,\n      number=137, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.LayerParameter.exp_param\', index=27,\n      number=111, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'flatten_param\', full_name=\'caffe.LayerParameter.flatten_param\', index=28,\n      number=135, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.LayerParameter.hdf5_data_param\', index=29,\n      number=112, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.LayerParameter.hdf5_output_param\', index=30,\n      number=113, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.LayerParameter.hinge_loss_param\', index=31,\n      number=114, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.LayerParameter.image_data_param\', index=32,\n      number=115, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.LayerParameter.infogain_loss_param\', index=33,\n      number=116, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.LayerParameter.inner_product_param\', index=34,\n      number=117, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_param\', full_name=\'caffe.LayerParameter.input_param\', index=35,\n      number=143, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'log_param\', full_name=\'caffe.LayerParameter.log_param\', index=36,\n      number=134, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.LayerParameter.lrn_param\', index=37,\n      number=118, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.LayerParameter.memory_data_param\', index=38,\n      number=119, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.LayerParameter.mvn_param\', index=39,\n      number=120, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.LayerParameter.pooling_param\', index=40,\n      number=121, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.LayerParameter.power_param\', index=41,\n      number=122, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'prelu_param\', full_name=\'caffe.LayerParameter.prelu_param\', index=42,\n      number=131, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'python_param\', full_name=\'caffe.LayerParameter.python_param\', index=43,\n      number=130, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reduction_param\', full_name=\'caffe.LayerParameter.reduction_param\', index=44,\n      number=136, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.LayerParameter.relu_param\', index=45,\n      number=123, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reshape_param\', full_name=\'caffe.LayerParameter.reshape_param\', index=46,\n      number=133, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale_param\', full_name=\'caffe.LayerParameter.scale_param\', index=47,\n      number=142, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.LayerParameter.sigmoid_param\', index=48,\n      number=124, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.LayerParameter.softmax_param\', index=49,\n      number=125, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'spp_param\', full_name=\'caffe.LayerParameter.spp_param\', index=50,\n      number=132, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.LayerParameter.slice_param\', index=51,\n      number=126, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.LayerParameter.tanh_param\', index=52,\n      number=127, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.LayerParameter.threshold_param\', index=53,\n      number=128, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tile_param\', full_name=\'caffe.LayerParameter.tile_param\', index=54,\n      number=138, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.LayerParameter.window_data_param\', index=55,\n      number=129, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2770,\n  serialized_end=5226,\n)\n\n\n_TRANSFORMATIONPARAMETER = _descriptor.Descriptor(\n  name=\'TransformationParameter\',\n  full_name=\'caffe.TransformationParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.TransformationParameter.scale\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.TransformationParameter.mirror\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.TransformationParameter.crop_size\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.TransformationParameter.mean_file\', index=3,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_value\', full_name=\'caffe.TransformationParameter.mean_value\', index=4,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_color\', full_name=\'caffe.TransformationParameter.force_color\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_gray\', full_name=\'caffe.TransformationParameter.force_gray\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5229,\n  serialized_end=5411,\n)\n\n\n_LOSSPARAMETER = _descriptor.Descriptor(\n  name=\'LossParameter\',\n  full_name=\'caffe.LossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.LossParameter.ignore_label\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'normalization\', full_name=\'caffe.LossParameter.normalization\', index=1,\n      number=3, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'normalize\', full_name=\'caffe.LossParameter.normalize\', index=2,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LOSSPARAMETER_NORMALIZATIONMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5414,\n  serialized_end=5608,\n)\n\n\n_ACCURACYPARAMETER = _descriptor.Descriptor(\n  name=\'AccuracyParameter\',\n  full_name=\'caffe.AccuracyParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.AccuracyParameter.top_k\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.AccuracyParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.AccuracyParameter.ignore_label\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5610,\n  serialized_end=5686,\n)\n\n\n_ARGMAXPARAMETER = _descriptor.Descriptor(\n  name=\'ArgMaxParameter\',\n  full_name=\'caffe.ArgMaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'out_max_val\', full_name=\'caffe.ArgMaxParameter.out_max_val\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.ArgMaxParameter.top_k\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ArgMaxParameter.axis\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5688,\n  serialized_end=5765,\n)\n\n\n_CONCATPARAMETER = _descriptor.Descriptor(\n  name=\'ConcatParameter\',\n  full_name=\'caffe.ConcatParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConcatParameter.axis\', index=0,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.ConcatParameter.concat_dim\', index=1,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5767,\n  serialized_end=5824,\n)\n\n\n_BATCHNORMPARAMETER = _descriptor.Descriptor(\n  name=\'BatchNormParameter\',\n  full_name=\'caffe.BatchNormParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'use_global_stats\', full_name=\'caffe.BatchNormParameter.use_global_stats\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'moving_average_fraction\', full_name=\'caffe.BatchNormParameter.moving_average_fraction\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.999,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.BatchNormParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1e-05,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5826,\n  serialized_end=5932,\n)\n\n\n_BIASPARAMETER = _descriptor.Descriptor(\n  name=\'BiasParameter\',\n  full_name=\'caffe.BiasParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.BiasParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.BiasParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.BiasParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5934,\n  serialized_end=6027,\n)\n\n\n_CONTRASTIVELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'ContrastiveLossParameter\',\n  full_name=\'caffe.ContrastiveLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'margin\', full_name=\'caffe.ContrastiveLossParameter.margin\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'legacy_version\', full_name=\'caffe.ContrastiveLossParameter.legacy_version\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6029,\n  serialized_end=6105,\n)\n\n\n_CONVOLUTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ConvolutionParameter\',\n  full_name=\'caffe.ConvolutionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.ConvolutionParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ConvolutionParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.ConvolutionParameter.pad\', index=2,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.ConvolutionParameter.kernel_size\', index=3,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.ConvolutionParameter.stride\', index=4,\n      number=6, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dilation\', full_name=\'caffe.ConvolutionParameter.dilation\', index=5,\n      number=18, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.ConvolutionParameter.pad_h\', index=6,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.ConvolutionParameter.pad_w\', index=7,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.ConvolutionParameter.kernel_h\', index=8,\n      number=11, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.ConvolutionParameter.kernel_w\', index=9,\n      number=12, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.ConvolutionParameter.stride_h\', index=10,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.ConvolutionParameter.stride_w\', index=11,\n      number=14, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.ConvolutionParameter.group\', index=12,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.ConvolutionParameter.weight_filler\', index=13,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ConvolutionParameter.bias_filler\', index=14,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ConvolutionParameter.engine\', index=15,\n      number=15, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConvolutionParameter.axis\', index=16,\n      number=16, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_nd_im2col\', full_name=\'caffe.ConvolutionParameter.force_nd_im2col\', index=17,\n      number=17, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _CONVOLUTIONPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6108,\n  serialized_end=6616,\n)\n\n\n_CROPPARAMETER = _descriptor.Descriptor(\n  name=\'CropParameter\',\n  full_name=\'caffe.CropParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.CropParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=2,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'offset\', full_name=\'caffe.CropParameter.offset\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6618,\n  serialized_end=6666,\n)\n\n\n_DATAPARAMETER = _descriptor.Descriptor(\n  name=\'DataParameter\',\n  full_name=\'caffe.DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.DataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.DataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'backend\', full_name=\'caffe.DataParameter.backend\', index=3,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.DataParameter.scale\', index=4,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.DataParameter.mean_file\', index=5,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.DataParameter.crop_size\', index=6,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.DataParameter.mirror\', index=7,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_encoded_color\', full_name=\'caffe.DataParameter.force_encoded_color\', index=8,\n      number=9, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'prefetch\', full_name=\'caffe.DataParameter.prefetch\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=4,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _DATAPARAMETER_DB,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6669,\n  serialized_end=6961,\n)\n\n\n_DROPOUTPARAMETER = _descriptor.Descriptor(\n  name=\'DropoutParameter\',\n  full_name=\'caffe.DropoutParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.DropoutParameter.dropout_ratio\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6963,\n  serialized_end=7009,\n)\n\n\n_DUMMYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'DummyDataParameter\',\n  full_name=\'caffe.DummyDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'data_filler\', full_name=\'caffe.DummyDataParameter.data_filler\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.DummyDataParameter.shape\', index=1,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.DummyDataParameter.num\', index=2,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.DummyDataParameter.channels\', index=3,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.DummyDataParameter.height\', index=4,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.DummyDataParameter.width\', index=5,\n      number=5, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7012,\n  serialized_end=7172,\n)\n\n\n_ELTWISEPARAMETER = _descriptor.Descriptor(\n  name=\'EltwiseParameter\',\n  full_name=\'caffe.EltwiseParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.EltwiseParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.EltwiseParameter.coeff\', index=1,\n      number=2, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stable_prod_grad\', full_name=\'caffe.EltwiseParameter.stable_prod_grad\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _ELTWISEPARAMETER_ELTWISEOP,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7175,\n  serialized_end=7340,\n)\n\n\n_ELUPARAMETER = _descriptor.Descriptor(\n  name=\'ELUParameter\',\n  full_name=\'caffe.ELUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.ELUParameter.alpha\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7342,\n  serialized_end=7374,\n)\n\n\n_EMBEDPARAMETER = _descriptor.Descriptor(\n  name=\'EmbedParameter\',\n  full_name=\'caffe.EmbedParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.EmbedParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.EmbedParameter.input_dim\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.EmbedParameter.bias_term\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.EmbedParameter.weight_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.EmbedParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7377,\n  serialized_end=7549,\n)\n\n\n_EXPPARAMETER = _descriptor.Descriptor(\n  name=\'ExpParameter\',\n  full_name=\'caffe.ExpParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.ExpParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ExpParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.ExpParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7551,\n  serialized_end=7619,\n)\n\n\n_FLATTENPARAMETER = _descriptor.Descriptor(\n  name=\'FlattenParameter\',\n  full_name=\'caffe.FlattenParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.FlattenParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'end_axis\', full_name=\'caffe.FlattenParameter.end_axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7621,\n  serialized_end=7678,\n)\n\n\n_HDF5DATAPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5DataParameter\',\n  full_name=\'caffe.HDF5DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.HDF5DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.HDF5DataParameter.batch_size\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.HDF5DataParameter.shuffle\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7680,\n  serialized_end=7759,\n)\n\n\n_HDF5OUTPUTPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5OutputParameter\',\n  full_name=\'caffe.HDF5OutputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'file_name\', full_name=\'caffe.HDF5OutputParameter.file_name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7761,\n  serialized_end=7801,\n)\n\n\n_HINGELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'HingeLossParameter\',\n  full_name=\'caffe.HingeLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'norm\', full_name=\'caffe.HingeLossParameter.norm\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _HINGELOSSPARAMETER_NORM,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7803,\n  serialized_end=7897,\n)\n\n\n_IMAGEDATAPARAMETER = _descriptor.Descriptor(\n  name=\'ImageDataParameter\',\n  full_name=\'caffe.ImageDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.ImageDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.ImageDataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.ImageDataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.ImageDataParameter.shuffle\', index=3,\n      number=8, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.ImageDataParameter.new_height\', index=4,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.ImageDataParameter.new_width\', index=5,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'is_color\', full_name=\'caffe.ImageDataParameter.is_color\', index=6,\n      number=11, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ImageDataParameter.scale\', index=7,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.ImageDataParameter.mean_file\', index=8,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.ImageDataParameter.crop_size\', index=9,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.ImageDataParameter.mirror\', index=10,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.ImageDataParameter.root_folder\', index=11,\n      number=12, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7900,\n  serialized_end=8179,\n)\n\n\n_INFOGAINLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'InfogainLossParameter\',\n  full_name=\'caffe.InfogainLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.InfogainLossParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8181,\n  serialized_end=8220,\n)\n\n\n_INNERPRODUCTPARAMETER = _descriptor.Descriptor(\n  name=\'InnerProductParameter\',\n  full_name=\'caffe.InnerProductParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.InnerProductParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.InnerProductParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.InnerProductParameter.weight_filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.InnerProductParameter.bias_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.InnerProductParameter.axis\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transpose\', full_name=\'caffe.InnerProductParameter.transpose\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8223,\n  serialized_end=8426,\n)\n\n\n_INPUTPARAMETER = _descriptor.Descriptor(\n  name=\'InputParameter\',\n  full_name=\'caffe.InputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.InputParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8428,\n  serialized_end=8477,\n)\n\n\n_LOGPARAMETER = _descriptor.Descriptor(\n  name=\'LogParameter\',\n  full_name=\'caffe.LogParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.LogParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.LogParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.LogParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8479,\n  serialized_end=8547,\n)\n\n\n_LRNPARAMETER = _descriptor.Descriptor(\n  name=\'LRNParameter\',\n  full_name=\'caffe.LRNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.LRNParameter.local_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.LRNParameter.alpha\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.LRNParameter.beta\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.75,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'norm_region\', full_name=\'caffe.LRNParameter.norm_region\', index=3,\n      number=4, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.LRNParameter.k\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.LRNParameter.engine\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LRNPARAMETER_NORMREGION,\n    _LRNPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8550,\n  serialized_end=8862,\n)\n\n\n_MEMORYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'MemoryDataParameter\',\n  full_name=\'caffe.MemoryDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.MemoryDataParameter.batch_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.MemoryDataParameter.channels\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.MemoryDataParameter.height\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.MemoryDataParameter.width\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8864,\n  serialized_end=8954,\n)\n\n\n_MVNPARAMETER = _descriptor.Descriptor(\n  name=\'MVNParameter\',\n  full_name=\'caffe.MVNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'normalize_variance\', full_name=\'caffe.MVNParameter.normalize_variance\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'across_channels\', full_name=\'caffe.MVNParameter.across_channels\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.MVNParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1e-09,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8956,\n  serialized_end=9056,\n)\n\n\n_POOLINGPARAMETER = _descriptor.Descriptor(\n  name=\'PoolingParameter\',\n  full_name=\'caffe.PoolingParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.PoolingParameter.pool\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.PoolingParameter.pad\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.PoolingParameter.pad_h\', index=2,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.PoolingParameter.pad_w\', index=3,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.PoolingParameter.kernel_size\', index=4,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.PoolingParameter.kernel_h\', index=5,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.PoolingParameter.kernel_w\', index=6,\n      number=6, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.PoolingParameter.stride\', index=7,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.PoolingParameter.stride_h\', index=8,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.PoolingParameter.stride_w\', index=9,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.PoolingParameter.engine\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'global_pooling\', full_name=\'caffe.PoolingParameter.global_pooling\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _POOLINGPARAMETER_POOLMETHOD,\n    _POOLINGPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9059,\n  serialized_end=9477,\n)\n\n\n_POWERPARAMETER = _descriptor.Descriptor(\n  name=\'PowerParameter\',\n  full_name=\'caffe.PowerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.PowerParameter.power\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.PowerParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.PowerParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9479,\n  serialized_end=9549,\n)\n\n\n_PYTHONPARAMETER = _descriptor.Descriptor(\n  name=\'PythonParameter\',\n  full_name=\'caffe.PythonParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'module\', full_name=\'caffe.PythonParameter.module\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.PythonParameter.layer\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param_str\', full_name=\'caffe.PythonParameter.param_str\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'share_in_parallel\', full_name=\'caffe.PythonParameter.share_in_parallel\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9551,\n  serialized_end=9654,\n)\n\n\n_REDUCTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ReductionParameter\',\n  full_name=\'caffe.ReductionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.ReductionParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReductionParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.ReductionParameter.coeff\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _REDUCTIONPARAMETER_REDUCTIONOP,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9657,\n  serialized_end=9830,\n)\n\n\n_RELUPARAMETER = _descriptor.Descriptor(\n  name=\'ReLUParameter\',\n  full_name=\'caffe.ReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'negative_slope\', full_name=\'caffe.ReLUParameter.negative_slope\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ReLUParameter.engine\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _RELUPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9833,\n  serialized_end=9974,\n)\n\n\n_RESHAPEPARAMETER = _descriptor.Descriptor(\n  name=\'ReshapeParameter\',\n  full_name=\'caffe.ReshapeParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.ReshapeParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReshapeParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ReshapeParameter.num_axes\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9976,\n  serialized_end=10066,\n)\n\n\n_SCALEPARAMETER = _descriptor.Descriptor(\n  name=\'ScaleParameter\',\n  full_name=\'caffe.ScaleParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ScaleParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ScaleParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.ScaleParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ScaleParameter.bias_term\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ScaleParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10069,\n  serialized_end=10234,\n)\n\n\n_SIGMOIDPARAMETER = _descriptor.Descriptor(\n  name=\'SigmoidParameter\',\n  full_name=\'caffe.SigmoidParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SigmoidParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SIGMOIDPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10236,\n  serialized_end=10356,\n)\n\n\n_SLICEPARAMETER = _descriptor.Descriptor(\n  name=\'SliceParameter\',\n  full_name=\'caffe.SliceParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SliceParameter.axis\', index=0,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_point\', full_name=\'caffe.SliceParameter.slice_point\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_dim\', full_name=\'caffe.SliceParameter.slice_dim\', index=2,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10358,\n  serialized_end=10434,\n)\n\n\n_SOFTMAXPARAMETER = _descriptor.Descriptor(\n  name=\'SoftmaxParameter\',\n  full_name=\'caffe.SoftmaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SoftmaxParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SoftmaxParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOFTMAXPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10437,\n  serialized_end=10574,\n)\n\n\n_TANHPARAMETER = _descriptor.Descriptor(\n  name=\'TanHParameter\',\n  full_name=\'caffe.TanHParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.TanHParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _TANHPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10576,\n  serialized_end=10690,\n)\n\n\n_TILEPARAMETER = _descriptor.Descriptor(\n  name=\'TileParameter\',\n  full_name=\'caffe.TileParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.TileParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tiles\', full_name=\'caffe.TileParameter.tiles\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10692,\n  serialized_end=10739,\n)\n\n\n_THRESHOLDPARAMETER = _descriptor.Descriptor(\n  name=\'ThresholdParameter\',\n  full_name=\'caffe.ThresholdParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'threshold\', full_name=\'caffe.ThresholdParameter.threshold\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10741,\n  serialized_end=10783,\n)\n\n\n_WINDOWDATAPARAMETER = _descriptor.Descriptor(\n  name=\'WindowDataParameter\',\n  full_name=\'caffe.WindowDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.WindowDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.WindowDataParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.WindowDataParameter.mean_file\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.WindowDataParameter.batch_size\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.WindowDataParameter.crop_size\', index=4,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.WindowDataParameter.mirror\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_threshold\', full_name=\'caffe.WindowDataParameter.fg_threshold\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bg_threshold\', full_name=\'caffe.WindowDataParameter.bg_threshold\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_fraction\', full_name=\'caffe.WindowDataParameter.fg_fraction\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.25,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'context_pad\', full_name=\'caffe.WindowDataParameter.context_pad\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_mode\', full_name=\'caffe.WindowDataParameter.crop_mode\', index=10,\n      number=11, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""warp"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'cache_images\', full_name=\'caffe.WindowDataParameter.cache_images\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.WindowDataParameter.root_folder\', index=12,\n      number=13, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10786,\n  serialized_end=11107,\n)\n\n\n_SPPPARAMETER = _descriptor.Descriptor(\n  name=\'SPPParameter\',\n  full_name=\'caffe.SPPParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pyramid_height\', full_name=\'caffe.SPPParameter.pyramid_height\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.SPPParameter.pool\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SPPParameter.engine\', index=2,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SPPPARAMETER_POOLMETHOD,\n    _SPPPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=11110,\n  serialized_end=11345,\n)\n\n\n_V1LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V1LayerParameter\',\n  full_name=\'caffe.V1LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.V1LayerParameter.bottom\', index=0,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.V1LayerParameter.top\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V1LayerParameter.name\', index=2,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.V1LayerParameter.include\', index=3,\n      number=32, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.V1LayerParameter.exclude\', index=4,\n      number=33, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V1LayerParameter.type\', index=5,\n      number=5, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V1LayerParameter.blobs\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.V1LayerParameter.param\', index=7,\n      number=1001, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blob_share_mode\', full_name=\'caffe.V1LayerParameter.blob_share_mode\', index=8,\n      number=1002, type=14, cpp_type=8, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V1LayerParameter.blobs_lr\', index=9,\n      number=7, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V1LayerParameter.weight_decay\', index=10,\n      number=8, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.V1LayerParameter.loss_weight\', index=11,\n      number=35, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.V1LayerParameter.accuracy_param\', index=12,\n      number=27, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.V1LayerParameter.argmax_param\', index=13,\n      number=23, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.V1LayerParameter.concat_param\', index=14,\n      number=9, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.V1LayerParameter.contrastive_loss_param\', index=15,\n      number=40, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.V1LayerParameter.convolution_param\', index=16,\n      number=10, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.V1LayerParameter.data_param\', index=17,\n      number=11, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.V1LayerParameter.dropout_param\', index=18,\n      number=12, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.V1LayerParameter.dummy_data_param\', index=19,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.V1LayerParameter.eltwise_param\', index=20,\n      number=24, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.V1LayerParameter.exp_param\', index=21,\n      number=41, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.V1LayerParameter.hdf5_data_param\', index=22,\n      number=13, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V1LayerParameter.hdf5_output_param\', index=23,\n      number=14, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.V1LayerParameter.hinge_loss_param\', index=24,\n      number=29, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.V1LayerParameter.image_data_param\', index=25,\n      number=15, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.V1LayerParameter.infogain_loss_param\', index=26,\n      number=16, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.V1LayerParameter.inner_product_param\', index=27,\n      number=17, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.V1LayerParameter.lrn_param\', index=28,\n      number=18, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.V1LayerParameter.memory_data_param\', index=29,\n      number=22, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.V1LayerParameter.mvn_param\', index=30,\n      number=34, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.V1LayerParameter.pooling_param\', index=31,\n      number=19, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.V1LayerParameter.power_param\', index=32,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.V1LayerParameter.relu_param\', index=33,\n      number=30, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.V1LayerParameter.sigmoid_param\', index=34,\n      number=38, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.V1LayerParameter.softmax_param\', index=35,\n      number=39, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.V1LayerParameter.slice_param\', index=36,\n      number=31, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.V1LayerParameter.tanh_param\', index=37,\n      number=37, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.V1LayerParameter.threshold_param\', index=38,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.V1LayerParameter.window_data_param\', index=39,\n      number=20, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.V1LayerParameter.transform_param\', index=40,\n      number=36, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.V1LayerParameter.loss_param\', index=41,\n      number=42, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.V1LayerParameter.layer\', index=42,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V1LAYERPARAMETER_LAYERTYPE,\n    _V1LAYERPARAMETER_DIMCHECKMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=11348,\n  serialized_end=13876,\n)\n\n\n_V0LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V0LayerParameter\',\n  full_name=\'caffe.V0LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V0LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V0LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.V0LayerParameter.num_output\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'biasterm\', full_name=\'caffe.V0LayerParameter.biasterm\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.V0LayerParameter.weight_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.V0LayerParameter.bias_filler\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.V0LayerParameter.pad\', index=6,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernelsize\', full_name=\'caffe.V0LayerParameter.kernelsize\', index=7,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.V0LayerParameter.group\', index=8,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.V0LayerParameter.stride\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.V0LayerParameter.pool\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.V0LayerParameter.dropout_ratio\', index=11,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.V0LayerParameter.local_size\', index=12,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.V0LayerParameter.alpha\', index=13,\n      number=14, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.V0LayerParameter.beta\', index=14,\n      number=15, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.75,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.V0LayerParameter.k\', index=15,\n      number=22, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.V0LayerParameter.source\', index=16,\n      number=16, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.V0LayerParameter.scale\', index=17,\n      number=17, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'meanfile\', full_name=\'caffe.V0LayerParameter.meanfile\', index=18,\n      number=18, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batchsize\', full_name=\'caffe.V0LayerParameter.batchsize\', index=19,\n      number=19, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'cropsize\', full_name=\'caffe.V0LayerParameter.cropsize\', index=20,\n      number=20, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.V0LayerParameter.mirror\', index=21,\n      number=21, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V0LayerParameter.blobs\', index=22,\n      number=50, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V0LayerParameter.blobs_lr\', index=23,\n      number=51, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V0LayerParameter.weight_decay\', index=24,\n      number=52, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.V0LayerParameter.rand_skip\', index=25,\n      number=53, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_threshold\', full_name=\'caffe.V0LayerParameter.det_fg_threshold\', index=26,\n      number=54, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_bg_threshold\', full_name=\'caffe.V0LayerParameter.det_bg_threshold\', index=27,\n      number=55, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_fraction\', full_name=\'caffe.V0LayerParameter.det_fg_fraction\', index=28,\n      number=56, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.25,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_context_pad\', full_name=\'caffe.V0LayerParameter.det_context_pad\', index=29,\n      number=58, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_crop_mode\', full_name=\'caffe.V0LayerParameter.det_crop_mode\', index=30,\n      number=59, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""warp"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_num\', full_name=\'caffe.V0LayerParameter.new_num\', index=31,\n      number=60, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_channels\', full_name=\'caffe.V0LayerParameter.new_channels\', index=32,\n      number=61, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.V0LayerParameter.new_height\', index=33,\n      number=62, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.V0LayerParameter.new_width\', index=34,\n      number=63, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle_images\', full_name=\'caffe.V0LayerParameter.shuffle_images\', index=35,\n      number=64, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.V0LayerParameter.concat_dim\', index=36,\n      number=65, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V0LayerParameter.hdf5_output_param\', index=37,\n      number=1001, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V0LAYERPARAMETER_POOLMETHOD,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=13879,\n  serialized_end=14900,\n)\n\n\n_PRELUPARAMETER = _descriptor.Descriptor(\n  name=\'PReLUParameter\',\n  full_name=\'caffe.PReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.PReLUParameter.filler\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channel_shared\', full_name=\'caffe.PReLUParameter.channel_shared\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=14902,\n  serialized_end=14989,\n)\n\n_BLOBPROTO.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_BLOBPROTOVECTOR.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_FILLERPARAMETER.fields_by_name[\'variance_norm\'].enum_type = _FILLERPARAMETER_VARIANCENORM\n_FILLERPARAMETER_VARIANCENORM.containing_type = _FILLERPARAMETER;\n_NETPARAMETER.fields_by_name[\'input_shape\'].message_type = _BLOBSHAPE\n_NETPARAMETER.fields_by_name[\'state\'].message_type = _NETSTATE\n_NETPARAMETER.fields_by_name[\'layer\'].message_type = _LAYERPARAMETER\n_NETPARAMETER.fields_by_name[\'layers\'].message_type = _V1LAYERPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'test_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'test_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'snapshot_format\'].enum_type = _SOLVERPARAMETER_SNAPSHOTFORMAT\n_SOLVERPARAMETER.fields_by_name[\'solver_mode\'].enum_type = _SOLVERPARAMETER_SOLVERMODE\n_SOLVERPARAMETER.fields_by_name[\'solver_type\'].enum_type = _SOLVERPARAMETER_SOLVERTYPE\n_SOLVERPARAMETER_SNAPSHOTFORMAT.containing_type = _SOLVERPARAMETER;\n_SOLVERPARAMETER_SOLVERMODE.containing_type = _SOLVERPARAMETER;\n_SOLVERPARAMETER_SOLVERTYPE.containing_type = _SOLVERPARAMETER;\n_SOLVERSTATE.fields_by_name[\'history\'].message_type = _BLOBPROTO\n_NETSTATE.fields_by_name[\'phase\'].enum_type = _PHASE\n_NETSTATERULE.fields_by_name[\'phase\'].enum_type = _PHASE\n_PARAMSPEC.fields_by_name[\'share_mode\'].enum_type = _PARAMSPEC_DIMCHECKMODE\n_PARAMSPEC_DIMCHECKMODE.containing_type = _PARAMSPEC;\n_LAYERPARAMETER.fields_by_name[\'phase\'].enum_type = _PHASE\n_LAYERPARAMETER.fields_by_name[\'param\'].message_type = _PARAMSPEC\n_LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'batch_norm_param\'].message_type = _BATCHNORMPARAMETER\n_LAYERPARAMETER.fields_by_name[\'bias_param\'].message_type = _BIASPARAMETER\n_LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'crop_param\'].message_type = _CROPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'elu_param\'].message_type = _ELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'embed_param\'].message_type = _EMBEDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'flatten_param\'].message_type = _FLATTENPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'input_param\'].message_type = _INPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'log_param\'].message_type = _LOGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_LAYERPARAMETER.fields_by_name[\'prelu_param\'].message_type = _PRELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'python_param\'].message_type = _PYTHONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reduction_param\'].message_type = _REDUCTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reshape_param\'].message_type = _RESHAPEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'scale_param\'].message_type = _SCALEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'spp_param\'].message_type = _SPPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tile_param\'].message_type = _TILEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_LOSSPARAMETER.fields_by_name[\'normalization\'].enum_type = _LOSSPARAMETER_NORMALIZATIONMODE\n_LOSSPARAMETER_NORMALIZATIONMODE.containing_type = _LOSSPARAMETER;\n_BIASPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'engine\'].enum_type = _CONVOLUTIONPARAMETER_ENGINE\n_CONVOLUTIONPARAMETER_ENGINE.containing_type = _CONVOLUTIONPARAMETER;\n_DATAPARAMETER.fields_by_name[\'backend\'].enum_type = _DATAPARAMETER_DB\n_DATAPARAMETER_DB.containing_type = _DATAPARAMETER;\n_DUMMYDATAPARAMETER.fields_by_name[\'data_filler\'].message_type = _FILLERPARAMETER\n_DUMMYDATAPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_ELTWISEPARAMETER.fields_by_name[\'operation\'].enum_type = _ELTWISEPARAMETER_ELTWISEOP\n_ELTWISEPARAMETER_ELTWISEOP.containing_type = _ELTWISEPARAMETER;\n_EMBEDPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_EMBEDPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_HINGELOSSPARAMETER.fields_by_name[\'norm\'].enum_type = _HINGELOSSPARAMETER_NORM\n_HINGELOSSPARAMETER_NORM.containing_type = _HINGELOSSPARAMETER;\n_INNERPRODUCTPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_INNERPRODUCTPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_INPUTPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_LRNPARAMETER.fields_by_name[\'norm_region\'].enum_type = _LRNPARAMETER_NORMREGION\n_LRNPARAMETER.fields_by_name[\'engine\'].enum_type = _LRNPARAMETER_ENGINE\n_LRNPARAMETER_NORMREGION.containing_type = _LRNPARAMETER;\n_LRNPARAMETER_ENGINE.containing_type = _LRNPARAMETER;\n_POOLINGPARAMETER.fields_by_name[\'pool\'].enum_type = _POOLINGPARAMETER_POOLMETHOD\n_POOLINGPARAMETER.fields_by_name[\'engine\'].enum_type = _POOLINGPARAMETER_ENGINE\n_POOLINGPARAMETER_POOLMETHOD.containing_type = _POOLINGPARAMETER;\n_POOLINGPARAMETER_ENGINE.containing_type = _POOLINGPARAMETER;\n_REDUCTIONPARAMETER.fields_by_name[\'operation\'].enum_type = _REDUCTIONPARAMETER_REDUCTIONOP\n_REDUCTIONPARAMETER_REDUCTIONOP.containing_type = _REDUCTIONPARAMETER;\n_RELUPARAMETER.fields_by_name[\'engine\'].enum_type = _RELUPARAMETER_ENGINE\n_RELUPARAMETER_ENGINE.containing_type = _RELUPARAMETER;\n_RESHAPEPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_SCALEPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_SCALEPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_SIGMOIDPARAMETER.fields_by_name[\'engine\'].enum_type = _SIGMOIDPARAMETER_ENGINE\n_SIGMOIDPARAMETER_ENGINE.containing_type = _SIGMOIDPARAMETER;\n_SOFTMAXPARAMETER.fields_by_name[\'engine\'].enum_type = _SOFTMAXPARAMETER_ENGINE\n_SOFTMAXPARAMETER_ENGINE.containing_type = _SOFTMAXPARAMETER;\n_TANHPARAMETER.fields_by_name[\'engine\'].enum_type = _TANHPARAMETER_ENGINE\n_TANHPARAMETER_ENGINE.containing_type = _TANHPARAMETER;\n_SPPPARAMETER.fields_by_name[\'pool\'].enum_type = _SPPPARAMETER_POOLMETHOD\n_SPPPARAMETER.fields_by_name[\'engine\'].enum_type = _SPPPARAMETER_ENGINE\n_SPPPARAMETER_POOLMETHOD.containing_type = _SPPPARAMETER;\n_SPPPARAMETER_ENGINE.containing_type = _SPPPARAMETER;\n_V1LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'type\'].enum_type = _V1LAYERPARAMETER_LAYERTYPE\n_V1LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V1LAYERPARAMETER.fields_by_name[\'blob_share_mode\'].enum_type = _V1LAYERPARAMETER_DIMCHECKMODE\n_V1LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'layer\'].message_type = _V0LAYERPARAMETER\n_V1LAYERPARAMETER_LAYERTYPE.containing_type = _V1LAYERPARAMETER;\n_V1LAYERPARAMETER_DIMCHECKMODE.containing_type = _V1LAYERPARAMETER;\n_V0LAYERPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'pool\'].enum_type = _V0LAYERPARAMETER_POOLMETHOD\n_V0LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V0LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V0LAYERPARAMETER_POOLMETHOD.containing_type = _V0LAYERPARAMETER;\n_PRELUPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'BlobShape\'] = _BLOBSHAPE\nDESCRIPTOR.message_types_by_name[\'BlobProto\'] = _BLOBPROTO\nDESCRIPTOR.message_types_by_name[\'BlobProtoVector\'] = _BLOBPROTOVECTOR\nDESCRIPTOR.message_types_by_name[\'Datum\'] = _DATUM\nDESCRIPTOR.message_types_by_name[\'FillerParameter\'] = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'NetParameter\'] = _NETPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverParameter\'] = _SOLVERPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverState\'] = _SOLVERSTATE\nDESCRIPTOR.message_types_by_name[\'NetState\'] = _NETSTATE\nDESCRIPTOR.message_types_by_name[\'NetStateRule\'] = _NETSTATERULE\nDESCRIPTOR.message_types_by_name[\'ParamSpec\'] = _PARAMSPEC\nDESCRIPTOR.message_types_by_name[\'LayerParameter\'] = _LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'TransformationParameter\'] = _TRANSFORMATIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'LossParameter\'] = _LOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'AccuracyParameter\'] = _ACCURACYPARAMETER\nDESCRIPTOR.message_types_by_name[\'ArgMaxParameter\'] = _ARGMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConcatParameter\'] = _CONCATPARAMETER\nDESCRIPTOR.message_types_by_name[\'BatchNormParameter\'] = _BATCHNORMPARAMETER\nDESCRIPTOR.message_types_by_name[\'BiasParameter\'] = _BIASPARAMETER\nDESCRIPTOR.message_types_by_name[\'ContrastiveLossParameter\'] = _CONTRASTIVELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConvolutionParameter\'] = _CONVOLUTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'CropParameter\'] = _CROPPARAMETER\nDESCRIPTOR.message_types_by_name[\'DataParameter\'] = _DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'DropoutParameter\'] = _DROPOUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'DummyDataParameter\'] = _DUMMYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'EltwiseParameter\'] = _ELTWISEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ELUParameter\'] = _ELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'EmbedParameter\'] = _EMBEDPARAMETER\nDESCRIPTOR.message_types_by_name[\'ExpParameter\'] = _EXPPARAMETER\nDESCRIPTOR.message_types_by_name[\'FlattenParameter\'] = _FLATTENPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5DataParameter\'] = _HDF5DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5OutputParameter\'] = _HDF5OUTPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'HingeLossParameter\'] = _HINGELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ImageDataParameter\'] = _IMAGEDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'InfogainLossParameter\'] = _INFOGAINLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'InnerProductParameter\'] = _INNERPRODUCTPARAMETER\nDESCRIPTOR.message_types_by_name[\'InputParameter\'] = _INPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'LogParameter\'] = _LOGPARAMETER\nDESCRIPTOR.message_types_by_name[\'LRNParameter\'] = _LRNPARAMETER\nDESCRIPTOR.message_types_by_name[\'MemoryDataParameter\'] = _MEMORYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'MVNParameter\'] = _MVNPARAMETER\nDESCRIPTOR.message_types_by_name[\'PoolingParameter\'] = _POOLINGPARAMETER\nDESCRIPTOR.message_types_by_name[\'PowerParameter\'] = _POWERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PythonParameter\'] = _PYTHONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReductionParameter\'] = _REDUCTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReLUParameter\'] = _RELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReshapeParameter\'] = _RESHAPEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ScaleParameter\'] = _SCALEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SigmoidParameter\'] = _SIGMOIDPARAMETER\nDESCRIPTOR.message_types_by_name[\'SliceParameter\'] = _SLICEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SoftmaxParameter\'] = _SOFTMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'TanHParameter\'] = _TANHPARAMETER\nDESCRIPTOR.message_types_by_name[\'TileParameter\'] = _TILEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ThresholdParameter\'] = _THRESHOLDPARAMETER\nDESCRIPTOR.message_types_by_name[\'WindowDataParameter\'] = _WINDOWDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'SPPParameter\'] = _SPPPARAMETER\nDESCRIPTOR.message_types_by_name[\'V1LayerParameter\'] = _V1LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'V0LayerParameter\'] = _V0LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PReLUParameter\'] = _PRELUPARAMETER\n\nclass BlobShape(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BLOBSHAPE\n\n  # @@protoc_insertion_point(class_scope:caffe.BlobShape)\n\nclass BlobProto(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BLOBPROTO\n\n  # @@protoc_insertion_point(class_scope:caffe.BlobProto)\n\nclass BlobProtoVector(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BLOBPROTOVECTOR\n\n  # @@protoc_insertion_point(class_scope:caffe.BlobProtoVector)\n\nclass Datum(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DATUM\n\n  # @@protoc_insertion_point(class_scope:caffe.Datum)\n\nclass FillerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _FILLERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.FillerParameter)\n\nclass NetParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _NETPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.NetParameter)\n\nclass SolverParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SOLVERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SolverParameter)\n\nclass SolverState(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SOLVERSTATE\n\n  # @@protoc_insertion_point(class_scope:caffe.SolverState)\n\nclass NetState(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _NETSTATE\n\n  # @@protoc_insertion_point(class_scope:caffe.NetState)\n\nclass NetStateRule(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _NETSTATERULE\n\n  # @@protoc_insertion_point(class_scope:caffe.NetStateRule)\n\nclass ParamSpec(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _PARAMSPEC\n\n  # @@protoc_insertion_point(class_scope:caffe.ParamSpec)\n\nclass LayerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LAYERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LayerParameter)\n\nclass TransformationParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _TRANSFORMATIONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.TransformationParameter)\n\nclass LossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LossParameter)\n\nclass AccuracyParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ACCURACYPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.AccuracyParameter)\n\nclass ArgMaxParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ARGMAXPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ArgMaxParameter)\n\nclass ConcatParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CONCATPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ConcatParameter)\n\nclass BatchNormParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BATCHNORMPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.BatchNormParameter)\n\nclass BiasParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BIASPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.BiasParameter)\n\nclass ContrastiveLossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CONTRASTIVELOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ContrastiveLossParameter)\n\nclass ConvolutionParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CONVOLUTIONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ConvolutionParameter)\n\nclass CropParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CROPPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.CropParameter)\n\nclass DataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.DataParameter)\n\nclass DropoutParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DROPOUTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.DropoutParameter)\n\nclass DummyDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DUMMYDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.DummyDataParameter)\n\nclass EltwiseParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ELTWISEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.EltwiseParameter)\n\nclass ELUParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ELUPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ELUParameter)\n\nclass EmbedParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _EMBEDPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.EmbedParameter)\n\nclass ExpParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _EXPPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ExpParameter)\n\nclass FlattenParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _FLATTENPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.FlattenParameter)\n\nclass HDF5DataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _HDF5DATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.HDF5DataParameter)\n\nclass HDF5OutputParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _HDF5OUTPUTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.HDF5OutputParameter)\n\nclass HingeLossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _HINGELOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.HingeLossParameter)\n\nclass ImageDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _IMAGEDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ImageDataParameter)\n\nclass InfogainLossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _INFOGAINLOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.InfogainLossParameter)\n\nclass InnerProductParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _INNERPRODUCTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.InnerProductParameter)\n\nclass InputParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _INPUTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.InputParameter)\n\nclass LogParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LOGPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LogParameter)\n\nclass LRNParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LRNPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LRNParameter)\n\nclass MemoryDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _MEMORYDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.MemoryDataParameter)\n\nclass MVNParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _MVNPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.MVNParameter)\n\nclass PoolingParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _POOLINGPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PoolingParameter)\n\nclass PowerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _POWERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PowerParameter)\n\nclass PythonParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _PYTHONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PythonParameter)\n\nclass ReductionParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _REDUCTIONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ReductionParameter)\n\nclass ReLUParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _RELUPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ReLUParameter)\n\nclass ReshapeParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _RESHAPEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ReshapeParameter)\n\nclass ScaleParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SCALEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ScaleParameter)\n\nclass SigmoidParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SIGMOIDPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SigmoidParameter)\n\nclass SliceParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SLICEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SliceParameter)\n\nclass SoftmaxParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SOFTMAXPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SoftmaxParameter)\n\nclass TanHParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _TANHPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.TanHParameter)\n\nclass TileParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _TILEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.TileParameter)\n\nclass ThresholdParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _THRESHOLDPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ThresholdParameter)\n\nclass WindowDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _WINDOWDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.WindowDataParameter)\n\nclass SPPParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SPPPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SPPParameter)\n\nclass V1LayerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _V1LAYERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.V1LayerParameter)\n\nclass V0LayerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _V0LAYERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.V0LayerParameter)\n\nclass PReLUParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _PRELUPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PReLUParameter)\n\n\n_BLOBSHAPE.fields_by_name[\'dim\'].has_options = True\n_BLOBSHAPE.fields_by_name[\'dim\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'data\'].has_options = True\n_BLOBPROTO.fields_by_name[\'data\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'diff\'].has_options = True\n_BLOBPROTO.fields_by_name[\'diff\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'double_data\'].has_options = True\n_BLOBPROTO.fields_by_name[\'double_data\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'double_diff\'].has_options = True\n_BLOBPROTO.fields_by_name[\'double_diff\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n# @@protoc_insertion_point(module_scope)\n'"
kaffe/caffe/resolver.py,0,"b""import sys\n\nSHARED_CAFFE_RESOLVER = None\n\nclass CaffeResolver(object):\n    def __init__(self):\n        self.import_caffe()\n\n    def import_caffe(self):\n        self.caffe = None\n        try:\n            # Try to import PyCaffe first\n            import caffe\n            self.caffe = caffe\n        except ImportError:\n            # Fall back to the protobuf implementation\n            from . import caffepb\n            self.caffepb = caffepb\n            show_fallback_warning()\n        if self.caffe:\n            # Use the protobuf code from the imported distribution.\n            # This way, Caffe variants with custom layers will work.\n            self.caffepb = self.caffe.proto.caffe_pb2\n        self.NetParameter = self.caffepb.NetParameter\n\n    def has_pycaffe(self):\n        return self.caffe is not None\n\ndef get_caffe_resolver():\n    global SHARED_CAFFE_RESOLVER\n    if SHARED_CAFFE_RESOLVER is None:\n        SHARED_CAFFE_RESOLVER = CaffeResolver()\n    return SHARED_CAFFE_RESOLVER\n\ndef has_pycaffe():\n    return get_caffe_resolver().has_pycaffe()\n\ndef show_fallback_warning():\n    msg = '''\n------------------------------------------------------------\n    WARNING: PyCaffe not found!\n    Falling back to a pure protocol buffer implementation.\n    * Conversions will be drastically slower.\n    * This backend is UNTESTED!\n------------------------------------------------------------\n\n'''\n    sys.stderr.write(msg)\n"""
kaffe/tensorflow/__init__.py,0,b'from .transformer import TensorFlowTransformer\nfrom .network import Network\n'
kaffe/tensorflow/network.py,32,"b""import numpy as np\nimport tensorflow as tf\nslim = tf.contrib.slim\n\nDEFAULT_PADDING = 'SAME'\n\n\ndef layer(op):\n    '''Decorator for composable network layers.'''\n\n    def layer_decorated(self, *args, **kwargs):\n        # Automatically set a name if not provided.\n        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n        # Figure out the layer inputs.\n        if len(self.terminals) == 0:\n            raise RuntimeError('No input variables found for layer %s.' % name)\n        elif len(self.terminals) == 1:\n            layer_input = self.terminals[0]\n        else:\n            layer_input = list(self.terminals)\n        # Perform the operation and get the output.\n        layer_output = op(self, layer_input, *args, **kwargs)\n        # Add to layer LUT.\n        self.layers[name] = layer_output\n        # This output is now the input for the next layer.\n        self.feed(layer_output)\n        # Return self for chained calls.\n        return self\n\n    return layer_decorated\n\n\nclass Network(object):\n\n    def __init__(self, inputs, trainable=True, is_training=False, num_classes=21):\n        # The input nodes for this network\n        self.inputs = inputs\n        # The current list of terminal nodes\n        self.terminals = []\n        # Mapping from layer names to layers\n        self.layers = dict(inputs)\n        # If true, the resulting variables are set as trainable\n        self.trainable = trainable\n        # Switch variable for dropout\n        self.use_dropout = tf.placeholder_with_default(tf.constant(1.0),\n                                                       shape=[],\n                                                       name='use_dropout')\n        self.setup(is_training, num_classes)\n\n    def setup(self, is_training):\n        '''Construct the network. '''\n        raise NotImplementedError('Must be implemented by the subclass.')\n\n    def load(self, data_path, session, ignore_missing=False):\n        '''Load network weights.\n        data_path: The path to the numpy-serialized network weights\n        session: The current TensorFlow session\n        ignore_missing: If true, serialized weights for missing layers are ignored.\n        '''\n        data_dict = np.load(data_path).item()\n        for op_name in data_dict:\n            with tf.variable_scope(op_name, reuse=True):\n                for param_name, data in data_dict[op_name].iteritems():\n                    try:\n                        var = tf.get_variable(param_name)\n                        session.run(var.assign(data))\n                    except ValueError:\n                        if not ignore_missing:\n                            raise\n\n    def feed(self, *args):\n        '''Set the input(s) for the next operation by replacing the terminal nodes.\n        The arguments can be either layer names or the actual layers.\n        '''\n        assert len(args) != 0\n        self.terminals = []\n        for fed_layer in args:\n            if isinstance(fed_layer, basestring):\n                try:\n                    fed_layer = self.layers[fed_layer]\n                except KeyError:\n                    raise KeyError('Unknown layer name fed: %s' % fed_layer)\n            self.terminals.append(fed_layer)\n        return self\n\n    def get_output(self):\n        '''Returns the current network output.'''\n        return self.terminals[-1]\n\n    def get_unique_name(self, prefix):\n        '''Returns an index-suffixed unique name for the given prefix.\n        This is used for auto-generating layer names based on the type-prefix.\n        '''\n        ident = sum(t.startswith(prefix) for t, _ in self.layers.items()) + 1\n        return '%s_%d' % (prefix, ident)\n\n    def make_var(self, name, shape):\n        '''Creates a new TensorFlow variable.'''\n        return tf.get_variable(name, shape, trainable=self.trainable)\n\n    def validate_padding(self, padding):\n        '''Verifies that the padding is one of the supported ones.'''\n        assert padding in ('SAME', 'VALID')\n\n    @layer\n    def conv(self,\n             input,\n             k_h,\n             k_w,\n             c_o,\n             s_h,\n             s_w,\n             name,\n             relu=True,\n             padding=DEFAULT_PADDING,\n             group=1,\n             biased=True):\n        # Verify that the padding is acceptable\n        self.validate_padding(padding)\n        # Get the number of channels in the input\n        c_i = input.get_shape()[-1]\n        # Verify that the grouping parameter is valid\n        assert c_i % group == 0\n        assert c_o % group == 0\n        # Convolution for a given input and kernel\n        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n        with tf.variable_scope(name) as scope:\n            kernel = self.make_var('weights', shape=[k_h, k_w, c_i / group, c_o])\n            if group == 1:\n                # This is the common-case. Convolve the input without any further complications.\n                output = convolve(input, kernel)\n            else:\n                # Split the input into groups and then convolve each of them independently\n                input_groups = tf.split(3, group, input)\n                kernel_groups = tf.split(3, group, kernel)\n                output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n                # Concatenate the groups\n                output = tf.concat(3, output_groups)\n            # Add the biases\n            if biased:\n                biases = self.make_var('biases', [c_o])\n                output = tf.nn.bias_add(output, biases)\n            if relu:\n                # ReLU non-linearity\n                output = tf.nn.relu(output, name=scope.name)\n            return output\n\n    @layer\n    def atrous_conv(self,\n                    input,\n                    k_h,\n                    k_w,\n                    c_o,\n                    dilation,\n                    name,\n                    relu=True,\n                    padding=DEFAULT_PADDING,\n                    group=1,\n                    biased=True):\n        # Verify that the padding is acceptable\n        self.validate_padding(padding)\n        # Get the number of channels in the input\n        c_i = input.get_shape()[-1]\n        # Verify that the grouping parameter is valid\n        assert c_i % group == 0\n        assert c_o % group == 0\n        # Convolution for a given input and kernel\n        convolve = lambda i, k: tf.nn.atrous_conv2d(i, k, dilation, padding=padding)\n        with tf.variable_scope(name) as scope:\n            kernel = self.make_var('weights', shape=[k_h, k_w, c_i / group, c_o])\n            if group == 1:\n                # This is the common-case. Convolve the input without any further complications.\n                output = convolve(input, kernel)\n            else:\n                # Split the input into groups and then convolve each of them independently\n                input_groups = tf.split(3, group, input)\n                kernel_groups = tf.split(3, group, kernel)\n                output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n                # Concatenate the groups\n                output = tf.concat(3, output_groups)\n            # Add the biases\n            if biased:\n                biases = self.make_var('biases', [c_o])\n                output = tf.nn.bias_add(output, biases)\n            if relu:\n                # ReLU non-linearity\n                output = tf.nn.relu(output, name=scope.name)\n            return output\n        \n    @layer\n    def relu(self, input, name):\n        return tf.nn.relu(input, name=name)\n\n    @layer\n    def max_pool(self, input, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n        self.validate_padding(padding)\n        return tf.nn.max_pool(input,\n                              ksize=[1, k_h, k_w, 1],\n                              strides=[1, s_h, s_w, 1],\n                              padding=padding,\n                              name=name)\n\n    @layer\n    def avg_pool(self, input, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n        self.validate_padding(padding)\n        return tf.nn.avg_pool(input,\n                              ksize=[1, k_h, k_w, 1],\n                              strides=[1, s_h, s_w, 1],\n                              padding=padding,\n                              name=name)\n\n    @layer\n    def lrn(self, input, radius, alpha, beta, name, bias=1.0):\n        return tf.nn.local_response_normalization(input,\n                                                  depth_radius=radius,\n                                                  alpha=alpha,\n                                                  beta=beta,\n                                                  bias=bias,\n                                                  name=name)\n\n    @layer\n    def concat(self, inputs, axis, name):\n        return tf.concat(concat_dim=axis, values=inputs, name=name)\n\n    @layer\n    def add(self, inputs, name):\n        return tf.add_n(inputs, name=name)\n\n    @layer\n    def fc(self, input, num_out, name, relu=True):\n        with tf.variable_scope(name) as scope:\n            input_shape = input.get_shape()\n            if input_shape.ndims == 4:\n                # The input is spatial. Vectorize it first.\n                dim = 1\n                for d in input_shape[1:].as_list():\n                    dim *= d\n                feed_in = tf.reshape(input, [-1, dim])\n            else:\n                feed_in, dim = (input, input_shape[-1].value)\n            weights = self.make_var('weights', shape=[dim, num_out])\n            biases = self.make_var('biases', [num_out])\n            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n            fc = op(feed_in, weights, biases, name=scope.name)\n            return fc\n\n    @layer\n    def softmax(self, input, name):\n        input_shape = map(lambda v: v.value, input.get_shape())\n        if len(input_shape) > 2:\n            # For certain models (like NiN), the singleton spatial dimensions\n            # need to be explicitly squeezed, since they're not broadcast-able\n            # in TensorFlow's NHWC ordering (unlike Caffe's NCHW).\n            if input_shape[1] == 1 and input_shape[2] == 1:\n                input = tf.squeeze(input, squeeze_dims=[1, 2])\n            else:\n                raise ValueError('Rank 2 tensor input expected for softmax!')\n        return tf.nn.softmax(input, name)\n        \n    @layer\n    def batch_normalization(self, input, name, is_training, activation_fn=None, scale=True):\n        with tf.variable_scope(name) as scope:\n            output = slim.batch_norm(\n                input,\n                activation_fn=activation_fn,\n                is_training=is_training,\n                updates_collections=None,\n                scale=scale,\n                scope=scope)\n            return output\n\n    @layer\n    def dropout(self, input, keep_prob, name):\n        keep = 1 - self.use_dropout + (self.use_dropout * keep_prob)\n        return tf.nn.dropout(input, keep, name=name)\n"""
kaffe/tensorflow/transformer.py,0,"b'import numpy as np\n\nfrom ..errors import KaffeError, print_stderr\nfrom ..graph import GraphBuilder, NodeMapper\nfrom ..layers import NodeKind\nfrom ..transformers import (DataInjector, DataReshaper, NodeRenamer, ReLUFuser,\n                            BatchNormScaleBiasFuser, BatchNormPreprocessor, ParameterNamer)\n\nfrom . import network\n\n\ndef get_padding_type(kernel_params, input_shape, output_shape):\n    \'\'\'Translates Caffe\'s numeric padding to one of (\'SAME\', \'VALID\').\n    Caffe supports arbitrary padding values, while TensorFlow only\n    supports \'SAME\' and \'VALID\' modes. So, not all Caffe paddings\n    can be translated to TensorFlow. There are some subtleties to\n    how the padding edge-cases are handled. These are described here:\n    https://github.com/Yangqing/caffe2/blob/master/caffe2/proto/caffe2_legacy.proto\n    \'\'\'\n    k_h, k_w, s_h, s_w, p_h, p_w = kernel_params\n    s_o_h = np.ceil(input_shape.height / float(s_h))\n    s_o_w = np.ceil(input_shape.width / float(s_w))\n    if (output_shape.height == s_o_h) and (output_shape.width == s_o_w):\n        return \'SAME\'\n    v_o_h = np.ceil((input_shape.height - k_h + 1.0) / float(s_h))\n    v_o_w = np.ceil((input_shape.width - k_w + 1.0) / float(s_w))\n    if (output_shape.height == v_o_h) and (output_shape.width == v_o_w):\n        return \'VALID\'\n    return None\n\n\nclass TensorFlowNode(object):\n    \'\'\'An intermediate representation for TensorFlow operations.\'\'\'\n\n    def __init__(self, op, *args, **kwargs):\n        # A string corresponding to the TensorFlow operation\n        self.op = op\n        # Positional arguments for the operation\n        self.args = args\n        # Keyword arguments for the operation\n        self.kwargs = list(kwargs.items())\n        # The source Caffe node\n        self.node = None\n\n    def format(self, arg):\n        \'\'\'Returns a string representation for the given value.\'\'\'\n        return ""\'%s\'"" % arg if isinstance(arg, basestring) else str(arg)\n\n    def pair(self, key, value):\n        \'\'\'Returns key=formatted(value).\'\'\'\n        return \'%s=%s\' % (key, self.format(value))\n\n    def emit(self):\n        \'\'\'Emits the Python source for this node.\'\'\'\n        # Format positional arguments\n        args = map(self.format, self.args)\n        # Format any keyword arguments\n        if self.kwargs:\n            args += [self.pair(k, v) for k, v in self.kwargs]\n        # Set the node name\n        args.append(self.pair(\'name\', self.node.name))\n        args = \', \'.join(args)\n        return \'%s(%s)\' % (self.op, args)\n\n\nclass MaybeActivated(object):\n\n    def __init__(self, node, default=True):\n        self.inject_kwargs = {}\n        if node.metadata.get(\'relu\', False) != default:\n            self.inject_kwargs[\'relu\'] = not default\n\n    def __call__(self, *args, **kwargs):\n        kwargs.update(self.inject_kwargs)\n        return TensorFlowNode(*args, **kwargs)\n\n\nclass TensorFlowMapper(NodeMapper):\n\n    def get_kernel_params(self, node):\n        kernel_params = node.layer.kernel_parameters\n        input_shape = node.get_only_parent().output_shape\n        padding = get_padding_type(kernel_params, input_shape, node.output_shape)\n        # Only emit the padding if it\'s not the default value.\n        padding = {\'padding\': padding} if padding != network.DEFAULT_PADDING else {}\n        return (kernel_params, padding)\n\n    def map_convolution(self, node):\n        (kernel_params, kwargs) = self.get_kernel_params(node)\n        h = kernel_params.kernel_h\n        w = kernel_params.kernel_w\n        c_o = node.output_shape[1]\n        c_i = node.parents[0].output_shape[1]\n        group = node.parameters.group\n        if group != 1:\n            kwargs[\'group\'] = group\n        if not node.parameters.bias_term:\n            kwargs[\'biased\'] = False\n        assert kernel_params.kernel_h == h\n        assert kernel_params.kernel_w == w\n        return MaybeActivated(node)(\'conv\', kernel_params.kernel_h, kernel_params.kernel_w, c_o,\n                                    kernel_params.stride_h, kernel_params.stride_w, **kwargs)\n\n    def map_relu(self, node):\n        return TensorFlowNode(\'relu\')\n\n    def map_pooling(self, node):\n        pool_type = node.parameters.pool\n        if pool_type == 0:\n            pool_op = \'max_pool\'\n        elif pool_type == 1:\n            pool_op = \'avg_pool\'\n        else:\n            # Stochastic pooling, for instance.\n            raise KaffeError(\'Unsupported pooling type.\')\n        (kernel_params, padding) = self.get_kernel_params(node)\n        return TensorFlowNode(pool_op, kernel_params.kernel_h, kernel_params.kernel_w,\n                              kernel_params.stride_h, kernel_params.stride_w, **padding)\n\n    def map_inner_product(self, node):\n        #TODO: Axis\n        assert node.parameters.axis == 1\n        #TODO: Unbiased\n        assert node.parameters.bias_term == True\n        return MaybeActivated(node)(\'fc\', node.parameters.num_output)\n\n    def map_softmax(self, node):\n        return TensorFlowNode(\'softmax\')\n\n    def map_lrn(self, node):\n        params = node.parameters\n        # The window size must be an odd value. For a window\n        # size of (2*n+1), TensorFlow defines depth_radius = n.\n        assert params.local_size % 2 == 1\n        # Caffe scales by (alpha/(2*n+1)), whereas TensorFlow\n        # just scales by alpha (as does Krizhevsky\'s paper).\n        # We\'ll account for that here.\n        alpha = params.alpha / float(params.local_size)\n        return TensorFlowNode(\'lrn\', int(params.local_size / 2), alpha, params.beta)\n\n    def map_concat(self, node):\n        axis = (2, 3, 1, 0)[node.parameters.axis]\n        return TensorFlowNode(\'concat\', axis)\n\n    def map_dropout(self, node):\n        return TensorFlowNode(\'dropout\', node.parameters.dropout_ratio)\n\n    def map_batch_norm(self, node):\n        scale_offset = len(node.data) == 4\n        kwargs = {\'is_training\': True} if scale_offset else {\'is_training\': True, \'scale\': False}\n        return MaybeActivated(node, default=False)(\'batch_normalization\', **kwargs)\n\n    def map_eltwise(self, node):\n        operations = {0: \'multiply\', 1: \'add\', 2: \'max\'}\n        op_code = node.parameters.operation\n        try:\n            return TensorFlowNode(operations[op_code])\n        except KeyError:\n            raise KaffeError(\'Unknown elementwise operation: {}\'.format(op_code))\n\n    def commit(self, chains):\n        return chains\n\n\nclass TensorFlowEmitter(object):\n\n    def __init__(self, tab=None):\n        self.tab = tab or \' \' * 4\n        self.prefix = \'\'\n\n    def indent(self):\n        self.prefix += self.tab\n\n    def outdent(self):\n        self.prefix = self.prefix[:-len(self.tab)]\n\n    def statement(self, s):\n        return self.prefix + s + \'\\n\'\n\n    def emit_imports(self):\n        return self.statement(\'from kaffe.tensorflow import Network\\n\')\n\n    def emit_class_def(self, name):\n        return self.statement(\'class %s(Network):\' % (name))\n\n    def emit_setup_def(self):\n        return self.statement(\'def setup(self):\')\n\n    def emit_parents(self, chain):\n        assert len(chain)\n        s = \'(self.feed(\'\n        sep = \', \\n\' + self.prefix + (\' \' * len(s))\n        s += sep.join([""\'%s\'"" % parent.name for parent in chain[0].node.parents])\n        return self.statement(s + \')\')\n\n    def emit_node(self, node):\n        return self.statement(\' \' * 5 + \'.\' + node.emit())\n\n    def emit(self, name, chains):\n        s = self.emit_imports()\n        s += self.emit_class_def(name)\n        self.indent()\n        s += self.emit_setup_def()\n        self.indent()\n        blocks = []\n        for chain in chains:\n            b = \'\'\n            b += self.emit_parents(chain)\n            for node in chain:\n                b += self.emit_node(node)\n            blocks.append(b[:-1] + \')\')\n        s = s + \'\\n\\n\'.join(blocks)\n        return s\n\n\nclass TensorFlowTransformer(object):\n\n    def __init__(self, def_path, data_path, verbose=True, phase=\'test\'):\n        self.verbose = verbose\n        self.phase = phase\n        self.load(def_path, data_path, phase)\n        self.params = None\n        self.source = None\n\n    def load(self, def_path, data_path, phase):\n        # Build the graph\n        graph = GraphBuilder(def_path, phase).build()\n\n        if data_path is not None:\n            # Load and associate learned parameters\n            graph = DataInjector(def_path, data_path)(graph)\n\n        # Transform the graph\n        transformers = [\n            # Fuse split batch normalization layers\n            BatchNormScaleBiasFuser(),\n\n            # Fuse ReLUs\n            # TODO: Move non-linearity application to layer wrapper, allowing\n            # any arbitrary operation to be optionally activated.\n            ReLUFuser(allowed_parent_types=[NodeKind.Convolution, NodeKind.InnerProduct,\n                                            NodeKind.BatchNorm]),\n\n            # Rename nodes\n            # Slashes are used for scoping in TensorFlow. Replace slashes\n            # in node names with underscores.\n            # (Caffe\'s GoogLeNet implementation uses slashes)\n            NodeRenamer(lambda node: node.name.replace(\'/\', \'_\'))\n        ]\n        self.graph = graph.transformed(transformers)\n\n        # Display the graph\n        if self.verbose:\n            print_stderr(self.graph)\n\n    def transform_data(self):\n        if self.params is None:\n            transformers = [\n\n                # Reshape the parameters to TensorFlow\'s ordering\n                DataReshaper({\n                    # (c_o, c_i, h, w) -> (h, w, c_i, c_o)\n                    NodeKind.Convolution: (2, 3, 1, 0),\n\n                    # (c_o, c_i) -> (c_i, c_o)\n                    NodeKind.InnerProduct: (1, 0)\n                }),\n\n                # Pre-process batch normalization data\n                BatchNormPreprocessor(),\n\n                # Convert parameters to dictionaries\n                ParameterNamer(),\n            ]\n            self.graph = self.graph.transformed(transformers)\n            self.params = {node.name: node.data for node in self.graph.nodes if node.data}\n        return self.params\n\n    def transform_source(self):\n        if self.source is None:\n            mapper = TensorFlowMapper(self.graph)\n            chains = mapper.map()\n            emitter = TensorFlowEmitter()\n            self.source = emitter.emit(self.graph.name, chains)\n        return self.source\n'"
