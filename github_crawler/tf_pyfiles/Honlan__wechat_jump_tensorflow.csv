file_path,api_count,code
simple/simple.py,0,"b'# -*- coding: utf-8 -*-\n\nimport numpy as np\nimport cv2\nimport os\nimport time\nimport re\n\n# \xe5\xb1\x8f\xe5\xb9\x95\xe6\x88\xaa\xe5\x9b\xbe\ndef pull_screenshot(path):\n\tos.system(\'adb shell screencap -p /sdcard/%s\' % path)\n\tos.system(\'adb pull /sdcard/%s .\' % path)\n\n# \xe6\xa0\xb9\xe6\x8d\xaex\xe8\xb7\x9d\xe7\xa6\xbb\xe8\xb7\xb3\xe8\xb7\x83\ndef jump(distance, alpha):\n\tpress_time = max(int(distance * alpha), 200)\n\n\tcmd = \'adb shell input swipe {} {} {} {} {}\'.format(bx1, by1, bx2, by2, press_time)\n\tos.system(cmd)\n\nscreenshot = \'screenshot.png\'\nalpha = 0\nbx1, by1, bx2, by2 = 0, 0, 0, 0\nchess_x = 0\ntarget_x = 0\n\nfix = 1.6667\n# \xe6\xa3\x80\xe6\x9f\xa5\xe5\x88\x86\xe8\xbe\xa8\xe7\x8e\x87\xe6\x98\xaf\xe5\x90\xa6\xe6\x98\xaf960x540\nsize_str = os.popen(\'adb shell wm size\').read()\nif size_str:\n\tm = re.search(r\'(\\d+)x(\\d+)\', size_str)\n\tif m:\n\t\thxw = ""{height}x{width}"".format(height=m.group(2), width=m.group(1))\n\t\tif hxw == ""960x540"":\n\t\t\tfix = 3.16\n\nwhile True:\n\tpull_screenshot(screenshot)\n\timage_np = cv2.imread(screenshot)\n\timage_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n\tgray = cv2.Canny(image_np, 20, 80)\n\n\tHEIGHT = image_np.shape[0]\n\tWIDTH = image_np.shape[1]\n\n\tbx1 = WIDTH / 2 + int(np.random.rand() * 10 - 5)\n\tbx2 = WIDTH / 2 + int(np.random.rand() * 10 - 5)\n\tby1 = HEIGHT * 0.785 + int(np.random.rand() * 4 - 2)\n\tby2 = HEIGHT * 0.785 + int(np.random.rand() * 4 - 2) \n\talpha = WIDTH * fix\n\n\t# \xe8\x8e\xb7\xe5\x8f\x96\xe6\xa3\x8b\xe5\xad\x90x\xe5\x9d\x90\xe6\xa0\x87\n\tlinemax = []\n\tfor i in range(int(HEIGHT * 0.4), int(HEIGHT * 0.6)):\n\t\tline = []\n\t\tfor j in range(int(WIDTH * 0.15), int(WIDTH * 0.85)):\n\t\t\tif image_np[i, j, 0] > 40 and image_np[i, j, 0] < 70 and image_np[i, j, 1] > 40 and image_np[i, j, 1] < 70 and image_np[i, j, 2] > 60 and image_np[i, j, 2] < 110:\n\t\t\t\tgray[i, j] = 255\n\t\t\t\tif len(line) > 0 and j - line[-1] > 1:\n\t\t\t\t\tbreak\n\t\t\t\telse:\n\t\t\t\t\tline.append(j)\n\n\t\tif len(line) > 5 and len(line) > len(linemax):\n\t\t\tlinemax = line\n\t\tif len(linemax) > 20 and len(line) == 0:\n\t\t\tbreak\n\n\tchess_x = int(np.mean(linemax))\n\n\t# \xe8\x8e\xb7\xe5\x8f\x96\xe7\x9b\xae\xe6\xa0\x87x\xe5\x9d\x90\xe6\xa0\x87\n\tfor i in range(int(HEIGHT * 0.3), int(HEIGHT * 0.5)):\n\t\tflag = False\n\t\tfor j in range(WIDTH):\n\t\t\t# \xe8\xb6\x85\xe8\xbf\x87\xe6\x9c\x8b\xe5\x8f\x8b\xe6\x97\xb6\xe6\xa3\x8b\xe5\xad\x90\xe4\xb8\x8a\xe6\x96\xb9\xe7\x9a\x84\xe5\x9b\xbe\xe6\xa1\x88\n\t\t\tif np.abs(j - chess_x) < len(linemax):\n\t\t\t\tcontinue\n\t\t\tif not gray[i, j] == 0:\n\t\t\t\ttarget_x = j\n\t\t\t\tflag = True\n\t\t\t\tbreak\n\t\tif flag:\n\t\t\tbreak\n\n\t# \xe4\xbf\xae\xe6\x94\xb9\xe6\xa3\x80\xe6\xb5\x8b\xe5\x9b\xbe\n\tgray[:, chess_x] = 255\n\tgray[:, target_x] = 255\n\t# \xe4\xbf\x9d\xe5\xad\x98\xe6\xa3\x80\xe6\xb5\x8b\xe5\x9b\xbe\n\tcv2.imwrite(\'detection.png\', gray)\n\n\tprint(chess_x, target_x)\n\tjump(float(np.abs(chess_x - target_x)) / WIDTH, alpha)\n\n\t# \xe7\xad\x89\xe6\xa3\x8b\xe5\xad\x90\xe8\x90\xbd\xe7\xa8\xb3\n\ttime.sleep(np.random.random() + 1)\n\n'"
simple/simple_ios.py,0,"b""# -*- coding: utf-8 -*-\n\n# \xe5\xb7\xb2\xe6\xb5\x8b\xe8\xaf\x95MacOS + IOS\xef\xbc\x8c\xe8\xa6\x81\xe6\xad\xa3\xe7\xa1\xae\xe8\xbf\x90\xe8\xa1\x8c\xe4\xb8\x8b\xe9\x9d\xa2\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x8c\xe8\xaf\xb7\xe5\x85\x88\xe9\x85\x8d\xe7\xbd\xae\xef\xbc\x9a\n# \xe4\xbd\xbf\xe7\x94\xa8\xe5\xbc\x80\xe5\x8f\x91\xe8\x80\x85\xe8\xb4\xa6\xe5\x8f\xb7Xcode\xe7\x9c\x9f\xe6\x9c\xba\xe8\xb0\x83\xe8\xaf\x95WDA\xef\xbc\x88WebDriverAgent\xef\xbc\x89\n# \xe5\x8f\x82\xe8\x80\x83\xe7\xbd\x91\xe5\x9d\x80 https://testerhome.com/topics/7220\n# \xe5\xae\x89\xe8\xa3\x85openatx/facebook-wda\xe6\x94\xaf\xe6\x8c\x81\xe4\xbd\xbf\xe7\x94\xa8Python\xe8\xb0\x83\xe7\x94\xa8WDA\n# \xe5\x8f\x82\xe8\x80\x83\xe7\xbd\x91\xe5\x9d\x80 https://github.com/openatx/facebook-wda\n\nimport numpy as np\nimport cv2\nimport time\nimport wda\n\n# iPhone 6s \xe6\x8c\x89\xe5\x8e\x8b\xe6\x97\xb6\xe9\x97\xb4\xe5\x8f\x82\xe6\x95\xb0\xe4\xbf\xae\xe6\xad\xa3\xef\xbc\x8c\xe5\x85\xb6\xe5\xae\x83\xe5\x9e\x8b\xe5\x8f\xb7iPhone\xe8\xaf\xb7\xe8\x87\xaa\xe8\xa1\x8c\xe4\xbf\xae\xe6\x94\xb9\nfixtime = 2.255\n\nc = wda.Client()\ns = c.session()\n\nscreenshot = 'jump_ios.png'\n\n# \xe5\xb1\x8f\xe5\xb9\x95\xe6\x88\xaa\xe5\x9b\xbe\ndef pull_screenshot():\n\tc.screenshot(screenshot)\n\n# \xe6\xa0\xb9\xe6\x8d\xaex\xe8\xb7\x9d\xe7\xa6\xbb\xe8\xb7\xb3\xe8\xb7\x83\ndef jump(distance, alpha):\n\tpress_time = max(int(distance * alpha), 200) / 1000.0\n\tprint('press time: {}'.format(press_time))\n\ts.tap_hold(200, 200, press_time)\n\nalpha = 0\nbx1, by1, bx2, by2 = 0, 0, 0, 0\nchess_x = 0\ntarget_x = 0\n\nwhile True:\n\tpull_screenshot()\n\timage_np = cv2.imread(screenshot)\n\timage_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n\tgray = cv2.Canny(image_np, 20, 80)\n\n\tHEIGHT = image_np.shape[0]\n\tWIDTH = image_np.shape[1]\n\n\tbx1 = WIDTH / 2 + int(np.random.rand() * 10 - 5)\n\tbx2 = WIDTH / 2 + int(np.random.rand() * 10 - 5)\n\tby1 = HEIGHT * 0.785 + int(np.random.rand() * 4 - 2)\n\tby2 = HEIGHT * 0.785 + int(np.random.rand() * 4 - 2)\n\talpha = WIDTH * fixtime\n\n\t# \xe8\x8e\xb7\xe5\x8f\x96\xe6\xa3\x8b\xe5\xad\x90x\xe5\x9d\x90\xe6\xa0\x87\n\tlinemax = []\n\tfor i in range(int(HEIGHT * 0.4), int(HEIGHT * 0.6)):\n\t\tline = []\n\t\tfor j in range(int(WIDTH * 0.15), int(WIDTH * 0.85)):\n\t\t\tif image_np[i, j, 0] > 40 and image_np[i, j, 0] < 70 and image_np[i, j, 1] > 40 and image_np[i, j, 1] < 70 and image_np[i, j, 2] > 60 and image_np[i, j, 2] < 110:\n\t\t\t\tgray[i, j] = 255\n\t\t\t\tif len(line) > 0 and j - line[-1] > 1:\n\t\t\t\t\tbreak\n\t\t\t\telse:\n\t\t\t\t\tline.append(j)\n\n\t\tif len(line) > 5 and len(line) > len(linemax):\n\t\t\tlinemax = line\n\n\t\tif len(linemax) > 50 and len(line) == 0:\n\t\t\tbreak\n\n\tchess_x = int(np.mean(linemax))\n\n\t# \xe8\x8e\xb7\xe5\x8f\x96\xe7\x9b\xae\xe6\xa0\x87x\xe5\x9d\x90\xe6\xa0\x87\n\tfor i in range(int(HEIGHT * 0.3), int(HEIGHT * 0.5)):\n\t\tflag = False\n\t\tfor j in range(WIDTH):\n\t\t\t# \xe8\xb6\x85\xe8\xbf\x87\xe6\x9c\x8b\xe5\x8f\x8b\xe6\x97\xb6\xe6\xa3\x8b\xe5\xad\x90\xe4\xb8\x8a\xe6\x96\xb9\xe7\x9a\x84\xe5\x9b\xbe\xe6\xa1\x88\n\t\t\tif np.abs(j - chess_x) < len(linemax):\n\t\t\t\tcontinue\n\t\t\tif not gray[i, j] == 0:\n\t\t\t\ttarget_x = j\n\t\t\t\tflag = True\n\t\t\t\tbreak\n\t\tif flag:\n\t\t\tbreak\n\n\t# \xe4\xbf\xae\xe6\x94\xb9\xe6\xa3\x80\xe6\xb5\x8b\xe5\x9b\xbe\n\tgray[:, chess_x] = 255\n\tgray[:, target_x] = 255\n\t# \xe4\xbf\x9d\xe5\xad\x98\xe6\xa3\x80\xe6\xb5\x8b\xe5\x9b\xbe\n\tcv2.imwrite('detection_ios.png', gray)\n\n\tprint(chess_x, target_x)\n\tjump(float(np.abs(chess_x - target_x)) / WIDTH, alpha)\n\n\t# \xe7\xad\x89\xe6\xa3\x8b\xe5\xad\x90\xe8\x90\xbd\xe7\xa8\xb3\n\ttime.sleep(np.random.random() + 1.4)\n"""
tensorflow/wechat_auto_jump.py,6,"b""# -*- coding: utf-8 -*-\n\nimport numpy as np\nimport tensorflow as tf\nimport time\nimport os\nfrom utils import label_map_util\nfrom utils import visualization_utils as vis_util\nimport cv2\n\nif tf.__version__ != '1.4.0':\n    raise ImportError('Please upgrade your tensorflow installation to v1.4.0!')\n\n# \xe6\xa8\xa1\xe5\x9e\x8b\xe9\x85\x8d\xe7\xbd\xae\nPATH_TO_CKPT = 'frozen_inference_graph_frcnn_inception_v2_coco.pb'\nPATH_TO_LABELS = 'wechat_jump_label_map.pbtxt'\nNUM_CLASSES = 7\n\n# \xe5\x8a\xa0\xe8\xbd\xbd\xe6\xa8\xa1\xe5\x9e\x8b\ndetection_graph = tf.Graph()\nwith detection_graph.as_default():\n    od_graph_def = tf.GraphDef()\n    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n        od_graph_def.ParseFromString(fid.read())\n        tf.import_graph_def(od_graph_def, name='')\n\n# \xe5\x8a\xa0\xe8\xbd\xbd\xe7\xb1\xbb\xe5\x88\xab\nlabel_map = label_map_util.load_labelmap(PATH_TO_LABELS)\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)\n\n# \xe5\xb1\x8f\xe5\xb9\x95\xe6\x88\xaa\xe5\x9b\xbe\ndef pull_screenshot(path):\n    os.system('adb shell screencap -p /sdcard/%s' % path)\n    os.system('adb pull /sdcard/%s .' % path)\n\n# \xe8\xaf\xbb\xe5\x8f\x96\xe5\x9b\xbe\xe7\x89\x87\ndef read_image(path):\n    image_np = cv2.imread(path)\n    image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n\n    WIDTH = image_np.shape[1]\n    HEIGHT = image_np.shape[0]\n    image_np_expanded = np.expand_dims(image_np, axis=0)\n\n    return image_np, image_np_expanded, WIDTH, HEIGHT\n\n# \xe8\x8e\xb7\xe5\x8f\x96\xe7\x89\xa9\xe4\xbd\x93\xe8\xaf\x86\xe5\x88\xab\xe7\xbb\x93\xe6\x9e\x9c\ndef get_positions(boxes, classes, scores, category_index):\n    cp = [1, 1, 1, 1]\n    tp = [1, 1, 1, 1]\n    target_type = ''\n    min_score_thresh = .5\n\n    for i in range(boxes.shape[0]):\n        if scores[i] > min_score_thresh:\n            if boxes[i][0] < 0.3 or boxes[i][2] > 0.8:\n                continue\n            if category_index[classes[i]]['name'] == 'chess':\n                cp = boxes[i]\n            elif boxes[i][0] < tp[0]:\n                tp = boxes[i]\n                target_type = category_index[classes[i]]['name']\n\n    return cp, tp, target_type\n\n# \xe4\xb8\x80\xe4\xba\x9b\xe5\x8f\x98\xe9\x87\x8f\nloop = 1\nalpha = 1800\nchess_x = 0\ntarget_x = 0\ndistance = 0\nscreenshot = 'screenshot.png'\n\n# \xe6\xa0\xb9\xe6\x8d\xaex\xe8\xb7\x9d\xe7\xa6\xbb\xe8\xb7\xb3\xe8\xb7\x83\ndef jump(distance, target_type, alpha, bx1, by1, bx2, by2):\n    press_time = max(int(distance * alpha), 200)\n\n    cmd = 'adb shell input swipe {} {} {} {} {}'.format(bx1, by1, bx2, by2, press_time)\n    os.system(cmd)\n\n    if target_type in ['waste', 'magic', 'shop', 'music']:\n        print('=' * 10, target_type , '=' * 10)\n\nwith detection_graph.as_default():\n    with tf.Session(graph=detection_graph) as sess:\n        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n        while True:\n            pull_screenshot(screenshot)\n            image_np, image_np_expanded, WIDTH, HEIGHT = read_image(screenshot)\n            \n            bx1 = WIDTH / 2 + int(np.random.rand() * 10 - 5)\n            bx2 = WIDTH / 2 + int(np.random.rand() * 10 - 5)\n            by1 = HEIGHT * 0.785 + int(np.random.rand() * 4 - 2)\n            by2 = HEIGHT * 0.785 + int(np.random.rand() * 4 - 2)\n\n            (boxes, scores, classes, num) = sess.run(\n                [detection_boxes, detection_scores, detection_classes, num_detections], \n                feed_dict={image_tensor: image_np_expanded})\n\n            boxes = np.reshape(boxes, (-1, boxes.shape[-1]))\n            scores = np.reshape(scores, (-1))\n            classes = np.reshape(classes, (-1)).astype(np.int32)\n\n            vis_util.visualize_boxes_and_labels_on_image_array(image_np, boxes, classes, scores, category_index, use_normalized_coordinates=True, line_thickness=8)\n            cv2.imwrite('detection.png', cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))\n\n            # \xe8\xae\xa1\xe7\xae\x97\xe6\xa3\x8b\xe5\xad\x90\xe5\x92\x8c\xe7\x9b\xae\xe6\xa0\x87\xe5\x9d\x97\xe4\xbd\x8d\xe7\xbd\xae\n            cp, tp, target_type = get_positions(boxes, classes, scores, category_index)\n            chess_x = (cp[1] + cp[3]) / 2\n            target_x = (tp[1] + tp[3]) / 2\n            distance = np.abs(chess_x - target_x)\n\n            # \xe8\xb7\xb3\xef\xbc\x81\n            jump(distance, target_type, alpha, bx1, by1, bx2, by2)\n            print(distance, target_type)\n\n            # \xe7\xad\x89\xe6\xa3\x8b\xe5\xad\x90\xe8\x90\xbd\xe7\xa8\xb3\n            loop += 1\n            time.sleep(np.random.rand() + 1)\n\n            # \xe8\xb7\xb3\xe7\xb4\xaf\xe4\xba\x86\xe4\xbc\x91\xe6\x81\xaf\xe4\xb8\x80\xe4\xbc\x9a\n            rest_jump = np.random.rand() * 50 + 50\n            rest_time = np.random.rand() * 5 + 5\n            if loop > rest_jump:\n                loop = 1\n                print('\xe5\xb7\xb2\xe7\xbb\x8f\xe8\xb7\xb3\xe4\xba\x86 %d \xe4\xb8\x8b\xef\xbc\x8c\xe4\xbc\x91\xe6\x81\xaf %d \xe7\xa7\x92' % (rest_jump, rest_time))\n                time.sleep(rest_time)\n"""
tensorflow/utils/dataset_util.py,6,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""Utility functions for creating TFRecord data sets.""""""\n\nimport tensorflow as tf\n\n\ndef int64_feature(value):\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef int64_list_feature(value):\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\n\ndef bytes_feature(value):\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\ndef bytes_list_feature(value):\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n\n\ndef float_list_feature(value):\n  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef read_examples_list(path):\n  """"""Read list of training or validation examples.\n\n  The file is assumed to contain a single example per line where the first\n  token in the line is an identifier that allows us to find the image and\n  annotation xml for that example.\n\n  For example, the line:\n  xyz 3\n  would allow us to find files xyz.jpg and xyz.xml (the 3 would be ignored).\n\n  Args:\n    path: absolute path to examples list file.\n\n  Returns:\n    list of example identifiers (strings).\n  """"""\n  with tf.gfile.GFile(path) as fid:\n    lines = fid.readlines()\n  return [line.strip().split(\' \')[0] for line in lines]\n\n\ndef recursive_parse_xml_to_dict(xml):\n  """"""Recursively parses XML contents to python dict.\n\n  We assume that `object` tags are the only ones that can appear\n  multiple times at the same level of a tree.\n\n  Args:\n    xml: xml tree obtained by parsing XML file contents using lxml.etree\n\n  Returns:\n    Python dictionary holding XML contents.\n  """"""\n  if not xml:\n    return {xml.tag: xml.text}\n  result = {}\n  for child in xml:\n    child_result = recursive_parse_xml_to_dict(child)\n    if child.tag != \'object\':\n      result[child.tag] = child_result[child.tag]\n    else:\n      if child.tag not in result:\n        result[child.tag] = []\n      result[child.tag].append(child_result[child.tag])\n  return {xml.tag: result}\n'"
tensorflow/utils/label_map_util.py,1,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""Label map utility functions.""""""\n\nimport logging\n\nimport tensorflow as tf\nfrom google.protobuf import text_format\n# from object_detection.protos import string_int_label_map_pb2\n\n\ndef _validate_label_map(label_map):\n  """"""Checks if a label map is valid.\n\n  Args:\n    label_map: StringIntLabelMap to validate.\n\n  Raises:\n    ValueError: if label map is invalid.\n  """"""\n  for item in label_map.item:\n    if item.id < 1:\n      raise ValueError(\'Label map ids should be >= 1.\')\n\n\ndef create_category_index(categories):\n  """"""Creates dictionary of COCO compatible categories keyed by category id.\n\n  Args:\n    categories: a list of dicts, each of which has the following keys:\n      \'id\': (required) an integer id uniquely identifying this category.\n      \'name\': (required) string representing category name\n        e.g., \'cat\', \'dog\', \'pizza\'.\n\n  Returns:\n    category_index: a dict containing the same entries as categories, but keyed\n      by the \'id\' field of each category.\n  """"""\n  category_index = {}\n  for cat in categories:\n    category_index[cat[\'id\']] = cat\n  return category_index\n\n\ndef convert_label_map_to_categories(label_map,\n                                    max_num_classes,\n                                    use_display_name=True):\n  """"""Loads label map proto and returns categories list compatible with eval.\n\n  This function loads a label map and returns a list of dicts, each of which\n  has the following keys:\n    \'id\': (required) an integer id uniquely identifying this category.\n    \'name\': (required) string representing category name\n      e.g., \'cat\', \'dog\', \'pizza\'.\n  We only allow class into the list if its id-label_id_offset is\n  between 0 (inclusive) and max_num_classes (exclusive).\n  If there are several items mapping to the same id in the label map,\n  we will only keep the first one in the categories list.\n\n  Args:\n    label_map: a StringIntLabelMapProto or None.  If None, a default categories\n      list is created with max_num_classes categories.\n    max_num_classes: maximum number of (consecutive) label indices to include.\n    use_display_name: (boolean) choose whether to load \'display_name\' field\n      as category name.  If False or if the display_name field does not exist,\n      uses \'name\' field as category names instead.\n  Returns:\n    categories: a list of dictionaries representing all possible categories.\n  """"""\n  categories = []\n  list_of_ids_already_added = []\n  if not label_map:\n    label_id_offset = 1\n    for class_id in range(max_num_classes):\n      categories.append({\n          \'id\': class_id + label_id_offset,\n          \'name\': \'category_{}\'.format(class_id + label_id_offset)\n      })\n    return categories\n  for item in label_map.item:\n    if not 0 < item.id <= max_num_classes:\n      logging.info(\'Ignore item %d since it falls outside of requested \'\n                   \'label range.\', item.id)\n      continue\n    if use_display_name and item.HasField(\'display_name\'):\n      name = item.display_name\n    else:\n      name = item.name\n    if item.id not in list_of_ids_already_added:\n      list_of_ids_already_added.append(item.id)\n      categories.append({\'id\': item.id, \'name\': name})\n  return categories\n\n\ndef load_labelmap(path):\n  """"""Loads label map proto.\n\n  Args:\n    path: path to StringIntLabelMap proto text file.\n  Returns:\n    a StringIntLabelMapProto\n  """"""\n  with tf.gfile.GFile(path, \'r\') as fid:\n    label_map_string = fid.read()\n    label_map = StringIntLabelMap()\n    try:\n      text_format.Merge(label_map_string, label_map)\n    except text_format.ParseError:\n      label_map.ParseFromString(label_map_string)\n  _validate_label_map(label_map)\n  return label_map\n\n\ndef get_label_map_dict(label_map_path, use_display_name=False):\n  """"""Reads a label map and returns a dictionary of label names to id.\n\n  Args:\n    label_map_path: path to label_map.\n    use_display_name: whether to use the label map items\' display names as keys.\n\n  Returns:\n    A dictionary mapping label names to id.\n  """"""\n  label_map = load_labelmap(label_map_path)\n  label_map_dict = {}\n  for item in label_map.item:\n    if use_display_name:\n      label_map_dict[item.display_name] = item.id\n    else:\n      label_map_dict[item.name] = item.id\n  return label_map_dict\n\n\ndef create_category_index_from_labelmap(label_map_path):\n  """"""Reads a label map and returns a category index.\n\n  Args:\n    label_map_path: Path to `StringIntLabelMap` proto text file.\n\n  Returns:\n    A category index, which is a dictionary that maps integer ids to dicts\n    containing categories, e.g.\n    {1: {\'id\': 1, \'name\': \'dog\'}, 2: {\'id\': 2, \'name\': \'cat\'}, ...}\n  """"""\n  label_map = load_labelmap(label_map_path)\n  max_num_classes = max(item.id for item in label_map.item)\n  categories = convert_label_map_to_categories(label_map, max_num_classes)\n  return create_category_index(categories)\n\n\ndef create_class_agnostic_category_index():\n  """"""Creates a category index with a single `object` class.""""""\n  return {1: {\'id\': 1, \'name\': \'object\'}}\n\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: object_detection/protos/string_int_label_map.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'object_detection/protos/string_int_label_map.proto\',\n  package=\'object_detection.protos\',\n  syntax=\'proto2\',\n  serialized_pb=_b(\'\\n2object_detection/protos/string_int_label_map.proto\\x12\\x17object_detection.protos\\""G\\n\\x15StringIntLabelMapItem\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\n\\n\\x02id\\x18\\x02 \\x01(\\x05\\x12\\x14\\n\\x0c\\x64isplay_name\\x18\\x03 \\x01(\\t\\""Q\\n\\x11StringIntLabelMap\\x12<\\n\\x04item\\x18\\x01 \\x03(\\x0b\\x32..object_detection.protos.StringIntLabelMapItem\')\n)\n\n\n\n\n_STRINGINTLABELMAPITEM = _descriptor.Descriptor(\n  name=\'StringIntLabelMapItem\',\n  full_name=\'object_detection.protos.StringIntLabelMapItem\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'object_detection.protos.StringIntLabelMapItem.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'id\', full_name=\'object_detection.protos.StringIntLabelMapItem.id\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'display_name\', full_name=\'object_detection.protos.StringIntLabelMapItem.display_name\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=79,\n  serialized_end=150,\n)\n\n\n_STRINGINTLABELMAP = _descriptor.Descriptor(\n  name=\'StringIntLabelMap\',\n  full_name=\'object_detection.protos.StringIntLabelMap\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'item\', full_name=\'object_detection.protos.StringIntLabelMap.item\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=152,\n  serialized_end=233,\n)\n\n_STRINGINTLABELMAP.fields_by_name[\'item\'].message_type = _STRINGINTLABELMAPITEM\nDESCRIPTOR.message_types_by_name[\'StringIntLabelMapItem\'] = _STRINGINTLABELMAPITEM\nDESCRIPTOR.message_types_by_name[\'StringIntLabelMap\'] = _STRINGINTLABELMAP\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nStringIntLabelMapItem = _reflection.GeneratedProtocolMessageType(\'StringIntLabelMapItem\', (_message.Message,), dict(\n  DESCRIPTOR = _STRINGINTLABELMAPITEM,\n  __module__ = \'object_detection.protos.string_int_label_map_pb2\'\n  # @@protoc_insertion_point(class_scope:object_detection.protos.StringIntLabelMapItem)\n  ))\n_sym_db.RegisterMessage(StringIntLabelMapItem)\n\nStringIntLabelMap = _reflection.GeneratedProtocolMessageType(\'StringIntLabelMap\', (_message.Message,), dict(\n  DESCRIPTOR = _STRINGINTLABELMAP,\n  __module__ = \'object_detection.protos.string_int_label_map_pb2\'\n  # @@protoc_insertion_point(class_scope:object_detection.protos.StringIntLabelMap)\n  ))\n_sym_db.RegisterMessage(StringIntLabelMap)\n\n\n# @@protoc_insertion_point(module_scope)\n'"
tensorflow/utils/visualization_utils.py,8,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""A set of functions that are used for visualization.\n\nThese functions often receive an image, perform some visualization on the image.\nThe functions do not return a value, instead they modify the image itself.\n\n""""""\nimport collections\nimport functools\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport PIL.Image as Image\nimport PIL.ImageColor as ImageColor\nimport PIL.ImageDraw as ImageDraw\nimport PIL.ImageFont as ImageFont\nimport six\nimport tensorflow as tf\n\n\n_TITLE_LEFT_MARGIN = 10\n_TITLE_TOP_MARGIN = 10\nSTANDARD_COLORS = [\n    \'AliceBlue\', \'Chartreuse\', \'Aqua\', \'Aquamarine\', \'Azure\', \'Beige\', \'Bisque\',\n    \'BlanchedAlmond\', \'BlueViolet\', \'BurlyWood\', \'CadetBlue\', \'AntiqueWhite\',\n    \'Chocolate\', \'Coral\', \'CornflowerBlue\', \'Cornsilk\', \'Crimson\', \'Cyan\',\n    \'DarkCyan\', \'DarkGoldenRod\', \'DarkGrey\', \'DarkKhaki\', \'DarkOrange\',\n    \'DarkOrchid\', \'DarkSalmon\', \'DarkSeaGreen\', \'DarkTurquoise\', \'DarkViolet\',\n    \'DeepPink\', \'DeepSkyBlue\', \'DodgerBlue\', \'FireBrick\', \'FloralWhite\',\n    \'ForestGreen\', \'Fuchsia\', \'Gainsboro\', \'GhostWhite\', \'Gold\', \'GoldenRod\',\n    \'Salmon\', \'Tan\', \'HoneyDew\', \'HotPink\', \'IndianRed\', \'Ivory\', \'Khaki\',\n    \'Lavender\', \'LavenderBlush\', \'LawnGreen\', \'LemonChiffon\', \'LightBlue\',\n    \'LightCoral\', \'LightCyan\', \'LightGoldenRodYellow\', \'LightGray\', \'LightGrey\',\n    \'LightGreen\', \'LightPink\', \'LightSalmon\', \'LightSeaGreen\', \'LightSkyBlue\',\n    \'LightSlateGray\', \'LightSlateGrey\', \'LightSteelBlue\', \'LightYellow\', \'Lime\',\n    \'LimeGreen\', \'Linen\', \'Magenta\', \'MediumAquaMarine\', \'MediumOrchid\',\n    \'MediumPurple\', \'MediumSeaGreen\', \'MediumSlateBlue\', \'MediumSpringGreen\',\n    \'MediumTurquoise\', \'MediumVioletRed\', \'MintCream\', \'MistyRose\', \'Moccasin\',\n    \'NavajoWhite\', \'OldLace\', \'Olive\', \'OliveDrab\', \'Orange\', \'OrangeRed\',\n    \'Orchid\', \'PaleGoldenRod\', \'PaleGreen\', \'PaleTurquoise\', \'PaleVioletRed\',\n    \'PapayaWhip\', \'PeachPuff\', \'Peru\', \'Pink\', \'Plum\', \'PowderBlue\', \'Purple\',\n    \'Red\', \'RosyBrown\', \'RoyalBlue\', \'SaddleBrown\', \'Green\', \'SandyBrown\',\n    \'SeaGreen\', \'SeaShell\', \'Sienna\', \'Silver\', \'SkyBlue\', \'SlateBlue\',\n    \'SlateGray\', \'SlateGrey\', \'Snow\', \'SpringGreen\', \'SteelBlue\', \'GreenYellow\',\n    \'Teal\', \'Thistle\', \'Tomato\', \'Turquoise\', \'Violet\', \'Wheat\', \'White\',\n    \'WhiteSmoke\', \'Yellow\', \'YellowGreen\'\n]\n\n\ndef save_image_array_as_png(image, output_path):\n  """"""Saves an image (represented as a numpy array) to PNG.\n\n  Args:\n    image: a numpy array with shape [height, width, 3].\n    output_path: path to which image should be written.\n  """"""\n  image_pil = Image.fromarray(np.uint8(image)).convert(\'RGB\')\n  with tf.gfile.Open(output_path, \'w\') as fid:\n    image_pil.save(fid, \'PNG\')\n\n\ndef encode_image_array_as_png_str(image):\n  """"""Encodes a numpy array into a PNG string.\n\n  Args:\n    image: a numpy array with shape [height, width, 3].\n\n  Returns:\n    PNG encoded image string.\n  """"""\n  image_pil = Image.fromarray(np.uint8(image))\n  output = six.BytesIO()\n  image_pil.save(output, format=\'PNG\')\n  png_string = output.getvalue()\n  output.close()\n  return png_string\n\n\ndef draw_bounding_box_on_image_array(image,\n                                     ymin,\n                                     xmin,\n                                     ymax,\n                                     xmax,\n                                     color=\'red\',\n                                     thickness=4,\n                                     display_str_list=(),\n                                     use_normalized_coordinates=True):\n  """"""Adds a bounding box to an image (numpy array).\n\n  Args:\n    image: a numpy array with shape [height, width, 3].\n    ymin: ymin of bounding box in normalized coordinates (same below).\n    xmin: xmin of bounding box.\n    ymax: ymax of bounding box.\n    xmax: xmax of bounding box.\n    color: color to draw bounding box. Default is red.\n    thickness: line thickness. Default value is 4.\n    display_str_list: list of strings to display in box\n                      (each to be shown on its own line).\n    use_normalized_coordinates: If True (default), treat coordinates\n      ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n      coordinates as absolute.\n  """"""\n  image_pil = Image.fromarray(np.uint8(image)).convert(\'RGB\')\n  draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n                             thickness, display_str_list,\n                             use_normalized_coordinates)\n  np.copyto(image, np.array(image_pil))\n\n\ndef draw_bounding_box_on_image(image,\n                               ymin,\n                               xmin,\n                               ymax,\n                               xmax,\n                               color=\'red\',\n                               thickness=4,\n                               display_str_list=(),\n                               use_normalized_coordinates=True):\n  """"""Adds a bounding box to an image.\n\n  Each string in display_str_list is displayed on a separate line above the\n  bounding box in black text on a rectangle filled with the input \'color\'.\n  If the top of the bounding box extends to the edge of the image, the strings\n  are displayed below the bounding box.\n\n  Args:\n    image: a PIL.Image object.\n    ymin: ymin of bounding box.\n    xmin: xmin of bounding box.\n    ymax: ymax of bounding box.\n    xmax: xmax of bounding box.\n    color: color to draw bounding box. Default is red.\n    thickness: line thickness. Default value is 4.\n    display_str_list: list of strings to display in box\n                      (each to be shown on its own line).\n    use_normalized_coordinates: If True (default), treat coordinates\n      ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n      coordinates as absolute.\n  """"""\n  draw = ImageDraw.Draw(image)\n  im_width, im_height = image.size\n  if use_normalized_coordinates:\n    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                  ymin * im_height, ymax * im_height)\n  else:\n    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n  draw.line([(left, top), (left, bottom), (right, bottom),\n             (right, top), (left, top)], width=thickness, fill=color)\n  try:\n    font = ImageFont.truetype(\'arial.ttf\', 24)\n  except IOError:\n    font = ImageFont.load_default()\n\n  # If the total height of the display strings added to the top of the bounding\n  # box exceeds the top of the image, stack the strings below the bounding box\n  # instead of above.\n  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n  # Each display_str has a top and bottom margin of 0.05x.\n  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n\n  if top > total_display_str_height:\n    text_bottom = top\n  else:\n    text_bottom = bottom + total_display_str_height\n  # Reverse list and print from bottom to top.\n  for display_str in display_str_list[::-1]:\n    text_width, text_height = font.getsize(display_str)\n    margin = np.ceil(0.05 * text_height)\n    draw.rectangle(\n        [(left, text_bottom - text_height - 2 * margin), (left + text_width,\n                                                          text_bottom)],\n        fill=color)\n    draw.text(\n        (left + margin, text_bottom - text_height - margin),\n        display_str,\n        fill=\'black\',\n        font=font)\n    text_bottom -= text_height - 2 * margin\n\n\ndef draw_bounding_boxes_on_image_array(image,\n                                       boxes,\n                                       color=\'red\',\n                                       thickness=4,\n                                       display_str_list_list=()):\n  """"""Draws bounding boxes on image (numpy array).\n\n  Args:\n    image: a numpy array object.\n    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n           The coordinates are in normalized format between [0, 1].\n    color: color to draw bounding box. Default is red.\n    thickness: line thickness. Default value is 4.\n    display_str_list_list: list of list of strings.\n                           a list of strings for each bounding box.\n                           The reason to pass a list of strings for a\n                           bounding box is that it might contain\n                           multiple labels.\n\n  Raises:\n    ValueError: if boxes is not a [N, 4] array\n  """"""\n  image_pil = Image.fromarray(image)\n  draw_bounding_boxes_on_image(image_pil, boxes, color, thickness,\n                               display_str_list_list)\n  np.copyto(image, np.array(image_pil))\n\n\ndef draw_bounding_boxes_on_image(image,\n                                 boxes,\n                                 color=\'red\',\n                                 thickness=4,\n                                 display_str_list_list=()):\n  """"""Draws bounding boxes on image.\n\n  Args:\n    image: a PIL.Image object.\n    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n           The coordinates are in normalized format between [0, 1].\n    color: color to draw bounding box. Default is red.\n    thickness: line thickness. Default value is 4.\n    display_str_list_list: list of list of strings.\n                           a list of strings for each bounding box.\n                           The reason to pass a list of strings for a\n                           bounding box is that it might contain\n                           multiple labels.\n\n  Raises:\n    ValueError: if boxes is not a [N, 4] array\n  """"""\n  boxes_shape = boxes.shape\n  if not boxes_shape:\n    return\n  if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n    raise ValueError(\'Input must be of size [N, 4]\')\n  for i in range(boxes_shape[0]):\n    display_str_list = ()\n    if display_str_list_list:\n      display_str_list = display_str_list_list[i]\n    draw_bounding_box_on_image(image, boxes[i, 0], boxes[i, 1], boxes[i, 2],\n                               boxes[i, 3], color, thickness, display_str_list)\n\n\ndef draw_bounding_boxes_on_image_tensors(images,\n                                         boxes,\n                                         classes,\n                                         scores,\n                                         category_index,\n                                         max_boxes_to_draw=20,\n                                         min_score_thresh=0.2):\n  """"""Draws bounding boxes on batch of image tensors.\n\n  Args:\n    images: A 4D uint8 image tensor of shape [N, H, W, C].\n    boxes: [N, max_detections, 4] float32 tensor of detection boxes.\n    classes: [N, max_detections] int tensor of detection classes. Note that\n      classes are 1-indexed.\n    scores: [N, max_detections] float32 tensor of detection scores.\n    category_index: a dict that maps integer ids to category dicts. e.g.\n      {1: {1: \'dog\'}, 2: {2: \'cat\'}, ...}\n    max_boxes_to_draw: Maximum number of boxes to draw on an image. Default 20.\n    min_score_thresh: Minimum score threshold for visualization. Default 0.2.\n\n  Returns:\n    4D image tensor of type uint8, with boxes drawn on top.\n  """"""\n  visualize_boxes_fn = functools.partial(\n      visualize_boxes_and_labels_on_image_array,\n      category_index=category_index,\n      instance_masks=None,\n      keypoints=None,\n      use_normalized_coordinates=True,\n      max_boxes_to_draw=max_boxes_to_draw,\n      min_score_thresh=min_score_thresh,\n      agnostic_mode=False,\n      line_thickness=4)\n\n  def draw_boxes(image_boxes_classes_scores):\n    """"""Draws boxes on image.""""""\n    (image, boxes, classes, scores) = image_boxes_classes_scores\n    image_with_boxes = tf.py_func(visualize_boxes_fn,\n                                  [image, boxes, classes, scores], tf.uint8)\n    return image_with_boxes\n\n  images = tf.map_fn(\n      draw_boxes, (images, boxes, classes, scores),\n      dtype=tf.uint8,\n      back_prop=False)\n  return images\n\n\ndef draw_keypoints_on_image_array(image,\n                                  keypoints,\n                                  color=\'red\',\n                                  radius=2,\n                                  use_normalized_coordinates=True):\n  """"""Draws keypoints on an image (numpy array).\n\n  Args:\n    image: a numpy array with shape [height, width, 3].\n    keypoints: a numpy array with shape [num_keypoints, 2].\n    color: color to draw the keypoints with. Default is red.\n    radius: keypoint radius. Default value is 2.\n    use_normalized_coordinates: if True (default), treat keypoint values as\n      relative to the image.  Otherwise treat them as absolute.\n  """"""\n  image_pil = Image.fromarray(np.uint8(image)).convert(\'RGB\')\n  draw_keypoints_on_image(image_pil, keypoints, color, radius,\n                          use_normalized_coordinates)\n  np.copyto(image, np.array(image_pil))\n\n\ndef draw_keypoints_on_image(image,\n                            keypoints,\n                            color=\'red\',\n                            radius=2,\n                            use_normalized_coordinates=True):\n  """"""Draws keypoints on an image.\n\n  Args:\n    image: a PIL.Image object.\n    keypoints: a numpy array with shape [num_keypoints, 2].\n    color: color to draw the keypoints with. Default is red.\n    radius: keypoint radius. Default value is 2.\n    use_normalized_coordinates: if True (default), treat keypoint values as\n      relative to the image.  Otherwise treat them as absolute.\n  """"""\n  draw = ImageDraw.Draw(image)\n  im_width, im_height = image.size\n  keypoints_x = [k[1] for k in keypoints]\n  keypoints_y = [k[0] for k in keypoints]\n  if use_normalized_coordinates:\n    keypoints_x = tuple([im_width * x for x in keypoints_x])\n    keypoints_y = tuple([im_height * y for y in keypoints_y])\n  for keypoint_x, keypoint_y in zip(keypoints_x, keypoints_y):\n    draw.ellipse([(keypoint_x - radius, keypoint_y - radius),\n                  (keypoint_x + radius, keypoint_y + radius)],\n                 outline=color, fill=color)\n\n\ndef draw_mask_on_image_array(image, mask, color=\'red\', alpha=0.7):\n  """"""Draws mask on an image.\n\n  Args:\n    image: uint8 numpy array with shape (img_height, img_height, 3)\n    mask: a uint8 numpy array of shape (img_height, img_height) with\n      values between either 0 or 1.\n    color: color to draw the keypoints with. Default is red.\n    alpha: transparency value between 0 and 1. (default: 0.7)\n\n  Raises:\n    ValueError: On incorrect data type for image or masks.\n  """"""\n  if image.dtype != np.uint8:\n    raise ValueError(\'`image` not of type np.uint8\')\n  if mask.dtype != np.uint8:\n    raise ValueError(\'`mask` not of type np.uint8\')\n  if np.any(np.logical_and(mask != 1, mask != 0)):\n    raise ValueError(\'`mask` elements should be in [0, 1]\')\n  rgb = ImageColor.getrgb(color)\n  pil_image = Image.fromarray(image)\n\n  solid_color = np.expand_dims(\n      np.ones_like(mask), axis=2) * np.reshape(list(rgb), [1, 1, 3])\n  pil_solid_color = Image.fromarray(np.uint8(solid_color)).convert(\'RGBA\')\n  pil_mask = Image.fromarray(np.uint8(255.0*alpha*mask)).convert(\'L\')\n  pil_image = Image.composite(pil_solid_color, pil_image, pil_mask)\n  np.copyto(image, np.array(pil_image.convert(\'RGB\')))\n\n\ndef visualize_boxes_and_labels_on_image_array(image,\n                                              boxes,\n                                              classes,\n                                              scores,\n                                              category_index,\n                                              instance_masks=None,\n                                              keypoints=None,\n                                              use_normalized_coordinates=False,\n                                              max_boxes_to_draw=20,\n                                              min_score_thresh=.5,\n                                              agnostic_mode=False,\n                                              line_thickness=4):\n  """"""Overlay labeled boxes on an image with formatted scores and label names.\n\n  This function groups boxes that correspond to the same location\n  and creates a display string for each detection and overlays these\n  on the image. Note that this function modifies the image in place, and returns\n  that same image.\n\n  Args:\n    image: uint8 numpy array with shape (img_height, img_width, 3)\n    boxes: a numpy array of shape [N, 4]\n    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n      and match the keys in the label map.\n    scores: a numpy array of shape [N] or None.  If scores=None, then\n      this function assumes that the boxes to be plotted are groundtruth\n      boxes and plot all boxes as black with no classes or scores.\n    category_index: a dict containing category dictionaries (each holding\n      category index `id` and category name `name`) keyed by category indices.\n    instance_masks: a numpy array of shape [N, image_height, image_width], can\n      be None\n    keypoints: a numpy array of shape [N, num_keypoints, 2], can\n      be None\n    use_normalized_coordinates: whether boxes is to be interpreted as\n      normalized coordinates or not.\n    max_boxes_to_draw: maximum number of boxes to visualize.  If None, draw\n      all boxes.\n    min_score_thresh: minimum score threshold for a box to be visualized\n    agnostic_mode: boolean (default: False) controlling whether to evaluate in\n      class-agnostic mode or not.  This mode will display scores but ignore\n      classes.\n    line_thickness: integer (default: 4) controlling line width of the boxes.\n\n  Returns:\n    uint8 numpy array with shape (img_height, img_width, 3) with overlaid boxes.\n  """"""\n  # Create a display string (and color) for every box location, group any boxes\n  # that correspond to the same location.\n  box_to_display_str_map = collections.defaultdict(list)\n  box_to_color_map = collections.defaultdict(str)\n  box_to_instance_masks_map = {}\n  box_to_keypoints_map = collections.defaultdict(list)\n  if not max_boxes_to_draw:\n    max_boxes_to_draw = boxes.shape[0]\n  for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n    if scores is None or scores[i] > min_score_thresh:\n      box = tuple(boxes[i].tolist())\n      if instance_masks is not None:\n        box_to_instance_masks_map[box] = instance_masks[i]\n      if keypoints is not None:\n        box_to_keypoints_map[box].extend(keypoints[i])\n      if scores is None:\n        box_to_color_map[box] = \'black\'\n      else:\n        if not agnostic_mode:\n          if classes[i] in category_index.keys():\n            class_name = category_index[classes[i]][\'name\']\n          else:\n            class_name = \'N/A\'\n          display_str = \'{}: {}%\'.format(\n              class_name,\n              int(100*scores[i]))\n        else:\n          display_str = \'score: {}%\'.format(int(100 * scores[i]))\n        box_to_display_str_map[box].append(display_str)\n        if agnostic_mode:\n          box_to_color_map[box] = \'DarkOrange\'\n        else:\n          box_to_color_map[box] = STANDARD_COLORS[\n              classes[i] % len(STANDARD_COLORS)]\n\n  # Draw all boxes onto image.\n  for box, color in box_to_color_map.items():\n    ymin, xmin, ymax, xmax = box\n    if instance_masks is not None:\n      draw_mask_on_image_array(\n          image,\n          box_to_instance_masks_map[box],\n          color=color\n      )\n    draw_bounding_box_on_image_array(\n        image,\n        ymin,\n        xmin,\n        ymax,\n        xmax,\n        color=color,\n        thickness=line_thickness,\n        display_str_list=box_to_display_str_map[box],\n        use_normalized_coordinates=use_normalized_coordinates)\n    if keypoints is not None:\n      draw_keypoints_on_image_array(\n          image,\n          box_to_keypoints_map[box],\n          color=color,\n          radius=line_thickness / 2,\n          use_normalized_coordinates=use_normalized_coordinates)\n\n  return image\n\n\ndef add_cdf_image_summary(values, name):\n  """"""Adds a tf.summary.image for a CDF plot of the values.\n\n  Normalizes `values` such that they sum to 1, plots the cumulative distribution\n  function and creates a tf image summary.\n\n  Args:\n    values: a 1-D float32 tensor containing the values.\n    name: name for the image summary.\n  """"""\n  def cdf_plot(values):\n    """"""Numpy function to plot CDF.""""""\n    normalized_values = values / np.sum(values)\n    sorted_values = np.sort(normalized_values)\n    cumulative_values = np.cumsum(sorted_values)\n    fraction_of_examples = (np.arange(cumulative_values.size, dtype=np.float32)\n                            / cumulative_values.size)\n    fig = plt.figure(frameon=False)\n    ax = fig.add_subplot(\'111\')\n    ax.plot(fraction_of_examples, cumulative_values)\n    ax.set_ylabel(\'cumulative normalized values\')\n    ax.set_xlabel(\'fraction of examples\')\n    fig.canvas.draw()\n    width, height = fig.get_size_inches() * fig.get_dpi()\n    image = np.fromstring(fig.canvas.tostring_rgb(), dtype=\'uint8\').reshape(\n        1, height, width, 3)\n    return image\n  cdf_plot = tf.py_func(cdf_plot, [values], tf.uint8)\n  tf.summary.image(name, cdf_plot)\n'"
