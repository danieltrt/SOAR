file_path,api_count,code
cache.py,0,"b'########################################################################\n#\n# Cache-wrapper for a function or class.\n#\n# Save the result of calling a function or creating an object-instance\n# to harddisk. This is used to persist the data so it can be reloaded\n# very quickly and easily.\n#\n# Implemented in Python 3.5\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2016 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport os\nimport pickle\nimport numpy as np\n\n########################################################################\n\n\ndef cache(cache_path, fn, *args, **kwargs):\n    """"""\n    Cache-wrapper for a function or class. If the cache-file exists\n    then the data is reloaded and returned, otherwise the function\n    is called and the result is saved to cache. The fn-argument can\n    also be a class instead, in which case an object-instance is\n    created and saved to the cache-file.\n\n    :param cache_path:\n        File-path for the cache-file.\n\n    :param fn:\n        Function or class to be called.\n\n    :param args:\n        Arguments to the function or class-init.\n\n    :param kwargs:\n        Keyword arguments to the function or class-init.\n\n    :return:\n        The result of calling the function or creating the object-instance.\n    """"""\n\n    # If the cache-file exists.\n    if os.path.exists(cache_path):\n        # Load the cached data from the file.\n        with open(cache_path, mode=\'rb\') as file:\n            obj = pickle.load(file)\n\n        print(""- Data loaded from cache-file: "" + cache_path)\n    else:\n        # The cache-file does not exist.\n\n        # Call the function / class-init with the supplied arguments.\n        obj = fn(*args, **kwargs)\n\n        # Save the data to a cache-file.\n        with open(cache_path, mode=\'wb\') as file:\n            pickle.dump(obj, file)\n\n        print(""- Data saved to cache-file: "" + cache_path)\n\n    return obj\n\n\n########################################################################\n\n\ndef convert_numpy2pickle(in_path, out_path):\n    """"""\n    Convert a numpy-file to pickle-file.\n\n    The first version of the cache-function used numpy for saving the data.\n    Instead of re-calculating all the data, you can just convert the\n    cache-file using this function.\n\n    :param in_path:\n        Input file in numpy-format written using numpy.save().\n\n    :param out_path:\n        Output file written as a pickle-file.\n\n    :return:\n        Nothing.\n    """"""\n\n    # Load the data using numpy.\n    data = np.load(in_path)\n\n    # Save the data using pickle.\n    with open(out_path, mode=\'wb\') as file:\n        pickle.dump(data, file)\n\n\n########################################################################\n\nif __name__ == \'__main__\':\n    # This is a short example of using a cache-file.\n\n    # This is the function that will only get called if the result\n    # is not already saved in the cache-file. This would normally\n    # be a function that takes a long time to compute, or if you\n    # need persistent data for some other reason.\n    def expensive_function(a, b):\n        return a * b\n\n    print(\'Computing expensive_function() ...\')\n\n    # Either load the result from a cache-file if it already exists,\n    # otherwise calculate expensive_function(a=123, b=456) and\n    # save the result to the cache-file for next time.\n    result = cache(cache_path=\'cache_expensive_function.pkl\',\n                   fn=expensive_function, a=123, b=456)\n\n    print(\'result =\', result)\n\n    # Newline.\n    print()\n\n    # This is another example which saves an object to a cache-file.\n\n    # We want to cache an object-instance of this class.\n    # The motivation is to do an expensive computation only once,\n    # or if we need to persist the data for some other reason.\n    class ExpensiveClass:\n        def __init__(self, c, d):\n            self.c = c\n            self.d = d\n            self.result = c * d\n\n        def print_result(self):\n            print(\'c =\', self.c)\n            print(\'d =\', self.d)\n            print(\'result = c * d =\', self.result)\n\n    print(\'Creating object from ExpensiveClass() ...\')\n\n    # Either load the object from a cache-file if it already exists,\n    # otherwise make an object-instance ExpensiveClass(c=123, d=456)\n    # and save the object to the cache-file for the next time.\n    obj = cache(cache_path=\'cache_ExpensiveClass.pkl\',\n                fn=ExpensiveClass, c=123, d=456)\n\n    obj.print_result()\n\n########################################################################\n'"
cifar10.py,0,"b'########################################################################\n#\n# Functions for downloading the CIFAR-10 data-set from the internet\n# and loading it into memory.\n#\n# Implemented in Python 3.5\n#\n# Usage:\n# 1) Set the variable data_path with the desired storage path.\n# 2) Call maybe_download_and_extract() to download the data-set\n#    if it is not already located in the given data_path.\n# 3) Call load_class_names() to get an array of the class-names.\n# 4) Call load_training_data() and load_test_data() to get\n#    the images, class-numbers and one-hot encoded class-labels\n#    for the training-set and test-set.\n# 5) Use the returned data in your own program.\n#\n# Format:\n# The images for the training- and test-sets are returned as 4-dim numpy\n# arrays each with the shape: [image_number, height, width, channel]\n# where the individual pixels are floats between 0.0 and 1.0.\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2016 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport numpy as np\nimport pickle\nimport os\nimport download\nfrom dataset import one_hot_encoded\n\n########################################################################\n\n# Directory where you want to download and save the data-set.\n# Set this before you start calling any of the functions below.\ndata_path = ""data/CIFAR-10/""\n\n# URL for the data-set on the internet.\ndata_url = ""https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz""\n\n########################################################################\n# Various constants for the size of the images.\n# Use these constants in your own program.\n\n# Width and height of each image.\nimg_size = 32\n\n# Number of channels in each image, 3 channels: Red, Green, Blue.\nnum_channels = 3\n\n# Length of an image when flattened to a 1-dim array.\nimg_size_flat = img_size * img_size * num_channels\n\n# Number of classes.\nnum_classes = 10\n\n########################################################################\n# Various constants used to allocate arrays of the correct size.\n\n# Number of files for the training-set.\n_num_files_train = 5\n\n# Number of images for each batch-file in the training-set.\n_images_per_file = 10000\n\n# Total number of images in the training-set.\n# This is used to pre-allocate arrays for efficiency.\n_num_images_train = _num_files_train * _images_per_file\n\n########################################################################\n# Private functions for downloading, unpacking and loading data-files.\n\n\ndef _get_file_path(filename=""""):\n    """"""\n    Return the full path of a data-file for the data-set.\n\n    If filename=="""" then return the directory of the files.\n    """"""\n\n    return os.path.join(data_path, ""cifar-10-batches-py/"", filename)\n\n\ndef _unpickle(filename):\n    """"""\n    Unpickle the given file and return the data.\n\n    Note that the appropriate dir-name is prepended the filename.\n    """"""\n\n    # Create full path for the file.\n    file_path = _get_file_path(filename)\n\n    print(""Loading data: "" + file_path)\n\n    with open(file_path, mode=\'rb\') as file:\n        # In Python 3.X it is important to set the encoding,\n        # otherwise an exception is raised here.\n        data = pickle.load(file, encoding=\'bytes\')\n\n    return data\n\n\ndef _convert_images(raw):\n    """"""\n    Convert images from the CIFAR-10 format and\n    return a 4-dim array with shape: [image_number, height, width, channel]\n    where the pixels are floats between 0.0 and 1.0.\n    """"""\n\n    # Convert the raw images from the data-files to floating-points.\n    raw_float = np.array(raw, dtype=float) / 255.0\n\n    # Reshape the array to 4-dimensions.\n    images = raw_float.reshape([-1, num_channels, img_size, img_size])\n\n    # Reorder the indices of the array.\n    images = images.transpose([0, 2, 3, 1])\n\n    return images\n\n\ndef _load_data(filename):\n    """"""\n    Load a pickled data-file from the CIFAR-10 data-set\n    and return the converted images (see above) and the class-number\n    for each image.\n    """"""\n\n    # Load the pickled data-file.\n    data = _unpickle(filename)\n\n    # Get the raw images.\n    raw_images = data[b\'data\']\n\n    # Get the class-numbers for each image. Convert to numpy-array.\n    cls = np.array(data[b\'labels\'])\n\n    # Convert the images.\n    images = _convert_images(raw_images)\n\n    return images, cls\n\n\n########################################################################\n# Public functions that you may call to download the data-set from\n# the internet and load the data into memory.\n\n\ndef maybe_download_and_extract():\n    """"""\n    Download and extract the CIFAR-10 data-set if it doesn\'t already exist\n    in data_path (set this variable first to the desired path).\n    """"""\n\n    download.maybe_download_and_extract(url=data_url, download_dir=data_path)\n\n\ndef load_class_names():\n    """"""\n    Load the names for the classes in the CIFAR-10 data-set.\n\n    Returns a list with the names. Example: names[3] is the name\n    associated with class-number 3.\n    """"""\n\n    # Load the class-names from the pickled file.\n    raw = _unpickle(filename=""batches.meta"")[b\'label_names\']\n\n    # Convert from binary strings.\n    names = [x.decode(\'utf-8\') for x in raw]\n\n    return names\n\n\ndef load_training_data():\n    """"""\n    Load all the training-data for the CIFAR-10 data-set.\n\n    The data-set is split into 5 data-files which are merged here.\n\n    Returns the images, class-numbers and one-hot encoded class-labels.\n    """"""\n\n    # Pre-allocate the arrays for the images and class-numbers for efficiency.\n    images = np.zeros(shape=[_num_images_train, img_size, img_size, num_channels], dtype=float)\n    cls = np.zeros(shape=[_num_images_train], dtype=int)\n\n    # Begin-index for the current batch.\n    begin = 0\n\n    # For each data-file.\n    for i in range(_num_files_train):\n        # Load the images and class-numbers from the data-file.\n        images_batch, cls_batch = _load_data(filename=""data_batch_"" + str(i + 1))\n\n        # Number of images in this batch.\n        num_images = len(images_batch)\n\n        # End-index for the current batch.\n        end = begin + num_images\n\n        # Store the images into the array.\n        images[begin:end, :] = images_batch\n\n        # Store the class-numbers into the array.\n        cls[begin:end] = cls_batch\n\n        # The begin-index for the next batch is the current end-index.\n        begin = end\n\n    return images, cls, one_hot_encoded(class_numbers=cls, num_classes=num_classes)\n\n\ndef load_test_data():\n    """"""\n    Load all the test-data for the CIFAR-10 data-set.\n\n    Returns the images, class-numbers and one-hot encoded class-labels.\n    """"""\n\n    images, cls = _load_data(filename=""test_batch"")\n\n    return images, cls, one_hot_encoded(class_numbers=cls, num_classes=num_classes)\n\n########################################################################\n'"
coco.py,0,"b'########################################################################\n#\n# Functions for downloading the COCO data-set from the internet\n# and loading it into memory. This data-set contains images and\n# various associated data such as text-captions describing the images.\n#\n# http://cocodataset.org\n#\n# Implemented in Python 3.6\n#\n# Usage:\n# 1) Call set_data_dir() to set the desired storage directory.\n# 2) Call maybe_download_and_extract() to download the data-set\n#    if it is not already located in the given data_dir.\n# 3) Call load_records(train=True) and load_records(train=False)\n#    to load the data-records for the training- and validation sets.\n# 5) Use the returned data in your own program.\n#\n# Format:\n# The COCO data-set contains a large number of images and various\n# data for each image stored in a JSON-file.\n# Functionality is provided for getting a list of image-filenames\n# (but not actually loading the images) along with their associated\n# data such as text-captions describing the contents of the images.\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2018 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport json\nimport os\nimport download\nfrom cache import cache\n\n########################################################################\n\n# Directory where you want to download and save the data-set.\n# Set this before you start calling any of the functions below.\n# Use the function set_data_dir() to also update train_dir and val_dir.\ndata_dir = ""data/coco/""\n\n# Sub-directories for the training- and validation-sets.\ntrain_dir = ""data/coco/train2017""\nval_dir = ""data/coco/val2017""\n\n# Base-URL for the data-sets on the internet.\ndata_url = ""http://images.cocodataset.org/""\n\n\n########################################################################\n# Private helper-functions.\n\ndef _load_records(train=True):\n    """"""\n    Load the image-filenames and captions\n    for either the training-set or the validation-set.\n    """"""\n\n    if train:\n        # Training-set.\n        filename = ""captions_train2017.json""\n    else:\n        # Validation-set.\n        filename = ""captions_val2017.json""\n\n    # Full path for the data-file.\n    path = os.path.join(data_dir, ""annotations"", filename)\n\n    # Load the file.\n    with open(path, ""r"", encoding=""utf-8"") as file:\n        data_raw = json.load(file)\n\n    # Convenience variables.\n    images = data_raw[\'images\']\n    annotations = data_raw[\'annotations\']\n\n    # Initialize the dict for holding our data.\n    # The lookup-key is the image-id.\n    records = dict()\n\n    # Collect all the filenames for the images.\n    for image in images:\n        # Get the id and filename for this image.\n        image_id = image[\'id\']\n        filename = image[\'file_name\']\n\n        # Initialize a new data-record.\n        record = dict()\n\n        # Set the image-filename in the data-record.\n        record[\'filename\'] = filename\n\n        # Initialize an empty list of image-captions\n        # which will be filled further below.\n        record[\'captions\'] = list()\n\n        # Save the record using the the image-id as the lookup-key.\n        records[image_id] = record\n\n    # Collect all the captions for the images.\n    for ann in annotations:\n        # Get the id and caption for an image.\n        image_id = ann[\'image_id\']\n        caption = ann[\'caption\']\n\n        # Lookup the data-record for this image-id.\n        # This data-record should already exist from the loop above.\n        record = records[image_id]\n\n        # Append the current caption to the list of captions in the\n        # data-record that was initialized in the loop above.\n        record[\'captions\'].append(caption)\n\n    # Convert the records-dict to a list of tuples.\n    records_list = [(key, record[\'filename\'], record[\'captions\'])\n                    for key, record in sorted(records.items())]\n\n    # Convert the list of tuples to separate tuples with the data.\n    ids, filenames, captions = zip(*records_list)\n\n    return ids, filenames, captions\n\n\n########################################################################\n# Public functions that you may call to download the data-set from\n# the internet and load the data into memory.\n\n\ndef set_data_dir(new_data_dir):\n    """"""\n    Set the base-directory for data-files and then\n    set the sub-dirs for training and validation data.\n    """"""\n\n    # Ensure we update the global variables.\n    global data_dir, train_dir, val_dir\n\n    data_dir = new_data_dir\n    train_dir = os.path.join(new_data_dir, ""train2017"")\n    val_dir = os.path.join(new_data_dir, ""val2017"")\n\n\ndef maybe_download_and_extract():\n    """"""\n    Download and extract the COCO data-set if the data-files don\'t\n    already exist in data_dir.\n    """"""\n\n    # Filenames to download from the internet.\n    filenames = [""zips/train2017.zip"", ""zips/val2017.zip"",\n                 ""annotations/annotations_trainval2017.zip""]\n\n    # Download these files.\n    for filename in filenames:\n        # Create the full URL for the given file.\n        url = data_url + filename\n\n        print(""Downloading "" + url)\n\n        download.maybe_download_and_extract(url=url, download_dir=data_dir)\n\n\ndef load_records(train=True):\n    """"""\n    Load the data-records for the data-set. This returns the image ids,\n    filenames and text-captions for either the training-set or validation-set.\n    \n    This wraps _load_records() above with a cache, so if the cache-file already\n    exists then it is loaded instead of processing the original data-file.\n    \n    :param train:\n        Bool whether to load the training-set (True) or validation-set (False).\n\n    :return: \n        ids, filenames, captions for the images in the data-set.\n    """"""\n\n    if train:\n        # Cache-file for the training-set data.\n        cache_filename = ""records_train.pkl""\n    else:\n        # Cache-file for the validation-set data.\n        cache_filename = ""records_val.pkl""\n\n    # Path for the cache-file.\n    cache_path = os.path.join(data_dir, cache_filename)\n\n    # If the data-records already exist in a cache-file then load it,\n    # otherwise call the _load_records() function and save its\n    # return-values to the cache-file so it can be loaded the next time.\n    records = cache(cache_path=cache_path,\n                    fn=_load_records,\n                    train=train)\n\n    return records\n\n########################################################################\n'"
convert.py,0,"b'#!/usr/bin/python\n\n########################################################################\n#\n# Function and script for converting videos to images.\n#\n# This can be run as a script in a Linux shell by typing:\n#\n#    python convert.py\n#\n# Or by running:\n#\n#    chmod +x convert.py\n#    ./convert.py\n#\n# Requires the program avconv to be installed.\n# Tested with avconv v. 9.18-6 on Linux Mint.\n#\n# Implemented in Python 3.5 (seems to work in Python 2.7 as well)\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2016 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport os\nimport subprocess\nimport argparse\n\n########################################################################\n\n\ndef video2images(in_dir, out_dir, crop_size, out_size, framerate, video_exts):\n    """"""\n    Convert videos to images. The videos are located in the directory in_dir\n    and all its sub-directories which are processed recursively. The directory\n    structure is replicated to out_dir where the jpeg-images are saved.\n\n    :param in_dir:\n        Input directory for the videos e.g. ""/home/magnus/video/""\n        All sub-directories are processed recursively.\n\n    :param out_dir:\n        Output directory for the images e.g. ""/home/magnus/video-images/""\n\n    :param crop_size:\n        Integer. First the videos are cropped to this width and height.\n\n    :param out_size:\n        Integer. After cropping, the videos are resized to this width and height.\n\n    :param framerate:\n        Integer. Number of frames to grab per second.\n\n    :param video_exts:\n        Tuple of strings. Extensions for video-files e.g. (\'.mts\', \'.mp4\')\n        Not case-sensitive.\n\n    :return:\n        Nothing.\n    """"""\n\n    # Convert all video extensions to lower-case.\n    video_exts = tuple(ext.lower() for ext in video_exts)\n\n    # Number of videos processed.\n    video_count = 0\n\n    # Process all the sub-dirs recursively.\n    for current_dir, dir_names, file_names in os.walk(in_dir):\n        # The current dir relative to the input directory.\n        relative_path = os.path.relpath(current_dir, in_dir)\n\n        # Name of the new directory for the output images.\n        new_dir = os.path.join(out_dir, relative_path)\n\n        # If the output-directory does not exist, then create it.\n        if not os.path.exists(new_dir):\n            os.makedirs(new_dir)\n\n        # For all the files in the current directory.\n        for file_name in file_names:\n            # If the file has a valid video-extension. Compare lower-cases.\n            if file_name.lower().endswith(video_exts):\n                # File-path for the input video.\n                in_file = os.path.join(current_dir, file_name)\n\n                # Split the file-path in root and extension.\n                file_root, file_ext = os.path.splitext(file_name)\n\n                # Create the template file-name for the output images.\n                new_file_name = file_root + ""-%4d.jpg""\n\n                # Complete file-path for the output images incl. all sub-dirs.\n                new_file_path = os.path.join(new_dir, new_file_name)\n\n                # Clean up the path by removing e.g. ""/./""\n                new_file_path = os.path.normpath(new_file_path)\n\n                # Print status.\n                print(""Converting video to images:"")\n                print(""- Input video:   {0}"".format(in_file))\n                print(""- Output images: {0}"".format(new_file_path))\n\n                # Command to be run in the shell for the video-conversion tool.\n                cmd = ""avconv -i {0} -r {1} -vf crop={2}:{2} -vf scale={3}:{3} -qscale 2 {4}""\n\n                # Fill in the arguments for the command-line.\n                cmd = cmd.format(in_file, framerate, crop_size, out_size, new_file_path)\n\n                # Run the command-line in a shell.\n                subprocess.call(cmd, shell=True)\n\n                # Increase the number of videos processed.\n                video_count += 1\n\n                # Print newline.\n                print()\n\n    print(""Number of videos converted: {0}"".format(video_count))\n\n\n########################################################################\n# This script allows you to run the video-conversion from the command-line.\n\nif __name__ == ""__main__"":\n    # Argument description.\n    desc = ""Convert videos to images. "" \\\n           ""Recursively processes all sub-dirs of INDIR "" \\\n           ""and replicates the dir-structure to OUTDIR. "" \\\n           ""The video is first cropped to CROP:CROP pixels, "" \\\n           ""then resized to SIZE:SIZE pixels and written as a jpeg-file. ""\n\n    # Create the argument parser.\n    parser = argparse.ArgumentParser(description=desc)\n\n    # Add arguments to the parser.\n    parser.add_argument(""--indir"", required=True,\n                        help=""input directory where videos are located"")\n\n    parser.add_argument(""--outdir"", required=True,\n                        help=""output directory where images will be saved"")\n\n    parser.add_argument(""--crop"", required=True, type=int,\n                        help=""the input videos are first cropped to CROP:CROP pixels"")\n\n    parser.add_argument(""--size"", required=True, type=int,\n                        help=""the input videos are then resized to SIZE:SIZE pixels"")\n\n    parser.add_argument(""--rate"", required=False, type=int, default=5,\n                        help=""the number of frames to convert per second"")\n\n    parser.add_argument(""--exts"", required=False, nargs=""+"",\n                        help=""list of extensions for video-files e.g. .mts .mp4"")\n\n    # Parse the command-line arguments.\n    args = parser.parse_args()\n\n    # Get the arguments.\n    in_dir = args.indir\n    out_dir = args.outdir\n    crop_size = args.crop\n    out_size = args.size\n    framerate = args.rate\n    video_exts = args.exts\n\n    if video_exts is None:\n        # Default extensions for video-files.\n        video_exts = ("".MTS"", "".mp4"")\n    else:\n        # A list of strings is provided as a command-line argument, but we\n        # need a tuple instead of a list, so convert it to a tuple.\n        video_exts = tuple(video_exts)\n\n    # Print the arguments.\n    print(""Convert videos to images."")\n    print(""- Input dir: "" + in_dir)\n    print(""- Output dir: "" + out_dir)\n    print(""- Crop width and height: {0}"".format(crop_size))\n    print(""- Resize width and height: {0}"".format(out_size))\n    print(""- Frame-rate: {0}"".format(framerate))\n    print(""- Video extensions: {0}"".format(video_exts))\n    print()\n\n    # Perform the conversions.\n    video2images(in_dir=in_dir, out_dir=out_dir,\n                 crop_size=crop_size, out_size=out_size,\n                 framerate=framerate, video_exts=video_exts)\n\n########################################################################\n'"
dataset.py,0,"b'########################################################################\n#\n# Class for creating a data-set consisting of all files in a directory.\n#\n# Example usage is shown in the file knifey.py and Tutorial #09.\n#\n# Implemented in Python 3.5\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2016 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport numpy as np\nimport os\nimport shutil\nfrom cache import cache\n\n########################################################################\n\n\ndef one_hot_encoded(class_numbers, num_classes=None):\n    """"""\n    Generate the One-Hot encoded class-labels from an array of integers.\n\n    For example, if class_number=2 and num_classes=4 then\n    the one-hot encoded label is the float array: [0. 0. 1. 0.]\n\n    :param class_numbers:\n        Array of integers with class-numbers.\n        Assume the integers are from zero to num_classes-1 inclusive.\n\n    :param num_classes:\n        Number of classes. If None then use max(class_numbers)+1.\n\n    :return:\n        2-dim array of shape: [len(class_numbers), num_classes]\n    """"""\n\n    # Find the number of classes if None is provided.\n    # Assumes the lowest class-number is zero.\n    if num_classes is None:\n        num_classes = np.max(class_numbers) + 1\n\n    return np.eye(num_classes, dtype=float)[class_numbers]\n\n\n########################################################################\n\n\nclass DataSet:\n    def __init__(self, in_dir, exts=\'.jpg\'):\n        """"""\n        Create a data-set consisting of the filenames in the given directory\n        and sub-dirs that match the given filename-extensions.\n\n        For example, the knifey-spoony data-set (see knifey.py) has the\n        following dir-structure:\n\n        knifey-spoony/forky/\n        knifey-spoony/knifey/\n        knifey-spoony/spoony/\n        knifey-spoony/forky/test/\n        knifey-spoony/knifey/test/\n        knifey-spoony/spoony/test/\n\n        This means there are 3 classes called: forky, knifey, and spoony.\n\n        If we set in_dir = ""knifey-spoony/"" and create a new DataSet-object\n        then it will scan through these directories and create a training-set\n        and test-set for each of these classes.\n\n        The training-set will contain a list of all the *.jpg filenames\n        in the following directories:\n\n        knifey-spoony/forky/\n        knifey-spoony/knifey/\n        knifey-spoony/spoony/\n\n        The test-set will contain a list of all the *.jpg filenames\n        in the following directories:\n\n        knifey-spoony/forky/test/\n        knifey-spoony/knifey/test/\n        knifey-spoony/spoony/test/\n\n        See the TensorFlow Tutorial #09 for a usage example.\n\n        :param in_dir:\n            Root-dir for the files in the data-set.\n            This would be \'knifey-spoony/\' in the example above.\n\n        :param exts:\n            String or tuple of strings with valid filename-extensions.\n            Not case-sensitive.\n\n        :return:\n            Object instance.\n        """"""\n\n        # Extend the input directory to the full path.\n        in_dir = os.path.abspath(in_dir)\n\n        # Input directory.\n        self.in_dir = in_dir\n\n        # Convert all file-extensions to lower-case.\n        self.exts = tuple(ext.lower() for ext in exts)\n\n        # Names for the classes.\n        self.class_names = []\n\n        # Filenames for all the files in the training-set.\n        self.filenames = []\n\n        # Filenames for all the files in the test-set.\n        self.filenames_test = []\n\n        # Class-number for each file in the training-set.\n        self.class_numbers = []\n\n        # Class-number for each file in the test-set.\n        self.class_numbers_test = []\n\n        # Total number of classes in the data-set.\n        self.num_classes = 0\n\n        # For all files/dirs in the input directory.\n        for name in os.listdir(in_dir):\n            # Full path for the file / dir.\n            current_dir = os.path.join(in_dir, name)\n\n            # If it is a directory.\n            if os.path.isdir(current_dir):\n                # Add the dir-name to the list of class-names.\n                self.class_names.append(name)\n\n                # Training-set.\n\n                # Get all the valid filenames in the dir (not sub-dirs).\n                filenames = self._get_filenames(current_dir)\n\n                # Append them to the list of all filenames for the training-set.\n                self.filenames.extend(filenames)\n\n                # The class-number for this class.\n                class_number = self.num_classes\n\n                # Create an array of class-numbers.\n                class_numbers = [class_number] * len(filenames)\n\n                # Append them to the list of all class-numbers for the training-set.\n                self.class_numbers.extend(class_numbers)\n\n                # Test-set.\n\n                # Get all the valid filenames in the sub-dir named \'test\'.\n                filenames_test = self._get_filenames(os.path.join(current_dir, \'test\'))\n\n                # Append them to the list of all filenames for the test-set.\n                self.filenames_test.extend(filenames_test)\n\n                # Create an array of class-numbers.\n                class_numbers = [class_number] * len(filenames_test)\n\n                # Append them to the list of all class-numbers for the test-set.\n                self.class_numbers_test.extend(class_numbers)\n\n                # Increase the total number of classes in the data-set.\n                self.num_classes += 1\n\n    def _get_filenames(self, dir):\n        """"""\n        Create and return a list of filenames with matching extensions in the given directory.\n\n        :param dir:\n            Directory to scan for files. Sub-dirs are not scanned.\n\n        :return:\n            List of filenames. Only filenames. Does not include the directory.\n        """"""\n\n        # Initialize empty list.\n        filenames = []\n\n        # If the directory exists.\n        if os.path.exists(dir):\n            # Get all the filenames with matching extensions.\n            for filename in os.listdir(dir):\n                if filename.lower().endswith(self.exts):\n                    filenames.append(filename)\n\n        return filenames\n\n    def get_paths(self, test=False):\n        """"""\n        Get the full paths for the files in the data-set.\n\n        :param test:\n            Boolean. Return the paths for the test-set (True) or training-set (False).\n\n        :return:\n            Iterator with strings for the path-names.\n        """"""\n\n        if test:\n            # Use the filenames and class-numbers for the test-set.\n            filenames = self.filenames_test\n            class_numbers = self.class_numbers_test\n\n            # Sub-dir for test-set.\n            test_dir = ""test/""\n        else:\n            # Use the filenames and class-numbers for the training-set.\n            filenames = self.filenames\n            class_numbers = self.class_numbers\n\n            # Don\'t use a sub-dir for test-set.\n            test_dir = """"\n\n        for filename, cls in zip(filenames, class_numbers):\n            # Full path-name for the file.\n            path = os.path.join(self.in_dir, self.class_names[cls], test_dir, filename)\n\n            yield path\n\n    def get_training_set(self):\n        """"""\n        Return the list of paths for the files in the training-set,\n        and the list of class-numbers as integers,\n        and the class-numbers as one-hot encoded arrays.\n        """"""\n\n        return list(self.get_paths()), \\\n               np.asarray(self.class_numbers), \\\n               one_hot_encoded(class_numbers=self.class_numbers,\n                               num_classes=self.num_classes)\n\n    def get_test_set(self):\n        """"""\n        Return the list of paths for the files in the test-set,\n        and the list of class-numbers as integers,\n        and the class-numbers as one-hot encoded arrays.\n        """"""\n\n        return list(self.get_paths(test=True)), \\\n               np.asarray(self.class_numbers_test), \\\n               one_hot_encoded(class_numbers=self.class_numbers_test,\n                               num_classes=self.num_classes)\n\n    def copy_files(self, train_dir, test_dir):\n        """"""\n        Copy all the files in the training-set to train_dir\n        and copy all the files in the test-set to test_dir.\n\n        For example, the normal directory structure for the\n        different classes in the training-set is:\n\n        knifey-spoony/forky/\n        knifey-spoony/knifey/\n        knifey-spoony/spoony/\n\n        Normally the test-set is a sub-dir of the training-set:\n\n        knifey-spoony/forky/test/\n        knifey-spoony/knifey/test/\n        knifey-spoony/spoony/test/\n\n        But some APIs use another dir-structure for the training-set:\n        \n        knifey-spoony/train/forky/\n        knifey-spoony/train/knifey/\n        knifey-spoony/train/spoony/\n\n        and for the test-set:\n        \n        knifey-spoony/test/forky/\n        knifey-spoony/test/knifey/\n        knifey-spoony/test/spoony/\n\n        :param train_dir: Directory for the training-set e.g. \'knifey-spoony/train/\'\n        :param test_dir: Directory for the test-set e.g. \'knifey-spoony/test/\'\n        :return: Nothing. \n        """"""\n\n        # Helper-function for actually copying the files.\n        def _copy_files(src_paths, dst_dir, class_numbers):\n\n            # Create a list of dirs for each class, e.g.:\n            # [\'knifey-spoony/test/forky/\',\n            #  \'knifey-spoony/test/knifey/\',\n            #  \'knifey-spoony/test/spoony/\']\n            class_dirs = [os.path.join(dst_dir, class_name + ""/"")\n                          for class_name in self.class_names]\n\n            # Check if each class-directory exists, otherwise create it.\n            for dir in class_dirs:\n                if not os.path.exists(dir):\n                    os.makedirs(dir)\n\n            # For all the file-paths and associated class-numbers,\n            # copy the file to the destination dir for that class.\n            for src, cls in zip(src_paths, class_numbers):\n                shutil.copy(src=src, dst=class_dirs[cls])\n\n        # Copy the files for the training-set.\n        _copy_files(src_paths=self.get_paths(test=False),\n                    dst_dir=train_dir,\n                    class_numbers=self.class_numbers)\n\n        print(""- Copied training-set to:"", train_dir)\n\n        # Copy the files for the test-set.\n        _copy_files(src_paths=self.get_paths(test=True),\n                    dst_dir=test_dir,\n                    class_numbers=self.class_numbers_test)\n\n        print(""- Copied test-set to:"", test_dir)\n\n\n########################################################################\n\n\ndef load_cached(cache_path, in_dir):\n    """"""\n    Wrapper-function for creating a DataSet-object, which will be\n    loaded from a cache-file if it already exists, otherwise a new\n    object will be created and saved to the cache-file.\n\n    This is useful if you need to ensure the ordering of the\n    filenames is consistent every time you load the data-set,\n    for example if you use the DataSet-object in combination\n    with Transfer Values saved to another cache-file, see e.g.\n    Tutorial #09 for an example of this.\n\n    :param cache_path:\n        File-path for the cache-file.\n\n    :param in_dir:\n        Root-dir for the files in the data-set.\n        This is an argument for the DataSet-init function.\n\n    :return:\n        The DataSet-object.\n    """"""\n\n    print(""Creating dataset from the files in: "" + in_dir)\n\n    # If the object-instance for DataSet(in_dir=data_dir) already\n    # exists in the cache-file then reload it, otherwise create\n    # an object instance and save it to the cache-file for next time.\n    dataset = cache(cache_path=cache_path,\n                    fn=DataSet, in_dir=in_dir)\n\n    return dataset\n\n\n########################################################################\n'"
download.py,0,"b'########################################################################\n#\n# Functions for downloading and extracting data-files from the internet.\n#\n# Implemented in Python 3.5\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2016 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport sys\nimport os\nimport urllib.request\nimport tarfile\nimport zipfile\n\n########################################################################\n\n\ndef _print_download_progress(count, block_size, total_size):\n    """"""\n    Function used for printing the download progress.\n    Used as a call-back function in maybe_download_and_extract().\n    """"""\n\n    # Percentage completion.\n    pct_complete = float(count * block_size) / total_size\n\n    # Limit it because rounding errors may cause it to exceed 100%.\n    pct_complete = min(1.0, pct_complete)\n\n    # Status-message. Note the \\r which means the line should overwrite itself.\n    msg = ""\\r- Download progress: {0:.1%}"".format(pct_complete)\n\n    # Print it.\n    sys.stdout.write(msg)\n    sys.stdout.flush()\n\n\n########################################################################\n\ndef download(base_url, filename, download_dir):\n    """"""\n    Download the given file if it does not already exist in the download_dir.\n\n    :param base_url: The internet URL without the filename.\n    :param filename: The filename that will be added to the base_url.\n    :param download_dir: Local directory for storing the file.\n    :return: Nothing.\n    """"""\n\n    # Path for local file.\n    save_path = os.path.join(download_dir, filename)\n\n    # Check if the file already exists, otherwise we need to download it now.\n    if not os.path.exists(save_path):\n        # Check if the download directory exists, otherwise create it.\n        if not os.path.exists(download_dir):\n            os.makedirs(download_dir)\n\n        print(""Downloading"", filename, ""..."")\n\n        # Download the file from the internet.\n        url = base_url + filename\n        file_path, _ = urllib.request.urlretrieve(url=url,\n                                                  filename=save_path,\n                                                  reporthook=_print_download_progress)\n\n        print("" Done!"")\n\n\ndef maybe_download_and_extract(url, download_dir):\n    """"""\n    Download and extract the data if it doesn\'t already exist.\n    Assumes the url is a tar-ball file.\n\n    :param url:\n        Internet URL for the tar-file to download.\n        Example: ""https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz""\n\n    :param download_dir:\n        Directory where the downloaded file is saved.\n        Example: ""data/CIFAR-10/""\n\n    :return:\n        Nothing.\n    """"""\n\n    # Filename for saving the file downloaded from the internet.\n    # Use the filename from the URL and add it to the download_dir.\n    filename = url.split(\'/\')[-1]\n    file_path = os.path.join(download_dir, filename)\n\n    # Check if the file already exists.\n    # If it exists then we assume it has also been extracted,\n    # otherwise we need to download and extract it now.\n    if not os.path.exists(file_path):\n        # Check if the download directory exists, otherwise create it.\n        if not os.path.exists(download_dir):\n            os.makedirs(download_dir)\n\n        # Download the file from the internet.\n        file_path, _ = urllib.request.urlretrieve(url=url,\n                                                  filename=file_path,\n                                                  reporthook=_print_download_progress)\n\n        print()\n        print(""Download finished. Extracting files."")\n\n        if file_path.endswith("".zip""):\n            # Unpack the zip-file.\n            zipfile.ZipFile(file=file_path, mode=""r"").extractall(download_dir)\n        elif file_path.endswith(("".tar.gz"", "".tgz"")):\n            # Unpack the tar-ball.\n            tarfile.open(name=file_path, mode=""r:gz"").extractall(download_dir)\n\n        print(""Done."")\n    else:\n        print(""Data has apparently already been downloaded and unpacked."")\n\n\n########################################################################\n'"
europarl.py,0,"b'########################################################################\n#\n# Functions for downloading the Europarl data-set from the internet\n# and loading it into memory. This data-set is used for translation\n# between English and most European languages.\n#\n# http://www.statmt.org/europarl/\n#\n# Implemented in Python 3.6\n#\n# Usage:\n# 1) Set the variable data_dir with the desired storage directory.\n# 2) Determine the language-code to use e.g. ""da"" for Danish.\n# 3) Call maybe_download_and_extract() to download the data-set\n#    if it is not already located in the given data_dir.\n# 4) Call load_data(english=True) and load_data(english=False)\n#    to load the two data-files.\n# 5) Use the returned data in your own program.\n#\n# Format:\n# The Europarl data-set contains millions of text-pairs between English\n# and most European languages. The data is stored in two text-files.\n# The data is returned as lists of strings by the load_data() function.\n#\n# The list of currently supported languages and their codes are as follows:\n#\n# bg - Bulgarian\n# cs - Czech\n# da - Danish\n# de - German\n# el - Greek\n# es - Spanish\n# et - Estonian\n# fi - Finnish\n# fr - French\n# hu - Hungarian\n# it - Italian\n# lt - Lithuanian\n# lv - Latvian\n# nl - Dutch\n# pl - Polish\n# pt - Portuguese\n# ro - Romanian\n# sk - Slovak\n# sl - Slovene\n# sv - Swedish\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2018 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport os\nimport download\n\n########################################################################\n\n# Directory where you want to download and save the data-set.\n# Set this before you start calling any of the functions below.\ndata_dir = ""data/europarl/""\n\n# Base-URL for the data-sets on the internet.\ndata_url = ""http://www.statmt.org/europarl/v7/""\n\n\n########################################################################\n# Public functions that you may call to download the data-set from\n# the internet and load the data into memory.\n\n\ndef maybe_download_and_extract(language_code=""da""):\n    """"""\n    Download and extract the Europarl data-set if the data-file doesn\'t\n    already exist in data_dir. The data-set is for translating between\n    English and the given language-code (e.g. \'da\' for Danish, see the\n    list of available language-codes above).\n    """"""\n\n    # Create the full URL for the file with this data-set.\n    url = data_url + language_code + ""-en.tgz""\n\n    download.maybe_download_and_extract(url=url, download_dir=data_dir)\n\n\ndef load_data(english=True, language_code=""da"", start="""", end=""""):\n    """"""\n    Load the data-file for either the English-language texts or\n    for the other language (e.g. ""da"" for Danish).\n\n    All lines of the data-file are returned as a list of strings.\n\n    :param english:\n      Boolean whether to load the data-file for\n      English (True) or the other language (False).\n\n    :param language_code:\n      Two-char code for the other language e.g. ""da"" for Danish.\n      See list of available codes above.\n\n    :param start:\n      Prepend each line with this text e.g. ""ssss "" to indicate start of line.\n\n    :param end:\n      Append each line with this text e.g. "" eeee"" to indicate end of line.\n\n    :return:\n      List of strings with all the lines of the data-file.\n    """"""\n\n    if english:\n        # Load the English data.\n        filename = ""europarl-v7.{0}-en.en"".format(language_code)\n    else:\n        # Load the other language.\n        filename = ""europarl-v7.{0}-en.{0}"".format(language_code)\n\n    # Full path for the data-file.\n    path = os.path.join(data_dir, filename)\n\n    # Open and read all the contents of the data-file.\n    with open(path, encoding=""utf-8"") as file:\n        # Read the line from file, strip leading and trailing whitespace,\n        # prepend the start-text and append the end-text.\n        texts = [start + line.strip() + end for line in file]\n\n    return texts\n\n\n########################################################################\n'"
imdb.py,0,"b'########################################################################\n#\n# Functions for downloading the IMDB Review data-set from the internet\n# and loading it into memory.\n#\n# Implemented in Python 3.6\n#\n# Usage:\n# 1) Set the variable data_dir with the desired storage directory.\n# 2) Call maybe_download_and_extract() to download the data-set\n#    if it is not already located in the given data_dir.\n# 3) Call load_data(train=True) to load the training-set.\n# 4) Call load_data(train=False) to load the test-set.\n# 5) Use the returned data in your own program.\n#\n# Format:\n# The IMDB Review data-set consists of 50000 reviews of movies\n# that are split into 25000 reviews for the training- and test-set,\n# and each of those is split into 12500 positive and 12500 negative reviews.\n# These are returned as lists of strings by the load_data() function.\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2018 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport os\nimport download\nimport glob\n\n########################################################################\n\n# Directory where you want to download and save the data-set.\n# Set this before you start calling any of the functions below.\ndata_dir = ""data/IMDB/""\n\n# URL for the data-set on the internet.\ndata_url = ""http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz""\n\n\n########################################################################\n# Private helper-functions.\n\ndef _read_text_file(path):\n    """"""\n    Read and return all the contents of the text-file with the given path.\n    It is returned as a single string where all lines are concatenated.\n    """"""\n\n    with open(path, \'rt\', encoding=\'utf-8\') as file:\n        # Read a list of strings.\n        lines = file.readlines()\n\n        # Concatenate to a single string.\n        text = "" "".join(lines)\n\n    return text\n\n\n########################################################################\n# Public functions that you may call to download the data-set from\n# the internet and load the data into memory.\n\n\ndef maybe_download_and_extract():\n    """"""\n    Download and extract the IMDB Review data-set if it doesn\'t already exist\n    in data_dir (set this variable first to the desired directory).\n    """"""\n\n    download.maybe_download_and_extract(url=data_url, download_dir=data_dir)\n\n\ndef load_data(train=True):\n    """"""\n    Load all the data from the IMDB Review data-set for sentiment analysis.\n\n    :param train: Boolean whether to load the training-set (True)\n                  or the test-set (False).\n\n    :return:      A list of all the reviews as text-strings,\n                  and a list of the corresponding sentiments\n                  where 1.0 is positive and 0.0 is negative.\n    """"""\n\n    # Part of the path-name for either training or test-set.\n    train_test_path = ""train"" if train else ""test""\n\n    # Base-directory where the extracted data is located.\n    dir_base = os.path.join(data_dir, ""aclImdb"", train_test_path)\n\n    # Filename-patterns for the data-files.\n    path_pattern_pos = os.path.join(dir_base, ""pos"", ""*.txt"")\n    path_pattern_neg = os.path.join(dir_base, ""neg"", ""*.txt"")\n\n    # Get lists of all the file-paths for the data.\n    paths_pos = glob.glob(path_pattern_pos)\n    paths_neg = glob.glob(path_pattern_neg)\n\n    # Read all the text-files.\n    data_pos = [_read_text_file(path) for path in paths_pos]\n    data_neg = [_read_text_file(path) for path in paths_neg]\n\n    # Concatenate the positive and negative data.\n    x = data_pos + data_neg\n\n    # Create a list of the sentiments for the text-data.\n    # 1.0 is a positive sentiment, 0.0 is a negative sentiment.\n    y = [1.0] * len(data_pos) + [0.0] * len(data_neg)\n\n    return x, y\n\n\n########################################################################\n'"
inception.py,8,"b'########################################################################\n#\n# The Inception Model v3 for TensorFlow.\n#\n# This is a pre-trained Deep Neural Network for classifying images.\n# You provide an image or filename for a jpeg-file which will be\n# loaded and input to the Inception model, which will then output\n# an array of numbers indicating how likely it is that the\n# input-image is of each class.\n#\n# See the example code at the bottom of this file or in the\n# accompanying Python Notebooks.\n#\n# Tutorial #07 shows how to use the Inception model.\n# Tutorial #08 shows how to use it for Transfer Learning.\n#\n# What is Transfer Learning?\n#\n# Transfer Learning is the use of a Neural Network for classifying\n# images from another data-set than it was trained on. For example,\n# the Inception model was trained on the ImageNet data-set using\n# a very powerful and expensive computer. But the Inception model\n# can be re-used on data-sets it was not trained on without having\n# to re-train the entire model, even though the number of classes\n# are different for the two data-sets. This allows you to use the\n# Inception model on your own data-sets without the need for a\n# very powerful and expensive computer to train it.\n#\n# The last layer of the Inception model before the softmax-classifier\n# is called the Transfer Layer because the output of that layer will\n# be used as the input in your new softmax-classifier (or as the\n# input for another neural network), which will then be trained on\n# your own data-set.\n#\n# The output values of the Transfer Layer are called Transfer Values.\n# These are the actual values that will be input to your new\n# softmax-classifier or to another neural network that you create.\n#\n# The word \'bottleneck\' is also sometimes used to refer to the\n# Transfer Layer or Transfer Values, but it is a confusing word\n# that is not used here.\n#\n# Implemented in Python 3.5 with TensorFlow v0.10.0rc0\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2016 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport numpy as np\nimport tensorflow as tf\nimport download\nfrom cache import cache\nimport os\nimport sys\n\n########################################################################\n# Various directories and file-names.\n\n# Internet URL for the tar-file with the Inception model.\n# Note that this might change in the future and will need to be updated.\ndata_url = ""http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz""\n\n# Directory to store the downloaded data.\ndata_dir = ""inception/""\n\n# File containing the mappings between class-number and uid. (Downloaded)\npath_uid_to_cls = ""imagenet_2012_challenge_label_map_proto.pbtxt""\n\n# File containing the mappings between uid and string. (Downloaded)\npath_uid_to_name = ""imagenet_synset_to_human_label_map.txt""\n\n# File containing the TensorFlow graph definition. (Downloaded)\npath_graph_def = ""classify_image_graph_def.pb""\n\n########################################################################\n\n\ndef maybe_download():\n    """"""\n    Download the Inception model from the internet if it does not already\n    exist in the data_dir. The file is about 85 MB.\n    """"""\n\n    print(""Downloading Inception v3 Model ..."")\n    download.maybe_download_and_extract(url=data_url, download_dir=data_dir)\n\n\n########################################################################\n\n\nclass NameLookup:\n    """"""\n    Used for looking up the name associated with a class-number.\n    This is used to print the name of a class instead of its number,\n    e.g. ""plant"" or ""horse"".\n\n    Maps between:\n    - cls is the class-number as an integer between 1 and 1000 (inclusive).\n    - uid is a class-id as a string from the ImageNet data-set, e.g. ""n00017222"".\n    - name is the class-name as a string, e.g. ""plant, flora, plant life""\n\n    There are actually 1008 output classes of the Inception model\n    but there are only 1000 named classes in these mapping-files.\n    The remaining 8 output classes of the model should not be used.\n    """"""\n\n    def __init__(self):\n        # Mappings between uid, cls and name are dicts, where insertions and\n        # lookup have O(1) time-usage on average, but may be O(n) in worst case.\n        self._uid_to_cls = {}   # Map from uid to cls.\n        self._uid_to_name = {}  # Map from uid to name.\n        self._cls_to_uid = {}   # Map from cls to uid.\n\n        # Read the uid-to-name mappings from file.\n        path = os.path.join(data_dir, path_uid_to_name)\n        with open(file=path, mode=\'r\') as file:\n            # Read all lines from the file.\n            lines = file.readlines()\n\n            for line in lines:\n                # Remove newlines.\n                line = line.replace(""\\n"", """")\n\n                # Split the line on tabs.\n                elements = line.split(""\\t"")\n\n                # Get the uid.\n                uid = elements[0]\n\n                # Get the class-name.\n                name = elements[1]\n\n                # Insert into the lookup-dict.\n                self._uid_to_name[uid] = name\n\n        # Read the uid-to-cls mappings from file.\n        path = os.path.join(data_dir, path_uid_to_cls)\n        with open(file=path, mode=\'r\') as file:\n            # Read all lines from the file.\n            lines = file.readlines()\n\n            for line in lines:\n                # We assume the file is in the proper format,\n                # so the following lines come in pairs. Other lines are ignored.\n\n                if line.startswith(""  target_class: ""):\n                    # This line must be the class-number as an integer.\n\n                    # Split the line.\n                    elements = line.split("": "")\n\n                    # Get the class-number as an integer.\n                    cls = int(elements[1])\n\n                elif line.startswith(""  target_class_string: ""):\n                    # This line must be the uid as a string.\n\n                    # Split the line.\n                    elements = line.split("": "")\n\n                    # Get the uid as a string e.g. ""n01494475""\n                    uid = elements[1]\n\n                    # Remove the enclosing """" from the string.\n                    uid = uid[1:-2]\n\n                    # Insert into the lookup-dicts for both ways between uid and cls.\n                    self._uid_to_cls[uid] = cls\n                    self._cls_to_uid[cls] = uid\n\n    def uid_to_cls(self, uid):\n        """"""\n        Return the class-number as an integer for the given uid-string.\n        """"""\n\n        return self._uid_to_cls[uid]\n\n    def uid_to_name(self, uid, only_first_name=False):\n        """"""\n        Return the class-name for the given uid string.\n\n        Some class-names are lists of names, if you only want the first name,\n        then set only_first_name=True.\n        """"""\n\n        # Lookup the name from the uid.\n        name = self._uid_to_name[uid]\n\n        # Only use the first name in the list?\n        if only_first_name:\n            name = name.split("","")[0]\n\n        return name\n\n    def cls_to_name(self, cls, only_first_name=False):\n        """"""\n        Return the class-name from the integer class-number.\n\n        Some class-names are lists of names, if you only want the first name,\n        then set only_first_name=True.\n        """"""\n\n        # Lookup the uid from the cls.\n        uid = self._cls_to_uid[cls]\n\n        # Lookup the name from the uid.\n        name = self.uid_to_name(uid=uid, only_first_name=only_first_name)\n\n        return name\n\n\n########################################################################\n\n\nclass Inception:\n    """"""\n    The Inception model is a Deep Neural Network which has already been\n    trained for classifying images into 1000 different categories.\n\n    When you create a new instance of this class, the Inception model\n    will be loaded and can be used immediately without training.\n\n    The Inception model can also be used for Transfer Learning.\n    """"""\n\n    # Name of the tensor for feeding the input image as jpeg.\n    tensor_name_input_jpeg = ""DecodeJpeg/contents:0""\n\n    # Name of the tensor for feeding the decoded input image.\n    # Use this for feeding images in other formats than jpeg.\n    tensor_name_input_image = ""DecodeJpeg:0""\n\n    # Name of the tensor for the resized input image.\n    # This is used to retrieve the image after it has been resized.\n    tensor_name_resized_image = ""ResizeBilinear:0""\n\n    # Name of the tensor for the output of the softmax-classifier.\n    # This is used for classifying images with the Inception model.\n    tensor_name_softmax = ""softmax:0""\n\n    # Name of the tensor for the unscaled outputs of the softmax-classifier (aka. logits).\n    tensor_name_softmax_logits = ""softmax/logits:0""\n\n    # Name of the tensor for the output of the Inception model.\n    # This is used for Transfer Learning.\n    tensor_name_transfer_layer = ""pool_3:0""\n\n    def __init__(self):\n        # Mappings between class-numbers and class-names.\n        # Used to print the class-name as a string e.g. ""horse"" or ""plant"".\n        self.name_lookup = NameLookup()\n\n        # Now load the Inception model from file. The way TensorFlow\n        # does this is confusing and requires several steps.\n\n        # Create a new TensorFlow computational graph.\n        self.graph = tf.Graph()\n\n        # Set the new graph as the default.\n        with self.graph.as_default():\n\n            # TensorFlow graphs are saved to disk as so-called Protocol Buffers\n            # aka. proto-bufs which is a file-format that works on multiple\n            # platforms. In this case it is saved as a binary file.\n\n            # Open the graph-def file for binary reading.\n            path = os.path.join(data_dir, path_graph_def)\n            with tf.gfile.FastGFile(path, \'rb\') as file:\n                # The graph-def is a saved copy of a TensorFlow graph.\n                # First we need to create an empty graph-def.\n                graph_def = tf.GraphDef()\n\n                # Then we load the proto-buf file into the graph-def.\n                graph_def.ParseFromString(file.read())\n\n                # Finally we import the graph-def to the default TensorFlow graph.\n                tf.import_graph_def(graph_def, name=\'\')\n\n                # Now self.graph holds the Inception model from the proto-buf file.\n\n        # Get the output of the Inception model by looking up the tensor\n        # with the appropriate name for the output of the softmax-classifier.\n        self.y_pred = self.graph.get_tensor_by_name(self.tensor_name_softmax)\n\n        # Get the unscaled outputs for the Inception model (aka. softmax-logits).\n        self.y_logits = self.graph.get_tensor_by_name(self.tensor_name_softmax_logits)\n\n        # Get the tensor for the resized image that is input to the neural network.\n        self.resized_image = self.graph.get_tensor_by_name(self.tensor_name_resized_image)\n\n        # Get the tensor for the last layer of the graph, aka. the transfer-layer.\n        self.transfer_layer = self.graph.get_tensor_by_name(self.tensor_name_transfer_layer)\n\n        # Get the number of elements in the transfer-layer.\n        self.transfer_len = self.transfer_layer.get_shape()[3]\n\n        # Create a TensorFlow session for executing the graph.\n        self.session = tf.Session(graph=self.graph)\n\n    def close(self):\n        """"""\n        Call this function when you are done using the Inception model.\n        It closes the TensorFlow session to release its resources.\n        """"""\n\n        self.session.close()\n\n    def _write_summary(self, logdir=\'summary/\'):\n        """"""\n        Write graph to summary-file so it can be shown in TensorBoard.\n\n        This function is used for debugging and may be changed or removed in the future.\n\n        :param logdir:\n            Directory for writing the summary-files.\n\n        :return:\n            Nothing.\n        """"""\n\n        writer = tf.train.SummaryWriter(logdir=logdir, graph=self.graph)\n        writer.close()\n\n    def _create_feed_dict(self, image_path=None, image=None):\n        """"""\n        Create and return a feed-dict with an image.\n\n        :param image_path:\n            The input image is a jpeg-file with this file-path.\n\n        :param image:\n            The input image is a 3-dim array which is already decoded.\n            The pixels MUST be values between 0 and 255 (float or int).\n\n        :return:\n            Dict for feeding to the Inception graph in TensorFlow.\n        """"""\n\n        if image is not None:\n            # Image is passed in as a 3-dim array that is already decoded.\n            feed_dict = {self.tensor_name_input_image: image}\n\n        elif image_path is not None:\n            # Read the jpeg-image as an array of bytes.\n            image_data = tf.gfile.FastGFile(image_path, \'rb\').read()\n\n            # Image is passed in as a jpeg-encoded image.\n            feed_dict = {self.tensor_name_input_jpeg: image_data}\n\n        else:\n            raise ValueError(""Either image or image_path must be set."")\n\n        return feed_dict\n\n    def classify(self, image_path=None, image=None):\n        """"""\n        Use the Inception model to classify a single image.\n\n        The image will be resized automatically to 299 x 299 pixels,\n        see the discussion in the Python Notebook for Tutorial #07.\n\n        :param image_path:\n            The input image is a jpeg-file with this file-path.\n\n        :param image:\n            The input image is a 3-dim array which is already decoded.\n            The pixels MUST be values between 0 and 255 (float or int).\n\n        :return:\n            Array of floats (aka. softmax-array) indicating how likely\n            the Inception model thinks the image is of each given class.\n        """"""\n\n        # Create a feed-dict for the TensorFlow graph with the input image.\n        feed_dict = self._create_feed_dict(image_path=image_path, image=image)\n\n        # Execute the TensorFlow session to get the predicted labels.\n        pred = self.session.run(self.y_pred, feed_dict=feed_dict)\n\n        # Reduce the array to a single dimension.\n        pred = np.squeeze(pred)\n\n        return pred\n\n    def get_resized_image(self, image_path=None, image=None):\n        """"""\n        Input an image to the Inception model and return\n        the resized image. The resized image can be plotted so\n        we can see what the neural network sees as its input.\n\n        :param image_path:\n            The input image is a jpeg-file with this file-path.\n\n        :param image:\n            The input image is a 3-dim array which is already decoded.\n            The pixels MUST be values between 0 and 255 (float or int).\n\n        :return:\n            A 3-dim array holding the image.\n        """"""\n\n        # Create a feed-dict for the TensorFlow graph with the input image.\n        feed_dict = self._create_feed_dict(image_path=image_path, image=image)\n\n        # Execute the TensorFlow session to get the predicted labels.\n        resized_image = self.session.run(self.resized_image, feed_dict=feed_dict)\n\n        # Remove the 1st dimension of the 4-dim tensor.\n        resized_image = resized_image.squeeze(axis=0)\n\n        # Scale pixels to be between 0.0 and 1.0\n        resized_image = resized_image.astype(float) / 255.0\n\n        return resized_image\n\n    def print_scores(self, pred, k=10, only_first_name=True):\n        """"""\n        Print the scores (or probabilities) for the top-k predicted classes.\n\n        :param pred:\n            Predicted class-labels returned from the predict() function.\n\n        :param k:\n            How many classes to print.\n\n        :param only_first_name:\n            Some class-names are lists of names, if you only want the first name,\n            then set only_first_name=True.\n\n        :return:\n            Nothing.\n        """"""\n\n        # Get a sorted index for the pred-array.\n        idx = pred.argsort()\n\n        # The index is sorted lowest-to-highest values. Take the last k.\n        top_k = idx[-k:]\n\n        # Iterate the top-k classes in reversed order (i.e. highest first).\n        for cls in reversed(top_k):\n            # Lookup the class-name.\n            name = self.name_lookup.cls_to_name(cls=cls, only_first_name=only_first_name)\n\n            # Predicted score (or probability) for this class.\n            score = pred[cls]\n\n            # Print the score and class-name.\n            print(""{0:>6.2%} : {1}"".format(score, name))\n\n    def transfer_values(self, image_path=None, image=None):\n        """"""\n        Calculate the transfer-values for the given image.\n        These are the values of the last layer of the Inception model before\n        the softmax-layer, when inputting the image to the Inception model.\n\n        The transfer-values allow us to use the Inception model in so-called\n        Transfer Learning for other data-sets and different classifications.\n\n        It may take several hours or more to calculate the transfer-values\n        for all images in a data-set. It is therefore useful to cache the\n        results using the function transfer_values_cache() below.\n\n        :param image_path:\n            The input image is a jpeg-file with this file-path.\n\n        :param image:\n            The input image is a 3-dim array which is already decoded.\n            The pixels MUST be values between 0 and 255 (float or int).\n\n        :return:\n            The transfer-values for those images.\n        """"""\n\n        # Create a feed-dict for the TensorFlow graph with the input image.\n        feed_dict = self._create_feed_dict(image_path=image_path, image=image)\n\n        # Use TensorFlow to run the graph for the Inception model.\n        # This calculates the values for the last layer of the Inception model\n        # prior to the softmax-classification, which we call transfer-values.\n        transfer_values = self.session.run(self.transfer_layer, feed_dict=feed_dict)\n\n        # Reduce to a 1-dim array.\n        transfer_values = np.squeeze(transfer_values)\n\n        return transfer_values\n\n\n########################################################################\n# Batch-processing.\n\n\ndef process_images(fn, images=None, image_paths=None):\n    """"""\n    Call the function fn() for each image, e.g. transfer_values() from\n    the Inception model above. All the results are concatenated and returned.\n\n    :param fn:\n        Function to be called for each image.\n\n    :param images:\n        List of images to process.\n\n    :param image_paths:\n        List of file-paths for the images to process.\n\n    :return:\n        Numpy array with the results.\n    """"""\n\n    # Are we using images or image_paths?\n    using_images = images is not None\n\n    # Number of images.\n    if using_images:\n        num_images = len(images)\n    else:\n        num_images = len(image_paths)\n\n    # Pre-allocate list for the results.\n    # This holds references to other arrays. Initially the references are None.\n    result = [None] * num_images\n\n    # For each input image.\n    for i in range(num_images):\n        # Status-message. Note the \\r which means the line should overwrite itself.\n        msg = ""\\r- Processing image: {0:>6} / {1}"".format(i+1, num_images)\n\n        # Print the status message.\n        sys.stdout.write(msg)\n        sys.stdout.flush()\n\n        # Process the image and store the result for later use.\n        if using_images:\n            result[i] = fn(image=images[i])\n        else:\n            result[i] = fn(image_path=image_paths[i])\n\n    # Print newline.\n    print()\n\n    # Convert the result to a numpy array.\n    result = np.array(result)\n\n    return result\n\n\n########################################################################\n\n\ndef transfer_values_cache(cache_path, model, images=None, image_paths=None):\n    """"""\n    This function either loads the transfer-values if they have\n    already been calculated, otherwise it calculates the values\n    and saves them to a file that can be re-loaded again later.\n\n    Because the transfer-values can be expensive to compute, it can\n    be useful to cache the values through this function instead\n    of calling transfer_values() directly on the Inception model.\n\n    See Tutorial #08 for an example on how to use this function.\n\n    :param cache_path:\n        File containing the cached transfer-values for the images.\n\n    :param model:\n        Instance of the Inception model.\n\n    :param images:\n        4-dim array with images. [image_number, height, width, colour_channel]\n\n    :param image_paths:\n        Array of file-paths for images (must be jpeg-format).\n\n    :return:\n        The transfer-values from the Inception model for those images.\n    """"""\n\n    # Helper-function for processing the images if the cache-file does not exist.\n    # This is needed because we cannot supply both fn=process_images\n    # and fn=model.transfer_values to the cache()-function.\n    def fn():\n        return process_images(fn=model.transfer_values, images=images, image_paths=image_paths)\n\n    # Read the transfer-values from a cache-file, or calculate them if the file does not exist.\n    transfer_values = cache(cache_path=cache_path, fn=fn)\n\n    return transfer_values\n\n\n########################################################################\n# Example usage.\n\nif __name__ == \'__main__\':\n    print(tf.__version__)\n\n    # Download Inception model if not already done.\n    maybe_download()\n\n    # Load the Inception model so it is ready for classifying images.\n    model = Inception()\n\n    # Path for a jpeg-image that is included in the downloaded data.\n    image_path = os.path.join(data_dir, \'cropped_panda.jpg\')\n\n    # Use the Inception model to classify the image.\n    pred = model.classify(image_path=image_path)\n\n    # Print the scores and names for the top-10 predictions.\n    model.print_scores(pred=pred, k=10)\n\n    # Close the TensorFlow session.\n    model.close()\n\n    # Transfer Learning is demonstrated in Tutorial #08.\n\n########################################################################\n'"
inception5h.py,7,"b'########################################################################\n#\n# The Inception Model 5h for TensorFlow.\n#\n# This variant of the Inception model is easier to use for DeepDream\n# and other imaging techniques. This is because it allows the input\n# image to be any size, and the optimized images are also prettier.\n#\n# It is unclear which Inception model this implements because the\n# Google developers have (as usual) neglected to document it.\n# It is dubbed the 5h-model because that is the name of the zip-file,\n# but it is apparently simpler than the v.3 model.\n#\n# See the Python Notebook for Tutorial #14 for an example usage.\n#\n# Implemented in Python 3.5 with TensorFlow v0.11.0rc0\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2016 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport numpy as np\nimport tensorflow as tf\nimport download\nimport os\n\n########################################################################\n# Various directories and file-names.\n\n# Internet URL for the tar-file with the Inception model.\n# Note that this might change in the future and will need to be updated.\ndata_url = ""http://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip""\n\n# Directory to store the downloaded data.\ndata_dir = ""inception/5h/""\n\n# File containing the TensorFlow graph definition. (Downloaded)\npath_graph_def = ""tensorflow_inception_graph.pb""\n\n########################################################################\n\n\ndef maybe_download():\n    """"""\n    Download the Inception model from the internet if it does not already\n    exist in the data_dir. The file is about 50 MB.\n    """"""\n\n    print(""Downloading Inception 5h Model ..."")\n    download.maybe_download_and_extract(url=data_url, download_dir=data_dir)\n\n\n########################################################################\n\n\nclass Inception5h:\n    """"""\n    The Inception model is a Deep Neural Network which has already been\n    trained for classifying images into 1000 different categories.\n\n    When you create a new instance of this class, the Inception model\n    will be loaded and can be used immediately without training.\n    """"""\n\n    # Name of the tensor for feeding the input image.\n    tensor_name_input_image = ""input:0""\n\n    # Names for some of the commonly used layers in the Inception model.\n    layer_names = [\'conv2d0\', \'conv2d1\', \'conv2d2\',\n                   \'mixed3a\', \'mixed3b\',\n                   \'mixed4a\', \'mixed4b\', \'mixed4c\', \'mixed4d\', \'mixed4e\',\n                   \'mixed5a\', \'mixed5b\']\n\n    def __init__(self):\n        # Now load the Inception model from file. The way TensorFlow\n        # does this is confusing and requires several steps.\n\n        # Create a new TensorFlow computational graph.\n        self.graph = tf.Graph()\n\n        # Set the new graph as the default.\n        with self.graph.as_default():\n\n            # TensorFlow graphs are saved to disk as so-called Protocol Buffers\n            # aka. proto-bufs which is a file-format that works on multiple\n            # platforms. In this case it is saved as a binary file.\n\n            # Open the graph-def file for binary reading.\n            path = os.path.join(data_dir, path_graph_def)\n            with tf.gfile.FastGFile(path, \'rb\') as file:\n                # The graph-def is a saved copy of a TensorFlow graph.\n                # First we need to create an empty graph-def.\n                graph_def = tf.GraphDef()\n\n                # Then we load the proto-buf file into the graph-def.\n                graph_def.ParseFromString(file.read())\n\n                # Finally we import the graph-def to the default TensorFlow graph.\n                tf.import_graph_def(graph_def, name=\'\')\n\n                # Now self.graph holds the Inception model from the proto-buf file.\n\n            # Get a reference to the tensor for inputting images to the graph.\n            self.input = self.graph.get_tensor_by_name(self.tensor_name_input_image)\n\n            # Get references to the tensors for the commonly used layers.\n            self.layer_tensors = [self.graph.get_tensor_by_name(name + "":0"") for name in self.layer_names]\n\n    def create_feed_dict(self, image=None):\n        """"""\n        Create and return a feed-dict with an image.\n\n        :param image:\n            The input image is a 3-dim array which is already decoded.\n            The pixels MUST be values between 0 and 255 (float or int).\n\n        :return:\n            Dict for feeding to the Inception graph in TensorFlow.\n        """"""\n\n        # Expand 3-dim array to 4-dim by prepending an \'empty\' dimension.\n        # This is because we are only feeding a single image, but the\n        # Inception model was built to take multiple images as input.\n        image = np.expand_dims(image, axis=0)\n\n        # Image is passed in as a 3-dim array of raw pixel-values.\n        feed_dict = {self.tensor_name_input_image: image}\n\n        return feed_dict\n\n    def get_gradient(self, tensor):\n        """"""\n        Get the gradient of the given tensor with respect to\n        the input image. This allows us to modify the input\n        image so as to maximize the given tensor.\n\n        For use in e.g. DeepDream and Visual Analysis.\n\n        :param tensor:\n            The tensor whose value we want to maximize\n            by changing the input image.\n\n        :return:\n            Gradient for the tensor with regard to the input image.\n        """"""\n\n        # Set the graph as default so we can add operations to it.\n        with self.graph.as_default():\n            # Square the tensor-values.\n            # You can try and remove this to see the effect.\n            tensor = tf.square(tensor)\n\n            # Average the tensor so we get a single scalar value.\n            tensor_mean = tf.reduce_mean(tensor)\n\n            # Use TensorFlow to automatically create a mathematical\n            # formula for the gradient using the chain-rule of\n            # differentiation.\n            gradient = tf.gradients(tensor_mean, self.input)[0]\n\n        return gradient\n\n########################################################################\n'"
knifey.py,0,"b'########################################################################\n#\n# Functions for downloading the Knifey-Spoony data-set from the internet\n# and loading it into memory. Note that this only loads the file-names\n# for the images in the data-set and does not load the actual images.\n#\n# Implemented in Python 3.5\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2016 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nfrom dataset import load_cached\nimport download\nimport os\n\n########################################################################\n\n# Directory where you want to download and save the data-set.\n# Set this before you start calling any of the functions below.\ndata_dir = ""data/knifey-spoony/""\n\n# Directory for the training-set after copying the files using copy_files().\ntrain_dir = os.path.join(data_dir, ""train/"")\n\n# Directory for the test-set after copying the files using copy_files().\ntest_dir = os.path.join(data_dir, ""test/"")\n\n# URL for the data-set on the internet.\ndata_url = ""https://github.com/Hvass-Labs/knifey-spoony/raw/master/knifey-spoony.tar.gz""\n\n########################################################################\n# Various constants for the size of the images.\n# Use these constants in your own program.\n\n# Width and height of each image.\nimg_size = 200\n\n# Number of channels in each image, 3 channels: Red, Green, Blue.\nnum_channels = 3\n\n# Shape of the numpy-array for an image.\nimg_shape = [img_size, img_size, num_channels]\n\n# Length of an image when flattened to a 1-dim array.\nimg_size_flat = img_size * img_size * num_channels\n\n# Number of classes.\nnum_classes = 3\n\n########################################################################\n# Public functions that you may call to download the data-set from\n# the internet and load the data into memory.\n\n\ndef maybe_download_and_extract():\n    """"""\n    Download and extract the Knifey-Spoony data-set if it doesn\'t already exist\n    in data_dir (set this variable first to the desired directory).\n    """"""\n\n    download.maybe_download_and_extract(url=data_url, download_dir=data_dir)\n\n\ndef load():\n    """"""\n    Load the Knifey-Spoony data-set into memory.\n\n    This uses a cache-file which is reloaded if it already exists,\n    otherwise the Knifey-Spoony data-set is created and saved to\n    the cache-file. The reason for using a cache-file is that it\n    ensure the files are ordered consistently each time the data-set\n    is loaded. This is important when the data-set is used in\n    combination with Transfer Learning as is done in Tutorial #09.\n\n    :return:\n        A DataSet-object for the Knifey-Spoony data-set.\n    """"""\n\n    # Path for the cache-file.\n    cache_path = os.path.join(data_dir, ""knifey-spoony.pkl"")\n\n    # If the DataSet-object already exists in a cache-file\n    # then load it, otherwise create a new object and save\n    # it to the cache-file so it can be loaded the next time.\n    dataset = load_cached(cache_path=cache_path,\n                          in_dir=data_dir)\n\n    return dataset\n\n\ndef copy_files():\n    """"""\n    Copy all the files in the training-set to train_dir\n    and copy all the files in the test-set to test_dir.\n\n    This creates the directories if they don\'t already exist,\n    and it overwrites the images if they already exist.\n\n    The images are originally stored in a directory-structure\n    that is incompatible with e.g. the Keras API. This function\n    copies the files to a dir-structure that works with e.g. Keras.\n    """"""\n\n    # Load the Knifey-Spoony dataset.\n    # This is very fast as it only gathers lists of the files\n    # and does not actually load the images into memory.\n    dataset = load()\n\n    # Copy the files to separate training- and test-dirs.\n    dataset.copy_files(train_dir=train_dir, test_dir=test_dir)\n\n########################################################################\n\nif __name__ == \'__main__\':\n    # Download and extract the data-set if it doesn\'t already exist.\n    maybe_download_and_extract()\n\n    # Load the data-set.\n    dataset = load()\n\n    # Get the file-paths for the images and their associated class-numbers\n    # and class-labels. This is for the training-set.\n    image_paths_train, cls_train, labels_train = dataset.get_training_set()\n\n    # Get the file-paths for the images and their associated class-numbers\n    # and class-labels. This is for the test-set.\n    image_paths_test, cls_test, labels_test = dataset.get_test_set()\n\n    # Check if the training-set looks OK.\n\n    # Print some of the file-paths for the training-set.\n    for path in image_paths_train[0:5]:\n        print(path)\n\n    # Print the associated class-numbers.\n    print(cls_train[0:5])\n\n    # Print the class-numbers as one-hot encoded arrays.\n    print(labels_train[0:5])\n\n    # Check if the test-set looks OK.\n\n    # Print some of the file-paths for the test-set.\n    for path in image_paths_test[0:5]:\n        print(path)\n\n    # Print the associated class-numbers.\n    print(cls_test[0:5])\n\n    # Print the class-numbers as one-hot encoded arrays.\n    print(labels_test[0:5])\n\n########################################################################\n'"
mnist.py,0,"b'########################################################################\n#\n# Downloads the MNIST data-set for recognizing hand-written digits.\n#\n# Implemented in Python 3.6\n#\n# Usage:\n# 1) Create a new object instance: data = MNIST(data_dir=""data/MNIST/"")\n#    This automatically downloads the files to the given dir.\n# 2) Use the training-set as data.x_train, data.y_train and data.y_train_cls\n# 3) Get random batches of training data using data.random_batch()\n# 4) Use the test-set as data.x_test, data.y_test and data.y_test_cls\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2016-18 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport numpy as np\nimport gzip\nimport os\nfrom dataset import one_hot_encoded\nfrom download import download\n\n########################################################################\n\n# Base URL for downloading the data-files from the internet.\nbase_url = ""https://storage.googleapis.com/cvdf-datasets/mnist/""\n\n# Filenames for the data-set.\nfilename_x_train = ""train-images-idx3-ubyte.gz""\nfilename_y_train = ""train-labels-idx1-ubyte.gz""\nfilename_x_test = ""t10k-images-idx3-ubyte.gz""\nfilename_y_test = ""t10k-labels-idx1-ubyte.gz""\n\n########################################################################\n\n\nclass MNIST:\n    """"""\n    The MNIST data-set for recognizing hand-written digits.\n    This automatically downloads the data-files if they do\n    not already exist in the local data_dir.\n\n    Note: Pixel-values are floats between 0.0 and 1.0.\n    """"""\n\n    # The images are 28 pixels in each dimension.\n    img_size = 28\n\n    # The images are stored in one-dimensional arrays of this length.\n    img_size_flat = img_size * img_size\n\n    # Tuple with height and width of images used to reshape arrays.\n    img_shape = (img_size, img_size)\n\n    # Number of colour channels for the images: 1 channel for gray-scale.\n    num_channels = 1\n\n    # Tuple with height, width and depth used to reshape arrays.\n    # This is used for reshaping in Keras.\n    img_shape_full = (img_size, img_size, num_channels)\n\n    # Number of classes, one class for each of 10 digits.\n    num_classes = 10\n\n    def __init__(self, data_dir=""data/MNIST/""):\n        """"""\n        Load the MNIST data-set. Automatically downloads the files\n        if they do not already exist locally.\n\n        :param data_dir: Base-directory for downloading files.\n        """"""\n\n        # Copy args to self.\n        self.data_dir = data_dir\n\n        # Number of images in each sub-set.\n        self.num_train = 55000\n        self.num_val = 5000\n        self.num_test = 10000\n\n        # Download / load the training-set.\n        x_train = self._load_images(filename=filename_x_train)\n        y_train_cls = self._load_cls(filename=filename_y_train)\n\n        # Split the training-set into train / validation.\n        # Pixel-values are converted from ints between 0 and 255\n        # to floats between 0.0 and 1.0.\n        self.x_train = x_train[0:self.num_train] / 255.0\n        self.x_val = x_train[self.num_train:] / 255.0\n        self.y_train_cls = y_train_cls[0:self.num_train]\n        self.y_val_cls = y_train_cls[self.num_train:]\n\n        # Download / load the test-set.\n        self.x_test = self._load_images(filename=filename_x_test) / 255.0\n        self.y_test_cls = self._load_cls(filename=filename_y_test)\n\n        # Convert the class-numbers from bytes to ints as that is needed\n        # some places in TensorFlow.\n        self.y_train_cls = self.y_train_cls.astype(np.int)\n        self.y_val_cls = self.y_val_cls.astype(np.int)\n        self.y_test_cls = self.y_test_cls.astype(np.int)\n\n        # Convert the integer class-numbers into one-hot encoded arrays.\n        self.y_train = one_hot_encoded(class_numbers=self.y_train_cls,\n                                       num_classes=self.num_classes)\n        self.y_val = one_hot_encoded(class_numbers=self.y_val_cls,\n                                     num_classes=self.num_classes)\n        self.y_test = one_hot_encoded(class_numbers=self.y_test_cls,\n                                      num_classes=self.num_classes)\n\n    def _load_data(self, filename, offset):\n        """"""\n        Load the data in the given file. Automatically downloads the file\n        if it does not already exist in the data_dir.\n\n        :param filename: Name of the data-file.\n        :param offset: Start offset in bytes when reading the data-file.\n        :return: The data as a numpy array.\n        """"""\n\n        # Download the file from the internet if it does not exist locally.\n        download(base_url=base_url, filename=filename, download_dir=self.data_dir)\n\n        # Read the data-file.\n        path = os.path.join(self.data_dir, filename)\n        with gzip.open(path, \'rb\') as f:\n            data = np.frombuffer(f.read(), np.uint8, offset=offset)\n\n        return data\n\n    def _load_images(self, filename):\n        """"""\n        Load image-data from the given file.\n        Automatically downloads the file if it does not exist locally.\n\n        :param filename: Name of the data-file.\n        :return: Numpy array.\n        """"""\n\n        # Read the data as one long array of bytes.\n        data = self._load_data(filename=filename, offset=16)\n\n        # Reshape to 2-dim array with shape (num_images, img_size_flat).\n        images_flat = data.reshape(-1, self.img_size_flat)\n\n        return images_flat\n\n    def _load_cls(self, filename):\n        """"""\n        Load class-numbers from the given file.\n        Automatically downloads the file if it does not exist locally.\n\n        :param filename: Name of the data-file.\n        :return: Numpy array.\n        """"""\n        return self._load_data(filename=filename, offset=8)\n\n    def random_batch(self, batch_size=32):\n        """"""\n        Create a random batch of training-data.\n\n        :param batch_size: Number of images in the batch.\n        :return: 3 numpy arrays (x, y, y_cls)\n        """"""\n\n        # Create a random index into the training-set.\n        idx = np.random.randint(low=0, high=self.num_train, size=batch_size)\n\n        # Use the index to lookup random training-data.\n        x_batch = self.x_train[idx]\n        y_batch = self.y_train[idx]\n        y_batch_cls = self.y_train_cls[idx]\n\n        return x_batch, y_batch, y_batch_cls\n\n\n########################################################################\n'"
reinforcement_learning.py,36,"b'########################################################################\n#\n# Reinforcement Learning (Q-Learning) for Atari Games\n#\n# How to run:\n#\n# To train a Neural Network for playing the Atari game Breakout,\n# run the following command in a terminal window.\n#\n# python reinforcement_learning.py --env \'Breakout-v0\' --training\n#\n# The agent should start to improve after a few hours, but a full\n# training run required 150 hours on a 2.6 GHz CPU and GTX 1070 GPU.\n#\n# The hyper-parameters were tuned for Breakout and did not work\n# quite as well for SpaceInvaders. Can you find better parameters?\n#\n# Once the Neural Network has been trained, you can test it and\n# watch it play the game by running this command in the terminal:\n#\n# python reinforcement_learning.py --env \'Breakout-v0\' --render --episodes 2\n#\n# Requirements:\n#\n# - Python 3.6 (Python 2.7 may not work)\n# - TensorFlow 1.1.0\n# - OpenAI Gym 0.8.1\n#\n# Summary:\n#\n# This program implements a variant of Reinforcement Learning known as\n# Q-learning. Imagine that we have an agent that must take actions in\n# some environment so as to maximize the cumulative reward over its life.\n# The agent sees the state of the game-environment through images\n# which are sent through a Neural Network in TensorFlow, so as to\n# estimate which action is most likely to maximize the cumulative\n# reward of all future actions. These action-values are also called\n# Q-values. If the Q-values are known in advance, then the agent merely\n# has to select the action corresponding to the highest Q-value in\n# each state of the game. But the Q-values are not known in advance\n# and must be learnt while the agent is playing the game.\n# This is done by initializing all Q-values to zero and then having\n# the agent take random actions. Whenever the agent obtains a reward,\n# the estimated Q-values can be updated with the new information.\n# The agent gradually learns to play the game better and better\n# because the Neural Network becomes better at estimating the Q-values.\n# But this process is very slow and the basic algorithm implemented\n# here typically requires 100 million steps in the game-environment,\n# although it will typically start to show improvement much sooner.\n#\n# Main classes:\n#\n# - MotionTracer:\n#\n#   This takes raw images from the game-environment and processes them.\n#   The output is called a state and consists of two images of equal size:\n#   (1) The last image from the game-environment, resized and gray-scaled.\n#   (2) A motion-trace that shows the recent trajectories of objects.\n#\n# - ReplayMemory:\n#\n#   Successive image-frames of the game-environment are almost identical.\n#   If we train the Neural Network to estimate Q-values from a small\n#   number of successive image-frames, then it cannot learn to distinguish\n#   important features and the training becomes unstable. For the basic\n#   Q-learning algorithm we need many thousand states from the game-environment\n#   in order to learn important features so the Q-values can be estimated.\n#\n# - NeuralNetwork:\n#\n#   This implements a Neural Network for estimating Q-values. It takes as\n#   input a state of the game-environment that was output by the Motion Tracer,\n#   and then the Neural Network outputs the estimated Q-values that indicate\n#   the cumulative reward of taking each action for a given state of the game.\n#\n# - Agent:\n#\n#   This implements the agent that plays games. It loads an Atari-game from\n#   OpenAI Gym and inputs the game-images to the Motion Tracer, which in turn\n#   outputs a state that is input to the Neural Network, which estimates the\n#   Q-values that are used for selecting the next action. The agent then\n#   takes a step in the game-environment. During training, the data is added\n#   to the Replay Memory and when it is sufficiently full, an optimization run\n#   is performed so as to improve the Neural Network\'s ability to estimate\n#   Q-values. This procedure is repeated many, many times until the Neural\n#   Network is sufficiently accurate at estimating Q-values.\n#\n# The Q-Value Formula:\n#\n# The Q-values for a given state is a vector with a value for each possible\n# action, indicating the total future reward that can be had by taking each\n# action. The Q-values are initialized to roughly zero and must then be\n# improved iteratively when new information becomes available.\n#\n# We know which action was taken in the current step and what the observed\n# reward was, so the estimated Q-value can be improved with this information.\n# The Q-value estimates the total cumulative reward for all future steps, which\n# is why we use the max Q-value for the next step.\n#\n# The formula for updating Q-values is implemented in the ReplayMemory-class\n# in the function update_all_q_values(), which does a complete backwards-sweep\n# through the Replay Memory. The formula for updating the Q-values is:\n#\n# Q-value for this state and action = observed reward for the current step\n#                            + discount factor * max Q-value for next step\n#\n# The discount factor is a number slightly below 1.0 (e.g. 0.97) which causes\n# distant future rewards to have a smaller effect on the Q-values. This means\n# that if the reward is the same, then it is considered more valuable to get\n# the reward sooner rather than later.\n#\n# Pseudo-Code:\n#\n# There are many lines of source-code required to implement all this, but the\n# main ideas of the algorithm can be described more simply in pseudo-code:\n#\n# 1) Initialize all Q-values to roughly zero.\n#    We use a Neural Network to estimate the Q-values, so this means\n#    we have to initialize the Neural Network with small random weights.\n#\n# 2) Reset the game-environment and Motion Tracer.\n#\n# 3) Get the state from the Motion Tracer which consists of two gray-scale\n#    images. The first is the image of the game-environment and the second\n#    is a motion-trace showing recent movements in the game-environment.\n#\n# 4) Input the state to the Neural Network to estimate the Q-values.\n#\n# 5) Either take a random action with probability epsilon, or take the\n#    action with the highest Q-value. This is called the epsilon-greedy policy.\n#\n# 6) Add the state, action and observed reward to the Replay Memory.\n#\n# 7) When the Replay Memory is sufficiently full, first perform a full\n#    backwards-sweep to update all the Q-values with the observed rewards.\n#\n#    Then perform an optimization run of the Neural Network.\n#    This takes random batches of data from the Replay Memory and uses them\n#    for training the Neural Network to become better at estimating Q-values.\n#\n#    Save a checkpoint for the Neural Network so we can reload it later.\n#\n# 8) Input the recent image of the game-environment to the Motion Tracer\n#    and repeat from step (3).\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2017 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\n# Use TensorFlow v.2 with this old v.1 code.\n# E.g. placeholder variables and sessions have changed in TF2.\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\nimport numpy as np\nimport gym\nimport PIL.Image\nimport sys\nimport os\nimport time\nimport csv\nimport argparse\n\n########################################################################\n# File-paths are global variables for convenience so they don\'t\n# have to be passed around between all the objects.\n# You should first set checkpoint_base_dir to whichever you like,\n# then call the function update_paths(env_name) to update all the paths.\n# This should be done before you create the Agent and NeuralNetwork etc.\n\n# Default base-directory for the checkpoints and log-files.\n# The environment-name will be appended to this.\ncheckpoint_base_dir = \'checkpoints_tutorial16/\'\n\n# Combination of base-dir and environment-name.\ncheckpoint_dir = None\n\n# Full path for the log-file for rewards.\nlog_reward_path = None\n\n# Full path for the log-file for Q-values.\nlog_q_values_path = None\n\n\ndef update_paths(env_name):\n    """"""\n    Update the path-names for the checkpoint-dir and log-files.\n    \n    Call this after you have changed checkpoint_base_dir and\n    before you create the Neural Network.\n    \n    :param env_name:\n        Name of the game-environment you will use in OpenAI Gym.\n    """"""\n\n    global checkpoint_dir\n    global log_reward_path\n    global log_q_values_path\n\n    # Add the environment-name to the checkpoint-dir.\n    checkpoint_dir = os.path.join(checkpoint_base_dir, env_name)\n\n    # Create the checkpoint-dir if it does not already exist.\n    if not os.path.exists(checkpoint_dir):\n        os.makedirs(checkpoint_dir)\n\n    # File-path for the log-file for episode rewards.\n    log_reward_path = os.path.join(checkpoint_dir, ""log_reward.txt"")\n\n    # File-path for the log-file for Q-values.\n    log_q_values_path = os.path.join(checkpoint_dir, ""log_q_values.txt"")\n\n\n########################################################################\n# Classes used for logging data during training.\n\n\nclass Log:\n    """"""\n    Base-class for logging data to a text-file during training.\n\n    It is possible to use TensorFlow / TensorBoard for this,\n    but it is quite awkward to implement, as it was intended\n    for logging variables and other aspects of the TensorFlow graph.\n    We want to log the reward and Q-values which are not in that graph.\n    """"""\n\n    def __init__(self, file_path):\n        """"""Set the path for the log-file. Nothing is saved or loaded yet.""""""\n\n        # Path for the log-file.\n        self.file_path = file_path\n\n        # Data to be read from the log-file by the _read() function.\n        self.count_episodes = None\n        self.count_states = None\n        self.data = None\n\n    def _write(self, count_episodes, count_states, msg):\n        """"""\n        Write a line to the log-file. This is only called by sub-classes.\n        \n        :param count_episodes:\n            Counter for the number of episodes processed during training.\n\n        :param count_states: \n            Counter for the number of states processed during training.\n\n        :param msg:\n            Message to write in the log.\n        """"""\n\n        with open(file=self.file_path, mode=\'a\', buffering=1) as file:\n            msg_annotated = ""{0}\\t{1}\\t{2}\\n"".format(count_episodes, count_states, msg)\n            file.write(msg_annotated)\n\n    def _read(self):\n        """"""\n        Read the log-file into memory so it can be plotted.\n\n        It sets self.count_episodes, self.count_states and self.data\n        """"""\n\n        # Open and read the log-file.\n        with open(self.file_path) as f:\n            reader = csv.reader(f, delimiter=""\\t"")\n            self.count_episodes, self.count_states, *data = zip(*reader)\n\n        # Convert the remaining log-data to a NumPy float-array.\n        self.data = np.array(data, dtype=\'float\')\n\n\nclass LogReward(Log):\n    """"""Log the rewards obtained for episodes during training.""""""\n\n    def __init__(self):\n        # These will be set in read() below.\n        self.episode = None\n        self.mean = None\n\n        # Super-class init.\n        Log.__init__(self, file_path=log_reward_path)\n\n    def write(self, count_episodes, count_states, reward_episode, reward_mean):\n        """"""\n        Write the episode and mean reward to file.\n        \n        :param count_episodes:\n            Counter for the number of episodes processed during training.\n\n        :param count_states: \n            Counter for the number of states processed during training.\n\n        :param reward_episode:\n            Reward for one episode.\n\n        :param reward_mean:\n            Mean reward for the last e.g. 30 episodes.\n        """"""\n\n        msg = ""{0:.1f}\\t{1:.1f}"".format(reward_episode, reward_mean)\n        self._write(count_episodes=count_episodes, count_states=count_states, msg=msg)\n\n    def read(self):\n        """"""\n        Read the log-file into memory so it can be plotted.\n\n        It sets self.count_episodes, self.count_states, self.episode and self.mean\n        """"""\n\n        # Read the log-file using the super-class.\n        self._read()\n\n        # Get the episode reward.\n        self.episode = self.data[0]\n\n        # Get the mean reward.\n        self.mean = self.data[1]\n\n\nclass LogQValues(Log):\n    """"""Log the Q-Values during training.""""""\n\n    def __init__(self):\n        # These will be set in read() below.\n        self.min = None\n        self.mean = None\n        self.max = None\n        self.std = None\n\n        # Super-class init.\n        Log.__init__(self, file_path=log_q_values_path)\n\n    def write(self, count_episodes, count_states, q_values):\n        """"""\n        Write basic statistics for the Q-values to file.\n\n        :param count_episodes:\n            Counter for the number of episodes processed during training.\n\n        :param count_states: \n            Counter for the number of states processed during training.\n\n        :param q_values:\n            Numpy array with Q-values from the replay-memory.\n        """"""\n\n        msg = ""{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}"".format(np.min(q_values),\n                                                          np.mean(q_values),\n                                                          np.max(q_values),\n                                                          np.std(q_values))\n\n        self._write(count_episodes=count_episodes,\n                    count_states=count_states,\n                    msg=msg)\n\n    def read(self):\n        """"""\n        Read the log-file into memory so it can be plotted.\n\n        It sets self.count_episodes, self.count_states, self.min / mean / max / std.\n        """"""\n\n        # Read the log-file using the super-class.\n        self._read()\n\n        # Get the logged statistics for the Q-values.\n        self.min = self.data[0]\n        self.mean = self.data[1]\n        self.max = self.data[2]\n        self.std = self.data[3]\n\n########################################################################\n\n\ndef print_progress(msg):\n    """"""\n    Print progress on a single line and overwrite the line.\n    Used during optimization.\n    """"""\n\n    sys.stdout.write(""\\r"" + msg)\n    sys.stdout.flush()\n\n########################################################################\n# A state is basically just a multi-dimensional array that is being\n# input to the Neural Network. The state consists of pre-processed images\n# from the game-environment. We will just convert the game-images to\n# gray-scale and resize them to roughly half their size. This is mainly\n# so we can save memory-space in the Replay Memory further below.\n# The original DeepMind paper used game-states consisting of 4 frames of\n# game-images that were gray-scaled, resized to 110 x 84 pixels, and then\n# cropped to 84 x 84 pixels because their implementation only supported this.\n\n# Height of each image-frame in the state.\nstate_height = 105\n\n# Width of each image-frame in the state.\nstate_width = 80\n\n# Size of each image in the state.\nstate_img_size = np.array([state_height, state_width])\n\n# Size of each image in the state. Reversed order used by PIL.Image.\nstate_img_size_reverse = tuple(reversed(state_img_size))\n\n# Number of images in the state.\nstate_channels = 2\n\n# Shape of the state-array.\nstate_shape = [state_height, state_width, state_channels]\n\n########################################################################\n# Functions and classes for processing images from the game-environment\n# and converting them into a state.\n\n\ndef _rgb_to_grayscale(image):\n    """"""\n    Convert an RGB-image into gray-scale using a formula from Wikipedia:\n    https://en.wikipedia.org/wiki/Grayscale\n    """"""\n\n    # Get the separate colour-channels.\n    r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n\n    # Convert to gray-scale using the Wikipedia formula.\n    img_gray = 0.2990 * r + 0.5870 * g + 0.1140 * b\n\n    return img_gray\n\n\ndef _pre_process_image(image):\n    """"""Pre-process a raw image from the game-environment.""""""\n\n    # Convert image to gray-scale.\n    img_gray = _rgb_to_grayscale(image=image)\n\n    # Create PIL-object from numpy array.\n    img = PIL.Image.fromarray(img_gray)\n\n    # Resize the image.\n    img_resized = img.resize(size=state_img_size_reverse,\n                             resample=PIL.Image.LINEAR)\n\n    # Convert 8-bit pixel values back to floating-point.\n    img_resized = np.float32(img_resized)\n\n    return img_resized\n\n\nclass MotionTracer:\n    """"""\n    Used for processing raw image-frames from the game-environment.\n\n    The image-frames are converted to gray-scale, resized, and then\n    the background is removed using filtering of the image-frames\n    so as to detect motions.\n\n    This is needed because a single image-frame of the game environment\n    is insufficient to determine the direction of moving objects.\n    \n    The original DeepMind implementation used the last 4 image-frames\n    of the game-environment to allow the Neural Network to learn how\n    to detect motion. This implementation could make it a little easier\n    for the Neural Network to learn how to detect motion, but it has\n    only been tested on Breakout and Space Invaders, and may not work\n    for games with more complicated graphics such as Doom. This remains\n    to be tested.\n    """"""\n\n    def __init__(self, image, decay=0.75):\n        """"""\n        \n        :param image:\n            First image from the game-environment,\n            used for resetting the motion detector.\n\n        :param decay:\n            Parameter for how long the tail should be on the motion-trace.\n            This is a float between 0.0 and 1.0 where higher values means\n            the trace / tail is longer.\n        """"""\n\n        # Pre-process the image and save it for later use.\n        # The input image may be 8-bit integers but internally\n        # we need to use floating-point to avoid image-noise\n        # caused by recurrent rounding-errors.\n        img = _pre_process_image(image=image)\n        self.last_input = img.astype(np.float)\n\n        # Set the last output to zero.\n        self.last_output = np.zeros_like(img)\n\n        self.decay = decay\n\n    def process(self, image):\n        """"""Process a raw image-frame from the game-environment.""""""\n\n        # Pre-process the image so it is gray-scale and resized.\n        img = _pre_process_image(image=image)\n\n        # Subtract the previous input. This only leaves the\n        # pixels that have changed in the two image-frames.\n        img_dif = img - self.last_input\n\n        # Copy the contents of the input-image to the last input.\n        self.last_input[:] = img[:]\n\n        # If the pixel-difference is greater than a threshold then\n        # set the output pixel-value to the highest value (white),\n        # otherwise set the output pixel-value to the lowest value (black).\n        # So that we merely detect motion, and don\'t care about details.\n        img_motion = np.where(np.abs(img_dif) > 20, 255.0, 0.0)\n\n        # Add some of the previous output. This recurrent formula\n        # is what gives the trace / tail.\n        output = img_motion + self.decay * self.last_output\n\n        # Ensure the pixel-values are within the allowed bounds.\n        output = np.clip(output, 0.0, 255.0)\n\n        # Set the last output.\n        self.last_output = output\n\n        return output\n\n    def get_state(self):\n        """"""\n        Get a state that can be used as input to the Neural Network.\n\n        It is basically just the last input and the last output of the\n        motion-tracer. This means it is the last image-frame of the\n        game-environment, as well as the motion-trace. This shows\n        the current location of all the objects in the game-environment\n        as well as trajectories / traces of where they have been.\n        """"""\n\n        # Stack the last input and output images.\n        state = np.dstack([self.last_input, self.last_output])\n\n        # Convert to 8-bit integer.\n        # This is done to save space in the replay-memory.\n        state = state.astype(np.uint8)\n\n        return state\n\n########################################################################\n\n\nclass ReplayMemory:\n    """"""\n    The replay-memory holds many previous states of the game-environment.\n    This helps stabilize training of the Neural Network because the data\n    is more diverse when sampled over thousands of different states.\n    """"""\n\n    def __init__(self, size, num_actions, discount_factor=0.97):\n        """"""\n        \n        :param size:\n            Capacity of the replay-memory. This is the number of states.\n\n        :param num_actions:\n            Number of possible actions in the game-environment. \n\n        :param discount_factor:\n            Discount-factor used for updating Q-values.\n        """"""\n\n        # Array for the previous states of the game-environment.\n        self.states = np.zeros(shape=[size] + state_shape, dtype=np.uint8)\n\n        # Array for the Q-values corresponding to the states.\n        self.q_values = np.zeros(shape=[size, num_actions], dtype=np.float)\n\n        # Array for the Q-values before being updated.\n        # This is used to compare the Q-values before and after the update.\n        self.q_values_old = np.zeros(shape=[size, num_actions], dtype=np.float)\n\n        # Actions taken for each of the states in the memory.\n        self.actions = np.zeros(shape=size, dtype=np.int)\n\n        # Rewards observed for each of the states in the memory.\n        self.rewards = np.zeros(shape=size, dtype=np.float)\n\n        # Whether the life had ended in each state of the game-environment.\n        self.end_life = np.zeros(shape=size, dtype=np.bool)\n\n        # Whether the episode had ended (aka. game over) in each state.\n        self.end_episode = np.zeros(shape=size, dtype=np.bool)\n\n        # Estimation errors for the Q-values. This is used to balance\n        # the sampling of batches for training the Neural Network,\n        # so we get a balanced combination of states with high and low\n        # estimation errors for their Q-values.\n        self.estimation_errors = np.zeros(shape=size, dtype=np.float)\n\n        # Capacity of the replay-memory as the number of states.\n        self.size = size\n\n        # Discount-factor for calculating Q-values.\n        self.discount_factor = discount_factor\n\n        # Reset the number of used states in the replay-memory.\n        self.num_used = 0\n\n        # Threshold for splitting between low and high estimation errors.\n        self.error_threshold = 0.1\n\n    def is_full(self):\n        """"""Return boolean whether the replay-memory is full.""""""\n        return self.num_used == self.size\n\n    def used_fraction(self):\n        """"""Return the fraction of the replay-memory that is used.""""""\n        return self.num_used / self.size\n\n    def reset(self):\n        """"""Reset the replay-memory so it is empty.""""""\n        self.num_used = 0\n\n    def add(self, state, q_values, action, reward, end_life, end_episode):\n        """"""\n        Add an observed state from the game-environment, along with the\n        estimated Q-values, action taken, observed reward, etc. \n        \n        :param state:\n            Current state of the game-environment.\n            This is the output of the MotionTracer-class.\n\n        :param q_values: \n            The estimated Q-values for the state.\n\n        :param action: \n            The action taken by the agent in this state of the game.\n\n        :param reward:\n            The reward that was observed from taking this action\n            and moving to the next state.\n\n        :param end_life:\n            Boolean whether the agent has lost a life in this state.\n         \n        :param end_episode: \n            Boolean whether the agent has lost all lives aka. game over\n            aka. end of episode.\n        """"""\n\n        if not self.is_full():\n            # Index into the arrays for convenience.\n            k = self.num_used\n\n            # Increase the number of used elements in the replay-memory.\n            self.num_used += 1\n\n            # Store all the values in the replay-memory.\n            self.states[k] = state\n            self.q_values[k] = q_values\n            self.actions[k] = action\n            self.end_life[k] = end_life\n            self.end_episode[k] = end_episode\n\n            # Note that the reward is limited. This is done to stabilize\n            # the training of the Neural Network.\n            self.rewards[k] = np.clip(reward, -1.0, 1.0)\n\n    def update_all_q_values(self):\n        """"""\n        Update all Q-values in the replay-memory.\n        \n        When states and Q-values are added to the replay-memory, the\n        Q-values have been estimated by the Neural Network. But we now\n        have more data available that we can use to improve the estimated\n        Q-values, because we now know which actions were taken and the\n        observed rewards. We sweep backwards through the entire replay-memory\n        to use the observed data to improve the estimated Q-values.\n        """"""\n\n        # Copy old Q-values so we can print their statistics later.\n        # Note that the contents of the arrays are copied.\n        self.q_values_old[:] = self.q_values[:]\n\n        # Process the replay-memory backwards and update the Q-values.\n        # This loop could be implemented entirely in NumPy for higher speed,\n        # but it is probably only a small fraction of the overall time usage,\n        # and it is much easier to understand when implemented like this.\n        for k in reversed(range(self.num_used-1)):\n            # Get the data for the k\'th state in the replay-memory.\n            action = self.actions[k]\n            reward = self.rewards[k]\n            end_life = self.end_life[k]\n            end_episode = self.end_episode[k]\n\n            # Calculate the Q-value for the action that was taken in this state.\n            if end_life or end_episode:\n                # If the agent lost a life or it was game over / end of episode,\n                # then the value of taking the given action is just the reward\n                # that was observed in this single step. This is because the\n                # Q-value is defined as the discounted value of all future game\n                # steps in a single life of the agent. When the life has ended,\n                # there will be no future steps.\n                action_value = reward\n            else:\n                # Otherwise the value of taking the action is the reward that\n                # we have observed plus the discounted value of future rewards\n                # from continuing the game. We use the estimated Q-values for\n                # the following state and take the maximum, because we will\n                # generally take the action that has the highest Q-value.\n                action_value = reward + self.discount_factor * np.max(self.q_values[k + 1])\n\n            # Error of the Q-value that was estimated using the Neural Network.\n            self.estimation_errors[k] = abs(action_value - self.q_values[k, action])\n\n            # Update the Q-value with the better estimate.\n            self.q_values[k, action] = action_value\n\n        self.print_statistics()\n\n    def prepare_sampling_prob(self, batch_size=128):\n        """"""\n        Prepare the probability distribution for random sampling of states\n        and Q-values for use in training of the Neural Network.\n\n        The probability distribution is just a simple binary split of the\n        replay-memory based on the estimation errors of the Q-values.\n        The idea is to create a batch of samples that are balanced somewhat\n        evenly between Q-values that the Neural Network already knows how to\n        estimate quite well because they have low estimation errors, and\n        Q-values that are poorly estimated by the Neural Network because\n        they have high estimation errors.\n        \n        The reason for this balancing of Q-values with high and low estimation\n        errors, is that if we train the Neural Network mostly on data with\n        high estimation errors, then it will tend to forget what it already\n        knows and hence become over-fit so the training becomes unstable.\n        """"""\n\n        # Get the errors between the Q-values that were estimated using\n        # the Neural Network, and the Q-values that were updated with the\n        # reward that was actually observed when an action was taken.\n        err = self.estimation_errors[0:self.num_used]\n\n        # Create an index of the estimation errors that are low.\n        idx = err<self.error_threshold\n        self.idx_err_lo = np.squeeze(np.where(idx))\n\n        # Create an index of the estimation errors that are high.\n        self.idx_err_hi = np.squeeze(np.where(np.logical_not(idx)))\n\n        # Probability of sampling Q-values with high estimation errors.\n        # This is either set to the fraction of the replay-memory that\n        # has high estimation errors - or it is set to 0.5. So at least\n        # half of the batch has high estimation errors.\n        prob_err_hi = len(self.idx_err_hi) / self.num_used\n        prob_err_hi = max(prob_err_hi, 0.5)\n\n        # Number of samples in a batch that have high estimation errors.\n        self.num_samples_err_hi = int(prob_err_hi * batch_size)\n\n        # Number of samples in a batch that have low estimation errors.\n        self.num_samples_err_lo = batch_size - self.num_samples_err_hi\n\n    def random_batch(self):\n        """"""\n        Get a random batch of states and Q-values from the replay-memory.\n        You must call prepare_sampling_prob() before calling this function,\n        which also sets the batch-size.\n\n        The batch has been balanced so it contains states and Q-values\n        that have both high and low estimation errors for the Q-values.\n        This is done to both speed up and stabilize training of the\n        Neural Network.\n        """"""\n\n        # Random index of states and Q-values in the replay-memory.\n        # These have LOW estimation errors for the Q-values.\n        idx_lo = np.random.choice(self.idx_err_lo,\n                                  size=self.num_samples_err_lo,\n                                  replace=False)\n\n        # Random index of states and Q-values in the replay-memory.\n        # These have HIGH estimation errors for the Q-values.\n        idx_hi = np.random.choice(self.idx_err_hi,\n                                  size=self.num_samples_err_hi,\n                                  replace=False)\n\n        # Combine the indices.\n        idx = np.concatenate((idx_lo, idx_hi))\n\n        # Get the batches of states and Q-values.\n        states_batch = self.states[idx]\n        q_values_batch = self.q_values[idx]\n\n        return states_batch, q_values_batch\n\n    def all_batches(self, batch_size=128):\n        """"""\n        Iterator for all the states and Q-values in the replay-memory.\n        It returns the indices for the beginning and end, as well as\n        a progress-counter between 0.0 and 1.0.\n        \n        This function is not currently being used except by the function\n        estimate_all_q_values() below. These two functions are merely\n        included to make it easier for you to experiment with the code\n        by showing you an easy and efficient way to loop over all the\n        data in the replay-memory.\n        """"""\n\n        # Start index for the current batch.\n        begin = 0\n\n        # Repeat until all batches have been processed.\n        while begin < self.num_used:\n            # End index for the current batch.\n            end = begin + batch_size\n\n            # Ensure the batch does not exceed the used replay-memory.\n            if end > self.num_used:\n                end = self.num_used\n\n            # Progress counter.\n            progress = end / self.num_used\n\n            # Yield the batch indices and completion-counter.\n            yield begin, end, progress\n\n            # Set the start-index for the next batch to the end of this batch.\n            begin = end\n\n    def estimate_all_q_values(self, model):\n        """"""\n        Estimate all Q-values for the states in the replay-memory\n        using the model / Neural Network.\n\n        Note that this function is not currently being used. It is provided\n        to make it easier for you to experiment with this code, by showing\n        you an efficient way to iterate over all the states and Q-values.\n\n        :param model:\n            Instance of the NeuralNetwork-class.\n        """"""\n\n        print(""Re-calculating all Q-values in replay memory ..."")\n\n        # Process the entire replay-memory in batches.\n        for begin, end, progress in self.all_batches():\n            # Print progress.\n            msg = ""\\tProgress: {0:.0%}""\n            msg = msg.format(progress)\n            print_progress(msg)\n\n            # Get the states for the current batch.\n            states = self.states[begin:end]\n\n            # Calculate the Q-values using the Neural Network\n            # and update the replay-memory.\n            self.q_values[begin:end] = model.get_q_values(states=states)\n\n        # Newline.\n        print()\n\n    def print_statistics(self):\n        """"""Print statistics for the contents of the replay-memory.""""""\n\n        print(""Replay-memory statistics:"")\n\n        # Print statistics for the Q-values before they were updated\n        # in update_all_q_values().\n        msg = ""\\tQ-values Before, Min: {0:5.2f}, Mean: {1:5.2f}, Max: {2:5.2f}""\n        print(msg.format(np.min(self.q_values_old),\n                         np.mean(self.q_values_old),\n                         np.max(self.q_values_old)))\n\n        # Print statistics for the Q-values after they were updated\n        # in update_all_q_values().\n        msg = ""\\tQ-values After,  Min: {0:5.2f}, Mean: {1:5.2f}, Max: {2:5.2f}""\n        print(msg.format(np.min(self.q_values),\n                         np.mean(self.q_values),\n                         np.max(self.q_values)))\n\n        # Print statistics for the difference in Q-values before and\n        # after the update in update_all_q_values().\n        q_dif = self.q_values - self.q_values_old\n        msg = ""\\tQ-values Diff.,  Min: {0:5.2f}, Mean: {1:5.2f}, Max: {2:5.2f}""\n        print(msg.format(np.min(q_dif),\n                         np.mean(q_dif),\n                         np.max(q_dif)))\n\n        # Print statistics for the number of large estimation errors.\n        # Don\'t use the estimation error for the last state in the memory,\n        # because its Q-values have not been updated.\n        err = self.estimation_errors[:-1]\n        err_count = np.count_nonzero(err > self.error_threshold)\n        msg = ""\\tNumber of large errors > {0}: {1} / {2} ({3:.1%})""\n        print(msg.format(self.error_threshold, err_count,\n                         self.num_used, err_count / self.num_used))\n\n        # How much of the replay-memory is used by states with end_life.\n        end_life_pct = np.count_nonzero(self.end_life) / self.num_used\n\n        # How much of the replay-memory is used by states with end_episode.\n        end_episode_pct = np.count_nonzero(self.end_episode) / self.num_used\n\n        # How much of the replay-memory is used by states with non-zero reward.\n        reward_nonzero_pct = np.count_nonzero(self.rewards) / self.num_used\n\n        # Print those statistics.\n        msg = ""\\tend_life: {0:.1%}, end_episode: {1:.1%}, reward non-zero: {2:.1%}""\n        print(msg.format(end_life_pct, end_episode_pct, reward_nonzero_pct))\n\n########################################################################\n\n\nclass LinearControlSignal:\n    """"""\n    A control signal that changes linearly over time.\n\n    This is used to change e.g. the learning-rate for the optimizer\n    of the Neural Network, as well as other parameters.\n    \n    TensorFlow has functionality for doing this, but it uses the\n    global_step counter inside the TensorFlow graph, while we\n    want the control signals to use a state-counter for the\n    game-environment. So it is easier to make this in Python.\n    """"""\n\n    def __init__(self, start_value, end_value, num_iterations, repeat=False):\n        """"""\n        Create a new object.\n\n        :param start_value:\n            Start-value for the control signal.\n\n        :param end_value:\n            End-value for the control signal.\n\n        :param num_iterations:\n            Number of iterations it takes to reach the end_value\n            from the start_value.\n\n        :param repeat:\n            Boolean whether to reset the control signal back to the start_value\n            after the end_value has been reached.\n        """"""\n\n        # Store arguments in this object.\n        self.start_value = start_value\n        self.end_value = end_value\n        self.num_iterations = num_iterations\n        self.repeat = repeat\n\n        # Calculate the linear coefficient.\n        self._coefficient = (end_value - start_value) / num_iterations\n\n    def get_value(self, iteration):\n        """"""Get the value of the control signal for the given iteration.""""""\n\n        if self.repeat:\n            iteration %= self.num_iterations\n\n        if iteration < self.num_iterations:\n            value = iteration * self._coefficient + self.start_value\n        else:\n            value = self.end_value\n\n        return value\n\n########################################################################\n\n\nclass EpsilonGreedy:\n    """"""\n    The epsilon-greedy policy either takes a random action with\n    probability epsilon, or it takes the action for the highest\n    Q-value.\n    \n    If epsilon is 1.0 then the actions are always random.\n    If epsilon is 0.0 then the actions are always argmax for the Q-values.\n\n    Epsilon is typically decreased linearly from 1.0 to 0.1\n    and this is also implemented in this class.\n\n    During testing, epsilon is usually chosen lower, e.g. 0.05 or 0.01\n    """"""\n\n    def __init__(self, num_actions,\n                 epsilon_testing=0.05,\n                 num_iterations=1e6,\n                 start_value=1.0, end_value=0.1,\n                 repeat=False):\n        """"""\n        \n        :param num_actions:\n            Number of possible actions in the game-environment.\n\n        :param epsilon_testing:\n            Epsilon-value when testing.\n\n        :param num_iterations:\n            Number of training iterations required to linearly\n            decrease epsilon from start_value to end_value.\n            \n        :param start_value:\n            Starting value for linearly decreasing epsilon.\n\n        :param end_value:\n            Ending value for linearly decreasing epsilon.\n\n        :param repeat:\n            Boolean whether to repeat and restart the linear decrease\n            when the end_value is reached, or only do it once and then\n            output the end_value forever after.\n        """"""\n\n        # Store parameters.\n        self.num_actions = num_actions\n        self.epsilon_testing = epsilon_testing\n\n        # Create a control signal for linearly decreasing epsilon.\n        self.epsilon_linear = LinearControlSignal(num_iterations=num_iterations,\n                                                  start_value=start_value,\n                                                  end_value=end_value,\n                                                  repeat=repeat)\n\n    def get_epsilon(self, iteration, training):\n        """"""\n        Return the epsilon for the given iteration.\n        If training==True then epsilon is linearly decreased,\n        otherwise epsilon is a fixed number.\n        """"""\n\n        if training:\n            epsilon = self.epsilon_linear.get_value(iteration=iteration)\n        else:\n            epsilon = self.epsilon_testing\n\n        return epsilon\n\n    def get_action(self, q_values, iteration, training):\n        """"""\n        Use the epsilon-greedy policy to select an action.\n        \n        :param q_values:\n            These are the Q-values that are estimated by the Neural Network\n            for the current state of the game-environment.\n         \n        :param iteration:\n            This is an iteration counter. Here we use the number of states\n            that has been processed in the game-environment.\n\n        :param training:\n            Boolean whether we are training or testing the\n            Reinforcement Learning agent.\n\n        :return:\n            action (integer), epsilon (float)\n        """"""\n\n        epsilon = self.get_epsilon(iteration=iteration, training=training)\n\n        # With probability epsilon.\n        if np.random.random() < epsilon:\n            # Select a random action.\n            action = np.random.randint(low=0, high=self.num_actions)\n        else:\n            # Otherwise select the action that has the highest Q-value.\n            action = np.argmax(q_values)\n\n        return action, epsilon\n\n########################################################################\n\n\nclass NeuralNetwork:\n    """"""\n    Creates a Neural Network for Reinforcement Learning (Q-Learning).\n\n    Functions are provided for estimating Q-values from states of the\n    game-environment, and for optimizing the Neural Network so it becomes\n    better at estimating the Q-values.\n    """"""\n\n    def __init__(self, num_actions, replay_memory):\n        """"""\n        :param num_actions:\n            Number of discrete actions for the game-environment.\n\n        :param replay_memory: \n            Object-instance of the ReplayMemory-class.\n        """"""\n\n        # Replay-memory used for sampling random batches.\n        self.replay_memory = replay_memory\n\n        # Path for saving/restoring checkpoints.\n        self.checkpoint_path = os.path.join(checkpoint_dir, ""checkpoint"")\n\n        # Placeholder variable for inputting states into the Neural Network.\n        # A state is a multi-dimensional array holding image-frames from\n        # the game-environment.\n        self.x = tf.placeholder(dtype=tf.float32, shape=[None] + state_shape, name=\'x\')\n\n        # Placeholder variable for inputting the learning-rate to the optimizer.\n        self.learning_rate = tf.placeholder(dtype=tf.float32, shape=[])\n\n        # Placeholder variable for inputting the target Q-values\n        # that we want the Neural Network to be able to estimate.\n        self.q_values_new = tf.placeholder(tf.float32,\n                                           shape=[None, num_actions],\n                                           name=\'q_values_new\')\n\n        # This is a hack that allows us to save/load the counter for\n        # the number of states processed in the game-environment.\n        # We will keep it as a variable in the TensorFlow-graph\n        # even though it will not actually be used by TensorFlow.\n        self.count_states = tf.Variable(initial_value=0,\n                                        trainable=False, dtype=tf.int64,\n                                        name=\'count_states\')\n\n        # Similarly, this is the counter for the number of episodes.\n        self.count_episodes = tf.Variable(initial_value=0,\n                                          trainable=False, dtype=tf.int64,\n                                          name=\'count_episodes\')\n\n        # TensorFlow operation for increasing count_states.\n        self.count_states_increase = tf.assign(self.count_states,\n                                               self.count_states + 1)\n\n        # TensorFlow operation for increasing count_episodes.\n        self.count_episodes_increase = tf.assign(self.count_episodes,\n                                                 self.count_episodes + 1)\n\n        # The Neural Network will be constructed in the following.\n        # Note that the architecture of this Neural Network is very\n        # different from that used in the original DeepMind papers,\n        # which was something like this:\n        # Input image:      84 x 84 x 4 (4 gray-scale images of 84 x 84 pixels).\n        # Conv layer 1:     16 filters 8 x 8, stride 4, relu.\n        # Conv layer 2:     32 filters 4 x 4, stride 2, relu.\n        # Fully-conn. 1:    256 units, relu. (Sometimes 512 units).\n        # Fully-conn. 2:    num-action units, linear.\n\n        # The DeepMind architecture does a very aggressive downsampling of\n        # the input images so they are about 10 x 10 pixels after the final\n        # convolutional layer. I found that this resulted in significantly\n        # distorted Q-values when using the training method further below.\n        # The reason DeepMind could get it working was perhaps that they\n        # used a very large replay memory (5x as big as here), and a single\n        # optimization iteration was performed after each step of the game,\n        # and some more tricks.\n\n        # Initializer for the layers in the Neural Network.\n        # If you change the architecture of the network, particularly\n        # if you add or remove layers, then you may have to change\n        # the stddev-parameter here. The initial weights must result\n        # in the Neural Network outputting Q-values that are very close\n        # to zero - but the network weights must not be too low either\n        # because it will make it hard to train the network.\n        # You can experiment with values between 1e-2 and 1e-3.\n        init = tf.truncated_normal_initializer(mean=0.0, stddev=2e-2)\n\n        # This builds the Neural Network using the tf.layers API,\n        # which is very verbose and inelegant, but should work for everyone.\n\n        # Padding used for the convolutional layers.\n        padding = \'SAME\'\n\n        # Activation function for all convolutional and fully-connected\n        # layers, except the last.\n        activation = tf.nn.relu\n\n        # Reference to the lastly added layer of the Neural Network.\n        # This makes it easy to add or remove layers.\n        net = self.x\n\n        # First convolutional layer.\n        net = tf.layers.conv2d(inputs=net, name=\'layer_conv1\',\n                               filters=16, kernel_size=3, strides=2,\n                               padding=padding,\n                               kernel_initializer=init, activation=activation)\n\n        # Second convolutional layer.\n        net = tf.layers.conv2d(inputs=net, name=\'layer_conv2\',\n                               filters=32, kernel_size=3, strides=2,\n                               padding=padding,\n                               kernel_initializer=init, activation=activation)\n\n        # Third convolutional layer.\n        net = tf.layers.conv2d(inputs=net, name=\'layer_conv3\',\n                               filters=64, kernel_size=3, strides=1,\n                               padding=padding,\n                               kernel_initializer=init, activation=activation)\n\n        # Flatten output of the last convolutional layer so it can\n        # be input to a fully-connected (aka. dense) layer.\n        net = tf.layers.flatten(net)\n\n        # First fully-connected (aka. dense) layer.\n        net = tf.layers.dense(inputs=net, name=\'layer_fc1\', units=1024,\n                              kernel_initializer=init, activation=activation)\n\n        # Second fully-connected layer.\n        net = tf.layers.dense(inputs=net, name=\'layer_fc2\', units=1024,\n                              kernel_initializer=init, activation=activation)\n\n        # Third fully-connected layer.\n        net = tf.layers.dense(inputs=net, name=\'layer_fc3\', units=1024,\n                              kernel_initializer=init, activation=activation)\n\n        # Fourth fully-connected layer.\n        net = tf.layers.dense(inputs=net, name=\'layer_fc4\', units=1024,\n                              kernel_initializer=init, activation=activation)\n\n        # Final fully-connected layer.\n        net = tf.layers.dense(inputs=net, name=\'layer_fc_out\', units=num_actions,\n                              kernel_initializer=init, activation=None)\n\n        # The output of the Neural Network is the estimated Q-values\n        # for each possible action in the game-environment.\n        self.q_values = net\n\n        # TensorFlow has a built-in loss-function for doing regression:\n        # self.loss = tf.nn.l2_loss(self.q_values - self.q_values_new)\n        # But it uses tf.reduce_sum() rather than tf.reduce_mean()\n        # which is used by PrettyTensor. This means the scale of the\n        # gradient is different and hence the hyper-parameters\n        # would have to be re-tuned, because they were tuned for\n        # the original version of this tutorial using PrettyTensor.\n        # So instead we calculate the L2-loss similarly to how it is\n        # done in PrettyTensor.\n        squared_error = tf.square(self.q_values - self.q_values_new)\n        sum_squared_error = tf.reduce_sum(squared_error, axis=1)\n        self.loss = tf.reduce_mean(sum_squared_error)\n\n        # Optimizer used for minimizing the loss-function.\n        # Note the learning-rate is a placeholder variable so we can\n        # lower the learning-rate as optimization progresses.\n        self.optimizer = tf.train.RMSPropOptimizer(learning_rate=self.learning_rate).minimize(self.loss)\n\n        # Used for saving and loading checkpoints.\n        self.saver = tf.train.Saver()\n\n        # Create a new TensorFlow session so we can run the Neural Network.\n        self.session = tf.Session()\n\n        # Load the most recent checkpoint if it exists,\n        # otherwise initialize all the variables in the TensorFlow graph.\n        self.load_checkpoint()\n\n    def close(self):\n        """"""Close the TensorFlow session.""""""\n        self.session.close()\n\n    def load_checkpoint(self):\n        """"""\n        Load all variables of the TensorFlow graph from a checkpoint.\n        If the checkpoint does not exist, then initialize all variables.\n        """"""\n\n        try:\n            print(""Trying to restore last checkpoint ..."")\n\n            # Use TensorFlow to find the latest checkpoint - if any.\n            last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=checkpoint_dir)\n\n            # Try and load the data in the checkpoint.\n            self.saver.restore(self.session, save_path=last_chk_path)\n\n            # If we get to this point, the checkpoint was successfully loaded.\n            print(""Restored checkpoint from:"", last_chk_path)\n        except:\n            # If the above failed for some reason, simply\n            # initialize all the variables for the TensorFlow graph.\n            print(""Failed to restore checkpoint from:"", checkpoint_dir)\n            print(""Initializing variables instead."")\n            self.session.run(tf.global_variables_initializer())\n\n    def save_checkpoint(self, current_iteration):\n        """"""Save all variables of the TensorFlow graph to a checkpoint.""""""\n\n        self.saver.save(self.session,\n                        save_path=self.checkpoint_path,\n                        global_step=current_iteration)\n\n        print(""Saved checkpoint."")\n\n    def get_q_values(self, states):\n        """"""\n        Calculate and return the estimated Q-values for the given states.\n\n        A single state contains two images (or channels): The most recent\n        image-frame from the game-environment, and a motion-tracing image.\n        See the MotionTracer-class for details.\n\n        The input to this function is an array of such states which allows\n        for batch-processing of the states. So the input is a 4-dim\n        array with shape: [batch, height, width, state_channels].\n        \n        The output of this function is an array of Q-value-arrays.\n        There is a Q-value for each possible action in the game-environment.\n        So the output is a 2-dim array with shape: [batch, num_actions]\n        """"""\n\n        # Create a feed-dict for inputting the states to the Neural Network.\n        feed_dict = {self.x: states}\n\n        # Use TensorFlow to calculate the estimated Q-values for these states.\n        values = self.session.run(self.q_values, feed_dict=feed_dict)\n\n        return values\n\n    def optimize(self, min_epochs=1.0, max_epochs=10,\n                 batch_size=128, loss_limit=0.015,\n                 learning_rate=1e-3):\n        """"""\n        Optimize the Neural Network by sampling states and Q-values\n        from the replay-memory.\n\n        The original DeepMind paper performed one optimization iteration\n        after processing each new state of the game-environment. This is\n        an un-natural way of doing optimization of Neural Networks.\n\n        So instead we perform a full optimization run every time the\n        Replay Memory is full (or it is filled to the desired fraction).\n        This also gives more efficient use of a GPU for the optimization.\n\n        The problem is that this may over-fit the Neural Network to whatever\n        is in the replay-memory. So we use several tricks to try and adapt\n        the number of optimization iterations.\n\n        :param min_epochs:\n            Minimum number of optimization epochs. One epoch corresponds\n            to the replay-memory being used once. However, as the batches\n            are sampled randomly and biased somewhat, we may not use the\n            whole replay-memory. This number is just a convenient measure.\n\n        :param max_epochs:\n            Maximum number of optimization epochs.\n\n        :param batch_size:\n            Size of each random batch sampled from the replay-memory.\n\n        :param loss_limit:\n            Optimization continues until the average loss-value of the\n            last 100 batches is below this value (or max_epochs is reached).\n\n        :param learning_rate:\n            Learning-rate to use for the optimizer.\n        """"""\n\n        print(""Optimizing Neural Network to better estimate Q-values ..."")\n        print(""\\tLearning-rate: {0:.1e}"".format(learning_rate))\n        print(""\\tLoss-limit: {0:.3f}"".format(loss_limit))\n        print(""\\tMax epochs: {0:.1f}"".format(max_epochs))\n\n        # Prepare the probability distribution for sampling the replay-memory.\n        self.replay_memory.prepare_sampling_prob(batch_size=batch_size)\n\n        # Number of optimization iterations corresponding to one epoch.\n        iterations_per_epoch = self.replay_memory.num_used / batch_size\n\n        # Minimum number of iterations to perform.\n        min_iterations = int(iterations_per_epoch * min_epochs)\n\n        # Maximum number of iterations to perform.\n        max_iterations = int(iterations_per_epoch * max_epochs)\n\n        # Buffer for storing the loss-values of the most recent batches.\n        loss_history = np.zeros(100, dtype=float)\n\n        for i in range(max_iterations):\n            # Randomly sample a batch of states and target Q-values\n            # from the replay-memory. These are the Q-values that we\n            # want the Neural Network to be able to estimate.\n            state_batch, q_values_batch = self.replay_memory.random_batch()\n\n            # Create a feed-dict for inputting the data to the TensorFlow graph.\n            # Note that the learning-rate is also in this feed-dict.\n            feed_dict = {self.x: state_batch,\n                         self.q_values_new: q_values_batch,\n                         self.learning_rate: learning_rate}\n\n            # Perform one optimization step and get the loss-value.\n            loss_val, _ = self.session.run([self.loss, self.optimizer],\n                                           feed_dict=feed_dict)\n\n            # Shift the loss-history and assign the new value.\n            # This causes the loss-history to only hold the most recent values.\n            loss_history = np.roll(loss_history, 1)\n            loss_history[0] = loss_val\n\n            # Calculate the average loss for the previous batches.\n            loss_mean = np.mean(loss_history)\n\n            # Print status.\n            pct_epoch = i / iterations_per_epoch\n            msg = ""\\tIteration: {0} ({1:.2f} epoch), Batch loss: {2:.4f}, Mean loss: {3:.4f}""\n            msg = msg.format(i, pct_epoch, loss_val, loss_mean)\n            print_progress(msg)\n\n            # Stop the optimization if we have performed the required number\n            # of iterations and the loss-value is sufficiently low.\n            if i > min_iterations and loss_mean < loss_limit:\n                break\n\n        # Print newline.\n        print()\n\n    def get_weights_variable(self, layer_name):\n        """"""\n        Return the variable inside the TensorFlow graph for the weights\n        in the layer with the given name.\n\n        Note that the actual values of the variables are not returned,\n        you must use the function get_variable_value() for that.\n        """"""\n\n        # The tf.layers API uses this name for the weights in a conv-layer.\n        variable_name = \'kernel\'\n\n        with tf.variable_scope(layer_name, reuse=True):\n            variable = tf.get_variable(variable_name)\n\n        return variable\n\n    def get_variable_value(self, variable):\n        """"""Return the value of a variable inside the TensorFlow graph.""""""\n\n        weights = self.session.run(variable)\n\n        return weights\n\n    def get_layer_tensor(self, layer_name):\n        """"""\n        Return the tensor for the output of a layer.\n        Note that this does not return the actual values,\n        but instead returns a reference to the tensor\n        inside the TensorFlow graph. Use get_tensor_value()\n        to get the actual contents of the tensor.\n        """"""\n\n        # The name of the last operation of a layer,\n        # assuming it uses Relu as the activation-function.\n        tensor_name = layer_name + ""/Relu:0""\n\n        # Get the tensor with this name.\n        tensor = tf.get_default_graph().get_tensor_by_name(tensor_name)\n\n        return tensor\n\n    def get_tensor_value(self, tensor, state):\n        """"""Get the value of a tensor in the Neural Network.""""""\n\n        # Create a feed-dict for inputting the state to the Neural Network.\n        feed_dict = {self.x: [state]}\n\n        # Run the TensorFlow session to calculate the value of the tensor.\n        output = self.session.run(tensor, feed_dict=feed_dict)\n\n        return output\n\n    def get_count_states(self):\n        """"""\n        Get the number of states that has been processed in the game-environment.\n        This is not used by the TensorFlow graph. It is just a hack to save and\n        reload the counter along with the checkpoint-file.\n        """"""\n        return self.session.run(self.count_states)\n\n    def get_count_episodes(self):\n        """"""\n        Get the number of episodes that has been processed in the game-environment.\n        """"""\n        return self.session.run(self.count_episodes)\n\n    def increase_count_states(self):\n        """"""\n        Increase the number of states that has been processed\n        in the game-environment.\n        """"""\n        return self.session.run(self.count_states_increase)\n\n    def increase_count_episodes(self):\n        """"""\n        Increase the number of episodes that has been processed\n        in the game-environment.\n        """"""\n        return self.session.run(self.count_episodes_increase)\n\n########################################################################\n\n\nclass Agent:\n    """"""\n    This implements the function for running the game-environment with\n    an agent that uses Reinforcement Learning. This class also creates\n    instances of the Replay Memory and Neural Network.\n    """"""\n\n    def __init__(self, env_name, training, render=False, use_logging=True):\n        """"""\n        Create an object-instance. This also creates a new object for the\n        Replay Memory and the Neural Network.\n        \n        Replay Memory will only be allocated if training==True.\n\n        :param env_name:\n            Name of the game-environment in OpenAI Gym.\n            Examples: \'Breakout-v0\' and \'SpaceInvaders-v0\'\n\n        :param training:\n            Boolean whether to train the agent and Neural Network (True),\n            or test the agent by playing a number of episodes of the game (False).\n        \n        :param render:\n            Boolean whether to render the game-images to screen during testing.\n\n        :param use_logging:\n            Boolean whether to use logging to text-files during training.\n        """"""\n\n        # Create the game-environment using OpenAI Gym.\n        self.env = gym.make(env_name)\n\n        # The number of possible actions that the agent may take in every step.\n        self.num_actions = self.env.action_space.n\n\n        # Whether we are training (True) or testing (False).\n        self.training = training\n\n        # Whether to render each image-frame of the game-environment to screen.\n        self.render = render\n\n        # Whether to use logging during training.\n        self.use_logging = use_logging\n\n        if self.use_logging and self.training:\n            # Used for logging Q-values and rewards during training.\n            self.log_q_values = LogQValues()\n            self.log_reward = LogReward()\n        else:\n            self.log_q_values = None\n            self.log_reward = None\n\n        # List of string-names for the actions in the game-environment.\n        self.action_names = self.env.unwrapped.get_action_meanings()\n\n        # Epsilon-greedy policy for selecting an action from the Q-values.\n        # During training the epsilon is decreased linearly over the given\n        # number of iterations. During testing the fixed epsilon is used.\n        self.epsilon_greedy = EpsilonGreedy(start_value=1.0,\n                                            end_value=0.1,\n                                            num_iterations=1e6,\n                                            num_actions=self.num_actions,\n                                            epsilon_testing=0.01)\n\n        if self.training:\n            # The following control-signals are only used during training.\n\n            # The learning-rate for the optimizer decreases linearly.\n            self.learning_rate_control = LinearControlSignal(start_value=1e-3,\n                                                             end_value=1e-5,\n                                                             num_iterations=5e6)\n\n            # The loss-limit is used to abort the optimization whenever the\n            # mean batch-loss falls below this limit.\n            self.loss_limit_control = LinearControlSignal(start_value=0.1,\n                                                          end_value=0.015,\n                                                          num_iterations=5e6)\n\n            # The maximum number of epochs to perform during optimization.\n            # This is increased from 5 to 10 epochs, because it was found for\n            # the Breakout-game that too many epochs could be harmful early\n            # in the training, as it might cause over-fitting.\n            # Later in the training we would occasionally get rare events\n            # and would therefore have to optimize for more iterations\n            # because the learning-rate had been decreased.\n            self.max_epochs_control = LinearControlSignal(start_value=5.0,\n                                                          end_value=10.0,\n                                                          num_iterations=5e6)\n\n            # The fraction of the replay-memory to be used.\n            # Early in the training, we want to optimize more frequently\n            # so the Neural Network is trained faster and the Q-values\n            # are learned and updated more often. Later in the training,\n            # we need more samples in the replay-memory to have sufficient\n            # diversity, otherwise the Neural Network will over-fit.\n            self.replay_fraction = LinearControlSignal(start_value=0.1,\n                                                       end_value=1.0,\n                                                       num_iterations=5e6)\n        else:\n            # We set these objects to None when they will not be used.\n            self.learning_rate_control = None\n            self.loss_limit_control = None\n            self.max_epochs_control = None\n            self.replay_fraction = None\n\n        if self.training:\n            # We only create the replay-memory when we are training the agent,\n            # because it requires a lot of RAM. The image-frames from the\n            # game-environment are resized to 105 x 80 pixels gray-scale,\n            # and each state has 2 channels (one for the recent image-frame\n            # of the game-environment, and one for the motion-trace).\n            # Each pixel is 1 byte, so this replay-memory needs more than\n            # 3 GB RAM (105 x 80 x 2 x 200000 bytes).\n\n            self.replay_memory = ReplayMemory(size=200000,\n                                              num_actions=self.num_actions)\n        else:\n            self.replay_memory = None\n\n        # Create the Neural Network used for estimating Q-values.\n        self.model = NeuralNetwork(num_actions=self.num_actions,\n                                   replay_memory=self.replay_memory)\n\n        # Log of the rewards obtained in each episode during calls to run()\n        self.episode_rewards = []\n\n    def reset_episode_rewards(self):\n        """"""Reset the log of episode-rewards.""""""\n        self.episode_rewards = []\n\n    def get_action_name(self, action):\n        """"""Return the name of an action.""""""\n        return self.action_names[action]\n\n    def get_lives(self):\n        """"""Get the number of lives the agent has in the game-environment.""""""\n        return self.env.unwrapped.ale.lives()\n\n    def run(self, num_episodes=None):\n        """"""\n        Run the game-environment and use the Neural Network to decide\n        which actions to take in each step through Q-value estimates.\n        \n        :param num_episodes: \n            Number of episodes to process in the game-environment.\n            If None then continue forever. This is useful during training\n            where you might want to stop the training using Ctrl-C instead.\n        """"""\n\n        # This will cause a reset in the first iteration of the following loop.\n        end_episode = True\n\n        # Counter for the number of states we have processed.\n        # This is stored in the TensorFlow graph so it can be\n        # saved and reloaded along with the checkpoint.\n        count_states = self.model.get_count_states()\n\n        # Counter for the number of episodes we have processed.\n        count_episodes = self.model.get_count_episodes()\n\n        if num_episodes is None:\n            # Loop forever by comparing the episode-counter to infinity.\n            num_episodes = float(\'inf\')\n        else:\n            # The episode-counter may not start at zero if training is\n            # continued from a checkpoint. Take this into account\n            # when determining the number of iterations to perform.\n            num_episodes += count_episodes\n\n        while count_episodes <= num_episodes:\n            if end_episode:\n                # Reset the game-environment and get the first image-frame.\n                img = self.env.reset()\n\n                # Create a new motion-tracer for processing images from the\n                # game-environment. Initialize with the first image-frame.\n                # This resets the motion-tracer so the trace starts again.\n                # This could also be done if end_life==True.\n                motion_tracer = MotionTracer(img)\n\n                # Reset the reward for the entire episode to zero.\n                # This is only used for printing statistics.\n                reward_episode = 0.0\n\n                # Increase the counter for the number of episodes.\n                # This counter is stored inside the TensorFlow graph\n                # so it can be saved and restored with the checkpoint.\n                count_episodes = self.model.increase_count_episodes()\n\n                # Get the number of lives that the agent has left in this episode.\n                num_lives = self.get_lives()\n\n            # Get the state of the game-environment from the motion-tracer.\n            # The state has two images: (1) The last image-frame from the game\n            # and (2) a motion-trace that shows movement trajectories.\n            state = motion_tracer.get_state()\n\n            # Use the Neural Network to estimate the Q-values for the state.\n            # Note that the function assumes an array of states and returns\n            # a 2-dim array of Q-values, but we just have a single state here.\n            q_values = self.model.get_q_values(states=[state])[0]\n\n            # Determine the action that the agent must take in the game-environment.\n            # The epsilon is just used for printing further below.\n            action, epsilon = self.epsilon_greedy.get_action(q_values=q_values,\n                                                             iteration=count_states,\n                                                             training=self.training)\n\n            # Take a step in the game-environment using the given action.\n            # Note that in OpenAI Gym, the step-function actually repeats the\n            # action between 2 and 4 time-steps for Atari games, with the number\n            # chosen at random.\n            img, reward, end_episode, info = self.env.step(action=action)\n\n            # Process the image from the game-environment in the motion-tracer.\n            # This will first be used in the next iteration of the loop.\n            motion_tracer.process(image=img)\n\n            # Add the reward for the step to the reward for the entire episode.\n            reward_episode += reward\n\n            # Determine if a life was lost in this step.\n            num_lives_new = self.get_lives()\n            end_life = (num_lives_new < num_lives)\n            num_lives = num_lives_new\n\n            # Increase the counter for the number of states that have been processed.\n            count_states = self.model.increase_count_states()\n\n            if not self.training and self.render:\n                # Render the game-environment to screen.\n                self.env.render()\n\n                # Insert a small pause to slow down the game,\n                # making it easier to follow for human eyes.\n                time.sleep(0.01)\n\n            # If we want to train the Neural Network to better estimate Q-values.\n            if self.training:\n                # Add the state of the game-environment to the replay-memory.\n                self.replay_memory.add(state=state,\n                                       q_values=q_values,\n                                       action=action,\n                                       reward=reward,\n                                       end_life=end_life,\n                                       end_episode=end_episode)\n\n                # How much of the replay-memory should be used.\n                use_fraction = self.replay_fraction.get_value(iteration=count_states)\n\n                # When the replay-memory is sufficiently full.\n                if self.replay_memory.is_full() \\\n                    or self.replay_memory.used_fraction() > use_fraction:\n\n                    # Update all Q-values in the replay-memory through a backwards-sweep.\n                    self.replay_memory.update_all_q_values()\n\n                    # Log statistics for the Q-values to file.\n                    if self.use_logging:\n                        self.log_q_values.write(count_episodes=count_episodes,\n                                                count_states=count_states,\n                                                q_values=self.replay_memory.q_values)\n\n                    # Get the control parameters for optimization of the Neural Network.\n                    # These are changed linearly depending on the state-counter.\n                    learning_rate = self.learning_rate_control.get_value(iteration=count_states)\n                    loss_limit = self.loss_limit_control.get_value(iteration=count_states)\n                    max_epochs = self.max_epochs_control.get_value(iteration=count_states)\n\n                    # Perform an optimization run on the Neural Network so as to\n                    # improve the estimates for the Q-values.\n                    # This will sample random batches from the replay-memory.\n                    self.model.optimize(learning_rate=learning_rate,\n                                        loss_limit=loss_limit,\n                                        max_epochs=max_epochs)\n\n                    # Save a checkpoint of the Neural Network so we can reload it.\n                    self.model.save_checkpoint(count_states)\n\n                    # Reset the replay-memory. This throws away all the data we have\n                    # just gathered, so we will have to fill the replay-memory again.\n                    self.replay_memory.reset()\n\n            if end_episode:\n                # Add the episode\'s reward to a list for calculating statistics.\n                self.episode_rewards.append(reward_episode)\n\n            # Mean reward of the last 30 episodes.\n            if len(self.episode_rewards) == 0:\n                # The list of rewards is empty.\n                reward_mean = 0.0\n            else:\n                reward_mean = np.mean(self.episode_rewards[-30:])\n\n            if self.training and end_episode:\n                # Log reward to file.\n                if self.use_logging:\n                    self.log_reward.write(count_episodes=count_episodes,\n                                          count_states=count_states,\n                                          reward_episode=reward_episode,\n                                          reward_mean=reward_mean)\n\n                # Print reward to screen.\n                msg = ""{0:4}:{1}\\t Epsilon: {2:4.2f}\\t Reward: {3:.1f}\\t Episode Mean: {4:.1f}""\n                print(msg.format(count_episodes, count_states, epsilon,\n                                 reward_episode, reward_mean))\n            elif not self.training and (reward != 0.0 or end_life or end_episode):\n                # Print Q-values and reward to screen.\n                msg = ""{0:4}:{1}\\tQ-min: {2:5.3f}\\tQ-max: {3:5.3f}\\tLives: {4}\\tReward: {5:.1f}\\tEpisode Mean: {6:.1f}""\n                print(msg.format(count_episodes, count_states, np.min(q_values),\n                                 np.max(q_values), num_lives, reward_episode, reward_mean))\n\n########################################################################\n\nif __name__ == \'__main__\':\n    # Description of this program.\n    desc = ""Reinformenct Learning (Q-learning) for Atari Games using TensorFlow.""\n\n    # Create the argument parser.\n    parser = argparse.ArgumentParser(description=desc)\n\n    # Add arguments to the parser.\n    parser.add_argument(""--env"", required=False, default=\'Breakout-v0\',\n                        help=""name of the game-environment in OpenAI Gym"")\n\n    parser.add_argument(""--training"", required=False,\n                        dest=\'training\', action=\'store_true\',\n                        help=""train the agent (otherwise test the agent)"")\n\n    parser.add_argument(""--render"", required=False,\n                        dest=\'render\', action=\'store_true\',\n                        help=""render game-output to screen"")\n\n    parser.add_argument(""--episodes"", required=False, type=int, default=None,\n                        help=""number of episodes to run"")\n\n    parser.add_argument(""--dir"", required=False, default=checkpoint_base_dir,\n                        help=""directory for the checkpoint and log-files"")\n\n    # Parse the command-line arguments.\n    args = parser.parse_args()\n\n    # Get the arguments.\n    env_name = args.env\n    training = args.training\n    render = args.render\n    num_episodes = args.episodes\n    checkpoint_base_dir = args.dir\n\n    # Update all the file-paths after the base-dir has been set.\n    update_paths(env_name=env_name)\n\n    # Create an agent for either training or testing on the game-environment.\n    agent = Agent(env_name=env_name,\n                  training=training,\n                  render=render)\n\n    # Run the agent\n    agent.run(num_episodes=num_episodes)\n\n    # Print statistics.\n    rewards = agent.episode_rewards\n    print()  # Newline.\n    print(""Rewards for {0} episodes:"".format(len(rewards)))\n    print(""- Min:   "", np.min(rewards))\n    print(""- Mean:  "", np.mean(rewards))\n    print(""- Max:   "", np.max(rewards))\n    print(""- Stdev: "", np.std(rewards))\n\n########################################################################\n'"
vgg16.py,4,"b'########################################################################\n#\n# The pre-trained VGG16 Model for TensorFlow.\n#\n# This model seems to produce better-looking images in Style Transfer\n# than the Inception 5h model that otherwise works well for DeepDream.\n#\n# See the Python Notebook for Tutorial #15 for an example usage.\n#\n# Implemented in Python 3.5 with TensorFlow v0.11.0rc0\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2016 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport numpy as np\nimport tensorflow as tf\nimport download\nimport os\n\n########################################################################\n# Various directories and file-names.\n\n# The pre-trained VGG16 model is taken from this tutorial:\n# https://github.com/pkmital/CADL/blob/master/session-4/libs/vgg16.py\n\n# The class-names are available in the following URL:\n# https://s3.amazonaws.com/cadl/models/synset.txt\n\n# Internet URL for the file with the VGG16 model.\n# Note that this might change in the future and will need to be updated.\ndata_url = ""https://s3.amazonaws.com/cadl/models/vgg16.tfmodel""\n\n# Directory to store the downloaded data.\ndata_dir = ""vgg16/""\n\n# File containing the TensorFlow graph definition. (Downloaded)\npath_graph_def = ""vgg16.tfmodel""\n\n########################################################################\n\n\ndef maybe_download():\n    """"""\n    Download the VGG16 model from the internet if it does not already\n    exist in the data_dir. WARNING! The file is about 550 MB.\n    """"""\n\n    print(""Downloading VGG16 Model ..."")\n\n    # The file on the internet is not stored in a compressed format.\n    # This function should not extract the file when it does not have\n    # a relevant filename-extensions such as .zip or .tar.gz\n    download.maybe_download_and_extract(url=data_url, download_dir=data_dir)\n\n\n########################################################################\n\n\nclass VGG16:\n    """"""\n    The VGG16 model is a Deep Neural Network which has already been\n    trained for classifying images into 1000 different categories.\n\n    When you create a new instance of this class, the VGG16 model\n    will be loaded and can be used immediately without training.\n    """"""\n\n    # Name of the tensor for feeding the input image.\n    tensor_name_input_image = ""images:0""\n\n    # Names of the tensors for the dropout random-values..\n    tensor_name_dropout = \'dropout/random_uniform:0\'\n    tensor_name_dropout1 = \'dropout_1/random_uniform:0\'\n\n    # Names for the convolutional layers in the model for use in Style Transfer.\n    layer_names = [\'conv1_1/conv1_1\', \'conv1_2/conv1_2\',\n                   \'conv2_1/conv2_1\', \'conv2_2/conv2_2\',\n                   \'conv3_1/conv3_1\', \'conv3_2/conv3_2\', \'conv3_3/conv3_3\',\n                   \'conv4_1/conv4_1\', \'conv4_2/conv4_2\', \'conv4_3/conv4_3\',\n                   \'conv5_1/conv5_1\', \'conv5_2/conv5_2\', \'conv5_3/conv5_3\']\n\n    def __init__(self):\n        # Now load the model from file. The way TensorFlow\n        # does this is confusing and requires several steps.\n\n        # Create a new TensorFlow computational graph.\n        self.graph = tf.Graph()\n\n        # Set the new graph as the default.\n        with self.graph.as_default():\n\n            # TensorFlow graphs are saved to disk as so-called Protocol Buffers\n            # aka. proto-bufs which is a file-format that works on multiple\n            # platforms. In this case it is saved as a binary file.\n\n            # Open the graph-def file for binary reading.\n            path = os.path.join(data_dir, path_graph_def)\n            with tf.gfile.FastGFile(path, \'rb\') as file:\n                # The graph-def is a saved copy of a TensorFlow graph.\n                # First we need to create an empty graph-def.\n                graph_def = tf.GraphDef()\n\n                # Then we load the proto-buf file into the graph-def.\n                graph_def.ParseFromString(file.read())\n\n                # Finally we import the graph-def to the default TensorFlow graph.\n                tf.import_graph_def(graph_def, name=\'\')\n\n                # Now self.graph holds the VGG16 model from the proto-buf file.\n\n            # Get a reference to the tensor for inputting images to the graph.\n            self.input = self.graph.get_tensor_by_name(self.tensor_name_input_image)\n\n            # Get references to the tensors for the commonly used layers.\n            self.layer_tensors = [self.graph.get_tensor_by_name(name + "":0"") for name in self.layer_names]\n\n    def get_layer_tensors(self, layer_ids):\n        """"""\n        Return a list of references to the tensors for the layers with the given id\'s.\n        """"""\n\n        return [self.layer_tensors[idx] for idx in layer_ids]\n\n    def get_layer_names(self, layer_ids):\n        """"""\n        Return a list of names for the layers with the given id\'s.\n        """"""\n\n        return [self.layer_names[idx] for idx in layer_ids]\n\n    def get_all_layer_names(self, startswith=None):\n        """"""\n        Return a list of all the layers (operations) in the graph.\n        The list can be filtered for names that start with the given string.\n        """"""\n\n        # Get a list of the names for all layers (operations) in the graph.\n        names = [op.name for op in self.graph.get_operations()]\n\n        # Filter the list of names so we only get those starting with\n        # the given string.\n        if startswith is not None:\n            names = [name for name in names if name.startswith(startswith)]\n\n        return names\n\n    def create_feed_dict(self, image):\n        """"""\n        Create and return a feed-dict with an image.\n\n        :param image:\n            The input image is a 3-dim array which is already decoded.\n            The pixels MUST be values between 0 and 255 (float or int).\n\n        :return:\n            Dict for feeding to the graph in TensorFlow.\n        """"""\n\n        # Expand 3-dim array to 4-dim by prepending an \'empty\' dimension.\n        # This is because we are only feeding a single image, but the\n        # VGG16 model was built to take multiple images as input.\n        image = np.expand_dims(image, axis=0)\n\n        if False:\n            # In the original code using this VGG16 model, the random values\n            # for the dropout are fixed to 1.0.\n            # Experiments suggest that it does not seem to matter for\n            # Style Transfer, and this causes an error with a GPU.\n            dropout_fix = 1.0\n\n            # Create feed-dict for inputting data to TensorFlow.\n            feed_dict = {self.tensor_name_input_image: image,\n                         self.tensor_name_dropout: [[dropout_fix]],\n                         self.tensor_name_dropout1: [[dropout_fix]]}\n        else:\n            # Create feed-dict for inputting data to TensorFlow.\n            feed_dict = {self.tensor_name_input_image: image}\n\n        return feed_dict\n\n########################################################################\n'"
weather.py,0,"b'########################################################################\n#\n# Functions for downloading and re-sampling weather-data\n# for 5 cities in Denmark between 1980-2018.\n#\n# The raw data was obtained from:\n#\n#   National Climatic Data Center (NCDC) in USA\n#   https://www7.ncdc.noaa.gov/CDO/cdoselect.cmd\n#\n# Note that the NCDC\'s database functionality may change soon, and\n# that the CSV-file needed some manual editing before it could be read.\n# See the function _convert_raw_data() below for inspiration if you\n# want to convert a new data-file from NCDC\'s database.\n#\n# Implemented in Python 3.6\n#\n# Usage:\n# 1) Set the desired storage directory in the data_dir variable.\n# 2) Call maybe_download_and_extract() to download the data-set\n#    if it is not already located in the given data_dir.\n# 3) Either call load_original_data() or load_resampled_data()\n#    to load the original or resampled data for use in your program.\n#\n# Format:\n# The raw data-file from NCDC is not included in the downloaded archive,\n# which instead contains a cleaned-up version of the raw data-file\n# referred to as the ""original data"". This data has not yet been resampled.\n# The original data-file is available as a pickled file for fast reloading\n# with Pandas, and as a CSV-file for broad compatibility.\n#\n########################################################################\n#\n# This file is part of the TensorFlow Tutorials available at:\n#\n# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n#\n# Published under the MIT License. See the file LICENSE for details.\n#\n# Copyright 2018 by Magnus Erik Hvass Pedersen\n#\n########################################################################\n\nimport pandas as pd\nimport os\nimport download\n\n########################################################################\n\n# Directory where you want to download and save the data-set.\n# Set this before you start calling any of the functions below.\ndata_dir = ""data/weather-denmark/""\n\n\n# Full path for the pickled data-file. (Original data).\ndef path_original_data_pickle():\n    return os.path.join(data_dir, ""weather-denmark.pkl"")\n\n\n# Full path for the comma-separated text-file. (Original data).\ndef path_original_data_csv():\n    return os.path.join(data_dir, ""weather-denmark.csv"")\n\n\n# Full path for the resampled data as a pickled file.\ndef path_resampled_data_pickle():\n    return os.path.join(data_dir, ""weather-denmark-resampled.pkl"")\n\n\n# URL for the data-set on the internet.\ndata_url = ""https://github.com/Hvass-Labs/weather-denmark/raw/master/weather-denmark.tar.gz""\n\n\n# List of the cities in this data-set. These are cities in Denmark.\ncities = [\'Aalborg\', \'Aarhus\', \'Esbjerg\', \'Odense\', \'Roskilde\']\n\n\n########################################################################\n# Private helper-functions.\n\n\ndef _date_string(x):\n    """"""Convert two integers to a string for the date and time.""""""\n\n    date = x[0]  # Date. Example: 19801231\n    time = x[1]  # Time. Example: 1230\n\n    return ""{0}{1:04d}"".format(date, time)\n\n\ndef _usaf_to_city(usaf):\n    """"""\n    The raw data-file uses USAF-codes to identify weather-stations.\n    If you download another data-set from NCDC then you will have to\n    change this function to use the USAF-codes in your new data-file.\n    """"""\n\n    table = \\\n        {\n            60300: \'Aalborg\',\n            60700: \'Aarhus\',\n            60800: \'Esbjerg\',\n            61200: \'Odense\',\n            61700: \'Roskilde\'\n        }\n\n    return table[usaf]\n\n\ndef _convert_raw_data(path):\n    """"""\n    This converts a raw data-file obtained from the NCDC database.\n    This function may be useful as an inspiration if you want to\n    download another raw data-file from NCDC, but you will have\n    to modify this function to match the data you have downloaded.\n\n    Note that you may also have to manually edit the raw data-file,\n    e.g. because the header is not in a proper comma-separated format.\n    """"""\n\n    # The raw CSV-file uses various markers for ""not-available"" (NA).\n    # (This is one of several oddities with NCDC\'s file-format.)\n    na_values = [\'999\', \'999.0\', \'999.9\', \'9999.9\']\n\n    # Use Pandas to load the comma-separated file.\n    # Note that you may have to manually edit the file\'s header\n    # to get this to load correctly.\n    df_raw = pd.read_csv(path, sep=\',\', header=1,\n                         index_col=False, na_values=na_values)\n\n    # Create a new data-frame containing only the data\n    # we are interested in.\n    df = pd.DataFrame()\n\n    # Get the city-name / weather-station name from the USAF code.\n    df[\'City\'] = df_raw[\'USAF  \'].apply(_usaf_to_city)\n\n    # Convert the integer date-time to a proper date-time object.\n    datestr = df_raw[[\'Date    \', \'HrMn\']].apply(_date_string, axis=1)\n    df[\'DateTime\'] = pd.to_datetime(datestr, format=\'%Y%m%d%H%M\')\n\n    # Get the data we are interested in.\n    df[\'Temp\'] = df_raw[\'Temp  \']\n    df[\'Pressure\'] = df_raw[\'Slp   \']\n    df[\'WindSpeed\'] = df_raw[\'Spd  \']\n    df[\'WindDir\'] = df_raw[\'Dir\']\n\n    # Set the city-name and date-time as the index.\n    df.set_index([\'City\', \'DateTime\'], inplace=True)\n\n    # Save the new data-frame as a pickle for fast reloading.\n    df.to_pickle(path_original_data_pickle())\n\n    # Save the new data-frame as a CSV-file for general readability.\n    df.to_csv(path_original_data_csv())\n\n    return df\n\n\ndef _resample(df):\n    """"""\n    Resample the contents of a Pandas data-frame by first\n    removing empty rows and columns, then up-sampling and\n    interpolating the data for 1-minute intervals, and\n    finally down-sampling to 60-minute intervals.\n    """"""\n\n    # Remove all empty rows.\n    df_res = df.dropna(how=\'all\')\n\n    # Upsample so the time-series has data for every minute.\n    df_res = df_res.resample(\'1T\')\n\n    # Fill in missing values.\n    df_res = df_res.interpolate(method=\'time\')\n\n    # Downsample so the time-series has data for every hour.\n    df_res = df_res.resample(\'60T\')\n\n    # Finalize the resampling. (Is this really necessary?)\n    df_res = df_res.interpolate()\n\n    # Remove all empty rows.\n    df_res = df_res.dropna(how=\'all\')\n\n    return df_res\n\n\n########################################################################\n# Public functions that you may call to download the data-set from\n# the internet and load the data into memory.\n\n\ndef maybe_download_and_extract():\n    """"""\n    Download and extract the weather-data if the data-files don\'t\n    already exist in the data_dir.\n    """"""\n\n    download.maybe_download_and_extract(url=data_url, download_dir=data_dir)\n\n\ndef load_original_data():\n    """"""\n    Load and return the original data that has not been resampled.\n    \n    Note that this is not the raw data obtained from NCDC.\n    It is a cleaned-up version of that data, as written by the\n    function _convert_raw_data() above.\n    """"""\n\n    return pd.read_pickle(path_original_data_pickle())\n\n\ndef load_resampled_data():\n    """"""\n    Load and return the resampled weather-data.\n\n    This has data-points at regular 60-minute intervals where\n    missing data has been linearly interpolated.\n\n    This uses a cache-file for saving and quickly reloading the data,\n    so the original data is only resampled once.\n    """"""\n\n    # Path for the cache-file with the resampled data.\n    path = path_resampled_data_pickle()\n\n    # If the cache-file exists ...\n    if os.path.exists(path):\n        # Reload the cache-file.\n        df = pd.read_pickle(path)\n    else:\n        # Otherwise resample the original data and save it in a cache-file.\n\n        # Load the original data.\n        df_org = load_original_data()\n\n        # Split the original data into separate data-frames for each city.\n        df_cities = [df_org.xs(city) for city in cities]\n\n        # Resample the data for each city.\n        df_resampled = [_resample(df_city) for df_city in df_cities]\n\n        # Join the resampled data into a single data-frame.\n        df = pd.concat(df_resampled, keys=cities,\n                       axis=1, join=\'inner\')\n\n        # Save the resampled data in a cache-file for quick reloading.\n        df.to_pickle(path)\n\n    return df\n\n\n########################################################################\n'"
