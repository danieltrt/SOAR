file_path,api_count,code
setup.py,0,"b'from distutils.core import setup\nfrom setuptools import setup\nimport glob\n\nsubpackages = glob.glob(""hypergan/*/"")\nsubpackages += glob.glob(""hypergan/*/*/"")\nsubpackages += glob.glob(""hypergan/*/*/*/"")\nsubpackages = [s.replace(""/"", ""."") for s in subpackages]\n\nsetup(\n  name = \'hypergan\',\n  packages = [\'hypergan\']+subpackages,\n  include_package_data=True,\n  version = \'0.10.1\',\n  description = \'A customizable generative adversarial network with reproducible configurations.  Build your own content generator.\',\n  author = \'Martyn Garcia, Mikkel Garcia\',\n  author_email = \'mikkel@255bits.com\',\n  maintainer = ""hypergan developers"",\n  maintainer_email = ""mikkel@255bits.com"",\n  license = ""MIT"",\n  url = \'https://github.com/255BITS/hypergan\', \n  keywords = [\'hypergan\', \'neural network\', \'procedural content generation\', \'generative adversarial network\'], # arbitrary keywords\n  classifiers = [\n      \'Development Status :: 4 - Beta\',\n      \'Topic :: Scientific/Engineering :: Artificial Intelligence\', \n      \'Topic :: Artistic Software\', \n      \'Topic :: Internet :: WWW/HTTP :: Dynamic Content\',\n      \'Intended Audience :: Science/Research\',\n      \'Intended Audience :: Developers\',\n      \'Programming Language :: Python :: 3\',\n      \'Programming Language :: Python :: 3.4\',\n      \'Programming Language :: Python :: 3.5\',\n      \'Programming Language :: Python :: 3.6\',\n      \'Operating System :: POSIX\',\n      \'Operating System :: Unix\',\n      \'Operating System :: MacOS\',\n      ],\n  platforms = [""Linux"", ""Mac OS-X"", ""Unix"", ""Windows""],\n  scripts = [\'bin/hypergan\', \'bin/hypergan.cmd\']\n)\n'"
examples/2d-distribution.py,23,"b'import argparse\nimport io\nimport os\nimport math\n\nimport uuid\nimport tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport json\nfrom hypergan.generators import *\nfrom hypergan.search.random_search import RandomSearch\nfrom hypergan.viewer import GlobalViewer\nfrom common import *\nfrom PIL import Image\nimport plotly.graph_objs as go\n\narg_parser = ArgumentParser(""Test your gan vs a known distribution"", require_directory=False)\narg_parser.parser.add_argument(\'--distribution\', \'-t\', type=str, default=\'circle\', help=\'what distribution to test, options are circle, modes\')\narg_parser.parser.add_argument(\'--contour_size\', \'-cs\', type=int, default=128, help=\'number of points to plot the discriminator contour with.  must be a multiple of batch_size\')\narg_parser.parser.add_argument(\'--sample_points\', \'-p\', type=int, default=512, help=\'number of scatter points to plot.  must be a multiple of batch_size\')\nargs = arg_parser.parse_args()\n\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nimport plotly.io as pio\n\nclass Custom2DDiscriminator(BaseGenerator):\n    def __init__(self, gan, config, g=None, x=None, name=None, input=None, reuse=None, features=[], skip_connections=[]):\n        self.x = x\n        self.g = g\n\n        GANComponent.__init__(self, gan, config, name=name, reuse=reuse)\n    def create(self):\n        gan = self.gan\n        if self.x is None:\n            self.x = gan.inputs.x\n        if self.g is None:\n            self.g = gan.generator.sample\n        net = tf.concat(axis=0, values=[self.x,self.g])\n        net = self.build(net)\n        self.sample = net\n        return net\n\n    def build(self, net):\n        gan = self.gan\n        config = self.config\n        ops = self.ops\n        layers=2\n\n        end_features = 1\n\n        for i in range(layers):\n            net = ops.linear(net, 16)\n            net = ops.lookup(\'bipolar\')(net)\n        net = ops.linear(net, 1)\n        self.sample = net\n\n        return net\n\n\nclass Custom2DGenerator(BaseGenerator):\n    def create(self):\n        gan = self.gan\n        config = self.config\n        ops = self.ops\n        end_features = config.end_features or 1\n\n        ops.describe(\'custom_generator\')\n\n        net = gan.latent.sample\n        for i in range(2):\n            net = ops.linear(net, 16)\n            net = ops.lookup(\'bipolar\')(net)\n        net = ops.linear(net, end_features)\n        print(""-- net is "", net)\n        self.sample = net\n        return net\n\nclass Custom2DInputDistribution:\n    def __init__(self, args):\n        with tf.device(args.device):\n            def circle(x):\n                spherenet = tf.square(x)\n                spherenet = tf.reduce_sum(spherenet, 1)\n                lam = tf.sqrt(spherenet)\n                return x/tf.reshape(lam,[int(lam.get_shape()[0]), 1])\n\n            def modes(x):\n                shape = x.get_shape()\n                return tf.round(x*2)/2.0#+tf.random_normal(shape, 0, 0.04)\n\n            if args.distribution == \'circle\':\n                x = tf.random_normal([args.batch_size, 2])\n                x = circle(x)\n            elif args.distribution == \'modes\':\n                x = tf.random_uniform([args.batch_size, 2], -1, 1)\n                x = modes(x)\n            elif args.distribution == \'modal-gaussian\':\n                x = tf.random_uniform([args.batch_size, 2], -1, 1)\n                y = tf.random_normal([args.batch_size, 2], stddev=0.04, mean=0.15)\n                x = tf.round(x) + y\n            elif args.distribution == \'sin\':\n                x = tf.random_uniform((1, args.batch_size), -10.5, 10.5 )\n                x = tf.transpose(x)\n                r_data = tf.random_normal((args.batch_size,1), mean=0, stddev=0.1)\n                xy = tf.sin(0.75*x)*7.0+x*0.5+r_data*1.0\n                x = tf.concat([xy,x], 1)/16.0\n\n            elif args.distribution == \'static-point\':\n                x = tf.ones([args.batch_size, 2])\n\n            self.x = x\n            self.xy = tf.zeros_like(self.x)\n\n\nx_v, z_v = None, None\nclass Custom2DSampler(BaseSampler):\n    def __init__(self, gan):\n        self.gan = gan\n        self.copy_vars = [tf.Variable(x) for x in self.gan.variables()]\n        self.reset_vars = [y.assign(x) for y, x in zip(self.copy_vars, self.gan.variables())]\n\n    def sample(self, filename, save_samples):\n        gan = self.gan\n        generator = gan.generator.sample\n\n        sess = gan.session\n        config = gan.config\n\n        contours = args.contour_size\n\n        x,y = np.meshgrid(np.arange(-1.5, 1.5, 3/contours), np.arange(-1.5, 1.5, 3/contours))\n        d = []\n        for i in range(args.contour_size):\n            _x = np.reshape(x[:,i], [-1]) \n            _y = np.reshape(y[:,i], [-1]) \n            for j in range(args.contour_size // gan.batch_size()):\n                offset = j*gan.batch_size()\n                endoffset = (j+1)*gan.batch_size()\n                _x_sample = _x[offset:endoffset]\n                _y_sample = _y[offset:endoffset]\n                _d = gan.session.run(gan.loss.d_real, {gan.inputs.x: [[__x,__y] for __x, __y in zip(_x_sample, _y_sample)]})\n                d.append(_d)\n        contour = go.Contour(\n            z = np.reshape(d, [-1]),\n            x = np.reshape(x, [-1]),\n            y = np.reshape(y, [-1]),\n            opacity=0.5,\n            showlegend=False,\n            contours = dict(\n                start=-0.5,\n                end=0.5,\n                size=0.03,\n            )\n        )\n        print(np.shape(x), np.shape(y))\n        #z = sess.run(gan.discriminator.sample, \n\n        global x_v, z_v\n        if x_v is None:\n            x_v = []\n            z_v = []\n            for j in range(args.sample_points // gan.batch_size()):\n                _x_v, _z_v = sess.run([gan.inputs.x, gan.latent.sample])\n                x_v.append(_x_v)\n                z_v.append( _z_v)\n            x_v = np.reshape(x_v, [-1,gan.inputs.x.shape[1]])\n            z_v = np.reshape(z_v, [-1,gan.latent.sample.shape[1]])\n\n        sample = []\n        for j in range(args.sample_points // gan.batch_size()):\n            offset = j*gan.batch_size()\n            endoffset = (j+1)*gan.batch_size()\n            z_v_sample = z_v[offset:endoffset]\n            x_v_sample = x_v[offset:endoffset]\n            _sample = sess.run(generator, {gan.inputs.x: x_v_sample, gan.latent.sample: z_v_sample})\n            sample.append(_sample)\n        sample = np.reshape(sample, [-1, 2])\n        points = go.Scatter(x=sample[:,0], y=sample[:,1],\n                mode=\'markers\',\n                marker = dict(\n                    size = 10,\n                    color = \'rgba(0, 152, 0, .8)\',\n                    line = dict(\n                       width = 2,\n                       color = \'rgb(0, 0, 0)\'\n                    )),\n                name=\'fake\')\n\n        xpoints = go.Scatter(x=x_v[:,0], y=x_v[:,1],\n                mode=\'markers\',\n                marker = dict(\n                    size = 10,\n                    color = \'rgba(255, 182, 193, .9)\',\n                    line = dict(\n                       width = 2,\n                       color = \'rgb(0, 0, 0)\'\n                    )),\n                name=\'real\')\n\n        layout = go.Layout(hovermode=\'closest\',\n                xaxis=dict(range=[-1.5,1.5]),\n                yaxis=dict(range=[-1.5,1.5]),\n                width=1920,\n                showlegend=False,\n                height=1080\n        )\n        fig = go.Figure([contour, xpoints, points], layout=layout)\n        data = pio.to_image(fig, format=\'png\')\n        #pio.write_image(fig,""sample.png"")\n        img = Image.open(io.BytesIO(data))\n        #img = Image.open(""sample.png"").convert(""RGB"")\n        #img.save(""save.jpg"")\n        #plt.savefig(filename)\n        self.plot(np.array(img), filename, save_samples, regularize=False)\n        return [{\'image\': filename, \'label\': \'2d\'}]\n\nconfig = lookup_config(args)\nif args.action == \'search\':\n    config = hc.Config(json.loads(open(os.getcwd()+\'/randomsearch.json\', \'r\').read()))\n    config[\'trainer\'][\'rbbr\'][\'optimizer\'][\'optimizer\'][\'learn_rate\'] = random.choice([0.1,0.01,0.001, 0.005, 0.0001])\n    config[\'trainer\'][\'rbbr\'][\'optimizer\'][\'optimizer\'][\'beta1\'] = random.choice([0.1, 0.0001, 0.5, 0.9, 0.999])\n    config[\'trainer\'][\'rbbr\'][\'optimizer\'][\'optimizer\'][\'beta2\'] = random.choice([0.1, 0.0001, 0.5, 0.9, 0.999])\n    config[\'trainer\'][\'rbbr\'][\'optimizer\'][\'beta\'] = random.choice([0, 1, 0.5, 0.99, 0.1])\n    config[\'trainer\'][\'rbbr\'][\'optimizer\'][\'gamma\'] = random.choice([0, 1, 0.5, 0.99, 0.1, 10])\n    config[\'trainer\'][\'rbbr\'][\'optimizer\'][\'rho\'] = random.choice([0, 1, 0.5, 0.99, 0.1])\n\ndef train(config, args):\n    title = ""[hypergan] 2d-test "" + args.config\n    GlobalViewer.title = title\n    GlobalViewer.enabled = args.viewer\n\n    with tf.device(args.device):\n        config.generator[\'end_features\'] = 2\n        config.generator[""class""]=""class:__main__.Custom2DGenerator"" # TODO\n        config.discriminator[""class""]=""class:__main__.Custom2DDiscriminator"" # TODO\n        gan = hg.GAN(config, inputs = Custom2DInputDistribution(args))\n        gan.name = args.config\n\n        accuracy_x_to_g=distribution_accuracy(gan.inputs.x, gan.generator.sample)\n        accuracy_g_to_x=distribution_accuracy(gan.generator.sample, gan.inputs.x)\n\n        sampler = Custom2DSampler(gan)\n        gan.selected_sampler = sampler\n\n        tf.train.start_queue_runners(sess=gan.session)\n        samples = 0\n        steps = args.steps\n        sampler.sample(""samples/000000.png"", args.save_samples)\n\n        metrics = [accuracy_x_to_g, accuracy_g_to_x]\n        sum_metrics = [0 for metric in metrics]\n        for i in range(steps):\n            gan.step()\n\n            if args.viewer and i % args.sample_every == 0:\n                samples += 1\n                print(""Sampling ""+str(samples), args.save_samples)\n                sample_file=""samples/%06d.png"" % (samples)\n                sampler.sample(sample_file, args.save_samples)\n\n            if i > steps * 9.0/10:\n                for k, metric in enumerate(gan.session.run(metrics)):\n                    sum_metrics[k] += metric \n            if i % 300 == 0:\n                for k, metric in enumerate(gan.metrics().keys()):\n                    metric_value = gan.session.run(gan.metrics()[metric])\n                    print(""--"", metric,  metric_value)\n                    if math.isnan(metric_value) or math.isinf(metric_value):\n                        print(""Breaking due to invalid metric"")\n                        return None\n\n        tf.reset_default_graph()\n        gan.session.close()\n\n    return sum_metrics\n\nif args.action == \'train\':\n    metrics = train(config, args)\n    print(""Resulting metrics:"", metrics)\nelif args.action == \'search\':\n    metric_sum = train(config, args)\n    if \'search_output\' in args:\n        search_output = args.search_output\n    else:\n        search_output = ""2d-test-results.csv""\n\n    config_filename = ""2d-measure-accuracy-""+str(uuid.uuid4())+\'.json\'\n    hc.Selector().save(config_filename, config)\n    with open(search_output, ""a"") as myfile:\n        total = sum(metric_sum)\n        myfile.write(config_filename+"",""+"","".join([str(x) for x in metric_sum])+"",""+str(total)+""\\n"")\nelse:\n    print(""Unknown action: ""+args.action)\n\n'"
examples/classification.py,8,"b'import argparse\nimport uuid\nimport os\nimport sys\nimport tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nfrom hypergan.inputs import *\nfrom hypergan.search.random_search import RandomSearch\nfrom common import *\n\narg_parser = ArgumentParser(description=\'Train an MNIST classifier G(x) = label\')\nargs = arg_parser.parse_args()\n\nclass MNISTInputLoader:\n    def __init__(self, batch_size):\n        from tensorflow.examples.tutorials.mnist import input_data\n        self.mnist = input_data.read_data_sets(\'MNIST_data\', one_hot=True)\n\n        self.x = tf.placeholder(tf.float32, shape=[batch_size, 28, 28, 1])\n        self.feed_y = tf.placeholder(tf.float32, shape=[batch_size, 10])\n        self.y = ((2*self.feed_y)-1)\n\n    def layer(self, name):\n        return getattr(self, name)\n\nclass MNISTGenerator(BaseGenerator):\n    def create(self):\n        gan = self.gan\n        config = self.config\n        ops = self.ops\n        end_features = config.end_features or 10\n\n        ops.describe(\'custom_generator\')\n\n        net = gan.inputs.x\n        net = ops.reshape(net, [gan.batch_size(), -1])\n        net = ops.linear(net, end_features)\n        net = ops.lookup(\'tanh\')(net)\n        self.fy = net\n        self.sample = net\n        return net\n    def layer(self, name):\n        return getattr(self, name)\nclass MNISTDiscriminator(BaseGenerator):\n    def build(self, net):\n        gan = self.gan\n        config = self.config\n        ops = self.ops\n\n        end_features = 1\n\n        x = gan.inputs.x\n        y = gan.inputs.y\n        x = ops.reshape(x, [gan.batch_size(), -1])\n        g = gan.generator.sample\n\n        print(""G"", x, g)\n        gnet = tf.concat(axis=1, values=[x,g])\n        ynet = tf.concat(axis=1, values=[x,y])\n\n        net = tf.concat(axis=0, values=[ynet, gnet])\n        net = ops.linear(net, 128)\n        net = tf.nn.tanh(net)\n        self.sample = net\n\n        return net\n\n\n\nconfig = lookup_config(args)\n\nif args.action == \'search\':\n    search = RandomSearch({\n        \'generator\': {\'class\': MNISTGenerator, \'end_features\': 10},\n        \'discriminator\': {\'class\': MNISTDiscriminator}\n        })\n\n    config = search.random_config()\n\nmnist_loader = MNISTInputLoader(args.batch_size)\n\ndef setup_gan(config, inputs, args):\n    gan = hg.GAN(config, inputs=inputs, batch_size=args.batch_size)\n    return gan\n\ndef train(config, args):\n    gan = setup_gan(config, mnist_loader, args)\n    correct_prediction = tf.equal(tf.argmax(gan.generator.layer(\'fy\'),1), tf.argmax(gan.inputs.y,1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) * 100\n    metrics = [accuracy]\n    sum_metrics = [0 for metric in metrics]\n    mnist = gan.inputs.mnist\n\n    test_batches = []\n    test_batch_image = []\n    test_batch_label = []\n    for _i, _y in zip(mnist.test._images, mnist.test._labels):\n        test_batch_image += [_i]\n        test_batch_label += [_y]\n        if gan.batch_size() == len(test_batch_label):\n            test_batches.append([test_batch_image, test_batch_label])\n            test_batch_image = []\n            test_batch_label = []\n    print(str(len(test_batch_label)) + "" tests excluded because of batch size"")\n\n    for i in range(args.steps):\n        batch = mnist.train.next_batch(args.batch_size)\n        input_x = np.reshape(batch[0], [gan.batch_size(), 28, 28, 1])\n\n        gan.step({gan.inputs.x: input_x, gan.inputs.feed_y: batch[1]})\n\n        if i % args.sample_every == 0 and i > 0:\n            accuracy_v = 0\n            test_batch = mnist.test.next_batch(args.batch_size)\n            for test_batch in test_batches:\n                input_x = np.reshape(test_batch[0], [gan.batch_size(), 28, 28, 1])\n                accuracy_v += gan.session.run(accuracy,{gan.inputs.x: input_x, gan.inputs.y: test_batch[1]})\n            accuracy_v /= len(test_batches) \n            print(""accuracy: "", accuracy_v)\n\n    return sum_metrics\n\ndef search(config, args):\n    metrics = train(config, args)\n    config_filename = ""classification-""+str(uuid.uuid4())+\'.json\'\n    hc.Selector().save(config_filename, config)\n\n    with open(args.search_output, ""a"") as myfile:\n        print(""Writing result"")\n        myfile.write(config_filename+"",""+"","".join([str(x) for x in metrics])+""\\n"")\n\nif args.action == \'train\':\n    metrics = train(config, args)\n    print(""Resulting metrics:"", metrics)\nelif args.action == \'search\':\n    search(config, args)\nelse:\n    print(""Unknown action: ""+args.action)\n\n\n'"
examples/colorizer.py,17,"b'import os\nimport uuid\nimport random\nimport tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\nfrom hypergan.viewer import GlobalViewer\nfrom hypergan.samplers.base_sampler import BaseSampler\nfrom hypergan.samplers.random_walk_sampler import RandomWalkSampler\nfrom hypergan.gans.standard_gan import StandardGAN\nfrom common import *\n\nfrom hypergan.gans.experimental.alpha_gan import AlphaGAN\n\nx_v = None\nz_v = None\nlayer_filter = None\n\nclass Sampler(BaseSampler):\n\n    def sample(self, path, save_samples):\n        gan = self.gan\n        generator = gan.generator.sample\n        z_t = gan.latent.sample\n        x_t = gan.inputs.x\n        width = 4\n        n_samples = 8\n        \n        sess = gan.session\n        config = gan.config\n        global x_v\n        global z_v\n        global layer_filter\n        if x_v is None:\n            x_v, z_v = sess.run([x_t, z_t])\n            x_v = np.tile(x_v[0], [gan.batch_size(),1,1,1])\n        if layer_filter == None:\n            layer_filter = gan.generator.config.layer_filter(gan, gan.generator.config, x_t)\n            if(gan.ops.shape(layer_filter)[-1] == 1):\n                layer_filter = tf.tile(layer_filter,[1,1,1,3])\n\n        \n        layer_filter_v = sess.run(layer_filter, {x_t: x_v, z_t: z_v})\n\n        samples = sess.run(generator, {x_t: x_v, z_t: z_v})\n        stacks = []\n        #stacks.append([x_v[0], layer_filter_v[0]] + samples[-4:0])\n \n        for i in range(n_samples//width):\n            stacks.append([samples[i*width+j] for j in range(width)])\n\n        stacks[0][0]=x_v[0]\n        print(np.shape(layer_filter),""----"")\n        stacks[0][1]=layer_filter_v[0]\n        images = np.vstack([np.hstack(s) for s in stacks])\n\n        self.plot(images, path, save_samples)\n        return [{\'images\': images, \'label\': \'tiled x sample\'}]\n\ndef apply_mask(gan, config, net,x=None):\n    if x == None:\n        x = gan.inputs.x\n    filtered = net\n    shape = gan.ops.shape(x)\n    mask = tf.ones([shape[1], shape[2], shape[3]])\n    mask = tf.greater(mask, 0)\n    scaling = 0.6\n    mask = tf.image.central_crop(mask, scaling)\n    left = (shape[1]*scaling)//2 * 0.75\n    top = (shape[2]*scaling)//2 * 0.75\n    mask = tf.image.pad_to_bounding_box(mask, int(top), int(left), shape[1], shape[2])\n    mask = tf.cast(mask, tf.float32)\n    backmask = (1.0-mask) \n    filtered = backmask* x + mask * filtered\n    print(""FRAMING IMAGE"", filtered) \n    return filtered\n\ndef add_bw(gan, config, net):\n    x = gan.inputs.x\n    s = [int(x) for x in net.get_shape()]\n    print(""S IS "", s)\n    shape = [s[1], s[2]]\n    x = tf.image.resize_images(x, shape, 1)\n    bwnet = tf.slice(net, [0, 0, 0, 0], [s[0],s[1],s[2], 3])\n    \n    if not gan.config.add_full_image:\n        print( ""[colorizer] Adding black and white image"", x)\n        filtered = tf.image.rgb_to_grayscale(x)\n        if config.blank_black_and_white is not None:\n            filtered = tf.zeros_like(filtered)\n        if config.colorizer_noise is not None:\n            filtered += tf.random_normal(filtered.get_shape(), mean=0, stddev=config.colorizer_noise, dtype=tf.float32)\n\n        if gan.config.add_full_image_frame:\n            bw = tf.image.rgb_to_grayscale(filtered)\n            bw = tf.tile(bw,[1,1,1,3])\n            filtered = apply_mask(gan,config,bw, x)\n    else:\n        print( ""[colorizer] Adding full image"", x)\n        filtered = x\n\n    return filtered\n\narg_parser = ArgumentParser(""Colorize an image"")\narg_parser.add_image_arguments()\narg_parser.parser.add_argument(\'--add_full_image\', type=bool, default=False, help=\'Instead of just the black and white X, add the whole thing.\')\narg_parser.parser.add_argument(\'--add_full_image_frame\', type=bool, default=False, help=\'Frame the corners of the image.  Incompatible with add_full_image.\')\nargs = arg_parser.parse_args()\n\nwidth, height, channels = parse_size(args.size)\n\nconfig = lookup_config(args)\n\nif args.add_full_image:\n    config[""add_full_image""]=True\nif args.add_full_image_frame:\n    config[""add_full_image_frame""]=True\n\nif args.action == \'build\':\n    flattened = tf.zeros([args.batch_size * width * height * channels], name=""flattened_x"")\n    x = tf.reshape(flattened, [args.batch_size, width, height, channels])\n    inputs = hc.Config({""x"": x, ""flattened"": flattened})\n\n\nelse:\n    inputs = hg.inputs.image_loader.ImageLoader(args.batch_size)\n    inputs.create(args.directory,\n            channels=channels, \n            format=args.format,\n            crop=args.crop,\n            width=width,\n            height=height,\n            resize=True)\n\nconfig_name = args.config\nsave_file = ""saves/""+config_name+""/model.ckpt""\nos.makedirs(os.path.expanduser(os.path.dirname(save_file)), exist_ok=True)\n\ndef setup_gan(config, inputs, args):\n    gan = hg.GAN(config, inputs=inputs, name=args.config)\n\n    if(os.path.isfile(save_file+"".meta"")):\n        gan.load(save_file)\n\n    tf.train.start_queue_runners(sess=gan.session)\n\n    config_name = args.config\n    GlobalViewer.title = ""[hypergan] colorizer "" + config_name\n    GlobalViewer.enabled = args.viewer\n\n    return gan\n\ndef train(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    gan.name = config_name\n    sampler = gan.sampler_for(""sampler"", args.sampler or Sampler)(gan)\n    samples = 0\n\n    metrics = [batch_accuracy(gan.inputs.x, gan.generator.sample), batch_diversity(gan.generator.sample)]\n    sum_metrics = [0 for metric in metrics]\n    for i in range(args.steps):\n        gan.step()\n\n        if args.action == \'train\' and i % args.save_every == 0 and i > 0:\n            print(""saving "" + save_file)\n            gan.save(save_file)\n\n        if i % args.sample_every == 0:\n            sample_file=""samples/""+config_name+""/%06d.png"" % (samples)\n            os.makedirs(os.path.expanduser(os.path.dirname(sample_file)), exist_ok=True)\n            samples += 1\n            sampler.sample(sample_file, args.save_samples)\n\n        if i > args.steps * 9.0/10:\n            for k, metric in enumerate(gan.session.run(metrics)):\n                print(""Metric ""+str(k)+"" ""+str(metric))\n                sum_metrics[k] += metric \n\n    tf.reset_default_graph()\n    return sum_metrics\n\ndef build(config, inputs, args):\n    def input_nodes():\n        return [\n                gan.inputs.flattened\n        ]\n    gan = setup_gan(config, inputs, args)\n    gan.build(input_nodes=gan.input_nodes() + input_nodes())\n\ndef sample(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    sampler = gan.sampler_for(args.sampler, default=RandomWalkSampler)(gan)\n    samples = 0\n    for i in range(args.steps):\n        sample_file=""samples/""+config_name+""/%06d.png"" % (samples)\n        os.makedirs(os.path.expanduser(os.path.dirname(sample_file)), exist_ok=True)\n        samples += 1\n        sampler.sample(sample_file, args.save_samples)\n\nif args.action == \'train\':\n    metrics = train(config, inputs, args)\n    print(""Resulting metrics:"", metrics)\nelif args.action == \'sample\':\n    sample(config, inputs, args)\nelif args.action == \'build\':\n    build(config, inputs, args)\nelse:\n    print(""Unknown action: ""+args.action)\n'"
examples/common.py,30,"b'import argparse\nimport tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\nimport random\n\nfrom hypergan.cli import CLI\nfrom hypergan.gan_component import GANComponent\nfrom hypergan.search.random_search import RandomSearch\nfrom hypergan.generators.base_generator import BaseGenerator\nfrom hypergan.samplers.base_sampler import BaseSampler\n\nclass ArgumentParser:\n    def __init__(self, description, require_directory=True):\n        self.require_directory = require_directory\n        self.parser = argparse.ArgumentParser(description=description, add_help=True)\n        self.add_global_arguments()\n        self.add_search_arguments()\n        self.add_train_arguments()\n\n    def add_global_arguments(self):\n        parser = self.parser\n        parser.add_argument(\'action\', action=\'store\', type=str, help=\'One of [""train"", ""search""]\')\n        if self.require_directory:\n            parser.add_argument(\'directory\', action=\'store\', type=str, help=\'The location of your data.  Subdirectories are treated as different classes.  You must have at least 1 subdirectory.\')\n        parser.add_argument(\'--config\', \'-c\', type=str, default=\'default\', help=\'config name\')\n        parser.add_argument(\'--device\', \'-d\', type=str, default=\'/gpu:0\', help=\'In the form ""/gpu:0"", ""/cpu:0"", etc.  Always use a GPU (or TPU) to train\')\n        parser.add_argument(\'--batch_size\', \'-b\', type=int, default=32, help=\'Number of samples to include in each batch.  If using batch norm, this needs to be preserved when in server mode\')\n        parser.add_argument(\'--steps\', type=int, default=1000000, help=\'Number of steps to train for.\')\n        parser.add_argument(\'--noviewer\', dest=\'viewer\', action=\'store_false\', help=\'Disables the display of samples in a window.\')\n        parser.add_argument(\'--save_samples\', dest=\'save_samples\', action=\'store_true\', help=\'Saves samples to disk.\')\n\n    def add_search_arguments(self):\n        parser = self.parser\n        parser.add_argument(\'--config_list\', \'-m\', type=str, default=None, help=\'config list name\')\n        parser.add_argument(\'--search_output\', \'-o\', type=str, default=""search.csv"", help=\'output file for search results\')\n\n    def add_train_arguments(self):\n        parser = self.parser\n        parser.add_argument(\'--sample_every\', type=int, default=50, help=\'Samples the model every n epochs.\')\n        parser.add_argument(\'--save_every\', type=int, default=1000, help=\'Samples the model every n epochs.\')\n\n    def add_image_arguments(self):\n        parser = self.parser\n        parser.add_argument(\'--crop\', type=bool, default=False, help=\'If your images are perfectly sized you can skip cropping.\')\n        parser.add_argument(\'--format\', \'-f\', type=str, default=\'png\', help=\'jpg or png\')\n        parser.add_argument(\'--size\', \'-s\', type=str, default=\'64x64x3\', help=\'Size of your data.  For images it is widthxheightxchannels.\')\n        parser.add_argument(\'--zoom\', \'-z\', type=int, default=1, help=\'Zoom level\')\n        parser.add_argument(\'--sampler\', type=str, default=None, help=\'Select a sampler.  Some choices: static_batch, batch, grid, progressive\')\n        return parser\n\n    def parse_args(self):\n        return self.parser.parse_args()\n\ndef batch_diversity(net):\n    bs = int(net.get_shape()[0])\n    avg = tf.reduce_mean(net, axis=0)\n\n    s = [int(x) for x in avg.get_shape()]\n    avg = tf.reshape(avg, [1, s[0], s[1], s[2]])\n\n    tile = [1 for x in net.get_shape()]\n    tile[0] = bs\n    avg = tf.tile(avg, tile)\n    net -= avg\n    return tf.reduce_sum(tf.abs(net))\n\ndef distribution_accuracy(a, b):\n    """"""\n    Each point of a is measured against the closest point on b.  Distance differences are added together.  \n    \n    This works best on a large batch of small inputs.""""""\n    tiled_a = a\n    tiled_a = tf.reshape(tiled_a, [int(tiled_a.get_shape()[0]), 1, int(tiled_a.get_shape()[1])])\n\n    tiled_a = tf.tile(tiled_a, [1, int(tiled_a.get_shape()[0]), 1])\n\n    tiled_b = b\n    tiled_b = tf.reshape(tiled_b, [1, int(tiled_b.get_shape()[0]), int(tiled_b.get_shape()[1])])\n    tiled_b = tf.tile(tiled_b, [int(tiled_b.get_shape()[0]), 1, 1])\n\n    difference = tf.abs(tiled_a-tiled_b)\n    difference = tf.reduce_min(difference, axis=1)\n    difference = tf.reduce_sum(difference, axis=1)\n    return tf.reduce_sum(difference, axis=0) \n\ndef batch_accuracy(a, b):\n    ""Difference from a to b.  Meant for reconstruction measurements.""\n    difference = tf.abs(a-b)\n    difference = tf.reduce_min(difference, axis=1)\n    difference = tf.reduce_sum(difference, axis=1)\n    return tf.reduce_sum( tf.reduce_sum(difference, axis=0) , axis=0) \n\nclass TextInput:\n    def __init__(self, config, batch_size, one_hot=False):\n        self.lookup = None\n        reader = tf.TextLineReader()\n        filename_queue = tf.train.string_input_producer([""chargan.txt""])\n        key, x = reader.read(filename_queue)\n        vocabulary = self.get_vocabulary()\n\n        table = tf.contrib.lookup.string_to_index_table_from_tensor(\n            mapping = vocabulary, default_value = 0)\n\n        x = tf.string_join([x, tf.constant("" "" * 64)]) \n        x = tf.substr(x, [0], [64])\n        x = tf.string_split(x,delimiter=\'\')\n        x = tf.sparse_tensor_to_dense(x, default_value=\' \')\n        x = tf.reshape(x, [64])\n        x = table.lookup(x)\n        self.one_hot = one_hot\n        if one_hot:\n            x = tf.one_hot(x, len(vocabulary))\n            x = tf.cast(x, dtype=tf.float32)\n            x = tf.reshape(x, [1, int(x.get_shape()[0]), int(x.get_shape()[1]), 1])\n        else:\n            x = tf.cast(x, dtype=tf.float32)\n            x -= len(vocabulary)/2.0\n            x /= len(vocabulary)/2.0\n            x = tf.reshape(x, [1,1, 64, 1])\n\n        num_preprocess_threads = 8\n\n        x = tf.train.shuffle_batch(\n          [x],\n          batch_size=batch_size,\n          num_threads=num_preprocess_threads,\n          capacity= 5000,\n          min_after_dequeue=500,\n          enqueue_many=True)\n\n        self.x = x\n        self.table = table\n\n    def inputs(self):\n        return [self.x]\n    def get_vocabulary(self):\n        vocab = list(""~()\\""\'&+#@/789zyxwvutsrqponmlkjihgfedcba ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456:-,;!?."")\n        return vocab\n\n    def np_one_hot(index, length):\n        return np.eye(length)[index]\n\n    def get_character(self, data):\n        return self.get_lookup_table()[data]\n\n    def get_lookup_table(self):\n        if self.lookup is None:\n            vocabulary = self.get_vocabulary()\n            values = np.arange(len(vocabulary))\n            lookup = {}\n\n            if self.one_hot:\n                for i, key in enumerate(vocabulary):\n                    lookup[key]=self.np_one_hot(values[i], len(values))\n            else:\n                for i, key in enumerate(vocabulary):\n                    lookup[key]=values[i]\n\n            #reverse the hash\n            lookup = {i[1]:i[0] for i in lookup.items()}\n            self.lookup = lookup\n        return self.lookup\n\n    def text_plot(self, size, filename, data, x):\n        bs = x.shape[0]\n        data = np.reshape(data, [bs, -1])\n        x = np.reshape(x, [bs, -1])\n        plt.clf()\n        plt.figure(figsize=(2,2))\n        data = np.squeeze(data)\n        plt.plot(x)\n        plt.plot(data)\n        plt.xlim([0, size])\n        plt.ylim([-2, 2.])\n        plt.ylabel(""Amplitude"")\n        plt.xlabel(""Time"")\n        plt.savefig(filename)\n\n    def sample_output(self, val):\n        vocabulary = self.get_vocabulary()\n        if self.one_hot:\n            vals = [ np.argmax(r) for r in val ]\n            ox_val = [vocabulary[obj] for obj in list(vals)]\n            string = """".join(ox_val)\n            return string\n        else:\n            val = np.reshape(val, [-1])\n            val *= len(vocabulary)/2.0\n            val += len(vocabulary)/2.0\n            val = np.round(val)\n\n            val = np.maximum(0, val)\n            val = np.minimum(len(vocabulary)-1, val)\n\n            ox_val = [self.get_character(obj) for obj in list(val)]\n            string = """".join(ox_val)\n            return string\n\n\ndef parse_size(size):\n    width = int(size.split(""x"")[0])\n    height = int(size.split(""x"")[1])\n    channels = int(size.split(""x"")[2])\n    return [width, height, channels]\n\ndef lookup_config(args):\n    if args.action != \'search\':\n        return hg.configuration.Configuration.load(args.config+"".json"")\n    \ndef random_config_from_list(config_list_file):\n    """""" Chooses a random configuration from a list of configs (separated by newline) """"""\n    lines = tuple(open(config_list_file, \'r\'))\n    config_file = random.choice(lines).strip()\n    print(""[hypergan] config file chosen from list "", config_list_file, \'  file:\', config_file)\n    return hg.configuration.Configuration.load(config_file+"".json"")\n\n'"
hypergan/__init__.py,0,"b'""""""\n# HyperGAN\n\nA composable GAN API and CLI.  Built for developers, researchers, and artists.\n\nHyperGAN is currently in open beta.\n\n![Colorizer 0.9 1](https://s3.amazonaws.com/hypergan-apidocs/0.9.0-images/colorizer-2.gif)\n\nPlease see [https://github.com/255BITS/HyperGAN](https://github.com/255BITS/HyperGAN) for an introduction, usage and API examples.\n\n## License\n\nMIT - https://opensource.org/licenses/MIT\n""""""\nimport hypergan\nfrom .gan import GAN\nfrom .cli import CLI\nfrom .configuration import Configuration\nimport tensorflow as tf\nimport hypergan.cli\nimport hypergan as hg\n\n'"
hypergan/cli.py,8,"b'""""""\nThe command line interface.  Trains a directory of data.\n""""""\nimport gc\nimport sys\nimport os\nimport hyperchamber as hc\nimport tensorflow as tf\nfrom hypergan.gan_component import ValidationException\nfrom .inputs import *\nfrom .viewer import GlobalViewer\nfrom .configuration import Configuration\nimport hypergan as hg\nimport time\n\nimport os\nimport shutil\nimport sys\n\nfrom hypergan.losses.supervised_loss import SupervisedLoss\nfrom hypergan.multi_component import MultiComponent\nfrom time import sleep\n\n\nclass CLI:\n    def __init__(self, gan, args={}):\n        self.samples = 0\n        self.steps = 0\n        self.gan = gan\n        if gan is not None:\n            self.gan.cli = self\n\n        args = hc.Config(args)\n        self.args = args\n\n        crop =  self.args.crop\n\n        self.config_name = self.args.config or \'default\'\n        self.method = args.method or \'test\'\n        self.total_steps = args.steps or -1\n        self.sample_every = self.args.sample_every or 100\n\n        self.sampler_name = args.sampler\n        self.sampler = None\n        self.validate()\n        if self.args.save_file:\n            self.save_file = self.args.save_file\n        else:\n            default_save_path = os.path.abspath(""saves/""+self.config_name)\n            self.save_file = default_save_path + ""/model.ckpt""\n            self.create_path(self.save_file)\n        if self.gan is not None:\n            self.gan.save_file = self.save_file\n\n        title = ""[hypergan] "" + self.config_name\n        GlobalViewer.enable_menu = self.args.menu\n        GlobalViewer.title = title\n        GlobalViewer.viewer_size = self.args.viewer_size\n        GlobalViewer.enabled = self.args.viewer\n        GlobalViewer.zoom = self.args.zoom\n\n    def sample(self, allow_save=True):\n        """""" Samples to a file.  Useful for visualizing the learning process.\n\n        If allow_save is False then saves will not be created.\n\n        Use with:\n\n             ffmpeg -i samples/grid-%06d.png -vcodec libx264 -crf 22 -threads 0 grid1-7.mp4\n\n        to create a video of the learning process.\n        """"""\n        sample_file=""samples/%s/%06d.png"" % (self.config_name, self.samples)\n        self.create_path(sample_file)\n        self.lazy_create()\n        sample_list = self.sampler.sample(sample_file, allow_save and self.args.save_samples)\n        self.samples += 1\n\n        return sample_list\n\n    def validate(self):\n        return True\n\n    def lazy_create(self):\n        if(self.sampler == None):\n            self.sampler = self.gan.sampler_for(self.sampler_name)(self.gan)\n            if(self.sampler == None):\n                raise ValidationException(""No sampler found by the name \'""+self.sampler_name+""\'"")\n\n    def step(self):\n        bgan = self.gan\n        self.gan.step()\n        if bgan.destroy:\n            self.sampler=None\n            self.gan = self.gan.newgan\n            gc.collect()\n            refs = gc.get_referrers(bgan)\n            d = bgan.trainer._delegate\n            bgan.trainer=None\n            gc.collect()\n            del bgan\n            tf.reset_default_graph()\n\n            gc.collect()\n\n        if(self.steps % self.sample_every == 0):\n            sample_list = self.sample()\n\n        self.steps+=1\n\n    def create_path(self, filename):\n        return os.makedirs(os.path.expanduser(os.path.dirname(filename)), exist_ok=True)\n\n    def build(self):\n        return self.gan.build()\n    def serve(self, gan):\n        return gan_server(self.gan.session, config)\n\n    def sample_forever(self):\n        while not self.gan.destroy:\n            self.sample()\n            GlobalViewer.tick()\n\n\n    def train(self):\n        i=0\n        if(self.args.ipython):\n            import fcntl\n            fd = sys.stdin.fileno()\n            fl = fcntl.fcntl(fd, fcntl.F_GETFL)\n            fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)\n\n        while((i < self.total_steps or self.total_steps == -1) and not self.gan.destroy):\n            i+=1\n            start_time = time.time()\n            self.step()\n            GlobalViewer.tick()\n\n            if (self.args.save_every != None and\n                self.args.save_every != -1 and\n                self.args.save_every > 0 and\n                i % self.args.save_every == 0):\n                print("" |= Saving network"")\n                self.gan.save(self.save_file)\n            if self.args.ipython:\n                self.check_stdin()\n            end_time = time.time()\n\n    def check_stdin(self):\n        try:\n            input = sys.stdin.read()\n            if input[0]==""y"":\n                return\n            from IPython import embed\n            # Misc code\n            embed()\n\n        except:\n            return\n\n    def new(self):\n        template = self.args.directory + \'.json\'\n        print(""[hypergan] Creating new configuration file \'""+template+""\' based off of \'""+self.config_name+"".json\'"")\n        if os.path.isfile(template):\n            raise ValidationException(""File exists: "" + template)\n        source_configuration = Configuration.find(self.config_name+"".json"")\n        shutil.copyfile(source_configuration, template)\n\n        return\n\n    def add_supervised_loss(self):\n        if self.args.classloss:\n            print(""[discriminator] Class loss is on.  Semi-supervised learning mode activated."")\n            supervised_loss = SupervisedLoss(self.gan, self.gan.config.loss)\n            self.gan.loss = MultiComponent(components=[supervised_loss, self.gan.loss], combine=\'add\')\n            #EWW\n        else:\n            print(""[discriminator] Class loss is off.  Unsupervised learning mode activated."")\n\n    def run(self):\n        if self.method == \'train\':\n            self.add_supervised_loss() # TODO I think this is broken now(after moving create out)\n            self.gan.session.run(tf.global_variables_initializer())\n\n            if not self.gan.load(self.save_file):\n                print(""Initializing new model"")\n            else:\n                print(""Model loaded"")\n            self.train()\n            self.gan.save(self.save_file)\n            tf.reset_default_graph()\n            self.gan.session.close()\n        elif self.method == \'build\':\n            if not self.gan.load(self.save_file):\n                raise ""Could not load model: ""+ save_file\n            else:\n                print(""Model loaded"")\n            self.build()\n        elif self.method == \'new\':\n            self.new()\n        elif self.method == \'sample\':\n            self.add_supervised_loss()\n            if not self.gan.load(self.save_file):\n                print(""Initializing new model"")\n            else:\n                print(""Model loaded"")\n\n            tf.train.start_queue_runners(sess=self.gan.session)\n            self.sample_forever()\n            tf.reset_default_graph()\n            self.gan.session.close()\n        elif self.method == \'test\':\n            print(""Hooray!"")\n            print(""Hypergan is installed correctly.  Testing tensorflow for GPU support."")\n            with tf.Session() as sess:\n                devices = sess.list_devices()\n\n            if not tf.test.gpu_device_name():\n                print(""Warning: no default GPU device available"")\n                allgood=False\n            else:\n                print(""Default GPU is available"")\n                allgood=True\n            print(\'Default GPU Device: {}\'.format(tf.test.gpu_device_name()))\n            print(""Current available tensorflow devices:"")\n            for device in devices:\n                print(device)\n            if allgood:\n                print(""Congratulations!  Tensorflow and hypergan both look installed correctly.  If you still experience issues come let us know on discord."")\n            else:\n                print(""There were errors in the test, please see the logs"")\n\n'"
hypergan/configurable_component.py,151,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport inspect\nimport copy\nimport re\nimport os\nimport operator\nfrom functools import reduce\n\nfrom hypergan.ops.tensorflow.extended_ops import bicubic_interp_2d\nfrom .gan_component import GANComponent\n\nclass ConfigurationException(Exception):\n    pass\n\nclass ConfigurableComponent:\n    def __init__(self, gan, config, name=None, input=None, reuse=None, x=None, g=None, features=[], skip_connections=[]):\n        self.layers = []\n        self.skip_connections = skip_connections\n        self.layer_options = {}\n        self.layer_ops = {\n            ""activation"": self.layer_activation,\n            ""adaptive_instance_norm"": self.layer_adaptive_instance_norm,\n            ""add"": self.layer_add,\n            ""attention"": self.layer_attention,\n            ""avg_pool"": self.layer_avg_pool,\n            ""bicubic_conv"": self.layer_bicubic_conv,\n            ""combine_features"": self.layer_combine_features,\n            ""concat"": self.layer_concat,\n            ""const"": self.layer_const,\n            ""control"": self.layer_controls,\n            ""conv"": self.layer_conv,\n            ""conv_double"": self.layer_conv_double,\n            ""conv_dts"": self.layer_conv_dts,\n            ""conv_reshape"": self.layer_conv_reshape,\n            ""crop"": self.layer_crop,\n            ""deconv"": self.layer_deconv,\n            ""double_resolution"": self.layer_double_resolution,\n            ""fractional_avg_pool"": self.layer_fractional_avg_pool,\n            ""gram_matrix"": self.layer_gram_matrix,\n            ""identity"": self.layer_identity,\n            ""image_statistics"": self.layer_image_statistics,\n            ""knowledge_base"": self.layer_knowledge_base,\n            ""layer_filter"": self.layer_filter,\n            ""layer_norm"": self.layer_layer_norm,\n            ""layer"": self.layer_layer,\n            ""latent"": self.layer_latent,\n            ""linear"": self.layer_linear,\n            ""match_support"": self.layer_match_support,\n            ""mask"": self.layer_mask,\n            ""minibatch"": self.layer_minibatch,\n            ""noise"": self.layer_noise,\n            ""pad"": self.layer_pad,\n            ""phase_shift"": self.layer_phase_shift,\n            ""pixel_norm"": self.layer_pixel_norm,\n            ""progressive_replace"": self.layer_progressive_replace,\n            ""reference"": self.layer_reference,\n            ""relational"": self.layer_relational,\n            ""reshape"": self.layer_reshape,\n            ""resize_conv"": self.layer_resize_conv,\n            ""resize_images"": self.layer_resize_images,\n            ""resnet"": self.layer_resnet,\n            ""slice"": self.layer_slice,\n            ""split"": self.layer_split,\n            ""squash"": self.layer_squash,\n            ""subpixel"": self.layer_subpixel,\n            ""turing_test"": self.layer_turing_test,\n            ""two_sample_stack"": self.layer_two_sample_stack,\n            ""unpool"": self.layer_unpool,\n            ""variational"": self.layer_variational,\n            ""variational_noise"": self.layer_variational_noise,\n            ""zeros"": self.layer_zeros,\n            ""zeros_like"": self.layer_zeros_like\n            }\n        self.features = features\n        self.controls = {}\n        self.named_layers = {}\n        if not hasattr(gan, ""named_layers""):\n            gan.named_layers = {}\n        self.subnets = hc.Config(hc.Config(config).subnets or {})\n\n    def required(self):\n        return ""layers defaults"".split()\n\n    def layer(self, name):\n        if name in self.gan.named_layers:\n            return self.gan.named_layers[name] \n        if name in self.named_layers:\n            return self.named_layers[name]\n        return None\n\n    def build(self, net, replace_controls={}):\n        self.replace_controls=replace_controls\n        config = self.config\n\n        for layer in config.layers:\n            net = self.parse_layer(net, layer)\n            self.layers += [net]\n\n        return net\n\n    def parse_args(self, strs):\n        options = {}\n        args = []\n        for x in strs:\n            if \'=\' in x:\n                lhs, rhs = x.split(\'=\', 1)\n                options[lhs]=self.gan.configurable_param(rhs)\n            else:\n                args.append(self.gan.configurable_param(x))\n        return args, options\n\n    def parse_layer(self, net, layer):\n        config = self.config\n\n        if isinstance(layer, list):\n            ns = []\n            axis = -1\n            for l in layer:\n                if isinstance(l, int):\n                    axis = l\n                    continue\n                n = self.parse_layer(net, l)\n                ns += [n]\n            net = tf.concat(ns, axis=axis)\n\n            return net\n\n        else:\n            parens = re.findall(\'\\(.*?\\)\',layer)\n            for i, paren in enumerate(parens):\n                layer = layer.replace(paren, ""PAREN""+str(i))\n            d = layer.split(\' \')\n            for i, _d in enumerate(d):\n                for j, paren in enumerate(parens):\n                    d[i] = d[i].replace(""PAREN""+str(j), paren)\n            op = d[0]\n            args, options = self.parse_args(d[1:])\n        \n            net = self.build_layer(net, op, args, options)\n            return net\n            \n\n    def build_layer(self, net, op, args, options):\n        if self.layer_ops[op]:\n            before = self.variables()\n            before_count = self.count_number_trainable_params()\n            net = self.layer_ops[op](net, args, options)\n            if \'name\' in options:\n                self.set_layer(options[\'name\'], net)\n\n            after = self.variables()\n            new = set(after) - set(before)\n            for j in new:\n                self.layer_options[j]=options\n            after_count = self.count_number_trainable_params()\n            print(""number of params in layer "", op, args, after_count-before_count)\n        else:\n            print(""ConfigurableComponent: Op not defined"", op)\n\n        return net\n\n    def set_layer(self, name, net):\n        #if options[\'name\'] in self.named_layers and op != \'reference\':\n        #    raise ConfigurationException(""Named layer "" + options[\'name\'] + "" with "" + str(net) + "" already exists as "" + str(self.named_layers[options[\'name\']]))\n        self.gan.named_layers[name] = net\n        self.named_layers[name]     = net\n\n    def count_number_trainable_params(self):\n        \'\'\'\n        Counts the number of trainable variables.\n        \'\'\'\n        def get_nb_params_shape(shape):\n            \'\'\'\n            Computes the total number of params for a given shap.\n            Works for any number of shapes etc [D,F] or [W,H,C] computes D*F and W*H*C.\n            \'\'\'\n            nb_params = 1\n            for dim in shape:\n                nb_params = nb_params*int(dim)\n            return nb_params\n\n        tot_nb_params = 0\n        for trainable_variable in tf.trainable_variables():\n            shape = trainable_variable.get_shape() # e.g [D,F] or [W,H,C]\n            current_nb_params = get_nb_params_shape(shape)\n            tot_nb_params = tot_nb_params + current_nb_params\n        return tot_nb_params\n    def layer_filter(self, net, args=[], options={}):\n        """"""\n            If a layer filter is defined, apply it.  Layer filters allow for adding information\n            to every layer of the network.\n        """"""\n        ops = self.ops\n        gan = self.gan\n        config = self.config\n        fltr = config.layer_filter(gan, self.config, net)\n        if ""only"" in options:\n            return fltr\n        if fltr is not None:\n            net = ops.concat(axis=3, values=[net, fltr])\n        return net\n\n\n    def layer_resnet(self, net, args, options):\n        options = hc.Config(options)\n        config = self.config\n        ops = self.ops\n        depth = int(args[0])\n        activation_s = options.activation or self.ops.config_option(""activation"")\n        activation = self.ops.lookup(activation_s)\n        stride = options.stride or 1\n        stride = int(stride)\n        shortcut = net\n        initializer = None # default to global\n\n        if self.ops.config_option(""avg_pool""):\n            net = ops.conv2d(net, 3, 3, 1, 1, depth, initializer=initializer)\n            if stride != 1:\n                ksize = [1,stride,stride,1]\n                net = tf.nn.avg_pool(net, ksize=ksize, strides=ksize, padding=\'SAME\')\n        else:\n            net = ops.conv2d(net, 3, 3, stride, stride, depth, initializer=initializer)\n        net = activation(net)\n        net = ops.conv2d(net, 3, 3, 1, 1, depth, initializer=initializer)\n        if ops.shape(net)[-1] != ops.shape(shortcut)[-1] or stride != 1:\n            if self.ops.config_option(""avg_pool""):\n                shortcut = ops.conv2d(shortcut, 3, 3, 1, 1, depth, initializer=initializer)\n                if stride != 1:\n                    ksize = [1,stride,stride,1]\n                    shortcut = tf.nn.avg_pool(shortcut, ksize=ksize, strides=ksize, padding=\'SAME\')\n            else:\n                shortcut = ops.conv2d(shortcut, 3, 3, stride, stride, depth, initializer=initializer)\n        net = shortcut + net\n        net = activation(net)\n\n        return net\n    \n    def layer_zeros(self, net, args, options):\n        options = hc.Config(options)\n        config = self.config\n        ops = self.ops\n\n        self.ops.activation_name = options.activation_name\n        reshape = [ops.shape(net)[0]] + [int(x) for x in args[0].split(""*"")]\n        size = reduce(operator.mul, reshape)\n        net = tf.zeros(reshape)\n\n        return net\n\n    def layer_match_support(self, net, args, options):\n        s = self.ops.shape(net)\n        s[0] //= 2\n        with tf.variable_scope(self.ops.generate_name(), reuse=self.ops._reuse):\n            xpx = self.ops.get_weight(s, name=\'xconst\')\n        with tf.variable_scope(self.ops.generate_name(), reuse=self.ops._reuse):\n            xpg = self.ops.get_weight(s, name=\'gconst\')\n        x,g = tf.split(net, 2, axis=0)\n        self.named_layers[options[\'name\']+""_mx""] = xpx\n        self.named_layers[options[\'name\']+""_mg""] = xpg\n        self.named_layers[options[\'name\']+""_m+x""] = x+xpx\n        self.named_layers[options[\'name\']+""_m+g""] = g+xpg\n        result = tf.concat([x+xpx, g+xpg], axis=0)\n        return result\n\n    def layer_mask(self, net, args, options):\n        options = hc.Config(options)\n        config = self.config\n        ops = self.ops\n\n        layer = options.layer\n        mask_layer = options.mask_layer\n\n        opts = copy.deepcopy(dict(options))\n        opts[""name""] = self.ops.description + ""/"" + (options.mask_name or ""mask"")\n        opts[""activation""] = ""sigmoid""\n\n        if options.upscale == ""subpixel"":\n            mask = self.layer_subpixel(self.gan.named_layers[options.layer], [1], opts)\n        else:\n            mask = self.layer_deconv(self.gan.named_layers[options.layer], [1], opts)\n        self.set_layer(opts[\'name\'], mask)\n        extra = self.gan.named_layers[mask_layer]\n        mask = tf.tile(mask, [1,1,1,self.ops.shape(net)[-1]])\n        net = (mask) * net + (1-mask) * extra\n\n        return net\n\n    def layer_identity(self, net, args, options):\n        if len(args) > 0:\n            self.set_layer(args[0], net)\n        return net\n\n    def layer_conv(self, net, args, options):\n        options = hc.Config(options)\n        config = self.config\n        ops = self.ops\n\n        self.ops.activation_name = options.activation_name\n        self.ops.activation_trainable = options.trainable\n\n        activation_s = options.activation or self.ops.config_option(""activation"")\n        activation = self.ops.lookup(activation_s)\n\n        for sk in self.skip_connections:\n            if len(ops.shape(sk)) == len(ops.shape(net)) and ops.shape(sk)[1] == ops.shape(net)[1]:\n\n                net = tf.concat([net, sk], axis=3)\n\n        if (options.adaptive_instance_norm or self.ops.config_option(""adaptive_instance_norm"")) and len(self.features) > 0:\n            feature = self.features[0]\n            feature = self.layer_linear(feature, [128], options)\n            opts = copy.deepcopy(dict(options))\n            opts[\'activation\']=\'null\'\n            size = self.ops.shape(net)[3]\n            feature = self.layer_linear(feature, [size*2], opts)\n            f1 = tf.reshape(self.ops.slice(feature, [0,0], [-1, size]), [-1, 1, 1, size])\n            f2 = tf.reshape(self.ops.slice(feature, [0,size], [-1, size]), [-1, 1, 1, size])\n            net = self.adaptive_instance_norm(net, f1,f2)\n\n\n        stride = options.stride or self.ops.config_option(""stride"", [2,2])\n        fltr = options.filter or self.ops.config_option(""filter"", [5,5])\n        if type(fltr) != type([]):\n            fltr = [int(fltr), int(fltr)]\n        if type(stride) != type([]):\n            stride = [int(stride), int(stride)]\n        if len(args) > 0:\n            depth = int(args[0])\n        else:\n            depth = self.ops.shape(net)[-1]\n        initializer = None # default to global\n\n        trainable = True\n        if options.trainable == \'false\':\n            trainable = False\n        if options.initializer is not None:\n            initializer = self.ops.lookup_initializer(options.initializer, options)\n        net = ops.conv2d(net, fltr[0], fltr[1], stride[0], stride[1], depth, initializer=initializer, name=options.name, trainable=trainable)\n        avg_pool = options.avg_pool or self.ops.config_option(""avg_pool"")\n        if type(avg_pool) != type([]):\n            avg_pool = [int(avg_pool), int(avg_pool)]\n        if avg_pool:\n            ksize = [1,avg_pool[0], avg_pool[1],1]\n            stride = ksize\n            net = tf.nn.avg_pool(net, ksize=ksize, strides=stride, padding=\'SAME\')\n\n        if activation:\n            #net = self.layer_regularizer(net)\n            net = activation(net)\n\n        self.ops.activation_name = None\n        self.ops.activation_trainable = None\n\n        return net\n\n\n    def layer_linear(self, net, args, options):\n\n        options = hc.Config(options)\n        ops = self.ops\n        config = self.config\n        fltr = options.filter or self.ops.config_option(""filter"")\n\n        self.ops.activation_name = options.activation_name\n        self.ops.activation_trainable = options.trainable\n\n        activation_s = options.activation or self.ops.config_option(""activation"")\n        activation = self.ops.lookup(activation_s)\n\n\n        if ""*"" in str(args[0]):\n            reshape = [int(x) for x in args[0].split(""*"")]\n            size = reduce(operator.mul, reshape)\n        else:\n            size = int(args[0])\n            reshape = None\n        net = ops.reshape(net, [ops.shape(net)[0], -1])\n\n        trainable = True\n        if options.trainable == \'false\':\n            trainable = False\n        bias = True\n        if options.bias == \'false\':\n            bias=False\n\n        if options.initializer is not None:\n            initializer = self.ops.lookup_initializer(options.initializer, options)\n        else:\n            initializer = None\n        name = None\n        if options.name:\n            name = self.ops.description+options.name\n        net = ops.linear(net, size, initializer=initializer, name=name, trainable=trainable, bias=bias)\n\n        if reshape is not None:\n            net = tf.reshape(net, [ops.shape(net)[0]] + reshape)\n        if activation:\n            #net = self.layer_regularizer(net)\n            net = activation(net)\n\n        self.ops.activation_name = None\n        self.ops.activation_trainable = None\n\n        return net\n\n    def layer_reshape(self, net, args, options):\n        dims = [int(x) for x in args[0].split(""*"")]\n        dims = [self.ops.shape(net)[0]] + dims\n        net = tf.reshape(net, dims)\n        return net\n\n    def layer_avg_pool(self, net, args, options):\n\n        options = hc.Config(options)\n        stride=options.stride or self.ops.shape(net)[1]\n        stride=int(stride)\n        ksize = [1,stride,stride,1]\n        size = [int(x) for x in options.slice.replace(""batch_size"",str(self.gan.batch_size())).split(""*"")]\n\n        if options.slice:\n            net = tf.slice(net, [0,0,0,0], size)\n        net = tf.nn.avg_pool(net, ksize=ksize, strides=ksize, padding=\'SAME\')\n\n        return net \n\n    def layer_combine_features(self, net, args, options):\n        op = None\n        if(len(args) > 0):\n            op = args[0]\n\n        def _combine_feature(net, feature, op=None):\n            if op == ""conv"":\n                options[\'stride\']=[1,1]\n                options[\'avg_pool\']=[1,1]\n                layers = int(args[1])\n                feature = self.layer_conv(feature, [layers], options)\n\n            if op == ""linear"":\n                feature = self.layer_linear(feature, [args[1]], options)\n                feature = self.layer_reshape(feature, [args[2]], options)\n\n            if op == \'gru\':\n                tanh = tf.tanh\n                #tanh = self.ops.prelu()\n               # tanh = self.ops.double_sided(default_activation=tanh)\n                sigmoid = tf.sigmoid\n               # sigmoid = self.ops.double_sided(default_activation=sigmoid)\n                def _conv(_net,name, scale=1):\n                    _options = dict(options)\n                    _options[\'activation\']=None\n                    _options[\'name\']=self.ops.description+name\n                    return self.layer_conv(_net, [int(args[1])//scale], _options)\n                z = sigmoid(_conv(net,\'z\',scale=2))\n                r = tf.sigmoid(_conv(net,\'r\',scale=2))\n                th = _conv(net,\'net\',scale=2)\n                fh = _conv(feature,\'feature\',scale=2)\n                h = tanh(th + fh  * r)\n                net = tf.multiply( (1-z), h) + tf.multiply(feature, z)\n\n            if \'only\' in options:\n                return net\n            if feature is not None:\n                net = tf.concat([net, feature], axis=len(self.ops.shape(net))-1)\n            return net\n\n        if \'name\' in options and type(self.features) == type({}):\n            return _combine_feature(net, self.features[options[\'name\']], op)\n\n        for feature in self.features:\n            net = _combine_feature(net, feature, op)\n\n        return net\n\n    def adaptive_instance_norm(self, content, gamma, beta, epsilon=1e-5):\n        c_mean, c_var = tf.nn.moments(content, axes=[1, 2], keep_dims=True)\n        c_std = tf.sqrt(c_var + epsilon)\n        return (1+gamma) * ((content - c_mean) / c_std) + beta\n\n\n\n    def layer_image_statistics(self, net, args, options):\n        s = self.ops.shape(net)\n        options = hc.Config(options)\n        batch_size = s[0]\n        s[-1]=3\n        s[0]=-1\n\n        mean, variance = tf.nn.moments(net, [1])\n        net = tf.concat([mean,variance], axis=1)\n        net = tf.reshape(net, [batch_size, -1])\n\n        return net\n        \n\n    def layer_activation(self, net, args, options):\n        options = hc.Config(options)\n        activation_s = options.activation or self.ops.config_option(""activation"")\n        activation = self.ops.lookup(activation_s)\n        return activation(net)\n\n    def layer_turing_test(self, net, args, options):\n        """"""https://arxiv.org/pdf/1810.10948""""""\n        options = hc.Config(options)\n        net2 = tf.reverse(net, [0])\n        net = tf.concat([net, net2], axis=3)\n        return net\n\n    \n    def layer_split(self, net, args, options):\n        options = hc.Config(options)\n        axis = len(self.ops.shape(net))-1\n        num_splits = int(args[0])\n        selected = int(options.select)\n        return tf.split(net, num_splits, axis)[selected]\n\n    def layer_slice(self, net, args, options):\n        start = int(args[0])\n        size = int(args[1])\n        bs = self.gan.batch_size()\n        return tf.slice(net, [0, start], [bs, size])\n\n\n    def layer_squash(self, net, args, options):\n        s = self.ops.shape(net)\n        batch_size = s[0]\n        net = tf.reshape(net, [batch_size, -1])\n        net = tf.reduce_mean(net, axis=1, keep_dims=True)\n\n        return net\n    \n    def layer_add(self, net, args, options):\n        ops = self.ops\n        gan = self.gan\n        config = self.config\n\n        orig = net\n        if ""layer"" in options:\n            net = self.layer(options[""layer""])\n\n        if len(args) > 0:\n            if args[0] == \'noise\':\n                net = tf.random_normal(self.ops.shape(orig), mean=0, stddev=0.1)\n            elif args[0] == \'layer_filter\':\n                net = config.layer_filter(gan, self.config, net)\n            else:\n                subnet = self.subnets[args[0]]\n                for layer in subnet:\n                    net = self.parse_layer(net, layer)\n                    self.layers += [net]\n\n        if \'mask\' in options:\n            options[\'activation\']=tf.nn.sigmoid\n            mask = self.layer_conv(orig, [self.ops.shape(net)[0]], options)\n            if \'threshold\' in options:\n                mask = tf.greater(mask, float(options[\'threshold\']))\n                mask = tf.cast(mask, tf.float32)\n            return mask * net + (1-mask)*orig\n        if ""lambda"" in options:\n            lam = self.parse_lambda(options)\n            return orig + lam * net\n        else:\n            return orig + net\n\n    def layer_conv_dts(self, net, args, options):\n        options = hc.Config(options)\n        config = self.config\n        ops = self.ops\n\n        self.ops.activation_name = options.activation_name\n        activation_s = options.activation or self.ops.config_option(""activation"")\n        activation = self.ops.lookup(activation_s)\n\n        stride = options.stride or self.ops.config_option(""stride"", [1,1])[0]\n        stride = int(stride)\n        fltr = options.filter or self.ops.config_option(""filter"", [3,3])\n        if type(fltr) == type(""""):\n            fltr=[int(fltr), int(fltr)]\n        depth = int(args[0])\n\n        initializer = None # default to global\n\n        trainable = True\n        if options.trainable == \'false\':\n            trainable = False\n        bias = True\n        if options.bias == \'false\':\n            bias=False\n        net = ops.conv2d(net, fltr[0], fltr[1], stride, stride, depth*4, initializer=initializer, trainable=trainable, bias=bias)\n        s = ops.shape(net)\n        net = tf.depth_to_space(net, 2)\n        if activation:\n            #net = self.layer_regularizer(net)\n            net = activation(net)\n\n        avg_pool = options.avg_pool or self.ops.config_option(""avg_pool"")\n        if type(avg_pool) == type(""""):\n            avg_pool = [int(avg_pool), int(avg_pool)]\n        if avg_pool:\n            ksize = [1,avg_pool[0], avg_pool[1],1]\n            stride = ksize\n            net = tf.nn.avg_pool(net, ksize=ksize, strides=stride, padding=\'SAME\')\n\n        return net\n\n    def layer_controls(self, net, args, options):\n        if args[0] in self.replace_controls:\n            return self.replace_controls[args[0]]\n        self.controls[args[0]] = net\n\n        return net\n\n    def layer_resize_conv(self, net, args, options):\n        options = hc.Config(options)\n        config = self.config\n        ops = self.ops\n\n        activation_s = options.activation or self.ops.config_option(""activation"")\n        activation = self.ops.lookup(activation_s)\n\n        stride = options.stride or self.ops.config_option(""stride"", [1,1])\n        fltr = options.filter or self.ops.config_option(""filter"", [5,5])\n        if type(fltr) == type(""""):\n            fltr=[int(fltr), int(fltr)]\n        depth = int(args[0])\n        initializer = None # default to global\n\n        original = net\n        net = tf.image.resize_images(net, [options.w or ops.shape(net)[1]*2, options.h or ops.shape(net)[2]*2],1)\n\n        if options.concat:\n            extra = self.layer(options.concat)\n            if self.ops.shape(extra) != self.ops.shape(net):\n                extra = tf.image.resize_images(extra, [self.ops.shape(net)[1],self.ops.shape(net)[2]], 1)\n            net = tf.concat([net, extra], axis=len(self.ops.shape(net))-1)\n\n        net = self.layer_conv(net, args, options)\n\n        if options.mask_with:\n            extra = self.layer(options.mask_with)\n            mask = tf.image.resize_images(original, [ops.shape(original)[1]*2, ops.shape(original)[2]*2],1)\n            options[\'activation\'] = \'sigmoid\'\n            mask = self.layer_conv(mask, [1], options)\n            mask = tf.tile(mask, [1,1,1,3])\n            if options.mask_square:\n                mask = tf.square(mask)\n            net = (1 - mask) * net + mask * extra\n\n        return net\n\n    def layer_bicubic_conv(self, net, args, options):\n        s = self.ops.shape(net)\n        net = bicubic_interp_2d(net, [s[1]*2, s[2]*2])\n        net = self.layer_conv(net, args, options)\n        return net\n\n    def layer_deconv(self, net, args, options):\n        options = hc.Config(options)\n        config = self.config\n        ops = self.ops\n\n        self.ops.activation_name = options.activation_name\n        self.ops.activation_trainable = options.trainable\n\n        activation_s = options.activation or self.ops.config_option(""activation"")\n        activation = self.ops.lookup(activation_s)\n\n        stride = options.stride or self.ops.config_option(""stride"", [2,2])\n        fltr = options.filter or self.ops.config_option(""filter"", [5,5])\n        depth = int(args[0])\n\n        if type(stride) != type([]):\n            stride = [int(stride), int(stride)]\n\n        initializer = None # default to global\n        if type(fltr) == type(""""):\n            fltr=[int(fltr), int(fltr)]\n\n        trainable = True\n        if options.trainable == \'false\':\n            trainable = False\n        bias = True\n        if options.bias == \'false\':\n            bias=False\n        if options.initializer is not None:\n            initializer = self.ops.lookup_initializer(options.initializer, options)\n        net = ops.deconv2d(net, fltr[0], fltr[1], stride[0], stride[1], depth, initializer=initializer, name=options.name, trainable=trainable, bias=bias)\n        if activation:\n            #net = self.layer_regularizer(net)\n            net = activation(net)\n\n        self.ops.activation_trainable = None\n        self.ops.activation_name = None\n        return net\n\n\n    def layer_conv_double(self, net, args, options):\n        x1 = self.layer_conv(net, args, options)\n        y1 = self.layer_conv(net, args, options)\n        x2 = self.layer_conv(net, args, options)\n        y2 = self.layer_conv(net, args, options)\n        x = tf.concat([x1,x2],axis=1)\n        y = tf.concat([y1,y2],axis=1)\n        net = tf.concat([x,y],axis=2)\n        return net\n\n\n    def layer_attention(self, net, args, options):\n        ops = self.ops\n        options = hc.Config(options)\n        gan = self.gan\n        oj_lambda = options[""lambda""]\n        if oj_lambda is None:\n            oj_lambda = 1.0\n        c_scale = float(options.c_scale or 8)\n\n        def _flatten(_net):\n            return tf.reshape(_net, [ops.shape(_net)[0], -1, ops.shape(_net)[-1]])\n        def _pool(_net, scale):\n            ksize = [1,scale,1,1]\n            _net = tf.nn.avg_pool(_net, ksize=ksize, strides=ksize, padding=\'SAME\')\n            return _net\n        def _attn(_net, name=None):\n            args = [ops.shape(_net)[-1]]\n            name = name or self.ops.generate_name()\n            options.name=name+\'_fx\'\n            options[\'activation\']=None\n            options[\'avg_pool\']=[1,1]\n            fx = self.layer_conv(_net, args, options)\n            options.name=name+\'_gx\'\n            gx = self.layer_conv(_net, args, options)\n            options.name=name+\'_hx\'\n            hx = self.layer_conv(_net, args, options)\n            if options.c_scale:\n                c_scale\n                fx = _pool(fx, c_scale)\n                gx = _pool(gx, c_scale)\n            bottleneck_shape = ops.shape(hx)\n            fx = _flatten(fx)\n            gx = _flatten(gx)\n            hx = _flatten(hx)\n            fx = tf.transpose(fx, [0,2,1])\n            if options.dot_product_similarity:\n                f = tf.matmul(gx,fx)\n                bji = f / tf.cast(tf.shape(f)[-1], tf.float32)\n            else:\n                bji = tf.nn.softmax(tf.matmul(gx,fx))\n\n            if options.h_activation:\n                hx = ops.lookup(options.h_activation)(hx)\n            oj = tf.matmul(bji, hx)\n            oj = tf.reshape(oj, bottleneck_shape)\n            #if options.final_conv:\n            #args[0] = ops.shape(_net)[-1]\n            #if options.final_activation == \'crelu\':\n            #    args[0] //= 2\n            #options.name=name+\'_oj\'\n            #oj = self.layer_conv(oj, args, options)\n            if options.final_activation:\n                oj = self.ops.lookup(options.final_activation)(oj)\n            if options.enable_at_step:\n                oj *= tf.cast(tf.greater(tf.train.get_global_step(),int(options.enable_at_step)), tf.float32)\n            if options.only:\n                return oj\n            return oj\n\n\n        ojs = [_attn(net, options.name) for i in range(self.config.heads or 1)]\n\n        if options.concat:\n            nets = [net] + [oj*oj_lambda for oj in ojs]\n            return tf.concat(nets, axis=3)\n        else:\n            for oj in ojs:\n                net += oj*oj_lambda\n            return net\n\n\n\n    def layer_conv_reshape(self, net, args, options):\n        options = hc.Config(options)\n        config = self.config\n        ops = self.ops\n\n        activation_s = options.activation or self.ops.config_option(""activation"")\n        activation = self.ops.lookup(activation_s)\n\n        stride = options.stride or self.ops.config_option(""stride"", [1,1])\n        fltr = options.filter or self.ops.config_option(""filter"", [3,3])\n        if type(fltr) == type(""""):\n            fltr=[int(fltr), int(fltr)]\n        if type(stride) == type(""""):\n            stride=[int(stride), int(stride)]\n        depth = int(args[0])\n\n        initializer = None # default to global\n\n        trainable = True\n        if options.trainable == \'false\':\n            trainable = False\n        net = ops.conv2d(net, fltr[0], fltr[1], stride[0], stride[1], depth*4, initializer=initializer, trainable=trainable)\n        s = ops.shape(net)\n        net = tf.reshape(net, [s[0], s[1]*2, s[2]*2, depth])\n        if activation:\n            #net = self.layer_regularizer(net)\n            net = activation(net)\n        return net\n\n    def layer_unpool(self, net, args, options):\n\n        def unpool_2d(pool, \n                       ind, \n                       stride=[1, 2, 2, 1], \n                       scope=\'unpool_2d\'):\n           """"""Adds a 2D unpooling op.\n           https://arxiv.org/abs/1505.04366\n         \n           Unpooling layer after max_pool_with_argmax.\n                Args:\n                    pool:        max pooled output tensor\n                    ind:         argmax indices\n                    stride:      stride is the same as for the pool\n                Return:\n                    unpool:    unpooling tensor\n           """"""\n           with tf.variable_scope(scope):\n             input_shape = tf.shape(pool)\n             output_shape = [input_shape[0], input_shape[1] * stride[1], input_shape[2] * stride[2], input_shape[3]]\n         \n             flat_input_size = tf.reduce_prod(input_shape)\n             flat_output_shape = [output_shape[0], output_shape[1] * output_shape[2] * output_shape[3]]\n         \n             pool_ = tf.reshape(pool, [flat_input_size])\n             batch_range = tf.reshape(tf.range(tf.cast(output_shape[0], tf.int64), dtype=ind.dtype), \n                                               shape=[input_shape[0], 1, 1, 1])\n             b = tf.ones_like(ind) * batch_range\n             b1 = tf.reshape(b, [flat_input_size, 1])\n             ind_ = tf.reshape(ind, [flat_input_size, 1])\n             ind_ = tf.concat([b1, ind_], 1)\n         \n             ret = tf.scatter_nd(ind_, pool_, shape=tf.cast(flat_output_shape, tf.int64))\n             ret = tf.reshape(pool_, output_shape)\n         \n             set_input_shape = pool.get_shape()\n             set_output_shape = [set_input_shape[0], set_input_shape[1] * stride[1], set_input_shape[2] * stride[2], set_input_shape[3]]\n             ret.set_shape(set_output_shape)\n             return ret\n \n \n        options = hc.Config(options)\n        net = unpool_2d(net, tf.ones_like(net, dtype=tf.int64))\n\n        return net \n\n\n    def layer_fractional_avg_pool(self, net, args, options):\n        options = hc.Config(options)\n        net,_,_ = tf.nn.fractional_avg_pool(net, [1.0,0.5,0.5,1.0])\n\n        return net \n    def layer_two_sample_stack(self, net, args, options):\n        options = hc.Config(options)\n        def _slice(_net):\n            s = self.ops.shape(_net)\n            s[0] = s[0] // 2\n            _net1 = tf.slice(_net, [0,0,0,0], s)\n            _net2 = tf.slice(_net, [s[0],0,0,0], s)\n            return _net1, _net2\n        net1, net2 = _slice(net)\n        net1a, net1b = _slice(net1)\n        net2a, net2b = _slice(net2)\n        if options.mixup:\n            alpha = tf.random_uniform([1], 0, 1)\n            t1 = alpha * net1a + (1-alpha) * net1b\n            t2 = alpha * net2a + (1-alpha) * net2b\n            t1 = tf.reshape(t1, self.ops.shape(net1b))\n            t2 = tf.reshape(t2, self.ops.shape(net2b))\n        else:\n            t1 = tf.concat([net1a, net1b], axis=3)\n            t2 = tf.concat([net2a, net2b], axis=3)\n        # hack fixes shape expectations\n        #t1 = tf.concat([t1,t1], axis=0)\n        #t2 = tf.concat([t2,t2], axis=0)\n        target = tf.concat([t1, t2], axis=0)\n        s = self.ops.shape(net)\n\n        return target\n    def layer_pad(self, net, args, options):\n        options = hc.Config(options)\n        s = self.ops.shape(net)\n        sizew = s[1]//2\n        sizeh = s[2]//2\n        net,_,_ = tf.pad(net, [[0,0],[ sizew,sizew],[ sizeh,sizeh],[ 0,0]])\n\n        return net \n\n    def layer_phase_shift(self, net, args, options):\n \n        def _phase_shift(I, r):\n            def _squeeze(x):\n                single_batch = (int(x.get_shape()[0]) == 1)\n                x = tf.squeeze(x)\n                if single_batch:\n                    x_shape = [1]+x.get_shape().as_list()\n                    x = tf.reshape(x, x_shape)\n                return x\n\n            # Helper function with main phase shift operation\n            bsize, a, b, c = I.get_shape().as_list()\n            X = tf.reshape(I, (bsize, a, b, r, r))\n            X = tf.transpose(X, (0, 1, 2, 4, 3))  # bsize, a, b, 1, 1\n            X = tf.split(axis=1, num_or_size_splits=a, value=X)  # a, [bsize, b, r, r]\n            X = tf.concat(axis=2, values=[_squeeze(x) for x in X])  # bsize, b, a*r, r\n            X = tf.split(axis=1, num_or_size_splits=b, value=X)  # b, [bsize, a*r, r]\n            X = tf.concat(axis=2, values=[_squeeze(x) for x in X])  #\n            bsize, a*r, b*r\n            return tf.reshape(X, (bsize, a*r, b*r, 1))\n\n        def phase_shift(X, r, color=False):\n          # Main OP that you can arbitrarily use in you tensorflow code\n          if color:\n            Xc = tf.split(axis=3, num_or_size_splits=3, value=X)\n            X = tf.concat(axis=3, values=[_phase_shift(x, r) for x in Xc])\n          else:\n            X = _phase_shift(X, r)\n          return X\n\n        return phase_shift(net, int(args[0]), color=True)\n\n\n    def layer_subpixel(self, net, args, options):\n        options = hc.Config(options)\n        depth = int(args[0])\n        config = self.config\n        activation = options.activation or self.ops.config_option(""activation"")\n        r = options.r or 2\n        r = int(r)\n        def _PS(X, r, n_out_channel):\n                if n_out_channel >= 1:\n                    bsize, a, b, c = X.get_shape().as_list()\n                    bsize = tf.shape(X)[0] # Handling Dimension(None) type for undefined batch dim\n                    Xs=tf.split(X,r,3) #b*h*w*r*r\n                    Xr=tf.concat(Xs,2) #b*h*(r*w)*r\n                    X=tf.reshape(Xr,(bsize,r*a,r*b,n_out_channel)) # b*(r*h)*(r*w)*c\n                return X\n        args[0]=depth*(r**2)\n        if (activation == \'crelu\' or activation == \'double_sided\'):\n            args[0] //= 2 \n        y1 = self.layer_conv(net, args, options)\n        ps = _PS(y1, r, depth)\n        return ps\n\n    def layer_crop(self, net, args, options):\n        options = hc.Config(options)\n        if len(args) == 0:\n            w = self.gan.width()\n            h = self.gan.height()\n            d = self.gan.channels()\n        else:\n            w = int(args[0])\n            h = int(args[1])\n            d = int(args[2])\n        s = self.ops.shape(net)\n        if w > s[1] or h > s[2] or d > s[3]:\n            raise ConfigurationException(""Input resolution too small for crop"")\n        net = tf.slice(net, [0,0,0,int(options.d_offset or 0)], [-1,w,h,d])\n        return net\n\n    def layer_noise(self, net, args, options):\n        options = hc.Config(options)\n        if ""learned"" in args or options.learned:\n            channels = self.ops.shape(net)[-1]\n            shape = [1,1,channels]\n            initializer = None\n            if options.initializer is not None:\n                initializer = self.ops.lookup_initializer(options.initializer, options)\n            trainable = True\n            if ""trainable"" in options and options[""trainable""] == ""false"":\n                trainable = False\n            with tf.variable_scope(self.ops.generate_name(), reuse=self.ops._reuse):\n                weights = self.ops.get_weight(shape, \'B\', initializer=initializer, trainable=trainable)\n            net += tf.random_normal(self.ops.shape(net), stddev=0.1) * weights\n\n        elif options.mask:\n            options[\'activation\']=tf.nn.sigmoid\n            mask = self.layer_conv(net, args, options)\n            net += tf.random_normal(self.ops.shape(net), stddev=0.1) * mask\n        else:\n            net += tf.random_normal(self.ops.shape(net), stddev=0.1)\n        return net\n\n    def layer_latent(self, net, args, options):\n        return self.gan.latent.sample\n        return tf.random_uniform([self.ops.shape(net)[0], args[0]], -1, 1)\n\n    def layer_layer(self, net, args, options):\n        options = hc.Config(options)\n        if ""src"" in options:\n            obj = getattr(self.gan, options.src)\n        else:\n            obj = self\n        return obj.layer(args[0])\n    def layer_layer_norm(self, net, args, options):\n        return self.ops.lookup(""layer_norm"")(self, net)\n\n    def layer_variational_noise(self, net, args, options):\n        net *= tf.random_normal(self.ops.shape(net), mean=1, stddev=0.02)\n        return net\n\n    def layer_variational(self, net, args, options):\n        ops = self.ops\n        options[\'name\']=self.ops.description+""k1""\n        mu = self.layer_conv(net, args, options)\n        options[\'name\']=self.ops.description+""k2""\n        sigma = self.layer_conv(net, args, options)\n        z = mu + sigma * tf.random_normal(tf.shape(mu), 0, 1, dtype=tf.float32)\n        self.variational=[mu,sigma]\n        if not self.ops._reuse:\n            if(hasattr(self.gan, ""variational"")):\n                self.gan.variational += [[mu,sigma]]\n            else:\n                self.gan.variational=[[mu,sigma]]\n        return z\n\n\n    def layer_concat_noise(self, net, args, options):\n        noise = tf.random_normal(self.ops.shape(net), stddev=0.1)\n        net = tf.concat([net, noise], axis=len(self.ops.shape(net))-1)\n        return net\n\n    def layer_concat(self, net, args, options):\n        if len(args) > 0 and args[0] == \'noise\':\n            extra = tf.random_normal(self.ops.shape(net), stddev=0.1)\n        if \'layer\' in options:\n            extra = self.layer(options[\'layer\'])\n\n        if self.ops.shape(extra) != self.ops.shape(net):\n            extra = tf.image.resize_images(extra, [self.ops.shape(net)[1],self.ops.shape(net)[2]], 1)\n\n        if \'mask\' in options:\n            options[\'activation\']=tf.nn.sigmoid\n            mask = self.layer_conv(net, [self.ops.shape(net)[-1]], options)\n            extra *= mask\n\n        net = tf.concat([net, extra], axis=len(self.ops.shape(net))-1)\n        return net\n\n    def layer_gram_matrix(self, net, args, options):\n\n        shape = self.ops.shape(net)\n        num_channels = shape[3]\n\n        bs = shape[0]\n        net = tf.reshape(net, shape=[bs, -1, num_channels])\n\n        net = tf.matmul(tf.transpose(net, perm=[0,2,1]), net)\n        net = tf.reshape(net, shape=[bs, shape[1], shape[1], -1])\n\n        return net\n\n\n    def layer_minibatch(self, net, args, options):\n        options = hc.Config(options)\n        s = self.ops.shape(net)\n        group_size = options.group_size or self.ops.shape(net)[0]\n        group = tf.reshape(net, [group_size, -1, s[1], s[2], s[3]])\n        group -= tf.reduce_mean(group, axis=0, keep_dims=True)\n        group = tf.reduce_mean(tf.square(group), axis=0)\n        group = tf.sqrt(group+1e-8)\n        group = tf.reduce_mean(group, axis=[1,2,3], keep_dims=True)\n        group = tf.tile(group, [group_size, s[1], s[2], s[3]])\n        group = tf.concat([net, group], axis=3)\n        return group\n\n    def layer_relational(self, net, args, options):\n        def concat_coor(o, i, d):\n            coor = tf.tile(tf.expand_dims(\n                [float(int(i / d)) / d, (i % d) / d], axis=0), [self.ops.shape(net)[0], 1])\n            o = tf.concat([o, tf.to_float(coor)], axis=1)\n            return o\n\n\n        # eq.1 in the paper\n        # g_theta = (o_i, o_j, q)\n        # conv_4 [B, d, d, k]\n        d = net.get_shape().as_list()[1]\n        all_g = []\n        for i in range(d*d):\n            o_i = net[:, int(i / d), int(i % d), :]\n            o_i = concat_coor(o_i, i, d)\n            for j in range(d*d):\n                o_j = net[:, int(j / d), int(j % d), :]\n                o_j = concat_coor(o_j, j, d)\n                r_input = tf.concat([o_i, o_j], axis=1)\n                if i == 0 and j == 0:\n                    g_theta = self.gan.create_component(self.config.relational, name=\'relational\', input=r_input, reuse=self.ops._reuse)\n                    g_i_j = g_theta.sample\n                    self.ops.weights += g_theta.variables()\n                else:\n                    g_i_j = g_theta.reuse(r_input)\n                all_g.append(g_i_j)\n\n        all_g = tf.stack(all_g, axis=0)\n        all_g = tf.reduce_mean(all_g, axis=0, name=\'all_g\')\n        return all_g\n\n    def layer_pixel_norm(self, net, args, options):\n        epsilon = 1e-8\n        return net * tf.rsqrt(tf.reduce_mean(tf.square(net), axis=1, keepdims=True) + epsilon)\n\n    def layer_double_resolution(self, net, args, options):\n\n        def scale_up(piece):\n            orig_shape = self.ops.shape(piece)\n            orig_piece = piece\n            piece = tf.reshape(piece, [-1, 1, 1])\n            piece = tf.tile(piece, [1,2,2])\n            ns = []\n            squares = tf.reshape(piece, [-1, 2])\n            cells = tf.split(squares, self.ops.shape(squares)[0], axis=0)\n            for i in range(0,self.ops.shape(squares)[0],orig_shape[1]*2):\n                ra = cells[i:(i+orig_shape[1]*2)]\n                ns += ra[::2]+ra[1::2]\n            ns = tf.concat(ns, axis=0)\n            new_shape = [orig_shape[0], orig_shape[1]*2, orig_shape[2]*2, 1]\n            result = tf.reshape(ns, new_shape)\n            return result\n        return scale_up(piece)\n        #pieces = tf.split(net, self.ops.shape(net)[3], 3)\n        #pieces = [scale_up(piece) for piece in pieces]\n        #return tf.concat(pieces, axis=3)\n\n    def layer_adaptive_instance_norm(self, net, args, options):\n        if \'w\' in options:\n            f = self.layer(options[\'w\'])\n        else:\n            f = self.layer(\'w\')\n        if f is None:\n            raise(""ERROR: Could not find named generator layer \'w\', add name=w to the input layer in your generator"")\n        if len(args) > 0:\n            w = args[0]\n        else:\n            w = 128\n        #f2 = self.layer_linear(f, [w], options)\n        opts = copy.deepcopy(dict(options))\n        size = self.ops.shape(net)[3]\n        opts[""activation""]=""null""\n        feature = self.layer_linear(f, [size*2], opts)\n        f1 = tf.reshape(self.ops.slice(feature, [0,0], [-1, size]), [-1, 1, 1, size])\n        f2 = tf.reshape(self.ops.slice(feature, [0,size], [-1, size]), [-1, 1, 1, size])\n        net = self.adaptive_instance_norm(net, f1,f2)\n        return net\n\n    def layer_zeros_like(self, net, args, options):\n        return tf.zeros_like(net)\n\n    def layer_const(self, net, args, options):\n        options = hc.Config(options)\n        s  = [1] + [int(x) for x in args[0].split(""*"")]\n        trainable = True\n        if ""trainable"" in options and options[""trainable""] == ""false"":\n            trainable = False\n        initializer = None\n        if ""initializer"" in options and options[""initializer""] is not None:\n            initializer = self.ops.lookup_initializer(options[""initializer""], options)\n        with tf.variable_scope(self.ops.generate_name(), reuse=self.ops._reuse):\n            return tf.tile(self.ops.get_weight(s, name=\'const\', trainable=trainable, initializer=initializer), [self.gan.batch_size(), 1,1,1])\n\n    def layer_reference(self, net, args, options):\n        options = hc.Config(options)\n\n        obj = self\n        if ""src"" in options:\n            obj = getattr(self.gan, options.src)\n        if ""resize_images"" in options:\n            if hasattr(obj, \'layer\'):\n                return self.layer_resize_images(obj.layer(options.name), options[""resize_images""].split(""*""), options)\n            else:\n                return self.layer_resize_images(getattr(obj, options.name), options[""resize_images""].split(""*""), options)\n        else:\n            return obj.layer(options.name)\n\n    def layer_knowledge_base(self, net, args, options):\n        if not hasattr(self, \'knowledge_base\'):\n            self.knowledge_base = []\n        kb = tf.Variable(tf.zeros_like(net), dtype=tf.float32, trainable=False)\n        self.knowledge_base.append([options[\'name\'], kb])\n        return tf.concat([net, kb], axis=-1)\n\n    def layer_resize_images(self, net, args, options):\n        options = hc.Config(options)\n        if len(args) == 0:\n            w = self.gan.width()\n            h = self.gan.height()\n        else:\n            w = int(args[0])\n            h = int(args[1])\n        method = options.method or 1\n        return tf.image.resize_images(net, [w, h], method=method)\n    \n    def layer_progressive_replace(self, net, args, options):\n        start = self.layer(options[""start""])\n        end = self.layer(options[""end""])\n        steps = float(options[""steps""])\n        delay = 0\n        if ""delay"" in options:\n            delay = int(options[""delay""])\n        if self.ops.shape(start) != self.ops.shape(end):\n            start = tf.image.resize_images(start, [self.ops.shape(end)[1], self.ops.shape(end)[2]],1)\n        decay = (tf.cast(self.gan.steps, dtype=tf.float32)-tf.constant(delay, dtype=tf.float32)) / tf.constant(steps, dtype=tf.float32)\n\n        decay = tf.minimum(1.0, decay)\n        decay = tf.maximum(0.0, decay)\n        self.gan.add_metric(\'decay\', decay)\n        self.gan.add_metric(\'gs\', self.gan.steps)\n\n        net = decay * end + (1.0-decay) * start\n        if ""name"" in options:\n            net = tf.identity(net, name=options[""name""])\n        return net\n\n'"
hypergan/configuration.py,0,"b'import hyperchamber as hc\nimport os\nimport glob\n\nclass Configuration:\n    def all_paths():\n        dirname = os.path.dirname(os.path.realpath(__file__))\n        paths = [\n                 os.path.abspath(os.path.relpath("".""))+""/"", \n                 dirname + ""/configurations/"", \n                 os.path.abspath(os.path.expanduser(\'~/.hypergan/configs/\'))+\'/\'\n                ]\n        return paths\n    def find(configuration, verbose=True):\n        def _find_file():\n            paths = Configuration.all_paths()\n            Configuration.paths = paths\n            for path in paths:\n                file_path = path + configuration\n                file_path = os.path.realpath(file_path)\n                if os.path.exists(file_path):\n                    return file_path\n\n        if not configuration.endswith(\'.json\'):\n            configuration += "".json""\n        config_filename = _find_file()\n        if config_filename is None:\n            message = ""Could not find configuration "" + configuration\n            print(message)\n            print(""Searched configuration paths"", Configuration.all_paths())\n            print(""See all available configurations with hypergan new -l ."")\n            raise Exception(message)\n        if verbose:\n            print(""Loading configuration"", config_filename)\n        return config_filename\n\n    def load(configuration, verbose=True):\n        config_file = Configuration.find(configuration, verbose=verbose)\n        if config_file is None:\n            print(""[hypergan] Could not find config named:"", configuration, ""checked paths"", Configuration.paths)\n        if verbose:\n          print(""[hypergan] Loading config"", config_file)\n        return hc.Selector().load(config_file)\n    def default():\n        return Configuration.load(\'default.json\')\n    def list():\n        paths = Configuration.all_paths()\n        return sorted(sum([[x.split(""/"")[-1].split(""."")[0] for x in glob.glob(path+""/*.json"")] for path in paths], []))\n\n'"
hypergan/gan.py,0,"b""from hypergan.gans.standard_gan import StandardGAN\nfrom hypergan.ops.tensorflow.ops import TensorflowOps\n\ndef gan_factory(*args, **kw_args):\n    if 'config' in kw_args:\n        config = kw_args['config']\n    elif len(args) > 0:\n        config = args[0]\n    else:\n        config = None\n    if config and 'class' in config:\n        return TensorflowOps.lookup_function(None, config['class'])(*args, **kw_args)\n    else:\n        return StandardGAN(*args, **kw_args)\n\nGAN=gan_factory\n"""
hypergan/gan_component.py,5,"b'import hyperchamber as hc\nimport inspect\nimport itertools\nimport types\nimport tensorflow as tf\n\nclass ValidationException(Exception):\n    """"""\n    GAN components validate their configurations before creation.  \n    \n    `ValidationException` occcurs if they fail.\n    """"""\n    pass\n\nclass GANComponent:\n    """"""\n    GANComponents are pluggable pieces within a GAN.\n\n    GAN objects are also GANComponents.\n    """"""\n    def __init__(self, gan, config, name=None, reuse=False):\n        """"""\n        Initializes a gan component based on a `gan` and a `config` dictionary.\n\n        Different components require different config variables.  \n\n        A `ValidationException` is raised if the GAN component configuration fails to validate.\n        """"""\n        self.gan = gan\n        self.config = hc.Config(config)\n        errors = self.validate()\n        if errors != []:\n            raise ValidationException(self.__class__.__name__+"": "" +""\\n"".join(errors))\n        self.create_ops(config)\n        self.ops.describe(name or self.__class__.__name__)\n        self._metrics = []\n\n        if reuse:\n            self.ops.reuse()\n\n        self.create()\n\n    def create_ops(self, config):\n        """"""\n        Create the ops object as `self.ops`.  Also looks up config\n        """"""\n        if self.gan is None:\n            return\n        if self.gan.ops_backend is None:\n            return\n        self.ops = self.gan.ops_backend(config=self.config, device=self.gan.device)\n        self.config = self.ops.lookup(config)\n        # set functions correctly\n        for k,v in dict(self.config).items():\n            self.config[k] = self.ops.lookup(v)\n\n    def create(self, *args):\n        raise ValidationException(""GANComponent.create() called directly.  Please override."")\n\n    def required(self):\n        """"""\n        Return a list of required config strings and a `ValidationException` will be thrown if any are missing.\n\n        Example: \n        ```python\n            class MyComponent(GANComponent):\n                def required(self):\n                    ""learn rate is required""\n                    [""learn_rate""]\n        ```\n        """"""\n        return []\n\n    def validate(self):\n        """"""\n        Validates a GANComponent.  Return an array of error messages. Empty array `[]` means success.\n        """"""\n        errors = []\n        required = self.required()\n        for argument in required:\n            if(self.config.__getattr__(argument) == None):\n                errors.append(""`""+argument+""` required"")\n\n        if(self.gan is None):\n            errors.append(""GANComponent constructed without GAN"")\n        return errors\n\n    def weights(self):\n        """"""\n            The weights of the GAN component.\n        """"""\n        return self.ops.weights\n\n    def biases(self):\n        """"""\n            Biases of the GAN component.\n        """"""\n        return self.ops.biases\n\n    def variables(self):\n        """"""\n            All variables associated with this component.\n        """"""\n        return self.ops.variables()\n\n    def add_variables(self, gan_component):\n        """"""\n            Add additional variables from a gan component for training\n        """"""\n        self.ops.biases += gan_component.ops.biases\n        self.ops.weights += gan_component.ops.weights\n\n\n    def split_batch(self, net, count=2):\n        """""" \n        Discriminators return stacked results (on axis 0).  \n        \n        This splits the results.  Returns [d_real, d_fake]\n        """"""\n        ops = self.ops or self.gan.ops\n        s = ops.shape(net)\n        bs = s[0]\n        nets = []\n        net = ops.reshape(net, [bs, -1])\n        start = [0 for x in ops.shape(net)]\n        for i in range(count):\n            size = [bs//count] + [x for x in ops.shape(net)[1:]]\n            nets.append(ops.slice(net, start, size))\n            start[0] += bs//count\n        s[0] = s[0] // count\n        nets = [ops.reshape(net,s) for net in nets]\n        return nets\n\n    def reuse(self, net):\n        self.ops.scope_count=0\n        self.ops.reuse()\n        net = self.build(net)\n        self.ops.stop_reuse()\n        return net\n\n    def layer_regularizer(self, net):\n        symbol = self.config.layer_regularizer\n        op = self.gan.ops.lookup(symbol)\n        if op and isinstance(op, types.FunctionType):\n            net = op(self, net)\n        return net\n\n    def split_by_width_height(self, net):\n        elems = []\n        ops = self.gan.ops\n        shape = ops.shape(net)\n        bs = shape[0]\n        height = shape[1]\n        width = shape[2]\n        for i in range(width):\n            for j in range(height):\n                elems.append(ops.slice(net, [0, i, j, 0], [bs, 1, 1, -1]))\n\n        return elems\n\n    def permute(self, nets, k):\n        return list(itertools.permutations(nets, k))\n\n    #this is broken\n    def fully_connected_from_list(self, nets):\n        results = []\n        ops = self.ops\n        for net, net2 in nets:\n            net = ops.concat([net, net2], axis=3)\n            shape = ops.shape(net)\n            bs = shape[0]\n            net = ops.reshape(net, [bs, -1])\n            features = ops.shape(net)[1]\n            net = ops.linear(net, features)\n            #net = self.layer_regularizer(net)\n            net = ops.lookup(\'lrelu\')(net)\n            #net = ops.linear(net, features)\n            net = ops.reshape(net, shape)\n            results.append(net)\n        return results\n\n    def progressive_growing_mask(self, index):\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        total_steps = self.gan.config.progressive_growing_steps or 100000\n        fade_amount = total_steps//(len(pe_layers)+1)\n        return self.measure_layers(fade_amount*index, fade_amount*(index+1))\n\n    def measure_layers(self, start, end):\n        global_step = tf.train.get_global_step()\n        global_step += end - start\n        start = tf.cast(start, tf.int32)\n        end = tf.cast(end, tf.int32)\n        ratio = (global_step - start)/(end - start)\n        ratio = tf.cast(ratio, tf.float32)\n        ratio = tf.maximum(tf.minimum(ratio, 1), 0)\n\n        return ratio\n\n    def inputs(self):\n        """"""inputs() returns any input tensors""""""\n        return []\n\n    def add_metric(self, name, value):\n        """"""adds metric to monitor during training\n            name:string\n            value:Tensor\n        """"""\n        counters = 0\n        for m in self._metrics:\n            if name == m[""name""] or m[""name""].startswith(name):\n                counters += 1\n        if counters != 0:\n            name += ""_""+str(counters+1)\n        self._metrics.append({\n            ""description"": self.ops.description,\n            ""name"": name,\n            ""value"": value\n        })\n        return self._metrics\n\n    def metrics(self):\n        """"""returns a metric : tensor hash""""""\n        metrics = {}\n        for metric in self._metrics:\n            metrics[metric[\'name\']]=metric[\'value\']\n        return metrics\n'"
hypergan/multi_component.py,5,"b'from hypergan.gan_component import GANComponent\n\nimport tensorflow as tf\n\nclass MultiComponent():\n    """"""\n        Used to combine multiple components into one.  For example, `gan.loss = MultiComponent([loss1, loss2])`\n    """"""\n    def __init__(self, components=[], combine=\'concat\'):\n        self.components = components\n        self.gan = components[0].gan\n        self._combine = combine\n        self._cache = {}\n\n    def __getattr__(self, name):\n        if len(self.components) == 0:\n            return None\n\n        attributes = self.lookup(name)\n        self._cache[name] = self.combine(name, attributes)\n        return self._cache[name]\n\n    def lookup(self, name):\n        lookups = []\n        for component in self.components:\n            if hasattr(component, name):\n                lookups.append(getattr(component,name))\n            else:\n                print(""Warning:Skipping lookup of ""+name+"" because None was returned"")\n\n        return lookups\n\n    def combine(self, name, data):\n        if data == None or data == []:\n            return data\n\n        if isinstance(data[0], type({})):\n            full_dict = {}\n            for d in data:\n                full_dict.update(d)\n            return full_dict\n        # loss functions return [d_loss, g_loss].  We combine columnwise.\n        if isinstance(data, list) and isinstance(data[0], list) and isinstance(data[0][0], tf.Tensor):\n            if(name in self._cache):\n                return self._cache[name]\n            result = []\n            for j,_ in enumerate(data[0]):\n                column = []\n                for i,_ in enumerate(data):\n                    column.append(data[i][j])\n                reduction = self.reduce(column)\n                result.append(reduction)\n\n            return result\n\n        if type(data[0]) == tf.Tensor:\n            if(name in self._cache):\n                return self._cache[name]\n            return self.reduce(data)\n        if callable(data[0]):\n            return self.call_each(data)\n        return data\n\n    def reduce(self, data):\n        data = [d for d in data if d is not None]\n        ops = self.gan.ops\n        if self._combine == \'concat\':\n            return self.gan.ops.concat(values=data, axis=len(self.gan.ops.shape(data[0]))-1)\n        elif self._combine == \'add\':\n            data = [ops.reshape(d,ops.shape(data[0])) for d in data]\n            return self.gan.ops.add_n(data)\n        elif self._combine == \'mask\':\n            def _mask(_net):\n                m=tf.slice(_net,[0,0,0,0], [-1,-1,-1,1])\n                d=tf.slice(_net,[0,0,0,1], [-1,-1,-1,ops.shape(_net)[-1]-1])\n                return tf.nn.sigmoid(m)*d\n            data = [_mask(d) for d in data]\n            return self.gan.ops.add_n(data)\n\n        raise ""Unknown combine"" + self._combine\n\n    def call_each(self, methods):\n        def do_call(*args, **kwargs):\n            results = []\n            for method in methods:\n                results.append(method(*args, **kwargs))\n            return self.combine(str(method), results)\n        return do_call\n'"
hypergan/pygame_viewer.py,0,"b'""""""\nOpens a window that displays an image.\nUsage:\n\n    from viewer import GlobalViewer\n    GlobalViewer.update(image)\n\n""""""\nimport numpy as np\n\n\n\nclass PygameViewer:\n\n    def __init__(self, title=""HyperGAN"", viewer_size=1, enabled=True):\n        self.screen = None\n        self.title = title\n        self.viewer_size = viewer_size\n        self.enabled = enabled\n\n    def update(self, image):\n        if not self.enabled: return\n\n        image = np.transpose(image, [1, 0,2])\n\n        if not self.screen:\n            import pygame\n            self.pg = pygame\n            if self.viewer_size <= 0:\n                self.viewer_size = 0.1\n            self.size = [int(image.shape[0] * self.viewer_size), int(image.shape[1] * self.viewer_size)]\n            self.aspect_w = image.shape[1] / image.shape[0]\n            self.aspect_h = image.shape[0] / image.shape[1]\n            self.temp_size = self.size\n            self.screen = self.pg.display.set_mode(self.size,self.pg.RESIZABLE)\n            self.pg.display.set_caption(self.title)\n\n        for event in self.pg.event.get():\n            if event.type == self.pg.VIDEORESIZE:\n                if self.size[0] != event.size[0]:\n                    self.temp_size = [event.size[0], int(event.size[0] * self.aspect_w)]\n                elif self.size[1] != event.size[1]:\n                    self.temp_size = [int(event.size[1] * self.aspect_h), event.size[1]]\n\n            elif event.type == self.pg.ACTIVEEVENT and event.state == 2 and event.gain == 1:\n                self.size = self.temp_size\n                self.screen = self.pg.display.set_mode(self.size,self.pg.RESIZABLE)   \n\n\n        surface = self.pg.Surface([image.shape[0],image.shape[1]])\n        self.pg.surfarray.blit_array(surface, image)\n        self.screen.blit(self.pg.transform.scale(surface,self.size),(0,0))\n        self.pg.display.flip()\n\n       \n'"
hypergan/skip_connections.py,0,"b'import hyperchamber as hc\nimport tensorflow as tf\n\nclass SkipConnections:\n    """"""\n    Skip connections allow for cross-graph connections by shape.\n\n    For example:\n\n    ```python\n        skip_connections.set(\'layer_filter\', net) # net is 64x64x3\n        skip_connections.set(\'layer_filter\', net2) # net2 is 128x128x3\n        skip_connections.get(\'layer_filter\', [128, 128, 3]) #returns net2\n        skip_connections.get(\'layer_filter\', [64, 64, 3]) #returns net\n    ```\n    """"""\n    def __init__(self):\n        self.connections = {}\n\n    def get(self, name, shape=None):\n        if shape:\n            shape = [int(x) for x in shape]\n        \n        connections = hc.Config(self.connections)\n        if name in connections:\n            conns = connections[name]\n        else:\n            conns = []\n        for con in conns:\n            if con[0] == shape:\n                return con[1]\n        return None\n\n    def get_closest(self, name, shape=None):\n        if shape:\n            shape = [int(x) for x in shape]\n        \n        connections = hc.Config(self.connections)\n        if name in connections:\n            conns = connections[name]\n        else:\n            conns = []\n        for con in conns:\n            s1 = con[0]\n            s2 = shape\n            print(""---->"", s1, s2)\n            if s1[1] >= s2[1]: \n                return con[1]\n        return None\n\n\n    def get_shapes(self, name):\n        if name not in self.connections.keys():\n            return None\n        shapes = []\n        if name not in self.connections.keys():\n            return []\n        for conn in self.connections[name]:\n            if conn[0] not in shapes:\n                shapes.append(conn[0])\n        return shapes\n\n    def clear(self, name, shape=None):\n        new_connections = []\n        for conn in self.connections[name]:\n            if(shape == conn[0] or shape is None):\n                pass\n            else:\n                new_connections.append(conn)\n        self.connections[name] = new_connections\n\n    def get_array(self, name, shape=None):\n        if shape:\n            shape = [int(x) for x in shape]\n        connections = hc.Config(self.connections)\n        if name in connections:\n            conns = connections[name]\n        else:\n            conns = []\n        return [con[1] for con in conns if shape is None or con[0] == shape]\n\n\n    def set(self, name, value):\n        shape = value.get_shape()\n        if name not in self.connections:\n            self.connections[name] = []\n        self.connections[name].append([[int(x) for x in shape], value])\n'"
hypergan/tk_viewer.py,0,"b'""""""\nOpens a window that displays an image.\nUsage:\n\n    from viewer import GlobalViewer\n    GlobalViewer.update(image)\n\n""""""\nimport numpy as np\nimport os\nimport contextlib\n\n\nclass TkViewer:\n    def __init__(self, title=""HyperGAN"", viewer_size=1, enabled=True):\n        self.screen = None\n        self.title = title\n        self.viewer_size = viewer_size\n        self.enabled = enabled\n        self.enable_menu = True\n\n    def update(self, gan, image):\n        if not self.enabled: return\n\n        original_image = image\n        if len(np.shape(image)) == 2:\n            s = np.shape(image)\n            image = np.reshape(image, [s[0], s[1], 1])\n            image = np.tile(image, [1,1,3])\n        image = np.transpose(image, [1, 0,2])\n\n        if not self.screen:\n\n            with contextlib.redirect_stdout(None):\n                import pygame\n\n            import tkinter as tk\n            import tkinter.ttk\n            class ResizableFrame(tk.Frame):\n                def __init__(self,parent,tkviewer=None,**kwargs):\n                    tk.Frame.__init__(self,parent,**kwargs)\n                    self.bind(""<Configure>"", self.on_resize)\n                    self.height = kwargs[\'height\']\n                    self.width = kwargs[\'width\']\n                    self.tkviewer = tkviewer\n                    self.aspect_ratio = float(self.width)/float(self.height)\n\n                def on_resize(self,event):\n                    wscale = float(event.width)/self.width\n                    hscale = float(event.height)/self.height\n                    self.width = event.width\n                    self.height = event.height\n                    self.config(width=self.width, height=self.height)\n                    self.tkviewer.size = [self.width, self.height]\n                    self.tkviewer.screen = self.tkviewer.pg.display.set_mode(self.tkviewer.size,self.tkviewer.pg.RESIZABLE)   \n                    self.enforce_aspect_ratio(event)\n                    surface = self.tkviewer.pg.Surface([image.shape[0],image.shape[1]])\n                    self.tkviewer.pg.surfarray.blit_array(surface, image[:,:,:3])\n                    self.tkviewer.screen.blit(self.tkviewer.pg.transform.scale(surface,self.tkviewer.size),(0,0))\n                    self.tkviewer.pg.display.flip()\n\n\n                def enforce_aspect_ratio(self, event):\n                    desired_width = event.width\n                    desired_height = int(event.width / self.aspect_ratio)\n\n                    if desired_height > event.height:\n                        desired_height = event.height\n                        desired_width = int(event.height * self.aspect_ratio)\n\n                    self.config(width=desired_width, height=desired_height)\n                    self.tkviewer.size = [desired_width, desired_height]\n                    self.tkviewer.screen = self.tkviewer.pg.display.set_mode(self.tkviewer.size,self.tkviewer.pg.RESIZABLE)   \n\n\n            self.size = [int(image.shape[0] * self.viewer_size), int(image.shape[1] * self.viewer_size)]\n\n            self.pg = pygame\n            self.tk = tk\n            root = tk.Tk(className=self.title)\n            embed = ResizableFrame(root, width=self.size[0], height=self.size[1], tkviewer=self)\n            root.rowconfigure(0,weight=1)\n            root.rowconfigure(1,weight=1)\n            root.columnconfigure(0,weight=1)\n            root.columnconfigure(1,weight=1)\n            embed.pack(expand=tk.YES, fill=tk.BOTH)\n\n            def _save_model(*args):\n                gan.save(gan.save_file)\n\n            def _exit(*args):\n                gan.exit()\n\n            def _refresh_sample(*args):\n                gan.cli.sample(False)\n\n            def _select_sampler(gan, name, value, submenu):\n                def _select_sampler_proc():\n                    gan.cli.sampler = gan.cli.sampler_for(name)(gan)\n                    gan.cli.sample(False)\n                    _refresh_sampler_submenu(submenu)\n                return _select_sampler_proc\n\n            def _refresh_sampler_submenu(submenu):\n                if submenu.count > 0:\n                    submenu.delete(0, submenu.count)\n\n                for (k, v) in gan.get_registered_samplers().items():\n                    showall = tk.BooleanVar()\n                    showall.set(gan.selected_sampler == k)\n                    if v.compatible_with(gan):\n                        state = tk.NORMAL\n                    else:\n                        state = tk.DISABLED\n\n                    print(""Selected"", gan.selected_sampler, k, gan.selected_sampler == k)\n                    submenu.add_checkbutton(label=k, onvalue=True, offvalue=False, variable=showall, command=_select_sampler(gan, k, showall, submenu), state=state)\n                num_samplers = len(gan.get_registered_samplers())\n\n                submenu.count = num_samplers\n\n\n            def _create_status_bar(root):\n                statusbar = tk.Frame(root, height=24)\n                statusbar.pack(side=tk.BOTTOM, fill=tk.X)\n\n                label_training = tk.Label(statusbar, text=""Training"", font=12)\n                label_training.grid(row=0,column=0) \n                sep = tkinter.ttk.Separator(statusbar, orient=tk.VERTICAL).grid(column=1, row=0, sticky=\'ns\')\n                label = tk.Label(statusbar, text=""Starting"", font=12)\n                label.grid(row=0, column=2) \n                def __update_step():\n                    if hasattr(gan, \'step_count\'):\n                        label[\'text\']=(""Step "" + str(gan.step_count))\n                    root.after(1000, __update_step)\n\n\n                __update_step()\n                return statusbar\n\n            menubar = tk.Menu(root)\n            filemenu = tk.Menu(menubar, tearoff=0)\n            filemenu.add_command(label=""Save"", command=_save_model, underline=0, accelerator=""Ctrl+s"")\n\n            filemenu.add_separator()\n\n            samplemenu = tk.Menu(menubar, tearoff=0)\n            samplemenu.add_command(label=""Refresh"", command=_refresh_sample, underline=0, accelerator=""Ctrl+r"")\n\n            filemenu.add_command(label=""Save and Exit"", command=_exit, underline=10, accelerator=""Ctrl+q"")\n            menubar.add_cascade(label=""File"", menu=filemenu, underline=0)\n            menubar.add_cascade(label=""Sample"", menu=samplemenu, underline=0)\n            samplermenu = tk.Menu(samplemenu)\n            samplemenu.add_cascade(label=""Sampler"", menu=samplermenu, underline=0)\n            samplermenu.count = 0\n            _refresh_sampler_submenu(samplermenu)\n\n            root.bind_all(""<Control-q>"", _exit)\n            root.bind_all(""<Control-r>"", _refresh_sample)\n            root.bind_all(""<Control-s>"", _save_model)\n\n\n            if self.enable_menu:\n                root.config(menu=menubar)\n                _create_status_bar(root)\n\n            # Tell pygame\'s SDL window which window ID to use\n            os.environ[\'SDL_WINDOWID\'] = str(embed.winfo_id())\n            # Show the window so it\'s assigned an ID.\n            root.update()\n            self.root = root\n\n            # Usual pygame initialization\n            if self.viewer_size <= 0:\n                self.viewer_size = 0.1\n            self.aspect_w = image.shape[1] / image.shape[0]\n            self.aspect_h = image.shape[0] / image.shape[1]\n            self.temp_size = self.size\n            self.screen = self.pg.display.set_mode(self.size,self.pg.RESIZABLE)\n            self.pg.display.set_caption(self.title)\n\n            root.title(self.title)\n            root.wm_title(self.title)\n            embed.winfo_toplevel().title(self.title)\n\n        padw = 0\n        padh = 0\n        if original_image.shape[0] > original_image.shape[1]:\n            padh = (original_image.shape[0] - original_image.shape[1])//2\n        if original_image.shape[1] > original_image.shape[0]:\n            padw = (original_image.shape[1] - original_image.shape[0])//2\n        pad_image = np.pad(original_image, [(padw, padw), (padh,padh), (0,0)], \'constant\')\n        w = pad_image.shape[0]\n        h = pad_image.shape[1]\n        #xdata = b\'P6 \' + str(w).encode() + b\' \' + str(h).encode() + b\' 255 \' + pad_image.tobytes()\n        #tk_image = self.tk.PhotoImage(data=xdata, format=""PPM"", width=w, height=h)\n        #self.root.tk.call(\'wm\', \'iconphoto\', self.root._w, tk_image.subsample(max(1, w//256), max(1, h//256)))\n\n        surface = self.pg.Surface([image.shape[0],image.shape[1]])\n        self.pg.surfarray.blit_array(surface, image[:,:,:3])\n        self.screen.blit(self.pg.transform.scale(surface,self.size),(0,0))\n        self.pg.display.flip()\n\n    def tick(self):\n        """"""\n            Called repeatedly regardless of gan state.\n        """"""\n        if hasattr(self, \'root\'):\n            self.root.update()\n\n       \n'"
hypergan/viewer.py,0,"b'""""""\nOpens a window that displays an image.\nUsage:\n\n    from viewer import GlobalViewer\n    GlobalViewer.update(image)\n\nDelays loading Gtk and friends until enable() is called.\n""""""\nfrom hypergan.pygame_viewer import PygameViewer\nfrom hypergan.tk_viewer import TkViewer\n\nGlobalViewer = TkViewer()\n'"
tests/cli_test.py,2,"b'import hypergan as hg\nimport hyperchamber as hc\nimport tensorflow as tf\nimport os\nfrom hypergan.gan_component import ValidationException\n\nfrom tests.inputs.image_loader_test import fixture_path\nfrom tests.mocks import MockDiscriminator, mock_gan\nimport shutil\n\nfrom hypergan.multi_component import MultiComponent\nfrom hypergan.losses.supervised_loss import SupervisedLoss\n\nclass CliTest(tf.test.TestCase):\n    def test_cli(self):\n        with self.test_session():\n            gan = mock_gan()\n            args = {\n            }\n            cli = hg.CLI(gan, args)\n            self.assertEqual(cli.gan, gan)\n\n    def test_run(self):\n        with self.test_session():\n            gan = mock_gan()\n            args = hc.Config({""size"": ""1""})\n            cli = hg.CLI(gan, args)\n            cli.run()\n            self.assertEqual(cli.gan, gan)\n\n    def test_step(self):\n        with self.test_session():\n            gan = mock_gan()\n            args = hc.Config({""size"": ""1"", ""steps"": 1, ""method"": ""train"", ""save_every"": -1})\n            cli = hg.CLI(gan, args)\n            cli.step()\n            self.assertEqual(cli.gan, gan)\n\n    def test_sample(self):\n        with self.test_session():\n            gan = mock_gan()\n            args = hc.Config({""size"": ""1"", ""steps"": 1, ""method"": ""train"", ""save_every"": -1})\n            cli = hg.CLI(gan, args)\n            cli.sample(\'/tmp/test-sample.png\')\n            self.assertEqual(cli.gan, gan)\n\n\n    def test_train(self):\n        with self.test_session():\n            gan = mock_gan()\n            args = hc.Config({""size"": ""1"", ""steps"": 1, ""method"": ""train"", ""save_every"": -1})\n            cli = hg.CLI(gan, args)\n            cli.train()\n            self.assertEqual(cli.gan, gan)\n\n    def test_adds_supervised_loss(self):\n        with self.test_session():\n            gan = mock_gan(y=2)\n            args = hc.Config({""size"": ""1"", ""steps"": 1, ""method"": ""train"", ""save_every"": -1, ""classloss"": True})\n            cli = hg.CLI(gan, args)\n            cli.add_supervised_loss()\n            self.assertEqual(type(cli.gan.loss), MultiComponent)\n            self.assertEqual(type(cli.gan.loss.components[0]), SupervisedLoss)\n\n    def test_new(self):\n        with self.test_session():\n            try: \n                os.remove(\'test.json\')\n            except Exception:\n                pass\n            gan = mock_gan()\n            args = hc.Config({""size"": ""1"", ""steps"": 1, ""method"": ""train"", ""directory"": ""test""})\n            cli = hg.CLI(gan, args)\n            cli.new()\n            self.assertTrue(os.path.isfile(\'test.json\'))\n\n    def test_safe_new(self):\n        with self.test_session():\n            try: \n                os.remove(\'test.json\')\n            except Exception:\n                pass\n            gan = mock_gan()\n            args = hc.Config({""size"": ""1"", ""steps"": 1, ""method"": ""train"", ""directory"": ""test""})\n            cli = hg.CLI(gan, args)\n            cli.new()\n            with self.assertRaises(ValidationException):\n                cli.new()\n\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/configuration_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport hypergan as hg\nfrom hypergan.discriminators.pyramid_discriminator import PyramidDiscriminator\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.ops import TensorflowOps\n\nfrom unittest.mock import MagicMock\n\nclass ConfigurationTest(tf.test.TestCase):\n    def test_constructor(self):\n        with self.test_session():\n            default = hg.Configuration.default()\n            self.assertNotEqual(default.trainer, None)\n            self.assertNotEqual(default.discriminator, None)\n            self.assertNotEqual(default.loss, None)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/gan_component_test.py,4,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.ops import TensorflowOps\nfrom hypergan.gan_component import GANComponent\nfrom hypergan.multi_component import MultiComponent\nfrom tests.mocks import mock_gan\nimport hypergan as hg\n\nfrom unittest.mock import MagicMock\n\ngan = mock_gan()\nclass MockComponent(GANComponent):\n    def create(self):\n        pass\n\ncomponent = MockComponent(gan=gan, config={\'test\':True})\nclass GanComponentTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            self.assertEqual(component.config.test, True)\n\n    def test_validate(self):\n        with self.test_session():\n            self.assertEqual(component.validate(), [])\n\n    def test_gan(self):\n        with self.test_session():\n            self.assertEqual(component.gan, gan)\n\n    def test_ops(self):\n        with self.test_session():\n            self.assertEqual(type(component.ops), TensorflowOps)\n\n    def test_missing_gan(self):\n        with self.assertRaises(ValidationException):\n            GANComponent(config={}, gan=None)\n\n    def test_proxy_methods(self):\n        component = MockComponent(gan=gan, config={\'test\':True})\n        with self.test_session():\n            self.assertEqual(component.weights(), [])\n            self.assertEqual(component.biases(), [])\n            self.assertEqual(component.variables(), [])\n\n    def test_relation_layer(self):\n        component = MockComponent(gan=gan, config={\'test\':True})\n        with self.test_session():\n            constant = tf.zeros([1, 2, 2, 1])\n            split = component.split_by_width_height(constant)\n            self.assertEqual(len(split), 4)\n            permute = component.permute(split, 2)\n            self.assertEqual(len(permute), 12)\n\n            constant = tf.zeros([1, 4, 4, 1])\n            split = component.split_by_width_height(constant)\n            self.assertEqual(len(split), 16)\n            permute = component.permute(split, 2)\n            self.assertEqual(len(permute), 240)\n\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/gan_test.py,2,"b'import hypergan as hg\nimport tensorflow as tf\nfrom tests.mocks import MockDiscriminator, mock_gan\n\nclass GanTest(tf.test.TestCase):\n    def test_hg_gan(self):\n        self.assertIs(type(mock_gan()), hg.gans.standard_gan.StandardGAN)\n\n    def test_can_create_default(self):\n        config = hg.Configuration.load(\'default.json\')\n        self.assertIs(type(mock_gan(config=config)), hg.gans.standard_gan.StandardGAN)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/mocks.py,3,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport hypergan as hg\n\nfrom hypergan.gan_component import GANComponent\n\ndef mock_gan(batch_size=1, y=1, config=None):\n    mock_config = config or hc.Config({\n        ""latent"": {\n            ""class"": ""function:hypergan.distributions.uniform_distribution.UniformDistribution"",\n            ""max"": 1,\n            ""min"": -1,\n            ""projections"": [\n              ""function:hypergan.distributions.uniform_distribution.identity""\n            ],\n            ""z"": 128\n\n         },\n        ""generator"": {\n            ""class"": ""class:hypergan.discriminators.configurable_discriminator.ConfigurableDiscriminator"",\n            ""defaults"": {\n              ""activation"": ""tanh"",\n              ""initializer"": ""he_normal""\n            },\n            ""layers"": [\n              ""linear 32*32*1 activation=null""\n            ]\n\n        },\n        ""discriminator"": {\n          ""class"": ""class:hypergan.discriminators.configurable_discriminator.ConfigurableDiscriminator"",\n          ""defaults"":{\n            ""activation"": ""tanh"",\n            ""initializer"": ""he_normal""\n          },\n          ""layers"":[\n            ""linear 1 activation=null""\n          ]\n\n        },\n        ""loss"": {\n          ""class"": ""function:hypergan.losses.ragan_loss.RaganLoss"",\n          ""reduce"": ""reduce_mean""\n        },\n        ""trainer"": {\n          ""class"": ""function:hypergan.trainers.alternating_trainer.AlternatingTrainer"",\n          ""optimizer"": {\n\n            ""class"": ""function:tensorflow.python.training.adam.AdamOptimizer"",\n            ""learn_rate"": 1e-4\n\n          }\n\n        }\n    })\n    return hg.GAN(config=mock_config, inputs=MockInput(batch_size=batch_size, y=y))\n\nclass MockDiscriminator(GANComponent):\n    def create(self):\n        self.sample = tf.constant(0, shape=[2,1], dtype=tf.float32)\n        return self.sample\n\nclass MockInput:\n    def __init__(self, batch_size=2, y=1):\n        self.x= tf.constant(10., shape=[batch_size,32,32,1], dtype=tf.float32)\n        self.y= tf.constant(1., shape=[batch_size, y], dtype=tf.float32)\n        self.sample = [self.x, self.y]\n\n'"
tests/multi_component_test.py,6,"b'import tensorflow as tf\nfrom hypergan.multi_component import MultiComponent\nfrom tests.mocks import MockDiscriminator, mock_gan\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.losses.supervised_loss import SupervisedLoss\nfrom hypergan.losses.standard_loss import StandardLoss\nimport hypergan as hg\n\ndef encoder(gan):\n    config = {\n            ""projections"": [\'identity\', \'identity\'],\n            ""z"": 2,\n            ""min"": 0,\n            ""max"": 1\n    }\n    return UniformDistribution(gan, config)\n\nloss_config = {\n        ""reduce"": ""reduce_mean""\n}\n\nclass MockLoss:\n    def __init__(self, gan, sample=None):\n        self.gan = gan\n        self.sample = sample\n\n    def proxy(self):\n        self.proxy_called = True\n\nclass MultiComponentTest(tf.test.TestCase):\n    def test_sample(self):\n        with self.test_session():\n            gan = mock_gan()\n            mock_sample = tf.constant(1., shape=[1,1])\n            multi = MultiComponent(combine=\'concat\',\n                components=[\n                    MockLoss(gan, sample=mock_sample),\n                    MockLoss(gan, sample=mock_sample)\n            ])\n\n            gan.encoder = multi\n            self.assertEqual(gan.ops.shape(multi.sample), [1,2])\n\n    def test_proxy_methods(self):\n        with self.test_session():\n            gan = mock_gan()\n            mock_sample = tf.constant(1., shape=[1,1])\n            multi = MultiComponent(combine=\'concat\',\n                components=[\n                    MockLoss(gan, sample=mock_sample),\n                    MockLoss(gan, sample=mock_sample)\n            ])\n\n            multi.proxy()\n            self.assertEqual(multi.proxy_called, [True, True])\n\n\n    def test_sample_loss(self):\n        with self.test_session():\n            gan = mock_gan()\n            ops = gan.ops\n            mock_sample = tf.constant(1., shape=[1])\n            multi = MultiComponent(combine=\'add\',\n                components=[\n                    MockLoss(gan, sample=[mock_sample, None]),\n                    MockLoss(gan, sample=[mock_sample, mock_sample])\n            ])\n            self.assertEqual(len(multi.sample), 2)\n            self.assertEqual(ops.shape(multi.sample[0]), [1])\n            self.assertEqual(ops.shape(multi.sample[1]), [1])\n\n    def test_combine_dict(self):\n        with self.test_session():\n            gan = mock_gan()\n            ops = gan.ops\n            mock_sample = tf.constant(1., shape=[1])\n            multi = MultiComponent(combine=\'add\',\n                components=[\n                    MockLoss(gan, sample={""a"":""b""}),\n                    MockLoss(gan, sample={""b"":""c""})\n            ])\n            self.assertEqual(len(multi.sample), 2)\n            self.assertEqual(multi.sample[\'a\'], \'b\')\n            self.assertEqual(multi.sample[\'b\'], \'c\')\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/skip_connections_test.py,12,"b'import hypergan as hg\nimport tensorflow as tf\nfrom hypergan.skip_connections import SkipConnections\n\nclass SkipConnectionsTest(tf.test.TestCase):\n    def test_get_none(self):\n        sc = SkipConnections()\n        self.assertIsNone(sc.get(\'none\'))\n\n    def test_get(self):\n        sc = SkipConnections()\n        a = tf.zeros([1,2,3])\n        b = tf.zeros([3,2,1])\n\n        sc.set(\'layer_filter\', a)\n        sc.set(\'layer_filter\', b)\n        self.assertEqual(a, sc.get(\'layer_filter\', a.get_shape()))\n        self.assertEqual(b, sc.get(\'layer_filter\', b.get_shape()))\n\n    def test_get_closest(self):\n        sc = SkipConnections()\n        b = tf.zeros([1,2,2])\n        a = tf.zeros([1,4,4])\n\n        sc.set(\'layer_filter\', b)\n        sc.set(\'layer_filter\', a)\n        self.assertEqual(a, sc.get_closest(\'layer_filter\', a.get_shape()))\n        self.assertEqual(b, sc.get_closest(\'layer_filter\', b.get_shape()))\n        self.assertEqual(a, sc.get_closest(\'layer_filter\', [1,3,3]))\n        self.assertEqual(b, sc.get_closest(\'layer_filter\', [1,1,1]))\n        self.assertEqual(None, sc.get_closest(\'layer_filter\', [1,5,5]))\n\n\n    def test_array(self):\n        sc = SkipConnections()\n        a = tf.zeros([1,2,3])\n        b = tf.zeros([3,2,1])\n\n        self.assertEqual([], sc.get_array(\'layer_filter\', a.get_shape()))\n        sc.set(\'layer_filter\', a)\n        self.assertEqual([a], sc.get_array(\'layer_filter\', a.get_shape()))\n        sc.set(\'layer_filter\', a)\n        self.assertEqual([a, a], sc.get_array(\'layer_filter\', a.get_shape()))\n\n    def test_get_shapes(self):\n        sc = SkipConnections()\n        a = tf.zeros([1,2,3])\n        b = tf.zeros([3,2,1])\n\n        sc.set(\'layer_filter\', a)\n        sc.set(\'layer_filter\', b)\n        shapes = sc.get_shapes(\'layer_filter\')\n        print(""SHAPES"", shapes)\n        self.assertEqual(len(shapes), 2)\n        self.assertEqual(shapes[0], [1,2,3])\n        self.assertEqual(shapes[1], [3,2,1])\n        self.assertEqual(sc.get_shapes(\'non-existant\'), None)\n\n    def test_clear(self):\n        sc = SkipConnections()\n        a = tf.zeros([1,2,3])\n        b = tf.zeros([3,2,1])\n\n        sc.set(\'layer_filter\', a)\n        sc.set(\'layer_filter\', b)\n        sc.clear(\'layer_filter\', shape=a.get_shape())\n        print(""C?LAEAR"", sc.connections)\n        self.assertEqual(None, sc.get(\'layer_filter\', a.get_shape()))\n        self.assertEqual([], sc.get_array(\'layer_filter\', a.get_shape()))\n        self.assertEqual(b, sc.get(\'layer_filter\', b.get_shape()))\n\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tools/preprocess-directory.py,4,"b'\nimport tensorflow as tf\nimport shared.predata_loader\nimport shared.inception_loader\nimport shared.vggnet_loader\nimport argparse\nfrom tensorflow.python.framework import ops\n\nparser = argparse.ArgumentParser(description=\'This script runs inception against a directory and saves to filename.preprocessed\')\n\nparser.add_argument(\'--channels\', type=int, default=3)\nparser.add_argument(\'--directory\', type=str)\nparser.add_argument(\'--crop\', type=bool, default=True)\n\nparser.add_argument(\'--width\', type=int, default=64)\nparser.add_argument(\'--height\', type=int, default=64)\nparser.add_argument(\'--batch\', type=int, default=64)\nparser.add_argument(\'--format\', type=str, default=\'png\')\nparser.add_argument(\'--save_every\', type=int, default=0)\nparser.add_argument(\'--device\', type=str, default=""/cpu:0"")\n\nparser.add_argument(\'--dataset\', type=str, default=""inception"")\nparser.add_argument(\'--layer\', type=str, default=""pool_3:0"")\n\nargs = parser.parse_args()\n\n\nimport numpy as np\ndef save(filename, output):\n    fname = filename.decode(\'ascii\') + "".preprocess""\n    #print(""Saving "", fname, np.min(output), np.max(output), np.mean(output), np.std(output), np.shape(output))\n    output.tofile(fname)\n\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\nchannels = args.channels\ncrop = args.crop\nwidth = args.width\nheight = args.height\nbatch_size = 1\nwith tf.device(""/cpu:0""):\n    train_x,train_y, filename_t, num_labels,examples_per_epoch = shared.predata_loader.labelled_image_tensors_from_directory(args.directory,batch_size, channels=channels, format=args.format,crop=crop,width=width,height=height)\n\ndataset = args.dataset\n\nif(dataset == \'inception\'):\n    shared.inception_loader.maybe_download_and_extract()\n    output_layer_t = shared.inception_loader.create_graph(train_x, args.layer)\nelif(dataset == \'vgg\'):\n    shared.vggnet_loader.maybe_download_and_extract()\n    with tf.device(""/gpu:0""):\n        output_layer_t = shared.vggnet_loader.create_graph(train_x, args.layer)\nelse:\n    raise ""Unknown dataset ""+dataset;\n\ntf.train.start_queue_runners(sess=sess)\n\nfor i in range(examples_per_epoch):\n    output, filename = sess.run([output_layer_t, filename_t])\n    for f,o in zip(filename, output):\n        #print(""O IS"", o.shape)\n        save(f,o)\n'"
examples/experimental/2d-sequence.py,13,"b'import argparse\nimport os\nimport math\n\nimport uuid\nimport tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nfrom hypergan.generators import *\nfrom hypergan.search.random_search import RandomSearch\nfrom hypergan.viewer import GlobalViewer\nfrom common import *\n\narg_parser = ArgumentParser(""Test your gan vs a known distribution"", require_directory=False)\narg_parser.parser.add_argument(\'--distribution\', \'-t\', type=str, default=\'circle\', help=\'what distribution to test, options are circle, modes\')\narg_parser.parser.add_argument(\'--sequence_length\', \'-n\', type=int, default=2, help=\'how many steps to look forward\')\nargs = arg_parser.parse_args()\n\nconfig = lookup_config(args)\nif args.action == \'search\':\n    config = RandomSearch({}).random_config()\n\nclass Sequence2DGenerator(BaseGenerator):\n    def create(self):\n        gan = self.gan\n        config = self.config\n        ops = self.ops\n        end_features = config.end_features or 2*args.sequence_length\n\n        ops.describe(\'custom_generator\')\n\n        net = gan.encoder.sample\n        for i in range(2):\n            net = ops.linear(net, 32)\n            net = ops.lookup(\'bipolar\')(net)\n        net = ops.linear(net, end_features)\n        print(""-- net is "", net)\n        self.sample = net\n        return net\n\nclass Sequence2DDiscriminator(BaseGenerator):\n    def __init__(self, gan, config, g=None, x=None, name=None, input=None, reuse=None, features=[], skip_connections=[]):\n        self.x = x\n        self.g = g\n\n        GANComponent.__init__(self, gan, config, name=name, reuse=reuse)\n    def create(self):\n        gan = self.gan\n        if self.x is None:\n            self.x = gan.inputs.x\n        if self.g is None:\n            self.g = gan.generator.sample\n        net = tf.concat(axis=0, values=[self.x,self.g])\n        net = self.build(net)\n        self.sample = net\n        return net\n\n    def build(self, net):\n        gan = self.gan\n        config = self.config\n        ops = self.ops\n        layers=2\n\n        end_features = 1\n\n        for i in range(layers):\n            net = ops.linear(net, 32)\n            net = ops.lookup(\'bipolar\')(net)\n        net = ops.linear(net, 1)\n        self.sample = net\n\n        return net\n    def reuse(self, net):\n        self.ops.reuse()\n        net = self.build(net)\n        self.ops.stop_reuse()\n        return net \n\nclass Sequence2DInputDistribution:\n    def __init__(self, args):\n        self.current_step = tf.Variable(0)\n\n        with tf.device(args.device):\n            def circle(step, length=180):\n                s = tf.cast(step, tf.float32) / float(length) * np.pi\n                x = tf.reshape(tf.sin(s), [1])\n                y = tf.reshape(tf.cos(s), [1])\n                return tf.concat([x,y], axis=-1)\n\n            if args.distribution == \'circle\':\n                batch = []\n                batch_offset = 39\n                for b in range(args.batch_size):\n                    result = []\n                    for seq in range(args.sequence_length):\n                        result += [circle(self.current_step+seq+b*batch_offset)]\n                    batch.append([tf.concat(result, axis=-1)])\n                x = tf.concat(batch, axis=0)\n\n            elif args.distribution == \'static-point\':\n                x = tf.ones([args.batch_size, gan.config.sequence_length*2])\n\n            self.x = x\n\nclass Sequence2DSampler(BaseSampler):\n    def __init__(self, gan):\n        self.sample_count = 0\n        self.gan = gan\n        self.enc = gan.session.run(gan.encoder.sample)\n    def sample(self, filename, save_samples):\n        gan = self.gan\n        generator = gan.generator.sample\n\n        sess = gan.session\n        config = gan.config\n\n        x_v, sample = sess.run([gan.inputs.x, generator], {gan.inputs.current_step: self.sample_count, gan.encoder.sample: self.enc})\n        self.sample_count+=1\n\n        def diff(xs):\n            r =[]\n            seq = args.sequence_length\n            for i in range(len(xs)-1):\n                if (i + 1) % seq == 0:\n                    r += [0]\n                else:\n                    r += [(xs[1+i]-xs[i])[0]]\n            r += [0]\n            return r\n\n        X, Y = np.split(np.reshape(x_v,[-1,2]), len(np.reshape(x_v,[-1,2])[0]), axis=1)\n\n        V = diff(Y)\n        U = diff(X)\n\n        mpl.style.use(\'classic\')\n        plt.clf()\n\n        #fig = plt.figure(figsize=(3,3))\n        fig = plt.figure()\n        plt.scatter(*zip(*np.reshape(x_v,[-1,2])), c=\'b\')\n        plt.scatter(*zip(*np.reshape(sample,[-1,2])), c=\'r\')\n        q = plt.quiver(X,Y,U,V, color=\'b\', units=\'x\')\n\n        gX, gY = np.split(np.reshape(sample,[-1,2]), len(np.reshape(x_v,[-1,2])[0]), axis=1)\n\n        gV = diff(gY)\n        gU = diff(gX)\n        q = plt.quiver(gX,gY,gU,gV, color=\'r\', units=\'x\')\n        #plt.xlim([-2, 2])\n        #plt.ylim([-2, 2])\n        #plt.ylabel(""z"")\n        fig.canvas.draw()\n        data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=\'\')\n        data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n        #plt.savefig(filename)\n        self.plot(data, filename, save_samples)\n        return [{\'image\': filename, \'label\': \'2d\'}]\n\n\n\ndef train(config, args):\n    title = ""[hypergan] 2d-test "" + args.config\n    GlobalViewer.title = title\n    GlobalViewer.enabled = args.viewer\n\n    with tf.device(args.device):\n        config.generator[""class""]=""class:__main__.Sequence2DGenerator""\n        config.discriminator[""class""]=""class:__main__.Sequence2DDiscriminator""\n        gan = hg.GAN(config, inputs = Sequence2DInputDistribution(args))\n\n        sampler = Sequence2DSampler(gan)\n\n        tf.train.start_queue_runners(sess=gan.session)\n        samples = 0\n        steps = args.steps\n        sampler.sample(""samples/000000.png"", args.save_samples)\n\n        #metrics = [accuracy_x_to_g, accuracy_g_to_x]\n        #sum_metrics = [0 for metric in metrics]\n        for i in range(steps):\n            gan.step({gan.inputs.current_step: i})\n\n            if args.viewer and i % args.sample_every == 0:\n                samples += 1\n                print(""Sampling ""+str(samples), args.save_samples)\n                sample_file=""samples/%06d.png"" % (samples)\n                sampler.sample(sample_file, args.save_samples)\n\n            #if i > steps * 9.0/10:\n            #    for k, metric in enumerate(gan.session.run(metrics)):\n            #        sum_metrics[k] += metric \n            #if i % 300 == 0:\n            #    for k, metric in enumerate(gan.metrics.keys()):\n            #        metric_value = gan.session.run(gan.metrics[metric])\n            #        print(""--"", metric,  metric_value)\n            #        if math.isnan(metric_value) or math.isinf(metric_value):\n            #            print(""Breaking due to invalid metric"")\n            #            return None\n\n        tf.reset_default_graph()\n        gan.session.close()\n\n    return {}#sum_metrics\n\nif args.action == \'train\':\n    metrics = train(config, args)\n    print(""Resulting metrics:"", metrics)\nelse:\n    print(""Unknown action: ""+args.action)\n\n'"
examples/experimental/alignment.py,3,"b'import argparse\nimport os\nimport uuid\nimport random\nimport sys\nimport tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\nfrom hypergan.generators import *\nfrom hypergan.gans.base_gan import BaseGAN\nfrom hypergan.gans.standard_gan import StandardGAN\nfrom hypergan.samplers.aligned_sampler import AlignedSampler\nfrom hypergan.viewer import GlobalViewer\nfrom hypergan.gans.aligned_gan import AlignedGAN\nfrom hypergan.search.aligned_random_search import AlignedRandomSearch\nfrom common import *\n\nfrom hypergan.samplers.random_walk_sampler import RandomWalkSampler\n\narg_parser = ArgumentParser(""Align two unaligned distributions.  One is black and white of image."")\narg_parser.add_image_arguments()\nargs = arg_parser.parse_args()\n\nwidth, height, channels = parse_size(args.size)\n\nconfig = lookup_config(args)\n\nsave_file = ""save/model.ckpt""\n\nif args.action == \'search\':\n    config = AlignedRandomSearch({}).random_config()\n\n    if args.config_list is not None:\n        config = random_config_from_list(args.config_list)\n        random_config = AlignedRandomSearch({}).random_config()\n\n        config[""generator""]=random_config[""generator""]\n        config[""discriminator""]=random_config[""discriminator""]\n        print(""config list chosen"", config_file)\n\nclass TwoImageInput():\n    def create(self, args):\n        self.inputsa = hg.inputs.image_loader.ImageLoader(args.batch_size)\n        self.inputsa.create(args.directory,\n                      channels=channels, \n                      format=args.format,\n                      crop=args.crop,\n                      width=width,\n                      height=height,\n                      resize=True)\n\n\n        xa = self.inputsa.x\n        xb = tf.tile(tf.image.rgb_to_grayscale(xa), [1,1,1,3])\n\n        self.xa = xa\n        self.x = xa #TODO remove\n        self.xb = xb\n\ndef setup_gan(config, inputs, args):\n    gan = AlignedGAN(config=config, inputs=inputs)\n    gan.create()\n\n    if(args.action != \'search\' and os.path.isfile(save_file+"".meta"")):\n        gan.load(save_file)\n\n    tf.train.start_queue_runners(sess=gan.session)\n\n    title = ""[hypergan] align-test "" + args.config\n    GlobalViewer.title = title\n    GlobalViewer.enabled = args.viewer\n\n    return gan\n\ndef train(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n\n    accuracies = [accuracy(gan.inputs.xb, gan.cycb),accuracy(gan.inputs.xa, gan.cyca)]\n    diversities = [batch_diversity(gan.xab), batch_diversity(gan.xba)]\n\n    sampler = AlignedSampler(gan)\n\n    sum_metrics = { \n            ""accuracy"": [0 for metric in accuracies], \n            ""diversity"": [0 for metric in diversities] \n    }\n\n    for i in range(args.steps):\n        if i % args.sample_every == 0:\n            print(""Sampling ""+str(i))\n            sample_file = ""samples/""+str(i)+"".png""\n            sampler.sample(sample_file, args.save_samples)\n        gan.step()\n\n        if args.action == \'train\' and i % args.save_every == 0 and i > 0:\n            print(""saving "" + save_file)\n            gan.save(save_file)\n\n        if i % 10 == 0 and i != 0: \n            if i > 20:\n                diversities_v = gan.session.run([v for v in diversities])\n                accuracies_v = gan.session.run([v for v in accuracies])\n                for k, v in enumerate(diversities_v):\n                    if(i > args.steps * 9.0/10):\n                        sum_metrics[""diversity""][k]+=v\n                    if(np.abs(v) < 20000):\n                        print(""break from diversity"")\n                        return\n\n                for k, v in enumerate(accuracies_v):\n                    if(i > args.steps * 9.0/10):\n                        sum_metrics[""accuracy""][k]+=v\n                    if(np.abs(v) > 800):\n                        print(""break from accuracy"")\n                        return\n \n    tf.reset_default_graph()\n    gan.session.close()\n    return sum_metrics\n\ndef search(config, inputs, args):\n    config_name=""alignment-""+str(uuid.uuid4()).split(""-"")[0]\n    config_filename = config_name+\'.json\'\n    print(""Saving config to "", config_filename)\n\n    hc.Selector().save(config_filename, config)\n    metrics = train(config, inputs, args)\n\n    with open(args.search_output, ""a"") as myfile:\n        accuracies = [""%.2f"" % sum for sum in (metrics[""accuracy""] or [])]\n        diversities = [""%.2f"" % sum for sum in (metrics[""diversity""] or [])]\n\n        myfile.write(config_name+"",""+"","".join(accuracies)+"","".join(diversities)+""\\n"")\n\ndef sample(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    sampler = lookup_sampler(args.sampler or RandomWalkSampler)(gan)\n    for i in range(args.steps):\n        sample_file = ""samples/""+str(i)+"".png""\n        sampler.sample(sample_file, args.save_samples)\n\ninputs = TwoImageInput()\ninputs.create(args)\n\nif args.action == \'train\':\n    metrics = train(config, inputs, args)\n    accuracies = [""%.2f"" % sum for sum in (metrics[""accuracy""] or [])]\n    diversities = [""%.2f"" % sum for sum in (metrics[""diversity""] or [])]\n    print(""Training complete.  Accuracy"", accuracies, ""Diversities"", diversities)\nelif args.action == \'sample\':\n    sample(config, inputs, args)\nelif args.action == \'search\':\n    search(config, inputs, args)\nelse:\n    print(""Unknown action: ""+args.action)\n\n'"
examples/experimental/autoencode.py,1,"b'import argparse\nimport os\nimport uuid\nimport random\nimport sys\nimport tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\nimport math\nfrom hypergan.generators import *\nfrom hypergan.gans.base_gan import BaseGAN\nfrom hypergan.gans.standard_gan import StandardGAN\nfrom hypergan.samplers.aligned_sampler import AlignedSampler\nfrom hypergan.viewer import GlobalViewer\nfrom hypergan.search.alphagan_random_search import AlphaGANRandomSearch\n\nfrom examples.common import *\n\narg_parser = ArgumentParser(""Autoencode an image with AlphaGAN"")\narg_parser.add_image_arguments()\nargs = arg_parser.parse_args()\n\nwidth, height, channels = parse_size(args.size)\n\nconfig = lookup_config(args)\nif args.action == \'search\':\n    random_config = AlphaGANRandomSearch({}).random_config()\n    if args.config_list is not None:\n        config = random_config_from_list(args.config_list)\n\n        config[""generator""]=random_config[""generator""]\n        config[""g_encoder""]=random_config[""g_encoder""]\n        config[""discriminator""]=random_config[""discriminator""]\n        config[""z_discriminator""]=random_config[""z_discriminator""]\n        config[""cycloss_lambda""]=random_config[""cycloss_lambda""]\n    else:\n        config = random_config\n\nconfig[""class""]=""class:hypergan.gans.alpha_gan.AlphaGAN"" # TODO\n\nsave_file = ""save/model.ckpt""\ninputs = hg.inputs.image_loader.ImageLoader(args.batch_size)\ninputs.create(args.directory,\n              channels=channels, \n              format=args.format,\n              crop=args.crop,\n              width=width,\n              height=height,\n              resize=True)\n\nsave_file = ""save/model.ckpt""\n\ndef setup_gan(config, inputs, args):\n    gan = hg.GAN(config=config, inputs=inputs)\n    gan.create()\n\n    if(args.action != \'search\' and os.path.isfile(save_file+"".meta"")):\n        gan.load(save_file)\n\n \n    tf.train.start_queue_runners(sess=gan.session)\n    config_name = args.config\n    title = ""[hypergan] autoencode "" + config_name\n    GlobalViewer.title = title\n    GlobalViewer.enabled = args.viewer\n\n    return gan\n\ndef train(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    sampler = lookup_sampler(args.sampler or \'autoencode\')(gan)\n\n    accuracy_t = batch_accuracy(gan.inputs.x, gan.generator.sample)\n    diversity_t = batch_diversity(gan.uniform_sample)\n    metrics = [accuracy_t, diversity_t]\n    sum_metrics = [0 for metric in metrics]\n    samples = 0\n\n    for i in range(args.steps):\n        gan.step()\n\n        if i == (args.steps-1):\n            for k, metric in enumerate(gan.session.run(metrics)):\n                print(""Metric ""+str(k)+"" ""+str(metric))\n                sum_metrics[k] += metric \n            \n        if i % args.sample_every == 0:\n            print(""sampling ""+str(i))\n            sample_file=""samples/%06d.png"" % (samples)\n            samples += 1\n            sampler.sample(sample_file, args.save_samples)\n\n        if args.action == \'train\' and i % args.save_every == 0 and i > 0:\n            print(""saving "" + save_file)\n            gan.save(save_file)\n\n        if i % 100 and i > 500:\n            losses = gan.session.run([loss[1] for loss in gan.trainer.losses])\n            accuracy, diversity = gan.session.run([\n                accuracy_t, \n                diversity_t\n            ])\n\n            has_failed = any([math.isnan(loss) for loss in losses]) or \\\n                    accuracy > 1000 or diversity < 1000\n\n            if has_failed:\n                sum_metrics = [-1,-1]\n                print(""breaking from failure detection"")\n                break\n\n    return sum_metrics\n\ndef sample(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    sampler = lookup_sampler(args.sampler or \'random_walk\')(gan)\n    for i in range(args.steps):\n        sample_file = ""samples/""+str(i)+"".png""\n        sampler.sample(sample_file, False)\n\ndef search(config, inputs, args):\n    metrics = train(config, inputs, args)\n\n    config_filename = ""autoencode-""+str(uuid.uuid4())+\'.json\'\n    hc.Selector().save(config_filename, config)\n    with open(args.search_output, ""a"") as myfile:\n        myfile.write(config_filename+"",""+"","".join([str(x) for x in metrics])+""\\n"")\n\nif args.action == \'train\':\n    metrics = train(config, inputs, args)\n    print(""Resulting metrics:"", metrics)\nelif args.action == \'sample\':\n    sample(config, inputs, args)\nelif args.action == \'search\':\n    search(config, inputs, args)\nelse:\n    print(""Unknown action: ""+args.action)\n'"
examples/experimental/chargan.py,4,"b'import argparse\nimport os\nimport string\nimport uuid\nimport tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport matplotlib.pyplot as plt\nfrom hypergan.generators import *\nfrom examples.common import *\nimport numpy as np\nfrom examples.common import *\nfrom hypergan.search.alphagan_random_search import AlphaGANRandomSearch\nfrom hypergan.gans.alpha_gan import AlphaGAN\n\narg_parser = ArgumentParser(""Learn from a text file"", require_directory=False)\narg_parser.parser.add_argument(\'--one_hot\', action=\'store_true\', help=\'Use character one-hot encodings.\')\nargs = arg_parser.parse_args()\n\n\nconfig = lookup_config(args)\nif args.action == \'search\':\n    config = AlphaGANRandomSearch({}).random_config()\n\ndef search(config, args):\n    metrics = train(config, args)\n    config_filename = ""chargan-""+str(uuid.uuid4())+\'.json\'\n    hc.Selector().save(config_filename, config)\n\n    with open(args.search_output, ""a"") as myfile:\n        myfile.write(config_filename+"",""+"","".join([str(x) for x in metric_sum])+""\\n"")\n\n\nsave_file = ""save/model.ckpt""\n\nconfig = lookup_config(args)\n\ninputs = TextInput(config, args.batch_size, one_hot=args.one_hot)\n\nif args.action == \'search\':\n    random_config = AlphaGANRandomSearch({}).random_config()\n\n    if args.config_list is not None:\n        config = random_config_from_list(args.config_list)\n\n        config[""generator""]=random_config[""generator""]\n        config[""discriminator""]=random_config[""discriminator""]\n        # TODO Other search terms?\n    else:\n        config = random_config\n\n\ndef setup_gan(config, inputs, args):\n    gan = hg.GAN(config, inputs=inputs)\n\n    gan.create()\n\n    if(args.action != \'search\' and os.path.isfile(save_file+"".meta"")):\n        gan.load(save_file)\n\n    with tf.device(args.device):\n        with gan.session.as_default():\n            inputs.table.init.run()\n    tf.train.start_queue_runners(sess=gan.session)\n\n    return gan\n\ndef sample(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n\ndef search(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n\ndef train(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n\n    trainers = []\n\n    with tf.device(args.device):\n        s = [int(g) for g in gan.generator.sample.get_shape()]\n        x_0 = gan.session.run(gan.inputs.x)\n        z_0 = gan.session.run(gan.latent.z)\n\n        ax_sum = 0\n        ag_sum = 0\n        diversity = 0.00001\n        dlog = 0\n        last_i = 0\n        samples = 0\n\n        vocabulary = inputs.get_vocabulary()\n\n        for i in range(args.steps):\n            gan.step()\n\n            if args.action == \'train\' and i % args.save_every == 0 and i > 0:\n                print(""saving "" + save_file)\n                gan.save(save_file)\n\n\n            if i % args.sample_every == 0:\n                g, x_val = gan.session.run([gan.generator.sample, gan.inputs.x], {gan.latent.z: z_0})\n                bs = np.shape(x_val)[0]\n                samples+=1\n                print(""X: ""+inputs.sample_output(x_val[0]))\n                print(""G:"")\n                for j, g0 in enumerate(g):\n                    if j > 4:\n                        break\n\n                    print(inputs.sample_output(g0))\n\n        if args.config is None:\n            with open(""sequence-results-10k.csv"", ""a"") as myfile:\n                myfile.write(config_name+"",""+str(ax_sum)+"",""+str(ag_sum)+"",""+ str(ax_sum+ag_sum)+"",""+str(ax_sum*ag_sum)+"",""+str(dlog)+"",""+str(diversity)+"",""+str(ax_sum*ag_sum*(1/diversity))+"",""+str(last_i)+""\\n"")\n        tf.reset_default_graph()\n        gan.session.close()\n\nif args.action == \'train\':\n    metrics = train(config, inputs, args)\n    print(""Resulting metrics:"", metrics)\nelif args.action == \'sample\':\n    sample(config, inputs, args)\nelif args.action == \'search\':\n    search(config, inputs, args)\nelse:\n    print(""Unknown action: ""+args.action)\n\n'"
examples/experimental/next-frame-wip.py,37,"b'import os\nimport uuid\nimport random\nimport tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\nimport glob\nimport time\nimport re\nfrom hypergan.viewer import GlobalViewer\nfrom hypergan.samplers.base_sampler import BaseSampler\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom hypergan.samplers.random_walk_sampler import RandomWalkSampler\nfrom hypergan.samplers.debug_sampler import DebugSampler\nfrom hypergan.search.alphagan_random_search import AlphaGANRandomSearch\nfrom hypergan.gans.base_gan import BaseGAN\nfrom common import *\n\nimport copy\n\nfrom hypergan.gans.alpha_gan import AlphaGAN\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom hypergan.gans.base_gan import BaseGAN\n\nfrom hypergan.discriminators.fully_connected_discriminator import FullyConnectedDiscriminator\nfrom hypergan.encoders.uniform_encoder import UniformEncoder\nfrom hypergan.trainers.multi_step_trainer import MultiStepTrainer\nfrom hypergan.trainers.multi_trainer_trainer import MultiTrainerTrainer\nfrom hypergan.trainers.consensus_trainer import ConsensusTrainer\n\n\narg_parser = ArgumentParser(""render next frame"")\nparser = arg_parser.add_image_arguments()\nparser.add_argument(\'--frames\', type=int, default=4, help=\'Number of frames to embed.\')\nparser.add_argument(\'--shuffle\', type=bool, default=False, help=\'Randomize inputs.\')\nargs = arg_parser.parse_args()\n\nwidth, height, channels = parse_size(args.size)\n\nconfig = lookup_config(args)\nif args.action == \'search\':\n    random_config = AlphaGANRandomSearch({}).random_config()\n    if args.config_list is not None:\n        config = random_config_from_list(args.config_list)\n\n        config[""generator""]=random_config[""generator""]\n        config[""g_encoder""]=random_config[""g_encoder""]\n        config[""discriminator""]=random_config[""discriminator""]\n        config[""z_discriminator""]=random_config[""z_discriminator""]\n\n        # TODO Other search terms?\n    else:\n        config = random_config\n\n\ndef tryint(s):\n    try:\n        return int(s)\n    except ValueError:\n        return s\n\ndef alphanum_key(s):\n    return [tryint(c) for c in re.split(\'([0-9]+)\', s)]\n\nclass VideoFrameLoader:\n    """"""\n    """"""\n\n    def __init__(self, batch_size, frame_count, shuffle):\n        self.batch_size = batch_size\n        self.frame_count = frame_count\n        self.shuffle = shuffle\n\n    def inputs(self):\n        return self.frames\n\n    def create(self, directory, channels=3, format=\'jpg\', width=64, height=64, crop=False, resize=False):\n        directories = glob.glob(directory+""/*"")\n        directories = [d for d in directories if os.path.isdir(d)]\n\n        if(len(directories) == 0):\n            directories = [directory] \n\n        # Create a queue that produces the filenames to read.\n        if(len(directories) == 1):\n            # No subdirectories, use all the images in the passed in path\n            filenames = glob.glob(directory+""/*.""+format)\n        else:\n            filenames = glob.glob(directory+""/**/*.""+format)\n\n        if(len(filenames) < self.frame_count):\n            print(""Error: Not enough frames in data folder "", directory)\n\n        self.file_count = len(filenames)\n        filenames = sorted(filenames, key=alphanum_key)\n        if self.file_count == 0:\n            raise ValidationException(""No images found in \'"" + directory + ""\'"")\n\n\n        # creates arrays of filenames[:end], filenames[1:end-1], etc for serialized random batching\n        if self.shuffle:\n            frames  = [tf.train.slice_input_producer([filenames], shuffle=True)[0] for i in range(self.frame_count)]\n        else:\n            input_t = [filenames[i:i-self.frame_count] for i in range(self.frame_count)]\n            input_queue = tf.train.slice_input_producer(input_t, shuffle=True)\n            frames = input_queue\n\n        # Read examples from files in the filename queue.\n        frames = [self.read_frame(frame, format, crop, resize) for frame in frames]\n        frames = self._get_data(frames)\n        self.frames = frames\n\n        x  = tf.train.slice_input_producer([filenames], shuffle=True)[0]\n        y  = tf.train.slice_input_producer([filenames], shuffle=True)[0]\n        self.x = self.read_frame(x, format, crop, resize)\n        self.y = self.read_frame(y, format, crop, resize)\n        self.x = self._get_data([self.x])\n        self.y = self._get_data([self.y])\n\n\n    def read_frame(self, t, format, crop, resize):\n        value = tf.read_file(t)\n\n        if format == \'jpg\':\n            img = tf.image.decode_jpeg(value, channels=channels)\n        elif format == \'png\':\n            img = tf.image.decode_png(value, channels=channels)\n        else:\n            print(""[loader] Failed to load format"", format)\n        img = tf.cast(img, tf.float32)\n\n\n      # Image processing for evaluation.\n      # Crop the central [height, width] of the image.\n        if crop:\n            resized_image = hypergan.inputs.resize_image_patch.resize_image_with_crop_or_pad(img, height, width, dynamic_shape=True)\n        elif resize:\n            resized_image = tf.image.resize_images(img, [height, width], 1)\n        else: \n            resized_image = img\n\n        tf.Tensor.set_shape(resized_image, [height,width,channels])\n\n        # This moves the image to a range of -1 to 1.\n        float_image = resized_image / 127.5 - 1.\n\n        return float_image\n\n    def _get_data(self, imgs):\n        batch_size = self.batch_size\n        num_preprocess_threads = 24\n        return tf.train.shuffle_batch(\n                imgs,\n            batch_size=batch_size,\n            num_threads=num_preprocess_threads,\n            capacity= batch_size*2, min_after_dequeue=batch_size)\ninputs = VideoFrameLoader(args.batch_size, args.frames, args.shuffle)\ninputs.create(args.directory,\n        channels=channels, \n        format=args.format,\n        crop=args.crop,\n        width=width,\n        height=height,\n        resize=True)\n\nsave_file = ""save/model.ckpt""\n\nclass AliNextFrameGAN(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n        self.g_vars = []\n        d_vars = []\n\n        with tf.device(self.device):\n            def random_t(shape):\n                shape[-1] //= len(config.z_distribution.projections)\n                return UniformEncoder(self, config.z_distribution, output_shape=shape).sample\n            def random_like(x):\n                shape = self.ops.shape(x)\n                return random_t(shape)\n\n            self.frame_count = len(self.inputs.frames)\n            self.frames = self.inputs.frames\n\n            dist = UniformEncoder(self, config.z_distribution)\n            dist2 = UniformEncoder(self, config.z_distribution)\n            dist3 = UniformEncoder(self, config.z_distribution)\n            dist4 = UniformEncoder(self, config.z_distribution)\n            dist5 = UniformEncoder(self, config.z_distribution)\n            uz = self.create_component(config.uz, name=\'u_to_z\', input=dist.sample)\n            uc = self.create_component(config.uc, name=\'u_to_c\', input=dist2.sample)\n            uz2 = self.create_component(config.uz, name=\'u_to_z\', input=dist3.sample, reuse=True)\n            uc2 = self.create_component(config.uc, name=\'u_to_c\', input=dist4.sample, reuse=True)\n            uc3 = self.create_component(config.uc, name=\'u_to_c\', input=dist5.sample, reuse=True)\n\n            self.g_vars += uz.variables()\n            self.g_vars += uc.variables()\n\n            def ec(zt, cp,reuse=True):\n                if config.noise:\n                    randt = random_like(cp)\n                    if config.proxy:\n                        dist3 = UniformEncoder(self, config.z_distribution)\n                        proxy_c = self.create_component(config.proxy_c, name=\'rand_ct\', input=dist3.sample, reuse=reuse)\n                        randt = proxy_c.sample\n                    print(""CC"", zt, randt)\n                    c = self.create_component(config.ec, name=\'ec\', input=zt, features={\'ct-1\':cp, \'n\':randt}, reuse=reuse)\n                else:\n                    c = self.create_component(config.ec, name=\'ec\', input=zt, features=[cp], reuse=reuse)\n                if not reuse:\n                    if config.proxy:\n                        self.g_vars += proxy_c.variables()\n                    self.g_vars += c.variables()\n                return c.sample\n            def ez(ft, zp,reuse=True):\n                z = self.create_component(config.ez, name=\'ez\', input=ft, features=[zp], reuse=reuse)\n                if not reuse:\n                    self.g_vars += z.variables()\n                return z.sample\n\n            def build_g(zt, ct, reuse=True):\n                print(""Gb"", reuse)\n                g = self.create_component(config.generator, name=\'generator\', input=ct, features=[zt], reuse=reuse)\n                if not reuse:\n                    self.g_vars += g.variables()\n                return g.sample\n\n            def encode_frames(fs, c0, z0, reuse=True):\n                cs = [c0]\n                zs = [z0]\n                x_hats = [build_g(zs[-1], cs[-1], reuse=reuse)]\n                for i in range(len(fs)):\n                    print(""encode frames"", i)\n                    _reuse = reuse or (i!=0)\n                    z = ez(fs[i], zs[-1], reuse=_reuse)\n                    c = ec(z, cs[-1], reuse=_reuse)\n                    x_hat = build_g(z, c, reuse=True)\n                    zs.append(z)\n                    cs.append(c)\n                    x_hats.append(x_hat)\n                return cs, zs, x_hats\n\n            def build_sim(z0, c0, steps, reuse=True):\n                zs = [z0]\n                cs = [c0]\n                gs = [build_g(zs[-1], cs[-1], reuse=reuse)]\n                for i in range(steps):\n                    _reuse = reuse or (i!=0)\n                    z = ez(gs[-1], zs[-1], reuse=_reuse)\n                    c = ec(z, cs[-1], reuse=_reuse)\n                    g = build_g(z, c, reuse=True)\n                    zs.append(z)\n                    cs.append(c)\n                    gs.append(g)\n\n                return gs, cs, zs\n\n            #self.frames = [f+tf.random_uniform(self.ops.shape(f), minval=-0.1, maxval=0.1) for f in self.frames ]\n            cs, zs, x_hats = encode_frames(self.frames, uc2.sample, uz2.sample, reuse=False)\n            self.zs = zs\n            self.cs = cs\n            ugs, ucs, uzs = build_sim(uz.sample, uc.sample, len(self.frames))\n            ugs_next, ucs_next, uzs_next = build_sim(uzs[-1], ucs[-1], len(self.frames))\n            re_ucs_next, re_uzs_next, re_ugs_next = encode_frames(ugs_next[1:], ucs_next[0], uzs_next[0])\n            gs_next, cs_next, zs_next = build_sim(zs[-1], cs[-1], len(self.frames))\n            #gs_next_next, cs_next_next, zs_next_next = build_sim(zs[-1], cs[-1], 21)\n            re_ucs, re_uzs, ugs_hat = encode_frames(ugs[1:], ucs[0], uzs[0])\n            re_cs_next, re_zs_next, re_gs_next = encode_frames(gs_next[1:], cs_next[0], zs_next[0])\n            self.x_hats = x_hats\n\n            t0 = tf.concat(zs[1:], axis=3)\n            t1 = tf.concat(re_uzs[:-1], axis=3)\n            t2 = tf.concat(re_zs_next[:-1], axis=3)\n            t3 = tf.concat(re_uzs_next[:-1], axis=3)\n            t4 = tf.concat(re_uzs[:-1], axis=3)\n            f0 = tf.concat(cs[1:], axis=3)\n            f1 = tf.concat(re_ucs[:-1], axis=3)\n            f2 = tf.concat(re_cs_next[:-1], axis=3)\n            f3 = tf.concat(re_ucs_next[:-1], axis=3)\n\n            stack = [t0,t1, t2]#, t4, t5]\n            stacked = ops.concat(stack, axis=0)\n            features =ops.concat([f0,f1,f2], axis=0)\n            d = self.create_component(config.z_discriminator, name=\'d_img\', input=stacked, features=[features])\n            d_vars += d.variables()\n            l = self.create_loss(config.loss, d, None, None, len(stack))\n            d_loss = l.d_loss\n            g_loss = l.g_loss\n\n            self.video_generator_last_z = uzs[0]\n            self.video_generator_last_c = ucs[0]\n            self.gs_next = gs_next\n            ztn = uzs[1]\n            ctn = ucs[1]\n            self.video_generator_last_zn = ztn\n            self.video_generator_last_cn = ctn\n            gen = hc.Config({""sample"":ugs[0]})\n\n            if config.use_x:\n                def rotate(first, second, offset=None):\n                    rotations = [tf.concat(first[:offset], axis=3)]\n                    elem = first\n                    for e in second:\n                        elem = elem[1:]+[e]\n                        rotations.append(tf.concat(elem[:offset], axis=3))\n                    return rotations\n\n\n                t0 = tf.concat(self.frames[1:], axis=3)\n                f0 = tf.concat(cs[1:-1], axis=3)\n\n                stack = [t0]\n                features = [f0]\n\n\n                if config.encode_forward:\n                    stack += rotate(self.frames[2:]+[gs_next[0]], gs_next[1:])\n                    features += rotate(cs[2:], cs_next[1:])\n                    #stack += [gs_next_next[-frames:]]\n                if config.encode_ug:\n                    stack += rotate(ugs[:-2], ugs[-2:]+ugs_next[1:])\n                    features += rotate(ucs[:-2], ucs[-2:]+ucs_next[1:])\n\n                stacked = ops.concat(stack, axis=0)\n                features = tf.concat(features, axis=0)\n                d = self.create_component(config.discriminator, name=\'d_manifold\', input=stacked, features=[features])\n                d_vars += d.variables()\n                l = self.create_loss(config.loss, d, None, None, len(stack))\n                d_loss += l.d_loss\n                g_loss += l.g_loss\n\n    \n            gx_sample = gen.sample\n            gy_sample = gen.sample\n            gx = hc.Config({""sample"":gx_sample})\n            gy = hc.Config({""sample"":gy_sample})\n\n            last_frame = tf.slice(gy_sample, [0,0,0,0], [-1, -1, -1, 3])\n            self.y = hc.Config({""sample"":last_frame})\n            self.gy = self.y\n            self.gx = self.y\n            self.uniform_sample = gen.sample\n\n            self.preview = tf.concat(self.inputs.frames[:-1] + [gen.sample], axis=1)#tf.concat(tf.split(gen.sample, (self.ops.shape(gen.sample)[3]//3), 3), axis=1)\n\n\n            metrics = {\n                    \'g_loss\': g_loss,\n                    \'d_loss\': d_loss\n                }\n\n \n            trainers = []\n\n            lossa = hc.Config({\'sample\': [d_loss, g_loss], \'metrics\': metrics, \'d_fake\': l.d_fake, \'d_real\': l.d_real, \'config\': l.config})\n            self.loss = lossa\n            self._g_vars = self.g_vars\n            self._d_vars = d_vars\n            trainer = self.create_component(config.trainer, loss = lossa, g_vars = self.g_vars, d_vars = d_vars)\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = gx\n        self.z_hat = gy.sample\n        self.x_input = self.inputs.frames[0]\n\n        self.uga = self.y.sample\n        self.uniform_encoder = dist\n\n    def g_vars(self):\n        return self._g_vars\n    def d_vars(self):\n        return self._d_vars\n\n    def fitness_inputs(self):\n        return self.inputs.frames\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator, split=split)\n        return loss\n\n    def create_encoder(self, x_input, name=\'input_encoder\', reuse=False):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input, reuse=reuse)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int\n        ]\nclass VideoFrameSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        sess = gan.session\n        self.x = gan.session.run(gan.preview)\n        print(""__________"", np.shape(self.x),\'---oo\')\n        frames = np.shape(self.x)[1]//height\n        self.frames=frames\n        self.x = np.split(self.x, frames, axis=1)\n        self.i = 0\n        BaseSampler.__init__(self, gan, samples_per_row)\n\n    def _sample(self):\n        gan = self.gan\n        z_t = gan.uniform_encoder.sample\n        sess = gan.session\n\n        feed_dict = {}\n        for i,f in enumerate(gan.inputs.frames):\n            if len(self.x) > i+1:\n                feed_dict[f]=self.x[i+1]\n            #if(1 + self.frames < len(self.x)):\n            #    feed_dict[f] = self.x[1+self.frames]\n        self.x = sess.run(gan.preview, feed_dict)\n        frames = np.shape(self.x)[1]//height\n        self.x = np.split(self.x, frames, axis=1)\n        x_ = self.x[-1]\n\n        time.sleep(0.15)\n        return {\n            \'generator\': x_\n        }\n\n\nclass TrainingVideoFrameSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        self.z = None\n\n        self.i = 0\n        BaseSampler.__init__(self, gan, samples_per_row)\n\n    def _sample(self):\n        gan = self.gan\n        z_t = gan.uniform_encoder.sample\n        sess = gan.session\n        \n \n        return {\n            \'generator\': gan.session.run(gan.preview)\n        }\n\n\n\n\ndef setup_gan(config, inputs, args):\n    gan = AliNextFrameGAN(config, inputs=inputs)\n\n    if(args.action != \'search\' and os.path.isfile(save_file+"".meta"")):\n        gan.load(save_file)\n\n    tf.train.start_queue_runners(sess=gan.session)\n\n    config_name = args.config\n    GlobalViewer.title = ""[hypergan] next-frame "" + config_name\n    GlobalViewer.enabled = args.viewer\n    GlobalViewer.zoom = args.zoom\n\n    return gan\n\ndef train(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    sampler = lookup_sampler(args.sampler or TrainingVideoFrameSampler)(gan)\n    samples = 0\n\n    #metrics = [batch_accuracy(gan.inputs.x, gan.uniform_sample), batch_diversity(gan.uniform_sample)]\n    #sum_metrics = [0 for metric in metrics]\n    for i in range(args.steps):\n        gan.step()\n\n        if args.action == \'train\' and i % args.save_every == 0 and i > 0:\n            print(""saving "" + save_file)\n            gan.save(save_file)\n\n        if i % args.sample_every == 0:\n            sample_file=""samples/%06d.png"" % (samples)\n            samples += 1\n            sampler.sample(sample_file, args.save_samples)\n\n        #if i > args.steps * 9.0/10:\n        #    for k, metric in enumerate(gan.session.run(metrics)):\n        #        print(""Metric ""+str(k)+"" ""+str(metric))\n        #        sum_metrics[k] += metric \n\n    tf.reset_default_graph()\n    return []#sum_metrics\n\ndef sample(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    sampler = lookup_sampler(args.sampler or VideoFrameSampler)(gan)\n    samples = 0\n    for i in range(args.steps):\n        sample_file=""samples/%06d.png"" % (samples)\n        samples += 1\n        sampler.sample(sample_file, args.save_samples)\n\ndef search(config, inputs, args):\n    metrics = train(config, inputs, args)\n\n    config_filename = ""colorizer-""+str(uuid.uuid4())+\'.json\'\n    hc.Selector().save(config_filename, config)\n    with open(args.search_output, ""a"") as myfile:\n        myfile.write(config_filename+"",""+"","".join([str(x) for x in metrics])+""\\n"")\n\nif args.action == \'train\':\n    metrics = train(config, inputs, args)\n    print(""Resulting metrics:"", metrics)\nelif args.action == \'sample\':\n    sample(config, inputs, args)\nelif args.action == \'search\':\n    search(config, inputs, args)\nelse:\n    print(""Unknown action: ""+args.action)\n'"
examples/experimental/next-frame.py,71,"b'import os\nimport uuid\nimport random\nimport tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\nimport glob\nimport time\nimport re\nfrom hypergan.viewer import GlobalViewer\nfrom hypergan.samplers.base_sampler import BaseSampler\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom hypergan.samplers.random_walk_sampler import RandomWalkSampler\nfrom hypergan.samplers.debug_sampler import DebugSampler\nfrom hypergan.search.alphagan_random_search import AlphaGANRandomSearch\nfrom hypergan.gans.base_gan import BaseGAN\nfrom common import *\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nimport copy\n\nfrom hypergan.gans.alpha_gan import AlphaGAN\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom hypergan.gans.base_gan import BaseGAN\n\nfrom hypergan.discriminators.fully_connected_discriminator import FullyConnectedDiscriminator\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.multi_step_trainer import MultiStepTrainer\nfrom hypergan.trainers.multi_trainer_trainer import MultiTrainerTrainer\nfrom hypergan.trainers.consensus_trainer import ConsensusTrainer\n\n\narg_parser = ArgumentParser(""render next frame"")\nparser = arg_parser.add_image_arguments()\nparser.add_argument(\'--frames\', type=int, default=4, help=\'Number of frames to embed.\')\nparser.add_argument(\'--shuffle\', type=bool, default=False, help=\'Randomize inputs.\')\nargs = arg_parser.parse_args()\n\nwidth, height, channels = parse_size(args.size)\n\nconfig = lookup_config(args)\nif args.action == \'search\':\n    random_config = AlphaGANRandomSearch({}).random_config()\n    if args.config_list is not None:\n        config = random_config_from_list(args.config_list)\n\n        config[""generator""]=random_config[""generator""]\n        config[""g_encoder""]=random_config[""g_encoder""]\n        config[""discriminator""]=random_config[""discriminator""]\n        config[""z_discriminator""]=random_config[""z_discriminator""]\n\n        # TODO Other search terms?\n    else:\n        config = random_config\n\n\ndef tryint(s):\n    try:\n        return int(s)\n    except ValueError:\n        return s\n\ndef alphanum_key(s):\n    return [tryint(c) for c in re.split(\'([0-9]+)\', s)]\n\nclass VideoFrameLoader:\n    """"""\n    """"""\n\n    def __init__(self, batch_size, frame_count, shuffle):\n        self.batch_size = batch_size\n        self.frame_count = frame_count\n        self.shuffle = shuffle\n\n    def inputs(self):\n        return self.frames\n\n    def create(self, directory, channels=3, format=\'jpg\', width=64, height=64, crop=False, resize=False):\n        directories = glob.glob(directory+""/*"")\n        directories = [d for d in directories if os.path.isdir(d)]\n\n        if(len(directories) == 0):\n            directories = [directory] \n\n        # Create a queue that produces the filenames to read.\n        if(len(directories) == 1):\n            # No subdirectories, use all the images in the passed in path\n            filenames = glob.glob(directory+""/*.""+format)\n        else:\n            filenames = glob.glob(directory+""/**/*.""+format)\n\n        if(len(filenames) < self.frame_count):\n            print(""Error: Not enough frames in data folder "", directory)\n\n        self.file_count = len(filenames)\n        filenames = sorted(filenames, key=alphanum_key)\n        if self.file_count == 0:\n            raise ValidationException(""No images found in \'"" + directory + ""\'"")\n\n\n        # creates arrays of filenames[:end], filenames[1:end-1], etc for serialized random batching\n        if self.shuffle:\n            frames  = [tf.train.slice_input_producer([filenames], shuffle=True)[0] for i in range(self.frame_count)]\n        else:\n            input_t = [filenames[i:i-self.frame_count] for i in range(self.frame_count)]\n            input_queue = tf.train.slice_input_producer(input_t)\n            frames = input_queue\n\n        # Read examples from files in the filename queue.\n        frames = [self.read_frame(frame, format, crop, resize) for frame in frames]\n        frames = self._get_data(frames)\n        self.frames = frames\n\n        x  = tf.train.slice_input_producer([filenames], shuffle=True)[0]\n        y  = tf.train.slice_input_producer([filenames], shuffle=True)[0]\n        self.x = self.read_frame(x, format, crop, resize)\n        self.y = self.read_frame(y, format, crop, resize)\n        self.x = self._get_data([self.x])\n        self.y = self._get_data([self.y])\n\n\n    def read_frame(self, t, format, crop, resize):\n        value = tf.read_file(t)\n\n        if format == \'jpg\':\n            img = tf.image.decode_jpeg(value, channels=channels)\n        elif format == \'png\':\n            img = tf.image.decode_png(value, channels=channels)\n        else:\n            print(""[loader] Failed to load format"", format)\n        img = tf.cast(img, tf.float32)\n\n\n      # Image processing for evaluation.\n      # Crop the central [height, width] of the image.\n        if crop:\n            resized_image = hypergan.inputs.resize_image_patch.resize_image_with_crop_or_pad(img, height, width, dynamic_shape=True)\n        elif resize:\n            resized_image = tf.image.resize_images(img, [height, width], 1)\n        else: \n            resized_image = img\n\n        tf.Tensor.set_shape(resized_image, [height,width,channels])\n\n        # This moves the image to a range of -1 to 1.\n        float_image = resized_image / 127.5 - 1.\n\n        return float_image\n\n    def _get_data(self, imgs):\n        batch_size = self.batch_size\n        num_preprocess_threads = 24\n        return tf.train.shuffle_batch(\n                imgs,\n            batch_size=batch_size,\n            num_threads=num_preprocess_threads,\n            capacity= batch_size*2, min_after_dequeue=batch_size)\ninputs = VideoFrameLoader(args.batch_size, args.frames, args.shuffle)\ninputs.create(args.directory,\n        channels=channels, \n        format=args.format,\n        crop=args.crop,\n        width=width,\n        height=height,\n        resize=True)\n\nsave_file = ""saves/"" + args.config + ""/model.ckpt""\n\nos.makedirs(os.path.expanduser(os.path.dirname(save_file)), exist_ok=True)\n\nclass RollingMemoryTrainHook(BaseTrainHook):\n  def __init__(self, gan=None, config=None, trainer=None, name=""RollingMemoryHook""):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    cur_c = [gan.ucs[1], gan.cs[1]]\n    cur_z = [gan.uzs[1], gan.zs[1]]\n    prev_c = [gan.ucs[0], gan.cs[0]]\n    prev_z = [gan.uzs[0], gan.zs[0]]\n    prev = prev_c + prev_z\n    cur = cur_c + cur_z\n    self.step_forward = [tf.assign(p, c) for p, c in zip(prev, cur)]\n    self.gan.add_metric(\'cur_c\', gan.ops.squash(cur_c[0]))\n    self.gan.add_metric(\'cur_z\', gan.ops.squash(cur_z[0]))\n\n  def losses(self):\n\n    return [None, None]\n\n  def after_step(self, step, feed_dict):\n      self.gan.session.run(self.step_forward)\n\n  def before_step(self, step, feed_dict):\n    pass\n\nclass AliNextFrameGAN(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n        self._g_vars = []\n        d_vars = []\n\n        with tf.device(self.device):\n            def random_t(shape):\n                shape[-1] //= len(config.z_distribution.projections)\n                return UniformDistribution(self, config.z_distribution, output_shape=shape).sample\n            def random_like(x):\n                shape = self.ops.shape(x)\n                return random_t(shape)\n\n            self.frame_count = len(self.inputs.frames)\n            self.frames = self.inputs.frames\n\n            dist = UniformDistribution(self, config.z_distribution)\n            dist2 = UniformDistribution(self, config.z_distribution)\n            dist3 = UniformDistribution(self, config.z_distribution)\n            dist4 = UniformDistribution(self, config.z_distribution)\n            dist5 = UniformDistribution(self, config.z_distribution)\n            _uz = self.create_component(config.uz, name=\'u_to_z\', input=dist.sample)\n            uz = tf.Variable(tf.zeros_like(_uz.sample), trainable=False)\n            uz2 = tf.Variable(tf.zeros_like(_uz.sample), trainable=False)\n            self.latent = uz\n            _uc = self.create_component(config.uc, name=\'u_to_c\', input=dist2.sample)\n            uc = tf.Variable(tf.zeros_like(_uc.sample), trainable=False)\n            uc2 = tf.Variable(tf.zeros_like(_uc.sample), trainable=False)\n\n\n            def ec(zt, cp,reuse=True):\n\n                if config.noise:\n                    randt = random_like(cp)\n                    if config.proxy:\n                        dist3 = UniformDistribution(self, config.z_distribution)\n                        proxy_c = self.create_component(config.proxy_c, name=\'rand_ct\', input=dist3.sample, reuse=reuse)\n                        randt = proxy_c.sample\n\n                        c = self.create_component(config.ec, name=\'ec\', input=zt, features={\'ct-1\':cp, \'n\':randt}, reuse=reuse)\n                    elif config.proxyrand:\n                        c = self.create_component(config.ec, name=\'ec\', input=zt, features={\'ct-1\':cp, \'n\':random_like(zt)}, reuse=reuse)\n                    elif config.proxyrand2:\n                        c = self.create_component(config.ec, name=\'ec\', input=zt, features={\'ct-1\':(cp+randt*0.01), \'n\':random_like(zt) }, reuse=reuse)\n                    else:\n                        c = self.create_component(config.ec, name=\'ec\', input=zt, features={\'ct-1\':cp, \'n\':tf.zeros_like(zt)}, reuse=reuse)\n\n                if not reuse:\n                    if config.proxy:\n                        self._g_vars += proxy_c.variables()\n                    self._g_vars += c.variables()\n                    self.encoder = c\n                return c.sample\n            def ez(ft, zp,reuse=True):\n                z = self.create_component(config.ez, name=\'ez\', input=ft, features=[zp], reuse=reuse)\n                if not reuse:\n                    self._g_vars += z.variables()\n                return z.sample\n\n            def build_g(zt, ct, reuse=True):\n                print(""Gb"", reuse,zt,ct)\n                g = self.create_component(config.generator, name=\'generator\', input=ct, features={\'z\':zt,\'c\':ct}, reuse=reuse)\n                if not reuse:\n                    self._g_vars += g.variables()\n                    self.generator = g\n                return g.sample\n\n            def encode_frames(fs, c0, z0, reuse=True):\n                cs = [c0]\n                zs = [z0]\n                x_hats = [build_g(zs[-1], cs[-1], reuse=reuse)]\n                for i in range(len(fs)):\n                    print(""encode frames"", i)\n                    _reuse = reuse or (i!=0)\n                    z = ez(fs[i], zs[-1], reuse=_reuse)\n                    c = ec(z, cs[-1], reuse=_reuse)\n                    x_hat = build_g(z, c, reuse=True)\n                    zs.append(z)\n                    cs.append(c)\n                    x_hats.append(x_hat)\n                return cs, zs, x_hats\n\n            def build_sim(z0, c0, steps, reuse=True):\n                zs = [z0]\n                cs = [c0]\n                gs = [build_g(zs[-1], cs[-1], reuse=reuse)]\n                for i in range(steps):\n                    _reuse = reuse or (i!=0)\n                    z = ez(gs[-1], zs[-1], reuse=_reuse)\n                    c = ec(z, cs[-1], reuse=_reuse)\n                    g = build_g(z, c, reuse=True)\n                    zs.append(z)\n                    cs.append(c)\n                    gs.append(g)\n\n                return gs, cs, zs\n\n            def rotate(first, second, offset=None):\n                ax = len(self.ops.shape(first[0]))-1\n                rotations = [tf.concat(first[:offset], axis=ax)]\n                elem = first\n                for e in second:\n                    elem = elem[1:]+[e]\n                    rotations.append(tf.concat(elem[:offset], axis=ax))\n                return rotations\n\n            def disc(metric, name, _inputs, _features, reuse=False):\n               _is = tf.concat(_inputs,axis=0)\n               _fs = tf.concat(_features,axis=0)\n               disc = self.create_component(config[name], name=name, input=_is, features=[_fs], reuse=reuse)\n               l2 = self.create_loss(config.loss, disc, None, None, len(_inputs))\n               self.add_metric(\'d_\'+metric, l2.d_loss)\n               self.add_metric(\'g_\'+metric, l2.g_loss)\n               return l2, disc.variables(), disc\n\n            def mi(metric, name, _inputs, _features):\n                _inputsb = [tf.zeros_like(x) for x in _inputs]\n                _featuresb = [tf.zeros_like(x) for x in _features]\n                beta = config.bottleneck_beta or 1\n                ib_2_c = config.ib_2_c or 1\n                inputs = tf.concat(_inputs, axis=0)\n                features = tf.concat(_features, axis=0)\n                gl,dl,d_vars,_ = disc(metric+\'1\', name, _inputs, _features)\n                gl2,dl2, _,_ = disc(metric+\'2\', name, _inputs, _features, reuse=True)\n                gl3,dl3, _,_ = disc(metric+\'3\', name, _inputs, _features, reuse=True)\n                dls = ib_2_c * beta *tf.add_n([dl,-dl2,-dl3])\n                gls = ib_2_c * beta *tf.add_n([gl,-gl2,-gl3])\n\n                return gls, dls, d_vars\n\n\n            #self.frames = [f+tf.random_uniform(self.ops.shape(f), minval=-0.1, maxval=0.1) for f in self.frames ]\n            cs, zs, x_hats = encode_frames(self.frames, uc2, uz2, reuse=False)\n            extra_frames = config.extra_frames or 2\n            ugs, ucs, uzs = build_sim(uz, uc, len(self.frames))\n            self.zs = zs\n            self.cs = cs\n            alt_gs, alt_cs, alt_zs = build_sim(zs[1], cs[1], len(self.frames))\n            self.ucs = ucs\n            self.uzs = uzs\n            self.alt_cs = alt_cs\n            self.alt_zs = alt_zs\n            ugs_next, ucs_next, uzs_next = build_sim(uzs[-1], ucs[-1], len(self.frames))\n            re_ucs_next, re_uzs_next, re_ugs_next = encode_frames(ugs_next[1:len(self.frames)], ucs_next[0], uzs_next[0])\n            gs_next, cs_next, zs_next = build_sim(zs[-1], cs[-1], len(self.frames)+extra_frames)\n            re_ucs, re_uzs, ugs_hat = encode_frames(ugs[1:len(self.frames)], ucs[0], uzs[0])\n            re_cs, re_zs, re_ugs = encode_frames(x_hats[1:len(self.frames)], cs[0], zs[0])\n            re_cs_next, re_zs_next, re_gs_next = encode_frames(gs_next[1:len(self.frames)], cs_next[0], zs_next[0])\n            self.x_hats = x_hats\n            axis = len(ops.shape(x_hats[1]))-1\n            zaxis = len(ops.shape(zs[1]))-1\n            caxis = len(ops.shape(cs[1]))-1\n            t0 = tf.concat(zs[1:-1], axis=zaxis)\n            t1 = tf.concat(uzs[1:-1], axis=zaxis)\n            t2 = tf.concat(zs_next[1:len(cs)-1], axis=zaxis)\n            if config.manifold_guided:\n                t1 = tf.concat(re_uzs[1:], axis=zaxis)\n                t2 = tf.concat(re_zs_next[1:len(cs)-1], axis=zaxis)\n            t3 = re_uzs_next#tf.concat(re_ucs_next, axis=axis)\n\n\n            t0 = tf.concat(self.frames[1:], axis=axis)\n            f0 = tf.concat(cs[1:-1], axis=caxis)\n            self.x0 = t0\n\n            stack = [t0]\n            features = [f0]\n            if config.encode_x_hat:\n                #stack += rotate(ugs[:-2], ugs[-2:]+ugs_next)\n                #features += rotate(ucs[:-2], ucs[-2:]+ucs_next)\n                stack += [tf.concat(x_hats[2:], axis=axis)]\n                features += [tf.concat(cs[1:-1], axis=caxis)]\n\n            if config.encode_alternate_path:\n                #stack += rotate(ugs[:-2], ugs[-2:]+ugs_next)\n                #features += rotate(ucs[:-2], ucs[-2:]+ucs_next)\n                stack.append(tf.concat(alt_gs[:-2], axis=axis))\n                features.append(tf.concat(alt_cs[:-2], axis=caxis))\n     \n            if config.encode_re_ug:\n                stack.append(tf.concat(re_ugs[1:], axis=axis))\n                features.append(tf.concat(re_ucs[1:], axis=caxis))\n                \n            if config.encode_forward:\n                stack += rotate(self.frames[2:]+[gs_next[0]], gs_next[1:])\n                features += rotate(cs[2:], cs_next[1:])\n                #stack += [tf.concat(self.frames[2:]+[gs_next[0]], axis=axis)]\n                #features += [tf.concat(cs[2:], axis=caxis)]\n                self.g0 = tf.concat(gs_next[1:len(self.frames)], axis=axis)\n                self.c0 = tf.concat(cs_next[1:-3], axis=caxis)\n                #print(""GS"", gs_next, features)\n                #stack += rotate(gs_next[:-4], gs_next[-4:])\n                #features += rotate(cs_next[:-4], cs_next[-4:])\n\n            if config.encode_ug:\n                #stack += rotate(ugs[:-2], ugs[-2:]+ugs_next)\n                #features += rotate(ucs[:-2], ucs[-2:]+ucs_next)\n                self.g0 = tf.concat(ugs[1:-1], axis=axis)\n                self.c0 = tf.concat(ucs[1:-1], axis=caxis)\n                stack.append(self.g0)\n                features.append(self.c0)\n\n            #if config.encode_forward_next:\n            #    stack += [tf.concat(gs_next[:-4],axis=axis)]\n            #    features += [tf.concat(cs_next[:-4],axis=axis)]\n\n            self.video_generator_last_z = uzs[0]\n            self.video_generator_last_c = ucs[0]\n            self.gs_next = gs_next\n            ztn = uzs[1]\n            ctn = ucs[1]\n            self.video_generator_last_zn = ztn\n            self.video_generator_last_cn = ctn\n            self.c_drift = self.ops.squash(tf.abs(ucs[1]-ucs[0]))\n            gen = hc.Config({""sample"":ugs[0]})\n\n\n            #_stacked = ops.concat(stack, axis=0)\n            #d = self.create_component(config.discriminator, name=\'d_manifold\', input=_stacked, features=[None])\n            #d_vars += d.variables()\n            #l = self.create_loss(config.loss, d, None, None, len(stack))\n            #d_loss += l.d_loss\n            #g_loss += l.g_loss\n\n\n            #gl, dl, dvs = mi(\'mi\', \'b_discriminator2\', stack, features)\n            #g_loss += gl\n            #d_loss += dl\n            #d_vars += dvs\n            self.features = features\n            l,dvs,disc = disc(\'loss\', \'discriminator\', stack, features)\n            self.discriminator = disc\n            g_loss = l.g_loss\n            d_loss = l.d_loss\n            d_vars += dvs\n\n            if config.use_z_discriminator:\n                a=tf.concat([zs[1], zs[1]], axis=zaxis)\n                _inputs = [a]\n                for c in re_zs:\n                    _inputs += [tf.concat([zs[1], c], axis=zaxis)]\n                d = self.create_component(config.z_discriminator, name=\'d_z\', input=tf.concat(_inputs, axis=0), features=[None])\n                d_vars += d.variables()\n                l = self.create_loss(config.loss, d, None, None, len(_inputs))\n                g_loss += l.g_loss\n                d_loss += l.d_loss\n\n            if config.use_c_discriminator:\n                a=tf.concat([cs[1], cs[1]], axis=caxis)\n                _inputs = [a]\n                for c in re_cs:\n                    _inputs += [tf.concat([cs[1], c], axis=caxis)]\n                d = self.create_component(config.c_discriminator, name=\'d_c\', input=tf.concat(_inputs, axis=0), features=[None])\n                d_vars += d.variables()\n                l = self.create_loss(config.loss, d, None, None, len(_inputs))\n                d_loss += l.d_loss\n                g_loss += l.g_loss\n\n\n            if config.vae:\n                if(hasattr(self, ""variational"")):\n                    for i,var in enumerate(self.variational):\n                        mu,sigma = var\n                        eps = 1e-8\n                        lam = config.vae_lambda or 0.01\n                        latent_loss = lam*(0.5 *self.ops.squash(tf.square(mu)-tf.square(sigma) - tf.log(tf.square(sigma)+eps) - 1, tf.reduce_sum ))\n                        self.add_metric(""vae""+str(i), latent_loss)\n                        #d_loss += latent_loss\n                        g_loss -= latent_loss\n\n\n            gx_sample = gen.sample\n            gy_sample = gen.sample\n            self.generator.sample = gx_sample\n            gy = hc.Config({""sample"":gy_sample})\n\n            last_frame = tf.slice(gy_sample, [0,0,0,0], [-1, -1, -1, 3])\n            self.y = hc.Config({""sample"":last_frame})\n            self.gy = self.y\n            self.gx = self.y\n            self.uniform_sample = gen.sample\n\n            self.preview = tf.concat(self.inputs.frames[:-1] + [gen.sample], axis=axis)#tf.concat(tf.split(gen.sample, (self.ops.shape(gen.sample)[3]//3), 3), axis=1)\n\n\n            trainers = []\n\n            lossa = hc.Config({\'sample\': [d_loss, g_loss], \'d_fake\': l.d_fake, \'d_real\': l.d_real, \'config\': l.config})\n            self.loss = lossa\n            self._d_vars = d_vars\n            if ""hooks"" not in config.trainer:\n                config.trainer[""hooks""] = []\n            config.trainer[""hooks""].append({""class"":RollingMemoryTrainHook})\n            trainer = self.create_component(config.trainer)\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.z_hat = gy.sample\n        self.x_input = self.inputs.frames[0]\n\n        self.uga = self.y.sample\n        self.uniform_distribution = dist\n\n    def g_vars(self):\n        return self._g_vars\n    def d_vars(self):\n        return self._d_vars\n\n    def sample_mixture(self):\n        diff = self.x0 - self.g0\n        alpha = tf.random_uniform(shape=self.ops.shape(self.g0), minval=0., maxval=1.0)\n        return self.x0 + alpha * diff\n\n    def fitness_inputs(self):\n        return self.inputs.frames\n\n    def create_discriminator(self, _input, reuse=False):\n        config = self.config\n        gan = self.gan\n        print(""___"", _input, self.g0, self.x0, self.c0)\n        _fs = tf.concat([tf.zeros_like(self.c0),tf.zeros_like(self.c0)],axis=0)\n        disc = self.create_component(config.discriminator, name=\'discriminator\', input=_input, features=[_fs], reuse=reuse)\n        return disc\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator, split=split)\n        return loss\n\n    def create_generator(self, _input, reuse=False):\n        return self.create_component(self.config.generator, name=\'generator\', input=self.ucs[0], features={\'z\':_input,\'c\':self.ucs[0]}, reuse=reuse)\n\n    def create_encoder(self, x_input, name=\'input_encoder\', reuse=False):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input, reuse=reuse)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int\n        ]\nclass VideoFrameSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        sess = gan.session\n        self.x = gan.session.run(gan.preview)\n        print(""__________"", np.shape(self.x),\'---oo\')\n        frames = np.shape(self.x)[1]//height\n        self.frames=frames\n        self.x = np.split(self.x, frames, axis=1)\n        self.i = 0\n        BaseSampler.__init__(self, gan, samples_per_row)\n\n    def _sample(self):\n        gan = self.gan\n        z_t = gan.uniform_distribution.sample\n        sess = gan.session\n\n        feed_dict = {}\n        for i,f in enumerate(gan.inputs.frames):\n            if len(self.x) > i+1:\n                feed_dict[f]=self.x[i+1]\n            #if(1 + self.frames < len(self.x)):\n            #    feed_dict[f] = self.x[1+self.frames]\n        self.x = sess.run(gan.preview, feed_dict)\n        frames = np.shape(self.x)[1]//height\n        self.x = np.split(self.x, frames, axis=1)\n        x_ = self.x[-1]\n\n        time.sleep(0.15)\n        return {\n            \'generator\': x_\n        }\n\n\nclass TrainingVideoFrameSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        self.z = None\n\n        self.i = 0\n        BaseSampler.__init__(self, gan, samples_per_row)\n\n    def _sample(self):\n        gan = self.gan\n        z_t = gan.uniform_distribution.sample\n        sess = gan.session\n        \n \n        return {\n            \'generator\': gan.session.run(gan.preview)\n        }\n\n\n\n\ndef setup_gan(config, inputs, args):\n    gan = AliNextFrameGAN(config, inputs=inputs)\n\n    if(args.action != \'search\' and os.path.isfile(save_file+"".meta"")):\n        gan.load(save_file)\n\n    tf.train.start_queue_runners(sess=gan.session)\n\n    config_name = args.config\n    GlobalViewer.title = ""[hypergan] next-frame "" + config_name\n    GlobalViewer.enabled = args.viewer\n    GlobalViewer.viewer_size = args.zoom\n\n    return gan\n\ndef train(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    sampler = lookup_sampler(args.sampler or TrainingVideoFrameSampler)(gan)\n    samples = 0\n\n    #metrics = [batch_accuracy(gan.inputs.x, gan.uniform_sample), batch_diversity(gan.uniform_sample)]\n    #sum_metrics = [0 for metric in metrics]\n    for i in range(args.steps):\n        gan.step()\n\n        if args.action == \'train\' and i % args.save_every == 0 and i > 0:\n            print(""saving "" + save_file)\n            gan.save(save_file)\n\n        if i % args.sample_every == 0:\n            sample_file=""samples/""+args.config+""/%06d.png"" % (samples)\n            os.makedirs(os.path.expanduser(os.path.dirname(sample_file)), exist_ok=True)\n            samples += 1\n            sampler.sample(sample_file, args.save_samples)\n\n        #if i > args.steps * 9.0/10:\n        #    for k, metric in enumerate(gan.session.run(metrics)):\n        #        print(""Metric ""+str(k)+"" ""+str(metric))\n        #        sum_metrics[k] += metric \n\n    tf.reset_default_graph()\n    return []#sum_metrics\n\ndef sample(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    sampler = lookup_sampler(args.sampler or VideoFrameSampler)(gan)\n    samples = 0\n    for i in range(args.steps):\n        sample_file=""samples/""+args.config+""/%06d.png"" % (samples)\n        os.makedirs(os.path.expanduser(os.path.dirname(sample_file)), exist_ok=True)\n        samples += 1\n        sampler.sample(sample_file, args.save_samples)\n\ndef search(config, inputs, args):\n    metrics = train(config, inputs, args)\n\n    config_filename = ""colorizer-""+str(uuid.uuid4())+\'.json\'\n    hc.Selector().save(config_filename, config)\n    with open(args.search_output, ""a"") as myfile:\n        myfile.write(config_filename+"",""+"","".join([str(x) for x in metrics])+""\\n"")\n\nif args.action == \'train\':\n    metrics = train(config, inputs, args)\n    print(""Resulting metrics:"", metrics)\nelif args.action == \'sample\':\n    sample(config, inputs, args)\nelif args.action == \'search\':\n    search(config, inputs, args)\nelse:\n    print(""Unknown action: ""+args.action)\n'"
examples/experimental/static.py,1,"b'import argparse\nimport os\nimport uuid\nimport tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\nfrom hypergan.generators import *\nfrom hypergan.viewer import GlobalViewer\nfrom common import *\nfrom hypergan.search.random_search import RandomSearch\n\nfrom hypergan.samplers.random_walk_sampler import RandomWalkSampler\nfrom hypergan.samplers.static_batch_sampler import StaticBatchSampler\n\narg_parser = ArgumentParser(""Feed static values into X/Z and memorize them"")\narg_parser.add_image_arguments()\nargs = arg_parser.parse_args()\n\nwidth, height, channels = parse_size(args.size)\n\nconfig = lookup_config(args)\n\nsave_file = ""save/model.ckpt""\n\nif args.action == \'search\':\n    config = RandomSearch({}).random_config()\n\n    if args.config_list is not None:\n        config = random_config_from_list(args.config_list)\n        random_config = RandomSearch({}).random_config()\n\n        config[""generator""]=random_config[""generator""]\n        config[""discriminator""]=random_config[""discriminator""]\n        # TODO Other search terms?\n\ninputs = hg.inputs.image_loader.ImageLoader(args.batch_size)\ninputs.create(args.directory,\n              channels=channels, \n              format=args.format,\n              crop=args.crop,\n              width=width,\n              height=height,\n              resize=True)\n\nsave_file = ""save/model.ckpt""\n\ndef setup_gan(config, inputs, args):\n    gan = hg.GAN(config, inputs=inputs)\n\n    gan.create()\n\n    if(args.action != \'search\' and os.path.isfile(save_file+"".meta"")):\n        gan.load(save_file)\n\n    tf.train.start_queue_runners(sess=gan.session)\n\n    config_name = args.config\n    title = ""[hypergan] static "" + config_name\n    GlobalViewer.title = title\n    GlobalViewer.enabled = args.viewer\n\n    return gan\n\ndef train(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    static_x, static_z = gan.session.run([gan.inputs.x, gan.encoder.sample])\n\n    accuracy_x_to_g=batch_accuracy(static_x, gan.generator.sample)\n    diversity_g = batch_diversity(gan.generator.sample)\n\n    metrics = [accuracy_x_to_g, diversity_g]\n    sum_metrics = [0 for metric in metrics]\n    sampler = lookup_sampler(args.sampler or StaticBatchSampler)(gan)\n    for i in range(args.steps):\n        gan.step({gan.inputs.x: static_x, gan.encoder.sample: static_z})\n\n        if i % args.sample_every == 0:\n            print(""sampling ""+str(i))\n            sample_file = ""samples/""+str(i)+"".png""\n            sampler.sample(sample_file, args.save_samples)\n\n        if args.action == \'train\' and i % args.save_every == 0 and i > 0:\n            print(""saving "" + save_file)\n            gan.save(save_file)\n\n        if i > args.steps * 9.0/10:\n            for k, metric in enumerate(gan.session.run(metrics)):\n                print(""Metric ""+str(k)+"" ""+str(metric))\n                sum_metrics[k] += metric \n    return sum_metrics\n\ndef sample(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    sampler = lookup_sampler(args.sampler or RandomWalkSampler)(gan)\n    for i in range(args.steps):\n        sample_file = ""samples/""+str(i)+"".png""\n        sampler.sample(sample_file, args.save_samples)\n\ndef search(config, inputs, args):\n    metrics = train(config, inputs, args)\n    config_filename = ""static-""+str(uuid.uuid4())+\'.json\'\n    hc.Selector().save(config_filename, config)\n\n    with open(args.search_output, ""a"") as myfile:\n        myfile.write(config_filename+"",""+"","".join([str(x) for x in metrics])+""\\n"")\n\nif args.action == \'train\':\n    metrics = train(config, inputs, args)\n    print(""Resulting metrics:"", metrics)\nelif args.action == \'sample\':\n    sample(config, inputs, args)\nelif args.action == \'search\':\n    search(config, inputs, args)\nelse:\n    print(""Unknown action: ""+args.action)\n'"
hypergan/configurations/__init__.py,0,"b'""""""\nConfigurations are shared and reproducable `json` files used in `hypergan.gan_component`.\n""""""\n'"
hypergan/configurations/generate_readme.py,0,"b'from subprocess import call\n\nimport glob\n\ndirnames = glob.glob(""samples/*"")\n\nfor d in dirnames:\n    images = glob.glob(d+""/*.png"")\n\n    print("""")\n    print(""### ""+d)\n    images.sort()\n    for image in images:\n        print("""")\n        print(""![""+image+""](""+image+"")"")\n\n\n'"
hypergan/configurations/generate_samples.py,0,"b'from subprocess import call\n\nimport glob\n\nfilenames = glob.glob(""*.json"")\n\ncmd=""rm -rf samples""\nresult = call(cmd, shell=True)\n\nfor f in filenames:\n    config = f.split(""."")[0]\n\n    cmd=""CUDA_VISIBLE_DEVICES=0 hypergan train /ml/datasets/faces/128x128/all --sample_every 8000 --sampler debug --format jpg --size 64x64x3 -b 8 -c ./""+config+"" --resize --save_samples --steps 16001 --save_every 1000000""\n    print(cmd)\n    result = call(cmd, shell=True)\n\n    cmd=""mkdir samples/""+config\n    result = call(cmd, shell=True)\n\n    cmd=""mv samples/*.png samples/""+config\n    result = call(cmd, shell=True)\n\n\n'"
hypergan/configurations/replace_hyperparms.py,0,"b'from subprocess import call\n\nimport glob\n\nfilenames = glob.glob(""*.json"")\n\nfor f in filenames:\n    cmd = ""jq \'.loss.gradient_locally_stable=0.01\' ""+f+"" | awk \'BEGIN{RS=\\""\\"";getline<\\""-\\"";print>ARGV[1]}\' ""+f\n    print(cmd)\n    \n    result = call(cmd, shell=True)\n\n\n\n'"
hypergan/configurations/run_all.py,0,"b'# An example of how to run all the configuration files in the current directory, in parallel.\n# Usage: python3 run_all.py\n\nimport logging\nimport random\nimport threading\nimport time\nimport queue\nimport glob\nimport os\nimport json\n\nlogging.basicConfig(level=logging.DEBUG,\n                    format=\'(%(threadName)-10s) %(message)s\',\n                    )\nclass Trainer(object):\n    def __init__(self, card=0):\n        self.lock = threading.Lock()\n        self.card = card\n        self.steps = 100000\n        #number_samples = 60*25 # one minute video\n        number_samples = 10*25 # ten second video\n        self.sample_every = self.steps//number_samples\n        self.format = \'jpg\'\n        self.dataset = ""/ml/datasets/faces/128x128_sketched/all""\n        self.batch_size = 8\n    def run(self, json_file):\n        obj = json.loads(open(json_file+"".json"", \'r\').read())\n        if ""width"" in obj[""runtime""]:\n            size = "" --size ""+str(obj[""runtime""][""width""])+""x""+ str(obj[""runtime""][""height""])+""x""+str(obj[""runtime""][""channels""])\n        else:\n            print(""NULL SIZE"", obj)\n            size = """"\n        command = obj[""runtime""][""train""]\n        \n        logging.debug(\'Run %s on card %d\', json_file, self.card)\n        if os.path.exists(""samples/""+json_file):\n            logging.info(\'Skipping \'+json_file+\', samples exist\')\n        else:\n            command = (""CUDA_VISIBLE_DEVICES=%d "" % self.card) + command\n            command = command.replace(""[dataset]"", self.dataset)\n            command = command.replace(""[hypergan]"", ""/ml/dev/hypergan/"")\n            command += "" --sample_every %d -b %d --format %s -c %s --save_every %d --steps %d --save_samples --resize"" % (self.sample_every, self.batch_size, self.format, json_file, self.steps-1, self.steps)\n            command += size\n            logging.debug(command)\n            os.system(command)\n\ndef worker(c):\n    thread = threading.currentThread()\n    if queue.empty():\n        return\n    json_file = queue.get()\n    config = json_file.replace("".json"","""")\n    c.run(config)\n    worker(c)\n    queue.task_done()\n    logging.debug(\'Done\')\n\n\ngpus = []\ngpu_count = 2\ngpu_offset = 0\nper_gpu = 2\nqueue = queue.Queue()\n\n\nfiles = glob.glob(""*.json"")\n\nfor f in files:\n    queue.put(f)\n\nfor j in range(per_gpu):\n    for i in range(gpu_count):\n        gpu = Trainer(i+gpu_offset)\n\n        t=threading.Thread(target=worker, args=(gpu,))\n        gpus.append(t)\n        t.start()\n\nlogging.debug(\'Waiting for worker threads\')\nmain_thread = threading.currentThread()\n\nqueue.join()\n\nfor t in threading.enumerate():\n    if t is not main_thread:\n        t.join()\n\nlogging.debug(""Goodbye"")\n'"
hypergan/discriminators/__init__.py,0,"b'""""""\nThere are many different types of discriminators.  This is sometimes called critic.\n""""""\nfrom os.path import dirname, basename, isfile\nimport glob\nmodules = glob.glob(dirname(__file__)+""/*.py"")\n__all__ = [ basename(f)[:-3] for f in modules if isfile(f)]\n'"
hypergan/discriminators/base_discriminator.py,3,"b'from hypergan.gan_component import GANComponent\nimport tensorflow as tf\n\nclass BaseDiscriminator(GANComponent):\n    def __init__(self, gan, config, name=None, input=None, reuse=None, features=None):\n        self.input = input\n        self.name = name\n        self.features = features\n        GANComponent.__init__(self, gan, config, name=name, reuse=reuse)\n\n    def create(self, net=None):\n        config = self.config\n        gan = self.gan\n        ops = self.ops\n\n        net = net or self.input\n\n        net = self.build(net)\n        self.sample = net\n        return net\n\n    def reuse(self, net=None, **opts):\n        config = self.config\n        gan = self.gan\n        ops = self.ops\n\n        self.ops.reuse()\n        net = self.build(net, **opts)\n        self.ops.stop_reuse()\n\n        return net\n\n    def add_noise(self, net):\n        config = self.config\n        if not config.noise:\n            return net\n        print(""[discriminator] adding noise"", config.noise)\n        net += tf.random_normal(net.get_shape(), mean=0, stddev=config.noise, dtype=tf.float32)\n        return net\n\n    def resize(self, config, x, g):\n        if(config.resize):\n            # shave off layers >= resize \n            def should_ignore_layer(layer, resize):\n                return int(layer.get_shape()[1]) > config[\'resize\'][0] or \\\n                       int(layer.get_shape()[2]) > config[\'resize\'][1]\n\n            xs = [px for px in xs if not should_ignore_layer(px, config[\'resize\'])]\n            gs = [pg for pg in gs if not should_ignore_layer(pg, config[\'resize\'])]\n\n            x = tf.image.resize_images(x,config[\'resize\'], 1)\n            g = tf.image.resize_images(g,config[\'resize\'], 1)\n\n        else:\n            return x, g\n\n\n'"
hypergan/discriminators/common.py,5,"b'import tensorflow as tf\nimport hyperchamber as hc\n\ndef densenet_block(component, net, depth, filter=3, padding=\'SAME\'):\n    ops = component.ops\n    config = component.config\n    layer_regularizer = config.layer_regularizer\n    net = standard_block(component, net, depth, filter=1, avg_pool=False)\n    for i in range(config.densenet_layers):\n        depth = config.densenet_filters\n        net = config.activation(net)\n        net2 = component.layer_regularizer(net)\n        net2 = ops.conv2d(net2, 3, 3, 1, 1, depth)\n        net = tf.concat([net, net2], 3)\n        print(""New densenet layer"", net)\n    stride = [1,filter-1,filter-1,1]\n    ksize = [1,filter-1,filter-1,1]\n    net = tf.nn.avg_pool(net, ksize=ksize, strides=stride, padding=\'SAME\')\n    return net\n\ndef repeating_block(component, net, depth, filter=3):\n    ops = component.ops\n    config = component.config\n    layer_regularizer = config.layer_regularizer\n    ksize = [1,filter-1,filter-1,1]\n    stride = [1,filter-1,filter-1,1]\n    for i in range(config.block_repeat_count-1):\n        net = config.activation(net)\n        if layer_regularizer is not None:\n            net = component.layer_regularizer(net)\n        net = ops.conv2d(net, 3, 3, 1, 1, depth)\n        print(""[discriminator] hidden layer"", net)\n\n    net = tf.nn.avg_pool(net, ksize=ksize, strides=stride, padding=\'SAME\')\n    print(\'[discriminator] layer\', net)\n    return net\n\ndef multi_block(component, net, depth, filter=3):\n    ops = component.ops\n    config = component.config\n    layer_regularizer = config.layer_regularizer\n    ksize = [1,filter-1,filter-1,1]\n    stride = [1,filter-1,filter-1,1]\n\n    net = standard_block(component, net, depth, filter=filter, avg_pool=False)\n    net2 = standard_block(component, net, depth, filter=filter, avg_pool=False, activation_regularizer=True)\n    net3 = standard_block(component, net2, depth, filter=filter, avg_pool=False, activation_regularizer=True)\n    net = net+net2+net3\n\n    net = tf.nn.avg_pool(net, ksize=ksize, strides=stride, padding=\'SAME\')\n    print(\'[discriminator] layer\', net)\n    return net\n\ndef repeating_strided_block(component, net, depth, filter=3):\n    ops = component.ops\n    config = component.config\n    layer_regularizer = config.layer_regularizer\n    ksize = [1,filter-1,filter-1,1]\n    stride = [1,filter-1,filter-1,1]\n    for i in range(config.block_repeat_count-1):\n        net = config.activation(net)\n        if layer_regularizer is not None:\n            net = component.layer_regularizer(net)\n        if i== config.block_repeat_count-2:\n            net = ops.conv2d(net, 3, 3, 2, 2, depth)\n        else:\n            net = ops.conv2d(net, 3, 3, 1, 1, depth)\n        print(""[discriminator] hidden layer"", net)\n\n    print(\'[discriminator] layer\', net)\n    return net\n\n\ndef standard_block(component, net, depth, filter=3, avg_pool=True, activation_regularizer=False, padding=""SAME""):\n    ops = component.ops\n    config = component.config\n    stride_w = filter-1\n    stride_h = filter-1\n    ksize = [1,filter-1,filter-1,1]\n    stride = [1,stride_w,stride_h,1]\n    layer_regularizer = config.layer_regularizer\n\n    if activation_regularizer:\n        net = config.activation(net)\n        if layer_regularizer is not None:\n            net = component.layer_regularizer(net)\n\n    print(""PREB LOCK IS "", net)\n    net = ops.conv2d(net, filter, filter, 1, 1, depth, padding=padding)\n    print(""POST BLOCK IS "", net)\n    if avg_pool:\n        net = tf.nn.avg_pool(net, ksize=ksize, strides=stride, padding=\'SAME\')\n    print(\'[discriminator] layer\', net)\n    return net\n\ndef strided_block(component, net, depth, filter=3, padding=""SAME""):\n    ops = component.ops\n    config = component.config\n    net = ops.conv2d(net, filter, filter, 2, 2, depth, padding=padding)\n    print(\'[discriminator] layer\', net)\n    return net\n'"
hypergan/discriminators/configurable_discriminator.py,3,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport inspect\nimport copy\nimport os\nimport operator\nfrom functools import reduce\n\nfrom hypergan.ops.tensorflow.extended_ops import bicubic_interp_2d\nfrom .base_discriminator import BaseDiscriminator\nfrom hypergan.configurable_component import ConfigurableComponent\n\nclass ConfigurableDiscriminator(BaseDiscriminator, ConfigurableComponent):\n    def __init__(self, gan, config, name=None, input=None, reuse=None, features=[], skip_connections=[]):\n        ConfigurableComponent.__init__(self, gan, config, name=name, input=input,features=features,reuse=reuse)\n        BaseDiscriminator.__init__(self, gan, config, name=name, input=input,features=features,reuse=reuse)\n\n    def layer_filter(self, net, args=[], options={}):\n        config = self.config\n        gan = self.gan\n        ops = self.ops\n        concats = []\n\n        if \'layer_filter\' in config and config.layer_filter is not None:\n            print(""[discriminator] applying layer filter"", config[\'layer_filter\'])\n            filters = []\n            stacks = self.ops.shape(net)[0] // gan.batch_size()\n            for stack in range(stacks):\n                piece = tf.slice(net, [stack * gan.batch_size(), 0,0,0], [gan.batch_size(), -1, -1, -1])\n                filters.append(ConfigurableComponent.layer_filter(self, piece, args, options))\n            layer = tf.concat(axis=0, values=filters)\n            concats.append(layer)\n\n        if len(concats) > 1:\n            net = tf.concat(axis=3, values=concats)\n\n        return net\n'"
hypergan/discriminators/dcgan_discriminator.py,0,"b""import tensorflow as tf\nimport hyperchamber as hc\nfrom hypergan.discriminators.common import *\nimport inspect\nimport os\n\nfrom .base_discriminator import BaseDiscriminator\n\nclass DCGANDiscriminator(BaseDiscriminator):\n\n    def required(self):\n        return []\n\n    def build(self, net):\n        config = self.config\n        gan = self.gan\n        ops = self.ops\n        activation = ops.lookup(config.activation or 'lrelu')\n        improved = config.improved\n\n        net = self.add_noise(net)\n        net = ops.conv2d(net, 3, 3, 2, 2, 64)\n        if improved:\n            net = self.layer_regularizer(net)\n        net = activation(net)\n        for layer in range(3):\n            net = ops.conv2d(net, 3, 3, 2, 2, ops.shape(net)[-1]*2)\n            net = self.layer_regularizer(net)\n            net = activation(net)\n        net = ops.reshape(net, [ops.shape(net)[0],-1])\n        net = ops.linear(net, config.final_features or 1, bias=False)\n        if improved:\n            net = self.layer_regularizer(net)\n            net = activation(net)\n\n        return net\n\n"""
hypergan/distributions/__init__.py,0,"b'""""""\nEncoders are the beginning of the network.  In `dcgan` it is a single projection of random noise.\n""""""\nfrom os.path import dirname, basename, isfile\nimport glob\nmodules = glob.glob(dirname(__file__)+""/*.py"")\n__all__ = [ basename(f)[:-3] for f in modules if isfile(f)]\n'"
hypergan/distributions/base_distribution.py,0,b'from hypergan.gan_component import GANComponent\n\nclass BaseDistribution(GANComponent):\n    pass\n'
hypergan/distributions/uniform_distribution.py,26,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nfrom .base_distribution import BaseDistribution\n\nfrom ..gan_component import ValidationException\n\nTINY=1e-12\n\nclass UniformDistribution(BaseDistribution):\n    def __init__(self, gan, config, name=""LatentDistribution"", output_shape=None, z=None):\n        self.output_shape = output_shape\n        self.z = z\n        BaseDistribution.__init__(self, gan, config, name=name)\n\n    def required(self):\n        return """".split()\n\n    def validate(self):\n        errors = BaseDistribution.validate(self)\n        #if(self.config.z is not None and int(self.config.z) % 2 != 0):\n        #    errors.append(""z must be a multiple of 2 (was %2d)"" % self.config.z)\n        return errors\n\n    def create(self):\n        gan = self.gan\n        ops = self.ops\n        config = self.config\n        projections = []\n        batch_size = self.gan.batch_size()\n        if self.z is None:\n            output_shape = self.output_shape or [batch_size, int(config.z)]\n            self.z = tf.random_uniform(output_shape, config.min or -1, config.max or 1, dtype=ops.dtype)\n\n        if \'projections\' in config:\n            for projection in config.projections:\n                projections.append(self.lookup(projection)(config, gan, self.z))\n        else:\n                projections.append(self.z)\n        self.sample = tf.concat(axis=len(self.z.get_shape())-1, values=projections)\n        return self.sample\n\n    def lookup(self, projection):\n        if callable(projection):\n            return projection\n        if projection == \'identity\':\n            return identity\n        if projection == \'sphere\':\n            return sphere\n        if projection == \'gaussian\':\n            return gaussian\n        if projection == \'periodic\':\n            return periodic\n        return self.ops.lookup(projection)\n        \n\ndef identity(config, gan, net):\n    return net\n\ndef sphere(config, gan, net):\n    net = gaussian(config, gan, net)\n    spherenet = tf.square(net)\n    if len(spherenet.get_shape()) == 2:\n        spherenet = tf.reduce_sum(spherenet, 1)\n        lam = tf.sqrt(spherenet+TINY)\n        return net/tf.reshape(lam,[int(lam.get_shape()[0]), 1])\n    else:\n        spherenet = tf.reduce_sum(spherenet, 3)\n        lam = tf.sqrt(spherenet+TINY)\n        return net/tf.reshape(lam,[int(lam.get_shape()[0]), int(lam.get_shape()[1]), int(lam.get_shape()[2]), 1])\n\ndef modal(config, gan, net):\n    net = tf.round(net*float(config.modes))/float(config.modes)\n    return net\n\ndef binary(config, gan, net):\n    net = tf.greater(net, 0)\n    net = tf.cast(net, tf.float32)\n    return net\n\ndef zero(config, gan, net):\n    return tf.zeros_like(net)\n\ndef modal_gaussian(config, gan, net):\n    a = modal(config, gan, net)\n    b = gaussian(config, gan, net)\n    return a + b * 0.1\n\ndef modal_sphere(config, gan, net):\n    net = gaussian(config, gan, net)\n    net = modal(config, gan, net)\n    spherenet = tf.square(net)\n    spherenet = tf.reduce_sum(spherenet, 1)\n    lam = tf.sqrt(spherenet+TINY)\n    return net/tf.reshape(lam,[int(lam.get_shape()[0]), 1])\n\ndef modal_sphere_gaussian(config, gan, net):\n    net = modal_sphere(config, gan, net)\n    return net + (gaussian(config, gan, net) * 0.01)\n\n# creates normal distribution from uniform values https://en.wikipedia.org/wiki/Box%E2%80%93Muller_transform\ndef gaussian(config, gan, net):\n    z_dim = net.get_shape().as_list()[-1]\n    net = (net + 1) / 2\n\n    if len(gan.ops.shape(net)) == 4:\n        za = tf.slice(net, [0,0,0,0], [gan.batch_size(), -1, -1, z_dim//2])\n        zb = tf.slice(net, [0,0,0,z_dim//2], [gan.batch_size(), -1, -1, z_dim//2])\n    else:\n        za = tf.slice(net, [0,0], [gan.batch_size(), z_dim//2])\n        zb = tf.slice(net, [0,z_dim//2], [gan.batch_size(), z_dim//2])\n\n    pi = np.pi\n    ra = tf.sqrt(-2 * tf.log(za+TINY))*tf.cos(2*pi*zb)\n    rb = tf.sqrt(-2 * tf.log(za+TINY))*tf.sin(2*pi*zb)\n\n    return tf.reshape(tf.concat(axis=len(net.get_shape())-1, values=[ra, rb]), net.get_shape())\n\n\ndef periodic(config, gan, net):\n    return periodic_triangle_waveform(net, config.periods)\n\ndef periodic_gaussian(config, gan, net):\n    net = periodic_triangle_waveform(net, config.periods)\n    return gaussian(config, gan, net)\n\ndef periodic_triangle_waveform(z, p):\n    return 2.0 / np.pi * tf.asin(tf.sin(2*np.pi*z/p))\n\ndef bounded(net):\n    minim = -1\n    maxim = 1\n    return tf.minimum(tf.maximum(net, minim), maxim)\n'"
hypergan/gans/__init__.py,0,"b'""""""\nGANs combine `hypergan.gan_component`s into unique compositions.\n""""""\n'"
hypergan/gans/ali_gan.py,24,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom .base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass AliGAN(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `encoder`  encodes X into Z\n        `discriminator`  measures X and G.\n        `generator` produces samples\n        """"""\n        return ""generator discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n        d_losses = []\n        g_losses = []\n\n        def random_like(x):\n            return UniformDistribution(self, config.latent, output_shape=self.ops.shape(x)).sample\n        with tf.device(self.device):\n            x_input = tf.identity(self.inputs.x, name=\'input\')\n\n            # q(z|x)\n            latent = UniformDistribution(self, config.latent)\n            self.latent = latent\n            encoder = self.create_encoder(self.inputs.x)\n            self.encoder = encoder\n \n            direction, slider = self.create_controls(self.ops.shape(latent.sample))\n            z = latent.sample + slider * direction\n            #projected_encoder = UniformDistribution(self, config.encoder, z=encoder.sample)\n\n\n            feature_dim = len(ops.shape(z))-1\n            #stack_z = tf.concat([encoder.sample, z], feature_dim)\n            #stack_encoded = tf.concat([encoder.sample, encoder.sample], feature_dim)\n\n\n            if config.u_to_z:\n                if config.style_encoder:\n                    style_encoder = self.create_component(config.style_encoder, input=x_input, name=\'style_encoder\')\n                    style = style_encoder.sample\n                    #style_sample = tf.concat(style, axis=0)\n                    style_sample = style\n                    #style_sample=random_like(style_sample)\n                    #x_hat_style = style_sample\n                    x_hat_style = random_like(style_sample)\n                    #style_sample =  random_like(x_hat_style)\n                    u_to_z = self.create_component(config.u_to_z, name=\'u_to_z\', features=[style_sample], input=z)\n                    generator = self.create_component(config.generator, input=u_to_z.sample, features=[style_sample], name=\'generator\')\n                else:\n                    u_to_z = self.create_component(config.u_to_z, name=\'u_to_z\', input=z)\n                    generator = self.create_component(config.generator, input=u_to_z.sample, name=\'generator\')\n                stacked = [x_input, generator.sample]\n                self.generator = generator\n\n                self.encoder = encoder\n                features = [encoder.sample, u_to_z.sample]\n                if self.config.reencode:\n                    er = self.create_encoder(generator.sample, reuse=True)\n                    features = [encoder.sample, er.sample]\n\n                self.u_to_z = u_to_z\n            else:\n                er = encoder.sample\n                generator = self.create_component(config.generator, input=er, name=\'generator\')\n                if self.config.reencode:\n                    self.reencode = self.create_encoder(generator.sample, reuse=True)\n                    er = self.reencode.sample\n                self.generator = generator\n                stacked = [x_input, generator.sample]\n\n                self.encoder = encoder\n                features = ops.concat([encoder.sample, er], axis=0)\n\n            if config.style_encoder:\n                x_hat = self.create_component(config.generator, input=encoder.sample, features=[x_hat_style], reuse=True, name=\'generator\').sample\n                stacked += [x_hat]\n                features += [encoder.sample]\n            else:\n                x_hat = self.create_component(config.generator, input=encoder.sample, reuse=True, name=\'generator\').sample\n            self.autoencoded_x = x_hat\n            self.uniform_sample = generator.sample\n\n            stacked_xg = tf.concat(stacked, axis=0)\n            features_zs = tf.concat(features, axis=0)\n            self.features = features_zs\n\n            standard_discriminator = self.create_component(config.discriminator, name=\'discriminator\', input=stacked_xg, features=[features_zs])\n            self.discriminator = standard_discriminator\n\n            d_vars = standard_discriminator.variables()\n            g_vars = generator.variables() + encoder.variables()\n            if config.style_encoder:\n                g_vars += style_encoder.variables()\n            if config.u_to_z:\n                g_vars += u_to_z.variables()\n\n            if self.config.manifold_guided:\n                reencode_u_to_z = self.create_encoder(generator.sample, reuse=True)\n                #stack_z = [encoder.sample, u_to_z.sample]#reencode_u_to_z.sample]\n                if self.config.manifold_target == \'reencode_u_to_z\':\n                    stack_z = [encoder.sample, reencode_u_to_z.sample]\n                else:\n                    stack_z = [encoder.sample, u_to_z.sample]#reencode_u_to_z.sample]\n                if self.config.terms == ""eg:ex"":\n                    stack_z = [reencode_u_to_z.sample, encoder.sample]\n                if self.config.terms == ""ex:eg"":\n                    stack_z = [encoder.sample, reencode_u_to_z.sample]\n                if self.config.stop_gradients:\n                    stack_z = [tf.stop_gradient(encoder.sample), u_to_z.sample]#reencode_u_to_z.sample]\n                stacked_zs = ops.concat(stack_z, axis=0)\n                z_discriminator = self.create_component(config.z_discriminator, name=\'z_discriminator\', input=stacked_zs)\n                self.z_discriminator = z_discriminator\n                d_vars += z_discriminator.variables()\n\n            self._g_vars = g_vars\n            self._d_vars = d_vars\n            standard_loss = self.create_loss(config.loss, standard_discriminator, x_input, generator, len(stacked))\n            self.standard_loss = standard_loss\n\n            loss1 = [""g_loss"", standard_loss.g_loss]\n            loss2 = [""d_loss"", standard_loss.d_loss]\n\n            if self.config.manifold_guided:\n                l2 = self.create_loss(config.loss, z_discriminator, x_input, generator, len(stack_z), reuse=True)\n                d_losses.append(l2.d_loss)\n                g_losses.append(l2.g_loss)\n\n            d_losses.append(standard_loss.d_loss)\n            g_losses.append(standard_loss.g_loss)\n            if self.config.autoencode:\n                l2_loss = self.ops.squash(10*tf.square(x_hat - x_input))\n                g_losses=[l2_loss]\n                d_losses=[l2_loss]\n            if self.config.vae:\n                mu,sigma = self.encoder.variational\n                eps = 1e-8\n                lam = config.vae_lambda or 0.001\n                latent_loss = lam*(0.5 *self.ops.squash(tf.square(mu)-tf.square(sigma) - tf.log(tf.square(sigma)+eps) - 1, tf.reduce_sum ))\n                g_losses.append(latent_loss)\n                mu,sigma = u_to_z.variational\n                latent_loss = lam*(0.5 *self.ops.squash(tf.square(mu)-tf.square(sigma) - tf.log(tf.square(sigma)+eps) - 1, tf.reduce_sum ))\n                g_losses.append(latent_loss)\n\n\n            for i,l in enumerate(g_losses):\n                self.add_metric(\'gl\'+str(i), l)\n            for i,l in enumerate(d_losses):\n                self.add_metric(\'dl\'+str(i),l)\n            loss = hc.Config({\n                \'d_fake\':standard_loss.d_fake,\n                \'d_real\':standard_loss.d_real,\n                \'sample\': [tf.add_n(d_losses), tf.add_n(g_losses)]\n            })\n            self.loss = loss\n            trainer = self.create_component(config.trainer, g_vars = g_vars, d_vars = d_vars)\n\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = generator\n        self.slider = slider\n        self.direction = direction\n        self.z = z\n        self.z_hat = encoder.sample\n        self.x_input = x_input\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n        self.random_z = tf.random_uniform(ops.shape(latent.sample), -1, 1, name=\'random_z\')\n\n        if hasattr(generator, \'mask_generator\'):\n            self.mask_generator = generator.mask_generator\n            self.mask = mask\n            self.autoencode_mask = generator.mask_generator.sample\n            self.autoencode_mask_3_channel = generator.mask\n\n\n    def create_discriminator(self, _input, reuse=False):\n        return self.create_component(self.config.discriminator, name=\'discriminator\', input=_input, features=[tf.zeros_like(self.features)], reuse=reuse)\n    def fitness_inputs(self):\n        return [\n                self.latent.sample\n                ]\n\n    def l1_distance(self):\n        return self.inputs.x - self.autoencoded_x\n\n\n    def create_generator(self, _input, reuse=False):\n        config = self.config\n        if self.ops.shape(_input) == self.ops.shape(self.gan.latent.sample):\n            u_to_z = self.create_component(config.u_to_z, name=\'u_to_z\', input=_input, reuse=reuse)\n            generator = self.create_component(config.generator, input=u_to_z.sample, name=\'generator\', reuse=reuse)\n        else:\n            generator = self.create_component(config.generator, input=_input, name=\'generator\', reuse=reuse)\n\n        return generator\n\n    def create_loss(self, loss_config, discriminator, x, generator, split, reuse=False):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator.sample, split=split, reuse=reuse)\n        return loss\n\n    def create_controls(self, z_shape):\n        direction = tf.random_normal(z_shape, stddev=0.3, name=\'direction\')\n        slider = tf.get_variable(\'slider\', initializer=tf.constant_initializer(0.0), shape=[1, 1], dtype=tf.float32, trainable=False)\n        return direction, slider\n\n    def create_encoder(self, x_input, name=\'encoder\', reuse=False):\n        config = self.config\n        encoder = dict(config.encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(encoder, name=name, input=x_input, reuse=reuse)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input,\n                self.slider, \n                self.direction,\n                self.latent.sample\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int,\n                self.random_z\n        ]\n\n    def g_vars(self):\n        return self._g_vars\n    def d_vars(self):\n        return self._d_vars\n'"
hypergan/gans/base_gan.py,40,"b'import hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom hypergan.skip_connections import SkipConnections\n\nimport re\nimport os\nimport inspect\nimport hypergan as hg\nimport tensorflow as tf\nimport numpy as np\n\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.tools import freeze_graph\nfrom tensorflow.python.tools import optimize_for_inference_lib\n\nfrom hypergan.samplers.static_batch_sampler import StaticBatchSampler\nfrom hypergan.samplers.progressive_sampler import ProgressiveSampler\nfrom hypergan.samplers.batch_sampler import BatchSampler\nfrom hypergan.samplers.batch_walk_sampler import BatchWalkSampler\nfrom hypergan.samplers.grid_sampler import GridSampler\nfrom hypergan.samplers.sorted_sampler import SortedSampler\nfrom hypergan.samplers.began_sampler import BeganSampler\nfrom hypergan.samplers.aligned_sampler import AlignedSampler\nfrom hypergan.samplers.autoencode_sampler import AutoencodeSampler\nfrom hypergan.samplers.random_walk_sampler import RandomWalkSampler\nfrom hypergan.samplers.style_walk_sampler import StyleWalkSampler\nfrom hypergan.samplers.alphagan_random_walk_sampler import AlphaganRandomWalkSampler\nfrom hypergan.samplers.debug_sampler import DebugSampler\nfrom hypergan.samplers.segment_sampler import SegmentSampler\nfrom hypergan.samplers.y_sampler import YSampler\nfrom hypergan.samplers.gang_sampler import GangSampler\n\nclass BaseGAN(GANComponent):\n    def __init__(self, config=None, inputs=None, device=\'/gpu:0\', ops_config=None, ops_backend=TensorflowOps, graph=None,\n            batch_size=None, width=None, height=None, channels=None, debug=None, session=None, name=""hypergan""):\n        """""" Initialized a new GAN.""""""\n        self.inputs = inputs\n        self.device = device\n        self.ops_backend = ops_backend\n        self.ops_config = ops_config\n        self.components = []\n        self._batch_size = batch_size\n        self._width = width\n        self._height = height\n        self._channels = channels\n        self.debug = debug\n        self.name = name\n        self.session = session\n        self.skip_connections = SkipConnections()\n        self.destroy = False\n        if graph is None:\n            graph = tf.get_default_graph()\n        self.graph = graph\n\n        if config == None:\n            config = hg.Configuration.default()\n\n        if debug and not isinstance(self.session, tf_debug.LocalCLIDebugWrapperSession):\n            self.session = tf_debug.LocalCLIDebugWrapperSession(self.session)\n            self.session.add_tensor_filter(""has_inf_or_nan"", tf_debug.has_inf_or_nan)\n        else:\n            tfconfig = tf.ConfigProto(allow_soft_placement=True)\n            #tfconfig = tf.ConfigProto(log_device_placement=True)\n            tfconfig.gpu_options.allow_growth=True\n\n            with tf.device(self.device):\n                self.session = self.session or tf.Session(config=tfconfig, graph=graph)\n\n        self.global_step = tf.Variable(0, trainable=False, name=\'global_step\')\n        self.steps = tf.Variable(0, trainable=False, name=\'global_step\')\n        self.increment_step = tf.assign(self.steps, self.steps+1)\n        if config.fixed_input:\n            self.feed_x = self.inputs.x\n            self.inputs.x = tf.Variable(tf.zeros_like(self.feed_x))\n            self.set_x = tf.assign(self.inputs.x, self.feed_x)\n\n        if config.fixed_input_xa:\n            self.feed_x = self.inputs.xa\n            self.inputs.xa = tf.Variable(tf.zeros_like(self.feed_x))\n            self.set_x = tf.assign(self.inputs.xa, self.feed_x)\n            self.feed_x = self.inputs.xb\n            self.inputs.xb = tf.Variable(tf.zeros_like(self.feed_x))\n            self.set_x = tf.group([self.set_x, tf.assign(self.inputs.xb, self.feed_x)])\n            self.inputs.x = self.inputs.xb\n\n\n\n        # A GAN as a component has a parent of itself\n        # gan.gan.gan.gan.gan.gan\n        GANComponent.__init__(self, self, config, name=self.name)\n        self.ops.debug = debug\n\n    def batch_size(self):\n        if self._batch_size:\n            return self._batch_size\n        if self.inputs == None:\n            raise ValidationException(""gan.batch_size() requested but no inputs provided"")\n        return self.ops.shape(self.inputs.x)[0]\n\n    def sample_mixture(self):\n        diff = self.inputs.x - self.generator.sample\n        alpha = tf.random_uniform(shape=self.ops.shape(self.generator.sample), minval=0., maxval=1.0)\n        return self.inputs.x + alpha * diff\n\n    def channels(self):\n        if self._channels:\n            return self._channels\n        if self.inputs == None:\n            raise ValidationException(""gan.channels() requested but no inputs provided"")\n        return self.ops.shape(self.inputs.x)[-1]\n\n    def width(self):\n        if self._width:\n            return self._width\n        if self.inputs == None:\n            raise ValidationException(""gan.width() requested but no inputs provided"")\n        return self.ops.shape(self.inputs.x)[2]\n\n    def height(self):\n        if self._height:\n            return self._height\n        if self.inputs == None:\n            raise ValidationException(""gan.height() requested but no inputs provided"")\n        return self.ops.shape(self.inputs.x)[1]\n\n    def output_shape(self):\n        return [self.width(), self.height(), self.channels()]\n\n    def l1_distance(self):\n        return self.inputs.x - self.generator.sample\n\n    def get_config_value(self, symbol):\n        if symbol in self.config:\n            config = hc.Config(hc.lookup_functions(self.config[symbol]))\n            return config\n        return None\n\n    def create_component(self, defn, *args, **kw_args):\n        if defn == None:\n            return None\n        if defn[\'class\'] == None:\n            raise ValidationException(""Component definition is missing \'"" + name + ""\'"")\n        print(\'class\', defn[\'class\'], self.ops.lookup(defn[\'class\']))\n        gan_component = self.ops.lookup(defn[\'class\'])(self, defn, *args, **kw_args)\n        self.components.append(gan_component)\n        return gan_component\n\n    def create_optimizer(self, options):\n        options = hc.lookup_functions(options)\n        klass = options[\'class\']\n        newopts = options.copy()\n        newopts[\'gan\']=self.gan\n        newopts[\'config\']=options\n        defn = {k: v for k, v in newopts.items() if k in inspect.getargspec(klass).args}\n        learn_rate = options.learn_rate or options.learning_rate\n        if \'learning_rate\' in options:\n            del defn[\'learning_rate\']\n        gan_component = klass(learn_rate, **defn)\n        self.components.append(gan_component)\n        return gan_component\n\n    def create_loss(self, discriminator, reuse=False, split=2):\n        loss = self.create_component(self.config.loss, discriminator = discriminator, split=split, reuse=reuse)\n        return loss\n    def create_generator(self, _input, reuse=False):\n        return self.gan.create_component(self.gan.config.generator, name=\'generator\', input=_input, reuse=reuse)\n\n    def create_discriminator(self, _input, reuse=False):\n        return self.gan.create_component(self.gan.config.discriminator, name=""discriminator"", input=_input, reuse=True)\n\n    def create(self):\n        print(""Warning: BaseGAN.create() called directly.  Please override"")\n\n    def step(self, feed_dict={}):\n        self.step_count = self.session.run(self.increment_step)\n        return self._step(feed_dict)\n\n    def _step(self, feed_dict={}):\n        if self.trainer == None:\n            raise ValidationException(""gan.trainer is missing.  Cannot train."")\n        return self.trainer.step(feed_dict)\n\n    def g_vars(self):\n        return self.generator.variables()\n    def d_vars(self):\n        return self.discriminator.variables()\n\n    def trainable_vars(self):\n        return self.trainable_d_vars(), self.trainable_g_vars()\n\n    def trainable_d_vars(self):\n        return list(set(self.d_vars()).intersection(tf.trainable_variables()))\n\n    def trainable_g_vars(self):\n        return list(set(self.g_vars()).intersection(tf.trainable_variables()))\n\n    def save(self, save_file):\n        if(np.any(np.isnan(self.session.run(self.loss.d_fake)))):\n            print(""[Error] NAN detected.  Refusing to save"")\n            exit()\n\n        with self.graph.as_default():\n            print(""[hypergan] Saving network to "", save_file)\n            os.makedirs(os.path.expanduser(os.path.dirname(save_file)), exist_ok=True)\n            saver = tf.train.Saver(self.variables())\n            print(""Saving "" +str(len(self.variables()))+ "" variables: "")\n            missing = set(tf.global_variables()) - set(self.variables())\n            missing = [ o for o in missing if ""dontsave"" not in o.name ]\n            if(len(missing) > 0):\n                print(""[hypergan] Warning: Variables on graph but not saved:"", missing)\n            saver.save(self.session, save_file)\n\n\n    def load(self, save_file):\n        save_file = os.path.expanduser(save_file)\n        if os.path.isfile(save_file) or os.path.isfile(save_file + "".index"" ):\n            print(""[hypergan] |= Loading network from ""+ save_file)\n            dir = os.path.dirname(save_file)\n            print(""[hypergan] |= Loading checkpoint from ""+ dir)\n            ckpt = tf.train.get_checkpoint_state(os.path.expanduser(dir))\n            if ckpt and ckpt.model_checkpoint_path:\n                self.optimistic_restore(self.session, save_file, self.variables())\n                return True\n            else:\n                return False\n        else:\n            return False\n\n    def optimistic_restore(self, session, save_file, variables):\n        reader = tf.train.NewCheckpointReader(save_file)\n        saved_shapes = reader.get_variable_to_shape_map()\n        var_names = sorted([(var.name, var.name.split(\':\')[0]) for var in variables\n                if var.name.split(\':\')[0] in saved_shapes])\n        restore_vars = []\n        post_restore_vars = []\n        name2var = dict(zip(map(lambda x:x.name.split(\':\')[0], variables), variables))\n        with tf.variable_scope(\'\', reuse=True):\n            for var_name, saved_var_name in var_names:\n                curr_var = name2var[saved_var_name]\n                var_shape = curr_var.get_shape().as_list()\n                if saved_shapes[saved_var_name] is None:\n                    print("" (load) No variable found, weights discarded"", saved_var_name)\n                if saved_shapes[saved_var_name] != var_shape:\n                    #print("" (load) Shapes do not match, weights discarded"", saved_var_name, var_shape, "" vs loaded "", saved_shapes[saved_var_name])\n                    print("" (load) Shapes do not match, extra reinitialized"", saved_var_name, var_shape, "" vs loaded "", saved_shapes[saved_var_name], curr_var)\n                    saved_var = tf.zeros(saved_shapes[saved_var_name])\n                    s1 = self.ops.shape(curr_var)\n                    s2 = saved_shapes[saved_var_name]\n                    new_var = saved_var\n\n                    for i, (_s1, _s2) in enumerate(zip(s1, s2)):\n                        if _s1 > _s2:\n                            s3 = self.ops.shape(new_var)\n                            ns = [i for i in s3]\n                            ns[i] = s1[i] - s2[i]\n\n                            curr_var_remainder = tf.slice(curr_var, [0 for i in s1], ns)\n                            new_var = tf.concat([new_var, curr_var_remainder], axis=i)\n\n                        elif _s2 > _s1:\n                            ns = [-1 for i in s1]\n                            ns[i] = _s1\n\n                            new_var = tf.slice(curr_var, [0 for i in s1], ns)\n\n                    post_restore_op = tf.assign(curr_var, new_var)\n                    post_restore_vars.append([post_restore_op, saved_var, reader.get_tensor(saved_var_name)])\n\n                if var_shape == saved_shapes[saved_var_name]:\n                    restore_vars.append(curr_var)\n        saver = tf.train.Saver(restore_vars)\n        saver.restore(session, save_file)\n\n        for op, var, val in post_restore_vars:\n            self.gan.session.run(op, {var: val})\n\n    def variables(self):\n        return list(set(self.ops.variables() + sum([c.variables() for c in self.components], []))) + [self.global_step, self.steps]\n\n    def weights(self):\n        return self.ops.weights + sum([c.ops.weights for c in self.components], [])\n\n    def inputs(self):\n        """"""inputs() returns any input tensors""""""\n        return sum([x.inputs() for x in self.components],[])\n\n\n    def metrics(self):\n        metrics = {}\n        for metric in self._metrics:\n            metrics[metric[\'name\']]=metric[\'value\']\n        for c in self.components:\n            try:\n                metrics.update(c.metrics())\n            except AttributeError:\n                pass\n        return metrics\n\n    def layer_options(self, l):\n        for component in self.components:\n            if hasattr(component, ""layer_options""):\n                if l in component.layer_options:\n                    return component.layer_options[l]\n        return None\n\n    def configurable_param(self, string):\n        self.param_ops = {\n            ""decay"": self.configurable_params_decay,\n            ""on"": self.configurable_params_turn_on\n        }\n        if isinstance(string, str):\n            if re.match(""^\\d+$"", string):\n                return int(string)\n            if re.match(""^\\d+?\\.\\d+?$"", string):\n                return float(string)\n            if ""("" not in string:\n                return string\n\n            method_name, inner = string.split(""("")\n            inner = inner.replace("")"", """")\n            if method_name not in self.param_ops:\n                raise ValidationException(""configurable param cannot find method: ""+ method_name + "" in string ""+string)\n            args, options = self.parse_args(inner.split("" ""))\n            result = self.param_ops[method_name](args, options)\n            if ""metric"" in options:\n                self.add_metric(options[""metric""], result)\n            return result\n        return string\n\n    def parse_args(self, strs):\n        options = hc.Config({})\n        args = []\n        for x in strs:\n            if \'=\' in x:\n                lhs, rhs = x.split(\'=\')\n                options[lhs]=rhs\n            else:\n                args.append(x)\n        return args, options\n\n    def configurable_params_decay(self, args, options):\n        _range = options.range or ""0:1""\n        steps = int(options.steps or 10000)\n        start = int(options.start or 0)\n        r1,r2 = _range.split("":"")\n        r1 = float(r1)\n        r2 = float(r2)\n        cycle = ""cycle"" in args\n        repeat = ""repeat"" in args\n        current_step = self.gan.steps\n        if repeat:\n            current_step %= steps\n        if start == 0:\n            return tf.train.polynomial_decay(r1, current_step, steps, end_learning_rate=r2, power=1, cycle=cycle)\n        else:\n            start = tf.constant(start, dtype=tf.int32)\n            steps = tf.constant(steps, dtype=tf.int32)\n            onoff = tf.minimum(1.0, tf.cast(tf.nn.relu(current_step - start), tf.float32))\n            return (1.0 - onoff)*r1 + onoff * tf.train.polynomial_decay(r1, tf.to_float(current_step-start), tf.to_float(steps), end_learning_rate=r2, power=1.0, cycle=cycle)\n\n    def configurable_params_turn_on(self, args, options):\n        offset = float(options[""offset""]) or 0.0\n        if ""random"" in args:\n            onvalue = float(options[""onvalue""]) or 1.0\n            n = tf.random_uniform([1], minval=-1, maxval=1)\n            n += tf.constant(offset, dtype=tf.float32)\n            return (tf.sign(n) + 1) /2 * tf.constant(float(options[""onvalue""], dtype=tf.float32))\n\n\n    def exit(self):\n        self.destroy = True\n\n    def build(self, input_nodes=None, output_nodes=None):\n        if input_nodes is None:\n            input_nodes = self.gan.input_nodes()\n        if output_nodes is None:\n            output_nodes = self.gan.output_nodes()\n        save_file_text = self.name+"".pbtxt""\n        build_file = os.path.expanduser(""builds/""+save_file_text)\n        def create_path(filename):\n            return os.makedirs(os.path.expanduser(os.path.dirname(filename)), exist_ok=True)\n        create_path(build_file)\n        tf.train.write_graph(self.gan.session.graph, \'builds\', save_file_text)\n        inputs = [x.name.split("":"")[0] for x in input_nodes]\n        outputs = [x.name.split("":"")[0] for x in output_nodes]\n\n        with self.gan.session as sess:\n            converter = tf.lite.TFLiteConverter.from_session(sess, self.gan.input_nodes(), self.gan.output_nodes())\n            converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n            tflite_model = converter.convert()\n            tflite_file = ""builds/""+self.gan.name+"".tflite""\n            f = open(tflite_file, ""wb"")\n            f.write(tflite_model)\n            f.close()\n        tf.reset_default_graph()\n        self.gan.session.close()\n        [print(""Input: "", x) for x in self.gan.input_nodes()]\n        [print(""Output: "", y) for y in self.gan.output_nodes()]\n        print(""Written to ""+tflite_file)\n\n\n    def get_registered_samplers(self=None):\n        return {\n                \'static_batch\': StaticBatchSampler,\n                \'progressive\': ProgressiveSampler,\n                \'random_walk\': RandomWalkSampler,\n                \'alphagan_random_walk\': AlphaganRandomWalkSampler,\n                \'style_walk\': StyleWalkSampler,\n                \'batch_walk\': BatchWalkSampler,\n                \'batch\': BatchSampler,\n                \'grid\': GridSampler,\n                \'sorted\': SortedSampler,\n                \'gang\': GangSampler,\n                \'began\': BeganSampler,\n                \'autoencode\': AutoencodeSampler,\n                \'debug\': DebugSampler,\n                \'y\': YSampler,\n                \'segment\': SegmentSampler,\n                \'aligned\': AlignedSampler\n            }\n    def sampler_for(self, name, default=StaticBatchSampler):\n        samplers = self.get_registered_samplers()\n        self.selected_sampler = name\n        if name in samplers:\n            return samplers[name]\n        else:\n            print(""[hypergan] No sampler found for "", name, "".  Defaulting to"", default)\n            return default\n\n\n'"
hypergan/gans/distribution_filtering_gan.py,10,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom .standard_gan import StandardGAN\n\nclass DistributionFilteringGAN(StandardGAN):\n    """"""\n    On Stabilizing Generative Adversarial Training with Noise\n    https://arxiv.org/pdf/1906.04612v1.pdf\n    """"""\n    def create(self):\n        config = self.config\n\n        with tf.device(self.device):\n            self.session = self.ops.new_session(self.ops_config)\n            self.latent = self.create_component(config.z_distribution or config.latent)\n            self.uniform_distribution = self.latent\n\n            z_shape = self.ops.shape(self.latent.sample)\n            self.android_input = tf.reshape(self.latent.sample, [-1])\n\n            direction, slider = self.create_controls(self.ops.shape(self.android_input))\n            self.slider = slider\n            self.direction = direction\n            z = self.android_input + slider * direction\n            z = tf.maximum(-1., z)\n            z = tf.minimum(1., z)\n            z = tf.reshape(z, z_shape)\n            self.control_z = z\n\n            self.generator = self.create_component(config.generator, name=""generator"", input=z)\n            self.noise_generator = self.create_component((config.noise_generator or config.generator), name=""noise_generator"", input=z)\n\n            #x, g = tf.concat([self.inputs.x, self.inputs.x + self.noise_generator.sample], axis=3), tf.concat([self.generator.sample, self.generator.sample + self.noise_generator.sample], axis=3)\n\n            x1, g1 = self.inputs.x, self.generator.sample\n            self.discriminator = self.create_component(config.discriminator, name=""discriminator"", input=tf.concat([x1,g1],axis=0))\n            x2, g2 = self.inputs.x+self.noise_generator.sample, self.generator.sample+self.noise_generator.sample\n            self.loss = self.create_component(config.loss, discriminator=self.discriminator)\n            self.noise_discriminator = self.create_component(config.discriminator, name=""discriminator"", input=tf.concat([x2,g2],axis=0), reuse=True)\n            noise_loss = self.create_component(config.loss, discriminator=self.noise_discriminator)\n            self.loss.sample[0] += noise_loss.sample[0]\n            self.loss.sample[1] += noise_loss.sample[1]\n            self.trainer = self.create_component(config.trainer)\n\n            self.android_output = tf.reshape(self.generator.sample, [-1])\n\n            self.session.run(tf.global_variables_initializer())\n\n    def g_vars(self):\n        return self.latent.variables() + self.generator.variables() + self.noise_generator.variables()\n    def d_vars(self):\n        return self.discriminator.variables()\n'"
hypergan/gans/standard_gan.py,10,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom .base_gan import BaseGAN\n\nclass StandardGAN(BaseGAN):\n    """""" \n    Standard GANs consist of:\n    \n    *required to sample*\n    \n    * latent\n    * generator\n    * sampler\n\n    *required to train*\n\n    * discriminator\n    * loss\n    * trainer\n    """"""\n    def __init__(self, *args, **kwargs):\n        self.discriminator = None\n        self.latent = None\n        self.generator = None\n        self.loss = None\n        self.trainer = None\n        self.features = []\n        self.session = None\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        return ""generator"".split()\n\n    def create(self):\n        config = self.config\n\n        with tf.device(self.device):\n            self.session = self.ops.new_session(self.ops_config)\n            self.latent = self.create_component(config.z_distribution or config.latent)\n            self.uniform_distribution = self.latent\n\n            z_shape = self.ops.shape(self.latent.sample)\n            self.android_input = tf.reshape(self.latent.sample, [-1])\n\n            direction, slider = self.create_controls(self.ops.shape(self.android_input))\n            self.slider = slider\n            self.direction = direction\n            z = self.android_input + slider * direction\n            z = tf.maximum(-1., z)\n            z = tf.minimum(1., z)\n            z = tf.reshape(z, z_shape)\n            self.control_z = z\n\n            self.generator = self.create_component(config.generator, name=""generator"", input=z)\n            self.autoencoded_x = self.generator.sample\n\n            x, g = self.inputs.x, self.generator.sample\n            if self.ops.shape(x) == self.ops.shape(g):\n                self.discriminator = self.create_component(config.discriminator, name=""discriminator"", input=tf.concat([x,g],axis=0))\n            else:\n                print(""X size"", self.ops.shape(x))\n                print(""G size"", self.ops.shape(g))\n                raise ValidationException(""X and G sizes differ"")\n            self.loss = self.create_component(config.loss, discriminator=self.discriminator)\n            self.trainer = self.create_component(config.trainer)\n\n            self.android_output = tf.reshape(self.generator.sample, [-1])\n\n            self.session.run(tf.global_variables_initializer())\n\n    def create_controls(self, z_shape):\n        direction = tf.constant(0.0, shape=z_shape, name=\'direction\') * 1.00\n        slider = tf.constant(0.0, name=\'slider\', dtype=tf.float32) * 1.00\n        return direction, slider\n\n    def g_vars(self):\n        return self.latent.variables() + self.generator.variables()\n    def d_vars(self):\n        return self.discriminator.variables()\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        return [\n                self.android_input\n        ]\n\n    def output_nodes(self):\n        ""used in hypergan build""\n        return [\n                self.android_output\n        ]\n'"
hypergan/generators/__init__.py,0,"b'""""""\nGenerators create the samples.  Trained generators are often the goal of our users.\n""""""\nfrom os.path import dirname, basename, isfile\nimport glob\nmodules = glob.glob(dirname(__file__)+""/*.py"")\n__all__ = [ basename(f)[:-3] for f in modules if isfile(f)]\n'"
hypergan/generators/base_generator.py,0,"b'from hypergan.gan_component import GANComponent\n\nclass BaseGenerator(GANComponent):\n\n    def __init__(self, gan, config, name=""BaseGenerator"", input=None, reuse=False):\n        self.input = input\n        self.name = name\n\n        GANComponent.__init__(self, gan, config, name=name, reuse=reuse)\n\n    """"""\n        Superclass for all Generators.  Provides some common functionality.\n    """"""\n    def create(self):\n        """"""\n        Create graph\n        """"""\n        self.sample = self.build(self.input)\n        return self.sample\n\n    def add_progressive_enhancement(self, net):\n        ops = self.ops\n        gan = self.gan\n        config = self.config\n        if config.progressive_enhancement:\n            split = ops.slice(net, [0, 0, 0, 0], [-1, -1, -1, gan.channels()])\n            if config.final_activation:\n                split = config.final_activation(split)\n            print(""[generator] adding progressive enhancement"", split)\n            gan.skip_connections.set(\'progressive_enhancement\', split)\n\n\n    def project_from_prior(self, primes, net, initial_depth, type=\'linear\', name=\'prior_projection\'):\n        ops = self.ops\n        net = ops.reshape(net, [ops.shape(net)[0], -1])\n        new_shape = [ops.shape(net)[0], primes[0], primes[1], initial_depth]\n        net = ops.linear(net, initial_depth*primes[0]*primes[1])\n        print(""projection "", net)\n        net = ops.reshape(net, new_shape)\n        return net\n\n\n'"
hypergan/generators/common.py,2,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\n\ndef repeating_block(component, net, output_channels, filter=None):\n    config = component.config\n    ops = component.ops\n    if output_channels == 3:\n        return standard_block(component, net, output_channels, filter=filter)\n    for i in range(config.block_repeat_count):\n        net = standard_block(component, net, output_channels, filter=filter)\n        print(""[generator] repeating block "", net)\n    return net\n\ndef multi_block(component, net, output_channels, filter=None):\n    config = component.config\n    ops = component.ops\n    if output_channels == 3:\n        return standard_block(component, net, output_channels, filter=filter)\n    net = standard_block(component, net, output_channels, filter=filter)\n    net2 = standard_block(component, net, output_channels, filter=filter, activation_regularizer=True)\n    net3 = standard_block(component, net2, output_channels, filter=filter, activation_regularizer=True)\n    return net+net2+net3\n\n\ndef standard_block(component, net, output_channels, filter=None, activation_regularizer=False, padding=""SAME""):\n    config = component.config\n    ops = component.ops\n    layer_regularizer = config.layer_regularizer\n\n    if activation_regularizer:\n        net = config.activation(net)\n        if layer_regularizer is not None:\n            net = component.layer_regularizer(net)\n\n    if padding == ""VALID"":\n        resize = [ops.shape(net)[1]+2, ops.shape(net)[2]+2]\n        net = ops.resize_images(net, resize, config.resize_image_type or 1)\n    net = ops.conv2d(net, filter, filter, 1, 1, output_channels, padding=padding)\n    return net\n\ndef inception_block(component, net, output_channels, filter=None):\n    config = component.config\n    ops = component.ops\n    activation = ops.lookup(config.activation)\n    size = int(net.get_shape()[-1])\n    batch_size = int(net.get_shape()[0])\n\n    if output_channels == 3:\n        return standard_block(component, net, output_channels)\n\n    net1 = ops.conv2d(net, filter, filter, 1, 1, output_channels//3)\n    net2 = ops.conv2d(net1, filter, filter, 1, 1, output_channels//3)\n    net3 = ops.conv2d(net2, filter, filter, 1, 1, output_channels//3)\n    net = tf.concat(axis=3, values=[net1, net2, net3])\n    return net\n\ndef dense_block(component, net, output_channels, filter=None):\n    config = component.config\n    ops = component.ops\n    if output_channels == 3:\n        return standard_block(component, net, output_channels)\n    net1 = standard_block(component, net, output_channels)\n    net2 = standard_block(component, net, output_channels)\n    net = tf.concat(axis=3, values=[net1, net2])\n    return net\n    \n\n\n'"
hypergan/generators/configurable_generator.py,0,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport inspect\nimport copy\nimport os\nimport operator\nfrom functools import reduce\n\nfrom hypergan.ops.tensorflow.extended_ops import bicubic_interp_2d\nfrom .base_generator import BaseGenerator\nfrom hypergan.configurable_component import ConfigurableComponent\n\nclass ConfigurableGenerator(BaseGenerator, ConfigurableComponent):\n    def __init__(self, gan, config, name=None, input=None, reuse=None, x=None, g=None, features=[], skip_connections=[]):\n        ConfigurableComponent.__init__(self, gan, config, name=name, input=input,features=features,reuse=reuse, x=x, g=g)\n        BaseGenerator.__init__(self, gan, config, name=name, input=input,reuse=reuse)\n'"
hypergan/generators/dcgan_generator.py,0,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nfrom hypergan.generators.common import *\n\nfrom .base_generator import BaseGenerator\n\nclass DCGANGenerator(BaseGenerator):\n\n    def required(self):\n        return []\n\n    def build(self, net):\n        gan = self.gan\n        ops = self.ops\n        config = self.config\n        activation = ops.lookup(config.activation or \'lrelu\')\n\n        print(""[dcgan] NET IS"", net)\n\n        net = ops.linear(net, 4*4*1024)\n\n        shape = ops.shape(net)\n\n        net = ops.reshape(net, [shape[0],4,4,1024])\n\n        net = activation(net)\n        net = ops.deconv2d(net, 5, 5, 2, 2, 512)\n        net = self.layer_regularizer(net)\n        net = activation(net)\n        net = ops.deconv2d(net, 5, 5, 2, 2, 256)\n        net = self.layer_regularizer(net)\n        net = activation(net)\n        net = ops.deconv2d(net, 5, 5, 2, 2, 128)\n        net = self.layer_regularizer(net)\n        net = activation(net)\n        net = ops.deconv2d(net, 5, 5, 2, 2, gan.channels())\n        net = self.layer_regularizer(net)\n        net = ops.lookup(\'tanh\')(net)\n\n        self.sample = net\n        return self.sample\n'"
hypergan/generators/multisegment_generator.py,10,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nfrom hypergan.generators.common import *\n\nfrom .base_generator import BaseGenerator\nfrom .segment_generator import SegmentGenerator\n\nclass MultisegmentGenerator(SegmentGenerator):\n\n    def required(self):\n        return []\n\n    def build(self, net, mask=None):\n        gan = self.gan\n        ops = self.ops\n        config = self.config\n\n        if(mask is None):\n            mask_config  = dict(config.mask_generator)\n            data_layers = 6\n            mask_config[""channels""]=3+data_layers\n            mask_config[""layer_filter""]=None\n            mask_generator = ResizeConvGenerator(gan, mask_config, name=\'mask\', input=net, reuse=self.ops._reuse)\n            self.mask_generator = mask_generator\n\n            mask_single_channel = mask_generator.sample\n        else:\n            mask_single_channel = mask\n            mask_generator = self.mask_generator\n\n\n \n        self.mask_single_channel = mask_generator.sample\n        #self.mask = tf.tile(mask_generator.sample, [1,1,1,3])\n        self.mask = mask_generator.sample\n\n\n\n        def add_mask(gan, config, net):\n            mask = mask_single_channel\n            s = gan.ops.shape(net)\n            shape = [s[1], s[2]]\n            return tf.image.resize_images(mask, shape, 1)\n\n \n        config[\'layer_filter\'] = add_mask\n\n        g1 = ResizeConvGenerator(gan, config, input=net, name=\'g1\', reuse=self.ops._reuse)\n        g2 = ResizeConvGenerator(gan, config, input=net, name=\'g2\', reuse=self.ops._reuse)\n        g3 = ResizeConvGenerator(gan, config, input=net, name=\'g3\', reuse=self.ops._reuse)\n\n        if not self.ops._reuse:\n            self.ops.add_weights(mask_generator.variables())\n            self.ops.add_weights(g1.variables())\n            self.ops.add_weights(g2.variables())\n            self.ops.add_weights(g3.variables())\n\n        mask1 = tf.slice(mask_single_channel, [0,0,0,0], [-1,-1,-1,1])\n        mask2 = tf.slice(mask_single_channel, [0,0,0,1], [-1,-1,-1,1])\n        mask3 = tf.slice(mask_single_channel, [0,0,0,2], [-1,-1,-1,1])\n\n\n        mask2 = tf.nn.relu(mask2-mask1)\n        mask3 = tf.nn.relu(mask3-mask2-mask1)\n        self.mask = tf.concat([mask1,mask2,mask3], axis=3)\n\n        #mask = tf.ones_like(mask1)\n        sample = tf.zeros_like(gan.inputs.x)\n        for applied_mask in [(mask1, g1), (mask2, g2), (mask3, g3)]:\n            g = applied_mask[1].sample\n            m = applied_mask[0]\n\n            #sample += (1.0-mask)*m*g\n            #mask = mask*(1.0-m)\n            sample += m*g\n\n        self.g1 = g1\n        self.g2 = g2\n        self.g3 = g3\n\n        self.g1x = (g1.sample * mask1) + \\\n                (1.0-mask1) * gan.inputs.x\n\n\n        self.g2x = (gan.inputs.x * (1.0-mask2)) + \\\n                (mask2) * g2.sample\n\n\n        self.g3x = (gan.inputs.x * (1.0-mask3)) + \\\n                (mask3) * g3.sample\n\n\n        self.mask_generator = mask_generator\n\n        return sample\n'"
hypergan/generators/multisegment_shared_generator.py,7,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nfrom hypergan.generators.common import *\n\nfrom .base_generator import BaseGenerator\nfrom .segment_generator import SegmentGenerator\n\ndef add_mask(gan, config, net):\n    mask = gan.generator.mask_single_channel\n    s = gan.ops.shape(net)\n    shape = [s[1], s[2]]\n    return tf.image.resize_images(mask, shape, 1)\n\nclass MultisegmentSharedGenerator(SegmentGenerator):\n\n    def required(self):\n        return []\n\n    def build(self, net):\n        gan = self.gan\n        ops = self.ops\n        config = self.config\n        activation = ops.lookup(config.activation or \'lrelu\')\n        activation = ops.lookup(config.final_activation or \'tanh\')\n\n        mask_config  = dict(config.mask_generator or config)\n        mask_config[""channels""]=config.segments * (config.segments_spacing or 1)\n        mask_config[""layer_filter""]=None\n        mask_generator = ResizeConvGenerator(gan, mask_config)\n        mask_generator.ops.describe(""mask"")\n        if self.ops._reuse:\n            mask_generator.ops.reuse()\n        mask_generator.build(net)\n\n        self.mask_single_channel = mask_generator.sample\n        #self.mask = tf.tile(mask_generator.sample, [1,1,1,3])\n        #self.mask = mask_generator.sample\n\n        mask = mask_generator.sample/2.0+0.5\n\n        config[\'layer_filter\'] = add_mask\n        config[\'channels\'] = config.segments * 3\n\n        g1 = ResizeConvGenerator(gan, config)\n        g1.ops.describe(""g1"")\n        if self.ops._reuse:\n            g1.ops.reuse()\n        g1.build(net)\n\n        self.ops.add_weights(mask_generator.variables())\n        self.ops.add_weights(g1.variables())\n\n        def get_mask(mask, i, config):\n            print(\'get mask\', i*(config.segments_spacing or 1), mask)\n            return tf.slice(mask, [0,0,0,i*(config.segments_spacing or 1)], [-1,-1,-1,1])\n\n        def get_image(image, i):\n            return tf.slice(image, [0,0,0,i*3], [-1,-1,-1,3])\n        masks = [(get_mask(mask, i, config), get_image(g1.sample, i)) for i in range(ops.shape(mask)[3]//(config.segments_spacing or 1))]\n\n        full_mask = tf.ones_like(masks[0][0])\n        sample = tf.zeros_like(gan.inputs.x)\n        if config.stacked:\n            for applied_mask in masks:\n                g = applied_mask[1]\n                m = applied_mask[0]\n\n                sample += (1.0-m)*sample+m*g\n                full_mask = full_mask*(1.0-m)\n\n        else:\n            for applied_mask in masks:\n                g = applied_mask[1]\n                m = applied_mask[0]\n\n                sample += (1.0-full_mask)*m*g\n                full_mask = full_mask*(1.0-m)\n\n        self.sample = sample\n\n        print(""OUTPUT"", self.sample, g1.sample, mask)\n\n        self.g1 = hc.Config({""sample"":masks[0][1]})\n        self.g2 = hc.Config({""sample"":masks[1][1]})\n\n        self.g1x = (masks[0][1] * masks[0][0]) + \\\n                (1.0-masks[0][0]) * gan.inputs.x\n\n\n        self.g2x = (gan.inputs.x * masks[0][0]) + \\\n                (1.0-masks[0][0]) * masks[1][1] \n\n        self.mask_generator = mask_generator\n\n        self.mask = tf.slice(mask_generator.sample, [0,0,0,0], [-1,-1,-1,3])\n        #self.sample = self.g1x\n        self.masks = masks\n\n        return self.sample\n'"
hypergan/generators/resizable_generator.py,0,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nfrom hypergan.generators.common import *\nfrom hypergan.generators.configurable_generator import ConfigurableGenerator\n\nfrom .base_generator import BaseGenerator\n\nclass ResizableGenerator(ConfigurableGenerator):\n\n    def required(self):\n        return ""final_depth"".split()\n\n    def depths(self, initial_width=4):\n        gan = self.gan\n        ops = self.ops\n        config = self.config\n        final_depth = config.final_depth\n        depths = []\n\n        target_w = gan.width()\n\n        w = initial_width\n        #ontehuas\n        i = 0\n\n        depths.append(final_depth)\n        while w < target_w:\n            w*=2\n            depths.append(final_depth * 2**i)\n            i+=1\n        depths = depths[1:]\n        depths.reverse()\n        return depths\n\n    def build(self, net):\n        gan = self.gan\n        ops = self.ops\n        config = self.config\n\n        nets = []\n\n        block = config.block or standard_block\n        padding = config.padding or ""SAME""\n        latent = net\n\n        net = ops.reshape(net, [ops.shape(net)[0], -1])\n        primes = config.initial_dimensions or [4, 4]\n        depths = self.depths(primes[0])\n        initial_depth = np.minimum(depths[0], config.max_depth or 512)\n        str_depth = str(primes[0])+""*""+str(primes[1])+""*""+str(initial_depth)\n        new_shape = [ops.shape(net)[0], primes[0], primes[1], initial_depth]\n        net = self.layer_linear(net, [str_depth], {""initializer"": ""stylegan""})\n        net = ops.reshape(net, new_shape)\n        print(""Generator Architecture:"")\n        print(""linear ""+str_depth)\n\n        shape = ops.shape(net)\n\n        depths = self.depths(initial_width = shape[1])\n\n        depth_reduction = np.float32(config.depth_reduction)\n        shape = ops.shape(net)\n\n        filter_size = config.filter or 3\n\n\n        if config.adaptive_instance_norm:\n            w = latent\n            for i in range(config.adaptive_instance_norm_layers or 2):\n                w = self.layer_linear(w, [512], {})\n            w = self.layer_identity(w, [""w""], {})\n            net = self.layer_adaptive_instance_norm(net, [], {})\n\n        for i, depth in enumerate(depths[1:]):\n            s = ops.shape(net)\n            resize = [min(s[1]*2, gan.height()), min(s[2]*2, gan.width())]\n            net = self.layer_regularizer(net)\n            self.add_progressive_enhancement(net)\n            dep = np.minimum(depth, config.max_depth or 512)\n            print(block + "" "" + str(dep))\n            if block == \'deconv\':\n                net = self.layer_deconv(net, [dep], {""initializer"": ""he_normal"", ""avg_pool"": 1, ""stride"": 2, ""filter"": 3})\n            elif block == \'subpixel\':\n                net = self.layer_subpixel(net, [dep], {""initializer"": ""he_normal"", ""avg_pool"": 1, ""stride"": 1, ""filter"": 3})\n            elif block == \'resize_conv\':\n                net = self.layer_resize_conv(net, [dep], {""initializer"": ""he_normal"", ""avg_pool"": 1, ""stride"": 1, ""filter"": 3})\n            else:\n                net = ops.resize_images(net, resize, config.resize_image_type or 1)\n                net = block(self, net, depth, filter=filter_size, padding=padding)\n\n            if config.adaptive_instance_norm:\n                net = self.layer_adaptive_instance_norm(net, [], {})\n\n            size = resize[0]*resize[1]*depth\n\n        net = self.layer_regularizer(net)\n\n        resize = [gan.height(), gan.width()]\n\n        dep = config.channels or gan.channels()\n        print(block + "" "" + str(dep))\n\n        if block == \'deconv\':\n            if resize != [e*2 for e in ops.shape(net)[1:3]]:\n                net = self.layer_deconv(net, [dep], {""initializer"": ""he_normal"", ""avg_pool"": 1, ""stride"": 2, ""filter"": 3, ""activation"": config.final_activation or ""tanh""})\n                net = ops.slice(net, [0,0,0,0], [ops.shape(net)[0], resize[0], resize[1], ops.shape(net)[3]])\n            else:\n                net = ops.deconv2d(net, 5, 5, 2, 2, dep)\n\n        elif block == ""subpixel"":\n            if resize != [e*2 for e in ops.shape(net)[1:3]]:\n                net = self.layer_subpixel(net, [dep], {""avg_pool"": 1, ""stride"": 1, ""filter"": 3, ""activation"": config.final_activation or ""tanh""})\n                net = ops.slice(net, [0,0,0,0], [ops.shape(net)[0], resize[0], resize[1], ops.shape(net)[3]])\n            else:\n                net = self.layer_subpixel(net, [dep], {""avg_pool"": 1, ""stride"": 1, ""filter"": 3, ""activation"": config.final_activation or ""tanh""})\n\n        elif block == ""resize_conv"":\n            net = self.layer_resize_conv(net, [dep], {""w"": resize[0], ""h"": resize[1], ""avg_pool"": 1, ""stride"": 1, ""filter"": 3, ""activation"": config.final_activation or ""tanh""})\n\n        else:\n            net = ops.resize_images(net, resize, config.resize_image_type or 1)\n            net = block(self, net, dep, filter=config.final_filter or 3, padding=padding)\n\n\n        return net\n\n\n'"
hypergan/generators/segment_generator.py,5,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nfrom hypergan.generators.common import *\n\nfrom .base_generator import BaseGenerator\nfrom .resizable_generator import ResizableGenerator\n\nclass SegmentGenerator(ResizableGenerator):\n\n    def required(self):\n        return [\'mask_generator\']\n\n    def reuse(self, net, mask=None):\n        self.ops.reuse()\n        net = self.build(net, mask)\n        self.ops.stop_reuse()\n        return net\n\n    def build(self, net, mask=None):\n        gan = self.gan\n        ops = self.ops\n        config = self.config\n\n        if(mask is None):\n            mask_config  = dict(config.mask_generator)\n            data_channels = 6 #todo parameterize\n            mask_config[""channels""]=1+data_channels\n            mask_config[""layer_filter""]=None\n            mask_generator = ResizeConvGenerator(gan, mask_config, name=\'mask\', input=net, reuse=self.ops._reuse)\n            self.mask_generator = mask_generator\n\n            mask_single_channel = mask_generator.sample\n        else:\n            mask_single_channel = mask\n\n\n        def add_mask(gan, config, net):\n            mask = mask_single_channel\n            s = gan.ops.shape(net)\n            shape = [s[1], s[2]]\n            return tf.image.resize_images(mask, shape, 1)\n\n        config[\'layer_filter\'] = add_mask\n\n        g1 = ResizeConvGenerator(gan, config, input=net, name=\'g1\', reuse=self.ops._reuse)\n        g2 = ResizeConvGenerator(gan, config, input=net, name=\'g2\', reuse=self.ops._reuse)\n\n        if not self.ops._reuse:\n            self.ops.add_weights(self.mask_generator.variables())\n            self.ops.add_weights(g1.variables())\n            self.ops.add_weights(g2.variables())\n\n        self.g1 = g1\n        self.g2 = g2\n\n        single = tf.slice(mask_generator.sample, [0,0,0,0], [-1,-1,-1,1])\n        self.mask = tf.tile(single, [1,1,1,3])\n        self.mask_single_channel = mask_single_channel\n\n        sample = (g1.sample * self.mask) + \\\n                 (1.0-self.mask) * g2.sample\n        self.g1x = (g1.sample * self.mask) + \\\n                   (1.0-self.mask) * gan.inputs.x\n        self.g2x = (gan.inputs.x * self.mask) + \\\n                   (1.0-self.mask) * g2.sample\n\n        pe = self.gan.skip_connections.get_shapes(""progressive_enhancement"")\n        if pe is not None and len(pe) > 0:\n            for shape in pe:\n                pe = self.gan.skip_connections.get_array(""progressive_enhancement"", shape=shape)\n                g1 = pe[-2]\n                g2 = pe[-1]\n                print(""[generator] segment generator combining progressive enhancement layers: "", len(pe))\n                resized_mask = tf.image.resize_images(self.mask, [shape[1], shape[2]], 1)\n                combine = resized_mask * g1 + (1 - resized_mask) * g2\n                self.gan.skip_connections.clear(""progressive_enhancement"", shape=shape)\n                for pe_layer in pe[0:-2]+[combine]:\n                    self.gan.skip_connections.set(""progressive_enhancement"", pe_layer)\n\n        if gan.config.progressive_growing:\n            pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n            last_layer = sample * self.progressive_growing_mask(len(pe_layers))\n            s = ops.shape(last_layer)\n            img_dims = [s[1],s[2]]\n            self.pe_layers = [tf.image.resize_images(elem, img_dims) for i, elem in enumerate(pe_layers)] + [sample]\n            self.debug_pe = [self.progressive_growing_mask(i) for i, elem in enumerate(pe_layers)]\n \n\n        return sample\n'"
hypergan/inputs/__init__.py,0,"b'""""""\nVarious common input types are shared here.  Other input types can be found in API examples.\n""""""\nfrom os.path import dirname, basename, isfile\nimport glob\nmodules = glob.glob(dirname(__file__)+""/*.py"")\n__all__ = [ basename(f)[:-3] for f in modules if isfile(f)]\n'"
hypergan/inputs/image_loader.py,9,"b'# Loads an image with the tensorflow input pipeline\nimport glob\nimport os\nimport tensorflow as tf\nimport hypergan.inputs.resize_image_patch\nfrom tensorflow.python.ops import array_ops\nfrom natsort import natsorted, ns\nfrom hypergan.gan_component import ValidationException, GANComponent\n\nclass ImageLoader:\n    """"""\n    ImageLoader loads a set of images into a tensorflow input pipeline.\n    """"""\n\n    def __init__(self, batch_size):\n        self.batch_size = batch_size\n\n    def create(self, directory, channels=3, format=\'jpg\', width=64, height=64, crop=False, resize=False, sequential=False):\n        directories = glob.glob(directory+""/*"")\n        directories = [d for d in directories if os.path.isdir(d)]\n\n        if(len(directories) == 0):\n            directories = [directory] \n\n        # Create a queue that produces the filenames to read.\n        if(len(directories) == 1):\n            # No subdirectories, use all the images in the passed in path\n            filenames = glob.glob(directory+""/*.""+format)\n        else:\n            filenames = glob.glob(directory+""/**/*.""+format)\n\n        filenames = natsorted(filenames)\n\n        print(""[loader] ImageLoader found"", len(filenames))\n        self.file_count = len(filenames)\n        if self.file_count == 0:\n            raise ValidationException(""No images found in \'"" + directory + ""\'"")\n        filenames = tf.convert_to_tensor(filenames, dtype=tf.string)\n\n        def parse_function(filename):\n            image_string = tf.read_file(filename)\n            if format == \'jpg\':\n                image = tf.image.decode_jpeg(image_string, channels=channels)\n            elif format == \'png\':\n                image = tf.image.decode_png(image_string, channels=channels)\n            else:\n                print(""[loader] Failed to load format"", format)\n            image = tf.cast(image, tf.float32)\n            # Image processing for evaluation.\n            # Crop the central [height, width] of the image.\n            if crop:\n                image = hypergan.inputs.resize_image_patch.resize_image_with_crop_or_pad(image, height, width, dynamic_shape=True)\n            elif resize:\n                image = tf.image.resize_images(image, [height, width], 1)\n\n            image = image / 127.5 - 1.\n            tf.Tensor.set_shape(image, [height,width,channels])\n\n            return image\n\n        # Generate a batch of images and labels by building up a queue of examples.\n        dataset = tf.data.Dataset.from_tensor_slices(filenames)\n        if not sequential:\n            print(""Shuffling data"")\n            dataset = dataset.shuffle(self.file_count)\n        dataset = dataset.map(parse_function, num_parallel_calls=4)\n        dataset = dataset.batch(self.batch_size, drop_remainder=True)\n        dataset = dataset.repeat()\n        dataset = dataset.prefetch(1)\n\n        self.dataset = dataset\n\n        self.iterator = self.dataset.make_one_shot_iterator()\n        self.x = tf.reshape( self.iterator.get_next(), [self.batch_size, height, width, channels])\n\n    def inputs(self):\n        return [self.x,self.x]\n'"
hypergan/inputs/multi_image_loader.py,9,"b'# Loads an image with the tensorflow input pipeline\nimport glob\nimport os\nimport tensorflow as tf\nfrom natsort import natsorted, ns\nimport hypergan.inputs.resize_image_patch\nfrom tensorflow.python.ops import array_ops\nfrom hypergan.gan_component import ValidationException, GANComponent\n\nclass MultiImageLoader:\n    """"""\n    MultiImageLoader loads a set of images into a tensorflow input pipeline.\n    Supports multiple directories\n    """"""\n\n    def __init__(self, batch_size):\n        self.batch_size = batch_size\n\n\n    def create(self, directories, channels=3, format=\'jpg\', width=64, height=64, crop=False, resize=False, sequential=False):\n        filenames_list = [natsorted(glob.glob(directory+""/*.""+format)) for directory in directories]\n\n        imgs = []\n\n        self.datasets = []\n        def parse_function(filename):\n            image_string = tf.read_file(filename)\n            if format == \'jpg\':\n                image = tf.image.decode_jpeg(image_string, channels=channels)\n            elif format == \'png\':\n                image = tf.image.decode_png(image_string, channels=channels)\n            else:\n                print(""[loader] Failed to load format"", format)\n            image = tf.cast(image, tf.float32)\n            # Image processing for evaluation.\n            # Crop the central [height, width] of the image.\n            if crop:\n                image = hypergan.inputs.resize_image_patch.resize_image_with_crop_or_pad(image, height, width, dynamic_shape=True)\n            elif resize:\n                image = tf.image.resize_images(image, [height, width], 1)\n\n            image = image / 127.5 - 1.\n            tf.Tensor.set_shape(image, [height,width,channels])\n            return image\n\n        for filenames in filenames_list:\n            self.file_count = len(filenames)\n            filenames = tf.convert_to_tensor(filenames, dtype=tf.string)\n\n            dataset = tf.data.Dataset.from_tensor_slices(filenames)\n            if not sequential:\n                print(""Shuffling data"")\n                dataset = dataset.shuffle(self.file_count)\n            dataset = dataset.map(parse_function, num_parallel_calls=4)\n            dataset = dataset.batch(self.batch_size, drop_remainder=True)\n            dataset = dataset.repeat()\n            dataset = dataset.prefetch(1)\n            shape = [self.batch_size, height, width, channels]\n            self.datasets.append(tf.reshape(dataset.make_one_shot_iterator().get_next(), shape))\n\n        self.xs = self.datasets\n        self.xa = self.datasets[0]\n        self.xb = self.datasets[1]\n        self.x = self.datasets[0]\n        return self.xs\n\n    def inputs(self):\n        return self.xs\n'"
hypergan/inputs/resize_image_patch.py,3,"b'\n# coding: utf-8\n\n# In[1]:\n\nfrom tensorflow.python.ops import image_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import array_ops\n\nimport tensorflow as tf\n\n# In[2]:\n\ndef crop_to_bounding_box(image, offset_height, offset_width, target_height,\n                         target_width, dynamic_shape=False):\n  """"""Crops an image to a specified bounding box.\n\n  This op cuts a rectangular part out of `image`. The top-left corner of the\n  returned image is at `offset_height, offset_width` in `image`, and its\n  lower-right corner is at\n  `offset_height + target_height, offset_width + target_width`.\n\n  Args:\n    image: 3-D tensor with shape `[height, width, channels]`\n    offset_height: Vertical coordinate of the top-left corner of the result in\n                   the input.\n    offset_width: Horizontal coordinate of the top-left corner of the result in\n                  the input.\n    target_height: Height of the result.\n    target_width: Width of the result.\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Returns:\n    3-D tensor of image with shape `[target_height, target_width, channels]`\n\n  Raises:\n    ValueError: If the shape of `image` is incompatible with the `offset_*` or\n    `target_*` arguments, and `dynamic_shape` is set to `False`.\n  """"""\n  image = tf.convert_to_tensor(image, name=\'image\')\n  _Check3DImage(image, require_static=(not dynamic_shape))\n  height, width, _ = _ImageDimensions(image, dynamic_shape=dynamic_shape)\n\n  if not dynamic_shape:\n    if offset_width < 0:\n      raise ValueError(\'offset_width must be >= 0.\')\n    if offset_height < 0:\n      raise ValueError(\'offset_height must be >= 0.\')\n\n    if width < (target_width + offset_width):\n      raise ValueError(\'width must be >= target + offset.\')\n    if height < (target_height + offset_height):\n      raise ValueError(\'height must be >= target + offset.\')\n\n  cropped = array_ops.slice(image,\n                            array_ops.stack([offset_height, offset_width, 0]),\n                            array_ops.stack([target_height, target_width, -1]))\n\n  return cropped\n\n\n# In[3]:\n\ndef pad_to_bounding_box(image, offset_height, offset_width, target_height,\n                        target_width, dynamic_shape=False):\n  """"""Pad `image` with zeros to the specified `height` and `width`.\n\n  Adds `offset_height` rows of zeros on top, `offset_width` columns of\n  zeros on the left, and then pads the image on the bottom and right\n  with zeros until it has dimensions `target_height`, `target_width`.\n\n  This op does nothing if `offset_*` is zero and the image already has size\n  `target_height` by `target_width`.\n\n  Args:\n    image: 3-D tensor with shape `[height, width, channels]`\n    offset_height: Number of rows of zeros to add on top.\n    offset_width: Number of columns of zeros to add on the left.\n    target_height: Height of output image.\n    target_width: Width of output image.\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Returns:\n    3-D tensor of shape `[target_height, target_width, channels]`\n  Raises:\n    ValueError: If the shape of `image` is incompatible with the `offset_*` or\n      `target_*` arguments, and `dynamic_shape` is set to `False`.\n  """"""\n  image = tf.convert_to_tensor(image, name=\'image\')\n  _Check3DImage(image, require_static=(not dynamic_shape))\n  height, width, depth = _ImageDimensions(image, dynamic_shape=dynamic_shape)\n\n  after_padding_width = target_width - offset_width - width\n  after_padding_height = target_height - offset_height - height\n\n  if not dynamic_shape:\n    if target_width < width:\n      raise ValueError(\'target_width must be >= width\')\n    if target_height < height:\n      raise ValueError(\'target_height must be >= height\')\n\n    if after_padding_width < 0:\n      raise ValueError(\'target_width not possible given \'\n                       \'offset_width and image width\')\n    if after_padding_height < 0:\n      raise ValueError(\'target_height not possible given \'\n                       \'offset_height and image height\')\n\n  # Do not pad on the depth dimensions.\n  if (dynamic_shape or offset_width or offset_height or\n      after_padding_width or after_padding_height):\n    paddings = array_ops.reshape(\n      array_ops.stack([offset_height, after_padding_height,\n                      offset_width, after_padding_width,\n                      0, 0]),\n      [3, 2])\n    padded = array_ops.pad(image, paddings)\n    if not dynamic_shape:\n      padded.set_shape([target_height, target_width, depth])\n  else:\n    padded = image\n\n  return padded\n\n\n# In[4]:\n\ndef resize_image_with_crop_or_pad(image, target_height, target_width,\n                                  dynamic_shape=False):\n  """"""Crops and/or pads an image to a target width and height.\n\n  Resizes an image to a target width and height by either centrally\n  cropping the image or padding it evenly with zeros.\n\n  If `width` or `height` is greater than the specified `target_width` or\n  `target_height` respectively, this op centrally crops along that dimension.\n  If `width` or `height` is smaller than the specified `target_width` or\n  `target_height` respectively, this op centrally pads with 0 along that\n  dimension.\n\n  Args:\n    image: 3-D tensor of shape [height, width, channels]\n    target_height: Target height.\n    target_width: Target width.\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Raises:\n    ValueError: if `target_height` or `target_width` are zero or negative.\n\n  Returns:\n    Cropped and/or padded image of shape\n    `[target_height, target_width, channels]`\n  """"""\n  image = tf.convert_to_tensor(image, name=\'image\')\n  _Check3DImage(image, require_static=(not dynamic_shape))\n  original_height, original_width, _ =     _ImageDimensions(image, dynamic_shape=dynamic_shape)\n\n  if target_width <= 0:\n    raise ValueError(\'target_width must be > 0.\')\n  if target_height <= 0:\n    raise ValueError(\'target_height must be > 0.\')\n\n  if dynamic_shape:\n    max_ = math_ops.maximum\n    min_ = math_ops.minimum\n  else:\n    max_ = max\n    min_ = min\n\n  width_diff = target_width - original_width\n  offset_crop_width = max_(-width_diff // 2, 0)\n  offset_pad_width = max_(width_diff // 2, 0)\n\n  height_diff = target_height - original_height\n  offset_crop_height = max_(-height_diff // 2, 0)\n  offset_pad_height = max_(height_diff // 2, 0)\n\n  # Maybe crop if needed.\n  cropped = crop_to_bounding_box(image, offset_crop_height, offset_crop_width,\n                                 min_(target_height, original_height),\n                                 min_(target_width, original_width),\n                                 dynamic_shape=dynamic_shape)\n\n  # Maybe pad if needed.\n  resized = pad_to_bounding_box(cropped, offset_pad_height, offset_pad_width,\n                                target_height, target_width,\n                                dynamic_shape=dynamic_shape)\n\n  if resized.get_shape().ndims is None:\n    raise ValueError(\'resized contains no shape.\')\n  if not resized.get_shape()[0].is_compatible_with(target_height):\n    raise ValueError(\'resized height is not correct.\')\n  if not resized.get_shape()[1].is_compatible_with(target_width):\n    raise ValueError(\'resized width is not correct.\')\n  return resized\n\n\n# In[5]:\n\ndef _ImageDimensions(images, dynamic_shape=False):\n  """"""Returns the dimensions of an image tensor.\n  Args:\n    images: 4-D Tensor of shape [batch, height, width, channels]\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Returns:\n    list of integers [batch, height, width, channels]\n  """"""\n  # A simple abstraction to provide names for each dimension. This abstraction\n  # should make it simpler to switch dimensions in the future (e.g. if we ever\n  # want to switch height and width.)\n  if dynamic_shape:\n    return array_ops.unstack(array_ops.shape(images))\n  else:\n    return images.get_shape().as_list()\n\n\n# In[6]:\n\ndef _Check3DImage(image, require_static=True):\n  """"""Assert that we are working with properly shaped image.\n  Args:\n    image: 3-D Tensor of shape [height, width, channels]\n    require_static: If `True`, requires that all dimensions of `image` are\n      known and non-zero.\n\n  Raises:\n    ValueError: if image.shape is not a [3] vector.\n  """"""\n  try:\n    image_shape = image.get_shape().with_rank(3)\n  except ValueError:\n    raise ValueError(\'\\\'image\\\' must be three-dimensional.\')\n  if require_static and not image_shape.is_fully_defined():\n    raise ValueError(\'\\\'image\\\' must be fully defined.\')\n  if any(x == 0 for x in image_shape):\n    raise ValueError(\'all dims of \\\'image.shape\\\' must be > 0: %s\' %\n                     image_shape)\n\n\n# In[7]:\n\nimage_ops.resize_image_with_crop_or_pad = resize_image_with_crop_or_pad\n#image_ops.crop_to_bounding_box = crop_to_bounding_box\n#image_ops.pad_to_bounding_box = pad_to_bounding_box\n#image_ops._ImageDimensions = _ImageDimensions\n#image_ops._Check3DImage = _Check3DImage\n\n'"
hypergan/losses/__init__.py,0,"b'""""""\nLosses can be swapped out to test various combinations.\n""""""\nfrom os.path import dirname, basename, isfile\nimport glob\nmodules = glob.glob(dirname(__file__)+""/*.py"")\n__all__ = [ basename(f)[:-3] for f in modules if isfile(f)]\n'"
hypergan/losses/ali_loss.py,12,"b'import tensorflow as tf\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nclass AliLoss(BaseLoss):\n\n    def required(self):\n        return ""reduce"".split()\n\n    def _create(self, d_real, d_fake):\n        ops = self.ops\n        config = self.config\n        gan = self.gan\n\n        pq = d_real\n        pp = d_fake\n        zeros = tf.zeros_like(d_fake)\n        ones = tf.ones_like(d_fake)\n\n\n        if config.type == \'original\':\n            d_loss = -tf.log(tf.nn.sigmoid(pq))-tf.log(1-tf.nn.sigmoid(pp))\n            g_loss = -tf.log(1-tf.nn.sigmoid(pq))-tf.log(tf.nn.sigmoid(pp))\n        elif config.type == \'least_squares\':\n            a,b,c = config.labels\n            square = ops.lookup(\'square\')\n            d_loss = 0.5*square(d_real - b) + 0.5*square(d_fake - a)\n            g_loss = 0.5*square(d_fake - c) + 0.5*square(d_real - a)\n            #g_loss = 0.5*square(d_fake - c) - d_real\n\n            #g_loss = 0.5*square(d_fake - c) + 0.5*(b-d_real)\n\n            \n        elif config.type == \'logistic\':\n            d_loss = tf.nn.softplus(-d_real) + tf.nn.softplus(d_fake)\n            g_loss = tf.nn.softplus(-d_fake) + tf.nn.softplus(d_real)\n        elif config.type == \'wasserstein\':\n            d_loss = -pq+pp\n            g_loss = pq-pp\n        elif config.type == \'label_smoothing\':\n            generator_target_probability = config.generator_target_probability or 0.8\n            label_smooth = config.label_smooth or 0.2\n            g_loss = self.sigmoid_kl_with_logits(d_fake, generator_target_probability) + \\\n                    tf.nn.sigmoid_cross_entropy_with_logits(logits=d_real, labels=zeros)\n            d_loss = self.sigmoid_kl_with_logits(d_real, 1.-label_smooth) + \\\n                    tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake, labels=zeros)\n        else:\n            g_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake, labels=zeros) + \\\n                     tf.nn.sigmoid_cross_entropy_with_logits(logits=d_real, labels=ones)\n            d_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=d_real, labels=zeros) + \\\n                     tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake, labels=ones)\n\n        return [d_loss, g_loss]\n\n'"
hypergan/losses/base_loss.py,27,"b'from hypergan.gan_component import GANComponent\nimport numpy as np\nimport tensorflow as tf\n\nclass BaseLoss(GANComponent):\n    def __init__(self, gan, config, discriminator=None, generator=None, x=None, split=2, d_fake=None, d_real=None, reuse=False, name=""BaseLoss""):\n        self.sample = None\n        self.ops = None\n        self.reuse=reuse\n        self.x = x\n        self.d_fake = d_fake\n        self.d_real = d_real\n        self.discriminator = discriminator or gan.discriminator\n        self.generator = generator\n        self.split = split\n        GANComponent.__init__(self, gan, config, name=name)\n\n    def reuse(self, d_real=None, d_fake=None):\n        self.discriminator.ops.reuse()\n        net = self._create(d_real, d_fake)\n        self.discriminator.ops.stop_reuse()\n        return net\n\n\n    def create(self):\n        gan = self.gan\n        config = self.config\n        ops = self.gan.ops\n        split = self.split\n        d_real = self.d_real\n        d_fake = self.d_fake\n\n        d_loss = None\n        g_loss = None\n        if d_real is None or d_fake is None:\n            # Not passed in, lets populate d_real/d_fake\n\n            net = self.discriminator.sample\n\n            ds = self.split_batch(net, split)\n            d_real = ds[0]\n            d_fake = tf.add_n(ds[1:])/(len(ds)-1)\n            d_loss, g_loss = self._create(d_real, d_fake)\n        else:\n            d_loss, g_loss = self._create(d_real, d_fake)\n\n        d_regularizers = []\n        g_regularizers = []\n        d_loss_features = d_loss\n        g_loss_features = g_loss\n        self.d_loss_features = d_loss_features\n        self.g_loss_features = g_loss_features\n\n        if config.random_penalty:\n            gp = self.random_penalty(d_fake, d_real)\n            d_regularizers.append(gp)\n            self.add_metric(\'random_penalty\', ops.squash(gp, tf.reduce_mean))\n\n        if self.gan.config.infogan and not hasattr(self.gan, \'infogan_q\'):\n            sample = self.gan.generator.sample\n            d = self.gan.create_component(self.gan.config.discriminator, name=""discriminator"", input=sample, reuse=True, features=[tf.zeros([1,16,16,256])])\n            last_layer = d.controls[\'infogan\']\n            q = self.gan.create_component(self.gan.config.infogan, input=(self.gan.discriminator.controls[\'infogan\']), name=\'infogan\')\n            self.gan.infogan_q=q\n            std_cont = tf.sqrt(tf.exp(q.sample))\n            true = self.gan.uniform_distribution.z\n            mean = tf.reshape(q.sample, self.ops.shape(true))\n            std_cont = tf.reshape(std_cont, self.ops.shape(true))\n            eps = (true - mean) / (std_cont + 1e-8)\n            continuous = -tf.reduce_mean( -0.5 * np.log(2*np.pi)- tf.log(std_cont+1e-8)*tf.square(eps), reduction_indices=1)\n            if self.gan.config.infogan.flipped:\n                continuous = -continuous\n\n            self.metrics[\'cinfo\']=ops.squash(continuous)\n            d_regularizers.append(continuous)\n\n        d_regularizers += self.d_regularizers()\n        g_regularizers += self.g_regularizers()\n\n        print(""prereg"", d_loss)\n        if len(d_regularizers) > 0:\n            d_loss += tf.add_n(d_regularizers)\n        if len(g_regularizers) > 0:\n            g_loss += tf.add_n(g_regularizers)\n\n        d_loss = ops.squash(d_loss, config.reduce or tf.reduce_mean) #linear doesn\'t work with this\n\n        # TODO: Why are we squashing before gradient penalty?\n        self.add_metric(\'d_loss\', d_loss)\n        if g_loss is not None:\n            g_loss = ops.squash(g_loss, config.reduce or tf.reduce_mean)\n            self.add_metric(\'g_loss\', g_loss)\n\n        self.sample = [d_loss, g_loss]\n        self.d_loss = d_loss\n        self.g_loss = g_loss\n        self.d_fake = d_fake\n        self.d_real = d_real\n\n        return self.sample\n\n    def d_regularizers(self):\n        return []\n\n    def g_regularizers(self):\n        return []\n\n    def rothk_penalty(self, d_real, d_fake):\n        config = self.config\n        g_sample = self.gan.uniform_sample\n        x = self.gan.inputs.x\n        gradx = tf.gradients(d_real, [x])[0]\n        gradg = tf.gradients(d_fake, [g_sample])[0]\n        gradx = tf.reshape(gradx, [self.ops.shape(gradx)[0], -1])\n        gradg = tf.reshape(gradg, [self.ops.shape(gradg)[0], -1])\n        gradx_norm = tf.norm(gradx, axis=1, keep_dims=True)\n        gradg_norm = tf.norm(gradg, axis=1, keep_dims=True)\n        if int(gradx_norm.get_shape()[0]) != int(d_real.get_shape()[0]):\n            print(""Condensing along batch for rothk"")\n            gradx_norm = tf.reduce_mean(gradx_norm, axis=0)\n            gradg_norm = tf.reduce_mean(gradg_norm, axis=0)\n        gradx = tf.square(gradx_norm) * tf.square(1-tf.nn.sigmoid(d_real))\n        gradg = tf.square(gradg_norm) * tf.square(tf.nn.sigmoid(d_fake))\n        loss = gradx + gradg\n        loss *= config.rothk_lambda or 1\n        if config.rothk_decay:\n            decay_function = config.decay_function or tf.train.exponential_decay\n            decay_steps = config.decay_steps or 50000\n            decay_rate = config.decay_rate or 0.9\n            decay_staircase = config.decay_staircase or False\n            global_step = tf.train.get_global_step()\n            loss = decay_function(loss, global_step, decay_steps, decay_rate, decay_staircase)\n\n        return loss\n\n    def random_penalty(self, d_fake, d_real):\n        config = self.config\n        gan = self.gan\n        ops = self.gan.ops\n        gradient_penalty = config.gradient_penalty\n        x = self.x \n        if x is None:\n            x=gan.inputs.x\n        shape = [1 for t in ops.shape(x)]\n        shape[0] = gan.batch_size()\n        uniform_noise = tf.random_uniform(shape=shape,minval=0.,maxval=1.)\n        mask = tf.cast(tf.greater(0.5, uniform_noise), tf.float32)\n        #interpolates = x * mask + g * (1-mask)\n        d = d_fake *(1-mask) + d_real * mask#discriminator.reuse(interpolates)\n        offset = config.random_penalty_offset or -0.8\n        penalty = tf.square(d - offset)\n        return penalty\n\n\n    def sigmoid_kl_with_logits(self, logits, targets):\n       # broadcasts the same target value across the whole batch\n       # this is implemented so awkwardly because tensorflow lacks an x log x op\n       assert isinstance(targets, float)\n       if targets in [0., 1.]:\n         entropy = 0.\n       else:\n         entropy = - targets * np.log(targets) - (1. - targets) * np.log(1. - targets)\n         return tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf.ones_like(logits) * targets) - entropy\n'"
hypergan/losses/boundary_equilibrium_loss.py,8,"b'import tensorflow as tf\nimport hyperchamber as hc\nfrom hypergan.ops.tensorflow.activations import minmaxzero\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nclass BoundaryEquilibriumLoss(BaseLoss):\n    def required(self):\n        return ""type use_k reduce k_lambda gamma initial_k"".split()\n\n    # boundary equilibrium gan\n    def began(self, d_real, d_fake):\n        gan = self.gan\n        config = self.config\n        ops = self.gan.ops\n\n        a,b,c = config.labels or [0,1,1]\n\n        d_real = config.reduce(d_real)\n        d_fake = config.reduce(d_fake)\n\n        k = tf.get_variable(gan.ops.generate_scope()+\'k\', [1], initializer=tf.constant_initializer(config.initial_k), dtype=config.dtype)\n\n        if config.type == \'wgan\':\n            l_x = d_real\n            l_dg =-d_fake\n            g_loss = d_fake\n        elif config.type == \'least-squares\':\n            l_x = tf.square(d_real-b)\n            l_dg = tf.square(d_fake - a)\n            g_loss = tf.square(d_fake - c)\n        else:\n            print(""No loss defined.  Get ready to crash"")\n\n        if config.use_k:\n            d_loss = l_x+k*l_dg\n        else:\n            d_loss = l_x+l_dg\n\n        gamma = config.gamma or 0.5\n        gamma_d_real = gamma*d_real\n\n        ### VERIFY FROM HERE\n        k_loss = gamma_d_real - g_loss\n        clip = k + config.k_lambda * k_loss\n        clip = tf.clip_by_value(clip, 0, 1)\n        clip = tf.reduce_mean(clip, axis=0)\n        update_k = tf.assign(k, tf.reshape(clip, [1]))\n        measure = self.gan.ops.squash(l_x + tf.abs(k_loss))\n\n        d_loss = ops.reshape(d_loss, [])\n        g_loss = ops.reshape(g_loss, [])\n\n        return [k, update_k, measure, d_loss, g_loss]\n\n\n    def _create(self, d_real, d_fake):\n        gan = self.gan\n        config = self.config\n\n        x = gan.inputs.x\n        k, update_k, measure, d_loss, g_loss = self.began(d_real, d_fake)\n\n        self.metrics = {\n            \'k\': k,\n            \'update_k\': update_k, #side effect, this actually trains k\n            \'measure\': measure\n        }\n\n        return [d_loss, g_loss]\n'"
hypergan/losses/category_loss.py,7,"b'from hypergan.losses.base_loss import BaseLoss\n\nimport numpy as np\nimport tensorflow as tf\n\nTINY = 1e-12\nclass CategoryLoss(BaseLoss):\n\n    def required(self):\n        return ""category_lambda activation"".split()\n\n    def _create(self, d_real, d_fake):\n        gan = self.gan\n        ops = self.ops\n        config = self.config\n        categories = gan.encoder.categories\n        size = sum([ops.shape(x)[1] for x in categories])\n        activation = ops.lookup(config.activation)\n\n        category_layer = gan.discriminator.ops.linear(gan.discriminator.sample, size)\n        category_layer= ops.layer_regularizer(d_real, config.layer_regularizer, config.batch_norm_epsilon)\n        category_layer = activation(category_layer)\n\n        loss = self.categories_loss(categories, category_layer)\n\n        loss = -1*config.category_lambda*loss\n        d_loss = loss\n        g_loss = loss\n\n        return d_loss, g_loss\n\n    def categories_loss(self, categories, layer):\n        gan = self.gan\n        loss = 0\n        batch_size = gan.batch_size()\n        def split(layer):\n            start = 0\n            ret = []\n            for category in categories:\n                count = int(category.get_shape()[1])\n                ret.append(tf.slice(layer, [0, start], [batch_size, count]))\n                start += count\n            return ret\n\n        for category,layer_s in zip(categories, split(layer)):\n            size = int(category.get_shape()[1])\n            category_prior = tf.ones([batch_size, size])*np.float32(1./size)\n            logli_prior = tf.reduce_sum(tf.log(category_prior + TINY) * category, axis=1)\n            layer_softmax = tf.nn.softmax(layer_s)\n            logli = tf.reduce_sum(tf.log(layer_softmax+TINY)*category, axis=1)\n            disc_ent = tf.reduce_mean(-logli_prior)\n            disc_cross_ent =  tf.reduce_mean(-logli)\n\n            loss += disc_ent - disc_cross_ent\n        return loss\n\n\n'"
hypergan/losses/cramer_loss.py,0,"b'import tensorflow as tf\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nclass CramerLoss(BaseLoss):\n\n    def _create(self, d_real, d_fake):\n        gan = self.gan\n        config = self.config\n        \n        g_loss = d_real - d_fake\n        d_loss = -g_loss\n\n        return [d_loss, g_loss]\n'"
hypergan/losses/evolution_loss.py,10,"b'import tensorflow as tf\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nclass EvolutionLoss(BaseLoss):\n\n    def required(self):\n        return ""reduce"".split()\n\n    def _create(self, d_real, d_fake):\n        ops = self.ops\n        config = self.config\n        gan = self.gan\n\n        pq = d_real\n        pp = d_fake\n        zeros = tf.zeros_like(d_fake)\n        ones = tf.ones_like(d_fake)\n\n\n\n        if config.mutation == \'least_squares\':\n            a,b,c = config.labels\n            square = ops.lookup(\'square\')\n            g_loss = 0.5*square(d_fake - c)\n        elif config.mutation == \'improved\':\n            g_loss = self.sigmoid_kl_with_logits(d_fake, generator_target_probability)\n        else:\n            g_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake, labels=zeros) \n\n        if config.type == \'label_smoothing\':\n            generator_target_probability = config.generator_target_probability or 0.8\n            label_smooth = config.label_smooth or 0.2\n            d_loss = self.sigmoid_kl_with_logits(d_real, 1.-label_smooth) + \\\n                    tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake, labels=zeros)\n        elif config.type == \'least_squares\':\n            a,b,c = config.labels\n            d_loss = 0.5*square(d_real - b) + 0.5*square(d_fake - a)\n        else:\n            d_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=d_real, labels=zeros) + \\\n                     tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake, labels=ones)\n\n        return [d_loss, g_loss]\n\n    def create(self):\n        gan = self.gan\n        config = self.config\n        ops = self.gan.ops\n        split = len(gan.generator.children)+len(gan.generator.parents)+1\n        #generator structure: \n        # x, gp1, ..., gpn, gc1, ..., gcm\n        d_real = self.d_real\n        d_fake = self.d_fake\n\n        net = gan.discriminator.sample\n\n        ds = self.split_batch(net, split)\n        d_real = ds[0]\n        d_fake = tf.add_n(ds[1:len(gan.generator.parents)+1])/(len(gan.generator.parents))\n        d_loss, _ = self._create(d_real, d_fake)\n\n        ds = self.split_batch(net, split)\n        d_real = ds[0]\n        d_fake = tf.add_n(ds[1+len(gan.generator.parents):])/(len(gan.generator.children))\n        _, g_loss = self._create(d_real, d_fake)\n        self.children_losses = self.split_batch(g_loss, len(gan.generator.children))\n\n        d_loss = ops.squash(d_loss, config.reduce or tf.reduce_mean) #linear doesn\'t work with this\n        g_loss = ops.squash(g_loss, config.reduce or tf.reduce_mean)\n\n        self.sample = [d_loss, g_loss]\n        self.d_loss = d_loss\n        self.g_loss = g_loss\n\n        return self.sample\n\n\n'"
hypergan/losses/f_divergence_loss.py,55,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nTINY=1e-8\nclass FDivergenceLoss(BaseLoss):\n\n    def _create(self, d_real, d_fake):\n        gan = self.gan\n        config = self.config\n\n        gfx = None\n        gfg = None\n\n        pi = config.pi or 2\n\n        g_loss_type = config.g_loss_type or \'gan\'\n\n        alpha = config.alpha or 0.5\n\n        if config.type == \'kl\':\n            bounded_x = tf.minimum(tf.constant(np.exp(9), dtype=tf.float32), d_real)\n            bounded_g = tf.minimum(10., d_fake)\n            gfx = bounded_x\n            gfg = bounded_g\n        elif config.type == \'js\':\n            gfx = np.log(2) - tf.log(1+tf.exp(-d_real))\n            gfg = np.log(2) - tf.log(1+tf.exp(-d_fake))\n        elif config.type == \'js_weighted\':\n            gfx = -pi*np.log(pi) - tf.log(1+tf.exp(-d_real))\n            gfg = -pi*np.log(pi) - tf.log(1+tf.exp(-d_fake))\n        elif config.type == \'gan\':\n            gfx = -tf.log(1+tf.exp(-d_real))\n            gfg = -tf.log(1+tf.exp(-d_fake))\n        elif config.type == \'reverse_kl\':\n            gfx = -tf.exp(-d_real)\n            gfg = -tf.exp(-d_fake)\n        elif config.type == \'pearson\' or config.type == \'jeffrey\' or config.type == \'alpha2\':\n            gfx = d_real\n            gfg = d_fake\n        elif config.type == \'squared_hellinger\':\n            gfx = 1-tf.exp(-d_real)\n            gfg = 1-tf.exp(-d_fake)\n        elif config.type == \'neyman\':\n            gfx = 1-tf.exp(-d_real)\n            gfx = tf.minimum(gfx, 1.9)\n            gfg = 1-tf.exp(-d_fake)\n\n        elif config.type == \'total_variation\':\n            gfx = 0.5*tf.nn.tanh(d_real)\n            gfg = 0.5*tf.nn.tanh(d_fake)\n\n        elif config.type == \'alpha1\':\n            gfx = 1./(1-alpha) - tf.log(1+tf.exp(-d_real))\n            gfg = 1./(1-alpha) - tf.log(1+tf.exp(-d_fake))\n\n        else:\n            raise ""Unknown type "" + config.type\n\n        conjugate = None\n\n        if config.type == \'kl\':\n            conjugate = tf.exp(gfg-1)\n        elif config.type == \'js\':\n            bounded = tf.minimum(tf.log(2.)-TINY, gfg)\n            conjugate = -tf.log(2-tf.exp(bounded))\n        elif config.type == \'js_weighted\':\n            c = -pi*np.log(pi)-TINY\n            c = tf.constant(c, dtype=tf.float32)\n            bounded = gfg#tf.maximum(gfg, c)\n            conjugate = (1-pi)*tf.log((1-pi)/((1-pi)*tf.exp(bounded/pi)))\n        elif config.type == \'gan\':\n            conjugate = -tf.log(1-tf.exp(gfg))\n        elif config.type == \'reverse_kl\':\n            conjugate = -1-tf.log(-gfg)\n        elif config.type == \'pearson\':\n            conjugate = 0.25 * tf.square(gfg)+gfg\n        elif config.type == \'neyman\':\n            conjugate = 2 - 2 * tf.sqrt(tf.nn.relu(1-gfg)+1e-2)\n        elif config.type == \'squared_hellinger\':\n            conjugate = gfg/(1.-gfg)\n        elif config.type == \'jeffrey\':\n            raise ""jeffrey conjugate not implemented""\n\n        elif config.type == \'alpha2\' or config.type == \'alpha1\':\n            bounded = gfg\n            bounded = 1./alpha * (bounded * ( alpha - 1) + 1)\n            conjugate = tf.pow(bounded, alpha/(alpha - 1.)) - 1. / alpha\n\n        elif config.type == \'total_variation\':\n            conjugate = gfg\n        else:\n            raise ""Unknown type "" + config.type\n\n        gf_threshold  = None # f\' in the paper\n\n        if config.type == \'kl\':\n            gf_threshold = 1\n        elif config.type == \'js\':\n            gf_threshold = 0\n        elif config.type == \'gan\':\n            gf_threshold = -np.log(2)\n        elif config.type == \'reverse_kl\':\n            gf_threshold = -1\n        elif config.type == \'pearson\':\n            gf_threshold = 0\n        elif config.type == \'squared_hellinger\':\n            gf_threshold = 0\n\n        self.gf_threshold=gf_threshold\n\n        d_loss = -gfx+conjugate\n        g_loss = -conjugate\n\n        if g_loss_type == \'gan\':\n            g_loss = -conjugate\n        elif g_loss_type == \'total_variation\':\n            # The inverse of derivative(1/2*x - 1)) = 0.5\n            # so we use the -conjugate for now\n            g_loss = -conjugate\n        elif g_loss_type == \'js\':\n            # https://www.wolframalpha.com/input/?i=inverse+of+derivative(-(u%2B1)*log((1%2Bu)%2F2)%2Bu*log(u))\n            g_loss = -tf.exp(d_fake)\n        elif g_loss_type == \'js_weighted\':\n            # https://www.wolframalpha.com/input/?i=inverse+of+derivative(-(u%2B1)*log((1%2Bu)%2F2)%2Bu*log(u))\n            p = pi\n            u = d_fake\n            #inner = (-4.*u*tf.exp(p/u) + tf.exp(2.)*tf.square(u)-2.*tf.exp(2.)*u+tf.exp(2.))/tf.square(u)\n            #inner = tf.nn.relu(inner) + 1e-3\n            #g_loss = (1.-u)/(2.*u) - tf.sqrt(inner)/(2.*tf.exp(1.))\n            exp_bounded = p/u\n            exp_bounded = tf.minimum(4., exp_bounded)\n            inner = (-4.*u*tf.exp(exp_bounded) +np.exp(2.)*tf.square(u)-2.*np.exp(2.)*u+np.exp(2.))/tf.square(u)\n            inner = tf.nn.relu(inner)\n            u = tf.maximum(0.1,u)\n            sqrt = tf.sqrt(inner+1e-2) / (2*np.exp(1))\n            g_loss = (1.-u)/(2.*u)# + sqrt\n        elif g_loss_type == \'pearson\':\n            g_loss = -(d_fake-2.0)/2.0\n        elif g_loss_type == \'neyman\':\n            g_loss = 1./tf.sqrt(1-d_fake) # does not work, causes \'nan\'\n        elif g_loss_type == \'squared_hellinger\':\n            g_loss = -1.0/(tf.square(d_fake-1)+1e-2)\n        elif g_loss_type == \'reverse_kl\':\n            g_loss = -d_fake\n        elif g_loss_type == \'kl\':\n            g_loss = -gfg * tf.exp(gfg)\n        elif g_loss_type == \'alpha1\': \n            a = alpha\n            bounded = d_fake\n            g_loss = (1.0/(a*(a-1))) * (tf.exp(a*bounded) - 1 - a*(tf.exp(bounded) - 1))\n        elif g_loss_type == \'alpha2\':\n            a = alpha\n            bounded = tf.minimum(d_fake, 4.)\n            g_loss = -(1.0/(a*(a-1))) * (tf.exp(a*bounded) - 1 - a*(tf.exp(bounded) - 1))\n        else:\n            raise ""Unknown g_loss_type "" + config.type\n\n        self.gfg = gfg\n        self.gfx = gfx\n\n        self.d_real = d_real\n        self.d_fake = d_fake\n\n        return [d_loss, g_loss]\n\n    def g_regularizers(self):\n        regularizer = None\n        config = self.config\n        pi = config.pi or 2\n        alpha = config.alpha or 0.5\n\n        ddfc = 0\n\n        if config.regularizer is None:\n            return []\n        if config.regularizer == \'kl\':\n            # https://www.wolframalpha.com/input/?i=derivative(derivative(exp(t-1)))\n            bounded = tf.minimum(4., self.gfg)\n            ddfc = tf.exp(bounded - 1)\n        elif config.regularizer == \'js\':\n            # https://www.wolframalpha.com/input/?i=derivative(derivative(-log(2-exp(t))))\n            ddfc = -(2*tf.exp(self.gfg)) / (tf.square(2-tf.exp(self.gfg))+1e-2)\n        elif config.regularizer == \'js_weighted\':\n            # https://www.wolframalpha.com/input/?i=derivative(derivative((1-C)*log(((1-C)%2F(1-C*exp(x%2FC)))))\n            ddfc = -((pi-1)*tf.exp(self.gfg/pi))/(pi*tf.square(pi*tf.exp(self.gfg/pi)-1))\n        elif config.regularizer == \'gan\':\n            # https://www.wolframalpha.com/input/?i=derivative(derivative(-log(1-exp(t))))\n            ddfc = (2*tf.exp(self.gfg)) / (tf.square(1-tf.exp(self.gfg))+1e-2)\n        elif config.regularizer == \'reverse_kl\':\n            # https://www.wolframalpha.com/input/?i=derivative(derivative(-1-log(-x)))\n            ddfc = 1.0/tf.square(self.gfg)\n        elif config.regularizer == \'pearson\':\n            # https://www.wolframalpha.com/input/?i=derivative(derivative(0.25*x*x+%2B+x))\n            ddfc = 0.5\n        elif config.regularizer == \'jeffrey\':\n            raise ""jeffrey regularizer not implemented""\n        elif config.regularizer == \'squared_hellinger\': \n            # https://www.wolframalpha.com/input/?i=derivative(derivative(t%2F(1-t)))\n            ddfc = 2 / (tf.pow(self.gfg - 1, 3)+1e-2)\n            #ddfc = 0\n        elif config.regularizer == \'neyman\':\n            # https://www.wolframalpha.com/input/?i=derivative(derivative(2-2*sqrt(1-t)))\n            ddfc = 1.0/(2*tf.pow(1-self.gfg, 3/2))\n        elif config.regularizer == \'total_variation\':\n            # https://www.wolframalpha.com/input/?i=derivative(derivative(t))\n            ddfc = 0\n        elif config.regularizer == \'alpha1\' or config.regularizer == \'alpha2\':\n            # https://www.wolframalpha.com/input/?i=derivative(derivative(1%2FC*(x*(C-1)%2B1)%5E(C%2FC-1)-1%2FC))\n            ddfc = -tf.pow((alpha - 1)*self.gfg+1, (1/(alpha-1)-1))\n        regularizer = ddfc * tf.nn.l2_normalize(self.gfg, [0]) * (config.regularizer_lambda or 1)\n        self.metrics[\'fgan_regularizer\'] = self.gan.ops.squash(regularizer)\n        return [regularizer ]\n        \n    def d_regularizers(self):\n        return []\n'"
hypergan/losses/lamb_gan_loss.py,0,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\n\nfrom hypergan.losses.standard_loss import StandardLoss\nfrom hypergan.losses.least_squares_loss import LeastSquaresLoss\nfrom hypergan.losses.wasserstein_loss import WassersteinLoss\nfrom hypergan.losses.base_loss import BaseLoss\n\n\nclass LambGanLoss(BaseLoss):\n\n    def required(self):\n        return ""label_smooth"".split()\n\n    def _create(self, d_real, d_fake):\n        config = self.config\n\n        alpha = config.alpha\n        beta = config.beta\n        wgan_loss_d, wgan_loss_g = WassersteinLoss._create(self, d_real, d_fake)\n        lsgan_loss_d, lsgan_loss_g = LeastSquaresLoss._create(self, d_real, d_fake)\n        standard_loss_d, standard_loss_g = StandardLoss._create(self, d_real, d_fake)\n\n        total = min(alpha + beta,1)\n\n        d_loss = wgan_loss_d*alpha + lsgan_loss_d*beta + (1-total)*standard_loss_d\n        g_loss = wgan_loss_g*alpha + lsgan_loss_g*beta + (1-total)*standard_loss_g\n\n        return [d_loss, g_loss]\n\n'"
hypergan/losses/least_squares_loss.py,0,"b'import tensorflow as tf\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nclass LeastSquaresLoss(BaseLoss):\n\n    def required(self):\n        return ""labels"".split()\n\n    def _create(self, d_real, d_fake):\n        ops = self.gan.ops\n        config = self.config\n\n        a,b,c = config.labels\n        square = ops.lookup(\'square\')\n        d_loss = 0.5*square(d_real - b) + 0.5*square(d_fake - a)\n        g_loss = 0.5*square(d_fake - c)\n\n        return [d_loss, g_loss]\n'"
hypergan/losses/logistic_loss.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nclass LogisticLoss(BaseLoss):\n\n    def _create(self, d_real, d_fake):\n        config = self.config\n\n        d_loss = tf.nn.softplus(-d_real) + tf.nn.softplus(d_fake)\n        g_loss = tf.nn.softplus(-d_fake)\n\n        return [d_loss, g_loss]\n'"
hypergan/losses/multi_loss.py,1,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\nfrom hypergan.multi_component import MultiComponent\n\nTINY=1e-8\nclass MultiLoss(BaseLoss):\n    """"""Takes multiple distributions and does an additional approximator""""""\n    def _create(self, d_real, d_fake):\n        gan = self.gan\n        config = self.config\n        losses = []\n        split = self.split\n\n        for d in gan.discriminator.children:\n            if config.swapped:\n                d_swap = d_real\n                d_real = d_fake\n                d_fake = d_swap\n            ds = self.split_batch(d.sample, split)\n            d_real = ds[0]\n            d_fake = tf.add_n(ds[1:])/(len(ds)-1)\n\n            loss_object = self.config[\'loss_class\'](gan, self.config, d_real=d_real, d_fake=d_fake)\n\n            losses.append(loss_object)\n\n        #relational layer?\n        combine = MultiComponent(combine=\'concat\', components=losses)\n\n        g_loss = combine.g_loss_features\n        d_loss = combine.d_loss_features\n\n        self.d_loss = d_loss\n        self.g_loss = g_loss\n\n        self.losses = losses\n\n        return [d_loss, g_loss]\n\n\n'"
hypergan/losses/qp_loss.py,4,"b'#https://arxiv.org/pdf/1811.07296.pdf\nimport tensorflow as tf\nimport hyperchamber as hc\nfrom functools import reduce\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nclass QPLoss(BaseLoss):\n\n\n    def _create(self, d_real, d_fake):\n        ops = self.ops\n        config = self.config\n        gan = self.gan\n\n        pq = d_real\n        pp = d_fake\n        zeros = tf.zeros_like(d_fake)\n        ones = tf.ones_like(d_fake)\n\n        lam = 10.0/(reduce(lambda x,y:x*y, gan.output_shape()))\n        dist = gan.l1_distance()\n\n        dl = d_real - d_fake\n        d_norm = 10 * tf.reduce_mean(tf.abs(dist), axis=[1, 2, 3])\n        d_loss = tf.reduce_mean(- dl + 0.5 * dl**2 / d_norm)\n\n        g_loss = d_real - d_fake\n\n\n\n        return [d_loss, g_loss]\n\n'"
hypergan/losses/ragan_loss.py,6,"b'import tensorflow as tf\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nTINY=1e-12\nclass RaganLoss(BaseLoss):\n\n    def required(self):\n        return ""reduce"".split()\n\n    def _create(self, d_real, d_fake):\n        ops = self.ops\n        config = self.config\n        gan = self.gan\n\n        pq = d_real\n        pp = d_fake\n        zeros = tf.zeros_like(d_fake)\n        ones = tf.ones_like(d_fake)\n\n\n        d_loss = -tf.log(tf.nn.sigmoid(pq-pp)+TINY)\n        g_loss = -tf.log(tf.nn.sigmoid(pp-pq)+TINY)\n\n        if config.type == ""least_squares"":\n            a,b,c = config.labels\n            d_loss = 0.5*tf.square(d_real - d_fake - b) + 0.5*tf.square(d_fake - d_real - a)\n            g_loss = 0.5*tf.square(d_fake - d_real - c) + 0.5*tf.square(d_real - d_fake - a)\n\n        return [d_loss, g_loss]\n\n'"
hypergan/losses/softmax_loss.py,4,"b'import tensorflow as tf\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nclass SoftmaxLoss(BaseLoss):\n\n    def _create(self, d_real, d_fake):\n        gan = self.gan\n        config = self.config\n        ops = self.gan.ops\n\n        ln_zb = tf.reduce_sum(tf.exp(-d_real), axis=1)+tf.reduce_sum(tf.exp(-d_fake), axis=1)\n        ln_zb = tf.log(ln_zb)\n\n        d_loss = tf.reduce_mean(d_real, axis=1) + ln_zb\n        g_loss = tf.reduce_mean(d_fake, axis=1) + tf.reduce_mean(d_real, axis=1) + ln_zb\n\n        d_loss = ops.reshape(d_loss, [])\n        g_loss = ops.reshape(g_loss, [])\n\n        return [d_loss, g_loss]\n\n'"
hypergan/losses/standard_loss.py,6,"b'import tensorflow as tf\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nclass StandardLoss(BaseLoss):\n\n    def required(self):\n        return ""reduce"".split()\n\n    def _create(self, d_real, d_fake):\n        ops = self.ops\n        config = self.config\n        gan = self.gan\n\n        generator_target_probability = config.generator_target_probability or 0.8\n        label_smooth = config.label_smooth or 0.2\n\n        zeros = tf.zeros_like(d_fake)\n        ones = tf.ones_like(d_fake)\n        if config.improved:\n            g_loss = self.sigmoid_kl_with_logits(d_fake, generator_target_probability)\n            d_loss = self.sigmoid_kl_with_logits(d_real, 1.-label_smooth) + \\\n                    tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake, labels=zeros)\n        else:\n            g_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake, labels=zeros)\n            d_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=d_real, labels=zeros) + \\\n                     tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake, labels=ones)\n\n        return [d_loss, g_loss]\n\n'"
hypergan/losses/supervised_loss.py,1,"b""import tensorflow as tf\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nclass SupervisedLoss(BaseLoss):\n\n    def _create(self, d_real, d_fake):\n        gan = self.gan\n        config = self.config\n\n        batch_size = gan.batch_size()\n        net = d_real\n\n        num_classes = gan.ops.shape(gan.inputs.y)[1]\n        net = gan.discriminator.ops.linear(net, num_classes)\n        net = self.layer_regularizer(net)\n\n        d_class_loss = tf.nn.softmax_cross_entropy_with_logits(logits=net,labels=gan.inputs.y)\n        d_class_loss = gan.ops.squash(d_class_loss)\n\n        self.metrics = {\n            'd_class_loss': d_class_loss\n        }\n\n        return [d_class_loss, None]\n"""
hypergan/losses/vral_loss.py,24,"b'import tensorflow as tf\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nclass VralLoss(BaseLoss):\n\n    def _create(self, d_real, d_fake):\n        TINY = 1e-12\n        config = self.config\n        ops = self.discriminator.ops\n        square = ops.lookup(\'square\')\n\n        print(""Initializing vral loss from "", d_fake, d_real)\n        fake_mean = config.fake_mean or 1\n        target_mean = config.target_mean or 0\n        nf = self.N(ops.shape(d_fake), fake_mean, 1)\n        f = self.F(nf)\n        fnf = f.sample\n\n        nr = self.N(ops.shape(d_real), target_mean, 1)\n        r = self.R(nr)\n        rnr = r.sample\n\n        if config.g_loss == \'l2\':\n            g_loss = tf.square(d_fake - target_mean)\n        elif config.g_loss == \'fr_l2\':\n            g_loss = tf.square(f.reuse(d_fake) - r.reuse(rnr))\n        elif config.g_loss == \'rr_l2\':\n            g_loss = tf.square(r.reuse(d_fake) - r.reuse(rnr))\n        else:\n            g_loss = tf.square(d_fake - target_mean)\n\n        #if config.type == \'lsgan\':\n        #    g_loss += square(f.sample - target_mean)\n\n        if config.value_function == \'l2\':\n            vf = 0.5*square(f.reuse(d_fake) - fnf)\n            vr = 0.5*square(r.reuse(d_real) - rnr)\n            d_loss = vr+vf\n        elif config.value_function == \'log\':\n            d_loss = -tf.log(tf.nn.sigmoid(f.reuse(d_fake))+TINY) - \\\n                      tf.log(tf.nn.sigmoid(r.reuse(d_real))+TINY)\n        else:\n            vf = tf.log(tf.nn.sigmoid(f.reuse(nf))+TINY) + \\\n                 tf.log(1 - tf.nn.sigmoid(f.reuse(d_fake))+TINY)\n            vr = tf.log(tf.nn.sigmoid(r.reuse(nr))+TINY) + \\\n                 tf.log(1 - tf.nn.sigmoid(r.reuse(d_real))+TINY)\n            d_loss = -vr-vf\n\n\n        if config.type == \'log_rr\':\n            d_loss -= tf.log(tf.nn.sigmoid(r.reuse(d_fake))+TINY)\n            d_loss -= tf.log(1 - tf.nn.sigmoid(r.reuse(d_real))+TINY)\n        elif config.type == \'log_rf\':\n            d_loss -= tf.log(tf.nn.sigmoid(r.reuse(d_fake))+TINY)\n            d_loss -= tf.log(1 - tf.nn.sigmoid(f.reuse(d_real))+TINY)\n        elif config.type == \'log_fr\':\n            d_loss -= tf.log(tf.nn.sigmoid(f.reuse(d_fake))+TINY)\n            d_loss -= tf.log(1 - tf.nn.sigmoid(r.reuse(d_real))+TINY)\n        elif config.type == \'log_ff\':\n            d_loss -= tf.log(tf.nn.sigmoid(f.reuse(d_fake))+TINY)\n            d_loss -= tf.log(1 - tf.nn.sigmoid(f.reuse(d_real))+TINY)\n        elif config.type == \'log_all\':\n            og = tf.log(tf.nn.sigmoid(f.reuse(d_fake))+TINY) + \\\n                 tf.log(1 - tf.nn.sigmoid(f.reuse(d_real))+TINY)\n            og2 = tf.log(tf.nn.sigmoid(r.reuse(d_real))+TINY) + \\\n                 tf.log(1 - tf.nn.sigmoid(r.reuse(d_fake))+TINY)\n            d_loss -= og\n            d_loss -= og2\n\n        else:\n            #d_loss = 0.5*square(f.reuse(d_real) - rnr) + 0.5*square(r.reuse(d_fake) - fnf)\n\n            d_loss += 0.5*square(r.reuse(d_real) - target_mean)\n            d_loss += 0.5*square(f.reuse(d_fake) - fake_mean)\n            d_loss += 0.5*square(r.reuse(d_fake) - fake_mean)\n            d_loss += 0.5*square(f.reuse(d_real) - target_mean)\n                     \n\n        return [d_loss, g_loss]\n\n    def N(self, shape, mean, stddev):\n        if self.config.distribution == ""uniform"":\n            return tf.random_uniform(shape, -1, 1) + mean\n        else:\n            return tf.random_normal(shape, mean, stddev)\n\n    def F(self, d_fake):\n        f_discriminator = self.gan.create_component(self.config.f_discriminator, name=""F_y_g_z"", reuse=self.discriminator.ops._reuse, input=d_fake)\n\n        self.discriminator.ops.add_weights(f_discriminator.variables())\n        if self.discriminator.ops._reuse:\n            f_discriminator.ops.stop_reuse()\n\n        return f_discriminator\n\n    def R(self, d_real):\n        r_discriminator = self.gan.create_component(self.config.r_discriminator, name=""R_y_X"", reuse=self.discriminator.ops._reuse, input=d_real)\n\n        self.discriminator.ops.add_weights(r_discriminator.variables())\n        if self.discriminator.ops._reuse:\n            r_discriminator.ops.stop_reuse()\n\n        return r_discriminator\n\n\n\n'"
hypergan/losses/wasserstein_loss.py,0,"b'import tensorflow as tf\nimport hyperchamber as hc\n\nfrom hypergan.losses.base_loss import BaseLoss\n\nclass WassersteinLoss(BaseLoss):\n\n    def _create(self, d_real, d_fake):\n        config = self.config\n\n        print(""Initializing Wasserstein loss"", config.reverse)\n        if(config.reverse):\n            d_loss = -d_real + d_fake\n            g_loss = -d_fake\n        else:\n            d_loss = d_real - d_fake\n            g_loss = d_fake\n\n        return [d_loss, g_loss]\n'"
hypergan/ops/__init__.py,0,"b'""""""\nHyperGAN depends on tensorflow.  We add commonly used operations here.\n""""""\nfrom .tensorflow.ops import TensorflowOps\nfrom .tensorflow.params import *\n'"
hypergan/optimizers/AdaBound.py,2,"b'""""""AdaBound for TensorFlow.""""""\n\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import resource_variable_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.ops import variable_scope\nfrom tensorflow.python.training import optimizer\nfrom tensorflow.python.ops.clip_ops import clip_by_value\nimport tensorflow as tf\n\n""""""Implements AdaBound algorithm.\n    It has been proposed in `Adaptive Gradient Methods with Dynamic Bound of Learning Rate`_.\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): Adam learning rate (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.9, 0.999))\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-8)\n        amsbound (boolean, optional): whether to use the AMSBound variant of this algorithm\n        arad(boolean, optional): use arad\n    .. Adaptive Gradient Methods with Dynamic Bound of Learning Rate:\n        https://openreview.net/forum?id=Bkg3g2R9FX\n    """"""\n\nclass AdaBoundOptimizer(optimizer.Optimizer):\n    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999,\n            beta1_power=""decay(range=0.1:0 steps=10000 metric=b1)"",\n            beta2_power=""decay(range=0.999:0 steps=10000 metric=b2)"",\n            lower_bound=""decay(range=0:1 steps=10000 metric=lower)"", \n            upper_bound=""decay(range=1000:1 steps=10000 metric=upper)"", \n            epsilon=1e-8, amsbound=False, gan=None, arad=False,\n                 config={},\n                 use_locking=False, name=""AdaBound""):\n        super(AdaBoundOptimizer, self).__init__(use_locking, name)\n        self._lr = gan.configurable_param(learning_rate)\n        self._beta1 = beta1\n        self._beta2 = beta2\n        self._epsilon = epsilon\n        self._gan = gan\n\n        self._lower_bound=gan.configurable_param(lower_bound)\n        self._upper_bound=gan.configurable_param(upper_bound)\n        self._beta1_power=gan.configurable_param(beta1_power)\n        self._beta2_power=gan.configurable_param(beta2_power)\n        self._amsbound = amsbound\n        self._arad = arad\n        self.config = config\n\n        self._lr_t = None\n        self._beta1_t = None\n        self._beta2_t = None\n        self._epsilon_t = None\n\n    def _create_slots(self, var_list):\n        first_var = min(var_list, key=lambda x: x.name)\n\n        graph = None if context.executing_eagerly() else ops.get_default_graph()\n        # Create slots for the first and second moments.\n        for v in var_list :\n            self._zeros_slot(v, ""m"", self._name)\n            self._zeros_slot(v, ""v"", self._name)\n            self._zeros_slot(v, ""vhat"", self._name)\n\n\n    def _prepare(self):\n        self._lr_t = ops.convert_to_tensor(self._lr)\n        self._base_lr_t = ops.convert_to_tensor(self._lr)\n        self._beta1_t = ops.convert_to_tensor(self._beta1)\n        self._beta2_t = ops.convert_to_tensor(self._beta2)\n        self._epsilon_t = ops.convert_to_tensor(self._epsilon)\n\n    def _apply(self, grad, var):\n        graph = None if context.executing_eagerly() else ops.get_default_graph()\n        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n        base_lr_t = math_ops.cast(self._base_lr_t, var.dtype.base_dtype)\n        beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)\n        beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)\n        epsilon_t = math_ops.cast(self._epsilon_t, var.dtype.base_dtype)\n\n        lr_t = lr_t * tf.sqrt(1-beta2_t)/(1-beta1_t)\n\n        lower_bound = lr_t * self._lower_bound\n        upper_bound = lr_t * self._upper_bound\n\n        # m_t = beta1 * m + (1 - beta1) * g_t\n        m = self.get_slot(var, ""m"")\n        m_scaled_g_values = grad * (1 - beta1_t)\n        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)\n\n        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n        v = self.get_slot(var, ""v"")\n        v_scaled_g_values = (grad * grad) * (1 - beta2_t)\n        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)\n\n        # amsgrad\n        vhat = self.get_slot(var, ""vhat"")\n        if self._amsbound :\n            vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))\n            v_sqrt = math_ops.sqrt(vhat_t)\n        else :\n            vhat_t = state_ops.assign(vhat, vhat)\n            v_sqrt = math_ops.sqrt(v_t)\n\n\n        # Compute the bounds\n        step_size_bound = lr_t / (v_sqrt + epsilon_t)\n        if isinstance(self.config.lower_bound, int) and self.config.lower_bound < 0:\n            bounded_lr = m_t * step_size_bound\n        else:\n            bounded_lr = m_t * clip_by_value(step_size_bound, lower_bound, upper_bound)\n\n        if self._arad:\n            bounded_lr *= (self.config.arad_lambda or 1.0) * tf.abs(m_t)\n\n        var_update = state_ops.assign_sub(var, bounded_lr, use_locking=self._use_locking)\n        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])\n\n    def _apply_dense(self, grad, var):\n        return self._apply(grad, var)\n\n    def _resource_apply_dense(self, grad, var):\n        return self._apply(grad, var)\n'"
hypergan/optimizers/amsgrad.py,0,"b'""""""AMSGrad for TensorFlow.""""""\n\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import resource_variable_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.ops import variable_scope\nfrom tensorflow.python.training import optimizer\n\n\nclass AMSGradOptimizer(optimizer.Optimizer):\n    def __init__(self, learning_rate=0.01, beta1=0.9, beta2=0.99, epsilon=1e-8, use_locking=False, name=""AMSGrad""):\n        super(AMSGradOptimizer, self).__init__(use_locking, name)\n        self._lr = learning_rate\n        self._beta1 = beta1\n        self._beta2 = beta2\n        self._epsilon = epsilon\n\n        self._lr_t = None\n        self._beta1_t = None\n        self._beta2_t = None\n        self._epsilon_t = None\n\n        self._beta1_power = None\n        self._beta2_power = None\n\n    def _create_slots(self, var_list):\n        first_var = min(var_list, key=lambda x: x.name)\n\n        create_new = self._beta1_power is None\n\n        if create_new:\n            with ops.colocate_with(first_var):\n                self._beta1_power = variable_scope.variable(self._beta1, name=""beta1_power"", trainable=False)\n                self._beta2_power = variable_scope.variable(self._beta2, name=""beta2_power"", trainable=False)\n        # Create slots for the first and second moments.\n        for v in var_list :\n            self._zeros_slot(v, ""m"", self._name)\n            self._zeros_slot(v, ""v"", self._name)\n            self._zeros_slot(v, ""vhat"", self._name)\n\n    def _prepare(self):\n        self._lr_t = ops.convert_to_tensor(self._lr)\n        self._beta1_t = ops.convert_to_tensor(self._beta1)\n        self._beta2_t = ops.convert_to_tensor(self._beta2)\n        self._epsilon_t = ops.convert_to_tensor(self._epsilon)\n\n    def _apply_dense(self, grad, var):\n        beta1_power = math_ops.cast(self._beta1_power, var.dtype.base_dtype)\n        beta2_power = math_ops.cast(self._beta2_power, var.dtype.base_dtype)\n        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n        beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)\n        beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)\n        epsilon_t = math_ops.cast(self._epsilon_t, var.dtype.base_dtype)\n\n        lr = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))\n\n        # m_t = beta1 * m + (1 - beta1) * g_t\n        m = self.get_slot(var, ""m"")\n        m_scaled_g_values = grad * (1 - beta1_t)\n        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)\n\n        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n        v = self.get_slot(var, ""v"")\n        v_scaled_g_values = (grad * grad) * (1 - beta2_t)\n        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)\n\n        # amsgrad\n        vhat = self.get_slot(var, ""vhat"")\n        vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))\n        v_sqrt = math_ops.sqrt(vhat_t)\n\n        var_update = state_ops.assign_sub(var, lr * m_t / (v_sqrt + epsilon_t), use_locking=self._use_locking)\n        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])\n\n    def _resource_apply_dense(self, grad, var):\n        var = var.handle\n        beta1_power = math_ops.cast(self._beta1_power, grad.dtype.base_dtype)\n        beta2_power = math_ops.cast(self._beta2_power, grad.dtype.base_dtype)\n        lr_t = math_ops.cast(self._lr_t, grad.dtype.base_dtype)\n        beta1_t = math_ops.cast(self._beta1_t, grad.dtype.base_dtype)\n        beta2_t = math_ops.cast(self._beta2_t, grad.dtype.base_dtype)\n        epsilon_t = math_ops.cast(self._epsilon_t, grad.dtype.base_dtype)\n\n        lr = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))\n\n        # m_t = beta1 * m + (1 - beta1) * g_t\n        m = self.get_slot(var, ""m"").handle\n        m_scaled_g_values = grad * (1 - beta1_t)\n        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)\n\n        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n        v = self.get_slot(var, ""v"").handle\n        v_scaled_g_values = (grad * grad) * (1 - beta2_t)\n        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)\n\n        # amsgrad\n        vhat = self.get_slot(var, ""vhat"").handle\n        vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))\n        v_sqrt = math_ops.sqrt(vhat_t)\n\n        var_update = state_ops.assign_sub(var, lr * m_t / (v_sqrt + epsilon_t), use_locking=self._use_locking)\n        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])\n\n    def _apply_sparse_shared(self, grad, var, indices, scatter_add):\n        beta1_power = math_ops.cast(self._beta1_power, var.dtype.base_dtype)\n        beta2_power = math_ops.cast(self._beta2_power, var.dtype.base_dtype)\n        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n        beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)\n        beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)\n        epsilon_t = math_ops.cast(self._epsilon_t, var.dtype.base_dtype)\n\n        lr = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))\n\n        # m_t = beta1 * m + (1 - beta1) * g_t\n        m = self.get_slot(var, ""m"")\n        m_scaled_g_values = grad * (1 - beta1_t)\n        m_t = state_ops.assign(m, m * beta1_t, use_locking=self._use_locking)\n        with ops.control_dependencies([m_t]):\n            m_t = scatter_add(m, indices, m_scaled_g_values)\n\n        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n        v = self.get_slot(var, ""v"")\n        v_scaled_g_values = (grad * grad) * (1 - beta2_t)\n        v_t = state_ops.assign(v, v * beta2_t, use_locking=self._use_locking)\n        with ops.control_dependencies([v_t]):\n            v_t = scatter_add(v, indices, v_scaled_g_values)\n\n        # amsgrad\n        vhat = self.get_slot(var, ""vhat"")\n        vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))\n        v_sqrt = math_ops.sqrt(vhat_t)\n        var_update = state_ops.assign_sub(var, lr * m_t / (v_sqrt + epsilon_t), use_locking=self._use_locking)\n        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])\n\n    def _apply_sparse(self, grad, var):\n        return self._apply_sparse_shared(\n            grad.values, var, grad.indices,\n            lambda x, i, v: state_ops.scatter_add(  # pylint: disable=g-long-lambda\n                x, i, v, use_locking=self._use_locking))\n\n    def _resource_scatter_add(self, x, i, v):\n        with ops.control_dependencies(\n                [resource_variable_ops.resource_scatter_add(x.handle, i, v)]):\n            return x.value()\n\n    def _resource_apply_sparse(self, grad, var, indices):\n        return self._apply_sparse_shared(\n            grad, var, indices, self._resource_scatter_add)\n\n    def _finish(self, update_ops, name_scope):\n        # Update the power accumulators.\n        with ops.control_dependencies(update_ops):\n            with ops.colocate_with(self._beta1_power):\n                update_beta1 = self._beta1_power.assign(\n                    self._beta1_power * self._beta1_t,\n                    use_locking=self._use_locking)\n                update_beta2 = self._beta2_power.assign(\n                    self._beta2_power * self._beta2_t,\n                    use_locking=self._use_locking)\n        return control_flow_ops.group(*update_ops + [update_beta1, update_beta2],\n                                      name=name_scope)\n'"
hypergan/optimizers/curl_optimizer.py,26,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass CurlOptimizer(optimizer.Optimizer):\n  def __init__(self, learning_rate=0.00001, p=0.1, gan=None, config=None, use_locking=False, name=""CurlOptimizer"", optimizer=None, rho=1, beta=-1, gamma=1, loss=None):\n    super().__init__(use_locking, name)\n    self._beta = gan.configurable_param(beta)\n    self._rho = rho\n    self._gamma = gamma\n    self.gan = gan\n    self.config = config\n    self._lr_t = learning_rate or 1e-5\n    self.g_rho = gan.configurable_param(self.config.g_rho or 1)\n    self.d_rho = gan.configurable_param(self.config.d_rho or 1)\n\n    optimizer[\'loss\'] = loss\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    d_vars = []\n    g_vars = []\n    d_grads = []\n    g_grads = []\n\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n            d_grads += [grad]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n            g_grads += [grad]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n\n    var_list = d_vars + g_vars\n\n    with ops.init_scope():\n        slots_list = []\n        if self.config.include_slots:\n            for name in self.optimizer.get_slot_names():\n                for var in self.optimizer.variables():\n                    slots_list.append(self._zeros_slot(var, ""curl"", ""curl""))\n    self._prepare()\n\n    def _name(post, s):\n        ss = s.split("":"")\n        return ss[0] + ""_"" + post + ""_dontsave""\n\n\n    v1 = [tf.Variable(v, name=_name(""curl"",v.name)) for v in var_list]\n    slots_list = []\n    slots_vars = []\n    if self.config.include_slots:\n        for name in self.optimizer.get_slot_names():\n            for var in self.optimizer.variables():\n                slots_vars += [var]\n                slots_list.append(self._zeros_slot(var, ""curl"", ""curl""))\n\n\n    restored_vars = var_list + slots_vars\n    tmp_vars = v1 + slots_list\n    # store variables for resetting\n\n    if self.config.beta_type == \'sga\':\n        Jgrads = tf.gradients(d_grads, d_vars, grad_ys=d_grads, stop_gradients=d_vars) + [tf.zeros_like(g) for g in g_vars]\n    elif self.config.beta_type == \'magnitude\':\n        consensus_reg = [tf.square(g) for g in d_grads if g is not None]\n        Jgrads = tf.gradients(consensus_reg, d_vars) + [tf.zeros_like(g) for g in g_vars]\n    else:\n        consensus_reg = 0.5 * sum(\n                tf.reduce_sum(tf.square(g)) for g in d_grads if g is not None\n        )\n        Jgrads = tf.gradients(consensus_reg, d_vars, stop_gradients=d_vars) + [tf.zeros_like(g) for g in g_vars]\n\n    g1s = d_grads + g_grads\n\n    op1 = tf.group(*[tf.assign(w, v) for w,v in zip(tmp_vars, restored_vars)]) # store variables\n\n    with tf.get_default_graph().control_dependencies([op1]):\n        # store g2\n        op3 = tf.group(*[tf.assign_sub(v, self._lr_t*grad) for grad,v in grads_and_vars])\n        with tf.get_default_graph().control_dependencies([op3]):\n\n            def curlcombine(g1,g2,_v1,_v2,curl,rho):\n                stepsize = self._lr_t\n                if curl == ""mirror"":\n                    return self._gamma*(g1 + 2*g2)\n                else:\n                    return self._gamma*g1-rho*(g2-g1)/stepsize\n            g2s = tf.gradients(self.gan.trainer.d_loss, d_vars) + tf.gradients(self.gan.trainer.g_loss, g_vars)\n            if self.config.form == \'central\':\n                def central_step():\n                    # restore v1, slots\n                    op5 = tf.group(*[ tf.assign(w,v) for w,v in zip(restored_vars, tmp_vars)])\n                    with tf.get_default_graph().control_dependencies([op5]):\n                        back =  tf.group(*[tf.assign_sub(v, -self._lr_t*grad) for grad,v in grads_and_vars])\n                        with tf.get_default_graph().control_dependencies([back]):\n                            return tf.gradients(self.gan.trainer.d_loss, d_vars) + tf.gradients(self.gan.trainer.g_loss, g_vars)\n                def curlcombinecentral(g1,g2,_v1,_v2,curl,rho):\n                    #stepsize = (_v2-_v1)/(g1+1e-8)\n                    stepsize = self._lr_t\n                    if curl == ""mirror"":\n                        return self._gamma*(g1 + 2*g2)\n                    else:\n                        return self._gamma*g1-rho*(g2-g1)/(2*stepsize)\n\n                g1s  = central_step()\n                g3s = [curlcombinecentral(g1,g2,v1,v2,self.config.d_curl,self.d_rho) if v2 in d_vars else curlcombinecentral(g1,g2,v1,v2,self.config.g_curl,self.g_rho) for g1,g2,v1,v2 in zip(g1s,g2s,v1,var_list)]\n            else:\n                #forward\n                g3s = [curlcombine(g1,g2,v1,v2,self.config.d_curl,self.d_rho) if v2 in d_vars else curlcombine(g1,g2,v1,v2,self.config.g_curl,self.g_rho) for g1,g2,v1,v2 in zip(g1s,g2s,v1,var_list)]\n            # restore v1, slots\n            op5 = tf.group(*[ tf.assign(w,v) for w,v in zip(restored_vars, tmp_vars)])\n            with tf.get_default_graph().control_dependencies([op5]):\n                flin = []\n                for grad, jg in zip(g3s, Jgrads):\n                    if jg is None or self._beta <= 0:\n                        flin += [grad]\n                    else:\n                        flin += [grad + jg * self._beta]\n\n                if self.config.orthonormal:\n                    shapes = [self.gan.ops.shape(l) for l in flin]\n                    u = [tf.reshape(l, [-1]) for l in flin[:len(d_vars)]]\n                    v = [tf.reshape(l, [-1]) for l in Jgrads[:len(d_vars)]]\n                    \n                    def proj(u, v,shape):\n                        dot = tf.tensordot(v, u, 1) / (tf.square(u)+1e-8)\n                        dot = tf.maximum(-1.0, dot)\n                        dot = tf.minimum(1.0, dot)\n                        dot = dot * u\n                        dot = tf.reshape(dot, shape)\n                        return dot\n                    proj_u1_v2 = [proj(_u, _v, _s) for _u, _v, _s in zip(u, v, shapes)]\n                    flin = [_flin + self.gan.configurable_param(self.config.ortholambda) * proj for _flin, proj in zip(flin, proj_u1_v2)] + flin[len(d_vars):]\n\n                step3 = list(zip(flin, var_list))\n                op6 = self.optimizer.apply_gradients(step3.copy(), global_step=global_step, name=name)\n\n                with tf.get_default_graph().control_dependencies([op6]):\n                    return tf.no_op()\n\n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n  def variables(self):\n      return self.optimizer.variables()\n'"
hypergan/optimizers/elastic_weight_consolidation_optimizer.py,17,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass ElasticWeightConsolidationOptimizer(optimizer.Optimizer):\n  """""" From https://arxiv.org/abs/1612.00796 """"""\n  def __init__(self, learning_rate=0.001, loss=None, p=0.1, gan=None, config=None, use_locking=False, name=""ElasticWeightConsolidationOptimizer"", optimizer=None, rho=1, beta=1, gamma=1):\n    super().__init__(use_locking, name)\n    self.gan = gan\n    self.config = config\n    self._lr_t = learning_rate\n    self.loss = loss\n\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    d_vars = []\n    g_vars = []\n    d_grads = []\n    g_grads = []\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n            d_grads += [grad]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n            g_grads += [grad]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n    all_grads = d_grads + g_grads\n    var_list = d_vars + g_vars\n\n    with ops.init_scope():\n        initial_f1 = [tf.constant(self.config.initial_constraint or 0.0, shape=self.gan.ops.shape(v)) for v in var_list]\n        f1 = [self._get_or_make_slot(v, f, ""f"", self._name) for f,v in zip(initial_f1, var_list)]\n        v1 = [self._get_or_make_slot(v, v, ""v1"", self._name) for v in var_list]\n        if self.config.include_slots:\n            for name in self.optimizer.get_slot_names():\n                for var in self.optimizer.variables():\n                    self._zeros_slot(var, ""pm"", ""pm"")\n    self._prepare()\n\n    f1 = [self.get_slot(v, ""f"") for v in var_list]\n    v1 = [self.get_slot(v, ""v1"") for v in var_list]\n    slots_list = []\n    slots_vars = []\n    if self.config.include_slots:\n        for name in self.optimizer.get_slot_names():\n            for var in self.optimizer.variables():\n                slots_vars += [var]\n                slots_list.append(self._zeros_slot(var, ""pm"", ""pm""))\n\n    current_vars = var_list + slots_vars\n    tmp_vars = v1 + slots_list\n\n    diff = [tf.square(v-t) for v,t in zip(current_vars, tmp_vars)]\n\n    f_accum = []\n    f_decay = self.gan.configurable_param(self.config.f_decay or 0.95)\n    gradient_scale = self.gan.configurable_param(self.config.gradient_scale or 1.0)\n    for v, f, g in zip(var_list, f1, all_grads):\n        opts = self.gan.layer_options(v)\n        if opts is not None and ""ewc_f_decay"" in opts:\n          f_decay = self.gan.configurable_param(opts[""ewc_f_decay""])\n          print(""Setting f_decay to "", f_decay, "" for "", v)\n\n        if opts is not None and ""ewc_gradient_scale"" in opts:\n          gradient_scale = self.gan.configurable_param(opts[""ewc_gradient_scale""])\n          print(""Setting gradient_scale to "", gradient_scale, "" for "", v)\n        f_accum += [f_decay * f + gradient_scale * tf.square(g)]\n    #f_accum = [tf.where(tf.is_nan(_f), tf.zeros_like(_f), _f) for _f in f_accum]\n    #f_accum = [tf.where(tf.is_inf(_f), tf.zeros_like(_f), _f) for _f in f_accum]\n    self.gan.add_metric(\'f1\',tf.reduce_sum([tf.reduce_sum(f) for f in f_accum]))\n\n    reg = [tf.multiply(f, d) for f,d in zip(f1, diff)]\n    #reg = [tf.where(tf.is_nan(_f), tf.zeros_like(_f), _f) for _f in reg]\n    ewc_loss = self.gan.configurable_param(self.config.lam or 17.5)/2.0 * tf.reduce_sum(tf.add_n([tf.reduce_sum(r) for r in reg]))\n    self.gan.add_metric(\'ewc\',ewc_loss)\n\n    save_weights = tf.group(*[tf.assign(w, v) for w,v in zip(tmp_vars, current_vars)]) # store variables\n\n    if isinstance(self.loss, list):\n        if self.config.add_ewc_loss_gradients:\n            newloss = [ewc_loss, ewc_loss]\n        else:\n            newloss = [self.loss[0]+ewc_loss, self.loss[1]+ewc_loss]\n\n        new_grads = tf.gradients(newloss[0], d_vars) + tf.gradients(newloss[1], g_vars)\n        self.optimizer.loss = [ewc_loss+self.loss[0], ewc_loss+self.loss[1]]\n    else:\n        if self.config.add_ewc_loss_gradients:\n            newloss = ewc_loss\n        else:\n            newloss = self.loss+ewc_loss\n\n        new_grads = tf.gradients(newloss, current_vars)\n        self.optimizer.loss =ewc_loss+self.loss\n\n    if self.config.add_ewc_loss_gradients:\n        new_grads = [_g+_ng for _g,_ng in zip(all_grads, new_grads)]\n\n    for g, oldg, v in zip(new_grads, all_grads, current_vars):\n        if(self.gan.ops.shape(g) != self.gan.ops.shape(oldg)):\n            print(""[ERROR] Shape change on gradients for"", v, g, ""old g"", oldg)\n            raise ""Gradient change error""\n    step = self.optimizer.apply_gradients(list(zip(new_grads, current_vars)).copy(), global_step=global_step, name=name)\n\n    store_f = tf.group(*[tf.assign(w, v) for w,v in zip(f1, f_accum)])\n    with tf.get_default_graph().control_dependencies([store_f]):\n        with tf.get_default_graph().control_dependencies([step]):\n            with tf.get_default_graph().control_dependencies([save_weights]):\n                return tf.no_op()\n\n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n  def variables(self):\n      return super().variables() + self.optimizer.variables()\n'"
hypergan/optimizers/giga_wolf_optimizer.py,20,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass GigaWolfOptimizer(optimizer.Optimizer):\n  def __init__(self, learning_rate=0.001, p=0.1, gan=None, config=None, use_locking=False, name=""GigaWolfOptimizer"", optimizer=None, optimizer2=None):\n    super().__init__(use_locking, name)\n    self.gan = gan\n    self.config = config\n    self._lr_t = learning_rate\n\n    optimizer = hc.lookup_functions(optimizer)\n    self.optimizer = self.gan.create_optimizer(optimizer)\n    optimizer2 = hc.lookup_functions(optimizer2)\n    self.optimizer2 = self.gan.create_optimizer(optimizer2)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    var_list = [ v for _,v in grads_and_vars]\n    with ops.init_scope():\n        zt = [self._get_or_make_slot(v, v, ""zt"", self._name) for _,v in grads_and_vars]\n        slots_list = []\n        for name in self.optimizer.get_slot_names():\n            for var in self.optimizer.variables():\n                self._get_or_make_slot(var, var, ""zt"", ""zt"")\n    self._prepare()\n\n    def _name(post, s):\n        ss = s.split("":"")\n        return ss[0] + ""_"" + post + ""_dontsave""\n    zt = [self.get_slot(v, ""zt"") for _,v in grads_and_vars]\n    xt = [tf.Variable(v, name=_name(""gigaxt"",v.name)) for _,v in grads_and_vars]\n    tmp = [tf.Variable(v, name=_name(""gigatmp"",v.name)) for _,v in grads_and_vars]\n    xslots_list = []\n    zslots_list = []\n    tmpslots_list = []\n    slots_vars = []\n    for name in self.optimizer.get_slot_names():\n        for var in self.optimizer.variables():\n            slots_vars += [var]\n            xslots_list.append(tf.Variable(var))\n            zslots_list.append(self._get_or_make_slot(var, var, ""zt"", ""zt""))\n            tmpslots_list.append(tf.Variable(var, name=_name(""gigaslottmp"", var.name)))\n\n\n    restored_vars = var_list + slots_vars\n    zt_vars = zt + zslots_list\n    xt_vars = xt + xslots_list\n    tmp_vars = tmp + tmpslots_list\n    all_grads = [ g for g, _ in grads_and_vars ]\n    # store variables for resetting\n\n    op1 = tf.group(*[tf.assign(w, v) for w,v in zip(tmp_vars, restored_vars)]) # store tmp_vars\n\n    with tf.get_default_graph().control_dependencies([op1]):\n        op2 = self.optimizer.apply_gradients(grads_and_vars.copy(), global_step=global_step, name=name)\n        with tf.get_default_graph().control_dependencies([op2]):\n            op3 = tf.group(*[tf.assign(w, v) for w,v in zip(xt_vars, restored_vars)]) # store xt^+1 in xt_vars\n            with tf.get_default_graph().control_dependencies([op3]):\n                op4 = tf.group(*[tf.assign(w, v) for w,v in zip(restored_vars, zt_vars)]) # restore vars to zt (different weights)\n                with tf.get_default_graph().control_dependencies([op4]):\n                    op5 = self.optimizer2.apply_gradients(grads_and_vars.copy(), global_step=global_step, name=name) # zt+1\n                    with tf.get_default_graph().control_dependencies([op5]):\n                        zt1_xt1 = [_restored_vars - _xt1_vars for _restored_vars, _xt1_vars in zip(restored_vars, xt_vars)]\n                        St1 = [tf.minimum(1.0, tf.norm(_zt1_vars-_zt_vars) / tf.norm(_zt1_xt1)) for _zt1_vars, _zt_vars, _zt1_xt1 in zip(restored_vars, zt_vars, zt1_xt1)]\n                        self.gan.add_metric(\'st1\',tf.reduce_mean(tf.add_n(St1)/len(St1)))\n                        #self.gan.add_metric(\'xzt1\',tf.norm(xt_vars[0]-zt_vars[0]))\n                        nextw = [_xt_t1 + _St1 * _zt1_xt1 for _xt_t1, _St1, _zt1_xt1 in zip(xt_vars, St1, zt1_xt1)]\n                        op6 = tf.group(*[tf.assign(w, v) for w,v in zip(zt_vars, restored_vars)]) # set zt+1\n                        with tf.get_default_graph().control_dependencies([op6]):\n                            op7 = tf.group(*[tf.assign(w, v) for w,v in zip(restored_vars, nextw)]) # set xt+1\n                            with tf.get_default_graph().control_dependencies([op7]):\n                                return tf.no_op()\n\n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n  def variables(self):\n      return super().variables() + self.optimizer2.variables()+ self.optimizer.variables()\n'"
hypergan/optimizers/gradient_magnitude_optimizer.py,7,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\n\nclass GradientMagnitudeOptimizer(optimizer.Optimizer):\n  """"""Projects layer gradients to a norm then multiplies by a constant""""""\n  def __init__(self, learning_rate=0.001, decay=0.9, gan=None, config=None, use_locking=False, name=""EmaOptimizer"", optimizer=None):\n    super().__init__(use_locking, name)\n    self._decay = decay\n    self.gan = gan\n    self.config = config\n    self.name = name\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    var_list = [v for _, v in grads_and_vars]\n    grad_list = [g for g, _ in grads_and_vars]\n\n\n    self._prepare()\n    def project_gradient_layer(gs):\n        if self.config.norm == \'softmax\':\n            return tf.nn.softmax(gs)\n        elif self.config.norm == \'euclidean\':\n            return gs / (tf.sqrt(tf.reduce_sum(tf.square(gs)))+1e-8)\n        elif self.config.norm == \'inf\':\n            return gs / (tf.norm(gs, ord=np.inf)+1e-8)\n        elif self.config.norm == \'max\':\n            return gs / (tf.reduce_max(tf.abs(gs))+1e-8)\n        elif self.config.norm == False:\n            return gs\n        else:\n            return gs / (tf.norm(gs, ord=self.config.norm)+1e-8)\n\n    lam = []\n    for g, v in grads_and_vars:\n        _lam = self.gan.configurable_param(self.config[""lambda""])\n        opts = self.gan.layer_options(v)\n        if opts is not None:\n            print(""OPTS"", opts)\n            if ""gradient_magnitude_lambda"" in opts:\n                _lam *= float(opts[""gradient_magnitude_lambda""])\n        lam.append(_lam)\n\n    print(""Lambdas = "", lam)\n\n    def number_weights(v):\n        count = np.prod(self.gan.ops.shape(v))\n        return count\n    if self.config.per_weight:\n        newlam = []\n        for _lam, v in zip(lam,grad_list):\n            newlam.append(_lam * number_weights(v))\n        lam = newlam\n    newgrads = [_lam * project_gradient_layer(g) for _lam, g in zip(lam, grad_list)]\n    newgrads_and_vars = list(zip(newgrads, var_list)).copy()\n    op = self.optimizer.apply_gradients(newgrads_and_vars, global_step=global_step, name=name)\n    with tf.get_default_graph().control_dependencies([op]):\n        return tf.no_op()\n\n  \n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n\n  def variables(self):\n      return super().variables() + self.optimizer.variables()\n'"
hypergan/optimizers/local_nash_optimizer.py,17,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\n\nclass LocalNashOptimizer(optimizer.Optimizer):\n  """"""https://arxiv.org/pdf/1901.00838v1.pdf""""""\n  def __init__(self, learning_rate=0.001, p=0.1, gan=None, config=None, use_locking=False, name=""SOSOptimizer"", optimizer=None, alpha=1, loss=None):\n    super().__init__(use_locking, name)\n    self._alpha = alpha\n    self.gan = gan\n    self.config = config\n    self._lr_t = learning_rate\n    optimizer[\'loss\']=loss\n    self.loss = loss\n\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def finite_differences(self, grads_and_vars, global_step, name, d_vars, g_vars, d_grads, g_grads):\n    """""" Attempt to directly compute hessian and apply equation (6) """"""\n    d_grads = []\n    g_grads = []\n    d_vars = []\n    g_vars = []\n    alpha = 0.5\n    if self.config.alpha is not None:\n        alpha = self.gan.configurable_param(self.config.alpha)\n    beta = 0.5\n    if self.config.beta is not None:\n        beta = self.gan.configurable_param(self.config.beta)\n\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n            d_grads += [grad]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n            g_grads += [grad]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n    orig_grads = d_grads+g_grads\n    all_vars = d_vars + g_vars\n\n    def curl():\n        grads = tf.gradients(self.gan.trainer.d_loss, d_vars) + tf.gradients(self.gan.trainer.g_loss, g_vars)\n        op3 = tf.group(*[tf.assign_sub(v, self._lr_t*grad) for grad,v in zip(grads, all_vars)])\n        with tf.get_default_graph().control_dependencies([op3]):\n            def curlcombine(g1,g2):\n                stepsize = self._lr_t\n                return g1-(g2-g1)/stepsize\n            new_grads = tf.gradients(self.gan.trainer.d_loss, d_vars) + tf.gradients(self.gan.trainer.g_loss, g_vars)\n            g3s = [curlcombine(g1,g2) for g1,g2 in zip(grads,new_grads)]\n            return g3s\n \n    #gamma12\n    if self.config.method == \'curl\':\n        all_grads = curl()\n        d_grads = all_grads[:len(d_vars)]\n        g_grads = all_grads[len(d_vars):]\n\n    all_grads = d_grads + g_grads\n\n    with ops.init_scope():\n        [self._zeros_slot(v, ""orig"", self._name) for _,v in grads_and_vars]\n\n    v1 = [self.get_slot(v, ""orig"") for v in all_vars]\n\n    restored_vars = all_vars\n    tmp_vars = v1\n\n    e1 = 0.0001\n    e2 = 0.0001\n\n    #gamma12\n    save = tf.group(*[tf.assign(w, v) for w,v in zip(tmp_vars.copy(), restored_vars.copy())]) # store variables\n\n    with tf.get_default_graph().control_dependencies([save]):\n        #opboth = self.optimizer.apply_gradients(grads_and_vars, global_step=global_step, name=name)\n        #opdp = self.optimizer.apply_gradients(grads_and_vars[:len(d_vars)], global_step=global_step, name=name)\n        #opgp = self.optimizer.apply_gradients(grads_and_vars[len(d_vars):], global_step=global_step, name=name)\n        restore = tf.group(*[tf.assign(w, v) for w,v in zip(restored_vars.copy(), tmp_vars.copy())]) # store variables\n        opboth = [tf.assign_sub(w, self._lr_t * v) for w,v in zip(all_vars.copy(), all_grads.copy())] # store variables\n        with tf.get_default_graph().control_dependencies([tf.group(*opboth)]):\n            if self.config.method == ""curl"":\n                gboth = curl()\n            else:\n                gboth = tf.gradients(self.loss[0], d_vars) + tf.gradients(self.loss[1], g_vars)\n            with tf.get_default_graph().control_dependencies([restore]):\n                opd = opboth[:len(d_vars)]\n                with tf.get_default_graph().control_dependencies([tf.group(*opd)]):\n                    if self.config.method == ""curl"":\n                        new_d_grads = curl()\n                    else:\n                        new_d_grads = tf.gradients(self.loss[0], d_vars) + tf.gradients(self.loss[1], g_vars)\n                    with tf.get_default_graph().control_dependencies([restore]):\n                        opg = opboth[len(d_vars):]\n                        with tf.get_default_graph().control_dependencies([tf.group(*opg)]):\n                            if self.config.method == ""curl"":\n                                new_g_grads = curl()\n                            else:\n                                new_g_grads = tf.gradients(self.loss[0], d_vars) + tf.gradients(self.loss[1], g_vars)\n                            with tf.get_default_graph().control_dependencies([restore]):\n                                new_grads = []\n                                for _gboth, _gd, _gg, _g, _orig_g in zip(gboth,new_d_grads,new_g_grads,(d_grads+g_grads), orig_grads):\n                                    a = (_gg - _g) / self._lr_t # d2f/dx2i\n                                    b = (_gboth - _gg) / (2*self._lr_t)+(_gd-_g)/(2*self._lr_t) # d2f/dx1dx2\n                                    c = (_gboth - _gd) / (2*self._lr_t)+(_gg-_g)/(2*self._lr_t) # d2f/dx1dx2\n                                    c = -c\n                                    d = -(_gd - _g) / self._lr_t # d2f/dx2j\n                                    if self.config.form == 5:\n                                        a = (_gg - _g) / self._lr_t # d2f/dx2i\n                                        b = (_gboth - _gg) / (2*self._lr_t)+(_gd-_g)/(2*self._lr_t) # d2f/dx1dx2\n                                        c = (_gboth - _gd) / (2*self._lr_t)+(_gg-_g)/(2*self._lr_t) # d2f/dx1dx2\n                                        d = (_gd - _g) / self._lr_t # d2f/dx2j\n                                    J = np.array([[a, b], [c,d]])\n                                    Jt = np.transpose(J)\n\n                                    det = a*d-b*c+1e-8\n                                    #h_1 = 1.0/det * (b+d-a-c)\n                                    h_1_a = d/det\n                                    h_1_b = -b/det\n                                    h_1_c = -c/det\n                                    h_1_d = a/det\n                                    Jinv = np.array([[h_1_a,h_1_b],[h_1_c,h_1_d]])\n                                    _j = Jt[0][0]*Jinv[0][0]*_g+Jt[1][0]*Jinv[1][0]*_g+Jt[0][1]*Jinv[0][1]*_g+Jt[1][1]*Jinv[1][1]*_g\n\n                                    new_grads.append( alpha*_orig_g + beta*_j )\n\n                                new_grads_and_vars = list(zip(new_grads, all_vars)).copy()\n                                return self.optimizer.apply_gradients(new_grads_and_vars, global_step=global_step, name=name)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    all_vars = [ v for _,v in grads_and_vars]\n    d_vars = []\n    g_vars = []\n    all_grads = [ g for g, _ in grads_and_vars ]\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n\n    with ops.init_scope():\n        self.optimizer._create_slots([v for g,v in grads_and_vars])\n    self._prepare()\n\n    d_grads = all_grads[:len(d_vars)]\n    g_grads = all_grads[len(d_vars):]\n    return self.finite_differences(grads_and_vars, global_step, name, d_vars, g_vars, d_grads, g_grads)\n  \n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n'"
hypergan/samplers/__init__.py,0,"b'""""""\nSamplers create images from generators.\n""""""\nfrom os.path import dirname, basename, isfile\nimport glob\nmodules = glob.glob(dirname(__file__)+""/*.py"")\n__all__ = [ basename(f)[:-3] for f in modules if isfile(f)]\n'"
hypergan/samplers/aligned_sampler.py,0,"b""from hypergan.samplers.base_sampler import BaseSampler\n\nimport tensorflow as tf\nimport numpy as np\n\nclass AlignedSampler(BaseSampler):\n    def __init__(self, gan):\n        BaseSampler.__init__(self, gan)\n        self.xa_v = None\n        self.xb_v = None\n        self.created = False\n\n    def compatible_with(gan):\n        if hasattr(gan.inputs, 'xa') and \\\n            hasattr(gan.inputs, 'xb') and \\\n            hasattr(gan, 'cyca'):\n            return True\n        return False\n\n    def sample(self, path, sample_to_file):\n        gan = self.gan\n        cyca = gan.cyca\n        cycb = gan.cycb\n        xa_t = gan.inputs.xa\n        xba_t = gan.xba\n        xab_t = gan.xab\n        xb_t = gan.inputs.xb\n        uga = gan.uga\n        ugb = gan.ugb\n\n        sess = gan.session\n        config = gan.config\n        if(not self.created):\n            self.xa_v, self.xb_v = sess.run([xa_t, xb_t])\n            self.created = True\n\n        xab_v, xba_v, samplea, sampleb, uga_v, ugb_v = sess.run([xab_t, xba_t, cyca, cycb, uga, ugb], {xa_t: self.xa_v, xb_t: self.xb_v})\n        stacks = []\n        bs = gan.batch_size() // 2\n        width = min(gan.batch_size(), 8)\n        for i in range(1):\n            stacks.append([self.xa_v[i*width+j] for j in range(width)])\n        for i in range(1):\n            stacks.append([xab_v[i*width+j] for j in range(width)])\n        for i in range(1):\n            stacks.append([samplea[i*width+j] for j in range(width)])\n        for i in range(1):\n            stacks.append([self.xb_v[i*width+j] for j in range(width)])\n        for i in range(1):\n            stacks.append([xba_v[i*width+j] for j in range(width)])\n        for i in range(1):\n            stacks.append([sampleb[i*width+j] for j in range(width)])\n        for i in range(1):\n            stacks.append([uga_v[i*width+j] for j in range(width)])\n        for i in range(1):\n            stacks.append([ugb_v[i*width+j] for j in range(width)])\n\n        images = np.vstack([np.hstack(s) for s in stacks])\n\n        self.plot(images, path, sample_to_file)\n        return [{'image': path, 'label': 'tiled x sample'}]\n"""
hypergan/samplers/alphagan_random_walk_sampler.py,2,"b""from hypergan.samplers.base_sampler import BaseSampler\nimport tensorflow as tf\nimport numpy as np\n\nclass AlphaganRandomWalkSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        BaseSampler.__init__(self, gan, samples_per_row)\n        self.z = None\n        self.y = None\n        self.x = None\n        self.mask = None\n        self.step = 0\n        self.steps = 8\n        self.target = None\n\n    def _sample(self):\n        gan = self.gan\n        z_t = gan.uniform_distribution.sample\n        inputs_t = gan.inputs.x\n        mask_t = gan.generator.mask\n\n        if self.z is None:\n            self.input = gan.session.run(gan.inputs.x)\n            self.z = gan.session.run(gan.z_hat, feed_dict={\n                inputs_t: self.input\n            })\n            self.direction = gan.uniform_distribution.sample.eval()/2\n            #direct = np.reshape(direct, [1, direct.shape[0]])\n            #self.direction = np.tile(direct, [self.z.shape[0], 1])\n            self.mask = gan.session.run(gan.autoencode_mask, feed_dict={\n                inputs_t: self.input, \n                gan.z_hat: self.z\n            })\n\n        if self.step > self.steps:\n            self.z = np.minimum(self.z+self.direction, 1)\n            self.z = np.maximum(self.z, -1)\n            self.direction = gan.uniform_distribution.sample.eval()\n\n            self.step = 0\n\n        self.direction = np.reshape(self.direction, self.z.shape)\n        percent = float(self.step)/self.steps\n        z_interp = self.z + self.direction*percent\n        z_interp = np.minimum(z_interp, 1)\n        z_interp = np.maximum(z_interp, -1)\n        self.step+=1\n\n        g=tf.get_default_graph()\n        with g.as_default():\n            tf.set_random_seed(1)\n            return {\n                'generator': gan.session.run(gan.uniform_sample, feed_dict={\n                    z_t: z_interp, \n                    inputs_t: self.input, \n                    mask_t: self.mask\n                })\n            }\n\n"""
hypergan/samplers/autoencode_sampler.py,2,"b""from hypergan.samplers.base_sampler import BaseSampler\nimport tensorflow as tf\nimport numpy as np\n\nclass AutoencodeSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        BaseSampler.__init__(self, gan, samples_per_row)\n        self.z = None\n        self.y = None\n        self.x = None\n\n    def _sample(self):\n        gan = self.gan\n        inputs_t = gan.inputs.x\n        z_t = gan.encoder.sample\n\n        if self.z is None:\n            self.input = gan.session.run(inputs_t)\n        self.z = gan.session.run(z_t, feed_dict={inputs_t: self.input})\n\n        destination = self.z[1]\n        origin = self.z[0]\n        for i in range(0, np.shape(self.z)[0], self.samples_per_row):\n            last = i+self.samples_per_row-1\n            multiple = np.linspace(0, 1, self.samples_per_row-4)\n\n            for j in range(i+2, last-1):\n                percent = (j - (i))/float((last) - (i+1))\n                self.z[j] = self.z[i]*(1.0-percent) + (self.z[last])*percent\n            self.z[i+1] = self.z[i]\n            self.z[last-1] = self.z[last]\n \n        output = gan.session.run(gan.generator.sample, feed_dict={z_t: self.z})\n        for i in range(0, np.shape(self.z)[0], self.samples_per_row):\n            last = i+self.samples_per_row-1\n            output[i] = self.input[i]\n            output[last] = self.input[last] \n        \n\n        g=tf.get_default_graph()\n        with g.as_default():\n            tf.set_random_seed(1)\n            return {\n                'generator': output\n            }\n\n"""
hypergan/samplers/base_sampler.py,1,"b'import numpy as np\nimport tensorflow as tf\nfrom PIL import Image\nfrom hypergan.viewer import GlobalViewer\n\nclass BaseSampler:\n    def __init__(self, gan, samples_per_row=8, session=None):\n        self.gan = gan\n        self.samples_per_row = samples_per_row\n\n    def _sample(self):\n        raise ""raw _sample method called.  You must override this""\n\n\n    def compatible_with(gan):\n        return False\n\n    def sample(self, path, save_samples):\n        gan = self.gan\n\n        with gan.session.as_default():\n\n            sample = self._sample()\n\n            data = sample[\'generator\']\n\n            width = min(gan.batch_size(), self.samples_per_row)\n            width = min(width, np.shape(data)[0])\n            stacks = [np.hstack(data[i*width:i*width+width]) for i in range(np.shape(data)[0]//width)]\n            sample_data = np.vstack(stacks)\n            self.plot(sample_data, path, save_samples)\n            sample_name = \'generator\'\n            samples = [[sample_data, sample_name]]\n\n            return [{\'image\':path, \'label\':\'sample\'} for sample_data, sample_filename in samples]\n\n\n    def replace_none(self, t):\n        """"""\n        This method replaces None with 0.\n        This can be used for sampling.  If sampling None, the viewer turns black and does not recover.\n        """"""\n        return tf.where(tf.is_nan(t),tf.zeros_like(t),t)\n\n    def plot(self, image, filename, save_sample, regularize=True):\n        """""" Plot an image.""""""\n        if regularize:\n            image = np.minimum(image, 1)\n            image = np.maximum(image, -1)\n        image = np.squeeze(image)\n        if np.shape(image)[2] == 4:\n            fmt = ""RGBA""\n        else:\n            fmt = ""RGB""\n        # Scale to 0..255.\n        imin, imax = image.min(), image.max()\n        image = (image - imin) * 255. / (imax - imin) + .5\n        image = image.astype(np.uint8)\n        if save_sample:\n            try:\n                Image.fromarray(image, fmt).save(filename)\n            except Exception as e:\n                print(""Warning: could not sample to "", filename, "".  Please check permissions and make sure the path exists"")\n                print(e)\n        GlobalViewer.update(self.gan, image)\n'"
hypergan/samplers/batch_sampler.py,0,"b""from hypergan.samplers.base_sampler import BaseSampler\nimport tensorflow as tf\n\nclass BatchSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        BaseSampler.__init__(self, gan, samples_per_row)\n\n    def _sample(self):\n        gan = self.gan\n\n        return {\n            'generator': gan.session.run(gan.generator.sample)\n        }\n\n"""
hypergan/samplers/batch_walk_sampler.py,0,"b'import numpy as np\nimport tensorflow as tf\nfrom PIL import Image\nfrom hypergan.viewer import GlobalViewer\nfrom hypergan.samplers.base_sampler import BaseSampler\nimport time\n\nclass BatchWalkSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8, session=None):\n        BaseSampler.__init__(self, gan, samples_per_row)\n        self.z_start = None\n        self.y = None\n        self.x = None\n        self.step = 0\n        self.steps = []\n        self.step_count = 30\n        self.target = None\n        self.rows = 2\n        self.columns = 4\n        self.needed = int(self.rows*self.columns / gan.batch_size())\n        #self.style_t = gan.styleb.sample\n        #self.style_v = gan.session.run(self.style_t)\n\n\n    def regenerate_steps(self):\n        gan = self.gan\n        z_t = gan.latent.sample\n        inputs_t = gan.inputs.x\n\n        s=np.shape(gan.session.run(gan.latent.sample))\n        bs = 16\n        if self.z_start is None:\n            self.z_start = [gan.session.run(gan.latent.sample)[0] for _ in range(self.needed)]\n        else:\n            print(""UPDAING Z STARCT"")\n            self.z_start = [self.steps[i][-1] for i in range(len(self.z_start))]\n\n        targ = [gan.session.run(gan.latent.sample)[0] for _ in range(self.needed)]\n\n        z_interps = []\n        for i in range(len(self.z_start)):\n            mask = np.linspace(0., 1., num=bs)\n            z = np.tile(np.expand_dims(np.reshape(self.z_start[i], [-1]), axis=0), [bs,1])\n            tg = np.tile(np.expand_dims(np.reshape(targ[i], [-1]), axis=0), [bs,1])\n            mask = np.tile(np.expand_dims(mask, axis=1), [1, np.shape(self.z_start[i])[-1]])\n            z_interp = np.multiply(1.0-mask,z) + mask*tg\n            z_interps += [z_interp]\n        print(\'z_INT\', np.shape(z_interps))\n        return z_interps\n\n    def _sample(self):\n        gan = self.gan\n        z_t = gan.latent.sample\n        inputs_t = gan.inputs.x\n        self.step+=1\n\n        if(len(self.steps) == 0 or self.step >= len(self.steps[0])):\n            self.steps = self.regenerate_steps()\n            self.step=0\n\n        gs = []\n        for i in range(int(self.needed)):\n            z = self.steps[i][self.step]\n            z = np.expand_dims(z,axis=0)\n            g = gan.session.run(gan.generator.sample, feed_dict={z_t: z})\n            gs.append(g)\n        g = np.hstack(gs)\n        xshape = gan.ops.shape(gan.inputs.x)\n        g = np.reshape(gs, [self.rows, self.columns, xshape[1], xshape[2], xshape[3]])\n        g = np.concatenate(g, axis=1)\n        g = np.concatenate(g, axis=1)\n        g = np.expand_dims(g, axis=0)\n        return {\n            \'generator\': g\n        }\n\n    def compatible_with(gan):\n        if hasattr(gan, \'latent\') and gan.batch_size() == 1:\n            return True\n        return False\n\n\n    def plot(self, image, filename, save_sample):\n        """""" Plot an image.""""""\n        image = np.minimum(image, 1)\n        image = np.maximum(image, -1)\n        image = np.squeeze(image)\n        # Scale to 0..255.\n        imin, imax = image.min(), image.max()\n        image = (image - imin) * 255. / (imax - imin) + .5\n        image = image.astype(np.uint8)\n        if save_sample:\n            try:\n                Image.fromarray(image).save(filename)\n            except Exception as e:\n                print(""Warning: could not sample to "", filename, "".  Please check permissions and make sure the path exists"")\n                print(e)\n        GlobalViewer.update(self.gan, image)\n'"
hypergan/samplers/began_sampler.py,0,"b""from hypergan.samplers.base_sampler import BaseSampler\n\nimport tensorflow as tf\nimport numpy as np\n\nclass BeganSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row):\n        BaseSampler.__init__(self, gan, samples_per_row)\n        self.x_v = None\n        self.z_v = None\n        self.created = False\n\n\n    def _sample(self):\n        gan = self.gan\n        config = gan.config\n        sess = gan.session\n        x_t = gan.inputs.x\n        z_t = gan.encoder.sample\n        if(not self.created):\n            self.x_v, self.z_v = sess.run([x_t, z_t])\n            self.created=True\n        g_t = gan.generator.sample\n        rx_t = gan.discriminator.reconstruction\n        rx_v, g_v = sess.run([rx_t, g_t], {x_t: self.x_v, z_t: self.z_v})\n        stacks = []\n        bs = gan.batch_size() // 2\n        width = self.samples_per_row\n        stacks.append(self.x_v)\n        stacks.append(rx_v)\n        stacks.append(g_v)\n\n        images = np.vstack(stacks)\n        return { 'generator':images}\n\n\n    def sample(self, path, save_samples=False):\n\n        self.plot(images, path, save_samples)\n        return [{'image': path, 'label': 'tiled x sample'}]\n\n"""
hypergan/samplers/debug_sampler.py,8,"b'from hypergan.samplers.base_sampler import BaseSampler\n\nfrom hypergan.samplers.began_sampler import BeganSampler\nfrom hypergan.samplers.batch_sampler import BatchSampler\nfrom hypergan.samplers.static_batch_sampler import StaticBatchSampler\nfrom hypergan.samplers.random_walk_sampler import RandomWalkSampler\nfrom hypergan.samplers.segment_sampler import SegmentSampler\nimport tensorflow as tf\nimport numpy as np\nimport hypergan as hg\nfrom hypergan.losses.boundary_equilibrium_loss import BoundaryEquilibriumLoss\nfrom hypergan.generators.segment_generator import SegmentGenerator\n\nz = None\nx = None\nclass IdentitySampler(BaseSampler):\n    def __init__(self, gan, node, samples_per_row=8, x=None, z=None):\n        self.node = node\n        BaseSampler.__init__(self, gan, samples_per_row)\n        self.z = None\n        self.x = None\n\n    def _sample(self,i,n):\n        gan = self.gan\n        z_t = gan.latent.sample\n        x_t = gan.inputs.x\n\n        if self.z is None:\n            self.z = []\n            self.x = []\n            for i in range(n):\n                self.z.append(gan.session.run(z_t))\n                self.x.append(gan.session.run(x_t))\n\n        return {\n                \'generator\': gan.session.run(self.node, {z_t: self.z[i], x_t: self.x[i]})\n        }\n\n\nclass DebugSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        BaseSampler.__init__(self, gan, samples_per_row)\n        x_t = gan.inputs.x\n        global x\n        x = gan.session.run(x_t)\n        self.samplers = [\n          #IdentitySampler(gan, gan.inputs.x, samples_per_row),\n          #IdentitySampler(gan, gan.inputs.xb, samples_per_row),\n          #IdentitySampler(gan, gan.autoencoded_x, samples_per_row),\n          #StaticBatchSampler(gan, samples_per_row),\n          #BatchSampler(gan, samples_per_row),\n          #RandomWalkSampler(gan, samples_per_row)\n        ]\n\n        #self.samplers += [IdentitySampler(gan, tf.image.resize_images(gan.inputs.x, [128,128], method=1), samples_per_row)]\n        #if hasattr(gan.generator, \'pe_layers\'):\n        #    self.samplers += [IdentitySampler(gan, gx, samples_per_row) for gx in gan.generator.pe_layers]\n        #    pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        if hasattr(gan, \'noise_generator\'):\n            self.samplers += [IdentitySampler(gan, tf.concat([gan.noise_generator.sample, gan.generator.sample, gan.noise_generator.sample + gan.generator.sample], axis=0), samples_per_row)]\n        #self.samplers += \n        if hasattr(gan, \'autoencoded_x\'):\n          self.samplers += [IdentitySampler(gan, tf.concat([gan.inputs.x,gan.autoencoded_x], axis=0), samples_per_row)]\n        if gan.config.loss[\'class\'] == BoundaryEquilibriumLoss:\n          self.samplers += [BeganSampler(gan, samples_per_row)]\n\n\n        if isinstance(gan.generator, SegmentGenerator):\n            self.samplers += [SegmentSampler(gan)]\n\n        if hasattr(gan, \'seq\'):\n            self.samplers += [IdentitySampler(gan, tf.image.resize_images(gx, [128,128], method=1), samples_per_row) for gx in gan.seq]\n\n        default = gan.generator.sample#tf.zeros_like(gan.generator.layer(\'gend8x8\'))\n        def add_samples(layer):\n            layer = gan.generator.layer(layer)\n            if layer is None:\n                layer = default\n\n            self.samplers.append(IdentitySampler(gan, tf.image.resize_images(layer, [128,128], method=1), 1))\n\n        add_samples(\'gend8x8\')\n        add_samples(\'gend16x16\')\n        #add_samples(\'gend32x32\')\n        #add_samples(\'gend64x64\')\n        #add_samples(\'gend128x128\')\n        if ""match_support_mx"" in gan.discriminator.named_layers:\n            self.samplers.append(IdentitySampler(gan, tf.concat([gan.inputs.x,tf.image.resize_images(gan.discriminator.named_layers[\'match_support_mx\'], [128,128], method=1), tf.image.resize_images(gan.discriminator.named_layers[\'match_support_m+x\'], [128,128], method=1)],axis=0),  1) )\n            self.samplers.append(IdentitySampler(gan, tf.concat([gan.generator.sample, tf.image.resize_images(gan.discriminator.named_layers[\'match_support_mg\'], [128,128], method=1), tf.image.resize_images(gan.discriminator.named_layers[\'match_support_m+g\'], [128,128], method=1)],axis=0),  1) ) \n\n\n\n\n    def _sample(self):\n        ss = []\n        n=4\n        for i in range(n):\n            samples = [sampler._sample(i,n)[\'generator\'] for sampler in self.samplers]\n            sample_stack = np.vstack(samples)\n            ss += [sample_stack]\n        all_samples = np.concatenate(ss, axis=2)\n\n        return {\n            \'generator\':all_samples\n        }\n\n'"
hypergan/samplers/gang_sampler.py,0,"b""from hypergan.samplers.base_sampler import BaseSampler\n\nfrom hypergan.samplers.began_sampler import BeganSampler\nfrom hypergan.samplers.batch_sampler import BatchSampler\nfrom hypergan.samplers.static_batch_sampler import StaticBatchSampler\nfrom hypergan.samplers.random_walk_sampler import RandomWalkSampler\nfrom hypergan.samplers.segment_sampler import SegmentSampler\nimport tensorflow as tf\nimport numpy as np\nimport hypergan as hg\n\nclass GangSampler(BaseSampler):\n    def __init__(self, gan):\n        BaseSampler.__init__(self, gan)\n        self.xs = None\n        self.samples = 3\n\n    def sample(self, path, sample_to_file):\n        gan = self.gan\n\n        sess = gan.session\n        config = gan.config\n        if self.xs is None:\n            self.xs = [sess.run([gan.latent.sample]) for i in range(self.samples)]\n\n        current_g = sess.run(gan.trainer.all_g_vars)\n        \n        stacks = []\n        def _samples():\n            n = 3\n            cs = []\n            for i in range(self.samples):\n                ts = [gan.latent.z]\n                vs = self.xs[i]\n                feed_dict = {}\n                for t,v in zip(ts, vs):\n                    feed_dict[t]=v\n                cs.append(sess.run(gan.generator.sample,feed_dict))\n                #cs.append(sess.run(gan.autoencoded_x,feed_dict))\n            return np.vstack(cs)\n\n        stacks.append(_samples())\n        for sg in gan.trainer.sgs:\n            gan.trainer.assign_g(sg)\n            stacks.append(_samples())\n        for i in range((gan.trainer.config.nash_memory_size or 10) - len(stacks)):\n            stacks.append(_samples())\n\n        gan.trainer.assign_g(current_g)\n\n        images = np.vstack([np.hstack(s) for s in stacks])\n\n        self.plot(images, path, sample_to_file)\n        return [{'image': path, 'label': 'tiled x sample'}]\n"""
hypergan/samplers/grid_sampler.py,0,"b""from hypergan.samplers.base_sampler import BaseSampler\nimport numpy as np\nimport tensorflow as tf\n\n\nclass GridSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        BaseSampler.__init__(self, gan, samples_per_row)\n        self.x = gan.session.run(gan.inputs.x)\n        batch = self.x.shape[0]\n        self.x = np.reshape(self.x[0], [1, self.x.shape[1], self.x.shape[2], self.x.shape[3]])\n        self.x = np.tile(self.x, [batch,1,1,1])\n\n    def _sample(self):\n        gan = self.gan\n        z_t = gan.latent.z\n        #This isn't doing any gridlike stuff.  Need to feed this into feed dict(also check size)\n        y = np.linspace(0,1, 6)\n\n        z = np.mgrid[-0.999:0.999:0.6, -0.999:0.999:0.26].reshape(2,-1).T\n        z = np.reshape(z, [32,2])\n        #z = np.mgrid[-0.499:0.499:0.3, -0.499:0.499:0.13].reshape(2,-1).T\n        #z = np.mgrid[-0.299:0.299:0.15, -0.299:0.299:0.075].reshape(2,-1).T\n        needed = 32 / gan.batch_size()\n        gs = []\n        for i in range(int(needed)):\n            zi = z[i*gan.batch_size():(i+1)*gan.batch_size()]\n            g = gan.session.run(gan.generator.sample, feed_dict={z_t: zi, gan.inputs.x: self.x})\n            gs.append(g)\n        g = np.hstack(gs)\n        xshape = gan.ops.shape(gan.inputs.x)\n        g = np.reshape(gs, [4, 8, xshape[1], xshape[2], xshape[3]])\n        g = np.concatenate(g, axis=1)\n        g = np.concatenate(g, axis=1)\n        g = np.expand_dims(g, axis=0)\n        x_hat = gan.session.run(gan.autoencoded_x, feed_dict={gan.inputs.x: self.x})\n        #e = gan.session.run(gan.encoder.sample, feed_dict={gan.inputs.x: g})\n\n        return {\n            'generator':g\n        }\n"""
hypergan/samplers/progressive_sampler.py,2,"b""from hypergan.samplers.base_sampler import BaseSampler\n\nfrom hypergan.samplers.began_sampler import BeganSampler\nfrom hypergan.samplers.batch_sampler import BatchSampler\nfrom hypergan.samplers.static_batch_sampler import StaticBatchSampler\nfrom hypergan.samplers.random_walk_sampler import RandomWalkSampler\nfrom hypergan.samplers.segment_sampler import SegmentSampler\nimport tensorflow as tf\nimport numpy as np\nimport hypergan as hg\nfrom hypergan.losses.boundary_equilibrium_loss import BoundaryEquilibriumLoss\nfrom hypergan.generators.segment_generator import SegmentGenerator\n\nz = None\nx = None\nclass IdentitySampler(BaseSampler):\n    def __init__(self, gan, node, samples_per_row=8, x=None, z=None):\n        self.node = node\n        BaseSampler.__init__(self, gan, samples_per_row)\n        self.z = None\n        self.x = None\n\n    def _sample(self,i,n):\n        gan = self.gan\n        z_t = gan.latent.sample\n        x_t = gan.inputs.x\n\n        global z\n        if z is None:\n            z = []\n            for i in range(n):\n                z.append(gan.session.run(z_t))\n        if self.x is None:\n            self.x = []\n            for i in range(n):\n                self.x.append(gan.session.run(x_t))\n\n        return {\n                'generator': gan.session.run(self.node, {z_t: z[i], x_t: self.x[i]})\n        }\n\n\nclass ProgressiveSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        BaseSampler.__init__(self, gan, samples_per_row)\n        x_t = gan.inputs.x\n        global x\n        x = gan.session.run(x_t)\n\n        self.samplers = []\n        default = tf.zeros_like(gan.generator.sample)\n        def add_samples(layer):\n            layer = gan.generator.layer(layer)\n            if layer is None:\n                layer = default\n\n            self.samplers.append(IdentitySampler(gan, tf.image.resize_images(layer, [256,256], method=1), 1))\n\n        add_samples('g8x8')\n        add_samples('g16x16')\n        add_samples('g32x32')\n        add_samples('g64x64')\n        add_samples('g128x128')\n        add_samples('g256x256')\n\n    def _sample(self):\n        ss = []\n        n=4\n        for i in range(n):\n            samples = [sampler._sample(i,n)['generator'] for sampler in self.samplers]\n            sample_stack = np.vstack(samples)\n            ss += [sample_stack]\n        all_samples = np.concatenate(ss, axis=2)\n\n        return {\n            'generator':all_samples\n        }\n\n"""
hypergan/samplers/random_walk_sampler.py,2,"b""from hypergan.samplers.base_sampler import BaseSampler\nimport tensorflow as tf\nimport numpy as np\n\nclass RandomWalkSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        BaseSampler.__init__(self, gan, samples_per_row)\n        self.z = None\n        self.y = None\n        self.x = None\n        self.step = 0\n        self.steps = 30\n        self.target = None\n\n    def _sample(self):\n        gan = self.gan\n        z_t = gan.latent.sample\n        inputs_t = gan.inputs.x\n\n        if self.z is None:\n            gan.session.run(gan.inputs.set['x'])\n            self.z = gan.latent.sample.eval()\n            self.target = gan.latent.sample.eval()\n            self.input = gan.session.run(gan.inputs.x)\n            self.input = np.tile(self.input[0], [gan.batch_size(), 1, 1, 1])\n\n        if self.step > self.steps:\n            self.z = self.target\n            self.target = gan.latent.sample.eval()\n            self.step = 0\n\n        percent = float(self.step)/self.steps\n        z_interp = self.z*(1.0-percent) + self.target*percent\n        self.step+=1\n        output = gan.session.run(gan.generator.sample, feed_dict={z_t: z_interp, inputs_t: self.input})\n        output[0] = self.input[0]\n        g=tf.get_default_graph()\n        with g.as_default():\n            tf.set_random_seed(1)\n            return {\n                'generator': output\n            }\n\n"""
hypergan/samplers/segment_sampler.py,0,"b""from hypergan.samplers.base_sampler import BaseSampler\n\nimport tensorflow as tf\nimport numpy as np\n\nclass SegmentSampler(BaseSampler):\n    def __init__(self, gan):\n        BaseSampler.__init__(self, gan)\n        self.x_v = None\n        self.z_v = None\n        self.created = False\n        self.mask_t = None\n    def _sample(self):\n        gan = self.gan\n        x_t = gan.inputs.x\n        g_t = gan.autoencoded_x\n        z_t = gan.uniform_distribution.sample\n\n        g1x_t = gan.generator.g1x\n        g2x_t = gan.generator.g2x\n        g3x_t = gan.generator.g3x\n\n\n        if self.mask_t is None:\n            self.mask_t = (gan.generator.mask-0.5)*2\n        sess = gan.session\n        config = gan.config\n        if(not self.created):\n            self.x_v = sess.run(x_t)\n            self.created=True\n\n        gens = sess.run(\n                [\n                    gan.inputs.x,\n                    self.mask_t,\n                    g_t,\n                    g1x_t,\n                    g2x_t,\n                    g3x_t\n                ], {\n                    x_t: self.x_v\n                })\n\n        stacks = []\n        bs = gan.batch_size() // 2\n        width = min(gan.batch_size(), 8)\n        for gen in gens:\n            for i in range(1):\n                stacks.append([gen[i*width+j] for j in range(width)])\n\n        images = np.vstack(stacks)\n        return {'generator':images}\n\n\n"""
hypergan/samplers/sorted_sampler.py,0,"b'from hypergan.samplers.base_sampler import BaseSampler\n\nfrom hypergan.samplers.began_sampler import BeganSampler\nfrom hypergan.samplers.batch_sampler import BatchSampler\nfrom hypergan.samplers.static_batch_sampler import StaticBatchSampler\nfrom hypergan.samplers.random_walk_sampler import RandomWalkSampler\nfrom hypergan.samplers.segment_sampler import SegmentSampler\nimport tensorflow as tf\nimport numpy as np\nimport hypergan as hg\n\nclass SortedSampler(BaseSampler):\n    def __init__(self, gan):\n        BaseSampler.__init__(self, gan)\n        self.xs = None\n        self.samples = 10\n        self.display_count = 5\n\n    def sample(self, path, sample_to_file):\n        gan = self.gan\n\n        sess = gan.session\n        config = gan.config\n        if self.xs is None:\n            self.xs = [sess.run(gan.fitness_inputs()) for i in range(self.samples)]\n\n        current_g = sess.run(gan.trainer.all_g_vars)\n        \n        stacks = []\n        def _samples():\n            cs = []\n            for i in range(self.samples):\n                ts = gan.fitness_inputs()\n                vs = self.xs[i]\n                feed_dict = {}\n                for t,v in zip(ts, vs):\n                    feed_dict[t]=v\n                cs.append(sess.run(gan.generator.sample,feed_dict))\n                #cs.append(sess.run(gan.autoencoded_x,feed_dict))\n            return cs\n        \n        gs = _samples()\n        priority = []\n        for i, sample in zip(range(self.samples), gs):\n            priority.append(gan.session.run(gan.loss.d_fake, {gan.generator.sample: sample}))\n\n        sorted_sgs = [[p, v] for p,v in zip(priority, gs)]\n        sorted_sgs.sort(key=lambda x: -x[0])\n        sorted_sgs = [s[1] for s in sorted_sgs]\n\n        top = sorted_sgs[:self.display_count]\n        end = sorted_sgs[(len(gs)-self.display_count):]\n\n        print(""TOP"", np.shape(top), ""end"", np.shape(end))\n        stacks.append(np.vstack(top))\n        stacks.append(np.vstack(end))\n        images = np.vstack([np.hstack(s) for s in stacks])\n\n        self.plot(images, path, sample_to_file)\n        return [{\'image\': path, \'label\': \'tiled x sample\'}]\n'"
hypergan/samplers/static_batch_sampler.py,0,"b""from hypergan.samplers.base_sampler import BaseSampler\nfrom hypergan.train_hooks.experimental.imle_train_hook import IMLETrainHook\nimport numpy as np\nimport tensorflow as tf\n\nclass StaticBatchSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        BaseSampler.__init__(self, gan, samples_per_row)\n        self.z = None\n        self.y = None\n        self.x = None\n        self.g_t = self.replace_none(gan.generator.sample)\n        self.rows = 4\n        self.columns = 8\n\n    def compatible_with(gan):\n        if hasattr(gan, 'latent'):\n            return True\n        return False\n\n    def _sample(self):\n        gan = self.gan\n        z_t = gan.latent.sample\n        inputs_t = gan.inputs.x\n        needed = int(self.rows*self.columns / gan.batch_size())\n\n        if self.z is None:\n            self.z = [gan.latent.sample.eval() for i in range(needed)]\n            self.z = np.reshape(self.z, [self.rows*self.columns, -1])\n\n        z = self.z\n        gs = []\n        for i in range(int(needed)):\n            zi = z[i*gan.batch_size():(i+1)*gan.batch_size()]\n            g = gan.session.run(self.g_t, feed_dict={z_t: zi})\n            gs.append(g)\n        for t in self.gan.trainer.train_hooks:\n            if isinstance(t, IMLETrainHook):\n                for j in range(t.config.memory_size):\n                    gs[j*2][0] = gan.session.run(t.gi[j].sample)\n                    gs[j*2+1][0] = gan.session.run(t.x_matched[j])\n        g = np.hstack(gs)\n        xshape = gan.ops.shape(gan.inputs.x)\n        g = np.reshape(gs, [self.rows, self.columns, xshape[1], xshape[2], xshape[3]])\n        g = np.concatenate(g, axis=1)\n        g = np.concatenate(g, axis=1)\n        g = np.expand_dims(g, axis=0)\n\n        return {\n            'generator': g\n        }\n\n"""
hypergan/samplers/style_walk_sampler.py,2,"b'import numpy as np\nimport tensorflow as tf\nfrom PIL import Image\nfrom hypergan.viewer import GlobalViewer\nfrom hypergan.samplers.base_sampler import BaseSampler\nimport time\n\nclass StyleWalkSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8, session=None):\n        BaseSampler.__init__(self, gan, samples_per_row)\n        self.z = None\n        self.y = None\n        self.x = None\n        self.step = 0\n        self.steps = 30\n        self.target = None\n        self.z_t = gan.uniform_distribution.sample\n        self.z_v = gan.session.run(self.z_t)\n        self.styleb_t = gan.styleb.sample\n\n    def _sample(self):\n        gan = self.gan\n        inputs_t = gan.inputs.x\n\n        if self.z is None:\n            self.input = gan.session.run(gan.inputs.x)\n            batch = self.input.shape[0]\n            self.input = np.reshape(self.input[0], [1, self.input.shape[1], self.input.shape[2], 3])\n            self.input = np.tile(self.input, [batch,1,1,1])\n\n            self.target = gan.random_style.eval()[0]\n        else:\n            self.target = self.z\n        self.z = gan.random_style.eval()[0]\n\n\n        g=tf.get_default_graph()\n        s=np.shape(gan.random_style.eval())\n        bs = s[0]\n        mask = np.linspace(0., 1., num=bs)\n        self.z = np.tile(np.expand_dims(np.reshape(self.z, [-1]), axis=0), [bs,1])\n        targ = np.tile(np.expand_dims(np.reshape(self.target, [-1]), axis=0), [bs,1])\n        print(""SHAPES"", np.shape(mask), np.shape(self.z), np.shape(targ))\n        mask = np.tile(np.expand_dims(mask, axis=1), [1, np.shape(targ)[1]])\n        z_interp = np.multiply(mask,self.z) + (1-mask)*targ\n        z_interp = np.reshape(z_interp, s)\n        print(""Z_I"", np.shape(z_interp), np.shape(self.z))\n        self.z = z_interp[-1]\n        with g.as_default():\n            tf.set_random_seed(1)\n            return {\n                    \'generator\': gan.session.run(gan.generator.sample, feed_dict={self.z_t: np.zeros_like(self.z_v), inputs_t: self.input, self.styleb_t: z_interp})\n            }\n\n    def sample(self, path, save_samples):\n        gan = self.gan\n\n        with gan.session.as_default():\n\n            sample = self._sample()\n\n            data = sample[\'generator\']\n            for i in range(np.shape(data)[0]):\n                sample_data = data[i:i+1]\n                self.plot(sample_data, path, save_samples)\n                time.sleep(0.018)\n\n            return []\n\n    def plot(self, image, filename, save_sample):\n        """""" Plot an image.""""""\n        image = np.minimum(image, 1)\n        image = np.maximum(image, -1)\n        image = np.squeeze(image)\n        # Scale to 0..255.\n        imin, imax = image.min(), image.max()\n        image = (image - imin) * 255. / (imax - imin) + .5\n        image = image.astype(np.uint8)\n        if save_sample:\n            try:\n                Image.fromarray(image).save(filename)\n            except Exception as e:\n                print(""Warning: could not sample to "", filename, "".  Please check permissions and make sure the path exists"")\n                print(e)\n        GlobalViewer.update(self.gan, image)\n'"
hypergan/samplers/y_sampler.py,3,"b""import numpy as np\nimport tensorflow as tf\nfrom PIL import Image\nfrom hypergan.viewer import GlobalViewer\nfrom hypergan.samplers.base_sampler import BaseSampler\nimport time\n\nclass YSampler(BaseSampler):\n    def __init__(self, gan, samples_per_row=8):\n        BaseSampler.__init__(self, gan, samples_per_row)\n        self.z = None\n        self.y = None\n        self.x = None\n        self.mask = None\n        self.step = 0\n        self.steps = 8\n        self.target = None\n        self.y_t = gan.y.sample\n        self.y = gan.session.run(self.y_t)\n        self.g=tf.get_default_graph()\n        self.frames = gan.session.run(gan.frames)\n        self.frames_t = gan.frames\n        self.zs2, self.cs2 = gan.session.run([gan.zs[-1], gan.cs[-1]])\n        self.zs2 = [self.zs2]\n        self.cs2 = [self.cs2]\n        self.zs_t = [gan.video_generator_last_z]\n        self.cs_t = [gan.video_generator_last_c]\n        self.zs = gan.session.run([gan.video_generator_last_z])\n        self.cs = gan.session.run([gan.video_generator_last_c])\n        self.i=0\n\n    def _sample(self):\n        gan = self.gan\n        z_t = gan.uniform_distribution.sample\n        g=tf.get_default_graph()\n        with g.as_default():\n            tf.set_random_seed(1)\n            feed_dict = dict(zip(self.frames_t, self.frames))\n            sample, *gstack = gan.session.run(gan.gs_next, feed_dict=feed_dict)\n            self.frames = self.frames[1:] + [sample]\n\n            feed_dict = dict(zip(self.frames_t, self.frames))\n            if self.i % 100 == 0:\n                if self.i == 0:\n                    self.frames3 = gan.session.run(gan.frames)\n            feed_dict = dict(zip(self.frames_t, self.frames3))\n            print('c_drift', gan.session.run(gan.c_drift, feed_dict=feed_dict))\n\n            if self.i % 100 == 0:\n                self.frames2 = gan.session.run(gan.frames)\n            feed_dict = dict(zip(self.frames_t, self.frames2))\n            sample_reset = gan.session.run(gan.gs_next[0], feed_dict=feed_dict)\n            self.frames2 = self.frames2[1:] + [sample_reset]\n\n            if self.i % 100 == 0:\n                self.prev_frames = gan.session.run(gan.frames)\n            feed_dict = dict(zip(gan.frames[1:], [self.prev_frames[0]]+self.prev_frames[:-1]))\n            prev_sample = gan.session.run(gan.gy.sample, feed_dict=feed_dict)\n            self.prev_frames = [prev_sample] + self.prev_frames[:-1]\n\n            feed_dict = dict(zip(self.zs_t, self.zs))\n            feed_dict.update(dict(zip(self.cs_t,self.cs)))\n            gx, z_sample, c_sample = gan.session.run([gan.generator.sample, gan.video_generator_last_zn, gan.video_generator_last_cn], feed_dict=feed_dict)\n            self.zs = self.zs[1:] + [z_sample]\n            self.cs = self.cs[1:] + [c_sample]\n\n            if self.i % 500 == 0:\n                self.zs2, self.cs2 = gan.session.run([gan.zs[-1], gan.cs[-1]])\n                self.zs2 = [self.zs2]\n                self.cs2 = [self.cs2]\n            feed_dict = dict(zip(self.zs_t, self.zs2))\n            feed_dict.update(dict(zip(self.cs_t,self.cs2)))\n            gc, z_sample, c_sample = gan.session.run([gan.generator.sample, gan.video_generator_last_zn, gan.video_generator_last_cn], feed_dict=feed_dict)\n            self.zs2 = self.zs2[1:] + [z_sample]\n            self.cs2 = self.cs2[1:] + [c_sample]\n\n            feed_dict = dict(zip(self.zs_t, self.zs))\n            x = gan.session.run(gan.generator.sample)\n            self.i+=1\n            return {\n                'generator': np.hstack([sample,  sample_reset, gx,gc])\n            }\n\n"""
hypergan/search/__init__.py,0,"b'""""""\nThere are many composable GAN pieces.  We can randomly combine them and see what happens.\n""""""\n'"
hypergan/search/aligned_random_search.py,0,"b'import tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\nimport random\n\nfrom hypergan.losses.boundary_equilibrium_loss import BoundaryEquilibriumLoss\nfrom hypergan.losses.wasserstein_loss import WassersteinLoss\nfrom hypergan.losses.least_squares_loss import LeastSquaresLoss\nfrom hypergan.losses.softmax_loss import SoftmaxLoss\nfrom hypergan.losses.standard_loss import StandardLoss\nfrom hypergan.losses.lamb_gan_loss import LambGanLoss\n\nfrom hypergan.search.random_search import RandomSearch\n\nimport hypergan as hg\n\nclass AlignedRandomSearch(RandomSearch):\n    def __init__(self, overrides):\n        self.options = {\n            \'discriminator\': self.discriminator(),\n            \'input_encoder\': self.input_encoder(),\n            \'generator\': self.generator(),\n            \'trainer\': self.trainer(),\n            \'loss\':self.loss(),\n            \'encoder\':self.encoder()\n         }\n\n        self.options[\'generator\'][\'skip_linear\'] = True\n\n\n        self.options[\'cycloss_lambda\'] = random.choice([0,10])\n\n        self.options = {**self.options, **overrides}\n\n    def input_encoder(self):\n        discriminator_opts = {\n            ""activation"":[\'relu\', \'lrelu\', \'tanh\', \'selu\', \'prelu\', \'crelu\'],\n            ""final_activation"":[\'relu\', \'lrelu\', \'tanh\', \'selu\', \'prelu\', \'crelu\'],\n            ""block_repeat_count"":[1,2,3],\n            ""block"":[\n                   hg.discriminators.common.standard_block,\n                   hg.discriminators.common.strided_block\n                   ],\n            ""depth_increase"":[32],\n            ""extra_layers"": [0, 1, 2],\n            ""extra_layers_reduction"":[1,2,4],\n            ""fc_layer_size"":[300, 400, 500],\n            ""fc_layers"":[0],\n            ""first_conv_size"":[32],\n            ""layers"": [2,3,4],\n            ""initial_depth"": [32],\n            ""initializer"": [\'orthogonal\', \'random\'],\n            ""layer_regularizer"": [None, \'batch_norm\', \'layer_norm\'],\n            ""noise"":[False, 1e-2],\n            ""progressive_enhancement"":[False, True],\n            ""orthogonal_gain"": list(np.linspace(0.1, 2, num=10000)),\n            ""random_stddev"": list(np.linspace(0.0, 0.1, num=10000)),\n            ""distance"":[\'l1_distance\', \'l2_distance\'],\n            ""class"":[\n                hg.discriminators.pyramid_discriminator.PyramidDiscriminator\n               # hg.discriminators.autoencoder_discriminator.AutoencoderDiscriminator\n            ]\n        }\n\n        return hc.Selector(discriminator_opts).random_config()\n\n\n'"
hypergan/search/alphagan_random_search.py,0,"b'import tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\n\nfrom hypergan.losses.boundary_equilibrium_loss import BoundaryEquilibriumLoss\nfrom hypergan.losses.wasserstein_loss import WassersteinLoss\nfrom hypergan.losses.least_squares_loss import LeastSquaresLoss\nfrom hypergan.losses.softmax_loss import SoftmaxLoss\nfrom hypergan.losses.standard_loss import StandardLoss\nfrom hypergan.losses.lamb_gan_loss import LambGanLoss\n\nfrom hypergan.search.random_search import RandomSearch\n\nclass AlphaGANRandomSearch(RandomSearch):\n    def __init__(self, overrides):\n        self.options = {\n            \'g_encoder\': self.discriminator(),\n            \'z_discriminator\': self.discriminator(),\n            \'discriminator\': self.discriminator(),\n            \'generator\': self.generator(),\n            \'trainer\': self.trainer(),\n            \'loss\':self.loss(),\n            \'encoder\':self.encoder()\n         }\n\n        alpha_options = {\n            \'g_encoder_layers\': [2,3,4,5],\n            \'z_discriminator_layers\': [0,1,2],\n            \'z_discriminator_extra_layers\': [0,1,2],\n            \'z_discriminator_extra_layers_reduction\': [1,2],\n            \'cycloss_lambda\': [0.1, 0.3, 0.2],\n            \'concat_linear\': [64,128,256],\n            \'concat_linear_filters\': [32,64,128,256],\n            \'skip_linear\': [False, True],\n            \'d_layer_filter\': [True,False],\n            \'g_layer_filter\': [True,False],\n            \'encode_layer_filter\': [True, False]\n        }\n\n        alpha_config = hc.Selector(alpha_options).random_config()\n\n        self.options[\'g_encoder\'][\'layers\']=alpha_config.g_encoder_layers\n        self.options[\'z_discriminator\'][\'layers\']=alpha_config.z_discriminator_layers\n        self.options[\'z_discriminator\'][\'extra_layers\']=alpha_config.z_discriminator_extra_layers\n        self.options[\'z_discriminator\'][\'extra_layers_reduction\']=alpha_config.z_discriminator_extra_layers_reduction\n        self.options[\'cycloss_lambda\']=alpha_config.cycloss_lambda\n        self.options[\'generator\'][\'concat_linear\']=alpha_config.concat_linear\n        self.options[\'generator\'][\'concat_linear_filters\']=alpha_config.concat_linear_filters\n        self.options[\'generator\'][\'skip_linear\']=alpha_config.skip_linear\n        self.options[""class""]=""class:hypergan.gans.alpha_gan.AlphaGAN""\n        self.options[\'d_layer_filter\']=alpha_config.d_layer_filter\n        self.options[\'g_layer_filter\']=alpha_config.g_layer_filter\n        self.options = {**self.options, **overrides}\n'"
hypergan/search/default_configurations.py,0,b'class DefaultConfigurations:\n    @staticmethod\n    def get():\n        return {}\n'
hypergan/search/random_search.py,6,"b'import tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\nimport random\nimport copy\n\nfrom hypergan.losses.boundary_equilibrium_loss import BoundaryEquilibriumLoss\nfrom hypergan.losses.wasserstein_loss import WassersteinLoss\nfrom hypergan.losses.least_squares_loss import LeastSquaresLoss\nfrom hypergan.losses.f_divergence_loss import FDivergenceLoss\nfrom hypergan.losses.softmax_loss import SoftmaxLoss\nfrom hypergan.losses.standard_loss import StandardLoss\nfrom hypergan.losses.lamb_gan_loss import LambGanLoss\nfrom hypergan.losses.vral_loss import VralLoss\n\nclass RandomSearch:\n    def __init__(self, overrides):\n        self.options = {\n            \'discriminator\': self.discriminator(),\n            \'generator\': self.generator(),\n            \'trainer\': self.trainer(),\n            \'loss\':self.loss(),\n            \'encoder\':self.encoder()\n         }\n\n        self.options = {**self.options, **overrides}\n\n    def range(self, start=0., end=1.):\n        return list(np.linspace(start, end, num=1000))\n\n    def trainer(self):\n        tftrainers = [\n                #tf.train.AdadeltaOptimizer,\n                #tf.train.AdagradOptimizer,\n                #tf.train.GradientDescentOptimizer,\n                tf.train.AdamOptimizer,\n                #tf.train.MomentumOptimizer,\n                tf.train.RMSPropOptimizer\n        ]\n\n        selector = hc.Selector({\n            \'learn_rate\': [1e-2, 1e-3, 1e-4, 5e-3, 5e-4],\n            \'beta1\': self.range(0.8, 0.9999),\n            \'beta2\': self.range(0.9, 0.9999),\n            \'epsilon\': self.range(1e-8, 0.1),\n            \'momentum\': [0, 0.01, 0.1],\n            \'decay\': self.range(0.8, 0.9999),\n            \'rho\': self.range(),\n            \'initial_accumulator_value\': self.range(),\n            \'clipped_gradients\': False,\n            \'trainer\':tftrainers,\n            \'class\': [\n                #hg.trainers.proportional_control_trainer.create,\n                #hg.trainers.alternating_trainer.AlternatingTrainer\n                hg.trainers.consensus_trainer.ConsensusTrainer\n            ]\n        })\n        \n        config = selector.random_config()\n        return config\n     \n    def fc_discriminator(self):\n        opts = {\n          ""activation"": [""selu"", ""lrelu"", ""relu""],\n          ""layer_regularizer"": [None, ""layer_norm""],\n          ""linear_type"": [None, ""cosine""],\n          ""features"": [1, 10, 100, 200, 512],\n          ""class"": ""class:hypergan.discriminators.fully_connected_discriminator.FullyConnectedDiscriminator""\n        }\n        return hc.Selector(opts).random_config()\n\n    def var_loss(self):\n        loss_opts = {\n            \'class\': [\n                    VralLoss\n            ],\n            ""target_mean"": [-1,-0.5,0,0.5,1],\n            ""fake_mean"": [-1,-0.5,0,0.5,1],\n            \'reduce\': [\'reduce_mean\',\'reduce_sum\',\'reduce_logsumexp\'],\n            \'type\': [\'log_rr\', \'log_rf\', \'log_fr\', \'log_ff\', \'log_all\'],\n            \'value_function\': [\'square\', \'log\', \'original\'],\n            \'g_loss\': [\'l2\',\'fr_l2\',\'rr_l2\'],\n            \n            ""r_discriminator"": self.fc_discriminator()\n\n        }\n        loss_opts[""f_discriminator""] = loss_opts[""r_discriminator""]\n\n        return  hc.Selector(loss_opts).random_config()\n\n    def loss(self):\n        a=self.loss_instance()\n        b=copy.deepcopy(dict(a))\n        b[""swapped""]=True\n        \n        loss={\n            ""class"": ""class:hypergan.losses.multi_loss.MultiLoss"",\n            ""combine"": ""concat"",\n            ""partition"": True\n        }\n\n        loss[""losses""]=[a,b]\n        return loss\n\n    def loss_instance(self):\n        loss_opts = {\n            \'class\': [\n                    FDivergenceLoss, StandardLoss, LeastSquaresLoss, WassersteinLoss\n            ],\n            ""type"": [""kl"",""js"",""gan"",""reverse_kl"",""pearson"",""squared_hellinger"", ""total_variation""],\n            ""labels"": [[-1,1,1]],\n            \'reduce\': [\'reduce_mean\']#,\'reduce_sum\']#,\'reduce_logsumexp\']\n        }\n\n        choice = hc.Selector(loss_opts).random_config()\n\n        if random.choice([True, False]):\n            choice[""regularizer""] = choice[""type""]\n        if random.choice([True, False]):\n            choice[""g_loss_type""] = choice[""type""]\n\n        return choice\n\n\n    def encoder(self):\n        projections = []\n        projections.append([hg.encoders.uniform_distribution.identity])\n        encoder_opts = {\n                \'z\': 1,\n                \'min\': -1,\n                \'max\':1,\n                ""projections"": projections,\n                \'class\': hg.encoders.uniform_distribution.UniformDistribution\n        }\n\n        return hc.Selector(encoder_opts).random_config()\n\n    def generator(self):\n        generator_opts = {\n            ""activation"":[\'lrelu\', \'tanh\', \'selu\', \'prelu\', \'crelu\', \'nsoftplus\'],\n            ""final_depth"":[32],\n            ""depth_increase"":[32],\n            ""initializer"": [\'xavier\'],\n            ""random_stddev"": list(np.linspace(0.0, 0.1, num=10000)),\n            ""final_activation"":[\'lrelu\', \'tanh\', None],\n            ""block_repeat_count"":[1,2,3],\n            ""block"":[\n                hg.generators.common.standard_block, \n                hg.generators.common.inception_block, \n                hg.generators.common.dense_block, \n                hg.generators.common.repeating_block\n                ],\n            ""orthogonal_initializer_gain"": list(np.linspace(0.1, 2, num=100)),\n            ""class"":[\n                hg.generators.resize_conv_generator.ResizeConvGenerator\n            ]\n        }\n\n        return hc.Selector(generator_opts).random_config()\n\n    def discriminator(self):\n        discriminator_opts = {\n            ""activation"":[\'relu\', \'lrelu\', \'tanh\', \'selu\', \'prelu\', \'crelu\'],\n            ""final_activation"":[None],\n            ""block_repeat_count"":[1,2,3],\n            ""block"":[hg.discriminators.common.repeating_block,\n                   hg.discriminators.common.standard_block,\n                   hg.discriminators.common.strided_block\n                   ],\n            ""depth_increase"":[32],\n            ""extra_layers"": [0, 1, 2, 3],\n            ""extra_layers_reduction"":[1,2,4],\n            ""fc_layer_size"":[300, 400, 500],\n            ""fc_layers"":[0,1],\n            ""first_conv_size"":[32],\n            ""layers"": [3,4,5,6],\n            ""initial_depth"": [32],\n            ""initializer"": [\'xavier\'],\n            ""layer_regularizer"": [None,  \'layer_norm\'],\n            ""noise"":[False, 1e-2],\n            ""progressive_enhancement"":[False, True],\n            ""orthogonal_gain"": list(np.linspace(0.1, 2, num=10000)),\n            ""random_stddev"": list(np.linspace(0.0, 0.1, num=10000)),\n            ""distance"":[\'l1_distance\', \'l2_distance\'],\n            ""class"":[\n                hg.discriminators.pyramid_discriminator.PyramidDiscriminator\n               # hg.discriminators.autoencoder_discriminator.AutoencoderDiscriminator\n            ]\n        }\n\n        return hc.Selector(discriminator_opts).random_config()\n\n    def random_config(self):\n        return hc.Selector(self.options).random_config()\n'"
hypergan/train_hooks/base_train_hook.py,0,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom hypergan.gan_component import GANComponent\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass BaseTrainHook(GANComponent):\n  def __init__(self, gan=None, config=None, trainer=None, name=""BaseTrainHook""):\n    super().__init__(gan, config, name=name)\n    self.trainer = trainer\n    self.name=name\n\n  def create(self):\n    pass\n\n  def losses(self):\n    return [None, None]\n\n  def before_step(self, step, feed_dict):\n    pass\n\n  def after_step(self, step, feed_dict):\n    pass\n\n  def after_create(self):\n    pass\n'"
hypergan/train_hooks/gradient_penalty_train_hook.py,7,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass GradientPenaltyTrainHook(BaseTrainHook):\n  def __init__(self, gan=None, config=None, trainer=None, name=""GradientPenaltyTrainHook""):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    if hasattr(self.gan, \'x0\'):\n        gan_inputs = self.gan.x0\n    else:\n        gan_inputs = self.gan.inputs.x\n\n    self._lambda = self.gan.configurable_param(config[\'lambda\'] or 1)\n\n    if self.config.target:\n        v = getattr(gan, self.config.target)\n    else:\n        v = gan.discriminator\n    target = v.sample\n    if ""components"" in self.config:\n        target_vars = []\n        for component in self.config.components:\n            c = getattr(gan, component)\n            target_vars += c.variables()\n    else:\n        target_vars = self.gan.variables()\n\n    gd = tf.gradients(target, target_vars)\n    gds = [tf.square(_gd) for _gd in gd if _gd is not None]\n    if self.config.flex:\n        if isinstance(self.config.flex,list):\n            gds = []\n            for i,flex in enumerate(self.config.flex):\n                split_target = tf.split(target, len(self.config.flex))\n                gd = tf.gradients(split_target, target_vars)\n                fc = self.gan.configurable_param(flex)\n                gds += [tf.square(tf.nn.relu(tf.abs(_gd) - fc)) for _gd in gd if _gd is not None]\n        else:\n            gds = [tf.square(tf.nn.relu(tf.abs(_gd) - flex)) for _gd in gd if _gd is not None]\n    self.loss = tf.add_n([self._lambda * tf.reduce_mean(_r) for _r in gds])\n    self.gds = gds\n    self.gd = gd\n    self.target_vars = target_vars\n    self.target = target\n    self.gan.add_metric(\'gp\', self.loss)\n\n  def losses(self):\n    if self.config.loss == ""g_loss"":\n        return [None, self.loss]\n    else:\n        return [self.loss, None]\n\n  def after_step(self, step, feed_dict):\n\n    if self.config.debug:\n        for _v, _g in zip(self.target_vars, self.gd):\n            if(_g is not None and np.mean(self.gan.session.run(_g)) > 0.1):\n                print(\' -> \' + _v.name,  _v, _g)\n                print("" in target?"", _v in self.target_vars)\n                print("" in dvars? "",_v in self.gan.d_vars())\n                print("" in t_dvars? "",_v in self.gan.trainable_d_vars())\n                print("" in gvars? "",_v in self.gan.g_vars())\n    pass\n\n  def before_step(self, step, feed_dict):\n    pass\n'"
hypergan/train_hooks/max_gp_train_hook.py,9,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass MaxGpTrainHook(BaseTrainHook):\n  ""https://arxiv.org/pdf/1902.05687v2.pdf C.2""\n  def __init__(self, gan=None, config=None, trainer=None, name=""MaxGpTrainHook"", memory_size=2, top_k=1):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    gan_inputs = self.gan.inputs.x\n    if hasattr(self.gan.inputs, \'frames\'):\n        gan_inputs = tf.concat(self.gan.inputs.frames[1:], axis=3)\n        latent_sample = self.gan.c0\n    else:\n        latent_sample = self.gan.latent.sample\n    self.s_max = [ tf.Variable( tf.zeros_like(gan_inputs)) for i in range(memory_size)]\n    self.d_lambda = config[\'lambda\'] or 1\n\n    self.assign_s_max_new_entries = [ tf.assign(self.s_max[i], self.gan.sample_mixture()) for i in range(memory_size) ]\n    self.memory_size = memory_size\n    self.top_k = top_k\n\n    self.current = tf.Variable(tf.zeros_like(gan_inputs))\n    d = self.gan.create_component(self.gan.config.discriminator, name=\'discriminator\', input=self.current, features=[tf.zeros_like(latent_sample)], reuse=True)\n    self.assign_current = [ self.current.assign(self.s_max[i]) for i in range(memory_size) ]\n    gd = tf.gradients(d.sample, gan.d_vars())\n    r = tf.add_n([tf.square(tf.norm(_gd, ord=2)) for _gd in gd])\n    self.d_loss = self.d_lambda * tf.reduce_mean(r)\n    self.gan.add_metric(\'gpsn\', self.d_loss)\n    if self.config.from_source:\n        self.d_loss = tf.add_n([tf.reduce_sum(tf.square(_gd)) for _gd in gd])\n\n  def losses(self):\n    return [self.d_loss, None]\n\n  def after_step(self, step, feed_dict):\n    pass\n\n  def before_step(self, step, feed_dict):\n    # get (memory_size - topk) x_hats\n    for i,s in enumerate(self.assign_s_max_new_entries[self.top_k:]):\n        self.gan.session.run(s)\n    # sort memory\n    scores = []\n    for i in range(self.memory_size):\n        self.gan.session.run(self.assign_current[i])\n        s = self.gan.session.run(self.d_loss)\n        scores.append(s)\n    sort = zip(scores, self.s_max, self.assign_s_max_new_entries)\n    sort2 = sorted(sort, key=itemgetter(0), reverse=True)\n    new_s_max = [s_max for _, s_max,_ in sort2]\n    new_assign = [a for _, _,a in sort2]\n    self.s_max = new_s_max\n    self.assign_s_max_new_entries = new_assign\n    # get max\n    if self.config.all:\n        winner = sum(scores)\n    else:\n        winner = scores[np.argmax(scores)]\n\n    # truncate memory to top_k\n    feed_dict[self.d_loss] = winner\n\n'"
hypergan/train_hooks/progress_compress_kbgan_train_hook.py,11,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.gans.base_gan import BaseGAN\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nEPS=1e-8\n\n\nclass KBGAN(BaseGAN):\n    def __init__(self, latent=None, x=None, *args, **kwargs):\n        self.discriminator = None\n        self.latent = None\n        self.generator = None\n        self.loss = None\n        self.trainer = None\n        self.session = None\n        self.latent = latent\n        self.x = x\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        return ""generator"".split()\n\n    def create(self):\n        config = self.config\n\n        with tf.device(self.device):\n            self.session = self.ops.new_session(self.ops_config)\n            self.generator = self.create_component(config.generator, name=""generator"", input=self.latent)\n            d_input = tf.concat([self.x, self.generator.sample],axis=0)\n            self.discriminator = self.create_component(config.discriminator, name=""discriminator"", input=d_input)\n            self.loss = self.create_component(config.loss, discriminator=self.discriminator)\n            self.trainer = self.create_component(config.trainer)\n            self.session.run(tf.global_variables_initializer())\n\n    def create_generator(self, latent, reuse=False):\n        return self.create_component(self.config.generator, name=""generator"", input=latent, reuse=reuse)\n\n    def width(self):\n        return 1\n\n    def height(self):\n        return 1\n\n    def g_vars(self):\n        return self.generator.variables()\n\n    def d_vars(self):\n        return self.discriminator.variables()\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        return [\n                self.latent\n        ]\n\n    def output_nodes(self):\n        ""used in hypergan build""\n        return [\n                self.latent,\n                self.random_z\n        ]\nclass ProgressCompressKBGanTrainHook(BaseTrainHook):\n  """"""https://arxiv.org/pdf/1805.06370v2.pdf""""""\n  def __init__(self, gan=None, config=None, trainer=None, name=""ProgressCompressTrainHook""):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    d_loss = []\n\n    self.x = tf.Variable(tf.zeros_like(gan.inputs.x))\n    self.g = tf.Variable(tf.zeros_like(gan.generator.sample))\n\n    stacked = tf.concat([self.gan.inputs.x, self.gan.generator.sample], axis=0)\n    self.assign_x = tf.assign(self.x, gan.inputs.x)\n    self.assign_g = tf.assign(self.g, gan.generator.sample)\n    self.re_init_d = [d.initializer for d in gan.discriminator.variables()]\n    gan.hack = self.g\n\n    self.assign_knowledge_base = []\n\n    bs = gan.batch_size()\n    real = gan.discriminator.named_layers[\'knowledge_base_target\']#tf.reshape(gan.loss.sample[:2], [2,-1])\n    _inputs = hc.Config({\'x\':real})\n    inner_gan = KBGAN(config=self.config.knowledge_base, inputs=_inputs, x=real, latent=stacked)\n    self.kb_loss = inner_gan.loss\n    self.kb = inner_gan.generator\n    self.trainer = inner_gan.trainer\n    variables = inner_gan.variables()\n    #variables += self.kb.variables()\n\n    for c in gan.components:\n        if hasattr(c, \'knowledge_base\'):\n            for name, net in c.knowledge_base:\n                assign = self.kb.named_layers[name]\n                if self.ops.shape(assign)[0] > self.ops.shape(net)[0]:\n                    assign = tf.slice(assign,[0 for i in self.ops.shape(net)] , [self.ops.shape(net)[0]]+self.ops.shape(assign)[1:])\n                self.assign_knowledge_base.append(tf.assign(net, assign))\n\n    self.gan.add_metric(\'d_kb\', self.kb_loss.sample[0])\n    self.gan.add_metric(\'g_kb\', self.kb_loss.sample[1])\n\n  def losses(self):\n      return [None, None]\n\n  def after_step(self, step, feed_dict):\n    if step % (self.config.step_count or 1) != 0:\n      return\n    # compress\n    for i in range(self.config.night_steps or 1):\n        self.trainer.step(feed_dict)\n    if self.config.reinitialize_every:\n        if step % (self.config.reinitialize_every)==0 and step > 0:\n            print(""Reinitializing active D"")\n            self.gan.session.run(self.re_init_d)\n\n  def before_step(self, step, feed_dict):\n    self.gan.session.run([self.assign_x, self.assign_g]+ self.assign_knowledge_base)\n\n'"
hypergan/train_hooks/self_supervised_train_hook.py,8,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass SelfSupervisedTrainHook(BaseTrainHook):\n  """"""https://arxiv.org/pdf/1810.11598v1.pdf""""""\n  def __init__(self, gan=None, config=None, trainer=None, name=""SelfSupervisedTrainHook""):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    g_loss = []\n    d_loss = []\n    if hasattr(self.gan.inputs, \'frames\'):\n        x = gan.x0#gan.inputs.x\n        g = gan.g0#gan.generator.sample\n    else:\n        x = gan.inputs.x\n        g = gan.generator.sample\n    reuse = False\n    for i in range(4):\n        if gan.width() != gan.height() and i % 2 == 0:\n            continue\n        _x = tf.image.rot90(x, i+1)\n        _g = tf.image.rot90(g, i+1)\n        stacked = tf.concat([_x, _g], axis=0)\n        shared = gan.create_discriminator(stacked, reuse=True).named_layers[\'shared\']\n        r = gan.create_component(config[""r""], input=shared, reuse=reuse)\n        reuse=True\n        gan.discriminator.add_variables(r)\n        gan.generator.add_variables(r)\n        labels = tf.one_hot(i, 4)\n        _dl = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=r.sample[0])\n        _gl = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=r.sample[1])\n        d_loss.append(_dl)\n        g_loss.append(_gl)\n\n    self.g_loss = (self.config.alpha or 1.0) * tf.add_n(g_loss)\n    self.d_loss = (self.config.beta or 1.0) * tf.add_n(d_loss)\n\n    self.gan.add_metric(\'ssgl\', self.g_loss)\n    self.gan.add_metric(\'ssdl\', self.d_loss)\n\n  def losses(self):\n      return [self.d_loss, self.g_loss]\n\n  def after_step(self, step, feed_dict):\n      pass\n\n  def before_step(self, step, feed_dict):\n    if step % (self.config.step_count or 1000) != 0:\n      return\n\n'"
hypergan/train_hooks/weight_constraint_train_hook.py,54,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\nimport numpy as np\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass WeightConstraintTrainHook(BaseTrainHook):\n  def after_create(self):\n    self.max = self.gan.configurable_param(self.config.max)\n    self.decay = self.gan.configurable_param(self.config.decay)\n    allvars = self.gan.variables()\n    self.update_weight_constraints = [self._update_weight_constraint(v,i) for i,v in enumerate(allvars)]\n    self.update_weight_constraints = [v for v in self.update_weight_constraints if v is not None]\n\n  def _update_ortho(self,v,i):\n    s = self.gan.ops.shape(v)\n    if len(s) == 4 and s[0] == s[1]:\n      w=v\n      newv = []\n      #s = self.ops.shape(v_transpose)\n      #identity = tf.reshape(identity, [s[0],s[1],1,1])\n      #identity = tf.tile(identity, [1,1,s[2],s[3]])\n      w = tf.transpose(w, perm=[2,3,0,1])\n      for i in range(self.config.iterations or 3):\n          wt = tf.transpose(w, perm=[1,0,2,3])\n          w2 = tf.reshape(w,[-1, s[0],s[1]])\n          wt2 = tf.reshape(wt,[-1, s[0],s[1]])\n          wtw = tf.matmul(wt2,w2)\n          eye = tf.eye(s[0],s[1])\n          eye = tf.tile(eye, [1,s[2]*s[3]])\n          eye = tf.reshape(eye, self.gan.ops.shape(w))\n          wtw = tf.reshape(wtw, self.gan.ops.shape(w))\n          qk = eye - wtw\n          w = w * (eye + 0.5*qk)\n      w = tf.transpose(w, perm=[2,3,0,1])\n      newv = w\n      newv=(1.0+self.decay)*v - self.decay*(newv)\n      newv = tf.reshape(newv,self.ops.shape(v))\n      return tf.assign(v, newv)\n    else:\n      return None\n\n\n  def _update_ortho2(self,v,i):\n    if len(v.shape) == 4:\n      w=v\n      w = tf.transpose(w, perm=[2,3,0,1])\n      identity = tf.cast(tf.diag(np.ones(self.ops.shape(w)[0])), tf.float32)\n      wt = tf.transpose(w, perm=[1,0,2,3])\n      #s = self.ops.shape(v_transpose)\n      #identity = tf.reshape(identity, [s[0],s[1],1,1])\n      #identity = tf.tile(identity, [1,1,s[2],s[3]])\n      newv = tf.matmul(w, tf.matmul(wt,w))\n      newv = tf.reshape(newv,self.ops.shape(v))\n      newv = tf.transpose(newv, perm=[2,3,0,1])\n      newv=(1+self.decay)*v - self.decay*(newv)\n\n      return tf.assign(v, newv)\n    return None\n  def _update_lipschitz(self,v,i):\n    config = self.config\n    if len(v.shape) > 1:\n      k = self.config.weight_constraint_k or 100.0000\n      wi_hat = v\n      if len(v.shape) == 4:\n        #fij = tf.reduce_sum(tf.abs(wi_hat),  axis=[0,1])\n        fij = wi_hat\n        fij = tf.reduce_sum(tf.abs(fij),  axis=[1])\n        fij = tf.reduce_max(fij,  axis=[0])\n      else:\n        fij = wi_hat\n\n      if self.config.ortho_pnorm == ""inf"":\n        wp = tf.reduce_max(tf.reduce_sum(tf.abs(fij), axis=0), axis=0)\n      else:\n        # conv\n        wp = tf.reduce_max(tf.reduce_sum(tf.abs(fij), axis=1), axis=0)\n      ratio = (1.0/tf.maximum(1.0, wp/k))\n      \n      if self.config.weight_bounce:\n        bounce = tf.minimum(1.0, tf.ceil(wp/k-0.999))\n        ratio -= tf.maximum(0.0, bounce) * 0.2\n\n      if self.config.weight_scaleup:\n        up = tf.minimum(1.0, tf.ceil(0.02-wp/k))\n        ratio += tf.maximum(0.0, up) * k/wp * 0.2\n\n      wi = ratio*(wi_hat)\n      #self.gan.metrics[\'wi\'+str(i)]=wp\n      #self.gan.metrics[\'wk\'+str(i)]=ratio\n      #self.gan.metrics[\'bouce\'+str(i)]=bounce\n      return tf.assign(v, wi)\n    return None\n\n  def _update_l2nn(self,v,i):\n    config = self.config\n    s = self.gan.ops.shape(v)\n    if len(v.shape) == 4 and s[0] == s[1]:\n      w=v\n      wt = tf.transpose(w, perm=[1,0,2,3])\n      w2 = tf.reshape(w,[-1, s[0],s[1]])\n      wt2 = tf.reshape(wt,[-1, s[0],s[1]])\n      wtw = tf.matmul(wt2,w2)\n      wwt = tf.matmul(w2,wt2)\n      wtw = tf.reshape(wtw, [-1, self.ops.shape(v)[-1]])\n      wwt = tf.reshape(wwt, [-1, self.ops.shape(v)[-1]])\n    else:\n      #w = v\n      #w = tf.reshape(w, [-1, self.ops.shape(v)[-1]])\n      #wt = tf.transpose(w)\n      #wtw = tf.matmul(wt,w)\n      #wwt = tf.matmul(w,wt)\n      return None\n    def _r(m):\n      s = self.ops.shape(m)\n      m = tf.abs(m)\n      m = tf.reduce_sum(m, axis=0,keep_dims=True)\n      m = tf.reduce_max(m, axis=1,keep_dims=True)\n      #m = tf.tile(m,[s[0],s[1],1,1])\n      return m\n    bw = tf.minimum(_r(wtw), _r(wwt))\n    #self.gan.add_metric(\'bw\', tf.reduce_mean(bw))\n    #wi = v-(tf.sign(v)*bw)#\n    wi = (v/bw)\n    if self.decay is not None:\n      wi = (1-self.decay)*v+(self.decay*wi)\n    wi = tf.reshape(wi, self.ops.shape(v))\n    return tf.assign(v, wi)\n\n  def _update_weight_constraint(self,v,i):\n    if ""Adam"" in v.name or ""AMSGrad"" in v.name or ""RMS"" in v.name or ""Adadelta"" in v.name:\n      print(""> skipping(name)"", v.name)\n      return None\n\n    config = self.config\n    #skipped = [gan.generator.ops.weights[0], gan.generator.ops.weights[-1], gan.discriminator.ops.weights[0], gan.discriminator.ops.weights[-1]]\n    #skipped = [gan.discriminator.ops.weights[-1]]\n    skipped=[]\n    for skip in skipped:\n      if self.ops.shape(v) == self.ops.shape(skip):\n        print(""Skipping constraints on"", v)\n        return None\n    constraints = self.config.constraints or self.config.weight_constraint or []\n    result = []\n    if ""ortho"" in constraints:\n      result.append(self._update_ortho(v,i))\n    if ""ortho2"" in constraints:\n      result.append(self._update_ortho2(v,i))\n    if ""lipschitz"" in constraints:\n      result.append(self._update_lipschitz(v,i))\n    if ""l2nn"" in constraints:\n      result.append(self._update_l2nn(v,i))\n    if ""l2nn-d"" in constraints:\n      if v in d_vars:\n        result.append(self._update_l2nn(v,i))\n    result = [r for r in result if r is not None]\n    if(len(result) == 0):\n      return None\n    return result\n\n  def before_step(self, step, feed_dict):\n    if self.config.order == ""after"":\n        pass\n    else:\n        if ((step % (self.config.constraint_every or 100)) == 0):\n            #print(""Applying weight constraint (pre)"")\n            self.gan.session.run(self.update_weight_constraints, feed_dict)\n\n  def after_step(self, step, feed_dict):\n    if self.config.order == ""after"":\n        if ((step % (self.config.constraint_every or 100)) == 0):\n            #print(""Applying weight constraint (post)"")\n            self.gan.session.run(self.update_weight_constraints, feed_dict)\n'"
hypergan/train_hooks/weight_penalty_train_hook.py,22,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass WeightPenaltyTrainHook(BaseTrainHook):\n  def __init__(self, gan=None, config=None, trainer=None, name=""WeightPenaltyTrainHook"", memory_size=2, top_k=1):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    d_losses = []\n    weights = self.gan.weights()\n    config = hc.Config(config)\n    if config.only_d:\n        weights = self.discriminator.weights()\n    else:\n        weights = self.gan.weights()\n    if ""l2nn"" in config.constraints:\n        l2nn_penalties = []\n        if len(weights) > 0:\n            for w in weights:\n                w = tf.reshape(w, [-1, self.ops.shape(w)[-1]])\n                wt = tf.transpose(w)\n                wtw = tf.matmul(wt,w)\n                wwt = tf.matmul(w,wt)\n                def _l(m):\n                    m = tf.abs(m)\n                    m = tf.reduce_sum(m, axis=0,keep_dims=True)\n                    m = tf.maximum(m-1, 0)\n                    m = tf.reduce_max(m, axis=1,keep_dims=True)\n                    return m\n                l2nn_penalties.append(tf.minimum(_l(wtw), _l(wwt)))\n            print(\'l2nn_penalty\', self.config.l2nn_penalty, l2nn_penalties)\n            l2nn_penalty = self.config.l2nn_penalty * tf.add_n(l2nn_penalties)\n            self.add_metric(\'l2nn_penalty\', self.gan.ops.squash(l2nn_penalty))\n            d_losses.append(l2nn_penalty)\n    if ""ortho"" in config.constraints:\n        penalties = []\n        for w in self.gan.weights():\n            print(""PENALTY"", w)\n            w = tf.reshape(w, [-1, self.ops.shape(w)[-1]])\n            wt = tf.transpose(w)\n            wtw = tf.matmul(wt,w)\n            wwt = tf.matmul(w,wt)\n            mwtw = tf.matmul(w, wtw)\n            mwwt = tf.matmul(wt, wwt)\n            def _l(w,m):\n                l = tf.reduce_mean(tf.abs(w - m))\n                l = self.ops.squash(l)\n                return l\n            penalties.append(tf.minimum(_l(w, mwtw), _l(wt, mwwt)))\n        penalty = self.config.ortho_penalty * tf.add_n(penalties)\n        self.add_metric(\'ortho_penalty\', self.gan.ops.squash(penalty))\n        print(""PENALTY"", penalty)\n        penalty = tf.reshape(penalty, [1,1])\n        penalty = tf.tile(penalty, [self.gan.batch_size(), 1])\n        d_losses.append(penalty)\n\n\n    print(""D_LOSSES"", d_losses)\n    self.loss = tf.add_n(d_losses)\n\n  def losses(self):\n    return [self.loss, self.loss]\n\n  def after_step(self, step, feed_dict):\n    pass\n\n  def before_step(self, step, feed_dict):\n    pass\n'"
hypergan/trainers/__init__.py,0,"b'""""""\nTrainers run on gan.step and define how the network trains.\n""""""\nfrom os.path import dirname, basename, isfile\nimport glob\nmodules = glob.glob(dirname(__file__)+""/*.py"")\n__all__ = [ basename(f)[:-3] for f in modules if isfile(f)]\n'"
hypergan/trainers/alternating_trainer.py,3,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass AlternatingTrainer(BaseTrainer):\n    def _create(self):\n        gan = self.gan\n        config = self.config\n\n        loss = gan.loss\n        d_loss, g_loss = loss.sample\n\n        self.d_log = -tf.log(tf.abs(d_loss+TINY))\n\n        g_optimizer = config.g_optimizer or config.optimizer\n        d_optimizer = config.d_optimizer or config.optimizer\n        d_optimizer[""loss""] = d_loss\n        g_optimizer[""loss""] = g_loss\n        g_optimizer = self.gan.create_optimizer(g_optimizer)\n        d_optimizer = self.gan.create_optimizer(d_optimizer)\n        \n        d_grads = tf.gradients(d_loss, gan.trainable_d_vars())\n        g_grads = tf.gradients(g_loss, gan.trainable_g_vars())\n        apply_vec_g = list(zip((g_grads), (gan.trainable_g_vars()))).copy()\n        apply_vec_d = list(zip((d_grads), (gan.trainable_d_vars()))).copy()\n        self.g_loss = g_loss\n        self.d_loss = d_loss\n        self.gan.trainer = self\n        g_optimizer_t = g_optimizer.apply_gradients(apply_vec_g, global_step=self.global_step)\n        d_optimizer_t = d_optimizer.apply_gradients(apply_vec_d, global_step=self.global_step)\n\n        self.d_optimizer = d_optimizer\n        self.d_optimizer_t = d_optimizer_t\n        self.g_optimizer = g_optimizer\n        self.g_optimizer_t = g_optimizer_t\n\n        return g_optimizer, d_optimizer\n\n    def variables(self):\n        return self.ops.variables() + self.d_optimizer.variables() + self.g_optimizer.variables()\n\n    def _step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n        loss = gan.loss\n        metrics = gan.metrics()\n\n        d_loss, g_loss = loss.sample\n\n        self.before_step(self.current_step, feed_dict)\n        for i in range(config.d_update_steps or 1):\n            sess.run([self.d_optimizer_t], feed_dict)\n\n        metric_values = sess.run([self.g_optimizer_t] + self.output_variables(metrics), feed_dict)[1:]\n        self.after_step(self.current_step, feed_dict)\n\n        if self.current_step % 10 == 0:\n            print(str(self.output_string(metrics) % tuple([self.current_step] + metric_values)))\n\n'"
hypergan/trainers/base_trainer.py,1,"b'from hypergan.gan_component import GANComponent\nimport hyperchamber as hc\nimport tensorflow as tf\nimport inspect\n\nclass BaseTrainer(GANComponent):\n    def __init__(self, gan, config, d_vars=None, g_vars=None, name=""BaseTrainer""):\n        self.current_step = 0\n        self.g_vars = g_vars\n        self.d_vars = d_vars\n        self.train_hooks = []\n        \n        GANComponent.__init__(self, gan, config, name=name)\n\n    def _step(self, feed_dict):\n        raise Exception(\'BaseTrainer _step called directly.  Please override.\')\n\n    def variables(self):\n        return self.ops.variables() + self.optimizer.variables()\n\n    def create(self):\n        config = self.config\n        g_lr = config.g_learn_rate\n        d_lr = config.d_learn_rate\n        self.create_called = True\n        self.global_step = tf.train.get_global_step()\n        self.d_lr = d_lr\n        self.g_lr = g_lr\n        for hook_config in (config.hooks or []):\n            hook_config = hc.lookup_functions(hook_config.copy())\n            defn = {k: v for k, v in hook_config.items() if k in inspect.getargspec(hook_config[\'class\']).args}\n            defn[\'gan\']=self.gan\n            defn[\'config\']=hook_config\n            defn[\'trainer\']=self\n            hook = hook_config[""class""](**defn)\n            self.gan.components += [hook]\n            losses = hook.losses()\n            if losses[0] is not None:\n                self.gan.loss.sample[0] += losses[0]\n            if losses[1] is not None:\n                self.gan.loss.sample[1] += losses[1]\n            self.train_hooks.append(hook)\n \n        result = self._create()\n\n        for hook in self.train_hooks:\n            hook.after_create()\n\n    def step(self, feed_dict={}):\n        with self.gan.graph.as_default():\n            step = self._step(feed_dict)\n        self.current_step += 1\n        return step\n\n    def required(self):\n        return """".split()\n\n    def output_string(self, metrics):\n        name = self.gan.name or """"\n        output = name + "" %2d: "" \n        for name in sorted(metrics.keys()):\n            output += "" "" + name\n            output += "" %.2f""\n        return output\n\n    def output_variables(self, metrics):\n        gan = self.gan\n        sess = gan.session\n        return [metrics[k] for k in sorted(metrics.keys())]\n\n\n    def before_step(self, step, feed_dict):\n        for component in self.train_hooks:\n            component.before_step(step, feed_dict)\n\n    def after_step(self, step, feed_dict):\n        for component in self.train_hooks:\n            component.after_step(step, feed_dict)\n'"
hypergan/trainers/batch_fitness_trainer.py,3,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass BatchFitnessTrainer(BaseTrainer):\n    def create(self):\n        self.hist = [0 for i in range(2)]\n        config = self.config\n        self.global_step = tf.train.get_global_step()\n        self.mix_threshold_reached = False\n        decay_function = config.decay_function\n        self.min_fitness = None\n        super(BatchFitnessTrainer, self).create()\n\n    def _create(self):\n        gan = self.gan\n        config = self.config\n        loss = gan.loss\n        d_vars = gan.d_vars()\n        g_vars = gan.g_vars()\n        self._delegate = self.gan.create_component(config.trainer)\n        ftype = config.type\n\n        self.fitness = -loss.d_fake\n        if self.config.reverse:\n            self.fitness = loss.d_fake\n        if self.config.abs:\n            self.fitness = tf.abs(self.gan.loss.d_fake)\n        if self.config.nabs:\n            self.fitness = -tf.abs(self.gan.loss.d_fake)\n        self.zs = None\n\n    def variables(self):\n        return self._delegate.variables()\n\n    def required(self):\n        return """".split()\n\n    def _step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n        loss = self.gan.loss \n        metrics = gan.metrics()\n\n        feed_dict = {}\n\n        fit = False\n        if self.zs is None:\n            d = sess.run([self.fitness,gan.latent.sample])\n            fitness = d[0]\n            zs = d[1]\n        else:\n            fitness = sess.run(self.fitness)\n            zs = self.zs\n        if self.config.heuristic is not None:\n            last_fitness = 10000\n            count = 0\n            for i in range(self.config.search_steps or 2):\n                d = sess.run([self.fitness,gan.latent.sample])\n                _f = d[0]\n                _z = d[1]\n                fitness = np.reshape(fitness, np.shape(_f))\n                fitness = np.concatenate([fitness,_f], axis=0)\n                zs = np.reshape(zs, np.shape(_z))\n                zs = np.concatenate([zs,_z], axis=0)\n                sort = np.argsort(fitness.flatten())[:gan.batch_size()]\n                zs = zs[sort]\n                fitness = fitness.flatten()[sort]\n                if fitness.flatten()[-1] < last_fitness:\n                    last_fitness = fitness[-1]\n                    count = 0\n                else:\n                    count += 1\n                    if count > self.config.heuristic:\n                        #print(""z fit "", i)\n                        sort_zs = np.reshape(zs, np.shape(_z))\n                        break\n        else:\n            for i in range(self.config.search_steps or 2):\n                d = sess.run([self.fitness,gan.latent.sample])\n                _f = d[0]\n                _z = d[1]\n                fitness = np.concatenate([fitness,_f], axis=0)\n                zs = np.concatenate([zs,_z], axis=0)\n            fitness = np.array(fitness).flatten()\n            sort = np.argsort(fitness)\n            sort = sort[:gan.batch_size()]\n            sort_zs = zs[sort]\n        feed_dict[gan.latent.sample]=sort_zs\n        self.zs = sort_zs\n        \n        self.before_step(self.current_step, feed_dict)\n        self._delegate.step(feed_dict)\n\n        self.after_step(self.current_step, feed_dict)\n\n'"
hypergan/trainers/curriculum_trainer.py,2,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\nimport nashpy as nash\nimport hypergan as hg\nimport hyperchamber as hc\nimport sys\nimport gc\nimport os\nimport random\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass CurriculumTrainer(BaseTrainer):\n    def create(self):\n        self.curriculum = self.config.curriculum\n        self.curriculum_index = 0\n        self._delegate = self.gan.create_component(self.config.delegate)\n\n    def variables(self):\n        return self._delegate.variables()\n\n    def required(self):\n        return []\n\n    def step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n\n        self._delegate.step(feed_dict)\n\n        transition_step = self.curriculum[self.curriculum_index][0]\n        self.current_step += 1\n        if (self.current_step-1) == transition_step:\n\n            gan.save(""saves/curriculum"")\n            self.curriculum_index+=1\n\n            if self.config.cycle:\n                self.curriculum_index = self.curriculum_index % len(self.curriculum)\n            if self.curriculum_index == len(self.curriculum):\n                print(""End of curriculum"")\n                gan.save(""saves/curriculum"")\n                gan.session.close()\n                tf.reset_default_graph()\n                sys.exit()\n\n\n            print(""Loading index"", self.curriculum_index, self.curriculum, self.curriculum[self.curriculum_index])\n            gan.session.close()\n            tf.reset_default_graph()\n\n            config_name = self.curriculum[self.curriculum_index][1]\n\n            newconfig_file = hg.Configuration.find(config_name+\'.json\')\n            if newconfig_file is None:\n                print(""Could not find file "", config_name+"".json"")\n                raise(""missing file"")\n            print(""=> Loading config file"", newconfig_file)\n            newconfig = hc.Selector().load(newconfig_file)\n            if \'inherit\' in newconfig:\n                base_filename = hg.Configuration.find(newconfig[\'inherit\']+\'.json\')\n                base_config = hc.Selector().load(base_filename)\n                newconfig = hc.Config({**base_config, **newconfig})\n\n            inputs = hg.inputs.image_loader.ImageLoader(newconfig.runtime[\'batch_size\'])\n            inputs.create(gan.args.directory,\n                  channels=newconfig.runtime[\'channels\'], \n                  format=gan.args.format,\n                  crop=gan.args.crop,\n                  width=newconfig.runtime[\'width\'],\n                  height=newconfig.runtime[\'height\'],\n                  resize=gan.args.resize)\n\n            newgan = gan.config[\'class\'](config=newconfig, inputs=inputs)\n            newgan.args = gan.args\n            newgan.cli = self.gan.cli\n            newgan.name=config_name\n            newgan.trainer.curriculum= self.curriculum\n            newgan.trainer.curriculum_index= self.curriculum_index\n            newgan.trainer.config.cycle = self.config.cycle\n            newgan.cli.sampler = None\n            gan.cli.sampler = None\n            gan.destroy=True\n            gan.newgan=newgan\n            gan=None\n            gc.collect()\n            newgan.load(""saves/curriculum"")\n\n'"
hypergan/trainers/depth_trainer.py,2,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass DepthTrainer(BaseTrainer):\n    """""" Runs an optimizer multiple times and combines the output into a mixture. """"""\n    def _create(self):\n        self.hist = [0 for i in range(2)]\n        config = self.config\n        self.mix_threshold_reached = False\n        variables = self.gan.d_vars() + self.gan.g_vars()\n        self.ema = [ tf.Variable(_v) for _v in variables ]\n        self.store_v = [ _v.assign(_v2) for _v,_v2 in zip(self.ema, variables) ]\n        self.combine = [ _v.assign((config.decay or 0.1) *_ema + (1.-(config.decay or 0.1))*_new) for _v, _ema, _new in zip(variables, self.ema, variables)]\n        self._delegate = self.gan.create_component(config.trainer, d_vars=self.d_vars, g_vars=self.g_vars)\n        self.reset_optimizer_t = tf.variables_initializer(self._delegate.variables())\n        self.depth_step = 0\n        self.fitness = -self.gan.loss.d_fake\n        self.latent = None\n\n    def required(self):\n        return """".split()\n\n    def _best_latent(self):\n        if self.latent is None:\n            self.latent = self.gan.session.run(self.gan.latent.sample)\n        fitness = self.gan.session.run(self.fitness, {self.gan.latent.sample:self.latent})\n        zs = self.latent\n        sort_zs = None\n        last_fitness = 10000\n        count = 0\n        while True:\n            d = self.gan.session.run([self.fitness,self.gan.latent.sample])\n            _f = d[0]\n            _z = d[1]\n            fitness = np.reshape(fitness, np.shape(_f))\n            fitness = np.concatenate([fitness,_f], axis=0)\n            zs = np.reshape(zs, np.shape(_z))\n            zs = np.concatenate([zs,_z], axis=0)\n            sort = np.argsort(fitness.flatten())[:self.gan.batch_size()]\n            zs = zs[sort]\n            fitness = fitness.flatten()[sort]\n            if fitness.flatten()[-1] < last_fitness:\n                last_fitness = fitness[-1]\n                count = 0\n            else:\n                count += 1\n                if count > self.config.heuristic:\n                    #print(""z fit "", i)\n                    sort_zs = np.reshape(zs, np.shape(_z))\n                    break\n        return sort_zs\n\n    def _step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n        depth = self.config.depth\n        if depth:\n            if self.current_step % depth == 0:\n                if self.config.freeze_latent:\n                    if self.config.freeze_latent == ""best"":\n                        self.latent = self._best_latent()\n                    else:\n                        self.latent = self.gan.session.run(self.gan.latent.sample)\n                    feed_dict[gan.latent.sample] = self.latent\n                self.before_step(self.current_step, feed_dict)\n                gan.session.run(self.store_v)\n                if self.config.reset_optimizer:\n                    self.gan.session.run([self.reset_optimizer_t])\n\n            if self.config.freeze_latent:\n                feed_dict[gan.latent.sample] = self.latent\n            self._delegate.step(feed_dict)\n            if self.current_step % depth == depth - 1:\n                gan.session.run(self.combine)\n                self.after_step(self.current_step, feed_dict)\n        else:\n            if self.depth_step == 0:\n                if self.config.freeze_latent:\n                    if self.config.freeze_latent == ""best"":\n                        self.latent = self._best_latent()\n                    else:\n                        self.latent = self.gan.session.run(self.gan.latent.sample)\n                    feed_dict[gan.latent.sample] = self.latent\n                self.before_step(self.current_step, feed_dict)\n                gan.session.run(self.store_v)\n                self.max_gradient_mean = 0.0\n            if self.config.freeze_latent:\n                feed_dict[gan.latent.sample] = self.latent\n            self._delegate.step(feed_dict)\n            gradient_mean = gan.session.run(gan.gradient_mean, feed_dict)\n            self.depth_step += 1\n            if gradient_mean > self.max_gradient_mean:\n                self.max_gradient_mean = gradient_mean\n            if gradient_mean/self.max_gradient_mean < (0.2 or self.config.gradient_threshold):\n                gan.session.run(self.combine)\n                self.after_step(self.current_step, feed_dict)\n                self.depth_step = 0\n\n    def variables(self):\n        return self._delegate.variables()\n'"
hypergan/trainers/fitness_trainer.py,17,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass FitnessTrainer(BaseTrainer):\n    def create(self):\n        self.hist = [0 for i in range(2)]\n        config = self.config\n        self.global_step = tf.train.get_global_step()\n        self.mix_threshold_reached = False\n        decay_function = config.decay_function\n        self.min_fitness = None\n\n        super(FitnessTrainer, self).create()\n\n    def _create(self):\n        gan = self.gan\n        config = self.config\n        loss = gan.loss\n        d_vars = gan.d_vars()\n        g_vars = gan.g_vars()\n        self._delegate = self.gan.create_component(config.trainer)\n        ftype = config.type\n\n        if(ftype == \'fail2\'):\n            self.fitness = -loss.d_fake\n        elif(ftype == \'fail2-reverse\'):\n            self.fitness = loss.d_fake\n        elif(ftype == \'ls\'):\n            a,b,c = loss.config.labels\n            self.fitness = tf.square(loss.d_fake-a)\n        elif(ftype == \'ls-r\'):\n            a,b,c = loss.config.labels\n            self.fitness = -tf.square(loss.d_fake-a)\n        elif(ftype == \'ls2\'):\n            a,b,c = loss.config.labels\n            self.fitness = tf.square(loss.d_fake-c)\n        elif(ftype == \'ls2-r\'):\n            a,b,c = loss.config.labels\n            self.fitness = -tf.square(loss.d_fake-c)\n        elif(ftype == \'std\'):\n            self.fitness = -tf.nn.sigmoid(loss.d_fake)\n        elif(ftype == \'ls3\'):\n            self.fitness = 1-loss.d_fake\n        elif(ftype == \'ls4\'):\n            self.fitness = loss.d_real-loss.d_fake\n        elif(ftype == \'ls5\'):\n            self.fitness = tf.square(loss.d_real)-tf.square(loss.d_fake)\n        elif(ftype == \'fq1\'):\n            lam = 0.1\n            self.fitness = -loss.d_fake-lam*mean\n        elif(ftype == \'fq2\'):\n            lam = 0.1\n            self.fitness = loss.d_real-loss.d_fake-lam*mean\n        elif(ftype == \'fq3\'):\n            lam = 1\n            self.fitness = loss.d_real-loss.d_fake+lam*mean\n        elif(ftype == \'fq4\'):\n            lam = 1\n            self.fitness = -loss.d_fake+lam*mean\n        elif(ftype == \'fq5\'):\n            lam = 1\n            self.fitness = -loss.d_fake-lam*tf.norm(mean)\n        elif(ftype == \'fq6\'):\n            lam = 0.1\n            self.fitness = -loss.d_fake-lam*tf.norm(mean+d_loss)\n        elif(ftype == \'fq7\'):\n            lam = 0.1\n            self.fitness = -loss.d_fake-lam*tf.norm(-mean-d_loss)\n        elif(ftype == \'fq8\'):\n            lam = 0.1\n            self.fitness = -tf.norm(mean+d_loss)\n        elif(ftype == \'fq9\'):\n            lam = 0.1\n            self.fitness = lam*mean\n        elif(ftype == \'fq10\'):\n            lam = 0.1\n            self.fitness = tf.norm(mean+d_loss)\n        elif(ftype == \'fq11\'):\n            lam = 100.00\n            self.fq = -loss.d_fake\n            self.fd = lam * mean\n            self.fitness = -loss.d_fake + lam * mean\n        elif(ftype == \'ls3-fail\'):\n            self.fitness = -(1-loss.d_fake)\n        elif(ftype == \'gldl\'):\n            self.fitness = -d_loss + g_loss\n        elif(ftype == \'df\'):\n            self.fitness = tf.abs(loss.d_fake) - tf.abs(loss.d_real)\n        elif(ftype == \'standard\'):\n            self.fitness = tf.reduce_mean(g_loss) - (config.diversity_importance or 1)* tf.log(tf.abs(self.mean - tf.log(TINY+tf.sigmoid(d_loss)) - \\\n                    tf.log(1.0-tf.sigmoid(g_loss)+TINY)))\n        else:\n            #self.fitness = tf.reduce_mean(loss.d_fake) - (config.diversity_importance or 1)* tf.log(tf.abs(self.mean + tf.reduce_mean(loss.d_real) - tf.reduce_mean(loss.d_fake)))\n            self.fitness = -loss.d_fake\n        self.fitness = tf.reduce_mean(self.fitness)\n\n    def variables(self):\n        return self._delegate.variables()\n\n    def required(self):\n        return """".split()\n\n    def _step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n        loss = self.gan.loss \n        metrics = gan.metrics()\n\n        feed_dict = {}\n\n        fit = False\n        steps_since_fit = 0\n        old_fitness = None\n        while not fit:\n            steps_since_fit+=1\n            fitness, *zs = sess.run([self.fitness,gan.latent.sample])\n            if old_fitness == fitness:\n                print(""Stuck state detected, unsticking"")\n                self.min_fitness = None\n                return\n            old_fitness = fitness\n\n\n            g = None\n            if(self.min_fitness is None or fitness <= self.min_fitness):\n                self.hist[0]+=1\n                self.min_fitness = fitness\n                steps_since_fit=0\n\n                for v, t in ([ [v, t] for v, t in zip(zs, [gan.latent.sample])]):\n                    feed_dict[t]=v\n\n                self.before_step(self.current_step, feed_dict)\n                self._delegate.step(feed_dict)\n\n                self.after_step(self.current_step, feed_dict)\n                fit=True\n            else:\n                self.hist[1]+=1\n                fitness_decay = config.fitness_decay or 0.99\n                self.min_fitness = self.min_fitness + (1.00-fitness_decay)*(fitness-self.min_fitness)\n\n            steps_since_fit=0\n\n        if ((self.current_step % 10) == 0):\n            hist_output = ""  "" + """".join([""G""+str(i)+"":""+str(v)+"" ""for i, v in enumerate(self.hist)])\n            print(hist_output)\n            self.hist = [0 for i in range(2)]\n\n'"
hypergan/trainers/gang_trainer.py,34,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\nimport nashpy as nash\nimport hypergan as hg\nimport hyperchamber as hc\nimport sys\nimport gc\nimport os\nimport random\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass GangTrainer(BaseTrainer):\n    def create(self):\n        config = self.config\n        gan = self.gan\n        loss = self.gan.loss\n        d_vars = gan.d_vars()\n        g_vars = gan.g_vars()\n        self.reinit = tf.variables_initializer(d_vars+g_vars)\n        self.priority_ds = []\n        self.priority_gs = []\n\n\n        self._delegate = self.gan.create_component(config.rbbr, d_vars=d_vars, g_vars=g_vars)\n        self.optimizer = self._delegate\n\n        print(""VARS  ___"", self.optimizer.variables())\n        for var in self.optimizer.variables():\n            if ""generator"" in var.name:\n                g_vars += [var]\n            elif ""discriminator"" in var.name:\n                d_vars += [var]\n            else:\n                print(""[WARNING] Unknown gang variable, not added to g_vars or d_vars: "", var)\n        d_loss, g_loss = loss.sample\n        if self.config.fitness_method == ""wasserstein"":\n            self.gang_loss = -(loss.d_real-loss.d_fake)\n        elif self.config.fitness_method == ""least_squares"":\n            b = gan.loss.config.labels[1]\n            a = gan.loss.config.labels[0]\n            self.gang_loss = tf.sign(loss.d_fake + loss.d_real) * tf.square(loss.d_fake+loss.d_real)\n        elif self.config.fitness_method == ""least_squares2"":\n            self.gang_loss = tf.square(loss.d_fake)-tf.square(loss.d_real)\n        elif self.config.fitness_method == ""least_squares3"":\n            c = gan.loss.config.labels[2]\n            b = gan.loss.config.labels[1]\n            a = gan.loss.config.labels[0]\n            self.gang_loss = tf.square(loss.d_fake)*tf.sign(loss.d_fake) + tf.square(loss.d_real)*tf.sign(d_real)\n        elif self.config.fitness_method == ""least_squares4"":\n            c = gan.loss.config.labels[2]\n            b = gan.loss.config.labels[1]\n            a = gan.loss.config.labels[0]\n            self.gang_loss = tf.square((-loss.d_fake+1)/2) - tf.square((-loss.d_real+1)/2)\n\n        elif self.config.fitness_method == \'double\':\n            self.gang_loss = [loss.d_fake+loss.d_real, loss.d_real-loss.d_fake]\n        elif self.config.fitness_method == \'double_ragan\':\n            self.gang_loss = [0.7*(loss.d_fake-loss.d_real)+0.3*(loss.d_real-loss.d_fake), \n                    0.7*(loss.d_real-loss.d_fake)-0.3*(loss.d_fake-loss.d_real)]\n        elif self.config.fitness_method == \'zero_raganls\':\n            c = gan.loss.config.labels[2]\n            b = gan.loss.config.labels[1]\n            a = gan.loss.config.labels[0]\n            self.gang_loss = tf.square(loss.d_real-loss.d_fake-b) - tf.square(loss.d_fake - loss.d_real - b)\n        elif self.config.fitness_method == \'zero_raganls2\':\n            c = gan.loss.config.labels[2]\n            b = gan.loss.config.labels[1]\n            a = gan.loss.config.labels[0]\n            self.gang_loss = tf.square(loss.d_real-loss.d_fake-b)\n        elif self.config.fitness_method == \'-gl-dl\':\n            self.gang_loss = [-g_loss, -d_loss]\n        elif self.config.fitness_method == \'gl-dl2\':\n            self.gang_loss = [-g_loss, g_loss]\n        elif self.config.fitness_method == \'gldl\':\n            # breaks\n            self.gang_loss = [g_loss, d_loss]\n        elif self.config.fitness_method == \'double2\':\n            a = gan.loss.config.labels[0]\n            b = gan.loss.config.labels[1]\n            self.gang_loss = [tf.square(loss.d_fake-a)+tf.square(loss.d_real-a), tf.square(los++d_real-a)+tf.square(loss.d_fake-b)]\n        elif self.config.fitness_method == ""least_squares5"":\n            c = gan.loss.config.labels[2]\n            b = gan.loss.config.labels[1]\n            a = gan.loss.config.labels[0]\n            self.gang_loss = tf.nn.relu(loss.d_real)*loss.d_fake\n        elif self.config.fitness_method == ""least_squares7"":\n            c = gan.loss.config.labels[2]\n            b = gan.loss.config.labels[1]\n            a = gan.loss.config.labels[0]\n            self.gang_loss = (tf.nn.relu(loss.d_real)*tf.nn.relu(loss.d_fake))\n        elif self.config.fitness_method == ""least_squares8"":\n            c = gan.loss.config.labels[2]\n            b = gan.loss.config.labels[1]\n            a = gan.loss.config.labels[0]\n            self.gang_loss = (loss.d_real-a)*(loss.d_fake-a)\n        elif self.config.fitness_method == ""least_squares9"":\n            c = gan.loss.config.labels[2]\n            b = gan.loss.config.labels[1]\n            a = gan.loss.config.labels[0]\n            self.gang_loss = (loss.d_real-a)*(loss.d_fake-a)-(loss.d_real-b)*(loss.d_fake-b)\n        elif self.config.fitness_method == ""least_squares6"":\n            c = gan.loss.config.labels[2]\n            b = gan.loss.config.labels[1]\n            a = gan.loss.config.labels[0]\n            self.gang_loss = tf.square(tf.nn.relu(loss.d_real))*tf.sign(loss.d_fake)*tf.square(loss.d_fake)\n\n        elif self.config.fitness_method == ""raleast_squares"":\n            c = gan.loss.config.labels[2]\n            b = gan.loss.config.labels[1]\n            a = gan.loss.config.labels[0]\n            self.gang_loss = tf.square((-(loss.d_fake - loss.d_real)+1)/2) - tf.square((-(loss.d_real-loss.d_fake)+1)/2)\n        elif self.config.fitness_method == ""jsd"":\n            def mean_entropy(p, q):\n                return p * (tf.log(p / (0.5*(p+q))))\n            p = loss.d_fake\n            q = loss.d_real\n            self.gang_loss = -((mean_entropy(q, p) + mean_entropy(p, q)) / 2)\n\n        elif self.config.fitness_method == ""g_loss"":\n            self.gang_loss = g_loss\n        elif self.config.fitness_method == ""d_loss"":\n            self.gang_loss = d_loss\n        elif self.config.fitness_method == ""-g_loss"":\n            self.gang_loss = -g_loss\n        elif self.config.fitness_method == \'ralsgan\':\n            b = gan.loss.config.labels[1]\n            a = gan.loss.config.labels[0]\n            self.gang_loss = 0.5*tf.square(loss.d_real - loss.d_fake - b) + 0.5*tf.square(loss.d_fake - loss.d_real - b)\n        elif self.config.fitness_method == \'ragan\':\n            self.gang_loss = -tf.nn.sigmoid(loss.d_real-loss.d_fake)+ \\\n                         tf.nn.sigmoid(loss.d_fake-loss.d_real)\n        elif self.config.fitness_method == \'ragan2\':\n            self.gang_loss = tf.log(tf.nn.sigmoid(loss.d_real)+TINY) - \\\n                         tf.log(tf.nn.sigmoid(loss.d_fake)+TINY)\n        elif self.config.fitness_method == \'f-r\':\n            #self.gang_loss = tf.nn.sigmoid(loss.d_fake - loss.d_real)\n            self.gang_loss = 2*tf.nn.sigmoid(2*(loss.d_fake-loss.d_real))-1\n        elif self.config.fitness_method == \'f-r2\':\n            #self.gang_loss = tf.nn.sigmoid(loss.d_fake - loss.d_real)\n            self.gang_loss = tf.nn.sigmoid((loss.d_fake))-tf.nn.sigmoid((loss.d_real))\n        elif self.config.fitness_method == \'f-r3\':\n            #self.gang_loss = tf.nn.sigmoid(loss.d_fake - loss.d_real)\n            self.gang_loss = tf.nn.sigmoid(loss.d_fake-loss.d_real)-tf.nn.sigmoid(loss.d_real-loss.d_fake)\n        else:\n            self.gang_loss = loss.d_fake - loss.d_real\n\n\n\n        g_vars = list(g_vars)\n        d_vars = list(d_vars)\n        self.all_g_vars = g_vars\n        self.all_d_vars = d_vars\n\n        def random_like(x):\n            shape = self.ops.shape(x)\n            return tf.random_uniform(shape, minval=-0.01, maxval=0.01)\n\n        self.ug = None#gan.session.run(g_vars)\n        self.ud = None#gan.session.run(d_vars)\n        self.pg = [tf.zeros_like(v) for v in g_vars]\n        self._assign_g = [v.assign(pv) for v,pv in zip(g_vars, self.pg)]\n        self.pd = [tf.zeros_like(v) for v in d_vars]\n        self._assign_d = [v.assign(pv) for v,pv in zip(d_vars, self.pd)]\n        self.pm = tf.zeros([1])\n        self.assign_add_d = [v.assign(pv*self.pm+v) for v,pv in zip(d_vars, self.pd)]\n        self.assign_add_g = [v.assign(pv*self.pm+v) for v,pv in zip(g_vars, self.pg)]\n        self.mutate_g = [v.assign(random_like(v)+v) for v in d_vars]\n        self.mutate_d = [v.assign(random_like(v)+v) for v in g_vars]\n\n        self.sgs = []\n        self.sds = []\n\n        self.last_fitness_step = 0\n\n    def required(self):\n        return """"\n\n\n    def rank_gs(self, gs):\n        # todo fitness?\n        return list(np.flip(gs, axis=0)) # most recent\n\n    def rank_ds(self, ds):\n        # todo fitness?\n        return list(np.flip(ds, axis=0)) # most recent\n\n    def destructive_mixture_g(self, priority_g):\n        g_vars = self.all_g_vars\n        self.gan.session.run(self._assign_g, {}) # zero\n        for i, s in enumerate(self.sgs):\n            self.add_g(priority_g[i], s)\n        return self.gan.session.run(g_vars)\n\n    def destructive_mixture_d(self, priority_d):\n        d_vars = self.all_d_vars\n        self.gan.session.run(self._assign_d, {}) # zero\n        for i, s in enumerate(self.sds):\n            self.add_d(priority_d[i], s)\n        return self.gan.session.run(d_vars)\n\n    def nash_memory(self, sg, sd, ug, ud):\n        is_sd_nan = np.isnan(np.sum(np.sum(v) for v in sg))\n        is_sg_nan = np.isnan(np.sum(np.sum(v) for v in sd))\n\n        if is_sd_nan or is_sg_nan:\n            print(""NAN detected, falling back to best candidate"")\n            return [self.sgs[0], self.sds[0]]\n        \n        #zs = [ self.gan.session.run(self.gan.fitness_inputs()) for i in range(self.config.fitness_test_points or 10)]\n        #xs = [ self.gan.session.run(self.gan.inputs.inputs()) for i in range(self.config.fitness_test_points or 10)]\n        #self.xs = xs\n        #self.zs = zs\n        xs = []\n        zs = []\n        self.sgs = [sg] + self.sgs\n        self.sds = [sd] + self.sds\n\n        if isinstance(self.gang_loss, list):\n            a = self.payoff_matrix(self.sgs, self.sds, xs, zs, self.gang_loss[0])\n            b = self.payoff_matrix(self.sgs, self.sds, xs, zs, self.gang_loss[1])\n            print(""Payoffa:"", a)\n            print(""Payoffb:"", b)\n        else:\n            print(""Calculating nash"")\n            a = self.payoff_matrix(self.sgs, self.sds, xs, zs)\n            if np.min(a) == np.max(a) or np.isnan(np.sum(a)):\n                print(""WARNING: Degenerate game, skipping"")\n                print(a)\n                self.priority_ds = list(np.zeros(len(self.sds)))\n                self.priority_gs = list(np.zeros(len(self.sgs)))\n                return [ug, ud]\n            print(""Payoff:"", a)\n            b = -a\n\n        is_a_nan = np.isnan(np.sum(np.sum(v) for v in a))\n        is_b_nan = np.isnan(np.sum(np.sum(v) for v in b))\n\n        if is_a_nan or is_b_nan:\n            print(""NAN detected in payoff matrix, falling back to best candidate"")\n            self.sgs = self.sgs[1:]\n            self.sds = self.sds[1:]\n            return [self.sgs[0], self.sds[0]]\n \n        if self.config.use_nash:\n            priority_g, new_ug, priority_d, new_ud = self.nash_mixture_from_payoff(a, b, self.sgs, self.sds)\n        elif self.config.use_crossover:\n            priority_g = self.mixture_from_payoff(a, 1, self.sgs)\n            priority_d = self.mixture_from_payoff(b, 0, self.sds)\n        else:\n            priority_g = self.mixture_from_payoff(a, 1, self.sgs)\n            new_ug = self.destructive_mixture_g(priority_g)\n\n            priority_d = self.mixture_from_payoff(b, 0, self.sds)\n            new_ud = self.destructive_mixture_d(priority_d)\n\n        memory_size = self.config.nash_memory_size or 10\n        sorted_sgs = [[p, v] for p,v in zip(priority_g, self.sgs)]\n        sorted_sds = [[p, v] for p,v in zip(priority_d, self.sds)]\n        sorted_sgs.sort(key=lambda x: -x[0])\n        sorted_sds.sort(key=lambda x: -x[0])\n        print(\'mixture g:\', [x[0] for x in sorted_sgs])\n        print(\'mixture d:\', [x[0] for x in sorted_sds])\n        self.priority_gs = [x[0] for x in sorted_sgs]\n        self.priority_ds = [x[0] for x in sorted_sds]\n        sorted_sds = [s[1] for s in sorted_sds]\n        sorted_sgs = [s[1] for s in sorted_sgs]\n        self.sgs = sorted_sgs[:memory_size]\n        self.sds = sorted_sds[:memory_size]\n        self.priority_gs = self.priority_gs[:memory_size]\n        self.priority_ds = self.priority_ds[:memory_size]\n\n        if self.config.use_crossover:\n            new_ug = self.crossover(self.sgs[0],self.sgs[1])\n            new_ud = self.crossover(self.sds[0],self.sds[1])\n\n\n        return [new_ug, new_ud]\n\n    def crossover(self, s1, s2):\n        strat = list(s1)\n        for i,layer in enumerate(s2):\n            mask = np.random.rand(*layer.shape)\n            if self.config.crossover_random == None:\n                mask = np.around(mask)\n            strat[i]=mask*layer + (1-mask)*strat[i]\n        return strat\n\n    def softmax(self, x):\n        e_x = np.exp(x - np.max(x))\n        return e_x / e_x.sum(axis=0)\n    def sumdiv(self, x):\n        e_x = x\n        return e_x / e_x.sum(axis=0)\n\n    def nash_mixture_from_payoff(self, payoffa, payoffb, sgs, sds):\n        config = self.config\n        def _update_g(p):\n            p = np.reshape(p, [-1])\n            result = self.destructive_mixture_g(p)\n            return p, result\n\n        def _update_d(p):\n            p = np.reshape(p, [-1])\n            result = self.destructive_mixture_d(p)\n            return p, result\n\n        if self.config.nash_method == \'support\':\n            try:\n                u = next(nash.Game(payoffa, payoffb).support_enumeration())\n            except(StopIteration):\n                print(""Nashpy \'support\' iteration failed.  Using 1,0,0..."")\n                u = [list(np.zeros(len(self.sds))), list(np.zeros(len(self.sgs)))]\n                u[0][0]=1.\n                u[1][0]=1.\n\n        elif self.config.nash_method == \'lemke\':\n            u = next(nash.Game(payoffa, payoffb).lemke_howson_enumeration())\n\n        else:\n            try:\n                u = next(nash.Game(payoffa, payoffb).vertex_enumeration())\n            except(StopIteration, scipy.spatial.qhull.QhullError):\n                print(""Nashpy \'vertex\' iteration failed.  Using 1,0,0..."")\n                u = [list(np.zeros(len(self.sds))), list(np.zeros(len(self.sgs)))]\n                u[0][0]=1.\n                u[1][0]=1.\n\n        if len(u[0]) != len(self.sgs):\n            return [None,None,None,None]\n        p1, p1result = _update_g(u[0])\n        p2, p2result = _update_d(u[1])\n\n        return p1, p1result, p2, p2result\n\n\n    def mixture_from_payoff(self, payoff, sum_dim, memory):\n        u = np.sum(payoff, axis=sum_dim)\n        u = self.softmax(u)\n        u = np.reshape(u, [len(memory)])\n        return u\n\n    def payoff_matrix(self, sgs, sds, xs, zs, method=None):\n        self._payoff_matrix = np.zeros([len(sgs), len(sds)])\n        result = self._payoff_matrix\n        for i, sg in enumerate(sgs):\n            for j, sd in enumerate(sds):\n                result[i, j]=self.fitness_score(sg, sd, xs, zs, method) # todo fitness ?\n        return result\n\n    def fitness_score(self, g, d, xs, zs, method=None):\n        self.assign_gd(g,d)\n        sum_fitness = 0\n        test_points = self.config.fitness_test_points or 10\n        if method == None:\n            method = self.gang_loss\n        for i in range(test_points):\n            df, dr = self.gan.session.run([self.gan.loss.d_fake, self.gan.loss.d_real])\n            fitness = self.gan.session.run(method)\n            sum_fitness += np.average(fitness)\n        #for x, z in zip(xs, zs):\n        #    loss = self.loss or self.gan.loss\n        #    feed_dict = {}\n        #    for v, t in zip(x, self.gan.inputs.inputs()):\n        #        feed_dict[t]=v\n        #    for v, t in zip(z, self.gan.fitness_inputs()):\n        #        feed_dict[t]=v\n        #    fitness = self.gan.session.run([method], feed_dict)\n        #    sum_fitness += np.average(fitness)\n\n        sum_fitness /= float(test_points)\n        return sum_fitness\n\n    def assign_gd(self, g, d):\n        self.assign_g(g)\n        self.assign_d(d)\n\n    def assign_g(self, g):\n        fg = {}\n        for v, t in zip(g, self.pg):\n            fg[t] = v\n        self.gan.session.run(self._assign_g, fg)\n\n    def assign_d(self, d):\n        fd = {}\n        for v, t in zip(d, self.pd):\n            fd[t] = v\n        self.gan.session.run(self._assign_d, fd)\n\n    def add_g(self, pm, g):\n        fg = {}\n        for v, t in zip(g, self.pg):\n            fg[t] = v\n        fg[self.pm] = np.reshape(pm, [1])\n        self.gan.session.run(self.assign_add_g, fg)\n\n    def add_d(self, pm, d):\n        fd = {}\n        for v, t in zip(d, self.pd):\n            fd[t] = v\n        fd[self.pm] = np.reshape(pm, [1])\n\n        self.gan.session.run(self.assign_add_d, fd)\n\n    def train_g_on_sds(self):\n        gan = self.gan\n        cd = gan.session.run(self._delegate.d_vars)\n        gl = np.zeros(self._delegate.g_loss.shape)\n        dl = np.zeros(self._delegate.d_loss.shape)\n        for i,sd in enumerate(self.sds):\n            p= self.priority_ds[i]\n            if(p == 0):\n                next\n            self.assign_d(sd)\n\n            _gl, _dl, *zs = gan.session.run([self._delegate.g_loss, self._delegate.d_loss]+gan.fitness_inputs())\n            print(""Train strategy"", i, ""P"", p, ""GL"", _gl, ""DL"", _dl)\n            gl += _gl * p\n            dl += _dl * p\n        feed_dict = {}\n        for v, t in ([[gl*p, self._delegate.g_loss],[dl*p, self._delegate.d_loss]] + [ [v, t] for v, t in zip(zs, gan.fitness_inputs())]):\n            feed_dict[t]=v\n        _ = gan.session.run([self._delegate.g_optimizer], feed_dict)\n        self.assign_d(cd)\n\n    def train_d_on_sgs(self):\n        gan = self.gan\n        cg = gan.session.run(self._delegate.g_vars)\n        for i,sg in enumerate(self.sgs):\n            p= self.priority_gs[i]\n            if(p == 0):\n                next\n            self.assign_g(sg)\n\n            _, _gl, _dl, *zs = gan.session.run([self._delegate.d_optimizer, self._delegate.g_loss, self._delegate.d_loss]+gan.fitness_inputs())\n            print(""Train strategy"", i, ""P"", p, ""GL"", _gl, ""DL"", _dl)\n\n        self.assign_g(cg)\n\n  \n    def _step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n        loss = gan.loss\n        metrics = loss.metrics\n        d_vars = self.all_d_vars\n        g_vars = self.all_g_vars\n        \n        if self.ug == None:\n            self.ug = gan.session.run(g_vars)\n            self.ud = gan.session.run(d_vars)\n            self.sgs.append(self.ug)\n            self.sds.append(self.ud)\n            self.priority_gs = [1]\n            self.priority_ds = [1]\n            if self.config.preload:\n                for preload in self.config.preload:\n                    print(""Preloading "", preload)\n                    default_save_path = os.path.abspath(""saves/""+preload)\n                    save_file = default_save_path + ""/model.ckpt""\n                    gan.session.run(tf.global_variables_initializer())\n                    if not self.gan.load(save_file):\n                        sys.exit(""Could not load "" + save_file)\n                    print(""Assigning to sds"")\n                    preload_ug = gan.session.run(g_vars)\n                    preload_ud = gan.session.run(d_vars)\n                    self.sgs.append(preload_ug)\n                    self.sds.append(preload_ud)\n                    self.priority_gs += [0]\n                    self.priority_ds += [0]\n \n                self.assign_gd(self.ug, self.ud)\n\n        self._delegate.step(feed_dict)\n\n        if config.train_g_on_sds and ((self._delegate.current_step+1) % (config.sds_steps or 100) == 0) and np.max(self.priority_ds) != 0:\n            self.train_g_on_sds()\n        if config.train_d_on_sgs and ((self._delegate.current_step+1) % (config.sgs_steps or 100) == 0) and np.max(self.priority_gs) != 0:\n            self.train_d_on_sgs()\n        \n        #if self.last_fitness_step == self._delegate.current_step:\n        #    return\n        self.last_fitness_step=self._delegate.current_step\n        #print(""Step"", self._delegate.current_step+1)\n        if (gan.step_count+1) % (config.mix_steps or 100) == 0:\n            sg = gan.session.run(g_vars)\n            sd = gan.session.run(d_vars)\n            if config.nash_memory:\n                print(""ENAMBLING NASH MEM"", len(self.sgs))\n                ug, ud = self.nash_memory(sg, sd, self.ug, self.ud)\n                print(""/ENAMBLING NASH MEM"", len(self.sgs))\n            else:\n                decay = config.decay or 0.5\n                ug = [ (o*decay + n*(1-decay)) for o, n in zip(sg, self.ug) ]\n                ud = [ (o*decay + n*(1-decay)) for o, n in zip(sd, self.ud) ]\n\n            if config.recreate:\n                gan.train_coordinator.request_stop()\n                gan.train_coordinator.join(gan.input_threads)\n                gan.session.close()\n                tf.reset_default_graph()\n                #x = tf.contrib.graph_editor.copy(self.gan.inputs.x)\n                #self.gan.inputs.x = x\n                inputs = hg.inputs.image_loader.ImageLoader(gan.args.batch_size)\n                inputs.create(gan.args.directory,\n                      channels=gan.x_channels, \n                      format=gan.args.format,\n                      crop=gan.args.crop,\n                      width=gan.x_width,\n                      height=gan.x_height,\n                      resize=gan.args.resize)\n                config_name = random.choice(self.config.mutations)\n\n                newconfig_file = hg.Configuration.find(config_name+\'.json\')\n                newconfig = hc.Selector().load(newconfig_file)\n\n                newgan = self.gan.config[\'class\'](config=newconfig, inputs=inputs)\n                newgan.args = gan.args\n                newgan.x_width = gan.x_width\n                newgan.x_height = gan.x_height\n                newgan.x_channels = gan.x_channels\n                newgan.cli = self.gan.cli\n                newgan.cli.sampler = None\n                gan.cli.sampler = None\n                newgan.trainer.sds = self.sds\n                newgan.trainer.sgs = self.sgs\n                newgan.train_coordinator = tf.train.Coordinator()\n                self.sds = None\n                self.sgs = None\n                self.ug = None\n                self.ud = None\n                for c in gan.components:\n                    c.gan = None\n                \n                def out(o):\n                    return str(type(o))\n                self.gan=None\n                gc.collect()\n                #for v in gc.get_referrers(gan):\n                #    try:\n                #        print(v.f_locals[\'self\'].__class__) \n                #    except AttributeError:\n                #        print(""!"", v) \n                #print(sys.getrefcount(gan), len(gc.get_referrers(gan)))\n\n                gan.destroy=True\n                gan.newgan=newgan\n                gan=None\n                gc.collect()\n                newgan.input_threads = tf.train.start_queue_runners(sess=newgan.session, coord=newgan.train_coordinator)\n                newgan.trainer.assign_gd(ug, ud)\n                return\n\n            self.assign_gd(ug, ud)\n\n            if self.config.mutate_child and np.random.rand() > (self.config.mutation_chance or 0.7):\n                print(""Mutating child"")\n                self.gan.session.run([self.mutate_d, self.mutate_g])\n\n            self.ug = gan.session.run(self.all_g_vars)\n            self.ud = gan.session.run(self.all_d_vars)\n            if self.current_step < (config.reset_before_step or 0):\n                gan.session.run(tf.global_variables_initializer())\n\n\n\n\n\n\n\n'"
hypergan/trainers/simultaneous_trainer.py,4,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass SimultaneousTrainer(BaseTrainer):\n    """""" Steps G and D simultaneously """"""\n    def _create(self):\n        gan = self.gan\n        config = self.config\n\n        if hasattr(self, \'loss\'):\n            loss = self.loss \n        else:\n            loss = self.gan.loss\n        d_loss, g_loss = loss.sample\n\n        self.d_log = -tf.log(tf.abs(d_loss+TINY))\n        config.optimizer[""loss""] = loss.sample\n\n        self.optimizer = self.gan.create_optimizer(config.optimizer)\n        d_vars = self.d_vars or self.gan.d_vars()\n        g_vars = self.g_vars or self.gan.g_vars()\n\n        d_grads = tf.gradients(d_loss, d_vars)\n        g_grads = tf.gradients(g_loss, g_vars)\n        apply_vec = list(zip((d_grads + g_grads), (d_vars + g_vars))).copy()\n        self.gan.gradient_mean = sum([tf.reduce_mean(tf.abs(grad)) for grad in d_grads+g_grads])/len(d_grads+g_grads)\n        self.g_loss = g_loss\n        self.d_loss = d_loss\n        self.gan.trainer = self\n\n        self.optimize_t = self.optimizer.apply_gradients(apply_vec, global_step=self.global_step)\n\n        return self.optimize_t, self.optimize_t\n\n    def required(self):\n        return """".split()\n\n    def _step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n        loss = gan.loss\n        metrics = gan.metrics()\n\n        d_loss, g_loss = loss.sample\n\n        self.before_step(self.current_step, feed_dict)\n        metric_values = sess.run([self.optimize_t] + self.output_variables(metrics), feed_dict)[1:]\n        self.after_step(self.current_step, feed_dict)\n\n        if self.current_step % 10 == 0:\n            print(str(self.output_string(metrics) % tuple([self.current_step] + metric_values)))\n\n'"
tests/discriminators/__init__.py,0,b''
tests/discriminators/autoencoder_discriminator_test.py,4,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nfrom hypergan.discriminators.pyramid_discriminator import PyramidDiscriminator\nfrom hypergan.discriminators.autoencoder_discriminator import AutoencoderDiscriminator\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.ops import TensorflowOps\nimport hypergan as hg\n\nfrom hypergan.gan_component import GANComponent\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import MockDiscriminator, mock_gan, MockInput\n\nfrom hypergan.discriminators.pyramid_discriminator import PyramidDiscriminator\nfrom hypergan.generators.resizable_generator import ResizableGenerator\n\nconfig = {\n        \'initial_depth\': 1,\n        \'activation\': tf.nn.tanh,\n        \'layers\': 3,\n        \'initial_depth\': 6,\n        \'depth_increase\' : 3,\n        \'block\' : hg.discriminators.common.standard_block,\n        \'distance\': \'l2_distance\',\n        \'encoder\': PyramidDiscriminator,\n        \'decoder\': ResizableGenerator\n\n        }\n\nclass AutoencoderDiscriminatorTest(tf.test.TestCase):\n    def test_config(self):\n        return None #disabled for now\n        with self.test_session():\n            gan = mock_gan()\n            discriminator = AutoencoderDiscriminator(gan, config)\n            self.assertEqual(discriminator.config.activation, tf.nn.tanh)\n\n    def test_create(self):\n        return None #disabled for now\n        with self.test_session():\n            remove_d_config = hg.Configuration.default()\n            remove_d_config[\'discriminator\'] = None\n            remove_d_config[\'loss\'] = None\n            remove_d_config[\'trainer\'] = None\n            gan = mock_gan(config = remove_d_config)\n            discriminator = AutoencoderDiscriminator(gan, config)\n            gan.encoder = gan.create_component(gan.config.encoder)\n            gan.generator = gan.create_component(gan.config.generator)\n            self.assertEqual(int(net.get_shape()[1]), 32)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/discriminators/cramer_discriminator_test.py,4,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nfrom hypergan.discriminators.cramer_discriminator import CramerDiscriminator\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.ops import TensorflowOps\nimport hypergan as hg\n\nfrom hypergan.gan_component import GANComponent\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import MockDiscriminator, mock_gan, MockInput\nconfig = {\n        \'initial_depth\': 1,\n        \'activation\': tf.nn.tanh,\n        \'layers\': 3,\n        \'depth_increase\' : 3,\n        \'block\' : hg.discriminators.common.standard_block\n        }\n\nclass CramerDiscriminatorTest(tf.test.TestCase):\n    def test_config(self):\n        return None # disable for now\n        with self.test_session():\n            gan = mock_gan()\n            discriminator = CramerDiscriminator(gan, config)\n            self.assertEqual(discriminator.config.activation, tf.nn.tanh)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/discriminators/pyramid_discriminator_test.py,4,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nfrom hypergan.discriminators.pyramid_discriminator import PyramidDiscriminator\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.ops import TensorflowOps\nimport hypergan as hg\n\nfrom hypergan.gan_component import GANComponent\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import MockDiscriminator, mock_gan, MockInput\n\nconfig = {\n        \'initial_depth\': 1,\n        \'activation\': tf.nn.tanh,\n        \'layers\': 3,\n        \'depth_increase\' : 3,\n        \'block\' : hg.discriminators.common.standard_block\n        }\n\nclass PyramidDiscriminatorTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            return None # disable for now\n            gan = mock_gan()\n            discriminator = PyramidDiscriminator(gan, config)\n            self.assertEqual(discriminator.config.activation, tf.nn.tanh)\n\n    def test_validate(self):\n        with self.assertRaises(ValidationException):\n            PyramidDiscriminator(hg.GAN(), {})\n        \nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/distributions/__init__.py,0,b''
tests/distributions/uniform_distribution_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport hypergan as hg\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.ops import TensorflowOps\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import MockDiscriminator, mock_gan\n\ngan = mock_gan()\ndistribution = UniformDistribution(gan, {\n    \'test\':True,\n    ""z"": 2,\n    ""min"": 0,\n    ""max"": 1\n})\nclass UniformDistributionTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            self.assertEqual(distribution.config.test, True)\n\n    def test_projection(self):\n        config = {\n                ""projections"": [hg.distributions.uniform_distribution.identity],\n                ""z"": 2,\n                ""min"": 0,\n                ""max"": 1\n                }\n        subject = UniformDistribution(gan, config)\n        with self.test_session():\n            projections = subject.create()\n            self.assertEqual(subject.ops.shape(projections)[1], 2)\n\n    def test_projection_twice(self):\n        config = {\n                ""projections"": [\'identity\', \'identity\'],\n                ""z"": 2,\n                ""min"": 0,\n                ""max"": 1\n                }\n        subject = UniformDistribution(gan, config)\n        with self.test_session():\n            projections = subject.create()\n            self.assertEqual(int(projections.get_shape()[1]), len(config[\'projections\'])*config[\'z\'])\n            \n    def test_projection_gaussian(self):\n        config = {\n                ""projections"": [\'identity\', \'gaussian\'],\n                ""z"": 2,\n                ""min"": 0,\n                ""max"": 1\n                }\n        subject = UniformDistribution(gan, config)\n        with self.test_session():\n            projections = subject.create()\n            self.assertEqual(int(projections.get_shape()[1]), len(config[\'projections\'])*config[\'z\'])\n \nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/gans/__init__.py,0,b''
tests/gans/base_gan_test.py,2,"b'from hypergan.discriminators.pyramid_discriminator import PyramidDiscriminator\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.ops import TensorflowOps\nfrom hypergan.search.default_configurations import DefaultConfigurations\n\nfrom hypergan.gans.base_gan import BaseGAN\nfrom hypergan.generators.resizable_generator import ResizableGenerator\nimport hypergan as hg\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nfrom hypergan.gan_component import ValidationException, GANComponent\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import MockDiscriminator, mock_gan, MockInput\n\ndefault_config = hg.Configuration.default()\n\nclass BaseGanTest(tf.test.TestCase):\n    def test_constructor(self):\n        with self.test_session():\n            gan = BaseGAN(inputs = MockInput())\n            self.assertNotEqual(gan.config.description, None)\n\n    # TODO: discuss `inputs` array as a map of hashes.  Uses first element in an unordered hash.\n    def test_has_input(self):\n        with self.test_session():\n            inputs = MockInput()\n            gan = BaseGAN(inputs = inputs)\n            self.assertEqual(gan.inputs.x, inputs.x)\n\n    def test_batch_size(self):\n        with self.test_session():\n            gan = BaseGAN(inputs = MockInput(batch_size = 1))\n            self.assertEqual(gan.batch_size(), 1)\n\n    def test_width(self):\n        with self.test_session():\n            gan = BaseGAN(inputs = MockInput())\n            self.assertEqual(gan.width(), 32)\n\n    def test_height(self):\n        with self.test_session():\n            gan = BaseGAN(inputs = MockInput())\n            self.assertEqual(gan.height(), 32)\n\n    def test_get_config_value(self):\n        with self.test_session():\n            gan = BaseGAN(inputs = MockInput())\n            self.assertEqual(type(gan.get_config_value(\'generator\')), hc.config.Config)\n            self.assertEqual(gan.get_config_value(\'missing\'), None)\n\n    def test_create_component(self):\n        with self.test_session():\n            gan = mock_gan()\n            distribution = gan.create_component(gan.config.latent)\n            self.assertEqual(type(distribution), hg.distributions.uniform_distribution.UniformDistribution)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/gans/standard_gan_test.py,2,"b'from hypergan.discriminators.pyramid_discriminator import PyramidDiscriminator\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.ops import TensorflowOps\nfrom hypergan.search.default_configurations import DefaultConfigurations\n\nfrom hypergan import GAN\nfrom hypergan.generators.resizable_generator import ResizableGenerator\nimport hypergan as hg\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import MockInput\n\ndefault_config = hg.Configuration.default()\n\nclass MockOps:\n    def __init__(self):\n        self.mock = True\n\nclass MockTrainer:\n    def __init__(self):\n        self.mock = True\n\n\nclass StandardGanTest(tf.test.TestCase):\n    def test_constructor(self):\n        with self.test_session():\n            mock_input = MockInput()\n            gan = GAN(inputs = mock_input, config = default_config)\n            self.assertEqual(gan.inputs.x, mock_input.x)\n\n    def test_fails_with_no_trainer(self):\n        trainer = MockTrainer()\n        bad_config = hg.Configuration.default()\n        bad_config[\'trainer\'] = None\n        gan = GAN(inputs = MockInput(), config = bad_config)\n        with self.assertRaises(ValidationException):\n            gan.step()\n\n    def test_validate(self):\n        with self.assertRaises(ValidationException):\n            gan = GAN(inputs = MockInput(), config = {})\n\n    def test_default(self):\n        with self.test_session():\n            gan = GAN(inputs = MockInput())\n            self.assertEqual(type(gan.generator), ResizableGenerator)\n\n    def test_train(self):\n        with self.test_session():\n            gan = GAN(inputs = MockInput())\n            gan.step()\n            self.assertEqual(gan.trainer.current_step, 1)\n\n    def test_train_updates_posterior(self):\n        with self.test_session():\n            gan = GAN(inputs = MockInput())\n            prior_g = gan.session.run(gan.generator.weights()[0])\n            prior_d = gan.session.run(gan.discriminator.weights()[0])\n            gan.step()\n            posterior_g = gan.session.run(gan.generator.weights()[0])\n            posterior_d = gan.session.run(gan.discriminator.weights()[0])\n            self.assertNotEqual(posterior_g.mean(), prior_g.mean())\n            self.assertNotEqual(posterior_d.mean(), prior_d.mean())\n\n\n    def test_overridable_components(self):\n        with self.test_session():\n            gan = GAN(inputs = MockInput())\n            gan.discriminator = ""d_override""\n            gan.generator = ""g_override""\n            gan.encoder = ""e_override""\n            gan.loss = ""l_override""\n            gan.trainer = ""t_override""\n\n\n            self.assertEqual(gan.discriminator, ""d_override"")\n            self.assertEqual(gan.generator, ""g_override"")\n            self.assertEqual(gan.encoder, ""e_override"")\n            self.assertEqual(gan.loss, ""l_override"")\n            self.assertEqual(gan.trainer, ""t_override"")\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/generators/__init__.py,0,b''
tests/generators/align_generator_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nfrom hypergan.generators.resizable_generator import ResizableGenerator\nfrom hypergan.ops import TensorflowOps\n\nfrom unittest.mock import MagicMock\n\nclass AlignGeneratorTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            pass\n\n    def test_create(self):\n        with self.test_session():\n            pass\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/generators/resizable_generator_test.py,4,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport hypergan as hg\nimport numpy as np\nfrom hypergan.generators.resizable_generator import ResizableGenerator\nfrom hypergan.ops import TensorflowOps\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import MockDiscriminator, mock_gan\n\nconfig = {\n    ""activation"": \'lrelu\',\n    \'final_activation\': \'tanh\',\n    \'depth_increase\': 4,\n    \'final_depth\': 4,\n    \'test\': True,\n    \'block\': hg.discriminators.common.standard_block\n}\n\nclass ResizableGeneratorTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            gan = mock_gan()\n            generator = ResizableGenerator(config=config, gan=gan, input=gan.latent.sample)\n            self.assertEqual(generator.config.test, True)\n\n    def test_initial_depth(self):\n        with self.test_session():\n            gan = mock_gan()\n            generator = ResizableGenerator(config=config, gan=gan, input=gan.latent.sample)\n            print(generator.depths())\n            depths = generator.depths()\n            self.assertEqual(depths[-1], 2)\n\n    def test_layer_norm(self):\n        with self.test_session():\n            gan = mock_gan()\n            config[\'layer_regularizer\'] = \'layer_norm\'\n            generator = ResizableGenerator(config=config, gan=gan, input=gan.latent.sample)\n            generator.layer_regularizer(tf.constant(1, shape=[1,1,1,1], dtype=tf.float32))\n            self.assertNotEqual(len(generator.variables()), 0)\n\n    def test_batch_norm(self):\n        with self.test_session():\n            config[\'layer_regularizer\'] = \'batch_norm\'\n            gan = mock_gan()\n            generator = ResizableGenerator(config=config, gan=gan, input=gan.latent.sample)\n            generator.layer_regularizer(tf.constant(1, shape=[1,1,1,1], dtype=tf.float32))\n            self.assertNotEqual(len(generator.variables()), 0)\n\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/inputs/__init__.py,0,b''
tests/inputs/image_loader_test.py,2,"b'import hypergan as hg\nimport tensorflow as tf\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.inputs.image_loader import ImageLoader\nimport os\n\ndef fixture_path(subpath=""""):\n    return os.path.dirname(os.path.realpath(__file__)) + \'/fixtures/\' + subpath\n\nclass ImageLoaderTest(tf.test.TestCase):\n    def test_constructor(self):\n        with self.test_session():\n            loader = ImageLoader(32)\n            self.assertEqual(loader.batch_size, 32)\n\n    def test_load_non_existent_path(self):\n        with self.assertRaises(ValidationException):\n            loader = ImageLoader(32)\n            loader.create(""/tmp/nonexistentpath"", format=\'png\')\n            \n    def test_load_fixture(self):\n        with self.test_session():\n            loader = ImageLoader(32)\n            x, y = loader.create(fixture_path(), width=4, height=4, format=\'png\')\n            self.assertEqual(y.get_shape(), [])\n            self.assertEqual(int(x.get_shape()[1]), 4)\n            self.assertEqual(int(x.get_shape()[2]), 4)\n\n    def test_load_fixture(self):\n        with self.test_session():\n            loader = ImageLoader(32) #TODO crop=true?\n            loader.create(fixture_path(), width=2, height=2, format=\'png\')\n            self.assertEqual(int(loader.x.get_shape()[1]), 2)\n            self.assertEqual(int(loader.x.get_shape()[2]), 2)\n\n\n    def test_load_fixture_resize(self):\n        with self.test_session():\n            loader = ImageLoader(32) #TODO crop=true?\n            loader.create(fixture_path(), width=8, height=8, resize=True, format=\'png\')\n            self.assertEqual(int(loader.x.get_shape()[1]), 8)\n            self.assertEqual(int(loader.x.get_shape()[2]), 8)\n\n\n    def test_load_fixture_single(self):\n        with self.test_session():\n            loader = ImageLoader(32) #TODO crop=true? why is this working\n            loader.create(fixture_path(\'images\'), width=4, height=4, format=\'png\')\n            self.assertEqual(int(loader.x.get_shape()[1]), 4)\n            self.assertEqual(int(loader.x.get_shape()[2]), 4)\n\n    def test_load_fixture_single(self):\n        with self.test_session():\n            loader = ImageLoader(32) #TODO crop=true?\n            loader.create(fixture_path(), width=4, height=4, format=\'png\')\n            self.assertEqual(loader.file_count, 2)\n\n    def test_load_fixture_single_count(self):\n        with self.test_session():\n            loader = ImageLoader(32) #TODO crop=true?\n            loader.create(fixture_path(\'white\'), width=4, height=4, format=\'png\')\n            self.assertEqual(loader.file_count, 1)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/losses/__init__.py,0,b''
tests/losses/boundary_equilibrium_loss_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport hypergan as hg\nimport numpy as np\nfrom hypergan.losses.boundary_equilibrium_loss import BoundaryEquilibriumLoss\nfrom hypergan.ops import TensorflowOps\n\nfrom tests.mocks import mock_gan\nfrom unittest.mock import MagicMock\nfrom tests.mocks import mock_gan\n\nloss_config = {\n        \'test\': True, \n        \'reduce\':\'reduce_mean\', \n        \'use_k\':True,\n        \'k_lambda\': 0.2,\n        \'gamma\': 0.1,\n        \'type\': \'wgan\',\n        \'initial_k\': 0.001,\n        \'labels\': [0,1,0]\n        }\nclass BoundaryEquilibriumLossTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            loss = BoundaryEquilibriumLoss(mock_gan(), loss_config)\n            self.assertTrue(loss.config.test)\n\n    def test_create(self):\n        with self.test_session():\n            gan = mock_gan()\n            loss = BoundaryEquilibriumLoss(gan, loss_config)\n            d_loss, g_loss = loss.create()\n            d_shape = gan.ops.shape(d_loss)\n            g_shape = gan.ops.shape(g_loss)\n            self.assertEqual(sum(d_shape), 0)\n            self.assertEqual(sum(g_shape), 0)\n\n    def test_metrics(self):\n        with self.test_session():\n            gan = mock_gan()\n            loss = BoundaryEquilibriumLoss(gan, loss_config)\n            d_loss, g_loss = loss.create()\n            metrics = loss.metrics\n            self.assertTrue(metrics[\'k\'] != None)\n\n\n\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/losses/category_loss_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport hypergan as hg\nimport numpy as np\nfrom hypergan.losses.category_loss import CategoryLoss\nfrom hypergan.ops import TensorflowOps\nfrom hypergan.multi_component import MultiComponent\n\n\nfrom tests.mocks import MockDiscriminator, mock_gan\nfrom unittest.mock import MagicMock\n\nclass CategoryLossTest(tf.test.TestCase):\n\n    def test_config(self):\n        pass\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/losses/cramer_loss_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport hypergan as hg\nimport numpy as np\nfrom hypergan.losses.cramer_loss import CramerLoss\nfrom hypergan.ops import TensorflowOps\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import mock_gan\nfrom tests.mocks import MockDiscriminator, mock_gan, MockInput\n\nloss_config = {\'test\': True, \'reduce\':\'reduce_mean\', \'labels\': [0,1,0]}\nclass CramerLossTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            gan = mock_gan()\n            loss = CramerLoss(gan, loss_config)\n            self.assertTrue(loss.config.test)\n\n    def test_create(self):\n        with self.test_session():\n            gan = mock_gan()\n            loss = CramerLoss(gan, loss_config)\n            d_loss, g_loss = loss.create()\n            d_shape = gan.ops.shape(d_loss)\n            g_shape = gan.ops.shape(g_loss)\n            self.assertEqual(sum(d_shape), 0)\n            self.assertEqual(sum(g_shape), 0)\n\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/losses/lamb_gan_loss_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport hypergan as hg\nimport numpy as np\nfrom hypergan.losses.lamb_gan_loss import LambGanLoss\nfrom hypergan.ops import TensorflowOps\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import mock_gan\n\nloss_config = {\'test\': True, \'reduce\':\'reduce_mean\', \'labels\': [0,1,0], \'label_smooth\': 0.3, \'alpha\': 0.2, \'beta\': 0.1}\nclass LambGanLossTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            loss = LambGanLoss(mock_gan(), loss_config)\n            self.assertTrue(loss.config.test)\n\n    def test_create(self):\n        with self.test_session():\n            gan = mock_gan()\n            loss = LambGanLoss(gan, loss_config)\n            d_loss, g_loss = loss.create()\n            d_shape = gan.ops.shape(d_loss)\n            g_shape = gan.ops.shape(g_loss)\n            self.assertEqual(d_shape, [])\n            self.assertEqual(g_shape, [])\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/losses/least_squares_loss_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport hypergan as hg\nimport numpy as np\nfrom hypergan.losses.least_squares_loss import LeastSquaresLoss\nfrom hypergan.ops import TensorflowOps\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import mock_gan\n\nloss_config = {\'test\': True, \'reduce\':\'reduce_mean\', \'labels\': [0,1,0]}\nclass LeastSquaresLossTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            loss = LeastSquaresLoss(mock_gan(), loss_config)\n            self.assertTrue(loss.config.test)\n\n    def test_create(self):\n        with self.test_session():\n            gan = mock_gan()\n            loss = LeastSquaresLoss(gan, loss_config)\n            d_loss, g_loss = loss.create()\n            d_shape = gan.ops.shape(d_loss)\n            g_shape = gan.ops.shape(g_loss)\n            self.assertEqual(sum(d_shape), 0)\n            self.assertEqual(sum(g_shape), 0)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/losses/softmax_loss_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport hypergan as hg\nimport numpy as np\nfrom hypergan.losses.softmax_loss import SoftmaxLoss\nfrom hypergan.ops import TensorflowOps\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import mock_gan\nloss_config = {\'test\': True, \'reduce\':\'reduce_mean\', \'labels\': [0,1,0]}\nclass SoftmaxLossTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            gan = mock_gan()\n            loss = SoftmaxLoss(gan, loss_config)\n            self.assertTrue(loss.config.test)\n\n    def test_create(self):\n        with self.test_session():\n            gan = mock_gan()\n            loss = SoftmaxLoss(gan, loss_config)\n            d_loss, g_loss = loss.create()\n            d_shape = gan.ops.shape(d_loss)\n            g_shape = gan.ops.shape(g_loss)\n            self.assertEqual(sum(d_shape), 0)\n            self.assertEqual(sum(g_shape), 0)\n\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/losses/standard_gan_loss_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport hypergan as hg\nimport numpy as np\nfrom hypergan.discriminators.pyramid_discriminator import PyramidDiscriminator\nfrom hypergan.ops import TensorflowOps\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import mock_gan\n\nfrom hypergan.losses.standard_loss import StandardLoss\n\nloss_config = {\'test\': True, \'reduce\':\'reduce_mean\', \'labels\': [0,1,0],\n        \'label_smooth\': 0.4, \'alpha\': 0.3, \'beta\': 0.2}\nclass StandardGanLossTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            loss = StandardLoss(mock_gan(), loss_config)\n            self.assertTrue(loss.config.test)\n\n    def test_create(self):\n        with self.test_session():\n            gan = mock_gan()\n\n            loss = StandardLoss(gan, loss_config)\n            d_loss, g_loss = loss.create()\n            d_shape = gan.ops.shape(d_loss)\n            g_shape = gan.ops.shape(g_loss)\n            self.assertEqual(d_shape, [])\n            self.assertEqual(g_shape, [])\n\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/losses/supervised_loss_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport hypergan as hg\nimport numpy as np\nfrom hypergan.losses.supervised_loss import SupervisedLoss\nfrom hypergan.ops import TensorflowOps\n\nfrom tests.mocks import mock_gan\nfrom unittest.mock import MagicMock\n\nloss_config = {\'test\': True, \'reduce\':\'reduce_mean\', \'labels\': [0,1,0]}\nclass SupervisedLossTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            loss = SupervisedLoss(mock_gan(), loss_config)\n            self.assertTrue(loss.config.test)\n\n    def test_create(self):\n        with self.test_session():\n            gan = mock_gan()\n            loss = SupervisedLoss(gan, loss_config)\n            d_loss, g_loss = loss.create()\n            d_shape = gan.ops.shape(d_loss)\n            self.assertEqual(d_shape, [1])\n            self.assertEqual(g_loss, None)\n\n    def test_metric(self):\n        with self.test_session():\n            gan = mock_gan()\n            loss = SupervisedLoss(gan, loss_config)\n            d_loss, g_loss = loss.create()\n            metrics = loss.metrics\n            self.assertTrue(metrics[\'d_class_loss\'] != None)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/losses/wasserstein_loss_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport hypergan as hg\nimport numpy as np\nfrom hypergan.losses.least_squares_loss import LeastSquaresLoss\nfrom hypergan.losses.wasserstein_loss import WassersteinLoss\nfrom hypergan.ops import TensorflowOps\n\nfrom unittest.mock import MagicMock\nfrom tests.mocks import mock_gan\n\nloss_config = {\'test\': True, \'reduce\':\'reduce_mean\', \'labels\': [0,1,0]}\nclass WassersteinLossTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            loss = WassersteinLoss(mock_gan(), loss_config)\n            self.assertTrue(loss.config.test)\n\n    def test_create(self):\n        with self.test_session():\n            gan = mock_gan()\n\n            loss = WassersteinLoss(gan, loss_config)\n            d_loss, g_loss = loss.create()\n            d_shape = gan.ops.shape(d_loss)\n            g_shape = gan.ops.shape(g_loss)\n            self.assertEqual(sum(d_shape), 0)\n            self.assertEqual(sum(g_shape), 0)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/samplers/__init__.py,0,b''
tests/samplers/batch_sampler_test.py,2,"b'import tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\n\nfrom hypergan.samplers.batch_sampler import BatchSampler\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.ops import TensorflowOps\nfrom tests.mocks import mock_gan\n\nclass BatchSamplerTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            gan = mock_gan()\n\n            sampler = BatchSampler(gan)\n            self.assertEqual(sampler._sample()[\'generator\'].shape[-1], 1)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/samplers/grid_sampler_test.py,2,"b'import tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\n\nfrom hypergan.samplers.grid_sampler import GridSampler\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.ops import TensorflowOps\nfrom tests.mocks import mock_gan\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\n\nclass GridSamplerTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            gan = mock_gan(batch_size=32)\n            gan.latent = UniformDistribution(gan, {\'z\':2, \'min\': -1, \'max\': 1, \'projections\':[\'identity\']})\n\n            sampler = GridSampler(gan)\n            self.assertEqual(sampler._sample()[\'generator\'].shape[-1], 1)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/samplers/static_batch_sampler_test.py,2,"b'import tensorflow as tf\nimport hypergan as hg\nimport hyperchamber as hc\nimport numpy as np\n\nfrom hypergan.samplers.static_batch_sampler import StaticBatchSampler\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.ops import TensorflowOps\nfrom tests.mocks import mock_gan\n\nclass StaticBatchSamplerTest(tf.test.TestCase):\n    def test_sample(self):\n        with self.test_session():\n            gan = mock_gan()\n\n            sampler = StaticBatchSampler(gan)\n            self.assertEqual(sampler._sample()[\'generator\'].shape[-1], 1)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/search/random_search_test.py,2,"b'import hypergan as hg\nimport hyperchamber as hc\nimport tensorflow as tf\nimport os\nfrom hypergan.search.random_search import RandomSearch\n\nfrom tests.inputs.image_loader_test import fixture_path\nfrom tests.mocks import MockDiscriminator, mock_gan\nimport shutil\n\n\nclass RandomSearchTest(tf.test.TestCase):\n    def test_overrides(self):\n        rs = RandomSearch({""trainer"": ""test""})\n        self.assertEqual(\'test\', rs.options[\'trainer\'])\n\n    def test_range(self):\n        rs = RandomSearch({})\n        self.assertTrue(isinstance(rs.range(), list))\n\n    def test_trainers(self):\n        rs = RandomSearch({})\n        self.assertTrue(rs.trainer()[""class""] != None)\n\n    def test_random_config(self):\n        rs = RandomSearch({})\n        self.assertTrue(rs.random_config()[\'trainer\'][""class""] != None)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/trainers/alternating_trainer_test.py,3,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport hypergan as hg\nimport numpy as np\nfrom hypergan.discriminators.pyramid_discriminator import PyramidDiscriminator\nfrom hypergan.gan_component import ValidationException\nfrom hypergan.ops import TensorflowOps\nfrom tests.mocks import MockDiscriminator, mock_gan\n\nfrom unittest.mock import MagicMock\n\nfrom hypergan.trainers.alternating_trainer import AlternatingTrainer\n\nclass AlternatingTrainerTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            config = {\'d_learn_rate\': 1e-3, \'g_learn_rate\': 1e-3, \'d_trainer\': \'rmsprop\', \'g_trainer\': \'adam\'}\n            gan = mock_gan()\n            trainer = AlternatingTrainer(gan, config)\n            self.assertEqual(trainer.config.d_learn_rate, 1e-3)\n\n    def test_validate(self):\n        with self.assertRaises(ValidationException):\n            gan = mock_gan()\n            AlternatingTrainer(gan, {})\n\n    def test_clip(self):\n        with self.test_session():\n\n            #trainer.create()\n            #self.assertEqual(gan.graph.clip, None)\n            pass\n\n    def test_output_string(self):\n        with self.test_session():\n            gan = mock_gan()\n            config = {\'d_learn_rate\': 1e-3, \'g_learn_rate\': 1e-3, \'d_trainer\': \'rmsprop\', \'g_trainer\': \'adam\'}\n            trainer = AlternatingTrainer(gan, config)\n            c = tf.constant(1)\n            self.assertTrue(\'d_loss\' in trainer.output_string({\'d_loss\':c}))\n            self.assertTrue(\'g_loss\' in trainer.output_string({\'g_loss\':c}))\n            self.assertEqual(len(trainer.output_variables({\'a\': c, \'b\': c})), 2)\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
tests/trainers/proportional_trainer_test.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nfrom hypergan.discriminators.pyramid_discriminator import PyramidDiscriminator\nfrom hypergan.ops import TensorflowOps\n\nfrom unittest.mock import MagicMock\n\nfrom hypergan.trainers.proportional_control_trainer import ProportionalControlTrainer\n\nclass ProportionalTrainerTest(tf.test.TestCase):\n    def test_config(self):\n        with self.test_session():\n            #trainer = ProportionalControlTrainer()\n            #self.assertEqual(trainer.config.d_learn_rate, 1e-3)\n            pass\n\n    def test_step(self):\n        with self.test_session():\n            #trainer = ProportionalControlTrainer()\n            #self.assertEqual(trainer.step(), [1, 1])\n            pass\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
hypergan/discriminators/experimental/autoencoder_discriminator.py,0,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport os\nimport hypergan\nfrom hypergan.discriminators.common import *\n\nfrom hypergan.discriminators.pyramid_discriminator import PyramidDiscriminator\nfrom ..base_discriminator import BaseDiscriminator\n\nclass AutoencoderDiscriminator(BaseDiscriminator):\n\n    def build(self, net):\n        config = self.config\n        gan = self.gan\n        ops = self.ops\n\n        generator = config.decoder(gan, gan.config.generator)\n        generator.ops = ops # share variable allocation to make variables part of the discriminator training step\n\n        encoder = config.encoder(gan, config)\n        encoder.ops = ops\n        ops.describe(ops.description+""autoencoder-d"")\n        hidden = encoder.build(net)\n        ops.describe(ops.description+""autoencoder-g"")\n        reconstruction = generator.build(hidden)\n        print(""[autoencoder discriminator] hidden layer "", hidden)\n\n        error = config.distance(net, reconstruction)\n\n        self.reconstruction = reconstruction\n\n        return error\n\n\n'"
hypergan/discriminators/experimental/cramer_discriminator.py,2,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport os\nimport hypergan\nfrom hypergan.discriminators.common import *\n\nfrom hypergan.discriminators.dcgan_discriminator import DCGANDiscriminator\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom ..base_discriminator import BaseDiscriminator\n\nclass CramerDiscriminator(BaseDiscriminator):\n\n    def build(self, net):\n        config = self.config\n        gan = self.gan\n        ops = self.ops\n\n        discriminator = DCGANDiscriminator(gan, config)\n        discriminator.ops = ops\n        encoder = UniformDistribution(gan, gan.config.encoder)\n\n        # careful, this order matters\n        g2 = gan.generator.reuse(encoder.create())\n        double = tf.concat([net] + [g2, g2], axis=0)\n        original = discriminator.build(double)\n        d1 = self.split_batch(original, 4)\n\n        dg = ops.concat([d1[2], d1[3]], axis=0) # xs for baseline\n\n        #dx is a sampling of x twice\n        dx = ops.concat([d1[0], d1[0]], axis=0) # xs for baseline\n\n        xinput = ops.concat([d1[0], d1[1]], axis=0)\n\n        #dg  is a sampling of g twice\n\n        # net is [x,g] (stacked)\n        error = self.f(xinput, dx, dg)\n        return error\n\n    # this is from the paper\n    def f(self, net, dx, dg):\n        # Note: this is currently not working that well. we might need a second sample of X \n\n        return tf.norm(net - dg, axis=1) - tf.norm(dx, axis=1)\n'"
hypergan/discriminators/experimental/fully_connected_discriminator.py,0,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport os\nimport hypergan\nfrom hypergan.discriminators.common import *\n\nfrom hypergan.discriminators.experimental.pyramid_discriminator import PyramidDiscriminator\nfrom ..base_discriminator import BaseDiscriminator\n\nclass FullyConnectedDiscriminator(BaseDiscriminator):\n    def build(self, net):\n        config = self.config\n        gan = self.gan\n        ops = self.ops\n        activation = ops.lookup(config.activation or \'lrelu\')\n        final_activation = ops.lookup(config.final_activation or None)\n\n        net = ops.reshape(net, [ops.shape(net)[0], -1])\n\n        print(""[fully connected discriminator] creating FC layer from "", net)\n        net = ops.linear(net, config.features or ops.shape(net)[-1])\n        for i in range(config.layers or 1):\n            net = self.layer_regularizer(net)\n            net = activation(net)\n            net = ops.linear(net, config.features or ops.shape(net)[-1])\n\n        if final_activation:\n            net = self.layer_regularizer(net)\n            net = final_activation(net)\n\n        self.sample = net\n\n        return net\n\n'"
hypergan/discriminators/experimental/multi_discriminator.py,0,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\n\nfrom hypergan.discriminators.base_discriminator import BaseDiscriminator\nfrom hypergan.multi_component import MultiComponent\n\nTINY=1e-8\nclass MultiDiscriminator(BaseDiscriminator):\n\n    def __init__(self, gan, config, **kwargs):\n        self.kwargs = kwargs\n        kwargs = hc.Config(kwargs)\n        BaseDiscriminator.__init__(self, gan, config, name=kwargs.name, input=kwargs.input,reuse=kwargs.reuse, x=kwargs.x, g=kwargs.g)\n\n    """"""Takes multiple distributions and does an additional approximator""""""\n    def build(self, net):\n        gan = self.gan\n        config = self.config\n        self.d_variables = []\n\n        discs = []\n        self.kwargs[""input""]=net\n        self.kwargs[""reuse""]=self.ops._reuse\n        for i in range(config.discriminator_count or 0):\n            name=self.ops.description+""_d_""+str(i)\n            self.kwargs[""name""]=name\n            print("">>CREATING "", i)\n            disc = config[\'discriminator_class\'](gan, config, **self.kwargs)\n            self.ops.add_weights(disc.variables())\n            self.d_variables += [disc.variables()]\n\n            discs.append(disc)\n\n        for i,dconfig in enumerate(config.discriminators):\n            name=self.ops.description+""_d_""+str(i)\n            self.kwargs[""name""]=name\n            disc = dconfig[\'class\'](gan, dconfig, **self.kwargs)\n\n            self.ops.add_weights(disc.variables())\n            self.d_variables += [disc.variables()]\n            discs.append(disc)\n\n        combine = MultiComponent(combine=self.config.combine or ""concat"", components=discs)\n        self.sample = combine.sample\n        self.children = discs\n        return self.sample\n\n\n'"
hypergan/discriminators/experimental/pyramid_discriminator.py,1,"b'import tensorflow as tf\nimport hyperchamber as hc\nimport inspect\nimport os\n\nfrom ..base_discriminator import BaseDiscriminator\n\nclass PyramidDiscriminator(BaseDiscriminator):\n\n    def required(self):\n        return ""activation layers block depth_increase initial_depth"".split()\n\n    def build(self, net):\n        config = self.config\n        gan = self.gan\n        ops = self.ops\n\n        layers = config.layers\n        depth_increase = config.depth_increase\n        activation = ops.lookup(config.activation)\n        final_activation = ops.lookup(config.final_activation)\n        total_layers = layers + (config.extra_layers or 0)\n        padding = config.padding or ""SAME""\n\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n\n        net = self.add_noise(net)\n\n        if config.progressive_growing:\n            stacks = ops.shape(net)[0] // gan.batch_size()\n            print(""Adding progressive growing mask zero"", len(pe_layers)//(stacks-1))\n            net *= self.progressive_growing_mask(len(pe_layers)//(stacks-1)) # handle batch stacking\n\n        if layers > 0:\n            initial_depth = max(ops.shape(net)[3], config.initial_depth or 64)\n\n            net = config.block(self, net, initial_depth, filter=config.initial_filter or 3, padding=padding)\n        for i in range(layers):\n            is_last_layer = (i == layers-1)\n            filters = ops.shape(net)[3]\n            net = activation(net)\n            net = self.layer_regularizer(net)\n\n            if config.skip_layer_filters and (i+1) in config.skip_layer_filters:\n                pass\n            else:\n                net = self.layer_filter(net, layer=i)\n                print(""[hypergan] adding layer filter"", net)\n\n            depth = filters + depth_increase\n            net = config.block(self, net, depth, filter=config.filter or 3, padding=padding)\n            net = self.normalize(net)\n\n            print(\'[discriminator] layer\', net)\n\n        for i in range(config.extra_layers or 0):\n            output_features = int(int(net.get_shape()[3]))\n            net = activation(net)\n            net = self.layer_regularizer(net)\n            filter_size_w = min(3, ops.shape(net)[1])\n            filter_size_h = min(3, ops.shape(net)[2])\n            if padding == ""VALID"":\n                filters = ops.shape(net)[3]\n                depth = filters + depth_increase\n                net = ops.conv2d(net, filter_size_w, filter_size_h, 1, 1, depth, padding=padding)\n                print(""depth"", depth)\n            else:\n                net = ops.conv2d(net, filter_size_w, filter_size_h, 1, 1, output_features//(config.extra_layers_reduction or 1), padding=padding)\n            #net = self.normalize(net)\n            print(\'[discriminator] extra layer\', net)\n        k=-1\n\n        if config.relation_layer:\n            net = activation(net) \n            net = self.layer_regularizer(net) \n            net = self.relation_layer(net)\n\n        #net = tf.reshape(net, [ops.shape(net)[0], -1])\n\n\n        for i in range(config.fc_layers or 0):\n            # if no layers, project with linear first\n            if total_layers > 0:\n                net = activation(net)\n                net = self.layer_regularizer(net)\n            net = ops.reshape(net, [ops.shape(net)[0], -1])\n            net = ops.linear(net, config.fc_layer_size or 300)\n\n        if final_activation:\n            net = self.layer_regularizer(net)\n            net = final_activation(net)\n\n        print(""[discriminator] output"", net)\n\n        return net\n'"
hypergan/gans/experimental/ali_gan_combined.py,19,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass AliGANCombined(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `encoder`  encodes X into Z\n        `discriminator`  measures X and G.\n        `generator` produces samples\n        """"""\n        return ""generator discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n        d_losses = []\n        g_losses = []\n\n        def random_like(x):\n            return UniformDistribution(self, config.z_distribution, output_shape=self.ops.shape(x)).sample\n        with tf.device(self.device):\n            x_input = tf.identity(self.inputs.x, name=\'input\')\n\n            # q(z|x)\n            if config.u_to_z:\n                UniformDistribution = UniformDistribution(self, config.z_distribution)\n            else:\n                z_shape = self.ops.shape(encoder.sample)\n                uz_shape = z_shape\n                uz_shape[-1] = uz_shape[-1] // len(config.z_distribution.projections)\n                UniformDistribution = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n            self.uniform_distribution = uniform_encoder\n \n            direction, slider = self.create_controls(self.ops.shape(UniformDistribution.sample))\n            z = UniformDistribution.sample + slider * direction\n            \n            #projected_encoder = UniformDistribution(self, config.encoder, z=encoder.sample)\n\n\n            feature_dim = len(ops.shape(z))-1\n            #stack_z = tf.concat([encoder.sample, z], feature_dim)\n            #stack_encoded = tf.concat([encoder.sample, encoder.sample], feature_dim)\n            stack_z = z\n\n            u_to_z = self.create_component(config.u_to_z, name=\'u_to_z\', input=z)\n            generator = self.create_component(config.generator, input=u_to_z.sample, name=\'generator\')\n            stacked = [x_input, generator.sample]\n            self.generator = generator\n\n            encoder = self.create_encoder(self.inputs.x)\n\n            self.encoder = encoder\n            features = [encoder.sample, u_to_z.sample]\n\n            reencode_u_to_z = self.create_encoder(generator.sample, reuse=True)\n            print(""GEN SAMPLE"", generator.sample, reencode_u_to_z.sample, u_to_z.sample)\n            reencode_u_to_z_to_g= self.create_component(config.generator, input=reencode_u_to_z.sample, name=\'generator\', reuse=True)\n            stacked += [reencode_u_to_z_to_g.sample]\n            features += [reencode_u_to_z.sample]\n\n            x_hat = self.create_component(config.generator, input=encoder.sample, reuse=True, name=\'generator\').sample\n            self.uniform_sample = generator.sample\n\n            stacked_xg = tf.concat(stacked, axis=0)\n            features_zs = tf.concat(features, axis=0)\n\n\n            standard_discriminator = self.create_component(config.discriminator, name=\'discriminator\', input=stacked_xg, features=[features_zs])\n            self.discriminator = standard_discriminator\n            d_vars = standard_discriminator.variables()\n            g_vars = generator.variables() + encoder.variables()\n            g_vars += u_to_z.variables()\n\n\n\n            self._g_vars = g_vars\n            self._d_vars = d_vars\n            standard_loss = self.create_loss(config.loss, standard_discriminator, x_input, generator, len(stacked))\n            if self.gan.config.infogan:\n                d_vars += self.gan.infogan_q.variables()\n\n            loss1 = [""g_loss"", standard_loss.g_loss]\n            loss2 = [""d_loss"", standard_loss.d_loss]\n\n            d_losses.append(standard_loss.d_loss)\n            g_losses.append(standard_loss.g_loss)\n            if self.config.autoencode:\n                l2_loss = self.ops.squash(10*tf.square(x_hat - x_input))\n                g_losses=[l2_loss]\n                d_losses=[l2_loss]\n\n            for i,l in enumerate(g_losses):\n                self.add_metric(\'gl\'+str(i),l)\n            for i,l in enumerate(d_losses):\n                self.add_metric(\'dl\'+str(i),l)\n            loss = hc.Config({\n                \'d_fake\':standard_loss.d_fake,\n                \'d_real\':standard_loss.d_real,\n                \'sample\': [tf.add_n(d_losses), tf.add_n(g_losses)]\n            })\n            self.loss = loss\n            self.uniform_distribution = uniform_encoder\n            trainer = self.create_component(config.trainer, loss = loss, g_vars = g_vars, d_vars = d_vars)\n\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = generator\n        self.slider = slider\n        self.direction = direction\n        self.z = z\n        self.z_hat = encoder.sample\n        self.x_input = x_input\n        self.autoencoded_x = x_hat\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n        self.random_z = tf.random_uniform(ops.shape(UniformDistribution.sample), -1, 1, name=\'random_z\')\n\n        if hasattr(generator, \'mask_generator\'):\n            self.mask_generator = generator.mask_generator\n            self.mask = mask\n            self.autoencode_mask = generator.mask_generator.sample\n            self.autoencode_mask_3_channel = generator.mask\n\n\n\n    def fitness_inputs(self):\n        return [\n                self.uniform_distribution.sample\n                ]\n\n\n    def create_loss(self, loss_config, discriminator, x, generator, split, reuse=False):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator.sample, split=split, reuse=reuse)\n        return loss\n\n    def create_controls(self, z_shape):\n        direction = tf.random_normal(z_shape, stddev=0.3, name=\'direction\')\n        slider = tf.get_variable(\'slider\', initializer=tf.constant_initializer(0.0), shape=[1, 1], dtype=tf.float32, trainable=False)\n        return direction, slider\n\n    def create_encoder(self, x_input, name=\'encoder\', reuse=False):\n        config = self.config\n        encoder = dict(config.encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(encoder, name=name, input=x_input, reuse=reuse)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input,\n                self.slider, \n                self.direction,\n                self.uniform_distribution.sample\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int,\n                self.random_z\n        ]\n\n    def g_vars(self):\n        return self._g_vars\n    def d_vars(self):\n        return self._d_vars\n'"
hypergan/gans/experimental/ali_style_gan.py,17,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass AliStyleGAN(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `input_encoder` is a discriminator.  It encodes X into Z\n        `discriminator` is a standard discriminator.  It measures X, reconstruction of X, and G.\n        `generator` produces two samples, input_encoder output and a known random distribution.\n        """"""\n        return ""generator discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n\n        with tf.device(self.device):\n            x_input = tf.identity(self.inputs.x, name=\'input\')\n\n            def random_like(x):\n                return UniformDistribution(self, config.z_distribution, output_shape=self.ops.shape(x)).sample\n            # q(z|x)\n            encoder = self.create_component(config.encoder, input=x_input, name=\'z_encoder\')\n            print(""ENCODER "", encoder.sample)\n\n            self.encoder = encoder\n            z_shape = self.ops.shape(encoder.sample)\n            style = self.create_component(config.style_encoder, input=x_input, name=\'style\')\n            self.style = style\n            self.styleb = style # hack for sampler\n            self.random_style = random_like(style.sample)\n\n            uz_shape = z_shape\n            uz_shape[-1] = uz_shape[-1] // len(config.z_distribution.projections)\n            UniformDistribution = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n            direction, slider = self.create_controls(self.ops.shape(UniformDistribution.sample))\n            z = UniformDistribution.sample + slider * direction\n            \n            #projected_encoder = UniformDistribution(self, config.encoder, z=encoder.sample)\n\n\n            feature_dim = len(ops.shape(z))-1\n            #stack_z = tf.concat([encoder.sample, z], feature_dim)\n            #stack_encoded = tf.concat([encoder.sample, encoder.sample], feature_dim)\n            stack_z = z\n\n            generator = self.create_component(config.generator, input=stack_z, features=[style.sample])\n            self.uniform_sample = generator.sample\n            x_hat = generator.reuse(encoder.sample)\n\n            features_zs = ops.concat([encoder.sample, z], axis=0)\n            stacked_xg = ops.concat([x_input, generator.sample], axis=0)\n\n            if config.u_to_z:\n                u_to_z = self.create_component(config.u_to_z, name=\'u_to_z\', input=random_like(z))\n                gu = generator.reuse(u_to_z.sample)\n                stacked_xg = ops.concat([x_input, gu], axis=0)\n                features_zs = ops.concat([encoder.sample, u_to_z.sample], axis=0)\n\n\n            standard_discriminator = self.create_component(config.discriminator, name=\'discriminator\', input=stacked_xg, features=[features_zs])\n            standard_loss = self.create_loss(config.loss, standard_discriminator, x_input, generator, 2)\n\n            l = standard_loss\n            d_loss1 = l.d_loss\n            g_loss1 = l.g_loss\n\n            d_vars1 = standard_discriminator.variables()\n            g_vars1 = generator.variables()+encoder.variables()+style.variables()\n\n\n            metrics = {\n                    \'g_loss\': l.g_loss,\n                    \'d_loss\': l.d_loss\n                }\n            t0 = random_like(style.sample)#tf.concat([random_like(style1), random_like(style1)], axis=1)\n            t1 = style.sample#tf.concat([style1, style2], axis=1)\n            stack = [t0,t1]\n            stacked = ops.concat(stack, axis=0)\n            features = None\n            z_d = self.create_component(config.z_discriminator, name=\'forcerandom_discriminator\', input=stacked)\n            loss3 = self.create_component(config.loss, discriminator = z_d, x=x_input, generator=generator, split=2)\n            metrics[""forcerandom_gloss""]=loss3.g_loss\n            metrics[""forcerandom_dloss""]=loss3.d_loss\n            if config.forcerandom:\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n                d_vars1 += z_d.variables()\n\n            if config.u_to_z:\n                g_vars1 += u_to_z.variables()\n\n            lossa = hc.Config({\'sample\': [d_loss1, g_loss1], \'metrics\': metrics})\n            trainer = ConsensusTrainer(self, config.trainer, loss = lossa, g_vars = g_vars1, d_vars = d_vars1)\n\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = generator\n        self.uniform_distribution = uniform_encoder\n        self.slider = slider\n        self.direction = direction\n        self.z = z\n        self.z_hat = encoder.sample\n        self.x_input = x_input\n        self.autoencoded_x = x_hat\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n        self.random_z = tf.random_uniform(ops.shape(UniformDistribution.sample), -1, 1, name=\'random_z\')\n\n        if hasattr(generator, \'mask_generator\'):\n            self.mask_generator = generator.mask_generator\n            self.mask = mask\n            self.autoencode_mask = generator.mask_generator.sample\n            self.autoencode_mask_3_channel = generator.mask\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator.sample, split=split)\n        return loss\n\n    def create_controls(self, z_shape):\n        direction = tf.random_normal(z_shape, stddev=0.3, name=\'direction\')\n        slider = tf.get_variable(\'slider\', initializer=tf.constant_initializer(0.0), shape=[1, 1], dtype=tf.float32, trainable=False)\n        return direction, slider\n\n    def create_encoder(self, x_input, name=\'input_encoder\'):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def create_trainer(self, cycloss, z_cycloss, encoder, generator, encoder_loss, standard_loss, standard_discriminator, encoder_discriminator):\n\n        metrics = []\n        metrics.append(standard_loss.metrics)\n\n        d_vars = standard_discriminator.variables()\n        g_vars = generator.variables() + encoder.variables()\n        print(""D_VARS"", d_vars)\n        print(""G_VARS"", g_vars)\n        #d_loss = standard_loss.d_loss\n        #g_loss = standard_loss.g_loss + cycloss\n        loss1 = (""g_loss"", standard_loss.g_loss)\n        loss2 = (""d_loss"", standard_loss.d_loss)\n        loss = hc.Config({\'sample\': [standard_loss.d_loss, standard_loss.g_loss], \'metrics\': \n            {\'g_loss\': loss1[1], \'d_loss\': loss2[1]}})\n        trainer = ConsensusTrainer(self, self.config.trainer, loss = loss, g_vars = g_vars, d_vars = d_vars)\n        return trainer\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input,\n                self.slider, \n                self.direction,\n                self.uniform_distribution.sample\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int,\n                self.random_z\n        ]\n'"
hypergan/gans/experimental/ali_vib_gan.py,22,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass AliVibGAN(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `encoder`  encodes X into Z\n        `discriminator`  measures X and G.\n        `generator` produces samples\n        """"""\n        return ""generator discriminator "".split()\n    def bottleneck(self, metric, name, term1, term2):\n        dvs = []\n        _inputs = term1\n        inputs = tf.concat(term2, axis=0)\n        features = None\n        bdisc = self.create_component(config[name+\'1\'], name=name+\'1\', input=inputs, features=[features])\n        dvs += bdisc.variables()\n        l2 = self.create_loss(config.loss, bdisc, None, None, len(_inputs))\n        self.add_metric(metric+\'_dl1\', l2.d_loss)\n        self.add_metric(metric+\'_gl1\', l2.g_loss)\n        dl= ib_1_c * l2.d_loss\n        gl=ib_1_c * l2.g_loss\n\n        beta = config.bottleneck_beta or 1\n        _features = term2\n        inputs = tf.concat(_inputs, axis=0)\n        features = tf.concat(_features, axis=0)\n        bdisc2 = self.create_component(config[name+\'2\'], name=name+\'2\', input=inputs, features=[features])\n        dvs += bdisc2.variables()\n        l2 = self.create_loss(config.loss, bdisc2, None, None, len(_inputs))\n        self.add_metric(metric+\'_dl2\',  ib_2_c * beta * l2.d_loss)\n        self.add_metric(metric+\'_gl2\',  ib_2_c * beta * l2.g_loss)\n        dl += ib_2_c * beta * l2.d_loss\n        gl += ib_2_c * beta * l2.g_loss\n        return gl, dl, dvs\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n        d_losses = []\n        g_losses = []\n        encoder = self.create_encoder(self.inputs.x)\n\n        with tf.device(self.device):\n            x_input = tf.identity(self.inputs.x, name=\'input\')\n\n            if config.u_to_z:\n                latent = UniformDistribution(self, config.latent)\n            else:\n                z_shape = self.ops.shape(encoder.sample)\n                uz_shape = z_shape\n                uz_shape[-1] = uz_shape[-1] // len(config.latent.projections)\n                latent = UniformDistribution(self, config.latent, output_shape=uz_shape)\n            self.uniform_distribution = latent \n            self.latent = latent\n            direction, slider = self.create_controls(self.ops.shape(latent.sample))\n            z = latent.sample + slider * direction\n\n            u_to_z = self.create_component(config.u_to_z, name=\'u_to_z\', input=z)\n            generator = self.create_component(config.generator, input=u_to_z.sample, name=\'generator\')\n            stacked = [x_input, generator.sample]\n            self.generator = generator\n\n\n            self.encoder = encoder\n            features = [encoder.sample, u_to_z.sample]\n\n            reencode_u_to_z = self.create_encoder(generator.sample, reuse=True)\n            reencode_u_to_z_to_g= self.create_component(config.generator, input=reencode_u_to_z.sample, name=\'generator\', reuse=True)\n\n            self.reencode_g = reencode_u_to_z_to_g\n\n            x_hat = self.create_component(config.generator, input=encoder.sample, reuse=True, name=\'generator\').sample\n            reencode_x_hat_to_z = self.create_encoder(x_hat, reuse=True)\n            self.uniform_sample = generator.sample\n\n            d_vars = []\n            g_vars = generator.variables() + encoder.variables()\n            g_vars += u_to_z.variables()\n\n            def ali(*stack, reuse=False):\n                xs=[t for t,_ in stack]\n                zs=[t for _,t in stack]\n                xs=tf.concat(xs,axis=0)\n                zs=tf.concat(zs,axis=0)\n\n                discriminator = self.create_component(config.discriminator, name=\'discriminator\', input=xs, features=[zs], reuse=reuse)\n                loss = self.create_loss(config.loss, discriminator, None, None, len(stack))\n                return loss,discriminator\n\n            def d(name, stack):\n                if name is None:\n                    name = config\n                stacked = tf.concat(stack,axis=0)\n                discriminator = self.create_component(config[name], name=name, input=stacked)\n                loss = self.create_loss(config.loss, discriminator, None, None, len(stack))\n                return loss,discriminator\n\n            l1, d1 = ali([self.inputs.x,encoder.sample],[generator.sample,u_to_z.sample],[reencode_u_to_z_to_g.sample, reencode_u_to_z.sample])\n            l2, d2 = ali([self.inputs.x,tf.zeros_like(encoder.sample)],[generator.sample,tf.zeros_like(u_to_z.sample)],[reencode_u_to_z_to_g.sample, tf.zeros_like(reencode_u_to_z.sample)], reuse=True)\n            l3, d3 = ali([tf.zeros_like(self.inputs.x),encoder.sample],[tf.zeros_like(generator.sample),u_to_z.sample],[tf.zeros_like(reencode_u_to_z_to_g.sample), reencode_u_to_z.sample], reuse=True)\n\n\n            if config.alternate:\n                d_losses = [beta * (l1.d_loss - l2.d_loss - l3.d_loss) + l2.d_loss + 2*l3.d_loss]\n                g_losses = [beta * (l1.g_loss - l2.g_loss - l3.g_loss) + l2.g_loss + 2*l3.g_loss]\n\n            if config.mutual_only:\n                d_losses = [2*l1.d_loss - l2.d_loss - l3.d_loss]\n                g_losses = [2*l1.g_loss - l2.g_loss - l3.g_loss]\n            else:\n\n                l4, d4 = d(\'x_discriminator\', [self.inputs.x, generator.sample, reencode_u_to_z_to_g.sample])\n                l5, d5 = d(\'z_discriminator\', [encoder.sample, u_to_z.sample, reencode_u_to_z.sample])\n\n                beta = config.beta or 0.9\n                d_losses = [beta * (l1.d_loss - l2.d_loss - l3.d_loss) + l4.d_loss + 2*l5.d_loss]\n                g_losses = [beta * (l1.g_loss - l2.g_loss - l3.g_loss) + l4.g_loss + 2*l5.g_loss]\n            self.discriminator = d1\n            self.loss = l1\n\n\n            self.add_metric(""ld"", d_losses[0])\n            self.add_metric(""lg"", g_losses[0])\n\n            if config.mutual_only or config.alternate:\n                for d in [d1]:\n                    d_vars += d.variables()\n            else:\n                for d in [d1,d4,d5]:\n                    d_vars += d.variables()\n\n            self._g_vars = g_vars\n            self._d_vars = d_vars\n\n            loss = hc.Config({\n                \'d_fake\':l1.d_fake,\n                \'d_real\':l1.d_real,\n                \'sample\': [tf.add_n(d_losses), tf.add_n(g_losses)]\n            })\n            self.loss = loss\n            self.uniform_distribution = latent \n            trainer = self.create_component(config.trainer, g_vars = g_vars, d_vars = d_vars)\n\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = generator\n        self.slider = slider\n        self.direction = direction\n        self.z = z\n        self.z_hat = encoder.sample\n        self.x_input = x_input\n        self.autoencoded_x = x_hat\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n        self.random_z = tf.random_uniform(ops.shape(latent.sample), -1, 1, name=\'random_z\')\n\n        if hasattr(generator, \'mask_generator\'):\n            self.mask_generator = generator.mask_generator\n            self.mask = mask\n            self.autoencode_mask = generator.mask_generator.sample\n            self.autoencode_mask_3_channel = generator.mask\n\n    def get_layer(self, name):\n        return self.discriminator.named_layers[name]\n\n    def fitness_inputs(self):\n        return [\n                self.uniform_distribution.sample\n                ]\n\n\n    def create_loss(self, loss_config, discriminator, x, generator, split, reuse=False):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, split=split, reuse=reuse)\n        return loss\n\n    def create_controls(self, z_shape):\n        direction = tf.random_normal(z_shape, stddev=0.3, name=\'direction\')\n        slider = tf.get_variable(\'slider\', initializer=tf.constant_initializer(0.0), shape=[1, 1], dtype=tf.float32, trainable=False)\n        return direction, slider\n\n    def create_encoder(self, x_input, name=\'encoder\', reuse=False):\n        config = self.config\n        encoder = dict(config.encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(encoder, name=name, input=x_input, reuse=reuse)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input,\n                self.slider, \n                self.direction,\n                self.uniform_distribution.sample\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int,\n                self.random_z\n        ]\n\n    def g_vars(self):\n        return self._g_vars\n    def d_vars(self):\n        return self._d_vars\n'"
hypergan/gans/experimental/alialpha_gan.py,15,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass AliAlphaGAN(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `input_encoder` is a discriminator.  It encodes X into Z\n        `discriminator` is a standard discriminator.  It measures X, reconstruction of X, and G.\n        `generator` produces two samples, input_encoder output and a known random distribution.\n        """"""\n        return ""generator discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n\n        with tf.device(self.device):\n            x_input = tf.identity(self.inputs.x, name=\'input\')\n\n            # q(z|x)\n            encoder = self.create_encoder(x_input)\n\n            self.encoder = encoder\n            z_shape = self.ops.shape(encoder.sample)\n\n            uz_shape = z_shape\n            uz_shape[-1] = uz_shape[-1] // len(config.encoder.projections)\n            UniformDistribution = UniformDistribution(self, config.encoder, output_shape=uz_shape)\n            direction, slider = self.create_controls(self.ops.shape(UniformDistribution.sample))\n            z = UniformDistribution.sample + slider * direction\n            \n            #projected_encoder = UniformDistribution(self, config.encoder, z=encoder.sample)\n\n\n            feature_dim = len(ops.shape(z))-1\n            #stack_z = tf.concat([encoder.sample, z], feature_dim)\n            #stack_encoded = tf.concat([encoder.sample, encoder.sample], feature_dim)\n            stack_z = z\n\n            generator = self.create_component(config.generator, input=stack_z)\n            self.uniform_sample = generator.sample\n            x_hat = generator.reuse(encoder.sample)\n\n            # z = random uniform\n            # z_hat = z of x\n            # g = random generated\n            # x_input\n\n            stacked_xg = ops.concat([generator.sample, x_input], axis=0)\n            stacked_zs = ops.concat([z, encoder.sample], axis=0)\n            standard_discriminator = self.create_component(config.discriminator, name=\'discriminator\', input=stacked_xg, features=[stacked_zs])\n            z_discriminator = self.create_z_discriminator(UniformDistribution.sample, encoder.sample)\n            standard_loss = self.create_loss(config.loss, standard_discriminator, x_input, generator, 2)\n\n            encoder_loss = self.create_loss(config.eloss or config.loss, z_discriminator, z, encoder, 2)\n\n            trainer = self.create_trainer(None, None, encoder, generator, encoder_loss, standard_loss, standard_discriminator, z_discriminator)\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = generator\n        self.uniform_distribution = uniform_encoder\n        self.slider = slider\n        self.direction = direction\n        self.z = z\n        self.z_hat = encoder.sample\n        self.x_input = x_input\n        self.autoencoded_x = x_hat\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n        self.random_z = tf.random_uniform(ops.shape(UniformDistribution.sample), -1, 1, name=\'random_z\')\n\n        if hasattr(generator, \'mask_generator\'):\n            self.mask_generator = generator.mask_generator\n            self.mask = mask\n            self.autoencode_mask = generator.mask_generator.sample\n            self.autoencode_mask_3_channel = generator.mask\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator.sample, split=split)\n        return loss\n\n    def create_controls(self, z_shape):\n        direction = tf.random_normal(z_shape, stddev=0.3, name=\'direction\')\n        slider = tf.get_variable(\'slider\', initializer=tf.constant_initializer(0.0), shape=[1, 1], dtype=tf.float32, trainable=False)\n        return direction, slider\n\n    def create_encoder(self, x_input, name=\'input_encoder\'):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.discriminator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def create_trainer(self, cycloss, z_cycloss, encoder, generator, encoder_loss, standard_loss, standard_discriminator, encoder_discriminator):\n\n        metrics = []\n        metrics.append(standard_loss.metrics)\n\n        d_vars = standard_discriminator.variables() + encoder_discriminator.variables()\n        g_vars = generator.variables() + encoder.variables()\n        print(""D_VARS"", d_vars)\n        print(""G_VARS"", g_vars)\n        #d_loss = standard_loss.d_loss\n        #g_loss = standard_loss.g_loss + cycloss\n        d_loss = standard_loss.d_loss+encoder_loss.d_loss\n        g_loss = standard_loss.g_loss+encoder_loss.g_loss\n        loss = hc.Config({\'sample\': [d_loss, g_loss], \'metrics\': \n            {\n                \'g_loss\': standard_loss.g_loss,\n                \'e_loss\': encoder_loss.g_loss,\n                \'ed_loss\': encoder_loss.d_loss,\n                \'d_loss\': standard_loss.d_loss\n            }\n        })\n        trainer = ConsensusTrainer(self, self.config.trainer, loss = loss, g_vars = g_vars, d_vars = d_vars)\n        return trainer\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input,\n                self.slider, \n                self.direction,\n                self.uniform_distribution.sample\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int,\n                self.random_z\n        ]\n'"
hypergan/gans/experimental/aligned_ali_gan.py,14,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass AlignedAliGAN(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `input_encoder` is a discriminator.  It encodes X into Z\n        `discriminator` is a standard discriminator.  It measures X, reconstruction of X, and G.\n        `generator` produces two samples, input_encoder output and a known random distribution.\n        """"""\n        return ""generator discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n\n        with tf.device(self.device):\n            #x_input = tf.identity(self.inputs.x, name=\'input\')\n            xa_input = tf.identity(self.inputs.xa, name=\'xa_i\')\n            xb_input = tf.identity(self.inputs.xb, name=\'xb_i\')\n\n            ga = self.create_component(config.generator, input=xb_input, name=\'a_generator\')\n            gb = self.create_component(config.generator, input=xa_input, name=\'b_generator\')\n\n            za = ga.controls[""z""]\n            zb = gb.controls[""z""]\n\n            self.uniform_sample = ga.sample\n\n            xba = ga.sample\n            xab = gb.sample\n            xa_hat = ga.reuse(gb.sample)\n            xb_hat = gb.reuse(ga.sample)\n\n            z_shape = self.ops.shape(za)\n            uz_shape = z_shape\n            uz_shape[-1] = uz_shape[-1] // len(config.z_distribution.projections)\n            ue = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n            features_a = ops.concat([ga.sample, xa_input], axis=0)\n            features_b = ops.concat([gb.sample, xb_input], axis=0)\n            stacked_a = ops.concat([xa_input, ga.sample], axis=0)\n            stacked_b = ops.concat([xb_input, gb.sample], axis=0)\n            stacked_z = ops.concat([ue.sample, za, zb], axis=0)\n            da = self.create_component(config.discriminator, name=\'a_discriminator\', input=stacked_a, features=[features_b])\n            db = self.create_component(config.discriminator, name=\'b_discriminator\', input=stacked_b, features=[features_a])\n            dz = self.create_component(config.z_discriminator, name=\'z_discriminator\', input=stacked_z)\n\n            if config.ali_z:\n                features_alia = ops.concat([za, ue.sample], axis=0)\n                features_alib = ops.concat([zb, ue.sample], axis=0)\n                uga = ga.reuse(tf.zeros_like(xb_input), replace_controls={""z"":ue.sample})\n                ugb = gb.reuse(tf.zeros_like(xa_input), replace_controls={""z"":ue.sample})\n                stacked_alia = ops.concat([xa_input, uga], axis=0)\n                stacked_alib = ops.concat([xb_input, ugb], axis=0)\n\n                dalia = self.create_component(config.ali_discriminator, name=\'alia_discriminator\', input=stacked_alia, features=[features_alib])\n                dalib = self.create_component(config.ali_discriminator, name=\'alib_discriminator\', input=stacked_alib, features=[features_alia])\n                lalia = self.create_loss(config.loss, dalia, None, None, 2)\n                lalib = self.create_loss(config.loss, dalib, None, None, 2)\n\n            la = self.create_loss(config.loss, da, xa_input, ga.sample, 2)\n            lb = self.create_loss(config.loss, db, xb_input, gb.sample, 2)\n            lz = self.create_loss(config.loss, dz, None, None, 3)\n\n            d_vars = da.variables() + db.variables() + lz.variables()\n            if config.ali_z:\n                d_vars += dalia.variables() + dalib.variables()\n            g_vars = ga.variables() + gb.variables()\n\n            d_loss = la.d_loss+lb.d_loss+lz.d_loss\n            g_loss = la.g_loss+lb.g_loss+lz.g_loss\n            metrics = {\n                    \'ga_loss\': la.g_loss,\n                    \'gb_loss\': lb.g_loss,\n                    \'gz_loss\': lz.g_loss,\n                    \'da_loss\': la.d_loss,\n                    \'db_loss\': lb.d_loss,\n                    \'dz_loss\': lz.d_loss\n                }\n            if config.ali_z:\n                d_loss+=lalib.d_loss+lalia.d_loss\n                g_loss+=lalib.g_loss+lalia.g_loss\n                metrics[\'galia_loss\']=lalia.g_loss\n                metrics[\'galib_loss\']=lalib.g_loss\n                metrics[\'dalia_loss\']=lalia.d_loss\n                metrics[\'dalib_loss\']=lalib.d_loss\n\n            loss = hc.Config({\'sample\': [d_loss, g_loss], \'metrics\': metrics})\n            trainer = ConsensusTrainer(self, config.trainer, loss = loss, g_vars = g_vars, d_vars = d_vars)\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = ga\n        self.encoder = gb # this is the other gan\n        self.uniform_distribution = hc.Config({""sample"":za})#uniform_encoder\n        self.zb = zb\n        self.z_hat = gb.sample\n        self.x_input = xa_input\n        self.autoencoded_x = xa_hat\n\n        self.cyca = xa_hat\n        self.cycb = xb_hat\n        self.xba = xba\n        self.xab = xab\n\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator, split=split)\n        return loss\n\n    def create_encoder(self, x_input, name=\'input_encoder\'):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int\n        ]\n'"
hypergan/gans/experimental/aligned_ali_gan3.py,21,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\n\nclass AlignedAliGAN3(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `input_encoder` is a discriminator.  It encodes X into Z\n        `discriminator` is a standard discriminator.  It measures X, reconstruction of X, and G.\n        `generator` produces two samples, input_encoder output and a known random distribution.\n        """"""\n        return ""discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n\n        with tf.device(self.device):\n            #x_input = tf.identity(self.inputs.x, name=\'input\')\n            xa_input = tf.identity(self.inputs.xa, name=\'xa_i\')\n            xb_input = tf.identity(self.inputs.xb, name=\'xb_i\')\n\n            if config.same_g:\n                ga = self.create_component(config.generator, input=xb_input, name=\'a_generator\')\n                gb = self.create_component(config.generator, input=xa_input, name=\'a_generator\', reuse=True)\n            elif config.two_g:\n                ga = self.create_component(config.generator1, input=xb_input, name=\'a_generator\')\n                gb = self.create_component(config.generator2, input=xa_input, name=\'b_generator\')\n            else:\n                ga = self.create_component(config.generator, input=xb_input, name=\'a_generator\')\n                gb = self.create_component(config.generator, input=xa_input, name=\'b_generator\')\n\n            za = ga.controls[""z""]\n            zb = gb.controls[""z""]\n\n            self.uniform_sample = ga.sample\n\n            xba = ga.sample\n            xab = gb.sample\n            xa_hat = ga.sample\n            xb_hat = gb.sample\n            #xa_hat = ga.reuse(gb.sample)\n            #xb_hat = gb.reuse(ga.sample)\n\n            z_shape = self.ops.shape(za)\n            uz_shape = z_shape\n            uz_shape[-1] = uz_shape[-1] // len(config.latent.projections or [1])\n            ue = UniformDistribution(self, config.latent, output_shape=uz_shape)\n            ue2 = UniformDistribution(self, config.latent, output_shape=uz_shape)\n            ue3 = UniformDistribution(self, config.latent, output_shape=uz_shape)\n            ue4 = UniformDistribution(self, config.latent, output_shape=uz_shape)\n            print(\'ue\', ue.sample)\n\n            zua = ue.sample\n            zub = ue2.sample\n\n            uga = ga.sample#ga.reuse(tf.zeros_like(xb_input), replace_controls={""z"":zua})\n            ugb = gb.sample#gb.reuse(tf.zeros_like(xa_input), replace_controls={""z"":zub})\n\n            xa = xa_input\n            xb = xb_input\n\n            re_ga = self.create_component(config.generator, input=gb.sample, name=\'a_generator\', reuse=True)\n            re_gb = self.create_component(config.generator, input=ga.sample, name=\'b_generator\', reuse=True)\n            re_zb = zb#re_gb.controls[\'z\']\n\n            t0 = tf.concat([xb, xb], axis=3)\n            t1 = tf.concat([gb.sample, gb.sample], axis=3)\n            zaxis = len(self.ops.shape(za))-1\n\n            f0 = tf.concat([za, za], axis=zaxis)\n            f1 = tf.concat([zb, zb], axis=zaxis)\n            #f0 = tf.concat([zb, za], axis=zaxis)\n            #f1 = tf.concat([za, zb], axis=zaxis)\n            stack = [t0, t1]\n            stacked = ops.concat(stack, axis=0)\n            features = ops.concat([f0, f1], axis=0)\n\n            d = self.create_component(config.discriminator, name=\'d_ab\', input=stacked, features=[features])\n\n            self.za = za\n            self.discriminator = d\n            l = self.create_loss(config.loss, d, None, None, len(stack))\n            loss = l\n            d1_lambda = config.d1_lambda\n            d2_lambda = config.d2_lambda\n            d_loss1 = d1_lambda * l.d_loss\n            g_loss1 = d1_lambda * l.g_loss\n\n            d_vars1 = d.variables()\n\n            d_loss = l.d_loss\n            g_loss = l.g_loss\n\n            metrics = {\n                    \'g_loss\': l.g_loss,\n                    \'d_loss\': l.d_loss\n                }\n\n\n            self._g_vars = ga.variables() + gb.variables()\n            self._d_vars = d_vars1\n            self.loss=loss\n            self.generator = gb\n            trainer = self.create_component(config.trainer)\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.latent = hc.Config({\'sample\':zb})\n        self.generator = gb\n        self.encoder = gb # this is the other gan\n        self.uniform_distribution = hc.Config({""sample"":zb})#uniform_encoder\n        self.zb = zb\n        self.z_hat = gb.sample\n        self.x_input = xa_input\n        self.autoencoded_x = xa_hat\n\n        self.cyca = xa_hat\n        self.cycb = xb_hat\n        self.xba = xba\n        self.xab = xab\n        self.uga = uga\n        self.ugb = ugb\n\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n\n\n    def d_vars(self):\n        return self._d_vars\n    def g_vars(self):\n        return self._g_vars\n\n    def create_discriminator(self, _input, reuse=False):\n        return self.create_component(self.config.discriminator, name=\'d_ab\', input=_input, features=[tf.zeros_like(self.za)], reuse=reuse)\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator, split=split)\n        return loss\n\n    def create_encoder(self, x_input, name=\'input_encoder\'):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int\n        ]\n'"
hypergan/gans/experimental/aligned_ali_gan6.py,15,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass AlignedAliGAN6(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `input_encoder` is a discriminator.  It encodes X into Z\n        `discriminator` is a standard discriminator.  It measures X, reconstruction of X, and G.\n        `generator` produces two samples, input_encoder output and a known random distribution.\n        """"""\n        return ""generator discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n\n        with tf.device(self.device):\n            #x_input = tf.identity(self.inputs.x, name=\'input\')\n            xa_input = tf.identity(self.inputs.xa, name=\'xa_i\')\n            xb_input = tf.identity(self.inputs.xb, name=\'xb_i\')\n\n            if config.same_g:\n                ga = self.create_component(config.generator, input=xb_input, name=\'a_generator\')\n                gb = hc.Config({""sample"":ga.reuse(xa_input),""controls"":{""z"":ga.controls[\'z\']}, ""reuse"": ga.reuse})\n            else:\n                ga = self.create_component(config.generator, input=xb_input, name=\'a_generator\')\n                gb = self.create_component(config.generator, input=xa_input, name=\'b_generator\')\n\n            za = ga.controls[""z""]\n            zb = gb.controls[""z""]\n\n            self.uniform_sample = gb.sample\n\n            xba = ga.sample\n            xab = gb.sample\n            xa_hat = ga.reuse(gb.sample)\n            xb_hat = gb.reuse(ga.sample)\n            xa = xa_input\n            xb = xb_input\n\n            if config.ignore_random:\n                t0 = xb\n                t1 = gb.sample\n                f0 = za\n                f1 = zb\n                stack = [t0, t1]\n                stacked = ops.concat(stack, axis=0)\n                features = ops.concat([f0, f1], axis=0)\n                self.inputs.x = xb\n                ugb = gb.sample\n                zub = zb\n                sourcezub = zb\n                \n\n            else:\n                z_shape = self.ops.shape(za)\n                uz_shape = z_shape\n                uz_shape[-1] = uz_shape[-1] // len(config.z_distribution.projections)\n                ue = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n                ue2 = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n                ue3 = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n                ue4 = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n                print(\'ue\', ue.sample)\n\n                zua = ue.sample\n                zub = ue2.sample\n\n                ue2 = UniformDistribution(self, config.z_distribution, output_shape=[self.ops.shape(za)[0], config.source_linear])\n                zub = ue2.sample\n                uz_to_gz = self.create_component(config.uz_to_gz, name=\'uzb_to_gzb\', input=zub)\n                zub = uz_to_gz.sample\n                sourcezub = zub\n                ugb = gb.reuse(tf.zeros_like(xa_input), replace_controls={""z"":zub})\n\n                t0 = xb\n                t1 = gb.sample\n                t2 = ugb\n                f0 = za\n                f1 = zb\n                f2 = zub\n                stack = [t0, t1, t2]\n                stacked = ops.concat(stack, axis=0)\n                features = ops.concat([f0, f1, f2], axis=0)\n\n\n            d = self.create_component(config.discriminator, name=\'d_ab\', input=stacked, features=[features])\n            l = self.create_loss(config.loss, d, xa_input, ga.sample, len(stack))\n            loss1 = l\n            d_loss1 = l.d_loss\n            g_loss1 = l.g_loss\n\n            d_vars1 = d.variables()\n            g_vars1 = gb.variables()+ga.variables()\n            if not config.ignore_random:\n                g_vars1 += uz_to_gz.variables()#gb.variables()# + gb.variables()\n\n            d_loss = l.d_loss\n            g_loss = l.g_loss\n\n            metrics = {\n                    \'g_loss\': l.g_loss,\n                    \'d_loss\': l.d_loss\n                }\n\n            if config.inline_alpha:\n                t0 = zub\n                t1 = zb\n                netzd = tf.concat(axis=0, values=[t0,t1])\n                z_d = self.create_component(config.z_discriminator, name=\'z_discriminator\', input=netzd)\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=xa_input, generator=ga, split=2)\n                metrics[""za_gloss""]=loss3.g_loss\n                metrics[""za_dloss""]=loss3.d_loss\n                d_vars1 += z_d.variables()\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n\n            trainers = []\n            if config.separate_alpha:\n                t0 = zub\n                t1 = zb\n                netzd = tf.concat(axis=0, values=[t0,t1])\n                z_d = self.create_component(config.z_discriminator, name=\'z_discriminator\', input=netzd)\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=xa_input, generator=ga, split=2)\n                metrics[""za_gloss""]=loss3.g_loss\n                metrics[""za_dloss""]=loss3.d_loss\n                g_vars1 = gb.variables()+ga.variables()#gb.variables()# + gb.variables()\n                trainers += [ConsensusTrainer(self, config.trainer, loss = loss3, g_vars = uz_to_gz.variables(), d_vars = z_d.variables())]\n\n\n            lossa = hc.Config({\'sample\': [d_loss1, g_loss1], \'metrics\': metrics})\n            #lossb = hc.Config({\'sample\': [d_loss2, g_loss2], \'metrics\': metrics})\n            trainers += [ConsensusTrainer(self, config.trainer, loss = lossa, g_vars = g_vars1, d_vars = d_vars1)]\n            #trainers += [ConsensusTrainer(self, config.trainer, loss = lossb, g_vars = g_vars2, d_vars = d_vars2)]\n            trainer = MultiTrainerTrainer(trainers)\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = ga\n        self.encoder = hc.Config({""sample"":ugb}) # this is the other gan\n        self.uniform_distribution = hc.Config({""sample"":zub})#uniform_encoder\n        self.uniform_distribution_source = hc.Config({""sample"":sourcezub})#uniform_encoder\n        self.zb = zb\n        self.z_hat = gb.sample\n        self.x_input = xa_input\n        self.autoencoded_x = xa_hat\n\n        self.cyca = xa_hat\n        self.cycb = xb_hat\n        self.xba = xba\n        self.xab = xab\n        self.uga = ugb\n        self.ugb = ugb\n\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator, split=split)\n        return loss\n\n    def create_encoder(self, x_input, name=\'input_encoder\'):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int\n        ]\n'"
hypergan/gans/experimental/aligned_ali_gan7.py,23,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass AlignedAliGAN7(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `input_encoder` is a discriminator.  It encodes X into Z\n        `discriminator` is a standard discriminator.  It measures X, reconstruction of X, and G.\n        `generator` produces two samples, input_encoder output and a known random distribution.\n        """"""\n        return ""generator discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n\n        with tf.device(self.device):\n            #x_input = tf.identity(self.inputs.x, name=\'input\')\n            xa_input = tf.identity(self.inputs.xa, name=\'xa_i\')\n            xb_input = tf.identity(self.inputs.xb, name=\'xb_i\')\n\n            if config.same_g:\n                ga = self.create_component(config.generator, input=xb_input, name=\'a_generator\')\n                gb = hc.Config({""sample"":ga.reuse(xa_input),""controls"":{""z"":ga.controls[\'z\']}, ""reuse"": ga.reuse})\n            else:\n                ga = self.create_component(config.generator, input=xb_input, name=\'a_generator\')\n                gb = self.create_component(config.generator, input=xa_input, name=\'b_generator\')\n\n            za = ga.controls[""z""]\n            zb = gb.controls[""z""]\n\n            self.uniform_sample = ga.sample\n\n            xba = ga.sample\n            xab = gb.sample\n            xa_hat = ga.reuse(gb.sample)\n            xb_hat = gb.reuse(ga.sample)\n\n            z_shape = self.ops.shape(za)\n            uz_shape = z_shape\n            uz_shape[-1] = uz_shape[-1] // len(config.z_distribution.projections)\n            ue = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n            ue2 = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n            ue3 = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n            ue4 = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n            print(\'ue\', ue.sample)\n\n            zua = ue.sample\n            zub = ue2.sample\n\n            ga2 = self.create_component(config.generator, input=tf.zeros_like(xb_input), name=\'ua_generator\')\n            gb2 = self.create_component(config.generator, input=tf.zeros_like(xb_input), name=\'ub_generator\')\n            uga = ga2.reuse(tf.zeros_like(xb_input), replace_controls={""z"":zua})\n            ugb = gb2.reuse(tf.zeros_like(xb_input), replace_controls={""z"":zub})\n\n            ugbprime = gb.reuse(uga)\n            ugbzb = gb.controls[\'z\']\n\n            xa = xa_input\n            xb = xb_input\n\n            t0 = xb\n            t1 = gb.sample\n            t2 = ugbprime\n            f0 = za\n            f1 = zb\n            f2 = ugbzb\n            stack = [t0, t1, t2]\n            stacked = ops.concat(stack, axis=0)\n            features = ops.concat([f0, f1, f2], axis=0)\n\n            xa_hat = ugbprime\n\n            d = self.create_component(config.discriminator, name=\'d_ab\', input=stacked, features=[features])\n            l = self.create_loss(config.loss, d, xa_input, ga.sample, len(stack))\n            loss1 = l\n            d_loss1 = l.d_loss\n            g_loss1 = l.g_loss\n\n            d_vars1 = d.variables()\n            g_vars1 = ga2.variables() + gb2.variables() + gb.variables()+ga.variables()#gb.variables()# + gb.variables()\n\n            d_loss = l.d_loss\n            g_loss = l.g_loss\n\n            metrics = {\n                    \'g_loss\': l.g_loss,\n                    \'d_loss\': l.d_loss\n                }\n\n            g_vars2 = ga.variables()\n            trainers = []\n\n            if config.cyc:\n                t0 = xa\n                t1 = ga.sample\n                f0 = zb\n                f1 = za\n                stack = [t0, t1]\n                stacked = ops.concat(stack, axis=0)\n                features = ops.concat([f0, f1], axis=0)\n\n                d = self.create_component(config.discriminator, name=\'d2_ab\', input=stacked, features=[features])\n                l = self.create_loss(config.loss, d, xa_input, ga.sample, len(stack))\n\n                d_loss1 += l.d_loss\n                g_loss1 += l.g_loss\n                d_vars1 += d.variables()\n                metrics[""gloss2""]=l.g_loss\n                metrics[""dloss2""]=l.d_loss\n                #loss2=l\n                #g_loss2 = loss2.g_loss\n                #d_loss2 = loss2.d_loss\n\n            if(config.alpha):\n                t0 = zub\n                t1 = zb\n                netzd = tf.concat(axis=0, values=[t0,t1])\n                z_d = self.create_component(config.z_discriminator, name=\'z_discriminator\', input=netzd)\n\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=xa_input, generator=ga, split=2)\n                d_vars1 += z_d.variables()\n                metrics[""za_gloss""]=loss3.g_loss\n                metrics[""za_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n\n\n            if(config.ug):\n                t0 = xb\n                t1 = ugb\n                netzd = tf.concat(axis=0, values=[t0,t1])\n                z_d = self.create_component(config.discriminator, name=\'ug_discriminator\', input=netzd)\n\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=xa_input, generator=ga, split=2)\n                d_vars1 += z_d.variables()\n                metrics[""za_gloss""]=loss3.g_loss\n                metrics[""za_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n\n            if(config.alpha2):\n                t0 = zua\n                t1 = za\n                netzd = tf.concat(axis=0, values=[t0,t1])\n                z_d = self.create_component(config.z_discriminator, name=\'z_discriminator2\', input=netzd)\n\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=xa_input, generator=ga, split=2)\n                d_vars1 += z_d.variables()\n                metrics[""za_gloss""]=loss3.g_loss\n                metrics[""za_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n\n            if config.ug2:\n                t0 = xa\n                t1 = uga\n                netzd = tf.concat(axis=0, values=[t0,t1])\n                z_d = self.create_component(config.discriminator, name=\'ug_discriminator2\', input=netzd)\n\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=xa_input, generator=ga, split=2)\n                d_vars1 += z_d.variables()\n                metrics[""za_gloss""]=loss3.g_loss\n                metrics[""za_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n\n            if config.ug3:\n                t0 = tf.concat(values=[xa,xb], axis=3)\n                t1 = tf.concat(values=[uga,ugb], axis=3)\n                netzd = tf.concat(axis=0, values=[t0,t1])\n                z_d = self.create_component(config.discriminator, name=\'ug_discriminator3\', input=netzd)\n\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=xa_input, generator=ga, split=2)\n                d_vars1 += z_d.variables()\n                metrics[""za_gloss""]=loss3.g_loss\n                metrics[""za_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n\n\n\n\n\n            lossa = hc.Config({\'sample\': [d_loss1, g_loss1], \'metrics\': metrics})\n            #lossb = hc.Config({\'sample\': [d_loss2, g_loss2], \'metrics\': metrics})\n            trainers += [ConsensusTrainer(self, config.trainer, loss = lossa, g_vars = g_vars1, d_vars = d_vars1)]\n            #trainers += [ConsensusTrainer(self, config.trainer, loss = lossb, g_vars = g_vars2, d_vars = d_vars2)]\n            trainer = MultiTrainerTrainer(trainers)\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = ga\n        self.encoder = gb # this is the other gan\n        self.uniform_distribution = hc.Config({""sample"":zb})#uniform_encoder\n        self.zb = zb\n        self.z_hat = gb.sample\n        self.x_input = xa_input\n        self.autoencoded_x = xa_hat\n\n        self.cyca = xa_hat\n        self.cycb = xb_hat\n        self.xba = xba\n        self.xab = xab\n        self.uga = uga\n        self.ugb = ugb\n\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator, split=split)\n        return loss\n\n    def create_encoder(self, x_input, name=\'input_encoder\'):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int\n        ]\n'"
hypergan/gans/experimental/aligned_ali_gan8.py,14,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass AlignedAliGAN8(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `input_encoder` is a discriminator.  It encodes X into Z\n        `discriminator` is a standard discriminator.  It measures X, reconstruction of X, and G.\n        `generator` produces two samples, input_encoder output and a known random distribution.\n        """"""\n        return ""generator discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n\n        with tf.device(self.device):\n            #x_input = tf.identity(self.inputs.x, name=\'input\')\n            def random_like(x):\n                return UniformDistribution(self, config.latent, output_shape=self.ops.shape(x)).sample\n            self.latent = self.create_component(config.latent, name=\'forcerandom_discriminator\')\n            zga = self.create_component(config.encoder, input=self.inputs.xb, name=\'xb_to_za\')\n            zgb = self.create_component(config.encoder, input=self.inputs.xa, name=\'xa_to_zb\')\n            self.zga = zga\n            self.zgb = zgb\n            za = zga.sample\n            zb = zgb.sample\n            if config.style:\n                styleb = self.create_component(config.style_encoder, input=self.inputs.xb, name=\'xb_style\')\n                stylea = self.create_component(config.style_encoder, input=self.inputs.xa, name=\'xa_style\')\n\n                self.stylea = stylea\n                self.styleb = styleb\n                self.random_style = random_like(styleb.sample)\n                ga = self.create_component(config.generator, input=za, name=\'a_generator\', features=[stylea.sample])\n                gb = self.create_component(config.generator, input=zb, name=\'b_generator\', features=[styleb.sample])\n            elif config.skip_connections:\n                ga = self.create_component(config.generator, input=za, skip_connections=zga.layers, name=\'a_generator\')\n                gb = self.create_component(config.generator, input=zb, skip_connections=zgb.layers, name=\'b_generator\')\n            else:\n                ga = self.create_component(config.generator, input=za, name=\'a_generator\')\n                gb = self.create_component(config.generator, input=zb, name=\'b_generator\')\n                self.ga = ga\n                self.gb = gb\n\n\n            re_zb = self.create_component(config.encoder, input=ga.sample, name=\'xa_to_zb\', reuse=True)\n            re_za = self.create_component(config.encoder, input=gb.sample, name=\'xb_to_za\', reuse=True)\n            self.ga = ga\n            self.gb = gb\n\n            self.uniform_sample = gb.sample\n\n            xba = ga.sample\n            xab = gb.sample\n            xa_hat = ga.reuse(re_za.sample)\n            xb_hat = gb.reuse(re_zb.sample)\n            xa = self.inputs.xa\n            xb = self.inputs.xb\n\n\n            t0 = xb\n            t1 = gb.sample\n            f0 = re_zb.sample#za\n            f1 = zb\n            stack = [t0, t1]\n            stacked = ops.concat(stack, axis=0)\n            features = ops.concat([f0, f1], axis=0)\n            self.features = features\n            # self.inputs.x = xa\n            ugb = gb.sample#gb.reuse(random_like(zb))\n            zub = zb\n            sourcezub = zb\n\n            #skip_connections = []\n            #for (a,b) in zip(zga.layers,zgb.layers):\n            #    layer = tf.concat([a,b],axis=0)\n            #    skip_connections += [layer]\n\n            d = self.create_component(config.discriminator, name=\'d_ab\', \n                    #skip_connections=skip_connections,\n                    input=stacked, features=[features])\n            self.discriminator = d\n            l = self.create_loss(config.loss, d, self.inputs.xa, ga.sample, len(stack))\n            self.loss = l\n            loss1 = l\n            d_loss1 = l.d_loss\n            g_loss1 = l.g_loss\n\n            d_vars1 = d.variables()\n            g_vars1 = gb.variables()+zga.variables()+zgb.variables()\n            self.generator = gb\n\n            d_loss = l.d_loss\n            g_loss = l.g_loss\n\n\n            metrics = {\n                    \'g_loss\': l.g_loss,\n                    \'d_loss\': l.d_loss\n                }\n\n            if config.uga:\n                t0 = xa\n                t1 = ga.sample\n                stack = [t0, t1]\n                stacked = ops.concat(stack, axis=0)\n                features = None\n                z_d = self.create_component(config.discriminator, name=\'uga_discriminator\', input=stacked)\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=self.inputs.xa, generator=ga, split=2)\n                metrics[""uga_gloss""]=loss3.g_loss\n                metrics[""uga_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n                d_vars1 += z_d.variables()\n\n\n            if config.ugb:\n                t0 = xb\n                t1 = gb.sample\n                stack = [t0, t1]\n                stacked = ops.concat(stack, axis=0)\n                features = None\n                z_d = self.create_component(config.discriminator, name=\'ugb_discriminator\', input=stacked)\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=self.inputs.xa, generator=ga, split=2)\n                self.db = z_d\n                self.lb = loss3\n                metrics[""ugb_gloss""]=loss3.g_loss\n                metrics[""ugb_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n                d_vars1 += z_d.variables()\n\n\n            if config.uga2:\n                t0 = xa\n                t1 = ga.sample\n                t2 = ga.reuse(za)\n                stack = [t0, t1, t2]\n                stacked = ops.concat(stack, axis=0)\n                features = None\n                z_d = self.create_component(config.discriminator, name=\'uga_discriminator\', input=stacked)\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=self.inputs.xa, generator=ga, split=3)\n                metrics[""uga_gloss""]=loss3.g_loss\n                metrics[""uga_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n                d_vars1 += z_d.variables()\n\n\n            if config.ugb2:\n                t0 = xb\n                t1 = gb.sample\n                t2 = gb.reuse(zb)\n                stack = [t0, t1]\n                stacked = ops.concat(stack, axis=0)\n                features = None\n                z_d = self.create_component(config.discriminator, name=\'ugb_discriminator\', input=stacked)\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=self.inputs.xa, generator=ga, split=3)\n                metrics[""ugb_gloss""]=loss3.g_loss\n                metrics[""ugb_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n                d_vars1 += z_d.variables()\n\n            if config.forcerandom:\n                t0 = random_like(styleb.sample)#tf.concat([random_like(style1), random_like(style1)], axis=1)\n                t1 = styleb.sample#tf.concat([style1, style2], axis=1)\n                stack = [t0,t1]\n                stacked = ops.concat(stack, axis=0)\n                features = None\n                z_d = self.create_component(config.latent, name=\'forcerandom_discriminator\', input=stacked)\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=self.inputs.xa, generator=ga, split=2)\n                metrics[""forcerandom_gloss""]=loss3.g_loss\n                metrics[""forcerandom_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n                d_vars1 += z_d.variables()\n\n\n            if config.forcerandom2:\n                style_reader = self.create_component(config.latent, name=\'style_discriminator2\', input=zb)\n                style1 = style_reader.sample\n                t0 = random_like(style1)\n                t1 = style1\n                stack = [t0,t1]\n                stacked = ops.concat(stack, axis=0)\n                features = None\n                z_d = self.create_component(config.latent, name=\'forcerandom_discriminator2\', input=stacked)\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=self.inputs.xa, generator=ga, split=2)\n                metrics[""forcerandom2_gloss""]=loss3.g_loss\n                metrics[""forcerandom2_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n                d_vars1 += z_d.variables()\n                g_vars1 += style_reader.variables()\n\n\n \n            trainers = []\n            if config.alpha:\n                t0 = random_like(zub)\n                t1 = zb\n                t2 = za\n                netzd = tf.concat(axis=0, values=[t0,t1,t2])\n                z_d = self.create_component(config.latent, name=\'latent\', input=netzd)\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=self.inputs.xa, generator=ga, split=3)\n                metrics[""za_gloss""]=loss3.g_loss\n                metrics[""za_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n                d_vars1 += z_d.variables()\n\n            if config.mirror_joint:\n                t0 = xa\n                t1 = ga.sample\n                f0 = zb\n                f1 = za\n                stack = [t0, t1]\n                stacked = ops.concat(stack, axis=0)\n                features = ops.concat([f0, f1], axis=0)\n                uga = ga.sample\n                zua = za\n                z_d = self.create_component(config.discriminator, name=\'d_ba\', input=stacked, features=[features])\n                loss3 = self.create_component(config.loss, discriminator = z_d, split=2)\n                self.gan.add_metric(""ba_gloss"",loss3.g_loss)\n                self.gan.add_metric(""ba_dloss"",loss3.d_loss)\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n                d_vars1 += z_d.variables()\n                g_vars1 += ga.variables()\n                self.al = loss1\n                self.bl = loss3\n                self.bd = z_d\n                self.ad = d\n\n            if config.style:\n                g_vars1 += styleb.variables()\n\n            self._g_vars = g_vars1\n            self._d_vars = d_vars1\n\n            self.loss = hc.Config({\n                \'d_fake\':l.d_fake,\n                \'d_real\':l.d_real,\n                \'sample\': [d_loss1, g_loss1],\n                \'metrics\': metrics\n                })\n            print(""g_vars1"", g_vars1)\n            trainer = self.create_component(config.trainer)\n\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = gb\n        self.encoder = hc.Config({""sample"":ugb}) # this is the other gan\n        self.uniform_distribution = hc.Config({""sample"":zub})#uniform_encoder\n        self.uniform_distribution_source = hc.Config({""sample"":sourcezub})#uniform_encoder\n        self.zb = zb\n        self.z_hat = gb.sample\n        self.x_input = self.inputs.xa\n        self.autoencoded_x = xb_hat\n\n        self.cyca = xa_hat\n        self.cycb = xb_hat\n        self.xba = xba\n        self.xab = xab\n        self.uga = ugb\n        self.ugb = ugb\n\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n\n    def d_vars(self):\n        return self._d_vars\n    def g_vars(self):\n        return self._g_vars\n    def fitness_inputs(self):\n        return [\n                self.uniform_distribution.sample, self.inputs.xa\n                ]\n\n\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator, split=split)\n        return loss\n\n    def create_encoder(self, x_input, name=\'input_encoder\'):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input)\n        return encoder\n\n    def create_latent(self, z, z_hat):\n        config = self.config\n        latent = dict(config.latent or config.discriminator)\n        latent[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(latent, name=\'latent\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int\n        ]\n'"
hypergan/gans/experimental/aligned_ali_gan_test.py,22,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom .base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\n\nclass AlignedAliGANTest(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `input_encoder` is a discriminator.  It encodes X into Z\n        `discriminator` is a standard discriminator.  It measures X, reconstruction of X, and G.\n        `generator` produces two samples, input_encoder output and a known random distribution.\n        """"""\n        return ""generator discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n\n        with tf.device(self.device):\n            #x_input = tf.identity(self.inputs.x, name=\'input\')\n            xa_input = tf.identity(self.inputs.xa, name=\'xa_i\')\n            xb_input = tf.identity(self.inputs.xb, name=\'xb_i\')\n\n            ue = UniformDistribution(self, config.latent)\n            ue2 = UniformDistribution(self, config.latent)\n            ue3 = UniformDistribution(self, config.latent)\n            ue4 = UniformDistribution(self, config.latent)\n            if config.same_g:\n                gb = self.create_component(config.generator, input=ue3.sample, name=\'a_generator\')\n                gb = self.create_component(config.generator, input=ue4.sample, name=\'a_generator\', reuse=True)\n            else:\n                def _append_xa(gan, config, net):\n                    _x = gan.inputs.xa\n                    s = [int(x) for x in net.get_shape()]\n                    shape = [s[1], s[2]]\n                    _x = tf.image.resize_images(_x, shape, 1)\n                    return _x \n                def _append_xb(gan, config, net):\n                    _x = gan.inputs.xb\n                    s = [int(x) for x in net.get_shape()]\n                    shape = [s[1], s[2]]\n                    _x = tf.image.resize_images(_x, shape, 1)\n                    return _x \n\n\n\n                #config.generator[\'layer_filter\'] = _append_xb\n                #gb = self.create_component(config.generator, input=ue3.sample, name=\'a_generator\')\n                config.generator[\'layer_filter\'] = _append_xa\n                gb = self.create_component(config.generator, input=ue4.sample, name=\'b_generator\')\n\n            za = gb.controls[""z""]\n            zb = gb.controls[""z""]\n\n            self.uniform_sample = gb.sample\n\n\n            zua = ue.sample\n            zub = ue2.sample\n\n            xa = xa_input\n            xb = xb_input\n\n\n            t0 = tf.concat([xb, xb], axis=3)\n            t1 = tf.concat([gb.sample, xb], axis=3)\n            t0 = xb\n            t1 = gb.sample\n            f0 = za\n            f1 = zb\n            f2 = zub\n            stack = [t0, t1]\n            stacked = ops.concat(stack, axis=0)\n            features = ops.concat([f0, f1], axis=0)\n\n            config.discriminator[\'layer_filter\'] = _append_xa\n            d = self.create_component(config.discriminator, name=\'d_ab\', input=stacked)\n\n            self.za = za\n            self.discriminator = d\n            l = self.create_loss(config.loss, d, xb_input, gb.sample, len(stack))\n            loss1 = l\n            d1_lambda = config.d1_lambda\n            d2_lambda = config.d2_lambda\n            d_loss1 = d1_lambda * l.d_loss\n            g_loss1 = d1_lambda * l.g_loss\n\n            d_vars1 = d.variables()\n\n            d_loss = l.d_loss\n            g_loss = l.g_loss\n\n            metrics = {\n                    \'g_loss\': l.g_loss,\n                    \'d_loss\': l.d_loss\n                }\n\n            if d2_lambda > -1:\n                t0 = xa\n                t1 = gb.sample\n                f0 = zb\n                f1 = za\n                stack = [t0, t1]\n                stacked = ops.concat(stack, axis=0)\n                features = ops.concat([f0, f1], axis=0)\n\n                config.discriminator[\'layer_filter\'] = _append_xa\n                d = self.create_component(config.discriminator, name=\'d2_ab\', input=stacked, features=[features])\n                self.discriminator2 = d\n                l = self.create_loss(config.loss, d, xb_input, gb.sample, len(stack))\n\n                d_vars2 = d.variables()\n                metrics[""gb_gloss""]=l.g_loss\n                metrics[""gb_dloss""]=l.d_loss\n                loss2=l\n                g_loss2 = d2_lambda * loss2.g_loss\n                d_loss2 = d2_lambda * loss2.d_loss\n            else:\n                d_loss2 = 0.0\n                g_loss2 = 0.0\n                d_vars2 = []\n\n            if(config.alpha):\n                t0 = zub\n                t1 = zb\n                netzd = tf.concat(axis=0, values=[t0,t1])\n                z_d = self.create_component(config.z_discriminator, name=\'z_discriminator\', input=netzd)\n\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=xa_input, generator=gb, split=2)\n                d_vars1 += z_d.variables()\n                metrics[""za_gloss""]=loss3.g_loss\n                metrics[""za_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n\n\n            if(config.ug):\n                t0 = xb\n                t1 = ugb\n                netzd = tf.concat(axis=0, values=[t0,t1])\n                z_d = self.create_component(config.discriminator, name=\'ug_discriminator\', input=netzd)\n\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=xa_input, generator=gb, split=2)\n                d_vars1 += z_d.variables()\n                metrics[""za_gloss""]=loss3.g_loss\n                metrics[""za_dloss""]=loss3.d_loss\n                d_loss1 += loss3.d_loss\n                g_loss1 += loss3.g_loss\n\n            if(config.alpha2):\n                t0 = zua\n                t1 = za\n                netzd = tf.concat(axis=0, values=[t0,t1])\n                z_d = self.create_component(config.z_discriminator, name=\'z_discriminator2\', input=netzd)\n\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=xa_input, generator=gb, split=2)\n                d_vars2 += z_d.variables()\n                metrics[""za_gloss""]=loss3.g_loss\n                metrics[""za_dloss""]=loss3.d_loss\n                d_loss2 += loss3.d_loss\n                g_loss2 += loss3.g_loss\n\n            if config.ug2:\n                t0 = xa\n                t1 = ugb\n                netzd = tf.concat(axis=0, values=[t0,t1])\n                z_d = self.create_component(config.discriminator, name=\'ug_discriminator2\', input=netzd)\n\n                loss3 = self.create_component(config.loss, discriminator = z_d, x=xa_input, generator=gb, split=2)\n                d_vars2 += z_d.variables()\n                metrics[""za_gloss""]=loss3.g_loss\n                metrics[""za_dloss""]=loss3.d_loss\n                d_loss2 += loss3.d_loss\n                g_loss2 += loss3.g_loss\n\n\n            loss = hc.Config({\n                \'d_fake\':loss1.d_fake,\n                \'d_real\':loss1.d_real,\n                \'sample\': [tf.add_n([d_loss1, d_loss2]), tf.add_n([g_loss1, g_loss2])]\n            })\n            self._g_vars = gb.variables() + gb.variables()\n            self._d_vars = d_vars1 + d_vars2\n            self.loss=loss\n            self.generator = gb\n            trainer = self.create_component(config.trainer)\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.latent = hc.Config({\'sample\':zb})\n        self.generator = gb\n        self.encoder = gb # this is the other gan\n        self.uniform_distribution = hc.Config({""sample"":zb})#uniform_encoder\n        self.zb = zb\n        self.z_hat = gb.sample\n        self.x_input = xa_input\n\n        self.uga = gb.sample\n        self.ugb = gb.sample\n        self.cyca = gb.sample\n        self.cycb = gb.sample\n        self.xba = gb.sample\n        self.xab = gb.sample\n\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n\n\n    def d_vars(self):\n        return self._d_vars\n    def g_vars(self):\n        return self._g_vars\n\n    def create_discriminator(self, _input, reuse=False):\n        return self.create_component(self.config.discriminator, name=\'d_ab\', input=_input, features=[tf.zeros_like(self.za)], reuse=reuse)\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator, split=split)\n        return loss\n\n    def create_encoder(self, x_input, name=\'input_encoder\'):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int\n        ]\n'"
hypergan/gans/experimental/aligned_ali_one_gan.py,23,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass AlignedAliOneGAN(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `input_encoder` is a discriminator.  It encodes X into Z\n        `discriminator` is a standard discriminator.  It measures X, reconstruction of X, and G.\n        `generator` produces two samples, input_encoder output and a known random distribution.\n        """"""\n        return ""generator discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n\n        with tf.device(self.device):\n            #x_input = tf.identity(self.inputs.x, name=\'input\')\n            xa_input = tf.identity(self.inputs.xa, name=\'xa_i\')\n            xb_input = tf.identity(self.inputs.xb, name=\'xb_i\')\n\n            if config.same_g:\n                ga = self.create_component(config.generator, input=xb_input, name=\'a_generator\')\n                gb = hc.Config({""sample"":ga.reuse(xa_input),""controls"":{""z"":ga.controls[\'z\']}, ""reuse"": ga.reuse})\n            else:\n                ga = self.create_component(config.generator, input=xb_input, name=\'a_generator\')\n                gb = self.create_component(config.generator, input=xa_input, name=\'b_generator\')\n\n            za = ga.controls[""z""]\n            zb = gb.controls[""z""]\n\n            self.uniform_sample = ga.sample\n\n            xba = ga.sample\n            xab = gb.sample\n            xa_hat = ga.reuse(gb.sample)\n            xb_hat = gb.reuse(ga.sample)\n\n            z_shape = self.ops.shape(za)\n            uz_shape = z_shape\n            uz_shape[-1] = uz_shape[-1] // len(config.z_distribution.projections)\n            ue = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n            ue2 = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n            ue3 = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n            ue4 = UniformDistribution(self, config.z_distribution, output_shape=uz_shape)\n            print(\'ue\', ue.sample)\n\n            zua = ue.sample\n            zub = ue2.sample\n\n            uga = ga.reuse(tf.zeros_like(xb_input), replace_controls={""z"":zua})\n            ugb = gb.reuse(tf.zeros_like(xa_input), replace_controls={""z"":zub})\n\n            xa = xa_input\n            xb = xb_input\n\n            t0 = ops.concat([xb, xa], axis=3)\n            t1 = ops.concat([ugb, uga], axis=3)\n            t2 = ops.concat([gb.sample, ga.sample], axis=3)\n            f0 = ops.concat([za, zb], axis=3)\n            f1 = ops.concat([zub, zua], axis=3)\n            f2 = ops.concat([zb, za], axis=3)\n            features = ops.concat([f0, f1, f2], axis=0)\n            stack = [t0, t1, t2]\n\n\n            if config.mess2:\n                xbxa = ops.concat([xb_input, xa_input], axis=3)\n                gbga = ops.concat([gb.sample, ga.sample], axis=3)\n                fa = ops.concat([za, zb], axis=3)\n                fb = ops.concat([za, zb], axis=3)\n                features = ops.concat([fa, fb], axis=0)\n                stack = [xbxa, gbga]\n \n            if config.mess6:\n                t0 = ops.concat([xb, xa], axis=3)\n\n                t1 = ops.concat([gb.sample, uga], axis=3)\n                t2 = ops.concat([gb.sample, xa], axis=3)\n                t3 = ops.concat([xb, ga.sample], axis=3)\n                t4 = ops.concat([ugb, ga.sample], axis=3)\n                features = None\n                stack = [t0, t1, t2, t3, t4]\n\n            if config.mess7:\n                ugb = gb.reuse(tf.zeros_like(xa_input), replace_controls={""z"":zua})\n                t0 = ops.concat([xb, ga.sample], axis=3)\n                t1 = ops.concat([ugb, uga], axis=3)\n                t2 = ops.concat([gb.sample, xa], axis=3)\n                features = None\n                stack = [t0, t1, t2]\n \n            if config.mess8:\n                ugb = gb.reuse(tf.zeros_like(xa_input), replace_controls={""z"":zua})\n                uga2 = ga.reuse(tf.zeros_like(xa_input), replace_controls={""z"":zub})\n                ugb2 = gb.reuse(tf.zeros_like(xa_input), replace_controls={""z"":zub})\n                t0 = ops.concat([xb, ga.sample, xa, gb.sample], axis=3)\n                t1 = ops.concat([ugb, uga, uga2, ugb2], axis=3)\n                features = None\n                stack = [t0, t1]\n\n\n            if config.mess10:\n                t0 = ops.concat([xb, xa], axis=3)\n\n                ugb = gb.reuse(tf.zeros_like(xa_input), replace_controls={""z"":zua})\n                t1 = ops.concat([ugb, uga], axis=3)\n                t2 = ops.concat([gb.sample, xa], axis=3)\n                t3 = ops.concat([xb, ga.sample], axis=3)\n                features = None\n                stack = [t0, t1, t2, t3]\n\n            if config.mess11:\n                t0 = ops.concat([xa, xb, ga.sample, gb.sample], axis=3)\n                ugbga = ga.reuse(ugb)\n                ugagb = gb.reuse(uga)\n\n                t1 = ops.concat([ga.sample, gb.sample, uga, ugb], axis=3)\n                features = None\n                stack = [t0, t1]\n\n            if config.mess12:\n                t0 = ops.concat([xb, xa], axis=3)\n                t2 = ops.concat([gb.sample, ga.sample], axis=3)\n                f0 = ops.concat([za, zb], axis=3)\n                f2 = ops.concat([zua, zub], axis=3)\n                features = ops.concat([f0, f2], axis=0)\n                stack = [t0, t2]\n\n            if config.mess13:\n                ugb = gb.reuse(tf.zeros_like(xa_input), replace_controls={""z"":zua})\n                features = None\n                t0 = ops.concat([xa, gb.sample], axis=3)\n                t1 = ops.concat([ga.sample, xb], axis=3)\n                t2 = ops.concat([uga, ugb], axis=3)\n                stack = [t0, t1, t2]\n\n\n            if config.mess14:\n                features = None\n                t0 = ops.concat([xa, gb.sample], axis=3)\n                t1 = ops.concat([ga.sample, xb], axis=3)\n                stack = [t0, t1]\n\n\n\n\n            stacked = ops.concat(stack, axis=0)\n            d = self.create_component(config.discriminator, name=\'alia_discriminator\', input=stacked, features=[features])\n            l = self.create_loss(config.loss, d, xa_input, ga.sample, len(stack))\n\n            d_vars = d.variables()\n            if config.same_g:\n                g_vars = ga.variables()\n            else:\n                g_vars = ga.variables() + gb.variables()\n\n            d_loss = l.d_loss\n            g_loss = l.g_loss\n\n            metrics = {\n                    \'g_loss\': l.g_loss,\n                    \'d_loss\': l.d_loss\n                }\n\n            if(config.alpha):\n                #t0 = ops.concat([zua,zub], axis=3)\n                #t1 = ops.concat([za,zb], axis=3)\n                t0 = zua\n                t1 = za\n                t2 = zb\n                netzd = tf.concat(axis=0, values=[t0,t1,t2])\n                z_d = self.create_component(config.z_discriminator, name=\'z_discriminator\', input=netzd)\n\n                print(""Z_D"", z_d)\n                lz = self.create_component(config.loss, discriminator = z_d, x=xa_input, generator=ga, split=2)\n                d_loss += lz.d_loss\n                g_loss += lz.g_loss\n                d_vars += z_d.variables()\n                metrics[""a_gloss""]=lz.g_loss\n                metrics[""a_dloss""]=lz.d_loss\n\n            if(config.mess13):\n                t0 = ops.concat([xb, ga.sample], axis=3)\n                t1 = ops.concat([gb.sample, xa], axis=3)\n                t2 = ops.concat([ugb, uga], axis=3)\n                stack = [t0, t1, t2]\n                features = None\n                stacked = tf.concat(axis=0, values=stack)\n                d2 = self.create_component(config.discriminator, name=\'align_2\', input=stacked, features=[features])\n                lz = self.create_loss(config.loss, d2, xa_input, ga.sample, len(stack))\n                d_vars += d2.variables()\n\n                d_loss += lz.d_loss\n                g_loss += lz.g_loss\n                metrics[""mess13_g""]=lz.g_loss\n                metrics[""mess13_d""]=lz.d_loss\n\n            if(config.mess14):\n                t0 = ops.concat([xb, xa], axis=3)\n                t2 = ops.concat([ugb, uga], axis=3)\n                stack = [t0, t2]\n                features = None\n                stacked = tf.concat(axis=0, values=stack)\n                d3 = self.create_component(config.discriminator, name=\'align_3\', input=stacked, features=[features])\n                lz = self.create_loss(config.loss, d3, xa_input, ga.sample, len(stack))\n                d_vars += d3.variables()\n\n                d_loss += lz.d_loss\n                g_loss += lz.g_loss\n                metrics[""mess14_g""]=lz.g_loss\n                metrics[""mess14_d""]=lz.d_loss\n\n\n\n            loss = hc.Config({\'sample\': [d_loss, g_loss], \'metrics\': metrics})\n            trainer = ConsensusTrainer(self, config.trainer, loss = loss, g_vars = g_vars, d_vars = d_vars)\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = ga\n        self.encoder = gb # this is the other gan\n        self.uniform_distribution = hc.Config({""sample"":zb})#uniform_encoder\n        self.zb = zb\n        self.z_hat = gb.sample\n        self.x_input = xa_input\n        self.autoencoded_x = xa_hat\n\n        self.cyca = xa_hat\n        self.cycb = xb_hat\n        self.xba = xba\n        self.xab = xab\n        self.uga = uga\n        self.ugb = ugb\n\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator, split=split)\n        return loss\n\n    def create_encoder(self, x_input, name=\'input_encoder\'):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int\n        ]\n'"
hypergan/gans/experimental/aligned_gan.py,14,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass AlignedGAN(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `input_encoder` is a discriminator.  It encodes X into Z\n        `discriminator` is a standard discriminator.  It measures X, reconstruction of X, and G.\n        `generator` produces two samples, input_encoder output and a known random distribution.\n        """"""\n        return ""generator discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n\n        with tf.device(self.device):\n            #x_input = tf.identity(self.inputs.x, name=\'input\')\n            x_input = tf.identity(self.inputs.xa, name=\'xa_i\')\n            z_input = tf.identity(self.inputs.xb, name=\'xb_i\')\n\n            # q(z|x)\n            encoder = self.create_encoder(x_input)\n\n            self.encoder = encoder\n            z_shape = self.ops.shape(encoder.sample)\n\n            generator = self.create_component(config.generator, input=z_input)\n            self.uniform_sample = generator.sample\n            if ""z"" in generator.controls:\n                z_control = generator.controls[""z""]\n            else:\n                z_control = generator.sample\n            zb = encoder.controls[""z""]\n            x_hat = generator.reuse(encoder.sample)\n            xba = generator.reuse(z_input)\n            xab = encoder.reuse(x_input)\n            cycb = encoder.reuse(xba)\n\n            features_xg = ops.concat([generator.sample, x_input], axis=0)\n            features_zs = ops.concat([encoder.sample, z_input], axis=0)\n            stacked_xg = ops.concat([x_input, generator.sample], axis=0)\n            stacked_zs = ops.concat([z_input, encoder.sample], axis=0)\n\n            standard_discriminator = self.create_component(config.discriminator, name=\'discriminator\', input=stacked_xg, features=[features_zs])\n            z_discriminator = self.create_component(config.discriminator, name=\'z_discriminator\', input=stacked_zs, features=[features_xg])\n            #z_discriminator = self.create_z_discriminator(z_input, encoder.sample)\n            standard_loss = self.create_loss(config.loss, standard_discriminator, x_input, generator, 2)\n\n            encoder_loss = self.create_loss(config.eloss or config.loss, z_discriminator, z_input, encoder, 2)\n\n            trainer = self.create_trainer(None, None, encoder, generator, encoder_loss, standard_loss, standard_discriminator, z_discriminator)\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = generator\n        self.uniform_distribution = hc.Config({""sample"":z_control})#uniform_encoder\n        self.z = z_input\n        self.zb = zb\n        self.z_hat = encoder.sample\n        self.x_input = x_input\n        self.autoencoded_x = x_hat\n\n        self.cyca = x_hat\n        self.cycb = cycb\n        self.xba = xba\n        self.xab = xab\n        self.uga = self.cyca\n        self.ugb = self.cycb\n\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n\n        if hasattr(generator, \'mask_generator\'):\n            self.mask_generator = generator.mask_generator\n            self.mask = mask\n            self.autoencode_mask = generator.mask_generator.sample\n            self.autoencode_mask_3_channel = generator.mask\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator.sample, split=split)\n        return loss\n\n    def create_controls(self, z_shape):\n        direction = tf.random_normal(z_shape, stddev=0.3, name=\'direction\')\n        slider = tf.get_variable(\'slider\', initializer=tf.constant_initializer(0.0), shape=[1, 1], dtype=tf.float32, trainable=False)\n        return direction, slider\n\n    def create_encoder(self, x_input, name=\'input_encoder\'):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def create_trainer(self, cycloss, z_cycloss, encoder, generator, encoder_loss, standard_loss, standard_discriminator, encoder_discriminator):\n\n        metrics = []\n        metrics.append(standard_loss.metrics)\n\n        print(\'ed vars!\', encoder_discriminator.variables())\n        d_vars = standard_discriminator.variables() + encoder_discriminator.variables()\n        g_vars = generator.variables() + encoder.variables()\n        print(""D_VARS"", d_vars)\n        print(""G_VARS"", g_vars)\n        #d_loss = standard_loss.d_loss\n        #g_loss = standard_loss.g_loss + cycloss\n        d_loss = standard_loss.d_loss+encoder_loss.d_loss\n        g_loss = standard_loss.g_loss+encoder_loss.g_loss\n        loss = hc.Config({\'sample\': [d_loss, g_loss], \'metrics\': \n            {\n                \'g_loss\': standard_loss.g_loss,\n                \'e_loss\': encoder_loss.g_loss,\n                \'ed_loss\': encoder_loss.d_loss,\n                \'d_loss\': standard_loss.d_loss\n            }\n        })\n        trainer = ConsensusTrainer(self, self.config.trainer, loss = loss, g_vars = g_vars, d_vars = d_vars)\n        return trainer\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int\n        ]\n'"
hypergan/gans/experimental/alpha_gan.py,24,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass AlphaGAN(BaseGAN):\n    """""" \n      AlphaGAN, or \xce\xb1-GAN from https://arxiv.org/pdf/1706.04987.pdf\n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `input_encoder` is a discriminator.  It encodes X into Z\n        `z_discriminator` is another discriminator.  It takes as input the output of input_encoder and z\n        `discriminator` is a standard discriminator.  It measures X, reconstruction of X, and G.\n        `generator` produces two samples, input_encoder output and a known random distribution.\n        """"""\n        return ""generator discriminator z_discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n\n        with tf.device(self.device):\n            x_input = tf.identity(self.inputs.x, name=\'input\')\n\n            encoder = self.create_encoder(x_input)\n            self.encoder = encoder\n            z_shape = self.ops.shape(encoder.sample)\n\n            uz_shape = z_shape\n            uz_shape[-1] = uz_shape[-1] // len(config.encoder.projections)\n            latent = UniformDistribution(self, config.encoder, output_shape=uz_shape)\n            direction, slider = self.create_controls(self.ops.shape(latent.sample))\n            z = latent.sample + slider * direction\n            \n            #projected_encoder = UniformDistribution(self, config.encoder, z=encoder.sample)\n\n            z_discriminator = self.create_z_discriminator(latent.sample, encoder.sample)\n\n            feature_dim = len(ops.shape(z))-1\n            #stack_z = tf.concat([encoder.sample, z], feature_dim)\n            #stack_encoded = tf.concat([encoder.sample, encoder.sample], feature_dim)\n            stack_z = z\n\n            generator = self.create_component(config.generator, input=stack_z)\n            self.uniform_sample = generator.sample\n            x_hat = generator.reuse(encoder.sample)\n\n            if hasattr(generator, \'mask_single_channel\'):\n                mask = generator.mask_single_channel\n\n            encoder_loss = self.create_loss(config.eloss or config.loss, z_discriminator, z, encoder, 2)\n            if config.segments_included:\n                newsample = generator.reuse(stack_z, mask=generator.mask_single_channel)\n#                stacked = [x_input, generator.sample, newsample, x_hat]\n                stacked = [x_input, newsample, generator.sample, x_hat, generator.g1x, generator.g2x, generator.g3x]\n                #stacked = [x_input, g1x, g2x, newsample, generator.sample, x_hat]\n                #stacked = [x_input, newsample, generator.sample, x_hat]\n            elif config.simple_d:\n                stacked = [x_input, self.uniform_sample]\n            else:\n                stacked = [x_input, self.uniform_sample, x_hat]\n\n            stacked_xg = ops.concat(stacked, axis=0)\n            standard_discriminator = self.create_component(config.discriminator, name=\'discriminator\', input=stacked_xg)\n            standard_loss = self.create_loss(config.loss, standard_discriminator, x_input, generator, len(stacked))\n            self.loss = standard_loss\n\n            #loss terms\n            cycloss = self.create_cycloss(x_input, x_hat)\n            z_cycloss = self.create_z_cycloss(latent.sample, encoder.sample, encoder, generator)\n\n            #first_pixel = tf.slice(generator.mask_single_channel, [0,0,0,0], [-1,1,1,-1]) + 1 # we want to minimize range -1 to 1\n            #cycloss += tf.reduce_sum(tf.reshape(first_pixel, [-1]), axis=0)\n\n            if hasattr(generator, \'mask\'): #TODO only segment\n                cycloss_whitening_lambda = config.cycloss_whitening_lambda or 0.01\n                cycloss += tf.reduce_mean(tf.reshape(0.5-tf.abs(generator.mask-0.5), [-1]), axis=0) * cycloss_whitening_lambda\n\n            #if hasattr(generator, \'mask\'): # TODO only multisegment\n            #    cycloss_single_channel_lambda = config.cycloss_single_channel_lambda or 0.01\n            #    m = tf.reduce_sum(generator.mask, 3)\n            #    cycloss += tf.reduce_mean(tf.reshape(tf.abs(1.0-m)/ops.shape(generator.mask)[3], [-1]), axis=0) * cycloss_single_channel_lambda\n            if hasattr(generator, \'mask\'): # TODO only multisegment\n            #    cycloss_single_channel_lambda = config.cycloss_single_channel_lambda or 0.01\n                m = tf.reduce_mean(generator.mask, 1, keep_dims=True)\n                m = tf.reduce_mean(m, 2, keep_dims=True)\n                c = 0.1\n                cycloss += (c - tf.minimum(tf.reduce_min(m, 3, keep_dims=True), c))\n            #    cycloss += tf.reduce_mean(tf.reshape(tf.abs(1.0-m)/ops.shape(generator.mask)[3], [-1]), axis=0) * cycloss_single_channel_lambda\n\n            trainer = self.create_trainer(cycloss, z_cycloss, encoder, generator, encoder_loss, standard_loss, standard_discriminator, z_discriminator)\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = generator\n        self.uniform_distribution = uniform_encoder\n        self.slider = slider\n        self.direction = direction\n        self.z = z\n        self.z_hat = encoder.sample\n        self.x_input = x_input\n        self.autoencoded_x = x_hat\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n        self.random_z = tf.random_uniform(ops.shape(UniformDistribution.sample), -1, 1, name=\'random_z\')\n\n        if hasattr(generator, \'mask_generator\'):\n            self.mask_generator = generator.mask_generator\n            self.mask = mask\n            self.autoencode_mask = generator.mask_generator.sample\n            self.autoencode_mask_3_channel = generator.mask\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator.sample, split=split)\n        return loss\n\n    def create_controls(self, z_shape):\n        direction = tf.random_normal(z_shape, stddev=0.3, name=\'direction\')\n        slider = tf.get_variable(\'slider\', initializer=tf.constant_initializer(0.0), shape=[1, 1], dtype=tf.float32, trainable=False)\n        return direction, slider\n\n    def create_encoder(self, x_input, name=\'input_encoder\'):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.discriminator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def create_trainer(self, cycloss, z_cycloss, encoder, generator, encoder_loss, standard_loss, standard_discriminator, encoder_discriminator):\n        if z_cycloss is not None:\n            loss1=(\'generator encoder\', z_cycloss + cycloss + encoder_loss.g_loss)\n            loss2=(\'generator image\', z_cycloss + cycloss + standard_loss.g_loss)\n            loss3=(\'discriminator image\', standard_loss.d_loss)\n            loss4=(\'discriminator encoder\', encoder_loss.d_loss)\n        else:\n            loss1=(\'generator encoder\', cycloss + encoder_loss.g_loss)\n            loss2=(\'generator image\',cycloss + standard_loss.g_loss)\n            loss3=(\'discriminator image\', standard_loss.d_loss)\n            loss4=(\'discriminator encoder\', encoder_loss.d_loss)\n\n        var_lists = []\n        var_lists.append(encoder.variables())\n        var_lists.append(generator.variables())\n        var_lists.append(standard_discriminator.variables())\n        var_lists.append(encoder_discriminator.variables())\n\n        metrics = []\n        metrics.append(None)\n        metrics.append(None)\n        metrics.append(standard_loss.metrics)\n        metrics.append(encoder_loss.metrics)\n\n        trainer = self.create_component(self.config.trainer)\n        return trainer\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input,\n                self.slider, \n                self.direction,\n                self.uniform_distribution.sample\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int,\n                self.random_z\n        ]\n'"
hypergan/gans/experimental/autoencoder_gan.py,3,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..standard_gan import StandardGAN\nfrom ..base_gan import BaseGAN\n\nclass AutoencoderGAN(StandardGAN):\n    """""" \n    """"""\n\n    def required(self):\n        return ""generator"".split()\n\n    def create(self):\n        config = self.config\n\n        d2 = dict(config.discriminator)\n        d2[\'class\'] = self.ops.lookup(""class:hypergan.discriminators.pyramid_discriminator.PyramidDiscriminator"")\n        self.encoder = self.create_component(d2)\n        self.encoder.ops.describe(""encoder"")\n        self.encoder.create(self.inputs.x)\n        self.encoder.z = tf.zeros(0)\n        self.trainer = self.create_component(config.trainer)\n\n        StandardGAN.create(self)\n        cycloss = tf.reduce_mean(tf.abs(self.inputs.x-self.generator.sample))\n        cycloss_lambda = config.cycloss_lambda or 10\n        self.loss.sample[1] *= config.g_lambda or 1\n        self.loss.sample[1] += cycloss*cycloss_lambda\n        self.trainer.create()\n\n        self.session.run(tf.global_variables_initializer())\n\n'"
hypergan/gans/experimental/conditional_gan.py,15,"b'\nimport importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\nfrom hypergan.trainers.experimental.consensus_trainer import ConsensusTrainer\n\nclass ConditionalGAN(BaseGAN):\n    """""" \n    """"""\n    def __init__(self, *args, **kwargs):\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        """"""\n        `input_encoder` is a discriminator.  It encodes X into Z\n        `discriminator` is a standard discriminator.  It measures X, reconstruction of X, and G.\n        `generator` produces two samples, input_encoder output and a known random distribution.\n        """"""\n        return ""generator discriminator "".split()\n\n    def create(self):\n        config = self.config\n        ops = self.ops\n\n        with tf.device(self.device):\n            #x_input = tf.identity(self.inputs.x, name=\'input\')\n            xa_input = tf.identity(self.inputs.xa, name=\'xa_i\')\n            xb_input = tf.identity(self.inputs.xb, name=\'xb_i\')\n\n            def random_like(x):\n                return UniformDistribution(self, config.z_distribution, output_shape=self.ops.shape(x)).sample\n            #y=a\n            #x=b\n            zgx = self.create_component(config.encoder, input=xa_input, name=\'xa_to_x\')\n            zgy = self.create_component(config.encoder, input=xb_input, name=\'xb_to_y\')\n            zx = zgx.sample\n            zy = zgy.sample\n\n            z_noise = random_like(zx)\n            n_noise = random_like(zx)\n            if config.style:\n                stylex = self.create_component(config.style_discriminator, input=xb_input, name=\'xb_style\')\n                styley = self.create_component(config.style_discriminator, input=xa_input, name=\'xa_style\')\n                zy = tf.concat(values=[zy, z_noise], axis=3)\n                zx = tf.concat(values=[zx, n_noise], axis=3)\n                gy = self.create_component(config.generator, features=[styley.sample], input=zy, name=\'gy_generator\')\n                y = hc.Config({""sample"": xa_input})\n                zx = self.create_component(config.encoder, input=y.sample, name=\'xa_to_x\', reuse=True).sample\n                zx = tf.concat(values=[zx, z_noise], axis=3)\n                gx = self.create_component(config.generator, features=[stylex.sample], input=zx, name=\'gx_generator\')\n            else:\n                gy = self.create_component(config.generator, features=[z_noise], input=zy, name=\'gy_generator\')\n                y = hc.Config({""sample"": xa_input})\n                zx = self.create_component(config.encoder, input=y.sample, name=\'xa_to_x\', reuse=True).sample\n                gx = self.create_component(config.generator, features=[z_noise], input=zx, name=\'gx_generator\')\n                stylex=hc.Config({""sample"":random_like(y.sample)})\n\n            self.y = y\n            self.gy = gy\n            self.gx = gx\n\n            ga = gy\n            gb = gx\n\n            self.uniform_sample = gb.sample\n\n            xba = ga.sample\n            xab = gb.sample\n            xa_hat = ga.reuse(zx)\n            xb_hat = gb.reuse(zy)\n            xa = xa_input\n            xb = xb_input\n\n            self.styleb = stylex\n            self.random_style = random_like(stylex.sample)\n\n\n\n            t0 = xb\n            t1 = gx.sample\n            f0 = gy.sample\n            f1 = y.sample\n            stack = [t0, t1]\n            stacked = ops.concat(stack, axis=0)\n            features = ops.concat([f0, f1], axis=0)\n            self.inputs.x = xa\n            ugb = gb.reuse(random_like(zy))\n            zub = zy\n            sourcezub = zy\n\n\n            d = self.create_component(config.discriminator, name=\'d_ab\', \n                    input=stacked, features=[features])\n            l = self.create_loss(config.loss, d, xa_input, ga.sample, len(stack))\n            loss1 = l\n            d_loss1 = l.d_loss\n            g_loss1 = l.g_loss\n\n            d_vars1 = d.variables()\n            g_vars1 = gb.variables()+ga.variables()+zgx.variables()+zgy.variables()\n\n            d_loss = l.d_loss\n            g_loss = l.g_loss\n\n\n            metrics = {\n                    \'g_loss\': l.g_loss,\n                    \'d_loss\': l.d_loss\n                }\n\n\n            trainers = []\n\n            lossa = hc.Config({\'sample\': [d_loss1, g_loss1], \'metrics\': metrics})\n            #lossb = hc.Config({\'sample\': [d_loss2, g_loss2], \'metrics\': metrics})\n            trainers += [ConsensusTrainer(self, config.trainer, loss = lossa, g_vars = g_vars1, d_vars = d_vars1)]\n            #trainers += [ConsensusTrainer(self, config.trainer, loss = lossb, g_vars = g_vars2, d_vars = d_vars2)]\n            trainer = MultiTrainerTrainer(trainers)\n            self.session.run(tf.global_variables_initializer())\n\n        self.trainer = trainer\n        self.generator = gb\n        self.encoder = hc.Config({""sample"":ugb}) # this is the other gan\n        self.uniform_distribution = hc.Config({""sample"":zub})#uniform_encoder\n        self.uniform_distribution_source = hc.Config({""sample"":sourcezub})#uniform_encoder\n        self.zb = zy\n        self.z_hat = gb.sample\n        self.x_input = xa_input\n        self.autoencoded_x = xb_hat\n\n        self.cyca = xa_hat\n        self.cycb = xb_hat\n        self.xba = xba\n        self.xab = xab\n        self.uga = y.sample\n        self.ugb = ugb\n\n        rgb = tf.cast((self.generator.sample+1)*127.5, tf.int32)\n        self.generator_int = tf.bitwise.bitwise_or(rgb, 0xFF000000, name=\'generator_int\')\n\n\n    def create_loss(self, loss_config, discriminator, x, generator, split):\n        loss = self.create_component(loss_config, discriminator = discriminator, x=x, generator=generator, split=split)\n        return loss\n\n    def create_encoder(self, x_input, name=\'input_encoder\'):\n        config = self.config\n        input_encoder = dict(config.input_encoder or config.g_encoder or config.generator)\n        encoder = self.create_component(input_encoder, name=name, input=x_input)\n        return encoder\n\n    def create_z_discriminator(self, z, z_hat):\n        config = self.config\n        z_discriminator = dict(config.z_discriminator or config.discriminator)\n        z_discriminator[\'layer_filter\']=None\n        net = tf.concat(axis=0, values=[z, z_hat])\n        encoder_discriminator = self.create_component(z_discriminator, name=\'z_discriminator\', input=net)\n        return encoder_discriminator\n\n    def create_cycloss(self, x_input, x_hat):\n        config = self.config\n        ops = self.ops\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        pe_layers = self.gan.skip_connections.get_array(""progressive_enhancement"")\n        cycloss_lambda = config.cycloss_lambda\n        if cycloss_lambda is None:\n            cycloss_lambda = 10\n        \n        if(len(pe_layers) > 0):\n            mask = self.progressive_growing_mask(len(pe_layers)//2+1)\n            cycloss = tf.reduce_mean(distance(mask*x_input,mask*x_hat))\n\n            cycloss *= mask\n        else:\n            cycloss = tf.reduce_mean(distance(x_input, x_hat))\n\n        cycloss *= cycloss_lambda\n        return cycloss\n\n\n    def create_z_cycloss(self, z, x_hat, encoder, generator):\n        config = self.config\n        ops = self.ops\n        total = None\n        distance = config.distance or ops.lookup(\'l1_distance\')\n        if config.z_hat_lambda:\n            z_hat_cycloss_lambda = config.z_hat_cycloss_lambda\n            recode_z_hat = encoder.reuse(x_hat)\n            z_hat_cycloss = tf.reduce_mean(distance(z_hat,recode_z_hat))\n            z_hat_cycloss *= z_hat_cycloss_lambda\n        if config.z_cycloss_lambda:\n            recode_z = encoder.reuse(generator.reuse(z))\n            z_cycloss = tf.reduce_mean(distance(z,recode_z))\n            z_cycloss_lambda = config.z_cycloss_lambda\n            if z_cycloss_lambda is None:\n                z_cycloss_lambda = 0\n            z_cycloss *= z_cycloss_lambda\n\n        if config.z_hat_lambda and config.z_cycloss_lambda:\n            total = z_cycloss + z_hat_cycloss\n        elif config.z_cycloss_lambda:\n            total = z_cycloss\n        elif config.z_hat_lambda:\n            total = z_hat_cycloss\n        return total\n\n\n\n    def input_nodes(self):\n        ""used in hypergan build""\n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [self.mask_generator.sample]\n        else:\n            extras = []\n        return extras + [\n                self.x_input\n        ]\n\n\n    def output_nodes(self):\n        ""used in hypergan build""\n\n    \n        if hasattr(self.generator, \'mask_generator\'):\n            extras = [\n                self.mask_generator.sample, \n                self.generator.g1x,\n                self.generator.g2x\n            ]\n        else:\n            extras = []\n        return extras + [\n                self.encoder.sample,\n                self.generator.sample, \n                self.uniform_sample,\n                self.generator_int\n        ]\n'"
hypergan/gans/experimental/multi_generator_gan.py,17,"b'import importlib\nimport json\nimport numpy as np\nimport os\nimport sys\nimport time\nimport uuid\nimport copy\n\nfrom hypergan.discriminators import *\nfrom hypergan.distributions import *\nfrom hypergan.generators import *\nfrom hypergan.inputs import *\nfrom hypergan.samplers import *\nfrom hypergan.trainers import *\n\nimport hyperchamber as hc\nfrom hyperchamber import Config\nfrom hypergan.ops import TensorflowOps\nimport tensorflow as tf\nimport hypergan as hg\n\nfrom hypergan.gan_component import ValidationException, GANComponent\nfrom ..base_gan import BaseGAN\n\nfrom hypergan.distributions.uniform_distribution import UniformDistribution\n\nclass MultiGeneratorGAN(BaseGAN):\n    """""" \n    https://arxiv.org/pdf/1708.02556v2.pdf\n    """"""\n    def __init__(self, *args, **kwargs):\n        self.discriminator = None\n        self.encoder = None\n        self.generator = None\n        self.loss = None\n        self.trainer = None\n        self.session = None\n        BaseGAN.__init__(self, *args, **kwargs)\n\n    def required(self):\n        return ""generator discriminator number_generators"".split()\n\n    def create(self):\n        BaseGAN.create(self)\n        if self.session is None: \n            self.session = self.ops.new_session(self.ops_config)\n        with tf.device(self.device):\n            config = self.config\n            print(config)\n            print(""________"")\n            ops = self.ops\n\n\n            self.encoder = self.create_component(config.encoder)\n            self.encoder.create()\n            generator_samples = []\n            config.generator.skip_linear = True\n\n            print(""!!!!!!!!!!!!!!!!!!!!!!! Creataing generator"", config.generator)\n            generator = self.create_component(config.generator)\n            generator.ops.describe(""generator"")\n            self.generator = generator\n            for i in range(config.number_generators):\n                primes = config.generator.initial_dimensions or [4, 4]\n                initial_depth = generator.depths(primes[0])[0]\n                net = ops.reshape(self.encoder.sample, [ops.shape(self.encoder.sample)[0], -1])\n                new_shape = [ops.shape(net)[0], primes[0], primes[1], initial_depth]\n                net = ops.linear(net, initial_depth*primes[0]*primes[1])\n                pi = ops.reshape(net, new_shape)\n         \n                #pi = tf.zeros([self.batch_size(), primes[0], primes[1], 256])\n                print(""[MultiGeneratorGAN] Creating generator "", i, pi)\n                if i == 0:\n                    gi = generator.create(pi)\n                else:\n                    gi = generator.reuse(pi)\n                generator_samples.append(gi)\n \n            self.discriminator = self.create_component(config.discriminator)\n            self.discriminator.ops.describe(""discriminator"")\n\n            losses = []\n            self.loss = self\n\n            self.loss = self.create_component(config.loss)\n\n            g_loss = tf.constant(0.0)\n            d_loss = tf.constant(0.0)\n            metrics = []\n            d_fake_features = []\n\n            for i in range(config.number_generators):\n                if i == 0:\n                    di = self.discriminator.create(x=self.inputs.x, g=generator_samples[i])\n                else:\n                    di = self.discriminator.reuse(x=self.inputs.x, g=generator_samples[i])\n                d_real, d_fake = self.split_batch(di, 2)\n                # after the divergence measure or before ? TODO\n                #d_fake_features.append(self.discriminator.g_loss_features)\n                d_fake_features.append(d_fake)\n\n                loss = self.loss.create(d_real=d_real, d_fake=d_fake)\n                losses.append(loss)\n                g_loss += loss[1]\n                d_loss += loss[0]\n\n            var_lists = []\n            steps = []\n\n            if config.class_loss_type == \'svm\':\n                # classifier loss \n                for i in range(config.number_generators):\n                    features = tf.reshape(d_fake_features[i], [self.batch_size(), -1])\n                    c_loss = ops.lookup(\'crelu\')(features)\n                    print(""C LOSS 1"", c_loss)\n                    c_loss = ops.linear(c_loss, config.number_generators)\n                    label = tf.one_hot([i], config.number_generators)\n                    label = tf.tile(label, [self.batch_size(), 1])\n                    c_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=c_loss, labels=label)\n            \n                    g_loss += c_loss*(config.c_loss_lambda or 1)\n                metrics.append({""class loss"": self.ops.squash(c_loss)})\n                metrics.append(self.loss.metrics)\n\n\n                var_lists.append(self.generator.variables() + self.variables())\n                var_lists.append(self.discriminator.variables())\n                steps = [(\'generator\', g_loss), (\'discriminator\', d_loss)]\n\n            if config.class_loss_type == \'gan\':\n                d2 = None\n                g2 = None\n                l2 = None\n                d2_loss_sum = tf.constant(0.)\n                g2_loss_sum = tf.constant(0.)\n\n                var_lists.append(self.generator.variables() + self.variables())\n                var_lists.append(self.discriminator.variables())\n                # classifier as gan loss \n                for i in range(config.number_generators):\n                    if i != 0:\n                        self.ops.reuse()\n                    features = tf.reshape(d_fake_features[i], [self.batch_size(), -1])\n                    label = tf.one_hot([i], config.number_generators)\n                    label = tf.tile(label, [self.batch_size(), 1])\n\n                    # D2(G2(gx), label)\n                    g2config = dict(config.generator2)\n                    g2 = self.create_component(g2config)\n                    # this is the generator\n                    g2.ops.describe(""G2"")\n\n                    if i == 0:\n                        g2sample = g2.create(tf.concat(generator_samples, axis=3))\n                    else:\n                        g2sample = g2.reuse(tf.concat(generator_samples, axis=3))\n\n\n                    d2config = dict(config.discriminator2)\n                    d2 = self.create_component(d2config)\n\n                    d2.ops.describe(""D2"")\n                    if i == 0:\n                        d2.create(x=label, g=g2sample)\n                        var_lists.append(g2.variables())\n                        var_lists.append(d2.variables())\n                    else:\n                        d2.reuse(x=label, g=g2sample)\n\n                    l2config = dict(config.loss)\n                    l2 = self.create_component(l2config,discriminator=d2, generator=g2)\n                    d2_loss, g2_loss = l2.create()\n\n                    g2_loss_sum += g2_loss\n                    d2_loss_sum += d2_loss\n\n                    if i != 0:\n                        self.ops.stop_reuse()\n\n\n                steps = [\n                        (\'generator 1\', g_loss + g2_loss_sum), \n                        (\'discriminator 1\', d_loss),\n                        (\'generator 2\', g2_loss_sum + g_loss), \n                        (\'discriminator 2\', d2_loss)\n                ]\n\n                metrics.append(None)\n                metrics.append(self.loss.metrics)\n                metrics.append(None)\n                metrics.append(l2.metrics)\n\n\n\n            print(""T"", self.config.trainer, steps, metrics)\n            self.trainer = MultiStepTrainer(self, self.config.trainer, steps, var_lists=var_lists, metrics=metrics)\n            self.trainer.create()\n\n            self.session.run(tf.global_variables_initializer())\n            self.uniform_sample = tf.concat(generator_samples, axis=1)\n\n'"
hypergan/generators/experimental/fully_connected_generator.py,0,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nfrom hypergan.generators.common import *\n\nfrom ..base_generator import BaseGenerator\n\nclass FullyConnectedGenerator(BaseGenerator):\n\n    def required(self):\n        return []\n\n    def build(self, net):\n        gan = self.gan\n        ops = self.ops\n        config = self.config\n        activation = ops.lookup(config.activation or \'lrelu\')\n\n        print(""[dcgan] NET IS"", net)\n\n        net = ops.linear(net, 1024)\n\n        shape = ops.shape(net)\n        x_shape = ops.shape(self.gan.inputs.x)\n        output_size = x_shape[1]*x_shape[2]*x_shape[3]\n        print(""Output size"", output_size)\n\n        net = activation(net)\n        net = ops.linear(net, 2*1024)\n        net = activation(net)\n        net = ops.linear(net, output_size)\n        net = ops.lookup(\'tanh\')(net)\n\n        net = ops.reshape(net, output_size)\n\n        self.sample = net\n        return self.sample\n'"
hypergan/inputs/experimental/audio_loader.py,13,"b'import glob\nimport tensorflow as tf\nimport hypergan.inputs.resize_audio_patch\nfrom tensorflow.contrib import ffmpeg\n\nclass AudioLoader:\n    def build_labels(dirs):\n      next_id=0\n      labels = {}\n      for dir in dirs:\n        labels[dir.split(\'/\')[-1]]=next_id\n        next_id+=1\n      return labels,next_id\n    def mp3_tensors_from_directory(directory, batch_size, channels=2, format=\'mp3\', seconds=30, bitrate=16384):\n      filenames = glob.glob(directory+""/**/*.""+format)\n      labels,total_labels = build_labels(sorted(glob.glob(directory+""/*"")))\n      num_examples_per_epoch = 10000\n\n      # Create a queue that produces the filenames to read.\n      classes = [labels[f.split(\'/\')[-2]] for f in filenames]\n      print(""Found files"", len(filenames))\n\n      filenames = tf.convert_to_tensor(filenames, dtype=tf.string)\n      classes = tf.convert_to_tensor(classes, dtype=tf.int32)\n      print(""[0]"", filenames[0], classes[0])\n\n      input_queue = tf.train.slice_input_producer([filenames, classes])\n\n      # Read examples from files in the filename queue.\n      print(""INPUT_QUEUE"", input_queue[0])\n      value = tf.read_file(input_queue[0])\n      #preprocess = tf.read_file(input_queue[0]+\'.preprocess\')\n\n      print(""Preloaded data"", value)\n      #print(""Loaded data"", data)\n\n      label = input_queue[1]\n\n      min_fraction_of_examples_in_queue = 0.4\n      min_queue_examples = int(num_examples_per_epoch *\n                               min_fraction_of_examples_in_queue)\n\n      #data = tf.cast(data, tf.float32)\n      data = ffmpeg.decode_audio(value, file_format=format, samples_per_second=bitrate, channel_count=channels)\n      data = shared.resize_audio_patch.resize_audio_with_crop_or_pad(data, seconds*bitrate*channels, 0,True)\n      #data = tf.slice(data, [0,0], [seconds*bitrate, channels])\n      tf.Tensor.set_shape(data, [seconds*bitrate, channels])\n      #data = tf.minimum(data, 1)\n      #data = tf.maximum(data, -1)\n      data = data/tf.reduce_max(tf.reshape(tf.abs(data),[-1]))\n      print(""DATA IS"", data)\n      x,y=_get_data(data, label, min_queue_examples, batch_size)\n\n      return x, y, total_labels, num_examples_per_epoch\n\n\n    def _get_data(image, label, min_queue_examples, batch_size):\n      num_preprocess_threads = 1\n      print(image, label)\n      images, label_batch= tf.train.shuffle_batch(\n          [image, label],\n          batch_size=batch_size,\n          num_threads=num_preprocess_threads,\n          capacity= 502,\n          min_after_dequeue=128)\n      return images, tf.reshape(label_batch, [batch_size])\n\n'"
hypergan/inputs/experimental/resize_audio_patch.py,5,"b'\n# coding: utf-8\n\n# In[1]:\n\nfrom tensorflow.python.ops import image_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import array_ops\n\ndef crop_to_1d_bounding_box(image, offset_height, target_height,\n                         dynamic_shape=False):\n  """"""Crops an image to a specified bounding box.\n\n  This op cuts a rectangular part out of `image`. The top-left corner of the\n  returned image is at `offset_height, offset_width` in `image`, and its\n  lower-right corner is at\n  `offset_height + target_height, offset_width + target_width`.\n\n  Args:\n    image: 3-D tensor with shape `[height, width, channels]`\n    offset_height: Vertical coordinate of the top-left corner of the result in\n                   the input.\n    target_height: Height of the result.\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Returns:\n    3-D tensor of image with shape `[target_height, target_width, channels]`\n\n  Raises:\n    ValueError: If the shape of `image` is incompatible with the `offset_*` or\n    `target_*` arguments, and `dynamic_shape` is set to `False`.\n  """"""\n  image = tf.convert_to_tensor(image, name=\'image\')\n  height, _ = _ImageDimensions(image, dynamic_shape=dynamic_shape)\n\n  cropped = array_ops.slice(image,\n                            array_ops.pack([offset_height, 0]),\n                            array_ops.pack([target_height, -1]))\n\n  return cropped\n\ndef pad_to_1d_bounding_box(image, offset_height, target_height,\n                        dynamic_shape=False):\n  """"""Pad `image` with zeros to the specified `height` and `width`.\n\n  Adds `offset_height` rows of zeros on top, `offset_width` columns of\n  zeros on the left, and then pads the image on the bottom and right\n  with zeros until it has dimensions `target_height`, `target_width`.\n\n  This op does nothing if `offset_*` is zero and the image already has size\n  `target_height` by `target_width`.\n\n  Args:\n    image: 3-D tensor with shape `[height, width, channels]`\n    offset_height: Number of rows of zeros to add on top.\n    offset_width: Number of columns of zeros to add on the left.\n    target_height: Height of output image.\n    target_width: Width of output image.\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Returns:\n    3-D tensor of shape `[target_height, target_width, channels]`\n  Raises:\n    ValueError: If the shape of `image` is incompatible with the `offset_*` or\n      `target_*` arguments, and `dynamic_shape` is set to `False`.\n  """"""\n  image = tf.convert_to_tensor(image, name=\'image\')\n  height, depth = _ImageDimensions(image, dynamic_shape=dynamic_shape)\n\n  after_padding_height = target_height - offset_height - height\n\n  if not dynamic_shape:\n    if target_height < height:\n      raise ValueError(\'target_height must be >= height\')\n\n    if after_padding_height < 0:\n      raise ValueError(\'target_height not possible given \'\n                       \'offset_height and image height\')\n\n  # Do not pad on the depth dimensions.\n  if (dynamic_shape or offset_height or\n      after_padding_height):\n    paddings = array_ops.reshape(\n      array_ops.pack([offset_height, after_padding_height,\n                      0, 0]),\n      [2, 2])\n    padded = array_ops.pad(image, paddings)\n    if not dynamic_shape:\n      padded.set_shape([target_height, depth])\n  else:\n    padded = image\n\n  return padded\n\n\n\n\n\n# In[2]:\n\ndef crop_to_bounding_box(image, offset_height, offset_width, target_height,\n                         target_width, dynamic_shape=False):\n  """"""Crops an image to a specified bounding box.\n\n  This op cuts a rectangular part out of `image`. The top-left corner of the\n  returned image is at `offset_height, offset_width` in `image`, and its\n  lower-right corner is at\n  `offset_height + target_height, offset_width + target_width`.\n\n  Args:\n    image: 3-D tensor with shape `[height, width, channels]`\n    offset_height: Vertical coordinate of the top-left corner of the result in\n                   the input.\n    offset_width: Horizontal coordinate of the top-left corner of the result in\n                  the input.\n    target_height: Height of the result.\n    target_width: Width of the result.\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Returns:\n    3-D tensor of image with shape `[target_height, target_width, channels]`\n\n  Raises:\n    ValueError: If the shape of `image` is incompatible with the `offset_*` or\n    `target_*` arguments, and `dynamic_shape` is set to `False`.\n  """"""\n  image = tf.convert_to_tensor(image, name=\'image\')\n  _Check3DImage(image, require_static=(not dynamic_shape))\n  shapes = _ImageDimensions(image, dynamic_shape=dynamic_shape)\n\n  cropped = array_ops.slice(image,\n                            array_ops.pack([offset_height, 0]),\n                            array_ops.pack([target_height, -1]))\n\n  return cropped\n\n\n# In[3]:\n\ndef pad_to_bounding_box(image, offset_height, offset_width, target_height,\n                        target_width, dynamic_shape=False):\n  """"""Pad `image` with zeros to the specified `height` and `width`.\n\n  Adds `offset_height` rows of zeros on top, `offset_width` columns of\n  zeros on the left, and then pads the image on the bottom and right\n  with zeros until it has dimensions `target_height`, `target_width`.\n\n  This op does nothing if `offset_*` is zero and the image already has size\n  `target_height` by `target_width`.\n\n  Args:\n    image: 3-D tensor with shape `[height, width, channels]`\n    offset_height: Number of rows of zeros to add on top.\n    offset_width: Number of columns of zeros to add on the left.\n    target_height: Height of output image.\n    target_width: Width of output image.\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Returns:\n    3-D tensor of shape `[target_height, target_width, channels]`\n  Raises:\n    ValueError: If the shape of `image` is incompatible with the `offset_*` or\n      `target_*` arguments, and `dynamic_shape` is set to `False`.\n  """"""\n  image = tf.convert_to_tensor(image, name=\'image\')\n  _Check3DImage(image, require_static=(not dynamic_shape))\n  height, width, depth = _ImageDimensions(image, dynamic_shape=dynamic_shape)\n\n  after_padding_width = target_width - offset_width - width\n  after_padding_height = target_height - offset_height - height\n\n  if not dynamic_shape:\n    if target_width < width:\n      raise ValueError(\'target_width must be >= width\')\n    if target_height < height:\n      raise ValueError(\'target_height must be >= height\')\n\n    if after_padding_width < 0:\n      raise ValueError(\'target_width not possible given \'\n                       \'offset_width and image width\')\n    if after_padding_height < 0:\n      raise ValueError(\'target_height not possible given \'\n                       \'offset_height and image height\')\n\n  # Do not pad on the depth dimensions.\n  if (dynamic_shape or offset_width or offset_height or\n      after_padding_width or after_padding_height):\n    paddings = array_ops.reshape(\n      array_ops.pack([offset_height, after_padding_height,\n                      offset_width, after_padding_width,\n                      0, 0]),\n      [3, 2])\n    padded = array_ops.pad(image, paddings)\n    if not dynamic_shape:\n      padded.set_shape([target_height, target_width, depth])\n  else:\n    padded = image\n\n  return padded\n\n\n# In[4]:\n\ndef resize_audio_with_crop_or_pad(image, target_height, target_width,\n                                  dynamic_shape=False):\n  image = tf.convert_to_tensor(image, name=\'audio\')\n  original_height,  _ =     _ImageDimensions(image, dynamic_shape=dynamic_shape)\n\n  if target_height <= 0:\n    raise ValueError(\'target_height must be > 0.\')\n\n  if dynamic_shape:\n    max_ = math_ops.maximum\n    min_ = math_ops.minimum\n  else:\n    max_ = max\n    min_ = min\n\n  height_diff = target_height - original_height\n  offset_crop_height = max_(-height_diff // 2, 0)\n  offset_pad_height = max_(height_diff // 2, 0)\n\n  # Maybe crop if needed.\n  cropped = crop_to_1d_bounding_box(image, offset_crop_height,\n                                 min_(target_height, original_height),\n                                 dynamic_shape=dynamic_shape)\n\n  # Maybe pad if needed.\n  resized = pad_to_1d_bounding_box(cropped, offset_pad_height, \n                                target_height, \n                                dynamic_shape=dynamic_shape)\n\n  if resized.get_shape().ndims is None:\n    raise ValueError(\'resized contains no shape.\')\n  if not resized.get_shape()[0].is_compatible_with(target_height):\n    raise ValueError(\'resized height is not correct.\')\n  return resized\n\n\n# In[5]:\n\ndef _ImageDimensions(images, dynamic_shape=False):\n  """"""Returns the dimensions of an image tensor.\n  Args:\n    images: 4-D Tensor of shape [batch, height, width, channels]\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Returns:\n    list of integers [batch, height, width, channels]\n  """"""\n  # A simple abstraction to provide names for each dimension. This abstraction\n  # should make it simpler to switch dimensions in the future (e.g. if we ever\n  # want to switch height and width.)\n  if dynamic_shape:\n    return array_ops.unpack(array_ops.shape(images))\n  else:\n    return images.get_shape().as_list()\n\n\n# In[6]:\n\ndef _Check3DImage(image, require_static=True):\n  """"""Assert that we are working with properly shaped image.\n  Args:\n    image: 3-D Tensor of shape [height, width, channels]\n    require_static: If `True`, requires that all dimensions of `image` are\n      known and non-zero.\n\n  Raises:\n    ValueError: if image.shape is not a [3] vector.\n  """"""\n  try:\n    image_shape = image.get_shape().with_rank(3)\n  except ValueError:\n    raise ValueError(\'\\\'image\\\' must be three-dimensional.\')\n  if require_static and not image_shape.is_fully_defined():\n    raise ValueError(\'\\\'image\\\' must be fully defined.\')\n  if any(x == 0 for x in image_shape):\n    raise ValueError(\'all dims of \\\'image.shape\\\' must be > 0: %s\' %\n                     image_shape)\n\n\n# In[7]:\n\n#image_ops.resize_image_with_crop_or_pad = resize_image_with_crop_or_pad\n#image_ops.crop_to_bounding_box = crop_to_bounding_box\n#image_ops.pad_to_bounding_box = pad_to_bounding_box\n#image_ops._ImageDimensions = _ImageDimensions\n#image_ops._Check3DImage = _Check3DImage\n\n'"
hypergan/ops/tensorflow/__init__.py,0,"b'""""""\nEach `hypergan.gan_component` has access to ```self.ops```.\n\nOps contains our tensorflow graph operations and keeps track of our component weights.\n""""""\nfrom os.path import dirname, basename, isfile\nimport glob\nmodules = glob.glob(dirname(__file__)+""/*.py"")\n__all__ = [ basename(f)[:-3] for f in modules if isfile(f)]\n\n\nfrom . import missing_gradients\n'"
hypergan/ops/tensorflow/activations.py,31,"b'import numpy as np\nimport tensorflow as tf\n\ndef lrelu(x, leak=0.2, name=""lrelu""):\n    with tf.variable_scope(name):\n        f1 = 0.5 * (1 + leak)\n        f2 = 0.5 * (1 - leak)\n        return f1 * x + f2 * abs(x)\n\n# http://stackoverflow.com/questions/39975676/how-to-implement-prelu-activation-in-tensorflow\ndef prelu(prefix, i, _x):\n    name = (prefix+""prelu_""+str(i))\n    orig_shape = _x.get_shape()\n    _x = tf.reshape(_x, [config[\'batch_size\'], -1])\n\n    #print(""prelu for"", _x.get_shape()[-1])\n    alphas = tf.get_variable(name, \n            _x.get_shape()[-1],\n            initializer=tf.random_normal_initializer(mean=0.0,stddev=0.01),\n            dtype=tf.float32)\n    pos = tf.nn.relu(_x)\n    neg = alphas * (_x - abs(_x)) * 0.5\n\n    return tf.reshape(pos + neg, orig_shape)\n\ndef selu(x):\n    alpha = 1.6732632423543772848170429916717\n    scale = 1.0507009873554804934193349852946\n    return scale*tf.where(x>=0.0, x, alpha*tf.nn.elu(x))\n\ndef sin_and_cos(x, name=""ignored""):\n    return tf.concat(axis=len(x.get_shape()) - 1, values=[tf.sin(x), tf.cos(x)])\n\ndef maxout(x, k = 2):\n    shape = [int(e) for e in x.get_shape()]\n    ax = len(shape)\n    ch = shape[-1]\n    assert ch % k == 0\n    shape[-1] = ch // k\n    shape.append(k)\n    x = tf.reshape(x, shape)\n    return tf.reduce_max(x, ax)\n\nrng = np.random.RandomState([2016, 6, 1])\ndef offset_maxout(x, k = 2):\n    shape = [int(e) for e in x.get_shape()]\n    ax = len(shape)\n    ch = shape[-1]\n    assert ch % k == 0\n    shape[-1] = ch // k\n    shape.append(k)\n    x = tf.reshape(x, shape)\n    ofs = rng.randn(1000, k).max(axis=1).mean()\n    return tf.reduce_max(x, ax) - ofs\n\ndef lrelu_sq(x):\n    """"""\n    Concatenates lrelu and square\n    """"""\n    dim = len(x.get_shape()) - 1\n    return tf.concat(axis=dim, values=[lrelu(x), tf.minimum(tf.abs(x), tf.square(x))])\n\ndef decayer(x, name=""decayer""):\n    with tf.variable_scope(name):\n        scale = tf.get_variable(""scale"", [1], initializer=tf.constant_initializer(1.,dtype=config[\'dtype\']),dtype=config[\'dtype\'])\n        decay_scale = tf.get_variable(""decay_scale"", [1], initializer=tf.constant_initializer(1.,dtype=config[\'dtype\']),dtype=config[\'dtype\'])\n        relu = tf.nn.relu(x)\n        return scale * relu / (1. + tf.abs(decay_scale) * tf.square(decay_scale))\n\ndef decayer2(x, name=""decayer""):\n    with tf.variable_scope(name):\n        scale = tf.get_variable(""scale"", [int(x.get_shape()[-1])], initializer=tf.constant_initializer(1.,dtype=config[\'dtype\']),dtype=config[\'dtype\'])\n        decay_scale = tf.get_variable(""decay_scale"", [int(x.get_shape()[-1])], initializer=tf.constant_initializer(1.,dtype=config[\'dtype\']), dtype=config[\'dtype\'])\n        relu = tf.nn.relu(x)\n        return scale * relu / (1. + tf.abs(decay_scale) * tf.square(decay_scale))\n\ndef masked_relu(x, name=""ignored""):\n    shape = [int(e) for e in x.get_shape()]\n    prefix = [0] * (len(shape) - 1)\n    most = shape[:-1]\n    assert shape[-1] % 2 == 0\n    half = shape[-1] // 2\n    first_half = tf.slice(x, prefix + [0], most + [half])\n    second_half = tf.slice(x, prefix + [half], most + [half])\n    return tf.nn.relu(first_half) * tf.nn.sigmoid(second_half)\n\ndef minmax(net):\n    net = tf.minimum(net, 1)\n    net = tf.maximum(net, -1)\n    return net\n\ndef minmaxzero(net):\n    net = tf.minimum(net, 1)\n    net = tf.maximum(net, 0)\n    return net\n'"
hypergan/ops/tensorflow/adamirror.py,5,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\n\n# Adapted from https://raw.githubusercontent.com/openai/iaf/master/tf_utils/adamax.py\n\nclass AdamirrorOptimizer(optimizer.Optimizer):\n\n\n  def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8,\n               use_locking=False, name=""Adamirror""):\n\n    \n    super(AdamirrorOptimizer, self).__init__(use_locking, name)\n    self._lr = learning_rate\n    self._beta1 = beta1\n    self._beta2 = beta2\n\n    # Tensor versions of the constructor arguments, created in _prepare().\n    self._lr_t = None\n    self._beta1_t = None\n    self._beta2_t = None\n\n  def _prepare(self):\n    self._lr_t = ops.convert_to_tensor(self._lr, name=""learning_rate"")\n    self._beta1_t = ops.convert_to_tensor(self._beta1, name=""beta1"")\n    self._beta2_t = ops.convert_to_tensor(self._beta2, name=""beta2"")\n\n\n  def _create_slots(self, var_list):\n    # Create slots for the first and second moments.\n    for v in var_list:\n      self._zeros_slot(v, ""m"", self._name)\n      self._zeros_slot(v, ""v"", self._name)\n      self._zeros_slot(v, ""g"", self._name)\n      \n  def _apply_dense(self, grad, var):\n    lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n    beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)\n    beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)\n    if var.dtype.base_dtype == tf.float16:\n        eps = 1e-7  # Can\'t use 1e-8 due to underflow -- not sure if it makes a big difference.\n    else:\n        eps = 1e-8\n\n    v = self.get_slot(var, ""v"")\n    v_t = v.assign(beta2_t * v + (1. - beta2_t) * tf.square(grad))\n    m = self.get_slot(var, ""m"")\n    m_t = m.assign( beta1_t * m + (1. - beta1_t) * grad )\n    v_t_hat = tf.div(v_t, 1. - beta2_t)\n    m_t_hat = tf.div(m_t, 1. - beta1_t)\n    \n    g_t = tf.div( m_t, tf.sqrt(v_t)+eps )\n    g_t_1 = self.get_slot(var, ""g"")\n    g_t = g_t_1.assign( g_t )\n\n    var_update = state_ops.assign_sub(var, 2. * lr_t * g_t - lr_t * g_t_1) #Adam would be lr_t * g_t\n    return control_flow_ops.group(*[var_update, m_t, v_t, g_t])\n  \n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n'"
hypergan/ops/tensorflow/extended_ops.py,21,"b'import tensorflow as tf\nimport numpy as np\n\ndef l2_distance(a,b):\n    return tf.square(a-b)\n\ndef l1_distance(a,b):\n    return tf.abs(a-b)\n\ndef bicubic_interp_2d(input_, new_size, endpoint=False):\n  """"""\n  Args :\n    input_ : Input tensor. Its shape should be\n        [batch_size, height, width, channel].\n        In this implementation, the shape should be fixed for speed.\n    new_size : The output size [new_height, new_width]\n  ref : \n    http://blog.demofox.org/2015/08/15/resizing-images-with-bicubic-interpolation/\n  """"""\n\n  shape = input_.get_shape().as_list()\n  batch_size = shape[0]\n  height  = shape[1]\n  width   = shape[2]\n  channel = shape[3]\n \n  def _hermite(A, B, C, D, t):\n    a = A * (-0.5) + B * 1.5 + C * (-1.5) + D * 0.5\n    b = A + B * (-2.5) + C * 2.0 + D * (-0.5)\n    c = A * (-0.5) + C * 0.5\n    d = B\n\n    return a*t*t*t + b*t*t + c*t + d\n\n  def _get_grid_array(n_i, y_i, x_i, c_i):\n    n, y, x, c = np.meshgrid(n_i, y_i, x_i, c_i, indexing=\'ij\')\n    n = np.expand_dims(n, axis=4)\n    y = np.expand_dims(y, axis=4)\n    x = np.expand_dims(x, axis=4)\n    c = np.expand_dims(c, axis=4)\n    \n    return np.concatenate([n,y,x,c], axis=4)\n\n  def _get_frac_array(y_d, x_d, n, c):\n    y = y_d.shape[0]\n    x = x_d.shape[0]\n    y_t = y_d.reshape([1, -1, 1, 1])\n    x_t = x_d.reshape([1, 1, -1, 1])\n    y_t = tf.constant(np.tile(y_t, (n,1,x,c)), dtype=tf.float32)\n    x_t = tf.constant(np.tile(x_t, (n,y,1,c)), dtype=tf.float32)\n    return y_t, x_t\n\n  def _get_index_tensor(grid, x, y):\n    new_grid = np.array(grid)\n\n    grid_y = grid[:,:,:,:,1] + y\n    grid_x = grid[:,:,:,:,2] + x\n\n    grid_y = np.clip(grid_y, 0, height-1)\n    grid_x = np.clip(grid_x, 0, width-1)\n\n    new_grid[:,:,:,:,1] = grid_y\n    new_grid[:,:,:,:,2] = grid_x\n\n    return tf.constant(new_grid, dtype=tf.int32)\n\n  new_height = new_size[0]\n  new_width  = new_size[1]\n\n  n_i = np.arange(batch_size)\n  c_i = np.arange(channel)\n\n  if endpoint:\n    y_f = np.linspace(0., height-1, new_height)\n  else:\n    y_f = np.linspace(0., height, new_height, endpoint=False)\n  y_i = y_f.astype(np.int32)\n  y_d = y_f - np.floor(y_f)\n\n  if endpoint:\n    x_f = np.linspace(0., width-1, new_width)\n  else:\n    x_f = np.linspace(0., width, new_width, endpoint=False)\n  x_i = x_f.astype(np.int32)\n  x_d = x_f - np.floor(x_f) \n\n  grid = _get_grid_array(n_i, y_i, x_i, c_i)\n  y_t, x_t = _get_frac_array(y_d, x_d, batch_size, channel)\n\n  i_00 = _get_index_tensor(grid, -1, -1)\n  i_10 = _get_index_tensor(grid, +0, -1)\n  i_20 = _get_index_tensor(grid, +1, -1)\n  i_30 = _get_index_tensor(grid, +2, -1)\n      \n  i_01 = _get_index_tensor(grid, -1, +0)\n  i_11 = _get_index_tensor(grid, +0, +0)\n  i_21 = _get_index_tensor(grid, +1, +0)\n  i_31 = _get_index_tensor(grid, +2, +0)\n      \n  i_02 = _get_index_tensor(grid, -1, +1)\n  i_12 = _get_index_tensor(grid, +0, +1)\n  i_22 = _get_index_tensor(grid, +1, +1)\n  i_32 = _get_index_tensor(grid, +2, +1)\n      \n  i_03 = _get_index_tensor(grid, -1, +2)\n  i_13 = _get_index_tensor(grid, +0, +2)\n  i_23 = _get_index_tensor(grid, +1, +2)\n  i_33 = _get_index_tensor(grid, +2, +2)\n\n  p_00 = tf.gather_nd(input_, i_00)\n  p_10 = tf.gather_nd(input_, i_10)\n  p_20 = tf.gather_nd(input_, i_20)\n  p_30 = tf.gather_nd(input_, i_30)\n\n  p_01 = tf.gather_nd(input_, i_01)\n  p_11 = tf.gather_nd(input_, i_11)\n  p_21 = tf.gather_nd(input_, i_21)\n  p_31 = tf.gather_nd(input_, i_31)\n\n  p_02 = tf.gather_nd(input_, i_02)\n  p_12 = tf.gather_nd(input_, i_12)\n  p_22 = tf.gather_nd(input_, i_22)\n  p_32 = tf.gather_nd(input_, i_32)\n\n  p_03 = tf.gather_nd(input_, i_03)\n  p_13 = tf.gather_nd(input_, i_13)\n  p_23 = tf.gather_nd(input_, i_23)\n  p_33 = tf.gather_nd(input_, i_33)\n\n  col0 = _hermite(p_00, p_10, p_20, p_30, x_t)\n  col1 = _hermite(p_01, p_11, p_21, p_31, x_t)\n  col2 = _hermite(p_02, p_12, p_22, p_32, x_t)\n  col3 = _hermite(p_03, p_13, p_23, p_33, x_t)\n  value = _hermite(col0, col1, col2, col3, y_t)\n  \n  return value\n'"
hypergan/ops/tensorflow/layer_regularizers.py,5,"b'import tensorflow as tf\n\ndef layer_norm_1(component, net):\n    ops = component.ops\n    scope = ops.generate_name()\n    with tf.variable_scope(scope, reuse=ops._reuse):\n        net = tf.contrib.layers.layer_norm(net, scope=scope, center=True, scale=True, variables_collections=tf.GraphKeys.LOCAL_VARIABLES)\n        vars = lookup_vars(scope)\n    if not ops._reuse:\n        ops.add_weights(vars)\n\n    return net\n\ndef batch_norm_1(component, net):\n    config = component.config\n    ops = component.ops\n\n    dtype = ops.dtype\n    shape = ops.shape(net)\n\n    epsilon = config.epsilon or 0.001\n    batch_norm_gamma_stddev = config.batch_norm_gamma_stddev or 0.02\n\n    decay = config.batch_norm_decay or 0.999\n    center = config.batch_norm_center or True\n    scale = config.batch_norm_scale or False\n    epsilon = config.batch_norm_epsilon or 0.001\n    scope = ops.generate_name()\n    with tf.variable_scope(scope, reuse=ops._reuse):\n        net = tf.contrib.layers.batch_norm(net, \n                decay = decay,\n                center = center,\n                scale = scale,\n                epsilon = epsilon,\n                is_training = True,\n                scope=scope\n                )\n        vars = lookup_vars(scope)\n    if not ops._reuse:\n        ops.add_weights(vars)\n    return net\n\n\ndef lookup_vars(name):\n    vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n    filtered = []\n    for var in vars:\n        if var.name.startswith(name):\n            filtered.append(var)\n    return filtered\n\n'"
hypergan/ops/tensorflow/missing_gradients.py,0,"b'from tensorflow.python.ops import gen_image_ops\nfrom tensorflow.python.framework import ops\n\n#@ops.RegisterGradient(""ResizeNearestNeighborGrad"")\ndef _ResizeNearestNeighborGrad(op, grad):\n    #TODO this is for ResizeNearestNeighbor not ResizeNearestNeighborGrad\n    """"""The derivatives for nearest neighbor resizing.\n\n    Args:\n    op: The ResizeNearestNeighbor op.\n    grad: The tensor representing the gradient w.r.t. the output.\n\n    Returns:\n    The gradients w.r.t. the input and the output.\n    """"""\n    image = op.inputs[0]\n    if image.get_shape()[1:3].is_fully_defined():\n        image_shape = image.get_shape()[1:3]\n    else:\n        image_shape = array_ops.shape(image)[1:3]\n\n    grads = gen_image_ops.resize_nearest_neighbor_grad(\n            grad,\n            image_shape,\n            align_corners=op.get_attr(""align_corners""))\n    return [grads, None]\n'"
hypergan/ops/tensorflow/ops.py,149,"b'import hyperchamber as hc\nimport tensorflow as tf\nimport numpy as np\nimport types\nimport uuid\nimport importlib\nimport hypergan\nfrom tensorflow.python.ops.variables import RefVariable\nfrom hypergan.ops.tensorflow import layer_regularizers\nfrom hypergan.ops.tensorflow.activations import lrelu, selu\nfrom hypergan.ops.tensorflow.extended_ops import *\nfrom hypergan.ops.tensorflow.sn import spectral_normed_weight\nclass TensorflowOps:\n    def __init__(self, config={}, device=""/gpu:0""):\n        config = hc.Config(config)\n        self.config = config\n        dtype = config.dtype or ""float32""\n        initializer = self.config_option(""initializer"", ""he_normal"")\n\n        self.dtype = self.parse_dtype(dtype)\n        self.scope_count = 0\n        self.description = \'\'\n        self.weights = []\n        self.biases = []\n        self.device = config.device\n        self.initialized = False\n        self._reuse = False\n        self.reuse_scope_count = 0\n        self.reuse_context = 0\n        self.initializer = self.lookup_initializer(initializer, config)\n\n    def config_option(self, name, default=None, config=None):\n        if config is None:\n            config = self.config\n        if name in config:\n            return config[name]\n        if ""defaults"" in config:\n            if name in config[""defaults""]:\n                return config[""defaults""][name]\n        return default\n\n    def lookup_initializer(self, name, config):\n        if name == \'orthogonal\':\n            orthogonal_gain = self.config_option(""orthogonal_gain"", 1.0, config)\n            return self.orthogonal_initializer(orthogonal_gain)\n        elif name == \'he_normal\':\n            return self.he_normal_initializer()\n        elif name == \'xavier\':\n            return self.xavier_initializer()\n        elif name == \'stylegan\':\n            return self.stylegan_initializer(config or self.config)\n        elif name == \'random_normal\':\n            return self.random_initializer(self.config_option(""random_stddev"", 0.02, config))\n        else:\n            raise Exception(""initializer not found"", name)\n\n    def assert_tensor(self, net):\n        if type(net) != tf.Tensor and type(net) != tf.Variable and type(net) != RefVariable:\n            raise Exception(""Expected a Tensor but received"", net)\n\n    def add_weights(self, weights):\n        if not isinstance(weights, list):\n            weights = [weights]\n        self.weights += weights\n\n    def variables(self):\n        return self.biases + self.weights\n\n    def random_initializer(self, stddev):\n        def _build(shape):\n            return tf.random_normal_initializer(0, stddev, dtype=self.dtype)\n        return _build\n\n    def stylegan_initializer(self, config):\n        def _build(shape):\n            gain = self.config_option(""gain"", np.sqrt(2), config)\n            use_wscale = self.config_option(""w_scale"", False, config)\n            lrmul = float(self.config_option(""lrmul"", 0.01, config))\n            fan_in = np.prod([int(x) for x in shape[:-1]]) # [kernel, kernel, fmaps_in, fmaps_out] or [in, out]\n            he_std = gain / np.sqrt(fan_in) # He init\n\n            # Equalized learning rate and custom learning rate multiplier.\n            if use_wscale:\n                init_std = 1.0 / lrmul\n                runtime_coef = he_std * lrmul\n            else:\n                init_std = he_std / lrmul\n                runtime_coef = lrmul\n\n            self.runtime_coef = runtime_coef\n\n            # Create variable.\n            return tf.initializers.random_normal(0, init_std)\n        return _build\n\n    def orthogonal_initializer(self, gain):\n        def _build(shape):\n            return tf.orthogonal_initializer(gain)\n        return _build\n\n    def he_normal_initializer(self):\n        def _build(shape):\n            return tf.variance_scaling_initializer()\n        return _build\n\n    def xavier_initializer(self):\n        def _build(shape):\n            return tf.contrib.layers.xavier_initializer()\n        return _build\n\n    def describe(self, description):\n        self.description = description\n\n    def reuse(self):\n        self._reuse = True\n        self.reuse_scope_count = 0\n        self.reuse_context += 1\n\n    def stop_reuse(self):\n        self.reuse_context -= 1\n        if self.reuse_context == 0:\n            self._reuse = False\n\n    def generate_scope(self):\n        if self._reuse:\n            self.reuse_scope_count += 1\n            return str(self.reuse_scope_count)\n        self.scope_count += 1\n        return str(self.scope_count)\n\n    def generate_name(self, name=None):\n        if name == None:\n            if self.description == """":\n                return self.generate_scope()\n            return self.description + ""_"" + self.generate_scope()\n        else:\n            return name\n\n    def parse_dtype(self, dtype):\n        if type(dtype) == Function:\n            return dtype\n        if dtype == \'float32\':\n            return tf.float32\n        elif dtype == \'float16\':\n            return tf.float16\n        else:\n            raise Exception(""dtype not defined: ""+str(dtype))\n\n    def get_weight(self, shape=None, name=None, initializer=None, trainable=None):\n        if name == None:\n            name = ""w""\n        if initializer == None:\n            initializer = self.initializer\n        initializer = initializer(shape)\n        weight = tf.get_variable(name, shape, dtype=self.dtype, initializer=initializer, trainable=trainable)\n        if not self._reuse:\n            self.weights.append(weight)\n        if hasattr(self, \'runtime_coef\'):\n            weight *= self.runtime_coef\n            delattr(self, ""runtime_coef"") # todo, better way to pass variables from initialiszer\n        return weight\n\n    def get_bias(self, shape, constant=0.0, name=None, trainable=None):\n        if name == None:\n            name=\'b\'\n        bias = tf.get_variable(name, shape, initializer=tf.constant_initializer(constant, dtype=self.dtype), dtype=self.dtype, trainable=trainable)\n        if not self._reuse:\n            self.biases.append(bias)\n        return bias\n    \n    def parse_dtype(self, dtype):\n        if dtype == \'float32\':\n            return tf.float32\n        elif dtype == \'float16\':\n            return tf.float16\n        else:\n            raise Exception(""dtype not defined: ""+str(dtype))\n\n    def cosine_conv2d(self, net, filter_w, filter_h, stride_w, stride_h, output_dim):\n        with tf.variable_scope(self.generate_name(), reuse=self._reuse):\n            w = self.get_weight([filter_h, filter_w, net.get_shape()[-1], output_dim])\n            conv = tf.nn.conv2d(net, w, strides=[1, 1, 1, 1], padding=\'SAME\')\n            biases = self.get_bias([output_dim], 0.001)\n            conv = tf.nn.bias_add(conv, biases)\n\n            w_square = tf.square(w)\n            #w_sum = tf.reduce_sum(w_square, [0,1,2])\n            w_conv = tf.nn.conv2d(tf.ones_like(net), w_square, strides=[1, 1, 1, 1], padding=\'SAME\')\n            w_norm = tf.sqrt(w_conv + 1e-4)\n\n            net_square = tf.square(net)\n            w_ones = tf.ones_like(w)\n            net_sum = tf.nn.conv2d(net_square, w_ones, strides=[1, 1, 1, 1], padding=\'SAME\')\n            net_norm = tf.sqrt(net_sum + 1e-4)\n\n            return conv / (w_norm * net_norm)\n\n    #def weightnorm_conv2d(self, net, filter_w, filter_h, stride_w, stride_h, output_dim):\n    #    with tf.variable_scope(self.generate_name(), reuse=self._reuse):\n    #        w = self.get_weight([filter_h, filter_w, net.get_shape()[-1], output_dim])\n    #        g = self.get_weight(name=\'g\', shape=[1,output_dim])\n    #        conv = tf.nn.conv2d(net, w, strides=[1, 1, 1, 1], padding=\'SAME\')\n    #        b = self.get_bias([output_dim], 0.001)\n\n    #        w_square = tf.square(w)\n    #        #w_sum = tf.reduce_sum(w_square, [0,1,2])\n    #        w_conv = tf.nn.conv2d(tf.ones_like(net), w_square, strides=[1, 1, 1, 1], padding=\'SAME\')\n    #        w_norm = tf.sqrt(w_conv + 1e-4)\n\n    #        return (conv*g+b) / (w_norm)\n\n    #def weightnorm_conv2d(self, net, filter_w, filter_h, stride_w, stride_h, output_dim):\n    #    with tf.variable_scope(self.generate_name(), reuse=self._reuse):\n    #        w = self.get_weight([filter_h, filter_w, net.get_shape()[-1], output_dim])\n    #        g = self.get_weight(name=\'g\', shape=[1,output_dim])\n    #        b = self.get_bias([output_dim])\n\n    #        # use weight normalization (Salimans & Kingma, 2016)\n    #        W = tf.reshape(g,[1,1,1,output_dim])*tf.nn.l2_normalize(w,[0,1,2])\n\n    #        # calculate convolutional layer output\n    #        return tf.nn.bias_add(tf.nn.conv2d(net, W, [1, stride_h, stride_w, 1], padding=\'SAME\'), b)\n\n    def weightnorm_conv2d(self, net, filter_w, filter_h, stride_w, stride_h, output_dim):\n        with tf.variable_scope(self.generate_name(), reuse=self._reuse):\n            # modified from https://github.com/openai/weightnorm/blob/master/tensorflow/nn.py\n            # data based initialization of parameters\n            g = self.get_weight(name=\'g\', shape=[1,1,1,output_dim])#, initializer=scale_init)\n            b = self.get_bias(shape=[output_dim])#, initializer=-m_init*scale_init)\n            shape = [filter_h, filter_w, int(net.get_shape()[-1]),output_dim]\n            V = self.get_weight(name=\'v\', shape=shape)\n            V_norm = tf.nn.l2_normalize(V, [0,1,2])\n            x_init = tf.nn.conv2d(net, V_norm, [1, stride_h, stride_w, 1], padding=""SAME"")\n            x_init = tf.nn.bias_add(x_init, b)\n            m_init, v_init = tf.nn.moments(x_init, [0,1,2])\n            scale_init = 1.0/tf.sqrt(v_init + 1e-8)\n            x_init = tf.reshape(scale_init,[1,1,1,output_dim])*(x_init-tf.reshape(m_init,[1,1,1,output_dim]))\n            return g*x_init\n\n    def weightnorm2_conv2d(self, net, filter_w, filter_h, stride_w, stride_h, output_dim, padding=""SAME""):\n        with tf.variable_scope(self.generate_name(), reuse=self._reuse):\n            # modified from https://github.com/openai/weightnorm/blob/master/tensorflow/nn.py\n            # data based initialization of parameters\n            g = self.get_weight(name=\'g\', shape=[1,1,1,output_dim])#, initializer=scale_init)\n            shape = [filter_h, filter_w, int(net.get_shape()[-1]),output_dim]\n            V = self.get_weight(name=\'v\', shape=shape)\n            V_norm = tf.nn.l2_normalize(V, [0,1,2])\n            x_init = tf.nn.conv2d(net, V_norm, [1, stride_h, stride_w, 1], padding=padding)\n            m_init, v_init = tf.nn.moments(x_init, [0,1,2])\n            scale_init = 1.0/tf.sqrt(v_init + 1e-8)\n            x_init = tf.reshape(scale_init,[1,1,1,output_dim])*(x_init-tf.reshape(m_init,[1,1,1,output_dim]))\n            return g*x_init\n\n    def weightnorm3_conv2d(self, net, filter_w, filter_h, stride_w, stride_h, output_dim):\n        with tf.variable_scope(self.generate_name(), reuse=self._reuse):\n            # modified from https://github.com/openai/weightnorm/blob/master/tensorflow/nn.py\n            # data based initialization of parameters\n            g = self.get_weight(name=\'g\', shape=[1,1,1,output_dim])#, initializer=scale_init)\n            shape = [filter_h, filter_w, int(net.get_shape()[-1]),output_dim]\n            V = self.get_weight(name=\'v\', shape=shape)\n            V_norm = tf.nn.l2_normalize(V, [0,1,2])*g\n            x_init = tf.nn.conv2d(net, V_norm, [1, stride_h, stride_w, 1], padding=""SAME"")\n            m_init, v_init = tf.nn.moments(x_init, [0,1,2])\n            scale_init = 1.0/tf.sqrt(v_init + 1e-8)\n            x_init = tf.reshape(scale_init,[1,1,1,output_dim])*(x_init-tf.reshape(m_init,[1,1,1,output_dim]))\n            return x_init\n\n\n    def spectralnorm_conv2d(self, net, filter_w, filter_h, stride_w, stride_h, output_dim, padding=\'SAME\'):\n        def spectral_norm(w, iteration=1):\n           w_shape = w.shape.as_list()\n           w = tf.reshape(w, [-1, w_shape[-1]])\n\n           u = tf.get_variable(""u"", [1, w_shape[-1]], initializer=tf.truncated_normal_initializer(), trainable=False)\n\n           u_hat = u\n           v_hat = None\n           for i in range(iteration):\n               v_ = tf.matmul(u_hat, tf.transpose(w))\n               v_hat =tf.nn.l2_normalize(v_, [0,1])\n\n               u_ = tf.matmul(v_hat, w)\n               u_hat =tf.nn.l2_normalize(u_, [0,1])\n\n           sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))\n           w_norm = w / sigma\n\n           with tf.control_dependencies([u.assign(u_hat)]):\n               w_norm = tf.reshape(w_norm, w_shape)\n\n           return w_norm\n        with tf.variable_scope(self.generate_name(), reuse=self._reuse):\n            w = self.get_weight([filter_h, filter_w, net.get_shape()[-1], output_dim])\n            conv = tf.nn.conv2d(net, strides=[1, stride_h, stride_w, 1], padding=padding, filter=spectral_norm(w))\n            biases = self.get_bias([output_dim])\n            conv = tf.nn.bias_add(conv, biases)\n            return conv\n\n    def weightnorm_deconv2d(self, net, filter_w, filter_h, stride_w, stride_h, output_dim):\n        with tf.variable_scope(self.generate_name(), reuse=self._reuse):\n            # modified from https://github.com/openai/weightnorm/blob/master/tensorflow/nn.py\n            # data based initialization of parameters\n            g = self.get_weight(name=\'g\', shape=[1,1,1,output_dim])#, initializer=scale_init)\n            b = self.get_bias(shape=[output_dim])#, initializer=-m_init*scale_init)\n            shape = [filter_h, filter_w, output_dim, int(net.get_shape()[-1])]\n            V = self.get_weight(name=\'v\', shape=shape)\n            V_norm = tf.nn.l2_normalize(V, [0,1,2])\n            \n            net_shape = self.shape(net)\n            target_shape = [net_shape[0], net_shape[1]*stride_h, net_shape[2]*stride_w, output_dim]\n            print(net, target_shape, V_norm)\n            x_init = tf.nn.conv2d_transpose(net, V_norm, target_shape, [1, stride_h, stride_w, 1], padding=""SAME"")\n            x_init = tf.nn.bias_add(x_init, b)\n            m_init, v_init = tf.nn.moments(x_init, [0,1,2])\n            scale_init = 1.0/tf.sqrt(v_init + 1e-8)\n            x_init = tf.reshape(scale_init,[1,1,1,output_dim])*(x_init-tf.reshape(m_init,[1,1,1,output_dim]))\n            return g*x_init\n\n\n    def conv2d(self, net, filter_w, filter_h, stride_w, stride_h, output_dim, padding=""SAME"", initializer=None, name=None, trainable=True, bias=True):\n        self.assert_tensor(net)\n\n\n        layer_regularizer = self.config_option(""layer_regularizer"")\n        if layer_regularizer == \'cosine_norm\':\n            return self.cosine_conv2d(net, filter_w, filter_h, stride_w, stride_h, output_dim)\n        if layer_regularizer == \'weight_norm3\':\n            return self.weightnorm3_conv2d(net, filter_w, filter_h, stride_w, stride_h, output_dim)\n        if layer_regularizer == \'weight_norm2\':\n            return self.weightnorm2_conv2d(net, filter_w, filter_h, stride_w, stride_h, output_dim, padding=padding)\n        if layer_regularizer == \'weight_norm\':\n            return self.weightnorm_conv2d(net, filter_w, filter_h, stride_w, stride_h, output_dim)\n        if layer_regularizer == \'spectral_norm\':\n            return self.spectralnorm_conv2d(net, filter_w, filter_h, stride_w, stride_h, output_dim, padding=padding)\n\n        if self.config_option(""l2_scale""):\n            net = net / tf.sqrt(float(filter_w)/float(stride_w)*float(filter_h)/float(stride_h))\n\n        with tf.variable_scope(self.generate_name(name), reuse=self._reuse):\n            shape=[filter_h, filter_w, net.get_shape()[-1], output_dim]\n            if initializer is None:\n                initializer = self.initializer\n            w = self.get_weight(shape, initializer=initializer, trainable=trainable)\n            conv = tf.nn.conv2d(net, w, strides=[1, stride_h, stride_w, 1], padding=padding)\n            if bias:\n                biases = self.get_bias([output_dim], trainable=trainable)\n                conv = tf.nn.bias_add(conv, biases)\n            return conv\n\n    def deconv2d(self, net, filter_w, filter_h, stride_w, stride_h, output_dim, initializer=None, name=None, trainable=True, bias=True):\n        self.assert_tensor(net)\n        shape = self.shape(net)\n        layer_regularizer = self.config_option(""layer_regularizer"")\n        if layer_regularizer == \'weight_norm\':\n            return self.weightnorm_deconv2d(net, filter_w, filter_h, stride_w, stride_h, output_dim)\n        output_shape = [shape[0], shape[1]*stride_h, shape[2]*stride_w, output_dim]\n        init_bias = 0.\n        with tf.variable_scope(self.generate_name(name), reuse=self._reuse):\n            # filter : [height, width, output_channels, in_channels]\n            shape=[filter_h, filter_w, output_dim, shape[3]]\n            if initializer is None:\n                initializer = self.initializer\n            w = self.get_weight(shape, initializer=initializer, trainable=trainable)\n\n            deconv = tf.nn.conv2d_transpose(net, w, output_shape=output_shape,\n                                    strides=[1, stride_h, stride_w, 1])\n            if bias:\n                biases = self.get_bias([output_shape[-1]])\n                deconv = tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())\n\n            return deconv\n\n    def cosine_linear(self, net, output_dim):\n        with tf.variable_scope(self.generate_name(), reuse=self._reuse):\n            w = self.get_weight([self.shape(net)[1], output_dim], name=\'cos_w\')\n            b = self.get_bias([output_dim], constant=0.001)\n            w_norm = tf.sqrt(tf.reduce_sum(w**2, axis=0, keep_dims=True) + b ** 2)+0.000001\n            x_norm = tf.sqrt(tf.reduce_sum(net**2, axis=1, keep_dims=True) + 0.000001)\n            return (tf.matmul(net, w) + 0.001 * b) / w_norm / x_norm\n\n    def weight_norm_linear(self, net, output_dim):\n        with tf.variable_scope(self.generate_name(), reuse=self._reuse):\n            g = self.get_weight([1, output_dim], name=\'weightnorm_g\')\n            v = self.get_weight([self.shape(net)[1], output_dim], name=\'weighnorm_v\')\n            v_norm = tf.nn.l2_normalize(v, [0])\n            b = self.get_bias([output_dim], constant=0.001)\n            return (tf.matmul(net, v_norm) * g+b)\n\n    def linear(self, net, output_dim, initializer=None, name=None, trainable=True, bias=True):\n        linear_type = self.config_option(""linear_type"")\n        if linear_type == \'cosine\':\n            return self.cosine_linear(net, output_dim)\n        if linear_type == \'weight_norm\':\n            return self.weight_norm_linear(net, output_dim)\n        self.assert_tensor(net)\n        shape = self.shape(net)\n        with tf.variable_scope(self.generate_name(name), reuse=self._reuse):\n            linshape=[shape[1], output_dim]\n            if initializer is None:\n                initializer = self.initializer\n            w = self.get_weight(linshape, initializer=initializer, trainable=trainable)\n            if(bias):\n                bias = self.get_bias([output_dim], trainable=trainable)\n                return tf.matmul(net, w) + bias\n            else:\n                return tf.matmul(net, w)\n\n    def reduce_linear(self):\n        def _build(net, axis=1):\n            return self.linear(net, 1)\n        return _build\n\n    def nsoftplus(self, net):\n        return tf.log(tf.exp(net)+1)/np.log(2) - 1.0\n\n    def clamped(self, net):\n        return tf.maximum(0., tf.minimum(net, 1.))\n\n    def clamped_unit(self, net):\n        return tf.maximum(-1., tf.minimum(net, 1.))\n\n    def null(self):\n        def _null(_x):\n            return _x\n        return _null\n\n    def groupsort(self, n=2):\n        def _activation(v):\n            fv = tf.reshape(v,[-1])\n            length = self.shape(fv)[0]\n            if(length < n or length % n != 0):\n                print(""not sorting"", length)\n                return v\n            fv = tf.reshape(v,[-1, n])\n            if n == 2:\n                b,c = tf.split(fv, 2, 1)\n                newv = tf.concat([tf.minimum(b, c), tf.maximum(b,c)], axis=1)\n                newv = tf.reshape(newv,self.shape(v))\n                return newv\n\n            newv = tf.contrib.framework.sort(fv)\n            newv = tf.reshape(newv,self.shape(v))\n            return newv\n\n        return _activation\n\n\n    def double_sided(self):\n        def _activation(_x):\n            activation = self.lookup(self.config_option(""double_sided_activation"", \'relu\'))\n            ops = self\n            orig_shape = self.shape(_x)\n            net = _x\n            namesstr = self.activation_name\n            names = None\n            if namesstr is not None:\n                names = namesstr.split("","")\n            names = names or [None, None]\n\n            if len(orig_shape) == 2:\n                self.activation_name = names[0]\n                a = activation(net)\n                self.activation_name = names[1]\n                b = activation(-net)\n                net = tf.concat([a,b],axis=1)\n            elif len(orig_shape) == 4:\n                self.activation_name = names[0]\n                a = activation(net)\n                self.activation_name = names[1]\n                b = activation(-net)\n                net = tf.concat([a,b],axis=3)\n            else:\n                raise ""Two sided relu activation requires input dimensions of 2 or 4""\n            self.activation_name = namesstr\n            return net\n\n\n        return _activation\n\n\n\n    def prelu(self):\n        def _prelu(_x):\n            orig_shape = self.shape(_x)\n            _x = tf.reshape(_x, [orig_shape[0], -1])\n\n            # TODO Hack, cant send through function params b/c must match tensorflow activations\n            name = None\n            trainable = None\n            if hasattr(self, \'activation_name\'):\n                name = self.activation_name \n\n            if hasattr(self, \'activation_trainable\'):\n                if self.activation_trainable == \'false\':\n                    self.activation_trainable = False\n                trainable = self.activation_trainable\n            # /TODO\n\n            name = name or self.generate_name()\n            with tf.variable_scope(name, reuse=self._reuse):\n                print(""Creating variable"",name,self._reuse, trainable)\n                alphas = tf.get_variable(\'prelu\', \n                          _x.get_shape()[-1],\n                          initializer=tf.random_normal_initializer(mean=0.0,stddev=0.01),\n                          dtype=tf.float32,\n                          trainable=trainable)\n                pos = tf.nn.relu(_x)\n                neg = alphas * (_x - abs(_x)) * 0.5\n\n            if not self._reuse:\n                self.biases += [alphas]\n            return tf.reshape(pos + neg, orig_shape)\n\n        return _prelu\n\n    def bipolar(self):\n        def _bipolar(_x, name=None):\n            activation = self.lookup(self.config_option(""bipolar_activation"", \'relu\'))\n            ops = self\n            orig_shape = self.shape(_x)\n            net = _x\n            if len(orig_shape) == 2:\n                a = tf.slice(net, [0,0], [ops.shape(net)[0], ops.shape(net)[1]//2])\n                b = tf.slice(net, [0,ops.shape(net)[1]//2],[ops.shape(net)[0], ops.shape(net)[1]//2])\n                a = activation(a)\n                b = -activation(-b)\n                net = tf.concat([a,b],axis=1)\n            elif len(orig_shape) == 4:\n                print(""Size is"", net)\n                a = tf.slice(net, [0,0,0,0], [-1, -1,-1, ops.shape(net)[3]//2])\n                b = tf.slice(net, [0,0,0,ops.shape(net)[3]//2],[-1, -1,-1,ops.shape(net)[3]//2])\n                a = activation(a)\n                b = -activation(-b)\n                net = tf.concat([a,b],axis=3)\n            else:\n                raise ""Bipolar activation requires input dimensions of 2 or 4""\n            return tf.reshape(net, orig_shape)\n\n\n        return _bipolar\n\n\n    def swish(self, x):\n        return x * tf.nn.sigmoid(x)\n\n    def trelu(self):\n        def _trelu(_x, name=None):\n            activation = self.lookup(self.config_option(""trelu_activation"", \'relu\'))\n            orig_shape = self.shape(_x)\n            _x = tf.reshape(_x, [orig_shape[0], -1])\n\n            with tf.variable_scope(self.generate_name(name), reuse=self._reuse):\n                alphas = tf.get_variable(\'trelu\', \n                          _x.get_shape()[-1],\n                          initializer=tf.random_normal_initializer(mean=0.0,stddev=0.01),\n                          dtype=tf.float32)\n                net = activation(_x - alphas) + alphas\n\n            #TODO this is wrong - need to add to biases only on no reuse\n            self.add_weights(alphas)\n            return tf.reshape(net, orig_shape)\n\n        return _trelu\n\n    def gelu(self, x):\n        return 0.5*x*(1+tf.nn.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x,3))))\n\n    def frelu(self):\n        def _frelu(_x, name=None):\n            activation = self.lookup(self.config_option(""frelu_activation"", \'relu\'))\n            orig_shape = self.shape(_x)\n            _x = tf.reshape(_x, [orig_shape[0], -1])\n\n            with tf.variable_scope(self.generate_name(name), reuse=self._reuse):\n                alphas = tf.get_variable(\'frelu\', \n                          [1],\n                          initializer=tf.random_normal_initializer(mean=0.0,stddev=0.01),\n                          dtype=tf.float32)\n                net = activation(_x) + alphas\n\n            #TODO this is wrong - need to add to biases only on no reuse\n            self.add_weights(alphas)\n            return tf.reshape(net, orig_shape)\n\n        return _frelu\n\n    def reshape(self, net, shape):\n        self.assert_tensor(net)\n        return tf.reshape(net, shape)\n\n    def concat(self, values=[], axis=0):\n        return tf.concat(values=values, axis=axis)\n\n    def resize_images(self, net, dims, op_type):\n        self.assert_tensor(net)\n        return tf.image.resize_images(net, dims, op_type)\n\n    def slice(self, net, x, y):\n        self.assert_tensor(net)\n        return tf.slice(net, x, y)\n\n    def shape(self, net):\n        self.assert_tensor(net)\n        return [(x._value or -1) for x in net.get_shape()]\n\n    def add_n(self, net):\n        return tf.add_n(net)\n\n    def squash(self, net, reduce=tf.reduce_mean):\n        """"""\n        Takes any size tensor and reduces it to a single value using `reduce`.\n        """"""\n        while(sum(self.shape(net)) > 1):\n            net = reduce(net)\n            net = tf.squeeze(net)\n\n        return net\n\n    def lookup(self, symbol, use_eval=True):\n        if symbol == None:\n            return None\n\n        if type(symbol) == type([]):\n            return [self.lookup(k, use_eval=False) for k in symbol]\n\n        if type(symbol) == type({}) or type(symbol) == hc.Config:\n            return hc.Config({k: self.lookup(symbol[k], use_eval=False) for k in symbol.keys()})\n\n        if type(symbol) != type(""""):\n            return symbol\n\n        if not use_eval:\n            return symbol\n\n        if symbol.startswith(\'function:\'):\n            return self.lookup_function(symbol)\n\n        if symbol.startswith(\'class:\'):\n            return self.lookup_class(symbol)\n\n        if symbol == \'groupsort\':\n            return self.groupsort(self.config_option(""groupsort_n"", 2))\n        if symbol == \'tanh\':\n            return tf.nn.tanh\n        if symbol == \'sigmoid\':\n            return tf.nn.sigmoid\n        if symbol == \'clamped\':\n            return self.clamped\n        if symbol == \'clamped_unit\':\n            return self.clamped_unit\n        if symbol == \'cosine_norm\':\n            return ""cosine_norm""\n        if symbol == \'batch_norm\':\n            return layer_regularizers.batch_norm_1\n        if symbol == \'layer_norm\':\n            return layer_regularizers.layer_norm_1\n        if symbol == ""crelu"":\n            return tf.nn.crelu\n        if symbol == \'null\':\n            return self.null()\n        if symbol == ""prelu"":\n            return self.prelu()\n        if symbol == ""double_sided"":\n            return self.double_sided()\n        if symbol == \'nsoftplus\':\n            return self.nsoftplus\n        if symbol == ""trelu"":\n            return self.trelu()\n        if symbol == ""bipolar"":\n            return self.bipolar()\n        if symbol == ""swish"":\n            return self.swish\n        if symbol == ""selu"":\n            return selu\n        if symbol == ""frelu"":\n            return self.frelu()\n        if symbol == ""gelu"":\n            return self.gelu\n        if symbol == ""lrelu"":\n            return lrelu\n        if symbol == ""relu"":\n            return tf.nn.relu\n        if symbol == \'square\':\n            return tf.square\n        if symbol == \'reduce_mean\':\n            return tf.reduce_mean\n        if symbol == \'reduce_min\':\n            return tf.reduce_min\n        if symbol == \'reduce_sum\':\n            return tf.reduce_sum\n        if symbol == \'reduce_logsumexp\':\n            return tf.reduce_logsumexp\n        if symbol == \'reduce_linear\':\n            return self.reduce_linear()\n\n        if symbol == \'l1_distance\':\n            return l1_distance\n        if symbol == \'l2_distance\':\n            return l2_distance\n\n        return symbol\n\n    def lookup_function(self, name):\n        namespaced_method = name.split("":"")[1]\n        method = namespaced_method.split(""."")[-1]\n        namespace = ""."".join(namespaced_method.split(""."")[0:-1])\n        return getattr(importlib.import_module(namespace),method)\n\n    def lookup_class(self, name):\n        return self.lookup_function(name)\n\n    def initialize_variables(self, session):\n        with tf.device(self.device):\n            if len(self.variables()) == 0:\n                return\n            init = tf.variables_initializer(self.variables())\n            session.run(init)\n            self.initialized = True\n\n    def new_session(self, tfconfig):\n        if tfconfig is None:\n            tfconfig = tf.ConfigProto(allow_soft_placement=True)\n            #tfconfig = tf.ConfigProto(log_device_placement=True)\n            tfconfig.gpu_options.allow_growth=True\n\n        with tf.device(self.device):\n            return tf.Session(config=tfconfig)\n'"
hypergan/ops/tensorflow/params.py,0,b'import tensorflow as tf\n\n'
hypergan/ops/tensorflow/sn.py,16,"b'import tensorflow as tf\nimport warnings\n\n\nNO_OPS = \'NO_OPS\'\n\n\ndef _l2normalize(v, eps=1e-12):\n  return v / (tf.reduce_sum(v ** 2) ** 0.5 + eps)\n\n\ndef spectral_normed_weight(W, u=None, num_iters=1, update_collection=None, with_sigma=False):\n  # Usually num_iters = 1 will be enough\n  W_shape = W.shape.as_list()\n  W_reshaped = tf.reshape(W, [-1, W_shape[-1]])\n  if u is None:\n    u = tf.get_variable(""u"", [1, W_shape[-1]], initializer=tf.truncated_normal_initializer(), trainable=False)\n  def power_iteration(i, u_i, v_i):\n    v_ip1 = _l2normalize(tf.matmul(u_i, tf.transpose(W_reshaped)))\n    u_ip1 = _l2normalize(tf.matmul(v_ip1, W_reshaped))\n    return i + 1, u_ip1, v_ip1\n  _, u_final, v_final = tf.while_loop(\n    cond=lambda i, _1, _2: i < num_iters,\n    body=power_iteration,\n    loop_vars=(tf.constant(0, dtype=tf.int32),\n               u, tf.zeros(dtype=tf.float32, shape=[1, W_reshaped.shape.as_list()[0]]))\n  )\n  if update_collection is None:\n    warnings.warn(\'Setting update_collection to None will make u being updated every W execution. This maybe undesirable\'\n                  \'. Please consider using a update collection instead.\')\n    sigma = tf.matmul(tf.matmul(v_final, W_reshaped), tf.transpose(u_final))[0, 0]\n    # sigma = tf.reduce_sum(tf.matmul(u_final, tf.transpose(W_reshaped)) * v_final)\n    W_bar = W_reshaped / sigma\n    with tf.control_dependencies([u.assign(u_final)]):\n      W_bar = tf.reshape(W_bar, W_shape)\n  else:\n    sigma = tf.matmul(tf.matmul(v_final, W_reshaped), tf.transpose(u_final))[0, 0]\n    # sigma = tf.reduce_sum(tf.matmul(u_final, tf.transpose(W_reshaped)) * v_final)\n    W_bar = W_reshaped / sigma\n    W_bar = tf.reshape(W_bar, W_shape)\n    # Put NO_OPS to not update any collection. This is useful for the second call of discriminator if the update_op\n    # has already been collected on the first call.\n    if update_collection != NO_OPS:\n      tf.add_to_collection(update_collection, u.assign(u_final))\n  if with_sigma:\n    return W_bar, sigma\n  else:\n    return W_bar\n'"
hypergan/optimizers/experimental/consensus_optimizer.py,5,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass ConsensusOptimizer(optimizer.Optimizer):\n  def __init__(self, learning_rate=0.001, p=0.1, gan=None, config=None, use_locking=False, name=""CurlOptimizer"", optimizer=None, beta=1):\n    super().__init__(use_locking, name)\n    self._beta = beta\n    self.gan = gan\n    self.config = config\n    self._lr_t = learning_rate\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    var_list = [ v for _,v in grads_and_vars]\n    d_vars = []\n    g_vars = []\n    all_grads = [ g for g, _ in grads_and_vars ]\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n\n    with ops.init_scope():\n        self.optimizer._create_slots([v for g,v in grads_and_vars])\n\n    self._prepare()\n    d_grads = all_grads[:len(d_vars)]\n    if self.config.type == \'sga\':\n        Jgrads = tf.gradients(d_grads, d_vars, grad_ys=d_grads, stop_gradients=d_vars) + [tf.zeros_like(g) for g in g_vars]\n    elif self.config.type == \'magnitude\':\n        consensus_reg = [tf.square(g) for g in d_grads if g is not None]\n        Jgrads = tf.gradients(consensus_reg, d_vars) + [tf.zeros_like(g) for g in g_vars]\n    else:\n        consensus_reg = 0.5 * sum(\n                tf.reduce_sum(tf.square(g)) for g in d_grads if g is not None\n        )\n        Jgrads = tf.gradients(consensus_reg, d_vars, stop_gradients=d_vars) + [tf.zeros_like(g) for g in g_vars]\n    new_grads = [g+jg*self._beta if jg is not None else g for g,v,jg in zip(all_grads, var_list, Jgrads)]\n    new_grads_and_vars = list(zip(new_grads, var_list)).copy()\n    return self.optimizer.apply_gradients(new_grads_and_vars, global_step=global_step, name=name)\n\n  \n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n'"
hypergan/optimizers/experimental/depth_optimizer.py,10,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass DepthOptimizer(optimizer.Optimizer):\n  """"""Steps multiple times and decays results""""""\n  def __init__(self, learning_rate=0.001, decay=0.9, gan=None, config=None, use_locking=False, name=""depthOptimizer"", optimizer=None, depth=3):\n    super().__init__(use_locking, name)\n    self._decay = decay\n    self._depth = depth\n    self.gan = gan\n    self.config = config\n    self.name = name\n    self.optimizer = self.gan.create_optimizer(optimizer)\n\n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    d_vars = []\n    g_vars = []\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n        else:\n            raise Exception(""Couldn\'t find var in g_vars or d_vars"")\n\n    if self.config.apply_on == ""discriminator"":\n        depth_vars = d_vars\n    else:\n        depth_vars = d_vars + g_vars\n    with ops.init_scope():\n        [self._get_or_make_slot(v, v, ""depth"", self.name) for v in depth_vars]\n        self.optimizer._create_slots([v for g,v in grads_and_vars])\n        for name in self.optimizer.get_slot_names():\n            for var in self.optimizer.variables():\n                self._zeros_slot(var, ""depth"", self.name)\n\n    self._prepare()\n    depth_slots = [self.get_slot(v, ""depth"") for v in depth_vars]\n    for name in self.optimizer.get_slot_names():\n        for var in self.optimizer.variables():\n            depth_vars += [var]\n            depth_slots += [self._zeros_slot(var, ""depth"", self.name)]\n\n    def calculate_depth(grads_and_vars_k,k=0):\n        if(k == 0):\n            return tf.group(*[tf.assign(v,nv) for v,nv in zip(depth_vars, depth_slots)])\n\n        op2 = self.optimizer.apply_gradients(grads_and_vars_k, global_step=global_step, name=name)\n        with tf.get_default_graph().control_dependencies([op2]):\n            w_k_combined = [self._decay *w_k_1 + (1.-self._decay)*w_hat for w_hat, w_k_1 in zip(depth_slots, depth_vars)]\n            op3 = tf.group(*[tf.assign(w, v) for w,v in zip(depth_slots, w_k_combined)]) # store variables\n            with tf.get_default_graph().control_dependencies([op3]):\n                d_loss, g_loss = self.gan.loss.sample\n                d_grads = tf.gradients(d_loss, d_vars)\n                g_grads = tf.gradients(g_loss, g_vars)\n                grads_k_1 = d_grads + g_grads\n                grads_and_vars_k_1 = list(zip(grads_k_1,depth_vars)).copy()\n                return calculate_depth(grads_and_vars_k_1,k-1)\n\n    op1 = tf.group(*[tf.assign(w, v) for w,v in zip(depth_slots, depth_vars)]) # store variables\n    with tf.get_default_graph().control_dependencies([op1]):\n        opd = calculate_depth(grads_and_vars, self._depth)\n        with tf.get_default_graph().control_dependencies([opd]):\n            return tf.no_op()\n\n  \n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n\n  def _apply_dense(self, grad, var):\n    raise NotImplementedError(""_apply_dense not callable."")\n\n  def variables(self):\n      return self.optimizer.variables()\n'"
hypergan/optimizers/experimental/ema_optimizer.py,6,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass EmaOptimizer(optimizer.Optimizer):\n  """"""Applies exponential moving average""""""\n  def __init__(self, learning_rate=0.001, decay=0.9, gan=None, config=None, use_locking=False, name=""EmaOptimizer"", optimizer=None):\n    super().__init__(use_locking, name)\n    self._decay = decay\n    self.gan = gan\n    self.config = config\n    self.name = name\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    d_vars = []\n    g_vars = []\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n\n    if self.config.apply_on == ""discriminator"":\n        ema_vars = d_vars\n    else:\n        ema_vars = d_vars + g_vars\n    with ops.init_scope():\n        [self._get_or_make_slot(v, v, ""ema"", self._name) for v in ema_vars]\n        self.optimizer._create_slots([v for g,v in grads_and_vars])\n        for name in self.optimizer.get_slot_names():\n            for var in self.optimizer.variables():\n                self._zeros_slot(var, ""ema"", self.name)\n\n    self._prepare()\n    ema_slots = [self.get_slot(v, ""ema"") for v in ema_vars]\n    for name in self.optimizer.get_slot_names():\n        for var in self.optimizer.variables():\n            ema_vars += [var]\n            ema_slots += [self._zeros_slot(var, ""ema"", self.name)]\n\n    def calculate_ema(_v1,_v2):\n        return self._decay *_v1 + (1-self._decay)*_v2\n    op1 = tf.group(*[tf.assign(w, v) for w,v in zip(ema_slots, ema_vars)]) # store variables\n    with tf.get_default_graph().control_dependencies([op1]):\n        op2 = self.optimizer.apply_gradients(grads_and_vars, global_step=global_step, name=name)\n        with tf.get_default_graph().control_dependencies([op2]):\n            calculated_ema = [calculate_ema(v1, v2) for v1,v2 in zip(ema_slots, ema_vars)] # store variables\n            op3 = tf.group(*[tf.assign(w, v) for w,v in zip(ema_vars, calculated_ema)])\n            with tf.get_default_graph().control_dependencies([op3]):\n                return tf.no_op()\n\n  \n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n\n  def variables(self):\n      return super().variables() + self.optimizer.variables()\n'"
hypergan/optimizers/experimental/gan_optimizer.py,1,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass GANOptimizer(optimizer.Optimizer):\n  """"""\n    Splits optimization targets between g_optimizer and g_optimizer\n  """"""\n\n  def __init__(self, _, gan=None, config=None, g_optimizer=None, d_optimizer=None, name=""GANOptimizer""):\n    super().__init__(config.learn_rate, name=name)\n    self.gan = gan\n    self.config = config\n\n    self.d_optimizer = self.gan.create_optimizer(d_optimizer)\n    self.g_optimizer = self.gan.create_optimizer(g_optimizer)\n\n  def _prepare(self):\n    super()._prepare()\n    self.d_optimizer._prepare()\n    self.g_optimizer._prepare()\n\n  def variables(self):\n    return self.d_optimizer.variables() + self.g_optimizer.variables()\n\n  def get_slot_names(self):\n    return self.d_optimizer.get_slot_names() + self.g_optimizer.get_slotnames()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    d_vars = [v for v in var_list if v in self.gan.d_vars()]\n    g_vars = [v for v in var_list if v in self.gan.g_vars()]\n    self.d_optimizer._create_slots(d_vars)\n    self.g_optimizer._create_slots(g_vars)\n    missing_vars = [v for v in var_list if v not in self.gan.g_vars() + self.gan.d_vars()]\n    if len(missing_vars) > 0:\n        print(""Error, GANOptimizer does not know how to handle missing variables (not in d_vars or g_vars)"", missing_vars)\n        raise(""Error, GANOptimizer does not know how to handle missing variables (not in d_vars or g_vars)"")\n\n  def _apply_dense(self, grad, var):\n    if var in self.gan.d_vars():\n        return self.d_optimizer._apply_dense(grad, var)\n    elif var in self.gan.g_vars():\n        return self.g_optimizer._apply_dense(grad, var)\n    raise(""Unable to handle"", var)\n\n\n  def get_slot_names(self):\n      return list(set(self.d_optimizer.get_slot_names() + self.g_optimizer.get_slot_names()))\n\n  def get_slot(self, var, name):\n      return self.d_optimizer.get_slot(var, name) or self.g_optimizer.get_slot(var, name)\n  \n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    d_vars = self.gan.d_vars()\n    args = []\n    if len(grads_and_vars) > len(d_vars):\n        args += [self.g_optimizer.apply_gradients(grads_and_vars[len(d_vars):], global_step, name)]\n    args += [self.d_optimizer.apply_gradients(grads_and_vars[:len(d_vars)], global_step, name)]\n    return tf.group(*args)\n'"
hypergan/optimizers/experimental/jr_optimizer.py,31,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass JROptimizer(optimizer.Optimizer):\n  """"""https://arxiv.org/pdf/1806.09235.pdf""""""\n  def __init__(self, learning_rate=0.001, p=0.1, gan=None, config=None, use_locking=False, name=""SOSOptimizer"", optimizer=None, alpha=1):\n    super().__init__(use_locking, name)\n    self._alpha = alpha\n    self.gan = gan\n    self.config = config\n    self._lr_t = learning_rate\n\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def finite_differences(self, grads_and_vars, global_step, name, d_vars, g_vars, d_grads, g_grads):\n    all_vars = [ v for _,v in grads_and_vars]\n    all_grads = [ g for g, _ in grads_and_vars ]\n    d_grads = all_grads[:len(d_vars)]\n    g_grads = all_grads[len(d_vars):]\n    d_vars = []\n    g_vars = []\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n\n    with ops.init_scope():\n        [self._zeros_slot(v, ""orig"", self._name) for _,v in grads_and_vars]\n        slots_list = []\n        if self.config.include_slots:\n            for name in self.optimizer.get_slot_names():\n                for var in self.optimizer.variables():\n                    slots_list.append(self.optimizer._zeros_slot(var, ""orig"", ""orig""))\n\n    v1 = [self.get_slot(v, ""orig"") for _,v in grads_and_vars]\n    slots_list = []\n    slots_vars = []\n\n    restored_vars = all_vars + slots_vars\n    tmp_vars = v1 + slots_list\n\n    e1 = 0.0001\n    e2 = 0.0001\n\n    #gamma12\n    save = tf.group(*[tf.assign(w, v) for w,v in zip(tmp_vars, restored_vars)]) # store variables\n    restore = tf.group(*[tf.assign(w, v) for w,v in zip(restored_vars, tmp_vars)]) # store variables\n\n    def curl():\n        grads = tf.gradients(self.gan.trainer.d_loss, d_vars) + tf.gradients(self.gan.trainer.g_loss, g_vars)\n        op3 = tf.group(*[tf.assign_sub(v, self._lr_t*grad) for grad,v in zip(grads, all_vars)])\n        with tf.get_default_graph().control_dependencies([op3]):\n            def curlcombine(g1,g2):\n                stepsize = self._lr_t\n                return g1-(g2-g1)/stepsize\n            new_grads = tf.gradients(self.gan.trainer.d_loss, d_vars) + tf.gradients(self.gan.trainer.g_loss, g_vars)\n            g3s = [curlcombine(g1,g2) for g1,g2 in zip(grads,new_grads)]\n            return g3s\n \n    #gamma12\n    with tf.get_default_graph().control_dependencies([save]):\n        #opboth = self.optimizer.apply_gradients(grads_and_vars, global_step=global_step, name=name)\n        #opdp = self.optimizer.apply_gradients(grads_and_vars[:len(d_vars)], global_step=global_step, name=name)\n        #opgp = self.optimizer.apply_gradients(grads_and_vars[len(d_vars):], global_step=global_step, name=name)\n        opboth = tf.group(*[tf.assign_sub(w, self._lr_t * v) for w,v in zip(all_vars, all_grads)]) # store variables\n        opd = tf.group(*[tf.assign_sub(w, self._lr_t * v) for w,v in zip(d_vars, d_grads)]) # store variables\n        opg = tf.group(*[tf.assign_sub(w, self._lr_t * v) for w,v in zip(g_vars, g_grads)]) # store variables\n        with tf.get_default_graph().control_dependencies([opboth]):\n            gboth = curl()#tf.gradients(self.gan.trainer.d_loss, d_vars) + tf.gradients(self.gan.trainer.g_loss, g_vars)\n            with tf.get_default_graph().control_dependencies([restore]):\n                with tf.get_default_graph().control_dependencies([opd]):\n                    #new_d_grads = [tf.zeros_like(_d) for _d in d_vars]+tf.gradients(self.gan.trainer.g_loss, g_vars)\n                    new_d_grads = curl()#tf.gradients(self.gan.trainer.d_loss, d_vars) + tf.gradients(self.gan.trainer.g_loss, g_vars)\n                    with tf.get_default_graph().control_dependencies([restore]):\n                        with tf.get_default_graph().control_dependencies([opg]):\n                            #new_g_grads = tf.gradients(self.gan.trainer.d_loss, d_vars) + [tf.zeros_like(_g) for _g in g_vars]\n                            new_g_grads = curl()#tf.gradients(self.gan.trainer.d_loss, d_vars) + tf.gradients(self.gan.trainer.g_loss, g_vars)\n                            with tf.get_default_graph().control_dependencies([restore]):\n                                new_grads = []\n                                for _gboth, _gd, _gg, _g in zip(gboth,new_d_grads,new_g_grads,d_grads):\n                                    det = tf.square(_gboth)-(_gg*_gd)+1e-8\n                                    h_1 = 1.0/det * (2*_gboth - _gd - _gg)\n                                    if self.config.hessian:\n                                        #v = (g(x + hjej)-g(x)))/(2hj) + \\\n                                        #    (g(x + hiei)-g(x))/(2hi)\n                                        a = (_gboth - _g) / self._lr_t # d2f/dx2i\n                                        c = (_gboth - _g) / self._lr_t # d2f/dx2j\n                                        b = (_gg - _g) / (2*self._lr_t)+(_gd-_g)/(2*self._lr_t) # d2f/dx1dx2\n                                        d = b # d2f/dx2dx1\n                                        det = a*d-b*c+1e-8\n                                        #h_1 = 1.0/det * (b+d-a-c)\n                                        h_1_a = d/det\n                                        h_1_b = -b/det\n                                        h_1_c = -c/det\n                                        h_1_d = a/det\n\n                                        h_1 = h_1_a*h_1_d-h_1_b*h_1_c\n                                    new_grads.append( _g*h_1 )\n\n                                for _gboth, _gd, _gg, _g in zip(gboth[len(d_vars):],new_d_grads[len(d_vars):],new_g_grads[len(d_vars):],g_grads):\n                                    det = tf.square(_gboth)-(_gg*_gd)+1e-8\n                                    h_1 = 1.0/det * (2*_gboth - _gd - _gg)\n                                    if self.config.hessian:\n                                        #v = (g(x + hjej)-g(x)))/(2hj) + \\\n                                        #    (g(x + hiei)-g(x))/(2hi)\n                                        a = (_gboth - _g) / self._lr_t # d2f/dx2i\n                                        c = (_gboth - _g) / self._lr_t # d2f/dx2j\n                                        b = (_gg - _g) / (2*self._lr_t)+(_gd-_g)/(2*self._lr_t) # d2f/dx1dx2\n                                        d = b # d2f/dx2dx1\n                                        det = a*d-b*c+1e-8\n                                        #h_1 = 1.0/det * (b+d-a-c)\n                                        h_1_a = d/det\n                                        h_1_b = -b/det\n                                        h_1_c = -c/det\n                                        h_1_d = a/det\n                                        h_1 = h_1_a*h_1_d-h_1_b*h_1_c\n                                    new_grads.append( _g*h_1 )\n\n                                new_grads_and_vars = list(zip(new_grads, all_vars)).copy()\n                                return self.optimizer.apply_gradients(new_grads_and_vars, global_step=global_step, name=name)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    all_vars = [ v for _,v in grads_and_vars]\n    d_vars = []\n    g_vars = []\n    all_grads = [ g for g, _ in grads_and_vars ]\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n\n    with ops.init_scope():\n        self.optimizer._create_slots([v for g,v in grads_and_vars])\n    self._prepare()\n\n    d_grads = all_grads[:len(d_vars)]\n    g_grads = all_grads[len(d_vars):]\n    if self.config.finite_differences:\n        return self.finite_differences(grads_and_vars, global_step, name, d_vars, g_vars, d_grads, g_grads)\n    dc_grads = sum([tf.reduce_sum(tf.square(d)) for d in d_grads])\n    gc_grads = sum([tf.reduce_sum(tf.square(g)) for g in g_grads])\n    gamma12 = tf.gradients(gc_grads, d_vars) + [tf.zeros_like(g) for g in g_vars]\n    gamma21 = [tf.zeros_like(d) for d in d_vars] + tf.gradients(dc_grads, g_vars)\n\n    gamma12 = [ tf.zeros_like(ddg) if _dg is None else _dg for ddg, _dg in zip(all_vars, gamma12) ]\n    gamma21 = [ tf.zeros_like(ddg) if _dg is None else _dg for ddg, _dg in zip(all_vars, gamma21) ]\n    __gamma12 = [ tf.reduce_sum(_gamma12) for _gamma12 in gamma12 ]\n    __gamma21 = [ tf.reduce_sum(_gamma21) for _gamma21 in gamma21 ]\n    #gamma12_metric = self.gan.ops.squash(sum(gamma12))\n    gamma12_metric = self.gan.ops.squash(sum(__gamma12))\n    self.gan.add_metric(\'gamma12\', gamma12_metric)\n    gamma21_metric = self.gan.ops.squash(sum(__gamma21))\n    self.gan.add_metric(\'gamma21\', gamma21_metric)\n   \n    new_grads = []\n    for _gamma12, _gamma21, _grads in zip(gamma12, gamma21, all_grads):\n        Eo = _grads - \\\n             0.5*self._alpha*_gamma21 +\\\n             0.5*self._alpha*_gamma12\n        new_grads += [ Eo ]\n\n    new_grads_and_vars = list(zip(new_grads, all_vars)).copy()\n\n    return self.optimizer.apply_gradients(new_grads_and_vars, global_step=global_step, name=name)\n  \n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n'"
hypergan/optimizers/experimental/negative_momentum_optimizer.py,5,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass NegativeMomentumOptimizer(optimizer.Optimizer):\n  """"""Steps multiple times and decays results""""""\n  def __init__(self, learning_rate=0.001, decay=1.0, gan=None, config=None, use_locking=False, name=""NegativeMomentumOptimizer"", optimizer=None):\n    super().__init__(use_locking, name)\n    self._decay = decay\n    self.gan = gan\n    self.config = config\n    self.name = name\n    self.optimizer = self.gan.create_optimizer(optimizer)\n\n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    d_vars = []\n    g_vars = []\n    d_grads = []\n    g_grads = []\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n            d_grads += [grad]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n            g_grads += [grad]\n        else:\n            raise ValidationException(""Couldn\'t find var in g_vars or d_vars "" + var.name)\n    grad_list = d_grads + g_grads\n    var_list = d_vars + g_vars\n\n    with ops.init_scope():\n            nms = [self._get_or_make_slot(v, tf.zeros_like(v), ""nm"", self._name) for v in var_list]\n    self._prepare()\n\n    nms = [self.get_slot(v, ""nm"") for v in var_list]\n    momentum = []\n    for grad, nm, w in zip(grad_list, nms, var_list):\n        momentum += [-self._decay * nm]\n\n    newgrads = [g + m for g, m in zip(grad_list, momentum)]\n\n    new_grads_and_vars = list(zip(newgrads, var_list)).copy()\n\n    op2 = self.optimizer.apply_gradients(new_grads_and_vars, global_step=global_step, name=name)\n    with tf.get_default_graph().control_dependencies([op2]):\n        save = tf.group(*[tf.assign(nm, ((self.config.alpha or 0.666) *grad+ (1-self.config.beta or 0.5)*nm)) for nm, grad in zip(nms, grad_list)])\n        with tf.get_default_graph().control_dependencies([save]):\n            return tf.no_op()\n\n  \n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n\n  def _apply_dense(self, grad, var):\n    raise NotImplementedError(""_apply_dense not callable."")\n\n  def variables(self):\n      return self.optimizer.variables()\n'"
hypergan/optimizers/experimental/orthonormal_optimizer.py,14,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass OrthonormalOptimizer(optimizer.Optimizer):\n  def __init__(self, learning_rate=0.001, p=0.1, gan=None, config=None, use_locking=False, name=""CurlOptimizer"", optimizer=None, rho=1, beta=1, gamma=1):\n    super().__init__(use_locking, name)\n    self.gan = gan\n    self.config = config\n\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    var_list = [ v for _,v in grads_and_vars]\n    flin = [ g for g,_ in grads_and_vars]\n    d_vars = []\n    g_vars = []\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n\n\n    consensus_reg = [tf.square(g) for g in flin[:len(d_vars)] if g is not None]\n    Jgrads = tf.gradients(consensus_reg, d_vars) + [tf.zeros_like(g) for g in g_vars]\n    shapes = [self.gan.ops.shape(l) for l in flin]\n    u = [tf.reshape(l, [-1]) for l in flin[:len(d_vars)]]\n    v = [tf.reshape(l, [-1]) if l is not None else tf.reshape(tf.zeros_like(v), [-1]) for l,v in zip(Jgrads[:len(d_vars)], d_vars)]\n    \n    def proj(u, v,shape):\n        dot = tf.tensordot(v, u, 1) / (tf.square(u)+1e-8)\n        dot = tf.maximum(0.0, dot)\n        dot = tf.minimum(1.0, dot)\n        dot = dot * u\n        dot = tf.reshape(dot, shape)\n        return dot\n    proj_u1_v2 = [proj(_u, _v, _s) for _u, _v, _s in zip(u, v, shapes)]\n    flin = [_flin + self.gan.configurable_param(self.config.ortholambda) * proj for _flin, proj in zip(flin, proj_u1_v2)] + flin[len(d_vars):]\n\n    step3 = list(zip(flin, var_list))\n    op6 = self.optimizer.apply_gradients(step3.copy(), global_step=global_step, name=name)\n\n\n    with tf.get_default_graph().control_dependencies([op6]):\n        return tf.no_op()\n\n                    # Flin = gamma * IF - rho * JF + beta * JtF\n                    #op7 = tf.group(*[tf.assign_add(gsw, (jg * self._beta)) if jg is not None else tf.no_op() for gsw, jg in zip(gswap, Jgrads)])\n                    #with tf.get_default_graph().control_dependencies([op7]):\n                    #    flin_grads_and_vars = zip(gswap, var_list)\n                    #    # step 1\n                    #    op8 = self.optimizer.apply_gradients(list(flin_grads_and_vars).copy(), global_step=global_step, name=name)\n                    #    with tf.get_default_graph().control_dependencies([op8]):\n                    #        return tf.no_op()\n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n  def variables(self):\n      return super().variables() + self.optimizer.variables()\n'"
hypergan/optimizers/experimental/potential_optimizer.py,20,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass PotentialOptimizer(optimizer.Optimizer):\n  def __init__(self, learning_rate=0.001, p=0.1, gan=None, config=None, use_locking=False, name=""CurlOptimizer"", optimizer=None, rho=1, beta=1, gamma=1):\n    super().__init__(use_locking, name)\n    self.gan = gan\n    self.config = config\n    self.name = name\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    var_list = [ v for _,v in grads_and_vars]\n    grad_list = [ g for g,_ in grads_and_vars]\n    d_vars = []\n    g_vars = []\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n\n    with ops.init_scope():\n        [self._get_or_make_slot(v, v, ""potential"", self._name) for v in var_list]\n        [self._get_or_make_slot(v, v, ""start"", self._name) for v in var_list]\n        self.optimizer._create_slots([v for g,v in grads_and_vars])\n        for name in self.optimizer.get_slot_names():\n            for var in self.optimizer.variables():\n                self._zeros_slot(var, ""potential"", self.name)\n                self._zeros_slot(var, ""start"", self.name)\n\n    self._prepare()\n    potential_slots = [self.get_slot(v, ""potential"") for v in var_list]\n    start_slots = [self.get_slot(v, ""start"") for v in var_list]\n    for name in self.optimizer.get_slot_names():\n        for var in self.optimizer.variables():\n            var_list += [var]\n            potential_slots += [self._zeros_slot(var, ""potential"", self.name)]\n            start_slots += [self._zeros_slot(var, ""start"", self.name)]\n\n    consensus_reg = [tf.square(g) for g in grad_list[:len(d_vars)] if g is not None]\n    Jgrads = tf.gradients(consensus_reg, d_vars) + [tf.zeros_like(g) for g in g_vars]\n\n    shapes = [self.gan.ops.shape(l) for l in grad_list]\n    u = [tf.reshape(l, [-1]) for l in grad_list[:len(d_vars)]]\n    v = [tf.reshape(l, [-1]) if l is not None else tf.reshape(tf.zeros_like(v), [-1]) for l,v in zip(Jgrads[:len(d_vars)], d_vars)]\n    \n    def proj(u, v,shape):\n        bounds = [-1.0,1.0]\n        if self.config.ortho_bounds:\n            bounds = self.config.ortho_bounds\n        dot = tf.tensordot(v, u, 1) / (tf.square(u)+1e-8)\n        dot = tf.maximum(bounds[0], dot)\n        dot = tf.minimum(bounds[1], dot)\n        dot = dot * u\n        dot = tf.reshape(dot, shape)\n        return dot\n    projs = [proj(_u, _v, _s) for _u, _v, _s in zip(u, v, shapes)]\n    if self.config.formulation == \'g-p,-p\':\n        h_grads = [grad-proj for grad, proj in zip(grad_list, projs)]\n    elif self.config.formulation == \'g-p,g-p\':\n        h_grads = [grad-proj for grad, proj in zip(grad_list, projs)]\n    elif self.config.formulation == \'g-p,g+p\':\n        h_grads = [grad-proj for grad, proj in zip(grad_list, projs)]\n    elif self.config.formulation == \'p,-p\':\n        h_grads = [proj for grad, proj in zip(grad_list, projs)]\n    elif self.config.formulation == \'g-p,p\':\n        h_grads = [grad-proj for grad, proj in zip(grad_list, projs)]\n    else:\n        h_grads = [grad+proj for grad, proj in zip(grad_list, projs)]\n    step1_grads = h_grads + grad_list[len(d_vars):]\n\n    step1 = list(zip(step1_grads, var_list))\n\n    mlam = self.config.merge_lambda or 0.5\n\n    op1 = tf.group(*[tf.assign(w, v) for w,v in zip(start_slots, var_list)]) # store variables\n    with tf.get_default_graph().control_dependencies([op1]):\n        op2 = self.optimizer.apply_gradients(step1.copy(), global_step=global_step, name=name)\n        with tf.get_default_graph().control_dependencies([op2]):\n            op3 = tf.group(*[tf.assign(w, v) for w,v in zip(potential_slots, var_list)]) # store variables\n            with tf.get_default_graph().control_dependencies([op3]):\n                op4 = tf.group(*[tf.assign(w, v) for w,v in zip(var_list, start_slots)])\n                with tf.get_default_graph().control_dependencies([op4]):\n                    if self.config.formulation == \'p,-p\':\n                        p_grads = [-proj for _g, proj in zip(grad_list, projs)]\n                    elif self.config.formulation == \'g-p,g-p\':\n                        p_grads = [_g-proj for _g, proj in zip(grad_list, projs)]\n                    elif self.config.formulation == \'g-p,g+p\':\n                        p_grads = [_g+proj for _g, proj in zip(grad_list, projs)]\n                    elif self.config.formulation == \'g-p,-p\':\n                        p_grads = [-proj for _g, proj in zip(grad_list, projs)]\n                    elif self.config.formulation == \'g-p,p\':\n                        p_grads = [proj for _g, proj in zip(grad_list, projs)]\n                    else:\n                        p_grads = [proj for _g, proj in zip(grad_list, projs)]\n                    step2_grads = p_grads + grad_list[len(d_vars):]\n                    step2 = list(zip(step2_grads, var_list))\n                    op5 = self.optimizer.apply_gradients(step2.copy(), global_step=global_step, name=name)\n                    with tf.get_default_graph().control_dependencies([op5]):\n                        if self.config.ema:\n                            op6 = tf.group(*[tf.assign(w, self.config.ema*start + (1.0-self.config.ema)*(mlam*h+(1-mlam)*p)) for start,w,h,p in zip(start_slots, var_list, var_list, potential_slots)])\n                        else:\n                            op6 = tf.group(*[tf.assign(w, mlam*h+(1-mlam)*p) for w,h,p in zip(var_list, var_list, potential_slots)])\n                        with tf.get_default_graph().control_dependencies([op6]):\n                            return tf.no_op()\n\n\n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n  def variables(self):\n      return super().variables() + self.optimizer.variables()\n'"
hypergan/optimizers/experimental/predictive_method_optimizer.py,7,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass PredictiveMethodOptimizer(optimizer.Optimizer):\n  """""" https://openreview.net/pdf?id=Skj8Kag0Z """"""\n  def __init__(self, learning_rate=0.001, p=0.1, gan=None, config=None, use_locking=False, name=""PredictiveMethodOptimizer"", optimizer=None, rho=1, beta=1, gamma=1):\n    super().__init__(use_locking, name)\n    self.gan = gan\n    self.config = config\n    self._lr_t = learning_rate\n\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    var_list = [ v for _,v in grads_and_vars]\n    d_vars = []\n    g_vars = []\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n\n    with ops.init_scope():\n        v1 = [self._zeros_slot(v, ""v1"", self._name) for _,v in grads_and_vars]\n        if self.config.include_slots:\n            for name in self.optimizer.get_slot_names():\n                for var in self.optimizer.variables():\n                    self._zeros_slot(var, ""pm"", ""pm"")\n    self._prepare()\n\n    v1 = [self.get_slot(v, ""v1"") for _,v in grads_and_vars]\n    slots_list = []\n    slots_vars = []\n    if self.config.include_slots:\n        for name in self.optimizer.get_slot_names():\n            for var in self.optimizer.variables():\n                slots_vars += [var]\n                slots_list.append(self._zeros_slot(var, ""pm"", ""pm""))\n\n\n    current_vars = var_list + slots_vars\n    tmp_vars = v1 + slots_list\n    all_grads = [ g for g, _ in grads_and_vars ]\n\n    op1 = tf.group(*[tf.assign(w, v) for w,v in zip(tmp_vars, current_vars)]) # store variables\n\n    with tf.get_default_graph().control_dependencies([op1]):\n        # store g2\n        #op3 = tf.group(*[tf.assign_sub(v, self._lr_t*grad) for grad,v in grads_and_vars])\n        op3 = self.optimizer.apply_gradients(grads_and_vars.copy(), global_step=global_step, name=name)\n        with tf.get_default_graph().control_dependencies([op3]):\n\n            def pmcombine(_v1,_v2):\n                return _v2 + (_v2 - _v1)\n\n            combined = [pmcombine(_v1, _v2) for _v1, _v2 in zip(tmp_vars, current_vars)]\n            # restore v1, slots\n            op5 = tf.group(*[ tf.assign(w,v) for w,v in zip(current_vars, combined)])\n            with tf.get_default_graph().control_dependencies([op5]):\n                return tf.no_op()\n\n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n  def variables(self):\n      return self.optimizer.variables()\n'"
hypergan/optimizers/experimental/sga_optimizer.py,9,"b'# Symplectic Gradient Adjustment\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass SgaOptimizer(optimizer.Optimizer):\n  def __init__(self, learning_rate=0.001, p=0.1, gan=None, config=None, use_locking=False, name=""CurlOptimizer"", optimizer=None, rho=1, beta=1, gamma=1,loss=None):\n    super().__init__(use_locking, name)\n    self._beta = beta\n    self._rho = rho\n    self._gamma = gamma\n    self.gan = gan\n    self.config = config\n    self._lr_t = learning_rate\n    self.loss = loss\n    optimizer[""loss""] = loss\n\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n\n  def fwd_gradients(self, ys, xs, grad_xs=None, stop_gradients=None, colocate_gradients_with_ops=True):\n    us = [tf.zeros_like(y) + float(\'nan\') for y in ys]\n    dydxs = tf.gradients(ys, xs, grad_ys=us,stop_gradients=stop_gradients,colocate_gradients_with_ops=colocate_gradients_with_ops)\n    dydxs = [tf.zeros_like(x) if dydx is None else dydx for x,dydx in zip(xs,dydxs)]\n    dysdx = tf.gradients(dydxs, us, grad_ys=grad_xs, colocate_gradients_with_ops=colocate_gradients_with_ops)\n    return dysdx\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    ws = [v for _,v in grads_and_vars]\n    grads = [g for g,_ in grads_and_vars]\n    self._prepare()\n\n    jac_vec = self.fwd_gradients(grads,ws, grad_xs=grads,stop_gradients=ws)\n    jac_vec = [tf.zeros_like(x) if dydx is None else dydx for x,dydx in zip(ws,jac_vec)]\n    jac_tran_vec = tf.gradients(grads, ws, grad_ys=grads, stop_gradients=ws)\n    jac_tran_vec = [tf.zeros_like(x) if dydx is None else dydx for x,dydx in zip(ws,jac_tran_vec)]\n    at_xi = [(ht-h)*0.5 for (h,ht) in zip(jac_vec, jac_tran_vec)]\n\n\n    if self.config.minus:\n        new_grads = [g-a for g,a in zip(grads, at_xi)]\n    else:\n        new_grads = [g+a for g,a in zip(grads, at_xi)]\n    grads_and_vars2 = zip(new_grads, ws)\n    op8 = self.optimizer.apply_gradients(list(grads_and_vars2).copy(), global_step=global_step, name=name)\n    with tf.get_default_graph().control_dependencies([op8]):\n        return tf.no_op()\n\n\n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n  def variables(self):\n      return super().variables() + self.optimizer.variables()\n'"
hypergan/optimizers/experimental/social_optimizer.py,10,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass SocialOptimizer(optimizer.Optimizer):\n  def __init__(self, learning_rate=0.001, p=0.1, gan=None, config=None, use_locking=False, name=""SocialOptimizer"", optimizer=None, rho=1, beta=1, gamma=1):\n    """"""https://arxiv.org/pdf/1803.03021.pdf""""""\n    super().__init__(use_locking, name)\n    self.gan = gan\n    self.config = config\n    self._lr_t = learning_rate\n\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    var_list = [ v for _,v in grads_and_vars]\n    d_vars = []\n    g_vars = []\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n    w = [tf.Variable(self.config.start_at or 0.0), tf.Variable(self.config.start_at or 0.0)]\n\n    Vidv = [self.gan.trainer.d_loss, self.gan.trainer.g_loss]\n    #Vsoc = [1/2. * self.gan.trainer.d_loss + 1/2.* self.gan.trainer.g_loss, -1/2. * self.gan.trainer.d_loss - 1/2.* self.gan.trainer.g_loss]\n    Vsoc = [1/2. * self.gan.trainer.d_loss + 1/2.* self.gan.trainer.g_loss, 1/2. * self.gan.trainer.d_loss + 1/2.* self.gan.trainer.g_loss]\n\n    wlr = self.config.w_learn_rate or 0.01\n    wt1 = [w[0] + wlr * (Vidv[0] - Vsoc[0]), w[1] + wlr * (Vidv[1] - Vsoc[1])]\n    def clamped(net):\n        return tf.maximum(self.config.min or 0., tf.minimum(net, self.config.max or 1.))\n\n    self._prepare()\n\n    wt1 = [clamped(wt1[0]),clamped(wt1[1])]\n    self.gan.add_metric(\'wt0\', wt1[0])\n    self.gan.add_metric(\'wt1\', wt1[1])\n    op1 = tf.group(*[tf.assign(w, v) for w,v in zip(w, wt1)]) # store variables\n\n    with tf.get_default_graph().control_dependencies([op1]):\n        Vi = [(1. - w[0]) * Vidv[0] + w[0] * Vsoc[0],\n              (1. - w[1]) * Vidv[1] + w[1] * Vsoc[1]]\n        if self.config.reverse_w:\n            Vi = [(w[0]) * Vidv[0] + (1.0-w[0]) * Vsoc[0],\n                  (w[1]) * Vidv[1] + (1.0-w[1]) * Vsoc[1]]\n        self.gan.add_metric(\'w0\', w[0])\n        self.gan.add_metric(\'w1\', w[1])\n\n        new_grads = tf.gradients(Vi[0], d_vars) + tf.gradients(Vi[1], g_vars)\n        self.gan.trainer.d_loss = Vi[0]\n        self.gan.trainer.g_loss = Vi[1]\n        new_grads_and_vars = list(zip(new_grads, var_list)).copy()\n        op3 = self.optimizer.apply_gradients(new_grads_and_vars.copy(), global_step=global_step, name=name)\n        with tf.get_default_graph().control_dependencies([op3]):\n            if(self.config.w_l1):\n                # return to selfish state\n                wt1 = [wt1[0] + self.config.w_l1 * ((self.config.l1_default or 0.0)-wt1[0]),\n                       wt1[1] + self.config.w_l1 * ((self.config.l1_default or 0.0)-wt1[1])]\n                op4 = tf.group(*[tf.assign(w, v) for w,v in zip(w, wt1)]) # store variables\n                with tf.get_default_graph().control_dependencies([op4]):\n                    self.gan.add_metric(\'l1w0\', w[0])\n                    self.gan.add_metric(\'l1w1\', w[1])\n                    return tf.no_op()\n\n            else:\n                return tf.no_op()\n\n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n  def variables(self):\n      return self.optimizer.variables()\n'"
hypergan/optimizers/experimental/sos_optimizer.py,50,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\n\nclass SOSOptimizer(optimizer.Optimizer):\n  def __init__(self, learning_rate=0.001, p=0.1, gan=None, config=None, use_locking=False, name=""SOSOptimizer"", optimizer=None, alpha=1):\n    super().__init__(use_locking, name)\n    self._alpha = alpha\n    self.gan = gan\n    self.config = config\n    self._lr_t = learning_rate\n    self.optimizer = self.gan.create_optimizer(optimizer)\n \n  def _prepare(self):\n    super()._prepare()\n    self.optimizer._prepare()\n\n  def _create_slots(self, var_list):\n    super()._create_slots(var_list)\n    self.optimizer._create_slots(var_list)\n\n  def _apply_dense(self, grad, var):\n    return self.optimizer._apply_dense(grad, var)\n\n  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n    all_vars = [ v for _,v in grads_and_vars]\n    d_vars = []\n    g_vars = []\n    all_grads = [ g for g, _ in grads_and_vars ]\n    for grad,var in grads_and_vars:\n        if var in self.gan.d_vars():\n            d_vars += [var]\n        elif var in self.gan.g_vars():\n            g_vars += [var]\n        else:\n            raise(""Couldn\'t find var in g_vars or d_vars"")\n\n    with ops.init_scope():\n        [self._get_or_make_slot(v, v, ""restore"", self._name) for v in all_vars]\n        self.optimizer._create_slots([v for g,v in grads_and_vars])\n        for name in self.optimizer.get_slot_names():\n            for var in self.optimizer.variables():\n                self._zeros_slot(var, ""restore"", self._name)\n\n    self._prepare()\n    restore_slots = [self.get_slot(v, ""restore"") for v in all_vars]\n    restore_vars = all_vars\n    for name in self.optimizer.get_slot_names():\n        for var in self.optimizer.variables():\n            restore_vars += [var]\n            restore_slots += [self._zeros_slot(var, ""restore"", self._name)]\n\n\n    d_grads = all_grads[:len(d_vars)]\n    g_grads = all_grads[len(d_vars):]\n    dc_grads = [tf.reduce_sum(tf.square(d)) for d in d_grads]\n    gc_grads = [tf.reduce_sum(tf.square(g)) for g in g_grads]\n    l1 = self.gan.trainer.d_loss# + lookahead_l2\n    l2 = self.gan.trainer.g_loss# + lookahead_l1\n    #h11 = tf.gradients(d_grads, d_vars) + tf.gradients(d_grads, g_vars, stop_gradients=g_vars)\n    h11 = tf.gradients(d_grads, d_vars) + [tf.zeros_like(g) for g in g_vars]\n    h12 = tf.gradients(gc_grads, d_vars) + [tf.zeros_like(g) for g in g_vars]\n    h21 = [tf.zeros_like(d) for d in d_vars] + tf.gradients(dc_grads, g_vars)\n    #h22 = tf.gradients(g_grads, d_vars) + tf.gradients(g_grads, g_vars, stop_gradients=d_vars)\n    h22 = [tf.zeros_like(d) for d in d_vars] + tf.gradients(g_grads, g_vars)\n    #h22 = [tf.zeros_like(d) for d in all_vars]\n    h11 = [ tf.zeros_like(_dg) if ddg is None else _dg for ddg, _dg in zip(all_vars, h11) ]\n    h12 = [ tf.zeros_like(_dg) if ddg is None else _dg for ddg, _dg in zip(all_vars, h12) ]\n    h21 = [ tf.zeros_like(_dg) if ddg is None else _dg for ddg, _dg in zip(all_vars, h21) ]\n    h22 = [ tf.zeros_like(_dg) if ddg is None else _dg for ddg, _dg in zip(all_vars, h22) ]\n    h21 = [ -_dg for _dg in h12 ]\n    h22 = [ -_dg for _dg in h12 ]\n    __h11 = [ tf.reduce_sum(_h11) for _h11 in h11 ]\n    __h12 = [ tf.reduce_sum(_h12) for _h12 in h12 ]\n    __h21 = [ tf.reduce_sum(_h21) for _h21 in h21 ]\n    __h22 = [ tf.reduce_sum(_h22) for _h22 in h22 ]\n    #h12_metric = self.gan.ops.squash(sum(h12))\n    h11_metric = self.gan.ops.squash(sum(__h11))\n    self.gan.add_metric(\'h11\', h11_metric)\n    h12_metric = self.gan.ops.squash(sum(__h12))\n    self.gan.add_metric(\'h12\', h12_metric)\n    h21_metric = self.gan.ops.squash(sum(__h21))\n    self.gan.add_metric(\'h21\', h21_metric)\n    h22_metric = self.gan.ops.squash(sum(__h22))\n    self.gan.add_metric(\'h22\', h22_metric)\n    ho = []\n    for _h12, _h21 in zip(h12, h21):\n        zero = tf.zeros_like(_h12)\n        shape = self.gan.ops.shape(_h12)\n        #_ho = tf.stack([zero, _h11, _h22, zero])\n        _ho = tf.stack([tf.stack([zero, _h12]),tf.stack([_h21, zero])])\n        ho.append(_ho)\n\n   \n    eps = []\n    m = tf.constant(0.0)\n    for _h12, _h21, _grads, _ho in zip(h12, h21, all_grads, ho):\n        # (I - alpha*Ho)\n        Eo = 2.0 * _grads - \\\n             self._alpha*_h21 * _grads -\\\n             self._alpha*_h12 * _grads\n        m += tf.reduce_sum(Eo)\n        eps += [ Eo ]\n\n    self.gan.add_metric(\'m\', m)\n    new_grads = eps\n    new_grads_and_vars = list(zip(new_grads, all_vars)).copy()\n\n    diag = []\n    ho_t = []\n\n\n    op1 = tf.group(*[tf.assign(w, v) for w,v in zip(restore_slots, restore_vars)]) # store variables\n    with tf.get_default_graph().control_dependencies([op1]):\n        #lookahead = DepthOptimizer(learning_rate=0.001, decay=1.0, gan=None, config=None, use_locking=False, name=""depthOptimizer"", optimizer=self.optimizer, depth=1)\n        #op2 = lookahead.apply_gradients(eps)\n        op2 = self.optimizer.apply_gradients(new_grads_and_vars, global_step=global_step, name=name)\n        with tf.get_default_graph().control_dependencies([op2]):\n            new_grads2 = tf.gradients(self.gan.trainer.d_loss, d_vars) + tf.gradients(self.gan.trainer.g_loss, g_vars)\n            new_grads3 = []\n            p1s = tf.constant(0.0)\n            p2s = tf.constant(0.0)\n            p1_masks = tf.constant(0.0)\n            p2_masks = tf.constant(0.0)\n            p1v2s = tf.constant(0.0)\n            ps = tf.constant(0.0)\n            for _grad1, _grad2, _ho in zip(eps, new_grads2, ho):\n                axis = [i for i in range(len(self.gan.ops.shape(_ho)))]\n                _X = (_ho[1][0] + _ho[0][1])*_grad2\n                _Xr = tf.reshape(_X, [-1])\n                _grad1r = tf.reshape(_grad1, [-1])\n                angle = tf.tensordot(-self._alpha * _Xr, _grad1r, 1)\n                p1_mask = (tf.sign(angle) + 1.0) / 2.0\n                aeo = - self.config.a * (tf.square(tf.norm(_grad1)))/(angle+1e-8)\n                p1 = tf.minimum(1.0, aeo)\n                p1 = p1_mask + (1.0-p1_mask) * p1\n                p2_mask = (tf.sign((tf.norm(_grad1)) - self.config.b) + 1.0) / 2.0\n                p2 = tf.square(tf.norm(_grad1)) * p2_mask + (1.0-p2_mask)\n                p = tf.minimum(p1, p2)\n                p1v2 = tf.reduce_sum(tf.sign(p1-p2))\n                ps+=tf.reduce_sum(p)\n                p1s+=tf.reduce_sum(p1)\n                p2s+=tf.reduce_sum(p2)\n                p1v2s+=tf.reduce_sum(p1v2)\n                p1_masks+=tf.reduce_sum(p1_mask)\n                p2_masks+=tf.reduce_sum(p2_mask)\n\n                if self.config.lola:\n                    new_grads3 += [_grad1 - _X * self._alpha]\n                else:\n                    new_grads3 += [_grad1 - p * _X * self._alpha]\n\n            self.gan.add_metric(""p1m"",p1_masks)\n            self.gan.add_metric(""p2m"",p2_masks)\n            self.gan.add_metric(""p1v2"",p1v2s)\n            self.gan.add_metric(""p"",ps)\n            self.gan.add_metric(""p1"",p1s)\n            self.gan.add_metric(""p2"",p2s)\n            new_grads_and_vars3 = list(zip(new_grads3, all_vars)).copy()\n            op3 = tf.group(*[tf.assign(w, v) for w,v in zip(restore_vars, restore_slots)]) # store variables\n            with tf.get_default_graph().control_dependencies([op3]):\n                return self.optimizer.apply_gradients(new_grads_and_vars3, global_step=global_step, name=name)\n\n  \n  def _apply_sparse(self, grad, var):\n    raise NotImplementedError(""Sparse gradient updates are not supported."")\n'"
hypergan/train_hooks/experimental/adversarial_robust_train_hook.py,12,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass AdversarialRobustTrainHook(BaseTrainHook):\n  ""AR from https://openreview.net/pdf?id=HJE6X305Fm""\n  def __init__(self, gan=None, config=None, trainer=None, name=""GradientPenaltyTrainHook""):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    if hasattr(self.gan, \'x0\'):\n        gan_inputs = self.gan.x0\n    else:\n        gan_inputs = self.gan.inputs.x\n    config = hc.Config(config)\n\n    if \'lambda\' in config:\n        self._lambda = self.gan.configurable_param(config[\'lambda\'])\n    else:\n        self._lambda = 1.0\n    self._vlambda = self.gan.configurable_param(config.vlambda or 1.0)\n\n    self.trainablex=tf.Variable(tf.zeros_like(self.gan.inputs.x))\n    self.trainableg=tf.Variable(tf.zeros_like(self.gan.inputs.x))\n    clearx=tf.assign(self.trainablex, tf.zeros_like(self.gan.inputs.x))\n    clearg=tf.assign(self.trainableg, tf.zeros_like(self.gan.inputs.x))\n    with tf.get_default_graph().control_dependencies([clearx, clearg]):\n        self.adversarial_discriminator = gan.create_component(gan.config.discriminator, name=""discriminator"", input=tf.concat([gan.inputs.x+self.trainablex,gan.generator.sample+self.trainableg],axis=0), features=[gan.features], reuse=True)\n        self.v = tf.gradients(self.adversarial_discriminator.sample, [self.trainablex, self.trainableg])\n        self.v = [self._vlambda*v/tf.norm(v, ord=2) for v in self.v]\n\n        self.robustness_discriminator = gan.create_component(gan.config.discriminator, name=\'discriminator\', input=tf.concat([gan.inputs.x+self.v[0], gan.generator.sample+self.v[1]], axis=0), features=[gan.features], reuse=True)\n\n        if config.loss_type == \'gan\':\n            self.loss = gan.create_component(gan.config.loss, self.robustness_discriminator).sample\n        else:\n            self.loss = tf.square(self.robustness_discriminator.sample - gan.discriminator.sample)\n\n        self.loss = [self._lambda * self.loss[0], self._lambda * self.loss[1]]\n\n        #self.loss = gan.create_component(gan.config.loss, self.robustness_discriminator)\n        self.gan.add_metric(\'adl\', self.loss[0])\n        self.gan.add_metric(\'agl\', self.loss[1])\n        self.gan.add_metric(\'vx\', tf.reduce_sum(self.v[0]))\n        self.gan.add_metric(\'vg\', tf.reduce_sum(self.v[1]))\n\n  def losses(self):\n    return self.loss\n'"
hypergan/train_hooks/experimental/force_equilibrium_train_hook.py,1,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass ForceEquilibriumTrainHook(BaseTrainHook):\n  ""Forces d_fake close to d_real iff too far apart""\n  def __init__(self, gan=None, config=None, trainer=None, name=""GpSnMemoryTrainHook"", distance=0.001, lam=1.0):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n\n    klip = self.gan.configurable_param(distance)\n    k_lip = (lam * tf.nn.relu(tf.abs(tf.reduce_mean(self.gan.loss.d_real-self.gan.loss.d_fake))-klip))\n    self.gan.add_metric(""force_eq"", k_lip)\n    self.loss = [k_lip, None]\n\n  def losses(self):\n      return self.loss\n\n'"
hypergan/train_hooks/experimental/gradient_locally_stable_train_hook.py,3,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass GradientLocallyStableTrainHook(BaseTrainHook):\n  def __init__(self, gan=None, config=None, trainer=None, name=""GradientLocallyStableTrainHook"", memory_size=2, top_k=1):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    d_vars = gan.d_vars()\n    g_vars = gan.g_vars()\n    d_loss = gan.loss.sample[0]\n    gls = tf.gradients(d_loss, d_vars+g_vars)\n    gls = tf.square(tf.global_norm(gls))\n    self.g_loss = self.config[""lambda""] * gls\n    self.add_metric(\'gradient_locally_stable\', ops.squash(gls, tf.reduce_mean))\n\n  def losses(self):\n    return [None, self.g_loss]\n\n  def after_step(self, step, feed_dict):\n    pass\n\n  def before_step(self, step, feed_dict):\n    pass\n'"
hypergan/train_hooks/experimental/imle_train_hook.py,12,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass IMLETrainHook(BaseTrainHook):\n  """"""https://arxiv.org/pdf/1809.09087.pdf""""""\n  def __init__(self, gan=None, config=None, trainer=None, name=""ClosestExampleTrainHook"", search_size=4, memory_size=1, new_entries=-1):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    latent = gan.latent\n    if self.config.use_encoder:\n        latent = gan.u_to_z\n    self.x_matched = [ tf.Variable(tf.zeros_like(gan.generator.sample)) for j in range(memory_size)]\n    self.latent_max = tf.Variable( tf.zeros_like(latent.sample))\n    self.latent = [ tf.Variable(tf.zeros_like(latent.sample)) for j in range(memory_size)]\n    self.assign_x = [tf.assign(self.x_matched[j], gan.inputs.x) for j in range(memory_size)]\n    self.d_lambda = config[\'lambda\'] or 1\n\n    self.search_size = search_size\n    self.memory_size = memory_size\n    self.new_entries = new_entries\n    if self.new_entries == -1:\n        self.new_entries = memory_size\n\n    if self.config.use_encoder:\n        encoded = self.gan.encoder.sample\n        self.assign_encoded_latent = [self.latent[j].assign(encoded) for j in range(memory_size)]\n    else:\n        self.assign_latent_to_min = [self.latent[j].assign(self.latent_max) for j in range(memory_size)]\n    self.assign_latent = self.latent_max.assign(latent.sample)\n\n    l2_losses = tf.zeros([1])\n    self.gi = []\n    for j in range(memory_size):\n        self.gi.append(self.gan.create_generator(self.latent[j], reuse=True))\n        diff = tf.abs(self.gi[-1].sample-self.x_matched[j])\n        n = tf.norm(diff, ord=2)\n        l2_losses += tf.reduce_sum(diff/n)\n        \n    self.l2_loss_on_saved = tf.reduce_sum(self.d_lambda * l2_losses)\n\n    l2_losses = []\n    for j in range(memory_size):\n        diff = tf.abs(gan.generator.sample-self.x_matched[j])\n        n = tf.norm(diff, ord=2)\n        l2_losses.append(tf.reduce_sum(diff/n))\n\n    self.l2_loss_on_g = l2_losses\n    self.offset = 0\n\n    self.gan.add_metric(\'perceptual\', self.l2_loss_on_saved)\n\n  def losses(self):\n      return [None, self.l2_loss_on_saved]\n\n  def after_step(self, step, feed_dict):\n      pass\n\n  def before_step(self, step, feed_dict):\n    if step % (self.config.step_count or 1000) != 0:\n      return\n\n    new_entries = self.new_entries\n    if step == 0:\n        new_entries = self.memory_size\n    print(""[IMLE] recalculating likelihood"")\n    if self.config.use_encoder:\n        for j in range(new_entries):\n            _j = (j+self.offset) % self.memory_size\n            self.gan.session.run([self.assign_x[_j], self.assign_encoded_latent[_j]])\n    else:\n        for j in range(new_entries):\n            _j = (j+self.offset) % self.memory_size\n            self.gan.session.run(self.assign_x[_j])\n            min_score = None\n            for i in range(self.search_size):\n                s,_ = self.gan.session.run([self.l2_loss_on_g[_j], self.assign_latent])\n                if( min_score == None or min_score > s):\n                    self.gan.session.run(self.assign_latent_to_min[_j])\n                    min_score = s\n                else:\n                    pass\n                    #print(""Ignoring score"", s)\n            print(""  Min "", min_score)\n    self.offset += new_entries\n\n'"
hypergan/train_hooks/experimental/input_fitness_train_hook.py,9,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass InputFitnessTrainHook(BaseTrainHook):\n  ""Keep track of Xs with high discriminator values""\n  def __init__(self, gan=None, config=None, trainer=None, name=""GpSnMemoryTrainHook"", memory_size=2, top_k=1):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    gan_inputs = self.gan.inputs.x\n\n    self.input = tf.split(self.gan.inputs.x, self.gan.batch_size(), axis=0)\n    fitness = self.gan.loss.d_real\n    if self.config.abs:\n        fitness = tf.abs(self.gan.loss.d_real)\n    if self.config.reverse:\n        fitness = -self.gan.loss.d_real\n    if self.config.nabs:\n        fitness = -tf.abs(self.gan.loss.d_real)\n    self.d_real = tf.split(fitness, self.gan.batch_size(), axis=0)\n    self.feed_input = tf.split(self.gan.feed_x, self.gan.batch_size(), axis=0)\n\n    self.sample_batch = self.gan.set_x\n    cache_count = self.gan.batch_size()\n    self.cache = [tf.Variable(tf.zeros_like(self.input[i])) for i in range(len(self.input))]\n    print(""C "", self.cache, self.input)\n    self.set_cache = [tf.assign(c, x) for c, x in zip(self.cache, self.input)]\n    if self.config.skip_restore is None:\n        self.restore_cache = [[tf.assign(self.gan.inputs.x[i], tf.reshape(self.cache[j], self.ops.shape(self.gan.inputs.x[i]))) for i in range(self.gan.batch_size())]  for j in range(self.gan.batch_size())]\n        for i in range(self.gan.batch_size()):\n            restore = []\n            for j in range(self.gan.batch_size()):\n                op = tf.assign(self.gan.inputs.x[i], tf.reshape(self.cache[j], self.ops.shape(self.gan.inputs.x[i])))\n                restore.append(op)\n            self.restore_cache.append(restore)\n    self.loss = [None, None]\n\n  def after_step(self, step, feed_dict):\n    pass\n\n  def losses(self):\n      return self.loss\n\n  def before_step(self, step, feed_dict):\n    if step == 0:\n        self.gan.session.run(self.sample_batch)\n    def sort():\n        raw_winners = np.argsort(np.array(scores).flatten())\n        winners = raw_winners[:self.gan.batch_size()]\n\n        sticky = 0\n        total = 0\n        cache_winners = [ scorei for scorei in winners if scorei < self.gan.batch_size()]\n        losers = [ i for i in range(self.gan.batch_size()) if (i+self.gan.batch_size()) not in winners ]\n\n        if self.config.skip_restore is None:\n            for loser, cache_winner in zip(cache_winners, losers):\n                self.gan.session.run(self.restore_cache[loser][cache_winner])\n        #if total == sticky or sticky == 0:\n        #    print(""Sticky ""+str(sticky) + "" / ""+ str(total))\n\n    if self.config.heuristic is not None:\n        count = 0\n        previous_last_score = 1000\n    search_steps = self.config.search_steps\n    if self.config.search_steps is None:\n        search_steps = 1\n\n    if search_steps == 0:\n        self.gan.session.run(self.sample_batch)\n\n    for i in range(search_steps):\n        scores = []\n        scores += self.gan.session.run(self.d_real)\n        self.gan.session.run(self.set_cache)\n        self.gan.session.run(self.sample_batch)\n        scores += self.gan.session.run(self.d_real)\n        sort()\n        if self.config.heuristic is not None:\n            last_score = np.sort(np.array(scores).flatten())[-1]\n            if last_score < previous_last_score:\n                count = 0\n                previous_last_score = last_score\n            else:\n                count += 1\n                if(count > self.config.heuristic):\n                    #print(i+1)\n                    break\n\n        if self.config.verify:\n            sortedscores = np.sort(np.array(scores).flatten())\n            newscores =np.sort(np.array(self.gan.session.run(self.d_real)).flatten())\n            print(i)\n            print(sortedscores[:self.gan.batch_size()].flatten())\n            print(np.sort(np.array(newscores).flatten()))\n            print(np.sort(newscores.flatten()) == np.array(sortedscores[:self.gan.batch_size()]).flatten())\n\n\n'"
hypergan/train_hooks/experimental/k_lipschitz_train_hook.py,2,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass KLipschitzTrainHook(BaseTrainHook):\n  def __init__(self, gan=None, config=None, trainer=None, name=""KLipschitzTrainHook"", memory_size=2, top_k=1):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    if config.ragan:\n        lipschitz_penalty = tf.maximum(tf.square(d_real-d_fake) - 1, 0) + tf.maximum(tf.square(d_fake-d_real) - 1, 0)\n        self.add_metric(\'k_lipschitz_ragan\', lipschitz_penalty)\n    else:\n        lipschitz_penalty = tf.maximum(tf.square(d_real) - 1, 0) + tf.maximum(tf.square(d_fake) - 1, 0)\n        self.add_metric(\'k_lipschitz\', ops.squash(lipschitz_penalty))\n    self.d_loss = lipschitz_penalty\n\n  def losses(self):\n    return [self.d_loss, None]\n\n  def after_step(self, step, feed_dict):\n    pass\n\n  def before_step(self, step, feed_dict):\n    pass\n'"
hypergan/train_hooks/experimental/match_support_train_hook.py,35,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nfrom hypergan.viewer import GlobalViewer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass MatchSupportTrainHook(BaseTrainHook):\n  """""" Makes d_fake and d_real match by training on a zero-based addition to the input images. """"""\n  def __init__(self, gan=None, config=None, trainer=None, name=""GradientPenaltyTrainHook"", layer=""match_support"", variables=[""x"",""g""]):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    component = getattr(self.gan,self.config.component or ""discriminator"")\n        \n    if not isinstance(layer, list):\n        layer = [layer]\n    m_x = [component.layer(l+""_mx"") for l in layer]\n    m_g = [component.layer(l+""_mg"") for l in layer]\n    if \'x\' in variables:\n        self.zero_x = [tf.assign(m, tf.zeros_like(m)) for m in m_x]\n    else:\n        self.zero_x = [tf.no_op()]\n    if \'g\' in variables:\n        self.zero_g = [tf.assign(m, tf.zeros_like(m)) for m in m_g]\n    else:\n        self.zero_g = [tf.no_op()]\n    target = getattr(self.gan, self.config.target or ""loss"")\n    self.target = target\n    d_fake = target.d_fake\n    d_real = target.d_real\n    if self.config.loss == ""base"":\n        self.loss = tf.reduce_mean(tf.square(d_fake - d_real))*(self.config.loss_lambda or 10000.0)\n    if self.config.loss == ""zero"":\n        self.loss += tf.reduce_mean(tf.square(d_fake))*10000.0\n    if self.config.loss == ""wgan"":\n        self.loss = tf.reduce_mean(tf.square(d_fake))*10000.0\n        self.loss += tf.reduce_mean(tf.square(d_real))*10000.0\n    if self.config.loss == ""close"":\n        self.loss += tf.reduce_mean(tf.square(tf.nn.relu(-d_fake-0.1)))*1000.0\n        self.loss += tf.reduce_mean(tf.square(tf.nn.relu(d_fake-0.1)))*1000.0\n    if self.config.loss == ""close2"":\n        self.loss = tf.reduce_mean(tf.square(tf.nn.relu(tf.abs(d_fake)-(self.config.distance or 0.1))))*1000.0\n        self.loss += tf.reduce_mean(tf.square(tf.nn.relu(tf.abs(d_real)-(self.config.distance or 0.1))))*1000.0\n    if self.config.loss == \'fixed\':\n        self.loss = tf.reduce_mean(tf.square(tf.reduce_mean(d_fake - d_real)))*(self.config.loss_lambda or 10000.0)\n    if self.config.loss == \'fixed2\':\n        self.loss = tf.reduce_mean(tf.square(tf.nn.relu(tf.reduce_mean(d_real) - tf.reduce_mean(d_fake))))*(self.config.loss_lambda or 10000.0)\n    if self.config.loss == \'ali2\':\n        self.loss = tf.reduce_mean(tf.square(tf.nn.relu(tf.reduce_mean(self.gan.standard_loss.d_real) - tf.reduce_mean(self.gan.standard_loss.d_fake))))*(self.config.loss_lambda or 10000.0)\n        self.loss += tf.reduce_mean(tf.square(tf.nn.relu(tf.reduce_mean(self.gan.z_loss.d_real) - tf.reduce_mean(self.gan.z_loss.d_fake))))*(self.config.loss_lambda or 10000.0)\n\n    if self.config.loss == \'fixed5\':\n        self.loss = tf.reduce_mean(tf.square(tf.nn.relu(tf.reduce_mean(d_real) - tf.reduce_mean(d_fake))))*(self.config.loss_lambda or 10000.0)\n        self.loss += tf.reduce_mean(tf.square(tf.nn.relu(tf.abs(d_fake)-(self.config.distance or 0.01))))*10000.0\n        self.loss += tf.reduce_mean(tf.square(tf.nn.relu(tf.abs(d_real)-(self.config.distance or 0.01))))*10000.0\n        self.gan.add_metric(\'d_fake_ms\', tf.reduce_mean(tf.square(tf.nn.relu(tf.abs(d_fake)-(self.config.distance or 0.01))))*10000.0)\n        self.gan.add_metric(\'ms_loss\', self.loss)\n    if self.config.loss == \'fixed7\':\n        self.loss = tf.reduce_mean(tf.square(tf.nn.relu(tf.abs(d_fake)-(self.config.distance or 0.01))))*10000.0\n        self.loss += tf.reduce_mean(tf.square(tf.nn.relu(tf.abs(d_real)-(self.config.distance or 0.01))))*10000.0\n    if self.config.loss == \'d1\':\n        self.loss = tf.reduce_mean(tf.square(tf.nn.relu(tf.abs(d_fake)-(self.config.distance or 0.01))))*10000.0\n        self.loss += tf.reduce_mean(tf.square(tf.nn.relu(tf.abs(d_real)-(self.config.distance or 0.01))))*10000.0\n \n    if self.config.loss == ""fixed3"":\n        self.loss = tf.reduce_mean(tf.square(d_real+0.05))*1000.0\n        self.loss += tf.reduce_mean(tf.square(d_fake-0.05))*1000.0\n    if self.config.loss == \'fixed4\':\n        self.loss = tf.reduce_mean(tf.square(tf.nn.relu(tf.reduce_mean(d_real) - tf.reduce_mean(d_fake))))*(self.config.loss_lambda or 10000.0)\n        self.loss += tf.reduce_mean(tf.square(tf.nn.relu(-d_fake)))*(self.config.loss_lambda or 10000.0)\n    if self.config.loss == \'targets\':\n        self.loss = tf.reduce_mean(tf.square(-d_fake-1e3))*(self.config.loss_lambda or 10000.0)\n        self.loss += tf.reduce_mean(tf.square(d_real-1e3))*(self.config.loss_lambda or 10000.0)\n    if self.config.loss == \'absdiff\':\n        self.loss = tf.reduce_mean(tf.square(tf.abs(d_fake)-tf.abs(d_real)))*(self.config.loss_lambda or 10000.0)\n    if self.config.loss == \'xor\':\n        self.loss = tf.reduce_mean(tf.square(d_fake+d_real))*(self.config.loss_lambda or 10000.0)\n        self.loss += tf.reduce_mean(tf.square(tf.abs(d_fake) - 0.01))*1000.0\n\n\n\n\n    var_list = []\n    for v in variables:\n        if ""x"" == v:\n            [var_list.append(m) for m in m_x]\n            continue\n        if ""g"" == v:\n            [var_list.append(m) for m in m_g]\n            continue\n        var_list.append(getattr(self.gan, v).variables())\n    self.initial_learn_rate = self.config.optimizer.learn_rate\n    self.learn_rate = tf.Variable(self.config.optimizer.learn_rate)\n    self.config.optimizer[\'learn_rate\']=self.learn_rate\n    self.optimizer = self.gan.create_optimizer(self.config.optimizer)\n    self.train_t = self.optimizer.minimize(self.loss, var_list=var_list)\n    self.reset_optimizer_t = tf.variables_initializer(self.optimizer.variables())\n\n  def before_step(self, step, feed_dict, depth=0):\n    max_depth = self.config.max_depth\n    if max_depth is None:\n        max_depth = 2\n    begin = self.gan.session.run(self.loss, feed_dict)\n    last_loss = begin\n    if last_loss < self.config.loss_threshold:\n        if self.config.verbose:\n            print(self.config.component, ""> Loss begin "" + str(begin) + "" skipping training"")\n        return\n    learn_rate = self.initial_learn_rate / 2*(depth+1)\n    feed_dict[self.learn_rate] = learn_rate\n    if self.config.verbose:\n        print(""Learn rate: "", learn_rate)\n    self.gan.session.run(self.zero_x+ self.zero_g+ [self.reset_optimizer_t])\n    for i in range((self.config.max_steps or 100)*(1+depth)):\n        _ = self.gan.session.run(self.train_t, feed_dict)\n        loss = self.gan.session.run(self.loss, feed_dict)\n        if np.any(np.isnan(loss)) or np.any(np.isinf(loss)):\n            if max_depth == depth+1:\n                print(""NAN during X and G training.  Resetting."")\n                return self.before_step(step, feed_dict, depth+1)\n        convergence = 1.0-loss/last_loss\n        last_loss = loss\n        if self.config.verbose:\n            print(""Convergence:"", convergence, loss)\n        if (self.config.convergence_threshold is not None and convergence < self.config.convergence_threshold) and convergence > 0.0:\n            if self.config.verbose:\n                print(""Convergence threshold reached"", self.config.convergence_threshold)\n            break\n\n        if self.config.loss_threshold is not None and loss < self.config.loss_threshold:\n            if self.config.verbose:\n                print(""Loss threshold reached"", self.config.loss_threshold)\n            break\n\n    if i+1 == ((self.config.max_steps or 100)*(1+depth)) and loss > self.config.loss_threshold:\n        if max_depth != depth+1:\n            print(""No convergence, decreasing learn rate"", feed_dict[self.learn_rate], depth, loss)\n            return self.before_step(step, feed_dict, depth+1)\n\n    print(self.config.component, ""> steps"", i, ""Loss begin "" + str(begin) + "" Loss end ""+str(i)+"":"", loss, ""lr"", feed_dict[self.learn_rate])\n\n  def after_step(self, step, feed_dict):\n    self.gan.session.run(self.zero_x+ self.zero_g)\n'"
hypergan/train_hooks/experimental/memory_train_hook.py,3,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport inspect\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass MemoryTrainHook(BaseTrainHook):\n  def __init__(self, gan=None, config=None, trainer=None, name=""MemoryTrainHook""):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    self.past_weights = []\n    self.prev_sample = tf.Variable(self.gan.generator.sample, dtype=tf.float32)\n    self.prev_zs = []\n    self.update_prev_sample = tf.assign(self.prev_sample, self.gan.generator.sample)\n    self.prev_l2_loss = self.ops.squash(tf.square(self.gan.generator.sample-self.prev_sample))\n    self.g_loss = self.prev_l2_loss * (self.config[\'lambda\'] or 1)\n    self.gan.add_metric(\'mem\', self.g_loss)\n\n  def losses(self):\n\n    return [None, self.g_loss]\n\n  def after_step(self, step, feed_dict):\n    pass\n\n  def before_step(self, step, feed_dict):\n    if step == 0:\n        # z0 = z\n        _, *self.prev_zs = self.gan.session.run([self.update_prev_sample]+self.gan.fitness_inputs(), feed_dict)\n        return\n    gan = self.gan\n\n    # assign prev sample for previous z\n    # replace previous z with new z\n    prev_feed_dict = {}\n    for v, t in ( [ [v, t] for v, t in zip(self.prev_zs, gan.fitness_inputs())]):\n        prev_feed_dict[t]=v\n    # l2 = ||(pg(z0) - g(z0))||2\n    prev_l2_loss = gan.session.run(self.g_loss, prev_feed_dict)\n    # pg(z0) = g(z)\n\n    # z0 = z\n    if (step % (self.config.stepsize or 1)) == 0:\n        _, *self.prev_zs = self.gan.session.run([self.update_prev_sample]+self.gan.fitness_inputs())\n\n    # optimize(l2, gl, dl)\n    feed_dict[self.g_loss] = prev_l2_loss\n\n'"
hypergan/train_hooks/experimental/minibatch_train_hook.py,23,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass MinibatchTrainHook(BaseTrainHook):\n  def __init__(self, gan=None, config=None, trainer=None, name=""MinibatchTrainHook""):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n\n    config = self.config\n    setattr(gan,config.name or \'minibatch\', self)\n\n    net = gan.discriminator.layer(config.target or \'minibatch\')\n    minibatch_size = gan.batch_size()*2\n    single_batch_size = gan.batch_size()\n    if self.config.gan_input is None:\n        n_kernels = config.kernels or 256\n        dim_per_kernel = config.dim_per_kernel or 10\n        print(""[discriminator] minibatch from"", net, ""to"", n_kernels*dim_per_kernel)\n        net = tf.reshape(net, [minibatch_size, -1])\n        initializer = self.ops.lookup_initializer(""stylegan"", config.initializer_options or {})\n        x = self.ops.linear(net, n_kernels * dim_per_kernel, initializer=initializer)\n        activation = tf.reshape(x, (minibatch_size, n_kernels, dim_per_kernel))\n\n        big = np.zeros((minibatch_size, minibatch_size))\n        big += np.eye(minibatch_size)\n        big = tf.expand_dims(big, 1)\n        big = tf.cast(big,dtype=tf.float32)\n\n        abs_dif = tf.reduce_sum(tf.abs(tf.expand_dims(activation,3) - tf.expand_dims(tf.transpose(activation, [1, 2, 0]), 0)), 2)\n        mask = 1. - big\n        masked = tf.exp(-abs_dif) * mask\n        def half(tens, second):\n            m, n, _ = tens.get_shape()\n            m = int(m)\n            n = int(n)\n            return tf.slice(tens, [0, 0, second * single_batch_size], [m, n, single_batch_size])\n\n        f1 = tf.reduce_sum(half(masked, 0), 2) / tf.reduce_sum(half(mask, 0))\n        f2 = tf.reduce_sum(half(masked, 1), 2) / tf.reduce_sum(half(mask, 1))\n        stack_f = tf.concat([f1,f2], axis=0)\n\n    if self.config.type == \'gan\':\n        if self.config.gan_input == \'distance\':\n            real, fake = tf.split(net, 2, 0)\n            stack_f = tf.concat([real - fake,fake-real],  axis=0)\n        if self.config.gan_input == \'moments\':\n            real, fake = tf.split(net, 2, 0)\n            rm,rv = tf.nn.moments(real, 0)\n            fm,fv = tf.nn.moments(fake, 0)\n            rm = tf.expand_dims(rm,0)\n            rv = tf.expand_dims(rv,0)\n            fm = tf.expand_dims(fm,0)\n            fv = tf.expand_dims(fv,0)\n            print(""_____"", fm)\n            r = tf.concat([rm, rv], axis=0)\n            f = tf.concat([fm, fv], axis=0)\n            stack_f = tf.concat([r,f],  axis=0)\n        minibatch_discriminator = gan.create_component(self.config.discriminator or gan.config.minibatch_discriminator, name=(config.name or \'minibatch_discriminator\'), input=stack_f)\n        setattr(gan, config.name+""_discriminator"", minibatch_discriminator)\n        gan.discriminator.add_variables(minibatch_discriminator)\n        loss = gan.create_component(self.gan.config.loss, minibatch_discriminator)\n        gan.add_metric(\'mini_dl\', loss.sample[0])\n        gan.add_metric(\'mini_gl\', loss.sample[1])\n        self.loss = loss.sample\n    else:\n        self.minibatch_value = tf.concat([f1, f2], axis=1)\n        self.minibatch_feed = gan.discriminator.layer(\'minibatch_feed\')\n        self.loss = [None, None]\n    gan.discriminator.add_variables(self)\n\n  def losses(self):\n      return self.loss\n\n  def after_step(self, step, feed_dict):\n      pass\n\n  def before_step(self, step, feed_dict):\n    if self.config.type != \'gan\':\n      feed_dict[self.minibatch_feed]=self.gan.session.run(self.minibatch_value)\n\n    pass\n'"
hypergan/train_hooks/experimental/progress_compress_train_hook.py,12,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nEPS=1e-8\n\nclass ProgressCompressTrainHook(BaseTrainHook):\n  """"""https://arxiv.org/pdf/1805.06370v2.pdf""""""\n  def __init__(self, gan=None, config=None, trainer=None, name=""ProgressCompressTrainHook""):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    d_loss = []\n\n    self.x = tf.Variable(tf.zeros_like(gan.inputs.x))\n    self.g = tf.Variable(tf.zeros_like(gan.generator.sample))\n\n    stacked = tf.concat([self.x, self.g], axis=0)\n    self.kb = gan.create_component(config[""knowledge_base""], name=""knowledge_base"", input=stacked)\n    self.assign_x = tf.assign(self.x, gan.inputs.x)\n    self.assign_g = tf.assign(self.g, gan.generator.sample)\n    self.re_init_d = [d.initializer for d in gan.discriminator.variables()]\n    gan.hack = self.g\n\n    self.assign_knowledge_base = []\n    for c in gan.components:\n        if hasattr(c, \'knowledge_base\'):\n            for name, net in c.knowledge_base:\n                assign = self.kb.named_layers[name]\n                if self.ops.shape(assign)[0] > self.ops.shape(net)[0]:\n                    assign = tf.slice(assign,[0 for i in self.ops.shape(net)] , [self.ops.shape(net)[0]]+self.ops.shape(assign)[1:])\n                self.assign_knowledge_base.append(tf.assign(net, assign))\n\n    def kl_divergence(_p, _q):\n        return tf.reduce_sum(_p * tf.log(_p/(_q+EPS)+EPS))\n\n    if self.config.method == \'gan\':\n        bs = gan.batch_size()\n        real = tf.reshape(gan.loss.sample[:2], [bs, 2])\n        fake = tf.reshape(self.kb.sample, [bs, 2])\n        gl = tf.concat([real, fake], axis=0)\n        self.kb_d = gan.create_component(self.config.knowledge_discriminator, name=""kb_d"", input=gl)\n        self.kb_loss = self.gan.create_loss(self.kb_d)\n        self.loss = self.kb_loss.sample[0] + self.kb_loss.sample[1]\n        variables = self.kb_d.variables()\n        variables += self.kb.variables()\n    else:\n        self.kb_loss = self.gan.create_component(gan.config.loss, discriminator=self.kb, split=2)\n\n        self.loss = kl_divergence(gan.loss.sample[0], self.kb_loss.sample[0])\n        if self.config.kl_on_d_fake:\n            self.loss = kl_divergence(gan.loss.d_real, self.kb_loss.d_real)\n        if self.config.kl_on_g:\n            self.loss += kl_divergence(gan.loss.sample[1], self.kb_loss.sample[1])\n        variables = self.kb.variables()\n    config[""optimizer""][""loss""] = self.loss\n    self.optimizer = self.gan.create_optimizer(config[""optimizer""])\n    grads = tf.gradients(self.loss, variables)\n    apply_vec = list(zip(grads, variables)).copy()\n    self.optimize_t = self.optimizer.apply_gradients(apply_vec, global_step=gan.global_step)\n\n    self.gan.add_metric(\'kbl\', self.kb_loss.sample[0])\n    self.gan.add_metric(\'kblg\', self.kb_loss.sample[1])\n    self.gan.add_metric(\'compress\', self.loss)\n\n  def losses(self):\n      return [None, None]\n\n  def after_step(self, step, feed_dict):\n    if step % (self.config.step_count or 1) != 0:\n      return\n    # compress\n    for i in range(self.config.night_steps or 1):\n        self.gan.session.run(self.optimize_t)\n    if self.config.reinitialize_every:\n        if step % (self.config.reinitialize_every)==0 and step > 0:\n            print(""Reinitializing active D"")\n            self.gan.session.run(self.re_init_d)\n\n  def before_step(self, step, feed_dict):\n    self.gan.session.run([self.assign_x, self.assign_g]+ self.assign_knowledge_base)\n\n'"
hypergan/train_hooks/experimental/zero_penalty_train_hook.py,1,"b'#From https://gist.github.com/EndingCredits/b5f35e84df10d46cfa716178d9c862a3\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.training import optimizer\nimport tensorflow as tf\nimport hyperchamber as hc\nimport numpy as np\nimport inspect\nfrom operator import itemgetter\nfrom hypergan.train_hooks.base_train_hook import BaseTrainHook\n\nclass ZeroPenaltyTrainHook(BaseTrainHook):\n  def __init__(self, gan=None, config=None, trainer=None, name=""GradientPenaltyTrainHook""):\n    super().__init__(config=config, gan=gan, trainer=trainer, name=name)\n    gan_inputs = self.gan.inputs.x\n\n    self._lambda = self.gan.configurable_param(config[\'lambda\'] or 1)\n\n    if self.config.component:\n        v = getattr(gan, self.config.component)\n    else:\n        v = gan.discriminator\n    if self.config.layer is not None:\n        layer = v.layer(self.config.layer)\n    else:\n        layer = v.sample\n    self.loss = self._lambda * tf.reduce_sum(tf.square(layer))\n    gan.add_metric(\'zero\', self.loss)\n\n  def losses(self):\n    return [self.loss, self.loss]\n'"
hypergan/trainers/experimental/consensus_trainer.py,7,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass ConsensusTrainer(BaseTrainer):\n    def create(self):\n        config = self.config\n        lr = config.learn_rate\n        self.global_step = tf.train.get_global_step()\n        decay_function = config.decay_function\n        if decay_function:\n            print(""!!using decay function"", decay_function)\n            decay_steps = config.decay_steps or 50000\n            decay_rate = config.decay_rate or 0.9\n            decay_staircase = config.decay_staircase or False\n            self.lr = decay_function(lr, self.global_step, decay_steps, decay_rate, decay_staircase)\n        else:\n            self.lr = lr\n\n        return self._create()\n\n\n    def _create(self):\n        gan = self.gan\n        config = self.config\n\n        d_vars = self.d_vars or gan.discriminator.variables()\n        g_vars = self.g_vars or (gan.encoder.variables() + gan.generator.variables())\n\n        loss = self.loss or gan.loss\n        d_loss, g_loss = loss.sample\n        allloss = d_loss + g_loss\n        allvars = d_vars + g_vars\n\n        d_grads = tf.gradients(d_loss, d_vars)\n        g_grads = tf.gradients(g_loss, g_vars)\n\n        grads = d_grads + g_grads\n\n        self.d_log = -tf.log(tf.abs(d_loss+TINY))\n        for g, d_v in zip(grads,d_vars):\n            if g is None:\n                print(""!!missing gradient"")\n                print(d_v)\n                return\n        reg = 0.5 * sum(\n            tf.reduce_sum(tf.square(g)) for g in grads if g is not None\n        )\n        # Jacobian times gradiant\n        if config.update_rule == ""ttur"" or config.update_rule == \'single-step\':\n            Jgrads = [0 for i in allvars]\n        else:\n            Jgrads = tf.gradients(reg, allvars)\n\n        print(""JG"", Jgrads)\n\n        self.g_gradient = tf.ones([1])\n        def amp_for(v):\n            if v in g_vars:\n                return config.g_w_lambda or 3\n            if v in d_vars:\n                return config.d_w_lambda or 1\n\n        def applyvec(g, jg, v, decay):\n            prev = v\n            nextw = v+g + jg * (config.jg_alpha or 0.1)\n            if decay is not None:\n                return ((decay) * prev + (1.0-decay)*nextw)-v\n            else:\n                return nextw-v\n\n        def gradient_for(g, jg, v, decay):\n            if config.update_rule == ""ttur"":\n                if decay is not None:\n                    amp = v+amp_for(v)*g\n                    ng = ((decay) * v + (1.0-decay)*amp)-v\n                else:\n                    ng = amp_for(v)*g\n            else:\n                if decay is not None:\n                    if v in g_vars:\n                        ng = applyvec(g, jg, v, decay)\n                    else:\n                        ng = applyvec(g, jg, v, None)\n                else:\n                    ng = applyvec(g, jg, v, decay)\n            return ng\n        decay = config.g_exponential_moving_average_decay\n        apply_vec = [ (gradient_for(g, Jg, v, decay), v) for (g, Jg, v) in zip(grads, Jgrads, allvars) if Jg is not None ]\n        apply_vec_d = [ (gradient_for(g, Jg, v, decay), v) for (g, Jg, v) in zip(d_grads, Jgrads[:len(d_vars)], d_vars) if Jg is not None ]\n        apply_vec_g = [ (gradient_for(g, Jg, v, decay), v) for (g, Jg, v) in zip(g_grads, Jgrads[len(d_vars):], g_vars) if Jg is not None ]\n\n        defn = {k: v for k, v in config.items() if k in inspect.getargspec(config.trainer).args}\n        tr = config.trainer(self.lr, **defn)\n\n\n        optimizer = tr.apply_gradients(apply_vec, global_step=self.global_step)\n        d_optimizer = tr.apply_gradients(apply_vec_d, global_step=self.global_step)\n        g_optimizer = tr.apply_gradients(apply_vec_g, global_step=self.global_step)\n\n        self.g_loss = g_loss\n        self.d_loss = d_loss\n        self.optimizer = optimizer\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n\n        return optimizer, optimizer\n\n    def required(self):\n        return ""trainer learn_rate"".split()\n\n    def _step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n        loss = self.loss or gan.loss\n        metrics = gan.metrics()\n\n        metric_values = sess.run([self.optimizer] + self.output_variables(metrics), feed_dict)[1:]\n\n        if self.current_step % 100 == 0:\n            print(self.output_string(metrics) % tuple([self.current_step] + metric_values))\n\n'"
hypergan/trainers/experimental/evolution_trainer.py,10,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass EvolutionTrainer(BaseTrainer):\n    def _create(self):\n        gan = self.gan\n        generator = self.gan.generator\n        config = self.config\n\n        d_vars = self.d_vars or gan.discriminator.variables()\n\n        loss = self.loss or gan.loss\n        d_loss, g_loss = loss.sample\n\n        self.d_log = -tf.log(tf.abs(d_loss+TINY))\n\n\n        d_optimizer = self.build_optimizer(config, \'d_\', config.d_trainer, self.d_lr, d_vars, d_loss)\n        #TODO more than one g_loss\n        g_optimizer = [self.build_optimizer(config, \'g_\', config.g_trainer, self.g_lr, g.variables(), g_loss) for g, l in zip(generator.children, loss.children_losses)]\n\n        assign_children = []\n        for p, o in generator.parent_child_tuples:\n            for ov, pv in zip(o.variables(), p.variables()):\n                op=tf.assign(ov, pv)\n                if config.mutation_percent:\n                    op += tf.random_normal(self.gan.ops.shape(pv), mean=0, stddev=0.01) * tf.cast(tf.greater(config.mutation_percent, tf.random_uniform(shape=self.gan.ops.shape(pv), minval=0, maxval=1)), tf.float32)\n                assign_children.append(op)\n        self.clone_parent = tf.group(*assign_children)\n\n\n        update_parent=[]\n        for p, o in generator.parent_child_tuples:\n            c_to_p = []\n            for ov, pv in zip(o.variables(), p.variables()):\n                op=tf.assign(pv, ov)\n                c_to_p.append(op)\n            update_parent.append(tf.group(*c_to_p))\n        self.update_parent = update_parent\n        f_lambda = config.f_lambda or 1\n\n        def _squash(grads):\n            return tf.add_n([tf.reshape(gan.ops.squash(g), [1]) for g in grads])\n        children_grads = [_squash(tf.gradients(l, d_vars)) for l in loss.children_losses]\n        if config.fitness == ""g"":\n            self.measure_g = [-l for l in loss.children_losses]\n        else:\n            self.measure_g = [-l+f_lambda*(-tf.log(TINY+grad_d - tf.log(TINY+tf.nn.sigmoid(loss.d_loss)) - tf.log(TINY+1-tf.nn.sigmoid(l)))) for l, grad_d in zip(loss.children_losses, children_grads)]\n        loss.metrics[\'measure_g\'] = tf.reduce_mean(self.measure_g)\n        loss.metrics[\'g_loss\'] = loss.g_loss\n        loss.metrics[\'d_loss\'] = loss.d_loss\n\n        self.g_loss = g_loss\n        self.d_loss = d_loss\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.hist = [0 for i in range(len(self.gan.generator.children))]\n\n        return g_optimizer, d_optimizer\n\n    def _step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n        loss = self.loss or gan.loss\n        metrics = loss.metrics\n        generator = gan.generator\n\n        d_loss, g_loss = loss.sample\n\n        #winner = np.random.choice(range(len(gan.generator.children)))\n        winners = []\n        \n        for i in range(len(generator.parents)):\n            child_count = generator.config.child_count\n            choices = self.measure_g[i*child_count:(i+1)*child_count]\n            choice = np.argmax(sess.run(choices))\n            winner = i*child_count + choice\n            self.hist[winner]+=1\n            winners.append(winner)\n        sess.run([self.update_parent[winner] for winner in winners])\n        for i in range(config.d_update_steps or 1):\n            sess.run(self.d_optimizer)\n\n        sess.run(self.clone_parent)\n        for i in range(config.g_update_steps or 1):\n            sess.run(self.g_optimizer)\n        measure_g = sess.run(self.measure_g)\n\n        if self.current_step % 100 == 0:\n            hist_output = ""  "" + """".join([""G""+str(i)+"":""+str(v)+"" ""for i, v in enumerate(self.hist)])\n            metric_values = sess.run(self.output_variables(metrics), feed_dict)\n            print(str(self.output_string(metrics) % tuple([self.current_step] + metric_values)+hist_output))\n            self.hist = [0 for i in range(len(self.gan.generator.children))]\n\n'"
hypergan/trainers/experimental/incremental_trainer.py,0,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass IncrementalTrainer():\n    def __init__(self, trainers, schedule):\n        self.trainers = trainers\n        self.schedule = schedule\n        self.i = 0\n\n    def step(self, feed_dict):\n        self.i += 1\n\n        index = 0\n        threshold = 0\n        for val in self.schedule:\n            threshold += val\n            if self.i > threshold:\n                index+=1\n                if len(self.trainers) <= index:\n                    index =len(self.trainers) - 1\n\n        return self.trainers[index].step(feed_dict)\n\n\n'"
hypergan/trainers/experimental/kbeam_trainer.py,3,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\n\nfrom hypergan.trainers.consensus_trainer import ConsensusTrainer\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass KBeamTrainer(BaseTrainer):\n\n    def _create(self):\n        gan = self.gan\n        config = self.config\n\n        d_vars = gan.discriminator.d_variables\n        g_vars = self.g_vars\n        loss = self.loss\n        trainers = []\n\n        for l, d in zip(gan.loss.losses, d_vars):\n            trainers += [ConsensusTrainer(self.gan, self.config, loss=l, d_vars=d, g_vars=g_vars)]\n\n        self.trainers = trainers\n        self.hist = [0 for i in range(len(self.trainers))]\n        self.tfsummary_writer = tf.summary.FileWriter(\'./logs/sess.graph\', tf.get_default_graph())\n        tf.summary.scalar(""zero"", tf.reduce_mean(gan.loss.losses[0].sample))\n        self.tfmerge_summary = tf.summary.merge_all()\n        return None, None\n\n    def required(self):\n        return ""trainer learn_rate"".split()\n\n    def _step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n        loss = self.loss or gan.loss\n        metrics = loss.metrics\n        \n        losses_g = [t.g_loss for t in self.trainers]\n        losses_d = [t.d_loss for t in self.trainers]\n        targets_t = losses_g+losses_d\n        targets = sess.run(targets_t)\n        l_g = targets[:len(targets)//2]\n        l_d = targets[len(targets)//2:]\n\n        if config.criteria == \'<g\':\n            i=np.argmin([float(x) for x in l_g])\n        elif config.criteria == \'>d\':\n            i=np.argax([float(x) for x in l_d])\n        elif config.criteria == \'<d\':\n            i=np.argmin([float(x) for x in l_d])\n        else:\n            # default from paper\n            i=np.argmax([float(x) for x in l_g])\n\n        i=np.argmax([float(x) for x in l_g])\n        self.hist[i]+=1\n        optimizer = self.trainers[i].optimizer\n\n        for t_t, t in zip(targets_t, targets):\n            feed_dict[t_t] = t\n\n        if config.alternating_trainer:\n            _ = sess.run(self.trainers[i].g_optimizer, feed_dict)\n            metric_values = sess.run([t.d_optimizer for j, t in enumerate(self.trainers)] + self.output_variables(metrics))[len(self.trainers):]\n        elif config.train_all:\n            metric_values = sess.run([t.optimizer for j, t in enumerate(self.trainers)] + self.output_variables(metrics), feed_dict)[len(self.trainers):]\n        else:\n            metric_values = sess.run([t.optimizer if j == i else t.d_optimizer for j, t in enumerate(self.trainers)] + self.output_variables(metrics), feed_dict)[len(self.trainers):]\n\n        if self.current_step % 100 == 0:\n            hist_output = ""  "" + """".join([""D""+str(i)+"":""+str(v)+"" ""for i, v in enumerate(self.hist)])\n            print(self.output_string(metrics) % tuple([self.current_step] + metric_values)+hist_output)\n            self.hist = [0 for i in range(len(self.trainers))]\n\n'"
hypergan/trainers/experimental/multi_step_trainer.py,1,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass MultiStepTrainer(BaseTrainer):\n    def __init__(self, gan, config, losses=[], var_lists=[], metrics=None):\n        self.losses = losses\n        self.var_lists = var_lists\n        self.metrics = metrics or [None for i in self.losses]\n        BaseTrainer.__init__(self, gan, config)\n\n    def _create(self):\n        gan = self.gan\n        config = self.config\n        losses = self.losses\n\n        optimizers = []\n        for i, _ in enumerate(losses):\n            loss = losses[i][1]\n            var_list = self.var_lists[i]\n            is_generator = \'generator\' in losses[i][0]\n\n            if is_generator:\n                optimizer = self.build_optimizer(config, \'g_\', config.g_trainer, self.g_lr, var_list, loss)\n            else:\n                optimizer = self.build_optimizer(config, \'d_\', config.d_trainer, self.d_lr, var_list, loss)\n            optimizers.append(optimizer)\n\n        self.optimizers = optimizers\n\n\n        if config.d_clipped_weights:\n            self.clip = [tf.assign(d,tf.clip_by_value(d, -config.d_clipped_weights, config.d_clipped_weights))  for d in d_vars]\n        else:\n            self.clip = []\n\n        return None\n\n    def _step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n        losses = self.losses\n        metrics = self.metrics\n\n        for i, _ in enumerate(losses):\n            loss = losses[i]\n            optimizer = self.optimizers[i]\n            metric = metrics[i]\n            if(metric):\n                metric_values = sess.run([optimizer] + self.output_variables(metric), feed_dict)[1:]\n\n                if self.current_step % 100 == 0:\n                    print(""loss "" + str(i) + ""  ""+ loss[0] + "" "" + self.output_string(metric) % tuple([self.current_step] + metric_values))\n            else:\n                _ = sess.run(optimizer, feed_dict)\n'"
hypergan/trainers/experimental/multi_trainer_trainer.py,0,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass MultiTrainerTrainer(BaseTrainer):\n    def __init__(self, trainers):\n        self.gan = trainers[0].gan\n        self.config = trainers[0].config\n        self.trainers = trainers\n        BaseTrainer.__init__(self, self.gan, self.config)\n\n    def required(self):\n        return []\n\n    def _create(self):\n        gan = self.gan\n        config = self.config\n\n        for i, t in enumerate(self.trainers):\n            t._create()\n        return None\n\n    def _step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n\n        for i, t in enumerate(self.trainers):\n            t.step(feed_dict)\n'"
hypergan/trainers/experimental/proportional_control_trainer.py,1,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nclass ProportionalControlTrainer(BaseTrainer):\n\n    def _create(self):\n        d_loss = gan.graph.d_loss\n        g_loss = gan.graph.g_loss\n        g_lr = np.float32(config.g_learn_rate)\n        d_lr = np.float32(config.d_learn_rate)\n\n        gan.graph.d_vars = d_vars\n        g_defk = {k[2:]: v for k, v in config.items() if k[2:] in inspect.getargspec(config.g_trainer).args and k.startswith(""d_"")}\n        d_defk = {k[2:]: v for k, v in config.items() if k[2:] in inspect.getargspec(config.d_trainer).args and k.startswith(""g_"")}\n        g_optimizer = config.g_trainer(g_lr, **g_defk)\n        d_optimizer = config.d_trainer(d_lr, **d_defk)\n        if(config.clipped_gradients):\n            g_optimizer = capped_optimizer(g_optimizer, config.clipped_gradients, g_loss, g_vars)\n            d_optimizer = capped_optimizer(d_optimizer, config.clipped_gradients, d_loss, d_vars)\n        else:\n            g_optimizer = g_optimizer.minimize(g_loss, var_list=g_vars)\n            d_optimizer = d_optimizer.minimize(d_loss, var_list=d_vars)\n\n        gan.graph.clip = [tf.assign(d,tf.clip_by_value(d, -config.d_clipped_weights, config.d_clipped_weights))  for d in d_vars]\n\n        return g_optimizer, d_optimizer\n\n\n    def _step(gan, feed_dict):\n        sess = gan.sess\n        config = gan.config\n        x_t = gan.graph.x\n        g_t = gan.graph.g\n        d_log_t = gan.graph.d_log\n        g_loss = gan.graph.g_loss\n        d_loss = gan.graph.d_loss\n        g_optimizer = gan.graph.g_optimizer\n        d_optimizer = gan.graph.d_optimizer\n        d_class_loss = gan.graph.d_class_loss\n        d_vars = gan.graph.d_vars\n\n        # in WGAN paper, values are clipped.  This might not work, and is slow.\n        if(config.d_clipped_weights):\n            sess.run(gan.graph.clip)\n\n        _, d_cost, d_log = sess.run([d_optimizer, d_loss, d_log_t], feed_dict)\n\n        _, g_cost, g_k, measure= sess.run([g_optimizer, g_loss, gan.graph.update_k, gan.graph.measure], feed_dict)\n        if self.step % 100 == 0:\n            print(""%2d: g cost %.2f d_loss %.2f k %.2f m %.2f gamma %.2f"" % (self.step, g_cost , d_cost, g_k, measure, gan.graph.gamma))\n\n        self.step+=1\n\n        return d_cost, g_cost\n'"
hypergan/trainers/experimental/qualified_step_trainer.py,5,"b'import tensorflow as tf\nimport numpy as np\nimport hyperchamber as hc\nimport inspect\n\nfrom hypergan.trainers.base_trainer import BaseTrainer\n\nTINY = 1e-12\n\nclass QualifiedStepTrainer(BaseTrainer):\n    def create(self):\n        self.hist = [0 for i in range(2)]\n        config = self.config\n        self.global_step = tf.train.get_global_step()\n        self.mix_threshold_reached = False\n        decay_function = config.decay_function\n        variables = self.gan.d_vars() + self.gan.g_vars()\n        self.ema = [ tf.Variable(_v) for _v in variables ]\n        self.store_v = [ _v.assign(_v2) for _v,_v2 in zip(self.ema, variables) ]\n        self._delegate = self.gan.create_component(config.trainer, d_vars=self.d_vars, g_vars=self.g_vars, loss=self.loss)\n        self._delegate.create()\n        self.slot_vars_g = self._delegate.slot_vars_g\n        self.slot_vars_d = self._delegate.slot_vars_g\n\n        self.mixg = tf.Variable(1, dtype=tf.float32)\n        self.mixd = tf.Variable(1, dtype=tf.float32)\n        self.combine_d = [ _v.assign((1.-self.mixd) *_ema + self.mixd*_new) for _v, _ema, _new in zip(self.gan.d_vars(), self.ema, self.gan.d_vars())]\n        self.combine_g = [ _v.assign((1.-self.mixg) *_ema + self.mixg*_new) for _v, _ema, _new in zip(self.gan.g_vars(), self.ema[len(self.gan.d_vars()):], self.gan.g_vars())]\n\n        self.candidate = [ tf.Variable(_v) for _v in variables ]\n        self.store_candidate = [ _v.assign(_v2) for _v,_v2 in zip(self.candidate, variables) ]\n        self.reset_discriminator = [ _v.assign(_v2) for _v,_v2 in zip(self.gan.d_vars(), self.ema) ]\n        self.reset_generator = [ _v.assign(_v2) for _v,_v2 in zip(self.gan.g_vars(), self.ema[len(self.gan.d_vars()):]) ]\n        self.reset_candidate_discriminator = [ _v.assign(_v2) for _v,_v2 in zip(self.gan.d_vars(), self.candidate) ]\n        self.reset_candidate_generator = [ _v.assign(_v2) for _v,_v2 in zip(self.gan.g_vars(), self.candidate[len(self.gan.d_vars()):]) ]\n        self.candidate_loss = self.gan.loss.sample[0] - self.gan.loss.sample[1]\n        if self.config.fitness == ""d_fake"":\n            self.candidate_loss = self.gan.loss.sample[0]\n        self.g_rate = 0.0\n        self.d_rate = 0.0\n        self.zs = [self.gan.session.run(self.gan.latent.sample) for i in range(self.config.candidate_tests)]\n\n    def required(self):\n        return """".split()\n\n    def _step(self, feed_dict):\n        gan = self.gan\n        sess = gan.session\n        config = self.config\n        loss = self.loss \n\n        gan.session.run(self.store_v)\n        self._delegate.step(feed_dict)\n        if(self.config.turn_off_step):\n            if(self.config.turn_off_step < self.current_step):\n                return\n            else:\n                print(str(-self.current_step+self.config.turn_off_step) + "" qualified steps remain"")\n\n        # b = generator at new step\n        # a = generator at past step\n        # 1 = discriminator at past step\n        # 2 = discriminator at new step\n        b2 = np.mean([gan.session.run(self.candidate_loss, {gan.latent.sample: self.zs[i]}) for i in range(self.config.candidate_tests)])\n        gan.session.run(self.store_candidate)\n        gan.session.run(self.reset_discriminator)\n        b1 = np.mean([gan.session.run(self.candidate_loss, {gan.latent.sample: self.zs[i]}) for i in range(self.config.candidate_tests)])\n        gan.session.run(self.reset_generator)\n        a1 = np.mean([gan.session.run(self.candidate_loss, {gan.latent.sample: self.zs[i]}) for i in range(self.config.candidate_tests)])\n        gan.session.run(self.reset_candidate_discriminator)\n        a2 = np.mean([gan.session.run(self.candidate_loss, {gan.latent.sample: self.zs[i]}) for i in range(self.config.candidate_tests)])\n        gan.session.run(self.reset_candidate_generator)\n\n        #    D1 D2\n        # G1 a1 b1\n        # G2 a2 b2\n        payoff = [[a1, b1],[a2, b2]]\n\n        d1 = a1 + a2\n        d2 = b1 + b2\n        g1 = a1 + b1\n        g2 = a2 + b2\n        if self.config.negate:\n            g1 = -g1\n            g2 = -g2\n        mixd = d2/(d1 + d2)\n        mixg = g1/(g1 + g2)\n        if self.config.find_zero:\n            slope = d2 - d1\n            t = -d1/slope\n            print(""d"", t)\n            mixd = t\n            slope = g2 - g1\n            t = -g1/slope\n            print(""g"", t)\n            mixg = t\n            print(t * slope + g1)\n        if self.config.reverse:\n            mixd = d1/(d1 + d2)\n            mixg = g2/(g1 + g2)\n        if self.config.loud:\n            mixd = d1/(d1 + d2)\n            mixg = g1/(g1 + g2)\n        if self.config.zero:\n            if np.abs(d2) <= np.abs(d1):\n                mixd = 1.0\n                self.d_rate += 1\n            else:\n                mixd = 0.0\n            if np.abs(g2) >= np.abs(g1):\n                self.g_rate += 1\n                mixg = 1.0\n            else:\n                mixg = 0.0\n        if self.config.unbounded:\n            pass\n        else:\n            bounds = self.config.bounds or [0.0, 1.0]\n            mixd = np.minimum(bounds[1], mixd)\n            mixd = np.maximum(bounds[0], mixd)\n            mixg = np.minimum(bounds[1], mixg)\n            mixg = np.maximum(bounds[0], mixg)\n        gan.session.run([self.combine_d, self.combine_g], {self.mixd: mixd, self.mixg: mixg})\n\n        if self.current_step % 100 == 0:\n            print(""rates %d/100 g %d/100 d"" % (self.g_rate, self.d_rate))\n            self.g_rate = 0.0\n            self.d_rate = 0.0\n'"
tests/ops/tensorflow/__init__.py,0,b''
tests/ops/tensorflow/ops_test.py,18,"b'import tensorflow as tf\nimport hypergan as hg\nfrom hypergan.ops.tensorflow.ops import TensorflowOps\n\nfrom unittest.mock import MagicMock\n\nops = TensorflowOps()\ntanh_str = ""function:tensorflow.python.ops.math_ops.tanh""\nclass OpsTest(tf.test.TestCase):\n    def test_lookup_activations(self):\n        x = tf.constant(-1.0, shape=[2, 2])\n        with self.test_session():\n            activations = [\'relu\',\'prelu\',\'selu\',\'crelu\']\n            for activation in activations:\n                activation = ops.lookup(activation)(x)\n                \n                tf.get_default_session().run(tf.global_variables_initializer())\n            \n                self.assertNotEqual(x.eval()[0][0], activation.eval()[0][0])\n\n    def test_lookup_function(self):\n        with self.test_session():\n            self.assertEqual(ops.lookup_function(tanh_str), tf.nn.tanh)\n\n    def test_lookup_class(self):\n        with self.test_session():\n            self.assertEqual(ops.lookup_class(\'class:hypergan.GAN\'), hg.GAN)\n\n    def test_lookup(self):\n        with self.test_session():\n            self.assertEqual(ops.lookup(\'tanh\'), tf.nn.tanh)\n            self.assertEqual(ops.lookup(tanh_str), tf.nn.tanh)\n            self.assertEqual(ops.lookup(None), None)\n\n    def test_dtype(self):\n        with self.test_session():\n            self.assertEqual(ops.parse_dtype(\'float32\'), tf.float32)\n\n    def test_shape(self):\n        with self.test_session():\n            self.assertEqual(ops.shape(tf.constant(1)), [])\n\n    def test_slice(self):\n        with self.test_session():\n            self.assertEqual(ops.shape(ops.slice(tf.constant(1,shape=[1]), [0],[1])), [1])\n\n    def test_resize(self):\n        with self.test_session():\n            self.assertEqual(ops.shape(ops.resize_images(tf.constant(1, shape=[1,1,1]), [2,2], 1))[1], 2)\n\n    def test_concat(self):\n        with self.test_session():\n            self.assertEqual(ops.shape(ops.concat([tf.constant(1)])), [])\n\n    def test_reshape(self):\n        with self.test_session():\n            self.assertEqual(ops.shape(ops.reshape(tf.constant(1), [1])), [1])\n\n    def test_linear(self):\n        with self.test_session():\n            net = ops.linear(tf.constant(1., shape=[1, 3]), 3)\n            self.assertEqual(ops.shape(net)[1], 3)\n\n    def test_conv2d(self):\n        with self.test_session():\n            net = ops.conv2d(tf.constant(1., shape=[1, 3, 3, 3]), 3, 3, 1, 1, 3)\n            self.assertEqual(ops.shape(net)[1], 3)\n\n    def test_deconv2d(self):\n        with self.test_session():\n            net = ops.deconv2d(tf.constant(1., shape=[1, 3, 3, 3]), 3, 3, 1, 1, 3)\n            self.assertEqual(ops.shape(net)[1], 3)\n\n    def test_generate_scope(self):\n        with self.test_session():\n            ops = TensorflowOps()\n            self.assertEqual(ops.generate_scope(), ""1"")\n            self.assertEqual(ops.generate_scope(), ""2"")\n\n    def test_generate_name(self):\n        with self.test_session():\n            ops = TensorflowOps()\n            ops.describe(""generator"")\n            self.assertEqual(ops.generate_name(), ""generator_1"")\n            self.assertEqual(ops.generate_name(), ""generator_2"")\n            self.assertEqual(ops.generate_name(""custom""), ""custom"")\n            self.assertEqual(ops.generate_name(), ""generator_3"")\n\n    def test_variable_constructor(self):\n        with self.test_session():\n            ops = TensorflowOps()\n            self.assertEqual(len(ops.weights), 0)\n            self.assertEqual(len(ops.biases), 0)\n            self.assertEqual(len(ops.variables()), 0)\n\n    def test_get_weight(self):\n        with self.test_session():\n            ops = TensorflowOps({\'dtype\':\'float32\'})\n            ops.get_weight([1,1])\n            self.assertTrue(\'float32\' in str(ops.weights[0].dtype))\n            self.assertEqual(ops.shape(ops.weights[0]), [1, 1])\n\n    def test_add_weight(self):\n        with self.test_session():\n            ops.add_weights(tf.constant(1))\n            ops.add_weights(tf.constant(1,shape=[2,1]))\n\n            self.assertEqual(len(ops.weights), 2)\n\n    def test_get_bias(self):\n        with self.test_session():\n            ops = TensorflowOps({\'dtype\':\'float32\'})\n            ops.get_bias([1,1])\n            self.assertTrue(\'float32\' in str(ops.biases[0].dtype))\n            self.assertEqual(ops.shape(ops.biases[0]), [1, 1])\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
