file_path,api_count,code
hangul_model.py,51,"b'#!/usr/bin/env python\n\nimport argparse\nimport io\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.python.tools import freeze_graph\nfrom tensorflow.python.tools import optimize_for_inference_lib\n\n\nSCRIPT_PATH = os.path.dirname(os.path.abspath(__file__))\n\n# Default paths.\nDEFAULT_LABEL_FILE = os.path.join(SCRIPT_PATH,\n                                  \'./labels/2350-common-hangul.txt\')\nDEFAULT_TFRECORDS_DIR = os.path.join(SCRIPT_PATH, \'tfrecords-output\')\nDEFAULT_OUTPUT_DIR = os.path.join(SCRIPT_PATH, \'saved-model\')\n\nMODEL_NAME = \'hangul_tensorflow\'\nIMAGE_WIDTH = 64\nIMAGE_HEIGHT = 64\n\nDEFAULT_NUM_EPOCHS = 15\nBATCH_SIZE = 100\n\n# This will be determined by the number of entries in the given label file.\nnum_classes = 2350\n\n\ndef _parse_function(example):\n    features = tf.parse_single_example(\n        example,\n        features={\n            \'image/class/label\': tf.FixedLenFeature([], tf.int64),\n            \'image/encoded\': tf.FixedLenFeature([], dtype=tf.string,\n                                                default_value=\'\')\n        })\n    label = features[\'image/class/label\']\n    image_encoded = features[\'image/encoded\']\n\n    # Decode the JPEG.\n    image = tf.image.decode_jpeg(image_encoded, channels=1)\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    image = tf.reshape(image, [IMAGE_WIDTH*IMAGE_HEIGHT])\n\n    # Represent the label as a one hot vector.\n    label = tf.stack(tf.one_hot(label, num_classes))\n    return image, label\n\n\ndef export_model(model_output_dir, input_node_names, output_node_name):\n    """"""Export the model so we can use it later.\n\n    This will create two Protocol Buffer files in the model output directory.\n    These files represent a serialized version of our model with all the\n    learned weights and biases. One of the ProtoBuf files is a version\n    optimized for inference-only usage.\n    """"""\n\n    name_base = os.path.join(model_output_dir, MODEL_NAME)\n    frozen_graph_file = os.path.join(model_output_dir,\n                                     \'frozen_\' + MODEL_NAME + \'.pb\')\n    freeze_graph.freeze_graph(\n        name_base + \'.pbtxt\', None, False, name_base + \'.chkp\',\n        output_node_name, ""save/restore_all"", ""save/Const:0"",\n        frozen_graph_file, True, """"\n    )\n\n    input_graph_def = tf.GraphDef()\n    with tf.gfile.Open(frozen_graph_file, ""rb"") as f:\n        input_graph_def.ParseFromString(f.read())\n\n    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n            input_graph_def, input_node_names, [output_node_name],\n            tf.float32.as_datatype_enum)\n\n    optimized_graph_file = os.path.join(model_output_dir,\n                                        \'optimized_\' + MODEL_NAME + \'.pb\')\n    with tf.gfile.GFile(optimized_graph_file, ""wb"") as f:\n        f.write(output_graph_def.SerializeToString())\n\n    print(""Inference optimized graph saved at: "" + optimized_graph_file)\n\n\ndef weight_variable(shape):\n    """"""Generates a weight variable of a given shape.""""""\n    initial = tf.random.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial, name=\'weight\')\n\n\ndef bias_variable(shape):\n    """"""Generates a bias variable of a given shape.""""""\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial, name=\'bias\')\n\n\ndef main(label_file, tfrecords_dir, model_output_dir, num_train_epochs):\n    """"""Perform graph definition and model training.\n\n    Here we will first create our input pipeline for reading in TFRecords\n    files and producing random batches of images and labels.\n    Next, a convolutional neural network is defined, and training is performed.\n    After training, the model is exported to be used in applications.\n    """"""\n    global num_classes\n    labels = io.open(label_file, \'r\', encoding=\'utf-8\').read().splitlines()\n    num_classes = len(labels)\n\n    # Define names so we can later reference specific nodes for when we use\n    # the model for inference later.\n    input_node_name = \'input\'\n    keep_prob_node_name = \'keep_prob\'\n    output_node_name = \'output\'\n\n    if not os.path.exists(model_output_dir):\n        os.makedirs(model_output_dir)\n\n    print(\'Processing data...\')\n\n    tf_record_pattern = os.path.join(tfrecords_dir, \'%s-*\' % \'train\')\n    train_data_files = tf.gfile.Glob(tf_record_pattern)\n\n    tf_record_pattern = os.path.join(tfrecords_dir, \'%s-*\' % \'test\')\n    test_data_files = tf.gfile.Glob(tf_record_pattern)\n\n    # Create training dataset input pipeline.\n    train_dataset = tf.data.TFRecordDataset(train_data_files) \\\n        .map(_parse_function) \\\n        .shuffle(1000) \\\n        .repeat(num_train_epochs) \\\n        .batch(BATCH_SIZE) \\\n        .prefetch(1)\n\n    # Create the model!\n\n    # Placeholder to feed in image data.\n    x = tf.placeholder(tf.float32, [None, IMAGE_WIDTH*IMAGE_HEIGHT],\n                       name=input_node_name)\n    # Placeholder to feed in label data. Labels are represented as one_hot\n    # vectors.\n    y_ = tf.placeholder(tf.float32, [None, num_classes])\n\n    # Reshape the image back into two dimensions so we can perform convolution.\n    x_image = tf.reshape(x, [-1, IMAGE_WIDTH, IMAGE_HEIGHT, 1])\n\n    # First convolutional layer. 32 feature maps.\n    W_conv1 = weight_variable([5, 5, 1, 32])\n    b_conv1 = bias_variable([32])\n    x_conv1 = tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1],\n                           padding=\'SAME\')\n    h_conv1 = tf.nn.relu(x_conv1 + b_conv1)\n\n    # Max-pooling.\n    h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1],\n                             strides=[1, 2, 2, 1], padding=\'SAME\')\n\n    # Second convolutional layer. 64 feature maps.\n    W_conv2 = weight_variable([5, 5, 32, 64])\n    b_conv2 = bias_variable([64])\n    x_conv2 = tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1],\n                           padding=\'SAME\')\n    h_conv2 = tf.nn.relu(x_conv2 + b_conv2)\n\n    h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1],\n                             strides=[1, 2, 2, 1], padding=\'SAME\')\n\n    # Third convolutional layer. 128 feature maps.\n    W_conv3 = weight_variable([3, 3, 64, 128])\n    b_conv3 = bias_variable([128])\n    x_conv3 = tf.nn.conv2d(h_pool2, W_conv3, strides=[1, 1, 1, 1],\n                           padding=\'SAME\')\n    h_conv3 = tf.nn.relu(x_conv3 + b_conv3)\n\n    h_pool3 = tf.nn.max_pool(h_conv3, ksize=[1, 2, 2, 1],\n                             strides=[1, 2, 2, 1], padding=\'SAME\')\n\n    # Fully connected layer. Here we choose to have 1024 neurons in this layer.\n    h_pool_flat = tf.reshape(h_pool3, [-1, 8*8*128])\n    W_fc1 = weight_variable([8*8*128, 1024])\n    b_fc1 = bias_variable([1024])\n    h_fc1 = tf.nn.relu(tf.matmul(h_pool_flat, W_fc1) + b_fc1)\n\n    # Dropout layer. This helps fight overfitting.\n    keep_prob = tf.placeholder(tf.float32, name=keep_prob_node_name)\n    h_fc1_drop = tf.nn.dropout(h_fc1, rate=1-keep_prob)\n\n    # Classification layer.\n    W_fc2 = weight_variable([1024, num_classes])\n    b_fc2 = bias_variable([num_classes])\n    y = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n\n    # This isn\'t used for training, but for when using the saved model.\n    tf.nn.softmax(y, name=output_node_name)\n\n    # Define our loss.\n    cross_entropy = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits_v2(\n            labels=tf.stop_gradient(y_),\n            logits=y\n        )\n    )\n\n    # Define our optimizer for minimizing our loss. Here we choose a learning\n    # rate of 0.0001 with AdamOptimizer. This utilizes someting\n    # called the Adam algorithm, and utilizes adaptive learning rates and\n    # momentum to get past saddle points.\n    train_step = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)\n\n    # Define accuracy.\n    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n    correct_prediction = tf.cast(correct_prediction, tf.float32)\n    accuracy = tf.reduce_mean(correct_prediction)\n\n    saver = tf.train.Saver()\n\n    with tf.Session() as sess:\n        # Initialize the variables.\n        sess.run(tf.global_variables_initializer())\n\n        checkpoint_file = os.path.join(model_output_dir, MODEL_NAME + \'.chkp\')\n\n        # Save the graph definition to a file.\n        tf.train.write_graph(sess.graph_def, model_output_dir,\n                             MODEL_NAME + \'.pbtxt\', True)\n\n        try:\n            iterator = train_dataset.make_one_shot_iterator()\n            batch = iterator.get_next()\n            step = 0\n\n            while True:\n\n                # Get a batch of images and their corresponding labels.\n                train_images, train_labels = sess.run(batch)\n\n                # Perform the training step, feeding in the batches.\n                sess.run(train_step, feed_dict={x: train_images,\n                                                y_: train_labels,\n                                                keep_prob: 0.5})\n                if step % 100 == 0:\n                    train_accuracy = sess.run(\n                        accuracy,\n                        feed_dict={x: train_images, y_: train_labels,\n                                   keep_prob: 1.0}\n                    )\n                    print(""Step %d, Training Accuracy %g"" %\n                          (step, float(train_accuracy)))\n\n                # Every 10,000 iterations, we save a checkpoint of the model.\n                if step % 10000 == 0:\n                    saver.save(sess, checkpoint_file, global_step=step)\n\n                step += 1\n\n        except tf.errors.OutOfRangeError:\n            pass\n\n        # Save a checkpoint after training has completed.\n        saver.save(sess, checkpoint_file)\n\n        # See how model did by running the testing set through the model.\n        print(\'Testing model...\')\n\n        # Create testing dataset input pipeline.\n        test_dataset = tf.data.TFRecordDataset(test_data_files) \\\n            .map(_parse_function) \\\n            .batch(BATCH_SIZE) \\\n            .prefetch(1)\n\n        # Define a different tensor operation for summing the correct\n        # predictions.\n        accuracy2 = tf.reduce_sum(correct_prediction)\n        total_correct_preds = 0\n        total_preds = 0\n\n        try:\n            iterator = test_dataset.make_one_shot_iterator()\n            batch = iterator.get_next()\n            while True:\n                test_images, test_labels = sess.run(batch)\n                acc = sess.run(accuracy2, feed_dict={x: test_images,\n                                                     y_: test_labels,\n                                                     keep_prob: 1.0})\n                total_preds += len(test_images)\n                total_correct_preds += acc\n\n        except tf.errors.OutOfRangeError:\n            pass\n\n        test_accuracy = total_correct_preds/total_preds\n        print(""Testing Accuracy {}"".format(test_accuracy))\n\n        export_model(model_output_dir, [input_node_name, keep_prob_node_name],\n                     output_node_name)\n\n        sess.close()\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--label-file\', type=str, dest=\'label_file\',\n                        default=DEFAULT_LABEL_FILE,\n                        help=\'File containing newline delimited labels.\')\n    parser.add_argument(\'--tfrecords-dir\', type=str, dest=\'tfrecords_dir\',\n                        default=DEFAULT_TFRECORDS_DIR,\n                        help=\'Directory of TFRecords files.\')\n    parser.add_argument(\'--output-dir\', type=str, dest=\'output_dir\',\n                        default=DEFAULT_OUTPUT_DIR,\n                        help=\'Output directory to store saved model files.\')\n    parser.add_argument(\'--num-train-epochs\', type=int,\n                        dest=\'num_train_epochs\',\n                        default=DEFAULT_NUM_EPOCHS,\n                        help=\'Number of times to iterate over all of the \'\n                             \'training data.\')\n    args = parser.parse_args()\n    main(args.label_file, args.tfrecords_dir,\n         args.output_dir, args.num_train_epochs)\n'"
tests/test_image_generator.py,0,"b'import imp\nimport glob\nimport os\nimport shutil\nimport tempfile\nimport unittest\n\n\nTEST_PATH = os.path.dirname(os.path.abspath(__file__))\nSCRIPT_PATH = os.path.join(TEST_PATH, \'../tools/hangul-image-generator.py\')\ngenerator = imp.load_source(\'hangul-image-generator\', SCRIPT_PATH)\n\n\nclass ImageGeneratorTestCase(unittest.TestCase):\n\n    @classmethod\n    def setUpClass(self):\n        self.expected_labels = [\'a\', \'b\', \'c\']\n\n        # Create a label file and temporary output directory.\n        temp_file = tempfile.NamedTemporaryFile(delete=False)\n        self.label_file = temp_file.name\n        labels = open(self.label_file, \'w\')\n        for label in self.expected_labels:\n            labels.write(\'%s\\n\' % label)\n\n        self.output_dir = tempfile.mkdtemp()\n        self.fonts_dir = os.path.join(TEST_PATH, \'test-fonts\')\n\n    @classmethod\n    def tearDownClass(self):\n        # Remove the created label file and output directory.\n        os.remove(self.label_file)\n        shutil.rmtree(self.output_dir)\n\n    def test_file_generation(self):\n        """"""Test the image generation function.""""""\n        generator.generate_hangul_images(self.label_file,\n                                         self.fonts_dir,\n                                         self.output_dir)\n\n        # Check that number of generated images is correct.\n        expected_num_images = \\\n            len(self.expected_labels) * (1 + generator.DISTORTION_COUNT)\n        num_images = len(glob.glob(os.path.join(self.output_dir,\n                                                \'hangul-images/*.jpeg\')))\n        self.assertEqual(expected_num_images, num_images)\n\n        # Check that the CSV file was properly generated.\n        with open(os.path.join(self.output_dir, \'labels-map.csv\'), \'r\') as f:\n            csv_lines = f.read().splitlines()\n        for line in csv_lines:\n            file_path, label = line.strip().split(\',\')\n            self.assertIn(\'.jpeg\', file_path)\n            self.assertIn(label, self.expected_labels)\n'"
tools/classify-hangul.py,10,"b'#!/usr/bin/env python\n\nimport argparse\nimport io\nimport os\nimport sys\n\nimport tensorflow as tf\n\nSCRIPT_PATH = os.path.dirname(os.path.abspath(__file__))\n\n# Default paths.\nDEFAULT_LABEL_FILE = os.path.join(\n    SCRIPT_PATH, \'../labels/2350-common-hangul.txt\'\n)\nDEFAULT_GRAPH_FILE = os.path.join(\n    SCRIPT_PATH, \'../saved-model/optimized_hangul_tensorflow.pb\'\n)\n\n\ndef read_image(file):\n    """"""Read an image file and convert it into a 1-D floating point array.""""""\n    file_content = tf.read_file(file)\n    image = tf.image.decode_jpeg(file_content, channels=1)\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    image = tf.reshape(image, (1, 64*64))\n    return image\n\n\ndef classify(args):\n    """"""Classify a character.\n\n    This method will import the saved model from the given graph file, and will\n    pass in the given image pixels as input for the classification. The top\n    five predictions will be printed.\n    """"""\n    labels = io.open(args.label_file,\n                     \'r\', encoding=\'utf-8\').read().splitlines()\n\n    if not os.path.isfile(args.image):\n        print(\'Error: Image %s not found.\' % args.image)\n        sys.exit(1)\n\n    # Load graph and parse file.\n    with tf.gfile.GFile(args.graph_file, ""rb"") as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n\n    with tf.Graph().as_default() as graph:\n        tf.import_graph_def(\n            graph_def,\n            input_map=None,\n            return_elements=None,\n            name=\'hangul-model\',\n            producer_op_list=None\n        )\n\n    # Get relevant nodes.\n    x = graph.get_tensor_by_name(\'hangul-model/input:0\')\n    y = graph.get_tensor_by_name(\'hangul-model/output:0\')\n    keep_prob = graph.get_tensor_by_name(\'hangul-model/keep_prob:0\')\n\n    image = read_image(args.image)\n    sess = tf.InteractiveSession()\n    image_array = sess.run(image)\n    sess.close()\n    with tf.Session(graph=graph) as graph_sess:\n        predictions = graph_sess.run(y, feed_dict={x: image_array,\n                                                   keep_prob: 1.0})\n        prediction = predictions[0]\n\n    # Get the indices that would sort the array, then only get the indices that\n    # correspond to the top 5 predictions.\n    sorted_indices = prediction.argsort()[::-1][:5]\n    for index in sorted_indices:\n        label = labels[index]\n        confidence = prediction[index]\n        print(\'%s (confidence = %.5f)\' % (label, confidence))\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'image\', type=str,\n                        help=\'Image to pass to model for classification.\')\n    parser.add_argument(\'--label-file\', type=str, dest=\'label_file\',\n                        default=DEFAULT_LABEL_FILE,\n                        help=\'File containing newline delimited labels.\')\n    parser.add_argument(\'--graph-file\', type=str, dest=\'graph_file\',\n                        default=DEFAULT_GRAPH_FILE,\n                        help=\'The saved model graph file to use for \'\n                             \'classification.\')\n    classify(parser.parse_args())\n'"
tools/convert-to-tfrecords.py,6,"b'#!/usr/bin/env python\n\nfrom __future__ import division\n\nimport argparse\nimport io\nimport math\nimport os\nimport random\n\nimport numpy as np\nimport tensorflow as tf\n\nSCRIPT_PATH = os.path.dirname(os.path.abspath(__file__))\n\n# Default data paths.\nDEFAULT_LABEL_CSV = os.path.join(SCRIPT_PATH, \'../image-data/labels-map.csv\')\nDEFAULT_LABEL_FILE = os.path.join(SCRIPT_PATH,\n                                  \'../labels/2350-common-hangul.txt\')\nDEFAULT_OUTPUT_DIR = os.path.join(SCRIPT_PATH, \'../tfrecords-output\')\nDEFAULT_NUM_SHARDS_TRAIN = 3\nDEFAULT_NUM_SHARDS_TEST = 1\n\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\nclass TFRecordsConverter(object):\n    """"""Class that handles converting images to TFRecords.""""""\n\n    def __init__(self, labels_csv, label_file, output_dir,\n                 num_shards_train, num_shards_test):\n\n        self.output_dir = output_dir\n        self.num_shards_train = num_shards_train\n        self.num_shards_test = num_shards_test\n\n        if not os.path.exists(self.output_dir):\n            os.makedirs(self.output_dir)\n\n        # Get lists of images and labels.\n        self.filenames, self.labels = \\\n            self.process_image_labels(labels_csv, label_file)\n\n        # Counter for total number of images processed.\n        self.counter = 0\n\n    def process_image_labels(self, labels_csv, label_file):\n        """"""This will constuct two shuffled lists for images and labels.\n\n        The index of each image in the images list will have the corresponding\n        label at the same index in the labels list.\n        """"""\n        labels_csv = io.open(labels_csv, \'r\', encoding=\'utf-8\')\n        labels_file = io.open(label_file, \'r\',\n                              encoding=\'utf-8\').read().splitlines()\n\n        # Map characters to indices.\n        label_dict = {}\n        count = 0\n        for label in labels_file:\n            label_dict[label] = count\n            count += 1\n\n        # Build the lists.\n        images = []\n        labels = []\n        for row in labels_csv:\n            file, label = row.strip().split(\',\')\n            images.append(file)\n            labels.append(label_dict[label])\n\n        # Randomize the order of all the images/labels.\n        shuffled_indices = list(range(len(images)))\n        random.seed(12121)\n        random.shuffle(shuffled_indices)\n        filenames = [images[i] for i in shuffled_indices]\n        labels = [labels[i] for i in shuffled_indices]\n\n        return filenames, labels\n\n    def write_tfrecords_file(self, output_path, indices):\n        """"""Writes out TFRecords file.""""""\n        writer = tf.python_io.TFRecordWriter(output_path)\n        for i in indices:\n            filename = self.filenames[i]\n            label = self.labels[i]\n            with tf.gfile.GFile(filename, \'rb\') as f:\n                im_data = f.read()\n\n            # Example is a data format that contains a key-value store, where\n            # each key maps to a Feature message. In this case, each Example\n            # contains two features. One will be a ByteList for the raw image\n            # data and the other will be an Int64List containing the index of\n            # the corresponding label in the labels list from the file.\n            example = tf.train.Example(features=tf.train.Features(feature={\n                \'image/class/label\': _int64_feature(label),\n                \'image/encoded\': _bytes_feature(tf.compat.as_bytes(im_data))}))\n            writer.write(example.SerializeToString())\n            self.counter += 1\n            if not self.counter % 1000:\n                print(\'Processed {} images...\'.format(self.counter))\n        writer.close()\n\n    def convert(self):\n        """"""This function will drive the conversion to TFRecords.\n\n        Here, we partition the data into a training and testing set, then\n        divide each data set into the specified number of TFRecords shards.\n        """"""\n\n        num_files_total = len(self.filenames)\n\n        # Allocate about 15 percent of images to testing\n        num_files_test = int(num_files_total * .15)\n\n        # About 85 percent will be for training.\n        num_files_train = num_files_total - num_files_test\n\n        print(\'Processing training set TFRecords...\')\n\n        files_per_shard = int(math.ceil(num_files_train /\n                                        self.num_shards_train))\n        start = 0\n        for i in range(1, self.num_shards_train):\n            shard_path = os.path.join(self.output_dir,\n                                      \'train-{}.tfrecords\'.format(str(i)))\n            # Get a subset of indices to get only a subset of images/labels for\n            # the current shard file.\n            file_indices = np.arange(start, start+files_per_shard, dtype=int)\n            start = start + files_per_shard\n            self.write_tfrecords_file(shard_path, file_indices)\n\n        # The remaining images will go in the final shard.\n        file_indices = np.arange(start, num_files_train, dtype=int)\n        final_shard_path = os.path.join(self.output_dir,\n                                        \'train-{}.tfrecords\'.format(\n                                            str(self.num_shards_train)))\n        self.write_tfrecords_file(final_shard_path, file_indices)\n\n        print(\'Processing testing set TFRecords...\')\n\n        files_per_shard = math.ceil(num_files_test / self.num_shards_test)\n        start = num_files_train\n        for i in range(1, self.num_shards_test):\n            shard_path = os.path.join(self.output_dir,\n                                      \'test-{}.tfrecords\'.format(str(i)))\n            file_indices = np.arange(start, start+files_per_shard, dtype=int)\n            start = start + files_per_shard\n            self.write_tfrecords_file(shard_path, file_indices)\n\n        # The remaining images will go in the final shard.\n        file_indices = np.arange(start, num_files_total, dtype=int)\n        final_shard_path = os.path.join(self.output_dir,\n                                        \'test-{}.tfrecords\'.format(\n                                            str(self.num_shards_test)))\n        self.write_tfrecords_file(final_shard_path, file_indices)\n\n        print(\'\\nProcessed {} total images...\'.format(self.counter))\n        print(\'Number of training examples: {}\'.format(num_files_train))\n        print(\'Number of testing examples: {}\'.format(num_files_test))\n        print(\'TFRecords files saved to {}\'.format(self.output_dir))\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--image-label-csv\', type=str, dest=\'labels_csv\',\n                        default=DEFAULT_LABEL_CSV,\n                        help=\'File containing image paths and corresponding \'\n                             \'labels.\')\n    parser.add_argument(\'--label-file\', type=str, dest=\'label_file\',\n                        default=DEFAULT_LABEL_FILE,\n                        help=\'File containing newline delimited labels.\')\n    parser.add_argument(\'--output-dir\', type=str, dest=\'output_dir\',\n                        default=DEFAULT_OUTPUT_DIR,\n                        help=\'Output directory to store TFRecords files.\')\n    parser.add_argument(\'--num-shards-train\', type=int,\n                        dest=\'num_shards_train\',\n                        default=DEFAULT_NUM_SHARDS_TRAIN,\n                        help=\'Number of shards to divide training set \'\n                             \'TFRecords into.\')\n    parser.add_argument(\'--num-shards-test\', type=int,\n                        dest=\'num_shards_test\',\n                        default=DEFAULT_NUM_SHARDS_TEST,\n                        help=\'Number of shards to divide testing set \'\n                             \'TFRecords into.\')\n    args = parser.parse_args()\n    converter = TFRecordsConverter(args.labels_csv,\n                                   args.label_file,\n                                   args.output_dir,\n                                   args.num_shards_train,\n                                   args.num_shards_test)\n    converter.convert()\n'"
tools/hangul-image-generator.py,0,"b'#!/usr/bin/env python\n\nimport argparse\nimport glob\nimport io\nimport os\nimport random\n\nimport numpy\nfrom PIL import Image, ImageFont, ImageDraw\nfrom scipy.ndimage.interpolation import map_coordinates\nfrom scipy.ndimage.filters import gaussian_filter\n\n\nSCRIPT_PATH = os.path.dirname(os.path.abspath(__file__))\n\n# Default data paths.\nDEFAULT_LABEL_FILE = os.path.join(SCRIPT_PATH,\n                                  \'../labels/2350-common-hangul.txt\')\nDEFAULT_FONTS_DIR = os.path.join(SCRIPT_PATH, \'../fonts\')\nDEFAULT_OUTPUT_DIR = os.path.join(SCRIPT_PATH, \'../image-data\')\n\n# Number of random distortion images to generate per font and character.\nDISTORTION_COUNT = 3\n\n# Width and height of the resulting image.\nIMAGE_WIDTH = 64\nIMAGE_HEIGHT = 64\n\n\ndef generate_hangul_images(label_file, fonts_dir, output_dir):\n    """"""Generate Hangul image files.\n\n    This will take in the passed in labels file and will generate several\n    images using the font files provided in the font directory. The font\n    directory is expected to be populated with *.ttf (True Type Font) files.\n    The generated images will be stored in the given output directory. Image\n    paths will have their corresponding labels listed in a CSV file.\n    """"""\n    with io.open(label_file, \'r\', encoding=\'utf-8\') as f:\n        labels = f.read().splitlines()\n\n    image_dir = os.path.join(output_dir, \'hangul-images\')\n    if not os.path.exists(image_dir):\n        os.makedirs(os.path.join(image_dir))\n\n    # Get a list of the fonts.\n    fonts = glob.glob(os.path.join(fonts_dir, \'*.ttf\'))\n\n    labels_csv = io.open(os.path.join(output_dir, \'labels-map.csv\'), \'w\',\n                         encoding=\'utf-8\')\n\n    total_count = 0\n    prev_count = 0\n    for character in labels:\n        # Print image count roughly every 5000 images.\n        if total_count - prev_count > 5000:\n            prev_count = total_count\n            print(\'{} images generated...\'.format(total_count))\n\n        for font in fonts:\n            total_count += 1\n            image = Image.new(\'L\', (IMAGE_WIDTH, IMAGE_HEIGHT), color=0)\n            font = ImageFont.truetype(font, 48)\n            drawing = ImageDraw.Draw(image)\n            w, h = drawing.textsize(character, font=font)\n            drawing.text(\n                ((IMAGE_WIDTH-w)/2, (IMAGE_HEIGHT-h)/2),\n                character,\n                fill=(255),\n                font=font\n            )\n            file_string = \'hangul_{}.jpeg\'.format(total_count)\n            file_path = os.path.join(image_dir, file_string)\n            image.save(file_path, \'JPEG\')\n            labels_csv.write(u\'{},{}\\n\'.format(file_path, character))\n\n            for i in range(DISTORTION_COUNT):\n                total_count += 1\n                file_string = \'hangul_{}.jpeg\'.format(total_count)\n                file_path = os.path.join(image_dir, file_string)\n                arr = numpy.array(image)\n\n                distorted_array = elastic_distort(\n                    arr, alpha=random.randint(30, 36),\n                    sigma=random.randint(5, 6)\n                )\n                distorted_image = Image.fromarray(distorted_array)\n                distorted_image.save(file_path, \'JPEG\')\n                labels_csv.write(u\'{},{}\\n\'.format(file_path, character))\n\n    print(\'Finished generating {} images.\'.format(total_count))\n    labels_csv.close()\n\n\ndef elastic_distort(image, alpha, sigma):\n    """"""Perform elastic distortion on an image.\n\n    Here, alpha refers to the scaling factor that controls the intensity of the\n    deformation. The sigma variable refers to the Gaussian filter standard\n    deviation.\n    """"""\n    random_state = numpy.random.RandomState(None)\n    shape = image.shape\n\n    dx = gaussian_filter(\n        (random_state.rand(*shape) * 2 - 1),\n        sigma, mode=""constant""\n    ) * alpha\n    dy = gaussian_filter(\n        (random_state.rand(*shape) * 2 - 1),\n        sigma, mode=""constant""\n    ) * alpha\n\n    x, y = numpy.meshgrid(numpy.arange(shape[0]), numpy.arange(shape[1]))\n    indices = numpy.reshape(y+dy, (-1, 1)), numpy.reshape(x+dx, (-1, 1))\n    return map_coordinates(image, indices, order=1).reshape(shape)\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--label-file\', type=str, dest=\'label_file\',\n                        default=DEFAULT_LABEL_FILE,\n                        help=\'File containing newline delimited labels.\')\n    parser.add_argument(\'--font-dir\', type=str, dest=\'fonts_dir\',\n                        default=DEFAULT_FONTS_DIR,\n                        help=\'Directory of ttf fonts to use.\')\n    parser.add_argument(\'--output-dir\', type=str, dest=\'output_dir\',\n                        default=DEFAULT_OUTPUT_DIR,\n                        help=\'Output directory to store generated images and \'\n                             \'label CSV file.\')\n    args = parser.parse_args()\n    generate_hangul_images(args.label_file, args.fonts_dir, args.output_dir)\n'"
