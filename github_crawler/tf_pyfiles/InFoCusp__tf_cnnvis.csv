file_path,api_count,code
setup.py,0,"b'# Setup script for tf_cnnvis\nimport os\nimport sys\nimport six\nimport pkgutil\nimport shutil\nimport glob\n\n# required pkgs\ndependencies = [\'numpy\', \'scipy\', \'h5py\', \'wget\', \'Pillow\', \'six\',\'scikit-image\']\n\ntry:\n    from setuptools import setup\nexcept ImportError:\n    from distutils.core import setup\n    print(""Please install if not installed:"", dependencies)\nfrom distutils.command.clean import clean\n\ndef read(fname):\n    if six.PY2:\n        return open(os.path.join(os.path.dirname(__file__), fname)).read()\n    else:\n        return open(os.path.join(os.path.dirname(__file__), fname), encoding=\'latin1\').read()\n\nclass CleanCommand(clean):\n    """"""Custom clean command to tidy up the project root.""""""\n    def deleteFileOrDir(self, f):\n        try:\n            if os.path.isdir(f):\n                shutil.rmtree(f, ignore_errors=True)\n            else:\n                os.remove(f)\n        except Exception as e:\n            print(e)\n\n    def run(self):\n        for p in \'./build ./dist ./*.pyc ./*.tgz ./*.egg-info\'.split(\' \'):\n            if \'*\' in p:\n                for f in glob.glob(p):\n                    self.deleteFileOrDir(f)\n            else:\n                self.deleteFileOrDir(p)\n\nsetup(\n    name = ""tf_cnnvis"",\n    version = ""1.0.0"",\n    author = ""Bhagyesh Vikani & Falak Shah"",\n    author_email = ""bhagyesh@infocusp.in & falak@infocusp.in"",\n    description = (""tf_cnnvis is a CNN visualization library based on the paper \'Visualizing and Understanding Convolutional Networks\' by Matthew D. Zeiler and Rob Fergus. We use the \'TensorFlow\' library to reconstruct the input images from different layers of the convolutional neural network. The generated images are displayed in [TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard).""),\n    license = ""MIT"",\n    keywords = ""tensorflow tensorboard convolutional-neural-networks cnn visualization"",\n    url = ""https://github.com/InFoCusp/tf_cnnvis"",\n    packages=[\'tf_cnnvis\'],\n    long_description=read(\'ReadMe.md\'),\n    classifiers=[\n        ""Development Status :: 3 - Alpha"",\n        ""Intended Audience :: Science/Research"",\n        ""Topic :: Utilities"",\n        ""License :: OSI Approved :: MIT License"",\n        ""Natural Language :: English"",\n        ""Operating System :: Unix"",\n        ""Programming Language :: Python"",\n        ""Topic :: Scientific/Engineering :: Visualization"",\n    ],\n    install_requires=dependencies,\n    cmdclass={\n        \'clean\': CleanCommand,\n    }\n)\n\n# Check TF version as it requires > 1.8\ntry:\n    import tensorflow\n    if (int(tensorflow.__version__.split(""."")[0]) + 0.1 * int(tensorflow.__version__.split(""."")[1])) < 1.8:\n        print(""Please upgrade to TensorFlow >= 1.8.0"")\nexcept:\n    print(""Please install TenSorflow with \'pip install tensorflow\'"")\n'"
tf_cnnvis/__init__.py,0,"b'from .tf_cnnvis import activation_visualization\nfrom .tf_cnnvis import deconv_visualization\nfrom .tf_cnnvis import deepdream_visualization\n\nfrom .utils import convert_into_grid\nfrom .utils import image_normalization\n\n__all__ = [""activation_visualization"", ""deconv_visualization"", ""deepdream_visualization"", ""convert_into_grid"", ""image_normalization""]\n'"
tf_cnnvis/tf_cnnvis.py,38,"b'# imports\nimport os\nimport time\n\nimport numpy as np\n\nfrom six.moves import range\nfrom six import string_types\n\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import gen_nn_ops\n\nfrom skimage.restoration import denoise_tv_bregman\n\nfrom .utils import *\nfrom .utils import config\n\n\nis_Registered = False # prevent duplicate gradient registration\n# map from keyword to layer type\ndict_layer = {\'r\' : ""relu"", \'p\' : \'maxpool\', \'c\' : \'conv2d\'}\nunits = None\n\nconfigProto = tf.ConfigProto(allow_soft_placement = True)\n\n# register custom gradients\ndef _register_custom_gradients():\n    """"""\n    Register Custom Gradients.\n    """"""\n    global is_Registered\n\n    if not is_Registered:\n        # register LRN gradients\n        @ops.RegisterGradient(""Customlrn"")\n        def _CustomlrnGrad(op, grad):\n            return grad\n\n        # register Relu gradients\n        @ops.RegisterGradient(""GuidedRelu"")\n        def _GuidedReluGrad(op, grad):\n            return tf.where(0. < grad, gen_nn_ops.relu_grad(grad, op.outputs[0]), tf.zeros_like(grad))\n\n        is_Registered = True\n\n\n# save given graph object as meta file\ndef _save_model(graph_or_sess):\n    """"""\n    Save the given TF session at PATH = ""./model/tmp-model""\n\n    :param sess:\n        TF sess\n    :type sess:  tf.Session object\n\n    :return:\n        Path to saved session\n    :rtype: String\n    """"""\n    if isinstance(graph_or_sess, tf.Graph):\n        ops = graph_or_sess.get_operations()\n        for op in ops:\n            if \'variable\' in op.type.lower():\n                raise ValueError(\'Please input a frozen graph (no variables). Or pass in the session object.\')\n\n        with graph_or_sess.as_default():\n            sess = tf.Session(config=configProto)\n\n            fake_var = tf.Variable([0.0], name=""fake_var"")\n            sess.run(tf.global_variables_initializer())\n    else:\n        sess=graph_or_sess\n\n    PATH = os.path.join(""model"", ""tmp-model"")\n    make_dir(path = os.path.dirname(PATH))\n    saver = tf.train.Saver()\n    #i should deal with the case in which sess is closed.\n    saver.save(sess, PATH)\n\n    if isinstance(graph_or_sess, tf.Graph):\n        sess.close()\n\n    return PATH + "".meta""\n\n\n# All visualization of convolution happens here\ndef _get_visualization(sess_graph_path, value_feed_dict, input_tensor, layers, path_logdir, path_outdir, method = None):\n    """"""\n    cnnvis main api function\n\n    :param sess_graph_path:\n        TF session (open) or\n        <Path-to-saved-sessiion> as String or\n        TF graph (either FROZEN - training variables set to const, or INITIALIZED - init. values will be visualized)\n    :type sess_graph_path: tf.Sess object or String or tf.Graph object\n\n    :param value_feed_dict:\n        Values of placeholders to feed while evaluting.\n        dict : {placeholder1 : value1, ...}.\n    :type value_feed_dict: dict or list\n\n    :param input_tensor:\n        tf.tensor object which is an input to TF graph\n    :type input_tensor: tf.tensor object (Default = None)\n\n    :param layers:\n        Name of the layer to visualize or layer type.\n        Supported layer types :\n        \'r\' : Reconstruction from all the relu layers\n        \'p\' : Reconstruction from all the pooling layers\n        \'c\' : Reconstruction from all the convolutional layers\n    :type layers: list or String (Default = \'r\')\n\n    :param path_logdir:\n        <path-to-log-dir> to make log file for TensorBoard visualization\n    :type path_logdir: String (Default = ""./Log"")\n\n    :param path_outdir:\n        <path-to-dir> to save results into disk as images\n    :type path_outdir: String (Default = ""./Output"")\n\n    :return:\n        True if successful. False otherwise.\n    :rtype: boolean\n    """"""\n    is_success = True\n\n    # convert all inplicit and explicit sess input cases to a PATH\n    if isinstance(sess_graph_path, tf.Graph):\n        PATH = _save_model(sess_graph_path)\n    elif isinstance(sess_graph_path, tf.Session):\n        PATH = _save_model(sess_graph_path)\n    elif isinstance(sess_graph_path, string_types):\n        PATH = sess_graph_path\n    elif sess_graph_path is None:\n        # None input defaults to the default session if available, to the default graoh otherwise.\n        if isinstance(tf.get_default_session(), tf.Session):\n            PATH = _save_model(tf.get_default_session())\n        else:\n            PATH = _save_model(tf.get_default_graph())\n    else:\n        print(""sess_graph_path must be an instance of tf.Session, tf. Graph, string or None."")\n        is_success = False\n        return is_success\n\n    is_gradient_overwrite = method == ""deconv""\n    if is_gradient_overwrite:\n        _register_custom_gradients() # register custom gradients\n\n    # a new default Graph g and Session s which are loaded and used only in these nested with statements\n    with tf.Graph().as_default() as g:\n        with tf.Session(graph=g).as_default() as s:\n            if is_gradient_overwrite:\n                with g.gradient_override_map({\'Relu\': \'GuidedRelu\', \'LRN\': \'Customlrn\'}): # overwrite gradients with custom gradients\n                    #works on s which is the default session, so it has an impact despite s is not used after this\n                    s = _graph_import_function(PATH,s)\n            else:\n                s = _graph_import_function(PATH,s)\n\n            if not isinstance(layers, list):\n                layers =[layers]\n\n            for layer in layers:\n                if layer != None and layer.lower() not in dict_layer.keys():\n                    is_success = _visualization_by_layer_name(g, value_feed_dict, input_tensor, layer, method, path_logdir, path_outdir)\n                elif layer != None and layer.lower() in dict_layer.keys():\n                    layer_type = dict_layer[layer.lower()]\n                    is_success = _visualization_by_layer_type(g, value_feed_dict, input_tensor, layer_type, method, path_logdir, path_outdir)\n                else:\n                    print(""Skipping %s . %s is not valid layer name or layer type"" % (layer, layer))\n\n    return is_success\n\n\ndef _graph_import_function(PATH, sess):\n    new_saver = tf.train.import_meta_graph(PATH) # Import graph\n    new_saver.restore(sess, tf.train.latest_checkpoint(os.path.dirname(PATH)))\n    return sess\n\ndef _visualization_by_layer_type(graph, value_feed_dict, input_tensor, layer_type, method, path_logdir, path_outdir):\n    """"""\n    Generate filter visualization from the layers which are of type layer_type\n\n    :param graph:\n        TF graph\n    :type graph: tf.Graph object\n\n    :param value_feed_dict:\n        Values of placeholders to feed while evaluting.\n        dict : {placeholder1 : value1, ...}.\n    :type value_feed_dict: dict or list\n\n    :param input_tensor:\n        Where to reconstruct\n    :type input_tensor: tf.tensor object (Default = None)\n\n    :param layer_type:\n        Type of the layer. Supported layer types :\n        \'r\' : Reconstruction from all the relu layers\n        \'p\' : Reconstruction from all the pooling layers\n        \'c\' : Reconstruction from all the convolutional layers\n    :type layer_type: String (Default = \'r\')\n\n    :param path_logdir:\n        <path-to-log-dir> to make log file for TensorBoard visualization\n    :type path_logdir: String (Default = ""./Log"")\n\n    :param path_outdir:\n        <path-to-dir> to save results into disk as images\n    :type path_outdir: String (Default = ""./Output"")\n\n    :return:\n        True if successful. False otherwise.\n    :rtype: boolean\n    """"""\n    is_success = True\n\n    layers = []\n    # Loop through all operations and parse operations\n    # for operations of type = layer_type\n    for i in graph.get_operations():\n        if layer_type.lower() == i.type.lower():\n            layers.append(i.name)\n\n    for layer in layers:\n        is_success = _visualization_by_layer_name(graph, value_feed_dict, input_tensor, layer, method, path_logdir, path_outdir)\n    return is_success\n\ndef _visualization_by_layer_name(graph, value_feed_dict, input_tensor, layer_name, method, path_logdir, path_outdir):\n    """"""\n    Generate and store filter visualization from the layer which has the name layer_name\n\n    :param graph:\n        TF graph\n    :type graph: tf.Graph object\n\n    :param value_feed_dict:\n        Values of placeholders to feed while evaluting.\n        dict : {placeholder1 : value1, ...}.\n    :type value_feed_dict: dict or list\n\n    :param input_tensor:\n        Where to reconstruct\n    :type input_tensor: tf.tensor object (Default = None)\n\n    :param layer_name:\n        Name of the layer to visualize\n    :type layer_name: String\n\n    :param path_logdir:\n        <path-to-log-dir> to make log file for TensorBoard visualization\n    :type path_logdir: String (Default = ""./Log"")\n\n    :param path_outdir:\n        <path-to-dir> to save results into disk as images\n    :type path_outdir: String (Default = ""./Output"")\n\n    :return:\n        True if successful. False otherwise.\n    :rtype: boolean\n    """"""\n    start = -time.time()\n    is_success = True\n\n    sess = tf.get_default_session()\n    if not(graph is sess.graph):\n        print(\'Error, the graph input is not the graph of the current session!!\')\n    # try:\n    parsed_tensors = parse_tensors_dict(graph, layer_name, value_feed_dict)\n    if parsed_tensors == None:\n        return is_success\n\n    op_tensor, x, X_in, feed_dict = parsed_tensors\n\n    is_deep_dream = True\n    #is_valid_sess = True\n    with graph.as_default():\n        # computing reconstruction\n        X = X_in\n        if input_tensor != None:\n            X = get_tensor(graph = graph, name = input_tensor.name)\n        # original_images = sess.run(X, feed_dict = feed_dict)\n\n        results = None\n        if method == ""act"":\n            # compute activations\n            results = _activation(graph, sess, op_tensor, feed_dict)\n        elif method == ""deconv"":\n            # deconvolution\n            results = _deconvolution(graph, sess, op_tensor, X, feed_dict)\n        elif method == ""deepdream"":\n            # deepdream\n            is_success = _deepdream(graph, sess, op_tensor, X, feed_dict, layer_name, path_outdir, path_logdir)\n            is_deep_dream = False\n\n    # except:\n    # \tis_success = False\n    # \tprint(""No Layer with layer name = %s"" % (layer_name))\n    # \treturn is_success\n\n    if is_deep_dream:\n        is_success = write_results(results, layer_name, path_outdir, path_logdir, method = method)\n\n    start += time.time()\n    print(""Reconstruction Completed for %s layer. Time taken = %f s"" % (layer_name, start))\n\n    return is_success\n\n\n# computing visualizations\ndef _activation(graph, sess, op_tensor, feed_dict):\n    with graph.as_default() as g:\n        with sess.as_default() as sess:\n            act = sess.run(op_tensor, feed_dict = feed_dict)\n    return act\ndef _deconvolution(graph, sess, op_tensor, X, feed_dict):\n    out = []\n    with graph.as_default() as g:\n        # get shape of tensor\n        tensor_shape = op_tensor.get_shape().as_list()\n\n        with sess.as_default() as sess:\n            # creating placeholders to pass featuremaps and\n            # creating gradient ops\n            featuremap = [tf.placeholder(tf.int32) for i in range(config[""N""])]\n            reconstruct = [tf.gradients(tf.transpose(tf.transpose(op_tensor)[featuremap[i]]), X)[0] for i in range(config[""N""])]\n\n            # Execute the gradient operations in batches of \'n\'\n            for i in range(0, tensor_shape[-1], config[""N""]):\n                c = 0\n                for j in range(config[""N""]):\n                    if (i + j) < tensor_shape[-1]:\n                        feed_dict[featuremap[j]] = i + j\n                        c += 1\n                if c > 0:\n                    out.extend(sess.run(reconstruct[:c], feed_dict = feed_dict))\n    return out\ndef _deepdream(graph, sess, op_tensor, X, feed_dict, layer, path_outdir, path_logdir):\n    tensor_shape = op_tensor.get_shape().as_list()\n\n    with graph.as_default() as g:\n        n = (config[""N""] + 1) // 2\n        feature_map = tf.placeholder(dtype = tf.int32)\n        tmp1 = tf.reduce_mean(tf.multiply(tf.gather(tf.transpose(op_tensor),feature_map),tf.diag(tf.ones_like(feature_map, dtype = tf.float32))), axis = 0)\n        tmp2 = 1e-3 * tf.reduce_mean(tf.square(X), axis = (1, 2 ,3))\n        tmp = tmp1 - tmp2\n        t_grad = tf.gradients(ys = tmp, xs = X)[0]\n\n        with sess.as_default() as sess:\n            input_shape = sess.run(tf.shape(X), feed_dict = feed_dict)\n            tile_size = input_shape[1 : 3]\n            channels = input_shape[3]\n\n            lap_in = tf.placeholder(np.float32, name=\'lap_in\')\n            laplacian_pyramid = lap_normalize(lap_in, channels, scale_n=config[""NUM_LAPLACIAN_LEVEL""])\n\n            image_to_resize = tf.placeholder(np.float32, name=\'image_to_resize\')\n            size_to_resize = tf.placeholder(np.int32, name=\'size_to_resize\')\n            resize_image = tf.image.resize_bilinear(image_to_resize, size_to_resize)\n\n            end = len(units)\n            for k in range(0, end, n):\n                c = n\n                if k + n > end:\n                    c = end - ((end // n) * n)\n                img = np.random.uniform(size = (c, tile_size[0], tile_size[1], channels)) + 117.0\n                feed_dict[feature_map] = units[k : k + c]\n\n                for octave in range(config[""NUM_OCTAVE""]):\n                    if octave > 0:\n                        hw = np.float32(img.shape[1:3])*config[""OCTAVE_SCALE""]\n                        img = sess.run(resize_image, {image_to_resize : img, size_to_resize : np.int32(hw)})\n\n                        for i, im in enumerate(img):\n                            min_img = im.min()\n                            max_img = im.max()\n                            temp = denoise_tv_bregman((im - min_img) / (max_img - min_img), weight = config[""TV_DENOISE_WEIGHT""])\n                            img[i] = (temp * (max_img - min_img) + min_img).reshape(img[i].shape)\n\n                    for j in range(config[""NUM_ITERATION""]):\n                        sz = tile_size\n                        h, w = img.shape[1:3]\n                        sx = np.random.randint(sz[1], size=1)\n                        sy = np.random.randint(sz[0], size=1)\n                        img_shift = np.roll(np.roll(img, sx, 2), sy, 1)\n                        grad = np.zeros_like(img)\n                        for y in range(0, max(h-sz[0]//2,sz[0]), sz[0] // 2):\n                            for x in range(0, max(h-sz[1]//2,sz[1]), sz[1] // 2):\n                                    feed_dict[X] = img_shift[:, y:y+sz[0],x:x+sz[1]]\n                                    try:\n                                        grad[:, y:y+sz[0],x:x+sz[1]] = sess.run(t_grad, feed_dict=feed_dict)\n                                    except:\n                                        pass\n\n                        lap_out = sess.run(laplacian_pyramid, feed_dict={lap_in:np.roll(np.roll(grad, -sx, 2), -sy, 1)})\n                        img = img + lap_out\n                is_success = write_results(img, (layer, units, k), path_outdir, path_logdir, method = ""deepdream"")\n                print(""%s -> featuremap completed."" % ("", "".join(str(num) for num in units[k:k+c])))\n    return is_success\n\n\n# main api methods\ndef activation_visualization(sess_graph_path, value_feed_dict, input_tensor = None,  layers = \'r\', path_logdir = \'./Log\', path_outdir = ""./Output""):\n    is_success = _get_visualization(sess_graph_path, value_feed_dict, input_tensor = input_tensor, layers = layers, method = ""act"",\n        path_logdir = path_logdir, path_outdir = path_outdir)\n    return is_success\ndef deconv_visualization(sess_graph_path, value_feed_dict, input_tensor = None,  layers = \'r\', path_logdir = \'./Log\', path_outdir = ""./Output""):\n    is_success = _get_visualization(sess_graph_path, value_feed_dict, input_tensor = input_tensor, layers = layers, method = ""deconv"",\n        path_logdir = path_logdir, path_outdir = path_outdir)\n    return is_success\n\ndef deepdream_visualization(sess_graph_path, value_feed_dict, layer, classes, input_tensor = None, path_logdir = \'./Log\', path_outdir = ""./Output""):\n    if isinstance(layer, list):\n        print(""Please only give classification layer name for reconstruction."")\n        return False\n    elif layer in dict_layer.keys():\n        print(""Please only give classification layer name for reconstruction."")\n        return False\n    else:\n        global units\n        units = classes\n        is_success = _get_visualization(sess_graph_path, value_feed_dict, input_tensor = input_tensor, layers = layer, method = ""deepdream"",\n            path_logdir = path_logdir, path_outdir = path_outdir)\n    return is_success\n'"
tf_cnnvis/utils.py,24,"b'import os\nimport time\nimport datetime\nfrom math import ceil, sqrt\n\nimport numpy as np\nfrom scipy.misc import imsave\n\nfrom six.moves import range\nfrom six import iteritems\n\nimport tensorflow as tf\n\n\nk = np.float32([1, 4, 6, 4, 1])\nk = np.outer(k, k)\nK5X5 = k[ : , : , None , None ] / k.sum() * np.eye(3, dtype = np.float32)\nchannels = 1\n\n# optional hyperparameter settings\nconfig = {\n    ""N"" : 8,\n    ""EPS"" : 1e-7,\n    ""K5X5"" : K5X5,\n    ""MAX_IMAGES"" : 1,\n    ""NUM_OCTAVE"" : 3,\n    ""STEP_SIZE"" : 1.0,\n    ""NUM_ITERATION"" : 50,\n    ""OCTAVE_SCALE"" : 1.4,\n    ""MAX_FEATUREMAP"" : 1024,\n    ""FORCE_COMPUTE"" : False,\n    ""TV_DENOISE_WEIGHT"" : 2.0,\n    ""NUM_LAPLACIAN_LEVEL"" : 4,\n    ""REGULARIZATION_STRENGTH"" : 1e-3\n}\ndef reset_config():\n    config = {\n        ""N"" : 8,\n        ""EPS"" : 1e-7,\n        ""K5X5"" : K5X5,\n        ""MAX_IMAGES"" : 1,\n        ""NUM_OCTAVE"" : 3,\n        ""STEP_SIZE"" : 1.0,\n        ""NUM_ITERATION"" : 50,\n        ""OCTAVE_SCALE"" : 1.4,\n        ""MAX_FEATUREMAP"" : 1024,\n        ""FORCE_COMPUTE"" : False,\n        ""TV_DENOISE_WEIGHT"" : 2.0,\n        ""NUM_LAPLACIAN_LEVEL"" : 4,\n        ""REGULARIZATION_STRENGTH"" : 1e-3\n    }\ndef get_config():\n    return config\ndef set_config(config_dict):\n    config = config_dict\n\n\n# parse tensors and prepare feed dict\ndef parse_tensors_dict(graph, layer_name, value_feed_dict):\n    x = []\n    feed_dict = {}\n    with graph.as_default() as g:\n        # get op of name given in method argument layer_name\n        op = get_operation(graph = g, name = layer_name)\n        op_tensor = op.outputs[0] # output tensor of the operation\n        tensor_shape = op_tensor.get_shape().as_list() # get shape of tensor\n\n        # check for limit on number of feature maps\n        if not config[""FORCE_COMPUTE""] and tensor_shape[-1] > config[""MAX_FEATUREMAP""]:\n            print(""Skipping. Too many featuremaps. May cause memory errors."")\n            return None\n\n        # creating feed_dict and find input tensors\n        X_in = None\n\n        # find tensors of value_feed_dict\n        # in current graph by name\n        for key_op, value in iteritems(value_feed_dict):\n            tmp = get_tensor(graph = g, name = key_op.name)\n            feed_dict[tmp] = value\n            x.append(tmp)\n\n        X_in = x[0]\n        feed_dict[X_in] = feed_dict[X_in][:config[""MAX_IMAGES""]] # only taking first MAX_IMAGES from given images array\n    return op_tensor, x, X_in, feed_dict\n\n\n# written results into disk as well as logfile of TensorBoard\ndef _write_activation(activations, layer, path_outdir, path_logdir):\n    is_success = True\n\n    act_shape = activations.shape\n    if len(act_shape) == 2:\n        grid_activations = [np.expand_dims(image_normalization(convert_into_grid(im[:,np.newaxis,np.newaxis,np.newaxis], padding=0)), axis = 0) for im in activations]\n    else:\n        activations = [np.expand_dims(im, axis = 3) for im in np.transpose(activations, (3, 0, 1, 2))]\n        activations = _im_normlize(activations)\n        grid_activations = _images_to_grid(activations)\n\n    # write into disk\n    path_out = os.path.join(path_outdir, layer.lower().replace(""/"", ""_""))\n\n    for i in range(len(grid_activations)):\n        time_stamp = time.time()\n        time_stamp = datetime.datetime.fromtimestamp(time_stamp).strftime(\'%Y-%m-%d_%H-%M-%S\')\n\n        grid_activation_path = os.path.join(path_out, ""activations"")\n        is_success = make_dir(grid_activation_path)\n        imsave(os.path.join(grid_activation_path, ""grid_activation.png""), grid_activations[i][0,:,:,0], format = ""png"")\n\n    # write into logfile\n    path_log = os.path.join(path_logdir, layer.lower().replace(""/"", ""_""))\n    is_success = make_dir(path_log)\n\n    with tf.Graph().as_default() as g:\n        image = tf.placeholder(tf.float32, shape = [None, None, None, None])\n        image_summary_t = tf.summary.image(name = ""All_At_Once_Activations"", tensor = image, max_outputs = config[""MAX_IMAGES""])\n\n        with tf.Session() as sess:\n            summary = sess.run(image_summary_t, feed_dict = {image : np.concatenate(grid_activations, axis = 0)})\n\n        try:\n            file_writer = tf.summary.FileWriter(path_log, g) # create file writer\n            file_writer.add_summary(summary)\n        except:\n            is_success = False\n            print(""Error occured int writting results into log file."")\n        finally:\n            file_writer.close() # close file writer\n    return is_success\ndef _write_deconv(images, layer, path_outdir, path_logdir):\n    is_success = True\n\n    images = _im_normlize(images)\n    grid_images = _images_to_grid(images)\n\n    # write into disk\n    path_out = os.path.join(path_outdir, layer.lower().replace(""/"", ""_""))\n\n    for i in range(len(grid_images)):\n        time_stamp = time.time()\n        time_stamp = datetime.datetime.fromtimestamp(time_stamp).strftime(\'%Y-%m-%d_%H-%M-%S\')\n\n        grid_image_path = os.path.join(path_out, ""deconvolution"")\n        is_success = make_dir(grid_image_path)\n        if grid_images[i].shape[-1] == 1:\n            imsave(os.path.join( grid_image_path, ""grid_image.png""), grid_images[i][0,:,:,0], format = ""png"")\n        else:\n            imsave(os.path.join(grid_image_path, ""grid_image.png""), grid_images[i][0], format = ""png"")\n\n    # for j in range(len(images[i])):\n    # \timage_path = os.path.join(path_out, ""image_%d"" % (j))\n    # \tis_success = make_dir(image_path)\n    # \tfor i in range(len(images)):\n    # \t\timsave(os.path.join(image_path, ""feature_%d"" % (i)), images[i][j], format = ""png"")\n\n    # write into logfile\n    path_log = os.path.join(path_logdir, layer.lower().replace(""/"", ""_""))\n    is_success = make_dir(path_log)\n\n    with tf.Graph().as_default() as g:\n        image = tf.placeholder(tf.float32, shape = [None, None, None, None])\n\n        image_summary_t1 = tf.summary.image(name = ""One_By_One_Deconv"", tensor = image, max_outputs = config[""MAX_FEATUREMAP""])\n        image_summary_t2 = tf.summary.image(name = ""All_At_Once_Deconv"", tensor = image, max_outputs = config[""MAX_IMAGES""])\n\n        with tf.Session() as sess:\n            summary1 = sess.run(image_summary_t1, feed_dict = {image : np.concatenate(images, axis = 0)})\n            summary2 = sess.run(image_summary_t2, feed_dict = {image : np.concatenate(grid_images, axis = 0)})\n        try:\n            file_writer = tf.summary.FileWriter(path_log, g) # create file writer\n            # compute and write the summary\n            file_writer.add_summary(summary1)\n            file_writer.add_summary(summary2)\n        except:\n            is_success = False\n            print(""Error occured in writting results into log file."")\n        finally:\n            file_writer.close() # close file writer\n    return is_success\ndef _write_deepdream(images, layer, path_outdir, path_logdir):\n    is_success = True\n\n    images = _im_normlize([images])\n    layer, units, k = layer\n    # write into disk\n    path_out = os.path.join(path_outdir, ""deepdream_"" + layer.lower().replace(""/"", ""_""))\n    is_success = make_dir(path_out)\n\n    for i in range(len(images)):\n        for j in range(images[i].shape[0]):\n            img_save = images[i][j]\n            if img_save.shape[2] == 1:\n                img_save = np.squeeze(img_save, axis=2)\n            imsave(os.path.join(path_out, ""image_%d.png"" % (units[(i * images[i].shape[0]) + j + k])), img_save, format = ""png"")\n\n    # write into logfile\n    path_log = os.path.join(path_logdir, layer.lower().replace(""/"", ""_""))\n    is_success = make_dir(path_log)\n\n    with tf.Graph().as_default() as g:\n        image = tf.placeholder(tf.float32, shape = [None, None, None, None])\n\n        image_summary_t = tf.summary.image(name = ""One_By_One_DeepDream"", tensor = image, max_outputs = config[""MAX_FEATUREMAP""])\n\n        with tf.Session() as sess:\n            summary = sess.run(image_summary_t, feed_dict = {image : np.concatenate(images, axis = 0)})\n        try:\n            file_writer = tf.summary.FileWriter(path_log, g) # create file writer\n            # compute and write the summary\n            file_writer.add_summary(summary)\n        except:\n            is_success = False\n            print(""Error occured in writting results into log file."")\n        finally:\n            file_writer.close() # close file writer\n    return is_success\ndef write_results(results, layer, path_outdir, path_logdir, method):\n    is_success = True\n\n    if method == ""act"":\n        is_success = _write_activation(results, layer, path_outdir, path_logdir)\n    elif method == ""deconv"":\n        is_success = _write_deconv(results, layer, path_outdir, path_logdir)\n    elif method == ""deepdream"":\n        is_success = _write_deepdream(results, layer, path_outdir, path_logdir)\n    return is_success\n\n\n# if dir not exits make one\ndef _is_dir_exist(path):\n    return os.path.exists(path)\ndef make_dir(path):\n    is_success = True\n\n    # if dir is not exist make one\n    if not _is_dir_exist(path):\n        try:\n            os.makedirs(path)\n        except OSError as exc:\n            is_success = False\n    return is_success\n\n\n# get operation and tensor by name\ndef get_operation(graph, name):\n    return graph.get_operation_by_name(name = name)\ndef get_tensor(graph, name):\n    return graph.get_tensor_by_name(name = name)\n\n\n# image or images normalization\ndef image_normalization(image, s = 0.1, ubound = 255.0):\n    """"""\n    Min-Max image normalization. Convert pixle values in range [0, ubound]\n\n    :param image:\n        A numpy array to normalize\n    :type image: 3-D numpy array\n\n    :param ubound:\n        upperbound for a image pixel value\n    :type ubound: float (Default = 255.0)\n\n    :return:\n        A normalized image\n    :rtype: 3-D numpy array\n    """"""\n    img_min = np.min(image)\n    img_max = np.max(image)\n    return (((image - img_min) * ubound) / (img_max - img_min + config[""EPS""])).astype(\'uint8\')\ndef _im_normlize(images, ubound = 255.0):\n    N = len(images)\n    H, W, C = images[0][0].shape\n\n    for i in range(N):\n        for j in range(images[i].shape[0]):\n            images[i][j] = image_normalization(images[i][j], ubound = ubound)\n    return images\n\n\n# convert a array of images or list of arrays of images into grid images\ndef convert_into_grid(Xs, ubound=255.0, padding=1):\n    """"""\n    Convert 4-D numpy array into a grid image\n\n    :param Xs:\n        A numpy array of images to make grid out of it\n    :type Xs: 4-D numpy array (first axis contations an image)\n\n    :param ubound:\n        upperbound for a image pixel value\n    :type ubound: float (Default = 255.0)\n\n    :param padding:\n        padding size between grid cells\n    :type padding: int (Default = 1)\n\n    :return:\n        A grid of input images\n    :rtype: 3-D numpy array\n    """"""\n    (N, H, W, C) = Xs.shape\n    grid_size = int(ceil(sqrt(N)))\n    grid_height = H * grid_size + padding * (grid_size - 1)\n    grid_width = W * grid_size + padding * (grid_size - 1)\n    grid = np.zeros((grid_height, grid_width, C))\n    next_idx = 0\n    y0, y1 = 0, H\n    for y in range(grid_size):\n        x0, x1 = 0, W\n        for x in range(grid_size):\n            if next_idx < N:\n                grid[y0:y1, x0:x1] = Xs[next_idx]\n                next_idx += 1\n            x0 += W + padding\n            x1 += W + padding\n        y0 += H + padding\n        y1 += H + padding\n    return grid.astype(\'uint8\')\ndef _images_to_grid(images):\n    """"""\n    Convert a list of arrays of images into a list of grid of images\n\n    :param images:\n        a list of 4-D numpy arrays(each containing images)\n    :type images: list\n\n    :return:\n        a list of grids which are grid representation of input images\n    :rtype: list\n    """"""\n    grid_images = []\n    # if \'images\' is not empty convert\n    # list of images into grid of images\n    if len(images) > 0:\n        N = len(images)\n        H, W, C = images[0][0].shape\n        for j in range(len(images[0])):\n            tmp = np.zeros((N, H, W, C))\n            for i in range(N):\n                tmp[i] = images[i][j]\n            grid_images.append(np.expand_dims(convert_into_grid(tmp), axis = 0))\n    return grid_images\n\n\n# laplacian pyramid gradient normalization\ndef _lap_split(img):\n    \'\'\'Split the image into lo and hi frequency components\'\'\'\n    with tf.name_scope(\'split\'):\n        lo = tf.nn.conv2d(img, config[""K5X5""], [1, 2, 2, 1], \'SAME\')\n        lo2 = tf.nn.conv2d_transpose(lo, config[""K5X5""] * 4, tf.shape(img), [1, 2, 2, 1])\n        hi = img-lo2\n    return lo, hi\ndef _lap_split_n(img, n):\n    \'\'\'Build Laplacian pyramid with n splits\'\'\'\n    levels = []\n    for i in range(n):\n        img, hi = _lap_split(img)\n        levels.append(hi)\n    levels.append(img)\n    return levels[::-1]\ndef _lap_merge(levels):\n    \'\'\'Merge Laplacian pyramid\'\'\'\n    img = levels[0]\n    for hi in levels[1:]:\n        with tf.name_scope(\'merge\'):\n            img = tf.nn.conv2d_transpose(img, config[""K5X5""]*4, tf.shape(hi), [1,2,2,1]) + hi\n    return img\ndef _normalize_std(img):\n    \'\'\'Normalize image by making its standard deviation = 1.0\'\'\'\n    with tf.name_scope(\'normalize\'):\n        std = tf.sqrt(tf.reduce_mean(tf.square(img), axis = (1, 2, 3), keep_dims=True))\n        return img/tf.maximum(std, config[""EPS""])\ndef lap_normalize(img, channels, scale_n):\n    \'\'\'Perform the Laplacian pyramid normalization.\'\'\'\n    K5X5 = k[ : , : , None , None ] / k.sum() * np.eye(channels, dtype = np.float32)\n    config[""K5X5""] = K5X5\n    tlevels = _lap_split_n(img, scale_n)\n    tlevels = list(map(_normalize_std, tlevels))\n    out = _lap_merge(tlevels)\n    return out\n'"
