file_path,api_count,code
datasets/__init__.py,0,b''
datasets/base.py,0,"b'# -*- coding:utf-8 -*-\nimport os\nimport json\nimport numpy as np\nfrom PIL import Image\n\n\ndef load_data(data_dir, flatten=False):\n    train_dir = os.path.join(data_dir, \'train\')\n    test_dir = os.path.join(data_dir, \'test\')\n\n    meta_info = os.path.join(data_dir, \'meta.json\')\n    with open(meta_info, \'r\') as f:\n        meta = json.load(f)\n\n    train_images, train_labels = _read_images_and_labels(train_dir, flatten=flatten, **meta)\n    test_images, test_labels = _read_images_and_labels(test_dir, flatten=flatten, **meta)\n\n    return (\n        meta,\n        DataSet(train_images, train_labels),\n        DataSet(test_images, test_labels),\n    )\n\n\ndef _read_images_and_labels(dir_name, flatten, ext=\'.png\', **meta):\n    images = []\n    labels = []\n    for fn in os.listdir(dir_name):\n        if fn.endswith(ext):\n            fd = os.path.join(dir_name, fn)\n            images.append(_read_image(fd, flatten=flatten, **meta))\n            labels.append(_read_label(fd, **meta))\n    return np.array(images), np.array(labels)\n\n\ndef _read_image(filename, flatten, width, height, **extra_meta):\n    im = Image.open(filename).convert(\'L\').resize((width, height), Image.ANTIALIAS)\n\n    data = np.asarray(im)\n    if flatten:\n        return data.reshape(width * height)\n\n    return data\n\n\ndef _read_label(filename, label_choices, **extra_meta):\n    basename = os.path.basename(filename)\n    labels = basename.split(\'_\')[0]\n\n    data = []\n\n    for c in labels:\n        idx = label_choices.index(c)\n        tmp = [0] * len(label_choices)\n        tmp[idx] = 1\n        data.extend(tmp)\n\n    return data\n\n\nclass DataSet(object):\n    """"""Provide `next_batch` method, which returns the next `batch_size` examples from this data set.""""""\n\n    def __init__(self, images, labels):\n        assert images.shape[0] == labels.shape[0], (\n            \'images.shape: %s labels.shape: %s\' % (images.shape, labels.shape))\n        self._num_examples = images.shape[0]\n\n        self._images = images\n        self._labels = labels\n\n        self._epochs_completed = 0\n        self._index_in_epoch = 0\n\n    @property\n    def images(self):\n        return self._images\n\n    @property\n    def labels(self):\n        return self._labels\n\n    @property\n    def num_examples(self):\n        return self._num_examples\n\n    @property\n    def epochs_completed(self):\n        return self._epochs_completed\n\n    def next_batch(self, batch_size):\n\n        assert batch_size <= self._num_examples\n\n        if self._index_in_epoch + batch_size > self._num_examples:\n            # Finished epoch\n            self._epochs_completed += 1\n            self._index_in_epoch = 0\n\n        if self._index_in_epoch == 0:\n            # Shuffle the data\n            perm = np.arange(self._num_examples)\n            np.random.shuffle(perm)\n            self._images = self._images[perm]\n            self._labels = self._labels[perm]\n\n        # read next batch\n        start = self._index_in_epoch\n        self._index_in_epoch += batch_size\n        return self._images[start:self._index_in_epoch], self._labels[start:self._index_in_epoch]\n\n\ndef display_debug_info(meta, train_data, test_data):\n    print(\'%s Meta Info %s\' % (\'=\' * 10, \'=\' * 10))\n    for k, v in meta.items():\n        print(\'%s: %s\' % (k, v))\n    print(\'=\' * 30)\n\n    print(\'train images: %s, labels: %s\' % (train_data.images.shape, train_data.labels.shape))\n\n    print(\'test images: %s, labels: %s\' % (test_data.images.shape, test_data.labels.shape))\n\n\nif __name__ == \'__main__\':\n    import sys\n    ret1 = load_data(data_dir=sys.argv[1])\n    display_debug_info(*ret1)\n'"
datasets/gen_captcha.py,0,"b""# -*- coding:utf-8 -*-\nimport argparse\nimport json\nimport string\nimport os\nimport shutil\nimport uuid\nfrom captcha.image import ImageCaptcha\n\nimport itertools\n\nFLAGS = None\nMETA_FILENAME = 'meta.json'\n\n\ndef get_choices():\n    choices = [\n        (FLAGS.digit, map(str, range(10))),\n        (FLAGS.lower, string.ascii_lowercase),\n        (FLAGS.upper, string.ascii_uppercase),\n        ]\n    return tuple([i for is_selected, subset in choices for i in subset if is_selected])\n\n\ndef _gen_captcha(img_dir, num_per_image, n, width, height, choices):\n    if os.path.exists(img_dir):\n        shutil.rmtree(img_dir)\n    if not os.path.exists(img_dir):\n        os.makedirs(img_dir)\n\n    image = ImageCaptcha(width=width, height=height)\n\n    print('generating %s epoches of captchas in %s' % (n, img_dir))\n    for _ in range(n):\n        for i in itertools.permutations(choices, num_per_image):\n            captcha = ''.join(i)\n            fn = os.path.join(img_dir, '%s_%s.png' % (captcha, uuid.uuid4()))\n            image.write(captcha, fn)\n\n\ndef build_file_path(x):\n    return os.path.join(FLAGS.data_dir, 'char-%s-epoch-%s' % (FLAGS.npi, FLAGS.n), x)\n\n\ndef gen_dataset():\n    n_epoch = FLAGS.n\n    num_per_image = FLAGS.npi\n    test_ratio = FLAGS.t\n\n    choices = get_choices()\n\n    width = 40 + 20 * num_per_image\n    height = 100\n\n    # meta info\n    meta = {\n        'num_per_image': num_per_image,\n        'label_size': len(choices),\n        'label_choices': ''.join(choices),\n        'n_epoch': n_epoch,\n        'width': width,\n        'height': height,\n    }\n\n    print('%s choices: %s' % (len(choices), ''.join(choices) or None))\n\n    _gen_captcha(build_file_path('train'), num_per_image, n_epoch, width, height, choices=choices)\n    _gen_captcha(build_file_path('test'), num_per_image, max(1, int(n_epoch * test_ratio)), width, height, choices=choices)\n\n    meta_filename = build_file_path(META_FILENAME)\n    with open(meta_filename, 'w') as f:\n        json.dump(meta, f, indent=4)\n    print('write meta info in %s' % meta_filename)\n\n\nif __name__ == '__main__':\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '-n',\n        default=1,\n        type=int,\n        help='epoch number of character permutations.')\n\n    parser.add_argument(\n        '-t',\n        default=0.2,\n        type=float,\n        help='ratio of test dataset.')\n\n    parser.add_argument(\n        '-d', '--digit',\n        action='store_true',\n        help='use digits in dataset.')\n    parser.add_argument(\n        '-l', '--lower',\n        action='store_true',\n        help='use lowercase in dataset.')\n    parser.add_argument(\n        '-u', '--upper',\n        action='store_true',\n        help='use uppercase in dataset.')\n    parser.add_argument(\n        '--npi',\n        default=1,\n        type=int,\n        help='number of characters per image.')\n    parser.add_argument(\n        '--data_dir',\n        default='./images',\n        type=str,\n        help='where data will be saved.')\n\n    FLAGS, unparsed = parser.parse_known_args()\n\n    gen_dataset()\n"""
tensorflow_v1/cnn_1_char.py,49,"b'# -*- coding:utf-8 -*-\nimport argparse\nimport datetime\nimport sys\nimport tensorflow as tf\n\nimport datasets.base as input_data\n\nMAX_STEPS = 10000\nBATCH_SIZE = 50\n\nLOG_DIR = \'log/cnn1-run-%s\' % datetime.datetime.now().strftime(\'%Y%m%d_%H%M%S\')\n\nFLAGS = None\n\n\ndef variable_summaries(var):\n    """"""Attach a lot of summaries to a Tensor (for TensorBoard visualization).""""""\n    with tf.name_scope(\'summaries\'):\n        mean = tf.reduce_mean(var)\n        tf.summary.scalar(\'mean\', mean)\n        # with tf.name_scope(\'stddev\'):\n        #    stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n        # tf.summary.scalar(\'stddev\', stddev)\n        # tf.summary.scalar(\'max\', tf.reduce_max(var))\n        # tf.summary.scalar(\'min\', tf.reduce_min(var))\n        # tf.summary.histogram(\'histogram\', var)\n\n\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\n\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\'SAME\')\n\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                          strides=[1, 2, 2, 1], padding=\'SAME\')\n\n\ndef main(_):\n    # load data\n    meta, train_data, test_data = input_data.load_data(FLAGS.data_dir, flatten=False)\n    print(\'data loaded\')\n    print(\'train images: %s. test images: %s\' % (train_data.images.shape[0], test_data.images.shape[0]))\n\n    LABEL_SIZE = meta[\'label_size\']\n    IMAGE_HEIGHT = meta[\'height\']\n    IMAGE_WIDTH = meta[\'width\']\n    IMAGE_SIZE = IMAGE_WIDTH * IMAGE_HEIGHT\n    print(\'label_size: %s, image_size: %s\' % (LABEL_SIZE, IMAGE_SIZE))\n\n    # variable in the graph for input data\n    with tf.name_scope(\'input\'):\n        x = tf.placeholder(tf.float32, [None, IMAGE_HEIGHT, IMAGE_WIDTH])\n        y_ = tf.placeholder(tf.float32, [None, LABEL_SIZE])\n\n        # must be 4-D with shape `[batch_size, height, width, channels]`\n        x_image = tf.reshape(x, [-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n        tf.summary.image(\'input\', x_image, max_outputs=LABEL_SIZE)\n\n    # define the model\n    with tf.name_scope(\'convolution-layer-1\'):\n        W_conv1 = weight_variable([5, 5, 1, 32])\n        b_conv1 = bias_variable([32])\n\n        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n        h_pool1 = max_pool_2x2(h_conv1)\n\n    with tf.name_scope(\'convolution-layer-2\'):\n        W_conv2 = weight_variable([5, 5, 32, 64])\n        b_conv2 = bias_variable([64])\n\n        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n        h_pool2 = max_pool_2x2(h_conv2)\n\n    with tf.name_scope(\'densely-connected\'):\n        W_fc1 = weight_variable([IMAGE_WIDTH * IMAGE_HEIGHT * 4, 1024])\n        b_fc1 = bias_variable([1024])\n\n        h_pool2_flat = tf.reshape(h_pool2, [-1, IMAGE_WIDTH*IMAGE_HEIGHT*4])\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n    with tf.name_scope(\'dropout\'):\n        # To reduce overfitting, we will apply dropout before the readout layer\n        keep_prob = tf.placeholder(tf.float32)\n        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n    with tf.name_scope(\'readout\'):\n        W_fc2 = weight_variable([1024, LABEL_SIZE])\n        b_fc2 = bias_variable([LABEL_SIZE])\n\n        y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n\n    # Define loss and optimizer\n    # Returns:\n    # A 1-D `Tensor` of length `batch_size`\n    # of the same type as `logits` with the softmax cross entropy loss.\n    with tf.name_scope(\'loss\'):\n        cross_entropy = tf.reduce_mean(\n            # -tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n            tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n        variable_summaries(cross_entropy)\n\n    # forword prop\n    with tf.name_scope(\'forword-prop\'):\n        predict = tf.argmax(y_conv, axis=1)\n        expect = tf.argmax(y_, axis=1)\n\n    # evaluate accuracy\n    with tf.name_scope(\'evaluate_accuracy\'):\n        correct_prediction = tf.equal(predict, expect)\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n        variable_summaries(accuracy)\n\n    with tf.Session() as sess:\n\n        merged = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(LOG_DIR + \'/train\', sess.graph)\n        test_writer = tf.summary.FileWriter(LOG_DIR + \'/test\', sess.graph)\n\n        tf.global_variables_initializer().run()\n\n        # Train\n        for i in range(MAX_STEPS):\n            batch_xs, batch_ys = train_data.next_batch(BATCH_SIZE)\n\n            step_summary, _ = sess.run([merged, train_step], feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})\n            train_writer.add_summary(step_summary, i)\n\n            if i % 100 == 0:\n                # Test trained model\n                valid_summary, train_accuracy = sess.run([merged, accuracy], feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})\n                train_writer.add_summary(valid_summary, i)\n\n                # final check after looping\n                test_x, test_y = test_data.next_batch(2000)\n                test_summary, test_accuracy = sess.run([merged, accuracy], feed_dict={x: test_x, y_: test_y, keep_prob: 1.0})\n                test_writer.add_summary(test_summary, i)\n\n                print(\'step %s, training accuracy = %.2f%%, testing accuracy = %.2f%%\' % (i, train_accuracy * 100, test_accuracy * 100))\n\n        train_writer.close()\n        test_writer.close()\n\n        # final check after looping\n        test_x, test_y = test_data.next_batch(2000)\n        test_accuracy = accuracy.eval(feed_dict={x: test_x, y_: test_y, keep_prob: 1.0})\n        print(\'testing accuracy = %.2f%%\' % (test_accuracy * 100, ))\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--data_dir\', type=str, default=\'images/char-1-epoch-2000/\',\n                        help=\'Directory for storing input data\')\n    FLAGS, unparsed = parser.parse_known_args()\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n'"
tensorflow_v1/cnn_n_char.py,51,"b'# -*- coding:utf-8 -*-\nimport argparse\nimport datetime\nimport sys\nimport tensorflow as tf\n\nimport datasets.base as input_data\n\nMAX_STEPS = 10000\nBATCH_SIZE = 50\n\nLOG_DIR = \'log/cnn1-run-%s\' % datetime.datetime.now().strftime(\'%Y%m%d_%H%M%S\')\n\nFLAGS = None\n\n\ndef variable_summaries(var):\n    """"""Attach a lot of summaries to a Tensor (for TensorBoard visualization).""""""\n    with tf.name_scope(\'summaries\'):\n        mean = tf.reduce_mean(var)\n        tf.summary.scalar(\'mean\', mean)\n        # with tf.name_scope(\'stddev\'):\n        #    stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n        # tf.summary.scalar(\'stddev\', stddev)\n        # tf.summary.scalar(\'max\', tf.reduce_max(var))\n        # tf.summary.scalar(\'min\', tf.reduce_min(var))\n        # tf.summary.histogram(\'histogram\', var)\n\n\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\n\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\'SAME\')\n\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                          strides=[1, 2, 2, 1], padding=\'SAME\')\n\n\ndef main(_):\n    # load data\n    meta, train_data, test_data = input_data.load_data(FLAGS.data_dir, flatten=False)\n    print(\'data loaded\')\n    print(\'train images: %s. test images: %s\' % (train_data.images.shape[0], test_data.images.shape[0]))\n\n    LABEL_SIZE = meta[\'label_size\']\n    NUM_PER_IMAGE = meta[\'num_per_image\']\n    IMAGE_HEIGHT = meta[\'height\']\n    IMAGE_WIDTH = meta[\'width\']\n    IMAGE_SIZE = IMAGE_WIDTH * IMAGE_HEIGHT\n    print(\'label_size: %s, image_size: %s\' % (LABEL_SIZE, IMAGE_SIZE))\n\n    # variable in the graph for input data\n    with tf.name_scope(\'input\'):\n        x = tf.placeholder(tf.float32, [None, IMAGE_HEIGHT, IMAGE_WIDTH])\n        y_ = tf.placeholder(tf.float32, [None, NUM_PER_IMAGE * LABEL_SIZE])\n\n        # must be 4-D with shape `[batch_size, height, width, channels]`\n        x_image = tf.reshape(x, [-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n        tf.summary.image(\'input\', x_image, max_outputs=LABEL_SIZE)\n\n    # define the model\n    with tf.name_scope(\'convolution-layer-1\'):\n        W_conv1 = weight_variable([5, 5, 1, 32])\n        b_conv1 = bias_variable([32])\n\n        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n        h_pool1 = max_pool_2x2(h_conv1)\n\n    with tf.name_scope(\'convolution-layer-2\'):\n        W_conv2 = weight_variable([5, 5, 32, 64])\n        b_conv2 = bias_variable([64])\n\n        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n        h_pool2 = max_pool_2x2(h_conv2)\n\n    with tf.name_scope(\'densely-connected\'):\n        W_fc1 = weight_variable([IMAGE_WIDTH * IMAGE_HEIGHT * 4, 1024])\n        b_fc1 = bias_variable([1024])\n\n        h_pool2_flat = tf.reshape(h_pool2, [-1, IMAGE_WIDTH*IMAGE_HEIGHT*4])\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n    with tf.name_scope(\'dropout\'):\n        # To reduce overfitting, we will apply dropout before the readout layer\n        keep_prob = tf.placeholder(tf.float32)\n        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n    with tf.name_scope(\'readout\'):\n        W_fc2 = weight_variable([1024, NUM_PER_IMAGE * LABEL_SIZE])\n        b_fc2 = bias_variable([NUM_PER_IMAGE * LABEL_SIZE])\n\n        y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n\n    with tf.name_scope(\'reshape\'):\n        y_expect_reshaped = tf.reshape(y_, [-1, NUM_PER_IMAGE, LABEL_SIZE])\n        y_got_reshaped = tf.reshape(y_conv, [-1, NUM_PER_IMAGE, LABEL_SIZE])\n\n    # Define loss and optimizer\n    # Returns:\n    # A 1-D `Tensor` of length `batch_size`\n    # of the same type as `logits` with the softmax cross entropy loss.\n    with tf.name_scope(\'loss\'):\n        cross_entropy = tf.reduce_mean(\n            tf.nn.softmax_cross_entropy_with_logits(labels=y_expect_reshaped, logits=y_got_reshaped))\n        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n        variable_summaries(cross_entropy)\n\n    # forword prop\n    with tf.name_scope(\'forword-prop\'):\n        predict = tf.argmax(y_got_reshaped, axis=2)\n        expect = tf.argmax(y_expect_reshaped, axis=2)\n\n    # evaluate accuracy\n    with tf.name_scope(\'evaluate_accuracy\'):\n        correct_prediction = tf.equal(predict, expect)\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n        variable_summaries(accuracy)\n\n    with tf.Session() as sess:\n\n        merged = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(LOG_DIR + \'/train\', sess.graph)\n        test_writer = tf.summary.FileWriter(LOG_DIR + \'/test\', sess.graph)\n\n        tf.global_variables_initializer().run()\n\n        # Train\n        for i in range(MAX_STEPS):\n            batch_xs, batch_ys = train_data.next_batch(BATCH_SIZE)\n\n            step_summary, _ = sess.run([merged, train_step], feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})\n            train_writer.add_summary(step_summary, i)\n\n            if i % 100 == 0:\n                # Test trained model\n                valid_summary, train_accuracy = sess.run([merged, accuracy], feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})\n                train_writer.add_summary(valid_summary, i)\n\n                # final check after looping\n                test_x, test_y = test_data.next_batch(2000)\n                test_summary, test_accuracy = sess.run([merged, accuracy], feed_dict={x: test_x, y_: test_y, keep_prob: 1.0})\n                test_writer.add_summary(test_summary, i)\n\n                print(\'step %s, training accuracy = %.2f%%, testing accuracy = %.2f%%\' % (i, train_accuracy * 100, test_accuracy * 100))\n\n        train_writer.close()\n        test_writer.close()\n\n        # final check after looping\n        test_x, test_y = test_data.next_batch(2000)\n        test_accuracy = accuracy.eval(feed_dict={x: test_x, y_: test_y, keep_prob: 1.0})\n        print(\'testing accuracy = %.2f%%\' % (test_accuracy * 100, ))\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--data_dir\', type=str, default=\'images/char-1-epoch-2000/\',\n                        help=\'Directory for storing input data\')\n    FLAGS, unparsed = parser.parse_known_args()\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n'"
tensorflow_v1/main.py,52,"b'# -*- coding:utf-8 -*-\nimport os\nimport argparse\nimport datetime\nimport sys\nimport tensorflow as tf\n\nimport datasets.base as input_data\n\nMAX_STEPS = 10000\nBATCH_SIZE = 50\n\nLOG_DIR = \'log/cnn1-run-%s\' % datetime.datetime.now().strftime(\'%Y%m%d_%H%M%S\')\nMODEL_DIR = \'/mnt/data/prod/cnn-captcha-model/\'\nMODEL = os.path.join(MODEL_DIR, \'cnn-n.ckpt\')\n\n\nFLAGS = None\n\n\ndef variable_summaries(var):\n    """"""Attach a lot of summaries to a Tensor (for TensorBoard visualization).""""""\n    with tf.name_scope(\'summaries\'):\n        mean = tf.reduce_mean(var)\n        tf.summary.scalar(\'mean\', mean)\n        # with tf.name_scope(\'stddev\'):\n        #    stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n        # tf.summary.scalar(\'stddev\', stddev)\n        # tf.summary.scalar(\'max\', tf.reduce_max(var))\n        # tf.summary.scalar(\'min\', tf.reduce_min(var))\n        # tf.summary.histogram(\'histogram\', var)\n\n\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\n\ndef conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\'SAME\')\n\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                          strides=[1, 2, 2, 1], padding=\'SAME\')\n\n\ndef main(_):\n    # load data\n    meta, train_data, test_data = input_data.load_data(FLAGS.data_dir, flatten=False)\n    print(\'data loaded\')\n    print(\'train images: %s. test images: %s\' % (train_data.images.shape[0], test_data.images.shape[0]))\n\n    LABEL_SIZE = meta[\'label_size\']\n    NUM_PER_IMAGE = meta[\'num_per_image\']\n    IMAGE_HEIGHT = meta[\'height\']\n    IMAGE_WIDTH = meta[\'width\']\n    IMAGE_SIZE = IMAGE_WIDTH * IMAGE_HEIGHT\n    print(\'label_size: %s, image_size: %s\' % (LABEL_SIZE, IMAGE_SIZE))\n\n    # variable in the graph for input data\n    with tf.name_scope(\'input\'):\n        x = tf.placeholder(tf.float32, [None, IMAGE_HEIGHT, IMAGE_WIDTH], name=\'x\')\n        y_ = tf.placeholder(tf.float32, [None, NUM_PER_IMAGE * LABEL_SIZE], name=\'y_\')\n\n        # must be 4-D with shape `[batch_size, height, width, channels]`\n        x_image = tf.reshape(x, [-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n        tf.summary.image(\'input\', x_image, max_outputs=LABEL_SIZE)\n\n    # define the model\n    with tf.name_scope(\'convolution-layer-1\'):\n        W_conv1 = weight_variable([5, 5, 1, 32])\n        b_conv1 = bias_variable([32])\n\n        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n        h_pool1 = max_pool_2x2(h_conv1)\n\n    with tf.name_scope(\'convolution-layer-2\'):\n        W_conv2 = weight_variable([5, 5, 32, 64])\n        b_conv2 = bias_variable([64])\n\n        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n        h_pool2 = max_pool_2x2(h_conv2)\n\n    with tf.name_scope(\'densely-connected\'):\n        W_fc1 = weight_variable([IMAGE_WIDTH * IMAGE_HEIGHT * 4, 1024])\n        b_fc1 = bias_variable([1024])\n\n        h_pool2_flat = tf.reshape(h_pool2, [-1, IMAGE_WIDTH*IMAGE_HEIGHT*4])\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n    with tf.name_scope(\'dropout\'):\n        # To reduce overfitting, we will apply dropout before the readout layer\n        keep_prob = tf.placeholder(tf.float32, name=\'keep_prob\')\n        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n    with tf.name_scope(\'readout\'):\n        W_fc2 = weight_variable([1024, NUM_PER_IMAGE * LABEL_SIZE])\n        b_fc2 = bias_variable([NUM_PER_IMAGE * LABEL_SIZE])\n\n        y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n\n    with tf.name_scope(\'reshape\'):\n        y_expect_reshaped = tf.reshape(y_, [-1, NUM_PER_IMAGE, LABEL_SIZE])\n        y_got_reshaped = tf.reshape(y_conv, [-1, NUM_PER_IMAGE, LABEL_SIZE])\n\n    # Define loss and optimizer\n    # Returns:\n    # A 1-D `Tensor` of length `batch_size`\n    # of the same type as `logits` with the softmax cross entropy loss.\n    with tf.name_scope(\'loss\'):\n        cross_entropy = tf.reduce_mean(\n            tf.nn.softmax_cross_entropy_with_logits(labels=y_expect_reshaped, logits=y_got_reshaped))\n        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n        variable_summaries(cross_entropy)\n\n    # forword prop\n    with tf.name_scope(\'forword-prop\'):\n        predict = tf.argmax(y_got_reshaped, axis=2, name=\'predict\')\n        expect = tf.argmax(y_expect_reshaped, axis=2)\n\n    # evaluate accuracy\n    with tf.name_scope(\'evaluate_accuracy\'):\n        correct_prediction = tf.equal(predict, expect)\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n        variable_summaries(accuracy)\n\n    # Add ops to save and restore all the variables.\n    saver = tf.train.Saver()\n\n    with tf.Session() as sess:\n\n        merged = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(LOG_DIR + \'/train\', sess.graph)\n        test_writer = tf.summary.FileWriter(LOG_DIR + \'/test\', sess.graph)\n\n        tf.global_variables_initializer().run()\n\n        # Train\n        for i in range(MAX_STEPS):\n            batch_xs, batch_ys = train_data.next_batch(BATCH_SIZE)\n\n            step_summary, _ = sess.run([merged, train_step], feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})\n            train_writer.add_summary(step_summary, i)\n\n            if i % 100 == 0:\n                # Test trained model\n                valid_summary, train_accuracy = sess.run([merged, accuracy], feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})\n                train_writer.add_summary(valid_summary, i)\n\n                # final check after looping\n                test_x, test_y = test_data.next_batch(2000)\n                test_summary, test_accuracy = sess.run([merged, accuracy], feed_dict={x: test_x, y_: test_y, keep_prob: 1.0})\n                test_writer.add_summary(test_summary, i)\n\n                print(\'step %s, training accuracy = %.2f%%, testing accuracy = %.2f%%\' % (i, train_accuracy * 100, test_accuracy * 100))\n\n        train_writer.close()\n        test_writer.close()\n\n        # final check after looping\n        test_x, test_y = test_data.next_batch(2000)\n        test_accuracy = accuracy.eval(feed_dict={x: test_x, y_: test_y, keep_prob: 1.0})\n        print(\'testing accuracy = %.2f%%\' % (test_accuracy * 100, ))\n\n        save_path = saver.save(sess, MODEL)\n        print(\'Model saved in file: %s\' % save_path)\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--data_dir\', type=str, default=\'images/char-1-epoch-2000/\',\n                        help=\'Directory for storing input data\')\n    FLAGS, unparsed = parser.parse_known_args()\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n'"
tensorflow_v1/simple_softmax.py,15,"b""# -*- coding:utf-8 -*-\nimport argparse\nimport sys\nimport tensorflow as tf\n\nimport datasets.base as input_data\n\n\nMAX_STEPS = 10000\nBATCH_SIZE = 1000\n\nFLAGS = None\n\n\ndef main(_):\n    # load data\n    meta, train_data, test_data = input_data.load_data(FLAGS.data_dir, flatten=True)\n    print('data loaded')\n    print('train images: %s. test images: %s' % (train_data.images.shape[0], test_data.images.shape[0]))\n\n    LABEL_SIZE = meta['label_size']\n    IMAGE_SIZE = meta['width'] * meta['height']\n    print('label_size: %s, image_size: %s' % (LABEL_SIZE, IMAGE_SIZE))\n\n    # variable in the graph for input data\n    x = tf.placeholder(tf.float32, [None, IMAGE_SIZE])\n    y_ = tf.placeholder(tf.float32, [None, LABEL_SIZE])\n\n    # define the model\n    W = tf.Variable(tf.zeros([IMAGE_SIZE, LABEL_SIZE]))\n    b = tf.Variable(tf.zeros([LABEL_SIZE]))\n    y = tf.matmul(x, W) + b\n\n    # Define loss and optimizer\n    diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n    cross_entropy = tf.reduce_mean(diff)\n    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\n    # forword prop\n    predict = tf.argmax(y, axis=1)\n    expect = tf.argmax(y_, axis=1)\n\n    # evaluate accuracy\n    correct_prediction = tf.equal(predict, expect)\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    with tf.Session() as sess:\n        tf.global_variables_initializer().run()\n\n        # Train\n        for i in range(MAX_STEPS):\n            batch_xs, batch_ys = train_data.next_batch(BATCH_SIZE)\n            sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n\n            if i % 100 == 0:\n                # Test trained model\n                r = sess.run(accuracy, feed_dict={x: test_data.images, y_: test_data.labels})\n                print('step = %s, accuracy = %.2f%%' % (i, r * 100))\n\n        # final check after looping\n        r_test = sess.run(accuracy, feed_dict={x: test_data.images, y_: test_data.labels})\n        print('testing accuracy = %.2f%%' % (r_test * 100, ))\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data_dir', type=str, default='images/char-1-epoch-2000/',\n                        help='Directory for storing input data')\n    FLAGS, unparsed = parser.parse_known_args()\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n"""
tensorflow_v1/softmax_with_log.py,36,"b'# -*- coding:utf-8 -*-\nimport argparse\nimport datetime\nimport sys\nimport tensorflow as tf\n\nimport datasets.base as input_data\n\n\nMAX_STEPS = 10000\nBATCH_SIZE = 100\n\nLOG_DIR = \'log/regression-run-%s\' % datetime.datetime.now().strftime(\'%Y%m%d_%H%M%S\')\n\nFLAGS = None\n\n\ndef variable_summaries(var):\n    """"""Attach a lot of summaries to a Tensor (for TensorBoard visualization).""""""\n    with tf.name_scope(\'summaries\'):\n        mean = tf.reduce_mean(var)\n        tf.summary.scalar(\'mean\', mean)\n        with tf.name_scope(\'stddev\'):\n            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n        tf.summary.scalar(\'stddev\', stddev)\n        tf.summary.scalar(\'max\', tf.reduce_max(var))\n        tf.summary.scalar(\'min\', tf.reduce_min(var))\n        tf.summary.histogram(\'histogram\', var)\n\n\ndef main(_):\n    # load data\n    meta, train_data, test_data = input_data.load_data(FLAGS.data_dir, flatten=True)\n    print(\'data loaded. train images: %s. test images: %s\' % (train_data.images.shape[0], test_data.images.shape[0]))\n\n    LABEL_SIZE = meta[\'label_size\']\n    IMAGE_WIDTH = meta[\'width\']\n    IMAGE_HEIGHT = meta[\'height\']\n    IMAGE_SIZE = IMAGE_WIDTH * IMAGE_HEIGHT\n    print(\'label_size: %s, image_size: %s\' % (LABEL_SIZE, IMAGE_SIZE))\n\n    # variable in the graph for input data\n    with tf.name_scope(\'input\'):\n        x = tf.placeholder(tf.float32, [None, IMAGE_SIZE])\n        y_ = tf.placeholder(tf.float32, [None, LABEL_SIZE])\n        variable_summaries(x)\n        variable_summaries(y_)\n\n        # must be 4-D with shape `[batch_size, height, width, channels]`\n        images_shaped_input = tf.reshape(x, [-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n        tf.summary.image(\'input\', images_shaped_input, max_outputs=LABEL_SIZE*2)\n\n    # define the model\n    # Adding a name scope ensures logical grouping of the layers in the graph.\n    with tf.name_scope(\'linear_model\'):\n        with tf.name_scope(\'W\'):\n            W = tf.Variable(tf.zeros([IMAGE_SIZE, LABEL_SIZE]))\n            variable_summaries(W)\n        with tf.name_scope(\'b\'):\n            b = tf.Variable(tf.zeros([LABEL_SIZE]))\n            variable_summaries(b)\n        with tf.name_scope(\'y\'):\n            y = tf.matmul(x, W) + b\n            tf.summary.histogram(\'y\', y)\n\n    # Define loss and optimizer\n    # Returns:\n    # A 1-D `Tensor` of length `batch_size`\n    # of the same type as `logits` with the softmax cross entropy loss.\n    with tf.name_scope(\'loss\'):\n        diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n        cross_entropy = tf.reduce_mean(diff)\n        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n        variable_summaries(diff)\n\n    # forword prop\n    predict = tf.argmax(y, axis=1)\n    expect = tf.argmax(y_, axis=1)\n\n    # evaluate accuracy\n    with tf.name_scope(\'evaluate_accuracy\'):\n        correct_prediction = tf.equal(predict, expect)\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n        variable_summaries(accuracy)\n\n    with tf.Session() as sess:\n\n        merged = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(LOG_DIR + \'/train\', sess.graph)\n\n        tf.global_variables_initializer().run()\n\n        # Train\n        for i in range(MAX_STEPS):\n            batch_xs, batch_ys = train_data.next_batch(BATCH_SIZE)\n            train_summary, _ = sess.run([merged, train_step], feed_dict={x: batch_xs, y_: batch_ys})\n            train_writer.add_summary(train_summary, i)\n\n            if i % 100 == 0:\n                # Test trained model\n                test_summary, r = sess.run([merged, accuracy], feed_dict={x: test_data.images, y_: test_data.labels})\n                train_writer.add_summary(test_summary, i)\n                print(\'step = %s, accuracy = %.2f%%\' % (i, r * 100))\n\n        train_writer.close()\n\n        # final check after looping\n        test_summary, r_test = sess.run([merged, accuracy], feed_dict={x: test_data.images, y_: test_data.labels})\n        train_writer.add_summary(test_summary, i)\n        print(\'testing accuracy = %.2f%%\' % (r_test * 100, ))\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--data_dir\', type=str, default=\'images/char-1-epoch-2000/\',\n                        help=\'Directory for storing input data\')\n    FLAGS, unparsed = parser.parse_known_args()\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n'"
