file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport re\n\nimport setuptools\n\nwith open(""README.md"", ""r"", encoding=\'utf-8\') as fh:\n    long_description = fh.read()\n\n\nwith open(\'deepdanbooru/__main__.py\', encoding=\'utf-8\') as f:\n    version = re.search(\'__version__ = \\\'([^\\\']+)\\\'\', f.read()).group(1)  # type: ignore\n\n\ninstall_requires = [\n    \'Click>=7.0\',\n    \'numpy>=1.16.2\',\n    \'scikit-image>=0.15.0\',\n    \'requests>=2.22.0\',\n    \'six>=1.13.0\',\n]\ntensorflow_pkg = \'tensorflow>=2.1.0\'\n\nsetuptools.setup(\n    name=""deepdanbooru"",\n    version=version,\n    author=""Kichang Kim"",\n    author_email=""admin@kanotype.net"",\n    description=""DeepDanbooru is AI based multi-label girl image classification system, ""\n    ""implemented by using TensorFlow."",\n    long_description=long_description,\n    long_description_content_type=""text/markdown"",\n    url=""https://github.com/KichangKim/DeepDanbooru"",\n    packages=setuptools.find_packages(),\n    classifiers=[\n        ""Programming Language :: Python :: 3"",\n        ""License :: OSI Approved :: MIT License"",\n        ""Operating System :: OS Independent"",\n    ],\n    python_requires=\'>=3.6\',\n    install_requires=install_requires,\n    extras_require={\n        \'tensorflow\': [tensorflow_pkg],\n        \'test\': [\'pytest\', \'flake8\', \'mypy\']\n    },\n    entry_points={\n        ""console_scripts"": [\n            ""deepdanbooru=deepdanbooru.__main__:main"",\n        ]\n    },\n)\n'"
deepdanbooru/__init__.py,0,b'import deepdanbooru.commands\nimport deepdanbooru.data\nimport deepdanbooru.extra\nimport deepdanbooru.image\nimport deepdanbooru.io\nimport deepdanbooru.model\nimport deepdanbooru.project\nimport deepdanbooru.train\n'
deepdanbooru/__main__.py,0,"b""import sys\n\nimport click\n\nimport deepdanbooru as dd\n\n__version__ = '1.0.0'\n\n\n@click.version_option(prog_name='DeepDanbooru', version=__version__)\n@click.group()\ndef main():\n    '''\n    AI based multi-label girl image classification system, implemented by using TensorFlow.\n    '''\n    pass\n\n\n@main.command('create-project')\n@click.argument('project_path', type=click.Path(exists=False, resolve_path=True, file_okay=False, dir_okay=True))\ndef create_project(project_path):\n    dd.commands.create_project(project_path)\n\n\n@main.command('download-tags')\n@click.option('--limit', default=10000, help='Limit for each category tag count.')\n@click.option('--minimum-post-count', default=500, help='Minimum post count for tag.')\n@click.option('--overwrite', help='Overwrite tags if exists.', is_flag=True)\n@click.argument('path', type=click.Path(exists=False, resolve_path=True, file_okay=False, dir_okay=True))\ndef download_tags(path, limit, minimum_post_count, overwrite):\n    dd.commands.download_tags(path, limit, minimum_post_count, overwrite)\n\n\n@main.command('make-training-database')\n@click.argument('source_path', type=click.Path(exists=True, resolve_path=True, file_okay=True, dir_okay=False), nargs=1, required=True)\n@click.argument('output_path', type=click.Path(exists=False, resolve_path=True, file_okay=True, dir_okay=False), nargs=1, required=True)\n@click.option('--start-id', default=1, help='Start id.', )\n@click.option('--end-id', default=sys.maxsize, help='End id.')\n@click.option('--use-deleted', help='Use deleted posts.', is_flag=True)\n@click.option('--chunk-size', default=5000000, help='Chunk size for internal processing.')\n@click.option('--overwrite', help='Overwrite tags if exists.', is_flag=True)\n@click.option('--vacuum', help='Execute VACUUM command after making database.', is_flag=True)\ndef make_training_database(source_path, output_path, start_id, end_id, use_deleted, chunk_size, overwrite, vacuum):\n    dd.commands.make_training_database(source_path, output_path, start_id, end_id,\n                                       use_deleted, chunk_size, overwrite, vacuum)\n\n\n@main.command('train-project')\n@click.argument('project_path', type=click.Path(exists=True, resolve_path=True, file_okay=False, dir_okay=True))\ndef train_project(project_path):\n    dd.commands.train_project(project_path)\n\n\n@main.command('evaluate-project', help='Evaluate the project. If the target path is folder, it evaulates all images recursively.')\n@click.argument('project_path', type=click.Path(exists=True, resolve_path=True, file_okay=False, dir_okay=True))\n@click.argument('target_path', type=click.Path(exists=True, resolve_path=True, file_okay=True, dir_okay=True))\n@click.option('--threshold', help='Threshold for tag estimation.', default=0.5)\ndef evaluate_project(project_path, target_path, threshold):\n    dd.commands.evaluate_project(project_path, target_path, threshold)\n\n\n@main.command('grad-cam', help='Experimental feature. Calculate activation map using Grad-CAM.')\n@click.argument('project_path', type=click.Path(exists=True, resolve_path=True, file_okay=False, dir_okay=True))\n@click.argument('target_path', type=click.Path(exists=True, resolve_path=True, file_okay=True, dir_okay=True))\n@click.argument('output_path', type=click.Path(resolve_path=True, file_okay=False, dir_okay=True), default='.')\n@click.option('--threshold', help='Threshold for tag estimation.', default=0.5)\ndef grad_cam(project_path, target_path, output_path, threshold):\n    dd.commands.grad_cam(project_path, target_path, output_path, threshold)\n\n\n@main.command('evaluate', help='Evaluate model by estimating image tag.')\n@click.argument('target_paths', nargs=-1, type=click.Path(exists=True, resolve_path=True, file_okay=True, dir_okay=True))\n@click.option('--project-path', type=click.Path(exists=True, resolve_path=True, file_okay=False, dir_okay=True),\n              help='Project path. If you want to use specific model and tags, use --model-path and --tags-path options.')\n@click.option('--model-path', type=click.Path(exists=True, resolve_path=True, file_okay=True, dir_okay=False))\n@click.option('--tags-path', type=click.Path(exists=True, resolve_path=True, file_okay=True, dir_okay=False))\n@click.option('--threshold', default=0.5)\n@click.option('--allow-gpu', default=False, is_flag=True)\n@click.option('--compile/--no-compile', 'compile_model', default=False)\n@click.option('--allow-folder', default=False, is_flag=True, help='If this option is enabled, TARGET_PATHS can be folder path and all images (using --folder-filters) in that folder is estimated recursively. If there are file and folder which has same name, the file is skipped and only folder is used.')\n@click.option('--folder-filters', default='*.[Pp][Nn][Gg],*.[Jj][Pp][Gg],*.[Jj][Pp][Ee][Gg],*.[Gg][Ii][Ff]', help='Glob pattern for searching image files in folder. You can specify multiple patterns by separating comma. This is used when --allow-folder is enabled. Default:*.[Pp][Nn][Gg],*.[Jj][Pp][Gg],*.[Jj][Pp][Ee][Gg],*.[Gg][Ii][Ff]')\n@click.option('--verbose', default=False, is_flag=True)\ndef evaluate(target_paths, project_path, model_path, tags_path, threshold, allow_gpu, compile_model, allow_folder, folder_filters, verbose):\n    dd.commands.evaluate(target_paths, project_path, model_path, tags_path, threshold, allow_gpu, compile_model, allow_folder, folder_filters, verbose)\n\n\nif __name__ == '__main__':\n    main()\n"""
deepdanbooru/gradcam.py,10,"b""import tensorflow as tf\nimport numpy as np\n\n# gpus = tf.config.experimental.list_physical_devices('GPU')\n\n# if gpus:\n#     try:\n#         for gpu in gpus:\n#             tf.config.experimental.set_memory_growth(gpu, True)\n#     except RuntimeError as e:\n#         print(e)\n\n\ndef grad(y, x):\n    V = tf.keras.layers.Lambda(lambda z: tf.gradients(\n        z[0], z[1]), output_shape=[1])([y, x])\n    return V\n\n\ndef grad_cam_test(model, x, some_variable):\n    fixed_input = model.inputs\n    fixed_output = tf.keras.layers.Lambda(lambda z: tf.keras.backend.gradients(\n        z[0], z[1]), output_shape=[2])([model.inputs[0], model.outputs[0]])\n\n    grad_model = tf.keras.Model(inputs=fixed_input, outputs=fixed_output)\n\n    return grad_model.predict(x)\n\n\ndef run_test():\n    # Generate sample model\n    x = tf.keras.Input(shape=(2))\n    y = tf.keras.layers.Dense(2)(x)\n    model = tf.keras.Model(inputs=x, outputs=y)\n    target = np.array([[1.0, 2.0]], dtype=np.float32)\n\n    # Calculate gradient using numpy array\n    input_numpy = np.array([[0.0, 0.0]])\n    grad_output_numpy = grad_cam_test(model, input_numpy, target)\n    print(f'numpy: {grad_output_numpy}')\n\n    # Calculate gradient using tf.Variable\n    input_variable = tf.constant([[0.0, 0.0]])\n    grad_output_variable = grad_cam_test(model, input_variable, target)\n    print(f'variable: {grad_output_variable}')\n\n\nrun_test()\n"""
tests/test_main.py,0,"b""#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport importlib\nfrom unittest import mock\n\nimport numpy\nimport pytest\nimport six\nfrom click.testing import CliRunner\nfrom PIL import Image\n\n\ndef test_import():\n    import deepdanbooru\n\n\n@pytest.mark.parametrize('func_name', ['main', 'evaluate'])\ndef test_help(func_name):\n    mod = importlib.import_module('deepdanbooru.__main__')\n    runner = CliRunner()\n    result = runner.invoke(getattr(mod, func_name), ['--help'])\n    assert result.exit_code == 0\n    assert result.output\n\n\n@pytest.fixture\ndef packages():\n    with open('requirements.txt') as f:\n        return f.read().splitlines()\n\n\ndef test_package_setup(packages):\n    import setuptools\n    with mock.patch('setuptools.setup'):\n        import setup\n        setup_pkgs = setup.install_requires\n        tensorflow_pkg = setup.tensorflow_pkg\n    assert setup_pkgs == list(\n        filter(lambda x: not x.startswith('tensorflow'), packages))\n    assert list(\n        filter(lambda x: x.startswith('tensorflow'), packages)\n    ) == [tensorflow_pkg]\n\n\ndef test_readme_pkg(packages):\n    with open('README.md') as f:\n        text = f.read()\n    line_start = 'Following packages are need to be installed.'\n    line_end = '\\n\\n'\n    pkg_text = text.split(line_start)[1].rsplit(line_end)[0].strip()\n    readme_pkgs = list(map(lambda x: x.split(' ', 1)[1], pkg_text.splitlines()))\n\n    assert list(\n        sorted(filter(lambda x: not x.startswith('tensorflow'), readme_pkgs))\n    ) == list(\n        sorted(filter(lambda x: not x.startswith('tensorflow'), packages))\n    )\n\n    assert list(\n        filter(lambda x: x.startswith('tensorflow'), packages)\n    ) == list(\n        filter(lambda x: x.startswith('tensorflow'), readme_pkgs)\n    )\n\n\n@pytest.mark.parametrize('use_bytes_io', [True, False])\ndef test_load_image_for_evaluate(tmp_path, use_bytes_io):\n    image_path = tmp_path / 'test.jpg'\n    image = Image.new('RGB', (300, 300), color='red')\n    image.save(image_path)\n    from deepdanbooru.data import load_image_for_evaluate\n    if not use_bytes_io:\n        res = load_image_for_evaluate(image_path.as_posix(), 299, 299)\n    else:\n        with open(image_path.as_posix(), 'rb') as f:\n            image_input = six.BytesIO(f.read())\n        res = load_image_for_evaluate(image_input, 299, 299)\n    assert isinstance(res, numpy.ndarray)\n    assert res.shape == (299, 299, 3)\n"""
deepdanbooru/commands/__init__.py,0,"b'from .create_project import create_project\r\nfrom .download_tags import download_tags\r\nfrom .make_training_database import make_training_database\r\nfrom .train_project import train_project\r\nfrom .evaluate_project import evaluate_project\r\nfrom .grad_cam import grad_cam\r\nfrom .evaluate import evaluate, evaluate_image\r\n'"
deepdanbooru/commands/create_project.py,0,"b'import os\n\nimport deepdanbooru as dd\n\n\ndef create_project(project_path):\n    """"""\n    Create new project with default parameters.\n    """"""\n    dd.io.try_create_directory(project_path)\n    project_context_path = os.path.join(project_path, \'project.json\')\n    dd.io.serialize_as_json(\n        dd.project.DEFAULT_PROJECT_CONTEXT, project_context_path)\n\n    print(f\'New project was successfully created. ({project_path})\')\n'"
deepdanbooru/commands/download_tags.py,0,"b'import os\r\nimport time\r\n\r\nimport requests\r\n\r\nimport deepdanbooru as dd\r\n\r\n\r\ndef download_category_tags(category, minimum_post_count, limit, page_size=1000, order=\'count\'):\r\n    category_to_index = {\r\n        \'general\': 0,\r\n        \'artist\': 1,\r\n        \'copyright\': 3,\r\n        \'character\': 4\r\n    }\r\n\r\n    gold_only_tags = [\'loli\', \'shota\', \'toddlercon\']\r\n\r\n    if category not in category_to_index:\r\n        raise Exception(f\'Not supported category : {category}\')\r\n\r\n    category_index = category_to_index[category]\r\n\r\n    parameters = {\r\n        \'limit\': page_size,\r\n        \'page\': 1,\r\n        \'search[order]\': order,\r\n        \'search[category]\': category_index\r\n    }\r\n\r\n    request_url = \'https://danbooru.donmai.us/tags.json\'\r\n\r\n    tags = set()\r\n\r\n    while True:\r\n        response = requests.get(request_url, params=parameters)\r\n        response_json = response.json()\r\n\r\n        response_tags = [tag_json[\'name\']\r\n                         for tag_json in response_json if tag_json[\'post_count\'] >= minimum_post_count]\r\n\r\n        if not response_tags:\r\n            break\r\n\r\n        is_full = False\r\n\r\n        for tag in response_tags:\r\n            if tag in gold_only_tags:\r\n                continue\r\n\r\n            tags.add(tag)\r\n\r\n            if len(tags) >= limit:\r\n                is_full = True\r\n                break\r\n\r\n        if is_full:\r\n            break\r\n        else:\r\n            parameters[\'page\'] += 1\r\n\r\n    return tags\r\n\r\n\r\ndef download_tags(project_path, limit, minimum_post_count, is_overwrite):\r\n    print(\r\n        f\'Start downloading tags ... (limit:{limit}, minimum_post_count:{minimum_post_count})\')\r\n\r\n    log = {\r\n        \'date\': time.strftime(""%Y/%m/%d %H:%M:%S""),\r\n        \'limit\': limit,\r\n        \'minimum_post_count\': minimum_post_count\r\n    }\r\n\r\n    system_tags = [\r\n        \'rating:safe\',\r\n        \'rating:questionable\',\r\n        \'rating:explicit\',\r\n        # \'score:very_bad\',\r\n        # \'score:bad\',\r\n        # \'score:average\',\r\n        # \'score:good\',\r\n        # \'score:very_good\',\r\n    ]\r\n\r\n    category_definitions = [\r\n        {\r\n            \'category_name\': \'General\',\r\n            \'category\': \'general\',\r\n            \'path\': os.path.join(project_path, \'tags-general.txt\'),\r\n        },\r\n        # {\r\n        #    \'category_name\': \'Artist\',\r\n        #    \'category\': \'artist\',\r\n        #    \'path\': os.path.join(path, \'tags-artist.txt\'),\r\n        # },\r\n        # {\r\n        #    \'category_name\': \'Copyright\',\r\n        #    \'category\': \'copyright\',\r\n        #    \'path\': os.path.join(path, \'tags-copyright.txt\'),\r\n        # },\r\n        {\r\n            \'category_name\': \'Character\',\r\n            \'category\': \'character\',\r\n            \'path\': os.path.join(project_path, \'tags-character.txt\'),\r\n        },\r\n    ]\r\n\r\n    all_tags_path = os.path.join(project_path, \'tags.txt\')\r\n\r\n    if not is_overwrite and os.path.exists(all_tags_path):\r\n        raise Exception(f\'Tags file is already exists : {all_tags_path}\')\r\n\r\n    dd.io.try_create_directory(os.path.dirname(all_tags_path))\r\n    dd.io.serialize_as_json(\r\n        log, os.path.join(project_path, \'tags_log.json\'))\r\n\r\n    categories_for_web = []\r\n    categories_for_web_path = os.path.join(project_path, \'categories.json\')\r\n    tag_start_index = 0\r\n\r\n    total_tags_count = 0\r\n\r\n    with open(all_tags_path, \'w\') as all_tags_stream:\r\n        for category_definition in category_definitions:\r\n            category = category_definition[\'category\']\r\n            category_tags_path = category_definition[\'path\']\r\n\r\n            print(f\'{category} tags are downloading ...\')\r\n            tags = download_category_tags(category, minimum_post_count, limit)\r\n\r\n            tags = dd.extra.natural_sorted(tags)\r\n            tag_count = len(tags)\r\n            if tag_count == 0:\r\n                print(f\'{category} tags are not exists.\')\r\n                continue\r\n            else:\r\n                print(f\'{tag_count} tags are downloaded.\')\r\n\r\n            with open(category_tags_path, \'w\') as category_tags_stream:\r\n                for tag in tags:\r\n                    category_tags_stream.write(f\'{tag}\\n\')\r\n                    all_tags_stream.write(f\'{tag}\\n\')\r\n\r\n            categories_for_web.append(\r\n                {\'name\': category_definition[\'category_name\'], \'start_index\': tag_start_index})\r\n\r\n            tag_start_index += len(tags)\r\n            total_tags_count += tag_count\r\n\r\n        for tag in system_tags:\r\n            all_tags_stream.write(f\'{tag}\\n\')\r\n\r\n        categories_for_web.append(\r\n            {\'name\': \'System\', \'start_index\': total_tags_count}\r\n        )\r\n\r\n    dd.io.serialize_as_json(categories_for_web, categories_for_web_path)\r\n\r\n    print(f\'Total {total_tags_count} tags are downloaded.\')\r\n\r\n    print(\'All processes are complete.\')\r\n'"
deepdanbooru/commands/evaluate.py,1,"b""import os\r\nfrom typing import Any, Iterable, List, Tuple, Union\r\n\r\nimport six\r\nimport tensorflow as tf\r\n\r\nimport deepdanbooru as dd\r\n\r\n\r\ndef evaluate_image(\r\n    image_input: Union[str, six.BytesIO], model: Any, tags: List[str], threshold: float\r\n) -> Iterable[Tuple[str, float]]:\r\n    width = model.input_shape[2]\r\n    height = model.input_shape[1]\r\n\r\n    image = dd.data.load_image_for_evaluate(\r\n        image_input, width=width, height=height)\r\n\r\n    image_shape = image.shape\r\n    image = image.reshape(\r\n        (1, image_shape[0], image_shape[1], image_shape[2]))\r\n    y = model.predict(image)[0]\r\n\r\n    result_dict = {}\r\n\r\n    for i, tag in enumerate(tags):\r\n        result_dict[tag] = y[i]\r\n\r\n    for tag in tags:\r\n        if result_dict[tag] >= threshold:\r\n            yield tag, result_dict[tag]\r\n\r\n\r\ndef evaluate(target_paths, project_path, model_path, tags_path, threshold, allow_gpu, compile_model, allow_folder, folder_filters, verbose):\r\n    if not allow_gpu:\r\n        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n\r\n    if not model_path and not project_path:\r\n        raise Exception('You must provide project path or model path.')\r\n\r\n    if not tags_path and not project_path:\r\n        raise Exception('You must provide project path or tags path.')\r\n\r\n    target_image_paths = []\r\n\r\n    for target_path in target_paths:\r\n        if allow_folder and not os.path.isfile(target_path):\r\n            target_image_paths.extend(dd.io.get_image_file_paths_recursive(target_path, folder_filters))\r\n        else:\r\n            target_image_paths.append(target_path)\r\n\r\n    target_image_paths = dd.extra.natural_sorted(target_image_paths)\r\n\r\n    if model_path:\r\n        if verbose:\r\n            print(f'Loading model from {model_path} ...')\r\n        model = tf.keras.models.load_model(model_path, compile=compile_model)\r\n    else:\r\n        if verbose:\r\n            print(f'Loading model from project {project_path} ...')\r\n        model = dd.project.load_model_from_project(project_path, compile_model=compile_model)\r\n\r\n    if tags_path:\r\n        if verbose:\r\n            print(f'Loading tags from {tags_path} ...')\r\n        tags = dd.data.load_tags(tags_path)\r\n    else:\r\n        if verbose:\r\n            print(f'Loading tags from project {project_path} ...')\r\n        tags = dd.project.load_tags_from_project(project_path)\r\n\r\n    for image_path in target_image_paths:\r\n        print(f'Tags of {image_path}:')\r\n        for tag, score in evaluate_image(image_path, model, tags, threshold):\r\n            print(f'({score:05.3f}) {tag}')\r\n\r\n        print()\r\n"""
deepdanbooru/commands/evaluate_project.py,0,"b""import os\n\nimport deepdanbooru as dd\n\n\ndef evaluate_project(project_path, target_path, threshold):\n    if not os.path.exists(target_path):\n        raise Exception(f'Target path {target_path} is not exists.')\n\n    if os.path.isfile(target_path):\n        taget_image_paths = [target_path]\n\n    else:\n        patterns = [\n            '*.[Pp][Nn][Gg]',\n            '*.[Jj][Pp][Gg]',\n            '*.[Jj][Pp][Ee][Gg]',\n            '*.[Gg][Ii][Ff]'\n        ]\n\n        taget_image_paths = dd.io.get_file_paths_in_directory(\n            target_path, patterns)\n\n        taget_image_paths = dd.extra.natural_sorted(taget_image_paths)\n\n    project_context, model, tags = dd.project.load_project(project_path)\n\n    width = project_context['image_width']\n    height = project_context['image_height']\n\n    for image_path in taget_image_paths:\n        image = dd.data.load_image_for_evaluate(\n            image_path, width=width, height=height)\n\n        image_shape = image.shape\n        # image = image.astype(np.float16)\n        image = image.reshape(\n            (1, image_shape[0], image_shape[1], image_shape[2]))\n        y = model.predict(image)[0]\n\n        result_dict = {}\n\n        for i, tag in enumerate(tags):\n            result_dict[tag] = y[i]\n\n        print(f'Tags of {image_path}:')\n        for tag in tags:\n            if result_dict[tag] >= threshold:\n                print(f'({result_dict[tag]:05.3f}) {tag}')\n\n        print()\n"""
deepdanbooru/commands/grad_cam.py,4,"b""import os\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom PIL import Image\r\nimport deepdanbooru as dd\r\nfrom scipy import ndimage\r\n\r\n\r\n@tf.function\r\ndef get_gradient(model, x, output_mask):\r\n    with tf.GradientTape() as tape:\r\n        output = model(x)\r\n        gradcam_loss = tf.reduce_sum(tf.multiply(output_mask, output))\r\n\r\n    return tape.gradient(gradcam_loss, x)\r\n\r\n\r\ndef norm_clip_grads(grads):\r\n    upper_quantile = np.quantile(grads, 0.99)\r\n    lower_quantile = np.quantile(grads, 0.01)\r\n    clipped_grads = np.abs(np.clip(grads, lower_quantile, upper_quantile))\r\n\r\n    return clipped_grads / np.max(clipped_grads)\r\n\r\n\r\ndef filter_grads(grads):\r\n    return ndimage.median_filter(grads, 10)\r\n\r\n\r\ndef to_onehot(length, index):\r\n    value = np.zeros(shape=(1, length), dtype=np.float32)\r\n    value[0, index] = 1.0\r\n    return value\r\n\r\n\r\ndef grad_cam(project_path, target_path, output_path, threshold):\r\n    # os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n\r\n    if not os.path.exists(target_path):\r\n        raise Exception(f'Target path {target_path} is not exists.')\r\n\r\n    if os.path.isfile(target_path):\r\n        taget_image_paths = [target_path]\r\n    else:\r\n        patterns = [\r\n            '*.[Pp][Nn][Gg]',\r\n            '*.[Jj][Pp][Gg]',\r\n            '*.[Jj][Pp][Ee][Gg]',\r\n            '*.[Gg][Ii][Ff]'\r\n        ]\r\n\r\n        taget_image_paths = dd.io.get_file_paths_in_directory(\r\n            target_path, patterns)\r\n\r\n        taget_image_paths = dd.extra.natural_sorted(taget_image_paths)\r\n\r\n    model = dd.project.load_model_from_project(project_path)\r\n    tags = dd.project.load_tags_from_project(project_path)\r\n    width = model.input_shape[2]\r\n    height = model.input_shape[1]\r\n\r\n    dd.io.try_create_directory(output_path)\r\n\r\n    for image_path in taget_image_paths:\r\n        image = dd.data.load_image_for_evaluate(\r\n            image_path, width=width, height=height)\r\n        image_name = os.path.splitext(os.path.basename(image_path))[0]\r\n\r\n        image_folder = os.path.join(output_path, image_name)\r\n        dd.io.try_create_directory(image_folder)\r\n\r\n        Image.fromarray(np.uint8(\r\n            image * 255.0)).save(os.path.join(image_folder, f'input.png'))\r\n        image_for_result = image\r\n        image_shape = image.shape\r\n        y = model.predict(image.reshape(\r\n            (1, image_shape[0], image_shape[1], image_shape[2])))[0]\r\n\r\n        result_dict = {}\r\n\r\n        estimated_tags = []\r\n\r\n        for i, tag in enumerate(tags):\r\n            result_dict[tag] = y[i]\r\n\r\n            if y[i] >= threshold:\r\n                estimated_tags.append((i, tag))\r\n\r\n        print(f'Tags of {image_path}:')\r\n\r\n        for tag in tags:\r\n            if result_dict[tag] >= threshold:\r\n                print(f'({result_dict[tag]:05.3f}) {tag}')\r\n\r\n        image = image.astype(np.float32)\r\n\r\n        for estimated_tag in estimated_tags:\r\n            print(f'Calculating grad-cam ... ({estimated_tag[1]})')\r\n            grads = get_gradient(model, tf.Variable(\r\n                [image]), to_onehot(len(tags), estimated_tag[0]))[0]\r\n            print('Normalizing gradients ...')\r\n            grads = norm_clip_grads(grads)\r\n            print('Filtering gradients ...')\r\n            grads = filter_grads(grads)\r\n            Image.fromarray(np.uint8(grads * 255.0)\r\n                            ).save(os.path.join(image_folder, f'result-{estimated_tag[1]}.png'.replace(':', '_').replace('/', '_')))\r\n            mask_array = np.stack([np.max(\r\n                grads, axis=-1)]*3, axis=2)\r\n            Image.fromarray(np.uint8(np.multiply(image_for_result, mask_array)\r\n                                     * 255.0)).save(os.path.join(image_folder, f'result-{estimated_tag[1]}-masked.png'.replace(':', '_').replace('/', '_')))\r\n"""
deepdanbooru/commands/make_training_database.py,0,"b'import os\nimport sqlite3\n\n\ndef make_training_database(source_path, output_path, start_id, end_id,\n                           use_deleted, chunk_size, overwrite, vacuum):\n    \'\'\'\n    Make sqlite database for training. Also add system tags.\n    \'\'\'\n    if source_path == output_path:\n        raise Exception(\'Source path and output path is equal.\')\n\n    if os.path.exists(output_path):\n        if overwrite:\n            os.remove(output_path)\n        else:\n            raise Exception(f\'{output_path} is already exists.\')\n\n    source_connection = sqlite3.connect(source_path)\n    source_connection.row_factory = sqlite3.Row\n    source_cursor = source_connection.cursor()\n\n    output_connection = sqlite3.connect(output_path)\n    output_connection.row_factory = sqlite3.Row\n    output_cursor = output_connection.cursor()\n\n    table_name = \'posts\'\n    id_column_name = \'id\'\n    md5_column_name = \'md5\'\n    extension_column_name = \'file_ext\'\n    tags_column_name = \'tag_string\'\n    tag_count_general_column_name = \'tag_count_general\'\n    rating_column_name = \'rating\'\n    score_column_name = \'score\'\n    deleted_column_name = \'is_deleted\'\n\n    # Create output table\n    print(\'Creating table ...\')\n    output_cursor.execute(f""""""CREATE TABLE {table_name} (\n        {id_column_name} INTEGER NOT NULL PRIMARY KEY,\n        {md5_column_name} TEXT,\n        {extension_column_name} TEXT,\n        {tags_column_name} TEXT,\n        {tag_count_general_column_name} INTEGER )"""""")\n    output_connection.commit()\n    print(\'Creating table is complete.\')\n\n    current_start_id = start_id\n\n    while True:\n        print(\n            f\'Fetching source rows ... ({current_start_id}~)\')\n        source_cursor.execute(\n            f""""""SELECT\n                {id_column_name},{md5_column_name},{extension_column_name},{tags_column_name},{tag_count_general_column_name},{rating_column_name},{score_column_name},{deleted_column_name}\n            FROM {table_name} WHERE ({id_column_name} >= ?) ORDER BY {id_column_name} ASC LIMIT ?"""""",\n            (current_start_id, chunk_size))\n\n        rows = source_cursor.fetchall()\n\n        if not rows:\n            break\n\n        insert_params = []\n\n        for row in rows:\n            post_id = row[id_column_name]\n            md5 = row[md5_column_name]\n            extension = row[extension_column_name]\n            tags = row[tags_column_name]\n            general_tag_count = row[tag_count_general_column_name]\n            rating = row[rating_column_name]\n            # score = row[score_column_name]\n            is_deleted = row[deleted_column_name]\n\n            if post_id > end_id:\n                break\n\n            if is_deleted and not use_deleted:\n                continue\n\n            if rating == \'s\':\n                tags += f\' rating:safe\'\n            elif rating == \'q\':\n                tags += f\' rating:questionable\'\n            elif rating == \'e\':\n                tags += f\' rating:explicit\'\n\n            # if score < -6:\n            #     tags += f\' score:very_bad\'\n            # elif score >= -6 and score < 0:\n            #     tags += f\' score:bad\'\n            # elif score >= 0 and score < 7:\n            #     tags += f\' score:average\'\n            # elif score >= 7 and score < 13:\n            #     tags += f\' score:good\'\n            # elif score >= 13:\n            #     tags += f\' score:very_good\'\n\n            insert_params.append(\n                (post_id, md5, extension, tags, general_tag_count))\n\n        if insert_params:\n            print(\'Inserting ...\')\n            output_cursor.executemany(\n                f""""""INSERT INTO {table_name} (\n                {id_column_name},{md5_column_name},{extension_column_name},{tags_column_name},{tag_count_general_column_name})\n                values (?, ?, ?, ?, ?)"""""", insert_params)\n            output_connection.commit()\n\n        current_start_id = rows[-1][id_column_name] + 1\n\n        if current_start_id > end_id or len(rows) < chunk_size:\n            break\n\n    if vacuum:\n        print(\'Vacuum ...\')\n        output_cursor.execute(\'vacuum\')\n        output_connection.commit()\n\n    source_connection.close()\n    output_connection.close()\n'"
deepdanbooru/commands/train_project.py,21,"b'import os\r\nimport random\r\nimport time\r\nimport datetime\r\n\r\nimport tensorflow as tf\r\n\r\nimport deepdanbooru as dd\r\n\r\n\r\ndef train_project(project_path):\r\n    project_context_path = os.path.join(project_path, \'project.json\')\r\n    project_context = dd.io.deserialize_from_json(project_context_path)\r\n\r\n    width = project_context[\'image_width\']\r\n    height = project_context[\'image_height\']\r\n    database_path = project_context[\'database_path\']\r\n    minimum_tag_count = project_context[\'minimum_tag_count\']\r\n    model_type = project_context[\'model\']\r\n    optimizer_type = project_context[\'optimizer\']\r\n    learning_rate = project_context[\'learning_rate\'] if \'learning_rate\' in project_context else 0.001\r\n    learning_rates = project_context[\'learning_rates\'] if \'learning_rates\' in project_context else None\r\n    minibatch_size = project_context[\'minibatch_size\']\r\n    epoch_count = project_context[\'epoch_count\']\r\n    export_model_per_epoch = project_context[\r\n        \'export_model_per_epoch\'] if \'export_model_per_epoch\' in project_context else 10\r\n    checkpoint_frequency_mb = project_context[\'checkpoint_frequency_mb\']\r\n    console_logging_frequency_mb = project_context[\'console_logging_frequency_mb\']\r\n    rotation_range = project_context[\'rotation_range\']\r\n    scale_range = project_context[\'scale_range\']\r\n    shift_range = project_context[\'shift_range\']\r\n\r\n    # disable PNG warning\r\n    os.environ[""TF_CPP_MIN_LOG_LEVEL""] = ""2""\r\n    # tf.logging.set_verbosity(tf.logging.ERROR)\r\n\r\n    # tf.keras.backend.set_epsilon(1e-4)\r\n    # tf.keras.mixed_precision.experimental.set_policy(\'infer_float32_vars\')\r\n    # tf.config.gpu.set_per_process_memory_growth(True)\r\n\r\n    if optimizer_type == \'adam\':\r\n        optimizer = tf.optimizers.Adam(learning_rate)\r\n        print(\'Using Adam optimizer ... \')\r\n    elif optimizer_type == \'sgd\':\r\n        optimizer = tf.optimizers.SGD(\r\n            learning_rate, momentum=0.9, nesterov=True)\r\n        print(\'Using SGD optimizer ... \')\r\n    elif optimizer_type == \'rmsprop\':\r\n        optimizer = tf.optimizers.RMSprop(learning_rate)\r\n        print(\'Using RMSprop optimizer ... \')\r\n    else:\r\n        raise Exception(\r\n            f""Not supported optimizer : {optimizer_type}"")\r\n\r\n    if model_type == \'resnet_152\':\r\n        model_delegate = dd.model.resnet.create_resnet_152\r\n    elif model_type == \'resnet_custom_v1\':\r\n        model_delegate = dd.model.resnet.create_resnet_custom_v1\r\n    elif model_type == \'resnet_custom_v2\':\r\n        model_delegate = dd.model.resnet.create_resnet_custom_v2\r\n    elif model_type == \'resnet_custom_v3\':\r\n        model_delegate = dd.model.resnet.create_resnet_custom_v3\r\n    else:\r\n        raise Exception(f\'Not supported model : {model_type}\')\r\n\r\n    print(\'Loading tags ... \')\r\n    tags = dd.project.load_tags_from_project(project_path)\r\n    output_dim = len(tags)\r\n\r\n    print(f\'Creating model ({model_type}) ... \')\r\n    # tf.keras.backend.set_learning_phase(1)\r\n\r\n    inputs = tf.keras.Input(shape=(height, width, 3),\r\n                            dtype=tf.float32)  # HWC\r\n    ouputs = model_delegate(inputs, output_dim)\r\n    model = tf.keras.Model(inputs=inputs, outputs=ouputs, name=model_type)\r\n    print(f\'Model : {model.input_shape} -> {model.output_shape}\')\r\n\r\n    model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(),\r\n                  metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\r\n\r\n    print(f\'Loading database ... \')\r\n    image_records = dd.data.load_image_records(\r\n        database_path, minimum_tag_count)\r\n\r\n    # Checkpoint variables\r\n    used_epoch = tf.Variable(0, dtype=tf.int64)\r\n    used_minibatch = tf.Variable(0, dtype=tf.int64)\r\n    used_sample = tf.Variable(0, dtype=tf.int64)\r\n    offset = tf.Variable(0, dtype=tf.int64)\r\n    random_seed = tf.Variable(0, dtype=tf.int64)\r\n\r\n    checkpoint = tf.train.Checkpoint(\r\n        optimizer=optimizer,\r\n        model=model,\r\n        used_epoch=used_epoch,\r\n        used_minibatch=used_minibatch,\r\n        used_sample=used_sample,\r\n        offset=offset,\r\n        random_seed=random_seed)\r\n\r\n    manager = tf.train.CheckpointManager(\r\n        checkpoint=checkpoint,\r\n        directory=os.path.join(project_path, \'checkpoints\'),\r\n        max_to_keep=3)\r\n\r\n    if manager.latest_checkpoint:\r\n        print(""Checkpoint exists. Continuing training ..."")\r\n        checkpoint.restore(manager.latest_checkpoint)\r\n        print(f\'used_epoch={int(used_epoch)}, used_minibatch={int(used_minibatch)}, used_sample={int(used_sample)}, offset={int(offset)}, random_seed={int(random_seed)}\')\r\n    else:\r\n        print(\'No checkpoint. Starting new training ...\')\r\n\r\n    epoch_size = len(image_records)\r\n    slice_size = minibatch_size * checkpoint_frequency_mb\r\n    loss_sum = 0.0\r\n    loss_count = 0\r\n    used_sample_sum = 0\r\n    last_time = time.time()\r\n\r\n    while int(used_epoch) < epoch_count:\r\n        print(f\'Shuffling samples (epoch {int(used_epoch)}) ... \')\r\n        epoch_random = random.Random(int(random_seed))\r\n        epoch_random.shuffle(image_records)\r\n\r\n        # Udpate learning rate\r\n        if learning_rates:\r\n            for learning_rate_per_epoch in learning_rates:\r\n                if learning_rate_per_epoch[\'used_epoch\'] <= int(used_epoch):\r\n                    learning_rate = learning_rate_per_epoch[\'learning_rate\']\r\n        print(f\'Trying to change learning rate to {learning_rate} ...\')\r\n        optimizer.learning_rate.assign(learning_rate)\r\n        print(f\'Learning rate is changed to {optimizer.learning_rate} ...\')\r\n\r\n        while int(offset) < epoch_size:\r\n            image_records_slice = image_records[int(offset):min(\r\n                int(offset) + slice_size, epoch_size)]\r\n\r\n            image_paths = [image_record[0]\r\n                           for image_record in image_records_slice]\r\n            tag_strings = [image_record[1]\r\n                           for image_record in image_records_slice]\r\n\r\n            dataset_wrapper = dd.data.DatasetWrapper(\r\n                (image_paths, tag_strings), tags, width, height, scale_range=scale_range, rotation_range=rotation_range, shift_range=shift_range)\r\n            dataset = dataset_wrapper.get_dataset(minibatch_size)\r\n\r\n            for (x_train, y_train) in dataset:\r\n                sample_count = x_train.shape[0]\r\n\r\n                step_result = model.train_on_batch(\r\n                    x_train, y_train, reset_metrics=False)\r\n\r\n                used_minibatch.assign_add(1)\r\n                used_sample.assign_add(sample_count)\r\n                used_sample_sum += sample_count\r\n                loss_sum += step_result[0]\r\n                loss_count += 1\r\n\r\n                if int(used_minibatch) % console_logging_frequency_mb == 0:\r\n                    # calculate logging informations\r\n                    current_time = time.time()\r\n                    delta_time = current_time - last_time\r\n                    step_metric_precision = step_result[1]\r\n                    step_metric_recall = step_result[2]\r\n                    if step_metric_precision + step_metric_recall > 0.0:\r\n                        step_metric_f1_score = 2.0 * \\\r\n                            (step_metric_precision * step_metric_recall) / \\\r\n                            (step_metric_precision + step_metric_recall)\r\n                    else:\r\n                        step_metric_f1_score = 0.0\r\n                    average_loss = loss_sum / float(loss_count)\r\n                    samples_per_seconds = float(\r\n                        used_sample_sum) / max(delta_time, 0.001)\r\n                    progress = float(int(used_sample)) / \\\r\n                        float(epoch_size * epoch_count) * 100.0\r\n                    remain_seconds = float(\r\n                        epoch_size * epoch_count - int(used_sample)) / max(samples_per_seconds, 0.001)\r\n                    eta_datetime = datetime.datetime.now() + datetime.timedelta(seconds=remain_seconds)\r\n                    eta_datetime_string = eta_datetime.strftime(\r\n                        \'%Y-%m-%d %H:%M:%S\')\r\n                    print(\r\n                        f\'Epoch[{int(used_epoch)}] Loss={average_loss:.6f}, P={step_metric_precision:.6f}, R={step_metric_recall:.6f}, F1={step_metric_f1_score:.6f}, Speed = {samples_per_seconds:.1f} samples/s, {progress:.2f} %, ETA = {eta_datetime_string}\')\r\n\r\n                    # reset for next logging\r\n                    model.reset_metrics()\r\n                    loss_sum = 0.0\r\n                    loss_count = 0\r\n                    used_sample_sum = 0\r\n                    last_time = current_time\r\n\r\n            offset.assign_add(slice_size)\r\n            print(\'Saving checkpoint ... \')\r\n            manager.save()\r\n\r\n        used_epoch.assign_add(1)\r\n        random_seed.assign_add(1)\r\n        offset.assign(0)\r\n\r\n        if int(used_epoch) % export_model_per_epoch == 0:\r\n            print(\'Saving model ... (per epoch {export_model_per_epoch})\')\r\n            export_path = os.path.join(\r\n                project_path, f\'model-{model_type}.h5.e{int(used_epoch)}\')\r\n            model.save(export_path, include_optimizer=False, save_format=\'h5\')\r\n\r\n    print(\'Saving model ...\')\r\n    model_path = os.path.join(\r\n        project_path, f\'model-{model_type}.h5\')\r\n\r\n    # tf.keras.experimental.export_saved_model throw exception now\r\n    # see https://github.com/tensorflow/tensorflow/issues/27112\r\n    model.save(model_path, include_optimizer=False)\r\n\r\n    print(\'Training is complete.\')\r\n    print(\r\n        f\'used_epoch={int(used_epoch)}, used_minibatch={int(used_minibatch)}, used_sample={int(used_sample)}\')\r\n'"
deepdanbooru/data/__init__.py,4,"b'from typing import Any, Union\r\n\r\nimport six\r\nimport tensorflow as tf\r\n\r\nimport deepdanbooru as dd\r\n\r\nfrom .dataset import load_image_records, load_tags\r\nfrom .dataset_wrapper import DatasetWrapper\r\n\r\n\r\ndef load_image_for_evaluate(\r\n        input_: Union[str, six.BytesIO], width: int, height: int, normalize: bool = True\r\n) -> Any:\r\n    if isinstance(input_, six.BytesIO):\r\n        image_raw = input_.getvalue()\r\n    else:\r\n        image_raw = tf.io.read_file(input_)\r\n    image = tf.io.decode_png(image_raw, channels=3)\r\n\r\n    image = tf.image.resize(\r\n        image, size=(height, width), method=tf.image.ResizeMethod.AREA, preserve_aspect_ratio=True)\r\n    image = image.numpy()  # EagerTensor to np.array\r\n    image = dd.image.transform_and_pad_image(image, width, height)\r\n\r\n    if normalize:\r\n        image = image / 255.0\r\n\r\n    return image\r\n'"
deepdanbooru/data/dataset.py,0,"b'import os\r\nimport sqlite3\r\n\r\n\r\ndef load_tags(tags_path):\r\n    with open(tags_path, \'r\') as tags_stream:\r\n        tags = [tag for tag in (tag.strip() for tag in tags_stream) if tag]\r\n        return tags\r\n\r\n\r\ndef load_image_records(sqlite_path, minimum_tag_count):\r\n    if not os.path.exists(sqlite_path):\r\n        raise Exception(f\'SQLite database is not exists : {sqlite_path}\')\r\n\r\n    connection = sqlite3.connect(sqlite_path)\r\n    connection.row_factory = sqlite3.Row\r\n    cursor = connection.cursor()\r\n\r\n    image_folder_path = os.path.join(os.path.dirname(sqlite_path), \'images\')\r\n\r\n    cursor.execute(\r\n        ""SELECT md5, file_ext, tag_string FROM posts WHERE (file_ext = \'png\' OR file_ext = \'jpg\' OR file_ext = \'jpeg\') AND (tag_count_general >= ?) ORDER BY id"",\r\n        (minimum_tag_count,))\r\n\r\n    rows = cursor.fetchall()\r\n\r\n    image_records = []\r\n\r\n    for row in rows:\r\n        md5 = row[\'md5\']\r\n        extension = row[\'file_ext\']\r\n        image_path = os.path.join(\r\n            image_folder_path, md5[0:2], f\'{md5}.{extension}\')\r\n        tag_string = row[\'tag_string\']\r\n\r\n        image_records.append((image_path, tag_string))\r\n\r\n    connection.close()\r\n\r\n    return image_records\r\n'"
deepdanbooru/data/dataset_wrapper.py,11,"b'import random\n\nimport numpy as np\nimport tensorflow as tf\n\nimport deepdanbooru as dd\n\n\nclass DatasetWrapper:\n    """"""\n    Wrapper class for data pipelining/augmentation.\n    """"""\n\n    def __init__(self, inputs, tags, width, height, scale_range, rotation_range, shift_range):\n        self.inputs = inputs\n        self.width = width\n        self.height = height\n        self.scale_range = scale_range\n        self.rotation_range = rotation_range\n        self.shift_range = shift_range\n        self.tag_all_array = np.array(tags)\n\n    def get_dataset(self, minibatch_size):\n        dataset = tf.data.Dataset.from_tensor_slices(self.inputs)\n        dataset = dataset.map(\n            self.map_load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n        dataset = dataset.apply(tf.data.experimental.ignore_errors())\n        dataset = dataset.map(\n            self.map_transform_image_and_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n        dataset = dataset.batch(minibatch_size)\n        dataset = dataset.prefetch(\n            buffer_size=tf.data.experimental.AUTOTUNE)\n        # dataset = dataset.apply(\n        #    tf.data.experimental.prefetch_to_device(\'/device:GPU:0\'))\n\n        return dataset\n\n    def map_load_image(self, image_path, tag_string):\n        image_raw = tf.io.read_file(image_path)\n        image = tf.io.decode_png(image_raw, channels=3)\n\n        if self.scale_range:\n            pre_scale = self.scale_range[1]\n        else:\n            pre_scale = 1.0\n\n        size = (int(self.height * pre_scale), int(self.width * pre_scale))\n\n        image = tf.image.resize(\n            image, size=size, method=tf.image.ResizeMethod.AREA, preserve_aspect_ratio=True)\n\n        return (image, tag_string)\n\n    def map_transform_image_and_label(self, image, tag_string):\n        return tf.py_function(self.map_transform_image_and_label_py, (image, tag_string), (tf.float32, tf.float32))\n\n    def map_transform_image_and_label_py(self, image, tag_string):\n        # transform image\n        image = image.numpy()\n\n        if self.scale_range:\n            scale = random.uniform(\n                self.scale_range[0], self.scale_range[1]) * (1.0 / self.scale_range[1])\n        else:\n            scale = None\n\n        if self.rotation_range:\n            rotation = random.uniform(\n                self.rotation_range[0], self.rotation_range[1])\n        else:\n            rotation = None\n\n        if self.shift_range:\n            shift_x = random.uniform(self.shift_range[0], self.shift_range[1])\n            shift_y = random.uniform(self.shift_range[0], self.shift_range[1])\n            shift = (shift_x, shift_y)\n        else:\n            shift = None\n\n        image = dd.image.transform_and_pad_image(\n            image=image,\n            target_width=self.width,\n            target_height=self.height,\n            rotation=rotation,\n            scale=scale,\n            shift=shift)\n\n        image = image / 255.0  # normalize to 0~1\n        # image = image.astype(np.float32)\n\n        # transform tag\n        tag_string = tag_string.numpy().decode()\n        tag_array = np.array(tag_string.split(\' \'))\n\n        labels = np.where(np.isin(self.tag_all_array,\n                                  tag_array), 1, 0).astype(np.float32)\n\n        return (image, labels)\n'"
deepdanbooru/extra/__init__.py,0,"b'import re\n\n\ndef atoi(text):\n    return int(text) if text.isdigit() else text\n\n\ndef natural_keys(text):\n    """"""\n    alist.sort(key=natural_keys) sorts in human order\n    http://nedbatchelder.com/blog/200712/human_sorting.html\n    (See Toothy\'s implementation in the comments)\n    """"""\n    return [atoi(c) for c in re.split(r\'(\\d+)\', text)]\n\n\ndef natural_sorted(iterable):\n    return sorted(iterable, key=natural_keys)\n'"
deepdanbooru/image/__init__.py,0,"b'import math\n\nimport numpy as np\nimport skimage.transform\n\n\ndef calculate_image_scale(source_width, source_height, target_width, target_height):\n    """"""\n    Calculate scale for image resizing while preserving aspect ratio.\n    """"""\n    if source_width == target_width and source_height == target_height:\n        return 1.0\n\n    source_ratio = source_width / source_height\n    target_ratio = target_width / target_height\n\n    if target_ratio < source_ratio:\n        scale = target_width / source_width\n    else:\n        scale = target_height / source_height\n\n    return scale\n\n\ndef transform_and_pad_image(image, target_width, target_height, scale=None, rotation=None, shift=None, order=1, mode=\'edge\'):\n    """"""\n    Transform image and pad by edge pixles.\n    """"""\n    image_width = image.shape[1]\n    image_height = image.shape[0]\n    image_array = image\n\n    # centerize\n    t = skimage.transform.AffineTransform(\n        translation=(-image_width * 0.5, -image_height * 0.5))\n\n    if scale:\n        t += skimage.transform.AffineTransform(scale=(scale, scale))\n\n    if rotation:\n        radian = (rotation / 180.0) * math.pi\n        t += skimage.transform.AffineTransform(rotation=radian)\n\n    t += skimage.transform.AffineTransform(\n        translation=(target_width * 0.5, target_height * 0.5))\n\n    if shift:\n        t += skimage.transform.AffineTransform(\n            translation=(target_width * shift[0], target_height * shift[1]))\n\n    warp_shape = (target_height, target_width)\n\n    image_array = skimage.transform.warp(\n        image_array, (t).inverse, output_shape=warp_shape, order=order, mode=mode)\n\n    return image_array\n'"
deepdanbooru/io/__init__.py,0,"b""import json\r\nimport os\r\nfrom pathlib import Path\r\n\r\n\r\ndef serialize_as_json(target_object, path, encoding='utf-8'):\r\n    with open(path, 'w', encoding=encoding) as stream:\r\n        stream.write(json.dumps(target_object, indent=4, ensure_ascii=False))\r\n\r\n\r\ndef deserialize_from_json(path, encoding='utf-8'):\r\n    with open(path, 'r', encoding=encoding) as stream:\r\n        return json.loads(stream.read())\r\n\r\n\r\ndef try_create_directory(path):\r\n    if not os.path.exists(path):\r\n        os.makedirs(path)\r\n\r\n\r\ndef get_file_paths_in_directory(path, patterns):\r\n    return [str(file_path) for pattern in patterns for file_path in Path(path).rglob(pattern)]\r\n\r\n\r\ndef get_image_file_paths_recursive(folder_path, patterns_string):\r\n    patterns = patterns_string.split(',')\r\n\r\n    return get_file_paths_in_directory(folder_path, patterns)\r\n"""
deepdanbooru/model/__init__.py,0,b'import deepdanbooru.model.layers\nimport deepdanbooru.model.losses\n\nfrom .resnet import create_resnet_152\nfrom .resnet import create_resnet_custom_v1\nfrom .resnet import create_resnet_custom_v2\nfrom .resnet import create_resnet_custom_v3\n'
deepdanbooru/model/resnet.py,16,"b'import numpy as np\r\nimport tensorflow as tf\r\nimport deepdanbooru as dd\r\n\r\n\r\ndef resnet_bottleneck_block(x, output_filters, inter_filters, activation=True, se=False):\r\n    c1 = dd.model.layers.conv_bn_relu(x, inter_filters, (1, 1))\r\n    c2 = dd.model.layers.conv_bn_relu(c1, inter_filters, (3, 3))\r\n    c3 = dd.model.layers.conv_bn(\r\n        c2, output_filters, (1, 1), bn_gamma_initializer=\'zeros\')\r\n\r\n    if se:\r\n        c3 = dd.model.layers.squeeze_excitation(c3)\r\n\r\n    p = tf.keras.layers.Add()([c3, x])\r\n\r\n    if activation:\r\n        return tf.keras.layers.Activation(\'relu\')(p)\r\n    else:\r\n        return p\r\n\r\n\r\ndef resnet_bottleneck_inc_block(x, output_filters, inter_filters, strides1x1=(1, 1), strides2x2=(2, 2), se=False):\r\n    c1 = dd.model.layers.conv_bn_relu(\r\n        x, inter_filters, (1, 1), strides=strides1x1)\r\n    c2 = dd.model.layers.conv_bn_relu(\r\n        c1, inter_filters, (3, 3), strides=strides2x2)\r\n    c3 = dd.model.layers.conv_bn(\r\n        c2, output_filters, (1, 1), bn_gamma_initializer=\'zeros\')\r\n\r\n    if se:\r\n        c3 = dd.model.layers.squeeze_excitation(c3)\r\n\r\n    strides = np.multiply(strides1x1, strides2x2)\r\n    s = dd.model.layers.conv_bn(\r\n        x, output_filters, (1, 1), strides=strides)  # shortcut\r\n\r\n    p = tf.keras.layers.Add()([c3, s])\r\n\r\n    return tf.keras.layers.Activation(\'relu\')(p)\r\n\r\n\r\ndef resnet_original_bottleneck_model(x, filter_sizes, repeat_sizes, final_pool=True, se=False):\r\n    """"""\r\n    https://github.com/Microsoft/CNTK/blob/master/Examples/Image/Classification/ResNet/Python/resnet_models.py\r\n    """"""\r\n    assert len(filter_sizes) == len(repeat_sizes)\r\n\r\n    x = dd.model.layers.conv_bn_relu(\r\n        x, filter_sizes[0] // 4, (7, 7), strides=(2, 2))\r\n    x = tf.keras.layers.MaxPool2D((3, 3), strides=(\r\n        2, 2), padding=\'same\')(x)\r\n\r\n    for i in range(len(repeat_sizes)):\r\n        x = resnet_bottleneck_inc_block(\r\n            x=x,\r\n            output_filters=filter_sizes[i],\r\n            inter_filters=filter_sizes[i] // 4,\r\n            strides2x2=(2, 2) if i > 0 else (1, 1),\r\n            se=se)\r\n        x = dd.model.layers.repeat_blocks(\r\n            x=x,\r\n            block_delegate=resnet_bottleneck_block,\r\n            count=repeat_sizes[i],\r\n            output_filters=filter_sizes[i],\r\n            inter_filters=filter_sizes[i] // 4,\r\n            se=se)\r\n\r\n    if final_pool:\r\n        x = tf.keras.layers.AveragePooling2D((7, 7), name=\'ap_final\')(x)\r\n\r\n    return x\r\n\r\n\r\ndef resnet_longterm_bottleneck_model(x, filter_sizes, repeat_sizes, final_pool=True, se=False):\r\n    """"""\r\n    Add long-term shortcut.\r\n    """"""\r\n    assert len(filter_sizes) == len(repeat_sizes)\r\n\r\n    x = dd.model.layers.conv_bn_relu(\r\n        x, filter_sizes[0] // 4, (7, 7), strides=(2, 2))\r\n    x = tf.keras.layers.MaxPool2D((3, 3), strides=(\r\n        2, 2), padding=\'same\')(x)\r\n\r\n    for i in range(len(repeat_sizes)):\r\n        x = resnet_bottleneck_inc_block(\r\n            x=x,\r\n            output_filters=filter_sizes[i],\r\n            inter_filters=filter_sizes[i] // 4,\r\n            strides2x2=(2, 2) if i > 0 else (1, 1),\r\n            se=se)\r\n        x_1 = dd.model.layers.repeat_blocks(\r\n            x=x,\r\n            block_delegate=resnet_bottleneck_block,\r\n            count=repeat_sizes[i] - 1,\r\n            output_filters=filter_sizes[i],\r\n            inter_filters=filter_sizes[i] // 4,\r\n            se=se)\r\n        x_1 = resnet_bottleneck_block(\r\n            x_1,\r\n            output_filters=filter_sizes[i],\r\n            inter_filters=filter_sizes[i] // 4,\r\n            activation=False,\r\n            se=se)\r\n\r\n        x = tf.keras.layers.Add()([x_1, x])  # long-term shortcut\r\n        x = tf.keras.layers.Activation(\'relu\')(x)\r\n\r\n    if final_pool:\r\n        x = tf.keras.layers.AveragePooling2D((7, 7), name=\'ap_final\')(x)\r\n\r\n    return x\r\n\r\n\r\ndef create_resnet_152(x, output_dim):\r\n    """"""\r\n    Original ResNet-152 Model.\r\n    """"""\r\n    filter_sizes = [256, 512, 1024, 2048]\r\n    repeat_sizes = [2, 7, 35, 2]\r\n\r\n    x = resnet_original_bottleneck_model(\r\n        x, filter_sizes=filter_sizes, repeat_sizes=repeat_sizes)\r\n\r\n    x = tf.keras.layers.Flatten()(x)\r\n    x = tf.keras.layers.Dense(output_dim)(x)\r\n    x = tf.keras.layers.Activation(\'sigmoid\')(x)\r\n\r\n    return x\r\n\r\n\r\ndef create_resnet_custom_v1(x, output_dim):\r\n    """"""\r\n    DeepDanbooru web (until 2019/04/20)\r\n    Short, wide\r\n    """"""\r\n    filter_sizes = [256, 512, 1024, 2048, 4096]\r\n    repeat_sizes = [2, 7, 35, 2, 2]\r\n\r\n    x = resnet_original_bottleneck_model(\r\n        x, filter_sizes=filter_sizes, repeat_sizes=repeat_sizes, final_pool=False)\r\n\r\n    x = dd.model.layers.conv_gap(x, output_dim)\r\n    x = tf.keras.layers.Activation(\'sigmoid\')(x)\r\n\r\n    return x\r\n\r\n\r\ndef create_resnet_custom_v2(x, output_dim):\r\n    """"""\r\n    Experimental (blazing-deep network)\r\n    Deep, narrow\r\n    """"""\r\n    filter_sizes = [256, 512, 1024, 1024, 1024, 2048]\r\n    repeat_sizes = [2, 7, 40, 16, 16, 6]\r\n\r\n    x = resnet_original_bottleneck_model(\r\n        x, filter_sizes=filter_sizes, repeat_sizes=repeat_sizes, final_pool=False)\r\n\r\n    x = dd.model.layers.conv_gap(x, output_dim)\r\n    x = tf.keras.layers.Activation(\'sigmoid\')(x)\r\n\r\n    return x\r\n\r\n\r\ndef create_resnet_custom_v3(x, output_dim):\r\n    """"""\r\n    DeepDanbooru web (until 2019/04/20)\r\n    Short, wide\r\n    """"""\r\n    filter_sizes = [256, 512, 1024, 1024, 2048, 4096]\r\n    repeat_sizes = [2, 7, 19, 19, 2, 2]\r\n\r\n    x = resnet_original_bottleneck_model(\r\n        x, filter_sizes=filter_sizes, repeat_sizes=repeat_sizes, final_pool=False)\r\n\r\n    x = dd.model.layers.conv_gap(x, output_dim)\r\n    x = tf.keras.layers.Activation(\'sigmoid\')(x)\r\n\r\n    return x\r\n'"
deepdanbooru/project/__init__.py,0,b'from .project import DEFAULT_PROJECT_CONTEXT\r\nfrom .project import load_project\r\nfrom .project import load_model_from_project\r\nfrom .project import load_tags_from_project\r\n'
deepdanbooru/project/project.py,2,"b""import os\r\nimport deepdanbooru as dd\r\nimport tensorflow as tf\r\n\r\nDEFAULT_PROJECT_CONTEXT = {\r\n    'image_width': 299,\r\n    'image_height': 299,\r\n    'database_path': None,\r\n    'minimum_tag_count': 20,\r\n    'model': 'resnet_custom_v2',\r\n    'minibatch_size': 32,\r\n    'epoch_count': 10,\r\n    'export_model_per_epoch': 10,\r\n    'checkpoint_frequency_mb': 200,\r\n    'console_logging_frequency_mb': 10,\r\n    'optimizer': 'adam',\r\n    'learning_rate': 0.001,\r\n    'rotation_range': [0.0, 360.0],\r\n    'scale_range': [0.9, 1.1],\r\n    'shift_range': [-0.1, 0.1]\r\n}\r\n\r\n\r\ndef load_project(project_path):\r\n    project_context_path = os.path.join(project_path, 'project.json')\r\n    project_context = dd.io.deserialize_from_json(project_context_path)\r\n    tags = dd.data.load_tags_from_project(project_path)\r\n\r\n    model_type = project_context['model']\r\n    model_path = os.path.join(project_path, f'model-{model_type}.h5')\r\n    model = tf.keras.models.load_model(model_path)\r\n\r\n    return project_context, model, tags\r\n\r\n\r\ndef load_model_from_project(project_path, compile_model=True):\r\n    project_context_path = os.path.join(project_path, 'project.json')\r\n    project_context = dd.io.deserialize_from_json(project_context_path)\r\n\r\n    model_type = project_context['model']\r\n    model_path = os.path.join(project_path, f'model-{model_type}.h5')\r\n    model = tf.keras.models.load_model(model_path, compile=compile_model)\r\n\r\n    return model\r\n\r\n\r\ndef load_tags_from_project(project_path):\r\n    tags_path = os.path.join(project_path, 'tags.txt')\r\n\r\n    return dd.data.load_tags(tags_path)\r\n"""
deepdanbooru/train/__init__.py,0,b''
deepdanbooru/model/layers/__init__.py,8,"b'import tensorflow as tf\n\n\ndef conv(x, filters, kernel_size, strides=(1, 1), padding=\'same\', initializer=\'he_normal\'):\n    c = tf.keras.layers.Conv2D(\n        filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, kernel_initializer=initializer, use_bias=False)(x)\n\n    return c\n\n\ndef conv_bn(x, filters, kernel_size, strides=(1, 1), padding=\'same\', initializer=\'he_normal\', bn_gamma_initializer=\'ones\'):\n    c = conv(x, filters=filters, kernel_size=kernel_size,\n             strides=strides, padding=padding, initializer=initializer)\n\n    c_bn = tf.keras.layers.BatchNormalization(\n        gamma_initializer=bn_gamma_initializer)(c)\n\n    return c_bn\n\n\ndef conv_bn_relu(x, filters, kernel_size, strides=(1, 1), padding=\'same\', initializer=\'he_normal\', bn_gamma_initializer=\'ones\'):\n    c_bn = conv_bn(x, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding,\n                   initializer=initializer, bn_gamma_initializer=bn_gamma_initializer)\n\n    return tf.keras.layers.Activation(\'relu\')(c_bn)\n\n\ndef conv_gap(x, output_filters, kernel_size=(1, 1)):\n    x = conv(x, filters=output_filters, kernel_size=kernel_size)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n\n    return x\n\n\ndef repeat_blocks(x, block_delegate, count, **kwargs):\n    assert count >= 0\n\n    for _ in range(count):\n        x = block_delegate(x, **kwargs)\n    return x\n\n\ndef squeeze_excitation(x, reduction=16):\n    """"""\n    Squeeze-Excitation layer from https://arxiv.org/abs/1709.01507\n    """"""\n    output_filters = x.shape[-1]\n\n    assert output_filters // reduction > 0\n\n    s = x\n\n    s = tf.keras.layers.GlobalAveragePooling2D()(s)\n    s = tf.keras.layers.Dense(\n        output_filters//reduction, activation=\'relu\')(x)\n    s = tf.keras.layers.Dense(\n        output_filters, activation=\'sigmoid\')(x)\n    x = tf.keras.layers.Multiply()([x, s])\n\n    return x\n'"
deepdanbooru/model/losses/__init__.py,9,"b'import tensorflow as tf\n\n\ndef focal_loss(alpha=0.25, gamma=2.0, epsilon=1e-7):\n    def loss(y_true, y_pred):\n        value = -alpha * y_true * tf.math.pow(1.0 - y_pred, gamma) * tf.math.log(y_pred + epsilon) - (\n            1.0 - alpha) * (1.0 - y_true) * tf.math.pow(y_pred, gamma) * tf.math.log(1.0 - y_pred + epsilon)\n\n        return tf.math.reduce_sum(value)\n\n    return loss\n\n\ndef binary_crossentropy(epsilon=1e-7):\n    def loss(y_true, y_pred):\n        clipped_y_pred = tf.clip_by_value(y_pred, epsilon, tf.float32.max)\n        clipped_y_pred_nega = tf.clip_by_value(\n            1.0 - y_pred, epsilon, tf.float32.max)\n        value = (-y_true) * tf.math.log(clipped_y_pred) - \\\n            (1.0 - y_true) * tf.math.log(clipped_y_pred_nega)\n\n        return tf.math.reduce_sum(value)\n\n    return loss\n'"
