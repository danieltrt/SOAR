file_path,api_count,code
data_load.py,9,"b'# -*- coding: utf-8 -*-\n#/usr/bin/python2\n\'\'\'\nBy kyubyong park. kbpark.linguist@gmail.com. \nhttps://www.github.com/kyubyong/tacotron\n\'\'\'\n\nfrom __future__ import print_function\n\nfrom hyperparams import Hyperparams as hp\nimport numpy as np\nimport tensorflow as tf\nfrom utils import *\nimport codecs\nimport re\nimport os\nimport unicodedata\n\ndef load_vocab():\n    char2idx = {char: idx for idx, char in enumerate(hp.vocab)}\n    idx2char = {idx: char for idx, char in enumerate(hp.vocab)}\n    return char2idx, idx2char\n\ndef text_normalize(text):\n    text = \'\'.join(char for char in unicodedata.normalize(\'NFD\', text)\n                           if unicodedata.category(char) != \'Mn\') # Strip accents\n\n    text = text.lower()\n    text = re.sub(""[^{}]"".format(hp.vocab), "" "", text)\n    text = re.sub(""[ ]+"", "" "", text)\n    return text\n\ndef load_data(mode=""train""):\n    # Load vocabulary\n    char2idx, idx2char = load_vocab()\n\n    if mode in (""train"", ""eval""):\n        # Parse\n        fpaths, text_lengths, texts = [], [], []\n        transcript = os.path.join(hp.data, \'transcript.csv\')\n        lines = codecs.open(transcript, \'r\', \'utf-8\').readlines()\n        total_hours = 0\n        if mode==""train"":\n            lines = lines[1:]\n        else: # We attack only one sample!\n            lines = lines[:1]\n\n        for line in lines:\n            fname, _, text = line.strip().split(""|"")\n\n            fpath = os.path.join(hp.data, ""wavs"", fname + "".wav"")\n            fpaths.append(fpath)\n\n            text = text_normalize(text) + ""E""  # E: EOS\n            text = [char2idx[char] for char in text]\n            text_lengths.append(len(text))\n            texts.append(np.array(text, np.int32).tostring())\n\n        return fpaths, text_lengths, texts\n    else:\n        # Parse\n        lines = codecs.open(hp.test_data, \'r\', \'utf-8\').readlines()[1:]\n        sents = [text_normalize(line.split("" "", 1)[-1]).strip() + ""E"" for line in lines] # text normalization, E: EOS\n        lengths = [len(sent) for sent in sents]\n        maxlen = sorted(lengths, reverse=True)[0]\n        texts = np.zeros((len(sents), maxlen), np.int32)\n        for i, sent in enumerate(sents):\n            texts[i, :len(sent)] = [char2idx[char] for char in sent]\n        return texts\n\ndef get_batch():\n    """"""Loads training data and put them in queues""""""\n    with tf.device(\'/cpu:0\'):\n        # Load data\n        fpaths, text_lengths, texts = load_data() # list\n        maxlen, minlen = max(text_lengths), min(text_lengths)\n\n        # Calc total batch count\n        num_batch = len(fpaths) // hp.batch_size\n\n        fpaths = tf.convert_to_tensor(fpaths)\n        text_lengths = tf.convert_to_tensor(text_lengths)\n        texts = tf.convert_to_tensor(texts)\n\n        # Create Queues\n        fpath, text_length, text = tf.train.slice_input_producer([fpaths, text_lengths, texts], shuffle=True)\n\n        # Parse\n        text = tf.decode_raw(text, tf.int32)  # (None,)\n\n        if hp.prepro:\n            def _load_spectrograms(fpath):\n                fname = os.path.basename(fpath)\n                mel = ""mels/{}"".format(fname.replace(""wav"", ""npy""))\n                mag = ""mags/{}"".format(fname.replace(""wav"", ""npy""))\n                return fname, np.load(mel), np.load(mag)\n\n            fname, mel, mag = tf.py_func(_load_spectrograms, [fpath], [tf.string, tf.float32, tf.float32])\n        else:\n            fname, mel, mag = tf.py_func(load_spectrograms, [fpath], [tf.string, tf.float32, tf.float32])  # (None, n_mels)\n\n        # Add shape information\n        fname.set_shape(())\n        text.set_shape((None,))\n        mel.set_shape((None, hp.n_mels*hp.r))\n        mag.set_shape((None, hp.n_fft//2+1))\n\n        # Batching\n        _, (texts, mels, mags, fnames) = tf.contrib.training.bucket_by_sequence_length(\n                                            input_length=text_length,\n                                            tensors=[text, mel, mag, fname],\n                                            batch_size=hp.batch_size,\n                                            bucket_boundaries=[i for i in range(minlen + 1, maxlen - 1, 20)],\n                                            num_threads=16,\n                                            capacity=hp.batch_size * 4,\n                                            dynamic_pad=True)\n\n    return texts, mels, mags, fnames, num_batch\n\n'"
eval.py,4,"b'# -*- coding: utf-8 -*-\n#/usr/bin/python2\n\'\'\'\nBy kyubyong park. kbpark.linguist@gmail.com. \nhttps://www.github.com/kyubyong/tacotron\n\'\'\'\n\nfrom __future__ import print_function\n\nfrom hyperparams import Hyperparams as hp\nimport numpy as np\nfrom data_load import load_data\nimport tensorflow as tf\nfrom train import Graph\nfrom utils import load_spectrograms\n\n\ndef eval(): \n    # Load graph\n    g = Graph(mode=""eval""); print(""Evaluation Graph loaded"")\n\n    # Load data\n    fpaths, text_lengths, texts = load_data(mode=""eval"")\n\n    # Parse\n    text = np.fromstring(texts[0], np.int32) # (None,)\n    fname, mel, mag = load_spectrograms(fpaths[0])\n\n    x = np.expand_dims(text, 0) # (1, None)\n    y = np.expand_dims(mel, 0) # (1, None, n_mels*r)\n    z = np.expand_dims(mag, 0) # (1, None, n_mfccs)\n\n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        saver.restore(sess, tf.train.latest_checkpoint(hp.logdir)); print(""Restored!"")\n\n        writer = tf.summary.FileWriter(hp.logdir, sess.graph)\n\n        # Feed Forward\n        ## mel\n        y_hat = np.zeros((1, y.shape[1], y.shape[2]), np.float32)  # hp.n_mels*hp.r\n        for j in range(y.shape[1]):\n            _y_hat = sess.run(g.y_hat, {g.x: x, g.y: y_hat})\n            y_hat[:, j, :] = _y_hat[:, j, :]\n\n        ## mag\n        merged, gs = sess.run([g.merged, g.global_step], {g.x:x, g.y:y, g.y_hat: y_hat, g.z: z})\n        writer.add_summary(merged, global_step=gs)\n        writer.close()\n\nif __name__ == \'__main__\':\n    eval()\n    print(""Done"")\n    \n    \n'"
hyperparams.py,0,"b'# -*- coding: utf-8 -*-\n#/usr/bin/python2\n\'\'\'\nBy kyubyong park. kbpark.linguist@gmail.com. \nhttps://www.github.com/kyubyong/tacotron\n\'\'\'\nclass Hyperparams:\n    \'\'\'Hyper parameters\'\'\'\n    \n    # pipeline\n    prepro = False  # if True, run `python prepro.py` first before running `python train.py`.\n\n    vocab = ""PE abcdefghijklmnopqrstuvwxyz\'.?"" # P: Padding E: End of Sentence\n\n    # data\n    data = ""/data/private/voice/LJSpeech-1.0""\n    # data = ""/data/private/voice/nick""\n    test_data = \'harvard_sentences.txt\'\n    max_duration = 10.0\n\n    # signal processing\n    sr = 22050 # Sample rate.\n    n_fft = 2048 # fft points (samples)\n    frame_shift = 0.0125 # seconds\n    frame_length = 0.05 # seconds\n    hop_length = int(sr*frame_shift) # samples.\n    win_length = int(sr*frame_length) # samples.\n    n_mels = 80 # Number of Mel banks to generate\n    power = 1.2 # Exponent for amplifying the predicted magnitude\n    n_iter = 50 # Number of inversion iterations\n    preemphasis = .97 # or None\n    max_db = 100\n    ref_db = 20\n\n    # model\n    embed_size = 256 # alias = E\n    encoder_num_banks = 16\n    decoder_num_banks = 8\n    num_highwaynet_blocks = 4\n    r = 5 # Reduction factor. Paper => 2, 3, 5\n    dropout_rate = .5\n\n    # training scheme\n    lr = 0.001 # Initial learning rate.\n    logdir = ""logdir/01""\n    sampledir = \'samples\'\n    batch_size = 32\n\n\n\n\n'"
modules.py,41,"b'# -*- coding: utf-8 -*-\n#/usr/bin/python2\n\'\'\'\nBy kyubyong park. kbpark.linguist@gmail.com. \nhttps://www.github.com/kyubyong/tacotron\n\'\'\'\n\nfrom __future__ import print_function\n\nfrom hyperparams import Hyperparams as hp\nimport tensorflow as tf\n\n\ndef embed(inputs, vocab_size, num_units, zero_pad=True, scope=""embedding"", reuse=None):\n    \'\'\'Embeds a given tensor. \n    \n    Args:\n      inputs: A `Tensor` with type `int32` or `int64` containing the ids\n         to be looked up in `lookup table`.\n      vocab_size: An int. Vocabulary size.\n      num_units: An int. Number of embedding hidden units.\n      zero_pad: A boolean. If True, all the values of the fist row (id 0)\n        should be constant zeros.\n      scope: Optional scope for `variable_scope`.  \n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n        \n    Returns:\n      A `Tensor` with one more rank than inputs\'s. The last dimesionality\n        should be `num_units`.\n    \'\'\'\n    with tf.variable_scope(scope, reuse=reuse):\n        lookup_table = tf.get_variable(\'lookup_table\', \n                                       dtype=tf.float32, \n                                       shape=[vocab_size, num_units],\n                                       initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.01))\n        if zero_pad:\n            lookup_table = tf.concat((tf.zeros(shape=[1, num_units]), \n                                      lookup_table[1:, :]), 0)\n    return tf.nn.embedding_lookup(lookup_table, inputs)\n\n\ndef bn(inputs,\n       is_training=True,\n       activation_fn=None,\n       scope=""bn"",\n       reuse=None):\n    \'\'\'Applies batch normalization.\n\n    Args:\n      inputs: A tensor with 2 or more dimensions, where the first dimension has\n        `batch_size`. If type is `bn`, the normalization is over all but\n        the last dimension. Or if type is `ln`, the normalization is over\n        the last dimension. Note that this is different from the native\n        `tf.contrib.layers.batch_norm`. For this I recommend you change\n        a line in ``tensorflow/contrib/layers/python/layers/layer.py`\n        as follows.\n        Before: mean, variance = nn.moments(inputs, axis, keep_dims=True)\n        After: mean, variance = nn.moments(inputs, [-1], keep_dims=True)\n      is_training: Whether or not the layer is in training mode.\n      activation_fn: Activation function.\n      scope: Optional scope for `variable_scope`.\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n\n    Returns:\n      A tensor with the same shape and data dtype as `inputs`.\n    \'\'\'\n    inputs_shape = inputs.get_shape()\n    inputs_rank = inputs_shape.ndims\n\n    # use fused batch norm if inputs_rank in [2, 3, 4] as it is much faster.\n    # pay attention to the fact that fused_batch_norm requires shape to be rank 4 of NHWC.\n    if inputs_rank in [2, 3, 4]:\n        if inputs_rank == 2:\n            inputs = tf.expand_dims(inputs, axis=1)\n            inputs = tf.expand_dims(inputs, axis=2)\n        elif inputs_rank == 3:\n            inputs = tf.expand_dims(inputs, axis=1)\n\n        outputs = tf.contrib.layers.batch_norm(inputs=inputs,\n                                               center=True,\n                                               scale=True,\n                                               updates_collections=None,\n                                               is_training=is_training,\n                                               scope=scope,\n                                               fused=True,\n                                               reuse=reuse)\n        # restore original shape\n        if inputs_rank == 2:\n            outputs = tf.squeeze(outputs, axis=[1, 2])\n        elif inputs_rank == 3:\n            outputs = tf.squeeze(outputs, axis=1)\n    else:  # fallback to naive batch norm\n        outputs = tf.contrib.layers.batch_norm(inputs=inputs,\n                                               center=True,\n                                               scale=True,\n                                               updates_collections=None,\n                                               is_training=is_training,\n                                               scope=scope,\n                                               reuse=reuse,\n                                               fused=False)\n    if activation_fn is not None:\n        outputs = activation_fn(outputs)\n\n    return outputs\n\ndef conv1d(inputs, \n           filters=None, \n           size=1, \n           rate=1, \n           padding=""SAME"", \n           use_bias=False,\n           activation_fn=None,\n           scope=""conv1d"",\n           reuse=None):\n    \'\'\'\n    Args:\n      inputs: A 3-D tensor with shape of [batch, time, depth].\n      filters: An int. Number of outputs (=activation maps)\n      size: An int. Filter size.\n      rate: An int. Dilation rate.\n      padding: Either `same` or `valid` or `causal` (case-insensitive).\n      use_bias: A boolean.\n      scope: Optional scope for `variable_scope`.\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n    \'\'\'\n    with tf.variable_scope(scope):\n        if padding.lower()==""causal"":\n            # pre-padding for causality\n            pad_len = (size - 1) * rate  # padding size\n            inputs = tf.pad(inputs, [[0, 0], [pad_len, 0], [0, 0]])\n            padding = ""valid""\n        \n        if filters is None:\n            filters = inputs.get_shape().as_list[-1]\n        \n        params = {""inputs"":inputs, ""filters"":filters, ""kernel_size"":size,\n                ""dilation_rate"":rate, ""padding"":padding, ""activation"":activation_fn, \n                ""use_bias"":use_bias, ""reuse"":reuse}\n        \n        outputs = tf.layers.conv1d(**params)\n    return outputs\n\ndef conv1d_banks(inputs, K=16, is_training=True, scope=""conv1d_banks"", reuse=None):\n    \'\'\'Applies a series of conv1d separately.\n    \n    Args:\n      inputs: A 3d tensor with shape of [N, T, C]\n      K: An int. The size of conv1d banks. That is, \n        The `inputs` are convolved with K filters: 1, 2, ..., K.\n      is_training: A boolean. This is passed to an argument of `bn`.\n      scope: Optional scope for `variable_scope`.\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n\n    Returns:\n      A 3d tensor with shape of [N, T, K*Hp.embed_size//2].\n    \'\'\'\n    with tf.variable_scope(scope, reuse=reuse):\n        outputs = conv1d(inputs, hp.embed_size//2, 1) # k=1\n        for k in range(2, K+1): # k = 2...K\n            with tf.variable_scope(""num_{}"".format(k)):\n                output = conv1d(inputs, hp.embed_size // 2, k)\n                outputs = tf.concat((outputs, output), -1)\n        outputs = bn(outputs, is_training=is_training, activation_fn=tf.nn.relu)\n    return outputs # (N, T, Hp.embed_size//2*K)\n\ndef gru(inputs, num_units=None, bidirection=False, scope=""gru"", reuse=None):\n    \'\'\'Applies a GRU.\n    \n    Args:\n      inputs: A 3d tensor with shape of [N, T, C].\n      num_units: An int. The number of hidden units.\n      bidirection: A boolean. If True, bidirectional results \n        are concatenated.\n      scope: Optional scope for `variable_scope`.  \n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n        \n    Returns:\n      If bidirection is True, a 3d tensor with shape of [N, T, 2*num_units],\n        otherwise [N, T, num_units].\n    \'\'\'\n    with tf.variable_scope(scope, reuse=reuse):\n        if num_units is None:\n            num_units = inputs.get_shape().as_list[-1]\n            \n        cell = tf.contrib.rnn.GRUCell(num_units)  \n        if bidirection: \n            cell_bw = tf.contrib.rnn.GRUCell(num_units)\n            outputs, _ = tf.nn.bidirectional_dynamic_rnn(cell, cell_bw, inputs, dtype=tf.float32)\n            return tf.concat(outputs, 2)  \n        else:\n            outputs, _ = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n            return outputs\n\ndef attention_decoder(inputs, memory, num_units=None, scope=""attention_decoder"", reuse=None):\n    \'\'\'Applies a GRU to `inputs`, while attending `memory`.\n    Args:\n      inputs: A 3d tensor with shape of [N, T\', C\']. Decoder inputs.\n      memory: A 3d tensor with shape of [N, T, C]. Outputs of encoder network.\n      num_units: An int. Attention size.\n      scope: Optional scope for `variable_scope`.  \n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n    \n    Returns:\n      A 3d tensor with shape of [N, T, num_units].    \n    \'\'\'\n    with tf.variable_scope(scope, reuse=reuse):\n        if num_units is None:\n            num_units = inputs.get_shape().as_list[-1]\n        \n        attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(num_units, \n                                                                   memory)\n        decoder_cell = tf.contrib.rnn.GRUCell(num_units)\n        cell_with_attention = tf.contrib.seq2seq.AttentionWrapper(decoder_cell,\n                                                                  attention_mechanism,\n                                                                  num_units,\n                                                                  alignment_history=True)\n        outputs, state = tf.nn.dynamic_rnn(cell_with_attention, inputs, dtype=tf.float32) #( N, T\', 16)\n\n    return outputs, state\n\ndef prenet(inputs, num_units=None, is_training=True, scope=""prenet"", reuse=None):\n    \'\'\'Prenet for Encoder and Decoder1.\n    Args:\n      inputs: A 2D or 3D tensor.\n      num_units: A list of two integers. or None.\n      is_training: A python boolean.\n      scope: Optional scope for `variable_scope`.  \n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n        \n    Returns:\n      A 3D tensor of shape [N, T, num_units/2].\n    \'\'\'\n    if num_units is None:\n        num_units = [hp.embed_size, hp.embed_size//2]\n        \n    with tf.variable_scope(scope, reuse=reuse):\n        outputs = tf.layers.dense(inputs, units=num_units[0], activation=tf.nn.relu, name=""dense1"")\n        outputs = tf.layers.dropout(outputs, rate=hp.dropout_rate, training=is_training, name=""dropout1"")\n        outputs = tf.layers.dense(outputs, units=num_units[1], activation=tf.nn.relu, name=""dense2"")\n        outputs = tf.layers.dropout(outputs, rate=hp.dropout_rate, training=is_training, name=""dropout2"") \n    return outputs # (N, ..., num_units[1])\n\ndef highwaynet(inputs, num_units=None, scope=""highwaynet"", reuse=None):\n    \'\'\'Highway networks, see https://arxiv.org/abs/1505.00387\n\n    Args:\n      inputs: A 3D tensor of shape [N, T, W].\n      num_units: An int or `None`. Specifies the number of units in the highway layer\n             or uses the input size if `None`.\n      scope: Optional scope for `variable_scope`.  \n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n\n    Returns:\n      A 3D tensor of shape [N, T, W].\n    \'\'\'\n    if not num_units:\n        num_units = inputs.get_shape()[-1]\n        \n    with tf.variable_scope(scope, reuse=reuse):\n        H = tf.layers.dense(inputs, units=num_units, activation=tf.nn.relu, name=""dense1"")\n        T = tf.layers.dense(inputs, units=num_units, activation=tf.nn.sigmoid,\n                            bias_initializer=tf.constant_initializer(-1.0), name=""dense2"")\n        outputs = H*T + inputs*(1.-T)\n    return outputs\n'"
networks.py,12,"b'# -*- coding: utf-8 -*-\n#/usr/bin/python2\n\'\'\'\nBy kyubyong park. kbpark.linguist@gmail.com. \nhttps://www.github.com/kyubyong/tacotron\n\'\'\'\n\nfrom __future__ import print_function\n\nfrom hyperparams import Hyperparams as hp\nfrom modules import *\nimport tensorflow as tf\n\n\ndef encoder(inputs, is_training=True, scope=""encoder"", reuse=None):\n    \'\'\'\n    Args:\n      inputs: A 2d tensor with shape of [N, T_x, E], with dtype of int32. Encoder inputs.\n      is_training: Whether or not the layer is in training mode.\n      scope: Optional scope for `variable_scope`\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n    \n    Returns:\n      A collection of Hidden vectors. So-called memory. Has the shape of (N, T_x, E).\n    \'\'\'\n    with tf.variable_scope(scope, reuse=reuse): \n        # Encoder pre-net\n        prenet_out = prenet(inputs, is_training=is_training) # (N, T_x, E/2)\n        \n        # Encoder CBHG \n        ## Conv1D banks\n        enc = conv1d_banks(prenet_out, K=hp.encoder_num_banks, is_training=is_training) # (N, T_x, K*E/2)\n        \n        ## Max pooling\n        enc = tf.layers.max_pooling1d(enc, pool_size=2, strides=1, padding=""same"")  # (N, T_x, K*E/2)\n          \n        ## Conv1D projections\n        enc = conv1d(enc, filters=hp.embed_size//2, size=3, scope=""conv1d_1"") # (N, T_x, E/2)\n        enc = bn(enc, is_training=is_training, activation_fn=tf.nn.relu, scope=""conv1d_1"")\n\n        enc = conv1d(enc, filters=hp.embed_size // 2, size=3, scope=""conv1d_2"")  # (N, T_x, E/2)\n        enc = bn(enc, is_training=is_training, scope=""conv1d_2"")\n\n        enc += prenet_out # (N, T_x, E/2) # residual connections\n          \n        ## Highway Nets\n        for i in range(hp.num_highwaynet_blocks):\n            enc = highwaynet(enc, num_units=hp.embed_size//2, \n                                 scope=\'highwaynet_{}\'.format(i)) # (N, T_x, E/2)\n\n        ## Bidirectional GRU\n        memory = gru(enc, num_units=hp.embed_size//2, bidirection=True) # (N, T_x, E)\n    \n    return memory\n        \ndef decoder1(inputs, memory, is_training=True, scope=""decoder1"", reuse=None):\n    \'\'\'\n    Args:\n      inputs: A 3d tensor with shape of [N, T_y/r, n_mels(*r)]. Shifted log melspectrogram of sound files.\n      memory: A 3d tensor with shape of [N, T_x, E].\n      is_training: Whether or not the layer is in training mode.\n      scope: Optional scope for `variable_scope`\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n        \n    Returns\n      Predicted log melspectrogram tensor with shape of [N, T_y/r, n_mels*r].\n    \'\'\'\n    with tf.variable_scope(scope, reuse=reuse):\n        # Decoder pre-net\n        inputs = prenet(inputs, is_training=is_training)  # (N, T_y/r, E/2)\n\n        # Attention RNN\n        dec, state = attention_decoder(inputs, memory, num_units=hp.embed_size) # (N, T_y/r, E)\n\n        ## for attention monitoring\n        alignments = tf.transpose(state.alignment_history.stack(),[1,2,0])\n\n        # Decoder RNNs\n        dec += gru(dec, hp.embed_size, bidirection=False, scope=""decoder_gru1"") # (N, T_y/r, E)\n        dec += gru(dec, hp.embed_size, bidirection=False, scope=""decoder_gru2"") # (N, T_y/r, E)\n          \n        # Outputs => (N, T_y/r, n_mels*r)\n        mel_hats = tf.layers.dense(dec, hp.n_mels*hp.r)\n    \n    return mel_hats, alignments\n\ndef decoder2(inputs, is_training=True, scope=""decoder2"", reuse=None):\n    \'\'\'Decoder Post-processing net = CBHG\n    Args:\n      inputs: A 3d tensor with shape of [N, T_y/r, n_mels*r]. Log magnitude spectrogram of sound files.\n        It is recovered to its original shape.\n      is_training: Whether or not the layer is in training mode.  \n      scope: Optional scope for `variable_scope`\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n        \n    Returns\n      Predicted linear spectrogram tensor with shape of [N, T_y, 1+n_fft//2].\n    \'\'\'\n    with tf.variable_scope(scope, reuse=reuse):\n        # Restore shape -> (N, Ty, n_mels)\n        inputs = tf.reshape(inputs, [tf.shape(inputs)[0], -1, hp.n_mels])\n\n        # Conv1D bank\n        dec = conv1d_banks(inputs, K=hp.decoder_num_banks, is_training=is_training) # (N, T_y, E*K/2)\n         \n        # Max pooling\n        dec = tf.layers.max_pooling1d(dec, pool_size=2, strides=1, padding=""same"") # (N, T_y, E*K/2)\n\n        ## Conv1D projections\n        dec = conv1d(dec, filters=hp.embed_size // 2, size=3, scope=""conv1d_1"")  # (N, T_x, E/2)\n        dec = bn(dec, is_training=is_training, activation_fn=tf.nn.relu, scope=""conv1d_1"")\n\n        dec = conv1d(dec, filters=hp.n_mels, size=3, scope=""conv1d_2"")  # (N, T_x, E/2)\n        dec = bn(dec, is_training=is_training, scope=""conv1d_2"")\n\n        # Extra affine transformation for dimensionality sync\n        dec = tf.layers.dense(dec, hp.embed_size//2) # (N, T_y, E/2)\n         \n        # Highway Nets\n        for i in range(4):\n            dec = highwaynet(dec, num_units=hp.embed_size//2, \n                                 scope=\'highwaynet_{}\'.format(i)) # (N, T_y, E/2)\n         \n        # Bidirectional GRU    \n        dec = gru(dec, hp.embed_size//2, bidirection=True) # (N, T_y, E)\n        \n        # Outputs => (N, T_y, 1+n_fft//2)\n        outputs = tf.layers.dense(dec, 1+hp.n_fft//2)\n\n    return outputs\n'"
prepro.py,0,"b'# -*- coding: utf-8 -*-\n#/usr/bin/python2\n\'\'\'\nBy kyubyong park. kbpark.linguist@gmail.com.\nhttps://www.github.com/kyubyong/tacotron\n\'\'\'\n\nfrom __future__ import print_function\n\nfrom utils import load_spectrograms\nimport os\nfrom data_load import load_data\nimport numpy as np\nimport tqdm\n\n# Load data\nfpaths, _, _ = load_data() # list\n\nfor fpath in tqdm.tqdm(fpaths):\n    fname, mel, mag = load_spectrograms(fpath)\n    if not os.path.exists(""mels""): os.mkdir(""mels"")\n    if not os.path.exists(""mags""): os.mkdir(""mags"")\n\n    np.save(""mels/{}"".format(fname.replace(""wav"", ""npy"")), mel)\n    np.save(""mags/{}"".format(fname.replace(""wav"", ""npy"")), mag)'"
synthesize.py,3,"b'# -*- coding: utf-8 -*-\n# /usr/bin/python2\n\'\'\'\nBy kyubyong park. kbpark.linguist@gmail.com.\nhttps://www.github.com/kyubyong/tacotron\n\'\'\'\n\nfrom __future__ import print_function\n\nfrom hyperparams import Hyperparams as hp\nimport tqdm\nfrom data_load import load_data\nimport tensorflow as tf\nfrom train import Graph\nfrom utils import spectrogram2wav\nfrom scipy.io.wavfile import write\nimport os\nimport numpy as np\n\n\ndef synthesize():\n    if not os.path.exists(hp.sampledir): os.mkdir(hp.sampledir)\n\n    # Load graph\n    g = Graph(mode=""synthesize""); print(""Graph loaded"")\n\n    # Load data\n    texts = load_data(mode=""synthesize"")\n\n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        saver.restore(sess, tf.train.latest_checkpoint(hp.logdir)); print(""Restored!"")\n\n        # Feed Forward\n        ## mel\n        y_hat = np.zeros((texts.shape[0], 200, hp.n_mels*hp.r), np.float32)  # hp.n_mels*hp.r\n        for j in tqdm.tqdm(range(200)):\n            _y_hat = sess.run(g.y_hat, {g.x: texts, g.y: y_hat})\n            y_hat[:, j, :] = _y_hat[:, j, :]\n        ## mag\n        mags = sess.run(g.z_hat, {g.y_hat: y_hat})\n        for i, mag in enumerate(mags):\n            print(""File {}.wav is being generated ..."".format(i+1))\n            audio = spectrogram2wav(mag)\n            write(os.path.join(hp.sampledir, \'{}.wav\'.format(i+1)), hp.sr, audio)\n\nif __name__ == \'__main__\':\n    synthesize()\n    print(""Done"")\n\n'"
train.py,24,"b'# -*- coding: utf-8 -*-\n#/usr/bin/python2\n\'\'\'\nBy kyubyong park. kbpark.linguist@gmail.com. \nhttps://www.github.com/kyubyong/tacotron\n\'\'\'\n\nfrom __future__ import print_function\n\nimport os\nfrom hyperparams import Hyperparams as hp\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom data_load import get_batch, load_vocab\nfrom modules import *\nfrom networks import encoder, decoder1, decoder2\nfrom utils import *\n\nclass Graph:\n    def __init__(self, mode=""train""):\n        # Load vocabulary\n        self.char2idx, self.idx2char = load_vocab()\n\n        # Set phase\n        is_training=True if mode==""train"" else False\n\n        # Graph\n        # Data Feeding\n        # x: Text. (N, Tx)\n        # y: Reduced melspectrogram. (N, Ty//r, n_mels*r)\n        # z: Magnitude. (N, Ty, n_fft//2+1)\n        if mode==""train"":\n            self.x, self.y, self.z, self.fnames, self.num_batch = get_batch()\n        elif mode==""eval"":\n            self.x = tf.placeholder(tf.int32, shape=(None, None))\n            self.y = tf.placeholder(tf.float32, shape=(None, None, hp.n_mels*hp.r))\n            self.z = tf.placeholder(tf.float32, shape=(None, None, 1+hp.n_fft//2))\n            self.fnames = tf.placeholder(tf.string, shape=(None,))\n        else: # Synthesize\n            self.x = tf.placeholder(tf.int32, shape=(None, None))\n            self.y = tf.placeholder(tf.float32, shape=(None, None, hp.n_mels * hp.r))\n\n        # Get encoder/decoder inputs\n        self.encoder_inputs = embed(self.x, len(hp.vocab), hp.embed_size) # (N, T_x, E)\n        self.decoder_inputs = tf.concat((tf.zeros_like(self.y[:, :1, :]), self.y[:, :-1, :]), 1) # (N, Ty/r, n_mels*r)\n        self.decoder_inputs = self.decoder_inputs[:, :, -hp.n_mels:] # feed last frames only (N, Ty/r, n_mels)\n\n        # Networks\n        with tf.variable_scope(""net""):\n            # Encoder\n            self.memory = encoder(self.encoder_inputs, is_training=is_training) # (N, T_x, E)\n\n            # Decoder1\n            self.y_hat, self.alignments = decoder1(self.decoder_inputs,\n                                                     self.memory,\n                                                     is_training=is_training) # (N, T_y//r, n_mels*r)\n            # Decoder2 or postprocessing\n            self.z_hat = decoder2(self.y_hat, is_training=is_training) # (N, T_y//r, (1+n_fft//2)*r)\n\n        # monitor\n        self.audio = tf.py_func(spectrogram2wav, [self.z_hat[0]], tf.float32)\n\n        if mode in (""train"", ""eval""):\n            # Loss\n            self.loss1 = tf.reduce_mean(tf.abs(self.y_hat - self.y))\n            self.loss2 = tf.reduce_mean(tf.abs(self.z_hat - self.z))\n            self.loss = self.loss1 + self.loss2\n\n            # Training Scheme\n            self.global_step = tf.Variable(0, name=\'global_step\', trainable=False)\n            self.lr = learning_rate_decay(hp.lr, global_step=self.global_step)\n            self.optimizer = tf.train.AdamOptimizer(learning_rate=self.lr)\n\n            ## gradient clipping\n            self.gvs = self.optimizer.compute_gradients(self.loss)\n            self.clipped = []\n            for grad, var in self.gvs:\n                grad = tf.clip_by_norm(grad, 5.)\n                self.clipped.append((grad, var))\n            self.train_op = self.optimizer.apply_gradients(self.clipped, global_step=self.global_step)\n\n            # Summary\n            tf.summary.scalar(\'{}/loss1\'.format(mode), self.loss1)\n            tf.summary.scalar(\'{}/loss\'.format(mode), self.loss)\n            tf.summary.scalar(\'{}/lr\'.format(mode), self.lr)\n\n            tf.summary.image(""{}/mel_gt"".format(mode), tf.expand_dims(self.y, -1), max_outputs=1)\n            tf.summary.image(""{}/mel_hat"".format(mode), tf.expand_dims(self.y_hat, -1), max_outputs=1)\n            tf.summary.image(""{}/mag_gt"".format(mode), tf.expand_dims(self.z, -1), max_outputs=1)\n            tf.summary.image(""{}/mag_hat"".format(mode), tf.expand_dims(self.z_hat, -1), max_outputs=1)\n\n            tf.summary.audio(""{}/sample"".format(mode), tf.expand_dims(self.audio, 0), hp.sr)\n            self.merged = tf.summary.merge_all()\n         \nif __name__ == \'__main__\':\n    g = Graph(); print(""Training Graph loaded"")\n    \n    # with g.graph.as_default():\n    sv = tf.train.Supervisor(logdir=hp.logdir, save_summaries_secs=60, save_model_secs=0)\n    with sv.managed_session() as sess:\n        while 1:\n            for _ in tqdm(range(g.num_batch), total=g.num_batch, ncols=70, leave=False, unit=\'b\'):\n                _, gs = sess.run([g.train_op, g.global_step])\n\n                # Write checkpoint files\n                if gs % 1000 == 0:\n                    sv.saver.save(sess, hp.logdir + \'/model_gs_{}k\'.format(gs//1000))\n\n                    # plot the first alignment for logging\n                    al = sess.run(g.alignments)\n                    plot_alignment(al[0], gs)\n\n    print(""Done"")\n'"
utils.py,2,"b'# -*- coding: utf-8 -*-\n# /usr/bin/python2\n\'\'\'\nBy kyubyong park. kbpark.linguist@gmail.com.\nhttps://www.github.com/kyubyong/dc_tts\n\'\'\'\nfrom __future__ import print_function, division\n\nfrom hyperparams import Hyperparams as hp\nimport numpy as np\nimport tensorflow as tf\nimport librosa\nimport copy\nimport matplotlib\nmatplotlib.use(\'pdf\')\nimport matplotlib.pyplot as plt\nfrom scipy import signal\nimport os\n\n\ndef get_spectrograms(fpath):\n    \'\'\'Returns normalized log(melspectrogram) and log(magnitude) from `sound_file`.\n    Args:\n      sound_file: A string. The full path of a sound file.\n\n    Returns:\n      mel: A 2d array of shape (T, n_mels) <- Transposed\n      mag: A 2d array of shape (T, 1+n_fft/2) <- Transposed\n    \'\'\'\n    # num = np.random.randn()\n    # if num < .2:\n    #     y, sr = librosa.load(fpath, sr=hp.sr)\n    # else:\n    #     if num < .4:\n    #         tempo = 1.1\n    #     elif num < .6:\n    #         tempo = 1.2\n    #     elif num < .8:\n    #         tempo = 0.9\n    #     else:\n    #         tempo = 0.8\n    #     cmd = ""ffmpeg -i {} -y ar {} -hide_banner -loglevel panic -ac 1 -filter:a atempo={} -vn temp.wav"".format(fpath, hp.sr, tempo)\n    #     os.system(cmd)\n    #     y, sr = librosa.load(\'temp.wav\', sr=hp.sr)\n\n    # Loading sound file\n    y, sr = librosa.load(fpath, sr=hp.sr)\n\n\n    # Trimming\n    y, _ = librosa.effects.trim(y)\n\n    # Preemphasis\n    y = np.append(y[0], y[1:] - hp.preemphasis * y[:-1])\n\n    # stft\n    linear = librosa.stft(y=y,\n                          n_fft=hp.n_fft,\n                          hop_length=hp.hop_length,\n                          win_length=hp.win_length)\n\n    # magnitude spectrogram\n    mag = np.abs(linear)  # (1+n_fft//2, T)\n\n    # mel spectrogram\n    mel_basis = librosa.filters.mel(hp.sr, hp.n_fft, hp.n_mels)  # (n_mels, 1+n_fft//2)\n    mel = np.dot(mel_basis, mag)  # (n_mels, t)\n\n    # to decibel\n    mel = 20 * np.log10(np.maximum(1e-5, mel))\n    mag = 20 * np.log10(np.maximum(1e-5, mag))\n\n    # normalize\n    mel = np.clip((mel - hp.ref_db + hp.max_db) / hp.max_db, 1e-8, 1)\n    mag = np.clip((mag - hp.ref_db + hp.max_db) / hp.max_db, 1e-8, 1)\n\n    # Transpose\n    mel = mel.T.astype(np.float32)  # (T, n_mels)\n    mag = mag.T.astype(np.float32)  # (T, 1+n_fft//2)\n\n    return mel, mag\n\n\ndef spectrogram2wav(mag):\n    \'\'\'# Generate wave file from spectrogram\'\'\'\n    # transpose\n    mag = mag.T\n\n    # de-noramlize\n    mag = (np.clip(mag, 0, 1) * hp.max_db) - hp.max_db + hp.ref_db\n\n    # to amplitude\n    mag = np.power(10.0, mag * 0.05)\n\n    # wav reconstruction\n    wav = griffin_lim(mag)\n\n    # de-preemphasis\n    wav = signal.lfilter([1], [1, -hp.preemphasis], wav)\n\n    # trim\n    wav, _ = librosa.effects.trim(wav)\n\n    return wav.astype(np.float32)\n\n\ndef griffin_lim(spectrogram):\n    \'\'\'Applies Griffin-Lim\'s raw.\n    \'\'\'\n    X_best = copy.deepcopy(spectrogram)\n    for i in range(hp.n_iter):\n        X_t = invert_spectrogram(X_best)\n        est = librosa.stft(X_t, hp.n_fft, hp.hop_length, win_length=hp.win_length)\n        phase = est / np.maximum(1e-8, np.abs(est))\n        X_best = spectrogram * phase\n    X_t = invert_spectrogram(X_best)\n    y = np.real(X_t)\n\n    return y\n\n\ndef invert_spectrogram(spectrogram):\n    \'\'\'\n    spectrogram: [f, t]\n    \'\'\'\n    return librosa.istft(spectrogram, hp.hop_length, win_length=hp.win_length, window=""hann"")\n\n\ndef plot_alignment(alignment, gs):\n    """"""Plots the alignment\n    alignments: A list of (numpy) matrix of shape (encoder_steps, decoder_steps)\n    gs : (int) global step\n    """"""\n    fig, ax = plt.subplots()\n    im = ax.imshow(alignment)\n\n    # cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n    fig.colorbar(im)\n    plt.title(\'{} Steps\'.format(gs))\n    plt.savefig(\'{}/alignment_{}k.png\'.format(hp.logdir, gs//1000), format=\'png\')\n\ndef learning_rate_decay(init_lr, global_step, warmup_steps=4000.):\n    \'\'\'Noam scheme from tensor2tensor\'\'\'\n    step = tf.cast(global_step + 1, dtype=tf.float32)\n    return init_lr * warmup_steps ** 0.5 * tf.minimum(step * warmup_steps ** -1.5, step ** -0.5)\n\ndef load_spectrograms(fpath):\n    fname = os.path.basename(fpath)\n    mel, mag = get_spectrograms(fpath)\n    t = mel.shape[0]\n    num_paddings = hp.r - (t % hp.r) if t % hp.r != 0 else 0 # for reduction\n    mel = np.pad(mel, [[0, num_paddings], [0, 0]], mode=""constant"")\n    mag = np.pad(mag, [[0, num_paddings], [0, 0]], mode=""constant"")\n    return fname, mel.reshape((-1, hp.n_mels*hp.r)), mag\n'"
