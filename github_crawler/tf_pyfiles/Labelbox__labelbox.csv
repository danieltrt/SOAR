file_path,api_count,code
custom-interfaces/video-segmentation-beaverdam/manage.py,0,"b'#!/usr/bin/env python\nimport os\nimport sys\n\nif __name__ == ""__main__"":\n    os.environ.setdefault(""DJANGO_SETTINGS_MODULE"", ""beaverdam.settings"")\n\n    from django.core.management import execute_from_command_line\n\n    execute_from_command_line(sys.argv)\n'"
docs/tfrecord-export/decode_tfrecord_export.py,16,"b'import sys\nfrom json import load\nfrom math import floor\nimport os\nfrom PIL import Image\nimport requests\nimport tensorflow as tf\n\n\ndef fail_for_missing_file():\n    print(\'You must provide the path to export.json file.\')\n    sys.exit(1)\n\n\nif __name__ == \'__main__\':\n\n    if len(sys.argv) < 2:\n        fail_for_missing_file()\n\n    export_file = sys.argv[1]\n\n    if not export_file:\n        fail_for_missing_file()\n\n    with open(export_file) as f:\n        export_json = load(f)\n\n    legend = export_json[\'legend\']\n    tfrecord_paths = export_json[\'tfrecord_paths\']\n\n    if not os.path.isdir(\'./output\'):\n        os.mkdir(\'./output\')\n    with tf.name_scope(\'input\'), tf.Session() as sess:\n        dataset_iterator = (tf.data.TFRecordDataset([tfrecord_paths])\n                .map(lambda example: tf.parse_single_example(\n                    example,\n                    features={\n                        \'image/encoded\': tf.FixedLenFeature([], tf.string),\n                        \'image/filename\': tf.FixedLenFeature([], tf.string),\n                        \'image/ID\': tf.FixedLenFeature([], tf.string),\n                        \'image/format\': tf.FixedLenFeature([], tf.string),\n                        \'image/height\': tf.FixedLenFeature([], tf.int64),\n                        \'image/width\': tf.FixedLenFeature([], tf.int64),\n                        \'image/channels\': tf.FixedLenFeature([], tf.int64),\n                        \'image/colorspace\': tf.FixedLenFeature([], tf.string),\n                        \'image/segmentation/class/encoded\': tf.FixedLenFeature([], tf.string),\n                        \'image/segmentation/class/format\': tf.FixedLenFeature([], tf.string),\n                        }))\n                .shuffle(buffer_size=10)\n                .make_one_shot_iterator())\n\n        try:\n            print(\'Pixel value to label legend:\\n{}\'.format(legend))\n            while True:\n                example = dataset_iterator.get_next()\n\n                ID, image, label, colorspace = sess.run([\n                    example[\'image/ID\'],\n                    tf.image.decode_image(example[\'image/encoded\']),\n                    tf.image.decode_image(example[\'image/segmentation/class/encoded\']),\n                    example[\'image/colorspace\']\n                    ])\n                ID = ID.decode(\'utf-8\')\n                colorspace = colorspace.decode(\'utf-8\')\n\n                image_output_path = \'output/{}.jpg\'.format(ID)\n                print(\'Writing image for label ID {} to {}\'.format(ID, image_output_path))\n                Image.fromarray(image, mode=colorspace).save(image_output_path)\n                input(""Press ENTER to continue..."")\n\n                label_output_path = \'output/{}-label.jpg\'.format(ID)\n                print(\'Writing label for label ID {} to {}\'.format(ID, label_output_path))\n                # Tensorflow returns a 3D array from `decode_image`, but `Image.fromarray(... mode=\'L\')` needs 2D\n                label = label[:,:,0]\n                # Multiplication to scale labels for increased visibility\n                Image.fromarray(floor(255 / len(legend.keys())) * label, mode=\'L\').save(label_output_path)\n                input(""Press ENTER to continue..."")\n\n        except tf.errors.OutOfRangeError:\n            print(\'Dataset iterator exhausted\')\n'"
exporters/coco-exporter/coco_exporter.py,0,"b'""""""\nModule for converting labelbox.com JSON exports to MS COCO format.\n""""""\n\nimport datetime as dt\nimport json\nimport logging\nfrom typing import Any, Dict\n\nfrom PIL import Image\nimport requests\nfrom shapely import wkt\nfrom shapely.geometry import Polygon\n\nfrom exceptions import UnknownFormatError\n\n\nLOGGER = logging.getLogger(__name__)\n\n\ndef from_json(labeled_data, coco_output, label_format=\'XY\'):\n    ""Writes labelbox JSON export into MS COCO format.""\n    # read labelbox JSON output\n    with open(labeled_data, \'r\') as file_handle:\n        label_data = json.loads(file_handle.read())\n\n    # setup COCO dataset container and info\n    coco = make_coco_metadata(label_data[0][\'Project Name\'], label_data[0][\'Created By\'],)\n\n    for data in label_data:\n        # Download and get image name\n        try:\n            add_label(coco, data[\'ID\'], data[\'Labeled Data\'], data[\'Label\'], label_format)\n        except requests.exceptions.MissingSchema as exc:\n            LOGGER.warning(exc)\n            continue\n        except requests.exceptions.ConnectionError:\n            LOGGER.warning(\'Failed to fetch image from %s, skipping\', data[\'Labeled Data\'])\n            continue\n\n    with open(coco_output, \'w+\') as file_handle:\n        file_handle.write(json.dumps(coco))\n\n\ndef make_coco_metadata(project_name: str, created_by: str) -> Dict[str, Any]:\n    """"""Initializes COCO export data structure.\n\n    Args:\n        project_name: name of the project\n        created_by: email of the project creator\n\n    Returns:\n        The COCO export represented as a dictionary.\n    """"""\n    return {\n        \'info\': {\n            \'year\': dt.datetime.now(dt.timezone.utc).year,\n            \'version\': None,\n            \'description\': project_name,\n            \'contributor\': created_by,\n            \'url\': \'labelbox.com\',\n            \'date_created\': dt.datetime.now(dt.timezone.utc).isoformat()\n        },\n        \'images\': [],\n        \'annotations\': [],\n        \'licenses\': [],\n        \'categories\': []\n    }\n\n\ndef add_label(\n        coco: Dict[str, Any], label_id: str, image_url: str,\n        labels: Dict[str, Any], label_format: str):\n    """"""Incrementally updates COCO export data structure with a new label.\n\n    Args:\n        coco: The current COCO export, will be incrementally updated by this method.\n        label_id: ID for the instance to write\n        image_url: URL to download image file from\n        labels: Labelbox formatted labels to use for generating annotation\n        label_format: Format of the labeled data. Valid options are: ""WKT"" and\n                      ""XY"", default is ""XY"".\n\n    Returns:\n        The updated COCO export represented as a dictionary.\n    """"""\n    image = {\n        ""id"": label_id,\n        ""file_name"": image_url,\n        ""license"": None,\n        ""flickr_url"": image_url,\n        ""coco_url"": image_url,\n        ""date_captured"": None,\n    }\n    response = requests.get(image_url, stream=True, timeout=10.0)\n    response.raw.decode_content = True\n    image[\'width\'], image[\'height\'] = Image.open(response.raw).size\n\n    coco[\'images\'].append(image)\n\n    # remove classification labels (Skip, etc...)\n    if not callable(getattr(labels, \'keys\', None)):\n        return\n\n    # convert label to COCO Polygon format\n    for category_name, label_data in labels.items():\n        try:\n            # check if label category exists in \'categories\' field\n            category_id = [c[\'id\']\n                           for c in coco[\'categories\']\n                           if c[\'supercategory\'] == category_name][0]\n        except IndexError:\n            category_id = len(coco[\'categories\']) + 1\n            category = {\n                \'supercategory\': category_name,\n                \'id\': category_id,\n                \'name\': category_name\n            }\n            coco[\'categories\'].append(category)\n\n        polygons = _get_polygons(label_format, label_data)\n        _append_polygons_as_annotations(coco, image, category_id, polygons)\n\n\ndef _append_polygons_as_annotations(coco, image, category_id, polygons):\n    ""Adds `polygons` as annotations in the `coco` export""\n    for polygon in polygons:\n        segmentation = []\n        for x_val, y_val in polygon.exterior.coords:\n            segmentation.extend([x_val, y_val])\n\n        annotation = {\n            ""id"": len(coco[\'annotations\']) + 1,\n            ""image_id"": image[\'id\'],\n            ""category_id"": category_id,\n            ""segmentation"": [segmentation],\n            ""area"": polygon.area,  # float\n            ""bbox"": [polygon.bounds[0], polygon.bounds[1],\n                     polygon.bounds[2] - polygon.bounds[0],\n                     polygon.bounds[3] - polygon.bounds[1]],\n            ""iscrowd"": 0\n        }\n\n        coco[\'annotations\'].append(annotation)\n\n\ndef _get_polygons(label_format, label_data):\n    ""Converts segmentation `label: String!` into polygons""\n    if label_format == \'WKT\':\n        if isinstance(label_data, list):  # V3\n            polygons = map(lambda x: wkt.loads(x[\'geometry\']), label_data)\n        else:  # V2\n            polygons = wkt.loads(label_data)\n    elif label_format == \'XY\':\n        polygons = []\n        for xy_list in label_data:\n            if \'geometry\' in xy_list:  # V3\n                xy_list = xy_list[\'geometry\']\n\n                # V2 and V3\n                if not isinstance(xy_list, list):\n                    LOGGER.warning(\'Could not get an point list to construct polygon, skipping\')\n                    continue\n            else:  # V2, or non-list\n                if not isinstance(xy_list, list) or not xy_list or \'x\' not in xy_list[0]:\n                    # skip non xy lists\n                    LOGGER.warning(\'Could not get an point list to construct polygon, skipping\')\n                    continue\n\n            if len(xy_list) > 2:  # need at least 3 points to make a polygon\n                polygons.append(Polygon(map(lambda p: (p[\'x\'], p[\'y\']), xy_list)))\n    else:\n        exc = UnknownFormatError(label_format=label_format)\n        LOGGER.exception(exc.message)\n        raise exc\n\n    return polygons\n'"
exporters/coco-exporter/exceptions.py,0,"b'""""""\nException classes for the labelbox python package.\n""""""\n\n\nclass UnknownFormatError(Exception):\n    """"""Exception raised for unknown label_format""""""\n\n    def __init__(self, label_format):\n        Exception.__init__(self)\n        self.message = ""Provided label_format \'{}\' is unsupported"".format(label_format)'"
exporters/coco-exporter/main.py,0,"b'import argparse\nimport json\nimport os\nimport logging\nimport traceback as tb\n\nimport coco_exporter\n\nlogging.basicConfig(level=logging.INFO)\nLOGGER = logging.getLogger(__name__)\n\ndef export(file_input, file_output):\n    ""Uses COCO exporter function from_json to convert labelbox JSON into MS COCO format.""\n\n    try:\n        artifact = \'{}/coco.json\'.format(file_output)\n        os.makedirs(file_output, exist_ok=True)\n        LOGGER.info(\'Creating coco export\')\n\n        coco_exporter.from_json(file_input, artifact)\n\n        LOGGER.info(\'Done saving coco export\')\n\n    except Exception as e:\n        tb.print_exc()\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'file_input\', help=\'File path to Labelbox JSON to parse export\')\n    parser.add_argument(\'file_output\', help=\'File path to desired output directory for export asset\')\n\n    args = parser.parse_args()\n\n    file_input = args.file_input\n    assert file_input\n\n    file_output = args.file_output\n    assert file_output\n\n    export(file_input, file_output)'"
exporters/voc-exporter/__init__.py,0,b''
exporters/voc-exporter/exceptions.py,0,"b'""""""\nException classes for the labelbox python package.\n""""""\n\n\nclass UnknownFormatError(Exception):\n    """"""Exception raised for unknown label_format""""""\n\n    def __init__(self, label_format):\n        Exception.__init__(self)\n        self.message = ""Provided label_format \'{}\' is unsupported"".format(label_format)'"
exporters/voc-exporter/main.py,0,"b'import argparse\nimport json\nimport os\nimport logging\nimport traceback as tb\n\nimport voc_exporter\n\nlogging.basicConfig(level=logging.INFO)\nLOGGER = logging.getLogger(__name__)\n\ndef export(file_input, file_output, image_output):\n    ""Uses VOC exporter function from_json to convert labelbox JSON into MS VOC format.""\n\n    try:\n        os.makedirs(file_output, exist_ok=True)\n        os.makedirs(image_output, exist_ok=True)\n        LOGGER.info(\'Creating voc export\')\n\n        voc_exporter.from_json(file_input, file_output, image_output)\n\n        LOGGER.info(\'Done saving voc export\')\n\n    except Exception as e:\n        tb.print_exc()\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'file_input\', help=\'File path to Labelbox JSON to parse export\')\n    parser.add_argument(\'file_output\', help=\'File path to desired output directory for export asset\')\n\n    args = parser.parse_args()\n\n    file_input = args.file_input\n    assert file_input\n\n    file_output = args.file_output\n    assert file_output\n\n    image_output = file_output + \'/images\'\n\n    export(file_input, file_output, image_output)'"
exporters/voc-exporter/voc_exporter.py,0,"b'""""""\nModule for converting labelbox.com JSON exports to Pascal VOC 2012 format.\n""""""\n\nimport json\nimport logging\nimport os\nfrom typing import Any, Dict\n\nfrom PIL import Image\nimport requests\nfrom shapely import wkt\n\nfrom exceptions import UnknownFormatError\nfrom pascal_voc_writer import Writer as PascalWriter\n\n\nLOGGER = logging.getLogger(__name__)\n\n\ndef from_json(labeled_data, annotations_output_dir, images_output_dir,\n              label_format=\'XY\'):\n    """"""Convert Labelbox JSON export to Pascal VOC format.\n\n    Args:\n        labeled_data (str): File path to Labelbox JSON export of label data.\n        annotations_output_dir (str): File path of directory to write Pascal VOC\n            annotation files.\n        images_output_dir (str): File path of directory to write images.\n        label_format (str): Format of the labeled data.\n            Valid options are: ""WKT"" and ""XY"", default is ""XY"".\n    """"""\n\n    # make sure annotation output directory is valid\n    try:\n        annotations_output_dir = os.path.abspath(annotations_output_dir)\n        assert os.path.isdir(annotations_output_dir)\n    except AssertionError as exc:\n        LOGGER.exception(\'Annotation output directory does not exist, please create it first.\')\n        raise exc\n\n    # read labelbox JSON output\n    with open(labeled_data, \'r\') as file_handle:\n        lines = file_handle.readlines()\n        label_data = json.loads(lines[0])\n\n    for data in label_data:\n        try:\n            write_label(\n                data[\'ID\'],\n                data[\'Labeled Data\'],\n                data[\'Label\'],\n                label_format,\n                images_output_dir,\n                annotations_output_dir)\n\n        except requests.exceptions.MissingSchema as exc:\n            LOGGER.warning(exc)\n            continue\n        except requests.exceptions.ConnectionError:\n            LOGGER.warning(\'Failed to fetch image from %s, skipping\', data[\'Labeled Data\'])\n            continue\n\n\ndef write_label(  # pylint: disable-msg=too-many-arguments\n        label_id: str, image_url: str, labels: Dict[str, Any], label_format: str,\n        images_output_dir: str, annotations_output_dir: str):\n    """"""Writes a single Pascal VOC formatted image and label pair to disk.\n\n    Args:\n        label_id: ID for the instance to write\n        image_url: URL to download image file from\n        labels: Labelbox formatted labels to use for generating annotation\n        label_format: Format of the labeled data. Valid options are: ""WKT"" and\n                      ""XY"", default is ""XY"".\n        annotations_output_dir: File path of directory to write Pascal VOC\n                                annotation files.\n        images_output_dir: File path of directory to write images.\n    """"""\n    # Download image and save it\n    response = requests.get(image_url, stream=True, timeout=10.0)\n    response.raw.decode_content = True\n    image = Image.open(response.raw)\n    image_fqn = os.path.join(\n        images_output_dir,\n        \'{img_id}.{ext}\'.format(img_id=label_id, ext=image.format.lower()))\n    image.save(image_fqn, format=image.format)\n\n    # generate image annotation in Pascal VOC\n    width, height = image.size\n    xml_writer = PascalWriter(image_fqn, width, height)\n\n    # remove classification labels (Skip, etc...)\n    if not callable(getattr(labels, \'keys\', None)):\n        # skip if no categories (e.g. ""Skip"")\n        return\n\n    # convert label to Pascal VOC format\n    for category_name, paths in labels.items():\n        if label_format == \'WKT\':\n            xml_writer = _add_pascal_object_from_wkt(\n                xml_writer, wkt_data=paths, label=category_name)\n        elif label_format == \'XY\':\n            xml_writer = _add_pascal_object_from_xy(xml_writer, polygons=paths, label=category_name)\n        else:\n            exc = UnknownFormatError(label_format=label_format)\n            logging.exception(exc.message)\n            raise exc\n\n    # write Pascal VOC xml annotation for image\n    xml_writer.save(os.path.join(annotations_output_dir, \'{}.xml\'.format(label_id)))\n\n\ndef _add_pascal_object_from_wkt(xml_writer, wkt_data, label):\n    polygons = []\n    if isinstance(wkt_data, list):  # V3+\n        polygons = map(lambda x: wkt.loads(x[\'geometry\']), wkt_data)\n    else:  # V2\n        polygons = wkt.loads(wkt_data)\n\n    for point in polygons:\n        xy_coords = []\n        for x_val, y_val in point.exterior.coords:\n            xy_coords.extend([x_val, y_val])\n        # remove last polygon if it is identical to first point\n        if xy_coords[-2:] == xy_coords[:2]:\n            xy_coords = xy_coords[:-2]\n        xml_writer.add_object(name=label, xy_coords=xy_coords)\n    return xml_writer\n\n\ndef _add_pascal_object_from_xy(xml_writer, polygons, label):\n    if not isinstance(polygons, list):\n        LOGGER.warning(\'polygons is not [{geometry: [xy]}] nor [[xy]], skipping\')\n        return xml_writer\n    for polygon in polygons:\n        if \'geometry\' in polygon:  # V3\n            polygon = polygon[\'geometry\']\n        if not isinstance(polygon, list) \\\n                or not all(map(lambda p: \'x\' in p and \'y\' in p, polygon)):\n            LOGGER.warning(\'Could not get an point list to construct polygon, skipping\')\n            return xml_writer\n\n        xy_coords = []\n        for point in polygon:\n            xy_coords.extend([point[\'x\'], point[\'y\']])\n        xml_writer.add_object(name=label, xy_coords=xy_coords)\n    return xml_writer\n'"
custom-interfaces/video-segmentation-beaverdam/annotator/__init__.py,0,b''
custom-interfaces/video-segmentation-beaverdam/annotator/admin.py,0,"b'from django.contrib import admin\nfrom django.contrib.admin import SimpleListFilter\nfrom .models import Video, Label, State\nfrom mturk.models import FullVideoTask\nfrom mturk.queries import get_active_video_turk_task\nfrom django.db.models import Count, Sum, Q, Case, When, IntegerField\nimport logging\n\nlogger = logging.getLogger() \n\ndef publish_to_turk(modeladmin, request, videos):\n    for video in videos:\n        video_task = get_active_video_turk_task(video.id)\n\n        if video_task != None:\n            raise Exception(\'video {} already has an active FullVideoTask\'.format(id))\n\n        video_task = FullVideoTask(video = video)\n        video_task.publish()\n\nclass PublishedFilter(SimpleListFilter):\n    title = \'Currently Published\' # or use _(\'country\') for translated title\n    parameter_name = \'Published\'\n    default_value = 2\n\n    def lookups(self, request, model_admin):\n        return (\n        (""1"", \'Yes\'),\n        (""0"", \'No\'),\n    )\n \n    def queryset(self, request, queryset):\n        if self.value() is None:\n            return queryset\n        else:\n            self.used_parameters[self.parameter_name] = self.value()\n\n        if self.value() == ""0"":\n            return queryset.annotate(num_video_tasks=\n                Sum(\n                    Case(\n                        When(Q(fullvideotask__id=None) | Q(fullvideotask__closed=True), then=0),\n                        default=1,\n                        output_field=IntegerField())\n                    )).filter(num_video_tasks = 0)\n\n        elif self.value() == ""1"":\n            return queryset.annotate(num_video_tasks=\n                Sum(\n                    Case(\n                        When(Q(fullvideotask__id=None) | Q(fullvideotask__closed=True), then=0),\n                        default=1,\n                        output_field=IntegerField())\n                    )).filter(num_video_tasks__gt = 0)\n        else:\n            return queryset\n\nclass VideoAdmin(admin.ModelAdmin):\n    list_display =(\'id\', \'video_url\',\'filename\',\'verified\', \'is_published\')\n    list_filter=[PublishedFilter, \'verified\']\n    search_fields=[\'filename\', \'id\']\n    actions=[publish_to_turk]\n\n    def is_published(self, obj):\n        task = get_active_video_turk_task(obj.id)\n        if task == None:\n            return False\n        if task.hit_id == \'\':\n            return False\n        return True\n\n    is_published.short_description = ""Currently Published""\n    is_published.boolean = True\n\n    def video_url(self, obj):\n        return \'<a target=""_"" href=""/video/{}/"">/video/{}/</a>\'.format(obj.id, obj.id)\n    video_url.allow_tags = True\n    video_url.short_description = \'Video\'\n\n\nclass StateAdmin(admin.ModelAdmin):\n    list_display = [\'name\', \'label_name\']\n    \n    \nadmin.site.register(Video, VideoAdmin)\nadmin.site.register(Label)\nadmin.site.register(State, StateAdmin)\n'"
custom-interfaces/video-segmentation-beaverdam/annotator/apps.py,0,"b""from django.apps import AppConfig\n\n\nclass AnnotatorConfig(AppConfig):\n    name = 'annotator'\n"""
custom-interfaces/video-segmentation-beaverdam/annotator/models.py,0,"b'from django.db import models\nfrom django.contrib.staticfiles import finders\n\n\nclass Label(models.Model):\n    """"""The classes available for workers to choose from for each object.""""""\n    id = models.AutoField(primary_key=True)\n    name = models.CharField(blank=True, max_length=100, unique=True,\n        help_text=""Name of class label option."")\n    color = models.CharField(blank=True, max_length=6,\n        help_text=""6 digit hex."")\n\n    def __str__(self):\n        return self.name\n\n\nclass State(models.Model):\n    """"""The states available for each label.""""""\n    id = models.AutoField(primary_key=True)\n    name = models.CharField(blank=True, max_length=100,\n        help_text=""Name of class label option."")\n    color = models.CharField(blank=True, max_length=6,\n        help_text=""6 digit hex."")\n    label_name = models.ForeignKey(Label, blank=True, to_field=\'name\')\n\n    def __str__(self):\n        return self.name\n\n\nclass Video(models.Model):\n    annotation = models.TextField(blank=True,\n        help_text=""A JSON blob containing all user annotation sent from client."")\n    source = models.CharField(max_length=1048, blank=True,\n        help_text=(""Name of video source or type, for easier grouping/searching of videos.""\n            ""This field is not used by BeaverDam and only facilitates querying on videos by type.""))\n    filename = models.CharField(max_length=100, blank=True,\n        help_text=(""Name of the video file.""\n            ""The video should be publically accessible by at <host><filename>.""))\n    image_list = models.TextField(blank=True,\n        help_text=(""List of filenames of images to be used as video frames, in JSON format.""\n            ""When present, image list is assumed and <filename> is ignored.""))\n    host = models.CharField(max_length=1048, blank=True,\n        help_text=""Path to prepend to filenames to form the url for this video or the images in `image_list`."")\n    verified = models.BooleanField(default=False, help_text=""Verified as correct by expert."")\n    rejected = models.BooleanField(default=False, help_text=""Rejected by expert."")\n    labels = models.ManyToManyField(Label, blank=True)\n\n    @classmethod\n    def from_list(cls, path_to_list, *, source, host, filename_prefix=\'\'):\n        created = []\n        for line in open(path_to_list, \'r\'):\n            if line:\n                video = cls(source=source, filename=filename_prefix + line.strip(), host=host)\n                video.save()\n                created.append(video)\n        return created\n\n    def __str__(self):\n        return \'/video/{}\'.format(self.id)\n\n    @property\n    def url(self):\n        if self.image_list:\n            return \'Image List\'\n        elif finders.find(\'videos/{}.mp4\'.format(self.id)):\n            return \'/static/videos/{}.mp4\'.format(self.id)\n        elif self.filename and self.host:\n            return self.host + self.filename\n        else:\n            raise Exception(\'Video {0} does not have a filename, host or image_list. Possible fixes: \\n1) Place {0}.mp4 into static/videos to serve locally. \\n2) Update the filename & host fields of the Video with id={0}\'.format(self.id))\n\n    def count_keyframes(self, at_time=None):\n        if at_time is None:\n            return self.annotation.count(\'""frame""\')\n        else:\n            return self.annotation.count(\'""frame"": {}\'.format(at_time))\n'"
custom-interfaces/video-segmentation-beaverdam/annotator/services.py,0,"b'import mturk.queries\nimport logging\nfrom django.http import HttpResponse, Http404 \n\nfrom django.contrib.admin.views.decorators import staff_member_required\nfrom mturk.models import Task, FullVideoTask\nfrom .models import *\nfrom mturk.queries import *\nfrom decimal import Decimal\n\nlogger = logging.getLogger()\n\n@staff_member_required\ndef publish_videos_to_turk(videos):\n    for video in videos:\n        video_task = get_active_video_turk_task(id)\n\n        if video_task != None:\n            raise Exception(\'video {} already has an active FullVideoTask\'.format(id))\n\n        video_task = FullVideoTask(video = video)\n        video_task.publish()\n\n@staff_member_required\ndef verify(request, video_id):\n    body = request.body.decode(\'utf-8\')\n    video = Video.objects.get(id=video_id)\n    if body == \'true\':\n        video.verified = True\n    elif body == \'false\':\n        video.verified = False\n    else:\n        print(body)\n        return HttpResponseBadRequest()\n    video.save()\n    return HttpResponse(\'video verification state saved\')\n\n@staff_member_required    \ndef accept_video(request, video_id, bonus, message, reopen, clear_boxes, blockWorker, updatedAnnotation):\n    video = Video.objects.get(pk=video_id)\n    video.verified = True\n\n    video_task = get_active_video_turk_task(video.id)\n\n    if video_task != None:\n        # accept on turk\n        video_task.approve_assignment(bonus, message)\n\n        if blockWorker:\n            video_task.blockWorker()\n\n        # delete from Turk\n        video_task.archive_turk_hit()\n\n        video_task.bonus = Decimal(bonus)\n        video_task.message = message\n        video_task.paid = True\n        video_task.closed = True\n        video_task.save()\n\n         # create a new HIT for this instaed\n        if reopen:\n            new_task = FullVideoTask(video = video)\n            new_task.publish()\n\n            # now mark the video as unverified as we\'re asking somebody else to fill this in\n            # why would we do this? Sometimes it\'s a better strategy to accept somebody\'s work, \n            # and block the worker but then get somebody else to do the work \n            video.verified = False\n\n  # clear the boxes as specified\n    if clear_boxes:\n        video.annotation = \'\'\n    else:\n        video.annotation = updatedAnnotation\n    \n    video.rejected = False\n    video.save()\n\n@staff_member_required\ndef reject_video(request, video_id, message, reopen, clear_boxes, blockWorker, updatedAnnotation):\n    video = Video.objects.get(pk=video_id)\n    video_task = get_active_video_turk_task(video.id)\n    \n    if video_task != None:\n        # reject on turk\n        video_task.reject_assignment(message)\n\n        if blockWorker:\n            video_task.blockWorker()\n\n        # update the task \n        video_task.message = message\n        video_task.rejected = True\n        video_task.bonus = 0\n        video_task.closed = True\n        video_task.save()\n\n        # delete from Turk\n        video_task.archive_turk_hit()\n\n        # create a new HIT for this instaed\n        if reopen:\n            new_task = FullVideoTask(video = video)\n            new_task.publish()\n\n    # clear the boxes as specified\n    if clear_boxes:\n        video.annotation = \'\'\n    else:\n        video.annotation = updatedAnnotation\n\n    video.verified = False\n    video.rejected = True\n    video.save()\n\n\n@staff_member_required\ndef email_worker(request, video_id, subject, message):\n    video = Video.objects.get(pk=video_id)\n    video_task = get_active_video_turk_task(video.id)\n    \n    if video_task == None:\n        raise Exception(""No video task to send email for {}"".format(video_id))\n\n    video_task.send_email(subject, message)'"
custom-interfaces/video-segmentation-beaverdam/annotator/tests.py,0,"b'from django.test import TestCase\n\nfrom .models import Video\n\nclass VideoTestCase(TestCase):\n\tdef setUp(self):\n\t\tVideo.objects.create(filename=\'test/video1\')\n\n\tdef test_count_keyframes(self):\n\t\tv = Video.objects.get(filename=\'test/video1\')\n\t\tv.annotation = \'{""color"": ""#137819"", ""keyframes"": [{""h"": 43.50453172205437, ""frame"": 0, ""x"": 919, ""y"": 694, ""w"": 84}], ""type"": ""car""},]\'\n\t\tself.assertEqual(v.count_keyframes(), 1)\n\t\tself.assertEqual(v.count_keyframes(at_time=0), 1)\n\t\tself.assertEqual(v.count_keyframes(at_time=0.5), 0)\n\n'"
custom-interfaces/video-segmentation-beaverdam/annotator/views.py,0,"b'from django.shortcuts import render, redirect\nfrom django.conf import settings\nfrom django.http import HttpResponse, Http404, HttpResponseBadRequest, HttpResponseForbidden\nfrom django.views.generic import View\nfrom django.views.decorators.clickjacking import xframe_options_exempt\nfrom django.contrib.admin.views.decorators import staff_member_required\nfrom django.core.exceptions import ObjectDoesNotExist\nfrom mturk.queries import get_active_video_turk_task\nfrom .models import *\nfrom mturk.models import Task, FullVideoTask, SingleFrameTask\nfrom .services import *\nfrom datetime import datetime, timezone\n\nfrom collections import namedtuple\nimport os\nimport json\nimport urllib.request\nimport urllib.parse\nimport markdown\nimport sys\nimport mturk.utils\nfrom mturk.queries import get_active_video_turk_task\nfrom .models import *\nfrom .services import *\n\nimport logging\nimport ast\n\nlogger = logging.getLogger()\n\n\ndef home(request):\n    need_annotating = Video.objects.filter(id__gt=0, verified=False)\n    return render(request, \'video_list.html\', context={\n        \'videos\': need_annotating,\n        \'thumbnail\': True,\n        \'test\': settings.AWS_ID,\n        \'title\': \'Videos\'\n    })\n\ndef verify_list(request):\n    need_verification = Video.objects.filter(id__gt=0, verified=False).exclude(annotation=\'\')[:250]\n    return render(request, \'video_list.html\', context={\n        \'videos\': need_verification,\n        \'title\': \'Videos to Verify\'\n    })\n\ndef verified_list(request):\n    verified = Video.objects.filter(id__gt=0, verified=True).exclude(annotation=\'\')[:100]\n    return render(request, \'video_list.html\', context={\n        \'videos\': verified,\n        \'title\': \'Verified Videos\'\n    })\n\ndef ready_to_pay(request):\n    #tasks = FullVideoTask.objects.filter(paid = False, video__verified = True).exclude(hit_id = \'\')\n    tasks = FullVideoTask.objects.all()#filter(paid = False, video__verified = True).exclude(hit_id = \'\')\n    print(""there are {} tasks"".format(len(tasks)))\n    return render(request, \'turk_ready_to_pay.html\', context={\n        \'tasks\': tasks,\n    })\n\ndef next_unannotated(request, video_id):\n    id = Video.objects.filter(id__gt=video_id, annotation=\'\')[0].id\n    return redirect(\'video\', id)\n\n# status of Not Published, Published, Awaiting Approval, Verified\n# this is a bit convoluted as there\'s status stored on\n# video (approved) as well as FullVideoTask (closed, paid, etc.)\ndef get_mturk_status(video, full_video_task):\n    if video.verified:\n        return ""Verified""\n    if full_video_task == None:\n        if video.rejected == True:\n            return ""Rejected""\n        elif video.annotation == \'\':\n            return ""Not Published""\n        else:\n            return ""Awaiting Approval""\n    if full_video_task.worker_id == \'\':\n        return ""Published""\n    if full_video_task.worker_id != \'\':\n        return ""Awaiting Approval""\n\n@xframe_options_exempt\ndef video(request):\n    # try:\n    #     video = Video.objects.get(id=video_id)\n    #     labels = Label.objects.all()\n    # except Video.DoesNotExist:\n    #     raise Http404(\'No video with id ""{}"". Possible fixes: \\n1) Download an up to date DB, see README. \\n2) Add this video to the DB via /admin\'.format(video_id))\n\n    # mturk_data = mturk.utils.authenticate_hit(request)\n    # if \'error\' in mturk_data:\n    #     return HttpResponseForbidden(mturk_data[\'error\'])\n    # if not (mturk_data[\'authenticated\'] or request.user.is_authenticated()):\n    #     return redirect(\'/login/?next=\' + request.path)\n\n    start_time = float(request.GET[\'s\']) if \'s\' in request.GET else None\n    end_time = float(request.GET[\'e\']) if \'e\' in request.GET else None\n\n    # turk_task = get_active_video_turk_task(video.id)\n\n    # if turk_task != None:\n    #     if turk_task.metrics != \'\':\n    #         metricsDictr = ast.literal_eval(turk_task.metrics)\n    #     else:\n    #         metricsDictr = {}\n\n    #     # Data for Javascript\n    #     full_video_task_data = {\n    #         \'id\': turk_task.id,\n    #         \'storedMetrics\': metricsDictr,\n    #         \'bonus\': float(turk_task.bonus),\n    #         \'bonusMessage\': turk_task.message,\n    #         \'rejectionMessage\': settings.MTURK_REJECTION_MESSAGE,\n    #         \'emailSubject\': settings.MTURK_EMAIL_SUBJECT,\n    #         \'emailMessage\': settings.MTURK_EMAIL_MESSAGE,\n    #         \'isComplete\': turk_task.worker_id != \'\'\n    #     }\n\n    #     # Data for python templating\n    #     if turk_task.last_email_sent_date != None:\n    #         mturk_data[\'last_email_sent_date\'] = turk_task.last_email_sent_date.strftime(""%Y-%m-%d %H:%M"")\n    # else:\n    #    full_video_task_data = None\n    full_video_task_data = None\n\n    # mturk_data[\'status\'] = get_mturk_status(video, turk_task)\n    # mturk_data[\'has_current_full_video_task\'] = full_video_task_data != None\n\n    video_data = json.dumps({\n        \'id\': \'cjlfk2gcl00u002s6o138ji1v\',\n        \'location\': \'https://firebasestorage.googleapis.com/v0/b/labelbox-193903.appspot.com/o/cji227p5ub6020794sz0dk57q%2F4d333587-4390-47ad-b644-5ba026e832af%2Ffrag_bunny.mp4?alt=media&token=d885537a-cb07-42b5-a87e-75617cef8275\',\n        # \'path\': video.host,\n        \'is_image_sequence\': False,\n        \'annotated\': False,\n        \'verified\': False,\n        \'rejected\': False,\n        \'start_time\': start_time,\n        \'end_time\' : end_time,\n    })\n\n    help_content = \'\'\n    if settings.HELP_URL and settings.HELP_USE_MARKDOWN:\n        help_content = urllib.request.urlopen(settings.HELP_URL).read().decode(\'utf-8\')\n        help_content = markdown.markdown(help_content)\n\n    response = render(request, \'video.html\', context={\n        \'video_data\': video_data,\n        \'image_list\': 0,\n        \'image_list_path\': urllib.parse.quote(\'\', safe=\'/:\'),\n        \'help_url\': settings.HELP_URL,\n        \'help_embed\': settings.HELP_EMBED,\n        \'survey\': False,\n        \'help_content\': help_content\n    })\n    response[\'X-Frame-Options\'] = \'SAMEORIGIN\'\n    return response\n\n\ndef get_states(request, states=None):\n    label_name = request.GET.get(\'label_name\')\n    if label_name:\n        label_name = label_name.replace(""%20"", "" "")\n    # iterate over each city and append to results list\n    state_data = [{\'name\': s.name, \'color\': s.color} for s in State.objects.filter(label_name=label_name)]\n    # return JSON object\n    return HttpResponse(json.dumps(state_data))\n\n\nclass AnnotationView(View):\n\n    def get(self, request, video_id):\n        video = Video.objects.get(id=video_id)\n        return HttpResponse(video.annotation, content_type=\'application/json\')\n\n    def post(self, request, video_id):\n        data = json.loads(request.body.decode(\'utf-8\'))\n\n        video = Video.objects.get(id=video_id)\n        video.annotation = json.dumps(data[\'annotation\'])\n        video.save()\n\n        hit_id = data.get(\'hitId\', None)\n        if hit_id != None:\n            if not Task.valid_hit_id(hit_id):\n                return HttpResponseForbidden(\'Not authenticated\')\n            else:\n                try:\n                    worker_id = data.get(\'workerId\', \'\')\n                    assignment_id = data.get(\'assignmentId\', \'\')\n                    task = Task.get_by_hit_id(hit_id)\n                    task.complete(worker_id, assignment_id, data[\'metrics\'])\n                except ObjectDoesNotExist:\n                    if not settings.DEBUG:\n                        raise\n        return HttpResponse(\'success\')\n\n\nclass ReceiveCommand(View):\n\n    def post(self, request, video_id):\n        data = json.loads(request.body.decode(\'utf-8\'))\n\n        try:\n            vid_id = int(video_id)\n            command_type = data[\'type\']\n\n            message = data[\'message\']\n\n            if command_type == ""accept"":\n                accept_video(request, vid_id,\n                             data[\'bonus\'], message,\n                             data[\'reopen\'],\n                             data[\'delete_boxes\'],\n                             data[\'block_worker\'],\n                             data[\'updated_annotations\'])\n            elif command_type == ""reject"":\n                reject_video(request, vid_id, message,\n                             data[\'reopen\'],\n                             data[\'delete_boxes\'],\n                             data[\'block_worker\'],\n                             data[\'updated_annotations\'])\n            elif command_type == ""email"":\n                email_worker(request, vid_id, data[\'subject\'], message)\n\n            return HttpResponse(status=200)\n        except Exception as e:\n            logger.exception(e)\n            response = HttpResponse(status=500)\n            response[\'error-message\'] = str(e)\n            return response\n'"
custom-interfaces/video-segmentation-beaverdam/beaverdam/__init__.py,0,b''
custom-interfaces/video-segmentation-beaverdam/beaverdam/settings.py,0,"b'""""""\nDjango settings for beaverdam project.\n\nGenerated by \'django-admin startproject\' using Django 1.9.7.\n\nFor more information on this file, see\nhttps://docs.djangoproject.com/en/1.9/topics/settings/\n\nFor the full list of settings and their values, see\nhttps://docs.djangoproject.com/en/1.9/ref/settings/\n""""""\n\nimport os\n\n# Build paths inside the project like this: os.path.join(BASE_DIR, ...)\nBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n\n# Use different key for production\nSECRET_KEY = \'8pje5%pxibt2c=&j_c+ly5v@x)$r77%h-x3%jluq-@)4^75)ak\'\nDEBUG = True\n\nHELP_URL = os.environ.get(\'HELP_URL\', \'https://raw.githubusercontent.com/antingshen/BeaverDam/master/default-instructions.md\')\n# this will show in a popup instead of the external HELP_URL\nHELP_USE_MARKDOWN = True\nHELP_EMBED = True\nURL_ROOT = os.environ.get(\'URL_ROOT\', \'url_root\')\nAWS_ID = os.environ.get(\'AWS_ID\', \'aws_id\')\nAWS_KEY = os.environ.get(\'AWS_KEY\', \'aws_key\')\n\nMTURK_TITLE = ""Video annotation""\nMTURK_DESCRIPTION = ""Draw accurate boxes around every person in the video, we will pay a $0.02 bonus per accurate box drawn. Most of the payment is in the bonus""\nMTURK_SANDBOX = True\nMTURK_BONUS_MESSAGE = ""Thanks for your work""\nMTURK_REJECTION_MESSAGE = ""Your work has not been accepted. You must follow the instructions of the task precisely to complete this task.""\nMTURK_BLOCK_MESSAGE = ""I\'m sorry but we have blocked you from working on our HITs. We have limited time and unfortunately your work accuracy was not up to the standards required.""\nMTURK_BONUS_PER_BOX = 0.02\nMTURK_BASE_PAY = 0.04\nMTURK_EMAIL_SUBJECT = ""Question about your work""\nMTURK_EMAIL_MESSAGE = """"""Thanks for your submission.\n\nUnfortunately, we\'re not able to accept this work as it does not meet the standards required.\n\nIf you\'d like to have another go at it, can you please carefully read the instructions and make sure you enter information for the entire video.\n\nOtherwise, we will reject the task in 24 hours.\n\nPlease let us know if you\'ve encountered any problems.\n\nRegards\n""""""\n\nALLOWED_HOSTS=[""*""]\n\nassert MTURK_SANDBOX or not DEBUG\n\n# Application definition\n\nINSTALLED_APPS = [\n    \'annotator\',\n    \'mturk\',\n    \'django.contrib.admin\',\n    \'django.contrib.auth\',\n    \'django.contrib.contenttypes\',\n    \'django.contrib.sessions\',\n    \'django.contrib.messages\',\n    \'django.contrib.staticfiles\',\n]\n\nMIDDLEWARE_CLASSES = [\n    \'django.middleware.security.SecurityMiddleware\',\n    \'django.contrib.sessions.middleware.SessionMiddleware\',\n    \'django.middleware.common.CommonMiddleware\',\n    \'django.middleware.csrf.CsrfViewMiddleware\',\n    \'django.contrib.auth.middleware.AuthenticationMiddleware\',\n    \'django.contrib.auth.middleware.SessionAuthenticationMiddleware\',\n    \'django.contrib.messages.middleware.MessageMiddleware\',\n    \'django.middleware.clickjacking.XFrameOptionsMiddleware\',\n]\n\nROOT_URLCONF = \'beaverdam.urls\'\n\nTEMPLATES = [\n    {\n        \'BACKEND\': \'django.template.backends.django.DjangoTemplates\',\n        \'DIRS\': [],\n        \'APP_DIRS\': True,\n        \'OPTIONS\': {\n            \'context_processors\': [\n                \'django.template.context_processors.debug\',\n                \'django.template.context_processors.request\',\n                \'django.contrib.auth.context_processors.auth\',\n                \'django.contrib.messages.context_processors.messages\',\n            ],\n        },\n    },\n]\n\nWSGI_APPLICATION = \'beaverdam.wsgi.application\'\n\n\n# Database\n# https://docs.djangoproject.com/en/1.9/ref/settings/#databases\n\nDATABASES = {\n    \'default\': {\n        \'ENGINE\': \'django.db.backends.sqlite3\',\n        \'NAME\': os.path.join(BASE_DIR, \'db.sqlite3\'),\n    }\n}\n\n\n# Password validation\n# https://docs.djangoproject.com/en/1.9/ref/settings/#auth-password-validators\n\nAUTH_PASSWORD_VALIDATORS = [\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.UserAttributeSimilarityValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.MinimumLengthValidator\',\n    },\n    {\n        \'NAME\': \'django.contrib.auth.password_validation.CommonPasswordValidator\',\n    },\n]\n\nLOGIN_REDIRECT_URL = \'/\'\nLOGIN_URL = \'/login/\'\n\nCSRF_COOKIE_SECURE = not DEBUG\n\n\n# Internationalization\n# https://docs.djangoproject.com/en/1.9/topics/i18n/\n\nLANGUAGE_CODE = \'en-us\'\n\nTIME_ZONE = \'America/Los_Angeles\'\n\nUSE_I18N = True\n\nUSE_L10N = True\n\nUSE_TZ = True\n\n\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/1.9/howto/static-files/\n\nSTATIC_URL = \'/static/\'\n\nSTATIC_ROOT = os.path.join(BASE_DIR, ""annotator/static/"")\n\ntry:\n    from beaverdam.deploy_settings import *\nexcept ImportError as e:\n    pass\n'"
custom-interfaces/video-segmentation-beaverdam/beaverdam/urls.py,0,"b""from django.conf.urls import url\nfrom django.conf.urls.static import static\nfrom django.contrib import admin\nfrom django.contrib.auth.views import login, logout\nfrom django.views.generic.base import RedirectView\n\nfrom annotator.views import *\nfrom annotator.services import *\n\nadmin.site.site_header = 'BeaverDam'\n\nurlpatterns = [\n    url(r'^$', video, name='video'),\n    # url(r'^verify/$', verify_list),\n    # url(r'^verified/$', verified_list),\n    # url(r'^readytopay/$', ready_to_pay),\n\n    url(r'^get_states/$', get_states, name='get_states'),\n\n    # url(r'^video/(\\d+)/$', video, name='video'),\n    # url(r'^video/(\\d+)/next/$', next_unannotated),\n    # url(r'^video/(\\d+)/verify/$', verify),\n    # url(r'^annotation/(\\d+)/$', AnnotationView.as_view()),\n    # url(r'^accept\\-annotation/(\\d+)/$', ReceiveCommand.as_view()),\n    # url(r'^reject\\-annotation/(\\d+)/$', ReceiveCommand.as_view()),\n    # url(r'^email-worker/(\\d+)/$', ReceiveCommand.as_view()),\n\n    # url(r'^login/$', login,\n    #     {'template_name': 'admin/login.html',\n    #         'extra_context': {'site_header': 'BeaverDam Login'}\n    #     }, name='login'),\n    # url(r'^logout/$', logout),\n    # url(r'^accounts/', RedirectView.as_view(url='/')),\n    # url(r'^admin/', admin.site.urls),\n]  + static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)\n"""
custom-interfaces/video-segmentation-beaverdam/beaverdam/wsgi.py,0,"b'import os\n\nfrom django.core.wsgi import get_wsgi_application\n\nos.environ.setdefault(""DJANGO_SETTINGS_MODULE"", ""beaverdam.settings"")\n\napplication = get_wsgi_application()\n'"
custom-interfaces/video-segmentation-beaverdam/mturk/__init__.py,0,b''
custom-interfaces/video-segmentation-beaverdam/mturk/admin.py,0,"b'from django.contrib import admin\nfrom .models import *\nimport logging\n\n\nlogger = logging.getLogger()\n\n\ndef recalculate_bonus(modeladmin, request, videos):\n    logger.error(""racalcing bonuses"")\n    for video_task in videos:\n        logger.error(""calc bonus for {}"".format(video_task.id))\n        video_task.bonus = video_task.calculate_bonus()\n        logger.error(""new bonus is {}"".format(video_task.bonus))\n        video_task.save()\n\nclass FullVideoTaskAdmin(admin.ModelAdmin):\n    list_display =(\'id\',\'video_url\',\'worker_id\', \'hit_id\', \'bonus\', \'closed\', \'paid\', \'last_email_sent_date\')\n    search_fields=[\'id\', \'worker_id\', \'hit_id\', \'assignment_id\']\n    list_filter=[\'paid\', \'closed\', \'worker_id\']\n    actions=[recalculate_bonus]\n\n    def video_url(self, obj):\n        return \'<a target=""_"" href=""/video/{}/"">/video/{}/</a>\'.format(obj.video.id, obj.video.id)\n    video_url.allow_tags = True\n    video_url.short_description = \'Video\'\n   \n\nadmin.site.register(FullVideoTask, FullVideoTaskAdmin)\nadmin.site.register(SingleFrameTask)\n'"
custom-interfaces/video-segmentation-beaverdam/mturk/apps.py,0,"b""from django.apps import AppConfig\n\n\nclass MturkConfig(AppConfig):\n    name = 'mturk'\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/models.py,0,"b'from django.db import models\nfrom django.conf import settings\nfrom django.core.urlresolvers import reverse\nfrom django.core.exceptions import ObjectDoesNotExist, MultipleObjectsReturned\n\nfrom tqdm import tqdm\nfrom datetime import datetime\n\nfrom .mturk_api import Server\nfrom annotator.models import Video\nimport time\nimport math\n\nimport logging\nimport os\n\nlogger = logging.getLogger()\n\n\nmturk = Server(settings.AWS_ID, settings.AWS_KEY, settings.URL_ROOT, settings.MTURK_SANDBOX)\n\n\nclass Task(models.Model):\n    hit_id = models.CharField(max_length=64, blank=True,\n        help_text=""ID on MTurk. Auto-populated when publishing"")\n    hit_group = models.CharField(max_length=64, blank=True,\n        help_text=(""Group ID on Mturk. ""\n            ""HITs with same title/description usually are placed in the same group by MTurk. ""\n            ""Auto-populated when publishing.""))\n    metrics = models.TextField(blank=True)\n    duration = 10800 # 3 hours\n    lifetime = 2592000 # 30 days\n    worker_id = models.CharField(max_length=64, blank=True,\n        help_text=""ID of worker who submitted this HIT"")\n    assignment_id = models.CharField(max_length=64, blank=True,\n        help_text=""ID of matching between this task and a worker. Used for authentication"")\n    time_completed = models.DateTimeField(null=True, blank=True)\n    bonus = models.DecimalField(max_digits=4, decimal_places=2, default=0)\n    sandbox = models.BooleanField(default=settings.MTURK_SANDBOX)\n    message = models.CharField(max_length=256, blank=True)\n    email_trail = models.TextField(blank=True)\n    last_email_sent_date = models.DateTimeField(null=True, blank=True)\n    closed = models.BooleanField(default=False)\n    paid = models.BooleanField(default=False)\n\n    class Meta:\n        abstract = True\n\n    def publish(self):\n        if settings.MTURK_SANDBOX != self.sandbox:\n            raise Exception(""settings.MTURK_SANDBOX != self.sandbox"")\n        if self.video.verified:\n            self.video.verified = False\n            self.video.save()\n        response = mturk.create_hit(self.title, self.description, self.url,\n            self.pay, self.duration, self.lifetime)\n        self.hit_id = response.values[\'hitid\']\n        self.hit_group = response.values[\'hittypeid\']\n        self.save()\n\n    def complete(self, worker_id, assignment_id, metrics):\n        self.worker_id = worker_id\n        self.assignment_id = assignment_id\n        self.metrics = metrics\n        self.bonus = self.calculate_bonus()\n        self.message = settings.MTURK_BONUS_MESSAGE\n        self.time_completed = datetime.now()\n\n        self.paid = False\n        self.save()\n\n    def send_email(self, subject, message):\n        if (self.worker_id == \'\'):\n            raise Exception(""No worked id to send email to for FullVideoTask({})"".format(id))\n\n        mturk.email(self.worker_id, subject, message)\n        self.last_email_sent_date = datetime.now()\n        self.email_trail += ""{}================================================{}"".format(os.linesep, os.linesep)\n        self.email_trail += ""Date: {}{}"".format(self.last_email_sent_date.strftime(""%c""), os.linesep)\n        self.email_trail += ""Subject: {}{}"".format(subject, os.linesep)\n        self.email_trail += ""--------------------------------------------------{}"".format(os.linesep)\n        self.email_trail += message\n        self.email_trail += os.linesep\n\n        self.save()\n\n    def approve_assignment(self, bonus, message):\n        if self.assignment_id == None:\n            raise Exception(""Cannot approve task - no work has been done on Turk"")\n\n        if bonus > 0:\n            mturk.bonus(self.worker_id, self.assignment_id, bonus, message)\n\n        mturk.accept(self.assignment_id, message)\n\n    def reject_assignment(self, message):\n        if self.assignment_id == None:\n            raise Exception(""Cannot reject task - no work has been done on Turk"")\n\n        mturk.reject(self.assignment_id, message)\n\n    def blockWorker(self):\n        if self.worker_id == None:\n            raise Exception(""Cannot reject task - no work has been done on Turk"")\n\n        mturk.block(self.worker_id, settings.MTURK_BLOCK_MESSAGE)\n\n    def archive_turk_hit(self):\n        res = mturk.disable(self.hit_id)\n\n    @classmethod\n    def calculate_bonus(self):\n        return 0\n\n    @classmethod\n    def batch_create_and_publish(cls, videos, **kwargs):\n        created = []\n        for video in tqdm(videos):\n            task = cls(video=video, **kwargs)\n            task.save()\n            task.publish()\n        return created\n\n    @classmethod\n    def valid_hit_id(cls, id):\n        if id is None:\n            return False\n        try:\n            item = cls.get_by_hit_id(id)\n            return True\n        except ObjectDoesNotExist:\n            return settings.DEBUG\n\n    @classmethod\n    def get_by_hit_id(cls, id):\n        items = []\n        for task_type in cls.__subclasses__():\n            try:\n                items.append(task_type.objects.get(hit_id=id))\n            except ObjectDoesNotExist:\n                pass\n        if len(items) > 1:\n            raise MultipleObjectsReturned()\n        elif len(items) == 0:\n            raise ObjectDoesNotExist()\n        else:\n            return items[0]\n\n\nclass FullVideoTask(Task):\n    video = models.ForeignKey(Video)\n    title = settings.MTURK_TITLE\n    description = settings.MTURK_DESCRIPTION\n    pay = settings.MTURK_BASE_PAY\n    bonus_per_box = settings.MTURK_BONUS_PER_BOX\n\n    @property\n    def url(self):\n        return reverse(\'video\', args=[self.video.id])\n\n    def __str__(self):\n        return self.video.filename or str(self.video)\n\n    def calculate_bonus(self):\n        boxes  = self.video.count_keyframes()\n        num_cents = boxes * self.bonus_per_box\n        return num_cents\n\n\nclass SingleFrameTask(Task):\n    video = models.ForeignKey(Video)\n    time = models.FloatField()\n    title = ""Image Annotation""\n    description = ""Draw boxes around all objects of interest in an image, with bonus per object""\n    pay = 0.01\n    bonus_per_box = 0.005\n\n    def calculate_bonus(self):\n        boxes = self.video.count_keyframes(at_time=self.time)\n        num_cents = ((boxes - 1) * self.bonus_per_box + self.pay) * 100\n        return math.ceil(num_cents) / 100\n\n    @property\n    def url(self):\n        return reverse(\'video\', args=[self.video.id]) + \'?s={0}&amp;e={0}\'.format(self.time)\n\n    def __str__(self):\n        return \'{:.2f} of {}\'.format(self.time, self.video.filename)\n'"
custom-interfaces/video-segmentation-beaverdam/mturk/mturk_api.py,0,"b'import base64\nimport time\nimport hashlib\nimport hmac\nimport urllib.parse\nimport urllib.request\nfrom math import ceil\nfrom xml.etree import ElementTree\n\nimport logging\n\nlogger = logging.getLogger(""turkic.api"")\n\nclass Server(object):\n    def __init__(self, mturk_id, mturk_key, localhost, sandbox=False):\n        self.mturk_key = bytes(mturk_key, \'utf-8\')\n        self.mturk_id = mturk_id\n        self.localhost = \'https://\' + localhost\n        self.sandbox = sandbox\n\n        if sandbox:\n            self.server = ""mechanicalturk.sandbox.amazonaws.com""\n        else:\n            self.server = ""mechanicalturk.amazonaws.com""\n\n    def request(self, operation, parameters = {}):\n        """"""\n        Sends the request to the Turk server and returns a response object.\n        """"""\n\n        if not self.mturk_key or not self.mturk_id:\n            raise RuntimeError(""Signature or access key missing"")\n\n        timestamp = time.strftime(""%Y-%m-%dT%H:%M:%SZ"", time.gmtime())\n        hmacstr = hmac.new(self.mturk_key,\n            bytes(""AWSMechanicalTurkRequester"" + operation + timestamp, \'utf-8\'), hashlib.sha1)\n        hmacstr = base64.encodestring(hmacstr.digest()).strip()\n\n        logger.info(""Request to MTurk: {0}"".format(operation))\n        for paramk, paramv in parameters.items():\n            logger.debug(""  {0}: {1}"".format(paramk, paramv))\n\n        baseurl = ""/?"" + urllib.parse.urlencode({\n                    ""Service"": ""AWSMechanicalTurkRequester"",\n                    ""AWSAccessKeyId"": self.mturk_id,\n                    ""Version"": ""2008-08-02"",\n                    ""Operation"": operation,\n                    ""Signature"": hmacstr,\n                    ""Timestamp"": timestamp})\n        url = baseurl + ""&"" + urllib.parse.urlencode(parameters)\n        url = ""https://"" + self.server + url\n\n        req = urllib.request.Request(url = url)\n        data = urllib.request.urlopen(req)\n        \n        response = Response(operation, data)\n        return response\n\n    def create_hit(self, title, description, page, amount, duration,\n        lifetime, keywords = """", autoapprove = 604800, height = 950,\n        minapprovedpercent = None, minapprovedamount = None, countrycode = None):\n        """"""\n        Creates a HIT on Mechanical Turk.\n        \n        If successful, returns a Response object that has fields:\n            hit_id          The HIT ID\n            hit_type_id     The HIT group ID\n\n        If unsuccessful, a CommunicationError is raised with a message\n        describing the failure.\n        """"""\n        r = {""Title"": title,\n            ""Description"": description,\n            ""Keywords"": keywords,\n            ""Reward.1.Amount"": amount,\n            ""Reward.1.CurrencyCode"": ""USD"",\n            ""AssignmentDurationInSeconds"": duration,\n            ""AutoApprovalDelayInSeconds"": autoapprove,\n            ""LifetimeInSeconds"": lifetime}\n\n        qualcounter = 0\n\n        if minapprovedpercent:\n            qualcounter += 1\n            base = ""QualificationRequirement.{0}."" .format(qualcounter)\n            r[base + ""QualificationTypeId""] = ""000000000000000000L0""\n            r[base + ""Comparator""] = ""GreaterThanOrEqualTo""\n            r[base + ""IntegerValue""] = minapprovedpercent \n\n        if minapprovedamount:\n            qualcounter += 1\n            base = ""QualificationRequirement.{0}."" .format(qualcounter)\n            r[base + ""QualificationTypeId""] = ""00000000000000000040""\n            r[base + ""Comparator""] = ""GreaterThanOrEqualTo""\n            r[base + ""IntegerValue""] = minapprovedamount \n\n        if countrycode:\n            qualcounter += 1\n            base = ""QualificationRequirement.{0}."" .format(qualcounter)\n            r[base + ""QualificationTypeId""] = ""00000000000000000071""\n            r[base + ""Comparator""] = ""EqualTo""\n            r[base + ""LocaleValue.Country""] = countrycode \n\n        assert page[0] == \'/\'\n        r[""Question""] = (""<ExternalQuestion xmlns=\\""http://mechanicalturk""\n                         "".amazonaws.com/AWSMechanicalTurkDataSchemas/""\n                         ""2006-07-14/ExternalQuestion.xsd\\"">""\n                         ""<ExternalURL>{0}{1}</ExternalURL>""\n                         ""<FrameHeight>{2}</FrameHeight>""\n                         ""</ExternalQuestion>"").format(self.localhost,\n                                                       page, height)\n\n        r = self.request(""CreateHIT"", r);\n        r.validate(""HIT/Request/IsValid"", ""HIT/Request/Errors/Error/Message"")\n        r.store(""HIT/HITId"", ""hitid"")\n        r.store(""HIT/HITTypeId"", ""hittypeid"")\n        return r\n    \n    def disable(self, hitid):\n        """"""\n        Disables the HIT from the MTurk service.\n        """"""\n        r = self.request(""DisableHIT"", {""HITId"": hitid})\n        r.validate(""DisableHITResult/Request/IsValid"",\n                   ""DisableHITResult/Request/Errors/Error/Message"")\n        return r\n\n    def purge(self):\n        """"""\n        Disables all the HITs on the MTurk server. Useful for debugging.\n        """"""\n        while True:\n            r = self.request(""SearchHITs"", {""SortProperty"": ""CreationTime"",\n                                            ""SortDirection"": ""Descending"",\n                                            ""PageSize"": ""100"",\n                                            ""PageNumber"": ""1""})\n            r.validate(""SearchHITsResult/Request/IsValid"")\n            r.store(""SearchHITsResult/TotalNumResults"", ""num"", int)\n            if r.num == 0:\n                return\n            for hit in r.tree.findall(""SearchHITsResult/HIT""):\n                hitid = hit.find(""HITId"").text.strip()\n                try:\n                    self.disable(hitid)\n                except CommunicationError:\n                    pass\n            print(""Next page"")\n\n    def get_assignments(self, hit_id):\n        res = self.request(\'GetAssignmentsForHIT\', {""HITId"":hit_id})\n        if res.has_path(""GetAssignmentsForHITResult/Assignment"") :\n            res.store(""GetAssignmentsForHITResult/Request/IsValid"", ""IsValid"", bool)\n            res.store(""GetAssignmentsForHITResult/Assignment/AssignmentId"", ""assignment_id"")\n            res.store(""GetAssignmentsForHITResult/Assignment/WorkerId"", ""worker_id"")\n\n            return (res.assignment_id, res.worker_id)\n\n        return (None, None)\n\n        \n\n    def accept(self, assignmentid, feedback = """"):\n        """"""\n        Accepts the assignment and pays the worker.\n        """"""\n        r = self.request(""ApproveAssignment"",\n                         {""AssignmentId"": assignmentid,\n                          ""RequesterFeedback"": feedback})\n        r.validate(""ApproveAssignmentResult/Request/IsValid"",\n                   ""ApproveAssignmentResult/Request/Errors/Error/Message"")\n        return r\n\n    def reject(self, assignmentid, feedback = """"):\n        """"""\n        Rejects the assignment and does not pay the worker.\n        """"""\n        r = self.request(""RejectAssignment"",\n                         {""AssignmentId"": assignmentid,\n                          ""RequesterFeedback"": feedback})\n        r.validate(""RejectAssignmentResult/Request/IsValid"",\n                   ""RejectAssignmentResult/Request/Errors/Error/Message"")\n        return r\n\n    def bonus(self, workerid, assignmentid, amount, feedback = """"):\n        """"""\n        Grants a bonus to a worker for an assignment.\n        """"""\n        r = self.request(""GrantBonus"",\n            {""WorkerId"": workerid,\n             ""AssignmentId"": assignmentid,\n             ""BonusAmount.1.Amount"": amount,\n             ""BonusAmount.1.CurrencyCode"": ""USD"",\n             ""Reason"": feedback});\n        r.validate(""GrantBonusResult/Request/IsValid"",\n                   ""GrantBonusResult/Request/Errors/Error/Message"")\n        return r\n\n    def block(self, workerid, reason = """"):\n        """"""\n        Blocks the worker from working on any of our HITs.\n        """"""\n        logger.error(""Blocking worker: {}"".format(workerid))\n\n        r = self.request(""BlockWorker"", {""WorkerId"": workerid,\n                                         ""Reason"": reason})\n        r.validate(""BlockWorkerResult/Request/IsValid"",\n                   ""BlockWorkerResult/Request/Errors/Error/Message"")\n        return r\n\n    def unblock(self, workerid, reason = """"):\n        """"""\n        Unblocks the worker and allows him to work for us again.\n        """"""\n        r = self.request(""UnblockWorker"", {""WorkerId"": workerid,\n                                           ""Reason"": reason})\n        r.validate(""UnblockWorkerResult/Request/IsValid"",\n                   ""UnblockWorkerResult/Request/Errors/Error/Message"")\n        return r\n\n    def email(self, workerid, subject, message):\n        """"""\n        Sends an email to the worker.\n        """"""\n        r = self.request(""NotifyWorkers"", {""Subject"": subject,\n                                           ""MessageText"": message,\n                                           ""WorkerId.1"": workerid})\n        r.validate(""NotifyWorkersResult/Request/IsValid"",\n                   ""NotifyWorkersResult/Request/Errors/Error/Message"")\n        return r\n\n    def getstatistic(self, statistic, type, timeperiod = ""LifeToDate""):\n        """"""\n        Returns the total reward payout.\n        """"""\n        r = self.request(""GetRequesterStatistic"", {""Statistic"": statistic,\n                                                   ""TimePeriod"": timeperiod})\n        r.validate(""GetStatisticResult/Request/IsValid"")\n        xmlvalue = ""LongValue"" if type is int else ""DoubleValue""\n        r.store(""GetStatisticResult/DataPoint/{0}"".format(xmlvalue),\n                ""value"", type)\n        return r.value\n\n    @property\n    def balance(self):\n        """"""\n        Returns a response object with the available balance in the amount\n        attribute.\n        """"""\n        r = self.request(""GetAccountBalance"")\n        r.validate(""GetAccountBalanceResult/Request/IsValid"")\n        r.store(""GetAccountBalanceResult/AvailableBalance/Amount"",\n                ""amount"", float)\n        r.store(""GetAccountBalanceResult/AvailableBalance/CurrencyCode"",\n                ""currency"")\n        return r.amount\n\n    @property\n    def rewardpayout(self):\n        """"""\n        Returns the total reward payout.\n        """"""\n        reward = self.getstatistic(""TotalRewardPayout"", float)\n        bonus = self.getstatistic(""TotalBonusPayout"", float)\n        return reward + bonus\n\n    @property\n    def approvalpercentage(self):\n        """"""\n        Returns the percent of assignments approved.\n        """"""\n        return self.getstatistic(""PercentAssignmentsApproved"", float)\n\n    @property\n    def feepayout(self):\n        """"""\n        Returns how much we paid to Amazon in fees.\n        """"""\n        reward = self.getstatistic(""TotalRewardFeePayout"", float)\n        bonus = self.getstatistic(""TotalBonusFeePayout"", float)\n        return reward + bonus\n\n    @property\n    def numcreated(self):\n        """"""\n        Returns the total number of HITs created.\n        """"""\n        return self.getstatistic(""NumberHITsCreated"", int)\n\nclass Response(object):\n    """"""\n    A generic response from the MTurk server.\n    """"""\n    def __init__(self, operation, httpresponse):\n        self.operation = operation\n        self.httpresponse = httpresponse\n        self.data = httpresponse.read()\n        logger.error(self.data)\n        self.tree = ElementTree.fromstring(self.data)\n        self.values = {}\n        #print(""------------------------------------------------------"")\n        logger.error(\'HTTP Response = \' + str(self.data))\n        #print(""------------------------------------------------------"")\n\n    def validate(self, valid, errormessage = None):\n        """"""\n        Validates the response and raises an exception if invalid.\n        \n        Valid contains a path that must contain False if the response\n        is invalid.\n        \n        If errormessage is not None, use this field as the error description.\n        """"""\n        valide = self.tree.find(valid)\n        if valide is None:\n            raise CommunicationError(""XML malformed"", self)\n        elif valide.text.strip() == ""False"":\n            if errormessage:\n                errormessage = self.tree.find(errormessage)\n                if errormessage is None:\n                    raise CommunicationError(""Response not valid ""\n                        ""and XML malformed"", self)\n                raise CommunicationError(errormessage.text.strip(), self)\n            else:\n                raise CommunicationError(""Response not valid"", self)\n    def has_path(self, path):\n        res = self.tree.find(path)\n        if res is None:\n            return False\n        return True\n\n    def has_path(self, path):\n        result = self.tree.find(path)\n        if result is None:\n            return False\n        return True\n\n    def store(self, path, name, type = str):\n        """"""\n        Stores the text at path into the attribute name.\n        """"""\n        node = self.tree.find(path)\n        if node is None:\n            raise CommunicationError(""XML malformed ""\n                ""(cannot find {0})"".format(path), self)\n        self.values[name] = type(node.text.strip())\n\n    def __getattr__(self, name):\n        """"""\n        Used to lookup attributes.\n        """"""\n        if name not in self.values:\n            raise AttributeError(""{0} is not stored"".format(name))\n        return self.values[name]\n\nclass CommunicationError(Exception):\n    """"""\n    The error raised due to a communication failure with MTurk.\n    """"""\n    def __init__(self, error, response):\n        self.error = error\n        self.response = response\n\n    def __str__(self):\n        return self.error\n'"
custom-interfaces/video-segmentation-beaverdam/mturk/queries.py,0,"b""from mturk.models import FullVideoTask\n\ndef get_active_video_turk_task(video_id):\n    tasks = FullVideoTask.objects.filter(video__id = video_id, closed = False)\n\n    if len(tasks) > 1:\n        raise Exception('More than one full video task for video {}'.format(video_id))\n    elif len(tasks) == 1:\n        return tasks[0]\n        \n    return None\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/tests.py,0,"b""from django.test import TestCase, RequestFactory\nfrom django.contrib.auth.models import AnonymousUser, User\n\nfrom .utils import authenticate_hit\nfrom .models import FullVideoTask\nfrom annotator.models import Video\n\n\nclass AuthenticateHitTest(TestCase):\n    def setUp(self):\n        self.factory = RequestFactory()\n        video = Video.objects.create()\n        FullVideoTask.objects.create(hit_id='real_hit_id', video=video)\n\n    def test_normal_hit(self):\n        request = self.factory.get('/?foo=bar&assignmentId=real_asmt_id&hitId=real_hit_id&workerId=real_worker_id')\n        data = authenticate_hit(request)\n        self.assertEqual(data['authenticated'], True)\n        self.assertEqual(data['preview'], False)\n        self.assertEqual(data['assignment_id'], 'real_asmt_id')\n\n    def test_preview(self):\n        mturk_request = self.factory.get('/?assignmentId=ASSIGNMENT_ID_NOT_AVAILABLE')\n        test_request = self.factory.get('/?preview=True')\n        for request in (mturk_request, test_request):\n            data = authenticate_hit(request)\n            self.assertEqual(data['authenticated'], True)\n            self.assertEqual(data['preview'], True)\n\n    def test_error(self):\n        request = self.factory.get('/?foo=bar&assignmentId=real_asmt_id&hitId=fake_hit_id&workerId=real_worker_id')\n        data = authenticate_hit(request)\n        self.assertEqual('error' in data, True)\n\n    def test_non_mturk(self):\n        request = self.factory.get('/')\n        data = authenticate_hit(request)\n        self.assertEqual(data['authenticated'], False)\n        self.assertEqual(data['preview'], False)\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/utils.py,0,"b""from django.conf import settings\n\nfrom .models import Task\n\ndef authenticate_hit(request):\n    assignment_id = request.GET.get('assignmentId', None) or request.GET.get('mturk', None)\n    if assignment_id == 'ASSIGNMENT_ID_NOT_AVAILABLE':\n        preview = True\n        assignment_id = None\n    else:\n        preview = bool(request.GET.get('preview', False))\n\n    hit_id = request.GET.get('hitId', '')\n    worker_id = request.GET.get('workerId', '')\n    if not preview:\n        if assignment_id is not None:\n            if not Task.valid_hit_id(hit_id):\n                # TODO: Log this error\n                return {'error': 'No HIT found with ID {}. Please return this HIT. Sorry for the inconvenience.'.format(hit_id)}\n        else:\n            return {'authenticated': False, 'preview': False}\n\n    return {\n        'authenticated': True,\n        'preview': preview,\n        'assignment_id': assignment_id,\n        'hit_id': hit_id,\n        'worker_id': worker_id,\n        'sandbox': settings.MTURK_SANDBOX,\n    }\n"""
docs/tfrecord-export/e2e-example/example.py,48,"b'import sys\nfrom json import load\nimport math\nimport tensorflow as tf\nfrom tensorflow.contrib import layers\nfrom tensorflow.contrib.data import map_and_batch\nfrom tensorflow.contrib.data import shuffle_and_repeat\nfrom tensorflow.contrib.layers.python.layers import layers as layers_lib\nfrom tensorflow.contrib.layers.python.layers import regularizers\nfrom tensorflow.contrib.layers.python.layers import utils\nimport tensorflow.contrib.slim as slim\nfrom tensorflow.python.ops import init_ops\nfrom tensorflow.python.ops import nn_ops\n\n\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\n\ndef fail_for_missing_file():\n    print(\'You must provide the path to export.json file.\')\n    sys.exit(1)\n\ndef _parse_tfrecord(serialized_example):\n    example = tf.parse_single_example(\n        serialized_example,\n        features={\n            \'image/encoded\': tf.FixedLenFeature([], tf.string),\n            \'image/filename\': tf.FixedLenFeature([], tf.string),\n            \'image/ID\': tf.FixedLenFeature([], tf.string),\n            \'image/format\': tf.FixedLenFeature([], tf.string),\n            \'image/height\': tf.FixedLenFeature([], tf.int64),\n            \'image/width\': tf.FixedLenFeature([], tf.int64),\n            \'image/channels\': tf.FixedLenFeature([], tf.int64),\n            \'image/colorspace\': tf.FixedLenFeature([], tf.string),\n            \'image/segmentation/class/encoded\': tf.FixedLenFeature([], tf.string),\n            \'image/segmentation/class/format\': tf.FixedLenFeature([], tf.string),\n            })\n    image = tf.image.decode_image(example[\'image/encoded\'])\n    image.set_shape([None, None, 3])\n    label = tf.image.decode_image(example[\'image/segmentation/class/encoded\'])\n    label.set_shape([None, None, 1])\n    image_float = tf.to_float(image)\n    label_float = tf.to_float(label)\n    return (image_float, label_float)\n\ndef _resize(image_dim):\n    def _inner(images_orig, labels_orig):\n        images = tf.image.resize_images(\n                images=images_orig,\n                size=[image_dim, image_dim],\n                method=tf.image.ResizeMethod.BILINEAR)\n        labels = tf.image.resize_images(\n                images=labels_orig,\n                size=[image_dim, image_dim],\n                method=tf.image.ResizeMethod.BILINEAR)\n        return (images, labels)\n    return _inner\n\nif __name__ == \'__main__\':\n    if len(sys.argv) < 2:\n        fail_for_missing_file()\n\n    export_file = sys.argv[1]\n\n    if not export_file:\n        fail_for_missing_file()\n\n    with open(export_file) as f:\n        export_json = load(f)\n\n    legend = export_json[\'legend\']\n    tfrecord_paths = export_json[\'tfrecord_paths\']\n\n    image_dim = 512\n    test_set_size = math.ceil(0.20 * len(tfrecord_paths))\n\n    training_dataset = (tf.data.TFRecordDataset(tfrecord_paths)\n            .skip(test_set_size)\n            .map(_parse_tfrecord)\n            .apply(shuffle_and_repeat(50))\n            .apply(map_and_batch(_resize(image_dim), 8)))\n    test_dataset = (tf.data.TFRecordDataset(tfrecord_paths)\n            .take(test_set_size)\n            .map(_parse_tfrecord)\n            .apply(map_and_batch(_resize(image_dim), test_set_size)))\n\n    training_iterator = training_dataset.make_one_shot_iterator()\n    test_iterator = test_dataset.make_initializable_iterator()\n\n    handle = tf.placeholder(tf.string, shape=[])\n    iterator = tf.data.Iterator.from_string_handle(\n        handle, training_dataset.output_types, training_dataset.output_shapes)\n    images, labels = iterator.get_next()\n\n    number_of_classes = len(legend) + 1 # +1 to include background class\n    weight_decay = 0.0005\n    dropout_keep_prob = tf.placeholder(tf.float32, shape=[])\n\n    # Define the network\n    with tf.variable_scope(\'fcn\', values=[images]):\n        with slim.arg_scope(\n            [layers.conv2d],\n            activation_fn=nn_ops.relu,\n            weights_regularizer=regularizers.l2_regularizer(weight_decay),\n            biases_initializer=init_ops.zeros_initializer()):\n\n            net = layers_lib.repeat(images, 2, layers.conv2d, 64, [3, 3], scope=\'conv1\')\n            logits = layers.conv2d( # replace fc layer with conv for FCN\n                net,\n                number_of_classes, [1, 1],\n                activation_fn=None,\n                normalizer_fn=None,\n                scope=\'fc2\')\n\n    # Flatten logit scores (predictions) for cross entropy computation\n    flat_logits = tf.reshape(tensor=logits, shape=(-1, number_of_classes))\n\n    # One-hot encode and flatten label\n    labels_one_hot = tf.concat(axis=3, values=[tf.equal(labels, i) for i in range(number_of_classes)])\n    flat_labels = tf.reshape(tensor=labels_one_hot, shape=(-1, number_of_classes))\n\n    cross_entropies = tf.nn.softmax_cross_entropy_with_logits_v2(\n        logits=flat_logits, labels=tf.stop_gradient(flat_labels))\n    cross_entropy_sum = tf.reduce_sum(cross_entropies)\n    tf.summary.scalar(\'cross_entropy_loss\', cross_entropy_sum)\n\n    # Tensor to get the final prediction for each pixel\n    pred = tf.argmax(logits, dimension=3)\n\n    with tf.name_scope(\'image_summaries\'):\n        tf.summary.image(\'inputs\', images)\n        print(logits.get_shape())\n        tf.summary.image(\'probabilities\', tf.expand_dims(tf.nn.softmax(logits)[:,:,:,1], axis=3))\n        tf.summary.image(\n            \'prediction\',\n            tf.expand_dims(math.floor(255 / number_of_classes) * tf.cast(pred, tf.uint8), axis=3))\n\n    with tf.variable_scope(""optimizer""):\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n        gradients = optimizer.compute_gradients(loss=cross_entropy_sum)\n\n        for grad_var_pair in gradients:\n            curr_var = grad_var_pair[1]\n            curr_grad = grad_var_pair[0]\n\n            tf.summary.histogram(curr_var.name.replace(\':\', \'_\') + \'-grad\', curr_grad)\n\n        train_step = optimizer.apply_gradients(grads_and_vars=gradients)\n\n    image_summaries = tf.summary.merge_all(scope=r""image_summaries"")\n    other_summaries = tf.summary.merge_all(scope=r""^((?!image_summaries).)*$"")\n\n    train_writer = tf.summary.FileWriter(\'./logs/train\')\n    test_writer = tf.summary.FileWriter(\'./logs/test\')\n\n    with tf.Session() as sess:\n        tf.global_variables_initializer().run()\n        training_handle = sess.run(training_iterator.string_handle())\n        test_handle = sess.run(test_iterator.string_handle())\n\n        print(\'Training started. Run `tensorboard --logdir ./logs` to visualize summaries\')\n\n        for i in range(1000):\n            summary, _ = sess.run([other_summaries, train_step], feed_dict={\n                handle: training_handle,\n                dropout_keep_prob: 0.5})\n            train_writer.add_summary(summary, i)\n\n            if i % 1 == 0: # evaluate on test set every iteration to generate visualizations\n                sess.run(test_iterator.initializer)\n                # NOTE: train_step must not be called with `test_handle` feed!\n                summary, summary_images = sess.run([other_summaries, image_summaries], feed_dict={\n                    handle: test_handle,\n                    dropout_keep_prob: 1.0})\n                test_writer.add_summary(summary, i)\n                test_writer.add_summary(summary_images, i)\n\n\n'"
exporters/voc-exporter/pascal_voc_writer/__init__.py,0,"b'""""""\nPascal VOC writer, forked from https://github.com/AndrewCarterUK/pascal-voc-writer\n""""""\nimport os\nfrom jinja2 import Environment, FileSystemLoader\n\n\nclass Writer:\n    ""Class for writing Pascal VOC annotation formats.""\n    def __init__(self, path, width, height):\n\n        root = os.path.dirname(os.path.abspath(__file__))\n        templates_dir = os.path.join(root, \'templates\')\n        environment = Environment( loader = FileSystemLoader(templates_dir), keep_trailing_newline=True)\n        self.annotation_template = environment.get_template(\'annotation.xml\')\n\n        abspath = os.path.abspath(path)\n\n        self.template_parameters = {\n            \'path\': abspath,\n            \'filename\': os.path.basename(abspath),\n            \'folder\': os.path.basename(os.path.dirname(abspath)),\n            \'width\': width,\n            \'height\': height,\n            \'depth\': 3,\n            \'database\': \'Unknown\',\n            \'segmented\': 0,\n            \'objects\': []\n        }\n\n    def add_object(self, name, xy_coords):\n        """"""\n        Adds an annotation object represented by `xy_coords` to the current annotation being built.\n\n        The object can be a bounding box or polygon. This method will detect\n        a bounding box annotation and create the appropriate output.\n        """"""\n        # figure out if label is bounding box or polygon\n        if len(xy_coords) == 8:\n            x_points = sorted(xy_coords[::2])\n            y_points = sorted(xy_coords[1::2])\n\n            # quantize up to 1 px off to bounding boxes\n            if abs(x_points[0] - x_points[1]) < 1 \\\n                    and abs(x_points[2] - x_points[3]) < 1 \\\n                    and abs(y_points[0] - y_points[1]) < 1 \\\n                    and abs(y_points[2] - y_points[3]) < 1:\n                x_points[0] = x_points[1]\n                x_points[2] = x_points[3]\n                label_type = \'bndbox\'\n            else:\n                label_type = \'polygon\'\n        else:\n            label_type = \'polygon\'\n\n        self.template_parameters[\'objects\'].append({\n            \'name\': name,\n            \'type\': label_type,\n            \'xy_coords\': xy_coords,\n            \'pose\': \'Unspecified\',\n            \'truncated\': 0,\n            \'difficult\': 0,\n        })\n\n    def save(self, annotation_path):\n        ""Saves the current annotation to `annotation_path`.""\n        with open(annotation_path, \'w\') as file:\n            content = self.annotation_template.render(**self.template_parameters)\n            file.write(content)\n'"
custom-interfaces/video-segmentation-beaverdam/annotator/migrations/0001_initial.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.9 on 2016-07-11 23:25\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    initial = True\n\n    dependencies = [\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='Video',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('name', models.CharField(blank=True, max_length=100)),\n                ('annotation', models.TextField(blank=True)),\n                ('source', models.CharField(blank=True, max_length=1048)),\n                ('url', models.CharField(blank=True, max_length=1048)),\n            ],\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/annotator/migrations/0002_auto_20160720_1851.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.9.7 on 2016-07-21 01:51\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('annotator', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.RenameField(\n            model_name='video',\n            old_name='url',\n            new_name='host',\n        ),\n        migrations.RemoveField(\n            model_name='video',\n            name='name',\n        ),\n        migrations.AddField(\n            model_name='video',\n            name='filename',\n            field=models.CharField(blank=True, max_length=100, unique=True),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/annotator/migrations/0003_video_verified.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.9.7 on 2016-07-21 19:56\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('annotator', '0002_auto_20160720_1851'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='video',\n            name='verified',\n            field=models.BooleanField(default=False),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/annotator/migrations/0004_add_label_model.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2016-11-17 02:46\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('annotator', '0003_video_verified'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='Label',\n            fields=[\n                ('id', models.AutoField(primary_key=True, serialize=False)),\n                ('name', models.CharField(blank=True, max_length=100, unique=True)),\n                ('color', models.CharField(blank=True, max_length=6)),\n            ],\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/annotator/migrations/0005_image_lists.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2016-11-17 06:07\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('annotator', '0004_add_label_model'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='video',\n            name='image_list',\n            field=models.TextField(blank=True),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/annotator/migrations/0006_video_rejected.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2016-11-28 03:07\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('annotator', '0005_image_lists'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='video',\n            name='rejected',\n            field=models.BooleanField(default=False),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/annotator/migrations/0007_auto_20170417_1814.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2017-04-18 01:14\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('annotator', '0006_video_rejected'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='label',\n            name='color',\n            field=models.CharField(blank=True, help_text='6 digit hex.', max_length=6),\n        ),\n        migrations.AlterField(\n            model_name='label',\n            name='name',\n            field=models.CharField(blank=True, help_text='Name of class label option.', max_length=100, unique=True),\n        ),\n        migrations.AlterField(\n            model_name='video',\n            name='annotation',\n            field=models.TextField(blank=True, help_text='A JSON blob containing all user annotation sent from client.'),\n        ),\n        migrations.AlterField(\n            model_name='video',\n            name='filename',\n            field=models.CharField(blank=True, help_text='Name of the video file.The video should be publically accessible by at <host><filename>.', max_length=100),\n        ),\n        migrations.AlterField(\n            model_name='video',\n            name='host',\n            field=models.CharField(blank=True, help_text='Path to prepend to filenames to form the url for this video or the images in `image_list`.', max_length=1048),\n        ),\n        migrations.AlterField(\n            model_name='video',\n            name='image_list',\n            field=models.TextField(blank=True, help_text='List of filenames of images to be used as video frames, in JSON format.When present, image list is assumed and <filename> is ignored.'),\n        ),\n        migrations.AlterField(\n            model_name='video',\n            name='rejected',\n            field=models.BooleanField(default=False, help_text='Rejected by expert.'),\n        ),\n        migrations.AlterField(\n            model_name='video',\n            name='source',\n            field=models.CharField(blank=True, help_text='Name of video source or type, for easier grouping/searching of videos.This field is not used by BeaverDam and only facilitates querying on videos by type.', max_length=1048),\n        ),\n        migrations.AlterField(\n            model_name='video',\n            name='verified',\n            field=models.BooleanField(default=False, help_text='Verified as correct by expert.'),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/annotator/migrations/0008_video_labels.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2017-07-25 18:49\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('annotator', '0007_auto_20170417_1814'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='video',\n            name='labels',\n            field=models.ManyToManyField(to='annotator.Label'),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/annotator/migrations/0009_auto_20170815_1341.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2017-08-15 20:41\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('annotator', '0008_video_labels'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='video',\n            name='labels',\n            field=models.ManyToManyField(blank=True, to='annotator.Label'),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/annotator/migrations/0010_state.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2018-01-09 10:33\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\nimport django.db.models.deletion\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('annotator', '0009_auto_20170815_1341'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='State',\n            fields=[\n                ('id', models.AutoField(primary_key=True, serialize=False)),\n                ('name', models.CharField(blank=True, help_text='Name of class label option.', max_length=100)),\n                ('color', models.CharField(blank=True, help_text='6 digit hex.', max_length=6)),\n                ('label_name', models.ForeignKey(blank=True, on_delete=django.db.models.deletion.CASCADE, to='annotator.Label', to_field='name')),\n            ],\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/annotator/migrations/__init__.py,0,b''
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/0001_initial.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.9 on 2016-07-11 23:25\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\nimport django.db.models.deletion\n\n\nclass Migration(migrations.Migration):\n\n    initial = True\n\n    dependencies = [\n        ('annotator', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='FullVideoTask',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('hit_id', models.CharField(blank=True, max_length=64)),\n                ('hit_group', models.CharField(blank=True, max_length=64)),\n                ('video', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='annotator.Video')),\n            ],\n            options={\n                'abstract': False,\n            },\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/0002_auto_20160814_1053.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.9.7 on 2016-08-14 17:53\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\nimport django.db.models.deletion\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('annotator', '0003_video_verified'),\n        ('mturk', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='SingleFrameTask',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                ('hit_id', models.CharField(blank=True, max_length=64)),\n                ('hit_group', models.CharField(blank=True, max_length=64)),\n                ('worker_id', models.CharField(blank=True, max_length=64)),\n                ('sandbox', models.BooleanField(default=True)),\n                ('time', models.FloatField()),\n                ('video', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='annotator.Video')),\n            ],\n            options={\n                'abstract': False,\n            },\n        ),\n        migrations.AddField(\n            model_name='fullvideotask',\n            name='sandbox',\n            field=models.BooleanField(default=True),\n        ),\n        migrations.AddField(\n            model_name='fullvideotask',\n            name='worker_id',\n            field=models.CharField(blank=True, max_length=64),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/0003_auto_20160815_1525.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.9 on 2016-08-15 22:25\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('mturk', '0002_auto_20160814_1053'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='fullvideotask',\n            name='assignment_id',\n            field=models.CharField(blank=True, max_length=64),\n        ),\n        migrations.AddField(\n            model_name='singleframetask',\n            name='assignment_id',\n            field=models.CharField(blank=True, max_length=64),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/0004_auto_20160816_0109.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.9 on 2016-08-16 08:09\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('mturk', '0003_auto_20160815_1525'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='fullvideotask',\n            name='bonus',\n            field=models.DecimalField(decimal_places=2, default=0, max_digits=3),\n        ),\n        migrations.AddField(\n            model_name='fullvideotask',\n            name='paid',\n            field=models.BooleanField(default=False),\n        ),\n        migrations.AddField(\n            model_name='singleframetask',\n            name='bonus',\n            field=models.DecimalField(decimal_places=2, default=0, max_digits=3),\n        ),\n        migrations.AddField(\n            model_name='singleframetask',\n            name='paid',\n            field=models.BooleanField(default=False),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/0005_auto_20160816_1512.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.9 on 2016-08-16 22:12\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('mturk', '0004_auto_20160816_0109'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='fullvideotask',\n            name='time_completed',\n            field=models.DateTimeField(null=True),\n        ),\n        migrations.AddField(\n            model_name='singleframetask',\n            name='time_completed',\n            field=models.DateTimeField(null=True),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/0006_auto_20160821_2258.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2016-08-22 05:58\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('mturk', '0005_auto_20160816_1512'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='fullvideotask',\n            name='metrics',\n            field=models.TextField(blank=True),\n        ),\n        migrations.AddField(\n            model_name='singleframetask',\n            name='metrics',\n            field=models.TextField(blank=True),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/0007_auto_20161122_1349.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2016-11-22 21:49\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('mturk', '0006_auto_20160821_2258'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='fullvideotask',\n            name='time_completed',\n            field=models.DateTimeField(blank=True, null=True),\n        ),\n        migrations.AlterField(\n            model_name='singleframetask',\n            name='time_completed',\n            field=models.DateTimeField(blank=True, null=True),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/0008_auto_20161127_1907.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2016-11-28 03:07\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('mturk', '0007_auto_20161122_1349'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='fullvideotask',\n            name='closed',\n            field=models.BooleanField(default=False),\n        ),\n        migrations.AddField(\n            model_name='fullvideotask',\n            name='message',\n            field=models.CharField(blank=True, max_length=256),\n        ),\n        migrations.AddField(\n            model_name='singleframetask',\n            name='closed',\n            field=models.BooleanField(default=False),\n        ),\n        migrations.AddField(\n            model_name='singleframetask',\n            name='message',\n            field=models.CharField(blank=True, max_length=256),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/0009_auto_20161128_0119.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2016-11-28 09:19\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('mturk', '0008_auto_20161127_1907'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='fullvideotask',\n            name='bonus',\n            field=models.DecimalField(decimal_places=2, default=0, max_digits=4),\n        ),\n        migrations.AlterField(\n            model_name='singleframetask',\n            name='bonus',\n            field=models.DecimalField(decimal_places=2, default=0, max_digits=4),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/0010_auto_20161129_1806.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2016-11-30 02:06\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('mturk', '0009_auto_20161128_0119'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='fullvideotask',\n            name='email_trail',\n            field=models.TextField(blank=True),\n        ),\n        migrations.AddField(\n            model_name='singleframetask',\n            name='email_trail',\n            field=models.TextField(blank=True),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/0011_auto_20161129_1859.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2016-11-30 02:59\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('mturk', '0010_auto_20161129_1806'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='fullvideotask',\n            name='last_email_sent_date',\n            field=models.DateTimeField(blank=True, null=True),\n        ),\n        migrations.AddField(\n            model_name='singleframetask',\n            name='last_email_sent_date',\n            field=models.DateTimeField(blank=True, null=True),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/0012_auto_20170417_1814.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by Django 1.10 on 2017-04-18 01:14\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('mturk', '0011_auto_20161129_1859'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='fullvideotask',\n            name='assignment_id',\n            field=models.CharField(blank=True, help_text='ID of matching between this task and a worker. Used for authentication', max_length=64),\n        ),\n        migrations.AlterField(\n            model_name='fullvideotask',\n            name='hit_group',\n            field=models.CharField(blank=True, help_text='Group ID on Mturk. HITs with same title/description usually are placed in the same group by MTurk. Auto-populated when publishing.', max_length=64),\n        ),\n        migrations.AlterField(\n            model_name='fullvideotask',\n            name='hit_id',\n            field=models.CharField(blank=True, help_text='ID on MTurk. Auto-populated when publishing', max_length=64),\n        ),\n        migrations.AlterField(\n            model_name='fullvideotask',\n            name='worker_id',\n            field=models.CharField(blank=True, help_text='ID of worker who submitted this HIT', max_length=64),\n        ),\n        migrations.AlterField(\n            model_name='singleframetask',\n            name='assignment_id',\n            field=models.CharField(blank=True, help_text='ID of matching between this task and a worker. Used for authentication', max_length=64),\n        ),\n        migrations.AlterField(\n            model_name='singleframetask',\n            name='hit_group',\n            field=models.CharField(blank=True, help_text='Group ID on Mturk. HITs with same title/description usually are placed in the same group by MTurk. Auto-populated when publishing.', max_length=64),\n        ),\n        migrations.AlterField(\n            model_name='singleframetask',\n            name='hit_id',\n            field=models.CharField(blank=True, help_text='ID on MTurk. Auto-populated when publishing', max_length=64),\n        ),\n        migrations.AlterField(\n            model_name='singleframetask',\n            name='worker_id',\n            field=models.CharField(blank=True, help_text='ID of worker who submitted this HIT', max_length=64),\n        ),\n    ]\n"""
custom-interfaces/video-segmentation-beaverdam/mturk/migrations/__init__.py,0,b''
custom-interfaces/video-segmentation-beaverdam/mturk/scripts/pay_confirmed_bonuses.py,0,"b'from mturk.models import FullVideoTask\nfrom mturk.mturk_api import Server\nfrom beaverdam import settings\n\nmturk = Server(settings.AWS_ID, settings.AWS_KEY, settings.URL_ROOT, settings.MTURK_SANDBOX)\n\ntasks = FullVideoTask.objects.filter(paid = False, video__verified = True).exclude(hit_id = \'\')\n\ndef calc_bonus(task):\n    res = mturk.request(\'GetAssignmentsForHIT\', {""HITId"":tasks[0].hit_id})\n    if res.has_path(""GetAssignmentsForHITResult/Assignment"") :\n        res.store(""GetAssignmentsForHITResult/Request/IsValid"", ""IsValid"", bool)\n        res.store(""GetAssignmentsForHITResult/Assignment/AssignmentId"", ""AssignmentId"")\n        res.store(""GetAssignmentsForHITResult/Assignment/WorkerId"", ""WorkerId"")\n        print(""Is valid = "" + str(res.IsValid)) \n        print(""Assignment id = "" + res.AssignmentId)\n        print(""worker id = "" + res.WorkerId)\n        task.complete(res.WorkerId, res.AssignmentId, \'Thanks for completing this - your bonus has been paid as {}\'.format(task.calculate_bonus()))\n\ndef calc_bonuses(tasks):\n    print(""{} tasks to process"".format(len(tasks)))\n    for task in tasks:\n        print(""Paying {}"".format(task.video.filename))\n        calc_bonus(task)\n\ncalc_bonuses(tasks)\n'"
custom-interfaces/video-segmentation-beaverdam/mturk/scripts/playground.py,0,"b'from mturk.models import FullVideoTask\nfrom annotator.models import Video\nfrom mturk.mturk_api import Server\nfrom beaverdam import settings\n\nmturk = Server(settings.AWS_ID, settings.AWS_KEY, settings.URL_ROOT, settings.MTURK_SANDBOX)\n\ndef get_hit_for_video(full_video_task):\n    res = mturk.request(\'GetHIT\', {""HITId"":full_video_task.hit_id})\n    res.store(""HIT/HITStatus"", ""status"")\n    res.store(""HIT/HITId"", ""hitID"")\n    print(full_video_task.video.filename)\n    print(""   - status={}, hitid={}"".format(res.status, res.hitID))\n    # if res.has_path(""GetAssignmentsForHITResult/Assignment"") :\n    #     res.store(""GetAssignmentsForHITResult/Request/IsValid"", ""IsValid"", bool)\n    #     res.store(""GetAssignmentsForHITResult/Assignment/AssignmentId"", ""AssignmentId"")\n    #     res.store(""GetAssignmentsForHITResult/Assignment/WorkerId"", ""WorkerId"")\n    #     print(""Is valid = "" + str(res.IsValid)) \n    #     print(""Assignment id = "" + res.AssignmentId)\n    #     print(""worker id = "" + res.WorkerId)\n    #     task.complete(res.WorkerId, res.AssignmentId, \'Thanks for completing this - your bonus has been paid as {}\'.format(task.calculate_bonus()))\n\ndef get_hits_for_video(video_tasks):\n    print(""{} tasks to process"".format(len(video_tasks)))\n    for task in video_tasks:\n        get_hit_for_video(task)\n\ndef get_completed_videos():\n    vids = Video.objects.filter(verified=True)\n    for vid in vids:\n        print(vid.id)\n\ndef get_tasks_by_hit_id(hitid):\n    fvs = FullVideoTask.objects.filter(hit_id = hitid)\n    print(""Returned: "" + str(len(fvs)))\n\ndef dump_all_tasks():\n    fvs = FullVideoTask.objects.exclude(hit_id = \'\')\n    for x in fvs:\n        print(x.hit_id)\n\ntasks = FullVideoTask.objects.filter(sandbox = False).exclude(hit_id = \'\')\nget_hits_for_video(tasks)\n#get_completed_videos()\n\n#get_tasks_by_hit_id(""3DQYSJDTYL1LBN7L0I2B6FA1K3YXEA"")\n#dump_all_tasks()\n'"
custom-interfaces/video-segmentation-beaverdam/mturk/scripts/publish.py,0,"b'from mturk.models import FullVideoTask\nfrom beaverdam import settings\n\n\nprint(settings.MTURK_SANDBOX)\n\ndef publish(arr):\n    count = 0\n    total = 0\n    for x in arr:\n        print(""Publishing {}"".format(x.video.filename))\n        if x.sandbox :\n            x.sandbox = False;\n            x.save()\n        x.publish()\n\narr = FullVideoTask.objects.filter(video__pk__in = [1541,1676,1774,1812,2010], video__verified = False)\npublish(arr)\n'"
custom-interfaces/video-segmentation-beaverdam/annotator/management/commands/export_annotations.py,0,"b""from django.core.management.base import BaseCommand, CommandError\nfrom annotator.models import Video\nimport os\nimport json\nimport re\nimport os\nimport shutil\nimport subprocess\nimport math\n\n\nclass Command(BaseCommand):\n\thelp = r'''Exports video annotations\n\nThis command creates JSON annotation files from video annotations. Besides keyframe annotations\nthis script also creates dense annotations, i.e interpolates between keyframes. To do so, the \nFPS of the video is required, which can be deduced automatically by video probing (requires ffmpeg).\n\n\tpython manage.py export_annotations\n\nWill create JSON annotation files for each video that has annotations. Use `--filter-` arguments\nto limit the number of matching video files. For example\n\n\tpython manage.py export_annotations --filter-ids 1 5 --filter-verified \n\nwould limit export to videos 1 and 5 if they are verified. \n\nA note on dense annotations: Dense annotations will be created between the first and last keyframe.\nBetween keyframes linear interpolation is used to advance bounding rectangle information. State \ninformation is always copied from the earlier of two keyframes involved in interpolation. \nInterpolation will be replaced by a direct keyframe copy if the keyframe timestamp is within `eps` of\nthe current timestamp.\n'''\n\n\tdef add_arguments(self, parser):\t\n\t\tparser.add_argument('--fps', type=float, help='Number of frames / second. If omitted, video will be probed for fps.')\n\t\tparser.add_argument('--out-dir', help='Output directory', default='./exported_annotations')\n\t\tparser.add_argument('--out-use-filename', action='store_true', help='Use filename property instead of video id when exporting.')\n\t\tparser.add_argument('--field', help='JSON field name to hold dense annotations', default='frames')\n\t\tparser.add_argument('--eps', type=float, help='Approximate key frame matching threshold. If omitted will computed based on fps.')\n\t\tparser.add_argument('--filter-ids', type=int, nargs='+', help='Only export these video ids.')\t\t\n\t\tparser.add_argument('--filter-verified', action='store_true', help='Only export verified annotations.')\t\t\n\t\tparser.add_argument('--sparse', action='store_true', help='Do not create dense annotations.')\n\t\tparser.add_argument('--probe-seconds', type=int, help='Limit video probing to first n seconds of video.', default=2)\n\n\tdef handle(self, *args, **options):\n\t\tos.makedirs(options['out_dir'], exist_ok=True)\n\n\t\t# Filter videos\n\t\tfilter_set = Video.objects.filter(annotation__gt='')\n\t\tif options['filter_ids']:\n\t\t\tfilter_set &= Video.objects.filter(id__in=options['filter_ids'])\n\t\tif options['filter_verified']:\n\t\t\tfilter_set &= Video.objects.filter(verified=True)\n\n\t\tprint('Found {} videos matching filter query'.format(len(filter_set)))\n\n\t\tfor vid in filter_set:\n\t\t\tprint('Processing video {}'.format(vid))\n\t\t\tself.export_annotations(vid, options)\n\n\tdef export_annotations(self, video, options):\t\t\n\t\tcontent = json.loads(video.annotation)\n\n\t\tif not options['sparse']:\n\t\t\n\t\t\tfps = options['fps']\n\t\t\tif fps is None:\n\t\t\t\tprint('--Probing video {}'.format(video.id))\n\t\t\t\tfps = self.probe_video(video, probesecs=options['probe_seconds'])\n\t\t\t\tif fps is None:\n\t\t\t\t\tprint('--Failed to probe.')\n\t\t\t\t\treturn\n\t\t\t\tprint('--Estimated fps {:.2f}'.format(fps))\n\n\t\t\teps = options['eps']\n\t\t\tif eps is None:\n\t\t\t\teps = (1 / fps) * 0.5\n\t\t\t\tprint('--Computing eps as {:.2f}'.format(eps))\n\n\t\t\tfor obj in content:\t\t\t\t\n\t\t\t\tframes = self.create_dense_annotations(obj, eps, fps)\n\t\t\t\tobj[options['field']] = frames\n\t\t\t\tprint('--Created {} dense annotations for object {}'.format(len(frames), obj['id']))\n\t\t\n\t\tfilename = str(video.id) + '.json'\n\t\tif options['out_use_filename'] and len(video.filename) > 0:\n\t\t\tfilename = str(video.filename) + '.json'\n\t\toutpath = os.path.normpath(os.path.join(options['out_dir'], filename))\n\t\twith open(outpath, 'w') as fh:\n\t\t\tjson.dump(content, fh, indent=4)\n\t\tprint('--Saved annotations to {}'.format(outpath))\n\n\tdef probe_video(self, video, probesecs):\n\t\t'''Probe video file or image directory for FPS and number of frames.'''\n\t\turl = video.url\n\n\t\tif url == 'Image List':\n\t\t\treturn 1 # 1 FPS\n\t\telse:\n\t\t\tROOT = os.path.join(os.path.dirname(__file__), '..', '..', '..')\n\t\t\t\n\t\t\tcmd = [\n\t\t\t\t'ffprobe', \n\t\t\t\t'-hide_banner',\t\t\t\t\n\t\t\t\t'-print_format', 'json',\n\t\t\t\t'-read_intervals', '%+{}'.format(probesecs),\n\t\t\t\t'-show_streams', \n\t\t\t\t'-count_frames',\n\t\t\t\t'-select_streams', 'v:0'\n\t\t\t]\n\t\t\t\n\t\t\tif not url.startswith('http'):\t\n\t\t\t\t# Local file path, relative to serving directory\t\t\t\n\t\t\t\turl = os.path.normpath(os.path.join(ROOT, 'annotator', url.strip('/')))\n\t\t\telse:\n\t\t\t\t# Timeout for reaching remote file\n\t\t\t\tcmd.extend(['-timeout', str(int(5e6))])\n\t\t\t\n\t\t\tcmd.extend(['-i', url])\n\n\t\t\ttry:   \n\t\t\t\tp = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)    \n\t\t\t\tout, err =  p.communicate()\n\t\t\t\tif p.returncode != 0:\n\t\t\t\t\tprint('--Failed to probe video with error {}'.format(err))\n\t\t\t\t\treturn None\n\t\t\t\t\n\t\t\t\tcontent = json.loads(out.decode('utf-8'))\n\t\t\t\tstream = content['streams'][0]\n\t\t\t\treturn eval(stream['r_frame_rate'])\n\t\t\texcept FileNotFoundError:\n\t\t\t\tprint('--Failed to find `ffprobe`. Make sure to have `ffmpeg` in your PATH.')\n\t\t\t\treturn None\n\t\t\t\n\n\n\tdef create_dense_annotations(self, obj, eps, fps):\n\t\t'''Creates dense annotations for a BeaverDam JSON object.\n\t\t\n\t\tDense annotations will be created between the first and last keyframe.\n\t\tBetween keyframes linear interpolation is used to advance bounding rectangle\n\t\tinformation. State information is always copied from the earlier of two\n\t\tkeyframes involved in interpolation. Interpolation will be replaced by a\n\t\tdirect keyframe copy if the keyframe timestamp is within `eps` of\n\t\tthe current timestamp.\n\t\t\n\t\tThe following information is stored within generated annotations:\n\t\t\t- `frameid` : Zero based frame index.\n\t\t\t- `frame`: timestamp of current frame, computed as `framerate * frameid`.\n\t\t\t- `state`: State set during labeling. See BeaverDam documentation.\n\t\t\t- `x,y,w,h`: Bounds information.\n\t\t\t- `refid`: Keyframe reference index if direct keyframe copy is applied.\n\t\t'''\n\n\t\tkeyframes = sorted(obj['keyframes'], key=lambda x: x['frame'])\n\t\t\t\n\t\tnewframes = []\n\t\tif len(keyframes) == 0:\n\t\t\treturn newframes\n\n\t\tframerate = 1. / fps\n\t\tfidx = int(math.floor(keyframes[0]['frame'] / framerate))\n\t\tknext = 0\n\t\t\n\t\twhile knext < len(keyframes):        \n\n\t\t\ttnext = keyframes[knext]['frame']\n\t\t\tt = fidx * framerate\n\t\t\ttd = tnext - t\n\t\t\t\n\t\t\tisinrange = abs(td) <= eps\n\n\t\t\tif isinrange:\n\t\t\t\tframe = dict(keyframes[knext])\n\t\t\t\tframe['frame'] = t\n\t\t\t\tframe['frameid'] = fidx    \n\t\t\t\tframe['refid'] = knext   \n\t\t\t\tnewframes.append(frame)\n\t\t\telif knext > 0:\n\t\t\t\tkprev = knext - 1\n\t\t\t\tfrac = (t - keyframes[kprev]['frame']) / (tnext - keyframes[kprev]['frame'])\n\t\t\t\tcloser = kprev if frac <= 0.5 else knext\n\t\t\t\tb = self.interpolate(\n\t\t\t\t\tself.bounds_from_json(keyframes[kprev]), \n\t\t\t\t\tself.bounds_from_json(keyframes[knext]), \n\t\t\t\t\tfrac)\n\n\t\t\t\tframe = dict(keyframes[closer])\n\t\t\t\tframe['frame'] = t\n\t\t\t\tframe['state'] = keyframes[kprev]['state']\n\t\t\t\tframe['frameid'] = fidx\n\t\t\t\tframe.update(self.bounds_to_json(b))\n\t\t\t\tnewframes.append(frame)\n\n\t\t\tif t + framerate > tnext:\n\t\t\t\tknext += 1\n\n\t\t\tfidx += 1\n\n\t\treturn newframes\n\n\tdef bounds_from_json(self, e):\n\t\t'''Reads bounds from BeaverDam JSON.'''\n\t\treturn [e['x'], e['x'] + e['w'], e['y'], e['y'] + e['h']]\n\n\tdef bounds_to_json(self, b):\n\t\t'''Converts array format to BeaverDam JSON.'''\n\t\treturn {'x' : b[0], 'y' : b[2], 'w' : b[1] - b[0], 'h' : b[3] - b[2]}\n\n\tdef interpolate(self, src, dst, frac):\n\t\t'''Linear interpolation of rectangles.'''\n\t\tifrac = 1.0 - frac\n\t\treturn [s*ifrac + d*frac for s,d in zip(src, dst)]\n"""
custom-interfaces/video-segmentation-beaverdam/annotator/management/commands/import_images_from_dir.py,0,"b'from django.core.management.base import BaseCommand, CommandError\nfrom annotator.models import Video\nimport os\nimport json\nimport re\nimport os\nimport shutil\n\n# referring to https://stackoverflow.com/questions/5967500/how-to-correctly-sort-a-string-with-a-number-inside for ""human sorting""\ndef atoi(text):\n\t    return int(text) if text.isdigit() else text\n\ndef natural_keys(text):\n\t    return [ atoi(c) for c in re.split(\'(\\d+)\', text) ]\n\nclass Command(BaseCommand):\n\thelp = ""Imports a directory of images as a new view object""\n\n\tdef add_arguments(self, parser):\n\t\tparser.add_argument(\'directory\')\n\n\tdef handle(self, *args, **options):\n\t\tif (options[\'directory\']):\n\t\t\tself.create_entry_from_dir(options[\'directory\'])\n\n\tdef create_entry_from_dir(self, directory):\n\t\tworking_dir = os.getcwd()\n\t\tif os.path.basename(working_dir) != ""BeaverDam"":\n\t\t\tself.stdout.write(f""Make the working directory BeaverDam root. Current working directory is {working_dir}"")\n\t\ti = 1\n\t\thost = f\'/static/image_import{i}\'\n\t\tdest_folder = \'annotator\'+host\n\t\twhile os.path.isdir(dest_folder):\n\t\t\ti+=1\n\t\t\thost = f\'/static/image_import{i}\'\n\t\t\tdest_folder = \'annotator\'+host\n\n\t\tos.makedirs(dest_folder)\n\t\tdir_list = os.listdir(directory)\n\t\tfile_list = []\n\t\tfor file in dir_list:\n\t\t\tfile_path = os.path.join(directory, file)\n\t\t\tif (os.path.isfile(file_path)):\n\t\t\t\tfile_list.append(file)\n\t\t\t\tshutil.copy(file_path, dest_folder)\n\n\t\tfile_list.sort(key = natural_keys)\n\t\timage_list_json = json.dumps(file_list)\n\t\tv = Video(image_list = image_list_json, host = host)\n\t\tv.save()\n\t\tself.stdout.write(f""Video {v.id} was made"")\n'"
