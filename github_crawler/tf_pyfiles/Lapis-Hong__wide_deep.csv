file_path,api_count,code
python/eval.py,8,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/1/15\n""""""Wide and Deep Model Evaluation""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport argparse\nimport os\nimport sys\nimport time\n\nimport tensorflow as tf\n\nfrom lib.read_conf import Config\nfrom lib.dataset import input_fn\nfrom lib.build_estimator import build_estimator\nfrom lib.utils.util import elapse_time\n\nCONFIG = Config().train\nparser = argparse.ArgumentParser(description=\'Evaluate Wide and Deep Model.\')\n\nparser.add_argument(\n    \'--model_dir\', type=str, default=CONFIG[""model_dir""],\n    help=\'Model checkpoint dir for evaluating.\')\n\nparser.add_argument(\n    \'--model_type\', type=str, default=CONFIG[""model_type""],\n    help=""Valid model types: {\'wide\', \'deep\', \'wide_deep\'}."")\n\nparser.add_argument(\n    \'--test_data\', type=str, default=CONFIG[""test_data""],\n    help=\'Evaluating data dir.\')\n\nparser.add_argument(\n    \'--image_test_data\', type=str, default=CONFIG[""image_test_data""],\n    help=\'Evaluating image data dir.\')\n\nparser.add_argument(\n    \'--batch_size\', type=int, default=CONFIG[""batch_size""],\n    help=\'Number of examples per batch.\')\n\nparser.add_argument(\n    \'--checkpoint_path\', type=str, default=CONFIG[""checkpoint_path""],\n    help=""Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used."")\n\n# TODO\xef\xbc\x9asupport distributed evaluation or not ?\n# parser.add_argument(\n#     \'--is_distribution\', type=int, default=0,\n#     help=\'Evaluating distributional or not\')\n\n\ndef main(unused_argv):\n    print(""Using TensorFlow version %s"" % tf.__version__)\n    assert ""1.4"" <= tf.__version__, ""TensorFlow r1.4 or later is needed""\n    # if FLAGS.is_distribution:\n    #     print(""Using distribution tensoflow. Job_name:{} Task_index:{}""\n    #           .format(CONFIG.distribution[""job_name""], CONFIG.distribution[""task_index""]))\n    print(\'Model type: {}\'.format(FLAGS.model_type))\n    model_dir = os.path.join(FLAGS.model_dir, FLAGS.model_type)\n    print(\'Model directory: {}\'.format(model_dir))\n    model = build_estimator(model_dir, FLAGS.model_type)\n    tf.logging.info(\'Build estimator: {}\'.format(model))\n    # checkpoint_path = FLAGS.checkpoint_path or model.latest_checkpoint()\n    # if checkpoint_path is None:\n    #     raise ValueError(\'No model checkpoint found, please check the model dir.\')\n    # tf.logging.info(\'Using model checkpoint: {}\'.format(checkpoint_path))\n    # print(\'\\n\')\n    tf.logging.info(\'=\'*30+\' START TESTING\'+\'=\'*30)\n    s_time = time.time()\n    results = model.evaluate(input_fn=lambda: input_fn(FLAGS.test_data, FLAGS.image_test_data, \'eval\', FLAGS.batch_size),\n                             steps=None,  # Number of steps for which to evaluate model.\n                             hooks=None,\n                             checkpoint_path=FLAGS.checkpoint_path,  # If None, the latest checkpoint is used.\n                             name=None)\n    tf.logging.info(\'=\'*30+\'FINISH TESTING, TAKE {}\'.format(elapse_time(s_time))+\'=\'*30)\n    # Display evaluation metrics\n    print(\'-\' * 80)\n    for key in sorted(results):\n        print(\'%s: %s\' % (key, results[key]))\n\nif __name__ == \'__main__\':\n    # Set to INFO for tracking training, default is WARN. ERROR for least messages\n    tf.logging.set_verbosity(tf.logging.INFO)\n    FLAGS, unparsed = parser.parse_known_args()\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n'"
python/pred.py,7,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/2/2\n""""""Wide and Deep Model Prediction\nNot support for custom classifier, cause use different variable name scope, key not found in checkpoint""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport argparse\nimport os\nimport sys\nimport time\n\nimport tensorflow as tf\n\nfrom lib.read_conf import Config\nfrom lib.dataset import input_fn\nfrom lib.build_estimator import build_estimator\nfrom lib.utils.util import elapse_time\n\nCONFIG = Config().train\nparser = argparse.ArgumentParser(description=\'Wide and Deep Model Prediction\')\n\nparser.add_argument(\n    \'--model_dir\', type=str, default=CONFIG[""model_dir""],\n    help=\'Model checkpoint dir for evaluating.\')\n\nparser.add_argument(\n    \'--model_type\', type=str, default=CONFIG[""model_type""],\n    help=""Valid model types: {\'wide\', \'deep\', \'wide_deep\'}."")\n\nparser.add_argument(\n    \'--data_dir\', type=str,\n    help=\'Evaluating data dir.\')\n\nparser.add_argument(\n    \'--image_data_dir\', type=str, default=None,\n    help=\'Evaluating image data dir.\')\n\nparser.add_argument(\n    \'--batch_size\', type=int, default=CONFIG[""batch_size""],\n    help=\'Number of examples per batch.\')\n\nparser.add_argument(\n    \'--checkpoint_path\', type=str, default=CONFIG[""checkpoint_path""],\n    help=""Path of a specific checkpoint to predict. If None, the latest checkpoint in model_dir is used."")\n\n\ndef main(unused_argv):\n    print(""Using TensorFlow version %s"" % tf.__version__)\n    assert ""1.4"" <= tf.__version__, ""TensorFlow r1.4 or later is needed""\n    if FLAGS.data_dir is None:\n        raise ValueError(""Must specify prediction data_file by --data_dir"")\n    print(\'Model type: {}\'.format(FLAGS.model_type))\n    model_dir = os.path.join(FLAGS.model_dir, FLAGS.model_type)\n    print(\'Model directory: {}\'.format(model_dir))\n    model = build_estimator(model_dir, FLAGS.model_type)\n    tf.logging.info(\'Build estimator: {}\'.format(model))\n\n    tf.logging.info(\'=\'*30+\'START PREDICTION\'+\'=\'*30)\n    t0 = time.time()\n    predictions = model.predict(input_fn=lambda: input_fn(FLAGS.data_dir, FLAGS.image_data_dir, \'pred\', FLAGS.batch_size),\n                                predict_keys=None,\n                                hooks=None,\n                                checkpoint_path=FLAGS.checkpoint_path)  # defaults None to use latest_checkpoint\n    tf.logging.info(\'=\'*30+\'FINISH PREDICTION, TAKE {} mins\'.format(elapse_time(t0))+\'=\'*30)\n\n    for pred_dict in predictions:  # dict{probabilities, classes, class_ids}\n        class_id = pred_dict[\'class_ids\'][0]\n        probability = pred_dict[\'probabilities\'][class_id]\n        print(\'\\nPrediction is ""{}"" ({:.1f}%)\'.format(class_id, 100 * probability))\n\nif __name__ == \'__main__\':\n    # Set to INFO for tracking training, default is WARN. ERROR for least messages\n    tf.logging.set_verbosity(tf.logging.INFO)\n    FLAGS, unparsed = parser.parse_known_args()\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n'"
python/train.py,30,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/1/15\n""""""Training Wide and Deep Model.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport argparse\nimport os\nimport shutil\nimport sys\nimport time\n\nimport tensorflow as tf\n\nfrom lib.read_conf import Config\nfrom lib.dataset import input_fn\nfrom lib.build_estimator import build_estimator, build_custom_estimator\nfrom lib.utils.util import elapse_time, list_files\n\nCONFIG = Config().train\nparser = argparse.ArgumentParser(description=\'Train Wide and Deep Model.\')\n\nparser.add_argument(\n    \'--model_dir\', type=str, default=CONFIG[""model_dir""],\n    help=\'Base directory for the model.\')\nparser.add_argument(\n    \'--model_type\', type=str, default=CONFIG[""model_type""],\n    help=""Valid model types: {\'wide\', \'deep\', \'wide_deep\'}."")\nparser.add_argument(\n    \'--train_epochs\', type=int, default=CONFIG[""train_epochs""],\n    help=\'Number of training epochs.\')\nparser.add_argument(\n    \'--epochs_per_eval\', type=int, default=CONFIG[""epochs_per_eval""],\n    help=\'The number of training epochs to run between evaluations.\')\nparser.add_argument(\n    \'--batch_size\', type=int, default=CONFIG[""batch_size""],\n    help=\'Number of examples per batch.\')\nparser.add_argument(\n    \'--train_data\', type=str, default=CONFIG[""train_data""],\n    help=\'Path to the train data.\')\nparser.add_argument(\n    \'--eval_data\', type=str, default=CONFIG[""eval_data""],\n    help=\'Path to the validation data.\')\nparser.add_argument(\n    \'--test_data\', type=str, default=CONFIG[""test_data""],\n    help=\'Path to the test data.\')\nparser.add_argument(\n    \'--image_train_data\', type=str, default=CONFIG[""image_train_data""],\n    help=\'Path to the train data.\')\nparser.add_argument(\n    \'--image_eval_data\', type=str, default=CONFIG[""image_eval_data""],\n    help=\'Path to the train data.\')\nparser.add_argument(\n    \'--image_test_data\', type=str, default=CONFIG[""image_test_data""],\n    help=\'Path to the train data.\')\nparser.add_argument(\n    \'--keep_train\', type=int, default=CONFIG[""keep_train""],\n    help=\'Whether to keep training on previous trained model.\')\n\n\ndef train_and_eval(model):\n    for n in range(FLAGS.train_epochs):\n        tf.logging.info(\'=\' * 30 + \' START EPOCH {} \'.format(n + 1) + \'=\' * 30 + \'\\n\')\n        train_data_list = list_files(FLAGS.train_data)  # dir to file list\n        for f in train_data_list:\n            t0 = time.time()\n            tf.logging.info(\'<EPOCH {}>: Start training {}\'.format(n + 1, f))\n            model.train(\n                input_fn=lambda: input_fn(f, FLAGS.image_train_data, \'train\', FLAGS.batch_size),\n                hooks=None,\n                steps=None,\n                max_steps=None,\n                saving_listeners=None)\n            tf.logging.info(\'<EPOCH {}>: Finish training {}, take {} mins\'.format(n + 1, f, elapse_time(t0)))\n            print(\'-\' * 80)\n            tf.logging.info(\'<EPOCH {}>: Start evaluating {}\'.format(n + 1, FLAGS.eval_data))\n            t0 = time.time()\n            results = model.evaluate(\n                input_fn=lambda: input_fn(FLAGS.eval_data, FLAGS.image_eval_data, \'eval\', FLAGS.batch_size),\n                steps=None,  # Number of steps for which to evaluate model.\n                hooks=None,\n                checkpoint_path=None,  # latest checkpoint in model_dir is used.\n                name=None)\n            tf.logging.info(\'<EPOCH {}>: Finish evaluation {}, take {} mins\'.format(n + 1, FLAGS.eval_data, elapse_time(t0)))\n            print(\'-\' * 80)\n            # Display evaluation metrics\n            for key in sorted(results):\n                print(\'{}: {}\'.format(key, results[key]))\n        # every epochs_per_eval test the model (use larger test dataset)\n        if (n+1) % FLAGS.epochs_per_eval == 0:\n            tf.logging.info(\'<EPOCH {}>: Start testing {}\'.format(n + 1, FLAGS.test_data))\n            results = model.evaluate(\n                input_fn=lambda: input_fn(FLAGS.test_data, FLAGS.image_test_data, \'pred\', FLAGS.batch_size),\n                 steps=None,  # Number of steps for which to evaluate model.\n                 hooks=None,\n                 checkpoint_path=None,  # If None, the latest checkpoint in model_dir is used.\n                 name=None)\n            tf.logging.info(\'<EPOCH {}>: Finish testing {}, take {} mins\'.format(n + 1, FLAGS.test_data, elapse_time(t0)))\n            print(\'-\' * 80)\n            # Display evaluation metrics\n            for key in sorted(results):\n                print(\'{}: {}\'.format(key, results[key]))\n\n\ndef dynamic_train(model):\n    """"""Dynamic train mode.\n    For example: \n        train_data_files: [0301, 0302, 0303, ...]\n        train mode:\n            first take 0301 as train data, 0302 as test data;\n            then keep training take 0302 as train data, 0303 as test data ...\n    """"""\n    data_files = list_files(FLAGS.train_data)\n    data_files.sort()\n    assert len(data_files) > 1, \'Dynamic train mode need more than 1 data file\'\n\n    for i in range(len(data_files)-1):\n        train_data = data_files[i]\n        test_data = data_files[i+1]\n        tf.logging.info(\'=\' * 30 + \' START TRAINING DATA: {} \'.format(train_data) + \'=\' * 30 + \'\\n\')\n        for n in range(FLAGS.train_epochs):\n            t0 = time.time()\n            tf.logging.info(\'START TRAIN DATA <{}> <EPOCH {}>\'.format(train_data, n + 1))\n            model.train(\n                input_fn=lambda: input_fn(train_data, FLAGS.image_train_data, \'train\', FLAGS.batch_size),\n                hooks=None,\n                steps=None,\n                max_steps=None,\n                saving_listeners=None)\n            tf.logging.info(\'FINISH TRAIN DATA <{}> <EPOCH {}> take {} mins\'.format(train_data, n + 1, elapse_time(t0)))\n            print(\'-\' * 80)\n            tf.logging.info(\'START EVALUATE TEST DATA <{}> <EPOCH {}>\'.format(test_data, n + 1))\n            t0 = time.time()\n            results = model.evaluate(\n                input_fn=lambda: input_fn(test_data, FLAGS.image_eval_data, \'eval\', FLAGS.batch_size),\n                steps=None,  # Number of steps for which to evaluate model.\n                hooks=None,\n                checkpoint_path=None,  # latest checkpoint in model_dir is used.\n                name=None)\n            tf.logging.info(\'FINISH EVALUATE TEST DATA <{}> <EPOCH {}>: take {} mins\'.format(test_data, n + 1, elapse_time(t0)))\n            print(\'-\' * 80)\n            # Display evaluation metrics\n            for key in sorted(results):\n                print(\'{}: {}\'.format(key, results[key]))\n\n\ndef train(model):\n    for n in range(FLAGS.train_epochs):\n        tf.logging.info(\'=\' * 30 + \' START EPOCH {} \'.format(n + 1) + \'=\' * 30 + \'\\n\')\n        train_data_list = list_files(FLAGS.train_data)  # dir to file list\n        for f in train_data_list:\n            t0 = time.time()\n            tf.logging.info(\'<EPOCH {}>: Start training {}\'.format(n + 1, f))\n            model.train(\n                input_fn=lambda: input_fn(f, FLAGS.image_train_data, \'train\', FLAGS.batch_size),\n                hooks=None,\n                steps=None,\n                max_steps=None,\n                saving_listeners=None)\n            tf.logging.info(\'<EPOCH {}>: Finish training {}, take {} mins\'.format(n + 1, f, elapse_time(t0)))\n\n\ndef train_and_eval_api(model):\n    train_spec = tf.estimator.TrainSpec(input_fn=lambda: input_fn(FLAGS.train_data, FLAGS.image_train_data, FLAGS.batch_size), max_steps=10000)\n    eval_spec = tf.estimator.EvalSpec(input_fn=lambda: input_fn(FLAGS.eval_data, FLAGS.image_eval_data, FLAGS.batch_size))\n    tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n\n\ndef main(unused_argv):\n    CONFIG = Config()\n    print(""Using TensorFlow Version %s"" % tf.__version__)\n    assert ""1.4"" <= tf.__version__, ""Need TensorFlow r1.4 or Later.""\n    print(\'\\nModel Type: {}\'.format(FLAGS.model_type))\n    model_dir = os.path.join(FLAGS.model_dir, FLAGS.model_type)\n    print(\'\\nModel Directory: {}\'.format(model_dir))\n\n    print(""\\nUsing Train Config:"")\n    for k, v in CONFIG.train.items():\n        print(\'{}: {}\'.format(k, v))\n    print(""\\nUsing Model Config:"")\n    for k, v in CONFIG.model.items():\n        print(\'{}: {}\'.format(k, v))\n\n    if not FLAGS.keep_train:\n        # Clean up the model directory if not keep training\n        shutil.rmtree(model_dir, ignore_errors=True)\n        print(\'Remove model directory: {}\'.format(model_dir))\n    # model = build_estimator(model_dir, FLAGS.model_type)\n    model = build_custom_estimator(model_dir, FLAGS.model_type)\n    tf.logging.info(\'Build estimator: {}\'.format(model))\n\n    if CONFIG.train[\'dynamic_train\']:\n        train_fn = dynamic_train\n        print(""Using dynamic train mode."")\n    else:\n        train_fn = train_and_eval\n\n    if CONFIG.distribution[""is_distribution""]:\n        print(""Using PID: {}"".format(os.getpid()))\n        cluster = CONFIG.distribution[""cluster""]\n        job_name = CONFIG.distribution[""job_name""]\n        task_index = CONFIG.distribution[""task_index""]\n        print(""Using Distributed TensorFlow. Local host: {} Job_name: {} Task_index: {}""\n              .format(cluster[job_name][task_index], job_name, task_index))\n        cluster = tf.train.ClusterSpec(CONFIG.distribution[""cluster""])\n        server = tf.train.Server(cluster,\n                                 job_name=job_name,\n                                 task_index=task_index)\n        # distributed can not including eval.\n        train_fn = train\n        if job_name == \'ps\':\n            # wait for incoming connection forever\n            server.join()\n            # sess = tf.Session(server.target)\n            # queue = create_done_queue(task_index, num_workers)\n            # for i in range(num_workers):\n            #     sess.run(queue.dequeue())\n            #     print(""ps {} received worker {} done"".format(task_index, i)\n            # print(""ps {} quitting"".format(task_index))\n        else:  # TODO\xef\xbc\x9asupervisor & MonotoredTrainingSession & experiment (deprecated)\n            train_fn(model)\n            # train_and_eval(model)\n            # Each worker only needs to contact the PS task(s) and the local worker task.\n            # config = tf.ConfigProto(device_filters=[\n            #     \'/job:ps\', \'/job:worker/task:%d\' % arguments.task_index])\n            # with tf.device(tf.train.replica_device_setter(\n            #         worker_device=""/job:worker/task:%d"" % task_index,\n            #         cluster=cluster)):\n            # e = _create_experiment_fn()\n            # e.train_and_evaluate()  # call estimator\'s train() and evaluate() method\n            # hooks = [tf.train.StopAtStepHook(last_step=10000)]\n            # with tf.train.MonitoredTrainingSession(\n            #         master=server.target,\n            #         is_chief=(task_index == 0),\n            #         checkpoint_dir=args.model_dir,\n            #         hooks=hooks) as mon_sess:\n            #     while not mon_sess.should_stop():\n            #         # mon_sess.run()\n            #         classifier.fit(input_fn=train_input_fn, steps=1)\n    else:\n        # local run\n        train_fn(model)\n\n\nif __name__ == \'__main__\':\n    # Set to INFO for tracking training, default is WARN. ERROR for least messages\n    tf.logging.set_verbosity(tf.logging.INFO)\n    FLAGS, unparsed = parser.parse_known_args()\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n'"
python/lib/__init__.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/3/12\n""""""lib is a python package\n\nwhen use absolute import in package, can not execute file directly (ImportError)\n\nadd package dir to sys.path fix this issue.\n\ncd directory outside lib, then \n\npython -m lib.dataset\n\n""""""\nimport os\nimport sys\nPACKAGE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, PACKAGE_DIR)\n'"
python/lib/build_estimator.py,42,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/1/15\n""""""\nBuild feature columns using tf.feature_column API.\nBuild estimator using tf.estimator API and custom API (defined in lib module)\nUse function `build_estimator` to use official classifier\nUse function `build_costum_estimator` to use custom classifier.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\n\nimport numpy as np\nimport tensorflow as tf\n\n# fix ImportError: No mudule named lib.*\nimport sys\nPACKAGE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, PACKAGE_DIR)\n\nfrom lib.read_conf import Config\nfrom lib.utils.model_util import activation_fn\nfrom lib.joint import WideAndDeepClassifier\n\n\n# wide columns\ncategorical_column_with_identity = tf.feature_column.categorical_column_with_identity\ncategorical_column_with_hash_bucket = tf.feature_column.categorical_column_with_hash_bucket\ncategorical_column_with_vocabulary_list = tf.feature_column.categorical_column_with_vocabulary_list\ncrossed_column = tf.feature_column.crossed_column\nbucketized_column = tf.feature_column.bucketized_column\n# deep columns\nembedding_column = tf.feature_column.embedding_column\nindicator_column = tf.feature_column.indicator_column\nnumeric_column = tf.feature_column.numeric_column\n\nCONF = Config()\nif CONF.train[\'pos_sample_loss_weight\'] is None and CONF.train[\'neg_sample_loss_weight\'] is None:\n    weight_column = None\nelse:\n    weight_column = \'weight_column\'\n\n\ndef _build_model_columns():\n    """"""\n    Build wide and deep feature columns from custom feature conf using tf.feature_column API\n    wide_columns: category features + cross_features + [discretized continuous features]\n    deep_columns: continuous features + category features(onehot or embedding for sparse features) + [cross_features(embedding)]\n    Return: \n        _CategoricalColumn and __DenseColumn instance in tf.feature_column API\n    """"""\n    def embedding_dim(dim):\n        """"""empirical embedding dim""""""\n        return int(np.power(2, np.ceil(np.log(dim**0.25))))\n\n    def normalizer_fn_builder(scaler, normalization_params):\n        """"""normalizer_fn builder""""""\n        if scaler == \'min_max\':\n            return lambda x: (x-normalization_params[0]) / (normalization_params[1]-normalization_params[0])\n        elif scaler == \'standard\':\n            return lambda x: (x-normalization_params[0]) / normalization_params[1]\n        else:\n            return lambda x: tf.log(x)\n\n    feature_conf_dic = CONF.read_feature_conf()\n    cross_feature_list = CONF.read_cross_feature_conf()\n    tf.logging.info(\'Total used feature class: {}\'.format(len(feature_conf_dic)))\n    tf.logging.info(\'Total used cross feature class: {}\'.format(len(cross_feature_list)))\n\n    wide_columns = []\n    deep_columns = []\n    wide_dim = 0\n    deep_dim = 0\n    for feature, conf in feature_conf_dic.items():\n        f_type, f_tran, f_param = conf[""type""], conf[""transform""], conf[""parameter""]\n        if f_type == \'category\':\n\n            if f_tran == \'hash_bucket\':\n                hash_bucket_size = f_param\n                embed_dim = embedding_dim(hash_bucket_size)\n                col = categorical_column_with_hash_bucket(feature,\n                    hash_bucket_size=hash_bucket_size,\n                    dtype=tf.string)\n                wide_columns.append(col)\n                deep_columns.append(embedding_column(col,\n                    dimension=embed_dim,\n                    combiner=\'mean\',\n                    initializer=None,\n                    ckpt_to_load_from=None,\n                    tensor_name_in_ckpt=None,\n                    max_norm=None,\n                    trainable=True))\n                wide_dim += hash_bucket_size\n                deep_dim += embed_dim\n\n            elif f_tran == \'vocab\':\n                col = categorical_column_with_vocabulary_list(feature,\n                    vocabulary_list=map(str, f_param),\n                    dtype=None,\n                    default_value=-1,\n                    num_oov_buckets=0)  # len(vocab)+num_oov_buckets\n                wide_columns.append(col)\n                deep_columns.append(indicator_column(col))\n                wide_dim += len(f_param)\n                deep_dim += len(f_param)\n\n            elif f_tran == \'identity\':\n                num_buckets = f_param\n                col = categorical_column_with_identity(feature,\n                    num_buckets=num_buckets,\n                    default_value=0)  # Values outside range will result in default_value if specified, otherwise it will fail.\n                wide_columns.append(col)\n                deep_columns.append(indicator_column(col))\n                wide_dim += num_buckets\n                deep_dim += num_buckets\n        else:\n            normalizaton, boundaries = f_param[""normalization""], f_param[""boundaries""]\n            if f_tran is None:\n                normalizer_fn = None\n            else:\n                normalizer_fn = normalizer_fn_builder(f_tran, tuple(normalizaton))\n            col = numeric_column(feature,\n                 shape=(1,),\n                 default_value=0,  # default None will fail if an example does not contain this column.\n                 dtype=tf.float32,\n                 normalizer_fn=normalizer_fn)\n            if boundaries:  # whether include continuous features in wide part\n                wide_columns.append(bucketized_column(col, boundaries=boundaries))\n                wide_dim += (len(boundaries)+1)\n            deep_columns.append(col)\n            deep_dim += 1\n\n    for cross_features, hash_bucket_size, is_deep in cross_feature_list:\n        cf_list = []\n        for f in cross_features:\n            f_type = feature_conf_dic[f][""type""]\n            f_tran = feature_conf_dic[f][""transform""]\n            f_param = feature_conf_dic[f][""parameter""]\n            if f_type == \'continuous\':\n                cf_list.append(bucketized_column(numeric_column(f, default_value=0), boundaries=f_param[\'boundaries\']))\n            else:\n                if f_tran == \'identity\':\n                    # If an input feature is of numeric type, you can use categorical_column_with_identity\n                    cf_list.append(categorical_column_with_identity(f, num_buckets=f_param,\n                    default_value=0))\n                else:\n                    cf_list.append(f)  # category col put the name in crossed_column\n        col = crossed_column(cf_list, hash_bucket_size)\n        wide_columns.append(col)\n        wide_dim += hash_bucket_size\n        if is_deep:\n            deep_columns.append(embedding_column(col, dimension=embedding_dim(hash_bucket_size)))\n            deep_dim += embedding_dim(hash_bucket_size)\n    # add columns logging info\n    tf.logging.info(\'Build total {} wide columns\'.format(len(wide_columns)))\n    for col in wide_columns:\n        tf.logging.debug(\'Wide columns: {}\'.format(col))\n    tf.logging.info(\'Build total {} deep columns\'.format(len(deep_columns)))\n    for col in deep_columns:\n        tf.logging.debug(\'Deep columns: {}\'.format(col))\n    tf.logging.info(\'Wide input dimension is: {}\'.format(wide_dim))\n    tf.logging.info(\'Deep input dimension is: {}\'.format(deep_dim))\n\n    return wide_columns, deep_columns\n\n\ndef _build_distribution():\n    """"""Build distribution configuration variable TF_CONFIG in tf.estimator API""""""\n    TF_CONFIG = CONF.distribution\n    if TF_CONFIG[""is_distribution""]:\n        cluster_spec = TF_CONFIG[""cluster""]\n        job_name = TF_CONFIG[""job_name""]\n        task_index = TF_CONFIG[""task_index""]\n        os.environ[\'TF_CONFIG\'] = json.dumps(\n            {\'cluster\': cluster_spec,\n             \'task\': {\'type\': job_name, \'index\': task_index}})\n        run_config = tf.estimator.RunConfig()\n        if job_name in [""ps"", ""chief"", ""worker""]:\n            assert run_config.master == \'grpc://\' + cluster_spec[job_name][task_index]  # grpc://10.120.180.212\n            assert run_config.task_type == job_name\n            assert run_config.task_id == task_index\n            assert run_config.num_ps_replicas == len(cluster_spec[""ps""])\n            assert run_config.num_worker_replicas == len(cluster_spec[""worker""]) + len(cluster_spec[""chief""])\n            assert run_config.is_chief == (job_name == ""chief"")\n        elif job_name == ""evaluator"":\n            assert run_config.master == \'\'\n            assert run_config.evaluator_master == \'\'\n            assert run_config.task_id == 0\n            assert run_config.num_ps_replicas == 0\n            assert run_config.num_worker_replicas == 0\n            assert run_config.cluster_spec == {}\n            assert run_config.task_type == \'evaluator\'\n            assert not run_config.is_chief\n\n\ndef build_estimator(model_dir, model_type):\n    """"""Build an estimator using official tf.estimator API.\n    Args:\n        model_dir: model save base directory\n        model_type: one of {`wide`, `deep`, `wide_deep`}\n    Returns:\n        model instance of tf.estimator.Estimator class\n    """"""\n    wide_columns, deep_columns = _build_model_columns()\n    _build_distribution()\n    # Create a tf.estimator.RunConfig to ensure the model is run on CPU, which\n    # trains faster than GPU for this model.\n    run_config = tf.estimator.RunConfig(**CONF.runconfig).replace(\n        session_config=tf.ConfigProto(device_count={\'GPU\': 0}))\n\n    if model_type == \'wide\':\n        return tf.estimator.LinearClassifier(\n            model_dir=model_dir,\n            feature_columns=wide_columns,\n            weight_column=weight_column,\n            optimizer=tf.train.FtrlOptimizer(  # can not read from conf\n                learning_rate=0.1,\n                l1_regularization_strength=0.5,\n                l2_regularization_strength=1),\n            partitioner=None,\n            config=run_config)\n    elif model_type == \'deep\':\n        return tf.estimator.DNNClassifier(\n            model_dir=model_dir,\n            feature_columns=deep_columns,\n            hidden_units=CONF.model[""dnn_hidden_units""],\n            optimizer=tf.train.ProximalAdagradOptimizer(\n                learning_rate=0.1,\n                l1_regularization_strength=0.1,\n                l2_regularization_strength=0.1),  # {\'Adagrad\', \'Adam\', \'Ftrl\', \'RMSProp\', \'SGD\'}\n            activation_fn=activation_fn(CONF.model[""dnn_activation_function""]),  # tf.nn.relu vs \'tf.nn.relu\'\n            dropout=CONF.model[""dnn_dropout""],\n            weight_column=weight_column,\n            input_layer_partitioner=None,\n            config=run_config)\n    else:\n        return tf.estimator.DNNLinearCombinedClassifier(\n            model_dir=model_dir,  # self._model_dir = model_dir or self._config.model_dir\n            linear_feature_columns=wide_columns,\n            linear_optimizer=tf.train.FtrlOptimizer(\n                learning_rate=0.1,\n                l1_regularization_strength=0.5,\n                l2_regularization_strength=1),\n            dnn_feature_columns=deep_columns,\n            dnn_optimizer=tf.train.ProximalAdagradOptimizer(\n                learning_rate=0.1,\n                l1_regularization_strength=0.1,\n                l2_regularization_strength=0.1),\n            dnn_hidden_units=CONF.model[""dnn_hidden_units""],\n            dnn_activation_fn=activation_fn(CONF.model[""dnn_activation_function""]),\n            dnn_dropout=CONF.model[""dnn_dropout""],\n            n_classes=2,\n            weight_column=weight_column,\n            label_vocabulary=None,\n            input_layer_partitioner=None,\n            config=run_config)\n\n\ndef build_custom_estimator(model_dir, model_type):\n    """"""Build an estimator using custom WideAndDeepClassifier API.\n    Args:\n        model_dir: model save base directory\n        model_type: one of {`wide`, `deep`, `wide_deep`}\n    Returns:\n        model instance of lib.joint.WideAndDeepClassifier class\n    """"""\n    wide_columns, deep_columns = _build_model_columns()\n    _build_distribution()\n    # Create a tf.estimator.RunConfig to ensure the model is run on CPU, which\n    # trains faster than GPU for this model.\n    run_config = tf.estimator.RunConfig(**CONF.runconfig).replace(\n        session_config=tf.ConfigProto(device_count={\'GPU\': 0}))\n\n    return WideAndDeepClassifier(\n        model_type=model_type,\n        model_dir=model_dir,\n        with_cnn=CONF.model[""cnn_use_flag""],\n        cnn_optimizer=CONF.model[""cnn_optimizer""],\n        linear_feature_columns=wide_columns,\n        linear_optimizer=CONF.model[""linear_optimizer""],\n        dnn_feature_columns=deep_columns,\n        dnn_optimizer=CONF.model[""dnn_optimizer""],\n        dnn_hidden_units=CONF.model[""dnn_hidden_units""],\n        dnn_connected_mode=CONF.model[""dnn_connected_mode""],\n        n_classes=2,\n        weight_column=weight_column,\n        label_vocabulary=None,\n        input_layer_partitioner=None,\n        config=run_config)\n\nif __name__ == \'__main__\':\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n    # _build_model_columns()\n    # _build_distribution()\n    model = build_estimator(\'../model\', \'wide\')\n    model = build_custom_estimator(\'../model\', \'wide\')\n    # print(model.config)  # <tensorflow.python.estimator.run_config.RunConfig object at 0x118de4e10>\n    # print(model.model_dir)  # ../model\n    # print(model.model_fn)  # <function public_model_fn at 0x118de7b18>\n    # print(model.params)  # {}\n    # print(model.get_variable_names())\n    # print(model.get_variable_value(\'dnn/hiddenlayer_0/bias\'))\n    # print(model.get_variable_value(\'dnn/hiddenlayer_0/bias/Adagrad\'))\n    # print(model.get_variable_value(\'dnn/hiddenlayer_0/kernel\'))\n    # print(model.latest_checkpoint())  # another 4 method is export_savedmodel,train evaluate predict\n'"
python/lib/dataset.py,51,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/1/24\n""""""Parse data and generate input_fn for tf.estimators""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom collections import OrderedDict\nimport abc\nimport tensorflow as tf\n\nimport os\nimport sys\nPACKAGE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, PACKAGE_DIR)\n\nfrom lib.read_conf import Config\nfrom lib.utils import image_preprocessing, vgg_preprocessing\n\n\nclass _CTRDataset(object):\n    """"""Interface for dataset using abstract class""""""\n    __metaclass__ = abc.ABCMeta\n\n    def __init__(self, data_file):\n        # check file exsits, turn to list so that data_file can be both file or directory.\n        assert tf.gfile.Exists(data_file), (\n            \'data file: {} not found. Please check input data path\'.format(data_file))\n        if tf.gfile.IsDirectory(data_file):\n            data_file_list = [f for f in tf.gfile.ListDirectory(data_file) if not f.startswith(\'.\')]\n            data_file = [data_file + \'/\' + file_name for file_name in data_file_list]\n        self._data_file = data_file\n        self._conf = Config()\n        self._train_conf = self._conf.train\n        self._dist_conf = self._conf.distribution\n        self._cnn_conf = self._conf.model\n        self._shuffle_buffer_size = self._train_conf[""num_examples""]\n        self._num_parallel_calls = self._train_conf[""num_parallel_calls""]\n        self._train_epochs = self._train_conf[""train_epochs""]\n\n    @abc.abstractmethod\n    def input_fn(self, mode, batch_size):\n        """"""\n        Abstract input function for train or evaluation (with label),\n        abstract method must be implemented in subclasses when instantiate.\n        Args:\n            mode: `train`, `eval` or `pred`\n                train for train mode, do shuffle, repeat num_epochs\n                eval for eval mode, no shuffle, no repeat\n                pred for pred input_fn, no shuffle, no repeat and no label \n            batch_size: Int\n        Returns:\n            (features, label) \n            `features` is a dictionary in which each value is a batch of values for\n            that feature; `labels` is a batch of labels.\n        """"""\n        raise NotImplementedError(\'Calling an abstract method.\')\n\n\nclass _CsvDataset(_CTRDataset):\n    """"""A class to parse csv data and build input_fn for tf.estimators""""""\n\n    def __init__(self, data_file):\n        super(_CsvDataset, self).__init__(data_file)\n        self._pos_sample_loss_weight = self._train_conf[""pos_sample_loss_weight""]\n        self._neg_sample_loss_weight = self._train_conf[""neg_sample_loss_weight""]\n        self._use_weight = False\n        if self._pos_sample_loss_weight is not None and self._neg_sample_loss_weight is not None:\n            self._use_weight = True\n            print(""Using weight column to use weighted loss."")\n        self._multivalue = self._train_conf[""multivalue""]\n        self._is_distribution = self._dist_conf[""is_distribution""]\n        cluster = self._dist_conf[""cluster""]\n        job_name = self._dist_conf[""job_name""]\n        task_index = self._dist_conf[""task_index""]\n        self._num_workers = 1 + len(cluster[""worker""])  # must have 1 chief worker\n        self._worker_index = task_index if job_name == ""worker"" else self._num_workers-1\n        self._feature = self._conf.get_feature_name()  # all features\n        self._feature_used = self._conf.get_feature_name(\'used\')  # used features\n        self._feature_unused = self._conf.get_feature_name(\'unused\')  # unused features\n        self._feature_conf = self._conf.read_feature_conf()  # feature conf dict\n        self._csv_defaults = self._column_to_csv_defaults()\n\n    def _column_to_csv_defaults(self):\n        """"""parse columns to record_defaults param in tf.decode_csv func\n        Return: \n            OrderedDict {\'feature name\': [\'\'],...}\n        """"""\n        csv_defaults = OrderedDict()\n        csv_defaults[\'label\'] = [0]  # first label default, empty if the field is must\n        for f in self._feature:\n            if f in self._feature_conf:  # used features\n                conf = self._feature_conf[f]\n                if conf[\'type\'] == \'category\':\n                    if conf[\'transform\'] == \'identity\':  # identity category column need int type\n                        csv_defaults[f] = [0]\n                    else:\n                        csv_defaults[f] = [\'\']\n                else:\n                    csv_defaults[f] = [0.0]  # 0.0 for float32\n            else:  # unused features\n                csv_defaults[f] = [\'\']\n        return csv_defaults\n\n    def _parse_csv(self, is_pred=False, field_delim=\'\\t\', na_value=\'-\', multivalue_delim=\',\'):\n        """"""Parse function for csv data\n        Args:\n            is_pred: bool, defaults to False\n                True for pred mode, parse input data with label\n                False for train or eval mode, parse input data without label\n            field_delim: csv fields delimiter, defaults to `\\t`\n            na_value: use csv defaults to fill na_value\n            multivalue: bool, defaults to False\n                True for csv data with multivalue features.\n                eg:   f1       f2   ...\n                    a, b, c    1    ...\n                     a, c      2    ...\n                     b, c      0    ...\n            multivalue_delim: multivalue feature delimiter, defaults to `,`\n        Returns:\n            feature dict: {feature: Tensor ... }\n        """"""\n        if is_pred:\n            self._csv_defaults.pop(\'label\')\n        csv_defaults = self._csv_defaults\n        multivalue = self._multivalue\n        pos_w = self._pos_sample_loss_weight\n        neg_w = self._neg_sample_loss_weight\n        use_weight = self._use_weight\n\n        def parser(value):\n            """"""Parse train and eval data with label\n            Args:\n                value: Tensor(""arg0:0"", shape=(), dtype=string)\n            """"""\n            # `tf.decode_csv` return rank 0 Tensor list: <tf.Tensor \'DecodeCSV:60\' shape=() dtype=string>\n            # na_value fill with record_defaults\n            columns = tf.decode_csv(\n                value, record_defaults=csv_defaults.values(),\n                field_delim=field_delim, use_quote_delim=False, na_value=na_value)\n            features = dict(zip(csv_defaults.keys(), columns))\n            for f, tensor in features.items():\n                if f in self._feature_unused:\n                    features.pop(f)  # remove unused features\n                    continue\n                if multivalue:  # split tensor\n                    if isinstance(csv_defaults[f][0], str):\n                        # input must be rank 1, return SparseTensor\n                        # print(st.values)  # <tf.Tensor \'StringSplit_11:1\' shape=(?,) dtype=string>\n                        features[f] = tf.string_split([tensor], multivalue_delim).values  # tensor shape (?,)\n                    else:\n                        features[f] = tf.expand_dims(tensor, 0)  # change shape from () to (1,)\n            if is_pred:\n                return features\n            else:\n                labels = tf.equal(features.pop(\'label\'), 1)\n                if use_weight:\n                    pred = labels[0] if multivalue else labels  # pred must be rank 0 scalar\n                    pos_weight, neg_weight = pos_w or 1, neg_w or 1\n                    weight = tf.cond(pred, lambda: pos_weight, lambda: neg_weight)\n                    features[""weight_column""] = [weight]  # padded_batch need rank 1\n                return features, labels\n        return parser\n\n    def input_fn(self, mode, batch_size):\n        assert mode in {\'train\', \'eval\', \'pred\'}, (\n            \'mode must in `train`, `eval`, or `pred`, found {}\'.format(mode))\n        tf.logging.info(\'Parsing input csv files: {}\'.format(self._data_file))\n        # Extract lines from input files using the Dataset API.\n        dataset = tf.data.TextLineDataset(self._data_file)\n        if self._is_distribution:  # allows each worker to read a unique subset.\n            dataset = dataset.shard(self._num_workers, self._worker_index)\n        # Use `Dataset.map()` to build a pair of a feature dictionary\n        # and a label tensor for each example.\n        # Shuffle, repeat, and batch the examples.\n        dataset = dataset.map(\n            self._parse_csv(is_pred=(mode == \'pred\')),\n            num_parallel_calls=self._num_parallel_calls)\n        if mode == \'train\':\n            dataset = dataset.shuffle(buffer_size=self._shuffle_buffer_size, seed=123)\n            # dataset = dataset.repeat(self._train_epochs)  # define outside loop\n\n        dataset = dataset.prefetch(2 * batch_size)\n        if self._multivalue:\n            padding_dic = {k: [None] for k in self._feature_used}\n            if self._use_weight:\n                padding_dic[\'weight_column\'] = [None]\n            padded_shapes = padding_dic if mode == \'pred\' else (padding_dic, [None])\n            dataset = dataset.padded_batch(batch_size, padded_shapes=padded_shapes)\n        else:\n            # batch(): each element tensor must have exactly same shape, change rank 0 to rank 1\n            dataset = dataset.batch(batch_size)\n        return dataset.make_one_shot_iterator().get_next()\n\n\nclass _ImageDataSet(_CTRDataset):\n    """"""A class to parse image data and build input_fn for tf.estimators\n    data only contains image (no label), so there is no need of pred version.\n    TODO: debug and improve.\n    """"""\n    def __init__(self, data_file):\n        super(_ImageDataSet, self).__init__(data_file)\n        print(self._cnn_conf[\'cnn_height\'])\n        self._height = self._cnn_conf[\'cnn_height\']\n        self._width = self._cnn_conf[\'cnn_width\']\n        self._num_channels = self._cnn_conf[\'cnn_num_channels\']\n        self._weight_decay = self._cnn_conf[\'cnn_weight_decay\']\n        self._momentum = self._cnn_conf[\'cnn_momentum\']\n        self._use_distortion = self._cnn_conf[\'cnn_use_distortion\']\n\n    def parse_example(self, serialized_example, is_training, preprocess=\'custom\'):\n        """"""Parses a single tf.Example into image tensors.\n        Args:\n            preprocess: \'custom\' or \'vgg\'\n                custom: custom image preprocessing, see utils.image_preprocessing\n                vgg: standard vgg preprocessing, see utils.vgg_preprocessing\n        Returns:\n            feature dict {\'image\': Tensor}\n        """"""\n        assert preprocess in {\'custom\', \'vgg\'}, \'Invalid preprocess parameters {}, must be `custom` or `vgg`\'.format(preprocess)\n        features = tf.parse_single_example(\n            serialized_example,\n                features={\n                    \'image\': tf.FixedLenFeature([], tf.string),\n                    # \'label\': tf.FixedLenFeature([], tf.int64),\n                    })\n        image = tf.decode_raw(features[\'image\'], tf.uint8)\n        image.set_shape([self._num_channels * self._height * self._width])\n        # Reshape from [depth * height * width] to [depth, height, width].\n        image = tf.cast(\n            tf.transpose(tf.reshape(image, [self._num_channels, self._height, self._width]), [1, 2, 0]),\n            tf.float32)\n        if self._use_distortion:\n            if preprocess == \'custom\':\n                image = image_preprocessing.preprocess_image(\n                    image,\n                    height=self._height,\n                    width=self._width,\n                    depth=self._num_channels,\n                    is_training=is_training)\n            else:\n                image = vgg_preprocessing.preprocess_image(\n                    image=image,\n                    output_height=self._height,\n                    output_width=self._width,\n                    is_training=is_training)\n        return {\'image\': image}\n\n    # def parse_value(self, value, is_training):\n    #     """"""Parse an Image record from `value`.""""""\n    #     keys_to_features = {\n    #         \'image\': tf.FixedLenFeature([], tf.string, default_value=\'\')}\n    #     parsed = tf.parse_single_example(value, keys_to_features)\n    #     image = tf.image.decode_image(\n    #         tf.reshape(parsed[\'image\'], shape=[]),\n    #         self._num_channels)\n    #     image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    #     return image\n\n    # def parse_raw(self, raw_record):\n    #     """"""Parse image from a raw record.""""""\n    #     # Every record consists of a image, with a fixed number of bytes for each.\n    #     record_vector = tf.decode_raw(raw_record, tf.uint8)\n    #     # reshape image from [depth * height * width] to [depth, height, width].\n    #     depth_major = tf.reshape(record_vector, [self._num_channels, self._height, self._width])\n    #     # Convert from [depth, height, width] to [height, width, depth]\n    #     image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)\n    #     return image\n    def input_fn(self, mode, batch_size):\n        assert mode in {\'train\', \'eval\', \'pred\'}, (\n            \'mode must in `train`, `eval`, or `pred`, found {}\'.format(mode))\n        # dataset = tf.data.Dataset.from_tensor_slices([data_dir])  # multiple input data file\n        # if is_training:\n        #     dataset = dataset.shuffle(buffer_size=100)\n        # dataset = dataset.flat_map(tf.data.TFRecordDataset)\n        tf.logging.info(\'Parsing input image data files: {}\'.format(self._data_file))\n        dataset = tf.data.TFRecordDataset(self._data_file)\n        dataset = dataset.map(lambda value: self.parse_example(value, mode == \'train\'))\n        dataset = dataset.prefetch(2*batch_size)\n        if mode == \'train\':\n            # When choosing shuffle buffer sizes, larger sizes result in better\n            # randomness, while smaller sizes have better performance.\n            # seed must be same with above CsvDataset\n            dataset = dataset.shuffle(buffer_size=self._shuffle_buffer_size, seed=123)\n            # dataset = dataset.repeat(self._train_epochs)\n        dataset = dataset.batch(batch_size)\n        images = dataset.make_one_shot_iterator().get_next()\n        return images\n\n\ndef input_fn(csv_data_file, img_data_file, mode, batch_size):\n    """"""Combine input_fn for tf.estimators\n    Combine both csv and image data; combine both train and pred mode.\n    set img_data_file None to use only csv data\n    """"""\n    if mode == \'pred\':\n        features = _CsvDataset(csv_data_file).input_fn(mode, batch_size)\n        if img_data_file is not None:\n            img_data = _ImageDataSet(img_data_file).input_fn(mode, batch_size)\n            features.update(img_data)  # add image Tensor to feature dict.\n        return features\n\n    else:\n        features, label = _CsvDataset(csv_data_file).input_fn(mode, batch_size)\n        if img_data_file is not None:\n            img_data = _ImageDataSet(img_data_file).input_fn(mode, batch_size)\n            features.update(img_data)  # add image Tensor to feature dict.\n        return features, label\n\n\ndef _input_tensor_test(data_file, batch_size=5):\n    """"""test for categorical_column and cross_column input.""""""\n    sess = tf.InteractiveSession()\n    features, labels = _CsvDataset(data_file).input_fn(\'train\', batch_size=batch_size)\n    print(features[\'ucomp\'].eval())\n    print(features[\'city_id\'].eval())\n    # categorical_column* can handle multivalue feature as a multihot\n    ucomp = tf.feature_column.categorical_column_with_hash_bucket(\'ucomp\', 10)\n    city_id = tf.feature_column.categorical_column_with_hash_bucket(\'city_id\', 10)\n    ucomp_X_city_id = tf.feature_column.crossed_column([\'ucomp\', \'city_id\'], 10)\n    for f in [ucomp, city_id, ucomp_X_city_id]:\n        f_dense = tf.feature_column.indicator_column(f)\n        # f_embed = tf.feature_column.embedding_column(f, 5)\n        # sess.run(tf.global_variables_initializer())\n        # input_tensor = tf.feature_column.input_layer(features, f_embed)\n        input_tensor = tf.feature_column.input_layer(features, f_dense)\n        print(\'{} input tensor:\\n {}\'.format(f, input_tensor.eval()))\n    # dense_tensor = tf.feature_column.input_layer(features, [ucomp, city_id, ucomp_X_city_id])\n    # print(\'total input tensor:\\n {}\'.format(sess.run(dense_tensor)))\n\n    # wide_columns, deep_columns = build_model_columns()\n    # dense_tensor = tf.feature_column.input_layer(features, deep_columns)\n    # sess.run(tf.global_variables_initializer())  # fix Attempting to use uninitialized value error.\n    # sess.run(tf.tables_initializer())  # fix Table not initialized error.\n    # print(sess.run(dense_tensor))\n\nif __name__ == \'__main__\':\n    csv_path = \'../../data/train/train1\'\n    img_path = \'../../data/image/train.tfrecords\'\n    _input_tensor_test(csv_path)\n    sess = tf.InteractiveSession()\n    data = input_fn(csv_path, img_path, \'train\', 5)\n    print(sess.run(data))\n\n\n\n\n\n\n'"
python/lib/dnn.py,65,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/2/9\n""""""This module is based on tf.estimator.DNNClassifier.\nDnn logits builder. \nExtend dnn architecture, add BN layer, add Regularization, add activation function options, add arbitrary connections between layers.\nExtend dnn to multi joint dnn.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nimport tensorflow as tf\nfrom tensorflow.python.estimator.canned import head as head_lib\n\nimport os\nimport sys\nPACKAGE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, PACKAGE_DIR)\n\nfrom lib.read_conf import Config\nfrom lib.utils.model_util import add_layer_summary, get_optimizer_instance, activation_fn\n\nCONF = Config().model\nACTIVATION_FN = activation_fn(CONF[\'dnn_activation_function\'])\nDROPOUT = CONF[\'dnn_dropout\']\nBATCH_NORM = CONF[\'dnn_batch_normalization\']\nDNN_L1 = CONF[\'dnn_l1\']\nDNN_L2 = CONF[\'dnn_l2\']\nregularizer_list = []\nif DNN_L1:\n    regularizer_list.append(tf.contrib.layers.l1_regularizer(DNN_L1))\nif DNN_L2:\n    regularizer_list.append(tf.contrib.layers.l2_regularizer(DNN_L2))\nif len(regularizer_list) == 0:\n    REG = None\nelse:\n    REG = tf.contrib.layers.sum_regularizer(regularizer_list)\n\n\ndef _dnn_logit_fn(features, mode, model_id, units,\n                  hidden_units, connected_mode, feature_columns, input_layer_partitioner):\n    """"""Deep Neural Network logit_fn.\n    Args:\n        features: This is the first item returned from the `input_fn`\n            passed to `train`, `evaluate`, and `predict`. This should be a\n            single `Tensor` or `dict` of same.\n        mode: Optional. Specifies if this training, evaluation or prediction. See\n            `ModeKeys`.\n        model_id: An int indicating the model index of multi dnn.\n        units: An int indicating the dimension of the logit layer.  In the\n            MultiHead case, this should be the sum of all component Heads\' logit\n            dimensions.\n        hidden_units: Iterable of integer number of hidden units per layer.\n        connected_mode: one of {`simple`, `first_dense`, `last_dense`, `dense`, `resnet`}\n            or arbitrary connections index tuples.\n            1. `simple`: normal dnn architecture.\n            2. `first_dense`: add addition connections from first input layer to all hidden layers.\n            3. `last_dense`: add addition connections from all previous layers to last layer.\n            4. `dense`: add addition connections between all layers, similar to DenseNet.\n            5. `resnet`: add addition connections between adjacent layers, similar to ResNet.\n            6. arbitrary connections list: add addition connections from layer_0 to layer_1 like 0-1.\n                eg: [0-1,0-3,1-2]  index start from zero (input_layer), max index is len(hidden_units), smaller index first.\n        feature_columns: Iterable of `feature_column._FeatureColumn` model inputs.\n        activation_fn: Activation function applied to each layer.\n        dropout: When not `None`, the probability we will drop out a given coordinate.\n        batch_norm: Bool, Whether to use BN in dnn.\n        input_layer_partitioner: Partitioner for input layer.\n    Returns:\n        A `Tensor` representing the logits, or a list of `Tensor`\'s representing\n      multiple logits in the MultiHead case.\n    Raises:\n        AssertError: If connected_mode is string, but not one of `simple`, `first_dense`, `last_dense`, \n            `dense` or `resnet`\n    """"""\n\n    if isinstance(connected_mode, str):\n        assert connected_mode in {\'simple\', \'first_dense\', \'lase_dense\', \'dense\', \'resnet\'}, (\n            \'Invalid connected_mode: {}\'.format(connected_mode)\n        )\n    with tf.variable_scope(\n            \'input_from_feature_columns\',\n            values=tuple(six.itervalues(features)),\n            partitioner=input_layer_partitioner,\n            reuse=tf.AUTO_REUSE):\n        net = tf.feature_column.input_layer(\n            features=features,\n            feature_columns=feature_columns)\n    input_layer = net\n    if connected_mode == \'simple\':\n        for layer_id, num_hidden_units in enumerate(hidden_units):\n            with tf.variable_scope(\'dnn_{}/hiddenlayer_{}\'.format(model_id, layer_id),\n                    values=(net,)) as hidden_layer_scope:\n                net = tf.layers.dense(\n                    net,\n                    units=num_hidden_units,\n                    activation=ACTIVATION_FN,\n                    use_bias=True,\n                    kernel_initializer=tf.glorot_uniform_initializer(),  # also called Xavier uniform initializer.\n                    bias_initializer=tf.zeros_initializer(),\n                    kernel_regularizer=REG,\n                    bias_regularizer=None,\n                    activity_regularizer=None,\n                    kernel_constraint=None,\n                    bias_constraint=None,\n                    trainable=True,\n                    reuse=None,\n                    name=hidden_layer_scope)\n                if DROPOUT is not None and mode == tf.estimator.ModeKeys.TRAIN:\n                    net = tf.layers.dropout(net, rate=DROPOUT, training=True)  # rate=0.1 would drop out 10% of input units.\n                if BATCH_NORM:\n                    net = tf.layers.batch_normalization(net)\n            add_layer_summary(net, hidden_layer_scope.name)\n\n    elif connected_mode == \'first_dense\':\n        for layer_id, num_hidden_units in enumerate(hidden_units):\n            with tf.variable_scope(\'dnn_{}/hiddenlayer_{}\'.format(model_id, layer_id),\n                    values=(net,)) as hidden_layer_scope:\n                net = tf.layers.dense(\n                    net,\n                    units=num_hidden_units,\n                    activation=ACTIVATION_FN,\n                    kernel_initializer=tf.glorot_uniform_initializer(),  # also called Xavier uniform initializer.\n                    kernel_regularizer=REG,\n                    name=hidden_layer_scope)\n                if DROPOUT is not None and mode == tf.estimator.ModeKeys.TRAIN:\n                    net = tf.layers.dropout(net, rate=DROPOUT, training=True)\n                if BATCH_NORM:\n                    net = tf.layers.batch_normalization(net)\n                net = tf.concat([net, input_layer], axis=1)\n            add_layer_summary(net, hidden_layer_scope.name)\n\n    elif connected_mode == \'last_dense\':\n        net_collections = [input_layer]\n        for layer_id, num_hidden_units in enumerate(hidden_units):\n            with tf.variable_scope(\'dnn_{}/hiddenlayer_{}\'.format(model_id, layer_id),\n                    values=(net,)) as hidden_layer_scope:\n                net = tf.layers.dense(\n                    net,\n                    units=num_hidden_units,\n                    activation=ACTIVATION_FN,\n                    kernel_initializer=tf.glorot_uniform_initializer(),  # also called Xavier uniform initializer.\n                    kernel_regularizer=REG,\n                    name=hidden_layer_scope)\n                if DROPOUT is not None and mode == tf.estimator.ModeKeys.TRAIN:\n                    net = tf.layers.dropout(net, rate=DROPOUT, training=True)\n                if BATCH_NORM:\n                    net = tf.layers.batch_normalization(net)\n                net_collections.append(net)\n            add_layer_summary(net, hidden_layer_scope.name)\n        net = tf.concat(net_collections, axis=1)  # Concatenates the list of tensors `values` along dimension `axis`\n\n    elif connected_mode == \'dense\':\n        net_collections = [input_layer]\n        for layer_id, num_hidden_units in enumerate(hidden_units):\n            with tf.variable_scope(\'dnn_{}/hiddenlayer_{}\'.format(model_id, layer_id),\n                    values=(net,)) as hidden_layer_scope:\n                net = tf.layers.dense(\n                    net,\n                    units=num_hidden_units,\n                    activation=ACTIVATION_FN,\n                    kernel_initializer=tf.glorot_uniform_initializer(),  # also called Xavier uniform initializer.\n                    kernel_regularizer=REG,\n                    name=hidden_layer_scope)\n                if DROPOUT is not None and mode == tf.estimator.ModeKeys.TRAIN:\n                    net = tf.layers.dropout(net, rate=DROPOUT, training=True)  # rate=0.1 would drop out 10% of input units.\n                if BATCH_NORM:\n                    net = tf.layers.batch_normalization(net)\n                net_collections.append(net)\n                net = tf.concat(net_collections, axis=1)\n            add_layer_summary(net, hidden_layer_scope.name)\n\n    elif connected_mode == \'resnet\':  # connect layers in turn 0-1; 1-2; 2-3;\n        net_collections = [input_layer]\n        for layer_id, num_hidden_units in enumerate(hidden_units):\n            with tf.variable_scope(\'dnn_{}/hiddenlayer_{}\'.format(model_id, layer_id),\n                    values=(net,)) as hidden_layer_scope:\n                net = tf.layers.dense(\n                    net,\n                    units=num_hidden_units,\n                    activation=ACTIVATION_FN,\n                    kernel_initializer=tf.glorot_uniform_initializer(),  # also called Xavier uniform initializer.\n                    kernel_regularizer=REG,\n                    name=hidden_layer_scope)\n                if DROPOUT is not None and mode == tf.estimator.ModeKeys.TRAIN:\n                    net = tf.layers.dropout(net, rate=DROPOUT, training=True)\n                if BATCH_NORM:\n                    net = tf.layers.batch_normalization(net)\n                net = tf.concat([net, net_collections[layer_id + 1 - 1]], axis=1)\n                net_collections.append(net)\n            add_layer_summary(net, hidden_layer_scope.name)\n\n    else:  # arbitrary connections, [\'0-1\',\'0-3\',\'1-3\'], small index layer first\n        connected_mode = [map(int, s.split(\'-\')) for s in connected_mode]\n        # map each layer index to its early connected layer index: {1: [0], 2: [1], 3: [0]}\n        connected_mapping = {}\n        for i, j in connected_mode:\n            if j not in connected_mapping:\n                connected_mapping[j] = [i]\n            else:\n                connected_mapping[j] = connected_mapping[j].append(i)\n\n        net_collections = [input_layer]\n        for layer_id, num_hidden_units in enumerate(hidden_units):\n            with tf.variable_scope(\'dnn_{}/hiddenlayer_{}\'.format(model_id, layer_id),\n                    values=(net,)) as hidden_layer_scope:\n                net = tf.layers.dense(\n                    net,\n                    units=num_hidden_units,\n                    activation=ACTIVATION_FN,\n                    kernel_initializer=tf.glorot_uniform_initializer(),  # also called Xavier uniform initializer.\n                    kernel_regularizer=REG,\n                    name=hidden_layer_scope)\n                if DROPOUT is not None and mode == tf.estimator.ModeKeys.TRAIN:\n                    net = tf.layers.dropout(net, rate=DROPOUT, training=True)\n                if BATCH_NORM:\n                    net = tf.layers.batch_normalization(net)\n                connect_net_collections = [net for idx, net in enumerate(net_collections) if idx in connected_mapping[layer_id + 1]]\n                connect_net_collections.append(net)\n                net = tf.concat(connect_net_collections, axis=1)\n                net_collections.append(net)\n            add_layer_summary(net, hidden_layer_scope.name)\n\n    with tf.variable_scope(\'dnn_{}/logits\'.format(model_id), values=(net,)) as logits_scope:\n        logits = tf.layers.dense(\n                net,\n                units=units,\n                kernel_initializer=tf.glorot_uniform_initializer(),\n                kernel_regularizer=REG,\n                name=logits_scope)\n    add_layer_summary(logits, logits_scope.name)\n    return logits\n\n\ndef multidnn_logit_fn_builder(units, hidden_units_list,\n                              connected_mode_list, feature_columns, input_layer_partitioner):\n    """"""Multi dnn logit function builder.\n    Args:\n        hidden_units_list: 1D iterable list for single dnn or 2D for multi dnn.\n            if use single format, default to use same hidden_units in all multi dnn.\n            eg: [128, 64, 32] or [[128, 64, 32], [64, 32]]\n        connected_mode_list: iterable list of {`simple`, `first_dense`, `last_dense`, `dense`, `resnet`} \n            consistent with above hidden_units_list. \n            if use single format, default to use same connected_mode in all multi dnn.\n            eg: `simple` or [`simple`, `first_dense`] or [0-1, 0-3] or [[0-1, 0-3], [0-1]]\n    Returns:\n        multidnn logit fn.\n    """"""\n    if not isinstance(units, int):\n        raise ValueError(\'units must be an int. Given type: {}\'.format(type(units)))\n    if not isinstance(hidden_units_list[0], (list, tuple)):\n        hidden_units_list = [hidden_units_list]  # compatible for single dnn input hidden_units\n        # raise ValueError(\'multi dnn hidden_units must be a 2D list or tuple. Given: {}\'.format(hidden_units_list))\n    if isinstance(connected_mode_list, str) or \\\n            (isinstance(connected_mode_list[0], str) and len(connected_mode_list[0]) == 3):  # `simple`\n        connected_mode_list = [connected_mode_list] * len(hidden_units_list)\n\n    def multidnn_logit_fn(features, mode):\n        logits = []\n        for idx, (hidden_units, connected_mode) in enumerate(zip(hidden_units_list, connected_mode_list)):\n            logits.append(\n                _dnn_logit_fn(\n                    features,\n                    mode,\n                    idx + 1,\n                    units,\n                    hidden_units,\n                    connected_mode,\n                    feature_columns,\n                    input_layer_partitioner))\n        logits = tf.add_n(logits)  # Adds all input tensors element-wise.\n        return logits\n    return multidnn_logit_fn\n\n\nclass DNN:\n    def __init__(self,\n                 hidden_units,\n                 connected_layers=None,\n                 activation_fn=tf.nn.relu,\n                 batch_norm=None,\n                 dropout=None):\n        """"""\n        hidden_units: \n            Iterable of number hidden units per layer. All layers are\n            fully connected. Ex. `[64, 32]` means first layer has 64 nodes and\n            second one has 32.\n        """"""\n        self.hidden_units = hidden_units\n        self.connected_layers = connected_layers\n        self.activation_fn = activation_fn\n        self.dropout = dropout\n        self.batch_norm = batch_norm\n\n\nclass MultiDNNClassifier(tf.estimator.Estimator):\n    """"""\n    A classifier for Multi DNN joint models based on tf.estimator.DNNClassifier.\n    """"""\n    def __init__(self,\n               model_collections,\n               feature_columns,\n               model_dir=None,\n               n_classes=2,\n               weight_column=None,\n               label_vocabulary=None,\n               optimizer=\'Adagrad\',\n               input_layer_partitioner=None,\n               config=None):\n        """"""Initializes a `DNNClassifier` instance.\n            Args:\n               feature_columns: An iterable containing all the feature columns used by\n                 the model. All items in the set should be instances of classes derived\n                 from `_FeatureColumn`.\n               model_dir: Directory to save model parameters, graph and etc. This can\n                 also be used to load checkpoints from the directory into a estimator to\n                 continue training a previously saved model.\n               n_classes: Number of label classes. Defaults to 2, namely binary\n                 classification. Must be > 1.\n               weight_column: A string or a `_NumericColumn` created by\n                 `tf.feature_column.numeric_column` defining feature column representing\n                 weights. It is used to down weight or boost examples during training. It\n                 will be multiplied by the loss of the example. If it is a string, it is\n                 used as a key to fetch weight tensor from the `features`. If it is a\n                 `_NumericColumn`, raw tensor is fetched by key `weight_column.key`,\n                 then weight_column.normalizer_fn is applied on it to get weight tensor.\n               label_vocabulary: A list of strings represents possible label values. If\n                 given, labels must be string type and have any value in\n                 `label_vocabulary`. If it is not given, that means labels are\n                 already encoded as integer or float within [0, 1] for `n_classes=2` and\n                 encoded as integer values in {0, 1,..., n_classes-1} for `n_classes`>2 .\n                 Also there will be errors if vocabulary is not provided and labels are\n                 string.\n               optimizer: An instance of `tf.Optimizer` used to train the model. Defaults\n                 to Adagrad optimizer.\n               activation_fn: Activation function applied to each layer. If `None`, will\n                 use `tf.nn.relu`.\n               dropout: When not `None`, the probability we will drop out a given\n                 coordinate.\n               input_layer_partitioner: Optional. Partitioner for input layer. Defaults\n                 to `min_max_variable_partitioner` with `min_slice_size` 64 << 20.\n               config: `RunConfig` object to configure the runtime settings.\n        """"""\n        if not model_collections:\n            raise ValueError(\'Empty model collections, must fill DNN model instance.\')\n        assert isinstance(model_collections, (list, tuple)), ""model_collections must be a list or tuple""\n        for model in model_collections:\n            if not isinstance(model, DNN):\n                raise ValueError(""model_collections element must be an instance of class DNN"")\n        if n_classes == 2:\n            head = head_lib._binary_logistic_head_with_sigmoid_cross_entropy_loss(  # pylint: disable=protected-access\n                weight_column=weight_column,\n                label_vocabulary=label_vocabulary)\n        else:\n            head = head_lib._multi_class_head_with_softmax_cross_entropy_loss(  # pylint: disable=protected-access\n                n_classes, weight_column=weight_column,\n                label_vocabulary=label_vocabulary)\n\n        def _dnn_model_fn(\n            features, labels, mode, head,\n            optimizer=\'Adagrad\', input_layer_partitioner=None, config=None):\n            """"""Deep Neural Net model_fn.\n            Args:\n              features: dict of `Tensor`.\n              labels: `Tensor` of shape [batch_size, 1] or [batch_size] labels of\n                dtype `int32` or `int64` in the range `[0, n_classes)`.\n              mode: Defines whether this is training, evaluation or prediction.\n                See `ModeKeys`.\n              head: A `head_lib._Head` instance.\n              hidden_units: Iterable of integer number of hidden units per layer.\n              feature_columns: Iterable of `feature_column._FeatureColumn` model inputs.\n              optimizer: String, `tf.Optimizer` object, or callable that creates the\n                optimizer to use for training. If not specified, will use the Adagrad\n                optimizer with a default learning rate of 0.05.\n              activation_fn: Activation function applied to each layer.\n              dropout: When not `None`, the probability we will drop out a given\n                coordinate.\n              input_layer_partitioner: Partitioner for input layer. Defaults\n                to `min_max_variable_partitioner` with `min_slice_size` 64 << 20.\n              config: `RunConfig` object to configure the runtime settings.\n            Returns:\n              predictions: A dict of `Tensor` objects.\n              loss: A scalar containing the loss of the step.\n              train_op: The op for training.\n            Raises:\n              ValueError: If features has the wrong type.\n            """"""\n            if not isinstance(features, dict):\n                raise ValueError(\'features should be a dictionary of `Tensor`s. \'\n                             \'Given type: {}\'.format(type(features)))\n            optimizer = get_optimizer_instance(\n                optimizer, learning_rate=0.05)\n            num_ps_replicas = config.num_ps_replicas if config else 0\n\n            partitioner = tf.min_max_variable_partitioner(\n                max_partitions=num_ps_replicas)\n            with tf.variable_scope(\n                \'dnn\',\n                values=tuple(six.itervalues(features)),\n                partitioner=partitioner):\n                input_layer_partitioner = input_layer_partitioner or (\n                    tf.min_max_variable_partitioner(\n                        max_partitions=num_ps_replicas,\n                        min_slice_size=64 << 20))\n                # unit is num_classes, shape(batch_size, num_classes)\n                logits = []\n                for idx, m in enumerate(model_collections):\n                    logits.append(\n                        _dnn_logit_fn(\n                            features,\n                            mode,\n                            idx+1,\n                            head.logits_dimension,\n                            m.hidden_units,\n                            m.connected_layers,\n                            feature_columns,\n                            input_layer_partitioner))\n                logits = tf.add_n(logits)  # add logit layer is same with concactenate the layer before logit layer\n\n                def _train_op_fn(loss):\n                    """"""Returns the op to optimize the loss.""""""\n                    return optimizer.minimize(\n                        loss, global_step=tf.train.get_global_step())\n            return head.create_estimator_spec(\n                features=features,\n                mode=mode,\n                labels=labels,\n                train_op_fn=_train_op_fn,\n                logits=logits)\n\n        def _model_fn(features, labels, mode, config):\n            return _dnn_model_fn(\n                features=features,\n                labels=labels,\n                mode=mode,\n                head=head,\n                optimizer=optimizer,\n                input_layer_partitioner=input_layer_partitioner,\n                config=config)\n        super(MultiDNNClassifier, self).__init__(\n            model_fn=_model_fn, model_dir=model_dir, config=config)\n\n\nif __name__ == \'__main__\':\n    dnn_1 = DNN(hidden_units=[128])\n    dnn_2 = DNN(hidden_units=[128, 64])\n    dnn_3 = DNN(hidden_units=[256, 128, 64])\n\n    multi_dnn = MultiDNNClassifier(\n        model_collections=(dnn_1, dnn_2, dnn_3),\n        feature_columns=""deep_columns"")\n\n\n'"
python/lib/joint.py,38,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/2/7\n""""""\nTensorFlow Custom Estimators for Wide and Deep Joint Training Models.\n\nThere are two ways to build custom estimator.\n    1. Write model_fn function to pass to `tf.estimator.Estimator` to generate an instance.\n       easier to build but with less flexibility. \n    2. Write subclass of `tf.estimator.Estimator` like premade(canned) estimators.\n       much suitable for official project. \n    \nThis module is based on tf.estimator.DNNLinearCombinedClassifier.\nIt merges `wide`, `deep`, `wide_deep` three types model into one class \n`WideAndDeepClassifier` by argument model_type \nIt is a flexible and general joint learning framework.\n\nCurrently extensions:\n    1. add BN layer options \n    2. arbitrary connections between layers (refer to ResNet and DenseNet)\n    3. add Cnn as deep part \n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nimport tensorflow as tf\nfrom tensorflow.python.estimator.canned import head as head_lib\n\nimport os\nimport sys\nPACKAGE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, PACKAGE_DIR)\n\nfrom lib.read_conf import Config\nfrom lib.linear import linear_logit_fn_builder\nfrom lib.dnn import multidnn_logit_fn_builder\nfrom lib.utils.model_util import add_layer_summary, check_no_sync_replicas_optimizer, activation_fn, get_optimizer_instance\nfrom lib.cnn.vgg import Vgg16\n\n\n# original import source\n# from tensorflow.python.estimator import estimator\n# from tensorflow.python.estimator.canned import dnn\n# from tensorflow.python.estimator.canned import head as head_lib\n# from tensorflow.python.estimator.canned import linear\n# from tensorflow.python.estimator.canned import optimizers\n# from tensorflow.python.framework import ops\n# from tensorflow.python.ops import control_flow_ops\n# from tensorflow.python.ops import nn\n# from tensorflow.python.ops import partitioned_variables\n# from tensorflow.python.ops import state_ops\n# from tensorflow.python.ops import variable_scope\n# from tensorflow.python.summary import summary\n# from tensorflow.python.training import sync_replicas_optimizer\n# from tensorflow.python.training import training_util\n\n# # The default learning rates are a historical artifact of the initial implementation.\n# _DNN_LEARNING_RATE = 0.001  # 0.05\n# _LINEAR_LEARNING_RATE = 0.005\n# _CNN_LEARNING_RATE = 0.001\n\n# # Weight decay learning rate implementation.\n# decayed_learning_rate = learning_rate * decay_rate ^ (global_step / decay_steps)\n\nCONF = Config().model\n_linear_init_learning_rate = CONF[\'linear_initial_learning_rate\'] or 0.005\n_dnn_init_learning_rate = CONF[\'dnn_initial_learning_rate\'] or 0.001\n_cnn_init_learning_rate = CONF[\'cnn_initial_learning_rate\'] or 0.001\n_linear_decay_rate = CONF[\'linear_decay_rate\'] or 1\n_dnn_decay_rate = CONF[\'dnn_decay_rate\'] or 1\n_cnn_decay_rate = CONF[\'cnn_decay_rate\'] or 1\n\n_batch_size = Config().train[\'batch_size\']\n_num_examples = Config().train[\'num_examples\']\ndecay_steps = _num_examples / _batch_size\n\n\ndef _wide_deep_combined_model_fn(\n        features, labels, mode, head,\n        model_type,\n        with_cnn=False,\n        cnn_optimizer=\'Adagrad\',\n        linear_feature_columns=None,\n        linear_optimizer=\'Ftrl\',\n        dnn_feature_columns=None,\n        dnn_optimizer=\'Adagrad\',\n        dnn_hidden_units=None,\n        dnn_connected_mode=None,\n        input_layer_partitioner=None,\n        config=None):\n    """"""Wide and Deep combined model_fn. (Dnn, Cnn, Linear)\n    Args:\n        features: dict of `Tensor`.\n        labels: `Tensor` of shape [batch_size, 1] or [batch_size] labels of dtype\n            `int32` or `int64` in the range `[0, n_classes)`.\n      mode: Defines whether this is training, evaluation or prediction. See `ModeKeys`.\n      head: A `Head` instance.\n      model_type: one of `wide`, `deep`, `wide_deep`.\n      with_cnn: Bool, set True to combine image input featrues using cnn.\n      cnn_optimizer: String, `Optimizer` object, or callable that defines the\n        optimizer to use for training the CNN model. Defaults to the Adagrad\n        optimizer.\n      linear_feature_columns: An iterable containing all the feature columns used\n          by the Linear model.\n      linear_optimizer: String, `Optimizer` object, or callable that defines the\n          optimizer to use for training the Linear model. Defaults to the Ftrl\n          optimizer.\n      dnn_feature_columns: An iterable containing all the feature columns used by\n        the DNN model.\n      dnn_optimizer: String, `Optimizer` object, or callable that defines the\n        optimizer to use for training the DNN model. Defaults to the Adagrad\n        optimizer.\n      dnn_hidden_units: List of hidden units per DNN layer.\n      dnn_connected_mode: List of connected mode.\n      dnn_activation_fn: Activation function applied to each DNN layer. If `None`,\n          will use `tf.nn.relu`.\n      dnn_dropout: When not `None`, the probability we will drop out a given DNN\n          coordinate.\n      dnn_batch_norm: Bool, add BN layer after each DNN layer\n      input_layer_partitioner: Partitioner for input layer.\n          config: `RunConfig` object to configure the runtime settings.\n    Returns:\n        `ModelFnOps`\n    Raises:\n        ValueError: If both `linear_feature_columns` and `dnn_features_columns`\n            are empty at the same time, or `input_layer_partitioner` is missing,\n            or features has the wrong type.\n    """"""\n    if not isinstance(features, dict):\n        raise ValueError(\'features should be a dictionary of `Tensor`s. \'\n                         \'Given type: {}\'.format(type(features)))\n    if with_cnn:\n        try:\n            cnn_features = features.pop(\'image\')  # separate image feature from input_fn\n        except KeyError:\n            raise ValueError(\'No input image features, must provide image features if use cnn.\')\n    num_ps_replicas = config.num_ps_replicas if config else 0\n    input_layer_partitioner = input_layer_partitioner or (\n        tf.min_max_variable_partitioner(max_partitions=num_ps_replicas,\n                                        min_slice_size=64 << 20))\n    # weight decay lr\n    global_step = tf.Variable(0)\n    _LINEAR_LEARNING_RATE = tf.train.exponential_decay(\n        _linear_init_learning_rate, global_step=global_step, decay_steps=decay_steps, decay_rate=_linear_decay_rate,\n        staircase=False)\n    _DNN_LEARNING_RATE = tf.train.exponential_decay(\n        _dnn_init_learning_rate, global_step=global_step, decay_steps=decay_steps, decay_rate=_dnn_decay_rate,\n        staircase=False)\n    _CNN_LEARNING_RATE = tf.train.exponential_decay(\n        _cnn_init_learning_rate, global_step=global_step, decay_steps=decay_steps, decay_rate=_cnn_decay_rate,\n        staircase=False)\n\n    # Build DNN Logits.\n    dnn_parent_scope = \'dnn\'\n    if model_type == \'wide\' or not dnn_feature_columns:\n        dnn_logits = None\n    else:\n        dnn_optimizer = get_optimizer_instance(\n            dnn_optimizer, learning_rate=_DNN_LEARNING_RATE)\n        if model_type == \'wide_deep\':\n            check_no_sync_replicas_optimizer(dnn_optimizer)\n        dnn_partitioner = tf.min_max_variable_partitioner(max_partitions=num_ps_replicas)\n        with tf.variable_scope(\n                dnn_parent_scope,\n                values=tuple(six.itervalues(features)),\n                partitioner=dnn_partitioner):\n            dnn_logit_fn = multidnn_logit_fn_builder(\n                units=head.logits_dimension,\n                hidden_units_list=dnn_hidden_units,\n                connected_mode_list=dnn_connected_mode,\n                feature_columns=dnn_feature_columns,\n                input_layer_partitioner=input_layer_partitioner\n            )\n            dnn_logits = dnn_logit_fn(features=features, mode=mode)\n\n    # Build Linear Logits.\n    linear_parent_scope = \'linear\'\n    if model_type == \'deep\' or not linear_feature_columns:\n        linear_logits = None\n    else:\n        linear_optimizer = get_optimizer_instance(linear_optimizer,\n            learning_rate=_LINEAR_LEARNING_RATE)\n        check_no_sync_replicas_optimizer(linear_optimizer)\n        with tf.variable_scope(\n                linear_parent_scope,\n                values=tuple(six.itervalues(features)),\n                partitioner=input_layer_partitioner) as scope:\n            logit_fn = linear_logit_fn_builder(\n                units=head.logits_dimension,\n                feature_columns=linear_feature_columns)\n            linear_logits = logit_fn(features=features)\n            add_layer_summary(linear_logits, scope.name)\n\n    # Build CNN Logits.\n    cnn_parent_scope = \'cnn\'\n    if not with_cnn:\n        cnn_logits = None\n    else:\n        cnn_optimizer = get_optimizer_instance(\n            cnn_optimizer, learning_rate=_CNN_LEARNING_RATE)\n        with tf.variable_scope(\n                cnn_parent_scope,\n                values=tuple([cnn_features]),\n                partitioner=input_layer_partitioner) as scope:\n            img_vec = Vgg16().build(cnn_features)\n            cnn_logits = tf.layers.dense(\n                img_vec,\n                units=head.logits_dimension,\n                kernel_initializer=tf.glorot_uniform_initializer(),\n                name=scope)\n            add_layer_summary(cnn_logits, scope.name)\n\n    # Combine logits and build full model.\n    logits_combine = []\n    # _BinaryLogisticHeadWithSigmoidCrossEntropyLoss, logits_dimension=1\n    for logits in [dnn_logits, linear_logits, cnn_logits]:  # shape: [batch_size, 1]\n        if logits is not None:\n            logits_combine.append(logits)\n    logits = tf.add_n(logits_combine)\n\n    def _train_op_fn(loss):\n        """"""Returns the op to optimize the loss.""""""\n        train_ops = []\n        global_step = tf.train.get_global_step()\n        # BN, when training, the moving_mean and moving_variance need to be updated. By default the\n        # update ops are placed in tf.GraphKeys.UPDATE_OPS, so they need to be added as a dependency to the train_op\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n        with tf.control_dependencies(update_ops):\n            if dnn_logits is not None:\n                train_ops.append(\n                    dnn_optimizer.minimize(\n                        loss,\n                        global_step=global_step,\n                        var_list=tf.get_collection(\n                            tf.GraphKeys.TRAINABLE_VARIABLES,\n                            scope=dnn_parent_scope)))\n            if linear_logits is not None:\n                train_ops.append(\n                    linear_optimizer.minimize(\n                        loss,\n                        global_step=global_step,\n                        var_list=tf.get_collection(\n                            tf.GraphKeys.TRAINABLE_VARIABLES,\n                            scope=linear_parent_scope)))\n            if cnn_logits is not None:\n                train_ops.append(\n                    cnn_optimizer.minimize(\n                        loss,\n                        global_step=global_step,\n                        var_list=tf.get_collection(\n                            tf.GraphKeys.TRAINABLE_VARIABLES,\n                            scope=cnn_parent_scope)))\n            # Create an op that groups multiple ops. When this op finishes,\n            # all ops in inputs have finished. This op has no output.\n            train_op = tf.group(*train_ops)\n        with tf.control_dependencies([train_op]):\n            # Returns a context manager that specifies an op to colocate with.\n            with tf.colocate_with(global_step):\n                return tf.assign_add(global_step, 1)\n\n    return head.create_estimator_spec(\n                          features=features,\n                          mode=mode,\n                          labels=labels,\n                          train_op_fn=_train_op_fn,\n                          logits=logits)\n\n\nclass WideAndDeepClassifier(tf.estimator.Estimator):\n    """"""An estimator for TensorFlow Wide and Deep joined classification models.\n    Example:\n    ```python\n    numeric_feature = numeric_column(...)\n    categorical_column_a = categorical_column_with_hash_bucket(...)\n    categorical_column_b = categorical_column_with_hash_bucket(...)\n    categorical_feature_a_x_categorical_feature_b = crossed_column(...)\n    categorical_feature_a_emb = embedding_column(\n        categorical_column=categorical_feature_a, ...)\n    categorical_feature_b_emb = embedding_column(\n        categorical_id_column=categorical_feature_b, ...)\n    estimator = DNNLinearCombinedClassifier(\n        # wide settings\n        linear_feature_columns=[categorical_feature_a_x_categorical_feature_b],\n        linear_optimizer=tf.train.FtrlOptimizer(...),\n        # deep settings\n        dnn_feature_columns=[\n            categorical_feature_a_emb, categorical_feature_b_emb,\n            numeric_feature],\n        dnn_hidden_units=[1000, 500, 100],\n        dnn_optimizer=tf.train.ProximalAdagradOptimizer(...))\n    # To apply L1 and L2 regularization, you can set optimizers as follows:\n    tf.train.ProximalAdagradOptimizer(\n        learning_rate=0.1,\n        l1_regularization_strength=0.001,\n        l2_regularization_strength=0.001)\n    # It is same for FtrlOptimizer.\n    # Input builders\n    def input_fn_train: # returns x, y\n        pass\n    estimator.train(input_fn=input_fn_train, steps=100)\n    def input_fn_eval: # returns x, y\n        pass\n    metrics = estimator.evaluate(input_fn=input_fn_eval, steps=10)\n    def input_fn_predict: # returns x, None\n        pass\n    predictions = estimator.predict(input_fn=input_fn_predict)\n    ```\n    Input of `train` and `evaluate` should have following features,\n    otherwise there will be a `KeyError`:\n    * for each `column` in `dnn_feature_columns` + `linear_feature_columns`:\n      - if `column` is a `_CategoricalColumn`, a feature with `key=column.name`\n        whose `value` is a `SparseTensor`.\n      - if `column` is a `_WeightedCategoricalColumn`, two features: the first\n        with `key` the id column name, the second with `key` the weight column\n        name. Both features\' `value` must be a `SparseTensor`.\n      - if `column` is a `_DenseColumn`, a feature with `key=column.name`\n        whose `value` is a `Tensor`.\n    Loss is calculated by using softmax cross entropy.\n    @compatibility(eager)\n    Estimators are not compatible with eager execution.\n    @end_compatibility\n    """"""\n    def __init__(self,\n                 model_type=None,\n                 model_dir=None,\n                 with_cnn=False,\n                 cnn_optimizer=\'Adagrad\',\n                 linear_feature_columns=None,\n                 linear_optimizer=\'Ftrl\',\n                 dnn_feature_columns=None,\n                 dnn_optimizer=\'Adagrad\',\n                 dnn_hidden_units=None,\n                 dnn_connected_mode=None,\n                 n_classes=2,\n                 weight_column=None,\n                 label_vocabulary=None,\n                 input_layer_partitioner=None,\n                 config=None):\n        """"""Initializes a WideDeepCombinedClassifier instance.\n        Args:\n            model_dir: Directory to save model parameters, graph and etc. This can\n                also be used to load checkpoints from the directory into a estimator\n                to continue training a previously saved model.\n            linear_feature_columns: An iterable containing all the feature columns\n                used by linear part of the model. All items in the set must be\n                instances of classes derived from `FeatureColumn`.\n            linear_optimizer: An instance of `tf.Optimizer` used to apply gradients to\n                the linear part of the model. Defaults to FTRL optimizer.\n            dnn_feature_columns: An iterable containing all the feature columns used\n                by deep part of the model. All items in the set must be instances of\n                classes derived from `FeatureColumn`.\n            dnn_optimizer: An instance of `tf.Optimizer` used to apply gradients to\n                the deep part of the model. Defaults to Adagrad optimizer.\n            dnn_hidden_units: List of hidden units per layer. All layers are fully\n                connected.\n            dnn_activation_fn: Activation function applied to each layer. If None,\n                will use `tf.nn.relu`.\n            dnn_dropout: When not None, the probability we will drop out\n                a given coordinate.\n            n_classes: Number of label classes. Defaults to 2, namely binary\n                classification. Must be > 1.\n            weight_column: A string or a `_NumericColumn` created by\n                `tf.feature_column.numeric_column` defining feature column representing\n                weights. It is used to down weight or boost examples during training. It\n                will be multiplied by the loss of the example. If it is a string, it is\n                used as a key to fetch weight tensor from the `features`. If it is a\n                `_NumericColumn`, raw tensor is fetched by key `weight_column.key`,\n                then weight_column.normalizer_fn is applied on it to get weight tensor.\n            label_vocabulary: A list of strings represents possible label values. If\n                given, labels must be string type and have any value in\n                `label_vocabulary`. If it is not given, that means labels are\n                already encoded as integer or float within [0, 1] for `n_classes=2` and\n                encoded as integer values in {0, 1,..., n_classes-1} for `n_classes`>2 .\n                Also there will be errors if vocabulary is not provided and labels are\n                string.\n            input_layer_partitioner: Partitioner for input layer. Defaults to\n                `min_max_variable_partitioner` with `min_slice_size` 64 << 20.\n            config: RunConfig object to configure the runtime settings.\n        Raises:\n            ValueError: If both linear_feature_columns and dnn_features_columns are\n                empty at the same time.\n        """"""\n        if not linear_feature_columns and not dnn_feature_columns:\n            raise ValueError(\'Either linear_feature_columns or dnn_feature_columns must be defined.\')\n        if model_type is None:\n            raise ValueError(""Model type must be defined. one of `wide`, `deep`, `wide_deep`."")\n        else:\n            assert model_type in {\'wide\', \'deep\', \'wide_deep\'}, (\n                ""Invalid model type, must be one of `wide`, `deep`, `wide_deep`."")\n            if model_type == \'wide\':\n                if not linear_feature_columns:\n                    raise ValueError(\'Linear_feature_columns must be defined for wide model.\')\n            elif model_type == \'deep\':\n                if not dnn_feature_columns:\n                    raise ValueError(\'Dnn_feature_columns must be defined for deep model.\')\n        if dnn_feature_columns and not dnn_hidden_units:\n            raise ValueError(\'dnn_hidden_units must be defined when dnn_feature_columns is specified.\')\n\n        if n_classes == 2:\n            # units = 1\n            head = head_lib._binary_logistic_head_with_sigmoid_cross_entropy_loss(\n                weight_column=weight_column,\n                label_vocabulary=label_vocabulary)\n        else:\n            # units = n_classes\n            head = head_lib._multi_class_head_with_softmax_cross_entropy_loss(\n                n_classes,\n                weight_column=weight_column,\n                label_vocabulary=label_vocabulary)\n\n        def _model_fn(features, labels, mode, config):\n            return _wide_deep_combined_model_fn(\n                features=features,\n                labels=labels,\n                mode=mode,\n                head=head,\n                model_type=model_type,\n                with_cnn=with_cnn,\n                cnn_optimizer=cnn_optimizer,\n                linear_feature_columns=linear_feature_columns,\n                linear_optimizer=linear_optimizer,\n                dnn_feature_columns=dnn_feature_columns,\n                dnn_connected_mode=dnn_connected_mode,\n                dnn_optimizer=dnn_optimizer,\n                dnn_hidden_units=dnn_hidden_units,\n                input_layer_partitioner=input_layer_partitioner,\n                config=config)\n        super(WideAndDeepClassifier, self).__init__(\n            model_fn=_model_fn, model_dir=model_dir, config=config)\n\n'"
python/lib/linear.py,2,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/2/9\n""""""This module is based on tf.estimator.LinearClassifier.\nlinear logits builder for wide part""""""\n# TODO: add FM as linear part\nimport tensorflow as tf\n\n\ndef linear_logit_fn_builder(units, feature_columns):\n    """"""Function builder for a linear logit_fn.\n    Args:\n      units: An int indicating the dimension of the logit layer.\n      feature_columns: An iterable containing all the feature columns used by the model.\n    Returns:\n      A logit_fn (see below).\n    """"""\n\n    def linear_logit_fn(features):\n        """"""Linear model logit_fn.\n        Args:\n          features: This is the first item returned from the `input_fn`\n                passed to `train`, `evaluate`, and `predict`. This should be a\n                single `Tensor` or `dict` of same.\n        Returns:\n          A `Tensor` representing the logits.\n        """"""\n        return tf.feature_column.linear_model(\n            units=units,\n            features=features,\n            feature_columns=feature_columns,\n            sparse_combiner=\'sum\',\n            weight_collections=None,\n            trainable=True,\n        )\n\n    return linear_logit_fn\n'"
python/lib/read_conf.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/1/24\n""""""Read All Configuration from wide_deep/conf/*.yaml""""""\nimport os\nimport yaml\n\nfrom os.path import dirname, abspath\n\nBASE_DIR = os.path.join(dirname(dirname(dirname(abspath(__file__)))), \'conf\')\nSCHEMA_CONF_FILE = \'schema.yaml\'\nDATA_PROCESS_CONF_FILE = \'data_process.yaml\'\nFEATURE_CONF_FILE = \'feature.yaml\'\nCROSS_FEATURE_CONF_FILE = \'cross_feature.yaml\'\nMODEL_CONF_FILE = \'model.yaml\'\nTRAIN_CONF_FILE = \'train.yaml\'\nSERVING_CONF_FILE = \'serving.yaml\'\n\n\nclass Config(object):\n    """"""Config class \n    Class attributes: config, train, distribution, model, runconfig, serving\n    """"""\n    def __init__(self,\n                 schema_conf_file=SCHEMA_CONF_FILE,\n                 data_process_conf_file=DATA_PROCESS_CONF_FILE,\n                 feature_conf_file=FEATURE_CONF_FILE,\n                 cross_feature_conf_file=CROSS_FEATURE_CONF_FILE,\n                 model_conf_file=MODEL_CONF_FILE,\n                 train_conf_file=TRAIN_CONF_FILE,\n                 serving_conf_file=SERVING_CONF_FILE):\n        self._schema_conf_file = os.path.join(BASE_DIR, schema_conf_file)\n        self._data_process_conf_file = os.path.join(BASE_DIR, data_process_conf_file)\n        self._feature_conf_file = os.path.join(BASE_DIR, feature_conf_file)\n        self._cross_feature_conf_file = os.path.join(BASE_DIR, cross_feature_conf_file)\n        self._model_conf_file = os.path.join(BASE_DIR, model_conf_file)\n        self._train_conf_file = os.path.join(BASE_DIR, train_conf_file)\n        self._serving_conf_file = os.path.join(BASE_DIR, serving_conf_file)\n\n    def read_schema(self):\n        with open(self._schema_conf_file) as f:\n            return {k: v.lower() for k, v in yaml.load(f).items()}\n\n    def read_data_process_conf(self):\n        with open(self._data_process_conf_file) as f:\n            return yaml.load(f)\n\n    @staticmethod\n    def _check_feature_conf(feature, valid_feature_name, **kwargs):\n        type_ = kwargs[""type""]\n        trans = kwargs[""transform""]\n        param = kwargs[""parameter""]\n        if type_ is None:\n            raise ValueError(""Type are required in feature conf, ""\n                             ""found empty value for feature `{}`"".format(feature))\n        if feature not in valid_feature_name:\n            raise ValueError(""Invalid feature name `{}` in feature conf, ""\n                             ""must be consistent with schema conf"".format(feature))\n        assert type_ in {\'category\', \'continuous\'}, (\n            ""Invalid type `{}` for feature `{}` in feature conf, ""\n            ""must be \'category\' or \'continuous\'"".format(type_, feature))\n        # check transform and parameter\n        if type_ == \'category\':\n            assert trans in {\'hash_bucket\', \'identity\', \'vocab\'}, (\n                ""Invalid transform `{}` for feature `{}` in feature conf, ""\n                ""must be one of `hash_bucket`, `vocab`, `identity`."".format(trans, feature))\n            if trans == \'hash_bucket\' or trans == \'identity\':\n                if not isinstance(param, int):\n                    raise TypeError(\'Invalid parameter `{}` for feature `{}` in feature conf, \'\n                                    \'{} parameter must be an integer.\'.format(param, feature, trans))\n            elif trans == \'vocab\':\n                if not isinstance(param, (tuple, list)):\n                    raise TypeError(\'Invalid parameter `{}` for feature `{}` in feature conf, \'\n                                    \'vocab parameter must be a list.\'.format(param, feature))\n        else:\n            normalization, boundaries = param[\'normalization\'], param[\'boundaries\']\n            if trans:\n                assert trans in {\'min_max\', \'log\', \'standard\'}, \\\n                    ""Invalid transform `{}` for feature `{}` in feature conf, "" \\\n                    ""continuous feature transform must be `min_max` or `log` or `standard`."".format(trans, feature)\n                if trans == \'min_max\' or \'standard\':\n                    if not isinstance(normalization, (list, tuple)) or len(normalization) != 2:\n                        raise TypeError(\'Invalid normalization parameter `{}` for feature `{}` in feature conf, \'\n                                        \'must be 2 elements list for `min_max` or `standard` scaler.\'.format(normalization, feature))\n                if trans == \'min_max\':\n                    min_, max_ = normalization\n                    if not isinstance(min_, (float, int)) or not isinstance(max_, (float, int)):\n                        raise TypeError(\'Invalid normalization parameter `{}` for feature `{}` in feature conf, \'\n                                        \'list elements must be int or float.\'.format(normalization, feature))\n                    assert min_ < max_, (\'Invalid normalization parameter `{}` for feature `{}` in feature conf, \'\n                                         \'[min, max] list elements must be min<max\'.format(normalization, feature))\n                elif trans == \'standard\':\n                    mean, std = normalization\n                    if not isinstance(mean, (float, int)):\n                        raise TypeError(\'Invalid normalization parameter `{}` for feature `{}` in feature conf, \'\n                                        \'parameter mean must be int or float.\'.format(mean, feature))\n                    if not isinstance(std, (float, int)) or std <= 0:\n                            raise TypeError(\'Invalid normalization parameter `{}` for feature `{}` in feature conf, \'\n                                            \'parameter std must be a positive number.\'.format(std, feature))\n            if boundaries:\n                if not isinstance(boundaries, (tuple, list)):\n                    raise TypeError(\'Invalid parameter `{}` for feature `{}` in feature conf, \'\n                                    \'discretize parameter must be a list.\'.format(boundaries, feature))\n                else:\n                    for v in boundaries:\n                        assert isinstance(v, (int, float)), \\\n                            ""Invalid parameter `{}` for feature `{}` in feature conf, "" \\\n                            ""discretize parameter element must be integer or float."".format(boundaries, feature)\n\n    @staticmethod\n    def _check_cross_feature_conf(features, feature_conf, **kwargs):\n        features_list = [f.strip() for f in features.split(\'&\')]\n        hash_bucket_size = kwargs[""hash_bucket_size""]\n        is_deep = kwargs[""is_deep""]\n        assert len(features_list) > 1, (\n            \'Invalid cross feature name `{}` in cross feature conf,\'\n            \'at least 2 features\'.format(features))\n        for f in features_list:\n            if f not in feature_conf:\n                raise ValueError(""Invalid cross feature name `{}` in cross feature conf, ""\n                                 ""must be consistent with feature conf"".format(features))\n            if feature_conf[f][\'type\'] == \'continuous\':\n                assert feature_conf[f][\'parameter\'][\'boundaries\'] is not None, \\\n                    \'Continuous feature must be set bounaries to be bucketized in feature conf as cross feature\'\n        if hash_bucket_size:\n            assert isinstance(hash_bucket_size, (int, float)), (\n                \'Invalid hash_bucket_size `{}` for features `{}` in cross feature conf, \' \n                \'expected int or float\'.format(hash_bucket_size, features))\n        if is_deep:\n            assert is_deep in {0, 1}, (\n                \'Invalid is_deep `{}` for features `{}`, \' \n                \'expected 0 or 1.\'.format(is_deep, features))\n\n    def read_feature_conf(self):\n        with open(self._feature_conf_file) as f:\n            feature_conf = yaml.load(f)\n            valid_feature_name = self.read_schema().values()\n            for feature, conf in feature_conf.items():\n                self._check_feature_conf(feature.lower(), valid_feature_name, **conf)\n            return feature_conf\n\n    def read_cross_feature_conf(self):\n        with open(self._cross_feature_conf_file) as f:\n            cross_feature_conf = yaml.load(f)\n            conf_list = []\n            feature_conf = self.read_feature_conf()  # used features\n            for features, conf in cross_feature_conf.items():\n                self._check_cross_feature_conf(features, feature_conf, **conf)\n                features = [f.strip() for f in features.split(\'&\')]\n                hash_bucket_size = 1000*conf[""hash_bucket_size""] or 10000  # defaults to 10k\n                is_deep = conf[""is_deep""] if conf[""is_deep""] is not None else 1  # defaults to 10k\n                conf_list.append((features, hash_bucket_size, is_deep))\n            return conf_list\n\n    @staticmethod\n    def _check_numeric(key, value):\n        if not isinstance(value, (int, float)):\n            raise ValueError(\'Numeric type is required for key `{}`, found `{}`.\'.format(key, value))\n\n    @staticmethod\n    def _check_string(key, value):\n        if not isinstance(value, (str, unicode)):\n            raise ValueError(\'String type is required for key `{}`, found `{}`.\'.format(key, value))\n\n    @staticmethod\n    def _check_bool(key, value):\n        if value not in {True, False, 1, 0}:\n            raise ValueError(\'Bool type is required for key `{}`, found `{}`.\'.format(key, value))\n\n    @staticmethod\n    def _check_list(key, value):\n        if not isinstance(value, (list, tuple)):\n            raise ValueError(\'List type is required for key `{}`, found `{}`.\'.format(key, value))\n\n    @staticmethod\n    def _check_required(key, value):\n        if value is None:\n            raise ValueError(\'Required type for key `{}`, found None.\'.format(key))\n\n    def _read_model_conf(self):\n        # required string params\n        req_str_keys = [\'linear_optimizer\', \'dnn_optimizer\', \'dnn_connected_mode\', \'dnn_activation_function\'\n                        \'cnn_optimizer\']\n        # optional int or float params\n        opt_num_keys = [\'linear_initial_learning_rate\', \'linear_decay_rate\', \'dnn_initial_learning_rate\',\n                        \'dnn_decay_rate\', \'dnn_l1\', \'dnn_l2\']\n        # optional bool params\n        opt_bool_keys = [\'dnn_batch_normalization\', \'cnn_use_flag\']\n        #\n        req_list_keys = [\'dnn_hidden_units\']\n        with open(self._model_conf_file) as f:\n            model_conf = yaml.load(f)\n            for k, v in model_conf.items():\n                if k in req_str_keys:\n                    self._check_required(k, v)\n                    self._check_string(k, v)\n                elif k in opt_num_keys:\n                    if v:\n                        self._check_numeric(k, v)\n                elif k in opt_bool_keys:\n                    if v:\n                        self._check_bool(k, v)\n                elif k in req_list_keys:\n                    self._check_required(k, v)\n                    self._check_list(k, v)\n            return model_conf\n\n    def _read_train_conf(self):\n        req_str_keys = [\'model_dir\', \'model_type\', \'train_data\', \'test_data\']\n        req_num_keys = [\'train_epochs\', \'epochs_per_eval\', \'batch_size\', \'num_examples\']\n        opt_num_keys = [\'pos_sample_loss_weight\', \'neg_sample_loss_weight\', \'num_parallel_calls\']\n        req_bool_key = [\'keep_train\', \'multivalue\', \'dynamic_train\']\n        with open(self._train_conf_file) as f:\n            train_conf = yaml.load(f)\n            for k, v in train_conf[\'train\'].items():\n                if k in req_str_keys:\n                    self._check_required(k, v)\n                    self._check_string(k, v)\n                elif k in req_num_keys:\n                    self._check_required(k, v)\n                    self._check_numeric(k, v)\n                elif k in opt_num_keys:\n                    if v:\n                        self._check_numeric(k, v)\n                elif k in req_bool_key:\n                    self._check_required(k, v)\n                    self._check_bool(k, v)\n            return train_conf\n\n    def _read_serving_conf(self):\n        with open(self._serving_conf_file) as f:\n            return yaml.load(f)\n\n    @property\n    def config(self):\n        return self._read_train_conf()\n\n    @property\n    def train(self):\n        return self._read_train_conf()[""train""]\n\n    @property\n    def distribution(self):\n        return self._read_train_conf()[""distribution""]\n\n    @property\n    def runconfig(self):\n        return self._read_train_conf()[""runconfig""]\n\n    @property\n    def model(self):\n        return self._read_model_conf()\n\n    @property\n    def serving(self):\n        return self._read_serving_conf()\n\n    def get_feature_name(self, feature_type=\'all\'):\n        """"""\n        Args:\n         feature_type: one of {\'all\', \'used\', \'category\', \'continuous\'}\n        Return: feature name list\n        """"""\n        feature_conf_dic = self.read_feature_conf()\n        feature_list = self.read_schema().values()\n        feature_list.remove(\'clk\')\n        if feature_type == \'all\':\n            return feature_list\n        elif feature_type == \'used\':\n            return feature_conf_dic.keys()\n        elif feature_type == \'unused\':\n            return set(feature_list) - set(feature_conf_dic.keys())\n        elif feature_type == \'category\':\n            return [feature for feature, conf in feature_conf_dic.items() if conf[\'type\'] == \'category\']\n        elif feature_type == \'continuous\':\n            return [feature for feature, conf in feature_conf_dic.items() if conf[\'type\'] == \'continuous\']\n        else:\n            raise ValueError(""Invalid parameter, must be one of \'all\', \'used\', \'category, \'continuous"")\n\n\ndef _test():\n    config = Config()\n    """"""test for Config methods""""""\n    print(\'\\nTrain config:\')\n    print(config.config)\n    print(config.train)\n    print(config.runconfig)\n    print(config.train[""model_dir""])\n\n    print(\'\\nModel conf:\')\n    for k, v in config.model.items():\n        print(k, v)\n\n    feature_conf_dic = config.read_feature_conf()\n    print(\'\\nFeature conf:\')\n    for k, v in feature_conf_dic.items():\n        print(k, v)\n\n    cross_feature_list = config.read_cross_feature_conf()\n    print(\'\\nCross feature conf:\')\n    for f in cross_feature_list:\n        print(f)\n\n    category_feature = config.get_feature_name(\'category\')\n    print(\'\\nCategory feature:\')\n    print(category_feature)\n\n    members = [m for m in Config.__dict__ if not m.startswith(\'_\')]\n    print(\'\\nConfig class members:\')\n    print(members)\n\nif __name__ == \'__main__\':\n    _test()\n\n\n\n\n'"
python/lib/wide_deep_test.py,5,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow as tf\n\nimport sys\nPACKAGE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, PACKAGE_DIR)\n\nfrom lib.read_conf import Config\nfrom lib.dataset import input_fn\nfrom lib.build_estimator import build_estimator\n\n\nTEST_CSV = os.path.join(os.path.dirname(PACKAGE_DIR), \'data/test/test2\')\nUSED_FEATURE_KEY = Config().get_feature_name(\'used\')\n\n\ndef _read_test_input():\n    for line in open(TEST_CSV):\n        return line\n\nTEST_INPUT_VALUES = _read_test_input()\nTEST_INPUT_KEYS = Config().get_feature_name()\nTEST_INPUT = zip(TEST_INPUT_KEYS, TEST_INPUT_VALUES)\n\n\nclass BaseTest(tf.test.TestCase):\n\n    def setUp(self):\n        # Create temporary CSV file\n        self.temp_dir = self.get_temp_dir()\n        self.input_csv = os.path.join(self.temp_dir, \'test.csv\')\n        with tf.gfile.Open(self.input_csv, \'w\') as temp_csv:\n            temp_csv.write(TEST_INPUT_VALUES)\n\n    def test_input_fn(self):\n        features, labels = input_fn(self.input_csv, \'eval\', batch_size=1)\n        with tf.Session() as sess:\n            features, labels = sess.run((features, labels))\n        # Compare the two features dictionaries.\n        for key in USED_FEATURE_KEY:\n            self.assertTrue(key in features)\n            self.assertEqual(len(features[key]), 1)\n\n            feature_value = features[key][0]\n            # Convert from bytes to string for Python 3.\n            if isinstance(feature_value, bytes):\n                feature_value = feature_value.decode()\n            self.assertEqual(TEST_INPUT[key], feature_value)\n        self.assertFalse(labels)\n\n    def build_and_test_estimator(self, model_type):\n        """"""Ensure that model trains and minimizes loss.""""""\n        model = build_estimator(self.temp_dir, model_type)\n\n        # Train for 1 step to initialize model and evaluate initial loss\n        model.train(\n            input_fn=lambda: input_fn(\n                TEST_CSV, None, \'eval\', batch_size=1),\n            steps=1)\n        initial_results = model.evaluate(\n            input_fn=lambda: input_fn(\n                TEST_CSV, None, \'eval\', batch_size=1))\n\n        # Train for 100 epochs at batch size 3 and evaluate final loss\n        model.train(\n            input_fn=lambda: input_fn(\n                TEST_CSV, None, \'eval\', batch_size=8))\n        final_results = model.evaluate(\n            input_fn=lambda: input_fn(\n                TEST_CSV, None, \'eval\', batch_size=1))\n\n        print(\'%s initial results:\' % model_type, initial_results)\n        print(\'%s final results:\' % model_type, final_results)\n\n        # Ensure loss has decreased, while accuracy and both AUCs have increased.\n        self.assertLess(final_results[\'loss\'], initial_results[\'loss\'])\n        self.assertGreater(final_results[\'auc\'], initial_results[\'auc\'])\n        self.assertGreater(final_results[\'auc_precision_recall\'],\n                           initial_results[\'auc_precision_recall\'])\n        self.assertGreater(final_results[\'accuracy\'], initial_results[\'accuracy\'])\n\n    def test_wide_deep_estimator_training(self):\n        self.build_and_test_estimator(\'wide_deep\')\n\n\nif __name__ == \'__main__\':\n    tf.logging.set_verbosity(tf.logging.ERROR)\n    tf.test.main()\n'"
python/spark/data_process.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/2/27\n""""""Using Spark to do Raw Data Preprocess\nRaw data --> Processed raw data\nData size is about 60G per day. 300M per part (200 part)\nIf use 0.01 down-sampling, use 2 part to avoid too much small partitions\nPerformance: 1 min one day one feature\n\nDetails:\n    1. generate new continuous features from category featrues (optional)\n        for each category, calculate target ratio under certain period as a new continuous feature\n        here we use past 1-day, 7-days, 30-days as our periods\n        for example:  \n            label  sex          label  sex  new_column\n              0     F    after    0     F     0.0\n              0     M   ------>   0     M     0.33\n              1     M             1     M     0.33\n              0     M             0     M     0.33\n        spark logic:\n            1) filter target 2 columns and calculate all the ratio (1day, 7days, 30days) using RDD\n            2) left join origin data and the new ratio column using DataFrame\n            3) repeat 1) and 2) with different category column\n            \n    2. down-sampling\n        ctr data is extremely unbalance, down sample for target 0\nAll configuration see conf/data_process.yaml\n""""""\n\n# TODO: performance improvement\nimport os\nimport sys\nimport subprocess\nfrom datetime import date, datetime, timedelta\n\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\n\nPACKAGE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, PACKAGE_DIR)\n\nfrom lib.read_conf import Config\nfrom lib.utils.util import timer\n\n\ndef gen_dates(start, days=1, fmt=\'%Y%m%d\'):\n    """"""generate date list before given date.""""""\n    start = datetime.strptime(start, fmt)\n    day = timedelta(days=1)\n    return [(start-day*i).strftime(fmt) for i in range(days)]\n\n\ndef list_dates(start, end, fmt=\'%Y%m%d\'):\n    """"""generate date list between start_date and end_date.""""""\n    start = datetime.strptime(start, fmt)\n    end = datetime.strptime(end, fmt)\n    days = (end-start).days\n    return [(start + timedelta(i)).strftime(fmt) for i in range(days+1)]\n\n\ndef get_today():\n    return date.today().strftime(\'%Y%m%d\')  # default %Y-%m-%d fmt\n\n\ndef exist_hdfs_path(path):\n    """"""check hdfs path exists or not, return bool""""""\n    if subprocess.call(\'hadoop fs -test -e {}\'.format(path), shell=True) == 0:\n        return True\n    else:\n        return False\n\n\n@timer(\'Successfully process the raw data!\')\ndef hdfs_data_preprocess(inpath, outpath):\n    """"""Use spark to process hdfs data and write result into hdfs\n    """"""\n    conf = SparkConf().setMaster(""yarn"")\n    sc = SparkContext(conf=conf)\n    ss = SparkSession.builder.getOrCreate()\n    # generate 1-day, 7-days, 30-days rdd list\n    rdd_list = [sc.textFile(inpath[0]), sc.textFile(\',\'.join(inpath[:7])), sc.textFile(\',\'.join(inpath))]\n\n    data = rdd_list[0].map(lambda x: x.strip().split(\'\\t\'))\n    if feature_index_list:  # if feature_index_l\n        for rdd in rdd_list:\n            for i in feature_index_list:\n                # pair rdd (k, v) -> (category_f, clk)\n                rdd = rdd.map(lambda x: x.strip().split(\'\\t\')).map(lambda x: (x[i-1], int(x[0])))\n                # calculate the mean value of pair rdd by key\n                # result like [(u\'150000\', 0.0), (u\'220000\', 0.0), (u\'130000\', 0.00303951367781155)...]\n                # mehthod 1: reduceByKey, using reduceByKey much faster than groupByKey\n                pair_rdd = rdd.mapValues(lambda v: (v, 1))\\\n                    .reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1])).mapValues(lambda v: float(v[0]) / v[1])\n                # method 2:  groupByKey\n                # pair_rdd = rdd.map(lambda x: (x[i-1], int(x[0]))).groupByKey().mapValues(\n                #    lambda x: float(sum(x)) / len(x))\n                # method 3: countByKey + reduceByKey\n                # countsByKey = sc.broadcast(rdd.countByKey())  # SAMPLE OUTPUT of countsByKey.value\n                # from operator import add\n                # pair_rdd = rdd.reduceByKey(add).map(lambda x: (x[0], float(x[1]) / countsByKey.value[x[0]]))\n                # method 4: aggregateByKey\n                # pair_rdd = rdd.aggregateByKey((0, 0), lambda a, b: (a[0]+b, a[1]+1), lambda a,b: (a[0]+b[0], a[1]+b[1]))\n                #    .mapValues(lambda v: float(v[0])/v[1])\n                dic = pair_rdd.collectAsMap()\n                # do not use append, modify inplace, return None\n                # must persist(), or it will all use the last same dic\n                # data = data.map(lambda x: x+[str(dic[x[i-1]])]).persist()\n                b = sc.broadcast(dic)\n                data = data.map(lambda x: x + [str(b.value[x[i - 1]])]).persist()\n                # b.unpersist()\n    # down sampling\n    data = data.map(lambda x: (x[0], x)).sampleByKey(\'clk\', fractions={\'0\': keep_prob, \'1\': 1}, seed=0)\n    # rdd.saveAsTextFile(outpath, \'org.apache.hadoop.io.compress.GzipCodec\')  # can not use snappy\n    # merged into 1 file, but slow for big data coalesce(1)\n    data.map(lambda x: ""\\t"".join(x)).repartition(2).saveAsTextFile(outpath)\n    sc.stop()\n    ss.stop()\n\n\nif __name__ == \'__main__\':\n    CONF = Config().read_data_process_conf()\n    SCHEMA = Config().read_schema()\n\n    feature_index_list = CONF[\'category_feature_index_list\']\n    start_date = str(CONF[\'start_date\'])\n    end_date = str(CONF[\'end_date\'])\n    keep_prob = CONF[\'downsampling_keep_ratio\']\n\n    if start_date is None or end_date is None:\n        date_list = [get_today()]\n    else:\n        date_list = list_dates(start_date, end_date)\n\n    for date in date_list:\n        print(\'Start processing date: {}\'.format(date))\n        inpath = [os.path.join(CONF[\'input_hdfs_dir\'], d) for d in gen_dates(date, 30)]\n        outpath = os.path.join(CONF[\'output_hdfs_dir\'], date)\n        # check path, hadoop output dir can not be exists, must be removed\n        for p in inpath:\n            if not exist_hdfs_path(p):\n                raise IOError(\'Hdfs path: {} not exsits\'.format(p))\n        if exist_hdfs_path(outpath):\n            subprocess.call(\'hadoop fs -rm -r {}\'.format(outpath), shell=True)\n            print(\'Remove hdfs path: {}\'.format(outpath))\n\n        hdfs_data_preprocess(inpath, outpath)\n\n\n'"
python/spark/data_process_local_test.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/3/1\n""""""This script is for spark local testing, process local data \nUsing spark local[*] mode, run Spark locally with as many worker threads as logical cores on your machine.\nsee http://spark.apache.org/docs/latest/submitting-applications.html#master-urls\n\nUsage $ python data_process_local_test.py $inpath $outpath\n""""""\nimport os\nimport shutil\nimport sys\n\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\n\nPACKAGE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, PACKAGE_DIR)\n\nfrom lib.read_conf import Config\nfrom lib.utils.util import timer\n\n\n@timer(\'Successfully process the raw data!\')\ndef local_data_preprocess(inpath, outpath):\n    """"""Use spark to process local data demo.\n    Args:\n        inpath: local data path\n        outpath: local processed data path\n    """"""\n    rdd = sc.textFile(\'file://{}\'.format(inpath)).map(lambda x: x.strip().split(\'\\t\'))\n    colnames = SCHEMA.values()\n    df = ss.createDataFrame(rdd, colnames)\n\n    for i in feature_index_list:\n        # first filter target 2 columns, then groupByKey and calculate the mean of clk (ratio of click)\n        # each rdd pair like [(u\'150000\', 0.0), (u\'220000\', 0.0), (u\'130000\', 0.00303951367781155)...]\n        rdd2 = rdd.map(lambda x: (x[i-1], int(x[0]))).groupByKey().mapValues(lambda x: float(sum(x))/len(x))\n        df2 = ss.createDataFrame(rdd2, (\'k2\', SCHEMA[i] + \'_rate_1\'))\n        df = df.join(df2, df[SCHEMA[i]] == df2[\'k2\'], how=\'left_outer\')\n        df = df.drop(\'k2\')\n        print(\'1-day feature `{}` finished.\'.format(SCHEMA[i]))\n\n    # down sampling\n    df = df.sampleBy(\'clk\', fractions={\'0\': 0.1, \'1\': 1}, seed=0)  # stratified sample without replacement\n    df.repartition(1).write.mode(\'overwrite\').csv(outpath, sep=\'\\t\')\n    sc.stop()\n    ss.stop()\n\n\n@timer(\'Successfully process the raw data!\')\ndef local_data_preprocess2(inpath, outpath):\n    """"""Using RDD API, much more effcient way""""""\n    rdd = sc.textFile(inpath).map(lambda x: x.strip().split(\'\\t\'))\n\n    data = rdd\n    if feature_index_list:\n        for i in feature_index_list:\n            # method 1\n            pair_rdd = rdd.map(lambda x: (x[i-1], int(x[0]))).mapValues(lambda v: (v, 1))\\\n                .reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1])).mapValues(lambda v: v[0] / v[1])\n            # method 2\n            # pair_rdd = rdd.map(lambda x: (x[i-1], int(x[0]))).groupByKey().mapValues(\n            #    lambda x: float(sum(x)) / len(x))\n            # method 3\n            # countsByKey = sc.broadcast(rdd.countByKey())  # SAMPLE OUTPUT of countsByKey.value\n            # from operator import add\n            # pair_rdd = rdd.reduceByKey(add).map(lambda x: (x[0], x[1] / countsByKey.value[x[0]]))\n            # method 4\n            # pair_rdd = rdd.aggregateByKey((0, 0), lambda a, b: (a[0]+b, a[1]+1), lambda a,b: (a[0]+b[0], a[1]+b[1]))\n            #    .mapValues(lambda v: v[0]/v[1])\n            dic = pair_rdd.collectAsMap()\n            # do not use append, modify inplace, return None\n            # must persist(), or it will all use the last same dic\n            data = data.map(lambda x: x + [str(dic[x[i-1]])]).persist()\n            # b = sc.broadcast(dic)\n            # data = data.map(lambda x: x + [str(b.value[x[i - 1]])]).persist()\n            # b.upersist()\n            print(\'feature `{}` finished.\'.format(SCHEMA[i-1]))\n    # down sampling, first map to pair rdd\n    data = data.map(lambda x: (x[0], x)).sampleByKey(\'clk\', fractions={\'0\': keep_prob, \'1\': 1}, seed=0).values()\n    print(\'down sampling finished.\')\n    print(data.first())\n    if os.path.exists(outpath):\n        shutil.rmtree(outpath)\n    data.map(lambda x: ""\\t"".join(x)).saveAsTextFile(outpath)\n    sc.stop()\n    ss.stop()\n\n\nif __name__ == \'__main__\':\n    CONF = Config().read_data_process_conf()\n    SCHEMA = Config().read_schema()\n    feature_index_list = CONF[\'category_feature_index_list\']\n    keep_prob = CONF[\'downsampling_keep_ratio\']\n    conf = SparkConf().setAppName(\'wide_deep\'). \\\n        set(\'spark.executor.memory\', \'10g\').set(\'spark.driver.memory\', \'10g\').setMaster(\'local[*]\')\n    sc = SparkContext(conf=conf)\n    ss = SparkSession.builder.getOrCreate()\n    inpath = \'/Users/lapis-hong/Documents/NetEase/wide_deep/data/train\'\n    outpath = \'/Users/lapis-hong/Documents/NetEase/wide_deep/data/spark\'\n    # if len(sys.argv) < 3:\n    #     exit(\'Missing arguments: \\nUsage: $ python data_process_local_test.py $inpath $outpath\')\n    if len(sys.argv) == 3:\n        inpath = sys.argv[1]\n        outpath = sys.argv[2]\n    local_data_preprocess2(inpath, outpath)\n'"
python/tensorflow_serving/client.py,13,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/3/19\n""""""A client that talks to tensorflow_model_server loaded with SavedModel.\n\nTypical usage example:\n    client.py --num_tests=100 --server=localhost:9000\n""""""\n\nfrom __future__ import print_function\n\nfrom os.path import dirname, abspath, join\nimport sys\nimport threading\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom grpc.beta import implementations\nfrom tensorflow_serving.apis import predict_pb2\nfrom tensorflow_serving.apis import prediction_service_pb2\n\nPACKAGE_DIR = dirname(dirname(abspath(__file__)))\nsys.path.insert(0, PACKAGE_DIR)\nfrom lib.utils.util import column_to_dtype\nfrom lib.read_conf import Config\n\n\ntf.app.flags.DEFINE_integer(\'concurrency\', 1,\n                            \'maximum number of concurrent inference requests\')\ntf.app.flags.DEFINE_integer(\'num_tests\', 100, \'Number of test images\')\ntf.app.flags.DEFINE_string(\'server\', \'localhost:9000\', \'PredictionService host:port\')\ntf.app.flags.DEFINE_string(\'model\', \'wide_deep\',\n                           \'Model name.\')\ntf.app.flags.DEFINE_string(\'work_dir\', \'/tmp\', \'Working directory. \')\nFLAGS = tf.app.flags.FLAGS\n\n\nclass _ResultCounter(object):\n    """"""Counter for the prediction results.""""""\n\n    def __init__(self, num_tests, concurrency):\n        self._num_tests = num_tests\n        self._concurrency = concurrency\n        self._error = 0\n        self._done = 0\n        self._active = 0\n        self._condition = threading.Condition()\n\n    def inc_error(self):\n        with self._condition:\n            self._error += 1\n\n    def inc_done(self):\n        with self._condition:\n            self._done += 1\n            self._condition.notify()\n\n    def dec_active(self):\n        with self._condition:\n            self._active -= 1\n            self._condition.notify()\n\n    def get_error_rate(self):\n        with self._condition:\n            while self._done != self._num_tests:\n                self._condition.wait()\n            return self._error / float(self._num_tests)\n\n    def throttle(self):\n        with self._condition:\n            while self._active == self._concurrency:\n                self._condition.wait()\n            self._active += 1\n\n\ndef _create_rpc_callback(label, result_counter):\n    """"""Creates RPC callback function.\n    Args:\n        label: The correct label for the predicted example.\n        result_counter: Counter for the prediction result.\n    Returns:\n        The callback function.\n    """"""\n    def _callback(result_future):\n        """"""Callback function.\n        Calculates the statistics for the prediction result.\n        Args:\n            result_future: Result future of the RPC.\n        """"""\n        exception = result_future.exception()\n        if exception:\n            result_counter.inc_error()\n            print(exception)\n        else:\n            sys.stdout.write(\'.\')\n            sys.stdout.flush()\n            response = np.array(\n                result_future.result().outputs[\'scores\'].float_val)\n            prediction = np.argmax(response)\n            if label != prediction:\n                result_counter.inc_error()\n        result_counter.inc_done()\n        result_counter.dec_active()\n    return _callback\n\n\ndef do_inference(hostport, work_dir, concurrency, num_tests):\n    """"""Tests PredictionService with concurrent requests.\n    Args:\n        hostport: Host:port address of the PredictionService.\n        work_dir: The full path of working directory for test data set.\n        concurrency: Maximum number of concurrent requests.\n        num_tests: Number of test images to use.\n    Returns:\n        The classification error rate.\n    Raises:\n        IOError: An error occurred processing test data set.\n    """"""\n    test_data_set = mnist_input_data.read_data_sets(work_dir).test\n    host, port = hostport.split(\':\')\n    channel = implementations.insecure_channel(host, int(port))\n    stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\n    result_counter = _ResultCounter(num_tests, concurrency)\n    for _ in range(num_tests):\n        request = predict_pb2.PredictRequest()\n        request.model_spec.name = \'mnist\'\n        request.model_spec.signature_name = \'predict_images\'\n        image, label = test_data_set.next_batch(1)\n        request.inputs[\'images\'].CopyFrom(\n            tf.contrib.util.make_tensor_proto(image[0], shape=[1, image[0].size]))\n        result_counter.throttle()\n        result_future = stub.Predict.future(request, 5.0)  # 5 seconds\n        result_future.add_done_callback(\n            _create_rpc_callback(label[0], result_counter))\n    return result_counter.get_error_rate()\n\n\nPRED_FILE = join(dirname(dirname(dirname(abspath(__file__)))), \'data/pred/pred1\')\n\n\ndef _read_test_input():\n    for line in open(PRED_FILE):\n        return line.strip(\'\\n\').split(\'\\t\')\n\n# Example Features for a movie recommendation application:\n#    feature {\n#      key: ""age""\n#      value { float_list {\n#        value: 29.0\n#      }}\n#    }\n#    feature {\n#      key: ""movie""\n#      value { bytes_list {\n#        value: ""The Shawshank Redemption""\n#        value: ""Fight Club""\n#      }}\n#    }\n\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\ndef pred_input_fn(csv_data):\n    """"""Prediction input fn for a single data, used for serving client""""""\n    conf = Config()\n    feature = conf.get_feature_name()\n    feature_unused = conf.get_feature_name(\'unused\')\n    feature_conf = conf.read_feature_conf()\n    csv_default = column_to_dtype(feature, feature_conf)\n    csv_default.pop(\'label\')\n\n    feature_dict = {}\n    for idx, f in enumerate(csv_default.keys()):\n        if f in feature_unused:\n            continue\n        else:\n            if csv_default[f] == tf.string:\n                feature_dict[f] = _bytes_feature(csv_data[idx])\n            else:\n                feature_dict[f] = _float_feature(float(csv_data[idx]))\n    return feature_dict\n\n\ndef main(_):\n    host, port = FLAGS.server.split(\':\')\n    channel = implementations.insecure_channel(host, int(port))\n    stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\n\n    request = predict_pb2.PredictRequest()\n    request.model_spec.name = FLAGS.model\n    request.model_spec.signature_name = \'serving_default\'\n    # feature_dict = {\'age\': _float_feature(value=25),\n    #               \'capital_gain\': _float_feature(value=0),\n    #               \'capital_loss\': _float_feature(value=0),\n    #               \'education\': _bytes_feature(value=\'11th\'.encode()),\n    #               \'education_num\': _float_feature(value=7),\n    #               \'gender\': _bytes_feature(value=\'Male\'.encode()),\n    #               \'hours_per_week\': _float_feature(value=40),\n    #               \'native_country\': _bytes_feature(value=\'United-States\'.encode()),\n    #               \'occupation\': _bytes_feature(value=\'Machine-op-inspct\'.encode()),\n    #               \'relationship\': _bytes_feature(value=\'Own-child\'.encode()),\n    #               \'workclass\': _bytes_feature(value=\'Private\'.encode())}\n    # label = 0\n    data = _read_test_input()\n    feature_dict = pred_input_fn(data)\n\n    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n    serialized = example.SerializeToString()\n\n    request.inputs[\'inputs\'].CopyFrom(\n        tf.contrib.util.make_tensor_proto(serialized, shape=[1]))\n\n    result_future = stub.Predict.future(request, 5.0)\n    prediction = result_future.result().outputs[\'scores\']\n\n    # print(\'True label: \' + str(label))\n    print(\'Prediction: \' + str(np.argmax(prediction.float_val)))\n\nif __name__ == \'__main__\':\n    tf.app.run()\n'"
python/tensorflow_serving/export_savedmodel.py,17,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/3/19\n""""""Export TensorFlow SavedModel of tf.estimator.\n\nSavedModel is a language-neutral, recoverable, hermetic serialization format. \nSavedModel enables higher-level systems and tools to produce, consume, and \ntransform TensorFlow models. TensorFlow provides several mechanisms for interacting \nwith SavedModel, including tf.saved_model APIs, Estimator APIs and a CLI.\n\nTo prepare a trained Estimator for serving, you must export it in the standard SavedModel format. \n\nhttps://www.tensorflow.org/programmers_guide/saved_model#using_savedmodel_with_estimators\n""""""\nfrom __future__ import print_function\n\nimport os\nimport sys\n\nimport tensorflow as tf\n\nPACKAGE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, PACKAGE_DIR)\n\nfrom lib.build_estimator import _build_model_columns, build_custom_estimator\nfrom lib.read_conf import Config\n\nmodel_base_dir = Config().train[\'model_dir\']\nCONF = Config().serving[\'SavedModel\']\n\ntf.app.flags.DEFINE_string(\'model_type\', CONF[\'model_type\'],\n                           """"""Model type to export"""""")\ntf.app.flags.DEFINE_string(\'checkpoint_path\', CONF[\'checkpoint_path\'],\n                           """"""Directory to read training checkpoints. If None, use latest."""""")\ntf.app.flags.DEFINE_string(\'export_dir\', CONF[\'model_dir\'],\n                           """"""Directory to export inference model."""""")\ntf.app.flags.DEFINE_integer(\'model_version\', CONF[\'model_version\'], \'version number of the model.\')\nFLAGS = tf.app.flags.FLAGS\n\n\ndef main(_):\n    if FLAGS.model_version <= 0:\n        print(\'Please specify a positive value for version number.\')\n        sys.exit(-1)\n    # tf.estimator.export.build_parsing_serving_input_receiver_fn\n    # tf.estimator.export.build_raw_serving_input_receiver_fn\n    # If these utilities do not meet your needs, you are free to write your own serving_input_receiver_fn()\n\n    # feature_spec = {\n    #     ""some_feature"": tf.FixedLenFeature([], dtype=tf.string, default_value=""""),\n    #     ""some_feature"": tf.VarLenFeature(dtype=tf.string),\n    # }\n    #\n    # def _serving_input_receiver_fn():\n    #     serialized_tf_example = tf.placeholder(dtype=tf.string, shape=None,\n    #                                            name=\'input_example_tensor\')\n    #     # key (e.g. \'examples\') should be same with the inputKey when you\n    #     # buid the request for prediction\n    #     receiver_tensors = {\'examples\': serialized_tf_example}\n    #     features = tf.parse_example(serialized_tf_example, your_feature_spec)\n    #     return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n    # estimator.export_savedmodel(export_dir, _serving_input_receiver_fn)\n\n    wide_columns, deep_columns = _build_model_columns()\n    feature_columns = wide_columns + deep_columns\n    # for f in feature_columns:\n    #     print(f._parse_example_spec)\n    # A dict mapping each feature key to a FixedLenFeature or VarLenFeature value.\n    feature_spec = tf.feature_column.make_parse_example_spec(feature_columns)\n    serving_input_receiver_fn = \\\n        tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n\n    model_dir = os.path.join(model_base_dir, FLAGS.model_type)\n    export_dir = os.path.join(FLAGS.export_dir, FLAGS.model_type)\n    model = build_custom_estimator(model_dir, FLAGS.model_type)\n    model.export_savedmodel(export_dir,\n                            serving_input_receiver_fn,\n                            as_text=CONF[\'as_text\'],\n                            checkpoint_path=FLAGS.checkpoint_path)\n\nif __name__ == \'__main__\':\n    tf.app.run()\n'"
python/lib/cnn/__init__.py,0,b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/3/5'
python/lib/cnn/resnet.py,26,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/2/8\n""""""Contains definitions for the preactivation form of Residual Networks.\n\nResidual networks (ResNets) were originally proposed in:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n\nThe full preactivation \'v2\' ResNet variant implemented in this module was\nintroduced by:\n[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Identity Mappings in Deep Residual Networks. arXiv: 1603.05027\n\nThe key difference of the full preactivation \'v2\' variant compared to the\n\'v1\' variant in [1] is the use of batch normalization before every weight layer\nrather than after.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n_BATCH_NORM_DECAY = 0.997\n_BATCH_NORM_EPSILON = 1e-5\n\n\ndef batch_norm_relu(inputs, is_training, data_format):\n    """"""Performs a batch normalization followed by a ReLU.""""""\n    # We set fused=True for a significant performance boost. See\n    # https://www.tensorflow.org/performance/performance_guide#common_fused_ops\n    inputs = tf.layers.batch_normalization(\n        inputs=inputs, axis=1 if data_format == \'channels_first\' else 3,\n        momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, center=True,\n        scale=True, training=is_training, fused=True)\n    inputs = tf.nn.relu(inputs)\n    return inputs\n\n\ndef fixed_padding(inputs, kernel_size, data_format):\n    """"""Pads the input along the spatial dimensions independently of input size.\n    Args:\n      inputs: A tensor of size [batch, channels, height_in, width_in] or\n        [batch, height_in, width_in, channels] depending on data_format.\n      kernel_size: The kernel to be used in the conv2d or max_pool2d operation.\n                   Should be a positive integer.\n      data_format: The input format (\'channels_last\' or \'channels_first\'). \n    Returns:\n      A tensor with the same format as the input with the data either intact\n      (if kernel_size == 1) or padded (if kernel_size > 1).\n    """"""\n    pad_total = kernel_size - 1\n    pad_beg = pad_total // 2\n    pad_end = pad_total - pad_beg\n\n    if data_format == \'channels_first\':\n        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n                               [pad_beg, pad_end], [pad_beg, pad_end]])\n    else:\n        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n                               [pad_beg, pad_end], [0, 0]])\n    return padded_inputs\n\n\ndef conv2d_fixed_padding(inputs, filters, kernel_size, strides, data_format):\n    """"""Strided 2-D convolution with explicit padding.""""""\n    # The padding is consistent and is based only on `kernel_size`, not on the\n    # dimensions of `inputs` (as opposed to using `tf.layers.conv2d` alone).\n    if strides > 1:\n        inputs = fixed_padding(inputs, kernel_size, data_format)\n    return tf.layers.conv2d(\n        inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides,\n        padding=(\'SAME\' if strides == 1 else \'VALID\'), use_bias=False,\n        kernel_initializer=tf.variance_scaling_initializer(),\n        data_format=data_format)\n\n\ndef building_block(inputs, filters, is_training, projection_shortcut, strides,\n                   data_format):\n    """"""Standard building block for residual networks with BN before convolutions.\n    Args:\n      inputs: A tensor of size [batch, channels, height_in, width_in] or\n        [batch, height_in, width_in, channels] depending on data_format.\n      filters: The number of filters for the convolutions.\n      is_training: A Boolean for whether the model is in training or inference\n        mode. Needed for batch normalization.\n      projection_shortcut: The function to use for projection shortcuts (typically\n        a 1x1 convolution when downsampling the input).\n      strides: The block\'s stride. If greater than 1, this block will ultimately\n        downsample the input.\n      data_format: The input format (\'channels_last\' or \'channels_first\').\n    Returns:\n      The output tensor of the block.\n    """"""\n    shortcut = inputs\n    inputs = batch_norm_relu(inputs, is_training, data_format)\n    # The projection shortcut should come after the first batch norm and ReLU\n    # since it performs a 1x1 convolution.\n    if projection_shortcut is not None:\n        shortcut = projection_shortcut(inputs)\n    inputs = conv2d_fixed_padding(\n        inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n        data_format=data_format)\n    inputs = batch_norm_relu(inputs, is_training, data_format)\n    inputs = conv2d_fixed_padding(\n        inputs=inputs, filters=filters, kernel_size=3, strides=1,\n        data_format=data_format)\n    return inputs + shortcut\n\n\ndef bottleneck_block(inputs, filters, is_training, projection_shortcut,\n                     strides, data_format):\n    """"""Bottleneck block variant for residual networks with BN before convolutions.\n    Args:\n      inputs: A tensor of size [batch, channels, height_in, width_in] or\n        [batch, height_in, width_in, channels] depending on data_format.\n      filters: The number of filters for the first two convolutions. Note that the\n        third and final convolution will use 4 times as many filters.\n      is_training: A Boolean for whether the model is in training or inference\n        mode. Needed for batch normalization.\n      projection_shortcut: The function to use for projection shortcuts (typically\n        a 1x1 convolution when downsampling the input).\n      strides: The block\'s stride. If greater than 1, this block will ultimately\n        downsample the input.\n      data_format: The input format (\'channels_last\' or \'channels_first\').\n    Returns:\n      The output tensor of the block.\n    """"""\n    shortcut = inputs\n    inputs = batch_norm_relu(inputs, is_training, data_format)\n    # The projection shortcut should come after the first batch norm and ReLU\n    # since it performs a 1x1 convolution.\n    if projection_shortcut is not None:\n        shortcut = projection_shortcut(inputs)\n    inputs = conv2d_fixed_padding(\n        inputs=inputs, filters=filters, kernel_size=1, strides=1,\n        data_format=data_format)\n    inputs = batch_norm_relu(inputs, is_training, data_format)\n    inputs = conv2d_fixed_padding(\n        inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n        data_format=data_format)\n    inputs = batch_norm_relu(inputs, is_training, data_format)\n    inputs = conv2d_fixed_padding(\n        inputs=inputs, filters=4 * filters, kernel_size=1, strides=1,\n        data_format=data_format)\n    return inputs + shortcut\n\n\ndef block_layer(inputs, filters, block_fn, blocks, strides, is_training, name,\n                data_format):\n    """"""Creates one layer of blocks for the ResNet model.\n    Args:\n      inputs: A tensor of size [batch, channels, height_in, width_in] or\n        [batch, height_in, width_in, channels] depending on data_format.\n      filters: The number of filters for the first convolution of the layer.\n      block_fn: The block to use within the model, either `building_block` or\n        `bottleneck_block`.\n      blocks: The number of blocks contained in the layer.\n      strides: The stride to use for the first convolution of the layer. If\n        greater than 1, this layer will ultimately downsample the input.\n      is_training: Either True or False, whether we are currently training the\n        model. Needed for batch norm.\n      name: A string name for the tensor output of the block layer.\n      data_format: The input format (\'channels_last\' or \'channels_first\').\n    Returns:\n      The output tensor of the block layer.\n    """"""\n    # Bottleneck blocks end with 4x the number of filters as they start with\n    filters_out = 4 * filters if block_fn is bottleneck_block else filters\n\n    def projection_shortcut(inputs):\n        return conv2d_fixed_padding(\n            inputs=inputs, filters=filters_out, kernel_size=1, strides=strides,\n            data_format=data_format)\n    # Only the first block per block_layer uses projection_shortcut and strides\n    inputs = block_fn(inputs, filters, is_training, projection_shortcut,\n                      strides, data_format)\n    for _ in range(1, blocks):\n        inputs = block_fn(inputs, filters, is_training, None, 1, data_format)\n    return tf.identity(inputs, name)\n\n\ndef cifar10_resnet_v2_generator(resnet_size, num_classes, data_format=None):\n    """"""Generator for CIFAR-10 ResNet v2 models.\n    Args:\n      resnet_size: A single integer for the size of the ResNet model.\n      num_classes: The number of possible classes for image classification.\n      data_format: The input format (\'channels_last\', \'channels_first\', or None).\n        If set to None, the format is dependent on whether a GPU is available.\n    Returns:\n      The model function that takes in `inputs` and `is_training` and\n      returns the output tensor of the ResNet model.\n    Raises:\n      ValueError: If `resnet_size` is invalid.\n    """"""\n    if resnet_size % 6 != 2:\n        raise ValueError(\'resnet_size must be 6n + 2:\', resnet_size)\n    num_blocks = (resnet_size - 2) // 6\n    if data_format is None:\n        data_format = (\n            \'channels_first\' if tf.test.is_built_with_cuda() else \'channels_last\')\n\n    def model(inputs, is_training):\n        """"""Constructs the ResNet model given the inputs.""""""\n        if data_format == \'channels_last\':\n        # Convert the inputs from channels_last (NHWC) to channels_first (NCHW).\n        # This provides a large performance boost on GPU. See\n        # https://www.tensorflow.org/performance/performance_guide#data_formats\n            inputs = tf.transpose(inputs, [0, 3, 1, 2])\n        inputs = conv2d_fixed_padding(\n            inputs=inputs, filters=16, kernel_size=3, strides=1,\n            data_format=data_format)\n        inputs = tf.identity(inputs, \'initial_conv\')\n\n        inputs = block_layer(\n            inputs=inputs, filters=16, block_fn=building_block, blocks=num_blocks,\n            strides=1, is_training=is_training, name=\'block_layer1\',\n            data_format=data_format)\n        inputs = block_layer(\n            inputs=inputs, filters=32, block_fn=building_block, blocks=num_blocks,\n            strides=2, is_training=is_training, name=\'block_layer2\',\n            data_format=data_format)\n        inputs = block_layer(\n            inputs=inputs, filters=64, block_fn=building_block, blocks=num_blocks,\n            strides=2, is_training=is_training, name=\'block_layer3\',\n            data_format=data_format)\n\n        inputs = batch_norm_relu(inputs, is_training, data_format)\n        inputs = tf.layers.average_pooling2d(\n            inputs=inputs, pool_size=8, strides=1, padding=\'VALID\',\n            data_format=data_format)\n        inputs = tf.identity(inputs, \'final_avg_pool\')\n        inputs = tf.reshape(inputs, [-1, 64])\n        inputs = tf.layers.dense(inputs=inputs, units=num_classes)\n        inputs = tf.identity(inputs, \'final_dense\')\n        return inputs\n    return model\n\n\ndef imagenet_resnet_v2_generator(block_fn, layers, num_classes,\n                                 data_format=None):\n    """"""Generator for ImageNet ResNet v2 models.\n    Args:\n      block_fn: The block to use within the model, either `building_block` or\n        `bottleneck_block`.\n      layers: A length-4 array denoting the number of blocks to include in each\n        layer. Each layer consists of blocks that take inputs of the same size.\n    num_classes: The number of possible classes for image classification.\n    data_format: The input format (\'channels_last\', \'channels_first\', or None).\n      If set to None, the format is dependent on whether a GPU is available.\n    Returns:\n      The model function that takes in `inputs` and `is_training` and\n      returns the output tensor of the ResNet model.\n    """"""\n    if data_format is None:\n        data_format = (\n            \'channels_first\' if tf.test.is_built_with_cuda() else \'channels_last\')\n\n    def model(inputs, is_training):\n        """"""Constructs the ResNet model given the inputs.""""""\n        if data_format == \'channels_last\':\n        # Convert the inputs from channels_last (NHWC) to channels_first (NCHW).\n        # This provides a large performance boost on GPU. See\n        # https://www.tensorflow.org/performance/performance_guide#data_formats\n            inputs = tf.transpose(inputs, [0, 3, 1, 2])\n        inputs = conv2d_fixed_padding(\n            inputs=inputs, filters=64, kernel_size=7, strides=2,\n            data_format=data_format)\n        inputs = tf.identity(inputs, \'initial_conv\')\n        inputs = tf.layers.max_pooling2d(\n            inputs=inputs, pool_size=3, strides=2, padding=\'SAME\',\n            data_format=data_format)\n        inputs = tf.identity(inputs, \'initial_max_pool\')\n        inputs = block_layer(\n            inputs=inputs, filters=64, block_fn=block_fn, blocks=layers[0],\n            strides=1, is_training=is_training, name=\'block_layer1\',\n            data_format=data_format)\n        inputs = block_layer(\n            inputs=inputs, filters=128, block_fn=block_fn, blocks=layers[1],\n            strides=2, is_training=is_training, name=\'block_layer2\',\n            data_format=data_format)\n        inputs = block_layer(\n            inputs=inputs, filters=256, block_fn=block_fn, blocks=layers[2],\n            strides=2, is_training=is_training, name=\'block_layer3\',\n            data_format=data_format)\n        inputs = block_layer(\n            inputs=inputs, filters=512, block_fn=block_fn, blocks=layers[3],\n            strides=2, is_training=is_training, name=\'block_layer4\',\n            data_format=data_format)\n\n        inputs = batch_norm_relu(inputs, is_training, data_format)\n        inputs = tf.layers.average_pooling2d(\n            inputs=inputs, pool_size=7, strides=1, padding=\'VALID\',\n            data_format=data_format)\n        inputs = tf.identity(inputs, \'final_avg_pool\')\n        inputs = tf.reshape(inputs,\n                            [-1, 512 if block_fn is building_block else 2048])\n        inputs = tf.layers.dense(inputs=inputs, units=num_classes)\n        inputs = tf.identity(inputs, \'final_dense\')\n        return inputs\n    return model\n\n\ndef imagenet_resnet_v2(resnet_size, num_classes, data_format=None):\n    """"""Returns the ResNet model for a given size and number of output classes.""""""\n    model_params = {\n      18: {\'block\': building_block, \'layers\': [2, 2, 2, 2]},\n      34: {\'block\': building_block, \'layers\': [3, 4, 6, 3]},\n      50: {\'block\': bottleneck_block, \'layers\': [3, 4, 6, 3]},\n      101: {\'block\': bottleneck_block, \'layers\': [3, 4, 23, 3]},\n      152: {\'block\': bottleneck_block, \'layers\': [3, 8, 36, 3]},\n      200: {\'block\': bottleneck_block, \'layers\': [3, 24, 36, 3]}\n    }\n    if resnet_size not in model_params:\n        raise ValueError(\'Not a valid resnet_size:\', resnet_size)\n    params = model_params[resnet_size]\n    return imagenet_resnet_v2_generator(\n        params[\'block\'], params[\'layers\'], num_classes, data_format)\n\n\ndef _cnn_logit_fn(units, inputs, resnet_size, num_classes, data_format=None):\n    network = cifar10_resnet_v2_generator(\n        resnet_size, num_classes, data_format=None)\n    logits = network(inputs, is_training=True)\n    return logits\n\n'"
python/lib/cnn/resnet_2.py,31,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/2/8\n""""""ResNet model.\n\nRelated papers:\nhttps://arxiv.org/pdf/1603.05027v2.pdf\nhttps://arxiv.org/pdf/1512.03385v1.pdf\nhttps://arxiv.org/pdf/1605.07146v1.pdf\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n\nclass ResNet(object):\n    """"""ResNet Model.""""""\n    def __init__(self, is_training, data_format, batch_norm_decay, batch_norm_epsilon):\n        """"""ResNet constructor.\n        Args:\n            is_training: if build training or inference model.\n            data_format: the data_format used during computation.\n                         one of \'channels_first\' or \'channels_last\'.\n        """"""\n        self._batch_norm_decay = batch_norm_decay\n        self._batch_norm_epsilon = batch_norm_epsilon\n        self._is_training = is_training\n        assert data_format in (\'channels_first\', \'channels_last\'), \'Wrong data format\'\n        self._data_format = data_format\n\n    def forward_pass(self, x):\n        raise NotImplementedError(\'forward_pass() is implemented in ResNet sub classes\')\n\n    def _residual_v1(self,\n                     x,\n                     kernel_size,\n                     in_filter,\n                     out_filter,\n                     stride,\n                     activate_before_residual=False):\n        """"""Residual unit with 2 sub layers, using Plan A for shortcut connection.""""""\n        del activate_before_residual\n        with tf.name_scope(\'residual_v1\') as name_scope:\n            orig_x = x\n\n            x = self._conv(x, kernel_size, out_filter, stride)\n            x = self._batch_norm(x)\n            x = self._relu(x)\n            x = self._conv(x, kernel_size, out_filter, 1)\n            x = self._batch_norm(x)\n\n            if in_filter != out_filter:\n                orig_x = self._avg_pool(orig_x, stride, stride)\n                pad = (out_filter - in_filter) // 2\n                if self._data_format == \'channels_first\':  # padding for channel\n                    orig_x = tf.pad(orig_x, [[0, 0], [pad, pad], [0, 0], [0, 0]])\n                else:\n                    orig_x = tf.pad(orig_x, [[0, 0], [0, 0], [0, 0], [pad, pad]])\n\n            x = self._relu(tf.add(x, orig_x))\n            tf.logging.info(\'image after unit %s: %s\', name_scope, x.get_shape())\n            return x\n\n    def _residual_v2(self,\n                     x,\n                     in_filter,\n                     out_filter,\n                     stride,\n                     activate_before_residual=False):\n        """"""Residual unit with 2 sub layers with preactivation, plan A shortcut.""""""\n        with tf.name_scope(\'residual_v2\') as name_scope:\n            if activate_before_residual:\n                x = self._batch_norm(x)\n                x = self._relu(x)\n                orig_x = x\n            else:\n                orig_x = x\n                x = self._batch_norm(x)\n                x = self._relu(x)\n            x = self._conv(x, 3, out_filter, stride)\n\n            x = self._batch_norm(x)\n            x = self._relu(x)\n            x = self._conv(x, 3, out_filter, [1, 1, 1, 1])\n\n            if in_filter != out_filter:\n                pad = (out_filter - in_filter) // 2\n                orig_x = self._avg_pool(orig_x, stride, stride)\n                if self._data_format == \'channels_first\':\n                    orig_x = tf.pad(orig_x, [[0, 0], [pad, pad], [0, 0], [0, 0]])\n                else:\n                    orig_x = tf.pad(orig_x, [[0, 0], [0, 0], [0, 0], [pad, pad]])\n            x = tf.add(x, orig_x)\n            tf.logging.info(\'image after unit %s: %s\', name_scope, x.get_shape())\n            return x\n\n    def _bottleneck_residual_v2(self,\n                                x,\n                                in_filter,\n                                out_filter,\n                                stride,\n                                activate_before_residual=False):\n        """"""Bottleneck residual unit with 3 sub layers, plan B shortcut.""""""\n        with tf.name_scope(\'bottle_residual_v2\') as name_scope:\n            if activate_before_residual:\n                x = self._batch_norm(x)\n                x = self._relu(x)\n                orig_x = x\n            else:\n                orig_x = x\n                x = self._batch_norm(x)\n                x = self._relu(x)\n\n            x = self._conv(x, 1, out_filter // 4, stride, is_atrous=True)\n\n            x = self._batch_norm(x)\n            x = self._relu(x)\n            # pad when stride isn\'t unit\n            x = self._conv(x, 3, out_filter // 4, 1, is_atrous=True)\n\n            x = self._batch_norm(x)\n            x = self._relu(x)\n            x = self._conv(x, 1, out_filter, 1, is_atrous=True)\n\n            if in_filter != out_filter:\n                orig_x = self._conv(orig_x, 1, out_filter, stride, is_atrous=True)\n            x = tf.add(x, orig_x)\n\n            tf.logging.info(\'image after unit %s: %s\', name_scope, x.get_shape())\n            return x\n\n    def _conv(self, x, kernel_size, filters, strides, is_atrous=False):\n        """"""Convolution Layers""""""\n        padding = \'SAME\'\n        if not is_atrous and strides > 1:\n            pad = kernel_size - 1\n            pad_beg = pad // 2\n            pad_end = pad - pad_beg\n            if self._data_format == \'channels_first\':\n                x = tf.pad(x, [[0, 0], [0, 0], [pad_beg, pad_end], [pad_beg, pad_end]])\n            else:\n                x = tf.pad(x, [[0, 0], [pad_beg, pad_end], [pad_beg, pad_end], [0, 0]])\n            padding = \'VALID\'\n        return tf.layers.conv2d(\n            inputs=x,\n            kernel_size=kernel_size,\n            filters=filters,\n            strides=strides,\n            padding=padding,\n            use_bias=False,\n            data_format=self._data_format)\n\n    def _batch_norm(self, x):\n        if self._data_format == \'channels_first\':\n            data_format = \'NCHW\'\n        else:\n            data_format = \'NHWC\'\n        return tf.contrib.layers.batch_norm(\n            x,\n            decay=self._batch_norm_decay,\n            center=True,\n            scale=True,\n            epsilon=self._batch_norm_epsilon,\n            is_training=self._is_training,\n            fused=True,\n            data_format=data_format)\n\n    def _relu(self, x):\n        return tf.nn.relu(x)\n\n    def _fully_connected(self, x, out_dim):\n        with tf.name_scope(\'fully_connected\') as name_scope:\n            x = tf.layers.dense(x, out_dim)\n        tf.logging.info(\'image after unit %s: %s\', name_scope, x.get_shape())\n        return x\n\n    def _avg_pool(self, x, pool_size, stride):\n        with tf.name_scope(\'avg_pool\') as name_scope:\n            x = tf.layers.average_pooling2d(\n                x, pool_size, stride, \'SAME\', data_format=self._data_format)\n        tf.logging.info(\'image after unit %s: %s\', name_scope, x.get_shape())\n        return x\n\n    def _global_avg_pool(self, x):\n        with tf.name_scope(\'global_avg_pool\') as name_scope:\n            assert x.get_shape().ndims == 4\n            if self._data_format == \'channels_first\':\n              x = tf.reduce_mean(x, [2, 3])\n            else:\n                x = tf.reduce_mean(x, [1, 2])\n        tf.logging.info(\'image after unit %s: %s\', name_scope, x.get_shape())\n        return x\n\n\nclass ResNetCifar10(ResNet):\n    """"""Cifar10 model with ResNetV1 and basic residual block.""""""\n\n    def __init__(self,\n               num_layers,\n               is_training,\n               batch_norm_decay,\n               batch_norm_epsilon,\n               data_format=\'channels_first\'):\n        super(ResNetCifar10, self).__init__(\n            is_training,\n            data_format,\n            batch_norm_decay,\n            batch_norm_epsilon\n        )\n        self.n = (num_layers - 2) // 6\n        # Add one in case label starts with 1. No impact if label starts with 0.\n        self.num_classes = 10 + 1\n        self.filters = [16, 16, 32, 64]\n        self.strides = [1, 2, 2]\n\n    def forward_pass(self, x, input_data_format=\'channels_last\'):\n        """"""Build the core model within the graph.""""""\n        if self._data_format != input_data_format:\n            if input_data_format == \'channels_last\':\n                x = tf.transpose(x, [0, 3, 1, 2])\n            else:\n                x = tf.transpose(x, [0, 2, 3, 1])\n        # Image standardization.\n        x = x / 128 - 1\n\n        x = self._conv(x, 3, 16, 1)\n        x = self._batch_norm(x)\n        x = self._relu(x)\n\n        # Use basic (non-bottleneck) block and ResNet V1 (post-activation).\n        res_func = self._residual_v1\n        # 3 stages of block stacking.\n        for i in range(3):\n            with tf.name_scope(\'stage\'):\n                for j in range(self.n):\n                    if j == 0:\n                        # First block in a stage, filters and strides may change.\n                        x = res_func(x, 3, self.filters[i], self.filters[i + 1], self.strides[i])\n                    else:\n                        # Following blocks in a stage, constant filters and unit stride.\n                        x = res_func(x, 3, self.filters[i + 1], self.filters[i + 1], 1)\n        x = self._global_avg_pool(x)\n        x = self._fully_connected(x, self.num_classes)\n        return x\n\n\n\n'"
python/lib/cnn/vgg.py,34,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/2/8\n""""""This module include vgg model, generate image vector logits to combine with dnn part logits""""""\n# TODO: summary info and other improvements\nimport time\n\nfrom functools import reduce\nimport numpy as np\nimport tensorflow as tf\n\nVGG_MEAN = [103.939, 116.779, 123.68]\n\n\nclass Vgg(object):\n    """"""\n    VGG base class, subclass must implement build method.\n    """"""\n    def __init__(self, vgg_npy_path=None, trainable=True, dropout=0.5):\n        if vgg_npy_path is not None:\n            self.data_dict = np.load(vgg_npy_path, encoding=\'latin1\').item()\n        else:\n            self.data_dict = None\n        self.var_dict = {}\n        self.trainable = trainable\n        self.dropout = dropout\n\n    def build(self, rgb, train_mode=None):\n        """"""\n        load variable from npy to build the VGG\n        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n        :param train_mode: a bool tensor, usually a placeholder: if True, dropout will be turned on\n        """"""\n        raise NotImplementedError\n\n    @staticmethod\n    def avg_pool(bottom, name):\n        return tf.nn.avg_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\', name=name)\n\n    @staticmethod\n    def max_pool(bottom, name):\n        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\', name=name)\n\n    def conv_layer(self, bottom, in_channels, out_channels, name):\n        with tf.variable_scope(name):\n            filt, conv_biases = self.get_conv_var(3, in_channels, out_channels, name)\n            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=\'SAME\')\n            bias = tf.nn.bias_add(conv, conv_biases)\n            relu = tf.nn.relu(bias)\n            return relu\n\n    def fc_layer(self, bottom, in_size, out_size, name):\n        with tf.variable_scope(name):\n            weights, biases = self.get_fc_var(in_size, out_size, name)\n            x = tf.reshape(bottom, [-1, in_size])\n            fc = tf.nn.bias_add(tf.matmul(x, weights), biases)\n            return fc\n\n    def get_conv_var(self, filter_size, in_channels, out_channels, name):\n        initial_value = tf.truncated_normal([filter_size, filter_size, in_channels, out_channels], 0.0, 0.001)\n        filters = self.get_var(initial_value, name, 0, name + ""_filters"")\n\n        initial_value = tf.truncated_normal([out_channels], .0, .001)\n        biases = self.get_var(initial_value, name, 1, name + ""_biases"")\n        return filters, biases\n\n    def get_fc_var(self, in_size, out_size, name):\n        initial_value = tf.truncated_normal([in_size, out_size], 0.0, 0.001)\n        weights = self.get_var(initial_value, name, 0, name + ""_weights"")\n\n        initial_value = tf.truncated_normal([out_size], .0, .001)\n        biases = self.get_var(initial_value, name, 1, name + ""_biases"")\n        return weights, biases\n\n    def get_var(self, initial_value, name, idx, var_name):\n        if self.data_dict is not None and name in self.data_dict:\n            value = self.data_dict[name][idx]\n        else:\n            value = initial_value\n        if self.trainable:\n            var = tf.Variable(value, name=var_name)\n        else:\n            var = tf.constant(value, dtype=tf.float32, name=var_name)\n        self.var_dict[(name, idx)] = var\n        # print var_name, var.get_shape().as_list()\n        assert var.get_shape() == initial_value.get_shape()\n        return var\n\n    def save_npy(self, sess, npy_path=None):\n        assert isinstance(sess, tf.Session)\n        data_dict = {}\n        for (name, idx), var in list(self.var_dict.items()):\n            var_out = sess.run(var)\n            if name not in data_dict:\n                data_dict[name] = {}\n            data_dict[name][idx] = var_out\n        np.save(npy_path, data_dict)\n        print(""file saved: {}"".format(npy_path))\n        return npy_path\n\n    def get_var_count(self):\n        count = 0\n        for v in list(self.var_dict.values()):\n            count += reduce(lambda x, y: x * y, v.get_shape().as_list())\n        return count\n\n\nclass Vgg16(Vgg):\n    """"""\n    A trainable version VGG16.\n    """"""\n    def __init__(self, vgg16_npy_path=None, trainable=True, dropout=0.5):\n        super(Vgg16, self).__init__(vgg_npy_path=vgg16_npy_path, trainable=trainable, dropout=dropout)\n\n    def build(self, rgb, train_mode=None):\n        """"""\n        load variable from npy to build the VGG\n        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n        :param train_mode: a bool tensor, usually a placeholder: if True, dropout will be turned on\n        """"""\n        start_time = time.time()\n        print(""build vgg model started"")\n        rgb_scaled = rgb * 255.0\n        # Convert RGB to BGR\n        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_scaled)\n        assert red.get_shape().as_list()[1:] == [224, 224, 1]\n        assert green.get_shape().as_list()[1:] == [224, 224, 1]\n        assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n        bgr = tf.concat(axis=3, values=[\n            blue - VGG_MEAN[0],\n            green - VGG_MEAN[1],\n            red - VGG_MEAN[2],\n        ])\n        assert bgr.get_shape().as_list()[1:] == [224, 224, 3]\n\n        self.conv1_1 = self.conv_layer(bgr, 3, 64, ""conv1_1"")\n        self.conv1_2 = self.conv_layer(self.conv1_1, 64, 64, ""conv1_2"")\n        self.pool1 = self.max_pool(self.conv1_2, \'pool1\')\n\n        self.conv2_1 = self.conv_layer(self.pool1, 64, 128, ""conv2_1"")\n        self.conv2_2 = self.conv_layer(self.conv2_1, 128, 128, ""conv2_2"")\n        self.pool2 = self.max_pool(self.conv2_2, \'pool2\')\n\n        self.conv3_1 = self.conv_layer(self.pool2, 128, 256, ""conv3_1"")\n        self.conv3_2 = self.conv_layer(self.conv3_1, 256, 256, ""conv3_2"")\n        self.conv3_3 = self.conv_layer(self.conv3_2, 256, 256, ""conv3_3"")\n        self.pool3 = self.max_pool(self.conv3_3, \'pool3\')\n\n        self.conv4_1 = self.conv_layer(self.pool3, 256, 512, ""conv4_1"")\n        self.conv4_2 = self.conv_layer(self.conv4_1, 512, 512, ""conv4_2"")\n        self.conv4_3 = self.conv_layer(self.conv4_2, 512, 512, ""conv4_3"")\n        self.pool4 = self.max_pool(self.conv4_3, \'pool4\')\n\n        self.conv5_1 = self.conv_layer(self.pool4, 512, 512, ""conv5_1"")\n        self.conv5_2 = self.conv_layer(self.conv5_1, 512, 512, ""conv5_2"")\n        self.conv5_3 = self.conv_layer(self.conv5_2, 512, 512, ""conv5_3"")\n        self.pool5 = self.max_pool(self.conv5_3, \'pool5\')\n\n        self.fc6 = self.fc_layer(self.pool5, 25088, 4096, ""fc6"")\n        assert self.fc6.get_shape().as_list()[1:] == [4096]\n        self.relu6 = tf.nn.relu(self.fc6)\n\n        self.fc7 = self.fc_layer(self.relu6, 4096, 4096, ""fc7"")\n        self.relu7 = tf.nn.relu(self.fc7)\n        if train_mode is not None:\n            self.relu7 = tf.cond(train_mode, lambda: tf.nn.dropout(self.relu7, self.dropout), lambda: self.relu7)\n        elif self.trainable:\n            self.relu7 = tf.nn.dropout(self.relu7, self.dropout)\n\n        self.fc8 = self.fc_layer(self.relu7, 4096, 1000, ""fc8"")\n        self.prob = tf.nn.softmax(self.fc8, name=""prob"")\n        self.data_dict = None\n        print(""build vgg model finished: %ds"" % (time.time() - start_time))\n        return self.fc8\n\n\nclass Vgg19(Vgg):\n    """"""\n    A trainable version VGG19.\n    """"""\n    def __init__(self, vgg19_npy_path=None, trainable=True, dropout=0.5):\n        super(Vgg19, self).__init__(vgg_npy_path=vgg19_npy_path, trainable=trainable, dropout=dropout)\n\n    def build(self, rgb, train_mode=None):\n        """"""\n        load variable from npy to build the VGG\n        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n        :param train_mode: a bool tensor, usually a placeholder: if True, dropout will be turned on\n        """"""\n        start_time = time.time()\n        print(""build vgg model started"")\n        rgb_scaled = rgb * 255.0\n        # Convert RGB to BGR\n        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_scaled)\n        assert red.get_shape().as_list()[1:] == [224, 224, 1]\n        assert green.get_shape().as_list()[1:] == [224, 224, 1]\n        assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n        bgr = tf.concat(axis=3, values=[\n            blue - VGG_MEAN[0],\n            green - VGG_MEAN[1],\n            red - VGG_MEAN[2]])\n        assert bgr.get_shape().as_list()[1:] == [224, 224, 3]\n        self.conv1_1 = self.conv_layer(bgr, 3, 64, ""conv1_1"")\n        self.conv1_2 = self.conv_layer(self.conv1_1, 64, 64, ""conv1_2"")\n        self.pool1 = self.max_pool(self.conv1_2, \'pool1\')\n\n        self.conv2_1 = self.conv_layer(self.pool1, 64, 128, ""conv2_1"")\n        self.conv2_2 = self.conv_layer(self.conv2_1, 128, 128, ""conv2_2"")\n        self.pool2 = self.max_pool(self.conv2_2, \'pool2\')\n\n        self.conv3_1 = self.conv_layer(self.pool2, 128, 256, ""conv3_1"")\n        self.conv3_2 = self.conv_layer(self.conv3_1, 256, 256, ""conv3_2"")\n        self.conv3_3 = self.conv_layer(self.conv3_2, 256, 256, ""conv3_3"")\n        self.conv3_4 = self.conv_layer(self.conv3_3, 256, 256, ""conv3_4"")\n        self.pool3 = self.max_pool(self.conv3_4, \'pool3\')\n\n        self.conv4_1 = self.conv_layer(self.pool3, 256, 512, ""conv4_1"")\n        self.conv4_2 = self.conv_layer(self.conv4_1, 512, 512, ""conv4_2"")\n        self.conv4_3 = self.conv_layer(self.conv4_2, 512, 512, ""conv4_3"")\n        self.conv4_4 = self.conv_layer(self.conv4_3, 512, 512, ""conv4_4"")\n        self.pool4 = self.max_pool(self.conv4_4, \'pool4\')\n\n        self.conv5_1 = self.conv_layer(self.pool4, 512, 512, ""conv5_1"")\n        self.conv5_2 = self.conv_layer(self.conv5_1, 512, 512, ""conv5_2"")\n        self.conv5_3 = self.conv_layer(self.conv5_2, 512, 512, ""conv5_3"")\n        self.conv5_4 = self.conv_layer(self.conv5_3, 512, 512, ""conv5_4"")\n        self.pool5 = self.max_pool(self.conv5_4, \'pool5\')\n\n        self.fc6 = self.fc_layer(self.pool5, 25088, 4096, ""fc6"")  # 25088 = ((224 // (2 ** 5)) ** 2) * 512\n        self.relu6 = tf.nn.relu(self.fc6)\n        if train_mode is not None:\n            self.relu6 = tf.cond(train_mode, lambda: tf.nn.dropout(self.relu6, self.dropout), lambda: self.relu6)\n        elif self.trainable:\n            self.relu6 = tf.nn.dropout(self.relu6, self.dropout)\n\n        self.fc7 = self.fc_layer(self.relu6, 4096, 4096, ""fc7"")\n        self.relu7 = tf.nn.relu(self.fc7)\n        if train_mode is not None:\n            self.relu7 = tf.cond(train_mode, lambda: tf.nn.dropout(self.relu7, self.dropout), lambda: self.relu7)\n        elif self.trainable:\n            self.relu7 = tf.nn.dropout(self.relu7, self.dropout)\n\n        self.fc8 = self.fc_layer(self.relu7, 4096, 1000, ""fc8"")\n        self.prob = tf.nn.softmax(self.fc8, name=""prob"")\n        self.data_dict = None\n        print(""build vgg model finished: %ds"" % (time.time() - start_time))\n        return self.fc8\n\nif __name__ == \'__main__\':\n    vgg = Vgg16()\n\n    # from lib.dataset import _ImageDataSet\n    # images = _ImageDataSet(\'../../../data/image/train.tfrecords\').input_fn(\'train\', 5)\n    # images_vec = vgg.build(images)\n    # sess = tf.InteractiveSession()\n    # sess.run(tf.global_variables_initializer())\n    # print(sess.run(images_vec))\n'"
python/lib/utils/__init__.py,0,b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/3/5'
python/lib/utils/create_record.py,10,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/3/6\n""""""This script convert the raw image to tfrecords format.""""""\nimport os\nimport tensorflow as tf\nfrom PIL import Image\n\ninpath = \'../../data/image/train\'\noutpath = \'../../data/image/train.tfrecords\'\n\n\ndef create_record():\n    writer = tf.python_io.TFRecordWriter(outpath)\n    for img_name in os.listdir(inpath):\n        img_path = os.path.join(inpath, img_name)\n        img = Image.open(img_path)\n        img = img.resize((224, 224))\n        img_raw = img.tobytes()\n        example = tf.train.Example(\n           features=tf.train.Features(feature={\n                \'image\': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))\n           }))\n        writer.write(example.SerializeToString())\n    writer.close()\n\n\ndef input_fn():\n    # Transforms a scalar string `example_proto` into a pair of a scalar string and\n    # a scalar integer, representing an image and its label, respectively.\n    def _parse_function(example_proto):\n        features = {""image"": tf.FixedLenFeature((), tf.string, default_value="""")}\n        parsed = tf.parse_single_example(example_proto, features)\n        # Perform additional preprocessing on the parsed data.\n        image = tf.decode_raw(parsed[""image""], tf.uint8)\n        image = tf.reshape(image, [224, 224, 3])\n        return image\n    # Creates a dataset that reads all of the examples from two files, and extracts\n    # the image and label features.\n    dataset = tf.data.TFRecordDataset(outpath)\n    dataset = dataset.map(_parse_function)\n    img = dataset.make_one_shot_iterator().get_next()\n    return img\n\n\nif __name__ == \'__main__\':\n    create_record()\n    image = input_fn()\n    sess = tf.InteractiveSession()\n    print(sess.run(image))\n\n'"
python/lib/utils/image_preprocessing.py,4,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/3/5\n""""""Provides custom function to preprocess images.\nTODO: custom preprocess for CTR task\n""""""\n\nimport tensorflow as tf\n\n\ndef preprocess_image(image, is_training, height, width, depth):\n    """"""Preprocess a single image of layout [height, width, depth].""""""\n    if is_training:\n        # Resize the image to add four extra pixels on each side.\n        image = tf.image.resize_image_with_crop_or_pad(\n            image, height + 8, width + 8)\n        # Randomly crop a [_HEIGHT, _WIDTH] section of the image.\n        image = tf.random_crop(image, [height, width, depth])\n        # Randomly flip the image horizontally.\n        image = tf.image.random_flip_left_right(image)\n    # Subtract off the mean and divide by the variance of the pixels.\n    image = tf.image.per_image_standardization(image)\n    return image\n'"
python/lib/utils/inspect_checkpoint.py,6,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/3/7\n""""""A simple script for inspect checkpoint files.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport sys\n\nimport tensorflow as tf\n\n# or use the inspect_checkpoint library\n# from tensorflow.python.tools import inspect_checkpoint as chkp\n# chkp.print_tensors_in_checkpoint_file(""/tmp/model.ckpt"", tensor_name=\'\', all_tensors=True)\n\n\nFLAGS = tf.app.flags.FLAGS\ntf.app.flags.DEFINE_string(""checkpoint_path"", """", ""Checkpoint file path"")\ntf.app.flags.DEFINE_string(""tensor_name"", """", ""Name of the tensor to inspect"")\n\n# checkpoint_path = FLAGS.file_name\n# reader = tf.train.NewCheckpointReader(checkpoint_path)\n# var_to_shape_map = reader.get_variable_to_shape_map()\n# for key in var_to_shape_map:\n#     print(""tensor_name: "", key)\n#     print(reader.get_tensor(key))  # Remove this is you want to print only variable names\n\n\ndef print_tensors_in_checkpoint_file(file_name, tensor_name):\n    """"""Prints tensors in a checkpoint file. \n    If no `tensor_name` is provided, prints the tensor names and shapes \n    in the checkpoint file. \n    If `tensor_name` is provided, prints the content of the tensor. \n    Args: \n      file_name: Name of the checkpoint file. \n      tensor_name: Name of the tensor in the checkpoint file to print. \n    """"""\n    try:\n        reader = tf.train.NewCheckpointReader(file_name)\n        if not tensor_name:\n            print(reader.debug_string().decode(""utf-8""))\n        else:\n            print(""tensor_name: "", tensor_name)\n            print(reader.get_tensor(tensor_name))\n    except Exception as e:\n        print(str(e))\n        if ""corrupted compressed block contents"" in str(e):\n            print(""It\'s likely that your checkpoint file has been compressed ""\n                  ""with SNAPPY."")\n\n\ndef main(unused_argv):\n    if not FLAGS.file_name:\n        print(""Usage: inspect_checkpoint --checkpoint_path=checkpoint_file_name ""\n              ""[--tensor_name=tensor_to_print]"")\n        sys.exit(1)\n    else:\n        print_tensors_in_checkpoint_file(FLAGS.file_name, FLAGS.tensor_name)\n\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
python/lib/utils/model_util.py,30,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/3/5\n""""""This module contains some model build related utility functions""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nimport math\nimport tensorflow as tf\n\n\ndef add_layer_summary(value, tag):\n    tf.summary.scalar(\'%s/fraction_of_zero_values\' % tag, tf.nn.zero_fraction(value))\n    tf.summary.histogram(\'%s/activation\' % tag, value)\n\n\ndef check_no_sync_replicas_optimizer(optimizer):\n    if isinstance(optimizer, tf.train.SyncReplicasOptimizer):\n        raise ValueError(\n            \'SyncReplicasOptimizer does not support multi optimizers case. \'\n            \'Therefore, it is not supported in DNNLinearCombined model. \'\n            \'If you want to use this optimizer, please use either DNN or Linear model.\')\n\n\ndef activation_fn(opt):\n    """"""Returns an activation function.\n    Args:\n        opt: string\n        Supported 10 strings:\n        * \'sigmoid\': Returns `tf.sigmoid`.\n        * \'tanh\': Returns `tf.tanh`.\n        * \'relu\': Returns `tf.nn.relu`.\n        * \'relu6\': Returns `tf.nn.relu6`.\n        * \'leaky_relu\': Returns `tf.nn.leaky_relu`.\n        * \'crelu\': Returns `tf.nn.crelu`.\n        * \'elu\': Returns `tf.nn.elu`.\n        * \'selu\': Returns `tf.nn.selu`.\n        * \'softplus\': Returns `tf.nn.softplus`.\n        * \'softsign\': Returns `tf.nn.softsign`.\n    """"""\n    _activation_fn_name = {\n        \'sigmoid\': tf.sigmoid,\n        \'tanh\': tf.tanh,\n        \'relu\': tf.nn.relu,\n        \'relu6\': tf.nn.relu6,\n        \'leaky_relu\': tf.nn.leaky_relu,\n        \'crelu\': tf.nn.crelu,\n        \'elu\': tf.nn.elu,\n        \'selu\': tf.nn.selu,\n        \'softplus\': tf.nn.softplus,\n        \'softsign\': tf.nn.softsign,\n    }\n    if opt in six.iterkeys(_activation_fn_name):\n        return _activation_fn_name[opt]\n    raise ValueError(\'Unsupported activation name: {}. Supported names are: {}\'.format(\n        opt, tuple(sorted(six.iterkeys(_activation_fn_name)))))\n\n\ndef get_optimizer_instance(opt, learning_rate=None):\n    """"""Returns an optimizer instance.\n    Supports the following types for the given `opt`:\n        * An `Optimizer` instance string: Returns the given `opt`.\n        * A supported string: Creates an `Optimizer` subclass with the given `learning_rate`.\n      Supported strings:\n        * \'Adagrad\': Returns an `AdagradOptimizer`.\n        * \'Adam\': Returns an `AdamOptimizer`.\n        * \'Ftrl\': Returns an `FtrlOptimizer`.\n        * \'RMSProp\': Returns an `RMSPropOptimizer`.\n        * \'SGD\': Returns a `GradientDescentOptimizer`.\n    Args:\n      opt: An `Optimizer` instance, or supported string, as discussed above.\n      learning_rate: A float. Only used if `opt` is a supported string.\n    Returns:\n      An `Optimizer` instance.\n    Raises:\n      ValueError: If `opt` is an unsupported string.\n      ValueError: If `opt` is a supported string but `learning_rate` was not specified.\n      ValueError: If `opt` is none of the above types.\n    """"""\n    # Methods related to optimizers used in canned_estimators.""""""\n    _OPTIMIZER_CLS_NAMES = {\n        \'Adagrad\': tf.train.AdagradOptimizer,\n        \'Adam\': tf.train.AdamOptimizer,\n        \'Ftrl\': tf.train.FtrlOptimizer,\n        \'RMSProp\': tf.train.RMSPropOptimizer,\n        \'SGD\': tf.train.GradientDescentOptimizer\n    }\n    if isinstance(opt, six.string_types):\n        if opt in six.iterkeys(_OPTIMIZER_CLS_NAMES):\n            if learning_rate is None:\n                raise ValueError(\'learning_rate must be specified when opt is supported string.\')\n            return _OPTIMIZER_CLS_NAMES[opt](learning_rate=learning_rate)\n        else:\n            try:\n                opt = eval(opt)  # eval(\'tf.nn.relu\') tf.nn.relu\n                if not isinstance(opt, tf.train.Optimizer):\n                    raise ValueError(\'The given object is not an Optimizer instance. Given: {}\'.format(opt))\n                return opt\n            except (AttributeError, NameError):\n                raise ValueError(\'Unsupported optimizer option: `{}`. \'\n                    \'Supported names are: {} or an `Optimizer` instance.\'.format(\n                    opt, tuple(sorted(six.iterkeys(_OPTIMIZER_CLS_NAMES)))))\n\n\ndef linear_learning_rate(num_linear_feature_columns):\n    """"""Returns the default learning rate of the linear model.\n    The calculation is a historical artifact of this initial implementation, but\n    has proven a reasonable choice.\n    Args:\n      num_linear_feature_columns: The number of feature columns of the linear model.\n    Returns:\n      A float.\n    """"""\n    default_learning_rate = 1. / math.sqrt(num_linear_feature_columns)\n    return min(0.005, default_learning_rate)'"
python/lib/utils/util.py,9,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/2/2\n""""""Provide some utility function.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport time\nimport os\nfrom collections import OrderedDict\nfrom functools import wraps\n\nimport tensorflow as tf\n\n\ndef timer(info=\'\'):\n    """"""parameter decarotor""""""\n    def _timer(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):  # passing params to func\n            s_time = time.time()\n            func(*args, **kwargs)\n            e_time = time.time()\n            period = (e_time-s_time) / 60.0\n            print(info + \'-> elapsed time: %.3f minutes\' % period)\n        return wrapper\n    return _timer\n\n\ndef elapse_time(start_time):\n    return round((time.time()-start_time) / 60)\n\n\ndef list_files(input_data):\n    """"""if input file is a dir, convert to a file path list\n    Return:\n         file path list\n    """"""\n    if tf.gfile.IsDirectory(input_data):\n        file_name = [f for f in tf.gfile.ListDirectory(input_data) if not f.startswith(\'.\')]\n        return [input_data + \'/\' + f for f in file_name]\n    else:\n        return [input_data]\n\n\ndef record_dataset(filenames, height, width, depth):\n    """"""Returns an input pipeline Dataset from `filenames`.""""""\n    record_bytes = height * width * depth\n    return tf.data.FixedLengthRecordDataset(filenames, record_bytes)\n\n\ndef get_filenames(data_dir):\n    """"""Returns a list of filenames.""""""\n    assert os.path.exists(data_dir), (\n        \'Image data dir {} not found.\'.format(data_dir))\n    return os.listdir(data_dir)\n\n\ndef column_to_dtype(feature, feature_conf):\n    """"""Parse columns to tf.dtype\n     Return: \n         similar to _csv_column_defaults()\n     """"""\n    _column_dtype_dic = OrderedDict()\n    _column_dtype_dic[\'label\'] = tf.int32\n    for f in feature:\n        if f in feature_conf:\n            conf = feature_conf[f]\n            if conf[\'type\'] == \'category\':\n                if conf[\'transform\'] == \'identity\':  # identity category column need int type\n                    _column_dtype_dic[f] = tf.int32\n                else:\n                    _column_dtype_dic[f] = tf.string\n            else:\n                _column_dtype_dic[f] = tf.float32  # 0.0 for float32\n        else:\n            _column_dtype_dic[f] = tf.string\n    return _column_dtype_dic\n\n\n\n'"
python/lib/utils/vgg_preprocessing.py,59,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Author: lapis-hong\n# @Date  : 2018/2/8\n""""""Provides utilities to preprocess images.\n\nThe preprocessing steps for VGG were introduced in the following technical\nreport:\n\n  Very Deep Convolutional Networks For Large-Scale Image Recognition\n  Karen Simonyan and Andrew Zisserman\n  arXiv technical report, 2015\n  PDF: http://arxiv.org/pdf/1409.1556.pdf\n  ILSVRC 2014 Slides: http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf\n  CC-BY-4.0\n\nMore information can be obtained from the VGG website:\nwww.robots.ox.ac.uk/~vgg/research/very_deep/\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n_R_MEAN = 123.68 / 255\n_G_MEAN = 116.78 / 255\n_B_MEAN = 103.94 / 255\n\n_RESIZE_SIDE_MIN = 256\n_RESIZE_SIDE_MAX = 512\n\n\ndef _crop(image, offset_height, offset_width, crop_height, crop_width):\n    """"""Crops the given image using the provided offsets and sizes.\n\n    Note that the method doesn\'t assume we know the input image size but it does\n    assume we know the input image rank.\n\n    Args:\n      image: an image of shape [height, width, channels].\n      offset_height: a scalar tensor indicating the height offset.\n      offset_width: a scalar tensor indicating the width offset.\n      crop_height: the height of the cropped image.\n      crop_width: the width of the cropped image.\n\n    Returns:\n      the cropped (and resized) image.\n\n    Raises:\n      InvalidArgumentError: if the rank is not 3 or if the image dimensions are\n        less than the crop size.\n    """"""\n    original_shape = tf.shape(image)\n    rank_assertion = tf.Assert(\n        tf.equal(tf.rank(image), 3),\n        [\'Rank of image must be equal to 3.\'])\n    with tf.control_dependencies([rank_assertion]):\n        cropped_shape = tf.stack([crop_height, crop_width, original_shape[2]])\n    size_assertion = tf.Assert(\n        tf.logical_and(\n            tf.greater_equal(original_shape[0], crop_height),\n            tf.greater_equal(original_shape[1], crop_width)),\n            [\'Crop size greater than the image size.\'])\n    offsets = tf.to_int32(tf.stack([offset_height, offset_width, 0]))\n    # Use tf.slice instead of crop_to_bounding box as it accepts tensors to\n    # define the crop size.\n    with tf.control_dependencies([size_assertion]):\n        image = tf.slice(image, offsets, cropped_shape)\n    return tf.reshape(image, cropped_shape)\n\n\ndef _random_crop(image_list, crop_height, crop_width):\n    """"""Crops the given list of images.\n    The function applies the same crop to each image in the list. This can be\n    effectively applied when there are multiple image inputs of the same\n    dimension such as:\n      image, depths, normals = _random_crop([image, depths, normals], 120, 150)\n    Args:\n      image_list: a list of image tensors of the same dimension but possibly\n        varying channel.\n      crop_height: the new height.\n      crop_width: the new width.\n    Returns:\n      the image_list with cropped images.\n    Raises:\n      ValueError: if there are multiple image inputs provided with different size\n        or the images are smaller than the crop dimensions.\n    """"""\n    if not image_list:\n        raise ValueError(\'Empty image_list.\')\n    # Compute the rank assertions.\n    rank_assertions = []\n    for image in image_list:\n        image_rank = tf.rank(image)\n        rank_assert = tf.Assert(\n            tf.equal(image_rank, 3),\n                [\'Wrong rank for tensor  %s [expected] [actual]\',\n                    image.name, 3, image_rank])\n        rank_assertions.append(rank_assert)\n\n    with tf.control_dependencies([rank_assertions[0]]):\n        image_shape = tf.shape(image_list[0])\n    image_height = image_shape[0]\n    image_width = image_shape[1]\n    crop_size_assert = tf.Assert(\n        tf.logical_and(\n            tf.greater_equal(image_height, crop_height),\n            tf.greater_equal(image_width, crop_width)),\n                [\'Crop size greater than the image size.\'])\n    asserts = [rank_assertions[0], crop_size_assert]\n\n    for i in range(1, len(image_list)):\n        image = image_list[i]\n        asserts.append(rank_assertions[i])\n        with tf.control_dependencies([rank_assertions[i]]):\n            shape = tf.shape(image)\n        height = shape[0]\n        width = shape[1]\n\n        height_assert = tf.Assert(\n            tf.equal(height, image_height),\n                [\'Wrong height for tensor %s [expected][actual]\',\n                    image.name, height, image_height])\n        width_assert = tf.Assert(\n            tf.equal(width, image_width),\n                [\'Wrong width for tensor %s [expected][actual]\',\n                    image.name, width, image_width])\n        asserts.extend([height_assert, width_assert])\n    # Create a random bounding box.\n    # Use tf.random_uniform and not numpy.random.rand as doing the former would\n    # generate random numbers at graph eval time, unlike the latter which\n    # generates random numbers at graph definition time.\n    with tf.control_dependencies(asserts):\n        max_offset_height = tf.reshape(image_height - crop_height + 1, [])\n    with tf.control_dependencies(asserts):\n        max_offset_width = tf.reshape(image_width - crop_width + 1, [])\n    offset_height = tf.random_uniform(\n            [], maxval=max_offset_height, dtype=tf.int32)\n    offset_width = tf.random_uniform(\n            [], maxval=max_offset_width, dtype=tf.int32)\n    return [_crop(image, offset_height, offset_width,\n                crop_height, crop_width) for image in image_list]\n\n\ndef _central_crop(image_list, crop_height, crop_width):\n    """"""Performs central crops of the given image list.\n    Args:\n      image_list: a list of image tensors of the same dimension but possibly\n        varying channel.\n      crop_height: the height of the image following the crop.\n      crop_width: the width of the image following the crop.\n    Returns:\n      the list of cropped images.\n    """"""\n    outputs = []\n    for image in image_list:\n        image_height = tf.shape(image)[0]\n        image_width = tf.shape(image)[1]\n        offset_height = (image_height - crop_height) / 2\n        offset_width = (image_width - crop_width) / 2\n        outputs.append(_crop(image, offset_height, offset_width,\n                         crop_height, crop_width))\n    return outputs\n\n\ndef _mean_image_subtraction(image, means):\n    """"""Subtracts the given means from each image channel.\n    For example:\n      means = [123.68, 116.779, 103.939]\n      image = _mean_image_subtraction(image, means)\n    Note that the rank of `image` must be known.\n    Args:\n      image: a tensor of size [height, width, C].\n      means: a C-vector of values to subtract from each channel.\n    Returns:\n      the centered image.\n    Raises:\n      ValueError: If the rank of `image` is unknown, if `image` has a rank other\n        than three or if the number of channels in `image` doesn\'t match the\n        number of values in `means`.\n    """"""\n    if image.get_shape().ndims != 3:\n        raise ValueError(\'Input must be of size [height, width, C>0]\')\n    num_channels = image.get_shape().as_list()[-1]\n    if len(means) != num_channels:\n        raise ValueError(\'len(means) must match the number of channels\')\n\n    channels = tf.split(axis=2, num_or_size_splits=num_channels, value=image)\n    for i in range(num_channels):\n        channels[i] -= means[i]\n    return tf.concat(axis=2, values=channels)\n\n\ndef _smallest_size_at_least(height, width, smallest_side):\n    """"""Computes new shape with the smallest side equal to `smallest_side`.\n    Computes new shape with the smallest side equal to `smallest_side` while\n    preserving the original aspect ratio.\n    Args:\n      height: an int32 scalar tensor indicating the current height.\n      width: an int32 scalar tensor indicating the current width.\n      smallest_side: A python integer or scalar `Tensor` indicating the size of\n        the smallest side after resize.\n    Returns:\n      new_height: an int32 scalar tensor indicating the new height.\n      new_width: and int32 scalar tensor indicating the new width.\n    """"""\n    smallest_side = tf.convert_to_tensor(smallest_side, dtype=tf.int32)\n    height = tf.to_float(height)\n    width = tf.to_float(width)\n    smallest_side = tf.to_float(smallest_side)\n    scale = tf.cond(tf.greater(height, width),\n                  lambda: smallest_side / width,\n                  lambda: smallest_side / height)\n    new_height = tf.to_int32(height * scale)\n    new_width = tf.to_int32(width * scale)\n    return new_height, new_width\n\n\ndef _aspect_preserving_resize(image, smallest_side):\n    """"""Resize images preserving the original aspect ratio.\n    Args:\n      image: A 3-D image `Tensor`.\n      smallest_side: A python integer or scalar `Tensor` indicating the size of\n        the smallest side after resize.\n    Returns:\n      resized_image: A 3-D tensor containing the resized image.\n    """"""\n    smallest_side = tf.convert_to_tensor(smallest_side, dtype=tf.int32)\n    shape = tf.shape(image)\n    height = shape[0]\n    width = shape[1]\n    new_height, new_width = _smallest_size_at_least(height, width, smallest_side)\n    image = tf.expand_dims(image, 0)\n    resized_image = tf.image.resize_bilinear(image, [new_height, new_width],\n                                             align_corners=False)\n    resized_image = tf.squeeze(resized_image)\n    resized_image.set_shape([None, None, 3])\n    return resized_image\n\n\ndef preprocess_for_train(image,\n                         output_height,\n                         output_width,\n                         resize_side_min=_RESIZE_SIDE_MIN,\n                         resize_side_max=_RESIZE_SIDE_MAX):\n    """"""Preprocesses the given image for training.\n    Note that the actual resizing scale is sampled from\n      [`resize_size_min`, `resize_size_max`].\n    Args:\n      image: A `Tensor` representing an image of arbitrary size.\n      output_height: The height of the image after preprocessing.\n      output_width: The width of the image after preprocessing.\n      resize_side_min: The lower bound for the smallest side of the image for\n        aspect-preserving resizing.\n      resize_side_max: The upper bound for the smallest side of the image for\n        aspect-preserving resizing.\n    Returns:\n      A preprocessed image.\n    """"""\n    resize_side = tf.random_uniform(\n        [], minval=resize_side_min, maxval=resize_side_max+1, dtype=tf.int32)\n    image = _aspect_preserving_resize(image, resize_side)\n    image = _random_crop([image], output_height, output_width)[0]\n    image.set_shape([output_height, output_width, 3])\n    image = tf.to_float(image)\n    image = tf.image.random_flip_left_right(image)\n    return _mean_image_subtraction(image, [_R_MEAN, _G_MEAN, _B_MEAN])\n\n\ndef preprocess_for_eval(image, output_height, output_width, resize_side):\n    """"""Preprocesses the given image for evaluation.\n    Args:\n      image: A `Tensor` representing an image of arbitrary size.\n      output_height: The height of the image after preprocessing.\n      output_width: The width of the image after preprocessing.\n      resize_side: The smallest side of the image for aspect-preserving resizing.\n    Returns:\n      A preprocessed image.\n    """"""\n    image = _aspect_preserving_resize(image, resize_side)\n    image = _central_crop([image], output_height, output_width)[0]\n    image.set_shape([output_height, output_width, 3])\n    image = tf.to_float(image)\n    return _mean_image_subtraction(image, [_R_MEAN, _G_MEAN, _B_MEAN])\n\n\ndef preprocess_image(image, output_height, output_width, is_training=False,\n                     resize_side_min=_RESIZE_SIDE_MIN,\n                     resize_side_max=_RESIZE_SIDE_MAX):\n    """"""Preprocesses the given image.\n    Args:\n      image: A `Tensor` representing an image of arbitrary size.\n      output_height: The height of the image after preprocessing.\n      output_width: The width of the image after preprocessing.\n      is_training: `True` if we\'re preprocessing the image for training and\n        `False` otherwise.\n      resize_side_min: The lower bound for the smallest side of the image for\n        aspect-preserving resizing. If `is_training` is `False`, then this value\n        is used for rescaling.\n      resize_side_max: The upper bound for the smallest side of the image for\n        aspect-preserving resizing. If `is_training` is `False`, this value is\n        ignored. Otherwise, the resize side is sampled from\n          [resize_size_min, resize_size_max].\n    Returns:\n      A preprocessed image.\n    """"""\n    if is_training:\n        return preprocess_for_train(image, output_height, output_width,\n                                resize_side_min, resize_side_max)\n    else:\n        return preprocess_for_eval(image, output_height, output_width,\n                               resize_side_min)\n'"
