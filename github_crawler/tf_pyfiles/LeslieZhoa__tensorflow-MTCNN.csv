file_path,api_count,code
test.py,0,"b'\n# coding: utf-8\n\n# In[1]:\n\n\nimport sys\nfrom detection.MtcnnDetector import MtcnnDetector\nfrom detection.detector import Detector\nfrom detection.fcn_detector import FcnDetector\nfrom train.model import P_Net,R_Net,O_Net\nimport cv2\nimport os\nimport numpy as np\nimport train.config as config\n\n\n# In[ ]:\n\n\ntest_mode=config.test_mode\nthresh=config.thresh\nmin_face_size=config.min_face\nstride=config.stride\ndetectors=[None,None,None]\n# \xe6\xa8\xa1\xe5\x9e\x8b\xe6\x94\xbe\xe7\xbd\xae\xe4\xbd\x8d\xe7\xbd\xae\nmodel_path=[\'model/PNet/\',\'model/RNet/\',\'model/ONet\']\nbatch_size=config.batches\nPNet=FcnDetector(P_Net,model_path[0])\ndetectors[0]=PNet\n\n\nif test_mode in [""RNet"", ""ONet""]:\n    RNet = Detector(R_Net, 24, batch_size[1], model_path[1])\n    detectors[1] = RNet\n\n\nif test_mode == ""ONet"":\n    ONet = Detector(O_Net, 48, batch_size[2], model_path[2])\n    detectors[2] = ONet\n\nmtcnn_detector = MtcnnDetector(detectors=detectors, min_face_size=min_face_size,\n                               stride=stride, threshold=thresh)\nout_path=config.out_path\nif config.input_mode==\'1\':\n    #\xe9\x80\x89\xe7\x94\xa8\xe5\x9b\xbe\xe7\x89\x87\n    path=config.test_dir\n    #print(path)\n    for item in os.listdir(path):\n        img_path=os.path.join(path,item)\n        img=cv2.imread(img_path)\n        boxes_c,landmarks=mtcnn_detector.detect(img)\n        for i in range(boxes_c.shape[0]):\n            bbox=boxes_c[i,:4]\n            score=boxes_c[i,4]\n            corpbbox = [int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])]\n            #\xe7\x94\xbb\xe4\xba\xba\xe8\x84\xb8\xe6\xa1\x86\n            cv2.rectangle(img, (corpbbox[0], corpbbox[1]),\n                          (corpbbox[2], corpbbox[3]), (255, 0, 0), 1)\n            #\xe5\x88\xa4\xe5\x88\xab\xe4\xb8\xba\xe4\xba\xba\xe8\x84\xb8\xe7\x9a\x84\xe7\xbd\xae\xe4\xbf\xa1\xe5\xba\xa6\n            cv2.putText(img, \'{:.2f}\'.format(score), \n                       (corpbbox[0], corpbbox[1] - 2), \n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0, 0, 255), 2)\n        #\xe7\x94\xbb\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\n        for i in range(landmarks.shape[0]):\n            for j in range(len(landmarks[i])//2):\n                cv2.circle(img, (int(landmarks[i][2*j]),int(int(landmarks[i][2*j+1]))), 2, (0,0,255))   \n        cv2.imshow(\'im\',img)\n        k = cv2.waitKey(0) & 0xFF\n        if k == 27:        \n            cv2.imwrite(out_path + item,img)\n    cv2.destroyAllWindows()\n\nif config.input_mode==\'2\':\n    cap=cv2.VideoCapture(0)\n    fourcc = cv2.VideoWriter_fourcc(*\'XVID\')\n    out = cv2.VideoWriter(out_path+\'out.mp4\' ,fourcc,10,(640,480))\n    while True:\n            t1=cv2.getTickCount()\n            ret,frame = cap.read()\n            if ret == True:\n                boxes_c,landmarks = mtcnn_detector.detect(frame)\n                t2=cv2.getTickCount()\n                t=(t2-t1)/cv2.getTickFrequency()\n                fps=1.0/t\n                for i in range(boxes_c.shape[0]):\n                    bbox = boxes_c[i, :4]\n                    score = boxes_c[i, 4]\n                    corpbbox = [int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])]\n                \n                    #\xe7\x94\xbb\xe4\xba\xba\xe8\x84\xb8\xe6\xa1\x86\n                    cv2.rectangle(frame, (corpbbox[0], corpbbox[1]),\n                          (corpbbox[2], corpbbox[3]), (255, 0, 0), 1)\n                    #\xe7\x94\xbb\xe7\xbd\xae\xe4\xbf\xa1\xe5\xba\xa6\n                    cv2.putText(frame, \'{:.2f}\'.format(score), \n                                (corpbbox[0], corpbbox[1] - 2), \n                                cv2.FONT_HERSHEY_SIMPLEX,\n                                0.5,(0, 0, 255), 2)\n                    #\xe7\x94\xbbfps\xe5\x80\xbc\n                cv2.putText(frame, \'{:.4f}\'.format(t) + "" "" + \'{:.3f}\'.format(fps), (10, 20),\n                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)\n                #\xe7\x94\xbb\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\n                for i in range(landmarks.shape[0]):\n                    for j in range(len(landmarks[i])//2):\n                        cv2.circle(frame, (int(landmarks[i][2*j]),int(int(landmarks[i][2*j+1]))), 2, (0,0,255))  \n                a = out.write(frame)\n                cv2.imshow(""result"", frame)\n                if cv2.waitKey(1) & 0xFF == ord(\'q\'):\n                    break\n            else:\n                break\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()\n\n'"
detection/MtcnnDetector.py,0,"b'\n# coding: utf-8\n\n# In[3]:\n\n\nimport cv2\nimport numpy as np\nimport sys\n\nsys.path.append(\'../\')\nfrom preprocess.utils import *\nfrom tqdm import tqdm\n\n\n# In[4]:\n\n\ndef py_nms(dets,thresh):\n    \'\'\'\xe5\x89\x94\xe9\x99\xa4\xe5\xa4\xaa\xe7\x9b\xb8\xe4\xbc\xbc\xe7\x9a\x84box\'\'\'\n    x1 = dets[:, 0]\n    y1 = dets[:, 1]\n    x2 = dets[:, 2]\n    y2 = dets[:, 3]\n    scores = dets[:, 4]\n\n    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n    #\xe5\xb0\x86\xe6\xa6\x82\xe7\x8e\x87\xe5\x80\xbc\xe4\xbb\x8e\xe5\xa4\xa7\xe5\x88\xb0\xe5\xb0\x8f\xe6\x8e\x92\xe5\x88\x97\n    order = scores.argsort()[::-1]\n\n    keep = []\n    while order.size > 0:\n        i = order[0]\n        keep.append(i)\n        xx1 = np.maximum(x1[i], x1[order[1:]])\n        yy1 = np.maximum(y1[i], y1[order[1:]])\n        xx2 = np.minimum(x2[i], x2[order[1:]])\n        yy2 = np.minimum(y2[i], y2[order[1:]])\n\n        w = np.maximum(0.0, xx2 - xx1 + 1)\n        h = np.maximum(0.0, yy2 - yy1 + 1)\n        inter = w * h\n        \n        ovr = inter / (areas[i] + areas[order[1:]] - inter+1e-10)\n       \n        #\xe4\xbf\x9d\xe7\x95\x99\xe5\xb0\x8f\xe4\xba\x8e\xe9\x98\x88\xe5\x80\xbc\xe7\x9a\x84\xe4\xb8\x8b\xe6\xa0\x87\xef\xbc\x8c\xe5\x9b\xa0\xe4\xb8\xbaorder[0]\xe6\x8b\xbf\xe5\x87\xba\xe6\x9d\xa5\xe5\x81\x9a\xe6\xaf\x94\xe8\xbe\x83\xe4\xba\x86\xef\xbc\x8c\xe6\x89\x80\xe4\xbb\xa5inds+1\xe6\x98\xaf\xe5\x8e\x9f\xe6\x9d\xa5\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe4\xb8\x8b\xe6\xa0\x87\n        inds = np.where(ovr <= thresh)[0]\n        order = order[inds + 1]\n\n    return keep\n\n\n# In[ ]:\n\n\nclass MtcnnDetector:\n    \'\'\'\xe6\x9d\xa5\xe7\x94\x9f\xe6\x88\x90\xe4\xba\xba\xe8\x84\xb8\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\'\'\'\n    def __init__(self,detectors,\n                min_face_size=20,\n                stride=2,\n                threshold=[0.6,0.7,0.7],\n                scale_factor=0.79#\xe5\x9b\xbe\xe5\x83\x8f\xe9\x87\x91\xe5\xad\x97\xe5\xa1\x94\xe7\x9a\x84\xe7\xbc\xa9\xe5\xb0\x8f\xe7\x8e\x87\n                ):\n        self.pnet_detector=detectors[0]\n        self.rnet_detector=detectors[1]\n        self.onet_detector=detectors[2]\n        self.min_face_size=min_face_size\n        self.stride=stride\n        self.thresh=threshold\n        self.scale_factor=scale_factor\n    def detect_face(self,test_data):\n        all_boxes=[]\n        landmarks=[]\n        batch_idx=0\n        num_of_img=test_data.size\n        empty_array=np.array([])\n        for databatch in tqdm(test_data):\n            batch_idx+=1\n            im=databatch\n            if self.pnet_detector:\n                boxes,boxes_c,landmark=self.detect_pnet(im)\n                if boxes_c is None:\n                    all_boxes.append(empty_array)\n                    landmarks.append(empty_array)\n                    continue\n            if self.rnet_detector:\n                boxes, boxes_c, landmark = self.detect_rnet(im, boxes_c)\n                \n                if boxes_c is None:\n                    all_boxes.append(empty_array)\n                    landmarks.append(empty_array)\n\n                    continue\n            if self.onet_detector:\n                \n                boxes, boxes_c, landmark = self.detect_onet(im, boxes_c)\n               \n                if boxes_c is None:\n                    all_boxes.append(empty_array)\n                    landmarks.append(empty_array)\n\n                    continue\n\n            all_boxes.append(boxes_c)\n            landmark = [1]\n            landmarks.append(landmark)\n        return all_boxes, landmarks\n    def detect_pnet(self,im):\n        \'\'\'\xe9\x80\x9a\xe8\xbf\x87pnet\xe7\xad\x9b\xe9\x80\x89box\xe5\x92\x8clandmark\n        \xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n          im:\xe8\xbe\x93\xe5\x85\xa5\xe5\x9b\xbe\xe5\x83\x8f[h,2,3]\n        \'\'\'\n        h,w,c=im.shape\n        net_size=12\n        #\xe4\xba\xba\xe8\x84\xb8\xe5\x92\x8c\xe8\xbe\x93\xe5\x85\xa5\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe6\xaf\x94\xe7\x8e\x87\n        current_scale=float(net_size)/self.min_face_size\n        im_resized=self.processed_image(im,current_scale)\n        current_height,current_width,_=im_resized.shape\n        all_boxes=list()\n        #\xe5\x9b\xbe\xe5\x83\x8f\xe9\x87\x91\xe5\xad\x97\xe5\xa1\x94\n        while min(current_height,current_width)>net_size:\n            #\xe7\xb1\xbb\xe5\x88\xab\xe5\x92\x8cbox\n            cls_cls_map,reg=self.pnet_detector.predict(im_resized)\n            boxes=self.generate_bbox(cls_cls_map[:,:,1],reg,current_scale,self.thresh[0])\n            current_scale*=self.scale_factor#\xe7\xbb\xa7\xe7\xbb\xad\xe7\xbc\xa9\xe5\xb0\x8f\xe5\x9b\xbe\xe5\x83\x8f\xe5\x81\x9a\xe9\x87\x91\xe5\xad\x97\xe5\xa1\x94\n            im_resized=self.processed_image(im,current_scale)\n            current_height,current_width,_=im_resized.shape\n            \n            if boxes.size==0:\n                continue\n            #\xe9\x9d\x9e\xe6\x9e\x81\xe5\xa4\xa7\xe5\x80\xbc\xe6\x8a\x91\xe5\x88\xb6\xe7\x95\x99\xe4\xb8\x8b\xe9\x87\x8d\xe5\xa4\x8d\xe4\xbd\x8e\xe7\x9a\x84box\n            keep=py_nms(boxes[:,:5],0.5)\n            boxes=boxes[keep]\n            all_boxes.append(boxes)\n        if len(all_boxes)==0:\n            return None,None,None\n        all_boxes=np.vstack(all_boxes)\n        #\xe5\xb0\x86\xe9\x87\x91\xe5\xad\x97\xe5\xa1\x94\xe4\xb9\x8b\xe5\x90\x8e\xe7\x9a\x84box\xe4\xb9\x9f\xe8\xbf\x9b\xe8\xa1\x8c\xe9\x9d\x9e\xe6\x9e\x81\xe5\xa4\xa7\xe5\x80\xbc\xe6\x8a\x91\xe5\x88\xb6\n        keep = py_nms(all_boxes[:, 0:5], 0.7)\n        all_boxes = all_boxes[keep]\n        boxes = all_boxes[:, :5]\n        #box\xe7\x9a\x84\xe9\x95\xbf\xe5\xae\xbd\n        bbw = all_boxes[:, 2] - all_boxes[:, 0] + 1\n        bbh = all_boxes[:, 3] - all_boxes[:, 1] + 1\n        #\xe5\xaf\xb9\xe5\xba\x94\xe5\x8e\x9f\xe5\x9b\xbe\xe7\x9a\x84box\xe5\x9d\x90\xe6\xa0\x87\xe5\x92\x8c\xe5\x88\x86\xe6\x95\xb0\n        boxes_c = np.vstack([all_boxes[:, 0] + all_boxes[:, 5] * bbw,\n                             all_boxes[:, 1] + all_boxes[:, 6] * bbh,\n                             all_boxes[:, 2] + all_boxes[:, 7] * bbw,\n                             all_boxes[:, 3] + all_boxes[:, 8] * bbh,\n                             all_boxes[:, 4]])\n        boxes_c = boxes_c.T\n\n        return boxes, boxes_c, None\n    def detect_rnet(self,im,dets):\n        \'\'\'\xe9\x80\x9a\xe8\xbf\x87rent\xe9\x80\x89\xe6\x8b\xa9box\n        \xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n          im\xef\xbc\x9a\xe8\xbe\x93\xe5\x85\xa5\xe5\x9b\xbe\xe5\x83\x8f\n          dets:pnet\xe9\x80\x89\xe6\x8b\xa9\xe7\x9a\x84box\xef\xbc\x8c\xe6\x98\xaf\xe7\x9b\xb8\xe5\xaf\xb9\xe5\x8e\x9f\xe5\x9b\xbe\xe7\x9a\x84\xe7\xbb\x9d\xe5\xaf\xb9\xe5\x9d\x90\xe6\xa0\x87\n        \xe8\xbf\x94\xe5\x9b\x9e\xe5\x80\xbc\xef\xbc\x9a\n          box\xe7\xbb\x9d\xe5\xaf\xb9\xe5\x9d\x90\xe6\xa0\x87\n        \'\'\'\n        h,w,c=im.shape\n        #\xe5\xb0\x86pnet\xe7\x9a\x84box\xe5\x8f\x98\xe6\x88\x90\xe5\x8c\x85\xe5\x90\xab\xe5\xae\x83\xe7\x9a\x84\xe6\xad\xa3\xe6\x96\xb9\xe5\xbd\xa2\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe9\x81\xbf\xe5\x85\x8d\xe4\xbf\xa1\xe6\x81\xaf\xe6\x8d\x9f\xe5\xa4\xb1\n        dets=convert_to_square(dets)\n        dets[:,0:4]=np.round(dets[:,0:4])\n        #\xe8\xb0\x83\xe6\x95\xb4\xe8\xb6\x85\xe5\x87\xba\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84box\n        [dy,edy,dx,edx,y,ey,x,ex,tmpw,tmph]=self.pad(dets,w,h)\n        delete_size=np.ones_like(tmpw)*20\n        ones=np.ones_like(tmpw)\n        zeros=np.zeros_like(tmpw)\n        num_boxes=np.sum(np.where((np.minimum(tmpw,tmph)>=delete_size),ones,zeros))\n        cropped_ims=np.zeros((num_boxes,24,24,3),dtype=np.float32)\n        for i in range(num_boxes):\n            #\xe5\xb0\x86pnet\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84box\xe7\x9b\xb8\xe5\xaf\xb9\xe4\xb8\x8e\xe5\x8e\x9f\xe5\x9b\xbe\xe8\xbf\x9b\xe8\xa1\x8c\xe8\xa3\x81\xe5\x89\xaa\xef\xbc\x8c\xe8\xb6\x85\xe5\x87\xba\xe9\x83\xa8\xe5\x88\x86\xe7\x94\xa80\xe8\xa1\xa5\n            if tmph[i]<20 or tmpw[i]<20:\n                continue\n            tmp = np.zeros((tmph[i], tmpw[i], 3), dtype=np.uint8)\n            tmp[dy[i]:edy[i] + 1, dx[i]:edx[i] + 1, :] = im[y[i]:ey[i] + 1, x[i]:ex[i] + 1, :]\n            cropped_ims[i, :, :, :] = (cv2.resize(tmp, (24, 24)) - 127.5) / 128\n        cls_scores, reg, _ = self.rnet_detector.predict(cropped_ims)\n        cls_scores = cls_scores[:, 1]\n        keep_inds = np.where(cls_scores > self.thresh[1])[0]\n        if len(keep_inds) > 0:\n            boxes = dets[keep_inds]\n            boxes[:, 4] = cls_scores[keep_inds]\n            reg = reg[keep_inds]\n        else:\n            return None, None, None\n\n        keep = py_nms(boxes, 0.6)\n        boxes = boxes[keep]\n        #\xe5\xaf\xb9pnet\xe6\x88\xaa\xe5\x8f\x96\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe5\x9d\x90\xe6\xa0\x87\xe8\xbf\x9b\xe8\xa1\x8c\xe6\xa0\xa1\xe5\x87\x86\xef\xbc\x8c\xe7\x94\x9f\xe6\x88\x90rnet\xe7\x9a\x84\xe4\xba\xba\xe8\x84\xb8\xe6\xa1\x86\xe5\xaf\xb9\xe4\xba\x8e\xe5\x8e\x9f\xe5\x9b\xbe\xe7\x9a\x84\xe7\xbb\x9d\xe5\xaf\xb9\xe5\x9d\x90\xe6\xa0\x87\n        boxes_c = self.calibrate_box(boxes, reg[keep])\n        return boxes, boxes_c, None\n    \n    def detect_onet(self,im,dets):\n        \'\'\'\xe5\xb0\x86onet\xe7\x9a\x84\xe9\x80\x89\xe6\xa1\x86\xe7\xbb\xa7\xe7\xbb\xad\xe7\xad\x9b\xe9\x80\x89\xe5\x9f\xba\xe6\x9c\xac\xe5\x92\x8crnet\xe5\xb7\xae\xe4\xb8\x8d\xe5\xa4\x9a\xe4\xbd\x86\xe5\xa4\x9a\xe8\xbf\x94\xe5\x9b\x9e\xe4\xba\x86landmark\'\'\'\n        h,w,c=im.shape\n        dets=convert_to_square(dets)\n        dets[:, 0:4] = np.round(dets[:, 0:4])\n        [dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph] = self.pad(dets, w, h)\n        num_boxes = dets.shape[0]\n        cropped_ims = np.zeros((num_boxes, 48, 48, 3), dtype=np.float32)\n        for i in range(num_boxes):\n            tmp = np.zeros((tmph[i], tmpw[i], 3), dtype=np.uint8)\n            tmp[dy[i]:edy[i] + 1, dx[i]:edx[i] + 1, :] = im[y[i]:ey[i] + 1, x[i]:ex[i] + 1, :]\n            cropped_ims[i, :, :, :] = (cv2.resize(tmp, (48, 48)) - 127.5) / 128\n\n        cls_scores, reg, landmark = self.onet_detector.predict(cropped_ims)\n        \n        cls_scores = cls_scores[:, 1]\n        keep_inds = np.where(cls_scores > self.thresh[2])[0]\n        if len(keep_inds) > 0:\n            \n            boxes = dets[keep_inds]\n            boxes[:, 4] = cls_scores[keep_inds]\n            reg = reg[keep_inds]\n            landmark = landmark[keep_inds]\n        else:\n            return None, None, None\n\n    \n        w = boxes[:, 2] - boxes[:, 0] + 1\n        \n        h = boxes[:, 3] - boxes[:, 1] + 1\n        landmark[:, 0::2] = (np.tile(w, (5, 1)) * landmark[:, 0::2].T + np.tile(boxes[:, 0], (5, 1)) - 1).T\n        landmark[:, 1::2] = (np.tile(h, (5, 1)) * landmark[:, 1::2].T + np.tile(boxes[:, 1], (5, 1)) - 1).T\n        boxes_c = self.calibrate_box(boxes, reg)\n\n        boxes = boxes[py_nms(boxes, 0.6)]\n        keep = py_nms(boxes_c, 0.6)\n        boxes_c = boxes_c[keep]\n        landmark = landmark[keep]\n        return boxes, boxes_c, landmark\n\n    def processed_image(self, img, scale):\n        \'\'\'\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe8\xbd\xac\xe5\x8c\x96\xe5\x9b\xbe\xe5\x83\x8f\xe5\xb0\xba\xe5\xba\xa6\xe5\xb9\xb6\xe5\xaf\xb9\xe5\x83\x8f\xe7\xb4\xa0\xe5\xbd\x92\xe4\xb8\x80\xe5\x88\xb0[-1,1]\n        \'\'\'\n        height, width, channels = img.shape\n        new_height = int(height * scale)  \n        new_width = int(width * scale)  \n        new_dim = (new_width, new_height)\n        img_resized = cv2.resize(img, new_dim, interpolation=cv2.INTER_LINEAR) \n        img_resized = (img_resized - 127.5) / 128\n        return img_resized\n        \n    def generate_bbox(self, cls_map, reg, scale, threshold):\n        """"""\n         \xe5\xbe\x97\xe5\x88\xb0\xe5\xaf\xb9\xe5\xba\x94\xe5\x8e\x9f\xe5\x9b\xbe\xe7\x9a\x84box\xe5\x9d\x90\xe6\xa0\x87\xef\xbc\x8c\xe5\x88\x86\xe7\xb1\xbb\xe5\x88\x86\xe6\x95\xb0\xef\xbc\x8cbox\xe5\x81\x8f\xe7\xa7\xbb\xe9\x87\x8f\n        """"""\n        #pnet\xe5\xa4\xa7\xe8\x87\xb4\xe5\xb0\x86\xe5\x9b\xbe\xe5\x83\x8fsize\xe7\xbc\xa9\xe5\xb0\x8f2\xe5\x80\x8d\n        stride = 2\n    \n        cellsize = 12\n\n        #\xe5\xb0\x86\xe7\xbd\xae\xe4\xbf\xa1\xe5\xba\xa6\xe9\xab\x98\xe7\x9a\x84\xe7\x95\x99\xe4\xb8\x8b\n        t_index = np.where(cls_map > threshold)\n\n        # \xe6\xb2\xa1\xe6\x9c\x89\xe4\xba\xba\xe8\x84\xb8\n        if t_index[0].size == 0:\n            return np.array([])\n        # \xe5\x81\x8f\xe7\xa7\xbb\xe9\x87\x8f\n        dx1, dy1, dx2, dy2 = [reg[t_index[0], t_index[1], i] for i in range(4)]\n\n        reg = np.array([dx1, dy1, dx2, dy2])\n        score = cls_map[t_index[0], t_index[1]]\n        #\xe5\xaf\xb9\xe5\xba\x94\xe5\x8e\x9f\xe5\x9b\xbe\xe7\x9a\x84box\xe5\x9d\x90\xe6\xa0\x87\xef\xbc\x8c\xe5\x88\x86\xe7\xb1\xbb\xe5\x88\x86\xe6\x95\xb0\xef\xbc\x8cbox\xe5\x81\x8f\xe7\xa7\xbb\xe9\x87\x8f\n        boundingbox = np.vstack([np.round((stride * t_index[1]) / scale),\n                                 np.round((stride * t_index[0]) / scale),\n                                 np.round((stride * t_index[1] + cellsize) / scale),\n                                 np.round((stride * t_index[0] + cellsize) / scale),\n                                 score,\n                                 reg])\n        #shape[n,9]\n        return boundingbox.T \n    def pad(self, bboxes, w, h):\n        \'\'\'\xe5\xb0\x86\xe8\xb6\x85\xe5\x87\xba\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84box\xe8\xbf\x9b\xe8\xa1\x8c\xe5\xa4\x84\xe7\x90\x86\n        \xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n          bboxes:\xe4\xba\xba\xe8\x84\xb8\xe6\xa1\x86\n          w,h:\xe5\x9b\xbe\xe5\x83\x8f\xe9\x95\xbf\xe5\xae\xbd\n        \xe8\xbf\x94\xe5\x9b\x9e\xe5\x80\xbc\xef\xbc\x9a\n          dy, dx : \xe4\xb8\xba\xe8\xb0\x83\xe6\x95\xb4\xe5\x90\x8e\xe7\x9a\x84box\xe7\x9a\x84\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe5\x9d\x90\xe6\xa0\x87\xe7\x9b\xb8\xe5\xaf\xb9\xe4\xba\x8e\xe5\x8e\x9fbox\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe7\x9a\x84\xe5\x9d\x90\xe6\xa0\x87\n          edy, edx : n\xe4\xb8\xba\xe8\xb0\x83\xe6\x95\xb4\xe5\x90\x8e\xe7\x9a\x84box\xe5\x8f\xb3\xe4\xb8\x8b\xe8\xa7\x92\xe7\x9b\xb8\xe5\xaf\xb9\xe5\x8e\x9fbox\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe7\x9a\x84\xe7\x9b\xb8\xe5\xaf\xb9\xe5\x9d\x90\xe6\xa0\x87\n          y, x : \xe8\xb0\x83\xe6\x95\xb4\xe5\x90\x8e\xe7\x9a\x84box\xe5\x9c\xa8\xe5\x8e\x9f\xe5\x9b\xbe\xe4\xb8\x8a\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe7\x9a\x84\xe5\x9d\x90\xe6\xa0\x87\n          ex, ex : \xe8\xb0\x83\xe6\x95\xb4\xe5\x90\x8e\xe7\x9a\x84box\xe5\x9c\xa8\xe5\x8e\x9f\xe5\x9b\xbe\xe4\xb8\x8a\xe5\x8f\xb3\xe4\xb8\x8b\xe8\xa7\x92\xe7\x9a\x84\xe5\x9d\x90\xe6\xa0\x87\n          tmph, tmpw: \xe5\x8e\x9f\xe5\xa7\x8bbox\xe7\x9a\x84\xe9\x95\xbf\xe5\xae\xbd\n        \'\'\'\n        #box\xe7\x9a\x84\xe9\x95\xbf\xe5\xae\xbd\n        tmpw, tmph = bboxes[:, 2] - bboxes[:, 0] + 1, bboxes[:, 3] - bboxes[:, 1] + 1\n        num_box = bboxes.shape[0]\n\n        dx, dy = np.zeros((num_box,)), np.zeros((num_box,))\n        edx, edy = tmpw.copy() - 1, tmph.copy() - 1\n        #box\xe5\xb7\xa6\xe4\xb8\x8a\xe5\x8f\xb3\xe4\xb8\x8b\xe7\x9a\x84\xe5\x9d\x90\xe6\xa0\x87\n        x, y, ex, ey = bboxes[:, 0], bboxes[:, 1], bboxes[:, 2], bboxes[:, 3]\n        #\xe6\x89\xbe\xe5\x88\xb0\xe8\xb6\x85\xe5\x87\xba\xe5\x8f\xb3\xe4\xb8\x8b\xe8\xbe\xb9\xe7\x95\x8c\xe7\x9a\x84box\xe5\xb9\xb6\xe5\xb0\x86ex,ey\xe5\xbd\x92\xe4\xb8\xba\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84w,h\n        #edx,edy\xe4\xb8\xba\xe8\xb0\x83\xe6\x95\xb4\xe5\x90\x8e\xe7\x9a\x84box\xe5\x8f\xb3\xe4\xb8\x8b\xe8\xa7\x92\xe7\x9b\xb8\xe5\xaf\xb9\xe5\x8e\x9fbox\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe7\x9a\x84\xe7\x9b\xb8\xe5\xaf\xb9\xe5\x9d\x90\xe6\xa0\x87\n        tmp_index = np.where(ex > w - 1)\n        edx[tmp_index] = tmpw[tmp_index] + w - 2 - ex[tmp_index]\n        ex[tmp_index] = w - 1\n\n        tmp_index = np.where(ey > h - 1)\n        edy[tmp_index] = tmph[tmp_index] + h - 2 - ey[tmp_index]\n        ey[tmp_index] = h - 1\n        #\xe6\x89\xbe\xe5\x88\xb0\xe8\xb6\x85\xe5\x87\xba\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe7\x9a\x84box\xe5\xb9\xb6\xe5\xb0\x86x,y\xe5\xbd\x92\xe4\xb8\xba0\n        #dx,dy\xe4\xb8\xba\xe8\xb0\x83\xe6\x95\xb4\xe5\x90\x8e\xe7\x9a\x84box\xe7\x9a\x84\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe5\x9d\x90\xe6\xa0\x87\xe7\x9b\xb8\xe5\xaf\xb9\xe4\xba\x8e\xe5\x8e\x9fbox\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe7\x9a\x84\xe5\x9d\x90\xe6\xa0\x87\n        tmp_index = np.where(x < 0)\n        dx[tmp_index] = 0 - x[tmp_index]\n        x[tmp_index] = 0\n\n        tmp_index = np.where(y < 0)\n        dy[tmp_index] = 0 - y[tmp_index]\n        y[tmp_index] = 0\n\n        return_list = [dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph]\n        return_list = [item.astype(np.int32) for item in return_list]\n\n        return return_list\n    def calibrate_box(self, bbox, reg):\n        \'\'\'\xe6\xa0\xa1\xe5\x87\x86box\n        \xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n          bbox:pnet\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84box\n\n          reg:rnet\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84box\xe5\x81\x8f\xe7\xa7\xbb\xe5\x80\xbc\n        \xe8\xbf\x94\xe5\x9b\x9e\xe5\x80\xbc\xef\xbc\x9a\n          \xe8\xb0\x83\xe6\x95\xb4\xe5\x90\x8e\xe7\x9a\x84box\xe6\x98\xaf\xe9\x92\x88\xe5\xaf\xb9\xe5\x8e\x9f\xe5\x9b\xbe\xe7\x9a\x84\xe7\xbb\x9d\xe5\xaf\xb9\xe5\x9d\x90\xe6\xa0\x87\n        \'\'\'\n\n        bbox_c = bbox.copy()\n        w = bbox[:, 2] - bbox[:, 0] + 1\n        w = np.expand_dims(w, 1)\n        h = bbox[:, 3] - bbox[:, 1] + 1\n        h = np.expand_dims(h, 1)\n        reg_m = np.hstack([w, h, w, h])\n        aug = reg_m * reg\n        bbox_c[:, 0:4] = bbox_c[:, 0:4] + aug\n        return bbox_c\n    def detect(self, img):\n        \'\'\'\xe7\x94\xa8\xe4\xba\x8e\xe6\xb5\x8b\xe8\xaf\x95\xe5\xbd\x93\xe4\xb8\xaa\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\'\'\'\n        boxes = None\n\n        # pnet\n        if self.pnet_detector:\n            boxes, boxes_c, _ = self.detect_pnet(img)\n            if boxes_c is None:\n                return np.array([]), np.array([])\n\n\n        # rnet\n        if self.rnet_detector:\n            boxes, boxes_c, _ = self.detect_rnet(img, boxes_c)\n            if boxes_c is None:\n                return np.array([]), np.array([])\n\n\n        # onet\n        if self.onet_detector:\n            boxes, boxes_c, landmark = self.detect_onet(img, boxes_c)\n            if boxes_c is None:\n                return np.array([]), np.array([])\n\n\n        return boxes_c, landmark\n\n'"
detection/__init__.py,0,b'####\n'
detection/detector.py,5,"b""\n# coding: utf-8\n\n# In[1]:\n\n\nimport tensorflow as tf\nimport numpy as np\n\n\n# In[2]:\n\n\nclass Detector:\n    '''\xe8\xaf\x86\xe5\x88\xab\xe5\xa4\x9a\xe7\xbb\x84\xe5\x9b\xbe\xe7\x89\x87'''\n    def __init__(self,net_factory,data_size,batch_size,model_path):\n        graph=tf.Graph()\n        with graph.as_default():\n            self.image_op=tf.placeholder(tf.float32,[None,data_size,data_size,3])\n            self.cls_prob, self.bbox_pred, self.landmark_pred = net_factory(self.image_op, training=False)\n            self.sess = tf.Session()\n            #\xe9\x87\x8d\xe8\xbd\xbd\xe6\xa8\xa1\xe5\x9e\x8b\n            saver=tf.train.Saver()\n            model_file=tf.train.latest_checkpoint(model_path)\n            saver.restore(self.sess,model_file)\n        self.data_size=data_size\n        self.batch_size=batch_size\n    def predict(self,databatch):\n        scores=[]\n        batch_size=self.batch_size\n        minibatch=[]\n        cur=0\n        #\xe6\x89\x80\xe6\x9c\x89\xe6\x95\xb0\xe6\x8d\xae\xe6\x80\xbb\xe6\x95\xb0\n        n=databatch.shape[0]\n        #\xe5\xb0\x86\xe6\x95\xb0\xe6\x8d\xae\xe6\x95\xb4\xe7\x90\x86\xe6\x88\x90\xe5\x9b\xba\xe5\xae\x9abatch\n        while cur<n:\n            minibatch.append(databatch[cur:min(cur+batch_size,n),:,:,:])\n            cur+=batch_size\n        cls_prob_list=[]\n        bbox_pred_list=[]\n        landmark_pred_list=[]\n        for idx,data in enumerate(minibatch):\n            m=data.shape[0]\n            real_size=self.batch_size\n            #\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe7\xbb\x84\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\x8d\xe5\xa4\x9f\xe4\xb8\x80\xe4\xb8\xaabatch\xe7\x9a\x84\xe5\xa4\x84\xe7\x90\x86\n            if m<batch_size:\n                keep_inds=np.arange(m)\n                gap=self.batch_size-m\n                while gap>=len(keep_inds):\n                    gap-=len(keep_inds)\n                    keep_inds=np.concatenate((keep_inds,keep_inds))\n                if gap!=0:\n                    keep_inds=np.concatenate((keep_inds,keep_inds[:gap]))\n                data=data[keep_inds]\n                real_size=m\n            cls_prob,bbox_pred,landmark_pred=self.sess.run([self.cls_prob, self.bbox_pred,self.landmark_pred],\n                                                          feed_dict={self.image_op: data})\n            \n            cls_prob_list.append(cls_prob[:real_size])\n            bbox_pred_list.append(bbox_pred[:real_size])\n            landmark_pred_list.append(landmark_pred[:real_size])\n        \n        return np.concatenate(cls_prob_list, axis=0), np.concatenate(bbox_pred_list, axis=0), np.concatenate(landmark_pred_list, axis=0)\n\n"""
detection/fcn_detector.py,8,"b""\n# coding: utf-8\n\n# In[1]:\n\n\nimport tensorflow as tf\nimport sys\nsys.path.append('../')\nimport train.config as config\n\n\n# In[2]:\n\n\nclass FcnDetector:\n    '''\xe8\xaf\x86\xe5\x88\xab\xe5\x8d\x95\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87'''\n    def __init__(self,net_factory,model_path):\n        graph=tf.Graph()\n        with graph.as_default():\n            self.image_op=tf.placeholder(tf.float32,name='input_image')\n            self.width_op=tf.placeholder(tf.int32,name='image_width')\n            self.height_op=tf.placeholder(tf.int32,name='image_height')\n            image_reshape=tf.reshape(self.image_op,[1,self.height_op,self.width_op,3])\n            #\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\n            self.cls_prob,self.bbox_pred,_=net_factory(image_reshape,training=False)\n            self.sess=tf.Session()\n            #\xe9\x87\x8d\xe8\xbd\xbd\xe6\xa8\xa1\xe5\x9e\x8b\n            saver=tf.train.Saver()\n            model_file=tf.train.latest_checkpoint(model_path)\n            saver.restore(self.sess,model_file)\n    def predict(self,databatch):\n        height,width,_=databatch.shape\n        cls_prob,bbox_pred=self.sess.run([self.cls_prob,self.bbox_pred],\n                                        feed_dict={self.image_op:databatch,\n                                                  self.width_op:width,\n                                                  self.height_op:height})\n        \n        return cls_prob,bbox_pred\n\n        \n\n"""
preprocess/BBox_utils.py,0,"b""\n# coding: utf-8\n\n# In[1]:\n\n\nimport os\nimport cv2\nimport numpy as np\n\n\n# In[2]:\n\n\ndef getDataFromTxt(txt,data_path,with_landmark=True):\n    '''\xe8\x8e\xb7\xe5\x8f\x96txt\xe4\xb8\xad\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xe8\xb7\xaf\xe5\xbe\x84\xef\xbc\x8c\xe4\xba\xba\xe8\x84\xb8box\xef\xbc\x8c\xe4\xba\xba\xe8\x84\xb8\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\n    \xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n      txt\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xaetxt\xe6\x96\x87\xe4\xbb\xb6\n      data_path:\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x98\xe5\x82\xa8\xe7\x9b\xae\xe5\xbd\x95\n      with_landmark:\xe6\x98\xaf\xe5\x90\xa6\xe7\x95\x99\xe6\x9c\x89\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\n    \xe8\xbf\x94\xe5\x9b\x9e\xe5\x80\xbc\xef\xbc\x9a\n      result\xe5\x8c\x85\xe5\x90\xab(\xe5\x9b\xbe\xe5\x83\x8f\xe8\xb7\xaf\xe5\xbe\x84\xef\xbc\x8c\xe4\xba\xba\xe8\x84\xb8box\xef\xbc\x8c\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9)\n    '''\n    with open(txt,'r') as f:\n        lines=f.readlines()\n    result=[]\n    for line in lines:\n        line=line.strip()\n        components=line.split(' ')\n        #\xe8\x8e\xb7\xe5\x8f\x96\xe5\x9b\xbe\xe5\x83\x8f\xe8\xb7\xaf\xe5\xbe\x84\n        img_path=os.path.join(data_path,components[0]).replace('\\\\','/')\n        #\xe4\xba\xba\xe8\x84\xb8box\n        box=(components[1],components[3],components[2],components[4])\n        box=[float(_) for _ in box]\n        box=list(map(int,box))\n        \n        if not with_landmark:\n            result.append((img_path,BBox(box)))\n            continue\n        #\xe4\xba\x94\xe4\xb8\xaa\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9(x,y)\n        landmark=np.zeros((5,2))\n        for index in range(5):\n            rv=(float(components[5+2*index]),float(components[5+2*index+1]))\n            landmark[index]=rv\n        result.append((img_path,BBox(box),landmark))\n    return result\n      \n\n\n# In[4]:\n\n\nclass BBox:\n    #\xe4\xba\xba\xe8\x84\xb8\xe7\x9a\x84box\n    def __init__(self,box):\n        self.left=box[0]\n        self.top=box[1]\n        self.right=box[2]\n        self.bottom=box[3]\n        \n        self.x=box[0]\n        self.y=box[1]\n        self.w=box[2]-box[0]\n        self.h=box[3]-box[1]\n    \n    def project(self,point):\n        '''\xe5\xb0\x86\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\xe7\x9a\x84\xe7\xbb\x9d\xe5\xaf\xb9\xe5\x80\xbc\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba\xe7\x9b\xb8\xe5\xaf\xb9\xe4\xba\x8e\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe5\x9d\x90\xe6\xa0\x87\xe5\x81\x8f\xe7\xa7\xbb\xe5\xb9\xb6\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\n        \xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n          point\xef\xbc\x9a\xe6\x9f\x90\xe4\xb8\x80\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\xe5\x9d\x90\xe6\xa0\x87(x,y)\n        \xe8\xbf\x94\xe5\x9b\x9e\xe5\x80\xbc\xef\xbc\x9a\n          \xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe5\x81\x8f\xe7\xa7\xbb\n        '''\n        x=(point[0]-self.x)/self.w\n        y=(point[1]-self.y)/self.h\n        return np.asarray([x,y])\n    def reproject(self,point):\n        '''\xe5\xb0\x86\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\xe7\x9a\x84\xe7\x9b\xb8\xe5\xaf\xb9\xe5\x80\xbc\xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xba\xe7\xbb\x9d\xe5\xaf\xb9\xe5\x80\xbc\xef\xbc\x8c\xe4\xb8\x8eproject\xe7\x9b\xb8\xe5\x8f\x8d\n        \xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n          point:\xe6\x9f\x90\xe4\xb8\x80\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\xe7\x9a\x84\xe7\x9b\xb8\xe5\xaf\xb9\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x9d\x90\xe6\xa0\x87\n        \xe8\xbf\x94\xe5\x9b\x9e\xe5\x80\xbc\xef\xbc\x9a\n          \xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe7\x9a\x84\xe7\xbb\x9d\xe5\xaf\xb9\xe5\x9d\x90\xe6\xa0\x87\n        '''\n        x=self.x+self.w*point[0]\n        y=self.y+self.h*point[1]\n        return np.asarray([x,y])\n    def reprojectLandmark(self,landmark):\n        '''\xe5\xaf\xb9\xe6\x89\x80\xe6\x9c\x89\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\xe8\xbf\x9b\xe8\xa1\x8creproject\xe6\x93\x8d\xe4\xbd\x9c'''\n        p=np.zeros((len(landmark),2))\n        for i in range(len(landmark)):\n            p[i]=self.reproject(landmark[i])\n        return p\n    def projectLandmark(self,landmark):\n        '''\xe5\xaf\xb9\xe6\x89\x80\xe6\x9c\x89\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\xe8\xbf\x9b\xe8\xa1\x8cproject\xe6\x93\x8d\xe4\xbd\x9c'''\n        p=np.zeros((len(landmark),2))\n        for i in range(len(landmark)):\n            p[i]=self.project(landmark[i])\n        return p\n        \n\n"""
preprocess/__init__.py,0,b'###\n'
preprocess/gen_12net_data.py,0,"b""\n# coding: utf-8\n\n# In[1]:\n\n\n'''\n\xe6\x88\xaa\xe5\x8f\x96pos\xef\xbc\x8cneg,part\xe4\xb8\x89\xe7\xa7\x8d\xe7\xb1\xbb\xe5\x9e\x8b\xe5\x9b\xbe\xe7\x89\x87\xe5\xb9\xb6resize\xe6\x88\x9012x12\xe5\xa4\xa7\xe5\xb0\x8f\xe4\xbd\x9c\xe4\xb8\xbaPNet\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\n'''\nimport os\nimport cv2\nimport numpy as np\nnpr=np.random\nfrom tqdm import  tqdm\nfrom utils import IOU \n\n#face\xe7\x9a\x84id\xe5\xaf\xb9\xe5\xba\x94label\xe7\x9a\x84txt\nanno_file='../data/wider_face_train.txt'\n#\xe5\x9b\xbe\xe7\x89\x87\xe5\x9c\xb0\xe5\x9d\x80\nim_dir='../data/WIDER_train/images'\n#pos\xef\xbc\x8cpart,neg\xe8\xa3\x81\xe5\x89\xaa\xe5\x9b\xbe\xe7\x89\x87\xe6\x94\xbe\xe7\xbd\xae\xe4\xbd\x8d\xe7\xbd\xae\npos_save_dir='../data/12/positive'\npart_save_dir='../data/12/part'\nneg_save_dir='../data/12/negative'\n#PNet\xe6\x95\xb0\xe6\x8d\xae\xe5\x9c\xb0\xe5\x9d\x80\nsave_dir='../data/12'\n\n\n# In[2]:\n\n\nif not os.path.exists(save_dir):\n    os.mkdir(save_dir)\nif not os.path.exists(pos_save_dir):\n    os.mkdir(pos_save_dir)\nif not os.path.exists(part_save_dir):\n    os.mkdir(part_save_dir)\nif not os.path.exists(neg_save_dir):\n    os.mkdir(neg_save_dir)\n    \nf1=open(os.path.join(save_dir,'pos_12.txt'),'w')\nf2=open(os.path.join(save_dir,'neg_12.txt'),'w')\nf3=open(os.path.join(save_dir,'part_12.txt'),'w')\n\nwith open(anno_file,'r') as f:\n    annotations=f.readlines()\nnum=len(annotations)\nprint('\xe6\x80\xbb\xe5\x85\xb1\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xef\xbc\x9a %d' % num)\n#\xe8\xae\xb0\xe5\xbd\x95pos,neg,part\xe4\xb8\x89\xe7\xb1\xbb\xe7\x94\x9f\xe6\x88\x90\xe6\x95\xb0\np_idx=0\nn_idx=0\nd_idx=0\n#\xe8\xae\xb0\xe5\xbd\x95\xe8\xaf\xbb\xe5\x8f\x96\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\nidx=0\nfor annotation in tqdm(annotations):\n    annotation=annotation.strip().split(' ')\n    im_path=annotation[0]\n    box=list(map(float,annotation[1:]))\n    \n    boxes=np.array(box,dtype=np.float32).reshape(-1,4)\n    \n    img=cv2.imread(os.path.join(im_dir,im_path+'.jpg'))\n    idx+=1\n    height,width,channel=img.shape\n    \n    neg_num=0\n    #\xe5\x85\x88\xe9\x87\x87\xe6\xa0\xb7\xe4\xb8\x80\xe5\xae\x9a\xe6\x95\xb0\xe9\x87\x8fneg\xe5\x9b\xbe\xe7\x89\x87\n    while neg_num<50:\n\n        #\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96\xe6\x88\xaa\xe5\x8f\x96\xe5\x9b\xbe\xe5\x83\x8f\xe5\xa4\xa7\xe5\xb0\x8f\n        size=npr.randint(12,min(width,height)/2)\n        #\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96\xe5\xb7\xa6\xe4\xb8\x8a\xe5\x9d\x90\xe6\xa0\x87\n        nx=npr.randint(0,width-size)\n        ny=npr.randint(0,height-size)\n        #\xe6\x88\xaa\xe5\x8f\x96box\n        crop_box=np.array([nx,ny,nx+size,ny+size])\n        #\xe8\xae\xa1\xe7\xae\x97iou\xe5\x80\xbc\n        Iou=IOU(crop_box,boxes)\n        #\xe6\x88\xaa\xe5\x8f\x96\xe5\x9b\xbe\xe7\x89\x87\xe5\xb9\xb6resize\xe6\x88\x9012x12\xe5\xa4\xa7\xe5\xb0\x8f\n        cropped_im=img[ny:ny+size,nx:nx+size,:]\n        resized_im=cv2.resize(cropped_im,(12,12),interpolation=cv2.INTER_LINEAR)\n\n        \n        \n        #iou\xe5\x80\xbc\xe5\xb0\x8f\xe4\xba\x8e0.3\xe5\x88\xa4\xe5\xae\x9a\xe4\xb8\xbaneg\xe5\x9b\xbe\xe5\x83\x8f\n        if np.max(Iou)<0.3:\n            save_file=os.path.join(neg_save_dir,'%s.jpg'%n_idx)\n            f2.write(neg_save_dir+'/%s.jpg'%n_idx+' 0\\n')\n            cv2.imwrite(save_file,resized_im)\n            n_idx+=1\n            neg_num+=1\n    \n    for box in boxes:\n        #\xe5\xb7\xa6\xe4\xb8\x8a\xe5\x8f\xb3\xe4\xb8\x8b\xe5\x9d\x90\xe6\xa0\x87\n        x1,y1,x2,y2=box\n        w=x2-x1+1\n        h=y2-y1+1\n        #\xe8\x88\x8d\xe5\x8e\xbb\xe5\x9b\xbe\xe5\x83\x8f\xe8\xbf\x87\xe5\xb0\x8f\xe5\x92\x8cbox\xe5\x9c\xa8\xe5\x9b\xbe\xe7\x89\x87\xe5\xa4\x96\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\n        if max(w,h)<20 or x1<0 or y1<0:\n            continue\n        for i in range(5):\n            size=npr.randint(12,min(width,height)/2)\n\n                     \n\n            #\xe9\x9a\x8f\xe6\x9c\xba\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe5\x85\xb3\xe4\xba\x8ex1,y1\xe7\x9a\x84\xe5\x81\x8f\xe7\xa7\xbb\xe9\x87\x8f\xef\xbc\x8c\xe5\xb9\xb6\xe4\xb8\x94\xe4\xbf\x9d\xe8\xaf\x81x1+delta_x>0,y1+delta_y>0\n            delta_x=npr.randint(max(-size,-x1),w)\n            delta_y=npr.randint(max(-size,-y1),h)\n            #\xe6\x88\xaa\xe5\x8f\x96\xe5\x90\x8e\xe7\x9a\x84\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\xe5\x9d\x90\xe6\xa0\x87\n            nx1=int(max(0,x1+delta_x))\n            ny1=int(max(0,y1+delta_y))\n            #\xe6\x8e\x92\xe9\x99\xa4\xe5\xa4\xa7\xe4\xba\x8e\xe5\x9b\xbe\xe7\x89\x87\xe5\xb0\xba\xe5\xba\xa6\xe7\x9a\x84\n            if nx1+size>width or ny1+size>height:\n                continue\n            crop_box=np.array([nx1,ny1,nx1+size,ny1+size])\n            Iou=IOU(crop_box,boxes)\n            cropped_im=img[ny1:ny1+size,nx1:nx1+size,:]\n            resized_im=cv2.resize(cropped_im,(12,12),interpolation=cv2.INTER_LINEAR)\n            \n            if np.max(Iou)<0.3:\n                save_file=os.path.join(neg_save_dir,'%s.jpg'%n_idx)\n                f2.write(neg_save_dir+'/%s.jpg'%n_idx+' 0\\n')\n                cv2.imwrite(save_file,resized_im)\n                n_idx+=1\n        for i in range(20):\n            #\xe7\xbc\xa9\xe5\xb0\x8f\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe5\x8f\x96size\xe8\x8c\x83\xe5\x9b\xb4\xef\xbc\x8c\xe6\x9b\xb4\xe5\xa4\x9a\xe6\x88\xaa\xe5\x8f\x96pos\xe5\x92\x8cpart\xe5\x9b\xbe\xe5\x83\x8f\n            size=npr.randint(int(min(w,h)*0.8),np.ceil(1.25*max(w,h)))\n \n            \n\n            #\xe9\x99\xa4\xe5\x8e\xbb\xe5\xb0\xba\xe5\xba\xa6\xe5\xb0\x8f\xe7\x9a\x84\n            if w<5:\n                continue\n            #\xe5\x81\x8f\xe7\xa7\xbb\xe9\x87\x8f\xef\xbc\x8c\xe8\x8c\x83\xe5\x9b\xb4\xe7\xbc\xa9\xe5\xb0\x8f\xe4\xba\x86\n            delta_x=npr.randint(-w*0.2,w*0.2)\n            delta_y=npr.randint(-h*0.2,h*0.2)\n            #\xe6\x88\xaa\xe5\x8f\x96\xe5\x9b\xbe\xe5\x83\x8f\xe5\xb7\xa6\xe4\xb8\x8a\xe5\x9d\x90\xe6\xa0\x87\xe8\xae\xa1\xe7\xae\x97\xe6\x98\xaf\xe5\x85\x88\xe8\xae\xa1\xe7\xae\x97x1+w/2\xe8\xa1\xa8\xe7\xa4\xba\xe7\x9a\x84\xe4\xb8\xad\xe5\xbf\x83\xe5\x9d\x90\xe6\xa0\x87\xef\xbc\x8c\xe5\x86\x8d+delta_x\xe5\x81\x8f\xe7\xa7\xbb\xe9\x87\x8f\xef\xbc\x8c\xe5\x86\x8d-size/2\xef\xbc\x8c\n            #\xe5\x8f\x98\xe6\x88\x90\xe6\x96\xb0\xe7\x9a\x84\xe5\xb7\xa6\xe4\xb8\x8a\xe5\x9d\x90\xe6\xa0\x87\n            nx1=int(max(x1+w/2+delta_x-size/2,0))\n            ny1=int(max(y1+h/2+delta_y-size/2,0))\n            nx2=nx1+size\n            ny2=ny1+size\n            \n            #\xe6\x8e\x92\xe9\x99\xa4\xe8\xb6\x85\xe5\x87\xba\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\n            if nx2>width or ny2>height:\n                continue\n            crop_box=np.array([nx1,ny1,nx2,ny2])\n            #\xe4\xba\xba\xe8\x84\xb8\xe6\xa1\x86\xe7\x9b\xb8\xe5\xaf\xb9\xe4\xba\x8e\xe6\x88\xaa\xe5\x8f\x96\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84\xe5\x81\x8f\xe7\xa7\xbb\xe9\x87\x8f\xe5\xb9\xb6\xe5\x81\x9a\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\xa4\x84\xe7\x90\x86\n            offset_x1=(x1-nx1)/float(size)\n            offset_y1=(y1-ny1)/float(size)\n            offset_x2=(x2-nx2)/float(size)\n            offset_y2=(y2-ny2)/float(size)\n            \n            cropped_im=img[ny1:ny2,nx1:nx2,:]\n            resized_im=cv2.resize(cropped_im,(12,12),interpolation=cv2.INTER_LINEAR)\n            #box\xe6\x89\xa9\xe5\x85\x85\xe4\xb8\x80\xe4\xb8\xaa\xe7\xbb\xb4\xe5\xba\xa6\xe4\xbd\x9c\xe4\xb8\xbaiou\xe8\xbe\x93\xe5\x85\xa5\n            box_=box.reshape(1,-1)\n            iou=IOU(crop_box,box_)\n            if iou>=0.65:\n                save_file=os.path.join(pos_save_dir,'%s.jpg'%p_idx)\n                f1.write(pos_save_dir+'/%s.jpg'%p_idx+' 1 %.2f %.2f %.2f %.2f\\n'%(offset_x1,\n                        offset_y1,offset_x2,offset_y2))\n                cv2.imwrite(save_file,resized_im)\n                p_idx+=1\n            elif iou>=0.4:\n                save_file=os.path.join(part_save_dir,'%s.jpg'%d_idx)\n                f3.write(part_save_dir+'/%s.jpg'%d_idx+' -1 %.2f %.2f %.2f %.2f\\n'%(offset_x1,\n                        offset_y1,offset_x2,offset_y2))\n                cv2.imwrite(save_file,resized_im)\n                d_idx+=1\n   \n   \nprint('%s \xe4\xb8\xaa\xe5\x9b\xbe\xe7\x89\x87\xe5\xb7\xb2\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8cpos\xef\xbc\x9a%s  part: %s neg:%s'%(idx,p_idx,d_idx,n_idx))\nf1.close()\nf2.close()\nf3.close()\n\n"""
preprocess/gen_hard_example.py,0,"b'\n# coding: utf-8\n\n# In[1]:\n\n\nimport sys\nfrom utils import *\nimport numpy as np\nimport argparse\nimport os\nimport pickle\nimport cv2\nfrom tqdm import tqdm\nfrom loader import TestLoader\nsys.path.append(\'../\')\nfrom train.model import P_Net,R_Net,O_Net\nimport train.config as config\nfrom detection.detector import Detector\nfrom detection.fcn_detector import FcnDetector\nfrom detection.MtcnnDetector import MtcnnDetector\n\n\n# In[3]:\n\n\ndef main(args):\n    \'\'\'\xe9\x80\x9a\xe8\xbf\x87PNet\xe6\x88\x96RNet\xe7\x94\x9f\xe6\x88\x90\xe4\xb8\x8b\xe4\xb8\x80\xe4\xb8\xaa\xe7\xbd\x91\xe7\xbb\x9c\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\'\'\'\n    size=args.input_size\n    batch_size=config.batches\n    min_face_size=config.min_face\n    stride=config.stride\n    thresh=config.thresh\n    #\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x9c\xb0\xe5\x9d\x80\n    model_path=[\'../model/PNet/\',\'../model/RNet/\',\'../model/ONet\']\n    if size==12:\n        net=\'PNet\'\n        save_size=24\n    elif size==24:\n        net=\'RNet\'\n        save_size=48\n    #\xe5\x9b\xbe\xe7\x89\x87\xe6\x95\xb0\xe6\x8d\xae\xe5\x9c\xb0\xe5\x9d\x80\n    base_dir=\'../data/WIDER_train/\'\n    #\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe5\xad\x98\xe6\x94\xbe\xe5\x9c\xb0\xe5\x9d\x80\n    data_dir=\'../data/%d\'%(save_size)\n    neg_dir=os.path.join(data_dir,\'negative\')\n    pos_dir=os.path.join(data_dir,\'positive\')\n    part_dir=os.path.join(data_dir,\'part\')\n    for dir_path in [neg_dir,pos_dir,part_dir]:\n        if not os.path.exists(dir_path):\n            os.makedirs(dir_path)\n    detectors=[None,None,None]\n    PNet=FcnDetector(P_Net,model_path[0])\n    detectors[0]=PNet\n    if net==\'RNet\':\n        RNet=Detector(R_Net,24,batch_size[1],model_path[1])\n        detectors[1]=RNet\n    basedir=\'../data/\'\n    filename=\'../data/wider_face_train_bbx_gt.txt\'\n    #\xe8\xaf\xbb\xe5\x8f\x96\xe6\x96\x87\xe4\xbb\xb6\xe7\x9a\x84image\xe5\x92\x8cbox\xe5\xaf\xb9\xe5\xba\x94\xe5\x87\xbd\xe6\x95\xb0\xe5\x9c\xa8utils\xe4\xb8\xad\n    data=read_annotation(base_dir,filename)\n    mtcnn_detector=MtcnnDetector(detectors,min_face_size=min_face_size,\n                                stride=stride,threshold=thresh)\n    save_path=data_dir\n    save_file=os.path.join(save_path,\'detections.pkl\')\n    if not os.path.exists(save_file):\n        #\xe5\xb0\x86data\xe5\x88\xb6\xe4\xbd\x9c\xe6\x88\x90\xe8\xbf\xad\xe4\xbb\xa3\xe5\x99\xa8\n        print(\'\xe8\xbd\xbd\xe5\x85\xa5\xe6\x95\xb0\xe6\x8d\xae\')\n        test_data=TestLoader(data[\'images\'])\n        detectors,_=mtcnn_detector.detect_face(test_data)\n        print(\'\xe5\xae\x8c\xe6\x88\x90\xe8\xaf\x86\xe5\x88\xab\')\n\n        with open(save_file,\'wb\') as f:\n            pickle.dump(detectors,f,1)\n    print(\'\xe5\xbc\x80\xe5\xa7\x8b\xe7\x94\x9f\xe6\x88\x90\xe5\x9b\xbe\xe5\x83\x8f\')\n    save_hard_example(save_size,data,neg_dir,pos_dir,part_dir,save_path)\n\n\n# In[2]:\n\n\ndef save_hard_example(save_size, data,neg_dir,pos_dir,part_dir,save_path):\n    \'\'\'\xe5\xb0\x86\xe7\xbd\x91\xe7\xbb\x9c\xe8\xaf\x86\xe5\x88\xab\xe7\x9a\x84box\xe7\x94\xa8\xe6\x9d\xa5\xe8\xa3\x81\xe5\x89\xaa\xe5\x8e\x9f\xe5\x9b\xbe\xe5\x83\x8f\xe4\xbd\x9c\xe4\xb8\xba\xe4\xb8\x8b\xe4\xb8\x80\xe4\xb8\xaa\xe7\xbd\x91\xe7\xbb\x9c\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\'\'\'\n\n    im_idx_list = data[\'images\']\n    \n    gt_boxes_list = data[\'bboxes\']\n    num_of_images = len(im_idx_list)\n\n\n    \n    # save files\n    neg_label_file = ""../data/%d/neg_%d.txt"" % (save_size, save_size)\n    neg_file = open(neg_label_file, \'w\')\n\n    pos_label_file = ""../data/%d/pos_%d.txt"" % (save_size, save_size)\n    pos_file = open(pos_label_file, \'w\')\n\n    part_label_file = ""../data/%d/part_%d.txt"" % (save_size, save_size)\n    part_file = open(part_label_file, \'w\')\n    #read detect result\n    det_boxes = pickle.load(open(os.path.join(save_path, \'detections.pkl\'), \'rb\'))\n    # print(len(det_boxes), num_of_images)\n   \n    assert len(det_boxes) == num_of_images, ""\xe5\xbc\x84\xe9\x94\x99\xe4\xba\x86""\n\n    \n    n_idx = 0\n    p_idx = 0\n    d_idx = 0\n    image_done = 0\n    \n    for im_idx, dets, gts in tqdm(zip(im_idx_list, det_boxes, gt_boxes_list)):\n        gts = np.array(gts, dtype=np.float32).reshape(-1, 4)\n        image_done += 1\n\n        if dets.shape[0] == 0:\n            continue\n        img = cv2.imread(im_idx)\n        #\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90\xe6\xad\xa3\xe6\x96\xb9\xe5\xbd\xa2\n        dets = convert_to_square(dets)\n        dets[:, 0:4] = np.round(dets[:, 0:4])\n        neg_num = 0\n        for box in dets:\n            x_left, y_top, x_right, y_bottom, _ = box.astype(int)\n            width = x_right - x_left + 1\n            height = y_bottom - y_top + 1\n\n            # \xe9\x99\xa4\xe5\x8e\xbb\xe8\xbf\x87\xe5\xb0\x8f\xe7\x9a\x84\n            if width < 20 or x_left < 0 or y_top < 0 or x_right > img.shape[1] - 1 or y_bottom > img.shape[0] - 1:\n                continue\n\n           \n            Iou = IOU(box, gts)\n            cropped_im = img[y_top:y_bottom + 1, x_left:x_right + 1, :]\n            resized_im = cv2.resize(cropped_im, (save_size, save_size),\n                                    interpolation=cv2.INTER_LINEAR)\n\n            #\xe5\x88\x92\xe5\x88\x86\xe7\xa7\x8d\xe7\xb1\xbb           \n            if np.max(Iou) < 0.3 and neg_num < 60:\n                \n                save_file = os.path.join(neg_dir, ""%s.jpg"" % n_idx)\n                \n                neg_file.write(save_file + \' 0\\n\')\n                cv2.imwrite(save_file, resized_im)\n                n_idx += 1\n                neg_num += 1\n            else:\n               \n                idx = np.argmax(Iou)\n                assigned_gt = gts[idx]\n                x1, y1, x2, y2 = assigned_gt\n\n                #\xe5\x81\x8f\xe7\xa7\xbb\xe9\x87\x8f\n                offset_x1 = (x1 - x_left) / float(width)\n                offset_y1 = (y1 - y_top) / float(height)\n                offset_x2 = (x2 - x_right) / float(width)\n                offset_y2 = (y2 - y_bottom) / float(height)\n\n                # pos\xe5\x92\x8cpart\n                if np.max(Iou) >= 0.65:\n                    save_file = os.path.join(pos_dir, ""%s.jpg"" % p_idx)\n                    pos_file.write(save_file + \' 1 %.2f %.2f %.2f %.2f\\n\' % (\n                        offset_x1, offset_y1, offset_x2, offset_y2))\n                    cv2.imwrite(save_file, resized_im)\n                    p_idx += 1\n\n                elif np.max(Iou) >= 0.4:\n                    save_file = os.path.join(part_dir, ""%s.jpg"" % d_idx)\n                    part_file.write(save_file + \' -1 %.2f %.2f %.2f %.2f\\n\' % (\n                        offset_x1, offset_y1, offset_x2, offset_y2))\n                    cv2.imwrite(save_file, resized_im)\n                    d_idx += 1\n    neg_file.close()\n    part_file.close()\n    pos_file.close()\n\n\n# In[4]:\n\n\ndef parse_arguments(argv):\n\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'input_size\', type=int,\n                        help=\'The input size for specific net\')\n    \n    return parser.parse_args(argv)\n\n\nif __name__ == \'__main__\':\n    main(parse_arguments(sys.argv[1:]))\n\n'"
preprocess/gen_imglist_pnet.py,0,"b""\n# coding: utf-8\n\n# In[1]:\n\n\nimport numpy as np\nnpr=np.random\nimport os\ndata_dir='../data/'\n\n\n# In[2]:\n\n\n'''\xe5\xb0\x86pos,part,neg,landmark\xe5\x9b\x9b\xe8\x80\x85\xe6\xb7\xb7\xe5\x9c\xa8\xe4\xb8\x80\xe8\xb5\xb7'''\nsize=12\nwith open(os.path.join(data_dir,'12/pos_12.txt'),'r') as f:\n    pos=f.readlines()\nwith open(os.path.join(data_dir,'12/neg_12.txt'),'r') as f:\n    neg=f.readlines()\nwith open(os.path.join(data_dir,'12/part_12.txt'),'r') as f:\n    part=f.readlines()\nwith open(os.path.join(data_dir,'12/landmark_12_aug.txt'),'r') as f:\n    landmark=f.readlines()\ndir_path=os.path.join(data_dir,'12')\nif not os.path.exists(dir_path):\n    os.makedirs(dir_path)\nwith open(os.path.join(dir_path,'train_pnet_landmark.txt'),'w') as f:\n    nums=[len(neg),len(pos),len(part)]\n    base_num=250000\n    print('neg\xe6\x95\xb0\xe9\x87\x8f\xef\xbc\x9a{} pos\xe6\x95\xb0\xe9\x87\x8f\xef\xbc\x9a{} part\xe6\x95\xb0\xe9\x87\x8f:{} \xe5\x9f\xba\xe6\x95\xb0:{}'.format(len(neg),len(pos),len(part),base_num))\n    if len(neg)>base_num*3:\n        neg_keep=npr.choice(len(neg),size=base_num*3,replace=True)\n    else:\n        neg_keep=npr.choice(len(neg),size=len(neg),replace=True)\n    sum_p=len(neg_keep)//3\n    pos_keep=npr.choice(len(pos),sum_p,replace=True)\n    part_keep=npr.choice(len(part),sum_p,replace=True)\n    print('neg\xe6\x95\xb0\xe9\x87\x8f\xef\xbc\x9a{} pos\xe6\x95\xb0\xe9\x87\x8f\xef\xbc\x9a{} part\xe6\x95\xb0\xe9\x87\x8f:{}'.format(len(neg_keep),len(pos_keep),len(part_keep)))\n    for i in pos_keep:\n        f.write(pos[i])\n    for i in neg_keep:\n        f.write(neg[i])\n    for i in part_keep:\n        f.write(part[i])\n    for item in landmark:\n        f.write(item) \n\n"""
preprocess/gen_landmark_aug.py,0,"b""\n# coding: utf-8\n\n# In[6]:\n\n\nimport os\nimport random\nimport sys\nimport cv2\nimport numpy as np\nnpr=np.random\nimport argparse\nfrom tqdm import tqdm\nfrom utils import IOU\nfrom BBox_utils import getDataFromTxt,BBox\ndata_dir='../data'\n\n\n# In[3]:\n\n\ndef main(args):\n    '''\xe7\x94\xa8\xe4\xba\x8e\xe5\xa4\x84\xe7\x90\x86\xe5\xb8\xa6\xe6\x9c\x89landmark\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae'''\n    size=args.input_size\n    #\xe6\x98\xaf\xe5\x90\xa6\xe5\xaf\xb9\xe5\x9b\xbe\xe5\x83\x8f\xe5\x8f\x98\xe6\x8d\xa2\n    argument=True\n    if size==12:\n        net='PNet'\n    elif size==24:\n        net='RNet'\n    elif size==48:\n        net='ONet'\n    image_id=0\n    #\xe6\x95\xb0\xe6\x8d\xae\xe8\xbe\x93\xe5\x87\xba\xe8\xb7\xaf\xe5\xbe\x84\n    OUTPUT=os.path.join(data_dir,str(size))\n    if not os.path.exists(OUTPUT):\n        os.mkdir(OUTPUT)\n    #\xe5\x9b\xbe\xe7\x89\x87\xe5\xa4\x84\xe7\x90\x86\xe5\x90\x8e\xe8\xbe\x93\xe5\x87\xba\xe8\xb7\xaf\xe5\xbe\x84\n    dstdir = os.path.join(OUTPUT,'train_%s_landmark_aug'%(net))\n    if not os.path.exists(dstdir):\n        os.mkdir(dstdir)\n    #label\xe8\xae\xb0\xe5\xbd\x95txt\n    ftxt=os.path.join(data_dir,'trainImageList.txt')\n    #\xe8\xae\xb0\xe5\xbd\x95label\xe7\x9a\x84txt\n    f=open(os.path.join(OUTPUT,'landmark_%d_aug.txt'%(size)),'w')\n    #\xe8\x8e\xb7\xe5\x8f\x96\xe5\x9b\xbe\xe5\x83\x8f\xe8\xb7\xaf\xe5\xbe\x84\xef\xbc\x8cbox\xef\xbc\x8c\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\n    data=getDataFromTxt(ftxt,data_dir)\n    idx=0\n    for (imgPath,box,landmarkGt) in tqdm(data):\n        #\xe5\xad\x98\xe5\x82\xa8\xe4\xba\xba\xe8\x84\xb8\xe5\x9b\xbe\xe7\x89\x87\xe5\x92\x8c\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\n        F_imgs=[]\n        F_landmarks=[]\n        img=cv2.imread(imgPath)\n        \n        img_h,img_w,img_c=img.shape\n        gt_box=np.array([box.left,box.top,box.right,box.bottom])\n        #\xe4\xba\xba\xe8\x84\xb8\xe5\x9b\xbe\xe7\x89\x87\n        f_face=img[box.top:box.bottom+1,box.left:box.right+1]\n        #resize\xe6\x88\x90\xe7\xbd\x91\xe7\xbb\x9c\xe8\xbe\x93\xe5\x85\xa5\xe5\xa4\xa7\xe5\xb0\x8f\n        f_face=cv2.resize(f_face,(size,size))\n        \n        landmark=np.zeros((5,2))\n        for index ,one in enumerate(landmarkGt):\n            #\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\xe7\x9b\xb8\xe5\xaf\xb9\xe4\xba\x8e\xe5\xb7\xa6\xe4\xb8\x8a\xe5\x9d\x90\xe6\xa0\x87\xe5\x81\x8f\xe7\xa7\xbb\xe9\x87\x8f\xe5\xb9\xb6\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\n            rv=((one[0]-gt_box[0])/(gt_box[2]-gt_box[0]),(one[1]-gt_box[1])/(gt_box[3]-gt_box[1]))\n            landmark[index]=rv\n        F_imgs.append(f_face)\n        F_landmarks.append(landmark.reshape(10))\n        landmark=np.zeros((5,2))\n        if argument:\n            #\xe5\xaf\xb9\xe5\x9b\xbe\xe5\x83\x8f\xe5\x8f\x98\xe6\x8d\xa2\n            idx=idx+1\n            x1,y1,x2,y2=gt_box\n            gt_w=x2-x1+1\n            gt_h=y2-y1+1\n            #\xe9\x99\xa4\xe5\x8e\xbb\xe8\xbf\x87\xe5\xb0\x8f\xe5\x9b\xbe\xe5\x83\x8f\n            if max(gt_w,gt_h)<40 or x1<0 or y1<0:\n                continue\n            for i in range(10):\n                #\xe9\x9a\x8f\xe6\x9c\xba\xe8\xa3\x81\xe5\x89\xaa\xe5\x9b\xbe\xe5\x83\x8f\xe5\xa4\xa7\xe5\xb0\x8f\n                box_size=npr.randint(int(min(gt_w,gt_h)*0.8),np.ceil(1.25*max(gt_w,gt_h)))\n                #\xe9\x9a\x8f\xe6\x9c\xba\xe5\xb7\xa6\xe4\xb8\x8a\xe5\x9d\x90\xe6\xa0\x87\xe5\x81\x8f\xe7\xa7\xbb\xe9\x87\x8f\n                delta_x=npr.randint(-gt_w*0.2,gt_w*0.2)\n                delta_y=npr.randint(-gt_h*0.2,gt_h*0.2)\n                #\xe8\xae\xa1\xe7\xae\x97\xe5\xb7\xa6\xe4\xb8\x8a\xe5\x9d\x90\xe6\xa0\x87\n                nx1=int(max(x1+gt_w/2-box_size/2+delta_x,0))\n                ny1=int(max(y1+gt_h/2-box_size/2+delta_y,0))\n                nx2=nx1+box_size\n                ny2=ny1+box_size\n                #\xe9\x99\xa4\xe5\x8e\xbb\xe8\xb6\x85\xe8\xbf\x87\xe8\xbe\xb9\xe7\x95\x8c\xe7\x9a\x84\n                if nx2>img_w or ny2>img_h:\n                    continue\n                #\xe8\xa3\x81\xe5\x89\xaa\xe8\xbe\xb9\xe6\xa1\x86\xef\xbc\x8c\xe5\x9b\xbe\xe7\x89\x87\n                crop_box=np.array([nx1,ny1,nx2,ny2])\n                cropped_im=img[ny1:ny2+1,nx1:nx2+1,:]\n                resized_im=cv2.resize(cropped_im,(size,size))\n                iou=IOU(crop_box,np.expand_dims(gt_box,0))\n                #\xe5\x8f\xaa\xe4\xbf\x9d\xe7\x95\x99pos\xe5\x9b\xbe\xe5\x83\x8f\n                if iou>0.65:\n                    F_imgs.append(resized_im)\n                    #\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\xe7\x9b\xb8\xe5\xaf\xb9\xe5\x81\x8f\xe7\xa7\xbb\n                    for index,one in enumerate(landmarkGt):\n                        rv=((one[0]-nx1)/box_size,(one[1]-ny1)/box_size)\n                        landmark[index]=rv\n                    F_landmarks.append(landmark.reshape(10))\n                    landmark=np.zeros((5,2))\n                    landmark_=F_landmarks[-1].reshape(-1,2)\n                    box=BBox([nx1,ny1,nx2,ny2])\n                    #\xe9\x95\x9c\xe5\x83\x8f\n                    if random.choice([0,1])>0:\n                        face_flipped,landmark_flipped=flip(resized_im,landmark_)\n                        face_flipped=cv2.resize(face_flipped,(size,size))\n                        F_imgs.append(face_flipped)\n                        F_landmarks.append(landmark_flipped.reshape(10))\n                    #\xe9\x80\x86\xe6\x97\xb6\xe9\x92\x88\xe7\xbf\xbb\xe8\xbd\xac\n                    if random.choice([0,1])>0:\n                        face_rotated_by_alpha,landmark_rorated=rotate(img,box,                                    box.reprojectLandmark(landmark_),5)\n                        #\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\xe5\x81\x8f\xe7\xa7\xbb\n                        landmark_rorated=box.projectLandmark(landmark_rorated)\n                        face_rotated_by_alpha=cv2.resize(face_rotated_by_alpha,(size,size))\n                        F_imgs.append(face_rotated_by_alpha)\n                        F_landmarks.append(landmark_rorated.reshape(10))\n                        \n                        #\xe5\xb7\xa6\xe5\x8f\xb3\xe7\xbf\xbb\xe8\xbd\xac\n                        face_flipped,landmark_flipped=flip(face_rotated_by_alpha,landmark_rorated)\n                        face_flipped=cv2.resize(face_flipped,(size,size))\n                        F_imgs.append(face_flipped)\n                        F_landmarks.append(landmark_flipped.reshape(10))\n                    #\xe9\xa1\xba\xe6\x97\xb6\xe9\x92\x88\xe7\xbf\xbb\xe8\xbd\xac\n                    if random.choice([0,1])>0:\n                        face_rotated_by_alpha,landmark_rorated=rotate(img,box,                                    box.reprojectLandmark(landmark_),-5)\n                        #\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\xe5\x81\x8f\xe7\xa7\xbb\n                        landmark_rorated=box.projectLandmark(landmark_rorated)\n                        face_rotated_by_alpha=cv2.resize(face_rotated_by_alpha,(size,size))\n                        F_imgs.append(face_rotated_by_alpha)\n                        F_landmarks.append(landmark_rorated.reshape(10))\n                        \n                        #\xe5\xb7\xa6\xe5\x8f\xb3\xe7\xbf\xbb\xe8\xbd\xac\n                        face_flipped,landmark_flipped=flip(face_rotated_by_alpha,landmark_rorated)\n                        face_flipped=cv2.resize(face_flipped,(size,size))\n                        F_imgs.append(face_flipped)\n                        F_landmarks.append(landmark_flipped.reshape(10))\n        F_imgs, F_landmarks = np.asarray(F_imgs), np.asarray(F_landmarks)\n        for i in range(len(F_imgs)):\n            #\xe5\x89\x94\xe9\x99\xa4\xe6\x95\xb0\xe6\x8d\xae\xe5\x81\x8f\xe7\xa7\xbb\xe9\x87\x8f\xe5\x9c\xa8[0,1]\xe4\xb9\x8b\xe9\x97\xb4\n            if np.sum(np.where(F_landmarks[i]<=0,1,0))>0:\n                continue\n            if np.sum(np.where(F_landmarks[i]>=1,1,0))>0:\n                continue\n            cv2.imwrite(os.path.join(dstdir,'%d.jpg'%(image_id)),F_imgs[i])\n            landmarks=list(map(str,list(F_landmarks[i])))\n            f.write(os.path.join(dstdir,'%d.jpg'%(image_id))+' -2 '+' '.join(landmarks)+'\\n')\n            image_id+=1\n    f.close()\n    return F_imgs,F_landmarks\n\n\n# In[4]:\n\n\ndef flip(face,landmark):\n    #\xe9\x95\x9c\xe5\x83\x8f\n    face_flipped_by_x=cv2.flip(face,1)\n    landmark_=np.asarray([(1-x,y) for (x,y) in landmark])\n    landmark_[[0,1]]=landmark_[[1,0]]\n    landmark_[[3,4]]=landmark_[[4,3]]\n    return (face_flipped_by_x,landmark_)\n    \n\n\n# In[5]:\n\n\ndef rotate(img,box,landmark,alpha):\n    #\xe6\x97\x8b\xe8\xbd\xac\n    center=((box.left+box.right)/2,(box.top+box.bottom)/2)\n    rot_mat=cv2.getRotationMatrix2D(center,alpha,1)\n    img_rotated_by_alpha=cv2.warpAffine(img,rot_mat,(img.shape[1],img.shape[0]))\n    landmark_=np.asarray([(rot_mat[0][0]*x+rot_mat[0][1]*y+rot_mat[0][2],\n                         rot_mat[1][0]*x+rot_mat[1][1]*y+rot_mat[1][2]) for (x,y) in landmark ])\n    face=img_rotated_by_alpha[box.top:box.bottom+1,box.left:box.right+1]\n    return (face,landmark_)\n\n\n# In[ ]:\n\n\ndef parse_arguments(argv):\n\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument('input_size', type=int,\n                        help='The input size for specific net')\n    \n    return parser.parse_args(argv)\n\n\nif __name__ == '__main__':\n    main(parse_arguments(sys.argv[1:]))\n\n"""
preprocess/gen_tfrecords.py,6,"b""\n# coding: utf-8\n\n# In[7]:\n\n\nimport os\nimport random\nimport sys\nimport time\nimport tensorflow as tf\nimport cv2\nfrom tqdm import tqdm\nimport argparse\n\n\n# In[ ]:\n\n\ndef main(args):\n    '''\xe7\x94\x9f\xe6\x88\x90tfrecords\xe6\x96\x87\xe4\xbb\xb6'''\n    size=args.input_size\n    #\xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x98\xe6\x94\xbe\xe5\x9c\xb0\xe5\x9d\x80\n    dataset_dir='../data/'\n    #tfrecord\xe5\xad\x98\xe6\x94\xbe\xe5\x9c\xb0\xe5\x9d\x80\n    output_dir=os.path.join(dataset_dir,str(size)+'/tfrecord')\n    if not os.path.exists(output_dir):\n        os.mkdir(output_dir)\n    #pnet\xe5\x8f\xaa\xe7\x94\x9f\xe6\x88\x90\xe4\xb8\x80\xe4\xb8\xaa\xe6\xb7\xb7\xe5\x90\x88\xe7\x9a\x84tfrecords\xef\xbc\x8crnet\xe5\x92\x8conet\xe8\xa6\x81\xe5\x88\x86\xe5\x88\xab\xe7\x94\x9f\xe6\x88\x904\xe4\xb8\xaa\n    if size==12:\n        net='PNet'\n        tf_filenames=[os.path.join(output_dir,'train_%s_landmark.tfrecord'%(net))]\n        items=['12/train_pnet_landmark.txt']\n    elif size==24:\n        net='RNet'\n        tf_filename1=os.path.join(output_dir,'pos_landmark.tfrecord')\n        item1='%d/pos_%d.txt'%(size,size)\n        tf_filename2=os.path.join(output_dir,'part_landmark.tfrecord')\n        item2='%d/part_%d.txt'%(size,size)\n        tf_filename3=os.path.join(output_dir,'neg_landmark.tfrecord')\n        item3='%d/neg_%d.txt'%(size,size)\n        tf_filename4=os.path.join(output_dir,'landmark_landmark.tfrecord')\n        item4='%d/landmark_%d_aug.txt'%(size,size)\n        tf_filenames=[tf_filename1,tf_filename2,tf_filename3,tf_filename4]\n        items=[item1,item2,item3,item4]\n    elif size==48:\n        net='ONet'\n        tf_filename1=os.path.join(output_dir,'pos_landmark.tfrecord')\n        item1='%d/pos_%d.txt'%(size,size)\n        tf_filename2=os.path.join(output_dir,'part_landmark.tfrecord')\n        item2='%d/part_%d.txt'%(size,size)\n        tf_filename3=os.path.join(output_dir,'neg_landmark.tfrecord')\n        item3='%d/neg_%d.txt'%(size,size)\n        tf_filename4=os.path.join(output_dir,'landmark_landmark.tfrecord')\n        item4='%d/landmark_%d_aug.txt'%(size,size)\n        tf_filenames=[tf_filename1,tf_filename2,tf_filename3,tf_filename4]\n        items=[item1,item2,item3,item4]\n    \n    if tf.gfile.Exists(tf_filenames[0]):\n        print('tfrecords\xe6\x96\x87\xe4\xbb\xb6\xe6\x97\xa9\xe5\xb7\xb2\xe7\x94\x9f\xe6\x88\x90\xef\xbc\x8c\xe6\x97\xa0\xe9\x9c\x80\xe6\xad\xa4\xe6\x93\x8d\xe4\xbd\x9c')\n        return\n    #\xe8\x8e\xb7\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\n    for tf_filename,item in zip(tf_filenames,items):\n        print('\xe5\xbc\x80\xe5\xa7\x8b\xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae')\n        dataset=get_dataset(dataset_dir,item)\n        tf_filename=tf_filename+'_shuffle'\n        random.shuffle(dataset)\n        print('\xe5\xbc\x80\xe5\xa7\x8b\xe8\xbd\xac\xe6\x8d\xa2tfrecords')\n        with tf.python_io.TFRecordWriter(tf_filename) as tfrecord_writer:\n            for image_example in tqdm(dataset):\n                filename=image_example['filename']\n                try:\n                    _add_to_tfrecord(filename,image_example,tfrecord_writer)\n                except:\n                    print(filename)\n    print('\xe5\xae\x8c\xe6\x88\x90\xe8\xbd\xac\xe6\x8d\xa2')\n                    \n    \n\n\n# In[2]:\n\n\ndef get_dataset(dir,item):\n    '''\xe4\xbb\x8etxt\xe8\x8e\xb7\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\n    \xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n      dir\xef\xbc\x9a\xe5\xad\x98\xe6\x94\xbe\xe6\x95\xb0\xe6\x8d\xae\xe7\x9b\xae\xe5\xbd\x95\n      item:txt\xe7\x9b\xae\xe5\xbd\x95\n    \xe8\xbf\x94\xe5\x9b\x9e\xe5\x80\xbc\xef\xbc\x9a\n      \xe5\x8c\x85\xe5\x90\xablabel,box\xef\xbc\x8c\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\xe7\x9a\x84data\n    '''\n    dataset_dir=os.path.join(dir,item)\n    imagelist=open(dataset_dir,'r')\n    dataset=[]\n    for line in tqdm(imagelist.readlines()):\n        info=line.strip().split(' ')\n        data_example=dict()\n        bbox=dict()\n        data_example['filename']=info[0]\n        data_example['label']=int(info[1])\n        #neg\xe7\x9a\x84box\xe9\xbb\x98\xe8\xae\xa4\xe4\xb8\xba0,part,pos\xe7\x9a\x84box\xe5\x8f\xaa\xe5\x8c\x85\xe5\x90\xab\xe4\xba\xba\xe8\x84\xb8\xe6\xa1\x86\xef\xbc\x8clandmark\xe7\x9a\x84box\xe5\x8f\xaa\xe5\x8c\x85\xe5\x90\xab\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\n        bbox['xmin'] = 0\n        bbox['ymin'] = 0\n        bbox['xmax'] = 0\n        bbox['ymax'] = 0\n        bbox['xlefteye'] = 0\n        bbox['ylefteye'] = 0\n        bbox['xrighteye'] = 0\n        bbox['yrighteye'] = 0\n        bbox['xnose'] = 0\n        bbox['ynose'] = 0\n        bbox['xleftmouth'] = 0\n        bbox['yleftmouth'] = 0\n        bbox['xrightmouth'] = 0\n        bbox['yrightmouth'] = 0        \n        if len(info) == 6:\n            bbox['xmin'] = float(info[2])\n            bbox['ymin'] = float(info[3])\n            bbox['xmax'] = float(info[4])\n            bbox['ymax'] = float(info[5])\n        if len(info) == 12:\n            bbox['xlefteye'] = float(info[2])\n            bbox['ylefteye'] = float(info[3])\n            bbox['xrighteye'] = float(info[4])\n            bbox['yrighteye'] = float(info[5])\n            bbox['xnose'] = float(info[6])\n            bbox['ynose'] = float(info[7])\n            bbox['xleftmouth'] = float(info[8])\n            bbox['yleftmouth'] = float(info[9])\n            bbox['xrightmouth'] = float(info[10])\n            bbox['yrightmouth'] = float(info[11])\n        data_example['bbox']=bbox\n        dataset.append(data_example)\n    return dataset\n\n\n# In[5]:\n\n\ndef _add_to_tfrecord(filename, image_example, tfrecord_writer):\n    '''\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90tfrecord\xe6\x96\x87\xe4\xbb\xb6\n    \xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n      filename\xef\xbc\x9a\xe5\x9b\xbe\xe7\x89\x87\xe6\x96\x87\xe4\xbb\xb6\xe5\x90\x8d\n      image_example:\xe6\x95\xb0\xe6\x8d\xae\n      tfrecord_writer:\xe5\x86\x99\xe5\x85\xa5\xe6\x96\x87\xe4\xbb\xb6\n    '''\n    image_data, height, width = _process_image_withoutcoder(filename)\n    example = _convert_to_example_simple(image_example, image_data)\n    tfrecord_writer.write(example.SerializeToString())\n\n\n# In[3]:\n\n\ndef _process_image_withoutcoder(filename):\n    '''\xe8\xaf\xbb\xe5\x8f\x96\xe5\x9b\xbe\xe7\x89\x87\xe6\x96\x87\xe4\xbb\xb6,\xe8\xbf\x94\xe5\x9b\x9e\xe5\x9b\xbe\xe7\x89\x87\xe5\xa4\xa7\xe5\xb0\x8f'''\n    image=cv2.imread(filename)\n    image_data=image.tostring()\n    assert len(image.shape)==3\n    height=image.shape[0]\n    width=image.shape[1]\n    assert image.shape[2]==3\n    return image_data,height,width\n\n\n# In[4]:\n\n\n#\xe4\xb8\x8d\xe5\x90\x8c\xe7\xb1\xbb\xe5\x9e\x8b\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe8\xbd\xac\xe6\x8d\xa2\ndef _int64_feature(value):\n    if not isinstance(value, list):\n        value = [value]\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\n\ndef _float_feature(value):\n    if not isinstance(value, list):\n        value = [value]\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef _bytes_feature(value):\n    if not isinstance(value, list):\n        value = [value]\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n\n\n\n# In[ ]:\n\n\ndef _convert_to_example_simple(image_example, image_buffer):\n    '''\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90tfrecord\xe6\x8e\xa5\xe5\x8f\x97\xe5\xbd\xa2\xe5\xbc\x8f'''\n    class_label = image_example['label']\n    bbox = image_example['bbox']\n    roi = [bbox['xmin'],bbox['ymin'],bbox['xmax'],bbox['ymax']]\n    landmark = [bbox['xlefteye'],bbox['ylefteye'],bbox['xrighteye'],bbox['yrighteye'],bbox['xnose'],bbox['ynose'],\n                bbox['xleftmouth'],bbox['yleftmouth'],bbox['xrightmouth'],bbox['yrightmouth']]\n                \n      \n    example = tf.train.Example(features=tf.train.Features(feature={\n        'image/encoded': _bytes_feature(image_buffer),\n        'image/label': _int64_feature(class_label),\n        'image/roi': _float_feature(roi),\n        'image/landmark': _float_feature(landmark)\n    }))\n    return example\n\n\n# In[ ]:\n\n\ndef parse_arguments(argv):\n\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument('input_size', type=int,\n                        help='The input size for specific net')\n    \n    return parser.parse_args(argv)\n\n\nif __name__ == '__main__':\n    main(parse_arguments(sys.argv[1:]))\n\n"""
preprocess/loader.py,0,"b'\n# coding: utf-8\n\n# In[ ]:\n\n\nimport numpy as np\nimport sys\nimport cv2\n\n\nclass TestLoader:\n    #\xe5\x88\xb6\xe4\xbd\x9c\xe8\xbf\xad\xe4\xbb\xa3\xe5\x99\xa8\n    def __init__(self, imdb, batch_size=1, shuffle=False):\n        self.imdb = imdb\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.size = len(imdb)\n       \n        \n        self.cur = 0\n        self.data = None\n        self.label = None\n\n        self.reset()\n        self.get_batch()\n\n    def reset(self):\n        self.cur = 0\n        if self.shuffle:\n            \n            np.random.shuffle(self.imdb)\n\n    def iter_next(self):\n        return self.cur + self.batch_size <= self.size\n\n    def __iter__(self):\n        return self\n    \n    def __next__(self):\n        return self.next()\n\n    def next(self):\n        if self.iter_next():\n            self.get_batch()\n            self.cur += self.batch_size\n            return self.data\n        else:\n            raise StopIteration\n\n    def getindex(self):\n        return self.cur / self.batch_size\n\n    def getpad(self):\n        if self.cur + self.batch_size > self.size:\n            return self.cur + self.batch_size - self.size\n        else:\n            return 0\n\n    def get_batch(self):\n        imdb = self.imdb[self.cur]\n        im = cv2.imread(imdb)\n        self.data = im\n\n'"
preprocess/utils.py,0,"b""\n# coding: utf-8\n\n# In[1]:\n\n\nimport numpy as np\n\n\n# In[2]:\n\n\ndef IOU(box,boxes):\n    '''\xe8\xa3\x81\xe5\x89\xaa\xe7\x9a\x84box\xe5\x92\x8c\xe5\x9b\xbe\xe7\x89\x87\xe6\x89\x80\xe6\x9c\x89\xe4\xba\xba\xe8\x84\xb8box\xe7\x9a\x84iou\xe5\x80\xbc\n    \xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n      box\xef\xbc\x9a\xe8\xa3\x81\xe5\x89\xaa\xe7\x9a\x84box,\xe5\xbd\x93box\xe7\xbb\xb4\xe5\xba\xa6\xe4\xb8\xba4\xe6\x97\xb6\xe8\xa1\xa8\xe7\xa4\xbabox\xe5\xb7\xa6\xe4\xb8\x8a\xe5\x8f\xb3\xe4\xb8\x8b\xe5\x9d\x90\xe6\xa0\x87\xef\xbc\x8c\xe7\xbb\xb4\xe5\xba\xa6\xe4\xb8\xba5\xe6\x97\xb6\xef\xbc\x8c\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe7\xbb\xb4\xe4\xb8\xbabox\xe7\x9a\x84\xe7\xbd\xae\xe4\xbf\xa1\xe5\xba\xa6\n      boxes\xef\xbc\x9a\xe5\x9b\xbe\xe7\x89\x87\xe6\x89\x80\xe6\x9c\x89\xe4\xba\xba\xe8\x84\xb8box,[n,4]\n    \xe8\xbf\x94\xe5\x9b\x9e\xe5\x80\xbc\xef\xbc\x9a\n      iou\xe5\x80\xbc\xef\xbc\x8c[n,]\n    '''\n    #box\xe9\x9d\xa2\xe7\xa7\xaf\n    box_area=(box[2]-box[0]+1)*(box[3]-box[1]+1)\n    #boxes\xe9\x9d\xa2\xe7\xa7\xaf,[n,]\n    area=(boxes[:,2]-boxes[:,0]+1)*(boxes[:,3]-boxes[:,1]+1)\n    #\xe9\x87\x8d\xe5\x8f\xa0\xe9\x83\xa8\xe5\x88\x86\xe5\xb7\xa6\xe4\xb8\x8a\xe5\x8f\xb3\xe4\xb8\x8b\xe5\x9d\x90\xe6\xa0\x87\n    xx1=np.maximum(box[0],boxes[:,0])\n    yy1=np.maximum(box[1],boxes[:,1])\n    xx2=np.minimum(box[2],boxes[:,2])\n    yy2=np.minimum(box[3],boxes[:,3])\n    \n    #\xe9\x87\x8d\xe5\x8f\xa0\xe9\x83\xa8\xe5\x88\x86\xe9\x95\xbf\xe5\xae\xbd\n    w=np.maximum(0,xx2-xx1+1)\n    h=np.maximum(0,yy2-yy1+1)\n    #\xe9\x87\x8d\xe5\x8f\xa0\xe9\x83\xa8\xe5\x88\x86\xe9\x9d\xa2\xe7\xa7\xaf\n    inter=w*h\n    return inter/(box_area+area-inter+1e-10)\n\n\n# In[3]:\n\ndef read_annotation(base_dir, label_path):\n    '''\xe8\xaf\xbb\xe5\x8f\x96\xe6\x96\x87\xe4\xbb\xb6\xe7\x9a\x84image\xef\xbc\x8cbox'''\n    data = dict()\n    images = []\n    bboxes = []\n    labelfile = open(label_path, 'r')\n    while True:\n        # \xe5\x9b\xbe\xe5\x83\x8f\xe5\x9c\xb0\xe5\x9d\x80\n        imagepath = labelfile.readline().strip('\\n')\n        if not imagepath:\n            break\n        imagepath = base_dir + '/images/' + imagepath\n        images.append(imagepath)\n        # \xe4\xba\xba\xe8\x84\xb8\xe6\x95\xb0\xe7\x9b\xae\n        nums = labelfile.readline().strip('\\n')\n     \n        one_image_bboxes = []\n        for i in range(int(nums)):\n           \n            bb_info = labelfile.readline().strip('\\n').split(' ')\n            #\xe4\xba\xba\xe8\x84\xb8\xe6\xa1\x86\n            face_box = [float(bb_info[i]) for i in range(4)]\n            \n            xmin = face_box[0]\n            ymin = face_box[1]\n            xmax = xmin + face_box[2]\n            ymax = ymin + face_box[3]\n            \n            one_image_bboxes.append([xmin, ymin, xmax, ymax])\n           \n        bboxes.append(one_image_bboxes)\n\n\n    data['images'] = images\n    data['bboxes'] = bboxes\n    return data\ndef convert_to_square(box):\n    '''\xe5\xb0\x86box\xe8\xbd\xac\xe6\x8d\xa2\xe6\x88\x90\xe6\x9b\xb4\xe5\xa4\xa7\xe7\x9a\x84\xe6\xad\xa3\xe6\x96\xb9\xe5\xbd\xa2\n    \xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n      box\xef\xbc\x9a\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84box,[n,5]\n    \xe8\xbf\x94\xe5\x9b\x9e\xe5\x80\xbc\xef\xbc\x9a\n      \xe8\xb0\x83\xe6\x95\xb4\xe5\x90\x8e\xe7\x9a\x84\xe6\xad\xa3\xe6\x96\xb9\xe5\xbd\xa2box\xef\xbc\x8c[n,5]\n    '''\n    square_box=box.copy()\n    h=box[:,3]-box[:,1]+1\n    w=box[:,2]-box[:,0]+1\n    #\xe6\x89\xbe\xe5\xaf\xbb\xe6\xad\xa3\xe6\x96\xb9\xe5\xbd\xa2\xe6\x9c\x80\xe5\xa4\xa7\xe8\xbe\xb9\xe9\x95\xbf\n    max_side=np.maximum(w,h)\n    \n    square_box[:,0]=box[:,0]+w*0.5-max_side*0.5\n    square_box[:,1]=box[:,1]+h*0.5-max_side*0.5\n    square_box[:,2]=square_box[:,0]+max_side-1\n    square_box[:,3]=square_box[:,1]+max_side-1\n    return square_box\n\n"""
train/__init__.py,0,b'###\n'
train/config.py,0,"b""\n# coding: utf-8\n\n# In[ ]:\n\n\n#\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\nend_epoch=[30,22,22]\n#\xe7\xbb\x8f\xe8\xbf\x87\xe5\xa4\x9a\xe5\xb0\x91batch\xe6\x98\xbe\xe7\xa4\xba\xe6\x95\xb0\xe6\x8d\xae\ndisplay=100\n#\xe5\x88\x9d\xe5\xa7\x8b\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\nlr=0.001\n\nbatch_size=384\n#\xe5\xad\xa6\xe4\xb9\xa0\xe7\x8e\x87\xe5\x87\x8f\xe5\xb0\x91\xe7\x9a\x84\xe8\xbf\xad\xe4\xbb\xa3\xe6\xac\xa1\xe6\x95\xb0\nLR_EPOCH=[6,14,20]\n#\xe6\x9c\x80\xe5\xb0\x8f\xe8\x84\xb8\xe5\xa4\xa7\xe5\xb0\x8f\xe8\xae\xbe\xe5\xae\x9a\nmin_face=20\n\n#\xe7\x94\x9f\xe6\x88\x90hard_example\xe7\x9a\x84batch\nbatches=[2048,256,16]\n#pent\xe5\xaf\xb9\xe5\x9b\xbe\xe5\x83\x8f\xe7\xbc\xa9\xe5\xb0\x8f\xe5\x80\x8d\xe6\x95\xb0\nstride=2\n#\xe4\xb8\x89\xe4\xb8\xaa\xe7\xbd\x91\xe7\xbb\x9c\xe7\x9a\x84\xe9\x98\x88\xe5\x80\xbc\nthresh=[0.6,0.7,0.7]\n#\xe6\x9c\x80\xe5\x90\x8e\xe6\xb5\x8b\xe8\xaf\x95\xe9\x80\x89\xe6\x8b\xa9\xe7\x9a\x84\xe7\xbd\x91\xe7\xbb\x9c\ntest_mode='ONet'\n#\xe9\x80\x89\xe7\x94\xa8\xe5\x9b\xbe\xe7\x89\x87\xe8\xbf\x98\xe6\x98\xaf\xe6\x91\x84\xe5\x83\x8f\xe5\xa4\xb4,1\xe6\x98\xaf\xe5\x9b\xbe\xe5\x83\x8f\xef\xbc\x8c2\xe6\x98\xaf\xe6\x91\x84\xe5\x83\x8f\xe5\xa4\xb4\ninput_mode='1'\n#\xe6\xb5\x8b\xe8\xaf\x95\xe5\x9b\xbe\xe7\x89\x87\xe6\x94\xbe\xe7\xbd\xae\xe4\xbd\x8d\xe7\xbd\xae\ntest_dir='picture/'\n#\xe6\xb5\x8b\xe8\xaf\x95\xe8\xbe\x93\xe5\x87\xba\xe4\xbd\x8d\xe7\xbd\xae\nout_path='output/'\n\n"""
train/model.py,60,"b""\n# coding: utf-8\n\n# In[1]:\n\n\nimport tensorflow as tf\nslim=tf.contrib.slim\nimport numpy as np\n#\xe5\x8f\xaa\xe6\x8a\x8a70%\xe6\x95\xb0\xe6\x8d\xae\xe7\x94\xa8\xe4\xbd\x9c\xe5\x8f\x82\xe6\x95\xb0\xe6\x9b\xb4\xe6\x96\xb0\nnum_keep_radio=0.7\n\n\n# In[7]:\n\n\ndef P_Net(inputs,label=None,bbox_target=None,landmark_target=None,training=True):\n    '''pnet\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x84'''\n    with tf.variable_scope('PNet'):\n        with slim.arg_scope([slim.conv2d],activation_fn=prelu,\n                           weights_initializer=slim.xavier_initializer(),\n                           weights_regularizer=slim.l2_regularizer(0.0005),\n                           padding='VALID'):\n            net=slim.conv2d(inputs,10,3,scope='conv1')\n            net=slim.max_pool2d(net,kernel_size=[2,2],stride=2,padding='SAME',scope='pool1')\n            net=slim.conv2d(net,16,3,scope='conv2')\n            net=slim.conv2d(net,32,3,scope='conv3')\n            #\xe4\xba\x8c\xe5\x88\x86\xe7\xb1\xbb\xe8\xbe\x93\xe5\x87\xba\xe9\x80\x9a\xe9\x81\x93\xe6\x95\xb0\xe4\xb8\xba2\n            conv4_1=slim.conv2d(net,2,1,activation_fn=tf.nn.softmax,scope='conv4_1')\n            bbox_pred=slim.conv2d(net,4,1,activation_fn=None,scope='conv4_2')\n            landmark_pred=slim.conv2d(net,10,1,activation_fn=None,scope='conv4_3')\n            \n            if training:\n                cls_prob=tf.squeeze(conv4_1,[1,2],name='cls_prob')#[batch,2]\n                cls_loss=cls_ohem(cls_prob,label)\n                \n                bbox_pred=tf.squeeze(bbox_pred,[1,2],name='bbox_pred')#[bacth,4]\n                bbox_loss=bbox_ohem(bbox_pred,bbox_target,label)\n                \n                landmark_pred=tf.squeeze(landmark_pred,[1,2],name='landmark_pred')#[batch,10]\n                landmark_loss=landmark_ohem(landmark_pred,landmark_target,label)\n                \n                accuracy=cal_accuracy(cls_prob,label)\n                L2_loss=tf.add_n(slim.losses.get_regularization_losses())\n                return cls_loss,bbox_loss,landmark_loss,L2_loss,accuracy\n            else:\n                #\xe6\xb5\x8b\xe8\xaf\x95\xe6\x97\xb6batch_size=1\n                cls_pro_test=tf.squeeze(conv4_1,axis=0)\n                bbox_pred_test=tf.squeeze(bbox_pred,axis=0)\n                landmark_pred_test=tf.squeeze(landmark_pred,axis=0)\n                return cls_pro_test,bbox_pred_test,landmark_pred_test\n\n\n# In[8]:\n\n\ndef R_Net(inputs,label=None,bbox_target=None,landmark_target=None,training=True):\n    '''RNet\xe7\xbb\x93\xe6\x9e\x84'''\n    with tf.variable_scope('RNet'):\n        with slim.arg_scope([slim.conv2d],\n                           activation_fn=prelu,\n                           weights_initializer=slim.xavier_initializer(),\n                           weights_regularizer=slim.l2_regularizer(0.0005),\n                           padding='VALID'):\n            net=slim.conv2d(inputs,28,3,scope='conv1')\n            net=slim.max_pool2d(net,kernel_size=[3,3],stride=2,padding='SAME',scope='pool1')\n            net=slim.conv2d(net,48,3,scope='conv2')\n            net=slim.max_pool2d(net,kernel_size=[3,3],stride=2,scope='pool2')\n            net=slim.conv2d(net,64,2,scope='conv3')\n            fc_flatten=slim.flatten(net)\n            fc1=slim.fully_connected(fc_flatten,num_outputs=128,scope='fc1')\n            \n            cls_prob=slim.fully_connected(fc1,num_outputs=2,activation_fn=tf.nn.softmax,scope='cls_fc')\n            bbox_pred=slim.fully_connected(fc1,num_outputs=4,activation_fn=None,scope='bbox_fc')\n            landmark_pred=slim.fully_connected(fc1,num_outputs=10,activation_fn=None,scope='landmark_fc')\n            if training:\n                cls_loss=cls_ohem(cls_prob,label)\n                \n                bbox_loss=bbox_ohem(bbox_pred,bbox_target,label)\n                \n                landmark_loss=landmark_ohem(landmark_pred,landmark_target,label)\n                \n                accuracy=cal_accuracy(cls_prob,label)\n                L2_loss=tf.add_n(slim.losses.get_regularization_losses())\n                return cls_loss,bbox_loss,landmark_loss,L2_loss,accuracy\n            else:\n                return cls_prob,bbox_pred,landmark_pred\n\n\n# In[9]:\n\n\ndef O_Net(inputs,label=None,bbox_target=None,landmark_target=None,training=True):\n    '''ONet\xe7\xbb\x93\xe6\x9e\x84'''\n    with tf.variable_scope('ONet'):\n        with slim.arg_scope([slim.conv2d],\n                           activation_fn=prelu,\n                           weights_initializer=slim.xavier_initializer(),\n                           weights_regularizer=slim.l2_regularizer(0.0005),\n                           padding='VALID'):\n            net=slim.conv2d(inputs,32,3,scope='conv1')\n            net=slim.max_pool2d(net,kernel_size=[3,3],stride=2,padding='SAME',scope='pool1')\n            net=slim.conv2d(net,64,3,scope='conv2')\n            net=slim.max_pool2d(net,kernel_size=[3,3],stride=2,scope='pool2')\n            net=slim.conv2d(net,64,3,scope='conv3')\n            net=slim.max_pool2d(net,kernel_size=[2,2],stride=2,padding='SAME',scope='pool3')\n            net=slim.conv2d(net,128,2,scope='conv4')\n            fc_flatten=slim.flatten(net)\n            fc1=slim.fully_connected(fc_flatten,num_outputs=256,scope='fc1')\n            \n            cls_prob=slim.fully_connected(fc1,num_outputs=2,activation_fn=tf.nn.softmax,scope='cls_fc')\n            bbox_pred=slim.fully_connected(fc1,num_outputs=4,activation_fn=None,scope='bbox_fc')\n            landmark_pred=slim.fully_connected(fc1,num_outputs=10,activation_fn=None,scope='landmark_fc')\n            if training:\n                cls_loss=cls_ohem(cls_prob,label)\n                \n                bbox_loss=bbox_ohem(bbox_pred,bbox_target,label)\n                \n                landmark_loss=landmark_ohem(landmark_pred,landmark_target,label)\n                \n                accuracy=cal_accuracy(cls_prob,label)\n                L2_loss=tf.add_n(slim.losses.get_regularization_losses())\n                return cls_loss,bbox_loss,landmark_loss,L2_loss,accuracy\n            else:\n                return cls_prob,bbox_pred,landmark_pred\n\n\n# In[2]:\n\n\ndef prelu(inputs):\n    '''prelu\xe5\x87\xbd\xe6\x95\xb0\xe5\xae\x9a\xe4\xb9\x89'''\n    alphas=tf.get_variable('alphas',shape=inputs.get_shape()[-1],dtype=tf.float32,\n                          initializer=tf.constant_initializer(0.25))\n    pos=tf.nn.relu(inputs)\n    neg=alphas*(inputs-abs(inputs))*0.5\n    return pos+neg\n\n\n# In[3]:\n\n\ndef cls_ohem(cls_prob,label):\n    '''\xe8\xae\xa1\xe7\xae\x97\xe7\xb1\xbb\xe5\x88\xab\xe6\x8d\x9f\xe5\xa4\xb1\n    \xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x9a\n      cls_prob\xef\xbc\x9a\xe9\xa2\x84\xe6\xb5\x8b\xe7\xb1\xbb\xe5\x88\xab\xef\xbc\x8c\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89\xe4\xba\xba\n      label\xef\xbc\x9a\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\n    \xe8\xbf\x94\xe5\x9b\x9e\xe5\x80\xbc\xef\xbc\x9a\n      \xe6\x8d\x9f\xe5\xa4\xb1\n    '''\n    zeros=tf.zeros_like(label)\n    #\xe5\x8f\xaa\xe6\x8a\x8apos\xe7\x9a\x84label\xe8\xae\xbe\xe5\xae\x9a\xe4\xb8\xba1,\xe5\x85\xb6\xe4\xbd\x99\xe9\x83\xbd\xe4\xb8\xba0\n    label_filter_invalid=tf.where(tf.less(label,0),zeros,label)\n    #\xe7\xb1\xbb\xe5\x88\xabsize[2*batch]\n    num_cls_prob=tf.size(cls_prob)\n    cls_prob_reshpae=tf.reshape(cls_prob,[num_cls_prob,-1])\n    label_int=tf.cast(label_filter_invalid,tf.int32)\n    #\xe8\x8e\xb7\xe5\x8f\x96batch\xe6\x95\xb0\n    num_row=tf.to_int32(cls_prob.get_shape()[0])\n    #\xe5\xaf\xb9\xe5\xba\x94\xe6\x9f\x90\xe4\xb8\x80batch\xe8\x80\x8c\xe8\xa8\x80\xef\xbc\x8cbatch*2\xe4\xb8\xba\xe9\x9d\x9e\xe4\xba\xba\xe7\xb1\xbb\xe5\x88\xab\xe6\xa6\x82\xe7\x8e\x87\xef\xbc\x8cbatch*2+1\xe4\xb8\xba\xe4\xba\xba\xe6\xa6\x82\xe7\x8e\x87\xe7\xb1\xbb\xe5\x88\xab,indices\xe4\xb8\xba\xe5\xaf\xb9\xe5\xba\x94 cls_prob_reshpae\n    #\xe5\xba\x94\xe8\xaf\xa5\xe7\x9a\x84\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xef\xbc\x8c\xe5\x90\x8e\xe7\xbb\xad\xe7\x94\xa8\xe4\xba\xa4\xe5\x8f\x89\xe7\x86\xb5\xe8\xae\xa1\xe7\xae\x97\xe6\x8d\x9f\xe5\xa4\xb1\n    row=tf.range(num_row)*2\n    indices_=row+label_int\n    #\xe7\x9c\x9f\xe5\xae\x9e\xe6\xa0\x87\xe7\xad\xbe\xe5\xaf\xb9\xe5\xba\x94\xe7\x9a\x84\xe6\xa6\x82\xe7\x8e\x87\n    label_prob=tf.squeeze(tf.gather(cls_prob_reshpae,indices_))\n    loss=-tf.log(label_prob+1e-10)\n    zeros=tf.zeros_like(label_prob,dtype=tf.float32)\n    ones=tf.ones_like(label_prob,dtype=tf.float32)\n    #\xe7\xbb\x9f\xe8\xae\xa1neg\xe5\x92\x8cpos\xe7\x9a\x84\xe6\x95\xb0\xe9\x87\x8f\n    valid_inds=tf.where(label<zeros,zeros,ones)\n    num_valid=tf.reduce_sum(valid_inds)\n    #\xe9\x80\x89\xe5\x8f\x9670%\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\n    keep_num=tf.cast(num_valid*num_keep_radio,dtype=tf.int32)\n    #\xe5\x8f\xaa\xe9\x80\x89\xe5\x8f\x96neg\xef\xbc\x8cpos\xe7\x9a\x8470%\xe6\x8d\x9f\xe5\xa4\xb1\n    loss=loss*valid_inds\n    loss,_=tf.nn.top_k(loss,k=keep_num)\n    return tf.reduce_mean(loss)\n\n\n# In[4]:\n\n\ndef bbox_ohem(bbox_pred,bbox_target,label):\n    '''\xe8\xae\xa1\xe7\xae\x97box\xe7\x9a\x84\xe6\x8d\x9f\xe5\xa4\xb1'''\n    zeros_index=tf.zeros_like(label,dtype=tf.float32)\n    ones_index=tf.ones_like(label,dtype=tf.float32)\n    #\xe4\xbf\x9d\xe7\x95\x99pos\xe5\x92\x8cpart\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\n    valid_inds=tf.where(tf.equal(tf.abs(label),1),ones_index,zeros_index)\n    #\xe8\xae\xa1\xe7\xae\x97\xe5\xb9\xb3\xe6\x96\xb9\xe5\xb7\xae\xe6\x8d\x9f\xe5\xa4\xb1\n    square_error=tf.square(bbox_pred-bbox_target)\n    square_error=tf.reduce_sum(square_error,axis=1)\n    #\xe4\xbf\x9d\xe7\x95\x99\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe7\x9a\x84\xe4\xb8\xaa\xe6\x95\xb0\n    num_valid=tf.reduce_sum(valid_inds)\n    keep_num=tf.cast(num_valid,dtype=tf.int32)\n    #\xe4\xbf\x9d\xe7\x95\x99pos\xe5\x92\x8cpart\xe9\x83\xa8\xe5\x88\x86\xe7\x9a\x84\xe6\x8d\x9f\xe5\xa4\xb1\n    square_error=square_error*valid_inds\n    square_error,_=tf.nn.top_k(square_error,k=keep_num)\n    return tf.reduce_mean(square_error)\n    \n\n\n# In[5]:\n\n\ndef landmark_ohem(landmark_pred,landmark_target,label):\n    '''\xe8\xae\xa1\xe7\xae\x97\xe5\x85\xb3\xe9\x94\xae\xe7\x82\xb9\xe6\x8d\x9f\xe5\xa4\xb1'''\n    ones=tf.ones_like(label,dtype=tf.float32)\n    zeros=tf.zeros_like(label,dtype=tf.float32)\n    #\xe5\x8f\xaa\xe4\xbf\x9d\xe7\x95\x99landmark\xe6\x95\xb0\xe6\x8d\xae\n    valid_inds=tf.where(tf.equal(label,-2),ones,zeros)\n    #\xe8\xae\xa1\xe7\xae\x97\xe5\xb9\xb3\xe6\x96\xb9\xe5\xb7\xae\xe6\x8d\x9f\xe5\xa4\xb1\n    square_error=tf.square(landmark_pred-landmark_target)\n    square_error=tf.reduce_sum(square_error,axis=1)\n    #\xe4\xbf\x9d\xe7\x95\x99\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xaa\xe6\x95\xb0\n    num_valid=tf.reduce_sum(valid_inds)\n    keep_num=tf.cast(num_valid,dtype=tf.int32)\n    #\xe4\xbf\x9d\xe7\x95\x99landmark\xe9\x83\xa8\xe5\x88\x86\xe6\x95\xb0\xe6\x8d\xae\xe6\x8d\x9f\xe5\xa4\xb1\n    square_error=square_error*valid_inds\n    square_error,_=tf.nn.top_k(square_error,k=keep_num)\n    return tf.reduce_mean(square_error)\n\n\n# In[6]:\n\n\ndef cal_accuracy(cls_prob,label):\n    '''\xe8\xae\xa1\xe7\xae\x97\xe5\x88\x86\xe7\xb1\xbb\xe5\x87\x86\xe7\xa1\xae\xe7\x8e\x87'''\n    #\xe9\xa2\x84\xe6\xb5\x8b\xe6\x9c\x80\xe5\xa4\xa7\xe6\xa6\x82\xe7\x8e\x87\xe7\x9a\x84\xe7\xb1\xbb\xe5\x88\xab\xef\xbc\x8c0\xe4\xbb\xa3\xe8\xa1\xa8\xe6\x97\xa0\xe4\xba\xba\xef\xbc\x8c1\xe4\xbb\xa3\xe8\xa1\xa8\xe6\x9c\x89\xe4\xba\xba\n    pred=tf.argmax(cls_prob,axis=1)\n    label_int=tf.cast(label,tf.int64)\n    #\xe4\xbf\x9d\xe7\x95\x99label>=0\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\x8d\xb3pos\xe5\x92\x8cneg\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\n    cond=tf.where(tf.greater_equal(label_int,0))\n    picked=tf.squeeze(cond)\n    #\xe8\x8e\xb7\xe5\x8f\x96pos\xe5\x92\x8cneg\xe7\x9a\x84label\xe5\x80\xbc\n    label_picked=tf.gather(label_int,picked)\n    pred_picked=tf.gather(pred,picked)\n    #\xe8\xae\xa1\xe7\xae\x97\xe5\x87\x86\xe7\xa1\xae\xe7\x8e\x87\n    accuracy_op=tf.reduce_mean(tf.cast(tf.equal(label_picked,pred_picked),tf.float32))\n    return accuracy_op\n\n"""
train/train.py,0,"b""\n# coding: utf-8\n\n# In[5]:\n\n\nfrom model import P_Net,R_Net,O_Net\nimport argparse\nimport os\nimport sys\nimport config as FLAGS\nfrom train_model import train\nnet_factorys=[P_Net,R_Net,O_Net]\n\n\n# In[ ]:\n\n\ndef main(args):\n    size=args.input_size\n    base_dir=os.path.join('../data/',str(size))\n    \n    if size==12:\n        net='PNet'\n        net_factory=net_factorys[0]\n        end_epoch=FLAGS.end_epoch[0]\n    elif size==24:\n        net='RNet'\n        net_factory=net_factorys[1]\n        end_epoch=FLAGS.end_epoch[1]\n    elif size==48:\n        net='ONet'\n        net_factory=net_factorys[2]\n        end_epoch=FLAGS.end_epoch[2]\n    model_path=os.path.join('../model/',net)\n    if not os.path.exists(model_path):\n        os.mkdir(model_path)\n    prefix=os.path.join(model_path,net)\n    display=FLAGS.display\n    lr=FLAGS.lr\n    train(net_factory,prefix,end_epoch,base_dir,display,lr)\n\n\n# In[ ]:\n\n\ndef parse_arguments(argv):\n\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument('input_size', type=int,\n                        help='The input size for specific net')\n    \n    return parser.parse_args(argv)\n\n\nif __name__ == '__main__':\n    main(parse_arguments(sys.argv[1:]))\n\n"""
train/train_model.py,45,"b'\n# coding: utf-8\n\n# In[1]:\n\n\nimport os\nimport sys\nfrom datetime import datetime\nimport numpy as np\nimport tensorflow as tf\nimport config as FLAGS\nimport random\nimport cv2\n\n\n# In[ ]:\n\n\ndef train(net_factory,prefix,end_epoch,base_dir,display,base_lr):\n    \'\'\'\xe8\xae\xad\xe7\xbb\x83\xe6\xa8\xa1\xe5\x9e\x8b\'\'\'\n    size=int(base_dir.split(\'/\')[-1])\n    if size==12:\n        net=\'PNet\'\n        radio_cls_loss = 1.0;radio_bbox_loss = 0.5;radio_landmark_loss = 0.5;\n    elif size==24:\n        net=\'RNet\'\n        radio_cls_loss = 1.0;radio_bbox_loss = 0.5;radio_landmark_loss = 0.5;\n    elif size==48:\n        net=\'ONet\'\n        radio_cls_loss = 1.0;radio_bbox_loss = 0.5;radio_landmark_loss = 1;\n        \n    if net==\'PNet\':\n        #\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe5\x85\xb1\xe5\xa4\x9a\xe5\xb0\x91\xe7\xbb\x84\xe6\x95\xb0\xe6\x8d\xae\n        label_file=os.path.join(base_dir,\'train_pnet_landmark.txt\')\n        f = open(label_file, \'r\')\n   \n        num = len(f.readlines())\n        dataset_dir=os.path.join(base_dir,\'tfrecord/train_PNet_landmark.tfrecord_shuffle\')\n        #\xe4\xbb\x8etfrecord\xe8\xaf\xbb\xe5\x8f\x96\xe6\x95\xb0\xe6\x8d\xae\n        image_batch,label_batch,bbox_batch,landmark_batch=read_single_tfrecord(dataset_dir,FLAGS.batch_size,net)\n    else:\n        #\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x80\xe5\x85\xb1\xe5\xa4\x9a\xe5\xb0\x91\xe7\xbb\x84\xe6\x95\xb0\xe6\x8d\xae\n        label_file1=os.path.join(base_dir,\'pos_%d.txt\'%(size))\n        f1 = open(label_file1, \'r\')\n        label_file2=os.path.join(base_dir,\'part_%d.txt\'%(size))\n        f2 = open(label_file2, \'r\')\n        label_file3=os.path.join(base_dir,\'neg_%d.txt\'%(size))\n        f3 = open(label_file3, \'r\')\n        label_file4=os.path.join(base_dir,\'landmark_%d_aug.txt\'%(size))\n        f4 = open(label_file4, \'r\')\n   \n        num = len(f1.readlines())+len(f2.readlines())+len(f3.readlines())+len(f4.readlines())\n    \n        pos_dir = os.path.join(base_dir,\'tfrecord/pos_landmark.tfrecord_shuffle\')\n        part_dir = os.path.join(base_dir,\'tfrecord/part_landmark.tfrecord_shuffle\')\n        neg_dir = os.path.join(base_dir,\'tfrecord/neg_landmark.tfrecord_shuffle\')\n        landmark_dir = os.path.join(base_dir,\'tfrecord/landmark_landmark.tfrecord_shuffle\')\n        dataset_dirs=[pos_dir,part_dir,neg_dir,landmark_dir]\n        #\xe5\x90\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x8d\xa0\xe6\xaf\x94\n        #\xe7\x9b\xae\xe7\x9a\x84\xe6\x98\xaf\xe4\xbd\xbf\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaabatch\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae\xe5\x8d\xa0\xe6\xaf\x94\xe9\x83\xbd\xe7\x9b\xb8\xe5\x90\x8c\n        pos_radio,part_radio,landmark_radio,neg_radio=1.0/6,1.0/6,1.0/6,3.0/6\n        pos_batch_size=int(np.ceil(FLAGS.batch_size*pos_radio))\n        assert pos_batch_size != 0,""Batch Size \xe6\x9c\x89\xe8\xaf\xaf ""\n        part_batch_size = int(np.ceil(FLAGS.batch_size*part_radio))\n        assert part_batch_size != 0,""BBatch Size \xe6\x9c\x89\xe8\xaf\xaf ""\n        neg_batch_size = int(np.ceil(FLAGS.batch_size*neg_radio))\n        assert neg_batch_size != 0,""Batch Size \xe6\x9c\x89\xe8\xaf\xaf ""\n        landmark_batch_size = int(np.ceil(FLAGS.batch_size*landmark_radio))\n        assert landmark_batch_size != 0,""Batch Size \xe6\x9c\x89\xe8\xaf\xaf ""\n        batch_sizes = [pos_batch_size,part_batch_size,neg_batch_size,landmark_batch_size]\n        image_batch, label_batch, bbox_batch,landmark_batch = read_multi_tfrecords(dataset_dirs,batch_sizes, net)  \n    input_image=tf.placeholder(tf.float32,shape=[FLAGS.batch_size,size,size,3],name=\'input_image\')\n    label=tf.placeholder(tf.float32,shape=[FLAGS.batch_size],name=\'label\')\n    bbox_target=tf.placeholder(tf.float32,shape=[FLAGS.batch_size,4],name=\'bbox_target\')\n    landmark_target=tf.placeholder(tf.float32,shape=[FLAGS.batch_size,10],name=\'landmark_target\')\n    #\xe5\x9b\xbe\xe5\x83\x8f\xe8\x89\xb2\xe7\x9b\xb8\xe5\x8f\x98\xe6\x8d\xa2\n    input_image=image_color_distort(input_image)\n    cls_loss_op,bbox_loss_op,landmark_loss_op,L2_loss_op,accuracy_op=net_factory(input_image,\n                        label,bbox_target,landmark_target,training=True)\n    total_loss_op=radio_cls_loss*cls_loss_op+radio_bbox_loss*bbox_loss_op+            radio_landmark_loss*landmark_loss_op+L2_loss_op\n    train_op,lr_op=optimize(base_lr,total_loss_op,num)\n    \n    \n    tf.summary.scalar(""cls_loss"",cls_loss_op)#cls_loss\n    tf.summary.scalar(""bbox_loss"",bbox_loss_op)#bbox_loss\n    tf.summary.scalar(""landmark_loss"",landmark_loss_op)#landmark_loss\n    tf.summary.scalar(""cls_accuracy"",accuracy_op)#cls_acc\n    tf.summary.scalar(""total_loss"",total_loss_op)#cls_loss, bbox loss, landmark loss and L2 loss add together\n    summary_op = tf.summary.merge_all()\n    logs_dir = ""../graph/%s"" %(net)\n    if os.path.exists(logs_dir) == False:\n        os.mkdir(logs_dir)\n    #\xe6\xa8\xa1\xe5\x9e\x8b\xe8\xae\xad\xe7\xbb\x83\n    init = tf.global_variables_initializer()\n    sess = tf.Session()\n\n\n    saver = tf.train.Saver(max_to_keep=3)\n    sess.run(init)\n    #\xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84graph\n    writer = tf.summary.FileWriter(logs_dir,sess.graph)\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n    i = 0\n    \n    MAX_STEP = int(num / FLAGS.batch_size + 1) * end_epoch\n    epoch = 0\n    sess.graph.finalize()\n    try:\n\n        for step in range(MAX_STEP):\n            i = i + 1\n            if coord.should_stop():\n                break\n            image_batch_array, label_batch_array, bbox_batch_array,landmark_batch_array = sess.run([image_batch, label_batch, bbox_batch,landmark_batch])\n            #\xe9\x9a\x8f\xe6\x9c\xba\xe7\xbf\xbb\xe8\xbd\xac\xe5\x9b\xbe\xe5\x83\x8f\n            image_batch_array,landmark_batch_array = random_flip_images(image_batch_array,label_batch_array,landmark_batch_array)\n           \n\n\n            _,_,summary = sess.run([train_op, lr_op ,summary_op], feed_dict={input_image: image_batch_array, label: label_batch_array, bbox_target: bbox_batch_array,landmark_target:landmark_batch_array})\n            #\xe5\xb1\x95\xe7\xa4\xba\xe8\xae\xad\xe7\xbb\x83\xe8\xbf\x87\xe7\xa8\x8b\n            if (step+1) % display == 0:\n                cls_loss, bbox_loss,landmark_loss,L2_loss,lr,acc = sess.run([cls_loss_op, bbox_loss_op,landmark_loss_op,L2_loss_op,lr_op,accuracy_op],\n                                                             feed_dict={input_image: image_batch_array, label: label_batch_array, bbox_target: bbox_batch_array, landmark_target: landmark_batch_array})\n\n                total_loss = radio_cls_loss*cls_loss + radio_bbox_loss*bbox_loss + radio_landmark_loss*landmark_loss + L2_loss\n                print(\'epoch:%d/%d\'%(epoch+1,end_epoch))\n                print(""Step: %d/%d, accuracy: %3f, cls loss: %4f, bbox loss: %4f,Landmark loss :%4f,L2 loss: %4f, Total Loss: %4f ,lr:%f "" % (step+1,MAX_STEP, acc, cls_loss, bbox_loss,landmark_loss, L2_loss,total_loss, lr))\n\n\n            #\xe6\xaf\x8f\xe4\xb8\x80\xe6\xac\xa1epoch\xe4\xbf\x9d\xe7\x95\x99\xe4\xb8\x80\xe6\xac\xa1\xe6\xa8\xa1\xe5\x9e\x8b\n            if i * FLAGS.batch_size > num:\n                epoch = epoch + 1\n                i = 0\n                path_prefix = saver.save(sess, prefix, global_step=epoch)\n            writer.add_summary(summary,global_step=step)\n    except tf.errors.OutOfRangeError:\n        print(""\xe5\xae\x8c\xe6\x88\x90\xef\xbc\x81\xef\xbc\x81\xef\xbc\x81"")\n    finally:\n        coord.request_stop()\n        writer.close()\n    coord.join(threads)\n    sess.close()\n\n\n# In[5]:\n\n\ndef optimize(base_lr,loss,data_num):\n    \'\'\'\xe5\x8f\x82\xe6\x95\xb0\xe4\xbc\x98\xe5\x8c\x96\'\'\'\n    lr_factor=0.1\n    global_step = tf.Variable(0, trainable=False)\n    boundaries = [int(epoch * data_num / FLAGS.batch_size) for epoch in FLAGS.LR_EPOCH]\n    lr_values = [base_lr * (lr_factor ** x) for x in range(0, len(FLAGS.LR_EPOCH) + 1)]\n    lr_op = tf.train.piecewise_constant(global_step, boundaries, lr_values)\n    optimizer = tf.train.MomentumOptimizer(lr_op, 0.9)\n    train_op = optimizer.minimize(loss, global_step)\n    return train_op, lr_op\n\n\n# In[2]:\n\n\ndef read_single_tfrecord(tfrecord_file,batch_size,net):\n    \'\'\'\xe8\xaf\xbb\xe5\x8f\x96tfrecord\xe6\x95\xb0\xe6\x8d\xae\'\'\'\n    filename_queue=tf.train.string_input_producer([tfrecord_file],shuffle=True)\n    reader=tf.TFRecordReader()\n    _,serialized_example=reader.read(filename_queue)\n    image_features=tf.parse_single_example(serialized_example,\n                        features={\n                        \'image/encoded\': tf.FixedLenFeature([], tf.string),\n                        \'image/label\': tf.FixedLenFeature([], tf.int64),\n                        \'image/roi\': tf.FixedLenFeature([4], tf.float32),\n                        \'image/landmark\': tf.FixedLenFeature([10],tf.float32)\n                    }\n                )\n    if net==\'PNet\':\n        image_size=12\n    elif net==\'RNet\':\n        image_size=24\n    elif net==\'ONet\':\n        image_size=48\n    image=tf.decode_raw(image_features[\'image/encoded\'],tf.uint8)\n    image=tf.reshape(image,[image_size,image_size,3])\n    #\xe5\xb0\x86\xe5\x80\xbc\xe8\xa7\x84\xe5\x88\x92\xe5\x9c\xa8[-1,1]\xe5\x86\x85\n    image=(tf.cast(image,tf.float32)-127.5)/128\n    \n    label=tf.cast(image_features[\'image/label\'],tf.float32)\n    roi=tf.cast(image_features[\'image/roi\'],tf.float32)\n    landmark=tf.cast(image_features[\'image/landmark\'],tf.float32)\n    image,label,roi,landmark=tf.train.batch([image,label,roi,landmark],\n                                           batch_size=batch_size,\n                                           num_threads=2,\n                                           capacity=batch_size)\n    label=tf.reshape(label,[batch_size])\n    roi=tf.reshape(roi,[batch_size,4])\n    landmark=tf.reshape(landmark,[batch_size,10])\n    return image,label,roi,landmark\n\n\n# In[3]:\n\n\ndef read_multi_tfrecords(tfrecord_files, batch_sizes, net):\n    \'\'\'\xe8\xaf\xbb\xe5\x8f\x96\xe5\xa4\x9a\xe4\xb8\xaatfrecord\xe6\x96\x87\xe4\xbb\xb6\xe6\x94\xbe\xe4\xb8\x80\xe8\xb5\xb7\'\'\'\n    pos_dir,part_dir,neg_dir,landmark_dir = tfrecord_files\n    pos_batch_size,part_batch_size,neg_batch_size,landmark_batch_size = batch_sizes\n   \n    pos_image,pos_label,pos_roi,pos_landmark = read_single_tfrecord(pos_dir, pos_batch_size, net)\n  \n    part_image,part_label,part_roi,part_landmark = read_single_tfrecord(part_dir, part_batch_size, net)\n  \n    neg_image,neg_label,neg_roi,neg_landmark = read_single_tfrecord(neg_dir, neg_batch_size, net)\n\n    landmark_image,landmark_label,landmark_roi,landmark_landmark = read_single_tfrecord(landmark_dir, landmark_batch_size, net)\n \n\n    images = tf.concat([pos_image,part_image,neg_image,landmark_image], 0, name=""concat/image"")\n   \n    labels = tf.concat([pos_label,part_label,neg_label,landmark_label],0,name=""concat/label"")\n \n    assert isinstance(labels, object)\n\n    rois = tf.concat([pos_roi,part_roi,neg_roi,landmark_roi],0,name=""concat/roi"")\n    \n    landmarks = tf.concat([pos_landmark,part_landmark,neg_landmark,landmark_landmark],0,name=""concat/landmark"")\n    return images,labels,rois,landmarks\n    \n\n\n# In[4]:\n\n\ndef image_color_distort(inputs):\n    inputs = tf.image.random_contrast(inputs, lower=0.5, upper=1.5)\n    inputs = tf.image.random_brightness(inputs, max_delta=0.2)\n    inputs = tf.image.random_hue(inputs,max_delta= 0.2)\n    inputs = tf.image.random_saturation(inputs,lower = 0.5, upper= 1.5)\n\n    return inputs\n\n\n# In[6]:\n\n\ndef random_flip_images(image_batch,label_batch,landmark_batch):\n    \'\'\'\xe9\x9a\x8f\xe6\x9c\xba\xe7\xbf\xbb\xe8\xbd\xac\xe5\x9b\xbe\xe5\x83\x8f\'\'\'\n    if random.choice([0,1]) > 0:\n        num_images = image_batch.shape[0]\n        fliplandmarkindexes = np.where(label_batch==-2)[0]\n        flipposindexes = np.where(label_batch==1)[0]\n        \n        flipindexes = np.concatenate((fliplandmarkindexes,flipposindexes))\n          \n        for i in flipindexes:\n            cv2.flip(image_batch[i],1,image_batch[i])        \n        \n           \n        for i in fliplandmarkindexes:\n            landmark_ = landmark_batch[i].reshape((-1,2))\n            landmark_ = np.asarray([(1-x, y) for (x, y) in landmark_])\n            landmark_[[0, 1]] = landmark_[[1, 0]]\n            landmark_[[3, 4]] = landmark_[[4, 3]]       \n            landmark_batch[i] = landmark_.ravel()\n        \n    return image_batch,landmark_batch\n\n'"
