file_path,api_count,code
Code/Day 11_k-NN.py,0,"b""# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Importing the dataset\ndataset = pd.read_csv('../datasets/Social_Network_Ads.csv')\nX = dataset.iloc[:, [2, 3]].values\ny = dataset.iloc[:, 4].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Fitting K-NN to the Training set\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(classification_report(y_test, y_pred))\n"""
Code/Day 13_SVM.py,0,"b""#Day13: Support Vector Machine (SVM)\r\n\r\n#Importing the libraries\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport pandas as pd\r\n\r\n#Importing the dataset\r\ndataset = pd.read_csv('../datasets/Social_Network_Ads.csv')\r\nX = dataset.iloc[:, [2, 3]].values\r\ny = dataset.iloc[:, 4].values\r\n\r\n#Splitting the dataset into the Training set and Test set\r\nfrom sklearn.model_selection import train_test_split\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\r\n\r\n#Feature Scaling\r\nfrom sklearn.preprocessing import StandardScaler\r\nsc = StandardScaler()\r\nX_train = sc.fit_transform(X_train)\r\nX_test = sc.transform(X_test)\r\n\r\n#Fitting SVM to the Training set\r\nfrom sklearn.svm import SVC\r\nclassifier = SVC(kernel = 'linear', random_state = 0)\r\nclassifier.fit(X_train, y_train)\r\n\r\n#Predicting the Test set results\r\ny_pred = classifier.predict(X_test)\r\n\r\n#Making the Confusion Matrix\r\nfrom sklearn.metrics import confusion_matrix\r\nfrom sklearn.metrics import classification_report\r\ncm = confusion_matrix(y_test, y_pred)\r\nprint(cm)\r\nprint(classification_report(y_test, y_pred))\r\n\r\n#Visualising the Training set results\r\nfrom matplotlib.colors import ListedColormap\r\nX_set, y_set = X_train, y_train\r\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\r\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\r\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\r\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\r\nplt.xlim(X1.min(), X1.max())\r\nplt.ylim(X2.min(), X2.max())\r\nfor i, j in enumerate(np.unique(y_set)):\r\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\r\n                c = ListedColormap(('red', 'green'))(i), label = j)\r\nplt.title('SVM (Training set)')\r\nplt.xlabel('Age')\r\nplt.ylabel('Estimated Salary')\r\nplt.legend()\r\nplt.show()\r\n\r\n#Visualising the Test set results\r\nfrom matplotlib.colors import ListedColormap\r\nX_set, y_set = X_test, y_test\r\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\r\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\r\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\r\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\r\nplt.xlim(X1.min(), X1.max())\r\nplt.ylim(X2.min(), X2.max())\r\nfor i, j in enumerate(np.unique(y_set)):\r\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\r\n                c = ListedColormap(('red', 'green'))(i), label = j)\r\nplt.title('SVM (Test set)')\r\nplt.xlabel('Age')\r\nplt.ylabel('Estimated Salary')\r\nplt.legend()\r\nplt.show()\r\n"""
Code/Day 1_Data_Preprocessing.py,0,"b'#Day 1: Data Prepocessing\r\n\r\n#Step 1: Importing the libraries\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\n#Step 2: Importing dataset\r\ndataset = pd.read_csv(\'../datasets/Data.csv\')\r\nX = dataset.iloc[ : , :-1].values\r\nY = dataset.iloc[ : , 3].values\r\nprint(""Step 2: Importing dataset"")\r\nprint(""X"")\r\nprint(X)\r\nprint(""Y"")\r\nprint(Y)\r\n\r\n#Step 3: Handling the missing data\r\n# If you use the newest version of sklearn, use the lines of code commented out\r\n# from sklearn.impute import SimpleImputer\r\n# imputer = SimpleImputer(missing_values=""NaN"", strategy=""mean"")\r\nfrom sklearn.preprocessing import Imputer\r\nimputer = Imputer(missing_values = ""NaN"", strategy = ""mean"", axis = 0)\r\nimputer = imputer.fit(X[ : , 1:3])\r\nX[ : , 1:3] = imputer.transform(X[ : , 1:3])\r\nprint(""---------------------"")\r\nprint(""Step 3: Handling the missing data"")\r\nprint(""step2"")\r\nprint(""X"")\r\nprint(X)\r\n\r\n#Step 4: Encoding categorical data\r\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\r\nlabelencoder_X = LabelEncoder()\r\nX[ : , 0] = labelencoder_X.fit_transform(X[ : , 0])\r\n#Creating a dummy variable\r\nonehotencoder = OneHotEncoder(categorical_features = [0])\r\nX = onehotencoder.fit_transform(X).toarray()\r\nlabelencoder_Y = LabelEncoder()\r\nY =  labelencoder_Y.fit_transform(Y)\r\nprint(""---------------------"")\r\nprint(""Step 4: Encoding categorical data"")\r\nprint(""X"")\r\nprint(X)\r\nprint(""Y"")\r\nprint(Y)\r\n\r\n#Step 5: Splitting the datasets into training sets and Test sets\r\nfrom sklearn.model_selection import train_test_split\r\nX_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.2, random_state = 0)\r\nprint(""---------------------"")\r\nprint(""Step 5: Splitting the datasets into training sets and Test sets"")\r\nprint(""X_train"")\r\nprint(X_train)\r\nprint(""X_test"")\r\nprint(X_test)\r\nprint(""Y_train"")\r\nprint(Y_train)\r\nprint(""Y_test"")\r\nprint(Y_test)\r\n\r\n#Step 6: Feature Scaling\r\nfrom sklearn.preprocessing import StandardScaler\r\nsc_X = StandardScaler()\r\nX_train = sc_X.fit_transform(X_train)\r\nX_test = sc_X.transform(X_test)\r\nprint(""---------------------"")\r\nprint(""Step 6: Feature Scaling"")\r\nprint(""X_train"")\r\nprint(X_train)\r\nprint(""X_test"")\r\nprint(X_test)\r\n'"
Code/Day 25_Decision_Tree.py,0,"b""# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Importing the dataset\ndataset = pd.read_csv('../datasets/Social_Network_Ads.csv')\nX = dataset.iloc[:, [2, 3]].values\ny = dataset.iloc[:, 4].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Fitting Decision Tree Classification to the Training set\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Visualising the Training set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Decision Tree Classification (Training set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()\n\n# Visualising the Test set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Decision Tree Classification (Test set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()\n\n"""
Code/Day 2_Simple_Linear_Regression.py,0,"b""# Data Preprocessing\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndataset = pd.read_csv('../datasets/studentscores.csv')\nX = dataset.iloc[ : ,   : 1 ].values\nY = dataset.iloc[ : , 1 ].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 1/4, random_state = 0) \n\n# Fitting Simple Linear Regression Model to the training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor = regressor.fit(X_train, Y_train)\n\n# Predecting the Result\nY_pred = regressor.predict(X_test)\n\n# Visualising the Training results\nplt.scatter(X_train , Y_train, color = 'red')\nplt.plot(X_train , regressor.predict(X_train), color ='blue')\n\n# Visualizing the test results\nplt.scatter(X_test , Y_test, color = 'red')\nplt.plot(X_test , regressor.predict(X_test), color ='blue')\nplt.show()\n"""
Code/Day 34_Random_Forests.py,0,"b""# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Importing the dataset\ndataset = pd.read_csv('../datasets/Social_Network_Ads.csv')\nX = dataset.iloc[:, [2, 3]].values\ny = dataset.iloc[:, 4].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Fitting Random Forest to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Visualising the Training set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Random Forest Classification (Training set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()\n\n# Visualising the Test set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Random Forest Classification (Test set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()\n\n"""
Code/Day 3_Multiple_Linear_Regression.py,0,"b""# Importing the libraries\nimport pandas as pd\nimport numpy as np\n\n# Importing the dataset\ndataset = pd.read_csv('../datasets/50_Startups.csv')\nX = dataset.iloc[ : , :-1].values\nY = dataset.iloc[ : ,  4 ].values\n\n# Encoding Categorical data\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder = LabelEncoder()\nX[: , 3] = labelencoder.fit_transform(X[ : , 3])\nonehotencoder = OneHotEncoder(categorical_features = [3])\nX = onehotencoder.fit_transform(X).toarray()\n\n# Avoiding Dummy Variable Trap\nX = X[: , 1:]\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n\n# Fitting Multiple Linear Regression to the Training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, Y_train)\n\n# Predicting the Test set results\ny_pred = regressor.predict(X_test)\n\n# regression evaluation\nfrom sklearn.metrics import r2_score\nprint(r2_score(Y_test, y_pred))\n"""
Code/Day 6_Logistic_Regression.py,0,"b""# Importing the Libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Importing the dataset\ndataset = pd.read_csv('../datasets/Social_Network_Ads.csv')\nX = dataset.iloc[:, [2, 3]].values\ny = dataset.iloc[:, 4].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Fitting Logistic Regression to the Training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression()\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)  # print confusion_matrix\nprint(classification_report(y_test, y_pred))   # print classification report\n\n#Visualization\nfrom matplotlib.colors import ListedColormap\nX_set,y_set=X_train,y_train\nX1,X2=np. meshgrid(np. arange(start=X_set[:,0].min()-1, stop=X_set[:, 0].max()+1, step=0.01),\n                   np. arange(start=X_set[:,1].min()-1, stop=X_set[:,1].max()+1, step=0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(),X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(),X1.max())\nplt.ylim(X2.min(),X2.max())\nfor i,j in enumerate(np. unique(y_set)):\n    plt.scatter(X_set[y_set==j,0],X_set[y_set==j,1],\n                c = ListedColormap(('red', 'green'))(i), label=j)\n\nplt. title(' LOGISTIC(Training set)')\nplt. xlabel(' Age')\nplt. ylabel(' Estimated Salary')\nplt. legend()\nplt. show()\n\nX_set,y_set=X_test,y_test\nX1,X2=np. meshgrid(np. arange(start=X_set[:,0].min()-1, stop=X_set[:, 0].max()+1, step=0.01),\n                   np. arange(start=X_set[:,1].min()-1, stop=X_set[:,1].max()+1, step=0.01))\n\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(),X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(),X1.max())\nplt.ylim(X2.min(),X2.max())\nfor i,j in enumerate(np. unique(y_set)):\n    plt.scatter(X_set[y_set==j,0],X_set[y_set==j,1],\n                c = ListedColormap(('red', 'green'))(i), label=j)\n\nplt. title(' LOGISTIC(Test set)')\nplt. xlabel(' Age')\nplt. ylabel(' Estimated Salary')\nplt. legend()\nplt. show()\n"""
Code/KafkaProducer.py,0,"b'#!/usr/bin/python\n\nfrom kafka import KafkaProducer\n\nkafkaHosts=[""kafka01.paas.longfor.sit:9092""\n            ,""kafka02.paas.longfor.sit:9092""\n            ,""kafka03.paas.longfor.sit:9092""]\n\nproducer = KafkaProducer(bootstrap_servers=kafkaHosts);\n\nfor _ in range(20):\n    producer.send(""testapplog_plm-prototype"",b""Hello...."")\nproducer.flush();'"
Code/TestKafka.py,0,"b'#!/usr/bin/python\n\nfrom kafka import KafkaConsumer;\n\n\nkafkaHosts=[""kafka01.paas.longfor.sit:9092""\n            ,""kafka02.paas.longfor.sit:9092""\n            ,""kafka03.paas.longfor.sit:9092""]\n\n\'\'\'\nearliest \n\xe5\xbd\x93\xe5\x90\x84\xe5\x88\x86\xe5\x8c\xba\xe4\xb8\x8b\xe6\x9c\x89\xe5\xb7\xb2\xe6\x8f\x90\xe4\xba\xa4\xe7\x9a\x84offset\xe6\x97\xb6\xef\xbc\x8c\xe4\xbb\x8e\xe6\x8f\x90\xe4\xba\xa4\xe7\x9a\x84offset\xe5\xbc\x80\xe5\xa7\x8b\xe6\xb6\x88\xe8\xb4\xb9\xef\xbc\x9b\xe6\x97\xa0\xe6\x8f\x90\xe4\xba\xa4\xe7\x9a\x84offset\xe6\x97\xb6\xef\xbc\x8c\xe4\xbb\x8e\xe5\xa4\xb4\xe5\xbc\x80\xe5\xa7\x8b\xe6\xb6\x88\xe8\xb4\xb9 \nlatest \n\xe5\xbd\x93\xe5\x90\x84\xe5\x88\x86\xe5\x8c\xba\xe4\xb8\x8b\xe6\x9c\x89\xe5\xb7\xb2\xe6\x8f\x90\xe4\xba\xa4\xe7\x9a\x84offset\xe6\x97\xb6\xef\xbc\x8c\xe4\xbb\x8e\xe6\x8f\x90\xe4\xba\xa4\xe7\x9a\x84offset\xe5\xbc\x80\xe5\xa7\x8b\xe6\xb6\x88\xe8\xb4\xb9\xef\xbc\x9b\xe6\x97\xa0\xe6\x8f\x90\xe4\xba\xa4\xe7\x9a\x84offset\xe6\x97\xb6\xef\xbc\x8c\xe6\xb6\x88\xe8\xb4\xb9\xe6\x96\xb0\xe4\xba\xa7\xe7\x94\x9f\xe7\x9a\x84\xe8\xaf\xa5\xe5\x88\x86\xe5\x8c\xba\xe4\xb8\x8b\xe7\x9a\x84\xe6\x95\xb0\xe6\x8d\xae \nnone \ntopic\xe5\x90\x84\xe5\x88\x86\xe5\x8c\xba\xe9\x83\xbd\xe5\xad\x98\xe5\x9c\xa8\xe5\xb7\xb2\xe6\x8f\x90\xe4\xba\xa4\xe7\x9a\x84offset\xe6\x97\xb6\xef\xbc\x8c\xe4\xbb\x8eoffset\xe5\x90\x8e\xe5\xbc\x80\xe5\xa7\x8b\xe6\xb6\x88\xe8\xb4\xb9\xef\xbc\x9b\xe5\x8f\xaa\xe8\xa6\x81\xe6\x9c\x89\xe4\xb8\x80\xe4\xb8\xaa\xe5\x88\x86\xe5\x8c\xba\xe4\xb8\x8d\xe5\xad\x98\xe5\x9c\xa8\xe5\xb7\xb2\xe6\x8f\x90\xe4\xba\xa4\xe7\x9a\x84offset\xef\xbc\x8c\xe5\x88\x99\xe6\x8a\x9b\xe5\x87\xba\xe5\xbc\x82\xe5\xb8\xb8\n\'\'\'\nconsumer = KafkaConsumer(\n    bootstrap_servers=kafkaHosts,group_id=\'mdf_group\',auto_offset_reset=\'latest\');\n\nconsumer.subscribe(""testapplog_plm-prototype"");\n\nfor msg in consumer:\n    print(msg.value)'"
Code/my/LinerTest.py,0,"b""import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndataset = pd.read_csv('Data_age_salary.csv');\ndataset.iloc[:1]"""
