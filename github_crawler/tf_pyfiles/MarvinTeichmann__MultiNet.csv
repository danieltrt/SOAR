file_path,api_count,code
demo.py,9,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n#\n# Author: Marvin Teichmann\n\n\n""""""\nDetects Cars in an image using KittiSeg.\n\nInput: Image\nOutput: Image (with Cars plotted in Green)\n\nUtilizes: Trained KittiSeg weights. If no logdir is given,\npretrained weights will be downloaded and used.\n\nUsage:\npython demo.py --input data/demo.png [--output_image output_image]\n                [--logdir /path/to/weights] [--gpus 0]\n\n\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport logging\nimport os\nimport sys\n\nimport collections\n\n# configure logging\n\nlogging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                    level=logging.INFO,\n                    stream=sys.stdout)\n\n# https://github.com/tensorflow/tensorflow/issues/2034#issuecomment-220820070\nimport numpy as np\nimport scipy as scp\nimport scipy.misc\nimport tensorflow as tf\n\nimport time\n\nfrom PIL import Image, ImageDraw, ImageFont\n\n\nflags = tf.app.flags\nFLAGS = flags.FLAGS\n\nsys.path.insert(1, \'incl\')\n\ntry:\n    # Check whether setup was done correctly\n\n    import tensorvision.utils as tv_utils\n    import tensorvision.core as core\nexcept ImportError:\n    # You forgot to initialize submodules\n    logging.error(""Could not import the submodules."")\n    logging.error(""Please execute:""\n                  ""\'git submodule update --init --recursive\'"")\n    exit(1)\n\n\nflags.DEFINE_string(\'logdir\', None,\n                    \'Path to logdir.\')\nflags.DEFINE_string(\'input\', None,\n                    \'Image to apply KittiSeg.\')\nflags.DEFINE_string(\'output\', None,\n                    \'Image to apply KittiSeg.\')\n\n\ndefault_run = \'MultiNet_ICCV\'\nweights_url = (""ftp://mi.eng.cam.ac.uk/""\n               ""pub/mttt2/models/MultiNet_ICCV.zip"")\n\n\ndef maybe_download_and_extract(runs_dir):\n    logdir = os.path.join(runs_dir, default_run)\n\n    if os.path.exists(logdir):\n        # weights are downloaded. Nothing to do\n        return\n\n    if not os.path.exists(runs_dir):\n        os.makedirs(runs_dir)\n        # weights are downloaded. Nothing to do\n\n    import zipfile\n    download_name = tv_utils.download(weights_url, runs_dir)\n\n    logging.info(""Extracting MultiNet_pretrained.zip"")\n\n    zipfile.ZipFile(download_name, \'r\').extractall(runs_dir)\n\n    return\n\n\ndef resize_label_image(image, gt_image, image_height, image_width):\n    image = scp.misc.imresize(image, size=(image_height, image_width),\n                              interp=\'cubic\')\n    shape = gt_image.shape\n    gt_image = scp.misc.imresize(gt_image, size=(image_height, image_width),\n                                 interp=\'nearest\')\n\n    return image, gt_image\n\n\ndef _output_generator(sess, tensor_list, image_pl, data_file,\n                      process_image=lambda x: x):\n    image_dir = os.path.dirname(data_file)\n    with open(data_file) as file:\n        for datum in file:\n            datum = datum.rstrip()\n            image_file = datum.split("" "")[0]\n            image_file = os.path.join(image_dir, image_file)\n\n            image = scp.misc.imread(image_file)\n\n            image = process_image(image)\n\n            feed_dict = {image_pl: image}\n            start_time = time.time()\n            output = sess.run(tensor_list, feed_dict=feed_dict)\n            yield image_file, output\n\n\ndef eval_runtime(sess, subhypes, image_pl, eval_list, data_file):\n    logging.info(\' \')\n    logging.info(\'Evaluation complete. Measuring runtime.\')\n    image_dir = os.path.dirname(data_file)\n    with open(data_file) as file:\n        for datum in file:\n            datum = datum.rstrip()\n    image_file = datum.split("" "")[0]\n    image_file = os.path.join(image_dir, image_file)\n    image = scp.misc.imread(image_file)\n    image = process_image(subhypes, image)\n    feed = {image_pl: image}\n    for i in xrange(100):\n        _ = sess.run(eval_list, feed_dict=feed)\n    start_time = time.time()\n    for i in xrange(100):\n        _ = sess.run(eval_list, feed_dict=feed)\n    dt = (time.time() - start_time)/100\n    logging.info(\'Joined inference can be conducted at the following rates on\'\n                 \' your machine:\')\n    logging.info(\'Speed (msec): %f \', 1000*dt)\n    logging.info(\'Speed (fps): %f \', 1/dt)\n    return dt\n\n\ndef test_constant_input(subhypes):\n    road_input_conf = subhypes[\'road\'][\'jitter\']\n    seg_input_conf = subhypes[\'segmentation\'][\'jitter\']\n    car_input_conf = subhypes[\'detection\']\n\n    gesund = True \\\n        and road_input_conf[\'image_width\'] == seg_input_conf[\'image_width\'] \\\n        and road_input_conf[\'image_height\'] == seg_input_conf[\'image_height\'] \\\n        and car_input_conf[\'image_width\'] == seg_input_conf[\'image_width\'] \\\n        and car_input_conf[\'image_height\'] == seg_input_conf[\'image_height\'] \\\n\n    if not gesund:\n        logging.error(""The different tasks are training""\n                      ""using different resolutions. Please retrain all tasks,""\n                      ""using the same resolution."")\n        exit(1)\n    return\n\n\ndef test_segmentation_input(subhypes):\n\n    if not subhypes[\'segmentation\'][\'jitter\'][\'reseize_image\']:\n        logging.error(\'\')\n        logging.error(""Issue with Segmentation input handling."")\n        logging.error(""Segmentation input will be resized during this""\n                      ""evaluation, but was not resized during training."")\n        logging.error(""This will lead to bad results."")\n        logging.error(""To use this script please train segmentation using""\n                      ""the configuration:."")\n        logging.error(""""""\n{\n    ""jitter"": {\n    ""reseize_image"": true,\n    ""image_height"" : 384,\n    ""image_width"" : 1248,\n    },\n}"""""")\n        logging.error(""Alternatively implement evaluation using non-resized""\n                      "" input."")\n        exit(1)\n    return\n\n\ndef road_draw(image, highway):\n    im = Image.fromarray(image.astype(\'uint8\'))\n    draw = ImageDraw.Draw(im)\n\n    fnt = ImageFont.truetype(\'FreeMono/FreeMonoBold.ttf\', 40)\n\n    shape = image.shape\n\n    if highway:\n        draw.text((65, 10), ""Highway"",\n                  font=fnt, fill=(255, 255, 0, 255))\n\n        draw.ellipse([10, 10, 55, 55], fill=(255, 255, 0, 255),\n                     outline=(255, 255, 0, 255))\n    else:\n        draw.text((65, 10), ""minor road"",\n                  font=fnt, fill=(255, 0, 0, 255))\n\n        draw.ellipse([10, 10, 55, 55], fill=(255, 0, 0, 255),\n                     outline=(255, 0, 0, 255))\n\n    return np.array(im).astype(\'float32\')\n\n\ndef process_image(subhypes, image):\n    hypes = subhypes[\'road\']\n    shape = image.shape\n    image_height = hypes[\'jitter\'][\'image_height\']\n    image_width = hypes[\'jitter\'][\'image_width\']\n    assert(image_height >= shape[0])\n    assert(image_width >= shape[1])\n\n    image = scp.misc.imresize(image, (image_height,\n                                      image_width, 3),\n                              interp=\'cubic\')\n    return image\n\n\ndef load_united_model(logdir):\n    subhypes = {}\n    subgraph = {}\n    submodules = {}\n    subqueues = {}\n\n    first_iter = True\n\n    meta_hypes = tv_utils.load_hypes_from_logdir(logdir, subdir="""",\n                                                 base_path=\'hypes\')\n    for model in meta_hypes[\'models\']:\n        subhypes[model] = tv_utils.load_hypes_from_logdir(logdir, subdir=model)\n        hypes = subhypes[model]\n        hypes[\'dirs\'][\'output_dir\'] = meta_hypes[\'dirs\'][\'output_dir\']\n        hypes[\'dirs\'][\'image_dir\'] = meta_hypes[\'dirs\'][\'image_dir\']\n        submodules[model] = tv_utils.load_modules_from_logdir(logdir,\n                                                              dirname=model,\n                                                              postfix=model)\n\n        modules = submodules[model]\n\n    image_pl = tf.placeholder(tf.float32)\n    image = tf.expand_dims(image_pl, 0)\n    image.set_shape([1, 384, 1248, 3])\n    decoded_logits = {}\n    for model in meta_hypes[\'models\']:\n        hypes = subhypes[model]\n        modules = submodules[model]\n        optimizer = modules[\'solver\']\n\n        with tf.name_scope(\'Validation_%s\' % model):\n            reuse = {True: False, False: True}[first_iter]\n\n            scope = tf.get_variable_scope()\n\n            with tf.variable_scope(scope, reuse=reuse):\n                logits = modules[\'arch\'].inference(hypes, image, train=False)\n\n            decoded_logits[model] = modules[\'objective\'].decoder(hypes, logits,\n                                                                 train=False)\n\n        first_iter = False\n    sess = tf.Session()\n    saver = tf.train.Saver()\n    cur_step = core.load_weights(logdir, sess, saver)\n\n    return meta_hypes, subhypes, submodules, decoded_logits, sess, image_pl\n\n\ndef main(_):\n    tv_utils.set_gpus_to_use()\n\n    if FLAGS.input is None:\n        logging.error(""No input was given."")\n        logging.info(\n            ""Usage: python demo.py --input data/test.png ""\n            ""[--output_image output_image] [--logdir /path/to/weights] ""\n            ""[--gpus GPUs_to_use] "")\n        exit(1)\n\n    if FLAGS.logdir is None:\n        # Download and use weights from the MultiNet Paper\n        if \'TV_DIR_RUNS\' in os.environ:\n            runs_dir = os.path.join(os.environ[\'TV_DIR_RUNS\'],\n                                    \'MultiNet\')\n        else:\n            runs_dir = \'RUNS\'\n        maybe_download_and_extract(runs_dir)\n        logdir = os.path.join(runs_dir, default_run)\n    else:\n        logging.info(""Using weights found in {}"".format(FLAGS.logdir))\n        logdir = FLAGS.logdir\n\n    logging.info(""Loading model from: {}"".format(logdir))\n\n    # Loads the model from rundir\n    load_out = load_united_model(logdir)\n\n    # Create list of relevant tensors to evaluate\n    meta_hypes, subhypes, submodules, decoded_logits, sess, image_pl = load_out\n\n    seg_softmax = decoded_logits[\'segmentation\'][\'softmax\']\n    pred_boxes_new = decoded_logits[\'detection\'][\'pred_boxes_new\']\n    pred_confidences = decoded_logits[\'detection\'][\'pred_confidences\']\n    if len(meta_hypes[\'model_list\']) == 3:\n        road_softmax = decoded_logits[\'road\'][\'softmax\'][0]\n    else:\n        road_softmax = None\n\n    eval_list = [seg_softmax, pred_boxes_new, pred_confidences, road_softmax]\n\n    # Run some tests on the hypes\n    test_constant_input(subhypes)\n    test_segmentation_input(subhypes)\n\n    # Load and reseize Image\n    image_file = FLAGS.input\n    image = scp.misc.imread(image_file)\n\n    hypes_road = subhypes[\'road\']\n    shape = image.shape\n    image_height = hypes_road[\'jitter\'][\'image_height\']\n    image_width = hypes_road[\'jitter\'][\'image_width\']\n    assert(image_height >= shape[0])\n    assert(image_width >= shape[1])\n\n    image = scp.misc.imresize(image, (image_height,\n                                      image_width, 3),\n                              interp=\'cubic\')\n\n    import utils.train_utils as dec_utils\n\n    # Run KittiSeg model on image\n    feed_dict = {image_pl: image}\n    output = sess.run(eval_list, feed_dict=feed_dict)\n\n    seg_softmax, pred_boxes_new, pred_confidences, road_softmax = output\n\n    # Create Segmentation Overlay\n    shape = image.shape\n    seg_softmax = seg_softmax[:, 1].reshape(shape[0], shape[1])\n    hard = seg_softmax > 0.5\n    overlay_image = tv_utils.fast_overlay(image, hard)\n\n    # Draw Detection Boxes\n    new_img, rects = dec_utils.add_rectangles(\n        subhypes[\'detection\'], [overlay_image], pred_confidences,\n        pred_boxes_new, show_removed=False,\n        use_stitching=True, rnn_len=subhypes[\'detection\'][\'rnn_len\'],\n        min_conf=0.50, tau=subhypes[\'detection\'][\'tau\'])\n\n    # Draw road classification\n    highway = (np.argmax(road_softmax) == 1)\n    new_img = road_draw(new_img, highway)\n\n    logging.info("""")\n\n    # Printing some more output information\n    threshold = 0.5\n    accepted_predictions = []\n    # removing predictions <= threshold\n    for rect in rects:\n        if rect.score >= threshold:\n            accepted_predictions.append(rect)\n\n    print(\'\')\n    logging.info(""{} Cars detected"".format(len(accepted_predictions)))\n\n    # Printing coordinates of predicted rects.\n    for i, rect in enumerate(accepted_predictions):\n        logging.info("""")\n        logging.info(""Coordinates of Box {}"".format(i))\n        logging.info(""    x1: {}"".format(rect.x1))\n        logging.info(""    x2: {}"".format(rect.x2))\n        logging.info(""    y1: {}"".format(rect.y1))\n        logging.info(""    y2: {}"".format(rect.y2))\n        logging.info(""    Confidence: {}"".format(rect.score))\n\n    if len(meta_hypes[\'model_list\']) == 3:\n        logging.info(""Raw Classification Softmax outputs are: {}""\n                     .format(output[0][0]))\n\n    # Save output image file\n    if FLAGS.output is None:\n        output_base_name = FLAGS.input\n        out_image_name = output_base_name.split(\'.\')[0] + \'_out.png\'\n    else:\n        out_image_name = FLAGS.output\n\n    scp.misc.imsave(out_image_name, new_img)\n\n    logging.info("""")\n    logging.info(""Output image has been saved to: {}"".format(\n        os.path.realpath(out_image_name)))\n\n    logging.info("""")\n    logging.warning(""Do NOT use this Code to evaluate multiple images."")\n\n    logging.warning(""Demo.py is **very slow** and designed ""\n                    ""to be a tutorial to show how the MultiNet works."")\n    logging.warning("""")\n    logging.warning(""Please see this comment, if you like to apply demo.py to""\n                    "" multiple images see:"")\n    logging.warning(""https://github.com/MarvinTeichmann/KittiBox/""\n                    ""issues/15#issuecomment-301800058"")\n\n    exit(0)\n\nif __name__ == \'__main__\':\n    tf.app.run()\n'"
download_data.py,0,"b'""""""Download data relevant to train the KittiSeg model.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport logging\nimport sys\nimport os\nimport subprocess\n\nimport zipfile\n\n\nfrom six.moves import urllib\nfrom shutil import copy2\n\nimport argparse\n\nlogging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                    level=logging.INFO,\n                    stream=sys.stdout)\n\nsys.path.insert(1, \'incl\')\n\n# Please set kitti_data_url to the download link for the Kitti DATA.\n#\n# You can obtain by going to this website:\n# http://www.cvlibs.net/download.php?file=data_road.zip\n#\n# Replace \'http://kitti.is.tue.mpg.de/kitti/?????????.???\' by the\n# correct URL.\n\n\nvgg_url = \'ftp://mi.eng.cam.ac.uk/pub/mttt2/models/vgg16.npy\'\n\ncopyfiles = [""train_2.idl"", ""train_3.idl"", ""train_4.idl"",\n             ""val_2.idl"", ""val_3.idl"", ""val_4.idl"",\n             ""train.txt"", ""val.txt"", ""testing.txt"", ""train3.txt"", ""val3.txt""]\n\ncopydirs = [""KittiBox"", ""KittiBox"", ""KittiBox"",\n            ""KittiBox"", ""KittiBox"", ""KittiBox"",\n            ""KittiBox"", ""KittiBox"", ""data_road"", ""data_road"", ""data_road""]\n\nkitti_download_files = [""data_object_image_2.zip"", ""data_object_label_2.zip"",\n                        ""data_road.zip""]\n\ndata_sub_dirs = [""KittiBox"", ""KittiBox"", """"]\n\n\ndef get_pathes():\n    """"""\n    Get location of `data_dir` and `run_dir\'.\n\n    Defaut is ./DATA and ./RUNS.\n    Alternativly they can be set by the environoment variabels\n    \'TV_DIR_DATA\' and \'TV_DIR_RUNS\'.\n    """"""\n\n    if \'TV_DIR_DATA\' in os.environ:\n        data_dir = os.path.join([\'hypes\'], os.environ[\'TV_DIR_DATA\'])\n    else:\n        data_dir = ""DATA""\n\n    if \'TV_DIR_RUNS\' in os.environ:\n        run_dir = os.path.join([\'hypes\'], os.environ[\'TV_DIR_DATA\'])\n    else:\n        run_dir = ""RUNS""\n\n    return data_dir, run_dir\n\n\ndef download(url, dest_directory):\n    filename = url.split(\'/\')[-1]\n    filepath = os.path.join(dest_directory, filename)\n\n    logging.info(""   Download URL: {}"".format(url))\n    logging.info(""   Download DIR: {}"".format(dest_directory))\n\n    def _progress(count, block_size, total_size):\n                prog = float(count * block_size) / float(total_size) * 100.0\n                sys.stdout.write(\'\\r>> Downloading %s %.1f%%\' %\n                                 (filename, prog))\n                sys.stdout.flush()\n\n    filepath, _ = urllib.request.urlretrieve(url, filepath,\n                                             reporthook=_progress)\n    print()\n    return filepath\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--kitti_url\', default=\'\', type=str)\n    args = parser.parse_args()\n\n    kitti_data_url = args.kitti_url\n\n    data_dir, run_dir = get_pathes()\n\n    if not os.path.exists(data_dir):\n            os.makedirs(data_dir)\n\n    vgg_weights = os.path.join(data_dir, \'vgg16.npy\')\n\n    # Download VGG DATA\n    if not os.path.exists(vgg_weights):\n        download_command = ""wget {} -P {}"".format(vgg_url, data_dir)\n        logging.info(""Downloading VGG weights."")\n        download(vgg_url, data_dir)\n    else:\n        logging.warning(""File: {} exists."".format(vgg_weights))\n        logging.warning(""Please delete to redownload VGG weights."")\n\n    # Checking whether the user provides an URL\n    if kitti_data_url == \'\':\n        logging.error(""Data URL for Kitti Data not provided."")\n        url = ""http://www.cvlibs.net/download.php?file=data_road.zip""\n        logging.error(""Please visit: {}"".format(url))\n        logging.error(""and request Kitti Download link."")\n        logging.error(""Rerun scrpt using""\n                      ""\'python download_data.py --kitti_url [url]\'"")\n        exit(1)\n\n    # Copy txt files\n    for file, subdir in zip(copyfiles, copydirs):\n        filename = os.path.join(\'data\', file)\n        target_dir = os.path.join(data_dir, subdir)\n        if not os.path.exists(target_dir):\n            os.makedirs(target_dir)\n        copy2(filename, target_dir)\n        logging.info(""Copied {} to {}."".format(filename, target_dir))\n\n    # Checking whether the user provides the correct URL\n    if not kitti_data_url[13:33] == \'is.tue.mpg.de/kitti/\':\n        logging.error(""Wrong url."")\n        url = ""http://www.cvlibs.net/download.php?file=data_road.zip""\n        logging.error(""Please visit: {}"".format(url))\n        logging.error(""and request Kitti Download link."")\n        logging.error(""You will receive an Email with the kitti download url"")\n        logging.error(""Rerun and enter the received [url] using""\n                      ""\'python download_data.py --kitti_url [url]\'"")\n        exit(1)\n\n    for zip_file, subdir in zip(kitti_download_files, data_sub_dirs):\n        # Get name of downloaded zip file\n        file_dir = os.path.join(data_dir, subdir)\n        # Creating dirs if nessasary\n        if not os.path.exists(file_dir):\n            os.makedirs(file_dir)\n        final_file = os.path.join(file_dir, zip_file)\n        # Check whether file exists\n        if os.path.exists(final_file):\n            logging.info(""File exists: {}"".format(final_file))\n            logging.info(""Skipping Download and extraction."")\n            logging.info(""Remove: {} if you wish to download that data again.""\n                         .format(final_file))\n            logging.info()\n            continue\n        # Make Kitti_URL\n        kitti_main = os.path.dirname(kitti_data_url)\n        kitti_zip_url = os.path.join(kitti_main, zip_file)\n        kitti_zip_url = os.path.join(kitti_main,\n                                     os.path.basename(zip_file))\n        logging.info(""Starting to download: {}"".format(zip_file))\n        download(kitti_zip_url, file_dir)\n        logging.info(""Extracting: {}"".format(final_file))\n        zipfile.ZipFile(final_file, \'r\').extractall(file_dir)\n\n    logging.info(""All data have been downloaded successful."")\n\n\nif __name__ == \'__main__\':\n    main()\n'"
predict_joint.py,8,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n""""""\nRuns MultiNet on a whole bunch of input images.\n\n\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport logging\nimport os\nimport sys\n\n# configure logging\nif \'TV_IS_DEV\' in os.environ and os.environ[\'TV_IS_DEV\']:\n    logging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                        level=logging.INFO,\n                        stream=sys.stdout)\nelse:\n    logging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                        level=logging.INFO,\n                        stream=sys.stdout)\n\n# https://github.com/tensorflow/tensorflow/issues/2034#issuecomment-220820070\nimport scipy as scp\nimport scipy.misc\nimport numpy as np\nimport tensorflow as tf\n\nimport time\n\nflags = tf.app.flags\nFLAGS = flags.FLAGS\n\nsys.path.insert(1, os.path.realpath(\'incl\'))\n\n\nimport train as united_train\n\nimport tensorvision.train as train\nimport tensorvision.utils as utils\nimport tensorvision.core as core\nfrom PIL import Image, ImageDraw, ImageFont\n\nflags.DEFINE_string(\'data\',\n                    ""data_road/testing.txt"",\n                    \'Text file containing images.\')\n\nflags.DEFINE_bool(\'speed_test\',\n                  False,\n                  \'Only measure inference speed.\')\n\nres_folder = \'results\'\n\n\ndef _output_generator(sess, tensor_list, image_pl, data_file,\n                      process_image=lambda x: x):\n    image_dir = os.path.dirname(data_file)\n    with open(data_file) as file:\n        for datum in file:\n            datum = datum.rstrip()\n            image_file = datum.split("" "")[0]\n            image_file = os.path.join(image_dir, image_file)\n\n            image = scp.misc.imread(image_file)\n\n            image = process_image(image)\n\n            feed_dict = {image_pl: image}\n            start_time = time.time()\n            output = sess.run(tensor_list, feed_dict=feed_dict)\n            yield image_file, output\n\n\ndef eval_runtime(sess, subhypes, image_pl, eval_list, data_file):\n    logging.info(\' \')\n    logging.info(\'Evaluation complete. Measuring runtime.\')\n    image_dir = os.path.dirname(data_file)\n    with open(data_file) as file:\n        for datum in file:\n            datum = datum.rstrip()\n    image_file = datum.split("" "")[0]\n    image_file = os.path.join(image_dir, image_file)\n    image = scp.misc.imread(image_file)\n    image = process_image(subhypes, image)\n    feed = {image_pl: image}\n    sess.run(eval_list, feed_dict=feed)\n    sess.run(eval_list, feed_dict=feed)\n    sess.run(eval_list, feed_dict=feed)\n    for i in xrange(100):\n        _ = sess.run(eval_list, feed_dict=feed)\n    start_time = time.time()\n    for i in xrange(100):\n        _ = sess.run(eval_list, feed_dict=feed)\n    dt = (time.time() - start_time)/100\n    logging.info(\'Joined inference can be conducted at the following rates on\'\n                 \' your machine:\')\n    logging.info(\'Speed (msec): %f \', 1000*dt)\n    logging.info(\'Speed (fps): %f \', 1/dt)\n    return dt\n\n\ndef test_constant_input(subhypes):\n    road_input_conf = subhypes[\'road\'][\'jitter\']\n    seg_input_conf = subhypes[\'segmentation\'][\'jitter\']\n    car_input_conf = subhypes[\'detection\']\n\n    gesund = True \\\n        and road_input_conf[\'image_width\'] == seg_input_conf[\'image_width\'] \\\n        and road_input_conf[\'image_height\'] == seg_input_conf[\'image_height\'] \\\n        and car_input_conf[\'image_width\'] == seg_input_conf[\'image_width\'] \\\n        and car_input_conf[\'image_height\'] == seg_input_conf[\'image_height\'] \\\n\n    if not gesund:\n        logging.error(""The different tasks are training""\n                      ""using different resolutions. Please retrain all tasks,""\n                      ""using the same resolution."")\n        exit(1)\n    return\n\n\ndef test_segmentation_input(subhypes):\n\n    if not subhypes[\'segmentation\'][\'jitter\'][\'reseize_image\']:\n        logging.error(\'\')\n        logging.error(""Issue with Segmentation input handling."")\n        logging.error(""Segmentation input will be resized during this""\n                      ""evaluation, but was not resized during training."")\n        logging.error(""This will lead to bad results."")\n        logging.error(""To use this script please train segmentation using""\n                      ""the configuration:."")\n        logging.error(""""""\n{\n    ""jitter"": {\n    ""reseize_image"": true,\n    ""image_height"" : 384,\n    ""image_width"" : 1248,\n    },\n}"""""")\n        logging.error(""Alternatively implement evaluation using non-resized""\n                      "" input."")\n        exit(1)\n    return\n\n\ndef road_draw(image, highway):\n    im = Image.fromarray(image.astype(\'uint8\'))\n    draw = ImageDraw.Draw(im)\n\n    fnt = ImageFont.truetype(\'FreeMono/FreeMonoBold.ttf\', 40)\n\n    shape = image.shape\n\n    if highway:\n        draw.text((65, 10), ""Highway"",\n                  font=fnt, fill=(255, 255, 0, 255))\n\n        draw.ellipse([10, 10, 55, 55], fill=(255, 255, 0, 255),\n                     outline=(255, 255, 0, 255))\n    else:\n        draw.text((65, 10), ""minor road"",\n                  font=fnt, fill=(255, 0, 0, 255))\n\n        draw.ellipse([10, 10, 55, 55], fill=(255, 0, 0, 255),\n                     outline=(255, 0, 0, 255))\n\n    return np.array(im).astype(\'float32\')\n\n\ndef run_eval(load_out, output_folder, data_file):\n    meta_hypes, subhypes, submodules, decoded_logits, sess, image_pl = load_out\n    assert(len(meta_hypes[\'model_list\']) == 3)\n    # inf_out[\'pred_boxes_new\'], inf_out[\'pred_confidences\']\n    seg_softmax = decoded_logits[\'segmentation\'][\'softmax\']\n    pred_boxes_new = decoded_logits[\'detection\'][\'pred_boxes_new\']\n    pred_confidences = decoded_logits[\'detection\'][\'pred_confidences\']\n    road_softmax = decoded_logits[\'road\'][\'softmax\'][0]\n    eval_list = [seg_softmax, pred_boxes_new, pred_confidences, road_softmax]\n\n    def my_process(image):\n        return process_image(subhypes, image)\n\n    if FLAGS.speed_test:\n        eval_runtime(sess, subhypes, image_pl, eval_list, data_file)\n        exit(0)\n\n    test_constant_input(subhypes)\n    test_segmentation_input(subhypes)\n\n    import utils.train_utils as dec_utils\n\n    gen = _output_generator(sess, eval_list, image_pl, data_file, my_process)\n    for image_file, output in gen:\n        image = scp.misc.imread(image_file)\n        image = process_image(subhypes, image)\n        shape = image.shape\n        seg_softmax, pred_boxes_new, pred_confidences, road_softmax = output\n\n        # Create Segmentation Overlay\n        shape = image.shape\n        seg_softmax = seg_softmax[:, 1].reshape(shape[0], shape[1])\n        hard = seg_softmax > 0.5\n        overlay_image = utils.fast_overlay(image, hard)\n\n        # Draw Detection Boxes\n        new_img, rects = dec_utils.add_rectangles(\n            subhypes[\'detection\'], [overlay_image], pred_confidences,\n            pred_boxes_new, show_removed=False,\n            use_stitching=True, rnn_len=subhypes[\'detection\'][\'rnn_len\'],\n            min_conf=0.50, tau=subhypes[\'detection\'][\'tau\'])\n\n        # Draw road classification\n        highway = (np.argmax(road_softmax) == 1)\n        new_img = road_draw(new_img, highway)\n\n        # Save image file\n        im_name = os.path.basename(image_file)\n        new_im_file = os.path.join(output_folder, im_name)\n        im_name = os.path.basename(image_file)\n        new_im_file = os.path.join(output_folder, im_name)\n        scp.misc.imsave(new_im_file, new_img)\n\n        logging.info(""Plotting file: {}"".format(new_im_file))\n\n    eval_runtime(sess, subhypes, image_pl, eval_list, data_file)\n    exit(0)\n\n\ndef process_image(subhypes, image):\n    hypes = subhypes[\'road\']\n    shape = image.shape\n    image_height = hypes[\'jitter\'][\'image_height\']\n    image_width = hypes[\'jitter\'][\'image_width\']\n    assert(image_height >= shape[0])\n    assert(image_width >= shape[1])\n\n    image = scp.misc.imresize(image, (image_height,\n                                      image_width, 3),\n                              interp=\'cubic\')\n    return image\n\n\ndef load_united_model(logdir):\n    subhypes = {}\n    subgraph = {}\n    submodules = {}\n    subqueues = {}\n\n    first_iter = True\n\n    meta_hypes = utils.load_hypes_from_logdir(logdir, subdir="""",\n                                              base_path=\'hypes\')\n    for model in meta_hypes[\'models\']:\n        subhypes[model] = utils.load_hypes_from_logdir(logdir, subdir=model)\n        hypes = subhypes[model]\n        hypes[\'dirs\'][\'output_dir\'] = meta_hypes[\'dirs\'][\'output_dir\']\n        hypes[\'dirs\'][\'image_dir\'] = meta_hypes[\'dirs\'][\'image_dir\']\n        submodules[model] = utils.load_modules_from_logdir(logdir,\n                                                           dirname=model,\n                                                           postfix=model)\n\n        modules = submodules[model]\n\n    image_pl = tf.placeholder(tf.float32)\n    image = tf.expand_dims(image_pl, 0)\n    image.set_shape([1, 384, 1248, 3])\n    decoded_logits = {}\n\n    hypes = subhypes[\'segmentation\']\n    modules = submodules[\'segmentation\']\n    logits = modules[\'arch\'].inference(hypes, image, train=False)\n    for model in meta_hypes[\'models\']:\n        hypes = subhypes[model]\n        modules = submodules[model]\n        optimizer = modules[\'solver\']\n\n        with tf.name_scope(\'Validation_%s\' % model):\n            reuse = {True: False, False: True}[first_iter]\n\n            scope = tf.get_variable_scope()\n\n            decoded_logits[model] = modules[\'objective\'].decoder(hypes, logits,\n                                                                 train=False)\n\n        first_iter = False\n    sess = tf.Session()\n    saver = tf.train.Saver()\n    cur_step = core.load_weights(logdir, sess, saver)\n\n    return meta_hypes, subhypes, submodules, decoded_logits, sess, image_pl\n\n\ndef main(_):\n    utils.set_gpus_to_use()\n\n    logdir = FLAGS.logdir\n    data_file = FLAGS.data\n\n    if logdir is None:\n        logging.error(\'Usage python predict_joint --logdir /path/to/logdir\'\n                      \'--data /path/to/data/txt\')\n        exit(1)\n\n    output_folder = os.path.join(logdir, res_folder)\n\n    if not os.path.exists(output_folder):\n        os.mkdir(output_folder)\n\n    logdir = logdir\n    utils.load_plugins()\n\n    if \'TV_DIR_DATA\' in os.environ:\n        data_file = os.path.join(os.environ[\'TV_DIR_DATA\'], data_file)\n    else:\n        data_file = os.path.join(\'DATA\', data_file)\n\n    if not os.path.exists(data_file):\n        logging.error(\'Please provide a valid data_file.\')\n        logging.error(\'Use --data_file\')\n        exit(1)\n\n    if \'TV_DIR_RUNS\' in os.environ:\n        os.environ[\'TV_DIR_RUNS\'] = os.path.join(os.environ[\'TV_DIR_RUNS\'],\n                                                 \'UnitedVision2\')\n    logging_file = os.path.join(output_folder, ""analysis.log"")\n    utils.create_filewrite_handler(logging_file, mode=\'a\')\n    load_out = load_united_model(logdir)\n\n    run_eval(load_out, output_folder, data_file)\n\n    # stopping input Threads\n\n\nif __name__ == \'__main__\':\n    tf.app.run()\n'"
train.py,33,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n""""""Trains, evaluates and saves the TensorDetect model.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport logging\nimport os\nimport sys\n\nimport scipy as scp\n\n# configure logging\nif \'TV_IS_DEV\' in os.environ and os.environ[\'TV_IS_DEV\']:\n    logging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                        level=logging.INFO,\n                        stream=sys.stdout)\nelse:\n    logging.basicConfig(format=\'%(asctime)s %(levelname)s %(message)s\',\n                        level=logging.INFO,\n                        stream=sys.stdout)\n\n# https://github.com/tensorflow/tensorflow/issues/2034#issuecomment-220820070\nimport numpy as np\nimport tensorflow as tf\n\nflags = tf.app.flags\nFLAGS = flags.FLAGS\n\nsys.path.insert(1, os.path.realpath(\'incl\'))\n\nimport tensorvision.train as train\nimport tensorvision.utils as utils\nimport tensorvision.core as core\n\nimport tensorflow_fcn\n\nimport time\n\nimport random\n\nflags.DEFINE_string(\'name\', None,\n                    \'Append a name Tag to run.\')\n\nflags.DEFINE_string(\'project\', None,\n                    \'Append a name Tag to run.\')\n\nflags.DEFINE_string(\'logdir\', None,\n                    \'Append a name Tag to run.\')\n\nflags.DEFINE_string(\'hypes\', None,\n                    \'File storing model parameters.\')\n\ntf.app.flags.DEFINE_boolean(\n    \'save\', True, (\'Whether to save the run. In case --nosave (default) \'\n                   \'output will be saved to the folder TV_DIR_RUNS/debug, \'\n                   \'hence it will get overwritten by further runs.\'))\n\n\ndef _print_training_status(hypes, step, loss_values, start_time, lr):\n\n    # Prepare printing\n    duration = (time.time() - start_time) / int(utils.cfg.step_show)\n    examples_per_sec = hypes[\'solver\'][\'batch_size\'] / duration\n    sec_per_batch = float(duration)\n\n    if len(loss_values.keys()) >= 2:\n        info_str = (\'Step {step}/{total_steps}: losses = ({loss_value1:.2f}, \'\n                    \'{loss_value2:.2f});\'\n                    \' lr = ({lr_value1:.2e}, {lr_value2:.2e}); \'\n                    \'({sec_per_batch:.3f} sec)\')\n        losses = loss_values.values()\n        lrs = lr.values()\n        logging.info(info_str.format(step=step,\n                                     total_steps=hypes[\'solver\'][\'max_steps\'],\n                                     loss_value1=losses[0],\n                                     loss_value2=losses[1],\n                                     lr_value1=lrs[0],\n                                     lr_value2=lrs[1],\n                                     sec_per_batch=sec_per_batch)\n                     )\n    else:\n        assert(False)\n\n\ndef build_training_graph(hypes, queue, modules, first_iter):\n    """"""\n    Build the tensorflow graph out of the model files.\n\n    Parameters\n    ----------\n    hypes : dict\n        Hyperparameters\n    queue: tf.queue\n        Data Queue\n    modules : tuple\n        The modules load in utils.\n\n    Returns\n    -------\n    tuple\n        (q, train_op, loss, eval_lists) where\n        q is a dict with keys \'train\' and \'val\' which includes queues,\n        train_op is a tensorflow op,\n        loss is a float,\n        eval_lists is a dict with keys \'train\' and \'val\'\n    """"""\n\n    data_input = modules[\'input\']\n    encoder = modules[\'arch\']\n    objective = modules[\'objective\']\n    optimizer = modules[\'solver\']\n\n    reuse = {True: False, False: True}[first_iter]\n\n    scope = tf.get_variable_scope()\n\n    with tf.variable_scope(scope, reuse=reuse):\n\n        learning_rate = tf.placeholder(tf.float32)\n\n        # Add Input Producers to the Graph\n        with tf.name_scope(""Inputs""):\n            image, labels = data_input.inputs(hypes, queue, phase=\'train\')\n\n        # Run inference on the encoder network\n        logits = encoder.inference(hypes, image, train=True)\n\n    # Build decoder on top of the logits\n    decoded_logits = objective.decoder(hypes, logits, train=True)\n\n    # Add to the Graph the Ops for loss calculation.\n    with tf.name_scope(""Loss""):\n        losses = objective.loss(hypes, decoded_logits,\n                                labels)\n\n    # Add to the Graph the Ops that calculate and apply gradients.\n    with tf.name_scope(""Optimizer""):\n        global_step = tf.Variable(0, trainable=False)\n        # Build training operation\n        train_op = optimizer.training(hypes, losses,\n                                      global_step, learning_rate)\n\n    with tf.name_scope(""Evaluation""):\n        # Add the Op to compare the logits to the labels during evaluation.\n        eval_list = objective.evaluation(\n            hypes, image, labels, decoded_logits, losses, global_step)\n\n        summary_op = tf.summary.merge_all()\n\n    graph = {}\n    graph[\'losses\'] = losses\n    graph[\'eval_list\'] = eval_list\n    graph[\'summary_op\'] = summary_op\n    graph[\'train_op\'] = train_op\n    graph[\'global_step\'] = global_step\n    graph[\'learning_rate\'] = learning_rate\n\n    return graph\n\n\ndef run_united_training(meta_hypes, subhypes, submodules, subgraph, tv_sess,\n                        start_step=0):\n\n    """"""Run one iteration of training.""""""\n    # Unpack operations for later use\n    summary = tf.Summary()\n    sess = tv_sess[\'sess\']\n    summary_writer = tv_sess[\'writer\']\n\n    solvers = {}\n    for model in meta_hypes[\'models\']:\n        solvers[model] = submodules[model][\'solver\']\n\n    display_iter = meta_hypes[\'logging\'][\'display_iter\']\n    write_iter = meta_hypes[\'logging\'].get(\'write_iter\', 5*display_iter)\n    eval_iter = meta_hypes[\'logging\'][\'eval_iter\']\n    save_iter = meta_hypes[\'logging\'][\'save_iter\']\n    image_iter = meta_hypes[\'logging\'].get(\'image_iter\', 5*save_iter)\n\n    models = meta_hypes[\'model_list\']\n    num_models = len(models)\n\n    py_smoothers = {}\n    dict_smoothers = {}\n    for model in models:\n        py_smoothers[model] = train.MedianSmoother(5)\n        dict_smoothers[model] = train.ExpoSmoother(0.95)\n\n    n = 0\n\n    eval_names = {}\n    eval_ops = {}\n    for model in models:\n        names, ops = zip(*subgraph[model][\'eval_list\'])\n        eval_names[model] = names\n        eval_ops[model] = ops\n\n    weights = meta_hypes[\'selection\'][\'weights\']\n    aweights = np.array([sum(weights[:i+1]) for i in range(len(weights))])\n    # eval_names, eval_ops = zip(*tv_graph[\'eval_list\'])\n    # Run the training Step\n    start_time = time.time()\n    for step in xrange(start_step, meta_hypes[\'solver\'][\'max_steps\']):\n\n        # select on which model to run the training step\n        # select model randomly?\n        if not meta_hypes[\'selection\'][\'random\']:\n            if not meta_hypes[\'selection\'][\'use_weights\']:\n                # non-random selection\n                model = models[step % num_models]\n            else:\n                # non-random, some models are selected multiple times\n                select = np.argmax((aweights > step % aweights[-1]))\n                model = models[select]\n        else:\n            # random selection. Use weights\n            # to increase chance\n            r = random.random()\n            select = np.argmax((aweights > r))\n            model = models[select]\n\n        lr = solvers[model].get_learning_rate(subhypes[model], step)\n        feed_dict = {subgraph[model][\'learning_rate\']: lr}\n\n        sess.run([subgraph[model][\'train_op\']], feed_dict=feed_dict)\n\n        # Write the summaries and print an overview fairly often.\n        if step % display_iter == 0:\n            # Print status to stdout.\n            loss_values = {}\n            eval_results = {}\n            lrs = {}\n            if select == 1:\n                logging.info(""Detection Loss was used."")\n            else:\n                logging.info(""Segmentation Loss was used."")\n            for model in models:\n                loss_values[model] = sess.run(subgraph[model][\'losses\']\n                                              [\'total_loss\'])\n\n                eval_results[model] = sess.run(eval_ops[model])\n                dict_smoothers[model].update_weights(eval_results[model])\n                lrs[model] = solvers[model].get_learning_rate(subhypes[model],\n                                                              step)\n\n            _print_training_status(meta_hypes, step,\n                                   loss_values,\n                                   start_time, lrs)\n\n            for model in models:\n                train._print_eval_dict(eval_names[model], eval_results[model],\n                                       prefix=\'   (raw)\')\n\n                smoothed_results = dict_smoothers[model].get_weights()\n\n                train._print_eval_dict(eval_names[model], smoothed_results,\n                                       prefix=\'(smooth)\')\n\n            output = sess.run(subgraph[\'debug_ops\'].values())\n\n            for name, res in zip(subgraph[\'debug_ops\'].keys(), output):\n                logging.info(""{} : {}"".format(name, res))\n\n            if step % write_iter == 0:\n                # write values to summary\n                summary_str = sess.run(tv_sess[\'summary_op\'],\n                                       feed_dict=feed_dict)\n                summary_writer.add_summary(summary_str,\n                                           global_step=step)\n                for model in models:\n                    summary.value.add(tag=\'training/%s/total_loss\' % model,\n                                      simple_value=float(loss_values[model]))\n                    summary.value.add(tag=\'training/%s/learning_rate\' % model,\n                                      simple_value=lrs[model])\n                summary_writer.add_summary(summary, step)\n                # Convert numpy types to simple types.\n                if False:\n                    eval_results = np.array(eval_results)\n                    eval_results = eval_results.tolist()\n                    eval_dict = zip(eval_names[model], eval_results)\n                    train._write_eval_dict_to_summary(eval_dict,\n                                                      \'Eval/%s/raw\' % model,\n                                                      summary_writer, step)\n                    eval_dict = zip(eval_names[model], smoothed_results)\n                    train._write_eval_dict_to_summary(eval_dict,\n                                                      \'Eval/%s/smooth\' % model,\n                                                      summary_writer, step)\n\n            # Reset timer\n            start_time = time.time()\n\n        # Do a evaluation and print the current state\n        if (step) % eval_iter == 0 and step > 0 or \\\n           (step + 1) == meta_hypes[\'solver\'][\'max_steps\']:\n            # write checkpoint to disk\n\n            logging.info(\'Running Evaluation Scripts.\')\n            for model in models:\n                eval_dict, images = submodules[model][\'eval\'].evaluate(\n                    subhypes[model], sess,\n                    subgraph[model][\'image_pl\'],\n                    subgraph[model][\'inf_out\'])\n\n                train._write_images_to_summary(images, summary_writer, step)\n\n                if images is not None and len(images) > 0:\n\n                    name = str(n % 10) + \'_\' + images[0][0]\n                    image_dir = subhypes[model][\'dirs\'][\'image_dir\']\n                    image_file = os.path.join(image_dir, name)\n                    scp.misc.imsave(image_file, images[0][1])\n                    n = n + 1\n\n                logging.info(""%s Evaluation Finished. Results"" % model)\n\n                logging.info(\'Raw Results:\')\n                utils.print_eval_dict(eval_dict, prefix=\'(raw)   \')\n                train._write_eval_dict_to_summary(\n                    eval_dict, \'Evaluation/%s/raw\' % model,\n                    summary_writer, step)\n\n                logging.info(\'Smooth Results:\')\n                names, res = zip(*eval_dict)\n                smoothed = py_smoothers[model].update_weights(res)\n                eval_dict = zip(names, smoothed)\n                utils.print_eval_dict(eval_dict, prefix=\'(smooth)\')\n                train._write_eval_dict_to_summary(\n                    eval_dict, \'Evaluation/%s/smoothed\' % model,\n                    summary_writer, step)\n\n                if step % image_iter == 0 and step > 0 or \\\n                        (step + 1) == meta_hypes[\'solver\'][\'max_steps\']:\n                    train._write_images_to_disk(meta_hypes, images, step)\n            logging.info(""Evaluation Finished. All results will be saved to:"")\n            logging.info(subhypes[model][\'dirs\'][\'output_dir\'])\n\n            # Reset timer\n            start_time = time.time()\n\n        # Save a checkpoint periodically.\n        if (step) % save_iter == 0 and step > 0 or \\\n           (step + 1) == meta_hypes[\'solver\'][\'max_steps\']:\n            # write checkpoint to disk\n            checkpoint_path = os.path.join(meta_hypes[\'dirs\'][\'output_dir\'],\n                                           \'model.ckpt\')\n            tv_sess[\'saver\'].save(sess, checkpoint_path, global_step=step)\n            # Reset timer\n            start_time = time.time()\n    return\n\n\ndef _recombine_2_losses(meta_hypes, subgraph, subhypes, submodules):\n    if meta_hypes[\'loss_build\'][\'recombine\']:\n        # Computing weight loss\n        segmentation_loss = subgraph[\'segmentation\'][\'losses\'][\'xentropy\']\n        detection_loss = subgraph[\'detection\'][\'losses\'][\'loss\']\n\n        reg_loss_col = tf.GraphKeys.REGULARIZATION_LOSSES\n        weight_loss = tf.add_n(tf.get_collection(reg_loss_col),\n                               name=\'reg_loss\')\n\n        if meta_hypes[\'loss_build\'][\'weighted\']:\n            w = meta_hypes[\'loss_build\'][\'weights\']\n            total_loss = segmentation_loss*w[0] + \\\n                detection_loss*w[1] + weight_loss\n            subgraph[\'segmentation\'][\'losses\'][\'total_loss\'] = total_loss\n        else:\n            total_loss = segmentation_loss + detection_loss + weight_loss\n            subgraph[\'segmentation\'][\'losses\'][\'total_loss\'] = total_loss\n\n        for model in meta_hypes[\'model_list\']:\n            hypes = subhypes[model]\n            modules = submodules[model]\n            optimizer = modules[\'solver\']\n            gs = subgraph[model][\'global_step\']\n            losses = subgraph[model][\'losses\']\n            lr = subgraph[model][\'learning_rate\']\n            subgraph[model][\'train_op\'] = optimizer.training(hypes, losses,\n                                                             gs, lr)\n\n\ndef _recombine_3_losses(meta_hypes, subgraph, subhypes, submodules):\n    if meta_hypes[\'loss_build\'][\'recombine\']:\n        # Read all losses\n        segmentation_loss = subgraph[\'segmentation\'][\'losses\'][\'xentropy\']\n        detection_loss = subgraph[\'detection\'][\'losses\'][\'loss\']\n        road_loss = subgraph[\'road\'][\'losses\'][\'loss\']\n\n        reg_loss_col = tf.GraphKeys.REGULARIZATION_LOSSES\n\n        weight_loss = tf.add_n(tf.get_collection(reg_loss_col),\n                               name=\'reg_loss\')\n\n        # compute total loss\n        if meta_hypes[\'loss_build\'][\'weighted\']:\n            w = meta_hypes[\'loss_build\'][\'weights\']\n            # use weights\n            total_loss = segmentation_loss*w[0] + \\\n                detection_loss*w[1] + road_loss*w[2] + weight_loss\n        else:\n            total_loss = segmentation_loss + detection_loss + road_loss \\\n                + weight_loss\n\n        # Build train_ops using the new losses\n        subgraph[\'segmentation\'][\'losses\'][\'total_loss\'] = total_loss\n        for model in meta_hypes[\'models\']:\n            hypes = subhypes[model]\n            modules = submodules[model]\n            optimizer = modules[\'solver\']\n            gs = subgraph[model][\'global_step\']\n            losses = subgraph[model][\'losses\']\n            lr = subgraph[model][\'learning_rate\']\n            subgraph[model][\'train_op\'] = optimizer.training(hypes, losses,\n                                                             gs, lr)\n\n\ndef load_united_model(logdir):\n    subhypes = {}\n    subgraph = {}\n    submodules = {}\n    subqueues = {}\n\n    subgraph[\'debug_ops\'] = {}\n\n    first_iter = True\n\n    meta_hypes = utils.load_hypes_from_logdir(logdir, subdir="""",\n                                              base_path=\'hypes\')\n    for model in meta_hypes[\'model_list\']:\n        subhypes[model] = utils.load_hypes_from_logdir(logdir, subdir=model)\n        hypes = subhypes[model]\n        hypes[\'dirs\'][\'output_dir\'] = meta_hypes[\'dirs\'][\'output_dir\']\n        hypes[\'dirs\'][\'image_dir\'] = meta_hypes[\'dirs\'][\'image_dir\']\n        hypes[\'dirs\'][\'data_dir\'] = meta_hypes[\'dirs\'][\'data_dir\']\n        submodules[model] = utils.load_modules_from_logdir(logdir,\n                                                           dirname=model,\n                                                           postfix=model)\n\n        modules = submodules[model]\n\n        logging.info(""Build %s computation Graph."", model)\n        with tf.name_scope(""Queues_%s"" % model):\n            subqueues[model] = modules[\'input\'].create_queues(hypes, \'train\')\n\n        logging.info(\'Building Model: %s\' % model)\n\n        subgraph[model] = build_training_graph(hypes,\n                                               subqueues[model],\n                                               modules,\n                                               first_iter)\n\n        first_iter = False\n\n    if len(meta_hypes[\'model_list\']) == 2:\n        _recombine_2_losses(meta_hypes, subgraph, subhypes, submodules)\n    else:\n        _recombine_3_losses(meta_hypes, subgraph, subhypes, submodules)\n\n    hypes = subhypes[meta_hypes[\'model_list\'][0]]\n\n    tv_sess = core.start_tv_session(hypes)\n    sess = tv_sess[\'sess\']\n    saver = tv_sess[\'saver\']\n\n    cur_step = core.load_weights(logdir, sess, saver)\n    for model in meta_hypes[\'model_list\']:\n        hypes = subhypes[model]\n        modules = submodules[model]\n        optimizer = modules[\'solver\']\n\n        with tf.name_scope(\'Validation_%s\' % model):\n            tf.get_variable_scope().reuse_variables()\n            image_pl = tf.placeholder(tf.float32)\n            image = tf.expand_dims(image_pl, 0)\n            inf_out = core.build_inference_graph(hypes, modules,\n                                                 image=image)\n            subgraph[model][\'image_pl\'] = image_pl\n            subgraph[model][\'inf_out\'] = inf_out\n\n        # Start the data load\n        modules[\'input\'].start_enqueuing_threads(hypes, subqueues[model],\n                                                 \'train\', sess)\n\n    target_file = os.path.join(meta_hypes[\'dirs\'][\'output_dir\'], \'hypes.json\')\n    with open(target_file, \'w\') as outfile:\n        json.dump(meta_hypes, outfile, indent=2, sort_keys=True)\n\n    return meta_hypes, subhypes, submodules, subgraph, tv_sess, cur_step\n\n\ndef build_united_model(meta_hypes):\n\n    logging.info(""Initialize training folder"")\n\n    subhypes = {}\n    subgraph = {}\n    submodules = {}\n    subqueues = {}\n\n    subgraph[\'debug_ops\'] = {}\n\n    base_path = meta_hypes[\'dirs\'][\'base_path\']\n    first_iter = True\n\n    for model in meta_hypes[\'model_list\']:\n        subhypes_file = os.path.join(base_path, meta_hypes[\'models\'][model])\n        with open(subhypes_file, \'r\') as f:\n            logging.info(""f: %s"", f)\n            subhypes[model] = json.load(f)\n\n        hypes = subhypes[model]\n        utils.set_dirs(hypes, subhypes_file)\n        hypes[\'dirs\'][\'output_dir\'] = meta_hypes[\'dirs\'][\'output_dir\']\n        hypes[\'dirs\'][\'data_dir\'] = meta_hypes[\'dirs\'][\'data_dir\']\n        train.initialize_training_folder(hypes, files_dir=model,\n                                         logging=first_iter)\n        meta_hypes[\'dirs\'][\'image_dir\'] = hypes[\'dirs\'][\'image_dir\']\n        submodules[model] = utils.load_modules_from_hypes(\n            hypes, postfix=""_%s"" % model)\n        modules = submodules[model]\n\n        logging.info(""Build %s computation Graph."", model)\n        with tf.name_scope(""Queues_%s"" % model):\n            subqueues[model] = modules[\'input\'].create_queues(hypes, \'train\')\n\n        logging.info(\'Building Model: %s\' % model)\n\n        subgraph[model] = build_training_graph(hypes,\n                                               subqueues[model],\n                                               modules,\n                                               first_iter)\n\n        first_iter = False\n\n    if len(meta_hypes[\'models\']) == 2:\n        _recombine_2_losses(meta_hypes, subgraph, subhypes, submodules)\n    else:\n        _recombine_3_losses(meta_hypes, subgraph, subhypes, submodules)\n\n    hypes = subhypes[meta_hypes[\'model_list\'][0]]\n\n    tv_sess = core.start_tv_session(hypes)\n    sess = tv_sess[\'sess\']\n    for model in meta_hypes[\'model_list\']:\n        hypes = subhypes[model]\n        modules = submodules[model]\n        optimizer = modules[\'solver\']\n\n        with tf.name_scope(\'Validation_%s\' % model):\n            tf.get_variable_scope().reuse_variables()\n            image_pl = tf.placeholder(tf.float32)\n            image = tf.expand_dims(image_pl, 0)\n            inf_out = core.build_inference_graph(hypes, modules,\n                                                 image=image)\n            subgraph[model][\'image_pl\'] = image_pl\n            subgraph[model][\'inf_out\'] = inf_out\n\n        # Start the data load\n        modules[\'input\'].start_enqueuing_threads(hypes, subqueues[model],\n                                                 \'train\', sess)\n\n    target_file = os.path.join(meta_hypes[\'dirs\'][\'output_dir\'], \'hypes.json\')\n    with open(target_file, \'w\') as outfile:\n        json.dump(meta_hypes, outfile, indent=2, sort_keys=True)\n\n    return subhypes, submodules, subgraph, tv_sess\n\n\ndef main(_):\n    utils.set_gpus_to_use()\n\n    load_weights = tf.app.flags.FLAGS.logdir is not None\n\n    if not load_weights:\n        with open(tf.app.flags.FLAGS.hypes, \'r\') as f:\n            logging.info(""f: %s"", f)\n            hypes = json.load(f)\n    utils.load_plugins()\n\n    if \'TV_DIR_RUNS\' in os.environ:\n        os.environ[\'TV_DIR_RUNS\'] = os.path.join(os.environ[\'TV_DIR_RUNS\'],\n                                                 \'MultiNet\')\n\n    with tf.Session() as sess:\n\n        if not load_weights:\n            utils.set_dirs(hypes, tf.app.flags.FLAGS.hypes)\n            utils._add_paths_to_sys(hypes)\n\n            # Build united Model\n            subhypes, submodules, subgraph, tv_sess = build_united_model(hypes)\n            start_step = 0\n        else:\n            logdir = tf.app.flags.FLAGS.logdir\n            logging_file = os.path.join(logdir, ""output.log"")\n            utils.create_filewrite_handler(logging_file, mode=\'a\')\n            hypes, subhypes, submodules, subgraph, tv_sess, start_step = \\\n                load_united_model(logdir)\n            if start_step is None:\n                start_step = 0\n\n        # Run united training\n        run_united_training(hypes, subhypes, submodules, subgraph,\n                            tv_sess, start_step=start_step)\n\n        # stopping input Threads\n        tv_sess[\'coord\'].request_stop()\n        tv_sess[\'coord\'].join(tv_sess[\'threads\'])\n\n\nif __name__ == \'__main__\':\n    tf.app.run()\n'"
