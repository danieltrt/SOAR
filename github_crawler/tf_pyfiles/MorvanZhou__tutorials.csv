file_path,api_count,code
basic/25_import.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport time\nprint(time.localtime())\n\nimport time as t\nprint(t.localtime())\n\nfrom time import localtime, time\nprint(localtime())\nprint(time())\n\nfrom time import *\nprint(localtime())\n'"
basic/28_try.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\ntry:\n    file = open('eeee', 'r+')\nexcept Exception as e:\n    print('there is no file named as eeeee')\n    response = input('do you want to create a new file')\n    if response =='y':\n        file = open('eeee','w')\n    else:\n        pass\nelse:\n    file.write('ssss')\nfile.close()\n\n\n"""
basic/29_zip_lambda_map.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\na = [1,2,3]\nb = [4,5,6]\n\n# for zip\nlist(zip(a,b))\nlist(zip(a,a,b))\nfor i, j in zip(a,b):\n    print(i,j)\n\n#for lambda\ndef f1(x,y):\n    return x+y\nf2= lambda x, y : x + y\nprint(f1(1,2))\nprint(f2(1,2))\n\n# for map\nprint(list(map(f1, [1],[2])))\nprint(list(map(f2, [2,3],[4,5])))\n'"
basic/30_copy_deepcopy.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport copy\n\na = [1,2,3]\nb = a\nb[1]=22\nprint(a)\nprint(id(a) == id(b))\n\n# deep copy\nc = copy.deepcopy(a)\nprint(id(a) == id(c))\nc[1] = 2\nprint(a)\na[1] = 111\nprint(c)\n\n# shallow copy\na = [1,2,[3,4]]\nd = copy.copy(a)\nprint(id(a) == id(d))\nprint(id(a[2]) == id(d[2]))\n'"
basic/34_pickle.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport pickle\n\na_dict = {'da': 111, 2: [23,1,4], '23': {1:2,'d':'sad'}}\n\n# pickle a variable to a file\nfile = open('pickle_example.pickle', 'wb')\npickle.dump(a_dict, file)\nfile.close()\n\n# reload a file to a variable\nwith open('pickle_example.pickle', 'rb') as file:\n    a_dict1 =pickle.load(file)\n\nprint(a_dict1)\n\n\n\n\n\n\n\n"""
basic/35_set.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nchar_list = ['a', 'b', 'c', 'c', 'd', 'd', 'd']\n\nsentence = 'Welcome Back to This Tutorial'\n\nprint(set(char_list))\nprint(set(sentence))\n\nprint(set(char_list + list(sentence)))\n\nunique_char = set(char_list)\nunique_char.add('x')\n# unique_char.add(['y', 'z']) this is wrong\nprint(unique_char)\n\nunique_char.remove('x')\nprint(unique_char)\nunique_char.discard('d')\nprint(unique_char)\nunique_char.clear()\nprint(unique_char)\n\nunique_char = set(char_list)\nprint(unique_char.difference({'a', 'e', 'i'}))\nprint(unique_char.intersection({'a', 'e', 'i'}))"""
basic/36_RegEx.py,0,"b'import re\n\n# matching string\npattern1 = ""cat""\npattern2 = ""bird""\nstring = ""dog runs to cat""\nprint(pattern1 in string)    # True\nprint(pattern2 in string)    # False\n\n\n# regular expression\npattern1 = ""cat""\npattern2 = ""bird""\nstring = ""dog runs to cat""\nprint(re.search(pattern1, string))  # <_sre.SRE_Match object; span=(12, 15), match=\'cat\'>\nprint(re.search(pattern2, string))  # None\n\n\n# multiple patterns (""run"" or ""ran"")\nptn = r""r[au]n""       # start with ""r"" means raw string\nprint(re.search(ptn, ""dog runs to cat""))    # <_sre.SRE_Match object; span=(4, 7), match=\'run\'>\n\n\n# continue\nprint(re.search(r""r[A-Z]n"", ""dog runs to cat""))     # None\nprint(re.search(r""r[a-z]n"", ""dog runs to cat""))     # <_sre.SRE_Match object; span=(4, 7), match=\'run\'>\nprint(re.search(r""r[0-9]n"", ""dog r2ns to cat""))     # <_sre.SRE_Match object; span=(4, 7), match=\'r2n\'>\nprint(re.search(r""r[0-9a-z]n"", ""dog runs to cat""))  # <_sre.SRE_Match object; span=(4, 7), match=\'run\'>\n\n\n# \\d : decimal digit\nprint(re.search(r""r\\dn"", ""run r4n""))                # <_sre.SRE_Match object; span=(4, 7), match=\'r4n\'>\n# \\D : any non-decimal digit\nprint(re.search(r""r\\Dn"", ""run r4n""))                # <_sre.SRE_Match object; span=(0, 3), match=\'run\'>\n# \\s : any white space [\\t\\n\\r\\f\\v]\nprint(re.search(r""r\\sn"", ""r\\nn r4n""))               # <_sre.SRE_Match object; span=(0, 3), match=\'r\\nn\'>\n# \\S : opposite to \\s, any non-white space\nprint(re.search(r""r\\Sn"", ""r\\nn r4n""))               # <_sre.SRE_Match object; span=(4, 7), match=\'r4n\'>\n# \\w : [a-zA-Z0-9_]\nprint(re.search(r""r\\wn"", ""r\\nn r4n""))               # <_sre.SRE_Match object; span=(4, 7), match=\'r4n\'>\n# \\W : opposite to \\w\nprint(re.search(r""r\\Wn"", ""r\\nn r4n""))               # <_sre.SRE_Match object; span=(0, 3), match=\'r\\nn\'>\n# \\b : empty string (only at the start or end of the word)\nprint(re.search(r""\\bruns\\b"", ""dog runs to cat""))    # <_sre.SRE_Match object; span=(4, 8), match=\'runs\'>\n# \\B : empty string (but not at the start or end of a word)\nprint(re.search(r""\\B runs \\B"", ""dog   runs  to cat""))  # <_sre.SRE_Match object; span=(8, 14), match=\' runs \'>\n# \\\\ : match \\\nprint(re.search(r""runs\\\\"", ""runs\\ to me""))          # <_sre.SRE_Match object; span=(0, 5), match=\'runs\\\\\'>\n# . : match anything (except \\n)\nprint(re.search(r""r.n"", ""r[ns to me""))              # <_sre.SRE_Match object; span=(0, 3), match=\'r[n\'>\n# ^ : match line beginning\nprint(re.search(r""^dog"", ""dog runs to cat""))        # <_sre.SRE_Match object; span=(0, 3), match=\'dog\'>\n# $ : match line ending\nprint(re.search(r""cat$"", ""dog runs to cat""))        # <_sre.SRE_Match object; span=(12, 15), match=\'cat\'>\n# ? : may or may not occur\nprint(re.search(r""Mon(day)?"", ""Monday""))            # <_sre.SRE_Match object; span=(0, 6), match=\'Monday\'>\nprint(re.search(r""Mon(day)?"", ""Mon""))               # <_sre.SRE_Match object; span=(0, 3), match=\'Mon\'>\n\n\n# multi-line\nstring = """"""\ndog runs to cat.\nI run to dog.\n""""""\nprint(re.search(r""^I"", string))                     # None\nprint(re.search(r""^I"", string, flags=re.M))         # <_sre.SRE_Match object; span=(18, 19), match=\'I\'>\n\n\n# * : occur 0 or more times\nprint(re.search(r""ab*"", ""a""))                       # <_sre.SRE_Match object; span=(0, 1), match=\'a\'>\nprint(re.search(r""ab*"", ""abbbbb""))                  # <_sre.SRE_Match object; span=(0, 6), match=\'abbbbb\'>\n\n# + : occur 1 or more times\nprint(re.search(r""ab+"", ""a""))                       # None\nprint(re.search(r""ab+"", ""abbbbb""))                  # <_sre.SRE_Match object; span=(0, 6), match=\'abbbbb\'>\n\n# {n, m} : occur n to m times\nprint(re.search(r""ab{2,10}"", ""a""))                  # None\nprint(re.search(r""ab{2,10}"", ""abbbbb""))             # <_sre.SRE_Match object; span=(0, 6), match=\'abbbbb\'>\n\n\n# group\nmatch = re.search(r""(\\d+), Date: (.+)"", ""ID: 021523, Date: Feb/12/2017"")\nprint(match.group())                                # 021523, Date: Feb/12/2017\nprint(match.group(1))                               # 021523\nprint(match.group(2))                               # Date: Feb/12/2017\n\nmatch = re.search(r""(?P<id>\\d+), Date: (?P<date>.+)"", ""ID: 021523, Date: Feb/12/2017"")\nprint(match.group(\'id\'))                            # 021523\nprint(match.group(\'date\'))                          # Date: Feb/12/2017\n\n# findall\nprint(re.findall(r""r[ua]n"", ""run ran ren""))         # [\'run\', \'ran\']\n\n# | : or\nprint(re.findall(r""(run|ran)"", ""run ran ren""))      # [\'run\', \'ran\']\n\n# re.sub() replace\nprint(re.sub(r""r[au]ns"", ""catches"", ""dog runs to cat""))     # dog catches to cat\n\n# re.split()\nprint(re.split(r""[,;\\.]"", ""a;b,c.d;e""))             # [\'a\', \'b\', \'c\', \'d\', \'e\']\n\n\n# compile\ncompiled_re = re.compile(r""r[ua]n"")\nprint(compiled_re.search(""dog ran to cat""))     # <_sre.SRE_Match object; span=(4, 7), match=\'ran\'>\n\n\n\n'"
kerasTUT/10-save.py,0,"b'""""""\nTo know more or get code samples, please visit my website:\nhttps://morvanzhou.github.io/tutorials/\nOr search: \xe8\x8e\xab\xe7\x83\xa6Python\nThank you for supporting!\n""""""\n\n# please note, all tutorial code are running under python3.5.\n# If you use the version like python2.7, please modify the code accordingly\n\n# 10 - save\n\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.models import load_model\n\n# create some data\nX = np.linspace(-1, 1, 200)\nnp.random.shuffle(X)    # randomize the data\nY = 0.5 * X + 2 + np.random.normal(0, 0.05, (200, ))\nX_train, Y_train = X[:160], Y[:160]     # first 160 data points\nX_test, Y_test = X[160:], Y[160:]       # last 40 data points\nmodel = Sequential()\nmodel.add(Dense(output_dim=1, input_dim=1))\nmodel.compile(loss=\'mse\', optimizer=\'sgd\')\nfor step in range(301):\n    cost = model.train_on_batch(X_train, Y_train)\n\n# save\nprint(\'test before save: \', model.predict(X_test[0:2]))\nmodel.save(\'my_model.h5\')   # HDF5 file, you have to pip3 install h5py if don\'t have it\ndel model  # deletes the existing model\n\n# load\nmodel = load_model(\'my_model.h5\')\nprint(\'test after load: \', model.predict(X_test[0:2]))\n""""""\n# save and load weights\nmodel.save_weights(\'my_model_weights.h5\')\nmodel.load_weights(\'my_model_weights.h5\')\n\n# save and load fresh network without trained weights\nfrom keras.models import model_from_json\njson_string = model.to_json()\nmodel = model_from_json(json_string)\n""""""\n\n\n\n'"
kerasTUT/2-installation.py,0,"b'""""""\nTo know more or get code samples, please visit my website:\nhttps://morvanzhou.github.io/tutorials/\nOr search: \xe8\x8e\xab\xe7\x83\xa6Python\nThank you for supporting!\n""""""\n\n# please note, all tutorial code are running under python3.5.\n# If you use the version like python2.7, please modify the code accordingly\n\n# 2 - Installation\n\n""""""\n---------------------------\n1. Make sure you have installed the following dependencies for Keras:\n- Numpy\n- Scipy\n\nfor install numpy and scipy, please refer to my video tutorial:\nhttps://www.youtube.com/watch?v=JauGYB-Bzuw&list=PLXO45tsB95cKKyC45gatc8wEc3Ue7BlI4&index=2\n---------------------------\n2. run \'pip install keras\' in command line for python 2+\nOr \'pip3 install keras\' for python 3+\n\nIf encounter the error related to permission, then use \'sudo pip install ***\'\n---------------------------\n\n""""""'"
kerasTUT/3-backend.py,0,"b'""""""\nTo know more or get code samples, please visit my website:\nhttps://morvanzhou.github.io/tutorials/\nOr search: \xe8\x8e\xab\xe7\x83\xa6Python\nThank you for supporting!\n""""""\n\n# please note, all tutorial code are running under python3.5.\n# If you use the version like python2.7, please modify the code accordingly\n\n# 3 - backend\n\n\n""""""\nDetails are showing in the video.\n\n----------------------\nMethod 1:\nIf you have run Keras at least once, you will find the Keras configuration file at:\n\n~/.keras/keras.json\n\nIf it isn\'t there, you can create it.\n\nThe default configuration file looks like this:\n\n{\n    ""image_dim_ordering"": ""tf"",\n    ""epsilon"": 1e-07,\n    ""floatx"": ""float32"",\n    ""backend"": ""theano""\n}\n\nSimply change the field backend to either ""theano"" or  ""tensorflow"",\nand Keras will use the new configuration next time you run any Keras code.\n----------------------------\nMethod 2:\n\ndefine this before import keras:\n\n>>> import os\n>>> os.environ[\'KERAS_BACKEND\']=\'theano\'\n>>> import keras\nUsing Theano backend.\n\n""""""\n\n'"
kerasTUT/4-regressor_example.py,0,"b'""""""\nTo know more or get code samples, please visit my website:\nhttps://morvanzhou.github.io/tutorials/\nOr search: \xe8\x8e\xab\xe7\x83\xa6Python\nThank you for supporting!\n""""""\n\n# please note, all tutorial code are running under python3.5.\n# If you use the version like python2.7, please modify the code accordingly\n\n# 4 - Regressor example\n\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport matplotlib.pyplot as plt\n\n# create some data\nX = np.linspace(-1, 1, 200)\nnp.random.shuffle(X)    # randomize the data\nY = 0.5 * X + 2 + np.random.normal(0, 0.05, (200, ))\n# plot data\nplt.scatter(X, Y)\nplt.show()\n\nX_train, Y_train = X[:160], Y[:160]     # first 160 data points\nX_test, Y_test = X[160:], Y[160:]       # last 40 data points\n\n# build a neural network from the 1st layer to the last layer\nmodel = Sequential()\n\nmodel.add(Dense(units=1, input_dim=1)) \n\n# choose loss function and optimizing method\nmodel.compile(loss=\'mse\', optimizer=\'sgd\')\n\n# training\nprint(\'Training -----------\')\nfor step in range(301):\n    cost = model.train_on_batch(X_train, Y_train)\n    if step % 100 == 0:\n        print(\'train cost: \', cost)\n\n# test\nprint(\'\\nTesting ------------\')\ncost = model.evaluate(X_test, Y_test, batch_size=40)\nprint(\'test cost:\', cost)\nW, b = model.layers[0].get_weights()\nprint(\'Weights=\', W, \'\\nbiases=\', b)\n\n# plotting the prediction\nY_pred = model.predict(X_test)\nplt.scatter(X_test, Y_test)\nplt.plot(X_test, Y_pred)\nplt.show()\n'"
kerasTUT/5-classifier_example.py,0,"b'""""""\nTo know more or get code samples, please visit my website:\nhttps://morvanzhou.github.io/tutorials/\nOr search: \xe8\x8e\xab\xe7\x83\xa6Python\nThank you for supporting!\n""""""\n\n# please note, all tutorial code are running under python3.5.\n# If you use the version like python2.7, please modify the code accordingly\n\n# 5 - Classifier example\n\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\nfrom keras.datasets import mnist\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.optimizers import RMSprop\n\n# download the mnist to the path \'~/.keras/datasets/\' if it is the first time to be called\n# X shape (60,000 28x28), y shape (10,000, )\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# data pre-processing\nX_train = X_train.reshape(X_train.shape[0], -1) / 255.   # normalize\nX_test = X_test.reshape(X_test.shape[0], -1) / 255.      # normalize\ny_train = np_utils.to_categorical(y_train, num_classes=10)\ny_test = np_utils.to_categorical(y_test, num_classes=10)\n\n# Another way to build your neural net\nmodel = Sequential([\n    Dense(32, input_dim=784),\n    Activation(\'relu\'),\n    Dense(10),\n    Activation(\'softmax\'),\n])\n\n# Another way to define your optimizer\nrmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\n# We add metrics to get more results you want to see\nmodel.compile(optimizer=rmsprop,\n              loss=\'categorical_crossentropy\',\n              metrics=[\'accuracy\'])\n\nprint(\'Training ------------\')\n# Another way to train the model\nmodel.fit(X_train, y_train, epochs=2, batch_size=32)\n\nprint(\'\\nTesting ------------\')\n# Evaluate the model with the metrics we defined earlier\nloss, accuracy = model.evaluate(X_test, y_test)\n\nprint(\'test loss: \', loss)\nprint(\'test accuracy: \', accuracy)\n\n\n'"
kerasTUT/6-CNN_example.py,0,"b'""""""\nTo know more or get code samples, please visit my website:\nhttps://morvanzhou.github.io/tutorials/\nOr search: \xe8\x8e\xab\xe7\x83\xa6Python\nThank you for supporting!\n""""""\n\n# please note, all tutorial code are running under python3.5.\n# If you use the version like python2.7, please modify the code accordingly\n\n# 6 - CNN example\n\n# to try tensorflow, un-comment following two lines\n# import os\n# os.environ[\'KERAS_BACKEND\']=\'tensorflow\'\n\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\nfrom keras.datasets import mnist\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\nfrom keras.optimizers import Adam\n\n# download the mnist to the path \'~/.keras/datasets/\' if it is the first time to be called\n# training X shape (60000, 28x28), Y shape (60000, ). test X shape (10000, 28x28), Y shape (10000, )\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# data pre-processing\nX_train = X_train.reshape(-1, 1,28, 28)/255.\nX_test = X_test.reshape(-1, 1,28, 28)/255.\ny_train = np_utils.to_categorical(y_train, num_classes=10)\ny_test = np_utils.to_categorical(y_test, num_classes=10)\n\n# Another way to build your CNN\nmodel = Sequential()\n\n# Conv layer 1 output shape (32, 28, 28)\nmodel.add(Convolution2D(\n    batch_input_shape=(None, 1, 28, 28),\n    filters=32,\n    kernel_size=5,\n    strides=1,\n    padding=\'same\',     # Padding method\n    data_format=\'channels_first\',\n))\nmodel.add(Activation(\'relu\'))\n\n# Pooling layer 1 (max pooling) output shape (32, 14, 14)\nmodel.add(MaxPooling2D(\n    pool_size=2,\n    strides=2,\n    padding=\'same\',    # Padding method\n    data_format=\'channels_first\',\n))\n\n# Conv layer 2 output shape (64, 14, 14)\nmodel.add(Convolution2D(64, 5, strides=1, padding=\'same\', data_format=\'channels_first\'))\nmodel.add(Activation(\'relu\'))\n\n# Pooling layer 2 (max pooling) output shape (64, 7, 7)\nmodel.add(MaxPooling2D(2, 2, \'same\', data_format=\'channels_first\'))\n\n# Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024)\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\'relu\'))\n\n# Fully connected layer 2 to shape (10) for 10 classes\nmodel.add(Dense(10))\nmodel.add(Activation(\'softmax\'))\n\n# Another way to define your optimizer\nadam = Adam(lr=1e-4)\n\n# We add metrics to get more results you want to see\nmodel.compile(optimizer=adam,\n              loss=\'categorical_crossentropy\',\n              metrics=[\'accuracy\'])\n\nprint(\'Training ------------\')\n# Another way to train the model\nmodel.fit(X_train, y_train, epochs=1, batch_size=64,)\n\nprint(\'\\nTesting ------------\')\n# Evaluate the model with the metrics we defined earlier\nloss, accuracy = model.evaluate(X_test, y_test)\n\nprint(\'\\ntest loss: \', loss)\nprint(\'\\ntest accuracy: \', accuracy)\n\n\n'"
kerasTUT/7-RNN_Classifier_example.py,0,"b'""""""\nTo know more or get code samples, please visit my website:\nhttps://morvanzhou.github.io/tutorials/\nOr search: \xe8\x8e\xab\xe7\x83\xa6Python\nThank you for supporting!\n""""""\n\n# please note, all tutorial code are running under python3.5.\n# If you use the version like python2.7, please modify the code accordingly\n\n# 8 - RNN Classifier example\n\n# to try tensorflow, un-comment following two lines\n# import os\n# os.environ[\'KERAS_BACKEND\']=\'tensorflow\'\n\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\n\nfrom keras.datasets import mnist\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import SimpleRNN, Activation, Dense\nfrom keras.optimizers import Adam\n\nTIME_STEPS = 28     # same as the height of the image\nINPUT_SIZE = 28     # same as the width of the image\nBATCH_SIZE = 50\nBATCH_INDEX = 0\nOUTPUT_SIZE = 10\nCELL_SIZE = 50\nLR = 0.001\n\n\n# download the mnist to the path \'~/.keras/datasets/\' if it is the first time to be called\n# X shape (60,000 28x28), y shape (10,000, )\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# data pre-processing\nX_train = X_train.reshape(-1, 28, 28) / 255.      # normalize\nX_test = X_test.reshape(-1, 28, 28) / 255.        # normalize\ny_train = np_utils.to_categorical(y_train, num_classes=10)\ny_test = np_utils.to_categorical(y_test, num_classes=10)\n\n# build RNN model\nmodel = Sequential()\n\n# RNN cell\nmodel.add(SimpleRNN(\n    # for batch_input_shape, if using tensorflow as the backend, we have to put None for the batch_size.\n    # Otherwise, model.evaluate() will get error.\n    batch_input_shape=(None, TIME_STEPS, INPUT_SIZE),       # Or: input_dim=INPUT_SIZE, input_length=TIME_STEPS,\n    output_dim=CELL_SIZE,\n    unroll=True,\n))\n\n# output layer\nmodel.add(Dense(OUTPUT_SIZE))\nmodel.add(Activation(\'softmax\'))\n\n# optimizer\nadam = Adam(LR)\nmodel.compile(optimizer=adam,\n              loss=\'categorical_crossentropy\',\n              metrics=[\'accuracy\'])\n\n# training\nfor step in range(4001):\n    # data shape = (batch_num, steps, inputs/outputs)\n    X_batch = X_train[BATCH_INDEX: BATCH_INDEX+BATCH_SIZE, :, :]\n    Y_batch = y_train[BATCH_INDEX: BATCH_INDEX+BATCH_SIZE, :]\n    cost = model.train_on_batch(X_batch, Y_batch)\n    BATCH_INDEX += BATCH_SIZE\n    BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n\n    if step % 500 == 0:\n        cost, accuracy = model.evaluate(X_test, y_test, batch_size=y_test.shape[0], verbose=False)\n        print(\'test cost: \', cost, \'test accuracy: \', accuracy)\n\n\n\n\n'"
kerasTUT/8-RNN_LSTM_Regressor_example.py,0,"b'""""""\nTo know more or get code samples, please visit my website:\nhttps://morvanzhou.github.io/tutorials/\nOr search: \xe8\x8e\xab\xe7\x83\xa6Python\nThank you for supporting!\n""""""\n\n# please note, all tutorial code are running under python3.5.\n# If you use the version like python2.7, please modify the code accordingly\n\n# 8 - RNN LSTM Regressor example\n\n# to try tensorflow, un-comment following two lines\n# import os\n# os.environ[\'KERAS_BACKEND\']=\'tensorflow\'\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, TimeDistributed, Dense\nfrom keras.optimizers import Adam\n\nBATCH_START = 0\nTIME_STEPS = 20\nBATCH_SIZE = 50\nINPUT_SIZE = 1\nOUTPUT_SIZE = 1\nCELL_SIZE = 20\nLR = 0.006\n\n\ndef get_batch():\n    global BATCH_START, TIME_STEPS\n    # xs shape (50batch, 20steps)\n    xs = np.arange(BATCH_START, BATCH_START+TIME_STEPS*BATCH_SIZE).reshape((BATCH_SIZE, TIME_STEPS)) / (10*np.pi)\n    seq = np.sin(xs)\n    res = np.cos(xs)\n    BATCH_START += TIME_STEPS\n    # plt.plot(xs[0, :], res[0, :], \'r\', xs[0, :], seq[0, :], \'b--\')\n    # plt.show()\n    return [seq[:, :, np.newaxis], res[:, :, np.newaxis], xs]\n\nmodel = Sequential()\n# build a LSTM RNN\nmodel.add(LSTM(\n    batch_input_shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE),       # Or: input_dim=INPUT_SIZE, input_length=TIME_STEPS,\n    output_dim=CELL_SIZE,\n    return_sequences=True,      # True: output at all steps. False: output as last step.\n    stateful=True,              # True: the final state of batch1 is feed into the initial state of batch2\n))\n# add output layer\nmodel.add(TimeDistributed(Dense(OUTPUT_SIZE)))\nadam = Adam(LR)\nmodel.compile(optimizer=adam,\n              loss=\'mse\',)\n\nprint(\'Training ------------\')\nfor step in range(501):\n    # data shape = (batch_num, steps, inputs/outputs)\n    X_batch, Y_batch, xs = get_batch()\n    cost = model.train_on_batch(X_batch, Y_batch)\n    pred = model.predict(X_batch, BATCH_SIZE)\n    plt.plot(xs[0, :], Y_batch[0].flatten(), \'r\', xs[0, :], pred.flatten()[:TIME_STEPS], \'b--\')\n    plt.ylim((-1.2, 1.2))\n    plt.draw()\n    plt.pause(0.1)\n    if step % 10 == 0:\n        print(\'train cost: \', cost)\n\n\n\n\n'"
kerasTUT/9-Autoencoder_example.py,0,"b'""""""\nTo know more or get code samples, please visit my website:\nhttps://morvanzhou.github.io/tutorials/\nOr search: \xe8\x8e\xab\xe7\x83\xa6Python\nThank you for supporting!\n""""""\n\n# please note, all tutorial code are running under python3.5.\n# If you use the version like python2.7, please modify the code accordingly\n\n# 9 - Autoencoder example\n\n# to try tensorflow, un-comment following two lines\n# import os\n# os.environ[\'KERAS_BACKEND\']=\'tensorflow\'\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\n\nfrom keras.datasets import mnist\nfrom keras.models import Model\nfrom keras.layers import Dense, Input\nimport matplotlib.pyplot as plt\n\n# download the mnist to the path \'~/.keras/datasets/\' if it is the first time to be called\n# X shape (60,000 28x28), y shape (10,000, )\n(x_train, _), (x_test, y_test) = mnist.load_data()\n\n# data pre-processing\nx_train = x_train.astype(\'float32\') / 255. - 0.5       # minmax_normalized\nx_test = x_test.astype(\'float32\') / 255. - 0.5         # minmax_normalized\nx_train = x_train.reshape((x_train.shape[0], -1))\nx_test = x_test.reshape((x_test.shape[0], -1))\nprint(x_train.shape)\nprint(x_test.shape)\n\n# in order to plot in a 2D figure\nencoding_dim = 2\n\n# this is our input placeholder\ninput_img = Input(shape=(784,))\n\n# encoder layers\nencoded = Dense(128, activation=\'relu\')(input_img)\nencoded = Dense(64, activation=\'relu\')(encoded)\nencoded = Dense(10, activation=\'relu\')(encoded)\nencoder_output = Dense(encoding_dim)(encoded)\n\n# decoder layers\ndecoded = Dense(10, activation=\'relu\')(encoder_output)\ndecoded = Dense(64, activation=\'relu\')(decoded)\ndecoded = Dense(128, activation=\'relu\')(decoded)\ndecoded = Dense(784, activation=\'tanh\')(decoded)\n\n# construct the autoencoder model\nautoencoder = Model(input=input_img, output=decoded)\n\n# construct the encoder model for plotting\nencoder = Model(input=input_img, output=encoder_output)\n\n# compile autoencoder\nautoencoder.compile(optimizer=\'adam\', loss=\'mse\')\n\n# training\nautoencoder.fit(x_train, x_train,\n                epochs=20,\n                batch_size=256,\n                shuffle=True)\n\n# plotting\nencoded_imgs = encoder.predict(x_test)\nplt.scatter(encoded_imgs[:, 0], encoded_imgs[:, 1], c=y_test)\nplt.colorbar()\nplt.show()\n\n\n\n\n'"
matplotlibTUT/plt10_scatter.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 10 - scatter\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://www.scipy-lectures.org/intro/matplotlib/matplotlib.html\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nn = 1024    # data size\nX = np.random.normal(0, 1, n)\nY = np.random.normal(0, 1, n)\nT = np.arctan2(Y, X)    # for color later on\n\nplt.scatter(X, Y, s=75, c=T, alpha=.5)\n\nplt.xlim(-1.5, 1.5)\nplt.xticks(())  # ignore xticks\nplt.ylim(-1.5, 1.5)\nplt.yticks(())  # ignore yticks\n\nplt.show()\n'"
matplotlibTUT/plt11_bar.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 11 - bar\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://www.scipy-lectures.org/intro/matplotlib/matplotlib.html\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nn = 12\nX = np.arange(n)\nY1 = (1 - X / float(n)) * np.random.uniform(0.5, 1.0, n)\nY2 = (1 - X / float(n)) * np.random.uniform(0.5, 1.0, n)\n\nplt.bar(X, +Y1, facecolor=\'#9999ff\', edgecolor=\'white\')\nplt.bar(X, -Y2, facecolor=\'#ff9999\', edgecolor=\'white\')\n\nfor x, y in zip(X, Y1):\n    # ha: horizontal alignment\n    # va: vertical alignment\n    plt.text(x + 0.4, y + 0.05, \'%.2f\' % y, ha=\'center\', va=\'bottom\')\n\nfor x, y in zip(X, Y2):\n    # ha: horizontal alignment\n    # va: vertical alignment\n    plt.text(x + 0.4, -y - 0.05, \'%.2f\' % y, ha=\'center\', va=\'top\')\n\nplt.xlim(-.5, n)\nplt.xticks(())\nplt.ylim(-1.25, 1.25)\nplt.yticks(())\n\nplt.show()\n'"
matplotlibTUT/plt12_contours.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 12 - contours\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://www.scipy-lectures.org/intro/matplotlib/matplotlib.html\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef f(x,y):\n    # the height function\n    return (1 - x / 2 + x**5 + y**3) * np.exp(-x**2 -y**2)\n\nn = 256\nx = np.linspace(-3, 3, n)\ny = np.linspace(-3, 3, n)\nX,Y = np.meshgrid(x, y)\n\n# use plt.contourf to filling contours\n# X, Y and value for (X,Y) point\nplt.contourf(X, Y, f(X, Y), 8, alpha=.75, cmap=plt.cm.hot)\n\n# use plt.contour to add contour lines\nC = plt.contour(X, Y, f(X, Y), 8, colors=\'black\', linewidth=.5)\n# adding label\nplt.clabel(C, inline=True, fontsize=10)\n\nplt.xticks(())\nplt.yticks(())\nplt.show()\n\n'"
matplotlibTUT/plt13_image.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 13 - image\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# image data\na = np.array([0.313660827978, 0.365348418405, 0.423733120134,\n              0.365348418405, 0.439599930621, 0.525083754405,\n              0.423733120134, 0.525083754405, 0.651536351379]).reshape(3,3)\n\n""""""\nfor the value of ""interpolation"", check this:\nhttp://matplotlib.org/examples/images_contours_and_fields/interpolation_methods.html\nfor the value of ""origin""= [\'upper\', \'lower\'], check this:\nhttp://matplotlib.org/examples/pylab_examples/image_origin.html\n""""""\nplt.imshow(a, interpolation=\'nearest\', cmap=\'bone\', origin=\'lower\')\nplt.colorbar(shrink=.92)\n\nplt.xticks(())\nplt.yticks(())\nplt.show()\n\n'"
matplotlibTUT/plt14_3d.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 14 - 3d\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://www.python-course.eu/matplotlib_multiple_figures.php\n""""""\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure()\nax = Axes3D(fig)\n# X, Y value\nX = np.arange(-4, 4, 0.25)\nY = np.arange(-4, 4, 0.25)\nX, Y = np.meshgrid(X, Y)\nR = np.sqrt(X ** 2 + Y ** 2)\n# height value\nZ = np.sin(R)\n\nax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=plt.get_cmap(\'rainbow\'))\n""""""\n============= ================================================\n        Argument      Description\n        ============= ================================================\n        *X*, *Y*, *Z* Data values as 2D arrays\n        *rstride*     Array row stride (step size), defaults to 10\n        *cstride*     Array column stride (step size), defaults to 10\n        *color*       Color of the surface patches\n        *cmap*        A colormap for the surface patches.\n        *facecolors*  Face colors for the individual patches\n        *norm*        An instance of Normalize to map values to colors\n        *vmin*        Minimum value to map\n        *vmax*        Maximum value to map\n        *shade*       Whether to shade the facecolors\n        ============= ================================================\n""""""\n\n# I think this is different from plt12_contours\nax.contourf(X, Y, Z, zdir=\'z\', offset=-2, cmap=plt.get_cmap(\'rainbow\'))\n""""""\n==========  ================================================\n        Argument    Description\n        ==========  ================================================\n        *X*, *Y*,   Data values as numpy.arrays\n        *Z*\n        *zdir*      The direction to use: x, y or z (default)\n        *offset*    If specified plot a projection of the filled contour\n                    on this position in plane normal to zdir\n        ==========  ================================================\n""""""\n\nax.set_zlim(-2, 2)\n\nplt.show()\n\n'"
matplotlibTUT/plt15_subplot.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 15 - subplot\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://www.scipy-lectures.org/intro/matplotlib/matplotlib.html\n""""""\n\nimport matplotlib.pyplot as plt\n\n# example 1:\n###############################\nplt.figure(figsize=(6, 4))\n# plt.subplot(n_rows, n_cols, plot_num)\nplt.subplot(2, 2, 1)\nplt.plot([0, 1], [0, 1])\n\nplt.subplot(222)\nplt.plot([0, 1], [0, 2])\n\nplt.subplot(223)\nplt.plot([0, 1], [0, 3])\n\nplt.subplot(224)\nplt.plot([0, 1], [0, 4])\n\nplt.tight_layout()\n\n# example 2:\n###############################\nplt.figure(figsize=(6, 4))\n# plt.subplot(n_rows, n_cols, plot_num)\nplt.subplot(2, 1, 1)\n# figure splits into 2 rows, 1 col, plot to the 1st sub-fig\nplt.plot([0, 1], [0, 1])\n\nplt.subplot(234)\n# figure splits into 2 rows, 3 col, plot to the 4th sub-fig\nplt.plot([0, 1], [0, 2])\n\nplt.subplot(235)\n# figure splits into 2 rows, 3 col, plot to the 5th sub-fig\nplt.plot([0, 1], [0, 3])\n\nplt.subplot(236)\n# figure splits into 2 rows, 3 col, plot to the 6th sub-fig\nplt.plot([0, 1], [0, 4])\n\n\nplt.tight_layout()\nplt.show()\n'"
matplotlibTUT/plt16_grid_subplot.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 16 - grid\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://matplotlib.org/users/gridspec.html\n""""""\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\n# method 1: subplot2grid\n##########################\nplt.figure()\nax1 = plt.subplot2grid((3, 3), (0, 0), colspan=3)  # stands for axes\nax1.plot([1, 2], [1, 2])\nax1.set_title(\'ax1_title\')\nax2 = plt.subplot2grid((3, 3), (1, 0), colspan=2)\nax3 = plt.subplot2grid((3, 3), (1, 2), rowspan=2)\nax4 = plt.subplot2grid((3, 3), (2, 0))\nax4.scatter([1, 2], [2, 2])\nax4.set_xlabel(\'ax4_x\')\nax4.set_ylabel(\'ax4_y\')\nax5 = plt.subplot2grid((3, 3), (2, 1))\n\n# method 2: gridspec\n#########################\nplt.figure()\ngs = gridspec.GridSpec(3, 3)\n# use index from 0\nax6 = plt.subplot(gs[0, :])\nax7 = plt.subplot(gs[1, :2])\nax8 = plt.subplot(gs[1:, 2])\nax9 = plt.subplot(gs[-1, 0])\nax10 = plt.subplot(gs[-1, -2])\n\n# method 3: easy to define structure\n####################################\nf, ((ax11, ax12), (ax13, ax14)) = plt.subplots(2, 2, sharex=True, sharey=True)\nax11.scatter([1,2], [1,2])\n\nplt.tight_layout()\nplt.show()\n'"
matplotlibTUT/plt17_plot_in_plot.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 17 - plot in plot\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://www.python-course.eu/matplotlib_multiple_figures.php\n""""""\n\nimport matplotlib.pyplot as plt\n\nfig = plt.figure()\nx = [1, 2, 3, 4, 5, 6, 7]\ny = [1, 3, 4, 2, 5, 8, 6]\n\n# below are all percentage\nleft, bottom, width, height = 0.1, 0.1, 0.8, 0.8\nax1 = fig.add_axes([left, bottom, width, height])  # main axes\nax1.plot(x, y, \'r\')\nax1.set_xlabel(\'x\')\nax1.set_ylabel(\'y\')\nax1.set_title(\'title\')\n\nax2 = fig.add_axes([0.2, 0.6, 0.25, 0.25])  # inside axes\nax2.plot(y, x, \'b\')\nax2.set_xlabel(\'x\')\nax2.set_ylabel(\'y\')\nax2.set_title(\'title inside 1\')\n\n\n# different method to add axes\n####################################\nplt.axes([0.6, 0.2, 0.25, 0.25])\nplt.plot(y[::-1], x, \'g\')\nplt.xlabel(\'x\')\nplt.ylabel(\'y\')\nplt.title(\'title inside 2\')\n\nplt.show()\n'"
matplotlibTUT/plt18_secondary_yaxis.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 18 - secondary y axis\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://www.python-course.eu/matplotlib_multiple_figures.php\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.arange(0, 10, 0.1)\ny1 = 0.05 * x**2\ny2 = -1 *y1\n\nfig, ax1 = plt.subplots()\n\nax2 = ax1.twinx()    # mirror the ax1\nax1.plot(x, y1, \'g-\')\nax2.plot(x, y2, \'b-\')\n\nax1.set_xlabel(\'X data\')\nax1.set_ylabel(\'Y1 data\', color=\'g\')\nax2.set_ylabel(\'Y2 data\', color=\'b\')\n\nplt.show()\n'"
matplotlibTUT/plt19_animation.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 19 - animation\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\n\nTutorial reference:\nhttp://matplotlib.org/examples/animation/simple_anim.html\n\nMore animation example code:\nhttp://matplotlib.org/examples/animation/\n""""""\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib import animation\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)\nline, = ax.plot(x, np.sin(x))\n\n\ndef animate(i):\n    line.set_ydata(np.sin(x + i/10.0))  # update the data\n    return line,\n\n\n# Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.sin(x))\n    return line,\n\n# call the animator.  blit=True means only re-draw the parts that have changed.\n# blit=True dose not work on Mac, set blit=False\n# interval= update frequency\nani = animation.FuncAnimation(fig=fig, func=animate, frames=100, init_func=init,\n                              interval=20, blit=False)\n\n# save the animation as an mp4.  This requires ffmpeg or mencoder to be\n# installed.  The extra_args ensure that the x264 codec is used, so that\n# the video can be embedded in html5.  You may need to adjust this for\n# your system: for more information, see\n# http://matplotlib.sourceforge.net/api/animation_api.html\n# anim.save(\'basic_animation.mp4\', fps=30, extra_args=[\'-vcodec\', \'libx264\'])\n\nplt.show()'"
matplotlibTUT/plt1_why.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 1 - why\n\n""""""\n1. matplotlib is a powerful python data visualization tool;\n2. similar with MATLAB. If know matlab, easy to move over to python;\n3. easy to plot 2D, 3D data;\n4. you can even make animation.\n""""""'"
matplotlibTUT/plt2_install.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 2 - install\n\n""""""\nMake sure you have installed numpy.\n\n------------------------------\nINSTALL on Linux:\nIf you have python3, in terminal you will type:\n$ sudo apt-get install python3-matplotlib\n\nOtherwise, if python2, type:\n$ sudo apt-get install python-matplotlib\n\n-------------------------------\nINSTALL on MacOS\nFor python3:\n$ pip3 install matplotlib\n\nFor python2:\n$ pip install matplotlib\n\n--------------------------------\nINSTALL on Windows:\n1. make sure you install Visual Studio;\n2. go to: https://pypi.python.org/pypi/matplotlib/\n3. find the wheel file (a file ending in .whl) matches your python version and system\n(e.g. cp35 for python3.5, win32 for 32-bit system, win_amd64 for 64-bit system);\n4. Copy the .whl file to your project folder, open a command window,\nand navigate to the project folder. Then use pip to install matplotlib:\n\ne.g.\n> cd python_work\npython_work> python -m pip3 install matplotlib-1.4.3-cp35-none-win32.whl\n\nIf not success. Try the alternative way: using ""Anaconda"" to install.\nPlease search this by yourself.\n\n""""""'"
matplotlibTUT/plt3_simple_plot.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 3 - simple plot\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(-1, 1, 50)\ny = 2*x + 1\n# y = x**2\nplt.plot(x, y)\nplt.show()\n'"
matplotlibTUT/plt4_figure.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 4 - figure\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://www.scipy-lectures.org/intro/matplotlib/matplotlib.html\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(-3, 3, 50)\ny1 = 2*x + 1\ny2 = x**2\n\nplt.figure()\nplt.plot(x, y1)\n\n\nplt.figure(num=3, figsize=(8, 5),)\nplt.plot(x, y2)\n# plot the second curve in this figure with certain parameters\nplt.plot(x, y1, color=\'red\', linewidth=1.0, linestyle=\'--\')\nplt.show()\n'"
matplotlibTUT/plt5_ax_setting1.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 5 - axis setting\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://www.scipy-lectures.org/intro/matplotlib/matplotlib.html\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(-3, 3, 50)\ny1 = 2*x + 1\ny2 = x**2\n\nplt.figure()\nplt.plot(x, y2)\n# plot the second curve in this figure with certain parameters\nplt.plot(x, y1, color=\'red\', linewidth=1.0, linestyle=\'--\')\n# set x limits\nplt.xlim((-1, 2))\nplt.ylim((-2, 3))\nplt.xlabel(\'I am x\')\nplt.ylabel(\'I am y\')\n\n# set new sticks\nnew_ticks = np.linspace(-1, 2, 5)\nprint(new_ticks)\nplt.xticks(new_ticks)\n# set tick labels\nplt.yticks([-2, -1.8, -1, 1.22, 3],\n           [r\'$really\\ bad$\', r\'$bad$\', r\'$normal$\', r\'$good$\', r\'$really\\ good$\'])\nplt.show()\n'"
matplotlibTUT/plt6_ax_setting2.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 6 - axis setting\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://www.scipy-lectures.org/intro/matplotlib/matplotlib.html\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(-3, 3, 50)\ny1 = 2*x + 1\ny2 = x**2\n\nplt.figure()\nplt.plot(x, y2)\n# plot the second curve in this figure with certain parameters\nplt.plot(x, y1, color=\'red\', linewidth=1.0, linestyle=\'--\')\n# set x limits\nplt.xlim((-1, 2))\nplt.ylim((-2, 3))\n\n# set new ticks\nnew_ticks = np.linspace(-1, 2, 5)\nplt.xticks(new_ticks)\n# set tick labels\nplt.yticks([-2, -1.8, -1, 1.22, 3],\n           [\'$really\\ bad$\', \'$bad$\', \'$normal$\', \'$good$\', \'$really\\ good$\'])\n# to use \'$ $\' for math text and nice looking, e.g. \'$\\pi$\'\n\n# gca = \'get current axis\'\nax = plt.gca()\nax.spines[\'right\'].set_color(\'none\')\nax.spines[\'top\'].set_color(\'none\')\n\nax.xaxis.set_ticks_position(\'bottom\')\n# ACCEPTS: [ \'top\' | \'bottom\' | \'both\' | \'default\' | \'none\' ]\n\nax.spines[\'bottom\'].set_position((\'data\', 0))\n# the 1st is in \'outward\' | \'axes\' | \'data\'\n# axes: percentage of y axis\n# data: depend on y data\n\nax.yaxis.set_ticks_position(\'left\')\n# ACCEPTS: [ \'left\' | \'right\' | \'both\' | \'default\' | \'none\' ]\n\nax.spines[\'left\'].set_position((\'data\',0))\nplt.show()\n'"
matplotlibTUT/plt7_legend.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 7 - legend\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://www.scipy-lectures.org/intro/matplotlib/matplotlib.html\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(-3, 3, 50)\ny1 = 2*x + 1\ny2 = x**2\n\nplt.figure()\n# set x limits\nplt.xlim((-1, 2))\nplt.ylim((-2, 3))\n\n# set new sticks\nnew_sticks = np.linspace(-1, 2, 5)\nplt.xticks(new_sticks)\n# set tick labels\nplt.yticks([-2, -1.8, -1, 1.22, 3],\n           [r\'$really\\ bad$\', r\'$bad$\', r\'$normal$\', r\'$good$\', r\'$really\\ good$\'])\n\nl1, = plt.plot(x, y1, label=\'linear line\')\nl2, = plt.plot(x, y2, color=\'red\', linewidth=1.0, linestyle=\'--\', label=\'square line\')\n\nplt.legend(loc=\'upper right\')\n# plt.legend(handles=[l1, l2], labels=[\'up\', \'down\'],  loc=\'best\')\n# the "","" is very important in here l1, = plt... and l2, = plt... for this step\n""""""legend( handles=(line1, line2, line3),\n           labels=(\'label1\', \'label2\', \'label3\'),\n           \'upper right\')\n    The *loc* location codes are::\n\n          \'best\' : 0,          (currently not supported for figure legends)\n          \'upper right\'  : 1,\n          \'upper left\'   : 2,\n          \'lower left\'   : 3,\n          \'lower right\'  : 4,\n          \'right\'        : 5,\n          \'center left\'  : 6,\n          \'center right\' : 7,\n          \'lower center\' : 8,\n          \'upper center\' : 9,\n          \'center\'       : 10,""""""\n\nplt.show()\n'"
matplotlibTUT/plt8_annotation.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 8 - annotation\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\n\nTutorial reference:\nhttp://www.scipy-lectures.org/intro/matplotlib/matplotlib.html\n\nMathematical expressions:\nhttp://matplotlib.org/users/mathtext.html#mathtext-tutorial\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(-3, 3, 50)\ny = 2*x + 1\n\nplt.figure(num=1, figsize=(8, 5),)\nplt.plot(x, y,)\n\nax = plt.gca()\nax.spines[\'right\'].set_color(\'none\')\nax.spines[\'top\'].set_color(\'none\')\nax.spines[\'top\'].set_color(\'none\')\nax.xaxis.set_ticks_position(\'bottom\')\nax.spines[\'bottom\'].set_position((\'data\', 0))\nax.yaxis.set_ticks_position(\'left\')\nax.spines[\'left\'].set_position((\'data\', 0))\n\nx0 = 1\ny0 = 2*x0 + 1\nplt.plot([x0, x0,], [0, y0,], \'k--\', linewidth=2.5)\nplt.scatter([x0, ], [y0, ], s=50, color=\'b\')\n\n# method 1:\n#####################\nplt.annotate(r\'$2x+1=%s$\' % y0, xy=(x0, y0), xycoords=\'data\', xytext=(+30, -30),\n             textcoords=\'offset points\', fontsize=16,\n             arrowprops=dict(arrowstyle=\'->\', connectionstyle=""arc3,rad=.2""))\n\n# method 2:\n########################\nplt.text(-3.7, 3, r\'$This\\ is\\ the\\ some\\ text. \\mu\\ \\sigma_i\\ \\alpha_t$\',\n         fontdict={\'size\': 16, \'color\': \'r\'})\n\nplt.show()\n'"
matplotlibTUT/plt9_tick_visibility.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 9 - tick_visibility\n""""""\nPlease note, this script is for python3+.\nIf you are using python2+, please modify it accordingly.\nTutorial reference:\nhttp://www.scipy-lectures.org/intro/matplotlib/matplotlib.html\n""""""\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(-3, 3, 50)\ny = 0.1*x\n\nplt.figure()\nplt.plot(x, y, linewidth=10, zorder=1)      # set zorder for ordering the plot in plt 2.0.2 or higher\nplt.ylim(-2, 2)\nax = plt.gca()\nax.spines[\'right\'].set_color(\'none\')\nax.spines[\'top\'].set_color(\'none\')\nax.spines[\'top\'].set_color(\'none\')\nax.xaxis.set_ticks_position(\'bottom\')\nax.spines[\'bottom\'].set_position((\'data\', 0))\nax.yaxis.set_ticks_position(\'left\')\nax.spines[\'left\'].set_position((\'data\', 0))\n\n\nfor label in ax.get_xticklabels() + ax.get_yticklabels():\n    label.set_fontsize(12)\n    # set zorder for ordering the plot in plt 2.0.2 or higher\n    label.set_bbox(dict(facecolor=\'white\', edgecolor=\'none\', alpha=0.8, zorder=2))\nplt.show()\n'"
multiprocessingTUT/multiprocessing3_queue.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport multiprocessing as mp\n\ndef job(q):\n    res = 0\n    for i in range(1000):\n        res += i+i**2+i**3\n    q.put(res) # queue\n\nif __name__ == '__main__':\n    q = mp.Queue()\n    p1 = mp.Process(target=job, args=(q,))\n    p2 = mp.Process(target=job, args=(q,))\n    p1.start()\n    p2.start()\n    p1.join()\n    p2.join()\n    res1 = q.get()\n    res2 = q.get()\n    print(res1+res2)\n\n"""
multiprocessingTUT/multiprocessing4_efficiency_comparison.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport multiprocessing as mp\nimport threading as td\nimport time\n\ndef job(q):\n    res = 0\n    for i in range(1000000):\n        res += i+i**2+i**3\n    q.put(res) # queue\n\ndef multicore():\n    q = mp.Queue()\n    p1 = mp.Process(target=job, args=(q,))\n    p2 = mp.Process(target=job, args=(q,))\n    p1.start()\n    p2.start()\n    p1.join()\n    p2.join()\n    res1 = q.get()\n    res2 = q.get()\n    print('multicore:' , res1+res2)\n\ndef normal():\n    res = 0\n    for _ in range(2):\n        for i in range(1000000):\n            res += i+i**2+i**3\n    print('normal:', res)\n\ndef multithread():\n    q = mp.Queue()\n    t1 = td.Thread(target=job, args=(q,))\n    t2 = td.Thread(target=job, args=(q,))\n    t1.start()\n    t2.start()\n    t1.join()\n    t2.join()\n    res1 = q.get()\n    res2 = q.get()\n    print('multithread:', res1+res2)\n\nif __name__ == '__main__':\n    st = time.time()\n    normal()\n    st1= time.time()\n    print('normal time:', st1 - st)\n    multithread()\n    st2 = time.time()\n    print('multithread time:', st2 - st1)\n    multicore()\n    print('multicore time:', time.time()-st2)\n\n"""
multiprocessingTUT/multiprocessing5_pool.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport multiprocessing as mp\n\ndef job(x):\n    return x*x\n\ndef multicore():\n    pool = mp.Pool(processes=2)\n    res = pool.map(job, range(10))\n    print(res)\n    res = pool.apply_async(job, (2,))\n    print(res.get())\n    multi_res =[pool.apply_async(job, (i,)) for i in range(10)]\n    print([res.get() for res in multi_res])\n\nif __name__ == '__main__':\n    multicore()\n\n\n"""
multiprocessingTUT/multiprocessing7_lock.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport multiprocessing as mp\nimport time\n\ndef job(v, num, l):\n    l.acquire()\n    for _ in range(10):\n        time.sleep(0.1)\n        v.value += num\n        print(v.value)\n    l.release()\n\ndef multicore():\n    l = mp.Lock()\n    v = mp.Value('i', 0)\n    p1 = mp.Process(target=job, args=(v, 1, l))\n    p2 = mp.Process(target=job, args=(v, 3, l))\n    p1.start()\n    p2.start()\n    p1.join()\n    p2.join()\n\nif __name__ == '__main__':\n    multicore()\n\n\n\n"""
numpy&pandas/11_pandas_intro.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport pandas as pd\nimport numpy as np\n\ns = pd.Series([1,3,6,np.nan,4,1]) # similar with 1D numpy\nprint(s)\ndates = pd.date_range(\'20160101\', periods=6)\ndf = pd.DataFrame(np.random.randn(6,4), index=dates, columns=[\'A\',\'B\',\'C\',\'D\'])\nprint(df[\'B\'])\ndf2 = pd.DataFrame({\'A\' : 1.,\n                       \'B\' : pd.Timestamp(\'20130102\'),\n                        \'C\' : pd.Series(1,index=list(range(4)),dtype=\'float32\'),\n                        \'D\' : np.array([3] * 4,dtype=\'int32\'),\n                        \'E\' : pd.Categorical([""test"",""train"",""test"",""train""]),\n                        \'F\' : \'foo\'})\nprint(df2)\nprint(df2.dtypes)\n\nprint(df.index)\nprint(df.columns)\nprint(df.values)\nprint(df.describe())\nprint(df.T)\nprint(df.sort_index(axis=1, ascending=False))\nprint(df.sort_values(by=\'B\'))'"
numpy&pandas/12_selection.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range(\'20130101\', periods=6)\ndf = pd.DataFrame(np.random.randn(6,4), index=dates, columns=[\'A\', \'B\', \'C\', \'D\'])\n\nprint(df[\'A\'], df.A)\nprint(df[0:3], df[\'20130102\':\'20130104\'])\n\n# select by label: loc\nprint(df.loc[\'20130102\'])\nprint(df.loc[:,[\'A\',\'B\']])\nprint(df.loc[\'20130102\', [\'A\',\'B\']])\n\n# select by position: iloc\nprint(df.iloc[3])\nprint(df.iloc[3, 1])\nprint(df.iloc[3:5,0:2])\nprint(df.iloc[[1,2,4],[0,2]])\n\n# mixed selection: ix\nprint(df.ix[:3, [\'A\', \'C\']])\n# Boolean indexing\nprint(df[df.A > 0])\n\n\n'"
numpy&pandas/13_set_value.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range(\'20130101\', periods=6)\ndf = pd.DataFrame(np.random.randn(6,4), index=dates, columns=[\'A\', \'B\', \'C\', \'D\'])\n\ndf.iloc[2,2] = 1111\ndf.loc[\'2013-01-03\', \'D\'] = 2222\ndf.A[df.A>0] = 0\ndf[\'F\'] = np.nan\ndf[\'G\']  = pd.Series([1,2,3,4,5,6], index=pd.date_range(\'20130101\', periods=6))\nprint(df)'"
numpy&pandas/14_nan.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range(\'20130101\', periods=6)\ndf = pd.DataFrame(np.arange(24).reshape((6,4)), index=dates, columns=[\'A\', \'B\', \'C\', \'D\'])\n\ndf.iloc[0,1] = np.nan\ndf.iloc[1,2] = np.nan\nprint(df.dropna(axis=0, how=\'any\'))   # how={\'any\', \'all\'}\nprint(df.fillna(value=0))\nprint(pd.isnull(df))'"
numpy&pandas/16_concat.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport pandas as pd\nimport numpy as np\n\n# concatenating\n# ignore index\ndf1 = pd.DataFrame(np.ones((3,4))*0, columns=[\'a\',\'b\',\'c\',\'d\'])\ndf2 = pd.DataFrame(np.ones((3,4))*1, columns=[\'a\',\'b\',\'c\',\'d\'])\ndf3 = pd.DataFrame(np.ones((3,4))*2, columns=[\'a\',\'b\',\'c\',\'d\'])\nres = pd.concat([df1, df2, df3], axis=0, ignore_index=True)\n\n# join, (\'inner\', \'outer\')\ndf1 = pd.DataFrame(np.ones((3,4))*0, columns=[\'a\',\'b\',\'c\',\'d\'], index=[1,2,3])\ndf2 = pd.DataFrame(np.ones((3,4))*1, columns=[\'b\',\'c\',\'d\', \'e\'], index=[2,3,4])\nres = pd.concat([df1, df2], axis=1, join=\'outer\')\nres = pd.concat([df1, df2], axis=1, join=\'inner\')\n\n# join_axes\nres = pd.concat([df1, df2], axis=1, join_axes=[df1.index])\n\n# append\ndf1 = pd.DataFrame(np.ones((3,4))*0, columns=[\'a\',\'b\',\'c\',\'d\'])\ndf2 = pd.DataFrame(np.ones((3,4))*1, columns=[\'a\',\'b\',\'c\',\'d\'])\ndf2 = pd.DataFrame(np.ones((3,4))*1, columns=[\'b\',\'c\',\'d\', \'e\'], index=[2,3,4])\nres = df1.append(df2, ignore_index=True)\nres = df1.append([df2, df3])\n\ns1 = pd.Series([1,2,3,4], index=[\'a\',\'b\',\'c\',\'d\'])\nres = df1.append(s1, ignore_index=True)\n\nprint(res)'"
numpy&pandas/17_merge.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport pandas as pd\n\n# merging two df by key/keys. (may be used in database)\n# simple example\nleft = pd.DataFrame({\'key\': [\'K0\', \'K1\', \'K2\', \'K3\'],\n                                  \'A\': [\'A0\', \'A1\', \'A2\', \'A3\'],\n                                  \'B\': [\'B0\', \'B1\', \'B2\', \'B3\']})\nright = pd.DataFrame({\'key\': [\'K0\', \'K1\', \'K2\', \'K3\'],\n                                    \'C\': [\'C0\', \'C1\', \'C2\', \'C3\'],\n                                    \'D\': [\'D0\', \'D1\', \'D2\', \'D3\']})\nprint(left)\nprint(right)\nres = pd.merge(left, right, on=\'key\')\nprint(res)\n\n# consider two keys\nleft = pd.DataFrame({\'key1\': [\'K0\', \'K0\', \'K1\', \'K2\'],\n                             \'key2\': [\'K0\', \'K1\', \'K0\', \'K1\'],\n                             \'A\': [\'A0\', \'A1\', \'A2\', \'A3\'],\n                             \'B\': [\'B0\', \'B1\', \'B2\', \'B3\']})\nright = pd.DataFrame({\'key1\': [\'K0\', \'K1\', \'K1\', \'K2\'],\n                              \'key2\': [\'K0\', \'K0\', \'K0\', \'K0\'],\n                              \'C\': [\'C0\', \'C1\', \'C2\', \'C3\'],\n                              \'D\': [\'D0\', \'D1\', \'D2\', \'D3\']})\nprint(left)\nprint(right)\nres = pd.merge(left, right, on=[\'key1\', \'key2\'], how=\'inner\')  # default for how=\'inner\'\n# how = [\'left\', \'right\', \'outer\', \'inner\']\nres = pd.merge(left, right, on=[\'key1\', \'key2\'], how=\'left\')\nprint(res)\n\n# indicator\ndf1 = pd.DataFrame({\'col1\':[0,1], \'col_left\':[\'a\',\'b\']})\ndf2 = pd.DataFrame({\'col1\':[1,2,2],\'col_right\':[2,2,2]})\nprint(df1)\nprint(df2)\nres = pd.merge(df1, df2, on=\'col1\', how=\'outer\', indicator=True)\n# give the indicator a custom name\nres = pd.merge(df1, df2, on=\'col1\', how=\'outer\', indicator=\'indicator_column\')\n\n\n# merged by index\nleft = pd.DataFrame({\'A\': [\'A0\', \'A1\', \'A2\'],\n                                  \'B\': [\'B0\', \'B1\', \'B2\']},\n                                  index=[\'K0\', \'K1\', \'K2\'])\nright = pd.DataFrame({\'C\': [\'C0\', \'C2\', \'C3\'],\n                                     \'D\': [\'D0\', \'D2\', \'D3\']},\n                                      index=[\'K0\', \'K2\', \'K3\'])\nprint(left)\nprint(right)\n# left_index and right_index\nres = pd.merge(left, right, left_index=True, right_index=True, how=\'outer\')\nres = pd.merge(left, right, left_index=True, right_index=True, how=\'inner\')\n\n# handle overlapping\nboys = pd.DataFrame({\'k\': [\'K0\', \'K1\', \'K2\'], \'age\': [1, 2, 3]})\ngirls = pd.DataFrame({\'k\': [\'K0\', \'K0\', \'K3\'], \'age\': [4, 5, 6]})\nres = pd.merge(boys, girls, on=\'k\', suffixes=[\'_boy\', \'_girl\'], how=\'inner\')\nprint(res)\n\n# join function in pandas is similar with merge. If know merge, you will understand join\n'"
numpy&pandas/18_plot.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# plot data\n\n# Series\ndata = pd.Series(np.random.randn(1000), index=np.arange(1000))\ndata = data.cumsum()\n##data.plot()\n\n# DataFrame\ndata = pd.DataFrame(np.random.randn(1000, 4), index=np.arange(1000), columns=list(""ABCD""))\ndata = data.cumsum()\n# plot methods:\n# \'bar\', \'hist\', \'box\', \'kde\', \'area\', scatter\', hexbin\', \'pie\'\nax = data.plot.scatter(x=\'A\', y=\'B\', color=\'DarkBlue\', label=""Class 1"")\ndata.plot.scatter(x=\'A\', y=\'C\', color=\'LightGreen\', label=\'Class 2\', ax=ax)\n\nplt.show()'"
sklearnTUT/sk10_cross_validation3.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nfrom sklearn.learning_curve import  validation_curve\nfrom sklearn.datasets import load_digits\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndigits = load_digits()\nX = digits.data\ny = digits.target\nparam_range = np.logspace(-6, -2.3, 5)\ntrain_loss, test_loss = validation_curve(\n        SVC(), X, y, param_name=\'gamma\', param_range=param_range, cv=10,\n        scoring=\'mean_squared_error\')\ntrain_loss_mean = -np.mean(train_loss, axis=1)\ntest_loss_mean = -np.mean(test_loss, axis=1)\n\nplt.plot(param_range, train_loss_mean, \'o-\', color=""r"",\n             label=""Training"")\nplt.plot(param_range, test_loss_mean, \'o-\', color=""g"",\n             label=""Cross-validation"")\n\nplt.xlabel(""gamma"")\nplt.ylabel(""Loss"")\nplt.legend(loc=""best"")\nplt.show()'"
sklearnTUT/sk11_save.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nfrom sklearn import svm\nfrom sklearn import datasets\n\nclf = svm.SVC()\niris = datasets.load_iris()\nX, y = iris.data, iris.target\nclf.fit(X, y)\n\n# method 1: pickle\nimport pickle\n# save\nwith open(\'save/clf.pickle\', \'wb\') as f:\n    pickle.dump(clf, f)\n# restore\nwith open(\'save/clf.pickle\', \'rb\') as f:\n   clf2 = pickle.load(f)\n   print(clf2.predict(X[0:1]))\n\n# method 2: joblib\nfrom sklearn.externals import joblib\n# Save\njoblib.dump(clf, \'save/clf.pkl\')\n# restore\nclf3 = joblib.load(\'save/clf.pkl\')\nprint(clf3.predict(X[0:1]))'"
sklearnTUT/sk4_learning_pattern.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\niris = datasets.load_iris()\niris_X = iris.data\niris_y = iris.target\n\n##print(iris_X[:2, :])\n##print(iris_y)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    iris_X, iris_y, test_size=0.3)\n\n##print(y_train)\n\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nprint(knn.predict(X_test))\nprint(y_test)\n\n\n'"
sklearnTUT/sk5_datasets.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nfrom sklearn import datasets\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\nloaded_data = datasets.load_boston()\ndata_X = loaded_data.data\ndata_y = loaded_data.target\n\nmodel = LinearRegression()\nmodel.fit(data_X, data_y)\n\nprint(model.predict(data_X[:4, :]))\nprint(data_y[:4])\n\nX, y = datasets.make_regression(n_samples=100, n_features=1, n_targets=1, noise=10)\nplt.scatter(X, y)\nplt.show()\n\n\n\n\n\n\n'"
sklearnTUT/sk6_model_attribute_method.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nfrom sklearn import datasets\nfrom sklearn.linear_model import LinearRegression\n\nloaded_data = datasets.load_boston()\ndata_X = loaded_data.data\ndata_y = loaded_data.target\n\nmodel = LinearRegression()\nmodel.fit(data_X, data_y)\n\nprint(model.predict(data_X[:4, :]))\nprint(model.coef_)\nprint(model.intercept_)\nprint(model.get_params())\nprint(model.score(data_X, data_y)) # R^2 coefficient of determination\n'"
sklearnTUT/sk7_normalization.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nfrom sklearn import preprocessing\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets.samples_generator import make_classification\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\n\na = np.array([[10, 2.7, 3.6],\n                     [-100, 5, -2],\n                     [120, 20, 40]], dtype=np.float64)\nprint(a)\nprint(preprocessing.scale(a))\n\nX, y = make_classification(n_samples=300, n_features=2 , n_redundant=0, n_informative=2,\n                           random_state=22, n_clusters_per_class=1, scale=100)\nplt.scatter(X[:, 0], X[:, 1], c=y)\nplt.show()\nX = preprocessing.scale(X)    # normalization step\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)\nclf = SVC()\nclf.fit(X_train, y_train)\nprint(clf.score(X_test, y_test))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'"
sklearnTUT/sk9_cross_validation2.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nfrom sklearn.learning_curve import  learning_curve\nfrom sklearn.datasets import load_digits\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndigits = load_digits()\nX = digits.data\ny = digits.target\ntrain_sizes, train_loss, test_loss= learning_curve(\n        SVC(gamma=0.01), X, y, cv=10, scoring=\'mean_squared_error\',\n        train_sizes=[0.1, 0.25, 0.5, 0.75, 1])\ntrain_loss_mean = -np.mean(train_loss, axis=1)\ntest_loss_mean = -np.mean(test_loss, axis=1)\n\nplt.plot(train_sizes, train_loss_mean, \'o-\', color=""r"",\n             label=""Training"")\nplt.plot(train_sizes, test_loss_mean, \'o-\', color=""g"",\n             label=""Cross-validation"")\n\nplt.xlabel(""Training examples"")\nplt.ylabel(""Loss"")\nplt.legend(loc=""best"")\nplt.show()\n\n\n\n'"
tensorflowTUT/tensorflow10_def_add_layer.py,3,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\n\n\ndef add_layer(inputs, in_size, out_size, activation_function=None):\n    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n    if activation_function is None:\n        outputs = Wx_plus_b\n    else:\n        outputs = activation_function(Wx_plus_b)\n    return outputs\n'"
tensorflowTUT/tensorflow11_build_network.py,13,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\n\ndef add_layer(inputs, in_size, out_size, activation_function=None):\n    # add one more layer and return the output of this layer\n    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n    if activation_function is None:\n        outputs = Wx_plus_b\n    else:\n        outputs = activation_function(Wx_plus_b)\n    return outputs\n\n# Make up some real data\nx_data = np.linspace(-1,1,300)[:, np.newaxis]\nnoise = np.random.normal(0, 0.05, x_data.shape)\ny_data = np.square(x_data) - 0.5 + noise\n\n# define placeholder for inputs to network\nxs = tf.placeholder(tf.float32, [None, 1])\nys = tf.placeholder(tf.float32, [None, 1])\n# add hidden layer\nl1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n# add output layer\nprediction = add_layer(l1, 10, 1, activation_function=None)\n\n# the error between prediction and real data\nloss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n                     reduction_indices=[1]))\ntrain_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n\n# important step\n# tf.initialize_all_variables() no long valid from\n# 2017-03-02 if using tensorflow >= 0.12\nif int((tf.__version__).split(\'.\')[1]) < 12:\n    init = tf.initialize_all_variables()\nelse:\n    init = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\nfor i in range(1000):\n    # training\n    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n    if i % 50 == 0:\n        # to see the step improvement\n        print(sess.run(loss, feed_dict={xs: x_data, ys: y_data}))\n\n'"
tensorflowTUT/tensorflow12_plut_result.py,13,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef add_layer(inputs, in_size, out_size, activation_function=None):\n    # add one more layer and return the output of this layer\n    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n    if activation_function is None:\n        outputs = Wx_plus_b\n    else:\n        outputs = activation_function(Wx_plus_b)\n    return outputs\n\n# Make up some real data\nx_data = np.linspace(-1,1,300)[:, np.newaxis]\nnoise = np.random.normal(0, 0.05, x_data.shape)\ny_data = np.square(x_data) - 0.5 + noise\n\n# define placeholder for inputs to network\nxs = tf.placeholder(tf.float32, [None, 1])\nys = tf.placeholder(tf.float32, [None, 1])\n# add hidden layer\nl1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n# add output layer\nprediction = add_layer(l1, 10, 1, activation_function=None)\n\n# the error between prediciton and real data\nloss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n                     reduction_indices=[1]))\ntrain_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n\n# important step\n# tf.initialize_all_variables() no long valid from\n# 2017-03-02 if using tensorflow >= 0.12\nif int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n    init = tf.initialize_all_variables()\nelse:\n    init = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\n# plot the real data\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nax.scatter(x_data, y_data)\nplt.ion()\nplt.show()\n\nfor i in range(1000):\n    # training\n    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n    if i % 50 == 0:\n        # to visualize the result and improvement\n        try:\n            ax.lines.remove(lines[0])\n        except Exception:\n            pass\n        prediction_value = sess.run(prediction, feed_dict={xs: x_data})\n        # plot the prediction\n        lines = ax.plot(x_data, prediction_value, \'r-\', lw=5)\n        plt.pause(0.1)\n\n\n\n\n'"
tensorflowTUT/tensorflow6_session.py,5,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\n\nmatrix1 = tf.constant([[3, 3]])\nmatrix2 = tf.constant([[2],\n                       [2]])\nproduct = tf.matmul(matrix1, matrix2)  # matrix multiply np.dot(m1, m2)\n\n# method 1\nsess = tf.Session()\nresult = sess.run(product)\nprint(result)\nsess.close()\n\n# method 2\nwith tf.Session() as sess:\n    result2 = sess.run(product)\n    print(result2)\n\n\n\n\n\n'"
tensorflowTUT/tensorflow7_variable.py,9,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\n\nstate = tf.Variable(0, name=\'counter\')\n#print(state.name)\none = tf.constant(1)\n\nnew_value = tf.add(state, one)\nupdate = tf.assign(state, new_value)\n\n# tf.initialize_all_variables() no long valid from\n# 2017-03-02 if using tensorflow >= 0.12\nif int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n    init = tf.initialize_all_variables()\nelse:\n    init = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n    for _ in range(3):\n        sess.run(update)\n        print(sess.run(state))\n\n'"
tensorflowTUT/tensorflow8_feeds.py,4,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\n\ninput1 = tf.placeholder(tf.float32)\ninput2 = tf.placeholder(tf.float32)\noutput = tf.multiply(input1, input2)\n\nwith tf.Session() as sess:\n    print(sess.run(output, feed_dict={input1: [7.], input2: [2.]}))\n'"
tensorflowTUT/tf19_saver.py,12,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\n\n# Save to file\n# remember to define the same dtype and shape when restore\n# W = tf.Variable([[1,2,3],[3,4,5]], dtype=tf.float32, name=\'weights\')\n# b = tf.Variable([[1,2,3]], dtype=tf.float32, name=\'biases\')\n\n# tf.initialize_all_variables() no long valid from\n# 2017-03-02 if using tensorflow >= 0.12\n# if int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n#     init = tf.initialize_all_variables()\n# else:\n#     init = tf.global_variables_initializer()\n#\n# saver = tf.train.Saver()\n#\n# with tf.Session() as sess:\n#    sess.run(init)\n#    save_path = saver.save(sess, ""my_net/save_net.ckpt"")\n#    print(""Save to path: "", save_path)\n\n\n################################################\n# restore variables\n# redefine the same shape and same type for your variables\nW = tf.Variable(np.arange(6).reshape((2, 3)), dtype=tf.float32, name=""weights"")\nb = tf.Variable(np.arange(3).reshape((1, 3)), dtype=tf.float32, name=""biases"")\n\n# not need init step\n\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    saver.restore(sess, ""my_net/save_net.ckpt"")\n    print(""weights:"", sess.run(W))\n    print(""biases:"", sess.run(b))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'"
theanoTUT/theano14_summary.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 14 - summary\n\n""""""\n==============================\nSummary:\n-----------------------------------------------\n1. Understand the basic usage of Theano;\n2. Built a regression neural networks;\n3. Built a classification neural networks;\n4. Understand the overfitting and the solutions for solving this problem;\n5. Save your networks for future usage.\n\n==============================\nGPU computation:\n-----------------------------------------------\nTheano tutorial link: http://deeplearning.net/software/theano/tutorial/using_gpu.html\nRequirement: NVIDIA cards and CUDA backend\n\n==============================\nTheano Convolutional Neural Networks:\n----------------------------------------------\nTheano tutorial link: http://deeplearning.net/tutorial/lenet.html\n\n\n==============================\nTheano Recurrent Neural Networks:\n-----------------------------------------------\nTheano tutorial link: http://deeplearning.net/tutorial/rnnslu.html\n\n\n""""""'"
theanoTUT/theano2_install.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 2 - Install theano\n\n""""""\nrequirements:\n1. python 2 >=2.6 or python 3>=3.3\n2. Numpy >= 1.7.1\n3. Scipy >=0.11\n\nIf using CPU, no other requirement.\nBut if using GPU, you will need NVIDIA CUDA drivers and SDK.\n\nThe must easy way to install theano is to use pip install.\n1. open your terminal (MacOS and Linux), or your command window (Windows)\n2. type ""pip install theano"" (for python 2x); type ""pip3 install theano"" (for python 3x)\n\nNote: to install theano on Windows machine may be a little bit struggling. If you encounter any\nproblem, please refer to this web page:\nhttp://deeplearning.net/software/theano/install_windows.html#install-windows\n\n""""""\n'"
theanoTUT/theano3_what_does_ML_do.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 3 - What does machine learning do?\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport theano\nimport theano.tensor as T\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nclass Layer(object):\n    def __init__(self, inputs, in_size, out_size, activation_function=None):\n        self.W = theano.shared(np.random.normal(0, 1, (in_size, out_size)))\n        self.b = theano.shared(np.zeros((out_size, )) + 0.1)\n        self.Wx_plus_b = T.dot(inputs, self.W) + self.b\n        self.activation_function = activation_function\n        if activation_function is None:\n            self.outputs = self.Wx_plus_b\n        else:\n            self.outputs = self.activation_function(self.Wx_plus_b)\n\n\n# Make up some fake data\nx_data = np.linspace(-1, 1, 300)[:, np.newaxis]\nnoise = np.random.normal(0, 0.05, x_data.shape)\ny_data = np.square(x_data) - 0.5 + noise        # y = x^2 - 0.5\n\n# show the fake data\nplt.scatter(x_data, y_data)\nplt.show()\n\n# determine the inputs dtype\nx = T.dmatrix(""x"")\ny = T.dmatrix(""y"")\n\n# add layers\nl1 = Layer(x, 1, 10, T.nnet.relu)\nl2 = Layer(l1.outputs, 10, 1, None)\n\n# compute the cost\ncost = T.mean(T.square(l2.outputs - y))\n\n# compute the gradients\ngW1, gb1, gW2, gb2 = T.grad(cost, [l1.W, l1.b, l2.W, l2.b])\n\n# apply gradient descent\nlearning_rate = 0.1\ntrain = theano.function(\n    inputs=[x, y],\n    outputs=[cost],\n    updates=[(l1.W, l1.W - learning_rate * gW1),\n             (l1.b, l1.b - learning_rate * gb1),\n             (l2.W, l2.W - learning_rate * gW2),\n             (l2.b, l2.b - learning_rate * gb2)])\n\n# prediction\npredict = theano.function(inputs=[x], outputs=l2.outputs)\n\n# plot the real data\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nax.scatter(x_data, y_data)\nplt.ion()\nplt.show()\n\nfor i in range(1000):\n    # training\n    err = train(x_data, y_data)\n    if i % 50 == 0:\n        # to visualize the result and improvement\n        try:\n            ax.lines.remove(lines[0])\n        except Exception:\n            pass\n        prediction_value = predict(x_data)\n        # plot the prediction\n        lines = ax.plot(x_data, prediction_value, \'r-\', lw=5)\n        plt.pause(.5)'"
theanoTUT/theano4_basic_usage.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 4 - basic usage\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport numpy as np\nimport theano.tensor as T\nfrom theano import function\n\n# basic\nx = T.dscalar(\'x\')\ny = T.dscalar(\'y\')\nz = x+y     # define the actual function in here\nf = function([x, y], z)  # the inputs are in [], and the output in the ""z""\n\nprint(f(2,3))  # only give the inputs ""x and y"" for this function, then it will calculate the output ""z""\n\n# to pretty-print the function\nfrom theano import pp\nprint(pp(z))\n\n# how about matrix\nx = T.dmatrix(\'x\')\ny = T.dmatrix(\'y\')\nz = x + y\nf = function([x, y], z)\nprint(f(np.arange(12).reshape((3,4)), 10*np.ones((3,4))))\n'"
theanoTUT/theano5_function.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 5 - theano.function\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport numpy as np\nimport theano\nimport theano.tensor as T\n\n# activation function example\nx = T.dmatrix(\'x\')\ns = 1 / (1 + T.exp(-x))    # logistic or soft step\nlogistic = theano.function([x], s)\nprint(logistic([[0, 1],[-1, -2]]))\n\n# multiply outputs for a function\na, b = T.dmatrices(\'a\', \'b\')\ndiff = a - b\nabs_diff = abs(diff)\ndiff_squared = diff ** 2\nf = theano.function([a, b], [diff, abs_diff, diff_squared])\nprint( f(np.ones((2, 2)), np.arange(4).reshape((2, 2))) )\n\n# default value and name for a function\nx, y, w = T.dscalars(\'x\', \'y\', \'w\')\nz = (x+y)*w\nf = theano.function([x,\n                     theano.In(y, value=1),\n                     theano.In(w, value=2, name=\'weights\')],\n                   z)\nprint(f(23, 2, weights=4))'"
theanoTUT/theano6_shared_variable.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 6 - shared variables\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport numpy as np\nimport theano\nimport theano.tensor as T\n\nstate = theano.shared(np.array(0,dtype=np.float64), \'state\') # inital state = 0\ninc = T.scalar(\'inc\', dtype=state.dtype)\naccumulator = theano.function([inc], state, updates=[(state, state+inc)])\n\n# to get variable value\nprint(state.get_value())\naccumulator(1)   # return previous value, 0 in here\nprint(state.get_value())\naccumulator(10)  # return previous value, 1 in here\nprint(state.get_value())\n\n# to set variable value\nstate.set_value(-1)\naccumulator(3)\nprint(state.get_value())\n\n# temporarily replace shared variable with another value in another function\ntmp_func = state * 2 + inc\na = T.scalar(dtype=state.dtype)\nskip_shared = theano.function([inc, a], tmp_func, givens=[(state, a)]) # temporarily use a\'s value for the state\nprint(skip_shared(2, 3))\nprint(state.get_value()) # old state value\n'"
theanoTUT/theano7_activation_function.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 7 - Activation function\n\n""""""\nThe available activation functions in theano can be found in this link:\nhttp://deeplearning.net/software/theano/library/tensor/nnet/nnet.html\n\nThe activation functions include but not limited to softplus, sigmoid, relu, softmax, elu, tanh...\n\nFor the hidden layer, we could use relu, tanh, softplus...\nFor classification problems, we could use sigmoid or softmax for the output layer.\nFor regression problems, we could use a linear function for the output layer.\n\n""""""'"
theanoTUT/theano8_Layer_class.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 8 - define Layer class\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport theano\nimport theano.tensor as T\nimport numpy as np\n\n\nclass Layer(object):\n    def __init__(self, inputs, in_size, out_size, activation_function=None):\n        self.W = theano.shared(np.random.normal(0, 1, (in_size, out_size)))\n        self.b = theano.shared(np.zeros((out_size, )) + 0.1)\n        self.Wx_plus_b = T.dot(inputs, self.W) + self.b\n        self.activation_function = activation_function\n        if activation_function is None:\n            self.outputs = self.Wx_plus_b\n        else:\n            self.outputs = self.activation_function(self.Wx_plus_b)\n\n""""""\nto define the layer like this:\nl1 = Layer(inputs, 1, 10, T.nnet.relu)\nl2 = Layer(l1.outputs, 10, 1, None)\n""""""\n'"
threadingTUT/thread2_add_thread.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport threading\n\n#def main():\n#    print(threading.active_count())\n#    print(threading.enumerate()) # see the thread list\n#    print(threading.current_thread())\n\ndef thread_job():\n    print('This is a thread of %s' % threading.current_thread())\n\ndef main():\n    thread = threading.Thread(target=thread_job,)\n    thread.start()\nif __name__ == '__main__':\n    main()\n"""
threadingTUT/thread3_join.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport threading\nimport time\ndef thread_job():\n    print('T1 start\\n')\n    for i in range(10):\n        time.sleep(0.1)\n    print('T1 finish\\n')\n\ndef T2_job():\n    print('T2 start\\n')\n    print('T2 finish\\n')\n\ndef main():\n    added_thread = threading.Thread(target=thread_job, name='T1')\n    thread2 = threading.Thread(target=T2_job, name='T2')\n    added_thread.start()\n    thread2.start()\n    thread2.join()\n    added_thread.join()\n\n    print('all done\\n')\n\nif __name__ == '__main__':\n    main()\n"""
threadingTUT/thread4_queue.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport threading\nimport time\nfrom queue import Queue\n\ndef job(l,q):\n    for i in range(len(l)):\n        l[i] = l[i]**2\n    q.put(l)\n\ndef multithreading():\n    q = Queue()\n    threads = []\n    data = [[1,2,3],[3,4,5],[4,4,4],[5,5,5]]\n    for i in range(4):\n        t = threading.Thread(target=job, args=(data[i], q))\n        t.start()\n        threads.append(t)\n    for thread in threads:\n        thread.join()\n    results = []\n    for _ in range(4):\n          results.append(q.get())\n    print(results)\n\nif __name__ == '__main__':\n    multithreading()\n"""
threadingTUT/thread5_GIL.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport threading\nfrom queue import Queue\nimport copy\nimport time\n\ndef job(l, q):\n    res = sum(l)\n    q.put(res)\n\ndef multithreading(l):\n    q = Queue()\n    threads = []\n    for i in range(4):\n        t = threading.Thread(target=job, args=(copy.copy(l), q), name='T%i' % i)\n        t.start()\n        threads.append(t)\n    [t.join() for t in threads]\n    total = 0\n    for _ in range(4):\n        total += q.get()\n    print(total)\n\ndef normal(l):\n    total = sum(l)\n    print(total)\n\nif __name__ == '__main__':\n    l = list(range(1000000))\n    s_t = time.time()\n    normal(l*4)\n    print('normal: ',time.time()-s_t)\n    s_t = time.time()\n    multithreading(l)\n    print('multithreading: ', time.time()-s_t)\n"""
threadingTUT/thread6_lock.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport threading\n\ndef job1():\n    global A, lock\n    lock.acquire()\n    for i in range(10):\n        A += 1\n        print('job1', A)\n    lock.release()\n\ndef job2():\n    global A, lock\n    lock.acquire()\n    for i in range(10):\n        A += 10\n        print('job2', A)\n    lock.release()\n\nif __name__ == '__main__':\n    lock = threading.Lock()\n    A = 0\n    t1 = threading.Thread(target=job1)\n    t2 = threading.Thread(target=job2)\n    t1.start()\n    t2.start()\n    t1.join()\n    t2.join()\n"""
tkinterTUT/tk10_frame.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\n\nwindow = tk.Tk()\nwindow.title('my window')\nwindow.geometry('200x200')\ntk.Label(window, text='on the window').pack()\n\nfrm = tk.Frame(window)\nfrm.pack()\nfrm_l = tk.Frame(frm, )\nfrm_r = tk.Frame(frm)\nfrm_l.pack(side='left')\nfrm_r.pack(side='right')\n\ntk.Label(frm_l, text='on the frm_l1').pack()\ntk.Label(frm_l, text='on the frm_l2').pack()\ntk.Label(frm_r, text='on the frm_r1').pack()\nwindow.mainloop()\n\n\n\n\n\n\n\n\n\n"""
tkinterTUT/tk11_msgbox.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\nimport tkinter.messagebox\n\nwindow = tk.Tk()\nwindow.title(\'my window\')\nwindow.geometry(\'200x200\')\n\ndef hit_me():\n    #tk.messagebox.showinfo(title=\'Hi\', message=\'hahahaha\')   # return \'ok\'\n    #tk.messagebox.showwarning(title=\'Hi\', message=\'nononono\')   # return \'ok\'\n    #tk.messagebox.showerror(title=\'Hi\', message=\'No!! never\')   # return \'ok\'\n    #print(tk.messagebox.askquestion(title=\'Hi\', message=\'hahahaha\'))   # return \'yes\' , \'no\'\n    #print(tk.messagebox.askyesno(title=\'Hi\', message=\'hahahaha\'))   # return True, False\n    print(tk.messagebox.asktrycancel(title=\'Hi\', message=\'hahahaha\'))   # return True, False\n    print(tk.messagebox.askokcancel(title=\'Hi\', message=\'hahahaha\'))   # return True, False\n    print(tk.messagebox.askyesnocancel(title=""Hi"", message=""haha""))     # return, True, False, None\n\ntk.Button(window, text=\'hit me\', command=hit_me).pack()\nwindow.mainloop()\n\n\n\n\n\n\n\n\n\n'"
tkinterTUT/tk12_position.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\n\nwindow = tk.Tk()\nwindow.geometry('200x200')\n\n#canvas = tk.Canvas(window, height=150, width=500)\n#canvas.grid(row=1, column=1)\n#image_file = tk.PhotoImage(file='welcome.gif')\n#image = canvas.create_image(0, 0, anchor='nw', image=image_file)\n\n#tk.Label(window, text='1').pack(side='top')\n#tk.Label(window, text='1').pack(side='bottom')\n#tk.Label(window, text='1').pack(side='left')\n#tk.Label(window, text='1').pack(side='right')\n\n#for i in range(4):\n    #for j in range(3):\n        #tk.Label(window, text=1).grid(row=i, column=j, padx=10, pady=10)\n\ntk.Label(window, text=1).place(x=20, y=10, anchor='nw')\n\nwindow.mainloop()\n"""
tkinterTUT/tk2_label_button.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\n\nwindow = tk.Tk()\nwindow.title('my window')\nwindow.geometry('200x100')\n\nvar = tk.StringVar()\nl = tk.Label(window, textvariable=var, bg='green', font=('Arial', 12), width=15,\n             height=2)\n#l = tk.Label(window, text='OMG! this is TK!', bg='green', font=('Arial', 12), width=15, height=2)\nl.pack()\n\non_hit = False\ndef hit_me():\n    global on_hit\n    if on_hit == False:\n        on_hit = True\n        var.set('you hit me')\n    else:\n        on_hit = False\n        var.set('')\n\nb = tk.Button(window, text='hit me', width=15,\n              height=2, command=hit_me)\nb.pack()\n\n\nwindow.mainloop()\n"""
tkinterTUT/tk3_entry_text.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\n\nwindow = tk.Tk()\nwindow.title(\'my window\')\nwindow.geometry(\'200x200\')\n# e = tk.Entry(window, show=""*"")\ne = tk.Entry(window, show=""1"")\ne.pack()\n\ndef insert_point():\n    var = e.get()\n    t.insert(\'insert\', var)\ndef insert_end():\n    var = e.get()\n    # t.insert(\'end\', var)\n    t.insert(2.2, var)\n\nb1 = tk.Button(window, text=\'insert point\', width=15,\n              height=2, command=insert_point)\nb1.pack()\nb2 = tk.Button(window, text=\'insert end\',\n               command=insert_end)\nb2.pack()\nt = tk.Text(window, height=2)\nt.pack()\n\nwindow.mainloop()\n'"
tkinterTUT/tk4_listbox.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\n\nwindow = tk.Tk()\nwindow.title('my window')\nwindow.geometry('200x200')\n\nvar1 = tk.StringVar()\nl = tk.Label(window, bg='yellow', width=4, textvariable=var1)\nl.pack()\n\ndef print_selection():\n    value = lb.get(lb.curselection())\n    var1.set(value)\n\nb1 = tk.Button(window, text='print selection', width=15,\n              height=2, command=print_selection)\nb1.pack()\n\nvar2 = tk.StringVar()\nvar2.set((11,22,33,44))\nlb = tk.Listbox(window, listvariable=var2)\nlist_items = [1,2,3,4]\nfor item in list_items:\n    lb.insert('end', item)\nlb.insert(1, 'first')\nlb.insert(2, 'second')\nlb.delete(2)\nlb.pack()\n\nwindow.mainloop()\n"""
tkinterTUT/tk5_radiobutton.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\n\nwindow = tk.Tk()\nwindow.title('my window')\nwindow.geometry('200x200')\n\nvar = tk.StringVar()\nl = tk.Label(window, bg='yellow', width=20, text='empty')\nl.pack()\n\ndef print_selection():\n    l.config(text='you have selected ' + var.get())\n\nr1 = tk.Radiobutton(window, text='Option A',\n                    variable=var, value='A',\n                    command=print_selection)\nr1.pack()\nr2 = tk.Radiobutton(window, text='Option B',\n                    variable=var, value='B',\n                    command=print_selection)\nr2.pack()\nr3 = tk.Radiobutton(window, text='Option C',\n                    variable=var, value='C',\n                    command=print_selection)\nr3.pack()\n\n\nwindow.mainloop()\n"""
tkinterTUT/tk6_scale.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\n\nwindow = tk.Tk()\nwindow.title('my window')\nwindow.geometry('200x200')\n\nl = tk.Label(window, bg='yellow', width=20, text='empty')\nl.pack()\n\ndef print_selection(v):\n    l.config(text='you have selected ' + v)\n\ns = tk.Scale(window, label='try me', from_=5, to=11, orient=tk.HORIZONTAL,\n             length=200, showvalue=0, tickinterval=2, resolution=0.01, command=print_selection)\ns.pack()\n\nwindow.mainloop()"""
tkinterTUT/tk7_checkbutton.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\n\nwindow = tk.Tk()\nwindow.title('my window')\nwindow.geometry('200x200')\n\nl = tk.Label(window, bg='yellow', width=20, text='empty')\nl.pack()\n\ndef print_selection():\n    if (var1.get() == 1) & (var2.get() == 0):\n        l.config(text='I love only Python ')\n    elif (var1.get() == 0) & (var2.get() == 1):\n        l.config(text='I love only C++')\n    elif (var1.get() == 0) & (var2.get() == 0):\n        l.config(text='I do not love either')\n    else:\n        l.config(text='I love both')\n\nvar1 = tk.IntVar()\nvar2 = tk.IntVar()\nc1 = tk.Checkbutton(window, text='Python', variable=var1, onvalue=1, offvalue=0,\n                    command=print_selection)\nc2 = tk.Checkbutton(window, text='C++', variable=var2, onvalue=1, offvalue=0,\n                    command=print_selection)\nc1.pack()\nc2.pack()\n\n\nwindow.mainloop()\n\n"""
tkinterTUT/tk8_canvas.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\n\nwindow = tk.Tk()\nwindow.title('my window')\nwindow.geometry('200x200')\n\ncanvas = tk.Canvas(window, bg='blue', height=100, width=200)\nimage_file = tk.PhotoImage(file='ins.gif')\nimage = canvas.create_image(10, 10, anchor='nw', image=image_file)\nx0, y0, x1, y1= 50, 50, 80, 80\nline = canvas.create_line(x0, y0, x1, y1)\noval = canvas.create_oval(x0, y0, x1, y1, fill='red')\narc = canvas.create_arc(x0+30, y0+30, x1+30, y1+30, start=0, extent=180)\nrect = canvas.create_rectangle(100, 30, 100+20, 30+20)\ncanvas.pack()\n\ndef moveit():\n    canvas.move(rect, 0, 2)\n\nb = tk.Button(window, text='move', command=moveit).pack()\n\n\nwindow.mainloop()\n\n"""
tkinterTUT/tk9_menubar.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\n\nwindow = tk.Tk()\nwindow.title(\'my window\')\nwindow.geometry(\'200x200\')\n\nl = tk.Label(window, text=\'\', bg=\'yellow\')\nl.pack()\ncounter = 0\ndef do_job():\n    global counter\n    l.config(text=\'do \'+ str(counter))\n    counter+=1\n\nmenubar = tk.Menu(window)\nfilemenu = tk.Menu(menubar, tearoff=0)\nmenubar.add_cascade(label=\'File\', menu=filemenu)\nfilemenu.add_command(label=\'New\', command=do_job)\nfilemenu.add_command(label=\'Open\', command=do_job)\nfilemenu.add_command(label=\'Save\', command=do_job)\nfilemenu.add_separator()\nfilemenu.add_command(label=\'Exit\', command=window.quit)\n\neditmenu = tk.Menu(menubar, tearoff=0)\nmenubar.add_cascade(label=\'Edit\', menu=editmenu)\neditmenu.add_command(label=\'Cut\', command=do_job)\neditmenu.add_command(label=\'Copy\', command=do_job)\neditmenu.add_command(label=\'Paste\', command=do_job)\n\nsubmenu = tk.Menu(filemenu)\nfilemenu.add_cascade(label=\'Import\', menu=submenu, underline=0)\nsubmenu.add_command(label=""Submenu1"", command=do_job)\n\nwindow.config(menu=menubar)\n\nwindow.mainloop()\n\n\n'"
numpy&pandas/15_read_to/15_read_to.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport pandas as pd\n\n# read from\ndata = pd.read_csv(\'student.csv\')\nprint(data)\n\n# save to\ndata.to_pickle(\'student.pickle\')'"
sklearnTUT/sk8_cross_validation/for_you_to_practice.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nfrom sklearn.datasets import load_iris\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\n# test train split #\n\n\n# this is cross_val_score #\n\n\n# this is how to use cross_val_score to choose model and configs #\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'"
sklearnTUT/sk8_cross_validation/full_code.py,0,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nfrom sklearn.datasets import load_iris\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\n# test train split #\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4)\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nprint(knn.score(X_test, y_test))\n\n# this is cross_val_score #\nfrom sklearn.cross_validation import cross_val_score\nknn = KNeighborsClassifier(n_neighbors=5)\nscores = cross_val_score(knn, X, y, cv=5, scoring=\'accuracy\')\nprint(scores)\n\n# this is how to use cross_val_score to choose model and configs #\nfrom sklearn.cross_validation import cross_val_score\nimport matplotlib.pyplot as plt\nk_range = range(1, 31)\nk_scores = []\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n##    loss = -cross_val_score(knn, X, y, cv=10, scoring=\'mean_squared_error\') # for regression\n    scores = cross_val_score(knn, X, y, cv=10, scoring=\'accuracy\') # for classification\n    k_scores.append(scores.mean())\n\nplt.plot(k_range, k_scores)\nplt.xlabel(\'Value of K for KNN\')\nplt.ylabel(\'Cross-Validated Accuracy\')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n'"
tensorflowTUT/tf11_build_network/full_code.py,13,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef add_layer(inputs, in_size, out_size, activation_function=None):\n    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n    if activation_function is None:\n        outputs = Wx_plus_b\n    else:\n        outputs = activation_function(Wx_plus_b)\n    return outputs\n\n# Make up some real data\nx_data = np.linspace(-1, 1, 300, dtype=np.float32)[:, np.newaxis]\nnoise = np.random.normal(0, 0.05, x_data.shape).astype(np.float32)\ny_data = np.square(x_data) - 0.5 + noise\n\n##plt.scatter(x_data, y_data)\n##plt.show()\n\n# define placeholder for inputs to network\nxs = tf.placeholder(tf.float32, [None, 1])\nys = tf.placeholder(tf.float32, [None, 1])\n# add hidden layer\nl1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n# add output layer\nprediction = add_layer(l1, 10, 1, activation_function=None)\n\n# the error between prediction and real data\nloss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction), reduction_indices=[1]))\ntrain_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n# important step\nsess = tf.Session()\n# tf.initialize_all_variables() no long valid from\n# 2017-03-02 if using tensorflow >= 0.12\nif int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n    init = tf.initialize_all_variables()\nelse:\n    init = tf.global_variables_initializer()\nsess.run(init)\n\nfor i in range(1000):\n    # training\n    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n    if i % 50 == 0:\n        # to see the step improvement\n        print(sess.run(loss, feed_dict={xs: x_data, ys: y_data}))\n'"
tensorflowTUT/tf12_plot_result/full_code.py,13,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef add_layer(inputs, in_size, out_size, activation_function=None):\n    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n    if activation_function is None:\n        outputs = Wx_plus_b\n    else:\n        outputs = activation_function(Wx_plus_b)\n    return outputs\n\n# Make up some real data\nx_data = np.linspace(-1, 1, 300)[:, np.newaxis]\nnoise = np.random.normal(0, 0.05, x_data.shape)\ny_data = np.square(x_data) - 0.5 + noise\n\n##plt.scatter(x_data, y_data)\n##plt.show()\n\n# define placeholder for inputs to network\nxs = tf.placeholder(tf.float32, [None, 1])\nys = tf.placeholder(tf.float32, [None, 1])\n# add hidden layer\nl1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n# add output layer\nprediction = add_layer(l1, 10, 1, activation_function=None)\n\n# the error between prediction and real data\nloss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction), reduction_indices=[1]))\ntrain_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n# important step\nsess = tf.Session()\n# tf.initialize_all_variables() no long valid from\n# 2017-03-02 if using tensorflow >= 0.12\nif int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n    init = tf.initialize_all_variables()\nelse:\n    init = tf.global_variables_initializer()\nsess.run(init)\n\n# plot the real data\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nax.scatter(x_data, y_data)\nplt.ion()\nplt.show()\n\n\nfor i in range(1000):\n    # training\n    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n    if i % 50 == 0:\n        # to visualize the result and improvement\n        try:\n            ax.lines.remove(lines[0])\n        except Exception:\n            pass\n        prediction_value = sess.run(prediction, feed_dict={xs: x_data})\n        # plot the prediction\n        lines = ax.plot(x_data, prediction_value, \'r-\', lw=5)\n        plt.pause(1)\n\n\n\n\n\n\n\n\n\n\n\n'"
tensorflowTUT/tf14_tensorboard/full_code.py,24,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\n\n\ndef add_layer(inputs, in_size, out_size, activation_function=None):\n    # add one more layer and return the output of this layer\n    with tf.name_scope(\'layer\'):\n        with tf.name_scope(\'weights\'):\n            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name=\'W\')\n        with tf.name_scope(\'biases\'):\n            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name=\'b\')\n        with tf.name_scope(\'Wx_plus_b\'):\n            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n        if activation_function is None:\n            outputs = Wx_plus_b\n        else:\n            outputs = activation_function(Wx_plus_b, )\n        return outputs\n\n\n# define placeholder for inputs to network\nwith tf.name_scope(\'inputs\'):\n    xs = tf.placeholder(tf.float32, [None, 1], name=\'x_input\')\n    ys = tf.placeholder(tf.float32, [None, 1], name=\'y_input\')\n\n# add hidden layer\nl1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n# add output layer\nprediction = add_layer(l1, 10, 1, activation_function=None)\n\n# the error between prediciton and real data\nwith tf.name_scope(\'loss\'):\n    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n                                        reduction_indices=[1]))\n\nwith tf.name_scope(\'train\'):\n    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n\nsess = tf.Session()\n\n# tf.train.SummaryWriter soon be deprecated, use following\nif int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:  # tensorflow version < 0.12\n    writer = tf.train.SummaryWriter(\'logs/\', sess.graph)\nelse: # tensorflow version >= 0.12\n    writer = tf.summary.FileWriter(""logs/"", sess.graph)\n\n# tf.initialize_all_variables() no long valid from\n# 2017-03-02 if using tensorflow >= 0.12\nif int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n    init = tf.initialize_all_variables()\nelse:\n    init = tf.global_variables_initializer()\nsess.run(init)\n\n# direct to the local dir and run this in terminal:\n# $ tensorboard --logdir=logs\n\n\n'"
tensorflowTUT/tf15_tensorboard/full_code.py,23,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\n\n\ndef add_layer(inputs, in_size, out_size, n_layer, activation_function=None):\n    # add one more layer and return the output of this layer\n    layer_name = \'layer%s\' % n_layer\n    with tf.name_scope(layer_name):\n        with tf.name_scope(\'weights\'):\n            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name=\'W\')\n            tf.summary.histogram(layer_name + \'/weights\', Weights)\n        with tf.name_scope(\'biases\'):\n            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name=\'b\')\n            tf.summary.histogram(layer_name + \'/biases\', biases)\n        with tf.name_scope(\'Wx_plus_b\'):\n            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n        if activation_function is None:\n            outputs = Wx_plus_b\n        else:\n            outputs = activation_function(Wx_plus_b, )\n        tf.summary.histogram(layer_name + \'/outputs\', outputs)\n    return outputs\n\n\n# Make up some real data\nx_data = np.linspace(-1, 1, 300)[:, np.newaxis]\nnoise = np.random.normal(0, 0.05, x_data.shape)\ny_data = np.square(x_data) - 0.5 + noise\n\n# define placeholder for inputs to network\nwith tf.name_scope(\'inputs\'):\n    xs = tf.placeholder(tf.float32, [None, 1], name=\'x_input\')\n    ys = tf.placeholder(tf.float32, [None, 1], name=\'y_input\')\n\n# add hidden layer\nl1 = add_layer(xs, 1, 10, n_layer=1, activation_function=tf.nn.relu)\n# add output layer\nprediction = add_layer(l1, 10, 1, n_layer=2, activation_function=None)\n\n# the error between prediciton and real data\nwith tf.name_scope(\'loss\'):\n    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n                                        reduction_indices=[1]))\n    tf.summary.scalar(\'loss\', loss)\n\nwith tf.name_scope(\'train\'):\n    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n\nsess = tf.Session()\nmerged = tf.summary.merge_all()\n\nwriter = tf.summary.FileWriter(""logs/"", sess.graph)\n\ninit = tf.global_variables_initializer()\nsess.run(init)\n\nfor i in range(1000):\n    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n    if i % 50 == 0:\n        result = sess.run(merged,\n                          feed_dict={xs: x_data, ys: y_data})\n        writer.add_summary(result, i)\n\n# direct to the local dir and run this in terminal:\n# $ tensorboard --logdir logs'"
tensorflowTUT/tf16_classification/full_code.py,15,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n# number 1 to 10 data\nmnist = input_data.read_data_sets(\'MNIST_data\', one_hot=True)\n\ndef add_layer(inputs, in_size, out_size, activation_function=None,):\n    # add one more layer and return the output of this layer\n    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1,)\n    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n    if activation_function is None:\n        outputs = Wx_plus_b\n    else:\n        outputs = activation_function(Wx_plus_b,)\n    return outputs\n\ndef compute_accuracy(v_xs, v_ys):\n    global prediction\n    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})\n    return result\n\n# define placeholder for inputs to network\nxs = tf.placeholder(tf.float32, [None, 784]) # 28x28\nys = tf.placeholder(tf.float32, [None, 10])\n\n# add output layer\nprediction = add_layer(xs, 784, 10,  activation_function=tf.nn.softmax)\n\n# the error between prediction and real data\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n                                              reduction_indices=[1]))       # loss\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\nsess = tf.Session()\n# important step\n# tf.initialize_all_variables() no long valid from\n# 2017-03-02 if using tensorflow >= 0.12\nif int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n    init = tf.initialize_all_variables()\nelse:\n    init = tf.global_variables_initializer()\nsess.run(init)\n\nfor i in range(1000):\n    batch_xs, batch_ys = mnist.train.next_batch(100)\n    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n    if i % 50 == 0:\n        print(compute_accuracy(\n            mnist.test.images, mnist.test.labels))\n\n'"
tensorflowTUT/tf17_dropout/full_code.py,21,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\n\n# load data\ndigits = load_digits()\nX = digits.data\ny = digits.target\ny = LabelBinarizer().fit_transform(y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)\n\n\ndef add_layer(inputs, in_size, out_size, layer_name, activation_function=None, ):\n    # add one more layer and return the output of this layer\n    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, )\n    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n    # here to dropout\n    Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)\n    if activation_function is None:\n        outputs = Wx_plus_b\n    else:\n        outputs = activation_function(Wx_plus_b, )\n    tf.summary.histogram(layer_name + \'/outputs\', outputs)\n    return outputs\n\n\n# define placeholder for inputs to network\nkeep_prob = tf.placeholder(tf.float32)\nxs = tf.placeholder(tf.float32, [None, 64])  # 8x8\nys = tf.placeholder(tf.float32, [None, 10])\n\n# add output layer\nl1 = add_layer(xs, 64, 50, \'l1\', activation_function=tf.nn.tanh)\nprediction = add_layer(l1, 50, 10, \'l2\', activation_function=tf.nn.softmax)\n\n# the loss between prediction and real data\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n                                              reduction_indices=[1]))  # loss\ntf.summary.scalar(\'loss\', cross_entropy)\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\nsess = tf.Session()\nmerged = tf.summary.merge_all()\n# summary writer goes in here\ntrain_writer = tf.summary.FileWriter(""logs/train"", sess.graph)\ntest_writer = tf.summary.FileWriter(""logs/test"", sess.graph)\n\n# tf.initialize_all_variables() no long valid from\n# 2017-03-02 if using tensorflow >= 0.12\nif int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n    init = tf.initialize_all_variables()\nelse:\n    init = tf.global_variables_initializer()\nsess.run(init)\nfor i in range(500):\n    # here to determine the keeping probability\n    sess.run(train_step, feed_dict={xs: X_train, ys: y_train, keep_prob: 0.5})\n    if i % 50 == 0:\n        # record loss\n        train_result = sess.run(merged, feed_dict={xs: X_train, ys: y_train, keep_prob: 1})\n        test_result = sess.run(merged, feed_dict={xs: X_test, ys: y_test, keep_prob: 1})\n        train_writer.add_summary(train_result, i)\n        test_writer.add_summary(test_result, i)\n'"
tensorflowTUT/tf18_CNN2/full_code.py,18,"b'# View more python tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n# number 1 to 10 data\nmnist = input_data.read_data_sets(\'MNIST_data\', one_hot=True)\n\ndef compute_accuracy(v_xs, v_ys):\n    global prediction\n    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n    return result\n\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\ndef conv2d(x, W):\n    # stride [1, x_movement, y_movement, 1]\n    # Must have strides[0] = strides[3] = 1\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\'SAME\')\n\ndef max_pool_2x2(x):\n    # stride [1, x_movement, y_movement, 1]\n    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\'SAME\')\n\n# define placeholder for inputs to network\nxs = tf.placeholder(tf.float32, [None, 784]) # 28x28\nys = tf.placeholder(tf.float32, [None, 10])\nkeep_prob = tf.placeholder(tf.float32)\n\n## conv1 layer ##\n\n## conv2 layer ##\n\n## func1 layer ##\n\n## func2 layer ##\n\n\n# the error between prediction and real data\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n                                              reduction_indices=[1]))       # loss\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\nsess = tf.Session()\n# important step\n# tf.initialize_all_variables() no long valid from\n# 2017-03-02 if using tensorflow >= 0.12\nif int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n    init = tf.initialize_all_variables()\nelse:\n    init = tf.global_variables_initializer()\nsess.run(init)\n\nfor i in range(1000):\n    batch_xs, batch_ys = mnist.train.next_batch(100)\n    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n    if i % 50 == 0:\n        print(compute_accuracy(\n            mnist.test.images[:1000], mnist.test.labels[:1000]))\n\n'"
tensorflowTUT/tf18_CNN3/full_code.py,25,"b'# View more python tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n# number 1 to 10 data\nmnist = input_data.read_data_sets(\'MNIST_data\', one_hot=True)\n\ndef compute_accuracy(v_xs, v_ys):\n    global prediction\n    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n    return result\n\ndef weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\ndef conv2d(x, W):\n    # stride [1, x_movement, y_movement, 1]\n    # Must have strides[0] = strides[3] = 1\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\'SAME\')\n\ndef max_pool_2x2(x):\n    # stride [1, x_movement, y_movement, 1]\n    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\'SAME\')\n\n# define placeholder for inputs to network\nxs = tf.placeholder(tf.float32, [None, 784])/255.   # 28x28\nys = tf.placeholder(tf.float32, [None, 10])\nkeep_prob = tf.placeholder(tf.float32)\nx_image = tf.reshape(xs, [-1, 28, 28, 1])\n# print(x_image.shape)  # [n_samples, 28,28,1]\n\n## conv1 layer ##\nW_conv1 = weight_variable([5,5, 1,32]) # patch 5x5, in size 1, out size 32\nb_conv1 = bias_variable([32])\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # output size 28x28x32\nh_pool1 = max_pool_2x2(h_conv1)                                         # output size 14x14x32\n\n## conv2 layer ##\nW_conv2 = weight_variable([5,5, 32, 64]) # patch 5x5, in size 32, out size 64\nb_conv2 = bias_variable([64])\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 14x14x64\nh_pool2 = max_pool_2x2(h_conv2)                                         # output size 7x7x64\n\n## fc1 layer ##\nW_fc1 = weight_variable([7*7*64, 1024])\nb_fc1 = bias_variable([1024])\n# [n_samples, 7, 7, 64] ->> [n_samples, 7*7*64]\nh_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n## fc2 layer ##\nW_fc2 = weight_variable([1024, 10])\nb_fc2 = bias_variable([10])\nprediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n\n\n# the error between prediction and real data\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n                                              reduction_indices=[1]))       # loss\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\nsess = tf.Session()\n# important step\n# tf.initialize_all_variables() no long valid from\n# 2017-03-02 if using tensorflow >= 0.12\nif int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n    init = tf.initialize_all_variables()\nelse:\n    init = tf.global_variables_initializer()\nsess.run(init)\n\nfor i in range(1000):\n    batch_xs, batch_ys = mnist.train.next_batch(100)\n    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n    if i % 50 == 0:\n        print(compute_accuracy(\n            mnist.test.images[:1000], mnist.test.labels[:1000]))\n\n'"
tensorflowTUT/tf20_RNN2.2/full_code.py,40,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n\nRun this script on tensorflow r0.10. Errors appear when using lower versions.\n""""""\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nBATCH_START = 0\nTIME_STEPS = 20\nBATCH_SIZE = 50\nINPUT_SIZE = 1\nOUTPUT_SIZE = 1\nCELL_SIZE = 10\nLR = 0.006\n\n\ndef get_batch():\n    global BATCH_START, TIME_STEPS\n    # xs shape (50batch, 20steps)\n    xs = np.arange(BATCH_START, BATCH_START+TIME_STEPS*BATCH_SIZE).reshape((BATCH_SIZE, TIME_STEPS)) / (10*np.pi)\n    seq = np.sin(xs)\n    res = np.cos(xs)\n    BATCH_START += TIME_STEPS\n    # plt.plot(xs[0, :], res[0, :], \'r\', xs[0, :], seq[0, :], \'b--\')\n    # plt.show()\n    # returned seq, res and xs: shape (batch, step, input)\n    return [seq[:, :, np.newaxis], res[:, :, np.newaxis], xs]\n\n\nclass LSTMRNN(object):\n    def __init__(self, n_steps, input_size, output_size, cell_size, batch_size):\n        self.n_steps = n_steps\n        self.input_size = input_size\n        self.output_size = output_size\n        self.cell_size = cell_size\n        self.batch_size = batch_size\n        with tf.name_scope(\'inputs\'):\n            self.xs = tf.placeholder(tf.float32, [None, n_steps, input_size], name=\'xs\')\n            self.ys = tf.placeholder(tf.float32, [None, n_steps, output_size], name=\'ys\')\n        with tf.variable_scope(\'in_hidden\'):\n            self.add_input_layer()\n        with tf.variable_scope(\'LSTM_cell\'):\n            self.add_cell()\n        with tf.variable_scope(\'out_hidden\'):\n            self.add_output_layer()\n        with tf.name_scope(\'cost\'):\n            self.compute_cost()\n        with tf.name_scope(\'train\'):\n            self.train_op = tf.train.AdamOptimizer(LR).minimize(self.cost)\n\n    def add_input_layer(self,):\n        l_in_x = tf.reshape(self.xs, [-1, self.input_size], name=\'2_2D\')  # (batch*n_step, in_size)\n        # Ws (in_size, cell_size)\n        Ws_in = self._weight_variable([self.input_size, self.cell_size])\n        # bs (cell_size, )\n        bs_in = self._bias_variable([self.cell_size,])\n        # l_in_y = (batch * n_steps, cell_size)\n        with tf.name_scope(\'Wx_plus_b\'):\n            l_in_y = tf.matmul(l_in_x, Ws_in) + bs_in\n        # reshape l_in_y ==> (batch, n_steps, cell_size)\n        self.l_in_y = tf.reshape(l_in_y, [-1, self.n_steps, self.cell_size], name=\'2_3D\')\n\n    def add_cell(self):\n        lstm_cell = tf.contrib.rnn.BasicLSTMCell(self.cell_size, forget_bias=1.0, state_is_tuple=True)\n        with tf.name_scope(\'initial_state\'):\n            self.cell_init_state = lstm_cell.zero_state(self.batch_size, dtype=tf.float32)\n        self.cell_outputs, self.cell_final_state = tf.nn.dynamic_rnn(\n            lstm_cell, self.l_in_y, initial_state=self.cell_init_state, time_major=False)\n\n    def add_output_layer(self):\n        # shape = (batch * steps, cell_size)\n        l_out_x = tf.reshape(self.cell_outputs, [-1, self.cell_size], name=\'2_2D\')\n        Ws_out = self._weight_variable([self.cell_size, self.output_size])\n        bs_out = self._bias_variable([self.output_size, ])\n        # shape = (batch * steps, output_size)\n        with tf.name_scope(\'Wx_plus_b\'):\n            self.pred = tf.matmul(l_out_x, Ws_out) + bs_out\n\n    def compute_cost(self):\n        losses = tf.contrib.legacy_seq2seq.sequence_loss_by_example(\n            [tf.reshape(self.pred, [-1], name=\'reshape_pred\')],\n            [tf.reshape(self.ys, [-1], name=\'reshape_target\')],\n            [tf.ones([self.batch_size * self.n_steps], dtype=tf.float32)],\n            average_across_timesteps=True,\n            softmax_loss_function=self.ms_error,\n            name=\'losses\'\n        )\n        with tf.name_scope(\'average_cost\'):\n            self.cost = tf.div(\n                tf.reduce_sum(losses, name=\'losses_sum\'),\n                self.batch_size,\n                name=\'average_cost\')\n            tf.summary.scalar(\'cost\', self.cost)\n\n    @staticmethod\n    def ms_error(labels, logits):\n        return tf.square(tf.subtract(labels, logits))\n\n    def _weight_variable(self, shape, name=\'weights\'):\n        initializer = tf.random_normal_initializer(mean=0., stddev=1.,)\n        return tf.get_variable(shape=shape, initializer=initializer, name=name)\n\n    def _bias_variable(self, shape, name=\'biases\'):\n        initializer = tf.constant_initializer(0.1)\n        return tf.get_variable(name=name, shape=shape, initializer=initializer)\n\n\nif __name__ == \'__main__\':\n    model = LSTMRNN(TIME_STEPS, INPUT_SIZE, OUTPUT_SIZE, CELL_SIZE, BATCH_SIZE)\n    sess = tf.Session()\n    merged = tf.summary.merge_all()\n    writer = tf.summary.FileWriter(""logs"", sess.graph)\n    # tf.initialize_all_variables() no long valid from\n    # 2017-03-02 if using tensorflow >= 0.12\n    if int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n        init = tf.initialize_all_variables()\n    else:\n        init = tf.global_variables_initializer()\n    sess.run(init)\n    # relocate to the local dir and run this line to view it on Chrome (http://0.0.0.0:6006/):\n    # $ tensorboard --logdir=\'logs\'\n\n    plt.ion()\n    plt.show()\n    for i in range(200):\n        seq, res, xs = get_batch()\n        if i == 0:\n            feed_dict = {\n                    model.xs: seq,\n                    model.ys: res,\n                    # create initial state\n            }\n        else:\n            feed_dict = {\n                model.xs: seq,\n                model.ys: res,\n                model.cell_init_state: state    # use last state as the initial state for this run\n            }\n\n        _, cost, state, pred = sess.run(\n            [model.train_op, model.cost, model.cell_final_state, model.pred],\n            feed_dict=feed_dict)\n\n        # plotting\n        plt.plot(xs[0, :], res[0].flatten(), \'r\', xs[0, :], pred.flatten()[:TIME_STEPS], \'b--\')\n        plt.ylim((-1.2, 1.2))\n        plt.draw()\n        plt.pause(0.3)\n\n        if i % 20 == 0:\n            print(\'cost: \', round(cost, 4))\n            result = sess.run(merged, feed_dict)\n            writer.add_summary(result, i)\n'"
tensorflowTUT/tf20_RNN2/full_code.py,31,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nThis code is a modified version of the code from this link:\nhttps://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n\nHis code is a very good one for RNN beginners. Feel free to check it out.\n""""""\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n# set random seed for comparing the two result calculations\ntf.set_random_seed(1)\n\n# this is data\nmnist = input_data.read_data_sets(\'MNIST_data\', one_hot=True)\n\n# hyperparameters\nlr = 0.001\ntraining_iters = 100000\nbatch_size = 128\n\nn_inputs = 28   # MNIST data input (img shape: 28*28)\nn_steps = 28    # time steps\nn_hidden_units = 128   # neurons in hidden layer\nn_classes = 10      # MNIST classes (0-9 digits)\n\n# tf Graph input\nx = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\ny = tf.placeholder(tf.float32, [None, n_classes])\n\n# Define weights\nweights = {\n    # (28, 128)\n    \'in\': tf.Variable(tf.random_normal([n_inputs, n_hidden_units])),\n    # (128, 10)\n    \'out\': tf.Variable(tf.random_normal([n_hidden_units, n_classes]))\n}\nbiases = {\n    # (128, )\n    \'in\': tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ])),\n    # (10, )\n    \'out\': tf.Variable(tf.constant(0.1, shape=[n_classes, ]))\n}\n\n\ndef RNN(X, weights, biases):\n    # hidden layer for input to cell\n    ########################################\n\n    # transpose the inputs shape from\n    # X ==> (128 batch * 28 steps, 28 inputs)\n    X = tf.reshape(X, [-1, n_inputs])\n\n    # into hidden\n    # X_in = (128 batch * 28 steps, 128 hidden)\n    X_in = tf.matmul(X, weights[\'in\']) + biases[\'in\']\n    # X_in ==> (128 batch, 28 steps, 128 hidden)\n    X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units])\n\n    # cell\n    ##########################################\n\n    # basic LSTM Cell.\n    if int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n        cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden_units, forget_bias=1.0, state_is_tuple=True)\n    else:\n        cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_units)\n    # lstm cell is divided into two parts (c_state, h_state)\n    init_state = cell.zero_state(batch_size, dtype=tf.float32)\n\n    # You have 2 options for following step.\n    # 1: tf.nn.rnn(cell, inputs);\n    # 2: tf.nn.dynamic_rnn(cell, inputs).\n    # If use option 1, you have to modified the shape of X_in, go and check out this:\n    # https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n    # In here, we go for option 2.\n    # dynamic_rnn receive Tensor (batch, steps, inputs) or (steps, batch, inputs) as X_in.\n    # Make sure the time_major is changed accordingly.\n    outputs, final_state = tf.nn.dynamic_rnn(cell, X_in, initial_state=init_state, time_major=False)\n\n    # hidden layer for output as the final results\n    #############################################\n    # results = tf.matmul(final_state[1], weights[\'out\']) + biases[\'out\']\n\n    # # or\n    # unpack to list [(batch, outputs)..] * steps\n    if int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n        outputs = tf.unpack(tf.transpose(outputs, [1, 0, 2]))    # states is the last outputs\n    else:\n        outputs = tf.unstack(tf.transpose(outputs, [1,0,2]))\n    results = tf.matmul(outputs[-1], weights[\'out\']) + biases[\'out\']    # shape = (128, 10)\n\n    return results\n\n\npred = RNN(x, weights, biases)\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\ntrain_op = tf.train.AdamOptimizer(lr).minimize(cost)\n\ncorrect_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\nwith tf.Session() as sess:\n    # tf.initialize_all_variables() no long valid from\n    # 2017-03-02 if using tensorflow >= 0.12\n    if int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n        init = tf.initialize_all_variables()\n    else:\n        init = tf.global_variables_initializer()\n    sess.run(init)\n    step = 0\n    while step * batch_size < training_iters:\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n        batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs])\n        sess.run([train_op], feed_dict={\n            x: batch_xs,\n            y: batch_ys,\n        })\n        if step % 20 == 0:\n            print(sess.run(accuracy, feed_dict={\n            x: batch_xs,\n            y: batch_ys,\n            }))\n        step += 1\n\n\n\n'"
tensorflowTUT/tf21_autoencoder/full_code.py,45,"b'# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# My tutorial website: https://morvanzhou.github.io/tutorials/\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False)\n\n\n# Visualize decoder setting\n# Parameters\nlearning_rate = 0.01\ntraining_epochs = 5\nbatch_size = 256\ndisplay_step = 1\nexamples_to_show = 10\n\n# Network Parameters\nn_input = 784  # MNIST data input (img shape: 28*28)\n\n# tf Graph input (only pictures)\nX = tf.placeholder(""float"", [None, n_input])\n\n# hidden layer settings\nn_hidden_1 = 256 # 1st layer num features\nn_hidden_2 = 128 # 2nd layer num features\nweights = {\n    \'encoder_h1\': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n    \'encoder_h2\': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    \'decoder_h1\': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),\n    \'decoder_h2\': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n}\nbiases = {\n    \'encoder_b1\': tf.Variable(tf.random_normal([n_hidden_1])),\n    \'encoder_b2\': tf.Variable(tf.random_normal([n_hidden_2])),\n    \'decoder_b1\': tf.Variable(tf.random_normal([n_hidden_1])),\n    \'decoder_b2\': tf.Variable(tf.random_normal([n_input])),\n}\n\n# Building the encoder\ndef encoder(x):\n    # Encoder Hidden layer with sigmoid activation #1\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[\'encoder_h1\']),\n                                   biases[\'encoder_b1\']))\n    # Decoder Hidden layer with sigmoid activation #2\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights[\'encoder_h2\']),\n                                   biases[\'encoder_b2\']))\n    return layer_2\n\n\n# Building the decoder\ndef decoder(x):\n    # Encoder Hidden layer with sigmoid activation #1\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[\'decoder_h1\']),\n                                   biases[\'decoder_b1\']))\n    # Decoder Hidden layer with sigmoid activation #2\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights[\'decoder_h2\']),\n                                   biases[\'decoder_b2\']))\n    return layer_2\n\n\n""""""\n\n# Visualize encoder setting\n# Parameters\nlearning_rate = 0.01    # 0.01 this learning rate will be better! Tested\ntraining_epochs = 10\nbatch_size = 256\ndisplay_step = 1\n\n# Network Parameters\nn_input = 784  # MNIST data input (img shape: 28*28)\n\n# tf Graph input (only pictures)\nX = tf.placeholder(""float"", [None, n_input])\n\n# hidden layer settings\nn_hidden_1 = 128\nn_hidden_2 = 64\nn_hidden_3 = 10\nn_hidden_4 = 2\n\nweights = {\n    \'encoder_h1\': tf.Variable(tf.truncated_normal([n_input, n_hidden_1],)),\n    \'encoder_h2\': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2],)),\n    \'encoder_h3\': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3],)),\n    \'encoder_h4\': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4],)),\n\n    \'decoder_h1\': tf.Variable(tf.truncated_normal([n_hidden_4, n_hidden_3],)),\n    \'decoder_h2\': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_2],)),\n    \'decoder_h3\': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_1],)),\n    \'decoder_h4\': tf.Variable(tf.truncated_normal([n_hidden_1, n_input],)),\n}\nbiases = {\n    \'encoder_b1\': tf.Variable(tf.random_normal([n_hidden_1])),\n    \'encoder_b2\': tf.Variable(tf.random_normal([n_hidden_2])),\n    \'encoder_b3\': tf.Variable(tf.random_normal([n_hidden_3])),\n    \'encoder_b4\': tf.Variable(tf.random_normal([n_hidden_4])),\n\n    \'decoder_b1\': tf.Variable(tf.random_normal([n_hidden_3])),\n    \'decoder_b2\': tf.Variable(tf.random_normal([n_hidden_2])),\n    \'decoder_b3\': tf.Variable(tf.random_normal([n_hidden_1])),\n    \'decoder_b4\': tf.Variable(tf.random_normal([n_input])),\n}\n\n\ndef encoder(x):\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[\'encoder_h1\']),\n                                   biases[\'encoder_b1\']))\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights[\'encoder_h2\']),\n                                   biases[\'encoder_b2\']))\n    layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights[\'encoder_h3\']),\n                                   biases[\'encoder_b3\']))\n    layer_4 = tf.add(tf.matmul(layer_3, weights[\'encoder_h4\']),\n                                    biases[\'encoder_b4\'])\n    return layer_4\n\n\ndef decoder(x):\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[\'decoder_h1\']),\n                                   biases[\'decoder_b1\']))\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights[\'decoder_h2\']),\n                                   biases[\'decoder_b2\']))\n    layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights[\'decoder_h3\']),\n                                biases[\'decoder_b3\']))\n    layer_4 = tf.nn.sigmoid(tf.add(tf.matmul(layer_3, weights[\'decoder_h4\']),\n                                biases[\'decoder_b4\']))\n    return layer_4\n""""""\n\n# Construct model\nencoder_op = encoder(X)\ndecoder_op = decoder(encoder_op)\n\n# Prediction\ny_pred = decoder_op\n# Targets (Labels) are the input data.\ny_true = X\n\n# Define loss and optimizer, minimize the squared error\ncost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n\n\n# Launch the graph\nwith tf.Session() as sess:\n    # tf.initialize_all_variables() no long valid from\n    # 2017-03-02 if using tensorflow >= 0.12\n    if int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n        init = tf.initialize_all_variables()\n    else:\n        init = tf.global_variables_initializer()\n    sess.run(init)\n    total_batch = int(mnist.train.num_examples/batch_size)\n    # Training cycle\n    for epoch in range(training_epochs):\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)  # max(x) = 1, min(x) = 0\n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            print(""Epoch:"", \'%04d\' % (epoch+1),\n                  ""cost="", ""{:.9f}"".format(c))\n\n    print(""Optimization Finished!"")\n\n    # # Applying encode and decode over test set\n    encode_decode = sess.run(\n        y_pred, feed_dict={X: mnist.test.images[:examples_to_show]})\n    # Compare original images with their reconstructions\n    f, a = plt.subplots(2, 10, figsize=(10, 2))\n    for i in range(examples_to_show):\n        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n        a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))\n    plt.show()\n\n    # encoder_result = sess.run(encoder_op, feed_dict={X: mnist.test.images})\n    # plt.scatter(encoder_result[:, 0], encoder_result[:, 1], c=mnist.test.labels)\n    # plt.colorbar()\n    # plt.show()\n\n'"
tensorflowTUT/tf22_scope/tf22_RNN_scope.py,38,"b""# visit https://morvanzhou.github.io/tutorials/ for more!\n\n\n# 22 scope (name_scope/variable_scope)\nfrom __future__ import print_function\nimport tensorflow as tf\n\nclass TrainConfig:\n    batch_size = 20\n    time_steps = 20\n    input_size = 10\n    output_size = 2\n    cell_size = 11\n    learning_rate = 0.01\n\n\nclass TestConfig(TrainConfig):\n    time_steps = 1\n\n\nclass RNN(object):\n\n    def __init__(self, config):\n        self._batch_size = config.batch_size\n        self._time_steps = config.time_steps\n        self._input_size = config.input_size\n        self._output_size = config.output_size\n        self._cell_size = config.cell_size\n        self._lr = config.learning_rate\n        self._built_RNN()\n\n    def _built_RNN(self):\n        with tf.variable_scope('inputs'):\n            self._xs = tf.placeholder(tf.float32, [self._batch_size, self._time_steps, self._input_size], name='xs')\n            self._ys = tf.placeholder(tf.float32, [self._batch_size, self._time_steps, self._output_size], name='ys')\n        with tf.name_scope('RNN'):\n            with tf.variable_scope('input_layer'):\n                l_in_x = tf.reshape(self._xs, [-1, self._input_size], name='2_2D')  # (batch*n_step, in_size)\n                # Ws (in_size, cell_size)\n                Wi = self._weight_variable([self._input_size, self._cell_size])\n                print(Wi.name)\n                # bs (cell_size, )\n                bi = self._bias_variable([self._cell_size, ])\n                # l_in_y = (batch * n_steps, cell_size)\n                with tf.name_scope('Wx_plus_b'):\n                    l_in_y = tf.matmul(l_in_x, Wi) + bi\n                l_in_y = tf.reshape(l_in_y, [-1, self._time_steps, self._cell_size], name='2_3D')\n\n            with tf.variable_scope('cell'):\n                cell = tf.contrib.rnn.BasicLSTMCell(self._cell_size)\n                with tf.name_scope('initial_state'):\n                    self._cell_initial_state = cell.zero_state(self._batch_size, dtype=tf.float32)\n\n                self.cell_outputs = []\n                cell_state = self._cell_initial_state\n                for t in range(self._time_steps):\n                    if t > 0: tf.get_variable_scope().reuse_variables()\n                    cell_output, cell_state = cell(l_in_y[:, t, :], cell_state)\n                    self.cell_outputs.append(cell_output)\n                self._cell_final_state = cell_state\n\n            with tf.variable_scope('output_layer'):\n                # cell_outputs_reshaped (BATCH*TIME_STEP, CELL_SIZE)\n                cell_outputs_reshaped = tf.reshape(tf.concat(self.cell_outputs, 1), [-1, self._cell_size])\n                Wo = self._weight_variable((self._cell_size, self._output_size))\n                bo = self._bias_variable((self._output_size,))\n                product = tf.matmul(cell_outputs_reshaped, Wo) + bo\n                # _pred shape (batch*time_step, output_size)\n                self._pred = tf.nn.relu(product)    # for displacement\n\n        with tf.name_scope('cost'):\n            _pred = tf.reshape(self._pred, [self._batch_size, self._time_steps, self._output_size])\n            mse = self.ms_error(_pred, self._ys)\n            mse_ave_across_batch = tf.reduce_mean(mse, 0)\n            mse_sum_across_time = tf.reduce_sum(mse_ave_across_batch, 0)\n            self._cost = mse_sum_across_time\n            self._cost_ave_time = self._cost / self._time_steps\n\n        with tf.variable_scope('trian'):\n            self._lr = tf.convert_to_tensor(self._lr)\n            self.train_op = tf.train.AdamOptimizer(self._lr).minimize(self._cost)\n\n    @staticmethod\n    def ms_error(y_target, y_pre):\n        return tf.square(tf.subtract(y_target, y_pre))\n\n    @staticmethod\n    def _weight_variable(shape, name='weights'):\n        initializer = tf.random_normal_initializer(mean=0., stddev=0.5, )\n        return tf.get_variable(shape=shape, initializer=initializer, name=name)\n\n    @staticmethod\n    def _bias_variable(shape, name='biases'):\n        initializer = tf.constant_initializer(0.1)\n        return tf.get_variable(name=name, shape=shape, initializer=initializer)\n\n\nif __name__ == '__main__':\n    train_config = TrainConfig()\n    test_config = TestConfig()\n\n    # the wrong method to reuse parameters in train rnn\n    with tf.variable_scope('train_rnn'):\n        train_rnn1 = RNN(train_config)\n    with tf.variable_scope('test_rnn'):\n        test_rnn1 = RNN(test_config)\n\n    # the right method to reuse parameters in train rnn\n    with tf.variable_scope('rnn') as scope:\n        sess = tf.Session()\n        train_rnn2 = RNN(train_config)\n        scope.reuse_variables()\n        test_rnn2 = RNN(test_config)\n        # tf.initialize_all_variables() no long valid from\n        # 2017-03-02 if using tensorflow >= 0.12\n        if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n            init = tf.initialize_all_variables()\n        else:\n            init = tf.global_variables_initializer()\n        sess.run(init)"""
tensorflowTUT/tf22_scope/tf22_scope.py,19,"b'# visit https://morvanzhou.github.io/tutorials/ for more!\n\n\n# 22 scope (name_scope/variable_scope)\nfrom __future__ import print_function\nimport tensorflow as tf\n\nwith tf.name_scope(""a_name_scope""):\n    initializer = tf.constant_initializer(value=1)\n    var1 = tf.get_variable(name=\'var1\', shape=[1], dtype=tf.float32, initializer=initializer)\n    var2 = tf.Variable(name=\'var2\', initial_value=[2], dtype=tf.float32)\n    var21 = tf.Variable(name=\'var2\', initial_value=[2.1], dtype=tf.float32)\n    var22 = tf.Variable(name=\'var2\', initial_value=[2.2], dtype=tf.float32)\n\n\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n    print(var1.name)        # var1:0\n    print(sess.run(var1))   # [ 1.]\n    print(var2.name)        # a_name_scope/var2:0\n    print(sess.run(var2))   # [ 2.]\n    print(var21.name)       # a_name_scope/var2_1:0\n    print(sess.run(var21))  # [ 2.0999999]\n    print(var22.name)       # a_name_scope/var2_2:0\n    print(sess.run(var22))  # [ 2.20000005]\n\n\nwith tf.variable_scope(""a_variable_scope"") as scope:\n    initializer = tf.constant_initializer(value=3)\n    var3 = tf.get_variable(name=\'var3\', shape=[1], dtype=tf.float32, initializer=initializer)\n    var4 = tf.Variable(name=\'var4\', initial_value=[4], dtype=tf.float32)\n    var4_reuse = tf.Variable(name=\'var4\', initial_value=[4], dtype=tf.float32)\n    scope.reuse_variables()\n    var3_reuse = tf.get_variable(name=\'var3\',)\n\nwith tf.Session() as sess:\n    # tf.initialize_all_variables() no long valid from\n    # 2017-03-02 if using tensorflow >= 0.12\n    if int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n        init = tf.initialize_all_variables()\n    else:\n        init = tf.global_variables_initializer()\n    sess.run(init)\n    print(var3.name)            # a_variable_scope/var3:0\n    print(sess.run(var3))       # [ 3.]\n    print(var4.name)            # a_variable_scope/var4:0\n    print(sess.run(var4))       # [ 4.]\n    print(var4_reuse.name)      # a_variable_scope/var4_1:0\n    print(sess.run(var4_reuse)) # [ 4.]\n    print(var3_reuse.name)      # a_variable_scope/var3:0\n    print(sess.run(var3_reuse)) # [ 3.]\n'"
tensorflowTUT/tf23_BN/tf23_BN.py,28,"b'""""""\nvisit https://morvanzhou.github.io/tutorials/ for more!\n\nBuild two networks.\n1. Without batch normalization\n2. With batch normalization\n\nRun tests on these two networks.\n""""""\n\n# 23 Batch Normalization\n\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n\nACTIVATION = tf.nn.relu\nN_LAYERS = 7\nN_HIDDEN_UNITS = 30\n\n\ndef fix_seed(seed=1):\n    # reproducible\n    np.random.seed(seed)\n    tf.set_random_seed(seed)\n\n\ndef plot_his(inputs, inputs_norm):\n    # plot histogram for the inputs of every layer\n    for j, all_inputs in enumerate([inputs, inputs_norm]):\n        for i, input in enumerate(all_inputs):\n            plt.subplot(2, len(all_inputs), j*len(all_inputs)+(i+1))\n            plt.cla()\n            if i == 0:\n                the_range = (-7, 10)\n            else:\n                the_range = (-1, 1)\n            plt.hist(input.ravel(), bins=15, range=the_range, color=\'#FF5733\')\n            plt.yticks(())\n            if j == 1:\n                plt.xticks(the_range)\n            else:\n                plt.xticks(())\n            ax = plt.gca()\n            ax.spines[\'right\'].set_color(\'none\')\n            ax.spines[\'top\'].set_color(\'none\')\n        plt.title(""%s normalizing"" % (""Without"" if j == 0 else ""With""))\n    plt.draw()\n    plt.pause(0.01)\n\n\ndef built_net(xs, ys, norm):\n    def add_layer(inputs, in_size, out_size, activation_function=None, norm=False):\n        # weights and biases (bad initialization for this case)\n        Weights = tf.Variable(tf.random_normal([in_size, out_size], mean=0., stddev=1.))\n        biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n\n        # fully connected product\n        Wx_plus_b = tf.matmul(inputs, Weights) + biases\n\n        # normalize fully connected product\n        if norm:\n            # Batch Normalize\n            fc_mean, fc_var = tf.nn.moments(\n                Wx_plus_b,\n                axes=[0],   # the dimension you wanna normalize, here [0] for batch\n                            # for image, you wanna do [0, 1, 2] for [batch, height, width] but not channel\n            )\n            scale = tf.Variable(tf.ones([out_size]))\n            shift = tf.Variable(tf.zeros([out_size]))\n            epsilon = 0.001\n\n            # apply moving average for mean and var when train on batch\n            ema = tf.train.ExponentialMovingAverage(decay=0.5)\n            def mean_var_with_update():\n                ema_apply_op = ema.apply([fc_mean, fc_var])\n                with tf.control_dependencies([ema_apply_op]):\n                    return tf.identity(fc_mean), tf.identity(fc_var)\n            mean, var = mean_var_with_update()\n\n            Wx_plus_b = tf.nn.batch_normalization(Wx_plus_b, mean, var, shift, scale, epsilon)\n            # similar with this two steps:\n            # Wx_plus_b = (Wx_plus_b - fc_mean) / tf.sqrt(fc_var + 0.001)\n            # Wx_plus_b = Wx_plus_b * scale + shift\n\n        # activation\n        if activation_function is None:\n            outputs = Wx_plus_b\n        else:\n            outputs = activation_function(Wx_plus_b)\n\n        return outputs\n\n    fix_seed(1)\n\n    if norm:\n        # BN for the first input\n        fc_mean, fc_var = tf.nn.moments(\n            xs,\n            axes=[0],\n        )\n        scale = tf.Variable(tf.ones([1]))\n        shift = tf.Variable(tf.zeros([1]))\n        epsilon = 0.001\n        # apply moving average for mean and var when train on batch\n        ema = tf.train.ExponentialMovingAverage(decay=0.5)\n        def mean_var_with_update():\n            ema_apply_op = ema.apply([fc_mean, fc_var])\n            with tf.control_dependencies([ema_apply_op]):\n                return tf.identity(fc_mean), tf.identity(fc_var)\n        mean, var = mean_var_with_update()\n        xs = tf.nn.batch_normalization(xs, mean, var, shift, scale, epsilon)\n\n    # record inputs for every layer\n    layers_inputs = [xs]\n\n    # build hidden layers\n    for l_n in range(N_LAYERS):\n        layer_input = layers_inputs[l_n]\n        in_size = layers_inputs[l_n].get_shape()[1].value\n\n        output = add_layer(\n            layer_input,    # input\n            in_size,        # input size\n            N_HIDDEN_UNITS, # output size\n            ACTIVATION,     # activation function\n            norm,           # normalize before activation\n        )\n        layers_inputs.append(output)    # add output for next run\n\n    # build output layer\n    prediction = add_layer(layers_inputs[-1], 30, 1, activation_function=None)\n\n    cost = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1]))\n    train_op = tf.train.GradientDescentOptimizer(0.001).minimize(cost)\n    return [train_op, cost, layers_inputs]\n\n# make up data\nfix_seed(1)\nx_data = np.linspace(-7, 10, 2500)[:, np.newaxis]\nnp.random.shuffle(x_data)\nnoise = np.random.normal(0, 8, x_data.shape)\ny_data = np.square(x_data) - 5 + noise\n\n# plot input data\nplt.scatter(x_data, y_data)\nplt.show()\n\nxs = tf.placeholder(tf.float32, [None, 1])  # [num_samples, num_features]\nys = tf.placeholder(tf.float32, [None, 1])\n\ntrain_op, cost, layers_inputs = built_net(xs, ys, norm=False)   # without BN\ntrain_op_norm, cost_norm, layers_inputs_norm = built_net(xs, ys, norm=True) # with BN\n\nsess = tf.Session()\nif int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n    init = tf.initialize_all_variables()\nelse:\n    init = tf.global_variables_initializer()\nsess.run(init)\n\n# record cost\ncost_his = []\ncost_his_norm = []\nrecord_step = 5\n\nplt.ion()\nplt.figure(figsize=(7, 3))\nfor i in range(250):\n    if i % 50 == 0:\n        # plot histogram\n        all_inputs, all_inputs_norm = sess.run([layers_inputs, layers_inputs_norm], feed_dict={xs: x_data, ys: y_data})\n        plot_his(all_inputs, all_inputs_norm)\n\n    # train on batch\n    sess.run([train_op, train_op_norm], feed_dict={xs: x_data[i*10:i*10+10], ys: y_data[i*10:i*10+10]})\n\n    if i % record_step == 0:\n        # record cost\n        cost_his.append(sess.run(cost, feed_dict={xs: x_data, ys: y_data}))\n        cost_his_norm.append(sess.run(cost_norm, feed_dict={xs: x_data, ys: y_data}))\n\nplt.ioff()\nplt.figure()\nplt.plot(np.arange(len(cost_his))*record_step, np.array(cost_his), label=\'no BN\')     # no norm\nplt.plot(np.arange(len(cost_his))*record_step, np.array(cost_his_norm), label=\'BN\')   # norm\nplt.legend()\nplt.show()\n\n\n'"
tensorflowTUT/tf5_example2/full_code.py,9,"b'# View more python tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\n\n# create data\nx_data = np.random.rand(100).astype(np.float32)\ny_data = x_data*0.1 + 0.3\n\n### create tensorflow structure start ###\nWeights = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\nbiases = tf.Variable(tf.zeros([1]))\n\ny = Weights*x_data + biases\n\nloss = tf.reduce_mean(tf.square(y-y_data))\noptimizer = tf.train.GradientDescentOptimizer(0.5)\ntrain = optimizer.minimize(loss)\n### create tensorflow structure end ###\n\nsess = tf.Session()\n# tf.initialize_all_variables() no long valid from\n# 2017-03-02 if using tensorflow >= 0.12\nif int((tf.__version__).split(\'.\')[1]) < 12 and int((tf.__version__).split(\'.\')[0]) < 1:\n    init = tf.initialize_all_variables()\nelse:\n    init = tf.global_variables_initializer()\nsess.run(init)\n\nfor step in range(201):\n    sess.run(train)\n    if step % 20 == 0:\n        print(step, sess.run(Weights), sess.run(biases))\n\n\n'"
theanoTUT/theano10_regression_visualization/for_you_to_practice.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 10 - visualize result\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport theano\nimport theano.tensor as T\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nclass Layer(object):\n    def __init__(self, inputs, in_size, out_size, activation_function=None):\n        self.W = theano.shared(np.random.normal(0, 1, (in_size, out_size)))\n        self.b = theano.shared(np.zeros((out_size, )) + 0.1)\n        self.Wx_plus_b = T.dot(inputs, self.W) + self.b\n        self.activation_function = activation_function\n        if activation_function is None:\n            self.outputs = self.Wx_plus_b\n        else:\n            self.outputs = self.activation_function(self.Wx_plus_b)\n\n\n# Make up some fake data\nx_data = np.linspace(-1, 1, 300)[:, np.newaxis]\nnoise = np.random.normal(0, 0.05, x_data.shape)\ny_data = np.square(x_data) - 0.5 + noise        # y = x^2 - 0.5\n\n# show the fake data\n# plt.scatter(x_data, y_data)\n# plt.show()\n\n# determine the inputs dtype\nx = T.dmatrix(""x"")\ny = T.dmatrix(""y"")\n\n# add layers\nl1 = Layer(x, 1, 10, T.nnet.relu)\nl2 = Layer(l1.outputs, 10, 1, None)\n\n# compute the cost\ncost = T.mean(T.square(l2.outputs - y))\n\n# compute the gradients\ngW1, gb1, gW2, gb2 = T.grad(cost, [l1.W, l1.b, l2.W, l2.b])\n\n# apply gradient descent\nlearning_rate = 0.05\ntrain = theano.function(\n    inputs=[x, y],\n    outputs=[cost],\n    updates=[(l1.W, l1.W - learning_rate * gW1),\n             (l1.b, l1.b - learning_rate * gb1),\n             (l2.W, l2.W - learning_rate * gW2),\n             (l2.b, l2.b - learning_rate * gb2)])\n\n# prediction\npredict = theano.function(inputs=[x], outputs=l2.outputs)\n\n# plot the real data\n\n\nfor i in range(1000):\n    # training\n    err = train(x_data, y_data)\n'"
theanoTUT/theano10_regression_visualization/full_code.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 10 - visualize result\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport theano\nimport theano.tensor as T\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nclass Layer(object):\n    def __init__(self, inputs, in_size, out_size, activation_function=None):\n        self.W = theano.shared(np.random.normal(0, 1, (in_size, out_size)))\n        self.b = theano.shared(np.zeros((out_size, )) + 0.1)\n        self.Wx_plus_b = T.dot(inputs, self.W) + self.b\n        self.activation_function = activation_function\n        if activation_function is None:\n            self.outputs = self.Wx_plus_b\n        else:\n            self.outputs = self.activation_function(self.Wx_plus_b)\n\n\n# Make up some fake data\nx_data = np.linspace(-1, 1, 300)[:, np.newaxis]\nnoise = np.random.normal(0, 0.05, x_data.shape)\ny_data = np.square(x_data) - 0.5 + noise        # y = x^2 - 0.5\n\n# show the fake data\nplt.scatter(x_data, y_data)\nplt.show()\n\n# determine the inputs dtype\nx = T.dmatrix(""x"")\ny = T.dmatrix(""y"")\n\n# add layers\nl1 = Layer(x, 1, 10, T.nnet.relu)\nl2 = Layer(l1.outputs, 10, 1, None)\n\n# compute the cost\ncost = T.mean(T.square(l2.outputs - y))\n\n# compute the gradients\ngW1, gb1, gW2, gb2 = T.grad(cost, [l1.W, l1.b, l2.W, l2.b])\n\n# apply gradient descent\nlearning_rate = 0.05\ntrain = theano.function(\n    inputs=[x, y],\n    outputs=[cost],\n    updates=[(l1.W, l1.W - learning_rate * gW1),\n             (l1.b, l1.b - learning_rate * gb1),\n             (l2.W, l2.W - learning_rate * gW2),\n             (l2.b, l2.b - learning_rate * gb2)])\n\n# prediction\npredict = theano.function(inputs=[x], outputs=l2.outputs)\n\n# plot the real data\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nax.scatter(x_data, y_data)\nplt.ion()\nplt.show()\n\nfor i in range(1000):\n    # training\n    err = train(x_data, y_data)\n    if i % 50 == 0:\n        # to visualize the result and improvement\n        try:\n            ax.lines.remove(lines[0])\n        except Exception:\n            pass\n        prediction_value = predict(x_data)\n        # plot the prediction\n        lines = ax.plot(x_data, prediction_value, \'r-\', lw=5)\n        plt.pause(.5)'"
theanoTUT/theano11_classification_nn/for_you_to_practice.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 11 - classification example\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport numpy as np\nimport theano\nimport theano.tensor as T\n\ndef compute_accuracy(y_target, y_predict):\n    correct_prediction = np.equal(y_predict, y_target)\n    accuracy = np.sum(correct_prediction)/len(correct_prediction)\n    return accuracy\n\nrng = np.random\n\nN = 400                                   # training sample size\nfeats = 784                               # number of input variables\n\n# generate a dataset: D = (input_values, target_class)\nD = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))\n\n# Declare Theano symbolic variables\n\n\n# initialize the weights and biases\n\n\n# Construct Theano expression graph\n\n\n# Compile\n\n\n# Training\nfor i in range(500):\n    pass\n    if i % 50 == 0:\n        pass\n\nprint(""target values for D:"")\nprint(\'\')\nprint(""prediction on D:"")\nprint(\'\')\n\n'"
theanoTUT/theano11_classification_nn/full_code.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 11 - classification example\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport numpy as np\nimport theano\nimport theano.tensor as T\n\ndef compute_accuracy(y_target, y_predict):\n    correct_prediction = np.equal(y_predict, y_target)\n    accuracy = np.sum(correct_prediction)/len(correct_prediction)\n    return accuracy\n\nrng = np.random\n\nN = 400                                   # training sample size\nfeats = 784                               # number of input variables\n\n# generate a dataset: D = (input_values, target_class)\nD = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))\n\n# Declare Theano symbolic variables\nx = T.dmatrix(""x"")\ny = T.dvector(""y"")\n\n# initialize the weights and biases\nW = theano.shared(rng.randn(feats), name=""w"")\nb = theano.shared(0., name=""b"")\n\n\n# Construct Theano expression graph\np_1 = T.nnet.sigmoid(T.dot(x, W) + b)   # Logistic Probability that target = 1 (activation function)\nprediction = p_1 > 0.5                    # The prediction thresholded\nxent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) # Cross-entropy loss function\n# or\n# xent = T.nnet.binary_crossentropy(p_1, y) # this is provided by theano\ncost = xent.mean() + 0.01 * (W ** 2).sum()# The cost to minimize (l2 regularization)\ngW, gb = T.grad(cost, [W, b])             # Compute the gradient of the cost\n\n\n# Compile\nlearning_rate = 0.1\ntrain = theano.function(\n          inputs=[x, y],\n          outputs=[prediction, xent.mean()],\n          updates=((W, W - learning_rate * gW), (b, b - learning_rate * gb)))\npredict = theano.function(inputs=[x], outputs=prediction)\n\n# Training\nfor i in range(500):\n    pred, err = train(D[0], D[1])\n    if i % 50 == 0:\n        print(\'cost:\', err)\n        print(""accuracy:"", compute_accuracy(D[1], predict(D[0])))\n\nprint(""target values for D:"")\nprint(D[1])\nprint(""prediction on D:"")\nprint(predict(D[0]))\n\n'"
theanoTUT/theano12_regularization/for_you_to_practice.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 12 - regularization\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport theano\nfrom sklearn.datasets import load_boston\nimport theano.tensor as T\nimport numpy as np\n\n\nclass Layer(object):\n    def __init__(self, inputs, in_size, out_size, activation_function=None):\n        self.W = theano.shared(np.random.normal(0, 1, (in_size, out_size)))\n        self.b = theano.shared(np.zeros((out_size, )) + 0.1)\n        self.Wx_plus_b = T.dot(inputs, self.W) + self.b\n        self.activation_function = activation_function\n        if activation_function is None:\n            self.outputs = self.Wx_plus_b\n        else:\n            self.outputs = self.activation_function(self.Wx_plus_b)\n\n\ndef minmax_normalization(data):\n    xs_max = np.max(data, axis=0)\n    xs_min = np.min(data, axis=0)\n    xs = (1 - 0) * (data - xs_min) / (xs_max - xs_min) + 0\n    return xs\n\nnp.random.seed(100)\nx_data = load_boston().data\n# minmax normalization, rescale the inputs\nx_data = minmax_normalization(x_data)\ny_data = load_boston().target[:, np.newaxis]\n\n# cross validation, train test data split\nx_train, y_train = x_data[:400], y_data[:400]\nx_test, y_test = x_data[400:], y_data[400:]\n\nx = T.dmatrix(""x"")\ny = T.dmatrix(""y"")\n\nl1 = Layer(x, 13, 50, T.tanh)\nl2 = Layer(l1.outputs, 50, 1, None)\n\n# the way to compute cost\ncost = T.mean(T.square(l2.outputs - y))\n\ngW1, gb1, gW2, gb2 = T.grad(cost, [l1.W, l1.b, l2.W, l2.b])\n\nlearning_rate = 0.01\ntrain = theano.function(\n    inputs=[x, y],\n    updates=[(l1.W, l1.W - learning_rate * gW1),\n             (l1.b, l1.b - learning_rate * gb1),\n             (l2.W, l2.W - learning_rate * gW2),\n             (l2.b, l2.b - learning_rate * gb2)])\n\ncompute_cost = theano.function(inputs=[x, y], outputs=cost)\n\n# record cost\n\nfor i in range(1000):\n    train(x_train, y_train)\n    if i % 10 == 0:\n        # record cost\n        pass\n\n# plot cost history\n'"
theanoTUT/theano12_regularization/full_code.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 12 - regularization\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport theano\nfrom sklearn.datasets import load_boston\nimport theano.tensor as T\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nclass Layer(object):\n    def __init__(self, inputs, in_size, out_size, activation_function=None):\n        self.W = theano.shared(np.random.normal(0, 1, (in_size, out_size)))\n        self.b = theano.shared(np.zeros((out_size, )) + 0.1)\n        self.Wx_plus_b = T.dot(inputs, self.W) + self.b\n        self.activation_function = activation_function\n        if activation_function is None:\n            self.outputs = self.Wx_plus_b\n        else:\n            self.outputs = self.activation_function(self.Wx_plus_b)\n\n\ndef minmax_normalization(data):\n    xs_max = np.max(data, axis=0)\n    xs_min = np.min(data, axis=0)\n    xs = (1 - 0) * (data - xs_min) / (xs_max - xs_min) + 0\n    return xs\n\nnp.random.seed(100)\nx_data = load_boston().data\n# minmax normalization, rescale the inputs\nx_data = minmax_normalization(x_data)\ny_data = load_boston().target[:, np.newaxis]\n\n# cross validation, train test data split\nx_train, y_train = x_data[:400], y_data[:400]\nx_test, y_test = x_data[400:], y_data[400:]\n\nx = T.dmatrix(""x"")\ny = T.dmatrix(""y"")\n\nl1 = Layer(x, 13, 50, T.tanh)\nl2 = Layer(l1.outputs, 50, 1, None)\n\n# the way to compute cost\ncost = T.mean(T.square(l2.outputs - y))      # without regularization\n# cost = T.mean(T.square(l2.outputs - y)) + 0.1 * ((l1.W ** 2).sum() + (l2.W ** 2).sum())  # with l2 regularization\n# cost = T.mean(T.square(l2.outputs - y)) + 0.1 * (abs(l1.W).sum() + abs(l2.W).sum())  # with l1 regularization\ngW1, gb1, gW2, gb2 = T.grad(cost, [l1.W, l1.b, l2.W, l2.b])\n\nlearning_rate = 0.01\ntrain = theano.function(\n    inputs=[x, y],\n    updates=[(l1.W, l1.W - learning_rate * gW1),\n             (l1.b, l1.b - learning_rate * gb1),\n             (l2.W, l2.W - learning_rate * gW2),\n             (l2.b, l2.b - learning_rate * gb2)])\n\ncompute_cost = theano.function(inputs=[x, y], outputs=cost)\n\n# record cost\ntrain_err_list = []\ntest_err_list = []\nlearning_time = []\nfor i in range(1000):\n    train(x_train, y_train)\n    if i % 10 == 0:\n        # record cost\n        train_err_list.append(compute_cost(x_train, y_train))\n        test_err_list.append(compute_cost(x_test, y_test))\n        learning_time.append(i)\n\n# plot cost history\nplt.plot(learning_time, train_err_list, \'r-\')\nplt.plot(learning_time, test_err_list, \'b--\')\nplt.show()'"
theanoTUT/theano13_save/for_you_to_practice.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 13 - save and reload\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport numpy as np\nimport theano\nimport theano.tensor as T\n\n\ndef compute_accuracy(y_target, y_predict):\n    correct_prediction = np.equal(y_predict, y_target)\n    accuracy = np.sum(correct_prediction)/len(correct_prediction)\n    return accuracy\n\nrng = np.random\n\n# set random seed\nnp.random.seed(100)\n\nN = 400\nfeats = 784\n\n# generate a dataset: D = (input_values, target_class)\nD = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))\n\n# Declare Theano symbolic variables\nx = T.dmatrix(""x"")\ny = T.dvector(""y"")\n\n# initialize the weights and biases\nw = theano.shared(rng.randn(feats), name=""w"")\nb = theano.shared(0., name=""b"")\n\n# Construct Theano expression graph\np_1 = 1 / (1 + T.exp(-T.dot(x, w) - b))\nprediction = p_1 > 0.5\nxent = -y * T.log(p_1) - (1-y) * T.log(1-p_1)\ncost = xent.mean() + 0.01 * (w ** 2).sum()\ngw, gb = T.grad(cost, [w, b])\n\n# Compile\nlearning_rate = 0.1\ntrain = theano.function(\n          inputs=[x, y],\n          updates=((w, w - learning_rate * gw), (b, b - learning_rate * gb)))\npredict = theano.function(inputs=[x], outputs=prediction)\n\n# Training\nfor i in range(500):\n    train(D[0], D[1])\n\n# save model\n\n\n# load model\n\n\n\n'"
theanoTUT/theano13_save/full_code.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 13 - save and reload\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport numpy as np\nimport theano\nimport theano.tensor as T\nimport pickle\n\ndef compute_accuracy(y_target, y_predict):\n    correct_prediction = np.equal(y_predict, y_target)\n    accuracy = np.sum(correct_prediction)/len(correct_prediction)\n    return accuracy\n\nrng = np.random\n\n# set random seed\nnp.random.seed(100)\n\nN = 400\nfeats = 784\n\n# generate a dataset: D = (input_values, target_class)\nD = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))\n\n# Declare Theano symbolic variables\nx = T.dmatrix(""x"")\ny = T.dvector(""y"")\n\n# initialize the weights and biases\nw = theano.shared(rng.randn(feats), name=""w"")\nb = theano.shared(0., name=""b"")\n\n# Construct Theano expression graph\np_1 = 1 / (1 + T.exp(-T.dot(x, w) - b))\nprediction = p_1 > 0.5\nxent = -y * T.log(p_1) - (1-y) * T.log(1-p_1)\ncost = xent.mean() + 0.01 * (w ** 2).sum()\ngw, gb = T.grad(cost, [w, b])\n\n# Compile\nlearning_rate = 0.1\ntrain = theano.function(\n          inputs=[x, y],\n          updates=((w, w - learning_rate * gw), (b, b - learning_rate * gb)))\npredict = theano.function(inputs=[x], outputs=prediction)\n\n# Training\nfor i in range(500):\n    train(D[0], D[1])\n\n# save model\nwith open(\'save/model.pickle\', \'wb\') as file:\n    model = [w.get_value(), b.get_value()]\n    pickle.dump(model, file)\n    print(model[0][:10])\n    print(""accuracy:"", compute_accuracy(D[1], predict(D[0])))\n\n# load model\nwith open(\'save/model.pickle\', \'rb\') as file:\n    model = pickle.load(file)\n    w.set_value(model[0])\n    b.set_value(model[1])\n    print(w.get_value()[:10])\n    print(""accuracy:"", compute_accuracy(D[1], predict(D[0])))\n\n\n'"
theanoTUT/theano9_regression_nn/for_you_to_practice.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 9 - regression example\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport theano\nimport theano.tensor as T\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nclass Layer(object):\n    def __init__(self, inputs, in_size, out_size, activation_function=None):\n        self.W = theano.shared(np.random.normal(0, 1, (in_size, out_size)))\n        self.b = theano.shared(np.zeros((out_size, )) + 0.1)\n        self.Wx_plus_b = T.dot(inputs, self.W) + self.b\n        self.activation_function = activation_function\n        if activation_function is None:\n            self.outputs = self.Wx_plus_b\n        else:\n            self.outputs = self.activation_function(self.Wx_plus_b)\n\n\n# Make up some fake data\nx_data = np.linspace(-1, 1, 300)[:, np.newaxis]\nnoise = np.random.normal(0, 0.05, x_data.shape)\ny_data = np.square(x_data) - 0.5 + noise        # y = x^2 - 0.5\n\n# show the fake data\nplt.scatter(x_data, y_data)\nplt.show()\n\n# determine the inputs dtype\n\n\n# add layers\n\n\n# compute the cost\n\n\n# compute the gradients\n\n\n# apply gradient descent\n\n\n# prediction\n\n\nfor i in range(1000):\n    # training\n\n    if i % 50 == 0:\n        pass'"
theanoTUT/theano9_regression_nn/full_code.py,0,"b'# View more python tutorials on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\n# 9 - regression example\n""""""\nPlease note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n""""""\nfrom __future__ import print_function\nimport theano\nimport theano.tensor as T\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nclass Layer(object):\n    def __init__(self, inputs, in_size, out_size, activation_function=None):\n        self.W = theano.shared(np.random.normal(0, 1, (in_size, out_size)))\n        self.b = theano.shared(np.zeros((out_size, )) + 0.1)\n        self.Wx_plus_b = T.dot(inputs, self.W) + self.b\n        self.activation_function = activation_function\n        if activation_function is None:\n            self.outputs = self.Wx_plus_b\n        else:\n            self.outputs = self.activation_function(self.Wx_plus_b)\n\n\n# Make up some fake data\nx_data = np.linspace(-1, 1, 300)[:, np.newaxis]\nnoise = np.random.normal(0, 0.05, x_data.shape)\ny_data = np.square(x_data) - 0.5 + noise        # y = x^2 - 0.5\n\n# show the fake data\nplt.scatter(x_data, y_data)\nplt.show()\n\n# determine the inputs dtype\nx = T.dmatrix(""x"")\ny = T.dmatrix(""y"")\n\n# add layers\nl1 = Layer(x, 1, 10, T.nnet.relu)\nl2 = Layer(l1.outputs, 10, 1, None)\n\n# compute the cost\ncost = T.mean(T.square(l2.outputs - y))\n\n# compute the gradients\ngW1, gb1, gW2, gb2 = T.grad(cost, [l1.W, l1.b, l2.W, l2.b])\n\n# apply gradient descent\nlearning_rate = 0.05\ntrain = theano.function(\n    inputs=[x, y],\n    outputs=cost,\n    updates=[(l1.W, l1.W - learning_rate * gW1),\n             (l1.b, l1.b - learning_rate * gb1),\n             (l2.W, l2.W - learning_rate * gW2),\n             (l2.b, l2.b - learning_rate * gb2)])\n\n# prediction\npredict = theano.function(inputs=[x], outputs=l2.outputs)\n\nfor i in range(1000):\n    # training\n    err = train(x_data, y_data)\n    if i % 50 == 0:\n        print(err)'"
tkinterTUT/tk13_login_example/tk13_login_example.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\n\nwindow = tk.Tk()\nwindow.title('Welcome to Mofan Python')\nwindow.geometry('450x300')\n\n# welcome image\ncanvas = tk.Canvas(window, height=200, width=500)\nimage_file = tk.PhotoImage(file='welcome.gif')\nimage = canvas.create_image(0,0, anchor='nw', image=image_file)\ncanvas.pack(side='top')\n\n# user information\ntk.Label(window, text='User name: ').place(x=50, y= 150)\ntk.Label(window, text='Password: ').place(x=50, y= 190)\n\nvar_usr_name = tk.StringVar()\nvar_usr_name.set('example@python.com')\nentry_usr_name = tk.Entry(window, textvariable=var_usr_name)\nentry_usr_name.place(x=160, y=150)\nvar_usr_pwd = tk.StringVar()\nentry_usr_pwd = tk.Entry(window, textvariable=var_usr_pwd, show='*')\nentry_usr_pwd.place(x=160, y=190)\n\ndef usr_login():\n    pass\ndef usr_sign_up():\n    pass\n\n# login and sign up button\nbtn_login = tk.Button(window, text='Login', command=usr_login)\nbtn_login.place(x=170, y=230)\nbtn_sign_up = tk.Button(window, text='Sign up', command=usr_sign_up)\nbtn_sign_up.place(x=270, y=230)\n\nwindow.mainloop()\n\n\n\n\n\n\n"""
tkinterTUT/tk14_login_example/tk14_login_example.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\nimport pickle\n\nwindow = tk.Tk()\nwindow.title('Welcome to Mofan Python')\nwindow.geometry('450x300')\n\n# welcome image\ncanvas = tk.Canvas(window, height=200, width=500)\nimage_file = tk.PhotoImage(file='welcome.gif')\nimage = canvas.create_image(0,0, anchor='nw', image=image_file)\ncanvas.pack(side='top')\n\n# user information\ntk.Label(window, text='User name: ').place(x=50, y= 150)\ntk.Label(window, text='Password: ').place(x=50, y= 190)\n\nvar_usr_name = tk.StringVar()\nvar_usr_name.set('example@python.com')\nentry_usr_name = tk.Entry(window, textvariable=var_usr_name)\nentry_usr_name.place(x=160, y=150)\nvar_usr_pwd = tk.StringVar()\nentry_usr_pwd = tk.Entry(window, textvariable=var_usr_pwd, show='*')\nentry_usr_pwd.place(x=160, y=190)\n\ndef usr_login():\n    usr_name = var_usr_name.get()\n    usr_pwd = var_usr_pwd.get()\n    try:\n        with open('usrs_info.pickle', 'rb') as usr_file:\n            usrs_info = pickle.load(usr_file)\n    except FileNotFoundError:\n        with open('usrs_info.pickle', 'wb') as usr_file:\n            usrs_info = {'admin': 'admin'}\n            pickle.dump(usrs_info, usr_file)\n    if usr_name in usrs_info:\n        if usr_pwd == usrs_info[usr_name]:\n            tk.messagebox.showinfo(title='Welcome', message='How are you? ' + usr_name)\n        else:\n            tk.messagebox.showerror(message='Error, your password is wrong, try again.')\n    else:\n        is_sign_up = tk.messagebox.askyesno('Welcome',\n                               'You have not sign up yet. Sign up today?')\n        if is_sign_up:\n            usr_sign_up()\n\ndef usr_sign_up():\n    pass\n\n# login and sign up button\nbtn_login = tk.Button(window, text='Login', command=usr_login)\nbtn_login.place(x=170, y=230)\nbtn_sign_up = tk.Button(window, text='Sign up', command=usr_sign_up)\nbtn_sign_up.place(x=270, y=230)\n\nwindow.mainloop()\n\n\n"""
tkinterTUT/tk15_login_example/tk15_login_example.py,0,"b""# View more python learning tutorial on my Youtube and Youku channel!!!\n\n# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n# Youku video tutorial: http://i.youku.com/pythontutorial\n\nimport tkinter as tk\nfrom tkinter import messagebox  # import this to fix messagebox error\nimport pickle\n\nwindow = tk.Tk()\nwindow.title('Welcome to Mofan Python')\nwindow.geometry('450x300')\n\n# welcome image\ncanvas = tk.Canvas(window, height=200, width=500)\nimage_file = tk.PhotoImage(file='welcome.gif')\nimage = canvas.create_image(0,0, anchor='nw', image=image_file)\ncanvas.pack(side='top')\n\n# user information\ntk.Label(window, text='User name: ').place(x=50, y= 150)\ntk.Label(window, text='Password: ').place(x=50, y= 190)\n\nvar_usr_name = tk.StringVar()\nvar_usr_name.set('example@python.com')\nentry_usr_name = tk.Entry(window, textvariable=var_usr_name)\nentry_usr_name.place(x=160, y=150)\nvar_usr_pwd = tk.StringVar()\nentry_usr_pwd = tk.Entry(window, textvariable=var_usr_pwd, show='*')\nentry_usr_pwd.place(x=160, y=190)\n\ndef usr_login():\n    usr_name = var_usr_name.get()\n    usr_pwd = var_usr_pwd.get()\n    try:\n        with open('usrs_info.pickle', 'rb') as usr_file:\n            usrs_info = pickle.load(usr_file)\n    except FileNotFoundError:\n        with open('usrs_info.pickle', 'wb') as usr_file:\n            usrs_info = {'admin': 'admin'}\n            pickle.dump(usrs_info, usr_file)\n    if usr_name in usrs_info:\n        if usr_pwd == usrs_info[usr_name]:\n            tk.messagebox.showinfo(title='Welcome', message='How are you? ' + usr_name)\n        else:\n            tk.messagebox.showerror(message='Error, your password is wrong, try again.')\n    else:\n        is_sign_up = tk.messagebox.askyesno('Welcome',\n                               'You have not signed up yet. Sign up today?')\n        if is_sign_up:\n            usr_sign_up()\n\ndef usr_sign_up():\n    def sign_to_Mofan_Python():\n        np = new_pwd.get()\n        npf = new_pwd_confirm.get()\n        nn = new_name.get()\n        with open('usrs_info.pickle', 'rb') as usr_file:\n            exist_usr_info = pickle.load(usr_file)\n        if np != npf:\n            tk.messagebox.showerror('Error', 'Password and confirm password must be the same!')\n        elif nn in exist_usr_info:\n            tk.messagebox.showerror('Error', 'The user has already signed up!')\n        else:\n            exist_usr_info[nn] = np\n            with open('usrs_info.pickle', 'wb') as usr_file:\n                pickle.dump(exist_usr_info, usr_file)\n            tk.messagebox.showinfo('Welcome', 'You have successfully signed up!')\n            window_sign_up.destroy()\n    window_sign_up = tk.Toplevel(window)\n    window_sign_up.geometry('350x200')\n    window_sign_up.title('Sign up window')\n\n    new_name = tk.StringVar()\n    new_name.set('example@python.com')\n    tk.Label(window_sign_up, text='User name: ').place(x=10, y= 10)\n    entry_new_name = tk.Entry(window_sign_up, textvariable=new_name)\n    entry_new_name.place(x=150, y=10)\n\n    new_pwd = tk.StringVar()\n    tk.Label(window_sign_up, text='Password: ').place(x=10, y=50)\n    entry_usr_pwd = tk.Entry(window_sign_up, textvariable=new_pwd, show='*')\n    entry_usr_pwd.place(x=150, y=50)\n\n    new_pwd_confirm = tk.StringVar()\n    tk.Label(window_sign_up, text='Confirm password: ').place(x=10, y= 90)\n    entry_usr_pwd_confirm = tk.Entry(window_sign_up, textvariable=new_pwd_confirm, show='*')\n    entry_usr_pwd_confirm.place(x=150, y=90)\n\n    btn_comfirm_sign_up = tk.Button(window_sign_up, text='Sign up', command=sign_to_Mofan_Python)\n    btn_comfirm_sign_up.place(x=150, y=130)\n\n# login and sign up button\nbtn_login = tk.Button(window, text='Login', command=usr_login)\nbtn_login.place(x=170, y=230)\nbtn_sign_up = tk.Button(window, text='Sign up', command=usr_sign_up)\nbtn_sign_up.place(x=270, y=230)\n\nwindow.mainloop()\n\n\n\n\n\n\n"""
