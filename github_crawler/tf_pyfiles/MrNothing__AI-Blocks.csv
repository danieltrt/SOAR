file_path,api_count,code
Example Projects/Gan Example/stdin_test.py,0,b'#description Empty script template\n#icon fa fa-flask\n\n'
Sources/build_scripts/global_functions.py,3,"b'import sys\nfrom PIL import Image\nimport tempfile\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport pickle\nimport soundfile as sf\nfrom scipy import misc\n\n#Built with AIBlocks\n#https://github.com/MrNothing/AI-Blocks\n\nNaN = None\n\ndef Log(msg, flush=True, ignore_errors=False):\n\tif ignore_errors:\n\t\tprint (msg.encode(sys.stdout.encoding, errors=\'replace\'))\n\telse:\n\t\tprint (msg)\n\n\tif EDITOR_MODE:\n\t\tsys.stderr.flush()\n\t\tsys.stdout.flush()\n\n\ndef LogErr(msg, flush=False):\n\tLog(\'err:\'+msg, flush)\n\ndef SetState(id, state, flush=True):\n\tif EDITOR_MODE:\n\t\tLog(\'status:\'+str(id)+\':\'+str(state), flush)\n\ndef SendChartData(id, name, value, color=\'#3e95cd\', flush=True):\n\tif EDITOR_MODE:\n\t\tLog(""chart:""+str(id)+"":""+str(name)+"":""+str(value)+"":""+str(color), flush)\n\ndef SendPieData(id, name, color=\'#3e95cd\', flush=True):\n\tif EDITOR_MODE:\n\t\tLog(""pie:""+str(id)+"":""+str(name)+"":""+str(color), flush)\n\n#data contains an array or normalized inputs (from 0 to 1)\ndef SendImageData(id, data, width=32, height=32, name="""", rgba=False, flush=True, invert=False, offset=0, resize=[]):\n\tif EDITOR_MODE:\n\t\timg = Image.new( \'RGBA\', (width,height), ""white"")\n\t\tpixels = img.load()\n\n\t\tfor i in range(len(data)):\t# for every pixel:\n\t\t\ty = int(np.floor(i/width))\n\t\t\tx = i-y*width\n\t\t\t#print(""coord: ""+str(x)+""_""+str(y)+"":""+str(data[i]))\n\t\t\tif rgba:\n\t\t\t\tpixel = [max(0, data[i][0]), max(0, data[i][1]), max(0, data[i][2]), max(0, data[i][3])]\n\t\t\telse:\n\t\t\t\tpixel = [max(0, data[i]), max(0, data[i]), max(0, data[i]), 1]\n\t\t\tif invert:\n\t\t\t\tpixels[x,height-y-1] = (int(pixel[0]*255), int(pixel[1]*255), int(pixel[2]*255), 255) # set the colour accordingly\n\t\t\telse:\n\t\t\t\tpixels[x,y] = (int(pixel[0]*255), int(pixel[1]*255), int(pixel[2]*255), 255) # set the colour accordingly\n\n\t\tif len(resize)>0:\n\t\t\timg = img.resize((resize[0], resize[1]), Image.NEAREST)\n\n\t\ttmpDir = tempfile.gettempdir()\n\t\timgPath = str(tmpDir)+""/""+name+""_out_""+str(id)+""_""+str(offset)+"".png""\n\t\timg.save(imgPath)\n\t\t\n\t\tLog(""img_data,""+str(id)+"",""+imgPath+"",""+name, flush)\n\ndef SendAudioData(id, data, name, samplerate=4410, offset=0):\n\tif EDITOR_MODE:\n\t\ttmpDir = tempfile.gettempdir()\n\t\timgPath = str(tmpDir)+""/""+name+""_out_""+str(id)+""_""+str(offset)+"".wav""\n\t\t\t\n\t\tsf.write(imgPath, data, samplerate)\n\t\tLog(""audio_data,""+str(id)+"",""+imgPath+"",""+name, True)\n\ndef SendGraph(id, data, data2=None, name="""", offset=0, flush=True, labels=[]):\n\tif EDITOR_MODE:\n\t\tplt.plot(data)\n\n\t\tif data2!=None:\n\t\t\tplt.plot(data2)\n\n\t\tplt.title(name)\n\n\t\tif len(labels)>0:\n\t\t\tplt.legend(labels)\n\n\t\ttmpDir = tempfile.gettempdir()\n\t\timgPath = str(tmpDir)+""/""+name+""_out_""+str(id)+""_""+str(offset)+"".png""\n\t\tplt.savefig(imgPath, bbox_inches=\'tight\')\n\t\tplt.close()\n\t\tLog(""img_data,""+str(id)+"",""+imgPath+"",""+name, flush)\n\nSendFastGraphWarningSent = False\ndef SendFastGraph(id, data, name="""", offset=0, flush=True):\n\tglobal SendFastGraphWarningSent\n\n\tif EDITOR_MODE:\n\t\twidth = len(data)\n\n\t\tif width>=1000 and not SendFastGraphWarningSent:\n\t\t\tLogErr(""Warning: feeding a large array to SendFastGraph can take time to render."", True)\n\t\t\tSendFastGraphWarningSent = True\n\n\t\theight = int(len(data)/2)\n\n\t\t_max = Math.MaxValue(data)\n\t\t_min = Math.MinValue(data)\n\n\t\tif _max==_min:\n\t\t\t_max+=100\n\t\t\t_min-=100\n\n\t\t#Log(""_max: ""+str(_max))\n\n\t\timg = Image.new( \'RGBA\', (width,height), ""white"")\n\t\tpixels = img.load()\n\n\t\tfor x in range(width):\n\t\t\tval = data[x]-_min\n\n\t\t\ty = max(0, int(height*(val/abs(_max-_min))))\n\t\t\ty = min(height-1, y)\n\n\t\t\tpixels[x, int(height/2)] = (128, 0, 0, 255) # set the colour accordingly\n\n\t\t\tstate = int(height/2)\n\n\t\t\twhile state!=y:\n\t\t\t\tif abs(state-y)>1:\n\t\t\t\t\tpixels[x,state] = (128, 128, 255, 255) # set the colour accordingly\n\t\t\t\telse:\n\t\t\t\t\tpixels[x,state] = (0, 0, 255, 255) # set the colour accordingly\n\n\t\t\t\tif state<y:\n\t\t\t\t\tstate+=1\n\t\t\t\telse:\n\t\t\t\t\tstate-=1\n\n\t\tIOHelpers.CarveNumber(pixels, _max, 10, 0)\n\t\tIOHelpers.CarveNumber(pixels, _min, 10, height-7)\n\n\t\ttmpDir = tempfile.gettempdir()\n\t\timgPath = str(tmpDir)+""/""+name+""_out_""+str(id)+""_""+str(offset)+"".png""\n\t\timg.save(imgPath)\n\t\t\n\t\tLog(""img_data,""+str(id)+"",""+imgPath+"",""+name, flush)\n\ndef SendSpectrogram(id, times, frequencies, spectogram, name="""", offset=0, flush=True):\n\tif EDITOR_MODE:\n\t\tplt.pcolormesh(times, frequencies, spectogram)\n\t\tplt.ylabel(\'Frequency [Hz]\')\n\t\tplt.xlabel(\'Time [sec]\')\n\n\t\ttmpDir = tempfile.gettempdir()\n\t\timgPath = str(tmpDir)+""/""+name+""_out_""+str(id)+""_""+str(offset)+"".png""\n\t\t\n\t\tplt.savefig(imgPath, bbox_inches=\'tight\')\n\t\tplt.close()\n\t\tLog(""img_data,""+str(id)+"",""+imgPath+"",""+name, flush)\n\n\nclass IOHelpers:\n\tdef save_output(data, cache_file):\n\t\twith open(cache_file, \'wb\') as f:\n\t\t\tpickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n\t\t\tLog(""data saved in file: ""+cache_file)\n\t\t\n\tdef load_output(cache_file):\t\t\n\t\tif os.path.exists(cache_file):\n\t\t\twith open(cache_file, \'rb\') as f:\n\t\t\t\tdata = pickle.load(f)\n\t\t\t\tLog(""data loaded from file: ""+cache_file)\n\t\t\t\treturn data\n\t\telse:\n\t\t\tLogErr(""file was not found: ""+cache_file)\n\t\t\treturn None\n\n\tdef SaveAudioFile(data, path, samplerate=4410, offset=0):\n\t\tsf.write(path, data, samplerate)\n\n\tdef CarveNumber(pixels, number, x, y, bg = (255, 255, 255, 255), color=(0, 0, 0, 255)):\n\t\tstr_num = str(number)\n\t\tloc_x = 0\n\t\tfor i in range(len(str_num)):\n\t\t\tIOHelpers.CarveDigit(pixels, str_num[i], x+loc_x, y, bg, color)\n\t\t\tloc_x+=4\n\n\tdef CreateImage(data, width=32, height=32, rgba=False, invert=False, resize=[]):\n\t\timg = Image.new( \'RGBA\', (width,height), ""white"")\n\t\tpixels = img.load()\n\n\t\tfor i in range(len(data)):\t# for every pixel:\n\t\t\ty = int(np.floor(i/width))\n\t\t\tx = i-y*width\n\t\t\t#print(""coord: ""+str(x)+""_""+str(y)+"":""+str(data[i]))\n\t\t\tif rgba:\n\t\t\t\tpixel = max(0, data[i])\n\t\t\telse:\n\t\t\t\tpixel = [max(0, data[i]), max(0, data[i]), max(0, data[i]), 1]\n\t\t\tif invert:\n\t\t\t\tpixels[x,height-y-1] = (int(pixel[0]*255), int(pixel[1]*255), int(pixel[2]*255), 255) # set the colour accordingly\n\t\t\telse:\n\t\t\t\tpixels[x,y] = (int(pixel[0]*255), int(pixel[1]*255), int(pixel[2]*255), 255) # set the colour accordingly\n\n\t\tif len(resize)>0:\n\t\t\timg = img.resize((resize[0], resize[1]), Image.NEAREST)\n\n\t\treturn img\n\n\tdef LoadImage(path):\n\t\tarr = misc.imread(path) # 640x480x3 array\n\t\treturn arr\n\n\t\n\tdef CarveDigit(pixels, digit, x, y, bg = (255, 255, 255, 255), color=(0, 0, 0, 255)):\n\t\t#3x5 = 15pixels\n\t\tif digit==\'0\':\n\t\t\tpixels[x+0, y+0] = bg\n\t\t\tpixels[x+1, y+0] = color\n\t\t\tpixels[x+2, y+0] = bg\n\n\t\t\tpixels[x+0, y+1] = color\n\t\t\tpixels[x+1, y+1] = bg\n\t\t\tpixels[x+2, y+1] = color\n\n\t\t\tpixels[x+0, y+2] = color\n\t\t\tpixels[x+1, y+2] = bg\n\t\t\tpixels[x+2, y+2] = color\n\n\t\t\tpixels[x+0, y+3] = color\n\t\t\tpixels[x+1, y+3] = bg\n\t\t\tpixels[x+2, y+3] = color\n\n\t\t\tpixels[x+0, y+4] = bg\n\t\t\tpixels[x+1, y+4] = color\n\t\t\tpixels[x+2, y+4] = bg\n\t\telif digit == \'1\':\n\t\t\tpixels[x+0, y+0] = bg\n\t\t\tpixels[x+1, y+0] = bg\n\t\t\tpixels[x+2, y+0] = color\n\n\t\t\tpixels[x+0, y+1] = bg\n\t\t\tpixels[x+1, y+1] = color\n\t\t\tpixels[x+2, y+1] = color\n\n\t\t\tpixels[x+0, y+2] = bg\n\t\t\tpixels[x+1, y+2] = bg\n\t\t\tpixels[x+2, y+2] = color\n\n\t\t\tpixels[x+0, y+3] = bg\n\t\t\tpixels[x+1, y+3] = bg\n\t\t\tpixels[x+2, y+3] = color\n\n\t\t\tpixels[x+0, y+4] = bg\n\t\t\tpixels[x+1, y+4] = bg\n\t\t\tpixels[x+2, y+4] = color\n\t\telif digit == \'2\':\n\t\t\tpixels[x+0, y+0] = color\n\t\t\tpixels[x+1, y+0] = color\n\t\t\tpixels[x+2, y+0] = bg\n\n\t\t\tpixels[x+0, y+1] = bg\n\t\t\tpixels[x+1, y+1] = bg\n\t\t\tpixels[x+2, y+1] = color\n\n\t\t\tpixels[x+0, y+2] = bg\n\t\t\tpixels[x+1, y+2] = color\n\t\t\tpixels[x+2, y+2] = bg\n\n\t\t\tpixels[x+0, y+3] = color\n\t\t\tpixels[x+1, y+3] = bg\n\t\t\tpixels[x+2, y+3] = bg\n\n\t\t\tpixels[x+0, y+4] = color\n\t\t\tpixels[x+1, y+4] = color\n\t\t\tpixels[x+2, y+4] = color\n\t\telif digit == \'3\':\n\t\t\tpixels[x+0, y+0] = color\n\t\t\tpixels[x+1, y+0] = color\n\t\t\tpixels[x+2, y+0] = bg\n\n\t\t\tpixels[x+0, y+1] = bg\n\t\t\tpixels[x+1, y+1] = bg\n\t\t\tpixels[x+2, y+1] = color\n\n\t\t\tpixels[x+0, y+2] = bg\n\t\t\tpixels[x+1, y+2] = color\n\t\t\tpixels[x+2, y+2] = bg\n\n\t\t\tpixels[x+0, y+3] = bg\n\t\t\tpixels[x+1, y+3] = bg\n\t\t\tpixels[x+2, y+3] = color\n\n\t\t\tpixels[x+0, y+4] = color\n\t\t\tpixels[x+1, y+4] = color\n\t\t\tpixels[x+2, y+4] = bg\n\t\telif digit == \'4\':\n\t\t\tpixels[x+0, y+0] = bg\n\t\t\tpixels[x+1, y+0] = bg\n\t\t\tpixels[x+2, y+0] = color\n\n\t\t\tpixels[x+0, y+1] = bg\n\t\t\tpixels[x+1, y+1] = color\n\t\t\tpixels[x+2, y+1] = color\n\n\t\t\tpixels[x+0, y+2] = color\n\t\t\tpixels[x+1, y+2] = bg\n\t\t\tpixels[x+2, y+2] = color\n\n\t\t\tpixels[x+0, y+3] = color\n\t\t\tpixels[x+1, y+3] = color\n\t\t\tpixels[x+2, y+3] = color\n\n\t\t\tpixels[x+0, y+4] = bg\n\t\t\tpixels[x+1, y+4] = bg\n\t\t\tpixels[x+2, y+4] = color\n\t\telif digit == \'5\':\n\t\t\tpixels[x+0, y+0] = color\n\t\t\tpixels[x+1, y+0] = color\n\t\t\tpixels[x+2, y+0] = color\n\n\t\t\tpixels[x+0, y+1] = color\n\t\t\tpixels[x+1, y+1] = bg\n\t\t\tpixels[x+2, y+1] = bg\n\n\t\t\tpixels[x+0, y+2] = color\n\t\t\tpixels[x+1, y+2] = color\n\t\t\tpixels[x+2, y+2] = color\n\n\t\t\tpixels[x+0, y+3] = bg\n\t\t\tpixels[x+1, y+3] = bg\n\t\t\tpixels[x+2, y+3] = color\n\n\t\t\tpixels[x+0, y+4] = color\n\t\t\tpixels[x+1, y+4] = color\n\t\t\tpixels[x+2, y+4] = bg\n\t\telif digit == \'6\':\n\t\t\tpixels[x+0, y+0] = bg\n\t\t\tpixels[x+1, y+0] = color\n\t\t\tpixels[x+2, y+0] = bg\n\n\t\t\tpixels[x+0, y+1] = color\n\t\t\tpixels[x+1, y+1] = bg\n\t\t\tpixels[x+2, y+1] = bg\n\n\t\t\tpixels[x+0, y+2] = color\n\t\t\tpixels[x+1, y+2] = color\n\t\t\tpixels[x+2, y+2] = bg\n\n\t\t\tpixels[x+0, y+3] = color\n\t\t\tpixels[x+1, y+3] = bg\n\t\t\tpixels[x+2, y+3] = color\n\n\t\t\tpixels[x+0, y+4] = bg\n\t\t\tpixels[x+1, y+4] = color\n\t\t\tpixels[x+2, y+4] = bg\n\t\telif digit == \'7\':\n\t\t\tpixels[x+0, y+0] = color\n\t\t\tpixels[x+1, y+0] = color\n\t\t\tpixels[x+2, y+0] = color\n\n\t\t\tpixels[x+0, y+1] = bg\n\t\t\tpixels[x+1, y+1] = bg\n\t\t\tpixels[x+2, y+1] = color\n\n\t\t\tpixels[x+0, y+2] = bg\n\t\t\tpixels[x+1, y+2] = color\n\t\t\tpixels[x+2, y+2] = bg\n\n\t\t\tpixels[x+0, y+3] = bg\n\t\t\tpixels[x+1, y+3] = color\n\t\t\tpixels[x+2, y+3] = bg\n\n\t\t\tpixels[x+0, y+4] = bg\n\t\t\tpixels[x+1, y+4] = color\n\t\t\tpixels[x+2, y+4] = bg\n\t\telif digit == \'8\':\n\t\t\tpixels[x+0, y+0] = bg\n\t\t\tpixels[x+1, y+0] = color\n\t\t\tpixels[x+2, y+0] = bg\n\n\t\t\tpixels[x+0, y+1] = color\n\t\t\tpixels[x+1, y+1] = bg\n\t\t\tpixels[x+2, y+1] = color\n\n\t\t\tpixels[x+0, y+2] = bg\n\t\t\tpixels[x+1, y+2] = color\n\t\t\tpixels[x+2, y+2] = bg\n\n\t\t\tpixels[x+0, y+3] = color\n\t\t\tpixels[x+1, y+3] = bg\n\t\t\tpixels[x+2, y+3] = color\n\n\t\t\tpixels[x+0, y+4] = bg\n\t\t\tpixels[x+1, y+4] = color\n\t\t\tpixels[x+2, y+4] = bg\n\t\telif digit == \'9\':\n\t\t\tpixels[x+0, y+0] = bg\n\t\t\tpixels[x+1, y+0] = color\n\t\t\tpixels[x+2, y+0] = bg\n\n\t\t\tpixels[x+0, y+1] = color\n\t\t\tpixels[x+1, y+1] = bg\n\t\t\tpixels[x+2, y+1] = color\n\n\t\t\tpixels[x+0, y+2] = color\n\t\t\tpixels[x+1, y+2] = color\n\t\t\tpixels[x+2, y+2] = color\n\n\t\t\tpixels[x+0, y+3] = bg\n\t\t\tpixels[x+1, y+3] = bg\n\t\t\tpixels[x+2, y+3] = color\n\n\t\t\tpixels[x+0, y+4] = bg\n\t\t\tpixels[x+1, y+4] = color\n\t\t\tpixels[x+2, y+4] = bg\n\t\telif digit==\'-\':\n\t\t\tpixels[x+0, y+0] = bg\n\t\t\tpixels[x+1, y+0] = bg\n\t\t\tpixels[x+2, y+0] = bg\n\n\t\t\tpixels[x+0, y+1] = bg\n\t\t\tpixels[x+1, y+1] = bg\n\t\t\tpixels[x+2, y+1] = bg\n\n\t\t\tpixels[x+0, y+2] = color\n\t\t\tpixels[x+1, y+2] = color\n\t\t\tpixels[x+2, y+2] = color\n\n\t\t\tpixels[x+0, y+3] = bg\n\t\t\tpixels[x+1, y+3] = bg\n\t\t\tpixels[x+2, y+3] = bg\n\n\t\t\tpixels[x+0, y+4] = bg\n\t\t\tpixels[x+1, y+4] = bg\n\t\t\tpixels[x+2, y+4] = bg\n\t\telif digit==\'.\':\n\t\t\tpixels[x+0, y+0] = bg\n\t\t\tpixels[x+1, y+0] = bg\n\t\t\tpixels[x+2, y+0] = bg\n\n\t\t\tpixels[x+0, y+1] = bg\n\t\t\tpixels[x+1, y+1] = bg\n\t\t\tpixels[x+2, y+1] = bg\n\n\t\t\tpixels[x+0, y+2] = bg\n\t\t\tpixels[x+1, y+2] = bg\n\t\t\tpixels[x+2, y+2] = bg\n\n\t\t\tpixels[x+0, y+3] = bg\n\t\t\tpixels[x+1, y+3] = bg\n\t\t\tpixels[x+2, y+3] = bg\n\n\t\t\tpixels[x+0, y+4] = bg\n\t\t\tpixels[x+1, y+4] = color\n\t\t\tpixels[x+2, y+4] = bg\n\t\telif digit==\'e\':\n\t\t\tpixels[x+0, y+0] = bg\n\t\t\tpixels[x+1, y+0] = color\n\t\t\tpixels[x+2, y+0] = bg\n\n\t\t\tpixels[x+0, y+1] = color\n\t\t\tpixels[x+1, y+1] = bg\n\t\t\tpixels[x+2, y+1] = color\n\n\t\t\tpixels[x+0, y+2] = color\n\t\t\tpixels[x+1, y+2] = color\n\t\t\tpixels[x+2, y+2] = color\n\n\t\t\tpixels[x+0, y+3] = color\n\t\t\tpixels[x+1, y+3] = bg\n\t\t\tpixels[x+2, y+3] = bg\n\n\t\t\tpixels[x+0, y+4] = bg\n\t\t\tpixels[x+1, y+4] = color\n\t\t\tpixels[x+2, y+4] = color\n\t\telse:\n\t\t\tpixels[x+0, y+0] = bg\n\t\t\tpixels[x+1, y+0] = bg\n\t\t\tpixels[x+2, y+0] = bg\n\n\t\t\tpixels[x+0, y+1] = bg\n\t\t\tpixels[x+1, y+1] = bg\n\t\t\tpixels[x+2, y+1] = bg\n\n\t\t\tpixels[x+0, y+2] = bg\n\t\t\tpixels[x+1, y+2] = bg\n\t\t\tpixels[x+2, y+2] = bg\n\n\t\t\tpixels[x+0, y+3] = bg\n\t\t\tpixels[x+1, y+3] = bg\n\t\t\tpixels[x+2, y+3] = bg\n\n\t\t\tpixels[x+0, y+4] = bg\n\t\t\tpixels[x+1, y+4] = bg\n\t\t\tpixels[x+2, y+4] = bg\n\t\treturn pixels\n\n\t\n\nclass TFInstance:\n\tdef __init__(self, session, saver, save_path):\n\t\tself.session = session\n\t\tself.saver = saver\n\t\tself.save_path = save_path\n\n\tdef Run(self, tensors, feed_dict):\n\t\treturn self.session.run(tensors, feed_dict=feed_dict)\n\nclass AIBlocks:\n\tdef InitModel(load_path=""""):\n\t\t# Initializing the variables\n\t\tinit = tf.global_variables_initializer()\n\n\t\t# \'Saver\' op to save and restore all the variables\n\t\tsaver = tf.train.Saver()\n\n\t\tsess = tf.Session()\n\t\tsess.run(init)\n\n\t\tif len(load_path)>0 and os.path.exists(load_path+""/model.meta""):\n\t\t\tres=saver.restore(sess, load_path+""/model"")\n\t\t\tLog (""Model loaded from: ""+load_path+""/model"")\n\n\t\treturn TFInstance(sess, saver, load_path)\n\n\tdef SaveModel(instance, save_path=""""):\n\t\tif len(instance.save_path)>0:\n\t\t\tsave_path = instance.save_path\n\n\t\tif len(save_path)>0:\n\t\t\t# Save model weights to disk\n\t\t\ts_path = instance.saver.save(instance.session, save_path+""/model"")\n\t\t\tLog (""Model saved in file: ""+str(s_path))\n\n\tdef CloseSession(instance):\n\t\tinstance.session.close()\n\n\tdef CloseInstance(instance):\n\t\tinstance.session.close()\n\n\tdef MaxIndex(data):\n\t\t_max = -10000000\n\t\tbest_index = 0\n\t\tfor i in range(len(data)):\n\t\t\tif(_max<data[i]):\n\t\t\t\t_max = data[i]\n\t\t\t\tbest_index = i\n\t\treturn best_index\n\nclass TextHelper:\n\tdef __init__(self):\n\t\tself.alphabet = {\'\':0, \'b\':1, \'c\':2, \'d\':3, \'e\':4, \'f\':5, \'g\':6, \'h\':7, \'i\':8, \'j\':9, \'k\':10, \'l\':11, \'m\':12, \'n\':13, \'o\':14, \'p\':15, \'q\':16, \'r\':17, \'s\':18, \'t\':19, \'u\':20, \'v\':21, \'w\':22, \'x\':23, \'y\':24, \'z\':25, \'a\':26, \' \':27}\n\t\tself.inv_alphabet = [\'\', \'b\', \'c\', \'d\', \'e\', \'f\', \'g\', \'h\', \'i\', \'j\', \'k\', \'l\', \'m\', \'n\', \'o\', \'p\', \'q\', \'r\', \'s\', \'t\', \'u\', \'v\', \'w\', \'x\', \'y\', \'z\', \'a\', \' \']\n\n\tdef char2float(self, c):\n\t\treturn ord(c)/256\n\n\tdef float2Char(self, value):\n\t\tval = int(value*256)\n\t\tif(val!=0):\n\t\t\treturn chr(val)\n\t\telif val>256:\n\t\t\treturn \'?\'\n\t\telse:\n\t\t\treturn \'\'\n\t\t\n\tdef word2vec(self, word, charactersPerWord=10):\n\t\tword = word.lower()\n\t\tres = []\n\t\tfor i in range(len(word)):\n\t\t\tres+=self.char2OneHot(word[i])\n\n\t\twhile len(res)<charactersPerWord*len(self.alphabet):\n\t\t\tres.append(0)\n\n\t\treturn res[0:charactersPerWord*len(self.alphabet)]\n\n\tdef vec2Word(self, vec):\n\t\tres = \'\'\n\t\tfor i in range(int(len(vec)/len(self.alphabet))):\n\t\t\tres+=self.oneHot2char(vec[i*len(self.alphabet):(i+1)*len(self.alphabet)])\n\t\treturn res\n\n\tdef oneHot2char(self, vec):\n\t\tindex = AIBlocks.MaxIndex(vec)\n\t\tif(index>len(self.alphabet)-1):\n\t\t\treturn \'?\'\n\t\telse:\n\t\t\treturn self.inv_alphabet[index]\n\n\tdef char2OneHot(self, value):\n\t\tval = 0\n\t\tres = [0]*len(self.alphabet)\n\t\tif self.alphabet.__contains__(value):\n\t\t\tval = self.alphabet[value]\n\t\tres[val] = 1\n\t\treturn res\n\n\tdef float2Word(self, value):\n\t\tval = int(value*self.wordsCounter)\n\t\tif(val<0):\n\t\t\treturn ""<?""\n\t\telif(val>self.wordsCounter-1):\n\t\t\treturn "">?""\n\t\telse:\n\t\t\treturn self.InvertedWordsIndex[val]\n\nclass Math:\n\tdef Lerp(a, b, t):\n\t\treturn (a+(b-a)*t)\n\n\tdef LerpVec(a, b, t):\n\t\tfor i in range(len(a)):\n\t\t\ta[i] = Math.Lerp(a[i], b[i], t)\n\n\tdef Magnitude(a):\n\t\ts = 0\n\t\tfor i in range(len(a)):\n\t\t\ts += abs(a[i])\n\t\treturn s\n\n\tdef MaxIndex(data):\n\t\t_max = -10000000\n\t\tbest_index = 0\n\t\tfor i in range(len(data)):\n\t\t\tif(_max<data[i]):\n\t\t\t\t_max = data[i]\n\t\t\t\tbest_index = i\n\t\treturn best_index\n\n\tdef MaxValue(data):\n\t\t_max = -10000000\n\t\tbest_index = 0\n\t\tfor i in range(len(data)):\n\t\t\tif(_max<data[i]):\n\t\t\t\t_max = data[i]\n\t\t\t\tbest_index = i\n\t\treturn data[best_index]\n\n\tdef MinValue(data):\n\t\t_min = 10000000\n\t\tbest_index = 0\n\t\tfor i in range(len(data)):\n\t\t\tif(_min>data[i]):\n\t\t\t\t_min = data[i]\n\t\t\t\tbest_index = i\n\t\treturn data[best_index]\n\n\tdef OneHot(data, labels=32, offset=0, strict=False):\n\t\toutput = []\n\t\tisMulti = False\n\t\tif str(labels.__class__())==""[]"":\n\t\t\tlabels = labels[0]\n\t\t\tisMulti = True\n\t\t\n\t\tif isMulti:\n\t\t\tfor d in data:\n\t\t\t\trow = [0]*labels\n\t\t\t\tindex = int(d*labels)\n\t\t\t\t\n\t\t\t\tif index<0:\n\t\t\t\t\tif strict:\n\t\t\t\t\t\traise Exception(""Value: ""+str(d)+"" was out of bounds while encoding OneHot"")\n\t\t\t\t\telse:\n\t\t\t\t\t\tindex = 0\n\t\t\t\telif index>labels-1:\n\t\t\t\t\tif strict:\n\t\t\t\t\t\traise Exception(""Value: ""+str(d)+"" was out of bounds while encoding OneHot"")\n\t\t\t\t\telse:\n\t\t\t\t\t\tindex = labels-1\n\t\t\t\t\t\n\t\t\t\trow[index] = 1\n\n\t\t\t\toutput.append(row)\n\t\telse:\n\t\t\toutput = [0]*labels\n\n\t\t\tindex = int(data*labels)\n\n\t\t\tif index<0:\n\t\t\t\tif strict:\n\t\t\t\t\traise Exception(""index: ""+str(index)+"" was out of bounds while encoding OneHot"")\n\t\t\t\telse:\n\t\t\t\t\tindex = 0\n\t\t\telif index>labels-1:\n\t\t\t\tif strict:\n\t\t\t\t\traise Exception(""index: ""+str(index)+"" was out of bounds while encoding OneHot"")\n\t\t\t\telse:\n\t\t\t\t\tindex = labels-1\n\n\t\t\toutput[index] = 1\n\t\t\t\t \n\t\treturn output\n\n\t\t\n\tdef uLaw(x, mu=8):\n\t\tif str(x.__class__())==""[]"":\n\t\t\tres = []\n\t\t\tfor i in range(len(x)):\n\t\t\t\tres.append(Math.uLaw(x[i], mu))\n\n\t\t\treturn res\n\t\telse:\n\t\t\treturn np.sign(x)*np.log(1+mu*abs(x))/np.log(1+mu)\n\t\t\n\tdef uLawInvert(x, mu=8):\n\t\ta = mu\n\t\tk = 1/np.log(1+a)\n\t\tu = abs(x)\n\t\treturn np.sign(x)*(np.exp(u/k)-1)/a\n\t\t\n\t#uLaw, default 8bit (256)\n\tdef uLawEncode(data, u=1024, real_uLaw=False, quantification=True):\n\t\t\n\t\tif quantification:\n\t\t\tdata = np.floor(data/(1/u))*(1/u)\n\t\t\n\t\tif real_uLaw:\n\t\t\tdata = (Encoder.uLaw(data*2-1)+1)/2\n\t\t\n\t\treturn data\n\t\t\n\tdef uLawDecode(data):\n\t\treturn (Encoder.uLawInvert((data-0.5)*2)+1)/2\n\n\tdef quantify(data, u=256):\n\t\treturn np.floor(data/(1/u))*(1/u)\n\t\t\n\tdef max_value(data=[]):\n\t\t_max = 0\n\t\t_max_index = -1\n\t\tfor i in range(len(data)):\n\t\t\tif abs(data[i])>_max:\n\t\t\t\t_max_index = i\n\t\t\t\t_max = abs(data[i])\n\t\t\t\t\n\t\treturn abs(data[_max_index])\n\t\t\n\tdef avg(data=[], steps=-1):\n\t\tif steps <= 0:\n\t\t\t_sum = 0\n\t\t\t\n\t\t\tfor v in data:\n\t\t\t\t_sum+=v\n\t\t\t\t\n\t\t\treturn _sum/len(data)\n\t\telse:\n\t\t\t_sum = 0\n\t\t\tstride = int(len(data)/steps)\n\t\t\t\n\t\t\tif stride<=0:\n\t\t\t\tstride = 1\n\t\t\t\t\n\t\t\tcounter = 0\n\t\t\tdivider = 0\n\t\t\tfor v in range(steps):\n\t\t\t\tif counter<len(data):\n\t\t\t\t\t_sum+=data[counter]\n\t\t\t\t\tdivider+=1\n\t\t\t\telse:\n\t\t\t\t\tbreak\n\n\t\t\t\tcounter+=stride\n\t\t\n\t\t\treturn _sum/divider\n\t\t\t\n\tdef entropy(data=[], ground=0, multiplier = 3):\n\t\t_sum = 0\n\t\t_len = max(1, len(data))\n\t\tfor v in data:\n\t\t\t_sum+=abs(v-ground)*multiplier\n\t\treturn min(0.99, _sum/_len)\n\t\t\n\tdef rangeFactor(t, point, _range):\n\t\tratio = np.abs (point - t) / _range\n\t\tif ratio < 1:\n\t\t\treturn 1 - ratio\n\t\telse:\n\t\t\treturn 0\n\t\t\t\n\tdef get_frequency(signal, zero_thresh=0.5, multiplier=1, auto_thresh=True, differential=False):\n\t\tif differential:\n\t\t\tdif = np.diff(signal)\n\t\t\t\n\t\t\tfor i in range(len(dif)):\n\t\t\t\tdif[i] = np.abs(dif[i])\n\t\t\t\t\n\t\t\treturn np.average(dif)*multiplier\n\t\telse:\n\t\t\tif(auto_thresh):\n\t\t\t\tzero_thresh = np.average(signal)\n\t\t\t\n\t\t\tzero_crossings = 0\n\t\t\tfor i in range(len(signal)-1):\n\t\t\t\tif(signal[i]<=zero_thresh and signal[i+1]>zero_thresh) or (signal[i]>=zero_thresh and signal[i+1]<zero_thresh):\n\t\t\t\t\tzero_crossings+=1\n\t\t \n\t\t\treturn zero_crossings*multiplier\n\t\t\t\n\tdef normalize(sample):\n\t\t_max = 0\n\t\t_min = np.Infinity\n\t\tfor m in sample:\n\t\t\tif m>_max:\n\t\t\t\t_max = abs(m)\n\t\t\tif m<_min:\n\t\t\t\t_min = m\n\n\t\t_max-=_min\n\t\t\n\t\tif _max>0:\n\t\t\tfor i in range(len(sample)):\n\t\t\t\tsample[i] = (sample[i]-_min)/_max\n\t\t\n\t\treturn sample\n\n\tdef get_normalized_bounds(sample):\n\t\t_max = 0\n\t\t_min = np.Infinity\n\t\tfor m in sample:\n\t\t\tif m>_max:\n\t\t\t\t_max = abs(m)\n\t\t\tif m<_min:\n\t\t\t\t_min = m\n\n\t\t_max-=_min\n\t\t\n\t\treturn _min, _max \n\n\tdef normalize2D(sample):\n\t\t_max = 0\n\t\tfor m in sample:\n\t\t\tfor n in m:\n\t\t\t\tif abs(n)>_max:\n\t\t\t\t\t_max = abs(n)\n\t\t\t\t\n\t\tfor i in range(len(sample)):\n\t\t\tfor j in range(len(sample[i])):\n\t\t\t\tsample[i][j] = sample[i][j]/_max\n\t\treturn sample\n\n\tdef Spectrogram(samples, samplerate):\n\t\tfrom scipy import signal\n\t\tfrequencies, times, spectogram = signal.spectrogram(samples, len(samples))\n\t\treturn spectogram\n\n\tdef Sigmoid(x):\n\t\treturn 1/(1+np.exp(-x))\n\n\tdef Abs(data):\n\t\tif str(data.__class__())==""[]"":\n\t\t\tres = []\n\t\t\tfor i in range(len(data)):\n\t\t\t\tres.append(abs(data[i]))\n\n\t\t\treturn res\n\t\telse:\n\t\t\treturn abs(data)\n\n\tdef get_input(_input, index):\n\t    if index<0:\n\t        return 0\n\t    elif index>len(_input)-1:\n\t        return 0\n\t    else:\n\t        return _input[index]     \n\n\tdef gaussian_blur(_input, _range=3):\n\t    output = []\n\t    for i in range(len(_input)):\n\t        avg = 0\n\t        for k in range(-_range, _range):\n\t            avg+=Math.get_input(_input, i+k)\n\t        avg = avg/(_range*2)\n\t        output.append(avg)\n\t    return output\n'"
Sources/build_scripts/scripts_init.py,0,"b'\tdef ButtonPressed(self, button_name):\n\t\tif EDITOR_MODE:\n\t\t\ttry:\n\t\t\t\ttmpDir = _aiblocks_default_tmp_folder+""\\\\buttons_""+str(self.id)+""_""+button_name\n\t\t\t\tfile = open(tmpDir,""rw"") \n\t\t\t\tlines = file.readlines()\n\n\t\t\t\tfor i in range(len(lines)):\n\t\t\t\t\tif current==0:\n\t\t\t\t\t\tname = lines[i].replace(""\\n"", """")\n\t\t\t\t\t\tcurrent = 1\n\t\t\t\t\telse:\n\t\t\t\t\t\tstate = int(lines[i].replace(""\\n"", """"))\n\t\t\t\t\t\tcurrent = 0\n\n\t\t\t\t\t\tvar = self._aiblocks_parseVal(val, type)\n\t\t\t\t\t\tself._aiblocks_vars_cache[name] = var\n\n\t\t\t\t\t\tif param_name==name:\n\t\t\t\t\t\t\treturn true\n\t\t\t\t\t\t\tfound = True\n\t\t\t\tif not found:\n\t\t\t\t\tif self._aiblocks_vars_cache.__contains__(param_name):\n\t\t\t\t\t\treturn self._aiblocks_vars_cache[param_name]\n\t\t\t\t\telse:\n\t\t\t\t\t\traise Exception(""Input was not found: ""+param_name)\n\t\t\texcept:\n\t\t\t\tLogErr(""Warning: Inputs were not found for object: ""+str(self.id))\n\t\t\t\treturn getattr(self, param_name)\n\n\tdef GetDynamicValue(self, param_name):\n\t\tif EDITOR_MODE:\n\t\t\ttry:\n\t\t\t\ttmpDir = _aiblocks_default_tmp_folder+""\\\\variables_""+str(self.id)\n\t\t\t\tfile = open(tmpDir,""r"") \n\t\t\t\tlines = file.readlines()\n\n\t\t\t\tname = None\n\t\t\t\ttype = None\n\t\t\t\tval = None\n\t\t\t\t\n\t\t\t\tfound = False\n\t\t\t\tcurrent = 0\n\t\t\t\tfor i in range(len(lines)):\n\t\t\t\t\tif current==0:\n\t\t\t\t\t\tname = lines[i].replace(""\\n"", """")\n\t\t\t\t\t\tcurrent = 1\n\t\t\t\t\telif current==1:\n\t\t\t\t\t\ttype = lines[i].replace(""\\n"", """")\n\t\t\t\t\t\tcurrent = 2\n\t\t\t\t\telse:\n\t\t\t\t\t\tval = lines[i].replace(""\\n"", """")\n\t\t\t\t\t\tcurrent = 0\n\n\t\t\t\t\t\tvar = self._aiblocks_parseVal(val, type)\n\t\t\t\t\t\tself._aiblocks_vars_cache[name] = var\n\n\t\t\t\t\t\tif param_name==name:\n\t\t\t\t\t\t\treturn var\n\t\t\t\t\t\t\tfound = True\n\t\t\t\tif not found:\n\t\t\t\t\tif self._aiblocks_vars_cache.__contains__(param_name):\n\t\t\t\t\t\treturn self._aiblocks_vars_cache[param_name]\n\t\t\t\t\telse:\n\t\t\t\t\t\traise Exception(""Dynamic editor variable was not found: ""+param_name)\n\t\t\texcept:\n\t\t\t\tLogErr(""Warning: Dynamic vars were not found for object: ""+str(self.id))\n\t\t\t\treturn getattr(self, param_name)\n\n\t\telse:\n\t\t\treturn getattr(self, param_name)\n\n\n\tdef _aiblocks_parseVal(self, val, type):\n\t\tif(type==""int""):\n\t\t\treturn int(val)\n\t\telif(type==""float""):\n\t\t\treturn float(val)\n\t\telif(type==""array""):\n\t\t\treturn eval(val)\n\t\telse:\n\t\t\treturn val\n\t\t'"
Sources/scripts/CIFAR10_loader.py,0,"b'import random as rand\nimport numpy as np\nimport pickle\nfrom random import randrange\n#description Input loader from the CIFAR 10 dataset\n#type data source\n#icon fa fa-file-image-o\n\n#param folder\npath=""""\n#param int\nbatch_size = 100\n#param list:Grayscale,RGB\nimage_format=""Grayscale""\n#param bool\none_pixel=False\n\n\nself.fileID=0\nself.format = self.image_format\nself.IMG_SIZE = 1024\nself.limiter = self.IMG_SIZE\nself.LABELS_COUNT = 10\nself.IMAGES_PER_FILE = 10000\nself.FILES_AMOUNT = 5\nself.data = []\nself.testData = {}\nself.input_size = self.IMG_SIZE\nself.labels_size = self.LABELS_COUNT\nself.image_size = [32, 32]\n\nLog(""Loading CIFAR 10 data..."")\nSetState(self.id, 0.01)\nself.loadAllFiles(self.path+""/"")\n\ndef loadAllFiles(self, path):\n\tLog(""Loading files..."")\n\n\tif self.FILES_AMOUNT<=1:\n\t\tself.loadFile(path+""train"", False)\n\t\tself.loadFile(path+""test"", True)\n\telse:\n\t\tfor i in range(self.FILES_AMOUNT):\n\t\t\tfile_name = path+""data_batch_""+str(i+1)\n\t\t\tself.loadFile(file_name)\n\t\t\tSetState(self.id, i/self.FILES_AMOUNT)\n\n\t\tfile_name = path+""test_batch""\n\t\tself.loadFile(path+""test_batch"", True)\n\ndef loadFile(self, file, isTest=False):\n\tfo = open(file, \'rb\')\n\tu = pickle._Unpickler(fo)\n\tu.encoding = \'latin1\'\n\tdict = u.load()\n\tfo.close()\n\tdict[""training_state""] = 0\n\n\tLog(""Loaded: ""+file)\n\n\tif isTest==False:\n\t\tself.data.append(dict)\n\telse:\n\t\tself.testData = dict\n\ndef getNextBatch(self):\n\tamount = self.batch_size\n\timagesData = []\n\tlabels = []\n\tflipped = []\n\n\tfor i in range(amount):\n\t\tfileID = 0\n\t\timgID = 0\n\t\t\n\t\tif self.FILES_AMOUNT<=1:\n\t\t\tfileID = 1\n\t\telse:\n\t\t\tfileID = randrange(1, self.FILES_AMOUNT)\n\t\t\n\t\timgID = randrange(0, self.IMAGES_PER_FILE-1)\n\t\t\n\t\timgObj = self.loadOneImage(imgID, fileID)\n\t\timagesData.append(imgObj[""image""])\n\t\tlabels.append(imgObj[""label""])\n\t\tflipped.append(imgObj[""flipped""])\n\n\treturn [imagesData, labels, flipped]\n\ndef getTestBatch(self):\n\tamount = self.batch_size\n\timagesData = []\n\tlabels = []\n\n\tfor i in range(amount):\n\t\timgID = randrange(0, amount)\n\t\t\n\t\timgObj = self.loadOneTestImage(imgID)\n\t\timagesData.append(imgObj[""image""])\n\t\tlabels.append(imgObj[""label""])\n\n\treturn [imagesData, labels]\n\ndef getImageData(self, index, fileID=0):\n\treturn self.data[fileID][""data""][index]\n\ndef loadOneTestImage(self, index):\n\t_image = []\n\t_label = None\n\n\tif self.one_pixel:\n\t\tif self.format==""Grayscale"":\n\t\t\t raise Exception(""Grayscale for generation not implemented"")\n\t\t\n\t\tfor byte in range(self.IMG_SIZE*3-1):\n\t\t\t\tpixel = self.testData[""data""][index][byte]\n\t\t\t\t_image.append(pixel/255)\n\t\t\t\t\n\t\t_label = [0]*256\n\t\t_label[self.testData[""labels""][index]] = 1\n\telse:\n\t\tif self.format==""Grayscale"":\n\t\t\tfor byte in range(self.IMG_SIZE):\n\t\t\t\tpixel = (self.testData[""data""][index][byte]+self.testData[""data""][index][self.IMG_SIZE+byte]+self.testData[""data""][index][self.IMG_SIZE*2+byte])/3\n\t\t\t\t_image.append(pixel/255)\n\t\telse:\n\t\t\tfor byte in range(self.IMG_SIZE*3):\n\t\t\t\tpixel = self.testData[""data""][index][byte]\n\t\t\t\t_image.append(pixel/255)\n\t\t\t\t\n\t\t_label = [0]*10\n\t\t_label[self.testData[""labels""][index]] = 1\n\t\t\n\treturn {""image"":_image, ""label"":_label}\n\ndef loadOneImage(self, index, fileID=0):\n\t_image = []\n\n\tflipped=rand.choice([0, 2]);\n\tstaturation = 0#rand.uniform(-10.0, 10.0)\n\n\tif self.format==""Grayscale"":\n\t\tfor byte in range(self.IMG_SIZE):\n\t\t\tif flipped:\n\t\t\t\tpixel = (self.data[fileID][""data""][index][self.IMG_SIZE-byte-1]+self.data[fileID][""data""][index][self.IMG_SIZE+byte]+self.data[fileID][""data""][index][self.IMG_SIZE*3-byte-1])/3\n\t\t\telse:\n\t\t\t\tpixel = (self.data[fileID][""data""][index][byte]+self.data[fileID][""data""][index][self.IMG_SIZE+byte]+self.data[fileID][""data""][index][self.IMG_SIZE*2+byte])/3\n\t\t\t_image.append(max(0, min(255, pixel+staturation))/255)\n\telse:\n\t\tfor byte in range(self.IMG_SIZE*3):\n\t\t\tif flipped==1:\n\t\t\t\tpixel = (self.data[fileID][""data""][index][self.IMG_SIZE-byte-1])\n\t\t\telif flipped==2:\n\t\t\t\tcolor_channel = int(byte/(32*32))*32*32\n\t\t\t\tlocal = byte-color_channel\n\t\t\t\tx = 32-local%32-1\n\t\t\t\ty = 32-int(local/32)\n\t\t\t\tpixel = (self.data[fileID][""data""][index][color_channel+local])\n\t\t\telse:\n\t\t\t\tpixel = self.data[fileID][""data""][index][byte]\n\t\t\t_image.append((pixel+staturation)/255)\n\n\t_label = [0]*10\n\t_label[self.data[fileID][""labels""][index]] = 1\n\t\n\treturn {""image"":_image, ""label"":_label, ""flipped"": flipped}\n\ndef getImageBytes(self):\n\tif self.format==""Grayscale"":\n\t\treturn self.IMG_SIZE\n\telse:\n\t\treturn self.IMG_SIZE*3\n\t\ndef getImageWidth(self):\n\tif self.format==""Grayscale"":\n\t\treturn int(np.sqrt(self.IMG_SIZE))\n\telse:\n\t\treturn int(np.sqrt(self.IMG_SIZE*3))\n\ndef getImagesCount(self):\n\treturn self.IMAGES_PER_FILE*self.FILES_AMOUNT\n\ndef getTrainedCount(self):\n\tcount = 0\n\tfor i in range(self.FILES_AMOUNT):\n\t\tcount+= self.data[i][""training_state""]\n\treturn count\n\t\ndef rangeFactor(t, point, _range):\n\tratio = np.abs (point - t) / _range;\n\tif ratio < 1:\n\t\treturn 1 - ratio;\n\telse:\n\t\treturn 0;'"
Sources/scripts/MINST_loader.py,0,"b'import random as rand\nfrom tensorflow.examples.tutorials.mnist import input_data as minst_input_data\n#description Input loader from the MNIST dataset\n#type data source\n#icon fa fa-sort-numeric-asc\n\n#param int\nbatch_size = 100\nself.path = """"\n\nself.input_size = 784\nself.labels_size = 10\nself.image_size = [28, 28]\n\nLog(""Loading minst data..."")\nSetState(self.id, 0.25)\nself.mnist = minst_input_data.read_data_sets(self.path, one_hot=True)\nSendImageData(self.id, self.mnist.test.images[rand.randint(0, len(self.mnist.test.images))], self.image_size[0], self.image_size[1])\nSetState(self.id, 1)\n\ndef getNextBatch(self):\n    batch_x, batch_y = self.mnist.train.next_batch(self.batch_size)\n    return [batch_x, batch_y]\n\ndef getTestBatch(self):\n    return [self.mnist.test.images[:self.batch_size], self.mnist.test.labels[:self.batch_size]]\n'"
Sources/scripts/MNIST_loader.py,0,"b'import random as rand\nfrom tensorflow.examples.tutorials.mnist import input_data as minst_input_data\n#description Input loader from the MNIST dataset\n#type data source\n#icon fa fa-sort-numeric-asc\n\n#param int\nbatch_size = 100\nself.path = """"\n\nself.input_size = 784\nself.labels_size = 10\nself.image_size = [28, 28]\n\nLog(""Loading minst data..."")\nSetState(self.id, 0.25)\nself.mnist = minst_input_data.read_data_sets(self.path, one_hot=True)\nSendImageData(self.id, self.mnist.test.images[rand.randint(0, len(self.mnist.test.images))], self.image_size[0], self.image_size[1])\nSetState(self.id, 1)\n\ndef getNextBatch(self):\n    batch_x, batch_y = self.mnist.train.next_batch(self.batch_size)\n    return [batch_x, batch_y]\n\ndef getTestBatch(self):\n    return [self.mnist.test.images[:self.batch_size], self.mnist.test.labels[:self.batch_size]]\n'"
Sources/scripts/audio_player.py,0,"b'#description Empty script template\n#icon glyphicon glyphicon-volume-up\n\n#param object\n_input = None\n#param string\nfilter = """"'"
Sources/scripts/auto_encoder.py,6,"b'#description An auto-encoder trainer\n#icon glyphicon glyphicon-random\n#MAIN=Run\n\n#param list:Training,Encoding,Decoding\nmode = ""Training""\n\n#param object\n_input = None\n#param object\nEncoder = None\n#param object\nDecoder = None\n\n#param float\nlearning_rate = 0.0001\n#param int\ntraining_iterations = 3000\t\n#param int\ndisplay_step = 100\n#param folder\nsave_path = """"\n#param list:Adam\nsolver = ""Adam""\n#param bool\npreview = False\n\ndef Run(self, graph=None):\n\tif self.mode==""Training"":\n\t\tself.Train()\n\telif self.mode==""Encoding"":\n\t\tself.Encode()\n\telse:\n\t\tself.Decode()\n\ndef Train(self):\n\tself.X = tf.placeholder(tf.float32, shape=[None, self._input.input_size], name=""x_input"")\t\t\n\t\t\n\tz = self.Encoder.Run(self.X)\n\tfakeX = self.Decoder.Run(z)\n\t\n\tAE_loss = tf.reduce_mean(tf.pow(fakeX-self.X, 2))\n\tAE_solver = tf.train.AdamOptimizer(self.learning_rate).minimize(AE_loss)\n\t\n\t# Initializing the variables\n\tinit = tf.global_variables_initializer()\n\t\n\t# \'Saver\' op to save and restore all the variables\n\tsaver = tf.train.Saver()\n\n\t# Launch the graph\n\twith tf.Session() as sess:\n\t\tsess.run(init)\n\t\t\n\t\tif len(self.save_path)>0 and os.path.exists(self.save_path+""/model.meta""):\n\t\t\t# Restore model weights from previously saved model\n\t\t\tload_path=saver.restore(sess, self.save_path+""/model"")\n\t\t\tprint (""Model restored from file: %s"" % self.save_path)  \n\t\t\t\n\t\tacc_log = []\n\t\t\t\n\t\tfor it in range(self.training_iterations):\n\t\t\tbatch = self._input.getNextBatch()\n\t\t\t\t\n\t\t\tX_batch  = batch[0]\n\t\t\t\n\t\t\t_, loss = sess.run([AE_solver, AE_loss], feed_dict={self.X: X_batch})\n\t\t\t\t\t\n\t\t\tif it % self.display_step == 0:\n\t\t\t\tSetState(self.id, it/self.training_iterations)\n\t\t\t\tSendChartData(self.id, ""Loss"", loss, ""#ff0000"")\n\t\t\tif it % self.display_step*10 == 0:\n\t\t\t\ttest_X = [X_batch[0]]\n\t\t\t\trebuilt_image = sess.run(fakeX, feed_dict = {self.X: test_X})[0]\n\t\t\t\tSendImageData(self.id, test_X[0], self._input.image_size[0], self._input.image_size[1], ""original"")\n\t\t\t\tSendImageData(self.id, rebuilt_image, self._input.image_size[0], self._input.image_size[1], ""fake"")\n\n\t\tif len(self.save_path)>0:\n\t\t\t# Save model weights to disk\n\t\t\ts_path = saver.save(sess, self.save_path+""/model"")\n\t\t\tprint (""Model saved in file: %s"" % s_path)'"
Sources/scripts/chart.py,0,"b'#description A chart that displays data\n#icon fa fa-area-chart\n\n#param object\n_input = None\n#param list:line,pie,doughnut,\ntype = ""line""\n#param string\nfilter = """"\n#param int\nlimit = 999'"
Sources/scripts/classifier.py,6,"b'import time\nimport tensorflow as tf\nimport os\n\n#description Train your model on classifing things!\n#icon fa fa-magic\n#MAIN=Run\n\n#param object\n_input = None\n#param object\n_model = None\n#param float\nlearning_rate = 0.0001\n#param int\ntraining_iterations = 3000\t\n#param int\ndisplay_step = 100\n#param list:Adam\nmethod = ""Adam""\n#param folder\nsave_path = """"\n\ndef Run(self):\n\n\t#defining the model...\n\tself.X = tf.placeholder(tf.float32, shape=[None, self._input.input_size], name=""x_input"")        \n\tself.y = tf.placeholder(tf.float32, shape=[None, self._input.labels_size], name=""y_labels"")\n   \t\n\t_y = self._model.Run(self.X)\n\t_loss = tf.reduce_mean(tf.pow(_y-self.y, 2))\n\n\tcorrect_pred = tf.equal(tf.argmax(_y, 1), tf.argmax(self.y, 1))\n\t_accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\t\n\t_solver = tf.train.AdamOptimizer(self.learning_rate).minimize(_loss)\n\t\n\tinstance = AIBlocks.InitModel(load_path=self.save_path)\n\tLog(""Model initialized!"")\n\t\n\tSetState(self.id, 0.001)\n        \n\tfor it in range(self.training_iterations):\n\t\tbatch = self._input.getNextBatch()\n            \n\t\tX_batch  = batch[0]\n\t\tY_batch  = batch[1]\n        \n\t\t_, loss, acc = instance.Run([_solver, _loss, _accuracy], feed_dict={self.X: X_batch, self.y: Y_batch})\n\n\t\tif it % self.display_step == 0:\n\t\t\tSetState(self.id, it/self.training_iterations)\n\t\t\tSendChartData(self.id, ""Loss"", loss, ""#ff0000"")\n\t\t\tSendChartData(self.id, ""Accuracy"", acc)\n        \n\tAIBlocks.SaveModel(instance)\n\tAIBlocks.CloseSession(instance)\n\n'"
Sources/scripts/convolutions.py,9,"b'#description An 2D convolutional layer\n#icon fa fa-sitemap\n#param list:conv2d,deconv2d,maxpool2d\ntype = ""conv2d""\n#zone type==conv2d\n#param array|int\nshape = [5, 5, 1, 32]\n#param int\nstrides = 1\n#endzone\n\n#zone type==maxpool2d\n#param int\nk = 2\n#endzone\n\nself.variables = []\n\ndef Run(self, batch_input, reuse=False):\n\t\n\tif self.type==""conv2d"":\n\t\tW = tf.Variable(tf.random_normal(self.shape))\n\t\tb = tf.Variable(tf.random_normal([self.shape[3]]))\n\n\t\tself.variables.append(W)\n\t\tself.variables.append(b)\n\t\t\n\t\tx =  self.conv2d(batch_input, W, b, strides=self.strides, name=self.name)\n\t\tLog(self.name+"" ""+str(x.get_shape()))\n\t\treturn x\n\telif self.type==""maxpool2d"":\n\t\tx = self.maxpool2d(batch_input, k=self.k, name=self.name)\n\t\tLog(self.name+"" ""+str(x.get_shape()))\n\t\treturn x\n\telse:\n\t\tstride = self.strides\n\t\tout_channels = self.out_channels\n\t\twith tf.variable_scope(self.name):\n\t\t\tbatch, in_height, in_width, in_channels = [int(d) for d in batch_input.get_shape()]\n\t\t\tfilter = tf.get_variable(""filter"", [4, 4, out_channels, in_channels], dtype=tf.float32, initializer=tf.random_normal_initializer(0, 0.02))\n\t\t\t# [batch, in_height, in_width, in_channels], [filter_width, filter_height, out_channels, in_channels]\n\t\t\t#\t => [batch, out_height, out_width, out_channels]\n\t\t\tconv = tf.nn.conv2d_transpose(batch_input, filter, [batch, in_height * 2, in_width * 2, out_channels], [1, 2, 2, 1], padding=""SAME"")\n\t\t\treturn conv\n\ndef conv2d(self, x, W, b, strides=1, name=""""):\n\t# Conv2D wrapper, with bias and relu activation\n\tx = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding=\'SAME\', name=name)\n\tx = tf.nn.bias_add(x, b)\n\treturn tf.nn.relu(x)\n\ndef maxpool2d(self, x, k=2, name=""""):\n\t# MaxPool2D wrapper\n\treturn tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=\'SAME\', name=name)'"
Sources/scripts/cpu_neural_network.py,0,"b'import numpy as np\nimport random as rand\n#description Empty script template\n#icon fa fa-flask\n\n#param array|int\nhidden_units = []\n\nself.weights = []\nself.biais = []\n\nself.init()\n\ndef init(self):\n    for u in range(len(self.hidden_units)-1):  \n        i = u+1\n\n        w0 = []\n        for j in range(self.hidden_units[i-1]):\n            w0.append(rand.uniform(0, 1))\n        \n        w1 = []\n        for j in range(self.hidden_units[i]):\n            w1.append(rand.uniform(0, 1))\n\n        b = []\n        for j in range(self.hidden_units[i]):\n            b.append(rand.uniform(0, 1))\n\n        self.weights.append([w0, w1])\n        self.biais.append(b)\n        Log(""[""+str(self.hidden_units[i-1])+""] => [""+str(self.hidden_units[i])+""]"")\n\ndef Run(self, h):\n    for i in range(len(self.weights)):\n        h = self.add(self.matmul(h, self.weights[i]), self.biais[i])\n    return h\n\ndef add(self, x, b):\n    if(len(x)!=len(b)):\n        raise Exception(""different array size: [""+str(len(x))+""] [""+str(len(b))+""]"")\n    val = []\n    for i in range(len(x)):\n        val.append(x[i]+b[i])\n    return val\n    \ndef matmul(self, x, w):\n    if(len(x)!=len(w[0])):\n        raise Exception(""different array size: [""+str(len(x))+""] [""+str(len(w[0]))+""]"")\n    else:\n        _sum = 0\n        for i in range(len(x)):\n            _sum+=(x[i]*w[0][i])\n        \n        _sum = self.sigmoid(_sum)\n\n        output = []\n        for i in range(len(w[1])):\n            output.append(self.sigmoid(_sum*w[1][i]))\n        return output\n\ndef sigmoid(self, x):\n    return 1/(1+np.exp(-x))\n\ndef relu(self, x):\n    return max(0.000001, x)\n\ndef getValues(self):\n\treturn [self.weights, self.biais]\n\ndef setValues(self, values):\n    self.weights = values[0]\n    self.biais = values[1]'"
Sources/scripts/csv_loader.py,0,"b'#description CSV data loader\n#type data source\n#icon fa fa-file-excel-o\n\n#param file\nfile_path = """"\n#param string\nseparator=\';\'\n#param int\nstartLine = 1\n#param array|int\ndata_columns = [0]\n#param array|int\nlabels_columns = [1, 2]\n\nself.input_size = len(data_columns)\nself.labels_size = len(labels_columns)\n\ntext_file = open(fileName, ""r"")\ndata = text_file.read()\n\nlines = data.split(\'\\n\')\n\nself.X = []\nself.Y = []\n\ni = 0\nwhile i<len(lines):\n\tline = lines[i]\n\tcolumns = line.split(separator)\n\t\n\t_input = []\n\tlabel = []\n\n\tfor _x in self.data_columns:\n\t\t_input.append(float(columns[_x]))\n\tfor _y in self.labels_columns:\n\t\tlabel.append(float(columns[_y]))\n\t\n\tself.X.append(_input)\n\tself.Y.append(label)\n\n\ti+=1\n\ndef getNextBatch(self):\n\tx = []\n\ty = []\n\tfor i in range(self.batch_size):\n\t\tindex = self.getRandomIndex()\n\t\tx.append(self.X[index])\n\t\ty.append(self.Y[index])\n\n\treturn [x, y]\n\ndef getTestBatch(self):\n\treturn self.getNextBatch()\n\ndef getRandomIndex(self):\n\trand_start = rand.uniform(0, 1)\n\treturn min(int(len(self.X)*rand_start), len(self.X)-1)'"
Sources/scripts/function.py,14,"b'import tensorflow as tf\n\n#description Activation functions: softmax, relu, tanh, sigmoid etc...\n#icon fa fa-flask\n\n#param list: sigmoid, tanh, softmax, relu, batchnorm, lrelu, reshape\nfunction = ""sigmoid""\n#zone function==lrelu\n#param float\na = 1\n#endzone\n\n#zone function==reshape\n#param array|eval\nshape = [-1, 100]\n#endzone\n\n\ndef Run(self, x, reuse=False):\n\tLog(self.function)\n\n\tif self.function==""sigmoid"":\n\t\treturn tf.nn.sigmoid(x)\n\telif self.function==""tanh"":\n\t\treturn tf.nn.tanh(x)\n\telif self.function==""softmax"":\n\t\treturn tf.nn.softmax(x)\n\telif self.function==""batchnorm"":\n\t\treturn self.batchnorm(x)\n\telif self.function==""lrelu"":\n\t\treturn self.lrelu(x)\n\telif self.function==""reshape"":\n\t\treturn tf.reshape(x, self.shape)\n\telse:\n\t\treturn tf.nn.relu(x)\n\ndef batchnorm(input):\n\twith tf.variable_scope(self.name):\n\t\t# this block looks like it has 3 inputs on the graph unless we do this\n\t\tinput = tf.identity(input)\n\n\t\tchannels = input.get_shape()[3]\n\t\toffset = tf.get_variable(""offset"", [channels], dtype=tf.float32, initializer=tf.zeros_initializer())\n\t\tscale = tf.get_variable(""scale"", [channels], dtype=tf.float32, initializer=tf.random_normal_initializer(1.0, 0.02))\n\t\tmean, variance = tf.nn.moments(input, axes=[0, 1, 2], keep_dims=False)\n\t\tvariance_epsilon = 1e-5\n\t\tnormalized = tf.nn.batch_normalization(input, mean, variance, offset, scale, variance_epsilon=variance_epsilon)\n\t\treturn normalized\n\ndef lrelu(x):\n\ta = self.a\n\twith tf.name_scope(self.name):\n\t\t# adding these together creates the leak part and linear part\n\t\t# then cancels them out by subtracting/adding an absolute value term\n\t\t# leak: a*x/2 - a*abs(x)/2\n\t\t# linear: x/2 + abs(x)/2\n\n\t\t# this block looks like it has 2 inputs on the graph unless we do this\n\t\tx = tf.identity(x)\n\treturn (0.5 * (1 + a)) * x + (0.5 * (1 - a)) * tf.abs(x)'"
Sources/scripts/gan.py,7,"b'import random as rand\n\n#description Generative Adverserial Networks trainer\n#icon fa fa-retweet\n#MAIN=Run\n\n#param object\n_input = None\n#param object\nGenerator = None\n#param object\nDiscriminator = None\n#param int\nlatent_size = 10\n\n#param float\nlearning_rate = 0.0001\n#param int\ntraining_iterations = 3000\t\n#param int\ndisplay_step = 100\n#param folder\nsave_path = """"\n#param list:None,Image,Sound,Text,3D Model\npreview = ""None""\n#param int\npreview_state = 0\n\ndef Run(self):\n\tself.X = tf.placeholder(tf.float32, shape=[None, self._input.input_size], name=""x_input"")\t\n\tself.Z = tf.placeholder(tf.float32, shape=[None, self.latent_size], name=""z_input"")\t\t\n\n\tfakeX = self.Generator.Run(self.Z)\n\t\n\tD_real = self.Discriminator.Run(self.X)\n\tD_fake = self.Discriminator.Run(fakeX)\n\n\n\tD_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real, labels=tf.ones_like(D_real)))\n\tD_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake, labels=tf.zeros_like(D_fake)))\n\tD_loss = D_loss_real + D_loss_fake\n\tG_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake, labels=tf.ones_like(D_fake)))\n\n\tD_solver = tf.train.AdamOptimizer(self.learning_rate).minimize(D_loss, var_list=self.Discriminator.getVariables())\n\tG_solver = tf.train.AdamOptimizer(self.learning_rate).minimize(G_loss, var_list=self.Generator.getVariables())\n\t\n\t#initialize everything\n\tinstance = AIBlocks.InitModel(load_path=self.save_path)\n\tLog(""Model initialized!"")\n\t\t\t\n\tacc_logd = []\n\tacc_logg = []\n\t\n\tresetRand = 0\n\ttest_Z = np.random.uniform(-1., 1., size=[self.latent_size])\n\ttargetRand = np.random.uniform(-1., 1., size=[self.latent_size])\n\n\tfor it in range(self.training_iterations):\n\t\tbatch = self._input.getNextBatch()\n\t\t\t\n\t\tX_batch  = batch[0]\n\t\tZ_batch = np.random.rand(self._input.batch_size, self.latent_size)\n\n\t\t_, _, d_loss, g_loss = instance.Run([D_solver, G_solver, D_loss, G_loss], feed_dict={self.X: X_batch, self.Z: Z_batch})\n\t\t\t\n\t\tacc_logd.append(d_loss)\n\t\tacc_logg.append(g_loss)\n\n\t\tif it % self.display_step == 0:\n\t\t\tSetState(self.id, it/self.training_iterations)\n\t\t\tSendChartData(self.id, ""D Loss"", d_loss, ""#ff0000"")\n\t\t\tSendChartData(self.id, ""G Loss"", g_loss, ""#00ff00"")\n\t\t\t#SendGraph(self.id, acc_logd[-1000:], data2=acc_logg[-1000:], name=""Loss"")\n\n\t\tif self.preview!=""None"":\n\t\t\tMath.LerpVec(test_Z, targetRand, 0.1)\n\t\t\timagined = instance.Run(fakeX, feed_dict = {self.Z: [test_Z]})[0]\n\n\t\t\tif(resetRand>10):\n\t\t\t\ttargetRand = np.random.uniform(-1., 1., size=[self.latent_size])\n\t\t\t\tresetRand = 0\n\n\t\t\tresetRand += 1\n\n\t\t\tif self.preview==""Image"":\n\t\t\t\tSendImageData(self.id, imagined, self._input.image_size[0], self._input.image_size[1], ""1"")\n\t\t\telse:\n\t\t\t\tpass\n\n\tAIBlocks.SaveModel(instance)\n\tAIBlocks.CloseInstance(instance)'"
Sources/scripts/gan_tester.py,2,"b'import random as rand\nimport time\n\n#description Generative Adverserial Networks trainer\n#icon fa fa-retweet\n#MAIN=Run\n\n#param object\n_input = None\n#param object\nGenerator = None\n#param object\nDiscriminator = None\n#param int\nlatent_size = 10\n#param folder\nsave_path = """"\n#param list: Image,Sound,Text,3D Model,Raw\npreview = ""Image""\n#editor param float\n#preview_state = 0.5\n\ndef Run(self):\n\tself.X = tf.placeholder(tf.float32, shape=[None, self._input.input_size], name=""x_input"")\t\n\tself.Z = tf.placeholder(tf.float32, shape=[None, self.latent_size], name=""z_input"")\t\t\n\n\tfakeX = self.Generator.Run(self.Z)\n\t\n\t#initialize everything\n\tinstance = AIBlocks.InitModel(load_path=self.save_path)\n\tLog(""Model initialized!"")\n\t\t\t\n\tacc_log = []\n\n\tresetRand = 0\n\ttest_Z = np.random.uniform(-1., 1., size=[self.latent_size])\n\ttest_Z1 = np.random.uniform(-1., 1., size=[self.latent_size])\n\ttest_Z2 = np.random.uniform(-1., 1., size=[self.latent_size])\n\ttargetRand = np.random.uniform(-1., 1., size=[self.latent_size])\n\ttargetRand1 = np.random.uniform(-1., 1., size=[self.latent_size])\n\ttargetRand2 = np.random.uniform(-1., 1., size=[self.latent_size])\n\t\n\twhile 1:\n\t\tMath.LerpVec(test_Z, targetRand, 0.1)\n\t\tMath.LerpVec(test_Z1, targetRand1, 0.1)\n\t\tMath.LerpVec(test_Z2, targetRand2, 0.1)\n\n\t\tif(resetRand>10):\n\t\t\ttargetRand = np.random.uniform(-1., 1., size=[self.latent_size])\n\t\t\ttargetRand1 = np.random.uniform(-1., 1., size=[self.latent_size])\n\t\t\ttargetRand2 = np.random.uniform(-1., 1., size=[self.latent_size])\n\t\t\tresetRand = 0\n\n\t\tresetRand += 1\n\t\t\n\t\timagined = instance.Run(fakeX, feed_dict = {self.Z: [test_Z]})[0]\n\t\timagined1 = instance.Run(fakeX, feed_dict = {self.Z: [test_Z1]})[0]\n\t\timagined2 = instance.Run(fakeX, feed_dict = {self.Z: [test_Z2]})[0]\n\n\t\tif self.preview==""Image"":\n\t\t\tSendImageData(self.id, imagined, self._input.image_size[0], self._input.image_size[1], ""1"")\n\t\t\tSendImageData(self.id, imagined1, self._input.image_size[0], self._input.image_size[1], ""2"")\n\t\t\tSendImageData(self.id, imagined2, self._input.image_size[0], self._input.image_size[1], ""3"")\n\t\telif self.preview==""Sound"":\n\t\t\tpass\n\t\telse:\n\t\t\tpass\n\n\t\ttime.sleep(0.01)\n\n\tAIBlocks.SaveModel(instance)\n\tAIBlocks.CloseInstance(instance)'"
Sources/scripts/graph.py,0,"b'#description Create your own custom model\n#icon fa fa-cubes\n\n#param array|object\nmodel_elements = []\n\ndef Run(self, graph, reuse=False):\n\tfor e in range(len(self.model_elements)):\n\t\tgraph = self.model_elements[e].Run(graph, reuse=reuse)\n\treturn graph\n\ndef GetChild(self, i):\n\treturn self.model_elements[i]\n\ndef GetAllWeightsCount(self):\n\tsum = 0\n\tfor i in range(len(self.model_elements)):\n\t\tobj = self.model_elements[i]\n\t\tif hasattr(obj, \'total_weights\'):\n\t\t\tsum+=obj.total_weights\n\n\treturn sum\n\ndef getVariables(self):\n\tvariables = []\n\tfor i in range(len(self.model_elements)):\n\t\tobj = self.model_elements[i]\n\t\tif hasattr(obj, \'variables\'):\n\t\t\tvariables+=obj.variables\n\n\treturn variables\n\ndef getInputSize(self):\n\tif hasattr(model_elements[0], \'hidden_units\'):\n\t\treturn model_elements[0].hidden_units[0]\n\telse:\n\t\tLogErr(""No hidden units found in graph: ""+str(self.id))\n\t\treturn None\n\ndef GetOutputSize(self):\n\tif hasattr(model_elements[len(model_elements)-1], \'hidden_units\'):\n\t\treturn model_elements[len(model_elements)-1].hidden_units[len(model_elements[len(model_elements)-1].hidden_units)-1]\n\telse:\n\t\tLogErr(""No hidden units found in graph: ""+str(self.id))\n\t\treturn None'"
Sources/scripts/image_viewer.py,0,"b'#description converts an input source into a 2D image\n#icon fa fa-eye\n\n#param object\n_input = null\n#param string\nfilter = """"'"
Sources/scripts/keras_optimizer.py,0,"b'import numpy as np\nfrom keras.models import load_model\nfrom keras import backend as K\n\n#description Keras Classifier script\n#icon fa fa-magic\n#MAIN=Run\n\n#param object\n_input = None\n#param object\nmodel = None\n#param int\nepochs = 1000\n#param int\ndisplay_step = 5\n#param list:raw tensor,image,sound,\n_type = ""raw tensor""\n#param folder\nsave_path = """"\n#param file\nload_file = """"\n#param float\nforce_lr = -1\n\ndef Run(self):\n    if self.load_file!="""":\n        _model = load_model(self.load_file)\n    else:\n        self.model.Run()\n        _model = self.model.instance\n\n    for it in range(self.epochs):\n        batch = self._input.getNextBatch()\n\n        X_batch  = np.asarray(batch[0])\n        Y_batch  = np.asarray(batch[1])\n        \n        X_batch = np.reshape(X_batch, [self._input.batch_size] + self.model.input_shape)\n        \n        if(self.force_lr>0):\n            K.set_value(_model.optimizer.lr, self.force_lr)  # set new lr\n\n        infos = _model.train_on_batch(X_batch, Y_batch)\n        SetState(self.id, it/self.epochs)\n\n\t\t#every N steps, send the state to the scene\n        if it % self.display_step == 0:\n            SendChartData(self.id, ""Loss"", infos[0], ""#ff0000"")\n            Log(""Loss: ""+str(infos[0]))\n            if self._type==""image"":\n                test_X = [X_batch[0]]\n                test_Y = [Y_batch[0]]\n                rebuilt_image = _model.predict(np.asarray(test_X))\n                rebuilt_image = np.reshape(rebuilt_image, [1, 1024])[0]\n                test_X = np.reshape(X_batch[0], [1, 1024])[0].tolist()\n                SendImageData(self.id, test_X, self._input.image_width, self._input.image_width, ""original"")\n                SendImageData(self.id, test_Y[0], self._input.image_width, self._input.image_width, ""depth"")\n                SendImageData(self.id, rebuilt_image, self._input.image_width, self._input.image_width, ""fake"")\n        \n    if(self.save_path):\n        _model.save(self.save_path+\'/model.h5\')  # creates a HDF5 file \'my_model.h5\'\n        \n'"
Sources/scripts/keras_predictor.py,0,"b'from keras.models import load_model\n\n#description Keras Predictot script\n#icon fa fa-magic\n#MAIN=Run\n\n#param object\n_input = None\n#param file\nmodel_path = """"\n#param bool\nloop = False\n#param bool \nmanual_refresh = False\n#param list:raw tensor,image,sound\n_type = ""raw tensor""\n#param array|int\nimage_shape = [32, 32, 1]\n\ndef Run(self):\n    \n    _model = load_model(self.model_path)\n\n    while(True):\n        _x = self._input.GetTestBatch()\n\n        x = None\n        if self._type==""image"":\n            x = np.reshape(_x, [len(_x)] + self.image_shape)\n\n        pred = _model.predict(x)[0]\n        \n        if self._type == ""raw tensor"":\n            Log(pred)\n        elif self._type == ""image"":\n            SendImageData(self.id, _x[0], self.image_shape[0], self.image_shape[1], ""original"", offset = 1)\n            SendImageData(self.id, pred, self.image_shape[0], self.image_shape[1], ""preview"")\n        elif self._type == ""sound"":\n            #todo: send sound data...\n            pass\n\n        if not self.loop:\n            break\n        else:\n            #wait for manual input:\n            if self.manual_refresh:\n                input(""Press enter to run next frame"")'"
Sources/scripts/keras_sequencial.py,0,"b'import keras\nimport json\nimport math\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\n#param array|eval\ninput_shape = [32, 32, 1]\n#param array|string\nmodel = []\n#param float\nlearning_rate = 0.0001\n#param float \ndecay = 1e-6\n#param list:mean_squared_error,mean_absolute_error,mean_absolute_percentage_error,mean_squared_logarithmic_error,squared_hinge,hinge,categorical_hinge,logcosh,huber_loss,categorical_crossentropy,sparse_categorical_crossentropy,binary_crossentropy,kullback_leibler_divergence,poisson,cosine_proximity\nloss = ""mean_squared_error""\n#param array|string\nmetrics = [""accuracy""]\n\n\ndef Run(self):\n    model = Sequential()\n    for i in range(len(self.model)):\n        layer = None\n\n        if i==0:\n            layer = self.ParseInput(self.model[i], True)\n        else:\n            layer = self.ParseInput(self.model[i])\n        Log(""layer_""+str(i)+"": ""+str(layer))\n        model.add(layer)\n\n    # initiate RMSprop optimizer\n    opt = keras.optimizers.RMSprop(learning_rate=self.learning_rate, decay=self.decay)\n\n    # Let\'s train the model using RMSprop\n    model.compile(loss=self.loss,\n                optimizer=opt,\n                metrics=self.metrics)\n\n    self.instance = model\n\ndef ParseInput(self, val, has_input=False):\n    args = val.split("":"")\n    typ = args[0]\n\n    if typ==""Activation"":\n        return Activation(args[1])\n    elif typ==""Dropout"":\n        return Dropout(float(args[1]))\n    elif typ==""Input"":\n        sh = []\n        for i in range(len(args)-1):\n            sh += int(args[i+1])\n        return Input(shape=sh)\n    elif typ==""Flatten"":\n        return Flatten()\n    elif typ==""MaxPooling2D"":\n        return MaxPooling2D(pool_size=(int(args[1]), int(args[2])))\n    elif typ==""MaxPooling1D"":\n        return MaxPooling1D(pool_size=(int(args[1])))\n\n    if has_input:\n        if typ==""Dense"":\n            return Dense(int(args[1]), input_dim=self.input_shape[0])\n        elif typ==""Conv2D"":\n            return Conv2D(int(args[1]), (int(args[2]), int(args[3])), padding=\'same\', input_shape=(self.input_shape[0], self.input_shape[1], self.input_shape[2]))\n        elif typ==""Conv1D"":\n            return Conv1D(int(args[1]), int(args[2]), input_shape=(self.input_shape[0],self.input_shape[1]))\n    else:\n        if typ==""Dense"":\n            return Dense(int(args[1]))\n        elif typ==""Conv2D"":\n            return Conv2D(int(args[1]), (int(args[2]), int(args[3])), padding=\'same\')\n        elif typ==""Conv1D"":\n            return Conv1D(int(args[1]), int(args[2]))\n        \n        \n'"
Sources/scripts/neural_network.py,8,"b'import tensorflow as tf\n\n#description A simple multi-layered perceptron\n#icon fa fa-code-fork\n\n#param bool\nuse_name = False\n\n#param array|eval\nhidden_units = [1024, 256, 10]\n\n#param bool\nuse_relu = True\n\nself.type = ""feedforward""\nself.name = self.name.replace("" "", ""_"")\nself.init()\n\ndef init(self):\n\tself.total_weights = 0\n\n\tself.variables = []\n\tfor u in range(len(self.hidden_units)-1):  \n\t\ti = u+1\n\t\tif self.use_name==False:\n\t\t\tW = tf.Variable(self.xavier_init([self.hidden_units[i-1], self.hidden_units[i]]))\n\t\t\tb = tf.Variable(tf.zeros(shape=[self.hidden_units[i]]))\n\t\telse:\n\t\t\tW = tf.Variable(self.xavier_init([self.hidden_units[i-1], self.hidden_units[i]]), name=self.name+""_W_""+str(u))\n\t\t\tb = tf.Variable(tf.zeros(shape=[self.hidden_units[i]]), name=self.name+""_W_""+str(u))\n\t\t\n\t\tself.total_weights+=self.hidden_units[i-1]+self.hidden_units[i]*2\n\t\tself.variables.append(W)\n\t\tself.variables.append(b)\n\ndef xavier_init(self, size):\n\tin_dim = size[0]\n\txavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n\treturn tf.random_normal(shape=size, stddev=xavier_stddev)\n\ndef Run(self, h, reuse=False):\n\tLog(""Running ""+self.name)\n\tfor i in range(int(len(self.variables)/2)):\n\t\tW=self.variables[i*2]\n\t\tb=self.variables[i*2+1]\n\t\th = tf.matmul(h, W) + b\n\t\tif i<len(self.variables)/2-1 and self.use_relu:\n\t\t\tLog(""relu on"")\n\t\t\th = tf.nn.relu(h)\n\t\telse:\n\t\t\tLog(""relu off"")\n\t\tLog(h.name+"" ""+str(h.get_shape()))\n\n\tLog(h.name+"" ""+str(h.get_shape()))\n\treturn h\n\ndef GetInputSize(self):\n\treturn self.hidden_units[0]\n\ndef GetOutputSize(self):\n\treturn self.hidden_units[len(self.hidden_units)-1]\n\ndef getVariables(self):\n\treturn self.variables'"
Sources/scripts/predictor.py,1,"b'import time\nimport tensorflow as tf\nimport os\n\n#description Train your model on classifing things!\n#icon fa fa-magic\n#MAIN=Run\n\n#param object\n_input = None\n#param object\n_model = None\n#param folder\nsave_path = """"\n\ndef Run(self):\n\n\t#defining the model...\n\tself.X = tf.placeholder(tf.float32, shape=[None, self._input.input_size], name=""x_input"")    \n\n\t_y = self._model.Run(self.X)\n\n\t\n\tinstance = AIBlocks.InitModel(load_path=self.save_path)\n\tLog(""Model initialized!"")\n\n\tbatch = self._input.getTestBatch()\n\tX_batch = batch[0]\n\tY_batch = batch[1]\n\t\n\tprediction = instance.Run(_y, feed_dict={self.X: X_batch})\n\n\tfound=0\n\tfailed=0\n\tfor i in range(len(prediction)):\n\t\tassert1 = self.max_index(Y_batch[i])\n\t\tassert2 = self.max_index(prediction[i])\n\n\t\ttmp = ""Found""\n\t\tcolor = ""#00ff00""\n\t\tif assert1!=assert2:\n\t\t\ttmp = ""Failed""\n\t\t\tcolor = ""#ff0000""\n\t\t\tfailed+=1\n\t\telse:\n\t\t\tfound+=1\n\n\t\tSendPieData(self.id, tmp, color);\t\t\n\t\tSetState(self.id, i/len(prediction))\n\t\ttime.sleep(0.1)\n\n\tLog(""Accuracy: ""+str(found/(failed+found)*100)+""%"")\n\n\tAIBlocks.CloseInstance(instance)\n\n\tSetState(self.id, 1)\n\ndef predict(self, input):\n\treturn sess.run(_y, feed_dict={self.X: input})\n\ndef max_index(self, data):\n\t_max = -10000000\n\tbest_index = 0\n\tfor i in range(len(data)):\n\t\tif(_max<data[i]):\n\t\t\t_max = data[i]\n\t\t\tbest_index = i\n\treturn best_index'"
Sources/scripts/rnn.py,22,"b'import tensorflow as tf\n\n#description Reccurent neural network implementations: LSTM, GRU\n#icon glyphicon glyphicon-link\n\n#param list:GRU, LSTM\ntype=""GRU""\n#param int\nn_classes = 2\n#param array|int\nhidden_units = [32]\n#param bool\nadvanced = False\n#zone advanced==True\n#param int\ndropout=0.75\n#param array|int\nreshape = [-1]\n#endzone\n\nself.name = self.name.replace("" "", ""_"")\n\nself.variables = []\n\ndef Run(self, graph, reuse=False):\n\tLog(graph.get_shape())\n\n\tif len(self.reshape)<=1:\n\t\tgraph = tf.reshape(graph, [-1, int(graph.get_shape()[1]), 1])\n\telse:\n\t\tgraph = tf.reshape(graph, self.reshape)\n\t\n\tif self.type==""GRU"":\n\t\tcells = []\n\t\tfor cell_n_hidden in self.hidden_units:\n\t\t\tt_cell = tf.nn.rnn_cell.GRUCell(cell_n_hidden)\n\t\t\tt_cell = tf.nn.rnn_cell.DropoutWrapper(t_cell, output_keep_prob=self.dropout)\n\t\t\tcells.append(t_cell)\n\t\tcell = tf.nn.rnn_cell.MultiRNNCell(cells)\n\t\t\t\n\t\twith tf.variable_scope(self.name, reuse=reuse):\n\t\t\tval, self.state = tf.nn.dynamic_rnn(cell, graph, dtype=tf.float32)\n\t\t\n\t\tval = tf.transpose(val, [1, 0, 2])\n\t\tlast = tf.gather(val, int(val.get_shape()[0]) - 1)\n\t\tself.weightV = tf.Variable(tf.truncated_normal([self.hidden_units[len(self.hidden_units)-1], self.n_classes]), name=self.name+""_W"")\n\t\tself.biasV = tf.Variable(tf.constant(0.1, shape=[self.n_classes]), name=self.name+""_b"")\n\t\tobj = tf.matmul(last, self.weightV) + self.biasV\n\n\t\tself.variables.append(self.weightV)\n\t\tself.variables.append(self.biasV)\n\n\t\tLog(self.name+"": ""+str(self.hidden_units)+"" => ""+str(obj.get_shape()))\n\n\t\treturn obj\n\telse:\n\t\tcells = []\n\t\tfor cell_n_hidden in self.hidden_units:\n\t\t\tt_cell = tf.nn.rnn_cell.LSTMCell(cell_n_hidden, state_is_tuple=True)\n\t\t\tt_cell = tf.nn.rnn_cell.DropoutWrapper(t_cell, output_keep_prob=self.dropout)\n\t\t\tcells.append(t_cell)\n\t\tcell = tf.nn.rnn_cell.MultiRNNCell(cells)\n\t\t\n\t\twith tf.variable_scope(self.name, reuse=reuse):\n\t\t  val, _ = tf.nn.dynamic_rnn(cell, graph, dtype=tf.float32)\n\n\t\tval = tf.transpose(val, [1, 0, 2])\n\t\tlast = tf.gather(val, int(val.get_shape()[0]) - 1)\n\t\tself.weightV = tf.Variable(tf.truncated_normal([self.hidden_units[len(self.hidden_units)-1], self.n_classes]), name=self.name+""_W"")\n\t\tself.biasV = tf.Variable(tf.constant(0.1, shape=[self.n_classes]), name=self.name+""_b"")\n\t\tobj = tf.matmul(last, self.weightV) + self.biasV\n\n\t\tself.variables.append(self.weightV)\n\t\tself.variables.append(self.biasV)\n\n\t\tLog(self.name+"": ""+str(self.hidden_units)+"" => ""+str(obj.get_shape()))\n\n\t\treturn obj\n\ndef getVariables(self):\n\treturn self.variables'"
Sources/scripts/socket_server.py,0,"b'#description Socket server\n#icon fa fa-plug\n\nimport socket\nimport _thread as thread\nfrom multiprocessing import Process, Lock, Manager, Value\nimport traceback\n\n#param string\nhost = ""127.0.0.1""\n#param int\nport = 15000\n#param object\nevent_listener = None\n#param bool\ndebug = False\n#param float\ntick_interval = 0.1\n#param eval\nbuffer_size = 1024*512\n\nlock = Lock()\nthread.start_new_thread(self.Init, (lock, None))\nif self.debug:\n\tLog (""Server Thread started, id: ""+str(self.id))\n\ndef Init(self, lock, tmp):\n\ttry:\n\t\tself.mySocket = socket.socket()\n\t\tself.mySocket.bind((self.host,self.port))\n\t\tself.mySocket.listen(1)\n\t\tconn, addr = self.mySocket.accept()\n\t\tself.conn = conn\n\t\tif self.debug:\n\t\t\tLog (""Connection from: "" + str(addr))\n\t\twhile True:\n\t\t\tdata = conn.recv(self.buffer_size).decode()\n\t\t\tif not data:\n\t\t\t\t\tbreak\n\t\t\tif self.debug:\n\t\t\t\tLog (""from connected  user: "" + str(data))\n\t\t\t\n\t\t\tdata = str(data)\n\t\t\tif self.event_listener:\n\t\t\t\tself.event_listener.onData(data)\n\t\t\telse:\n\t\t\t\tLog(""event_listener: ""+str(self.event_listener))\n\n\t\t\tif self.debug:\n\t\t\t\tLog (""recieved data: "" + str(data))\n\t\t\ttime.sleep(self.tick_interval)\n\t\t\t\t\n\t\tconn.close()\n\texcept Exception as e:\n\t\texc_type, exc_value, exc_traceback = sys.exc_info()\n\t\tLogErr (str(exc_type))\n\t\tLogErr (str(e))\n\n\t\ttrace = \'\'.join(traceback.format_tb(exc_traceback)).replace(""\\n"", """")\n\n\t\tLogErr (trace)\n\t\tLog (""Thread stopped: ""+str(self.id))\n\ndef Send(self, msg):\n\tif self.debug:\n\t\tLog (""sending: "" + str(msg))\n\tself.conn.send(msg.encode())'"
Sources/templates/classifier_template.py,6,"b'import time\nimport tensorflow as tf\nimport os\n\n#description Classifier script template\n#icon fa fa-magic\n#MAIN=Run\n\n#param object\n_input = None\n#param object\n_model = None\n#param float\nlearning_rate = 0.0001\n#param int\ntraining_iterations = 3000\t\n#param int\ndisplay_step = 100\n#param folder\nsave_path = """"\n\ndef Run(self):\n\n\t### defining the model: ###\n\n\t#inputs: \n\tself.X = tf.placeholder(tf.float32, shape=[None, self._input.input_size], name=""x_input"")        \n\tself.y = tf.placeholder(tf.float32, shape=[None, self._input.labels_size], name=""y_labels"")\n   \t\n    #\touput: \n\toutput = self._model.Run(self.X)\n\n\t#Loss function\n\t_loss = tf.reduce_mean(tf.pow(output-self.y, 2))\n\n\t#measure the accuracy\n\tcorrect_pred = tf.equal(tf.argmax(output, 1), tf.argmax(self.y, 1))\n\t_accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n\t#run the optimizer\n\t_solver = tf.train.AdamOptimizer(self.learning_rate).minimize(_loss)\n\n\t#initalize everything\n\tinstance = AIBlocks.InitModel(load_path=self.save_path)\n\tLog(""Model initialized!"")\n\n\t#set the progress bar state\n\tSetState(self.id, 0.001)\n        \n\tfor it in range(self.training_iterations):\n\t\tbatch = self._input.getNextBatch()\n            \n\t\tX_batch  = batch[0]\n\t\tY_batch  = batch[1]\n        \n\t\t_, loss, acc = instance.Run([_solver, _loss, _accuracy], feed_dict={self.X: X_batch, self.y: Y_batch})\n\n\t\t#every N steps, send the state to the scene\n\t\tif it % self.display_step == 0:\n\t\t\tSetState(self.id, it/self.training_iterations)\n\t\t\tSendChartData(self.id, ""Loss"", loss, ""#ff0000"")\n\t\t\tSendChartData(self.id, ""Accuracy"", acc)\n        \n\tAIBlocks.SaveModel(instance)\n\tAIBlocks.CloseInstance(instance)\n\n'"
Sources/templates/empty_template.py,0,b'#description Empty script template\n#icon fa fa-flask'
Sources/templates/loader_template.py,0,"b""#description Loader template\n#type data source\n#icon fa fa-sort-numeric-asc\n\n#param int\ninput_size = 10\n#param int\nlabels_size = 2\n#param int\nbatch_size = 100\n\n### You should intialize the datasets here...\nself.X = [[0]*self.input_length]*1000\nself.Y = [[0]*self.labels_size]*1000\n\nself.testX = [[0]*self.input_length]*100\nself.testY = [[0]*self.labels_size]*100\n\n#This function is called by the trainer to fetch data\n#It output two arrays: one for the inputs, and the other for the labels\n#Example inputs: x=[[1, 0, 0], [0, 1, 0], ...]\n#Example labels: y=[[1, 0], [0, 1], ...]\ndef getNextBatch(self):\n\tx = []\n\ty = []\n\t#TODO: fetch some data here...\n\n\treturn x, y\n\n#same rules as 'getNextBatch' except this is from the test dataset\ndef getTestBatch(self):\n\tx = []\n\ty = []\n\t#TODO: fetch some test data here...\n\n\treturn x, y\n"""
Sources/templates/predictor_template.py,1,"b'import time\nimport tensorflow as tf\nimport os\n\n#description Predictor script template\n#icon fa fa-magic\n#MAIN=Run\n\n#param object\n_input = None\n#param object\n_model = None\n#param folder\nload_path = """"\n\ndef Run(self):\n\n\t### defining the model ###\n\n\t#input\n\tinput = tf.placeholder(tf.float32, shape=[None, self._input.input_size], name=""x_input"")    \n\t\n\t#output\n\toutput = self._model.Run(input)\n\n\t#initialize everything\n \tinstance = AIBlocks.InitModel(load_path=self.load_path)\n\tLog(""Model initialized!"")\n\n\t#load test data\n\tbatch = self._input.getTestBatch()\n\tinputs = batch[0]\n\treal_categories = batch[1]\n\t\n\tpredictions = instance.Run(output, feed_dict={input: inputs})\n\n\tfor i in range(len(predictions)):\n\t\testimation = AIBlocks.MaxIndex(predictions[i])\n\t\treal = AIBlocks.MaxIndex(Y_batch[i])\n\t\t\n\t\tif(estimation==real):\n\t\t\t#TODO: Do something here...\n\n\tAIBlocks.CloseInstance(instance)'"
