file_path,api_count,code
config.py,2,"b'import os\nimport tensorflow as tf\n\n\'\'\'\nThis file is taken and modified from R-Net by HKUST-KnowComp\nhttps://github.com/HKUST-KnowComp/R-Net\n\'\'\'\n\nfrom prepro import prepro\nfrom main import train, test, demo\n\nflags = tf.flags\n\nhome = os.getcwd()\ntrain_file = os.path.join(home, ""datasets"", ""squad"", ""train-v1.1.json"")\ndev_file = os.path.join(home, ""datasets"", ""squad"", ""dev-v1.1.json"")\ntest_file = os.path.join(home, ""datasets"", ""squad"", ""dev-v1.1.json"")\nglove_word_file = os.path.join(home, ""datasets"", ""glove"", ""glove.840B.300d.txt"")\n\ntrain_dir = ""train""\nmodel_name = ""FRC""\ndir_name = os.path.join(train_dir, model_name)\nif not os.path.exists(train_dir):\n    os.mkdir(train_dir)\nif not os.path.exists(os.path.join(os.getcwd(),dir_name)):\n    os.mkdir(os.path.join(os.getcwd(),dir_name))\ntarget_dir = ""data""\nlog_dir = os.path.join(dir_name, ""event"")\nsave_dir = os.path.join(dir_name, ""model"")\nanswer_dir = os.path.join(dir_name, ""answer"")\ntrain_record_file = os.path.join(target_dir, ""train.tfrecords"")\ndev_record_file = os.path.join(target_dir, ""dev.tfrecords"")\ntest_record_file = os.path.join(target_dir, ""test.tfrecords"")\nword_emb_file = os.path.join(target_dir, ""word_emb.json"")\nchar_emb_file = os.path.join(target_dir, ""char_emb.json"")\ntrain_eval = os.path.join(target_dir, ""train_eval.json"")\ndev_eval = os.path.join(target_dir, ""dev_eval.json"")\ntest_eval = os.path.join(target_dir, ""test_eval.json"")\ndev_meta = os.path.join(target_dir, ""dev_meta.json"")\ntest_meta = os.path.join(target_dir, ""test_meta.json"")\nword_dictionary = os.path.join(target_dir, ""word_dictionary.json"")\nchar_dictionary = os.path.join(target_dir, ""char_dictionary.json"")\nanswer_file = os.path.join(answer_dir, ""answer.json"")\n\nif not os.path.exists(target_dir):\n    os.makedirs(target_dir)\nif not os.path.exists(log_dir):\n    os.makedirs(log_dir)\nif not os.path.exists(save_dir):\n    os.makedirs(save_dir)\nif not os.path.exists(answer_dir):\n    os.makedirs(answer_dir)\n\nflags.DEFINE_string(""mode"", ""train"", ""Running mode train/debug/test"")\n\nflags.DEFINE_string(""target_dir"", target_dir, ""Target directory for out data"")\nflags.DEFINE_string(""log_dir"", log_dir, ""Directory for tf event"")\nflags.DEFINE_string(""save_dir"", save_dir, ""Directory for saving model"")\nflags.DEFINE_string(""train_file"", train_file, ""Train source file"")\nflags.DEFINE_string(""dev_file"", dev_file, ""Dev source file"")\nflags.DEFINE_string(""test_file"", test_file, ""Test source file"")\nflags.DEFINE_string(""glove_word_file"", glove_word_file, ""Glove word embedding source file"")\n\nflags.DEFINE_string(""train_record_file"", train_record_file, ""Out file for train data"")\nflags.DEFINE_string(""dev_record_file"", dev_record_file, ""Out file for dev data"")\nflags.DEFINE_string(""test_record_file"", test_record_file, ""Out file for test data"")\nflags.DEFINE_string(""word_emb_file"", word_emb_file, ""Out file for word embedding"")\nflags.DEFINE_string(""char_emb_file"", char_emb_file, ""Out file for char embedding"")\nflags.DEFINE_string(""train_eval_file"", train_eval, ""Out file for train eval"")\nflags.DEFINE_string(""dev_eval_file"", dev_eval, ""Out file for dev eval"")\nflags.DEFINE_string(""test_eval_file"", test_eval, ""Out file for test eval"")\nflags.DEFINE_string(""dev_meta"", dev_meta, ""Out file for dev meta"")\nflags.DEFINE_string(""test_meta"", test_meta, ""Out file for test meta"")\nflags.DEFINE_string(""answer_file"", answer_file, ""Out file for answer"")\nflags.DEFINE_string(""word_dictionary"", word_dictionary, ""Word dictionary"")\nflags.DEFINE_string(""char_dictionary"", char_dictionary, ""Character dictionary"")\n\n\nflags.DEFINE_integer(""glove_char_size"", 94, ""Corpus size for Glove"")\nflags.DEFINE_integer(""glove_word_size"", int(2.2e6), ""Corpus size for Glove"")\nflags.DEFINE_integer(""glove_dim"", 300, ""Embedding dimension for Glove"")\nflags.DEFINE_integer(""char_dim"", 64, ""Embedding dimension for char"")\n\nflags.DEFINE_integer(""para_limit"", 400, ""Limit length for paragraph"")\nflags.DEFINE_integer(""ques_limit"", 50, ""Limit length for question"")\nflags.DEFINE_integer(""ans_limit"", 30, ""Limit length for answers"")\nflags.DEFINE_integer(""test_para_limit"", 1000, ""Limit length for paragraph in test file"")\nflags.DEFINE_integer(""test_ques_limit"", 100, ""Limit length for question in test file"")\nflags.DEFINE_integer(""char_limit"", 16, ""Limit length for character"")\nflags.DEFINE_integer(""word_count_limit"", -1, ""Min count for word"")\nflags.DEFINE_integer(""char_count_limit"", -1, ""Min count for char"")\n\nflags.DEFINE_integer(""capacity"", 15000, ""Batch size of dataset shuffle"")\nflags.DEFINE_integer(""num_threads"", 4, ""Number of threads in input pipeline"")\nflags.DEFINE_boolean(""is_bucket"", False, ""build bucket batch iterator or not"")\nflags.DEFINE_list(""bucket_range"", [40, 401, 40], ""the range of bucket"")\n\nflags.DEFINE_integer(""batch_size"", 32, ""Batch size"")\nflags.DEFINE_integer(""num_steps"", 60000, ""Number of steps"")\nflags.DEFINE_integer(""checkpoint"", 1000, ""checkpoint to save and evaluate the model"")\nflags.DEFINE_integer(""period"", 100, ""period to save batch loss"")\nflags.DEFINE_integer(""val_num_batches"", 150, ""Number of batches to evaluate the model"")\nflags.DEFINE_float(""dropout"", 0.1, ""Dropout prob across the layers"")\nflags.DEFINE_float(""grad_clip"", 5.0, ""Global Norm gradient clipping rate"")\nflags.DEFINE_float(""learning_rate"", 0.001, ""Learning rate"")\nflags.DEFINE_float(""decay"", 0.9999, ""Exponential moving average decay"")\nflags.DEFINE_float(""l2_norm"", 3e-7, ""L2 norm scale"")\nflags.DEFINE_integer(""hidden"", 96, ""Hidden size"")\nflags.DEFINE_integer(""num_heads"", 1, ""Number of heads in self attention"")\nflags.DEFINE_integer(""early_stop"", 10, ""Checkpoints for early stop"")\n\n# Extensions (Uncomment corresponding code in download.sh to download the required data)\nglove_char_file = os.path.join(home, ""data"", ""glove"", ""glove.840B.300d-char.txt"")\nflags.DEFINE_string(""glove_char_file"", glove_char_file, ""Glove character embedding source file"")\nflags.DEFINE_boolean(""pretrained_char"", False, ""Whether to use pretrained character embedding"")\n\nfasttext_file = os.path.join(home, ""data"", ""fasttext"", ""wiki-news-300d-1M.vec"")\nflags.DEFINE_string(""fasttext_file"", fasttext_file, ""Fasttext word embedding source file"")\nflags.DEFINE_boolean(""fasttext"", False, ""Whether to use fasttext"")\n\n\ndef main(_):\n    config = flags.FLAGS\n    if config.mode == ""train"":\n        train(config)\n    elif config.mode == ""prepro"":\n        prepro(config)\n    elif config.mode == ""debug"":\n        config.num_steps = 2\n        config.val_num_batches = 1\n        config.checkpoint = 1\n        config.period = 1\n        train(config)\n    elif config.mode == ""test"":\n        test(config)\n    elif config.mode == ""demo"":\n        demo(config)\n    else:\n        print(""Unknown mode"")\n        exit(0)\n\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
demo.py,5,"b'#!/usr/bin/env python\n# coding=utf-8\n\nimport tensorflow as tf\nimport bottle\nfrom bottle import route, run\nimport threading\nimport json\nimport numpy as np\n\nfrom prepro import convert_to_features, word_tokenize\nfrom time import sleep\n\n\'\'\'\nThis file is taken and modified from R-Net by Minsangkim142\nhttps://github.com/minsangkim142/R-net\n\'\'\'\n\napp = bottle.Bottle()\nquery = []\nresponse = """"\n\n@app.get(""/"")\ndef home():\n    with open(\'demo.html\', \'r\') as fl:\n        html = fl.read()\n        return html\n\n@app.post(\'/answer\')\ndef answer():\n    passage = bottle.request.json[\'passage\']\n    question = bottle.request.json[\'question\']\n    print(""received question: {}"".format(question))\n    # if not passage or not question:\n    #     exit()\n    global query, response\n    query = (passage, question)\n    while not response:\n        sleep(0.1)\n    print(""received response: {}"".format(response))\n    response_ = {""answer"": response}\n    response = []\n    return response_\n\nclass Demo(object):\n    def __init__(self, model, config):\n        run_event = threading.Event()\n        run_event.set()\n        threading.Thread(target=self.demo_backend, args = [model, config, run_event]).start()\n        app.run(port=8080, host=\'0.0.0.0\')\n        try:\n            while 1:\n                sleep(.1)\n        except KeyboardInterrupt:\n            print(""Closing server..."")\n            run_event.clear()\n\n    def demo_backend(self, model, config, run_event):\n        global query, response\n\n        with open(config.word_dictionary, ""r"") as fh:\n            word_dictionary = json.load(fh)\n        with open(config.char_dictionary, ""r"") as fh:\n            char_dictionary = json.load(fh)\n\n        sess_config = tf.ConfigProto(allow_soft_placement=True)\n        sess_config.gpu_options.allow_growth = True\n\n        with model.graph.as_default():\n\n            with tf.Session(config=sess_config) as sess:\n                sess.run(tf.global_variables_initializer())\n                saver = tf.train.Saver()\n                saver.restore(sess, tf.train.latest_checkpoint(config.save_dir))\n                if config.decay < 1.0:\n                    sess.run(model.assign_vars)\n                while run_event.is_set():\n                    sleep(0.1)\n                    if query:\n                        context = word_tokenize(query[0].replace(""\'\'"", \'"" \').replace(""``"", \'"" \'))\n                        c,ch,q,qh = convert_to_features(config, query, word_dictionary, char_dictionary)\n                        fd = {\'context:0\': [c],\n                              \'question:0\': [q],\n                              \'context_char:0\': [ch],\n                              \'question_char:0\': [qh]}\n                        yp1,yp2 = sess.run([model.yp1, model.yp2], feed_dict = fd)\n                        yp2[0] += 1\n                        response = "" "".join(context[yp1[0]:yp2[0]])\n                        query = []\n'"
evaluate-v1.1.py,0,"b'"""""" Official evaluation script for v1.1 of the SQuAD dataset. """"""\nfrom __future__ import print_function\nfrom collections import Counter\nimport string\nimport re\nimport argparse\nimport json\nimport sys\n\n\ndef normalize_answer(s):\n    """"""Lower text and remove punctuation, articles and extra whitespace.""""""\n    def remove_articles(text):\n        return re.sub(r\'\\b(a|an|the)\\b\', \' \', text)\n\n    def white_space_fix(text):\n        return \' \'.join(text.split())\n\n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return \'\'.join(ch for ch in text if ch not in exclude)\n\n    def lower(text):\n        return text.lower()\n\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\n\n\ndef f1_score(prediction, ground_truth):\n    prediction_tokens = normalize_answer(prediction).split()\n    ground_truth_tokens = normalize_answer(ground_truth).split()\n    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n    num_same = sum(common.values())\n    if num_same == 0:\n        return 0\n    precision = 1.0 * num_same / len(prediction_tokens)\n    recall = 1.0 * num_same / len(ground_truth_tokens)\n    f1 = (2 * precision * recall) / (precision + recall)\n    return f1\n\n\ndef exact_match_score(prediction, ground_truth):\n    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n\n\ndef metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n    scores_for_ground_truths = []\n    for ground_truth in ground_truths:\n        score = metric_fn(prediction, ground_truth)\n        scores_for_ground_truths.append(score)\n    return max(scores_for_ground_truths)\n\n\ndef evaluate(dataset, predictions):\n    f1 = exact_match = total = 0\n    for article in dataset:\n        for paragraph in article[\'paragraphs\']:\n            for qa in paragraph[\'qas\']:\n                total += 1\n                if qa[\'id\'] not in predictions:\n                    message = \'Unanswered question \' + qa[\'id\'] + \\\n                              \' will receive score 0.\'\n                    print(message, file=sys.stderr)\n                    continue\n                ground_truths = list(map(lambda x: x[\'text\'], qa[\'answers\']))\n                prediction = predictions[qa[\'id\']]\n                exact_match += metric_max_over_ground_truths(\n                    exact_match_score, prediction, ground_truths)\n                f1 += metric_max_over_ground_truths(\n                    f1_score, prediction, ground_truths)\n\n    exact_match = 100.0 * exact_match / total\n    f1 = 100.0 * f1 / total\n\n    return {\'exact_match\': exact_match, \'f1\': f1}\n\n\nif __name__ == \'__main__\':\n    expected_version = \'1.1\'\n    parser = argparse.ArgumentParser(\n        description=\'Evaluation for SQuAD \' + expected_version)\n    parser.add_argument(\'dataset_file\', help=\'Dataset file\')\n    parser.add_argument(\'prediction_file\', help=\'Prediction File\')\n    args = parser.parse_args()\n    with open(args.dataset_file) as dataset_file:\n        dataset_json = json.load(dataset_file)\n        if (dataset_json[\'version\'] != expected_version):\n            print(\'Evaluation expects v-\' + expected_version +\n                  \', but got dataset with v-\' + dataset_json[\'version\'],\n                  file=sys.stderr)\n        dataset = dataset_json[\'data\']\n    with open(args.prediction_file) as prediction_file:\n        predictions = json.load(prediction_file)\n    print(json.dumps(evaluate(dataset, predictions)))\n'"
layers.py,113,"b'# -*- coding: utf-8 -*-\n#/usr/bin/python2\n\nimport tensorflow as tf\nimport numpy as np\nimport math\n\nfrom tensorflow.contrib.rnn import MultiRNNCell\nfrom tensorflow.contrib.rnn import RNNCell\n\nfrom tensorflow.python.util import nest\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import init_ops\nfrom tensorflow.python.ops import nn_ops\nfrom tensorflow.python.ops import clip_ops\n\nfrom functools import reduce\nfrom operator import mul\n\n\'\'\'\nSome functions are taken directly from Tensor2Tensor Library:\nhttps://github.com/tensorflow/tensor2tensor/\nand BiDAF repository:\nhttps://github.com/allenai/bi-att-flow\n\'\'\'\n\ninitializer = lambda: tf.contrib.layers.variance_scaling_initializer(factor=1.0,\n                                                             mode=\'FAN_AVG\',\n                                                             uniform=True,\n                                                             dtype=tf.float32)\ninitializer_relu = lambda: tf.contrib.layers.variance_scaling_initializer(factor=2.0,\n                                                             mode=\'FAN_IN\',\n                                                             uniform=False,\n                                                             dtype=tf.float32)\nregularizer = tf.contrib.layers.l2_regularizer(scale = 3e-7)\n\ndef glu(x):\n    """"""Gated Linear Units from https://arxiv.org/pdf/1612.08083.pdf""""""\n    x, x_h = tf.split(x, 2, axis = -1)\n    return tf.sigmoid(x) * x_h\n\ndef noam_norm(x, epsilon=1.0, scope=None, reuse=None):\n    """"""One version of layer normalization.""""""\n    with tf.name_scope(scope, default_name=""noam_norm"", values=[x]):\n        shape = x.get_shape()\n        ndims = len(shape)\n        return tf.nn.l2_normalize(x, ndims - 1, epsilon=epsilon) * tf.sqrt(tf.to_float(shape[-1]))\n\ndef layer_norm_compute_python(x, epsilon, scale, bias):\n    """"""Layer norm raw computation.""""""\n    mean = tf.reduce_mean(x, axis=[-1], keep_dims=True)\n    variance = tf.reduce_mean(tf.square(x - mean), axis=[-1], keep_dims=True)\n    norm_x = (x - mean) * tf.rsqrt(variance + epsilon)\n    return norm_x * scale + bias\n\ndef layer_norm(x, filters=None, epsilon=1e-6, scope=None, reuse=None):\n    """"""Layer normalize the tensor x, averaging over the last dimension.""""""\n    if filters is None:\n        filters = x.get_shape()[-1]\n    with tf.variable_scope(scope, default_name=""layer_norm"", values=[x], reuse=reuse):\n        scale = tf.get_variable(\n            ""layer_norm_scale"", [filters], regularizer = regularizer, initializer=tf.ones_initializer())\n        bias = tf.get_variable(\n            ""layer_norm_bias"", [filters], regularizer = regularizer, initializer=tf.zeros_initializer())\n        result = layer_norm_compute_python(x, epsilon, scale, bias)\n        return result\n\nnorm_fn = layer_norm#tf.contrib.layers.layer_norm #tf.contrib.layers.layer_norm or noam_norm\n\ndef highway(x, size = None, activation = None,\n            num_layers = 2, scope = ""highway"", dropout = 0.0, reuse = None):\n    with tf.variable_scope(scope, reuse):\n        if size is None:\n            size = x.shape.as_list()[-1]\n        else:\n            x = conv(x, size, name = ""input_projection"", reuse = reuse)\n        for i in range(num_layers):\n            T = conv(x, size, bias = True, activation = tf.sigmoid,\n                     name = ""gate_%d""%i, reuse = reuse)\n            H = conv(x, size, bias = True, activation = activation,\n                     name = ""activation_%d""%i, reuse = reuse)\n            H = tf.nn.dropout(H, 1.0 - dropout)\n            x = H * T + x * (1.0 - T)\n        return x\n\ndef layer_dropout(inputs, residual, dropout):\n    pred = tf.random_uniform([]) < dropout\n    return tf.cond(pred, lambda: residual, lambda: tf.nn.dropout(inputs, 1.0 - dropout) + residual)\n\ndef residual_block(inputs, num_blocks, num_conv_layers, kernel_size, mask = None,\n                   num_filters = 128, input_projection = False, num_heads = 8,\n                   seq_len = None, scope = ""res_block"", is_training = True,\n                   reuse = None, bias = True, dropout = 0.0):\n    with tf.variable_scope(scope, reuse = reuse):\n        if input_projection:\n            inputs = conv(inputs, num_filters, name = ""input_projection"", reuse = reuse)\n        outputs = inputs\n        sublayer = 1\n        total_sublayers = (num_conv_layers + 2) * num_blocks\n        for i in range(num_blocks):\n            outputs = add_timing_signal_1d(outputs)\n            outputs, sublayer = conv_block(outputs, num_conv_layers, kernel_size, num_filters,\n                seq_len = seq_len, scope = ""encoder_block_%d""%i,reuse = reuse, bias = bias,\n                dropout = dropout, sublayers = (sublayer, total_sublayers))\n            outputs, sublayer = self_attention_block(outputs, num_filters, seq_len, mask = mask, num_heads = num_heads,\n                scope = ""self_attention_layers%d""%i, reuse = reuse, is_training = is_training,\n                bias = bias, dropout = dropout, sublayers = (sublayer, total_sublayers))\n        return outputs\n\ndef conv_block(inputs, num_conv_layers, kernel_size, num_filters,\n               seq_len = None, scope = ""conv_block"", is_training = True,\n               reuse = None, bias = True, dropout = 0.0, sublayers = (1, 1)):\n    with tf.variable_scope(scope, reuse = reuse):\n        outputs = tf.expand_dims(inputs,2)\n        l, L = sublayers\n        for i in range(num_conv_layers):\n            residual = outputs\n            outputs = norm_fn(outputs, scope = ""layer_norm_%d""%i, reuse = reuse)\n            if (i) % 2 == 0:\n                outputs = tf.nn.dropout(outputs, 1.0 - dropout)\n            outputs = depthwise_separable_convolution(outputs,\n                kernel_size = (kernel_size, 1), num_filters = num_filters,\n                scope = ""depthwise_conv_layers_%d""%i, is_training = is_training, reuse = reuse)\n            outputs = layer_dropout(outputs, residual, dropout * float(l) / L)\n            l += 1\n        return tf.squeeze(outputs,2), l\n\ndef self_attention_block(inputs, num_filters, seq_len, mask = None, num_heads = 8,\n                         scope = ""self_attention_ffn"", reuse = None, is_training = True,\n                         bias = True, dropout = 0.0, sublayers = (1, 1)):\n    with tf.variable_scope(scope, reuse = reuse):\n        l, L = sublayers\n        # Self attention\n        outputs = norm_fn(inputs, scope = ""layer_norm_1"", reuse = reuse)\n        outputs = tf.nn.dropout(outputs, 1.0 - dropout)\n        outputs = multihead_attention(outputs, num_filters,\n            num_heads = num_heads, seq_len = seq_len, reuse = reuse,\n            mask = mask, is_training = is_training, bias = bias, dropout = dropout)\n        residual = layer_dropout(outputs, inputs, dropout * float(l) / L)\n        l += 1\n        # Feed-forward\n        outputs = norm_fn(residual, scope = ""layer_norm_2"", reuse = reuse)\n        outputs = tf.nn.dropout(outputs, 1.0 - dropout)\n        outputs = conv(outputs, num_filters, True, tf.nn.relu, name = ""FFN_1"", reuse = reuse)\n        outputs = conv(outputs, num_filters, True, None, name = ""FFN_2"", reuse = reuse)\n        outputs = layer_dropout(outputs, residual, dropout * float(l) / L)\n        l += 1\n        return outputs, l\n\ndef multihead_attention(queries, units, num_heads,\n                        memory = None,\n                        seq_len = None,\n                        scope = ""Multi_Head_Attention"",\n                        reuse = None,\n                        mask = None,\n                        is_training = True,\n                        bias = True,\n                        dropout = 0.0):\n    with tf.variable_scope(scope, reuse = reuse):\n        # Self attention\n        if memory is None:\n            memory = queries\n\n        memory = conv(memory, 2 * units, name = ""memory_projection"", reuse = reuse)\n        query = conv(queries, units, name = ""query_projection"", reuse = reuse)\n        Q = split_last_dimension(query, num_heads)\n        K, V = [split_last_dimension(tensor, num_heads) for tensor in tf.split(memory,2,axis = 2)]\n\n        key_depth_per_head = units // num_heads\n        Q *= key_depth_per_head**-0.5\n        x = dot_product_attention(Q,K,V,\n                                  bias = bias,\n                                  seq_len = seq_len,\n                                  mask = mask,\n                                  is_training = is_training,\n                                  scope = ""dot_product_attention"",\n                                  reuse = reuse, dropout = dropout)\n        return combine_last_two_dimensions(tf.transpose(x,[0,2,1,3]))\n\ndef conv(inputs, output_size, bias = None, activation = None, kernel_size = 1, name = ""conv"", reuse = None):\n    with tf.variable_scope(name, reuse = reuse):\n        shapes = inputs.shape.as_list()\n        if len(shapes) > 4:\n            raise NotImplementedError\n        elif len(shapes) == 4:\n            filter_shape = [1,kernel_size,shapes[-1],output_size]\n            bias_shape = [1,1,1,output_size]\n            strides = [1,1,1,1]\n        else:\n            filter_shape = [kernel_size,shapes[-1],output_size]\n            bias_shape = [1,1,output_size]\n            strides = 1\n        conv_func = tf.nn.conv1d if len(shapes) == 3 else tf.nn.conv2d\n        kernel_ = tf.get_variable(""kernel_"",\n                        filter_shape,\n                        dtype = tf.float32,\n                        regularizer=regularizer,\n                        initializer = initializer_relu() if activation is not None else initializer())\n        outputs = conv_func(inputs, kernel_, strides, ""VALID"")\n        if bias:\n            outputs += tf.get_variable(""bias_"",\n                        bias_shape,\n                        regularizer=regularizer,\n                        initializer = tf.zeros_initializer())\n        if activation is not None:\n            return activation(outputs)\n        else:\n            return outputs\n\ndef mask_logits(inputs, mask, mask_value = -1e30):\n    shapes = inputs.shape.as_list()\n    mask = tf.cast(mask, tf.float32)\n    return inputs + mask_value * (1 - mask)\n\ndef depthwise_separable_convolution(inputs, kernel_size, num_filters,\n                                    scope = ""depthwise_separable_convolution"",\n                                    bias = True, is_training = True, reuse = None):\n    with tf.variable_scope(scope, reuse = reuse):\n        shapes = inputs.shape.as_list()\n        depthwise_filter = tf.get_variable(""depthwise_filter"",\n                                        (kernel_size[0], kernel_size[1], shapes[-1], 1),\n                                        dtype = tf.float32,\n                                        regularizer=regularizer,\n                                        initializer = initializer_relu())\n        pointwise_filter = tf.get_variable(""pointwise_filter"",\n                                        (1,1,shapes[-1],num_filters),\n                                        dtype = tf.float32,\n                                        regularizer=regularizer,\n                                        initializer = initializer_relu())\n        outputs = tf.nn.separable_conv2d(inputs,\n                                        depthwise_filter,\n                                        pointwise_filter,\n                                        strides = (1,1,1,1),\n                                        padding = ""SAME"")\n        if bias:\n            b = tf.get_variable(""bias"",\n                    outputs.shape[-1],\n                    regularizer=regularizer,\n                    initializer = tf.zeros_initializer())\n            outputs += b\n        outputs = tf.nn.relu(outputs)\n        return outputs\n\ndef split_last_dimension(x, n):\n    """"""Reshape x so that the last dimension becomes two dimensions.\n    The first of these two dimensions is n.\n    Args:\n    x: a Tensor with shape [..., m]\n    n: an integer.\n    Returns:\n    a Tensor with shape [..., n, m/n]\n    """"""\n    old_shape = x.get_shape().dims\n    last = old_shape[-1]\n    new_shape = old_shape[:-1] + [n] + [last // n if last else None]\n    ret = tf.reshape(x, tf.concat([tf.shape(x)[:-1], [n, -1]], 0))\n    ret.set_shape(new_shape)\n    return tf.transpose(ret,[0,2,1,3])\n\ndef dot_product_attention(q,\n                          k,\n                          v,\n                          bias,\n                          seq_len = None,\n                          mask = None,\n                          is_training = True,\n                          scope=None,\n                          reuse = None,\n                          dropout = 0.0):\n    """"""dot-product attention.\n    Args:\n    q: a Tensor with shape [batch, heads, length_q, depth_k]\n    k: a Tensor with shape [batch, heads, length_kv, depth_k]\n    v: a Tensor with shape [batch, heads, length_kv, depth_v]\n    bias: bias Tensor (see attention_bias())\n    is_training: a bool of training\n    scope: an optional string\n    Returns:\n    A Tensor.\n    """"""\n    with tf.variable_scope(scope, default_name=""dot_product_attention"", reuse = reuse):\n        # [batch, num_heads, query_length, memory_length]\n        logits = tf.matmul(q, k, transpose_b=True)\n        if bias:\n            b = tf.get_variable(""bias"",\n                    logits.shape[-1],\n                    regularizer=regularizer,\n                    initializer = tf.zeros_initializer())\n            logits += b\n        if mask is not None:\n            shapes = [x  if x != None else -1 for x in logits.shape.as_list()]\n            mask = tf.reshape(mask, [shapes[0],1,1,shapes[-1]])\n            logits = mask_logits(logits, mask)\n        weights = tf.nn.softmax(logits, name=""attention_weights"")\n        # dropping out the attention links for each of the heads\n        weights = tf.nn.dropout(weights, 1.0 - dropout)\n        return tf.matmul(weights, v)\n\ndef combine_last_two_dimensions(x):\n    """"""Reshape x so that the last two dimension become one.\n    Args:\n    x: a Tensor with shape [..., a, b]\n    Returns:\n    a Tensor with shape [..., ab]\n    """"""\n    old_shape = x.get_shape().dims\n    a, b = old_shape[-2:]\n    new_shape = old_shape[:-2] + [a * b if a and b else None]\n    ret = tf.reshape(x, tf.concat([tf.shape(x)[:-2], [-1]], 0))\n    ret.set_shape(new_shape)\n    return ret\n\ndef add_timing_signal_1d(x, min_timescale=1.0, max_timescale=1.0e4):\n    """"""Adds a bunch of sinusoids of different frequencies to a Tensor.\n    Each channel of the input Tensor is incremented by a sinusoid of a different\n    frequency and phase.\n    This allows attention to learn to use absolute and relative positions.\n    Timing signals should be added to some precursors of both the query and the\n    memory inputs to attention.\n    The use of relative position is possible because sin(x+y) and cos(x+y) can be\n    experessed in terms of y, sin(x) and cos(x).\n    In particular, we use a geometric sequence of timescales starting with\n    min_timescale and ending with max_timescale.  The number of different\n    timescales is equal to channels / 2. For each timescale, we\n    generate the two sinusoidal signals sin(timestep/timescale) and\n    cos(timestep/timescale).  All of these sinusoids are concatenated in\n    the channels dimension.\n    Args:\n    x: a Tensor with shape [batch, length, channels]\n    min_timescale: a float\n    max_timescale: a float\n    Returns:\n    a Tensor the same shape as x.\n    """"""\n    length = tf.shape(x)[1]\n    channels = tf.shape(x)[2]\n    signal = get_timing_signal_1d(length, channels, min_timescale, max_timescale)\n    return x + signal\n\ndef get_timing_signal_1d(length, channels, min_timescale=1.0, max_timescale=1.0e4):\n    """"""Gets a bunch of sinusoids of different frequencies.\n    Each channel of the input Tensor is incremented by a sinusoid of a different\n    frequency and phase.\n    This allows attention to learn to use absolute and relative positions.\n    Timing signals should be added to some precursors of both the query and the\n    memory inputs to attention.\n    The use of relative position is possible because sin(x+y) and cos(x+y) can be\n    experessed in terms of y, sin(x) and cos(x).\n    In particular, we use a geometric sequence of timescales starting with\n    min_timescale and ending with max_timescale.  The number of different\n    timescales is equal to channels / 2. For each timescale, we\n    generate the two sinusoidal signals sin(timestep/timescale) and\n    cos(timestep/timescale).  All of these sinusoids are concatenated in\n    the channels dimension.\n    Args:\n    length: scalar, length of timing signal sequence.\n    channels: scalar, size of timing embeddings to create. The number of\n        different timescales is equal to channels / 2.\n    min_timescale: a float\n    max_timescale: a float\n    Returns:\n    a Tensor of timing signals [1, length, channels]\n    """"""\n    position = tf.to_float(tf.range(length))\n    num_timescales = channels // 2\n    log_timescale_increment = (\n        math.log(float(max_timescale) / float(min_timescale)) /\n            (tf.to_float(num_timescales) - 1))\n    inv_timescales = min_timescale * tf.exp(\n        tf.to_float(tf.range(num_timescales)) * -log_timescale_increment)\n    scaled_time = tf.expand_dims(position, 1) * tf.expand_dims(inv_timescales, 0)\n    signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)\n    signal = tf.pad(signal, [[0, 0], [0, tf.mod(channels, 2)]])\n    signal = tf.reshape(signal, [1, length, channels])\n    return signal\n\ndef ndim(x):\n    """"""Copied from keras==2.0.6\n    Returns the number of axes in a tensor, as an integer.\n\n    # Arguments\n        x: Tensor or variable.\n\n    # Returns\n        Integer (scalar), number of axes.\n\n    # Examples\n    ```python\n        >>> from keras import backend as K\n        >>> inputs = K.placeholder(shape=(2, 4, 5))\n        >>> val = np.array([[1, 2], [3, 4]])\n        >>> kvar = K.variable(value=val)\n        >>> K.ndim(inputs)\n        3\n        >>> K.ndim(kvar)\n        2\n    ```\n    """"""\n    dims = x.get_shape()._dims\n    if dims is not None:\n        return len(dims)\n    return None\n\ndef dot(x, y):\n    """"""Modified from keras==2.0.6\n    Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n\n    When attempting to multiply a nD tensor\n    with a nD tensor, it reproduces the Theano behavior.\n    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n\n    # Arguments\n        x: Tensor or variable.\n        y: Tensor or variable.\n\n    # Returns\n        A tensor, dot product of `x` and `y`.\n    """"""\n    if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n        x_shape = []\n        for i, s in zip(x.get_shape().as_list(), tf.unstack(tf.shape(x))):\n            if i is not None:\n                x_shape.append(i)\n            else:\n                x_shape.append(s)\n        x_shape = tuple(x_shape)\n        y_shape = []\n        for i, s in zip(y.get_shape().as_list(), tf.unstack(tf.shape(y))):\n            if i is not None:\n                y_shape.append(i)\n            else:\n                y_shape.append(s)\n        y_shape = tuple(y_shape)\n        y_permute_dim = list(range(ndim(y)))\n        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n        xt = tf.reshape(x, [-1, x_shape[-1]])\n        yt = tf.reshape(tf.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\n        return tf.reshape(tf.matmul(xt, yt),\n                          x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n    if isinstance(x, tf.SparseTensor):\n        out = tf.sparse_tensor_dense_matmul(x, y)\n    else:\n        out = tf.matmul(x, y)\n    return out\n\ndef batch_dot(x, y, axes=None):\n    """"""Copy from keras==2.0.6\n    Batchwise dot product.\n\n    `batch_dot` is used to compute dot product of `x` and `y` when\n    `x` and `y` are data in batch, i.e. in a shape of\n    `(batch_size, :)`.\n    `batch_dot` results in a tensor or variable with less dimensions\n    than the input. If the number of dimensions is reduced to 1,\n    we use `expand_dims` to make sure that ndim is at least 2.\n\n    # Arguments\n        x: Keras tensor or variable with `ndim >= 2`.\n        y: Keras tensor or variable with `ndim >= 2`.\n        axes: list of (or single) int with target dimensions.\n            The lengths of `axes[0]` and `axes[1]` should be the same.\n\n    # Returns\n        A tensor with shape equal to the concatenation of `x`\'s shape\n        (less the dimension that was summed over) and `y`\'s shape\n        (less the batch dimension and the dimension that was summed over).\n        If the final rank is 1, we reshape it to `(batch_size, 1)`.\n    """"""\n    if isinstance(axes, int):\n        axes = (axes, axes)\n    x_ndim = ndim(x)\n    y_ndim = ndim(y)\n    if x_ndim > y_ndim:\n        diff = x_ndim - y_ndim\n        y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))\n    elif y_ndim > x_ndim:\n        diff = y_ndim - x_ndim\n        x = tf.reshape(x, tf.concat([tf.shape(x), [1] * (diff)], axis=0))\n    else:\n        diff = 0\n    if ndim(x) == 2 and ndim(y) == 2:\n        if axes[0] == axes[1]:\n            out = tf.reduce_sum(tf.multiply(x, y), axes[0])\n        else:\n            out = tf.reduce_sum(tf.multiply(tf.transpose(x, [1, 0]), y), axes[1])\n    else:\n        if axes is not None:\n            adj_x = None if axes[0] == ndim(x) - 1 else True\n            adj_y = True if axes[1] == ndim(y) - 1 else None\n        else:\n            adj_x = None\n            adj_y = None\n        out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n    if diff:\n        if x_ndim > y_ndim:\n            idx = x_ndim + y_ndim - 3\n        else:\n            idx = x_ndim - 1\n        out = tf.squeeze(out, list(range(idx, idx + diff)))\n    if ndim(out) == 1:\n        out = tf.expand_dims(out, 1)\n    return out\n\ndef optimized_trilinear_for_attention(args, c_maxlen, q_maxlen, input_keep_prob=1.0,\n    scope=\'efficient_trilinear\',\n    bias_initializer=tf.zeros_initializer(),\n    kernel_initializer=initializer()):\n    assert len(args) == 2, ""just use for computing attention with two input""\n    arg0_shape = args[0].get_shape().as_list()\n    arg1_shape = args[1].get_shape().as_list()\n    if len(arg0_shape) != 3 or len(arg1_shape) != 3:\n        raise ValueError(""`args` must be 3 dims (batch_size, len, dimension)"")\n    if arg0_shape[2] != arg1_shape[2]:\n        raise ValueError(""the last dimension of `args` must equal"")\n    arg_size = arg0_shape[2]\n    dtype = args[0].dtype\n    droped_args = [tf.nn.dropout(arg, input_keep_prob) for arg in args]\n    with tf.variable_scope(scope):\n        weights4arg0 = tf.get_variable(\n            ""linear_kernel4arg0"", [arg_size, 1],\n            dtype=dtype,\n            regularizer=regularizer,\n            initializer=kernel_initializer)\n        weights4arg1 = tf.get_variable(\n            ""linear_kernel4arg1"", [arg_size, 1],\n            dtype=dtype,\n            regularizer=regularizer,\n            initializer=kernel_initializer)\n        weights4mlu = tf.get_variable(\n            ""linear_kernel4mul"", [1, 1, arg_size],\n            dtype=dtype,\n            regularizer=regularizer,\n            initializer=kernel_initializer)\n        biases = tf.get_variable(\n            ""linear_bias"", [1],\n            dtype=dtype,\n            regularizer=regularizer,\n            initializer=bias_initializer)\n        subres0 = tf.tile(dot(droped_args[0], weights4arg0), [1, 1, q_maxlen])\n        subres1 = tf.tile(tf.transpose(dot(droped_args[1], weights4arg1), perm=(0, 2, 1)), [1, c_maxlen, 1])\n        subres2 = batch_dot(droped_args[0] * weights4mlu, tf.transpose(droped_args[1], perm=(0, 2, 1)))\n        res = subres0 + subres1 + subres2\n        nn_ops.bias_add(res, biases)\n        return res\n\ndef trilinear(args,\n            output_size = 1,\n            bias = True,\n            squeeze=False,\n            wd=0.0,\n            input_keep_prob= 1.0,\n            scope = ""trilinear""):\n    with tf.variable_scope(scope):\n        flat_args = [flatten(arg, 1) for arg in args]\n        flat_args = [tf.nn.dropout(arg, input_keep_prob) for arg in flat_args]\n        flat_out = _linear(flat_args, output_size, bias, scope=scope)\n        out = reconstruct(flat_out, args[0], 1)\n        return tf.squeeze(out, -1)\n\ndef flatten(tensor, keep):\n    fixed_shape = tensor.get_shape().as_list()\n    start = len(fixed_shape) - keep\n    left = reduce(mul, [fixed_shape[i] or tf.shape(tensor)[i] for i in range(start)])\n    out_shape = [left] + [fixed_shape[i] or tf.shape(tensor)[i] for i in range(start, len(fixed_shape))]\n    flat = tf.reshape(tensor, out_shape)\n    return flat\n\ndef reconstruct(tensor, ref, keep):\n    ref_shape = ref.get_shape().as_list()\n    tensor_shape = tensor.get_shape().as_list()\n    ref_stop = len(ref_shape) - keep\n    tensor_start = len(tensor_shape) - keep\n    pre_shape = [ref_shape[i] or tf.shape(ref)[i] for i in range(ref_stop)]\n    keep_shape = [tensor_shape[i] or tf.shape(tensor)[i] for i in range(tensor_start, len(tensor_shape))]\n    # pre_shape = [tf.shape(ref)[i] for i in range(len(ref.get_shape().as_list()[:-keep]))]\n    # keep_shape = tensor.get_shape().as_list()[-keep:]\n    target_shape = pre_shape + keep_shape\n    out = tf.reshape(tensor, target_shape)\n    return out\n\ndef _linear(args,\n            output_size,\n            bias,\n            bias_initializer=tf.zeros_initializer(),\n            scope = None,\n            kernel_initializer=initializer(),\n            reuse = None):\n  """"""Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n  Args:\n    args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n    output_size: int, second dimension of W[i].\n    bias: boolean, whether to add a bias term or not.\n    bias_initializer: starting value to initialize the bias\n      (default is all zeros).\n    kernel_initializer: starting value to initialize the weight.\n  Returns:\n    A 2D Tensor with shape [batch x output_size] equal to\n    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n  Raises:\n    ValueError: if some of the arguments has unspecified or wrong shape.\n  """"""\n  if args is None or (nest.is_sequence(args) and not args):\n    raise ValueError(""`args` must be specified"")\n  if not nest.is_sequence(args):\n    args = [args]\n  # Calculate the total size of arguments on dimension 1.\n  total_arg_size = 0\n  shapes = [a.get_shape() for a in args]\n  for shape in shapes:\n    if shape.ndims != 2:\n      raise ValueError(""linear is expecting 2D arguments: %s"" % shapes)\n    if shape[1].value is None:\n      raise ValueError(""linear expects shape[1] to be provided for shape %s, ""\n                       ""but saw %s"" % (shape, shape[1]))\n    else:\n      total_arg_size += shape[1].value\n\n  dtype = [a.dtype for a in args][0]\n\n  # Now the computation.\n  with tf.variable_scope(scope, reuse = reuse) as outer_scope:\n    weights = tf.get_variable(\n        ""linear_kernel"", [total_arg_size, output_size],\n        dtype=dtype,\n        regularizer=regularizer,\n        initializer=kernel_initializer)\n    if len(args) == 1:\n      res = math_ops.matmul(args[0], weights)\n    else:\n      res = math_ops.matmul(array_ops.concat(args, 1), weights)\n    if not bias:\n      return res\n    with tf.variable_scope(outer_scope) as inner_scope:\n      inner_scope.set_partitioner(None)\n      biases = tf.get_variable(\n          ""linear_bias"", [output_size],\n          dtype=dtype,\n          regularizer=regularizer,\n          initializer=bias_initializer)\n    return nn_ops.bias_add(res, biases)\n\ndef total_params():\n    total_parameters = 0\n    for variable in tf.trainable_variables():\n        shape = variable.get_shape()\n        variable_parametes = 1\n        for dim in shape:\n            variable_parametes *= dim.value\n        total_parameters += variable_parametes\n    print(""Total number of trainable parameters: {}"".format(total_parameters))\n'"
main.py,19,"b'import tensorflow as tf\nimport ujson as json\nimport numpy as np\nfrom tqdm import tqdm\nimport os\n\n\'\'\'\nThis file is taken and modified from R-Net by HKUST-KnowComp\nhttps://github.com/HKUST-KnowComp/R-Net\n\'\'\'\n\n\nfrom model import Model\nfrom demo import Demo\nfrom util import get_record_parser, convert_tokens, evaluate, get_batch_dataset, get_dataset\n\n\ndef train(config):\n    with open(config.word_emb_file, ""r"") as fh:\n        word_mat = np.array(json.load(fh), dtype=np.float32)\n    with open(config.char_emb_file, ""r"") as fh:\n        char_mat = np.array(json.load(fh), dtype=np.float32)\n    with open(config.train_eval_file, ""r"") as fh:\n        train_eval_file = json.load(fh)\n    with open(config.dev_eval_file, ""r"") as fh:\n        dev_eval_file = json.load(fh)\n    with open(config.dev_meta, ""r"") as fh:\n        meta = json.load(fh)\n\n    dev_total = meta[""total""]\n    print(""Building model..."")\n    parser = get_record_parser(config)\n    graph = tf.Graph()\n    with graph.as_default() as g:\n        train_dataset = get_batch_dataset(config.train_record_file, parser, config)\n        dev_dataset = get_dataset(config.dev_record_file, parser, config)\n        handle = tf.placeholder(tf.string, shape=[])\n        iterator = tf.data.Iterator.from_string_handle(\n            handle, train_dataset.output_types, train_dataset.output_shapes)\n        train_iterator = train_dataset.make_one_shot_iterator()\n        dev_iterator = dev_dataset.make_one_shot_iterator()\n\n        model = Model(config, iterator, word_mat, char_mat, graph = g)\n\n        sess_config = tf.ConfigProto(allow_soft_placement=True)\n        sess_config.gpu_options.allow_growth = True\n\n        loss_save = 100.0\n        patience = 0\n        best_f1 = 0.\n        best_em = 0.\n\n        with tf.Session(config=sess_config) as sess:\n            writer = tf.summary.FileWriter(config.log_dir)\n            sess.run(tf.global_variables_initializer())\n            saver = tf.train.Saver()\n            train_handle = sess.run(train_iterator.string_handle())\n            dev_handle = sess.run(dev_iterator.string_handle())\n            if os.path.exists(os.path.join(config.save_dir, ""checkpoint"")):\n                saver.restore(sess, tf.train.latest_checkpoint(config.save_dir))\n            global_step = max(sess.run(model.global_step), 1)\n\n            for _ in tqdm(range(global_step, config.num_steps + 1)):\n                global_step = sess.run(model.global_step) + 1\n                loss, train_op = sess.run([model.loss, model.train_op], feed_dict={\n                                          handle: train_handle, model.dropout: config.dropout})\n                if global_step % config.period == 0:\n                    loss_sum = tf.Summary(value=[tf.Summary.Value(\n                        tag=""model/loss"", simple_value=loss), ])\n                    writer.add_summary(loss_sum, global_step)\n                if global_step % config.checkpoint == 0:\n                    _, summ = evaluate_batch(\n                        model, config.val_num_batches, train_eval_file, sess, ""train"", handle, train_handle)\n                    for s in summ:\n                        writer.add_summary(s, global_step)\n\n                    metrics, summ = evaluate_batch(\n                        model, dev_total // config.batch_size + 1, dev_eval_file, sess, ""dev"", handle, dev_handle)\n\n                    dev_f1 = metrics[""f1""]\n                    dev_em = metrics[""exact_match""]\n                    if dev_f1 < best_f1 and dev_em < best_em:\n                        patience += 1\n                        if patience > config.early_stop:\n                            break\n                    else:\n                        patience = 0\n                        best_em = max(best_em, dev_em)\n                        best_f1 = max(best_f1, dev_f1)\n\n                    for s in summ:\n                        writer.add_summary(s, global_step)\n                    writer.flush()\n                    filename = os.path.join(\n                        config.save_dir, ""model_{}.ckpt"".format(global_step))\n                    saver.save(sess, filename)\n\n\ndef evaluate_batch(model, num_batches, eval_file, sess, data_type, handle, str_handle):\n    answer_dict = {}\n    losses = []\n    for _ in tqdm(range(1, num_batches + 1)):\n        qa_id, loss, yp1, yp2, = sess.run(\n            [model.qa_id, model.loss, model.yp1, model.yp2], feed_dict={handle: str_handle})\n        answer_dict_, _ = convert_tokens(\n            eval_file, qa_id.tolist(), yp1.tolist(), yp2.tolist())\n        answer_dict.update(answer_dict_)\n        losses.append(loss)\n    loss = np.mean(losses)\n    metrics = evaluate(eval_file, answer_dict)\n    metrics[""loss""] = loss\n    loss_sum = tf.Summary(value=[tf.Summary.Value(\n        tag=""{}/loss"".format(data_type), simple_value=metrics[""loss""]), ])\n    f1_sum = tf.Summary(value=[tf.Summary.Value(\n        tag=""{}/f1"".format(data_type), simple_value=metrics[""f1""]), ])\n    em_sum = tf.Summary(value=[tf.Summary.Value(\n        tag=""{}/em"".format(data_type), simple_value=metrics[""exact_match""]), ])\n    return metrics, [loss_sum, f1_sum, em_sum]\n\n\ndef demo(config):\n    with open(config.word_emb_file, ""r"") as fh:\n        word_mat = np.array(json.load(fh), dtype=np.float32)\n    with open(config.char_emb_file, ""r"") as fh:\n        char_mat = np.array(json.load(fh), dtype=np.float32)\n    with open(config.test_meta, ""r"") as fh:\n        meta = json.load(fh)\n\n    model = Model(config, None, word_mat, char_mat, trainable=False, demo = True)\n    demo = Demo(model, config)\n\n\ndef test(config):\n    with open(config.word_emb_file, ""r"") as fh:\n        word_mat = np.array(json.load(fh), dtype=np.float32)\n    with open(config.char_emb_file, ""r"") as fh:\n        char_mat = np.array(json.load(fh), dtype=np.float32)\n    with open(config.test_eval_file, ""r"") as fh:\n        eval_file = json.load(fh)\n    with open(config.test_meta, ""r"") as fh:\n        meta = json.load(fh)\n\n    total = meta[""total""]\n\n    graph = tf.Graph()\n    print(""Loading model..."")\n    with graph.as_default() as g:\n        test_batch = get_dataset(config.test_record_file, get_record_parser(\n            config, is_test=True), config).make_one_shot_iterator()\n\n        model = Model(config, test_batch, word_mat, char_mat, trainable=False, graph = g)\n\n        sess_config = tf.ConfigProto(allow_soft_placement=True)\n        sess_config.gpu_options.allow_growth = True\n\n        with tf.Session(config=sess_config) as sess:\n            sess.run(tf.global_variables_initializer())\n            saver = tf.train.Saver()\n            saver.restore(sess, tf.train.latest_checkpoint(config.save_dir))\n            if config.decay < 1.0:\n                sess.run(model.assign_vars)\n            losses = []\n            answer_dict = {}\n            remapped_dict = {}\n            for step in tqdm(range(total // config.batch_size + 1)):\n                qa_id, loss, yp1, yp2 = sess.run(\n                    [model.qa_id, model.loss, model.yp1, model.yp2])\n                answer_dict_, remapped_dict_ = convert_tokens(\n                    eval_file, qa_id.tolist(), yp1.tolist(), yp2.tolist())\n                answer_dict.update(answer_dict_)\n                remapped_dict.update(remapped_dict_)\n                losses.append(loss)\n            loss = np.mean(losses)\n            metrics = evaluate(eval_file, answer_dict)\n            with open(config.answer_file, ""w"") as fh:\n                json.dump(remapped_dict, fh)\n            print(""Exact Match: {}, F1: {}"".format(\n                metrics[\'exact_match\'], metrics[\'f1\']))\n'"
model.py,83,"b'import tensorflow as tf\nfrom layers import initializer, regularizer, residual_block, highway, conv, mask_logits, trilinear, total_params, optimized_trilinear_for_attention\n\nclass Model(object):\n    def __init__(self, config, batch, word_mat=None, char_mat=None, trainable=True, opt=True, demo = False, graph = None):\n        self.config = config\n        self.demo = demo\n        self.graph = graph if graph is not None else tf.Graph()\n        with self.graph.as_default():\n\n            self.global_step = tf.get_variable(\'global_step\', shape=[], dtype=tf.int32,\n                                               initializer=tf.constant_initializer(0), trainable=False)\n            self.dropout = tf.placeholder_with_default(0.0, (), name=""dropout"")\n            if self.demo:\n                self.c = tf.placeholder(tf.int32, [None, config.test_para_limit],""context"")\n                self.q = tf.placeholder(tf.int32, [None, config.test_ques_limit],""question"")\n                self.ch = tf.placeholder(tf.int32, [None, config.test_para_limit, config.char_limit],""context_char"")\n                self.qh = tf.placeholder(tf.int32, [None, config.test_ques_limit, config.char_limit],""question_char"")\n                self.y1 = tf.placeholder(tf.int32, [None, config.test_para_limit],""answer_index1"")\n                self.y2 = tf.placeholder(tf.int32, [None, config.test_para_limit],""answer_index2"")\n            else:\n                self.c, self.q, self.ch, self.qh, self.y1, self.y2, self.qa_id = batch.get_next()\n\n            # self.word_unk = tf.get_variable(""word_unk"", shape = [config.glove_dim], initializer=initializer())\n            self.word_mat = tf.get_variable(""word_mat"", initializer=tf.constant(\n                word_mat, dtype=tf.float32), trainable=False)\n            self.char_mat = tf.get_variable(\n                ""char_mat"", initializer=tf.constant(char_mat, dtype=tf.float32))\n\n            self.c_mask = tf.cast(self.c, tf.bool)\n            self.q_mask = tf.cast(self.q, tf.bool)\n            self.c_len = tf.reduce_sum(tf.cast(self.c_mask, tf.int32), axis=1)\n            self.q_len = tf.reduce_sum(tf.cast(self.q_mask, tf.int32), axis=1)\n\n            if opt:\n                N, CL = config.batch_size if not self.demo else 1, config.char_limit\n                self.c_maxlen = tf.reduce_max(self.c_len)\n                self.q_maxlen = tf.reduce_max(self.q_len)\n                self.c = tf.slice(self.c, [0, 0], [N, self.c_maxlen])\n                self.q = tf.slice(self.q, [0, 0], [N, self.q_maxlen])\n                self.c_mask = tf.slice(self.c_mask, [0, 0], [N, self.c_maxlen])\n                self.q_mask = tf.slice(self.q_mask, [0, 0], [N, self.q_maxlen])\n                self.ch = tf.slice(self.ch, [0, 0, 0], [N, self.c_maxlen, CL])\n                self.qh = tf.slice(self.qh, [0, 0, 0], [N, self.q_maxlen, CL])\n                self.y1 = tf.slice(self.y1, [0, 0], [N, self.c_maxlen])\n                self.y2 = tf.slice(self.y2, [0, 0], [N, self.c_maxlen])\n            else:\n                self.c_maxlen, self.q_maxlen = config.para_limit, config.ques_limit\n\n            self.ch_len = tf.reshape(tf.reduce_sum(\n                tf.cast(tf.cast(self.ch, tf.bool), tf.int32), axis=2), [-1])\n            self.qh_len = tf.reshape(tf.reduce_sum(\n                tf.cast(tf.cast(self.qh, tf.bool), tf.int32), axis=2), [-1])\n\n            self.forward()\n            total_params()\n\n            if trainable:\n                self.lr = tf.minimum(config.learning_rate, 0.001 / tf.log(999.) * tf.log(tf.cast(self.global_step, tf.float32) + 1))\n                self.opt = tf.train.AdamOptimizer(learning_rate = self.lr, beta1 = 0.8, beta2 = 0.999, epsilon = 1e-7)\n                grads = self.opt.compute_gradients(self.loss)\n                gradients, variables = zip(*grads)\n                capped_grads, _ = tf.clip_by_global_norm(\n                    gradients, config.grad_clip)\n                self.train_op = self.opt.apply_gradients(\n                    zip(capped_grads, variables), global_step=self.global_step)\n\n    def forward(self):\n        config = self.config\n        N, PL, QL, CL, d, dc, nh = config.batch_size if not self.demo else 1, self.c_maxlen, self.q_maxlen, config.char_limit, config.hidden, config.char_dim, config.num_heads\n\n        with tf.variable_scope(""Input_Embedding_Layer""):\n            ch_emb = tf.reshape(tf.nn.embedding_lookup(\n                self.char_mat, self.ch), [N * PL, CL, dc])\n            qh_emb = tf.reshape(tf.nn.embedding_lookup(\n                self.char_mat, self.qh), [N * QL, CL, dc])\n            ch_emb = tf.nn.dropout(ch_emb, 1.0 - 0.5 * self.dropout)\n            qh_emb = tf.nn.dropout(qh_emb, 1.0 - 0.5 * self.dropout)\n\n\t\t\t# Bidaf style conv-highway encoder\n            ch_emb = conv(ch_emb, d,\n                bias = True, activation = tf.nn.relu, kernel_size = 5, name = ""char_conv"", reuse = None)\n            qh_emb = conv(qh_emb, d,\n                bias = True, activation = tf.nn.relu, kernel_size = 5, name = ""char_conv"", reuse = True)\n\n            ch_emb = tf.reduce_max(ch_emb, axis = 1)\n            qh_emb = tf.reduce_max(qh_emb, axis = 1)\n\n            ch_emb = tf.reshape(ch_emb, [N, PL, ch_emb.shape[-1]])\n            qh_emb = tf.reshape(qh_emb, [N, QL, ch_emb.shape[-1]])\n\n            c_emb = tf.nn.dropout(tf.nn.embedding_lookup(self.word_mat, self.c), 1.0 - self.dropout)\n            q_emb = tf.nn.dropout(tf.nn.embedding_lookup(self.word_mat, self.q), 1.0 - self.dropout)\n\n            c_emb = tf.concat([c_emb, ch_emb], axis=2)\n            q_emb = tf.concat([q_emb, qh_emb], axis=2)\n\n            c_emb = highway(c_emb, size = d, scope = ""highway"", dropout = self.dropout, reuse = None)\n            q_emb = highway(q_emb, size = d, scope = ""highway"", dropout = self.dropout, reuse = True)\n\n        with tf.variable_scope(""Embedding_Encoder_Layer""):\n            c = residual_block(c_emb,\n                num_blocks = 1,\n                num_conv_layers = 4,\n                kernel_size = 7,\n                mask = self.c_mask,\n                num_filters = d,\n                num_heads = nh,\n                seq_len = self.c_len,\n                scope = ""Encoder_Residual_Block"",\n                bias = False,\n                dropout = self.dropout)\n            q = residual_block(q_emb,\n                num_blocks = 1,\n                num_conv_layers = 4,\n                kernel_size = 7,\n                mask = self.q_mask,\n                num_filters = d,\n                num_heads = nh,\n                seq_len = self.q_len,\n                scope = ""Encoder_Residual_Block"",\n                reuse = True, # Share the weights between passage and question\n                bias = False,\n                dropout = self.dropout)\n\n        with tf.variable_scope(""Context_to_Query_Attention_Layer""):\n            # C = tf.tile(tf.expand_dims(c,2),[1,1,self.q_maxlen,1])\n            # Q = tf.tile(tf.expand_dims(q,1),[1,self.c_maxlen,1,1])\n            # S = trilinear([C, Q, C*Q], input_keep_prob = 1.0 - self.dropout)\n            S = optimized_trilinear_for_attention([c, q], self.c_maxlen, self.q_maxlen, input_keep_prob = 1.0 - self.dropout)\n            mask_q = tf.expand_dims(self.q_mask, 1)\n            S_ = tf.nn.softmax(mask_logits(S, mask = mask_q))\n            mask_c = tf.expand_dims(self.c_mask, 2)\n            S_T = tf.transpose(tf.nn.softmax(mask_logits(S, mask = mask_c), dim = 1),(0,2,1))\n            self.c2q = tf.matmul(S_, q)\n            self.q2c = tf.matmul(tf.matmul(S_, S_T), c)\n            attention_outputs = [c, self.c2q, c * self.c2q, c * self.q2c]\n\n        with tf.variable_scope(""Model_Encoder_Layer""):\n            inputs = tf.concat(attention_outputs, axis = -1)\n            self.enc = [conv(inputs, d, name = ""input_projection"")]\n            for i in range(3):\n                if i % 2 == 0: # dropout every 2 blocks\n                    self.enc[i] = tf.nn.dropout(self.enc[i], 1.0 - self.dropout)\n                self.enc.append(\n                    residual_block(self.enc[i],\n                        num_blocks = 7,\n                        num_conv_layers = 2,\n                        kernel_size = 5,\n                        mask = self.c_mask,\n                        num_filters = d,\n                        num_heads = nh,\n                        seq_len = self.c_len,\n                        scope = ""Model_Encoder"",\n                        bias = False,\n                        reuse = True if i > 0 else None,\n                        dropout = self.dropout)\n                    )\n\n        with tf.variable_scope(""Output_Layer""):\n            start_logits = tf.squeeze(conv(tf.concat([self.enc[1], self.enc[2]],axis = -1),1, bias = False, name = ""start_pointer""),-1)\n            end_logits = tf.squeeze(conv(tf.concat([self.enc[1], self.enc[3]],axis = -1),1, bias = False, name = ""end_pointer""), -1)\n            self.logits = [mask_logits(start_logits, mask = self.c_mask),\n                           mask_logits(end_logits, mask = self.c_mask)]\n\n            logits1, logits2 = [l for l in self.logits]\n\n            outer = tf.matmul(tf.expand_dims(tf.nn.softmax(logits1), axis=2),\n                              tf.expand_dims(tf.nn.softmax(logits2), axis=1))\n            outer = tf.matrix_band_part(outer, 0, config.ans_limit)\n            self.yp1 = tf.argmax(tf.reduce_max(outer, axis=2), axis=1)\n            self.yp2 = tf.argmax(tf.reduce_max(outer, axis=1), axis=1)\n            losses = tf.nn.softmax_cross_entropy_with_logits(\n                logits=logits1, labels=self.y1)\n            losses2 = tf.nn.softmax_cross_entropy_with_logits(\n                logits=logits2, labels=self.y2)\n            self.loss = tf.reduce_mean(losses + losses2)\n\n        if config.l2_norm is not None:\n            variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n            l2_loss = tf.contrib.layers.apply_regularization(regularizer, variables)\n            self.loss += l2_loss\n\n        if config.decay is not None:\n            self.var_ema = tf.train.ExponentialMovingAverage(config.decay)\n            ema_op = self.var_ema.apply(tf.trainable_variables())\n            with tf.control_dependencies([ema_op]):\n                self.loss = tf.identity(self.loss)\n\n                self.assign_vars = []\n                for var in tf.global_variables():\n                    v = self.var_ema.average(var)\n                    if v:\n                        self.assign_vars.append(tf.assign(var,v))\n\n    def get_loss(self):\n        return self.loss\n\n    def get_global_step(self):\n        return self.global_step\n'"
prepro.py,9,"b'import tensorflow as tf\nimport random\nfrom tqdm import tqdm\nimport spacy\nimport ujson as json\nfrom collections import Counter\nimport numpy as np\nfrom codecs import open\n\n\'\'\'\nThis file is taken and modified from R-Net by HKUST-KnowComp\nhttps://github.com/HKUST-KnowComp/R-Net\n\'\'\'\n\nnlp = spacy.blank(""en"")\n\n\ndef word_tokenize(sent):\n    doc = nlp(sent)\n    return [token.text for token in doc]\n\n\ndef convert_idx(text, tokens):\n    current = 0\n    spans = []\n    for token in tokens:\n        current = text.find(token, current)\n        if current < 0:\n            print(""Token {} cannot be found"".format(token))\n            raise Exception()\n        spans.append((current, current + len(token)))\n        current += len(token)\n    return spans\n\n\ndef process_file(filename, data_type, word_counter, char_counter):\n    print(""Generating {} examples..."".format(data_type))\n    examples = []\n    eval_examples = {}\n    total = 0\n    with open(filename, ""r"") as fh:\n        source = json.load(fh)\n        for article in tqdm(source[""data""]):\n            for para in article[""paragraphs""]:\n                context = para[""context""].replace(\n                    ""\'\'"", \'"" \').replace(""``"", \'"" \')\n                context_tokens = word_tokenize(context)\n                context_chars = [list(token) for token in context_tokens]\n                spans = convert_idx(context, context_tokens)\n                for token in context_tokens:\n                    word_counter[token] += len(para[""qas""])\n                    for char in token:\n                        char_counter[char] += len(para[""qas""])\n                for qa in para[""qas""]:\n                    total += 1\n                    ques = qa[""question""].replace(\n                        ""\'\'"", \'"" \').replace(""``"", \'"" \')\n                    ques_tokens = word_tokenize(ques)\n                    ques_chars = [list(token) for token in ques_tokens]\n                    for token in ques_tokens:\n                        word_counter[token] += 1\n                        for char in token:\n                            char_counter[char] += 1\n                    y1s, y2s = [], []\n                    answer_texts = []\n                    for answer in qa[""answers""]:\n                        answer_text = answer[""text""]\n                        answer_start = answer[\'answer_start\']\n                        answer_end = answer_start + len(answer_text)\n                        answer_texts.append(answer_text)\n                        answer_span = []\n                        for idx, span in enumerate(spans):\n                            if not (answer_end <= span[0] or answer_start >= span[1]):\n                                answer_span.append(idx)\n                        y1, y2 = answer_span[0], answer_span[-1]\n                        y1s.append(y1)\n                        y2s.append(y2)\n                    example = {""context_tokens"": context_tokens, ""context_chars"": context_chars, ""ques_tokens"": ques_tokens,\n                               ""ques_chars"": ques_chars, ""y1s"": y1s, ""y2s"": y2s, ""id"": total}\n                    examples.append(example)\n                    eval_examples[str(total)] = {\n                        ""context"": context, ""spans"": spans, ""answers"": answer_texts, ""uuid"": qa[""id""]}\n        random.shuffle(examples)\n        print(""{} questions in total"".format(len(examples)))\n    return examples, eval_examples\n\n\ndef get_embedding(counter, data_type, limit=-1, emb_file=None, size=None, vec_size=None):\n    print(""Generating {} embedding..."".format(data_type))\n    embedding_dict = {}\n    filtered_elements = [k for k, v in counter.items() if v > limit]\n    if emb_file is not None:\n        assert size is not None\n        assert vec_size is not None\n        with open(emb_file, ""r"", encoding=""utf-8"") as fh:\n            for line in tqdm(fh, total=size):\n                array = line.split()\n                word = """".join(array[0:-vec_size])\n                vector = list(map(float, array[-vec_size:]))\n                if word in counter and counter[word] > limit:\n                    embedding_dict[word] = vector\n        print(""{} / {} tokens have corresponding {} embedding vector"".format(\n            len(embedding_dict), len(filtered_elements), data_type))\n    else:\n        assert vec_size is not None\n        for token in filtered_elements:\n            embedding_dict[token] = [np.random.normal(\n                scale=0.1) for _ in range(vec_size)]\n        print(""{} tokens have corresponding embedding vector"".format(\n            len(filtered_elements)))\n\n    NULL = ""--NULL--""\n    OOV = ""--OOV--""\n    token2idx_dict = {token: idx for idx,\n                      token in enumerate(embedding_dict.keys(), 2)}\n    token2idx_dict[NULL] = 0\n    token2idx_dict[OOV] = 1\n    embedding_dict[NULL] = [0. for _ in range(vec_size)]\n    embedding_dict[OOV] = [0. for _ in range(vec_size)]\n    idx2emb_dict = {idx: embedding_dict[token]\n                    for token, idx in token2idx_dict.items()}\n    emb_mat = [idx2emb_dict[idx] for idx in range(len(idx2emb_dict))]\n    return emb_mat, token2idx_dict\n\ndef convert_to_features(config, data, word2idx_dict, char2idx_dict):\n\n    example = {}\n    context, question = data\n    context = context.replace(""\'\'"", \'"" \').replace(""``"", \'"" \')\n    question = question.replace(""\'\'"", \'"" \').replace(""``"", \'"" \')\n    example[\'context_tokens\'] = word_tokenize(context)\n    example[\'ques_tokens\'] = word_tokenize(question)\n    example[\'context_chars\'] = [list(token) for token in example[\'context_tokens\']]\n    example[\'ques_chars\'] = [list(token) for token in example[\'ques_tokens\']]\n\n    para_limit = config.test_para_limit\n    ques_limit = config.test_ques_limit\n    ans_limit = 100\n    char_limit = config.char_limit\n\n    def filter_func(example):\n        return len(example[""context_tokens""]) > para_limit or \\\n               len(example[""ques_tokens""]) > ques_limit\n\n    if filter_func(example):\n        raise ValueError(""Context/Questions lengths are over the limit"")\n\n    context_idxs = np.zeros([para_limit], dtype=np.int32)\n    context_char_idxs = np.zeros([para_limit, char_limit], dtype=np.int32)\n    ques_idxs = np.zeros([ques_limit], dtype=np.int32)\n    ques_char_idxs = np.zeros([ques_limit, char_limit], dtype=np.int32)\n    y1 = np.zeros([para_limit], dtype=np.float32)\n    y2 = np.zeros([para_limit], dtype=np.float32)\n\n    def _get_word(word):\n        for each in (word, word.lower(), word.capitalize(), word.upper()):\n            if each in word2idx_dict:\n                return word2idx_dict[each]\n        return 1\n\n    def _get_char(char):\n        if char in char2idx_dict:\n            return char2idx_dict[char]\n        return 1\n\n    for i, token in enumerate(example[""context_tokens""]):\n        context_idxs[i] = _get_word(token)\n\n    for i, token in enumerate(example[""ques_tokens""]):\n        ques_idxs[i] = _get_word(token)\n\n    for i, token in enumerate(example[""context_chars""]):\n        for j, char in enumerate(token):\n            if j == char_limit:\n                break\n            context_char_idxs[i, j] = _get_char(char)\n\n    for i, token in enumerate(example[""ques_chars""]):\n        for j, char in enumerate(token):\n            if j == char_limit:\n                break\n            ques_char_idxs[i, j] = _get_char(char)\n\n    return context_idxs, context_char_idxs, ques_idxs, ques_char_idxs\n\ndef build_features(config, examples, data_type, out_file, word2idx_dict, char2idx_dict, is_test=False):\n\n    para_limit = config.test_para_limit if is_test else config.para_limit\n    ques_limit = config.test_ques_limit if is_test else config.ques_limit\n    ans_limit = 100 if is_test else config.ans_limit\n    char_limit = config.char_limit\n\n    def filter_func(example, is_test=False):\n        return len(example[""context_tokens""]) > para_limit or \\\n               len(example[""ques_tokens""]) > ques_limit or \\\n               (example[""y2s""][0] - example[""y1s""][0]) > ans_limit\n\n    print(""Processing {} examples..."".format(data_type))\n    writer = tf.python_io.TFRecordWriter(out_file)\n    total = 0\n    total_ = 0\n    meta = {}\n    for example in tqdm(examples):\n        total_ += 1\n\n        if filter_func(example, is_test):\n            continue\n\n        total += 1\n        context_idxs = np.zeros([para_limit], dtype=np.int32)\n        context_char_idxs = np.zeros([para_limit, char_limit], dtype=np.int32)\n        ques_idxs = np.zeros([ques_limit], dtype=np.int32)\n        ques_char_idxs = np.zeros([ques_limit, char_limit], dtype=np.int32)\n        y1 = np.zeros([para_limit], dtype=np.float32)\n        y2 = np.zeros([para_limit], dtype=np.float32)\n\n        def _get_word(word):\n            for each in (word, word.lower(), word.capitalize(), word.upper()):\n                if each in word2idx_dict:\n                    return word2idx_dict[each]\n            return 1\n\n        def _get_char(char):\n            if char in char2idx_dict:\n                return char2idx_dict[char]\n            return 1\n\n        for i, token in enumerate(example[""context_tokens""]):\n            context_idxs[i] = _get_word(token)\n\n        for i, token in enumerate(example[""ques_tokens""]):\n            ques_idxs[i] = _get_word(token)\n\n        for i, token in enumerate(example[""context_chars""]):\n            for j, char in enumerate(token):\n                if j == char_limit:\n                    break\n                context_char_idxs[i, j] = _get_char(char)\n\n        for i, token in enumerate(example[""ques_chars""]):\n            for j, char in enumerate(token):\n                if j == char_limit:\n                    break\n                ques_char_idxs[i, j] = _get_char(char)\n\n        start, end = example[""y1s""][-1], example[""y2s""][-1]\n        y1[start], y2[end] = 1.0, 1.0\n\n        record = tf.train.Example(features=tf.train.Features(feature={\n                                  ""context_idxs"": tf.train.Feature(bytes_list=tf.train.BytesList(value=[context_idxs.tostring()])),\n                                  ""ques_idxs"": tf.train.Feature(bytes_list=tf.train.BytesList(value=[ques_idxs.tostring()])),\n                                  ""context_char_idxs"": tf.train.Feature(bytes_list=tf.train.BytesList(value=[context_char_idxs.tostring()])),\n                                  ""ques_char_idxs"": tf.train.Feature(bytes_list=tf.train.BytesList(value=[ques_char_idxs.tostring()])),\n                                  ""y1"": tf.train.Feature(bytes_list=tf.train.BytesList(value=[y1.tostring()])),\n                                  ""y2"": tf.train.Feature(bytes_list=tf.train.BytesList(value=[y2.tostring()])),\n                                  ""id"": tf.train.Feature(int64_list=tf.train.Int64List(value=[example[""id""]]))\n                                  }))\n        writer.write(record.SerializeToString())\n    print(""Built {} / {} instances of features in total"".format(total, total_))\n    meta[""total""] = total\n    writer.close()\n    return meta\n\n\ndef save(filename, obj, message=None):\n    if message is not None:\n        print(""Saving {}..."".format(message))\n        with open(filename, ""w"") as fh:\n            json.dump(obj, fh)\n\n\ndef prepro(config):\n    word_counter, char_counter = Counter(), Counter()\n    train_examples, train_eval = process_file(\n        config.train_file, ""train"", word_counter, char_counter)\n    dev_examples, dev_eval = process_file(\n        config.dev_file, ""dev"", word_counter, char_counter)\n    test_examples, test_eval = process_file(\n        config.test_file, ""test"", word_counter, char_counter)\n\n    word_emb_file = config.fasttext_file if config.fasttext else config.glove_word_file\n    char_emb_file = config.glove_char_file if config.pretrained_char else None\n    char_emb_size = config.glove_char_size if config.pretrained_char else None\n    char_emb_dim = config.glove_dim if config.pretrained_char else config.char_dim\n\n    word_emb_mat, word2idx_dict = get_embedding(\n        word_counter, ""word"", emb_file=word_emb_file, size=config.glove_word_size, vec_size=config.glove_dim)\n    char_emb_mat, char2idx_dict = get_embedding(\n        char_counter, ""char"", emb_file=char_emb_file, size=char_emb_size, vec_size=char_emb_dim)\n\n    build_features(config, train_examples, ""train"",\n                   config.train_record_file, word2idx_dict, char2idx_dict)\n    dev_meta = build_features(config, dev_examples, ""dev"",\n                              config.dev_record_file, word2idx_dict, char2idx_dict)\n    test_meta = build_features(config, test_examples, ""test"",\n                               config.test_record_file, word2idx_dict, char2idx_dict, is_test=True)\n\n    save(config.word_emb_file, word_emb_mat, message=""word embedding"")\n    save(config.char_emb_file, char_emb_mat, message=""char embedding"")\n    save(config.train_eval_file, train_eval, message=""train eval"")\n    save(config.dev_eval_file, dev_eval, message=""dev eval"")\n    save(config.test_eval_file, test_eval, message=""test eval"")\n    save(config.dev_meta, dev_meta, message=""dev meta"")\n    save(config.test_meta, test_meta, message=""test meta"")\n    save(config.word_dictionary, word2idx_dict, message=""word dictionary"")\n    save(config.char_dictionary, char2idx_dict, message=""char dictionary"")\n'"
util.py,30,"b'import tensorflow as tf\nimport re\nfrom collections import Counter\nimport string\n\n\'\'\'\nThis file is taken and modified from R-Net by HKUST-KnowComp\nhttps://github.com/HKUST-KnowComp/R-Net\n\'\'\'\n\n\ndef get_record_parser(config, is_test=False):\n    def parse(example):\n        para_limit = config.test_para_limit if is_test else config.para_limit\n        ques_limit = config.test_ques_limit if is_test else config.ques_limit\n        char_limit = config.char_limit\n        features = tf.parse_single_example(example,\n                                           features={\n                                               ""context_idxs"": tf.FixedLenFeature([], tf.string),\n                                               ""ques_idxs"": tf.FixedLenFeature([], tf.string),\n                                               ""context_char_idxs"": tf.FixedLenFeature([], tf.string),\n                                               ""ques_char_idxs"": tf.FixedLenFeature([], tf.string),\n                                               ""y1"": tf.FixedLenFeature([], tf.string),\n                                               ""y2"": tf.FixedLenFeature([], tf.string),\n                                               ""id"": tf.FixedLenFeature([], tf.int64)\n                                           })\n        context_idxs = tf.reshape(tf.decode_raw(\n            features[""context_idxs""], tf.int32), [para_limit])\n        ques_idxs = tf.reshape(tf.decode_raw(\n            features[""ques_idxs""], tf.int32), [ques_limit])\n        context_char_idxs = tf.reshape(tf.decode_raw(\n            features[""context_char_idxs""], tf.int32), [para_limit, char_limit])\n        ques_char_idxs = tf.reshape(tf.decode_raw(\n            features[""ques_char_idxs""], tf.int32), [ques_limit, char_limit])\n        y1 = tf.reshape(tf.decode_raw(\n            features[""y1""], tf.float32), [para_limit])\n        y2 = tf.reshape(tf.decode_raw(\n            features[""y2""], tf.float32), [para_limit])\n        qa_id = features[""id""]\n        return context_idxs, ques_idxs, context_char_idxs, ques_char_idxs, y1, y2, qa_id\n    return parse\n\n\ndef get_batch_dataset(record_file, parser, config):\n    num_threads = tf.constant(config.num_threads, dtype=tf.int32)\n    dataset = tf.data.TFRecordDataset(record_file).map(\n        parser, num_parallel_calls=num_threads).shuffle(config.capacity).repeat()\n    if config.is_bucket:\n        buckets = [tf.constant(num) for num in range(*config.bucket_range)]\n\n        def key_func(context_idxs, ques_idxs, context_char_idxs, ques_char_idxs, y1, y2, qa_id):\n            c_len = tf.reduce_sum(\n                tf.cast(tf.cast(context_idxs, tf.bool), tf.int32))\n            t = tf.clip_by_value(buckets, 0, c_len)\n            return tf.argmax(t)\n\n        def reduce_func(key, elements):\n            return elements.batch(config.batch_size)\n\n        dataset = dataset.apply(tf.contrib.data.group_by_window(\n            key_func, reduce_func, window_size=5 * config.batch_size)).shuffle(len(buckets) * 25)\n    else:\n        dataset = dataset.batch(config.batch_size)\n    return dataset\n\n\ndef get_dataset(record_file, parser, config):\n    num_threads = tf.constant(config.num_threads, dtype=tf.int32)\n    dataset = tf.data.TFRecordDataset(record_file).map(\n        parser, num_parallel_calls=num_threads).repeat().batch(config.batch_size)\n    return dataset\n\n\ndef convert_tokens(eval_file, qa_id, pp1, pp2):\n    answer_dict = {}\n    remapped_dict = {}\n    for qid, p1, p2 in zip(qa_id, pp1, pp2):\n        context = eval_file[str(qid)][""context""]\n        spans = eval_file[str(qid)][""spans""]\n        uuid = eval_file[str(qid)][""uuid""]\n        start_idx = spans[p1][0]\n        end_idx = spans[p2][1]\n        answer_dict[str(qid)] = context[start_idx: end_idx]\n        remapped_dict[uuid] = context[start_idx: end_idx]\n    return answer_dict, remapped_dict\n\n\ndef evaluate(eval_file, answer_dict):\n    f1 = exact_match = total = 0\n    for key, value in answer_dict.items():\n        total += 1\n        ground_truths = eval_file[key][""answers""]\n        prediction = value\n        exact_match += metric_max_over_ground_truths(\n            exact_match_score, prediction, ground_truths)\n        f1 += metric_max_over_ground_truths(f1_score,\n                                            prediction, ground_truths)\n    exact_match = 100.0 * exact_match / total\n    f1 = 100.0 * f1 / total\n    return {\'exact_match\': exact_match, \'f1\': f1}\n\n\ndef normalize_answer(s):\n\n    def remove_articles(text):\n        return re.sub(r\'\\b(a|an|the)\\b\', \' \', text)\n\n    def white_space_fix(text):\n        return \' \'.join(text.split())\n\n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return \'\'.join(ch for ch in text if ch not in exclude)\n\n    def lower(text):\n        return text.lower()\n\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\n\n\ndef f1_score(prediction, ground_truth):\n    prediction_tokens = normalize_answer(prediction).split()\n    ground_truth_tokens = normalize_answer(ground_truth).split()\n    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n    num_same = sum(common.values())\n    if num_same == 0:\n        return 0\n    precision = 1.0 * num_same / len(prediction_tokens)\n    recall = 1.0 * num_same / len(ground_truth_tokens)\n    f1 = (2 * precision * recall) / (precision + recall)\n    return f1\n\n\ndef exact_match_score(prediction, ground_truth):\n    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n\n\ndef metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n    scores_for_ground_truths = []\n    for ground_truth in ground_truths:\n        score = metric_fn(prediction, ground_truth)\n        scores_for_ground_truths.append(score)\n    return max(scores_for_ground_truths)\n'"
