file_path,api_count,code
setup.py,0,"b""from setuptools import find_packages, setup\n\nsetup(\n    name='tf_trt_models',\n    version='0.0',\n    description='TensorFlow models accelerated with NVIDIA TensorRT',\n    author='',\n    author_email='',\n    url='https://github.com/NVIDIA-Jetson/tf_trt_models',\n    packages=find_packages(),\n)\n"""
tf_trt_models/__init__.py,0,b''
tf_trt_models/classification.py,26,"b'from collections import namedtuple\n\nfrom .graph_utils import convert_relu6\n\nimport nets\nimport nets.inception\nimport nets.mobilenet_v1\nimport nets.resnet_v1\nimport nets.resnet_v2\nimport nets.vgg\n\nimport os\nimport subprocess\nimport tarfile\n\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\nNetDef = namedtuple(\'NetDef\', [\'model\', \'arg_scope\', \'input_width\',\n                    \'input_height\', \'preprocess\', \'postprocess\', \'url\', \'checkpoint_name\',\n                    \'num_classes\'])\n\n\ndef _mobilenet_v1_1p0_224(*args, **kwargs):\n    kwargs[\'depth_multiplier\'] = 1.0\n    return nets.mobilenet_v1.mobilenet_v1(*args, **kwargs)\n\n\ndef _mobilenet_v1_0p5_160(*args, **kwargs):\n    kwargs[\'depth_multiplier\'] = 0.5\n    return nets.mobilenet_v1.mobilenet_v1(*args, **kwargs)\n\n\ndef _mobilenet_v1_0p25_128(*args, **kwargs):\n    kwargs[\'depth_multiplier\'] = 0.25\n    return nets.mobilenet_v1.mobilenet_v1(*args, **kwargs)\n\n\ndef _preprocess_vgg(x):\n    tf_x_float = tf.cast(x, tf.float32)\n    tf_mean = tf.constant([123.68, 116.78, 103.94], tf.float32)\n    return tf.subtract(tf_x_float, tf_mean)\n\n\ndef _preprocess_inception(x):\n    tf_x_float = tf.cast(x, tf.float32)\n    return 2.0 * (tf_x_float / 255.0 - 0.5)\n\n\ninput_name = \'input\'\noutput_name = \'scores\'\nNETS = {\n    \'mobilenet_v1_0p25_128\':\n    NetDef(_mobilenet_v1_0p25_128,\n           nets.mobilenet_v1.mobilenet_v1_arg_scope, 128, 128,\n           _preprocess_inception, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_0.25_128.tgz\',\n           \'mobilenet_v1_0.25_128.ckpt\', 1001),\n    \'mobilenet_v1_0p5_160\':\n    NetDef(_mobilenet_v1_0p5_160, nets.mobilenet_v1.mobilenet_v1_arg_scope,\n           160, 160, _preprocess_inception, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_0.5_160.tgz\',\n           \'mobilenet_v1_0.5_160.ckpt\', 1001),\n    \'mobilenet_v1_1p0_224\':\n    NetDef(_mobilenet_v1_1p0_224, nets.mobilenet_v1.mobilenet_v1_arg_scope,\n           224, 224, _preprocess_inception, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz\',\n           \'mobilenet_v1_1.0_224.ckpt\', 1001),\n    \'vgg_16\':\n    NetDef(nets.vgg.vgg_16, nets.vgg.vgg_arg_scope, 224, 224,\n           _preprocess_vgg, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz\',\n           \'vgg_16.ckpt\', 1000),\n    \'vgg_19\':\n    NetDef(nets.vgg.vgg_19, nets.vgg.vgg_arg_scope, 224, 224,\n           _preprocess_vgg, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz\',\n           \'vgg_19.ckpt\', 1000),\n    \'inception_v1\':\n    NetDef(nets.inception.inception_v1, nets.inception.inception_v1_arg_scope,\n           224, 224, _preprocess_inception, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/inception_v1_2016_08_28.tar.gz\',\n           \'inception_v1.ckpt\', 1001),\n    \'inception_v2\':\n    NetDef(nets.inception.inception_v2, nets.inception.inception_v2_arg_scope,\n           224, 224, _preprocess_inception, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/inception_v2_2016_08_28.tar.gz\',\n           \'inception_v2.ckpt\', 1001),\n    \'inception_v3\':\n    NetDef(nets.inception.inception_v3, nets.inception.inception_v3_arg_scope,\n           299, 299, _preprocess_inception, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\',\n           \'inception_v3.ckpt\', 1001),\n    \'inception_v4\':\n    NetDef(nets.inception.inception_v4, nets.inception.inception_v4_arg_scope,\n           299, 299, _preprocess_inception, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/inception_v4_2016_09_09.tar.gz\',\n           \'inception_v4.ckpt\', 1001),\n    \'inception_resnet_v2\':\n    NetDef(nets.inception.inception_resnet_v2,\n           nets.inception.inception_resnet_v2_arg_scope, 299, 299,\n           _preprocess_inception, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz\',\n           \'inception_resnet_v2_2016_08_30.ckpt\', 1001),\n    \'resnet_v1_50\':\n    NetDef(nets.resnet_v1.resnet_v1_50, nets.resnet_v1.resnet_arg_scope,\n           224, 224, _preprocess_vgg, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz\',\n           \'resnet_v1_50.ckpt\', 1000),\n    \'resnet_v1_101\':\n    NetDef(nets.resnet_v1.resnet_v1_101, nets.resnet_v1.resnet_arg_scope,\n           224, 224, _preprocess_vgg, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/resnet_v1_101_2016_08_28.tar.gz\',\n           \'resnet_v1_101.ckpt\', 1000),\n    \'resnet_v1_152\':\n    NetDef(nets.resnet_v1.resnet_v1_152, nets.resnet_v1.resnet_arg_scope,\n           224, 224, _preprocess_vgg, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/resnet_v1_152_2016_08_28.tar.gz\',\n           \'resnet_v1_152.ckpt\', 1000),\n    \'resnet_v2_50\':\n    NetDef(nets.resnet_v2.resnet_v2_50, nets.resnet_v2.resnet_arg_scope,\n           299, 299, _preprocess_inception, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/resnet_v2_50_2017_04_14.tar.gz\',\n           \'resnet_v2_50.ckpt\', 1001),\n    \'resnet_v2_101\':\n    NetDef(nets.resnet_v2.resnet_v2_101, nets.resnet_v2.resnet_arg_scope,\n           299, 299, _preprocess_inception, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/resnet_v2_101_2017_04_14.tar.gz\',\n           \'resnet_v2_101.ckpt\', 1001),\n    \'resnet_v2_152\':\n    NetDef(nets.resnet_v2.resnet_v2_152, nets.resnet_v2.resnet_arg_scope,\n           299, 299, _preprocess_inception, tf.nn.softmax,\n           \'http://download.tensorflow.org/models/resnet_v2_152_2017_04_14.tar.gz\',\n           \'resnet_v2_152.ckpt\', 1001),\n}\n\n\ndef download_classification_checkpoint(model, output_dir=\'.\'):\n    """"""Downloads an image classification model pretrained checkpoint by name\n\n    :param model: the model name (see table)\n    :type model: string\n    :param output_dir: the directory where files are downloaded to\n    :type output_dir: string\n    :return checkpoint_path:  path to the checkpoint file containing trained model params\n    :rtype string\n    """"""\n    global NETS, input_name, output_name\n    checkpoint_path = \'\'\n\n    if not os.path.exists(output_dir):\n      os.makedirs(output_dir)\n\n    modeldir_path = os.path.join(output_dir, model)\n    if not os.path.exists(modeldir_path):\n      os.makedirs(modeldir_path)\n\n    modeltar_path = os.path.join(output_dir, os.path.basename(NETS[model].url))\n    if not os.path.isfile(modeltar_path):\n        subprocess.call([\'wget\', \'--no-check-certificate\', NETS[model].url, \'-O\', modeltar_path])\n     \n    checkpoint_path = os.path.join(modeldir_path, NETS[model].checkpoint_name)\n    if not os.path.isfile(checkpoint_path):\n        subprocess.call([\'tar\', \'-xzf\', modeltar_path, \'-C\', modeldir_path])\n\n    return checkpoint_path\n\n\ndef build_classification_graph(model, checkpoint, num_classes):\n    """"""Builds an image classification model by name\n\n    This function builds an image classification model given a model\n    name, parameter checkpoint file path, and number of classes.  This\n    function performs some graph processing (such as replacing relu6(x)\n    operations with relu(x) - relu(x-6)) to produce a graph that is\n    well optimized by the TensorRT package in TensorFlow 1.7+.\n\n    :param model: the model name (see table)\n    :type model: string\n    :param checkpoint: the checkpoint file path\n    :type checkpoint: string\n    :param num_classes: the number of output classes\n    :type num_classes: integer\n\n    :returns: the TensorRT compatible frozen graph\n    :rtype: a tensorflow.GraphDef\n    """"""\n    global NETS, input_name, output_name\n\n    net = NETS[model]\n    tf_config = tf.ConfigProto()\n    tf_config.gpu_options.allow_growth = True\n\n    with tf.Graph().as_default() as tf_graph:\n        with tf.Session(config=tf_config) as tf_sess:\n\n            tf_input = tf.placeholder(tf.float32, [None, net.input_height, net.input_width, 3],\n                    name=input_name)\n            tf_preprocessed = net.preprocess(tf_input)\n\n            with slim.arg_scope(net.arg_scope()):\n                tf_net, tf_end_points = net.model(tf_preprocessed, is_training=False,\n                    num_classes=num_classes)\n\n            tf_output = net.postprocess(tf_net, name=output_name)\n\n            # load checkpoint\n            tf_saver = tf.train.Saver()\n            tf_saver.restore(save_path=checkpoint, sess=tf_sess)\n\n            # freeze graph\n            frozen_graph = tf.graph_util.convert_variables_to_constants(\n                tf_sess,\n                tf_sess.graph_def,\n                output_node_names=[output_name]\n            )\n\n            # remove relu 6\n            frozen_graph = convert_relu6(frozen_graph)\n\n    return frozen_graph, [input_name], [output_name]\n'"
tf_trt_models/detection.py,4,"b'from object_detection.protos import pipeline_pb2\nfrom object_detection.protos import image_resizer_pb2\nfrom object_detection import exporter\n\nimport os\nimport subprocess\n\nfrom collections import namedtuple\nfrom google.protobuf import text_format\n\nimport tensorflow as tf\n\nfrom .graph_utils import force_nms_cpu as f_force_nms_cpu\nfrom .graph_utils import replace_relu6 as f_replace_relu6\nfrom .graph_utils import remove_assert as f_remove_assert\n\nDetectionModel = namedtuple(\'DetectionModel\', [\'name\', \'url\', \'extract_dir\'])\n\nINPUT_NAME=\'image_tensor\'\nBOXES_NAME=\'detection_boxes\'\nCLASSES_NAME=\'detection_classes\'\nSCORES_NAME=\'detection_scores\'\nMASKS_NAME=\'detection_masks\'\nNUM_DETECTIONS_NAME=\'num_detections\'\nFROZEN_GRAPH_NAME=\'frozen_inference_graph.pb\'\nPIPELINE_CONFIG_NAME=\'pipeline.config\'\nCHECKPOINT_PREFIX=\'model.ckpt\'\n\n\nMODELS = {\n    \'ssd_mobilenet_v1_coco\': DetectionModel(\n        \'ssd_mobilenet_v1_coco\',\n        \'http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz\',\n        \'ssd_mobilenet_v1_coco_2018_01_28\',\n    ),\n    \'ssd_mobilenet_v2_coco\': DetectionModel(\n        \'ssd_mobilenet_v2_coco\',\n        \'http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\',\n        \'ssd_mobilenet_v2_coco_2018_03_29\',\n    ),\n    \'ssd_inception_v2_coco\': DetectionModel(\n        \'ssd_inception_v2_coco\',\n        \'http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\',\n        \'ssd_inception_v2_coco_2018_01_28\',\n    ),\n    \'ssd_resnet_50_fpn_coco\': DetectionModel(\n        \'ssd_resnet_50_fpn_coco\',\n        \'http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\',\n        \'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03\',\n    ),\n    \'faster_rcnn_resnet50_coco\': DetectionModel(\n        \'faster_rcnn_resnet50_coco\',\n        \'http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz\',\n        \'faster_rcnn_resnet50_coco_2018_01_28\',\n    ),\n    \'faster_rcnn_nas\': DetectionModel(\n        \'faster_rcnn_nas\',\n        \'http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_coco_2018_01_28.tar.gz\',\n        \'faster_rcnn_nas_coco_2018_01_28\',\n    ),\n    \'mask_rcnn_resnet50_atrous_coco\': DetectionModel(\n        \'mask_rcnn_resnet50_atrous_coco\',\n        \'http://download.tensorflow.org/models/object_detection/mask_rcnn_resnet50_atrous_coco_2018_01_28.tar.gz\',\n        \'mask_rcnn_resnet50_atrous_coco_2018_01_28\',\n    )\n}\n\n\ndef get_input_names(model):\n    return [INPUT_NAME]\n\n\ndef get_output_names(model):\n    output_names = [BOXES_NAME, CLASSES_NAME, SCORES_NAME, NUM_DETECTIONS_NAME]\n    if model == \'mask_rcnn_resnet50_atrous_coco\':\n        output_names.append(MASKS_NAME)\n    return output_names\n\n\ndef download_detection_model(model, output_dir=\'.\'):\n    """"""Downloads a pre-trained object detection model""""""\n    global MODELS\n\n    model_name = model\n\n    model = MODELS[model_name]\n    subprocess.call([\'mkdir\', \'-p\', output_dir])\n    tar_file = os.path.join(output_dir, os.path.basename(model.url))\n\n    config_path = os.path.join(output_dir, model.extract_dir, PIPELINE_CONFIG_NAME)\n    checkpoint_path = os.path.join(output_dir, model.extract_dir, CHECKPOINT_PREFIX)\n\n    if not os.path.exists(os.path.join(output_dir, model.extract_dir)):\n        subprocess.call([\'wget\', model.url, \'-O\', tar_file])\n        subprocess.call([\'tar\', \'-xzf\', tar_file, \'-C\', output_dir])\n\n        # hack fix to handle mobilenet_v2 config bug\n        subprocess.call([\'sed\', \'-i\', \'/batch_norm_trainable/d\', config_path])\n\n    return config_path, checkpoint_path\n\n\ndef build_detection_graph(config, checkpoint,\n        batch_size=1,\n        score_threshold=None,\n        force_nms_cpu=True,\n        replace_relu6=True,\n        remove_assert=True,\n        input_shape=None,\n        output_dir=\'.generated_model\'):\n    """"""Builds a frozen graph for a pre-trained object detection model""""""\n    \n    config_path = config\n    checkpoint_path = checkpoint\n\n    # parse config from file\n    config = pipeline_pb2.TrainEvalPipelineConfig()\n    with open(config_path, \'r\') as f:\n        text_format.Merge(f.read(), config, allow_unknown_extension=True)\n\n    # override some config parameters\n    if config.model.HasField(\'ssd\'):\n        config.model.ssd.feature_extractor.override_base_feature_extractor_hyperparams = True\n        if score_threshold is not None:\n            config.model.ssd.post_processing.batch_non_max_suppression.score_threshold = score_threshold    \n        if input_shape is not None:\n            config.model.ssd.image_resizer.fixed_shape_resizer.height = input_shape[0]\n            config.model.ssd.image_resizer.fixed_shape_resizer.width = input_shape[1]\n    elif config.model.HasField(\'faster_rcnn\'):\n        if score_threshold is not None:\n            config.model.faster_rcnn.second_stage_post_processing.score_threshold = score_threshold\n        if input_shape is not None:\n            config.model.faster_rcnn.image_resizer.fixed_shape_resizer.height = input_shape[0]\n            config.model.faster_rcnn.image_resizer.fixed_shape_resizer.width = input_shape[1]\n\n    if os.path.isdir(output_dir):\n        subprocess.call([\'rm\', \'-rf\', output_dir])\n\n    tf_config = tf.ConfigProto()\n    tf_config.gpu_options.allow_growth = True\n\n    # export inference graph to file (initial)\n    with tf.Session(config=tf_config) as tf_sess:\n        with tf.Graph().as_default() as tf_graph:\n            exporter.export_inference_graph(\n                \'image_tensor\', \n                config, \n                checkpoint_path, \n                output_dir, \n                input_shape=[batch_size, None, None, 3]\n            )\n\n    # read frozen graph from file\n    frozen_graph = tf.GraphDef()\n    with open(os.path.join(output_dir, FROZEN_GRAPH_NAME), \'rb\') as f:\n        frozen_graph.ParseFromString(f.read())\n\n    # apply graph modifications\n    if force_nms_cpu:\n        frozen_graph = f_force_nms_cpu(frozen_graph)\n    if replace_relu6:\n        frozen_graph = f_replace_relu6(frozen_graph)\n    if remove_assert:\n        frozen_graph = f_remove_assert(frozen_graph)\n\n    # get input names\n    # TODO: handle mask_rcnn \n    input_names = [INPUT_NAME]\n    output_names = [BOXES_NAME, CLASSES_NAME, SCORES_NAME, NUM_DETECTIONS_NAME]\n\n    # remove temporary directory\n    subprocess.call([\'rm\', \'-rf\', output_dir])\n\n    return frozen_graph, input_names, output_names\n'"
tf_trt_models/graph_utils.py,11,"b""import tensorflow as tf\n\n\ndef make_const6(const6_name='const6'):\n    graph = tf.Graph()\n    with graph.as_default():\n        tf_6 = tf.constant(dtype=tf.float32, value=6.0, name=const6_name)\n    return graph.as_graph_def()\n\n\ndef make_relu6(output_name, input_name, const6_name='const6'):\n    graph = tf.Graph()\n    with graph.as_default():\n        tf_x = tf.placeholder(tf.float32, [10, 10], name=input_name)\n        tf_6 = tf.constant(dtype=tf.float32, value=6.0, name=const6_name)\n        with tf.name_scope(output_name):\n            tf_y1 = tf.nn.relu(tf_x, name='relu1')\n            tf_y2 = tf.nn.relu(tf.subtract(tf_x, tf_6, name='sub1'), name='relu2')\n\n            #tf_y = tf.nn.relu(tf.subtract(tf_6, tf.nn.relu(tf_x, name='relu1'), name='sub'), name='relu2')\n        #tf_y = tf.subtract(tf_6, tf_y, name=output_name)\n        tf_y = tf.subtract(tf_y1, tf_y2, name=output_name)\n        \n    graph_def = graph.as_graph_def()\n    graph_def.node[-1].name = output_name\n\n    # remove unused nodes\n    for node in graph_def.node:\n        if node.name == input_name:\n            graph_def.node.remove(node)\n    for node in graph_def.node:\n        if node.name == const6_name:\n            graph_def.node.remove(node)\n    for node in graph_def.node:\n        if node.op == '_Neg':\n            node.op = 'Neg'\n            \n    return graph_def\n\n\ndef convert_relu6(graph_def, const6_name='const6'):\n    # add constant 6\n    has_const6 = False\n    for node in graph_def.node:\n        if node.name == const6_name:\n            has_const6 = True\n    if not has_const6:\n        const6_graph_def = make_const6(const6_name=const6_name)\n        graph_def.node.extend(const6_graph_def.node)\n        \n    for node in graph_def.node:\n        if node.op == 'Relu6':\n            input_name = node.input[0]\n            output_name = node.name\n            relu6_graph_def = make_relu6(output_name, input_name, const6_name=const6_name)\n            graph_def.node.remove(node)\n            graph_def.node.extend(relu6_graph_def.node)\n            \n    return graph_def\n\n\ndef remove_node(graph_def, node):\n    for n in graph_def.node:\n        if node.name in n.input:\n            n.input.remove(node.name)\n        ctrl_name = '^' + node.name\n        if ctrl_name in n.input:\n            n.input.remove(ctrl_name)\n    graph_def.node.remove(node)\n\n\ndef remove_op(graph_def, op_name):\n    matches = [node for node in graph_def.node if node.op == op_name]\n    for match in matches:\n        remove_node(graph_def, match)\n\n\ndef force_nms_cpu(frozen_graph):\n    for node in frozen_graph.node:\n        if 'NonMaxSuppression' in node.name:\n            node.device = '/device:CPU:0'\n    return frozen_graph\n\n\ndef replace_relu6(frozen_graph):\n    return convert_relu6(frozen_graph)\n\n\ndef remove_assert(frozen_graph):\n    remove_op(frozen_graph, 'Assert')\n    return frozen_graph\n"""
