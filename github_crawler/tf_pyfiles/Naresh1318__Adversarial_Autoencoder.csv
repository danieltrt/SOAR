file_path,api_count,code
adversarial_autoencoder.py,49,"b'import tensorflow as tf\nimport numpy as np\nimport datetime\nimport os\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n# Progressbar\n# bar = progressbar.ProgressBar(widgets=[\'[\', progressbar.Timer(), \']\', progressbar.Bar(), \'(\', progressbar.ETA(), \')\'])\n\n# Get the MNIST data\nmnist = input_data.read_data_sets(\'./Data\', one_hot=True)\n\n# Parameters\ninput_dim = 784\nn_l1 = 1000\nn_l2 = 1000\nz_dim = 2\nbatch_size = 100\nn_epochs = 1000\nlearning_rate = 0.001\nbeta1 = 0.9\nresults_path = \'./Results/Adversarial_Autoencoder\'\n\n# Placeholders for input data and the targets\nx_input = tf.placeholder(dtype=tf.float32, shape=[batch_size, input_dim], name=\'Input\')\nx_target = tf.placeholder(dtype=tf.float32, shape=[batch_size, input_dim], name=\'Target\')\nreal_distribution = tf.placeholder(dtype=tf.float32, shape=[batch_size, z_dim], name=\'Real_distribution\')\ndecoder_input = tf.placeholder(dtype=tf.float32, shape=[1, z_dim], name=\'Decoder_input\')\n\n\ndef form_results():\n    """"""\n    Forms folders for each run to store the tensorboard files, saved models and the log files.\n    :return: three string pointing to tensorboard, saved models and log paths respectively.\n    """"""\n    folder_name = ""/{0}_{1}_{2}_{3}_{4}_{5}_Adversarial_Autoencoder"". \\\n        format(datetime.datetime.now(), z_dim, learning_rate, batch_size, n_epochs, beta1)\n    tensorboard_path = results_path + folder_name + \'/Tensorboard\'\n    saved_model_path = results_path + folder_name + \'/Saved_models/\'\n    log_path = results_path + folder_name + \'/log\'\n    if not os.path.exists(results_path + folder_name):\n        os.mkdir(results_path + folder_name)\n        os.mkdir(tensorboard_path)\n        os.mkdir(saved_model_path)\n        os.mkdir(log_path)\n    return tensorboard_path, saved_model_path, log_path\n\n\ndef generate_image_grid(sess, op):\n    """"""\n    Generates a grid of images by passing a set of numbers to the decoder and getting its output.\n    :param sess: Tensorflow Session required to get the decoder output\n    :param op: Operation that needs to be called inorder to get the decoder output\n    :return: None, displays a matplotlib window with all the merged images.\n    """"""\n    x_points = np.arange(-10, 10, 1.5).astype(np.float32)\n    y_points = np.arange(-10, 10, 1.5).astype(np.float32)\n\n    nx, ny = len(x_points), len(y_points)\n    plt.subplot()\n    gs = gridspec.GridSpec(nx, ny, hspace=0.05, wspace=0.05)\n\n    for i, g in enumerate(gs):\n        z = np.concatenate(([x_points[int(i / ny)]], [y_points[int(i % nx)]]))\n        z = np.reshape(z, (1, 2))\n        x = sess.run(op, feed_dict={decoder_input: z})\n        ax = plt.subplot(g)\n        img = np.array(x.tolist()).reshape(28, 28)\n        ax.imshow(img, cmap=\'gray\')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_aspect(\'auto\')\n    plt.show()\n\n\ndef dense(x, n1, n2, name):\n    """"""\n    Used to create a dense layer.\n    :param x: input tensor to the dense layer\n    :param n1: no. of input neurons\n    :param n2: no. of output neurons\n    :param name: name of the entire dense layer.i.e, variable scope name.\n    :return: tensor with shape [batch_size, n2]\n    """"""\n    with tf.variable_scope(name, reuse=None):\n        weights = tf.get_variable(""weights"", shape=[n1, n2],\n                                  initializer=tf.random_normal_initializer(mean=0., stddev=0.01))\n        bias = tf.get_variable(""bias"", shape=[n2], initializer=tf.constant_initializer(0.0))\n        out = tf.add(tf.matmul(x, weights), bias, name=\'matmul\')\n        return out\n\n\n# The autoencoder network\ndef encoder(x, reuse=False):\n    """"""\n    Encode part of the autoencoder.\n    :param x: input to the autoencoder\n    :param reuse: True -> Reuse the encoder variables, False -> Create or search of variables before creating\n    :return: tensor which is the hidden latent variable of the autoencoder.\n    """"""\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    with tf.name_scope(\'Encoder\'):\n        e_dense_1 = tf.nn.relu(dense(x, input_dim, n_l1, \'e_dense_1\'))\n        e_dense_2 = tf.nn.relu(dense(e_dense_1, n_l1, n_l2, \'e_dense_2\'))\n        latent_variable = dense(e_dense_2, n_l2, z_dim, \'e_latent_variable\')\n        return latent_variable\n\n\ndef decoder(x, reuse=False):\n    """"""\n    Decoder part of the autoencoder.\n    :param x: input to the decoder\n    :param reuse: True -> Reuse the decoder variables, False -> Create or search of variables before creating\n    :return: tensor which should ideally be the input given to the encoder.\n    """"""\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    with tf.name_scope(\'Decoder\'):\n        d_dense_1 = tf.nn.relu(dense(x, z_dim, n_l2, \'d_dense_1\'))\n        d_dense_2 = tf.nn.relu(dense(d_dense_1, n_l2, n_l1, \'d_dense_2\'))\n        output = tf.nn.sigmoid(dense(d_dense_2, n_l1, input_dim, \'d_output\'))\n        return output\n\n\ndef discriminator(x, reuse=False):\n    """"""\n    Discriminator that is used to match the posterior distribution with a given prior distribution.\n    :param x: tensor of shape [batch_size, z_dim]\n    :param reuse: True -> Reuse the discriminator variables,\n                  False -> Create or search of variables before creating\n    :return: tensor of shape [batch_size, 1]\n    """"""\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    with tf.name_scope(\'Discriminator\'):\n        dc_den1 = tf.nn.relu(dense(x, z_dim, n_l1, name=\'dc_den1\'))\n        dc_den2 = tf.nn.relu(dense(dc_den1, n_l1, n_l2, name=\'dc_den2\'))\n        output = dense(dc_den2, n_l2, 1, name=\'dc_output\')\n        return output\n\n\ndef train(train_model=True):\n    """"""\n    Used to train the autoencoder by passing in the necessary inputs.\n    :param train_model: True -> Train the model, False -> Load the latest trained model and show the image grid.\n    :return: does not return anything\n    """"""\n    with tf.variable_scope(tf.get_variable_scope()):\n        encoder_output = encoder(x_input)\n        decoder_output = decoder(encoder_output)\n\n    with tf.variable_scope(tf.get_variable_scope()):\n        d_real = discriminator(real_distribution)\n        d_fake = discriminator(encoder_output, reuse=True)\n\n    with tf.variable_scope(tf.get_variable_scope()):\n        decoder_image = decoder(decoder_input, reuse=True)\n\n    # Autoencoder loss\n    autoencoder_loss = tf.reduce_mean(tf.square(x_target - decoder_output))\n\n    # Discrimminator Loss\n    dc_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_real), logits=d_real))\n    dc_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(d_fake), logits=d_fake))\n    dc_loss = dc_loss_fake + dc_loss_real\n\n    # Generator loss\n    generator_loss = tf.reduce_mean(\n        tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_fake), logits=d_fake))\n\n    all_variables = tf.trainable_variables()\n    dc_var = [var for var in all_variables if \'dc_\' in var.name]\n    en_var = [var for var in all_variables if \'e_\' in var.name]\n\n    # Optimizers\n    autoencoder_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                                   beta1=beta1).minimize(autoencoder_loss)\n    discriminator_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                                     beta1=beta1).minimize(dc_loss, var_list=dc_var)\n    generator_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                                 beta1=beta1).minimize(generator_loss, var_list=en_var)\n\n    init = tf.global_variables_initializer()\n\n    # Reshape immages to display them\n    input_images = tf.reshape(x_input, [-1, 28, 28, 1])\n    generated_images = tf.reshape(decoder_output, [-1, 28, 28, 1])\n\n    # Tensorboard visualization\n    tf.summary.scalar(name=\'Autoencoder Loss\', tensor=autoencoder_loss)\n    tf.summary.scalar(name=\'Discriminator Loss\', tensor=dc_loss)\n    tf.summary.scalar(name=\'Generator Loss\', tensor=generator_loss)\n    tf.summary.histogram(name=\'Encoder Distribution\', values=encoder_output)\n    tf.summary.histogram(name=\'Real Distribution\', values=real_distribution)\n    tf.summary.image(name=\'Input Images\', tensor=input_images, max_outputs=10)\n    tf.summary.image(name=\'Generated Images\', tensor=generated_images, max_outputs=10)\n    summary_op = tf.summary.merge_all()\n\n    # Saving the model\n    saver = tf.train.Saver()\n    step = 0\n    with tf.Session() as sess:\n        if train_model:\n            tensorboard_path, saved_model_path, log_path = form_results()\n            sess.run(init)\n            writer = tf.summary.FileWriter(logdir=tensorboard_path, graph=sess.graph)\n            for i in range(n_epochs):\n                n_batches = int(mnist.train.num_examples / batch_size)\n                print(""------------------Epoch {}/{}------------------"".format(i, n_epochs))\n                for b in range(1, n_batches + 1):\n                    z_real_dist = np.random.randn(batch_size, z_dim) * 5.\n                    batch_x, _ = mnist.train.next_batch(batch_size)\n                    sess.run(autoencoder_optimizer, feed_dict={x_input: batch_x, x_target: batch_x})\n                    sess.run(discriminator_optimizer,\n                             feed_dict={x_input: batch_x, x_target: batch_x, real_distribution: z_real_dist})\n                    sess.run(generator_optimizer, feed_dict={x_input: batch_x, x_target: batch_x})\n                    if b % 50 == 0:\n                        a_loss, d_loss, g_loss, summary = sess.run(\n                            [autoencoder_loss, dc_loss, generator_loss, summary_op],\n                            feed_dict={x_input: batch_x, x_target: batch_x,\n                                       real_distribution: z_real_dist})\n                        writer.add_summary(summary, global_step=step)\n                        print(""Epoch: {}, iteration: {}"".format(i, b))\n                        print(""Autoencoder Loss: {}"".format(a_loss))\n                        print(""Discriminator Loss: {}"".format(d_loss))\n                        print(""Generator Loss: {}"".format(g_loss))\n                        with open(log_path + \'/log.txt\', \'a\') as log:\n                            log.write(""Epoch: {}, iteration: {}\\n"".format(i, b))\n                            log.write(""Autoencoder Loss: {}\\n"".format(a_loss))\n                            log.write(""Discriminator Loss: {}\\n"".format(d_loss))\n                            log.write(""Generator Loss: {}\\n"".format(g_loss))\n                    step += 1\n\n                saver.save(sess, save_path=saved_model_path, global_step=step)\n        else:\n            # Get the latest results folder\n            all_results = os.listdir(results_path)\n            all_results.sort()\n            saver.restore(sess, save_path=tf.train.latest_checkpoint(results_path + \'/\' + all_results[-1] + \'/Saved_models/\'))\n            generate_image_grid(sess, op=decoder_image)\n\nif __name__ == \'__main__\':\n    train(train_model=True)\n'"
autoencoder.py,33,"b'import tensorflow as tf\nimport numpy as np\nimport datetime\nimport os\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n# Get the MNIST data\nmnist = input_data.read_data_sets(\'./Data\', one_hot=True)\n\n# Parameters\ninput_dim = 784\nn_l1 = 1000\nn_l2 = 1000\nz_dim = 2\nbatch_size = 100\nn_epochs = 1000\nlearning_rate = 0.001\nbeta1 = 0.9\nresults_path = \'./Results/Autoencoder\'\n\n\n# Placeholders for input data and the targets\nx_input = tf.placeholder(dtype=tf.float32, shape=[batch_size, input_dim], name=\'Input\')\nx_target = tf.placeholder(dtype=tf.float32, shape=[batch_size, input_dim], name=\'Target\')\ndecoder_input = tf.placeholder(dtype=tf.float32, shape=[1, z_dim], name=\'Decoder_input\')\n\n\ndef generate_image_grid(sess, op):\n    """"""\n    Generates a grid of images by passing a set of numbers to the decoder and getting its output.\n    :param sess: Tensorflow Session required to get the decoder output\n    :param op: Operation that needs to be called inorder to get the decoder output\n    :return: None, displays a matplotlib window with all the merged images.\n    """"""\n    x_points = np.arange(0, 1, 1.5).astype(np.float32)\n    y_points = np.arange(0, 1, 1.5).astype(np.float32)\n\n    nx, ny = len(x_points), len(y_points)\n    plt.subplot()\n    gs = gridspec.GridSpec(nx, ny, hspace=0.05, wspace=0.05)\n\n    for i, g in enumerate(gs):\n        z = np.concatenate(([x_points[int(i / ny)]], [y_points[int(i % nx)]]))\n        z = np.reshape(z, (1, 2))\n        x = sess.run(op, feed_dict={decoder_input: z})\n        ax = plt.subplot(g)\n        img = np.array(x.tolist()).reshape(28, 28)\n        ax.imshow(img, cmap=\'gray\')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_aspect(\'auto\')\n    plt.show()\n\n\ndef form_results():\n    """"""\n    Forms folders for each run to store the tensorboard files, saved models and the log files.\n    :return: three string pointing to tensorboard, saved models and log paths respectively.\n    """"""\n    folder_name = ""/{0}_{1}_{2}_{3}_{4}_{5}_autoencoder"". \\\n        format(datetime.datetime.now(), z_dim, learning_rate, batch_size, n_epochs, beta1)\n    tensorboard_path = results_path + folder_name + \'/Tensorboard\'\n    saved_model_path = results_path + folder_name + \'/Saved_models/\'\n    log_path = results_path + folder_name + \'/log\'\n    if not os.path.exists(results_path + folder_name):\n        os.mkdir(results_path + folder_name)\n        os.mkdir(tensorboard_path)\n        os.mkdir(saved_model_path)\n        os.mkdir(log_path)\n    return tensorboard_path, saved_model_path, log_path\n\n\ndef dense(x, n1, n2, name):\n    """"""\n    Used to create a dense layer.\n    :param x: input tensor to the dense layer\n    :param n1: no. of input neurons\n    :param n2: no. of output neurons\n    :param name: name of the entire dense layer.i.e, variable scope name.\n    :return: tensor with shape [batch_size, n2]\n    """"""\n    with tf.variable_scope(name, reuse=None):\n        weights = tf.get_variable(""weights"", shape=[n1, n2],\n                                  initializer=tf.random_normal_initializer(mean=0., stddev=0.01))\n        bias = tf.get_variable(""bias"", shape=[n2], initializer=tf.constant_initializer(0.0))\n        out = tf.add(tf.matmul(x, weights), bias, name=\'matmul\')\n        return out\n\n\n# The autoencoder network\ndef encoder(x, reuse=False):\n    """"""\n    Encode part of the autoencoder\n    :param x: input to the autoencoder\n    :param reuse: True -> Reuse the encoder variables, False -> Create or search of variables before creating\n    :return: tensor which is the hidden latent variable of the autoencoder.\n    """"""\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    with tf.name_scope(\'Encoder\'):\n        e_dense_1 = tf.nn.relu(dense(x, input_dim, n_l1, \'e_dense_1\'))\n        e_dense_2 = tf.nn.relu(dense(e_dense_1, n_l1, n_l2, \'e_dense_2\'))\n        latent_variable = dense(e_dense_2, n_l2, z_dim, \'e_latent_variable\')\n        return latent_variable\n\n\ndef decoder(x, reuse=False):\n    """"""\n    Decoder part of the autoencoder\n    :param x: input to the decoder\n    :param reuse: True -> Reuse the decoder variables, False -> Create or search of variables before creating\n    :return: tensor which should ideally be the input given to the encoder.\n    """"""\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    with tf.name_scope(\'Decoder\'):\n        d_dense_1 = tf.nn.relu(dense(x, z_dim, n_l2, \'d_dense_1\'))\n        d_dense_2 = tf.nn.relu(dense(d_dense_1, n_l2, n_l1, \'d_dense_2\'))\n        output = tf.nn.sigmoid(dense(d_dense_2, n_l1, input_dim, \'d_output\'))\n        return output\n\n\ndef train(train_model):\n    """"""\n    Used to train the autoencoder by passing in the necessary inputs.\n    :param train_model: True -> Train the model, False -> Load the latest trained model and show the image grid.\n    :return: does not return anything\n    """"""\n    with tf.variable_scope(tf.get_variable_scope()):\n        encoder_output = encoder(x_input)\n        decoder_output = decoder(encoder_output)\n\n    with tf.variable_scope(tf.get_variable_scope()):\n        decoder_image = decoder(decoder_input, reuse=True)\n\n    # Loss\n    loss = tf.reduce_mean(tf.square(x_target - decoder_output))\n\n    # Optimizer\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(loss)\n    init = tf.global_variables_initializer()\n\n    # Visualization\n    tf.summary.scalar(name=\'Loss\', tensor=loss)\n    tf.summary.histogram(name=\'Encoder Distribution\', values=encoder_output)\n    input_images = tf.reshape(x_input, [-1, 28, 28, 1])\n    generated_images = tf.reshape(decoder_output, [-1, 28, 28, 1])\n    tf.summary.image(name=\'Input Images\', tensor=input_images, max_outputs=10)\n    tf.summary.image(name=\'Generated Images\', tensor=generated_images, max_outputs=10)\n    summary_op = tf.summary.merge_all()\n\n    # Saving the model\n    saver = tf.train.Saver()\n    step = 0\n    with tf.Session() as sess:\n        sess.run(init)\n        if train_model:\n            tensorboard_path, saved_model_path, log_path = form_results()\n            writer = tf.summary.FileWriter(logdir=tensorboard_path, graph=sess.graph)\n            for i in range(n_epochs):\n                n_batches = int(mnist.train.num_examples / batch_size)\n                for b in range(n_batches):\n                    batch_x, _ = mnist.train.next_batch(batch_size)\n                    sess.run(optimizer, feed_dict={x_input: batch_x, x_target: batch_x})\n                    if b % 50 == 0:\n                        batch_loss, summary = sess.run([loss, summary_op], feed_dict={x_input: batch_x, x_target: batch_x})\n                        writer.add_summary(summary, global_step=step)\n                        print(""Loss: {}"".format(batch_loss))\n                        print(""Epoch: {}, iteration: {}"".format(i, b))\n                        with open(log_path + \'/log.txt\', \'a\') as log:\n                            log.write(""Epoch: {}, iteration: {}\\n"".format(i, b))\n                            log.write(""Loss: {}\\n"".format(batch_loss))\n                    step += 1\n                saver.save(sess, save_path=saved_model_path, global_step=step)\n            print(""Model Trained!"")\n            print(""Tensorboard Path: {}"".format(tensorboard_path))\n            print(""Log Path: {}"".format(log_path + \'/log.txt\'))\n            print(""Saved Model Path: {}"".format(saved_model_path))\n        else:\n            all_results = os.listdir(results_path)\n            all_results.sort()\n            saver.restore(sess,\n                          save_path=tf.train.latest_checkpoint(results_path + \'/\' + all_results[-1] + \'/Saved_models/\'))\n            generate_image_grid(sess, op=decoder_image)\n\nif __name__ == \'__main__\':\n    train(train_model=True)\n'"
basic_nn_classifier.py,19,"b'import tensorflow as tf\nimport numpy as np\nimport os\nimport datetime\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n# Parameters\ninput_dim = 784\nn_l1 = 1000\nn_l2 = 1000\nbatch_size = 100\nn_epochs = 1000\nlearning_rate = 0.001\nbeta1 = 0.9\nz_dim = \'NA\'\nresults_path = \'./Results/Basic_NN_Classifier\'\nn_labels = 10\nn_labeled = 1000\n\n# Get MNIST data\nmnist = input_data.read_data_sets(\'./Data\', one_hot=True)\n\n# Placeholders\nx_input = tf.placeholder(dtype=tf.float32, shape=[None, 784])\ny_target = tf.placeholder(dtype=tf.float32, shape=[None, 10])\n\n\ndef form_results():\n    """"""\n    Forms folders for each run to store the tensorboard files, saved models and the log files.\n    :return: three string pointing to tensorboard, saved models and log paths respectively.\n    """"""\n    folder_name = ""/{0}_{1}_{2}_{3}_{4}_{5}_Basic_NN_Classifier"". \\\n        format(datetime.datetime.now(), z_dim, learning_rate, batch_size, n_epochs, beta1)\n    tensorboard_path = results_path + folder_name + \'/Tensorboard\'\n    saved_model_path = results_path + folder_name + \'/Saved_models/\'\n    log_path = results_path + folder_name + \'/log\'\n    if not os.path.exists(results_path + folder_name):\n        os.mkdir(results_path + folder_name)\n        os.mkdir(tensorboard_path)\n        os.mkdir(saved_model_path)\n        os.mkdir(log_path)\n    return tensorboard_path, saved_model_path, log_path\n\n\ndef next_batch(x, y, batch_size):\n    """"""\n    Used to return a random batch from the given inputs.\n    :param x: Input images of shape [None, 784]\n    :param y: Input labels of shape [None, 10]\n    :param batch_size: integer, batch size of images and labels to return\n    :return: x -> [batch_size, 784], y-> [batch_size, 10]\n    """"""\n    index = np.arange(n_labeled)\n    random_index = np.random.permutation(index)[:batch_size]\n    return x[random_index], y[random_index]\n\n\ndef dense(x, n1, n2, name):\n    """"""\n    Used to create a dense layer.\n    :param x: input tensor to the dense layer\n    :param n1: no. of input neurons\n    :param n2: no. of output neurons\n    :param name: name of the entire dense layer.\n    :return: tensor with shape [batch_size, n2]\n    """"""\n    with tf.name_scope(name):\n        weights = tf.Variable(tf.random_normal(shape=[n1, n2], mean=0., stddev=0.01), name=\'weights\')\n        bias = tf.Variable(tf.zeros(shape=[n2]), name=\'bias\')\n        output = tf.add(tf.matmul(x, weights), bias, name=\'output\')\n        return output\n\n\n# Dense Network\ndef dense_nn(x):\n    """"""\n    Network used to classify MNIST digits.\n    :param x: tensor with shape [batch_size, 784], input to the dense fully connected layer.\n    :return: [batch_size, 10], logits of dense fully connected.\n    """"""\n    dense_1 = tf.nn.dropout(tf.nn.relu(dense(x, input_dim, n_l1, \'dense_1\')), keep_prob=0.25)\n    dense_2 = tf.nn.dropout(tf.nn.relu(dense(dense_1, n_l1, n_l2, \'dense_2\')), keep_prob=0.25)\n    dense_3 = dense(dense_2, n_l2, n_labels, \'dense_3\')\n    return dense_3\n\n\ndef train():\n    """"""\n    Used to train the autoencoder by passing in the necessary inputs.\n    :return: does not return anything\n    """"""\n    dense_output = dense_nn(x_input)\n\n    # Loss function\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=dense_output, labels=y_target))\n\n    # Optimizer\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(loss)\n\n    # Accuracy\n    pred_op = tf.equal(tf.argmax(dense_output, 1), tf.argmax(y_target, 1))\n    accuracy = tf.reduce_mean(tf.cast(pred_op, dtype=tf.float32))\n\n    # Summary\n    tf.summary.scalar(name=\'Loss\', tensor=loss)\n    tf.summary.scalar(name=\'Accuracy\', tensor=accuracy)\n    summary_op = tf.summary.merge_all()\n\n    saver = tf.train.Saver()\n\n    init = tf.global_variables_initializer()\n\n    step = 0\n    with tf.Session() as sess:\n        tensorboard_path, saved_model_path, log_path = form_results()\n        x_l, y_l = mnist.test.next_batch(n_labeled)\n        writer = tf.summary.FileWriter(logdir=tensorboard_path, graph=sess.graph)\n        sess.run(init)\n        for e in range(1, n_epochs + 1):\n            n_batches = int(n_labeled / batch_size)\n            for b in range(1, n_batches + 1):\n                batch_x_l, batch_y_l = next_batch(x_l, y_l, batch_size=batch_size)\n                sess.run(optimizer, feed_dict={x_input: batch_x_l, y_target: batch_y_l})\n                if b % 5 == 0:\n                    loss_, summary = sess.run([loss, summary_op], feed_dict={x_input: batch_x_l, y_target: batch_y_l})\n                    writer.add_summary(summary, step)\n                    print(""Epoch: {} Iteration: {}"".format(e, b))\n                    print(""Loss: {}"".format(loss_))\n                    with open(log_path + \'/log.txt\', \'a\') as log:\n                        log.write(""Epoch: {}, iteration: {}\\n"".format(e, b))\n                        log.write(""Loss: {}\\n"".format(loss_))\n                step += 1\n            acc = 0\n            num_batches = int(mnist.validation.num_examples / batch_size)\n            for j in range(num_batches):\n                # Classify unseen validation data instead of test data or train data\n                batch_x_l, batch_y_l = mnist.validation.next_batch(batch_size=batch_size)\n                val_acc = sess.run(accuracy, feed_dict={x_input: batch_x_l, y_target: batch_y_l})\n                acc += val_acc\n            acc /= num_batches\n            print(""Classification Accuracy: {}"".format(acc))\n            with open(log_path + \'/log.txt\', \'a\') as log:\n                log.write(""Classification Accuracy: {}"".format(acc))\n            saver.save(sess, save_path=saved_model_path, global_step=step)\n\nif __name__ == \'__main__\':\n    train()\n'"
semi_supervised_adversarial_autoencoder.py,78,"b'import tensorflow as tf\nimport numpy as np\nimport datetime\nimport os\nimport argparse\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n# Get the MNIST data\nmnist = input_data.read_data_sets(\'./Data\', one_hot=True)\n\n# Parameters\ninput_dim = 784\nn_l1 = 1000\nn_l2 = 1000\nz_dim = 10\nbatch_size = 100\nn_epochs = 1000\nlearning_rate = 0.001\nbeta1 = 0.9\nresults_path = \'./Results/Semi_Supervised\'\nn_labels = 10\nn_labeled = 1000\n\n# Placeholders for input data and the targets\nx_input = tf.placeholder(dtype=tf.float32, shape=[batch_size, input_dim], name=\'Input\')\nx_input_l = tf.placeholder(dtype=tf.float32, shape=[batch_size, input_dim], name=\'Labeled_Input\')\ny_input = tf.placeholder(dtype=tf.float32, shape=[batch_size, n_labels], name=\'Labels\')\nx_target = tf.placeholder(dtype=tf.float32, shape=[batch_size, input_dim], name=\'Target\')\nreal_distribution = tf.placeholder(dtype=tf.float32, shape=[batch_size, z_dim], name=\'Real_distribution\')\ncategorial_distribution = tf.placeholder(dtype=tf.float32, shape=[batch_size, n_labels],\n                                         name=\'Categorical_distribution\')\nmanual_decoder_input = tf.placeholder(dtype=tf.float32, shape=[1, z_dim + n_labels], name=\'Decoder_input\')\n\n\ndef form_results():\n    """"""\n    Forms folders for each run to store the tensorboard files, saved models and the log files.\n    :return: three string pointing to tensorboard, saved models and log paths respectively.\n    """"""\n    folder_name = ""/{0}_{1}_{2}_{3}_{4}_{5}_Semi_Supervised"". \\\n        format(datetime.datetime.now(), z_dim, learning_rate, batch_size, n_epochs, beta1)\n    tensorboard_path = results_path + folder_name + \'/Tensorboard\'\n    saved_model_path = results_path + folder_name + \'/Saved_models/\'\n    log_path = results_path + folder_name + \'/log\'\n    if not os.path.exists(results_path + folder_name):\n        os.mkdir(results_path + folder_name)\n        os.mkdir(tensorboard_path)\n        os.mkdir(saved_model_path)\n        os.mkdir(log_path)\n    return tensorboard_path, saved_model_path, log_path\n\n\ndef generate_image_grid(sess, op):\n    """"""\n    Generates a grid of images by passing a set of numbers to the decoder and getting its output.\n    :param sess: Tensorflow Session required to get the decoder output\n    :param op: Operation that needs to be called inorder to get the decoder output\n    :return: None, displays a matplotlib window with all the merged images.\n    """"""\n    nx, ny = 10, 10\n    random_inputs = np.random.randn(10, z_dim) * 5.\n    sample_y = np.identity(10)\n    plt.subplot()\n    gs = gridspec.GridSpec(nx, ny, hspace=0.05, wspace=0.05)\n    i = 0\n    for r in random_inputs:\n        for t in sample_y:\n            r, t = np.reshape(r, (1, z_dim)), np.reshape(t, (1, n_labels))\n            dec_input = np.concatenate((t, r), 1)\n            x = sess.run(op, feed_dict={manual_decoder_input: dec_input})\n            ax = plt.subplot(gs[i])\n            i += 1\n            img = np.array(x.tolist()).reshape(28, 28)\n            ax.imshow(img, cmap=\'gray\')\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_aspect(\'auto\')\n    plt.show()\n\n\ndef dense(x, n1, n2, name):\n    """"""\n    Used to create a dense layer.\n    :param x: input tensor to the dense layer\n    :param n1: no. of input neurons\n    :param n2: no. of output neurons\n    :param name: name of the entire dense layer.i.e, variable scope name.\n    :return: tensor with shape [batch_size, n2]\n    """"""\n    with tf.variable_scope(name, reuse=None):\n        weights = tf.get_variable(""weights"", shape=[n1, n2],\n                                  initializer=tf.random_normal_initializer(mean=0., stddev=0.01))\n        bias = tf.get_variable(""bias"", shape=[n2], initializer=tf.constant_initializer(0.0))\n        out = tf.add(tf.matmul(x, weights), bias, name=\'matmul\')\n        return out\n\n\n# The autoencoder network\ndef encoder(x, reuse=False, supervised=False):\n    """"""\n    Encode part of the autoencoder.\n    :param x: input to the autoencoder\n    :param reuse: True -> Reuse the encoder variables, False -> Create or search of variables before creating\n    :param supervised: True -> returns output without passing it through softmax,\n                       False -> returns output after passing it through softmax.\n    :return: tensor which is the classification output and a hidden latent variable of the autoencoder.\n    """"""\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    with tf.name_scope(\'Encoder\'):\n        e_dense_1 = tf.nn.relu(dense(x, input_dim, n_l1, \'e_dense_1\'))\n        e_dense_2 = tf.nn.relu(dense(e_dense_1, n_l1, n_l2, \'e_dense_2\'))\n        latent_variable = dense(e_dense_2, n_l2, z_dim, \'e_latent_variable\')\n        cat_op = dense(e_dense_2, n_l2, n_labels, \'e_label\')\n        if not supervised:\n            softmax_label = tf.nn.softmax(logits=cat_op, name=\'e_softmax_label\')\n        else:\n            softmax_label = cat_op\n        return softmax_label, latent_variable\n\n\ndef decoder(x, reuse=False):\n    """"""\n    Decoder part of the autoencoder.\n    :param x: input to the decoder\n    :param reuse: True -> Reuse the decoder variables, False -> Create or search of variables before creating\n    :return: tensor which should ideally be the input given to the encoder.\n    """"""\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    with tf.name_scope(\'Decoder\'):\n        d_dense_1 = tf.nn.relu(dense(x, z_dim + n_labels, n_l2, \'d_dense_1\'))\n        d_dense_2 = tf.nn.relu(dense(d_dense_1, n_l2, n_l1, \'d_dense_2\'))\n        output = tf.nn.sigmoid(dense(d_dense_2, n_l1, input_dim, \'d_output\'))\n        return output\n\n\ndef discriminator_gauss(x, reuse=False):\n    """"""\n    Discriminator that is used to match the posterior distribution with a given gaussian distribution.\n    :param x: tensor of shape [batch_size, z_dim]\n    :param reuse: True -> Reuse the discriminator variables,\n                  False -> Create or search of variables before creating\n    :return: tensor of shape [batch_size, 1]\n    """"""\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    with tf.name_scope(\'Discriminator_Gauss\'):\n        dc_den1 = tf.nn.relu(dense(x, z_dim, n_l1, name=\'dc_g_den1\'))\n        dc_den2 = tf.nn.relu(dense(dc_den1, n_l1, n_l2, name=\'dc_g_den2\'))\n        output = dense(dc_den2, n_l2, 1, name=\'dc_g_output\')\n        return output\n\n\ndef discriminator_categorical(x, reuse=False):\n    """"""\n    Discriminator that is used to match the posterior distribution with a given categorical distribution.\n    :param x: tensor of shape [batch_size, n_labels]\n    :param reuse: True -> Reuse the discriminator variables,\n                  False -> Create or search of variables before creating\n    :return: tensor of shape [batch_size, 1]\n    """"""\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    with tf.name_scope(\'Discriminator_Categorial\'):\n        dc_den1 = tf.nn.relu(dense(x, n_labels, n_l1, name=\'dc_c_den1\'))\n        dc_den2 = tf.nn.relu(dense(dc_den1, n_l1, n_l2, name=\'dc_c_den2\'))\n        output = dense(dc_den2, n_l2, 1, name=\'dc_c_output\')\n        return output\n\n\ndef next_batch(x, y, batch_size):\n    """"""\n    Used to return a random batch from the given inputs.\n    :param x: Input images of shape [None, 784]\n    :param y: Input labels of shape [None, 10]\n    :param batch_size: integer, batch size of images and labels to return\n    :return: x -> [batch_size, 784], y-> [batch_size, 10]\n    """"""\n    index = np.arange(n_labeled)\n    random_index = np.random.permutation(index)[:batch_size]\n    return x[random_index], y[random_index]\n\n\ndef train(train_model=True):\n    """"""\n    Used to train the autoencoder by passing in the necessary inputs.\n    :param train_model: True -> Train the model, False -> Load the latest trained model and show the image grid.\n    :return: does not return anything\n    """"""\n\n    # Reconstruction Phase\n    with tf.variable_scope(tf.get_variable_scope()):\n        encoder_output_label, encoder_output_latent = encoder(x_input)\n        # Concat class label and the encoder output\n        decoder_input = tf.concat([encoder_output_label, encoder_output_latent], 1)\n        decoder_output = decoder(decoder_input)\n\n    # Regularization Phase\n    with tf.variable_scope(tf.get_variable_scope()):\n        d_g_real = discriminator_gauss(real_distribution)\n        d_g_fake = discriminator_gauss(encoder_output_latent, reuse=True)\n\n    with tf.variable_scope(tf.get_variable_scope()):\n        d_c_real = discriminator_categorical(categorial_distribution)\n        d_c_fake = discriminator_categorical(encoder_output_label, reuse=True)\n\n    # Semi-Supervised Classification Phase\n    with tf.variable_scope(tf.get_variable_scope()):\n        encoder_output_label_, _ = encoder(x_input_l, reuse=True, supervised=True)\n\n    # Generate output images\n    with tf.variable_scope(tf.get_variable_scope()):\n        decoder_image = decoder(manual_decoder_input, reuse=True)\n\n    # Classification accuracy of encoder\n    correct_pred = tf.equal(tf.argmax(encoder_output_label_, 1), tf.argmax(y_input, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n    # Autoencoder loss\n    autoencoder_loss = tf.reduce_mean(tf.square(x_target - decoder_output))\n\n    # Gaussian Discriminator Loss\n    dc_g_loss_real = tf.reduce_mean(\n        tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_g_real), logits=d_g_real))\n    dc_g_loss_fake = tf.reduce_mean(\n        tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(d_g_fake), logits=d_g_fake))\n    dc_g_loss = dc_g_loss_fake + dc_g_loss_real\n\n    # Categorical Discrimminator Loss\n    dc_c_loss_real = tf.reduce_mean(\n        tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_c_real), logits=d_c_real))\n    dc_c_loss_fake = tf.reduce_mean(\n        tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(d_c_fake), logits=d_c_fake))\n    dc_c_loss = dc_c_loss_fake + dc_c_loss_real\n\n    # Generator loss\n    generator_g_loss = tf.reduce_mean(\n        tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_g_fake), logits=d_g_fake))\n    generator_c_loss = tf.reduce_mean(\n        tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_c_fake), logits=d_c_fake))\n    generator_loss = generator_c_loss + generator_g_loss\n\n    # Supervised Encoder Loss\n    supervised_encoder_loss = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits(labels=y_input, logits=encoder_output_label_))\n\n    all_variables = tf.trainable_variables()\n    dc_g_var = [var for var in all_variables if \'dc_g_\' in var.name]\n    dc_c_var = [var for var in all_variables if \'dc_c_\' in var.name]\n    en_var = [var for var in all_variables if \'e_\' in var.name]\n\n    # Optimizers\n    autoencoder_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                                   beta1=beta1).minimize(autoencoder_loss)\n    discriminator_g_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                                       beta1=beta1).minimize(dc_g_loss, var_list=dc_g_var)\n    discriminator_c_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                                       beta1=beta1).minimize(dc_c_loss, var_list=dc_c_var)\n    generator_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                                 beta1=beta1).minimize(generator_loss, var_list=en_var)\n    supervised_encoder_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                                          beta1=beta1).minimize(supervised_encoder_loss,\n                                                                                var_list=en_var)\n\n    init = tf.global_variables_initializer()\n\n    # Reshape immages to display them\n    input_images = tf.reshape(x_input, [-1, 28, 28, 1])\n    generated_images = tf.reshape(decoder_output, [-1, 28, 28, 1])\n\n    # Tensorboard visualization\n    tf.summary.scalar(name=\'Autoencoder Loss\', tensor=autoencoder_loss)\n    tf.summary.scalar(name=\'Discriminator gauss Loss\', tensor=dc_g_loss)\n    tf.summary.scalar(name=\'Discriminator categorical Loss\', tensor=dc_c_loss)\n    tf.summary.scalar(name=\'Generator Loss\', tensor=generator_loss)\n    tf.summary.scalar(name=\'Supervised Encoder Loss\', tensor=supervised_encoder_loss)\n    tf.summary.histogram(name=\'Encoder Gauss Distribution\', values=encoder_output_latent)\n    tf.summary.histogram(name=\'Real Gauss Distribution\', values=real_distribution)\n    tf.summary.histogram(name=\'Encoder Categorical Distribution\', values=encoder_output_label)\n    tf.summary.histogram(name=\'Real Categorical Distribution\', values=categorial_distribution)\n    tf.summary.image(name=\'Input Images\', tensor=input_images, max_outputs=10)\n    tf.summary.image(name=\'Generated Images\', tensor=generated_images, max_outputs=10)\n    summary_op = tf.summary.merge_all()\n\n    # Saving the model\n    saver = tf.train.Saver()\n    step = 0\n    with tf.Session() as sess:\n        if train_model:\n            tensorboard_path, saved_model_path, log_path = form_results()\n            sess.run(init)\n            writer = tf.summary.FileWriter(logdir=tensorboard_path, graph=sess.graph)\n            x_l, y_l = mnist.test.next_batch(n_labeled)\n            for i in range(n_epochs):\n                n_batches = int(n_labeled / batch_size)\n                print(""------------------Epoch {}/{}------------------"".format(i, n_epochs))\n                for b in range(1, n_batches + 1):\n                    z_real_dist = np.random.randn(batch_size, z_dim) * 5.\n                    real_cat_dist = np.random.randint(low=0, high=10, size=batch_size)\n                    real_cat_dist = np.eye(n_labels)[real_cat_dist]\n                    batch_x_ul, _ = mnist.train.next_batch(batch_size)\n                    batch_x_l, batch_y_l = next_batch(x_l, y_l, batch_size=batch_size)\n                    sess.run(autoencoder_optimizer, feed_dict={x_input: batch_x_ul, x_target: batch_x_ul})\n                    sess.run(discriminator_g_optimizer,\n                             feed_dict={x_input: batch_x_ul, x_target: batch_x_ul, real_distribution: z_real_dist})\n                    sess.run(discriminator_c_optimizer,\n                             feed_dict={x_input: batch_x_ul, x_target: batch_x_ul,\n                                        categorial_distribution: real_cat_dist})\n                    sess.run(generator_optimizer, feed_dict={x_input: batch_x_ul, x_target: batch_x_ul})\n                    sess.run(supervised_encoder_optimizer, feed_dict={x_input_l: batch_x_l, y_input: batch_y_l})\n                    if b % 5 == 0:\n                        a_loss, d_g_loss, d_c_loss, g_loss, s_loss, summary = sess.run(\n                            [autoencoder_loss, dc_g_loss, dc_c_loss, generator_loss, supervised_encoder_loss,\n                             summary_op],\n                            feed_dict={x_input: batch_x_ul, x_target: batch_x_ul,\n                                       real_distribution: z_real_dist, y_input: batch_y_l, x_input_l: batch_x_l,\n                                       categorial_distribution: real_cat_dist})\n                        writer.add_summary(summary, global_step=step)\n                        print(""Epoch: {}, iteration: {}"".format(i, b))\n                        print(""Autoencoder Loss: {}"".format(a_loss))\n                        print(""Discriminator Gauss Loss: {}"".format(d_g_loss))\n                        print(""Discriminator Categorical Loss: {}"".format(d_c_loss))\n                        print(""Generator Loss: {}"".format(g_loss))\n                        print(""Supervised Loss: {}\\n"".format(s_loss))\n                        with open(log_path + \'/log.txt\', \'a\') as log:\n                            log.write(""Epoch: {}, iteration: {}\\n"".format(i, b))\n                            log.write(""Autoencoder Loss: {}\\n"".format(a_loss))\n                            log.write(""Discriminator Gauss Loss: {}"".format(d_g_loss))\n                            log.write(""Discriminator Categorical Loss: {}"".format(d_c_loss))\n                            log.write(""Generator Loss: {}\\n"".format(g_loss))\n                            log.write(""Supervised Loss: {}"".format(s_loss))\n                    step += 1\n                acc = 0\n                num_batches = int(mnist.validation.num_examples/batch_size)\n                for j in range(num_batches):\n                    # Classify unseen validation data instead of test data or train data\n                    batch_x_l, batch_y_l = mnist.validation.next_batch(batch_size=batch_size)\n                    encoder_acc = sess.run(accuracy, feed_dict={x_input_l: batch_x_l, y_input: batch_y_l})\n                    acc += encoder_acc\n                acc /= num_batches\n                print(""Encoder Classification Accuracy: {}"".format(acc))\n                with open(log_path + \'/log.txt\', \'a\') as log:\n                    log.write(""Encoder Classification Accuracy: {}"".format(acc))\n                saver.save(sess, save_path=saved_model_path, global_step=step)\n        else:\n            # Get the latest results folder\n            all_results = os.listdir(results_path)\n            all_results.sort()\n            saver.restore(sess, save_path=tf.train.latest_checkpoint(results_path + \'/\' +\n                                                                     all_results[-1] + \'/Saved_models/\'))\n            generate_image_grid(sess, op=decoder_image)\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser(description=""Autoencoder Train Parameter"")\n    parser.add_argument(\'--train\', \'-t\', type=bool, default=True,\n                        help=\'Set to True to train a new model, False to load weights and display image grid\')\n    args = parser.parse_args()\n    train(train_model=args.train)\n'"
supervised_adversarial_autoencoder.py,51,"b'import tensorflow as tf\nimport numpy as np\nimport datetime\nimport os\nimport argparse\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n# Get the MNIST data\nmnist = input_data.read_data_sets(\'./Data\', one_hot=True)\n\n# Parameters\ninput_dim = 784\nn_l1 = 1000\nn_l2 = 1000\nz_dim = 15\nbatch_size = 100\nn_epochs = 1000\nlearning_rate = 0.001\nbeta1 = 0.9\nresults_path = \'./Results/Supervised\'\nn_labels = 10\n\n# Placeholders for input data and the targets\nx_input = tf.placeholder(dtype=tf.float32, shape=[batch_size, input_dim], name=\'Input\')\ny_input = tf.placeholder(dtype=tf.float32, shape=[batch_size, n_labels], name=\'Labels\')\nx_target = tf.placeholder(dtype=tf.float32, shape=[batch_size, input_dim], name=\'Target\')\nreal_distribution = tf.placeholder(dtype=tf.float32, shape=[batch_size, z_dim], name=\'Real_distribution\')\nmanual_decoder_input = tf.placeholder(dtype=tf.float32, shape=[1, z_dim + n_labels], name=\'Decoder_input\')\n\n\ndef form_results():\n    """"""\n    Forms folders for each run to store the tensorboard files, saved models and the log files.\n    :return: three string pointing to tensorboard, saved models and log paths respectively.\n    """"""\n    folder_name = ""/{0}_{1}_{2}_{3}_{4}_{5}_Supervised"". \\\n        format(datetime.datetime.now(), z_dim, learning_rate, batch_size, n_epochs, beta1)\n    tensorboard_path = results_path + folder_name + \'/Tensorboard\'\n    saved_model_path = results_path + folder_name + \'/Saved_models/\'\n    log_path = results_path + folder_name + \'/log\'\n    if not os.path.exists(results_path + folder_name):\n        os.mkdir(results_path + folder_name)\n        os.mkdir(tensorboard_path)\n        os.mkdir(saved_model_path)\n        os.mkdir(log_path)\n    return tensorboard_path, saved_model_path, log_path\n\n\ndef generate_image_grid(sess, op):\n    """"""\n    Generates a grid of images by passing a set of numbers to the decoder and getting its output.\n    :param sess: Tensorflow Session required to get the decoder output\n    :param op: Operation that needs to be called inorder to get the decoder output\n    :return: None, displays a matplotlib window with all the merged images.\n    """"""\n    nx, ny = 10, 10\n    random_inputs = np.random.randn(10, z_dim) * 5.\n    sample_y = np.identity(10)\n    plt.subplot()\n    gs = gridspec.GridSpec(nx, ny, hspace=0.05, wspace=0.05)\n    i = 0\n    for r in random_inputs:\n        for t in sample_y:\n            r, t = np.reshape(r, (1, z_dim)), np.reshape(t, (1, n_labels))\n            dec_input = np.concatenate((t, r), 1)\n            x = sess.run(op, feed_dict={manual_decoder_input: dec_input})\n            ax = plt.subplot(gs[i])\n            i += 1\n            img = np.array(x.tolist()).reshape(28, 28)\n            ax.imshow(img, cmap=\'gray\')\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.set_aspect(\'auto\')\n    plt.show()\n\n\ndef dense(x, n1, n2, name):\n    """"""\n    Used to create a dense layer.\n    :param x: input tensor to the dense layer\n    :param n1: no. of input neurons\n    :param n2: no. of output neurons\n    :param name: name of the entire dense layer.i.e, variable scope name.\n    :return: tensor with shape [batch_size, n2]\n    """"""\n    with tf.variable_scope(name, reuse=None):\n        weights = tf.get_variable(""weights"", shape=[n1, n2],\n                                  initializer=tf.random_normal_initializer(mean=0., stddev=0.01))\n        bias = tf.get_variable(""bias"", shape=[n2], initializer=tf.constant_initializer(0.0))\n        out = tf.add(tf.matmul(x, weights), bias, name=\'matmul\')\n        return out\n\n\n# The autoencoder network\ndef encoder(x, reuse=False):\n    """"""\n    Encode part of the autoencoder.\n    :param x: input to the autoencoder\n    :param reuse: True -> Reuse the encoder variables, False -> Create or search of variables before creating\n    :param supervised: True -> returns output without passing it through softmax,\n                       False -> returns output after passing it through softmax.\n    :return: tensor which is the classification output and a hidden latent variable of the autoencoder.\n    """"""\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    with tf.name_scope(\'Encoder\'):\n        e_dense_1 = tf.nn.relu(dense(x, input_dim, n_l1, \'e_dense_1\'))\n        e_dense_2 = tf.nn.relu(dense(e_dense_1, n_l1, n_l2, \'e_dense_2\'))\n        latent_variable = dense(e_dense_2, n_l2, z_dim, \'e_latent_variable\')\n        return latent_variable\n\n\ndef decoder(x, reuse=False):\n    """"""\n    Decoder part of the autoencoder.\n    :param x: input to the decoder\n    :param reuse: True -> Reuse the decoder variables, False -> Create or search of variables before creating\n    :return: tensor which should ideally be the input given to the encoder.\n    """"""\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    with tf.name_scope(\'Decoder\'):\n        d_dense_1 = tf.nn.relu(dense(x, z_dim + n_labels, n_l2, \'d_dense_1\'))\n        d_dense_2 = tf.nn.relu(dense(d_dense_1, n_l2, n_l1, \'d_dense_2\'))\n        output = tf.nn.sigmoid(dense(d_dense_2, n_l1, input_dim, \'d_output\'))\n        return output\n\n\ndef discriminator(x, reuse=False):\n    """"""\n    Discriminator that is used to match the posterior distribution with a given prior distribution.\n    :param x: tensor of shape [batch_size, z_dim]\n    :param reuse: True -> Reuse the discriminator variables,\n                  False -> Create or search of variables before creating\n    :return: tensor of shape [batch_size, 1]\n    """"""\n    if reuse:\n        tf.get_variable_scope().reuse_variables()\n    with tf.name_scope(\'Discriminator\'):\n        dc_den1 = tf.nn.relu(dense(x, z_dim, n_l1, name=\'dc_den1\'))\n        dc_den2 = tf.nn.relu(dense(dc_den1, n_l1, n_l2, name=\'dc_den2\'))\n        output = dense(dc_den2, n_l2, 1, name=\'dc_output\')\n        return output\n\n\ndef train(train_model=True):\n    """"""\n    Used to train the autoencoder by passing in the necessary inputs.\n    :param train_model: True -> Train the model, False -> Load the latest trained model and show the image grid.\n    :return: does not return anything\n    """"""\n    with tf.variable_scope(tf.get_variable_scope()):\n        encoder_output = encoder(x_input)\n        # Concat class label and the encoder output\n        decoder_input = tf.concat([y_input, encoder_output], 1)\n        decoder_output = decoder(decoder_input)\n\n    with tf.variable_scope(tf.get_variable_scope()):\n        d_real = discriminator(real_distribution)\n        d_fake = discriminator(encoder_output, reuse=True)\n\n    with tf.variable_scope(tf.get_variable_scope()):\n        decoder_image = decoder(manual_decoder_input, reuse=True)\n\n    # Autoencoder loss\n    autoencoder_loss = tf.reduce_mean(tf.square(x_target - decoder_output))\n\n    # Discriminator Loss\n    dc_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_real), logits=d_real))\n    dc_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(d_fake), logits=d_fake))\n    dc_loss = dc_loss_fake + dc_loss_real\n\n    # Generator loss\n    generator_loss = tf.reduce_mean(\n        tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_fake), logits=d_fake))\n\n    all_variables = tf.trainable_variables()\n    dc_var = [var for var in all_variables if \'dc_\' in var.name]\n    en_var = [var for var in all_variables if \'e_\' in var.name]\n\n    # Optimizers\n    autoencoder_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                                   beta1=beta1).minimize(autoencoder_loss)\n    discriminator_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                                     beta1=beta1).minimize(dc_loss, var_list=dc_var)\n    generator_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                                 beta1=beta1).minimize(generator_loss, var_list=en_var)\n\n    init = tf.global_variables_initializer()\n\n    # Reshape images to display them\n    input_images = tf.reshape(x_input, [-1, 28, 28, 1])\n    generated_images = tf.reshape(decoder_output, [-1, 28, 28, 1])\n\n    # Tensorboard visualization\n    tf.summary.scalar(name=\'Autoencoder Loss\', tensor=autoencoder_loss)\n    tf.summary.scalar(name=\'Discriminator Loss\', tensor=dc_loss)\n    tf.summary.scalar(name=\'Generator Loss\', tensor=generator_loss)\n    tf.summary.histogram(name=\'Encoder Distribution\', values=encoder_output)\n    tf.summary.histogram(name=\'Real Distribution\', values=real_distribution)\n    tf.summary.image(name=\'Input Images\', tensor=input_images, max_outputs=10)\n    tf.summary.image(name=\'Generated Images\', tensor=generated_images, max_outputs=10)\n    summary_op = tf.summary.merge_all()\n\n    # Saving the model\n    saver = tf.train.Saver()\n    step = 0\n    with tf.Session() as sess:\n        if train_model:\n            tensorboard_path, saved_model_path, log_path = form_results()\n            sess.run(init)\n            writer = tf.summary.FileWriter(logdir=tensorboard_path, graph=sess.graph)\n            for i in range(n_epochs):\n                n_batches = int(mnist.train.num_examples / batch_size)\n                print(""------------------Epoch {}/{}------------------"".format(i, n_epochs))\n                for b in range(1, n_batches + 1):\n                    z_real_dist = np.random.randn(batch_size, z_dim) * 5.\n                    batch_x, batch_y = mnist.train.next_batch(batch_size)\n                    sess.run(autoencoder_optimizer, feed_dict={x_input: batch_x, x_target: batch_x, y_input: batch_y})\n                    sess.run(discriminator_optimizer,\n                             feed_dict={x_input: batch_x, x_target: batch_x, real_distribution: z_real_dist})\n                    sess.run(generator_optimizer, feed_dict={x_input: batch_x, x_target: batch_x})\n                    if b % 50 == 0:\n                        a_loss, d_loss, g_loss, summary = sess.run(\n                            [autoencoder_loss, dc_loss, generator_loss, summary_op],\n                            feed_dict={x_input: batch_x, x_target: batch_x,\n                                       real_distribution: z_real_dist, y_input: batch_y})\n                        writer.add_summary(summary, global_step=step)\n                        print(""Epoch: {}, iteration: {}"".format(i, b))\n                        print(""Autoencoder Loss: {}"".format(a_loss))\n                        print(""Discriminator Loss: {}"".format(d_loss))\n                        print(""Generator Loss: {}"".format(g_loss))\n                        with open(log_path + \'/log.txt\', \'a\') as log:\n                            log.write(""Epoch: {}, iteration: {}\\n"".format(i, b))\n                            log.write(""Autoencoder Loss: {}\\n"".format(a_loss))\n                            log.write(""Discriminator Loss: {}\\n"".format(d_loss))\n                            log.write(""Generator Loss: {}\\n"".format(g_loss))\n                    step += 1\n\n                saver.save(sess, save_path=saved_model_path, global_step=step)\n        else:\n            # Get the latest results folder\n            all_results = os.listdir(results_path)\n            all_results.sort()\n            saver.restore(sess, save_path=tf.train.latest_checkpoint(results_path + \'/\' +\n                                                                     all_results[-1] + \'/Saved_models/\'))\n            generate_image_grid(sess, op=decoder_image)\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser(description=""Autoencoder Train Parameter"")\n    parser.add_argument(\'--train\', \'-t\', type=bool, default=True,\n                        help=\'Set to True to train a new model, False to load weights and display image grid\')\n    args = parser.parse_args()\n    train(train_model=args.train)\n'"
