file_path,api_count,code
examples/ax.py,8,"b'# ==============================================================================\n#  Copyright 2018-2019 Intel Corporation\n#\n#  Licensed under the Apache License, Version 2.0 (the ""License"");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an ""AS IS"" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n# ==============================================================================\n\nimport ngraph_bridge\nimport argparse\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.core.protobuf import rewriter_config_pb2\n\n\ndef str2bool(v):\n    if isinstance(v, bool):\n        return v\n    if v.lower() in (\'yes\', \'true\', \'t\', \'y\', \'1\'):\n        return True\n    elif v.lower() in (\'no\', \'false\', \'f\', \'n\', \'0\'):\n        return False\n    else:\n        raise argparse.ArgumentTypeError(\'Boolean value expected.\')\n\n\ndef server_config_from_flags(FLAGS, tensor_param_name):\n    rewriter_options = rewriter_config_pb2.RewriterConfig()\n    rewriter_options.meta_optimizer_iterations = (\n        rewriter_config_pb2.RewriterConfig.ONE)\n    rewriter_options.min_graph_nodes = -1\n    server_config = rewriter_options.custom_optimizers.add()\n    server_config.name = ""ngraph-optimizer""\n    server_config.parameter_map[""ngraph_backend""].s = FLAGS.backend.encode()\n    server_config.parameter_map[""device_id""].s = b\'\'\n    server_config.parameter_map[\n        ""encryption_parameters""].s = FLAGS.encryption_parameters.encode()\n    server_config.parameter_map[\'enable_client\'].s = (str(\n        FLAGS.enable_client)).encode()\n    if FLAGS.enable_client:\n        server_config.parameter_map[tensor_param_name].s = b\'client_input\'\n\n    config = tf.compat.v1.ConfigProto()\n    config.MergeFrom(\n        tf.compat.v1.ConfigProto(\n            graph_options=tf.compat.v1.GraphOptions(\n                rewrite_options=rewriter_options)))\n\n    return config\n\n\ndef main(FLAGS):\n\n    a = tf.constant(np.array([[1, 2, 3, 4]]), dtype=np.float32)\n    b = tf.compat.v1.placeholder(\n        tf.float32, shape=(1, 4), name=\'client_parameter_name\')\n    c = tf.compat.v1.placeholder(tf.float32, shape=(1, 4))\n    f = c * (a + b)\n\n    # Create config to load parameter b from client\n    config = server_config_from_flags(FLAGS, b.name)\n    print(\'config\', config)\n\n    with tf.compat.v1.Session(config=config) as sess:\n        f_val = sess.run(f, feed_dict={b: np.ones((1, 4)), c: np.ones((1, 4))})\n        print(""Result: "", f_val)\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--batch_size\', type=int, default=1, help=\'Batch size\')\n    parser.add_argument(\n        \'--enable_client\',\n        type=str2bool,\n        default=False,\n        help=\'Enable the client\')\n    parser.add_argument(\n        \'--backend\',\n        type=str,\n        default=\'HE_SEAL\',\n        help=\'Name of backend to use\')\n    parser.add_argument(\n        \'--encryption_parameters\',\n        type=str,\n        default=\'\',\n        help=\n        \'Filename containing json description of encryption parameters, or json description itself\'\n    )\n\n    FLAGS, unparsed = parser.parse_known_args()\n    main(FLAGS)\n'"
examples/pyclient.py,0,"b'# ==============================================================================\n#  Copyright 2018-2019 Intel Corporation\n#\n#  Licensed under the Apache License, Version 2.0 (the ""License"");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an ""AS IS"" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n# ==============================================================================\n\nimport pyhe_client\nimport time\nimport argparse\n\n\ndef main(FLAGS):\n    data = (2, 4, 6, 8)\n\n    port = 34000\n    batch_size = 1\n\n    client = pyhe_client.HESealClient(\n        FLAGS.hostname, port, batch_size,\n        {\'client_parameter_name\': (\'encrypt\', data)})\n\n    results = client.get_results()\n\n    print(\'results\', results)\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \'--hostname\', type=str, default=\'localhost\', help=\'Hostname of server\')\n\n    FLAGS, unparsed = parser.parse_known_args()\n\n    print(FLAGS)\n    main(FLAGS)\n'"
python/setup.py,0,"b'from setuptools import setup, Extension\nfrom setuptools.command.build_ext import build_ext\nimport sys\nimport setuptools\nimport os\n\n# TODO: get from environment\n__version__ = \'0.6.0-rc0\'\n\nPYNGRAPH_ROOT_DIR = os.path.abspath(os.path.dirname(__file__))\nBOOST_ROOT_DIR = os.path.abspath(os.path.dirname(__file__))\nSEAL_ROOT_DIR = os.path.abspath(os.path.dirname(__file__))\n\n\ndef find_he_transformer_dist_dir():\n    """"""Return location of he-transformer library home""""""\n\n    if os.environ.get(\'NGRAPH_HE_BUILD_PATH\'):\n        ngraph_he_dist_dir = os.environ.get(\'NGRAPH_HE_BUILD_PATH\')\n    else:\n        print(\'Must set NGRAPH_HE_BUILD_PATH\')\n        sys.exit(1)\n\n    found = os.path.exists(os.path.join(ngraph_he_dist_dir, \'include\'))\n    found = found and os.path.exists(os.path.join(ngraph_he_dist_dir, \'lib\'))\n\n    if not found:\n        print(\n            \'Cannot find he-transformer library in {} make sure that \'\n            \'NGRAPH_HE_BUILD_PATH is set correctly\'.format(ngraph_he_dist_dir))\n        sys.exit(1)\n    else:\n        print(\'he-transformer library found in {}\'.format(ngraph_he_dist_dir))\n        return ngraph_he_dist_dir\n\n\ndef find_pybind_headers_dir():\n    """"""Return location of pybind11 headers.""""""\n    if os.environ.get(\'PYBIND_HEADERS_PATH\'):\n        pybind_headers_dir = os.environ.get(\'PYBIND_HEADERS_PATH\')\n    else:\n        pybind_headers_dir = os.path.join(PYNGRAPH_ROOT_DIR, \'pybind11\')\n\n    found = os.path.exists(\n        os.path.join(pybind_headers_dir, \'include/pybind11\'))\n    if not found:\n        print(\n            \'Cannot find pybind11 library in {} make sure that \'\n            \'PYBIND_HEADERS_PATH is set correctly\'.format(pybind_headers_dir))\n        sys.exit(1)\n    else:\n        print(\'pybind11 library found in {}\'.format(pybind_headers_dir))\n        return pybind_headers_dir\n\n\ndef find_seal_headers_dir():\n    """"""Return location of SEAL headers.""""""\n    if os.environ.get(\'SEAL_HEADERS_PATH\'):\n        seal_headers_dir = os.environ.get(\'SEAL_HEADERS_PATH\')\n    else:\n        seal_headers_dir = [os.path.join(SEAL_ROOT_DIR)]\n\n    found = os.path.exists(os.path.join(seal_headers_dir, \'seal\'))\n\n    if not found:\n        print(\'Cannot find SEAL library in {} make sure that \'\n              \'SEAL_HEADERS_PATH is set correctly\'.format(seal_headers_dir))\n\n    print(\'SEAL library found in {}\'.format(seal_headers_dir))\n    return seal_headers_dir\n\n\ndef find_boost_headers_dir():\n    """"""Return location of boost headers.""""""\n    if os.environ.get(\'BOOST_HEADERS_PATH\'):\n        boost_headers_dir = os.environ.get(\'BOOST_HEADERS_PATH\')\n    else:\n        boost_headers_dir = [os.path.join(BOOST_ROOT_DIR)]\n\n    found = os.path.exists(os.path.join(boost_headers_dir, \'boost/asio\'))\n\n    if not found:\n        print(\'Cannot find boost library in {} make sure that \'\n              \'BOOST_HEADERS_PATH is set correctly\'.format(boost_headers_dir))\n\n    print(\'boost library found in {}\'.format(boost_headers_dir))\n    return boost_headers_dir\n\n\ndef find_cxx_compiler():\n    """"""Returns C++ compiler.""""""\n    if os.environ.get(\'CXX_COMPILER\'):\n        print(\'CXX_COMPILER\', os.environ.get(\'CXX_COMPILER\'))\n        return os.environ.get(\'CXX_COMPILER\')\n    else:\n        return \'CXX\'\n\n\ndef find_c_compiler():\n    """"""Returns C compiler.""""""\n    if os.environ.get(\'C_COMPILER\'):\n        print(\'C_COMPILER\', os.environ.get(\'C_COMPILER\'))\n        return os.environ.get(\'C_COMPILER\')\n    else:\n        return \'CC\'\n\n\ndef find_project_root_dir():\n    """"""Returns PROJECT_ROOT_DIR""""""\n    if os.environ.get(""PROJECT_ROOT_DIR""):\n        return os.environ.get(""PROJECT_ROOT_DIR"")\n    else:\n        print(\'Cannot find PROJECT_ROOT_DIR\')\n        sys.exit(1)\n\n\nos.environ[""CXX""] = find_cxx_compiler()\nos.environ[""CC""] = find_cxx_compiler()\n\nPYBIND11_INCLUDE_DIR = find_pybind_headers_dir() + \'/include\'\nNGRAPH_HE_DIST_DIR = find_he_transformer_dist_dir()\nNGRAPH_HE_INCLUDE_DIR = os.path.join(NGRAPH_HE_DIST_DIR, \'include\')\nNGRAPH_HE_LIB_DIR = os.path.join(NGRAPH_HE_DIST_DIR, \'lib\')\nBOOST_INCLUDE_DIR = find_boost_headers_dir()\nSEAL_INCLUDE_DIR = find_seal_headers_dir()\nPROJECT_ROOT_DIR = find_project_root_dir()\n\nprint(\'NGRAPH_HE_DIST_DIR\', NGRAPH_HE_DIST_DIR)\nprint(\'NGRAPH_HE_LIB_DIR \', NGRAPH_HE_LIB_DIR)\nprint(\'NGRAPH_HE_INCLUDE_DIR\', NGRAPH_HE_INCLUDE_DIR)\nprint(\'BOOST_INCLUDE_DIR\', BOOST_INCLUDE_DIR)\nprint(\'SEAL_INCLUDE_DIR\', SEAL_INCLUDE_DIR)\nprint(\'PROJECT_ROOT_DIR\', PROJECT_ROOT_DIR)\n\ninclude_dirs = [\n    PYNGRAPH_ROOT_DIR, NGRAPH_HE_INCLUDE_DIR, PYBIND11_INCLUDE_DIR,\n    BOOST_INCLUDE_DIR, SEAL_INCLUDE_DIR\n]\nprint(\'include_dirs\', include_dirs)\n\nlibrary_dirs = [NGRAPH_HE_LIB_DIR]\n\nlibraries = [\'he_seal_backend\']\n\nlib_files = [os.path.join(NGRAPH_HE_LIB_DIR, f) for f in os.listdir(NGRAPH_HE_LIB_DIR) if os.path.isfile(os.path.join(NGRAPH_HE_LIB_DIR, f))]\n\ndata_files = [(\'lib\', lib_files)]\nprint(\'data_files\', data_files)\n\nsources = [\'pyhe_client/he_seal_client.cpp\', \'pyhe_client/pyhe_client.cpp\']\nsources = [PYNGRAPH_ROOT_DIR + \'/\' + source for source in sources]\n\next_modules = [\n    Extension(\n        \'pyhe_client\',\n        sources=sources,\n        include_dirs=include_dirs,\n        library_dirs=library_dirs,\n        libraries=libraries,\n        language=\'c++\'),\n]\n\n\n# As of Python 3.6, CCompiler has a `has_flag` method.\n# cf http://bugs.python.org/issue26689\ndef has_flag(compiler, flagname):\n    """"""Return a boolean indicating whether a flag name is supported on\n    the specified compiler.\n    """"""\n    import tempfile\n    with tempfile.NamedTemporaryFile(\'w\', suffix=\'.cpp\') as f:\n        f.write(\'int main (int argc, char **argv) { return 0; }\')\n        try:\n            compiler.compile([f.name], extra_postargs=[flagname])\n        except setuptools.distutils.errors.CompileError:\n            return False\n    return True\n\n\ndef cpp_flag(compiler):\n    """"""Return the -std=c++[11/14] compiler flag.\n    The c++14 is prefered over c++11 (when it is available).\n    """"""\n    if has_flag(compiler, \'-std=c++17\'):\n        return \'-std=c++17\'\n    elif has_flag(compiler, \'-std=c++14\'):\n        return \'-std=c++14\'\n    elif has_flag(compiler, \'-std=c++11\'):\n        return \'-std=c++11\'\n    else:\n        raise RuntimeError(\'Unsupported compiler -- at least C++11 support \'\n                           \'is needed!\')\n\n\ndef add_platform_specific_link_args(link_args):\n    """"""Add linker flags specific for actual OS.""""""\n    if sys.platform.startswith(\'linux\'):\n        link_args += [\'-Wl,-rpath,$ORIGIN/../..\']\n        link_args += [\'-z\', \'noexecstack\']\n        link_args += [\'-z\', \'relro\']\n        link_args += [\'-z\', \'now\']\n        #link_args += [\'-z\', \'flto\']\n\n\nclass BuildExt(build_ext):\n    """"""A custom build extension for adding compiler-specific options.""""""\n\n    def _add_extra_compile_arg(self, flag, compile_args):\n        """"""Return True if successfully added given flag to compiler args.""""""\n        if has_flag(self.compiler, flag):\n            compile_args += [flag]\n            return True\n        return False\n\n    def build_extensions(self):\n        """"""Build extension providing extra compiler flags.""""""\n        # -Wstrict-prototypes is not a valid option for c++\n        try:\n            self.compiler.compiler_so.remove(\'-Wstrict-prototypes\')\n        except (AttributeError, ValueError):\n            pass\n        for ext in self.extensions:\n            ext.extra_compile_args += [cpp_flag(self.compiler)]\n\n            if not self._add_extra_compile_arg(\'-fstack-protector-strong\',\n                                               ext.extra_compile_args):\n                self._add_extra_compile_arg(\'-fstack-protector\',\n                                            ext.extra_compile_args)\n\n            self._add_extra_compile_arg(\'-fvisibility=hidden\',\n                                        ext.extra_compile_args)\n            # self._add_extra_compile_arg(\'-flto\', ext.extra_compile_args)\n            self._add_extra_compile_arg(\'-fPIC\', ext.extra_compile_args)\n            self._add_extra_compile_arg(\'-fopenmp\', ext.extra_compile_args)\n            self._add_extra_compile_arg(\n                \'-DPROJECT_ROOT_DIR=""\' + PROJECT_ROOT_DIR + \'""\',\n                ext.extra_compile_args)\n            add_platform_specific_link_args(ext.extra_link_args)\n\n            ext.extra_compile_args += [\'-Wformat\', \'-Wformat-security\']\n            ext.extra_compile_args += [\'-O2\', \'-D_FORTIFY_SOURCE=2\']\n            ext.extra_compile_args += [\'-v\']\n        build_ext.build_extensions(self)\n\n\nsetup(\n    name=\'pyhe_client\',\n    version=__version__,\n    author=\'Intel Corporation\',\n    url=\'https://github.com/NervanaSystems/he-transformer\',\n    description=\'Client for HE-transformer\',\n    long_description=\'\',\n    ext_modules=ext_modules,\n    data_files=data_files,\n    install_requires=[\'pybind11>=2.2\'],\n    cmdclass={\'build_ext\': BuildExt},\n    zip_safe=False)\n'"
examples/MNIST/__init__.py,0,b''
examples/MNIST/mnist_util.py,11,"b'#!/usr/bin/python3\n\n# ******************************************************************************\n# Copyright 2018-2019 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# *****************************************************************************\n\nimport tensorflow as tf\nimport numpy as np\nimport argparse\nfrom tensorflow.core.protobuf import rewriter_config_pb2\n\n\ndef load_mnist_data():\n    """"""Returns MNIST data in one-hot form""""""\n    mnist = tf.keras.datasets.mnist\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    y_train = tf.compat.v1.keras.utils.to_categorical(y_train, num_classes=10)\n    y_test = tf.compat.v1.keras.utils.to_categorical(y_test, num_classes=10)\n    x_train = np.expand_dims(x_train, axis=-1)\n    x_test = np.expand_dims(x_test, axis=-1)\n\n    return (x_train, y_train, x_test, y_test)\n\n\ndef get_train_batch(train_iter, batch_size, x_train, y_train):\n    """"""Returns training batch from dataset""""""\n    start_index = train_iter * batch_size\n    end_index = start_index + batch_size\n\n    data_count = x_train.shape[0]\n\n    if start_index > data_count and end_index > data_count:\n        start_index %= data_count\n        end_index %= data_count\n        x_batch = x_train[start_index:end_index]\n        y_batch = y_train[start_index:end_index]\n    elif end_index > data_count:\n        end_index %= data_count\n        x_batch = np.concatenate((x_train[start_index:], x_train[0:end_index]))\n        y_batch = np.concatenate((y_train[start_index:], y_train[0:end_index]))\n    else:\n        x_batch = x_train[start_index:end_index]\n        y_batch = y_train[start_index:end_index]\n\n    return x_batch, y_batch\n\n\ndef conv2d_stride_2_valid(x, W, name=None):\n    """"""returns a 2d convolution layer with stride 2, valid pooling""""""\n    return tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding=\'VALID\')\n\n\ndef avg_pool_3x3_same_size(x):\n    """"""3x3 avg_pool using same padding, keeping original feature map size""""""\n    return tf.nn.avg_pool2d(\n        x, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n\n\ndef max_pool_3x3_same_size(x):\n    """"""3x3 avg_pool using same padding, keeping original feature map size""""""\n    return tf.nn.max_pool2d(\n        x, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n\n\ndef get_variable(name, shape, mode):\n    if mode not in set([\'train\', \'test\']):\n        print(\'mode should be train or test\')\n        raise Exception()\n\n    if mode == \'train\':\n        return tf.compat.v1.get_variable(name, shape)\n    else:\n        return tf.constant(\n            np.loadtxt(name + \'.txt\', dtype=np.float32).reshape(shape))\n\n\ndef str2bool(v):\n    if isinstance(v, bool):\n        return v\n    if v.lower() in (\'yes\', \'true\', \'t\', \'y\', \'1\'):\n        return True\n    elif v.lower() in (\'no\', \'false\', \'f\', \'n\', \'0\'):\n        return False\n    else:\n        raise argparse.ArgumentTypeError(\'Boolean value expected.\')\n\n\ndef server_argument_parser():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--batch_size\', type=int, default=1, help=\'Batch size\')\n    parser.add_argument(\n        \'--enable_client\',\n        type=str2bool,\n        default=False,\n        help=\'Enable the client\')\n    parser.add_argument(\n        \'--backend\',\n        type=str,\n        default=\'HE_SEAL\',\n        help=\'Name of backend to use\')\n    parser.add_argument(\n        \'--encryption_parameters\',\n        type=str,\n        default=\'\',\n        help=\n        \'Filename containing json description of encryption parameters, or json description itself\'\n    )\n    parser.add_argument(\n        \'--encrypt_server_data\',\n        type=str2bool,\n        default=False,\n        help=\n        \'Encrypt server data (should not be used when enable_client is used)\')\n    parser.add_argument(\n        \'--pack_data\',\n        type=str2bool,\n        default=True,\n        help=\'Use plaintext packing on data\')\n\n    return parser\n\n\ndef server_config_from_flags(FLAGS, tensor_param_name):\n    rewriter_options = rewriter_config_pb2.RewriterConfig()\n    rewriter_options.meta_optimizer_iterations = (\n        rewriter_config_pb2.RewriterConfig.ONE)\n    rewriter_options.min_graph_nodes = -1\n    server_config = rewriter_options.custom_optimizers.add()\n    server_config.name = ""ngraph-optimizer""\n    server_config.parameter_map[""ngraph_backend""].s = FLAGS.backend.encode()\n    server_config.parameter_map[""device_id""].s = b\'\'\n    server_config.parameter_map[\n        ""encryption_parameters""].s = FLAGS.encryption_parameters.encode()\n    server_config.parameter_map[\'enable_client\'].s = str(\n        FLAGS.enable_client).encode()\n\n    if FLAGS.enable_client:\n        server_config.parameter_map[tensor_param_name].s = b\'client_input\'\n    elif FLAGS.encrypt_server_data:\n        server_config.parameter_map[tensor_param_name].s = b\'encrypt\'\n\n    if FLAGS.pack_data:\n        server_config.parameter_map[tensor_param_name].s += b\',packed\'\n\n    config = tf.compat.v1.ConfigProto()\n    config.MergeFrom(\n        tf.compat.v1.ConfigProto(\n            graph_options=tf.compat.v1.GraphOptions(\n                rewrite_options=rewriter_options)))\n\n    return config\n'"
examples/MNIST/pyclient_mnist.py,0,"b'# ==============================================================================\n#  Copyright 2018-2019 Intel Corporation\n#\n#  Licensed under the Apache License, Version 2.0 (the ""License"");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an ""AS IS"" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n# ==============================================================================\n\nimport time\nimport argparse\nimport numpy as np\nimport sys\nimport os\n\nfrom mnist_util import load_mnist_data, str2bool\nimport pyhe_client\n\n\ndef test_mnist_cnn(FLAGS):\n    (x_train, y_train, x_test, y_test) = load_mnist_data()\n\n    x_test_batch = x_test[:FLAGS.batch_size]\n    y_test_batch = y_test[:FLAGS.batch_size]\n\n    data = x_test_batch.flatten(\'C\')\n    print(\'Client batch size from FLAG:\', FLAGS.batch_size)\n\n    port = 34000\n\n    encrypt_str = \'encrypt\' if FLAGS.encrypt_data else \'plain\'\n    client = pyhe_client.HESealClient(FLAGS.hostname, port, FLAGS.batch_size,\n                                      {\'input\': (encrypt_str, data)})\n\n    results = client.get_results()\n    results = np.round(results, 2)\n\n    y_pred_reshape = np.array(results).reshape(FLAGS.batch_size, 10)\n    with np.printoptions(precision=3, suppress=True):\n        print(y_pred_reshape)\n\n    y_pred = y_pred_reshape.argmax(axis=1)\n    print(\'y_pred\', y_pred)\n    y_true = y_test_batch.argmax(axis=1)\n\n    correct = np.sum(np.equal(y_pred, y_true))\n    acc = correct / float(FLAGS.batch_size)\n    print(\'pred size\', len(y_pred))\n    print(\'correct\', correct)\n    print(\'Accuracy (batch size\', FLAGS.batch_size, \') =\', acc * 100., \'%\')\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--batch_size\', type=int, default=1, help=\'Batch size\')\n    parser.add_argument(\n        \'--hostname\', type=str, default=\'localhost\', help=\'Hostname of server\')\n    parser.add_argument(\n        \'--encrypt_data\',\n        type=str2bool,\n        default=True,\n        help=\'Whether or not to encrypt client data\')\n\n    FLAGS, unparsed = parser.parse_known_args()\n\n    print(FLAGS)\n\n    test_mnist_cnn(FLAGS)\n'"
examples/ImageNet/MobileNetV2/client.py,4,"b'# ******************************************************************************\n# Copyright 2018-2019 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# *****************************************************************************\n\nimport tensorflow as tf\nfrom tensorflow.python.platform import gfile\n\nimport ngraph_bridge\nimport pyhe_client\n\nimport numpy as np\nimport argparse\nimport os\nimport util\nimport numpy as np\nfrom PIL import Image\nfrom util import get_imagenet_inference_labels, \\\n                 get_imagenet_training_labels, \\\n                 get_validation_image, \\\n                 get_validation_images, \\\n                 get_validation_labels, \\\n                 str2bool\n\n\ndef print_nodes(filename):\n    graph_def = read_pb_file(filename)\n    nodes = [n.name for n in graph_def.node]\n    print(\'nodes\', len(nodes))\n    for node in sorted(nodes):\n        print(node)\n\n\ndef read_pb_file(filename):\n    sess = tf.compat.v1.Session()\n    print(""load graph"", filename)\n    with gfile.GFile(filename, \'rb\') as f:\n        graph_def = tf.compat.v1.GraphDef()\n    graph_def.ParseFromString(f.read())\n    sess.graph.as_default()\n    tf.import_graph_def(graph_def, name=\'\')\n    return graph_def\n\n\ndef get_imagenet_labels():\n    labels_path = tf.keras.utils.get_file(\n        \'ImageNetLabels.txt\',\n        \'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\'\n    )\n    imagenet_labels = np.array(open(labels_path).read().splitlines())\n    return imagenet_labels\n\n\ndef main(FLAGS):\n    imagenet_inference_labels = get_imagenet_inference_labels()\n    imagenet_training_labels = get_imagenet_training_labels()\n    assert (\n        sorted(imagenet_training_labels) == sorted(imagenet_inference_labels))\n    validation_nums = get_validation_labels(FLAGS)\n    x_test = get_validation_images(FLAGS)\n    validation_labels = imagenet_inference_labels[validation_nums]\n\n    if FLAGS.batch_size < 10:\n        print(\'validation_labels\', validation_labels)\n\n    (batch_size, width, height, channels) = x_test.shape\n    print(\'batch_size\', batch_size)\n    print(\'width\', width)\n    print(\'height\', height)\n    print(\'channels\', channels)\n\n    x_test_flat = x_test.flatten(order=\'C\')\n    port = 34000\n\n    client = pyhe_client.HESealClient(FLAGS.hostname, port, batch_size,\n                                      {\'input\': (\'encrypt\', x_test_flat)})\n\n    results = client.get_results()\n\n    imagenet_labels = get_imagenet_labels()\n    results = np.array(results)\n\n    if (FLAGS.batch_size == 1):\n        top5 = results.argsort()[-5:]\n    else:\n        results = np.reshape(results, (FLAGS.batch_size, 1001))\n        top5 = np.flip(results.argsort()[:, -5:], axis=1)\n\n    preds = imagenet_labels[top5]\n    print(\'validation_labels\', validation_labels)\n    print(\'top5\', preds)\n\n    util.accuracy(preds, validation_labels)\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \'--data_dir\',\n        type=str,\n        default=None,\n        help=\n        \'Directory where cropped ImageNet data and ground truth labels are stored\'\n    )\n    parser.add_argument(\n        \'--image_size\', type=int, default=96, help=\'image size\')\n    parser.add_argument(\n        \'--save_images\',\n        type=str2bool,\n        default=False,\n        help=\'save cropped images\')\n    parser.add_argument(\n        \'--load_cropped_images\',\n        type=str2bool,\n        default=False,\n        help=\'load saved cropped images\')\n    parser.add_argument(\n        \'--standardize\',\n        type=str2bool,\n        default=False,\n        help=\'subtract training set mean from each image\')\n    parser.add_argument(\n        \'--crop_size\',\n        type=int,\n        default=256,\n        help=\'crop to this size before resizing to image_size\')\n    parser.add_argument(\n        \'--hostname\', type=str, default=\'localhost\', help=\'server hostname\')\n    parser.add_argument(\'--batch_size\', type=int, default=1, help=\'Batch size\')\n    parser.add_argument(\n        \'--start_batch\', type=int, default=0, help=\'Test data start index\')\n\n    FLAGS, unparsed = parser.parse_known_args()\n    if FLAGS.data_dir == None:\n        print(\'data_dir must be specified\')\n        exit(1)\n\n    print(FLAGS)\n    main(FLAGS)'"
examples/ImageNet/MobileNetV2/get_models.py,0,"b'# ******************************************************************************\n# Copyright 2018-2019 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# *****************************************************************************\n\nimport os\nimport sys\n\n\n# See here: https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet\n# for a description of models used\ndef main():\n    if not os.path.exists(\'model\'):\n        os.mkdir(\'model\')\n    os.chdir(os.path.join(sys.path[0], \'model\'))\n\n    url_prefix = \'https://storage.googleapis.com/mobilenet_v2/checkpoints/\'\n    filename_suffix = \'.tgz\'\n    filename_prefixes = [\n        \'mobilenet_v2_0.35_96\', \'mobilenet_v2_0.35_128\',\n        \'mobilenet_v2_0.35_160\', \'mobilenet_v2_0.35_192\',\n        \'mobilenet_v2_0.35_224\', \'mobilenet_v2_0.5_96\', \'mobilenet_v2_0.5_128\',\n        \'mobilenet_v2_0.5_160\', \'mobilenet_v2_0.5_192\', \'mobilenet_v2_0.5_224\',\n        \'mobilenet_v2_0.75_96\', \'mobilenet_v2_0.75_128\',\n        \'mobilenet_v2_0.75_160\', \'mobilenet_v2_0.75_192\',\n        \'mobilenet_v2_0.75_224\', \'mobilenet_v2_1.0_96\', \'mobilenet_v2_1.0_128\',\n        \'mobilenet_v2_1.0_160\', \'mobilenet_v2_1.0_192\', \'mobilenet_v2_1.0_224\',\n        \'mobilenet_v2_1.3_224\', \'mobilenet_v2_1.4_224\'\n    ]\n    pb_suffix = \'_frozen.pb\'\n    opt_suffix = \'_opt.pb\'\n\n    for filename_prefix in filename_prefixes:\n        filename = filename_prefix + filename_suffix\n        if not os.path.isfile(filename):\n            os.system(\'wget \' + url_prefix + filename)\n\n        pb_filename = filename_prefix + pb_suffix\n\n        if not os.path.isfile(pb_filename):\n            os.system(\'tar -zxvf \' + filename)\n\n        opt_filename = filename_prefix + opt_suffix\n\n        if not os.path.isfile(opt_filename):\n            transform_cmd = \'transform_graph --in_graph=\'\n            transform_cmd += pb_filename\n            transform_cmd += \' --out_graph=\'\n            transform_cmd += opt_filename\n            transform_cmd += \' --inputs=""Placeholder""\'\n            transform_cmd += \' --outputs=""MobilenetV2/Logits/Conv2d_1c_1x1/BiasAdd""\'\n            transform_cmd += \'\'\' --transforms=""strip_unused_nodes remove_nodes(op=Identity)\'\'\'\n            transform_cmd += \'\'\' fold_constants(ignore_errors=true) fold_batch_norms""\'\'\'\n            print(\'transform_cmd\')\n            print(transform_cmd)\n            os.system(transform_cmd)\n\n\nif __name__ == \'__main__\':\n    main()'"
examples/ImageNet/MobileNetV2/test.py,5,"b'# ******************************************************************************\n# Copyright 2018-2019 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# *****************************************************************************\n\nimport tensorflow as tf\nfrom tensorflow.python.platform import gfile\nimport numpy as np\nimport argparse\nimport time\nimport PIL\nfrom PIL import Image\nimport multiprocessing as mp\nimport util\nimport ngraph_bridge\n\nfrom util import get_imagenet_inference_labels, \\\n                 get_imagenet_training_labels, \\\n                 get_validation_image, \\\n                 get_validation_images, \\\n                 get_validation_labels, \\\n                 str2bool, \\\n                 server_argument_parser, \\\n                 server_config_from_flags\n\n\ndef print_nodes(filename):\n    graph_def = load_model(filename)\n    nodes = [n.name for n in graph_def.node]\n    print(\'nodes\', len(nodes))\n    for node in sorted(nodes):\n        print(node)\n\n\ndef load_model(filename):\n    print(""loading graph"", filename)\n    sess = tf.compat.v1.Session()\n    with gfile.GFile(filename, \'rb\') as f:\n        graph_def = tf.compat.v1.GraphDef()\n    graph_def.ParseFromString(f.read())\n    sess.graph.as_default()\n    tf.import_graph_def(graph_def, name=\'\')\n    return graph_def\n\n\ndef main(FLAGS):\n\n    if FLAGS.enable_client:\n        print(\'Using client\')\n    else:\n        print(\'Not using client\')\n\n    imagenet_inference_labels = get_imagenet_inference_labels()\n    imagenet_training_labels = get_imagenet_training_labels()\n\n    util.VAL_IMAGE_FLAGS = FLAGS\n\n    assert (\n        sorted(imagenet_training_labels) == sorted(imagenet_inference_labels))\n\n    validation_nums = get_validation_labels(FLAGS)\n    validation_labels = imagenet_inference_labels[validation_nums]\n\n    if FLAGS.enable_client:\n        # Server input is dummy\n        x_test = np.random.rand(FLAGS.batch_size, FLAGS.image_size,\n                                FLAGS.image_size, 3)\n    else:\n        x_test = get_validation_images(FLAGS)\n\n    config = server_config_from_flags(FLAGS, \'input\')\n\n    sess = tf.compat.v1.Session(config=config)\n    graph_def = load_model(FLAGS.model)\n\n    tf.import_graph_def(graph_def, name=\'\')\n\n    input_tensor = sess.graph.get_tensor_by_name(\'input:0\')\n    output_tensor = sess.graph.get_tensor_by_name(\n        \'MobilenetV2/Logits/Conv2d_1c_1x1/BiasAdd:0\')\n\n    print(\'performing inference\')\n    start_time = time.time()\n    y_pred = sess.run(output_tensor, {input_tensor: x_test})\n    end_time = time.time()\n    runtime = end_time - start_time\n    per_image_runtime = runtime / float(FLAGS.batch_size)\n    print(\'performed inference, runtime (s):\', np.round(runtime, 2))\n    print(\'runtime per image (s)\', np.round(per_image_runtime, 2))\n    y_pred = np.squeeze(y_pred)\n\n    if (FLAGS.batch_size == 1):\n        top5 = y_pred.argsort()[-5:]\n    else:\n        top5 = np.flip(y_pred.argsort()[:, -5:], axis=1)\n\n    if not FLAGS.enable_client:\n        preds = imagenet_training_labels[top5]\n\n        if FLAGS.batch_size < 10:\n            print(\'validation_labels\', validation_labels)\n            print(\'validation_labels shape\', validation_labels.shape)\n            print(\'preds\', preds)\n            print(\'preds shape\', preds.shape)\n\n        util.accuracy(preds, validation_labels)\n\n\nif __name__ == \'__main__\':\n    parser = server_argument_parser()\n    parser.add_argument(\n        \'--data_dir\',\n        type=str,\n        default=None,\n        help=\n        \'Directory where cropped ImageNet data and ground truth labels are stored\'\n    )\n    parser.add_argument(\n        \'--model\',\n        type=str,\n        default=\'./model/mobilenet_v2_0.35_96_opt.pb\',\n        help=\'Model to run inference with\')\n    parser.add_argument(\n        \'--image_size\', type=int, default=96, help=\'image size\')\n    parser.add_argument(\n        \'--save_images\',\n        type=str2bool,\n        default=False,\n        help=\'save cropped images\')\n    parser.add_argument(\n        \'--load_cropped_images\',\n        type=str2bool,\n        default=False,\n        help=\'load saved cropped images\')\n    parser.add_argument(\n        \'--standardize\',\n        type=str2bool,\n        default=False,\n        help=\'subtract training set mean from each image\')\n    parser.add_argument(\n        \'--crop_size\',\n        type=int,\n        default=256,\n        help=\'crop to this size before resizing to image_size\')\n    parser.add_argument(\n        \'--ngraph\', type=str2bool, default=False, help=\'use ngraph backend\')\n    parser.add_argument(\n        \'--start_batch\', type=int, default=0, help=\'Test data start index\')\n\n    FLAGS, unparsed = parser.parse_known_args()\n    if FLAGS.data_dir == None:\n        print(\'data_dir must be specified\')\n        exit(1)\n\n    print(FLAGS)\n    main(FLAGS)'"
examples/ImageNet/MobileNetV2/util.py,5,"b'# ******************************************************************************\n# Copyright 2018-2019 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# *****************************************************************************\n\nimport tensorflow as tf\nfrom tensorflow.python.platform import gfile\nimport numpy as np\nimport argparse\nimport os\nimport time\nimport PIL\nfrom PIL import Image\nimport multiprocessing as mp\nfrom functools import partial\nfrom tensorflow.core.protobuf import rewriter_config_pb2\n\n\ndef get_imagenet_training_labels():\n    labels_path = tf.keras.utils.get_file(\n        \'ImageNetLabels.txt\',\n        \'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\'\n    )\n    imagenet_labels = np.array(open(labels_path).read().splitlines())\n    return imagenet_labels\n\n\ndef get_imagenet_inference_labels():\n    filename = ""https://gist.githubusercontent.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57/raw/aa66dd9dbf6b56649fa3fab83659b2acbf3cbfd1/map_clsloc.txt""\n\n    labels_path = tf.keras.utils.get_file(\'map_clsloc.txt\', filename)\n    labels = open(labels_path).read().splitlines()\n    labels = [\'background\'] + [label.split()[2] for label in labels]\n    labels = [label.replace(\'_\', \' \') for label in labels]\n    labels = np.array(labels)\n    return labels\n\n\ndef str2bool(v):\n    if isinstance(v, bool):\n        return v\n    if v.lower() in (\'yes\', \'true\', \'t\', \'y\', \'1\'):\n        return True\n    elif v.lower() in (\'no\', \'false\', \'f\', \'n\', \'0\'):\n        return False\n    else:\n        raise argparse.ArgumentTypeError(\'Boolean value expected.\')\n\n\ndef get_validation_labels(FLAGS):\n    data_dir = FLAGS.data_dir\n    ground_truth_filename = \'ILSVRC2012_validation_ground_truth.txt\'\n\n    truth_file = os.path.join(data_dir, ground_truth_filename)\n    if not os.path.isfile(truth_file):\n        print(\'Cannot find \', ground_truth_filename, \' in \', data_dir)\n        print(\'File \', truth_file, \' does not exist\')\n        exit(1)\n\n    truth_labels = np.loadtxt(truth_file, dtype=np.int32)\n    assert (truth_labels.shape == (50000, ))\n    return truth_labels[FLAGS.start_batch:FLAGS.start_batch + FLAGS.batch_size]\n\n\ndef center_crop(im, new_size):\n    # Center-crop image\n    width, height = im.size\n    left = (width - new_size) / 2\n    top = (height - new_size) / 2\n    right = (width + new_size) / 2\n    bottom = (height + new_size) / 2\n    im = im.crop((left, top, right, bottom))\n    assert (im.size == (new_size, new_size))\n    return im\n\n\ndef center_crop2(im, new_size):\n    # Resize such that shortest side has new_size\n    width, height = im.size\n    ratio = min(width / new_size, height / new_size)\n    im = im.resize((int(width / ratio), int(height / ratio)),\n                   resample=Image.LANCZOS)\n\n    # Center crop to new_size x new_size\n    im = center_crop(im, new_size)\n    return im\n\n\ndef get_validation_image(i, FLAGS):\n    image_num_str = str(i + 1).zfill(8)\n    data_dir = FLAGS.data_dir\n    crop_size = FLAGS.crop_size\n\n    image_prefix = \'validation_images/ILSVRC2012_val_\' + image_num_str\n    image_suffix = \'.JPEG\'\n    image_name = image_prefix + image_suffix\n\n    crop_filename = os.path.join(data_dir, image_prefix + \'_crop\' + \'.png\')\n\n    filename = os.path.join(data_dir, image_name)\n    if FLAGS.batch_size < 10:\n        print(\'opening image at\', filename)\n    if not os.path.isfile(filename):\n        print(\'Cannot find image \', filename)\n        exit(1)\n\n    if FLAGS.load_cropped_images:\n        im = Image.open(crop_filename)\n    else:\n        im = Image.open(filename)\n        im = center_crop2(im, crop_size)\n        im = im.resize((FLAGS.image_size, FLAGS.image_size), PIL.Image.LANCZOS)\n\n    # Fix grey images\n    if im.mode != ""RGB"":\n        im = im.convert(mode=""RGB"")\n    assert (im.size == (FLAGS.image_size, FLAGS.image_size))\n\n    if FLAGS.save_images:\n        im.save(crop_filename, ""PNG"")\n    im = np.array(im, dtype=np.float)\n\n    assert (im.shape == (FLAGS.image_size, FLAGS.image_size, 3))\n\n    # Standardize to [-1,1]\n    if FLAGS.standardize:\n        im = im / 255.\n        means = [0.485, 0.456, 0.406]\n        stds = [0.229, 0.224, 0.225]\n        # Subtract mean, then scale such that result is in (-1, 1)\n        for channel in range(3):\n            im[:, :, channel] = (im[:, :, channel] - means[channel]) * (\n                1. / means[channel])\n    else:\n        im = im / 128. - 1\n    im = np.expand_dims(im, axis=0)\n    return im\n\n\ndef get_validation_images(FLAGS, crop=False):\n    print(\'getting validation images\')\n    FLAGS = FLAGS\n    images = np.empty((FLAGS.batch_size, FLAGS.image_size, FLAGS.image_size,\n                       3))\n    end_idx = min(FLAGS.start_batch + FLAGS.batch_size, 50000)\n\n    with mp.Pool() as pool:\n        images[:] = pool.map(\n            partial(get_validation_image, FLAGS=FLAGS),\n            range(FLAGS.start_batch, end_idx))\n\n    print(\'got validation images\')\n    return images\n\n\ndef accuracy(preds, truth):\n    truth = truth.flatten()\n    num_preds = truth.size\n\n    if (preds.shape[0] != num_preds):\n        preds = preds.T\n    assert (preds.shape[0] == num_preds)\n\n    if num_preds == 1:\n        top1_cnt = int(truth[0] == preds[0])\n        top5_cnt = int(truth[0] in preds)\n    else:\n        top1_cnt = 0\n        top5_cnt = 0\n        for i in range(num_preds):\n            if preds[i][0] == truth[i]:\n                top1_cnt += 1\n            if truth[i] in preds[i]:\n                top5_cnt += 1\n\n    top5_acc = top5_cnt / float(num_preds) * 100.\n    top1_acc = top1_cnt / float(num_preds) * 100.\n\n    print(\'Accuracy on\', num_preds, \'predictions:\')\n    print(\'top1_acc\', np.round(top1_acc, 3))\n    print(\'top5_acc\', np.round(top5_acc, 3))\n\n\ndef server_argument_parser():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--batch_size\', type=int, default=1, help=\'Batch size\')\n    parser.add_argument(\n        \'--enable_client\',\n        type=str2bool,\n        default=False,\n        help=\'Enable the client\')\n    parser.add_argument(\n        \'--backend\',\n        type=str,\n        default=\'HE_SEAL\',\n        help=\'Name of backend to use\')\n    parser.add_argument(\n        \'--encryption_parameters\',\n        type=str,\n        default=\'\',\n        help=\n        \'Filename containing json description of encryption parameters, or json description itself\'\n    )\n    parser.add_argument(\n        \'--encrypt_server_data\',\n        type=str2bool,\n        default=False,\n        help=\n        \'Encrypt server data (should not be used when enable_client is used)\')\n    parser.add_argument(\n        \'--pack_data\',\n        type=str2bool,\n        default=True,\n        help=\'Use plaintext packing on data\')\n\n    return parser\n\n\ndef server_config_from_flags(FLAGS, tensor_param_name):\n    rewriter_options = rewriter_config_pb2.RewriterConfig()\n    rewriter_options.meta_optimizer_iterations = (\n        rewriter_config_pb2.RewriterConfig.ONE)\n    rewriter_options.min_graph_nodes = -1\n    server_config = rewriter_options.custom_optimizers.add()\n    server_config.name = ""ngraph-optimizer""\n    server_config.parameter_map[""ngraph_backend""].s = FLAGS.backend.encode()\n    server_config.parameter_map[""device_id""].s = b\'\'\n    server_config.parameter_map[\n        ""encryption_parameters""].s = FLAGS.encryption_parameters.encode()\n    server_config.parameter_map[\'enable_client\'].s = str(\n        FLAGS.enable_client).encode()\n\n    if FLAGS.enable_client:\n        server_config.parameter_map[tensor_param_name].s = b\'client_input\'\n    elif FLAGS.encrypt_server_data:\n        server_config.parameter_map[tensor_param_name].s = b\'encrypt\'\n\n    if FLAGS.pack_data:\n        server_config.parameter_map[tensor_param_name].s += b\',packed\'\n\n    config = tf.compat.v1.ConfigProto()\n    config.MergeFrom(\n        tf.compat.v1.ConfigProto(\n            graph_options=tf.compat.v1.GraphOptions(\n                rewrite_options=rewriter_options)))\n\n    return config\n'"
examples/MNIST/Cryptonets-Relu/__init__.py,0,b''
examples/MNIST/Cryptonets-Relu/model.py,7,"b'# ******************************************************************************\n# Copyright 2018-2019 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# *****************************************************************************\n\nimport tensorflow as tf\nimport numpy as np\nimport os\nimport sys\n\n# Add parent directory to path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom mnist_util import load_mnist_data, \\\n    get_variable, \\\n    conv2d_stride_2_valid, \\\n    avg_pool_3x3_same_size, \\\n    max_pool_3x3_same_size\n\n\ndef cryptonets_relu_model(x, mode):\n    if mode not in set([\'train\', \'test\']):\n        print(\'mode should be train or test\')\n        raise Exception()\n\n    paddings = tf.constant([[0, 0], [0, 1], [0, 1], [0, 0]], name=\'pad_const\')\n    x = tf.pad(x, paddings)\n\n    W_conv1 = get_variable(\'W_conv1\', [5, 5, 1, 5], mode)\n    y = conv2d_stride_2_valid(x, W_conv1)\n    W_bc1 = get_variable(\'W_conv1_bias\', [1, 13, 13, 5], mode)\n    y = y + W_bc1\n    y = tf.nn.relu(y)\n\n    y = avg_pool_3x3_same_size(y)\n    W_conv2 = get_variable(\'W_conv2\', [5, 5, 5, 50], mode)\n    y = conv2d_stride_2_valid(y, W_conv2)\n    y = avg_pool_3x3_same_size(y)\n\n    y = tf.reshape(y, [-1, 5 * 5 * 50])\n    W_fc1 = get_variable(\'W_fc1\', [5 * 5 * 50, 100], mode)\n    W_b1 = get_variable(\'W_fc1_bias\', [100], mode)\n    y = tf.matmul(y, W_fc1)\n    y = y + W_b1\n    y = tf.nn.relu(y)\n\n    W_fc2 = get_variable(\'W_fc2\', [100, 10], mode)\n    W_b2 = get_variable(\'W_fc2_bias\', [10], mode)\n    y = tf.matmul(y, W_fc2)\n    y = y + W_b2\n    return y'"
examples/MNIST/Cryptonets-Relu/test.py,9,"b'# ==============================================================================\n#  Copyright 2018-2019 Intel Corporation\n#\n#  Licensed under the Apache License, Version 2.0 (the ""License"");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an ""AS IS"" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n# ==============================================================================\n""""""An MNIST classifier using convolutional layers and relu activations. """"""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\nimport time\nimport numpy as np\nimport itertools\nimport glob\nimport tensorflow as tf\nimport model\nimport ngraph_bridge\nimport os\nfrom tensorflow.core.protobuf import rewriter_config_pb2\n\n# Add parent directory to path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom mnist_util import load_mnist_data, \\\n                       get_variable, \\\n                       conv2d_stride_2_valid, \\\n                       str2bool, \\\n                       server_argument_parser, \\\n                       server_config_from_flags\n\n\ndef cryptonets_relu_test_squashed(x):\n    """"""Constructs test network for Cryptonets Relu using saved weights.\n       Assumes linear layers have been squashed.""""""\n    paddings = [[0, 0], [0, 1], [0, 1], [0, 0]]\n    x = tf.pad(x, paddings)\n\n    W_conv1 = get_variable(\'W_conv1\', [5, 5, 1, 5], \'test\')\n    y = conv2d_stride_2_valid(x, W_conv1)\n    W_bc1 = get_variable(\'W_conv1_bias\', [1, 13, 13, 5], \'test\')\n    y = tf.nn.relu(y)\n\n    W_squash = get_variable(\'W_squash\', [5 * 13 * 13, 100], \'test\')\n    y = tf.reshape(y, [-1, 5 * 13 * 13])\n    y = tf.matmul(y, W_squash)\n    W_b1 = get_variable(\'W_fc1_bias\', [100], \'test\')\n    y = y + W_b1\n\n    y = tf.nn.relu(y)\n    W_fc2 = get_variable(\'W_fc2\', [100, 10], \'test\')\n    y = tf.matmul(y, W_fc2)\n\n    W_b2 = get_variable(\'W_fc2_bias\', [10], \'test\')\n    y = y + W_b2\n\n    return y\n\n\ndef test_cryptonets_relu(FLAGS):\n    (x_train, y_train, x_test, y_test) = load_mnist_data()\n\n    x = tf.compat.v1.placeholder(tf.float32, [None, 28, 28, 1], name=\'input\')\n    y_ = tf.compat.v1.placeholder(tf.float32, [None, 10])\n\n    # Create the model\n    y_conv = cryptonets_relu_test_squashed(x)\n\n    config = server_config_from_flags(FLAGS, x.name)\n    print(\'config\', config)\n\n    with tf.compat.v1.Session(config=config) as sess:\n        x_test = x_test[:FLAGS.batch_size]\n        y_test = y_test[:FLAGS.batch_size]\n        start_time = time.time()\n        y_conv_val = y_conv.eval(feed_dict={x: x_test, y_: y_test})\n        elasped_time = (time.time() - start_time)\n        print(""total time(s)"", np.round(elasped_time, 3))\n\n    if not FLAGS.enable_client:\n        y_test_batch = y_test[:FLAGS.batch_size]\n        y_label_batch = np.argmax(y_test_batch, 1)\n\n        y_pred = np.argmax(y_conv_val, 1)\n        correct_prediction = np.equal(y_pred, y_label_batch)\n        error_count = np.size(correct_prediction) - np.sum(correct_prediction)\n        test_accuracy = np.mean(correct_prediction)\n\n        print(\'Error count\', error_count, \'of\', FLAGS.batch_size, \'elements.\')\n        print(\'Accuracy: %g \' % test_accuracy)\n\n\nif __name__ == \'__main__\':\n    parser = server_argument_parser()\n    FLAGS, unparsed = parser.parse_known_args()\n\n    if unparsed:\n        print(\'Unparsed flags:\', unparsed)\n    if FLAGS.encrypt_server_data and FLAGS.enable_client:\n        raise Exception(\n            ""encrypt_server_data flag only valid when client is not enabled. Note: the client can specify whether or not to encrypt the data using \'encrypt\' or \'plain\' in the configuration map""\n        )\n\n    test_cryptonets_relu(FLAGS)\n'"
examples/MNIST/Cryptonets-Relu/train.py,20,"b'# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""An MNIST classifier based on Cryptonets using convolutional layers. """"""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\nimport time\nimport numpy as np\nimport itertools\nimport tensorflow as tf\nimport model\nimport os\n\n# Add parent directory to path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom mnist_util import load_mnist_data, \\\n    get_variable, \\\n    conv2d_stride_2_valid, \\\n    avg_pool_3x3_same_size, \\\n    get_train_batch\n\n\n# Squash weights and save as W_squash.txt\ndef squash_layers():\n    print(""Squashing layers"")\n    tf.compat.v1.reset_default_graph()\n\n    # Input from h_conv1 squaring\n    x = tf.compat.v1.placeholder(tf.float32, [None, 13, 13, 5])\n\n    # Pooling layer\n    h_pool1 = avg_pool_3x3_same_size(x)  # To N x 13 x 13 x 5\n\n    # Second convolution\n    W_conv2 = np.loadtxt(\n        \'W_conv2.txt\', dtype=np.float32).reshape([5, 5, 5, 50])\n    h_conv2 = conv2d_stride_2_valid(h_pool1, W_conv2)\n\n    # Second pooling layer.\n    h_pool2 = avg_pool_3x3_same_size(h_conv2)\n\n    # Fully connected layer 1\n    # Input: N x 5 x 5 x 50\n    # Output: N x 100\n    W_fc1 = np.loadtxt(\n        \'W_fc1.txt\', dtype=np.float32).reshape([5 * 5 * 50, 100])\n    h_pool2_flat = tf.reshape(h_pool2, [-1, 5 * 5 * 50])\n    pre_square = tf.matmul(h_pool2_flat, W_fc1)\n\n    with tf.compat.v1.Session() as sess:\n        x_in = np.eye(13 * 13 * 5)\n        x_in = x_in.reshape([13 * 13 * 5, 13, 13, 5])\n        W = (sess.run([pre_square], feed_dict={x: x_in}))[0]\n        squashed_file_name = ""W_squash.txt""\n        np.savetxt(squashed_file_name, W)\n        print(""Saved to"", squashed_file_name)\n\n        # Sanity check\n        x_in = np.random.rand(100, 13, 13, 5)\n        network_out = (sess.run([pre_square], feed_dict={x: x_in}))[0]\n        linear_out = x_in.reshape(100, 13 * 13 * 5).dot(W)\n        assert (np.max(np.abs(linear_out - network_out)) < 1e-5)\n\n    print(""Squashed layers"")\n\n\ndef main(FLAGS):\n    (x_train, y_train, x_test, y_test) = load_mnist_data()\n\n    x = tf.compat.v1.placeholder(tf.float32, [None, 28, 28, 1])\n    y_ = tf.compat.v1.placeholder(tf.float32, [None, 10])\n    y_conv = model.cryptonets_relu_model(x, \'train\')\n\n    with tf.name_scope(\'loss\'):\n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n            labels=y_, logits=y_conv)\n    cross_entropy = tf.reduce_mean(cross_entropy)\n\n    with tf.name_scope(\'adam_optimizer\'):\n        train_step = tf.compat.v1.train.AdamOptimizer(1e-4).minimize(\n            cross_entropy)\n\n    with tf.name_scope(\'accuracy\'):\n        correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n        correct_prediction = tf.cast(correct_prediction, tf.float32)\n    accuracy = tf.reduce_mean(correct_prediction)\n\n    with tf.compat.v1.Session() as sess:\n        sess.run(tf.compat.v1.global_variables_initializer())\n        for i in range(FLAGS.train_loop_count):\n            x_batch, y_batch = get_train_batch(i, FLAGS.batch_size, x_train,\n                                               y_train)\n            if i % 100 == 0:\n                t = time.time()\n                train_accuracy = accuracy.eval(feed_dict={\n                    x: x_batch,\n                    y_: y_batch\n                })\n                print(\'step %d, training accuracy %g, %g msec to evaluate\' %\n                      (i, train_accuracy, 1000 * (time.time() - t)))\n            t = time.time()\n            _, loss = sess.run([train_step, cross_entropy],\n                               feed_dict={\n                                   x: x_batch,\n                                   y_: y_batch\n                               })\n\n            if i % 1000 == 999 or i == FLAGS.train_loop_count - 1:\n                test_accuracy = accuracy.eval(feed_dict={\n                    x: x_test,\n                    y_: y_test\n                })\n                print(\'test accuracy %g\' % test_accuracy)\n\n        print(""Training finished. Saving variables."")\n        for var in tf.compat.v1.get_collection(\n                tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES):\n            weight = (sess.run([var]))[0].flatten().tolist()\n            filename = (str(var).split())[1].replace(\'/\', \'_\')\n            filename = filename.replace(""\'"", """").replace(\':0\', \'\') + \'.txt\'\n\n            print(""saving"", filename)\n            np.savetxt(str(filename), weight)\n\n    squash_layers()\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \'--train_loop_count\',\n        type=int,\n        default=20000,\n        help=\'Number of training iterations\')\n    parser.add_argument(\n        \'--batch_size\', type=int, default=50, help=\'Batch Size\')\n    FLAGS, unparsed = parser.parse_known_args()\n\n    main(FLAGS)\n'"
examples/MNIST/Cryptonets/__init__.py,0,b''
examples/MNIST/Cryptonets/model.py,12,"b'# ******************************************************************************\n# Copyright 2018-2019 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# *****************************************************************************\n\nimport tensorflow as tf\nimport numpy as np\nimport os\nimport sys\n\n# Add parent directory to path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom mnist_util import load_mnist_data, \\\n    get_variable, \\\n    conv2d_stride_2_valid, \\\n    avg_pool_3x3_same_size\n\n\ndef cryptonets_model(x, mode):\n    """"""Builds the graph for classifying digits based on Cryptonets\n\n    Args:\n        x: an input tensor with the dimensions (N_examples, 28, 28)\n\n    Returns:\n        A tuple (y, a scalar placeholder). y is a tensor of shape\n        (N_examples, 10), with values equal to the logits of classifying the\n        digit into one of 10 classes (the digits 0-9).\n    """"""\n    if mode not in set([\'train\', \'test\']):\n        print(\'mode should be train or test\')\n        raise Exception()\n\n    # Reshape to use within a conv neural net.\n    # Last dimension is for ""features"" - there is only one here, since images\n    # are grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n    # CryptoNets\'s output of the first conv layer has feature map size 13 x 13,\n    # therefore, we manually add paddings.\n    with tf.name_scope(\'reshape\'):\n        print(\'padding\')\n        paddings = [[0, 0], [0, 1], [0, 1], [0, 0]]\n        x = tf.pad(x, paddings)\n        print(\'padded\')\n\n    # First conv layer\n    # Input: N x 28 x 28 x 1\n    # Filter: 5 x 5 x 1 x 5\n    # Output: N x 13 x 13 x 5\n    with tf.name_scope(\'conv1\'):\n        W_conv1 = get_variable(""W_conv1"", [5, 5, 1, 5], mode)\n        h_conv1 = tf.square(conv2d_stride_2_valid(x, W_conv1))\n\n    # Pooling layer\n    # Input: N x 13 x 13 x 5\n    # Output: N x 13 x 13 x 5\n    with tf.name_scope(\'pool1\'):\n        h_pool1 = avg_pool_3x3_same_size(h_conv1)\n\n    # Second convolution\n    # Input: N x 13 x 13 x 5\n    # Filter: 5 x 5 x 5 x 50\n    # Output: N x 5 x 5 x 50\n    with tf.name_scope(\'conv2\'):\n        W_conv2 = get_variable(""W_conv2"", [5, 5, 5, 50], mode)\n        h_conv2 = conv2d_stride_2_valid(h_pool1, W_conv2)\n\n    # Second pooling layer\n    # Input: N x 5 x 5 x 50\n    # Output: N x 5 x 5 x 50\n    with tf.name_scope(\'pool2\'):\n        h_pool2 = avg_pool_3x3_same_size(h_conv2)\n\n    # Fully connected layer 1\n    # Input: N x 5 x 5 x 50\n    # Input flattened: N x 1250\n    # Weight: 1250 x 100\n    # Output: N x 100\n    with tf.name_scope(\'fc1\'):\n        h_pool2_flat = tf.reshape(h_pool2, [-1, 5 * 5 * 50])\n        W_fc1 = get_variable(""W_fc1"", [5 * 5 * 50, 100], mode)\n        h_fc1 = tf.square(tf.matmul(h_pool2_flat, W_fc1))\n\n    # Map the 100 features to 10 classes, one for each digit\n    # Input: N x 100\n    # Weight: 100 x 10\n    # Output: N x 10\n    with tf.name_scope(\'fc2\'):\n        W_fc2 = get_variable(""W_fc2"", [100, 10], mode)\n        y_conv = tf.matmul(h_fc1, W_fc2)\n    return y_conv\n'"
examples/MNIST/Cryptonets/test.py,9,"b'# ==============================================================================\n#  Copyright 2018-2019 Intel Corporation\n#\n#  Licensed under the Apache License, Version 2.0 (the ""License"");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an ""AS IS"" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n# ==============================================================================\n""""""An MNIST classifier based on Cryptonets using convolutional layers. """"""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\nimport time\nimport numpy as np\nimport itertools\nimport glob\nimport tensorflow as tf\nimport ngraph_bridge\nimport os\nfrom tensorflow.core.protobuf import rewriter_config_pb2\n\n# Add parent directory to path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom mnist_util import load_mnist_data, \\\n                       get_variable, \\\n                       conv2d_stride_2_valid, \\\n                       str2bool, \\\n                       server_argument_parser, \\\n                       server_config_from_flags\n\n\ndef cryptonets_test_squashed(x):\n    """"""Constructs test network for Cryptonets using saved weights.\n       Assumes linear layers have been squashed.""""""\n    paddings = [[0, 0], [0, 1], [0, 1], [0, 0]]\n    x = tf.pad(x, paddings)\n\n    W_conv1 = get_variable(\'W_conv1\', [5, 5, 1, 5], \'test\')\n    y = conv2d_stride_2_valid(x, W_conv1)\n    y = tf.square(y)\n    W_squash = get_variable(\'W_squash\', [5 * 13 * 13, 100], \'test\')\n    y = tf.reshape(y, [-1, 5 * 13 * 13])\n    y = tf.matmul(y, W_squash)\n    y = tf.square(y)\n    W_fc2 = get_variable(\'W_fc2\', [100, 10], \'test\')\n    y = tf.matmul(y, W_fc2)\n    return y\n\n\ndef test_mnist_cnn(FLAGS):\n    (x_train, y_train, x_test, y_test) = load_mnist_data()\n\n    x = tf.compat.v1.placeholder(tf.float32, [None, 28, 28, 1], name=\'input\')\n    y_ = tf.compat.v1.placeholder(tf.float32, [None, 10])\n\n    # Create the model\n    y_conv = cryptonets_test_squashed(x)\n\n    config = server_config_from_flags(FLAGS, x.name)\n\n    print(\'config\', config)\n\n    with tf.compat.v1.Session(config=config) as sess:\n        x_test = x_test[:FLAGS.batch_size]\n        y_test = y_test[:FLAGS.batch_size]\n        start_time = time.time()\n        y_conv_val = y_conv.eval(feed_dict={x: x_test, y_: y_test})\n        elasped_time = (time.time() - start_time)\n        print(""total time(s)"", np.round(elasped_time, 3))\n        print(\'y_conv_val\', np.round(y_conv_val, 2))\n\n    y_test_batch = y_test[:FLAGS.batch_size]\n    y_label_batch = np.argmax(y_test_batch, 1)\n\n    correct_prediction = np.equal(np.argmax(y_conv_val, 1), y_label_batch)\n    error_count = np.size(correct_prediction) - np.sum(correct_prediction)\n    test_accuracy = np.mean(correct_prediction)\n\n    print(\'Error count:\', error_count, \'of\', FLAGS.batch_size, \'elements.\')\n    print(\'Accuracy: \', test_accuracy)\n\n\nif __name__ == \'__main__\':\n    parser = server_argument_parser()\n    FLAGS, unparsed = parser.parse_known_args()\n\n    if unparsed:\n        print(\'Unparsed flags:\', unparsed)\n    if FLAGS.encrypt_server_data and FLAGS.enable_client:\n        raise Exception(\n            ""encrypt_server_data flag only valid when client is not enabled. Note: the client can specify whether or not to encrypt the data using \'encrypt\' or \'plain\' in the configuration map""\n        )\n\n    test_mnist_cnn(FLAGS)'"
examples/MNIST/Cryptonets/train.py,20,"b'# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""An MNIST classifier based on Cryptonets using convolutional layers. """"""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\nimport time\nimport numpy as np\nimport itertools\nimport tensorflow as tf\nimport model\nimport os\n\n# Add parent directory to path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom mnist_util import load_mnist_data, \\\n    get_variable, \\\n    conv2d_stride_2_valid, \\\n    avg_pool_3x3_same_size, \\\n    get_train_batch\n\n\ndef squash_layers():\n    print(""Squashing layers"")\n    tf.compat.v1.reset_default_graph()\n\n    # Input from h_conv1 squaring\n    x = tf.compat.v1.placeholder(tf.float32, [None, 13, 13, 5])\n\n    # Pooling layer\n    h_pool1 = avg_pool_3x3_same_size(x)  # To N x 13 x 13 x 5\n\n    # Second convolution\n    W_conv2 = np.loadtxt(\n        \'W_conv2.txt\', dtype=np.float32).reshape([5, 5, 5, 50])\n    h_conv2 = conv2d_stride_2_valid(h_pool1, W_conv2)\n\n    # Second pooling layer.\n    h_pool2 = avg_pool_3x3_same_size(h_conv2)\n\n    # Fully connected layer 1\n    # Input: N x 5 x 5 x 50\n    # Output: N x 100\n    W_fc1 = np.loadtxt(\n        \'W_fc1.txt\', dtype=np.float32).reshape([5 * 5 * 50, 100])\n    h_pool2_flat = tf.reshape(h_pool2, [-1, 5 * 5 * 50])\n    pre_square = tf.matmul(h_pool2_flat, W_fc1)\n\n    with tf.compat.v1.Session() as sess:\n        x_in = np.eye(13 * 13 * 5)\n        x_in = x_in.reshape([13 * 13 * 5, 13, 13, 5])\n        W = (sess.run([pre_square], feed_dict={x: x_in}))[0]\n        squashed_file_name = ""W_squash.txt""\n        np.savetxt(squashed_file_name, W)\n        print(""Saved to"", squashed_file_name)\n\n        # Sanity check\n        x_in = np.random.rand(100, 13, 13, 5)\n        network_out = (sess.run([pre_square], feed_dict={x: x_in}))[0]\n        linear_out = x_in.reshape(100, 13 * 13 * 5).dot(W)\n        assert (np.max(np.abs(linear_out - network_out)) < 1e-5)\n\n    print(""Squashed layers"")\n\ndef main(FLAGS):\n    (x_train, y_train, x_test, y_test) = load_mnist_data()\n\n    x = tf.compat.v1.placeholder(tf.float32, [None, 28, 28, 1])\n    y_ = tf.compat.v1.placeholder(tf.float32, [None, 10])\n    y_conv = model.cryptonets_model(x, \'train\')\n\n    with tf.name_scope(\'loss\'):\n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n            labels=y_, logits=y_conv)\n    cross_entropy = tf.reduce_mean(cross_entropy)\n\n    with tf.name_scope(\'adam_optimizer\'):\n        train_step = tf.compat.v1.train.AdamOptimizer(1e-4).minimize(\n            cross_entropy)\n\n    with tf.name_scope(\'accuracy\'):\n        correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n        correct_prediction = tf.cast(correct_prediction, tf.float32)\n    accuracy = tf.reduce_mean(correct_prediction)\n\n    with tf.compat.v1.Session() as sess:\n        sess.run(tf.compat.v1.global_variables_initializer())\n        loss_values = []\n        for i in range(FLAGS.train_loop_count):\n            x_batch, y_batch = get_train_batch(i, FLAGS.batch_size, x_train,\n                                               y_train)\n            if i % 100 == 0:\n                t = time.time()\n                train_accuracy = accuracy.eval(feed_dict={\n                    x: x_batch,\n                    y_: y_batch\n                })\n                print(\'step %d, training accuracy %g, %g msec to evaluate\' %\n                      (i, train_accuracy, 1000 * (time.time() - t)))\n            t = time.time()\n            _, loss = sess.run([train_step, cross_entropy],\n                               feed_dict={\n                                   x: x_batch,\n                                   y_: y_batch\n                               })\n            loss_values.append(loss)\n\n            if i % 1000 == 999 or i == FLAGS.train_loop_count - 1:\n                test_accuracy = accuracy.eval(feed_dict={\n                    x: x_test,\n                    y_: y_test\n                })\n                print(\'test accuracy %g\' % test_accuracy)\n\n        print(""Training finished. Saving variables."")\n        for var in tf.compat.v1.get_collection(\n                tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES):\n            weight = (sess.run([var]))[0].flatten().tolist()\n            filename = (str(var).split())[1].replace(\'/\', \'_\')\n            filename = filename.replace(""\'"", """").replace(\':0\', \'\') + \'.txt\'\n\n            print(""saving"", filename)\n            np.savetxt(str(filename), weight)\n\n    # Squash weights and save as W_squash.txt\n    squash_layers()\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \'--train_loop_count\',\n        type=int,\n        default=20000,\n        help=\'Number of training iterations\')\n    parser.add_argument(\n        \'--batch_size\', type=int, default=50, help=\'Batch Size\')\n    FLAGS, unparsed = parser.parse_known_args()\n\n    main(FLAGS)'"
examples/MNIST/MLP/__init__.py,0,b''
examples/MNIST/MLP/model.py,15,"b'# ******************************************************************************\n# Copyright 2018-2019 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# *****************************************************************************\n\nimport tensorflow as tf\nimport numpy as np\nimport os\nimport sys\n\n# Add parent directory to path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom mnist_util import load_mnist_data, \\\n    get_variable, \\\n    conv2d_stride_2_valid, \\\n    avg_pool_3x3_same_size, \\\n    max_pool_3x3_same_size\n\n\ndef mnist_mlp_model(x):\n    paddings = tf.constant([[0, 0], [0, 1], [0, 1], [0, 0]], name=\'pad_const\')\n    x = tf.pad(x, paddings)\n\n    W_conv1 = tf.compat.v1.get_variable(\'W_conv1\', [5, 5, 1, 5])\n    y = conv2d_stride_2_valid(x, W_conv1)\n    W_bc1 = tf.compat.v1.get_variable(\'W_conv1_bias\', [1, 13, 13, 5])\n    y = y + W_bc1\n    y = tf.nn.relu(y)\n\n    y = max_pool_3x3_same_size(y)\n    W_conv2 = tf.compat.v1.get_variable(\'W_conv2\', [5, 5, 5, 50])\n    y = conv2d_stride_2_valid(y, W_conv2)\n    y = max_pool_3x3_same_size(y)\n\n    y = tf.reshape(y, [-1, 5 * 5 * 50])\n    W_fc1 = tf.compat.v1.get_variable(\'W_fc1\', [5 * 5 * 50, 100])\n    W_b1 = tf.compat.v1.get_variable(\'W_fc1_bias\', [100])\n    y = tf.matmul(y, W_fc1)\n    y = y + W_b1\n    y = tf.nn.relu(y)\n\n    W_fc2 = tf.compat.v1.get_variable(\'W_fc2\', [100, 10])\n    W_b2 = tf.compat.v1.get_variable(\'W_fc2_bias\', [10])\n    y = tf.matmul(y, W_fc2)\n    y = tf.add(y, W_b2, name=\'output\')\n\n    return y'"
examples/MNIST/MLP/test.py,7,"b'# ==============================================================================\n#  Copyright 2018-2019 Intel Corporation\n#\n#  Licensed under the Apache License, Version 2.0 (the ""License"");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an ""AS IS"" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n# ==============================================================================\n""""""An MNIST classifier using convolutional layers and relu activations. """"""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\nimport time\nimport numpy as np\nimport itertools\nimport glob\nimport tensorflow as tf\nimport model\nimport ngraph_bridge\nimport os\nfrom tensorflow.python.tools import freeze_graph\nfrom tensorflow.python.tools import optimize_for_inference_lib\nfrom tensorflow.core.protobuf import rewriter_config_pb2\n\n# Add parent directory to path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom mnist_util import load_mnist_data, \\\n                       get_variable, \\\n                       conv2d_stride_2_valid, \\\n                       str2bool, \\\n                       server_argument_parser, \\\n                       server_config_from_flags\n\n\ndef load_pb_file(filename):\n    with tf.io.gfile.GFile(filename, \'rb\') as f:\n        graph_def = tf.compat.v1.GraphDef()\n        graph_def.ParseFromString(f.read())\n\n    print(\'Model restored\')\n    return graph_def\n\n\ndef test_mnist_mlp(FLAGS):\n    (x_train, y_train, x_test, y_test) = load_mnist_data()\n    x_test = x_test[:FLAGS.batch_size]\n    y_test = y_test[:FLAGS.batch_size]\n\n    graph_def = load_pb_file(\'./model/model.pb\')\n\n    with tf.Graph().as_default():\n        tf.import_graph_def(graph_def)\n        y_conv = tf.compat.v1.get_default_graph().get_tensor_by_name(\n            ""import/output:0"")\n        x_input = tf.compat.v1.get_default_graph().get_tensor_by_name(\n            ""import/input:0"")\n\n        config = server_config_from_flags(FLAGS, x_input.name)\n\n        print(\'config\', config)\n\n        with tf.compat.v1.Session(config=config) as sess:\n            start_time = time.time()\n            y_conv_val = y_conv.eval(\n                session=sess, feed_dict={\n                    x_input: x_test,\n                })\n            elasped_time = (time.time() - start_time)\n            print(""total time(s)"", np.round(elasped_time, 3))\n\n    if not FLAGS.enable_client:\n        y_test_batch = y_test[:FLAGS.batch_size]\n        y_label_batch = np.argmax(y_test_batch, 1)\n\n        y_pred = np.argmax(y_conv_val, 1)\n        print(\'y_pred\', y_pred)\n        correct_prediction = np.equal(y_pred, y_label_batch)\n        error_count = np.size(correct_prediction) - np.sum(correct_prediction)\n        test_accuracy = np.mean(correct_prediction)\n\n        print(\'Error count\', error_count, \'of\', FLAGS.batch_size, \'elements.\')\n        print(\'Accuracy: %g \' % test_accuracy)\n\n\nif __name__ == \'__main__\':\n    parser = server_argument_parser()\n    FLAGS, unparsed = parser.parse_known_args()\n\n    if unparsed:\n        print(\'Unparsed flags:\', unparsed)\n    if FLAGS.encrypt_server_data and FLAGS.enable_client:\n        raise Exception(\n            ""encrypt_data flag only valid when client is not enabled. Note: the client can specify whether or not to encrypt the data using \'encrypt\' or \'plain\' in the configuration map""\n        )\n\n    test_mnist_mlp(FLAGS)\n'"
examples/MNIST/MLP/train.py,16,"b'# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""An MNIST classifier based on Cryptonets using convolutional layers. """"""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\nimport time\nimport numpy as np\nimport itertools\nimport tensorflow as tf\nimport model\nimport os\nfrom tensorflow.python.tools import freeze_graph\n\n# Add parent directory to path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom mnist_util import load_mnist_data, \\\n    get_variable, \\\n    conv2d_stride_2_valid, \\\n    avg_pool_3x3_same_size, \\\n    get_train_batch\n\n\ndef save_model(sess, directory, filename):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    saver = tf.compat.v1.train.Saver()\n    ckpt_filepath = os.path.join(directory, filename + \'.ckpt\')\n    saver.save(sess, ckpt_filepath)\n\n    pbtxt_filename = filename + \'.pbtxt\'\n    pbtxt_filepath = os.path.join(directory, pbtxt_filename)\n    pb_filepath = os.path.join(directory, filename + \'.pb\')\n\n    tf.io.write_graph(\n        graph_or_graph_def=sess.graph_def,\n        logdir=directory,\n        name=filename + \'.pb\',\n        as_text=False)\n\n    tf.io.write_graph(\n        graph_or_graph_def=sess.graph_def,\n        logdir=directory,\n        name=pbtxt_filename,\n        as_text=True)\n\n    # Freeze graph to turn variables into constants\n    freeze_graph.freeze_graph(\n        input_graph=pbtxt_filepath,\n        input_saver=\'\',\n        input_binary=False,\n        input_checkpoint=ckpt_filepath,\n        output_node_names=\'output\',\n        restore_op_name=\'save/restore_all\',\n        filename_tensor_name=\'save/Const:0\',\n        output_graph=pb_filepath,\n        clear_devices=True,\n        initializer_nodes=\'\')\n\n    print(""Model saved to: %s"" % pb_filepath)\n\n\ndef main(FLAGS):\n    (x_train, y_train, x_test, y_test) = load_mnist_data()\n\n    x = tf.compat.v1.placeholder(tf.float32, [None, 28, 28, 1], name=\'input\')\n    y_ = tf.compat.v1.placeholder(tf.float32, [None, 10])\n    y_conv = model.mnist_mlp_model(x)\n\n    with tf.name_scope(\'loss\'):\n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n            labels=y_, logits=y_conv)\n    cross_entropy = tf.reduce_mean(cross_entropy)\n\n    with tf.name_scope(\'adam_optimizer\'):\n        train_step = tf.compat.v1.train.AdamOptimizer(1e-4).minimize(\n            cross_entropy)\n\n    with tf.name_scope(\'accuracy\'):\n        correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n        correct_prediction = tf.cast(correct_prediction, tf.float32)\n    accuracy = tf.reduce_mean(correct_prediction)\n\n    with tf.compat.v1.Session() as sess:\n        sess.run(tf.compat.v1.global_variables_initializer())\n        for i in range(FLAGS.train_loop_count):\n            x_batch, y_batch = get_train_batch(i, FLAGS.batch_size, x_train,\n                                               y_train)\n            if i % 100 == 0:\n                t = time.time()\n                train_accuracy = accuracy.eval(feed_dict={\n                    x: x_batch,\n                    y_: y_batch\n                })\n                print(\'step %d, training accuracy %g, %g msec to evaluate\' %\n                      (i, train_accuracy, 1000 * (time.time() - t)))\n            t = time.time()\n            _, loss = sess.run([train_step, cross_entropy],\n                               feed_dict={\n                                   x: x_batch,\n                                   y_: y_batch\n                               })\n            if i % 1000 == 999 or i == FLAGS.train_loop_count - 1:\n                test_accuracy = accuracy.eval(feed_dict={\n                    x: x_test,\n                    y_: y_test\n                })\n                print(\'test accuracy %g\' % test_accuracy)\n\n        print(""Training finished. Saving model."")\n\n        save_model(sess, \'./model\', \'model\')\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \'--train_loop_count\',\n        type=int,\n        default=20000,\n        help=\'Number of training iterations\')\n    parser.add_argument(\n        \'--batch_size\', type=int, default=50, help=\'Batch Size\')\n    FLAGS, unparsed = parser.parse_known_args()\n\n    main(FLAGS)\n'"
