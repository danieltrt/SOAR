file_path,api_count,code
captcha_eval.py,10,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom datetime import datetime\nimport argparse\nimport sys\nimport math\n\nimport tensorflow as tf\nimport captcha_model as captcha\n\nFLAGS = None\n\ndef run_eval():\n  with tf.Graph().as_default(), tf.device('/cpu:0'):\n    images, labels = captcha.inputs(train=False, batch_size=FLAGS.batch_size)\n    logits = captcha.inference(images, keep_prob=1)\n    eval_correct = captcha.evaluation(logits, labels)  \n    sess = tf.Session()    \n    saver = tf.train.Saver()    \n    saver.restore(sess, tf.train.latest_checkpoint(FLAGS.checkpoint_dir))\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n    try:\n      num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))\n      true_count = 0\n      total_true_count = 0\n      total_sample_count = num_iter * FLAGS.batch_size\n      step = 0\n      print('>> loop: %d, total_sample_count: %d' % (num_iter, total_sample_count))\n      while step < num_iter and not coord.should_stop():\n        true_count = sess.run(eval_correct)\n        total_true_count += true_count\n        precision = true_count / FLAGS.batch_size\n        print('>> %s Step %d: true/total: %d/%d precision @ 1 = %.3f'\n                    %(datetime.now(), step, true_count, FLAGS.batch_size, precision))\n        step += 1\n      precision = total_true_count / total_sample_count\n      print('>> %s true/total: %d/%d precision @ 1 = %.3f'\n                    %(datetime.now(), total_true_count, total_sample_count, precision))       \n    except Exception as e:\n      coord.request_stop(e)\n    finally:\n      coord.request_stop()\n    coord.join(threads)\n    sess.close()\n\n\ndef main(_):\n  if tf.gfile.Exists(FLAGS.eval_dir):\n    tf.gfile.DeleteRecursively(FLAGS.eval_dir)\n  tf.gfile.MakeDirs(FLAGS.eval_dir)\n  run_eval()\n\n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      '--num_examples',\n      type=int,\n      default=20000,\n      help='Number of examples to run validation.'\n  )\n  parser.add_argument(\n      '--batch_size',\n      type=int,\n      default=100,\n      help='Batch size.'\n  )\n  parser.add_argument(\n      '--checkpoint_dir',\n      type=str,\n      default='./captcha_train',\n      help='Directory where to restore checkpoint.'\n  )\n  parser.add_argument(\n      '--eval_dir',\n      type=str,\n      default='./captcha_eval',\n      help='Directory where to write event logs.'\n  )\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n"""
captcha_gen_default.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport random\nimport os\nfrom captcha.image import ImageCaptcha\n\nimport config\n\nIMAGE_HEIGHT = config.IMAGE_HEIGHT\nIMAGE_WIDTH = config.IMAGE_WIDTH\nCHARS_NUM = config.CHARS_NUM\n\nTEST_SIZE = 1000\nTRAIN_SIZE = 50000\nVALID_SIZE = 20000\n\nFLAGS = None\n\ndef gen(gen_dir, total_size, chars_num):\n  if not os.path.exists(gen_dir):\n    os.makedirs(gen_dir)\n  image = ImageCaptcha(width=IMAGE_WIDTH, height=IMAGE_HEIGHT,font_sizes=[40])\n  # must be subset of config.CHAR_SETS\n  char_sets = 'ABCDEFGHIJKLMNPQRSTUVWXYZ'\n  for i in xrange(total_size):\n    label = ''.join(random.sample(char_sets, chars_num))\n    image.write(label, os.path.join(gen_dir, label+'_num'+str(i)+'.png'))\n\n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      '--test_dir',\n      type=str,\n      default='./data/test_data',\n      help='Directory testing to generate captcha data files'\n  )\n  parser.add_argument(\n      '--train_dir',\n      type=str,\n      default='./data/train_data',\n      help='Directory training to generate captcha data files'\n  )\n  parser.add_argument(\n      '--valid_dir',\n      type=str,\n      default='./data/valid_data',\n      help='Directory validation to generate captcha data files'\n  )\n  FLAGS, unparsed = parser.parse_known_args()\n  print('>> generate %d captchas in %s' % (TEST_SIZE, FLAGS.test_dir))\n  gen(FLAGS.test_dir, TEST_SIZE, CHARS_NUM)\n  print ('>> generate %d captchas in %s' % (TRAIN_SIZE, FLAGS.train_dir))\n  gen(FLAGS.train_dir, TRAIN_SIZE, CHARS_NUM)\n  print ('>> generate %d captchas in %s' % (VALID_SIZE, FLAGS.valid_dir))\n  gen(FLAGS.valid_dir, VALID_SIZE, CHARS_NUM)\n  print ('>> generate Done!')\n"""
captcha_input.py,14,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os.path\nimport tensorflow as tf\n\nimport config\n\nRECORD_DIR = config.RECORD_DIR\nTRAIN_FILE = config.TRAIN_FILE\nVALID_FILE = config.VALID_FILE\n\nIMAGE_WIDTH = config.IMAGE_WIDTH\nIMAGE_HEIGHT = config.IMAGE_HEIGHT\nCLASSES_NUM = config.CLASSES_NUM\nCHARS_NUM = config.CHARS_NUM\n\ndef read_and_decode(filename_queue):\n  reader = tf.TFRecordReader()\n  _, serialized_example = reader.read(filename_queue)\n  features = tf.parse_single_example(\n      serialized_example,\n      features={\n          'image_raw': tf.FixedLenFeature([], tf.string),\n          'label_raw': tf.FixedLenFeature([], tf.string),\n      })\n  image = tf.decode_raw(features['image_raw'], tf.int16)\n  image.set_shape([IMAGE_HEIGHT * IMAGE_WIDTH])\n  image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n  reshape_image = tf.reshape(image, [IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n  label = tf.decode_raw(features['label_raw'], tf.uint8)\n  label.set_shape([CHARS_NUM * CLASSES_NUM])\n  reshape_label = tf.reshape(label, [CHARS_NUM, CLASSES_NUM])\n  return tf.cast(reshape_image, tf.float32), tf.cast(reshape_label, tf.float32)\n\n\ndef inputs(train, batch_size):\n  filename = os.path.join(RECORD_DIR,\n                          TRAIN_FILE if train else VALID_FILE)\n\n  with tf.name_scope('input'):\n    filename_queue = tf.train.string_input_producer([filename])\n    image, label = read_and_decode(filename_queue)\n    if train:\n        images, sparse_labels = tf.train.shuffle_batch([image, label],\n                                                       batch_size=batch_size,\n                                                       num_threads=6,\n                                                       capacity=2000 + 3 * batch_size,\n                                                       min_after_dequeue=2000)\n    else:\n        images, sparse_labels = tf.train.batch([image, label],\n                                               batch_size=batch_size,\n                                               num_threads=6,\n                                               capacity=2000 + 3 * batch_size)\n\n    return images, sparse_labels\n"""
captcha_model.py,37,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport captcha_input\nimport config\n\nIMAGE_WIDTH = config.IMAGE_WIDTH\nIMAGE_HEIGHT = config.IMAGE_HEIGHT\nCLASSES_NUM = config.CLASSES_NUM\nCHARS_NUM = config.CHARS_NUM\n\ndef inputs(train, batch_size):\n    return captcha_input.inputs(train, batch_size=batch_size)\n\n\ndef _conv2d(value, weight):\n  """"""conv2d returns a 2d convolution layer with full stride.""""""\n  return tf.nn.conv2d(value, weight, strides=[1, 1, 1, 1], padding=\'SAME\')\n\n\ndef _max_pool_2x2(value, name):\n  """"""max_pool_2x2 downsamples a feature map by 2X.""""""\n  return tf.nn.max_pool(value, ksize=[1, 2, 2, 1],\n                        strides=[1, 2, 2, 1], padding=\'SAME\', name=name)\n\n\ndef _weight_variable(name, shape):\n  """"""weight_variable generates a weight variable of a given shape.""""""\n  with tf.device(\'/cpu:0\'):\n    initializer = tf.truncated_normal_initializer(stddev=0.1)\n    var = tf.get_variable(name,shape,initializer=initializer, dtype=tf.float32)\n  return var\n\n\ndef _bias_variable(name, shape):\n  """"""bias_variable generates a bias variable of a given shape.""""""\n  with tf.device(\'/cpu:0\'):\n    initializer = tf.constant_initializer(0.1)\n    var = tf.get_variable(name, shape, initializer=initializer,dtype=tf.float32)\n  return var\n  \ndef inference(images, keep_prob):\n  images = tf.reshape(images, [-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n  \n  with tf.variable_scope(\'conv1\') as scope:\n    kernel = _weight_variable(\'weights\', shape=[3,3,1,64])\n    biases = _bias_variable(\'biases\',[64])\n    pre_activation = tf.nn.bias_add(_conv2d(images, kernel),biases)\n    conv1 = tf.nn.relu(pre_activation, name=scope.name)\n    \n  pool1 = _max_pool_2x2(conv1, name=\'pool1\')\n  \n  with tf.variable_scope(\'conv2\') as scope:\n    kernel = _weight_variable(\'weights\', shape=[3,3,64,64])\n    biases = _bias_variable(\'biases\',[64])\n    pre_activation = tf.nn.bias_add(_conv2d(pool1, kernel),biases)\n    conv2 = tf.nn.relu(pre_activation, name=scope.name)\n    \n  pool2 = _max_pool_2x2(conv2, name=\'pool2\')\n  \n  with tf.variable_scope(\'conv3\') as scope:\n    kernel = _weight_variable(\'weights\', shape=[3,3,64,64])\n    biases = _bias_variable(\'biases\',[64])\n    pre_activation = tf.nn.bias_add(_conv2d(pool2, kernel),biases)\n    conv3 = tf.nn.relu(pre_activation, name=scope.name)\n    \n  pool3 = _max_pool_2x2(conv3, name=\'pool3\')\n  \n  with tf.variable_scope(\'conv4\') as scope:\n    kernel = _weight_variable(\'weights\', shape=[3,3,64,64])\n    biases = _bias_variable(\'biases\',[64])\n    pre_activation = tf.nn.bias_add(_conv2d(pool3, kernel),biases)\n    conv4 = tf.nn.relu(pre_activation, name=scope.name)\n    \n  pool4 = _max_pool_2x2(conv4, name=\'pool4\')\n  \n  with tf.variable_scope(\'local1\') as scope:\n    batch_size = images.get_shape()[0].value\n    reshape = tf.reshape(pool4, [batch_size,-1])\n    dim = reshape.get_shape()[1].value\n    weights = _weight_variable(\'weights\', shape=[dim,1024])\n    biases = _bias_variable(\'biases\',[1024])\n    local1 = tf.nn.relu(tf.matmul(reshape,weights) + biases, name=scope.name)\n\n  local1_drop = tf.nn.dropout(local1, keep_prob)\n\n  with tf.variable_scope(\'softmax_linear\') as scope:\n    weights = _weight_variable(\'weights\',shape=[1024,CHARS_NUM*CLASSES_NUM])\n    biases = _bias_variable(\'biases\',[CHARS_NUM*CLASSES_NUM])\n    softmax_linear = tf.add(tf.matmul(local1_drop,weights), biases, name=scope.name)\n\n  return tf.reshape(softmax_linear, [-1, CHARS_NUM, CLASSES_NUM])\n\n\ndef loss(logits, labels):\n  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n                  labels=labels, logits=logits, name=\'corss_entropy_per_example\')\n  cross_entropy_mean = tf.reduce_mean(cross_entropy, name=\'cross_entropy\')\n  tf.add_to_collection(\'losses\', cross_entropy_mean)\n  return tf.add_n(tf.get_collection(\'losses\'), name=\'total_loss\')\n\n\ndef training(loss):\n  optimizer = tf.train.AdamOptimizer(1e-4)\n  train_op = optimizer.minimize(loss)\n  return train_op\n\n\ndef evaluation(logits, labels):\n  correct_prediction = tf.equal(tf.argmax(logits,2), tf.argmax(labels,2))\n  correct_batch = tf.reduce_mean(tf.cast(correct_prediction, tf.int32), 1)\n  return tf.reduce_sum(tf.cast(correct_batch, tf.float32))\n\n\ndef output(logits):\n  return tf.argmax(logits, 2)\n\n'"
captcha_multi_gpu_train.py,19,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport time\nfrom datetime import datetime\nimport argparse\nimport sys\n\nimport numpy as np\nfrom six.moves import xrange \nimport tensorflow as tf\nimport captcha_model as captcha\n\nFLAGS = None\n\ndef tower_loss(scope, keep_prob):\n  images, labels = captcha.inputs(train=True, batch_size=FLAGS.batch_size)\n  logits = captcha.inference(images, keep_prob)\n  _ = captcha.loss(logits, labels)\n  losses = tf.get_collection('losses', scope)\n  total_loss = tf.add_n(losses, name='total_loss')\n  return total_loss\n\n\ndef average_gradients(tower_grads):\n  average_grads = []\n  for grad_and_vars in zip(*tower_grads):\n    grads = []\n    for g, _ in grad_and_vars:\n      expanded_g = tf.expand_dims(g, 0)\n      grads.append(expanded_g)\n    grad = tf.concat(axis=0, values=grads)\n    grad = tf.reduce_mean(grad, 0)\n    v = grad_and_vars[0][1]\n    grad_and_var = (grad, v)\n    average_grads.append(grad_and_var)\n  return average_grads\n\n\ndef run_train():\n  with tf.Graph().as_default(), tf.device('/cpu:0'):\n    opt = tf.train.AdamOptimizer(1e-4)\n    tower_grads = []\n    with tf.variable_scope(tf.get_variable_scope()):\n      for i in xrange(FLAGS.num_gpus):\n        with tf.device('/gpu:%d' % i):\n          with tf.name_scope('tower_%d' % (i)) as scope:\n            loss = tower_loss(scope, keep_prob=0.5)\n            tf.get_variable_scope().reuse_variables()\n            grads = opt.compute_gradients(loss)\n            tower_grads.append(grads)\n\n    grads = average_gradients(tower_grads)\n    train_op = opt.apply_gradients(grads)\n    saver = tf.train.Saver(tf.global_variables())\n    init = tf.global_variables_initializer()\n    sess = tf.Session(config=tf.ConfigProto(\n        allow_soft_placement=True,\n        log_device_placement=True))\n    \n    sess.run(init)\n    tf.train.start_queue_runners(sess=sess)\n    for step in xrange(FLAGS.max_steps):\n      start_time = time.time()\n      _, loss_value = sess.run([train_op, loss])\n      duration = time.time() - start_time\n\n      assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n\n      if step % 10 == 0:\n        num_examples_per_step = FLAGS.batch_size * FLAGS.num_gpus\n        examples_per_sec = num_examples_per_step / duration\n        sec_per_batch = duration / FLAGS.num_gpus\n\n        format_str = ('>> %s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n                      'sec/batch)')\n        print (format_str % (datetime.now(), step, loss_value,\n                             examples_per_sec, sec_per_batch))\n\n      if step % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n        print('>> %s Saving in %s' % (datetime.now(), FLAGS.checkpoint))\n        saver.save(sess, FLAGS.checkpoint, global_step=step)\n   \n        \ndef main(_):\n  if tf.gfile.Exists(FLAGS.train_dir):\n    tf.gfile.DeleteRecursively(FLAGS.train_dir)\n  tf.gfile.MakeDirs(FLAGS.train_dir)\n  run_train()\n\n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      '--batch_size',\n      type=int,\n      default=128,\n      help='Batch size.'\n  )\n  parser.add_argument(\n      '--max_steps',\n      type=int,\n      default=1000000,\n      help='Number of batches to run.'\n  )\n  parser.add_argument(\n      '--num_gpus',\n      type=int,\n      default=8,\n      help='How many GPUs to use.'\n  )\n  parser.add_argument(\n      '--train_dir',\n      type=str,\n      default='./captcha_train',\n      help='Directory where to write event logs.'\n  )\n  parser.add_argument(\n      '--checkpoint',\n      type=str,\n      default='./captcha_train/captcha',\n      help='Directory where to write checkpoint.'\n  )\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n"""
captcha_recognize.py,7,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\nimport os.path\nfrom datetime import datetime\nfrom PIL import Image\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.python.platform import gfile\nimport captcha_model as captcha\n\nimport config\n\nIMAGE_WIDTH = config.IMAGE_WIDTH\nIMAGE_HEIGHT = config.IMAGE_HEIGHT\n\nCHAR_SETS = config.CHAR_SETS\nCLASSES_NUM = config.CLASSES_NUM\nCHARS_NUM = config.CHARS_NUM\n\nFLAGS = None\n\ndef one_hot_to_texts(recog_result):\n  texts = []\n  for i in xrange(recog_result.shape[0]):\n    index = recog_result[i]\n    texts.append(\'\'.join([CHAR_SETS[i] for i in index]))\n  return texts\n\n\ndef input_data(image_dir):\n  if not gfile.Exists(image_dir):\n    print("">> Image director \'"" + image_dir + ""\' not found."")\n    return None\n  extensions = [\'jpg\', \'JPG\', \'jpeg\', \'JPEG\', \'png\', \'PNG\']\n  print("">> Looking for images in \'"" + image_dir + ""\'"")\n  file_list = []\n  for extension in extensions:\n    file_glob = os.path.join(image_dir, \'*.\' + extension)\n    file_list.extend(gfile.Glob(file_glob))\n  if not file_list:\n    print("">> No files found in \'"" + image_dir + ""\'"")\n    return None\n  batch_size = len(file_list)\n  images = np.zeros([batch_size, IMAGE_HEIGHT*IMAGE_WIDTH], dtype=\'float32\')\n  files = []\n  i = 0\n  for file_name in file_list:\n    image = Image.open(file_name)\n    image_gray = image.convert(\'L\')\n    image_resize = image_gray.resize(size=(IMAGE_WIDTH,IMAGE_HEIGHT))\n    image.close()\n    input_img = np.array(image_resize, dtype=\'float32\')\n    input_img = np.multiply(input_img.flatten(), 1./255) - 0.5    \n    images[i,:] = input_img\n    base_name = os.path.basename(file_name)\n    files.append(base_name)\n    i += 1\n  return images, files\n\n\ndef run_predict():\n  with tf.Graph().as_default(), tf.device(\'/cpu:0\'):\n    input_images, input_filenames = input_data(FLAGS.captcha_dir)\n    images = tf.constant(input_images)\n    logits = captcha.inference(images, keep_prob=1)\n    result = captcha.output(logits)\n    saver = tf.train.Saver()\n    sess = tf.Session()\n    saver.restore(sess, tf.train.latest_checkpoint(FLAGS.checkpoint_dir))\n    print(tf.train.latest_checkpoint(FLAGS.checkpoint_dir))\n    recog_result = sess.run(result)\n    sess.close()\n    text = one_hot_to_texts(recog_result)\n    total_count = len(input_filenames)\n    true_count = 0.\n    for i in range(total_count):\n      print(\'image \' + input_filenames[i] + "" recognize ----> \'"" + text[i] + ""\'"")\n      if text[i] in input_filenames[i]:\n        true_count += 1\n    precision = true_count / total_count\n    print(\'%s true/total: %d/%d recognize @ 1 = %.3f\'\n                    %(datetime.now(), true_count, total_count, precision))\n\n\ndef main(_):\n  run_predict()\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      \'--checkpoint_dir\',\n      type=str,\n      default=\'./captcha_train\',\n      help=\'Directory where to restore checkpoint.\'\n  )\n  parser.add_argument(\n      \'--captcha_dir\',\n      type=str,\n      default=\'./data/test_data\',\n      help=\'Directory where to get captcha images.\'\n  )\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n'"
captcha_records.py,5,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport os.path\nimport sys\n\nfrom PIL import Image\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.platform import gfile\nimport config\n\nIMAGE_HEIGHT = config.IMAGE_HEIGHT\nIMAGE_WIDTH = config.IMAGE_WIDTH\nCHAR_SETS = config.CHAR_SETS\nCLASSES_NUM = config.CLASSES_NUM\nCHARS_NUM = config.CHARS_NUM\n\nRECORD_DIR = config.RECORD_DIR\nTRAIN_FILE = config.TRAIN_FILE\nVALID_FILE = config.VALID_FILE\n\nFLAGS = None\n\ndef _int64_feature(value):\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef _bytes_feature(value):\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n  \ndef label_to_one_hot(label):\n  one_hot_label = np.zeros([CHARS_NUM, CLASSES_NUM])\n  offset = []\n  index = []\n  for i, c in enumerate(label):\n    offset.append(i)\n    index.append(CHAR_SETS.index(c))\n  one_hot_index = [offset, index]\n  one_hot_label[one_hot_index] = 1.0\n  return one_hot_label.astype(np.uint8)\n\n\ndef conver_to_tfrecords(data_set, name):\n  """"""Converts a dataset to tfrecords.""""""\n  if not os.path.exists(RECORD_DIR):\n      os.makedirs(RECORD_DIR)\n  filename = os.path.join(RECORD_DIR, name)\n  print(\'>> Writing\', filename)\n  writer = tf.python_io.TFRecordWriter(filename)\n  num_examples = len(data_set)\n  for index in range(num_examples):\n    image = data_set[index][0]\n    height = image.shape[0]\n    width = image.shape[1]\n    image_raw = image.tostring()\n    label = data_set[index][1]\n    label_raw = label_to_one_hot(label).tostring()\n    example = tf.train.Example(features=tf.train.Features(feature={\n        \'height\': _int64_feature(height),\n        \'width\': _int64_feature(width),\n        \'label_raw\': _bytes_feature(label_raw),\n        \'image_raw\': _bytes_feature(image_raw)}))\n    writer.write(example.SerializeToString())\n  writer.close()\n  print(\'>> Writing Done!\')\n  \n\ndef create_data_list(image_dir):\n  if not gfile.Exists(image_dir):\n    print(""Image director \'"" + image_dir + ""\' not found."")\n    return None\n  extensions = [\'jpg\', \'JPG\', \'jpeg\', \'JPEG\', \'png\', \'PNG\']\n  print(""Looking for images in \'"" + image_dir + ""\'"")\n  file_list = []\n  for extension in extensions:\n    file_glob = os.path.join(image_dir, \'*.\' + extension)\n    file_list.extend(gfile.Glob(file_glob))\n  if not file_list:\n    print(""No files found in \'"" + image_dir + ""\'"")\n    return None\n  images = []\n  labels = []\n  for file_name in file_list:\n    image = Image.open(file_name)\n    image_gray = image.convert(\'L\')\n    image_resize = image_gray.resize(size=(IMAGE_WIDTH,IMAGE_HEIGHT))\n    input_img = np.array(image_resize, dtype=\'int16\')\n    image.close()\n    label_name = os.path.basename(file_name).split(\'_\')[0]\n    images.append(input_img)\n    labels.append(label_name)\n  return zip(images, labels)\n\n\ndef main(_):\n  training_data = create_data_list(FLAGS.train_dir)\n  conver_to_tfrecords(training_data, TRAIN_FILE)\n    \n  validation_data = create_data_list(FLAGS.valid_dir)\n  conver_to_tfrecords(validation_data, VALID_FILE)\n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      \'--train_dir\',\n      type=str,\n      default=\'./data/train_data\',\n      help=\'Directory training to get captcha data files and write the converted result.\'\n  )\n  parser.add_argument(\n      \'--valid_dir\',\n      type=str,\n      default=\'./data/valid_data\',\n      help=\'Directory validation to get captcha data files and write the converted result.\'\n  )\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n'"
captcha_train.py,11,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport time\nfrom datetime import datetime\nimport argparse\nimport sys\n\nimport tensorflow as tf\nimport captcha_model as captcha\n\nFLAGS = None\n\ndef run_train():\n  """"""Train CAPTCHA for a number of steps.""""""\n\n  with tf.Graph().as_default():\n    images, labels = captcha.inputs(train=True, batch_size=FLAGS.batch_size)\n\n    logits = captcha.inference(images, keep_prob=0.5)\n\n    loss = captcha.loss(logits, labels)\n\n    train_op = captcha.training(loss)\n\n    saver = tf.train.Saver(tf.global_variables())\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    sess = tf.Session()\n\n    sess.run(init_op)\n\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n    try:\n      step = 0\n      while not coord.should_stop():\n        start_time = time.time()\n        _, loss_value = sess.run([train_op, loss])\n        duration = time.time() - start_time\n        if step % 10 == 0:\n          print(\'>> Step %d run_train: loss = %.2f (%.3f sec)\' % (step, loss_value,\n                                                     duration))\n        if step % 100 == 0:\n          print(\'>> %s Saving in %s\' % (datetime.now(), FLAGS.checkpoint))\n          saver.save(sess, FLAGS.checkpoint, global_step=step)\n        step += 1\n    except Exception as e:\n      print(\'>> %s Saving in %s\' % (datetime.now(), FLAGS.checkpoint))\n      saver.save(sess, FLAGS.checkpoint, global_step=step)\n      coord.request_stop(e)\n    finally:\n      coord.request_stop()\n    coord.join(threads)\n    sess.close()\n\n\ndef main(_):\n  if tf.gfile.Exists(FLAGS.train_dir):\n    tf.gfile.DeleteRecursively(FLAGS.train_dir)\n  tf.gfile.MakeDirs(FLAGS.train_dir)\n  run_train()\n\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      \'--batch_size\',\n      type=int,\n      default=128,\n      help=\'Batch size.\'\n  )\n  parser.add_argument(\n      \'--train_dir\',\n      type=str,\n      default=\'./captcha_train\',\n      help=\'Directory where to write event logs.\'\n  )\n  parser.add_argument(\n      \'--checkpoint\',\n      type=str,\n      default=\'./captcha_train/captcha\',\n      help=\'Directory where to write checkpoint.\'\n  )\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n'"
config.py,0,"b""# about captcha image\nIMAGE_HEIGHT = 48\nIMAGE_WIDTH = 128\nCHAR_SETS = 'abcdefghijklmnpqrstuvwxyz123456789ABCDEFGHIJKLMNPQRSTUVWXYZ'\nCLASSES_NUM = len(CHAR_SETS)\nCHARS_NUM = 5\n# for train\nRECORD_DIR = './data'\nTRAIN_FILE = 'train.tfrecords'\nVALID_FILE = 'valid.tfrecords'"""
