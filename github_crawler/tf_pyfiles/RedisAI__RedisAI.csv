file_path,api_count,code
docs/generate_llapi_reference.py,0,"b'#!/usr/bin/python\n# generates the llapi docs based on the doxygen comments on the header files\n# Python 3.X\n# Version 0.1\n\nimport argparse\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef whereis(program):\n    for path in os.environ.get(\'PATH\', \'\').split(\':\'):\n        if os.path.exists(os.path.join(path, program)) and \\\n                not os.path.isdir(os.path.join(path, program)):\n            return os.path.join(path, program)\n    return None\n\n\n# Check if system has the required utilities, cset numactl etc\ndef required_utilities(utility_list):\n    required_utilities = 1\n    for index in utility_list:\n        if whereis(index) == None:\n            print(\'Cannot locate \' + index + \' in path!\')\n            required_utilities = 0\n    return required_utilities\n\n\ndef extract_public_functions_documentation(data, md_function_def_map):\n    first_split = data.split(""## Public Functions Documentation"")\n    if len(first_split) == 2:\n        public_functions_definition = first_split[1]\n        functions_split = public_functions_definition.split(""### function"")\n        for function_md_block in functions_split:\n            function_md_block_lines = function_md_block.splitlines()\n            func = function_md_block_lines[0].strip()\n            md_function_def_map[func] = function_md_block_lines[1:]\n\n\ndef prune_and_merge_markdown(llapi_functions, md_function_def_map):\n    final_markdown = []\n    for llapi_function in llapi_functions:\n        internal_naming = ""RAI\\\\_{}"".format(llapi_function)\n        llapi_function_name = ""RedisAI\\\\_{}"".format(llapi_function)\n        if internal_naming in md_function_def_map:\n            final_markdown.append(""### {}"".format(llapi_function_name))\n            for line in md_function_def_map[internal_naming]:\n                # clear links\n                p = re.compile(r\'\\[(\\*\\*\\S+\\*\\*)\\]\\(\\S+\\)\')\n                newline = p.sub(r\'\\1\', line)\n                \n                # move from cpp to c code snippets\n                if newline.startswith(""```cpp""):\n                    newline = newline.replace(""```cpp"", ""```c"")\n\n                    # change from RAI_* to RedisAI_* in the code snipets and comments\n                p = re.compile(r\'RAI\\_(\\w+)\')\n                newline = p.sub(r\'RedisAI_\\1\', newline)\n                final_markdown.append(newline)\n\n    return final_markdown\n\n\ndef extra_llapi_functions(register_src_file):\n    llapi_functions = []\n    with open(register_src_file, ""r"") as mainredis:\n        for line in mainredis.readlines():\n            fname_regex = re.search(\n                \'.*REGISTER_API\\((\\w+),.*\\)\', line)\n            if fname_regex is not None:\n                llname_sufix = fname_regex.group(1)\n                llapi_functions.append(llname_sufix)\n\n    llapi_functions.sort()\n    return llapi_functions\n\n\ndef generate_md_function_def_map(llapi_mkdown_dir):\n    md_function_def_map = {}\n    for f in files:\n        if ""8h.md"" in f:\n            with open(""{}/{}"".format(llapi_mkdown_dir, f), \'r\') as file_content:\n                data = file_content.read()\n                extract_public_functions_documentation(data, md_function_def_map)\n\n    return md_function_def_map\n\ndef run_doxigen():\n    cp = subprocess.Popen([\'doxygen\'], shell=True, stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n    cp.communicate()\n    rc = cp.returncode\n    return True if rc == 0 else False\n\ndef clean_doxigen():\n    cp = subprocess.Popen([\'rm -rf xml\'], shell=True, stdout=subprocess.PIPE)\n    cp.communicate()\n    rc = cp.returncode\n    return  True if rc == 0 else False\n\n\ndef run_doxybook(input,output):\n    cp = subprocess.Popen([\'doxybook -t mkdocs -i {} -o {}\'.format(input,output)], shell=True, stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n    cp.communicate()\n    rc = cp.returncode\n    return  True if rc == 0 else False\n\ndef clean_doxybook(doxybook_folder):\n    cp = subprocess.Popen([\'rm -rf {}\'.format(doxybook_folder)], shell=True, stdout=subprocess.PIPE)\n    cp.communicate()\n    rc = cp.returncode\n    return  True if rc == 0 else False\n\n# Main Function\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(\n        description=\'generates the llapi docs based on the doxygen comments on the header files.\')\n    parser.add_argument(\'--register-src-file\', type=str, default=""./../src/redisai.c"",\n                        help=\'file including the call to REGISTER_API macro\')\n    parser.add_argument(\'--out\', type=str, default=""api_reference.md"", help=\'file to save the final markdown\')\n    args = parser.parse_args()\n\n    if required_utilities([\'doxygen\', \'doxybook\']) == 0:\n        print(\'Utilities Missing! Exiting..\')\n        sys.exit(1)\n\n    doxybook_temp_dir = ""doxybook_temp""\n\n    print(\'Running doxygen step...\')\n    result = run_doxigen()\n    if result == 0:\n        print(\'Something went wrong on doxygen step! Exiting..\')\n        sys.exit(1)\n\n    print(\'Running doxybook step...\')\n    result = run_doxybook(""xml"",doxybook_temp_dir)\n    if result == 0:\n        print(\'Something went wrong on doxybook step! Exiting..\')\n        sys.exit(1)\n\n    print(\'Searching on {} for REGISTER_API macro...\'.format(args.register_src_file))\n    llapi_functions = extra_llapi_functions(args.register_src_file)\n\n    files = os.listdir(doxybook_temp_dir)\n    files.sort()\n    md_function_def_map = generate_md_function_def_map(doxybook_temp_dir)\n    print(\'Associating {} registered llapi functions with their code comments...\'.format(len(llapi_functions)))   \n    final_markdown = prune_and_merge_markdown(llapi_functions, md_function_def_map)\n\n    print(\'Saving markdown to {}...\'.format(args.out))\n    with open(args.out, ""w"") as output_md:\n        output_md.write(""# RedisAI low-level API\\n\\n""\n                        ""The RedisAI low-level API makes RedisAI available as a library that can be used by other Redis modules written in C or Rust.\\n""\n                        ""Other modules will be able to use this API by calling the function RedisModule_GetSharedAPI() and casting the return value to the right function pointer.\\n\\n""\n                        )\n\n        output_md.write(""## Public Functions Documentation\\n\\n"")\n        for line in final_markdown:\n            output_md.write(line + ""\\n"")\n\n    clean_doxigen()\n    clean_doxybook(doxybook_temp_dir)\n'"
opt/system-setup.py,0,"b'#!/usr/bin/env python3\n\nimport sys\nimport os\nimport argparse\n\nHERE = os.path.abspath(os.path.dirname(__file__))\nROOT = os.path.abspath(os.path.join(HERE, ""..""))\nsys.path.insert(0, os.path.join(HERE, ""readies""))\nimport paella\n\n#----------------------------------------------------------------------------------------------\n\nclass RedisAISetup(paella.Setup):\n    def __init__(self, nop=False):\n        paella.Setup.__init__(self, nop)\n\n    def common_first(self):\n        self.install_downloaders()\n        self.setup_pip()\n        self.pip3_install(""wheel virtualenv"")\n        self.pip3_install(""setuptools --upgrade"")\n\n        if self.os == \'linux\':\n            self.install(""ca-certificates"")\n        self.install(""git unzip wget patchelf awscli"")\n        self.install(""coreutils"") # for realpath\n\n    def debian_compat(self):\n        self.install(""build-essential cmake"")\n        self.install(""python3-regex"")\n        self.install(""python3-venv python3-psutil python3-networkx python3-numpy"") # python3-skimage\n        self.install_git_lfs_on_linux()\n\n    def redhat_compat(self):\n        self.install(""redhat-lsb-core"")\n        self.run(""%s/readies/bin/enable-utf8"" % HERE)\n        \n        self.group_install(""\'Development Tools\'"")\n        self.install(""cmake3"")\n        self.run(""ln -s `command -v cmake3` /usr/local/bin/cmake"")\n        \n        self.install(""centos-release-scl"")\n        self.install(""devtoolset-8"")\n        self.run(""cp /opt/rh/devtoolset-8/enable /etc/profile.d/scl-devtoolset-8.sh"")\n        paella.mkdir_p(""%s/profile.d"" % ROOT)\n        self.run(""cp /opt/rh/devtoolset-8/enable %s/profile.d/scl-devtoolset-8.sh"" % ROOT)\n\n        if not self.dist == ""amzn"":\n            self.install(""epel-release"")\n            self.install(""python3-devel libaec-devel"")\n            self.install(""python36-psutil"")\n        else:\n            self.run(""amazon-linux-extras install epel"", output_on_error=True)\n            self.install(""python3-devel"")\n            self.pip3_install(""psutil"")\n\n        self.install_git_lfs_on_linux()\n\n    def fedora(self):\n        self.group_install(""\'Development Tools\'"")\n        self.install(""cmake"")\n        self.run(""ln -s `command -v cmake3` /usr/local/bin/cmake"")\n        self.install(""python3-venv python3-psutil python3-networkx"")\n        self.install_git_lfs_on_linux()\n\n    def macosx(self):\n        if sh(\'xcode-select -p\') == \'\':\n            fatal(""Xcode tools are not installed. Please run xcode-select --install."")\n\n        self.install_gnu_utils()\n        self.install(""cmake"")\n        self.install(""git-lfs"")\n        self.install(""redis"")\n\n    def common_last(self):\n        self.run(""python3 -m pip uninstall -y ramp-packer RLTest || true"")\n        # redis-py-cluster should be installed from git due to redis-py dependency\n        self.pip3_install(""--no-cache-dir git+https://github.com/Grokzen/redis-py-cluster.git@master"")\n        self.pip3_install(""--no-cache-dir git+https://github.com/RedisLabsModules/RLTest.git@master"")\n        self.pip3_install(""--no-cache-dir git+https://github.com/RedisLabs/RAMP@master"")\n\n        self.pip3_install(""-r %s/readies/paella/requirements.txt"" % HERE)\n        self.pip3_install(""-r %s/test/test_requirements.txt"" % ROOT)\n\n        self.pip3_install(""mkdocs mkdocs-material mkdocs-extensions"")\n\n#----------------------------------------------------------------------------------------------\n\nparser = argparse.ArgumentParser(description=\'Set up system for build.\')\nparser.add_argument(\'-n\', \'--nop\', action=""store_true"", help=\'no operation\')\nargs = parser.parse_args()\n\nRedisAISetup(nop=args.nop).setup()\n'"
test/__init__.py,0,b''
test/includes.py,0,"b'import json\nimport os\nimport random\nimport sys\nimport time\nfrom multiprocessing import Process\nimport threading\nfrom numpy.random import default_rng\nimport numpy as np\nfrom skimage.io import imread\nfrom skimage.transform import resize\n\ntry:\n    sys.path.insert(0, os.path.join(os.path.dirname(__file__), ""../../deps/readies""))\n    import paella\nexcept:\n    pass\n\nTEST_TF = os.environ.get(""TEST_TF"") != ""0"" and os.environ.get(""WITH_TF"") != ""0""\nTEST_TFLITE = os.environ.get(""TEST_TFLITE"") != ""0"" and os.environ.get(""WITH_TFLITE"") != ""0""\nTEST_PT = os.environ.get(""TEST_PT"") != ""0"" and os.environ.get(""WITH_PT"") != ""0""\nTEST_ONNX = os.environ.get(""TEST_ONNX"") != ""0"" and os.environ.get(""WITH_ORT"") != ""0""\nCOV = os.environ.get(""COV"") != ""0"" and os.environ.get(""COV"") != ""0""\nDEVICE = os.environ.get(\'DEVICE\', \'CPU\').upper().encode(\'utf-8\', \'ignore\').decode(\'utf-8\')\nVALGRIND = os.environ.get(""VALGRIND"") == ""1""\nprint(f""Running tests on {DEVICE}\\n"")\n\n# change this to make inference tests longer\nMAX_TRANSACTIONS=100\n\ndef ensureSlaveSynced(con, env, timeout_ms=5000):\n    if env.useSlaves:\n        # When WAIT returns, all the previous write commands\n        # sent in the context of the current connection are\n        # guaranteed to be received by the number of replicas returned by WAIT.\n        wait_reply = con.execute_command(\'WAIT\', \'1\', timeout_ms)\n        number_replicas = 0\n        try:\n            number_replicas = int(wait_reply)\n        # does not contain anything convertible to int\n        except ValueError as verr:\n            pass\n        # Exception occurred while converting to int\n        except Exception as ex:\n            pass\n        env.assertTrue(number_replicas >= 1)\n\n\n# Ensures command is sent and forced disconnect\n# after without waiting for the reply to be parsed\n# Usefull for checking behaviour of commands\n# that are run with background threads\ndef send_and_disconnect(cmd, red):\n    pool = red.connection_pool\n    con = pool.get_connection(cmd[0])\n    ret = con.send_command(*cmd)\n    con.disconnect()\n    return ret\n\n\ndef check_cuda():\n    return os.system(\'which nvcc\')\n\n\ndef info_to_dict(info):\n    info = [el.decode(\'utf-8\') if type(el) is bytes else el for el in info]\n    return dict(zip(info[::2], info[1::2]))\n\n\ndef load_resnet_test_data():\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data/imagenet\')\n    labels_filename = os.path.join(test_data_path, \'imagenet_class_index.json\')\n    image_filename = os.path.join(test_data_path, \'dog.jpg\')\n    model_filename = os.path.join(test_data_path, \'resnet50.pb\')\n    script_filename = os.path.join(test_data_path, \'data_processing_script.txt\')\n\n    with open(script_filename, \'rb\') as f:\n        script = f.read()\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    with open(labels_filename, \'r\') as f:\n        labels = json.load(f)\n\n    img_height, img_width = 224, 224\n\n    img = imread(image_filename)\n    img = resize(img, (img_height, img_width), mode=\'constant\', anti_aliasing=True)\n    img = img.astype(np.uint8)\n\n    return model_pb, script, labels, img\n\n\ndef load_mobilenet_test_data():\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    labels_filename = os.path.join(test_data_path, \'imagenet_class_index.json\')\n    image_filename = os.path.join(test_data_path, \'panda.jpg\')\n    model_filename = os.path.join(test_data_path, \'mobilenet_v2_1.4_224_frozen.pb\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    with open(labels_filename, \'r\') as f:\n        labels = json.load(f)\n\n    img_height, img_width = 224, 224\n\n    img = imread(image_filename)\n    img = resize(img, (img_height, img_width), mode=\'constant\', anti_aliasing=True)\n    img = img.astype(np.float32)\n\n    return model_pb, labels, img\n\ndef load_creditcardfraud_data(env,max_tensors=10000):\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'creditcardfraud.pb\')\n    creditcard_transaction_filename = os.path.join(test_data_path, \'creditcard_10K.csv\')\n    rg = default_rng()\n\n    creditcard_transactions = np.genfromtxt(creditcard_transaction_filename, delimiter=\',\', dtype=\'float32\', skip_header=1, usecols=range(0,30))\n\n    creditcard_referencedata = []\n    for tr in range(0,max_tensors):\n        creditcard_referencedata.append(rg.random((1,256), dtype=\'float32\'))\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    return model_pb, creditcard_transactions, creditcard_referencedata\n\ndef run_mobilenet(con, img, input_var, output_var):\n    time.sleep(0.5 * random.randint(0, 10))\n    con.execute_command(\'AI.TENSORSET\', \'input\',\n                        \'FLOAT\', 1, img.shape[1], img.shape[0], img.shape[2],\n                        \'BLOB\', img.tobytes())\n\n    con.execute_command(\'AI.MODELRUN\', \'mobilenet\',\n                        \'INPUTS\', \'input\', \'OUTPUTS\', \'output\')\n\n\ndef run_test_multiproc(env, n_procs, fn, args=tuple()):\n    procs = []\n\n    def tmpfn():\n        con = env.getConnection()\n        fn(con, *args)\n        return 1\n\n    for _ in range(n_procs):\n        p = Process(target=tmpfn)\n        p.start()\n        procs.append(p)\n\n    [p.join() for p in procs]\n'"
test/tests_common.py,0,"b'import redis\n\nfrom includes import *\n\n\'\'\'\npython -m RLTest --test tests_common.py --module path/to/redisai.so\n\'\'\'\n\n\ndef test_common_tensorset(env):\n    con = env.getConnection()\n\n    tested_datatypes = [""FLOAT"", ""DOUBLE"", ""INT8"", ""INT16"", ""INT32"", ""INT64"", ""UINT8"", ""UINT16""]\n    for datatype in tested_datatypes:\n        ret = con.execute_command(\'AI.TENSORSET\', \'tensor_{0}\'.format(datatype), datatype, 2, \'VALUES\', 1, 1)\n        env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    # AI.TENSORGET in BLOB format and set in a new key\n    for datatype in tested_datatypes:\n        _, tensor_dtype, _, tensor_dim, _, tensor_blob = con.execute_command(\'AI.TENSORGET\', \'tensor_{0}\'.format(datatype),\n                                                                             \'META\', \'BLOB\')\n        ret = con.execute_command(\'AI.TENSORSET\', \'tensor_blob_{0}\'.format(datatype), datatype, 2, \'BLOB\', tensor_blob)\n        env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    reply_types = [""META"", ""VALUES"", ""BLOB""]\n    # Confirm that tensor_{0} and tensor_blob_{0} are equal for META VALUES BLOB\n    for datatype in tested_datatypes:\n        for reply_type in reply_types:\n            tensor_1_reply = con.execute_command(\'AI.TENSORGET\', \'tensor_{0}\'.format(datatype), reply_type)\n            tensor_2_reply = con.execute_command(\'AI.TENSORGET\', \'tensor_blob_{0}\'.format(datatype), reply_type)\n            env.assertEqual(tensor_1_reply, tensor_2_reply)\n\n\ndef test_common_tensorset_error_replies(env):\n    con = env.getConnection()\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    sample_filename = os.path.join(test_data_path, \'one.raw\')\n\n    with open(sample_filename, \'rb\') as f:\n        sample_raw = f.read()\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'sample_raw_ok\', \'FLOAT\', 1, 1, 28, 28, \'BLOB\', sample_raw)\n    env.assertEqual(ret, b\'OK\')\n\n    # WRONGTYPE Operation against a key holding the wrong kind of value\n    try:\n        con.execute_command(\'SET\',\'non-tensor\',\'value\')\n        con.execute_command(\'AI.TENSORSET\', \'non-tensor\', \'INT32\', 2, \'unsupported\', 2, 3)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(exception.__str__(), ""WRONGTYPE Operation against a key holding the wrong kind of value"")\n\n    # ERR invalid data type\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'z\', \'INT128\', 2, \'VALUES\', 2, 3)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(exception.__str__(), ""invalid data type"")\n\n    # ERR invalid or negative value found in tensor shape\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'z\', \'INT32\', -1, \'VALUES\', 2, 3)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""invalid or negative value found in tensor shape"",exception.__str__())\n\n    # ERR invalid argument found in tensor shape\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'z\', \'INT32\', 2, \'unsupported\', 2, 3)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""invalid or negative value found in tensor shape"",exception.__str__())\n\n    # ERR invalid value\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'z\', \'FLOAT\', 2, \'VALUES\', 2, \'A\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""invalid value"",exception.__str__())\n\n    # ERR invalid value\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'z\', \'INT32\', 2, \'VALUES\', 2, \'A\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(exception.__str__(), ""invalid value"")\n\n    try:\n        con.execute_command(\'AI.TENSORSET\', 1)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'y\', \'FLOAT\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'y\', \'FLOAT\', \'2\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'y\', \'FLOAT\', 2, \'VALUES\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'y\', \'FLOAT\', 2, \'VALUES\', 1)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'y\', \'FLOAT\', 2, \'VALUES\', \'1\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'blob_tensor_moreargs\', \'FLOAT\', 2, \'BLOB\', \'\\x00\', \'extra-argument\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""wrong number of arguments for \'AI.TENSORSET\' command"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'blob_tensor_lessargs\', \'FLOAT\', 2, \'BLOB\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""wrong number of arguments for \'AI.TENSORSET\' command"", exception.__str__())\n\n    # ERR data length does not match tensor shape and type\n    try:\n        con.execute_command(\'AI.TENSORSET\', \'sample_raw_wrong_blob_for_dim\', \'FLOAT\', 1, 1, 28, 280, \'BLOB\', sample_raw)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""data length does not match tensor shape and type"", exception.__str__())\n\n\ndef test_common_tensorget(env):\n    con = env.getConnection()\n    tested_datatypes = [""FLOAT"", ""DOUBLE"", ""INT8"", ""INT16"", ""INT32"", ""INT64"", ""UINT8"", ""UINT16""]\n    tested_datatypes_fp = [""FLOAT"", ""DOUBLE""]\n    tested_datatypes_int = [""INT8"", ""INT16"", ""INT32"", ""INT64"", ""UINT8"", ""UINT16""]\n    for datatype in tested_datatypes:\n        ret = con.execute_command(\'AI.TENSORSET\', \'tensor_{0}\'.format(datatype), datatype, 2, \'VALUES\', 1, 1)\n        env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    # AI.TENSORGET in BLOB format and set in a new key\n    for datatype in tested_datatypes:\n        tensor_blob = con.execute_command(\'AI.TENSORGET\', \'tensor_{0}\'.format(datatype), \'BLOB\')\n        ret = con.execute_command(\'AI.TENSORSET\', \'tensor_blob_{0}\'.format(datatype), datatype, 2, \'BLOB\', tensor_blob)\n        env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    reply_types = [""META"", ""VALUES"", ""BLOB""]\n    # Confirm that tensor_{0} and tensor_blog_{0} are equal for META VALUES BLOB\n    for datatype in tested_datatypes:\n        for reply_type in reply_types:\n            tensor_1_reply = con.execute_command(\'AI.TENSORGET\', \'tensor_{0}\'.format(datatype), reply_type)\n            tensor_2_reply = con.execute_command(\'AI.TENSORGET\', \'tensor_blob_{0}\'.format(datatype), reply_type)\n            env.assertEqual(tensor_1_reply, tensor_2_reply)\n\n    # Confirm that the output is the expected for META\n    for datatype in tested_datatypes:\n        _, tensor_dtype, _, tensor_dim = con.execute_command(\'AI.TENSORGET\', \'tensor_{0}\'.format(datatype), ""META"")\n        env.assertEqual(datatype.encode(\'utf-8\'), tensor_dtype)\n        env.assertEqual([2], tensor_dim)\n\n    # Confirm that the output is the expected for VALUES\n    for datatype in tested_datatypes:\n        _, tensor_dtype, _, tensor_dim, _, tensor_values = con.execute_command(\'AI.TENSORGET\', \'tensor_{0}\'.format(datatype),\n                                                                               \'META\', \'VALUES\')\n        env.assertEqual(datatype.encode(\'utf-8\'), tensor_dtype)\n        env.assertEqual([2], tensor_dim)\n        if datatype in tested_datatypes_fp:\n            env.assertEqual([b\'1\', b\'1\'], tensor_values)\n        if datatype in tested_datatypes_int:\n            env.assertEqual([1, 1], tensor_values)\n\n    # Confirm that the output is the expected for BLOB\n    for datatype in tested_datatypes:\n        _, tensor_dtype, _, tensor_dim, _, tensor_blob = con.execute_command(\'AI.TENSORGET\', \'tensor_{0}\'.format(datatype),\n                                                                             \'META\', \'BLOB\')\n        env.assertEqual(datatype.encode(\'utf-8\'), tensor_dtype)\n        env.assertEqual([2], tensor_dim)\n\n\ndef test_common_tensorget_error_replies(env):\n    con = env.getConnection()\n\n    # ERR tensor key is empty\n    try:\n        con.execute_command(\'AI.TENSORGET\', \'empty\', \'unsupported\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""tensor key is empty"",exception.__str__())\n\n    # WRONGTYPE Operation against a key holding the wrong kind of value\n    try:\n        con.execute_command(\'SET\', \'non-tensor\', \'value\')\n        con.execute_command(\'AI.TENSORGET\', \'non-tensor\', \'unsupported\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""WRONGTYPE Operation against a key holding the wrong kind of value"",exception.__str__())\n\n    # ERR unsupported data format\n    ret = con.execute_command(\'AI.TENSORSET\', ""T_FLOAT"", ""FLOAT"", 2, \'VALUES\', 1, 1)\n    env.assertEqual(ret, b\'OK\')\n    try:\n        con.execute_command(\'AI.TENSORGET\', \'T_FLOAT\', \'unsupported\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""unsupported data format"",exception.__str__())\n\n\ndef test_common_tensorset_multiproc(env):\n    run_test_multiproc(env, 10,\n                       lambda env: env.execute_command(\'AI.TENSORSET\', \'x\', \'FLOAT\', 2, \'VALUES\', 2, 3))\n\n    con = env.getConnection()\n    ensureSlaveSynced(con, env)\n    values = con.execute_command(\'AI.TENSORGET\', \'x\', \'VALUES\')\n    env.assertEqual(values, [b\'2\', b\'3\'])\n\n\ndef test_common_tensorset_multiproc_blob(env):\n    con = env.getConnection()\n    tested_datatypes = [""FLOAT"", ""DOUBLE"", ""INT8"", ""INT16"", ""INT32"", ""INT64"", ""UINT8"", ""UINT16""]\n    tested_datatypes_map = {}\n    for datatype in tested_datatypes:\n        ret = con.execute_command(\'AI.TENSORSET\', \'tensor_{0}\'.format(datatype), datatype, 1, 256)\n        env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    # AI.TENSORGET in BLOB format and set in a new key\n    for datatype in tested_datatypes:\n        tensor_blob = con.execute_command(\'AI.TENSORGET\', \'tensor_{0}\'.format(datatype),\n                                                                    \'BLOB\')\n        ret = con.execute_command(\'AI.TENSORSET\', \'tensor_blob_{0}\'.format(datatype), datatype, 1, 256, \'BLOB\', tensor_blob)\n        tested_datatypes_map[datatype] = tensor_blob\n        env.assertEqual(ret, b\'OK\')\n\n    def funcname(env, blob, repetitions, same_key):\n        for _ in range(1,same_key):\n            for repetion in range(1,repetitions):\n                env.execute_command(\'AI.TENSORSET\', \'tensor_{0}\'.format(repetitions), \'FLOAT\', 1, 256, \'BLOB\', blob)\n    \n    tensor_blob = tested_datatypes_map[""FLOAT""]\n    t = time.time()\n    run_test_multiproc(env, 10,\n                       lambda env: funcname(env,tensor_blob,MAX_TRANSACTIONS,10) )\n    elapsed_time = time.time() - t\n    avg_ops_sec = 100000*10/elapsed_time\n    # env.debugPrint(""AI.TENSORSET elapsed time(sec) {:6.2f}\\tAvg. ops/sec {:10.2f}"".format(elapsed_time, avg_ops_sec), True)\n\n\ndef test_tensorset_disconnect(env):\n    red = env.getConnection()\n    ret = send_and_disconnect((\'AI.TENSORSET\', \'t_FLOAT\', \'FLOAT\', 2, \'VALUES\', 2, 3), red)\n    env.assertEqual(ret, None)\n\n\ndef test_tensorget_disconnect(env):\n    red = env.getConnection()\n    ret = red.execute_command(\'AI.TENSORSET\', \'t_FLOAT\', \'FLOAT\', 2, \'VALUES\', 2, 3)\n    env.assertEqual(ret, b\'OK\')\n    ret = send_and_disconnect((\'AI.TENSORGET\', \'t_FLOAT\', \'META\'), red)\n    env.assertEqual(ret, None)\n'"
test/tests_dag.py,0,"b'import redis\nfrom functools import wraps\nimport multiprocessing as mp\nfrom includes import *\n\n\'\'\'\npython -m RLTest --test tests_dag.py --module path/to/redisai.so\n\'\'\'\n\n# change this to make inference tests longer\nMAX_TRANSACTIONS=100\n\ndef test_dag_load(env):\n    con = env.getConnection()\n    ret = con.execute_command(\n        ""AI.TENSORSET persisted_tensor_1 FLOAT 1 2 VALUES 5 10"")\n    env.assertEqual(ret, b\'OK\')\n    command = ""AI.DAGRUN ""\\\n                ""LOAD 1 persisted_tensor_1 ""\\\n                ""PERSIST 1 tensor1 |> ""\\\n              ""AI.TENSORSET tensor1 FLOAT 1 2 VALUES 5 10""\n\n    ret = con.execute_command(command)\n    env.assertEqual(ret, [b\'OK\'])\n\ndef test_dag_load_errors(env):\n    con = env.getConnection()\n\n    # ERR tensor key is empty\n    try:\n        command = ""AI.DAGRUN ""\\\n                    ""LOAD 1 persisted_tensor_1 ""\\\n                    ""PERSIST 1 tensor1 |> ""\\\n                ""AI.TENSORSET tensor1 FLOAT 1 2 VALUES 5 10""\n\n        ret = con.execute_command(command)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""tensor key is empty"",exception.__str__())\n\n    # WRONGTYPE Operation against a key holding the wrong kind of value\n    try:\n        con.execute_command(\'SET\', \'non-tensor\', \'value\')\n        command = ""AI.DAGRUN ""\\\n                    ""LOAD 1 non-tensor ""\\\n                    ""PERSIST 1 tensor1 |> ""\\\n                ""AI.TENSORSET tensor1 FLOAT 1 2 VALUES 5 10""\n\n        ret = con.execute_command(command)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""WRONGTYPE Operation against a key holding the wrong kind of value"",exception.__str__())\n\n\ndef test_dag_common_errors(env):\n    con = env.getConnection()\n\n    # ERR unsupported command within DAG\n    try:\n        command = ""AI.DAGRUN |> ""\\\n                ""AI.DONTEXIST tensor1 FLOAT 1 2 VALUES 5 10""\n\n        ret = con.execute_command(command)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""ERR unsupported command within DAG"",exception.__str__())\n\n    # ERR wrong number of arguments for \'AI.DAGRUN\' command\n    try:\n        command = ""AI.DAGRUN ""\n\n        ret = con.execute_command(command)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""wrong number of arguments for \'AI.DAGRUN\' command"",exception.__str__())\n\n    # ERR invalid or negative value found in number of keys to PERSIST\n    try:\n        command = ""AI.DAGRUN PERSIST notnumber |> ""\\\n                ""AI.TENSORSET tensor1 FLOAT 1 2 VALUES 5 10""\n\n        ret = con.execute_command(command)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""invalid or negative value found in number of keys to PERSIST"",exception.__str__())\n\n    # ERR invalid or negative value found in number of keys to LOAD\n    try:\n        command = ""AI.DAGRUN LOAD notnumber |> ""\\\n                ""AI.TENSORSET tensor1 FLOAT 1 2 VALUES 5 10""\n\n        ret = con.execute_command(command)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""invalid or negative value found in number of keys to LOAD"",exception.__str__())\n\n\ndef test_dagro_common_errors(env):\n    con = env.getConnection()\n\n    # ERR unsupported command within DAG\n    try:\n        command = ""AI.DAGRUN_RO |> ""\\\n                ""AI.DONTEXIST tensor1 FLOAT 1 2 VALUES 5 10""\n\n        ret = con.execute_command(command)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""ERR unsupported command within DAG"",exception.__str__())\n\n    # ERR wrong number of arguments for \'AI.DAGRUN\' command\n    try:\n        command = ""AI.DAGRUN_RO ""\n\n        ret = con.execute_command(command)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""wrong number of arguments for \'AI.DAGRUN_RO\' command"",exception.__str__())\n\n    # ERR invalid or negative value found in number of keys to LOAD\n    try:\n        command = ""AI.DAGRUN_RO LOAD notnumber |> ""\\\n                ""AI.TENSORSET tensor1 FLOAT 1 2 VALUES 5 10""\n\n        ret = con.execute_command(command)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""invalid or negative value found in number of keys to LOAD"",exception.__str__())\n\n\ndef test_dagrun_ro_modelrun_scriptrun_resnet(env):\n    if (not TEST_TF or not TEST_PT):\n        return\n    con = env.getConnection()\n    model_name = \'imagenet_model\'\n    script_name = \'imagenet_script\'\n    inputvar = \'images\'\n    outputvar = \'output\'\n    model_pb, script, labels, img = load_resnet_test_data()\n\n    ret = con.execute_command(\'AI.MODELSET\', model_name, \'TF\', DEVICE,\n                        \'INPUTS\', inputvar,\n                        \'OUTPUTS\', outputvar,\n                        \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', script_name, DEVICE, \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n    #\n    for opnumber in range(1,100):\n        image_key = \'image\'\n        temp_key1 = \'temp_key1\'\n        temp_key2 = \'temp_key2\'\n        class_key = \'output\'\n\n        ret = con.execute_command(\n            \'AI.DAGRUN_RO\', \'|>\',\n            \'AI.TENSORSET\', image_key,\n            \'UINT8\', img.shape[1], img.shape[0], 3,\n            \'BLOB\', img.tobytes(), \'|>\',\n            \'AI.SCRIPTRUN\',  script_name,\n            \'pre_process_3ch\', \'INPUTS\', image_key, \'OUTPUTS\', temp_key1,  \'|>\',\n            \'AI.MODELRUN\', model_name,\n            \'INPUTS\', temp_key1, \'OUTPUTS\', temp_key2,  \'|>\',\n            \'AI.SCRIPTRUN\',  script_name,\n            \'post_process\', \'INPUTS\', temp_key2, \'OUTPUTS\', class_key, \'|>\',\n            \'AI.TENSORGET\', class_key, \'VALUES\'\n        )\n        env.assertEqual([b\'OK\',b\'OK\',b\'OK\',b\'OK\'],ret[0:4])\n        # tf model has 100 classes [0,999]\n        env.assertEqual(ret[4][0]>=0 and ret[4][0]<1001, True)\n\ndef test_dagrun_modelrun_scriptrun_resnet(env):\n    if (not TEST_TF or not TEST_PT):\n        return\n    con = env.getConnection()\n    model_name = \'imagenet_model\'\n    script_name = \'imagenet_script\'\n    inputvar = \'images\'\n    outputvar = \'output\'\n    model_pb, script, labels, img = load_resnet_test_data()\n\n    ret = con.execute_command(\'AI.MODELSET\', model_name, \'TF\', DEVICE,\n                              \'INPUTS\', inputvar,\n                              \'OUTPUTS\', outputvar,\n                              \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', script_name, DEVICE, \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    #\n    for opnumber in range(1,100):\n        image_key = \'image\'\n        temp_key1 = \'temp_key1\'\n        temp_key2 = \'temp_key2\'\n        class_key = \'output\'\n\n        ret = con.execute_command(\n            \'AI.DAGRUN\',\n                        \'PERSIST\', \'1\', class_key, \'|>\',\n            \'AI.TENSORSET\', image_key, \'UINT8\', img.shape[1], img.shape[0], 3, \'BLOB\', img.tobytes(), \'|>\',\n            \'AI.SCRIPTRUN\',  script_name, \'pre_process_3ch\',\n                         \'INPUTS\', image_key,\n                         \'OUTPUTS\', temp_key1,  \'|>\',\n            \'AI.MODELRUN\', model_name,\n                         \'INPUTS\', temp_key1,\n                         \'OUTPUTS\', temp_key2,  \'|>\',\n            \'AI.SCRIPTRUN\',  script_name, \'post_process\',\n                          \'INPUTS\', temp_key2,\n                          \'OUTPUTS\', class_key\n        )\n        env.assertEqual([b\'OK\',b\'OK\',b\'OK\',b\'OK\'],ret)\n\n        ret = con.execute_command(\'AI.TENSORGET\', class_key, \'VALUES\' )\n        # tf model has 100 classes [0,999]\n        env.assertEqual(ret[0]>=0 and ret[0]<1001, True)\n\ndef test_dag_scriptrun_errors(env):\n    if (not TEST_TF or not TEST_PT):\n        return\n    con = env.getConnection()\n    model_name = \'imagenet_model\'\n    script_name = \'imagenet_script\'\n    inputvar = \'images\'\n    outputvar = \'output\'\n    model_pb, script, labels, img = load_resnet_test_data()\n\n    ret = con.execute_command(\'AI.MODELSET\', model_name, \'TF\', DEVICE,\n                              \'INPUTS\', inputvar,\n                              \'OUTPUTS\', outputvar,\n                              \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', script_name, DEVICE, \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n\n    # ERR wrong number of inputs\n    try:\n        image_key = \'image\'\n        temp_key1 = \'temp_key1\'\n        temp_key2 = \'temp_key2\'\n        class_key = \'output\'\n\n        ret = con.execute_command(\n            \'AI.DAGRUN\',\'|>\',\n            \'AI.TENSORSET\', image_key, \'UINT8\', img.shape[1], img.shape[0], 3, \'BLOB\', img.tobytes(), \'|>\',\n            \'AI.SCRIPTRUN\',  script_name,\n            \'INPUTS\', image_key,\n            \'OUTPUTS\', temp_key1,  \'|>\',\n            \'AI.MODELRUN\', model_name,\n            \'INPUTS\', temp_key1,\n            \'OUTPUTS\', temp_key2,  \'|>\',\n            \'AI.SCRIPTRUN\',  script_name, \'post_process\',\n            \'INPUTS\', temp_key2,\n            \'OUTPUTS\', class_key\n        )\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""ERR unsupported command within DAG"",exception.__str__())\n\n\ndef test_dag_modelrun_financialNet_errors(env):\n    if not TEST_TF:\n        return\n    con = env.getConnection()\n\n    model_pb, creditcard_transactions, creditcard_referencedata = load_creditcardfraud_data(\n        env)\n    ret = con.execute_command(\'AI.MODELSET\', \'financialNet\', \'TF\', ""CPU"",\n                              \'INPUTS\', \'transaction\', \'reference\', \'OUTPUTS\', \'output\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    tensor_number=1\n    ret = con.execute_command(  \'AI.TENSORSET\', \'referenceTensor:{0}\'.format(tensor_number),\n                                  \'FLOAT\', 1, 256,\n                                  \'BLOB\', creditcard_referencedata[0].tobytes())\n    env.assertEqual(ret, b\'OK\')\n\n    # ERR wrong number of inputs\n    try:\n        tensor_number=1\n        ret = con.execute_command(\n        \'AI.DAGRUN\', \'LOAD\', \'1\', \'referenceTensor:{}\'.format(tensor_number), \n                        \'PERSIST\', \'1\', \'classificationTensor:{}\'.format(tensor_number), \'|>\',\n        \'AI.TENSORSET\', \'transactionTensor:{}\'.format(tensor_number), \'FLOAT\', 1, 30, \'|>\',\n        \'AI.MODELRUN\', \'financialNet\', \n                        \'INPUTS\', \'transactionTensor:{}\'.format(tensor_number),\n                        \'OUTPUTS\', \'classificationTensor:{}\'.format(tensor_number), \'|>\',\n        \'AI.TENSORGET\', \'classificationTensor:{}\'.format(tensor_number), \'META\',\n    )\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""ERR unsupported command within DAG"",exception.__str__())\n\n\ndef test_dag_local_tensorset(env):\n    con = env.getConnection()\n\n    command = ""AI.DAGRUN ""\\\n        ""AI.TENSORSET volatile_tensor1 FLOAT 1 2 VALUES 5 10 |> ""\\\n        ""AI.TENSORSET volatile_tensor2 FLOAT 1 2 VALUES 5 10 ""\n\n    ret = con.execute_command(command)\n    env.assertEqual(ret, [b\'OK\',b\'OK\'])\n\n    # assert that transaction tensor does not exist\n    ret = con.execute_command(""EXISTS volatile_tensor"")\n    env.assertEqual(ret, 0 )\n\n\ndef test_dagro_local_tensorset(env):\n    con = env.getConnection()\n\n    command = ""AI.DAGRUN_RO ""\\\n        ""AI.TENSORSET volatile_tensor1 FLOAT 1 2 VALUES 5 10 |> ""\\\n        ""AI.TENSORSET volatile_tensor2 FLOAT 1 2 VALUES 5 10 ""\n\n    ret = con.execute_command(command)\n    env.assertEqual(ret, [b\'OK\',b\'OK\'])\n\n    # assert that transaction tensor does not exist\n    ret = con.execute_command(""EXISTS volatile_tensor"")\n    env.assertEqual(ret, 0 )\n\n\ndef test_dag_local_tensorset_persist(env):\n    con = env.getConnection()\n\n    command = ""AI.DAGRUN ""\\\n        ""PERSIST 1 tensor1 |> ""\\\n        ""AI.TENSORSET tensor1 FLOAT 1 2 VALUES 5 10""\n\n    ret = con.execute_command(command)\n    env.assertEqual(ret, [b\'OK\'])\n\n    # assert that transaction tensor exists\n    ret = con.execute_command(""EXISTS tensor1"")\n    env.assertEqual(ret, 1 )\n\n    ret = con.execute_command(""AI.TENSORGET tensor1 META VALUES"")\n    env.assertEqual(ret, [b\'dtype\', b\'FLOAT\', b\'shape\', [1, 2], b\'values\', [b\'5\', b\'10\']])\n\n\ndef test_dagro_local_tensorset_persist(env):\n    con = env.getConnection()\n\n    command = ""AI.DAGRUN_RO ""\\\n        ""PERSIST 1 tensor1 |> ""\\\n        ""AI.TENSORSET tensor1 FLOAT 1 2 VALUES 5 10""\n\n    try:\n        con.execute_command(command)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""PERSIST cannot be specified in a read-only DAG"", exception.__str__())\n\n\ndef test_dag_multilocal_tensorset_persist(env):\n    con = env.getConnection()\n\n    command = ""AI.DAGRUN ""\\\n        ""PERSIST 1 tensor3 |> ""\\\n        ""AI.TENSORSET tensor1 FLOAT 1 2 VALUES 5 10 |> ""\\\n        ""AI.TENSORSET tensor2 FLOAT 1 2 VALUES 5 10 |> ""\\\n        ""AI.TENSORSET tensor3 FLOAT 1 2 VALUES 5 10 |> ""\\\n        ""AI.TENSORSET tensor4 FLOAT 1 2 VALUES 5 10 ""\n\n    ret = con.execute_command(command)\n    env.assertEqual([b\'OK\',b\'OK\',b\'OK\',b\'OK\'],ret)\n\n    # assert that transaction tensor exists\n    ret = con.execute_command(""EXISTS tensor1"")\n    env.assertEqual(ret, 0 )\n\n    # assert that transaction tensor exists\n    ret = con.execute_command(""EXISTS tensor2"")\n    env.assertEqual(ret, 0 )\n\n    # assert that transaction tensor exists\n    ret = con.execute_command(""EXISTS tensor3"")\n    env.assertEqual(ret, 1 )\n\n    # assert that transaction tensor exists\n    ret = con.execute_command(""EXISTS tensor4"")\n    env.assertEqual(ret, 0 )\n\n    ret = con.execute_command(""AI.TENSORGET tensor3 META VALUES"")\n    env.assertEqual(ret, [b\'dtype\', b\'FLOAT\', b\'shape\', [1, 2], b\'values\', [b\'5\', b\'10\']])\n\n\ndef test_dag_local_tensorset_tensorget_persist(env):\n    con = env.getConnection()\n\n    command = ""AI.DAGRUN PERSIST 1 tensor1 |> ""\\\n        ""AI.TENSORSET tensor1 FLOAT 1 2 VALUES 5 10 |> ""\\\n        ""AI.TENSORGET tensor1 VALUES""\n\n    ret = con.execute_command(command)\n    env.assertEqual(ret, [b\'OK\', [b\'5\', b\'10\']])\n\n    ret = con.execute_command(""AI.TENSORGET tensor1 VALUES"")\n    env.assertEqual(ret, [b\'5\', b\'10\'])\n\n\ndef test_dag_local_multiple_tensorset_on_same_tensor(env):\n    con = env.getConnection()\n\n    command = ""AI.DAGRUN ""\\\n                     ""PERSIST 1 tensor1 |> ""\\\n        ""AI.TENSORSET tensor1 FLOAT 1 2 VALUES 5 10 |> ""\\\n        ""AI.TENSORGET tensor1 META VALUES |> ""\\\n        ""AI.TENSORSET tensor1 FLOAT 1 4 VALUES 20 40 60 80 |> ""\\\n        ""AI.TENSORGET tensor1 META VALUES""\n\n    ret = con.execute_command(command)\n    env.assertEqual([\n                     b\'OK\', \n                    [b\'dtype\', b\'FLOAT\', b\'shape\', [1, 2], b\'values\', [b\'5\', b\'10\']],\n                     b\'OK\', \n                    [b\'dtype\', b\'FLOAT\', b\'shape\', [1, 4], b\'values\', [b\'20\', b\'40\', b\'60\', b\'80\']]\n                    ], ret)\n\n    ret = con.execute_command(""AI.TENSORGET tensor1 META VALUES"")\n    env.assertEqual([b\'dtype\', b\'FLOAT\', b\'shape\', [1, 4], b\'values\', [b\'20\', b\'40\',b\'60\',b\'80\']],ret)\n\n\ndef test_dag_load_persist_tensorset_tensorget(env):\n    con = env.getConnection()\n\n    ret = con.execute_command(\n        ""AI.TENSORSET persisted_tensor_1 FLOAT 1 2 VALUES 5 10"")\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\n        ""AI.TENSORSET persisted_tensor_2 FLOAT 1 3 VALUES 0 0 0"")\n    env.assertEqual(ret, b\'OK\')\n\n    command = ""AI.DAGRUN LOAD 2 persisted_tensor_1 persisted_tensor_2 PERSIST 1 volatile_tensor_persisted |> ""\\\n        ""AI.TENSORSET volatile_tensor_persisted FLOAT 1 2 VALUES 5 10 |> ""\\\n        ""AI.TENSORGET persisted_tensor_1 META VALUES |> ""\\\n        ""AI.TENSORGET persisted_tensor_2 META VALUES ""\n\n    ret = con.execute_command(command)\n    env.assertEqual(ret, [b\'OK\', [b\'dtype\', b\'FLOAT\', b\'shape\', [1, 2], b\'values\', [b\'5\', b\'10\']], [\n                    b\'dtype\', b\'FLOAT\', b\'shape\', [1, 3], b\'values\', [b\'0\', b\'0\', b\'0\']]])\n\n    ret = con.execute_command(""AI.TENSORGET volatile_tensor_persisted META VALUES"")\n    env.assertEqual(ret, [b\'dtype\', b\'FLOAT\', b\'shape\', [1, 2], b\'values\', [b\'5\', b\'10\']])\n\n\ndef test_dag_local_tensorset_tensorget(env):\n    con = env.getConnection()\n\n    command = ""AI.DAGRUN ""\\\n        ""AI.TENSORSET volatile_tensor FLOAT 1 2 VALUES 5 10 |> ""\\\n        ""AI.TENSORGET volatile_tensor META VALUES""\n\n    ret = con.execute_command(command)\n    env.assertEqual(ret, [b\'OK\', [b\'dtype\', b\'FLOAT\', b\'shape\', [1, 2], b\'values\', [b\'5\', b\'10\']]])\n\n\ndef test_dag_keyspace_tensorget(env):\n    con = env.getConnection()\n\n    ret = con.execute_command(\n        ""AI.TENSORSET persisted_tensor FLOAT 1 2 VALUES 5 10"")\n    env.assertEqual(ret, b\'OK\')\n\n    command = ""AI.DAGRUN LOAD 1 persisted_tensor |> ""\\\n        ""AI.TENSORGET persisted_tensor VALUES""\n\n    ret = con.execute_command(command)\n    env.assertEqual(ret, [[b\'5\', b\'10\']])\n\n\ndef test_dagro_keyspace_tensorget(env):\n    con = env.getConnection()\n\n    ret = con.execute_command(\n        ""AI.TENSORSET persisted_tensor FLOAT 1 2 VALUES 5 10"")\n    env.assertEqual(ret, b\'OK\')\n\n    command = ""AI.DAGRUN_RO LOAD 1 persisted_tensor |> ""\\\n        ""AI.TENSORGET persisted_tensor VALUES""\n\n    ret = con.execute_command(command)\n    env.assertEqual(ret, [[b\'5\', b\'10\']])\n\n\ndef test_dag_keyspace_and_localcontext_tensorget(env):\n    con = env.getConnection()\n\n    ret = con.execute_command(\n        ""AI.TENSORSET persisted_tensor FLOAT 1 2 VALUES 5 10"")\n    env.assertEqual(ret, b\'OK\')\n\n    command = ""AI.DAGRUN LOAD 1 persisted_tensor |> ""\\\n        ""AI.TENSORSET volatile_tensor FLOAT 1 2 VALUES 5 10 |> ""\\\n        ""AI.TENSORGET persisted_tensor VALUES |> ""\\\n        ""AI.TENSORGET volatile_tensor VALUES""\n\n    ret = con.execute_command(command)\n    env.assertEqual(ret, [b\'OK\', [b\'5\', b\'10\'], [b\'5\', b\'10\']])\n\n\ndef test_dag_modelrun_financialNet_separate_tensorget(env):\n    if not TEST_TF:\n        return\n    con = env.getConnection()\n\n    model_pb, creditcard_transactions, creditcard_referencedata = load_creditcardfraud_data(\n        env)\n    ret = con.execute_command(\'AI.MODELSET\', \'financialNet\', \'TF\', ""CPU"",\n                              \'INPUTS\', \'transaction\', \'reference\', \'OUTPUTS\', \'output\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    tensor_number = 1\n    for reference_tensor in creditcard_referencedata[:MAX_TRANSACTIONS]:\n        ret = con.execute_command(\'AI.TENSORSET\', \'referenceTensor:{0}\'.format(tensor_number),\n                                  \'FLOAT\', 1, 256,\n                                  \'BLOB\', reference_tensor.tobytes())\n        env.assertEqual(ret, b\'OK\')\n        tensor_number = tensor_number + 1\n\n    tensor_number = 1\n    for transaction_tensor in creditcard_transactions[:MAX_TRANSACTIONS]:\n        ret = con.execute_command(\n            \'AI.DAGRUN\', \'LOAD\', \'1\', \'referenceTensor:{}\'.format(tensor_number), \n            \'PERSIST\', \'1\', \'classificationTensor:{}\'.format(tensor_number), \'|>\',\n            \'AI.TENSORSET\', \'transactionTensor:{}\'.format(tensor_number), \'FLOAT\', 1, 30,\'BLOB\', transaction_tensor.tobytes(), \'|>\',\n            \'AI.MODELRUN\', \'financialNet\', \n                \'INPUTS\', \'transactionTensor:{}\'.format(tensor_number), \'referenceTensor:{}\'.format(tensor_number),\n                \'OUTPUTS\', \'classificationTensor:{}\'.format(tensor_number), \n        )\n        env.assertEqual([b\'OK\',b\'OK\'],ret)\n\n        ret = con.execute_command(""AI.TENSORGET classificationTensor:{} META"".format(\n            tensor_number))\n        env.assertEqual([b\'dtype\', b\'FLOAT\', b\'shape\', [1, 2]], ret)\n\n        # assert that transaction tensor does not exist\n        ret = con.execute_command(""EXISTS transactionTensor:{} META"".format(\n            tensor_number))\n        env.assertEqual(ret, 0 )\n        tensor_number = tensor_number + 1\n\n\ndef test_dag_modelrun_financialNet(env):\n    if not TEST_TF:\n        return\n    con = env.getConnection()\n\n    model_pb, creditcard_transactions, creditcard_referencedata = load_creditcardfraud_data(\n        env)\n    ret = con.execute_command(\'AI.MODELSET\', \'financialNet\', \'TF\', ""CPU"",\n                              \'INPUTS\', \'transaction\', \'reference\', \'OUTPUTS\', \'output\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    tensor_number = 1\n    for reference_tensor in creditcard_referencedata[:MAX_TRANSACTIONS]:\n        ret = con.execute_command(\'AI.TENSORSET\', \'referenceTensor:{0}\'.format(tensor_number),\n                                  \'FLOAT\', 1, 256,\n                                  \'BLOB\', reference_tensor.tobytes())\n        env.assertEqual(ret, b\'OK\')\n        tensor_number = tensor_number + 1\n\n    tensor_number = 1\n    for transaction_tensor in creditcard_transactions[:MAX_TRANSACTIONS]:\n        ret = con.execute_command(\n            \'AI.DAGRUN\', \'LOAD\', \'1\', \'referenceTensor:{}\'.format(tensor_number), \n                         \'PERSIST\', \'1\', \'classificationTensor:{}\'.format(tensor_number), \'|>\',\n            \'AI.TENSORSET\', \'transactionTensor:{}\'.format(tensor_number), \'FLOAT\', 1, 30,\'BLOB\', transaction_tensor.tobytes(), \'|>\',\n            \'AI.MODELRUN\', \'financialNet\', \n                           \'INPUTS\', \'transactionTensor:{}\'.format(tensor_number), \'referenceTensor:{}\'.format(tensor_number),\n                           \'OUTPUTS\', \'classificationTensor:{}\'.format(tensor_number), \'|>\',\n            \'AI.TENSORGET\', \'classificationTensor:{}\'.format(tensor_number), \'META\',\n        )\n        env.assertEqual([b\'OK\',b\'OK\',[b\'dtype\', b\'FLOAT\', b\'shape\', [1, 2]]], ret)\n\n        # assert that transaction tensor does not exist\n        ret = con.execute_command(""EXISTS transactionTensor:{}"".format(\n            tensor_number))\n        env.assertEqual(ret, 0 )\n        tensor_number = tensor_number + 1\n\n\ndef test_dag_modelrun_financialNet_no_writes(env):\n    if not TEST_TF:\n        return\n    con = env.getConnection()\n\n    model_pb, creditcard_transactions, creditcard_referencedata = load_creditcardfraud_data(\n        env)\n    ret = con.execute_command(\'AI.MODELSET\', \'financialNet\', \'TF\', ""CPU"",\n                              \'INPUTS\', \'transaction\', \'reference\', \'OUTPUTS\', \'output\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    tensor_number = 1\n    for reference_tensor in creditcard_referencedata[:MAX_TRANSACTIONS]:\n        ret = con.execute_command(\'AI.TENSORSET\', \'referenceTensor:{0}\'.format(tensor_number),\n                                  \'FLOAT\', 1, 256,\n                                  \'BLOB\', reference_tensor.tobytes())\n        env.assertEqual(ret, b\'OK\')\n        tensor_number = tensor_number + 1\n\n    tensor_number = 1\n    for transaction_tensor in creditcard_transactions[:MAX_TRANSACTIONS]:\n        for run_number in range(1,10):\n            ret = con.execute_command(\n                \'AI.DAGRUN\', \'LOAD\', \'1\', \'referenceTensor:{}\'.format(tensor_number), \'|>\',\n                \'AI.TENSORSET\', \'transactionTensor:{}\'.format(tensor_number), \'FLOAT\', 1, 30,\'BLOB\', transaction_tensor.tobytes(), \'|>\',\n                \'AI.MODELRUN\', \'financialNet\', \n                            \'INPUTS\', \'transactionTensor:{}\'.format(tensor_number), \'referenceTensor:{}\'.format(tensor_number),\n                            \'OUTPUTS\', \'classificationTensor:{}\'.format(tensor_number), \'|>\',\n                \'AI.TENSORGET\', \'classificationTensor:{}\'.format(tensor_number), \'META\',  \'|>\',\n                \'AI.TENSORGET\', \'classificationTensor:{}\'.format(tensor_number), \'VALUES\'\n            )\n            env.assertEqual(4, len(ret))\n            env.assertEqual([b\'OK\', b\'OK\'], ret[:2])\n            env.assertEqual([b\'dtype\', b\'FLOAT\', b\'shape\', [1, 2]], ret[2])\n            values = ret[3]\n            # Assert that resulting classification is within [0,1]\n            env.assertEqual(True, 0 <= float(values[0]) <= 1)\n            env.assertEqual(True, 0 <= float(values[1]) <= 1)\n\n            # assert that transactionTensor does not exist\n            ret = con.execute_command(""EXISTS transactionTensor:{}"".format(\n                tensor_number))\n            env.assertEqual(ret, 0 )\n\n            # assert that classificationTensor does not exist\n            ret = con.execute_command(""EXISTS classificationTensor:{}"".format(\n                tensor_number))\n            env.assertEqual(ret, 0 )\n        tensor_number = tensor_number + 1\n\n\ndef test_dagro_modelrun_financialNet_no_writes_multiple_modelruns(env):\n    if not TEST_TF:\n        return\n    con = env.getConnection()\n\n    model_pb, creditcard_transactions, creditcard_referencedata = load_creditcardfraud_data(\n        env)\n    ret = con.execute_command(\'AI.MODELSET\', \'financialNet\', \'TF\', DEVICE,\n                              \'INPUTS\', \'transaction\', \'reference\', \'OUTPUTS\', \'output\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    tensor_number = 1\n    for reference_tensor in creditcard_referencedata[:MAX_TRANSACTIONS]:\n        ret = con.execute_command(\'AI.TENSORSET\', \'referenceTensor:{0}\'.format(tensor_number),\n                                  \'FLOAT\', 1, 256,\n                                  \'BLOB\', reference_tensor.tobytes())\n        env.assertEqual(ret, b\'OK\')\n        tensor_number = tensor_number + 1\n\n    tensor_number = 1\n    for transaction_tensor in creditcard_transactions[:MAX_TRANSACTIONS]:\n        ret = con.execute_command(\n            \'AI.DAGRUN_RO\', \'LOAD\', \'1\', \'referenceTensor:{}\'.format(tensor_number), \'|>\',\n            \'AI.TENSORSET\', \'transactionTensor:{}\'.format(tensor_number), \'FLOAT\', 1, 30,\'BLOB\', transaction_tensor.tobytes(), \'|>\',\n            \'AI.MODELRUN\', \'financialNet\', \n                           \'INPUTS\', \'transactionTensor:{}\'.format(tensor_number), \'referenceTensor:{}\'.format(tensor_number),\n                           \'OUTPUTS\', \'classificationTensor:{}\'.format(tensor_number), \'|>\',\n            \'AI.TENSORGET\', \'classificationTensor:{}\'.format(tensor_number), \'META\', \'VALUES\', \'|>\',\n            \'AI.MODELRUN\', \'financialNet\', \n                           \'INPUTS\', \'transactionTensor:{}\'.format(tensor_number), \'referenceTensor:{}\'.format(tensor_number),\n                           \'OUTPUTS\', \'classificationTensor:{}\'.format(tensor_number), \'|>\',\n            \'AI.TENSORGET\', \'classificationTensor:{}\'.format(tensor_number), \'META\', \'VALUES\', \n        )\n        env.assertEqual(5, len(ret))\n        env.assertEqual([b\'OK\', b\'OK\'], ret[:2])\n        env.assertEqual([b\'dtype\', b\'FLOAT\', b\'shape\', [1, 2]], ret[2][:4])\n        env.assertEqual(b\'OK\', ret[3])\n        env.assertEqual([b\'dtype\', b\'FLOAT\', b\'shape\', [1, 2]], ret[4][:4])\n        for _, dtype, _, shape, _, values in [ret[2], ret[4]]:\n            # Assert that resulting classification is within [0,1]\n            env.assertEqual(True, 0 <= float(values[0]) <= 1)\n            env.assertEqual(True, 0 <= float(values[1]) <= 1)\n\n        # assert that transactionTensor does not exist\n        ret = con.execute_command(""EXISTS transactionTensor:{}"".format(\n            tensor_number))\n        env.assertEqual(ret, 0)\n\n        # assert that classificationTensor does not exist\n        ret = con.execute_command(""EXISTS classificationTensor:{}"".format(\n            tensor_number))\n        env.assertEqual(ret, 0)\n        tensor_number = tensor_number + 1\n\n    info = con.execute_command(\'AI.INFO\', \'financialNet\')\n    financialNetRunInfo = info_to_dict(info)\n\n    env.assertEqual(\'financialNet\', financialNetRunInfo[\'key\'])\n    env.assertEqual(\'MODEL\', financialNetRunInfo[\'type\'])\n    env.assertEqual(\'TF\', financialNetRunInfo[\'backend\'])\n    env.assertEqual(DEVICE, financialNetRunInfo[\'device\'])\n    env.assertTrue(financialNetRunInfo[\'duration\'] > 0)\n    env.assertEqual(0, financialNetRunInfo[\'samples\'])\n    env.assertEqual(2*MAX_TRANSACTIONS, financialNetRunInfo[\'calls\'])\n    env.assertEqual(0, financialNetRunInfo[\'errors\'])\n\n    con.execute_command(\'AI.INFO\', \'financialNet\', \'RESETSTAT\')\n    info = con.execute_command(\'AI.INFO\', \'financialNet\')\n    financialNetRunInfo = info_to_dict(info)\n\n    env.assertEqual(\'financialNet\', financialNetRunInfo[\'key\'])\n    env.assertEqual(\'MODEL\', financialNetRunInfo[\'type\'])\n    env.assertEqual(\'TF\', financialNetRunInfo[\'backend\'])\n    env.assertEqual(DEVICE, financialNetRunInfo[\'device\'])\n    env.assertEqual(0, financialNetRunInfo[\'duration\'])\n    env.assertEqual(0, financialNetRunInfo[\'samples\'])\n    env.assertEqual(0, financialNetRunInfo[\'calls\'])\n    env.assertEqual(0, financialNetRunInfo[\'errors\'])\n'"
test/tests_onnx.py,0,"b'import sys\nimport os\nimport subprocess\nimport redis\nfrom includes import *\n\n\'\'\'\npython -m RLTest --test tests_onnx.py --module path/to/redisai.so\n\'\'\'\n\n\ndef test_onnx_modelrun_mnist(env):\n    if not TEST_ONNX:\n        env.debugPrint(""skipping {} since TEST_ONNX=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'mnist.onnx\')\n    wrong_model_filename = os.path.join(test_data_path, \'graph.pb\')\n    sample_filename = os.path.join(test_data_path, \'one.raw\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    with open(wrong_model_filename, \'rb\') as f:\n        wrong_model_pb = f.read()\n\n    with open(sample_filename, \'rb\') as f:\n        sample_raw = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'ONNX\', DEVICE, \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    env.assertEqual(len(ret), 14)\n    env.assertEqual(ret[5], b\'\')\n    # assert there are no inputs or outputs\n    env.assertEqual(len(ret[11]), 0)\n    env.assertEqual(len(ret[13]), 0)\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'ONNX\', DEVICE, \'TAG\', \'version:2\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    env.assertEqual(len(ret), 14)\n    # TODO: enable me. CI is having issues on GPU asserts of ONNX and CPU\n    if DEVICE == ""CPU"":\n        env.assertEqual(ret[1], b\'ONNX\')\n        env.assertEqual(ret[3], b\'CPU\')\n    env.assertEqual(ret[5], b\'version:2\')\n    # assert there are no inputs or outputs\n    env.assertEqual(len(ret[11]), 0)\n    env.assertEqual(len(ret[13]), 0)\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m\', \'ONNX\', DEVICE, \'BLOB\', wrong_model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""No graph was found in the protobuf."", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_1\', \'ONNX\', \'BLOB\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Invalid DEVICE"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_2\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""wrong number of arguments for \'AI.MODELSET\' command"", exception.__str__())\n\n    con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 1, 1, 28, 28, \'BLOB\', sample_raw)\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_1\', \'INPUTS\', \'a\', \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""model key is empty"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_2\', \'INPUTS\', \'a\', \'b\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""model key is empty"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_3\', \'a\', \'b\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""model key is empty"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_1\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""model key is empty"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""INPUTS not specified"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""tensor key is empty"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_1\', \'INPUTS\', \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""model key is empty"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_1\', \'INPUTS\', \'a\', \'OUTPUTS\', \'b\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""model key is empty"", exception.__str__())\n\n    con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'OUTPUTS\', \'b\')\n\n    ensureSlaveSynced(con, env)\n\n    values = con.execute_command(\'AI.TENSORGET\', \'b\', \'VALUES\')\n    argmax = max(range(len(values)), key=lambda i: values[i])\n\n    env.assertEqual(argmax, 1)\n\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        values2 = con2.execute_command(\'AI.TENSORGET\', \'b\', \'VALUES\')\n        env.assertEqual(values2, values)\n\n\ndef test_onnx_modelrun_mnist_autobatch(env):\n    if not TEST_ONNX:\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'mnist_batched.onnx\')\n    sample_filename = os.path.join(test_data_path, \'one.raw\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    with open(sample_filename, \'rb\') as f:\n        sample_raw = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'ONNX\', \'CPU\',\n                              \'BATCHSIZE\', 2, \'MINBATCHSIZE\', 2, \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    env.assertEqual(len(ret), 14)\n    # TODO: enable me. CI is having issues on GPU asserts of ONNX and CPU\n    if DEVICE == ""CPU"":\n        env.assertEqual(ret[1], b\'ONNX\')\n        env.assertEqual(ret[3], b\'CPU\')\n    env.assertEqual(ret[5], b\'\')\n    env.assertEqual(ret[7], 2)\n    env.assertEqual(ret[9], 2)\n    # assert there are no inputs or outputs\n    env.assertEqual(len(ret[11]), 0)\n    env.assertEqual(len(ret[13]), 0)\n\n    con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 1, 1, 28, 28, \'BLOB\', sample_raw)\n    con.execute_command(\'AI.TENSORSET\', \'c\', \'FLOAT\', 1, 1, 28, 28, \'BLOB\', sample_raw)\n\n    ensureSlaveSynced(con, env)\n\n    def run():\n        con = env.getConnection()\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'c\', \'OUTPUTS\', \'d\')\n\n    t = threading.Thread(target=run)\n    t.start()\n\n    con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'OUTPUTS\', \'b\')\n\n    ensureSlaveSynced(con, env)\n\n    import time\n    time.sleep(1)\n\n    values = con.execute_command(\'AI.TENSORGET\', \'b\', \'VALUES\')\n    argmax = max(range(len(values)), key=lambda i: values[i])\n\n    env.assertEqual(argmax, 1)\n\n    values = con.execute_command(\'AI.TENSORGET\', \'d\', \'VALUES\')\n    argmax = max(range(len(values)), key=lambda i: values[i])\n\n    env.assertEqual(argmax, 1)\n\n\ndef test_onnx_modelrun_iris(env):\n    if not TEST_ONNX:\n        env.debugPrint(""skipping {} since TEST_ONNX=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    linear_model_filename = os.path.join(test_data_path, \'linear_iris.onnx\')\n    logreg_model_filename = os.path.join(test_data_path, \'logreg_iris.onnx\')\n\n    with open(linear_model_filename, \'rb\') as f:\n        linear_model = f.read()\n\n    with open(logreg_model_filename, \'rb\') as f:\n        logreg_model = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'linear\', \'ONNX\', DEVICE, \'BLOB\', linear_model)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.MODELSET\', \'logreg\', \'ONNX\', DEVICE, \'BLOB\', logreg_model)\n    env.assertEqual(ret, b\'OK\')\n\n    con.execute_command(\'AI.TENSORSET\', \'features\', \'FLOAT\', 1, 4, \'VALUES\', 5.1, 3.5, 1.4, 0.2)\n\n    ensureSlaveSynced(con, env)\n\n    con.execute_command(\'AI.MODELRUN\', \'linear\', \'INPUTS\', \'features\', \'OUTPUTS\', \'linear_out\')\n    con.execute_command(\'AI.MODELRUN\', \'logreg\', \'INPUTS\', \'features\', \'OUTPUTS\', \'logreg_out\', \'logreg_probs\')\n\n    ensureSlaveSynced(con, env)\n\n    linear_out = con.execute_command(\'AI.TENSORGET\', \'linear_out\', \'VALUES\')\n    logreg_out = con.execute_command(\'AI.TENSORGET\', \'logreg_out\', \'VALUES\')\n\n    env.assertEqual(float(linear_out[0]), -0.090524077415466309)\n    env.assertEqual(logreg_out[0], 0)\n\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        linear_out2 = con2.execute_command(\'AI.TENSORGET\', \'linear_out\', \'VALUES\')\n        logreg_out2 = con2.execute_command(\'AI.TENSORGET\', \'logreg_out\', \'VALUES\')\n        env.assertEqual(linear_out, linear_out2)\n        env.assertEqual(logreg_out, logreg_out2)\n\n\ndef test_onnx_modelinfo(env):\n    if not TEST_ONNX:\n        env.debugPrint(""skipping {} since TEST_ONNX=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    linear_model_filename = os.path.join(test_data_path, \'linear_iris.onnx\')\n\n    with open(linear_model_filename, \'rb\') as f:\n        linear_model = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'linear\', \'ONNX\', DEVICE, \'BLOB\', linear_model)\n    env.assertEqual(ret, b\'OK\')\n\n    model_serialized_master = con.execute_command(\'AI.MODELGET\', \'linear\', \'META\')\n    con.execute_command(\'AI.TENSORSET\', \'features\', \'FLOAT\', 1, 4, \'VALUES\', 5.1, 3.5, 1.4, 0.2)\n\n    ensureSlaveSynced(con, env)\n\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        model_serialized_slave = con2.execute_command(\'AI.MODELGET\', \'linear\', \'META\')\n        env.assertEqual(len(model_serialized_master), len(model_serialized_slave))\n    previous_duration = 0\n    for call in range(1, 10):\n        res = con.execute_command(\'AI.MODELRUN\', \'linear\', \'INPUTS\', \'features\', \'OUTPUTS\', \'linear_out\')\n        env.assertEqual(res, b\'OK\')\n        ensureSlaveSynced(con, env)\n\n        info = con.execute_command(\'AI.INFO\', \'linear\')\n        info_dict_0 = info_to_dict(info)\n\n        env.assertEqual(info_dict_0[\'key\'], \'linear\')\n        env.assertEqual(info_dict_0[\'type\'], \'MODEL\')\n        env.assertEqual(info_dict_0[\'backend\'], \'ONNX\')\n        env.assertEqual(info_dict_0[\'device\'], DEVICE)\n        env.assertTrue(info_dict_0[\'duration\'] > previous_duration)\n        env.assertEqual(info_dict_0[\'samples\'], call)\n        env.assertEqual(info_dict_0[\'calls\'], call)\n        env.assertEqual(info_dict_0[\'errors\'], 0)\n\n        previous_duration = info_dict_0[\'duration\']\n\n    res = con.execute_command(\'AI.INFO\', \'linear\', \'RESETSTAT\')\n    env.assertEqual(res, b\'OK\')\n\n    info = con.execute_command(\'AI.INFO\', \'linear\')\n    info_dict_0 = info_to_dict(info)\n    env.assertEqual(info_dict_0[\'duration\'], 0)\n    env.assertEqual(info_dict_0[\'samples\'], 0)\n    env.assertEqual(info_dict_0[\'calls\'], 0)\n    env.assertEqual(info_dict_0[\'errors\'], 0)\n\n\ndef test_onnx_modelrun_disconnect(env):\n    if not TEST_ONNX:\n        env.debugPrint(""skipping {} since TEST_ONNX=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    linear_model_filename = os.path.join(test_data_path, \'linear_iris.onnx\')\n\n    with open(linear_model_filename, \'rb\') as f:\n        linear_model = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'linear\', \'ONNX\', DEVICE, \'BLOB\', linear_model)\n    env.assertEqual(ret, b\'OK\')\n\n    model_serialized_master = con.execute_command(\'AI.MODELGET\', \'linear\', \'META\')\n    con.execute_command(\'AI.TENSORSET\', \'features\', \'FLOAT\', 1, 4, \'VALUES\', 5.1, 3.5, 1.4, 0.2)\n\n    ensureSlaveSynced(con, env)\n\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        model_serialized_slave = con2.execute_command(\'AI.MODELGET\', \'linear\', \'META\')\n        env.assertEqual(len(model_serialized_master), len(model_serialized_slave))\n\n    ret = send_and_disconnect((\'AI.MODELRUN\', \'linear\', \'INPUTS\', \'features\', \'OUTPUTS\', \'linear_out\'), con)\n    env.assertEqual(ret, None)\n\ndef test_onnx_model_rdb_save_load(env):\n    env.skipOnCluster()\n    if env.useAof or not TEST_ONNX:\n        env.debugPrint(""skipping {}"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    linear_model_filename = os.path.join(test_data_path, \'linear_iris.onnx\')\n\n    with open(linear_model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    con = env.getConnection()\n    ret = con.execute_command(\'AI.MODELSET\', \'linear\', \'ONNX\', DEVICE, \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    model_serialized_memory = con.execute_command(\'AI.MODELGET\', \'linear\', \'BLOB\')\n\n    ensureSlaveSynced(con, env)\n    ret = con.execute_command(\'SAVE\')\n    env.assertEqual(ret, True)\n\n    env.stop()\n    env.start()\n    con = env.getConnection()\n    model_serialized_after_rdbload = con.execute_command(\'AI.MODELGET\', \'linear\', \'BLOB\')\n    env.assertEqual(len(model_serialized_memory), len(model_serialized_after_rdbload))\n    env.assertEqual(len(model_pb), len(model_serialized_after_rdbload))\n    # Assert in memory model binary is equal to loaded model binary\n    env.assertTrue(model_serialized_memory == model_serialized_after_rdbload)\n    # Assert input model binary is equal to loaded model binary\n    env.assertTrue(model_pb == model_serialized_after_rdbload)\n\n'"
test/tests_pytorch.py,0,"b'import redis\n\nfrom includes import *\n\n\'\'\'\npython -m RLTest --test tests_pytorch.py --module path/to/redisai.so\n\'\'\'\n\n\ndef test_pytorch_chunked_modelset(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'pt-minimal.pt\')\n\n    with open(model_filename, \'rb\') as f:\n        model = f.read()\n\n    chunk_size = len(model) // 3\n\n    model_chunks = [model[i:i + chunk_size] for i in range(0, len(model), chunk_size)]\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m1\', \'TORCH\', DEVICE, \'BLOB\', model)\n    ret = con.execute_command(\'AI.MODELSET\', \'m2\', \'TORCH\', DEVICE, \'BLOB\', *model_chunks)\n\n    model1 = con.execute_command(\'AI.MODELGET\', \'m1\', \'BLOB\')\n    model2 = con.execute_command(\'AI.MODELGET\', \'m2\', \'BLOB\')\n\n    env.assertEqual(model1, model2)\n\n\ndef test_pytorch_modelrun(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'pt-minimal.pt\')\n    wrong_model_filename = os.path.join(test_data_path, \'graph.pb\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    with open(wrong_model_filename, \'rb\') as f:\n        wrong_model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TORCH\', DEVICE, \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    env.assertEqual(len(ret), 14)\n    # TODO: enable me. CI is having issues on GPU asserts of TORCH and CPU\n    if DEVICE == ""CPU"":\n        env.assertEqual(ret[1], b\'TORCH\')\n        env.assertEqual(ret[3], b\'CPU\')\n    env.assertEqual(ret[5], b\'\')\n    env.assertEqual(ret[7], 0)\n    env.assertEqual(ret[9], 0)\n    # assert there are no inputs or outputs\n    env.assertEqual(len(ret[11]), 0)\n    env.assertEqual(len(ret[13]), 0)\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TORCH\', DEVICE, \'TAG\', \'my:tag:v3\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    env.assertEqual(len(ret), 14)\n    env.assertEqual(ret[5], b\'my:tag:v3\')\n    # TODO: enable me. CI is having issues on GPU asserts of TORCH and CPU\n    if DEVICE == ""CPU"":\n        env.assertEqual(ret[1], b\'TORCH\')\n        env.assertEqual(ret[3], b\'CPU\')\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m\', \'TORCH\', DEVICE, \'BLOB\', wrong_model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_1\', \'TORCH\', \'BLOB\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_2\', \'BLOB\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_1\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_2\', \'INPUTS\', \'a\', \'b\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_3\', \'a\', \'b\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_1\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_1\', \'INPUTS\', \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_1\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\', \'d\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\')\n\n    ensureSlaveSynced(con, env)\n\n    values = con.execute_command(\'AI.TENSORGET\', \'c\', \'VALUES\')\n    env.assertEqual(values, [b\'4\', b\'6\', b\'4\', b\'6\'])\n\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        values2 = con2.execute_command(\'AI.TENSORGET\', \'c\', \'VALUES\')\n        env.assertEqual(values2, values)\n\n\ndef test_pytorch_modelrun_autobatch(env):\n    if not TEST_PT:\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'pt-minimal.pt\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TORCH\', \'CPU\',\n                              \'BATCHSIZE\', 4, \'MINBATCHSIZE\', 3, \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n\n    con.execute_command(\'AI.TENSORSET\', \'d\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    con.execute_command(\'AI.TENSORSET\', \'e\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n\n    ensureSlaveSynced(con, env)\n\n    def run():\n        con = env.getConnection()\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'d\', \'e\', \'OUTPUTS\', \'f\')\n        ensureSlaveSynced(con, env)\n\n    t = threading.Thread(target=run)\n    t.start()\n\n    con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\')\n\n    ensureSlaveSynced(con, env)\n\n    values = con.execute_command(\'AI.TENSORGET\', \'c\', \'VALUES\')\n    env.assertEqual(values, [b\'4\', b\'6\', b\'4\', b\'6\'])\n\n    values = con.execute_command(\'AI.TENSORGET\', \'f\', \'VALUES\')\n    env.assertEqual(values, [b\'4\', b\'6\', b\'4\', b\'6\'])\n\n\ndef test_pytorch_modelrun_autobatch_badbatch(env):\n    if not TEST_PT:\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'pt-minimal-bb.pt\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TORCH\', \'CPU\',\n                              \'BATCHSIZE\', 4, \'MINBATCHSIZE\', 3, \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n\n    con.execute_command(\'AI.TENSORSET\', \'d\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    con.execute_command(\'AI.TENSORSET\', \'e\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n\n    ensureSlaveSynced(con, env)\n\n    def run():\n        con = env.getConnection()\n        try:\n            con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'d\', \'e\', \'OUTPUTS\', \'f1\', \'f2\')\n        except Exception as e:\n            exception = e\n            env.assertEqual(type(exception), redis.exceptions.ResponseError)\n            env.assertEqual(""Model did not generate the expected batch size"", exception.__str__())\n\n    t = threading.Thread(target=run)\n    t.start()\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c1\', \'c2\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Model did not generate the expected batch size"", exception.__str__())\n\n\n\ndef test_pytorch_modelinfo(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'pt-minimal.pt\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TORCH\', DEVICE, \'TAG\', \'asdf\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    previous_duration = 0\n    for call in range(1, 10):\n        ret = con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\')\n        env.assertEqual(ret, b\'OK\')\n        ensureSlaveSynced(con, env)\n\n        info = con.execute_command(\'AI.INFO\', \'m\')\n        info_dict_0 = info_to_dict(info)\n\n        env.assertEqual(info_dict_0[\'key\'], \'m\')\n        env.assertEqual(info_dict_0[\'type\'], \'MODEL\')\n        env.assertEqual(info_dict_0[\'backend\'], \'TORCH\')\n        env.assertEqual(info_dict_0[\'device\'], DEVICE)\n        env.assertEqual(info_dict_0[\'tag\'], \'asdf\')\n        env.assertTrue(info_dict_0[\'duration\'] > previous_duration)\n        env.assertEqual(info_dict_0[\'samples\'], 2 * call)\n        env.assertEqual(info_dict_0[\'calls\'], call)\n        env.assertEqual(info_dict_0[\'errors\'], 0)\n\n        previous_duration = info_dict_0[\'duration\']\n\n    res = con.execute_command(\'AI.INFO\', \'m\', \'RESETSTAT\')\n    env.assertEqual(res, b\'OK\')\n    info = con.execute_command(\'AI.INFO\', \'m\')\n    info_dict_0 = info_to_dict(info)\n    env.assertEqual(info_dict_0[\'duration\'], 0)\n    env.assertEqual(info_dict_0[\'samples\'], 0)\n    env.assertEqual(info_dict_0[\'calls\'], 0)\n    env.assertEqual(info_dict_0[\'errors\'], 0)\n\n\ndef test_pytorch_scriptset(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    try:\n        con.execute_command(\'AI.SCRIPTSET\', \'ket\', DEVICE, \'SOURCE\', \'return 1\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.SCRIPTSET\', \'nope\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.SCRIPTSET\', \'nope\', \'SOURCE\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.SCRIPTSET\', \'more\', DEVICE)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    script_filename = os.path.join(test_data_path, \'script.txt\')\n\n    with open(script_filename, \'rb\') as f:\n        script = f.read()\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', \'ket\', DEVICE, \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    with open(script_filename, \'rb\') as f:\n        script = f.read()\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', \'ket\', DEVICE, \'TAG\', \'asdf\', \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    # TODO: Check why this COMMAND is hanging CI\n    # ret = con.execute_command(\'AI.SCRIPTGET\', \'ket\')\n    # env.assertEqual([b\'CPU\',script],ret)\n    #\n    # if env.useSlaves:\n    #     con2 = env.getSlaveConnection()\n    #     script_slave = con2.execute_command(\'AI.SCRIPTGET\', \'ket\')\n    #     env.assertEqual(ret, script_slave)\n\n\ndef test_pytorch_scriptdel(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    script_filename = os.path.join(test_data_path, \'script.txt\')\n\n    with open(script_filename, \'rb\') as f:\n        script = f.read()\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', \'ket\', DEVICE, \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = con.execute_command(\'AI.SCRIPTDEL\', \'ket\')\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    env.assertFalse(con.execute_command(\'EXISTS\', \'ket\'))\n\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        env.assertFalse(con2.execute_command(\'EXISTS\', \'ket\'))\n\n    # ERR no script at key from SCRIPTDEL\n    try:\n        con.execute_command(\'DEL\', \'EMPTY\')\n        con.execute_command(\'AI.SCRIPTDEL\', \'EMPTY\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""script key is empty"", exception.__str__())\n\n    # ERR wrong type from SCRIPTDEL\n    try:\n        con.execute_command(\'SET\', \'NOT_SCRIPT\', \'BAR\')\n        con.execute_command(\'AI.SCRIPTDEL\', \'NOT_SCRIPT\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""WRONGTYPE Operation against a key holding the wrong kind of value"", exception.__str__())\n\n\ndef test_pytorch_scriptrun(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    script_filename = os.path.join(test_data_path, \'script.txt\')\n\n    with open(script_filename, \'rb\') as f:\n        script = f.read()\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', \'myscript\', DEVICE, \'TAG\', \'version1\', \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n    ret = con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    for _ in range( 0,100):\n\n        ret = con.execute_command(\'AI.SCRIPTRUN\', \'myscript\', \'bar\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\')\n        env.assertEqual(ret, b\'OK\')\n\n\n    ensureSlaveSynced(con, env)\n\n    info = con.execute_command(\'AI.INFO\', \'myscript\')\n    info_dict_0 = info_to_dict(info)\n\n    env.assertEqual(info_dict_0[\'key\'], \'myscript\')\n    env.assertEqual(info_dict_0[\'type\'], \'SCRIPT\')\n    env.assertEqual(info_dict_0[\'backend\'], \'TORCH\')\n    env.assertEqual(info_dict_0[\'tag\'], \'version1\')\n    env.assertTrue(info_dict_0[\'duration\'] > 0)\n    env.assertEqual(info_dict_0[\'samples\'], -1)\n    env.assertEqual(info_dict_0[\'calls\'], 100)\n    env.assertEqual(info_dict_0[\'errors\'], 0)\n\n    values = con.execute_command(\'AI.TENSORGET\', \'c\', \'VALUES\')\n    env.assertEqual(values, [b\'4\', b\'6\', b\'4\', b\'6\'])\n\n    ensureSlaveSynced(con, env)\n\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        values2 = con2.execute_command(\'AI.TENSORGET\', \'c\', \'VALUES\')\n        env.assertEqual(values2, values)\n\n\ndef test_pytorch_scriptrun_variadic(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    script_filename = os.path.join(test_data_path, \'script.txt\')\n\n    with open(script_filename, \'rb\') as f:\n        script = f.read()\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', \'myscript\', DEVICE, \'TAG\', \'version1\', \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n    ret = con.execute_command(\'AI.TENSORSET\', \'b1\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n    ret = con.execute_command(\'AI.TENSORSET\', \'b2\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    for _ in range( 0,100):\n        ret = con.execute_command(\'AI.SCRIPTRUN\', \'myscript\', \'bar_variadic\', \'INPUTS\', \'a\', \'$\', \'b1\', \'b2\', \'OUTPUTS\', \'c\')\n        env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    info = con.execute_command(\'AI.INFO\', \'myscript\')\n    info_dict_0 = info_to_dict(info)\n\n    env.assertEqual(info_dict_0[\'key\'], \'myscript\')\n    env.assertEqual(info_dict_0[\'type\'], \'SCRIPT\')\n    env.assertEqual(info_dict_0[\'backend\'], \'TORCH\')\n    env.assertEqual(info_dict_0[\'tag\'], \'version1\')\n    env.assertTrue(info_dict_0[\'duration\'] > 0)\n    env.assertEqual(info_dict_0[\'samples\'], -1)\n    env.assertEqual(info_dict_0[\'calls\'], 100)\n    env.assertEqual(info_dict_0[\'errors\'], 0)\n\n    values = con.execute_command(\'AI.TENSORGET\', \'c\', \'VALUES\')\n    env.assertEqual(values, [b\'4\', b\'6\', b\'4\', b\'6\'])\n\n    ensureSlaveSynced(con, env)\n\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        values2 = con2.execute_command(\'AI.TENSORGET\', \'c\', \'VALUES\')\n        env.assertEqual(values2, values)\n\n\ndef test_pytorch_scriptrun_errors(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    script_filename = os.path.join(test_data_path, \'script.txt\')\n\n    with open(script_filename, \'rb\') as f:\n        script = f.read()\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', \'ket\', DEVICE, \'TAG\', \'asdf\', \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n    ret = con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    # ERR no script at key from SCRIPTGET\n    try:\n        con.execute_command(\'DEL\', \'EMPTY\')\n        con.execute_command(\'AI.SCRIPTGET\', \'EMPTY\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""script key is empty"", exception.__str__())\n\n    # ERR wrong type from SCRIPTGET\n    try:\n        con.execute_command(\'SET\', \'NOT_SCRIPT\', \'BAR\')\n        con.execute_command(\'AI.SCRIPTGET\', \'NOT_SCRIPT\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""WRONGTYPE Operation against a key holding the wrong kind of value"", exception.__str__())\n\n    # ERR no script at key from SCRIPTRUN\n    try:\n        con.execute_command(\'DEL\', \'EMPTY\')\n        con.execute_command(\'AI.SCRIPTRUN\', \'EMPTY\', \'bar\', \'INPUTS\', \'b\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""script key is empty"", exception.__str__())\n\n    # ERR wrong type from SCRIPTRUN\n    try:\n        con.execute_command(\'SET\', \'NOT_SCRIPT\', \'BAR\')\n        con.execute_command(\'AI.SCRIPTRUN\', \'NOT_SCRIPT\', \'bar\', \'INPUTS\', \'b\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""WRONGTYPE Operation against a key holding the wrong kind of value"", exception.__str__())\n\n    # ERR Input key is empty\n    try:\n        con.execute_command(\'DEL\', \'EMPTY\')\n        con.execute_command(\'AI.SCRIPTRUN\', \'ket\', \'bar\', \'INPUTS\', \'EMPTY\', \'b\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""tensor key is empty"", exception.__str__())\n\n    # ERR Input key not tensor\n    try:\n        con.execute_command(\'SET\', \'NOT_TENSOR\', \'BAR\')\n        con.execute_command(\'AI.SCRIPTRUN\', \'ket\', \'bar\', \'INPUTS\', \'NOT_TENSOR\', \'b\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""WRONGTYPE Operation against a key holding the wrong kind of value"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.SCRIPTRUN\', \'ket\', \'bar\', \'INPUTS\', \'b\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.SCRIPTRUN\', \'ket\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.SCRIPTRUN\', \'ket\', \'bar\', \'INPUTS\', \'b\', \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.SCRIPTRUN\', \'ket\', \'bar\', \'INPUTS\', \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n\ndef test_pytorch_scriptrun_errors(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    script_filename = os.path.join(test_data_path, \'script.txt\')\n\n    with open(script_filename, \'rb\') as f:\n        script = f.read()\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', \'ket\', DEVICE, \'TAG\', \'asdf\', \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n    ret = con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    # ERR Variadic input key is empty\n    try:\n        con.execute_command(\'DEL\', \'EMPTY\')\n        con.execute_command(\'AI.SCRIPTRUN\', \'ket\', \'bar_variadic\', \'INPUTS\', \'a\', \'$\', \'EMPTY\', \'b\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""tensor key is empty"", exception.__str__())\n\n    # ERR Variadic input key not tensor\n    try:\n        con.execute_command(\'SET\', \'NOT_TENSOR\', \'BAR\')\n        con.execute_command(\'AI.SCRIPTRUN\', \'ket\', \'bar_variadic\', \'INPUTS\', \'a\', \'$\' , \'NOT_TENSOR\', \'b\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""WRONGTYPE Operation against a key holding the wrong kind of value"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.SCRIPTRUN\', \'ket\', \'bar_variadic\', \'INPUTS\', \'b\', \'$\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.SCRIPTRUN\', \'ket\', \'bar_variadic\', \'INPUTS\', \'b\', \'$\', \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.SCRIPTRUN\', \'ket\', \'bar_variadic\', \'INPUTS\', \'$\', \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n    \n    # ""ERR Already encountered a variable size list of tensors""\n    try:\n        con.execute_command(\'AI.SCRIPTRUN\', \'ket\', \'bar_variadic\', \'INPUTS\', \'$\', \'a\', \'$\', \'b\' \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n\ndef test_pytorch_scriptinfo(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    # env.debugPrint(""skipping this test for now"", force=True)\n    # return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    script_filename = os.path.join(test_data_path, \'script.txt\')\n\n    with open(script_filename, \'rb\') as f:\n        script = f.read()\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', \'ket_script\', DEVICE, \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n    ret = con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    previous_duration = 0\n    for call in range(1, 100):\n        ret = con.execute_command(\'AI.SCRIPTRUN\', \'ket_script\', \'bar\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\')\n        env.assertEqual(ret, b\'OK\')\n        ensureSlaveSynced(con, env)\n\n        info = con.execute_command(\'AI.INFO\', \'ket_script\')\n        info_dict_0 = info_to_dict(info)\n\n        env.assertEqual(info_dict_0[\'key\'], \'ket_script\')\n        env.assertEqual(info_dict_0[\'type\'], \'SCRIPT\')\n        env.assertEqual(info_dict_0[\'backend\'], \'TORCH\')\n        env.assertEqual(info_dict_0[\'device\'], DEVICE)\n        env.assertTrue(info_dict_0[\'duration\'] > previous_duration)\n        env.assertEqual(info_dict_0[\'samples\'], -1)\n        env.assertEqual(info_dict_0[\'calls\'], call)\n        env.assertEqual(info_dict_0[\'errors\'], 0)\n\n        previous_duration = info_dict_0[\'duration\']\n\n    res = con.execute_command(\'AI.INFO\', \'ket_script\', \'RESETSTAT\')\n    env.assertEqual(res, b\'OK\')\n    info = con.execute_command(\'AI.INFO\', \'ket_script\')\n    info_dict_0 = info_to_dict(info)\n    env.assertEqual(info_dict_0[\'duration\'], 0)\n    env.assertEqual(info_dict_0[\'samples\'], -1)\n    env.assertEqual(info_dict_0[\'calls\'], 0)\n    env.assertEqual(info_dict_0[\'errors\'], 0)\n\n\ndef test_pytorch_scriptrun_disconnect(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    if DEVICE == ""GPU"":\n        env.debugPrint(""skipping {} since it\'s hanging CI"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    script_filename = os.path.join(test_data_path, \'script.txt\')\n\n    with open(script_filename, \'rb\') as f:\n        script = f.read()\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', \'ket_script\', DEVICE, \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n    ret = con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = send_and_disconnect((\'AI.SCRIPTRUN\', \'ket_script\', \'bar\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\'), con)\n    env.assertEqual(ret, None)\n\n\ndef test_pytorch_modelrun_disconnect(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    if DEVICE == ""GPU"":\n        env.debugPrint(""skipping {} since it\'s hanging CI"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'pt-minimal.pt\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TORCH\', DEVICE, \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = send_and_disconnect((\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\'), con)\n    env.assertEqual(ret, None)\n\n\ndef test_pytorch_modelscan_scriptscan(env):\n    if not TEST_PT:\n        env.debugPrint(""skipping {} since TEST_PT=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    # ensure cleaned DB\n    # env.flush()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'pt-minimal.pt\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m1\', \'TORCH\', DEVICE, \'TAG\', \'m:v1\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m2\', \'TORCH\', DEVICE, \'TAG\', \'m:v1\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    script_filename = os.path.join(test_data_path, \'script.txt\')\n\n    with open(script_filename, \'rb\') as f:\n        script = f.read()\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', \'s1\', DEVICE, \'TAG\', \'s:v1\', \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', \'s2\', DEVICE, \'TAG\', \'s:v1\', \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = con.execute_command(\'AI._MODELSCAN\')\n    env.assertEqual(2, len(ret[0]))\n    env.assertEqual(2, len(ret[1]))\n\n    ret = con.execute_command(\'AI._SCRIPTSCAN\')\n\n    env.assertEqual(2, len(ret[0]))\n    env.assertEqual(2, len(ret[1]))\n\n\ndef test_pytorch_model_rdb_save_load(env):\n    env.skipOnCluster()\n    if env.useAof or not TEST_PT:\n        env.debugPrint(""skipping {}"".format(sys._getframe().f_code.co_name), force=True)\n        return\n    if DEVICE == ""GPU"":\n        env.debugPrint(""skipping {} since it\'s hanging CI"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'pt-minimal.pt\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    con = env.getConnection()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TORCH\', DEVICE, \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    model_serialized_memory = con.execute_command(\'AI.MODELGET\', \'m\', \'BLOB\')\n\n    con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\')\n    _, dtype_memory, _, shape_memory, _, data_memory = con.execute_command(\'AI.TENSORGET\', \'c\', \'META\', \'VALUES\')\n\n    ensureSlaveSynced(con, env)\n    ret = con.execute_command(\'SAVE\')\n    env.assertEqual(ret, True)\n\n    env.stop()\n    env.start()\n    con = env.getConnection()\n    model_serialized_after_rdbload = con.execute_command(\'AI.MODELGET\', \'m\', \'BLOB\')\n    con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\')\n    _, dtype_after_rdbload, _, shape_after_rdbload, _, data_after_rdbload = con.execute_command(\'AI.TENSORGET\', \'c\', \'META\', \'VALUES\')\n\n    # Assert in memory model metadata is equal to loaded model metadata\n    env.assertTrue(model_serialized_memory[1:6] == model_serialized_after_rdbload[1:6])\n    # Assert in memory tensor data is equal to loaded tensor data\n    env.assertTrue(dtype_memory == dtype_after_rdbload)\n    env.assertTrue(shape_memory == shape_after_rdbload)\n    env.assertTrue(data_memory == data_after_rdbload)\n'"
test/tests_tensorflow.py,0,"b'import redis\nfrom functools import wraps\nimport multiprocessing as mp\n\nfrom includes import *\n\n\'\'\'\npython -m RLTest --test tests_tensorflow.py --module path/to/redisai.so\n\'\'\'\n\n\ndef skip_if_no_TF(f):\n    @wraps(f)\n    def wrapper(env, *args, **kwargs):\n        if not TEST_TF:\n            env.debugPrint(""skipping {} since TEST_TF=0"".format(\n                sys._getframe().f_code.co_name), force=True)\n            return\n        return f(env, *args, **kwargs)\n    return wrapper\n\n\n@skip_if_no_TF\ndef test_run_mobilenet(env):\n    con = env.getConnection()\n\n    input_var = \'input\'\n    output_var = \'MobilenetV2/Predictions/Reshape_1\'\n\n    model_pb, labels, img = load_mobilenet_test_data()\n\n    con.execute_command(\'AI.MODELSET\', \'mobilenet\', \'TF\', DEVICE,\n                        \'INPUTS\', input_var, \'OUTPUTS\', output_var, \'BLOB\', model_pb)\n\n    ensureSlaveSynced(con, env)\n\n    mobilenet_model_serialized = con.execute_command(\n        \'AI.MODELGET\', \'mobilenet\', \'META\')\n\n    ensureSlaveSynced(con, env)\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        slave_mobilenet_model_serialized = con2.execute_command(\n            \'AI.MODELGET\', \'mobilenet\', \'META\')\n        env.assertEqual(len(mobilenet_model_serialized),\n                        len(slave_mobilenet_model_serialized))\n\n    con.execute_command(\'AI.TENSORSET\', \'input\',\n                        \'FLOAT\', 1, img.shape[1], img.shape[0], img.shape[2],\n                        \'BLOB\', img.tobytes())\n\n    ensureSlaveSynced(con, env)\n    input_tensor_meta = con.execute_command(\'AI.TENSORGET\', \'input\', \'META\')\n    env.assertEqual(\n        [b\'dtype\', b\'FLOAT\', b\'shape\', [1, img.shape[1], img.shape[0], img.shape[2]]], input_tensor_meta)\n\n    ensureSlaveSynced(con, env)\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        slave_tensor_meta = con2.execute_command(\n            \'AI.TENSORGET\', \'input\', \'META\')\n        env.assertEqual(input_tensor_meta, slave_tensor_meta)\n\n    con.execute_command(\'AI.MODELRUN\', \'mobilenet\',\n                        \'INPUTS\', \'input\', \'OUTPUTS\', \'output\')\n\n    ensureSlaveSynced(con, env)\n\n    _, dtype, _, shape, _, data = con.execute_command(\'AI.TENSORGET\', \'output\', \'META\', \'BLOB\')\n\n    dtype_map = {b\'FLOAT\': np.float32}\n    tensor = np.frombuffer(data, dtype=dtype_map[dtype]).reshape(shape)\n    label_id = np.argmax(tensor) - 1\n\n    _, label = labels[str(label_id)]\n\n    env.assertEqual(label, \'giant_panda\')\n\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        _, slave_dtype, _, slave_shape, _, slave_data = con2.execute_command(\n            \'AI.TENSORGET\', \'output\', \'META\', \'BLOB\')\n        env.assertEqual(dtype, slave_dtype)\n        env.assertEqual(shape, slave_shape)\n        env.assertEqual(data, slave_data)\n\n\n@skip_if_no_TF\ndef test_run_mobilenet_multiproc(env):\n    if VALGRIND:\n        env.debugPrint(""skipping {} since VALGRIND=1"".format(\n            sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    input_var = \'input\'\n    output_var = \'MobilenetV2/Predictions/Reshape_1\'\n\n    model_pb, labels, img = load_mobilenet_test_data()\n    con.execute_command(\'AI.MODELSET\', \'mobilenet\', \'TF\', DEVICE,\n                        \'INPUTS\', input_var, \'OUTPUTS\', output_var, \'BLOB\', model_pb)\n    ensureSlaveSynced(con, env)\n\n    run_test_multiproc(env, 30, run_mobilenet, (img, input_var, output_var))\n\n    ensureSlaveSynced(con, env)\n\n    _, dtype, _, shape, _, data = con.execute_command(\'AI.TENSORGET\', \'output\', \'META\', \'BLOB\')\n\n    dtype_map = {b\'FLOAT\': np.float32}\n    tensor = np.frombuffer(data, dtype=dtype_map[dtype]).reshape(shape)\n    label_id = np.argmax(tensor) - 1\n\n    _, label = labels[str(label_id)]\n\n    env.assertEqual(\n        label, \'giant_panda\'\n    )\n\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        _, slave_dtype, _, slave_shape, _, slave_data = con2.execute_command(\n            \'AI.TENSORGET\', \'output\', \'META\', \'BLOB\')\n        env.assertEqual(dtype, slave_dtype)\n        env.assertEqual(shape, slave_shape)\n        env.assertEqual(data, slave_data)\n\n\n@skip_if_no_TF\ndef test_del_tf_model(env):\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'graph.pb\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TF\', DEVICE,\n                              \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    con.execute_command(\'AI.MODELDEL\', \'m\')\n    env.assertFalse(con.execute_command(\'EXISTS\', \'m\'))\n\n    ensureSlaveSynced(con, env)\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        env.assertFalse(con2.execute_command(\'EXISTS\', \'m\'))\n\n    # ERR no model at key\n    try:\n        con.execute_command(\'AI.MODELDEL\', \'m\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""model key is empty"", exception.__str__())\n\n    # ERR wrong type\n    try:\n        con.execute_command(\'SET\', \'NOT_MODEL\', \'BAR\')\n        con.execute_command(\'AI.MODELDEL\', \'NOT_MODEL\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(\n            ""WRONGTYPE Operation against a key holding the wrong kind of value"", exception.__str__())\n\n\n@skip_if_no_TF\ndef test_run_tf_model(env):\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'graph.pb\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TF\', DEVICE,\n                              \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    env.assertEqual(len(ret), 14)\n    env.assertEqual(ret[5], b\'\')\n    env.assertEqual(ret[11][0], b\'a\')\n    env.assertEqual(ret[11][1], b\'b\')\n    env.assertEqual(ret[13][0], b\'mul\')\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TF\', DEVICE, \'TAG\', \'version:1\',\n                              \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    env.assertEqual(len(ret), 14)\n    # TODO: enable me. CI is having issues on GPU asserts of TF and CPU\n    if DEVICE == ""CPU"":\n        env.assertEqual(ret[1], b\'TF\')\n        env.assertEqual(ret[3], b\'CPU\')\n    env.assertEqual(ret[5], b\'version:1\')\n    env.assertEqual(ret[11][0], b\'a\')\n    env.assertEqual(ret[11][1], b\'b\')\n    env.assertEqual(ret[13][0], b\'mul\')\n\n    con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\',\n                        2, 2, \'VALUES\', 2, 3, 2, 3)\n    con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\',\n                        2, 2, \'VALUES\', 2, 3, 2, 3)\n\n    ensureSlaveSynced(con, env)\n\n    con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\')\n\n    ensureSlaveSynced(con, env)\n\n    values = con.execute_command(\'AI.TENSORGET\', \'c\', \'VALUES\')\n    env.assertEqual(values, [b\'4\', b\'9\', b\'4\', b\'9\'])\n\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        values2 = con2.execute_command(\'AI.TENSORGET\', \'c\', \'VALUES\')\n        env.assertEqual(values2, values)\n\n    for _ in env.reloadingIterator():\n        env.assertExists(\'m\')\n        env.assertExists(\'a\')\n        env.assertExists(\'b\')\n        env.assertExists(\'c\')\n\n    con.execute_command(\'AI.MODELDEL\', \'m\')\n    ensureSlaveSynced(con, env)\n\n    env.assertFalse(con.execute_command(\'EXISTS\', \'m\'))\n\n    ensureSlaveSynced(con, env)\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        env.assertFalse(con2.execute_command(\'EXISTS\', \'m\'))\n\n\n@skip_if_no_TF\ndef test_run_tf2_model(env):\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'graph_v2.pb\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TF\', DEVICE,\n                              \'INPUTS\', \'x\', \'OUTPUTS\', \'Identity\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    env.assertEqual(len(ret), 14)\n    env.assertEqual(ret[5], b\'\')\n    env.assertEqual(ret[11][0], b\'x\')\n    env.assertEqual(ret[13][0], b\'Identity\')\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TF\', DEVICE, \'TAG\', \'asdf\',\n                              \'INPUTS\', \'x\', \'OUTPUTS\', \'Identity\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    env.assertEqual(len(ret), 14)\n    env.assertEqual(ret[5], b\'asdf\')\n    env.assertEqual(ret[11][0], b\'x\')\n    env.assertEqual(ret[13][0], b\'Identity\')\n\n    zero_values = [0] * (28 * 28)\n\n    con.execute_command(\'AI.TENSORSET\', \'x\', \'FLOAT\',\n                        1, 1, 28, 28, \'VALUES\', *zero_values)\n\n    ensureSlaveSynced(con, env)\n\n    con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'x\', \'OUTPUTS\', \'y\')\n\n    ensureSlaveSynced(con, env)\n\n    values = con.execute_command(\'AI.TENSORGET\', \'y\', \'VALUES\')\n    for value in values:\n        env.assertAlmostEqual(float(value), 0.1, 1E-4)\n\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        values2 = con2.execute_command(\'AI.TENSORGET\', \'y\', \'VALUES\')\n        env.assertEqual(values2, values)\n\n    for _ in env.reloadingIterator():\n        env.assertExists(\'m\')\n        env.assertExists(\'x\')\n        env.assertExists(\'y\')\n\n    con.execute_command(\'AI.MODELDEL\', \'m\')\n    ensureSlaveSynced(con, env)\n\n    env.assertFalse(con.execute_command(\'EXISTS\', \'m\'))\n\n    ensureSlaveSynced(con, env)\n    if env.useSlaves:\n        con2 = env.getSlaveConnection()\n        env.assertFalse(con2.execute_command(\'EXISTS\', \'m\'))\n\n\n@skip_if_no_TF\ndef test_run_tf_model_errors(env):\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'graph.pb\')\n    wrong_model_filename = os.path.join(test_data_path, \'pt-minimal.pt\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    with open(wrong_model_filename, \'rb\') as f:\n        wrong_model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TF\', DEVICE,\n                              \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    try:\n        con.execute_command(\'AI.MODELGET\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(\n            ""wrong number of arguments for \'AI.MODELGET\' command"", exception.__str__())\n\n    # ERR WRONGTYPE\n    con.execute_command(\'SET\', \'NOT_MODEL\', \'BAR\')\n    try:\n        con.execute_command(\'AI.MODELGET\', \'NOT_MODEL\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(\n            ""WRONGTYPE Operation against a key holding the wrong kind of value"", exception.__str__())\n    # cleanup\n    con.execute_command(\'DEL\', \'NOT_MODEL\')\n\n    # ERR model key is empty\n    con.execute_command(\'DEL\', \'DONT_EXIST\')\n    try:\n        con.execute_command(\'AI.MODELGET\', \'DONT_EXIST\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""model key is empty"", exception.__str__())\n\n    try:\n        ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TF\', DEVICE,\n                                  \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', wrong_model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Invalid GraphDef"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_1\', \'TF\',\n                            \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Invalid DEVICE"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_2\', \'PORCH\', DEVICE,\n                            \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""unsupported backend"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_3\', \'TORCH\', DEVICE,\n                            \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_4\', \'TF\',\n                            \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Invalid DEVICE"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_5\', \'TF\', DEVICE,\n                            \'INPUTS\', \'a\', \'b\', \'c\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""WRONGTYPE Operation against a key holding the wrong kind of value"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_6\', \'TF\', DEVICE,\n                            \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mult\', \'BLOB\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Output node named \\""mult\\"" not found in TF graph"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_7\', \'TF\', DEVICE, \'BLOB\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Insufficient arguments, INPUTS and OUTPUTS not specified"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_8\', \'TF\', DEVICE,\n                            \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Insufficient arguments, missing model BLOB"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_8\', \'TF\', DEVICE,\n                            \'INPUTS\', \'a_\', \'b\', \'OUTPUTS\', \'mul\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Insufficient arguments, missing model BLOB"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_8\', \'TF\', DEVICE,\n                            \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul_\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Insufficient arguments, missing model BLOB"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_8\', \'TF\', DEVICE,\n                            \'INPUTS\', \'a\', \'b\', \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Insufficient arguments, missing model BLOB"",exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""tensor key is empty"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""INPUTS not specified"", exception.__str__())\n\n\n@skip_if_no_TF\ndef test_run_tf_model_autobatch(env):\n    if not TEST_PT:\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'graph.pb\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TF\', \'CPU\',\n                              \'BATCHSIZE\', 4, \'MINBATCHSIZE\', 3,\n                              \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\',\n                        2, 2, \'VALUES\', 2, 3, 2, 3)\n    con.execute_command(\'AI.TENSORSET\', \'b\', \'FLOAT\',\n                        2, 2, \'VALUES\', 2, 3, 2, 3)\n\n    con.execute_command(\'AI.TENSORSET\', \'d\', \'FLOAT\',\n                        2, 2, \'VALUES\', 2, 3, 2, 3)\n    con.execute_command(\'AI.TENSORSET\', \'e\', \'FLOAT\',\n                        2, 2, \'VALUES\', 2, 3, 2, 3)\n\n    ensureSlaveSynced(con, env)\n\n    def run():\n        con = env.getConnection()\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\',\n                            \'d\', \'e\', \'OUTPUTS\', \'f\')\n        ensureSlaveSynced(con, env)\n\n    t = threading.Thread(target=run)\n    t.start()\n\n    con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\')\n\n    ensureSlaveSynced(con, env)\n\n    values = con.execute_command(\'AI.TENSORGET\', \'c\', \'VALUES\')\n    env.assertEqual(values, [b\'4\', b\'9\', b\'4\', b\'9\'])\n\n    values = con.execute_command(\'AI.TENSORGET\', \'f\', \'VALUES\')\n    env.assertEqual(values, [b\'4\', b\'9\', b\'4\', b\'9\'])\n\n\n@skip_if_no_TF\ndef test_tensorflow_modelinfo(env):\n    con = env.getConnection()\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'graph.pb\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TF\', DEVICE,\n                              \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n    info = con.execute_command(\'AI.INFO\', \'m\')  # Getting initial info before modelrun\n    info_dict0 = info_to_dict(info)\n    expected = {\'key\': \'m\', \'type\': \'MODEL\', \'backend\': \'TF\', \'device\': DEVICE,\n                \'tag\': \'\', \'duration\': 0, \'samples\': 0, \'calls\': 0, \'errors\': 0}\n    env.assertEqual(info_dict0, expected)\n\n    # second modelset; a corner case\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TF\', DEVICE,\n                              \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n    info = con.execute_command(\'AI.INFO\', \'m\')  # this will fail\n    info_dict1 = info_to_dict(info)\n    env.assertEqual(info_dict1, info_dict0)\n\n    ret = con.execute_command(\n        \'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\n        \'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    previous_duration = 0\n    for call in range(1, 10):\n        ret = con.execute_command(\n            \'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\')\n        env.assertEqual(ret, b\'OK\')\n        ensureSlaveSynced(con, env)\n\n        info = con.execute_command(\'AI.INFO\', \'m\')\n        info_dict_0 = info_to_dict(info)\n\n        env.assertEqual(info_dict_0[\'key\'], \'m\')\n        env.assertEqual(info_dict_0[\'type\'], \'MODEL\')\n        env.assertEqual(info_dict_0[\'backend\'], \'TF\')\n        env.assertEqual(info_dict_0[\'device\'], DEVICE)\n        env.assertTrue(info_dict_0[\'duration\'] > previous_duration)\n        env.assertEqual(info_dict_0[\'samples\'], 2 * call)\n        env.assertEqual(info_dict_0[\'calls\'], call)\n        env.assertEqual(info_dict_0[\'errors\'], 0)\n\n        previous_duration = info_dict_0[\'duration\']\n\n    res = con.execute_command(\'AI.INFO\', \'m\', \'RESETSTAT\')\n    env.assertEqual(res, b\'OK\')\n    info = con.execute_command(\'AI.INFO\', \'m\')\n    info_dict_0 = info_to_dict(info)\n    env.assertEqual(info_dict_0[\'duration\'], 0)\n    env.assertEqual(info_dict_0[\'samples\'], 0)\n    env.assertEqual(info_dict_0[\'calls\'], 0)\n    env.assertEqual(info_dict_0[\'errors\'], 0)\n\n\n@skip_if_no_TF\ndef test_tensorflow_modelrun_disconnect(env):\n    red = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'graph.pb\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    ret = red.execute_command(\'AI.MODELSET\', \'m\', \'TF\', DEVICE,\n                              \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'mul\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = red.execute_command(\n        \'AI.TENSORSET\', \'a\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = red.execute_command(\n        \'AI.TENSORSET\', \'b\', \'FLOAT\', 2, 2, \'VALUES\', 2, 3, 2, 3)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(red, env)\n\n    ret = send_and_disconnect(\n        (\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\', \'OUTPUTS\', \'c\'), red)\n    env.assertEqual(ret, None)\n\n\n@skip_if_no_TF\ndef test_tensorflow_modelrun_with_batch_and_minbatch(env):\n    con = env.getConnection()\n    batch_size = 2\n    minbatch_size = 2\n    model_name = \'model\'\n    another_model_name = \'another_model\'\n    inputvar = \'input\'\n    outputvar = \'MobilenetV2/Predictions/Reshape_1\'\n\n    model_pb, labels, img = load_mobilenet_test_data()\n\n    con.execute_command(\'AI.MODELSET\', model_name, \'TF\', DEVICE,\n                        \'BATCHSIZE\', batch_size, \'MINBATCHSIZE\', minbatch_size,\n                        \'INPUTS\', inputvar,\n                        \'OUTPUTS\', outputvar,\n                        \'BLOB\', model_pb)\n    con.execute_command(\'AI.TENSORSET\', \'input\',\n                        \'FLOAT\', 1, img.shape[1], img.shape[0], img.shape[2],\n                        \'BLOB\', img.tobytes())\n\n    def run(name=model_name, output_name=\'output\'):\n        con = env.getConnection()\n        con.execute_command(\'AI.MODELRUN\', name,\n                            \'INPUTS\', \'input\', \'OUTPUTS\', output_name)\n\n    # Running thrice since minbatchsize = 2\n    p1 = mp.Process(target=run)\n    p1.start()\n    p2 = mp.Process(target=run)\n    p2.start()\n    p3 = mp.Process(target=run)\n    p3.start()\n\n    time.sleep(3)\n\n    con.execute_command(\'AI.MODELSET\', another_model_name, \'TF\', DEVICE,\n                        \'BATCHSIZE\', batch_size, \'MINBATCHSIZE\', minbatch_size,\n                        \'INPUTS\', inputvar,\n                        \'OUTPUTS\', outputvar,\n                        \'BLOB\', model_pb)\n\n    p1b = mp.Process(target=run, args=(another_model_name, \'final1\'))\n    p1b.start()\n\n    run(another_model_name, \'final2\')\n\n    _, dtype, _, shape, _, data = con.execute_command(\'AI.TENSORGET\', \'final1\', \'META\', \'BLOB\')\n    dtype_map = {b\'FLOAT\': np.float32}\n    tensor = np.frombuffer(data, dtype=dtype_map[dtype]).reshape(shape)\n    label_id = np.argmax(tensor) - 1\n\n    _, label = labels[str(label_id)]\n\n    env.assertEqual(label, \'giant_panda\')\n\n    p3.terminate()\n\n\n@skip_if_no_TF\ndef test_tensorflow_modelrun_financialNet(env):\n    con = env.getConnection()\n\n    model_pb, creditcard_transactions, creditcard_referencedata = load_creditcardfraud_data(env)\n\n    tensor_number = 1\n    for transaction_tensor in creditcard_transactions[:MAX_TRANSACTIONS]:\n        ret = con.execute_command(\'AI.TENSORSET\', \'transactionTensor:{0}\'.format(tensor_number),\n                                  \'FLOAT\', 1, 30,\n                                  \'BLOB\', transaction_tensor.tobytes())\n        env.assertEqual(ret, b\'OK\')\n        tensor_number = tensor_number + 1\n\n    tensor_number = 1\n    for reference_tensor in creditcard_referencedata[:MAX_TRANSACTIONS]:\n        ret = con.execute_command(\'AI.TENSORSET\', \'referenceTensor:{0}\'.format(tensor_number),\n                                  \'FLOAT\', 1, 256,\n                                  \'BLOB\', reference_tensor.tobytes())\n        env.assertEqual(ret, b\'OK\')\n        tensor_number = tensor_number + 1\n\n    ret = con.execute_command(\'AI.MODELSET\', \'financialNet\', \'TF\', DEVICE,\n                              \'INPUTS\', \'transaction\', \'reference\', \'OUTPUTS\', \'output\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    for tensor_number in range(1, MAX_TRANSACTIONS):\n        for repetition in range(0, 10):\n            ret = con.execute_command(\'AI.MODELRUN\', \'financialNet\', \'INPUTS\',\n                                      \'transactionTensor:{}\'.format(tensor_number),\n                                      \'referenceTensor:{}\'.format(tensor_number), \'OUTPUTS\',\n                                      \'classificationTensor:{}_{}\'.format(tensor_number, repetition))\n            env.assertEqual(ret, b\'OK\')\n\n\ndef test_tensorflow_modelrun_financialNet_multiproc(env):\n    con = env.getConnection()\n\n    model_pb, creditcard_transactions, creditcard_referencedata = load_creditcardfraud_data(env)\n\n    tensor_number = 1\n    for transaction_tensor in creditcard_transactions[:MAX_TRANSACTIONS]:\n        ret = con.execute_command(\'AI.TENSORSET\', \'transactionTensor:{0}\'.format(tensor_number),\n                                  \'FLOAT\', 1, 30,\n                                  \'BLOB\', transaction_tensor.tobytes())\n        env.assertEqual(ret, b\'OK\')\n        tensor_number = tensor_number + 1\n\n    tensor_number = 1\n    for reference_tensor in creditcard_referencedata[:MAX_TRANSACTIONS]:\n        ret = con.execute_command(\'AI.TENSORSET\', \'referenceTensor:{0}\'.format(tensor_number),\n                                  \'FLOAT\', 1, 256,\n                                  \'BLOB\', reference_tensor.tobytes())\n        env.assertEqual(ret, b\'OK\')\n        tensor_number = tensor_number + 1\n\n    ret = con.execute_command(\'AI.MODELSET\', \'financialNet\', \'TF\', DEVICE,\n                              \'INPUTS\', \'transaction\', \'reference\', \'OUTPUTS\', \'output\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    def functor_financialNet(env, key_max, repetitions):\n        for tensor_number in range(1, key_max):\n            for repetition in range(1, repetitions):\n                ret = env.execute_command(\'AI.MODELRUN\', \'financialNet\', \'INPUTS\',\n                                        \'transactionTensor:{}\'.format(tensor_number),\n                                        \'referenceTensor:{}\'.format(tensor_number), \'OUTPUTS\',\n                                        \'classificationTensor:{}_{}\'.format(tensor_number, repetition))\n\n    t = time.time()\n    run_test_multiproc(env, 10,\n                       lambda env: functor_financialNet(env,MAX_TRANSACTIONS,100) )\n    elapsed_time = time.time() - t\n    total_ops = len(transaction_tensor)*100\n    avg_ops_sec = total_ops/elapsed_time\n    # env.debugPrint(""AI.MODELRUN elapsed time(sec) {:6.2f}\\tTotal ops  {:10.2f}\\tAvg. ops/sec {:10.2f}"".format(elapsed_time, total_ops, avg_ops_sec), True)\n\n\ndef test_tensorflow_modelrun_scriptrun_resnet(env):\n    if (not TEST_TF or not TEST_PT):\n        return\n    con = env.getConnection()\n    model_name = \'imagenet_model\'\n    script_name = \'imagenet_script\'\n    inputvar = \'images\'\n    outputvar = \'output\'\n\n\n    model_pb, script, labels, img = load_resnet_test_data()\n\n    ret = con.execute_command(\'AI.MODELSET\', model_name, \'TF\', DEVICE,\n                              \'INPUTS\', inputvar,\n                              \'OUTPUTS\', outputvar,\n                              \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.SCRIPTSET\', script_name, DEVICE, \'SOURCE\', script)\n    env.assertEqual(ret, b\'OK\')\n\n    image_key = \'image1\'\n    temp_key1 = \'temp_key1\'\n    temp_key2 = \'temp_key2\'\n\n    ret = con.execute_command(\'AI.TENSORSET\', image_key,\n                              \'UINT8\', img.shape[1], img.shape[0], 3,\n                              \'BLOB\', img.tobytes())\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.SCRIPTRUN\',  script_name,\n                              \'pre_process_3ch\', \'INPUTS\', image_key, \'OUTPUTS\', temp_key1 )\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.MODELRUN\', model_name,\n                              \'INPUTS\', temp_key1, \'OUTPUTS\', temp_key2 )\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.SCRIPTRUN\',  script_name,\n                              \'post_process\', \'INPUTS\', temp_key2, \'OUTPUTS\', outputvar )\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = con.execute_command(\'AI.TENSORGET\', outputvar, \'VALUES\' )\n    # tf model has 100 classes [0,999]\n    env.assertEqual(ret[0]>=0 and ret[0]<1001, True)\n'"
test/tests_tflite.py,0,"b'import redis\n\nfrom includes import *\n\n\'\'\'\npython -m RLTest --test tests_tflite.py --module path/to/redisai.so\n\'\'\'\n\n\ndef test_run_tflite_model(env):\n    if not TEST_TFLITE:\n        env.debugPrint(""skipping {} since TEST_TFLITE=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'mnist_model_quant.tflite\')\n    wrong_model_filename = os.path.join(test_data_path, \'graph.pb\')\n    sample_filename = os.path.join(test_data_path, \'one.raw\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    with open(model_filename, \'rb\') as f:\n        model_pb2 = f.read()\n\n    with open(wrong_model_filename, \'rb\') as f:\n        wrong_model_pb = f.read()\n\n    with open(sample_filename, \'rb\') as f:\n        sample_raw = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TFLITE\', \'CPU\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    env.assertEqual(len(ret), 14)\n    env.assertEqual(ret[5], b\'\')\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TFLITE\', \'CPU\', \'TAG\', \'asdf\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    env.assertEqual(len(ret), 14)\n    env.assertEqual(ret[5], b\'asdf\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 1, 1, 28, 28, \'BLOB\', sample_raw)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    ret = con.execute_command(\'AI.MODELGET\', \'m\', \'META\')\n    env.assertEqual(len(ret), 14)\n    # TODO: enable me. CI is having issues on GPU asserts of TFLITE and CPU\n    if DEVICE == ""CPU"":\n        env.assertEqual(ret[1], b\'TFLITE\')\n        env.assertEqual(ret[3], b\'CPU\')\n\n    con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'OUTPUTS\', \'b\', \'c\')\n\n    ensureSlaveSynced(con, env)\n\n    values = con.execute_command(\'AI.TENSORGET\', \'b\', \'VALUES\')\n\n    env.assertEqual(values[0], 1)\n\n\ndef test_run_tflite_model_errors(env):\n    if not TEST_TFLITE:\n        env.debugPrint(""skipping {} since TEST_TFLITE=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'mnist_model_quant.tflite\')\n    wrong_model_filename = os.path.join(test_data_path, \'graph.pb\')\n    sample_filename = os.path.join(test_data_path, \'one.raw\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    with open(model_filename, \'rb\') as f:\n        model_pb2 = f.read()\n\n    with open(wrong_model_filename, \'rb\') as f:\n        wrong_model_pb = f.read()\n\n    with open(sample_filename, \'rb\') as f:\n        sample_raw = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m_2\', \'TFLITE\', \'CPU\', \'BLOB\', model_pb2)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TFLITE\', \'CPU\', \'TAG\', \'asdf\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 1, 1, 28, 28, \'BLOB\', sample_raw)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_1\', \'TFLITE\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Insufficient arguments, missing model BLOB"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELSET\', \'m_2\', \'BLOB\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""unsupported backend"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_2\', \'INPUTS\', \'EMPTY_TENSOR\', \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""tensor key is empty"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_2\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""wrong number of arguments for \'AI.MODELRUN\' command"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'EMPTY\', \'INPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""model key is empty"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_2\', \'INPUTS\', \'a\', \'b\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""tensor key is empty"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_2\', \'a\', \'b\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""INPUTS not specified"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m_2\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""INPUTS not specified"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'OUTPUTS\', \'c\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""INPUTS not specified"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'b\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""tensor key is empty"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Inconsistent number of inputs"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'OUTPUTS\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Inconsistent number of outputs"", exception.__str__())\n\n    try:\n        con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'OUTPUTS\', \'b\')\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Inconsistent number of outputs"", exception.__str__())\n\n\n# TODO: Autobatch is tricky with TFLITE because TFLITE expects a fixed batch\n#       size. At least we should constrain MINBATCHSIZE according to the\n#       hard-coded dims in the tflite model.\ndef test_run_tflite_model_autobatch(env):\n    if not TEST_TFLITE:\n        return\n\n    con = env.getConnection()\n\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'mnist_model_quant.tflite\')\n    sample_filename = os.path.join(test_data_path, \'one.raw\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    with open(sample_filename, \'rb\') as f:\n        sample_raw = f.read()\n\n    try:\n        ret = con.execute_command(\'AI.MODELSET\', \'m\', \'TFLITE\', \'CPU\',\n                                  \'BATCHSIZE\', 2, \'MINBATCHSIZE\', 2, \'BLOB\', model_pb)\n    except Exception as e:\n        exception = e\n        env.assertEqual(type(exception), redis.exceptions.ResponseError)\n        env.assertEqual(""Auto-batching not supported by the TFLITE backend"", exception.__str__())\n\n    # env.assertEqual(ret, b\'OK\')\n\n    # con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 1, 1, 28, 28, \'BLOB\', sample_raw)\n    # con.execute_command(\'AI.TENSORSET\', \'c\', \'FLOAT\', 1, 1, 28, 28, \'BLOB\', sample_raw)\n\n    # def run():\n    #     con = env.getConnection()\n    #     con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'c\', \'OUTPUTS\', \'d\', \'d2\')\n\n    # t = threading.Thread(target=run)\n    # t.start()\n\n    # con.execute_command(\'AI.MODELRUN\', \'m\', \'INPUTS\', \'a\', \'OUTPUTS\', \'b\', \'b2\')\n\n    # values = con.execute_command(\'AI.TENSORGET\', \'b\', \'VALUES\')\n\n    # env.assertEqual(values[0], 1)\n\n    # values = con.execute_command(\'AI.TENSORGET\', \'d\', \'VALUES\')\n\n    # env.assertEqual(values[0], 1)\n\n\ndef test_tflite_modelinfo(env):\n    if not TEST_TFLITE:\n        env.debugPrint(""skipping {} since TEST_TFLITE=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    if DEVICE == ""GPU"":\n        env.debugPrint(""skipping {} since it\'s hanging CI"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'mnist_model_quant.tflite\')\n    sample_filename = os.path.join(test_data_path, \'one.raw\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    with open(sample_filename, \'rb\') as f:\n        sample_raw = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'mnist\', \'TFLITE\', \'CPU\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = con.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 1, 1, 28, 28, \'BLOB\', sample_raw)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(con, env)\n\n    previous_duration = 0\n    for call in range(1, 10):\n        ret = con.execute_command(\'AI.MODELRUN\', \'mnist\', \'INPUTS\', \'a\', \'OUTPUTS\', \'b\', \'c\')\n        env.assertEqual(ret, b\'OK\')\n        ensureSlaveSynced(con, env)\n\n        info = con.execute_command(\'AI.INFO\', \'mnist\')\n        info_dict_0 = info_to_dict(info)\n\n        env.assertEqual(info_dict_0[\'key\'], \'mnist\')\n        env.assertEqual(info_dict_0[\'type\'], \'MODEL\')\n        env.assertEqual(info_dict_0[\'backend\'], \'TFLITE\')\n        env.assertEqual(info_dict_0[\'device\'], DEVICE)\n        env.assertTrue(info_dict_0[\'duration\'] > previous_duration)\n        env.assertEqual(info_dict_0[\'samples\'], call)\n        env.assertEqual(info_dict_0[\'calls\'], call)\n        env.assertEqual(info_dict_0[\'errors\'], 0)\n\n        previous_duration = info_dict_0[\'duration\']\n\n    res = con.execute_command(\'AI.INFO\', \'mnist\', \'RESETSTAT\')\n    env.assertEqual(res, b\'OK\')\n    info = con.execute_command(\'AI.INFO\', \'mnist\')\n    info_dict_0 = info_to_dict(info)\n    env.assertEqual(info_dict_0[\'duration\'], 0)\n    env.assertEqual(info_dict_0[\'samples\'], 0)\n    env.assertEqual(info_dict_0[\'calls\'], 0)\n    env.assertEqual(info_dict_0[\'errors\'], 0)\n\n\ndef test_tflite_modelrun_disconnect(env):\n    if not TEST_TFLITE:\n        env.debugPrint(""skipping {} since TEST_TFLITE=0"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    red = env.getConnection()\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'mnist_model_quant.tflite\')\n    sample_filename = os.path.join(test_data_path, \'one.raw\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    with open(sample_filename, \'rb\') as f:\n        sample_raw = f.read()\n\n    ret = red.execute_command(\'AI.MODELSET\', \'mnist\', \'TFLITE\', \'CPU\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    ret = red.execute_command(\'AI.TENSORSET\', \'a\', \'FLOAT\', 1, 1, 28, 28, \'BLOB\', sample_raw)\n    env.assertEqual(ret, b\'OK\')\n\n    ensureSlaveSynced(red, env)\n\n    ret = send_and_disconnect((\'AI.MODELRUN\', \'mnist\', \'INPUTS\', \'a\', \'OUTPUTS\', \'b\', \'c\'), red)\n    env.assertEqual(ret, None)\n\n\ndef test_tflite_model_rdb_save_load(env):\n    env.skipOnCluster()\n    if env.useAof or not TEST_TFLITE:\n        env.debugPrint(""skipping {}"".format(sys._getframe().f_code.co_name), force=True)\n        return\n\n    con = env.getConnection()\n    test_data_path = os.path.join(os.path.dirname(__file__), \'test_data\')\n    model_filename = os.path.join(test_data_path, \'mnist_model_quant.tflite\')\n\n    with open(model_filename, \'rb\') as f:\n        model_pb = f.read()\n\n    ret = con.execute_command(\'AI.MODELSET\', \'mnist\', \'TFLITE\', \'CPU\', \'BLOB\', model_pb)\n    env.assertEqual(ret, b\'OK\')\n\n    model_serialized_memory = con.execute_command(\'AI.MODELGET\', \'mnist\', \'BLOB\')\n\n    ensureSlaveSynced(con, env)\n    ret = con.execute_command(\'SAVE\')\n    env.assertEqual(ret, True)\n\n    env.stop()\n    env.start()\n    con = env.getConnection()\n    model_serialized_after_rdbload = con.execute_command(\'AI.MODELGET\', \'mnist\', \'BLOB\')\n    env.assertEqual(len(model_serialized_memory), len(model_serialized_after_rdbload))\n    env.assertEqual(len(model_pb), len(model_serialized_after_rdbload))\n    # Assert in memory model binary is equal to loaded model binary\n    env.assertTrue(model_serialized_memory == model_serialized_after_rdbload)\n    # Assert input model binary is equal to loaded model binary\n    env.assertTrue(model_pb == model_serialized_after_rdbload)\n'"
test/test_data/onnx_batch.py,0,"b'# From https://github.com/onnx/onnx/issues/2182#issuecomment-513888258\n\nimport onnx\n\ndef change_input_dim(model):\n    sym_batch_dim = -1\n\n    inputs = model.graph.input\n    for input in inputs:\n        if ""Input"" not in input.name:\n            continue\n        dim1 = input.type.tensor_type.shape.dim[0]\n        dim1.dim_value = sym_batch_dim\n\n    nodes = model.graph.node\n    for node in nodes:\n        if node.op_type != \'Reshape\':\n            continue\n        shape_node = [el for el in node.input if \'shape\' in el][0]\n        shape = [el for el in model.graph.initializer if el.name == shape_node][0]\n        if shape.int64_data[0] == 1:\n            shape.int64_data[0] = sym_batch_dim\n\n\ndef apply(transform, infile, outfile):\n    model = onnx.load(infile)\n    transform(model)\n    onnx.save(model, outfile)\n\n\nif __name__ == \'__main__\':\n    import sys\n\n    infile = sys.argv[1]\n    outfile = sys.argv[2]\n\n    apply(change_input_dim, infile, outfile)\n\n'"
test/test_data/pt_minimal.py,0,"b'import torch\n\n\nclass MyModule(torch.jit.ScriptModule):\n    def __init__(self):\n        super(MyModule, self).__init__()\n\n    @torch.jit.script_method\n    def forward(self, a, b):\n        return a + b\n\n\nmy_script_module = MyModule()\nprint(my_script_module(torch.rand(2), torch.rand(2)))\nmy_script_module.save(""pt-minimal.pt"")\n'"
test/test_data/pt_minimal_bb.py,0,"b'import torch\n\n\nclass MyModule(torch.jit.ScriptModule):\n    def __init__(self):\n        super(MyModule, self).__init__()\n\n    @torch.jit.script_method\n    def forward(self, a, b):\n        return a + b, torch.ones(1)\n\n\nmy_script_module = MyModule()\nprint(my_script_module(torch.rand(2), torch.rand(2)))\nmy_script_module.save(""pt-minimal-bb.pt"")\n'"
test/test_data/tf-minimal.py,5,"b""import tensorflow as tf\nfrom tensorflow.python.framework.graph_util import convert_variables_to_constants\n\nwith tf.Session() as sess:\n\n    a = tf.placeholder(tf.float32, name='a')\n    b = tf.placeholder(tf.float32, name='b')\n\n    c = a * b\n\n    c = tf.identity(c, name='c')\n\n    # res = sess.run(c, feed_dict = {a: 3.0, b: 4.0})\n\n    frozen_graph = convert_variables_to_constants(sess, sess.graph_def, ['c'])\n    tf.train.write_graph(frozen_graph, './', 'graph.pb', as_text=False)\n\n"""
test/test_data/tf2-minimal.py,4,"b'import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\nimport numpy as np\n\n# From https://github.com/leimao/Frozen_Graph_TensorFlow\n\ntf.random.set_seed(seed=0)\n\nmodel = keras.Sequential(layers=[\n                             keras.layers.InputLayer(input_shape=(28, 28), name=""input""),\n                             keras.layers.Flatten(input_shape=(28, 28), name=""flatten""),\n                             keras.layers.Dense(128, activation=""relu"", name=""dense""),\n                             keras.layers.Dense(10, activation=""softmax"", name=""output"")\n                         ], name=""FCN"")\n\nmodel.compile(optimizer=""adam"",\n              loss=""sparse_categorical_crossentropy"",\n              metrics=[""accuracy""])\n\nfull_model = tf.function(lambda x: model(x))\nfull_model = full_model.get_concrete_function(\n                 tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n\nfrozen_func = convert_variables_to_constants_v2(full_model)\nfrozen_func.graph.as_graph_def()\n\ntf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n                  logdir=""."",\n                  name=""graph_v2.pb"",\n                  as_text=False)\n\n'"
opt/build/libtorch/collect.py,0,"b'#!/usr/bin/env python3\n\nimport os\nimport sys\nimport argparse\nfrom pathlib import Path\nimport shutil\nimport tarfile\n\n# this refers to deps directory inside a container\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), ""readies""))\nimport paella\n\n#----------------------------------------------------------------------------------------------\n\nPYTORCH_VERSION = \'1.2.0\'\n\nparser = argparse.ArgumentParser(description=\'Prepare RedisAI dependant distribution packages.\')\nparser.add_argument(\'--pytorch\', default=\'pytorch\', help=\'root of pytorch repository\')\nparser.add_argument(\'--pytorch-ver\', default=PYTORCH_VERSION, help=\'pytorch version\')\nparser.add_argument(\'--dest\', default=\'dest\', help=\'destination directory\')\nparser.add_argument(\'-n\', \'--nop\', action=""store_true"", help=\'no operation\')\nargs = parser.parse_args()\n\n#----------------------------------------------------------------------------------------------\n\npytorch = Path(args.pytorch).resolve()\ndest = Path(args.dest).resolve()\n\n#----------------------------------------------------------------------------------------------\n\npt_build=\'cpu\'\n\nplatform = paella.Platform()\n\npt_os = platform.os\nif pt_os == \'macosx\':\n    pt_os = \'darwin\'\n\npt_arch = platform.arch\nif pt_arch == \'x64\':\n    pt_arch = \'x86_64\'\nelif pt_arch == \'arm64v8\':\n    pt_arch = \'arm64\'\nelif pt_arch == \'arm32v7\':\n    pt_arch = \'arm\'\n\npt_ver = args.pytorch_ver\n\n#----------------------------------------------------------------------------------------------\n\ndef copy_p(src, dest):\n    f = dest/src\n    paella.mkdir_p(os.path.dirname(f))\n    shutil.copy(src, f, follow_symlinks=False)\n\ndef create_tar(name, basedir, dir=\'.\'):\n    def reset_uid(tarinfo):\n        tarinfo.uid = tarinfo.gid = 0\n        tarinfo.uname = tarinfo.gname = ""root""\n        return tarinfo\n    with cwd(basedir):\n        with tarfile.open(name, \'w:gz\') as tar:\n            tar.add(dir, filter=reset_uid)\n\ndef collect_pytorch():\n    d_pytorch = dest/\'libtorch\'\n    with cwd(pytorch/\'torch/include\'):\n        for f in Path(\'.\').glob(\'**/*.h\'):\n            copy_p(f, d_pytorch/\'include\')\n    with cwd(pytorch/\'torch/lib\'):\n        for f in Path(\'.\').glob(\'*.a\'):\n            copy_p(f, d_pytorch/\'lib\')\n        for f in Path(\'.\').glob(\'*.so*\'):\n            copy_p(f, d_pytorch/\'lib\')\n    with cwd(pytorch/\'torch\'):\n        shutil.copytree(\'share\', d_pytorch/\'share\', ignore_dangling_symlinks=True)\n    create_tar(\'libtorch-{}-{}-{}-{}.tar.gz\'.format(pt_build, pt_os, pt_arch, pt_ver), dest, \'libtorch\')\n\n#----------------------------------------------------------------------------------------------\n\ncollect_pytorch()\n'"
opt/build/tensorflow/collect.py,0,"b'#!/usr/bin/env python3\n\nimport os\nimport sys\nimport argparse\nfrom pathlib import Path\nimport shutil\nimport tarfile\n\n# this refers to deps directory inside a container\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), ""readies""))\nimport paella\n\n#----------------------------------------------------------------------------------------------\n\nTENSORFLOW_VERSION = \'1.15.0\'\n\nparser = argparse.ArgumentParser(description=\'Prepare RedisAI dependant distribution packages.\')\nparser.add_argument(\'--tensorflow\', default=\'tensorflow\', help=\'root of tensorflow repository\')\nparser.add_argument(\'--tensorflow-ver\', default=TENSORFLOW_VERSION, help=\'tensorflow version\')\nparser.add_argument(\'--dest\', default=\'dest\', help=\'destination directory\')\nparser.add_argument(\'-n\', \'--nop\', action=""store_true"", help=\'no operation\')\nargs = parser.parse_args()\n\n#----------------------------------------------------------------------------------------------\n\ntensorflow = Path(args.tensorflow).resolve()\ndest = Path(args.dest).resolve()\n\n\n#----------------------------------------------------------------------------------------------\n\ntf_build=\'cpu\'\n\nplatform = paella.Platform()\n\ntf_os = platform.os\nif tf_os == \'macosx\':\n    tf_os = \'darwin\'\n\ntf_arch = platform.arch\nif tf_arch == \'x64\':\n    tf_arch = \'x86_64\'\nelif tf_arch == \'arm64v8\':\n    tf_arch = \'arm64\'\n\ntf_ver = args.tensorflow_ver\n\n#----------------------------------------------------------------------------------------------\n\ndef copy_p(src, dest):\n    f = dest/src\n    paella.mkdir_p(os.path.dirname(f))\n    shutil.copy(src, f, follow_symlinks=False)\n\ndef create_tar(name, basedir, dir=\'.\'):\n    def reset_uid(tarinfo):\n        tarinfo.uid = tarinfo.gid = 0\n        tarinfo.uname = tarinfo.gname = ""root""\n        return tarinfo\n    with cwd(basedir):\n        with tarfile.open(name, \'w:gz\') as tar:\n            tar.add(dir, filter=reset_uid)\n\ndef collect_tensorflow():\n    d_tensorflow = dest #/\'tensorflow\'\n    with cwd(tensorflow):\n        for f in Path(\'tensorflow/c\').glob(\'**/*.h\'):\n            copy_p(f, d_tensorflow/\'include\')\n    with cwd(tensorflow/\'bazel-bin\'/\'tensorflow\'):\n        for f in Path(\'.\').glob(\'*.so*\'):\n            if str(f).endswith("".params""):\n                continue\n            copy_p(f, d_tensorflow/\'lib\')\n    create_tar(dest/f\'libtensorflow-{tf_build}-{tf_os}-{tf_arch}-{tf_ver}.tar.gz\', dest)\n\n#----------------------------------------------------------------------------------------------\n\ncollect_tensorflow()\n'"
opt/build/tflite/collect.py,0,"b'#!/usr/bin/env python3\n\nimport os\nimport sys\nimport argparse\nfrom pathlib import Path\nimport shutil\nimport tarfile\n\n# this refers to deps directory inside a container\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), ""readies""))\nimport paella\n\n#----------------------------------------------------------------------------------------------\n\nTFLITE_VERSION = \'2.0.0\'\n\nparser = argparse.ArgumentParser(description=\'Prepare RedisAI dependant distribution packages.\')\nparser.add_argument(\'--tensorflow\', default=\'tensorflow\', help=\'root of tensorflow repository\')\nparser.add_argument(\'--version\', default=TFLITE_VERSION, help=\'tensorflow version\')\nparser.add_argument(\'--dest\', default=\'dest\', help=\'destination directory\')\nparser.add_argument(\'-n\', \'--nop\', action=""store_true"", help=\'no operation\')\nargs = parser.parse_args()\n\n#----------------------------------------------------------------------------------------------\n\ntensorflow = Path(args.tensorflow).resolve()\ndest = Path(args.dest).resolve()\n\n#----------------------------------------------------------------------------------------------\n\nplatform = paella.Platform()\n\ntf_os = platform.os\ntf_os_internal = tf_os\nif tf_os == \'macosx\':\n    tf_os = \'darwin\'\n    tf_os_internal = \'osx\'\n\ntf_arch = platform.arch\nif tf_arch == \'x64\':\n    tf_arch = \'x86_64\'\nelif tf_arch == \'arm64v8\':\n    tf_arch = \'arm64\'\n\ntf_ver = args.version\n\n#----------------------------------------------------------------------------------------------\n\ndef copy_p(src, dest):\n    f = dest/src\n    paella.mkdir_p(os.path.dirname(f))\n    shutil.copy(src, f, follow_symlinks=False)\n\ndef create_tar(name, basedir, dir=\'.\'):\n    def reset_uid(tarinfo):\n        tarinfo.uid = tarinfo.gid = 0\n        tarinfo.uname = tarinfo.gname = ""root""\n        return tarinfo\n    with cwd(basedir):\n        with tarfile.open(name, \'w:gz\') as tar:\n            tar.add(dir, filter=reset_uid)\n\ndef collect_tflite():\n    d_tensorflow = dest\n    with cwd(tensorflow):\n        for f in Path(\'tensorflow/lite\').glob(\'**/*.h\'):\n            copy_p(f, d_tensorflow/\'include\')\n        with cwd(\'tensorflow/lite/tools/make\'):\n            with cwd(\'downloads/flatbuffers/include\'):\n                for f in Path(\'.\').glob(\'**/*.h\'):\n                    copy_p(f, d_tensorflow/\'include\')\n            with cwd(f\'gen/{tf_os_internal}_{tf_arch}/lib\'):\n                for f in Path(\'.\').glob(\'*.a\'):\n                    copy_p(f, d_tensorflow/\'lib\')\n    create_tar(dest/f\'libtensorflowlite-{tf_os}-{tf_arch}-{tf_ver}.tar.gz\', dest)\n\n#----------------------------------------------------------------------------------------------\n\ncollect_tflite()\n'"
test/test_data/imagenet/model_checker.py,6,"b'import tensorflow as tf\nfrom skimage import io\nimport numpy as np\nimport json\n\n\nclass_idx = json.load(open(""../../../data/imagenet_classes.json""))\n\nfilepath = \'../../../data/guitar.jpg\'\nnumpy_img = io.imread(filepath).astype(dtype=np.float32)\nnumpy_img = np.expand_dims(numpy_img, axis=0) / 255\n\n\nfrozen_graph = ""resnet50.pb""\nwith tf.gfile.GFile(frozen_graph, ""rb"") as f:\n    restored_graph_def = tf.GraphDef()\n    restored_graph_def.ParseFromString(f.read())\nwith tf.Graph().as_default() as graph:\n    tf.import_graph_def(\n        restored_graph_def,\n        input_map=None,\n        return_elements=None,\n        name="""")\nimages = graph.get_tensor_by_name(\'images:0\')\nlogits = graph.get_tensor_by_name(\'output:0\')\nwith tf.Session(graph=graph) as sess:\n    sess.run([tf.global_variables_initializer()])\n    ret = sess.run(logits, feed_dict={images: numpy_img})\n\nprint(ret.shape, ret.dtype)\nind = ret.argmax()\nprint(class_idx[str(ind.item() - 1)])\n'"
test/test_data/imagenet/model_saver.py,5,"b""import tensorflow as tf\nimport tensorflow_hub as hub\nimport ml2rt\n\nvar_converter = tf.compat.v1.graph_util.convert_variables_to_constants\nurl = 'https://tfhub.dev/google/imagenet/resnet_v2_50/classification/1'\nimages = tf.placeholder(tf.float32, shape=(1, 224, 224, 3), name='images')\nmodule = hub.Module(url)\nprint(module.get_signature_names())\nprint(module.get_output_info_dict())\nlogits = module(images)\nlogits = tf.identity(logits, 'output')\nwith tf.Session() as sess:\n    sess.run([tf.global_variables_initializer()])\n    ml2rt.save_tensorflow(sess, 'resnet50.pb', output=['output'])\n"""
