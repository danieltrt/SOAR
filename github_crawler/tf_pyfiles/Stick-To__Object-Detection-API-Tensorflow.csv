file_path,api_count,code
CenterNet.py,109,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\nimport sys\nimport os\n\n\nclass CenterNet:\n    def __init__(self, config, data_provider):\n\n        assert config['mode'] in ['train', 'test']\n        assert config['data_format'] in ['channels_first', 'channels_last']\n        self.config = config\n        self.data_provider = data_provider\n        self.input_size = config['input_size']\n        if config['data_format'] == 'channels_last':\n            self.data_shape = [self.input_size, self.input_size, 3]\n        else:\n            self.data_shape = [3, self.input_size, self.input_size]\n        self.num_classes = config['num_classes']\n        self.weight_decay = config['weight_decay']\n        self.prob = 1. - config['keep_prob']\n        self.data_format = config['data_format']\n        self.mode = config['mode']\n        self.batch_size = config['batch_size'] if config['mode'] == 'train' else 1\n\n        if self.mode == 'train':\n            self.num_train = data_provider['num_train']\n            self.num_val = data_provider['num_val']\n            self.train_generator = data_provider['train_generator']\n            self.train_initializer, self.train_iterator = self.train_generator\n            if data_provider['val_generator'] is not None:\n                self.val_generator = data_provider['val_generator']\n                self.val_initializer, self.val_iterator = self.val_generator\n        else:\n            self.score_threshold = config['score_threshold']\n            self.top_k_results_output = config['top_k_results_output']\n\n        self.global_step = tf.get_variable(name='global_step', initializer=tf.constant(0), trainable=False)\n        self.is_training = True\n\n        self._define_inputs()\n        self._build_graph()\n        self._create_saver()\n        if self.mode == 'train':\n            self._create_summary()\n        self._init_session()\n\n    def _define_inputs(self):\n        shape = [self.batch_size]\n        shape.extend(self.data_shape)\n        mean = tf.convert_to_tensor([0.485, 0.456, 0.406], dtype=tf.float32)\n        std = tf.convert_to_tensor([0.229, 0.224, 0.225], dtype=tf.float32)\n        if self.data_format == 'channels_last':\n            mean = tf.reshape(mean, [1, 1, 1, 3])\n            std = tf.reshape(std, [1, 1, 1, 3])\n        else:\n            mean = tf.reshape(mean, [1, 3, 1, 1])\n            std = tf.reshape(std, [1, 3, 1, 1])\n        if self.mode == 'train':\n            self.images, self.ground_truth = self.train_iterator.get_next()\n            self.images.set_shape(shape)\n            self.images = (self.images / 255. - mean) / std\n        else:\n            self.images = tf.placeholder(tf.float32, shape, name='images')\n            self.images = (self.images / 255. - mean) / std\n            self.ground_truth = tf.placeholder(tf.float32, [self.batch_size, None, 5], name='labels')\n        self.lr = tf.placeholder(dtype=tf.float32, shape=[], name='lr')\n\n    def _build_graph(self):\n        with tf.variable_scope('backone'):\n            conv = self._conv_bn_activation(\n                bottom=self.images,\n                filters=16,\n                kernel_size=7,\n                strides=1,\n            )\n            conv = self._conv_bn_activation(\n                bottom=conv,\n                filters=16,\n                kernel_size=3,\n                strides=1,\n            )\n            conv = self._conv_bn_activation(\n                bottom=conv,\n                filters=32,\n                kernel_size=3,\n                strides=2,\n            )\n            dla_stage3 = self._dla_generator(conv, 64, 1, self._basic_block)\n            dla_stage3 = self._max_pooling(dla_stage3, 2, 2)\n\n            dla_stage4 = self._dla_generator(dla_stage3, 128, 2, self._basic_block)\n            residual = self._conv_bn_activation(dla_stage3, 128, 1, 1)\n            residual = self._avg_pooling(residual, 2, 2)\n            dla_stage4 = self._max_pooling(dla_stage4, 2, 2)\n            dla_stage4 = dla_stage4 + residual\n\n            dla_stage5 = self._dla_generator(dla_stage4, 256, 2, self._basic_block)\n            residual = self._conv_bn_activation(dla_stage4, 256, 1, 1)\n            residual = self._avg_pooling(residual, 2, 2)\n            dla_stage5 = self._max_pooling(dla_stage5, 2, 2)\n            dla_stage5 = dla_stage5 + residual\n\n            dla_stage6 = self._dla_generator(dla_stage5, 512, 1, self._basic_block)\n            residual = self._conv_bn_activation(dla_stage5, 512, 1, 1)\n            residual = self._avg_pooling(residual, 2, 2)\n            dla_stage6 = self._max_pooling(dla_stage6, 2, 2)\n            dla_stage6 = dla_stage6 + residual\n        with tf.variable_scope('upsampling'):\n            dla_stage6 = self._conv_bn_activation(dla_stage6, 256, 1, 1)\n            dla_stage6_5 = self._dconv_bn_activation(dla_stage6, 256, 4, 2)\n            dla_stage6_4 = self._dconv_bn_activation(dla_stage6_5, 256, 4, 2)\n            dla_stage6_3 = self._dconv_bn_activation(dla_stage6_4, 256, 4, 2)\n\n            dla_stage5 = self._conv_bn_activation(dla_stage5, 256, 1, 1)\n            dla_stage5_4 = self._conv_bn_activation(dla_stage5+dla_stage6_5, 256, 3, 1)\n            dla_stage5_4 = self._dconv_bn_activation(dla_stage5_4, 256, 4, 2)\n            dla_stage5_3 = self._dconv_bn_activation(dla_stage5_4, 256, 4, 2)\n\n            dla_stage4 = self._conv_bn_activation(dla_stage4, 256, 1, 1)\n            dla_stage4_3 = self._conv_bn_activation(dla_stage4+dla_stage5_4+dla_stage6_4, 256, 3, 1)\n            dla_stage4_3 = self._dconv_bn_activation(dla_stage4_3, 256, 4, 2)\n\n            features = self._conv_bn_activation(dla_stage6_3+dla_stage5_3+dla_stage4_3, 256, 3, 1)\n            features = self._conv_bn_activation(features, 256, 1, 1)\n            stride = 4.0\n\n        with tf.variable_scope('center_detector'):\n            keypoints = self._conv_bn_activation(features, self.num_classes, 3, 1, None)\n            offset = self._conv_bn_activation(features, 2, 3, 1, None)\n            size = self._conv_bn_activation(features, 2, 3, 1, None)\n            if self.data_format == 'channels_first':\n                keypoints = tf.transpose(keypoints, [0, 2, 3, 1])\n                offset = tf.transpose(offset, [0, 2, 3, 1])\n                size = tf.transpose(size, [0, 2, 3, 1])\n            pshape = [tf.shape(offset)[1], tf.shape(offset)[2]]\n\n            h = tf.range(0., tf.cast(pshape[0], tf.float32), dtype=tf.float32)\n            w = tf.range(0., tf.cast(pshape[1], tf.float32), dtype=tf.float32)\n            [meshgrid_x, meshgrid_y] = tf.meshgrid(w, h)\n            if self.mode == 'train':\n                total_loss = []\n                for i in range(self.batch_size):\n                    loss = self._compute_one_image_loss(keypoints[i, ...], offset[i, ...], size[i, ...],\n                                                        self.ground_truth[i, ...], meshgrid_y, meshgrid_x,\n                                                        stride, pshape)\n                    total_loss.append(loss)\n\n                self.loss = tf.reduce_mean(total_loss) + self.weight_decay * tf.add_n(\n                    [tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n                optimizer = tf.train.AdamOptimizer(self.lr)\n                update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n                train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n                self.train_op = tf.group([update_ops, train_op])\n            else:\n                keypoints = tf.sigmoid(keypoints)\n                meshgrid_y = tf.expand_dims(meshgrid_y, axis=-1)\n                meshgrid_x = tf.expand_dims(meshgrid_x, axis=-1)\n                center = tf.concat([meshgrid_y, meshgrid_x], axis=-1)\n                category = tf.expand_dims(tf.squeeze(tf.argmax(keypoints, axis=-1, output_type=tf.int32)), axis=-1)\n                meshgrid_xyz = tf.concat([tf.zeros_like(category), tf.cast(center, tf.int32), category], axis=-1)\n                keypoints = tf.gather_nd(keypoints, meshgrid_xyz)\n                keypoints = tf.expand_dims(keypoints, axis=0)\n                keypoints = tf.expand_dims(keypoints, axis=-1)\n                keypoints_peak = self._max_pooling(keypoints, 3, 1)\n                keypoints_mask = tf.cast(tf.equal(keypoints, keypoints_peak), tf.float32)\n                keypoints = keypoints * keypoints_mask\n                scores = tf.reshape(keypoints, [-1])\n                class_id = tf.reshape(category, [-1])\n                bbox_yx = tf.reshape(center+offset, [-1, 2])\n                bbox_hw = tf.reshape(size, [-1, 2])\n                score_mask = scores > self.score_threshold\n                scores = tf.boolean_mask(scores, score_mask)\n                class_id = tf.boolean_mask(class_id, score_mask)\n                bbox_yx = tf.boolean_mask(bbox_yx, score_mask)\n                bbox_hw = tf.boolean_mask(bbox_hw, score_mask)\n                bbox = tf.concat([bbox_yx-bbox_hw/2., bbox_yx+bbox_hw/2.], axis=-1) * stride\n                num_select = tf.cond(tf.shape(scores)[0] > self.top_k_results_output, lambda: self.top_k_results_output, lambda: tf.shape(scores)[0])\n                select_scores, select_indices = tf.nn.top_k(scores, num_select)\n                select_class_id = tf.gather(class_id, select_indices)\n                select_bbox = tf.gather(bbox, select_indices)\n                self.detection_pred = [select_scores, select_bbox, select_class_id]\n\n    def _compute_one_image_loss(self, keypoints, offset, size, ground_truth, meshgrid_y, meshgrid_x,\n                                stride, pshape):\n        slice_index = tf.argmin(ground_truth, axis=0)[0]\n        ground_truth = tf.gather(ground_truth, tf.range(0, slice_index, dtype=tf.int64))\n        ngbbox_y = ground_truth[..., 0] / stride\n        ngbbox_x = ground_truth[..., 1] / stride\n        ngbbox_h = ground_truth[..., 2] / stride\n        ngbbox_w = ground_truth[..., 3] / stride\n        class_id = tf.cast(ground_truth[..., 4], dtype=tf.int32)\n        ngbbox_yx = ground_truth[..., 0:2] / stride\n        ngbbox_yx_round = tf.floor(ngbbox_yx)\n        offset_gt = ngbbox_yx - ngbbox_yx_round\n        size_gt = ground_truth[..., 2:4] / stride\n        ngbbox_yx_round_int = tf.cast(ngbbox_yx_round, tf.int64)\n        keypoints_loss = self._keypoints_loss(keypoints, ngbbox_yx_round_int, ngbbox_y, ngbbox_x, ngbbox_h,\n                                              ngbbox_w, class_id, meshgrid_y, meshgrid_x, pshape)\n\n        offset = tf.gather_nd(offset, ngbbox_yx_round_int)\n        size = tf.gather_nd(size, ngbbox_yx_round_int)\n        offset_loss = tf.reduce_mean(tf.abs(offset_gt - offset))\n        size_loss = tf.reduce_mean(tf.abs(size_gt - size))\n        total_loss = keypoints_loss + 0.1*size_loss + offset_loss\n        return total_loss\n\n    def _keypoints_loss(self, keypoints, gbbox_yx, gbbox_y, gbbox_x, gbbox_h, gbbox_w,\n                        classid, meshgrid_y, meshgrid_x, pshape):\n        sigma = self._gaussian_radius(gbbox_h, gbbox_w, 0.7)\n        gbbox_y = tf.reshape(gbbox_y, [-1, 1, 1])\n        gbbox_x = tf.reshape(gbbox_x, [-1, 1, 1])\n        sigma = tf.reshape(sigma, [-1, 1, 1])\n\n        num_g = tf.shape(gbbox_y)[0]\n        meshgrid_y = tf.expand_dims(meshgrid_y, 0)\n        meshgrid_y = tf.tile(meshgrid_y, [num_g, 1, 1])\n        meshgrid_x = tf.expand_dims(meshgrid_x, 0)\n        meshgrid_x = tf.tile(meshgrid_x, [num_g, 1, 1])\n\n        keyp_penalty_reduce = tf.exp(-((gbbox_y-meshgrid_y)**2 + (gbbox_x-meshgrid_x)**2)/(2*sigma**2))\n        zero_like_keyp = tf.expand_dims(tf.zeros(pshape, dtype=tf.float32), axis=-1)\n        reduction = []\n        gt_keypoints = []\n        for i in range(self.num_classes):\n            exist_i = tf.equal(classid, i)\n            reduce_i = tf.boolean_mask(keyp_penalty_reduce, exist_i, axis=0)\n            reduce_i = tf.cond(\n                tf.equal(tf.shape(reduce_i)[0], 0),\n                lambda: zero_like_keyp,\n                lambda: tf.expand_dims(tf.reduce_max(reduce_i, axis=0), axis=-1)\n            )\n            reduction.append(reduce_i)\n\n            gbbox_yx_i = tf.boolean_mask(gbbox_yx, exist_i)\n            gt_keypoints_i = tf.cond(\n                tf.equal(tf.shape(gbbox_yx_i)[0], 0),\n                lambda: zero_like_keyp,\n                lambda: tf.expand_dims(tf.sparse.to_dense(tf.sparse.SparseTensor(gbbox_yx_i, tf.ones_like(gbbox_yx_i[..., 0], tf.float32), dense_shape=pshape), validate_indices=False),\n                                       axis=-1)\n            )\n            gt_keypoints.append(gt_keypoints_i)\n        reduction = tf.concat(reduction, axis=-1)\n        gt_keypoints = tf.concat(gt_keypoints, axis=-1)\n        keypoints_pos_loss = -tf.pow(1.-tf.sigmoid(keypoints), 2.) * tf.log_sigmoid(keypoints) * gt_keypoints\n        keypoints_neg_loss = -tf.pow(1.-reduction, 4) * tf.pow(tf.sigmoid(keypoints), 2.) * (-keypoints+tf.log_sigmoid(keypoints)) * (1.-gt_keypoints)\n        keypoints_loss = tf.reduce_sum(keypoints_pos_loss) / tf.cast(num_g, tf.float32) + tf.reduce_sum(keypoints_neg_loss) / tf.cast(num_g, tf.float32)\n        return keypoints_loss\n\n    # from cornernet\n    def _gaussian_radius(self, height, width, min_overlap=0.7):\n        a1 = 1.\n        b1 = (height + width)\n        c1 = width * height * (1. - min_overlap) / (1. + min_overlap)\n        sq1 = tf.sqrt(b1 ** 2. - 4. * a1 * c1)\n        r1 = (b1 + sq1) / 2.\n        a2 = 4.\n        b2 = 2. * (height + width)\n        c2 = (1. - min_overlap) * width * height\n        sq2 = tf.sqrt(b2 ** 2. - 4. * a2 * c2)\n        r2 = (b2 + sq2) / 2.\n        a3 = 4. * min_overlap\n        b3 = -2. * min_overlap * (height + width)\n        c3 = (min_overlap - 1.) * width * height\n        sq3 = tf.sqrt(b3 ** 2. - 4. * a3 * c3)\n        r3 = (b3 + sq3) / 2.\n        return tf.reduce_min([r1, r2, r3])\n\n    def _init_session(self):\n        self.sess = tf.InteractiveSession()\n        self.sess.run(tf.global_variables_initializer())\n        if self.mode == 'train':\n            self.sess.run(self.train_initializer)\n\n    def _create_saver(self):\n        weights = tf.trainable_variables('backone')\n        self.pretrained_saver = tf.train.Saver(weights)\n        self.saver = tf.train.Saver()\n        self.best_saver = tf.train.Saver()\n\n    def _create_summary(self):\n        with tf.variable_scope('summaries'):\n            tf.summary.scalar('loss', self.loss)\n            self.summary_op = tf.summary.merge_all()\n\n    def train_one_epoch(self, lr):\n        self.is_training = True\n        self.sess.run(self.train_initializer)\n        mean_loss = []\n        num_iters = self.num_train // self.batch_size\n        for i in range(num_iters):\n            _, loss = self.sess.run([self.train_op, self.loss], feed_dict={self.lr: lr})\n            sys.stdout.write('\\r>> ' + 'iters '+str(i+1)+str('/')+str(num_iters)+' loss '+str(loss))\n            sys.stdout.flush()\n            mean_loss.append(loss)\n        sys.stdout.write('\\n')\n        mean_loss = np.mean(mean_loss)\n        return mean_loss\n\n    def test_one_image(self, images):\n        self.is_training = False\n        pred = self.sess.run(self.detection_pred, feed_dict={self.images: images})\n        return pred\n\n    def save_weight(self, mode, path):\n        assert (mode in ['latest', 'best'])\n        if mode == 'latest':\n            saver = self.saver\n        else:\n            saver = self.best_saver\n        if not tf.gfile.Exists(os.path.dirname(path)):\n            tf.gfile.MakeDirs(os.path.dirname(path))\n            print(os.path.dirname(path), 'does not exist, create it done')\n        saver.save(self.sess, path, global_step=self.global_step)\n        print('save', mode, 'model in', path, 'successfully')\n\n    def load_weight(self, path):\n        self.saver.restore(self.sess, path)\n        print('load weight', path, 'successfully')\n\n    def load_pretrained_weight(self, path):\n        self.pretrained_saver.restore(self.sess, path)\n        print('load pretrained weight', path, 'successfully')\n\n    def _bn(self, bottom):\n        bn = tf.layers.batch_normalization(\n            inputs=bottom,\n            axis=3 if self.data_format == 'channels_last' else 1,\n            training=self.is_training\n        )\n        return bn\n\n    def _conv_bn_activation(self, bottom, filters, kernel_size, strides, activation=tf.nn.relu):\n        conv = tf.layers.conv2d(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format\n        )\n        bn = self._bn(conv)\n        if activation is not None:\n            return activation(bn)\n        else:\n            return bn\n\n    def _dconv_bn_activation(self, bottom, filters, kernel_size, strides, activation=tf.nn.relu):\n        conv = tf.layers.conv2d_transpose(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n        )\n        bn = self._bn(conv)\n        if activation is not None:\n            bn = activation(bn)\n        return bn\n\n    def _separable_conv_layer(self, bottom, filters, kernel_size, strides, activation=tf.nn.relu):\n        conv = tf.layers.separable_conv2d(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            use_bias=False,\n        )\n        bn = self._bn(conv)\n        if activation is not None:\n            bn = activation(bn)\n        return bn\n\n    def _basic_block(self, bottom, filters):\n        conv = self._conv_bn_activation(bottom, filters, 3, 1)\n        conv = self._conv_bn_activation(conv, filters, 3, 1)\n        axis = 3 if self.data_format == 'channels_last' else 1\n        input_channels = tf.shape(bottom)[axis]\n        shutcut = tf.cond(\n            tf.equal(input_channels, filters),\n            lambda: bottom,\n            lambda: self._conv_bn_activation(bottom, filters, 1, 1)\n        )\n        return conv + shutcut\n\n    def _dla_generator(self, bottom, filters, levels, stack_block_fn):\n        if levels == 1:\n            block1 = stack_block_fn(bottom, filters)\n            block2 = stack_block_fn(block1, filters)\n            aggregation = block1 + block2\n            aggregation = self._conv_bn_activation(aggregation, filters, 3, 1)\n        else:\n            block1 = self._dla_generator(bottom, filters, levels-1, stack_block_fn)\n            block2 = self._dla_generator(block1, filters, levels-1, stack_block_fn)\n            aggregation = block1 + block2\n            aggregation = self._conv_bn_activation(aggregation, filters, 3, 1)\n        return aggregation\n\n    def _max_pooling(self, bottom, pool_size, strides, name=None):\n        return tf.layers.max_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _avg_pooling(self, bottom, pool_size, strides, name=None):\n        return tf.layers.average_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _dropout(self, bottom, name):\n        return tf.layers.dropout(\n            inputs=bottom,\n            rate=self.prob,\n            training=self.is_training,\n            name=name\n        )\n"""
FCOS.py,180,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\nimport sys\nimport os\nimport math\n\n\nclass FCOS:\n    def __init__(self, config, data_provider):\n\n        assert config['mode'] in ['train', 'test']\n        assert config['data_format'] in ['channels_first', 'channels_last']\n        self.config = config\n        self.data_provider = data_provider\n        self.data_shape = config['data_shape']\n        self.num_classes = config['num_classes']\n        self.weight_decay = config['weight_decay']\n        self.prob = 1. - config['keep_prob']\n        self.data_format = config['data_format']\n        self.mode = config['mode']\n        self.batch_size = config['batch_size'] if config['mode'] == 'train' else 1\n        self.nms_score_threshold = config['nms_score_threshold']\n        self.nms_max_boxes = config['nms_max_boxes']\n        self.nms_iou_threshold = config['nms_iou_threshold']\n\n        self.is_bottleneck = True,\n        self.block_list = [3, 4, 6, 3]     # must len 4\n        self.filters_list = [16 * (2 ** i) for i in range(len(self.block_list))]\n\n        if self.mode == 'train':\n            self.num_train = data_provider['num_train']\n            self.num_val = data_provider['num_val']\n            self.train_generator = data_provider['train_generator']\n            self.train_initializer, self.train_iterator = self.train_generator\n            if data_provider['val_generator'] is not None:\n                self.val_generator = data_provider['val_generator']\n                self.val_initializer, self.val_iterator = self.val_generator\n\n        self.global_step = tf.get_variable(name='global_step', initializer=tf.constant(0), trainable=False)\n        self.is_training = True\n\n        self._define_inputs()\n        self._build_graph()\n        self._create_saver()\n        if self.mode == 'train':\n            self._create_summary()\n        self._init_session()\n\n    def _define_inputs(self):\n        shape = [self.batch_size]\n        shape.extend(self.data_shape)\n        mean = tf.convert_to_tensor([123.68, 116.779, 103.979], dtype=tf.float32)\n        if self.data_format == 'channels_last':\n            mean = tf.reshape(mean, [1, 1, 1, 3])\n        else:\n            mean = tf.reshape(mean, [1, 3, 1, 1])\n        if self.mode == 'train':\n            self.images, self.ground_truth = self.train_iterator.get_next()\n            self.images.set_shape(shape)\n            self.images = self.images - mean\n        else:\n            self.images = tf.placeholder(tf.float32, shape, name='images')\n            self.images = self.images - mean\n            self.ground_truth = tf.placeholder(tf.float32, [self.batch_size, None, 5], name='labels')\n        self.lr = tf.placeholder(dtype=tf.float32, shape=[], name='lr')\n\n    def _build_graph(self):\n        with tf.variable_scope('backone'):\n            endpoints = []\n            conv1_1 = self._conv_bn_activation(\n                bottom=self.images,\n                filters=16,\n                kernel_size=7,\n                strides=2,\n            )\n            pool1 = self._max_pooling(\n                bottom=conv1_1,\n                pool_size=3,\n                strides=2,\n                name='pool1'\n            )\n            if self.is_bottleneck:\n                stack_residual_unit_fn = self._residual_bottleneck\n            else:\n                stack_residual_unit_fn = self._residual_block\n            residual_block = pool1\n            for i in range(self.block_list[0]):\n                residual_block = stack_residual_unit_fn(residual_block, self.filters_list[0], 1, 'block1_unit' + str(i + 1))\n            endpoints.append(residual_block)\n            for i in range(1, len(self.block_list)):\n                residual_block = stack_residual_unit_fn(residual_block, self.filters_list[i], 2, 'block' + str(i + 1) + '_unit' + str(1))\n                for j in range(1, self.block_list[i]):\n                    residual_block = stack_residual_unit_fn(residual_block, self.filters_list[i], 1, 'block' + str(i + 1) + '_unit' + str(j + 1))\n                endpoints.append(residual_block)\n\n        with tf.variable_scope('pyramid'):\n            c3 = self._bn_activation_conv(endpoints[-3], 256, 1, 1)\n            c4 = self._bn_activation_conv(endpoints[-2], 256, 1, 1)\n            c5 = self._bn_activation_conv(endpoints[-1], 256, 1, 1)\n            p5 = self._get_pyramid(c5, 256)\n            p4, top_down = self._get_pyramid(c4, 256, p5)\n            p3, _ = self._get_pyramid(c3, 256, top_down)\n            p6 = self._bn_activation_conv(p5, 256, 3, 2)\n            p7 = self._bn_activation_conv(p6, 256, 3, 2)\n        with tf.variable_scope('head'):\n            p3conf, p3reg, p3center = self._detect_head(p3)\n            p4conf, p4reg, p4center = self._detect_head(p4)\n            p5conf, p5reg, p5center = self._detect_head(p5)\n            p6conf, p6reg, p6center = self._detect_head(p6)\n            p7conf, p7reg, p7center = self._detect_head(p7)\n            if self.data_format == 'channels_first':\n                p3conf = tf.transpose(p3conf, [0, 2, 3, 1])\n                p3reg = tf.transpose(p3reg, [0, 2, 3, 1])\n                p3center = tf.transpose(p3center, [0, 2, 3, 1])\n                p4conf = tf.transpose(p4conf, [0, 2, 3, 1])\n                p4reg = tf.transpose(p4reg, [0, 2, 3, 1])\n                p4center = tf.transpose(p4center, [0, 2, 3, 1])\n                p5conf = tf.transpose(p5conf, [0, 2, 3, 1])\n                p5reg = tf.transpose(p5reg, [0, 2, 3, 1])\n                p5center = tf.transpose(p5center, [0, 2, 3, 1])\n                p6conf = tf.transpose(p6conf, [0, 2, 3, 1])\n                p6reg = tf.transpose(p6reg, [0, 2, 3, 1])\n                p6center = tf.transpose(p6center, [0, 2, 3, 1])\n                p7conf = tf.transpose(p7conf, [0, 2, 3, 1])\n                p7reg = tf.transpose(p7reg, [0, 2, 3, 1])\n                p7center = tf.transpose(p7center, [0, 2, 3, 1])\n            s3, s4, s5, s6, s7 = 8, 16, 32, 64, 128\n            p3shape = [tf.shape(p3center)[1], tf.shape(p3center)[2]]\n            p4shape = [tf.shape(p4center)[1], tf.shape(p4center)[2]]\n            p5shape = [tf.shape(p5center)[1], tf.shape(p5center)[2]]\n            p6shape = [tf.shape(p6center)[1], tf.shape(p6center)[2]]\n            p7shape = [tf.shape(p7center)[1], tf.shape(p7center)[2]]\n            h3 = tf.range(0., tf.cast(p3shape[0], tf.float32), dtype=tf.float32)\n            w3 = tf.range(0., tf.cast(p3shape[1], tf.float32), dtype=tf.float32)\n            h4 = tf.range(0., tf.cast(p4shape[0], tf.float32), dtype=tf.float32)\n            w4 = tf.range(0., tf.cast(p4shape[1], tf.float32), dtype=tf.float32)\n            h5 = tf.range(0., tf.cast(p5shape[0], tf.float32), dtype=tf.float32)\n            w5 = tf.range(0., tf.cast(p5shape[1], tf.float32), dtype=tf.float32)\n            h6 = tf.range(0., tf.cast(p6shape[0], tf.float32), dtype=tf.float32)\n            w6 = tf.range(0., tf.cast(p6shape[1], tf.float32), dtype=tf.float32)\n            h7 = tf.range(0., tf.cast(p7shape[0], tf.float32), dtype=tf.float32)\n            w7 = tf.range(0., tf.cast(p7shape[1], tf.float32), dtype=tf.float32)\n            [grid_x3, grid_y3] = tf.meshgrid(w3, h3)\n            [grid_x4, grid_y4] = tf.meshgrid(w4, h4)\n            [grid_x5, grid_y5] = tf.meshgrid(w5, h5)\n            [grid_x6, grid_y6] = tf.meshgrid(w6, h6)\n            [grid_x7, grid_y7] = tf.meshgrid(w7, h7)\n\n            if self.mode == 'train':\n                total_loss = []\n                for i in range(self.batch_size):\n                    gt_i = self.ground_truth[i, ...]\n                    slice_index = tf.argmin(gt_i, axis=0)[0]\n                    gt_i = tf.gather(gt_i, tf.range(0, slice_index, dtype=tf.int64))\n                    gt_size = tf.sqrt(gt_i[..., 2] * gt_i[..., 3])\n                    g3 = tf.boolean_mask(gt_i, gt_size <= 64.)\n                    g4 = tf.boolean_mask(gt_i, tf.cast(gt_size >= 64., tf.float32)*tf.cast(gt_size <= 128., tf.float32) > 0.)\n                    g5 = tf.boolean_mask(gt_i, tf.cast(gt_size >= 128., tf.float32)*tf.cast(gt_size <= 256., tf.float32) > 0.)\n                    g6 = tf.boolean_mask(gt_i, tf.cast(gt_size >= 256., tf.float32)*tf.cast(gt_size <= 512., tf.float32) > 0.)\n                    g7 = tf.boolean_mask(gt_i, gt_size >= 512.)\n                    loss3 = tf.cond(\n                        tf.shape(g3)[0] > 0,\n                        lambda: self._compute_one_image_loss(p3conf[i, ...], p3reg[i, ...], p3center[i, ...], g3, grid_y3, grid_x3, s3, p3shape),\n                        lambda: 0.\n                    )\n                    loss4 = tf.cond(\n                        tf.shape(g4)[0] > 0,\n                        lambda: self._compute_one_image_loss(p4conf[i, ...], p4reg[i, ...], p4center[i, ...], g4, grid_y4, grid_x4, s4, p4shape),\n                        lambda: 0.\n                    )\n                    loss5 = tf.cond(\n                        tf.shape(g5)[0] > 0,\n                        lambda: self._compute_one_image_loss(p5conf[i, ...], p5reg[i, ...], p5center[i, ...], g5, grid_y5, grid_x5, s5, p5shape),\n                        lambda: 0.\n                    )\n                    loss6 = tf.cond(\n                        tf.shape(g6)[0] > 0,\n                        lambda: self._compute_one_image_loss(p6conf[i, ...], p6reg[i, ...], p6center[i, ...], g6, grid_y6, grid_x6, s6, p6shape),\n                        lambda: 0.\n                    )\n                    loss7 = tf.cond(\n                        tf.shape(g7)[0] > 0,\n                        lambda: self._compute_one_image_loss(p7conf[i, ...], p7reg[i, ...], p7center[i, ...], g7, grid_y7, grid_x7, s7, p7shape),\n                        lambda: 0.\n                    )\n                    total_loss.append(loss3 + loss4 + loss5 + loss6 + loss7)\n                self.loss = tf.reduce_mean(total_loss) + self.weight_decay * tf.add_n(\n                            [tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n                optimizer = tf.train.MomentumOptimizer(self.lr, momentum=0.9)\n                update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n                train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n                self.train_op = tf.group([update_ops, train_op])\n            else:\n                p3conf = tf.reshape(tf.sigmoid(p3conf[0, ...])*tf.sigmoid(p3center[0, ...]), [-1, self.num_classes])\n                p4conf = tf.reshape(tf.sigmoid(p4conf[0, ...])*tf.sigmoid(p4center[0, ...]), [-1, self.num_classes])\n                p5conf = tf.reshape(tf.sigmoid(p5conf[0, ...])*tf.sigmoid(p5center[0, ...]), [-1, self.num_classes])\n                p6conf = tf.reshape(tf.sigmoid(p6conf[0, ...])*tf.sigmoid(p6center[0, ...]), [-1, self.num_classes])\n                p7conf = tf.reshape(tf.sigmoid(p7conf[0, ...])*tf.sigmoid(p7center[0, ...]), [-1, self.num_classes])\n                pconf = tf.concat([p3conf, p4conf, p5conf, p6conf, p7conf], axis=0)\n\n                p3reg = p3reg[0, ...]\n                p4reg = p4reg[0, ...]\n                p5reg = p5reg[0, ...]\n                p6reg = p6reg[0, ...]\n                p7reg = p7reg[0, ...]\n                grid_y3 = tf.expand_dims(grid_y3, axis=-1)\n                grid_x3 = tf.expand_dims(grid_x3, axis=-1)\n                grid_y4 = tf.expand_dims(grid_y4, axis=-1)\n                grid_x4 = tf.expand_dims(grid_x4, axis=-1)\n                grid_y5 = tf.expand_dims(grid_y5, axis=-1)\n                grid_x5 = tf.expand_dims(grid_x5, axis=-1)\n                grid_y6 = tf.expand_dims(grid_y6, axis=-1)\n                grid_x6 = tf.expand_dims(grid_x6, axis=-1)\n                grid_y7 = tf.expand_dims(grid_y7, axis=-1)\n                grid_x7 = tf.expand_dims(grid_x7, axis=-1)\n\n                p3_y1 = grid_y3 - p3reg[..., 2:3]\n                p3_y2 = grid_y3 + p3reg[..., 3:4]\n                p3_x1 = grid_x3 - p3reg[..., 0:1]\n                p3_x2 = grid_x3 + p3reg[..., 1:2]\n                p4_y1 = grid_y4 - p4reg[..., 2:3]\n                p4_y2 = grid_y4 + p4reg[..., 3:4]\n                p4_x1 = grid_x4 - p4reg[..., 0:1]\n                p4_x2 = grid_x4 + p4reg[..., 1:2]\n                p5_y1 = grid_y5 - p5reg[..., 2:3]\n                p5_y2 = grid_y5 + p5reg[..., 3:4]\n                p5_x1 = grid_x5 - p5reg[..., 0:1]\n                p5_x2 = grid_x5 + p5reg[..., 1:2]\n                p6_y1 = grid_y6 - p6reg[..., 2:3]\n                p6_y2 = grid_y6 + p6reg[..., 3:4]\n                p6_x1 = grid_x6 - p6reg[..., 0:1]\n                p6_x2 = grid_x6 + p6reg[..., 1:2]\n                p7_y1 = grid_y7 - p7reg[..., 2:3]\n                p7_y2 = grid_y7 + p7reg[..., 3:4]\n                p7_x1 = grid_x7 - p7reg[..., 0:1]\n                p7_x2 = grid_x7 + p7reg[..., 1:2]\n\n                p3bbox = tf.reshape(tf.concat([p3_y1, p3_x1, p3_y2, p3_x2], axis=-1), [-1, 4]) * s3\n                p4bbox = tf.reshape(tf.concat([p4_y1, p4_x1, p4_y2, p4_x2], axis=-1), [-1, 4]) * s4\n                p5bbox = tf.reshape(tf.concat([p5_y1, p5_x1, p5_y2, p5_x2], axis=-1), [-1, 4]) * s5\n                p6bbox = tf.reshape(tf.concat([p6_y1, p6_x1, p6_y2, p6_x2], axis=-1), [-1, 4]) * s6\n                p7bbox = tf.reshape(tf.concat([p7_y1, p7_x1, p7_y2, p7_x2], axis=-1), [-1, 4]) * s7\n                pbbox = tf.concat([p3bbox, p4bbox, p5bbox, p6bbox, p7bbox], axis=0)\n\n                filter_mask = tf.greater_equal(pconf, self.nms_score_threshold)\n                scores = []\n                class_id = []\n                bbox = []\n                for i in range(self.num_classes - 1):\n                    scoresi = tf.boolean_mask(pconf[:, i], filter_mask[:, i])\n                    bboxi = tf.boolean_mask(pbbox, filter_mask[:, i])\n                    selected_indices = tf.image.non_max_suppression(\n                        bboxi, scoresi, self.nms_max_boxes, self.nms_iou_threshold,\n                    )\n                    scores.append(tf.gather(scoresi, selected_indices))\n                    bbox.append(tf.gather(bboxi, selected_indices))\n                    class_id.append(tf.ones_like(tf.gather(scoresi, selected_indices), tf.int32) * i)\n                bbox = tf.concat(bbox, axis=0)\n                scores = tf.concat(scores, axis=0)\n                class_id = tf.concat(class_id, axis=0)\n                self.detection_pred = [scores, bbox, class_id]\n\n    def _compute_one_image_loss(self, heatmap_pred, dist_pred, center_pred, ground_truth, grid_y, grid_x,\n                                stride, pshape):\n        gbbox_y = ground_truth[..., 0] / stride\n        gbbox_x = ground_truth[..., 1] / stride\n        gbbox_h = ground_truth[..., 2] / stride\n        gbbox_w = ground_truth[..., 3] / stride\n        class_id = tf.cast(ground_truth[..., 4], dtype=tf.int32)\n        gbbox_y1 = gbbox_y - gbbox_h/2.\n        gbbox_y2 = gbbox_y + gbbox_h/2.\n        gbbox_x1 = gbbox_x - gbbox_w/2.\n        gbbox_x2 = gbbox_x + gbbox_w/2.\n\n        gbbox_y1 = tf.reshape(gbbox_y1, [1, 1, -1])\n        gbbox_x1 = tf.reshape(gbbox_x1, [1, 1, -1])\n        gbbox_y2 = tf.reshape(gbbox_y2, [1, 1, -1])\n        gbbox_x2 = tf.reshape(gbbox_x2, [1, 1, -1])\n        num_g = tf.shape(gbbox_y1)[-1]\n        grid_y = tf.expand_dims(grid_y, -1)\n        grid_x = tf.expand_dims(grid_x, -1)\n        grid_y = tf.tile(grid_y, [1, 1, num_g])\n        grid_x = tf.tile(grid_x, [1, 1, num_g])\n        dist_l = grid_x - gbbox_x1\n        dist_r = gbbox_x2 - grid_x\n        dist_t = grid_y - gbbox_y1\n        dist_b = gbbox_y2 - grid_y\n        grid_y_mask = tf.cast(dist_t > 0., tf.float32) * tf.cast(dist_b > 0., tf.float32)\n        grid_x_mask = tf.cast(dist_l > 0., tf.float32) * tf.cast(dist_r > 0., tf.float32)\n        heatmask = grid_y_mask * grid_x_mask\n        dist_l *= heatmask\n        dist_r *= heatmask\n        dist_t *= heatmask\n        dist_b *= heatmask\n        loc = tf.reduce_max(heatmask, axis=-1)\n        dist_area = (dist_l + dist_r) * (dist_t + dist_b)\n        dist_area_ = dist_area + (1. - heatmask) * 1e8\n        dist_area_min = tf.reduce_min(dist_area_, axis=-1, keepdims=True)\n        dist_mask = tf.cast(tf.equal(dist_area, dist_area_min), tf.float32) * tf.expand_dims(loc, axis=-1)\n        dist_l *= dist_mask\n        dist_r *= dist_mask\n        dist_t *= dist_mask\n        dist_b *= dist_mask\n        dist_l = tf.reduce_max(dist_l, axis=-1)\n        dist_r = tf.reduce_max(dist_r, axis=-1)\n        dist_t = tf.reduce_max(dist_t, axis=-1)\n        dist_b = tf.reduce_max(dist_b, axis=-1)\n        dist_pred_l = dist_pred[..., 0]\n        dist_pred_r = dist_pred[..., 1]\n        dist_pred_t = dist_pred[..., 2]\n        dist_pred_b = dist_pred[..., 3]\n        inter_width = tf.minimum(dist_l, dist_pred_l) + tf.minimum(dist_r, dist_pred_r)\n        inter_height = tf.minimum(dist_t, dist_pred_t) + tf.minimum(dist_b, dist_pred_b)\n        inter_area = inter_width * inter_height\n        union_area = (dist_l+dist_r)*(dist_t+dist_b) + (dist_pred_l+dist_pred_r)*(dist_pred_t+dist_pred_b) - inter_area\n        iou = inter_area / (union_area+1e-12)\n        iou_loss = tf.reduce_sum(-tf.log(iou+1e-12)*loc)\n\n        lr_min = tf.minimum(dist_l, dist_r)\n        tb_min = tf.minimum(dist_t, dist_b)\n        lr_max = tf.maximum(dist_l, dist_r)\n        tb_max = tf.maximum(dist_t, dist_b)\n        center_pred = tf.squeeze(center_pred)\n        center_gt = tf.sqrt(lr_min*tb_min/(lr_max*tb_max+1e-12))\n        # center_loss = tf.square(center_pred - center_gt)\n        center_loss = tf.keras.backend.binary_crossentropy(output=center_pred, target=center_gt, from_logits=True)\n        center_loss = tf.reduce_sum(center_loss)\n\n        zero_like_heat = tf.expand_dims(tf.zeros(pshape, dtype=tf.float32), axis=-1)\n        heatmap_gt = []\n        for i in range(self.num_classes):\n            exist_i = tf.equal(class_id, i)\n            heatmask_i = tf.boolean_mask(heatmask, exist_i, axis=2)\n            heatmap_i = tf.cond(\n                tf.equal(tf.shape(heatmask_i)[-1], 0),\n                lambda: zero_like_heat,\n                lambda: tf.reduce_max(heatmask_i, axis=2, keepdims=True)\n            )\n            heatmap_gt.append(heatmap_i)\n        heatmap_gt = tf.concat(heatmap_gt, axis=-1)\n        heatmap_pos_loss = -.25 * tf.pow(1.-tf.sigmoid(heatmap_pred), 2.) * tf.log_sigmoid(heatmap_pred) * heatmap_gt\n        heatmap_neg_loss = -.25 * tf.pow(tf.sigmoid(heatmap_pred), 2.) * (-heatmap_pred+tf.log_sigmoid(heatmap_pred)) * (1.-heatmap_gt)\n        heatmap_loss = tf.reduce_sum(heatmap_pos_loss) + tf.reduce_sum(heatmap_neg_loss)\n        total_loss = (iou_loss + heatmap_loss + center_loss) / tf.reduce_sum(heatmap_gt)\n        return total_loss\n\n    def _detect_head(self, bottom):\n        with tf.variable_scope('classifier_head', reuse=tf.AUTO_REUSE):\n            conv1 = self._bn_activation_conv(bottom, 256, 3, 1)\n            conv2 = self._bn_activation_conv(conv1, 256, 3, 1)\n            conv3 = self._bn_activation_conv(conv2, 256, 3, 1)\n            conv4 = self._bn_activation_conv(conv3, 256, 3, 1)\n            pconf = self._bn_activation_conv(conv4, self.num_classes, 3, 1, pi_init=True)\n            pcenterness = self._bn_activation_conv(conv4, 1, 3, 1, pi_init=True)\n        with tf.variable_scope('regress_head', reuse=tf.AUTO_REUSE):\n            conva = self._bn_activation_conv(bottom, 256, 3, 1)\n            convb = self._bn_activation_conv(conva, 256, 3, 1)\n            convc = self._bn_activation_conv(convb, 256, 3, 1)\n            convd = self._bn_activation_conv(convc, 256, 3, 1)\n            preg = tf.exp(self._bn_activation_conv(convd, 4, 3, 1))\n        return pconf, preg, pcenterness\n\n    def _get_pyramid(self, feat, feature_size, top_feat=None):\n        if top_feat is None:\n            return self._bn_activation_conv(feat, feature_size, 3, 1)\n        else:\n            if self.data_format == 'channels_last':\n                feat = self._bn_activation_conv(feat, feature_size, 1, 1)\n                top_feat = tf.image.resize_bilinear(top_feat, [tf.shape(feat)[1], tf.shape(feat)[2]])\n                total_feat = feat + top_feat\n                return self._bn_activation_conv(total_feat, feature_size, 3, 1), total_feat\n            else:\n                feat = self._bn_activation_conv(feat, feature_size, 1, 1)\n                feat = tf.transpose(feat, [0, 2, 3, 1])\n                top_feat = tf.transpose(top_feat, [0, 2, 3, 1])\n                top_feat = tf.image.resize_bilinear(top_feat, [tf.shape(feat)[1], tf.shape(feat)[2]])\n                total_feat = feat + top_feat\n                total_feat = tf.transpose(total_feat, [0, 3, 1, 2])\n                return self._bn_activation_conv(total_feat, feature_size, 3, 1), total_feat\n\n    def _init_session(self):\n        self.sess = tf.InteractiveSession()\n        self.sess.run(tf.global_variables_initializer())\n        if self.mode == 'train':\n            self.sess.run(self.train_initializer)\n\n    def _create_saver(self):\n        weights = tf.trainable_variables('backone')\n        self.pretrained_saver = tf.train.Saver(weights)\n        self.saver = tf.train.Saver()\n        self.best_saver = tf.train.Saver()\n\n    def _create_summary(self):\n        with tf.variable_scope('summaries'):\n            tf.summary.scalar('loss', self.loss)\n            self.summary_op = tf.summary.merge_all()\n\n    def train_one_epoch(self, lr):\n        self.is_training = True\n        self.sess.run(self.train_initializer)\n        mean_loss = []\n        num_iters = self.num_train // self.batch_size\n        for i in range(num_iters):\n            _, loss = self.sess.run([self.train_op, self.loss], feed_dict={self.lr: lr})\n            sys.stdout.write('\\r>> ' + 'iters '+str(i+1)+str('/')+str(num_iters)+' loss '+str(loss))\n            sys.stdout.flush()\n            mean_loss.append(loss)\n        sys.stdout.write('\\n')\n        mean_loss = np.mean(mean_loss)\n        return mean_loss\n\n    def test_one_image(self, images):\n        self.is_training = False\n        pred = self.sess.run(self.detection_pred, feed_dict={self.images: images})\n        return pred\n\n    def save_weight(self, mode, path):\n        assert (mode in ['latest', 'best'])\n        if mode == 'latest':\n            saver = self.saver\n        else:\n            saver = self.best_saver\n        if not tf.gfile.Exists(os.path.dirname(path)):\n            tf.gfile.MakeDirs(os.path.dirname(path))\n            print(os.path.dirname(path), 'does not exist, create it done')\n        saver.save(self.sess, path, global_step=self.global_step)\n        print('save', mode, 'model in', path, 'successfully')\n\n    def load_weight(self, path):\n        self.saver.restore(self.sess, path)\n        print('load weight', path, 'successfully')\n\n    def load_pretrained_weight(self, path):\n        self.pretrained_saver.restore(self.sess, path)\n        print('load pretrained weight', path, 'successfully')\n\n    def _gn(self, bottom):\n        gn = tf.contrib.layers.group_norm(\n            inputs=bottom,\n            groups=8,\n            channels_axis=3 if self.data_format == 'channels_last' else 1,\n            reduction_axes=(1, 2) if self.data_format == 'channels_last' else (2, 3),\n            trainable=self.is_training\n        )\n        return gn\n\n    def _conv_bn_activation(self, bottom, filters, kernel_size, strides, activation=tf.nn.relu):\n        conv = tf.layers.conv2d(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            kernel_initializer=tf.contrib.layers.variance_scaling_initializer()\n        )\n        bn = self._gn(conv)\n        if activation is not None:\n            return activation(bn)\n        else:\n            return bn\n\n    def _bn_activation_conv(self, bottom, filters, kernel_size, strides, activation=tf.nn.relu, pi_init=False):\n        bn = self._gn(bottom)\n        if activation is not None:\n            bn = activation(bn)\n        if not pi_init:\n            conv = tf.layers.conv2d(\n                inputs=bn,\n                filters=filters,\n                kernel_size=kernel_size,\n                strides=strides,\n                padding='same',\n                data_format=self.data_format,\n                kernel_initializer=tf.contrib.layers.variance_scaling_initializer()\n            )\n        else:\n            conv = tf.layers.conv2d(\n                inputs=bn,\n                filters=filters,\n                kernel_size=kernel_size,\n                strides=strides,\n                padding='same',\n                data_format=self.data_format,\n                kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),\n                bias_initializer=tf.constant_initializer(-math.log((1 - 0.01) / 0.01))\n            )\n        return conv\n\n    def _residual_block(self, bottom, filters, strides, scope):\n        with tf.variable_scope(scope):\n            with tf.variable_scope('conv_branch'):\n                conv = self._bn_activation_conv(bottom, filters, 3, strides)\n                conv = self._bn_activation_conv(conv, filters, 3, 1)\n            with tf.variable_scope('identity_branch'):\n                if strides != 1:\n                    shutcut = self._bn_activation_conv(bottom, filters, 3, strides)\n                else:\n                    shutcut = bottom\n\n        return conv + shutcut\n\n    def _residual_bottleneck(self, bottom, filters, strides, scope):\n        with tf.variable_scope(scope):\n            with tf.variable_scope('conv_branch'):\n                conv = self._bn_activation_conv(bottom, filters, 1, 1)\n                conv = self._bn_activation_conv(conv, filters, 3, strides)\n                conv = self._bn_activation_conv(conv, filters * 4, 1, 1)\n            with tf.variable_scope('identity_branch'):\n                shutcut = self._bn_activation_conv(bottom, filters * 4, 3, strides)\n\n        return conv + shutcut\n\n    def _max_pooling(self, bottom, pool_size, strides, name=None):\n        return tf.layers.max_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _avg_pooling(self, bottom, pool_size, strides, name=None):\n        return tf.layers.average_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _dropout(self, bottom, name):\n        return tf.layers.dropout(\n            inputs=bottom,\n            rate=self.prob,\n            training=self.is_training,\n            name=name\n        )\n"""
LH_RCNN.py,256,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nimport sys\nimport os\nimport numpy as np\n\n\nclass LHRCNN:\n    def __init__(self, config, data_provider):\n        assert config['mode'] in ['train', 'test']\n        assert config['data_format'] in ['channels_first', 'channels_last']\n        self.config = config\n        self.data_provider = data_provider\n        self.data_shape = config['data_shape']\n        self.num_classes = config['num_classes'] + 1\n        self.weight_decay = config['weight_decay']\n        self.prob = 1. - config['keep_prob']\n        self.data_format = config['data_format']\n        self.mode = config['mode']\n        self.batch_size = config['batch_size'] if config['mode'] == 'train' else 1\n        self.nms_score_threshold = config['nms_score_threshold']\n        self.nms_max_boxes = config['nms_max_boxes']\n        self.nms_iou_threshold = config['nms_iou_threshold']\n\n        self.rpn_first_step = config['rpn_first_step']\n        self.rcnn_first_step = config['rcnn_first_step']\n        self.rpn_second_step = config['rpn_second_step']\n        self.post_nms_proposal = config['post_nms_proposal']\n\n        self.anchor_scales = [32, 64, 128, 256, 512]\n        self.anchor_ratios = [0.5, 1.0, 2.0]\n        self.num_anchors = len(self.anchor_scales) * len(self.anchor_ratios)\n\n        if self.data_format == 'channels_first':\n            self.h, self.w = float(self.data_shape[1]-1), float(self.data_shape[2]-1)\n        else:\n            self.h, self.w = float(self.data_shape[0]-1), float(self.data_shape[1]-1)\n\n        if self.mode == 'train':\n            self.num_train = data_provider['num_train']\n            self.num_val = data_provider['num_val']\n            self.train_generator = data_provider['train_generator']\n            self.train_initializer, self.train_iterator = self.train_generator\n            if data_provider['val_generator'] is not None:\n                self.val_generator = data_provider['val_generator']\n                self.val_initializer, self.val_iterator = self.val_generator\n\n        self.global_step = tf.get_variable(name='global_step', initializer=tf.constant(0), trainable=False)\n        self.is_training = True\n\n        self._define_inputs()\n        self._build_graph()\n        self._create_saver()\n        if self.mode == 'train':\n            self._create_summary()\n        self._init_session()\n\n    def _define_inputs(self):\n        shape = [self.batch_size]\n        shape.extend(self.data_shape)\n        if self.mode == 'train':\n            self.images, self.ground_truth = self.train_iterator.get_next()\n            self.images.set_shape(shape)\n            self.images = self.images / 127.5 -1.\n        else:\n            self.images = tf.placeholder(tf.float32, shape, name='images')\n            self.images = self.images / 127.5 -1.\n            self.ground_truth = tf.placeholder(tf.float32, [self.batch_size, None, 5], name='labels')\n        self.lr = tf.placeholder(dtype=tf.float32, shape=[], name='lr')\n\n    def _build_graph(self):\n        with tf.variable_scope('feature_extractor'):\n            c4_feat, stride = self._feature_extractor(self.images)\n        with tf.variable_scope('rpn'):\n            rpn_conv = self._conv_layer(c4_feat, 256, 3, 1, 'rpn_conv', activation=tf.nn.relu)\n            rpn_conf = self._conv_layer(rpn_conv, self.num_anchors*2, 3, 1, 'rpn_conf')\n            rpn_pbbox = self._conv_layer(rpn_conv, self.num_anchors*4, 3, 1, 'rpn_pbbox')\n            if self.data_format == 'channels_first':\n                rpn_conf = tf.transpose(rpn_conf, [0, 2, 3, 1])\n                rpn_pbbox = tf.transpose(rpn_pbbox, [0, 2, 3, 1])\n            pshape = tf.shape(rpn_conf)\n            rpn_pbbox_yx, rpn_pbbox_hw, rpn_pconf = self._get_rpn_pbbox(rpn_conf, rpn_pbbox)\n            abbox_y1x1, abbox_y2x2, abbox_yx, abbox_hw = self._get_abbox(pshape, stride)\n\n            min_mask = tf.cast(abbox_y1x1[:, 0] >= 0., tf.float32) * tf.cast(abbox_y1x1[:, 1] >= 0., tf.float32)\n            max_mask = tf.cast(abbox_y2x2[:, 0] <= self.h-1, tf.float32) * tf.cast(abbox_y2x2[:, 1] <= self.w-1, tf.float32)\n            mask = (min_mask * max_mask) > 0.\n            abbox_y1x1 = tf.boolean_mask(abbox_y1x1, mask)\n            abbox_y2x2 = tf.boolean_mask(abbox_y2x2, mask)\n            abbox_yx = tf.boolean_mask(abbox_yx, mask)\n            abbox_hw = tf.boolean_mask(abbox_hw, mask)\n            rpn_pbbox_yx = tf.boolean_mask(rpn_pbbox_yx, mask, axis=1)\n            rpn_pbbox_hw = tf.boolean_mask(rpn_pbbox_hw, mask, axis=1)\n            rpn_pconf = tf.boolean_mask(rpn_pconf, mask, axis=1)\n        with tf.variable_scope('rcnn'):\n            state5_conv1_1 = self._separable_conv_layer(c4_feat, 256, [1, 15], 1, 'state5_conv1_1', activation=tf.nn.relu)\n            state5_conv1_2 = self._separable_conv_layer(state5_conv1_1, 490, [15, 1], 1, 'state5_conv1_2', activation=tf.nn.relu)\n            state5_conv2_1 = self._separable_conv_layer(c4_feat, 256, [1, 15], 1, 'state5_conv2_1', activation=tf.nn.relu)\n            state5_conv2_2 = self._separable_conv_layer(state5_conv2_1, 490, [15, 1], 1, 'state5_conv2_2', activation=tf.nn.relu)\n            rcnn_feat = state5_conv1_2 + state5_conv2_2\n            if self.mode == 'train':\n                rpn_loss = []\n                pos_proposal = []\n                pos_rcnn_label = []\n                rcnn_truth_pbbox = []\n                neg_proposal = []\n                pos_box_ind = []\n                neg_box_ind = []\n                for i in range(self.batch_size):\n                    rpn_loss_, pos_proposal_, pos_rcnn_label_, rcnn_truth_pbbox_, neg_proposal_ = self._compute_one_image_loss(\n                        rpn_pbbox_yx[i, ...], rpn_pbbox_hw[i, ...],\n                        abbox_y1x1, abbox_y2x2, abbox_yx, abbox_hw,\n                        rpn_pconf[i, ...], self.ground_truth[i, ...]\n                    )\n                    pos_box_ind_ = tf.zeros_like(pos_rcnn_label_, dtype=tf.int32) + i\n                    neg_box_ind_ = tf.zeros_like(neg_proposal_[:, 0], dtype=tf.int32) + i\n                    rpn_loss.append(rpn_loss_)\n                    pos_proposal.append(pos_proposal_)\n                    pos_rcnn_label.append(pos_rcnn_label_)\n                    rcnn_truth_pbbox.append(rcnn_truth_pbbox_)\n                    neg_proposal.append(neg_proposal_)\n                    pos_box_ind.append(pos_box_ind_)\n                    neg_box_ind.append(neg_box_ind_)\n\n                rpn_loss = tf.reduce_mean(rpn_loss)\n                pos_proposal = tf.concat(pos_proposal, axis=0)\n                pos_rcnn_label = tf.concat(pos_rcnn_label, axis=0)\n                rcnn_truth_pbbox = tf.concat(rcnn_truth_pbbox, axis=0)\n                neg_proposal = tf.concat(neg_proposal, axis=0)\n                pos_box_ind = tf.concat(pos_box_ind, axis=0)\n                neg_box_ind = tf.concat(neg_box_ind, axis=0)\n            else:\n                proposal_yx = rpn_pbbox_yx[0, ...] * abbox_hw + abbox_yx\n                proposal_hw = tf.exp(rpn_pbbox_hw[0, ...]) * abbox_hw\n                proposal = tf.concat([proposal_yx-proposal_hw/2., proposal_yx+proposal_hw/2.], axis=-1)\n                proposal_conf = tf.nn.softmax(rpn_pconf[0, ...])\n\n            if self.mode == 'train':\n                pos_proposal = tf.maximum(pos_proposal, [0., 0., 0., 0.])\n                pos_proposal = tf.minimum(pos_proposal, [self.h, self.w, self.h, self.w])\n                neg_proposal = tf.maximum(neg_proposal, [0., 0., 0., 0.])\n                neg_proposal = tf.minimum(neg_proposal, [self.h, self.w, self.h, self.w])\n                norm_factor = [self.h, self.w, self.h, self.w]\n                pos_roi_feat = tf.image.crop_and_resize(rcnn_feat, pos_proposal/norm_factor, pos_box_ind, [7, 7])\n                pos_roi_feat = tf.layers.flatten(pos_roi_feat)\n                neg_roi_feat = tf.image.crop_and_resize(rcnn_feat, neg_proposal/norm_factor, neg_box_ind, [7, 7])\n                neg_rcnn_label = tf.constant([self.num_classes-1])\n                neg_rcnn_label = tf.tile(neg_rcnn_label, [tf.shape(neg_roi_feat)[0]])\n                neg_roi_feat = tf.layers.flatten(neg_roi_feat)\n                roi_feat = tf.concat([pos_roi_feat, neg_roi_feat], axis=0)\n                rcnn_label = tf.concat([pos_rcnn_label, neg_rcnn_label], axis=0)\n                num_pos = tf.shape(pos_rcnn_label)[0]\n            else:\n                proposal = tf.maximum(proposal, [0., 0., 0., 0.])\n                proposal = tf.minimum(proposal, [self.h, self.w, self.h, self.w])\n                selected_indices = tf.image.non_max_suppression(\n                    proposal, proposal_conf[:, 0], self.post_nms_proposal, iou_threshold=0.7\n                )\n                proposal = tf.gather(proposal, selected_indices)\n                proposal_yx = proposal[..., 0:2] / 2. + proposal[..., 2:4] / 2.\n                proposal_hw = proposal[..., 2:4] - proposal[..., 0:2]\n                box_ind = tf.zeros_like(selected_indices, dtype=tf.int32)\n                norm_factor = [self.h, self.w, self.h, self.w]\n                roi_feat = tf.image.crop_and_resize(rcnn_feat, proposal/norm_factor, box_ind, [7, 7])\n                roi_feat = tf.layers.flatten(roi_feat)\n\n            roi_feat = tf.layers.dense(roi_feat, 2048, name='roi_feat_dense', activation=tf.nn.relu)\n            rcnn_pconf = tf.layers.dense(roi_feat, self.num_classes, name='rcnn_pconf')\n            rcnn_pbbox = tf.layers.dense(roi_feat, 4, name='rcnn_pbbox')\n\n            if self.mode == 'train':\n                rcnn_conf_loss = tf.losses.sparse_softmax_cross_entropy(rcnn_label, rcnn_pconf, reduction=tf.losses.Reduction.MEAN)\n                pos_rcnn_pbbox_loss = self._smooth_l1_loss(tf.gather(rcnn_pbbox, tf.range(num_pos, dtype=tf.int32)) - rcnn_truth_pbbox)\n                pos_rcnn_pbbox_loss = tf.reduce_mean(tf.reduce_sum(pos_rcnn_pbbox_loss, axis=-1))\n                rcnn_loss = rcnn_conf_loss + pos_rcnn_pbbox_loss\n                optimizer = tf.train.MomentumOptimizer(learning_rate=self.lr, momentum=.9)\n                rpn_loss = rpn_loss + self.weight_decay * tf.add_n(\n                    [tf.nn.l2_loss(var) for var in tf.trainable_variables('feature_extractor')]\n                ) + self.weight_decay * tf.add_n(\n                    [tf.nn.l2_loss(var) for var in tf.trainable_variables('rpn')]\n                )\n                rcnn_loss = rcnn_loss + + self.weight_decay * tf.add_n(\n                    [tf.nn.l2_loss(var) for var in tf.trainable_variables('rcnn')]\n                )\n                rpn_vars = tf.trainable_variables('feature_extractor') + tf.trainable_variables('rpn')\n                rpn_grads_and_vars = optimizer.compute_gradients(rpn_loss, rpn_vars)\n                train_rpn_op = optimizer.apply_gradients(rpn_grads_and_vars)\n                rcnn_vars = tf.trainable_variables('rcnn')\n                rcnn_grads_and_vars = optimizer.compute_gradients(rcnn_loss, rcnn_vars)\n                train_rcnn_op = optimizer.apply_gradients(rcnn_grads_and_vars, global_step=self.global_step)\n\n                train_op = tf.case([(tf.less(self.global_step, self.rpn_first_step), lambda: train_rpn_op),\n                                    (tf.less(self.global_step, self.rcnn_first_step), lambda: train_rcnn_op),\n                                    (tf.less(self.global_step, self.rpn_second_step), lambda: train_rpn_op)],\n                                         default=lambda: train_rcnn_op, exclusive=False)\n                update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n                self.train_op = tf.group([update_ops, train_op])\n                self.loss = tf.case([(tf.less(self.global_step, self.rpn_first_step), lambda: rpn_loss),\n                                     (tf.less(self.global_step, self.rcnn_first_step), lambda: rcnn_loss),\n                                     (tf.less(self.global_step, self.rpn_second_step), lambda: rpn_loss)],\n                                     default=lambda: rcnn_loss, exclusive=False)\n\n            else:\n                rcnn_pbbox_yxt = rcnn_pbbox[..., 0:2]\n                rcnn_pbbox_hwt = rcnn_pbbox[..., 2:4]\n                proposal_yxt = proposal_yx\n                proposal_hwt = proposal_hw\n                confidence = tf.nn.softmax(rcnn_pconf)\n                class_id = tf.argmax(confidence, axis=-1)\n                conf_mask = tf.less(class_id, self.num_classes-1)\n                rcnn_pbbox_yxt = tf.boolean_mask(rcnn_pbbox_yxt, conf_mask)\n                rcnn_pbbox_hwt = tf.boolean_mask(rcnn_pbbox_hwt, conf_mask)\n                confidence = tf.boolean_mask(confidence, conf_mask)\n                proposal_yxt = tf.boolean_mask(proposal_yxt, conf_mask)\n                proposal_hwt = tf.boolean_mask(proposal_hwt, conf_mask)\n                dpbbox_yxt = rcnn_pbbox_yxt * proposal_hwt + proposal_yxt\n                dpbbox_hwt = proposal_hwt * tf.exp(rcnn_pbbox_hwt)\n                dpbbox_y1x1 = dpbbox_yxt - dpbbox_hwt / 2.\n                dpbbox_y2x2 = dpbbox_yxt + dpbbox_hwt / 2.\n                dpbbox_y1x1y2x2 = tf.concat([dpbbox_y1x1, dpbbox_y2x2], axis=-1)\n                filter_mask = tf.greater_equal(confidence, self.nms_score_threshold)\n                scores = []\n                class_id = []\n                bbox = []\n                for i in range(self.num_classes-1):\n                    scoresi = tf.boolean_mask(confidence[:, i], filter_mask[:, i])\n                    bboxi = tf.boolean_mask(dpbbox_y1x1y2x2, filter_mask[:, i])\n                    selected_indices = tf.image.non_max_suppression(\n\n                        bboxi, scoresi, self.nms_max_boxes, self.nms_iou_threshold,\n                    )\n                    scores.append(tf.gather(scoresi, selected_indices))\n                    bbox.append(tf.gather(bboxi, selected_indices))\n                    class_id.append(tf.ones_like(tf.gather(scoresi, selected_indices), tf.int32) * i)\n                bbox = tf.concat(bbox, axis=0)\n                scores = tf.concat(scores, axis=0)\n                class_id = tf.concat(class_id, axis=0)\n                self.detection_pred = [scores, bbox, class_id]\n\n    def _feature_extractor(self, images):\n        with tf.variable_scope('stage1'):\n            conv1 = self._conv_layer(images, 24, 3, 2, 'conv1', activation=tf.nn.relu)\n            pool1 = self._max_pooling(conv1, 3, 2, 'pool1')\n        with tf.variable_scope('stage2'):\n            stage2_sconv1 = self._conv_layer(pool1, 144, 3, 2, 'stage2_sconv1', activation=tf.nn.relu)\n            stage2_sconv2 = self._separable_conv_layer(stage2_sconv1, 144, 3, 1, 'stage2_sconv2', activation=tf.nn.relu)\n            stage2_sconv3 = self._separable_conv_layer(stage2_sconv2, 144, 3, 1, 'stage2_sconv3', activation=tf.nn.relu)\n            stage2_sconv4 = self._separable_conv_layer(stage2_sconv3, 144, 3, 1, 'stage2_sconv4', activation=tf.nn.relu)\n        with tf.variable_scope('stage3'):\n            stage3_sconv1 = self._conv_layer(stage2_sconv4, 288, 3, 2, 'stage3_sconv1', activation=tf.nn.relu)\n            stage3_sconv2 = self._separable_conv_layer(stage3_sconv1, 288, 3, 1, 'stage3_sconv2', activation=tf.nn.relu)\n            stage3_sconv3 = self._separable_conv_layer(stage3_sconv2, 288, 3, 1, 'stage3_sconv3', activation=tf.nn.relu)\n            stage3_sconv4 = self._separable_conv_layer(stage3_sconv3, 288, 3, 1, 'stage3_sconv4', activation=tf.nn.relu)\n            stage3_sconv5 = self._separable_conv_layer(stage3_sconv4, 288, 3, 1, 'stage3_sconv5', activation=tf.nn.relu)\n            stage3_sconv6 = self._separable_conv_layer(stage3_sconv5, 288, 3, 1, 'stage3_sconv6', activation=tf.nn.relu)\n            stage3_sconv7 = self._separable_conv_layer(stage3_sconv6, 288, 3, 1, 'stage3_sconv7', activation=tf.nn.relu)\n            stage3_sconv8 = self._separable_conv_layer(stage3_sconv7, 288, 3, 1, 'stage3_sconv8', activation=tf.nn.relu)\n        with tf.variable_scope('stage4'):\n            stage4_sconv1 = self._conv_layer(stage3_sconv8, 576, 3, 2, 'stage4_sconv1', activation=tf.nn.relu)\n            stage4_sconv2 = self._separable_conv_layer(stage4_sconv1, 576, 3, 1, 'stage4_sconv2', activation=tf.nn.relu)\n            stage4_sconv3 = self._separable_conv_layer(stage4_sconv2, 576, 3, 1, 'stage4_sconv3', activation=tf.nn.relu)\n            stage4_sconv4 = self._separable_conv_layer(stage4_sconv3, 576, 3, 1, 'stage4_sconv4', activation=tf.nn.relu)\n\n        downsampling_rate = 32.\n        return stage4_sconv4, downsampling_rate\n\n    def _get_rpn_pbbox(self, rpn_conf, rpn_bbox):\n        rpn_conf = tf.reshape(rpn_conf, [self.batch_size, -1, 2])\n        rpn_bbox = tf.reshape(rpn_bbox, [self.batch_size, -1, 4])\n        rpn_pbbox_yx = rpn_bbox[..., :2]\n        rpn_pbbox_hw = rpn_bbox[..., 2:]\n        return rpn_pbbox_yx, rpn_pbbox_hw, rpn_conf\n\n    def _get_abbox(self, pshape, stride):\n        topleft_y = tf.range(0., tf.cast(pshape[1], tf.float32), dtype=tf.float32)\n        topleft_x = tf.range(0., tf.cast(pshape[2], tf.float32), dtype=tf.float32)\n        topleft_y = tf.reshape(topleft_y, [-1, 1, 1, 1]) + 0.5\n        topleft_x = tf.reshape(topleft_x, [1, -1, 1, 1]) + 0.5\n        topleft_y = tf.tile(topleft_y, [1, pshape[2], 1, 1])\n        topleft_x = tf.tile(topleft_x, [pshape[1], 1, 1, 1])\n        topleft_yx = tf.concat([topleft_y, topleft_x], -1)\n        topleft_yx = tf.tile(topleft_yx, [1, 1, self.num_anchors, 1]) * stride\n\n        priors = []\n        for size in self.anchor_scales:\n            for ratio in self.anchor_ratios:\n                priors.append([size*(ratio**0.5), size/(ratio**0.5)])\n        priors = tf.convert_to_tensor(priors, tf.float32)\n        priors = tf.reshape(priors, [1, 1, -1, 2])\n\n        abbox_y1x1 = tf.reshape(topleft_yx - priors / 2., [-1, 2])\n        abbox_y2x2 = tf.reshape(topleft_yx + priors / 2., [-1, 2])\n        abbox_yx = abbox_y1x1 / 2. + abbox_y2x2 / 2.\n        abbox_hw = abbox_y2x2 - abbox_y1x1\n        return abbox_y1x1, abbox_y2x2, abbox_yx, abbox_hw\n\n    def _compute_one_image_loss(self, pbbox_yx, pbbox_hw, abbox_y1x1, abbox_y2x2,\n                                abbox_yx, abbox_hw, pconf, ground_truth):\n        slice_index = tf.argmin(ground_truth, axis=0)[0]\n        ground_truth = tf.gather(ground_truth, tf.range(0, slice_index, dtype=tf.int64))\n        gbbox_yx = ground_truth[..., 0:2]\n        gbbox_hw = ground_truth[..., 2:4]\n        gbbox_y1x1 = gbbox_yx - gbbox_hw / 2.\n        gbbox_y2x2 = gbbox_yx + gbbox_hw / 2.\n        rcnn_label = tf.cast(ground_truth[..., 4], dtype=tf.int32)\n\n        abbox_hwti = tf.reshape(abbox_hw, [1, -1, 2])\n        abbox_y1x1ti = tf.reshape(abbox_y1x1, [1, -1, 2])\n        abbox_y2x2ti = tf.reshape(abbox_y2x2, [1, -1, 2])\n        gbbox_hwti = tf.reshape(gbbox_hw, [-1, 1, 2])\n        gbbox_y1x1ti = tf.reshape(gbbox_y1x1, [-1, 1, 2])\n        gbbox_y2x2ti = tf.reshape(gbbox_y2x2, [-1, 1, 2])\n        num_a = tf.shape(abbox_hwti)[1]\n        num_g = tf.shape(gbbox_hwti)[0]\n        abbox_hwti = tf.tile(abbox_hwti, [num_g, 1, 1])\n        abbox_y1x1ti = tf.tile(abbox_y1x1ti, [num_g, 1, 1])\n        abbox_y2x2ti = tf.tile(abbox_y2x2ti, [num_g, 1, 1])\n        gbbox_hwti = tf.tile(gbbox_hwti, [1, num_a, 1])\n        gbbox_y1x1ti = tf.tile(gbbox_y1x1ti, [1, num_a, 1])\n        gbbox_y2x2ti = tf.tile(gbbox_y2x2ti, [1, num_a, 1])\n\n        gaiou_y1x1ti = tf.maximum(abbox_y1x1ti, gbbox_y1x1ti)\n        gaiou_y2x2ti = tf.minimum(abbox_y2x2ti, gbbox_y2x2ti)\n        gaiou_area = tf.reduce_prod(tf.maximum(gaiou_y2x2ti - gaiou_y1x1ti, 0), axis=-1)\n        aarea = tf.reduce_prod(abbox_hwti, axis=-1)\n        garea = tf.reduce_prod(gbbox_hwti, axis=-1)\n        gaiou_rate = gaiou_area / (aarea + garea - gaiou_area + 1e-8)\n\n        best_raindex = tf.argmax(gaiou_rate, axis=1)\n        best_pbbox_yx = tf.gather(pbbox_yx, best_raindex)\n        best_pbbox_hw = tf.gather(pbbox_hw, best_raindex)\n        best_pconf = tf.gather(pconf, best_raindex)\n        best_abbox_yx = tf.gather(abbox_yx, best_raindex)\n        best_abbox_hw = tf.gather(abbox_hw, best_raindex)\n        best_rcnn_label = tf.gather(rcnn_label, best_raindex)\n\n        bestmask, _ = tf.unique(best_raindex)\n        bestmask = tf.contrib.framework.sort(bestmask)\n        bestmask = tf.reshape(bestmask, [-1, 1])\n        bestmask = tf.sparse.SparseTensor(tf.concat([bestmask, tf.zeros_like(bestmask)], axis=-1),\n                                          tf.squeeze(tf.ones_like(bestmask)), dense_shape=[num_a, 1])\n        bestmask = tf.reshape(tf.cast(tf.sparse.to_dense(bestmask), tf.float32), [-1])\n\n        othermask = 1. - bestmask\n        othermask = othermask > 0.\n        other_pbbox_yx = tf.boolean_mask(pbbox_yx, othermask)\n        other_pbbox_hw = tf.boolean_mask(pbbox_hw, othermask)\n        other_pconf = tf.boolean_mask(pconf, othermask)\n        other_abbox_yx = tf.boolean_mask(abbox_yx, othermask)\n        other_abbox_hw = tf.boolean_mask(abbox_hw, othermask)\n\n        agiou_rate = tf.transpose(gaiou_rate)\n        other_agiou_rate = tf.boolean_mask(agiou_rate, othermask)\n        max_agiou_rate = tf.reduce_max(other_agiou_rate, axis=1)\n        pos_agiou_mask = max_agiou_rate > 0.5\n        neg_agiou_mask = max_agiou_rate < 0.3\n        rgindex = tf.argmax(other_agiou_rate, axis=1)\n        pos_rgindex = tf.boolean_mask(rgindex, pos_agiou_mask)\n        pos_pbbox_yx = tf.boolean_mask(other_pbbox_yx, pos_agiou_mask)\n        pos_pbbox_hw = tf.boolean_mask(other_pbbox_hw, pos_agiou_mask)\n        pos_pconf = tf.boolean_mask(other_pconf, pos_agiou_mask)\n        pos_abbox_yx = tf.boolean_mask(other_abbox_yx, pos_agiou_mask)\n        pos_abbox_hw = tf.boolean_mask(other_abbox_hw, pos_agiou_mask)\n        pos_gbbox_yx = tf.gather(gbbox_yx, pos_rgindex)\n        pos_gbbox_hw = tf.gather(gbbox_hw, pos_rgindex)\n        pos_rcnn_label = tf.gather(rcnn_label, pos_rgindex)\n\n        pos_pbbox_yx = tf.concat([best_pbbox_yx, pos_pbbox_yx], axis=0)\n        pos_pbbox_hw = tf.concat([best_pbbox_hw, pos_pbbox_hw], axis=0)\n        pos_pconf = tf.concat([best_pconf, pos_pconf], axis=0)\n        pos_gbbox_yx = tf.concat([gbbox_yx, pos_gbbox_yx], axis=0)\n        pos_gbbox_hw = tf.concat([gbbox_hw, pos_gbbox_hw], axis=0)\n        pos_rcnn_label = tf.concat([best_rcnn_label, pos_rcnn_label], axis=0)\n        pos_abbox_yx = tf.concat([best_abbox_yx, pos_abbox_yx], axis=0)\n        pos_abbox_hw = tf.concat([best_abbox_hw, pos_abbox_hw], axis=0)\n        pos_abbox_y1x1y2x2 = tf.concat([pos_abbox_yx-pos_abbox_hw/2., pos_abbox_yx+pos_abbox_hw/2.], axis=-1)\n\n        neg_pconf = tf.boolean_mask(other_pconf, neg_agiou_mask)\n        neg_abbox_yx = tf.boolean_mask(other_abbox_yx, neg_agiou_mask)\n        neg_abbox_hw = tf.boolean_mask(other_abbox_hw, neg_agiou_mask)\n        neg_pbbox_yx = tf.boolean_mask(other_pbbox_yx, neg_agiou_mask)\n        neg_pbbox_hw = tf.boolean_mask(other_pbbox_hw, neg_agiou_mask)\n        neg_abbox_y1x1y2x2 = tf.concat([neg_abbox_yx-neg_abbox_hw/2., neg_abbox_yx+neg_abbox_hw/2.], axis=-1)\n\n        num_pos = tf.shape(pos_pconf)[0]\n        num_neg = tf.shape(neg_pconf)[0]\n        pos_label = tf.constant([0])\n        pos_label = tf.tile(pos_label, [num_pos])\n        neg_label = tf.constant([1])\n        neg_label = tf.tile(neg_label, [num_neg])\n        chosen_num_pos = tf.cond(num_pos > 128, lambda: 128, lambda: num_pos)\n        chosen_num_neg = tf.cond(num_neg > 256-chosen_num_pos, lambda: 256-chosen_num_pos, lambda: num_neg)\n        pos_conf_loss = tf.losses.sparse_softmax_cross_entropy(pos_label, pos_pconf, reduction=tf.losses.Reduction.NONE)\n        selected_posindices = tf.image.non_max_suppression(\n            pos_abbox_y1x1y2x2, tf.nn.softmax(pos_pconf)[:, 0], chosen_num_pos, iou_threshold=0.7\n        )\n        pos_conf_loss = tf.reduce_mean(tf.gather(pos_conf_loss, selected_posindices))\n\n        neg_loss = tf.losses.sparse_softmax_cross_entropy(neg_label, neg_pconf, reduction=tf.losses.Reduction.NONE)\n        selected_negindices = tf.image.non_max_suppression(\n            neg_abbox_y1x1y2x2, neg_loss, chosen_num_neg, iou_threshold=0.7\n        )\n        neg_loss = tf.reduce_mean(tf.gather(neg_loss, selected_negindices))\n\n        pos_abbox_yx = tf.gather(pos_abbox_yx, selected_posindices)\n        pos_abbox_hw = tf.gather(pos_abbox_hw, selected_posindices)\n        pos_pbbox_yx = tf.gather(pos_pbbox_yx, selected_posindices)\n        pos_pbbox_hw = tf.gather(pos_pbbox_hw, selected_posindices)\n        pos_gbbox_yx = tf.gather(pos_gbbox_yx, selected_posindices)\n        pos_gbbox_hw = tf.gather(pos_gbbox_hw, selected_posindices)\n        pos_rcnn_label = tf.gather(pos_rcnn_label, selected_posindices)\n\n        neg_abbox_yx = tf.gather(neg_abbox_yx, selected_negindices)\n        neg_abbox_hw = tf.gather(neg_abbox_hw, selected_negindices)\n        neg_pbbox_yx = tf.gather(neg_pbbox_yx, selected_negindices)\n        neg_pbbox_hw = tf.gather(neg_pbbox_hw, selected_negindices)\n\n        pos_truth_pbbox_yx = (pos_gbbox_yx - pos_abbox_yx) / pos_abbox_hw\n        pos_truth_pbbox_hw = tf.log(pos_gbbox_hw / pos_abbox_hw)\n        pos_yx_loss = tf.reduce_sum(self._smooth_l1_loss(pos_pbbox_yx - pos_truth_pbbox_yx), axis=-1)\n        pos_hw_loss = tf.reduce_sum(self._smooth_l1_loss(pos_pbbox_hw - pos_truth_pbbox_hw), axis=-1)\n        pos_coord_loss = tf.reduce_mean(pos_yx_loss + pos_hw_loss)\n\n        total_loss = neg_loss + pos_conf_loss + 10.*pos_coord_loss\n\n        pos_proposal_yx = pos_abbox_hw * pos_pbbox_yx + pos_abbox_yx\n        pos_proposal_hw = tf.exp(pos_pbbox_hw) * pos_abbox_hw\n        rcnn_truth_pbbox_yx = (pos_gbbox_yx - pos_proposal_yx) / pos_proposal_yx\n        rcnn_truth_pbbox_hw = tf.log(pos_gbbox_hw / pos_proposal_hw)\n        rcnn_truth_pbbox = tf.concat([rcnn_truth_pbbox_yx, rcnn_truth_pbbox_hw], axis=-1)\n        neg_proposal_yx = neg_abbox_hw * neg_pbbox_yx + neg_abbox_yx\n        neg_proposal_hw = tf.exp(neg_pbbox_hw) * neg_abbox_hw\n        pos_proposal_y1x1 = pos_proposal_yx - pos_proposal_hw / 2.\n        pos_proposal_y2x2 = pos_proposal_yx + pos_proposal_hw / 2.\n        pos_proposal = tf.concat([pos_proposal_y1x1, pos_proposal_y2x2], axis=-1)\n        neg_proposal_y1x1 = neg_proposal_yx - neg_proposal_hw / 2.\n        neg_proposal_y2x2 = neg_proposal_yx + neg_proposal_hw / 2.\n        neg_proposal = tf.concat([neg_proposal_y1x1, neg_proposal_y2x2], axis=-1)\n\n        return total_loss, pos_proposal, pos_rcnn_label, rcnn_truth_pbbox, neg_proposal\n\n    def _smooth_l1_loss(self, x):\n        return tf.where(tf.abs(x) < 1., 0.5*x*x, tf.abs(x)-0.5)\n\n    def _init_session(self):\n        self.sess = tf.InteractiveSession()\n        self.sess.run(tf.global_variables_initializer())\n        if self.mode == 'train':\n            self.sess.run(self.train_initializer)\n\n    def _create_saver(self):\n        weights = tf.trainable_variables(scope='feature_extractor')\n        self.pretraining_weight_saver = tf.train.Saver(weights)\n        self.saver = tf.train.Saver()\n        self.best_saver = tf.train.Saver()\n\n    def _create_summary(self):\n        with tf.variable_scope('summaries'):\n            tf.summary.scalar('loss', self.loss)\n            self.summary_op = tf.summary.merge_all()\n\n    def train_one_epoch(self, lr):\n        self.is_training = True\n        self.sess.run(self.train_initializer)\n        mean_loss = []\n        num_iters = self.num_train // self.batch_size\n        for i in range(num_iters):\n            _, loss, global_step = self.sess.run([self.train_op, self.loss, self.global_step], feed_dict={self.lr: lr})\n            # sys.stdout.write('\\r>> ' + 'iters '+str(i+1)+str('/')+str(num_iters)+' loss '+str(loss))\n            if global_step < self.rpn_first_step:\n                loss_name = 'rpn_loss'\n            elif global_step < self.rcnn_first_step:\n                loss_name = 'rcnn_loss'\n            elif global_step < self.rpn_second_step:\n                loss_name = 'rpn_loss'\n            else:\n                loss_name = 'rcnn_loss'\n            print('iters ',str(i+1)+str('/')+str(num_iters), loss_name, loss, 'global_step', global_step)\n            # sys.stdout.flush()\n            mean_loss.append(loss)\n        # sys.stdout.write('\\n')\n        mean_loss = np.mean(mean_loss)\n        return mean_loss\n\n    def test_one_image(self, images):\n        self.is_training = False\n        pred = self.sess.run(self.detection_pred, feed_dict={self.images: images})\n        return pred\n\n    def save_weight(self, mode, path):\n        assert(mode in ['latest', 'best'])\n        if mode == 'latest':\n            saver = self.saver\n        else:\n            saver = self.best_saver\n        if not tf.gfile.Exists(os.path.dirname(path)):\n            tf.gfile.MakeDirs(os.path.dirname(path))\n            print(os.path.dirname(path), 'does not exist, create it done')\n        saver.save(self.sess, path, global_step=self.global_step)\n        print('save', mode, 'model in', path, 'successfully')\n\n    def load_weight(self, path):\n        self.saver.restore(self.sess, path)\n        print('load weight', path, 'successfully')\n\n    def load_rpn_weight(self, path):\n        self.rpn_saver.restore(self.sess, path)\n        print('load rpn weight', path, 'successfully')\n\n    def load_pretraining_weight(self, path):\n        self.pretraining_weight_saver.restore(self.sess, path)\n        print('>> load pretraining weight', path, 'successfully')\n\n    def _bn(self, bottom):\n        bn = tf.layers.batch_normalization(\n            inputs=bottom,\n            axis=3 if self.data_format == 'channels_last' else 1,\n            training=self.is_training\n        )\n        return bn\n\n    def _conv_layer(self, bottom, filters, kernel_size, strides, name=None, dilation_rate=1, activation=None, padding='same'):\n        conv = tf.layers.conv2d(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            name=name,\n            data_format=self.data_format,\n            dilation_rate=dilation_rate,\n        )\n        bn = self._bn(conv)\n        if activation is not None:\n            bn = activation(bn)\n        return bn\n\n    def _separable_conv_layer(self, bottom, filters, kernel_size, strides, name=None, dilation_rate=1, activation=None):\n        conv = tf.layers.separable_conv2d(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding='same',\n            name=name,\n            data_format=self.data_format,\n            use_bias=False,\n            dilation_rate=dilation_rate,\n        )\n        bn = self._bn(conv)\n        if activation is not None:\n            bn = activation(bn)\n        return bn\n\n    def _max_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.max_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _avg_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.average_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _dropout(self, bottom, name):\n        return tf.layers.dropout(\n            inputs=bottom,\n            rate=self.prob,\n            training=self.is_training,\n            name=name\n        )\n"""
PFPNetR.py,291,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nfrom tensorflow.python import pywrap_tensorflow as wrap\nimport sys\nimport os\nimport numpy as np\n\n\nclass PFPNetR:\n    def __init__(self, config, data_provider):\n        assert config[\'mode\'] in [\'train\', \'test\']\n        assert config[\'data_format\'] in [\'channels_first\', \'channels_last\']\n        assert config[\'input_size\'] % 64 == 0\n        self.config = config\n        self.data_provider = data_provider\n        self.input_size = config[\'input_size\']\n\n        if config[\'data_format\'] == \'channels_last\':\n            self.data_shape = [self.input_size, self.input_size, 3]\n        else:\n            self.data_shape = [3, self.input_size, self.input_size]\n        self.num_classes = config[\'num_classes\'] + 1\n        self.weight_decay = config[\'weight_decay\']\n        self.prob = 1. - config[\'keep_prob\']\n        self.data_format = config[\'data_format\']\n        self.mode = config[\'mode\']\n        self.batch_size = config[\'batch_size\'] if config[\'mode\'] == \'train\' else 1\n        self.anchor_ratios = [0.5, 1.0, 2.0]\n        self.num_anchors = len(self.anchor_ratios)\n        self.nms_score_threshold = config[\'nms_score_threshold\']\n        self.nms_max_boxes = config[\'nms_max_boxes\']\n        self.nms_iou_threshold = config[\'nms_iou_threshold\']\n        self.reader = wrap.NewCheckpointReader(config[\'pretraining_weight\'])\n\n        if self.mode == \'train\':\n            self.num_train = data_provider[\'num_train\']\n            self.num_val = data_provider[\'num_val\']\n            self.train_generator = data_provider[\'train_generator\']\n            self.train_initializer, self.train_iterator = self.train_generator\n            if data_provider[\'val_generator\'] is not None:\n                self.val_generator = data_provider[\'val_generator\']\n                self.val_initializer, self.val_iterator = self.val_generator\n\n        self.global_step = tf.get_variable(name=\'global_step\', initializer=tf.constant(0), trainable=False)\n        self.is_training = True\n\n        self._define_inputs()\n        self._build_graph()\n        self._create_saver()\n        if self.mode == \'train\':\n            self._create_summary()\n        self._init_session()\n\n    def _define_inputs(self):\n        shape = [self.batch_size]\n        shape.extend(self.data_shape)\n        mean = tf.convert_to_tensor([123.68, 116.779, 103.979], dtype=tf.float32)\n        if self.data_format == \'channels_last\':\n            mean = tf.reshape(mean, [1, 1, 1, 3])\n        else:\n            mean = tf.reshape(mean, [1, 3, 1, 1])\n        if self.mode == \'train\':\n            self.images, self.ground_truth = self.train_iterator.get_next()\n            self.images.set_shape(shape)\n            self.images = self.images - mean\n        else:\n            self.images = tf.placeholder(tf.float32, shape, name=\'images\')\n            self.images = self.images - mean\n            self.ground_truth = tf.placeholder(tf.float32, [self.batch_size, None, 5], name=\'labels\')\n        self.lr = tf.placeholder(dtype=tf.float32, shape=[], name=\'lr\')\n\n    def _build_graph(self):\n        with tf.variable_scope(\'feature_extractor\'):\n            feat1, feat2, feat3, feat4, stride1, stride2, stride3, stride4 = self._feature_extractor(self.images)\n            axes = 3 if self.data_format == \'channels_last\' else 1\n            feat1 = tf.nn.l2_normalize(feat1, axis=axes)\n            feat1_norm_factor = tf.get_variable(\'feat1_l2_norm\', shape=[1], initializer=tf.constant_initializer(10.))\n            feat2 = tf.nn.l2_normalize(feat2, axis=axes)\n            feat2_norm_factor = tf.get_variable(\'feat2_l2_norm\', shape=[1], initializer=tf.constant_initializer(8.))\n            feat1_channels = tf.shape(feat1)[axes]\n            feat1_norm_factor = tf.tile(feat1_norm_factor, [feat1_channels])\n            feat2_channels = tf.shape(feat2)[axes]\n            feat2_norm_factor = tf.tile(feat2_norm_factor, [feat2_channels])\n            if self.data_format == \'channels_last\':\n                feat1_norm_factor = tf.reshape(feat1_norm_factor, [1, 1, 1, -1])\n                feat2_norm_factor = tf.reshape(feat2_norm_factor, [1, 1, 1, -1])\n            else:\n                feat1_norm_factor = tf.reshape(feat1_norm_factor, [1, -1, 1, 1])\n                feat2_norm_factor = tf.reshape(feat2_norm_factor, [1, 1, 1, -1])\n            feat1 = feat1_norm_factor * feat1\n            feat2 = feat2_norm_factor * feat2\n        with tf.variable_scope(\'ARM\'):\n            arm1loc, arm1conf = self._arm(feat1, \'arm1\')\n            arm2loc, arm2conf = self._arm(feat2, \'arm2\')\n            arm3loc, arm3conf = self._arm(feat3, \'arm3\')\n            arm4loc, arm4conf = self._arm(feat4, \'arm4\')\n        with tf.variable_scope(\'TCB\'):\n            tcb4 = self._tcb(feat4, \'tcb4\')\n            tcb3 = self._tcb(feat3, \'tcb3\', tcb4)\n            tcb2 = self._tcb(feat2, \'tcb2\', tcb3)\n            tcb1 = self._tcb(feat1, \'tcb1\', tcb2)\n        with tf.variable_scope(\'ODM\'):\n            odm1loc, odm1conf = self._odm(tcb1, \'odm1\')\n            odm2loc, odm2conf = self._odm(tcb2, \'odm2\')\n            odm3loc, odm3conf = self._odm(tcb3, \'odm3\')\n            odm4loc, odm4conf = self._odm(tcb4, \'odm4\')\n        with tf.variable_scope(\'inference\'):\n            if self.data_format == \'channels_first\':\n                arm1loc = tf.transpose(arm1loc, [0, 2, 3, 1])\n                arm1conf = tf.transpose(arm1conf, [0, 2, 3, 1])\n                arm2loc = tf.transpose(arm2loc, [0, 2, 3, 1])\n                arm2conf = tf.transpose(arm2conf, [0, 2, 3, 1])\n                arm3loc = tf.transpose(arm3loc, [0, 2, 3, 1])\n                arm3conf = tf.transpose(arm3conf, [0, 2, 3, 1])\n                arm4loc = tf.transpose(arm4loc, [0, 2, 3, 1])\n                arm4conf = tf.transpose(arm4conf, [0, 2, 3, 1])\n                odm1loc = tf.transpose(odm1loc, [0, 2, 3, 1])\n                odm1conf = tf.transpose(odm1conf, [0, 2, 3, 1])\n                odm2loc = tf.transpose(odm2loc, [0, 2, 3, 1])\n                odm2conf = tf.transpose(odm2conf, [0, 2, 3, 1])\n                odm3loc = tf.transpose(odm3loc, [0, 2, 3, 1])\n                odm3conf = tf.transpose(odm3conf, [0, 2, 3, 1])\n                odm4loc = tf.transpose(odm4loc, [0, 2, 3, 1])\n                odm4conf = tf.transpose(odm4conf, [0, 2, 3, 1])\n            p1shape = tf.shape(arm1loc)\n            p2shape = tf.shape(arm2loc)\n            p3shape = tf.shape(arm3loc)\n            p4shape = tf.shape(arm4loc)\n            arm1pbbox_yx, arm1pbbox_hw, arm1pconf = self._get_armpbbox(arm1loc, arm1conf)\n            arm2pbbox_yx, arm2pbbox_hw, arm2pconf = self._get_armpbbox(arm2loc, arm2conf)\n            arm3pbbox_yx, arm3pbbox_hw, arm3pconf = self._get_armpbbox(arm3loc, arm3conf)\n            arm4pbbox_yx, arm4pbbox_hw, arm4pconf = self._get_armpbbox(arm4loc, arm4conf)\n\n            odm1pbbox_yx, odm1pbbox_hw, odm1pconf = self._get_odmpbbox(odm1loc, odm1conf)\n            odm2pbbox_yx, odm2pbbox_hw, odm2pconf = self._get_odmpbbox(odm2loc, odm2conf)\n            odm3pbbox_yx, odm3pbbox_hw, odm3pconf = self._get_odmpbbox(odm3loc, odm3conf)\n            odm4pbbox_yx, odm4pbbox_hw, odm4pconf = self._get_odmpbbox(odm4loc, odm4conf)\n\n            a1bbox_y1x1, a1bbox_y2x2, a1bbox_yx, a1bbox_hw = self._get_abbox(stride1*4, stride1, p1shape)\n            a2bbox_y1x1, a2bbox_y2x2, a2bbox_yx, a2bbox_hw = self._get_abbox(stride2*4, stride2, p2shape)\n            a3bbox_y1x1, a3bbox_y2x2, a3bbox_yx, a3bbox_hw = self._get_abbox(stride3*4, stride3, p3shape)\n            a4bbox_y1x1, a4bbox_y2x2, a4bbox_yx, a4bbox_hw = self._get_abbox(stride4*4, stride4, p4shape)\n\n            armpbbox_yx = tf.concat([arm1pbbox_yx, arm2pbbox_yx, arm3pbbox_yx, arm4pbbox_yx], axis=1)\n            armpbbox_hw = tf.concat([arm1pbbox_hw, arm2pbbox_hw, arm3pbbox_hw, arm4pbbox_hw], axis=1)\n            armpconf = tf.concat([arm1pconf, arm2pconf, arm3pconf, arm4pconf], axis=1)\n            odmpbbox_yx = tf.concat([odm1pbbox_yx, odm2pbbox_yx, odm3pbbox_yx, odm4pbbox_yx], axis=1)\n            odmpbbox_hw = tf.concat([odm1pbbox_hw, odm2pbbox_hw, odm3pbbox_hw, odm4pbbox_hw], axis=1)\n            odmpconf = tf.concat([odm1pconf, odm2pconf, odm3pconf, odm4pconf], axis=1)\n            abbox_y1x1 = tf.concat([a1bbox_y1x1, a2bbox_y1x1, a3bbox_y1x1, a4bbox_y1x1], axis=0)\n            abbox_y2x2 = tf.concat([a1bbox_y2x2, a2bbox_y2x2, a3bbox_y2x2, a4bbox_y2x2], axis=0)\n            abbox_yx = tf.concat([a1bbox_yx, a2bbox_yx, a3bbox_yx, a4bbox_yx], axis=0)\n            abbox_hw = tf.concat([a1bbox_hw, a2bbox_hw, a3bbox_hw, a4bbox_hw], axis=0)\n            if self.mode == \'train\':\n                i = 0.\n                loss = 0.\n                cond = lambda loss, i: tf.less(i, tf.cast(self.batch_size, tf.float32))\n                body = lambda loss, i: (\n                    tf.add(loss, self._compute_one_image_loss(\n                        tf.squeeze(tf.gather(armpbbox_yx, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(armpbbox_hw, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(armpconf, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(odmpbbox_yx, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(odmpbbox_hw, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(odmpconf, tf.cast(i, tf.int32))),\n                        abbox_y1x1,\n                        abbox_y2x2,\n                        abbox_yx,\n                        abbox_hw,\n                        tf.squeeze(tf.gather(self.ground_truth, tf.cast(i, tf.int32))),\n                    )),\n                    tf.add(i, 1.)\n                )\n                init_state = (loss, i)\n                state = tf.while_loop(cond, body, init_state)\n                total_loss, _ = state\n                total_loss = total_loss / self.batch_size\n                optimizer = tf.train.MomentumOptimizer(learning_rate=self.lr, momentum=.9)\n                self.loss = total_loss + self.weight_decay * tf.add_n(\n                    [tf.nn.l2_loss(var) for var in tf.trainable_variables()]\n                )\n                train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n                update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n                self.train_op = tf.group([update_ops, train_op])\n            else:\n                armconft = tf.nn.softmax(armpconf[0, ...])\n                odmconft = tf.nn.softmax(odmpconf[0, ...])\n                armmask = armconft[:, 1] < 0.99\n                odmmask = tf.argmax(odmconft, axis=-1) < self.num_classes - 1\n                mask = (tf.cast(armmask, tf.float32) * tf.cast(odmmask, tf.float32)) > 0.\n                armpbbox_yxt = tf.boolean_mask(armpbbox_yx[0, ...], mask)\n                armpbbox_hwt = tf.boolean_mask(armpbbox_hw[0, ...], mask)\n                odmpbbox_yxt = tf.boolean_mask(odmpbbox_yx[0, ...], mask)\n                odmpbbox_hwt = tf.boolean_mask(odmpbbox_hw[0, ...], mask)\n                abbox_yxt = tf.boolean_mask(abbox_yx, mask)\n                abbox_hwt = tf.boolean_mask(abbox_hw, mask)\n                odmconft = tf.boolean_mask(odmconft, mask)\n                confidence = odmconft[..., :self.num_classes-1]\n\n                arm_yx = armpbbox_yxt * abbox_hwt + abbox_yxt\n                arm_hw = tf.exp(armpbbox_hwt) * abbox_hwt\n                odm_yx = odmpbbox_yxt * arm_hw + arm_yx\n                odm_hw = tf.exp(odmpbbox_hwt) * arm_hw\n\n                odm_y1x1 = odm_yx - odm_hw / 2.\n                odm_y2x2 = odm_yx + odm_hw / 2.\n                odm_y1x1y2x2 = tf.concat([odm_y1x1, odm_y2x2], axis=-1)\n                filter_mask = tf.greater_equal(confidence, self.nms_score_threshold)\n                scores = []\n                class_id = []\n                bbox = []\n                for i in range(self.num_classes-1):\n                    scoresi = tf.boolean_mask(confidence[:, i], filter_mask[:, i])\n                    bboxi = tf.boolean_mask(odm_y1x1y2x2, filter_mask[:, i])\n                    selected_indices = tf.image.non_max_suppression(\n\n                        bboxi, scoresi, self.nms_max_boxes, self.nms_iou_threshold,\n                    )\n                    scores.append(tf.gather(scoresi, selected_indices))\n                    bbox.append(tf.gather(bboxi, selected_indices))\n                    class_id.append(tf.ones_like(tf.gather(scoresi, selected_indices), tf.int32) * i)\n                bbox = tf.concat(bbox, axis=0)\n                scores = tf.concat(scores, axis=0)\n                class_id = tf.concat(class_id, axis=0)\n\n                self.detection_pred = [scores, bbox, class_id]\n\n    def _feature_extractor(self, images):\n        conv1_1 = self._load_conv_layer(images,\n                                        tf.get_variable(name=\'kernel_conv1_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv1_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_1/biases""),\n                                                        trainable=True),\n                                        name=""conv1_1"")\n        conv1_2 = self._load_conv_layer(conv1_1,\n                                        tf.get_variable(name=\'kernel_conv1_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv1_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_2/biases""),\n                                                        trainable=True),\n                                        name=""conv1_2"")\n        pool1 = self._max_pooling(conv1_2, 2, 2, name=""pool1"")\n\n        conv2_1 = self._load_conv_layer(pool1,\n                                        tf.get_variable(name=\'kenrel_conv2_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv2_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_1/biases""),\n                                                        trainable=True),\n                                        name=""conv2_1"")\n        conv2_2 = self._load_conv_layer(conv2_1,\n                                        tf.get_variable(name=\'kernel_conv2_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv2_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_2/biases""),\n                                                        trainable=True),\n                                        name=""conv2_2"")\n        pool2 = self._max_pooling(conv2_2, 2, 2, name=""pool2"")\n        conv3_1 = self._load_conv_layer(pool2,\n                                        tf.get_variable(name=\'kernel_conv3_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv_3_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_1/biases""),\n                                                        trainable=True),\n                                        name=""conv3_1"")\n        conv3_2 = self._load_conv_layer(conv3_1,\n                                        tf.get_variable(name=\'kernel_conv3_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv3_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_2/biases""),\n                                                        trainable=True),\n                                        name=""conv3_2"")\n        conv3_3 = self._load_conv_layer(conv3_2,\n                                        tf.get_variable(name=\'kernel_conv3_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_3/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv3_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_3/biases""),\n                                                        trainable=True),\n                                        name=""conv3_3"")\n        pool3 = self._max_pooling(conv3_3, 2, 2, name=""pool3"")\n\n        conv4_1 = self._load_conv_layer(pool3,\n                                        tf.get_variable(name=\'kernel_conv4_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv4_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_1/biases""),\n                                                        trainable=True),\n                                        name=""conv4_1"")\n        conv4_2 = self._load_conv_layer(conv4_1,\n                                        tf.get_variable(name=\'kernel_conv4_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv4_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_2/biases""),\n                                                        trainable=True),\n                                        name=""conv4_2"")\n        fh1 = self._load_conv_layer(conv4_2,\n                                    tf.get_variable(name=\'kernel_conv4_3\',\n                                                    initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_3/weights""),\n                                                    trainable=True),\n                                    tf.get_variable(name=\'bias_conv4_3\',\n                                                    initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_3/biases""),\n                                                    trainable=True),\n                                    name=""conv4_3"")\n\n        if self.data_format == \'channels_first\':\n            fh1 = tf.transpose(fh1, [0, 2, 3, 1])\n        p1shape = tf.shape(fh1)\n        p1_h, p1_w = p1shape[1], p1shape[2]\n        p2_h, p2_w = p1_h // 2, p1_w // 2\n        p3_h, p3_w = p2_h // 2, p2_w // 2\n        p4_h, p4_w = p3_h // 2, p3_w // 2\n        fh2 = tf.image.resize_bilinear(fh1, [p2_h, p2_w], align_corners=True)\n        fh3 = tf.image.resize_bilinear(fh1, [p3_h, p3_w], align_corners=True)\n        fh4 = tf.image.resize_bilinear(fh1, [p4_h, p4_w], align_corners=True)\n        if self.data_format == \'channels_first\':\n            fh1 = tf.transpose(fh1, [0, 3, 1, 2])\n            fh2 = tf.transpose(fh2, [0, 3, 1, 2])\n            fh3 = tf.transpose(fh3, [0, 3, 1, 2])\n            fh4 = tf.transpose(fh4, [0, 3, 1, 2])\n        fl1 = self._conv_layer(fh1, 512 // 6, 1, 1, activation=tf.nn.relu)\n        fl2 = self._conv_layer(fh2, 512 // 6, 1, 1, activation=tf.nn.relu)\n        fl3 = self._conv_layer(fh3, 512 // 6, 1, 1, activation=tf.nn.relu)\n        fl4 = self._conv_layer(fh4, 512 // 6, 1, 1, activation=tf.nn.relu)\n        fl2_1 = self._dconv_layer(fl2, 512 // 6, 4, 2)\n        fl2_1 = self._conv_layer(fl2_1 + fl1, 512 // 6, 1, 1, activation=tf.nn.relu)\n        fl3_2 = self._dconv_layer(fl3, 512 // 6, 4, 2)\n        fl3_2 = self._conv_layer(fl3_2 + fl2, 512 // 6, 1, 1, activation=tf.nn.relu)\n        fl3_1 = self._dconv_layer(fl3_2, 512 // 6, 4, 2)\n        fl3_1 = self._conv_layer(fl3_1 + fl1, 512 // 6, 1, 1, activation=tf.nn.relu)\n        fl4_3 = self._dconv_layer(fl4, 512 // 6, 4, 2)\n        fl4_3 = self._conv_layer(fl4_3 + fl3, 512 // 6, 1, 1, activation=tf.nn.relu)\n        fl4_2 = self._dconv_layer(fl4_3, 512 // 6, 4, 2)\n        fl4_2 = self._conv_layer(fl4_2 + fl2, 512 // 6, 1, 1, activation=tf.nn.relu)\n        fl4_1 = self._dconv_layer(fl4_2, 512 // 6, 4, 2)\n        fl4_1 = self._conv_layer(fl4_1 + fl1, 512 // 6, 1, 1, activation=tf.nn.relu)\n\n        fl1_2 = self._avg_pooling(fl1, 2, 2)\n        fl1_2 = self._conv_layer(fl1_2, 512 // 6, 1, 1)\n        fl1_3 = self._avg_pooling(fl1_2, 2, 2)\n        fl1_3 = self._conv_layer(fl1_3, 512 // 6, 1, 1)\n        fl1_4 = self._avg_pooling(fl1_3, 2, 2)\n        fl1_4 = self._conv_layer(fl1_4, 512 // 6, 1, 1)\n\n        fl2_3 = self._avg_pooling(fl2, 2, 2)\n        fl2_3 = self._conv_layer(fl2_3, 512 // 6, 1, 1)\n        fl2_4 = self._avg_pooling(fl2_3, 2, 2)\n        fl2_4 = self._conv_layer(fl2_4, 512 // 6, 1, 1)\n\n        fl3_4 = self._avg_pooling(fl3, 2, 2)\n        fl3_4 = self._conv_layer(fl3_4, 512 // 6, 1, 1)\n\n        feat1 = tf.concat(\n            [\n                fh1,\n                fl2_1,\n                fl3_1,\n                fl4_1\n            ], axis=-1 if self.data_format== \'channels_last\' else 1\n        )\n        feat2 = tf.concat(\n            [\n                fl1_2,\n                fh2,\n                fl3_2,\n                fl4_2\n            ], axis=-1 if self.data_format== \'channels_last\' else 1\n        )\n        feat3 = tf.concat(\n            [\n                fl1_3,\n                fl2_3,\n                fh3,\n                fl4_3\n            ], axis=-1 if self.data_format== \'channels_last\' else 1\n        )\n        feat4 = tf.concat(\n            [\n                fl1_4,\n                fl2_4,\n                fl3_4,\n                fh4\n            ], axis=-1 if self.data_format== \'channels_last\' else 1\n        )\n\n        stride1 = 8\n        stride2 = 16\n        stride3 = 32\n        stride4 = 64\n        return feat1, feat2, feat3, feat4, stride1, stride2, stride3, stride4\n\n    def _arm(self, bottom, scope):\n        with tf.variable_scope(scope):\n            conv1 = self._conv_layer(bottom, 256, 3, 1, activation=tf.nn.relu)\n            conv2 = self._conv_layer(conv1, 256, 3, 1, activation=tf.nn.relu)\n            conv3 = self._conv_layer(conv2, 256, 3, 1, activation=tf.nn.relu)\n            conv4 = self._conv_layer(conv3, 256, 3, 1, activation=tf.nn.relu)\n            ploc = self._conv_layer(conv4, 4*self.num_anchors, 3, 1)\n            pconf = self._conv_layer(conv4, 2*self.num_anchors, 3, 1)\n            return ploc, pconf\n\n    def _tcb(self, bottom, scope, high_level_feat=None):\n        with tf.variable_scope(scope):\n            conv1 = self._conv_layer(bottom, 256, 3, 1, activation=tf.nn.relu)\n            conv2 = self._conv_layer(conv1, 256, 3, 1)\n            if high_level_feat is not None:\n                dconv = self._dconv_layer(high_level_feat, 256, 4, 2)\n                conv2 = tf.nn.relu(conv2 + dconv)\n            conv3 = tf.nn.relu(conv2)\n            return conv3\n\n    def _odm(self, bottom, scope):\n        with tf.variable_scope(scope):\n            conv1 = self._conv_layer(bottom, 256, 3, 1, activation=tf.nn.relu)\n            conv2 = self._conv_layer(conv1, 256, 3, 1, activation=tf.nn.relu)\n            conv3 = self._conv_layer(conv2, 256, 3, 1, activation=tf.nn.relu)\n            conv4 = self._conv_layer(conv3, 256, 3, 1, activation=tf.nn.relu)\n            ploc = self._conv_layer(conv4, 4*self.num_anchors, 3, 1)\n            pconf = self._conv_layer(conv4, self.num_classes*self.num_anchors, 3, 1)\n            return ploc, pconf\n\n    def _get_armpbbox(self, ploc, pconf):\n        pconf = tf.reshape(pconf, [self.batch_size, -1, 2])\n        ploc = tf.reshape(ploc, [self.batch_size, -1, 4])\n        pbbox_yx = ploc[..., :2]\n        pbbox_hw = ploc[..., 2:]\n        return pbbox_yx, pbbox_hw, pconf\n\n    def _get_odmpbbox(self, ploc, pconf):\n        pconf = tf.reshape(pconf, [self.batch_size, -1, self.num_classes])\n        ploc = tf.reshape(ploc, [self.batch_size, -1, 4])\n        pbbox_yx = ploc[..., :2]\n        pbbox_hw = ploc[..., 2:]\n        return pbbox_yx, pbbox_hw, pconf\n\n    def _get_abbox(self, size, stride, pshape):\n        topleft_y = tf.range(0., tf.cast(pshape[1], tf.float32), dtype=tf.float32)\n        topleft_x = tf.range(0., tf.cast(pshape[2], tf.float32), dtype=tf.float32)\n        topleft_y = tf.reshape(topleft_y, [-1, 1, 1, 1]) + 0.5\n        topleft_x = tf.reshape(topleft_x, [1, -1, 1, 1]) + 0.5\n        topleft_y = tf.tile(topleft_y, [1, pshape[2], 1, 1]) * stride\n        topleft_x = tf.tile(topleft_x, [pshape[1], 1, 1, 1]) * stride\n        topleft_yx = tf.concat([topleft_y, topleft_x], -1)\n        topleft_yx = tf.tile(topleft_yx, [1, 1, self.num_anchors, 1])\n\n        priors = []\n        for ratio in self.anchor_ratios:\n            priors.append([size*(ratio**0.5), size/(ratio**0.5)])\n        priors = tf.convert_to_tensor(priors, tf.float32)\n        priors = tf.reshape(priors, [1, 1, -1, 2])\n\n        abbox_y1x1 = tf.reshape(topleft_yx - priors / 2., [-1, 2])\n        abbox_y2x2 = tf.reshape(topleft_yx + priors / 2., [-1, 2])\n        abbox_yx = abbox_y1x1 / 2. + abbox_y2x2 / 2.\n        abbox_hw = abbox_y2x2 - abbox_y1x1\n        return abbox_y1x1, abbox_y2x2, abbox_yx, abbox_hw\n\n    def _compute_one_image_loss(self, armpbbox_yx, armpbbox_hw, armpconf,\n                                odmpbbox_yx, odmpbbox_hw, odmpconf,\n                                abbox_y1x1, abbox_y2x2,\n                                abbox_yx, abbox_hw,  ground_truth):\n        slice_index = tf.argmin(ground_truth, axis=0)[0]\n        ground_truth = tf.gather(ground_truth, tf.range(0, slice_index, dtype=tf.int64))\n        gbbox_yx = ground_truth[..., 0:2]\n        gbbox_hw = ground_truth[..., 2:4]\n        gbbox_y1x1 = gbbox_yx - gbbox_hw / 2.\n        gbbox_y2x2 = gbbox_yx + gbbox_hw / 2.\n        class_id = tf.cast(ground_truth[..., 4:5], dtype=tf.int32)\n        label = class_id\n\n        abbox_hwti = tf.reshape(abbox_hw, [1, -1, 2])\n        abbox_y1x1ti = tf.reshape(abbox_y1x1, [1, -1, 2])\n        abbox_y2x2ti = tf.reshape(abbox_y2x2, [1, -1, 2])\n        gbbox_hwti = tf.reshape(gbbox_hw, [-1, 1, 2])\n        gbbox_y1x1ti = tf.reshape(gbbox_y1x1, [-1, 1, 2])\n        gbbox_y2x2ti = tf.reshape(gbbox_y2x2, [-1, 1, 2])\n        ashape = tf.shape(abbox_hwti)\n        gshape = tf.shape(gbbox_hwti)\n        abbox_hwti = tf.tile(abbox_hwti, [gshape[0], 1, 1])\n        abbox_y1x1ti = tf.tile(abbox_y1x1ti, [gshape[0], 1, 1])\n        abbox_y2x2ti = tf.tile(abbox_y2x2ti, [gshape[0], 1, 1])\n        gbbox_hwti = tf.tile(gbbox_hwti, [1, ashape[1], 1])\n        gbbox_y1x1ti = tf.tile(gbbox_y1x1ti, [1, ashape[1], 1])\n        gbbox_y2x2ti = tf.tile(gbbox_y2x2ti, [1, ashape[1], 1])\n\n        gaiou_y1x1ti = tf.maximum(abbox_y1x1ti, gbbox_y1x1ti)\n        gaiou_y2x2ti = tf.minimum(abbox_y2x2ti, gbbox_y2x2ti)\n        gaiou_area = tf.reduce_prod(tf.maximum(gaiou_y2x2ti - gaiou_y1x1ti, 0), axis=-1)\n        aarea = tf.reduce_prod(abbox_hwti, axis=-1)\n        garea = tf.reduce_prod(gbbox_hwti, axis=-1)\n        gaiou_rate = gaiou_area / (aarea + garea - gaiou_area)\n\n        best_raindex = tf.argmax(gaiou_rate, axis=1)\n        best_armpbbox_yx = tf.gather(armpbbox_yx, best_raindex)\n        best_armpbbox_hw = tf.gather(armpbbox_hw, best_raindex)\n        best_armpconf = tf.gather(armpconf, best_raindex)\n        best_odmpbbox_yx = tf.gather(odmpbbox_yx, best_raindex)\n        best_odmpbbox_hw = tf.gather(odmpbbox_hw, best_raindex)\n        best_odmpconf = tf.gather(odmpconf, best_raindex)\n        best_abbox_yx = tf.gather(abbox_yx, best_raindex)\n        best_abbox_hw = tf.gather(abbox_hw, best_raindex)\n\n        bestmask, _ = tf.unique(best_raindex)\n        bestmask = tf.contrib.framework.sort(bestmask)\n        bestmask = tf.reshape(bestmask, [-1, 1])\n        bestmask = tf.sparse.SparseTensor(tf.concat([bestmask, tf.zeros_like(bestmask)], axis=-1),\n                                          tf.squeeze(tf.ones_like(bestmask)), dense_shape=[ashape[1], 1])\n        bestmask = tf.reshape(tf.cast(tf.sparse.to_dense(bestmask), tf.float32), [-1])\n\n        othermask = 1. - bestmask\n        othermask = othermask > 0.\n        other_armpbbox_yx = tf.boolean_mask(armpbbox_yx, othermask)\n        other_armpbbox_hw = tf.boolean_mask(armpbbox_hw, othermask)\n        other_armpconf = tf.boolean_mask(armpconf, othermask)\n        other_odmpbbox_yx = tf.boolean_mask(odmpbbox_yx, othermask)\n        other_odmpbbox_hw = tf.boolean_mask(odmpbbox_hw, othermask)\n        other_odmpconf = tf.boolean_mask(odmpconf, othermask)\n        other_abbox_yx = tf.boolean_mask(abbox_yx, othermask)\n        other_abbox_hw = tf.boolean_mask(abbox_hw, othermask)\n\n        agiou_rate = tf.transpose(gaiou_rate)\n        other_agiou_rate = tf.boolean_mask(agiou_rate, othermask)\n        max_agiou_rate = tf.reduce_max(other_agiou_rate, axis=1)\n        pos_agiou_mask = max_agiou_rate > 0.5\n        neg_agiou_mask = max_agiou_rate < 0.4\n        rgindex = tf.argmax(other_agiou_rate, axis=1)\n        pos_rgindex = tf.boolean_mask(rgindex, pos_agiou_mask)\n        pos_armppox_yx = tf.boolean_mask(other_armpbbox_yx, pos_agiou_mask)\n        pos_armppox_hw = tf.boolean_mask(other_armpbbox_hw, pos_agiou_mask)\n        pos_armpconf = tf.boolean_mask(other_armpconf, pos_agiou_mask)\n        pos_odmppox_yx = tf.boolean_mask(other_odmpbbox_yx, pos_agiou_mask)\n        pos_odmppox_hw = tf.boolean_mask(other_odmpbbox_hw, pos_agiou_mask)\n        pos_odmpconf = tf.boolean_mask(other_odmpconf, pos_agiou_mask)\n        pos_abbox_yx = tf.boolean_mask(other_abbox_yx, pos_agiou_mask)\n        pos_abbox_hw = tf.boolean_mask(other_abbox_hw, pos_agiou_mask)\n        pos_odmlabel = tf.gather(label, pos_rgindex)\n        pos_gbbox_yx = tf.gather(gbbox_yx, pos_rgindex)\n        pos_gbbox_hw = tf.gather(gbbox_hw, pos_rgindex)\n        neg_armpconf = tf.boolean_mask(other_armpconf, neg_agiou_mask)\n        neg_armabbox_yx = tf.boolean_mask(other_abbox_yx, neg_agiou_mask)\n        neg_armabbox_hw = tf.boolean_mask(other_abbox_hw, neg_agiou_mask)\n        neg_armabbox_y1x1y2x2 = tf.concat([neg_armabbox_yx - neg_armabbox_hw/2., neg_armabbox_yx + neg_armabbox_hw/2.], axis=-1)\n        neg_odmpconf = tf.boolean_mask(other_odmpconf, neg_agiou_mask)\n\n        total_pos_armpbbox_yx = tf.concat([best_armpbbox_yx, pos_armppox_yx], axis=0)\n        total_pos_armpbbox_hw = tf.concat([best_armpbbox_hw, pos_armppox_hw], axis=0)\n        total_pos_armpconf = tf.concat([best_armpconf, pos_armpconf], axis=0)\n        total_pos_odmpbbox_yx = tf.concat([best_odmpbbox_yx, pos_odmppox_yx], axis=0)\n        total_pos_odmpbbox_hw = tf.concat([best_odmpbbox_hw, pos_odmppox_hw], axis=0)\n        total_pos_odmpconf = tf.concat([best_odmpconf, pos_odmpconf], axis=0)\n        total_pos_odmlabel = tf.concat([label, pos_odmlabel], axis=0)\n        total_pos_gbbox_yx = tf.concat([gbbox_yx, pos_gbbox_yx], axis=0)\n        total_pos_gbbox_hw = tf.concat([gbbox_hw, pos_gbbox_hw], axis=0)\n        total_pos_abbox_yx = tf.concat([best_abbox_yx, pos_abbox_yx], axis=0)\n        total_pos_abbox_hw = tf.concat([best_abbox_hw, pos_abbox_hw], axis=0)\n\n        num_pos = tf.shape(total_pos_odmlabel)[0]\n        num_armneg = tf.shape(neg_armpconf)[0]\n        chosen_num_armneg = tf.cond(num_armneg > 3*num_pos, lambda: 3*num_pos, lambda: num_armneg)\n        neg_armclass_id = tf.constant([1])\n        pos_armclass_id = tf.constant([0])\n        neg_armlabel = tf.tile(neg_armclass_id, [num_armneg])\n        pos_armlabel = tf.tile(pos_armclass_id, [num_pos])\n        total_neg_armloss = tf.losses.sparse_softmax_cross_entropy(neg_armlabel, neg_armpconf, reduction=tf.losses.Reduction.NONE)\n        selected_armindices = tf.image.non_max_suppression(\n            neg_armabbox_y1x1y2x2, total_neg_armloss, chosen_num_armneg, iou_threshold=0.7\n        )\n        neg_armloss = tf.reduce_mean(tf.gather(total_neg_armloss, selected_armindices))\n\n        chosen_neg_armpconf = tf.gather(neg_armpconf, selected_armindices)\n        chosen_neg_odmpconf = tf.gather(neg_odmpconf, selected_armindices)\n\n        neg_odm_mask = chosen_neg_armpconf[:, 1] < 0.99\n        chosen_neg_odmpconf = tf.boolean_mask(chosen_neg_odmpconf, neg_odm_mask)\n        chosen_num_odmneg = tf.shape(chosen_neg_odmpconf)[0]\n        neg_odmclass_id = tf.constant([self.num_classes-1])\n        neg_odmlabel = tf.tile(neg_odmclass_id, [chosen_num_odmneg])\n        neg_odmloss = tf.losses.sparse_softmax_cross_entropy(neg_odmlabel, chosen_neg_odmpconf, reduction=tf.losses.Reduction.MEAN)\n\n        pos_armconf_loss = tf.losses.sparse_softmax_cross_entropy(pos_armlabel, total_pos_armpconf, reduction=tf.losses.Reduction.MEAN)\n        pos_truth_armpbbox_yx = (total_pos_gbbox_yx - total_pos_abbox_yx) / total_pos_abbox_hw\n        pos_truth_armpbbox_hw = tf.log(total_pos_gbbox_hw / total_pos_abbox_hw)\n        pos_yx_armloss = tf.reduce_sum(self._smooth_l1_loss(total_pos_armpbbox_yx - pos_truth_armpbbox_yx), axis=-1)\n        pos_hw_armloss = tf.reduce_sum(self._smooth_l1_loss(total_pos_armpbbox_hw - pos_truth_armpbbox_hw), axis=-1)\n        pos_coord_armloss = tf.reduce_mean(pos_yx_armloss + pos_hw_armloss)\n\n        arm_yx = total_pos_armpbbox_yx * total_pos_abbox_hw + total_pos_abbox_yx\n        arm_hw = tf.exp(total_pos_armpbbox_hw) * total_pos_abbox_hw\n\n        pos_odmconf_loss = tf.losses.sparse_softmax_cross_entropy(total_pos_odmlabel, total_pos_odmpconf, reduction=tf.losses.Reduction.MEAN)\n        pos_truth_odmpbbox_yx = (total_pos_gbbox_yx - arm_yx) / arm_hw\n        pos_truth_odmpbbox_hw = tf.log(total_pos_gbbox_hw / arm_hw)\n        pos_yx_odmloss = tf.reduce_sum(self._smooth_l1_loss(total_pos_odmpbbox_yx - pos_truth_odmpbbox_yx), axis=-1)\n        pos_hw_odmloss = tf.reduce_sum(self._smooth_l1_loss(total_pos_odmpbbox_hw - pos_truth_odmpbbox_hw), axis=-1)\n        pos_coord_odmloss = tf.reduce_mean(pos_yx_odmloss + pos_hw_odmloss)\n\n        armloss = neg_armloss + pos_armconf_loss + pos_coord_armloss\n        odmloss = neg_odmloss + pos_odmconf_loss + pos_coord_odmloss\n        return armloss + odmloss\n\n    def _smooth_l1_loss(self, x):\n        return tf.where(tf.abs(x) < 1., 0.5*x*x, tf.abs(x)-0.5)\n\n    def _init_session(self):\n        self.sess = tf.InteractiveSession()\n        self.sess.run(tf.global_variables_initializer())\n        if self.mode == \'train\':\n            self.sess.run(self.train_initializer)\n\n    def _create_saver(self):\n        self.saver = tf.train.Saver()\n        self.best_saver = tf.train.Saver()\n\n    def _create_summary(self):\n        with tf.variable_scope(\'summaries\'):\n            tf.summary.scalar(\'loss\', self.loss)\n            self.summary_op = tf.summary.merge_all()\n\n    def train_one_epoch(self, lr):\n        self.is_training = True\n        self.sess.run(self.train_initializer)\n        mean_loss = []\n        num_iters = self.num_train // self.batch_size\n        for i in range(num_iters):\n            _, loss = self.sess.run([self.train_op, self.loss], feed_dict={self.lr: lr})\n            sys.stdout.write(\'\\r>> \' + \'iters \'+str(i+1)+str(\'/\')+str(num_iters)+\' loss \'+str(loss))\n            sys.stdout.flush()\n            mean_loss.append(loss)\n        sys.stdout.write(\'\\n\')\n        mean_loss = np.mean(mean_loss)\n        return mean_loss\n\n    def test_one_image(self, images):\n        self.is_training = False\n        pred = self.sess.run(self.detection_pred, feed_dict={self.images: images})\n        return pred\n\n    def save_weight(self, mode, path):\n        assert(mode in [\'latest\', \'best\'])\n        if mode == \'latest\':\n            saver = self.saver\n        else:\n            saver = self.best_saver\n        if not tf.gfile.Exists(os.path.dirname(path)):\n            tf.gfile.MakeDirs(os.path.dirname(path))\n            print(os.path.dirname(path), \'does not exist, create it done\')\n        saver.save(self.sess, path, global_step=self.global_step)\n        print(\'save\', mode, \'model in\', path, \'successfully\')\n\n    def load_weight(self, path):\n        self.saver.restore(self.sess, path)\n        print(\'load weight\', path, \'successfully\')\n\n    def _bn(self, bottom):\n        bn = tf.layers.batch_normalization(\n            inputs=bottom,\n            axis=3 if self.data_format == \'channels_last\' else 1,\n            training=self.is_training\n        )\n        return bn\n\n    def _load_conv_layer(self, bottom, filters, bias, name):\n        if self.data_format == \'channels_last\':\n            data_format = \'NHWC\'\n        else:\n            data_format = \'NCHW\'\n        conv = tf.nn.conv2d(bottom, filter=filters, strides=[1, 1, 1, 1], name=""kernel""+name, padding=""SAME"", data_format=data_format)\n        conv_bias = tf.nn.bias_add(conv, bias=bias, name=""bias""+name)\n        return tf.nn.relu(conv_bias)\n\n    def _conv_layer(self, bottom, filters, kernel_size, strides, name=None, dilation_rate=1, activation=None):\n        conv = tf.layers.conv2d(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=\'same\',\n            name=name,\n            data_format=self.data_format,\n            dilation_rate=dilation_rate,\n        )\n        bn = self._bn(conv)\n        if activation is not None:\n            bn = activation(bn)\n        return bn\n\n    def _dconv_layer(self, bottom, filters, kernel_size, strides, name=None, activation=None):\n        conv = tf.layers.conv2d_transpose(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=\'same\',\n            name=name,\n            data_format=self.data_format,\n        )\n        bn = self._bn(conv)\n        if activation is not None:\n            bn = activation(bn)\n        return bn\n\n    def _max_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.max_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding=\'same\',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _avg_pooling(self, bottom, pool_size, strides):\n        return tf.layers.average_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding=\'same\',\n            data_format=self.data_format,\n        )\n\n    def _dropout(self, bottom, name):\n        return tf.layers.dropout(\n            inputs=bottom,\n            rate=self.prob,\n            training=self.is_training,\n            name=name\n        )\n'"
RefineDet.py,282,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nfrom tensorflow.python import pywrap_tensorflow as wrap\nimport sys\nimport os\nimport numpy as np\n\n\nclass RefineDet320:\n    def __init__(self, config, data_provider):\n        assert config[\'mode\'] in [\'train\', \'test\']\n        assert config[\'data_format\'] in [\'channels_first\', \'channels_last\']\n        self.config = config\n        self.data_provider = data_provider\n        self.input_size = config[\'input_size\']\n        if config[\'data_format\'] == \'channels_last\':\n            self.data_shape = [self.input_size, self.input_size, 3]\n        else:\n            self.data_shape = [3, self.input_size, self.input_size]\n        self.num_classes = config[\'num_classes\'] + 1\n        self.weight_decay = config[\'weight_decay\']\n        self.prob = 1. - config[\'keep_prob\']\n        self.data_format = config[\'data_format\']\n        self.mode = config[\'mode\']\n        self.batch_size = config[\'batch_size\'] if config[\'mode\'] == \'train\' else 1\n        self.anchor_ratios = [0.5, 1.0, 2.0]\n        self.num_anchors = len(self.anchor_ratios)\n        self.nms_score_threshold = config[\'nms_score_threshold\']\n        self.nms_max_boxes = config[\'nms_max_boxes\']\n        self.nms_iou_threshold = config[\'nms_iou_threshold\']\n        self.reader = wrap.NewCheckpointReader(config[\'pretraining_weight\'])\n\n        if self.mode == \'train\':\n            self.num_train = data_provider[\'num_train\']\n            self.num_val = data_provider[\'num_val\']\n            self.train_generator = data_provider[\'train_generator\']\n            self.train_initializer, self.train_iterator = self.train_generator\n            if data_provider[\'val_generator\'] is not None:\n                self.val_generator = data_provider[\'val_generator\']\n                self.val_initializer, self.val_iterator = self.val_generator\n\n        self.global_step = tf.get_variable(name=\'global_step\', initializer=tf.constant(0), trainable=False)\n        self.is_training = True\n\n        self._define_inputs()\n        self._build_graph()\n        self._create_saver()\n        if self.mode == \'train\':\n            self._create_summary()\n        self._init_session()\n\n    def _define_inputs(self):\n        shape = [self.batch_size]\n        shape.extend(self.data_shape)\n        mean = tf.convert_to_tensor([123.68, 116.779, 103.979], dtype=tf.float32)\n        if self.data_format == \'channels_last\':\n            mean = tf.reshape(mean, [1, 1, 1, 3])\n        else:\n            mean = tf.reshape(mean, [1, 3, 1, 1])\n        if self.mode == \'train\':\n            self.images, self.ground_truth = self.train_iterator.get_next()\n            self.images.set_shape(shape)\n            self.images = self.images - mean\n        else:\n            self.images = tf.placeholder(tf.float32, shape, name=\'images\')\n            self.images = self.images - mean\n            self.ground_truth = tf.placeholder(tf.float32, [self.batch_size, None, 5], name=\'labels\')\n        self.lr = tf.placeholder(dtype=tf.float32, shape=[], name=\'lr\')\n\n    def _build_graph(self):\n        with tf.variable_scope(\'feature_extractor\'):\n            feat1, feat2, feat3, feat4, stride1, stride2, stride3, stride4 = self._feature_extractor(self.images)\n            axes = 3 if self.data_format == \'channels_last\' else 1\n            feat1 = tf.nn.l2_normalize(feat1, axis=axes)\n            feat1_norm_factor = tf.get_variable(\'feat1_l2_norm\', shape=[1], initializer=tf.constant_initializer(10.))\n            feat2 = tf.nn.l2_normalize(feat2, axis=axes)\n            feat2_norm_factor = tf.get_variable(\'feat2_l2_norm\', shape=[1], initializer=tf.constant_initializer(8.))\n            feat1_channels = tf.shape(feat1)[axes]\n            feat1_norm_factor = tf.tile(feat1_norm_factor, [feat1_channels])\n            feat2_channels = tf.shape(feat2)[axes]\n            feat2_norm_factor = tf.tile(feat2_norm_factor, [feat2_channels])\n            if self.data_format == \'channels_last\':\n                feat1_norm_factor = tf.reshape(feat1_norm_factor, [1, 1, 1, -1])\n                feat2_norm_factor = tf.reshape(feat2_norm_factor, [1, 1, 1, -1])\n            else:\n                feat1_norm_factor = tf.reshape(feat1_norm_factor, [1, -1, 1, 1])\n                feat2_norm_factor = tf.reshape(feat2_norm_factor, [1, 1, 1, -1])\n            feat1 = feat1_norm_factor * feat1\n            feat2 = feat2_norm_factor * feat2\n        with tf.variable_scope(\'ARM\'):\n            arm1loc, arm1conf = self._arm(feat1, \'arm1\')\n            arm2loc, arm2conf = self._arm(feat2, \'arm2\')\n            arm3loc, arm3conf = self._arm(feat3, \'arm3\')\n            arm4loc, arm4conf = self._arm(feat4, \'arm4\')\n        with tf.variable_scope(\'TCB\'):\n            tcb4 = self._tcb(feat4, \'tcb4\')\n            tcb3 = self._tcb(feat3, \'tcb3\', tcb4)\n            tcb2 = self._tcb(feat2, \'tcb2\', tcb3)\n            tcb1 = self._tcb(feat1, \'tcb1\', tcb2)\n        with tf.variable_scope(\'ODM\'):\n            odm1loc, odm1conf = self._odm(tcb1, \'odm1\')\n            odm2loc, odm2conf = self._odm(tcb2, \'odm2\')\n            odm3loc, odm3conf = self._odm(tcb3, \'odm3\')\n            odm4loc, odm4conf = self._odm(tcb4, \'odm4\')\n        with tf.variable_scope(\'inference\'):\n            if self.data_format == \'channels_first\':\n                arm1loc = tf.transpose(arm1loc, [0, 2, 3, 1])\n                arm1conf = tf.transpose(arm1conf, [0, 2, 3, 1])\n                arm2loc = tf.transpose(arm2loc, [0, 2, 3, 1])\n                arm2conf = tf.transpose(arm2conf, [0, 2, 3, 1])\n                arm3loc = tf.transpose(arm3loc, [0, 2, 3, 1])\n                arm3conf = tf.transpose(arm3conf, [0, 2, 3, 1])\n                arm4loc = tf.transpose(arm4loc, [0, 2, 3, 1])\n                arm4conf = tf.transpose(arm4conf, [0, 2, 3, 1])\n                odm1loc = tf.transpose(odm1loc, [0, 2, 3, 1])\n                odm1conf = tf.transpose(odm1conf, [0, 2, 3, 1])\n                odm2loc = tf.transpose(odm2loc, [0, 2, 3, 1])\n                odm2conf = tf.transpose(odm2conf, [0, 2, 3, 1])\n                odm3loc = tf.transpose(odm3loc, [0, 2, 3, 1])\n                odm3conf = tf.transpose(odm3conf, [0, 2, 3, 1])\n                odm4loc = tf.transpose(odm4loc, [0, 2, 3, 1])\n                odm4conf = tf.transpose(odm4conf, [0, 2, 3, 1])\n            p1shape = tf.shape(arm1loc)\n            p2shape = tf.shape(arm2loc)\n            p3shape = tf.shape(arm3loc)\n            p4shape = tf.shape(arm4loc)\n            arm1pbbox_yx, arm1pbbox_hw, arm1pconf = self._get_armpbbox(arm1loc, arm1conf)\n            arm2pbbox_yx, arm2pbbox_hw, arm2pconf = self._get_armpbbox(arm2loc, arm2conf)\n            arm3pbbox_yx, arm3pbbox_hw, arm3pconf = self._get_armpbbox(arm3loc, arm3conf)\n            arm4pbbox_yx, arm4pbbox_hw, arm4pconf = self._get_armpbbox(arm4loc, arm4conf)\n\n            odm1pbbox_yx, odm1pbbox_hw, odm1pconf = self._get_odmpbbox(odm1loc, odm1conf)\n            odm2pbbox_yx, odm2pbbox_hw, odm2pconf = self._get_odmpbbox(odm2loc, odm2conf)\n            odm3pbbox_yx, odm3pbbox_hw, odm3pconf = self._get_odmpbbox(odm3loc, odm3conf)\n            odm4pbbox_yx, odm4pbbox_hw, odm4pconf = self._get_odmpbbox(odm4loc, odm4conf)\n\n            a1bbox_y1x1, a1bbox_y2x2, a1bbox_yx, a1bbox_hw = self._get_abbox(stride1*4, stride1, p1shape)\n            a2bbox_y1x1, a2bbox_y2x2, a2bbox_yx, a2bbox_hw = self._get_abbox(stride2*4, stride2, p2shape)\n            a3bbox_y1x1, a3bbox_y2x2, a3bbox_yx, a3bbox_hw = self._get_abbox(stride3*4, stride3, p3shape)\n            a4bbox_y1x1, a4bbox_y2x2, a4bbox_yx, a4bbox_hw = self._get_abbox(stride4*4, stride4, p4shape)\n\n            armpbbox_yx = tf.concat([arm1pbbox_yx, arm2pbbox_yx, arm3pbbox_yx, arm4pbbox_yx], axis=1)\n            armpbbox_hw = tf.concat([arm1pbbox_hw, arm2pbbox_hw, arm3pbbox_hw, arm4pbbox_hw], axis=1)\n            armpconf = tf.concat([arm1pconf, arm2pconf, arm3pconf, arm4pconf], axis=1)\n            odmpbbox_yx = tf.concat([odm1pbbox_yx, odm2pbbox_yx, odm3pbbox_yx, odm4pbbox_yx], axis=1)\n            odmpbbox_hw = tf.concat([odm1pbbox_hw, odm2pbbox_hw, odm3pbbox_hw, odm4pbbox_hw], axis=1)\n            odmpconf = tf.concat([odm1pconf, odm2pconf, odm3pconf, odm4pconf], axis=1)\n            abbox_y1x1 = tf.concat([a1bbox_y1x1, a2bbox_y1x1, a3bbox_y1x1, a4bbox_y1x1], axis=0)\n            abbox_y2x2 = tf.concat([a1bbox_y2x2, a2bbox_y2x2, a3bbox_y2x2, a4bbox_y2x2], axis=0)\n            abbox_yx = tf.concat([a1bbox_yx, a2bbox_yx, a3bbox_yx, a4bbox_yx], axis=0)\n            abbox_hw = tf.concat([a1bbox_hw, a2bbox_hw, a3bbox_hw, a4bbox_hw], axis=0)\n            if self.mode == \'train\':\n                i = 0.\n                loss = 0.\n                cond = lambda loss, i: tf.less(i, tf.cast(self.batch_size, tf.float32))\n                body = lambda loss, i: (\n                    tf.add(loss, self._compute_one_image_loss(\n                        tf.squeeze(tf.gather(armpbbox_yx, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(armpbbox_hw, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(armpconf, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(odmpbbox_yx, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(odmpbbox_hw, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(odmpconf, tf.cast(i, tf.int32))),\n                        abbox_y1x1,\n                        abbox_y2x2,\n                        abbox_yx,\n                        abbox_hw,\n                        tf.squeeze(tf.gather(self.ground_truth, tf.cast(i, tf.int32))),\n                    )),\n                    tf.add(i, 1.)\n                )\n                init_state = (loss, i)\n                state = tf.while_loop(cond, body, init_state)\n                total_loss, _ = state\n                total_loss = total_loss / self.batch_size\n                optimizer = tf.train.MomentumOptimizer(learning_rate=self.lr, momentum=.9)\n                self.loss = total_loss + self.weight_decay * tf.add_n(\n                    [tf.nn.l2_loss(var) for var in tf.trainable_variables()]\n                )\n                train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n                update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n                self.train_op = tf.group([update_ops, train_op])\n            else:\n                armconft = tf.nn.softmax(armpconf[0, ...])\n                odmconft = tf.nn.softmax(odmpconf[0, ...])\n                armmask = armconft[:, 1] < 0.99\n                odmmask = tf.argmax(odmconft, axis=-1) < self.num_classes - 1\n                mask = (tf.cast(armmask, tf.float32) * tf.cast(odmmask, tf.float32)) > 0.\n                armpbbox_yxt = tf.boolean_mask(armpbbox_yx[0, ...], mask)\n                armpbbox_hwt = tf.boolean_mask(armpbbox_hw[0, ...], mask)\n                odmpbbox_yxt = tf.boolean_mask(odmpbbox_yx[0, ...], mask)\n                odmpbbox_hwt = tf.boolean_mask(odmpbbox_hw[0, ...], mask)\n                abbox_yxt = tf.boolean_mask(abbox_yx, mask)\n                abbox_hwt = tf.boolean_mask(abbox_hw, mask)\n                odmconft = tf.boolean_mask(odmconft, mask)\n                confidence = odmconft[..., :self.num_classes-1]\n\n                arm_yx = armpbbox_yxt * abbox_hwt + abbox_yxt\n                arm_hw = tf.exp(armpbbox_hwt) * abbox_hwt\n                odm_yx = odmpbbox_yxt * arm_hw + arm_yx\n                odm_hw = tf.exp(odmpbbox_hwt) * arm_hw\n\n                odm_y1x1 = odm_yx - odm_hw / 2.\n                odm_y2x2 = odm_yx + odm_hw / 2.\n                odm_y1x1y2x2 = tf.concat([odm_y1x1, odm_y2x2], axis=-1)\n                filter_mask = tf.greater_equal(confidence, self.nms_score_threshold)\n                scores = []\n                class_id = []\n                bbox = []\n                for i in range(self.num_classes-1):\n                    scoresi = tf.boolean_mask(confidence[:, i], filter_mask[:, i])\n                    bboxi = tf.boolean_mask(odm_y1x1y2x2, filter_mask[:, i])\n                    selected_indices = tf.image.non_max_suppression(\n\n                        bboxi, scoresi, self.nms_max_boxes, self.nms_iou_threshold,\n                    )\n                    scores.append(tf.gather(scoresi, selected_indices))\n                    bbox.append(tf.gather(bboxi, selected_indices))\n                    class_id.append(tf.ones_like(tf.gather(scoresi, selected_indices), tf.int32) * i)\n                bbox = tf.concat(bbox, axis=0)\n                scores = tf.concat(scores, axis=0)\n                class_id = tf.concat(class_id, axis=0)\n\n                self.detection_pred = [scores, bbox, class_id]\n\n    def _feature_extractor(self, images):\n        conv1_1 = self._load_conv_layer(images,\n                                        tf.get_variable(name=\'kernel_conv1_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv1_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_1/biases""),\n                                                        trainable=True),\n                                        name=""conv1_1"")\n        conv1_2 = self._load_conv_layer(conv1_1,\n                                        tf.get_variable(name=\'kernel_conv1_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv1_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_2/biases""),\n                                                        trainable=True),\n                                        name=""conv1_2"")\n        pool1 = self._max_pooling(conv1_2, 2, 2, name=""pool1"")\n\n        conv2_1 = self._load_conv_layer(pool1,\n                                        tf.get_variable(name=\'kenrel_conv2_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv2_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_1/biases""),\n                                                        trainable=True),\n                                        name=""conv2_1"")\n        conv2_2 = self._load_conv_layer(conv2_1,\n                                        tf.get_variable(name=\'kernel_conv2_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv2_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_2/biases""),\n                                                        trainable=True),\n                                        name=""conv2_2"")\n        pool2 = self._max_pooling(conv2_2, 2, 2, name=""pool2"")\n        conv3_1 = self._load_conv_layer(pool2,\n                                        tf.get_variable(name=\'kernel_conv3_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv_3_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_1/biases""),\n                                                        trainable=True),\n                                        name=""conv3_1"")\n        conv3_2 = self._load_conv_layer(conv3_1,\n                                        tf.get_variable(name=\'kernel_conv3_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv3_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_2/biases""),\n                                                        trainable=True),\n                                        name=""conv3_2"")\n        conv3_3 = self._load_conv_layer(conv3_2,\n                                        tf.get_variable(name=\'kernel_conv3_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_3/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv3_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_3/biases""),\n                                                        trainable=True),\n                                        name=""conv3_3"")\n        pool3 = self._max_pooling(conv3_3, 2, 2, name=""pool3"")\n\n        conv4_1 = self._load_conv_layer(pool3,\n                                        tf.get_variable(name=\'kernel_conv4_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv4_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_1/biases""),\n                                                        trainable=True),\n                                        name=""conv4_1"")\n        conv4_2 = self._load_conv_layer(conv4_1,\n                                        tf.get_variable(name=\'kernel_conv4_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv4_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_2/biases""),\n                                                        trainable=True),\n                                        name=""conv4_2"")\n        conv4_3 = self._load_conv_layer(conv4_2,\n                                        tf.get_variable(name=\'kernel_conv4_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_3/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv4_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_3/biases""),\n                                                        trainable=True),\n                                        name=""conv4_3"")\n        pool4 = self._max_pooling(conv4_3, 2, 2, name=""pool4"")\n        conv5_1 = self._load_conv_layer(pool4,\n                                        tf.get_variable(name=\'kernel_conv5_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv5_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_1/biases""),\n                                                        trainable=True),\n                                        name=""conv5_1"")\n        conv5_2 = self._load_conv_layer(conv5_1,\n                                        tf.get_variable(name=\'kernel_conv5_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv5_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_2/biases""),\n                                                        trainable=True),\n                                        name=""conv5_2"")\n        conv5_3 = self._load_conv_layer(conv5_2,\n                                        tf.get_variable(name=\'kernel_conv5_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_3/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv5_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_3/biases""),\n                                                        trainable=True),\n                                        name=""conv5_3"")\n        pool5 = self._max_pooling(conv5_3, 3, 1, \'pool5\')\n        conv6 = self._conv_layer(pool5, 1024, 3, 1, \'conv6\', dilation_rate=2, activation=tf.nn.relu)\n        conv7 = self._conv_layer(conv6, 1024, 1, 1, \'conv7\', activation=tf.nn.relu)\n        conv8_1 = self._conv_layer(conv7, 256, 1, 1, \'conv8_1\', activation=tf.nn.relu)\n        conv8_2 = self._conv_layer(conv8_1, 512, 3, 2, \'conv8_2\', activation=tf.nn.relu)\n        conv9_1 = self._conv_layer(conv8_2, 256, 1, 1, \'conv9_1\', activation=tf.nn.relu)\n        conv9_2 = self._conv_layer(conv9_1, 512, 3, 2, \'conv9_2\', activation=tf.nn.relu)\n        conv10_1 = self._conv_layer(conv9_2, 256, 1, 1, \'conv10_1\', activation=tf.nn.relu)\n        conv10_2 = self._conv_layer(conv10_1, 256, 3, 1, \'conv10_2\', activation=tf.nn.relu)\n        stride1 = 8\n        stride2 = 16\n        stride3 = 32\n        stride4 = 64\n        return conv4_3, conv5_3, conv8_2, conv10_2, stride1, stride2, stride3, stride4\n\n    def _arm(self, bottom, scope):\n        with tf.variable_scope(scope):\n            conv1 = self._conv_layer(bottom, 256, 3, 1, activation=tf.nn.relu)\n            conv2 = self._conv_layer(conv1, 256, 3, 1, activation=tf.nn.relu)\n            conv3 = self._conv_layer(conv2, 256, 3, 1, activation=tf.nn.relu)\n            conv4 = self._conv_layer(conv3, 256, 3, 1, activation=tf.nn.relu)\n            ploc = self._conv_layer(conv4, 4*self.num_anchors, 3, 1)\n            pconf = self._conv_layer(conv4, 2*self.num_anchors, 3, 1)\n            return ploc, pconf\n\n    def _tcb(self, bottom, scope, high_level_feat=None):\n        with tf.variable_scope(scope):\n            conv1 = self._conv_layer(bottom, 256, 3, 1, activation=tf.nn.relu)\n            conv2 = self._conv_layer(conv1, 256, 3, 1)\n            if high_level_feat is not None:\n                dconv = self._dconv_layer(high_level_feat, 256, 4, 2)\n                conv2 = tf.nn.relu(conv2 + dconv)\n            conv3 = tf.nn.relu(conv2)\n            return conv3\n\n    def _odm(self, bottom, scope):\n        with tf.variable_scope(scope):\n            conv1 = self._conv_layer(bottom, 256, 3, 1, activation=tf.nn.relu)\n            conv2 = self._conv_layer(conv1, 256, 3, 1, activation=tf.nn.relu)\n            conv3 = self._conv_layer(conv2, 256, 3, 1, activation=tf.nn.relu)\n            conv4 = self._conv_layer(conv3, 256, 3, 1, activation=tf.nn.relu)\n            ploc = self._conv_layer(conv4, 4*self.num_anchors, 3, 1)\n            pconf = self._conv_layer(conv4, self.num_classes*self.num_anchors, 3, 1)\n            return ploc, pconf\n\n    def _get_armpbbox(self, ploc, pconf):\n        pconf = tf.reshape(pconf, [self.batch_size, -1, 2])\n        ploc = tf.reshape(ploc, [self.batch_size, -1, 4])\n        pbbox_yx = ploc[..., :2]\n        pbbox_hw = ploc[..., 2:]\n        return pbbox_yx, pbbox_hw, pconf\n\n    def _get_odmpbbox(self, ploc, pconf):\n        pconf = tf.reshape(pconf, [self.batch_size, -1, self.num_classes])\n        ploc = tf.reshape(ploc, [self.batch_size, -1, 4])\n        pbbox_yx = ploc[..., :2]\n        pbbox_hw = ploc[..., 2:]\n        return pbbox_yx, pbbox_hw, pconf\n\n    def _get_abbox(self, size, stride, pshape):\n        topleft_y = tf.range(0., tf.cast(pshape[1], tf.float32), dtype=tf.float32)\n        topleft_x = tf.range(0., tf.cast(pshape[2], tf.float32), dtype=tf.float32)\n        topleft_y = tf.reshape(topleft_y, [-1, 1, 1, 1]) + 0.5\n        topleft_x = tf.reshape(topleft_x, [1, -1, 1, 1]) + 0.5\n        topleft_y = tf.tile(topleft_y, [1, pshape[2], 1, 1]) * stride\n        topleft_x = tf.tile(topleft_x, [pshape[1], 1, 1, 1]) * stride\n        topleft_yx = tf.concat([topleft_y, topleft_x], -1)\n        topleft_yx = tf.tile(topleft_yx, [1, 1, self.num_anchors, 1])\n\n        priors = []\n        for ratio in self.anchor_ratios:\n            priors.append([size*(ratio**0.5), size/(ratio**0.5)])\n        priors = tf.convert_to_tensor(priors, tf.float32)\n        priors = tf.reshape(priors, [1, 1, -1, 2])\n\n        abbox_y1x1 = tf.reshape(topleft_yx - priors / 2., [-1, 2])\n        abbox_y2x2 = tf.reshape(topleft_yx + priors / 2., [-1, 2])\n        abbox_yx = abbox_y1x1 / 2. + abbox_y2x2 / 2.\n        abbox_hw = abbox_y2x2 - abbox_y1x1\n        return abbox_y1x1, abbox_y2x2, abbox_yx, abbox_hw\n\n    def _compute_one_image_loss(self, armpbbox_yx, armpbbox_hw, armpconf,\n                                odmpbbox_yx, odmpbbox_hw, odmpconf,\n                                abbox_y1x1, abbox_y2x2,\n                                abbox_yx, abbox_hw,  ground_truth):\n        slice_index = tf.argmin(ground_truth, axis=0)[0]\n        ground_truth = tf.gather(ground_truth, tf.range(0, slice_index, dtype=tf.int64))\n        gbbox_yx = ground_truth[..., 0:2]\n        gbbox_hw = ground_truth[..., 2:4]\n        gbbox_y1x1 = gbbox_yx - gbbox_hw / 2.\n        gbbox_y2x2 = gbbox_yx + gbbox_hw / 2.\n        class_id = tf.cast(ground_truth[..., 4:5], dtype=tf.int32)\n        label = class_id\n\n        abbox_hwti = tf.reshape(abbox_hw, [1, -1, 2])\n        abbox_y1x1ti = tf.reshape(abbox_y1x1, [1, -1, 2])\n        abbox_y2x2ti = tf.reshape(abbox_y2x2, [1, -1, 2])\n        gbbox_hwti = tf.reshape(gbbox_hw, [-1, 1, 2])\n        gbbox_y1x1ti = tf.reshape(gbbox_y1x1, [-1, 1, 2])\n        gbbox_y2x2ti = tf.reshape(gbbox_y2x2, [-1, 1, 2])\n        ashape = tf.shape(abbox_hwti)\n        gshape = tf.shape(gbbox_hwti)\n        abbox_hwti = tf.tile(abbox_hwti, [gshape[0], 1, 1])\n        abbox_y1x1ti = tf.tile(abbox_y1x1ti, [gshape[0], 1, 1])\n        abbox_y2x2ti = tf.tile(abbox_y2x2ti, [gshape[0], 1, 1])\n        gbbox_hwti = tf.tile(gbbox_hwti, [1, ashape[1], 1])\n        gbbox_y1x1ti = tf.tile(gbbox_y1x1ti, [1, ashape[1], 1])\n        gbbox_y2x2ti = tf.tile(gbbox_y2x2ti, [1, ashape[1], 1])\n\n        gaiou_y1x1ti = tf.maximum(abbox_y1x1ti, gbbox_y1x1ti)\n        gaiou_y2x2ti = tf.minimum(abbox_y2x2ti, gbbox_y2x2ti)\n        gaiou_area = tf.reduce_prod(tf.maximum(gaiou_y2x2ti - gaiou_y1x1ti, 0), axis=-1)\n        aarea = tf.reduce_prod(abbox_hwti, axis=-1)\n        garea = tf.reduce_prod(gbbox_hwti, axis=-1)\n        gaiou_rate = gaiou_area / (aarea + garea - gaiou_area)\n\n        best_raindex = tf.argmax(gaiou_rate, axis=1)\n        best_armpbbox_yx = tf.gather(armpbbox_yx, best_raindex)\n        best_armpbbox_hw = tf.gather(armpbbox_hw, best_raindex)\n        best_armpconf = tf.gather(armpconf, best_raindex)\n        best_odmpbbox_yx = tf.gather(odmpbbox_yx, best_raindex)\n        best_odmpbbox_hw = tf.gather(odmpbbox_hw, best_raindex)\n        best_odmpconf = tf.gather(odmpconf, best_raindex)\n        best_abbox_yx = tf.gather(abbox_yx, best_raindex)\n        best_abbox_hw = tf.gather(abbox_hw, best_raindex)\n\n        bestmask, _ = tf.unique(best_raindex)\n        bestmask = tf.contrib.framework.sort(bestmask)\n        bestmask = tf.reshape(bestmask, [-1, 1])\n        bestmask = tf.sparse.SparseTensor(tf.concat([bestmask, tf.zeros_like(bestmask)], axis=-1),\n                                          tf.squeeze(tf.ones_like(bestmask)), dense_shape=[ashape[1], 1])\n        bestmask = tf.reshape(tf.cast(tf.sparse.to_dense(bestmask), tf.float32), [-1])\n\n        othermask = 1. - bestmask\n        othermask = othermask > 0.\n        other_armpbbox_yx = tf.boolean_mask(armpbbox_yx, othermask)\n        other_armpbbox_hw = tf.boolean_mask(armpbbox_hw, othermask)\n        other_armpconf = tf.boolean_mask(armpconf, othermask)\n        other_odmpbbox_yx = tf.boolean_mask(odmpbbox_yx, othermask)\n        other_odmpbbox_hw = tf.boolean_mask(odmpbbox_hw, othermask)\n        other_odmpconf = tf.boolean_mask(odmpconf, othermask)\n        other_abbox_yx = tf.boolean_mask(abbox_yx, othermask)\n        other_abbox_hw = tf.boolean_mask(abbox_hw, othermask)\n\n        agiou_rate = tf.transpose(gaiou_rate)\n        other_agiou_rate = tf.boolean_mask(agiou_rate, othermask)\n        max_agiou_rate = tf.reduce_max(other_agiou_rate, axis=1)\n        pos_agiou_mask = max_agiou_rate > 0.5\n        neg_agiou_mask = max_agiou_rate < 0.4\n        rgindex = tf.argmax(other_agiou_rate, axis=1)\n        pos_rgindex = tf.boolean_mask(rgindex, pos_agiou_mask)\n        pos_armppox_yx = tf.boolean_mask(other_armpbbox_yx, pos_agiou_mask)\n        pos_armppox_hw = tf.boolean_mask(other_armpbbox_hw, pos_agiou_mask)\n        pos_armpconf = tf.boolean_mask(other_armpconf, pos_agiou_mask)\n        pos_odmppox_yx = tf.boolean_mask(other_odmpbbox_yx, pos_agiou_mask)\n        pos_odmppox_hw = tf.boolean_mask(other_odmpbbox_hw, pos_agiou_mask)\n        pos_odmpconf = tf.boolean_mask(other_odmpconf, pos_agiou_mask)\n        pos_abbox_yx = tf.boolean_mask(other_abbox_yx, pos_agiou_mask)\n        pos_abbox_hw = tf.boolean_mask(other_abbox_hw, pos_agiou_mask)\n        pos_odmlabel = tf.gather(label, pos_rgindex)\n        pos_gbbox_yx = tf.gather(gbbox_yx, pos_rgindex)\n        pos_gbbox_hw = tf.gather(gbbox_hw, pos_rgindex)\n        neg_armpconf = tf.boolean_mask(other_armpconf, neg_agiou_mask)\n        neg_armabbox_yx = tf.boolean_mask(other_abbox_yx, neg_agiou_mask)\n        neg_armabbox_hw = tf.boolean_mask(other_abbox_hw, neg_agiou_mask)\n        neg_armabbox_y1x1y2x2 = tf.concat([neg_armabbox_yx - neg_armabbox_hw/2., neg_armabbox_yx + neg_armabbox_hw/2.], axis=-1)\n        neg_odmpconf = tf.boolean_mask(other_odmpconf, neg_agiou_mask)\n\n        total_pos_armpbbox_yx = tf.concat([best_armpbbox_yx, pos_armppox_yx], axis=0)\n        total_pos_armpbbox_hw = tf.concat([best_armpbbox_hw, pos_armppox_hw], axis=0)\n        total_pos_armpconf = tf.concat([best_armpconf, pos_armpconf], axis=0)\n        total_pos_odmpbbox_yx = tf.concat([best_odmpbbox_yx, pos_odmppox_yx], axis=0)\n        total_pos_odmpbbox_hw = tf.concat([best_odmpbbox_hw, pos_odmppox_hw], axis=0)\n        total_pos_odmpconf = tf.concat([best_odmpconf, pos_odmpconf], axis=0)\n        total_pos_odmlabel = tf.concat([label, pos_odmlabel], axis=0)\n        total_pos_gbbox_yx = tf.concat([gbbox_yx, pos_gbbox_yx], axis=0)\n        total_pos_gbbox_hw = tf.concat([gbbox_hw, pos_gbbox_hw], axis=0)\n        total_pos_abbox_yx = tf.concat([best_abbox_yx, pos_abbox_yx], axis=0)\n        total_pos_abbox_hw = tf.concat([best_abbox_hw, pos_abbox_hw], axis=0)\n\n        num_pos = tf.shape(total_pos_odmlabel)[0]\n        num_armneg = tf.shape(neg_armpconf)[0]\n        chosen_num_armneg = tf.cond(num_armneg > 3*num_pos, lambda: 3*num_pos, lambda: num_armneg)\n        neg_armclass_id = tf.constant([1])\n        pos_armclass_id = tf.constant([0])\n        neg_armlabel = tf.tile(neg_armclass_id, [num_armneg])\n        pos_armlabel = tf.tile(pos_armclass_id, [num_pos])\n        total_neg_armloss = tf.losses.sparse_softmax_cross_entropy(neg_armlabel, neg_armpconf, reduction=tf.losses.Reduction.NONE)\n        selected_armindices = tf.image.non_max_suppression(\n            neg_armabbox_y1x1y2x2, total_neg_armloss, chosen_num_armneg, iou_threshold=0.7\n        )\n        neg_armloss = tf.reduce_mean(tf.gather(total_neg_armloss, selected_armindices))\n\n        chosen_neg_armpconf = tf.gather(neg_armpconf, selected_armindices)\n        chosen_neg_odmpconf = tf.gather(neg_odmpconf, selected_armindices)\n\n        neg_odm_mask = chosen_neg_armpconf[:, 1] < 0.99\n        chosen_neg_odmpconf = tf.boolean_mask(chosen_neg_odmpconf, neg_odm_mask)\n        chosen_num_odmneg = tf.shape(chosen_neg_odmpconf)[0]\n        neg_odmclass_id = tf.constant([self.num_classes-1])\n        neg_odmlabel = tf.tile(neg_odmclass_id, [chosen_num_odmneg])\n        neg_odmloss = tf.losses.sparse_softmax_cross_entropy(neg_odmlabel, chosen_neg_odmpconf, reduction=tf.losses.Reduction.MEAN)\n\n        pos_armconf_loss = tf.losses.sparse_softmax_cross_entropy(pos_armlabel, total_pos_armpconf, reduction=tf.losses.Reduction.MEAN)\n        pos_truth_armpbbox_yx = (total_pos_gbbox_yx - total_pos_abbox_yx) / total_pos_abbox_hw\n        pos_truth_armpbbox_hw = tf.log(total_pos_gbbox_hw / total_pos_abbox_hw)\n        pos_yx_armloss = tf.reduce_sum(self._smooth_l1_loss(total_pos_armpbbox_yx - pos_truth_armpbbox_yx), axis=-1)\n        pos_hw_armloss = tf.reduce_sum(self._smooth_l1_loss(total_pos_armpbbox_hw - pos_truth_armpbbox_hw), axis=-1)\n        pos_coord_armloss = tf.reduce_mean(pos_yx_armloss + pos_hw_armloss)\n\n        arm_yx = total_pos_armpbbox_yx * total_pos_abbox_hw + total_pos_abbox_yx\n        arm_hw = tf.exp(total_pos_armpbbox_hw) * total_pos_abbox_hw\n\n        pos_odmconf_loss = tf.losses.sparse_softmax_cross_entropy(total_pos_odmlabel, total_pos_odmpconf, reduction=tf.losses.Reduction.MEAN)\n        pos_truth_odmpbbox_yx = (total_pos_gbbox_yx - arm_yx) / arm_hw\n        pos_truth_odmpbbox_hw = tf.log(total_pos_gbbox_hw / arm_hw)\n        pos_yx_odmloss = tf.reduce_sum(self._smooth_l1_loss(total_pos_odmpbbox_yx - pos_truth_odmpbbox_yx), axis=-1)\n        pos_hw_odmloss = tf.reduce_sum(self._smooth_l1_loss(total_pos_odmpbbox_hw - pos_truth_odmpbbox_hw), axis=-1)\n        pos_coord_odmloss = tf.reduce_mean(pos_yx_odmloss + pos_hw_odmloss)\n\n        armloss = neg_armloss + pos_armconf_loss + pos_coord_armloss\n        odmloss = neg_odmloss + pos_odmconf_loss + pos_coord_odmloss\n        return armloss + odmloss\n\n    def _smooth_l1_loss(self, x):\n        return tf.where(tf.abs(x) < 1., 0.5*x*x, tf.abs(x)-0.5)\n\n    def _init_session(self):\n        self.sess = tf.InteractiveSession()\n        self.sess.run(tf.global_variables_initializer())\n        if self.mode == \'train\':\n            self.sess.run(self.train_initializer)\n\n    def _create_saver(self):\n        self.saver = tf.train.Saver()\n        self.best_saver = tf.train.Saver()\n\n    def _create_summary(self):\n        with tf.variable_scope(\'summaries\'):\n            tf.summary.scalar(\'loss\', self.loss)\n            self.summary_op = tf.summary.merge_all()\n\n    def train_one_epoch(self, lr):\n        self.is_training = True\n        self.sess.run(self.train_initializer)\n        mean_loss = []\n        num_iters = self.num_train // self.batch_size\n        for i in range(num_iters):\n            _, loss = self.sess.run([self.train_op, self.loss], feed_dict={self.lr: lr})\n            sys.stdout.write(\'\\r>> \' + \'iters \'+str(i+1)+str(\'/\')+str(num_iters)+\' loss \'+str(loss))\n            sys.stdout.flush()\n            mean_loss.append(loss)\n        sys.stdout.write(\'\\n\')\n        mean_loss = np.mean(mean_loss)\n        return mean_loss\n\n    def test_one_image(self, images):\n        self.is_training = False\n        pred = self.sess.run(self.detection_pred, feed_dict={self.images: images})\n        return pred\n\n    def save_weight(self, mode, path):\n        assert(mode in [\'latest\', \'best\'])\n        if mode == \'latest\':\n            saver = self.saver\n        else:\n            saver = self.best_saver\n        if not tf.gfile.Exists(os.path.dirname(path)):\n            tf.gfile.MakeDirs(os.path.dirname(path))\n            print(os.path.dirname(path), \'does not exist, create it done\')\n        saver.save(self.sess, path, global_step=self.global_step)\n        print(\'save\', mode, \'model in\', path, \'successfully\')\n\n    def load_weight(self, path):\n        self.saver.restore(self.sess, path)\n        print(\'load weight\', path, \'successfully\')\n\n    def _bn(self, bottom):\n        bn = tf.layers.batch_normalization(\n            inputs=bottom,\n            axis=3 if self.data_format == \'channels_last\' else 1,\n            training=self.is_training\n        )\n        return bn\n\n    def _load_conv_layer(self, bottom, filters, bias, name):\n        if self.data_format == \'channels_last\':\n            data_format = \'NHWC\'\n        else:\n            data_format = \'NCHW\'\n        conv = tf.nn.conv2d(bottom, filter=filters, strides=[1, 1, 1, 1], name=""kernel""+name, padding=""SAME"", data_format=data_format)\n        conv_bias = tf.nn.bias_add(conv, bias=bias, name=""bias""+name)\n        return tf.nn.relu(conv_bias)\n\n    def _conv_layer(self, bottom, filters, kernel_size, strides, name=None, dilation_rate=1, activation=None):\n        conv = tf.layers.conv2d(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=\'same\',\n            name=name,\n            data_format=self.data_format,\n            dilation_rate=dilation_rate,\n        )\n        bn = self._bn(conv)\n        if activation is not None:\n            bn = activation(bn)\n        return bn\n\n    def _dconv_layer(self, bottom, filters, kernel_size, strides, name=None, activation=None):\n        conv = tf.layers.conv2d_transpose(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=\'same\',\n            name=name,\n            data_format=self.data_format,\n        )\n        bn = self._bn(conv)\n        if activation is not None:\n            bn = activation(bn)\n        return bn\n\n    def _max_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.max_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding=\'same\',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _avg_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.average_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding=\'same\',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _dropout(self, bottom, name):\n        return tf.layers.dropout(\n            inputs=bottom,\n            rate=self.prob,\n            training=self.is_training,\n            name=name\n        )\n'"
RetinaNet.py,227,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nimport os\nimport sys\nimport numpy as np\nimport math\n\n\nclass RetinaNet:\n    def __init__(self, config, data_provider):\n\n        assert len(config['data_shape']) == 3\n        assert config['mode'] in ['train', 'test']\n        assert config['data_format'] in ['channels_first', 'channels_last']\n        self.config = config\n        self.data_provider = data_provider\n\n        self.init_conv_kernel_size = 7\n        self.init_conv_strides = 2  # must be 2 for construct pyramid\n        self.init_pooling_pool_size = 3\n        self.init_pooling_strides = 2  # must be 2 for construct pyramid\n\n        self.is_bottleneck = config['is_bottleneck']\n        self.block_list = config['residual_block_list']\n        self.filters_list = [self.init_conv_kernel_size * (2 ** i) for i in range(len(config['residual_block_list']))]\n        self.is_pretraining = config['is_pretraining']\n        self.data_shape = config['data_shape']\n        self.num_classes = config['num_classes'] + 1\n        self.weight_decay = config['weight_decay']\n        self.prob = 1. - config['keep_prob']\n        self.data_format = config['data_format']\n        self.mode = config['mode']\n        self.batch_size = config['batch_size'] if config['mode'] == 'train' else 1\n        self.gamma = config['gamma']\n        self.alpha = config['alpha']\n\n        self.anchors = [32, 64, 128, 256, 512]\n        self.aspect_ratios = [1, 1/2, 2]\n        self.anchor_size = [2**0, 2**(1/3), 2**(2/3)]\n        self.num_anchors = len(self.aspect_ratios) * len(self.anchor_size)\n        self.nms_score_threshold = config['nms_score_threshold']\n        self.nms_max_boxes = config['nms_max_boxes']\n        self.nms_iou_threshold = config['nms_iou_threshold']\n\n        # pi for initialize final conv layer for classifier\n        self.pi = 0.01\n\n        if self.mode == 'train':\n            self.num_train = data_provider['num_train']\n            self.num_val = data_provider['num_val']\n            self.train_generator = data_provider['train_generator']\n            self.train_initializer, self.train_iterator = self.train_generator\n            if data_provider['val_generator'] is not None:\n                self.val_generator = data_provider['val_generator']\n                self.val_initializer, self.val_iterator = self.val_generator\n\n        self.global_step = tf.get_variable(name='global_step', initializer=tf.constant(0), trainable=False)\n        self.is_training = True\n\n        if self.is_pretraining:\n            self._define_pretraining_inputs()\n            self._build_pretraining_graph()\n            self._create_pretraining_saver()\n            self.save_weight = self._save_pretraining_weight\n            self.train_one_epoch = self._train_pretraining_epoch\n            self.test_one_image = self._test_one_pretraining_image\n            if self.mode == 'train':\n                self._create_pretraining_summary()\n        else:\n            self._define_detection_inputs()\n            self._build_detection_graph()\n            self._create_detection_saver()\n            self.save_weight = self._save_detection_weight\n            self.train_one_epoch = self._train_detection_epoch\n            self.test_one_image = self._test_one_detection_image\n            if self.mode == 'train':\n                self._create_detection_summary()\n        self._init_session()\n\n    def _define_pretraining_inputs(self):\n        shape = [self.batch_size]\n        shape.extend(self.data_shape)\n        mean = tf.convert_to_tensor([123.68, 116.779, 103.979], dtype=tf.float32)\n        if self.data_format == 'channels_last':\n            mean = tf.reshape(mean, [1, 1, 1, 3])\n        else:\n            mean = tf.reshape(mean, [1, 3, 1, 1])\n        if self.mode == 'train':\n            self.images, self.labels = self.train_iterator.get_next()\n            self.images.set_shape(shape)\n            self.images = self.images - mean\n            self.labels = tf.cast(self.labels, tf.int32)\n        else:\n            self.images = tf.placeholder(tf.float32, shape, name='images')\n            self.images = self.images - mean\n            self.labels = tf.placeholder(tf.int32, [self.batch_size, 1], name='labels')\n        self.lr = tf.placeholder(dtype=tf.float32, shape=[], name='lr')\n\n    def _define_detection_inputs(self):\n        shape = [self.batch_size]\n        shape.extend(self.data_shape)\n        mean = tf.convert_to_tensor([123.68, 116.779, 103.979], dtype=tf.float32)\n        if self.data_format == 'channels_last':\n            mean = tf.reshape(mean, [1, 1, 1, 3])\n        else:\n            mean = tf.reshape(mean, [1, 3, 1, 1])\n        if self.mode == 'train':\n            self.images, self.ground_truth = self.train_iterator.get_next()\n            self.images.set_shape(shape)\n            self.images = self.images - mean\n        else:\n            self.images = tf.placeholder(tf.float32, shape, name='images')\n            self.images = self.images - mean\n            self.ground_truth = tf.placeholder(tf.float32, [self.batch_size, None, 5], name='labels')\n        self.lr = tf.placeholder(dtype=tf.float32, shape=[], name='lr')\n\n    def _build_pretraining_graph(self):\n        with tf.variable_scope('feature_extractor'):\n            _, _, features = self._feature_extractor(self.images)\n        with tf.variable_scope('pretraining'):\n            axes = [1, 2] if self.data_format == 'channels_last' else [2, 3]\n            global_pool = tf.reduce_mean(features, axis=axes, name='global_pool')\n            loss = tf.losses.sparse_softmax_cross_entropy(self.labels, global_pool, reduction=tf.losses.Reduction.MEAN)\n            self.pred = tf.argmax(global_pool, 1)\n            self.accuracy = tf.reduce_mean(\n                tf.cast(tf.equal(self.pred, self.labels), tf.float32), name='accuracy'\n            )\n            self.loss = loss + self.weight_decay * tf.add_n(\n                [tf.nn.l2_loss(var) for var in tf.trainable_variables('feature_extractor')]\n            )\n            optimizer = tf.train.MomentumOptimizer(learning_rate=self.lr, momentum=0.9)\n            self.train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n\n    def _build_detection_graph(self):\n        with tf.variable_scope('feature_extractor'):\n            feat1, feat2, feat3 = self._feature_extractor(self.images)\n            p5 = self._get_pyramid(feat3, 256)\n            p4, top_down = self._get_pyramid(feat2, 256, p5)\n            p3, _ = self._get_pyramid(feat1, 256, top_down)\n            p6 = self._bn_activation_conv(p5, 256, 3, 2)\n            p7 = self._bn_activation_conv(p6, 256, 3, 2)\n        with tf.variable_scope('regressor'):\n            pred3c = self._classification_subnet(p3, 256)\n            pred3r = self._regression_subnet(p3, 256)\n            pred4c = self._classification_subnet(p4, 256)\n            pred4r = self._regression_subnet(p4, 256)\n            pred5c = self._classification_subnet(p5, 256)\n            pred5r = self._regression_subnet(p5, 256)\n            pred6c = self._classification_subnet(p6, 256)\n            pred6r = self._regression_subnet(p6, 256)\n            pred7c = self._classification_subnet(p7, 256)\n            pred7r = self._regression_subnet(p7, 256)\n            if self.data_format == 'channels_first':\n                pred3c = tf.transpose(pred3c, [0, 2, 3, 1])\n                pred3r = tf.transpose(pred3r, [0, 2, 3, 1])\n                pred4c = tf.transpose(pred4c, [0, 2, 3, 1])\n                pred4r = tf.transpose(pred4r, [0, 2, 3, 1])\n                pred5c = tf.transpose(pred5c, [0, 2, 3, 1])\n                pred5r = tf.transpose(pred5r, [0, 2, 3, 1])\n                pred6c = tf.transpose(pred6c, [0, 2, 3, 1])\n                pred6r = tf.transpose(pred6r, [0, 2, 3, 1])\n                pred7c = tf.transpose(pred7c, [0, 2, 3, 1])\n                pred7r = tf.transpose(pred7r, [0, 2, 3, 1])\n            p3shape = tf.shape(pred3c)\n            p4shape = tf.shape(pred4c)\n            p5shape = tf.shape(pred5c)\n            p6shape = tf.shape(pred6c)\n            p7shape = tf.shape(pred7c)\n        with tf.variable_scope('inference'):\n            p3bbox_yx, p3bbox_hw, p3conf = self._get_pbbox(pred3c, pred3r)\n            p4bbox_yx, p4bbox_hw, p4conf = self._get_pbbox(pred4c, pred4r)\n            p5bbox_yx, p5bbox_hw, p5conf = self._get_pbbox(pred5c, pred5r)\n            p6bbox_yx, p6bbox_hw, p6conf = self._get_pbbox(pred6c, pred6r)\n            p7bbox_yx, p7bbox_hw, p7conf = self._get_pbbox(pred7c, pred7r)\n\n            a3bbox_y1x1, a3bbox_y2x2, a3bbox_yx, a3bbox_hw = self._get_abbox(self.anchors[0], p3shape)\n            a4bbox_y1x1, a4bbox_y2x2, a4bbox_yx, a4bbox_hw = self._get_abbox(self.anchors[1], p4shape)\n            a5bbox_y1x1, a5bbox_y2x2, a5bbox_yx, a5bbox_hw = self._get_abbox(self.anchors[2], p5shape)\n            a6bbox_y1x1, a6bbox_y2x2, a6bbox_yx, a6bbox_hw = self._get_abbox(self.anchors[3], p6shape)\n            a7bbox_y1x1, a7bbox_y2x2, a7bbox_yx, a7bbox_hw = self._get_abbox(self.anchors[4], p7shape)\n\n            pbbox_yx = tf.concat([p3bbox_yx, p4bbox_yx, p5bbox_yx, p6bbox_yx, p7bbox_yx], axis=1)\n            pbbox_hw = tf.concat([p3bbox_hw, p4bbox_hw, p5bbox_hw, p6bbox_hw, p7bbox_hw], axis=1)\n            pconf = tf.concat([p3conf, p4conf, p5conf, p6conf, p7conf], axis=1)\n            abbox_y1x1 = tf.concat([a3bbox_y1x1, a4bbox_y1x1, a5bbox_y1x1, a6bbox_y1x1, a7bbox_y1x1], axis=0)\n            abbox_y2x2 = tf.concat([a3bbox_y2x2, a4bbox_y2x2, a5bbox_y2x2, a6bbox_y2x2, a7bbox_y2x2], axis=0)\n            abbox_yx = tf.concat([a3bbox_yx, a4bbox_yx, a5bbox_yx, a6bbox_yx, a7bbox_yx], axis=0)\n            abbox_hw = tf.concat([a3bbox_hw, a4bbox_hw, a5bbox_hw, a6bbox_hw, a7bbox_hw], axis=0)\n\n            if self.mode == 'train':\n                i = 0.\n                loss = 0.\n                cond = lambda loss, i: tf.less(i, tf.cast(self.batch_size, tf.float32))\n                body = lambda loss, i: (\n                    tf.add(loss, self._compute_one_image_loss(\n                        tf.squeeze(tf.gather(pbbox_yx, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(pbbox_hw, tf.cast(i, tf.int32))),\n                        abbox_y1x1,\n                        abbox_y2x2,\n                        abbox_yx,\n                        abbox_hw,\n                        tf.squeeze(tf.gather(pconf, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(self.ground_truth, tf.cast(i, tf.int32))),\n                    )),\n                    tf.add(i, 1.)\n                )\n                init_state = (loss, i)\n                state = tf.while_loop(cond, body, init_state)\n                total_loss, _ = state\n                total_loss = total_loss / self.batch_size\n                optimizer = tf.train.MomentumOptimizer(learning_rate=self.lr, momentum=.9)\n                self.loss = total_loss + self.weight_decay * tf.add_n(\n                    [tf.nn.l2_loss(var) for var in tf.trainable_variables('feature_extractor')]\n                ) + self.weight_decay * tf.add_n(\n                    [tf.nn.l2_loss(var) for var in tf.trainable_variables('regressor')]\n                )\n                train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n                update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n                self.train_op = tf.group([update_ops, train_op])\n            else:\n                pbbox_yxt = pbbox_yx[0, ...]\n                pbbox_hwt = pbbox_hw[0, ...]\n                confidence = tf.nn.softmax(pconf[0, ...])\n                class_id = tf.argmax(confidence, axis=-1)\n                conf_mask = tf.less(class_id, self.num_classes - 1)\n                pbbox_yxt = tf.boolean_mask(pbbox_yxt, conf_mask)\n                pbbox_hwt = tf.boolean_mask(pbbox_hwt, conf_mask)\n                confidence = tf.boolean_mask(confidence, conf_mask)[:, :self.num_classes - 1]\n                abbox_yxt = tf.boolean_mask(abbox_yx, conf_mask)\n                abbox_hwt = tf.boolean_mask(abbox_hw, conf_mask)\n                dpbbox_yxt = pbbox_yxt * abbox_hwt + abbox_yxt\n                dpbbox_hwt = abbox_hwt * tf.exp(pbbox_hwt)\n                dpbbox_y1x1 = dpbbox_yxt - dpbbox_hwt / 2.\n                dpbbox_y2x2 = dpbbox_yxt + dpbbox_hwt / 2.\n                dpbbox_y1x1y2x2 = tf.concat([dpbbox_y1x1, dpbbox_y2x2], axis=-1)\n                filter_mask = tf.greater_equal(confidence, self.nms_score_threshold)\n                scores = []\n                class_id = []\n                bbox = []\n                for i in range(self.num_classes - 1):\n                    scoresi = tf.boolean_mask(confidence[:, i], filter_mask[:, i])\n                    bboxi = tf.boolean_mask(dpbbox_y1x1y2x2, filter_mask[:, i])\n                    selected_indices = tf.image.non_max_suppression(\n\n                        bboxi, scoresi, self.nms_max_boxes, self.nms_iou_threshold,\n                    )\n                    scores.append(tf.gather(scoresi, selected_indices))\n                    bbox.append(tf.gather(bboxi, selected_indices))\n                    class_id.append(tf.ones_like(tf.gather(scoresi, selected_indices), tf.int32) * i)\n                bbox = tf.concat(bbox, axis=0)\n                scores = tf.concat(scores, axis=0)\n                class_id = tf.concat(class_id, axis=0)\n                self.detection_pred = [scores, bbox, class_id]\n\n    def _feature_extractor(self, image):\n        endpoints = []\n        conv1_1 = self._conv_bn_activation(\n            bottom=image,\n            filters=self.config['init_conv_filters'],\n            kernel_size=self.init_conv_kernel_size,\n            strides=self.init_conv_strides,\n            )\n        pool1 = self._max_pooling(\n            bottom=conv1_1,\n            pool_size=self.init_pooling_pool_size,\n            strides=self.init_pooling_strides,\n            name='pool1'\n        )\n        if self.is_bottleneck:\n            stack_residual_unit_fn = self._residual_bottleneck\n        else:\n            stack_residual_unit_fn = self._residual_block\n        residual_block = pool1\n        for i in range(self.block_list[0]):\n            residual_block = stack_residual_unit_fn(residual_block, self.filters_list[0], 1, 'block1_unit'+str(i+1))\n        endpoints.append(residual_block)\n        for i in range(1, len(self.block_list)):\n            residual_block = stack_residual_unit_fn(residual_block, self.filters_list[i], 2, 'block'+str(i+1)+'_unit'+str(1))\n            for j in range(1, self.block_list[i]):\n                residual_block = stack_residual_unit_fn(residual_block, self.filters_list[i], 1, 'block'+str(i+1)+'_unit'+str(j+1))\n            endpoints.append(residual_block)\n        return endpoints[-3], endpoints[-2], endpoints[-1]\n\n    def _classification_subnet(self, bottom, filters):\n        conv1 = self._bn_activation_conv(bottom, filters, 3, 1)\n        conv2 = self._bn_activation_conv(conv1, filters, 3, 1)\n        conv3 = self._bn_activation_conv(conv2, filters, 3, 1)\n        conv4 = self._bn_activation_conv(conv3, filters, 3, 1)\n        pred = self._bn_activation_conv(conv4, self.num_classes * self.num_anchors, 3, 1, pi_init=True)\n        return pred\n\n    def _regression_subnet(self, bottom, filters):\n        conv1 = self._bn_activation_conv(bottom, filters, 3, 1)\n        conv2 = self._bn_activation_conv(conv1, filters, 3, 1)\n        conv3 = self._bn_activation_conv(conv2, filters, 3, 1)\n        conv4 = self._bn_activation_conv(conv3, filters, 3, 1)\n        pred = self._bn_activation_conv(conv4, 4 * self.num_anchors, 3, 1)\n        return pred\n\n    def _get_pyramid(self, feat, feature_size, top_feat=None):\n        if top_feat is None:\n            return self._bn_activation_conv(feat, feature_size, 3, 1)\n        else:\n            if self.data_format == 'channels_last':\n                feat = self._bn_activation_conv(feat, feature_size, 1, 1)\n                top_feat = tf.image.resize_bilinear(top_feat, [tf.shape(feat)[1], tf.shape(feat)[2]])\n                total_feat = feat + top_feat\n                return self._bn_activation_conv(total_feat, feature_size, 3, 1), total_feat\n            else:\n                feat = self._bn_activation_conv(feat, feature_size, 1, 1)\n                feat = tf.transpose(feat, [0, 2, 3, 1])\n                top_feat = tf.transpose(top_feat, [0, 2, 3, 1])\n                top_feat = tf.image.resize_bilinear(top_feat, [tf.shape(feat)[1], tf.shape(feat)[2]])\n                total_feat = feat + top_feat\n                total_feat = tf.transpose(total_feat, [0, 3, 1, 2])\n                return self._bn_activation_conv(total_feat, feature_size, 3, 1), total_feat\n\n    def _get_pbbox(self, predc, predr):\n        pconf = tf.reshape(predc, [self.batch_size, -1, self.num_classes])\n        pbbox = tf.reshape(predr, [self.batch_size, -1, 4])\n        pbbox_yx = pbbox[..., :2]\n        pbbox_hw = pbbox[..., 2:]\n        return pbbox_yx, pbbox_hw, pconf\n\n    def _get_abbox(self, size, pshape):\n        if self.data_format == 'channels_last':\n            input_h = self.data_shape[1]\n            downsampling_rate = tf.cast(input_h, tf.float32) / tf.cast(pshape[1], tf.float32)\n        else:\n            input_h = self.data_shape[2]\n            downsampling_rate = tf.cast(input_h, tf.float32) / tf.cast(pshape[1], tf.float32)\n        topleft_y = tf.range(0., tf.cast(pshape[1], tf.float32), dtype=tf.float32)\n        topleft_x = tf.range(0., tf.cast(pshape[2], tf.float32), dtype=tf.float32)\n        topleft_y = tf.reshape(topleft_y, [-1, 1, 1, 1]) + 0.5\n        topleft_x = tf.reshape(topleft_x, [1, -1, 1, 1]) + 0.5\n        topleft_y = tf.tile(topleft_y, [1, pshape[2], 1, 1]) * downsampling_rate\n        topleft_x = tf.tile(topleft_x, [pshape[1], 1, 1, 1]) * downsampling_rate\n        topleft_yx = tf.concat([topleft_y, topleft_x], -1)\n        topleft_yx = tf.tile(topleft_yx, [1, 1, self.num_anchors, 1])\n\n        priors = []\n        for r in self.aspect_ratios:\n            for s in self.anchor_size:\n                priors.append([s*size*(r**0.5), s*size/(r**0.5)])\n        priors = tf.convert_to_tensor(priors, tf.float32)\n        priors = tf.reshape(priors, [1, 1, -1, 2])\n\n        abbox_y1x1 = tf.reshape(topleft_yx - priors / 2., [-1, 2])\n        abbox_y2x2 = tf.reshape(topleft_yx + priors / 2., [-1, 2])\n        abbox_yx = abbox_y1x1 / 2. + abbox_y2x2 / 2.\n        abbox_hw = abbox_y2x2 - abbox_y1x1\n        return abbox_y1x1, abbox_y2x2, abbox_yx, abbox_hw\n\n    def _compute_one_image_loss(self, pbbox_yx, pbbox_hw, abbox_y1x1, abbox_y2x2,\n                                abbox_yx, abbox_hw, pconf, ground_truth):\n        slice_index = tf.argmin(ground_truth, axis=0)[0]\n        ground_truth = tf.gather(ground_truth, tf.range(0, slice_index, dtype=tf.int64))\n        gbbox_yx = ground_truth[..., 0:2]\n        gbbox_hw = ground_truth[..., 2:4]\n        gbbox_y1x1 = gbbox_yx - gbbox_hw / 2.\n        gbbox_y2x2 = gbbox_yx + gbbox_hw / 2.\n        class_id = tf.cast(ground_truth[..., 4:5], dtype=tf.int32)\n        label = class_id\n\n        abbox_hwti = tf.reshape(abbox_hw, [1, -1, 2])\n        abbox_y1x1ti = tf.reshape(abbox_y1x1, [1, -1, 2])\n        abbox_y2x2ti = tf.reshape(abbox_y2x2, [1, -1, 2])\n        gbbox_hwti = tf.reshape(gbbox_hw, [-1, 1, 2])\n        gbbox_y1x1ti = tf.reshape(gbbox_y1x1, [-1, 1, 2])\n        gbbox_y2x2ti = tf.reshape(gbbox_y2x2, [-1, 1, 2])\n        ashape = tf.shape(abbox_hwti)\n        gshape = tf.shape(gbbox_hwti)\n        abbox_hwti = tf.tile(abbox_hwti, [gshape[0], 1, 1])\n        abbox_y1x1ti = tf.tile(abbox_y1x1ti, [gshape[0], 1, 1])\n        abbox_y2x2ti = tf.tile(abbox_y2x2ti, [gshape[0], 1, 1])\n        gbbox_hwti = tf.tile(gbbox_hwti, [1, ashape[1], 1])\n        gbbox_y1x1ti = tf.tile(gbbox_y1x1ti, [1, ashape[1], 1])\n        gbbox_y2x2ti = tf.tile(gbbox_y2x2ti, [1, ashape[1], 1])\n\n        gaiou_y1x1ti = tf.maximum(abbox_y1x1ti, gbbox_y1x1ti)\n        gaiou_y2x2ti = tf.minimum(abbox_y2x2ti, gbbox_y2x2ti)\n        gaiou_area = tf.reduce_prod(tf.maximum(gaiou_y2x2ti - gaiou_y1x1ti, 0), axis=-1)\n        aarea = tf.reduce_prod(abbox_hwti, axis=-1)\n        garea = tf.reduce_prod(gbbox_hwti, axis=-1)\n        gaiou_rate = gaiou_area / (aarea + garea - gaiou_area)\n\n        best_raindex = tf.argmax(gaiou_rate, axis=1)\n        best_pbbox_yx = tf.gather(pbbox_yx, best_raindex)\n        best_pbbox_hw = tf.gather(pbbox_hw, best_raindex)\n        best_pconf = tf.gather(pconf, best_raindex)\n        best_abbox_yx = tf.gather(abbox_yx, best_raindex)\n        best_abbox_hw = tf.gather(abbox_hw, best_raindex)\n\n        bestmask, _ = tf.unique(best_raindex)\n        bestmask = tf.contrib.framework.sort(bestmask)\n        bestmask = tf.reshape(bestmask, [-1, 1])\n        bestmask = tf.sparse.SparseTensor(tf.concat([bestmask, tf.zeros_like(bestmask)], axis=-1),\n                                          tf.squeeze(tf.ones_like(bestmask)), dense_shape=[ashape[1], 1])\n        bestmask = tf.reshape(tf.cast(tf.sparse.to_dense(bestmask), tf.float32), [-1])\n\n        othermask = 1. - bestmask\n        othermask = othermask > 0.\n        other_pbbox_yx = tf.boolean_mask(pbbox_yx, othermask)\n        other_pbbox_hw = tf.boolean_mask(pbbox_hw, othermask)\n        other_pconf = tf.boolean_mask(pconf, othermask)\n\n        other_abbox_yx = tf.boolean_mask(abbox_yx, othermask)\n        other_abbox_hw = tf.boolean_mask(abbox_hw, othermask)\n\n        agiou_rate = tf.transpose(gaiou_rate)\n        other_agiou_rate = tf.boolean_mask(agiou_rate, othermask)\n        best_agiou_rate = tf.reduce_max(other_agiou_rate, axis=1)\n        pos_agiou_mask = best_agiou_rate > 0.5\n        neg_agiou_mask = best_agiou_rate < 0.4\n        rgindex = tf.argmax(other_agiou_rate, axis=1)\n        pos_rgindex = tf.boolean_mask(rgindex, pos_agiou_mask)\n        pos_ppox_yx = tf.boolean_mask(other_pbbox_yx, pos_agiou_mask)\n        pos_ppox_hw = tf.boolean_mask(other_pbbox_hw, pos_agiou_mask)\n        pos_pconf = tf.boolean_mask(other_pconf, pos_agiou_mask)\n        pos_abbox_yx = tf.boolean_mask(other_abbox_yx, pos_agiou_mask)\n        pos_abbox_hw = tf.boolean_mask(other_abbox_hw, pos_agiou_mask)\n        pos_label = tf.gather(label, pos_rgindex)\n        pos_gbbox_yx = tf.gather(gbbox_yx, pos_rgindex)\n        pos_gbbox_hw = tf.gather(gbbox_hw, pos_rgindex)\n\n        neg_pconf = tf.boolean_mask(other_pconf, neg_agiou_mask)\n        neg_shape = tf.shape(neg_pconf)\n        num_neg = neg_shape[0]\n        neg_class_id = tf.constant([self.num_classes-1])\n        neg_label = tf.tile(neg_class_id, [num_neg])\n\n        pos_pbbox_yx = tf.concat([best_pbbox_yx, pos_ppox_yx], axis=0)\n        pos_pbbox_hw = tf.concat([best_pbbox_hw, pos_ppox_hw], axis=0)\n        pos_pconf = tf.concat([best_pconf, pos_pconf], axis=0)\n        pos_label = tf.concat([label, pos_label], axis=0)\n        pos_gbbox_yx = tf.concat([gbbox_yx, pos_gbbox_yx], axis=0)\n        pos_gbbox_hw = tf.concat([gbbox_hw, pos_gbbox_hw], axis=0)\n        pos_abbox_yx = tf.concat([best_abbox_yx, pos_abbox_yx], axis=0)\n        pos_abbox_hw = tf.concat([best_abbox_hw, pos_abbox_hw], axis=0)\n        conf_loss = self._focal_loss(pos_label, pos_pconf, neg_label, neg_pconf)\n\n        pos_truth_pbbox_yx = (pos_gbbox_yx - pos_abbox_yx) / pos_abbox_hw\n        pos_truth_pbbox_hw = tf.log(pos_gbbox_hw / pos_abbox_hw)\n        pos_yx_loss = tf.reduce_sum(self._smooth_l1_loss(pos_pbbox_yx - pos_truth_pbbox_yx), axis=-1)\n        pos_hw_loss = tf.reduce_sum(self._smooth_l1_loss(pos_pbbox_hw - pos_truth_pbbox_hw), axis=-1)\n        pos_coord_loss = tf.reduce_mean(pos_yx_loss + pos_hw_loss)\n\n        total_loss = conf_loss + pos_coord_loss\n        return total_loss\n\n    def _smooth_l1_loss(self, x):\n        return tf.where(tf.abs(x) < 1., 0.5*x*x, tf.abs(x)-0.5)\n\n    def _focal_loss(self, poslabel, posprob, neglabel, negprob):\n        posprob = tf.nn.softmax(posprob)\n        negprob = tf.nn.softmax(negprob)\n        pos_index = tf.concat([\n            tf.expand_dims(tf.range(0, tf.shape(posprob)[0], dtype=tf.int32), axis=-1),\n            tf.reshape(poslabel, [-1, 1])\n        ], axis=-1)\n        neg_index = tf.concat([\n            tf.expand_dims(tf.range(0, tf.shape(negprob)[0], dtype=tf.int32), axis=-1),\n            tf.reshape(neglabel, [-1, 1])\n        ], axis=-1)\n        posprob = tf.clip_by_value(tf.gather_nd(posprob, pos_index), 1e-8, 1.)\n        negprob = tf.clip_by_value(tf.gather_nd(negprob, neg_index), 1e-8, 1.)\n        posloss = - self.alpha * tf.pow(1. - posprob, self.gamma) * tf.log(posprob)\n        negloss = - self.alpha * tf.pow(1. - negprob, self.gamma) * tf.log(negprob)\n        total_loss = tf.concat([posloss, negloss], axis=0)\n        loss = tf.reduce_sum(total_loss) / tf.cast(tf.shape(posloss)[0], tf.float32)\n        return loss\n\n    def _train_pretraining_epoch(self, lr):\n        self.is_training = True\n        self.sess.run(self.train_initializer)\n        mean_loss = []\n        mean_acc = []\n        for i in range(self.num_train // self.batch_size):\n            _, loss, acc = self.sess.run([self.train_op, self.loss, self.accuracy], feed_dict={self.lr: lr})\n            mean_loss.append(loss)\n            mean_acc.append(acc)\n        mean_loss = np.mean(mean_loss)\n        mean_acc = np.mean(mean_acc)\n        return mean_loss, mean_acc\n\n    def _train_detection_epoch(self, lr):\n        self.is_training = True\n        self.sess.run(self.train_initializer)\n        mean_loss = []\n        num_iters = self.num_train // self.batch_size\n        for i in range(num_iters):\n            _, loss = self.sess.run([self.train_op, self.loss], feed_dict={self.lr: lr})\n            sys.stdout.write('\\r>> ' + 'iters '+str(i+1)+str('/')+str(num_iters)+' loss '+str(loss))\n            sys.stdout.flush()\n            mean_loss.append(loss)\n        sys.stdout.write('\\n')\n        mean_loss = np.mean(mean_loss)\n        return mean_loss\n\n    def _test_one_pretraining_image(self, images):\n        self.is_training = False\n        pred = self.sess.run(self.pred, feed_dict={self.images: images})\n        return pred\n\n    def _test_one_detection_image(self, images):\n        self.is_training = False\n        pred = self.sess.run(self.detection_pred, feed_dict={self.images: images})\n        return pred\n\n    def _save_pretraining_weight(self, mode, path):\n        assert(mode in ['latest', 'best'])\n        if mode == 'latest':\n            saver = self.saver\n        else:\n            saver = self.best_saver\n        if not tf.gfile.Exists(os.path.dirname(path)):\n            tf.gfile.MakeDirs(os.path.dirname(path))\n            print(os.path.dirname(path), 'does not exist, create it done')\n        saver.save(self.sess, path, global_step=self.global_step)\n        print('>> save', mode, 'model in', path, 'successfully')\n\n    def _save_detection_weight(self, mode, path):\n        assert(mode in ['latest', 'best'])\n        if mode == 'latest':\n            saver = self.saver\n        else:\n            saver = self.best_saver\n        if not tf.gfile.Exists(os.path.dirname(path)):\n            tf.gfile.MakeDirs(os.path.dirname(path))\n            print(os.path.dirname(path), 'does not exist, create it done')\n        saver.save(self.sess, path, global_step=self.global_step)\n        print('>> save', mode, 'model in', path, 'successfully')\n\n    def load_weight(self, path):\n        self.saver.restore(self.sess, path)\n        print('>> load weight', path, 'successfully')\n\n    def load_pretraining_weight(self, path):\n        self.pretraining_weight_saver.restore(self.sess, path)\n        print('>> load pretraining weight', path, 'successfully')\n\n    def _init_session(self):\n        self.sess = tf.InteractiveSession()\n        self.sess.run(tf.global_variables_initializer())\n        if self.mode == 'train':\n            if self.train_initializer is not None:\n                self.sess.run(self.train_initializer)\n\n    def _create_pretraining_saver(self):\n        weights = tf.trainable_variables(scope='feature_extractor')\n        self.saver = tf.train.Saver(weights)\n        self.best_saver = tf.train.Saver(weights)\n\n    def _create_detection_saver(self):\n        weights = tf.trainable_variables(scope='feature_extractor')\n        self.pretraining_weight_saver = tf.train.Saver(weights)\n        self.saver = tf.train.Saver()\n        self.best_saver = tf.train.Saver()\n\n    def _create_pretraining_summary(self):\n        with tf.variable_scope('summaries'):\n            tf.summary.scalar('loss', self.loss)\n            tf.summary.scalar('accuracy', self.accuracy)\n            self.summary_op = tf.summary.merge_all()\n\n    def _create_detection_summary(self):\n        with tf.variable_scope('summaries'):\n            tf.summary.scalar('loss', self.loss)\n            self.summary_op = tf.summary.merge_all()\n\n    def _bn(self, bottom):\n        bn = tf.layers.batch_normalization(\n            inputs=bottom,\n            axis=3 if self.data_format == 'channels_last' else 1,\n            training=self.is_training\n        )\n        return bn\n\n    def _conv_bn_activation(self, bottom, filters, kernel_size, strides, activation=tf.nn.relu):\n        conv = tf.layers.conv2d(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            kernel_initializer=tf.contrib.layers.variance_scaling_initializer()\n        )\n        bn = self._bn(conv)\n        if activation is not None:\n            return activation(bn)\n        else:\n            return bn\n\n    def _bn_activation_conv(self, bottom, filters, kernel_size, strides, activation=tf.nn.relu, pi_init=False):\n        bn = self._bn(bottom)\n        if activation is not None:\n            bn = activation(bn)\n        if not pi_init:\n            conv = tf.layers.conv2d(\n                inputs=bn,\n                filters=filters,\n                kernel_size=kernel_size,\n                strides=strides,\n                padding='same',\n                data_format=self.data_format,\n                kernel_initializer=tf.contrib.layers.variance_scaling_initializer()\n            )\n        else:\n            conv = tf.layers.conv2d(\n                inputs=bn,\n                filters=filters,\n                kernel_size=kernel_size,\n                strides=strides,\n                padding='same',\n                data_format=self.data_format,\n                kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),\n                bias_initializer=tf.constant_initializer(-math.log((1 - self.pi) / self.pi))\n            )\n        return conv\n\n    def _residual_block(self, bottom, filters, strides, scope):\n        with tf.variable_scope(scope):\n            with tf.variable_scope('conv_branch'):\n                conv = self._bn_activation_conv(bottom, filters, 3, strides)\n                conv = self._bn_activation_conv(conv, filters, 3, 1)\n            with tf.variable_scope('identity_branch'):\n                if strides != 1:\n                    shutcut = self._bn_activation_conv(bottom, filters, 3, strides)\n                else:\n                    shutcut = bottom\n\n        return conv + shutcut\n\n    def _residual_bottleneck(self, bottom, filters, strides, scope):\n        with tf.variable_scope(scope):\n            with tf.variable_scope('conv_branch'):\n                conv = self._bn_activation_conv(bottom, filters, 1, 1)\n                conv = self._bn_activation_conv(conv, filters, 3, strides)\n                conv = self._bn_activation_conv(conv, filters*4, 1, 1)\n            with tf.variable_scope('identity_branch'):\n                shutcut = self._bn_activation_conv(bottom, filters*4, 3, strides)\n\n        return conv + shutcut\n\n    def _max_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.max_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _avg_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.average_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _dropout(self, bottom, name):\n        return tf.layers.dropout(\n            inputs=bottom,\n            rate=self.prob,\n            training=self.is_training,\n            name=name\n        )\n"""
SSD300.py,213,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nfrom tensorflow.python import pywrap_tensorflow as wrap\nimport sys\nimport os\nimport numpy as np\n\n\nclass SSD300:\n    def __init__(self, config, data_provider):\n        assert config[\'mode\'] in [\'train\', \'test\']\n        assert config[\'data_format\'] in [\'channels_first\', \'channels_last\']\n        self.config = config\n        self.data_provider = data_provider\n        self.input_size = 300\n        if config[\'data_format\'] == \'channels_last\':\n            self.data_shape = [300, 300, 3]\n        else:\n            self.data_shape = [3, 300, 300]\n        self.num_classes = config[\'num_classes\'] + 1\n        self.weight_decay = config[\'weight_decay\']\n        self.prob = 1. - config[\'keep_prob\']\n        self.data_format = config[\'data_format\']\n        self.mode = config[\'mode\']\n        self.batch_size = config[\'batch_size\'] if config[\'mode\'] == \'train\' else 1\n        self.nms_score_threshold = config[\'nms_score_threshold\']\n        self.nms_max_boxes = config[\'nms_max_boxes\']\n        self.nms_iou_threshold = config[\'nms_iou_threshold\']\n        self.reader = wrap.NewCheckpointReader(config[\'pretraining_weight\'])\n\n        if self.mode == \'train\':\n            self.num_train = data_provider[\'num_train\']\n            self.num_val = data_provider[\'num_val\']\n            self.train_generator = data_provider[\'train_generator\']\n            self.train_initializer, self.train_iterator = self.train_generator\n            if data_provider[\'val_generator\'] is not None:\n                self.val_generator = data_provider[\'val_generator\']\n                self.val_initializer, self.val_iterator = self.val_generator\n\n        self.global_step = tf.get_variable(name=\'global_step\', initializer=tf.constant(0), trainable=False)\n        self.is_training = True\n\n        self._define_inputs()\n        self._build_graph()\n        self._create_saver()\n        if self.mode == \'train\':\n            self._create_summary()\n        self._init_session()\n\n    def _define_inputs(self):\n        shape = [self.batch_size]\n        shape.extend(self.data_shape)\n        mean = tf.convert_to_tensor([123.68, 116.779, 103.979], dtype=tf.float32)\n        if self.data_format == \'channels_last\':\n            mean = tf.reshape(mean, [1, 1, 1, 3])\n        else:\n            mean = tf.reshape(mean, [1, 3, 1, 1])\n        if self.mode == \'train\':\n            self.images, self.ground_truth = self.train_iterator.get_next()\n            self.images.set_shape(shape)\n            self.images = self.images - mean\n        else:\n            self.images = tf.placeholder(tf.float32, shape, name=\'images\')\n            self.images = self.images - mean\n            self.ground_truth = tf.placeholder(tf.float32, [self.batch_size, None, 5], name=\'labels\')\n        self.lr = tf.placeholder(dtype=tf.float32, shape=[], name=\'lr\')\n\n    def _build_graph(self):\n        with tf.variable_scope(\'feature_extractor\'):\n            feat1, feat2, feat3, feat4, feat5, feat6 = self._feature_extractor(self.images)\n            axes = 3 if self.data_format == \'channels_last\' else 1\n            feat1 = tf.nn.l2_normalize(feat1, axis=axes)\n            channels = tf.shape(feat1)[axes]\n            norm_factor = tf.get_variable(\'l2_norm_factor\', shape=[1], initializer=tf.constant_initializer(20.))\n            norm_factor = tf.tile(norm_factor, [channels])\n            if self.data_format == \'channels_last\':\n                norm_factor = tf.reshape(norm_factor, [1, 1, 1, -1])\n            else:\n                norm_factor = tf.reshape(norm_factor, [1, -1, 1, 1])\n            feat1 = norm_factor * feat1\n        with tf.variable_scope(\'regressor\'):\n            pred1 = self._conv_layer(feat1, 4*(self.num_classes+4), 3, 1, \'pred1\')\n            pred2 = self._conv_layer(feat2, 6*(self.num_classes+4), 3, 1, \'pred2\')\n            pred3 = self._conv_layer(feat3, 6*(self.num_classes+4), 3, 1, \'pred3\')\n            pred4 = self._conv_layer(feat4, 6*(self.num_classes+4), 3, 1, \'pred4\')\n            pred5 = self._conv_layer(feat5, 4*(self.num_classes+4), 3, 1, \'pred5\')\n            pred6 = self._conv_layer(feat6, 4*(self.num_classes+4), 3, 1, \'pred6\')\n            if self.data_format == \'channels_first\':\n                pred1 = tf.transpose(pred1, [0, 2, 3, 1])\n                pred2 = tf.transpose(pred2, [0, 2, 3, 1])\n                pred3 = tf.transpose(pred3, [0, 2, 3, 1])\n                pred4 = tf.transpose(pred4, [0, 2, 3, 1])\n                pred5 = tf.transpose(pred5, [0, 2, 3, 1])\n                pred6 = tf.transpose(pred6, [0, 2, 3, 1])\n            p1shape = tf.shape(pred1)\n            p2shape = tf.shape(pred2)\n            p3shape = tf.shape(pred3)\n            p4shape = tf.shape(pred4)\n            p5shape = tf.shape(pred5)\n            p6shape = tf.shape(pred6)\n        with tf.variable_scope(\'inference\'):\n            p1bbox_yx, p1bbox_hw, p1conf = self._get_pbbox(pred1)\n            p2bbox_yx, p2bbox_hw, p2conf = self._get_pbbox(pred2)\n            p3bbox_yx, p3bbox_hw, p3conf = self._get_pbbox(pred3)\n            p4bbox_yx, p4bbox_hw, p4conf = self._get_pbbox(pred4)\n            p5bbox_yx, p5bbox_hw, p5conf = self._get_pbbox(pred5)\n            p6bbox_yx, p6bbox_hw, p6conf = self._get_pbbox(pred6)\n\n            s = [(0.2 + (0.9 - 0.2) / 5 * (i-1)) * self.input_size for i in range(1, 8)]\n            s = [[s[i], (s[i]*s[i+1])**0.5] for i in range(0, 6)]\n            a1bbox_y1x1, a1bbox_y2x2, a1bbox_yx, a1bbox_hw = self._get_abbox(s[0], [2, 1/2], p1shape)\n            a2bbox_y1x1, a2bbox_y2x2, a2bbox_yx, a2bbox_hw = self._get_abbox(s[1], [2, 1/2, 3, 1/3], p2shape)\n            a3bbox_y1x1, a3bbox_y2x2, a3bbox_yx, a3bbox_hw = self._get_abbox(s[2], [2, 1/2, 3, 1/3], p3shape)\n            a4bbox_y1x1, a4bbox_y2x2, a4bbox_yx, a4bbox_hw = self._get_abbox(s[3], [2, 1/2, 3, 1/3], p4shape)\n            a5bbox_y1x1, a5bbox_y2x2, a5bbox_yx, a5bbox_hw = self._get_abbox(s[4], [2, 1/2], p5shape)\n            a6bbox_y1x1, a6bbox_y2x2, a6bbox_yx, a6bbox_hw = self._get_abbox(s[5], [2, 1/2], p6shape)\n\n            pbbox_yx = tf.concat([p1bbox_yx, p2bbox_yx, p3bbox_yx, p4bbox_yx, p5bbox_yx, p6bbox_yx], axis=1)\n            pbbox_hw = tf.concat([p1bbox_hw, p2bbox_hw, p3bbox_hw, p4bbox_hw, p5bbox_hw, p6bbox_hw], axis=1)\n            pconf = tf.concat([p1conf, p2conf, p3conf, p4conf, p5conf, p6conf], axis=1)\n            abbox_y1x1 = tf.concat([a1bbox_y1x1, a2bbox_y1x1, a3bbox_y1x1, a4bbox_y1x1, a5bbox_y1x1, a6bbox_y1x1], axis=0)\n            abbox_y2x2 = tf.concat([a1bbox_y2x2, a2bbox_y2x2, a3bbox_y2x2, a4bbox_y2x2, a5bbox_y2x2, a6bbox_y2x2], axis=0)\n            abbox_yx = tf.concat([a1bbox_yx, a2bbox_yx, a3bbox_yx, a4bbox_yx, a5bbox_yx, a6bbox_yx], axis=0)\n            abbox_hw = tf.concat([a1bbox_hw, a2bbox_hw, a3bbox_hw, a4bbox_hw, a5bbox_hw, a6bbox_hw], axis=0)\n            if self.mode == \'train\':\n                i = 0.\n                loss = 0.\n                cond = lambda loss, i: tf.less(i, tf.cast(self.batch_size, tf.float32))\n                body = lambda loss, i: (\n                    tf.add(loss, self._compute_one_image_loss(\n                        tf.squeeze(tf.gather(pbbox_yx, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(pbbox_hw, tf.cast(i, tf.int32))),\n                        abbox_y1x1,\n                        abbox_y2x2,\n                        abbox_yx,\n                        abbox_hw,\n                        tf.squeeze(tf.gather(pconf, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(self.ground_truth, tf.cast(i, tf.int32))),\n                    )),\n                    tf.add(i, 1.)\n                )\n                init_state = (loss, i)\n                state = tf.while_loop(cond, body, init_state)\n                total_loss, _ = state\n                total_loss = total_loss / self.batch_size\n                optimizer = tf.train.MomentumOptimizer(learning_rate=self.lr, momentum=.9)\n                self.loss = total_loss + self.weight_decay * tf.add_n(\n                    [tf.nn.l2_loss(var) for var in tf.trainable_variables()]\n                ) \n                update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n                train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n                self.train_op = tf.group([update_ops, train_op])\n            else:\n                pbbox_yxt = pbbox_yx[0, ...]\n                pbbox_hwt = pbbox_hw[0, ...]\n                confidence = tf.nn.softmax(pconf[0, ...])\n                class_id = tf.argmax(confidence, axis=-1)\n                conf_mask = tf.less(class_id, self.num_classes - 1)\n                pbbox_yxt = tf.boolean_mask(pbbox_yxt, conf_mask)\n                pbbox_hwt = tf.boolean_mask(pbbox_hwt, conf_mask)\n                confidence = tf.boolean_mask(confidence, conf_mask)[:, :self.num_classes - 1]\n                abbox_yxt = tf.boolean_mask(abbox_yx, conf_mask)\n                abbox_hwt = tf.boolean_mask(abbox_hw, conf_mask)\n                dpbbox_yxt = pbbox_yxt * abbox_hwt + abbox_yxt\n                dpbbox_hwt = abbox_hwt * tf.exp(pbbox_hwt)\n                dpbbox_y1x1 = dpbbox_yxt - dpbbox_hwt / 2.\n                dpbbox_y2x2 = dpbbox_yxt + dpbbox_hwt / 2.\n                dpbbox_y1x1y2x2 = tf.concat([dpbbox_y1x1, dpbbox_y2x2], axis=-1)\n                filter_mask = tf.greater_equal(confidence, self.nms_score_threshold)\n                scores = []\n                class_id = []\n                bbox = []\n                for i in range(self.num_classes - 1):\n                    scoresi = tf.boolean_mask(confidence[:, i], filter_mask[:, i])\n                    bboxi = tf.boolean_mask(dpbbox_y1x1y2x2, filter_mask[:, i])\n                    selected_indices = tf.image.non_max_suppression(\n\n                        bboxi, scoresi, self.nms_max_boxes, self.nms_iou_threshold,\n                    )\n                    scores.append(tf.gather(scoresi, selected_indices))\n                    bbox.append(tf.gather(bboxi, selected_indices))\n                    class_id.append(tf.ones_like(tf.gather(scoresi, selected_indices), tf.int32) * i)\n                bbox = tf.concat(bbox, axis=0)\n                scores = tf.concat(scores, axis=0)\n                class_id = tf.concat(class_id, axis=0)\n\n                self.detection_pred = [scores, bbox, class_id]\n\n    def _feature_extractor(self, images):\n        conv1_1 = self._load_conv_layer(images,\n                                        tf.get_variable(name=\'kernel_conv1_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv1_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_1/biases""),\n                                                        trainable=True),\n                                        name=""conv1_1"")\n        conv1_2 = self._load_conv_layer(conv1_1,\n                                        tf.get_variable(name=\'kernel_conv1_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv1_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_2/biases""),\n                                                        trainable=True),\n                                        name=""conv1_2"")\n        pool1 = self._max_pooling(conv1_2, 2, 2, name=""pool1"")\n\n        conv2_1 = self._load_conv_layer(pool1,\n                                        tf.get_variable(name=\'kenrel_conv2_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv2_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_1/biases""),\n                                                        trainable=True),\n                                        name=""conv2_1"")\n        conv2_2 = self._load_conv_layer(conv2_1,\n                                        tf.get_variable(name=\'kernel_conv2_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv2_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_2/biases""),\n                                                        trainable=True),\n                                        name=""conv2_2"")\n        pool2 = self._max_pooling(conv2_2, 2, 2, name=""pool2"")\n        conv3_1 = self._load_conv_layer(pool2,\n                                        tf.get_variable(name=\'kernel_conv3_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv_3_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_1/biases""),\n                                                        trainable=True),\n                                        name=""conv3_1"")\n        conv3_2 = self._load_conv_layer(conv3_1,\n                                        tf.get_variable(name=\'kernel_conv3_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv3_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_2/biases""),\n                                                        trainable=True),\n                                        name=""conv3_2"")\n        conv3_3 = self._load_conv_layer(conv3_2,\n                                        tf.get_variable(name=\'kernel_conv3_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_3/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv3_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_3/biases""),\n                                                        trainable=True),\n                                        name=""conv3_3"")\n        pool3 = self._max_pooling(conv3_3, 2, 2, name=""pool3"")\n\n        conv4_1 = self._load_conv_layer(pool3,\n                                        tf.get_variable(name=\'kernel_conv4_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv4_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_1/biases""),\n                                                        trainable=True),\n                                        name=""conv4_1"")\n        conv4_2 = self._load_conv_layer(conv4_1,\n                                        tf.get_variable(name=\'kernel_conv4_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv4_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_2/biases""),\n                                                        trainable=True),\n                                        name=""conv4_2"")\n        conv4_3 = self._load_conv_layer(conv4_2,\n                                        tf.get_variable(name=\'kernel_conv4_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_3/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv4_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_3/biases""),\n                                                        trainable=True),\n                                        name=""conv4_3"")\n        pool4 = self._max_pooling(conv4_3, 2, 2, name=""pool4"")\n        conv5_1 = self._load_conv_layer(pool4,\n                                        tf.get_variable(name=\'kernel_conv5_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv5_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_1/biases""),\n                                                        trainable=True),\n                                        name=""conv5_1"")\n        conv5_2 = self._load_conv_layer(conv5_1,\n                                        tf.get_variable(name=\'kernel_conv5_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv5_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_2/biases""),\n                                                        trainable=True),\n                                        name=""conv5_2"")\n        conv5_3 = self._load_conv_layer(conv5_2,\n                                        tf.get_variable(name=\'kernel_conv5_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_3/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv5_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_3/biases""),\n                                                        trainable=True),\n                                        name=""conv5_3"")\n        pool5 = self._max_pooling(conv5_3, 3, 1, \'pool5\')\n        conv6 = self._conv_layer(pool5, 1024, 3, 1, \'conv6\', dilation_rate=2, activation=tf.nn.relu)\n        conv7 = self._conv_layer(conv6, 1024, 1, 1, \'conv7\', activation=tf.nn.relu)\n        conv8_1 = self._conv_layer(conv7, 256, 1, 1, \'conv8_1\', activation=tf.nn.relu)\n        conv8_2 = self._conv_layer(conv8_1, 512, 3, 2, \'conv8_2\', activation=tf.nn.relu)\n        conv9_1 = self._conv_layer(conv8_2, 128, 1, 1, \'conv9_1\', activation=tf.nn.relu)\n        conv9_2 = self._conv_layer(conv9_1, 256, 3, 2, \'conv9_2\', activation=tf.nn.relu)\n        conv10_1 = self._conv_layer(conv9_2, 128, 1, 1, \'conv10_1\', activation=tf.nn.relu)\n        conv10_2 = self._conv_layer(conv10_1, 256, 3, 1, \'conv10_2\', activation=tf.nn.relu)\n        conv11_1 = self._conv_layer(conv10_2, 128, 1, 1, \'conv11_1\', activation=tf.nn.relu)\n        conv11_2 = self._conv_layer(conv11_1, 256, 3, 2, \'conv11_2\', activation=tf.nn.relu)\n        return conv4_3, conv7, conv8_2, conv9_2, conv10_2, conv11_2\n\n    def _get_pbbox(self, pred):\n        pred = tf.reshape(pred, [self.batch_size, -1, self.num_classes+4])\n        pconf = pred[..., :self.num_classes]\n        pbbox_yx = pred[..., self.num_classes:self.num_classes+2]\n        pbbox_hw = pred[..., self.num_classes+2:]\n        return pbbox_yx, pbbox_hw, pconf\n\n    def _get_abbox(self, size, aspect_ratio, pshape):\n        topleft_y = tf.range(0., tf.cast(pshape[1], tf.float32), dtype=tf.float32)\n        topleft_x = tf.range(0., tf.cast(pshape[2], tf.float32), dtype=tf.float32)\n        topleft_y = tf.reshape(topleft_y, [-1, 1, 1, 1]) + 0.5\n        topleft_x = tf.reshape(topleft_x, [1, -1, 1, 1]) + 0.5\n        topleft_y = tf.tile(topleft_y, [1, pshape[2], 1, 1]) * tf.cast(self.input_size, tf.float32) / tf.cast(pshape[1], tf.float32)\n        topleft_x = tf.tile(topleft_x, [pshape[1], 1, 1, 1]) * tf.cast(self.input_size, tf.float32) / tf.cast(pshape[2], tf.float32)\n        topleft_yx = tf.concat([topleft_y, topleft_x], -1)\n        topleft_yx = tf.tile(topleft_yx, [1, 1, len(aspect_ratio)+2, 1])\n\n        priors = [[size[0], size[0]], [size[1], size[1]]]\n        for i in range(len(aspect_ratio)):\n            priors.append([size[0]*(aspect_ratio[i]**0.5), size[0]/(aspect_ratio[i]**0.5)])\n        priors = tf.convert_to_tensor(priors, tf.float32)\n        priors = tf.reshape(priors, [1, 1, -1, 2])\n\n        abbox_y1x1 = tf.reshape(topleft_yx - priors / 2., [-1, 2])\n        abbox_y2x2 = tf.reshape(topleft_yx + priors / 2., [-1, 2])\n        abbox_yx = abbox_y1x1 / 2. + abbox_y2x2 / 2.\n        abbox_hw = abbox_y2x2 - abbox_y1x1\n        return abbox_y1x1, abbox_y2x2, abbox_yx, abbox_hw\n\n    def _compute_one_image_loss(self, pbbox_yx, pbbox_hw, abbox_y1x1, abbox_y2x2,\n                                abbox_yx, abbox_hw, pconf, ground_truth):\n        slice_index = tf.argmin(ground_truth, axis=0)[0]\n        ground_truth = tf.gather(ground_truth, tf.range(0, slice_index, dtype=tf.int64))\n        gbbox_yx = ground_truth[..., 0:2]\n        gbbox_hw = ground_truth[..., 2:4]\n        gbbox_y1x1 = gbbox_yx - gbbox_hw / 2.\n        gbbox_y2x2 = gbbox_yx + gbbox_hw / 2.\n        class_id = tf.cast(ground_truth[..., 4:5], dtype=tf.int32)\n        label = class_id\n\n        abbox_hwti = tf.reshape(abbox_hw, [1, -1, 2])\n        abbox_y1x1ti = tf.reshape(abbox_y1x1, [1, -1, 2])\n        abbox_y2x2ti = tf.reshape(abbox_y2x2, [1, -1, 2])\n        gbbox_hwti = tf.reshape(gbbox_hw, [-1, 1, 2])\n        gbbox_y1x1ti = tf.reshape(gbbox_y1x1, [-1, 1, 2])\n        gbbox_y2x2ti = tf.reshape(gbbox_y2x2, [-1, 1, 2])\n        ashape = tf.shape(abbox_hwti)\n        gshape = tf.shape(gbbox_hwti)\n        abbox_hwti = tf.tile(abbox_hwti, [gshape[0], 1, 1])\n        abbox_y1x1ti = tf.tile(abbox_y1x1ti, [gshape[0], 1, 1])\n        abbox_y2x2ti = tf.tile(abbox_y2x2ti, [gshape[0], 1, 1])\n        gbbox_hwti = tf.tile(gbbox_hwti, [1, ashape[1], 1])\n        gbbox_y1x1ti = tf.tile(gbbox_y1x1ti, [1, ashape[1], 1])\n        gbbox_y2x2ti = tf.tile(gbbox_y2x2ti, [1, ashape[1], 1])\n\n        gaiou_y1x1ti = tf.maximum(abbox_y1x1ti, gbbox_y1x1ti)\n        gaiou_y2x2ti = tf.minimum(abbox_y2x2ti, gbbox_y2x2ti)\n        gaiou_area = tf.reduce_prod(tf.maximum(gaiou_y2x2ti - gaiou_y1x1ti, 0), axis=-1)\n        aarea = tf.reduce_prod(abbox_hwti, axis=-1)\n        garea = tf.reduce_prod(gbbox_hwti, axis=-1)\n        gaiou_rate = gaiou_area / (aarea + garea - gaiou_area)\n\n        best_raindex = tf.argmax(gaiou_rate, axis=1)\n        best_pbbox_yx = tf.gather(pbbox_yx, best_raindex)\n        best_pbbox_hw = tf.gather(pbbox_hw, best_raindex)\n        best_pconf = tf.gather(pconf, best_raindex)\n        best_abbox_yx = tf.gather(abbox_yx, best_raindex)\n        best_abbox_hw = tf.gather(abbox_hw, best_raindex)\n\n        bestmask, _ = tf.unique(best_raindex)\n        bestmask = tf.contrib.framework.sort(bestmask)\n        bestmask = tf.reshape(bestmask, [-1, 1])\n        bestmask = tf.sparse.SparseTensor(tf.concat([bestmask, tf.zeros_like(bestmask)], axis=-1),\n                                          tf.squeeze(tf.ones_like(bestmask)), dense_shape=[ashape[1], 1])\n        bestmask = tf.reshape(tf.cast(tf.sparse.to_dense(bestmask), tf.float32), [-1])\n\n        othermask = 1. - bestmask\n        othermask = othermask > 0.\n        other_pbbox_yx = tf.boolean_mask(pbbox_yx, othermask)\n        other_pbbox_hw = tf.boolean_mask(pbbox_hw, othermask)\n        other_pconf = tf.boolean_mask(pconf, othermask)\n\n        other_abbox_yx = tf.boolean_mask(abbox_yx, othermask)\n        other_abbox_hw = tf.boolean_mask(abbox_hw, othermask)\n\n        agiou_rate = tf.transpose(gaiou_rate)\n        other_agiou_rate = tf.boolean_mask(agiou_rate, othermask)\n        best_agiou_rate = tf.reduce_max(other_agiou_rate, axis=1)\n        pos_agiou_mask = best_agiou_rate > 0.5\n        neg_agiou_mask = (1. - tf.cast(pos_agiou_mask, tf.float32)) > 0.\n        rgindex = tf.argmax(other_agiou_rate, axis=1)\n        pos_rgindex = tf.boolean_mask(rgindex, pos_agiou_mask)\n        pos_pbbox_yx = tf.boolean_mask(other_pbbox_yx, pos_agiou_mask)\n        pos_pbbox_hw = tf.boolean_mask(other_pbbox_hw, pos_agiou_mask)\n        pos_pconf = tf.boolean_mask(other_pconf, pos_agiou_mask)\n        pos_abbox_yx = tf.boolean_mask(other_abbox_yx, pos_agiou_mask)\n        pos_abbox_hw = tf.boolean_mask(other_abbox_hw, pos_agiou_mask)\n        pos_label = tf.gather(label, pos_rgindex)\n        pos_gbbox_yx = tf.gather(gbbox_yx, pos_rgindex)\n        pos_gbbox_hw = tf.gather(gbbox_hw, pos_rgindex)\n        pos_shape = tf.shape(pos_pconf)\n\n        neg_pconf = tf.boolean_mask(other_pconf, neg_agiou_mask)\n        neg_abbox_yx = tf.boolean_mask(other_abbox_yx, neg_agiou_mask)\n        neg_abbox_hw = tf.boolean_mask(other_abbox_hw, neg_agiou_mask)\n        neg_abbox_y1x1y2x2 = tf.concat([neg_abbox_yx - neg_abbox_hw/2., neg_abbox_yx + neg_abbox_hw/2.], axis=-1)\n\n        neg_shape = tf.shape(neg_pconf)\n        num_pos = gshape[0] + pos_shape[0]\n        num_neg = neg_shape[0]\n        chosen_num_neg = tf.cond(num_neg > 3*num_pos, lambda: 3*num_pos, lambda: num_neg)\n        neg_class_id = tf.constant([self.num_classes-1])\n        neg_label = tf.tile(neg_class_id, [num_neg])\n\n        total_neg_loss = tf.losses.sparse_softmax_cross_entropy(neg_label, neg_pconf, reduction=tf.losses.Reduction.NONE)\n        selected_indices = tf.image.non_max_suppression(\n            neg_abbox_y1x1y2x2, total_neg_loss, chosen_num_neg, iou_threshold=0.7\n        )\n        neg_loss = tf.reduce_mean(tf.gather(total_neg_loss, selected_indices))\n\n        total_pos_pbbox_yx = tf.concat([best_pbbox_yx, pos_pbbox_yx], axis=0)\n        total_pos_pbbox_hw = tf.concat([best_pbbox_hw, pos_pbbox_hw], axis=0)\n        total_pos_pconf = tf.concat([best_pconf, pos_pconf], axis=0)\n        total_pos_label = tf.concat([label, pos_label], axis=0)\n        total_pos_gbbox_yx = tf.concat([gbbox_yx, pos_gbbox_yx], axis=0)\n        total_pos_gbbox_hw = tf.concat([gbbox_hw, pos_gbbox_hw], axis=0)\n        total_pos_abbox_yx = tf.concat([best_abbox_yx, pos_abbox_yx], axis=0)\n        total_pos_abbox_hw = tf.concat([best_abbox_hw, pos_abbox_hw], axis=0)\n\n        pos_conf_loss = tf.losses.sparse_softmax_cross_entropy(total_pos_label, total_pos_pconf, reduction=tf.losses.Reduction.MEAN)\n        pos_truth_pbbox_yx = (total_pos_gbbox_yx - total_pos_abbox_yx) / total_pos_abbox_hw\n        pos_truth_pbbox_hw = tf.log(total_pos_gbbox_hw / total_pos_abbox_hw)\n        pos_yx_loss = tf.reduce_sum(self._smooth_l1_loss(total_pos_pbbox_yx - pos_truth_pbbox_yx), axis=-1)\n        pos_hw_loss = tf.reduce_sum(self._smooth_l1_loss(total_pos_pbbox_hw - pos_truth_pbbox_hw), axis=-1)\n        pos_coord_loss = tf.reduce_mean(pos_yx_loss + pos_hw_loss)\n\n        total_loss = neg_loss + pos_conf_loss + pos_coord_loss\n        return total_loss\n\n    def _smooth_l1_loss(self, x):\n        return tf.where(tf.abs(x) < 1., 0.5*x*x, tf.abs(x)-0.5)\n\n    def _init_session(self):\n        self.sess = tf.InteractiveSession()\n        self.sess.run(tf.global_variables_initializer())\n        if self.mode == \'train\':\n            self.sess.run(self.train_initializer)\n\n    def _create_saver(self):\n        self.saver = tf.train.Saver()\n        self.best_saver = tf.train.Saver()\n\n    def _create_summary(self):\n        with tf.variable_scope(\'summaries\'):\n            tf.summary.scalar(\'loss\', self.loss)\n            self.summary_op = tf.summary.merge_all()\n\n    def train_one_epoch(self, lr):\n        self.is_training = True\n        self.sess.run(self.train_initializer)\n        mean_loss = []\n        num_iters = self.num_train // self.batch_size\n        for i in range(num_iters):\n            _, loss = self.sess.run([self.train_op, self.loss], feed_dict={self.lr: lr})\n            sys.stdout.write(\'\\r>> \' + \'iters \'+str(i)+str(\'/\')+str(num_iters)+\' loss \'+str(loss))\n            sys.stdout.flush()\n            mean_loss.append(loss)\n        sys.stdout.write(\'\\n\')\n        mean_loss = np.mean(mean_loss)\n        return mean_loss\n\n    def test_one_image(self, images):\n        self.is_training = False\n        pred = self.sess.run(self.detection_pred, feed_dict={self.images: images})\n        return pred\n\n    def save_weight(self, mode, path):\n        assert(mode in [\'latest\', \'best\'])\n        if mode == \'latest\':\n            saver = self.saver\n        else:\n            saver = self.best_saver\n        if not tf.gfile.Exists(os.path.dirname(path)):\n            tf.gfile.MakeDirs(os.path.dirname(path))\n            print(os.path.dirname(path), \'does not exist, create it done\')\n        saver.save(self.sess, path, global_step=self.global_step)\n        print(\'save\', mode, \'model in\', path, \'successfully\')\n\n    def load_weight(self, path):\n        self.saver.restore(self.sess, path)\n        print(\'load weight\', path, \'successfully\')\n\n    def _bn(self, bottom):\n        bn = tf.layers.batch_normalization(\n            inputs=bottom,\n            axis=3 if self.data_format == \'channels_last\' else 1,\n            training=self.is_training\n        )\n        return bn\n\n    def _load_conv_layer(self, bottom, filters, bias, name):\n        if self.data_format == \'channels_last\':\n            data_format = \'NHWC\'\n        else:\n            data_format = \'NCHW\'\n        conv = tf.nn.conv2d(bottom, filter=filters, strides=[1, 1, 1, 1], name=""kernel""+name, padding=""SAME"", data_format=data_format)\n        conv_bias = tf.nn.bias_add(conv, bias=bias, name=""bias""+name)\n        return tf.nn.relu(conv_bias)\n\n    def _conv_layer(self, bottom, filters, kernel_size, strides, name, dilation_rate=1, activation=None):\n        conv = tf.layers.conv2d(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=\'same\',\n            name=name,\n            data_format=self.data_format,\n            dilation_rate=dilation_rate,\n        )\n        bn = self._bn(conv)\n        if activation is not None:\n            bn = activation(bn)\n        return bn\n\n    def _max_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.max_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding=\'same\',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _avg_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.average_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding=\'same\',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _dropout(self, bottom, name):\n        return tf.layers.dropout(\n            inputs=bottom,\n            rate=self.prob,\n            training=self.is_training,\n            name=name\n        )\n'"
SSD512.py,217,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nfrom tensorflow.python import pywrap_tensorflow as wrap\nimport sys\nimport os\nimport numpy as np\n\n\nclass SSD512:\n    def __init__(self, config, data_provider):\n        assert config[\'mode\'] in [\'train\', \'test\']\n        assert config[\'data_format\'] in [\'channels_first\', \'channels_last\']\n        self.config = config\n        self.data_provider = data_provider\n        self.input_size = 512\n        if config[\'data_format\'] == \'channels_last\':\n            self.data_shape = [512, 512, 3]\n        else:\n            self.data_shape = [3, 512, 512]\n        self.num_classes = config[\'num_classes\'] + 1\n        self.weight_decay = config[\'weight_decay\']\n        self.prob = 1. - config[\'keep_prob\']\n        self.data_format = config[\'data_format\']\n        self.mode = config[\'mode\']\n        self.batch_size = config[\'batch_size\'] if config[\'mode\'] == \'train\' else 1\n        self.nms_score_threshold = config[\'nms_score_threshold\']\n        self.nms_max_boxes = config[\'nms_max_boxes\']\n        self.nms_iou_threshold = config[\'nms_iou_threshold\']\n        self.reader = wrap.NewCheckpointReader(config[\'pretraining_weight\'])\n\n        if self.mode == \'train\':\n            self.num_train = data_provider[\'num_train\']\n            self.num_val = data_provider[\'num_val\']\n            self.train_generator = data_provider[\'train_generator\']\n            self.train_initializer, self.train_iterator = self.train_generator\n            if data_provider[\'val_generator\'] is not None:\n                self.val_generator = data_provider[\'val_generator\']\n                self.val_initializer, self.val_iterator = self.val_generator\n\n        self.global_step = tf.get_variable(name=\'global_step\', initializer=tf.constant(0), trainable=False)\n        self.is_training = True\n\n        self._define_inputs()\n        self._build_graph()\n        self._create_saver()\n        if self.mode == \'train\':\n            self._create_summary()\n        self._init_session()\n\n    def _define_inputs(self):\n        shape = [self.batch_size]\n        shape.extend(self.data_shape)\n        mean = tf.convert_to_tensor([123.68, 116.779, 103.979], dtype=tf.float32)\n        if self.data_format == \'channels_last\':\n            mean = tf.reshape(mean, [1, 1, 1, 3])\n        else:\n            mean = tf.reshape(mean, [1, 3, 1, 1])\n        if self.mode == \'train\':\n            self.images, self.ground_truth = self.train_iterator.get_next()\n            self.images.set_shape(shape)\n            self.images = self.images - mean\n        else:\n            self.images = tf.placeholder(tf.float32, shape, name=\'images\')\n            self.images = self.images - mean\n            self.ground_truth = tf.placeholder(tf.float32, [self.batch_size, None, 5], name=\'labels\')\n        self.lr = tf.placeholder(dtype=tf.float32, shape=[], name=\'lr\')\n\n    def _build_graph(self):\n        with tf.variable_scope(\'feature_extractor\'):\n            feat1, feat2, feat3, feat4, feat5, feat6, feat7 = self._feature_extractor(self.images)\n            axes = 3 if self.data_format == \'channels_last\' else 1\n            feat1 = tf.nn.l2_normalize(feat1, axis=axes)\n            channels = tf.shape(feat1)[axes]\n            norm_factor = tf.get_variable(\'l2_norm_factor\', shape=[1], initializer=tf.constant_initializer(20.))\n            norm_factor = tf.tile(norm_factor, [channels])\n            if self.data_format == \'channels_last\':\n                norm_factor = tf.reshape(norm_factor, [1, 1, 1, -1])\n            else:\n                norm_factor = tf.reshape(norm_factor, [1, -1, 1, 1])\n            feat1 = norm_factor * feat1\n        with tf.variable_scope(\'regressor\'):\n            pred1 = self._conv_layer(feat1, 4*(self.num_classes+4), 3, 1, \'pred1\')\n            pred2 = self._conv_layer(feat2, 6*(self.num_classes+4), 3, 1, \'pred2\')\n            pred3 = self._conv_layer(feat3, 6*(self.num_classes+4), 3, 1, \'pred3\')\n            pred4 = self._conv_layer(feat4, 6*(self.num_classes+4), 3, 1, \'pred4\')\n            pred5 = self._conv_layer(feat5, 6*(self.num_classes+4), 3, 1, \'pred5\')\n            pred6 = self._conv_layer(feat6, 4*(self.num_classes+4), 3, 1, \'pred6\')\n            pred7 = self._conv_layer(feat7, 4*(self.num_classes+4), 3, 1, \'pred7\')\n            if self.data_format == \'channels_first\':\n                pred1 = tf.transpose(pred1, [0, 2, 3, 1])\n                pred2 = tf.transpose(pred2, [0, 2, 3, 1])\n                pred3 = tf.transpose(pred3, [0, 2, 3, 1])\n                pred4 = tf.transpose(pred4, [0, 2, 3, 1])\n                pred5 = tf.transpose(pred5, [0, 2, 3, 1])\n                pred6 = tf.transpose(pred6, [0, 2, 3, 1])\n                pred7 = tf.transpose(pred7, [0, 2, 3, 1])\n            p1shape = tf.shape(pred1)\n            p2shape = tf.shape(pred2)\n            p3shape = tf.shape(pred3)\n            p4shape = tf.shape(pred4)\n            p5shape = tf.shape(pred5)\n            p6shape = tf.shape(pred6)\n            p7shape = tf.shape(pred7)\n        with tf.variable_scope(\'inference\'):\n            p1bbox_yx, p1bbox_hw, p1conf = self._get_pbbox(pred1)\n            p2bbox_yx, p2bbox_hw, p2conf = self._get_pbbox(pred2)\n            p3bbox_yx, p3bbox_hw, p3conf = self._get_pbbox(pred3)\n            p4bbox_yx, p4bbox_hw, p4conf = self._get_pbbox(pred4)\n            p5bbox_yx, p5bbox_hw, p5conf = self._get_pbbox(pred5)\n            p6bbox_yx, p6bbox_hw, p6conf = self._get_pbbox(pred6)\n            p7bbox_yx, p7bbox_hw, p7conf = self._get_pbbox(pred7)\n\n            s = [0.07 * self.input_size]\n            s = s + [(0.15 + (0.9 - 0.15) / 5 * (i-1)) * self.input_size for i in range(1, 8)]\n            s = [[s[i], (s[i]*s[i+1])**0.5] for i in range(0, 7)]\n            a1bbox_y1x1, a1bbox_y2x2, a1bbox_yx, a1bbox_hw = self._get_abbox(s[0], [2, 1/2], p1shape)\n            a2bbox_y1x1, a2bbox_y2x2, a2bbox_yx, a2bbox_hw = self._get_abbox(s[1], [2, 1/2, 3, 1/3], p2shape)\n            a3bbox_y1x1, a3bbox_y2x2, a3bbox_yx, a3bbox_hw = self._get_abbox(s[2], [2, 1/2, 3, 1/3], p3shape)\n            a4bbox_y1x1, a4bbox_y2x2, a4bbox_yx, a4bbox_hw = self._get_abbox(s[3], [2, 1/2, 3, 1/3], p4shape)\n            a5bbox_y1x1, a5bbox_y2x2, a5bbox_yx, a5bbox_hw = self._get_abbox(s[4], [2, 1/2, 3, 1/3], p5shape)\n            a6bbox_y1x1, a6bbox_y2x2, a6bbox_yx, a6bbox_hw = self._get_abbox(s[5], [2, 1/2], p6shape)\n            a7bbox_y1x1, a7bbox_y2x2, a7bbox_yx, a7bbox_hw = self._get_abbox(s[6], [2, 1/2], p7shape)\n\n            pbbox_yx = tf.concat([p1bbox_yx, p2bbox_yx, p3bbox_yx, p4bbox_yx, p5bbox_yx, p6bbox_yx, p7bbox_yx], axis=1)\n            pbbox_hw = tf.concat([p1bbox_hw, p2bbox_hw, p3bbox_hw, p4bbox_hw, p5bbox_hw, p6bbox_hw, p7bbox_hw], axis=1)\n            pconf = tf.concat([p1conf, p2conf, p3conf, p4conf, p5conf, p6conf, p7conf], axis=1)\n            abbox_y1x1 = tf.concat([a1bbox_y1x1, a2bbox_y1x1, a3bbox_y1x1, a4bbox_y1x1, a5bbox_y1x1, a6bbox_y1x1, a7bbox_y1x1], axis=0)\n            abbox_y2x2 = tf.concat([a1bbox_y2x2, a2bbox_y2x2, a3bbox_y2x2, a4bbox_y2x2, a5bbox_y2x2, a6bbox_y2x2, a7bbox_y2x2], axis=0)\n            abbox_yx = tf.concat([a1bbox_yx, a2bbox_yx, a3bbox_yx, a4bbox_yx, a5bbox_yx, a6bbox_yx, a7bbox_yx], axis=0)\n            abbox_hw = tf.concat([a1bbox_hw, a2bbox_hw, a3bbox_hw, a4bbox_hw, a5bbox_hw, a6bbox_hw, a7bbox_hw], axis=0)\n            if self.mode == \'train\':\n                i = 0.\n                loss = 0.\n                cond = lambda loss, i: tf.less(i, tf.cast(self.batch_size, tf.float32))\n                body = lambda loss, i: (\n                    tf.add(loss, self._compute_one_image_loss(\n                        tf.squeeze(tf.gather(pbbox_yx, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(pbbox_hw, tf.cast(i, tf.int32))),\n                        abbox_y1x1,\n                        abbox_y2x2,\n                        abbox_yx,\n                        abbox_hw,\n                        tf.squeeze(tf.gather(pconf, tf.cast(i, tf.int32))),\n                        tf.squeeze(tf.gather(self.ground_truth, tf.cast(i, tf.int32))),\n                    )),\n                    tf.add(i, 1.)\n                )\n                init_state = (loss, i)\n                state = tf.while_loop(cond, body, init_state)\n                total_loss, _ = state\n                total_loss = total_loss / self.batch_size\n                optimizer = tf.train.MomentumOptimizer(learning_rate=self.lr, momentum=.9)\n                self.loss = total_loss + self.weight_decay * tf.add_n(\n                    [tf.nn.l2_loss(var) for var in tf.trainable_variables()]\n                )\n                update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n                train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n                self.train_op = tf.group([update_ops, train_op])\n            else:\n                pbbox_yxt = pbbox_yx[0, ...]\n                pbbox_hwt = pbbox_hw[0, ...]\n                confidence = tf.nn.softmax(pconf[0, ...])\n                class_id = tf.argmax(confidence, axis=-1)\n                conf_mask = tf.less(class_id, self.num_classes - 1)\n                pbbox_yxt = tf.boolean_mask(pbbox_yxt, conf_mask)\n                pbbox_hwt = tf.boolean_mask(pbbox_hwt, conf_mask)\n                confidence = tf.boolean_mask(confidence, conf_mask)[:, :self.num_classes - 1]\n                abbox_yxt = tf.boolean_mask(abbox_yx, conf_mask)\n                abbox_hwt = tf.boolean_mask(abbox_hw, conf_mask)\n                dpbbox_yxt = pbbox_yxt * abbox_hwt + abbox_yxt\n                dpbbox_hwt = abbox_hwt * tf.exp(pbbox_hwt)\n                dpbbox_y1x1 = dpbbox_yxt - dpbbox_hwt / 2.\n                dpbbox_y2x2 = dpbbox_yxt + dpbbox_hwt / 2.\n                dpbbox_y1x1y2x2 = tf.concat([dpbbox_y1x1, dpbbox_y2x2], axis=-1)\n                filter_mask = tf.greater_equal(confidence, self.nms_score_threshold)\n                scores = []\n                class_id = []\n                bbox = []\n                for i in range(self.num_classes - 1):\n                    scoresi = tf.boolean_mask(confidence[:, i], filter_mask[:, i])\n                    bboxi = tf.boolean_mask(dpbbox_y1x1y2x2, filter_mask[:, i])\n                    selected_indices = tf.image.non_max_suppression(\n\n                        bboxi, scoresi, self.nms_max_boxes, self.nms_iou_threshold,\n                    )\n                    scores.append(tf.gather(scoresi, selected_indices))\n                    bbox.append(tf.gather(bboxi, selected_indices))\n                    class_id.append(tf.ones_like(tf.gather(scoresi, selected_indices), tf.int32) * i)\n                bbox = tf.concat(bbox, axis=0)\n                scores = tf.concat(scores, axis=0)\n                class_id = tf.concat(class_id, axis=0)\n\n                self.detection_pred = [scores, bbox, class_id]\n\n    def _feature_extractor(self, images):\n        conv1_1 = self._load_conv_layer(images,\n                                        tf.get_variable(name=\'kernel_conv1_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv1_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_1/biases""),\n                                                        trainable=True),\n                                        name=""conv1_1"")\n        conv1_2 = self._load_conv_layer(conv1_1,\n                                        tf.get_variable(name=\'kernel_conv1_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv1_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv1/conv1_2/biases""),\n                                                        trainable=True),\n                                        name=""conv1_2"")\n        pool1 = self._max_pooling(conv1_2, 2, 2, name=""pool1"")\n\n        conv2_1 = self._load_conv_layer(pool1,\n                                        tf.get_variable(name=\'kenrel_conv2_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv2_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_1/biases""),\n                                                        trainable=True),\n                                        name=""conv2_1"")\n        conv2_2 = self._load_conv_layer(conv2_1,\n                                        tf.get_variable(name=\'kernel_conv2_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv2_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv2/conv2_2/biases""),\n                                                        trainable=True),\n                                        name=""conv2_2"")\n        pool2 = self._max_pooling(conv2_2, 2, 2, name=""pool2"")\n        conv3_1 = self._load_conv_layer(pool2,\n                                        tf.get_variable(name=\'kernel_conv3_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv_3_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_1/biases""),\n                                                        trainable=True),\n                                        name=""conv3_1"")\n        conv3_2 = self._load_conv_layer(conv3_1,\n                                        tf.get_variable(name=\'kernel_conv3_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv3_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_2/biases""),\n                                                        trainable=True),\n                                        name=""conv3_2"")\n        conv3_3 = self._load_conv_layer(conv3_2,\n                                        tf.get_variable(name=\'kernel_conv3_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_3/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv3_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv3/conv3_3/biases""),\n                                                        trainable=True),\n                                        name=""conv3_3"")\n        pool3 = self._max_pooling(conv3_3, 2, 2, name=""pool3"")\n\n        conv4_1 = self._load_conv_layer(pool3,\n                                        tf.get_variable(name=\'kernel_conv4_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv4_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_1/biases""),\n                                                        trainable=True),\n                                        name=""conv4_1"")\n        conv4_2 = self._load_conv_layer(conv4_1,\n                                        tf.get_variable(name=\'kernel_conv4_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv4_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_2/biases""),\n                                                        trainable=True),\n                                        name=""conv4_2"")\n        conv4_3 = self._load_conv_layer(conv4_2,\n                                        tf.get_variable(name=\'kernel_conv4_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_3/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv4_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv4/conv4_3/biases""),\n                                                        trainable=True),\n                                        name=""conv4_3"")\n        pool4 = self._max_pooling(conv4_3, 2, 2, name=""pool4"")\n        conv5_1 = self._load_conv_layer(pool4,\n                                        tf.get_variable(name=\'kernel_conv5_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_1/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv5_1\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_1/biases""),\n                                                        trainable=True),\n                                        name=""conv5_1"")\n        conv5_2 = self._load_conv_layer(conv5_1,\n                                        tf.get_variable(name=\'kernel_conv5_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_2/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv5_2\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_2/biases""),\n                                                        trainable=True),\n                                        name=""conv5_2"")\n        conv5_3 = self._load_conv_layer(conv5_2,\n                                        tf.get_variable(name=\'kernel_conv5_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_3/weights""),\n                                                        trainable=True),\n                                        tf.get_variable(name=\'bias_conv5_3\',\n                                                        initializer=self.reader.get_tensor(""vgg_16/conv5/conv5_3/biases""),\n                                                        trainable=True),\n                                        name=""conv5_3"")\n        pool5 = self._max_pooling(conv5_3, 3, 1, \'pool5\')\n        conv6 = self._conv_layer(pool5, 1024, 3, 1, \'conv6\', dilation_rate=2, activation=tf.nn.relu)\n        conv7 = self._conv_layer(conv6, 1024, 1, 1, \'conv7\', activation=tf.nn.relu)\n        conv8_1 = self._conv_layer(conv7, 256, 1, 1, \'conv8_1\', activation=tf.nn.relu)\n        conv8_2 = self._conv_layer(conv8_1, 512, 3, 2, \'conv8_2\', activation=tf.nn.relu)\n        conv9_1 = self._conv_layer(conv8_2, 128, 1, 1, \'conv9_1\', activation=tf.nn.relu)\n        conv9_2 = self._conv_layer(conv9_1, 256, 3, 2, \'conv9_2\', activation=tf.nn.relu)\n        conv10_1 = self._conv_layer(conv9_2, 128, 1, 1, \'conv10_1\', activation=tf.nn.relu)\n        conv10_2 = self._conv_layer(conv10_1, 256, 3, 1, \'conv10_2\', activation=tf.nn.relu)\n        conv11_1 = self._conv_layer(conv10_2, 128, 1, 1, \'conv11_1\', activation=tf.nn.relu)\n        conv11_2 = self._conv_layer(conv11_1, 256, 3, 2, \'conv11_2\', activation=tf.nn.relu)\n        conv12_1 = self._conv_layer(conv11_2, 128, 1, 1, \'conv12_1\', activation=tf.nn.relu)\n        conv12_2 = self._conv_layer(conv12_1, 256, 3, 2, \'conv12_2\', activation=tf.nn.relu)\n        return conv4_3, conv7, conv8_2, conv9_2, conv10_2, conv11_2, conv12_2\n\n    def _get_pbbox(self, pred):\n        pred = tf.reshape(pred, [self.batch_size, -1, self.num_classes+4])\n        pconf = pred[..., :self.num_classes]\n        pbbox_yx = pred[..., self.num_classes:self.num_classes+2]\n        pbbox_hw = pred[..., self.num_classes+2:]\n        return pbbox_yx, pbbox_hw, pconf\n\n    def _get_abbox(self, size, aspect_ratio, pshape):\n        topleft_y = tf.range(0., tf.cast(pshape[1], tf.float32), dtype=tf.float32)\n        topleft_x = tf.range(0., tf.cast(pshape[2], tf.float32), dtype=tf.float32)\n        topleft_y = tf.reshape(topleft_y, [-1, 1, 1, 1]) + 0.5\n        topleft_x = tf.reshape(topleft_x, [1, -1, 1, 1]) + 0.5\n        topleft_y = tf.tile(topleft_y, [1, pshape[2], 1, 1]) * tf.cast(self.input_size, tf.float32) / tf.cast(pshape[1], tf.float32)\n        topleft_x = tf.tile(topleft_x, [pshape[1], 1, 1, 1]) * tf.cast(self.input_size, tf.float32) / tf.cast(pshape[2], tf.float32)\n        topleft_yx = tf.concat([topleft_y, topleft_x], -1)\n        topleft_yx = tf.tile(topleft_yx, [1, 1, len(aspect_ratio)+2, 1])\n\n        priors = [[size[0], size[0]], [size[1], size[1]]]\n        for i in range(len(aspect_ratio)):\n            priors.append([size[0]*(aspect_ratio[i]**0.5), size[0]/(aspect_ratio[i]**0.5)])\n        priors = tf.convert_to_tensor(priors, tf.float32)\n        priors = tf.reshape(priors, [1, 1, -1, 2])\n\n        abbox_y1x1 = tf.reshape(topleft_yx - priors / 2., [-1, 2])\n        abbox_y2x2 = tf.reshape(topleft_yx + priors / 2., [-1, 2])\n        abbox_yx = abbox_y1x1 / 2. + abbox_y2x2 / 2.\n        abbox_hw = abbox_y2x2 - abbox_y1x1\n        return abbox_y1x1, abbox_y2x2, abbox_yx, abbox_hw\n\n    def _compute_one_image_loss(self, pbbox_yx, pbbox_hw, abbox_y1x1, abbox_y2x2,\n                                abbox_yx, abbox_hw, pconf, ground_truth):\n        slice_index = tf.argmin(ground_truth, axis=0)[0]\n        ground_truth = tf.gather(ground_truth, tf.range(0, slice_index, dtype=tf.int64))\n        gbbox_yx = ground_truth[..., 0:2]\n        gbbox_hw = ground_truth[..., 2:4]\n        gbbox_y1x1 = gbbox_yx - gbbox_hw / 2.\n        gbbox_y2x2 = gbbox_yx + gbbox_hw / 2.\n        class_id = tf.cast(ground_truth[..., 4:5], dtype=tf.int32)\n        label = class_id\n\n        abbox_hwti = tf.reshape(abbox_hw, [1, -1, 2])\n        abbox_y1x1ti = tf.reshape(abbox_y1x1, [1, -1, 2])\n        abbox_y2x2ti = tf.reshape(abbox_y2x2, [1, -1, 2])\n        gbbox_hwti = tf.reshape(gbbox_hw, [-1, 1, 2])\n        gbbox_y1x1ti = tf.reshape(gbbox_y1x1, [-1, 1, 2])\n        gbbox_y2x2ti = tf.reshape(gbbox_y2x2, [-1, 1, 2])\n        ashape = tf.shape(abbox_hwti)\n        gshape = tf.shape(gbbox_hwti)\n        abbox_hwti = tf.tile(abbox_hwti, [gshape[0], 1, 1])\n        abbox_y1x1ti = tf.tile(abbox_y1x1ti, [gshape[0], 1, 1])\n        abbox_y2x2ti = tf.tile(abbox_y2x2ti, [gshape[0], 1, 1])\n        gbbox_hwti = tf.tile(gbbox_hwti, [1, ashape[1], 1])\n        gbbox_y1x1ti = tf.tile(gbbox_y1x1ti, [1, ashape[1], 1])\n        gbbox_y2x2ti = tf.tile(gbbox_y2x2ti, [1, ashape[1], 1])\n\n        gaiou_y1x1ti = tf.maximum(abbox_y1x1ti, gbbox_y1x1ti)\n        gaiou_y2x2ti = tf.minimum(abbox_y2x2ti, gbbox_y2x2ti)\n        gaiou_area = tf.reduce_prod(tf.maximum(gaiou_y2x2ti - gaiou_y1x1ti, 0), axis=-1)\n        aarea = tf.reduce_prod(abbox_hwti, axis=-1)\n        garea = tf.reduce_prod(gbbox_hwti, axis=-1)\n        gaiou_rate = gaiou_area / (aarea + garea - gaiou_area)\n\n        best_raindex = tf.argmax(gaiou_rate, axis=1)\n        best_pbbox_yx = tf.gather(pbbox_yx, best_raindex)\n        best_pbbox_hw = tf.gather(pbbox_hw, best_raindex)\n        best_pconf = tf.gather(pconf, best_raindex)\n        best_abbox_yx = tf.gather(abbox_yx, best_raindex)\n        best_abbox_hw = tf.gather(abbox_hw, best_raindex)\n\n        bestmask, _ = tf.unique(best_raindex)\n        bestmask = tf.contrib.framework.sort(bestmask)\n        bestmask = tf.reshape(bestmask, [-1, 1])\n        bestmask = tf.sparse.SparseTensor(tf.concat([bestmask, tf.zeros_like(bestmask)], axis=-1),\n                                          tf.squeeze(tf.ones_like(bestmask)), dense_shape=[ashape[1], 1])\n        bestmask = tf.reshape(tf.cast(tf.sparse.to_dense(bestmask), tf.float32), [-1])\n\n        othermask = 1. - bestmask\n        othermask = othermask > 0.\n        other_pbbox_yx = tf.boolean_mask(pbbox_yx, othermask)\n        other_pbbox_hw = tf.boolean_mask(pbbox_hw, othermask)\n        other_pconf = tf.boolean_mask(pconf, othermask)\n\n        other_abbox_yx = tf.boolean_mask(abbox_yx, othermask)\n        other_abbox_hw = tf.boolean_mask(abbox_hw, othermask)\n\n        agiou_rate = tf.transpose(gaiou_rate)\n        other_agiou_rate = tf.boolean_mask(agiou_rate, othermask)\n        best_agiou_rate = tf.reduce_max(other_agiou_rate, axis=1)\n        pos_agiou_mask = best_agiou_rate > 0.5\n        neg_agiou_mask = (1. - tf.cast(pos_agiou_mask, tf.float32)) > 0.\n        rgindex = tf.argmax(other_agiou_rate, axis=1)\n        pos_rgindex = tf.boolean_mask(rgindex, pos_agiou_mask)\n        pos_pbbox_yx = tf.boolean_mask(other_pbbox_yx, pos_agiou_mask)\n        pos_pbbox_hw = tf.boolean_mask(other_pbbox_hw, pos_agiou_mask)\n        pos_pconf = tf.boolean_mask(other_pconf, pos_agiou_mask)\n        pos_abbox_yx = tf.boolean_mask(other_abbox_yx, pos_agiou_mask)\n        pos_abbox_hw = tf.boolean_mask(other_abbox_hw, pos_agiou_mask)\n        pos_label = tf.gather(label, pos_rgindex)\n        pos_gbbox_yx = tf.gather(gbbox_yx, pos_rgindex)\n        pos_gbbox_hw = tf.gather(gbbox_hw, pos_rgindex)\n        pos_shape = tf.shape(pos_pconf)\n\n        neg_pconf = tf.boolean_mask(other_pconf, neg_agiou_mask)\n        neg_abbox_yx = tf.boolean_mask(other_abbox_yx, neg_agiou_mask)\n        neg_abbox_hw = tf.boolean_mask(other_abbox_hw, neg_agiou_mask)\n        neg_abbox_y1x1y2x2 = tf.concat([neg_abbox_yx - neg_abbox_hw/2., neg_abbox_yx + neg_abbox_hw/2.], axis=-1)\n\n        neg_shape = tf.shape(neg_pconf)\n        num_pos = gshape[0] + pos_shape[0]\n        num_neg = neg_shape[0]\n        chosen_num_neg = tf.cond(num_neg > 3*num_pos, lambda: 3*num_pos, lambda: num_neg)\n        neg_class_id = tf.constant([self.num_classes-1])\n        neg_label = tf.tile(neg_class_id, [num_neg])\n\n        total_neg_loss = tf.losses.sparse_softmax_cross_entropy(neg_label, neg_pconf, reduction=tf.losses.Reduction.NONE)\n        selected_indices = tf.image.non_max_suppression(\n            neg_abbox_y1x1y2x2, total_neg_loss, chosen_num_neg, iou_threshold=0.7\n        )\n        neg_loss = tf.reduce_mean(tf.gather(total_neg_loss, selected_indices))\n\n        total_pos_pbbox_yx = tf.concat([best_pbbox_yx, pos_pbbox_yx], axis=0)\n        total_pos_pbbox_hw = tf.concat([best_pbbox_hw, pos_pbbox_hw], axis=0)\n        total_pos_pconf = tf.concat([best_pconf, pos_pconf], axis=0)\n        total_pos_label = tf.concat([label, pos_label], axis=0)\n        total_pos_gbbox_yx = tf.concat([gbbox_yx, pos_gbbox_yx], axis=0)\n        total_pos_gbbox_hw = tf.concat([gbbox_hw, pos_gbbox_hw], axis=0)\n        total_pos_abbox_yx = tf.concat([best_abbox_yx, pos_abbox_yx], axis=0)\n        total_pos_abbox_hw = tf.concat([best_abbox_hw, pos_abbox_hw], axis=0)\n\n        pos_conf_loss = tf.losses.sparse_softmax_cross_entropy(total_pos_label, total_pos_pconf, reduction=tf.losses.Reduction.MEAN)\n        pos_truth_pbbox_yx = (total_pos_gbbox_yx - total_pos_abbox_yx) / total_pos_abbox_hw\n        pos_truth_pbbox_hw = tf.log(total_pos_gbbox_hw / total_pos_abbox_hw)\n        pos_yx_loss = tf.reduce_sum(self._smooth_l1_loss(total_pos_pbbox_yx - pos_truth_pbbox_yx), axis=-1)\n        pos_hw_loss = tf.reduce_sum(self._smooth_l1_loss(total_pos_pbbox_hw - pos_truth_pbbox_hw), axis=-1)\n        pos_coord_loss = tf.reduce_mean(pos_yx_loss + pos_hw_loss)\n\n        total_loss = neg_loss + pos_conf_loss + pos_coord_loss\n        return total_loss\n\n    def _smooth_l1_loss(self, x):\n        return tf.where(tf.abs(x) < 1., 0.5*x*x, tf.abs(x)-0.5)\n\n    def _init_session(self):\n        self.sess = tf.InteractiveSession()\n        self.sess.run(tf.global_variables_initializer())\n        if self.mode == \'train\':\n            self.sess.run(self.train_initializer)\n\n    def _create_saver(self):\n        self.saver = tf.train.Saver()\n        self.best_saver = tf.train.Saver()\n\n    def _create_summary(self):\n        with tf.variable_scope(\'summaries\'):\n            tf.summary.scalar(\'loss\', self.loss)\n            self.summary_op = tf.summary.merge_all()\n\n    def train_one_epoch(self, lr):\n        self.is_training = True\n        self.sess.run(self.train_initializer)\n        mean_loss = []\n        num_iters = self.num_train // self.batch_size\n        for i in range(num_iters):\n            _, loss = self.sess.run([self.train_op, self.loss], feed_dict={self.lr: lr})\n            sys.stdout.write(\'\\r>> \' + \'iters \'+str(i)+str(\'/\')+str(num_iters)+\' loss \'+str(loss))\n            sys.stdout.flush()\n            mean_loss.append(loss)\n        sys.stdout.write(\'\\n\')\n        mean_loss = np.mean(mean_loss)\n        return mean_loss\n\n    def test_one_image(self, images):\n        self.is_training = False\n        pred = self.sess.run(self.detection_pred, feed_dict={self.images: images})\n        return pred\n\n    def save_weight(self, mode, path):\n        assert(mode in [\'latest\', \'best\'])\n        if mode == \'latest\':\n            saver = self.saver\n        else:\n            saver = self.best_saver\n        if not tf.gfile.Exists(os.path.dirname(path)):\n            tf.gfile.MakeDirs(os.path.dirname(path))\n            print(os.path.dirname(path), \'does not exist, create it done\')\n        saver.save(self.sess, path, global_step=self.global_step)\n        print(\'save\', mode, \'model in\', path, \'successfully\')\n\n    def load_weight(self, path):\n        self.saver.restore(self.sess, path)\n        print(\'load weight\', path, \'successfully\')\n\n    def _bn(self, bottom):\n        bn = tf.layers.batch_normalization(\n            inputs=bottom,\n            axis=3 if self.data_format == \'channels_last\' else 1,\n            training=self.is_training\n        )\n        return bn\n\n    def _load_conv_layer(self, bottom, filters, bias, name):\n        if self.data_format == \'channels_last\':\n            data_format = \'NHWC\'\n        else:\n            data_format = \'NCHW\'\n        conv = tf.nn.conv2d(bottom, filter=filters, strides=[1, 1, 1, 1], name=""kernel""+name, padding=""SAME"", data_format=data_format)\n        conv_bias = tf.nn.bias_add(conv, bias=bias, name=""bias""+name)\n        return tf.nn.relu(conv_bias)\n\n    def _conv_layer(self, bottom, filters, kernel_size, strides, name, dilation_rate=1, activation=None):\n        conv = tf.layers.conv2d(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=\'same\',\n            name=name,\n            data_format=self.data_format,\n            dilation_rate=dilation_rate,\n        )\n        bn = self._bn(conv)\n        if activation is not None:\n            bn = activation(bn)\n        return bn\n\n    def _max_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.max_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding=\'same\',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _avg_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.average_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding=\'same\',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _dropout(self, bottom, name):\n        return tf.layers.dropout(\n            inputs=bottom,\n            rate=self.prob,\n            training=self.is_training,\n            name=name\n        )\n'"
YOLOv2.py,141,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nimport os\nimport sys\nimport numpy as np\n\n\nclass YOLOv2:\n    def __init__(self, config, data_provider):\n\n        assert len(config['data_shape']) == 3\n        assert config['mode'] in ['train', 'test']\n        assert config['data_format'] in ['channels_first', 'channels_last']\n        self.config = config\n        self.data_provider = data_provider\n        self.data_shape = config['data_shape']\n        self.num_classes = config['num_classes']\n        self.weight_decay = config['weight_decay']\n        self.prob = 1. - config['keep_prob']\n        self.data_format = config['data_format']\n        self.mode = config['mode']\n        self.batch_size = config['batch_size'] if config['mode'] == 'train' else 1\n        self.coord_sacle = config['coord_scale']\n        self.noobj_scale = config['noobj_scale']\n        self.obj_scale = config['obj_scale']\n        self.class_scale = config['class_scale']\n        self.nms_score_threshold = config['nms_score_threshold']\n        self.nms_max_boxes = config['nms_max_boxes']\n        self.nms_iou_threshold = config['nms_iou_threshold']\n        self.rescore_confidence = config['rescore_confidence']\n        self.num_priors = len(config['priors'])\n        priors = tf.convert_to_tensor(config['priors'], dtype=tf.float32)\n        self.priors = tf.reshape(priors, [1, 1, self.num_priors, 2])\n        self.final_units = (self.num_classes + 5) * self.num_priors\n\n        if self.mode == 'train':\n            self.num_train = data_provider['num_train']\n            self.num_val = data_provider['num_val']\n            self.train_generator = data_provider['train_generator']\n            self.train_initializer, self.train_iterator = self.train_generator\n            if data_provider['val_generator'] is not None:\n                self.val_generator = data_provider['val_generator']\n                self.val_initializer, self.val_iterator = self.val_generator\n\n        self.global_step = tf.get_variable(name='global_step', initializer=tf.constant(0), trainable=False)\n        self.is_training = True\n\n        self._define_inputs()\n        self._build_graph()\n        self._create_saver()\n        if self.mode == 'train':\n            self._create_summary()\n        self._init_session()\n\n    def _define_inputs(self):\n        shape = [self.batch_size]\n        shape.extend(self.data_shape)\n        mean = tf.convert_to_tensor([123.68, 116.779, 103.979], dtype=tf.float32)\n        if self.data_format == 'channels_last':\n            mean = tf.reshape(mean, [1, 1, 1, 3])\n        else:\n            mean = tf.reshape(mean, [1, 3, 1, 1])\n        if self.mode == 'train':\n            self.images, self.ground_truth = self.train_iterator.get_next()\n            self.images.set_shape(shape)\n            self.images = self.images - mean\n        else:\n            self.images = tf.placeholder(tf.float32, shape, name='images')\n            self.images = self.images - mean\n            self.ground_truth = tf.placeholder(tf.float32, [self.batch_size, None, 5], name='labels')\n        self.lr = tf.placeholder(dtype=tf.float32, shape=[], name='lr')\n\n    def _build_graph(self):\n        with tf.variable_scope('backone'):\n            features, passthrough, downsampling_rate = self._feature_extractor(self.images)\n        with tf.variable_scope('head'):\n            conv1 = self._conv_layer(features, 1024, 3, 1, 'conv1')\n            lrelu1 = tf.nn.leaky_relu(conv1, 0.1, 'lrelu1')\n            conv2 = self._conv_layer(lrelu1, 512, 1, 1, 'conv2')\n            lrelu2 = tf.nn.leaky_relu(conv2, 0.1, 'lrelu2')\n            conv3 = self._conv_layer(lrelu2, 1024, 3, 1, 'conv3')\n            lrelu3 = tf.nn.leaky_relu(conv3, 0.1, 'lrelu3')\n            conv4 = self._conv_layer(lrelu3, 512, 1, 1, 'conv4')\n            lrelu4 = tf.nn.leaky_relu(conv4, 0.1, 'lrelu4')\n            conv5 = self._conv_layer(lrelu4, 1024, 3, 1, 'conv5')\n            lrelu5 = tf.nn.leaky_relu(conv5, 0.1, 'lrelu5')\n            axes = 3 if self.data_format == 'channels_last' else 1\n            lrelu5 = tf.concat([passthrough, lrelu5], axis=axes)\n            pred = self._conv_layer(lrelu5, self.final_units, 1, 1, 'predictions')\n            if self.data_format == 'channels_first':\n                pred = tf.transpose(pred, [0, 2, 3, 1])\n            pshape = tf.shape(pred)\n\n            pred = tf.reshape(pred, [pshape[0], pshape[1], pshape[2], self.num_priors, -1])\n            pclass = pred[..., :self.num_classes]\n            pbbox_yx = pred[..., self.num_classes:self.num_classes + 2]\n            pbbox_hw = pred[..., self.num_classes + 2:self.num_classes + 4]\n            pobj = pred[..., self.num_classes + 4:]\n            abbox_yx, abbox_hw, abbox_y1x1, abbox_y2x2 = self._get_priors(pshape, self.priors)\n\n        if self.mode == 'train':\n            total_loss = []\n            for i in range(self.batch_size):\n                gn_yxi, gn_hwi, gn_labeli = self._get_normlized_gn(downsampling_rate, i)\n                gn_floor_ = tf.cast(tf.floor(gn_yxi), tf.int64)\n                nogn_mask = tf.sparse.SparseTensor(gn_floor_, tf.ones_like(gn_floor_[..., 0]), dense_shape=[pshape[1], pshape[2]])\n                nogn_mask = (1 - tf.sparse.to_dense(nogn_mask, validate_indices=False)) > 0\n                rpbbox_yx = tf.gather_nd(pbbox_yx[i, ...], gn_floor_)\n                rpbbox_hw = tf.gather_nd(pbbox_hw[i, ...], gn_floor_)\n                rabbox_hw = tf.gather_nd(abbox_hw, gn_floor_)\n                rpclass = tf.gather_nd(pclass[i, ...], gn_floor_)\n                rpobj = tf.gather_nd(pobj[i, ...], gn_floor_)\n                rabbox_y1x1 = tf.gather_nd(abbox_y1x1, gn_floor_)\n                rabbox_y2x2 = tf.gather_nd(abbox_y2x2, gn_floor_)\n                gn_y1x1i = tf.expand_dims(gn_yxi - gn_hwi / 2., axis=1)\n                gn_y2x2i = tf.expand_dims(gn_yxi + gn_hwi / 2., axis=1)\n                rgaiou_y1x1 = tf.maximum(gn_y1x1i, rabbox_y1x1)\n                rgaiou_y2x2 = tf.minimum(gn_y2x2i, rabbox_y2x2)\n\n                rgaiou_area = tf.reduce_prod(rgaiou_y2x2 - rgaiou_y1x1, axis=-1)\n\n                garea = tf.reduce_prod(gn_y2x2i - gn_y1x1i, axis=-1)\n                aarea = tf.reduce_prod(rabbox_hw, axis=-1)\n                rgaiou = rgaiou_area / (aarea + garea - rgaiou_area)\n\n                rgaindex = tf.expand_dims(tf.cast(tf.argmax(rgaiou, axis=-1), tf.int32), -1)\n                rgaindex = tf.concat([tf.expand_dims(tf.range(tf.shape(rgaindex)[0]), -1), rgaindex], axis=-1)\n\n                rpbbox_yx = tf.reshape(tf.gather_nd(rpbbox_yx, rgaindex), [-1, 2])\n                rpbbox_hw = tf.reshape(tf.gather_nd(rpbbox_hw, rgaindex), [-1, 2])\n\n                rpclass = tf.reshape(tf.gather_nd(rpclass, rgaindex), [-1, self.num_classes])\n                rpobj = tf.reshape(tf.gather_nd(rpobj, rgaindex), [-1, 1])\n                rabbox_hw = tf.reshape(tf.gather_nd(rabbox_hw, rgaindex), [-1, 2])\n\n                gn_labeli = tf.one_hot(gn_labeli, self.num_classes)\n                rpbbox_yx_target = gn_yxi - tf.floor(gn_yxi)\n                rpbbox_hw_target = tf.log(gn_hwi / rabbox_hw)\n                yx_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=rpbbox_yx_target, logits=rpbbox_yx))\n                hw_loss = 0.5 * tf.reduce_sum(tf.square(rpbbox_hw - rpbbox_hw_target))\n                coord_loss = yx_loss + hw_loss\n                class_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=gn_labeli, logits=rpclass))\n                obj_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(rpobj), logits=rpobj))\n                nogn_mask = tf.reshape(nogn_mask, [-1])\n\n                abbox_yx_nobest = tf.expand_dims(tf.boolean_mask(tf.reshape(abbox_yx-abbox_hw/2., [-1, self.num_priors, 2]), nogn_mask), 1)\n                abbox_hw_nobest = tf.expand_dims(tf.boolean_mask(tf.reshape(abbox_yx+abbox_hw/2., [-1, self.num_priors, 2]), nogn_mask), 1)\n                abbox_y1x1_nobest = abbox_yx_nobest - abbox_hw_nobest/2.\n                abbox_y2x2_nobest = abbox_yx_nobest + abbox_hw_nobest/2.\n                pobj_nobest = tf.boolean_mask(tf.reshape(pobj[i, ...], [-1, self.num_priors]), nogn_mask)\n\n\n                num_g = tf.shape(gn_y1x1i)[0]\n                num_p = tf.shape(abbox_y1x1_nobest)[0]\n                gn_y1x1i = tf.tile(tf.expand_dims(gn_y1x1i, 0), [num_p, 1, 1, 1])\n                gn_y2x2i = tf.tile(tf.expand_dims(gn_y2x2i, 0), [num_p, 1, 1, 1])\n\n                abbox_y1x1_nobest = tf.tile(abbox_y1x1_nobest, [1, num_g, 1, 1])\n                abbox_y2x2_nobest = tf.tile(abbox_y2x2_nobest, [1, num_g, 1, 1])\n                agiou_y1x1 = tf.maximum(gn_y1x1i, abbox_y1x1_nobest)\n                agiou_y2x2 = tf.minimum(gn_y2x2i, abbox_y2x2_nobest)\n\n                agiou_area = tf.reduce_prod(agiou_y2x2 - agiou_y1x1, axis=-1)\n                aarea = tf.reduce_prod(abbox_y2x2_nobest - abbox_y1x1_nobest, axis=-1)\n                garea = tf.reduce_prod(gn_y2x2i - gn_y1x1i, axis=-1)\n                agiou = agiou_area / (aarea + garea - agiou_area)\n                agiou = tf.reduce_max(agiou, axis=1)\n\n                noobj_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(pobj_nobest), logits=pobj_nobest)*tf.cast(agiou <= 0.6, tf.float32))\n                loss = self.coord_sacle * coord_loss + self.class_scale * class_loss + self.obj_scale * obj_loss + self.noobj_scale * noobj_loss\n                total_loss.append(loss)\n            total_loss = tf.reduce_mean(total_loss)\n            optimizer = tf.train.MomentumOptimizer(learning_rate=self.lr, momentum=0.9)\n            self.loss = total_loss + self.weight_decay * tf.add_n(\n                [tf.nn.l2_loss(var) for var in tf.trainable_variables()]\n            )\n            train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n            self.train_op = tf.group([update_ops, train_op])\n        else:\n            pclasst = tf.sigmoid(tf.reshape(pclass[0, ...], [-1, self.num_classes]))\n            pobjt = tf.sigmoid(tf.reshape(pobj[0, ...], [-1, 1]))\n            pbbox_yx = tf.reshape(pbbox_yx[0, ...], [-1, 2])\n            pbbox_hw = tf.reshape(pbbox_hw[0, ...], [-1, 2])\n            abbox_yx = tf.reshape(abbox_yx, [-1, 2])\n            abbox_hw = tf.reshape(abbox_hw, [-1, 2])\n            bbox_yx = abbox_yx + tf.sigmoid(pbbox_yx)\n            bbox_hw = abbox_hw + tf.exp(pbbox_hw)\n            bbox_y1x1y2x2 = tf.concat([bbox_yx - bbox_hw / 2., bbox_yx + bbox_hw / 2.], axis=-1) * downsampling_rate\n            confidence = pclasst * pobjt\n            filter_mask = tf.greater_equal(confidence, self.nms_score_threshold)\n            scores = []\n            class_id = []\n            bbox = []\n            for i in range(self.num_classes):\n                scoresi = tf.boolean_mask(confidence[:, i], filter_mask[:, i])\n                bboxi = tf.boolean_mask(bbox_y1x1y2x2, filter_mask[:, i])\n                selected_indices = tf.image.non_max_suppression(\n\n                    bboxi, scoresi, self.nms_max_boxes, self.nms_iou_threshold,\n                )\n                scores.append(tf.gather(scoresi, selected_indices))\n                bbox.append(tf.gather(bboxi, selected_indices))\n                class_id.append(tf.ones_like(tf.gather(scoresi, selected_indices), tf.int32) * i)\n            bbox = tf.concat(bbox, axis=0)\n            scores = tf.concat(scores, axis=0)\n            class_id = tf.concat(class_id, axis=0)\n            self.detection_pred = [scores, bbox, class_id]\n\n    def _init_session(self):\n        self.sess = tf.InteractiveSession()\n        self.sess.run(tf.global_variables_initializer())\n        if self.mode == 'train':\n            if self.train_initializer is not None:\n                self.sess.run(self.train_initializer)\n\n    def _create_saver(self):\n        weights = tf.trainable_variables(scope='backone')\n        self.pretraining_weight_saver = tf.train.Saver(weights)\n        self.saver = tf.train.Saver()\n        self.best_saver = tf.train.Saver()\n\n    def _create_summary(self):\n        with tf.variable_scope('summaries'):\n            tf.summary.scalar('loss', self.loss)\n            self.summary_op = tf.summary.merge_all()\n\n    def _get_priors(self, pshape, priors):\n        tl_y = tf.range(0., tf.cast(pshape[1], tf.float32), dtype=tf.float32)\n        tl_x = tf.range(0., tf.cast(pshape[2], tf.float32), dtype=tf.float32)\n        tl_y_ = tf.reshape(tl_y, [-1, 1, 1, 1])\n        tl_x_ = tf.reshape(tl_x, [1, -1, 1, 1])\n        tl_y_ = tf.tile(tl_y_, [1, pshape[2], 1, 1])\n        tl_x_ = tf.tile(tl_x_, [pshape[1], 1, 1, 1])\n        tl = tf.concat([tl_y_, tl_x_], -1)\n        abbox_yx = tl + 0.5\n        abbox_yx = tf.tile(abbox_yx, [1, 1, self.num_priors, 1])\n        abbox_hw = priors\n        abbox_hw = tf.tile(abbox_hw, [pshape[1], pshape[2], 1, 1])\n        abbox_y1x1 = abbox_yx - abbox_hw / 2\n        abbox_y2x2 = abbox_yx + abbox_hw / 2\n        return abbox_yx, abbox_hw, abbox_y1x1, abbox_y2x2\n\n    def _get_normlized_gn(self, downsampling_rate, i):\n\n        slice_index = tf.argmin(self.ground_truth[i, ...], axis=0)[0]\n        ground_truth = tf.gather(self.ground_truth[i, ...], tf.range(0, slice_index, dtype=tf.int64))\n        scale = tf.constant([downsampling_rate, downsampling_rate, downsampling_rate, downsampling_rate, 1], dtype=tf.float32)\n        scale = tf.reshape(scale, [1, 5])\n        gn = ground_truth / scale\n        return gn[..., :2], gn[..., 2:4], tf.cast(gn[..., 4], tf.int32)\n\n    def _feature_extractor(self, image):\n        conv1 = self._conv_layer(image, 32, 3, 1, 'conv1')\n        lrelu1 = tf.nn.leaky_relu(conv1, 0.1, 'lrelu1')\n        pool1 = self._max_pooling(lrelu1, 2, 2, 'pool1')\n\n        conv2 = self._conv_layer(pool1, 64, 3, 1, 'conv2')\n        lrelu2 = tf.nn.leaky_relu(conv2, 0.1, 'lrelu2')\n        pool2 = self._max_pooling(lrelu2, 2, 2, 'pool2')\n\n        conv3 = self._conv_layer(pool2, 128, 3, 1, 'conv3')\n        lrelu3 = tf.nn.leaky_relu(conv3, 0.1, 'lrelu3')\n        conv4 = self._conv_layer(lrelu3, 64, 1, 1, 'conv4')\n        lrelu4 = tf.nn.leaky_relu(conv4, 0.1, 'lrelu4')\n        conv5 = self._conv_layer(lrelu4, 128, 3, 1, 'conv5')\n        lrelu5 = tf.nn.leaky_relu(conv5, 0.1, 'lrelu5')\n        pool3 = self._max_pooling(lrelu5, 2, 2, 'pool3')\n\n        conv6 = self._conv_layer(pool3, 256, 3, 1, 'conv6')\n        lrelu6 = tf.nn.leaky_relu(conv6, 0.1, 'lrelu6')\n        conv7 = self._conv_layer(lrelu6, 128, 1, 1, 'conv7')\n        lrelu7 = tf.nn.leaky_relu(conv7, 0.1, 'lrelu7')\n        conv8 = self._conv_layer(lrelu7, 256, 3, 1, 'conv8')\n        lrelu8 = tf.nn.leaky_relu(conv8, 0.1, 'lrelu8')\n        pool4 = self._max_pooling(lrelu8, 2, 2, 'pool4')\n\n        conv9 = self._conv_layer(pool4, 512, 3, 1, 'conv9')\n        lrelu9 = tf.nn.leaky_relu(conv9, 0.1, 'lrelu9')\n        conv10 = self._conv_layer(lrelu9, 256, 1, 1, 'conv10')\n        lrelu10 = tf.nn.leaky_relu(conv10, 0.1, 'lrelu10')\n        conv11 = self._conv_layer(lrelu10, 512, 3, 1, 'conv11')\n        lrelu11 = tf.nn.leaky_relu(conv11, 0.1, 'lrelu11')\n        conv12 = self._conv_layer(lrelu11, 256, 1, 1, 'conv12')\n        lrelu12 = tf.nn.leaky_relu(conv12, 0.1, 'lrelu12')\n        conv13 = self._conv_layer(lrelu12, 512, 3, 1, 'conv13')\n        lrelu13 = tf.nn.leaky_relu(conv13, 0.1, 'lrelu13')\n        pool5 = self._max_pooling(lrelu13, 2, 2, 'pool5')\n\n        conv14 = self._conv_layer(pool5, 1024, 3, 1, 'conv14')\n        lrelu14 = tf.nn.leaky_relu(conv14, 0.1, 'lrelu14')\n        conv15 = self._conv_layer(lrelu14, 512, 1, 1, 'conv15')\n        lrelu15 = tf.nn.leaky_relu(conv15, 0.1, 'lrelu15')\n        conv16 = self._conv_layer(lrelu15, 1024, 3, 1, 'conv16')\n        lrelu16 = tf.nn.leaky_relu(conv16, 0.1, 'lrelu16')\n        conv17 = self._conv_layer(lrelu16, 512, 1, 1, 'conv17')\n        lrelu17 = tf.nn.leaky_relu(conv17, 0.1, 'lrelu17')\n        conv18 = self._conv_layer(lrelu17, 1024, 3, 1, 'conv18')\n        lrelu18 = tf.nn.leaky_relu(conv18, 0.1, 'lrelu18')\n        downsampling_rate = 32.0\n        return lrelu18, lrelu17, downsampling_rate\n\n    def train_one_epoch(self, lr, writer=None):\n        self.is_training = True\n        self.sess.run(self.train_initializer)\n        mean_loss = []\n        num_iters = self.num_train // self.batch_size\n        for i in range(num_iters):\n            _, loss, summaries = self.sess.run([self.train_op, self.loss, self.summary_op],\n                                               feed_dict={self.lr: lr})\n            sys.stdout.write('\\r>> ' + 'iters '+str(i+1)+str('/')+str(num_iters)+' loss '+str(loss))\n            sys.stdout.flush()\n            mean_loss.append(loss)\n            if writer is not None:\n                writer.add_summary(summaries, global_step=self.global_step)\n        sys.stdout.write('\\n')\n        mean_loss = np.mean(mean_loss)\n        return mean_loss\n\n    def test_one_image(self, images):\n        self.is_training = False\n        pred = self.sess.run(self.detection_pred, feed_dict={self.images: images})\n        return pred\n\n    def save_weight(self, mode, path):\n        assert(mode in ['latest', 'best'])\n        if mode == 'latest':\n            saver = self.saver\n        else:\n            saver = self.best_saver\n        if not tf.gfile.Exists(os.path.dirname(path)):\n            tf.gfile.MakeDirs(os.path.dirname(path))\n            print(os.path.dirname(path), 'does not exist, create it done')\n        saver.save(self.sess, path, global_step=self.global_step)\n        print('>> save', mode, 'model in', path, 'successfully')\n\n    def load_weight(self, path):\n        self.saver.restore(self.sess, path)\n        print('>> load weight', path, 'successfully')\n\n    def load_pretraining_weight(self, path):\n        self.pretraining_weight_saver.restore(self.sess, path)\n        print('>> load pretraining weight', path, 'successfully')\n\n    def _bn(self, bottom):\n        bn = tf.layers.batch_normalization(\n            inputs=bottom,\n            axis=3 if self.data_format == 'channels_last' else 1,\n            training=self.is_training\n        )\n        return bn\n\n    def _conv_layer(self, bottom, filters, kernel_size, strides, name):\n        conv = tf.layers.conv2d(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding='same',\n            name=name,\n            data_format=self.data_format,\n        )\n        bn = self._bn(conv)\n        return bn\n\n    def _max_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.max_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _avg_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.average_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _dropout(self, bottom, name):\n        return tf.layers.dropout(\n            inputs=bottom,\n            rate=self.prob,\n            training=self.is_training,\n            name=name\n        )\n"""
YOLOv3.py,265,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nimport os\nimport numpy as np\nimport sys\nimport datetime\n\n\nclass YOLOv3:\n    def __init__(self, config, data_provider):\n\n        assert len(config['data_shape']) == 3\n        assert config['mode'] in ['train', 'test']\n        assert config['data_format'] in ['channels_first', 'channels_last']\n        self.config = config\n        self.data_provider = data_provider\n        self.data_shape = config['data_shape']\n        self.num_classes = config['num_classes']\n        self.weight_decay = config['weight_decay']\n        self.prob = 1. - config['keep_prob']\n        self.data_format = config['data_format']\n        self.mode = config['mode']\n        self.batch_size = config['batch_size'] if config['mode'] == 'train' else 1\n\n        self.coord_sacle = config['coord_scale']\n        self.noobj_scale = config['noobj_scale']\n        self.obj_scale = config['obj_scale']\n        self.class_scale = config['class_scale']\n        self.num_priors = config['num_priors']\n\n        self.nms_score_threshold = config['nms_score_threshold']\n        self.nms_max_boxes = config['nms_max_boxes']\n        self.nms_iou_threshold = config['nms_iou_threshold']\n\n        priors = config['priors']\n        self.stride = [8., 16., 32.]\n        self.priors = []\n        for i in range(len(priors)):\n            self.priors.append(tf.reshape(tf.constant(priors[i], dtype=tf.float32)/self.stride[i], [1, 1, -1, 2]))\n        self.final_units = (self.num_classes + 5) * self.num_priors\n\n        if self.mode == 'train':\n            self.num_train = data_provider['num_train']\n            self.train_generator = data_provider['train_generator']\n            self.train_initializer, self.train_iterator = self.train_generator\n            if data_provider['val_generator'] is not None:\n                self.num_val = data_provider['num_val']\n                self.val_generator = data_provider['val_generator']\n                self.val_initializer, self.val_iterator = self.val_generator\n\n        self.global_step = tf.get_variable(name='global_step', initializer=tf.constant(0), trainable=False)\n        self.is_training = True\n\n        self._define_inputs()\n        self._build_graph()\n        self._create_saver()\n        if self.mode == 'train':\n            self._create_summary()\n        self._init_session()\n\n    def _define_inputs(self):\n        shape = [self.batch_size]\n        shape.extend(self.data_shape)\n        mean = tf.convert_to_tensor([123.68, 116.779, 103.979], dtype=tf.float32)\n        if self.data_format == 'channels_last':\n            mean = tf.reshape(mean, [1, 1, 1, 3])\n        else:\n            mean = tf.reshape(mean, [1, 3, 1, 1])\n        if self.mode == 'train':\n            self.images, self.ground_truth = self.train_iterator.get_next()\n            self.images.set_shape(shape)\n            self.images = self.images - mean\n        else:\n            self.images = tf.placeholder(tf.float32, shape, name='images')\n            self.images = self.images - mean\n            self.ground_truth = tf.placeholder(tf.float32, [self.batch_size, None, 5], name='labels')\n        self.lr = tf.placeholder(dtype=tf.float32, shape=[], name='lr')\n\n    def _build_graph(self):\n        with tf.variable_scope('backone'):\n            pyd1, pyd2, pyd3= self._feature_extractor(self.images)\n        with tf.variable_scope('head'):\n            pred1, top_down = self._yolo3_header(pyd1, 1024, 'pyd1', )\n            pred2, top_down = self._yolo3_header(pyd2, 256, 'pyd2', top_down)\n            pred3, _ = self._yolo3_header(pyd3, 128, 'pyd3', top_down)\n            if self.data_format != 'channels_last':\n                pred1 = tf.transpose(pred1, [0, 2, 3, 1])\n                pred2 = tf.transpose(pred2, [0, 2, 3, 1])\n                pred3 = tf.transpose(pred3, [0, 2, 3, 1])\n            p1shape = tf.shape(pred1)\n            p2shape = tf.shape(pred2)\n            p3shape = tf.shape(pred3)\n            pred1 = tf.reshape(pred1, [p1shape[0], p1shape[1], p1shape[2], self.num_priors, -1])\n            pred2 = tf.reshape(pred2, [p2shape[0], p2shape[1], p2shape[2], self.num_priors, -1])\n            pred3 = tf.reshape(pred3, [p3shape[0], p3shape[1], p3shape[2], self.num_priors, -1])\n\n            p1class = pred1[..., :self.num_classes]\n            p1bbox_yx = pred1[..., self.num_classes:self.num_classes+2]\n            p1bbox_hw = pred1[..., self.num_classes+2:self.num_classes+4]\n            p1obj = pred1[..., self.num_classes+4:]\n            p2class = pred2[..., :self.num_classes]\n            p2bbox_yx = pred2[..., self.num_classes:self.num_classes + 2]\n            p2bbox_hw = pred2[..., self.num_classes + 2:self.num_classes + 4]\n            p2obj = pred2[..., self.num_classes + 4:]\n            p3class = pred3[..., :self.num_classes]\n            p3bbox_yx = pred3[..., self.num_classes:self.num_classes + 2]\n            p3bbox_hw = pred3[..., self.num_classes + 2:self.num_classes + 4]\n            p3obj = pred3[..., self.num_classes + 4:]\n            a1bbox_yx, a1bbox_hw, a1bbox_y1x1, a1bbox_y2x2 = self._get_priors(p1shape, self.priors[0])\n            a2bbox_yx, a2bbox_hw, a2bbox_y1x1, a2bbox_y2x2 = self._get_priors(p2shape, self.priors[1])\n            a3bbox_yx, a3bbox_hw, a3bbox_y1x1, a3bbox_y2x2 = self._get_priors(p3shape, self.priors[2])\n\n        if self.mode == 'train':\n            total_loss = []\n            for i in range(self.batch_size):\n                gn1_yxi, gn1_hwi, gn1_labeli = self._get_normlized_gn(self.stride[-1], i)\n                gn2_yxi, gn2_hwi, gn2_labeli = self._get_normlized_gn(self.stride[-2], i)\n                gn3_yxi, gn3_hwi, gn3_labeli = self._get_normlized_gn(self.stride[-3], i)\n                num_g = tf.shape(gn2_labeli)[0]\n                num_gf = tf.cast(num_g, tf.float32)\n                gn1_floor_ = tf.cast(tf.floor(gn1_yxi), tf.int64)\n                gn2_floor_ = tf.cast(tf.floor(gn2_yxi), tf.int64)\n                gn3_floor_ = tf.cast(tf.floor(gn3_yxi), tf.int64)\n                nogn1_mask = tf.sparse.SparseTensor(gn1_floor_, tf.ones_like(gn1_floor_[..., 0]), dense_shape=[p1shape[1], p1shape[2]])\n                nogn1_mask = (1 - tf.sparse.to_dense(nogn1_mask, validate_indices=False)) > 0\n                nogn2_mask = tf.sparse.SparseTensor(gn2_floor_, tf.ones_like(gn2_floor_[..., 0]), dense_shape=[p2shape[1], p2shape[2]])\n                nogn2_mask = (1 - tf.sparse.to_dense(nogn2_mask, validate_indices=False)) > 0\n                nogn3_mask = tf.sparse.SparseTensor(gn3_floor_, tf.ones_like(gn3_floor_[..., 0]), dense_shape=[p3shape[1], p3shape[2]])\n                nogn3_mask = (1 - tf.sparse.to_dense(nogn3_mask, validate_indices=False)) > 0\n                rp1bbox_yx = tf.gather_nd(p1bbox_yx[i, ...], gn1_floor_)\n                rp2bbox_yx = tf.gather_nd(p2bbox_yx[i, ...], gn2_floor_)\n                rp3bbox_yx = tf.gather_nd(p3bbox_yx[i, ...], gn3_floor_)\n                rp1bbox_hw = tf.gather_nd(p1bbox_hw[i, ...], gn1_floor_)\n                rp2bbox_hw = tf.gather_nd(p2bbox_hw[i, ...], gn2_floor_)\n                rp3bbox_hw = tf.gather_nd(p3bbox_hw[i, ...], gn3_floor_)\n                ra1bbox_hw = tf.gather_nd(a1bbox_hw, gn1_floor_)\n                ra2bbox_hw = tf.gather_nd(a2bbox_hw, gn2_floor_)\n                ra3bbox_hw = tf.gather_nd(a3bbox_hw, gn3_floor_)\n                rp1class = tf.gather_nd(p1class[i, ...], gn1_floor_)\n                rp2class = tf.gather_nd(p2class[i, ...], gn2_floor_)\n                rp3class = tf.gather_nd(p3class[i, ...], gn3_floor_)\n                rp1obj = tf.gather_nd(p1obj[i, ...], gn1_floor_)\n                rp2obj = tf.gather_nd(p2obj[i, ...], gn2_floor_)\n                rp3obj = tf.gather_nd(p3obj[i, ...], gn3_floor_)\n                ra1bbox_y1x1 = tf.gather_nd(a1bbox_y1x1, gn1_floor_)\n                ra2bbox_y1x1 = tf.gather_nd(a2bbox_y1x1, gn2_floor_)\n                ra3bbox_y1x1 = tf.gather_nd(a3bbox_y1x1, gn3_floor_)\n                ra1bbox_y2x2 = tf.gather_nd(a1bbox_y2x2, gn1_floor_)\n                ra2bbox_y2x2 = tf.gather_nd(a2bbox_y2x2, gn2_floor_)\n                ra3bbox_y2x2 = tf.gather_nd(a3bbox_y2x2, gn3_floor_)\n                gn1_y1x1i = tf.expand_dims(gn1_yxi - gn1_hwi / 2., axis=1)\n                gn1_y2x2i = tf.expand_dims(gn1_yxi + gn1_hwi / 2., axis=1)\n                gn2_y1x1i = tf.expand_dims(gn2_yxi - gn2_hwi / 2., axis=1)\n                gn2_y2x2i = tf.expand_dims(gn2_yxi + gn2_hwi / 2., axis=1)\n                gn3_y1x1i = tf.expand_dims(gn3_yxi - gn3_hwi / 2., axis=1)\n                gn3_y2x2i = tf.expand_dims(gn3_yxi + gn3_hwi / 2., axis=1)\n                rga1iou_y1x1 = tf.maximum(gn1_y1x1i, ra1bbox_y1x1)\n                rga2iou_y1x1 = tf.maximum(gn2_y1x1i, ra2bbox_y1x1)\n                rga3iou_y1x1 = tf.maximum(gn3_y1x1i, ra3bbox_y1x1)\n                rga1iou_y2x2 = tf.minimum(gn1_y2x2i, ra1bbox_y2x2)\n                rga2iou_y2x2 = tf.minimum(gn2_y2x2i, ra2bbox_y2x2)\n                rga3iou_y2x2 = tf.minimum(gn3_y2x2i, ra3bbox_y2x2)\n                rga1iou_area = tf.reduce_prod(rga1iou_y2x2 - rga1iou_y1x1, axis=-1)\n                rga2iou_area = tf.reduce_prod(rga2iou_y2x2 - rga2iou_y1x1, axis=-1)\n                rga3iou_area = tf.reduce_prod(rga3iou_y2x2 - rga3iou_y1x1, axis=-1)\n\n                g1area = tf.reduce_prod(gn1_y2x2i - gn1_y1x1i, axis=-1)\n                g2area = tf.reduce_prod(gn2_y2x2i - gn2_y1x1i, axis=-1)\n                g3area = tf.reduce_prod(gn3_y2x2i - gn3_y1x1i, axis=-1)\n                a1area = tf.reduce_prod(ra1bbox_hw, axis=-1)\n                a2area = tf.reduce_prod(ra2bbox_hw, axis=-1)\n                a3area = tf.reduce_prod(ra3bbox_hw, axis=-1)\n                rga1iou = rga1iou_area / (a1area + g1area - rga1iou_area)\n                rga2iou = rga2iou_area / (a2area + g2area - rga2iou_area)\n                rga3iou = rga3iou_area / (a3area + g3area - rga3iou_area)\n\n                rga1index = tf.expand_dims(tf.cast(tf.argmax(rga1iou, axis=-1), tf.int32), -1)\n                rga2index = tf.expand_dims(tf.cast(tf.argmax(rga2iou, axis=-1), tf.int32), -1)\n                rga3index = tf.expand_dims(tf.cast(tf.argmax(rga3iou, axis=-1), tf.int32), -1)\n                rga1iou_max = tf.reduce_max(rga1iou, axis=-1)\n                rga2iou_max = tf.reduce_max(rga2iou, axis=-1)\n                rga3iou_max = tf.reduce_max(rga3iou, axis=-1)\n                rga1mask = tf.cast(rga1iou_max > rga2iou_max, tf.float32) * tf.cast(rga1iou_max > rga3iou_max, tf.float32)\n                rga2mask = tf.cast(rga2iou_max > rga1iou_max, tf.float32) * tf.cast(rga2iou_max > rga3iou_max, tf.float32)\n                rga3mask = (1. - tf.cast(rga1mask + rga2mask, tf.float32)) > 0.\n                rga2mask = rga2mask > 0.\n                rga1mask = rga1mask > 0.\n                rga1index = tf.boolean_mask(rga1index, rga1mask)\n                rga2index = tf.boolean_mask(rga2index, rga2mask)\n                rga3index = tf.boolean_mask(rga3index, rga3mask)\n                rga1index = tf.concat([tf.expand_dims(tf.range(tf.shape(rga1index)[0]), -1), rga1index], axis=-1)\n                rga2index = tf.concat([tf.expand_dims(tf.range(tf.shape(rga2index)[0]), -1), rga2index], axis=-1)\n                rga3index = tf.concat([tf.expand_dims(tf.range(tf.shape(rga3index)[0]), -1), rga3index], axis=-1)\n\n                rp1bbox_yx = tf.reshape(tf.gather_nd(tf.boolean_mask(rp1bbox_yx, rga1mask), rga1index), [-1, 2])\n                rp2bbox_yx = tf.reshape(tf.gather_nd(tf.boolean_mask(rp2bbox_yx, rga2mask), rga2index), [-1, 2])\n                rp3bbox_yx = tf.reshape(tf.gather_nd(tf.boolean_mask(rp3bbox_yx, rga3mask), rga3index), [-1, 2])\n                rp1bbox_hw = tf.reshape(tf.gather_nd(tf.boolean_mask(rp1bbox_hw, rga1mask), rga1index), [-1, 2])\n                rp2bbox_hw = tf.reshape(tf.gather_nd(tf.boolean_mask(rp2bbox_hw, rga2mask), rga2index), [-1, 2])\n                rp3bbox_hw = tf.reshape(tf.gather_nd(tf.boolean_mask(rp3bbox_hw, rga3mask), rga3index), [-1, 2])\n                rp1class = tf.reshape(tf.gather_nd(tf.boolean_mask(rp1class, rga1mask), rga1index), [-1, self.num_classes])\n                rp2class = tf.reshape(tf.gather_nd(tf.boolean_mask(rp2class, rga2mask), rga2index), [-1, self.num_classes])\n                rp3class = tf.reshape(tf.gather_nd(tf.boolean_mask(rp3class, rga3mask), rga3index), [-1, self.num_classes])\n                rp1obj = tf.reshape(tf.gather_nd(tf.boolean_mask(rp1obj, rga1mask), rga1index), [-1, 1])\n                rp2obj = tf.reshape(tf.gather_nd(tf.boolean_mask(rp2obj, rga2mask), rga2index), [-1, 1])\n                rp3obj = tf.reshape(tf.gather_nd(tf.boolean_mask(rp3obj, rga3mask), rga3index), [-1, 1])\n                ra1bbox_hw = tf.reshape(tf.gather_nd(tf.boolean_mask(ra1bbox_hw, rga1mask), rga1index), [-1, 2])\n                ra2bbox_hw = tf.reshape(tf.gather_nd(tf.boolean_mask(ra2bbox_hw, rga2mask), rga2index), [-1, 2])\n                ra3bbox_hw = tf.reshape(tf.gather_nd(tf.boolean_mask(ra3bbox_hw, rga3mask), rga3index), [-1, 2])\n                gn1_yxi = tf.boolean_mask(gn1_yxi, rga1mask)\n                gn1_hwi = tf.boolean_mask(gn1_hwi, rga1mask)\n                gn2_yxi = tf.boolean_mask(gn2_yxi, rga2mask)\n                gn2_hwi = tf.boolean_mask(gn2_hwi, rga2mask)\n                gn3_yxi = tf.boolean_mask(gn3_yxi, rga3mask)\n                gn3_hwi = tf.boolean_mask(gn3_hwi, rga3mask)\n                gn1_labeli = tf.one_hot(tf.boolean_mask(gn1_labeli, rga1mask), self.num_classes)\n                gn2_labeli = tf.one_hot(tf.boolean_mask(gn2_labeli, rga2mask), self.num_classes)\n                gn3_labeli = tf.one_hot(tf.boolean_mask(gn3_labeli, rga3mask), self.num_classes)\n                rp1bbox_yx_target = gn1_yxi - tf.floor(gn1_yxi)\n                rp2bbox_yx_target = gn2_yxi - tf.floor(gn2_yxi)\n                rp3bbox_yx_target = gn3_yxi - tf.floor(gn3_yxi)\n                rp1bbox_hw_target = tf.log(gn1_hwi/ra1bbox_hw)\n                rp2bbox_hw_target = tf.log(gn2_hwi/ra2bbox_hw)\n                rp3bbox_hw_target = tf.log(gn3_hwi/ra3bbox_hw)\n                yx_loss1 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=rp1bbox_yx_target, logits=rp1bbox_yx))\n                yx_loss2 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=rp2bbox_yx_target, logits=rp2bbox_yx))\n                yx_loss3 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=rp3bbox_yx_target, logits=rp3bbox_yx))\n                hw_loss1 = 0.5 * tf.reduce_sum(tf.square(rp1bbox_hw - rp1bbox_hw_target))\n                hw_loss2 = 0.5 * tf.reduce_sum(tf.square(rp2bbox_hw - rp2bbox_hw_target))\n                hw_loss3 = 0.5 * tf.reduce_sum(tf.square(rp3bbox_hw - rp3bbox_hw_target))\n                coord_loss = (yx_loss1 + yx_loss2 + yx_loss3 + hw_loss1 + hw_loss2 + hw_loss3)\n                class_loss1 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=gn1_labeli, logits=rp1class))\n                class_loss2 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=gn2_labeli, logits=rp2class))\n                class_loss3 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=gn3_labeli, logits=rp3class))\n                class_loss = (class_loss1 + class_loss2 + class_loss3)\n                obj_loss1 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(rp1obj), logits=rp1obj))\n                obj_loss2 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(rp2obj), logits=rp2obj))\n                obj_loss3 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(rp3obj), logits=rp3obj))\n                obj_loss = (obj_loss1 + obj_loss2 + obj_loss3)\n                nogn1_mask = tf.reshape(nogn1_mask, [-1])\n                nogn2_mask = tf.reshape(nogn2_mask, [-1])\n                nogn3_mask = tf.reshape(nogn3_mask, [-1])\n\n                a1bbox_yx_nobest = tf.expand_dims(tf.boolean_mask(tf.reshape(a1bbox_yx-a1bbox_hw/2., [-1, self.num_priors, 2]), nogn1_mask), 1)\n                a1bbox_hw_nobest = tf.expand_dims(tf.boolean_mask(tf.reshape(a1bbox_yx+a1bbox_hw/2., [-1, self.num_priors, 2]), nogn1_mask), 1)\n                a2bbox_yx_nobest = tf.expand_dims(tf.boolean_mask(tf.reshape(a2bbox_yx-a2bbox_hw/2., [-1, self.num_priors, 2]), nogn2_mask), 1)\n                a2bbox_hw_nobest = tf.expand_dims(tf.boolean_mask(tf.reshape(a2bbox_yx+a2bbox_hw/2., [-1, self.num_priors, 2]), nogn2_mask), 1)\n                a3bbox_yx_nobest = tf.expand_dims(tf.boolean_mask(tf.reshape(a3bbox_yx-a3bbox_hw/2., [-1, self.num_priors, 2]), nogn3_mask), 1)\n                a3bbox_hw_nobest = tf.expand_dims(tf.boolean_mask(tf.reshape(a3bbox_yx+a3bbox_hw/2., [-1, self.num_priors, 2]), nogn3_mask), 1)\n                a1bbox_y1x1_nobest = a1bbox_yx_nobest - a1bbox_hw_nobest/2.\n                a1bbox_y2x2_nobest = a1bbox_yx_nobest + a1bbox_hw_nobest/2.\n                a2bbox_y1x1_nobest = a2bbox_yx_nobest - a2bbox_hw_nobest/2.\n                a2bbox_y2x2_nobest = a2bbox_yx_nobest + a2bbox_hw_nobest/2.\n                a3bbox_y1x1_nobest = a3bbox_yx_nobest - a3bbox_hw_nobest/2.\n                a3bbox_y2x2_nobest = a3bbox_yx_nobest + a3bbox_hw_nobest/2.\n\n                p1obj_nobest = tf.boolean_mask(tf.reshape(p1obj[i, ...], [-1, self.num_priors]), nogn1_mask)\n                p2obj_nobest = tf.boolean_mask(tf.reshape(p2obj[i, ...], [-1, self.num_priors]), nogn2_mask)\n                p3obj_nobest = tf.boolean_mask(tf.reshape(p3obj[i, ...], [-1, self.num_priors]), nogn3_mask)\n                num_g1 = tf.shape(gn1_y1x1i)[0]\n                num_g2 = tf.shape(gn2_y1x1i)[0]\n                num_g3 = tf.shape(gn3_y1x1i)[0]\n                num_a1 = tf.shape(a1bbox_y1x1_nobest)[0]\n                num_a2 = tf.shape(a2bbox_y1x1_nobest)[0]\n                num_a3 = tf.shape(a3bbox_y1x1_nobest)[0]\n                gn1_y1x1i = tf.tile(tf.expand_dims(gn1_y1x1i, 0), [num_a1, 1, 1, 1])\n                gn1_y2x2i = tf.tile(tf.expand_dims(gn1_y2x2i, 0), [num_a1, 1, 1, 1])\n                gn2_y1x1i = tf.tile(tf.expand_dims(gn2_y1x1i, 0), [num_a2, 1, 1, 1])\n                gn2_y2x2i = tf.tile(tf.expand_dims(gn2_y2x2i, 0), [num_a2, 1, 1, 1])\n                gn3_y1x1i = tf.tile(tf.expand_dims(gn3_y1x1i, 0), [num_a3, 1, 1, 1])\n                gn3_y2x2i = tf.tile(tf.expand_dims(gn3_y2x2i, 0), [num_a3, 1, 1, 1])\n                a1bbox_y1x1_nobest = tf.tile(a1bbox_y1x1_nobest, [1, num_g1, 1, 1])\n                a2bbox_y1x1_nobest = tf.tile(a2bbox_y1x1_nobest, [1, num_g2, 1, 1])\n                a3bbox_y1x1_nobest = tf.tile(a3bbox_y1x1_nobest, [1, num_g3, 1, 1])\n                a1bbox_y2x2_nobest = tf.tile(a1bbox_y2x2_nobest, [1, num_g1, 1, 1])\n                a2bbox_y2x2_nobest = tf.tile(a2bbox_y2x2_nobest, [1, num_g2, 1, 1])\n                a3bbox_y2x2_nobest = tf.tile(a3bbox_y2x2_nobest, [1, num_g3, 1, 1])\n                ag1iou_y1x1 = tf.maximum(gn1_y1x1i, a1bbox_y1x1_nobest)\n                ag1iou_y2x2 = tf.minimum(gn1_y2x2i, a1bbox_y2x2_nobest)\n                ag2iou_y1x1 = tf.maximum(gn2_y1x1i, a2bbox_y1x1_nobest)\n                ag2iou_y2x2 = tf.minimum(gn2_y2x2i, a2bbox_y2x2_nobest)\n                ag3iou_y1x1 = tf.maximum(gn3_y1x1i, a3bbox_y1x1_nobest)\n                ag3iou_y2x2 = tf.minimum(gn3_y2x2i, a3bbox_y2x2_nobest)\n                ag1iou_area = tf.reduce_prod(ag1iou_y2x2 - ag1iou_y1x1, axis=-1)\n                ag2iou_area = tf.reduce_prod(ag2iou_y2x2 - ag2iou_y1x1, axis=-1)\n                ag3iou_area = tf.reduce_prod(ag3iou_y2x2 - ag3iou_y1x1, axis=-1)\n                a1area = tf.reduce_prod(a1bbox_y2x2_nobest-a1bbox_y1x1_nobest, axis=-1)\n                g1area = tf.reduce_prod(gn1_y2x2i - gn1_y1x1i, axis=-1)\n                a2area = tf.reduce_prod(a2bbox_y2x2_nobest - a2bbox_y1x1_nobest, axis=-1)\n                g2area = tf.reduce_prod(gn2_y2x2i - gn2_y1x1i, axis=-1)\n                a3area = tf.reduce_prod(a3bbox_y2x2_nobest - a3bbox_y1x1_nobest, axis=-1)\n                g3area = tf.reduce_prod(gn3_y2x2i - gn3_y1x1i, axis=-1)\n                ag1iou = ag1iou_area / (a1area + g1area - ag1iou_area)\n                ag2iou = ag2iou_area / (a2area + g2area - ag2iou_area)\n                ag3iou = ag3iou_area / (a3area + g3area - ag3iou_area)\n                ag1iou = tf.reduce_max(ag1iou, axis=1)\n                ag2iou = tf.reduce_max(ag2iou, axis=1)\n                ag3iou = tf.reduce_max(ag3iou, axis=1)\n                ag1iou_noobj_mask = tf.cast(ag1iou <= 0.5, tf.float32)\n                ag2iou_noobj_mask = tf.cast(ag2iou <= 0.5, tf.float32)\n                ag3iou_noobj_mask = tf.cast(ag3iou <= 0.5, tf.float32)\n                noonj_loss1 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(p1obj_nobest), logits=p1obj_nobest) * ag1iou_noobj_mask)\n                noonj_loss2 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(p2obj_nobest), logits=p2obj_nobest) * ag2iou_noobj_mask)\n                noonj_loss3 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(p3obj_nobest), logits=p3obj_nobest) * ag3iou_noobj_mask)\n                noonj_loss = noonj_loss1 + noonj_loss2 + noonj_loss3\n                pos_loss = (self.coord_sacle*coord_loss+self.class_scale*class_loss+self.obj_scale*obj_loss) / num_gf\n                neg_loss = self.noobj_scale*noonj_loss / num_gf\n                total_loss.append(pos_loss + neg_loss)\n            total_loss = tf.reduce_mean(total_loss)\n            optimizer = tf.train.MomentumOptimizer(learning_rate=self.lr, momentum=0.9)\n            self.loss = .5 * total_loss + self.weight_decay * tf.add_n(\n                [tf.nn.l2_loss(var) for var in tf.trainable_variables()]\n            )\n            train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n            self.train_op = tf.group([update_ops, train_op])\n        else:\n            p1class = tf.reshape(p1class[0, ...], [-1, self.num_classes])\n            p2class = tf.reshape(p2class[0, ...], [-1, self.num_classes])\n            p3class = tf.reshape(p3class[0, ...], [-1, self.num_classes])\n            p1obj = tf.reshape(p1obj[0, ...], [-1, 1])\n            p2obj = tf.reshape(p2obj[0, ...], [-1, 1])\n            p3obj = tf.reshape(p3obj[0, ...], [-1, 1])\n            p1bbox_yx = tf.reshape(p1bbox_yx[0, ...], [-1, 2])\n            p2bbox_yx = tf.reshape(p2bbox_yx[0, ...], [-1, 2])\n            p3bbox_yx = tf.reshape(p3bbox_yx[0, ...], [-1, 2])\n            p1bbox_hw = tf.reshape(p1bbox_hw[0, ...], [-1, 2])\n            p2bbox_hw = tf.reshape(p2bbox_hw[0, ...], [-1, 2])\n            p3bbox_hw = tf.reshape(p3bbox_hw[0, ...], [-1, 2])\n            a1bbox_yx = tf.reshape(a1bbox_yx, [-1, 2])\n            a2bbox_yx = tf.reshape(a2bbox_yx, [-1, 2])\n            a3bbox_yx = tf.reshape(a3bbox_yx, [-1, 2])\n            a1bbox_hw = tf.reshape(a1bbox_hw, [-1, 2])\n            a2bbox_hw = tf.reshape(a2bbox_hw, [-1, 2])\n            a3bbox_hw = tf.reshape(a3bbox_hw, [-1, 2])\n            pclasst = tf.sigmoid(tf.concat([p1class, p2class, p3class], axis=0))\n            pobjt = tf.sigmoid(tf.concat([p1obj, p2obj, p3obj], axis=0))\n            bbox_yx1 = a1bbox_yx + tf.sigmoid(p1bbox_yx)\n            bbox_hw1 = a1bbox_hw + tf.exp(p1bbox_hw)\n            bbox_yx2 = a2bbox_yx + tf.sigmoid(p2bbox_yx)\n            bbox_hw2 = a2bbox_hw + tf.exp(p2bbox_hw)\n            bbox_yx3 = a3bbox_yx + tf.sigmoid(p3bbox_yx)\n            bbox_hw3 = a3bbox_hw + tf.exp(p3bbox_hw)\n            bbox1_y1x1y2x2 = tf.concat([bbox_yx1 - bbox_hw1 / 2., bbox_yx1 + bbox_hw1 / 2.], axis=-1) * self.stride[-1]\n            bbox2_y1x1y2x2 = tf.concat([bbox_yx2 - bbox_hw2 / 2., bbox_yx2 + bbox_hw2 / 2.], axis=-1) * self.stride[-1]\n            bbox3_y1x1y2x2 = tf.concat([bbox_yx3 - bbox_hw3 / 2., bbox_yx3 + bbox_hw3 / 2.], axis=-1) * self.stride[-2]\n            bbox_y1x1y2x2 = tf.concat([bbox1_y1x1y2x2, bbox2_y1x1y2x2, bbox3_y1x1y2x2], axis=0)\n            confidence = pclasst * pobjt\n            filter_mask = tf.greater_equal(confidence, self.nms_score_threshold)\n            scores = []\n            class_id = []\n            bbox = []\n            for i in range(self.num_classes):\n                scoresi = tf.boolean_mask(confidence[:, i], filter_mask[:, i])\n                bboxi = tf.boolean_mask(bbox_y1x1y2x2, filter_mask[:, i])\n                selected_indices = tf.image.non_max_suppression(\n\n                    bboxi, scoresi, self.nms_max_boxes, self.nms_iou_threshold,\n                )\n                scores.append(tf.gather(scoresi, selected_indices))\n                bbox.append(tf.gather(bboxi, selected_indices))\n                class_id.append(tf.ones_like(tf.gather(scoresi, selected_indices), tf.int32) * i)\n            bbox = tf.concat(bbox, axis=0)\n            scores = tf.concat(scores, axis=0)\n            class_id = tf.concat(class_id, axis=0)\n            self.detection_pred = [scores, bbox, class_id]\n\n    def _init_session(self):\n        self.sess = tf.InteractiveSession()\n        self.sess.run(tf.global_variables_initializer())\n        if self.mode == 'train':\n            self.sess.run(self.train_initializer)\n\n    def _create_saver(self):\n        weights = tf.trainable_variables(scope='backone')\n        self.pretraining_weight_saver = tf.train.Saver(weights)\n        self.saver = tf.train.Saver()\n        self.best_saver = tf.train.Saver()\n\n    def _create_summary(self):\n        with tf.variable_scope('summaries'):\n            tf.summary.scalar('loss', self.loss)\n            self.summary_op = tf.summary.merge_all()\n\n    def _feature_extractor(self, image):\n        init_conv = self._conv_layer(image, 32, 3, 1)\n        block1 = self._darknet_block(init_conv, 64, 1, 'block1')\n        block2 = self._darknet_block(block1, 128, 2, 'block2')\n        block3 = self._darknet_block(block2, 256, 8, 'block3')\n        block4 = self._darknet_block(block3, 512, 8, 'block4')\n        block5 = self._darknet_block(block4, 1024, 4, 'block5')\n        return block5, block4, block3\n\n    def _yolo3_header(self, bottom, filters, scope, pyramid=None):\n        with tf.variable_scope(scope):\n            if pyramid is not None:\n                if self.data_format == 'channels_last':\n                    axes = 3\n                    shape = [int(bottom.get_shape()[1]), int(bottom.get_shape()[2])]\n                else:\n                    axes = 1\n                    shape = [int(bottom.get_shape()[2]), int(bottom.get_shape()[3])]\n                conv = self._conv_layer(pyramid, filters, 1, 1, False)\n                conv = tf.image.resize_nearest_neighbor(conv, shape)\n                conv = tf.concat([bottom, conv], axis=axes)\n            else:\n                conv = bottom\n            conv1 = self._conv_layer(conv, filters/2, 1, 1)\n            conv2 = self._conv_layer(conv1, filters, 3, 1)\n            conv3 = self._conv_layer(conv2, filters/2, 1, 1)\n            conv4 = self._conv_layer(conv3, filters, 3, 1)\n            conv5 = self._conv_layer(conv4, filters/2, 1, 1)\n            conv6 = self._conv_layer(conv5, filters, 3, 1)\n            pred = self._conv_layer(conv6, self.final_units, 1, 1)\n            return pred, conv5\n\n    def _get_priors(self, pshape, priors):\n        tl_y = tf.range(0., tf.cast(pshape[1], tf.float32), dtype=tf.float32)\n        tl_x = tf.range(0., tf.cast(pshape[2], tf.float32), dtype=tf.float32)\n        tl_y_ = tf.reshape(tl_y, [-1, 1, 1, 1])\n        tl_x_ = tf.reshape(tl_x, [1, -1, 1, 1])\n        tl_y_ = tf.tile(tl_y_, [1, pshape[2], 1, 1])\n        tl_x_ = tf.tile(tl_x_, [pshape[1], 1, 1, 1])\n        tl = tf.concat([tl_y_, tl_x_], -1)\n        abbox_yx = tl + 0.5\n        abbox_yx = tf.tile(abbox_yx, [1, 1, self.num_priors, 1])\n        abbox_hw = priors\n        abbox_hw = tf.tile(abbox_hw, [pshape[1], pshape[2], 1, 1])\n        abbox_y1x1 = abbox_yx - abbox_hw / 2\n        abbox_y2x2 = abbox_yx + abbox_hw / 2\n        return abbox_yx, abbox_hw, abbox_y1x1, abbox_y2x2\n\n    def _get_normlized_gn(self, downsampling_rate, i):\n\n        slice_index = tf.argmin(self.ground_truth[i, ...], axis=0)[0]\n        ground_truth = tf.gather(self.ground_truth[i, ...], tf.range(0, slice_index, dtype=tf.int64))\n        scale = tf.constant([downsampling_rate, downsampling_rate, downsampling_rate, downsampling_rate, 1], dtype=tf.float32)\n        scale = tf.reshape(scale, [1, 5])\n        gn = ground_truth / scale\n        return gn[..., :2], gn[..., 2:4], tf.cast(gn[..., 4], tf.int32)\n\n    def train_one_epoch(self, lr):\n        self.is_training = True\n        self.sess.run(self.train_initializer)\n        mean_loss = []\n        num_iters = self.num_train // self.batch_size\n        for i in range(num_iters):\n            _, loss, _ = self.sess.run([self.train_op, self.loss, self.summary_op],\n                                       feed_dict={self.lr: lr})\n            sys.stdout.write('\\r>> ' + 'iters '+str(i)+str('/')+str(num_iters)+' loss '+str(loss))\n            sys.stdout.flush()\n            mean_loss.append(loss)\n        sys.stdout.write('\\n')\n        mean_loss = np.mean(mean_loss)\n        return mean_loss\n\n    def test_one_image(self, images):\n        self.is_training = False\n        print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'))\n\n        pred = self.sess.run(self.detection_pred, feed_dict={self.images: images})\n        print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'))\n        return pred\n\n    def save_weight(self, mode, path):\n        assert(mode in ['latest', 'best'])\n        if mode == 'latest':\n            saver = self.saver\n        else:\n            saver = self.best_saver\n        if not tf.gfile.Exists(os.path.dirname(path)):\n            tf.gfile.MakeDirs(os.path.dirname(path))\n            print(os.path.dirname(path), 'does not exist, create it done')\n        saver.save(self.sess, path, global_step=self.global_step)\n        print('save', mode, 'model in', path, 'successfully')\n\n    def load_weight(self, path):\n        self.saver.restore(self.sess, path)\n        print('load weight', path, 'successfully')\n\n    def load_pretraining_weight(self, path):\n        self.pretraining_weight_saver.restore(self.sess, path)\n        print('load pretraining weight', path, 'successfully')\n\n    def _darknet_block(self, bottom, filters, blocks, scope):\n        with tf.variable_scope(scope):\n            conv = self._conv_layer(bottom, filters, 3, 2)\n            for i in range(1, blocks+1):\n                conv1 = self._conv_layer(conv, filters/2, 1, 1)\n                conv2 = self._conv_layer(conv1, filters, 3, 1)\n                conv = conv + conv2\n            return conv\n\n    def _conv_layer(self, bottom, filters, kernel_size, strides, is_activation=True):\n        conv = tf.layers.conv2d(\n            inputs=bottom,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            kernel_initializer=tf.contrib.layers.variance_scaling_initializer()\n        )\n        bn = self._bn(conv)\n        if is_activation:\n            bn = tf.nn.leaky_relu(bn, 0.1)\n        return bn\n\n    def _bn(self, bottom):\n        bn = tf.layers.batch_normalization(\n            inputs=bottom,\n            axis=3 if self.data_format == 'channels_last' else 1,\n            training=self.is_training\n        )\n        return bn\n\n    def _max_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.max_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _avg_pooling(self, bottom, pool_size, strides, name):\n        return tf.layers.average_pooling2d(\n            inputs=bottom,\n            pool_size=pool_size,\n            strides=strides,\n            padding='same',\n            data_format=self.data_format,\n            name=name\n        )\n\n    def _dropout(self, bottom, name):\n        return tf.layers.dropout(\n            inputs=bottom,\n            rate=self.prob,\n            training=self.is_training,\n            name=name\n        )\n"""
testSSD300.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom utils import tfrecord_voc_utils as voc_utils\nimport tensorflow as tf\nimport numpy as np\nimport SSD300 as net\nimport os\n# import matplotlib.pyplot as plt\n# import matplotlib.patches as patches\n# from skimage import io, transform\n# from utils.voc_classname_encoder import classname_to_ids\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nlr = 0.01\nbatch_size = 32\nbuffer_size = 1024\nepochs = 160\nreduce_lr_epoch = [50, 150]\nckpt_path = os.path.join('.', 'vgg_16.ckpt')\nconfig = {\n    'mode': 'train',                                       # 'train', 'test'\n    'data_format': 'channels_last',                        # 'channels_last' 'channels_first'\n    'num_classes': 20,\n    'weight_decay': 1e-4,\n    'keep_prob': 0.5,                                      # not used\n    'batch_size': batch_size,\n    'nms_score_threshold': 0.5,\n    'nms_max_boxes': 20,\n    'nms_iou_threshold': 0.5,\n    'pretraining_weight': ckpt_path\n}\n\nimage_augmentor_config = {\n    'data_format': 'channels_last',\n    'output_shape': [300, 300],\n    # 'zoom_size': [320, 320],\n    'crop_method': 'random',\n    'flip_prob': [0., 0.5],\n    'fill_mode': 'BILINEAR',\n    'keep_aspect_ratios': False,\n    'constant_values': 0.,\n    'color_jitter_prob': 0.5,\n    'rotate': [0.5, -5., -5.],\n    'pad_truth_to': 60,\n}\n\ndata = os.listdir('./data/')\ndata = [os.path.join('./data/', name) for name in data]\n\ntrain_gen = voc_utils.get_generator(data,\n                                    batch_size, buffer_size, image_augmentor_config)\ntrainset_provider = {\n    'data_shape': [300, 300, 3],\n    'num_train': 5000,\n    'num_val': 0,                                         # not used\n    'train_generator': train_gen,\n    'val_generator': None                                 # not used\n}\nssd300 = net.SSD300(config, trainset_provider)\n# ssd300.load_weight('./ssd/test-64954')\nfor i in range(epochs):\n    print('-'*25, 'epoch', i, '-'*25)\n    if i in reduce_lr_epoch:\n        lr = lr/10.\n        print('reduce lr, lr=', lr, 'now')\n    mean_loss = ssd300.train_one_epoch(lr)\n    print('>> mean loss', mean_loss)\n    ssd300.save_weight('latest', './ssd/test')            # 'latest', 'best\n# img = io.imread('000026.jpg')\n# img = transform.resize(img, [300,300])\n# img = np.expand_dims(img, 0)\n# result = ssd300.test_one_image(img)\n# id_to_clasname = {k:v for (v,k) in classname_to_ids.items()}\n# scores = result[0]\n# bbox = result[1]\n# class_id = result[2]\n# print(scores, bbox, class_id)\n# plt.figure(1)\n# plt.imshow(np.squeeze(img))\n# axis = plt.gca()\n# for i in range(len(scores)):\n#     rect = patches.Rectangle((bbox[i][1],bbox[i][0]), bbox[i][3]-bbox[i][1],bbox[i][2]-bbox[i][0],linewidth=2,edgecolor='b',facecolor='none')\n#     axis.add_patch(rect)\n#     plt.text(bbox[i][1],bbox[i][0], id_to_clasname[class_id[i]]+str(' ')+str(scores[i]), color='red', fontsize=12)\n# plt.show()\n"""
testSSD512.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom utils import tfrecord_voc_utils as voc_utils\nimport tensorflow as tf\nimport numpy as np\nimport SSD512 as net\nimport os\n# import matplotlib.pyplot as plt\n# import matplotlib.patches as patches\n# from skimage import io, transform\nfrom utils.voc_classname_encoder import classname_to_ids\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nlr = 0.01\nbatch_size = 32\nbuffer_size = 1024\nepochs = 160\nreduce_lr_epoch = [50, 150]\nckpt_path = os.path.join('.', 'vgg_16.ckpt')\nconfig = {\n    'mode': 'train',                                             # train ,test\n    'data_format': 'channels_last',                              # 'channels_last' 'channels_first'\n    'num_classes': 20,\n    'weight_decay': 1e-4,\n    'keep_prob': 0.5,                                            # not used\n    'batch_size': batch_size,\n    'nms_score_threshold': 0.5,\n    'nms_max_boxes': 20,\n    'nms_iou_threshold': 0.5,\n    'pretraining_weight': ckpt_path\n}\n\nimage_augmentor_config = {\n    'data_format': 'channels_last',\n    'output_shape': [512, 512],\n    # 'zoom_size': [530, 530],\n    'crop_method': 'random',\n    'flip_prob': [0., 0.5],\n    'fill_mode': 'BILINEAR',\n    'keep_aspect_ratios': False,\n    'constant_values': 0.,\n    'color_jitter_prob': 0.5,\n    'rotate': [0.5, -5., -5.],\n    'pad_truth_to': 60,\n}\n\ndata = os.listdir('./data/')\ndata = [os.path.join('./data/', name) for name in data]\n\ntrain_gen = voc_utils.get_generator(data,\n                                    batch_size, buffer_size, image_augmentor_config)\ntrainset_provider = {\n    'data_shape': [512, 512, 3],\n    'num_train': 5000,\n    'num_val': 0,  # not used\n    'train_generator': train_gen,\n    'val_generator': None   # not used\n}\nssd512 = net.SSD512(config, trainset_provider)\n# ssd512.load_weight('./ssd/test-64954')\nfor i in range(epochs):\n    print('-'*25, 'epoch', i, '-'*25)\n    if i in reduce_lr_epoch:\n        lr = lr/10.\n        print('reduce lr, lr=', lr, 'now')\n    mean_loss = ssd512.train_one_epoch(lr)\n    print('>> mean loss', mean_loss)\n    ssd512.save_weight('latest', './ssd/test')                     # 'latest', 'best\n# img = io.imread('000026.jpg')\n# img = transform.resize(img, [512,512])\n# img = np.expand_dims(img, 0)\n# result = ssd512.test_one_image(img)\n# id_to_clasname = {k:v for (v,k) in classname_to_ids.items()}\n# scores = result[0]\n# bbox = result[1]\n# class_id = result[2]\n# print(scores, bbox, class_id)\n# plt.figure(1)\n# plt.imshow(np.squeeze(img))\n# axis = plt.gca()\n# for i in range(len(scores)):\n#     rect = patches.Rectangle((bbox[i][1],bbox[i][0]), bbox[i][3]-bbox[i][1],bbox[i][2]-bbox[i][0],linewidth=2,edgecolor='b',facecolor='none')\n#     axis.add_patch(rect)\n#     plt.text(bbox[i][1],bbox[i][0], id_to_clasname[class_id[i]]+str(' ')+str(scores[i]), color='red', fontsize=12)\n# plt.show()\n"""
testYOLOv2.py,1,"b""import tensorflow as tf\nimport numpy as np\nimport os\nimport utils.tfrecord_voc_utils as voc_utils\nimport YOLOv2 as yolov2\n# import matplotlib.pyplot as plt\n# import matplotlib.patches as patches\n# from skimage import io, transform\nfrom utils.voc_classname_encoder import classname_to_ids\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\ndevice_name = tf.test.gpu_device_name()\nif device_name is not '':\n    print('Found GPU Device!')\nelse:\n    print('Found GPU Device Failed!')\n\nlr = 0.005\nbatch_size = 32\nbuffer_size = 1024\nepochs = 280\ninput_shape = [480, 480, 3]\nreduce_lr_epoch = []\nconfig = {\n    'mode': 'train',                                 # 'train', 'test'\n    'is_pretraining': False,\n    'data_shape': input_shape,\n    'num_classes': 20,\n    'weight_decay': 1e-4,\n    'keep_prob': 0.5,\n    'data_format': 'channels_last',                  # 'channels_last' 'channels_first'\n    'batch_size': batch_size,\n    'coord_scale': 1,\n    'noobj_scale': 1,\n    'obj_scale': 5.,\n    'class_scale': 1.,\n\n    'nms_score_threshold': 0.5,\n    'nms_max_boxes': 10,\n    'nms_iou_threshold': 0.5,\n\n    'rescore_confidence': False,\n    'priors': [[1.08, 1.19], [3.42, 4.41], [6.63, 11.38], [9.42, 5.11], [16.62, 10.52]]\n}\n\ndata = os.listdir('./voc2007/')\ndata = [os.path.join('./voc2007/', name) for name in data]\n\nimage_augmentor_config = {\n    'data_format': 'channels_last',\n    'output_shape': [480, 480],\n    # 'zoom_size': [520, 520],\n    # 'crop_method': 'random',\n    'flip_prob': [0., 0.5],\n    'fill_mode': 'BILINEAR',\n    'keep_aspect_ratios': False,\n    'constant_values': 0.,\n    # 'color_jitter_prob': 0.5,\n    # 'rotate': [0.5, -10., 10.],\n    'pad_truth_to': 60,\n}\ntrain_gen = voc_utils.get_generator(data,\n                                    batch_size, buffer_size, image_augmentor_config)\ntrain_provider = {\n    'data_shape': input_shape,\n    'num_train': 5011,\n    'num_val': 0,\n    'train_generator': train_gen,\n    'val_generator': None\n}\n\n\ntestnet = yolov2.YOLOv2(config, train_provider)\ntestnet.load_weight('./yolo2/test-5304')\nfor i in range(epochs):\n    print('-'*25, 'epoch', i, '-'*25)\n    if i in reduce_lr_epoch:\n        lr = lr/10.\n        print('reduce lr, lr=', lr, 'now')\n    mean_loss = testnet.train_one_epoch(lr)\n    print('>> mean loss', mean_loss)\n    testnet.save_weight('latest', './yolo2/test')       # 'latest', 'best'\n\n\n# img = io.imread('/home/test/Desktop/YOLO-TF-master/VOC/JPEGImages/000012.jpg')\n# img = transform.resize(img, [448,448])\n# img = np.expand_dims(img, 0)\n# result = testnet.test_one_image(img)\n# id_to_clasname = {k:v for (v,k) in classname_to_ids.items()}\n# scores = result[0]\n# bbox = result[1]\n# class_id = result[2]\n# print(scores, bbox, class_id)\n# plt.figure(1)\n# plt.imshow(np.squeeze(img))\n# axis = plt.gca()\n# for i in range(len(scores)):\n#     rect = patches.Rectangle((bbox[i][1],bbox[i][0]), bbox[i][3]-bbox[i][1],bbox[i][2]-bbox[i][0],linewidth=1,edgecolor='c',facecolor='none')\n#     axis.add_patch(rect)\n#     plt.text(bbox[i][1],bbox[i][0], id_to_clasname[class_id[i]]+str(' ')+str(scores[i]), color='red', fontsize=12)\n# plt.show()\n"""
testYOLOv3.py,0,"b""import tensorflow as tf\nimport numpy as np\nimport os\nimport utils.tfrecord_voc_utils as voc_utils\nimport YOLOv3 as yolov3\n# import matplotlib.pyplot as plt\n# import matplotlib.patches as patches\n# from skimage import io, transform\nfrom utils.voc_classname_encoder import classname_to_ids\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\n\nlr = 0.001\nbatch_size = 12\nbuffer_size = 256\nepochs = 160\nreduce_lr_epoch = []\nconfig = {\n    'mode': 'train',                                    # 'train', 'test'\n    'data_shape': [448, 448, 3],\n    'num_classes': 20,\n    'weight_decay': 5e-4,\n    'keep_prob': 0.5,                                   # not used\n    'data_format': 'channels_last',                     # 'channels_last' 'channels_first'\n    'batch_size': batch_size,\n    'coord_scale': 1,\n    'noobj_scale': 1,\n    'obj_scale': 5.,\n    'class_scale': 1.,\n    'num_priors': 3,\n\n    'nms_score_threshold': 0.5,\n    'nms_max_boxes': 10,\n    'nms_iou_threshold': 0.5,\n\n\n    'priors': [[[10., 13.], [16, 30.], [33., 23.]],\n               [[30., 61.], [62., 45.], [59., 119.]],\n              [[116., 90.], [156., 198.], [373.,326.]]]\n\n}\n\nimage_augmentor_config = {\n    'data_format': 'channels_last',\n    'output_shape': [448, 448],\n    # 'zoom_size': [520, 520],\n    # 'crop_method': 'random',\n    'flip_prob': [0., 0.5],\n    'fill_mode': 'BILINEAR',\n    'keep_aspect_ratios': False,\n    'constant_values': 0.,\n    # 'color_jitter_prob': 0.5,\n    # 'rotate': [0.5, -10., 10.],\n    'pad_truth_to': 60,\n}\n\n\ndata = os.listdir('./voc2007/')\ndata = [os.path.join('./voc2007/', name) for name in data]\n\ntrain_gen = voc_utils.get_generator(data,\n                                    batch_size, buffer_size, image_augmentor_config)\ntrainset_provider = {\n    'data_shape': [448, 448, 3],\n    'num_train': 5011,\n    'num_val': 0,                                       # not used\n    'train_generator': train_gen,\n    'val_generator': None                               # not used\n}\n\ntestnet = yolov3.YOLOv3(config, trainset_provider)\ntestnet.load_weight('./weight/test-40449')\nfor i in range(epochs):\n    print('-'*25, 'epoch', i, '-'*25)\n    if i in reduce_lr_epoch:\n        lr = lr/10.\n        print('reduce lr, lr=', lr, 'now')\n    mean_loss = testnet.train_one_epoch(lr)\n    print('>> mean loss', mean_loss)\n    testnet.save_weight('latest', './weight/test')       # 'latest', 'best'\n\n# img = io.imread()\n# img = transform.resize(img, [448,448])\n# img = np.expand_dims(img, 0)\n# result = testnet.test_one_image(img)\n# id_to_clasname = {k:v for (v,k) in classname_to_ids.items()}\n# scores = result[0]\n# bbox = result[1]\n# class_id = result[2]\n# print(scores, bbox, class_id)\n# plt.figure(1)\n# plt.imshow(np.squeeze(img))\n# axis = plt.gca()\n# for i in range(len(scores)):\n#     rect = patches.Rectangle((bbox[i][1],bbox[i][0]), bbox[i][3]-bbox[i][1],bbox[i][2]-bbox[i][0],linewidth=2,edgecolor='b',facecolor='none')\n#     axis.add_patch(rect)\n#     plt.text(bbox[i][1],bbox[i][0], id_to_clasname[class_id[i]]+str(' ')+str(scores[i]), color='red', fontsize=12)\n# plt.show()\n"""
testcenternet.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom utils import tfrecord_voc_utils as voc_utils\nimport tensorflow as tf\nimport numpy as np\nimport CenterNet as net\nimport os\n# import matplotlib.pyplot as plt\n# import matplotlib.patches as patches\n# from skimage import io, transform\n# from utils.voc_classname_encoder import classname_to_ids\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n# os.environ['CUDA_VISIBLE_DEVICES'] = '2'\nlr = 0.001\nbatch_size = 15\nbuffer_size = 256\nepochs = 160\nreduce_lr_epoch = []\nconfig = {\n    'mode': 'train',                                       # 'train', 'test'\n    'input_size': 384,\n    'data_format': 'channels_last',                        # 'channels_last' 'channels_first'\n    'num_classes': 20,\n    'weight_decay': 1e-4,\n    'keep_prob': 0.5,                                      # not used\n    'batch_size': batch_size,\n\n    'score_threshold': 0.1,                                 \n    'top_k_results_output': 100,                           \n\n\n}\n\nimage_augmentor_config = {\n    'data_format': 'channels_last',\n    'output_shape': [384, 384],\n    'zoom_size': [400, 400],\n    'crop_method': 'random',\n    'flip_prob': [0., 0.5],\n    'fill_mode': 'BILINEAR',\n    'keep_aspect_ratios': False,\n    'constant_values': 0.,\n    'color_jitter_prob': 0.5,\n    'rotate': [0.5, -5., -5.],\n    'pad_truth_to': 60,\n}\n\ndata = os.listdir('./voc2007/')\ndata = [os.path.join('./voc2007/', name) for name in data]\n\ntrain_gen = voc_utils.get_generator(data,\n                                    batch_size, buffer_size, image_augmentor_config)\ntrainset_provider = {\n    'data_shape': [384, 384, 3],\n    'num_train': 5011,\n    'num_val': 0,                                         # not used\n    'train_generator': train_gen,\n    'val_generator': None                                 # not used\n}\ncenternet = net.CenterNet(config, trainset_provider)\n# centernet.load_weight('./centernet/test-8350')\n# centernet.load_pretrained_weight('./centernet/test-8350')\nfor i in range(epochs):\n    print('-'*25, 'epoch', i, '-'*25)\n    if i in reduce_lr_epoch:\n        lr = lr/10.\n        print('reduce lr, lr=', lr, 'now')\n    mean_loss = centernet.train_one_epoch(lr)\n    print('>> mean loss', mean_loss)\n    centernet.save_weight('latest', './centernet/test')            # 'latest', 'best\n# img = io.imread('000026.jpg')\n# img = transform.resize(img, [384,384])\n# img = np.expand_dims(img, 0)\n# result = centernet.test_one_image(img)\n# id_to_clasname = {k:v for (v,k) in classname_to_ids.items()}\n# scores = result[0]\n# bbox = result[1]\n# class_id = result[2]\n# print(scores, bbox, class_id)\n# plt.figure(1)\n# plt.imshow(np.squeeze(img))\n# axis = plt.gca()\n# for i in range(len(scores)):\n#     rect = patches.Rectangle((bbox[i][1],bbox[i][0]), bbox[i][3]-bbox[i][1],bbox[i][2]-bbox[i][0],linewidth=2,edgecolor='b',facecolor='none')\n#     axis.add_patch(rect)\n#     plt.text(bbox[i][1],bbox[i][0], id_to_clasname[class_id[i]]+str(' ')+str(scores[i]), color='red', fontsize=12)\n# plt.show()\n"""
testfcos.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom utils import tfrecord_voc_utils as voc_utils\nimport tensorflow as tf\nimport numpy as np\nimport FCOS as net\nimport os\n# import matplotlib.pyplot as plt\n# import matplotlib.patches as patches\n# from skimage import io, transform\n# from utils.voc_classname_encoder import classname_to_ids\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nlr = 0.01\nbatch_size = 8\nbuffer_size = 256\nepochs = 160\nreduce_lr_epoch = []\nconfig = {\n    'mode': 'train',                                       # 'train', 'test'\n    'data_shape': [800, 1200, 3],\n    'data_format': 'channels_last',                        # 'channels_last' 'channels_first'\n    'num_classes': 20,\n    'weight_decay': 1e-4,\n    'keep_prob': 0.5,                                      # not used\n    'batch_size': batch_size,\n\n    'nms_score_threshold': 0.5,\n    'nms_max_boxes': 10,\n    'nms_iou_threshold': 0.45,\n}\n\nimage_augmentor_config = {\n    'data_format': 'channels_last',\n    'output_shape': [800, 1200],\n    # 'zoom_size': [400, 400],\n    # 'crop_method': 'random',\n    'flip_prob': [0., 0.5],\n    'fill_mode': 'BILINEAR',\n    'keep_aspect_ratios': False,\n    # 'constant_values': 0.,\n    # 'color_jitter_prob': 0.5,\n    # 'rotate': [0.5, -5., -5.],\n    'pad_truth_to': 60,\n}\ndata = os.listdir('./voc2007/')\ndata = [os.path.join('./voc2007/', name) for name in data]\n\ntrain_gen = voc_utils.get_generator(data,\n                                    batch_size, buffer_size, image_augmentor_config)\ntrainset_provider = {\n    'data_shape': [800, 1200, 3],\n    'num_train': 5011,\n    'num_val': 0,                                         # not used\n    'train_generator': train_gen,\n    'val_generator': None                                 # not used\n}\nfcos = net.FCOS(config, trainset_provider)\nfcos.load_weight('./fcos/test-95778')\n# fcos.load_pretrained_weight('./fcos/test-8350')\nfor i in range(epochs):\n    print('-'*25, 'epoch', i, '-'*25)\n    if i in reduce_lr_epoch:\n        lr = lr/10.\n        print('reduce lr, lr=', lr, 'now')\n    mean_loss = fcos.train_one_epoch(lr)\n    print('>> mean loss', mean_loss)\n    fcos.save_weight('latest', './fcos/test')            # 'latest', 'best\n# img = io.imread('000026.jpg')\n# img = transform.resize(img, [384,384])\n# img = np.expand_dims(img, 0)\n# result = centernet.test_one_image(img)\n# id_to_clasname = {k:v for (v,k) in classname_to_ids.items()}\n# scores = result[0]\n# bbox = result[1]\n# class_id = result[2]\n# print(scores, bbox, class_id)\n# plt.figure(1)\n# plt.imshow(np.squeeze(img))\n# axis = plt.gca()\n# for i in range(len(scores)):\n#     rect = patches.Rectangle((bbox[i][1],bbox[i][0]), bbox[i][3]-bbox[i][1],bbox[i][2]-bbox[i][0],linewidth=1,edgecolor='c',facecolor='none')\n#     axis.add_patch(rect)\n#     plt.text(bbox[i][1],bbox[i][0], id_to_clasname[class_id[i]]+str(' ')+str(scores[i]), color='red', fontsize=12)\n# plt.show()\n"""
testlhrcnn.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom utils import tfrecord_voc_utils as voc_utils\nimport tensorflow as tf\nimport numpy as np\nimport LH_RCNN as net\nimport os\n# import matplotlib.pyplot as plt\n# import matplotlib.patches as patches\n# from skimage import io, transform\n# from utils.voc_classname_encoder import classname_to_ids\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\nlr = 0.003\nbatch_size = 32\nbuffer_size = 1024\nepochs = 1500\nreduce_lr_epoch = []\nconfig = {\n    'data_shape': [700, 1100, 3],\n    'mode': 'train',                            # 'train' ,'test'\n    'is_pretraining': False,\n    'data_format': 'channels_last',             # 'channels_last' ,'channels_first'\n    'num_classes': 20,\n    'weight_decay': 1e-4,\n    'keep_prob': 0.5,                           # not used\n    'batch_size': batch_size,\n    'rpn_first_step': 60000,                    # iters 0 - rpn_first_step train  rpn only\n    'rcnn_first_step': 100000,                   # iters rpn_first_step - rcnn_first_step train  rcnn only\n    'rpn_second_step': 160000,                   # iters rcnn_first_step - rpn_second_step train  rpn only\n                                                # iters rpn_second_step - end train  rcnn only\n    'nms_score_threshold': 0.5,\n    'nms_max_boxes': 20,\n    'nms_iou_threshold': 0.45,\n    'post_nms_proposal': 500                    # when test, how many proposal are kept after nms\n}\n\nimage_augmentor_config = {\n    'data_format': 'channels_last',\n    'output_shape': [700, 1100],\n    'zoom_size': [720, 1120],\n    'crop_method': 'random',\n    'flip_prob': [0., 0.5],\n    'fill_mode': 'BILINEAR',\n    'keep_aspect_ratios': False,\n    'constant_values': 0.,\n    'color_jitter_prob': 0.5,\n    'rotate': [0.5, -5., -5.],\n    'pad_truth_to': 60,\n}\n\ndata = os.listdir('./voc2007/')\ndata = [os.path.join('./voc2007/', name) for name in data]\n\ntrain_gen = voc_utils.get_generator(data,\n                                    batch_size, buffer_size, image_augmentor_config)\ntrainset_provider = {\n    'data_shape': [700, 1100, 3],\n    'num_train': 5011,\n    'num_val': 0,                               # not used\n    'train_generator': train_gen,\n    'val_generator': None                       # not used\n}\nrcnn = net.LHRCNN(config, trainset_provider)\n# rcnn.load_pretraining_weight('./rcnnpretrain/test-30000')\n# rcnn.load_weight('./lhrcnn/test-44304')\nfor i in range(epochs):\n    print('-'*25, 'epoch', i, '-'*25)\n    if i in reduce_lr_epoch:\n        lr = lr/10.\n        print('reduce lr, lr=', lr, 'now')\n    mean_loss = rcnn.train_one_epoch(lr)\n    print('>> mean loss', mean_loss, )\n    rcnn.save_weight('latest', './lhrcnn/test')    # 'latest' 'best'\n\n# img = io.imread('000026.jpg')\n# img = transform.resize(img, [700,1100])\n# img = np.expand_dims(img, 0)\n# result = ssd300.test_one_image(img)\n# id_to_clasname = {k:v for (v,k) in classname_to_ids.items()}\n# scores = result[0]\n# bbox = result[1]\n# class_id = result[2]\n# print(scores, bbox, class_id)\n# plt.figure(1)\n# plt.imshow(np.squeeze(img))\n# axis = plt.gca()\n# for i in range(len(scores)):\n#     rect = patches.Rectangle((bbox[i][1],bbox[i][0]), bbox[i][3]-bbox[i][1],bbox[i][2]-bbox[i][0],linewidth=2,edgecolor='b',facecolor='none')\n#     axis.add_patch(rect)\n#     plt.text(bbox[i][1],bbox[i][0], id_to_clasname[class_id[i]]+str(' ')+str(scores[i]), color='red', fontsize=12)\n# plt.show()\n"""
testpfpnet.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom utils import tfrecord_voc_utils as voc_utils\nimport tensorflow as tf\nimport numpy as np\nimport PFPNetR as net\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n# from skimage import io, transform\n# from utils.voc_classname_encoder import classname_to_ids\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n# os.environ['CUDA_VISIBLE_DEVICES'] = '2'\nlr = 0.001\nbatch_size = 32\nbuffer_size = 1024\nepochs = 300\nreduce_lr_epoch = []\nckpt_path = os.path.join('.', 'vgg_16.ckpt')\nconfig = {\n    'mode': 'train',                            # 'train' ,'test'\n    'input_size': 320,                          # 320 for PFPNetR320, 512 for PFPNetR512\n    'data_format': 'channels_last',             # 'channels_last' ,'channels_first'\n    'num_classes': 20,\n    'weight_decay': 1e-4,\n    'keep_prob': 0.5,                           # not used\n    'batch_size': batch_size,\n    'nms_score_threshold': 0.1,\n    'nms_max_boxes': 20,\n    'nms_iou_threshold': 0.45,\n    'pretraining_weight': ckpt_path\n}\n\nimage_augmentor_config = {\n    'data_format': 'channels_last',\n    'output_shape': [320, 320],\n    'zoom_size': [330, 330],\n    'crop_method': 'random',\n    'flip_prob': [0.0, 0.5],\n    'fill_mode': 'BILINEAR',\n    'keep_aspect_ratios': False,\n    'constant_values': 0.,\n    'color_jitter_prob': 0.5,\n    'rotate': [0.5, -5., -5.],\n    'pad_truth_to': 60,\n}\n\ndata = os.listdir('./voc2007/')\ndata = [os.path.join('./voc2007/', name) for name in data]\n\ntrain_gen = voc_utils.get_generator(data,\n                                    batch_size, buffer_size, image_augmentor_config)\ntrainset_provider = {\n    'data_shape': [320, 320, 3],\n    'num_train': 5011,\n    'num_val': 0,                               # not used\n    'train_generator': train_gen,\n    'val_generator': None                       # not used\n}\nrefinedet = net.PFPNetR(config, trainset_provider)\nrefinedet.load_weight('./PFPNetR/test-18252')\nfor i in range(epochs):\n    print('-'*25, 'epoch', i, '-'*25)\n    if i in reduce_lr_epoch:\n        lr = lr/10.\n        print('reduce lr, lr=', lr, 'now')\n    mean_loss = refinedet.train_one_epoch(lr)\n    print('>> mean loss', mean_loss)\n    refinedet.save_weight('latest', './PFPNetR/test')    # 'latest' 'best'\n\n# img = io.imread('000026.jpg')\n# img = transform.resize(img, [300,300])\n# img = np.expand_dims(img, 0)\n# result = ssd300.test_one_image(img)\n# id_to_clasname = {k:v for (v,k) in classname_to_ids.items()}\n# scores = result[0]\n# bbox = result[1]\n# class_id = result[2]\n# print(scores, bbox, class_id)\n# plt.figure(1)\n# plt.imshow(np.squeeze(img))\n# axis = plt.gca()\n# for i in range(len(scores)):\n#     rect = patches.Rectangle((bbox[i][1],bbox[i][0]), bbox[i][3]-bbox[i][1],bbox[i][2]-bbox[i][0],linewidth=2,edgecolor='b',facecolor='none')\n#     axis.add_patch(rect)\n#     plt.text(bbox[i][1],bbox[i][0], id_to_clasname[class_id[i]]+str(' ')+str(scores[i]), color='red', fontsize=12)\n# plt.show()\n"""
testrefinedet.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom utils import tfrecord_voc_utils as voc_utils\nimport tensorflow as tf\nimport numpy as np\nimport RefineDet as net\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom skimage import io, transform\nfrom utils.voc_classname_encoder import classname_to_ids\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n# os.environ['CUDA_VISIBLE_DEVICES'] = '2'\nlr = 0.0001\nbatch_size = 32\nbuffer_size = 1024\nepochs = 300\nreduce_lr_epoch = []\nckpt_path = os.path.join('.', 'vgg_16.ckpt')\nconfig = {\n    'mode': 'train',                            # 'train' ,'test'\n    'input_size': 320,                          # 320 for refinedet320, 512 for refinedet512\n    'data_format': 'channels_last',             # 'channels_last' ,'channels_first'\n    'num_classes': 20,\n    'weight_decay': 1e-4,\n    'keep_prob': 0.5,                           # not used\n    'batch_size': batch_size,\n    'nms_score_threshold': 0.1,\n    'nms_max_boxes': 20,\n    'nms_iou_threshold': 0.45,\n    'pretraining_weight': ckpt_path\n}\n\nimage_augmentor_config = {\n    'data_format': 'channels_last',\n    'output_shape': [320, 320],\n    'zoom_size': [330, 330],\n    'crop_method': 'random',\n    'flip_prob': [0.0, 0.5],\n    'fill_mode': 'BILINEAR',\n    'keep_aspect_ratios': False,\n    'constant_values': 0.,\n    'color_jitter_prob': 0.5,\n    'rotate': [0.5, -5., -5.],\n    'pad_truth_to': 60,\n}\n\ndata = os.listdir('./voc2007/')\ndata = [os.path.join('./voc2007/', name) for name in data]\n\ntrain_gen = voc_utils.get_generator(data,\n                                    batch_size, buffer_size, image_augmentor_config)\ntrainset_provider = {\n    'data_shape': [320, 320, 3],\n    'num_train': 5011,\n    'num_val': 0,                               # not used\n    'train_generator': train_gen,\n    'val_generator': None                       # not used\n}\nrefinedet = net.RefineDet320(config, trainset_provider)\nrefinedet.load_weight('./refinedet320/test-1092')\nfor i in range(epochs):\n    print('-'*25, 'epoch', i, '-'*25)\n    if i in reduce_lr_epoch:\n        lr = lr/10.\n        print('reduce lr, lr=', lr, 'now')\n    mean_loss = refinedet.train_one_epoch(lr)\n    print('>> mean loss', mean_loss)\n    refinedet.save_weight('latest', './refinedet320/test')    # 'latest' 'best'\n\n# img = io.imread('000026.jpg')\n# img = transform.resize(img, [300,300])\n# img = np.expand_dims(img, 0)\n# result = ssd300.test_one_image(img)\n# id_to_clasname = {k:v for (v,k) in classname_to_ids.items()}\n# scores = result[0]\n# bbox = result[1]\n# class_id = result[2]\n# print(scores, bbox, class_id)\n# plt.figure(1)\n# plt.imshow(np.squeeze(img))\n# axis = plt.gca()\n# for i in range(len(scores)):\n#     rect = patches.Rectangle((bbox[i][1],bbox[i][0]), bbox[i][3]-bbox[i][1],bbox[i][2]-bbox[i][0],linewidth=2,edgecolor='b',facecolor='none')\n#     axis.add_patch(rect)\n#     plt.text(bbox[i][1],bbox[i][0], id_to_clasname[class_id[i]]+str(' ')+str(scores[i]), color='red', fontsize=12)\n# plt.show()\n"""
testretinanet.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom utils import tfrecord_voc_utils as voc_utils\nimport tensorflow as tf\nimport numpy as np\nimport RetinaNet as net\nimport os\n# import matplotlib.pyplot as plt\n# import matplotlib.patches as patches\n# from skimage import io, transform\nfrom utils.voc_classname_encoder import classname_to_ids\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n\nlr = 0.01\nbatch_size = 32\nbuffer_size = 1024\nepochs = 280\ninput_shape = [500, 500, 3]\nreduce_lr_epoch = [120, 250]\nconfig = {\n    'is_bottleneck': True,\n    'residual_block_list': [3, 4, 6, 3],\n    'init_conv_filters': 16,\n\n    'mode': 'train',                                          # 'train', 'test'\n    'is_pretraining': False,\n    'data_shape': input_shape,\n    'num_classes': 20,\n    'weight_decay': 1e-4,\n    'keep_prob': 0.5,                                         # not used\n    'data_format': 'channels_last',                           # 'channels_last' 'channels_first'\n    'batch_size': batch_size,\n\n    'gamma': 2.0,                                             # gamma for focal loss\n    'alpha': 0.25,                                            # alpha for focal loss\n\n    'nms_score_threshold': 0.8,\n    'nms_max_boxes': 10,\n    'nms_iou_threshold': 0.45,\n}\n\n\nimage_augmentor_config = {\n    'data_format': 'channels_last',\n    'output_shape': [500, 500],\n    'zoom_size': [520, 520],\n    'crop_method': 'random',\n    'flip_prob': [0., 0.5],\n    'fill_mode': 'BILINEAR',\n    'keep_aspect_ratios': False,\n    'constant_values': 0.,\n    'color_jitter_prob': 0.5,\n    'rotate': [0.5, -5., -5.],\n    'pad_truth_to': 60,\n}\n\ndata = ['./test/test_00000-of-00005.tfrecord',\n        './test/test_00001-of-00005.tfrecord']\n\ntrain_gen = voc_utils.get_generator(data,\n                                    batch_size, buffer_size, image_augmentor_config)\ntrainset_provider = {\n    'data_shape': [500, 500, 3],\n    'num_train': 100,\n    'num_val': 0,                                             # not used\n    'train_generator': train_gen,\n    'val_generator': None                                     # not used\n}\nretinanet = net.RetinaNet(config, trainset_provider)\n# retinanet.load_weight('./retinanet/test-64954')\nfor i in range(epochs):\n    print('-'*25, 'epoch', i, '-'*25)\n    if i in reduce_lr_epoch:\n        lr = lr/10.\n        print('reduce lr, lr=', lr, 'now')\n    mean_loss = retinanet.train_one_epoch(lr)\n    print('>> mean loss', mean_loss)\n    retinanet.save_weight('latest', './retina/test')         # 'latest' 'best'\n\n\n# img = io.imread('000026.jpg')\n# img = transform.resize(img, [300,300])\n# img = np.expand_dims(img, 0)\n# result = ssd300.test_one_image(img)\n# id_to_clasname = {k:v for (v,k) in classname_to_ids.items()}\n# scores = result[0]\n# bbox = result[1]\n# class_id = result[2]\n# print(scores, bbox, class_id)\n# plt.figure(1)\n# plt.imshow(np.squeeze(img))\n# axis = plt.gca()\n# for i in range(len(scores)):\n#     rect = patches.Rectangle((bbox[i][1],bbox[i][0]), bbox[i][3]-bbox[i][1],bbox[i][2]-bbox[i][0],linewidth=2,edgecolor='b',facecolor='none')\n#     axis.add_patch(rect)\n#     plt.text(bbox[i][1],bbox[i][0], id_to_clasname[class_id[i]]+str(' ')+str(scores[i]), color='red', fontsize=12)\n# plt.show()\n"""
utils/image_augmentor.py,87,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\n\n\ndef image_augmentor(image, input_shape, data_format, output_shape, zoom_size=None,\n                    crop_method=None, flip_prob=None, fill_mode=\'BILINEAR\', keep_aspect_ratios=False,\n                    constant_values=0., color_jitter_prob=None, rotate=None, ground_truth=None, pad_truth_to=None):\n\n    """"""\n    :param image: HWC or CHW\n    :param input_shape: [h, w]\n    :param data_format: \'channels_first\', \'channels_last\'\n    :param output_shape: [h, w]\n    :param zoom_size: [h, w]\n    :param crop_method: \'random\', \'center\'\n    :param flip_prob: [flip_top_down_prob, flip_left_right_prob]\n    :param fill_mode: \'CONSTANT\', \'NEAREST_NEIGHBOR\', \'BILINEAR\', \'BICUBIC\'\n    :param keep_aspect_ratios: True, False\n    :param constant_values:\n    :param color_jitter_prob: prob of color_jitter\n    :param rotate: [prob, min_angle, max_angle]\n    :param ground_truth: [ymin, ymax, xmin, xmax, classid]\n    :param pad_truth_to: pad ground_truth to size [pad_truth_to, 5] with -1\n    :return image: output_shape\n    :return ground_truth: [pad_truth_to, 5] [ycenter, xcenter, h, w, class_id]\n    """"""\n    if data_format not in [\'channels_first\', \'channels_last\']:\n        raise Exception(""data_format must in [\'channels_first\', \'channels_last\']!"")\n    if fill_mode not in [\'CONSTANT\', \'NEAREST_NEIGHBOR\', \'BILINEAR\', \'BICUBIC\']:\n        raise Exception(""fill_mode must in [\'CONSTANT\', \'NEAREST_NEIGHBOR\', \'BILINEAR\', \'BICUBIC\']!"")\n    if fill_mode == \'CONSTANT\' and zoom_size is not None:\n        raise Exception(""if fill_mode is \'CONSTANT\', zoom_size can\'t be None!"")\n    if zoom_size is not None:\n        if keep_aspect_ratios:\n            if constant_values is None:\n                raise Exception(\'please provide constant_values!\')\n        if not zoom_size[0] >= output_shape[0] and zoom_size[1] >= output_shape[1]:\n            raise Exception(""output_shape can\'t greater that zoom_size!"")\n        if crop_method not in [\'random\', \'center\']:\n            raise Exception(""crop_method must in [\'random\', \'center\']!"")\n        if fill_mode is \'CONSTANT\' and constant_values is None:\n            raise Exception(""please provide constant_values!"")\n    if color_jitter_prob is not None:\n        if not 0. <= color_jitter_prob <= 1.:\n            raise Exception(""color_jitter_prob can\'t less that 0.0, and can\'t grater that 1.0"")\n    if flip_prob is not None:\n        if not 0. <= flip_prob[0] <= 1. and 0. <= flip_prob[1] <= 1.:\n            raise Exception(""flip_prob can\'t less than 0.0, and can\'t grater than 1.0"")\n    if rotate is not None:\n        if len(rotate) != 3:\n            raise Exception(\'please provide ""rotate"" parameter as [rotate_prob, min_angle, max_angle]!\')\n        if not 0. <= rotate[0] <= 1.:\n            raise Exception(""rotate prob can\'t less that 0.0, and can\'t grater that 1.0"")\n        if ground_truth is not None:\n            if not -5. <= rotate[1] <= 5. and -5. <= rotate[2] <= 5.:\n                raise Exception(\'rotate range must be -5 to 5, otherwise coordinate mapping become imprecise!\')\n        if not rotate[1] <= rotate[2]:\n            raise Exception(""rotate[1] can\'t  grater than rotate[2]"")\n\n    image_copy = image\n\n    input_h, input_w, input_c = input_shape[0], input_shape[1], input_shape[2]\n    input_h_f, input_w_f, input_c_f = tf.cast(input_h, tf.float32), tf.cast(input_w, tf.float32), \\\n                                      tf.cast(input_c, tf.float32)\n    output_h_f, output_w_f = float(output_shape[0]), float(output_shape[1])\n\n    if fill_mode == \'CONSTANT\':\n        keep_aspect_ratios = True\n    fill_mode_project = {\n        \'NEAREST_NEIGHBOR\': tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n        \'BILINEAR\': tf.image.ResizeMethod.BILINEAR,\n        \'BICUBIC\': tf.image.ResizeMethod.BICUBIC\n    }\n    if ground_truth is not None:\n        ymin = ground_truth[:, 0:1]\n        ymax = ground_truth[:, 1:2]\n        xmin = ground_truth[:, 2:3]\n        xmax = ground_truth[:, 3:4]\n        class_id = ground_truth[:, 4:5]\n        ground_truth_copy = tf.concat([ymin/2.+ymax/2., xmin/2.+xmax/2., ymax-ymin, xmax-xmin, class_id], axis=-1)\n\n    if data_format == \'channels_first\':\n        image = tf.transpose(image, [1, 2, 0])\n    input_h, input_w, input_c = input_shape[0], input_shape[1], input_shape[2]\n    output_h, output_w = output_shape\n    if zoom_size is not None:\n        zoom_or_output_h, zoom_or_output_w = zoom_size\n    else:\n        zoom_or_output_h, zoom_or_output_w = output_shape\n    if keep_aspect_ratios:\n        if fill_mode in [\'NEAREST_NEIGHBOR\', \'BILINEAR\', \'BICUBIC\']:\n            zoom_ratio = tf.cond(\n                tf.less(zoom_or_output_h / input_h, zoom_or_output_w / input_w),\n                lambda: tf.cast(zoom_or_output_h / input_h, tf.float32),\n                lambda: tf.cast(zoom_or_output_w / input_w, tf.float32)\n            )\n            resize_h, resize_w = tf.cond(\n                tf.less(zoom_or_output_h / input_h, zoom_or_output_w / input_w),\n                lambda: (zoom_or_output_h,tf.cast(tf.cast(input_w, tf.float32) * zoom_ratio, tf.int32)),\n                lambda: (tf.cast(tf.cast(input_h, tf.float32)*zoom_ratio, tf.int32), zoom_or_output_w)\n            )\n            image = tf.image.resize_images(\n                image, [resize_h, resize_w], fill_mode_project[fill_mode],\n                align_corners=True,\n            )\n            if ground_truth is not None:\n                ymin, ymax = ymin * zoom_ratio, ymax * zoom_ratio\n                xmin, xmax = xmin * zoom_ratio, xmax * zoom_ratio\n            image = tf.pad(\n                image, [[0, zoom_or_output_h-resize_h], [0, zoom_or_output_w-resize_w], [0, 0]],\n                mode=\'CONSTANT\', constant_values=constant_values\n            )\n        else:\n            image = tf.pad(\n                image, [[0, zoom_or_output_h-input_h], [0, zoom_or_output_w-input_w], [0, 0]],\n                mode=\'CONSTANT\', constant_values=constant_values\n            )\n    else:\n        image = tf.image.resize_images(\n            image, [zoom_or_output_h, zoom_or_output_w], fill_mode_project[fill_mode],\n            align_corners=True, preserve_aspect_ratio=False\n        )\n        if ground_truth is not None:\n            zoom_ratio_y = tf.cast(zoom_or_output_h / input_h, tf.float32)\n            zoom_ratio_x = tf.cast(zoom_or_output_w / input_w, tf.float32)\n            ymin, ymax = ymin * zoom_ratio_y, ymax * zoom_ratio_y\n            xmin, xmax = xmin * zoom_ratio_x, xmax * zoom_ratio_x\n\n    if zoom_size is not None:\n        if crop_method == \'random\':\n            random_h = zoom_or_output_h - output_h\n            random_w = zoom_or_output_w - output_w\n            crop_h = tf.random_uniform([], 0, random_h, tf.int32)\n            crop_w = tf.random_uniform([], 0, random_w, tf.int32)\n        else:\n            crop_h = (zoom_or_output_h - output_h) // 2\n            crop_w = (zoom_or_output_w - output_w) // 2\n        image = tf.slice(\n            image, [crop_h, crop_w, 0], [output_h, output_w, input_c]\n        )\n        if ground_truth is not None:\n            ymin, ymax = ymin - tf.cast(crop_h, tf.float32), ymax - tf.cast(crop_h, tf.float32)\n            xmin, xmax = xmin - tf.cast(crop_w, tf.float32), xmax - tf.cast(crop_w, tf.float32)\n\n    if flip_prob is not None:\n        flip_td_prob = tf.random_uniform([], 0., 1.)\n        flip_lr_prob = tf.random_uniform([], 0., 1.)\n        image = tf.cond(\n            tf.less(flip_td_prob, flip_prob[0]),\n            lambda: tf.reverse(image, [0]),\n            lambda: image\n        )\n        image = tf.cond(\n            tf.less(flip_lr_prob, flip_prob[1]),\n            lambda: tf.reverse(image, [1]),\n            lambda: image\n        )\n        if ground_truth is not None:\n            ymax, ymin = tf.cond(\n                tf.less(flip_td_prob, flip_prob[0]),\n                lambda: (output_h - ymin -1., output_h - ymax -1.),\n                lambda: (ymax, ymin)\n            )\n            xmax, xmin = tf.cond(\n                tf.less(flip_lr_prob, flip_prob[1]),\n                lambda: (output_w - xmin -1., output_w - xmax - 1.),\n                lambda: (xmax, xmin)\n            )\n    if color_jitter_prob is not None:\n        bcs = tf.random_uniform([3], 0., 1.)\n        image = tf.cond(bcs[0] < color_jitter_prob,\n                        lambda: tf.image.adjust_brightness(image, tf.random_uniform([], 0., 0.3)),\n                        lambda: image\n                )\n        image = tf.cond(bcs[1] < color_jitter_prob,\n                        lambda: tf.image.adjust_contrast(image, tf.random_uniform([], 0.8, 1.2)),\n                        lambda: image\n                )\n        image = tf.cond(bcs[2] < color_jitter_prob,\n                        lambda: tf.image.adjust_hue(image, tf.random_uniform([], -0.1, 0.1)),\n                        lambda: image\n                )\n\n    if rotate is not None:\n        rotate_prob, angmin, angmax = rotate[0], rotate[1], rotate[2]\n        rp = tf.random.uniform([], 0., 1.)\n        image, ymin, xmin, ymax, xmax = tf.cond(\n            rp < rotate_prob,\n            lambda: rotate_helper(image, angmin, angmax, ymin, xmin, ymax, xmax, output_h_f, output_w_f),\n            lambda: (image, ymin, xmin, ymax, xmax)\n        )\n\n    if data_format == \'channels_first\':\n        image = tf.transpose(image, [2, 0, 1])\n    if ground_truth is not None:\n        ymin = tf.where(ymin < 0., ymin-ymin, ymin)\n        xmin = tf.where(xmin < 0., xmin-xmin, xmin)\n        ymax = tf.where(ymax < 0., ymax-ymax, ymax)\n        xmax = tf.where(xmax < 0., xmax-xmax, xmax)\n        ymin = tf.where(ymin > output_h_f - 1., ymin-ymin+output_h_f - 1., ymin)\n        xmin = tf.where(xmin > output_w_f - 1., xmin-xmin+output_w_f - 1., xmin)\n        ymax = tf.where(ymax > output_h_f - 1., ymax-ymax+output_h_f - 1., ymax)\n        xmax = tf.where(xmax > output_w_f - 1., xmax-xmax+output_w_f - 1., xmax)\n        y_center = (ymin + ymax) / 2.\n        x_center = (xmin + xmax) / 2.\n        y_mask = tf.cast(y_center > 0., tf.float32) * tf.cast(y_center < output_h_f - 1., tf.float32)\n        x_mask = tf.cast(x_center > 0., tf.float32) * tf.cast(x_center < output_w_f - 1., tf.float32)\n        mask = tf.reshape((x_mask * y_mask) > 0., [-1])\n        ymin = tf.boolean_mask(ymin, mask)\n        xmin = tf.boolean_mask(xmin, mask)\n        ymax = tf.boolean_mask(ymax, mask)\n        xmax = tf.boolean_mask(xmax, mask)\n        class_id = tf.boolean_mask(class_id, mask)\n\n        ground_truth = tf.concat([y_center, x_center, ymax-ymin, xmax-xmin, class_id], axis=-1)\n\n        image, ground_truth = tf.cond(\n            tf.shape(ymin)[0] <= 0,\n            lambda: gt_checker_helper(image_copy, ground_truth_copy, output_shape, output_h_f / input_h_f,\n                                      output_w_f / input_w_f),\n            lambda: (image, ground_truth)\n        )\n\n    if pad_truth_to is not None:\n        ground_truth = tf.pad(\n                        ground_truth, [[0, pad_truth_to-tf.shape(ground_truth)[0]], [0, 0]],\n                        constant_values=-1.0\n                    )\n        return image_copy, ground_truth\n    else:\n        return image\n\n\ndef rotate_helper(img, angmn, angmx, ymn, xmn, ymx, xmx, outh, outw):\n    ang = tf.random.uniform([], angmn, angmx) * 3.1415926 / 180.\n    img = tf.contrib.image.rotate(img, ang, \'BILINEAR\')\n    ang = -ang\n    rotate_center_x = (outw - 1.) / 2.\n    rotate_center_y = (outh - 1.) / 2.\n    offset_x = rotate_center_x * (1 - tf.cos(ang)) + rotate_center_y * tf.sin(ang)\n    offset_y = rotate_center_y * (1 - tf.cos(ang)) - rotate_center_x * tf.sin(ang)\n    xmnymn_x = xmn * tf.cos(ang) - ymn * tf.sin(ang) + offset_x\n    xmnymn_y = xmn * tf.sin(ang) + ymn * tf.cos(ang) + offset_y\n    xmxymx_x = xmx * tf.cos(ang) - ymx * tf.sin(ang) + offset_x\n    xmxymx_y = xmx * tf.sin(ang) + ymx * tf.cos(ang) + offset_y\n    xmnymx_x = xmn * tf.cos(ang) - ymx * tf.sin(ang) + offset_x\n    xmnymx_y = xmn * tf.sin(ang) + ymx * tf.cos(ang) + offset_y\n    xmxymn_x = xmx * tf.cos(ang) - ymn * tf.sin(ang) + offset_x\n    xmxymn_y = xmx * tf.sin(ang) + ymn * tf.cos(ang) + offset_y\n    xmn = tf.reduce_min(tf.concat([xmnymn_x, xmxymx_x, xmnymx_x, xmxymn_x], axis=-1), axis=-1,\n                        keepdims=True)\n    ymn = tf.reduce_min(tf.concat([xmnymn_y, xmxymx_y, xmnymx_y, xmxymn_y], axis=-1), axis=-1,\n                        keepdims=True)\n    xmx = tf.reduce_max(tf.concat([xmnymn_x, xmxymx_x, xmnymx_x, xmxymn_x], axis=-1), axis=-1,\n                        keepdims=True)\n    ymx = tf.reduce_max(tf.concat([xmnymn_y, xmxymx_y, xmnymx_y, xmxymn_y], axis=-1), axis=-1,\n                        keepdims=True)\n    return img, ymn, xmn, ymx, xmx\n\n\ndef gt_checker_helper(image, ground_truth, size, h_ratio, w_ratio):\n    image = tf.image.resize(image, size)\n    fact = tf.reshape([h_ratio, w_ratio, h_ratio, w_ratio, 1.], [1, 5])\n    ground_truth = ground_truth * fact\n    return image, ground_truth\n'"
utils/imagenet_classname_encoder.py,0,"b""classname_to_ids = {'n01440764': 0, 'n01443537': 1, 'n01484850': 2, 'n01491361': 3, 'n01494475': 4, 'n01496331': 5, 'n01498041': 6, 'n01514668': 7, 'n01514859': 8, 'n01518878': 9, 'n01530575': 10, 'n01531178': 11, 'n01532829': 12, 'n01534433': 13, 'n01537544': 14, 'n01558993': 15, 'n01560419': 16, 'n01580077': 17, 'n01582220': 18, 'n01592084': 19, 'n01601694': 20, 'n01608432': 21, 'n01614925': 22, 'n01616318': 23, 'n01622779': 24, 'n01629819': 25, 'n01630670': 26, 'n01631663': 27, 'n01632458': 28, 'n01632777': 29, 'n01641577': 30, 'n01644373': 31, 'n01644900': 32, 'n01664065': 33, 'n01665541': 34, 'n01667114': 35, 'n01667778': 36, 'n01669191': 37, 'n01675722': 38, 'n01677366': 39, 'n01682714': 40, 'n01685808': 41, 'n01687978': 42, 'n01688243': 43, 'n01689811': 44, 'n01692333': 45, 'n01693334': 46, 'n01694178': 47, 'n01695060': 48, 'n01697457': 49, 'n01698640': 50, 'n01704323': 51, 'n01728572': 52, 'n01728920': 53, 'n01729322': 54, 'n01729977': 55, 'n01734418': 56, 'n01735189': 57, 'n01737021': 58, 'n01739381': 59, 'n01740131': 60, 'n01742172': 61, 'n01744401': 62, 'n01748264': 63, 'n01749939': 64, 'n01751748': 65, 'n01753488': 66, 'n01755581': 67, 'n01756291': 68, 'n01768244': 69, 'n01770081': 70, 'n01770393': 71, 'n01773157': 72, 'n01773549': 73, 'n01773797': 74, 'n01774384': 75, 'n01774750': 76, 'n01775062': 77, 'n01776313': 78, 'n01784675': 79, 'n01795545': 80, 'n01796340': 81, 'n01797886': 82, 'n01798484': 83, 'n01806143': 84, 'n01806567': 85, 'n01807496': 86, 'n01817953': 87, 'n01818515': 88, 'n01819313': 89, 'n01820546': 90, 'n01824575': 91, 'n01828970': 92, 'n01829413': 93, 'n01833805': 94, 'n01843065': 95, 'n01843383': 96, 'n01847000': 97, 'n01855032': 98, 'n01855672': 99, 'n01860187': 100, 'n01871265': 101, 'n01872401': 102, 'n01873310': 103, 'n01877812': 104, 'n01882714': 105, 'n01883070': 106, 'n01910747': 107, 'n01914609': 108, 'n01917289': 109, 'n01924916': 110, 'n01930112': 111, 'n01943899': 112, 'n01944390': 113, 'n01945685': 114, 'n01950731': 115, 'n01955084': 116, 'n01968897': 117, 'n01978287': 118, 'n01978455': 119, 'n01980166': 120, 'n01981276': 121, 'n01983481': 122, 'n01984695': 123, 'n01985128': 124, 'n01986214': 125, 'n01990800': 126, 'n02002556': 127, 'n02002724': 128, 'n02006656': 129, 'n02007558': 130, 'n02009229': 131, 'n02009912': 132, 'n02011460': 133, 'n02012849': 134, 'n02013706': 135, 'n02017213': 136, 'n02018207': 137, 'n02018795': 138, 'n02025239': 139, 'n02027492': 140, 'n02028035': 141, 'n02033041': 142, 'n02037110': 143, 'n02051845': 144, 'n02056570': 145, 'n02058221': 146, 'n02066245': 147, 'n02071294': 148, 'n02074367': 149, 'n02077923': 150, 'n02085620': 151, 'n02085782': 152, 'n02085936': 153, 'n02086079': 154, 'n02086240': 155, 'n02086646': 156, 'n02086910': 157, 'n02087046': 158, 'n02087394': 159, 'n02088094': 160, 'n02088238': 161, 'n02088364': 162, 'n02088466': 163, 'n02088632': 164, 'n02089078': 165, 'n02089867': 166, 'n02089973': 167, 'n02090379': 168, 'n02090622': 169, 'n02090721': 170, 'n02091032': 171, 'n02091134': 172, 'n02091244': 173, 'n02091467': 174, 'n02091635': 175, 'n02091831': 176, 'n02092002': 177, 'n02092339': 178, 'n02093256': 179, 'n02093428': 180, 'n02093647': 181, 'n02093754': 182, 'n02093859': 183, 'n02093991': 184, 'n02094114': 185, 'n02094258': 186, 'n02094433': 187, 'n02095314': 188, 'n02095570': 189, 'n02095889': 190, 'n02096051': 191, 'n02096177': 192, 'n02096294': 193, 'n02096437': 194, 'n02096585': 195, 'n02097047': 196, 'n02097130': 197, 'n02097209': 198, 'n02097298': 199, 'n02097474': 200, 'n02097658': 201, 'n02098105': 202, 'n02098286': 203, 'n02098413': 204, 'n02099267': 205, 'n02099429': 206, 'n02099601': 207, 'n02099712': 208, 'n02099849': 209, 'n02100236': 210, 'n02100583': 211, 'n02100735': 212, 'n02100877': 213, 'n02101006': 214, 'n02101388': 215, 'n02101556': 216, 'n02102040': 217, 'n02102177': 218, 'n02102318': 219, 'n02102480': 220, 'n02102973': 221, 'n02104029': 222, 'n02104365': 223, 'n02105056': 224, 'n02105162': 225, 'n02105251': 226, 'n02105412': 227, 'n02105505': 228, 'n02105641': 229, 'n02105855': 230, 'n02106030': 231, 'n02106166': 232, 'n02106382': 233, 'n02106550': 234, 'n02106662': 235, 'n02107142': 236, 'n02107312': 237, 'n02107574': 238, 'n02107683': 239, 'n02107908': 240, 'n02108000': 241, 'n02108089': 242, 'n02108422': 243, 'n02108551': 244, 'n02108915': 245, 'n02109047': 246, 'n02109525': 247, 'n02109961': 248, 'n02110063': 249, 'n02110185': 250, 'n02110341': 251, 'n02110627': 252, 'n02110806': 253, 'n02110958': 254, 'n02111129': 255, 'n02111277': 256, 'n02111500': 257, 'n02111889': 258, 'n02112018': 259, 'n02112137': 260, 'n02112350': 261, 'n02112706': 262, 'n02113023': 263, 'n02113186': 264, 'n02113624': 265, 'n02113712': 266, 'n02113799': 267, 'n02113978': 268, 'n02114367': 269, 'n02114548': 270, 'n02114712': 271, 'n02114855': 272, 'n02115641': 273, 'n02115913': 274, 'n02116738': 275, 'n02117135': 276, 'n02119022': 277, 'n02119789': 278, 'n02120079': 279, 'n02120505': 280, 'n02123045': 281, 'n02123159': 282, 'n02123394': 283, 'n02123597': 284, 'n02124075': 285, 'n02125311': 286, 'n02127052': 287, 'n02128385': 288, 'n02128757': 289, 'n02128925': 290, 'n02129165': 291, 'n02129604': 292, 'n02130308': 293, 'n02132136': 294, 'n02133161': 295, 'n02134084': 296, 'n02134418': 297, 'n02137549': 298, 'n02138441': 299, 'n02165105': 300, 'n02165456': 301, 'n02167151': 302, 'n02168699': 303, 'n02169497': 304, 'n02172182': 305, 'n02174001': 306, 'n02177972': 307, 'n02190166': 308, 'n02206856': 309, 'n02219486': 310, 'n02226429': 311, 'n02229544': 312, 'n02231487': 313, 'n02233338': 314, 'n02236044': 315, 'n02256656': 316, 'n02259212': 317, 'n02264363': 318, 'n02268443': 319, 'n02268853': 320, 'n02276258': 321, 'n02277742': 322, 'n02279972': 323, 'n02280649': 324, 'n02281406': 325, 'n02281787': 326, 'n02317335': 327, 'n02319095': 328, 'n02321529': 329, 'n02325366': 330, 'n02326432': 331, 'n02328150': 332, 'n02342885': 333, 'n02346627': 334, 'n02356798': 335, 'n02361337': 336, 'n02363005': 337, 'n02364673': 338, 'n02389026': 339, 'n02391049': 340, 'n02395406': 341, 'n02396427': 342, 'n02397096': 343, 'n02398521': 344, 'n02403003': 345, 'n02408429': 346, 'n02410509': 347, 'n02412080': 348, 'n02415577': 349, 'n02417914': 350, 'n02422106': 351, 'n02422699': 352, 'n02423022': 353, 'n02437312': 354, 'n02437616': 355, 'n02441942': 356, 'n02442845': 357, 'n02443114': 358, 'n02443484': 359, 'n02444819': 360, 'n02445715': 361, 'n02447366': 362, 'n02454379': 363, 'n02457408': 364, 'n02480495': 365, 'n02480855': 366, 'n02481823': 367, 'n02483362': 368, 'n02483708': 369, 'n02484975': 370, 'n02486261': 371, 'n02486410': 372, 'n02487347': 373, 'n02488291': 374, 'n02488702': 375, 'n02489166': 376, 'n02490219': 377, 'n02492035': 378, 'n02492660': 379, 'n02493509': 380, 'n02493793': 381, 'n02494079': 382, 'n02497673': 383, 'n02500267': 384, 'n02504013': 385, 'n02504458': 386, 'n02509815': 387, 'n02510455': 388, 'n02514041': 389, 'n02526121': 390, 'n02536864': 391, 'n02606052': 392, 'n02607072': 393, 'n02640242': 394, 'n02641379': 395, 'n02643566': 396, 'n02655020': 397, 'n02666196': 398, 'n02667093': 399, 'n02669723': 400, 'n02672831': 401, 'n02676566': 402, 'n02687172': 403, 'n02690373': 404, 'n02692877': 405, 'n02699494': 406, 'n02701002': 407, 'n02704792': 408, 'n02708093': 409, 'n02727426': 410, 'n02730930': 411, 'n02747177': 412, 'n02749479': 413, 'n02769748': 414, 'n02776631': 415, 'n02777292': 416, 'n02782093': 417, 'n02783161': 418, 'n02786058': 419, 'n02787622': 420, 'n02788148': 421, 'n02790996': 422, 'n02791124': 423, 'n02791270': 424, 'n02793495': 425, 'n02794156': 426, 'n02795169': 427, 'n02797295': 428, 'n02799071': 429, 'n02802426': 430, 'n02804414': 431, 'n02804610': 432, 'n02807133': 433, 'n02808304': 434, 'n02808440': 435, 'n02814533': 436, 'n02814860': 437, 'n02815834': 438, 'n02817516': 439, 'n02823428': 440, 'n02823750': 441, 'n02825657': 442, 'n02834397': 443, 'n02835271': 444, 'n02837789': 445, 'n02840245': 446, 'n02841315': 447, 'n02843684': 448, 'n02859443': 449, 'n02860847': 450, 'n02865351': 451, 'n02869837': 452, 'n02870880': 453, 'n02871525': 454, 'n02877765': 455, 'n02879718': 456, 'n02883205': 457, 'n02892201': 458, 'n02892767': 459, 'n02894605': 460, 'n02895154': 461, 'n02906734': 462, 'n02909870': 463, 'n02910353': 464, 'n02916936': 465, 'n02917067': 466, 'n02927161': 467, 'n02930766': 468, 'n02939185': 469, 'n02948072': 470, 'n02950826': 471, 'n02951358': 472, 'n02951585': 473, 'n02963159': 474, 'n02965783': 475, 'n02966193': 476, 'n02966687': 477, 'n02971356': 478, 'n02974003': 479, 'n02977058': 480, 'n02978881': 481, 'n02979186': 482, 'n02980441': 483, 'n02981792': 484, 'n02988304': 485, 'n02992211': 486, 'n02992529': 487, 'n02999410': 488, 'n03000134': 489, 'n03000247': 490, 'n03000684': 491, 'n03014705': 492, 'n03016953': 493, 'n03017168': 494, 'n03018349': 495, 'n03026506': 496, 'n03028079': 497, 'n03032252': 498, 'n03041632': 499, 'n03042490': 500, 'n03045698': 501, 'n03047690': 502, 'n03062245': 503, 'n03063599': 504, 'n03063689': 505, 'n03065424': 506, 'n03075370': 507, 'n03085013': 508, 'n03089624': 509, 'n03095699': 510, 'n03100240': 511, 'n03109150': 512, 'n03110669': 513, 'n03124043': 514, 'n03124170': 515, 'n03125729': 516, 'n03126707': 517, 'n03127747': 518, 'n03127925': 519, 'n03131574': 520, 'n03133878': 521, 'n03134739': 522, 'n03141823': 523, 'n03146219': 524, 'n03160309': 525, 'n03179701': 526, 'n03180011': 527, 'n03187595': 528, 'n03188531': 529, 'n03196217': 530, 'n03197337': 531, 'n03201208': 532, 'n03207743': 533, 'n03207941': 534, 'n03208938': 535, 'n03216828': 536, 'n03218198': 537, 'n03220513': 538, 'n03223299': 539, 'n03240683': 540, 'n03249569': 541, 'n03250847': 542, 'n03255030': 543, 'n03259280': 544, 'n03271574': 545, 'n03272010': 546, 'n03272562': 547, 'n03290653': 548, 'n03291819': 549, 'n03297495': 550, 'n03314780': 551, 'n03325584': 552, 'n03337140': 553, 'n03344393': 554, 'n03345487': 555, 'n03347037': 556, 'n03355925': 557, 'n03372029': 558, 'n03376595': 559, 'n03379051': 560, 'n03384352': 561, 'n03388043': 562, 'n03388183': 563, 'n03388549': 564, 'n03393912': 565, 'n03394916': 566, 'n03400231': 567, 'n03404251': 568, 'n03417042': 569, 'n03424325': 570, 'n03425413': 571, 'n03443371': 572, 'n03444034': 573, 'n03445777': 574, 'n03445924': 575, 'n03447447': 576, 'n03447721': 577, 'n03450230': 578, 'n03452741': 579, 'n03457902': 580, 'n03459775': 581, 'n03461385': 582, 'n03467068': 583, 'n03476684': 584, 'n03476991': 585, 'n03478589': 586, 'n03481172': 587, 'n03482405': 588, 'n03483316': 589, 'n03485407': 590, 'n03485794': 591, 'n03492542': 592, 'n03494278': 593, 'n03495258': 594, 'n03496892': 595, 'n03498962': 596, 'n03527444': 597, 'n03529860': 598, 'n03530642': 599, 'n03532672': 600, 'n03534580': 601, 'n03535780': 602, 'n03538406': 603, 'n03544143': 604, 'n03584254': 605, 'n03584829': 606, 'n03590841': 607, 'n03594734': 608, 'n03594945': 609, 'n03595614': 610, 'n03598930': 611, 'n03599486': 612, 'n03602883': 613, 'n03617480': 614, 'n03623198': 615, 'n03627232': 616, 'n03630383': 617, 'n03633091': 618, 'n03637318': 619, 'n03642806': 620, 'n03649909': 621, 'n03657121': 622, 'n03658185': 623, 'n03661043': 624, 'n03662601': 625, 'n03666591': 626, 'n03670208': 627, 'n03673027': 628, 'n03676483': 629, 'n03680355': 630, 'n03690938': 631, 'n03691459': 632, 'n03692522': 633, 'n03697007': 634, 'n03706229': 635, 'n03709823': 636, 'n03710193': 637, 'n03710637': 638, 'n03710721': 639, 'n03717622': 640, 'n03720891': 641, 'n03721384': 642, 'n03724870': 643, 'n03729826': 644, 'n03733131': 645, 'n03733281': 646, 'n03733805': 647, 'n03742115': 648, 'n03743016': 649, 'n03759954': 650, 'n03761084': 651, 'n03763968': 652, 'n03764736': 653, 'n03769881': 654, 'n03770439': 655, 'n03770679': 656, 'n03773504': 657, 'n03775071': 658, 'n03775546': 659, 'n03776460': 660, 'n03777568': 661, 'n03777754': 662, 'n03781244': 663, 'n03782006': 664, 'n03785016': 665, 'n03786901': 666, 'n03787032': 667, 'n03788195': 668, 'n03788365': 669, 'n03791053': 670, 'n03792782': 671, 'n03792972': 672, 'n03793489': 673, 'n03794056': 674, 'n03796401': 675, 'n03803284': 676, 'n03804744': 677, 'n03814639': 678, 'n03814906': 679, 'n03825788': 680, 'n03832673': 681, 'n03837869': 682, 'n03838899': 683, 'n03840681': 684, 'n03841143': 685, 'n03843555': 686, 'n03854065': 687, 'n03857828': 688, 'n03866082': 689, 'n03868242': 690, 'n03868863': 691, 'n03871628': 692, 'n03873416': 693, 'n03874293': 694, 'n03874599': 695, 'n03876231': 696, 'n03877472': 697, 'n03877845': 698, 'n03884397': 699, 'n03887697': 700, 'n03888257': 701, 'n03888605': 702, 'n03891251': 703, 'n03891332': 704, 'n03895866': 705, 'n03899768': 706, 'n03902125': 707, 'n03903868': 708, 'n03908618': 709, 'n03908714': 710, 'n03916031': 711, 'n03920288': 712, 'n03924679': 713, 'n03929660': 714, 'n03929855': 715, 'n03930313': 716, 'n03930630': 717, 'n03933933': 718, 'n03935335': 719, 'n03937543': 720, 'n03938244': 721, 'n03942813': 722, 'n03944341': 723, 'n03947888': 724, 'n03950228': 725, 'n03954731': 726, 'n03956157': 727, 'n03958227': 728, 'n03961711': 729, 'n03967562': 730, 'n03970156': 731, 'n03976467': 732, 'n03976657': 733, 'n03977966': 734, 'n03980874': 735, 'n03982430': 736, 'n03983396': 737, 'n03991062': 738, 'n03992509': 739, 'n03995372': 740, 'n03998194': 741, 'n04004767': 742, 'n04005630': 743, 'n04008634': 744, 'n04009552': 745, 'n04019541': 746, 'n04023962': 747, 'n04026417': 748, 'n04033901': 749, 'n04033995': 750, 'n04037443': 751, 'n04039381': 752, 'n04040759': 753, 'n04041544': 754, 'n04044716': 755, 'n04049303': 756, 'n04065272': 757, 'n04067472': 758, 'n04069434': 759, 'n04070727': 760, 'n04074963': 761, 'n04081281': 762, 'n04086273': 763, 'n04090263': 764, 'n04099969': 765, 'n04111531': 766, 'n04116512': 767, 'n04118538': 768, 'n04118776': 769, 'n04120489': 770, 'n04125021': 771, 'n04127249': 772, 'n04131690': 773, 'n04133789': 774, 'n04136333': 775, 'n04141076': 776, 'n04141327': 777, 'n04141975': 778, 'n04146614': 779, 'n04147183': 780, 'n04149813': 781, 'n04152593': 782, 'n04153751': 783, 'n04154565': 784, 'n04162706': 785, 'n04179913': 786, 'n04192698': 787, 'n04200800': 788, 'n04201297': 789, 'n04204238': 790, 'n04204347': 791, 'n04208210': 792, 'n04209133': 793, 'n04209239': 794, 'n04228054': 795, 'n04229816': 796, 'n04235860': 797, 'n04238763': 798, 'n04239074': 799, 'n04243546': 800, 'n04251144': 801, 'n04252077': 802, 'n04252225': 803, 'n04254120': 804, 'n04254680': 805, 'n04254777': 806, 'n04258138': 807, 'n04259630': 808, 'n04263257': 809, 'n04264628': 810, 'n04265275': 811, 'n04266014': 812, 'n04270147': 813, 'n04273569': 814, 'n04275548': 815, 'n04277352': 816, 'n04285008': 817, 'n04286575': 818, 'n04296562': 819, 'n04310018': 820, 'n04311004': 821, 'n04311174': 822, 'n04317175': 823, 'n04325704': 824, 'n04326547': 825, 'n04328186': 826, 'n04330267': 827, 'n04332243': 828, 'n04335435': 829, 'n04336792': 830, 'n04344873': 831, 'n04346328': 832, 'n04347754': 833, 'n04350905': 834, 'n04355338': 835, 'n04355933': 836, 'n04356056': 837, 'n04357314': 838, 'n04366367': 839, 'n04367480': 840, 'n04370456': 841, 'n04371430': 842, 'n04371774': 843, 'n04372370': 844, 'n04376876': 845, 'n04380533': 846, 'n04389033': 847, 'n04392985': 848, 'n04398044': 849, 'n04399382': 850, 'n04404412': 851, 'n04409515': 852, 'n04417672': 853, 'n04418357': 854, 'n04423845': 855, 'n04428191': 856, 'n04429376': 857, 'n04435653': 858, 'n04442312': 859, 'n04443257': 860, 'n04447861': 861, 'n04456115': 862, 'n04458633': 863, 'n04461696': 864, 'n04462240': 865, 'n04465501': 866, 'n04467665': 867, 'n04476259': 868, 'n04479046': 869, 'n04482393': 870, 'n04483307': 871, 'n04485082': 872, 'n04486054': 873, 'n04487081': 874, 'n04487394': 875, 'n04493381': 876, 'n04501370': 877, 'n04505470': 878, 'n04507155': 879, 'n04509417': 880, 'n04515003': 881, 'n04517823': 882, 'n04522168': 883, 'n04523525': 884, 'n04525038': 885, 'n04525305': 886, 'n04532106': 887, 'n04532670': 888, 'n04536866': 889, 'n04540053': 890, 'n04542943': 891, 'n04548280': 892, 'n04548362': 893, 'n04550184': 894, 'n04552348': 895, 'n04553703': 896, 'n04554684': 897, 'n04557648': 898, 'n04560804': 899, 'n04562935': 900, 'n04579145': 901, 'n04579432': 902, 'n04584207': 903, 'n04589890': 904, 'n04590129': 905, 'n04591157': 906, 'n04591713': 907, 'n04592741': 908, 'n04596742': 909, 'n04597913': 910, 'n04599235': 911, 'n04604644': 912, 'n04606251': 913, 'n04612504': 914, 'n04613696': 915, 'n06359193': 916, 'n06596364': 917, 'n06785654': 918, 'n06794110': 919, 'n06874185': 920, 'n07248320': 921, 'n07565083': 922, 'n07579787': 923, 'n07583066': 924, 'n07584110': 925, 'n07590611': 926, 'n07613480': 927, 'n07614500': 928, 'n07615774': 929, 'n07684084': 930, 'n07693725': 931, 'n07695742': 932, 'n07697313': 933, 'n07697537': 934, 'n07711569': 935, 'n07714571': 936, 'n07714990': 937, 'n07715103': 938, 'n07716358': 939, 'n07716906': 940, 'n07717410': 941, 'n07717556': 942, 'n07718472': 943, 'n07718747': 944, 'n07720875': 945, 'n07730033': 946, 'n07734744': 947, 'n07742313': 948, 'n07745940': 949, 'n07747607': 950, 'n07749582': 951, 'n07753113': 952, 'n07753275': 953, 'n07753592': 954, 'n07754684': 955, 'n07760859': 956, 'n07768694': 957, 'n07802026': 958, 'n07831146': 959, 'n07836838': 960, 'n07860988': 961, 'n07871810': 962, 'n07873807': 963, 'n07875152': 964, 'n07880968': 965, 'n07892512': 966, 'n07920052': 967, 'n07930864': 968, 'n07932039': 969, 'n09193705': 970, 'n09229709': 971, 'n09246464': 972, 'n09256479': 973, 'n09288635': 974, 'n09332890': 975, 'n09399592': 976, 'n09421951': 977, 'n09428293': 978, 'n09468604': 979, 'n09472597': 980, 'n09835506': 981, 'n10148035': 982, 'n10565667': 983, 'n11879895': 984, 'n11939491': 985, 'n12057211': 986, 'n12144580': 987, 'n12267677': 988, 'n12620546': 989, 'n12768682': 990, 'n12985857': 991, 'n12998815': 992, 'n13037406': 993, 'n13040303': 994, 'n13044778': 995, 'n13052670': 996, 'n13054560': 997, 'n13133613': 998, 'n15075141': 999}\n"""
utils/test_imagenet_utils.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport utils.tfrecord_imagenet_utils as imagenet_utils\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\n\ntfrecord = imagenet_utils.dataset2tfrecord('F:\\\\test\\\\',\n                                           'F:\\\\tfrecord\\\\', 'test', 5)\nprint(tfrecord)\n"""
utils/test_voc_utils.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport utils.tfrecord_voc_utils as voc_utils\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n\n# annotations path, image path, save path, tfrecord prefix, shard\n\ntfrecord = voc_utils.dataset2tfrecord('../VOC/Annotations', '../VOC/JPEGImages',\n                                      '../data/', 'test', 10)\nprint(tfrecord)\n"""
utils/tfrecord_imagenet_utils.py,22,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nimport os\nimport numpy as np\nimport warnings\nimport math\nimport sys\nimport random\nfrom utils.imagenet_classname_encoder import classname_to_ids\nfrom utils.image_augmentor import image_augmentor\n\n\nclass ImageReader(object):\n        def __init__(self):\n            self._decode_jpeg_data = tf.placeholder(dtype=tf.string)\n            self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n\n        def decode_jpeg(self, sess, image_data):\n            image = sess.run(self._decode_jpeg, feed_dict={\n                self._decode_jpeg_data: image_data\n            })\n            assert len(image.shape) == 3\n            assert image.shape[2] == 3\n            return image\n\n        def read_image_dims(self, sess, image_data):\n            image = self.decode_jpeg(sess, image_data)\n            return image.shape\n\n\ndef int64_feature(values):\n    if not isinstance(values, (tuple, list)):\n        values = [values]\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n\n\ndef bytes_feature(values):\n    if not isinstance(values, (tuple, list)):\n        values = [values]\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=values))\n\n\ndef dataset2tfrecord(img_dir, output_dir, name, total_shards=50):\n    if not tf.gfile.Exists(output_dir):\n        tf.gfile.MakeDirs(output_dir)\n        print(output_dir, 'does not exist, create it done')\n    else:\n        if len(tf.gfile.ListDirectory(output_dir)) == 0:\n            print(output_dir, 'already exist, need not create new')\n        else:\n            warnings.warn(output_dir + ' is not empty!', UserWarning)\n    image_reader = ImageReader()\n    sess = tf.Session()\n    outputfiles = []\n    directories = []\n    class_names = []\n    for filename in os.listdir(img_dir):\n        path = os.path.join(img_dir, filename)\n        if os.path.isdir(path):\n            directories.append(path)\n            class_names.append(filename)\n    imglist = []\n    for directory in directories:\n        for filename in os.listdir(directory):\n            imgname = os.path.join(directory, filename)\n            imglist.append(imgname)\n    random.shuffle(imglist)\n    num_per_shard = int(math.ceil(len(imglist)) / float(total_shards))\n    for shard_id in range(total_shards):\n        outputname = '%s_%05d-of-%05d.tfrecord' % (name, shard_id+1, total_shards)\n        outputname = os.path.join(output_dir, outputname)\n        outputfiles.append(outputname)\n        with tf.python_io.TFRecordWriter(outputname) as tf_writer:\n            start_ndx = shard_id * num_per_shard\n            end_ndx = min((shard_id+1) * num_per_shard, len(imglist))\n            for i in range(start_ndx, end_ndx):\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d/%d' % (\n                    i+1, len(imglist), shard_id+1, total_shards))\n                sys.stdout.flush()\n                image_data = tf.gfile.GFile(imglist[i], 'rb').read()\n                shape = image_reader.read_image_dims(sess, image_data)\n                shape = np.asarray(shape, np.int32)\n                class_name = os.path.basename(os.path.dirname(imglist[i]))\n                class_id = classname_to_ids[class_name]\n                features = {\n                    'image': bytes_feature(image_data),\n                    'shape': bytes_feature(shape.tobytes()),\n                    'label': int64_feature(class_id)\n                }\n                example = tf.train.Example(features=tf.train.Features(\n                                           feature=features))\n                tf_writer.write(example.SerializeToString())\n            sys.stdout.write('\\n')\n            sys.stdout.flush()\n    return outputfiles\n\n\ndef parse_function(data, config):\n        features = tf.parse_single_example(data, features={\n            'image': tf.FixedLenFeature([], tf.string),\n            'shape': tf.FixedLenFeature([], tf.string),\n            'label': tf.FixedLenFeature([], tf.int64)\n        })\n        shape = tf.decode_raw(features['shape'], tf.int32)\n        label = tf.cast(features['label'], tf.int64)\n        shape = tf.reshape(shape, [3])\n        images = tf.image.decode_jpeg(features['image'], channels=3)\n        images = tf.cast(tf.reshape(images, shape), tf.float32)\n        images = image_augmentor(image=images,\n                                 input_shape=shape,\n                                 **config\n                                 )\n        return images, label, # shape\n\n\ndef get_generator(tfrecords, batch_size, buffer_size, image_preprocess_config):\n    data = tf.data.TFRecordDataset(tfrecords)\n    data = data.map(lambda x: parse_function(x, image_preprocess_config)).shuffle(buffer_size=buffer_size).batch(batch_size, drop_remainder=True).repeat()\n    iterator = tf.data.Iterator.from_structure(data.output_types, data.output_shapes)\n    init_op = iterator.make_initializer(data)\n    return init_op, iterator\n\n"""
utils/tfrecord_voc_utils.py,22,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport tensorflow as tf\nfrom lxml import etree\nimport os\nimport numpy as np\nimport warnings\nimport math\nimport sys\nfrom utils.voc_classname_encoder import classname_to_ids\nfrom utils.image_augmentor import image_augmentor\n\n\ndef int64_feature(values):\n    if not isinstance(values, (tuple, list)):\n        values = [values]\n    return tf.train.Feature(bytes_list=tf.train.Int64List(value=values))\n\n\ndef bytes_feature(values):\n    if not isinstance(values, (tuple, list)):\n        values = [values]\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=values))\n\n\ndef float_feature(values):\n    if not isinstance(values, (tuple, list)):\n        values = [values]\n    return tf.train.Feature(bytes_list=tf.train.FloatList(value=values))\n\n\ndef xml_to_example(xmlpath, imgpath):\n    xml = etree.parse(xmlpath)\n    root = xml.getroot()\n    imgname = root.find('filename').text\n    imgname = os.path.join(imgpath, imgname)\n    image = tf.gfile.GFile(imgname, 'rb').read()\n    size = root.find('size')\n    height = int(size.find('height').text)\n    width = int(size.find('width').text)\n    depth = int(size.find('depth').text)\n    shape = np.asarray([height, width, depth], np.int32)\n    xpath = xml.xpath('//object')\n    ground_truth = np.zeros([len(xpath), 5], np.float32)\n    for i in range(len(xpath)):\n        obj = xpath[i]\n        classid = classname_to_ids[obj.find('name').text]\n        bndbox = obj.find('bndbox')\n        ymin = float(bndbox.find('ymin').text)\n        ymax = float(bndbox.find('ymax').text)\n        xmin = float(bndbox.find('xmin').text)\n        xmax = float(bndbox.find('xmax').text)\n        ground_truth[i, :] = np.asarray([ymin, ymax, xmin, xmax, classid], np.float32)\n    features = {\n        'image': bytes_feature(image),\n        'shape': bytes_feature(shape.tobytes()),\n        'ground_truth': bytes_feature(ground_truth.tobytes())\n    }\n    example = tf.train.Example(features=tf.train.Features(\n        feature=features))\n    return example\n\n\ndef dataset2tfrecord(xml_dir, img_dir, output_dir, name, total_shards=5):\n    if not tf.gfile.Exists(output_dir):\n        tf.gfile.MakeDirs(output_dir)\n        print(output_dir, 'does not exist, create it done')\n    else:\n        if len(tf.gfile.ListDirectory(output_dir)) == 0:\n            print(output_dir, 'already exist, need not create new')\n        else:\n            warnings.warn(output_dir + ' is not empty!', UserWarning)\n    outputfiles = []\n    xmllist = tf.gfile.Glob(os.path.join(xml_dir, '*.xml'))\n    num_per_shard = int(math.ceil(len(xmllist)) / float(total_shards))\n    for shard_id in range(total_shards):\n        outputname = '%s_%05d-of-%05d.tfrecord' % (name, shard_id+1, total_shards)\n        outputname = os.path.join(output_dir, outputname)\n        outputfiles.append(outputname)\n        with tf.python_io.TFRecordWriter(outputname) as tf_writer:\n            start_ndx = shard_id * num_per_shard\n            end_ndx = min((shard_id+1) * num_per_shard, len(xmllist))\n            for i in range(start_ndx, end_ndx):\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d/%d' % (\n                    i+1, len(xmllist), shard_id+1, total_shards))\n                sys.stdout.flush()\n                example = xml_to_example(xmllist[i], img_dir)\n                tf_writer.write(example.SerializeToString())\n            sys.stdout.write('\\n')\n            sys.stdout.flush()\n    return outputfiles\n\n\ndef parse_function(data, config):\n        features = tf.parse_single_example(data, features={\n            'image': tf.FixedLenFeature([], tf.string),\n            'shape': tf.FixedLenFeature([], tf.string),\n            'ground_truth': tf.FixedLenFeature([], tf.string)\n        })\n        shape = tf.decode_raw(features['shape'], tf.int32)\n        ground_truth = tf.decode_raw(features['ground_truth'], tf.float32)\n        shape = tf.reshape(shape, [3])\n        ground_truth = tf.reshape(ground_truth, [-1, 5])\n        images = tf.image.decode_jpeg(features['image'], channels=3)\n        images = tf.cast(tf.reshape(images, shape), tf.float32)\n        images, ground_truth = image_augmentor(image=images,\n                                               input_shape=shape,\n                                               ground_truth=ground_truth,\n                                               **config\n                                               )\n        return images, ground_truth\n\n\ndef get_generator(tfrecords, batch_size, buffer_size, image_preprocess_config):\n    data = tf.data.TFRecordDataset(tfrecords)\n    data = data.map(lambda x: parse_function(x, image_preprocess_config)).shuffle(buffer_size=buffer_size).batch(batch_size, drop_remainder=True).repeat()\n    iterator = tf.data.Iterator.from_structure(data.output_types, data.output_shapes)\n    init_op = iterator.make_initializer(data)\n    return init_op, iterator\n\n"""
utils/voc_classname_encoder.py,0,"b""classname_to_ids = {\n    'aeroplane': 0,\n    'bicycle': 1,\n    'bird': 2,\n    'boat': 3,\n    'bottle': 4,\n    'bus': 5,\n    'car': 6,\n    'cat': 7,\n    'chair': 8,\n    'cow': 9,\n    'diningtable': 10,\n    'dog': 11,\n    'horse': 12,\n    'motorbike': 13,\n    'person': 14,\n    'pottedplant': 15,\n    'sheep': 16,\n    'sofa': 17,\n    'train': 18,\n    'tvmonitor': 19,\n}\n"""
