file_path,api_count,code
data.py,0,"b'import numpy as np\nimport scipy.io as sio\n\ndef process_gridworld_data(input, imsize):\n    # run training from input matlab data file, and save test data prediction in output file\n    # load data from Matlab file, including\n    # im_data: flattened images\n    # state_data: concatenated one-hot vectors for each state variable\n    # state_xy_data: state variable (x,y position)\n    # label_data: one-hot vector for action (state difference)\n    im_size=[imsize, imsize]\n    matlab_data = sio.loadmat(input)\n    im_data = matlab_data[""batch_im_data""]\n    im_data = (im_data - 1)/255  # obstacles = 1, free zone = 0\n    value_data = matlab_data[""batch_value_data""]\n    state1_data = matlab_data[""state_x_data""]\n    state2_data = matlab_data[""state_y_data""]\n    label_data = matlab_data[""batch_label_data""]\n    ydata = label_data.astype(\'int8\')\n    Xim_data = im_data.astype(\'float32\')\n    Xim_data = Xim_data.reshape(-1, 1, im_size[0], im_size[1])\n    Xval_data = value_data.astype(\'float32\')\n    Xval_data = Xval_data.reshape(-1, 1, im_size[0], im_size[1])\n    Xdata = np.append(Xim_data, Xval_data, axis=1)\n    # Need to transpose because Theano is NCHW, while TensorFlow is NHWC\n    Xdata = np.transpose(Xdata,  (0, 2, 3, 1))\n    S1data = state1_data.astype(\'int8\')\n    S2data = state2_data.astype(\'int8\')\n\n    all_training_samples = int(6/7.0*Xdata.shape[0])\n    training_samples = all_training_samples\n    Xtrain = Xdata[0:training_samples]\n    S1train = S1data[0:training_samples]\n    S2train = S2data[0:training_samples]\n    ytrain = ydata[0:training_samples]\n\n    Xtest = Xdata[all_training_samples:]\n    S1test = S1data[all_training_samples:]\n    S2test = S2data[all_training_samples:]\n    ytest = ydata[all_training_samples:]\n    ytest = ytest.flatten()\n\n    sortinds = np.random.permutation(training_samples)\n    Xtrain = Xtrain[sortinds]\n    S1train = S1train[sortinds]\n    S2train = S2train[sortinds]\n    ytrain = ytrain[sortinds]\n    ytrain = ytrain.flatten()\n    return Xtrain, S1train, S2train, ytrain, Xtest, S1test, S2test, ytest\n'"
model.py,42,"b'import numpy as np\nimport tensorflow as tf\nfrom utils import conv2d_flipkernel\n\ndef VI_Block(X, S1, S2, config):\n    k    = config.k    # Number of value iterations performed\n    ch_i = config.ch_i # Channels in input layer\n    ch_h = config.ch_h # Channels in initial hidden layer\n    ch_q = config.ch_q # Channels in q layer (~actions)\n    state_batch_size = config.statebatchsize # k+1 state inputs for each channel\n\n    bias  = tf.Variable(np.random.randn(1, 1, 1, ch_h)    * 0.01, dtype=tf.float32)\n    # weights from inputs to q layer (~reward in Bellman equation)\n    w0    = tf.Variable(np.random.randn(3, 3, ch_i, ch_h) * 0.01, dtype=tf.float32)\n    w1    = tf.Variable(np.random.randn(1, 1, ch_h, 1)    * 0.01, dtype=tf.float32)\n    w     = tf.Variable(np.random.randn(3, 3, 1, ch_q)    * 0.01, dtype=tf.float32)\n    # feedback weights from v layer into q layer (~transition probabilities in Bellman equation)\n    w_fb  = tf.Variable(np.random.randn(3, 3, 1, ch_q)    * 0.01, dtype=tf.float32)\n    w_o   = tf.Variable(np.random.randn(ch_q, 8)          * 0.01, dtype=tf.float32)\n\n    # initial conv layer over image+reward prior\n    h = conv2d_flipkernel(X, w0, name=""h0"") + bias\n\n    r = conv2d_flipkernel(h, w1, name=""r"")\n    q = conv2d_flipkernel(r, w, name=""q"")\n    v = tf.reduce_max(q, axis=3, keep_dims=True, name=""v"")\n\n    for i in range(0, k-1):\n        rv = tf.concat([r, v], 3)\n        wwfb = tf.concat([w, w_fb], 2)\n        q = conv2d_flipkernel(rv, wwfb, name=""q"")\n        v = tf.reduce_max(q, axis=3, keep_dims=True, name=""v"")\n\n    # do one last convolution\n    q = conv2d_flipkernel(tf.concat([r, v], 3),\n                          tf.concat([w, w_fb], 2), name=""q"")\n\n    # CHANGE TO THEANO ORDERING\n    # Since we are selecting over channels, it becomes easier to work with\n    # the tensor when it is in NCHW format vs NHWC\n    q = tf.transpose(q, perm=[0, 3, 1, 2])\n\n    # Select the conv-net channels at the state position (S1,S2).\n    # This intuitively corresponds to each channel representing an action, and the convnet the Q function.\n    # The tricky thing is we want to select the same (S1,S2) position *for each* channel and for each sample\n    # TODO: performance can be improved here by substituting expensive\n    #       transpose calls with better indexing for gather_nd\n    bs = tf.shape(q)[0]\n    rprn = tf.reshape(tf.tile(tf.reshape(tf.range(bs), [-1, 1]), [1, state_batch_size]), [-1])\n    ins1 = tf.cast(tf.reshape(S1, [-1]), tf.int32)\n    ins2 = tf.cast(tf.reshape(S2, [-1]), tf.int32)\n    idx_in = tf.transpose(tf.stack([ins1, ins2, rprn]), [1, 0])\n    q_out = tf.gather_nd(tf.transpose(q, [2, 3, 0, 1]), idx_in, name=""q_out"")\n\n    # add logits\n    logits = tf.matmul(q_out, w_o)\n    # softmax output weights\n    output = tf.nn.softmax(logits, name=""output"")\n    return logits, output\n\n# similar to the normal VI_Block except there are separate weights for each q layer\ndef VI_Untied_Block(X, S1, S2, config):\n    k    = config.k    # Number of value iterations performed\n    ch_i = config.ch_i # Channels in input layer\n    ch_h = config.ch_h # Channels in initial hidden layer\n    ch_q = config.ch_q # Channels in q layer (~actions)\n    state_batch_size = config.statebatchsize # k+1 state inputs for each channel\n\n    bias   = tf.Variable(np.random.randn(1, 1, 1, ch_h)    * 0.01, dtype=tf.float32)\n    # weights from inputs to q layer (~reward in Bellman equation)\n    w0     = tf.Variable(np.random.randn(3, 3, ch_i, ch_h) * 0.01, dtype=tf.float32)\n    w1     = tf.Variable(np.random.randn(1, 1, ch_h, 1)    * 0.01, dtype=tf.float32)\n    w_l    = [tf.Variable(np.random.randn(3, 3, 1, ch_q)   * 0.01, dtype=tf.float32) for i in range(0, k+1)]\n    # feedback weights from v layer into q layer (~transition probabilities in Bellman equation)\n    w_fb_l = [tf.Variable(np.random.randn(3, 3, 1, ch_q)   * 0.01, dtype=tf.float32) for i in range(0,k)]\n    w_o    = tf.Variable(np.random.randn(ch_q, 8)          * 0.01, dtype=tf.float32)\n\n    # initial conv layer over image+reward prior\n    h = conv2d_flipkernel(X, w0, name=""h0"") + bias\n\n    r = conv2d_flipkernel(h, w1, name=""r"")\n    q = conv2d_flipkernel(r, w_l[0], name=""q"")\n    v = tf.reduce_max(q, axis=3, keep_dims=True, name=""v"")\n\n    for i in range(0, k-1):\n        rv = tf.concat([r, v], 3)\n        wwfb = tf.concat([w_l[i+1], w_fb_l[i]], 2)\n        q = conv2d_flipkernel(rv, wwfb, name=""q"")\n        v = tf.reduce_max(q, axis=3, keep_dims=True, name=""v"")\n\n    # do one last convolution\n    q = conv2d_flipkernel(tf.concat([r, v], 3),\n                          tf.concat([w_l[k], w_fb_l[k-1]], 2), name=""q"")\n\n    # CHANGE TO THEANO ORDERING\n    # Since we are selecting over channels, it becomes easier to work with\n    # the tensor when it is in NCHW format vs NHWC\n    q = tf.transpose(q, perm=[0, 3, 1, 2])\n\n    # Select the conv-net channels at the state position (S1,S2).\n    # This intuitively corresponds to each channel representing an action, and the convnet the Q function.\n    # The tricky thing is we want to select the same (S1,S2) position *for each* channel and for each sample\n    # TODO: performance can be improved here by substituting expensive\n    #       transpose calls with better indexing for gather_nd\n    bs = tf.shape(q)[0]\n    rprn = tf.reshape(tf.tile(tf.reshape(tf.range(bs), [-1, 1]), [1, state_batch_size]), [-1])\n    ins1 = tf.cast(tf.reshape(S1, [-1]), tf.int32)\n    ins2 = tf.cast(tf.reshape(S2, [-1]), tf.int32)\n    idx_in = tf.transpose(tf.stack([ins1, ins2, rprn]), [1, 0])\n    q_out = tf.gather_nd(tf.transpose(q, [2, 3, 0, 1]), idx_in, name=""q_out"")\n\n    # add logits\n    logits = tf.matmul(q_out, w_o)\n    # softmax output weights\n    output = tf.nn.softmax(logits, name=""output"")\n    return logits, output\n'"
train.py,38,"b'import time\nimport numpy as np\nimport tensorflow as tf\nfrom data  import process_gridworld_data\nfrom model import VI_Block, VI_Untied_Block\nfrom utils import fmt_row\n\n# Data\ntf.app.flags.DEFINE_string(\'input\',           \'data/gridworld_8.mat\', \'Path to data\')\ntf.app.flags.DEFINE_integer(\'imsize\',         8,                      \'Size of input image\')\n# Parameters\ntf.app.flags.DEFINE_float(\'lr\',               0.001,                  \'Learning rate for RMSProp\')\ntf.app.flags.DEFINE_integer(\'epochs\',         30,                     \'Maximum epochs to train for\')\ntf.app.flags.DEFINE_integer(\'k\',              10,                     \'Number of value iterations\')\ntf.app.flags.DEFINE_integer(\'ch_i\',           2,                      \'Channels in input layer\')\ntf.app.flags.DEFINE_integer(\'ch_h\',           150,                    \'Channels in initial hidden layer\')\ntf.app.flags.DEFINE_integer(\'ch_q\',           10,                     \'Channels in q layer (~actions)\')\ntf.app.flags.DEFINE_integer(\'batchsize\',      12,                     \'Batch size\')\ntf.app.flags.DEFINE_integer(\'statebatchsize\', 10,                     \'Number of state inputs for each sample (real number, technically is k+1)\')\ntf.app.flags.DEFINE_boolean(\'untied_weights\', False,                  \'Untie weights of VI network\')\n# Misc.\ntf.app.flags.DEFINE_integer(\'seed\',           0,                      \'Random seed for numpy\')\ntf.app.flags.DEFINE_integer(\'display_step\',   1,                      \'Print summary output every n epochs\')\ntf.app.flags.DEFINE_boolean(\'log\',            False,                  \'Enable for tensorboard summary\')\ntf.app.flags.DEFINE_string(\'logdir\',          \'/tmp/vintf/\',          \'Directory to store tensorboard summary\')\n\nconfig = tf.app.flags.FLAGS\n\nnp.random.seed(config.seed)\n\n# symbolic input image tensor where typically first channel is image, second is the reward prior\nX  = tf.placeholder(tf.float32, name=""X"",  shape=[None, config.imsize, config.imsize, config.ch_i])\n# symbolic input batches of vertical positions\nS1 = tf.placeholder(tf.int32,   name=""S1"", shape=[None, config.statebatchsize])\n# symbolic input batches of horizontal positions\nS2 = tf.placeholder(tf.int32,   name=""S2"", shape=[None, config.statebatchsize])\ny  = tf.placeholder(tf.int32,   name=""y"",  shape=[None])\n\n# Construct model (Value Iteration Network)\nif (config.untied_weights):\n    logits, nn = VI_Untied_Block(X, S1, S2, config)\nelse:\n    logits, nn = VI_Block(X, S1, S2, config)\n\n# Define loss and optimizer\ny_ = tf.cast(y, tf.int64)\ncross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n    logits=logits, labels=y_, name=\'cross_entropy\')\ncross_entropy_mean = tf.reduce_mean(cross_entropy, name=\'cross_entropy_mean\')\ntf.add_to_collection(\'losses\', cross_entropy_mean)\n\ncost = tf.add_n(tf.get_collection(\'losses\'), name=\'total_loss\')\noptimizer = tf.train.RMSPropOptimizer(learning_rate=config.lr, epsilon=1e-6, centered=True).minimize(cost)\n\n# Test model & calculate accuracy\ncp = tf.cast(tf.argmax(nn, 1), tf.int32)\nerr = tf.reduce_mean(tf.cast(tf.not_equal(cp, y), dtype=tf.float32))\n\n# Initializing the variables\ninit = tf.global_variables_initializer()\nsaver = tf.train.Saver()\n\nXtrain, S1train, S2train, ytrain, Xtest, S1test, S2test, ytest = process_gridworld_data(input=config.input, imsize=config.imsize)\n\n# Launch the graph\nwith tf.Session() as sess:\n    if config.log:\n        for var in tf.trainable_variables():\n            tf.summary.histogram(var.op.name, var)\n        summary_op = tf.summary.merge_all()\n        summary_writer = tf.summary.FileWriter(config.logdir, sess.graph)\n    sess.run(init)\n\n    batch_size = config.batchsize\n    print(fmt_row(10, [""Epoch"", ""Train Cost"", ""Train Err"", ""Epoch Time""]))\n    for epoch in range(int(config.epochs)):\n        tstart = time.time()\n        avg_err, avg_cost = 0.0, 0.0\n        num_batches = int(Xtrain.shape[0]/batch_size)\n        # Loop over all batches\n        for i in range(0, Xtrain.shape[0], batch_size):\n            j = i + batch_size\n            if j <= Xtrain.shape[0]:\n                # Run optimization op (backprop) and cost op (to get loss value)\n                fd = {X: Xtrain[i:j], S1: S1train[i:j], S2: S2train[i:j],\n                    y: ytrain[i * config.statebatchsize:j * config.statebatchsize]}\n                _, e_, c_ = sess.run([optimizer, err, cost], feed_dict=fd)\n                avg_err += e_\n                avg_cost += c_\n        # Display logs per epoch step\n        if epoch % config.display_step == 0:\n            elapsed = time.time() - tstart\n            print(fmt_row(10, [epoch, avg_cost/num_batches, avg_err/num_batches, elapsed]))\n        if config.log:\n            summary = tf.Summary()\n            summary.ParseFromString(sess.run(summary_op))\n            summary.value.add(tag=\'Average error\', simple_value=float(avg_err/num_batches))\n            summary.value.add(tag=\'Average cost\', simple_value=float(avg_cost/num_batches))\n            summary_writer.add_summary(summary, epoch)\n    print(""Finished training!"")\n\n    # Test model\n    correct_prediction = tf.cast(tf.argmax(nn, 1), tf.int32)\n    # Calculate accuracy\n    accuracy = tf.reduce_mean(tf.cast(tf.not_equal(correct_prediction, y), dtype=tf.float32))\n    acc = accuracy.eval({X: Xtest, S1: S1test, S2: S2test, y: ytest})\n    print(f\'Accuracy: {100 * (1 - acc)}%\')\n'"
utils.py,1,"b'import numpy as np\nimport tensorflow as tf\n\n# helper methods to print nice table (taken from CGT code)\ndef fmt_item(x, l):\n    if isinstance(x, np.ndarray):\n        assert x.ndim==0\n        x = x.item()\n    if isinstance(x, float): rep = ""%g""%x\n    else: rep = str(x)\n    return "" ""*(l - len(rep)) + rep\n\ndef fmt_row(width, row):\n    out = "" | "".join(fmt_item(x, width) for x in row)\n    return out\n\ndef flipkernel(kern):\n    return kern[(slice(None, None, -1),) * 2 + (slice(None), slice(None))]\n\ndef conv2d_flipkernel(x, k, name=None):\n    return tf.nn.conv2d(x, flipkernel(k), name=name,\n                        strides=(1, 1, 1, 1), padding=\'SAME\')'"
