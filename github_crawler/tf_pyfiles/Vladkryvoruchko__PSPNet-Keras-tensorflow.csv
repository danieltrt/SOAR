file_path,api_count,code
ade20k_labels.py,0,"b""#!/usr/bin/python\n#\n# ADE20k labels\n#\n\nfrom collections import namedtuple\nimport scipy.io\n\n\nLabel = namedtuple('Label', [\n\n    'name',\n    'id',\n    'color'\n])\n\nlabels = [Label('wall', 0, (120, 120, 120)),\n        Label('building', 1, (180, 120, 120)),\n        Label('sky', 2, (6, 230, 230)),\n        Label('floor', 3, (80, 50, 50)),\n        Label('tree', 4, (4, 200, 3)),\n        Label('ceiling', 5, (120, 120, 80)),\n        Label('road', 6, (140, 140, 140)),\n        Label('bed', 7, (204, 5, 255)),\n        Label('windowpane', 8, (230, 230, 230)),\n        Label('grass', 9, (4, 250, 7)),\n        Label('cabinet', 10, (224, 5, 255)),\n        Label('sidewalk', 11, (235, 255, 7)),\n        Label('person', 12, (150, 5, 61)),\n        Label('earth', 13, (120, 120, 70)),\n        Label('door', 14, (8, 255, 51)),\n        Label('table', 15, (255, 6, 82)),\n        Label('mountain', 16, (143, 255, 140)),\n        Label('plant', 17, (204, 255, 4)),\n        Label('curtain', 18, (255, 51, 7)),\n        Label('chair', 19, (204, 70, 3)),\n        Label('car', 20, (0, 102, 200)),\n        Label('water', 21, (61, 230, 250)),\n        Label('painting', 22, (255, 6, 51)),\n        Label('sofa', 23, (11, 102, 255)),\n        Label('shelf', 24, (255, 7, 71)),\n        Label('house', 25, (255, 9, 224)),\n        Label('sea', 26, (9, 7, 230)),\n        Label('mirror', 27, (220, 220, 220)),\n        Label('rug', 28, (255, 9, 92)),\n        Label('field', 29, (112, 9, 255)),\n        Label('armchair', 30, (8, 255, 214)),\n        Label('seat', 31, (7, 255, 224)),\n        Label('fence', 32, (255, 184, 6)),\n        Label('desk', 33, (10, 255, 71)),\n        Label('rock', 34, (255, 41, 10)),\n        Label('wardrobe', 35, (7, 255, 255)),\n        Label('lamp', 36, (224, 255, 8)),\n        Label('bathtub', 37, (102, 8, 255)),\n        Label('railing', 38, (255, 61, 6)),\n        Label('cushion', 39, (255, 194, 7)),\n        Label('base', 40, (255, 122, 8)),\n        Label('box', 41, (0, 255, 20)),\n        Label('column', 42, (255, 8, 41)),\n        Label('signboard', 43, (255, 5, 153)),\n        Label('chest of drawers', 44, (6, 51, 255)),\n        Label('counter', 45, (235, 12, 255)),\n        Label('sand', 46, (160, 150, 20)),\n        Label('sink', 47, (0, 163, 255)),\n        Label('skyscraper', 48, (140, 140, 140)),\n        Label('fireplace', 49, (250, 10, 15)),\n        Label('refrigerator', 50, (20, 255, 0)),\n        Label('grandstand', 51, (31, 255, 0)),\n        Label('path', 52, (255, 31, 0)),\n        Label('stairs', 53, (255, 224, 0)),\n        Label('runway', 54, (153, 255, 0)),\n        Label('case', 55, (0, 0, 255)),\n        Label('pool table', 56, (255, 71, 0)),\n        Label('pillow', 57, (0, 235, 255)),\n        Label('screen door', 58, (0, 173, 255)),\n        Label('stairway', 59, (31, 0, 255)),\n        Label('river', 60, (11, 200, 200)),\n        Label('bridge', 61, (255, 82, 0)),\n        Label('bookcase', 62, (0, 255, 245)),\n        Label('blind', 63, (0, 61, 255)),\n        Label('coffee table', 64, (0, 255, 112)),\n        Label('toilet', 65, (0, 255, 133)),\n        Label('flower', 66, (255, 0, 0)),\n        Label('book', 67, (255, 163, 0)),\n        Label('hill', 68, (255, 102, 0)),\n        Label('bench', 69, (194, 255, 0)),\n        Label('countertop', 70, (0, 143, 255)),\n        Label('stove', 71, (51, 255, 0)),\n        Label('palm', 72, (0, 82, 255)),\n        Label('kitchen island', 73, (0, 255, 41)),\n        Label('computer', 74, (0, 255, 173)),\n        Label('swivel chair', 75, (10, 0, 255)),\n        Label('boat', 76, (173, 255, 0)),\n        Label('bar', 77, (0, 255, 153)),\n        Label('arcade machine', 78, (255, 92, 0)),\n        Label('hovel', 79, (255, 0, 255)),\n        Label('bus', 80, (255, 0, 245)),\n        Label('towel', 81, (255, 0, 102)),\n        Label('light', 82, (255, 173, 0)),\n        Label('truck', 83, (255, 0, 20)),\n        Label('tower', 84, (255, 184, 184)),\n        Label('chandelier', 85, (0, 31, 255)),\n        Label('awning', 86, (0, 255, 61)),\n        Label('streetlight', 87, (0, 71, 255)),\n        Label('booth', 88, (255, 0, 204)),\n        Label('television receiver', 89, (0, 255, 194)),\n        Label('airplane', 90, (0, 255, 82)),\n        Label('dirt track', 91, (0, 10, 255)),\n        Label('apparel', 92, (0, 112, 255)),\n        Label('pole', 93, (51, 0, 255)),\n        Label('land', 94, (0, 194, 255)),\n        Label('bannister', 95, (0, 122, 255)),\n        Label('escalator', 96, (0, 255, 163)),\n        Label('ottoman', 97, (255, 153, 0)),\n        Label('bottle', 98, (0, 255, 10)),\n        Label('buffet', 99, (255, 112, 0)),\n        Label('poster', 100, (143, 255, 0)),\n        Label('stage', 101, (82, 0, 255)),\n        Label('van', 102, (163, 255, 0)),\n        Label('ship', 103, (255, 235, 0)),\n        Label('fountain', 104, (8, 184, 170)),\n        Label('conveyer belt', 105, (133, 0, 255)),\n        Label('canopy', 106, (0, 255, 92)),\n        Label('washer', 107, (184, 0, 255)),\n        Label('plaything', 108, (255, 0, 31)),\n        Label('swimming pool', 109, (0, 184, 255)),\n        Label('stool', 110, (0, 214, 255)),\n        Label('barrel', 111, (255, 0, 112)),\n        Label('basket', 112, (92, 255, 0)),\n        Label('waterfall', 113, (0, 224, 255)),\n        Label('tent', 114, (112, 224, 255)),\n        Label('bag', 115, (70, 184, 160)),\n        Label('minibike', 116, (163, 0, 255)),\n        Label('cradle', 117, (153, 0, 255)),\n        Label('oven', 118, (71, 255, 0)),\n        Label('ball', 119, (255, 0, 163)),\n        Label('food', 120, (255, 204, 0)),\n        Label('step', 121, (255, 0, 143)),\n        Label('tank', 122, (0, 255, 235)),\n        Label('trade name', 123, (133, 255, 0)),\n        Label('microwave', 124, (255, 0, 235)),\n        Label('pot', 125, (245, 0, 255)),\n        Label('animal', 126, (255, 0, 122)),\n        Label('bicycle', 127, (255, 245, 0)),\n        Label('lake', 128, (10, 190, 212)),\n        Label('dishwasher', 129, (214, 255, 0)),\n        Label('screen', 130, (0, 204, 255)),\n        Label('blanket', 131, (20, 0, 255)),\n        Label('sculpture', 132, (255, 255, 0)),\n        Label('hood', 133, (0, 153, 255)),\n        Label('sconce', 134, (0, 41, 255)),\n        Label('vase', 135, (0, 255, 204)),\n        Label('traffic light', 136, (41, 0, 255)),\n        Label('tray', 137, (41, 255, 0)),\n        Label('ashcan', 138, (173, 0, 255)),\n        Label('fan', 139, (0, 245, 255)),\n        Label('pier', 140, (71, 0, 255)),\n        Label('crt screen', 141, (122, 0, 255)),\n        Label('plate', 142, (0, 255, 184)),\n        Label('monitor', 143, (0, 92, 255)),\n        Label('bulletin board', 144, (184, 255, 0)),\n        Label('shower', 145, (0, 133, 255)),\n        Label('radiator', 146, (255, 214, 0)),\n        Label('glass', 147, (25, 194, 194)),\n        Label('clock', 148, (102, 255, 0)),\n        Label('flag', 149, (92, 0, 255))]\n\nade20k_id2label = {label.id: label for label in labels}\n"""
cityscapes_labels.py,0,"b'#!/usr/bin/python\n#\n# Cityscapes labels\n#\n\nfrom collections import namedtuple\n\n\n# --------------------------------------------------------------------------------\n# Definitions\n# --------------------------------------------------------------------------------\n\n# a label and all meta information\nLabel = namedtuple(\'Label\', [\n\n    \'name\',  # The identifier of this label, e.g. \'car\', \'person\', ... .\n    # We use them to uniquely name a class\n\n    \'id\',  # An integer ID that is associated with this label.\n    # The IDs are used to represent the label in ground truth images\n    # An ID of -1 means that this label does not have an ID and thus\n    # is ignored when creating ground truth images (e.g. license plate).\n    # Do not modify these IDs, since exactly these IDs are expected by the\n    # evaluation server.\n\n    \'trainId\',  # Feel free to modify these IDs as suitable for your method. Then create\n    # ground truth images with train IDs, using the tools provided in the\n    # \'preparation\' folder. However, make sure to validate or submit results\n    # to our evaluation server using the regular IDs above!\n    # For trainIds, multiple labels might have the same ID. Then, these labels\n    # are mapped to the same class in the ground truth images. For the inverse\n    # mapping, we use the label that is defined first in the list below.\n    # For example, mapping all void-type classes to the same ID in training,\n    # might make sense for some approaches.\n    # Max value is 255!\n\n    \'category\',  # The name of the category that this label belongs to\n\n    \'categoryId\',  # The ID of this category. Used to create ground truth images\n    # on category level.\n\n    \'hasInstances\',  # Whether this label distinguishes between single instances or not\n\n    \'ignoreInEval\',  # Whether pixels having this class as ground truth label are ignored\n    # during evaluations or not\n\n    \'color\',  # The color of this label\n])\n\n\n# --------------------------------------------------------------------------------\n# A list of all labels\n# --------------------------------------------------------------------------------\n\n# Please adapt the train IDs as appropriate for you approach.\n# Note that you might want to ignore labels with ID 255 during training.\n# Further note that the current train IDs are only a suggestion. You can use whatever you like.\n# Make sure to provide your results using the original IDs and not the training IDs.\n# Note that many IDs are ignored in evaluation and thus you never need to predict these!\n\nlabels = [\n    #     name                     id trainId  category     catId hasInstances ignoreInEval color\n    Label(\'unlabeled\',              0,  255,    \'void\',         0, False,       True,       (0,  0,  0)),\n    Label(\'ego vehicle\',            1,  255,    \'void\',         0, False,       True,       (0,  0,  0)),\n    Label(\'rectification border\',   2,  255,    \'void\',         0, False,       True,       (0,  0,  0)),\n    Label(\'out of roi\',             3,  255,    \'void\',         0, False,       True,       (0,  0,  0)),\n    Label(\'static\',                 4,  255,    \'void\',         0, False,       True,       (0,  0,  0)),\n    Label(\'dynamic\',                5,  255,    \'void\',         0, False,       True,       (111, 74,  0)),\n    Label(\'ground\',                 6,  255,    \'void\',         0, False,       True,       (81,  0, 81)),\n    Label(\'road\',                   7,  0,      \'flat\',         1, False,       False,      (128, 64, 128)),\n    Label(\'sidewalk\',               8,  1,      \'flat\',         1, False,       False,      (244, 35, 232)),\n    Label(\'parking\',                9,  255,    \'flat\',         1, False,       True,       (250, 170, 160)),\n    Label(\'rail track\',             10, 255,    \'flat\',         1, False,       True,       (230, 150, 140)),\n    Label(\'building\',               11, 2,      \'construction\', 2, False,       False,      (70, 70, 70)),\n    Label(\'wall\',                   12, 3,      \'construction\', 2, False,       False,      (102, 102, 156)),\n    Label(\'fence\',                  13, 4,      \'construction\', 2, False,       False,      (190, 153, 153)),\n    Label(\'guard rail\',             14, 255,    \'construction\', 2, False,       True,       (180, 165, 180)),\n    Label(\'bridge\',                 15, 255,    \'construction\', 2, False,       True,       (150, 100, 100)),\n    Label(\'tunnel\',                 16, 255,    \'construction\', 2, False,       True,       (150, 120, 90)),\n    Label(\'pole\',                   17, 5,      \'object\',       3, False,       False,      (153, 153, 153)),\n    Label(\'polegroup\',              18, 255,    \'object\',       3, False,       True,       (153, 153, 153)),\n    Label(\'traffic light\',          19, 6,      \'object\',       3, False,       False,      (250, 170, 30)),\n    Label(\'traffic sign\',           20, 7,      \'object\',       3, False,       False,      (220, 220,  0)),\n    Label(\'vegetation\',             21, 8,      \'nature\',       4, False,       False,      (107, 142, 35)),\n    Label(\'terrain\',                22, 9,      \'nature\',       4, False,       False,      (152, 251, 152)),\n    Label(\'sky\',                    23, 10,     \'sky\',          5, False,       False,      (70, 130, 180)),\n    Label(\'person\',                 24, 11,     \'human\',        6, True,        False,      (220, 20, 60)),\n    Label(\'rider\',                  25, 12,     \'human\',        6, True,        False,      (255,  0,  0)),\n    Label(\'car\',                    26, 13,     \'vehicle\',      7, True,        False,      (0,  0, 142)),\n    Label(\'truck\',                  27, 14,     \'vehicle\',      7, True,        False,      (0,  0, 70)),\n    Label(\'bus\',                    28, 15,     \'vehicle\',      7, True,        False,      (0, 60, 100)),\n    Label(\'caravan\',                29, 255,    \'vehicle\',      7, True,        True,       (0,  0, 90)),\n    Label(\'trailer\',                30, 255,    \'vehicle\',      7, True,        True,       (0,  0, 110)),\n    Label(\'train\',                  31, 16,     \'vehicle\',      7, True,        False,      (0, 80, 100)),\n    Label(\'motorcycle\',             32, 17,     \'vehicle\',      7, True,        False,      (0,  0, 230)),\n    Label(\'bicycle\',                33, 18,     \'vehicle\',      7, True,        False,      (119, 11, 32)),\n    Label(\'license plate\',          -1, -1,     \'vehicle\',      7, False,       True,       (0,  0, 142)),\n]\n\n\n# --------------------------------------------------------------------------------\n# Create dictionaries for a fast lookup\n# --------------------------------------------------------------------------------\n\n# Please refer to the main method below for example usages!\n\n# name to label object\nname2label = {label.name: label for label in labels}\n# id to label object\nid2label = {label.id: label for label in labels}\n# trainId to label object\ntrainId2label = {label.trainId: label for label in reversed(labels)}\n# category to list of label objects\ncategory2labels = {}\nfor label in labels:\n    category = label.category\n    if category in category2labels:\n        category2labels[category].append(label)\n    else:\n        category2labels[category] = [label]\n\n# --------------------------------------------------------------------------------\n# Assure single instance name\n# --------------------------------------------------------------------------------\n\n# returns the label name that describes a single instance (if possible)\n# e.g.     input     |   output\n#        ----------------------\n#          car       |   car\n#          cargroup  |   car\n#          foo       |   None\n#          foogroup  |   None\n#          skygroup  |   None\n\n\ndef assureSingleInstanceName(name):\n    # if the name is known, it is not a group\n    if name in name2label:\n        return name\n    # test if the name actually denotes a group\n    if not name.endswith(""group""):\n        return None\n    # remove group\n    name = name[:-len(""group"")]\n    # test if the new name exists\n    if name not in name2label:\n        return None\n    # test if the new name denotes a label that actually has instances\n    if not name2label[name].hasInstances:\n        return None\n    # all good then\n    return name\n'"
layers_builder.py,2,"b'from __future__ import print_function\nfrom math import ceil\nfrom keras import layers\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import BatchNormalization, Activation, Input, Dropout, ZeroPadding2D, Lambda\nfrom keras.layers.merge import Concatenate, Add\nfrom keras.models import Model\nfrom keras.optimizers import SGD\nfrom keras.backend import tf as ktf\n\nimport tensorflow as tf\n\nlearning_rate = 1e-3  # Layer specific learning rate\n# Weight decay not implemented\n\n\ndef BN(name=""""):\n    return BatchNormalization(momentum=0.95, name=name, epsilon=1e-5)\n\n\nclass Interp(layers.Layer):\n\n    def __init__(self, new_size, **kwargs):\n        self.new_size = new_size\n        super(Interp, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        super(Interp, self).build(input_shape)\n\n    def call(self, inputs, **kwargs):\n        new_height, new_width = self.new_size\n        resized = ktf.image.resize_images(inputs, [new_height, new_width],\n                                          align_corners=True)\n        return resized\n\n    def compute_output_shape(self, input_shape):\n        return tuple([None, self.new_size[0], self.new_size[1], input_shape[3]])\n\n    def get_config(self):\n        config = super(Interp, self).get_config()\n        config[\'new_size\'] = self.new_size\n        return config\n\n\n# def Interp(x, shape):\n#    new_height, new_width = shape\n#    resized = ktf.image.resize_images(x, [new_height, new_width],\n#                                      align_corners=True)\n#    return resized\n\n\ndef residual_conv(prev, level, pad=1, lvl=1, sub_lvl=1, modify_stride=False):\n    lvl = str(lvl)\n    sub_lvl = str(sub_lvl)\n    names = [""conv"" + lvl + ""_"" + sub_lvl + ""_1x1_reduce"",\n             ""conv"" + lvl + ""_"" + sub_lvl + ""_1x1_reduce_bn"",\n             ""conv"" + lvl + ""_"" + sub_lvl + ""_3x3"",\n             ""conv"" + lvl + ""_"" + sub_lvl + ""_3x3_bn"",\n             ""conv"" + lvl + ""_"" + sub_lvl + ""_1x1_increase"",\n             ""conv"" + lvl + ""_"" + sub_lvl + ""_1x1_increase_bn""]\n    if modify_stride is False:\n        prev = Conv2D(64 * level, (1, 1), strides=(1, 1), name=names[0],\n                      use_bias=False)(prev)\n    elif modify_stride is True:\n        prev = Conv2D(64 * level, (1, 1), strides=(2, 2), name=names[0],\n                      use_bias=False)(prev)\n\n    prev = BN(name=names[1])(prev)\n    prev = Activation(\'relu\')(prev)\n\n    prev = ZeroPadding2D(padding=(pad, pad))(prev)\n    prev = Conv2D(64 * level, (3, 3), strides=(1, 1), dilation_rate=pad,\n                  name=names[2], use_bias=False)(prev)\n\n    prev = BN(name=names[3])(prev)\n    prev = Activation(\'relu\')(prev)\n    prev = Conv2D(256 * level, (1, 1), strides=(1, 1), name=names[4],\n                  use_bias=False)(prev)\n    prev = BN(name=names[5])(prev)\n    return prev\n\n\ndef short_convolution_branch(prev, level, lvl=1, sub_lvl=1, modify_stride=False):\n    lvl = str(lvl)\n    sub_lvl = str(sub_lvl)\n    names = [""conv"" + lvl + ""_"" + sub_lvl + ""_1x1_proj"",\n             ""conv"" + lvl + ""_"" + sub_lvl + ""_1x1_proj_bn""]\n\n    if modify_stride is False:\n        prev = Conv2D(256 * level, (1, 1), strides=(1, 1), name=names[0],\n                      use_bias=False)(prev)\n    elif modify_stride is True:\n        prev = Conv2D(256 * level, (1, 1), strides=(2, 2), name=names[0],\n                      use_bias=False)(prev)\n\n    prev = BN(name=names[1])(prev)\n    return prev\n\n\ndef empty_branch(prev):\n    return prev\n\n\ndef residual_short(prev_layer, level, pad=1, lvl=1, sub_lvl=1, modify_stride=False):\n    prev_layer = Activation(\'relu\')(prev_layer)\n    block_1 = residual_conv(prev_layer, level,\n                            pad=pad, lvl=lvl, sub_lvl=sub_lvl,\n                            modify_stride=modify_stride)\n\n    block_2 = short_convolution_branch(prev_layer, level,\n                                       lvl=lvl, sub_lvl=sub_lvl,\n                                       modify_stride=modify_stride)\n    added = Add()([block_1, block_2])\n    return added\n\n\ndef residual_empty(prev_layer, level, pad=1, lvl=1, sub_lvl=1):\n    prev_layer = Activation(\'relu\')(prev_layer)\n\n    block_1 = residual_conv(prev_layer, level, pad=pad,\n                            lvl=lvl, sub_lvl=sub_lvl)\n    block_2 = empty_branch(prev_layer)\n    added = Add()([block_1, block_2])\n    return added\n\n\ndef ResNet(inp, layers):\n    # Names for the first couple layers of model\n    names = [""conv1_1_3x3_s2"",\n             ""conv1_1_3x3_s2_bn"",\n             ""conv1_2_3x3"",\n             ""conv1_2_3x3_bn"",\n             ""conv1_3_3x3"",\n             ""conv1_3_3x3_bn""]\n\n    # Short branch(only start of network)\n\n    cnv1 = Conv2D(64, (3, 3), strides=(2, 2), padding=\'same\', name=names[0],\n                  use_bias=False)(inp)  # ""conv1_1_3x3_s2""\n    bn1 = BN(name=names[1])(cnv1)  # ""conv1_1_3x3_s2/bn""\n    relu1 = Activation(\'relu\')(bn1)  # ""conv1_1_3x3_s2/relu""\n\n    cnv1 = Conv2D(64, (3, 3), strides=(1, 1), padding=\'same\', name=names[2],\n                  use_bias=False)(relu1)  # ""conv1_2_3x3""\n    bn1 = BN(name=names[3])(cnv1)  # ""conv1_2_3x3/bn""\n    relu1 = Activation(\'relu\')(bn1)  # ""conv1_2_3x3/relu""\n\n    cnv1 = Conv2D(128, (3, 3), strides=(1, 1), padding=\'same\', name=names[4],\n                  use_bias=False)(relu1)  # ""conv1_3_3x3""\n    bn1 = BN(name=names[5])(cnv1)  # ""conv1_3_3x3/bn""\n    relu1 = Activation(\'relu\')(bn1)  # ""conv1_3_3x3/relu""\n\n    res = MaxPooling2D(pool_size=(3, 3), padding=\'same\',\n                       strides=(2, 2))(relu1)  # ""pool1_3x3_s2""\n\n    # ---Residual layers(body of network)\n\n    """"""\n    Modify_stride --Used only once in first 3_1 convolutions block.\n    changes stride of first convolution from 1 -> 2\n    """"""\n\n    # 2_1- 2_3\n    res = residual_short(res, 1, pad=1, lvl=2, sub_lvl=1)\n    for i in range(2):\n        res = residual_empty(res, 1, pad=1, lvl=2, sub_lvl=i + 2)\n\n    # 3_1 - 3_3\n    res = residual_short(res, 2, pad=1, lvl=3, sub_lvl=1, modify_stride=True)\n    for i in range(3):\n        res = residual_empty(res, 2, pad=1, lvl=3, sub_lvl=i + 2)\n    if layers is 50:\n        # 4_1 - 4_6\n        res = residual_short(res, 4, pad=2, lvl=4, sub_lvl=1)\n        for i in range(5):\n            res = residual_empty(res, 4, pad=2, lvl=4, sub_lvl=i + 2)\n    elif layers is 101:\n        # 4_1 - 4_23\n        res = residual_short(res, 4, pad=2, lvl=4, sub_lvl=1)\n        for i in range(22):\n            res = residual_empty(res, 4, pad=2, lvl=4, sub_lvl=i + 2)\n    else:\n        print(""This ResNet is not implemented"")\n\n    # 5_1 - 5_3\n    res = residual_short(res, 8, pad=4, lvl=5, sub_lvl=1)\n    for i in range(2):\n        res = residual_empty(res, 8, pad=4, lvl=5, sub_lvl=i + 2)\n\n    res = Activation(\'relu\')(res)\n    return res\n\n\ndef interp_block(prev_layer, level, feature_map_shape, input_shape):\n    if input_shape == (473, 473):\n        kernel_strides_map = {1: 60,\n                              2: 30,\n                              3: 20,\n                              6: 10}\n    elif input_shape == (713, 713):\n        kernel_strides_map = {1: 90,\n                              2: 45,\n                              3: 30,\n                              6: 15}\n    else:\n        print(""Pooling parameters for input shape "",\n              input_shape, "" are not defined."")\n        exit(1)\n\n    names = [\n        ""conv5_3_pool"" + str(level) + ""_conv"",\n        ""conv5_3_pool"" + str(level) + ""_conv_bn""\n    ]\n    kernel = (kernel_strides_map[level], kernel_strides_map[level])\n    strides = (kernel_strides_map[level], kernel_strides_map[level])\n    prev_layer = AveragePooling2D(kernel, strides=strides)(prev_layer)\n    prev_layer = Conv2D(512, (1, 1), strides=(1, 1), name=names[0],\n                        use_bias=False)(prev_layer)\n    prev_layer = BN(name=names[1])(prev_layer)\n    prev_layer = Activation(\'relu\')(prev_layer)\n    # prev_layer = Lambda(Interp, arguments={\n    #                    \'shape\': feature_map_shape})(prev_layer)\n    prev_layer = Interp(feature_map_shape)(prev_layer)\n    return prev_layer\n\n\ndef build_pyramid_pooling_module(res, input_shape):\n    """"""Build the Pyramid Pooling Module.""""""\n    # ---PSPNet concat layers with Interpolation\n    feature_map_size = tuple(int(ceil(input_dim / 8.0))\n                             for input_dim in input_shape)\n    print(""PSP module will interpolate to a final feature map size of %s"" %\n          (feature_map_size, ))\n\n    interp_block1 = interp_block(res, 1, feature_map_size, input_shape)\n    interp_block2 = interp_block(res, 2, feature_map_size, input_shape)\n    interp_block3 = interp_block(res, 3, feature_map_size, input_shape)\n    interp_block6 = interp_block(res, 6, feature_map_size, input_shape)\n\n    # concat all these layers. resulted\n    # shape=(1,feature_map_size_x,feature_map_size_y,4096)\n    res = Concatenate()([res,\n                         interp_block6,\n                         interp_block3,\n                         interp_block2,\n                         interp_block1])\n    return res\n\n\ndef build_pspnet(nb_classes, resnet_layers, input_shape, activation=\'softmax\'):\n    """"""Build PSPNet.""""""\n    print(""Building a PSPNet based on ResNet %i expecting inputs of shape %s predicting %i classes"" % (\n        resnet_layers, input_shape, nb_classes))\n\n    inp = Input((input_shape[0], input_shape[1], 3))\n    res = ResNet(inp, layers=resnet_layers)\n    psp = build_pyramid_pooling_module(res, input_shape)\n\n    x = Conv2D(512, (3, 3), strides=(1, 1), padding=""same"", name=""conv5_4"",\n               use_bias=False)(psp)\n    x = BN(name=""conv5_4_bn"")(x)\n    x = Activation(\'relu\')(x)\n    x = Dropout(0.1)(x)\n\n    x = Conv2D(nb_classes, (1, 1), strides=(1, 1), name=""conv6"")(x)\n    # x = Lambda(Interp, arguments={\'shape\': (\n    #    input_shape[0], input_shape[1])})(x)\n    x = Interp([input_shape[0], input_shape[1]])(x)\n    x = Activation(\'softmax\')(x)\n\n    model = Model(inputs=inp, outputs=x)\n\n    # Solver\n    sgd = SGD(lr=learning_rate, momentum=0.9, nesterov=True)\n    model.compile(optimizer=sgd,\n                  loss=\'categorical_crossentropy\',\n                  metrics=[\'accuracy\'])\n    return model\n'"
pascal_voc_labels.py,0,"b'#!/usr/bin/python\n#\n# Pascal VOC labels\n#\n\nfrom collections import namedtuple\nimport numpy as np\n\nLabel = namedtuple(\'Label\', [\n\n    \'name\',\n    \'id\',\n    \'color\'\n])\n\nlabels = [Label(\'background\', 0, (0, 0, 0)),\n          Label(\'aeroplane\', 1, (128, 0, 0)),\n          Label(\'bicycle\', 2, (0, 128, 0)),\n          Label(\'bird\', 3, (128, 128, 0)),\n          Label(\'boat\', 4, (0, 0, 128)),\n          Label(\'bottle\', 5, (128, 0, 128)),\n          Label(\'bus\', 6, (0, 128, 128)),\n          Label(\'car\', 7, (128, 128, 128)),\n          Label(\'cat\', 8, (64, 0, 0)),\n          Label(\'chair\', 9, (192, 0, 0)),\n          Label(\'cow\', 10, (64, 128, 0)),\n          Label(\'diningtable\', 11, (192, 128, 0)),\n          Label(\'dog\', 12, (64, 0, 128)),\n          Label(\'horse\', 13, (192, 0, 128)),\n          Label(\'motorbike\', 14, (64, 128, 128)),\n          Label(\'person\', 15, (192, 128, 128)),\n          Label(\'pottedplant\', 16, (0, 64, 0)),\n          Label(\'sheep\', 17, (128, 64, 0)),\n          Label(\'sofa\', 18, (0, 192, 0)),\n          Label(\'train\', 19, (128, 192, 0)),\n          Label(\'tvmonitor\', 20, (0, 64, 128)),\n          Label(\'void\', 21, (128, 64, 12))]\n\nvoc_id2label = {label.id: label for label in labels}\n\n\ndef generate_color_map(N=256, normalized=False):\n    """"""from https://gist.github.com/wllhf/a4533e0adebe57e3ed06d4b50c8419ae .""""""\n    def bitget(byteval, idx):\n        return ((byteval & (1 << idx)) != 0)\n\n    dtype = \'float32\' if normalized else \'uint8\'\n    cmap = np.zeros((N, 3), dtype=dtype)\n    for i in range(N):\n        r = g = b = 0\n        c = i\n        for j in range(8):\n            r = r | (bitget(c, 0) << 7 - j)\n            g = g | (bitget(c, 1) << 7 - j)\n            b = b | (bitget(c, 2) << 7 - j)\n            c = c >> 3\n\n        cmap[i] = np.array([r, g, b])\n\n    cmap = cmap / 255 if normalized else cmap\n    return cmap\n\n\ndef generate_voc_labels():\n    labels = [\'background\', \'aeroplane\', \'bicycle\', \'bird\', \'boat\', \'bottle\', \'bus\', \'car\', \'cat\', \'chair\', \'cow\',\n              \'diningtable\', \'dog\', \'horse\', \'motorbike\', \'person\', \'pottedplant\', \'sheep\', \'sofa\', \'train\', \'tvmonitor\', \'void\']\n    color_map = generate_color_map()\n    for id, name in enumerate(labels):\n        color = color_map[id]\n        print(""Label(\\\'%s\\\', %i, (%i, %i, %i)),"" %\n              (name, id, color[0], color[1], color[2]))\n'"
pspnet-video.py,1,"b'#!/usr/bin/env python\n""""""\nThis module is a Keras/Tensorflow based implementation of Pyramid Scene Parsing Networks.\n\nOriginal paper & code published by Hengshuang Zhao et al. (2017)\n""""""\nfrom __future__ import print_function\nfrom __future__ import division\nfrom os.path import splitext, join, isfile\nfrom os import environ\nfrom math import ceil\nimport argparse\nimport numpy as np\nfrom scipy import misc, ndimage\nfrom keras import backend as K\nfrom keras.models import model_from_json\nimport tensorflow as tf\nimport layers_builder as layers\nfrom utils import utils\nimport matplotlib.pyplot as plt\nimport cv2\nimport datetime\nfrom tensorflow.python.client import device_lib\n\n__author__ = ""Vlad Kryvoruchko, Chaoyue Wang, Jeffrey Hu & Julian Tatsch""\n\n\n# These are the means for the ImageNet pretrained ResNet\nDATA_MEAN = np.array([[[123.68, 116.779, 103.939]]])  # RGB order\nEVALUATION_SCALES = [1.0]  # must be all floats!\n\n\ndef getGPUname():\n    local_device_protos = device_lib.list_local_devices()\n    l = [x.physical_device_desc for x in local_device_protos if x.device_type == \'GPU\']\n    s=\'\'\n    for t in l:\n        s+=t[t.find(""name: "")+len(""name: ""):t.find("", pci"")] + "" ""\n    return s\n\n\nGPU_NAME = getGPUname()\n\n\nclass PSPNet(object):\n    """"""Pyramid Scene Parsing Network by Hengshuang Zhao et al 2017.""""""\n\n    def __init__(self, nb_classes, resnet_layers, input_shape, weights):\n        """"""Instanciate a PSPNet.""""""\n        self.input_shape = input_shape\n        json_path = join(""weights"", ""keras"", weights + "".json"")\n        h5_path = join(""weights"", ""keras"", weights + "".h5"")\n        if isfile(json_path) and isfile(h5_path):\n            print(""Keras model & weights found, loading..."")\n            with open(json_path, \'r\') as file_handle:\n                self.model = model_from_json(file_handle.read())\n            self.model.load_weights(h5_path)\n        else:\n            print(""No Keras model & weights found, import from npy weights."")\n            self.model = layers.build_pspnet(nb_classes=nb_classes,\n                                             resnet_layers=resnet_layers,\n                                             input_shape=self.input_shape)\n            self.set_npy_weights(weights)\n\n    def predict(self, img, flip_evaluation):\n        """"""\n        Predict segementation for an image.\n\n        Arguments:\n            img: must be rowsxcolsx3\n        """"""\n        h_ori, w_ori = img.shape[:2]\n        if img.shape[0:2] != self.input_shape:\n            # print(""Input %s not fitting for network size %s, resizing. You may want to try sliding prediction for better results."" % (img.shape[0:2], self.input_shape))\n            img = misc.imresize(img, self.input_shape)\n        input_data = self.preprocess_image(img)\n        # utils.debug(self.model, input_data)\n\n        regular_prediction = self.model.predict(input_data)[0]\n        if flip_evaluation:\n            print(""Predict flipped"")\n            flipped_prediction = np.fliplr(self.model.predict(np.flip(input_data, axis=2))[0])\n            prediction = (regular_prediction + flipped_prediction) / 2.0\n        else:\n            prediction = regular_prediction\n\n        if img.shape[0:1] != self.input_shape:  # upscale prediction if necessary\n            h, w = prediction.shape[:2]\n            # prediction = ndimage.zoom(prediction, (1.*h_ori/h, 1.*w_ori/w, 1.), order=1, prefilter=False)\n            prediction = cv2.resize(prediction,(w_ori,h_ori))\n        return prediction\n\n    def preprocess_image(self, img):\n        """"""Preprocess an image as input.""""""\n        float_img = img.astype(\'float16\')\n        centered_image = float_img - DATA_MEAN\n        bgr_image = centered_image[:, :, ::-1]  # RGB => BGR\n        input_data = bgr_image[np.newaxis, :, :, :]  # Append sample dimension for keras\n        return input_data\n\n    def set_npy_weights(self, weights_path):\n        """"""Set weights from the intermediary npy file.""""""\n        npy_weights_path = join(""weights"", ""npy"", weights_path + "".npy"")\n        json_path = join(""weights"", ""keras"", weights_path + "".json"")\n        h5_path = join(""weights"", ""keras"", weights_path + "".h5"")\n\n        print(""Importing weights from %s"" % npy_weights_path)\n        weights = np.load(npy_weights_path, encoding=""latin1"").item()\n\n        whitelist = [""InputLayer"", ""Activation"", ""ZeroPadding2D"", ""Add"", ""MaxPooling2D"", ""AveragePooling2D"", ""Lambda"", ""Concatenate"", ""Dropout""]\n\n        weights_set = 0\n        for layer in self.model.layers:\n            print(""Processing %s"" % layer.name)\n            if layer.name[:4] == \'conv\' and layer.name[-2:] == \'bn\':\n                mean = weights[layer.name][\'mean\'].reshape(-1)\n                variance = weights[layer.name][\'variance\'].reshape(-1)\n                scale = weights[layer.name][\'scale\'].reshape(-1)\n                offset = weights[layer.name][\'offset\'].reshape(-1)\n\n                self.model.get_layer(layer.name).set_weights([mean, variance,\n                                                             scale, offset])\n                weights_set += 1\n            elif layer.name[:4] == \'conv\' and not layer.name[-4:] == \'relu\':\n                try:\n                    weight = weights[layer.name][\'weights\']\n                    self.model.get_layer(layer.name).set_weights([weight])\n                except Exception:\n                    biases = weights[layer.name][\'biases\']\n                    self.model.get_layer(layer.name).set_weights([weight,\n                                                                 biases])\n                weights_set += 1\n            elif layer.__class__.__name__ in whitelist:\n                # print(""Nothing to set in %s"" % layer.__class__.__name__)\n                pass\n            else:\n                print(""Warning: Did not find weights for keras layer %s in numpy weights"" % layer)\n\n        print(""Set a total of %i weights"" % weights_set)\n\n        print(\'Finished importing weights.\')\n\n        print(""Writing keras model & weights"")\n        json_string = self.model.to_json()\n        with open(json_path, \'w\') as file_handle:\n            file_handle.write(json_string)\n        self.model.save_weights(h5_path)\n        print(""Finished writing Keras model & weights"")\n\n\nclass PSPNet50(PSPNet):\n    """"""Build a PSPNet based on a 50-Layer ResNet.""""""\n\n    def __init__(self, nb_classes, weights, input_shape):\n        """"""Instanciate a PSPNet50.""""""\n        PSPNet.__init__(self, nb_classes=nb_classes, resnet_layers=50,\n                        input_shape=input_shape, weights=weights)\n\n\nclass PSPNet101(PSPNet):\n    """"""Build a PSPNet based on a 101-Layer ResNet.""""""\n\n    def __init__(self, nb_classes, weights, input_shape):\n        """"""Instanciate a PSPNet101.""""""\n        PSPNet.__init__(self, nb_classes=nb_classes, resnet_layers=101,\n                        input_shape=input_shape, weights=weights)\n\n\ndef pad_image(img, target_size):\n    """"""Pad an image up to the target size.""""""\n    rows_missing = target_size[0] - img.shape[0]\n    cols_missing = target_size[1] - img.shape[1]\n    padded_img = np.pad(img, ((0, rows_missing), (0, cols_missing), (0, 0)), \'constant\')\n    return padded_img\n\n\ndef visualize_prediction(prediction):\n    """"""Visualize prediction.""""""\n    cm = np.argmax(prediction, axis=2) + 1\n    color_cm = utils.add_color(cm)\n    plt.imshow(color_cm)\n    plt.show()\n\n\ndef predict_sliding(full_image, net, flip_evaluation):\n    """"""Predict on tiles of exactly the network input shape so nothing gets squeezed.""""""\n    tile_size = net.input_shape\n    classes = net.model.outputs[0].shape[3]\n    overlap = 1/3\n\n    stride = ceil(tile_size[0] * (1 - overlap))\n    tile_rows = int(ceil((full_image.shape[0] - tile_size[0]) / stride) + 1)  # strided convolution formula\n    tile_cols = int(ceil((full_image.shape[1] - tile_size[1]) / stride) + 1)\n    print(""Need %i x %i prediction tiles @ stride %i px"" % (tile_cols, tile_rows, stride))\n    full_probs = np.zeros((full_image.shape[0], full_image.shape[1], classes))\n    count_predictions = np.zeros((full_image.shape[0], full_image.shape[1], classes))\n    tile_counter = 0\n    for row in range(tile_rows):\n        for col in range(tile_cols):\n            x1 = int(col * stride)\n            y1 = int(row * stride)\n            x2 = min(x1 + tile_size[1], full_image.shape[1])\n            y2 = min(y1 + tile_size[0], full_image.shape[0])\n            x1 = max(int(x2 - tile_size[1]), 0)  # for portrait images the x1 underflows sometimes\n            y1 = max(int(y2 - tile_size[0]), 0)  # for very few rows y1 underflows\n\n            img = full_image[y1:y2, x1:x2]\n            padded_img = pad_image(img, tile_size)\n            # plt.imshow(padded_img)\n            # plt.show()\n            tile_counter += 1\n            print(""Predicting tile %i"" % tile_counter)\n            padded_prediction = net.predict(padded_img, flip_evaluation)\n            prediction = padded_prediction[0:img.shape[0], 0:img.shape[1], :]\n            count_predictions[y1:y2, x1:x2] += 1\n            full_probs[y1:y2, x1:x2] += prediction  # accumulate the predictions also in the overlapping regions\n\n    # average the predictions in the overlapping regions\n    full_probs /= count_predictions\n    # visualize normalization Weights\n    # plt.imshow(np.mean(count_predictions, axis=2))\n    # plt.show()\n    return full_probs\n\n\ndef predict_multi_scale(full_image, net, scales, sliding_evaluation, flip_evaluation):\n    """"""Predict an image by looking at it with different scales.""""""\n    classes = net.model.outputs[0].shape[3]\n    full_probs = np.zeros((full_image.shape[0], full_image.shape[1], classes))\n    h_ori, w_ori = full_image.shape[:2]\n    for scale in scales:\n        print(""Predicting image scaled by %f"" % scale)\n        scaled_img = misc.imresize(full_image, size=scale, interp=""bilinear"")\n        if sliding_evaluation:\n            scaled_probs = predict_sliding(scaled_img, net, flip_evaluation)\n        else:\n            scaled_probs = net.predict(scaled_img, flip_evaluation)\n        # scale probs up to full size\n        h, w = scaled_probs.shape[:2]\n        probs = ndimage.zoom(scaled_probs, (1.*h_ori/h, 1.*w_ori/w, 1.),order=1, prefilter=False)\n        # visualize_prediction(probs)\n        # integrate probs over all scales\n        full_probs += probs\n    full_probs /= len(scales)\n    return full_probs\n\n\ndef _predict(full_image, net, flip_evaluation):\n    classes = net.model.outputs[0].shape[3]\n    full_probs = np.zeros((full_image.shape[0], full_image.shape[1], classes))\n    h_ori, w_ori = full_image.shape[:2]\n    scaled_probs = net.predict(full_image, flip_evaluation)\n    # scale probs up to full size\n    h, w = scaled_probs.shape[:2]\n    probs = cv2.resize(scaled_probs,(w_ori,h_ori))\n    # visualize_prediction(probs)\n    # integrate probs over all scales\n    full_probs += probs\n    return full_probs\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-m\', \'--model\', type=str, default=\'pspnet50_ade20k\',\n                        help=\'Model/Weights to use\',\n                        choices=[\'pspnet50_ade20k\',\n                                 \'pspnet101_cityscapes\',\n                                 \'pspnet101_voc2012\'])\n    parser.add_argument(\'-i\', \'--input_path\', type=str, default=\'example_images/ade20k.jpg\',\n                        help=\'Path the input image\')\n    parser.add_argument(\'-o\', \'--output_path\', type=str, default=\'example_results/ade20k.jpg\',\n                        help=\'Path to output\')\n    parser.add_argument(\'--id\', default=""1"")\n    parser.add_argument(\'-s\', \'--sliding\', action=\'store_true\',\n                        help=""Whether the network should be slided over the original image for prediction."")\n    parser.add_argument(\'-f\', \'--flip\', action=\'store_true\',\n                        help=""Whether the network should predict on both image and flipped image."")\n    parser.add_argument(\'-ms\', \'--multi_scale\', action=\'store_true\',\n                        help=""Whether the network should predict on multiple scales."")\n    args = parser.parse_args()\n\n    # environ[""CUDA_VISIBLE_DEVICES""] = args.id\n\n    sess = tf.Session()\n    K.set_session(sess)\n\n    with sess.as_default():\n        cap = cv2.VideoCapture(args.input_path)\n        print(args)\n        counter = 0\n\n        if ""pspnet50"" in args.model:\n            pspnet = PSPNet50(nb_classes=150, input_shape=(473, 473),\n                              weights=args.model)\n        elif ""pspnet101"" in args.model:\n            if ""cityscapes"" in args.model:\n                pspnet = PSPNet101(nb_classes=19, input_shape=(713, 713),\n                                   weights=args.model)\n            if ""voc2012"" in args.model:\n                pspnet = PSPNet101(nb_classes=21, input_shape=(473, 473),\n                                   weights=args.model)\n\n        else:\n            print(""Network architecture not implemented."")\n\n        if args.multi_scale:\n            EVALUATION_SCALES = [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]  # must be all floats!\n            EVALUATION_SCALES = [0.15, 0.25, 0.5]  # must be all floats!\n\n        time_sum = 0\n        while(True):\n            # Capture frame-by-frame\n            ret, img = cap.read()\n            if img is None:\n                break\n\n\n            # img = cv2.resize(img,(int(16.0*713/9.0),713))\n            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n\n            start = datetime.datetime.now()\n            # class_scores = predict_multi_scale(img, pspnet, EVALUATION_SCALES, args.sliding, args.flip)\n            class_scores = _predict(img, pspnet, args.flip)\n\n            # End time\n            end = datetime.datetime.now()\n\n            # Time elapsed\n            diff = end - start\n\n            class_image = np.argmax(class_scores, axis=2)\n            pm = np.max(class_scores, axis=2)\n            colored_class_image = utils.color_class_image(class_image, args.model)\n\n            alpha_blended = 0.5 * colored_class_image + 0.5 * img\n            filename, ext = splitext(args.output_path)\n\n            time_sum += diff.microseconds/1000.0\n            print(counter,diff.microseconds/1000.0,\'ms\')\n\n\n            cv2.putText(alpha_blended,\'%s %s\'%(GPU_NAME,args.model),(100,100), cv2.FONT_HERSHEY_SIMPLEX, 3,(0,0,0),16,cv2.LINE_AA)\n            cv2.putText(alpha_blended,\'%s %s\'%(GPU_NAME,args.model),(100,100), cv2.FONT_HERSHEY_SIMPLEX, 3,(255,255,255),10,cv2.LINE_AA)\n\n            cv2.putText(alpha_blended,\'Prediction time: %.0fms (%.1f fps) AVG: %.0fms (%.1f fps)\'%(diff.microseconds/1000.0,1000000.0/diff.microseconds,time_sum/(counter+1),1000.0/(time_sum/(counter+1))),(100,200), cv2.FONT_HERSHEY_SIMPLEX, 3,(0,0,0),16,cv2.LINE_AA)\n            cv2.putText(alpha_blended,\'Prediction time: %.0fms (%.1f fps) AVG: %.0fms (%.1f fps)\'%(diff.microseconds/1000.0,1000000.0/diff.microseconds,time_sum/(counter+1),1000.0/(time_sum/(counter+1))),(100,200), cv2.FONT_HERSHEY_SIMPLEX, 3,(255,255,255),10,cv2.LINE_AA)\n\n            misc.imsave(filename + ""_%08d_seg""%counter + ext, colored_class_image)\n            misc.imsave(filename + ""_%08d_probs""%counter + ext, pm)\n            misc.imsave(filename + ""_%08d_seg_blended""%counter + ext, alpha_blended)\n            counter = counter + 1\n'"
pspnet.py,1,"b'#!/usr/bin/env python\nfrom __future__ import print_function\nimport os\nfrom os.path import splitext, join, isfile, isdir, basename\nimport argparse\nimport numpy as np\nfrom scipy import misc, ndimage\nfrom keras import backend as K\nfrom keras.models import model_from_json, load_model\nimport tensorflow as tf\nimport layers_builder as layers\nfrom glob import glob\nfrom utils import utils\nfrom keras.utils.generic_utils import CustomObjectScope\nimport cv2\nimport math\n# -- Fix for macos, uncomment it\n# import matplotlib\n# matplotlib.use(\'TkAgg\')\n# --\nimport matplotlib.pyplot as plt\n\n\nfrom imageio import imread\n# These are the means for the ImageNet pretrained ResNet\nDATA_MEAN = np.array([[[123.68, 116.779, 103.939]]])  # RGB order\n\n\nclass PSPNet(object):\n    """"""Pyramid Scene Parsing Network by Hengshuang Zhao et al 2017""""""\n\n    def __init__(self, nb_classes, resnet_layers, input_shape, weights):\n        self.input_shape = input_shape\n        self.num_classes = nb_classes\n\n        json_path = join(""weights"", ""keras"", weights + "".json"")\n        h5_path = join(""weights"", ""keras"", weights + "".h5"")\n        if \'pspnet\' in weights:\n            if os.path.isfile(json_path) and os.path.isfile(h5_path):\n                print(""Keras model & weights found, loading..."")\n                with CustomObjectScope({\'Interp\': layers.Interp}):\n                    with open(json_path) as file_handle:\n                        self.model = model_from_json(file_handle.read())\n                self.model.load_weights(h5_path)\n            else:\n                print(""No Keras model & weights found, import from npy weights."")\n                self.model = layers.build_pspnet(nb_classes=nb_classes,\n                                                 resnet_layers=resnet_layers,\n                                                 input_shape=self.input_shape)\n                self.set_npy_weights(weights)\n        else:\n            print(\'Load pre-trained weights\')\n            self.model = load_model(weights)\n\n    def predict(self, img, flip_evaluation=False):\n        """"""\n        Predict segementation for an image.\n        Arguments:\n            img: must be rowsxcolsx3\n        """"""\n\n        if img.shape[0:2] != self.input_shape:\n            print(\n                ""Input %s not fitting for network size %s, resizing. You may want to try sliding prediction for better results."" % (\n                img.shape[0:2], self.input_shape))\n            img = misc.imresize(img, self.input_shape)\n\n        img = img - DATA_MEAN\n        img = img[:, :, ::-1]  # RGB => BGR\n        img = img.astype(\'float32\')\n\n        probs = self.feed_forward(img, flip_evaluation)\n\n        return probs\n\n    def predict_sliding(self, full_img, flip_evaluation):\n        """"""\n        Predict on tiles of exactly the network input shape.\n        This way nothing gets squeezed.\n        """"""\n        tile_size = self.input_shape\n        classes = self.num_classes\n        overlap = 1 / 3\n\n        stride = math.ceil(tile_size[0] * (1 - overlap))\n        tile_rows = max(int(math.ceil((full_img.shape[0] - tile_size[0]) / stride) + 1), 1)  # strided convolution formula\n        tile_cols = max(int(math.ceil((full_img.shape[1] - tile_size[1]) / stride) + 1), 1)\n        print(""Need %i x %i prediction tiles @ stride %i px"" % (tile_cols, tile_rows, stride))\n        full_probs = np.zeros((full_img.shape[0], full_img.shape[1], classes))\n        count_predictions = np.zeros((full_img.shape[0], full_img.shape[1], classes))\n        tile_counter = 0\n        for row in range(tile_rows):\n            for col in range(tile_cols):\n                x1 = int(col * stride)\n                y1 = int(row * stride)\n                x2 = min(x1 + tile_size[1], full_img.shape[1])\n                y2 = min(y1 + tile_size[0], full_img.shape[0])\n                x1 = max(int(x2 - tile_size[1]), 0)  # for portrait images the x1 underflows sometimes\n                y1 = max(int(y2 - tile_size[0]), 0)  # for very few rows y1 underflows\n\n                img = full_img[y1:y2, x1:x2]\n                padded_img = self.pad_image(img, tile_size)\n                plt.imshow(padded_img)\n                plt.show()\n                tile_counter += 1\n                print(""Predicting tile %i"" % tile_counter)\n                padded_prediction = self.predict(padded_img, flip_evaluation)\n                prediction = padded_prediction[0:img.shape[0], 0:img.shape[1], :]\n                count_predictions[y1:y2, x1:x2] += 1\n                full_probs[y1:y2, x1:x2] += prediction  # accumulate the predictions also in the overlapping regions\n\n        # average the predictions in the overlapping regions\n        full_probs /= count_predictions\n        # visualize normalization Weights\n        # plt.imshow(np.mean(count_predictions, axis=2))\n        # plt.show()\n        return full_probs\n\n    @staticmethod\n    def pad_image(img, target_size):\n        """"""Pad an image up to the target size.""""""\n        rows_missing = target_size[0] - img.shape[0]\n        cols_missing = target_size[1] - img.shape[1]\n        padded_img = np.pad(img, ((0, rows_missing), (0, cols_missing), (0, 0)), \'constant\')\n        return padded_img\n\n    def predict_multi_scale(self, img, flip_evaluation, sliding_evaluation, scales):\n        """"""Predict an image by looking at it with different scales.""""""\n\n        full_probs = np.zeros((img.shape[0], img.shape[1], self.num_classes))\n        h_ori, w_ori = img.shape[:2]\n\n        print(""Started prediction..."")\n        for scale in scales:\n            print(""Predicting image scaled by %f"" % scale)\n            scaled_img = misc.imresize(img, size=scale, interp=""bilinear"")\n\n            if sliding_evaluation:\n                scaled_probs = self.predict_sliding(scaled_img, flip_evaluation)\n            else:\n                scaled_probs = self.predict(scaled_img, flip_evaluation)\n\n            # scale probs up to full size\n            # visualize_prediction(probs)\n            probs = cv2.resize(scaled_probs, (w_ori, h_ori))\n            full_probs += probs\n        full_probs /= len(scales)\n        print(""Finished prediction..."")\n\n        return full_probs\n\n    def feed_forward(self, data, flip_evaluation=False):\n        assert data.shape == (self.input_shape[0], self.input_shape[1], 3)\n\n        if flip_evaluation:\n            print(""Predict flipped"")\n            input_with_flipped = np.array(\n                [data, np.flip(data, axis=1)])\n            prediction_with_flipped = self.model.predict(input_with_flipped)\n            prediction = (prediction_with_flipped[\n                          0] + np.fliplr(prediction_with_flipped[1])) / 2.0\n        else:\n            prediction = self.model.predict(np.expand_dims(data, 0))[0]\n        return prediction\n\n    def set_npy_weights(self, weights_path):\n        npy_weights_path = join(""weights"", ""npy"", weights_path + "".npy"")\n        json_path = join(""weights"", ""keras"", weights_path + "".json"")\n        h5_path = join(""weights"", ""keras"", weights_path + "".h5"")\n\n        print(""Importing weights from %s"" % npy_weights_path)\n        weights = np.load(npy_weights_path, encoding=\'bytes\').item()\n        for layer in self.model.layers:\n            print(layer.name)\n            if layer.name[:4] == \'conv\' and layer.name[-2:] == \'bn\':\n                mean = weights[layer.name.encode()][\n                    \'mean\'.encode()].reshape(-1)\n                variance = weights[layer.name.encode()][\n                    \'variance\'.encode()].reshape(-1)\n                scale = weights[layer.name.encode()][\n                    \'scale\'.encode()].reshape(-1)\n                offset = weights[layer.name.encode()][\n                    \'offset\'.encode()].reshape(-1)\n\n                self.model.get_layer(layer.name).set_weights(\n                    [scale, offset, mean, variance])\n\n            elif layer.name[:4] == \'conv\' and not layer.name[-4:] == \'relu\':\n                try:\n                    weight = weights[layer.name.encode()][\'weights\'.encode()]\n                    self.model.get_layer(layer.name).set_weights([weight])\n                except Exception as err:\n                    biases = weights[layer.name.encode()][\'biases\'.encode()]\n                    self.model.get_layer(layer.name).set_weights([weight,\n                                                                  biases])\n        print(\'Finished importing weights.\')\n\n        print(""Writing keras model & weights"")\n        json_string = self.model.to_json()\n        with open(json_path, \'w\') as file_handle:\n            file_handle.write(json_string)\n        self.model.save_weights(h5_path)\n        print(""Finished writing Keras model & weights"")\n\n\nclass PSPNet50(PSPNet):\n    """"""Build a PSPNet based on a 50-Layer ResNet.""""""\n\n    def __init__(self, nb_classes, weights, input_shape):\n        PSPNet.__init__(self, nb_classes=nb_classes, resnet_layers=50,\n                        input_shape=input_shape, weights=weights)\n\n\nclass PSPNet101(PSPNet):\n    """"""Build a PSPNet based on a 101-Layer ResNet.""""""\n\n    def __init__(self, nb_classes, weights, input_shape):\n        PSPNet.__init__(self, nb_classes=nb_classes, resnet_layers=101,\n                        input_shape=input_shape, weights=weights)\n\n\ndef main(args):\n    # Handle input and output args\n    images = glob(args.glob_path) if args.glob_path else [args.input_path, ]\n    if args.glob_path:\n        fn, ext = splitext(args.output_path)\n        if ext:\n            parser.error(""output_path should be a folder for multiple file input"")\n        if not isdir(args.output_path):\n            os.mkdir(args.output_path)\n\n    # Predict\n    os.environ[""CUDA_VISIBLE_DEVICES""] = args.id\n\n    sess = tf.Session()\n    K.set_session(sess)\n\n    with sess.as_default():\n        print(args)\n        if not args.weights:\n            if ""pspnet50"" in args.model:\n                pspnet = PSPNet50(nb_classes=150, input_shape=(473, 473),\n                                  weights=args.model)\n            elif ""pspnet101"" in args.model:\n                if ""cityscapes"" in args.model:\n                    pspnet = PSPNet101(nb_classes=19, input_shape=(713, 713),\n                                       weights=args.model)\n                if ""voc2012"" in args.model:\n                    pspnet = PSPNet101(nb_classes=21, input_shape=(473, 473),\n                                       weights=args.model)\n\n            else:\n                print(""Network architecture not implemented."")\n        else:\n            pspnet = PSPNet50(nb_classes=2, input_shape=(\n                768, 480), weights=args.weights)\n\n        EVALUATION_SCALES = [1.0]\n        if args.multi_scale:\n            EVALUATION_SCALES = [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]  # must be all floats! Taken from original paper\n\n        for i, img_path in enumerate(images):\n            print(""Processing image {} / {}"".format(i + 1, len(images)))\n            img = imread(img_path, pilmode=\'RGB\')\n\n            probs = pspnet.predict_multi_scale(img, args.flip, args.sliding, EVALUATION_SCALES)\n\n            cm = np.argmax(probs, axis=2)\n            pm = np.max(probs, axis=2)\n\n            colored_class_image = utils.color_class_image(cm, args.model)\n            alpha_blended = 0.5 * colored_class_image + 0.5 * img\n\n            if args.glob_path:\n                input_filename, ext = splitext(basename(img_path))\n                filename = join(args.output_path, input_filename)\n            else:\n                filename, ext = splitext(args.output_path)\n\n            misc.imsave(filename + ""_seg_read"" + ext, cm)\n            misc.imsave(filename + ""_seg"" + ext, colored_class_image)\n            misc.imsave(filename + ""_probs"" + ext, pm)\n            misc.imsave(filename + ""_seg_blended"" + ext, alpha_blended)\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-m\', \'--model\', type=str, default=\'pspnet101_voc2012\',\n                        help=\'Model/Weights to use\',\n                        choices=[\'pspnet50_ade20k\',\n                                 \'pspnet101_cityscapes\',\n                                 \'pspnet101_voc2012\'])\n    parser.add_argument(\'-w\', \'--weights\', type=str, default=None)\n    parser.add_argument(\'-i\', \'--input_path\', type=str, default=\'example_images/ade20k.jpg\',\n                        help=\'Path the input image\')\n    parser.add_argument(\'-g\', \'--glob_path\', type=str, default=None,\n                        help=\'Glob path for multiple images\')\n    parser.add_argument(\'-o\', \'--output_path\', type=str, default=\'example_results/ade20k.jpg\',\n                        help=\'Path to output\')\n    parser.add_argument(\'--id\', default=""0"")\n    parser.add_argument(\'--input_size\', type=int, default=500)\n    parser.add_argument(\'-s\', \'--sliding\', action=\'store_true\',\n                        help=""Whether the network should be slided over the original image for prediction."")\n    parser.add_argument(\'-f\', \'--flip\', action=\'store_true\', default=True,\n                        help=""Whether the network should predict on both image and flipped image."")\n    parser.add_argument(\'-ms\', \'--multi_scale\', action=\'store_true\',\n                        help=""Whether the network should predict on multiple scales."")\n\n    args = parser.parse_args()\n\n    main(args)\n\n'"
train.py,0,"b'from os import path\nfrom os.path import join\nfrom scipy.misc import imresize\nfrom utils.preprocessing import data_generator_s31\nfrom utils.callbacks import callbacks\nfrom keras.models import load_model\nimport layers_builder as layers\nimport numpy as np\nimport argparse\nimport os\n\n\ndef set_npy_weights(weights_path, model):\n    npy_weights_path = join(""weights"", ""npy"", weights_path + "".npy"")\n    json_path = join(""weights"", ""keras"", weights_path + "".json"")\n    h5_path = join(""weights"", ""keras"", weights_path + "".h5"")\n\n    print(""Importing weights from %s"" % npy_weights_path)\n    weights = np.load(npy_weights_path).item()\n\n    for layer in model.layers:\n        print(layer.name)\n        if layer.name[:4] == \'conv\' and layer.name[-2:] == \'bn\':\n            mean = weights[layer.name][\'mean\'].reshape(-1)\n            variance = weights[layer.name][\'variance\'].reshape(-1)\n            scale = weights[layer.name][\'scale\'].reshape(-1)\n            offset = weights[layer.name][\'offset\'].reshape(-1)\n\n            self.model.get_layer(layer.name).set_weights(\n                [scale, offset, mean, variance])\n\n        elif layer.name[:4] == \'conv\' and not layer.name[-4:] == \'relu\':\n            try:\n                weight = weights[layer.name][\'weights\']\n                model.get_layer(layer.name).set_weights([weight])\n            except Exception as err:\n                try:\n                    biases = weights[layer.name][\'biases\']\n                    model.get_layer(layer.name).set_weights([weight,\n                                                             biases])\n                except Exception as err2:\n                    print(err2)\n\n        if layer.name == \'activation_52\':\n            break\n\n\ndef train(datadir, logdir, input_size, nb_classes, resnet_layers, batchsize, weights, initial_epoch, pre_trained, sep):\n    if args.weights:\n        model = load_model(weights)\n    else:\n        model = layers.build_pspnet(nb_classes=nb_classes,\n                                    resnet_layers=resnet_layers,\n                                    input_shape=input_size)\n        set_npy_weights(pre_trained, model)\n    dataset_len = len(os.listdir(os.path.join(datadir, \'imgs\')))\n    train_generator, val_generator = data_generator_s31(\n        datadir=datadir, batch_size=batchsize, input_size=input_size, nb_classes=nb_classes, separator=sep)\n    model.fit_generator(\n        generator=train_generator,\n        epochs=100000, verbose=True, steps_per_epoch=500,\n        callbacks=callbacks(logdir), initial_epoch=initial_epoch)\n\n\nclass PSPNet(object):\n    """"""Pyramid Scene Parsing Network by Hengshuang Zhao et al 2017""""""\n\n    def __init__(self, nb_classes, resnet_layers, input_shape):\n        self.input_shape = input_shape\n        self.model = layers.build_pspnet(nb_classes=nb_classes,\n                                         layers=resnet_layers,\n                                         input_shape=self.input_shape)\n        print(""Load pre-trained weights"")\n        self.model.load_weights(""weights/keras/pspnet101_voc2012.h5"")\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--input_dim\', type=int, default=473)\n    parser.add_argument(\'--classes\', type=int, default=2)\n    parser.add_argument(\'--resnet_layers\', type=int, default=50)\n    parser.add_argument(\'--batch\', type=int, default=2)\n    parser.add_argument(\'--datadir\', type=str, required=True)\n    parser.add_argument(\'--logdir\', type=str)\n    parser.add_argument(\'--weights\', type=str, default=None)\n    parser.add_argument(\'--initial_epoch\', type=int, default=0)\n    parser.add_argument(\'-m\', \'--model\', type=str, default=\'pspnet50_ade20k\',\n                        help=\'Model/Weights to use\',\n                        choices=[\'pspnet50_ade20k\',\n                                 \'pspnet101_cityscapes\',\n                                 \'pspnet101_voc2012\'])\n    parser.add_argument(\'--gpu\', type=int, default=0)\n    parser.add_argument(\'--sep\', default=\').\')\n    args = parser.parse_args()\n\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = str(args.gpu)\n\n    train(args.datadir, args.logdir, (640, 480), args.classes, args.resnet_layers,\n          args.batch, args.weights, args.initial_epoch, args.model, args.sep)\n'"
weight_converter.py,0,"b'#!/usr/bin/env python\n\nfrom __future__ import print_function\n\nimport sys\nfrom os.path import splitext\nimport numpy as np\n\nimport caffe\n\n# Not needed because Tensorflow and Caffe do convolution the same way\n# Needed for conversion to Theano\n\n\ndef rot90(W):\n    for i in range(W.shape[0]):\n        for j in range(W.shape[1]):\n            W[i, j] = np.rot90(W[i, j], 2)\n    return W\n\n\nweights = {}\nassert ""prototxt"" in splitext(\n    sys.argv[1])[1], ""First argument must be caffe prototxt %s"" % sys.argv[1]\nassert ""caffemodel"" in splitext(\n    sys.argv[2])[1], ""Second argument must be caffe weights %s"" % sys.argv[2]\nnet = caffe.Net(sys.argv[1], sys.argv[2], caffe.TEST)\nfor k, v in net.params.items():\n    print(""Layer %s, has %d params."" % (k, len(v)))\n    if len(v) == 1:\n        W = v[0].data[...]\n        W = np.transpose(W, (2, 3, 1, 0))\n        weights[k] = {""weights"": W}\n    elif len(v) == 2:\n        W = v[0].data[...]\n        W = np.transpose(W, (2, 3, 1, 0))\n        b = v[1].data[...]\n        weights[k] = {""weights"": W, ""biases"": b}\n    elif len(v) == 4:  # Batchnorm layer\n        k = k.replace(\'/\', \'_\')\n        scale = v[0].data[...]\n        offset = v[1].data[...]\n        mean = v[2].data[...]\n        variance = v[3].data[...]\n\n        weights[k] = {""mean"": mean, ""variance"": variance,\n                      ""scale"": scale, ""offset"": offset}\n\n    else:\n        print(""Undefined layer"")\n        exit()\n\narr = np.asarray(weights)\nweights_name = splitext(sys.argv[2])[0] + "".npy""\nnp.save(weights_name.lower(), arr)\n'"
caffe-tensorflow/convert.py,0,"b""#!/usr/bin/env python\n\nimport os\nimport sys\nimport numpy as np\nimport argparse\nfrom kaffe import KaffeError, print_stderr\nfrom kaffe.tensorflow import TensorFlowTransformer\n\n\ndef fatal_error(msg):\n    print_stderr(msg)\n    exit(-1)\n\n\ndef validate_arguments(args):\n    if (args.data_output_path is not None) and (args.caffemodel is None):\n        fatal_error('No input data path provided.')\n    if (args.caffemodel is not None) and (args.data_output_path is None):\n        fatal_error('No output data path provided.')\n    if (args.code_output_path is None) and (args.data_output_path is None):\n        fatal_error('No output path specified.')\n\n\ndef convert(def_path, caffemodel_path, data_output_path, code_output_path, phase):\n    try:\n        transformer = TensorFlowTransformer(def_path, caffemodel_path, phase=phase)\n        print_stderr('Converting data...')\n        if caffemodel_path is not None:\n            data = transformer.transform_data()\n            print_stderr('Saving data...')\n            with open(data_output_path, 'wb') as data_out:\n                np.save(data_out, data)\n        if code_output_path:\n            print_stderr('Saving source...')\n            with open(code_output_path, 'wb') as src_out:\n                src_out.write(transformer.transform_source())\n        print_stderr('Done.')\n    except KaffeError as err:\n        fatal_error('Error encountered: {}'.format(err))\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('def_path', help='Model definition (.prototxt) path')\n    parser.add_argument('--caffemodel', help='Model data (.caffemodel) path')\n    parser.add_argument('--data-output-path', help='Converted data output path')\n    parser.add_argument('--code-output-path', help='Save generated source to this path')\n    parser.add_argument('-p',\n                        '--phase',\n                        default='test',\n                        help='The phase to convert: test (default) or train')\n    args = parser.parse_args()\n    validate_arguments(args)\n    convert(args.def_path, args.caffemodel, args.data_output_path, args.code_output_path,\n            args.phase)\n\n\nif __name__ == '__main__':\n    main()\n"""
tests/conftest.py,0,"b""import argparse\n\nimport pytest\n\n\n@pytest.fixture\ndef cli_args_ade():\n    args = argparse.Namespace(flip=False, glob_path=None, id='0', input_path='tests/ade20k_test.jpg', input_size=500, model='pspnet50_ade20k', output_path='tests/ade20k_test.jpg', sliding=False, weights=None, multi_scale=False)\n    return args\n\n@pytest.fixture\ndef cli_args_cityscapes():\n    args = argparse.Namespace(flip=False, glob_path=None, id='0', input_path='tests/cityscapes_test.jpg', input_size=500, model='pspnet101_cityscapes', output_path='tests/cityscapes_test.jpg', sliding=False, weights=None, multi_scale=False)\n    return args\n\n@pytest.fixture\ndef cli_args_voc():\n    args = argparse.Namespace(flip=False, glob_path=None, id='0', input_path='tests/pascal_voc_test.jpg', input_size=500, model='pspnet101_voc2012', output_path='tests/pascal_voc_test.jpg', sliding=False, weights=None, multi_scale=False)\n    return args\n"""
tests/test_smoke.py,0,"b'import os\nimport pytest\n\nimport numpy as np\nfrom imageio import imread\n\n\ndef compare_2_images(validator_path, output_path):\n    val_abs_path = os.path.join(os.path.dirname(__file__), validator_path)\n    out_abs_path = os.path.join(os.path.dirname(__file__), output_path)\n    val_img = imread(val_abs_path, pilmode=\'RGB\')\n    out_img = imread(out_abs_path, pilmode=\'RGB\')\n    assert np.all(np.equal(val_img, out_img))\n\ndef clean_test_results(output_file_no_ext):\n    os.remove(""tests/"" + output_file_no_ext + ""_probs.jpg"")\n    os.remove(""tests/"" + output_file_no_ext + ""_seg.jpg"")\n    os.remove(""tests/"" + output_file_no_ext + ""_seg_blended.jpg"")\n    os.remove(""tests/"" + output_file_no_ext + ""_seg_read.jpg"")\n\ndef test_main_flip_ade20k(cli_args_ade):\n    from pspnet import main\n    main(cli_args_ade)\n    compare_2_images(""ade20k_test_probs.jpg"", ""validators/ade20k_test_probs.jpg"")\n    compare_2_images(""ade20k_test_seg.jpg"", ""validators/ade20k_test_seg.jpg"")\n    compare_2_images(""ade20k_test_seg_read.jpg"", ""validators/ade20k_test_seg_read.jpg"")\n    clean_test_results(""ade20k_test"")\n\n\n@pytest.mark.skip\ndef test_main_flip_cityscapes(cli_args_cityscapes):\n    """"""\n    TODO: Add images\n    :param cli_args_cityscapes:\n    :return:\n    """"""\n    from pspnet import main\n    main(cli_args_cityscapes)\n\n    compare_2_images(""cityscapes_test_probs.jpg"", ""validators/cityscapes_test_probs.jpg"")\n    compare_2_images(""cityscapes_test_seg.jpg"", ""validators/cityscapes_test_seg.jpg"")\n    compare_2_images(""cityscapes_test_seg_read.jpg"", ""validators/cityscapes_test_seg_read.jpg"")\n    clean_test_results(""cityscapes_test"")\n\n\n\n@pytest.mark.skip\ndef test_main_flip_voc(cli_args_voc):\n    """"""\n    TODO: Add images\n    :param cli_args_voc:\n    :return:\n    """"""\n    from pspnet import main\n    main(cli_args_voc)\n\n    compare_2_images(""pascal_voc_test_probs.jpg"", ""validators/pascal_voc_test_probs.jpg"")\n    compare_2_images(""pascal_voc_test_seg.jpg"", ""validators/pascal_voc_test_seg.jpg"")\n    compare_2_images(""pascal_voc_test_seg_read.jpg"", ""validators/pascal_voc_test_seg_read.jpg"")\n    clean_test_results(""pascal_voc_test"")'"
utils/__init__.py,0,b''
utils/callbacks.py,0,"b'import os\nimport time\nimport keras.backend as K\nfrom keras.callbacks import Callback, TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n\nclass LrReducer(Callback):\n  def __init__(self, base_lr = 0.01, max_epoch = 150, power=0.9, verbose=1):\n    super(Callback, self).__init__()\n    self.max_epoch = max_epoch\n    self.power = power\n    self.verbose = verbose\n    self.base_lr = base_lr\n\n  def on_epoch_end(self, epoch, logs={}):\n    lr_now = K.get_value(self.model.optimizer.lr)\n    new_lr = max(0.00001, min(self.base_lr * (1 - epoch / float(self.max_epoch))**self.power, lr_now))\n    K.set_value(self.model.optimizer.lr, new_lr)\n    if self.verbose:\n        print("" - learning rate: %10f"" % (new_lr))\n\ndef callbacks(logdir):\n  model_checkpoint = ModelCheckpoint(""weights_train/weights.{epoch:02d}-{loss:.2f}.h5"", monitor=\'loss\', verbose=1, period=10) \n  tensorboard_callback = TensorBoard(log_dir=logdir, write_graph=True, write_images=True, histogram_freq=1)\n  plateau_callback = ReduceLROnPlateau(monitor=\'loss\', factor=0.99, verbose=1, patience=0, min_lr=0.00001) \n  #return [CheckPoints(), tensorboard_callback, LrReducer()]\n  return [model_checkpoint, tensorboard_callback, plateau_callback, LrReducer()]\n'"
utils/preprocessing.py,0,"b'import os\nimport random\nimport numpy as np\nfrom scipy.misc import imresize, imread\nfrom scipy.ndimage import zoom\nfrom collections import defaultdict\n\nDATA_MEAN = np.array([[[123.68, 116.779, 103.939]]])\n\ndef preprocess_img(img, input_shape):\n    img = imresize(img, input_shape)\n    img = img - DATA_MEAN\n    img = img[:, :, ::-1]\n    img.astype(\'float32\')\n    return img\n\ndef update_inputs(batch_size = None, input_size = None, num_classes = None):\n  return np.zeros([batch_size, input_size[0], input_size[1], 3]), \\\n    np.zeros([batch_size, input_size[0], input_size[1], num_classes])\n\ndef data_generator_s31(datadir=\'\', nb_classes = None, batch_size = None, input_size=None, separator=\'_\', test_nmb=50):\n  if not os.path.exists(datadir):\n    print(""ERROR!The folder is not exist"")\n  #listdir = os.listdir(datadir)\n  data = defaultdict(dict)\n  image_dir = os.path.join(datadir, ""imgs"")\n  image_paths = os.listdir(image_dir)\n  for image_path in image_paths:\n    nmb = image_path.split(separator)[0]\n    data[nmb][\'image\'] = image_path\n  anno_dir = os.path.join(datadir, ""maps_bordered"")\n  anno_paths = os.listdir(anno_dir)\n  for anno_path in anno_paths:\n    nmb = anno_path.split(separator)[0]\n    data[nmb][\'anno\'] = anno_path\n  values = data.values()\n  random.shuffle(values)\n  return generate(values[test_nmb:], nb_classes, batch_size, input_size, image_dir, anno_dir), \\\n      generate(values[:test_nmb], nb_classes, batch_size, input_size, image_dir, anno_dir)\n\ndef generate(values, nb_classes, batch_size, input_size, image_dir, anno_dir):\n  while 1:\n    random.shuffle(values)\n    images, labels = update_inputs(batch_size=batch_size,\n       input_size=input_size, num_classes=nb_classes)\n    for i, d in enumerate(values):\n      img = imresize(imread(os.path.join(image_dir, d[\'image\']), mode=\'RGB\'), input_size)\n      y = imread(os.path.join(anno_dir, d[\'anno\']), mode=\'L\')\n      h, w = input_size\n      y = zoom(y, (1.*h/y.shape[0], 1.*w/y.shape[1]), order=1, prefilter=False)\n      y = (np.arange(nb_classes) == y[:,:,None]).astype(\'float32\')\n      assert y.shape[2] == nb_classes\n      images[i % batch_size] = img\n      labels[i % batch_size] = y\n      if (i + 1) % batch_size == 0:\n        yield images, labels\n        images, labels = update_inputs(batch_size=batch_size,\n          input_size=input_size, num_classes=nb_classes)\n\n\n\n'"
utils/utils.py,0,"b'from __future__ import print_function\nimport colorsys\nimport numpy as np\nfrom keras.models import Model\nfrom cityscapes_labels import trainId2label\nfrom ade20k_labels import ade20k_id2label\nfrom pascal_voc_labels import voc_id2label\n\n\ndef class_image_to_image(class_id_image, class_id_to_rgb_map):\n    """"""Map the class image to a rgb-color image.""""""\n    colored_image = np.zeros(\n        (class_id_image.shape[0], class_id_image.shape[1], 3), np.uint8)\n    for row in range(class_id_image.shape[0]):\n        for col in range(class_id_image.shape[1]):\n            try:\n                colored_image[row, col, :] = class_id_to_rgb_map[\n                    int(class_id_image[row, col])].color\n            except KeyError as key_error:\n                print(""Warning: could not resolve classid %s"" % key_error)\n    return colored_image\n\n\ndef color_class_image(class_image, model_name):\n    """"""Color classed depending on the model used.""""""\n    if \'cityscapes\' in model_name:\n        colored_image = class_image_to_image(class_image, trainId2label)\n    elif \'voc\' in model_name:\n        colored_image = class_image_to_image(class_image, voc_id2label)\n    elif \'ade20k\' in model_name:\n        colored_image = class_image_to_image(class_image, ade20k_id2label)\n    else:\n        colored_image = add_color(class_image)\n    return colored_image\n\n\ndef add_color(img, num_classes=32):\n    h, w = img.shape\n    img_color = np.zeros((h, w, 3))\n    for i in range(1, 151):\n        img_color[img == i] = to_color(i)\n    img_color[img == num_classes] = (1.0, 1.0, 1.0)\n    return img_color\n\n\ndef to_color(category):\n    """"""Map each category color a good distance away from each other on the HSV color space.""""""\n    v = (category - 1) * (137.5 / 360)\n    return colorsys.hsv_to_rgb(v, 1, 1)\n\n\ndef debug(model, data):\n    """"""Debug model by printing the activations in each layer.""""""\n    names = [layer.name for layer in model.layers]\n    for name in names[:]:\n        print_activation(model, name, data)\n\n\ndef print_activation(model, layer_name, data):\n    """"""Print the activations in each layer.""""""\n    intermediate_layer_model = Model(inputs=model.input,\n                                     outputs=model.get_layer(layer_name).output)\n    io = intermediate_layer_model.predict(data)\n    print(layer_name, array_to_str(io))\n\n\ndef array_to_str(a):\n    return ""{} {} {} {} {}"".format(a.dtype, a.shape, np.min(a),\n                                   np.max(a), np.mean(a))\n'"
caffe-tensorflow/kaffe/__init__.py,0,"b'from .graph import GraphBuilder, NodeMapper\nfrom .errors import KaffeError, print_stderr\n\nfrom . import tensorflow\n'"
caffe-tensorflow/kaffe/errors.py,0,"b""import sys\n\nclass KaffeError(Exception):\n    pass\n\ndef print_stderr(msg):\n    sys.stderr.write('%s\\n' % msg)\n"""
caffe-tensorflow/kaffe/graph.py,0,"b'from google.protobuf import text_format\n\nfrom .caffe import get_caffe_resolver\nfrom .errors import KaffeError, print_stderr\nfrom .layers import LayerAdapter, LayerType, NodeKind, NodeDispatch\nfrom .shapes import TensorShape\n\nclass Node(object):\n\n    def __init__(self, name, kind, layer=None):\n        self.name = name\n        self.kind = kind\n        self.layer = LayerAdapter(layer, kind) if layer else None\n        self.parents = []\n        self.children = []\n        self.data = None\n        self.output_shape = None\n        self.metadata = {}\n\n    def add_parent(self, parent_node):\n        assert parent_node not in self.parents\n        self.parents.append(parent_node)\n        if self not in parent_node.children:\n            parent_node.children.append(self)\n\n    def add_child(self, child_node):\n        assert child_node not in self.children\n        self.children.append(child_node)\n        if self not in child_node.parents:\n            child_node.parents.append(self)\n\n    def get_only_parent(self):\n        if len(self.parents) != 1:\n            raise KaffeError(\'Node (%s) expected to have 1 parent. Found %s.\' %\n                             (self, len(self.parents)))\n        return self.parents[0]\n\n    @property\n    def parameters(self):\n        if self.layer is not None:\n            return self.layer.parameters\n        return None\n\n    def __str__(self):\n        return \'[%s] %s\' % (self.kind, self.name)\n\n    def __repr__(self):\n        return \'%s (0x%x)\' % (self.name, id(self))\n\n\nclass Graph(object):\n\n    def __init__(self, nodes=None, name=None):\n        self.nodes = nodes or []\n        self.node_lut = {node.name: node for node in self.nodes}\n        self.name = name\n\n    def add_node(self, node):\n        self.nodes.append(node)\n        self.node_lut[node.name] = node\n\n    def get_node(self, name):\n        try:\n            return self.node_lut[name]\n        except KeyError:\n            raise KaffeError(\'Layer not found: %s\' % name)\n\n    def get_input_nodes(self):\n        return [node for node in self.nodes if len(node.parents) == 0]\n\n    def get_output_nodes(self):\n        return [node for node in self.nodes if len(node.children) == 0]\n\n    def topologically_sorted(self):\n        sorted_nodes = []\n        unsorted_nodes = list(self.nodes)\n        temp_marked = set()\n        perm_marked = set()\n\n        def visit(node):\n            if node in temp_marked:\n                raise KaffeError(\'Graph is not a DAG.\')\n            if node in perm_marked:\n                return\n            temp_marked.add(node)\n            for child in node.children:\n                visit(child)\n            perm_marked.add(node)\n            temp_marked.remove(node)\n            sorted_nodes.insert(0, node)\n\n        while len(unsorted_nodes):\n            visit(unsorted_nodes.pop())\n        return sorted_nodes\n\n    def compute_output_shapes(self):\n        sorted_nodes = self.topologically_sorted()\n        for node in sorted_nodes:\n            node.output_shape = TensorShape(*NodeKind.compute_output_shape(node))\n\n    def replaced(self, new_nodes):\n        return Graph(nodes=new_nodes, name=self.name)\n\n    def transformed(self, transformers):\n        graph = self\n        for transformer in transformers:\n            graph = transformer(graph)\n            if graph is None:\n                raise KaffeError(\'Transformer failed: {}\'.format(transformer))\n            assert isinstance(graph, Graph)\n        return graph\n\n    def __contains__(self, key):\n        return key in self.node_lut\n\n    def __str__(self):\n        hdr = \'{:<20} {:<30} {:>20} {:>20}\'.format(\'Type\', \'Name\', \'Param\', \'Output\')\n        s = [hdr, \'-\' * 94]\n        for node in self.topologically_sorted():\n            # If the node has learned parameters, display the first one\'s shape.\n            # In case of convolutions, this corresponds to the weights.\n            data_shape = node.data[0].shape if node.data else \'--\'\n            out_shape = node.output_shape or \'--\'\n            s.append(\'{:<20} {:<30} {:>20} {:>20}\'.format(node.kind, node.name, data_shape,\n                                                          tuple(out_shape)))\n        return \'\\n\'.join(s)\n\n\nclass GraphBuilder(object):\n    \'\'\'Constructs a model graph from a Caffe protocol buffer definition.\'\'\'\n\n    def __init__(self, def_path, phase=\'test\'):\n        \'\'\'\n        def_path: Path to the model definition (.prototxt)\n        data_path: Path to the model data (.caffemodel)\n        phase: Either \'test\' or \'train\'. Used for filtering phase-specific nodes.\n        \'\'\'\n        self.def_path = def_path\n        self.phase = phase\n        self.load()\n\n    def load(self):\n        \'\'\'Load the layer definitions from the prototxt.\'\'\'\n        self.params = get_caffe_resolver().NetParameter()\n        with open(self.def_path, \'rb\') as def_file:\n            text_format.Merge(def_file.read(), self.params)\n\n    def filter_layers(self, layers):\n        \'\'\'Filter out layers based on the current phase.\'\'\'\n        phase_map = {0: \'train\', 1: \'test\'}\n        filtered_layer_names = set()\n        filtered_layers = []\n        for layer in layers:\n            phase = self.phase\n            if len(layer.include):\n                phase = phase_map[layer.include[0].phase]\n            if len(layer.exclude):\n                phase = phase_map[1 - layer.include[0].phase]\n            exclude = (phase != self.phase)\n            # Dropout layers appear in a fair number of Caffe\n            # test-time networks. These are just ignored. We\'ll\n            # filter them out here.\n            if (not exclude) and (phase == \'test\'):\n                exclude = (layer.type == LayerType.Dropout)\n            if not exclude:\n                filtered_layers.append(layer)\n                # Guard against dupes.\n                assert layer.name not in filtered_layer_names\n                filtered_layer_names.add(layer.name)\n        return filtered_layers\n\n    def make_node(self, layer):\n        \'\'\'Create a graph node for the given layer.\'\'\'\n        kind = NodeKind.map_raw_kind(layer.type)\n        if kind is None:\n            raise KaffeError(\'Unknown layer type encountered: %s\' % layer.type)\n        # We want to use the layer\'s top names (the ""output"" names), rather than the\n        # name attribute, which is more of readability thing than a functional one.\n        # Other layers will refer to a node by its ""top name"".\n        return Node(layer.name, kind, layer=layer)\n\n    def make_input_nodes(self):\n        \'\'\'\n        Create data input nodes.\n\n        This method is for old-style inputs, where the input specification\n        was not treated as a first-class layer in the prototext.\n        Newer models use the ""Input layer"" type.\n        \'\'\'\n        nodes = [Node(name, NodeKind.Data) for name in self.params.input]\n        if len(nodes):\n            input_dim = map(int, self.params.input_dim)\n            if not input_dim:\n                if len(self.params.input_shape) > 0:\n                    input_dim = map(int, self.params.input_shape[0].dim)\n                else:\n                    raise KaffeError(\'Dimensions for input not specified.\')\n            for node in nodes:\n                node.output_shape = tuple(input_dim)\n        return nodes\n\n    def build(self):\n        \'\'\'\n        Builds the graph from the Caffe layer definitions.\n        \'\'\'\n        # Get the layers\n        layers = self.params.layers or self.params.layer\n        # Filter out phase-excluded layers\n        layers = self.filter_layers(layers)\n        # Get any separately-specified input layers\n        nodes = self.make_input_nodes()\n        nodes += [self.make_node(layer) for layer in layers]\n        # Initialize the graph\n        graph = Graph(nodes=nodes, name=self.params.name)\n        # Connect the nodes\n        #\n        # A note on layers and outputs:\n        # In Caffe, each layer can produce multiple outputs (""tops"") from a set of inputs\n        # (""bottoms""). The bottoms refer to other layers\' tops. The top can rewrite a bottom\n        # (in case of in-place operations). Note that the layer\'s name is not used for establishing\n        # any connectivity. It\'s only used for data association. By convention, a layer with a\n        # single top will often use the same name (although this is not required).\n        #\n        # The current implementation only supports single-output nodes (note that a node can still\n        # have multiple children, since multiple child nodes can refer to the single top\'s name).\n        node_outputs = {}\n        for layer in layers:\n            node = graph.get_node(layer.name)\n            for input_name in layer.bottom:\n                assert input_name != layer.name\n                parent_node = node_outputs.get(input_name)\n                if (parent_node is None) or (parent_node == node):\n                    parent_node = graph.get_node(input_name)\n                node.add_parent(parent_node)\n            if len(layer.top)>1:\n                raise KaffeError(\'Multiple top nodes are not supported.\')\n            for output_name in layer.top:\n                if output_name == layer.name:\n                    # Output is named the same as the node. No further action required.\n                    continue\n                # There are two possibilities here:\n                #\n                # Case 1: output_name refers to another node in the graph.\n                # This is an ""in-place operation"" that overwrites an existing node.\n                # This would create a cycle in the graph. We\'ll undo the in-placing\n                # by substituting this node wherever the overwritten node is referenced.\n                #\n                # Case 2: output_name violates the convention layer.name == output_name.\n                # Since we are working in the single-output regime, we will can rename it to\n                # match the layer name.\n                #\n                # For both cases, future references to this top re-routes to this node.\n                node_outputs[output_name] = node\n\n        graph.compute_output_shapes()\n        return graph\n\n\nclass NodeMapper(NodeDispatch):\n\n    def __init__(self, graph):\n        self.graph = graph\n\n    def map(self):\n        nodes = self.graph.topologically_sorted()\n        # Remove input nodes - we\'ll handle them separately.\n        input_nodes = self.graph.get_input_nodes()\n        nodes = [t for t in nodes if t not in input_nodes]\n        # Decompose DAG into chains.\n        chains = []\n        for node in nodes:\n            attach_to_chain = None\n            if len(node.parents) == 1:\n                parent = node.get_only_parent()\n                for chain in chains:\n                    if chain[-1] == parent:\n                        # Node is part of an existing chain.\n                        attach_to_chain = chain\n                        break\n            if attach_to_chain is None:\n                # Start a new chain for this node.\n                attach_to_chain = []\n                chains.append(attach_to_chain)\n            attach_to_chain.append(node)\n        # Map each chain.\n        mapped_chains = []\n        for chain in chains:\n            mapped_chains.append(self.map_chain(chain))\n        return self.commit(mapped_chains)\n\n    def map_chain(self, chain):\n        return [self.map_node(node) for node in chain]\n\n    def map_node(self, node):\n        map_func = self.get_handler(node.kind, \'map\')\n        mapped_node = map_func(node)\n        assert mapped_node is not None\n        mapped_node.node = node\n        return mapped_node\n\n    def commit(self, mapped_chains):\n        raise NotImplementedError(\'Must be implemented by subclass.\')\n'"
caffe-tensorflow/kaffe/layers.py,0,"b""import re\nimport numbers\nfrom collections import namedtuple\n\nfrom .shapes import *\n\nLAYER_DESCRIPTORS = {\n\n    # Caffe Types\n    'AbsVal': shape_identity,\n    'Accuracy': shape_scalar,\n    'ArgMax': shape_not_implemented,\n    'BatchNorm': shape_identity,\n    'BN': shape_identity,\n    'BNLL': shape_not_implemented,\n    'Concat': shape_concat,\n    'ContrastiveLoss': shape_scalar,\n    'Convolution': shape_convolution,\n    'Deconvolution': shape_not_implemented,\n    'Data': shape_data,\n    'Dropout': shape_identity,\n    'Interp': shape_identity,\n    'DummyData': shape_data,\n    'EuclideanLoss': shape_scalar,\n    'Eltwise': shape_identity,\n    'Exp': shape_identity,\n    'Flatten': shape_not_implemented,\n    'HDF5Datapython': shape_data,\n    'HDF5Output': shape_identity,\n    'HingeLoss': shape_scalar,\n    'Im2col': shape_not_implemented,\n    'ImageData': shape_data,\n    'InfogainLoss': shape_scalar,\n    'InnerProduct': shape_inner_product,\n    'Input': shape_data,\n    'LRN': shape_identity,\n    'MemoryData': shape_mem_data,\n    'MultinomialLogisticLoss': shape_scalar,\n    'MVN': shape_not_implemented,\n    'Pooling': shape_pool,\n    'Power': shape_identity,\n    'ReLU': shape_identity,\n    'Scale': shape_identity,\n    'Sigmoid': shape_identity,\n    'SigmoidCrossEntropyLoss': shape_scalar,\n    'Silence': shape_not_implemented,\n    'Softmax': shape_identity,\n    'SoftmaxWithLoss': shape_scalar,\n    'Split': shape_not_implemented,\n    'Slice': shape_not_implemented,\n    'TanH': shape_identity,\n    'WindowData': shape_not_implemented,\n    'Threshold': shape_identity,\n}\n\nLAYER_TYPES = LAYER_DESCRIPTORS.keys()\n\nLayerType = type('LayerType', (), {t: t for t in LAYER_TYPES})\n\nclass NodeKind(LayerType):\n\n    @staticmethod\n    def map_raw_kind(kind):\n        if kind in LAYER_TYPES:\n            return kind\n        return None\n\n    @staticmethod\n    def compute_output_shape(node):\n        try:\n            val = LAYER_DESCRIPTORS[node.kind](node)\n            return val\n        except NotImplementedError:\n            raise KaffeError('Output shape computation not implemented for type: %s' % node.kind)\n\n\nclass NodeDispatchError(KaffeError):\n\n    pass\n\n\nclass NodeDispatch(object):\n\n    @staticmethod\n    def get_handler_name(node_kind):\n        if len(node_kind) <= 4:\n            # A catch-all for things like ReLU and tanh\n            return node_kind.lower()\n        # Convert from CamelCase to under_scored\n        name = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', node_kind)\n        return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', name).lower()\n\n    def get_handler(self, node_kind, prefix):\n        name = self.get_handler_name(node_kind)\n        name = '_'.join((prefix, name))\n        try:\n            return getattr(self, name)\n        except AttributeError:\n            raise NodeDispatchError('No handler found for node kind: %s (expected: %s)' %\n                                    (node_kind, name))\n\n\nclass LayerAdapter(object):\n\n    def __init__(self, layer, kind):\n        self.layer = layer\n        self.kind = kind\n\n    @property\n    def parameters(self):\n        name = NodeDispatch.get_handler_name(self.kind)\n        name = '_'.join((name, 'param'))\n        try:\n            return getattr(self.layer, name)\n        except AttributeError:\n            raise NodeDispatchError('Caffe parameters not found for layer kind: %s' % (self.kind))\n\n    @staticmethod\n    def get_kernel_value(scalar, repeated, idx, default=None):\n        if scalar:\n            return scalar\n        if repeated:\n            if isinstance(repeated, numbers.Number):\n                return repeated\n            if len(repeated) == 1:\n                # Same value applies to all spatial dimensions\n                return int(repeated[0])\n            assert idx < len(repeated)\n            # Extract the value for the given spatial dimension\n            return repeated[idx]\n        if default is None:\n            raise ValueError('Unable to determine kernel parameter!')\n        return default\n\n    @property\n    def kernel_parameters(self):\n        assert self.kind in (NodeKind.Convolution, NodeKind.Pooling)\n        params = self.parameters\n        k_h = self.get_kernel_value(params.kernel_h, params.kernel_size, 0)\n        k_w = self.get_kernel_value(params.kernel_w, params.kernel_size, 1)\n        s_h = self.get_kernel_value(params.stride_h, params.stride, 0, default=1)\n        s_w = self.get_kernel_value(params.stride_w, params.stride, 1, default=1)\n        p_h = self.get_kernel_value(params.pad_h, params.pad, 0, default=0)\n        p_w = self.get_kernel_value(params.pad_h, params.pad, 1, default=0)\n        return KernelParameters(k_h, k_w, s_h, s_w, p_h, p_w)\n\n\nKernelParameters = namedtuple('KernelParameters', ['kernel_h', 'kernel_w', 'stride_h', 'stride_w',\n                                                   'pad_h', 'pad_w'])\n"""
caffe-tensorflow/kaffe/shapes.py,0,"b'import math\nfrom collections import namedtuple\n\nfrom .errors import KaffeError\n\nTensorShape = namedtuple(\'TensorShape\', [\'batch_size\', \'channels\', \'height\', \'width\'])\n\n\ndef get_filter_output_shape(i_h, i_w, params, round_func):\n    o_h = (i_h + 2 * params.pad_h - params.kernel_h) / float(params.stride_h) + 1\n    o_w = (i_w + 2 * params.pad_w - params.kernel_w) / float(params.stride_w) + 1\n    return (int(round_func(o_h)), int(round_func(o_w)))\n\n\ndef get_strided_kernel_output_shape(node, round_func):\n    assert node.layer is not None\n    input_shape = node.get_only_parent().output_shape\n    o_h, o_w = get_filter_output_shape(input_shape.height, input_shape.width,\n                                       node.layer.kernel_parameters, round_func)\n    params = node.layer.parameters\n    has_c_o = hasattr(params, \'num_output\')\n    c = params.num_output if has_c_o else input_shape.channels\n    return TensorShape(input_shape.batch_size, c, o_h, o_w)\n\n\ndef shape_not_implemented(node):\n    raise NotImplementedError\n\n\ndef shape_identity(node):\n    assert len(node.parents) > 0\n    return node.parents[0].output_shape\n\n\ndef shape_scalar(node):\n    return TensorShape(1, 1, 1, 1)\n\n\ndef shape_data(node):\n    if node.output_shape:\n        # Old-style input specification\n        return node.output_shape\n    try:\n        # New-style input specification\n        return map(int, node.parameters.shape[0].dim)\n    except:\n        # We most likely have a data layer on our hands. The problem is,\n        # Caffe infers the dimensions of the data from the source (eg: LMDB).\n        # We want to avoid reading datasets here. Fail for now.\n        # This can be temporarily fixed by transforming the data layer to\n        # Caffe\'s ""input"" layer (as is usually used in the ""deploy"" version).\n        # TODO: Find a better solution for this.\n        raise KaffeError(\'Cannot determine dimensions of data layer.\\n\'\n                         \'See comments in function shape_data for more info.\')\n\n\ndef shape_mem_data(node):\n    params = node.parameters\n    return TensorShape(params.batch_size, params.channels, params.height, params.width)\n\n\ndef shape_concat(node):\n    axis = node.layer.parameters.axis\n    output_shape = None\n    for parent in node.parents:\n        if output_shape is None:\n            output_shape = list(parent.output_shape)\n        else:\n            output_shape[axis] += parent.output_shape[axis]\n    return tuple(output_shape)\n\n\ndef shape_convolution(node):\n    return get_strided_kernel_output_shape(node, math.floor)\n\n\ndef shape_pool(node):\n    return get_strided_kernel_output_shape(node, math.ceil)\n\n\ndef shape_inner_product(node):\n    input_shape = node.get_only_parent().output_shape\n    return TensorShape(input_shape.batch_size, node.layer.parameters.num_output, 1, 1)\n'"
caffe-tensorflow/kaffe/transformers.py,0,"b""'''\nA collection of graph transforms.\n\nA transformer is a callable that accepts a graph and returns a transformed version.\n'''\n\nimport numpy as np\n\nfrom .caffe import get_caffe_resolver, has_pycaffe\nfrom .errors import KaffeError, print_stderr\nfrom .layers import NodeKind\n\n\nclass DataInjector(object):\n    '''\n    Associates parameters loaded from a .caffemodel file with their corresponding nodes.\n    '''\n\n    def __init__(self, def_path, data_path):\n        # The .prototxt file defining the graph\n        self.def_path = def_path\n        # The .caffemodel file containing the learned parameters\n        self.data_path = data_path\n        # Set to true if the fallback protocol-buffer based backend was used\n        self.did_use_pb = False\n        # A list containing (layer name, parameters) tuples\n        self.params = None\n        # Load the parameters\n        self.load()\n\n    def load(self):\n        if has_pycaffe():\n            self.load_using_caffe()\n        else:\n            self.load_using_pb()\n\n    def load_using_caffe(self):\n        caffe = get_caffe_resolver().caffe\n        net = caffe.Net(self.def_path, self.data_path, caffe.TEST)\n        data = lambda blob: blob.data\n        self.params = [(k, map(data, v)) for k, v in net.params.items()]\n\n    def load_using_pb(self):\n        data = get_caffe_resolver().NetParameter()\n        data.MergeFromString(open(self.data_path, 'rb').read())\n        pair = lambda layer: (layer.name, self.normalize_pb_data(layer))\n        layers = data.layers or data.layer\n        self.params = [pair(layer) for layer in layers if layer.blobs]\n        self.did_use_pb = True\n\n    def normalize_pb_data(self, layer):\n        transformed = []\n        for blob in layer.blobs:\n            if len(blob.shape.dim):\n                dims = blob.shape.dim\n                c_o, c_i, h, w = map(int, [1] * (4 - len(dims)) + list(dims))\n            else:\n                c_o = blob.num\n                c_i = blob.channels\n                h = blob.height\n                w = blob.width\n            data = np.array(blob.data, dtype=np.float32).reshape(c_o, c_i, h, w)\n            transformed.append(data)\n        return transformed\n\n    def adjust_parameters(self, node, data):\n        if not self.did_use_pb:\n            return data\n        # When using the protobuf-backend, each parameter initially has four dimensions.\n        # In certain cases (like FC layers), we want to eliminate the singleton dimensions.\n        # This implementation takes care of the common cases. However, it does leave the\n        # potential for future issues.\n        # The Caffe-backend does not suffer from this problem.\n        data = list(data)\n        squeeze_indices = [1]  # Squeeze biases.\n        if node.kind == NodeKind.InnerProduct:\n            squeeze_indices.append(0)  # Squeeze FC.\n        for idx in squeeze_indices:\n            data[idx] = np.squeeze(data[idx])\n        return data\n\n    def __call__(self, graph):\n        for layer_name, data in self.params:\n            if layer_name in graph:\n                node = graph.get_node(layer_name)\n                node.data = self.adjust_parameters(node, data)\n            else:\n                print_stderr('Ignoring parameters for non-existent layer: %s' % layer_name)\n        return graph\n\n\nclass DataReshaper(object):\n\n    def __init__(self, mapping, replace=True):\n        # A dictionary mapping NodeKind to the transposed order.\n        self.mapping = mapping\n        # The node kinds eligible for reshaping\n        self.reshaped_node_types = self.mapping.keys()\n        # If true, the reshaped data will replace the old one.\n        # Otherwise, it's set to the reshaped_data attribute.\n        self.replace = replace\n\n    def has_spatial_parent(self, node):\n        try:\n            parent = node.get_only_parent()\n            s = parent.output_shape\n            return s.height > 1 or s.width > 1\n        except KaffeError:\n            return False\n\n    def map(self, node_kind):\n        try:\n            return self.mapping[node_kind]\n        except KeyError:\n            raise KaffeError('Ordering not found for node kind: {}'.format(node_kind))\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.data is None:\n                continue\n            if node.kind not in self.reshaped_node_types:\n\n                # Check for 2+ dimensional data\n                if any(len(tensor.shape) > 1 for tensor in node.data):\n                    print_stderr('Warning: parmaters not reshaped for node: {}'.format(node))\n                continue\n            transpose_order = self.map(node.kind)\n            weights = node.data[0]\n            if (node.kind == NodeKind.InnerProduct) and self.has_spatial_parent(node):\n                # The FC layer connected to the spatial layer needs to be\n                # re-wired to match the new spatial ordering.\n                in_shape = node.get_only_parent().output_shape\n                fc_shape = weights.shape\n                output_channels = fc_shape[0]\n                weights = weights.reshape((output_channels, in_shape.channels, in_shape.height,\n                                           in_shape.width))\n                weights = weights.transpose(self.map(NodeKind.Convolution))\n                node.reshaped_data = weights.reshape(fc_shape[transpose_order[0]],\n                                                     fc_shape[transpose_order[1]])\n            else:\n                node.reshaped_data = weights.transpose(transpose_order)\n\n        if self.replace:\n            for node in graph.nodes:\n                if hasattr(node, 'reshaped_data'):\n                    # Set the weights\n                    node.data[0] = node.reshaped_data\n                    del node.reshaped_data\n        return graph\n\n\nclass SubNodeFuser(object):\n    '''\n    An abstract helper for merging a single-child with its single-parent.\n    '''\n\n    def __call__(self, graph):\n        nodes = graph.nodes\n        print graph.name\n        fused_nodes = []\n        for node in nodes:\n            if len(node.parents) != 1:\n                # We're only fusing nodes with single parents\n                continue\n            parent = node.get_only_parent()\n            if len(parent.children) != 1:\n                # We can only fuse a node if its parent's\n                # value isn't used by any other node.\n                continue\n            if not self.is_eligible_pair(parent, node):\n                continue\n            # Rewrite the fused node's children to its parent.\n            for child in node.children:\n                child.parents.remove(node)\n                parent.add_child(child)\n            # Disconnect the fused node from the graph.\n            parent.children.remove(node)\n            fused_nodes.append(node)\n            # Let the sub-class merge the fused node in any arbitrary way.\n            self.merge(parent, node)\n        transformed_nodes = [node for node in nodes if node not in fused_nodes]\n        return graph.replaced(transformed_nodes)\n\n    def is_eligible_pair(self, parent, child):\n        '''Returns true if this parent/child pair is eligible for fusion.'''\n        raise NotImplementedError('Must be implemented by subclass.')\n\n    def merge(self, parent, child):\n        '''Merge the child node into the parent.'''\n        raise NotImplementedError('Must be implemented by subclass')\n\n\nclass ReLUFuser(SubNodeFuser):\n    '''\n    Fuses rectified linear units with their parent nodes.\n    '''\n\n    def __init__(self, allowed_parent_types=None):\n        # Fuse ReLUs when the parent node is one of the given types.\n        # If None, all node types are eligible.\n        self.allowed_parent_types = allowed_parent_types\n\n    def is_eligible_pair(self, parent, child):\n        return ((self.allowed_parent_types is None or parent.kind in self.allowed_parent_types) and\n                child.kind == NodeKind.ReLU)\n\n    def merge(self, parent, _):\n        parent.metadata['relu'] = True\n\n\nclass BatchNormScaleBiasFuser(SubNodeFuser):\n    '''\n    The original batch normalization paper includes two learned\n    parameters: a scaling factor \\gamma and a bias \\beta.\n    Caffe's implementation does not include these two. However, it is commonly\n    replicated by adding a scaling+bias layer immidiately after the batch norm.\n\n    This fuser merges the scaling+bias layer with the batch norm.\n    '''\n\n    def is_eligible_pair_(self, parent, child):\n        return (parent.kind == NodeKind.BatchNorm and child.kind == NodeKind.Scale and\n                child.parameters.axis == 1 and child.parameters.bias_term == True)\n\n    '''\n    Made for the purpose of \n    '''\n    def is_eligible_pair(self, parent, child):\n        if parent.kind == NodeKind.BatchNorm: \n            print 'kaffe/transformers.py  line 227: use function above'\n        return (parent.kind == NodeKind.BN and child.kind == NodeKind.Scale and\n                child.parameters.axis == 1 and child.parameters.bias_term == True)\n\n    def merge(self, parent, child):\n\n        parent.scale_bias_node = child\n\n\nclass BatchNormPreprocessor(object):\n    '''\n    Prescale batch normalization parameters.\n    Concatenate gamma (scale) and beta (bias) terms if set.\n    '''\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.kind not in (NodeKind.BatchNorm, NodeKind.BN):\n                continue\n            else:\n                continue\n            assert node.data is not None\n            print len(node.data)\n            print node\n            assert len(node.data) == 3\n\n            mean, variance, scale = node.data\n            # Prescale the stats\n            scaling_factor = 1.0 / scale if scale != 0 else 0\n            mean *= scaling_factor\n            variance *= scaling_factor\n            # Replace with the updated values\n            node.data = [mean, variance]\n            if hasattr(node, 'scale_bias_node'):\n                # Include the scale and bias terms\n                gamma, beta = node.scale_bias_node.data\n                node.data += [gamma, beta]\n        return graph\n\n\nclass NodeRenamer(object):\n    '''\n    Renames nodes in the graph using a given unary function that\n    accepts a node and returns its new name.\n    '''\n\n    def __init__(self, renamer):\n        self.renamer = renamer\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            node.name = self.renamer(node)\n        return graph\n\n\nclass ParameterNamer(object):\n    '''\n    Convert layer data arrays to a dictionary mapping parameter names to their values.\n    '''\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.data is None:\n                continue\n            if node.kind in (NodeKind.Convolution, NodeKind.InnerProduct):\n                names = ('weights',)\n                if node.parameters.bias_term:\n                    names += ('biases',)\n            elif node.kind in (NodeKind.BatchNorm, NodeKind.BN):\n                names = ('mean', 'variance')\n                if len(node.data) == 4:\n\n                    names += ('scale', 'offset')\n            else:\n                print_stderr('WARNING: Unhandled parameters: {}'.format(node.kind))\n                continue\n            assert len(names) == len(node.data)\n            node.data = dict(zip(names, node.data))\n        return graph\n"""
caffe-tensorflow/examples/imagenet/classify.py,3,"b""#!/usr/bin/env python\nimport argparse\nimport numpy as np\nimport tensorflow as tf\nimport os.path as osp\n\nimport models\nimport dataset\n\n\ndef display_results(image_paths, probs):\n    '''Displays the classification results given the class probability for each image'''\n    # Get a list of ImageNet class labels\n    with open('imagenet-classes.txt', 'rb') as infile:\n        class_labels = map(str.strip, infile.readlines())\n    # Pick the class with the highest confidence for each image\n    class_indices = np.argmax(probs, axis=1)\n    # Display the results\n    print('\\n{:20} {:30} {}'.format('Image', 'Classified As', 'Confidence'))\n    print('-' * 70)\n    for img_idx, image_path in enumerate(image_paths):\n        img_name = osp.basename(image_path)\n        class_name = class_labels[class_indices[img_idx]]\n        confidence = round(probs[img_idx, class_indices[img_idx]] * 100, 2)\n        print('{:20} {:30} {} %'.format(img_name, class_name, confidence))\n\n\ndef classify(model_data_path, image_paths):\n    '''Classify the given images using GoogleNet.'''\n\n    # Get the data specifications for the GoogleNet model\n    spec = models.get_data_spec(model_class=models.GoogleNet)\n\n    # Create a placeholder for the input image\n    input_node = tf.placeholder(tf.float32,\n                                shape=(None, spec.crop_size, spec.crop_size, spec.channels))\n\n    # Construct the network\n    net = models.GoogleNet({'data': input_node})\n\n    # Create an image producer (loads and processes images in parallel)\n    image_producer = dataset.ImageProducer(image_paths=image_paths, data_spec=spec)\n\n    with tf.Session() as sesh:\n        # Start the image processing workers\n        coordinator = tf.train.Coordinator()\n        threads = image_producer.start(session=sesh, coordinator=coordinator)\n\n        # Load the converted parameters\n        print('Loading the model')\n        net.load(model_data_path, sesh)\n\n        # Load the input image\n        print('Loading the images')\n        indices, input_images = image_producer.get(sesh)\n\n        # Perform a forward pass through the network to get the class probabilities\n        print('Classifying')\n        probs = sesh.run(net.get_output(), feed_dict={input_node: input_images})\n        display_results([image_paths[i] for i in indices], probs)\n\n        # Stop the worker threads\n        coordinator.request_stop()\n        coordinator.join(threads, stop_grace_period_secs=2)\n\ndef main():\n    # Parse arguments\n    parser = argparse.ArgumentParser()\n    parser.add_argument('model_path', help='Converted parameters for the GoogleNet model')\n    parser.add_argument('image_paths', nargs='+', help='One or more images to classify')\n    args = parser.parse_args()\n\n    # Classify the image\n    classify(args.model_path, args.image_paths)\n\n\nif __name__ == '__main__':\n    main()\n"""
caffe-tensorflow/examples/imagenet/dataset.py,18,"b""'''Utility functions and classes for handling image datasets.'''\n\nimport os.path as osp\nimport numpy as np\nimport tensorflow as tf\n\n\ndef process_image(img, scale, isotropic, crop, mean):\n    '''Crops, scales, and normalizes the given image.\n    scale : The image wil be first scaled to this size.\n            If isotropic is true, the smaller side is rescaled to this,\n            preserving the aspect ratio.\n    crop  : After scaling, a central crop of this size is taken.\n    mean  : Subtracted from the image\n    '''\n    # Rescale\n    if isotropic:\n        img_shape = tf.to_float(tf.shape(img)[:2])\n        min_length = tf.minimum(img_shape[0], img_shape[1])\n        new_shape = tf.to_int32((scale / min_length) * img_shape)\n    else:\n        new_shape = tf.pack([scale, scale])\n    img = tf.image.resize_images(img, new_shape[0], new_shape[1])\n    # Center crop\n    # Use the slice workaround until crop_to_bounding_box supports deferred tensor shapes\n    # See: https://github.com/tensorflow/tensorflow/issues/521\n    offset = (new_shape - crop) / 2\n    img = tf.slice(img, begin=tf.pack([offset[0], offset[1], 0]), size=tf.pack([crop, crop, -1]))\n    # Mean subtraction\n    return tf.to_float(img) - mean\n\n\nclass ImageProducer(object):\n    '''\n    Loads and processes batches of images in parallel.\n    '''\n\n    def __init__(self, image_paths, data_spec, num_concurrent=4, batch_size=None, labels=None):\n        # The data specifications describe how to process the image\n        self.data_spec = data_spec\n        # A list of full image paths\n        self.image_paths = image_paths\n        # An optional list of labels corresponding to each image path\n        self.labels = labels\n        # A boolean flag per image indicating whether its a JPEG or PNG\n        self.extension_mask = self.create_extension_mask(self.image_paths)\n        # Create the loading and processing operations\n        self.setup(batch_size=batch_size, num_concurrent=num_concurrent)\n\n    def setup(self, batch_size, num_concurrent):\n        # Validate the batch size\n        num_images = len(self.image_paths)\n        batch_size = min(num_images, batch_size or self.data_spec.batch_size)\n        if num_images % batch_size != 0:\n            raise ValueError(\n                'The total number of images ({}) must be divisible by the batch size ({}).'.format(\n                    num_images, batch_size))\n        self.num_batches = num_images / batch_size\n\n        # Create a queue that will contain image paths (and their indices and extension indicator)\n        self.path_queue = tf.FIFOQueue(capacity=num_images,\n                                       dtypes=[tf.int32, tf.bool, tf.string],\n                                       name='path_queue')\n\n        # Enqueue all image paths, along with their indices\n        indices = tf.range(num_images)\n        self.enqueue_paths_op = self.path_queue.enqueue_many([indices, self.extension_mask,\n                                                              self.image_paths])\n        # Close the path queue (no more additions)\n        self.close_path_queue_op = self.path_queue.close()\n\n        # Create an operation that dequeues a single path and returns a processed image\n        (idx, processed_image) = self.process()\n\n        # Create a queue that will contain the processed images (and their indices)\n        image_shape = (self.data_spec.crop_size, self.data_spec.crop_size, self.data_spec.channels)\n        processed_queue = tf.FIFOQueue(capacity=int(np.ceil(num_images / float(num_concurrent))),\n                                       dtypes=[tf.int32, tf.float32],\n                                       shapes=[(), image_shape],\n                                       name='processed_queue')\n\n        # Enqueue the processed image and path\n        enqueue_processed_op = processed_queue.enqueue([idx, processed_image])\n\n        # Create a dequeue op that fetches a batch of processed images off the queue\n        self.dequeue_op = processed_queue.dequeue_many(batch_size)\n\n        # Create a queue runner to perform the processing operations in parallel\n        num_concurrent = min(num_concurrent, num_images)\n        self.queue_runner = tf.train.QueueRunner(processed_queue,\n                                                 [enqueue_processed_op] * num_concurrent)\n\n    def start(self, session, coordinator, num_concurrent=4):\n        '''Start the processing worker threads.'''\n        # Queue all paths\n        session.run(self.enqueue_paths_op)\n        # Close the path queue\n        session.run(self.close_path_queue_op)\n        # Start the queue runner and return the created threads\n        return self.queue_runner.create_threads(session, coord=coordinator, start=True)\n\n    def get(self, session):\n        '''\n        Get a single batch of images along with their indices. If a set of labels were provided,\n        the corresponding labels are returned instead of the indices.\n        '''\n        (indices, images) = session.run(self.dequeue_op)\n        if self.labels is not None:\n            labels = [self.labels[idx] for idx in indices]\n            return (labels, images)\n        return (indices, images)\n\n    def batches(self, session):\n        '''Yield a batch until no more images are left.'''\n        for _ in xrange(self.num_batches):\n            yield self.get(session=session)\n\n    def load_image(self, image_path, is_jpeg):\n        # Read the file\n        file_data = tf.read_file(image_path)\n        # Decode the image data\n        img = tf.cond(\n            is_jpeg,\n            lambda: tf.image.decode_jpeg(file_data, channels=self.data_spec.channels),\n            lambda: tf.image.decode_png(file_data, channels=self.data_spec.channels))\n        if self.data_spec.expects_bgr:\n            # Convert from RGB channel ordering to BGR\n            # This matches, for instance, how OpenCV orders the channels.\n            img = tf.reverse(img, [False, False, True])\n        return img\n\n    def process(self):\n        # Dequeue a single image path\n        idx, is_jpeg, image_path = self.path_queue.dequeue()\n        # Load the image\n        img = self.load_image(image_path, is_jpeg)\n        # Process the image\n        processed_img = process_image(img=img,\n                                      scale=self.data_spec.scale_size,\n                                      isotropic=self.data_spec.isotropic,\n                                      crop=self.data_spec.crop_size,\n                                      mean=self.data_spec.mean)\n        # Return the processed image, along with its index\n        return (idx, processed_img)\n\n    @staticmethod\n    def create_extension_mask(paths):\n\n        def is_jpeg(path):\n            extension = osp.splitext(path)[-1].lower()\n            if extension in ('.jpg', '.jpeg'):\n                return True\n            if extension != '.png':\n                raise ValueError('Unsupported image format: {}'.format(extension))\n            return False\n\n        return [is_jpeg(p) for p in paths]\n\n    def __len__(self):\n        return len(self.image_paths)\n\n\nclass ImageNetProducer(ImageProducer):\n\n    def __init__(self, val_path, data_path, data_spec):\n        # Read in the ground truth labels for the validation set\n        # The get_ilsvrc_aux.sh in Caffe's data/ilsvrc12 folder can fetch a copy of val.txt\n        gt_lines = open(val_path).readlines()\n        gt_pairs = [line.split() for line in gt_lines]\n        # Get the full image paths\n        # You will need a copy of the ImageNet validation set for this.\n        image_paths = [osp.join(data_path, p[0]) for p in gt_pairs]\n        # The corresponding ground truth labels\n        labels = np.array([int(p[1]) for p in gt_pairs])\n        # Initialize base\n        super(ImageNetProducer, self).__init__(image_paths=image_paths,\n                                               data_spec=data_spec,\n                                               labels=labels)\n"""
caffe-tensorflow/examples/imagenet/validate.py,5,"b""#!/usr/bin/env python\n'''Validates a converted ImageNet model against the ILSVRC12 validation set.'''\n\nimport argparse\nimport numpy as np\nimport tensorflow as tf\nimport os.path as osp\n\nimport models\nimport dataset\n\n\ndef load_model(name):\n    '''Creates and returns an instance of the model given its class name.\n    The created model has a single placeholder node for feeding images.\n    '''\n    # Find the model class from its name\n    all_models = models.get_models()\n    lut = {model.__name__: model for model in all_models}\n    if name not in lut:\n        print('Invalid model index. Options are:')\n        # Display a list of valid model names\n        for model in all_models:\n            print('\\t* {}'.format(model.__name__))\n        return None\n    NetClass = lut[name]\n\n    # Create a placeholder for the input image\n    spec = models.get_data_spec(model_class=NetClass)\n    data_node = tf.placeholder(tf.float32,\n                               shape=(None, spec.crop_size, spec.crop_size, spec.channels))\n\n    # Construct and return the model\n    return NetClass({'data': data_node})\n\n\ndef validate(net, model_path, image_producer, top_k=5):\n    '''Compute the top_k classification accuracy for the given network and images.'''\n    # Get the data specifications for given network\n    spec = models.get_data_spec(model_instance=net)\n    # Get the input node for feeding in the images\n    input_node = net.inputs['data']\n    # Create a placeholder for the ground truth labels\n    label_node = tf.placeholder(tf.int32)\n    # Get the output of the network (class probabilities)\n    probs = net.get_output()\n    # Create a top_k accuracy node\n    top_k_op = tf.nn.in_top_k(probs, label_node, top_k)\n    # The number of images processed\n    count = 0\n    # The number of correctly classified images\n    correct = 0\n    # The total number of images\n    total = len(image_producer)\n\n    with tf.Session() as sesh:\n        coordinator = tf.train.Coordinator()\n        # Load the converted parameters\n        net.load(data_path=model_path, session=sesh)\n        # Start the image processing workers\n        threads = image_producer.start(session=sesh, coordinator=coordinator)\n        # Iterate over and classify mini-batches\n        for (labels, images) in image_producer.batches(sesh):\n            correct += np.sum(sesh.run(top_k_op,\n                                       feed_dict={input_node: images,\n                                                  label_node: labels}))\n            count += len(labels)\n            cur_accuracy = float(correct) * 100 / count\n            print('{:>6}/{:<6} {:>6.2f}%'.format(count, total, cur_accuracy))\n        # Stop the worker threads\n        coordinator.request_stop()\n        coordinator.join(threads, stop_grace_period_secs=2)\n    print('Top {} Accuracy: {}'.format(top_k, float(correct) / total))\n\n\n\ndef main():\n    # Parse arguments\n    parser = argparse.ArgumentParser()\n    parser.add_argument('model_path', help='Path to the converted model parameters (.npy)')\n    parser.add_argument('val_gt', help='Path to validation set ground truth (.txt)')\n    parser.add_argument('imagenet_data_dir', help='ImageNet validation set images directory path')\n    parser.add_argument('--model', default='GoogleNet', help='The name of the model to evaluate')\n    args = parser.parse_args()\n\n    # Load the network\n    net = load_model(args.model)\n    if net is None:\n        exit(-1)\n\n    # Load the dataset\n    data_spec = models.get_data_spec(model_instance=net)\n    image_producer = dataset.ImageNetProducer(val_path=args.val_gt,\n                                              data_path=args.imagenet_data_dir,\n                                              data_spec=data_spec)\n\n    # Evaluate its performance on the ILSVRC12 validation set\n    validate(net, args.model_path, image_producer)\n\n\nif __name__ == '__main__':\n    main()\n"""
caffe-tensorflow/examples/mnist/finetune_mnist.py,7,"b""# Import the converted model's class\nimport numpy as np\nimport random\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nfrom mynet import LeNet as MyNet\n\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\nbatch_size = 32\n\ndef gen_data(source):\n    while True:\n        indices = range(len(source.images))\n        random.shuffle(indices)\n        for i in indices:\n            image = np.reshape(source.images[i], (28, 28, 1))\n            label = source.labels[i]\n            yield image, label\n\ndef gen_data_batch(source):\n    data_gen = gen_data(source)\n    while True:\n        image_batch = []\n        label_batch = []\n        for _ in range(batch_size):\n            image, label = next(data_gen)\n            image_batch.append(image)\n            label_batch.append(label)\n        yield np.array(image_batch), np.array(label_batch)\n\n\nimages = tf.placeholder(tf.float32, [batch_size, 28, 28, 1])\nlabels = tf.placeholder(tf.float32, [batch_size, 10])\nnet = MyNet({'data': images})\n\nip2 = net.layers['ip2']\npred = tf.nn.softmax(ip2)\n\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(ip2, labels), 0)\nopt = tf.train.RMSPropOptimizer(0.001)\ntrain_op = opt.minimize(loss)\n\nwith tf.Session() as sess:\n    # Load the data\n    sess.run(tf.initialize_all_variables())\n    net.load('mynet.npy', sess)\n\n    data_gen = gen_data_batch(mnist.train)\n    for i in range(1000):\n        np_images, np_labels = next(data_gen)\n        feed = {images: np_images, labels: np_labels}\n\n        np_loss, np_pred, _ = sess.run([loss, pred, train_op], feed_dict=feed)\n        if i % 10 == 0:\n            print('Iteration: ', i, np_loss)\n"""
caffe-tensorflow/kaffe/caffe/__init__.py,0,"b'from .resolver import get_caffe_resolver, has_pycaffe\n'"
caffe-tensorflow/kaffe/caffe/caffepb.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: caffe.proto\n\nfrom google.protobuf.internal import enum_type_wrapper\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import descriptor_pb2\n# @@protoc_insertion_point(imports)\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'caffe.proto\',\n  package=\'caffe\',\n  serialized_pb=\'\\n\\x0b\\x63\\x61\\x66\\x66\\x65.proto\\x12\\x05\\x63\\x61\\x66\\x66\\x65\\""\\x1c\\n\\tBlobShape\\x12\\x0f\\n\\x03\\x64im\\x18\\x01 \\x03(\\x03\\x42\\x02\\x10\\x01\\""\\xcc\\x01\\n\\tBlobProto\\x12\\x1f\\n\\x05shape\\x18\\x07 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x10\\n\\x04\\x64\\x61ta\\x18\\x05 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x10\\n\\x04\\x64iff\\x18\\x06 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_data\\x18\\x08 \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_diff\\x18\\t \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x0e\\n\\x03num\\x18\\x01 \\x01(\\x05:\\x01\\x30\\x12\\x13\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x11\\n\\x06height\\x18\\x03 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05width\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""2\\n\\x0f\\x42lobProtoVector\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\""\\x81\\x01\\n\\x05\\x44\\x61tum\\x12\\x10\\n\\x08\\x63hannels\\x18\\x01 \\x01(\\x05\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\x05\\x12\\r\\n\\x05width\\x18\\x03 \\x01(\\x05\\x12\\x0c\\n\\x04\\x64\\x61ta\\x18\\x04 \\x01(\\x0c\\x12\\r\\n\\x05label\\x18\\x05 \\x01(\\x05\\x12\\x12\\n\\nfloat_data\\x18\\x06 \\x03(\\x02\\x12\\x16\\n\\x07\\x65ncoded\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\x8a\\x02\\n\\x0f\\x46illerParameter\\x12\\x16\\n\\x04type\\x18\\x01 \\x01(\\t:\\x08\\x63onstant\\x12\\x10\\n\\x05value\\x18\\x02 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03min\\x18\\x03 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03max\\x18\\x04 \\x01(\\x02:\\x01\\x31\\x12\\x0f\\n\\x04mean\\x18\\x05 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03std\\x18\\x06 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x06sparse\\x18\\x07 \\x01(\\x05:\\x02-1\\x12\\x42\\n\\rvariance_norm\\x18\\x08 \\x01(\\x0e\\x32#.caffe.FillerParameter.VarianceNorm:\\x06\\x46\\x41N_IN\\""4\\n\\x0cVarianceNorm\\x12\\n\\n\\x06\\x46\\x41N_IN\\x10\\x00\\x12\\x0b\\n\\x07\\x46\\x41N_OUT\\x10\\x01\\x12\\x0b\\n\\x07\\x41VERAGE\\x10\\x02\\""\\x8e\\x02\\n\\x0cNetParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05input\\x18\\x03 \\x03(\\t\\x12%\\n\\x0binput_shape\\x18\\x08 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x11\\n\\tinput_dim\\x18\\x04 \\x03(\\x05\\x12\\x1d\\n\\x0e\\x66orce_backward\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1e\\n\\x05state\\x18\\x06 \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x19\\n\\ndebug_info\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\x12$\\n\\x05layer\\x18\\x64 \\x03(\\x0b\\x32\\x15.caffe.LayerParameter\\x12\\\'\\n\\x06layers\\x18\\x02 \\x03(\\x0b\\x32\\x17.caffe.V1LayerParameter\\""\\x9c\\n\\n\\x0fSolverParameter\\x12\\x0b\\n\\x03net\\x18\\x18 \\x01(\\t\\x12&\\n\\tnet_param\\x18\\x19 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12\\x11\\n\\ttrain_net\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x08test_net\\x18\\x02 \\x03(\\t\\x12,\\n\\x0ftrain_net_param\\x18\\x15 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12+\\n\\x0etest_net_param\\x18\\x16 \\x03(\\x0b\\x32\\x13.caffe.NetParameter\\x12$\\n\\x0btrain_state\\x18\\x1a \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12#\\n\\ntest_state\\x18\\x1b \\x03(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x11\\n\\ttest_iter\\x18\\x03 \\x03(\\x05\\x12\\x18\\n\\rtest_interval\\x18\\x04 \\x01(\\x05:\\x01\\x30\\x12 \\n\\x11test_compute_loss\\x18\\x13 \\x01(\\x08:\\x05\\x66\\x61lse\\x12!\\n\\x13test_initialization\\x18  \\x01(\\x08:\\x04true\\x12\\x0f\\n\\x07\\x62\\x61se_lr\\x18\\x05 \\x01(\\x02\\x12\\x0f\\n\\x07\\x64isplay\\x18\\x06 \\x01(\\x05\\x12\\x17\\n\\x0c\\x61verage_loss\\x18! \\x01(\\x05:\\x01\\x31\\x12\\x10\\n\\x08max_iter\\x18\\x07 \\x01(\\x05\\x12\\x14\\n\\titer_size\\x18$ \\x01(\\x05:\\x01\\x31\\x12\\x11\\n\\tlr_policy\\x18\\x08 \\x01(\\t\\x12\\r\\n\\x05gamma\\x18\\t \\x01(\\x02\\x12\\r\\n\\x05power\\x18\\n \\x01(\\x02\\x12\\x10\\n\\x08momentum\\x18\\x0b \\x01(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x0c \\x01(\\x02\\x12\\x1f\\n\\x13regularization_type\\x18\\x1d \\x01(\\t:\\x02L2\\x12\\x10\\n\\x08stepsize\\x18\\r \\x01(\\x05\\x12\\x11\\n\\tstepvalue\\x18\\"" \\x03(\\x05\\x12\\x1a\\n\\x0e\\x63lip_gradients\\x18# \\x01(\\x02:\\x02-1\\x12\\x13\\n\\x08snapshot\\x18\\x0e \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0fsnapshot_prefix\\x18\\x0f \\x01(\\t\\x12\\x1c\\n\\rsnapshot_diff\\x18\\x10 \\x01(\\x08:\\x05\\x66\\x61lse\\x12K\\n\\x0fsnapshot_format\\x18% \\x01(\\x0e\\x32%.caffe.SolverParameter.SnapshotFormat:\\x0b\\x42INARYPROTO\\x12;\\n\\x0bsolver_mode\\x18\\x11 \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverMode:\\x03GPU\\x12\\x14\\n\\tdevice_id\\x18\\x12 \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0brandom_seed\\x18\\x14 \\x01(\\x03:\\x02-1\\x12\\x11\\n\\x04type\\x18( \\x01(\\t:\\x03SGD\\x12\\x14\\n\\x05\\x64\\x65lta\\x18\\x1f \\x01(\\x02:\\x05\\x31\\x65-08\\x12\\x18\\n\\tmomentum2\\x18\\\' \\x01(\\x02:\\x05\\x30.999\\x12\\x11\\n\\trms_decay\\x18& \\x01(\\x02\\x12\\x19\\n\\ndebug_info\\x18\\x17 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x14snapshot_after_train\\x18\\x1c \\x01(\\x08:\\x04true\\x12;\\n\\x0bsolver_type\\x18\\x1e \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverType:\\x03SGD\\""+\\n\\x0eSnapshotFormat\\x12\\x08\\n\\x04HDF5\\x10\\x00\\x12\\x0f\\n\\x0b\\x42INARYPROTO\\x10\\x01\\""\\x1e\\n\\nSolverMode\\x12\\x07\\n\\x03\\x43PU\\x10\\x00\\x12\\x07\\n\\x03GPU\\x10\\x01\\""U\\n\\nSolverType\\x12\\x07\\n\\x03SGD\\x10\\x00\\x12\\x0c\\n\\x08NESTEROV\\x10\\x01\\x12\\x0b\\n\\x07\\x41\\x44\\x41GRAD\\x10\\x02\\x12\\x0b\\n\\x07RMSPROP\\x10\\x03\\x12\\x0c\\n\\x08\\x41\\x44\\x41\\x44\\x45LTA\\x10\\x04\\x12\\x08\\n\\x04\\x41\\x44\\x41M\\x10\\x05\\""l\\n\\x0bSolverState\\x12\\x0c\\n\\x04iter\\x18\\x01 \\x01(\\x05\\x12\\x13\\n\\x0blearned_net\\x18\\x02 \\x01(\\t\\x12!\\n\\x07history\\x18\\x03 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x17\\n\\x0c\\x63urrent_step\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""N\\n\\x08NetState\\x12!\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase:\\x04TEST\\x12\\x10\\n\\x05level\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\r\\n\\x05stage\\x18\\x03 \\x03(\\t\\""s\\n\\x0cNetStateRule\\x12\\x1b\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x11\\n\\tmin_level\\x18\\x02 \\x01(\\x05\\x12\\x11\\n\\tmax_level\\x18\\x03 \\x01(\\x05\\x12\\r\\n\\x05stage\\x18\\x04 \\x03(\\t\\x12\\x11\\n\\tnot_stage\\x18\\x05 \\x03(\\t\\""\\xa3\\x01\\n\\tParamSpec\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x31\\n\\nshare_mode\\x18\\x02 \\x01(\\x0e\\x32\\x1d.caffe.ParamSpec.DimCheckMode\\x12\\x12\\n\\x07lr_mult\\x18\\x03 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\ndecay_mult\\x18\\x04 \\x01(\\x02:\\x01\\x31\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\x98\\x13\\n\\x0eLayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x03 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x04 \\x03(\\t\\x12\\x1b\\n\\x05phase\\x18\\n \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x13\\n\\x0bloss_weight\\x18\\x05 \\x03(\\x02\\x12\\x1f\\n\\x05param\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.ParamSpec\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x07 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x16\\n\\x0epropagate_down\\x18\\x0b \\x03(\\x08\\x12$\\n\\x07include\\x18\\x08 \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18\\t \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12\\x37\\n\\x0ftransform_param\\x18\\x64 \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18\\x65 \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x66 \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18g \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12\\x34\\n\\x10\\x62\\x61tch_norm_param\\x18\\x8b\\x01 \\x01(\\x0b\\x32\\x19.caffe.BatchNormParameter\\x12)\\n\\nbias_param\\x18\\x8d\\x01 \\x01(\\x0b\\x32\\x14.caffe.BiasParameter\\x12,\\n\\x0c\\x63oncat_param\\x18h \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18i \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18j \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12)\\n\\ncrop_param\\x18\\x90\\x01 \\x01(\\x0b\\x32\\x14.caffe.CropParameter\\x12(\\n\\ndata_param\\x18k \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18l \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18m \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18n \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12\\\'\\n\\telu_param\\x18\\x8c\\x01 \\x01(\\x0b\\x32\\x13.caffe.ELUParameter\\x12+\\n\\x0b\\x65mbed_param\\x18\\x89\\x01 \\x01(\\x0b\\x32\\x15.caffe.EmbedParameter\\x12&\\n\\texp_param\\x18o \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12/\\n\\rflatten_param\\x18\\x87\\x01 \\x01(\\x0b\\x32\\x17.caffe.FlattenParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18p \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18q \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18r \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18s \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18t \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18u \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12+\\n\\x0binput_param\\x18\\x8f\\x01 \\x01(\\x0b\\x32\\x15.caffe.InputParameter\\x12\\\'\\n\\tlog_param\\x18\\x86\\x01 \\x01(\\x0b\\x32\\x13.caffe.LogParameter\\x12&\\n\\tlrn_param\\x18v \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18w \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18x \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18y \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18z \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12+\\n\\x0bprelu_param\\x18\\x83\\x01 \\x01(\\x0b\\x32\\x15.caffe.PReLUParameter\\x12-\\n\\x0cpython_param\\x18\\x82\\x01 \\x01(\\x0b\\x32\\x16.caffe.PythonParameter\\x12\\x33\\n\\x0freduction_param\\x18\\x88\\x01 \\x01(\\x0b\\x32\\x19.caffe.ReductionParameter\\x12(\\n\\nrelu_param\\x18{ \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12/\\n\\rreshape_param\\x18\\x85\\x01 \\x01(\\x0b\\x32\\x17.caffe.ReshapeParameter\\x12+\\n\\x0bscale_param\\x18\\x8e\\x01 \\x01(\\x0b\\x32\\x15.caffe.ScaleParameter\\x12.\\n\\rsigmoid_param\\x18| \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18} \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12\\\'\\n\\tspp_param\\x18\\x84\\x01 \\x01(\\x0b\\x32\\x13.caffe.SPPParameter\\x12*\\n\\x0bslice_param\\x18~ \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18\\x7f \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x33\\n\\x0fthreshold_param\\x18\\x80\\x01 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12)\\n\\ntile_param\\x18\\x8a\\x01 \\x01(\\x0b\\x32\\x14.caffe.TileParameter\\x12\\x36\\n\\x11window_data_param\\x18\\x81\\x01 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\""\\xb6\\x01\\n\\x17TransformationParameter\\x12\\x10\\n\\x05scale\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\x06mirror\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x14\\n\\tcrop_size\\x18\\x03 \\x01(\\r:\\x01\\x30\\x12\\x11\\n\\tmean_file\\x18\\x04 \\x01(\\t\\x12\\x12\\n\\nmean_value\\x18\\x05 \\x03(\\x02\\x12\\x1a\\n\\x0b\\x66orce_color\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\nforce_gray\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xc2\\x01\\n\\rLossParameter\\x12\\x14\\n\\x0cignore_label\\x18\\x01 \\x01(\\x05\\x12\\x44\\n\\rnormalization\\x18\\x03 \\x01(\\x0e\\x32&.caffe.LossParameter.NormalizationMode:\\x05VALID\\x12\\x11\\n\\tnormalize\\x18\\x02 \\x01(\\x08\\""B\\n\\x11NormalizationMode\\x12\\x08\\n\\x04\\x46ULL\\x10\\x00\\x12\\t\\n\\x05VALID\\x10\\x01\\x12\\x0e\\n\\nBATCH_SIZE\\x10\\x02\\x12\\x08\\n\\x04NONE\\x10\\x03\\""L\\n\\x11\\x41\\x63\\x63uracyParameter\\x12\\x10\\n\\x05top_k\\x18\\x01 \\x01(\\r:\\x01\\x31\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x0cignore_label\\x18\\x03 \\x01(\\x05\\""M\\n\\x0f\\x41rgMaxParameter\\x12\\x1a\\n\\x0bout_max_val\\x18\\x01 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x10\\n\\x05top_k\\x18\\x02 \\x01(\\r:\\x01\\x31\\x12\\x0c\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05\\""9\\n\\x0f\\x43oncatParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x15\\n\\nconcat_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""j\\n\\x12\\x42\\x61tchNormParameter\\x12\\x18\\n\\x10use_global_stats\\x18\\x01 \\x01(\\x08\\x12&\\n\\x17moving_average_fraction\\x18\\x02 \\x01(\\x02:\\x05\\x30.999\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-05\\""]\\n\\rBiasParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""L\\n\\x18\\x43ontrastiveLossParameter\\x12\\x11\\n\\x06margin\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x1d\\n\\x0elegacy_version\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xfc\\x03\\n\\x14\\x43onvolutionParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12\\x0b\\n\\x03pad\\x18\\x03 \\x03(\\r\\x12\\x13\\n\\x0bkernel_size\\x18\\x04 \\x03(\\r\\x12\\x0e\\n\\x06stride\\x18\\x06 \\x03(\\r\\x12\\x10\\n\\x08\\x64ilation\\x18\\x12 \\x03(\\r\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x08kernel_h\\x18\\x0b \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x0c \\x01(\\r\\x12\\x10\\n\\x08stride_h\\x18\\r \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x0e \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\x05 \\x01(\\r:\\x01\\x31\\x12-\\n\\rweight_filler\\x18\\x07 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x08 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12;\\n\\x06\\x65ngine\\x18\\x0f \\x01(\\x0e\\x32\\"".caffe.ConvolutionParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x10 \\x01(\\x05:\\x01\\x31\\x12\\x1e\\n\\x0f\\x66orce_nd_im2col\\x18\\x11 \\x01(\\x08:\\x05\\x66\\x61lse\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""0\\n\\rCropParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x32\\x12\\x0e\\n\\x06offset\\x18\\x02 \\x03(\\r\\""\\xa4\\x02\\n\\rDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x31\\n\\x07\\x62\\x61\\x63kend\\x18\\x08 \\x01(\\x0e\\x32\\x17.caffe.DataParameter.DB:\\x07LEVELDB\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x13\\x66orce_encoded_color\\x18\\t \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x13\\n\\x08prefetch\\x18\\n \\x01(\\r:\\x01\\x34\\""\\x1b\\n\\x02\\x44\\x42\\x12\\x0b\\n\\x07LEVELDB\\x10\\x00\\x12\\x08\\n\\x04LMDB\\x10\\x01\\"".\\n\\x10\\x44ropoutParameter\\x12\\x1a\\n\\rdropout_ratio\\x18\\x01 \\x01(\\x02:\\x03\\x30.5\\""\\xa0\\x01\\n\\x12\\x44ummyDataParameter\\x12+\\n\\x0b\\x64\\x61ta_filler\\x18\\x01 \\x03(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1f\\n\\x05shape\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0b\\n\\x03num\\x18\\x02 \\x03(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x03 \\x03(\\r\\x12\\x0e\\n\\x06height\\x18\\x04 \\x03(\\r\\x12\\r\\n\\x05width\\x18\\x05 \\x03(\\r\\""\\xa5\\x01\\n\\x10\\x45ltwiseParameter\\x12\\x39\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32!.caffe.EltwiseParameter.EltwiseOp:\\x03SUM\\x12\\r\\n\\x05\\x63oeff\\x18\\x02 \\x03(\\x02\\x12\\x1e\\n\\x10stable_prod_grad\\x18\\x03 \\x01(\\x08:\\x04true\\""\\\'\\n\\tEltwiseOp\\x12\\x08\\n\\x04PROD\\x10\\x00\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x07\\n\\x03MAX\\x10\\x02\\"" \\n\\x0c\\x45LUParameter\\x12\\x10\\n\\x05\\x61lpha\\x18\\x01 \\x01(\\x02:\\x01\\x31\\""\\xac\\x01\\n\\x0e\\x45mbedParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x11\\n\\tinput_dim\\x18\\x02 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x03 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""D\\n\\x0c\\x45xpParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""9\\n\\x10\\x46lattenParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x08\\x65nd_axis\\x18\\x02 \\x01(\\x05:\\x02-1\\""O\\n\\x11HDF5DataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x02 \\x01(\\r\\x12\\x16\\n\\x07shuffle\\x18\\x03 \\x01(\\x08:\\x05\\x66\\x61lse\\""(\\n\\x13HDF5OutputParameter\\x12\\x11\\n\\tfile_name\\x18\\x01 \\x01(\\t\\""^\\n\\x12HingeLossParameter\\x12\\x30\\n\\x04norm\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.HingeLossParameter.Norm:\\x02L1\\""\\x16\\n\\x04Norm\\x12\\x06\\n\\x02L1\\x10\\x01\\x12\\x06\\n\\x02L2\\x10\\x02\\""\\x97\\x02\\n\\x12ImageDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\nbatch_size\\x18\\x04 \\x01(\\r:\\x01\\x31\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x07shuffle\\x18\\x08 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nnew_height\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x08is_color\\x18\\x0b \\x01(\\x08:\\x04true\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\x0c \\x01(\\t:\\x00\\""\\\'\\n\\x15InfogainLossParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\""\\xcb\\x01\\n\\x15InnerProductParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x05 \\x01(\\x05:\\x01\\x31\\x12\\x18\\n\\ttranspose\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\""1\\n\\x0eInputParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\""D\\n\\x0cLogParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""\\xb8\\x02\\n\\x0cLRNParameter\\x12\\x15\\n\\nlocal_size\\x18\\x01 \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x03 \\x01(\\x02:\\x04\\x30.75\\x12\\x44\\n\\x0bnorm_region\\x18\\x04 \\x01(\\x0e\\x32\\x1e.caffe.LRNParameter.NormRegion:\\x0f\\x41\\x43ROSS_CHANNELS\\x12\\x0c\\n\\x01k\\x18\\x05 \\x01(\\x02:\\x01\\x31\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.LRNParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""5\\n\\nNormRegion\\x12\\x13\\n\\x0f\\x41\\x43ROSS_CHANNELS\\x10\\x00\\x12\\x12\\n\\x0eWITHIN_CHANNEL\\x10\\x01\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x13MemoryDataParameter\\x12\\x12\\n\\nbatch_size\\x18\\x01 \\x01(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x03 \\x01(\\r\\x12\\r\\n\\x05width\\x18\\x04 \\x01(\\r\\""d\\n\\x0cMVNParameter\\x12 \\n\\x12normalize_variance\\x18\\x01 \\x01(\\x08:\\x04true\\x12\\x1e\\n\\x0f\\x61\\x63ross_channels\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-09\\""\\xa2\\x03\\n\\x10PoolingParameter\\x12\\x35\\n\\x04pool\\x18\\x01 \\x01(\\x0e\\x32\\"".caffe.PoolingParameter.PoolMethod:\\x03MAX\\x12\\x0e\\n\\x03pad\\x18\\x04 \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x13\\n\\x0bkernel_size\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08kernel_h\\x18\\x05 \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x06 \\x01(\\r\\x12\\x11\\n\\x06stride\\x18\\x03 \\x01(\\r:\\x01\\x31\\x12\\x10\\n\\x08stride_h\\x18\\x07 \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x08 \\x01(\\r\\x12\\x37\\n\\x06\\x65ngine\\x18\\x0b \\x01(\\x0e\\x32\\x1e.caffe.PoolingParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x1d\\n\\x0eglobal_pooling\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""F\\n\\x0ePowerParameter\\x12\\x10\\n\\x05power\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""g\\n\\x0fPythonParameter\\x12\\x0e\\n\\x06module\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05layer\\x18\\x02 \\x01(\\t\\x12\\x13\\n\\tparam_str\\x18\\x03 \\x01(\\t:\\x00\\x12 \\n\\x11share_in_parallel\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xad\\x01\\n\\x12ReductionParameter\\x12=\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32%.caffe.ReductionParameter.ReductionOp:\\x03SUM\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05\\x63oeff\\x18\\x03 \\x01(\\x02:\\x01\\x31\\""5\\n\\x0bReductionOp\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x08\\n\\x04\\x41SUM\\x10\\x02\\x12\\t\\n\\x05SUMSQ\\x10\\x03\\x12\\x08\\n\\x04MEAN\\x10\\x04\\""\\x8d\\x01\\n\\rReLUParameter\\x12\\x19\\n\\x0enegative_slope\\x18\\x01 \\x01(\\x02:\\x01\\x30\\x12\\x34\\n\\x06\\x65ngine\\x18\\x02 \\x01(\\x0e\\x32\\x1b.caffe.ReLUParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x10ReshapeParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\x08num_axes\\x18\\x03 \\x01(\\x05:\\x02-1\\""\\xa5\\x01\\n\\x0eScaleParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x18\\n\\tbias_term\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""x\\n\\x10SigmoidParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SigmoidParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""L\\n\\x0eSliceParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x0bslice_point\\x18\\x02 \\x03(\\r\\x12\\x14\\n\\tslice_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""\\x89\\x01\\n\\x10SoftmaxParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SoftmaxParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""r\\n\\rTanHParameter\\x12\\x34\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1b.caffe.TanHParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""/\\n\\rTileParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\r\\n\\x05tiles\\x18\\x02 \\x01(\\x05\\""*\\n\\x12ThresholdParameter\\x12\\x14\\n\\tthreshold\\x18\\x01 \\x01(\\x02:\\x01\\x30\\""\\xc1\\x02\\n\\x13WindowDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\x0c\\x66g_threshold\\x18\\x07 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0c\\x62g_threshold\\x18\\x08 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0b\\x66g_fraction\\x18\\t \\x01(\\x02:\\x04\\x30.25\\x12\\x16\\n\\x0b\\x63ontext_pad\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x17\\n\\tcrop_mode\\x18\\x0b \\x01(\\t:\\x04warp\\x12\\x1b\\n\\x0c\\x63\\x61\\x63he_images\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\r \\x01(\\t:\\x00\\""\\xeb\\x01\\n\\x0cSPPParameter\\x12\\x16\\n\\x0epyramid_height\\x18\\x01 \\x01(\\r\\x12\\x31\\n\\x04pool\\x18\\x02 \\x01(\\x0e\\x32\\x1e.caffe.SPPParameter.PoolMethod:\\x03MAX\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.SPPParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""\\xe0\\x13\\n\\x10V1LayerParameter\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x02 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x03 \\x03(\\t\\x12\\x0c\\n\\x04name\\x18\\x04 \\x01(\\t\\x12$\\n\\x07include\\x18  \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18! \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12/\\n\\x04type\\x18\\x05 \\x01(\\x0e\\x32!.caffe.V1LayerParameter.LayerType\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x0e\\n\\x05param\\x18\\xe9\\x07 \\x03(\\t\\x12>\\n\\x0f\\x62lob_share_mode\\x18\\xea\\x07 \\x03(\\x0e\\x32$.caffe.V1LayerParameter.DimCheckMode\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x07 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x08 \\x03(\\x02\\x12\\x13\\n\\x0bloss_weight\\x18# \\x03(\\x02\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x1b \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18\\x17 \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12,\\n\\x0c\\x63oncat_param\\x18\\t \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18( \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18\\n \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12(\\n\\ndata_param\\x18\\x0b \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18\\x0c \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18\\x1a \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18\\x18 \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12&\\n\\texp_param\\x18) \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18\\r \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18\\x0e \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18\\x1d \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18\\x0f \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18\\x10 \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18\\x11 \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12&\\n\\tlrn_param\\x18\\x12 \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18\\x16 \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18\\"" \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18\\x13 \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18\\x15 \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12(\\n\\nrelu_param\\x18\\x1e \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12.\\n\\rsigmoid_param\\x18& \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18\\\' \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12*\\n\\x0bslice_param\\x18\\x1f \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18% \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x32\\n\\x0fthreshold_param\\x18\\x19 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12\\x35\\n\\x11window_data_param\\x18\\x14 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\x12\\x37\\n\\x0ftransform_param\\x18$ \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18* \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12&\\n\\x05layer\\x18\\x01 \\x01(\\x0b\\x32\\x17.caffe.V0LayerParameter\\""\\xd8\\x04\\n\\tLayerType\\x12\\x08\\n\\x04NONE\\x10\\x00\\x12\\n\\n\\x06\\x41\\x42SVAL\\x10#\\x12\\x0c\\n\\x08\\x41\\x43\\x43URACY\\x10\\x01\\x12\\n\\n\\x06\\x41RGMAX\\x10\\x1e\\x12\\x08\\n\\x04\\x42NLL\\x10\\x02\\x12\\n\\n\\x06\\x43ONCAT\\x10\\x03\\x12\\x14\\n\\x10\\x43ONTRASTIVE_LOSS\\x10%\\x12\\x0f\\n\\x0b\\x43ONVOLUTION\\x10\\x04\\x12\\x08\\n\\x04\\x44\\x41TA\\x10\\x05\\x12\\x11\\n\\rDECONVOLUTION\\x10\\\'\\x12\\x0b\\n\\x07\\x44ROPOUT\\x10\\x06\\x12\\x0e\\n\\nDUMMY_DATA\\x10 \\x12\\x12\\n\\x0e\\x45UCLIDEAN_LOSS\\x10\\x07\\x12\\x0b\\n\\x07\\x45LTWISE\\x10\\x19\\x12\\x07\\n\\x03\\x45XP\\x10&\\x12\\x0b\\n\\x07\\x46LATTEN\\x10\\x08\\x12\\r\\n\\tHDF5_DATA\\x10\\t\\x12\\x0f\\n\\x0bHDF5_OUTPUT\\x10\\n\\x12\\x0e\\n\\nHINGE_LOSS\\x10\\x1c\\x12\\n\\n\\x06IM2COL\\x10\\x0b\\x12\\x0e\\n\\nIMAGE_DATA\\x10\\x0c\\x12\\x11\\n\\rINFOGAIN_LOSS\\x10\\r\\x12\\x11\\n\\rINNER_PRODUCT\\x10\\x0e\\x12\\x07\\n\\x03LRN\\x10\\x0f\\x12\\x0f\\n\\x0bMEMORY_DATA\\x10\\x1d\\x12\\x1d\\n\\x19MULTINOMIAL_LOGISTIC_LOSS\\x10\\x10\\x12\\x07\\n\\x03MVN\\x10\\""\\x12\\x0b\\n\\x07POOLING\\x10\\x11\\x12\\t\\n\\x05POWER\\x10\\x1a\\x12\\x08\\n\\x04RELU\\x10\\x12\\x12\\x0b\\n\\x07SIGMOID\\x10\\x13\\x12\\x1e\\n\\x1aSIGMOID_CROSS_ENTROPY_LOSS\\x10\\x1b\\x12\\x0b\\n\\x07SILENCE\\x10$\\x12\\x0b\\n\\x07SOFTMAX\\x10\\x14\\x12\\x10\\n\\x0cSOFTMAX_LOSS\\x10\\x15\\x12\\t\\n\\x05SPLIT\\x10\\x16\\x12\\t\\n\\x05SLICE\\x10!\\x12\\x08\\n\\x04TANH\\x10\\x17\\x12\\x0f\\n\\x0bWINDOW_DATA\\x10\\x18\\x12\\r\\n\\tTHRESHOLD\\x10\\x1f\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\xfd\\x07\\n\\x10V0LayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x12\\n\\nnum_output\\x18\\x03 \\x01(\\r\\x12\\x16\\n\\x08\\x62iasterm\\x18\\x04 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x06 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0e\\n\\x03pad\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x12\\n\\nkernelsize\\x18\\x08 \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\t \\x01(\\r:\\x01\\x31\\x12\\x11\\n\\x06stride\\x18\\n \\x01(\\r:\\x01\\x31\\x12\\x35\\n\\x04pool\\x18\\x0b \\x01(\\x0e\\x32\\"".caffe.V0LayerParameter.PoolMethod:\\x03MAX\\x12\\x1a\\n\\rdropout_ratio\\x18\\x0c \\x01(\\x02:\\x03\\x30.5\\x12\\x15\\n\\nlocal_size\\x18\\r \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x0e \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x0f \\x01(\\x02:\\x04\\x30.75\\x12\\x0c\\n\\x01k\\x18\\x16 \\x01(\\x02:\\x01\\x31\\x12\\x0e\\n\\x06source\\x18\\x10 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x11 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x08meanfile\\x18\\x12 \\x01(\\t\\x12\\x11\\n\\tbatchsize\\x18\\x13 \\x01(\\r\\x12\\x13\\n\\x08\\x63ropsize\\x18\\x14 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x15 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x32 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x33 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x34 \\x03(\\x02\\x12\\x14\\n\\trand_skip\\x18\\x35 \\x01(\\r:\\x01\\x30\\x12\\x1d\\n\\x10\\x64\\x65t_fg_threshold\\x18\\x36 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x10\\x64\\x65t_bg_threshold\\x18\\x37 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x0f\\x64\\x65t_fg_fraction\\x18\\x38 \\x01(\\x02:\\x04\\x30.25\\x12\\x1a\\n\\x0f\\x64\\x65t_context_pad\\x18: \\x01(\\r:\\x01\\x30\\x12\\x1b\\n\\rdet_crop_mode\\x18; \\x01(\\t:\\x04warp\\x12\\x12\\n\\x07new_num\\x18< \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0cnew_channels\\x18= \\x01(\\x05:\\x01\\x30\\x12\\x15\\n\\nnew_height\\x18> \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18? \\x01(\\x05:\\x01\\x30\\x12\\x1d\\n\\x0eshuffle_images\\x18@ \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nconcat_dim\\x18\\x41 \\x01(\\r:\\x01\\x31\\x12\\x36\\n\\x11hdf5_output_param\\x18\\xe9\\x07 \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""W\\n\\x0ePReLUParameter\\x12&\\n\\x06\\x66iller\\x18\\x01 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1d\\n\\x0e\\x63hannel_shared\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse*\\x1c\\n\\x05Phase\\x12\\t\\n\\x05TRAIN\\x10\\x00\\x12\\x08\\n\\x04TEST\\x10\\x01\')\n\n_PHASE = _descriptor.EnumDescriptor(\n  name=\'Phase\',\n  full_name=\'caffe.Phase\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'TRAIN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TEST\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=14991,\n  serialized_end=15019,\n)\n\nPhase = enum_type_wrapper.EnumTypeWrapper(_PHASE)\nTRAIN = 0\nTEST = 1\n\n\n_FILLERPARAMETER_VARIANCENORM = _descriptor.EnumDescriptor(\n  name=\'VarianceNorm\',\n  full_name=\'caffe.FillerParameter.VarianceNorm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_IN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_OUT\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVERAGE\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=658,\n  serialized_end=710,\n)\n\n_SOLVERPARAMETER_SNAPSHOTFORMAT = _descriptor.EnumDescriptor(\n  name=\'SnapshotFormat\',\n  full_name=\'caffe.SolverParameter.SnapshotFormat\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BINARYPROTO\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2132,\n  serialized_end=2175,\n)\n\n_SOLVERPARAMETER_SOLVERMODE = _descriptor.EnumDescriptor(\n  name=\'SolverMode\',\n  full_name=\'caffe.SolverParameter.SolverMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'CPU\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'GPU\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2177,\n  serialized_end=2207,\n)\n\n_SOLVERPARAMETER_SOLVERTYPE = _descriptor.EnumDescriptor(\n  name=\'SolverType\',\n  full_name=\'caffe.SolverParameter.SolverType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SGD\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NESTEROV\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAGRAD\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RMSPROP\', index=3, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADADELTA\', index=4, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAM\', index=5, number=5,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2209,\n  serialized_end=2294,\n)\n\n_PARAMSPEC_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.ParamSpec.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2725,\n  serialized_end=2767,\n)\n\n_LOSSPARAMETER_NORMALIZATIONMODE = _descriptor.EnumDescriptor(\n  name=\'NormalizationMode\',\n  full_name=\'caffe.LossParameter.NormalizationMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FULL\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'VALID\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BATCH_SIZE\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=3, number=3,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=5542,\n  serialized_end=5608,\n)\n\n_CONVOLUTIONPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ConvolutionParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_DATAPARAMETER_DB = _descriptor.EnumDescriptor(\n  name=\'DB\',\n  full_name=\'caffe.DataParameter.DB\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'LEVELDB\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LMDB\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6934,\n  serialized_end=6961,\n)\n\n_ELTWISEPARAMETER_ELTWISEOP = _descriptor.EnumDescriptor(\n  name=\'EltwiseOp\',\n  full_name=\'caffe.EltwiseParameter.EltwiseOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'PROD\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7301,\n  serialized_end=7340,\n)\n\n_HINGELOSSPARAMETER_NORM = _descriptor.EnumDescriptor(\n  name=\'Norm\',\n  full_name=\'caffe.HingeLossParameter.Norm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'L1\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'L2\', index=1, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7875,\n  serialized_end=7897,\n)\n\n_LRNPARAMETER_NORMREGION = _descriptor.EnumDescriptor(\n  name=\'NormRegion\',\n  full_name=\'caffe.LRNParameter.NormRegion\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'ACROSS_CHANNELS\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WITHIN_CHANNEL\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=8764,\n  serialized_end=8817,\n)\n\n_LRNPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.LRNParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_POOLINGPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.PoolingParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9386,\n  serialized_end=9432,\n)\n\n_POOLINGPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.PoolingParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_REDUCTIONPARAMETER_REDUCTIONOP = _descriptor.EnumDescriptor(\n  name=\'ReductionOp\',\n  full_name=\'caffe.ReductionParameter.ReductionOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ASUM\', index=1, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUMSQ\', index=2, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEAN\', index=3, number=4,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9777,\n  serialized_end=9830,\n)\n\n_RELUPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ReLUParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_SIGMOIDPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SigmoidParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_SOFTMAXPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SoftmaxParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_TANHPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.TanHParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_SPPPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.SPPParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9386,\n  serialized_end=9432,\n)\n\n_SPPPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SPPParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_V1LAYERPARAMETER_LAYERTYPE = _descriptor.EnumDescriptor(\n  name=\'LayerType\',\n  full_name=\'caffe.V1LayerParameter.LayerType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ABSVAL\', index=1, number=35,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ACCURACY\', index=2, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ARGMAX\', index=3, number=30,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BNLL\', index=4, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONCAT\', index=5, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONTRASTIVE_LOSS\', index=6, number=37,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONVOLUTION\', index=7, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DATA\', index=8, number=5,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DECONVOLUTION\', index=9, number=39,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DROPOUT\', index=10, number=6,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DUMMY_DATA\', index=11, number=32,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EUCLIDEAN_LOSS\', index=12, number=7,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ELTWISE\', index=13, number=25,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EXP\', index=14, number=38,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FLATTEN\', index=15, number=8,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_DATA\', index=16, number=9,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_OUTPUT\', index=17, number=10,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HINGE_LOSS\', index=18, number=28,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IM2COL\', index=19, number=11,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IMAGE_DATA\', index=20, number=12,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INFOGAIN_LOSS\', index=21, number=13,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INNER_PRODUCT\', index=22, number=14,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LRN\', index=23, number=15,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEMORY_DATA\', index=24, number=29,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MULTINOMIAL_LOGISTIC_LOSS\', index=25, number=16,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MVN\', index=26, number=34,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POOLING\', index=27, number=17,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POWER\', index=28, number=26,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RELU\', index=29, number=18,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID\', index=30, number=19,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID_CROSS_ENTROPY_LOSS\', index=31, number=27,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SILENCE\', index=32, number=36,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX\', index=33, number=20,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX_LOSS\', index=34, number=21,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SPLIT\', index=35, number=22,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SLICE\', index=36, number=33,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TANH\', index=37, number=23,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WINDOW_DATA\', index=38, number=24,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'THRESHOLD\', index=39, number=31,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=13232,\n  serialized_end=13832,\n)\n\n_V1LAYERPARAMETER_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.V1LayerParameter.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2725,\n  serialized_end=2767,\n)\n\n_V0LAYERPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.V0LayerParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9386,\n  serialized_end=9432,\n)\n\n\n_BLOBSHAPE = _descriptor.Descriptor(\n  name=\'BlobShape\',\n  full_name=\'caffe.BlobShape\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dim\', full_name=\'caffe.BlobShape.dim\', index=0,\n      number=1, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=22,\n  serialized_end=50,\n)\n\n\n_BLOBPROTO = _descriptor.Descriptor(\n  name=\'BlobProto\',\n  full_name=\'caffe.BlobProto\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.BlobProto.shape\', index=0,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.BlobProto.data\', index=1,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'diff\', full_name=\'caffe.BlobProto.diff\', index=2,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'double_data\', full_name=\'caffe.BlobProto.double_data\', index=3,\n      number=8, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'double_diff\', full_name=\'caffe.BlobProto.double_diff\', index=4,\n      number=9, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.BlobProto.num\', index=5,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.BlobProto.channels\', index=6,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.BlobProto.height\', index=7,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.BlobProto.width\', index=8,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=53,\n  serialized_end=257,\n)\n\n\n_BLOBPROTOVECTOR = _descriptor.Descriptor(\n  name=\'BlobProtoVector\',\n  full_name=\'caffe.BlobProtoVector\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.BlobProtoVector.blobs\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=259,\n  serialized_end=309,\n)\n\n\n_DATUM = _descriptor.Descriptor(\n  name=\'Datum\',\n  full_name=\'caffe.Datum\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.Datum.channels\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.Datum.height\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.Datum.width\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.Datum.data\', index=3,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value="""",\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'label\', full_name=\'caffe.Datum.label\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'float_data\', full_name=\'caffe.Datum.float_data\', index=5,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'encoded\', full_name=\'caffe.Datum.encoded\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=312,\n  serialized_end=441,\n)\n\n\n_FILLERPARAMETER = _descriptor.Descriptor(\n  name=\'FillerParameter\',\n  full_name=\'caffe.FillerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.FillerParameter.type\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""constant"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'caffe.FillerParameter.value\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min\', full_name=\'caffe.FillerParameter.min\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max\', full_name=\'caffe.FillerParameter.max\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean\', full_name=\'caffe.FillerParameter.mean\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'std\', full_name=\'caffe.FillerParameter.std\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sparse\', full_name=\'caffe.FillerParameter.sparse\', index=6,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'variance_norm\', full_name=\'caffe.FillerParameter.variance_norm\', index=7,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _FILLERPARAMETER_VARIANCENORM,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=444,\n  serialized_end=710,\n)\n\n\n_NETPARAMETER = _descriptor.Descriptor(\n  name=\'NetParameter\',\n  full_name=\'caffe.NetParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.NetParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input\', full_name=\'caffe.NetParameter.input\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_shape\', full_name=\'caffe.NetParameter.input_shape\', index=2,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.NetParameter.input_dim\', index=3,\n      number=4, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_backward\', full_name=\'caffe.NetParameter.force_backward\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'state\', full_name=\'caffe.NetParameter.state\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.NetParameter.debug_info\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.NetParameter.layer\', index=7,\n      number=100, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layers\', full_name=\'caffe.NetParameter.layers\', index=8,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=713,\n  serialized_end=983,\n)\n\n\n_SOLVERPARAMETER = _descriptor.Descriptor(\n  name=\'SolverParameter\',\n  full_name=\'caffe.SolverParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'net\', full_name=\'caffe.SolverParameter.net\', index=0,\n      number=24, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'net_param\', full_name=\'caffe.SolverParameter.net_param\', index=1,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_net\', full_name=\'caffe.SolverParameter.train_net\', index=2,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_net\', full_name=\'caffe.SolverParameter.test_net\', index=3,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_net_param\', full_name=\'caffe.SolverParameter.train_net_param\', index=4,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_net_param\', full_name=\'caffe.SolverParameter.test_net_param\', index=5,\n      number=22, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_state\', full_name=\'caffe.SolverParameter.train_state\', index=6,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_state\', full_name=\'caffe.SolverParameter.test_state\', index=7,\n      number=27, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_iter\', full_name=\'caffe.SolverParameter.test_iter\', index=8,\n      number=3, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_interval\', full_name=\'caffe.SolverParameter.test_interval\', index=9,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_compute_loss\', full_name=\'caffe.SolverParameter.test_compute_loss\', index=10,\n      number=19, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_initialization\', full_name=\'caffe.SolverParameter.test_initialization\', index=11,\n      number=32, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'base_lr\', full_name=\'caffe.SolverParameter.base_lr\', index=12,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'display\', full_name=\'caffe.SolverParameter.display\', index=13,\n      number=6, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'average_loss\', full_name=\'caffe.SolverParameter.average_loss\', index=14,\n      number=33, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max_iter\', full_name=\'caffe.SolverParameter.max_iter\', index=15,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'iter_size\', full_name=\'caffe.SolverParameter.iter_size\', index=16,\n      number=36, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lr_policy\', full_name=\'caffe.SolverParameter.lr_policy\', index=17,\n      number=8, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'gamma\', full_name=\'caffe.SolverParameter.gamma\', index=18,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.SolverParameter.power\', index=19,\n      number=10, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum\', full_name=\'caffe.SolverParameter.momentum\', index=20,\n      number=11, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.SolverParameter.weight_decay\', index=21,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'regularization_type\', full_name=\'caffe.SolverParameter.regularization_type\', index=22,\n      number=29, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""L2"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stepsize\', full_name=\'caffe.SolverParameter.stepsize\', index=23,\n      number=13, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stepvalue\', full_name=\'caffe.SolverParameter.stepvalue\', index=24,\n      number=34, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'clip_gradients\', full_name=\'caffe.SolverParameter.clip_gradients\', index=25,\n      number=35, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot\', full_name=\'caffe.SolverParameter.snapshot\', index=26,\n      number=14, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_prefix\', full_name=\'caffe.SolverParameter.snapshot_prefix\', index=27,\n      number=15, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_diff\', full_name=\'caffe.SolverParameter.snapshot_diff\', index=28,\n      number=16, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_format\', full_name=\'caffe.SolverParameter.snapshot_format\', index=29,\n      number=37, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'solver_mode\', full_name=\'caffe.SolverParameter.solver_mode\', index=30,\n      number=17, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'device_id\', full_name=\'caffe.SolverParameter.device_id\', index=31,\n      number=18, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'random_seed\', full_name=\'caffe.SolverParameter.random_seed\', index=32,\n      number=20, type=3, cpp_type=2, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.SolverParameter.type\', index=33,\n      number=40, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""SGD"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'delta\', full_name=\'caffe.SolverParameter.delta\', index=34,\n      number=31, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1e-08,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum2\', full_name=\'caffe.SolverParameter.momentum2\', index=35,\n      number=39, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.999,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rms_decay\', full_name=\'caffe.SolverParameter.rms_decay\', index=36,\n      number=38, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.SolverParameter.debug_info\', index=37,\n      number=23, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_after_train\', full_name=\'caffe.SolverParameter.snapshot_after_train\', index=38,\n      number=28, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'solver_type\', full_name=\'caffe.SolverParameter.solver_type\', index=39,\n      number=30, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOLVERPARAMETER_SNAPSHOTFORMAT,\n    _SOLVERPARAMETER_SOLVERMODE,\n    _SOLVERPARAMETER_SOLVERTYPE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=986,\n  serialized_end=2294,\n)\n\n\n_SOLVERSTATE = _descriptor.Descriptor(\n  name=\'SolverState\',\n  full_name=\'caffe.SolverState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'iter\', full_name=\'caffe.SolverState.iter\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'learned_net\', full_name=\'caffe.SolverState.learned_net\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'history\', full_name=\'caffe.SolverState.history\', index=2,\n      number=3, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'current_step\', full_name=\'caffe.SolverState.current_step\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2296,\n  serialized_end=2404,\n)\n\n\n_NETSTATE = _descriptor.Descriptor(\n  name=\'NetState\',\n  full_name=\'caffe.NetState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetState.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'level\', full_name=\'caffe.NetState.level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetState.stage\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2406,\n  serialized_end=2484,\n)\n\n\n_NETSTATERULE = _descriptor.Descriptor(\n  name=\'NetStateRule\',\n  full_name=\'caffe.NetStateRule\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetStateRule.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min_level\', full_name=\'caffe.NetStateRule.min_level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max_level\', full_name=\'caffe.NetStateRule.max_level\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetStateRule.stage\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'not_stage\', full_name=\'caffe.NetStateRule.not_stage\', index=4,\n      number=5, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2486,\n  serialized_end=2601,\n)\n\n\n_PARAMSPEC = _descriptor.Descriptor(\n  name=\'ParamSpec\',\n  full_name=\'caffe.ParamSpec\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.ParamSpec.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'share_mode\', full_name=\'caffe.ParamSpec.share_mode\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lr_mult\', full_name=\'caffe.ParamSpec.lr_mult\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'decay_mult\', full_name=\'caffe.ParamSpec.decay_mult\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _PARAMSPEC_DIMCHECKMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2604,\n  serialized_end=2767,\n)\n\n\n_LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'LayerParameter\',\n  full_name=\'caffe.LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.LayerParameter.bottom\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.LayerParameter.top\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.LayerParameter.phase\', index=4,\n      number=10, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.LayerParameter.loss_weight\', index=5,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.LayerParameter.param\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.LayerParameter.blobs\', index=7,\n      number=7, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'propagate_down\', full_name=\'caffe.LayerParameter.propagate_down\', index=8,\n      number=11, type=8, cpp_type=7, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.LayerParameter.include\', index=9,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.LayerParameter.exclude\', index=10,\n      number=9, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.LayerParameter.transform_param\', index=11,\n      number=100, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.LayerParameter.loss_param\', index=12,\n      number=101, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.LayerParameter.accuracy_param\', index=13,\n      number=102, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.LayerParameter.argmax_param\', index=14,\n      number=103, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_norm_param\', full_name=\'caffe.LayerParameter.batch_norm_param\', index=15,\n      number=139, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_param\', full_name=\'caffe.LayerParameter.bias_param\', index=16,\n      number=141, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.LayerParameter.concat_param\', index=17,\n      number=104, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.LayerParameter.contrastive_loss_param\', index=18,\n      number=105, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.LayerParameter.convolution_param\', index=19,\n      number=106, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_param\', full_name=\'caffe.LayerParameter.crop_param\', index=20,\n      number=144, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.LayerParameter.data_param\', index=21,\n      number=107, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.LayerParameter.dropout_param\', index=22,\n      number=108, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.LayerParameter.dummy_data_param\', index=23,\n      number=109, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.LayerParameter.eltwise_param\', index=24,\n      number=110, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'elu_param\', full_name=\'caffe.LayerParameter.elu_param\', index=25,\n      number=140, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'embed_param\', full_name=\'caffe.LayerParameter.embed_param\', index=26,\n      number=137, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.LayerParameter.exp_param\', index=27,\n      number=111, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'flatten_param\', full_name=\'caffe.LayerParameter.flatten_param\', index=28,\n      number=135, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.LayerParameter.hdf5_data_param\', index=29,\n      number=112, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.LayerParameter.hdf5_output_param\', index=30,\n      number=113, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.LayerParameter.hinge_loss_param\', index=31,\n      number=114, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.LayerParameter.image_data_param\', index=32,\n      number=115, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.LayerParameter.infogain_loss_param\', index=33,\n      number=116, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.LayerParameter.inner_product_param\', index=34,\n      number=117, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_param\', full_name=\'caffe.LayerParameter.input_param\', index=35,\n      number=143, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'log_param\', full_name=\'caffe.LayerParameter.log_param\', index=36,\n      number=134, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.LayerParameter.lrn_param\', index=37,\n      number=118, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.LayerParameter.memory_data_param\', index=38,\n      number=119, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.LayerParameter.mvn_param\', index=39,\n      number=120, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.LayerParameter.pooling_param\', index=40,\n      number=121, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.LayerParameter.power_param\', index=41,\n      number=122, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'prelu_param\', full_name=\'caffe.LayerParameter.prelu_param\', index=42,\n      number=131, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'python_param\', full_name=\'caffe.LayerParameter.python_param\', index=43,\n      number=130, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reduction_param\', full_name=\'caffe.LayerParameter.reduction_param\', index=44,\n      number=136, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.LayerParameter.relu_param\', index=45,\n      number=123, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reshape_param\', full_name=\'caffe.LayerParameter.reshape_param\', index=46,\n      number=133, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale_param\', full_name=\'caffe.LayerParameter.scale_param\', index=47,\n      number=142, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.LayerParameter.sigmoid_param\', index=48,\n      number=124, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.LayerParameter.softmax_param\', index=49,\n      number=125, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'spp_param\', full_name=\'caffe.LayerParameter.spp_param\', index=50,\n      number=132, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.LayerParameter.slice_param\', index=51,\n      number=126, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.LayerParameter.tanh_param\', index=52,\n      number=127, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.LayerParameter.threshold_param\', index=53,\n      number=128, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tile_param\', full_name=\'caffe.LayerParameter.tile_param\', index=54,\n      number=138, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.LayerParameter.window_data_param\', index=55,\n      number=129, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2770,\n  serialized_end=5226,\n)\n\n\n_TRANSFORMATIONPARAMETER = _descriptor.Descriptor(\n  name=\'TransformationParameter\',\n  full_name=\'caffe.TransformationParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.TransformationParameter.scale\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.TransformationParameter.mirror\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.TransformationParameter.crop_size\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.TransformationParameter.mean_file\', index=3,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_value\', full_name=\'caffe.TransformationParameter.mean_value\', index=4,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_color\', full_name=\'caffe.TransformationParameter.force_color\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_gray\', full_name=\'caffe.TransformationParameter.force_gray\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5229,\n  serialized_end=5411,\n)\n\n\n_LOSSPARAMETER = _descriptor.Descriptor(\n  name=\'LossParameter\',\n  full_name=\'caffe.LossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.LossParameter.ignore_label\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'normalization\', full_name=\'caffe.LossParameter.normalization\', index=1,\n      number=3, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'normalize\', full_name=\'caffe.LossParameter.normalize\', index=2,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LOSSPARAMETER_NORMALIZATIONMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5414,\n  serialized_end=5608,\n)\n\n\n_ACCURACYPARAMETER = _descriptor.Descriptor(\n  name=\'AccuracyParameter\',\n  full_name=\'caffe.AccuracyParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.AccuracyParameter.top_k\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.AccuracyParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.AccuracyParameter.ignore_label\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5610,\n  serialized_end=5686,\n)\n\n\n_ARGMAXPARAMETER = _descriptor.Descriptor(\n  name=\'ArgMaxParameter\',\n  full_name=\'caffe.ArgMaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'out_max_val\', full_name=\'caffe.ArgMaxParameter.out_max_val\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.ArgMaxParameter.top_k\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ArgMaxParameter.axis\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5688,\n  serialized_end=5765,\n)\n\n\n_CONCATPARAMETER = _descriptor.Descriptor(\n  name=\'ConcatParameter\',\n  full_name=\'caffe.ConcatParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConcatParameter.axis\', index=0,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.ConcatParameter.concat_dim\', index=1,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5767,\n  serialized_end=5824,\n)\n\n\n_BATCHNORMPARAMETER = _descriptor.Descriptor(\n  name=\'BatchNormParameter\',\n  full_name=\'caffe.BatchNormParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'use_global_stats\', full_name=\'caffe.BatchNormParameter.use_global_stats\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'moving_average_fraction\', full_name=\'caffe.BatchNormParameter.moving_average_fraction\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.999,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.BatchNormParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1e-05,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5826,\n  serialized_end=5932,\n)\n\n\n_BIASPARAMETER = _descriptor.Descriptor(\n  name=\'BiasParameter\',\n  full_name=\'caffe.BiasParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.BiasParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.BiasParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.BiasParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5934,\n  serialized_end=6027,\n)\n\n\n_CONTRASTIVELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'ContrastiveLossParameter\',\n  full_name=\'caffe.ContrastiveLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'margin\', full_name=\'caffe.ContrastiveLossParameter.margin\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'legacy_version\', full_name=\'caffe.ContrastiveLossParameter.legacy_version\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6029,\n  serialized_end=6105,\n)\n\n\n_CONVOLUTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ConvolutionParameter\',\n  full_name=\'caffe.ConvolutionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.ConvolutionParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ConvolutionParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.ConvolutionParameter.pad\', index=2,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.ConvolutionParameter.kernel_size\', index=3,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.ConvolutionParameter.stride\', index=4,\n      number=6, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dilation\', full_name=\'caffe.ConvolutionParameter.dilation\', index=5,\n      number=18, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.ConvolutionParameter.pad_h\', index=6,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.ConvolutionParameter.pad_w\', index=7,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.ConvolutionParameter.kernel_h\', index=8,\n      number=11, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.ConvolutionParameter.kernel_w\', index=9,\n      number=12, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.ConvolutionParameter.stride_h\', index=10,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.ConvolutionParameter.stride_w\', index=11,\n      number=14, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.ConvolutionParameter.group\', index=12,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.ConvolutionParameter.weight_filler\', index=13,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ConvolutionParameter.bias_filler\', index=14,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ConvolutionParameter.engine\', index=15,\n      number=15, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConvolutionParameter.axis\', index=16,\n      number=16, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_nd_im2col\', full_name=\'caffe.ConvolutionParameter.force_nd_im2col\', index=17,\n      number=17, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _CONVOLUTIONPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6108,\n  serialized_end=6616,\n)\n\n\n_CROPPARAMETER = _descriptor.Descriptor(\n  name=\'CropParameter\',\n  full_name=\'caffe.CropParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.CropParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=2,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'offset\', full_name=\'caffe.CropParameter.offset\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6618,\n  serialized_end=6666,\n)\n\n\n_DATAPARAMETER = _descriptor.Descriptor(\n  name=\'DataParameter\',\n  full_name=\'caffe.DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.DataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.DataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'backend\', full_name=\'caffe.DataParameter.backend\', index=3,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.DataParameter.scale\', index=4,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.DataParameter.mean_file\', index=5,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.DataParameter.crop_size\', index=6,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.DataParameter.mirror\', index=7,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_encoded_color\', full_name=\'caffe.DataParameter.force_encoded_color\', index=8,\n      number=9, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'prefetch\', full_name=\'caffe.DataParameter.prefetch\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=4,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _DATAPARAMETER_DB,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6669,\n  serialized_end=6961,\n)\n\n\n_DROPOUTPARAMETER = _descriptor.Descriptor(\n  name=\'DropoutParameter\',\n  full_name=\'caffe.DropoutParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.DropoutParameter.dropout_ratio\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6963,\n  serialized_end=7009,\n)\n\n\n_DUMMYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'DummyDataParameter\',\n  full_name=\'caffe.DummyDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'data_filler\', full_name=\'caffe.DummyDataParameter.data_filler\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.DummyDataParameter.shape\', index=1,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.DummyDataParameter.num\', index=2,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.DummyDataParameter.channels\', index=3,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.DummyDataParameter.height\', index=4,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.DummyDataParameter.width\', index=5,\n      number=5, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7012,\n  serialized_end=7172,\n)\n\n\n_ELTWISEPARAMETER = _descriptor.Descriptor(\n  name=\'EltwiseParameter\',\n  full_name=\'caffe.EltwiseParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.EltwiseParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.EltwiseParameter.coeff\', index=1,\n      number=2, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stable_prod_grad\', full_name=\'caffe.EltwiseParameter.stable_prod_grad\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _ELTWISEPARAMETER_ELTWISEOP,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7175,\n  serialized_end=7340,\n)\n\n\n_ELUPARAMETER = _descriptor.Descriptor(\n  name=\'ELUParameter\',\n  full_name=\'caffe.ELUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.ELUParameter.alpha\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7342,\n  serialized_end=7374,\n)\n\n\n_EMBEDPARAMETER = _descriptor.Descriptor(\n  name=\'EmbedParameter\',\n  full_name=\'caffe.EmbedParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.EmbedParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.EmbedParameter.input_dim\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.EmbedParameter.bias_term\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.EmbedParameter.weight_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.EmbedParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7377,\n  serialized_end=7549,\n)\n\n\n_EXPPARAMETER = _descriptor.Descriptor(\n  name=\'ExpParameter\',\n  full_name=\'caffe.ExpParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.ExpParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ExpParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.ExpParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7551,\n  serialized_end=7619,\n)\n\n\n_FLATTENPARAMETER = _descriptor.Descriptor(\n  name=\'FlattenParameter\',\n  full_name=\'caffe.FlattenParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.FlattenParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'end_axis\', full_name=\'caffe.FlattenParameter.end_axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7621,\n  serialized_end=7678,\n)\n\n\n_HDF5DATAPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5DataParameter\',\n  full_name=\'caffe.HDF5DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.HDF5DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.HDF5DataParameter.batch_size\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.HDF5DataParameter.shuffle\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7680,\n  serialized_end=7759,\n)\n\n\n_HDF5OUTPUTPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5OutputParameter\',\n  full_name=\'caffe.HDF5OutputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'file_name\', full_name=\'caffe.HDF5OutputParameter.file_name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7761,\n  serialized_end=7801,\n)\n\n\n_HINGELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'HingeLossParameter\',\n  full_name=\'caffe.HingeLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'norm\', full_name=\'caffe.HingeLossParameter.norm\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _HINGELOSSPARAMETER_NORM,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7803,\n  serialized_end=7897,\n)\n\n\n_IMAGEDATAPARAMETER = _descriptor.Descriptor(\n  name=\'ImageDataParameter\',\n  full_name=\'caffe.ImageDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.ImageDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.ImageDataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.ImageDataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.ImageDataParameter.shuffle\', index=3,\n      number=8, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.ImageDataParameter.new_height\', index=4,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.ImageDataParameter.new_width\', index=5,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'is_color\', full_name=\'caffe.ImageDataParameter.is_color\', index=6,\n      number=11, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ImageDataParameter.scale\', index=7,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.ImageDataParameter.mean_file\', index=8,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.ImageDataParameter.crop_size\', index=9,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.ImageDataParameter.mirror\', index=10,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.ImageDataParameter.root_folder\', index=11,\n      number=12, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7900,\n  serialized_end=8179,\n)\n\n\n_INFOGAINLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'InfogainLossParameter\',\n  full_name=\'caffe.InfogainLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.InfogainLossParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8181,\n  serialized_end=8220,\n)\n\n\n_INNERPRODUCTPARAMETER = _descriptor.Descriptor(\n  name=\'InnerProductParameter\',\n  full_name=\'caffe.InnerProductParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.InnerProductParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.InnerProductParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.InnerProductParameter.weight_filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.InnerProductParameter.bias_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.InnerProductParameter.axis\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transpose\', full_name=\'caffe.InnerProductParameter.transpose\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8223,\n  serialized_end=8426,\n)\n\n\n_INPUTPARAMETER = _descriptor.Descriptor(\n  name=\'InputParameter\',\n  full_name=\'caffe.InputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.InputParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8428,\n  serialized_end=8477,\n)\n\n\n_LOGPARAMETER = _descriptor.Descriptor(\n  name=\'LogParameter\',\n  full_name=\'caffe.LogParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.LogParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.LogParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.LogParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8479,\n  serialized_end=8547,\n)\n\n\n_LRNPARAMETER = _descriptor.Descriptor(\n  name=\'LRNParameter\',\n  full_name=\'caffe.LRNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.LRNParameter.local_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.LRNParameter.alpha\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.LRNParameter.beta\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.75,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'norm_region\', full_name=\'caffe.LRNParameter.norm_region\', index=3,\n      number=4, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.LRNParameter.k\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.LRNParameter.engine\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LRNPARAMETER_NORMREGION,\n    _LRNPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8550,\n  serialized_end=8862,\n)\n\n\n_MEMORYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'MemoryDataParameter\',\n  full_name=\'caffe.MemoryDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.MemoryDataParameter.batch_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.MemoryDataParameter.channels\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.MemoryDataParameter.height\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.MemoryDataParameter.width\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8864,\n  serialized_end=8954,\n)\n\n\n_MVNPARAMETER = _descriptor.Descriptor(\n  name=\'MVNParameter\',\n  full_name=\'caffe.MVNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'normalize_variance\', full_name=\'caffe.MVNParameter.normalize_variance\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'across_channels\', full_name=\'caffe.MVNParameter.across_channels\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.MVNParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1e-09,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8956,\n  serialized_end=9056,\n)\n\n\n_POOLINGPARAMETER = _descriptor.Descriptor(\n  name=\'PoolingParameter\',\n  full_name=\'caffe.PoolingParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.PoolingParameter.pool\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.PoolingParameter.pad\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.PoolingParameter.pad_h\', index=2,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.PoolingParameter.pad_w\', index=3,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.PoolingParameter.kernel_size\', index=4,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.PoolingParameter.kernel_h\', index=5,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.PoolingParameter.kernel_w\', index=6,\n      number=6, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.PoolingParameter.stride\', index=7,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.PoolingParameter.stride_h\', index=8,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.PoolingParameter.stride_w\', index=9,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.PoolingParameter.engine\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'global_pooling\', full_name=\'caffe.PoolingParameter.global_pooling\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _POOLINGPARAMETER_POOLMETHOD,\n    _POOLINGPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9059,\n  serialized_end=9477,\n)\n\n\n_POWERPARAMETER = _descriptor.Descriptor(\n  name=\'PowerParameter\',\n  full_name=\'caffe.PowerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.PowerParameter.power\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.PowerParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.PowerParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9479,\n  serialized_end=9549,\n)\n\n\n_PYTHONPARAMETER = _descriptor.Descriptor(\n  name=\'PythonParameter\',\n  full_name=\'caffe.PythonParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'module\', full_name=\'caffe.PythonParameter.module\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.PythonParameter.layer\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param_str\', full_name=\'caffe.PythonParameter.param_str\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'share_in_parallel\', full_name=\'caffe.PythonParameter.share_in_parallel\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9551,\n  serialized_end=9654,\n)\n\n\n_REDUCTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ReductionParameter\',\n  full_name=\'caffe.ReductionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.ReductionParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReductionParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.ReductionParameter.coeff\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _REDUCTIONPARAMETER_REDUCTIONOP,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9657,\n  serialized_end=9830,\n)\n\n\n_RELUPARAMETER = _descriptor.Descriptor(\n  name=\'ReLUParameter\',\n  full_name=\'caffe.ReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'negative_slope\', full_name=\'caffe.ReLUParameter.negative_slope\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ReLUParameter.engine\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _RELUPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9833,\n  serialized_end=9974,\n)\n\n\n_RESHAPEPARAMETER = _descriptor.Descriptor(\n  name=\'ReshapeParameter\',\n  full_name=\'caffe.ReshapeParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.ReshapeParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReshapeParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ReshapeParameter.num_axes\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9976,\n  serialized_end=10066,\n)\n\n\n_SCALEPARAMETER = _descriptor.Descriptor(\n  name=\'ScaleParameter\',\n  full_name=\'caffe.ScaleParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ScaleParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ScaleParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.ScaleParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ScaleParameter.bias_term\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ScaleParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10069,\n  serialized_end=10234,\n)\n\n\n_SIGMOIDPARAMETER = _descriptor.Descriptor(\n  name=\'SigmoidParameter\',\n  full_name=\'caffe.SigmoidParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SigmoidParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SIGMOIDPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10236,\n  serialized_end=10356,\n)\n\n\n_SLICEPARAMETER = _descriptor.Descriptor(\n  name=\'SliceParameter\',\n  full_name=\'caffe.SliceParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SliceParameter.axis\', index=0,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_point\', full_name=\'caffe.SliceParameter.slice_point\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_dim\', full_name=\'caffe.SliceParameter.slice_dim\', index=2,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10358,\n  serialized_end=10434,\n)\n\n\n_SOFTMAXPARAMETER = _descriptor.Descriptor(\n  name=\'SoftmaxParameter\',\n  full_name=\'caffe.SoftmaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SoftmaxParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SoftmaxParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOFTMAXPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10437,\n  serialized_end=10574,\n)\n\n\n_TANHPARAMETER = _descriptor.Descriptor(\n  name=\'TanHParameter\',\n  full_name=\'caffe.TanHParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.TanHParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _TANHPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10576,\n  serialized_end=10690,\n)\n\n\n_TILEPARAMETER = _descriptor.Descriptor(\n  name=\'TileParameter\',\n  full_name=\'caffe.TileParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.TileParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tiles\', full_name=\'caffe.TileParameter.tiles\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10692,\n  serialized_end=10739,\n)\n\n\n_THRESHOLDPARAMETER = _descriptor.Descriptor(\n  name=\'ThresholdParameter\',\n  full_name=\'caffe.ThresholdParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'threshold\', full_name=\'caffe.ThresholdParameter.threshold\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10741,\n  serialized_end=10783,\n)\n\n\n_WINDOWDATAPARAMETER = _descriptor.Descriptor(\n  name=\'WindowDataParameter\',\n  full_name=\'caffe.WindowDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.WindowDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.WindowDataParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.WindowDataParameter.mean_file\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.WindowDataParameter.batch_size\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.WindowDataParameter.crop_size\', index=4,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.WindowDataParameter.mirror\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_threshold\', full_name=\'caffe.WindowDataParameter.fg_threshold\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bg_threshold\', full_name=\'caffe.WindowDataParameter.bg_threshold\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_fraction\', full_name=\'caffe.WindowDataParameter.fg_fraction\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.25,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'context_pad\', full_name=\'caffe.WindowDataParameter.context_pad\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_mode\', full_name=\'caffe.WindowDataParameter.crop_mode\', index=10,\n      number=11, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""warp"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'cache_images\', full_name=\'caffe.WindowDataParameter.cache_images\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.WindowDataParameter.root_folder\', index=12,\n      number=13, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10786,\n  serialized_end=11107,\n)\n\n\n_SPPPARAMETER = _descriptor.Descriptor(\n  name=\'SPPParameter\',\n  full_name=\'caffe.SPPParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pyramid_height\', full_name=\'caffe.SPPParameter.pyramid_height\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.SPPParameter.pool\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SPPParameter.engine\', index=2,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SPPPARAMETER_POOLMETHOD,\n    _SPPPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=11110,\n  serialized_end=11345,\n)\n\n\n_V1LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V1LayerParameter\',\n  full_name=\'caffe.V1LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.V1LayerParameter.bottom\', index=0,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.V1LayerParameter.top\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V1LayerParameter.name\', index=2,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.V1LayerParameter.include\', index=3,\n      number=32, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.V1LayerParameter.exclude\', index=4,\n      number=33, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V1LayerParameter.type\', index=5,\n      number=5, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V1LayerParameter.blobs\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.V1LayerParameter.param\', index=7,\n      number=1001, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blob_share_mode\', full_name=\'caffe.V1LayerParameter.blob_share_mode\', index=8,\n      number=1002, type=14, cpp_type=8, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V1LayerParameter.blobs_lr\', index=9,\n      number=7, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V1LayerParameter.weight_decay\', index=10,\n      number=8, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.V1LayerParameter.loss_weight\', index=11,\n      number=35, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.V1LayerParameter.accuracy_param\', index=12,\n      number=27, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.V1LayerParameter.argmax_param\', index=13,\n      number=23, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.V1LayerParameter.concat_param\', index=14,\n      number=9, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.V1LayerParameter.contrastive_loss_param\', index=15,\n      number=40, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.V1LayerParameter.convolution_param\', index=16,\n      number=10, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.V1LayerParameter.data_param\', index=17,\n      number=11, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.V1LayerParameter.dropout_param\', index=18,\n      number=12, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.V1LayerParameter.dummy_data_param\', index=19,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.V1LayerParameter.eltwise_param\', index=20,\n      number=24, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.V1LayerParameter.exp_param\', index=21,\n      number=41, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.V1LayerParameter.hdf5_data_param\', index=22,\n      number=13, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V1LayerParameter.hdf5_output_param\', index=23,\n      number=14, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.V1LayerParameter.hinge_loss_param\', index=24,\n      number=29, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.V1LayerParameter.image_data_param\', index=25,\n      number=15, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.V1LayerParameter.infogain_loss_param\', index=26,\n      number=16, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.V1LayerParameter.inner_product_param\', index=27,\n      number=17, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.V1LayerParameter.lrn_param\', index=28,\n      number=18, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.V1LayerParameter.memory_data_param\', index=29,\n      number=22, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.V1LayerParameter.mvn_param\', index=30,\n      number=34, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.V1LayerParameter.pooling_param\', index=31,\n      number=19, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.V1LayerParameter.power_param\', index=32,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.V1LayerParameter.relu_param\', index=33,\n      number=30, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.V1LayerParameter.sigmoid_param\', index=34,\n      number=38, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.V1LayerParameter.softmax_param\', index=35,\n      number=39, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.V1LayerParameter.slice_param\', index=36,\n      number=31, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.V1LayerParameter.tanh_param\', index=37,\n      number=37, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.V1LayerParameter.threshold_param\', index=38,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.V1LayerParameter.window_data_param\', index=39,\n      number=20, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.V1LayerParameter.transform_param\', index=40,\n      number=36, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.V1LayerParameter.loss_param\', index=41,\n      number=42, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.V1LayerParameter.layer\', index=42,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V1LAYERPARAMETER_LAYERTYPE,\n    _V1LAYERPARAMETER_DIMCHECKMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=11348,\n  serialized_end=13876,\n)\n\n\n_V0LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V0LayerParameter\',\n  full_name=\'caffe.V0LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V0LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V0LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.V0LayerParameter.num_output\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'biasterm\', full_name=\'caffe.V0LayerParameter.biasterm\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.V0LayerParameter.weight_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.V0LayerParameter.bias_filler\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.V0LayerParameter.pad\', index=6,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernelsize\', full_name=\'caffe.V0LayerParameter.kernelsize\', index=7,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.V0LayerParameter.group\', index=8,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.V0LayerParameter.stride\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.V0LayerParameter.pool\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.V0LayerParameter.dropout_ratio\', index=11,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.V0LayerParameter.local_size\', index=12,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.V0LayerParameter.alpha\', index=13,\n      number=14, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.V0LayerParameter.beta\', index=14,\n      number=15, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.75,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.V0LayerParameter.k\', index=15,\n      number=22, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.V0LayerParameter.source\', index=16,\n      number=16, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.V0LayerParameter.scale\', index=17,\n      number=17, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'meanfile\', full_name=\'caffe.V0LayerParameter.meanfile\', index=18,\n      number=18, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batchsize\', full_name=\'caffe.V0LayerParameter.batchsize\', index=19,\n      number=19, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'cropsize\', full_name=\'caffe.V0LayerParameter.cropsize\', index=20,\n      number=20, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.V0LayerParameter.mirror\', index=21,\n      number=21, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V0LayerParameter.blobs\', index=22,\n      number=50, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V0LayerParameter.blobs_lr\', index=23,\n      number=51, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V0LayerParameter.weight_decay\', index=24,\n      number=52, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.V0LayerParameter.rand_skip\', index=25,\n      number=53, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_threshold\', full_name=\'caffe.V0LayerParameter.det_fg_threshold\', index=26,\n      number=54, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_bg_threshold\', full_name=\'caffe.V0LayerParameter.det_bg_threshold\', index=27,\n      number=55, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_fraction\', full_name=\'caffe.V0LayerParameter.det_fg_fraction\', index=28,\n      number=56, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.25,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_context_pad\', full_name=\'caffe.V0LayerParameter.det_context_pad\', index=29,\n      number=58, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_crop_mode\', full_name=\'caffe.V0LayerParameter.det_crop_mode\', index=30,\n      number=59, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""warp"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_num\', full_name=\'caffe.V0LayerParameter.new_num\', index=31,\n      number=60, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_channels\', full_name=\'caffe.V0LayerParameter.new_channels\', index=32,\n      number=61, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.V0LayerParameter.new_height\', index=33,\n      number=62, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.V0LayerParameter.new_width\', index=34,\n      number=63, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle_images\', full_name=\'caffe.V0LayerParameter.shuffle_images\', index=35,\n      number=64, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.V0LayerParameter.concat_dim\', index=36,\n      number=65, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V0LayerParameter.hdf5_output_param\', index=37,\n      number=1001, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V0LAYERPARAMETER_POOLMETHOD,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=13879,\n  serialized_end=14900,\n)\n\n\n_PRELUPARAMETER = _descriptor.Descriptor(\n  name=\'PReLUParameter\',\n  full_name=\'caffe.PReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.PReLUParameter.filler\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channel_shared\', full_name=\'caffe.PReLUParameter.channel_shared\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=14902,\n  serialized_end=14989,\n)\n\n_BLOBPROTO.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_BLOBPROTOVECTOR.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_FILLERPARAMETER.fields_by_name[\'variance_norm\'].enum_type = _FILLERPARAMETER_VARIANCENORM\n_FILLERPARAMETER_VARIANCENORM.containing_type = _FILLERPARAMETER;\n_NETPARAMETER.fields_by_name[\'input_shape\'].message_type = _BLOBSHAPE\n_NETPARAMETER.fields_by_name[\'state\'].message_type = _NETSTATE\n_NETPARAMETER.fields_by_name[\'layer\'].message_type = _LAYERPARAMETER\n_NETPARAMETER.fields_by_name[\'layers\'].message_type = _V1LAYERPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'test_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'test_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'snapshot_format\'].enum_type = _SOLVERPARAMETER_SNAPSHOTFORMAT\n_SOLVERPARAMETER.fields_by_name[\'solver_mode\'].enum_type = _SOLVERPARAMETER_SOLVERMODE\n_SOLVERPARAMETER.fields_by_name[\'solver_type\'].enum_type = _SOLVERPARAMETER_SOLVERTYPE\n_SOLVERPARAMETER_SNAPSHOTFORMAT.containing_type = _SOLVERPARAMETER;\n_SOLVERPARAMETER_SOLVERMODE.containing_type = _SOLVERPARAMETER;\n_SOLVERPARAMETER_SOLVERTYPE.containing_type = _SOLVERPARAMETER;\n_SOLVERSTATE.fields_by_name[\'history\'].message_type = _BLOBPROTO\n_NETSTATE.fields_by_name[\'phase\'].enum_type = _PHASE\n_NETSTATERULE.fields_by_name[\'phase\'].enum_type = _PHASE\n_PARAMSPEC.fields_by_name[\'share_mode\'].enum_type = _PARAMSPEC_DIMCHECKMODE\n_PARAMSPEC_DIMCHECKMODE.containing_type = _PARAMSPEC;\n_LAYERPARAMETER.fields_by_name[\'phase\'].enum_type = _PHASE\n_LAYERPARAMETER.fields_by_name[\'param\'].message_type = _PARAMSPEC\n_LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'batch_norm_param\'].message_type = _BATCHNORMPARAMETER\n_LAYERPARAMETER.fields_by_name[\'bias_param\'].message_type = _BIASPARAMETER\n_LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'crop_param\'].message_type = _CROPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'elu_param\'].message_type = _ELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'embed_param\'].message_type = _EMBEDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'flatten_param\'].message_type = _FLATTENPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'input_param\'].message_type = _INPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'log_param\'].message_type = _LOGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_LAYERPARAMETER.fields_by_name[\'prelu_param\'].message_type = _PRELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'python_param\'].message_type = _PYTHONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reduction_param\'].message_type = _REDUCTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reshape_param\'].message_type = _RESHAPEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'scale_param\'].message_type = _SCALEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'spp_param\'].message_type = _SPPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tile_param\'].message_type = _TILEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_LOSSPARAMETER.fields_by_name[\'normalization\'].enum_type = _LOSSPARAMETER_NORMALIZATIONMODE\n_LOSSPARAMETER_NORMALIZATIONMODE.containing_type = _LOSSPARAMETER;\n_BIASPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'engine\'].enum_type = _CONVOLUTIONPARAMETER_ENGINE\n_CONVOLUTIONPARAMETER_ENGINE.containing_type = _CONVOLUTIONPARAMETER;\n_DATAPARAMETER.fields_by_name[\'backend\'].enum_type = _DATAPARAMETER_DB\n_DATAPARAMETER_DB.containing_type = _DATAPARAMETER;\n_DUMMYDATAPARAMETER.fields_by_name[\'data_filler\'].message_type = _FILLERPARAMETER\n_DUMMYDATAPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_ELTWISEPARAMETER.fields_by_name[\'operation\'].enum_type = _ELTWISEPARAMETER_ELTWISEOP\n_ELTWISEPARAMETER_ELTWISEOP.containing_type = _ELTWISEPARAMETER;\n_EMBEDPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_EMBEDPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_HINGELOSSPARAMETER.fields_by_name[\'norm\'].enum_type = _HINGELOSSPARAMETER_NORM\n_HINGELOSSPARAMETER_NORM.containing_type = _HINGELOSSPARAMETER;\n_INNERPRODUCTPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_INNERPRODUCTPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_INPUTPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_LRNPARAMETER.fields_by_name[\'norm_region\'].enum_type = _LRNPARAMETER_NORMREGION\n_LRNPARAMETER.fields_by_name[\'engine\'].enum_type = _LRNPARAMETER_ENGINE\n_LRNPARAMETER_NORMREGION.containing_type = _LRNPARAMETER;\n_LRNPARAMETER_ENGINE.containing_type = _LRNPARAMETER;\n_POOLINGPARAMETER.fields_by_name[\'pool\'].enum_type = _POOLINGPARAMETER_POOLMETHOD\n_POOLINGPARAMETER.fields_by_name[\'engine\'].enum_type = _POOLINGPARAMETER_ENGINE\n_POOLINGPARAMETER_POOLMETHOD.containing_type = _POOLINGPARAMETER;\n_POOLINGPARAMETER_ENGINE.containing_type = _POOLINGPARAMETER;\n_REDUCTIONPARAMETER.fields_by_name[\'operation\'].enum_type = _REDUCTIONPARAMETER_REDUCTIONOP\n_REDUCTIONPARAMETER_REDUCTIONOP.containing_type = _REDUCTIONPARAMETER;\n_RELUPARAMETER.fields_by_name[\'engine\'].enum_type = _RELUPARAMETER_ENGINE\n_RELUPARAMETER_ENGINE.containing_type = _RELUPARAMETER;\n_RESHAPEPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_SCALEPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_SCALEPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_SIGMOIDPARAMETER.fields_by_name[\'engine\'].enum_type = _SIGMOIDPARAMETER_ENGINE\n_SIGMOIDPARAMETER_ENGINE.containing_type = _SIGMOIDPARAMETER;\n_SOFTMAXPARAMETER.fields_by_name[\'engine\'].enum_type = _SOFTMAXPARAMETER_ENGINE\n_SOFTMAXPARAMETER_ENGINE.containing_type = _SOFTMAXPARAMETER;\n_TANHPARAMETER.fields_by_name[\'engine\'].enum_type = _TANHPARAMETER_ENGINE\n_TANHPARAMETER_ENGINE.containing_type = _TANHPARAMETER;\n_SPPPARAMETER.fields_by_name[\'pool\'].enum_type = _SPPPARAMETER_POOLMETHOD\n_SPPPARAMETER.fields_by_name[\'engine\'].enum_type = _SPPPARAMETER_ENGINE\n_SPPPARAMETER_POOLMETHOD.containing_type = _SPPPARAMETER;\n_SPPPARAMETER_ENGINE.containing_type = _SPPPARAMETER;\n_V1LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'type\'].enum_type = _V1LAYERPARAMETER_LAYERTYPE\n_V1LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V1LAYERPARAMETER.fields_by_name[\'blob_share_mode\'].enum_type = _V1LAYERPARAMETER_DIMCHECKMODE\n_V1LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'layer\'].message_type = _V0LAYERPARAMETER\n_V1LAYERPARAMETER_LAYERTYPE.containing_type = _V1LAYERPARAMETER;\n_V1LAYERPARAMETER_DIMCHECKMODE.containing_type = _V1LAYERPARAMETER;\n_V0LAYERPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'pool\'].enum_type = _V0LAYERPARAMETER_POOLMETHOD\n_V0LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V0LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V0LAYERPARAMETER_POOLMETHOD.containing_type = _V0LAYERPARAMETER;\n_PRELUPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'BlobShape\'] = _BLOBSHAPE\nDESCRIPTOR.message_types_by_name[\'BlobProto\'] = _BLOBPROTO\nDESCRIPTOR.message_types_by_name[\'BlobProtoVector\'] = _BLOBPROTOVECTOR\nDESCRIPTOR.message_types_by_name[\'Datum\'] = _DATUM\nDESCRIPTOR.message_types_by_name[\'FillerParameter\'] = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'NetParameter\'] = _NETPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverParameter\'] = _SOLVERPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverState\'] = _SOLVERSTATE\nDESCRIPTOR.message_types_by_name[\'NetState\'] = _NETSTATE\nDESCRIPTOR.message_types_by_name[\'NetStateRule\'] = _NETSTATERULE\nDESCRIPTOR.message_types_by_name[\'ParamSpec\'] = _PARAMSPEC\nDESCRIPTOR.message_types_by_name[\'LayerParameter\'] = _LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'TransformationParameter\'] = _TRANSFORMATIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'LossParameter\'] = _LOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'AccuracyParameter\'] = _ACCURACYPARAMETER\nDESCRIPTOR.message_types_by_name[\'ArgMaxParameter\'] = _ARGMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConcatParameter\'] = _CONCATPARAMETER\nDESCRIPTOR.message_types_by_name[\'BatchNormParameter\'] = _BATCHNORMPARAMETER\nDESCRIPTOR.message_types_by_name[\'BiasParameter\'] = _BIASPARAMETER\nDESCRIPTOR.message_types_by_name[\'ContrastiveLossParameter\'] = _CONTRASTIVELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConvolutionParameter\'] = _CONVOLUTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'CropParameter\'] = _CROPPARAMETER\nDESCRIPTOR.message_types_by_name[\'DataParameter\'] = _DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'DropoutParameter\'] = _DROPOUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'DummyDataParameter\'] = _DUMMYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'EltwiseParameter\'] = _ELTWISEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ELUParameter\'] = _ELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'EmbedParameter\'] = _EMBEDPARAMETER\nDESCRIPTOR.message_types_by_name[\'ExpParameter\'] = _EXPPARAMETER\nDESCRIPTOR.message_types_by_name[\'FlattenParameter\'] = _FLATTENPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5DataParameter\'] = _HDF5DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5OutputParameter\'] = _HDF5OUTPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'HingeLossParameter\'] = _HINGELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ImageDataParameter\'] = _IMAGEDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'InfogainLossParameter\'] = _INFOGAINLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'InnerProductParameter\'] = _INNERPRODUCTPARAMETER\nDESCRIPTOR.message_types_by_name[\'InputParameter\'] = _INPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'LogParameter\'] = _LOGPARAMETER\nDESCRIPTOR.message_types_by_name[\'LRNParameter\'] = _LRNPARAMETER\nDESCRIPTOR.message_types_by_name[\'MemoryDataParameter\'] = _MEMORYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'MVNParameter\'] = _MVNPARAMETER\nDESCRIPTOR.message_types_by_name[\'PoolingParameter\'] = _POOLINGPARAMETER\nDESCRIPTOR.message_types_by_name[\'PowerParameter\'] = _POWERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PythonParameter\'] = _PYTHONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReductionParameter\'] = _REDUCTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReLUParameter\'] = _RELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReshapeParameter\'] = _RESHAPEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ScaleParameter\'] = _SCALEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SigmoidParameter\'] = _SIGMOIDPARAMETER\nDESCRIPTOR.message_types_by_name[\'SliceParameter\'] = _SLICEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SoftmaxParameter\'] = _SOFTMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'TanHParameter\'] = _TANHPARAMETER\nDESCRIPTOR.message_types_by_name[\'TileParameter\'] = _TILEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ThresholdParameter\'] = _THRESHOLDPARAMETER\nDESCRIPTOR.message_types_by_name[\'WindowDataParameter\'] = _WINDOWDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'SPPParameter\'] = _SPPPARAMETER\nDESCRIPTOR.message_types_by_name[\'V1LayerParameter\'] = _V1LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'V0LayerParameter\'] = _V0LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PReLUParameter\'] = _PRELUPARAMETER\n\nclass BlobShape(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BLOBSHAPE\n\n  # @@protoc_insertion_point(class_scope:caffe.BlobShape)\n\nclass BlobProto(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BLOBPROTO\n\n  # @@protoc_insertion_point(class_scope:caffe.BlobProto)\n\nclass BlobProtoVector(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BLOBPROTOVECTOR\n\n  # @@protoc_insertion_point(class_scope:caffe.BlobProtoVector)\n\nclass Datum(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DATUM\n\n  # @@protoc_insertion_point(class_scope:caffe.Datum)\n\nclass FillerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _FILLERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.FillerParameter)\n\nclass NetParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _NETPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.NetParameter)\n\nclass SolverParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SOLVERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SolverParameter)\n\nclass SolverState(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SOLVERSTATE\n\n  # @@protoc_insertion_point(class_scope:caffe.SolverState)\n\nclass NetState(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _NETSTATE\n\n  # @@protoc_insertion_point(class_scope:caffe.NetState)\n\nclass NetStateRule(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _NETSTATERULE\n\n  # @@protoc_insertion_point(class_scope:caffe.NetStateRule)\n\nclass ParamSpec(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _PARAMSPEC\n\n  # @@protoc_insertion_point(class_scope:caffe.ParamSpec)\n\nclass LayerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LAYERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LayerParameter)\n\nclass TransformationParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _TRANSFORMATIONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.TransformationParameter)\n\nclass LossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LossParameter)\n\nclass AccuracyParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ACCURACYPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.AccuracyParameter)\n\nclass ArgMaxParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ARGMAXPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ArgMaxParameter)\n\nclass ConcatParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CONCATPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ConcatParameter)\n\nclass BatchNormParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BATCHNORMPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.BatchNormParameter)\n\nclass BiasParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BIASPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.BiasParameter)\n\nclass ContrastiveLossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CONTRASTIVELOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ContrastiveLossParameter)\n\nclass ConvolutionParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CONVOLUTIONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ConvolutionParameter)\n\nclass CropParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CROPPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.CropParameter)\n\nclass DataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.DataParameter)\n\nclass DropoutParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DROPOUTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.DropoutParameter)\n\nclass DummyDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DUMMYDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.DummyDataParameter)\n\nclass EltwiseParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ELTWISEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.EltwiseParameter)\n\nclass ELUParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ELUPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ELUParameter)\n\nclass EmbedParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _EMBEDPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.EmbedParameter)\n\nclass ExpParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _EXPPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ExpParameter)\n\nclass FlattenParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _FLATTENPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.FlattenParameter)\n\nclass HDF5DataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _HDF5DATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.HDF5DataParameter)\n\nclass HDF5OutputParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _HDF5OUTPUTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.HDF5OutputParameter)\n\nclass HingeLossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _HINGELOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.HingeLossParameter)\n\nclass ImageDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _IMAGEDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ImageDataParameter)\n\nclass InfogainLossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _INFOGAINLOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.InfogainLossParameter)\n\nclass InnerProductParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _INNERPRODUCTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.InnerProductParameter)\n\nclass InputParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _INPUTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.InputParameter)\n\nclass LogParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LOGPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LogParameter)\n\nclass LRNParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LRNPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LRNParameter)\n\nclass MemoryDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _MEMORYDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.MemoryDataParameter)\n\nclass MVNParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _MVNPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.MVNParameter)\n\nclass PoolingParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _POOLINGPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PoolingParameter)\n\nclass PowerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _POWERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PowerParameter)\n\nclass PythonParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _PYTHONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PythonParameter)\n\nclass ReductionParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _REDUCTIONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ReductionParameter)\n\nclass ReLUParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _RELUPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ReLUParameter)\n\nclass ReshapeParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _RESHAPEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ReshapeParameter)\n\nclass ScaleParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SCALEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ScaleParameter)\n\nclass SigmoidParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SIGMOIDPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SigmoidParameter)\n\nclass SliceParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SLICEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SliceParameter)\n\nclass SoftmaxParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SOFTMAXPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SoftmaxParameter)\n\nclass TanHParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _TANHPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.TanHParameter)\n\nclass TileParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _TILEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.TileParameter)\n\nclass ThresholdParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _THRESHOLDPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ThresholdParameter)\n\nclass WindowDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _WINDOWDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.WindowDataParameter)\n\nclass SPPParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SPPPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SPPParameter)\n\nclass V1LayerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _V1LAYERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.V1LayerParameter)\n\nclass V0LayerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _V0LAYERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.V0LayerParameter)\n\nclass PReLUParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _PRELUPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PReLUParameter)\n\n\n_BLOBSHAPE.fields_by_name[\'dim\'].has_options = True\n_BLOBSHAPE.fields_by_name[\'dim\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'data\'].has_options = True\n_BLOBPROTO.fields_by_name[\'data\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'diff\'].has_options = True\n_BLOBPROTO.fields_by_name[\'diff\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'double_data\'].has_options = True\n_BLOBPROTO.fields_by_name[\'double_data\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'double_diff\'].has_options = True\n_BLOBPROTO.fields_by_name[\'double_diff\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n# @@protoc_insertion_point(module_scope)\n'"
caffe-tensorflow/kaffe/caffe/resolver.py,0,"b""import sys\n\nSHARED_CAFFE_RESOLVER = None\n\nclass CaffeResolver(object):\n    def __init__(self):\n        self.import_caffe()\n\n    def import_caffe(self):\n        self.caffe = None\n        try:\n            # Try to import PyCaffe first\n            import caffe\n            self.caffe = caffe\n        except ImportError:\n            # Fall back to the protobuf implementation\n            from . import caffepb\n            self.caffepb = caffepb\n            show_fallback_warning()\n        if self.caffe:\n            # Use the protobuf code from the imported distribution.\n            # This way, Caffe variants with custom layers will work.\n            self.caffepb = self.caffe.proto.caffe_pb2\n        self.NetParameter = self.caffepb.NetParameter\n\n    def has_pycaffe(self):\n        return self.caffe is not None\n\ndef get_caffe_resolver():\n    global SHARED_CAFFE_RESOLVER\n    if SHARED_CAFFE_RESOLVER is None:\n        SHARED_CAFFE_RESOLVER = CaffeResolver()\n    return SHARED_CAFFE_RESOLVER\n\ndef has_pycaffe():\n    return get_caffe_resolver().has_pycaffe()\n\ndef show_fallback_warning():\n    msg = '''\n------------------------------------------------------------\n    WARNING: PyCaffe not found!\n    Falling back to a pure protocol buffer implementation.\n    * Conversions will be drastically slower.\n    * This backend is UNTESTED!\n------------------------------------------------------------\n\n'''\n    sys.stderr.write(msg)\n"""
caffe-tensorflow/kaffe/tensorflow/__init__.py,0,b'from .transformer import TensorFlowTransformer\nfrom .network import Network\n'
caffe-tensorflow/kaffe/tensorflow/network.py,26,"b""import numpy as np\nimport tensorflow as tf\n\nDEFAULT_PADDING = 'SAME'\n\n\ndef layer(op):\n    '''Decorator for composable network layers.'''\n\n    def layer_decorated(self, *args, **kwargs):\n        # Automatically set a name if not provided.\n        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n        # Figure out the layer inputs.\n        if len(self.terminals) == 0:\n            raise RuntimeError('No input variables found for layer %s.' % name)\n        elif len(self.terminals) == 1:\n            layer_input = self.terminals[0]\n        else:\n            layer_input = list(self.terminals)\n        # Perform the operation and get the output.\n        layer_output = op(self, layer_input, *args, **kwargs)\n        # Add to layer LUT.\n        self.layers[name] = layer_output\n        # This output is now the input for the next layer.\n        self.feed(layer_output)\n        # Return self for chained calls.\n        return self\n\n    return layer_decorated\n\n\nclass Network(object):\n\n    def __init__(self, inputs, trainable=True):\n        # The input nodes for this network\n        self.inputs = inputs\n        # The current list of terminal nodes\n        self.terminals = []\n        # Mapping from layer names to layers\n        self.layers = dict(inputs)\n        # If true, the resulting variables are set as trainable\n        self.trainable = trainable\n        # Switch variable for dropout\n        self.use_dropout = tf.placeholder_with_default(tf.constant(1.0),\n                                                       shape=[],\n                                                       name='use_dropout')\n        self.setup()\n\n    def setup(self):\n        '''Construct the network. '''\n        raise NotImplementedError('Must be implemented by the subclass.')\n\n    def load(self, data_path, session, ignore_missing=False):\n        '''Load network weights.\n        data_path: The path to the numpy-serialized network weights\n        session: The current TensorFlow session\n        ignore_missing: If true, serialized weights for missing layers are ignored.\n        '''\n        data_dict = np.load(data_path).item()\n        for op_name in data_dict:\n            with tf.variable_scope(op_name, reuse=True):\n                for param_name, data in data_dict[op_name].iteritems():\n                    try:\n                        var = tf.get_variable(param_name)\n                        session.run(var.assign(data))\n                    except ValueError:\n                        if not ignore_missing:\n                            raise\n\n    def feed(self, *args):\n        '''Set the input(s) for the next operation by replacing the terminal nodes.\n        The arguments can be either layer names or the actual layers.\n        '''\n        assert len(args) != 0\n        self.terminals = []\n        for fed_layer in args:\n            if isinstance(fed_layer, basestring):\n                try:\n                    fed_layer = self.layers[fed_layer]\n                except KeyError:\n                    raise KeyError('Unknown layer name fed: %s' % fed_layer)\n            self.terminals.append(fed_layer)\n        return self\n\n    def get_output(self):\n        '''Returns the current network output.'''\n        return self.terminals[-1]\n\n    def get_unique_name(self, prefix):\n        '''Returns an index-suffixed unique name for the given prefix.\n        This is used for auto-generating layer names based on the type-prefix.\n        '''\n        ident = sum(t.startswith(prefix) for t, _ in self.layers.items()) + 1\n        return '%s_%d' % (prefix, ident)\n\n    def make_var(self, name, shape):\n        '''Creates a new TensorFlow variable.'''\n        return tf.get_variable(name, shape, trainable=self.trainable)\n\n    def validate_padding(self, padding):\n        '''Verifies that the padding is one of the supported ones.'''\n        assert padding in ('SAME', 'VALID')\n\n    @layer\n    def conv(self,\n             input,\n             k_h,\n             k_w,\n             c_o,\n             s_h,\n             s_w,\n             name,\n             relu=True,\n             padding=DEFAULT_PADDING,\n             group=1,\n             biased=True):\n        # Verify that the padding is acceptable\n        self.validate_padding(padding)\n        # Get the number of channels in the input\n        c_i = input.get_shape()[-1]\n        # Verify that the grouping parameter is valid\n        assert c_i % group == 0\n        assert c_o % group == 0\n        # Convolution for a given input and kernel\n        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n        with tf.variable_scope(name) as scope:\n            kernel = self.make_var('weights', shape=[k_h, k_w, c_i / group, c_o])\n            if group == 1:\n                # This is the common-case. Convolve the input without any further complications.\n                output = convolve(input, kernel)\n            else:\n                # Split the input into groups and then convolve each of them independently\n                input_groups = tf.split(3, group, input)\n                kernel_groups = tf.split(3, group, kernel)\n                output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n                # Concatenate the groups\n                output = tf.concat(3, output_groups)\n            # Add the biases\n            if biased:\n                biases = self.make_var('biases', [c_o])\n                output = tf.nn.bias_add(output, biases)\n            if relu:\n                # ReLU non-linearity\n                output = tf.nn.relu(output, name=scope.name)\n            return output\n\n    @layer\n    def relu(self, input, name):\n        return tf.nn.relu(input, name=name)\n\n    @layer\n    def max_pool(self, input, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n        self.validate_padding(padding)\n        return tf.nn.max_pool(input,\n                              ksize=[1, k_h, k_w, 1],\n                              strides=[1, s_h, s_w, 1],\n                              padding=padding,\n                              name=name)\n\n    @layer\n    def avg_pool(self, input, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n        self.validate_padding(padding)\n        return tf.nn.avg_pool(input,\n                              ksize=[1, k_h, k_w, 1],\n                              strides=[1, s_h, s_w, 1],\n                              padding=padding,\n                              name=name)\n\n    @layer\n    def lrn(self, input, radius, alpha, beta, name, bias=1.0):\n        return tf.nn.local_response_normalization(input,\n                                                  depth_radius=radius,\n                                                  alpha=alpha,\n                                                  beta=beta,\n                                                  bias=bias,\n                                                  name=name)\n\n    @layer\n    def concat(self, inputs, axis, name):\n        return tf.concat(concat_dim=axis, values=inputs, name=name)\n\n    @layer\n    def add(self, inputs, name):\n        return tf.add_n(inputs, name=name)\n\n    @layer\n    def fc(self, input, num_out, name, relu=True):\n        with tf.variable_scope(name) as scope:\n            input_shape = input.get_shape()\n            if input_shape.ndims == 4:\n                # The input is spatial. Vectorize it first.\n                dim = 1\n                for d in input_shape[1:].as_list():\n                    dim *= d\n                feed_in = tf.reshape(input, [-1, dim])\n            else:\n                feed_in, dim = (input, input_shape[-1].value)\n            weights = self.make_var('weights', shape=[dim, num_out])\n            biases = self.make_var('biases', [num_out])\n            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n            fc = op(feed_in, weights, biases, name=scope.name)\n            return fc\n\n    @layer\n    def softmax(self, input, name):\n        input_shape = map(lambda v: v.value, input.get_shape())\n        if len(input_shape) > 2:\n            # For certain models (like NiN), the singleton spatial dimensions\n            # need to be explicitly squeezed, since they're not broadcast-able\n            # in TensorFlow's NHWC ordering (unlike Caffe's NCHW).\n            if input_shape[1] == 1 and input_shape[2] == 1:\n                input = tf.squeeze(input, squeeze_dims=[1, 2])\n            else:\n                raise ValueError('Rank 2 tensor input expected for softmax!')\n        return tf.nn.softmax(input, name=name)\n\n    @layer\n    def batch_normalization(self, input, name, scale_offset=True, relu=False):\n        # NOTE: Currently, only inference is supported\n        with tf.variable_scope(name) as scope:\n            shape = [input.get_shape()[-1]]\n            if scale_offset:\n                scale = self.make_var('scale', shape=shape)\n                offset = self.make_var('offset', shape=shape)\n            else:\n                scale, offset = (None, None)\n            output = tf.nn.batch_normalization(\n                input,\n                mean=self.make_var('mean', shape=shape),\n                variance=self.make_var('variance', shape=shape),\n                offset=offset,\n                scale=scale,\n                # TODO: This is the default Caffe batch norm eps\n                # Get the actual eps from parameters\n                variance_epsilon=1e-5,\n                name=name)\n            if relu:\n                output = tf.nn.relu(output)\n            return output\n\n    @layer\n    def dropout(self, input, keep_prob, name):\n        keep = 1 - self.use_dropout + (self.use_dropout * keep_prob)\n        return tf.nn.dropout(input, keep, name=name)\n"""
caffe-tensorflow/kaffe/tensorflow/transformer.py,0,"b'import numpy as np\n\nfrom ..errors import KaffeError, print_stderr\nfrom ..graph import GraphBuilder, NodeMapper\nfrom ..layers import NodeKind\nfrom ..transformers import (DataInjector, DataReshaper, NodeRenamer, ReLUFuser,\n                            BatchNormScaleBiasFuser, BatchNormPreprocessor, ParameterNamer)\n\nfrom . import network\n\n\ndef get_padding_type(kernel_params, input_shape, output_shape):\n    \'\'\'Translates Caffe\'s numeric padding to one of (\'SAME\', \'VALID\').\n    Caffe supports arbitrary padding values, while TensorFlow only\n    supports \'SAME\' and \'VALID\' modes. So, not all Caffe paddings\n    can be translated to TensorFlow. There are some subtleties to\n    how the padding edge-cases are handled. These are described here:\n    https://github.com/Yangqing/caffe2/blob/master/caffe2/proto/caffe2_legacy.proto\n    \'\'\'\n    k_h, k_w, s_h, s_w, p_h, p_w = kernel_params\n    s_o_h = np.ceil(input_shape.height / float(s_h))\n    s_o_w = np.ceil(input_shape.width / float(s_w))\n    if (output_shape.height == s_o_h) and (output_shape.width == s_o_w):\n        return \'SAME\'\n    v_o_h = np.ceil((input_shape.height - k_h + 1.0) / float(s_h))\n    v_o_w = np.ceil((input_shape.width - k_w + 1.0) / float(s_w))\n    if (output_shape.height == v_o_h) and (output_shape.width == v_o_w):\n        return \'VALID\'\n    return None\n\n\nclass TensorFlowNode(object):\n    \'\'\'An intermediate representation for TensorFlow operations.\'\'\'\n\n    def __init__(self, op, *args, **kwargs):\n        # A string corresponding to the TensorFlow operation\n        self.op = op\n        # Positional arguments for the operation\n        self.args = args\n        # Keyword arguments for the operation\n        self.kwargs = list(kwargs.items())\n        # The source Caffe node\n        self.node = None\n\n    def format(self, arg):\n        \'\'\'Returns a string representation for the given value.\'\'\'\n        return ""\'%s\'"" % arg if isinstance(arg, basestring) else str(arg)\n\n    def pair(self, key, value):\n        \'\'\'Returns key=formatted(value).\'\'\'\n        return \'%s=%s\' % (key, self.format(value))\n\n    def emit(self):\n        \'\'\'Emits the Python source for this node.\'\'\'\n        # Format positional arguments\n        args = map(self.format, self.args)\n        # Format any keyword arguments\n        if self.kwargs:\n            args += [self.pair(k, v) for k, v in self.kwargs]\n        # Set the node name\n        args.append(self.pair(\'name\', self.node.name))\n        args = \', \'.join(args)\n        return \'%s(%s)\' % (self.op, args)\n\n\nclass MaybeActivated(object):\n\n    def __init__(self, node, default=True):\n        self.inject_kwargs = {}\n        if node.metadata.get(\'relu\', False) != default:\n            self.inject_kwargs[\'relu\'] = not default\n\n    def __call__(self, *args, **kwargs):\n        kwargs.update(self.inject_kwargs)\n        return TensorFlowNode(*args, **kwargs)\n\n\nclass TensorFlowMapper(NodeMapper):\n\n    def get_kernel_params(self, node):\n        kernel_params = node.layer.kernel_parameters\n        input_shape = node.get_only_parent().output_shape\n        padding = get_padding_type(kernel_params, input_shape, node.output_shape)\n        # Only emit the padding if it\'s not the default value.\n        padding = {\'padding\': padding} if padding != network.DEFAULT_PADDING else {}\n        return (kernel_params, padding)\n\n    def map_convolution(self, node):\n        (kernel_params, kwargs) = self.get_kernel_params(node)\n        h = kernel_params.kernel_h\n        w = kernel_params.kernel_w\n        c_o = node.output_shape[1]\n        c_i = node.parents[0].output_shape[1]\n        group = node.parameters.group\n        if group != 1:\n            kwargs[\'group\'] = group\n        if not node.parameters.bias_term:\n            kwargs[\'biased\'] = False\n        assert kernel_params.kernel_h == h\n        assert kernel_params.kernel_w == w\n        return MaybeActivated(node)(\'conv\', kernel_params.kernel_h, kernel_params.kernel_w, c_o,\n                                    kernel_params.stride_h, kernel_params.stride_w, **kwargs)\n\n    def map_relu(self, node):\n        return TensorFlowNode(\'relu\')\n\n    def map_interp(self, node):\n        return TensorFlowNode(\'relu\')\n\n    def map_pooling(self, node):\n        pool_type = node.parameters.pool\n        if pool_type == 0:\n            pool_op = \'max_pool\'\n        elif pool_type == 1:\n            pool_op = \'avg_pool\'\n        else:\n            # Stochastic pooling, for instance.\n            raise KaffeError(\'Unsupported pooling type.\')\n        (kernel_params, padding) = self.get_kernel_params(node)\n        return TensorFlowNode(pool_op, kernel_params.kernel_h, kernel_params.kernel_w,\n                              kernel_params.stride_h, kernel_params.stride_w, **padding)\n\n    def map_inner_product(self, node):\n        #TODO: Axis\n        assert node.parameters.axis == 1\n        #TODO: Unbiased\n        assert node.parameters.bias_term == True\n        return MaybeActivated(node)(\'fc\', node.parameters.num_output)\n\n    def map_softmax(self, node):\n        return TensorFlowNode(\'softmax\')\n\n    def map_lrn(self, node):\n        params = node.parameters\n        # The window size must be an odd value. For a window\n        # size of (2*n+1), TensorFlow defines depth_radius = n.\n        assert params.local_size % 2 == 1\n        # Caffe scales by (alpha/(2*n+1)), whereas TensorFlow\n        # just scales by alpha (as does Krizhevsky\'s paper).\n        # We\'ll account for that here.\n        alpha = params.alpha / float(params.local_size)\n        return TensorFlowNode(\'lrn\', int(params.local_size / 2), alpha, params.beta)\n\n    def map_concat(self, node):\n        axis = (2, 3, 1, 0)[node.parameters.axis]\n        return TensorFlowNode(\'concat\', axis)\n\n    def map_dropout(self, node):\n        return TensorFlowNode(\'dropout\', node.parameters.dropout_ratio)\n\n    def map_batch_norm(self, node):\n        scale_offset = len(node.data) == 4\n        kwargs = {} if scale_offset else {\'scale_offset\': False}\n        return MaybeActivated(node, default=False)(\'batch_normalization\', **kwargs)\n\n    def map_bn(self, node):\n        scale_offset = len(node.data) == 4\n        print node\n        kwargs = {} if scale_offset else {\'scale_offset\': False}\n        return MaybeActivated(node, default=False)(\'batch_normalization\', **kwargs)\n\n    def map_eltwise(self, node):\n        operations = {0: \'multiply\', 1: \'add\', 2: \'max\'}\n        op_code = node.parameters.operation\n        try:\n            return TensorFlowNode(operations[op_code])\n        except KeyError:\n            raise KaffeError(\'Unknown elementwise operation: {}\'.format(op_code))\n\n    def commit(self, chains):\n        return chains\n\n\nclass TensorFlowEmitter(object):\n\n    def __init__(self, tab=None):\n        self.tab = tab or \' \' * 4\n        self.prefix = \'\'\n\n    def indent(self):\n        self.prefix += self.tab\n\n    def outdent(self):\n        self.prefix = self.prefix[:-len(self.tab)]\n\n    def statement(self, s):\n        return self.prefix + s + \'\\n\'\n\n    def emit_imports(self):\n        return self.statement(\'from kaffe.tensorflow import Network\\n\')\n\n    def emit_class_def(self, name):\n        return self.statement(\'class %s(Network):\' % (name))\n\n    def emit_setup_def(self):\n        return self.statement(\'def setup(self):\')\n\n    def emit_parents(self, chain):\n        assert len(chain)\n        s = \'(self.feed(\'\n        sep = \', \\n\' + self.prefix + (\' \' * len(s))\n        s += sep.join([""\'%s\'"" % parent.name for parent in chain[0].node.parents])\n        return self.statement(s + \')\')\n\n    def emit_node(self, node):\n        return self.statement(\' \' * 5 + \'.\' + node.emit())\n\n    def emit(self, name, chains):\n        s = self.emit_imports()\n        s += self.emit_class_def(name)\n        self.indent()\n        s += self.emit_setup_def()\n        self.indent()\n        blocks = []\n        for chain in chains:\n            b = \'\'\n            b += self.emit_parents(chain)\n            for node in chain:\n                b += self.emit_node(node)\n            blocks.append(b[:-1] + \')\')\n        s = s + \'\\n\\n\'.join(blocks)\n        return s\n\n\nclass TensorFlowTransformer(object):\n\n    def __init__(self, def_path, data_path, verbose=True, phase=\'test\'):\n        self.verbose = verbose\n        self.phase = phase\n        self.load(def_path, data_path, phase)\n        self.params = None\n        self.source = None\n\n    def load(self, def_path, data_path, phase):\n        # Build the graph\n        graph = GraphBuilder(def_path, phase).build()\n\n        if data_path is not None:\n            # Load and associate learned parameters\n            graph = DataInjector(def_path, data_path)(graph)\n\n        # Transform the graph\n        transformers = [\n            # Fuse split batch normalization layers\n            BatchNormScaleBiasFuser(),\n\n            # Fuse ReLUs\n            # TODO: Move non-linearity application to layer wrapper, allowing\n            # any arbitrary operation to be optionally activated.\n            ReLUFuser(allowed_parent_types=[NodeKind.Convolution, NodeKind.InnerProduct,\n                                            NodeKind.BatchNorm]),\n\n            # Rename nodes\n            # Slashes are used for scoping in TensorFlow. Replace slashes\n            # in node names with underscores.\n            # (Caffe\'s GoogLeNet implementation uses slashes)\n            NodeRenamer(lambda node: node.name.replace(\'/\', \'_\'))\n        ]\n        self.graph = graph.transformed(transformers)\n\n        # Display the graph\n        if self.verbose:\n            print_stderr(self.graph)\n\n    def transform_data(self):\n        if self.params is None:\n            transformers = [\n\n                # Reshape the parameters to TensorFlow\'s ordering\n                DataReshaper({\n                    # (c_o, c_i, h, w) -> (h, w, c_i, c_o)\n                    NodeKind.Convolution: (2, 3, 1, 0),\n\n                    # (c_o, c_i) -> (c_i, c_o)\n                    NodeKind.InnerProduct: (1, 0)\n                }),\n\n                # Pre-process batch normalization data\n                BatchNormPreprocessor(),\n\n                # Convert parameters to dictionaries\n                ParameterNamer(),\n            ]\n            self.graph = self.graph.transformed(transformers)\n            self.params = {node.name: node.data for node in self.graph.nodes if node.data}\n        return self.params\n\n    def transform_source(self):\n        if self.source is None:\n            mapper = TensorFlowMapper(self.graph)\n            chains = mapper.map()\n            emitter = TensorFlowEmitter()\n            self.source = emitter.emit(self.graph.name, chains)\n        return self.source\n'"
caffe-tensorflow/examples/imagenet/models/__init__.py,0,b'from helper import *\n'
caffe-tensorflow/examples/imagenet/models/alexnet.py,0,"b""from kaffe.tensorflow import Network\n\nclass AlexNet(Network):\n    def setup(self):\n        (self.feed('data')\n             .conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')\n             .lrn(2, 2e-05, 0.75, name='norm1')\n             .max_pool(3, 3, 2, 2, padding='VALID', name='pool1')\n             .conv(5, 5, 256, 1, 1, group=2, name='conv2')\n             .lrn(2, 2e-05, 0.75, name='norm2')\n             .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n             .conv(3, 3, 384, 1, 1, name='conv3')\n             .conv(3, 3, 384, 1, 1, group=2, name='conv4')\n             .conv(3, 3, 256, 1, 1, group=2, name='conv5')\n             .max_pool(3, 3, 2, 2, padding='VALID', name='pool5')\n             .fc(4096, name='fc6')\n             .fc(4096, name='fc7')\n             .fc(1000, relu=False, name='fc8')\n             .softmax(name='prob'))\n"""
caffe-tensorflow/examples/imagenet/models/caffenet.py,0,"b""from kaffe.tensorflow import Network\n\nclass CaffeNet(Network):\n    def setup(self):\n        (self.feed('data')\n             .conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')\n             .max_pool(3, 3, 2, 2, padding='VALID', name='pool1')\n             .lrn(2, 2e-05, 0.75, name='norm1')\n             .conv(5, 5, 256, 1, 1, group=2, name='conv2')\n             .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n             .lrn(2, 2e-05, 0.75, name='norm2')\n             .conv(3, 3, 384, 1, 1, name='conv3')\n             .conv(3, 3, 384, 1, 1, group=2, name='conv4')\n             .conv(3, 3, 256, 1, 1, group=2, name='conv5')\n             .max_pool(3, 3, 2, 2, padding='VALID', name='pool5')\n             .fc(4096, name='fc6')\n             .fc(4096, name='fc7')\n             .fc(1000, relu=False, name='fc8')\n             .softmax(name='prob'))\n"""
caffe-tensorflow/examples/imagenet/models/googlenet.py,0,"b""from kaffe.tensorflow import Network\n\nclass GoogleNet(Network):\n    def setup(self):\n        (self.feed('data')\n             .conv(7, 7, 64, 2, 2, name='conv1_7x7_s2')\n             .max_pool(3, 3, 2, 2, name='pool1_3x3_s2')\n             .lrn(2, 2e-05, 0.75, name='pool1_norm1')\n             .conv(1, 1, 64, 1, 1, name='conv2_3x3_reduce')\n             .conv(3, 3, 192, 1, 1, name='conv2_3x3')\n             .lrn(2, 2e-05, 0.75, name='conv2_norm2')\n             .max_pool(3, 3, 2, 2, name='pool2_3x3_s2')\n             .conv(1, 1, 64, 1, 1, name='inception_3a_1x1'))\n\n        (self.feed('pool2_3x3_s2')\n             .conv(1, 1, 96, 1, 1, name='inception_3a_3x3_reduce')\n             .conv(3, 3, 128, 1, 1, name='inception_3a_3x3'))\n\n        (self.feed('pool2_3x3_s2')\n             .conv(1, 1, 16, 1, 1, name='inception_3a_5x5_reduce')\n             .conv(5, 5, 32, 1, 1, name='inception_3a_5x5'))\n\n        (self.feed('pool2_3x3_s2')\n             .max_pool(3, 3, 1, 1, name='inception_3a_pool')\n             .conv(1, 1, 32, 1, 1, name='inception_3a_pool_proj'))\n\n        (self.feed('inception_3a_1x1',\n                   'inception_3a_3x3',\n                   'inception_3a_5x5',\n                   'inception_3a_pool_proj')\n             .concat(3, name='inception_3a_output')\n             .conv(1, 1, 128, 1, 1, name='inception_3b_1x1'))\n\n        (self.feed('inception_3a_output')\n             .conv(1, 1, 128, 1, 1, name='inception_3b_3x3_reduce')\n             .conv(3, 3, 192, 1, 1, name='inception_3b_3x3'))\n\n        (self.feed('inception_3a_output')\n             .conv(1, 1, 32, 1, 1, name='inception_3b_5x5_reduce')\n             .conv(5, 5, 96, 1, 1, name='inception_3b_5x5'))\n\n        (self.feed('inception_3a_output')\n             .max_pool(3, 3, 1, 1, name='inception_3b_pool')\n             .conv(1, 1, 64, 1, 1, name='inception_3b_pool_proj'))\n\n        (self.feed('inception_3b_1x1',\n                   'inception_3b_3x3',\n                   'inception_3b_5x5',\n                   'inception_3b_pool_proj')\n             .concat(3, name='inception_3b_output')\n             .max_pool(3, 3, 2, 2, name='pool3_3x3_s2')\n             .conv(1, 1, 192, 1, 1, name='inception_4a_1x1'))\n\n        (self.feed('pool3_3x3_s2')\n             .conv(1, 1, 96, 1, 1, name='inception_4a_3x3_reduce')\n             .conv(3, 3, 208, 1, 1, name='inception_4a_3x3'))\n\n        (self.feed('pool3_3x3_s2')\n             .conv(1, 1, 16, 1, 1, name='inception_4a_5x5_reduce')\n             .conv(5, 5, 48, 1, 1, name='inception_4a_5x5'))\n\n        (self.feed('pool3_3x3_s2')\n             .max_pool(3, 3, 1, 1, name='inception_4a_pool')\n             .conv(1, 1, 64, 1, 1, name='inception_4a_pool_proj'))\n\n        (self.feed('inception_4a_1x1',\n                   'inception_4a_3x3',\n                   'inception_4a_5x5',\n                   'inception_4a_pool_proj')\n             .concat(3, name='inception_4a_output')\n             .conv(1, 1, 160, 1, 1, name='inception_4b_1x1'))\n\n        (self.feed('inception_4a_output')\n             .conv(1, 1, 112, 1, 1, name='inception_4b_3x3_reduce')\n             .conv(3, 3, 224, 1, 1, name='inception_4b_3x3'))\n\n        (self.feed('inception_4a_output')\n             .conv(1, 1, 24, 1, 1, name='inception_4b_5x5_reduce')\n             .conv(5, 5, 64, 1, 1, name='inception_4b_5x5'))\n\n        (self.feed('inception_4a_output')\n             .max_pool(3, 3, 1, 1, name='inception_4b_pool')\n             .conv(1, 1, 64, 1, 1, name='inception_4b_pool_proj'))\n\n        (self.feed('inception_4b_1x1',\n                   'inception_4b_3x3',\n                   'inception_4b_5x5',\n                   'inception_4b_pool_proj')\n             .concat(3, name='inception_4b_output')\n             .conv(1, 1, 128, 1, 1, name='inception_4c_1x1'))\n\n        (self.feed('inception_4b_output')\n             .conv(1, 1, 128, 1, 1, name='inception_4c_3x3_reduce')\n             .conv(3, 3, 256, 1, 1, name='inception_4c_3x3'))\n\n        (self.feed('inception_4b_output')\n             .conv(1, 1, 24, 1, 1, name='inception_4c_5x5_reduce')\n             .conv(5, 5, 64, 1, 1, name='inception_4c_5x5'))\n\n        (self.feed('inception_4b_output')\n             .max_pool(3, 3, 1, 1, name='inception_4c_pool')\n             .conv(1, 1, 64, 1, 1, name='inception_4c_pool_proj'))\n\n        (self.feed('inception_4c_1x1',\n                   'inception_4c_3x3',\n                   'inception_4c_5x5',\n                   'inception_4c_pool_proj')\n             .concat(3, name='inception_4c_output')\n             .conv(1, 1, 112, 1, 1, name='inception_4d_1x1'))\n\n        (self.feed('inception_4c_output')\n             .conv(1, 1, 144, 1, 1, name='inception_4d_3x3_reduce')\n             .conv(3, 3, 288, 1, 1, name='inception_4d_3x3'))\n\n        (self.feed('inception_4c_output')\n             .conv(1, 1, 32, 1, 1, name='inception_4d_5x5_reduce')\n             .conv(5, 5, 64, 1, 1, name='inception_4d_5x5'))\n\n        (self.feed('inception_4c_output')\n             .max_pool(3, 3, 1, 1, name='inception_4d_pool')\n             .conv(1, 1, 64, 1, 1, name='inception_4d_pool_proj'))\n\n        (self.feed('inception_4d_1x1',\n                   'inception_4d_3x3',\n                   'inception_4d_5x5',\n                   'inception_4d_pool_proj')\n             .concat(3, name='inception_4d_output')\n             .conv(1, 1, 256, 1, 1, name='inception_4e_1x1'))\n\n        (self.feed('inception_4d_output')\n             .conv(1, 1, 160, 1, 1, name='inception_4e_3x3_reduce')\n             .conv(3, 3, 320, 1, 1, name='inception_4e_3x3'))\n\n        (self.feed('inception_4d_output')\n             .conv(1, 1, 32, 1, 1, name='inception_4e_5x5_reduce')\n             .conv(5, 5, 128, 1, 1, name='inception_4e_5x5'))\n\n        (self.feed('inception_4d_output')\n             .max_pool(3, 3, 1, 1, name='inception_4e_pool')\n             .conv(1, 1, 128, 1, 1, name='inception_4e_pool_proj'))\n\n        (self.feed('inception_4e_1x1',\n                   'inception_4e_3x3',\n                   'inception_4e_5x5',\n                   'inception_4e_pool_proj')\n             .concat(3, name='inception_4e_output')\n             .max_pool(3, 3, 2, 2, name='pool4_3x3_s2')\n             .conv(1, 1, 256, 1, 1, name='inception_5a_1x1'))\n\n        (self.feed('pool4_3x3_s2')\n             .conv(1, 1, 160, 1, 1, name='inception_5a_3x3_reduce')\n             .conv(3, 3, 320, 1, 1, name='inception_5a_3x3'))\n\n        (self.feed('pool4_3x3_s2')\n             .conv(1, 1, 32, 1, 1, name='inception_5a_5x5_reduce')\n             .conv(5, 5, 128, 1, 1, name='inception_5a_5x5'))\n\n        (self.feed('pool4_3x3_s2')\n             .max_pool(3, 3, 1, 1, name='inception_5a_pool')\n             .conv(1, 1, 128, 1, 1, name='inception_5a_pool_proj'))\n\n        (self.feed('inception_5a_1x1',\n                   'inception_5a_3x3',\n                   'inception_5a_5x5',\n                   'inception_5a_pool_proj')\n             .concat(3, name='inception_5a_output')\n             .conv(1, 1, 384, 1, 1, name='inception_5b_1x1'))\n\n        (self.feed('inception_5a_output')\n             .conv(1, 1, 192, 1, 1, name='inception_5b_3x3_reduce')\n             .conv(3, 3, 384, 1, 1, name='inception_5b_3x3'))\n\n        (self.feed('inception_5a_output')\n             .conv(1, 1, 48, 1, 1, name='inception_5b_5x5_reduce')\n             .conv(5, 5, 128, 1, 1, name='inception_5b_5x5'))\n\n        (self.feed('inception_5a_output')\n             .max_pool(3, 3, 1, 1, name='inception_5b_pool')\n             .conv(1, 1, 128, 1, 1, name='inception_5b_pool_proj'))\n\n        (self.feed('inception_5b_1x1',\n                   'inception_5b_3x3',\n                   'inception_5b_5x5',\n                   'inception_5b_pool_proj')\n             .concat(3, name='inception_5b_output')\n             .avg_pool(7, 7, 1, 1, padding='VALID', name='pool5_7x7_s1')\n             .fc(1000, relu=False, name='loss3_classifier')\n             .softmax(name='prob'))\n"""
caffe-tensorflow/examples/imagenet/models/helper.py,0,"b'import sys\nimport os.path as osp\nimport numpy as np\n\n# Add the kaffe module to the import path\nsys.path.append(osp.realpath(osp.join(osp.dirname(__file__), \'../../../\')))\n\nfrom googlenet import GoogleNet\nfrom vgg import VGG16\nfrom alexnet import AlexNet\nfrom caffenet import CaffeNet\nfrom nin import NiN\nfrom resnet import ResNet50, ResNet101, ResNet152\n\n\nclass DataSpec(object):\n    \'\'\'Input data specifications for an ImageNet model.\'\'\'\n\n    def __init__(self,\n                 batch_size,\n                 scale_size,\n                 crop_size,\n                 isotropic,\n                 channels=3,\n                 mean=None,\n                 bgr=True):\n        # The recommended batch size for this model\n        self.batch_size = batch_size\n        # The image should be scaled to this size first during preprocessing\n        self.scale_size = scale_size\n        # Whether the model expects the rescaling to be isotropic\n        self.isotropic = isotropic\n        # A square crop of this dimension is expected by this model\n        self.crop_size = crop_size\n        # The number of channels in the input image expected by this model\n        self.channels = channels\n        # The mean to be subtracted from each image. By default, the per-channel ImageNet mean.\n        # The values below are ordered BGR, as many Caffe models are trained in this order.\n        # Some of the earlier models (like AlexNet) used a spatial three-channeled mean.\n        # However, using just the per-channel mean values instead doesn\'t affect things too much.\n        self.mean = mean if mean is not None else np.array([104., 117., 124.])\n        # Whether this model expects images to be in BGR order\n        self.expects_bgr = True\n\n\ndef alexnet_spec(batch_size=500):\n    \'\'\'Parameters used by AlexNet and its variants.\'\'\'\n    return DataSpec(batch_size=batch_size, scale_size=256, crop_size=227, isotropic=False)\n\n\ndef std_spec(batch_size, isotropic=True):\n    \'\'\'Parameters commonly used by ""post-AlexNet"" architectures.\'\'\'\n    return DataSpec(batch_size=batch_size, scale_size=256, crop_size=224, isotropic=isotropic)\n\n# Collection of sample auto-generated models\nMODELS = (AlexNet, CaffeNet, GoogleNet, NiN, ResNet50, ResNet101, ResNet152, VGG16)\n\n# The corresponding data specifications for the sample models\n# These specifications are based on how the models were trained.\n# The recommended batch size is based on a Titan X (12GB).\nMODEL_DATA_SPECS = {\n    AlexNet: alexnet_spec(),\n    CaffeNet: alexnet_spec(),\n    GoogleNet: std_spec(batch_size=200, isotropic=False),\n    ResNet50: std_spec(batch_size=25),\n    ResNet101: std_spec(batch_size=25),\n    ResNet152: std_spec(batch_size=25),\n    NiN: std_spec(batch_size=500),\n    VGG16: std_spec(batch_size=25)\n}\n\n\ndef get_models():\n    \'\'\'Returns a tuple of sample models.\'\'\'\n    return MODELS\n\n\ndef get_data_spec(model_instance=None, model_class=None):\n    \'\'\'Returns the data specifications for the given network.\'\'\'\n    model_class = model_class or model_instance.__class__\n    return MODEL_DATA_SPECS[model_class]\n'"
caffe-tensorflow/examples/imagenet/models/nin.py,0,"b""from kaffe.tensorflow import Network\n\nclass NiN(Network):\n    def setup(self):\n        (self.feed('data')\n             .conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')\n             .conv(1, 1, 96, 1, 1, name='cccp1')\n             .conv(1, 1, 96, 1, 1, name='cccp2')\n             .max_pool(3, 3, 2, 2, name='pool1')\n             .conv(5, 5, 256, 1, 1, name='conv2')\n             .conv(1, 1, 256, 1, 1, name='cccp3')\n             .conv(1, 1, 256, 1, 1, name='cccp4')\n             .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n             .conv(3, 3, 384, 1, 1, name='conv3')\n             .conv(1, 1, 384, 1, 1, name='cccp5')\n             .conv(1, 1, 384, 1, 1, name='cccp6')\n             .max_pool(3, 3, 2, 2, padding='VALID', name='pool3')\n             .conv(3, 3, 1024, 1, 1, name='conv4-1024')\n             .conv(1, 1, 1024, 1, 1, name='cccp7-1024')\n             .conv(1, 1, 1000, 1, 1, name='cccp8-1024')\n             .avg_pool(6, 6, 1, 1, padding='VALID', name='pool4')\n             .softmax(name='prob'))\n"""
caffe-tensorflow/examples/imagenet/models/resnet.py,0,"b""from kaffe.tensorflow import Network\n\nclass ResNet50(Network):\n    def setup(self):\n        (self.feed('data')\n             .conv(7, 7, 64, 2, 2, relu=False, name='conv1')\n             .batch_normalization(relu=True, name='bn_conv1')\n             .max_pool(3, 3, 2, 2, name='pool1')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n             .batch_normalization(name='bn2a_branch1'))\n\n        (self.feed('pool1')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n             .batch_normalization(relu=True, name='bn2a_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n             .batch_normalization(relu=True, name='bn2a_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n             .batch_normalization(name='bn2a_branch2c'))\n\n        (self.feed('bn2a_branch1',\n                   'bn2a_branch2c')\n             .add(name='res2a')\n             .relu(name='res2a_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2b_branch2a')\n             .batch_normalization(relu=True, name='bn2b_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2b_branch2b')\n             .batch_normalization(relu=True, name='bn2b_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2b_branch2c')\n             .batch_normalization(name='bn2b_branch2c'))\n\n        (self.feed('res2a_relu',\n                   'bn2b_branch2c')\n             .add(name='res2b')\n             .relu(name='res2b_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2c_branch2a')\n             .batch_normalization(relu=True, name='bn2c_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2c_branch2b')\n             .batch_normalization(relu=True, name='bn2c_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2c_branch2c')\n             .batch_normalization(name='bn2c_branch2c'))\n\n        (self.feed('res2b_relu',\n                   'bn2c_branch2c')\n             .add(name='res2c')\n             .relu(name='res2c_relu')\n             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res3a_branch1')\n             .batch_normalization(name='bn3a_branch1'))\n\n        (self.feed('res2c_relu')\n             .conv(1, 1, 128, 2, 2, biased=False, relu=False, name='res3a_branch2a')\n             .batch_normalization(relu=True, name='bn3a_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3a_branch2b')\n             .batch_normalization(relu=True, name='bn3a_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3a_branch2c')\n             .batch_normalization(name='bn3a_branch2c'))\n\n        (self.feed('bn3a_branch1',\n                   'bn3a_branch2c')\n             .add(name='res3a')\n             .relu(name='res3a_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b_branch2a')\n             .batch_normalization(relu=True, name='bn3b_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b_branch2b')\n             .batch_normalization(relu=True, name='bn3b_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b_branch2c')\n             .batch_normalization(name='bn3b_branch2c'))\n\n        (self.feed('res3a_relu',\n                   'bn3b_branch2c')\n             .add(name='res3b')\n             .relu(name='res3b_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3c_branch2a')\n             .batch_normalization(relu=True, name='bn3c_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3c_branch2b')\n             .batch_normalization(relu=True, name='bn3c_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3c_branch2c')\n             .batch_normalization(name='bn3c_branch2c'))\n\n        (self.feed('res3b_relu',\n                   'bn3c_branch2c')\n             .add(name='res3c')\n             .relu(name='res3c_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3d_branch2a')\n             .batch_normalization(relu=True, name='bn3d_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3d_branch2b')\n             .batch_normalization(relu=True, name='bn3d_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3d_branch2c')\n             .batch_normalization(name='bn3d_branch2c'))\n\n        (self.feed('res3c_relu',\n                   'bn3d_branch2c')\n             .add(name='res3d')\n             .relu(name='res3d_relu')\n             .conv(1, 1, 1024, 2, 2, biased=False, relu=False, name='res4a_branch1')\n             .batch_normalization(name='bn4a_branch1'))\n\n        (self.feed('res3d_relu')\n             .conv(1, 1, 256, 2, 2, biased=False, relu=False, name='res4a_branch2a')\n             .batch_normalization(relu=True, name='bn4a_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4a_branch2b')\n             .batch_normalization(relu=True, name='bn4a_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4a_branch2c')\n             .batch_normalization(name='bn4a_branch2c'))\n\n        (self.feed('bn4a_branch1',\n                   'bn4a_branch2c')\n             .add(name='res4a')\n             .relu(name='res4a_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b_branch2a')\n             .batch_normalization(relu=True, name='bn4b_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b_branch2b')\n             .batch_normalization(relu=True, name='bn4b_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b_branch2c')\n             .batch_normalization(name='bn4b_branch2c'))\n\n        (self.feed('res4a_relu',\n                   'bn4b_branch2c')\n             .add(name='res4b')\n             .relu(name='res4b_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4c_branch2a')\n             .batch_normalization(relu=True, name='bn4c_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4c_branch2b')\n             .batch_normalization(relu=True, name='bn4c_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4c_branch2c')\n             .batch_normalization(name='bn4c_branch2c'))\n\n        (self.feed('res4b_relu',\n                   'bn4c_branch2c')\n             .add(name='res4c')\n             .relu(name='res4c_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4d_branch2a')\n             .batch_normalization(relu=True, name='bn4d_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4d_branch2b')\n             .batch_normalization(relu=True, name='bn4d_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4d_branch2c')\n             .batch_normalization(name='bn4d_branch2c'))\n\n        (self.feed('res4c_relu',\n                   'bn4d_branch2c')\n             .add(name='res4d')\n             .relu(name='res4d_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4e_branch2a')\n             .batch_normalization(relu=True, name='bn4e_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4e_branch2b')\n             .batch_normalization(relu=True, name='bn4e_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4e_branch2c')\n             .batch_normalization(name='bn4e_branch2c'))\n\n        (self.feed('res4d_relu',\n                   'bn4e_branch2c')\n             .add(name='res4e')\n             .relu(name='res4e_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4f_branch2a')\n             .batch_normalization(relu=True, name='bn4f_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4f_branch2b')\n             .batch_normalization(relu=True, name='bn4f_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4f_branch2c')\n             .batch_normalization(name='bn4f_branch2c'))\n\n        (self.feed('res4e_relu',\n                   'bn4f_branch2c')\n             .add(name='res4f')\n             .relu(name='res4f_relu')\n             .conv(1, 1, 2048, 2, 2, biased=False, relu=False, name='res5a_branch1')\n             .batch_normalization(name='bn5a_branch1'))\n\n        (self.feed('res4f_relu')\n             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res5a_branch2a')\n             .batch_normalization(relu=True, name='bn5a_branch2a')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='res5a_branch2b')\n             .batch_normalization(relu=True, name='bn5a_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5a_branch2c')\n             .batch_normalization(name='bn5a_branch2c'))\n\n        (self.feed('bn5a_branch1',\n                   'bn5a_branch2c')\n             .add(name='res5a')\n             .relu(name='res5a_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5b_branch2a')\n             .batch_normalization(relu=True, name='bn5b_branch2a')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='res5b_branch2b')\n             .batch_normalization(relu=True, name='bn5b_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5b_branch2c')\n             .batch_normalization(name='bn5b_branch2c'))\n\n        (self.feed('res5a_relu',\n                   'bn5b_branch2c')\n             .add(name='res5b')\n             .relu(name='res5b_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5c_branch2a')\n             .batch_normalization(relu=True, name='bn5c_branch2a')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='res5c_branch2b')\n             .batch_normalization(relu=True, name='bn5c_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5c_branch2c')\n             .batch_normalization(name='bn5c_branch2c'))\n\n        (self.feed('res5b_relu',\n                   'bn5c_branch2c')\n             .add(name='res5c')\n             .relu(name='res5c_relu')\n             .avg_pool(7, 7, 1, 1, padding='VALID', name='pool5')\n             .fc(1000, relu=False, name='fc1000')\n             .softmax(name='prob'))\n\n\nclass ResNet101(Network):\n    def setup(self):\n        (self.feed('data')\n             .conv(7, 7, 64, 2, 2, biased=False, relu=False, name='conv1')\n             .batch_normalization(relu=True, name='bn_conv1')\n             .max_pool(3, 3, 2, 2, name='pool1')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n             .batch_normalization(name='bn2a_branch1'))\n\n        (self.feed('pool1')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n             .batch_normalization(relu=True, name='bn2a_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n             .batch_normalization(relu=True, name='bn2a_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n             .batch_normalization(name='bn2a_branch2c'))\n\n        (self.feed('bn2a_branch1',\n                   'bn2a_branch2c')\n             .add(name='res2a')\n             .relu(name='res2a_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2b_branch2a')\n             .batch_normalization(relu=True, name='bn2b_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2b_branch2b')\n             .batch_normalization(relu=True, name='bn2b_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2b_branch2c')\n             .batch_normalization(name='bn2b_branch2c'))\n\n        (self.feed('res2a_relu',\n                   'bn2b_branch2c')\n             .add(name='res2b')\n             .relu(name='res2b_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2c_branch2a')\n             .batch_normalization(relu=True, name='bn2c_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2c_branch2b')\n             .batch_normalization(relu=True, name='bn2c_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2c_branch2c')\n             .batch_normalization(name='bn2c_branch2c'))\n\n        (self.feed('res2b_relu',\n                   'bn2c_branch2c')\n             .add(name='res2c')\n             .relu(name='res2c_relu')\n             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res3a_branch1')\n             .batch_normalization(name='bn3a_branch1'))\n\n        (self.feed('res2c_relu')\n             .conv(1, 1, 128, 2, 2, biased=False, relu=False, name='res3a_branch2a')\n             .batch_normalization(relu=True, name='bn3a_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3a_branch2b')\n             .batch_normalization(relu=True, name='bn3a_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3a_branch2c')\n             .batch_normalization(name='bn3a_branch2c'))\n\n        (self.feed('bn3a_branch1',\n                   'bn3a_branch2c')\n             .add(name='res3a')\n             .relu(name='res3a_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2a')\n             .batch_normalization(relu=True, name='bn3b1_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2b')\n             .batch_normalization(relu=True, name='bn3b1_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b1_branch2c')\n             .batch_normalization(name='bn3b1_branch2c'))\n\n        (self.feed('res3a_relu',\n                   'bn3b1_branch2c')\n             .add(name='res3b1')\n             .relu(name='res3b1_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2a')\n             .batch_normalization(relu=True, name='bn3b2_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2b')\n             .batch_normalization(relu=True, name='bn3b2_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b2_branch2c')\n             .batch_normalization(name='bn3b2_branch2c'))\n\n        (self.feed('res3b1_relu',\n                   'bn3b2_branch2c')\n             .add(name='res3b2')\n             .relu(name='res3b2_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2a')\n             .batch_normalization(relu=True, name='bn3b3_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2b')\n             .batch_normalization(relu=True, name='bn3b3_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b3_branch2c')\n             .batch_normalization(name='bn3b3_branch2c'))\n\n        (self.feed('res3b2_relu',\n                   'bn3b3_branch2c')\n             .add(name='res3b3')\n             .relu(name='res3b3_relu')\n             .conv(1, 1, 1024, 2, 2, biased=False, relu=False, name='res4a_branch1')\n             .batch_normalization(name='bn4a_branch1'))\n\n        (self.feed('res3b3_relu')\n             .conv(1, 1, 256, 2, 2, biased=False, relu=False, name='res4a_branch2a')\n             .batch_normalization(relu=True, name='bn4a_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4a_branch2b')\n             .batch_normalization(relu=True, name='bn4a_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4a_branch2c')\n             .batch_normalization(name='bn4a_branch2c'))\n\n        (self.feed('bn4a_branch1',\n                   'bn4a_branch2c')\n             .add(name='res4a')\n             .relu(name='res4a_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b1_branch2a')\n             .batch_normalization(relu=True, name='bn4b1_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b1_branch2b')\n             .batch_normalization(relu=True, name='bn4b1_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b1_branch2c')\n             .batch_normalization(name='bn4b1_branch2c'))\n\n        (self.feed('res4a_relu',\n                   'bn4b1_branch2c')\n             .add(name='res4b1')\n             .relu(name='res4b1_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b2_branch2a')\n             .batch_normalization(relu=True, name='bn4b2_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b2_branch2b')\n             .batch_normalization(relu=True, name='bn4b2_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b2_branch2c')\n             .batch_normalization(name='bn4b2_branch2c'))\n\n        (self.feed('res4b1_relu',\n                   'bn4b2_branch2c')\n             .add(name='res4b2')\n             .relu(name='res4b2_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b3_branch2a')\n             .batch_normalization(relu=True, name='bn4b3_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b3_branch2b')\n             .batch_normalization(relu=True, name='bn4b3_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b3_branch2c')\n             .batch_normalization(name='bn4b3_branch2c'))\n\n        (self.feed('res4b2_relu',\n                   'bn4b3_branch2c')\n             .add(name='res4b3')\n             .relu(name='res4b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b4_branch2a')\n             .batch_normalization(relu=True, name='bn4b4_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b4_branch2b')\n             .batch_normalization(relu=True, name='bn4b4_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b4_branch2c')\n             .batch_normalization(name='bn4b4_branch2c'))\n\n        (self.feed('res4b3_relu',\n                   'bn4b4_branch2c')\n             .add(name='res4b4')\n             .relu(name='res4b4_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b5_branch2a')\n             .batch_normalization(relu=True, name='bn4b5_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b5_branch2b')\n             .batch_normalization(relu=True, name='bn4b5_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b5_branch2c')\n             .batch_normalization(name='bn4b5_branch2c'))\n\n        (self.feed('res4b4_relu',\n                   'bn4b5_branch2c')\n             .add(name='res4b5')\n             .relu(name='res4b5_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b6_branch2a')\n             .batch_normalization(relu=True, name='bn4b6_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b6_branch2b')\n             .batch_normalization(relu=True, name='bn4b6_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b6_branch2c')\n             .batch_normalization(name='bn4b6_branch2c'))\n\n        (self.feed('res4b5_relu',\n                   'bn4b6_branch2c')\n             .add(name='res4b6')\n             .relu(name='res4b6_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b7_branch2a')\n             .batch_normalization(relu=True, name='bn4b7_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b7_branch2b')\n             .batch_normalization(relu=True, name='bn4b7_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b7_branch2c')\n             .batch_normalization(name='bn4b7_branch2c'))\n\n        (self.feed('res4b6_relu',\n                   'bn4b7_branch2c')\n             .add(name='res4b7')\n             .relu(name='res4b7_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b8_branch2a')\n             .batch_normalization(relu=True, name='bn4b8_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b8_branch2b')\n             .batch_normalization(relu=True, name='bn4b8_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b8_branch2c')\n             .batch_normalization(name='bn4b8_branch2c'))\n\n        (self.feed('res4b7_relu',\n                   'bn4b8_branch2c')\n             .add(name='res4b8')\n             .relu(name='res4b8_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b9_branch2a')\n             .batch_normalization(relu=True, name='bn4b9_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b9_branch2b')\n             .batch_normalization(relu=True, name='bn4b9_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b9_branch2c')\n             .batch_normalization(name='bn4b9_branch2c'))\n\n        (self.feed('res4b8_relu',\n                   'bn4b9_branch2c')\n             .add(name='res4b9')\n             .relu(name='res4b9_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b10_branch2a')\n             .batch_normalization(relu=True, name='bn4b10_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b10_branch2b')\n             .batch_normalization(relu=True, name='bn4b10_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b10_branch2c')\n             .batch_normalization(name='bn4b10_branch2c'))\n\n        (self.feed('res4b9_relu',\n                   'bn4b10_branch2c')\n             .add(name='res4b10')\n             .relu(name='res4b10_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b11_branch2a')\n             .batch_normalization(relu=True, name='bn4b11_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b11_branch2b')\n             .batch_normalization(relu=True, name='bn4b11_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b11_branch2c')\n             .batch_normalization(name='bn4b11_branch2c'))\n\n        (self.feed('res4b10_relu',\n                   'bn4b11_branch2c')\n             .add(name='res4b11')\n             .relu(name='res4b11_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b12_branch2a')\n             .batch_normalization(relu=True, name='bn4b12_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b12_branch2b')\n             .batch_normalization(relu=True, name='bn4b12_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b12_branch2c')\n             .batch_normalization(name='bn4b12_branch2c'))\n\n        (self.feed('res4b11_relu',\n                   'bn4b12_branch2c')\n             .add(name='res4b12')\n             .relu(name='res4b12_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b13_branch2a')\n             .batch_normalization(relu=True, name='bn4b13_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b13_branch2b')\n             .batch_normalization(relu=True, name='bn4b13_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b13_branch2c')\n             .batch_normalization(name='bn4b13_branch2c'))\n\n        (self.feed('res4b12_relu',\n                   'bn4b13_branch2c')\n             .add(name='res4b13')\n             .relu(name='res4b13_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b14_branch2a')\n             .batch_normalization(relu=True, name='bn4b14_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b14_branch2b')\n             .batch_normalization(relu=True, name='bn4b14_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b14_branch2c')\n             .batch_normalization(name='bn4b14_branch2c'))\n\n        (self.feed('res4b13_relu',\n                   'bn4b14_branch2c')\n             .add(name='res4b14')\n             .relu(name='res4b14_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b15_branch2a')\n             .batch_normalization(relu=True, name='bn4b15_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b15_branch2b')\n             .batch_normalization(relu=True, name='bn4b15_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b15_branch2c')\n             .batch_normalization(name='bn4b15_branch2c'))\n\n        (self.feed('res4b14_relu',\n                   'bn4b15_branch2c')\n             .add(name='res4b15')\n             .relu(name='res4b15_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b16_branch2a')\n             .batch_normalization(relu=True, name='bn4b16_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b16_branch2b')\n             .batch_normalization(relu=True, name='bn4b16_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b16_branch2c')\n             .batch_normalization(name='bn4b16_branch2c'))\n\n        (self.feed('res4b15_relu',\n                   'bn4b16_branch2c')\n             .add(name='res4b16')\n             .relu(name='res4b16_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b17_branch2a')\n             .batch_normalization(relu=True, name='bn4b17_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b17_branch2b')\n             .batch_normalization(relu=True, name='bn4b17_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b17_branch2c')\n             .batch_normalization(name='bn4b17_branch2c'))\n\n        (self.feed('res4b16_relu',\n                   'bn4b17_branch2c')\n             .add(name='res4b17')\n             .relu(name='res4b17_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b18_branch2a')\n             .batch_normalization(relu=True, name='bn4b18_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b18_branch2b')\n             .batch_normalization(relu=True, name='bn4b18_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b18_branch2c')\n             .batch_normalization(name='bn4b18_branch2c'))\n\n        (self.feed('res4b17_relu',\n                   'bn4b18_branch2c')\n             .add(name='res4b18')\n             .relu(name='res4b18_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b19_branch2a')\n             .batch_normalization(relu=True, name='bn4b19_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b19_branch2b')\n             .batch_normalization(relu=True, name='bn4b19_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b19_branch2c')\n             .batch_normalization(name='bn4b19_branch2c'))\n\n        (self.feed('res4b18_relu',\n                   'bn4b19_branch2c')\n             .add(name='res4b19')\n             .relu(name='res4b19_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b20_branch2a')\n             .batch_normalization(relu=True, name='bn4b20_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b20_branch2b')\n             .batch_normalization(relu=True, name='bn4b20_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b20_branch2c')\n             .batch_normalization(name='bn4b20_branch2c'))\n\n        (self.feed('res4b19_relu',\n                   'bn4b20_branch2c')\n             .add(name='res4b20')\n             .relu(name='res4b20_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b21_branch2a')\n             .batch_normalization(relu=True, name='bn4b21_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b21_branch2b')\n             .batch_normalization(relu=True, name='bn4b21_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b21_branch2c')\n             .batch_normalization(name='bn4b21_branch2c'))\n\n        (self.feed('res4b20_relu',\n                   'bn4b21_branch2c')\n             .add(name='res4b21')\n             .relu(name='res4b21_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b22_branch2a')\n             .batch_normalization(relu=True, name='bn4b22_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b22_branch2b')\n             .batch_normalization(relu=True, name='bn4b22_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b22_branch2c')\n             .batch_normalization(name='bn4b22_branch2c'))\n\n        (self.feed('res4b21_relu',\n                   'bn4b22_branch2c')\n             .add(name='res4b22')\n             .relu(name='res4b22_relu')\n             .conv(1, 1, 2048, 2, 2, biased=False, relu=False, name='res5a_branch1')\n             .batch_normalization(name='bn5a_branch1'))\n\n        (self.feed('res4b22_relu')\n             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res5a_branch2a')\n             .batch_normalization(relu=True, name='bn5a_branch2a')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='res5a_branch2b')\n             .batch_normalization(relu=True, name='bn5a_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5a_branch2c')\n             .batch_normalization(name='bn5a_branch2c'))\n\n        (self.feed('bn5a_branch1',\n                   'bn5a_branch2c')\n             .add(name='res5a')\n             .relu(name='res5a_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5b_branch2a')\n             .batch_normalization(relu=True, name='bn5b_branch2a')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='res5b_branch2b')\n             .batch_normalization(relu=True, name='bn5b_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5b_branch2c')\n             .batch_normalization(name='bn5b_branch2c'))\n\n        (self.feed('res5a_relu',\n                   'bn5b_branch2c')\n             .add(name='res5b')\n             .relu(name='res5b_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5c_branch2a')\n             .batch_normalization(relu=True, name='bn5c_branch2a')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='res5c_branch2b')\n             .batch_normalization(relu=True, name='bn5c_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5c_branch2c')\n             .batch_normalization(name='bn5c_branch2c'))\n\n        (self.feed('res5b_relu',\n                   'bn5c_branch2c')\n             .add(name='res5c')\n             .relu(name='res5c_relu')\n             .avg_pool(7, 7, 1, 1, padding='VALID', name='pool5')\n             .fc(1000, relu=False, name='fc1000')\n             .softmax(name='prob'))\n\n\nclass ResNet152(Network):\n    def setup(self):\n        (self.feed('data')\n             .conv(7, 7, 64, 2, 2, biased=False, relu=False, name='conv1')\n             .batch_normalization(relu=True, name='bn_conv1')\n             .max_pool(3, 3, 2, 2, name='pool1')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n             .batch_normalization(name='bn2a_branch1'))\n\n        (self.feed('pool1')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n             .batch_normalization(relu=True, name='bn2a_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n             .batch_normalization(relu=True, name='bn2a_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n             .batch_normalization(name='bn2a_branch2c'))\n\n        (self.feed('bn2a_branch1',\n                   'bn2a_branch2c')\n             .add(name='res2a')\n             .relu(name='res2a_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2b_branch2a')\n             .batch_normalization(relu=True, name='bn2b_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2b_branch2b')\n             .batch_normalization(relu=True, name='bn2b_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2b_branch2c')\n             .batch_normalization(name='bn2b_branch2c'))\n\n        (self.feed('res2a_relu',\n                   'bn2b_branch2c')\n             .add(name='res2b')\n             .relu(name='res2b_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2c_branch2a')\n             .batch_normalization(relu=True, name='bn2c_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2c_branch2b')\n             .batch_normalization(relu=True, name='bn2c_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2c_branch2c')\n             .batch_normalization(name='bn2c_branch2c'))\n\n        (self.feed('res2b_relu',\n                   'bn2c_branch2c')\n             .add(name='res2c')\n             .relu(name='res2c_relu')\n             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res3a_branch1')\n             .batch_normalization(name='bn3a_branch1'))\n\n        (self.feed('res2c_relu')\n             .conv(1, 1, 128, 2, 2, biased=False, relu=False, name='res3a_branch2a')\n             .batch_normalization(relu=True, name='bn3a_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3a_branch2b')\n             .batch_normalization(relu=True, name='bn3a_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3a_branch2c')\n             .batch_normalization(name='bn3a_branch2c'))\n\n        (self.feed('bn3a_branch1',\n                   'bn3a_branch2c')\n             .add(name='res3a')\n             .relu(name='res3a_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2a')\n             .batch_normalization(relu=True, name='bn3b1_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2b')\n             .batch_normalization(relu=True, name='bn3b1_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b1_branch2c')\n             .batch_normalization(name='bn3b1_branch2c'))\n\n        (self.feed('res3a_relu',\n                   'bn3b1_branch2c')\n             .add(name='res3b1')\n             .relu(name='res3b1_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2a')\n             .batch_normalization(relu=True, name='bn3b2_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2b')\n             .batch_normalization(relu=True, name='bn3b2_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b2_branch2c')\n             .batch_normalization(name='bn3b2_branch2c'))\n\n        (self.feed('res3b1_relu',\n                   'bn3b2_branch2c')\n             .add(name='res3b2')\n             .relu(name='res3b2_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2a')\n             .batch_normalization(relu=True, name='bn3b3_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2b')\n             .batch_normalization(relu=True, name='bn3b3_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b3_branch2c')\n             .batch_normalization(name='bn3b3_branch2c'))\n\n        (self.feed('res3b2_relu',\n                   'bn3b3_branch2c')\n             .add(name='res3b3')\n             .relu(name='res3b3_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b4_branch2a')\n             .batch_normalization(relu=True, name='bn3b4_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b4_branch2b')\n             .batch_normalization(relu=True, name='bn3b4_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b4_branch2c')\n             .batch_normalization(name='bn3b4_branch2c'))\n\n        (self.feed('res3b3_relu',\n                   'bn3b4_branch2c')\n             .add(name='res3b4')\n             .relu(name='res3b4_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b5_branch2a')\n             .batch_normalization(relu=True, name='bn3b5_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b5_branch2b')\n             .batch_normalization(relu=True, name='bn3b5_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b5_branch2c')\n             .batch_normalization(name='bn3b5_branch2c'))\n\n        (self.feed('res3b4_relu',\n                   'bn3b5_branch2c')\n             .add(name='res3b5')\n             .relu(name='res3b5_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b6_branch2a')\n             .batch_normalization(relu=True, name='bn3b6_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b6_branch2b')\n             .batch_normalization(relu=True, name='bn3b6_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b6_branch2c')\n             .batch_normalization(name='bn3b6_branch2c'))\n\n        (self.feed('res3b5_relu',\n                   'bn3b6_branch2c')\n             .add(name='res3b6')\n             .relu(name='res3b6_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b7_branch2a')\n             .batch_normalization(relu=True, name='bn3b7_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b7_branch2b')\n             .batch_normalization(relu=True, name='bn3b7_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b7_branch2c')\n             .batch_normalization(name='bn3b7_branch2c'))\n\n        (self.feed('res3b6_relu',\n                   'bn3b7_branch2c')\n             .add(name='res3b7')\n             .relu(name='res3b7_relu')\n             .conv(1, 1, 1024, 2, 2, biased=False, relu=False, name='res4a_branch1')\n             .batch_normalization(name='bn4a_branch1'))\n\n        (self.feed('res3b7_relu')\n             .conv(1, 1, 256, 2, 2, biased=False, relu=False, name='res4a_branch2a')\n             .batch_normalization(relu=True, name='bn4a_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4a_branch2b')\n             .batch_normalization(relu=True, name='bn4a_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4a_branch2c')\n             .batch_normalization(name='bn4a_branch2c'))\n\n        (self.feed('bn4a_branch1',\n                   'bn4a_branch2c')\n             .add(name='res4a')\n             .relu(name='res4a_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b1_branch2a')\n             .batch_normalization(relu=True, name='bn4b1_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b1_branch2b')\n             .batch_normalization(relu=True, name='bn4b1_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b1_branch2c')\n             .batch_normalization(name='bn4b1_branch2c'))\n\n        (self.feed('res4a_relu',\n                   'bn4b1_branch2c')\n             .add(name='res4b1')\n             .relu(name='res4b1_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b2_branch2a')\n             .batch_normalization(relu=True, name='bn4b2_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b2_branch2b')\n             .batch_normalization(relu=True, name='bn4b2_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b2_branch2c')\n             .batch_normalization(name='bn4b2_branch2c'))\n\n        (self.feed('res4b1_relu',\n                   'bn4b2_branch2c')\n             .add(name='res4b2')\n             .relu(name='res4b2_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b3_branch2a')\n             .batch_normalization(relu=True, name='bn4b3_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b3_branch2b')\n             .batch_normalization(relu=True, name='bn4b3_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b3_branch2c')\n             .batch_normalization(name='bn4b3_branch2c'))\n\n        (self.feed('res4b2_relu',\n                   'bn4b3_branch2c')\n             .add(name='res4b3')\n             .relu(name='res4b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b4_branch2a')\n             .batch_normalization(relu=True, name='bn4b4_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b4_branch2b')\n             .batch_normalization(relu=True, name='bn4b4_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b4_branch2c')\n             .batch_normalization(name='bn4b4_branch2c'))\n\n        (self.feed('res4b3_relu',\n                   'bn4b4_branch2c')\n             .add(name='res4b4')\n             .relu(name='res4b4_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b5_branch2a')\n             .batch_normalization(relu=True, name='bn4b5_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b5_branch2b')\n             .batch_normalization(relu=True, name='bn4b5_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b5_branch2c')\n             .batch_normalization(name='bn4b5_branch2c'))\n\n        (self.feed('res4b4_relu',\n                   'bn4b5_branch2c')\n             .add(name='res4b5')\n             .relu(name='res4b5_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b6_branch2a')\n             .batch_normalization(relu=True, name='bn4b6_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b6_branch2b')\n             .batch_normalization(relu=True, name='bn4b6_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b6_branch2c')\n             .batch_normalization(name='bn4b6_branch2c'))\n\n        (self.feed('res4b5_relu',\n                   'bn4b6_branch2c')\n             .add(name='res4b6')\n             .relu(name='res4b6_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b7_branch2a')\n             .batch_normalization(relu=True, name='bn4b7_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b7_branch2b')\n             .batch_normalization(relu=True, name='bn4b7_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b7_branch2c')\n             .batch_normalization(name='bn4b7_branch2c'))\n\n        (self.feed('res4b6_relu',\n                   'bn4b7_branch2c')\n             .add(name='res4b7')\n             .relu(name='res4b7_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b8_branch2a')\n             .batch_normalization(relu=True, name='bn4b8_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b8_branch2b')\n             .batch_normalization(relu=True, name='bn4b8_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b8_branch2c')\n             .batch_normalization(name='bn4b8_branch2c'))\n\n        (self.feed('res4b7_relu',\n                   'bn4b8_branch2c')\n             .add(name='res4b8')\n             .relu(name='res4b8_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b9_branch2a')\n             .batch_normalization(relu=True, name='bn4b9_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b9_branch2b')\n             .batch_normalization(relu=True, name='bn4b9_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b9_branch2c')\n             .batch_normalization(name='bn4b9_branch2c'))\n\n        (self.feed('res4b8_relu',\n                   'bn4b9_branch2c')\n             .add(name='res4b9')\n             .relu(name='res4b9_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b10_branch2a')\n             .batch_normalization(relu=True, name='bn4b10_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b10_branch2b')\n             .batch_normalization(relu=True, name='bn4b10_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b10_branch2c')\n             .batch_normalization(name='bn4b10_branch2c'))\n\n        (self.feed('res4b9_relu',\n                   'bn4b10_branch2c')\n             .add(name='res4b10')\n             .relu(name='res4b10_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b11_branch2a')\n             .batch_normalization(relu=True, name='bn4b11_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b11_branch2b')\n             .batch_normalization(relu=True, name='bn4b11_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b11_branch2c')\n             .batch_normalization(name='bn4b11_branch2c'))\n\n        (self.feed('res4b10_relu',\n                   'bn4b11_branch2c')\n             .add(name='res4b11')\n             .relu(name='res4b11_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b12_branch2a')\n             .batch_normalization(relu=True, name='bn4b12_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b12_branch2b')\n             .batch_normalization(relu=True, name='bn4b12_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b12_branch2c')\n             .batch_normalization(name='bn4b12_branch2c'))\n\n        (self.feed('res4b11_relu',\n                   'bn4b12_branch2c')\n             .add(name='res4b12')\n             .relu(name='res4b12_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b13_branch2a')\n             .batch_normalization(relu=True, name='bn4b13_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b13_branch2b')\n             .batch_normalization(relu=True, name='bn4b13_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b13_branch2c')\n             .batch_normalization(name='bn4b13_branch2c'))\n\n        (self.feed('res4b12_relu',\n                   'bn4b13_branch2c')\n             .add(name='res4b13')\n             .relu(name='res4b13_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b14_branch2a')\n             .batch_normalization(relu=True, name='bn4b14_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b14_branch2b')\n             .batch_normalization(relu=True, name='bn4b14_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b14_branch2c')\n             .batch_normalization(name='bn4b14_branch2c'))\n\n        (self.feed('res4b13_relu',\n                   'bn4b14_branch2c')\n             .add(name='res4b14')\n             .relu(name='res4b14_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b15_branch2a')\n             .batch_normalization(relu=True, name='bn4b15_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b15_branch2b')\n             .batch_normalization(relu=True, name='bn4b15_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b15_branch2c')\n             .batch_normalization(name='bn4b15_branch2c'))\n\n        (self.feed('res4b14_relu',\n                   'bn4b15_branch2c')\n             .add(name='res4b15')\n             .relu(name='res4b15_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b16_branch2a')\n             .batch_normalization(relu=True, name='bn4b16_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b16_branch2b')\n             .batch_normalization(relu=True, name='bn4b16_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b16_branch2c')\n             .batch_normalization(name='bn4b16_branch2c'))\n\n        (self.feed('res4b15_relu',\n                   'bn4b16_branch2c')\n             .add(name='res4b16')\n             .relu(name='res4b16_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b17_branch2a')\n             .batch_normalization(relu=True, name='bn4b17_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b17_branch2b')\n             .batch_normalization(relu=True, name='bn4b17_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b17_branch2c')\n             .batch_normalization(name='bn4b17_branch2c'))\n\n        (self.feed('res4b16_relu',\n                   'bn4b17_branch2c')\n             .add(name='res4b17')\n             .relu(name='res4b17_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b18_branch2a')\n             .batch_normalization(relu=True, name='bn4b18_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b18_branch2b')\n             .batch_normalization(relu=True, name='bn4b18_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b18_branch2c')\n             .batch_normalization(name='bn4b18_branch2c'))\n\n        (self.feed('res4b17_relu',\n                   'bn4b18_branch2c')\n             .add(name='res4b18')\n             .relu(name='res4b18_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b19_branch2a')\n             .batch_normalization(relu=True, name='bn4b19_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b19_branch2b')\n             .batch_normalization(relu=True, name='bn4b19_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b19_branch2c')\n             .batch_normalization(name='bn4b19_branch2c'))\n\n        (self.feed('res4b18_relu',\n                   'bn4b19_branch2c')\n             .add(name='res4b19')\n             .relu(name='res4b19_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b20_branch2a')\n             .batch_normalization(relu=True, name='bn4b20_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b20_branch2b')\n             .batch_normalization(relu=True, name='bn4b20_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b20_branch2c')\n             .batch_normalization(name='bn4b20_branch2c'))\n\n        (self.feed('res4b19_relu',\n                   'bn4b20_branch2c')\n             .add(name='res4b20')\n             .relu(name='res4b20_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b21_branch2a')\n             .batch_normalization(relu=True, name='bn4b21_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b21_branch2b')\n             .batch_normalization(relu=True, name='bn4b21_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b21_branch2c')\n             .batch_normalization(name='bn4b21_branch2c'))\n\n        (self.feed('res4b20_relu',\n                   'bn4b21_branch2c')\n             .add(name='res4b21')\n             .relu(name='res4b21_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b22_branch2a')\n             .batch_normalization(relu=True, name='bn4b22_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b22_branch2b')\n             .batch_normalization(relu=True, name='bn4b22_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b22_branch2c')\n             .batch_normalization(name='bn4b22_branch2c'))\n\n        (self.feed('res4b21_relu',\n                   'bn4b22_branch2c')\n             .add(name='res4b22')\n             .relu(name='res4b22_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b23_branch2a')\n             .batch_normalization(relu=True, name='bn4b23_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b23_branch2b')\n             .batch_normalization(relu=True, name='bn4b23_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b23_branch2c')\n             .batch_normalization(name='bn4b23_branch2c'))\n\n        (self.feed('res4b22_relu',\n                   'bn4b23_branch2c')\n             .add(name='res4b23')\n             .relu(name='res4b23_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b24_branch2a')\n             .batch_normalization(relu=True, name='bn4b24_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b24_branch2b')\n             .batch_normalization(relu=True, name='bn4b24_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b24_branch2c')\n             .batch_normalization(name='bn4b24_branch2c'))\n\n        (self.feed('res4b23_relu',\n                   'bn4b24_branch2c')\n             .add(name='res4b24')\n             .relu(name='res4b24_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b25_branch2a')\n             .batch_normalization(relu=True, name='bn4b25_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b25_branch2b')\n             .batch_normalization(relu=True, name='bn4b25_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b25_branch2c')\n             .batch_normalization(name='bn4b25_branch2c'))\n\n        (self.feed('res4b24_relu',\n                   'bn4b25_branch2c')\n             .add(name='res4b25')\n             .relu(name='res4b25_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b26_branch2a')\n             .batch_normalization(relu=True, name='bn4b26_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b26_branch2b')\n             .batch_normalization(relu=True, name='bn4b26_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b26_branch2c')\n             .batch_normalization(name='bn4b26_branch2c'))\n\n        (self.feed('res4b25_relu',\n                   'bn4b26_branch2c')\n             .add(name='res4b26')\n             .relu(name='res4b26_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b27_branch2a')\n             .batch_normalization(relu=True, name='bn4b27_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b27_branch2b')\n             .batch_normalization(relu=True, name='bn4b27_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b27_branch2c')\n             .batch_normalization(name='bn4b27_branch2c'))\n\n        (self.feed('res4b26_relu',\n                   'bn4b27_branch2c')\n             .add(name='res4b27')\n             .relu(name='res4b27_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b28_branch2a')\n             .batch_normalization(relu=True, name='bn4b28_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b28_branch2b')\n             .batch_normalization(relu=True, name='bn4b28_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b28_branch2c')\n             .batch_normalization(name='bn4b28_branch2c'))\n\n        (self.feed('res4b27_relu',\n                   'bn4b28_branch2c')\n             .add(name='res4b28')\n             .relu(name='res4b28_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b29_branch2a')\n             .batch_normalization(relu=True, name='bn4b29_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b29_branch2b')\n             .batch_normalization(relu=True, name='bn4b29_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b29_branch2c')\n             .batch_normalization(name='bn4b29_branch2c'))\n\n        (self.feed('res4b28_relu',\n                   'bn4b29_branch2c')\n             .add(name='res4b29')\n             .relu(name='res4b29_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b30_branch2a')\n             .batch_normalization(relu=True, name='bn4b30_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b30_branch2b')\n             .batch_normalization(relu=True, name='bn4b30_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b30_branch2c')\n             .batch_normalization(name='bn4b30_branch2c'))\n\n        (self.feed('res4b29_relu',\n                   'bn4b30_branch2c')\n             .add(name='res4b30')\n             .relu(name='res4b30_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b31_branch2a')\n             .batch_normalization(relu=True, name='bn4b31_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b31_branch2b')\n             .batch_normalization(relu=True, name='bn4b31_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b31_branch2c')\n             .batch_normalization(name='bn4b31_branch2c'))\n\n        (self.feed('res4b30_relu',\n                   'bn4b31_branch2c')\n             .add(name='res4b31')\n             .relu(name='res4b31_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b32_branch2a')\n             .batch_normalization(relu=True, name='bn4b32_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b32_branch2b')\n             .batch_normalization(relu=True, name='bn4b32_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b32_branch2c')\n             .batch_normalization(name='bn4b32_branch2c'))\n\n        (self.feed('res4b31_relu',\n                   'bn4b32_branch2c')\n             .add(name='res4b32')\n             .relu(name='res4b32_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b33_branch2a')\n             .batch_normalization(relu=True, name='bn4b33_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b33_branch2b')\n             .batch_normalization(relu=True, name='bn4b33_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b33_branch2c')\n             .batch_normalization(name='bn4b33_branch2c'))\n\n        (self.feed('res4b32_relu',\n                   'bn4b33_branch2c')\n             .add(name='res4b33')\n             .relu(name='res4b33_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b34_branch2a')\n             .batch_normalization(relu=True, name='bn4b34_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b34_branch2b')\n             .batch_normalization(relu=True, name='bn4b34_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b34_branch2c')\n             .batch_normalization(name='bn4b34_branch2c'))\n\n        (self.feed('res4b33_relu',\n                   'bn4b34_branch2c')\n             .add(name='res4b34')\n             .relu(name='res4b34_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b35_branch2a')\n             .batch_normalization(relu=True, name='bn4b35_branch2a')\n             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b35_branch2b')\n             .batch_normalization(relu=True, name='bn4b35_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b35_branch2c')\n             .batch_normalization(name='bn4b35_branch2c'))\n\n        (self.feed('res4b34_relu',\n                   'bn4b35_branch2c')\n             .add(name='res4b35')\n             .relu(name='res4b35_relu')\n             .conv(1, 1, 2048, 2, 2, biased=False, relu=False, name='res5a_branch1')\n             .batch_normalization(name='bn5a_branch1'))\n\n        (self.feed('res4b35_relu')\n             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res5a_branch2a')\n             .batch_normalization(relu=True, name='bn5a_branch2a')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='res5a_branch2b')\n             .batch_normalization(relu=True, name='bn5a_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5a_branch2c')\n             .batch_normalization(name='bn5a_branch2c'))\n\n        (self.feed('bn5a_branch1',\n                   'bn5a_branch2c')\n             .add(name='res5a')\n             .relu(name='res5a_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5b_branch2a')\n             .batch_normalization(relu=True, name='bn5b_branch2a')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='res5b_branch2b')\n             .batch_normalization(relu=True, name='bn5b_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5b_branch2c')\n             .batch_normalization(name='bn5b_branch2c'))\n\n        (self.feed('res5a_relu',\n                   'bn5b_branch2c')\n             .add(name='res5b')\n             .relu(name='res5b_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5c_branch2a')\n             .batch_normalization(relu=True, name='bn5c_branch2a')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='res5c_branch2b')\n             .batch_normalization(relu=True, name='bn5c_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5c_branch2c')\n             .batch_normalization(name='bn5c_branch2c'))\n\n        (self.feed('res5b_relu',\n                   'bn5c_branch2c')\n             .add(name='res5c')\n             .relu(name='res5c_relu')\n             .avg_pool(7, 7, 1, 1, padding='VALID', name='pool5')\n             .fc(1000, relu=False, name='fc1000')\n             .softmax(name='prob'))\n"""
caffe-tensorflow/examples/imagenet/models/vgg.py,0,"b""from kaffe.tensorflow import Network\n\nclass VGG16(Network):\n    def setup(self):\n        (self.feed('data')\n             .conv(3, 3, 64, 1, 1, name='conv1_1')\n             .conv(3, 3, 64, 1, 1, name='conv1_2')\n             .max_pool(2, 2, 2, 2, name='pool1')\n             .conv(3, 3, 128, 1, 1, name='conv2_1')\n             .conv(3, 3, 128, 1, 1, name='conv2_2')\n             .max_pool(2, 2, 2, 2, name='pool2')\n             .conv(3, 3, 256, 1, 1, name='conv3_1')\n             .conv(3, 3, 256, 1, 1, name='conv3_2')\n             .conv(3, 3, 256, 1, 1, name='conv3_3')\n             .max_pool(2, 2, 2, 2, name='pool3')\n             .conv(3, 3, 512, 1, 1, name='conv4_1')\n             .conv(3, 3, 512, 1, 1, name='conv4_2')\n             .conv(3, 3, 512, 1, 1, name='conv4_3')\n             .max_pool(2, 2, 2, 2, name='pool4')\n             .conv(3, 3, 512, 1, 1, name='conv5_1')\n             .conv(3, 3, 512, 1, 1, name='conv5_2')\n             .conv(3, 3, 512, 1, 1, name='conv5_3')\n             .max_pool(2, 2, 2, 2, name='pool5')\n             .fc(4096, name='fc6')\n             .fc(4096, name='fc7')\n             .fc(1000, relu=False, name='fc8')\n             .softmax(name='prob'))\n"""
