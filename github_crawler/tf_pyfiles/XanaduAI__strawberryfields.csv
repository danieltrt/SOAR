file_path,api_count,code
setup.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport os\nimport sys\n\nfrom setuptools import setup, find_packages\n\n\nwith open(""strawberryfields/_version.py"") as f:\n    version = f.readlines()[-1].split()[-1].strip(""\\""\'"")\n\n\nrequirements = [\n    ""numpy>=1.17.4"",\n    ""scipy>=1.0.0"",\n    ""sympy>=1.5"",\n    ""networkx>=2.0"",\n    ""quantum-blackbird>=0.2.3"",\n    ""python-dateutil>=2.8.0"",\n    ""thewalrus>=0.12"",\n    ""numba"",\n    ""toml"",\n    ""appdirs"",\n    ""requests>=2.22.0"",\n    ""urllib3>=1.25.3"",\n]\n\ninfo = {\n    ""name"": ""StrawberryFields"",\n    ""version"": version,\n    ""maintainer"": ""Xanadu Inc."",\n    ""maintainer_email"": ""software@xanadu.ai"",\n    ""url"": ""https://github.com/XanaduAI/StrawberryFields"",\n    ""license"": ""Apache License 2.0"",\n    ""packages"": find_packages(where="".""),\n    ""package_data"": {""strawberryfields"": [""backends/data/*"", ""apps/data/*""]},\n    ""include_package_data"": True,\n    ""entry_points"" : {\n        \'console_scripts\': [\n            \'sf=strawberryfields.cli:main\'\n        ]\n    },\n    ""description"": ""Open source library for continuous-variable quantum computation"",\n    ""long_description"": open(""README.rst"", encoding=""utf-8"").read(),\n    ""provides"": [""strawberryfields""],\n    ""install_requires"": requirements,\n    # \'extras_require\': extra_requirements,\n    ""command_options"": {\n        ""build_sphinx"": {""version"": (""setup.py"", version), ""release"": (""setup.py"", version)}\n    },\n}\n\nclassifiers = [\n    ""Development Status :: 4 - Beta"",\n    ""Environment :: Console"",\n    ""Intended Audience :: Science/Research"",\n    ""License :: OSI Approved :: Apache Software License"",\n    ""Natural Language :: English"",\n    ""Operating System :: POSIX"",\n    ""Operating System :: MacOS :: MacOS X"",\n    ""Operating System :: POSIX :: Linux"",\n    ""Operating System :: Microsoft :: Windows"",\n    ""Programming Language :: Python"",\n    ""Programming Language :: Python :: 3"",\n    ""Programming Language :: Python :: 3.6"",\n    ""Programming Language :: Python :: 3.7"",\n    ""Programming Language :: Python :: 3.8"",\n    ""Programming Language :: Python :: 3 :: Only"",\n    ""Topic :: Scientific/Engineering :: Physics"",\n]\n\nsetup(classifiers=classifiers, **(info))\n'"
doc/conf.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Strawberry Fields documentation build configuration file, created by\n# sphinx-quickstart on Fri Sep  8 14:44:21 2017.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys, os, re\nfrom unittest.mock import MagicMock, PropertyMock\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\nsys.path.insert(0, os.path.abspath(\'..\'))\nsys.path.insert(0, os.path.abspath(\'_ext\'))\nsys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(\'.\')), \'doc\'))\n\n\nclass Mock(MagicMock):\n    __name__ = \'foo\'\n\n    @classmethod\n    def __getattr__(cls, name):\n        return MagicMock()\n\n\nsys.modules[""tensorflow""] = Mock(__version__=""2.0"")\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\nneeds_sphinx = \'1.5\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.autosummary\',\n    \'sphinx.ext.todo\',\n    \'sphinx.ext.coverage\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.napoleon\',\n    \'sphinx.ext.inheritance_diagram\',\n    \'sphinx.ext.viewcode\',\n    \'sphinxcontrib.bibtex\',\n    \'edit_on_github\',\n    \'sphinx_autodoc_typehints\',\n    \'nbsphinx\',\n    \'sphinx_gallery.gen_gallery\',\n    ""sphinx.ext.intersphinx"",\n    ""sphinx_automodapi.automodapi"",\n    \'sphinx_copybutton\',\n    ""m2r""\n]\n\nsource_suffix = [\'.rst\', \'.md\']\n\nfrom glob import glob\nimport shutil\nimport warnings\n\nautosummary_generate = True\nautosummary_imported_members = False\nautomodapi_toctreedirnm = ""code/api""\nautomodsumm_inherited_members = True\n\nadd_module_names = False\n\nmathjax_path = ""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML""\n\n# nbsphinx settings\n\nexclude_patterns = [\'_build\', \'**.ipynb_checkpoints\']\nnbsphinx_execute = \'never\'\nnbsphinx_epilog = """"""\n.. note:: :download:`Click here <../../{{env.docname}}.ipynb>` to download this gallery page as an interactive Jupyter notebook.\n""""""\nnbsphinx_requirejs_path = """"\n\nsphinx_gallery_conf = {\n    # path to your example scripts\n    \'examples_dirs\': \'../examples_apps\',\n    # path where to save gallery generated examples\n    \'gallery_dirs\': \'tutorials_apps\',\n    # execute files that match the following filename pattern,\n    # and skip those that don\'t. If the following option is not provided,\n    # all example scripts in the \'examples_dirs\' folder will be skiped.\n    \'filename_pattern\': r\'/run_\',\n    # first notebook cell in generated Jupyter notebooks\n    \'first_notebook_cell\': (""# This cell is added by sphinx-gallery\\n""\n                            ""# It can be customized to whatever you like\\n""\n                            ""%matplotlib inline""),\n    # thumbnail size\n    \'thumbnail_size\': (400, 400),\n    \'capture_repr\': (),\n}\n\n# Remove warnings that occur when generating the the tutorials\nwarnings.filterwarnings(""ignore"", category=UserWarning, message=r""Matplotlib is currently using agg"")\nwarnings.filterwarnings(""ignore"", category=FutureWarning, message=r""Passing \\(type, 1\\) or \'1type\' as a synonym of type is deprecated.+"")\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\', \'xanadu_theme\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = \'Strawberry Fields\'\ncopyright = """"""Nathan Killoran, Josh Izaac, Nicol\xc3\xa1s Quesada, Ville Bergholm, Matthew Amy, and Christian Weedbrook. <br>\n""Strawberry Fields: A Software Platform for Photonic Quantum Computing"", Quantum, 3, 129 (2019).<br>\n&copy; Copyright 2019, Xanadu Quantum Technologies Inc.""""""\nauthor = \'Xanadu Inc.\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The full version, including alpha/beta/rc tags.\nimport strawberryfields as sf\nrelease = sf.__version__\n\n# The short X.Y version.\nversion = re.match(r\'^(\\d+\\.\\d+)\', release).expand(r\'\\1\')\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\ntoday_fmt = \'%Y-%m-%d\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\'_build\']\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n#default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\nshow_authors = True\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n\n# If true, keep warnings as ""system message"" paragraphs in the built documents.\n#keep_warnings = False\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n# html_theme = \'nature\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\n#html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# ""<project> v<release> documentation"".\n#html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n#html_logo = None\n\n# The name of an image file (relative to this directory) to use as a favicon of\n# the docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\nhtml_favicon = \'_static/favicon.ico\'\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n#html_extra_path = []\n\n# If not \'\', a \'Last updated on:\' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = \'%b %d, %Y\'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# This is required for the alabaster theme\n# refs: http://alabaster.readthedocs.io/en/latest/installation.html#sidebars\n#html_sidebars = {\n#    \'**\': [\n#        \'about.html\',\n#        \'navigation.html\',\n#        \'relations.html\',  # needs \'show_related\': True theme option to display\n#        \'searchbox.html\',\n#        \'donate.html\',\n#    ]\n#}\nhtml_sidebars = {\n    \'**\' : [\n        \'logo-text.html\',\n        \'searchbox.html\',\n        \'globaltoc.html\',\n        # \'sourcelink.html\'\n    ]\n}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n\n# If false, no module index is generated.\n#html_domain_indices = True\n\n# If false, no index is generated.\n#html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\n#html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n#html_file_suffix = None\n\n# Language to be used for generating the HTML full-text search index.\n# Sphinx supports the following languages:\n#   \'da\', \'de\', \'en\', \'es\', \'fi\', \'fr\', \'h\', \'it\', \'ja\'\n#   \'nl\', \'no\', \'pt\', \'ro\', \'r\', \'sv\', \'tr\'\n#html_search_language = \'en\'\n\n# A dictionary with options for the search language support, empty by default.\n# Now only \'ja\' uses this config value\n#html_search_options = {\'type\': \'default\'}\n\n# The name of a javascript file (relative to the configuration directory) that\n# implements a search results scorer. If empty, the default will be used.\n#html_search_scorer = \'scorer.js\'\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'Strawberryfieldsdoc\'\n\n# # -- Xanadu theme ---------------------------------------------------------\nhtml_theme = \'xanadu_theme\'\nhtml_theme_path = [\'.\']\n\n# Register the theme as an extension to generate a sitemap.xml\n# extensions.append(""guzzle_sphinx_theme"")\n\n# xanadu theme options (see theme.conf for more information)\nhtml_theme_options = {\n    # Set the path to a special layout to include for the homepage\n    # ""homepage"": ""special_index.html"",\n\n    # Set the name of the project to appear in the left sidebar.\n    ""project_nav_name"": ""Strawberry Fields"",\n    ""touch_icon"": ""_static/logo_new.png"",\n\n    # Set GA account ID to enable tracking\n    ""google_analytics_account"": ""UA-116279123-2"",\n\n    # colors\n    ""navigation_button"": ""#b13a59"",\n    ""navigation_button_hover"": ""#712b3d"",\n    ""toc_caption"": ""#b13a59"",\n    ""toc_hover"": ""#b13a59"",\n    ""table_header_bg"": ""#ffdce5"",\n    ""table_header_border"": ""#b13a59"",\n    ""download_button"": ""#b13a59"",\n\n    # gallery options\n    ""github_repo"": ""XanaduAI/strawberryfields"",\n    ""gallery_dirs"": sphinx_gallery_conf[\'gallery_dirs\']\n}\n\nedit_on_github_project = \'XanaduAI/strawberryfields\'\nedit_on_github_branch = \'master/doc\'\n\n\n# the order in which autodoc lists the documented members\nautodoc_member_order = \'bysource\'\n\n# inheritance_diagram graphviz attributes\ninheritance_node_attrs = dict(color=\'lightskyblue1\', style=\'filled\')\n\n\nfrom custom_directives import IncludeDirective, GalleryItemDirective, CustomGalleryItemDirective, DetailsDirective\n\ndef setup(app):\n    app.add_directive(\'includenodoc\', IncludeDirective)\n    app.add_directive(\'galleryitem\', GalleryItemDirective)\n    app.add_directive(\'customgalleryitem\', CustomGalleryItemDirective)\n    app.add_directive(\'details\', DetailsDirective)\n    app.add_stylesheet(\'xanadu_gallery.css\')\n'"
doc/custom_directives.py,0,"b'# BSD 3-Clause License\n\n# Copyright (c) 2017, Pytorch contributors\n# All rights reserved.\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# * Redistributions of source code must retain the above copyright notice, this\n#   list of conditions and the following disclaimer.\n\n# * Redistributions in binary form must reproduce the above copyright notice,\n#   this list of conditions and the following disclaimer in the documentation\n#   and/or other materials provided with the distribution.\n\n# * Neither the name of the copyright holder nor the names of its\n#   contributors may be used to endorse or promote products derived from\n#   this software without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nfrom docutils.parsers.rst import Directive, directives\nfrom docutils.statemachine import StringList \nfrom docutils import nodes\nimport re\nimport os\nimport sphinx_gallery\n\ntry:\n    FileNotFoundError\nexcept NameError:\n    FileNotFoundError = IOError\n\n\nclass IncludeDirective(Directive):\n    """"""Include source file without docstring at the top of file.\n\n    Implementation just replaces the first docstring found in file\n    with \'\' once.\n\n    Example usage:\n\n    .. includenodoc:: /beginner/examples_tensor/two_layer_net_tensor.py\n\n    """"""\n\n    # defines the parameter the directive expects\n    # directives.unchanged means you get the raw value from RST\n    required_arguments = 1\n    optional_arguments = 0\n    final_argument_whitespace = True\n    has_content = False\n    add_index = False\n\n    docstring_pattern = r\'""""""(?P<docstring>(?:.|[\\r\\n])*?)""""""\\n\'\n    docstring_regex = re.compile(docstring_pattern)\n\n    def run(self):\n        document = self.state.document\n        env = document.settings.env\n        rel_filename, filename = env.relfn2path(self.arguments[0])\n\n        try:\n            text = open(filename).read()\n            text_no_docstring = self.docstring_regex.sub(\'\', text, count=1)\n\n            code_block = nodes.literal_block(text=text_no_docstring)\n            return [code_block]\n        except FileNotFoundError as e:\n            print(e)\n            return []\n\n\nclass GalleryItemDirective(Directive):\n    """"""\n    Create a sphinx gallery thumbnail for insertion anywhere in docs.\n\n    Optionally, you can specify the custom figure and intro/tooltip for the\n    thumbnail.\n\n    Example usage:\n\n    .. galleryitem:: intermediate/char_rnn_generation_tutorial.py\n        :figure: _static/img/char_rnn_generation.png\n        :intro: Put your custom intro here.\n        :size: put image size here\n\n    If figure is specified, a thumbnail will be made out of it and stored in\n    _static/thumbs. Therefore, consider _static/thumbs as a \'built\' directory.\n    """"""\n\n    required_arguments = 1\n    optional_arguments = 1\n    final_argument_whitespace = True\n    option_spec = {\'figure\': directives.unchanged,\n                   \'intro\': directives.unchanged}\n    has_content = False\n    add_index = False\n\n    def run(self):\n        args = self.arguments\n        fname = args[-1]\n\n        env = self.state.document.settings.env\n        fname, abs_fname = env.relfn2path(fname)\n        basename = os.path.basename(fname)\n        dirname = os.path.dirname(fname)\n\n        try:\n            if \'intro\' in self.options:\n                intro = self.options[\'intro\'][:195] + \'...\'\n            else:\n                _, blocks = sphinx_gallery.gen_rst.split_code_and_text_blocks(abs_fname)\n                intro, _ = sphinx_gallery.gen_rst.extract_intro_and_title(abs_fname, blocks[0][1])\n\n            thumbnail_rst = sphinx_gallery.backreferences._thumbnail_div(\n                dirname, basename, intro)\n\n            if \'figure\' in self.options:\n                rel_figname, figname = env.relfn2path(self.options[\'figure\'])\n                save_figname = os.path.join(\'_static/thumbs/\',\n                                            os.path.basename(figname))\n\n                try:\n                    os.makedirs(\'_static/thumbs\')\n                except OSError:\n                    pass\n\n                x, y = (400, 280)\n                if \'size\' in self.options:\n                    x, y = self.options[\'size\'].split("" "")\n\n                sphinx_gallery.gen_rst.scale_image(figname, save_figname,\n                                                   x, y)\n                # replace figure in rst with simple regex\n                thumbnail_rst = re.sub(r\'..\\sfigure::\\s.*\\.png\',\n                                       \'.. figure:: /{}\'.format(save_figname),\n                                       thumbnail_rst)\n\n            thumbnail = StringList(thumbnail_rst.split(\'\\n\'))\n            thumb = nodes.paragraph()\n            self.state.nested_parse(thumbnail, self.content_offset, thumb)\n\n            return [thumb]\n        except FileNotFoundError as e:\n            print(e)\n            return []\n\n\nGALLERY_TEMPLATE = """"""\n.. raw:: html\n\n    <div class=""sphx-glr-thumbcontainer"" tooltip=""{tooltip}"">\n\n.. only:: html\n\n    .. figure:: /{thumbnail}\n\n        {description}\n\n.. raw:: html\n\n    </div>\n""""""\n\n\nclass CustomGalleryItemDirective(Directive):\n    """"""Create a sphinx gallery style thumbnail.\n\n    tooltip and figure are self explanatory. Description could be a link to\n    a document like in below example.\n\n    Example usage:\n\n    .. customgalleryitem::\n        :tooltip: I am writing this tutorial to focus specifically on NLP for people who have never written code in any deep learning framework\n        :figure: /_static/img/thumbnails/babel.jpg\n        :description: :doc:`/beginner/deep_learning_nlp_tutorial`\n        :size: put image size here\n\n    If figure is specified, a thumbnail will be made out of it and stored in\n    _static/thumbs. Therefore, consider _static/thumbs as a \'built\' directory.\n    """"""\n\n    required_arguments = 0\n    optional_arguments = 1\n    final_argument_whitespace = True\n    option_spec = {\'tooltip\': directives.unchanged,\n                   \'figure\': directives.unchanged,\n                   \'description\': directives.unchanged,\n                   \'size\': directives.unchanged}\n\n    has_content = False\n    add_index = False\n\n    def run(self):\n        try:\n            if \'tooltip\' in self.options:\n                tooltip = self.options[\'tooltip\'][:195]\n            else:\n                raise ValueError(\'tooltip not found\')\n\n            if \'figure\' in self.options:\n                env = self.state.document.settings.env\n                rel_figname, figname = env.relfn2path(self.options[\'figure\'])\n                thumbnail = os.path.join(\'_static/thumbs/\', os.path.basename(figname))\n\n                try:\n                    os.makedirs(\'_static/thumbs\')\n                except FileExistsError:\n                    pass\n\n                x, y = (400, 280)\n                if \'size\' in self.options:\n                    x, y = self.options[\'size\'].split("" "")\n\n                sphinx_gallery.gen_rst.scale_image(figname, thumbnail, int(x), int(y))\n            else:\n                thumbnail = \'_static/thumbs/code.png\'\n\n            if \'description\' in self.options:\n                description = self.options[\'description\']\n            else:\n                raise ValueError(\'description not doc found\')\n\n        except FileNotFoundError as e:\n            print(e)\n            return []\n        except ValueError as e:\n            print(e)\n            raise\n            return []\n\n        thumbnail_rst = GALLERY_TEMPLATE.format(tooltip=tooltip,\n                                                thumbnail=thumbnail,\n                                                description=description)\n        thumbnail = StringList(thumbnail_rst.split(\'\\n\'))\n        thumb = nodes.paragraph()\n        self.state.nested_parse(thumbnail, self.content_offset, thumb)\n        return [thumb]\n\n\nDETAILS_TEMPLATE = """"""\n.. raw:: html\n\n    <a class=""details-header collapse-header"" data-toggle=""collapse"" href=""#details"" aria-expanded=""false"" aria-controls=""details"">\n        <h2 style=""font-size: 24px;"">\n            <i class=""fas fa-angle-down rotate"" style=""float: right;""></i> {title}\n        </h2>\n    </a>\n    <div class=""collapse"" id=""details"">\n\n{content}\n\n.. raw:: html\n\n    </div>\n""""""\n\n\nclass DetailsDirective(Directive):\n    """"""Create a collapsed details section in the documentation.""""""\n    required_arguments = 0\n    optional_arguments = 1\n    final_argument_whitespace = False\n    option_spec = {\'name\': directives.unchanged}\n    has_content = True\n    add_index = False\n\n    def run(self):\n        name = self.options.get(""name"", ""Details and conventions"")\n        rst = DETAILS_TEMPLATE.format(title=name, content=""\\n"".join(self.content))\n        string_list = StringList(rst.split(\'\\n\'))\n        node = nodes.tbody()\n        self.state.nested_parse(string_list, self.content_offset, node)\n        return [node]\n'"
examples/IQP.py,0,"b'#!/usr/bin/env python3\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\n\n# initialize engine and program objects\neng = sf.Engine(backend=""fock"", backend_options={""cutoff_dim"": 5})\niqp_circuit = sf.Program(4)\n\nwith iqp_circuit.context as q:\n    # prepare the input squeezed states\n    S = Sgate(-1)\n    S | q[0]\n    S | q[1]\n    S | q[2]\n    S | q[3]\n\n    # gates diagonal in the x quadrature\n    CZgate(0.5719) | (q[0], q[1])\n    Vgate(-1.9782) | q[2]\n    Zgate(2.0603)  | q[3]\n    Zgate(-0.7804) | q[0]\n    Zgate(0.8578)  | q[2]\n    CZgate(1.321)  | (q[1], q[2])\n    Zgate(0.473)   | q[3]\n    CZgate(0.9946) | (q[0], q[3])\n    Zgate(0.1223)  | q[3]\n    Vgate(0.6157)  | q[0]\n    Vgate(0.3110)  | q[1]\n    Zgate(-1.243)  | q[2]\n    # end circuit\n\n# run the engine\nresults = eng.run(iqp_circuit)\n'"
examples/boson_sampling.py,0,"b'#!/usr/bin/env python3\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\n\n# initialize engine and program objects\neng = sf.Engine(backend=""fock"", backend_options={""cutoff_dim"": 7})\nboson_sampling = sf.Program(4)\n\nwith boson_sampling.context as q:\n    # prepare the input fock states\n    Fock(1) | q[0]\n    Fock(1) | q[1]\n    Vac     | q[2]\n    Fock(1) | q[3]\n\n    # rotation gates\n    Rgate(0.5719) | q[0]\n    Rgate(-1.9782) | q[1]\n    Rgate(2.0603) | q[2]\n    Rgate(0.0644) | q[3]\n\n    # beamsplitter array\n    BSgate(0.7804, 0.8578)  | (q[0], q[1])\n    BSgate(0.06406, 0.5165) | (q[2], q[3])\n    BSgate(0.473, 0.1176)   | (q[1], q[2])\n    BSgate(0.563, 0.1517)   | (q[0], q[1])\n    BSgate(0.1323, 0.9946)  | (q[2], q[3])\n    BSgate(0.311, 0.3231)   | (q[1], q[2])\n    BSgate(0.4348, 0.0798)  | (q[0], q[1])\n    BSgate(0.4368, 0.6157)  | (q[2], q[3])\n    # end circuit\n\n# run the engine\nresults = eng.run(boson_sampling)\n\n# extract the joint Fock probabilities\nprobs = results.state.all_fock_probs()\n\n# print the joint Fock state probabilities\nprint(probs[1, 1, 0, 1])\nprint(probs[2, 0, 0, 1])\n'"
examples/custom_operation.py,0,"b'#!/usr/bin/env python3\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\nfrom strawberryfields.utils import operation\n\n\n@operation(4)\ndef prepare_squeezing(q):\n    """"""This operation prepares modes 0 and 1\n    as squeezed states with r = -1.\n\n    Args:\n        q (register): the qumode register.\n    """"""\n    S = Sgate(-1)\n    S | q[0]\n    S | q[1]\n\n\n@operation(3)\ndef circuit_op(v1, v2, q):\n    """"""Some gates that are groups into a custom operation.\n\n    Args:\n        v1 (float): parameter for CZgate\n        v2 (float): parameter for the cubic phase gate\n        q (register): the qumode register\n    """"""\n    CZgate(v1) | (q[0], q[1])\n    Vgate(v2) | q[1]\n\n\n# initialize engine and program objects\neng = sf.Engine(backend=""fock"", backend_options={""cutoff_dim"": 5})\ncircuit = sf.Program(4)\n\nwith circuit.context as q:\n    # The following operation takes no arguments\n    prepare_squeezing() | q\n\n    # another operation with 2 parameters that operates on three registers: 0, 1\n    circuit_op(0.5719, 2.0603) | (q[0], q[1], q[3])\n\n# run the engine\nresults = eng.run(circuit)\n'"
examples/gate_teleportation.py,0,"b'#!/usr/bin/env python3\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\n\n# initialize engine and program objects\neng = sf.Engine(backend=""gaussian"")\ngate_teleportation = sf.Program(4)\n\nwith gate_teleportation.context as q:\n    # create initial states\n    Squeezed(0.1) | q[0]\n    Squeezed(-2)  | q[1]\n    Squeezed(-2)  | q[2]\n\n    # apply the gate to be teleported\n    Pgate(0.5) | q[1]\n\n    # conditional phase entanglement\n    CZgate(1) | (q[0], q[1])\n    CZgate(1) | (q[1], q[2])\n\n    # projective measurement onto\n    # the position quadrature\n    Fourier.H | q[0]\n    MeasureX | q[0]\n    Fourier.H | q[1]\n    MeasureX | q[1]\n    # compare against the expected output\n    # X(q1/sqrt(2)).F.P(0.5).X(q0/sqrt(0.5)).F.|z>\n    # not including the corrections\n    Squeezed(0.1) | q[3]\n    Fourier       | q[3]\n    Xgate(q[0])   | q[3]\n    Pgate(0.5)    | q[3]\n    Fourier       | q[3]\n    Xgate(q[1])   | q[3]\n    # end circuit\n\nresults = eng.run(gate_teleportation)\nprint(results.state.reduced_gaussian([2]))\nprint(results.state.reduced_gaussian([3]))\n'"
examples/gaussian_boson_sampling.py,0,"b'#!/usr/bin/env python3\nimport numpy as np\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\n\n# initialize engine and program objects\neng = sf.Engine(backend=""gaussian"")\ngbs = sf.Program(4)\n\n# define the linear interferometer\nU = np.array([\n [ 0.219546940711-0.256534554457j, 0.611076853957+0.524178937791j,\n    -0.102700187435+0.474478834685j,-0.027250232925+0.03729094623j],\n [ 0.451281863394+0.602582912475j, 0.456952590016+0.01230749109j,\n    0.131625867435-0.450417744715j, 0.035283194078-0.053244267184j],\n [ 0.038710094355+0.492715562066j,-0.019212744068-0.321842852355j,\n    -0.240776471286+0.524432833034j,-0.458388143039+0.329633367819j],\n [-0.156619083736+0.224568570065j, 0.109992223305-0.163750223027j,\n    -0.421179844245+0.183644837982j, 0.818769184612+0.068015658737j]\n])\n\n\nwith gbs.context as q:\n    # prepare the input squeezed states\n    S = Sgate(1)\n    S | q[0]\n    S | q[1]\n    S | q[2]\n    S | q[3]\n\n    # linear interferometer\n    Interferometer(U) | q\n    # end circuit\n\n# run the engine\nresults = eng.run(gbs)\n\n# Fock states to measure at output\nmeasure_states = [[0,0,0,0], [1,1,0,0], [0,1,0,1], [1,1,1,1], [2,0,0,0]]\n\n# extract the probabilities of calculating several\n# different Fock states at the output, and print them to the terminal\nfor i in measure_states:\n    prob = results.state.fock_prob(i)\n    print(""|{}>: {}"".format("""".join(str(j) for j in i), prob))\n'"
examples/gaussian_cloning.py,0,"b'import numpy as np\nfrom numpy import pi, sqrt\n\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\n\n# initialize engine and program objects\neng = sf.Engine(backend=""gaussian"")\ngaussian_cloning = sf.Program(4)\n\nwith gaussian_cloning.context as q:\n    # state to be cloned\n    Coherent(0.7+1.2j) | q[0]\n\n    # 50-50 beamsplitter\n    BS = BSgate(pi/4, 0)\n\n    # symmetric Gaussian cloning scheme\n    BS | (q[0], q[1])\n    BS | (q[1], q[2])\n    MeasureX | q[1]\n    MeasureP | q[2]\n    Xgate(q[1].par * sqrt(2)) | q[0]\n    Zgate(q[2].par * sqrt(2)) | q[0]\n\n    # after the final beamsplitter, modes q[0] and q[3]\n    # will contain identical approximate clones of the\n    # initial state Coherent(0.1+0j)\n    BS | (q[0], q[3])\n    # end circuit\n\n# run the engine\nresults = eng.run(gaussian_cloning, modes=[0, 3])\n\n# return the cloning fidelity\nfidelity = sqrt(results.state.fidelity_coherent([0.7+1.2j, 0.7+1.2j]))\n# return the cloned displacement\nalpha = results.state.displacement()\n\n# run the engine over an ensemble\nreps = 1000\nf = np.empty([reps])\na = np.empty([reps], dtype=np.complex128)\n\nfor i in range(reps):\n    eng.reset()\n    results = eng.run(gaussian_cloning, modes=[0])\n    f[i] = results.state.fidelity_coherent([0.7+1.2j])\n    a[i] = results.state.displacement()\n\nprint(""Fidelity of cloned state:"", np.mean(f))\nprint(""Mean displacement of cloned state:"", np.mean(a))\nprint(""Mean covariance matrix of cloned state:"", np.cov([a.real, a.imag]))\n'"
examples/hamiltonian_simulation.py,0,"b'#!/usr/bin/env python3\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\nfrom numpy import pi\n\n# initialize engine and program objects\neng = sf.Engine(backend=""fock"", backend_options={""cutoff_dim"": 5})\nham_simulation = sf.Program(2)\n\n# set the Hamiltonian parameters\nJ = 1           # hopping transition\nU = 1.5         # on-site interaction\nk = 20          # Lie product decomposition terms\nt = 1.086       # timestep\ntheta = -J*t/k  \nr = -U*t/(2*k)\n\nwith ham_simulation.context as q:\n    # prepare the initial state\n    Fock(2) | q[0]\n\n    # Two node tight-binding\n    # Hamiltonian simulation\n\n    for i in range(k):\n        BSgate(theta, pi/2) | (q[0], q[1])\n        Kgate(r)  | q[0]\n        Rgate(-r) | q[0]\n        Kgate(r)  | q[1]\n        Rgate(-r) | q[1]\n    # end circuit\n\n# run the engine\nresults = eng.run(ham_simulation)\n# the output state probabilities\nprint(results.state.fock_prob([0,2]))\nprint(results.state.fock_prob([1,1]))\nprint(results.state.fock_prob([2,0]))\n'"
examples/optimization.py,4,"b'#!/usr/bin/env python3\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\nimport tensorflow as tf\n\n# initialize engine and program objects\neng = sf.Engine(backend=""tf"", backend_options={""cutoff_dim"": 7})\ncircuit = sf.Program(1)\n\ntf_alpha = tf.Variable(0.1)\ntf_phi = tf.Variable(0.1)\n\nalpha, phi = circuit.params(\'alpha\', \'phi\')\n\nwith circuit.context as q:\n    Dgate(alpha, phi) | q[0]\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.1)\nsteps = 50\n\nfor step in range(steps):\n\n    # reset the engine if it has already been executed\n    if eng.run_progs:\n        eng.reset()\n\n    with tf.GradientTape() as tape:\n        # execute the engine\n        results = eng.run(circuit, args={\'alpha\': tf_alpha, \'phi\': tf_phi})\n        # get the probability of fock state |1>\n        prob = results.state.fock_prob([1])\n        # negative sign to maximize prob\n        loss = -prob\n\n    gradients = tape.gradient(loss, [tf_alpha, tf_phi])\n    opt.apply_gradients(zip(gradients, [tf_alpha, tf_phi]))\n    print(""Value at step {}: {}"".format(step, prob))\n'"
examples/quantum_neural_network.py,17,"b'#!/usr/bin/env python3\nimport numpy as np\nimport tensorflow as tf\nimport strawberryfields as sf\nfrom strawberryfields import ops\n\n\n# =========================================================================\n# Utility functions\n# =========================================================================\n\n\n# define interferometer\ndef interferometer(params, q):\n    """"""Parameterised interferometer acting on ``N`` modes.\n\n    Args:\n        params (list[float]): list of length ``max(1, N-1) + (N-1)*N`` parameters.\n\n            * The first ``N(N-1)/2`` parameters correspond to the beamsplitter angles\n            * The second ``N(N-1)/2`` parameters correspond to the beamsplitter phases\n            * The final ``N-1`` parameters correspond to local rotation on the first N-1 modes\n\n        q (list[RegRef]): list of Strawberry Fields quantum registers the interferometer\n            is to be applied to\n    """"""\n    N = len(q)\n    theta = params[:N*(N-1)//2]\n    phi = params[N*(N-1)//2:N*(N-1)]\n    rphi = params[-N+1:]\n\n    if N == 1:\n        # the interferometer is a single rotation\n        ops.Rgate(rphi[0]) | q[0]\n        return\n\n    n = 0  # keep track of free parameters\n\n    # Apply the rectangular beamsplitter array\n    # The array depth is N\n    for l in range(N):\n        for k, (q1, q2) in enumerate(zip(q[:-1], q[1:])):\n            # skip even or odd pairs depending on layer\n            if (l + k) % 2 != 1:\n                ops.BSgate(theta[n], phi[n]) | (q1, q2)\n                n += 1\n\n    # apply the final local phase shifts to all modes except the last one\n    for i in range(max(1, N - 1)):\n        ops.Rgate(rphi[i]) | q[i]\n    # Rgate only applied to first N - 1 modes\n\n\n# define layer\ndef layer(params, q):\n    """"""CV quantum neural network layer acting on ``N`` modes.\n\n    Args:\n        params (list[float]): list of length ``2*(max(1, N-1) + N**2 + n)`` containing\n            the number of parameters for the layer\n        q (list[RegRef]): list of Strawberry Fields quantum registers the layer\n            is to be applied to\n    """"""\n    N = len(q)\n    M = int(N * (N - 1)) + max(1, N - 1)\n\n    int1 = params[:M]\n    s = params[M:M+N]\n    int2 = params[M+N:2*M+N]\n    dr = params[2*M+N:2*M+2*N]\n    dp = params[2*M+2*N:2*M+3*N]\n    k = params[2*M+3*N:2*M+4*N]\n\n    # begin layer\n    interferometer(int1, q)\n\n    for i in range(N):\n        ops.Sgate(s[i]) | q[i]\n\n    interferometer(int2, q)\n\n    for i in range(N):\n        ops.Dgate(dr[i], dp[i]) | q[i]\n        ops.Kgate(k[i]) | q[i]\n    # end layer\n\n\ndef init_weights(modes, layers, active_sd=0.0001, passive_sd=0.1):\n    """"""Initialize a 2D TensorFlow Variable containing normally-distributed\n    random weights for an ``N`` mode quantum neural network with ``L`` layers.\n\n    Args:\n        modes (int): the number of modes in the quantum neural network\n        layers (int): the number of layers in the quantum neural network\n        active_sd (float): the standard deviation used when initializing\n            the normally-distributed weights for the active parameters\n            (displacement, squeezing, and Kerr magnitude)\n        passive_sd (float): the standard deviation used when initializing\n            the normally-distributed weights for the passive parameters\n            (beamsplitter angles and all gate phases)\n\n    Returns:\n        tf.Variable[tf.float32]: A TensorFlow Variable of shape\n        ``[layers, 2*(max(1, modes-1) + modes**2 + modes)]``, where the Lth\n        row represents the layer parameters for the Lth layer.\n    """"""\n    # Number of interferometer parameters:\n    M = int(modes * (modes - 1)) + max(1, modes - 1)\n\n    # Create the TensorFlow variables\n    int1_weights = tf.random.normal(shape=[layers, M], stddev=passive_sd)\n    s_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n    int2_weights = tf.random.normal(shape=[layers, M], stddev=passive_sd)\n    dr_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n    dp_weights = tf.random.normal(shape=[layers, modes], stddev=passive_sd)\n    k_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n\n    weights = tf.concat([int1_weights, s_weights, int2_weights, dr_weights, dp_weights, k_weights], axis=1)\n    weights = tf.Variable(weights)\n\n    return weights\n\n\n# =========================================================================\n# Define the optimization problem\n# =========================================================================\n\n\n# set the random seed\ntf.random.set_seed(137)\nnp.random.seed(137)\n\n\n# define width and depth of CV quantum neural network\nmodes = 1\nlayers = 8\ncutoff_dim = 6\n\n\n# defining desired state (single photon state)\ntarget_state = np.zeros(cutoff_dim)\ntarget_state[1] = 1\ntarget_state = tf.constant(target_state, dtype=tf.complex64)\n\n\n# initialize engine and program\neng = sf.Engine(backend=""tf"", backend_options={""cutoff_dim"": cutoff_dim})\nqnn = sf.Program(modes)\n\n\n# initialize QNN weights\nweights = init_weights(modes, layers)\nnum_params = np.prod(weights.shape)\n\n\n# Create array of Strawberry Fields symbolic gate arguments, matching\n# the size of the weights Variable.\nsf_params = np.arange(num_params).reshape(weights.shape).astype(np.str)\nsf_params = np.array([qnn.params(*i) for i in sf_params])\n\n\n# Construct the symbolic Strawberry Fields program by\n# looping and applying layers to the program.\nwith qnn.context as q:\n    for k in range(layers):\n        layer(sf_params[k], q)\n\n\ndef cost(weights):\n    # Create a dictionary mapping from the names of the Strawberry Fields\n    # symbolic gate parameters to the TensorFlow weight values.\n    mapping = {p.name: w for p, w in zip(sf_params.flatten(), tf.reshape(weights, [-1]))}\n\n    # run the engine\n    state = eng.run(qnn, args=mapping).state\n    ket = state.ket()\n\n    difference = tf.reduce_sum(tf.abs(ket - target_state))\n    fidelity = tf.abs(tf.reduce_sum(tf.math.conj(ket) * target_state)) ** 2\n    return difference, fidelity, ket, tf.math.real(state.trace())\n\n\n# set up optimizer\nopt = tf.keras.optimizers.Adam()\ncost_before, fidelity_before, _, _ = cost(weights)\n\nprint(""Beginning optimization"")\n\n\n# Perform the optimization\nfor i in range(1000):\n    # reset the engine if it has already been executed\n    if eng.run_progs:\n        eng.reset()\n\n    with tf.GradientTape() as tape:\n        loss, fid, _, trace = cost(weights)\n\n    # one repetition of the optimization\n    gradients = tape.gradient(loss, weights)\n    opt.apply_gradients(zip([gradients], [weights]))\n\n    # Prints progress at every rep\n    if i % 1 == 0:\n        print(""Rep: {} Cost: {:.4f} Fidelity: {:.4f} Trace: {:.4f}"".format(i, loss, fid, trace))\n\n\ncost_after, fidelity_after, ket_after, _ = cost(weights)\n\n\nprint(""\\nFidelity before optimization: "", fidelity_before.numpy())\nprint(""Fidelity after optimization: "", fidelity_after.numpy())\nprint(""\\nTarget state: "", target_state.numpy())\nprint(""Output state: "", np.round(ket_after.numpy(), decimals=3))\n'"
examples/teleportation.py,0,"b'#!/usr/bin/env python3\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\nfrom strawberryfields.utils import scale\nfrom numpy import pi, sqrt\n\n# initialize engine and program objects\neng = sf.Engine(backend=""gaussian"")\nteleportation = sf.Program(3)\n\nwith teleportation.context as q:\n    psi, alice, bob = q[0], q[1], q[2]\n\n    # state to be teleported:\n    Coherent(1+0.5j) | psi\n\n    # 50-50 beamsplitter\n    BS = BSgate(pi/4, 0)\n\n    # maximally entangled states\n    Squeezed(-2) | alice\n    Squeezed(2) | bob\n    BS | (alice, bob)\n\n    # Alice performs the joint measurement\n    # in the maximally entangled basis\n    BS | (psi, alice)\n    MeasureX | psi\n    MeasureP | alice\n\n    # Bob conditionally displaces his mode\n    # based on Alice\'s measurement result\n    Xgate(psi.par*sqrt(2)) | bob\n    Zgate(alice.par*sqrt(2)) | bob\n    # end circuit\n\nresults = eng.run(teleportation)\n# view Bob\'s output state and fidelity\nprint(results.samples)\nprint(results.state.displacement([2]))\nprint(results.state.fidelity_coherent([0, 0, 1+0.5j]))\n'"
examples_apps/gate_synthesis.py,17,"b'r""""""\nQuantum gate synthesis\n======================\n\nThis demonstration works through the process used to produce the gate\nsynthesis results presented in `""Machine learning method for state\npreparation and gate synthesis on photonic quantum\ncomputers"" <https://arxiv.org/abs/1807.10781>`__.\n\nThis tutorial uses the TensorFlow backend of Strawberry Fields, giving us\naccess to a number of additional functionalities including: GPU integration,\nautomatic gradient computation, built-in optimization algorithms, and other\nmachine learning tools.\n\n\nVariational quantum circuits\n----------------------------\n\nA key element of machine learning is optimization. We can use\nTensorFlow\'s automatic differentiation tools to optimize the parameters\nof variational quantum circuits constructed using Strawberry Fields. In\nthis approach, we fix a circuit architecture where the states, gates,\nand/or measurements may have learnable parameters :math:`\\vec{\\theta}`\nassociated with them. We then define a loss function based on the output\nstate of this circuit. In this case, we define a loss function such that the\naction of the variational quantum circuit is close to some specified target\nunitary.\n\n.. note::\n\n    For more details on the TensorFlow backend in Strawberry Fields, please see\n    :ref:`machine_learning_tutorial`.\n\nFor arbitrary gate synthesis using optimization, we need to make use of\na quantum circuit with a layer structure that is **universal** - that\nis, by \'stacking\' the layers, we can guarantee that we can produce *any*\nCV state with at-most polynomial overhead. Therefore, the architecture\nwe choose must consist of layers with each layer containing\nparameterized Gaussian *and* non-Gaussian gates. **The non-Gaussian\ngates provide both the nonlinearity and the universality of the model.**\nTo this end, we employ the CV quantum neural network architecture\ndescribed below:\n\n.. figure:: https://i.imgur.com/NEsaVIX.png\n   :alt: layer\n\nHere,\n\n-  :math:`\\mathcal{U}_i(\\theta_i,\\phi_i)` is an N-mode linear optical\n   interferometer composed of two-mode beamsplitters\n   :math:`BS(\\theta,\\phi)` and single-mode rotation gates\n   :math:`R(\\phi)=e^{i\\phi\\hat{n}}`,\n\n-  :math:`\\mathcal{D}(\\alpha_i)` are single mode displacements in the\n   phase space by complex value :math:`\\alpha_i`,\n\n-  :math:`\\mathcal{S}(r_i, \\phi_i)` are single mode squeezing operations\n   of magnitude :math:`r_i` and phase :math:`\\phi_i`, and\n\n-  :math:`\\Phi(\\lambda_i)` is a single mode non-Gaussian operation, in\n   this case chosen to be the Kerr interaction\n   :math:`\\mathcal{K}(\\kappa_i)=e^{i\\kappa_i\\hat{n}^2}` of strength\n   :math:`\\kappa_i`.\n\nHyperparameters\n---------------\n\nFirst, we must define the **hyperparameters** of our layer structure:\n\n-  ``cutoff``: the simulation Fock space truncation we will use in the\n   optimization. The TensorFlow backend will perform numerical\n   operations in this truncated Fock space when performing the\n   optimization.\n\n-  ``depth``: The number of layers in our variational quantum\n   circuit. As a general rule, increasing the number of layers (and\n   thus, the number of parameters we are optimizing over) increases the\n   optimizer\'s chance of finding a reasonable local minimum in the\n   optimization landscape.\n\n-  ``reps``: the number of steps in the optimization routine performing\n   gradient descent\n\nSome other optional hyperparameters include:\n\n-  The standard deviation of initial parameters. Note that we make a\n   distinction between the standard deviation of *passive* parameters\n   (those that preserve photon number when changed, such as phase\n   parameters), and *active* parameters (those that introduce or remove\n   energy from the system when changed).\n""""""\nimport numpy as np\n\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\nfrom strawberryfields.utils import operation\n\n# Cutoff dimension\ncutoff = 10\n\n# gate cutoff\ngate_cutoff = 4\n\n# Number of layers\ndepth = 15\n\n# Number of steps in optimization routine performing gradient descent\nreps = 200\n\n# Learning rate\nlr = 0.025\n\n# Standard deviation of initial parameters\npassive_sd = 0.1\nactive_sd = 0.001\n\n\n######################################################################\n# Note that, unlike in state learning, we must also specify a *gate\n# cutoff* :math:`d`. This restricts the target unitary to its action on a\n# :math:`d`-dimensional subspace of the truncated Fock space, where\n# :math:`d\\leq D`, where :math:`D` is the overall simulation Fock basis\n# cutoff. As a result, we restrict the gate synthesis optimization to only\n# :math:`d` input-output relations.\n#\n# The layer parameters :math:`\\vec{\\theta}`\n# -----------------------------------------\n#\n# We use TensorFlow to create the variables corresponding to the gate\n# parameters. Note that each variable has shape ``(depth,)``, with each\n# individual element representing the gate parameter in layer :math:`i`.\n#\n\nimport tensorflow as tf\n\n# set the random seed\ntf.random.set_seed(42)\nnp.random.seed(42)\n\n# squeeze gate\nsq_r = tf.random.normal(shape=[depth], stddev=active_sd)\nsq_phi = tf.random.normal(shape=[depth], stddev=passive_sd)\n\n# displacement gate\nd_r = tf.random.normal(shape=[depth], stddev=active_sd)\nd_phi = tf.random.normal(shape=[depth], stddev=passive_sd)\n\n# rotation gates\nr1 = tf.random.normal(shape=[depth], stddev=passive_sd)\nr2 = tf.random.normal(shape=[depth], stddev=passive_sd)\n\n# kerr gate\nkappa = tf.random.normal(shape=[depth], stddev=active_sd)\n\n\n######################################################################\n# For convenience, we store the TensorFlow variables representing the weights as\n# a tensor:\n\nweights = tf.convert_to_tensor([r1, sq_r, sq_phi, r2, d_r, d_phi, kappa])\nweights = tf.Variable(tf.transpose(weights))\n\n######################################################################\n# Since we have a depth of 15 (so 15 layers), and each layer takes\n# 7 different types of parameters, the final shape of our weights\n# array should be :math:`\\text{depth}\\times 7` or ``(15, 7)``:\n\nprint(weights.shape)\n\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     (15, 7)\n\n\n######################################################################\n# Constructing the circuit\n# ------------------------\n# We can now construct the corresponding single-mode Strawberry Fields program:\n#\n\n# Single-mode Strawberry Fields program\nprog = sf.Program(1)\n\n# Create the 7 Strawberry Fields free parameters for each layer\nsf_params = []\nnames = [""r1"", ""sq_r"", ""sq_phi"", ""r2"", ""d_r"", ""d_phi"", ""kappa""]\n\nfor i in range(depth):\n    # For the ith layer, generate parameter names ""r1_i"", ""sq_r_i"", etc.\n    sf_params_names = [""{}_{}"".format(n, i) for n in names]\n    # Create the parameters, and append them to our list ``sf_params``.\n    sf_params.append(prog.params(*sf_params_names))\n\n######################################################################\n# ``sf_params`` is now a nested list of shape ``(depth, 7)``, matching\n# the shape of ``weights``.\n\nsf_params = np.array(sf_params)\nprint(sf_params.shape)\n\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     (15, 7)\n\n######################################################################\n# Now, we can create a function to define the :math:`i`\\ th layer, acting\n# on qumode ``q``. We add the :class:`~.utils.operation` decorator so that the layer can be used\n# as a single operation when constructing our circuit within the usual\n# Strawberry Fields Program context.\n\n# layer architecture\n@operation(1)\ndef layer(i, q):\n    Rgate(sf_params[i][0]) | q\n    Sgate(sf_params[i][1], sf_params[i][2]) | q\n    Rgate(sf_params[i][3]) | q\n    Dgate(sf_params[i][4], sf_params[i][5]) | q\n    Kgate(sf_params[i][6]) | q\n    return q\n\n######################################################################\n# We must also specify the input states to the variational quantum circuit\n# - these are the Fock state :math:`\\ket{i}`, :math:`i=0,\\dots,d`,\n# allowing us to optimize the circuit parameters to learn the target\n# unitary acting on all input Fock states within the :math:`d`-dimensional\n# subspace.\n#\n\nin_ket = np.zeros([gate_cutoff, cutoff])\nnp.fill_diagonal(in_ket, 1)\n\n# Apply circuit of layers with corresponding depth\nwith prog.context as q:\n    Ket(in_ket) | q\n    for k in range(depth):\n        layer(k) | q[0]\n\n######################################################################\n# Performing the optimization\n# ---------------------------\n#\n# :math:`\\newcommand{ket}[1]{\\left|#1\\right\\rangle}`\n# With the Strawberry Fields TensorFlow backend calculating the\n# resulting state of the circuit symbolically, we can use TensorFlow to\n# optimize the gate parameters to minimize the cost function we specify.\n# With gate synthesis, we minimize the overlaps in the Fock basis\n# between the target and learnt unitaries via the following cost function:\n#\n# .. math::\n#\n#     C(\\vec{\\theta}) = \\frac{1}{d}\\sum_{i=0}^{d-1} \\left| \\langle i \\mid\n#     V^\\dagger U(\\vec{\\theta})\\mid i\\rangle - 1\\right|\n#\n# where :math:`V` is the target unitary, :math:`U(\\vec{\\theta})` is the\n# learnt unitary, and :math:`d` is the gate cutoff. Note that this is a\n# generalization of state preparation to more than one input-output\n# relation.\n#\n# For our target unitary, let\'s use Strawberry Fields to generate a 4x4\n# random unitary:\n#\n\nfrom strawberryfields.utils import random_interferometer\n\n# define unitary up to gate_cutoff\nrandom_unitary = random_interferometer(gate_cutoff)\nprint(random_unitary)\n\n# extend unitary up to cutoff\ntarget_unitary = np.identity(cutoff, dtype=np.complex128)\ntarget_unitary[:gate_cutoff, :gate_cutoff] = random_unitary\n\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     [[ 0.23648826-0.48221431j  0.06829648+0.04447898j  0.51150074-0.09529866j\n#        0.55205719-0.35974699j]\n#      [-0.11148167+0.69780321j -0.24943828+0.08410701j  0.46705929-0.43192981j\n#        0.16220654-0.01817602j]\n#      [-0.22351926-0.25918352j  0.24364996-0.05375623j -0.09259829-0.53810588j\n#        0.27267708+0.66941977j]\n#      [ 0.11519953-0.28596729j -0.90164923-0.22099186j -0.09627758-0.13105595j\n#       -0.0200152 +0.12766128j]]\n\n######################################################################\n# This matches the gate cutoff of :math:`d=4` that we chose above when\n# defining our hyperparameters.\n#\n# Now, we instantiate the Strawberry Fields TensorFlow backend:\n\neng = sf.Engine(\'tf\', backend_options={""cutoff_dim"": cutoff, ""batch_size"": gate_cutoff})\n\n######################################################################\n# Here, we use the ``batch_size`` argument to perform the optimization in\n# parallel - each batch calculates the variational quantum circuit acting\n# on a different input Fock state: :math:`U(\\vec{\\theta}) | n\\rangle`.\n#\n\nin_state = np.arange(gate_cutoff)\n\n# extract action of the target unitary acting on\n# the allowed input fock states.\ntarget_kets = np.array([target_unitary[:, i] for i in in_state])\ntarget_kets = tf.constant(target_kets, dtype=tf.complex64)\n\n######################################################################\n# Using this target unitary, we define the cost function we would like to\n# minimize. We must use TensorFlow functions to manipulate this data, as well\n# as a ``GradientTape`` to keep track of the corresponding gradients!\n#\ndef cost(weights):\n    # Create a dictionary mapping from the names of the Strawberry Fields\n    # free parameters to the TensorFlow weight values.\n    mapping = {p.name: w for p, w in zip(sf_params.flatten(), tf.reshape(weights, [-1]))}\n\n    # Run engine\n    state = eng.run(prog, args=mapping).state\n\n    # Extract the statevector\n    ket = state.ket()\n\n    # overlaps\n    overlaps = tf.math.real(tf.einsum(\'bi,bi->b\', tf.math.conj(target_kets), ket))\n    mean_overlap = tf.reduce_mean(overlaps)\n\n    # Objective function to minimize\n    cost = tf.abs(tf.reduce_sum(overlaps - 1))\n    return cost, overlaps, ket\n\n\n\n######################################################################\n# Now that the cost function is defined, we can define and run the\n# optimization. Below, we choose the Adam optimizer that is built into\n# TensorFlow.\n#\n\n# Using Adam algorithm for optimization\nopt = tf.keras.optimizers.Adam(learning_rate=lr)\n\n\n######################################################################\n# We then loop over all repetitions, storing the best predicted overlap\n# value.\n#\n\noverlap_progress = []\ncost_progress = []\n\n# Run optimization\nfor i in range(reps):\n\n    # reset the engine if it has already been executed\n    if eng.run_progs:\n        eng.reset()\n\n    # one repetition of the optimization\n    with tf.GradientTape() as tape:\n        loss, overlaps_val, ket_val = cost(weights)\n\n    # calculate the mean overlap\n    # This gives us an idea of how the optimization is progressing\n    mean_overlap_val = np.mean(overlaps_val)\n\n    # store cost at each step\n    cost_progress.append(loss)\n    overlap_progress.append(overlaps_val)\n\n    # one repetition of the optimization\n    gradients = tape.gradient(loss, weights)\n    opt.apply_gradients(zip([gradients], [weights]))\n\n    # Prints progress at every rep\n    if i % 1 == 0:\n        # print progress\n        print(""Rep: {} Cost: {:.4f} Mean overlap: {:.4f}"".format(i, loss, mean_overlap_val))\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     Rep: 0 Cost: 4.2947 Mean overlap: -0.0737\n#     Rep: 1 Cost: 3.2125 Mean overlap: 0.1969\n#     Rep: 2 Cost: 4.3774 Mean overlap: -0.0944\n#     Rep: 3 Cost: 3.6844 Mean overlap: 0.0789\n#     Rep: 4 Cost: 3.7196 Mean overlap: 0.0701\n#     Rep: 5 Cost: 3.2360 Mean overlap: 0.1910\n#     Rep: 6 Cost: 3.1782 Mean overlap: 0.2055\n#     Rep: 7 Cost: 3.1090 Mean overlap: 0.2228\n#     Rep: 8 Cost: 3.0612 Mean overlap: 0.2347\n#     Rep: 9 Cost: 3.0602 Mean overlap: 0.2349\n#     Rep: 10 Cost: 2.7062 Mean overlap: 0.3234\n#     Rep: 11 Cost: 2.7678 Mean overlap: 0.3081\n#     Rep: 12 Cost: 2.2194 Mean overlap: 0.4451\n#     Rep: 13 Cost: 2.0853 Mean overlap: 0.4787\n#     Rep: 14 Cost: 2.2453 Mean overlap: 0.4387\n#     Rep: 15 Cost: 1.6812 Mean overlap: 0.5797\n#     Rep: 16 Cost: 1.9051 Mean overlap: 0.5237\n#     Rep: 17 Cost: 1.4323 Mean overlap: 0.6419\n#     Rep: 18 Cost: 1.4057 Mean overlap: 0.6486\n#     Rep: 19 Cost: 1.2089 Mean overlap: 0.6978\n#     Rep: 20 Cost: 1.1891 Mean overlap: 0.7027\n#     Rep: 21 Cost: 1.2000 Mean overlap: 0.7000\n#     Rep: 22 Cost: 1.1956 Mean overlap: 0.7011\n#     Rep: 23 Cost: 1.1900 Mean overlap: 0.7025\n#     Rep: 24 Cost: 1.1602 Mean overlap: 0.7100\n#     Rep: 25 Cost: 1.0940 Mean overlap: 0.7265\n#     Rep: 26 Cost: 1.0667 Mean overlap: 0.7333\n#     Rep: 27 Cost: 1.0020 Mean overlap: 0.7495\n#     Rep: 28 Cost: 0.9791 Mean overlap: 0.7552\n#     Rep: 29 Cost: 0.9648 Mean overlap: 0.7588\n#     Rep: 30 Cost: 0.9356 Mean overlap: 0.7661\n#     Rep: 31 Cost: 0.9526 Mean overlap: 0.7618\n#     Rep: 32 Cost: 0.8805 Mean overlap: 0.7799\n#     Rep: 33 Cost: 0.9031 Mean overlap: 0.7742\n#     Rep: 34 Cost: 0.8137 Mean overlap: 0.7966\n#     Rep: 35 Cost: 0.8456 Mean overlap: 0.7886\n#     Rep: 36 Cost: 0.8192 Mean overlap: 0.7952\n#     Rep: 37 Cost: 0.8201 Mean overlap: 0.7950\n#     Rep: 38 Cost: 0.8197 Mean overlap: 0.7951\n#     Rep: 39 Cost: 0.7660 Mean overlap: 0.8085\n#     Rep: 40 Cost: 0.7770 Mean overlap: 0.8058\n#     Rep: 41 Cost: 0.7360 Mean overlap: 0.8160\n#     Rep: 42 Cost: 0.7346 Mean overlap: 0.8163\n#     Rep: 43 Cost: 0.7328 Mean overlap: 0.8168\n#     Rep: 44 Cost: 0.7027 Mean overlap: 0.8243\n#     Rep: 45 Cost: 0.7108 Mean overlap: 0.8223\n#     Rep: 46 Cost: 0.6900 Mean overlap: 0.8275\n#     Rep: 47 Cost: 0.6831 Mean overlap: 0.8292\n#     Rep: 48 Cost: 0.6847 Mean overlap: 0.8288\n#     Rep: 49 Cost: 0.6627 Mean overlap: 0.8343\n#     Rep: 50 Cost: 0.6624 Mean overlap: 0.8344\n#     Rep: 51 Cost: 0.6518 Mean overlap: 0.8370\n#     Rep: 52 Cost: 0.6354 Mean overlap: 0.8412\n#     Rep: 53 Cost: 0.6388 Mean overlap: 0.8403\n#     Rep: 54 Cost: 0.6310 Mean overlap: 0.8422\n#     Rep: 55 Cost: 0.6186 Mean overlap: 0.8453\n#     Rep: 56 Cost: 0.6168 Mean overlap: 0.8458\n#     Rep: 57 Cost: 0.6052 Mean overlap: 0.8487\n#     Rep: 58 Cost: 0.5878 Mean overlap: 0.8531\n#     Rep: 59 Cost: 0.5823 Mean overlap: 0.8544\n#     Rep: 60 Cost: 0.5790 Mean overlap: 0.8552\n#     Rep: 61 Cost: 0.5666 Mean overlap: 0.8583\n#     Rep: 62 Cost: 0.5546 Mean overlap: 0.8614\n#     Rep: 63 Cost: 0.5487 Mean overlap: 0.8628\n#     Rep: 64 Cost: 0.5416 Mean overlap: 0.8646\n#     Rep: 65 Cost: 0.5304 Mean overlap: 0.8674\n#     Rep: 66 Cost: 0.5214 Mean overlap: 0.8696\n#     Rep: 67 Cost: 0.5165 Mean overlap: 0.8709\n#     Rep: 68 Cost: 0.5098 Mean overlap: 0.8726\n#     Rep: 69 Cost: 0.4999 Mean overlap: 0.8750\n#     Rep: 70 Cost: 0.4911 Mean overlap: 0.8772\n#     Rep: 71 Cost: 0.4850 Mean overlap: 0.8788\n#     Rep: 72 Cost: 0.4789 Mean overlap: 0.8803\n#     Rep: 73 Cost: 0.4711 Mean overlap: 0.8822\n#     Rep: 74 Cost: 0.4627 Mean overlap: 0.8843\n#     Rep: 75 Cost: 0.4551 Mean overlap: 0.8862\n#     Rep: 76 Cost: 0.4484 Mean overlap: 0.8879\n#     Rep: 77 Cost: 0.4420 Mean overlap: 0.8895\n#     Rep: 78 Cost: 0.4360 Mean overlap: 0.8910\n#     Rep: 79 Cost: 0.4307 Mean overlap: 0.8923\n#     Rep: 80 Cost: 0.4261 Mean overlap: 0.8935\n#     Rep: 81 Cost: 0.4217 Mean overlap: 0.8946\n#     Rep: 82 Cost: 0.4175 Mean overlap: 0.8956\n#     Rep: 83 Cost: 0.4135 Mean overlap: 0.8966\n#     Rep: 84 Cost: 0.4106 Mean overlap: 0.8974\n#     Rep: 85 Cost: 0.4089 Mean overlap: 0.8978\n#     Rep: 86 Cost: 0.4093 Mean overlap: 0.8977\n#     Rep: 87 Cost: 0.4116 Mean overlap: 0.8971\n#     Rep: 88 Cost: 0.4185 Mean overlap: 0.8954\n#     Rep: 89 Cost: 0.4284 Mean overlap: 0.8929\n#     Rep: 90 Cost: 0.4437 Mean overlap: 0.8891\n#     Rep: 91 Cost: 0.4490 Mean overlap: 0.8877\n#     Rep: 92 Cost: 0.4441 Mean overlap: 0.8890\n#     Rep: 93 Cost: 0.4154 Mean overlap: 0.8962\n#     Rep: 94 Cost: 0.3849 Mean overlap: 0.9038\n#     Rep: 95 Cost: 0.3642 Mean overlap: 0.9089\n#     Rep: 96 Cost: 0.3601 Mean overlap: 0.9100\n#     Rep: 97 Cost: 0.3686 Mean overlap: 0.9079\n#     Rep: 98 Cost: 0.3814 Mean overlap: 0.9047\n#     Rep: 99 Cost: 0.3918 Mean overlap: 0.9020\n#     Rep: 100 Cost: 0.3890 Mean overlap: 0.9027\n#     Rep: 101 Cost: 0.3765 Mean overlap: 0.9059\n#     Rep: 102 Cost: 0.3562 Mean overlap: 0.9110\n#     Rep: 103 Cost: 0.3395 Mean overlap: 0.9151\n#     Rep: 104 Cost: 0.3304 Mean overlap: 0.9174\n#     Rep: 105 Cost: 0.3291 Mean overlap: 0.9177\n#     Rep: 106 Cost: 0.3333 Mean overlap: 0.9167\n#     Rep: 107 Cost: 0.3396 Mean overlap: 0.9151\n#     Rep: 108 Cost: 0.3465 Mean overlap: 0.9134\n#     Rep: 109 Cost: 0.3496 Mean overlap: 0.9126\n#     Rep: 110 Cost: 0.3499 Mean overlap: 0.9125\n#     Rep: 111 Cost: 0.3426 Mean overlap: 0.9144\n#     Rep: 112 Cost: 0.3324 Mean overlap: 0.9169\n#     Rep: 113 Cost: 0.3190 Mean overlap: 0.9203\n#     Rep: 114 Cost: 0.3071 Mean overlap: 0.9232\n#     Rep: 115 Cost: 0.2975 Mean overlap: 0.9256\n#     Rep: 116 Cost: 0.2909 Mean overlap: 0.9273\n#     Rep: 117 Cost: 0.2868 Mean overlap: 0.9283\n#     Rep: 118 Cost: 0.2845 Mean overlap: 0.9289\n#     Rep: 119 Cost: 0.2838 Mean overlap: 0.9290\n#     Rep: 120 Cost: 0.2848 Mean overlap: 0.9288\n#     Rep: 121 Cost: 0.2888 Mean overlap: 0.9278\n#     Rep: 122 Cost: 0.2966 Mean overlap: 0.9258\n#     Rep: 123 Cost: 0.3116 Mean overlap: 0.9221\n#     Rep: 124 Cost: 0.3308 Mean overlap: 0.9173\n#     Rep: 125 Cost: 0.3530 Mean overlap: 0.9118\n#     Rep: 126 Cost: 0.3528 Mean overlap: 0.9118\n#     Rep: 127 Cost: 0.3306 Mean overlap: 0.9173\n#     Rep: 128 Cost: 0.2866 Mean overlap: 0.9283\n#     Rep: 129 Cost: 0.2533 Mean overlap: 0.9367\n#     Rep: 130 Cost: 0.2439 Mean overlap: 0.9390\n#     Rep: 131 Cost: 0.2555 Mean overlap: 0.9361\n#     Rep: 132 Cost: 0.2737 Mean overlap: 0.9316\n#     Rep: 133 Cost: 0.2785 Mean overlap: 0.9304\n#     Rep: 134 Cost: 0.2655 Mean overlap: 0.9336\n#     Rep: 135 Cost: 0.2411 Mean overlap: 0.9397\n#     Rep: 136 Cost: 0.2240 Mean overlap: 0.9440\n#     Rep: 137 Cost: 0.2216 Mean overlap: 0.9446\n#     Rep: 138 Cost: 0.2291 Mean overlap: 0.9427\n#     Rep: 139 Cost: 0.2360 Mean overlap: 0.9410\n#     Rep: 140 Cost: 0.2332 Mean overlap: 0.9417\n#     Rep: 141 Cost: 0.2215 Mean overlap: 0.9446\n#     Rep: 142 Cost: 0.2068 Mean overlap: 0.9483\n#     Rep: 143 Cost: 0.1970 Mean overlap: 0.9507\n#     Rep: 144 Cost: 0.1943 Mean overlap: 0.9514\n#     Rep: 145 Cost: 0.1964 Mean overlap: 0.9509\n#     Rep: 146 Cost: 0.1992 Mean overlap: 0.9502\n#     Rep: 147 Cost: 0.1992 Mean overlap: 0.9502\n#     Rep: 148 Cost: 0.1956 Mean overlap: 0.9511\n#     Rep: 149 Cost: 0.1886 Mean overlap: 0.9529\n#     Rep: 150 Cost: 0.1805 Mean overlap: 0.9549\n#     Rep: 151 Cost: 0.1729 Mean overlap: 0.9568\n#     Rep: 152 Cost: 0.1670 Mean overlap: 0.9582\n#     Rep: 153 Cost: 0.1629 Mean overlap: 0.9593\n#     Rep: 154 Cost: 0.1602 Mean overlap: 0.9599\n#     Rep: 155 Cost: 0.1586 Mean overlap: 0.9603\n#     Rep: 156 Cost: 0.1581 Mean overlap: 0.9605\n#     Rep: 157 Cost: 0.1588 Mean overlap: 0.9603\n#     Rep: 158 Cost: 0.1613 Mean overlap: 0.9597\n#     Rep: 159 Cost: 0.1671 Mean overlap: 0.9582\n#     Rep: 160 Cost: 0.1782 Mean overlap: 0.9554\n#     Rep: 161 Cost: 0.1975 Mean overlap: 0.9506\n#     Rep: 162 Cost: 0.2244 Mean overlap: 0.9439\n#     Rep: 163 Cost: 0.2522 Mean overlap: 0.9369\n#     Rep: 164 Cost: 0.2572 Mean overlap: 0.9357\n#     Rep: 165 Cost: 0.2291 Mean overlap: 0.9427\n#     Rep: 166 Cost: 0.1776 Mean overlap: 0.9556\n#     Rep: 167 Cost: 0.1401 Mean overlap: 0.9650\n#     Rep: 168 Cost: 0.1342 Mean overlap: 0.9664\n#     Rep: 169 Cost: 0.1540 Mean overlap: 0.9615\n#     Rep: 170 Cost: 0.1779 Mean overlap: 0.9555\n#     Rep: 171 Cost: 0.1819 Mean overlap: 0.9545\n#     Rep: 172 Cost: 0.1622 Mean overlap: 0.9595\n#     Rep: 173 Cost: 0.1354 Mean overlap: 0.9662\n#     Rep: 174 Cost: 0.1232 Mean overlap: 0.9692\n#     Rep: 175 Cost: 0.1301 Mean overlap: 0.9675\n#     Rep: 176 Cost: 0.1448 Mean overlap: 0.9638\n#     Rep: 177 Cost: 0.1523 Mean overlap: 0.9619\n#     Rep: 178 Cost: 0.1451 Mean overlap: 0.9637\n#     Rep: 179 Cost: 0.1301 Mean overlap: 0.9675\n#     Rep: 180 Cost: 0.1182 Mean overlap: 0.9704\n#     Rep: 181 Cost: 0.1162 Mean overlap: 0.9709\n#     Rep: 182 Cost: 0.1223 Mean overlap: 0.9694\n#     Rep: 183 Cost: 0.1296 Mean overlap: 0.9676\n#     Rep: 184 Cost: 0.1324 Mean overlap: 0.9669\n#     Rep: 185 Cost: 0.1285 Mean overlap: 0.9679\n#     Rep: 186 Cost: 0.1208 Mean overlap: 0.9698\n#     Rep: 187 Cost: 0.1133 Mean overlap: 0.9717\n#     Rep: 188 Cost: 0.1091 Mean overlap: 0.9727\n#     Rep: 189 Cost: 0.1089 Mean overlap: 0.9728\n#     Rep: 190 Cost: 0.1114 Mean overlap: 0.9721\n#     Rep: 191 Cost: 0.1149 Mean overlap: 0.9713\n#     Rep: 192 Cost: 0.1178 Mean overlap: 0.9706\n#     Rep: 193 Cost: 0.1194 Mean overlap: 0.9702\n#     Rep: 194 Cost: 0.1191 Mean overlap: 0.9702\n#     Rep: 195 Cost: 0.1176 Mean overlap: 0.9706\n#     Rep: 196 Cost: 0.1148 Mean overlap: 0.9713\n#     Rep: 197 Cost: 0.1119 Mean overlap: 0.9720\n#     Rep: 198 Cost: 0.1090 Mean overlap: 0.9728\n#     Rep: 199 Cost: 0.1064 Mean overlap: 0.9734\n\n\n######################################################################\n# Results and visualisation\n# -------------------------\n#\n# Plotting the cost vs.\xc2\xa0optimization step:\n#\n\nfrom matplotlib import pyplot as plt\n# %matplotlib inline\nplt.rcParams[\'font.family\'] = \'serif\'\nplt.rcParams[\'font.sans-serif\'] = [\'Computer Modern Roman\']\nplt.style.use(\'default\')\n\nplt.plot(cost_progress)\nplt.ylabel(\'Cost\')\nplt.xlabel(\'Step\')\nplt.show()\n\n\n######################################################################\n# .. image:: /_static/images/sphx_glr_run_gate_synthesis_001.png\n#     :class: sphx-glr-single-img\n\n\n######################################################################\n# We can use matrix plots to plot the real and imaginary components of the\n# target unitary :math:`V` and learnt unitary :math:`U`.\n#\n\nlearnt_unitary = ket_val.numpy().T[:gate_cutoff, :gate_cutoff]\ntarget_unitary = target_unitary[:gate_cutoff, :gate_cutoff]\n\nfig, ax = plt.subplots(1, 4, figsize=(7, 4))\nax[0].matshow(target_unitary.real, cmap=plt.get_cmap(\'Reds\'))\nax[1].matshow(target_unitary.imag, cmap=plt.get_cmap(\'Greens\'))\nax[2].matshow(learnt_unitary.real, cmap=plt.get_cmap(\'Reds\'))\nax[3].matshow(learnt_unitary.imag, cmap=plt.get_cmap(\'Greens\'))\n\nax[0].set_xlabel(r\'$\\mathrm{Re}(V)$\')\nax[1].set_xlabel(r\'$\\mathrm{Im}(V)$\')\nax[2].set_xlabel(r\'$\\mathrm{Re}(U)$\')\nax[3].set_xlabel(r\'$\\mathrm{Im}(U)$\')\nfig.show()\n\n######################################################################\n# .. image:: /_static/images/sphx_glr_run_gate_synthesis_002.png\n#     :class: sphx-glr-single-img\n\n######################################################################\n# Process fidelity\n# ----------------\n#\n# The process fidelity between the two unitaries is defined by\n#\n# .. math:: F_e  = \\left| \\left\\langle \\Psi(V) \\mid \\Psi(U)\\right\\rangle\\right|^2\n#\n# where:\n#\n# -  :math:`\\left|\\Psi(V)\\right\\rangle` is the action of :math:`V` on one\n#    half of a maximally entangled state :math:`\\left|\\phi\\right\\rangle`:\n#\n# .. math:: \\left|\\Psi(V)\\right\\rangle = (I\\otimes V)\\left|\\phi\\right\\rangle,\n#\n# -  :math:`V` is the target unitary,\n# -  :math:`U` the learnt unitary.\n#\n\nI = np.identity(gate_cutoff)\nphi = I.flatten()/np.sqrt(gate_cutoff)\npsiV = np.kron(I, target_unitary) @ phi\npsiU = np.kron(I, learnt_unitary) @ phi\n\n\n\n######################################################################\n# Therefore, after 200 repetitions, the learnt unitary synthesized via a\n# variational quantum circuit has the following process fidelity to the target\n# unitary:\n#\n\nprint(np.abs(np.vdot(psiV, psiU))**2)\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     0.9481729779485119\n\n######################################################################\n# Circuit parameters\n# ------------------\n#\n# We can also query the optimal variational circuit parameters\n# :math:`\\vec{\\theta}` that resulted in the learnt unitary. For example,\n# to determine the maximum squeezing magnitude in the variational quantum\n# circuit:\n#\n\nprint(np.max(np.abs(weights[:, 0])))\n\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     0.39022577\n\n######################################################################\n# Further results\n# ---------------\n#\n# After downloading the tutorial, even more refined results can be obtained by\n# increasing the number of repetitions (``reps``), changing the depth of the\n# circuit or altering the gate cutoff!\n#\n\n######################################################################\n# References\n# ----------\n#\n# 1. Juan Miguel Arrazola, Thomas R. Bromley, Josh Izaac, Casey R. Myers,\n#    Kamil Br\xc3\xa1dler, and Nathan Killoran. Machine learning method for state\n#    preparation and gate synthesis on photonic quantum computers. `Quantum\n#    Science and Technology, 4\n#    024004 <https://iopscience.iop.org/article/10.1088/2058-9565/aaf59e>`__,\n#    (2019).\n#\n# 2. Nathan Killoran, Thomas R. Bromley, Juan Miguel Arrazola, Maria Schuld,\n#    Nicolas Quesada, and Seth Lloyd. Continuous-variable quantum neural networks.\n#    `Physical Review Research, 1(3), 033063.\n#    <https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.1.033063>`__,\n#    (2019).\n'"
examples_apps/machine_learning.py,26,"b'r""""""\r\n.. _machine_learning_tutorial:\r\n\r\nOptimization & machine learning\r\n===============================\r\n\r\n.. note::\r\n\r\n\tThe content in this page is suited to more advanced users who already have an understanding\r\n\tof Strawberry Fields, e.g., those who have completed the :ref:`teleportation tutorial <tutorial>`.\r\n\tSome basic knowledge of `TensorFlow <https://www.tensorflow.org/>`_ is also helpful.\r\n\r\n.. note::\r\n\r\n    This tutorial requires TensorFlow 2.0 and above. TensorFlow can be installed via ``pip``:\r\n\r\n    .. code-block:: console\r\n\r\n        pip install tensorflow\r\n\r\n    For more installation details and instructions, please refer to the\r\n    `TensorFlow documentation <https://www.tensorflow.org/install>`_.\r\n\r\nIn this demonstration, we show how the user can carry out optimization and machine learning on quantum\r\ncircuits in Strawberry Fields. This functionality is provided via the TensorFlow simulator\r\nbackend. By leveraging TensorFlow, we have access to a number of additional functionalities,\r\nincluding GPU integration, automatic gradient computation, built-in optimization algorithms,\r\nand other machine learning tools.\r\n\r\nBasic functionality\r\n-------------------\r\n\r\nAs usual, we can initialize a Strawberry Fields program:\r\n""""""\r\nimport numpy as np\r\nimport strawberryfields as sf\r\nfrom strawberryfields.ops import *\r\n\r\nprog = sf.Program(2)\r\n\r\n\r\n##############################################################################\r\n# Replacing numbers with Tensors\r\n# ------------------------------\r\n#\r\n# When a circuit contains only numerical parameters, the TensorFlow backend works the same\r\n# as the other backends. However, with the TensorFlow backend, we have the additional option\r\n# to use TensorFlow ``tf.Variable`` and ``tf.tensor`` objects for the parameters of Blackbird\r\n# states, gates, and measurements.\r\n#\r\n# To construct the circuit to allow for TensorFlow objects, we **must** use **symbolic\r\n# parameters** as the gate arguments. These can be created via the ``Program.params()``\r\n# method:\r\n\r\nimport tensorflow as tf\r\n\r\n# we can create symbolic parameters one by one\r\nalpha = prog.params(""alpha"")\r\n\r\n# or create multiple at the same time\r\ntheta_bs, phi_bs = prog.params(""theta_bs"", ""phi_bs"")\r\n\r\nwith prog.context as q:\r\n    # States\r\n    Coherent(alpha) | q[0]\r\n    # Gates\r\n    BSgate(theta_bs, phi_bs) | (q[0], q[1])\r\n    # Measurements\r\n    MeasureHomodyne(0.0) | q[0]\r\n\r\n\r\n##############################################################################\r\n# To run a Strawberry Fields simulation with the TensorFlow backend, we need to specify\r\n# ``\'tf\'`` as the backend argument when initializing the engine:\r\n\r\neng = sf.Engine(backend=""tf"", backend_options={""cutoff_dim"": 7})\r\n\r\n##############################################################################\r\n# We can now run our program using :meth:`eng.run() <.Engine.run>`. However, directly\r\n# evaluating a circuit which contains symbolic parameters using :meth:`eng.run() <.Engine.run>`\r\n# will produce errors. The reason for this is that :meth:`eng.run() <.Engine.run>` tries,\r\n# by default, to numerically evaluate any measurement result. But we have not provided\r\n# numerical values for the symbolic arguments yet!\r\n#\r\n# .. code-block:: python3\r\n#\r\n#     eng.run(prog)\r\n#\r\n# .. rst-class:: sphx-glr-script-out\r\n#\r\n#     Out:\r\n#\r\n#     .. code-block:: none\r\n#\r\n#         ParameterError: {alpha}: unbound parameter with no default value.\r\n#\r\n# To bind a numerical value to the free parameters, we pass a mapping from parameter\r\n# name to value using the ``args`` keyword argument when running the engine:\r\n\r\nmapping = {""alpha"": tf.Variable(0.5), ""theta_bs"": tf.constant(0.4), ""phi_bs"": tf.constant(0.0)}\r\n\r\nresult = eng.run(prog, args=mapping)\r\n\r\n\r\n##############################################################################\r\n# This code will execute without error, and both the output results and the\r\n# output samples will contain numeric values based on the given value for the angle ``phi``:\r\n\r\nprint(result.samples)\r\n\r\n##############################################################################\r\n# .. rst-class:: sphx-glr-script-out\r\n#\r\n#  Out:\r\n#\r\n#  .. code-block:: none\r\n#\r\n#     [[<tf.Tensor: id=794, shape=(), dtype=complex64, numpy=(2.6271262+0j)>\r\n#       None]]\r\n\r\n##############################################################################\r\n# We can select measurement results at other angles by supplying different values for\r\n# ``phi`` in ``mapping``. We can also return and perform processing on the underlying state:\r\n\r\nstate = result.state\r\nprint(""Density matrix element [0,0,1,2]:"", state.dm()[0, 0, 1, 2])\r\n\r\n##############################################################################\r\n# .. rst-class:: sphx-glr-script-out\r\n#\r\n#  Out:\r\n#\r\n#  .. code-block:: none\r\n#\r\n#     Density matrix element [0,0,1,2]: tf.Tensor((0.0050359764+0j), shape=(), dtype=complex64)\r\n\r\n##############################################################################\r\n# Computing gradients\r\n# -------------------\r\n#\r\n# When used within a gradient tape context, any output generated from the state\r\n# class can be differentiated natively using ``GradientTape().gradient()``.\r\n# For example, lets displace a one-mode program, and then compute the gradient\r\n# of the mean photon number:\r\n\r\neng.reset()\r\nprog = sf.Program(1)\r\n\r\nalpha = prog.params(""alpha"")\r\n\r\nwith prog.context as q:\r\n    Dgate(alpha) | q\r\n\r\n# Assign our TensorFlow variables, so that we can\r\n# refer to them later when differentiating/training.\r\na = tf.Variable(0.43)\r\n\r\nwith tf.GradientTape() as tape:\r\n    # Here, we map our quantum free parameter `alpha`\r\n    # to our TensorFlow variable `a` and pass it to the engine.\r\n\r\n    result = eng.run(prog, args={""alpha"": a})\r\n    state = result.state\r\n\r\n    # Note that all processing, including state-based post-processing,\r\n    # must be done within the gradient tape context!\r\n    mean, var = state.mean_photon(0)\r\n\r\n# test that the gradient of the mean photon number is correct\r\n\r\ngrad = tape.gradient(mean, [a])\r\nprint(""Gradient:"", grad)\r\n\r\n##############################################################################\r\n# .. rst-class:: sphx-glr-script-out\r\n#\r\n#  Out:\r\n#\r\n#  .. code-block:: none\r\n#\r\n#     Gradient: [<tf.Tensor: id=1343, shape=(), dtype=float32, numpy=0.85999966>]\r\n\r\n##############################################################################\r\n# The mean photon number of a displaced state :math:`|\\alpha\\rangle` is given by\r\n# :math:`\\langle \\hat{n} \\rangle(\\alpha) = |\\alpha|^2`, and thus, for real-valued\r\n# :math:`\\alpha`, the gradient is given by :math:`\\langle \\hat{n}\\rangle\'(\\alpha) = 2\\alpha`:\r\n\r\nprint(""Exact gradient:"", 2 * a)\r\nprint(""Exact and TensorFlow gradient agree:"", np.allclose(grad, 2 * a))\r\n\r\n##############################################################################\r\n# .. rst-class:: sphx-glr-script-out\r\n#\r\n#  Out:\r\n#\r\n#  .. code-block:: none\r\n#\r\n#     Exact gradient: tf.Tensor(0.86, shape=(), dtype=float32)\r\n#     Exact and TensorFlow gradient agree: True\r\n\r\n##############################################################################\r\n# Processing data\r\n# ---------------\r\n#\r\n# The parameters for Blackbird states, gates, and measurements may be more complex\r\n# than just raw data or machine learning weights. These can themselves be the outputs\r\n# from some learnable function like a neural network [#]_.\r\n#\r\n# We can also use the ``sf.math`` module to allow arbitrary processing of measurement\r\n# results within the TensorFlow backend, by manipulating the ``.par`` attribute of\r\n# the measured register. Note that the math functions in ``sf.math`` will be automatically\r\n# converted to the equivalent TensorFlow ``tf.math`` function:\r\n\r\neng.reset()\r\nprog = sf.Program(2)\r\n\r\nwith prog.context as q:\r\n    MeasureX | q[0]\r\n    Dgate(sf.math.sin(q[0].par)) | q[1]\r\n\r\nresult = eng.run(prog)\r\nprint(""Measured Homodyne sample from mode 0:"", result.samples[0][0])\r\n\r\nmean, var = result.state.mean_photon(0)\r\nprint(""Mean photon number of mode 0:"", mean)\r\n\r\nmean, var = result.state.mean_photon(1)\r\nprint(""Mean photon number of mode 1:"", mean)\r\n\r\n##############################################################################\r\n# .. rst-class:: sphx-glr-script-out\r\n#\r\n#  Out:\r\n#\r\n#  .. code-block:: none\r\n#\r\n#     Measured Homodyne sample from mode 0: tf.Tensor((1.099311+0j), shape=(), dtype=complex64)\r\n#     Mean photon number of mode 0: tf.Tensor(0.0, shape=(), dtype=float32)\r\n#     Mean photon number of mode 1: tf.Tensor(0.793553, shape=(), dtype=float32)\r\n\r\n##############################################################################\r\n# The mean photon number of mode 1 should be given by :math:`\\sin(q[0])^2`, where :math:`q[0]`\r\n# is the measured Homodyne sample value:\r\n\r\nq0 = result.samples[0][0]\r\nprint(np.sin(q0) ** 2)\r\n\r\n##############################################################################\r\n# .. rst-class:: sphx-glr-script-out\r\n#\r\n#  Out:\r\n#\r\n#  .. code-block:: none\r\n#\r\n#     (0.7936931737133115+0j)\r\n\r\n##############################################################################\r\n# Working with batches\r\n# --------------------\r\n#\r\n# It is common in machine learning to process data in *batches*. Strawberry Fields supports both\r\n# unbatched and batched data when using the TensorFlow backend. Unbatched operation is the default\r\n# behaviour (shown above). To enable batched operation, you should provide an extra\r\n# ``batch_size`` argument within the ``backend_options`` dictionary [#]_, e.g.,\r\n\r\n\r\n# run simulation in batched-processing mode\r\nbatch_size = 3\r\nprog = sf.Program(1)\r\neng = sf.Engine(""tf"", backend_options={""cutoff_dim"": 15, ""batch_size"": batch_size})\r\n\r\nx = prog.params(""x"")\r\n\r\nwith prog.context as q:\r\n    Thermal(x) | q[0]\r\n\r\nx_val = tf.Variable([0.1, 0.2, 0.3])\r\nresult = eng.run(prog, args={""x"": x_val})\r\nprint(""Mean photon number of mode 0 (batched):"", result.state.mean_photon(0)[0])\r\n\r\n##############################################################################\r\n# .. rst-class:: sphx-glr-script-out\r\n#\r\n#  Out:\r\n#\r\n#  .. code-block:: none\r\n#\r\n#     Mean photon number of mode 0 (batched): tf.Tensor([0.09999999 0.19999996 0.30000004], shape=(3,), dtype=float32)\r\n\r\n\r\n##############################################################################\r\n# .. note:: The batch size should be static, i.e., not changing over the course of a computation.\r\n#\r\n# Parameters supplied to a circuit in batch-mode operation can either be scalars or vectors\r\n# (of length ``batch_size``). Scalars are automatically broadcast over the batch dimension.\r\n\r\nalpha = tf.Variable([0.5] * batch_size)\r\ntheta = tf.constant(0.0)\r\nphi = tf.Variable([0.1, 0.33, 0.5])\r\n\r\n##############################################################################\r\n# Measurement results will be returned as Tensors with shape ``(batch_size,)``.\r\n# We can picture batch-mode operation as simulating multiple circuit configurations at the\r\n# same time. Combined with appropriate parallelized hardware like GPUs, this can result in\r\n# significant speedups compared to serial evaluation.\r\n\r\n\r\n##############################################################################\r\n# Example: variational quantum circuit optimization\r\n# -------------------------------------------------\r\n#\r\n# A key element of machine learning is optimization. We can use TensorFlow\'s automatic differentiation\r\n# tools to optimize the parameters of *variational quantum circuits*. In this approach, we fix a\r\n# circuit architecture where the states, gates, and/or measurements may have learnable parameters\r\n# associated with them. We then define a loss function based on the output state of this circuit.\r\n#\r\n# .. warning::\r\n#\r\n#     The state representation in the simulator can change from a ket (pure) to a density\r\n#     matrix (mixed) if we use certain operations (e.g., state preparations). We can check ``state.is_pure``\r\n#     to determine which representation is being used.\r\n#\r\n# In the example below, we optimize a :class:`~.Dgate` to produce an output with the largest overlap\r\n# with the Fock state :math:`n=1`. In this example, we compute the loss function imperatively\r\n# within a gradient tape, and then apply the gradients using the chosen optimizer:\r\n\r\n# initialize engine and program objects\r\neng = sf.Engine(backend=""tf"", backend_options={""cutoff_dim"": 7})\r\ncircuit = sf.Program(1)\r\n\r\ntf_alpha = tf.Variable(0.1)\r\ntf_phi = tf.Variable(0.1)\r\n\r\nalpha, phi = circuit.params(""alpha"", ""phi"")\r\n\r\nwith circuit.context as q:\r\n    Dgate(alpha, phi) | q[0]\r\n\r\nopt = tf.keras.optimizers.Adam(learning_rate=0.1)\r\nsteps = 50\r\n\r\nfor step in range(steps):\r\n\r\n    # reset the engine if it has already been executed\r\n    if eng.run_progs:\r\n        eng.reset()\r\n\r\n    with tf.GradientTape() as tape:\r\n        # execute the engine\r\n        results = eng.run(circuit, args={""alpha"": tf_alpha, ""phi"": tf_phi})\r\n        # get the probability of fock state |1>\r\n        prob = results.state.fock_prob([1])\r\n        # negative sign to maximize prob\r\n        loss = -prob\r\n\r\n    gradients = tape.gradient(loss, [tf_alpha, tf_phi])\r\n    opt.apply_gradients(zip(gradients, [tf_alpha, tf_phi]))\r\n    print(""Probability at step {}: {}"".format(step, prob))\r\n\r\n##############################################################################\r\n# .. rst-class:: sphx-glr-script-out\r\n#\r\n#  Out:\r\n#\r\n#  .. code-block:: none\r\n#\r\n#     Probability at step 0: 0.009900497272610664\r\n#     Probability at step 1: 0.03843098133802414\r\n#     Probability at step 2: 0.08083382993936539\r\n#     Probability at step 3: 0.1331305205821991\r\n#     Probability at step 4: 0.19035020470619202\r\n#     Probability at step 5: 0.24677760899066925\r\n#     Probability at step 6: 0.29659587144851685\r\n#     Probability at step 7: 0.3348417580127716\r\n#     Probability at step 8: 0.35853680968284607\r\n#     Probability at step 9: 0.3676064908504486\r\n#     Probability at step 10: 0.3649454414844513\r\n#     Probability at step 11: 0.355256587266922\r\n#     Probability at step 12: 0.3432542383670807\r\n#     Probability at step 13: 0.3323868215084076\r\n#     Probability at step 14: 0.32456544041633606\r\n#     Probability at step 15: 0.32050856947898865\r\n#     Probability at step 16: 0.3201928436756134\r\n#     Probability at step 17: 0.3231735825538635\r\n#     Probability at step 18: 0.3287637233734131\r\n#     Probability at step 19: 0.3361213207244873\r\n#     Probability at step 20: 0.3443049192428589\r\n#     Probability at step 21: 0.3523356020450592\r\n#     Probability at step 22: 0.3592878580093384\r\n#     Probability at step 23: 0.364411860704422\r\n#     Probability at step 24: 0.36726585030555725\r\n#     Probability at step 25: 0.3678152561187744\r\n#     Probability at step 26: 0.36645036935806274\r\n#     Probability at step 27: 0.36389175057411194\r\n#     Probability at step 28: 0.36100488901138306\r\n#     Probability at step 29: 0.35858556628227234\r\n#     Probability at step 30: 0.35718992352485657\r\n#     Probability at step 31: 0.35705265402793884\r\n#     Probability at step 32: 0.35809454321861267\r\n#     Probability at step 33: 0.3599957227706909\r\n#     Probability at step 34: 0.36230403184890747\r\n#     Probability at step 35: 0.3645508885383606\r\n#     Probability at step 36: 0.3663528263568878\r\n#     Probability at step 37: 0.36747899651527405\r\n#     Probability at step 38: 0.36787670850753784\r\n#     Probability at step 39: 0.36765244603157043\r\n#     Probability at step 40: 0.3670196831226349\r\n#     Probability at step 41: 0.366233766078949\r\n#     Probability at step 42: 0.3655299246311188\r\n#     Probability at step 43: 0.3650795519351959\r\n#     Probability at step 44: 0.3649670481681824\r\n#     Probability at step 45: 0.365190327167511\r\n#     Probability at step 46: 0.3656746745109558\r\n#     Probability at step 47: 0.36629951000213623\r\n#     Probability at step 48: 0.36692991852760315\r\n#     Probability at step 49: 0.3674468994140625\r\n\r\n##############################################################################\r\n# After 50 or so iterations, the optimization should converge to the optimal probability value of\r\n# :math:`e^{-1}\\approx 0.3678` at a parameter of :math:`\\alpha=1` [#]_.\r\n#\r\n# In cases where we want to take advantage of TensorFlow\'s graph mode,\r\n# or do not need to extract/accumulate intermediate values used to calculate\r\n# the cost function, we could also make use of TensorFlow\'s ``Optimizer().minimize``\r\n# method, which requires the loss be defined as a function with no arguments:\r\n\r\n\r\ndef loss():\r\n    # reset the engine if it has already been executed\r\n    if eng.run_progs:\r\n        eng.reset()\r\n\r\n    # execute the engine\r\n    results = eng.run(circuit, args={""alpha"": tf_alpha, ""phi"": tf_phi})\r\n    # get the probability of fock state |1>\r\n    prob = results.state.fock_prob([1])\r\n    # negative sign to maximize prob\r\n    return -prob\r\n\r\n\r\ntf_alpha = tf.Variable(0.1)\r\ntf_phi = tf.Variable(0.1)\r\n\r\n\r\nfor step in range(steps):\r\n    # In eager mode, calling Optimizer.minimize performs a single optimization step,\r\n    # and automatically updates the parameter values.\r\n    _ = opt.minimize(loss, [tf_alpha, tf_phi])\r\n    parameter_vals = [tf_alpha.numpy(), tf_phi.numpy()]\r\n    print(""Parameter values at step {}: {}"".format(step, parameter_vals))\r\n\r\n##############################################################################\r\n# .. rst-class:: sphx-glr-script-out\r\n#\r\n#  Out:\r\n#\r\n#  .. code-block:: none\r\n#\r\n#     Parameter values at step 0: [0.17085811, 0.10000666]\r\n#     Parameter values at step 1: [0.2653996, 0.10000824]\r\n#     Parameter values at step 2: [0.3756343, 0.10003564]\r\n#     Parameter values at step 3: [0.498407, 0.10004087]\r\n#     Parameter values at step 4: [0.6317963, 0.10005679]\r\n#     Parameter values at step 5: [0.7733106, 0.10010292]\r\n#     Parameter values at step 6: [0.91795504, 0.100087106]\r\n#     Parameter values at step 7: [1.056465, 0.09979849]\r\n#     Parameter values at step 8: [1.1767575, 0.0995149]\r\n#     Parameter values at step 9: [1.2695967, 0.099197276]\r\n#     Parameter values at step 10: [1.3319764, 0.09904715]\r\n#     Parameter values at step 11: [1.3654184, 0.098881036]\r\n#     Parameter values at step 12: [1.3732629, 0.098441504]\r\n#     Parameter values at step 13: [1.3591939, 0.09790572]\r\n#     Parameter values at step 14: [1.3267639, 0.09771576]\r\n#     Parameter values at step 15: [1.2793746, 0.09764076]\r\n#     Parameter values at step 16: [1.2204303, 0.097491466]\r\n#     Parameter values at step 17: [1.1535465, 0.09737021]\r\n#     Parameter values at step 18: [1.0827549, 0.09747333]\r\n#     Parameter values at step 19: [1.0126097, 0.097629994]\r\n#     Parameter values at step 20: [0.9480358, 0.09750217]\r\n#     Parameter values at step 21: [0.89378, 0.09736596]\r\n#     Parameter values at step 22: [0.85358965, 0.09750438]\r\n#     Parameter values at step 23: [0.8295505, 0.09758021]\r\n#     Parameter values at step 24: [0.82193875, 0.097489305]\r\n#     Parameter values at step 25: [0.82952106, 0.09749036]\r\n#     Parameter values at step 26: [0.85000145, 0.09736506]\r\n#     Parameter values at step 27: [0.8804064, 0.09721753]\r\n#     Parameter values at step 28: [0.9173693, 0.09727109]\r\n#     Parameter values at step 29: [0.957366, 0.09753705]\r\n#     Parameter values at step 30: [0.99695796, 0.0978495]\r\n#     Parameter values at step 31: [1.0330576, 0.09814763]\r\n#     Parameter values at step 32: [1.0631745, 0.09897915]\r\n#     Parameter values at step 33: [1.0855812, 0.09966516]\r\n#     Parameter values at step 34: [1.0993629, 0.10014479]\r\n#     Parameter values at step 35: [1.1043644, 0.10067672]\r\n#     Parameter values at step 36: [1.1010801, 0.10097134]\r\n#     Parameter values at step 37: [1.090526, 0.10137434]\r\n#     Parameter values at step 38: [1.0741205, 0.102029756]\r\n#     Parameter values at step 39: [1.0535735, 0.10259121]\r\n#     Parameter values at step 40: [1.0307757, 0.102993794]\r\n#     Parameter values at step 41: [1.0076759, 0.103460334]\r\n#     Parameter values at step 42: [0.9861408, 0.10372111]\r\n#     Parameter values at step 43: [0.967804, 0.10424348]\r\n#     Parameter values at step 44: [0.9539274, 0.10505462]\r\n#     Parameter values at step 45: [0.9452985, 0.105316624]\r\n#     Parameter values at step 46: [0.9421848, 0.10547027]\r\n#     Parameter values at step 47: [0.94434804, 0.105495274]\r\n#     Parameter values at step 48: [0.9511101, 0.10539721]\r\n#     Parameter values at step 49: [0.9614545, 0.1051061]\r\n\r\n\r\n###############################################################################\r\n# Other high-level optimization interfaces, such as Keras, may also\r\n# be used to train models built using the Strawberry Fields TensorFlow backend.\r\n#\r\n# .. warning::\r\n#\r\n#     When optimizing circuits which contains energy-changing operations (displacement, squeezing, etc.),\r\n#     one should be careful to monitor that the state does not leak out of the given truncation level. This can\r\n#     be accomplished by regularizing or using ``tf.clip_by_value`` on the relevant parameters.\r\n#\r\n# TensorFlow supports a large set of mathematical and machine learning operations which can be applied to\r\n# a circuit\'s output state to enable further processing. Examples include ``tf.norm``,\r\n# ``tf.linalg.eigh``, ``tf.linalg.svd``, and ``tf.linalg.inv`` [#]_.\r\n#\r\n# Exercise: Hong-Ou-Mandel Effect\r\n# -------------------------------\r\n#\r\n# Use the optimization methods outlined above to find the famous\r\n# `Hong-Ou-Mandel effect <https://en.wikipedia.org/wiki/Hong%E2%80%93Ou%E2%80%93Mandel_effect>`_,\r\n# where photons bunch together in the same mode. Your circuit should contain two modes, each with a\r\n# single-photon input state, and a beamsplitter with variable parameters. By optimizing the beamsplitter\r\n# parameters, minimize the probability of the :math:`|1,1\\rangle` Fock-basis element of the output state.\r\n#\r\n# .. rubric:: Footnotes\r\n#\r\n# .. [#] Note that certain operations---in particular, measurements---may not have gradients defined within\r\n#        TensorFlow. When optimizing via gradient descent, we must be careful to define a circuit which is end-to-end differentiable.\r\n#\r\n#\r\n# .. [#] Note that ``batch_size`` should not be set to 1. Instead, use ``batch_size=None``, or just\r\n#        omit the ``batch_size`` argument.\r\n#\r\n# .. [#] In this tutorial, we have applied classical machine learning tools to learn a quantum optical circuit.\r\n#        Of course, there are many other possibilities for combining machine learning and quantum computing,\r\n#        e.g., using quantum algorithms to speed up machine learning subroutines, or fully quantum learning on\r\n#        unprocessed quantum data.\r\n#\r\n# .. [#] Remember that it might be necessary to reshape a ket or density matrix before using some of these functions.\r\n'"
examples_apps/minimizing_correlations.py,12,"b'""""""\nMinimizing the amount of correlations\n=====================================\n\n*Author: Nicolas Quesada*\n\n""""""\n\n\n######################################################################\n# In `this paper <https://doi.org/10.1103/PhysRevA.88.044301>`__ by Jiang,\n# Lang, and Caves [1], the authors show that if one has two qumodes states\n# :math:`\\left|\\psi \\right\\rangle` and :math:`\\left|\\phi \\right\\rangle`\n# and a beamsplitter :math:`\\text{BS}(\\theta)`, then the only way no\n# entanglement is generated when the beamsplitter acts on the product of\n# the two states\n#\n# .. math:: \\left|\\Psi  \\right\\rangle = \\text{BS}(\\theta) \\ \\left|\\psi \\right\\rangle \\otimes \\left|\\phi \\right\\rangle,\n#\n# is if the states :math:`\\left|\\psi \\right\\rangle` and\n# :math:`\\left|\\phi \\right\\rangle` are squeezed states along the same\n# quadrature and by the same amount.\n#\n# Now imagine the following task: > Given an input state\n# :math:`\\left|\\psi \\right\\rangle`, which is not necessarily a squeezed\n# state, what is the optimal state :math:`\\left|\\phi \\right\\rangle`\n# incident on a beamsplitter :math:`\\text{BS}(\\theta)` together with\n# :math:`\\left|\\psi \\right\\rangle` such that the resulting entanglement is\n# minimized?\n#\n# In our `paper <https://journals.aps.org/pra/abstract/10.1103/PhysRevA.98.043813>`__ we showed that if\n# :math:`\\theta \\ll 1` the optimal state :math:`\\left|\\phi \\right\\rangle`,\n# for any input state :math:`\\left|\\psi \\right\\rangle`, is always a\n# squeezed state. We furthermore conjectured that this holds for any value\n# of :math:`\\theta`.\n#\n# Here, we numerically explore this question by performing numerical\n# minimization over :math:`\\left|\\phi \\right\\rangle` to find the state\n# that minimizes the entanglement between the two modes.\n#\n# First, we import the libraries required for this analysis; NumPy, SciPy,\n# TensorFlow, and StrawberryFields.\n#\n\nimport numpy as np\nfrom scipy.linalg import expm\nimport tensorflow as tf\n\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\nfrom strawberryfields.backends.tfbackend.ops import partial_trace\n\n\n# set the random seed\ntf.random.set_seed(137)\nnp.random.seed(42)\n\n\n######################################################################\n# Now, we set the Fock basis truncation; in this case, we choose\n# :math:`cutoff=30`:\n#\n\ncutoff = 30\n\n\n######################################################################\n# Creating the initial states\n# ---------------------------\n#\n# We define our input state\n# :math:`\\newcommand{ket}[1]{\\left|#1\\right\\rangle}\\ket{\\psi}`, an equal\n# superposition of :math:`\\ket{0}` and :math:`\\ket{1}`:\n#\n# .. math:: \\ket{\\psi}=\\frac{1}{\\sqrt{2}}\\left(\\ket{0}+\\ket{1}\\right)\n#\n\npsi = np.zeros([cutoff], dtype=np.complex128)\npsi[0] = 1.0\npsi[1] = 1.0\npsi /= np.linalg.norm(psi)\n\n\n######################################################################\n# We can now define our initial random guess for the second state\n# :math:`\\ket{\\phi}`:\n#\n\nphi = np.random.random(size=[cutoff]) + 1j*np.random.random(size=[cutoff])\nphi[10:] = 0.\nphi /= np.linalg.norm(phi)\n\n\n######################################################################\n# Next, we define the creation operator :math:`\\hat{a}`,\n#\n\na = np.diag(np.sqrt(np.arange(1, cutoff)), k=1)\n\n\n######################################################################\n# the number operator :math:`\\hat{n}=\\hat{a}^\\dagger \\hat{a}`,\n#\n\nn_opt = a.T @ a\n\n\n######################################################################\n# and the quadrature operators :math:`\\hat{x}=a+a^\\dagger`,\n# :math:`\\hat{p}=-i(a-a^\\dagger)`.\n#\n\n# Define quadrature operators\nx = a + a.T\np = -1j*(a-a.T)\n\n\n######################################################################\n# We can now calculate the displacement of the states in the phase space,\n# :math:`\\alpha=\\langle \\psi \\mid\\hat{a}\\mid\\psi\\rangle`. The following\n# function calculates this displacement, and then displaces the state by\n# :math:`-\\alpha` to ensure it has zero displacement.\n#\n\ndef recenter(state):\n    alpha = state.conj() @ a @ state\n    disp_alpha = expm(alpha.conj()*a - alpha*a.T)\n    out_state = disp_alpha @ state\n    return out_state\n\n\n######################################################################\n# First, let\xe2\x80\x99s have a look at the displacement of state :math:`\\ket{\\psi}`\n# and state :math:`\\ket{\\phi}`:\n#\n\nprint(psi.conj().T @ a @ psi)\nprint(phi.conj().T @ a @ phi)\n\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     (0.4999999999999999+0j)\n#     (1.4916658938055996+0.20766920902420394j)\n\n######################################################################\n# Now, let\xe2\x80\x99s center them in the phase space:\n#\n\npsi = recenter(psi)\nphi = recenter(phi)\n\n\n######################################################################\n# Checking they now have zero displacement:\n#\n\nprint(np.round(psi.conj().T @ a @ psi, 8))\nprint(np.round(phi.conj().T @ a @ phi, 8))\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     0j\n#     0j\n\n######################################################################\n# Performing the optimization\n# ---------------------------\n#\n# We can construct the variational quantum circuit cost function, using Strawberry\n# Fields:\n#\n\npenalty_strength = 10\n\nprog = sf.Program(2)\neng = sf.Engine(""tf"", backend_options={""cutoff_dim"": cutoff})\n\npsi = tf.cast(psi, tf.complex64)\nphi_var_re = tf.Variable(phi.real)\nphi_var_im = tf.Variable(phi.imag)\n\n\nwith prog.context as q:\n    Ket(prog.params(""input_state"")) | q\n    BSgate(np.pi/4, 0) | q\n\n\n\n######################################################################\n# Here, we are initializing a TensorFlow variable ``phi_var`` representing\n# the initial state of mode ``q[1]``, which we will optimize over. Note\n# that we take the outer product\n# :math:`\\ket{in}=\\ket{\\psi}\\otimes\\ket{\\phi}`, and use the ``Ket``\n# operator to initialise the circuit in this initial multimode pure state.\n\n\ndef cost(phi_var_re, phi_var_im):\n    phi_var = tf.cast(phi_var_re, tf.complex64) + 1j*tf.cast(phi_var_im, tf.complex64)\n\n    in_state = tf.einsum(\'i,j->ij\', psi, phi_var)\n\n    result = eng.run(prog, args={""input_state"": in_state}, modes=[1])\n    state = result.state\n\n    rhoB = state.dm()\n    cost = tf.cast(tf.math.real((tf.linalg.trace(rhoB @ rhoB)\n                                -penalty_strength*tf.linalg.trace(rhoB @ x)**2\n                                -penalty_strength*tf.linalg.trace(rhoB @ p)**2)\n                           /(tf.linalg.trace(rhoB))**2), tf.float64)\n\n    return cost\n\n\n######################################################################\n# The cost function runs the engine, and we use the argument ``modes=[1]`` to\n# return the density matrix of mode ``q[1]``.\n#\n# The returned cost contains the purity of the reduced density matrix\n#\n# .. math:: \\text{Tr}(\\rho_B^2),\n#\n# and an extra penalty that forces the optimized state to have zero\n# displacement; that is, we want to minimise the value\n#\n# .. math:: \\langle \\hat{x}\\rangle=\\text{Tr}(\\rho_B\\hat{x}).\n#\n# Finally, we divide by the :math:`\\text{Tr}(\\rho_B)^2` so that the state\n# is always normalized.\n#\n# We can now set up the optimization, to minimise the cost function.\n# Running the optimization process for 200 reps:\n#\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.007)\n\nreps = 200\n\ncost_progress = []\n\nfor i in range(reps):\n    # reset the engine if it has already been executed\n    if eng.run_progs:\n        eng.reset()\n\n    with tf.GradientTape() as tape:\n        loss = -cost(phi_var_re, phi_var_im)\n\n    # Stores cost at each step\n    cost_progress.append(loss.numpy())\n\n    # one repetition of the optimization\n    gradients = tape.gradient(loss, [phi_var_re, phi_var_im])\n    opt.apply_gradients(zip(gradients, [phi_var_re, phi_var_im]))\n\n    # Prints progress\n    if i % 1 == 0:\n        print(""Rep: {} Cost: {}"".format(i, loss))\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     Rep: 0 Cost: -0.4766758978366852\n#     Rep: 1 Cost: -0.4223320484161377\n#     Rep: 2 Cost: -0.4963147044181824\n#     Rep: 3 Cost: -0.45958423614501953\n#     Rep: 4 Cost: -0.4818280339241028\n#     Rep: 5 Cost: -0.5147174596786499\n#     Rep: 6 Cost: -0.5162041783332825\n#     Rep: 7 Cost: -0.5110473036766052\n#     Rep: 8 Cost: -0.5209271907806396\n#     Rep: 9 Cost: -0.5389845371246338\n#     Rep: 10 Cost: -0.5502253770828247\n#     Rep: 11 Cost: -0.5520217418670654\n#     Rep: 12 Cost: -0.5553423762321472\n#     Rep: 13 Cost: -0.5651862621307373\n#     Rep: 14 Cost: -0.5767862796783447\n#     Rep: 15 Cost: -0.5858915448188782\n#     Rep: 16 Cost: -0.592574417591095\n#     Rep: 17 Cost: -0.5986008644104004\n#     Rep: 18 Cost: -0.6053515076637268\n#     Rep: 19 Cost: -0.6134768724441528\n#     Rep: 20 Cost: -0.6225422620773315\n#     Rep: 21 Cost: -0.631293535232544\n#     Rep: 22 Cost: -0.6387172937393188\n#     Rep: 23 Cost: -0.6450194716453552\n#     Rep: 24 Cost: -0.6514304876327515\n#     Rep: 25 Cost: -0.6588233113288879\n#     Rep: 26 Cost: -0.666886568069458\n#     Rep: 27 Cost: -0.6747294068336487\n#     Rep: 28 Cost: -0.6818798184394836\n#     Rep: 29 Cost: -0.688532292842865\n#     Rep: 30 Cost: -0.6950534582138062\n#     Rep: 31 Cost: -0.7016120553016663\n#     Rep: 32 Cost: -0.7082613110542297\n#     Rep: 33 Cost: -0.715013861656189\n#     Rep: 34 Cost: -0.7217401266098022\n#     Rep: 35 Cost: -0.7281915545463562\n#     Rep: 36 Cost: -0.7342450618743896\n#     Rep: 37 Cost: -0.7400316596031189\n#     Rep: 38 Cost: -0.7457355856895447\n#     Rep: 39 Cost: -0.7513759136199951\n#     Rep: 40 Cost: -0.7568838596343994\n#     Rep: 41 Cost: -0.7622535824775696\n#     Rep: 42 Cost: -0.7675091028213501\n#     Rep: 43 Cost: -0.7726098895072937\n#     Rep: 44 Cost: -0.7774857878684998\n#     Rep: 45 Cost: -0.7821434140205383\n#     Rep: 46 Cost: -0.7866566181182861\n#     Rep: 47 Cost: -0.7910702228546143\n#     Rep: 48 Cost: -0.7953729629516602\n#     Rep: 49 Cost: -0.7995505332946777\n#     Rep: 50 Cost: -0.8036108613014221\n#     Rep: 51 Cost: -0.8075516223907471\n#     Rep: 52 Cost: -0.8113498091697693\n#     Rep: 53 Cost: -0.8149938583374023\n#     Rep: 54 Cost: -0.8185041546821594\n#     Rep: 55 Cost: -0.82191002368927\n#     Rep: 56 Cost: -0.8252224326133728\n#     Rep: 57 Cost: -0.8284385204315186\n#     Rep: 58 Cost: -0.8315609693527222\n#     Rep: 59 Cost: -0.8345984220504761\n#     Rep: 60 Cost: -0.8375518321990967\n#     Rep: 61 Cost: -0.840415358543396\n#     Rep: 62 Cost: -0.8431857228279114\n#     Rep: 63 Cost: -0.8458709716796875\n#     Rep: 64 Cost: -0.8484804034233093\n#     Rep: 65 Cost: -0.8510205149650574\n#     Rep: 66 Cost: -0.8534920811653137\n#     Rep: 67 Cost: -0.8558962941169739\n#     Rep: 68 Cost: -0.8582370281219482\n#     Rep: 69 Cost: -0.8605165481567383\n#     Rep: 70 Cost: -0.8627358078956604\n#     Rep: 71 Cost: -0.8648967146873474\n#     Rep: 72 Cost: -0.8670018315315247\n#     Rep: 73 Cost: -0.8690568208694458\n#     Rep: 74 Cost: -0.8710666298866272\n#     Rep: 75 Cost: -0.8730334043502808\n#     Rep: 76 Cost: -0.874958336353302\n#     Rep: 77 Cost: -0.8768417239189148\n#     Rep: 78 Cost: -0.8786842226982117\n#     Rep: 79 Cost: -0.8804850578308105\n#     Rep: 80 Cost: -0.8822449445724487\n#     Rep: 81 Cost: -0.8839642405509949\n#     Rep: 82 Cost: -0.8856424689292908\n#     Rep: 83 Cost: -0.8872807025909424\n#     Rep: 84 Cost: -0.8888780474662781\n#     Rep: 85 Cost: -0.8904346823692322\n#     Rep: 86 Cost: -0.8919486999511719\n#     Rep: 87 Cost: -0.8934181928634644\n#     Rep: 88 Cost: -0.8948409557342529\n#     Rep: 89 Cost: -0.8962130546569824\n#     Rep: 90 Cost: -0.8975301384925842\n#     Rep: 91 Cost: -0.8987880349159241\n#     Rep: 92 Cost: -0.899979829788208\n#     Rep: 93 Cost: -0.9011000990867615\n#     Rep: 94 Cost: -0.9021427631378174\n#     Rep: 95 Cost: -0.9031027555465698\n#     Rep: 96 Cost: -0.9039766192436218\n#     Rep: 97 Cost: -0.9047646522521973\n#     Rep: 98 Cost: -0.9054698348045349\n#     Rep: 99 Cost: -0.9061003923416138\n#     Rep: 100 Cost: -0.9066662192344666\n#     Rep: 101 Cost: -0.9071784019470215\n#     Rep: 102 Cost: -0.9076470732688904\n#     Rep: 103 Cost: -0.9080801606178284\n#     Rep: 104 Cost: -0.9084805846214294\n#     Rep: 105 Cost: -0.9088495373725891\n#     Rep: 106 Cost: -0.9091846346855164\n#     Rep: 107 Cost: -0.9094842672348022\n#     Rep: 108 Cost: -0.9097475409507751\n#     Rep: 109 Cost: -0.9099751710891724\n#     Rep: 110 Cost: -0.9101698398590088\n#     Rep: 111 Cost: -0.9103357195854187\n#     Rep: 112 Cost: -0.9104783535003662\n#     Rep: 113 Cost: -0.9106017351150513\n#     Rep: 114 Cost: -0.9107118844985962\n#     Rep: 115 Cost: -0.9108109474182129\n#     Rep: 116 Cost: -0.9109019637107849\n#     Rep: 117 Cost: -0.9109862446784973\n#     Rep: 118 Cost: -0.9110654592514038\n#     Rep: 119 Cost: -0.9111390709877014\n#     Rep: 120 Cost: -0.91120845079422\n#     Rep: 121 Cost: -0.9112733602523804\n#     Rep: 122 Cost: -0.9113341569900513\n#     Rep: 123 Cost: -0.9113907814025879\n#     Rep: 124 Cost: -0.9114443063735962\n#     Rep: 125 Cost: -0.9114949107170105\n#     Rep: 126 Cost: -0.9115434288978577\n#     Rep: 127 Cost: -0.9115898013114929\n#     Rep: 128 Cost: -0.9116342067718506\n#     Rep: 129 Cost: -0.9116772413253784\n#     Rep: 130 Cost: -0.9117189645767212\n#     Rep: 131 Cost: -0.9117587804794312\n#     Rep: 132 Cost: -0.9117969274520874\n#     Rep: 133 Cost: -0.9118331670761108\n#     Rep: 134 Cost: -0.9118679165840149\n#     Rep: 135 Cost: -0.9118999242782593\n#     Rep: 136 Cost: -0.9119301438331604\n#     Rep: 137 Cost: -0.9119581580162048\n#     Rep: 138 Cost: -0.9119839072227478\n#     Rep: 139 Cost: -0.9120074510574341\n#     Rep: 140 Cost: -0.9120291471481323\n#     Rep: 141 Cost: -0.91204833984375\n#     Rep: 142 Cost: -0.9120661020278931\n#     Rep: 143 Cost: -0.9120829105377197\n#     Rep: 144 Cost: -0.9120978713035583\n#     Rep: 145 Cost: -0.9121111631393433\n#     Rep: 146 Cost: -0.9121232628822327\n#     Rep: 147 Cost: -0.9121342897415161\n#     Rep: 148 Cost: -0.9121443033218384\n#     Rep: 149 Cost: -0.9121529459953308\n#     Rep: 150 Cost: -0.9121609926223755\n#     Rep: 151 Cost: -0.9121681451797485\n#     Rep: 152 Cost: -0.9121744632720947\n#     Rep: 153 Cost: -0.9121802449226379\n#     Rep: 154 Cost: -0.9121854305267334\n#     Rep: 155 Cost: -0.9121901988983154\n#     Rep: 156 Cost: -0.9121944904327393\n#     Rep: 157 Cost: -0.912198543548584\n#     Rep: 158 Cost: -0.912202000617981\n#     Rep: 159 Cost: -0.912205159664154\n#     Rep: 160 Cost: -0.9122082591056824\n#     Rep: 161 Cost: -0.9122109413146973\n#     Rep: 162 Cost: -0.9122134447097778\n#     Rep: 163 Cost: -0.9122157692909241\n#     Rep: 164 Cost: -0.9122180342674255\n#     Rep: 165 Cost: -0.912219762802124\n#     Rep: 166 Cost: -0.912221372127533\n#     Rep: 167 Cost: -0.9122230410575867\n#     Rep: 168 Cost: -0.912224292755127\n#     Rep: 169 Cost: -0.9122257828712463\n#     Rep: 170 Cost: -0.9122268557548523\n#     Rep: 171 Cost: -0.9122276306152344\n#     Rep: 172 Cost: -0.9122287034988403\n#     Rep: 173 Cost: -0.9122294187545776\n#     Rep: 174 Cost: -0.9122301340103149\n#     Rep: 175 Cost: -0.9122307896614075\n#     Rep: 176 Cost: -0.9122319221496582\n#     Rep: 177 Cost: -0.9122322201728821\n#     Rep: 178 Cost: -0.9122328758239746\n#     Rep: 179 Cost: -0.9122334718704224\n#     Rep: 180 Cost: -0.9122337698936462\n#     Rep: 181 Cost: -0.9122341275215149\n#     Rep: 182 Cost: -0.9122346043586731\n#     Rep: 183 Cost: -0.9122347235679626\n#     Rep: 184 Cost: -0.9122350215911865\n#     Rep: 185 Cost: -0.9122350811958313\n#     Rep: 186 Cost: -0.9122355580329895\n#     Rep: 187 Cost: -0.9122354388237\n#     Rep: 188 Cost: -0.9122354984283447\n#     Rep: 189 Cost: -0.9122358560562134\n#     Rep: 190 Cost: -0.9122357964515686\n#     Rep: 191 Cost: -0.9122359156608582\n#     Rep: 192 Cost: -0.9122360944747925\n#     Rep: 193 Cost: -0.9122361540794373\n#     Rep: 194 Cost: -0.912236213684082\n#     Rep: 195 Cost: -0.9122362732887268\n#     Rep: 196 Cost: -0.912236213684082\n#     Rep: 197 Cost: -0.9122360348701477\n#     Rep: 198 Cost: -0.9122362732887268\n#     Rep: 199 Cost: -0.912236213684082\n\n\n######################################################################\n# We can see that the optimization converges to the optimum purity value\n# of 0.9122365.\n#\n# Visualising the optimum state\n# -----------------------------\n#\n# We can now calculate the density matrix of the input state\n# :math:`\\ket{\\phi}` which minimises entanglement:\n#\n# .. math:: \\rho_{\\phi} = \\ket{\\phi}\\left\\langle \\phi\\right|\n#\n\nket_val = phi_var_re.numpy() + phi_var_im.numpy()*1j\nout_rhoB = np.outer(ket_val, ket_val.conj())\nout_rhoB /= np.trace(out_rhoB)\n\n\n######################################################################\n# Note that the optimization is not guaranteed to keep the state normalized,\n# so we renormalize the minimized state.\n#\n# Next, we can use the following function to plot the Wigner function of\n# this density matrix:\n#\n\nimport copy\ndef wigner(rho, xvec, pvec):\n    # Modified from qutip.org\n    Q, P = np.meshgrid(xvec, pvec)\n    A = (Q + P * 1.0j) / (2 * np.sqrt(2 / 2))\n\n    Wlist = np.array([np.zeros(np.shape(A), dtype=complex) for k in range(cutoff)])\n\n    # Wigner function for |0><0|\n    Wlist[0] = np.exp(-2.0 * np.abs(A) ** 2) / np.pi\n\n    # W = rho(0,0)W(|0><0|)\n    W = np.real(rho[0, 0]) * np.real(Wlist[0])\n\n    for n in range(1, cutoff):\n        Wlist[n] = (2.0 * A * Wlist[n - 1]) / np.sqrt(n)\n        W += 2 * np.real(rho[0, n] * Wlist[n])\n\n    for m in range(1, cutoff):\n        temp = copy.copy(Wlist[m])\n        # Wlist[m] = Wigner function for |m><m|\n        Wlist[m] = (2 * np.conj(A) * temp - np.sqrt(m)\n                    * Wlist[m - 1]) / np.sqrt(m)\n\n        # W += rho(m,m)W(|m><m|)\n        W += np.real(rho[m, m] * Wlist[m])\n\n        for n in range(m + 1, cutoff):\n            temp2 = (2 * A * Wlist[n - 1] - np.sqrt(m) * temp) / np.sqrt(n)\n            temp = copy.copy(Wlist[n])\n            # Wlist[n] = Wigner function for |m><n|\n            Wlist[n] = temp2\n\n            # W += rho(m,n)W(|m><n|) + rho(n,m)W(|n><m|)\n            W += 2 * np.real(rho[m, n] * Wlist[n])\n\n    return Q, P, W / 2\n\n# Import plotting\nfrom matplotlib import pyplot as plt\n# %matplotlib inline\n\nx = np.arange(-5, 5, 0.1)\np = np.arange(-5, 5, 0.1)\nX, P, W = wigner(out_rhoB, x, p)\nplt.contourf(X, P, np.round(W,3), cmap=""PiYG"")\nplt.show()\n\n######################################################################\n# .. image:: /_static/images/sphx_glr_run_minimizing_correlations_001.png\n#     :class: sphx-glr-single-img\n\n######################################################################\n# We see that the optimal state is indeed a (mildly) squeezed state. This\n# can be confirmed by visuallising the Fock state probabilities of state\n# :math:`\\ket{\\phi}`:\n#\n\nplt.bar(np.arange(cutoff), height=np.diag(out_rhoB).real)\nplt.show()\n\n\n######################################################################\n# .. image:: /_static/images/sphx_glr_run_minimizing_correlations_002.png\n#     :class: sphx-glr-single-img\n\n\n######################################################################\n# Finally, printing out the mean number of photons\n# :math:`\\bar{n} = \\left\\langle \\phi \\mid \\hat{n} \\mid \\phi\\right\\rangle = \\text{Tr}(\\hat{n}\\rho)`,\n# as well as the squeezing magnitude\n# :math:`r=\\sinh^{-1}\\left(\\sqrt{\\bar{n}}\\right)` of this state:\n#\n\nnbar = np.trace(n_opt @ out_rhoB).real\nprint(""mean number of photons ="", nbar)\nprint(""squeezing parameter ="", np.arcsinh(np.sqrt(nbar)))\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     mean number of photons = 0.08352929059995343\n#     squeezing parameter = 0.28513493641217097\n\n######################################################################\n# References\n# ----------\n#\n# [1] Jiang, Z., Lang, M. D., & Caves, C. M. (2013). Mixing nonclassical\n# pure states in a linear-optical network almost always generates modal\n# entanglement. *Physical Review A*, 88(4), 044301.\n#\n# [2] Quesada, N., & Bra\xc5\x84czyk, A. M. (2018). Gaussian functions are\n# optimal for waveguided nonlinear-quantum-optical processes.\n# *Physical Review A*, 98, 043813.\n#\n'"
examples_apps/run_tutorial_dense.py,0,"b'# pylint: disable=wrong-import-position,wrong-import-order,ungrouped-imports\r\n""""""\r\n.. _apps-subgraph-tutorial:\r\n\r\nDense Subgraphs\r\n===============\r\n\r\n*Technical details are available in the API documentation:* :doc:`/code/api/strawberryfields.apps.subgraph`\r\n\r\nGraphs can be used to model a wide variety of concepts: social networks, financial markets,\r\nbiological networks, and many others. A common problem of interest is to find subgraphs that\r\ncontain a large number of connections between their nodes. These subgraphs may correspond to\r\ncommunities in social networks, correlated assets in a market, or mutually influential proteins\r\nin a biological network.\r\n\r\nMathematically, this task is known as the `dense subgraph problem\r\n<https://en.wikipedia.org/wiki/Dense_subgraph>`__. The density of a :math:`k`-node subgraph is equal\r\nto the number of its edges divided by the maximum possible number of edges.\r\nIdentifying the densest graph of a given size, known as the densest-:math:`k` subgraph problem,\r\nis `NP-Hard <https://en.wikipedia.org/wiki/NP-hardness>`__.\r\n\r\n\r\nAs shown in :cite:`arrazola2018using`, a defining feature of GBS is that when we encode a graph\r\ninto a GBS device, it samples dense subgraphs with high probability. This property can be\r\nused to find dense subgraphs by sampling from a GBS device and postprocessing the outputs.\r\nLet\'s take a look!\r\n\r\nFinding dense subgraphs\r\n-----------------------\r\nThe first step is to import all required modules. We\'ll need the :mod:`~.apps.data`\r\nmodule to load pre-generated samples, the :mod:`~.apps.sample` module to postselect samples, the\r\n:mod:`~.apps.subgraph` module to search for dense subgraphs, and the :mod:`~.apps.plot` module to\r\nvisualize the graphs. We\'ll also use Plotly which is required for the :mod:`~.apps.plot` module and\r\nNetworkX for graph operations.\r\n""""""\r\nfrom strawberryfields.apps import data, sample, subgraph, plot\r\nimport plotly\r\nimport networkx as nx\r\n\r\n##############################################################################\r\n# Here we\'ll study a 30-node graph with a planted 10-node graph, as considered in\r\n# :cite:`arrazola2018using`. The graph is generated by joining two Erd\xc5\x91s\xe2\x80\x93R\xc3\xa9nyi random graphs. The\r\n# first graph of 20 nodes is created with edge probability of 0.5. The second planted\r\n# graph is generated with edge probability of 0.875. The planted nodes are the last ten nodes in the\r\n# graph. The two graphs are joined by selecting 8 nodes at random from both graphs and adding an\r\n# edge between them. This graph has the sneaky property that even though the planted subgraph is the\r\n# densest of its size, its nodes have a lower average degree than the nodes in the rest of the\r\n# graph.\r\n#\r\n# The :mod:`~.apps.data` module has pre-generated GBS samples from this graph. Let\'s load them,\r\n# postselect on samples with a large number of clicks, and convert them to subgraphs:\r\n\r\nplanted = data.Planted()\r\npostselected = sample.postselect(planted, 16, 30)\r\npl_graph = nx.to_networkx_graph(planted.adj)\r\nsamples = sample.to_subgraphs(postselected, pl_graph)\r\nprint(len(samples))\r\n\r\n##############################################################################\r\n# Not bad! We have more than 2000 samples to play with \xf0\x9f\x98\x8e. The planted subgraph is actually easy to\r\n# identify; it even appears clearly from the force-directed Kamada-Kawai algorithm that is used to\r\n# plot graphs in Strawberry Fields:\r\nsub = list(range(20, 30))\r\nplot_graph = plot.graph(pl_graph, sub)\r\nplotly.offline.plot(plot_graph, filename=""planted.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/planted.html\r\n#\r\n# .. note::\r\n#     The command ``plotly.offline.plot()`` is used to display plots in the documentation. In\r\n#     practice, you can simply use ``plot_graph.show()`` to view the graph.\r\n\r\n##############################################################################\r\n# A more interesting challenge is to find dense subgraphs of different sizes; it is often\r\n# useful to identify many high-density subgraphs, not just the densest ones. This is the purpose of\r\n# the :func:`~.subgraph.search` function in the :mod:`~.apps.subgraph` module: to identify\r\n# collections of dense subgraphs for a range of sizes. The output of this function is a\r\n# dictionary whose keys correspond to subgraph sizes within the specified range. The values in\r\n# the dictionary are the top subgraphs of that size and their corresponding density.\r\n\r\ndense = subgraph.search(samples, pl_graph, 8, 16, max_count=3)  # we look at top 3 densest subgraphs\r\nfor k in range(8, 17):\r\n    print(dense[k][0])  # print only the densest subgraph of each size\r\n\r\n##############################################################################\r\n# From the results of the search we learn that, depending on their size, the densest subgraphs\r\n# belong to different regions of the graph: dense subgraphs of less than ten nodes are contained\r\n# within the planted subgraph, whereas larger dense subgraphs appear outside of the planted\r\n# subgraph. Smaller dense subgraphs can be cliques, characterized by having\r\n# maximum density of 1, while larger subgraphs are less dense. Let\'s see what the smallest and\r\n# largest subgraphs look like:\r\n\r\ndensest_8 = plot.graph(pl_graph, dense[8][0][1])\r\ndensest_16 = plot.graph(pl_graph, dense[12][0][1])\r\n\r\nplotly.offline.plot(densest_8, filename=""densest_8.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/densest_8.html\r\n\r\nplotly.offline.plot(densest_16, filename=""densest_16.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/densest_16.html\r\n\r\n##############################################################################\r\n# In principle there are different methods to postprocess GBS outputs to identify dense\r\n# subgraphs. For example, techniques for finding maximum cliques, included in the\r\n# :mod:`~.apps.clique` module could help provide initial subgraphs that can be resized to find\r\n# larger dense subgraphs. Such methods are hybrid algorithms combining the ability of GBS to\r\n# sample dense subgraphs with clever classical techniques. Can you think of your own hybrid\r\n# algorithm? \xf0\x9f\xa4\x94\r\n'"
examples_apps/run_tutorial_max_clique.py,0,"b'# pylint: disable=wrong-import-position,wrong-import-order,ungrouped-imports\r\n""""""\r\n.. _apps-clique-tutorial:\r\n\r\nMaximum Clique\r\n==============\r\n\r\n*Technical details are available in the API documentation:* :doc:`/code/api/strawberryfields.apps.clique`\r\n\r\nHere we\'ll explore how to combine GBS samples with local search algorithms to find large cliques\r\nin graphs. Let\'s get started!\r\n\r\nA clique is a special type of subgraph where all possible connections between nodes are present;\r\nthey are densest possible subgraphs of their size. The maximum clique problem, or max clique for\r\nshort, asks the question: given a graph :math:`G`, what is the largest clique in the graph?\r\nMax clique is `NP-Hard <https://en.wikipedia.org/wiki/NP-hardness>`_, so finding the biggest clique\r\nbecomes challenging for graphs with many\r\nnodes. This is why we need clever algorithms to identify large cliques!\r\n\r\nTo get started, we\'ll analyze the 24-node TACE-AS graph used in :cite:`banchi2019molecular`. This\r\nis the *binding interaction graph* representing the spatial compatibility of atom pairs in a\r\nprotein-molecule complex. Cliques in this graph correspond to stable docking configurations, which\r\nare of interest in determining how the molecule interacts with the protein.\r\n\r\nThe first step is to import the Strawberry Fields ``apps`` module and external dependencies:\r\n""""""\r\nfrom strawberryfields.apps import data, plot, sample, clique\r\nimport numpy as np\r\nimport networkx as nx\r\nimport plotly\r\n\r\n##############################################################################\r\n# The adjacency matrix of the TACE-AS graph can be loaded from the :mod:`~.apps.data` module and the\r\n# graph can be visualized using the :mod:`~.apps.plot` module:\r\n\r\nTA = data.TaceAs()\r\nA = TA.adj\r\nTA_graph = nx.Graph(A)\r\nplot_graph = plot.graph(TA_graph)\r\nplotly.offline.plot(plot_graph, filename=""TACE-AS.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/TACE-AS.html\r\n#\r\n# .. note::\r\n#     The command ``plotly.offline.plot()`` is used to display plots in the documentation. In\r\n#     practice, you can simply use ``plot_graph.show()`` to view your graph.\r\n\r\n##############################################################################\r\n# Can you spot any cliques in the graph? It\'s not so easy using only your eyes! The TACE-AS graph\r\n# is sufficiently small that all cliques can be found by performing an exhaustive search over\r\n# all subgraphs. For example, below we highlight a small *maximal* clique, i.e., a clique\r\n# not contained inside another clique:\r\n\r\nmaximal_clique = [4, 11, 12, 18]\r\nmaximal_fig = plot.graph(TA_graph, maximal_clique)\r\nplotly.offline.plot(maximal_fig, filename=""maximal_clique.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/maximal_clique.html\r\n\r\n##############################################################################\r\n# We\'ll now use the :mod:`~.apps.clique` module to find larger cliques in the graph. We can make\r\n# use of the pre-generated samples from the TACE-AS graph in the :mod:`~.apps.data` module and\r\n# post-select samples with a specific number of clicks. Here we\'ll look at samples with eight\r\n# clicks, of which there are a total of 1,984:\r\n\r\npostselected = sample.postselect(TA, 8, 8)\r\nsamples = sample.to_subgraphs(postselected, TA_graph)\r\nprint(len(samples))\r\n\r\n##############################################################################\r\n# GBS produces samples that correspond to subgraphs of high density. For fun, let\'s confirm this\r\n# by comparing the average subgraph density in the GBS samples to uniformly generated samples:\r\n\r\nGBS_dens = []\r\nu_dens = []\r\n\r\nfor s in samples:\r\n    uniform = list(np.random.choice(24, 8, replace=False))  # generates uniform sample\r\n    GBS_dens.append(nx.density(TA_graph.subgraph(s)))\r\n    u_dens.append(nx.density(TA_graph.subgraph(uniform)))\r\n\r\nprint(""GBS mean density = {:.4f}"".format(np.mean(GBS_dens)))\r\nprint(""Uniform mean density = {:.4f}"".format(np.mean(u_dens)))\r\n\r\n##############################################################################\r\n# Those look like great GBS samples \xf0\x9f\x92\xaa! To obtain cliques, we shrink the samples by greedily\r\n# removing nodes with low degree until a clique is found.\r\n\r\nshrunk = [clique.shrink(s, TA_graph) for s in samples]\r\nprint(clique.is_clique(TA_graph.subgraph(shrunk[0])))\r\n\r\n##############################################################################\r\n# Let\'s take a look at some of these cliques. What are the clique sizes in the first ten samples?\r\n# What is the average clique size? How about the largest and smallest clique size?\r\n\r\nclique_sizes = [len(s) for s in shrunk]\r\nprint(""First ten clique sizes = "", clique_sizes[:10])\r\nprint(""Average clique size = {:.3f}"".format(np.mean(clique_sizes)))\r\nprint(""Maximum clique size = "", np.max(clique_sizes))\r\nprint(""Minimum clique size = "", np.min(clique_sizes))\r\n\r\n##############################################################################\r\n# Even in the first few samples, we\'ve already identified larger cliques than the 4-node clique\r\n# we studied before. Awesome! Indeed, this simple shrinking strategy gives cliques with average\r\n# size of roughly five. We can enlarge these cliques by searching for larger cliques in their\r\n# vicinity. We\'ll do this by taking ten iterations of local search and studying the results.\r\n# Note: this may take a few seconds.\r\n\r\nsearched = [clique.search(s, TA_graph, 10) for s in shrunk]\r\nclique_sizes = [len(s) for s in searched]\r\nprint(""First two cliques = "", searched[:2])\r\nprint(""Average clique size = {:.3f}"".format(np.mean(clique_sizes)))\r\n\r\n##############################################################################\r\n# Wow! Local search is very helpful, we\'ve found cliques with the maximum size of eight for\r\n# essentially all samples \xf0\x9f\xa4\xa9.  Let\'s take a look at the first clique we found\r\n\r\nclique_fig = plot.graph(TA_graph, searched[0])\r\nplotly.offline.plot(clique_fig, filename=""maximum_clique.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/maximum_clique.html\r\n\r\n##############################################################################\r\n# The TACE-AS graph is relatively small, so finding large cliques is not particularly difficult. A\r\n# tougher challenge is the 300-node ``p_hat300-1`` random graph from the `DIMACS\r\n# <http://iridia.ulb.ac.be/~fmascia/maximum_clique/DIMACS-benchmark>`_ maximum clique\r\n# dataset. In this section, we\'ll write a short program that uses GBS samples in combination with\r\n# local search to identify large cliques in this graph.\r\n\r\nPhat = data.PHat()  # Load data\r\nphat_graph = nx.Graph(Phat.adj)  # Obtain graph\r\npostselected = sample.postselect(Phat, 16, 20)  # Post-select samples\r\nsamples = sample.to_subgraphs(postselected, phat_graph)  # Convert samples into subgraphs\r\nshrunk = [clique.shrink(s, phat_graph) for s in samples]  # Shrink subgraphs to cliques\r\nsearched = [clique.search(s, phat_graph, 10) for s in shrunk]  # Perform local search\r\nclique_sizes = [len(s) for s in searched]\r\nlargest_clique = searched[np.argmax(clique_sizes)]  # Identify largest clique found\r\nprint(""Largest clique found is = "", largest_clique)\r\n\r\n##############################################################################\r\n# Let\'s make a plot to take a closer look at the largest clique we found\r\nlargest_fig = plot.graph(phat_graph, largest_clique)\r\nplotly.offline.plot(largest_fig, filename=""largest_clique.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/largest_clique.html\r\n\r\njust_largest = plot.subgraph(phat_graph.subgraph(largest_clique))\r\nplotly.offline.plot(just_largest, filename=""just_largest.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/just_largest.html\r\n\r\n##############################################################################\r\n# The ``p_hat300-1`` graph has several maximum cliques of size eight,\r\n# and we have managed to find them! What other graphs can you analyze using GBS?\r\n'"
examples_apps/run_tutorial_points.py,0,"b'# pylint: disable=wrong-import-position,wrong-import-order,ungrouped-imports,invalid-name\nr""""""\n.. _apps-points-tutorial:\n\nPoint processes\n===============\n\n*Technical details are available in the API documentation:* :doc:`/code/api/strawberryfields.apps.points`\n\nThis section shows how to generate GBS point process samples and use them to detect outlier\npoints in a data set. Point processes are models for generating random point patterns and can be\nuseful in machine learning, providing a source of randomness with\npreference towards both diversity :cite:`kulesza2012determinantal` and similarity in data. GBS\ndevices can be programmed to operate as special types of point processes that generate clustered\nrandom point patterns :cite:`jahangiri2019point`.\n\nThe probability of generating a specific pattern of points in GBS point processes depends on\nmatrix functions of a kernel matrix :math:`K` that describes the similarity between the points.\nMatrix functions that appear in GBS point processes are typically\n`permanents <https://en.wikipedia.org/wiki/Permanent_(mathematics)>`__ and\n`hafnians <https://the-walrus.readthedocs.io/en/latest/hafnian.html>`__. Here we use\nthe permanental point process, in which the probability of observing a pattern of points :math:`S`\ndepends on the permanent of their corresponding kernel submatrix :math:`K_S` as\n:cite:`jahangiri2019point`:\n\n.. math::\n    \\mathcal{P}(S) = \\frac{1}{\\alpha(S)}\\text{per}(K_S),\n\nwhere :math:`\\alpha` is a normalization function that depends on :math:`S` and the average number\nof points. Let\'s look at a simple example to better understand the permanental point process.\n""""""\n\n##############################################################################\n# We first import the modules we need. Note that the :mod:`~.apps.points` module has most of\n# the core functionalities exploring point processes.\n\nimport numpy as np\nimport plotly\nfrom sklearn.datasets import make_blobs\nfrom strawberryfields.apps import points, plot\n\n##############################################################################\n# We define a space where the GBS point process patterns are generated. This\n# space is referred to as the state space and is defined by a set of points. The\n# point process selects a subset of these points in each sample. Here we create\n# a 20 :math:`\\times` 20 square grid of points.\n\nR = np.array([(i, j) for i in range(20) for j in range(20)])\n\n##############################################################################\n# The rows of R are the coordinates of the points.\n#\n# Next step is to create the kernel matrix for the points of this discrete space. We call\n# the :func:`~.rbf_kernel` function which uses the *radial basis function* (RBF) kernel defined as:\n#\n# .. math::\n#     K_{i,j} = e^{-\\|\\bf{r}_i-\\bf{r}_j\\|^2/2\\sigma^2},\n#\n# where :math:`\\bf{r}_i` are the coordinates of point :math:`i` and :math:`\\sigma` is a kernel\n# parameter that determines the scale of the kernel.\n#\n# In the RBF kernel, points that are much further than a distance :math:`\\sigma` from each other\n# lead to small entries of the kernel matrix, whereas points much closer than :math:`\\sigma`\n# generate large entries. Now consider a specific point pattern in which all points\n# are close to each other, which simply means that their matrix elements have larger entries. The\n# permanent of a matrix is a sum over the product of some matrix entries. Therefore,\n# the submatrix that corresponds to those points has a large permanent and the probability of\n# observing them in a sample is larger.\n#\n# For kernel matrices that are positive-semidefinite, such as the RBF kernel, there exist efficient\n# quantum-inspired classical algorithms for permanental point process sampling\n# :cite:`jahangiri2019point`. In this tutorial we use positive-semidefinite kernels and the\n# quantum-inspired classical algorithm.\n#\n# Let\'s construct the RBF kernel with the parameter :math:`\\sigma` set to 2.5.\n\nK = points.rbf_kernel(R, 2.5)\n\n##############################################################################\n# We generate 10 samples with an average number of 50 points per sample by calling\n# the :func:`~.points.sample` function of the :mod:`~.apps.points` module.\n\nsamples = points.sample(K, 50.0, 10)\n\n##############################################################################\n# We visualize the first sample by using the :func:`~.points` function of\n# the :mod:`~.apps.plot` module. The point patterns generated by the permanental point process\n# usually have a higher degree of clustering compared to a uniformly random pattern.\n\nplot_1 = plot.points(R, samples[0], point_size=10)\n\nplotly.offline.plot(plot_1, filename=""Points.html"")\n\n##############################################################################\n# .. raw:: html\n#     :file: ../../examples_apps/Points.html\n#\n# .. note::\n#     The command ``plotly.offline.plot()`` is used to display plots in the documentation. In\n#     practice, you can simply use ``plot_1.show()`` to view your graph.\n\n##############################################################################\n# Outlier Detection\n# -----------------\n#\n# When the distribution of points in a given space is inhomogeneous, GBS point processes\n# sample points from the dense regions with higher probability. This feature of the GBS point\n# processes can be used to detect outlier points in a data set. In this example, we create two\n# dense clusters and place them in a two-dimensional space containing some randomly distributed\n# points in the background. We consider the random background points as outliers to the clustered\n# points and show that the permanental point process selects points from the dense clusters with\n# a higher probability.\n#\n# We first create the data points. The clusters have 50 points each and the points have a\n# standard deviation of 0.3. The clusters are centered at :math:`[x = 2, y = 2]` and :math:`[x = 4,\n# y = 4]`, respectively. We also add 25 randomly generated points to the data set.\n\nclusters = make_blobs(n_samples=100, centers=[[2, 2], [4, 4]], cluster_std=0.3)[0]\n\nnoise = np.random.rand(25, 2) * 6.0\n\nR = np.concatenate((clusters, noise))\n\n##############################################################################\n# Then construct the kernel matrix and generate 10000 samples.\n\nK = points.rbf_kernel(R, 1.0)\n\nsamples = points.sample(K, 10.0, 10000)\n\n##############################################################################\n# We obtain the indices of 100 points that appear most frequently in the permanental point\n# process samples and visualize them. The majority of the commonly appearing points belong\n# to the clusters and the points that do not appear frequently are the outlier points. Note that\n# some of the background points might overlap with the clusters.\n\ngbs_frequent_points = np.argsort(np.sum(samples, axis=0))[-100:]\n\nplot_2 = plot.points(\n    R, [1 if i in gbs_frequent_points else 0 for i in range(len(samples[0]))], point_size=10\n)\n\nplotly.offline.plot(plot_2, filename=""Outliers.html"")\n\n##############################################################################\n# .. raw:: html\n#     :file: ../../examples_apps/Outliers.html\n\n##############################################################################\n# The two-dimensional examples considered here can be easily extended to higher dimensions. The\n# GBS point processes retain their clustering property in higher dimensions but visual inspection\n# of this clustering feature might not be very straightforward.\n#\n# GBS point processes can potentially be used in other applications such as clustering data points\n# and finding correlations in time series data. Can you design your own example for using GBS point\n# processes in a new application?\n'"
examples_apps/run_tutorial_sample.py,0,"b'# pylint: disable=invalid-name,no-member,wrong-import-position,wrong-import-order,ungrouped-imports\r\n""""""\r\n.. _apps-sample-tutorial:\r\n\r\nSampling from GBS\r\n=================\r\n\r\n*Technical details are available in the API documentation:* :doc:`/code/api/strawberryfields.apps.sample`\r\n\r\nA GBS device can be programmed to sample from any symmetric matrix :math:`A`. To sample,\r\nwe must specify the mean number of photons being generated in the device and optionally the form of\r\ndetection used at the output: threshold detection or photon-number resolving (PNR) detection.\r\nThreshold detectors are restricted to measuring whether photons have arrived at the detector,\r\nwhereas PNR detectors are able to count the number of photons. Photon loss can also be specified\r\nwith the ``loss`` argument.\r\n\r\nSampling functionality is provided in the :mod:`~.apps.sample` module.\r\n\r\nLet\'s take a look at both types of sampling methods. We can generate samples from a random\r\n5-dimensional symmetric matrix:\r\n""""""\r\n\r\nfrom strawberryfields.apps import sample\r\nimport numpy as np\r\n\r\nmodes = 5\r\nn_mean = 6\r\nsamples = 5\r\n\r\nA = np.random.normal(0, 1, (modes, modes))\r\nA = A + A.T\r\n\r\ns_thresh = sample.sample(A, n_mean, samples, threshold=True)\r\ns_pnr = sample.sample(A, n_mean, samples, threshold=False)\r\n\r\nprint(s_thresh)\r\nprint(s_pnr)\r\n\r\n##############################################################################\r\n# In each case, a sample is a sequence of integers of length five, i.e., ``len(modes) = 5``.\r\n# Threshold samples are ``0``\'s and ``1``\'s, corresponding to whether or not photons were\r\n# detected in a mode. A ``1`` here is conventionally called a ""click"". PNR samples are\r\n# non-negative integers counting the number of photons detected in each mode. For example,\r\n# suppose a PNR sample is ``[2, 1, 1, 0, 0]``, meaning that 2 photons were detected in mode 0,\r\n# 1 photons were detected in modes 1 and 2, and 0 photons were detected in modes 3 and 4. If\r\n# threshold detectors were used instead, the sample would be: ``[1, 1, 1, 0, 0]``.\r\n#\r\n# A more general :func:`~.apps.sample.gaussian` function allows for sampling from arbitrary pure\r\n# Gaussian states.\r\n#\r\n# Sampling subgraphs\r\n# ------------------\r\n#\r\n# So when would threshold detection or PNR detection be preferred in GBS? Since threshold samples\r\n# can be post-processed from PNR samples, we might expect that PNR detection is always the\r\n# preferred choice. However, in practice *simulating* PNR-based GBS is significantly slower,\r\n# and it turns out that threshold samples can provide enough useful information for a range of\r\n# applications.\r\n#\r\n# Strawberry Fields provides tools for solving graph-based problems. In this setting,\r\n# we typically want to use GBS to sample subgraphs, which are likely to be dense due to the\r\n# probability distribution of GBS :cite:`arrazola2018using`. In this case, threshold sampling\r\n# is enough, since it lets us select nodes of the subgraph. Let\'s take a look at this by using a\r\n# small fixed graph as an example:\r\n\r\nfrom strawberryfields.apps import plot\r\nimport networkx as nx\r\nimport plotly\r\n\r\nadj = np.array(\r\n    [\r\n        [0, 1, 0, 0, 1, 1],\r\n        [1, 0, 1, 0, 1, 1],\r\n        [0, 1, 0, 1, 1, 0],\r\n        [0, 0, 1, 0, 1, 0],\r\n        [1, 1, 1, 1, 0, 1],\r\n        [1, 1, 0, 0, 1, 0],\r\n    ]\r\n)\r\n\r\ngraph = nx.Graph(adj)\r\nplot_graph = plot.graph(graph)\r\n\r\nplotly.offline.plot(plot_graph, filename=""random_graph.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/random_graph.html\r\n#\r\n# .. note::\r\n#     The command ``plotly.offline.plot()`` is used to display plots in the documentation. In\r\n#     practice, you can simply use ``plot_graph.show()`` to view your graph.\r\n#\r\n# This is a 6-node graph with the nodes ``[0, 1, 4, 5]`` fully connected to each other. We expect\r\n# to be able to sample dense subgraphs with high probability.\r\n#\r\n# Samples can be generated from this graph through GBS using the :func:`~.apps.sample.sample`\r\n# function:\r\n\r\nn_mean = 4\r\nsamples = 20\r\n\r\ns = sample.sample(adj, n_mean, samples)\r\n\r\nprint(s[:5])\r\n\r\n##############################################################################\r\n# Each sample in ``s`` is a list of modes with ``1``\'s for nodes that have clicked and ``0``\'s\r\n# for nodes that haven\'t. We want to convert a sample to another representation where the result\r\n# is a list of modes that have clicked. This list of modes can be used to select a subgraph.\r\n# For example, if ``[0, 1, 0, 1, 1, 0]`` is a sample from GBS then ``[1, 3, 4]`` are\r\n# the selected nodes of the corresponding subgraph.\r\n#\r\n# However, the number of clicks in GBS is a random variable and we are not always guaranteed to\r\n# have enough clicks in a sample for the resultant subgraph to be of interest. We can filter out\r\n# the uninteresting samples using the :func:`~.apps.sample.postselect` function:\r\n\r\nmin_clicks = 3\r\nmax_clicks = 4\r\n\r\ns = sample.postselect(s, min_clicks, max_clicks)\r\n\r\nprint(len(s))\r\ns.append([0, 1, 0, 1, 1, 0])\r\n\r\n##############################################################################\r\n# As expected, we have fewer samples than before. The number of samples that survive this\r\n# postselection is determined by the mean photon number in GBS. We have also added in our example\r\n# sample ``[0, 1, 0, 1, 1, 0]`` to ensure that there is at least one for the following.\r\n#\r\n# Let\'s convert our postselected samples to subgraphs:\r\n\r\nsubgraphs = sample.to_subgraphs(s, graph)\r\n\r\nprint(subgraphs)\r\n\r\n##############################################################################\r\n# We can take a look at one of the sampled subgraphs:\r\n\r\nplotly.offline.plot(plot.graph(graph, subgraphs[0]), filename=""subgraph.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/subgraph.html\r\n#\r\n# These sampled subgraphs act as the starting point for some of the applications made available\r\n# in Strawberry Fields, including the maximum clique and dense subgraph identification problems.\r\n#\r\n# .. note::\r\n#       Simulating GBS can be computationally intensive when using both threshold and PNR\r\n#       detectors. After all, we are using a classical algorithm to simulate a quantum process!\r\n#       To help users get to grips with the applications of Strawberry Fields as quickly as\r\n#       possible, we have provided datasets of pre-calculated GBS samples. These datasets are\r\n#       available in the :mod:`~.apps.data` module.\r\n'"
examples_apps/run_tutorial_similarity.py,0,"b'# pylint: disable=wrong-import-position,wrong-import-order,ungrouped-imports,invalid-name\r\n""""""\r\n.. _apps-sim-tutorial:\r\n\r\nGraph similarity\r\n================\r\n\r\n*Technical details are available in the API documentation:* :doc:`/code/api/strawberryfields.apps.similarity`\r\n\r\nThis page looks at how to use GBS to construct a similarity measure between graphs,\r\nknown as a graph kernel :cite:`schuld2019quantum`. Kernels can be applied to graph-based\r\ndata for machine learning tasks such as classification using a support vector machine.\r\n\r\nGraph data\r\n----------\r\n\r\nWe begin by fixing a dataset of graphs to consider and loading GBS samples from these graphs,\r\nwhich will be needed in the following.\r\n\r\nLet\'s use the MUTAG dataset of graphs :cite:`debnath1991structure,kriege2012subgraph`. This is a\r\ndataset of 188 different graphs that each correspond to the structure of a chemical compound. Our\r\ngoal is to use GBS samples from these graphs to measure their similarity.\r\n\r\nThe :mod:`~.apps.data` module provides pre-calculated GBS samples for selected graphs in the MUTAG\r\ndataset. Each set of samples is generated by encoding the graph into a GBS device, and collecting\r\nphoton click events. We\'ll start by loading four sets of samples and visualizing the\r\ncorresponding graphs.\r\n""""""\r\n\r\nfrom strawberryfields.apps import data, plot, similarity\r\n\r\nm0 = data.Mutag0()\r\nm1 = data.Mutag1()\r\nm2 = data.Mutag2()\r\nm3 = data.Mutag3()\r\n\r\n##############################################################################\r\n# These datasets contain both the adjacency matrix of the graph and the samples generated through\r\n# GBS. We can access the adjacency matrix through:\r\n\r\nm0_a = m0.adj\r\nm1_a = m1.adj\r\nm2_a = m2.adj\r\nm3_a = m3.adj\r\n\r\n##############################################################################\r\n# Samples from these graphs can be accessed by indexing:\r\n\r\nprint(m0[0])\r\n\r\n##############################################################################\r\n# We can now plot the four graphs using the :mod:`~.apps.plot` module. To use this module,\r\n# we need to convert the adjacency matrices into NetworkX Graphs:\r\n\r\nimport networkx as nx\r\nimport plotly\r\n\r\nplot_mutag_0 = plot.graph(nx.Graph(m0_a))\r\nplot_mutag_1 = plot.graph(nx.Graph(m1_a))\r\nplot_mutag_2 = plot.graph(nx.Graph(m2_a))\r\nplot_mutag_3 = plot.graph(nx.Graph(m3_a))\r\n\r\nplotly.offline.plot(plot_mutag_0, filename=""MUTAG_0.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/MUTAG_0.html\r\n#\r\n# .. note::\r\n#     The command ``plotly.offline.plot()`` is used to display plots in the documentation. In\r\n#     practice, you can simply use ``plot_mutag_0.show()`` to view your graph.\r\n\r\nplotly.offline.plot(plot_mutag_1, filename=""MUTAG_1.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/MUTAG_1.html\r\n\r\nplotly.offline.plot(plot_mutag_2, filename=""MUTAG_2.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/MUTAG_2.html\r\n\r\nplotly.offline.plot(plot_mutag_3, filename=""MUTAG_3.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/MUTAG_3.html\r\n#\r\n# The graphs of ``m1_a`` and ``m2_a`` look very similar. In fact,\r\n# it turns out that they are *isomorphic* to each other, which means that the graphs can be made\r\n# identical by permuting their node labels.\r\n\r\n##############################################################################\r\n# Creating a feature vector\r\n# -------------------------\r\n#\r\n# Following :cite:`schuld2019quantum`, we can create a *feature vector* to describe each graph.\r\n# These feature vectors contain information about the graphs and can be viewed as a mapping to a\r\n# high-dimensional feature space, a technique often used in machine learning that allows us to\r\n# employ properties of the feature space to separate and classify the vectors.\r\n#\r\n# The feature vector of a graph can be composed in a variety of ways. One approach is to\r\n# associate features with the relative frequencies of certain types of measurements being\r\n# recorded from a GBS device configured to sample from the graph, as we now discuss.\r\n#\r\n# We begin by defining the concept of an *orbit*, which is the set of all GBS samples that are\r\n# equivalent under permutation of the modes. A sample can be converted to its corresponding orbit\r\n# using the :func:`~.sample_to_orbit` function. For example, the first sample of ``m0`` is ``[0,\r\n# 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]`` and has orbit:\r\n\r\nprint(similarity.sample_to_orbit(m0[0]))\r\n\r\n##############################################################################\r\n# Here, ``[1, 1]`` means that two photons were detected, each in a separate mode. Other samples\r\n# can be randomly generated from the ``[1, 1]`` orbit using:\r\n\r\nprint(similarity.orbit_to_sample([1, 1], modes=m0.modes))\r\n\r\n##############################################################################\r\n# Orbits provide a useful way to coarse-grain the samples from GBS into outcomes that are\r\n# statistically more likely to be observed. However, we are interested in coarse-graining further\r\n# into *events*, which correspond to a combination of orbits with the same photon number such\r\n# that the number of photons counted in each mode does not exceed a fixed value\r\n# ``max_count_per_mode``. To understand this, let\'s look at all of the orbits with a photon\r\n# number of 5:\r\n\r\nprint(list(similarity.orbits(5)))\r\n\r\n##############################################################################\r\n# All 5-photon samples belong to one of the orbits above. A 5-photon event with\r\n# ``max_count_per_mode = 3`` means that we include the orbits: ``[[1, 1, 1, 1, 1], [2, 1, 1, 1],\r\n# [3, 1, 1], [2, 2, 1], [3, 2]]`` and ignore the orbits ``[[4, 1], [5]]``. For example,\r\n# the sample ``[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0]`` is a 5-photon event:\r\n\r\nprint(similarity.sample_to_event([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0], 3))\r\n\r\n##############################################################################\r\n# Samples with more than ``max_count_per_mode`` in any mode are not counted as part of the event:\r\n\r\nprint(similarity.sample_to_event([0, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 3))\r\n\r\n##############################################################################\r\n# Now that we have mastered orbits and events, how can we make a feature vector? It was shown in\r\n# :cite:`schuld2019quantum` that one way of making a feature vector of a graph is through the\r\n# frequencies of events. Specifically, for a :math:`k` photon event :math:`E_{k, n_{\\max}}`\r\n# with maximum count per mode :math:`n_{\\max}` and corresponding probability :math:`p_{k,\r\n# n_{\\max}}:=p_{E_{k, n_{\\max}}}(G)` with respect to a graph :math:`G`, a feature vector can be\r\n# written as\r\n#\r\n# .. math::\r\n#     f_{\\mathbf{k}, n_{\\max}} = (p_{k_{1}, n_{\\max}}, p_{k_{2}, n_{\\max}}, \\ldots , p_{k_{K},\r\n#         n_{\\max}}),\r\n#\r\n# where :math:`\\mathbf{k} := (k_{1}, k_{2}, \\ldots , k_{K})` is a list of different total photon\r\n# numbers.\r\n#\r\n# For example, if :math:`\\mathbf{k} := (2, 4, 6)` and :math:`n_{\\max} = 2`, we have\r\n#\r\n# .. math::\r\n#     f_{(2, 4, 6), 2} = (p_{2, 2}, p_{4, 2}, p_{6, 2}).\r\n#\r\n# In this case, we are interested in the probabilities of events :math:`E_{2, 2}`, :math:`E_{4,\r\n# 2}`, and :math:`E_{6, 2}`. Suppose we are sampling from a four-mode device and have the samples\r\n# ``[0, 3, 0, 1]`` and ``[1, 2, 0, 1]``. These samples are part of the orbits ``[3, 1]`` and\r\n# ``[2, 1, 1]``, respectively. However, ``[3, 1]`` is not part of the :math:`E_{4, 2}` event while\r\n# ``[2, 1, 1]`` is.\r\n#\r\n# Calculating a feature vector\r\n# ----------------------------\r\n#\r\n# We provide two methods for calculating a feature vector of GBS event probabilities in\r\n# Strawberry Fields:\r\n#\r\n# 1. Through sampling.\r\n# 2. Using a Monte Carlo estimate of the probability.\r\n#\r\n# In the first method, all one needs to do is generate some GBS samples from the graph of\r\n# interest and fix the composition of the feature vector. For example, for a feature vector\r\n# :math:`f_{\\mathbf{k} = (2, 4, 6), n_{\\max}=2}` we use:\r\n\r\nprint(similarity.feature_vector_sampling(m0, event_photon_numbers=[2, 4, 6], max_count_per_mode=2))\r\n\r\n##############################################################################\r\n# For the second method, suppose we want to calculate the event probabilities exactly rather than\r\n# through sampling. To do this, we consider the event probability :math:`p_{k, n_{\\max}}` as the\r\n# sum over all sample probabilities in the event. In GBS, each sample probability is determined by\r\n# the hafnian of a relevant sub-adjacency matrix. While this is tough to calculate, what makes\r\n# calculating :math:`p_{k, n_{\\max}}` really challenging is the number of samples the corresponding\r\n# event contains! For example, the 6-photon event over 17 modes :math:`E_{k=6, n_{\\max}=2}`\r\n# contains the following number of samples :\r\n\r\nprint(similarity.event_cardinality(6, 2, 17))\r\n\r\n##############################################################################\r\n# To avoid calculating a large number of sample probabilities, an alternative is to perform a\r\n# Monte Carlo approximation. Here, samples within an event are selected uniformly at random and\r\n# their resultant probabilities are calculated. If :math:`N` samples :math:`\\{S_{1}, S_{2},\r\n# \\ldots , S_{N}\\}` are generated, then the event probability can be approximated as\r\n#\r\n# .. math::\r\n#     p(E_{k, n_{\\max}}) \\approx \\frac{1}{N}\\sum_{i=1}^N p(S_i) |E_{k, n_{\\max}}|,\r\n#\r\n# with :math:`|E_{k, n_{\\max}}|` denoting the cardinality of the event.\r\n#\r\n# This method can be accessed using the :func:`~.prob_event_mc` function. The 4-photon event is\r\n# approximated as:\r\n\r\nprint(similarity.prob_event_mc(nx.Graph(m0_a), 4, max_count_per_mode=2, n_mean=6))\r\n\r\n##############################################################################\r\n# The feature vector can then be calculated through Monte Carlo sampling using\r\n# :func:`~.feature_vector_mc`.\r\n#\r\n# .. note::\r\n#     The results of :func:`~.prob_event_mc` and :func:`~.feature_vector_mc` are probabilistic and\r\n#     may vary between runs. Increasing the optional ``samples`` parameter will increase accuracy\r\n#     but slow down calculation.\r\n#\r\n# The second method of Monte Carlo approximation is intended for use in scenarios where it is\r\n# computationally intensive to pre-calculate a statistically significant dataset of samples from\r\n# GBS.\r\n#\r\n# Machine learning with GBS graph kernels\r\n# ---------------------------------------\r\n#\r\n# The power of feature vectors that embed graphs in a vector space of real numbers is that we can\r\n# now measure similarities between graphs. This is very useful in machine learning, where similar\r\n# labels are assigned to graphs that are close to each other. GBS feature vectors therefore give\r\n# rise to a similarity measure between graphs!\r\n#\r\n# Let\'s build this up a bit more. The MUTAG dataset we are considering contains not only graphs\r\n# corresponding to the structure of chemical compounds, but also a *label* of each\r\n# compound based upon its mutagenic effect. The four graphs we consider here have labels:\r\n#\r\n# - MUTAG0: Class 1\r\n# - MUTAG1: Class 0\r\n# - MUTAG2: Class 0\r\n# - MUTAG3: Class 1\r\n\r\nclasses = [1, 0, 0, 1]\r\n\r\n##############################################################################\r\n# We can use GBS feature vectors in a `support vector machine\r\n# <https://en.wikipedia.org/wiki/Support-vector_machine>`__ (SVM) that finds a separating\r\n# hyperplane between classes in the feature space. We start by defining two-dimensional feature\r\n# vectors:\r\n\r\nevents = [8, 10]\r\nmax_count = 2\r\n\r\nf1 = similarity.feature_vector_sampling(m0, events, max_count)\r\nf2 = similarity.feature_vector_sampling(m1, events, max_count)\r\nf3 = similarity.feature_vector_sampling(m2, events, max_count)\r\nf4 = similarity.feature_vector_sampling(m3, events, max_count)\r\n\r\nimport numpy as np\r\n\r\nR = np.array([f1, f2, f3, f4])\r\n\r\nprint(R)\r\n\r\n##############################################################################\r\n# There is freedom in the choice of ``events`` composing the feature vectors and we encourage the\r\n# reader to explore different combinations. Note, however, that odd photon-numbered events have\r\n# zero probability because ideal GBS only generates and outputs pairs of photons.\r\n#\r\n# Given our points in the feature space and their target labels, we can use\r\n# scikit-learn\'s Support Vector Machine `LinearSVC <https://scikit-learn.org/stable/modules/generated/sklearn.svm\r\n# .LinearSVC.html>`__ as our model to train:\r\n\r\nfrom sklearn.svm import LinearSVC\r\nfrom sklearn.preprocessing import StandardScaler\r\n\r\nR_scaled = StandardScaler().fit_transform(R)  # Transform data to zero mean and unit variance\r\n\r\nclassifier = LinearSVC()\r\nclassifier.fit(R_scaled, classes)\r\n\r\n##############################################################################\r\n# Here, the term ""linear"" refers to the *kernel* function used to calculate inner products\r\n# between vectors in the space. We can use a linear SVM because we have already embedded the\r\n# graphs in a feature space based on GBS. We have also rescaled the feature vectors so that they\r\n# zero mean and unit variance using scikit-learn\'s ``StandardScaler``, a technique\r\n# `often used <https://scikit-learn.org/stable/modules/preprocessing.html>`__ in machine learning.\r\n#\r\n# We can then visualize the trained SVM by plotting the decision boundary with respect to the\r\n# points:\r\n\r\nw = classifier.coef_[0]\r\ni = classifier.intercept_[0]\r\n\r\nm = -w[0] / w[1]  # finding the values for y = mx + b\r\nb = -i / w[1]\r\n\r\nxx = [-1, 1]\r\nyy = [m * x + b for x in xx]\r\n\r\nfig = plot.points(R_scaled, classes)\r\nfig.add_trace(plotly.graph_objects.Scatter(x=xx, y=yy, mode=""lines""))\r\n\r\nplotly.offline.plot(fig, filename=""SVM.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/SVM.html\r\n#\r\n# This plot shows the two classes (grey points for class 0 and red points for class 1)\r\n# successfully separated by the linear hyperplane using the GBS feature space. Moreover,\r\n# recall that the two MUTAG1 and MUTAG2 graphs of class 0 are actually isomorphic. Reassuringly,\r\n# their corresponding feature vectors are very similar. In fact, the feature vectors of\r\n# isomorphic graphs should always be identical :cite:`bradler2018graph` - the small discrepancy\r\n# in this plot is due to the statistical approximation from sampling.\r\n'"
examples_apps/run_tutorial_vibronic.py,0,"b'# pylint: disable=wrong-import-position,wrong-import-order,ungrouped-imports\r\nr""""""\r\n.. _apps-vibronic-tutorial:\r\n\r\nVibronic spectra\r\n================\r\n\r\n*Technical details are available in the API documentation:* :doc:`/code/api/strawberryfields.apps.vibronic`\r\n\r\nHere we study how GBS can be used to compute vibronic spectra. So let\'s start from\r\nthe beginning: what is a vibronic spectrum? Molecules absorb light at frequencies that depend on\r\nthe allowed transitions between different electronic states. These electronic transitions\r\ncan be accompanied by changes in the vibrational energy of the molecules. In this case, the\r\nabsorption lines that represent the frequencies at which light is more strongly absorbed are\r\nreferred to as the *vibronic* spectrum. The term *vibronic* refers to the simultaneous vibrational\r\nand electronic transitions of a molecule upon absorption of light.\r\n\r\nIt is possible to determine vibronic spectra by running clever and careful spectroscopy experiments.\r\nHowever, this can be slow and expensive, in which case it is valuable to predict vibronic spectra\r\nusing theoretical calculations. To model molecular vibronic transitions with GBS, we need only a few\r\nrelevant molecular parameters:\r\n\r\n#. :math:`\\Omega`: diagonal matrix whose entries are the square-roots of the frequencies of the\r\n   normal modes of the electronic *initial* state.\r\n#. :math:`\\Omega\'`: diagonal matrix whose entries are the square-roots of the frequencies of the\r\n   normal modes of the electronic *final* state.\r\n#. :math:`U_\\text{D}`: Duschinsky matrix.\r\n#. :math:`\\delta`: displacement vector.\r\n#. :math:`T`: temperature.\r\n\r\nThe Duschinsky matrix and displacement vector encode information regarding how\r\nvibrational modes are transformed when the molecule changes from the initial to final electronic\r\nstate. At zero temperature, all initial modes are in the vibrational ground state. At finite\r\ntemperature, other vibrational states are also populated.\r\n\r\nIn the GBS algorithm for computing vibronic spectra :cite:`huh2015boson`, these chemical parameters\r\nare sufficient to determine the configuration of a GBS device. As opposed to other applications\r\nthat involve only single-mode squeezing and linear interferometry, in vibronic spectra we\r\nprepare a Gaussian state using two-mode squeezing, linear interferometry, single-mode squeezing,\r\nand displacements.\r\n\r\nThe function :func:`~.gbs_params` of the :mod:`~.apps.vibronic` module can be\r\nused to obtain the squeezing, interferometer, and displacement parameters from the input\r\nchemical parameters listed above. In this page, we study the vibronic spectrum of\r\n`formic acid <https://en.wikipedia.org/wiki/Formic_acid>`_ \xf0\x9f\x90\x9c. Its chemical parameters, obtained\r\nfrom :cite:`huh2015boson`, can be found in the :mod:`~.apps.data` module:\r\n""""""\r\nfrom strawberryfields.apps import vibronic, data\r\nimport numpy as np\r\nformic = data.Formic()\r\nw = formic.w  # ground state frequencies\r\nwp = formic.wp  # excited state frequencies\r\nUd = formic.Ud  # Duschinsky matrix\r\ndelta = formic.delta  # displacement vector\r\nT = 0  # temperature\r\n\r\n##############################################################################\r\n# We can now map this chemical information to GBS parameters using the function\r\n# :func:`~.gbs_params`:\r\n\r\nt, U1, r, U2, alpha = vibronic.gbs_params(w, wp, Ud, delta, T)\r\n\r\n##############################################################################\r\n# Note that since two-mode squeezing operators are involved, if we have :math:`N` vibrational\r\n# modes, the Gaussian state prepared is a :math:`2N`-mode Gaussian state and the samples\r\n# are vectors of length :math:`2N`. The first :math:`N` modes are those of the final electronic\r\n# state; the remaining :math:`N` modes are those of the ground state. From above, :math:`t` is a\r\n# vector of two-mode squeezing parameters, :math:`U_1` and :math:`U_2` are the interferometer\r\n# unitaries (we need two interferometers), :math:`r` is a vector of single-mode squeezing\r\n# parameters, and `alpha` is a vector of displacements.\r\n#\r\n# Photons detected at the output of the GBS device correspond to a specific transition energy.\r\n# The GBS algorithm for vibronic spectra works because the programmed device provides samples\r\n# in such a way that the energies that are sampled with high probability are the peaks of the\r\n# vibronic spectrum. The function :func:`~.energies` can be used to compute the energies for\r\n# a set of samples. In this case we show the energy of the first five samples:\r\n\r\ne = vibronic.energies(formic, w, wp)\r\nprint(np.around(e[:5], 4))  # 4 decimal precision\r\n\r\n##############################################################################\r\n# Once the GBS parameters have been obtained, it is straightforward to run the GBS algorithm: we\r\n# generate many samples, compute their energies, and make a histogram of the observed energies.\r\n# The :mod:`~.apps.sample` module contains the function :func:`~.vibronic`, which is tailored for\r\n# use in vibronic spectra applications. Similarly, the :mod:`~.apps.plot` module includes a\r\n# :func:`~.spectrum` function that generates the vibronic spectrum from the GBS samples. Let\'s see\r\n# how this is done for just a few samples:\r\n\r\nfrom strawberryfields.apps import sample, plot\r\nimport plotly\r\nnr_samples = 10\r\ns = sample.vibronic(t, U1, r, U2, alpha, nr_samples)\r\ne = vibronic.energies(s, w, wp)\r\nspectrum = plot.spectrum(e, xmin=-1000, xmax=8000)\r\nplotly.offline.plot(spectrum, filename=""spectrum.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/spectrum.html\r\n#\r\n# .. note::\r\n#     The command ``plotly.offline.plot()`` is used to display plots in the documentation. In\r\n#     practice, you can simply use ``spectrum.show()`` to generate the figure.\r\n\r\n##############################################################################\r\n# The bars in the plot are the histogram of energies. The curve surrounding them is a Lorentzian\r\n# broadening of the spectrum, which better represents the observations from an actual experiment.\r\n# Of course, 10 samples are not enough to accurately reconstruct the vibronic spectrum. Let\'s\r\n# instead use the 20,000 pre-generated samples from the :mod:`~.apps.data` module.\r\n\r\ne = vibronic.energies(formic, w, wp)\r\nfull_spectrum = plot.spectrum(e, xmin=-1000, xmax=8000)\r\nplotly.offline.plot(full_spectrum, filename=""full_spectrum.html"")\r\n\r\n##############################################################################\r\n# .. raw:: html\r\n#     :file: ../../examples_apps/full_spectrum.html\r\n\r\n##############################################################################\r\n#\r\n# We can compare this prediction with an actual experimental spectrum, obtained from Fig. 3 in\r\n# Ref. :cite:`huh2015boson`, shown below:\r\n\r\n##############################################################################\r\n# .. image:: ../_static/formic_spec.png\r\n#    :width: 740px\r\n\r\n##############################################################################\r\n#\r\n# The agreement is remarkable! Formic acid is a small molecule, which means that its vibronic\r\n# spectrum can be computed using classical computers. However, for larger molecules, this task\r\n# quickly becomes intractable, for much the same reason that simulating GBS cannot be done\r\n# efficiently with classical devices. Photonic quantum computing therefore holds the potential to\r\n# enable new computational capabilities in this area of quantum chemistry \xe2\x9a\x9b\xef\xb8\x8f.\r\n'"
examples_apps/state_learner.py,15,"b'r""""""\nQuantum state learning\n======================\n\nThis demonstration works through the process used to produce the state\npreparation results presented in `""Machine learning method for state\npreparation and gate synthesis on photonic quantum\ncomputers"" <https://arxiv.org/abs/1807.10781>`__.\n\nThis tutorial uses the TensorFlow backend of Strawberry Fields, giving us access\nto a number of\nadditional functionalities including: GPU integration, automatic gradient\ncomputation, built-in optimization algorithms, and other machine\nlearning tools.\n\nVariational quantum circuits\n----------------------------\n\nA key element of machine learning is optimization. We can use\nTensorFlow\'s automatic differentiation tools to optimize the parameters\nof variational quantum circuits constructed using Strawberry Fields. In\nthis approach, we fix a circuit architecture where the states, gates,\nand/or measurements may have learnable parameters :math:`\\vec{\\theta}`\nassociated with them. We then define a loss function based on the output\nstate of this circuit. In this case, we define a loss function such that\nthe fidelity of the output state of the variational circuit is maximized\nwith respect to some target state.\n\n.. note::\n\n    For more details on the TensorFlow backend in Strawberry Fields, please see\n    :ref:`machine_learning_tutorial`.\n\n\nFor arbitrary state preparation using optimization, we need to make use\nof a quantum circuit with a layer structure that is **universal** - that\nis, by \'stacking\' the layers, we can guarantee that we can produce *any*\nCV state with at-most polynomial overhead. Therefore, the architecture\nwe choose must consist of layers with each layer containing\nparameterized Gaussian *and* non-Gaussian gates. **The non-Gaussian\ngates provide both the nonlinearity and the universality of the model.**\nTo this end, we employ the CV quantum neural network architecture as described in\n`Killoran et al. <https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.1.033063>`__:\n\n.. figure:: https://i.imgur.com/NEsaVIX.png\n   :alt: layer\n\nHere,\n\n-  :math:`\\mathcal{U}_i(\\theta_i,\\phi_i)` is an N-mode linear optical\n   interferometer composed of two-mode beamsplitters\n   :math:`BS(\\theta,\\phi)` and single-mode rotation gates\n   :math:`R(\\phi)=e^{i\\phi\\hat{n}}`,\n\n-  :math:`\\mathcal{D}(\\alpha_i)` are single mode displacements in the\n   phase space by complex value :math:`\\alpha_i`,\n\n-  :math:`\\mathcal{S}(r_i, \\phi_i)` are single mode squeezing operations\n   of magnitude :math:`r_i` and phase :math:`\\phi_i`, and\n\n-  :math:`\\Phi(\\lambda_i)` is a single mode non-Gaussian operation, in\n   this case chosen to be the Kerr interaction\n   :math:`\\mathcal{K}(\\kappa_i)=e^{i\\kappa_i\\hat{n}^2}` of strength\n   :math:`\\kappa_i`.\n\n\nHyperparameters\n---------------\n\nFirst, we must define the **hyperparameters** of our layer structure:\n\n-  ``cutoff``: the simulation Fock space truncation we will use in the\n   optimization. The TensorFlow backend will perform numerical\n   operations in this truncated Fock space when performing the\n   optimization.\n\n-  ``depth``: The number of layers in our variational quantum\n   circuit. As a general rule, increasing the number of layers (and\n   thus, the number of parameters we are optimizing over) increases the\n   optimizer\'s chance of finding a reasonable local minimum in the\n   optimization landscape.\n\n-  ``reps``: the number of steps in the optimization routine performing\n   gradient descent\n\nSome other optional hyperparameters include:\n\n-  The standard deviation of initial parameters. Note that we make a\n   distinction between the standard deviation of *passive* parameters\n   (those that preserve photon number when changed, such as phase\n   parameters), and *active* parameters (those that introduce or remove\n   energy from the system when changed).\n""""""\n\nimport numpy as np\n\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\nfrom strawberryfields.utils import operation\n\n# Cutoff dimension\ncutoff = 9\n\n# Number of layers\ndepth = 15\n\n# Number of steps in optimization routine performing gradient descent\nreps = 200\n\n# Learning rate\nlr = 0.05\n\n# Standard deviation of initial parameters\npassive_sd = 0.1\nactive_sd = 0.001\n\n######################################################################\n# The layer parameters :math:`\\vec{\\theta}`\n# -----------------------------------------\n#\n# We use TensorFlow to create the variables corresponding to the gate\n# parameters. Note that we focus on a single mode circuit where\n# each variable has shape ``(depth,)``, with each\n# individual element representing the gate parameter in layer :math:`i`.\n\nimport tensorflow as tf\n\n# set the random seed\ntf.random.set_seed(42)\n\n# squeeze gate\nsq_r = tf.random.normal(shape=[depth], stddev=active_sd)\nsq_phi = tf.random.normal(shape=[depth], stddev=passive_sd)\n\n# displacement gate\nd_r = tf.random.normal(shape=[depth], stddev=active_sd)\nd_phi = tf.random.normal(shape=[depth], stddev=passive_sd)\n\n# rotation gates\nr1 = tf.random.normal(shape=[depth], stddev=passive_sd)\nr2 = tf.random.normal(shape=[depth], stddev=passive_sd)\n\n# kerr gate\nkappa = tf.random.normal(shape=[depth], stddev=active_sd)\n\n\n######################################################################\n# For convenience, we store the TensorFlow variables representing the\n# weights as a tensor:\n\nweights = tf.convert_to_tensor([r1, sq_r, sq_phi, r2, d_r, d_phi, kappa])\nweights = tf.Variable(tf.transpose(weights))\n\n\n######################################################################\n# Since we have a depth of 15 (so 15 layers), and each layer takes\n# 7 different types of parameters, the final shape of our weights\n# array should be :math:`\\text{depth}\\times 7` or ``(15, 7)``:\n\nprint(weights.shape)\n\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     (15, 7)\n\n\n######################################################################\n# Constructing the circuit\n# ------------------------\n#\n# We can now construct the corresponding\n# single-mode Strawberry Fields program:\n\n# Single-mode Strawberry Fields program\nprog = sf.Program(1)\n\n# Create the 7 Strawberry Fields free parameters for each layer\nsf_params = []\nnames = [""r1"", ""sq_r"", ""sq_phi"", ""r2"", ""d_r"", ""d_phi"", ""kappa""]\n\nfor i in range(depth):\n    # For the ith layer, generate parameter names ""r1_i"", ""sq_r_i"", etc.\n    sf_params_names = [""{}_{}"".format(n, i) for n in names]\n    # Create the parameters, and append them to our list ``sf_params``.\n    sf_params.append(prog.params(*sf_params_names))\n\n\n######################################################################\n# ``sf_params`` is now a nested list of shape ``(depth, 7)``, matching\n# the shape of ``weights``.\n\nsf_params = np.array(sf_params)\nprint(sf_params.shape)\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     (15, 7)\n\n######################################################################\n# Now, we can create a function to define the :math:`i`\\ th layer, acting\n# on qumode ``q``. We add the :class:`~.utils.operation` decorator so that the layer can be used\n# as a single operation when constructing our circuit within the usual\n# Strawberry Fields Program context\n\n# layer architecture\n@operation(1)\ndef layer(i, q):\n    Rgate(sf_params[i][0]) | q\n    Sgate(sf_params[i][1], sf_params[i][2]) | q\n    Rgate(sf_params[i][3]) | q\n    Dgate(sf_params[i][4], sf_params[i][5]) | q\n    Kgate(sf_params[i][6]) | q\n    return q\n\n\n######################################################################\n#\n# Now that we have defined our gate parameters and our layer structure, we\n# can construct our variational quantum circuit.\n\n\n# Apply circuit of layers with corresponding depth\nwith prog.context as q:\n    for k in range(depth):\n        layer(k) | q[0]\n\n\n######################################################################\n# Performing the optimization\n# ---------------------------\n#\n# :math:`\\newcommand{ket}[1]{\\left|#1\\right\\rangle}` With the Strawberry\n# Fields TensorFlow backend calculating the resulting state of the circuit\n# symbolically, we can use TensorFlow to optimize the gate parameters to\n# minimize the cost function we specify. With state learning, the measure\n# of distance between two quantum states is given by the fidelity of the\n# output state :math:`\\ket{\\psi}` with some target state\n# :math:`\\ket{\\psi_t}`. This is defined as the overlap between the two\n# states:\n#\n# .. math::  F = \\left|\\left\\langle{\\psi}\\mid{\\psi_t}\\right\\rangle\\right|^2\n#\n# where the output state can be written\n# :math:`\\ket{\\psi}=U(\\vec{\\theta})\\ket{\\psi_0}`, with\n# :math:`U(\\vec{\\theta})` the unitary operation applied by the variational\n# quantum circuit, and :math:`\\ket{\\psi_0}=\\ket{0}` the initial state.\n#\n# Let\'s first instantiate the TensorFlow backend, making sure to pass\n# the Fock basis truncation cutoff.\n\neng = sf.Engine(""tf"", backend_options={""cutoff_dim"": cutoff})\n\n######################################################################\n# Now let\'s define the target state as the single photon state\n# :math:`\\ket{\\psi_t}=\\ket{1}`:\n\nimport numpy as np\n\ntarget_state = np.zeros([cutoff])\ntarget_state[1] = 1\nprint(target_state)\n\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n\n######################################################################\n# Using this target state, we calculate the fidelity with the state\n# exiting the variational circuit. We must use TensorFlow functions to\n# manipulate this data, as well as a ``GradientTape`` to keep track of the\n# corresponding gradients!\n#\n# We choose the following cost function:\n#\n# .. math:: C(\\vec{\\theta}) = \\left| \\langle \\psi_t \\mid U(\\vec{\\theta})\\mid 0\\rangle - 1\\right|\n#\n# By minimizing this cost function, the variational quantum circuit will\n# prepare a state with high fidelity to the target state.\n\n\ndef cost(weights):\n    # Create a dictionary mapping from the names of the Strawberry Fields\n    # free parameters to the TensorFlow weight values.\n    mapping = {p.name: w for p, w in zip(sf_params.flatten(), tf.reshape(weights, [-1]))}\n\n    # Run engine\n    state = eng.run(prog, args=mapping).state\n\n    # Extract the statevector\n    ket = state.ket()\n\n    # Compute the fidelity between the output statevector\n    # and the target state.\n    fidelity = tf.abs(tf.reduce_sum(tf.math.conj(ket) * target_state)) ** 2\n\n    # Objective function to minimize\n    cost = tf.abs(tf.reduce_sum(tf.math.conj(ket) * target_state) - 1)\n    return cost, fidelity, ket\n\n\n#######################################################################\n# Now that the cost function is defined, we can define and run the\n# optimization. Below, we choose the Adam\n# optimizer that is built into TensorFlow:\n\nopt = tf.keras.optimizers.Adam(learning_rate=lr)\n\n######################################################################\n# We then loop over all repetitions, storing the best predicted fidelity\n# value.\n\nfid_progress = []\nbest_fid = 0\n\nfor i in range(reps):\n    # reset the engine if it has already been executed\n    if eng.run_progs:\n        eng.reset()\n\n    with tf.GradientTape() as tape:\n        loss, fid, ket = cost(weights)\n\n    # Stores fidelity at each step\n    fid_progress.append(fid.numpy())\n\n    if fid > best_fid:\n        # store the new best fidelity and best state\n        best_fid = fid.numpy()\n        learnt_state = ket.numpy()\n\n    # one repetition of the optimization\n    gradients = tape.gradient(loss, weights)\n    opt.apply_gradients(zip([gradients], [weights]))\n\n    # Prints progress at every rep\n    if i % 1 == 0:\n        print(""Rep: {} Cost: {:.4f} Fidelity: {:.4f}"".format(i, loss, fid))\n\n######################################################################\n# .. rst-class:: sphx-glr-script-out\n#\n#  Out:\n#\n#  .. code-block:: none\n#\n#     Rep: 0 Cost: 0.9973 Fidelity: 0.0000\n#     Rep: 1 Cost: 0.3459 Fidelity: 0.4297\n#     Rep: 2 Cost: 0.5866 Fidelity: 0.2695\n#     Rep: 3 Cost: 0.4118 Fidelity: 0.4013\n#     Rep: 4 Cost: 0.5630 Fidelity: 0.1953\n#     Rep: 5 Cost: 0.4099 Fidelity: 0.4548\n#     Rep: 6 Cost: 0.2258 Fidelity: 0.6989\n#     Rep: 7 Cost: 0.3994 Fidelity: 0.5251\n#     Rep: 8 Cost: 0.1787 Fidelity: 0.7421\n#     Rep: 9 Cost: 0.3777 Fidelity: 0.5672\n#     Rep: 10 Cost: 0.2201 Fidelity: 0.6140\n#     Rep: 11 Cost: 0.3580 Fidelity: 0.6169\n#     Rep: 12 Cost: 0.3944 Fidelity: 0.5549\n#     Rep: 13 Cost: 0.3197 Fidelity: 0.5456\n#     Rep: 14 Cost: 0.1766 Fidelity: 0.6878\n#     Rep: 15 Cost: 0.1305 Fidelity: 0.7586\n#     Rep: 16 Cost: 0.1304 Fidelity: 0.7598\n#     Rep: 17 Cost: 0.1256 Fidelity: 0.7899\n#     Rep: 18 Cost: 0.2366 Fidelity: 0.8744\n#     Rep: 19 Cost: 0.1744 Fidelity: 0.7789\n#     Rep: 20 Cost: 0.1093 Fidelity: 0.7965\n#     Rep: 21 Cost: 0.1846 Fidelity: 0.8335\n#     Rep: 22 Cost: 0.0876 Fidelity: 0.8396\n#     Rep: 23 Cost: 0.0985 Fidelity: 0.8630\n#     Rep: 24 Cost: 0.1787 Fidelity: 0.9070\n#     Rep: 25 Cost: 0.0620 Fidelity: 0.9116\n#     Rep: 26 Cost: 0.2743 Fidelity: 0.8738\n#     Rep: 27 Cost: 0.2477 Fidelity: 0.8895\n#     Rep: 28 Cost: 0.0815 Fidelity: 0.8494\n#     Rep: 29 Cost: 0.1855 Fidelity: 0.8072\n#     Rep: 30 Cost: 0.1315 Fidelity: 0.8200\n#     Rep: 31 Cost: 0.1403 Fidelity: 0.8799\n#     Rep: 32 Cost: 0.1530 Fidelity: 0.8853\n#     Rep: 33 Cost: 0.0718 Fidelity: 0.8679\n#     Rep: 34 Cost: 0.1112 Fidelity: 0.8838\n#     Rep: 35 Cost: 0.0394 Fidelity: 0.9237\n#     Rep: 36 Cost: 0.0781 Fidelity: 0.9487\n#     Rep: 37 Cost: 0.0619 Fidelity: 0.9613\n#     Rep: 38 Cost: 0.0291 Fidelity: 0.9607\n#     Rep: 39 Cost: 0.0669 Fidelity: 0.9595\n#     Rep: 40 Cost: 0.0685 Fidelity: 0.9458\n#     Rep: 41 Cost: 0.0317 Fidelity: 0.9466\n#     Rep: 42 Cost: 0.0308 Fidelity: 0.9484\n#     Rep: 43 Cost: 0.0729 Fidelity: 0.9612\n#     Rep: 44 Cost: 0.0581 Fidelity: 0.9658\n#     Rep: 45 Cost: 0.0272 Fidelity: 0.9766\n#     Rep: 46 Cost: 0.0818 Fidelity: 0.9760\n#     Rep: 47 Cost: 0.0123 Fidelity: 0.9828\n#     Rep: 48 Cost: 0.0431 Fidelity: 0.9826\n#     Rep: 49 Cost: 0.0866 Fidelity: 0.9775\n#     Rep: 50 Cost: 0.0245 Fidelity: 0.9779\n#     Rep: 51 Cost: 0.1784 Fidelity: 0.9657\n#     Rep: 52 Cost: 0.2022 Fidelity: 0.9552\n#     Rep: 53 Cost: 0.0907 Fidelity: 0.9511\n#     Rep: 54 Cost: 0.1477 Fidelity: 0.9100\n#     Rep: 55 Cost: 0.2128 Fidelity: 0.8746\n#     Rep: 56 Cost: 0.1493 Fidelity: 0.8677\n#     Rep: 57 Cost: 0.0704 Fidelity: 0.8736\n#     Rep: 58 Cost: 0.1368 Fidelity: 0.8962\n#     Rep: 59 Cost: 0.1268 Fidelity: 0.9239\n#     Rep: 60 Cost: 0.0222 Fidelity: 0.9566\n#     Rep: 61 Cost: 0.1432 Fidelity: 0.9641\n#     Rep: 62 Cost: 0.1233 Fidelity: 0.9619\n#     Rep: 63 Cost: 0.0487 Fidelity: 0.9633\n#     Rep: 64 Cost: 0.0689 Fidelity: 0.9604\n#     Rep: 65 Cost: 0.0488 Fidelity: 0.9584\n#     Rep: 66 Cost: 0.0248 Fidelity: 0.9618\n#     Rep: 67 Cost: 0.0967 Fidelity: 0.9660\n#     Rep: 68 Cost: 0.0678 Fidelity: 0.9731\n#     Rep: 69 Cost: 0.0859 Fidelity: 0.9768\n#     Rep: 70 Cost: 0.0904 Fidelity: 0.9787\n#     Rep: 71 Cost: 0.0312 Fidelity: 0.9789\n#     Rep: 72 Cost: 0.0258 Fidelity: 0.9757\n#     Rep: 73 Cost: 0.0826 Fidelity: 0.9704\n#     Rep: 74 Cost: 0.0661 Fidelity: 0.9667\n#     Rep: 75 Cost: 0.0554 Fidelity: 0.9651\n#     Rep: 76 Cost: 0.0626 Fidelity: 0.9602\n#     Rep: 77 Cost: 0.0358 Fidelity: 0.9513\n#     Rep: 78 Cost: 0.0366 Fidelity: 0.9570\n#     Rep: 79 Cost: 0.0524 Fidelity: 0.9734\n#     Rep: 80 Cost: 0.0279 Fidelity: 0.9798\n#     Rep: 81 Cost: 0.0962 Fidelity: 0.9768\n#     Rep: 82 Cost: 0.0980 Fidelity: 0.9802\n#     Rep: 83 Cost: 0.0127 Fidelity: 0.9884\n#     Rep: 84 Cost: 0.0134 Fidelity: 0.9893\n#     Rep: 85 Cost: 0.0874 Fidelity: 0.9864\n#     Rep: 86 Cost: 0.0666 Fidelity: 0.9883\n#     Rep: 87 Cost: 0.0601 Fidelity: 0.9885\n#     Rep: 88 Cost: 0.0661 Fidelity: 0.9859\n#     Rep: 89 Cost: 0.0317 Fidelity: 0.9830\n#     Rep: 90 Cost: 0.0222 Fidelity: 0.9796\n#     Rep: 91 Cost: 0.0763 Fidelity: 0.9769\n#     Rep: 92 Cost: 0.0665 Fidelity: 0.9742\n#     Rep: 93 Cost: 0.0377 Fidelity: 0.9702\n#     Rep: 94 Cost: 0.0428 Fidelity: 0.9685\n#     Rep: 95 Cost: 0.0415 Fidelity: 0.9703\n#     Rep: 96 Cost: 0.0291 Fidelity: 0.9729\n#     Rep: 97 Cost: 0.0673 Fidelity: 0.9749\n#     Rep: 98 Cost: 0.0606 Fidelity: 0.9775\n#     Rep: 99 Cost: 0.0385 Fidelity: 0.9815\n#     Rep: 100 Cost: 0.0360 Fidelity: 0.9827\n#     Rep: 101 Cost: 0.0580 Fidelity: 0.9801\n#     Rep: 102 Cost: 0.0494 Fidelity: 0.9804\n#     Rep: 103 Cost: 0.0504 Fidelity: 0.9832\n#     Rep: 104 Cost: 0.0482 Fidelity: 0.9822\n#     Rep: 105 Cost: 0.0444 Fidelity: 0.9772\n#     Rep: 106 Cost: 0.0391 Fidelity: 0.9761\n#     Rep: 107 Cost: 0.0526 Fidelity: 0.9784\n#     Rep: 108 Cost: 0.0471 Fidelity: 0.9771\n#     Rep: 109 Cost: 0.0444 Fidelity: 0.9726\n#     Rep: 110 Cost: 0.0421 Fidelity: 0.9725\n#     Rep: 111 Cost: 0.0441 Fidelity: 0.9755\n#     Rep: 112 Cost: 0.0373 Fidelity: 0.9763\n#     Rep: 113 Cost: 0.0525 Fidelity: 0.9757\n#     Rep: 114 Cost: 0.0477 Fidelity: 0.9771\n#     Rep: 115 Cost: 0.0422 Fidelity: 0.9794\n#     Rep: 116 Cost: 0.0381 Fidelity: 0.9802\n#     Rep: 117 Cost: 0.0503 Fidelity: 0.9797\n#     Rep: 118 Cost: 0.0440 Fidelity: 0.9801\n#     Rep: 119 Cost: 0.0470 Fidelity: 0.9811\n#     Rep: 120 Cost: 0.0438 Fidelity: 0.9809\n#     Rep: 121 Cost: 0.0436 Fidelity: 0.9789\n#     Rep: 122 Cost: 0.0386 Fidelity: 0.9785\n#     Rep: 123 Cost: 0.0489 Fidelity: 0.9797\n#     Rep: 124 Cost: 0.0441 Fidelity: 0.9793\n#     Rep: 125 Cost: 0.0430 Fidelity: 0.9768\n#     Rep: 126 Cost: 0.0396 Fidelity: 0.9767\n#     Rep: 127 Cost: 0.0449 Fidelity: 0.9789\n#     Rep: 128 Cost: 0.0391 Fidelity: 0.9793\n#     Rep: 129 Cost: 0.0474 Fidelity: 0.9774\n#     Rep: 130 Cost: 0.0434 Fidelity: 0.9778\n#     Rep: 131 Cost: 0.0418 Fidelity: 0.9802\n#     Rep: 132 Cost: 0.0374 Fidelity: 0.9804\n#     Rep: 133 Cost: 0.0475 Fidelity: 0.9785\n#     Rep: 134 Cost: 0.0423 Fidelity: 0.9789\n#     Rep: 135 Cost: 0.0435 Fidelity: 0.9808\n#     Rep: 136 Cost: 0.0399 Fidelity: 0.9806\n#     Rep: 137 Cost: 0.0438 Fidelity: 0.9784\n#     Rep: 138 Cost: 0.0390 Fidelity: 0.9784\n#     Rep: 139 Cost: 0.0452 Fidelity: 0.9802\n#     Rep: 140 Cost: 0.0408 Fidelity: 0.9800\n#     Rep: 141 Cost: 0.0428 Fidelity: 0.9780\n#     Rep: 142 Cost: 0.0389 Fidelity: 0.9781\n#     Rep: 143 Cost: 0.0436 Fidelity: 0.9800\n#     Rep: 144 Cost: 0.0386 Fidelity: 0.9802\n#     Rep: 145 Cost: 0.0448 Fidelity: 0.9785\n#     Rep: 146 Cost: 0.0408 Fidelity: 0.9788\n#     Rep: 147 Cost: 0.0417 Fidelity: 0.9807\n#     Rep: 148 Cost: 0.0373 Fidelity: 0.9808\n#     Rep: 149 Cost: 0.0452 Fidelity: 0.9791\n#     Rep: 150 Cost: 0.0406 Fidelity: 0.9793\n#     Rep: 151 Cost: 0.0421 Fidelity: 0.9810\n#     Rep: 152 Cost: 0.0381 Fidelity: 0.9810\n#     Rep: 153 Cost: 0.0436 Fidelity: 0.9791\n#     Rep: 154 Cost: 0.0391 Fidelity: 0.9793\n#     Rep: 155 Cost: 0.0429 Fidelity: 0.9810\n#     Rep: 156 Cost: 0.0386 Fidelity: 0.9809\n#     Rep: 157 Cost: 0.0429 Fidelity: 0.9792\n#     Rep: 158 Cost: 0.0387 Fidelity: 0.9794\n#     Rep: 159 Cost: 0.0423 Fidelity: 0.9810\n#     Rep: 160 Cost: 0.0378 Fidelity: 0.9811\n#     Rep: 161 Cost: 0.0435 Fidelity: 0.9795\n#     Rep: 162 Cost: 0.0394 Fidelity: 0.9797\n#     Rep: 163 Cost: 0.0413 Fidelity: 0.9813\n#     Rep: 164 Cost: 0.0370 Fidelity: 0.9814\n#     Rep: 165 Cost: 0.0438 Fidelity: 0.9798\n#     Rep: 166 Cost: 0.0394 Fidelity: 0.9800\n#     Rep: 167 Cost: 0.0412 Fidelity: 0.9815\n#     Rep: 168 Cost: 0.0371 Fidelity: 0.9814\n#     Rep: 169 Cost: 0.0430 Fidelity: 0.9799\n#     Rep: 170 Cost: 0.0386 Fidelity: 0.9801\n#     Rep: 171 Cost: 0.0417 Fidelity: 0.9815\n#     Rep: 172 Cost: 0.0376 Fidelity: 0.9815\n#     Rep: 173 Cost: 0.0422 Fidelity: 0.9801\n#     Rep: 174 Cost: 0.0380 Fidelity: 0.9803\n#     Rep: 175 Cost: 0.0417 Fidelity: 0.9816\n#     Rep: 176 Cost: 0.0375 Fidelity: 0.9816\n#     Rep: 177 Cost: 0.0421 Fidelity: 0.9804\n#     Rep: 178 Cost: 0.0380 Fidelity: 0.9806\n#     Rep: 179 Cost: 0.0414 Fidelity: 0.9817\n#     Rep: 180 Cost: 0.0371 Fidelity: 0.9818\n#     Rep: 181 Cost: 0.0421 Fidelity: 0.9807\n#     Rep: 182 Cost: 0.0379 Fidelity: 0.9809\n#     Rep: 183 Cost: 0.0412 Fidelity: 0.9818\n#     Rep: 184 Cost: 0.0371 Fidelity: 0.9818\n#     Rep: 185 Cost: 0.0417 Fidelity: 0.9808\n#     Rep: 186 Cost: 0.0375 Fidelity: 0.9810\n#     Rep: 187 Cost: 0.0413 Fidelity: 0.9819\n#     Rep: 188 Cost: 0.0372 Fidelity: 0.9819\n#     Rep: 189 Cost: 0.0413 Fidelity: 0.9810\n#     Rep: 190 Cost: 0.0371 Fidelity: 0.9812\n#     Rep: 191 Cost: 0.0414 Fidelity: 0.9820\n#     Rep: 192 Cost: 0.0373 Fidelity: 0.9820\n#     Rep: 193 Cost: 0.0410 Fidelity: 0.9813\n#     Rep: 194 Cost: 0.0368 Fidelity: 0.9815\n#     Rep: 195 Cost: 0.0413 Fidelity: 0.9821\n#     Rep: 196 Cost: 0.0372 Fidelity: 0.9821\n#     Rep: 197 Cost: 0.0408 Fidelity: 0.9815\n#     Rep: 198 Cost: 0.0367 Fidelity: 0.9817\n#     Rep: 199 Cost: 0.0412 Fidelity: 0.9821\n\n\n\n######################################################################\n# Results and visualisation\n# -------------------------\n#\n# Plotting the fidelity vs.\xc2\xa0optimization step:\n\nfrom matplotlib import pyplot as plt\n\nplt.rcParams[""font.family""] = ""serif""\nplt.rcParams[""font.sans-serif""] = [""Computer Modern Roman""]\nplt.style.use(""default"")\n\nplt.plot(fid_progress)\nplt.ylabel(""Fidelity"")\nplt.xlabel(""Step"")\n\n######################################################################\n# .. image:: /_static/images/sphx_glr_run_state_learner_001.png\n#     :class: sphx-glr-single-img\n\n######################################################################\n# We can use the following function to plot the Wigner function of our\n# target and learnt state:\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\ndef wigner(rho):\n    """"""This code is a modified version of the \'iterative\' method\n    of the wigner function provided in QuTiP, which is released\n    under the BSD license, with the following copyright notice:\n\n    Copyright (C) 2011 and later, P.D. Nation, J.R. Johansson,\n    A.J.G. Pitchford, C. Granade, and A.L. Grimsmo.\n\n    All rights reserved.""""""\n    import copy\n\n    # Domain parameter for Wigner function plots\n    l = 5.0\n    cutoff = rho.shape[0]\n\n    # Creates 2D grid for Wigner function plots\n    x = np.linspace(-l, l, 100)\n    p = np.linspace(-l, l, 100)\n\n    Q, P = np.meshgrid(x, p)\n    A = (Q + P * 1.0j) / (2 * np.sqrt(2 / 2))\n\n    Wlist = np.array([np.zeros(np.shape(A), dtype=complex) for k in range(cutoff)])\n\n    # Wigner function for |0><0|\n    Wlist[0] = np.exp(-2.0 * np.abs(A) ** 2) / np.pi\n\n    # W = rho(0,0)W(|0><0|)\n    W = np.real(rho[0, 0]) * np.real(Wlist[0])\n\n    for n in range(1, cutoff):\n        Wlist[n] = (2.0 * A * Wlist[n - 1]) / np.sqrt(n)\n        W += 2 * np.real(rho[0, n] * Wlist[n])\n\n    for m in range(1, cutoff):\n        temp = copy.copy(Wlist[m])\n        # Wlist[m] = Wigner function for |m><m|\n        Wlist[m] = (2 * np.conj(A) * temp - np.sqrt(m) * Wlist[m - 1]) / np.sqrt(m)\n\n        # W += rho(m,m)W(|m><m|)\n        W += np.real(rho[m, m] * Wlist[m])\n\n        for n in range(m + 1, cutoff):\n            temp2 = (2 * A * Wlist[n - 1] - np.sqrt(m) * temp) / np.sqrt(n)\n            temp = copy.copy(Wlist[n])\n            # Wlist[n] = Wigner function for |m><n|\n            Wlist[n] = temp2\n\n            # W += rho(m,n)W(|m><n|) + rho(n,m)W(|n><m|)\n            W += 2 * np.real(rho[m, n] * Wlist[n])\n\n    return Q, P, W / 2\n\n\n######################################################################\n# Computing the density matrices\n# :math:`\\rho = \\left|\\psi\\right\\rangle \\left\\langle\\psi\\right|` of the\n# target and learnt state,\n\nrho_target = np.outer(target_state, target_state.conj())\nrho_learnt = np.outer(learnt_state, learnt_state.conj())\n\n\n######################################################################\n# Plotting the Wigner function of the target state:\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection=""3d"")\nX, P, W = wigner(rho_target)\nax.plot_surface(X, P, W, cmap=""RdYlGn"", lw=0.5, rstride=1, cstride=1)\nax.contour(X, P, W, 10, cmap=""RdYlGn"", linestyles=""solid"", offset=-0.17)\nax.set_axis_off()\nfig.show()\n\n######################################################################\n# .. image:: /_static/images/sphx_glr_run_state_learner_002.png\n#     :class: sphx-glr-single-img\n\n######################################################################\n# Plotting the Wigner function of the learnt state:\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection=""3d"")\nX, P, W = wigner(rho_learnt)\nax.plot_surface(X, P, W, cmap=""RdYlGn"", lw=0.5, rstride=1, cstride=1)\nax.contour(X, P, W, 10, cmap=""RdYlGn"", linestyles=""solid"", offset=-0.17)\nax.set_axis_off()\nfig.show()\n\n######################################################################\n# .. image:: /_static/images/sphx_glr_run_state_learner_003.png\n#     :class: sphx-glr-single-img\n\n\n######################################################################\n# References\n# ----------\n#\n# 1. Juan Miguel Arrazola, Thomas R. Bromley, Josh Izaac, Casey R. Myers,\n#    Kamil Br\xc3\xa1dler, and Nathan Killoran. Machine learning method for state\n#    preparation and gate synthesis on photonic quantum computers. `Quantum\n#    Science and Technology, 4\n#    024004 <https://iopscience.iop.org/article/10.1088/2058-9565/aaf59e>`__,\n#    (2019).\n#\n# 2. Nathan Killoran, Thomas R. Bromley, Juan Miguel Arrazola, Maria Schuld,\n#    Nicolas Quesada, and Seth Lloyd. Continuous-variable quantum neural networks.\n#    `Physical Review Research, 1(3), 033063.\n#    <https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.1.033063>`__,\n#    (2019).\n'"
strawberryfields/__init__.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThe Strawberry Fields codebase includes a number of complementary components.\nThese can be separated into frontend components, applications layer,\nand backend components (all found within the :mod:`strawberryfields.backends` submodule).\n\n.. image:: ../_static/sfcomponents.svg\n    :align: center\n    :width: 90%\n    :target: javascript:void(0);\n""""""\nfrom . import apps\nfrom ._version import __version__\nfrom .cli import ping\nfrom .configuration import store_account, active_configs, reset_config, delete_config\nfrom .engine import Engine, LocalEngine, RemoteEngine\nfrom .io import load, save\nfrom .parameters import par_funcs as math\nfrom .program import Program\n\n__all__ = [\n    ""Engine"",\n    ""RemoteEngine"",\n    ""Program"",\n    ""version"",\n    ""save"",\n    ""load"",\n    ""about"",\n    ""cite"",\n    ""ping"",\n    ""store_account"",\n    ""active_configs"",\n    ""reset_config"",\n    ""delete_config"",\n]\n\n\n#: float: numerical value of hbar for the frontend (in the implicit units of position * momentum)\nhbar = 2\n\n\ndef version():\n    r""""""\n    Version number of Strawberry Fields.\n\n    Returns:\n      str: package version number\n    """"""\n    return __version__\n\n\ndef about():\n    """"""Strawberry Fields information.\n\n    Prints the installed version numbers for SF and its dependencies,\n    and some system info. Please include this information in bug reports.\n\n    **Example:**\n\n    .. code-block:: pycon\n\n        >>> sf.about()\n        Strawberry Fields: a Python library for continuous-variable quantum circuits.\n        Copyright 2018-2020 Xanadu Quantum Technologies Inc.\n\n        Python version:            3.6.8\n        Platform info:             Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid\n        Installation path:         /home/josh/Dropbox/Work/Xanadu/sf_cloud/strawberryfields\n        Strawberry Fields version: 0.12.0-dev\n        Numpy version:             1.17.4\n        Scipy version:             1.3.0\n        Sympy version:             1.5\n        NetworkX version:          2.4\n        The Walrus version:        0.10.0\n        Blackbird version:         0.2.1\n        TensorFlow version:        2.0.0\n    """"""\n    # pylint: disable=import-outside-toplevel\n    import sys\n    import platform\n    import os\n    import numpy\n    import scipy\n    import sympy\n    import networkx\n    import thewalrus\n    import blackbird\n\n    # a QuTiP-style infobox\n    print(""\\nStrawberry Fields: a Python library for continuous-variable quantum circuits."")\n    print(""Copyright 2018-2020 Xanadu Quantum Technologies Inc.\\n"")\n\n    print(""Python version:            {}.{}.{}"".format(*sys.version_info[0:3]))\n    print(""Platform info:             {}"".format(platform.platform()))\n    print(""Installation path:         {}"".format(os.path.dirname(__file__)))\n    print(""Strawberry Fields version: {}"".format(__version__))\n    print(""Numpy version:             {}"".format(numpy.__version__))\n    print(""Scipy version:             {}"".format(scipy.__version__))\n    print(""SymPy version:             {}"".format(sympy.__version__))\n    print(""NetworkX version:          {}"".format(networkx.__version__))\n    print(""The Walrus version:        {}"".format(thewalrus.__version__))\n    print(""Blackbird version:         {}"".format(blackbird.__version__))\n\n    try:\n        import tensorflow\n\n        tf_version = tensorflow.__version__\n    except ImportError:\n        tf_version = None\n\n    print(""TensorFlow version:        {}"".format(tf_version))\n\n\ndef cite():\n    """"""Prints the BibTeX citation for Strawberry Fields.\n\n    **Example:**\n\n    .. code-block:: pycon\n\n        >>> sf.cite()\n        @article{strawberryfields,\n            title = {{S}trawberry {F}ields: A Software Platform for Photonic Quantum Computing},\n            author = {Killoran, Nathan and Izaac, Josh and Quesada, Nicol{\'{a}}s and Bergholm, Ville and Amy, Matthew and Weedbrook, Christian},\n            journal = {Quantum},\n            volume = {3},\n            pages = {129},\n            year = {2019},\n            doi = {10.22331/q-2019-03-11-129},\n            archivePrefix = {arXiv},\n            eprint = {1804.03159},\n        }\n    """"""\n    citation = """"""@article{strawberryfields,\n    title = {{S}trawberry {F}ields: A Software Platform for Photonic Quantum Computing},\n    author = {Killoran, Nathan and Izaac, Josh and Quesada, Nicol{\\\'{a}}s and Bergholm, Ville and Amy, Matthew and Weedbrook, Christian},\n    journal = {Quantum},\n    volume = {3},\n    pages = {129},\n    year = {2019},\n    doi = {10.22331/q-2019-03-11-129},\n    archivePrefix = {arXiv},\n    eprint = {1804.03159},\n}""""""\n    print(citation)\n'"
strawberryfields/_version.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Version information.\n   Version number (major.minor.patch[-label])\n""""""\n\n__version__ = ""0.15.0-dev0""\n'"
strawberryfields/circuitdrawer.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nA Strawberry Fields module that provides an object-oriented interface for building\nquantum circuit representations of continuous-variable circuits using the\n:math:`\\LaTeX` `Qcircuit package <https://ctan.org/pkg/qcircuit>`_.\n""""""\nimport datetime\nimport os\n\n# string constants used by :class:`~strawberryfields.circuitdrawer.Circuit`\n# to transform Strawberry Fields operators to latex code.\n\nDOCUMENT_CLASS = r""\\documentclass{article}""\nEMPTY_PAGESTYLE = r""\\pagestyle{empty}""\nQCIRCUIT_PACKAGE = r""\\usepackage{qcircuit}""\nBEGIN_DOCUMENT = r""\\begin{document}""\nDOCUMENT_END = r""\\end{document}""\nCIRCUIT_START = r""\\Qcircuit""\nCOLUMN_SPACING = ""@C={0}""  # spacing i.e. ""1em""\nROW_SPACING = ""@R={0}""  # spacing\nUNIFORM_ROW_SPACING = ""@!R""\nUNIFORM_COLUMN_SPACING = ""@!C""\nUNIFORM_ELEMENT_SPACING = ""@!""\nQUANTUM_WIRE = r""\\qw""\nMULTI_QUANTUM_WIRE = r""\\qw[{0}]""  # length vector i.e. ""-1""\nVERTICAL_QUANTUM_WIRE = r""\\qwx[{0}]""  # length vector\nWIRE_END = r""\\qwa[{0}]""  # length vector\nCLASSICAL_WIRE = r""\\cw[{0}]""  # length vector\nCLASSICAL_WIRE_END = r""\\cwa[{0}]""  # length vector\nVERTICAL_CLASSICAL_WIRE = r""\\cwx[{0}]""  # length vector\nLABELLED_GATE = r""\\gate{{{0}}}""  # label i.e. ""X""\nTARGET = r""\\targ""\nSWAP = r""\\qswap""\nMULTIGATE = r""\\multigate{{{0}}}{{{1}}}""  # depth i.e. ""2"", label\nNON_ADJACENT_MULTIGATE = r""\\sgate{{{0}}}{{{1}}}""  # gate i.e. ""X"", second wire vector i.e. ""1""\nGHOST = r""\\ghost{{{0}}}""  # gate\nCLASSICAL_GHOST = r""\\cghost{{{0}}}""  # gate\nNO_GHOST = r""\\nghost{{{0}}}""  # gate\nCONTROL = r""\\ctrl{{{0}}}""  # length vector\nCONTROL_ON_ZERO = r""\\ctrlo{{{0}}}""  # length vector\nCLASSICAL_CONTROL = r""\\cctrl{{{0}}}""  # length vector\nCLASSICAL_CONTROL_ON_ZERO = r""\\cctrlo{{{0}}}""  # length vector\nISOLATED_CONTROL = r""\\control""\nISOLATED_CONTROL_ON_ZERO = r""\\controlo""\nMETER = r""\\meter""\nBASIS_METER = r""\\meterB{{{0}}}""  # basis i.e. \\ket{\\xi_\\pm}\nSPLIT_BASIS_METER = r""\\smeterB{{{0}}}{{{1}}}""  # basis, second wire vector\nMEASURE = r""\\measuretab{{{0}}}""  # label\nMULTIMEASURE = r""\\multimeasure{{{0}}}{{{1}}}""  # depth, label\nLEFT_WIRE_LABEL = r""\\lstick{{{0}}}""  # label\nRIGHT_WIRE_LABEL = r""\\rstick{{{0}}}""  # label\nBRA = r""\\bra{{{0}}}""  # state i.e. ""\\psi""\nKET = r""\\ket{{{0}}}""  # state\n\nHADAMARD_COMP = LABELLED_GATE.format(""H"")\nPAULI_X_COMP = LABELLED_GATE.format(""X"")\nPAULI_Y_COMP = LABELLED_GATE.format(""Y"")\nPAULI_Z_COMP = LABELLED_GATE.format(""Z"")\nD_COMP = LABELLED_GATE.format(""D"")\nS_COMP = LABELLED_GATE.format(""S"")\nR_COMP = LABELLED_GATE.format(""R"")\nP_COMP = LABELLED_GATE.format(""P"")\nV_COMP = LABELLED_GATE.format(""V"")\nK_COMP = LABELLED_GATE.format(""K"")\nFOURIER_COMP = LABELLED_GATE.format(""F"")\n\nBS_MULTI_COMP = ""BS""\nS_MULTI_COMP = ""S""\n\nWIRE_OPERATION = ""& {0}""\nWIRE_TERMINATOR = r""\\\\"" + ""\\n""\nCIRCUIT_BODY_TERMINATOR = ""}\\n""\nCIRCUIT_BODY_START = "" {"" + ""\\n""\nINIT_DOCUMENT = (\n    DOCUMENT_CLASS\n    + ""\\n""\n    + EMPTY_PAGESTYLE\n    + ""\\n""\n    + QCIRCUIT_PACKAGE\n    + ""\\n""\n    + BEGIN_DOCUMENT\n    + ""\\n""\n    + CIRCUIT_START\n)\n\nPIPE = ""|""\nLINE_RETURN = ""\\n""\n\n\nclass NotDrawableException(Exception):\n    """"""Exception raised when a circuit is not drawable.\n\n    This class corresponds to the exception raised by :meth:`~.parse_op`\n    when a circuit is deemed impossible to effectively render using qcircuit.\n    """"""\n\n    pass\n\n\nclass ModeMismatchException(Exception):\n    """"""Exception raised when parsing a Gate object.\n\n    This class corresponds to the exception raised by :meth:`~.parse_op`\n    when an operator is interpreted as an n-mode gate but is applied to a number of modes != n.\n    """"""\n\n    pass\n\n\nclass UnsupportedGateException(Exception):\n    """"""Exception raised when attempting to add an unsupported operator.\n\n    This class corresponds to the exception raised by :meth:`~.parse_op` when it is attempted to add an\n    unsupported operator to the circuit.\n    """"""\n\n    pass\n\n\nclass Circuit:\n    """"""Represents a quantum circuit that can be compiled to tex format.\n\n    Args:\n        wires (int): the number of quantum wires or subsystems to use in the\n            circuit diagram.\n    """"""\n\n    _circuit_matrix = []\n\n    def __init__(self, wires):\n        self._document = """"\n        self._circuit_matrix = [[QUANTUM_WIRE.format(1)] for wire in range(wires)]\n        self._column_spacing = None\n        self._row_spacing = None\n\n        self.single_mode_gates = {\n            ""Xgate"": self._x,\n            ""Zgate"": self._z,\n            ""Dgate"": self._d,\n            ""Sgate"": self._s,\n            ""Rgate"": self._r,\n            ""Pgate"": self._p,\n            ""Vgate"": self._v,\n            ""Kgate"": self._k,\n            ""Fourier"": self._fourier,\n        }\n\n        self.two_mode_gates = {\n            ""CXgate"": self._cx,\n            ""CZgate"": self._cz,\n            ""CKgate"": self._ck,\n            ""BSgate"": self._bs,\n            ""S2gate"": self._s2,\n        }\n\n    def _gate_from_operator(self, op):\n        """"""Infers the number of modes and callable Circuit class method that correspond\n        with a Strawberry Fields operator object.\n\n        Args:\n            op (strawberryfields.ops.Gate): the Strawberry Fields operator object.\n\n        Returns:\n            method (function): callable method that adds the given operator to the latex circuit.\n            mode (int): the number of modes affected by the operator gate.\n        """"""\n        operator = str(op).split(PIPE)[0]\n        method = None\n        mode = None\n\n        for two_mode_gate in self.two_mode_gates:\n            if two_mode_gate in operator:\n                method = self.two_mode_gates[two_mode_gate]\n                mode = 2\n\n        if method is None:\n            for single_mode_gate in self.single_mode_gates:\n                if single_mode_gate in operator:\n                    method = self.single_mode_gates[single_mode_gate]\n                    mode = 1\n\n        return method, mode\n\n    def parse_op(self, op):\n        """"""Transforms a Strawberry Fields operator object to a latex qcircuit gate.\n\n        Args:\n            op (strawberryfields.ops.Gate): the Strawberry Fields operator object.\n\n        Raises:\n            UnsupportedGateException: if the operator is not supported by the circuit drawer module.\n            ModeMismatchException: if the operator is interpreted as an n-mode gate but is\n                applied to a number of modes != n.\n\n        """"""\n        if not op.__class__.__name__ == ""Command"":\n            return\n\n        method, mode = self._gate_from_operator(op)\n        wires = list(map(lambda register: register.ind, op.reg))\n\n        if method is None:\n            raise UnsupportedGateException(\n                ""Unsupported operation {0} not printable by circuit builder!"".format(str(op))\n            )\n        if mode == len(wires):\n            method(*wires)\n        else:\n            raise ModeMismatchException(\n                ""{0} mode gate applied to {1} wires!"".format(mode, len(wires))\n            )\n\n    def _x(self, wire):\n        """"""Adds a position displacement operator to the circuit.\n\n        Args:\n            wire (int): the subsystem wire to apply the operator to.\n        """"""\n        self._single_mode_gate(wire, PAULI_X_COMP)\n\n    def _z(self, wire):\n        """"""Adds a momentum displacement operator to the circuit.\n\n        Args:\n            wire (int): the subsystem wire to apply the operator to.\n        """"""\n        self._single_mode_gate(wire, PAULI_Z_COMP)\n\n    def _s(self, wire):\n        """"""Adds a squeezing operator to the circuit.\n\n        Args:\n            wire (int): the subsystem wire to apply the operator to.\n        """"""\n        self._single_mode_gate(wire, S_COMP)\n\n    def _d(self, wire):\n        """"""Adds a displacement operator to the circuit.\n\n        Args:\n            wire (int): the subsystem wire to apply the operator to.\n        """"""\n        self._single_mode_gate(wire, D_COMP)\n\n    def _r(self, wire):\n        """"""Adds a rotation operator to the circuit.\n\n        Args:\n            wire (int): the subsystem wire to apply the operator to.\n        """"""\n        self._single_mode_gate(wire, R_COMP)\n\n    def _p(self, wire):\n        """"""Adds a quadratic phase shift operator to the circuit.\n\n        Args:\n            wire (int): the subsystem wire to apply the operator to.\n        """"""\n        self._single_mode_gate(wire, P_COMP)\n\n    def _v(self, wire):\n        """"""Adds a cubic phase shift operator to the circuit.\n\n        Args:\n            wire (int): the subsystem wire to apply the operator to.\n        """"""\n        self._single_mode_gate(wire, V_COMP)\n\n    def _k(self, wire):\n        """"""Adds a Kerr operator to the circuit.\n\n        Args:\n            wire (int): the subsystem wire to apply the operator to.\n        """"""\n        self._single_mode_gate(wire, K_COMP)\n\n    def _fourier(self, wire):\n        """"""Adds a Fourier transform operator to the circuit.\n\n        Args:\n            wire (int): the subsystem wire to apply the operator to.\n        """"""\n        self._single_mode_gate(wire, FOURIER_COMP)\n\n    def _cx(self, source_wire, target_wire):\n        """"""Adds a controlled position displacement operator to the circuit.\n\n        Args:\n            source_wire (int): the controlling subsystem wire.\n            target_wire (int): the controlled subsystem wire.\n        """"""\n        self._controlled_mode_gate(source_wire, target_wire, TARGET)\n\n    def _cz(self, source_wire, target_wire):\n        """"""Adds a controlled phase operator to the circuit.\n\n        Args:\n            source_wire (int): the controlling subsystem wire.\n            target_wire (int): the controlled subsystem wire.\n        """"""\n        self._controlled_mode_gate(source_wire, target_wire, PAULI_Z_COMP)\n\n    def _ck(self, source_wire, target_wire):\n        """"""Adds a controlled Kerr operator to the circuit.\n\n        Args:\n            source_wire (int): the controlling subsystem wire.\n            target_wire (int): the controlled subsystem wire.\n        """"""\n        self._controlled_mode_gate(source_wire, target_wire, K_COMP)\n\n    def _bs(self, first_wire, second_wire):\n        """"""Adds a beams plitter operator to the circuit.\n\n        Args:\n            first_wire (int): the first subsystem wire to apply the operator to.\n            second_wire (int): the second subsystem wire to apply the operator to.\n        """"""\n        self._multi_mode_gate(BS_MULTI_COMP, [first_wire, second_wire])\n\n    def _s2(self, first_wire, second_wire):\n        """"""Adds an two mode squeezing operator to the circuit.\n\n        Args:\n            first_wire (int): the first subsystem wire to apply the operator to.\n            second_wire (int): the second subsystem wire to apply the operator to.\n        """"""\n        self._multi_mode_gate(S_MULTI_COMP, [first_wire, second_wire])\n\n    # operation types\n\n    def _single_mode_gate(self, wire, circuit_op):\n        """"""Adds a single-mode operator gate to the circuit.\n\n        Args:\n            circuit_op (str): the latex code for the operator.\n            wires (list[int]): a list of the indeces of subsystem wires to apply the multi-mode gate to.\n        """"""\n        matrix = self._circuit_matrix\n        wire_ops = matrix[wire]\n\n        if Circuit._is_empty(wire_ops[-1]):\n            wire_ops[-1] = circuit_op\n        else:\n            wire_ops.append(circuit_op)\n            for prev_wire in matrix[:wire]:\n                prev_wire.append(QUANTUM_WIRE.format(1))\n            for post_wire in matrix[wire + 1 :]:\n                post_wire.append(QUANTUM_WIRE.format(1))\n\n    def _multi_mode_gate(self, circuit_op, wires):\n        """"""Adds a multi-mode operator to the circuit.\n\n        Args:\n            circuit_op (str): the latex code for the operator.\n            wires (list[int]): a list of the indeces of subsystem wires to apply the gate to.\n        Raises:\n            ModeMismatchException: if the operator is applied to non-adjacent wires.\n        """"""\n        matrix = self._circuit_matrix\n\n        if not self._on_empty_column():\n            self._add_column()\n\n        wires.sort()\n\n        first_wire = wires.pop(0)\n        wire_ops = matrix[first_wire]\n        wire_ops[-1] = MULTIGATE.format(1, circuit_op)\n        matrix[first_wire] = wire_ops\n        previous_wire = first_wire\n\n        for wire in wires:\n            if not previous_wire == wire - 1:\n                raise NotDrawableException(\n                    ""{0} multi-mode gate applied to non-adjacent wires!"".format(circuit_op)\n                )\n            wire_ops = matrix[wire]\n            wire_ops[-1] = GHOST.format(circuit_op)\n            matrix[wire] = wire_ops\n            previous_wire = wire\n\n        self._circuit_matrix = matrix\n\n    def _controlled_mode_gate(self, source_wire, target_wire, circuit_op):\n        """"""Adds a controlled operator gate to the circuit.\n\n        Args:\n            source wire (int): the index of the controlling subsystem.\n            target_wire (int): the index of the controlled subsystem.\n            circuit_op (str): the latex code for the operator.\n        """"""\n        matrix = self._circuit_matrix\n        source_ops = matrix[source_wire]\n        target_ops = matrix[target_wire]\n        distance = target_wire - source_wire\n\n        if Circuit._is_empty(source_ops[-1]) and Circuit._is_empty(target_ops[-1]):\n            source_ops[-1] = CONTROL.format(distance)\n            target_ops[-1] = circuit_op\n        else:\n            for index, wire_ops in enumerate(matrix):\n                if index == source_wire:\n                    wire_ops.append(CONTROL.format(distance))\n                elif index == target_wire:\n                    wire_ops.append(circuit_op)\n                else:\n                    wire_ops.append(QUANTUM_WIRE.format(1))\n\n    # helpers\n\n    def _on_empty_column(self):\n        """"""Checks if the right-most wires for each subsystem in the circuit are all empty\n\n        Returns:\n            bool: whether the right-most wires for each subsystem in the circuit are all empty\n        """"""\n        matrix = self._circuit_matrix\n\n        empty_column = True\n        for wire in enumerate(matrix):\n            wire_ops = wire[1]\n            if not Circuit._is_empty(wire_ops[-1]):\n                empty_column = False\n                break\n\n        return empty_column\n\n    def _add_column(self):\n        """"""Adds a unit of quantum wire to each subsystem in the circuit.""""""\n        for wire in self._circuit_matrix:\n            wire.append(QUANTUM_WIRE.format(1))\n\n    @staticmethod\n    def _is_empty(op):\n        """"""Checks for a NOP, a quantum wire location without an operator.\n\n        Args:\n            op (str): latex code for either an operator, or empty quantum wire.\n\n        Returns:\n            bool: whether the argument is an empty quantum wire.\n        """"""\n        return op == QUANTUM_WIRE.format(1)\n\n    # cosmetic\n\n    def _set_column_spacing(self, spacing):\n        """"""Sets visual spacing between operators in quantum circuit.\n\n        Args:\n            spacing (int): spacing between operators.\n        """"""\n        self._column_spacing = spacing\n\n    def _set_row_spacing(self, spacing):\n        """"""Sets visual spacing of wires in quantum circuit.\n\n        Args:\n            spacing (int): spacing between wires.\n        """"""\n        self._row_spacing = spacing\n\n    @staticmethod\n    def _pad_with_spaces(string):\n        """"""Pads string with spaces.\n\n        Args:\n            string (str): string to pad.\n\n        Returns:\n            str: string with space added to either side.\n        """"""\n        return "" "" + string + "" ""\n\n    # latex translation\n\n    def dump_to_document(self):\n        """"""Writes current circuit to document.\n\n        Returns:\n            str: latex document string.\n        """"""\n        self._init_document()\n        self._apply_spacing()\n        self._begin_circuit()\n\n        self._add_column()\n\n        for wire_ops in enumerate(self._circuit_matrix):\n            for wire_op in wire_ops[1]:\n                self._write_operation_to_document(wire_op)\n            self._end_wire()\n\n        self._end_circuit()\n        self._end_document()\n\n        return self._document\n\n    def compile_document(self, tex_dir=""./circuit_tex""):\n        """"""Compiles latex documents.\n\n        Args:\n            tex_dir (str): relative directory for latex document output.\n\n        Returns:\n            str: the file path of the resulting latex document.\n        """"""\n        tex_dir = os.path.abspath(tex_dir)\n\n        if not os.path.isdir(tex_dir):\n            os.mkdir(tex_dir)\n\n        file_name = ""output_{0}"".format(datetime.datetime.now().strftime(""%Y_%B_%d_%I:%M%p""))\n        file_path = ""{0}/{1}.tex"".format(tex_dir, file_name)\n\n        with open(file_path, ""w+"") as output_file:\n            output_file.write(self._document)\n\n        return file_path\n\n    def _init_document(self):\n        """"""Adds the required latex headers to the document.""""""\n        self._document = INIT_DOCUMENT\n\n    def _end_document(self):\n        """"""Appends latex EOD code to the document.""""""\n        self._document += DOCUMENT_END\n\n    def _begin_circuit(self):\n        """"""Prepares document for latex circuit content.""""""\n        self._document += CIRCUIT_BODY_START\n\n    def _end_circuit(self):\n        """"""Ends the latex circuit content.""""""\n        self._document += CIRCUIT_BODY_TERMINATOR\n\n    def _end_wire(self):\n        """"""Ends a wire within the latex circuit.""""""\n        self._document += WIRE_TERMINATOR\n\n    def _apply_spacing(self):\n        """"""Applies wire and operator visual spacing.""""""\n        if self._column_spacing is not None:\n            self._document += Circuit._pad_with_spaces(COLUMN_SPACING.format(self._column_spacing))\n        if self._row_spacing is not None:\n            self._document += Circuit._pad_with_spaces(ROW_SPACING.format(self._row_spacing))\n\n    def _write_operation_to_document(self, operation):\n        """"""Appends operation latex code to circuit in latex document.\n\n        Args:\n            operation (str): the latex code for the quantum operation to be applied.\n        """"""\n        self._document += Circuit._pad_with_spaces(WIRE_OPERATION.format(operation))\n\n    def __str__(self):\n        """"""String representation of the Circuit class.""""""\n        return self._document\n'"
strawberryfields/configuration.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nThis module contains functions used to load, store, save, and modify\nconfiguration options for Strawberry Fields.\n""""""\nimport os\n\nimport toml\nfrom appdirs import user_config_dir\n\nfrom strawberryfields.logger import create_logger\n\nDEFAULT_CONFIG_SPEC = {\n    ""api"": {\n        ""authentication_token"": (str, """"),\n        ""hostname"": (str, ""platform.strawberryfields.ai""),\n        ""use_ssl"": (bool, True),\n        ""port"": (int, 443),\n    }\n}\n\n\nclass ConfigurationError(Exception):\n    """"""Exception used for configuration errors""""""\n\n\ndef load_config(filename=""config.toml"", **kwargs):\n    """"""Load configuration from keyword arguments, configuration file or\n    environment variables.\n\n    .. note::\n\n        The configuration dictionary will be created based on the following\n        (order defines the importance, going from most important to least\n        important):\n\n        1. keyword arguments passed to ``load_config``\n        2. data contained in environmental variables (if any)\n        3. data contained in a configuration file (if exists)\n\n    Keyword Args:\n        filename (str): the name of the configuration file to look for.\n            Additional configuration options are detailed in\n            :doc:`/code/sf_configuration`\n\n    Returns:\n        dict[str, dict[str, Union[str, bool, int]]]: the configuration\n    """"""\n    config = create_config()\n\n    filepath = find_config_file(filename=filename)\n\n    if filepath is not None:\n        loaded_config = load_config_file(filepath)\n        api_config = get_api_config(loaded_config, filepath)\n\n        valid_api_options = keep_valid_options(api_config)\n        config[""api""].update(valid_api_options)\n    else:\n        log = create_logger(__name__)\n        log.warning(""No Strawberry Fields configuration file found."")\n\n    update_from_environment_variables(config)\n\n    valid_kwargs_config = keep_valid_options(kwargs)\n    config[""api""].update(valid_kwargs_config)\n\n    return config\n\n\ndef create_config(authentication_token=None, **kwargs):\n    """"""Create a configuration object that stores configuration related data\n    organized into sections.\n\n    The configuration object contains API-related configuration options. This\n    function takes into consideration only pre-defined options.\n\n    If called without passing any keyword arguments, then a default\n    configuration object is created.\n\n    Keyword Args:\n        Configuration options as detailed in :doc:`/code/sf_configuration`\n\n    Returns:\n        dict[str, dict[str, Union[str, bool, int]]]: the configuration\n            object\n    """"""\n    authentication_token = authentication_token or """"\n    hostname = kwargs.get(""hostname"", DEFAULT_CONFIG_SPEC[""api""][""hostname""][1])\n    use_ssl = kwargs.get(""use_ssl"", DEFAULT_CONFIG_SPEC[""api""][""use_ssl""][1])\n    port = kwargs.get(""port"", DEFAULT_CONFIG_SPEC[""api""][""port""][1])\n\n    config = {\n        ""api"": {\n            ""authentication_token"": authentication_token,\n            ""hostname"": hostname,\n            ""use_ssl"": use_ssl,\n            ""port"": port,\n        }\n    }\n    return config\n\n\ndef delete_config(filename=""config.toml"", directory=None):\n    """"""Delete a configuration file.\n\n    If called with no arguments, the currently active configuration file is deleted.\n\n    Keyword Args:\n        filename (str): the filename of the configuration file to delete\n        directory (str): the directory of the configuration file to delete\n            If ``None``, the currently active configuration file is deleted.\n    """"""\n    if directory is None:\n        file_path = find_config_file(filename)\n    else:\n        file_path = os.path.join(directory, filename)\n\n    os.remove(file_path)\n\n\ndef reset_config(filename=""config.toml""):\n    """"""Delete all active configuration files\n\n    .. warning::\n        This will delete all configuration files with the specified filename\n        (default ``config.toml``) found in the configuration directories.\n\n    Keyword Args:\n        filename (str): the filename of the configuration files to reset\n    """"""\n    for config in get_available_config_paths(filename):\n        delete_config(os.path.basename(config), os.path.dirname(config))\n\n\ndef find_config_file(filename=""config.toml""):\n    """"""Get the filepath of the first configuration file found from the defined\n    configuration directories (if any).\n\n    .. note::\n\n        The following directories are checked (in the following order):\n\n        * The current working directory\n        * The directory specified by the environment variable ``SF_CONF`` (if specified)\n        * The user configuration directory (if specified)\n\n    Keyword Args:\n        filename (str): the configuration file to look for\n\n    Returns:\n         Union[str, None]: the filepath to the configuration file or None, if\n             no file was found\n    """"""\n    directories = directories_to_check()\n    for directory in directories:\n        filepath = os.path.join(directory, filename)\n        if os.path.exists(filepath):\n            return filepath\n\n    return None\n\n\ndef directories_to_check():\n    """"""Returns the list of directories that should be checked for a configuration file.\n\n    .. note::\n\n        The following directories are checked (in the following order):\n\n        * The current working directory\n        * The directory specified by the environment variable ``SF_CONF`` (if specified)\n        * The user configuration directory (if specified)\n\n    Returns:\n        list: the list of directories to check\n    """"""\n    directories = []\n\n    current_dir = os.getcwd()\n    sf_env_config_dir = os.environ.get(""SF_CONF"", """")\n    sf_user_config_dir = user_config_dir(""strawberryfields"", ""Xanadu"")\n\n    directories.append(current_dir)\n    if sf_env_config_dir != """":\n        directories.append(sf_env_config_dir)\n    directories.append(sf_user_config_dir)\n\n    return directories\n\n\ndef load_config_file(filepath):\n    """"""Load a configuration object from a TOML formatted file.\n\n    Args:\n        filepath (str): path to the configuration file\n\n    Returns:\n         dict[str, dict[str, Union[str, bool, int]]]: the configuration\n            object that was loaded\n    """"""\n    with open(filepath, ""r"") as f:\n        config_from_file = toml.load(f)\n    return config_from_file\n\n\ndef get_api_config(loaded_config, filepath):\n    """"""Gets the API section from the loaded configuration.\n\n    Args:\n        loaded_config (dict): the configuration that was loaded from the TOML config\n            file\n        filepath (str): path to the configuration file\n\n    Returns:\n        dict[str, Union[str, bool, int]]: the api section of the configuration\n\n    Raises:\n        ConfigurationError: if the api section was not defined in the\n            configuration\n    """"""\n    try:\n        return loaded_config[""api""]\n    except KeyError:\n        log = create_logger(__name__)\n        log.error(\'The configuration from the %s file does not contain an ""api"" section.\', filepath)\n        raise ConfigurationError\n\n\ndef keep_valid_options(sectionconfig):\n    """"""Filters the valid options in a section of a configuration dictionary.\n\n    Args:\n        sectionconfig (dict[str, Union[str, bool, int]]): the section of the\n            configuration to check\n\n    Returns:\n        dict[str, Union[str, bool, int]]: the keep section of the\n            configuration\n    """"""\n    return {k: v for k, v in sectionconfig.items() if k in VALID_KEYS}\n\n\ndef update_from_environment_variables(config):\n    """"""Updates the current configuration object from data stored in environment\n    variables.\n\n    The list of environment variables can be found at :mod:`strawberryfields.configuration`\n\n    Args:\n        config (dict[str, dict[str, Union[str, bool, int]]]): the\n            configuration to be updated\n    Returns:\n        dict[str, dict[str, Union[str, bool, int]]]): the updated\n        configuration\n    """"""\n    for section, sectionconfig in config.items():\n        env_prefix = ""SF_{}_"".format(section.upper())\n        for key in sectionconfig:\n            env = env_prefix + key.upper()\n            if env in os.environ:\n                config[section][key] = parse_environment_variable(key, os.environ[env])\n\n\ndef parse_environment_variable(key, value):\n    """"""Parse a value stored in an environment variable.\n\n    Args:\n        key (str): the name of the environment variable\n        value (Union[str, bool, int]): the value obtained from the environment\n            variable\n\n    Returns:\n        [str, bool, int]: the parsed value\n    """"""\n    trues = (True, ""true"", ""True"", ""TRUE"", ""1"", 1)\n    falses = (False, ""false"", ""False"", ""FALSE"", ""0"", 0)\n\n    if DEFAULT_CONFIG_SPEC[""api""][key][0] is bool:\n        if value in trues:\n            return True\n\n        if value in falses:\n            return False\n\n        raise ValueError(""Boolean could not be parsed"")\n\n    if DEFAULT_CONFIG_SPEC[""api""][key][0] is int:\n        return int(value)\n\n    return value\n\n\ndef active_configs(filename=""config.toml""):\n    """"""Prints the filepaths for existing configuration files to the standard\n    output and marks the one that is active.\n\n    This function relies on the precedence ordering of directories to check\n    when marking the active configuration.\n\n    Args:\n        filename (str): the name of the configuration files to look for\n    """"""\n    active_configs_list = get_available_config_paths(filename)\n\n    # print the active configurations found based on the filename specified\n    if active_configs_list:\n        active = True\n\n        print(\n            ""\\nThe following Strawberry Fields configuration files were found ""\n            \'with the name ""{}"":\\n\'.format(filename)\n        )\n\n        for config in active_configs_list:\n            if active:\n                config += "" (active)""\n                active = False\n\n            print(""* "" + config)\n    else:\n        print(\n            ""\\nNo Strawberry Fields configuration files were found with the ""\n            \'name ""{}"".\\n\'.format(filename)\n        )\n\n    # print the directores that are being checked for a configuration file\n    directories = directories_to_check()\n\n    print(""\\nThe following directories were checked:\\n"")\n    for directory in directories:\n        print(""* "" + directory)\n\n\ndef get_available_config_paths(filename=""config.toml""):\n    """"""Get the paths for the configuration files available in Strawberry Fields.\n\n    Args:\n        filename (str): the name of the configuration files to look for\n\n    Returns:\n        list[str]: the filepaths for the active configurations\n    """"""\n    active_configs_list = []\n\n    directories = directories_to_check()\n\n    for directory in directories:\n        filepath = os.path.join(directory, filename)\n        if os.path.exists(filepath):\n            active_configs_list.append(filepath)\n\n    return active_configs_list\n\n\ndef store_account(authentication_token, filename=""config.toml"", location=""user_config"", **kwargs):\n    r""""""Configure Strawberry Fields for access to the Xanadu cloud platform by\n    saving your account credentials.\n\n    The configuration file can be created in the following locations:\n\n    - A global user configuration directory (``""user_config""``)\n    - The current working directory (``""local""``)\n\n    This global user configuration directory differs depending on the operating system:\n\n    * On Linux: ``~/.config/strawberryfields``\n    * On Windows: ``C:\\Users\\USERNAME\\AppData\\Local\\Xanadu\\strawberryfields``\n    * On MacOS: ``~/Library/Application Support/strawberryfields``\n\n    By default, Strawberry Fields will load the configuration and account credentials from the global\n    user configuration directory, no matter the working directory. However, if there exists a configuration\n    file in the *local* working directory, this takes precedence. The ``""local""`` option is therefore useful\n    for maintaining per-project configuration settings.\n\n    **Examples:**\n\n    In these examples ``""AUTHENTICATION_TOKEN""`` should be replaced with a valid authentication\n    token.\n\n    Access to the Xanadu cloud can be configured as follows:\n\n    >>> sf.store_account(""AUTHENTICATION_TOKEN"")\n\n    This creates the following ``""config.toml""`` file:\n\n    .. code-block:: toml\n\n        [api]\n        authentication_token = ""AUTHENTICATION_TOKEN""\n        hostname = ""platform.strawberryfields.ai""\n        use_ssl = true\n        port = 443\n\n    You can also create the configuration file locally (in the **current\n    working directory**) the following way:\n\n    >>> import strawberryfields as sf\n    >>> sf.store_account(""AUTHENTICATION_TOKEN"", location=""local"")\n\n    Each of the configuration options can be passed as further keyword\n    arguments as well (see the :doc:`/code/sf_configuration` page\n    for a list of options):\n\n    >>> import strawberryfields as sf\n    >>> sf.store_account(""AUTHENTICATION_TOKEN"", location=""local"", hostname=""MyHost"", use_ssl=False, port=123)\n\n    This creates the following ``""config.toml""`` file in the **current working directory**:\n\n    .. code-block:: toml\n\n        [api]\n        authentication_token = ""AUTHENTICATION_TOKEN""\n        hostname = ""MyHost""\n        use_ssl = false\n        port = 123\n\n    Args:\n        authentication_token (str): API token for authentication to the Xanadu cloud platform.\n            This is required for submitting remote jobs using :class:`~.RemoteEngine`.\n\n    Keyword Args:\n        location (str): determines where the configuration file should be saved\n        filename (str): the name of the configuration file to look for\n\n    Additional configuration options are detailed in :doc:`/code/sf_configuration` and can be passed\n    as keyword arguments.\n    """"""\n    if location == ""user_config"":\n        directory = user_config_dir(""strawberryfields"", ""Xanadu"")\n\n        # Create target Directory if it doesn\'t exist\n        os.makedirs(directory, exist_ok=True)\n    elif location == ""local"":\n        directory = os.getcwd()\n    else:\n        raise ConfigurationError(""This location is not recognized."")\n\n    filepath = os.path.join(directory, filename)\n\n    config = create_config(authentication_token=authentication_token, **kwargs)\n    save_config_to_file(config, filepath)\n\n\ndef save_config_to_file(config, filepath):\n    """"""Saves a configuration to a TOML file.\n\n    Args:\n        config (dict[str, dict[str, Union[str, bool, int]]]): the\n            configuration to be saved\n        filepath (str): path to the configuration file\n    """"""\n    with open(filepath, ""w"") as f:\n        toml.dump(config, f)\n\n\nVALID_KEYS = set(create_config()[""api""].keys())\nDEFAULT_CONFIG = create_config()\n'"
strawberryfields/decompositions.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThis module implements common shared matrix decompositions that are\nused to perform gate decompositions.\n""""""\n\nfrom itertools import groupby\n\nimport numpy as np\nfrom scipy.linalg import block_diag, sqrtm, polar, schur\nfrom thewalrus.quantum import find_scaling_adjacency_matrix\n\nfrom .backends.shared_ops import sympmat, changebasis\n\n\ndef takagi(N, tol=1e-13, rounding=13):\n    r""""""Autonne-Takagi decomposition of a complex symmetric (not Hermitian!) matrix.\n\n    Note that singular values of N are considered equal if they are equal after np.round(values, tol).\n\n    See :cite:`cariolaro2016` and references therein for a derivation.\n\n    Args:\n        N (array[complex]): square, symmetric matrix N\n        rounding (int): the number of decimal places to use when rounding the singular values of N\n        tol (float): the tolerance used when checking if the input matrix is symmetric: :math:`|N-N^T| <` tol\n\n    Returns:\n        tuple[array, array]: (rl, U), where rl are the (rounded) singular values,\n            and U is the Takagi unitary, such that :math:`N = U \\diag(rl) U^T`.\n    """"""\n    (n, m) = N.shape\n    if n != m:\n        raise ValueError(""The input matrix must be square"")\n    if np.linalg.norm(N - np.transpose(N)) >= tol:\n        raise ValueError(""The input matrix is not symmetric"")\n\n    N = np.real_if_close(N)\n\n    if np.allclose(N, 0):\n        return np.zeros(n), np.eye(n)\n\n    if np.isrealobj(N):\n        # If the matrix N is real one can be more clever and use its eigendecomposition\n        l, U = np.linalg.eigh(N)\n        vals = np.abs(l)  # These are the Takagi eigenvalues\n        phases = np.sqrt(np.complex128([1 if i > 0 else -1 for i in l]))\n        Uc = U @ np.diag(phases)  # One needs to readjust the phases\n        list_vals = [(vals[i], i) for i in range(len(vals))]\n        list_vals.sort(reverse=True)\n        sorted_l, permutation = zip(*list_vals)\n        permutation = np.array(permutation)\n        Uc = Uc[:, permutation]\n        # And also rearrange the unitary and values so that they are decreasingly ordered\n        return np.array(sorted_l), Uc\n\n    v, l, ws = np.linalg.svd(N)\n    w = np.transpose(np.conjugate(ws))\n    rl = np.round(l, rounding)\n\n    # Generate list with degenerancies\n    result = []\n    for k, g in groupby(rl):\n        result.append(list(g))\n\n    # Generate lists containing the columns that correspond to degenerancies\n    kk = 0\n    for k in result:\n        for ind, j in enumerate(k):  # pylint: disable=unused-variable\n            k[ind] = kk\n            kk = kk + 1\n\n    # Generate the lists with the degenerate column subspaces\n    vas = []\n    was = []\n    for i in result:\n        vas.append(v[:, i])\n        was.append(w[:, i])\n\n    # Generate the matrices qs of the degenerate subspaces\n    qs = []\n    for i in range(len(result)):\n        qs.append(sqrtm(np.transpose(vas[i]) @ was[i]))\n\n    # Construct the Takagi unitary\n    qb = block_diag(*qs)\n\n    U = v @ np.conj(qb)\n    return rl, U\n\n\ndef graph_embed_deprecated(A, max_mean_photon=1.0, make_traceless=False, rtol=1e-05, atol=1e-08):\n    r""""""Embed a graph into a Gaussian state.\n\n    Note: The default behaviour of graph embedding has been changed; see :func:`~.graph_embed`. This version is deprecated, but has been kept for consistency.\n\n    Given a graph in terms of a symmetric adjacency matrix\n    (in general with arbitrary complex off-diagonal and real diagonal entries),\n    returns the squeezing parameters and interferometer necessary for\n    creating the Gaussian state whose off-diagonal parts are proportional to that matrix.\n\n    Uses :func:`~.takagi`.\n\n    Args:\n        A (array[complex]): square, symmetric (weighted) adjacency matrix of the graph\n        max_mean_photon (float): Threshold value. It guarantees that the mode with\n            the largest squeezing has ``max_mean_photon`` as the mean photon number\n            i.e., :math:`sinh(r_{max})^2 ==` :code:``max_mean_photon``.\n        make_traceless (bool): Removes the trace of the input matrix, by performing the transformation\n            :math:`\\tilde{A} = A-\\mathrm{tr}(A) \\I/n`. This may reduce the amount of squeezing needed to encode\n            the graph but will lead to different photon number statistics for events with more than\n            one photon in any mode.\n        rtol (float): relative tolerance used when checking if the input matrix is symmetric\n        atol (float): absolute tolerance used when checking if the input matrix is symmetric\n\n    Returns:\n        tuple[array, array]: squeezing parameters of the input\n            state to the interferometer, and the unitary matrix representing the interferometer\n    """"""\n    (m, n) = A.shape\n\n    if m != n:\n        raise ValueError(""The matrix is not square."")\n\n    if not np.allclose(A, np.transpose(A), rtol=rtol, atol=atol):\n        raise ValueError(""The matrix is not symmetric."")\n\n    if make_traceless:\n        A = A - np.trace(A) * np.identity(n) / n\n\n    s, U = takagi(A, tol=atol)\n    sc = np.sqrt(1.0 + 1.0 / max_mean_photon)\n    vals = -np.arctanh(s / (s[0] * sc))\n    return vals, U\n\n\ndef graph_embed(A, mean_photon_per_mode=1.0, make_traceless=False, rtol=1e-05, atol=1e-08):\n    r""""""Embed a graph into a Gaussian state.\n\n    Given a graph in terms of a symmetric adjacency matrix\n    (in general with arbitrary complex entries),\n    returns the squeezing parameters and interferometer necessary for\n    creating the Gaussian state whose off-diagonal parts are proportional to that matrix.\n\n    Uses :func:`~.takagi`.\n\n    Args:\n        A (array[complex]): square, symmetric (weighted) adjacency matrix of the graph\n        mean_photon_per_mode (float): guarantees that the mean photon number in the pure Gaussian state\n            representing the graph satisfies  :math:`\\frac{1}{N}\\sum_{i=1}^N sinh(r_{i})^2 ==` :code:``mean_photon``\n        make_traceless (bool): Removes the trace of the input matrix, by performing the transformation\n            :math:`\\tilde{A} = A-\\mathrm{tr}(A) \\I/n`. This may reduce the amount of squeezing needed to encode\n            the graph but will lead to different photon number statistics for events with more than\n            one photon in any mode.\n        rtol (float): relative tolerance used when checking if the input matrix is symmetric\n        atol (float): absolute tolerance used when checking if the input matrix is symmetric\n\n    Returns:\n        tuple[array, array]: squeezing parameters of the input\n        state to the interferometer, and the unitary matrix representing the interferometer\n    """"""\n    (m, n) = A.shape\n\n    if m != n:\n        raise ValueError(""The matrix is not square."")\n\n    if not np.allclose(A, np.transpose(A), rtol=rtol, atol=atol):\n        raise ValueError(""The matrix is not symmetric."")\n\n    if make_traceless:\n        A = A - np.trace(A) * np.identity(n) / n\n\n    scale = find_scaling_adjacency_matrix(A, n * mean_photon_per_mode)\n    A = scale * A\n    s, U = takagi(A, tol=atol)\n    vals = -np.arctanh(s)\n    return vals, U\n\n\ndef bipartite_graph_embed(A, mean_photon_per_mode=1.0, rtol=1e-05, atol=1e-08):\n    r""""""Embed a bipartite graph into a Gaussian state.\n\n    Given a bipartite graph in terms of an adjacency matrix\n    (in general with arbitrary complex entries),\n    returns the two-mode squeezing parameters and interferometers necessary for\n    creating the Gaussian state that encodes such adjacency matrix\n\n    Uses :func:`~.takagi`.\n\n    Args:\n        A (array[complex]): square, (weighted) adjacency matrix of the bipartite graph\n        mean_photon_per_mode (float): guarantees that the mean photon number in the pure Gaussian state\n            representing the graph satisfies  :math:`\\frac{1}{N}\\sum_{i=1}^N sinh(r_{i})^2 ==` :code:``mean_photon``\n        rtol (float): relative tolerance used when checking if the input matrix is symmetric\n        atol (float): absolute tolerance used when checking if the input matrix is symmetric\n\n    Returns:\n        tuple[array, array, array]: squeezing parameters of the input\n        state to the interferometer, and the unitaries matrix representing the interferometer\n    """"""\n    (m, n) = A.shape\n\n    if m != n:\n        raise ValueError(""The matrix is not square."")\n\n    B = np.block([[0 * A, A], [A.T, 0 * A]])\n    scale = find_scaling_adjacency_matrix(B, 2 * n * mean_photon_per_mode)\n    A = scale * A\n\n    if np.allclose(A, A.T, rtol=rtol, atol=atol):\n        s, u = takagi(A, tol=atol)\n        v = u\n    else:\n        u, s, v = np.linalg.svd(A)\n        v = v.T\n\n    vals = -np.arctanh(s)\n    return vals, u, v\n\n\ndef T(m, n, theta, phi, nmax):\n    r""""""The Clements T matrix from Eq 1 of the paper""""""\n    mat = np.identity(nmax, dtype=np.complex128)\n    mat[m, m] = np.exp(1j * phi) * np.cos(theta)\n    mat[m, n] = -np.sin(theta)\n    mat[n, m] = np.exp(1j * phi) * np.sin(theta)\n    mat[n, n] = np.cos(theta)\n    return mat\n\n\ndef Ti(m, n, theta, phi, nmax):\n    r""""""The inverse Clements T matrix""""""\n    return np.transpose(T(m, n, theta, -phi, nmax))\n\n\ndef nullTi(m, n, U):\n    r""""""Nullifies element m,n of U using Ti""""""\n    (nmax, mmax) = U.shape\n\n    if nmax != mmax:\n        raise ValueError(""U must be a square matrix"")\n\n    if U[m, n] == 0:\n        # no swaps for the identity-like case\n        thetar = 0\n        phir = 0\n    elif U[m, n + 1] == 0:\n        # swap in the divide-by-zero case\n        thetar = np.pi / 2\n        phir = 0\n    else:\n        r = U[m, n] / U[m, n + 1]\n        thetar = np.arctan(np.abs(r))\n        phir = np.angle(r)\n\n    return [n, n + 1, thetar, phir, nmax]\n\n\ndef nullT(n, m, U):\n    r""""""Nullifies element n,m of U using T""""""\n    (nmax, mmax) = U.shape\n\n    if nmax != mmax:\n        raise ValueError(""U must be a square matrix"")\n\n    if U[n, m] == 0:\n        # no swaps for the identity-like case\n        thetar = 0\n        phir = 0\n    elif U[n - 1, m] == 0:\n        # swap in the divide-by-zero case\n        thetar = np.pi / 2\n        phir = 0\n    else:\n        r = -U[n, m] / U[n - 1, m]\n        thetar = np.arctan(np.abs(r))\n        phir = np.angle(r)\n\n    return [n - 1, n, thetar, phir, nmax]\n\n\ndef rectangular(V, tol=1e-11):\n    r""""""Rectangular decomposition of a unitary matrix, with local\n    phase shifts applied between two interferometers.\n\n    See :ref:`rectangular` or :cite:`clements2016` for more details.\n\n    This function returns a circuit corresponding to an intermediate step in\n    the decomposition as described in Eq. 4 of the article. In this form,\n    the circuit comprises some T matrices (as in Eq. 1), then phases on all modes,\n    and more T matrices.\n\n    The procedure to construct these matrices is detailed in the supplementary\n    material of the article.\n\n    Args:\n        V (array[complex]): unitary matrix of size n_size\n        tol (float): the tolerance used when checking if the matrix is unitary:\n            :math:`|VV^\\dagger-I| \\leq` tol\n\n    Returns:\n        tuple[array]: tuple of the form ``(tilist,np.diag(localV),tlist)``\n            where:\n\n            * ``tilist``: list containing ``[n,m,theta,phi,n_size]`` of the Ti unitaries needed\n            * ``tlist``: list containing ``[n,m,theta,phi,n_size]`` of the T unitaries needed\n            * ``localV``: Diagonal unitary sitting sandwiched by Ti\'s and the T\'s\n    """"""\n    localV = V\n    (nsize, _) = localV.shape\n\n    if not np.allclose(V @ V.conj().T, np.identity(nsize), atol=tol, rtol=0):\n        raise ValueError(""The input matrix is not unitary"")\n\n    tilist = []\n    tlist = []\n    for k, i in enumerate(range(nsize - 2, -1, -1)):\n        if k % 2 == 0:\n            for j in reversed(range(nsize - 1 - i)):\n                tilist.append(nullTi(i + j + 1, j, localV))\n                localV = localV @ Ti(*tilist[-1])\n        else:\n            for j in range(nsize - 1 - i):\n                tlist.append(nullT(i + j + 1, j, localV))\n                localV = T(*tlist[-1]) @ localV\n\n    return tilist, np.diag(localV), tlist\n\n\ndef rectangular_phase_end(V, tol=1e-11):\n    r""""""Rectangular decomposition of a unitary matrix, with all\n    local phase shifts placed after the interferometers.\n\n    See :cite:`clements2016` for more details.\n\n    Final step in the decomposition of a given discrete unitary matrix.\n    The output is of the form given in Eq. 5.\n\n    Args:\n        V (array[complex]): unitary matrix of size n_size\n        tol (float): the tolerance used when checking if the matrix is unitary\n    Returns:\n        tuple[array]: returns a tuple of the form ``(tlist, np.diag(localV), None)``\n            where:\n\n            * ``tlist``: list containing ``[n,m,theta,phi,n_size]`` of the T unitaries needed\n            * ``localV``: Diagonal unitary matrix to be applied at the end of circuit\n    """"""\n    tilist, diags, tlist = rectangular(V, tol)\n    new_tlist, new_diags = tilist.copy(), diags.copy()\n\n    # Push each beamsplitter through the diagonal unitary\n    for i in reversed(tlist):\n        em, en = int(i[0]), int(i[1])\n        alpha, beta = np.angle(new_diags[em]), np.angle(new_diags[en])\n        theta, phi = i[2], i[3]\n\n        # The new parameters required for D\',T\' st. T^(-1)D = D\'T\'\n        new_theta = theta\n        new_phi = (alpha - beta + np.pi) % (2 * np.pi)\n        new_alpha = beta - phi + np.pi\n        new_beta = beta\n\n        new_i = [i[0], i[1], new_theta, new_phi, i[4]]\n        new_diags[em], new_diags[en] = np.exp(1j * new_alpha), np.exp(1j * new_beta)\n\n        new_tlist = new_tlist + [new_i]\n\n    return new_tlist, new_diags, None\n\n\ndef mach_zehnder(m, n, internal_phase, external_phase, nmax):\n    r""""""A two-mode Mach-Zehnder interferometer section.\n\n    This section is constructed by an external phase shifter on the input mode\n    m, a symmetric beamsplitter combining modes m and n, an internal phase\n    shifter on mode m, and another symmetric beamsplitter combining modes m\n    and n.\n\n    The resulting matrix is\n\n    .. math::\n\n       M = i e^{i \\phi_{i}/2} \\left[\\begin{matrix}\\sin \\left( \\phi_{i}/2 \\right) e^{i \\phi_{e}} & \\cos \\left( \\phi_{i}/2 \\right) \\\\\n       \\cos \\left( \\phi_{i}/2 \\right) e^{i \\phi_{e}} & - \\sin \\left( \\phi_{i}/2 \\right) \\end{matrix}\\right]\n\n    Args:\n        m (int): mode number on which the phase shifters act\n        n (int): mode number which is combined with mode m by the beamsplitters\n        internal_phase (float): phase in between the symmetric beamsplitters\n        external_phase (float): phase acting before the first beamsplitter\n        nmax (int): maximum number of modes in the circuit\n\n    Returns:\n        array: unitary matrix of the effective transformation the series of phaseshifters\n        and beamsplitters.\n    """"""\n    Rexternal = np.identity(nmax, dtype=np.complex128)\n    Rexternal[m, m] = np.exp(1j * external_phase)\n    Rinternal = np.identity(nmax, dtype=np.complex128)\n    Rinternal[m, m] = np.exp(1j * internal_phase)\n    BS = np.identity(nmax, dtype=np.complex128)\n    BS[m, m] = 1.0 / np.sqrt(2)\n    BS[m, n] = 1.0j / np.sqrt(2)\n    BS[n, m] = 1.0j / np.sqrt(2)\n    BS[n, n] = 1.0 / np.sqrt(2)\n    return BS @ Rinternal @ BS @ Rexternal\n\n\ndef mach_zehnder_inv(m, n, phi_int, phi_ext, nmax):\n    r""""""The inverse of the Mach-Zehnder unitary matrix.\n    See :func:`~.mach_zehnder` for more details on the Mach-Zehnder unitary.\n    """"""\n    return mach_zehnder(m, n, phi_int, phi_ext, nmax).conj().T\n\n\ndef nullMZi(m, n, U):\n    r""""""Nullifies element m,n of U using mach_zehnder_inv.\n\n    Args:\n        m (int): row index of element to be nullified\n        n (int): column index of element to be nullified\n        U (array): matrix whose m,n element is to be nullified\n\n    Returns:\n        list: list containing ``[m, n, internal_phase, external_phase, nmax]`` of the\n            mach_zehnder_inv unitaries needed\n    """"""\n    (nmax, mmax) = U.shape\n\n    if nmax != mmax:\n        raise ValueError(""U must be a square matrix"")\n\n    if U[m, n] == 0:\n        # no swaps for the identity-like case\n        phi_i = np.pi\n        phi_e = 0\n    elif U[m, n + 1] == 0:\n        # swap in the divide-by-zero case\n        phi_i = 0\n        phi_e = 0\n    else:\n        r = -U[m, n + 1] / U[m, n]\n        phi_i = 2 * np.arctan(np.abs(r))\n        phi_e = -np.angle(r)\n\n    return [n, n + 1, phi_i, phi_e, nmax]\n\n\ndef nullMZ(n, m, U):\n    r""""""Nullifies element n,m of U using mach_zehnder.\n\n    Args:\n        n (int): row index of element to be nullified\n        m (int): column index of element to be nullified\n        U (array): matrix whose m,n element is to be nullified\n\n    Returns:\n        list: list containing ``[m, n, internal_phase, external_phase, nmax]`` of the\n            mach_zehnder unitaries needed\n    """"""\n    (nmax, mmax) = U.shape\n\n    if nmax != mmax:\n        raise ValueError(""U must be a square matrix"")\n\n    if U[n, m] == 0:\n        # no swaps for the identity-like case\n        phi_i = np.pi\n        phi_e = 0\n    elif U[n - 1, m] == 0:\n        # swap in the divide-by-zero case\n        phi_i = 0\n        phi_e = 0\n    else:\n        r = U[n - 1, m] / U[n, m]\n        phi_i = 2 * np.arctan(np.abs(r))\n        phi_e = -np.angle(r)\n\n    return [n - 1, n, phi_i, phi_e, nmax]\n\n\ndef rectangular_MZ(V, tol=1e-11):\n    r""""""Rectangular decomposition of a unitary matrix, with local\n    phase shifts applied between two interferometers.\n\n    Is similar to :func:`~.rectangular` except that it uses Mach Zehnder matrices to null elements of V\n    using the :func:`~.null_MZ` and :func:`~.null_MZi` instead of :func:`~.T` matrices and corresponding :func:`~.nullT`\n    and :func:`~.nullTi` functions.\n\n    Args:\n        V (array[complex]): unitary matrix of size n_size\n        tol (float): the tolerance used when checking if the matrix is unitary\n\n    Returns:\n        tuple[array]: tuple of the form ``(tilist, np.diag(localV), tlist)``\n        where:\n\n        * ``tilist``: list containing ``[n,m,phi_int,phi_ext,n_size]`` of the ``mach_zehnder_inv`` unitaries needed\n        * ``tlist``: list containing ``[n,m,phi_int,phi_ext,n_size]`` of the ``mach_zehnder`` unitaries needed\n        * ``localV``: Diagonal unitary sitting sandwiched by ``mach_zehnder_inv``\'s and the ``mach_zehnder``\'s\n    """"""\n    localV = V\n    (nsize, _) = localV.shape\n\n    if not np.allclose(V @ V.conj().T, np.identity(nsize), atol=tol, rtol=0):\n        raise ValueError(""The input matrix is not unitary"")\n\n    tilist = []\n    tlist = []\n    for k, i in enumerate(range(nsize - 2, -1, -1)):\n        if k % 2 == 0:\n            for j in reversed(range(nsize - 1 - i)):\n                tilist.append(nullMZi(i + j + 1, j, localV))\n                tilist[-1][2] %= 2 * np.pi\n                tilist[-1][3] %= 2 * np.pi\n                # repeat modulo operations, otherwise the input unitary\n                # numpy.identity(20) yields an external_phase of exactly 2 * pi\n                tilist[-1][2] %= 2 * np.pi\n                tilist[-1][3] %= 2 * np.pi\n                localV = localV @ mach_zehnder_inv(*tilist[-1])\n        else:\n            for j in range(nsize - 1 - i):\n                tlist.append(nullMZ(i + j + 1, j, localV))\n                tlist[-1][2] %= 2 * np.pi\n                tlist[-1][3] %= 2 * np.pi\n                # repeat modulo operations, otherwise the input unitary\n                # numpy.identity(20) yields an external_phase of exactly 2 * pi\n                tlist[-1][2] %= 2 * np.pi\n                tlist[-1][3] %= 2 * np.pi\n                localV = mach_zehnder(*tlist[-1]) @ localV\n\n    return tilist, np.diag(localV), tlist\n\n\ndef rectangular_symmetric(V, tol=1e-11):\n    r""""""Decomposition of a unitary into an array of symmetric beamsplitters.\n\n    This decomposition starts with the output from :func:`~.rectangular_MZ`\n    and performs the equivalent of :func:`~.rectangular_phase_end` by placing all the\n    local phase shifts after the interferometers.\n\n    If the Mach-Zehnder unitaries are represented as M and the local phase shifts as D, the new\n    parameters to shift the local phases to the end are calculated such that\n\n    .. math::\n\n       M^{-1} D = D_{\\mathrm{new}} M_{\\mathrm{new}}\n\n    Args:\n        V (array): unitary matrix of size n_size\n        tol (int): the number of decimal places to use when determining\n          whether the matrix is unitary\n\n    Returns:\n        tuple[array]: returns a tuple of the form ``(tlist,np.diag(localV), None)``\n            where:\n\n            * ``tlist``: list containing ``[n, m, internal_phase, external_phase, n_size]`` of the T unitaries needed\n            * ``localV``: Diagonal unitary matrix to be applied at the end of circuit\n            * ``None``: the value ``None``, in order to make the return\n              signature identical to :func:`~.rectangular`\n    """"""\n    tilist, diags, tlist = rectangular_MZ(V, tol)\n    new_tlist, new_diags = tilist.copy(), diags.copy()\n\n    # Push each beamsplitter through the diagonal unitary\n    for i in reversed(tlist):\n        em, en = int(i[0]), int(i[1])\n        alpha, beta = np.angle(new_diags[em]), np.angle(new_diags[en])\n        phi_i, phi_e = i[2], i[3]\n\n        # The new parameters required for D\', MZ\' st. MZ^(-1)D = D\'MZ\'\n\n        new_phi_e = (alpha - beta) % (2 * np.pi)\n        new_alpha = (beta - phi_e - phi_i + np.pi) % (2 * np.pi)\n        new_beta = (beta - phi_i + np.pi) % (2 * np.pi)\n        new_phi_i = phi_i % (2 * np.pi)\n        # repeat modulo operations , otherwise the input unitary\n        # numpy.identity(20) yields an external_phase of exactly 2 * pi\n        new_phi_i %= 2 * np.pi\n        new_phi_e %= 2 * np.pi\n\n        new_i = [i[0], i[1], new_phi_i, new_phi_e, i[4]]\n        new_diags[em], new_diags[en] = np.exp(1j * new_alpha), np.exp(1j * new_beta)\n\n        new_tlist = new_tlist + [new_i]\n\n    return new_tlist, new_diags, None\n\n\ndef triangular(V, tol=1e-11):\n    r""""""Triangular decomposition of a unitary matrix due to Reck et al.\n\n    See :cite:`reck1994` for more details and :cite:`clements2016` for details on notation.\n\n    Args:\n        V (array[complex]): unitary matrix of size ``n_size``\n        tol (float): the tolerance used when checking if the matrix is unitary:\n            :math:`|VV^\\dagger-I| \\leq` tol\n\n    Returns:\n        tuple[array]: returns a tuple of the form ``(tlist,np.diag(localV), None)``\n            where:\n\n            * ``tlist``: list containing ``[n,m,theta,phi,n_size]`` of the T unitaries needed\n            * ``localV``: Diagonal unitary applied at the beginning of circuit\n    """"""\n    localV = V\n    (nsize, _) = localV.shape\n\n    if not np.allclose(V @ V.conj().T, np.identity(nsize), atol=tol, rtol=0):\n        raise ValueError(""The input matrix is not unitary"")\n\n    tlist = []\n    for i in range(nsize - 2, -1, -1):\n        for j in range(i + 1):\n            tlist.append(nullT(nsize - j - 1, nsize - i - 2, localV))\n            localV = T(*tlist[-1]) @ localV\n\n    return list(reversed(tlist)), np.diag(localV), None\n\n\ndef williamson(V, tol=1e-11):\n    r""""""Williamson decomposition of positive-definite (real) symmetric matrix.\n\n    See :ref:`williamson`.\n\n    Note that it is assumed that the symplectic form is\n\n    .. math:: \\Omega = \\begin{bmatrix}0&I\\\\-I&0\\end{bmatrix}\n\n    where :math:`I` is the identity matrix and :math:`0` is the zero matrix.\n\n    See https://math.stackexchange.com/questions/1171842/finding-the-symplectic-matrix-in-williamsons-theorem/2682630#2682630\n\n    Args:\n        V (array[float]): positive definite symmetric (real) matrix\n        tol (float): the tolerance used when checking if the matrix is symmetric: :math:`|V-V^T| \\leq` tol\n\n    Returns:\n        tuple[array,array]: ``(Db, S)`` where ``Db`` is a diagonal matrix\n            and ``S`` is a symplectic matrix such that :math:`V = S^T Db S`\n    """"""\n    (n, m) = V.shape\n\n    if n != m:\n        raise ValueError(""The input matrix is not square"")\n\n    diffn = np.linalg.norm(V - np.transpose(V))\n\n    if diffn >= tol:\n        raise ValueError(""The input matrix is not symmetric"")\n\n    if n % 2 != 0:\n        raise ValueError(""The input matrix must have an even number of rows/columns"")\n\n    n = n // 2\n    omega = sympmat(n)\n    rotmat = changebasis(n)\n    vals = np.linalg.eigvalsh(V)\n\n    for val in vals:\n        if val <= 0:\n            raise ValueError(""Input matrix is not positive definite"")\n\n    Mm12 = sqrtm(np.linalg.inv(V)).real\n    r1 = Mm12 @ omega @ Mm12\n    s1, K = schur(r1)\n    X = np.array([[0, 1], [1, 0]])\n    I = np.identity(2)\n    seq = []\n\n    # In what follows I construct a permutation matrix p  so that the Schur matrix has\n    # only positive elements above the diagonal\n    # Also the Schur matrix uses the x_1,p_1, ..., x_n,p_n  ordering thus I use rotmat to\n    # go to the ordering x_1, ..., x_n, p_1, ... , p_n\n\n    for i in range(n):\n        if s1[2 * i, 2 * i + 1] > 0:\n            seq.append(I)\n        else:\n            seq.append(X)\n\n    p = block_diag(*seq)\n    Kt = K @ p\n    s1t = p @ s1 @ p\n    dd = np.transpose(rotmat) @ s1t @ rotmat\n    Ktt = Kt @ rotmat\n    Db = np.diag([1 / dd[i, i + n] for i in range(n)] + [1 / dd[i, i + n] for i in range(n)])\n    S = Mm12 @ Ktt @ sqrtm(Db)\n    return Db, np.linalg.inv(S).T\n\n\ndef bloch_messiah(S, tol=1e-10, rounding=9):\n    r""""""Bloch-Messiah decomposition of a symplectic matrix.\n\n    See :ref:`bloch_messiah`.\n\n    Decomposes a symplectic matrix into two symplectic unitaries and squeezing transformation.\n    It automatically sorts the squeezers so that they respect the canonical symplectic form.\n\n    Note that it is assumed that the symplectic form is\n\n    .. math:: \\Omega = \\begin{bmatrix}0&I\\\\-I&0\\end{bmatrix}\n\n    where :math:`I` is the identity matrix and :math:`0` is the zero matrix.\n\n    As in the Takagi decomposition, the singular values of N are considered\n    equal if they are equal after np.round(values, rounding).\n\n    If S is a passive transformation, then return the S as the first passive\n    transformation, and set the the squeezing and second unitary matrices to\n    identity. This choice is not unique.\n\n    For more info see:\n    https://math.stackexchange.com/questions/1886038/finding-euler-decomposition-of-a-symplectic-matrix\n\n    Args:\n        S (array[float]): symplectic matrix\n        tol (float): the tolerance used when checking if the matrix is symplectic:\n            :math:`|S^T\\Omega S-\\Omega| \\leq tol`\n        rounding (int): the number of decimal places to use when rounding the singular values\n\n    Returns:\n        tuple[array]: Returns the tuple ``(ut1, st1, vt1)``. ``ut1`` and ``vt1`` are symplectic orthogonal,\n            and ``st1`` is diagonal and of the form :math:`= \\text{diag}(s1,\\dots,s_n, 1/s_1,\\dots,1/s_n)`\n            such that :math:`S = ut1  st1  v1`\n    """"""\n    (n, m) = S.shape\n\n    if n != m:\n        raise ValueError(""The input matrix is not square"")\n    if n % 2 != 0:\n        raise ValueError(""The input matrix must have an even number of rows/columns"")\n\n    n = n // 2\n    omega = sympmat(n)\n    if np.linalg.norm(np.transpose(S) @ omega @ S - omega) >= tol:\n        raise ValueError(""The input matrix is not symplectic"")\n\n    if np.linalg.norm(np.transpose(S) @ S - np.eye(2 * n)) >= tol:\n\n        u, sigma = polar(S, side=""left"")\n        ss, uss = takagi(sigma, tol=tol, rounding=rounding)\n\n        # Apply a permutation matrix so that the squeezers appear in the order\n        # s_1,...,s_n, 1/s_1,...1/s_n\n        perm = np.array(list(range(0, n)) + list(reversed(range(n, 2 * n))))\n\n        pmat = np.identity(2 * n)[perm, :]\n        ut = uss @ pmat\n\n        # Apply a second permutation matrix to permute s\n        # (and their corresonding inverses) to get the canonical symplectic form\n        qomega = np.transpose(ut) @ (omega) @ ut\n        st = pmat @ np.diag(ss) @ pmat\n\n        # Identifying degenerate subspaces\n        result = []\n        for _k, g in groupby(np.round(np.diag(st), rounding)[:n]):\n            result.append(list(g))\n\n        stop_is = list(np.cumsum([len(res) for res in result]))\n        start_is = [0] + stop_is[:-1]\n\n        # Rotation matrices (not permutations) based on svd.\n        # See Appendix B2 of Serafini\'s book for more details.\n        u_list, v_list = [], []\n\n        for start_i, stop_i in zip(start_is, stop_is):\n            x = qomega[start_i:stop_i, n + start_i : n + stop_i].real\n            u_svd, _s_svd, v_svd = np.linalg.svd(x)\n            u_list = u_list + [u_svd]\n            v_list = v_list + [v_svd.T]\n\n        pmat1 = block_diag(*(u_list + v_list))\n\n        st1 = pmat1.T @ pmat @ np.diag(ss) @ pmat @ pmat1\n        ut1 = uss @ pmat @ pmat1\n        v1 = np.transpose(ut1) @ u\n\n    else:\n        ut1 = S\n        st1 = np.eye(2 * n)\n        v1 = np.eye(2 * n)\n\n    return ut1.real, st1.real, v1.real\n\n\ndef covmat_to_hamil(V, tol=1e-10):  # pragma: no cover\n    r""""""Converts a covariance matrix to a Hamiltonian.\n\n    Given a covariance matrix V of a Gaussian state :math:`\\rho` in the xp ordering,\n    finds a positive matrix :math:`H` such that\n\n    .. math:: \\rho = \\exp(-Q^T H Q/2)/Z\n\n    where :math:`Q = (x_1,\\dots,x_n,p_1,\\dots,p_n)` are the canonical\n    operators, and Z is the partition function.\n\n    For more details, see https://arxiv.org/abs/1507.01941\n\n    Args:\n        V (array): Gaussian covariance matrix\n        tol (int): the number of decimal places to use when determining if the matrix is symmetric\n\n    Returns:\n        array: positive definite Hamiltonian matrix\n    """"""\n    (n, m) = V.shape\n    if n != m:\n        raise ValueError(""Input matrix must be square"")\n    if np.linalg.norm(V - np.transpose(V)) >= tol:\n        raise ValueError(""The input matrix is not symmetric"")\n\n    n = n // 2\n    omega = sympmat(n)\n\n    vals = np.linalg.eigvalsh(V)\n    for val in vals:\n        if val <= 0:\n            raise ValueError(""Input matrix is not positive definite"")\n\n    W = 1j * V @ omega\n    l, v = np.linalg.eig(W)\n    H = (1j * omega @ (v @ np.diag(np.arctanh(1.0 / l.real)) @ np.linalg.inv(v))).real\n\n    return H\n\n\ndef hamil_to_covmat(H, tol=1e-10):  # pragma: no cover\n    r""""""Converts a Hamiltonian matrix to a covariance matrix.\n\n    Given a Hamiltonian matrix of a Gaussian state H, finds the equivalent covariance matrix\n    V in the xp ordering.\n\n    For more details, see https://arxiv.org/abs/1507.01941\n\n    Args:\n        H (array): positive definite Hamiltonian matrix\n        tol (int): the number of decimal places to use when determining if the Hamiltonian is symmetric\n\n    Returns:\n        array: Gaussian covariance matrix\n    """"""\n    (n, m) = H.shape\n    if n != m:\n        raise ValueError(""Input matrix must be square"")\n    if np.linalg.norm(H - np.transpose(H)) >= tol:\n        raise ValueError(""The input matrix is not symmetric"")\n\n    vals = np.linalg.eigvalsh(H)\n    for val in vals:\n        if val <= 0:\n            raise ValueError(""Input matrix is not positive definite"")\n\n    n = n // 2\n    omega = sympmat(n)\n\n    Wi = 1j * omega @ H\n    l, v = np.linalg.eig(Wi)\n    V = (1j * (v @ np.diag(1.0 / np.tanh(l.real)) @ np.linalg.inv(v)) @ omega).real\n    return V\n'"
strawberryfields/engine.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThis module implements :class:`BaseEngine` and its subclasses that are responsible for\ncommunicating quantum programs represented by :class:`.Program` objects\nto a backend that could be e.g., a simulator or a hardware quantum processor.\nOne can think of each BaseEngine instance as a separate quantum computation.\n""""""\nimport abc\nimport collections.abc\nimport time\nfrom typing import Optional\n\nimport numpy as np\n\nfrom strawberryfields.api import Connection, Job, Result\nfrom strawberryfields.api.job import FailedJobError\nfrom strawberryfields.logger import create_logger\nfrom strawberryfields.program import Program\n\nfrom .backends import load_backend\nfrom .backends.base import BaseBackend, NotApplicableError\n\n# for automodapi, do not include the classes that should appear under the top-level strawberryfields namespace\n__all__ = [""BaseEngine"", ""LocalEngine""]\n\n\nclass BaseEngine(abc.ABC):\n    r""""""Abstract base class for quantum program executor engines.\n\n    Args:\n        backend (str): backend short name\n        backend_options (Dict[str, Any]): keyword arguments for the backend\n    """"""\n\n    def __init__(self, backend, backend_options=None):\n        if backend_options is None:\n            backend_options = {}\n\n        #: str: short name of the backend\n        self.backend_name = backend\n        #: Dict[str, Any]: keyword arguments for the backend\n        self.backend_options = backend_options.copy()  # dict is mutable\n        #: List[Program]: list of Programs that have been run\n        self.run_progs = []\n        #: List[List[Number]]: latest measurement results, shape == (modes, shots)\n        self.samples = None\n\n        if isinstance(backend, str):\n            self.backend_name = backend\n            self.backend = load_backend(backend)\n        elif isinstance(backend, BaseBackend):\n            self.backend_name = backend.short_name\n            self.backend = backend\n        else:\n            raise TypeError(""backend must be a string or a BaseBackend instance."")\n\n    @abc.abstractmethod\n    def __str__(self):\n        """"""String representation.""""""\n\n    @abc.abstractmethod\n    def reset(self, backend_options):\n        r""""""Re-initialize the quantum computation.\n\n        Resets the state of the engine and the quantum circuit represented by the backend.\n\n        * The original number of modes is restored.\n        * All modes are reset to the vacuum state.\n        * All registers of previously run Programs are cleared of measured values.\n        * List of previously run Progams is cleared.\n\n        Note that the reset does nothing to any Program objects in existence, beyond\n        erasing the measured values.\n\n        **Example:**\n\n        .. code-block:: python\n\n            # create a program\n            prog = sf.Program(3)\n\n            with prog.context as q:\n                ops.Sgate(0.543) | q[1]\n                ops.BSgate(0.6, 0.1) | (q[2], q[0])\n\n            # create an engine\n            eng = sf.Engine(""gaussian"")\n\n        Running the engine with the above program will\n        modify the state of the statevector simulator:\n\n        >>> eng.run(prog)\n        >>> eng.backend.is_vacuum()\n        False\n\n        Resetting the engine will return the backend simulator\n        to the vacuum state:\n\n        >>> eng.reset()\n        >>> eng.backend.is_vacuum()\n        True\n\n        .. note:: The ``reset()`` method only applies to statevector backends.\n\n        Args:\n            backend_options (Dict[str, Any]): keyword arguments for the backend,\n                updating (overriding) old values\n        """"""\n        self.backend_options.update(backend_options)\n        for p in self.run_progs:\n            p._clear_regrefs()\n        self.run_progs.clear()\n        self.samples = None\n\n    def print_applied(self, print_fn=print):\n        """"""Print all the Programs run since the backend was initialized.\n\n        This will be blank until the first call to :meth:`~.LocalEngine.run`. The output may\n        differ compared to :meth:`.Program.print`, due to backend-specific\n        device compilation performed by :meth:`~.LocalEngine.run`.\n\n        **Example:**\n\n        .. code-block:: python\n\n            # create a program\n            prog = sf.Program(2)\n\n            with prog.context as q:\n                ops.S2gate(0.543) | (q[0], q[1])\n\n            # create an engine\n            eng = sf.Engine(""gaussian"")\n\n        Initially, the engine will have applied no operations:\n\n        >>> eng.print_applied()\n        None\n\n        After running the engine, we can now see the quantum\n        operations that were applied:\n\n        >>> eng.run(prog)\n        >>> eng.print_applied()\n        Run 0:\n        BSgate(0.7854, 0) | (q[0], q[1])\n        Sgate(0.543, 0) | (q[0])\n        Sgate(0.543, 0).H | (q[1])\n        BSgate(0.7854, 0).H | (q[0], q[1])\n\n        Note that the :class:`~.S2gate` has been decomposed into\n        single-mode squeezers and beamsplitters, which are supported\n        by the ``\'gaussian\'`` backend.\n\n        Subsequent program runs can also be viewed:\n\n        .. code-block:: python\n\n            # a second program\n            prog2 = sf.Program(2)\n            with prog2.context as q:\n                ops.S2gate(0.543) | (q[0], q[1])\n\n        >>> eng.run(prog2)\n        >>> eng.print_applied()\n        Run 0:\n        BSgate(0.7854, 0) | (q[0], q[1])\n        Sgate(0.543, 0) | (q[0])\n        Sgate(0.543, 0).H | (q[1])\n        BSgate(0.7854, 0).H | (q[0], q[1])\n        Run 1:\n        Dgate(0.06, 0) | (q[0])\n\n        Args:\n            print_fn (function): optional custom function to use for string printing.\n        """"""\n        for k, r in enumerate(self.run_progs):\n            print_fn(""Run {}:"".format(k))\n            r.print(print_fn)\n\n    @abc.abstractmethod\n    def _init_backend(self, init_num_subsystems):\n        """"""Initialize the backend.\n\n        Args:\n            init_num_subsystems (int): number of subsystems the backend is initialized to\n        """"""\n\n    @abc.abstractmethod\n    def _run_program(self, prog, **kwargs):\n        """"""Execute a single program on the backend.\n\n        This method should not be called directly.\n\n        Args:\n            prog (Program): program to run\n        Returns:\n            list[Command]: commands that were applied to the backend\n        """"""\n\n    def _run(self, program, *, args, compile_options, **kwargs):\n        """"""Execute the given programs by sending them to the backend.\n\n        If multiple Programs are given they will be executed sequentially as\n        parts of a single computation.\n        For each :class:`.Program` instance given as input, the following happens:\n\n        * The Program instance is compiled for the target backend.\n        * The compiled program is executed on the backend.\n        * The measurement results of each subsystem (if any) are stored in the :class:`.RegRef`\n          instances of the corresponding Program, as well as in :attr:`~BaseEngine.samples`.\n        * The compiled program is appended to :attr:`~BaseEngine.run_progs`.\n\n        Finally, the result of the computation is returned.\n\n        Args:\n            program (Program, Sequence[Program]): quantum programs to run\n            args (Dict[str, Any]): values for the free parameters in the program(s) (if any)\n            compile_options (Dict[str, Any]): keyword arguments for :meth:`.Program.compile`\n\n        The ``kwargs`` keyword arguments are passed to the backend API calls via :meth:`Operation.apply`.\n\n        Returns:\n            Result: results of the computation\n        """"""\n\n        def _broadcast_nones(val, dim):\n            """"""Helper function to ensure register values have same shape, even if not measured""""""\n            if val is None and dim > 1:\n                return [None] * dim\n            return val\n\n        if not isinstance(program, collections.abc.Sequence):\n            program = [program]\n\n        kwargs.setdefault(""shots"", 1)\n        # NOTE: by putting ``shots`` into keyword arguments, it allows for the\n        # signatures of methods in Operations to remain cleaner, since only\n        # Measurements need to know about shots\n\n        prev = self.run_progs[-1] if self.run_progs else None  # previous program segment\n        for p in program:\n            if prev is None:\n                # initialize the backend\n                self._init_backend(p.init_num_subsystems)\n            else:\n                # there was a previous program segment\n                if not p.can_follow(prev):\n                    raise RuntimeError(\n                        ""Register mismatch: program {}, \'{}\'."".format(len(self.run_progs), p.name)\n                    )\n\n                # Copy the latest measured values in the RegRefs of p.\n                # We cannot copy from prev directly because it could be used in more than one\n                # engine.\n                for k, v in enumerate(self.samples):\n                    p.reg_refs[k].val = v\n\n            # bind free parameters to their values\n            p.bind_params(args)\n\n            # if the program hasn\'t been compiled for this backend, do it now\n            target = self.backend.circuit_spec\n            if target is not None and p.target != target:\n                p = p.compile(target, **compile_options)\n            p.lock()\n\n            self._run_program(p, **kwargs)\n            shots = kwargs.get(""shots"", 1)\n            self.samples = [_broadcast_nones(p.reg_refs[k].val, shots) for k in sorted(p.reg_refs)]\n            self.run_progs.append(p)\n\n            prev = p\n\n        if self.samples is not None:\n            return Result(np.array(self.samples).T)\n\n\nclass LocalEngine(BaseEngine):\n    """"""Local quantum program executor engine.\n\n    The Strawberry Fields engine is used to execute :class:`.Program` instances\n    on the chosen local backend, and makes the results available via :class:`.Result`.\n\n    **Example:**\n\n    The following example creates a Strawberry Fields\n    quantum :class:`~.Program` and runs it using an engine.\n\n    .. code-block:: python\n\n        # create a program\n        prog = sf.Program(2)\n\n        with prog.context as q:\n            ops.S2gate(0.543) | (q[0], q[1])\n\n    We initialize the engine with the name of the local backend,\n    and can pass optional backend options.\n\n    >>> eng = sf.Engine(""fock"", backend_options={""cutoff_dim"": 5})\n\n    The :meth:`~.LocalEngine.run` method is used to execute quantum\n    programs on the attached backend, and returns a :class:`.Result`\n    object containing the results of the execution.\n\n    >>> results = eng.run(prog)\n\n    Args:\n        backend (str, BaseBackend): short name of the backend, or a pre-constructed backend instance\n        backend_options (None, Dict[str, Any]): keyword arguments to be passed to the backend\n    """"""\n\n    def __init__(self, backend, *, backend_options=None):\n        backend_options = backend_options or {}\n        super().__init__(backend, backend_options)\n\n    def __str__(self):\n        return self.__class__.__name__ + ""({})"".format(self.backend_name)\n\n    def reset(self, backend_options=None):\n        backend_options = backend_options or {}\n        super().reset(backend_options)\n        self.backend.reset(**self.backend_options)\n        # TODO should backend.reset and backend.begin_circuit be combined?\n\n    def _init_backend(self, init_num_subsystems):\n        self.backend.begin_circuit(init_num_subsystems, **self.backend_options)\n\n    def _run_program(self, prog, **kwargs):\n        applied = []\n        for cmd in prog.circuit:\n            try:\n                # try to apply it to the backend\n                # NOTE we could also handle storing measured vals here\n                cmd.op.apply(cmd.reg, self.backend, **kwargs)\n                applied.append(cmd)\n            except NotApplicableError:\n                # command is not applicable to the current backend type\n                raise NotApplicableError(\n                    ""The operation {} cannot be used with {}."".format(cmd.op, self.backend)\n                ) from None\n            except NotImplementedError:\n                # command not directly supported by backend API\n                raise NotImplementedError(\n                    ""The operation {} has not been implemented in {} for the arguments {}."".format(\n                        cmd.op, self.backend, kwargs\n                    )\n                ) from None\n        return applied\n\n    def run(self, program, *, args=None, compile_options=None, **kwargs):\n        """"""Execute quantum programs by sending them to the backend.\n\n        Args:\n            program (Program, Sequence[Program]): quantum programs to run\n            args (dict[str, Any]): values for the free parameters in the program(s) (if any)\n            compile_options (None, Dict[str, Any]): keyword arguments for :meth:`.Program.compile`\n\n        Keyword Args:\n            shots (int): number of times the program measurement evaluation is repeated\n            modes (None, Sequence[int]): Modes to be returned in the ``Result.state`` :class:`.BaseState` object.\n                ``None`` returns all the modes (default). An empty sequence means no state object is returned.\n\n        Returns:\n            Result: results of the computation\n        """"""\n        args = args or {}\n        compile_options = compile_options or {}\n        temp_run_options = {}\n\n        if isinstance(program, collections.abc.Sequence):\n            # succesively update all run option defaults.\n            # the run options of successive programs\n            # overwrite the run options of previous programs\n            # in the list\n            program_lst = program\n            for p in program:\n                temp_run_options.update(p.run_options)\n        else:\n            # single program to execute\n            program_lst = [program]\n            temp_run_options.update(program.run_options)\n\n        temp_run_options.update(kwargs or {})\n        temp_run_options.setdefault(""shots"", 1)\n        temp_run_options.setdefault(""modes"", None)\n\n        # avoid unexpected keys being sent to Operations\n        eng_run_keys = [""eval"", ""session"", ""feed_dict"", ""shots""]\n        eng_run_options = {\n            key: temp_run_options[key] for key in temp_run_options.keys() & eng_run_keys\n        }\n\n        # check that batching is not used together with shots > 1\n        if self.backend_options.get(""batch_size"", 0) and eng_run_options[""shots""] > 1:\n            raise NotImplementedError(""Batching cannot be used together with multiple shots."")\n\n        # check that post-selection and feed-forwarding is not used together with shots > 1\n        for p in program_lst:\n            for c in p.circuit:\n                try:\n                    if c.op.select and eng_run_options[""shots""] > 1:\n                        raise NotImplementedError(\n                            ""Post-selection cannot be used together with multiple shots.""\n                        )\n                except AttributeError:\n                    pass\n\n                if c.op.measurement_deps and eng_run_options[""shots""] > 1:\n                    raise NotImplementedError(\n                        ""Feed-forwarding of measurements cannot be used together with multiple shots.""\n                    )\n\n        result = super()._run(\n            program, args=args, compile_options=compile_options, **eng_run_options\n        )\n\n        modes = temp_run_options[""modes""]\n\n        if modes is None or modes:\n            # state object requested\n            # session and feed_dict are needed by TF backend both during simulation (if program\n            # contains measurements) and state object construction.\n            result._state = self.backend.state(**temp_run_options)\n\n        return result\n\n\nclass RemoteEngine:\n    """"""A quantum program executor engine that provides a simple interface for\n    running remote jobs in a blocking or non-blocking manner.\n\n    **Example:**\n\n    The following examples instantiate an engine with the default configuration, and\n    run both blocking and non-blocking jobs.\n\n    Run a blocking job:\n\n    >>> engine = RemoteEngine(""X8_01"")\n    >>> result = engine.run(program, shots=1) # blocking call\n    >>> result\n    [[0 1 0 2 1 0 0 0]]\n\n    Run a non-blocking job:\n\n    >>> job = engine.run_async(program, shots=1)\n    >>> job.status\n    ""queued""\n    >>> job.result\n    InvalidJobOperationError\n    >>> job.refresh()\n    >>> job.status\n    ""complete""\n    >>> job.result\n    [[0 1 0 2 1 0 0 0]]\n\n    Args:\n        target (str): the target device\n        connection (strawberryfields.api.Connection): a connection to the remote job\n            execution platform\n        backend_options (Dict[str, Any]): keyword arguments for the backend\n    """"""\n\n    POLLING_INTERVAL_SECONDS = 1\n    VALID_TARGETS = (""X8_01"", ""X12_01"", ""X12_02"")\n    DEFAULT_TARGETS = {""X8"": ""X8_01"", ""X12"": ""X12_01""}\n\n    def __init__(self, target: str, connection: Connection = None, backend_options: dict = None):\n        self._target = self.DEFAULT_TARGETS.get(target, target)\n\n        if self._target not in self.VALID_TARGETS:\n            raise ValueError(\n                ""Invalid engine target: {} (valid targets: {})"".format(\n                    target, tuple(self.DEFAULT_TARGETS.keys()) + self.VALID_TARGETS\n                )\n            )\n\n        self._connection = connection or Connection()\n        self._backend_options = backend_options or {}\n        self.log = create_logger(__name__)\n\n    @property\n    def target(self) -> str:\n        """"""The target device used by the engine.\n\n        Returns:\n            str: the name of the target\n        """"""\n        return self._target\n\n    @property\n    def connection(self) -> Connection:\n        """"""The connection object used by the engine.\n\n        Returns:\n            strawberryfields.api.Connection\n        """"""\n        return self._connection\n\n    def run(self, program: Program, *, compile_options=None, **kwargs) -> Optional[Result]:\n        """"""Runs a blocking job.\n\n        In the blocking mode, the engine blocks until the job is completed, failed, or\n        cancelled. A job in progress can be cancelled with a keyboard interrupt (`ctrl+c`).\n\n        If the job completes successfully, the result is returned; if the job\n        fails or is cancelled, ``None`` is returned.\n\n        Args:\n            program (strawberryfields.Program): the quantum circuit\n\n        Keyword Args:\n            shots (Optional[int]): The number of shots for which to run the job. If this\n                argument is not provided, the shots are derived from the given ``program``.\n\n        Returns:\n            [strawberryfields.api.Result, None]: the job result if successful, and\n            ``None`` otherwise\n        """"""\n        job = self.run_async(program, compile_options=compile_options, **kwargs)\n        try:\n            while True:\n                job.refresh()\n                if job.status == ""complete"":\n                    self.log.info(""The remote job %s has been completed."", job.id)\n                    return job.result\n\n                if job.status == ""failed"":\n                    message = (\n                        ""The remote job {} failed due to an internal ""\n                        ""server error. Please try again. {}"".format(job.id, job.meta)\n                    )\n                    self.log.error(message)\n\n                    raise FailedJobError(message)\n\n                time.sleep(self.POLLING_INTERVAL_SECONDS)\n        except KeyboardInterrupt:\n            self._connection.cancel_job(job.id)\n            raise KeyboardInterrupt(""The job has been cancelled."")\n\n    def run_async(self, program: Program, *, compile_options=None, **kwargs) -> Job:\n        """"""Runs a non-blocking remote job.\n\n        In the non-blocking mode, a ``Job`` object is returned immediately, and the user can\n        manually refresh the status and check for updated results of the job.\n\n        Args:\n            program (strawberryfields.Program): the quantum circuit\n            compile_options (None, Dict[str, Any]): keyword arguments for :meth:`.Program.compile`\n\n        Keyword Args:\n            shots (Optional[int]): The number of shots for which to run the job. If this\n                argument is not provided, the shots are derived from the given ``program``.\n\n        Returns:\n            strawberryfields.api.Job: the created remote job\n        """"""\n        # get the specific chip to submit the program to\n        # TODO: this should be provided by the chip API, rather\n        # than built-in to Strawberry Fields.\n        compile_options = compile_options or {}\n        kwargs.update(self._backend_options)\n\n        if program.target is None or (program.target.split(""_"")[0] != self.target.split(""_"")[0]):\n            # Program is either:\n            #\n            # * uncompiled (program.target is None)\n            # * compiled to a different chip family to the engine target\n            #\n            # In both cases, recompile the program to match the intended target.\n            program = program.compile(self.target, **compile_options)\n\n        # update the run options if provided\n        run_options = {}\n        run_options.update(program.run_options)\n        run_options.update(kwargs or {})\n\n        if ""shots"" not in run_options:\n            raise ValueError(""Number of shots must be specified."")\n\n        return self._connection.create_job(self.target, program, run_options)\n\n    def __repr__(self):\n        return ""<{}: target={}, connection={}>"".format(\n            self.__class__.__name__, self.target, self.connection\n        )\n\n    def __str__(self):\n        return self.__repr__()\n\n\nclass Engine(LocalEngine):\n    """"""dummy""""""\n\n    # alias for backwards compatibility\n    __doc__ = LocalEngine.__doc__\n'"
strawberryfields/io.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThis module contains functions for loading and saving Strawberry\nFields :class:`~.Program` objects from/to Blackbird scripts.\n""""""\n# pylint: disable=protected-access,too-many-nested-blocks\nimport os\n\nimport blackbird\n\nimport strawberryfields.program as sfp\nimport strawberryfields.parameters as sfpar\nfrom . import ops\n\n\n# for automodapi, do not include the classes that should appear under the top-level strawberryfields namespace\n__all__ = [""to_blackbird"", ""to_program"", ""loads""]\n\n\ndef to_blackbird(prog, version=""1.0""):\n    """"""Convert a Strawberry Fields Program to a Blackbird Program.\n\n    Args:\n        prog (Program): the Strawberry Fields program\n        version (str): Blackbird script version number\n\n    Returns:\n        blackbird.BlackbirdProgram:\n    """"""\n    bb = blackbird.BlackbirdProgram(name=prog.name, version=version)\n\n    # TODO not sure if this makes sense: the program has *already been* compiled using this target\n    if prog.target is not None:\n        # set the target\n        bb._target[""name""] = prog.target\n\n        # set the run options\n        if prog.run_options:\n            bb._target[""options""].update(prog.run_options)\n\n        if prog.backend_options:\n            bb._target[""options""].update(prog.backend_options)\n\n    # fill in the quantum circuit\n    for cmd in prog.circuit:\n        op = {""kwargs"": {}, ""args"": []}\n\n        op[""op""] = cmd.op.__class__.__name__\n        op[""modes""] = [i.ind for i in cmd.reg]\n\n        if ""Measure"" in op[""op""]:\n            # special case to take into account \'select\' keyword argument\n            if cmd.op.select is not None:\n                op[""kwargs""][""select""] = cmd.op.select\n\n            if cmd.op.p:\n                # argument is quadrature phase\n                op[""kwargs""][""phi""] = cmd.op.p[0]\n\n            if op[""op""] == ""MeasureFock"":\n                # special case to take into account \'dark_counts\' keyword argument\n                if cmd.op.dark_counts is not None:\n                    op[""kwargs""][""dark_counts""] = cmd.op.dark_counts\n\n        else:\n            for a in cmd.op.p:\n                if sfpar.par_is_symbolic(a):\n                    # SymPy object, convert to string\n                    a = str(a)\n                op[""args""].append(a)\n\n        bb._operations.append(op)\n\n    return bb\n\n\ndef to_program(bb):\n    """"""Convert a Blackbird Program to a Strawberry Fields Program.\n\n    Args:\n        bb (blackbird.BlackbirdProgram): the input Blackbird program object\n\n    Returns:\n        Program: corresponding SF program\n    """"""\n    # create a SF program\n    if not bb.modes:\n        # we can\'t return an empty program, since we don\'t know how many modes\n        # to initialize the Program object with.\n        raise ValueError(""Blackbird program contains no quantum operations!"")\n\n    prog = sfp.Program(max(bb.modes) + 1, name=bb.name)\n\n    # append the quantum operations\n    with prog.context as q:\n        for op in bb.operations:\n            # check if operation name is in the list of\n            # defined StrawberryFields operations.\n            # This is used by checking against the ops.py __all__\n            # module attribute, which contains the names\n            # of all defined quantum operations\n            if op[""op""] in ops.__all__:\n                # get the quantum operation from the sf.ops module\n                gate = getattr(ops, op[""op""])\n            else:\n                raise NameError(""Quantum operation {} not defined!"".format(op[""op""]))\n\n            # create the list of regrefs\n            regrefs = [q[i] for i in op[""modes""]]\n\n            if ""args"" in op:\n                # the gate has arguments\n                args = op[""args""]\n                kwargs = op[""kwargs""]\n\n                # Convert symbolic expressions in args/kwargs containing measured and free parameters to\n                # symbolic expressions containing the corresponding MeasuredParameter and FreeParameter instances.\n                args = sfpar.par_convert(args, prog)\n                vals = sfpar.par_convert(kwargs.values(), prog)\n                kwargs = dict(zip(kwargs.keys(), vals))\n                gate(*args, **kwargs) | regrefs  # pylint:disable=expression-not-assigned\n            else:\n                # the gate has no arguments\n                gate | regrefs  # pylint:disable=expression-not-assigned,pointless-statement\n\n    # compile the program if a compile target is given\n    targ = bb.target\n    if targ[""name""] is not None:\n        prog = prog.compile(targ[""name""], **targ[""options""])\n\n    return prog\n\n\ndef save(f, prog):\n    """"""Saves a quantum program to a Blackbird .xbb file.\n\n    **Example:**\n\n    .. code-block:: python3\n\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Sgate(0.543) | q[1]\n            ops.BSgate(0.6, 0.1) | (q[2], q[0])\n            ops.MeasureFock() | q\n\n        sf.save(""program1.xbb"", prog)\n\n    This will create the following Blackbird file:\n\n    .. code-block:: pycon\n\n        >>> f = open(""program1.xbb"").read()\n        >>> print(f)\n        name None\n        version 1.0\n\n        Sgate(0.543, 0.0) | 1\n        BSgate(0.6, 0.1) | [2, 0]\n        MeasureFock() | [0, 1, 2]\n\n    Args:\n        f (Union[file, str, pathlib.Path]): File or filename to which\n            the data is saved. If file is a file-object, then the filename\n            is unchanged. If file is a string or Path, a .xbb extension will\n            be appended to the file name if it does not already have one.\n        prog (Program): Strawberry Fields program\n    """"""\n    own_file = False\n    bb = to_blackbird(prog).serialize()\n\n    if hasattr(f, ""read""):\n        # argument file is a file-object\n        fid = f\n    else:\n        # argument file is a string or Path\n        filename = os.fspath(f)\n\n        if not filename.endswith("".xbb""):\n            filename = filename + "".xbb""\n\n        fid = open(filename, ""w"")\n\n        # this function owns the open file,\n        # must remember to safely close it.\n        own_file = True\n\n    try:\n        fid.write(bb)\n    finally:\n        if own_file:\n            # safely close the file\n            fid.close()\n\n\ndef loads(s):\n    """"""Load a quantum program from a string.\n\n    Args:\n        s (str): string containing the Blackbird circuit\n    Returns:\n        prog (Program): Strawberry Fields program\n\n    """"""\n    bb = blackbird.loads(s)\n    return to_program(bb)\n\n\ndef load(f):\n    """"""Load a quantum program from a Blackbird .xbb file.\n\n    **Example:**\n\n    The following Blackbird file, ``program1.xbb``,\n\n    .. code-block:: python3\n\n        name test_program\n        version 1.0\n\n        Sgate(0.543, 0.0) | 1\n        BSgate(0.6, 0.1) | [2, 0]\n        MeasureFock() | [0, 1, 2]\n\n    can be imported into Strawberry Fields using the ``loads``\n    function:\n\n    >>> sf.loads(""program1.xbb"")\n    >>> prog.name\n    \'test_program\'\n    >>> prog.num_subsystems\n    3\n    >>> prog.print()\n    Sgate(0.543, 0) | (q[1])\n    BSgate(0.6, 0.1) | (q[2], q[0])\n    MeasureFock | (q[0], q[1], q[2])\n\n    Args:\n        f (Union[file, str, pathlib.Path]): File or filename from which\n            the data is loaded. If file is a string or Path, a value with the\n            .xbb extension is expected.\n\n    Returns:\n        prog (Program): Strawberry Fields program\n    """"""\n    own_file = False\n\n    try:\n        if hasattr(f, ""read""):\n            # argument file is a file-object\n            fid = f\n        else:\n            # argument file is a Path or string\n            filename = os.fspath(f)\n            fid = open(filename, ""r"")\n            own_file = True\n\n    except TypeError:\n        raise ValueError(""file must be a string, pathlib.Path, or file-like object"")\n\n    try:\n        bb_str = fid.read()\n    finally:\n        if own_file:\n            # safely close the file\n            fid.close()\n\n    # load blackbird program\n    return loads(bb_str)\n'"
strawberryfields/logger.py,0,"b'# Copyright 2010 Pallets\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright notice,\n#    this list of conditions and the following disclaimer.\n# 2. Redistributions in binary form must reproduce the above copyright notice,\n#    this list of conditions and the following disclaimer in the documentation\n#    and/or other materials provided with the distribution.\n# 3. Neither the name of the copyright holder nor the names of its contributors\n#    may be used to endorse or promote products derived from this software\n#    without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\n# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThis module contains functions for creating a logger that can be used in Strawberry\nFields.\n\nThe implementation in this module is based on the solution for logging used in\nthe Flask web application framework:\nhttps://github.com/pallets/flask/blob/master/src/flask/logging.py\n""""""\n\nimport logging\nimport sys\n\n\ndef logging_handler_defined(logger):\n    """"""Checks if the logger or any of its ancestors has a handler defined.\n\n    The output depends on whether or not propagation was set for the logger.\n\n    Args:\n        logger (logging.Logger): the logger to check\n\n    Returns:\n        bool: whether or not a handler was defined\n    """"""\n    current = logger\n\n    while current:\n        if current.handlers:\n            return True\n\n        if not current.propagate:\n            break\n\n        current = current.parent\n\n    return False\n\n\ndefault_handler = logging.StreamHandler(sys.stderr)\nformatter = logging.Formatter(""%(asctime)s - %(levelname)s - %(message)s"")\ndefault_handler.setFormatter(formatter)\n\n\ndef create_logger(name, level=logging.INFO):\n    """"""Get the Strawberry Fields module specific logger and configure it if needed.\n\n    Configuration only takes place if no user configuration was applied to the\n    logger. Therefore, the logger is configured if and only if the following\n    are true:\n\n    - the logger has WARNING as effective level,\n    - the level of the logger was not explicitly set,\n    - no handlers were added to the logger.\n\n    As the root logger has a WARNING level by default, any module specific\n    logger will inherit the same as effective level.\n\n    The default handler that is used for configuration writes to the standard\n    error stream and uses a datetime and level formatter.\n\n    Args:\n        name (str): the name of the module for which the logger is being created\n        level (logging.level): the logging level to set for the logger\n    """"""\n    logger = logging.getLogger(name)\n\n    effective_level_inherited = logger.getEffectiveLevel() == logging.WARNING\n    level_not_set = not logger.level\n    no_handlers = not logging_handler_defined(logger)\n\n    if effective_level_inherited and level_not_set and no_handlers:\n        logger.setLevel(level)\n        logger.addHandler(default_handler)\n\n    return logger\n'"
strawberryfields/ops.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nThis module defines and implements the Python-embedded quantum programming language\nfor continuous-variable (CV) quantum systems.\nThe syntax is modeled after ProjectQ :cite:`projectq2016`.\n""""""\nfrom collections.abc import Sequence\nimport copy\nimport warnings\n\nimport numpy as np\n\nfrom scipy.linalg import block_diag\nimport scipy.special as ssp\n\nimport strawberryfields as sf\nimport strawberryfields.program_utils as pu\nimport strawberryfields.decompositions as dec\nfrom .backends.states import BaseFockState, BaseGaussianState\nfrom .backends.shared_ops import changebasis\nfrom .program_utils import Command, RegRef, MergeFailure\nfrom .parameters import par_regref_deps, par_str, par_evaluate, par_is_symbolic, par_funcs as pf\n\n# pylint: disable=abstract-method\n# pylint: disable=protected-access\n# pylint: disable=arguments-differ  # Measurement._apply introduces the ""shots"" argument\n\n# numerical tolerances\n_decomposition_merge_tol = 1e-13\n_decomposition_tol = (\n    1e-13  # TODO this tolerance is used for various purposes and is not well-defined\n)\n\n# data type to use for complex arrays\nCOMPLEX_DTYPE = np.complex128\n\n\ndef evaluate_complex_parameter(p, phase):\n    """"""Convenience function for evaluating symbolic arguments\n    with potentially batched phase parameters.\n\n    Args:\n        p (Any): parameters\n        phase (Any): complex phase of parameter ``p``\n\n    """"""\n    # We need to check if any value of the phase is non-zero,\n    # as the phase might be batched.\n    if np.any(phase != 0):\n        # There exists a non-zero phase; cast the parameter\n        # to a complex data type when evaluating it.\n        return par_evaluate(p, dtype=COMPLEX_DTYPE)\n\n    # All phases are zero; evaluate the parameter without\n    # any additional casting.\n    return par_evaluate(p)\n\n\ndef warning_on_one_line(message, category, filename, lineno, file=None, line=None):\n    """"""User warning formatter""""""\n    # pylint: disable=unused-argument\n    return ""{}:{}: {}: {}\\n"".format(filename, lineno, category.__name__, message)\n\n\nwarnings.formatwarning = warning_on_one_line\n\n\ndef _seq_to_list(s):\n    ""Converts a Sequence or a single object into a list.""\n    if not isinstance(s, Sequence):\n        s = [s]\n    return list(s)\n\n\nclass Operation:\n    """"""Abstract base class for quantum operations acting on one or more subsystems.\n\n    :attr:`Operation.measurement_deps` is a set containing the :class:`.RegRef`\n    the :class:`Operation` depends on through its parameters.\n    In the quantum circuit diagram notation it corresponds to the vertical double lines of classical\n    information entering the :class:`Operation` that originate in the measurement of a subsystem.\n\n    This abstract base class may be initialised with parameters; see the\n    :class:`~strawberryfields.parameters.Parameter` class for more details.\n\n    Args:\n        par (Sequence[Any]): Operation parameters. An empty sequence if no parameters\n            are required.\n    """"""\n\n    # default: one-subsystem operation\n    #: int: number of subsystems the operation acts on, or None if any number > 0 is ok\n    ns = 1\n\n    def __init__(self, par):\n        #: set[RegRef]: extra dependencies due to deferred measurements, used during optimization\n        self._measurement_deps = set()\n        #: list[Parameter]: operation parameters\n        self.p = []\n\n        # convert each parameter into a Parameter instance, keep track of dependenciens\n        for q in par:\n            if isinstance(q, RegRef):\n                raise TypeError(""Use RegRef.par for measured parameters."")\n            self.p.append(q)\n            self._measurement_deps |= par_regref_deps(q)\n\n    def __str__(self):\n        """"""String representation for the Operation using Blackbird syntax.\n\n        Returns:\n            str: string representation\n        """"""\n        # defaults to the class name\n        if not self.p:\n            return self.__class__.__name__\n\n        # class name and parameter values\n        temp = [par_str(i) for i in self.p]\n        return self.__class__.__name__ + ""("" + "", "".join(temp) + "")""\n\n    @property\n    def measurement_deps(self):\n        """"""Extra dependencies due to parameters that depend on measurements.\n\n        Returns:\n            set[RegRef]: dependencies\n        """"""\n        return self._measurement_deps\n\n    def __or__(self, reg):\n        """"""Apply the operation to a part of a quantum register.\n\n        Appends the Operation to a :class:`.Program` instance.\n\n        Args:\n            reg (RegRef, Sequence[RegRef]): subsystem(s) the operation is acting on\n\n        Returns:\n            list[RegRef]: subsystem list as RegRefs\n        """"""\n        # into a list of subsystems\n        reg = _seq_to_list(reg)\n        if (not reg) or (self.ns is not None and self.ns != len(reg)):\n            raise ValueError(""Wrong number of subsystems."")\n        # append it to the Program\n        reg = pu.Program_current_context.append(self, reg)\n        return reg\n\n    def merge(self, other):\n        """"""Merge the operation with another (acting on the exact same set of subsystems).\n\n        .. note:: For subclass overrides: merge may return a newly created object,\n           or self, or other, but it must never modify self or other\n           because the same Operation objects may be also used elsewhere.\n\n        Args:\n            other (Operation): operation to merge this one with\n\n        Returns:\n            Operation, None: other * self. The return value None represents\n            the identity gate (doing nothing).\n\n        Raises:\n            .MergeFailure: if the two operations cannot be merged\n        """"""\n        # todo: Using the return value None to denote the identity is a\n        # bit dangerous, since a function with no explicit return statement\n        # also returns None, which can lead to puzzling bugs. Maybe return\n        # a special singleton Identity object instead?\n        raise NotImplementedError\n\n    def decompose(self, reg, **kwargs):\n        """"""Decompose the operation into elementary operations supported by the backend API.\n\n        See :mod:`strawberryfields.backends.base`.\n\n        Args:\n            reg (Sequence[RegRef]): subsystems the operation is acting on\n\n        Returns:\n            list[Command]: decomposition as a list of operations acting on specific subsystems\n        """"""\n        return self._decompose(reg, **kwargs)\n\n    def _decompose(self, reg, **kwargs):\n        """"""Internal decomposition method defined by subclasses.\n\n        NOTE: Does not evaluate Operation parameters, symbolic parameters remain symbolic.\n\n        Args:\n            reg (Sequence[RegRef]): subsystems the operation is acting on\n\n        Returns:\n            list[Command]: decomposition as a list of operations acting on specific subsystems\n        """"""\n        raise NotImplementedError(""No decomposition available: {}"".format(self))\n\n    def _apply(self, reg, backend, **kwargs):\n        """"""Internal apply method. Uses numeric subsystem referencing.\n\n        Args:\n            reg (Sequence[int]): subsystem indices the operation is\n                acting on (this is how the backend API wants them)\n            backend (BaseBackend): backend to execute the operation\n\n        Returns:\n            array[Number] or None: Measurement results, if any; shape == (len(reg), shots).\n        """"""\n        raise NotImplementedError(""Missing direct implementation: {}"".format(self))\n\n    def apply(self, reg, backend, **kwargs):\n        """"""Ask a local backend to execute the operation on the current register state right away.\n\n        Takes care of parameter evaluations and any pending formal\n        transformations (like dagger) and then calls :meth:`Operation._apply`.\n\n        Args:\n            reg (Sequence[RegRef]): subsystem(s) the operation is acting on\n            backend (BaseBackend): backend to execute the operation\n\n        Returns:\n            Any: the result of self._apply\n        """"""\n        # NOTE: We cannot just replace all parameters with their evaluated\n        # numerical values here. If we re-initialize a measured mode and\n        # re-measure it, the corresponding MeasuredParameter value should change accordingly\n        # when it is used again after the new measurement.\n\n        # convert RegRefs back to indices for the backend API\n        temp = [rr.ind for rr in reg]\n        # call the child class specialized _apply method\n        return self._apply(temp, backend, **kwargs)\n\n\n# ====================================================================\n# Derived operation classes\n# ====================================================================\n\n\nclass Preparation(Operation):\n    """"""Abstract base class for operations that demolish\n    the previous state of the subsystem entirely.\n    """"""\n\n    def merge(self, other):\n        # sequential preparation, only the last one matters\n        if isinstance(other, Preparation):\n            # give a warning, since this is pointless and probably a user error\n            warnings.warn(""Two subsequent state preparations, first one has no effect."")\n            return other\n\n        raise MergeFailure(""For now, Preparations cannot be merged with anything else."")\n\n\nclass Measurement(Operation):\n    """"""Abstract base class for subsystem measurements.\n\n    The measurement is deferred: its result is available only\n    after the backend has executed it. The value of the measurement can\n    be accessed in the program through the symbolic subsystem reference\n    to the measured subsystem.\n\n    When the measurement happens, the state of the system is updated\n    to the conditional state corresponding to the measurement result.\n    Measurements also support postselection, see below.\n\n    Args:\n        select (None, Sequence[Number]): Desired values of the measurement\n            results, one for each subsystem the measurement acts on.\n            Allows the post-selection of specific measurement results\n            instead of randomly sampling. None means no postselection.\n    """"""\n\n    # todo: self.select could support :class:`~strawberryfields.parameters.Parameter` instances.\n    ns = None\n\n    def __init__(self, par, select=None):\n        super().__init__(par)\n        #: None, Sequence[Number]: postselection values, one for each measured subsystem\n        self.select = select\n\n    def __str__(self):\n        # class name, parameter values, and possibly the select parameter\n        temp = super().__str__()\n\n        if self.select is not None:\n            if not self.p:\n                temp += f""(select={self.select})""\n            else:\n                temp = f""{temp[:-1]}, select={self.select})""\n\n        return temp\n\n    def merge(self, other):\n        raise MergeFailure(""For now, measurements cannot be merged with anything else."")\n\n    def apply(self, reg, backend, **kwargs):\n        """"""Ask a backend to execute the operation on the current register state right away.\n\n        Like :func:`Operation.apply`, but also stores the measurement result in the RegRefs.\n\n        Keyword Args:\n            shots (int): Number of independent evaluations to perform.\n                Only applies to Measurements.\n        """"""\n        values = super().apply(reg, backend, **kwargs)\n        # convert the returned values into an iterable with the measured modes indexed along\n        # the first axis and shots along second axis (if larger than 1), so that we can assign\n        # register values\n        shots = kwargs.get(""shots"", 1)\n        if self.ns == 1:\n            values = [values]  # values is either a scalar, or has shape (shots,)\n        else:\n            if shots > 1:\n                values = values.T  # shape of values would be (shots, num_meas,)\n\n        # store the results in the register reference objects\n        for v, r in zip(values, reg):\n            r.val = v\n\n\nclass Decomposition(Operation):\n    """"""Abstract base class for multimode matrix transformations.\n\n    This class provides the base behaviour for decomposing various multimode operations\n    into a sequence of gates and state preparations.\n\n    .. note:: The first parameter ``p[0]`` of a Decomposition is always a square matrix, and it cannot be symbolic.\n    """"""\n\n    ns = None  # overridden by child classes in __init__\n\n    @staticmethod\n    def _check_p0(p0):\n        """"""Checks that p0 is not symbolic.""""""\n        if par_is_symbolic(p0):\n            raise TypeError(\n                ""The first parameter of a Decomposition is a square matrix, and cannot be symbolic.""\n            )\n\n    def __init__(self, par, decomp=True):\n        self._check_p0(par[0])\n        super().__init__(par)\n        self.decomp = decomp\n        """"""bool: If False, try to apply the Decomposition as a single primitive operation\n        instead of decomposing it.""""""\n\n    def merge(self, other):\n        # can be merged if they are the same class\n        if isinstance(other, self.__class__):\n            # at the moment, we will assume all state decompositions only\n            # take one argument. The only exception currently are state\n            # decompositions, which cannot be merged.\n            U1 = self.p[0]\n            U2 = other.p[0]\n            U = U2 @ U1\n            # Note: above we strip the Parameter wrapper to make the following check\n            # easier to perform. The constructor restores it.\n            # Another option would be to add the required methods to Parameter class.\n            # check if the matrices cancel\n            if np.allclose(U, np.identity(len(U)), atol=_decomposition_merge_tol, rtol=0):\n                return None\n\n            return self.__class__(U)\n\n        raise MergeFailure(""Not the same decomposition type."")\n\n\nclass Transformation(Operation):\n    """"""Abstract base class for transformations.\n\n    This class provides the base behaviour for operations which\n    act on existing states.\n    """"""\n\n    # NOTE: At the moment this is an empty class, and only\n    # exists for a nicer inheritence diagram. One option is\n    # to remove, and make Channel and Gate top-level derived classes.\n    #\n    # Are there any useful operations/properties shared by Gate/Channel?\n\n\n# ====================================================================\n# Derived transformation classes\n# ====================================================================\n\n\nclass Channel(Transformation):\n    """"""Abstract base class for quantum channels.\n\n    This class provides the base behaviour for non-unitary\n    maps and transformations.\n    """"""\n\n    # TODO decide how all Channels should treat the first parameter p[0]\n    # (see e.g. https://en.wikipedia.org/wiki/C0-semigroup), cf. p[0] in ops.Gate\n\n    def merge(self, other):\n        if not self.__class__ == other.__class__:\n            raise MergeFailure(""Not the same channel family."")\n\n        # channels can be merged if they are the same class and share all the other parameters\n        if self.p[1:] == other.p[1:]:\n            # determine the combined first parameter\n            T = self.p[0] * other.p[0]\n            # if one, replace with the identity\n            if T == 1:\n                return None\n\n            # return a copy\n            # NOTE deepcopy would make copies of the parameters which would mess things up\n            temp = copy.copy(self)\n            temp.p = [T] + self.p[1:]  # change the parameter list\n            return temp\n\n        raise MergeFailure(""Don\'t know how to merge these operations."")\n\n\nclass Gate(Transformation):\n    """"""Abstract base class for unitary quantum gates.\n\n    The first parameter p[0] of the Gate class is special:\n\n    * The value p[0] = 0 corresponds to the identity gate.\n    * The inverse gate is obtained by negating p[0].\n    * Two gates of this class can be merged by adding the\n      first parameters together, assuming all the other parameters match.\n    """"""\n\n    def __init__(self, par):\n        super().__init__(par)\n        # default: non-dagger form\n        self.dagger = False  #: bool: formal inversion of the gate\n\n    def __str__(self):\n        """"""String representation for the gate.""""""\n        # add a dagger symbol to the class name if needed\n        temp = super().__str__()\n        if self.dagger:\n            temp += "".H""\n        return temp\n\n    @property\n    def H(self):\n        """"""Returns a copy of the gate with the self.dagger flag flipped.\n\n        H stands for hermitian conjugate.\n\n        Returns:\n            Gate: formal inverse of this gate\n        """"""\n        # HACK Semantically a bad use of @property since this method is not a getter.\n        # NOTE deepcopy would make copies of the parameters which would mess things up\n        s = copy.copy(self)\n        s.dagger = not s.dagger\n        return s\n\n    def decompose(self, reg, **kwargs):\n        """"""Decompose the operation into elementary operations supported by the backend API.\n\n        Like :func:`Operation.decompose`, but applies self.dagger.\n        """"""\n        seq = self._decompose(reg, **kwargs)\n        if self.dagger:\n            # apply daggers, reverse the Command sequence\n            for cmd in seq:\n                cmd.op.dagger = not cmd.op.dagger\n            seq = list(reversed(seq))\n        return seq\n\n    def apply(self, reg, backend, **kwargs):\n        """"""Ask a backend to execute the operation on the current register state right away.\n\n        Like :func:`Operation.apply`, but takes into account the special nature of\n        p[0] and applies self.dagger.\n\n        Returns:\n            None: Gates do not return anything, return value is None\n        """"""\n        z = self.p[0]\n        # if z represents a batch of parameters, then all of these\n        # must be zero to skip calling backend\n        if np.all(z == 0):\n            # identity, no need to apply\n            return\n        if self.dagger:\n            z = -z\n        original_p0 = self.p[0]  # store the original Parameter\n        self.p[0] = z\n\n        # convert RegRefs back to indices for the backend API\n        temp = [rr.ind for rr in reg]\n        # call the child class specialized _apply method\n        self._apply(temp, backend, **kwargs)\n        self.p[0] = original_p0  # restore the original Parameter instance\n\n    def merge(self, other):\n        if not self.__class__ == other.__class__:\n            raise MergeFailure(""Not the same gate family."")\n\n        # gates can be merged if they are the same class and share all the other parameters\n        if self.p[1:] == other.p[1:]:\n            # make sure the gates have the same dagger flag, if not, invert the second p[0]\n            if self.dagger == other.dagger:\n                temp = other.p[0]\n            else:\n                temp = -other.p[0]\n            # now we can add up the parameters and keep self.dagger\n            p0 = self.p[0] + temp\n            if p0 == 0:\n                return None  # identity gate\n\n            # return a copy\n            # NOTE deepcopy would make copies the parameters which would mess things up\n            temp = copy.copy(self)\n            temp.p = [p0] + self.p[1:]  # change the parameter list\n            return temp\n\n        raise MergeFailure(""Don\'t know how to merge these gates."")\n\n\n# ====================================================================\n# State preparation operations\n# ====================================================================\n\n\nclass Vacuum(Preparation):\n    r""""""Prepare a mode in the vacuum state.\n\n    Can be accessed via the shortcut variable ``Vac``.\n\n    .. note:: By default, newly created modes in Strawberry Fields default to the vacuum state.\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            The vacuum state :math:`\\ket{0}` is a Gaussian state defined by\n\n            .. math::\n                \\ket{0} = \\frac{1}{\\sqrt[4]{\\pi \\hbar}}\n                \\int dx~e^{-x^2/(2 \\hbar)}\\ket{x} ~~\\text{where}~~ \\a\\ket{0}=0\n\n        .. tip::\n\n            *Available in Strawberry Fields as a NumPy array by*\n            :func:`strawberryfields.utils.vacuum_state`\n\n        In the Fock basis, it is represented by Fock state :math:`\\ket{0}`,\n        and in the Gaussian formulation, by :math:`\\bar{\\mathbf{r}}=(0,0)`\n        and :math:`\\mathbf{V}= \\frac{\\hbar}{2} I`.\n    """"""\n\n    def __init__(self):\n        super().__init__([])\n\n    def _apply(self, reg, backend, **kwargs):\n        backend.prepare_vacuum_state(*reg)\n\n    def __str__(self):\n        # return the shorthand object when the\n        # command is printed by the user\n        return ""Vac""\n\n\nclass Coherent(Preparation):\n    r""""""Prepare a mode in a coherent state.\n\n    The gate is parameterized so that a user can specify a single complex number :math:`a=\\alpha`\n    or use the polar form :math:`a = r, p=\\phi` and still get the same result.\n\n    Args:\n        a (complex): displacement parameter :math:`\\alpha`\n        p (float): phase angle :math:`\\phi`\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            The coherent state :math:`\\ket{\\alpha}`, :math:`\\alpha\\in\\mathbb{C}`\n            is a displaced vacuum state defined by\n\n            .. math::\n                \\ket{\\alpha} = D(\\alpha)\\ket{0}\n\n        .. tip::\n\n            *Available in Strawberry Fields as a NumPy array by*\n            :func:`strawberryfields.utils.coherent_state`\n\n        A coherent state is a minimum uncertainty state, and the\n        eigenstate of the annihilation operator:\n\n        .. math:: \\a\\ket{\\alpha} = \\alpha\\ket{\\alpha}\n\n        In the Fock basis, it has the decomposition\n\n        .. math:: |\\alpha\\rangle = e^{-|\\alpha|^2/2} \\sum_{n=0}^\\infty\n                  \\frac{\\alpha^n}{\\sqrt{n!}}|n\\rangle\n\n        whilst in the Gaussian formulation, :math:`\\bar{\\mathbf{r}}=2\n        \\sqrt{\\frac{\\hbar}{2}}(\\text{Re}(\\alpha), \\text{Im}(\\alpha))` and\n        :math:`\\mathbf{V}= \\frac{\\hbar}{2} I`.\n    """"""\n\n    def __init__(self, a=0.0, p=0.0):\n        super().__init__([a, p])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = self.p[0] * pf.exp(1j * self.p[1])\n        z = evaluate_complex_parameter(p, self.p[1])\n        backend.prepare_coherent_state(z, *reg)\n\n\nclass Squeezed(Preparation):\n    r""""""Prepare a mode in a squeezed vacuum state.\n\n    Args:\n        r (float): squeezing magnitude\n        p (float): squeezing angle :math:`\\phi`\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            The squeezed state :math:`\\ket{z}`, :math:`z=re^{i\\phi}`\n            is a squeezed vacuum state defined by\n\n            .. math::\n                \\ket{z} = S(z)\\ket{0}\n\n        .. tip::\n\n            *Available in Strawberry Fields as a NumPy array by*\n            :func:`strawberryfields.utils.squeezed_state`\n\n        A squeezed state is a minimum uncertainty state with unequal\n        quadrature variances, and satisfies the following eigenstate equation:\n\n        .. math:: \\left(\\a\\cosh(r)+\\ad e^{i\\phi}\\sinh(r)\\right)\\ket{z} = 0\n\n        In the Fock basis, it has the decomposition\n\n        .. math:: |z\\rangle = \\frac{1}{\\sqrt{\\cosh(r)}}\\sum_{n=0}^\\infty\n                  \\frac{\\sqrt{(2n)!}}{2^n n!}(-e^{i\\phi}\\tanh(r))^n|2n\\rangle\n\n        whilst in the Gaussian formulation, :math:`\\bar{\\mathbf{r}} = (0,0)`,\n        :math:`\\mathbf{V} = \\frac{\\hbar}{2}R(\\phi/2)\\begin{bmatrix}e^{-2r} & 0 \\\\\n        0 & e^{2r} \\\\\\end{bmatrix}R(\\phi/2)^T`.\n\n        We can use the squeezed vacuum state to approximate the zero position and\n        zero momentum eigenstates;\n\n        .. math:: \\ket{0}_x \\approx S(r)\\ket{0}, ~~~~ \\ket{0}_p \\approx S(-r)\\ket{0}\n\n        where :math:`z=r` is sufficiently large.\n    """"""\n\n    def __init__(self, r=0.0, p=0.0):\n        super().__init__([r, p])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = par_evaluate(self.p)\n        backend.prepare_squeezed_state(p[0], p[1], *reg)\n\n\nclass DisplacedSqueezed(Preparation):\n    r""""""Prepare a mode in a displaced squeezed state.\n\n    A displaced squeezed state is prepared by squeezing a vacuum state, and\n    then applying a displacement operator.\n\n    .. math::\n       \\ket{\\alpha,z} = D(\\alpha)\\ket{0,z} = D(\\alpha)S(z)\\ket{0},\n\n    where the squeezing parameter :math:`z=re^{i\\phi}`.\n\n    Args:\n        alpha (complex): displacement parameter\n        r (float): squeezing magnitude\n        p (float): squeezing angle :math:`\\phi`\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            The displaced squeezed state :math:`\\ket{\\alpha, z}`, :math:`\\alpha\\in\\mathbb{C}`,\n            :math:`z=re^{i\\phi}` is a displaced and squeezed vacuum state defined by\n\n            .. math::\n                \\ket{\\alpha, z} = D(\\alpha)S(z)\\ket{0}\n\n        .. tip::\n\n            *Available in Strawberry Fields as a NumPy array by*\n            :func:`strawberryfields.utils.displaced_squeezed_state`\n\n        In the Fock basis, it has the decomposition\n\n        .. math::\n            |\\alpha,z\\rangle = e^{-\\frac{1}{2}|\\alpha|^2-\\frac{1}{2}{\\alpha^*}^2\n            e^{i\\phi}\\tanh{(r)}} \\sum_{n=0}^\\infty\\frac{\\left[\\frac{1}{2}e^{i\\phi}\n            \\tanh(r)\\right]^{n/2}}{\\sqrt{n!\\cosh(r)}} H_n\n            \\left[ \\frac{\\alpha\\cosh(r)+\\alpha^*e^{i\\phi}\\sinh(r)}{\\sqrt{e^{i\\phi}\\sinh(2r)}} \\right]\n            |n\\rangle\n\n\n        where :math:`H_n(x)` are the Hermite polynomials defined by\n        :math:`H_n(x)=(-1)^n e^{x^2}\\frac{d}{dx}e^{-x^2}`. Alternatively,\n        in the Gaussian formulation, :math:`\\bar{\\mathbf{r}} = 2\n        \\sqrt{\\frac{\\hbar}{2}}(\\text{Re}(\\alpha),\\text{Im}(\\alpha))` and\n        :math:`\\mathbf{V} = R(\\phi/2)\\begin{bmatrix}e^{-2r} & 0 \\\\0 & e^{2r} \\\\\n        \\end{bmatrix}R(\\phi/2)^T`\n\n\n        We can use the displaced squeezed states to approximate the :math:`x`\n        position and :math:`p` momentum eigenstates;\n\n        .. math::\n            \\ket{x}_x \\approx D\\left(\\frac{1}{2}x\\right)S(r)\\ket{0}, ~~~~\n            \\ket{p}_p \\approx D\\left(\\frac{i}{2}p\\right)S(-r)\\ket{0}\n\n        where :math:`z=r` is sufficiently large.\n    """"""\n\n    def __init__(self, alpha=0.0, r=0.0, p=0.0):\n        super().__init__([alpha, r, p])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = par_evaluate(self.p)\n        # prepare the displaced squeezed state directly\n        backend.prepare_displaced_squeezed_state(p[0], p[1], p[2], *reg)\n\n    def _decompose(self, reg, **kwargs):\n        # squeezed state preparation followed by a displacement gate\n        return [Command(Squeezed(self.p[1], self.p[2]), reg), Command(Dgate(self.p[0]), reg)]\n\n\nclass Fock(Preparation):\n    r""""""Prepare a mode in a Fock basis state.\n\n    The prepared mode is traced out and replaced with the Fock state :math:`\\ket{n}`.\n    As a result the state of the other subsystems may have to be described using a density matrix.\n\n    .. warning::\n        The Fock basis is **non-Gaussian**, and thus can\n        only be used in the Fock backends, *not* the Gaussian backend.\n\n    Args:\n        n (int): Fock state to prepare\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            A single mode state can be decomposed into the Fock basis as follows:\n\n            .. math::\n                \\ket{\\psi} = \\sum_n c_n \\ket{n}\n\n            if there exists a unique integer :math:`m` such that\n            :math:`\\begin{cases}c_n=1& n=m\\\\c_n=0&n\\neq m\\end{cases}`,\n            then the single mode is simply a Fock state or :math:`n` photon state.\n\n        .. tip::\n\n            *Available in Strawberry Fields as a NumPy array by*\n            :func:`strawberryfields.utils.fock_state`\n\n            *Arbitrary states in the Fock basis can be applied in Strawberry Fields\n            using the state preparation operator* :class:`strawberryfields.ops.Ket`\n    """"""\n\n    def __init__(self, n=0):\n        super().__init__([n])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = par_evaluate(self.p)\n        backend.prepare_fock_state(p[0], *reg)\n\n\nclass Catstate(Preparation):\n    r""""""Prepare a mode in a cat state.\n\n    A cat state is the coherent superposition of two coherent states,\n\n    .. math::\n       \\ket{\\text{cat}(\\alpha)} = \\frac{1}{N} (\\ket{\\alpha} +e^{i\\phi} \\ket{-\\alpha}),\n\n    where :math:`N = \\sqrt{2 (1+\\cos(\\phi)e^{-2|\\alpha|^2})}` is the normalization factor.\n\n    .. warning::\n        Cat states are **non-Gaussian**, and thus can\n        only be used in the Fock backends, *not* the Gaussian backend.\n\n    Args:\n        alpha (complex): displacement parameter\n        p (float): parity, where :math:`\\phi=p\\pi`. ``p=0`` corresponds to an even\n            cat state, and ``p=1`` an odd cat state.\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            The cat state is a non-Gaussian superposition of coherent states\n\n            .. math::\n                |cat\\rangle = \\frac{e^{-|\\alpha|^2/2}}{\\sqrt{2(1+e^{-2|\\alpha|^2}\\cos(\\phi))}}\n                \\left(|\\alpha\\rangle +e^{i\\phi}|-\\alpha\\rangle\\right)\n\n            with the even cat state given for :math:`\\phi=0`, and the odd cat state\n            given for :math:`\\phi=\\pi`.\n\n        .. tip::\n\n            *Implemented in Strawberry Fields as a NumPy array by*\n            :class:`strawberryfields.utils.cat_state`\n\n        In the case where :math:`\\alpha<1.2`, the cat state can be approximated by\n        the squeezed single photon state :math:`S\\ket{1}`.\n    """"""\n\n    def __init__(self, alpha=0, p=0):\n        super().__init__([alpha, p])\n\n    def _apply(self, reg, backend, **kwargs):\n        alpha = self.p[0]\n        phi = np.pi * self.p[1]\n        D = backend.get_cutoff_dim()\n        l = np.arange(D)[:, np.newaxis]\n\n        # normalization constant\n        temp = pf.exp(-0.5 * pf.Abs(alpha) ** 2)\n        N = temp / pf.sqrt(2 * (1 + pf.cos(phi) * temp ** 4))\n\n        # coherent states\n        c1 = (alpha ** l) / np.sqrt(ssp.factorial(l))\n        c2 = ((-alpha) ** l) / np.sqrt(ssp.factorial(l))\n        # add them up with a relative phase\n        ket = (c1 + pf.exp(1j * phi) * c2) * N\n\n        # in order to support broadcasting, the batch axis has been located at last axis, but backend expects it up as first axis\n        ket = np.transpose(ket)\n\n        # drop dummy batch axis if it is not necessary\n        ket = np.squeeze(ket)\n\n        # evaluate the array (elementwise)\n        ket = evaluate_complex_parameter(ket, self.p[1])\n\n        backend.prepare_ket_state(ket, *reg)\n\n\nclass Ket(Preparation):\n    r""""""Prepare mode(s) using the given ket vector(s) in the Fock basis.\n\n    The prepared modes are traced out and replaced with the given ket state\n    (in the Fock basis). As a result the state of the other subsystems may have\n    to be described using a density matrix.\n\n    The provided kets must be each be of length ``cutoff_dim``, matching\n    the cutoff dimension used in calls to :meth:`eng.run <~.Engine.run>`.\n\n    .. warning::\n        The Fock basis is **non-Gaussian**, and thus can\n        only be used in the Fock backends, *not* the Gaussian backend.\n\n    Args:\n        state (array or BaseFockState): state vector in the Fock basis.\n            This can be provided as either:\n\n            * a single ket vector, for single mode state preparation\n            * a multimode ket, with one array dimension per mode\n            * a :class:`BaseFockState` state object.\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            A single mode state can be decomposed into the Fock basis as follows:\n\n            .. math::\n                \\ket{\\psi} = \\sum_n c_n \\ket{n}\n    """"""\n    ns = None\n\n    def __init__(self, state):\n        if isinstance(state, BaseFockState):\n            if not state.is_pure:\n                raise ValueError(""Provided Fock state is not pure."")\n            super().__init__([state.ket()])\n        elif isinstance(state, BaseGaussianState):\n            raise ValueError(""Gaussian states are not supported for the Ket operation."")\n        else:\n            super().__init__([state])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = par_evaluate(self.p)\n        backend.prepare_ket_state(p[0], reg)\n\n\nclass DensityMatrix(Preparation):\n    r""""""Prepare mode(s) using the given density matrix in the Fock basis.\n\n    The prepared modes are traced out and replaced with the given state\n    (in the Fock basis). As a result, the overall state of system\n    will also have to be described using a density matrix.\n\n    The provided density matrices must be of size ``[cutoff_dim, cutoff_dim]``,\n    matching the cutoff dimension used in calls to :meth:`eng.run <~.Engine.run>`.\n\n    .. warning::\n        The Fock basis is **non-Gaussian**, and thus can\n        only be used in the Fock backends, *not* the Gaussian backend.\n\n    Args:\n        state (array or BaseFockState): density matrix in the Fock basis.\n            This can be provided as either:\n\n            * a single mode two-dimensional matrix :math:`\\rho_{ij}`,\n            * a multimode tensor :math:`\\rho_{ij,kl,\\dots,mn}`, with two indices per mode,\n            * a :class:`BaseFockState` state object.\n\n    .. details::\n\n        When working with an :math:`N`-mode density matrix in the Fock basis,\n\n        .. math::\n            \\rho = \\sum_{n_1}\\cdots\\sum_{n_N} c_{n_1,\\cdots,n_N}\n            \\ket{n_1,\\cdots,n_N}\\bra{n_1,\\cdots,n_N}\n\n        we use the convention that every pair of consecutive dimensions\n        corresponds to a subsystem; i.e.,\n\n        .. math::\n            \\rho_{\\underbrace{ij}_{\\text{mode}~0}~\\underbrace{kl}_{\\text{mode}~1}\n            ~\\underbrace{mn}_{\\text{mode}~2}}\n\n        Thus, using index notation, we can calculate the reduced density matrix\n        for mode 2 by taking the partial trace over modes 0 and 1:\n\n        .. math:: \\braketT{n}{\\text{Tr}_{01}[\\rho]}{m} = \\sum_{i}\\sum_k \\rho_{iikkmn}\n    """"""\n    ns = None\n\n    def __init__(self, state):\n        if isinstance(state, BaseFockState):\n            super().__init__([state.dm()])\n        elif isinstance(state, BaseGaussianState):\n            raise ValueError(""Gaussian states are not supported for the Ket operation."")\n        else:\n            super().__init__([state])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = par_evaluate(self.p)\n        backend.prepare_dm_state(p[0], reg)\n\n\nclass Thermal(Preparation):\n    r""""""Prepare a mode in a thermal state.\n\n    The requested mode is traced out and replaced with the thermal state :math:`\\rho(\\bar{n})`.\n    As a result the state will be described using a density matrix.\n\n    Args:\n        n (float): mean thermal population of the mode\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            The thermal state is a mixed Gaussian state defined by\n\n            .. math::\n                \\rho(\\nbar) := \\sum_{n=0}^\\infty\\frac{\\nbar^n}{(1+\\nbar)^{n+1}}\\ketbra{n}{n}\n\n            where :math:`\\nbar:=\\tr{(\\rho(\\nbar)\\hat{n})}` is the mean photon number.\n            In the Gaussian formulation one has :math:`\\mathbf{V}=(2 \\nbar +1) \\frac{\\hbar}{2} I`\n            and :math:`\\bar{\\mathbf{r}}=(0,0)`.\n    """"""\n\n    def __init__(self, n=0):\n        super().__init__([n])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = par_evaluate(self.p)\n        backend.prepare_thermal_state(p[0], *reg)\n\n\n# ====================================================================\n# Measurements\n# ====================================================================\n\n\nclass MeasureFock(Measurement):\n    r""""""Photon counting measurement: measures a set of modes in the Fock basis.\n\n    Also accessible via the shortcut variable ``Measure``.\n\n    After measurement, the modes are reset to the vacuum state.\n\n    .. warning::\n        Photon counting is available in the Gaussian backend,\n        but the state of the circuit is not updated after measurement\n        (since it would be non-Gaussian).\n\n    .. details::\n\n        .. admonition:: Definition\n           :class: defn\n\n           Photon counting is a non-Gaussian projective measurement given by\n\n           .. math:: \\ket{n_i}\\bra{n_i}\n    """"""\n\n    ns = None\n\n    def __init__(self, select=None, dark_counts=None):\n        if dark_counts and select:\n            raise NotImplementedError(""Post-selection cannot be used together with dark counts."")\n\n        if dark_counts is not None and not isinstance(dark_counts, Sequence):\n            dark_counts = [dark_counts]\n\n        if select is not None and not isinstance(select, Sequence):\n            select = [select]\n\n        self.dark_counts = dark_counts\n        super().__init__([], select)\n\n    def _apply(self, reg, backend, shots=1, **kwargs):\n        samples = backend.measure_fock(reg, shots=shots, select=self.select, **kwargs)\n\n        if isinstance(samples, list):\n            samples = np.array(samples)\n\n        if self.dark_counts is not None:\n            if len(self.dark_counts) != len(reg):\n                raise ValueError(\n                    ""The number of dark counts must be equal to the number of measured modes: ""\n                    ""{} != {}"".format(len(self.dark_counts), len(reg))\n                )\n            samples += np.random.poisson(self.dark_counts, samples.shape)\n\n        return samples\n\n    def __str__(self):\n        # class name, parameter values, possible select and dark_counts parameters\n        temp = super().__str__()\n\n        if self.dark_counts is not None:\n            if not self.select:\n                temp += f""(dark_counts={self.dark_counts})""\n            else:\n                temp = f""{temp[:-1]}, dark_counts={self.dark_counts})""\n\n        return temp\n\n\nclass MeasureThreshold(Measurement):\n    """"""Measures a set of modes with thresholded Fock-state measurements, i.e.,\n    measuring whether a mode contain zero or nonzero photons.\n\n    After measurement, the modes are reset to the vacuum state.\n    """"""\n\n    ns = None\n\n    def __init__(self, select=None):\n        if select is not None and not isinstance(select, Sequence):\n            select = [select]\n        super().__init__([], select)\n\n    def _apply(self, reg, backend, shots=1, **kwargs):\n        return backend.measure_threshold(reg, shots=shots, select=self.select, **kwargs)\n\n\nclass MeasureHomodyne(Measurement):\n    r""""""Performs a homodyne measurement, measures one quadrature of a mode.\n\n    * Position basis measurement: :math:`\\phi = 0`\n      (also accessible via the shortcut variable ``MeasureX``).\n\n    * Momentum basis measurement: :math:`\\phi = \\pi/2`.\n      (also accessible via the shortcut variable ``MeasureP``)\n\n    The measured mode is reset to the vacuum state.\n\n    Args:\n        phi (float): measurement angle :math:`\\phi`\n        select (None, float): (Optional) desired values of measurement result.\n            Allows the post-selection of specific measurement results instead of randomly sampling.\n\n    .. details::\n\n        .. admonition:: Definition\n           :class: defn\n\n           Homodyne measurement is a Gaussian projective measurement given by projecting the state\n           onto the states\n\n           .. math:: \\ket{x_\\phi}\\bra{x_\\phi},\n\n           defined as eigenstates of the Hermitian operator\n\n           .. math:: \\hat{x}_\\phi = \\cos(\\phi) \\hat{x} + \\sin(\\phi)\\hat{p}.\n\n        In the Gaussian backend, this is done by projecting onto finitely squeezed states\n        approximating the :math:`x` and :math:`p` eigenstates. Due to the finite squeezing\n        approximation, this results in a measurement variance of :math:`\\sigma_H^2`, where\n        :math:`\\sigma_H=2\\times 10^{-4}`.\n\n        In the Fock backends, this is done by using Hermite polynomials to calculate the\n        :math:`\\x_\\phi` probability distribution over a specific range and number of bins,\n        before taking a random sample.\n    """"""\n    ns = 1\n\n    def __init__(self, phi, select=None):\n        super().__init__([phi], select)\n\n    def _apply(self, reg, backend, shots=1, **kwargs):\n        p = par_evaluate(self.p)\n        s = np.sqrt(sf.hbar / 2)  # scaling factor, since the backend API call is hbar-independent\n        select = self.select\n        if select is not None:\n            select = select / s\n\n        return s * backend.measure_homodyne(p[0], *reg, shots=shots, select=select, **kwargs)\n\n    def __str__(self):\n        if self.select is None:\n            if self.p[0] == 0:\n                return ""MeasureX""\n            if self.p[0] == np.pi / 2:\n                return ""MeasureP""\n        return super().__str__()\n\n\nclass MeasureHeterodyne(Measurement):\n    r""""""Performs a heterodyne measurement on a mode.\n\n    Also accessible via the shortcut variable ``MeasureHD``.\n\n    Samples the joint Husimi distribution :math:`Q(\\vec{\\alpha}) =\n    \\frac{1}{\\pi}\\bra{\\vec{\\alpha}}\\rho\\ket{\\vec{\\alpha}}`.\n    The measured mode is reset to the vacuum state.\n\n    .. warning:: The heterodyne measurement can only be performed in the Gaussian backend.\n\n    Args:\n        select (None, complex): (Optional) desired values of measurement result.\n            Allows the post-selection of specific measurement results instead of randomly sampling.\n\n    .. details::\n\n        .. admonition:: Definition\n           :class: defn\n\n           Heterodyne measurement is a Gaussian projective measurement given by projecting\n           the state onto the coherent states,\n\n           .. math:: \\frac{1}{\\pi} \\ket{\\alpha}\\bra{\\alpha}\n    """"""\n    ns = 1\n\n    def __init__(self, select=None):\n        super().__init__([], select)\n\n    def _apply(self, reg, backend, shots=1, **kwargs):\n        return backend.measure_heterodyne(*reg, shots=shots, select=self.select, **kwargs)\n\n    def __str__(self):\n        if self.select is None:\n            return ""MeasureHD""\n        return ""MeasureHeterodyne(select={})"".format(self.select)\n\n\n# ====================================================================\n# Channels\n# ====================================================================\n\n\nclass LossChannel(Channel):\n    r""""""Perform a loss channel operation on the specified mode.\n\n    This channel couples mode :math:`\\a` to another bosonic mode :math:`\\hat{b}`\n    prepared in the vacuum state using the following transformation:\n\n    .. math::\n        \\a \\mapsto \\sqrt{T} a+\\sqrt{1-T} \\hat{b}\n\n    Args:\n        T (float): the loss parameter :math:`0\\leq T\\leq 1`.\n\n    .. details::\n\n        Loss is implemented by a CPTP map whose Kraus representation is\n\n        .. math::\n           \\mathcal{N}(T)\\left\\{\\ \\cdot \\ \\right\\} = \\sum_{n=0}^{\\infty} E_n(T) \\\n           \\cdot \\ E_n(T)^\\dagger , \\quad E_n(T) = \\left(\\frac{1-T}{T} \\right)^{n/2}\n           \\frac{\\a^n}{\\sqrt{n!}} \\left(\\sqrt{T}\\right)^{\\ad \\a}\n\n        .. admonition:: Definition\n            :class: defn\n\n            Loss is implemented by coupling mode :math:`\\a` to another bosonic mode\n            :math:`\\hat{b}` prepared in the vacuum state, by using the following transformation\n\n            .. math::\n               \\a \\to \\sqrt{T} \\a+\\sqrt{1-T} \\hat{b}\n\n            and then tracing it out. Here, :math:`T` is the *energy* transmissivity.\n            For :math:`T = 0` the state is mapped to the vacuum state, and for\n            :math:`T=1` one has the identity map.\n\n        One useful identity is\n\n        .. math::\n           \\mathcal{N}(T)\\left\\{\\ket{n}\\bra{m} \\right\\}=\\sum_{l=0}^{\\min(n,m)}\n           \\left(\\frac{1-T}{T}\\right)^l \\frac{T^{(n+m)/2}}{l!} \\sqrt{\\frac{n! m!}{(n-l)!(m-l)!}}\n           \\ket{n-l}\\bra{m-l}\n\n        In particular :math:`\\mathcal{N}(T)\\left\\{\\ket{0}\\bra{0} \\right\\} =  \\pr{0}`.\n    """"""\n\n    def __init__(self, T):\n        super().__init__([T])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = par_evaluate(self.p)\n        backend.loss(p[0], *reg)\n\n\nclass ThermalLossChannel(Channel):\n    r""""""Perform a thermal loss channel operation on the specified mode.\n\n    This channel couples mode :math:`\\a` to another bosonic mode :math:`\\hat{b}`\n    prepared in a thermal state with mean photon number :math:`\\bar{n}`,\n    using the following transformation:\n\n    .. math::\n       \\a \\mapsto \\sqrt{T} a+\\sqrt{1-T} \\hat{b}\n\n    Args:\n        T (float): the loss parameter :math:`0\\leq T\\leq 1`.\n        nbar (float): mean photon number of the environment thermal state\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            Thermal loss is implemented by coupling mode :math:`\\a` to another\n            bosonic mode :math:`\\hat{b}` prepared in the thermal state\n            :math:`\\ket{\\bar{n}}`, by using the following transformation\n\n            .. math::\n               \\a \\to \\sqrt{T} \\a+\\sqrt{1-T} \\hat{b}\n\n            and then tracing it out. Here, :math:`T` is the *energy* transmissivity.\n            For :math:`T = 0` the state is mapped to the thermal state :math:`\\ket{\\bar{n}}`\n            with mean photon number :math:`\\bar{n}`, and for :math:`T=1` one has the identity map.\n\n        Note that if :math:`\\bar{n}=0`, the thermal loss channel is equivalent to the\n        :doc:`loss channel <strawberryfields.ops.LossChannel>`.\n    """"""\n\n    def __init__(self, T, nbar):\n        super().__init__([T, nbar])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = par_evaluate(self.p)\n        backend.thermal_loss(p[0], p[1], *reg)\n\n\n# ====================================================================\n# Unitary gates\n# ====================================================================\n\n\nclass Dgate(Gate):\n    r""""""Phase space displacement gate.\n\n    .. math::\n        D(\\alpha) = \\exp(\\alpha a^\\dagger -\\alpha^* a) = \\exp\\left(-i\\sqrt{2}(\\re(\\alpha) \\hat{p} -\\im(\\alpha) \\hat{x})/\\sqrt{\\hbar}\\right)\n\n    where :math:`\\alpha = r e^{i\\phi}` has magnitude :math:`r\\geq 0` and phase :math:`\\phi`.\n\n    The gate is parameterized so that a user can specify a single complex number :math:`a=\\alpha`\n    or use the polar form :math:`a = r, \\phi` and still get the same result.\n\n    Args:\n        a (complex): displacement parameter :math:`\\alpha`\n        phi (float): extra (optional) phase angle :math:`\\phi`\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            .. math::\n                D(\\alpha) = \\exp( \\alpha \\ad -\\alpha^* \\a) = \\exp(r (e^{i\\phi}\\ad -e^{-i\\phi}\\a)),\n                \\quad D^\\dagger(\\alpha) \\a D(\\alpha)=\\a +\\alpha\\I\n\n            where :math:`\\alpha=r e^{i \\phi}` with :math:`r \\geq 0` and :math:`\\phi \\in [0,2 \\pi)`.\n\n        We obtain for the position and momentum operators\n\n        .. math::\n            D^\\dagger(\\alpha) \\x D(\\alpha) = \\x +\\sqrt{2 \\hbar } \\re(\\alpha) \\I,\\\\\n            D^\\dagger(\\alpha) \\p D(\\alpha) = \\p +\\sqrt{2 \\hbar } \\im(\\alpha) \\I.\n\n        The matrix elements of the displacement operator in the Fock basis were derived by Cahill and Glauber :cite:`cahill1969`:\n\n        .. math::\n            \\bra{m}\\hat D(\\alpha) \\ket{n}  = \\sqrt{\\frac{n!}{m!}} \\alpha^{m-n} e^{-|\\alpha|^2/2} L_n^{m-n}\\left( |\\alpha|^2 \\right)\n\n        where :math:`L_n^{m}(x)` is a generalized Laguerre polynomial :cite:`dlmf`.\n    """"""\n\n    def __init__(self, a, phi=0.0):\n        super().__init__([a, phi])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = self.p[0] * pf.exp(1j * self.p[1])\n        z = evaluate_complex_parameter(p, self.p[1])\n        backend.displacement(z, *reg)\n\n\nclass Xgate(Gate):\n    r""""""Position displacement gate.\n\n    .. math::\n        X(x) = e^{-i x \\hat{p}/\\hbar}\n\n    Args:\n        x (float): position displacement\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            The pure position displacement operator is defined as\n\n            .. math::\n                X(x) = D\\left( x/\\sqrt{2 \\hbar}\\right)  = \\exp(-i x \\p /\\hbar),\n                \\quad X^\\dagger(x) \\x X(x) = \\x +x\\I,\n\n            where :math:`D` is the :doc:`displacement gate <strawberryfields.ops.Dgate>`.\n    """"""\n\n    def __init__(self, x):\n        super().__init__([x])\n\n    def _decompose(self, reg, **kwargs):\n        # into a displacement\n        z = self.p[0] / np.sqrt(2 * sf.hbar)\n        return [Command(Dgate(z, 0), reg)]\n\n\nclass Zgate(Gate):\n    r""""""Momentum displacement gate.\n\n    .. math::\n        Z(p) = e^{i p \\hat{x}/\\hbar}\n\n    Args:\n        p (float): momentum displacement\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            The pure position displacement operator is defined as\n\n            .. math::\n                Z(p) = D\\left(i p/\\sqrt{2 \\hbar}\\right) = \\exp(i p \\x /\\hbar ),\n                \\quad Z^\\dagger(p) \\p Z(p) = \\p +p\\I,\n\n            where :math:`D` is the :doc:`displacement gate <strawberryfields.ops.Dgate>`.\n    """"""\n\n    def __init__(self, p):\n        super().__init__([p])\n\n    def _decompose(self, reg, **kwargs):\n        # into a displacement\n        r = self.p[0] / np.sqrt(2 * sf.hbar)\n        return [Command(Dgate(r, np.pi / 2), reg)]\n\n\nclass Sgate(Gate):\n    r""""""Phase space squeezing gate.\n\n    .. math::\n        S(z) = \\exp\\left(\\frac{1}{2}(z^* a^2 -z {a^\\dagger}^2)\\right)\n\n    where :math:`z = r e^{i\\phi}`.\n\n    Args:\n        r (float): squeezing amount\n        phi (float): squeezing phase angle :math:`\\phi`\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            .. math::\n                & S(z) = \\exp\\left(\\frac{1}{2}\\left(z^* \\a^2-z {\\ad}^{2} \\right) \\right)\n                = \\exp\\left(\\frac{r}{2}\\left(e^{-i\\phi}\\a^2 -e^{i\\phi}{\\ad}^{2} \\right) \\right)\\\\\n                & S^\\dagger(z) \\a S(z) = \\a \\cosh(r) -\\ad e^{i \\phi} \\sinh r\\\\\n                & S^\\dagger(z) \\ad S(z) = \\ad \\cosh(r) -\\a e^{-i \\phi} \\sinh(r)\n\n            where :math:`z=r e^{i \\phi}` with :math:`r \\geq 0` and :math:`\\phi \\in [0,2 \\pi)`.\n\n        The squeeze gate affects the position and momentum operators as\n\n        .. math::\n            S^\\dagger(z) \\x_{\\phi} S(z) = e^{-r}\\x_{\\phi}, ~~~ S^\\dagger(z) \\p_{\\phi} S(z) = e^{r}\\p_{\\phi}\n\n        The Fock basis decomposition of displacement and squeezing operations was analysed\n        by Krall :cite:`kral1990`, and the following quantity was calculated,\n\n        .. math::\n            f_{n,m}(r,\\phi,\\beta)&=\\bra{n}\\exp\\left(\\frac{r}{2}\\left(e^{i \\phi} \\a^2\n                -e^{-i \\phi} \\ad \\right) \\right) D(\\beta) \\ket{m} = \\bra{n}S(z^*) D(\\beta) \\ket{m}\\\\\n            &=\\sqrt{\\frac{n!}{\\mu  m!}} e^{\\frac{\\beta ^2 \\nu ^*}{2\\mu }-\\frac{\\left| \\beta \\right| ^2}{2}}\n            \\sum_{i=0}^{\\min(m,n)}\\frac{\\binom{m}{i} \\left(\\frac{1}{\\mu  \\nu }\\right)^{i/2}2^{\\frac{i-m}{2}\n                +\\frac{i}{2}-\\frac{n}{2}} \\left(\\frac{\\nu }{\\mu }\\right)^{n/2}\n                \\left(-\\frac{\\nu ^*}{\\mu }\\right)^{\\frac{m-i}{2}} H_{n-i}\\left(\\frac{\\beta }{\\sqrt{2}\n                \\sqrt{\\mu  \\nu }}\\right) H_{m-i}\\left(-\\frac{\\alpha ^*}{\\sqrt{2}\\sqrt{-\\mu  \\nu ^*}}\\right)}{(n-i)!}\n\n        where :math:`\\nu=e^{- i\\phi} \\sinh(r), \\mu=\\cosh(r), \\alpha=\\beta \\mu - \\beta^* \\nu`.\n\n        Two important special cases of the last formula are obtained when :math:`r \\to 0`\n        and when :math:`\\beta \\to 0`:\n\n        * For :math:`r \\to 0` we can take :math:`\\nu \\to 1, \\mu \\to r, \\alpha \\to \\beta` and use\n          the fact that for large :math:`x \\gg 1` the leading order term of the Hermite\n          polynomials is  :math:`H_n(x) = 2^n x^n +O(x^{n-2})` to obtain\n\n          .. math::\n              f_{n,m}(0,\\phi,\\beta) = \\bra{n}D(\\beta) \\ket{m}=\\sqrt{\\frac{n!}{  m!}}\n              e^{-\\frac{\\left| \\beta \\right| ^2}{2}} \\sum_{i=0}^{\\min(m,n)}\n              \\frac{(-1)^{m-i}}{(n-i)!} \\binom{m}{i} \\beta^{n-i} (\\beta^*)^{m-i}\n\n        * On the other hand if we let :math:`\\beta\\to 0` we use the fact that\n\n          .. math::\n              H_n(0) =\\begin{cases}0,  & \\mbox{if }n\\mbox{ is odd} \\\\\n              (-1)^{\\tfrac{n}{2}} 2^{\\tfrac{n}{2}} (n-1)!! , & \\mbox{if }n\\mbox{ is even} \\end{cases}\n\n          to deduce that :math:`f_{n,m}(r,\\phi,0)` is zero if :math:`n` is even and\n          :math:`m` is odd or vice versa.\n\n        When writing the Bloch-Messiah reduction :cite:`cariolaro2016`:cite:`cariolaro2016b`\n        of a Gaussian state in the Fock basis one often needs the following matrix element\n\n        .. math::\n            \\bra{k} D(\\alpha) R(\\theta) S(r) \\ket{l}  = e^{i \\theta l }\n            \\bra{k} D(\\alpha) S(r e^{2i \\theta}) \\ket{l} = e^{i \\theta l}\n            f^*_{l,k}(-r,-2\\theta,-\\alpha)\n    """"""\n\n    def __init__(self, r, phi=0.0):\n        super().__init__([r, phi])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = self.p[0] * pf.exp(1j * self.p[1])\n        z = evaluate_complex_parameter(p, self.p[1])\n        backend.squeeze(z, *reg)\n\n\nclass Pgate(Gate):\n    r""""""Quadratic phase gate.\n\n    .. math::\n        P(s) = e^{i \\frac{s}{2} \\hat{x}^2/\\hbar}\n\n    Args:\n        s (float): parameter\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            .. math::\n                P(s) = \\exp\\left(i  \\frac{s}{2 \\hbar} \\x^2\\right),\n                \\quad P^\\dagger(s) \\a P(s) = \\a +i\\frac{s}{2}(\\a +\\ad)\n\n        It shears the phase space, preserving position:\n\n        .. math::\n            P^\\dagger(s) \\x P(s) &= \\x,\\\\\n            P^\\dagger(s) \\p P(s) &= \\p +s\\x.\n\n        This gate can be decomposed as\n\n        .. math::\n            P(s) = R(\\theta) S(r e^{i \\phi})\n\n        where :math:`\\cosh(r) = \\sqrt{1+(\\frac{s}{2})^2}, \\quad\n        \\tan(\\theta) = \\frac{s}{2}, \\quad \\phi = -\\sign(s)\\frac{\\pi}{2} -\\theta`.\n    """"""\n\n    def __init__(self, s):\n        super().__init__([s])\n\n    def _decompose(self, reg, **kwargs):\n        # into a squeeze and a rotation\n        temp = self.p[0] / 2\n        r = pf.acosh(pf.sqrt(1 + temp ** 2))\n        theta = pf.atan(temp)\n        phi = -np.pi / 2 * pf.sign(temp) - theta\n        return [Command(Sgate(r, phi), reg), Command(Rgate(theta), reg)]\n\n\nclass Vgate(Gate):\n    r""""""Cubic phase gate.\n\n    .. math::\n        V(\\gamma) = e^{i \\frac{\\gamma}{3 \\hbar} \\hat{x}^3}\n\n    .. warning::\n\n        * The cubic phase gate has lower accuracy than the Kerr gate at the same cutoff dimension.\n\n        * The cubic phase gate is **non-Gaussian**, and thus can only be used\n          in the Fock backends, *not* the Gaussian backend.\n\n    Args:\n        gamma (float): parameter\n\n    .. details::\n\n        .. warning::\n            The cubic phase gate can suffer heavily from numerical inaccuracies due to\n            finite-dimensional cutoffs in the Fock basis. The gate implementation in\n            Strawberry Fields is unitary, but it does not implement an exact cubic phase\n            gate. The Kerr gate provides an alternative non-Gaussian gate.\n\n        .. admonition:: Definition\n            :class: defn\n\n            .. math::\n                V(\\gamma) = \\exp\\left(i \\frac{\\gamma}{3 \\hbar} \\x^3\\right),\n                \\quad V^\\dagger(\\gamma) \\a V(\\gamma) = \\a +i\\frac{\\gamma}{2\\sqrt{2/\\hbar}} (\\a +\\ad)^2\n\n        It transforms the phase space as follows:\n\n        .. math::\n            V^\\dagger(\\gamma) \\x V(\\gamma) &= \\x,\\\\\n            V^\\dagger(\\gamma) \\p V(\\gamma) &= \\p +\\gamma \\x^2.\n    """"""\n\n    def __init__(self, gamma):\n        super().__init__([gamma])\n\n    def _apply(self, reg, backend, **kwargs):\n        gamma_prime = self.p[0] * np.sqrt(sf.hbar / 2)\n        # the backend API call cubic_phase is hbar-independent\n        backend.cubic_phase(par_evaluate(gamma_prime), *reg)\n\n\nclass Kgate(Gate):\n    r""""""Kerr gate.\n\n    .. math::\n        K(\\kappa) = e^{i \\kappa \\hat{n}^2}\n\n    .. warning::\n        The Kerr gate is **non-Gaussian**, and thus can only be used\n        in the Fock backends, *not* the Gaussian backend.\n\n    Args:\n        kappa (float): parameter\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            The Kerr interaction is given by the Hamiltonian\n\n            .. math::\n                H = (\\hat{a}^\\dagger\\hat{a})^2=\\hat{n}^2\n\n            which is non-Gaussian and diagonal in the Fock basis.\n\n        We can therefore define the Kerr gate, with parameter :math:`\\kappa` as\n\n        .. math::\n            K(\\kappa) = \\exp{(i\\kappa\\hat{n}^2)}.\n    """"""\n\n    def __init__(self, kappa):\n        super().__init__([kappa])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = par_evaluate(self.p)\n        backend.kerr_interaction(p[0], *reg)\n\n\nclass Rgate(Gate):\n    r""""""Rotation gate.\n\n    .. math::\n        R(\\theta) = e^{i \\theta a^\\dagger a}\n\n    Args:\n        theta (float): rotation angle :math:`\\theta`.\n\n    .. details::\n\n        .. note::\n            We use the convention that a positive value of :math:`\\phi`\n            corresponds to an **anticlockwise** rotation in the phase space.\n\n        .. admonition:: Definition\n            :class: defn\n\n            We write the phase space rotation operator as\n\n            .. math::\n                R(\\phi) = \\exp\\left(i \\phi \\ad \\a\\right)=\n                \\exp\\left(i \\frac{\\phi}{2} \\left(\\frac{\\x^2+  \\p^2}{\\hbar}-\\I\\right)\\right),\n                \\quad R^\\dagger(\\phi) \\a R(\\phi) = \\a e^{i \\phi}\n\n        It rotates the position and momentum quadratures to each other:\n\n        .. math::\n            R^\\dagger(\\phi)\\x R(\\phi) = \\x \\cos \\phi -\\p \\sin \\phi,\\\\\n            R^\\dagger(\\phi)\\p R(\\phi) = \\p \\cos \\phi +\\x \\sin \\phi.\n    """"""\n\n    def __init__(self, theta):\n        super().__init__([theta])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = par_evaluate(self.p)\n        backend.rotation(p[0], *reg)\n\n\nclass BSgate(Gate):\n    r""""""BSgate(theta=pi/4, phi=0.)\n    Beamsplitter gate.\n\n    .. math::\n        B(\\theta,\\phi) = \\exp\\left(\\theta (e^{i \\phi} a_1 a_2^\\dagger -e^{-i \\phi} a_1^\\dagger a_2) \\right)\n\n    Args:\n        theta (float): Transmittivity angle :math:`\\theta`. The transmission amplitude of\n            the beamsplitter is :math:`t = \\cos(\\theta)`.\n            The value :math:`\\theta=\\pi/4` gives the 50-50 beamsplitter (default).\n        phi (float): Phase angle :math:`\\phi`. The reflection amplitude of the beamsplitter\n            is :math:`r = e^{i\\phi}\\sin(\\theta)`.\n            The value :math:`\\phi = \\pi/2` gives the symmetric beamsplitter.\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            For the annihilation and creation operators of two modes, denoted :math:`\\a_1`\n            and :math:`\\a_2`, the beamsplitter is defined by\n\n            .. math::\n                B(\\theta,\\phi) = \\exp\\left(\\theta (e^{i \\phi}\\a_1 \\ad_2 - e^{-i \\phi} \\ad_1 \\a_2) \\right)\n\n        **Action on the creation and annihilation operators**\n\n        They will transform the operators according to\n\n        .. math::\n            B^\\dagger(\\theta,\\phi) \\a_1  B(\\theta,\\phi) &= \\a_1\\cos \\theta -\\a_2 e^{-i \\phi} \\sin \\theta  = t \\a_1 -r^* \\a_2,\\\\\n            B^\\dagger(\\theta,\\phi) \\a_2  B(\\theta,\\phi) &= \\a_2\\cos \\theta + \\a_1  e^{i \\phi} \\sin \\theta= t \\a_2 +r \\a_1.\n\n        where :math:`t = \\cos \\theta` and :math:`r = e^{i\\phi} \\sin \\theta` are the\n        transmittivity and reflectivity amplitudes of the beamsplitter respectively.\n\n        Therefore, the beamsplitter transforms two input coherent states to two output\n        coherent states :math:`B(\\theta, \\phi) \\ket{\\alpha,\\beta} = \\ket{\\alpha\',\\beta\'}`, where\n\n        .. math::\n            \\alpha\' &= \\alpha\\cos \\theta-\\beta e^{-i\\phi}\\sin\\theta = t\\alpha - r^*\\beta\\\\\n            \\beta\' &= \\beta\\cos \\theta+\\alpha e^{i\\phi}\\sin\\theta = t\\beta + r\\alpha\\\\\n\n        **Action on the quadrature operators**\n\n        By substituting in the definition of the creation and annihilation operators in terms\n        of the position and momentum operators, it is possible to derive an expression for\n        how the beamsplitter transforms the quadrature operators:\n\n        .. math::\n            &\\begin{cases}\n                B^\\dagger(\\theta,\\phi) \\x_1 B(\\theta,\\phi) = \\x_1 \\cos(\\theta)-\\sin(\\theta) [\\x_2\\cos(\\phi)+\\p_2\\sin(\\phi)]\\\\\n                B^\\dagger(\\theta,\\phi) \\p_1 B(\\theta,\\phi) = \\p_1 \\cos(\\theta)-\\sin(\\theta) [\\p_2\\cos(\\phi)-\\x_2\\sin(\\phi)]\\\\\n            \\end{cases}\\\\[12pt]\n            &\\begin{cases}\n                B^\\dagger(\\theta,\\phi) \\x_2 B(\\theta,\\phi) = \\x_2 \\cos(\\theta)+\\sin(\\theta) [\\x_1\\cos(\\phi)-\\p_1\\sin(\\phi)]\\\\\n                B^\\dagger(\\theta,\\phi) \\p_2 B(\\theta,\\phi) = \\p_2 \\cos(\\theta)+\\sin(\\theta) [\\p_1\\cos(\\phi)+\\x_1\\sin(\\phi)]\n            \\end{cases}\n\n        **Action on the position and momentum eigenstates**\n\n        A 50% or **50-50 beamsplitter** has :math:`\\theta=\\pi/4` and :math:`\\phi=0` or\n        :math:`\\phi=\\pi`; consequently :math:`|t|^2 = |r|^2 = \\frac{1}{2}`, and it acts as follows:\n\n        .. math::\n            & B(\\pi/4,0)\\xket{x_1}\\xket{x_2} = \\xket{\\frac{1}{\\sqrt{2}}(x_1-x_2)}\\xket{\\frac{1}{\\sqrt{2}}(x_1+x_2)}\\\\\n            & B(\\pi/4,0)\\ket{p_1}_p\\ket{p_2}_p = \\xket{\\frac{1}{\\sqrt{2}}(p_1-p_2)}\\xket{\\frac{1}{\\sqrt{2}}(p_1+p_2)}\n\n        and\n\n        .. math::\n            & B(\\pi/4,\\pi)\\xket{x_1}\\xket{x_2} = \\xket{\\frac{1}{\\sqrt{2}}(x_1+x_2)}\\xket{\\frac{1}{\\sqrt{2}}(x_2-x_1)}\\\\\n            & B(\\pi/4,\\pi)\\ket{p_1}_p\\ket{p_2}_p = \\xket{\\frac{1}{\\sqrt{2}}(p_1+p_2)}\\xket{\\frac{1}{\\sqrt{2}}(p_2-p_1)}\n\n        Alternatively, **symmetric beamsplitter** (one that does not distinguish between\n        :math:`\\a_1` and :math:`\\a_2`) is obtained by setting :math:`\\phi=\\pi/2`.\n    """"""\n    ns = 2\n\n    def __init__(self, theta=np.pi / 4, phi=0.0):\n        # default: 50% beamsplitter\n        super().__init__([theta, phi])\n\n    def _apply(self, reg, backend, **kwargs):\n        t = pf.cos(self.p[0])\n        r = pf.sin(self.p[0]) * pf.exp(1j * self.p[1])\n\n        t = par_evaluate(t)\n        r = evaluate_complex_parameter(r, self.p[1])\n        backend.beamsplitter(t, r, *reg)\n\n\nclass MZgate(Gate):\n    r""""""Mach-Zehnder interferometer.\n\n    .. math::\n\n        \\mathrm{MZ}(\\phi_{in}, \\phi_{ex}) = BS\\left(\\frac{\\pi}{4}, \\frac{\\pi}{2}\\right)\n            (R(\\phi_{in})\\otimes I) BS\\left(\\frac{\\pi}{4}, \\frac{\\pi}{2}\\right)\n            (R(\\phi_{ex})\\otimes I)\n\n    Args:\n        phi_in (float): internal phase\n        phi_ex (float): external phase\n    """"""\n    ns = 2\n\n    def __init__(self, phi_in, phi_ex):\n        super().__init__([phi_in, phi_ex])\n\n    def _decompose(self, reg, **kwargs):\n        # into local phase shifts and two 50-50 beamsplitters\n        return [\n            Command(Rgate(self.p[1]), reg[0]),\n            Command(BSgate(np.pi / 4, np.pi / 2), reg),\n            Command(Rgate(self.p[0]), reg[0]),\n            Command(BSgate(np.pi / 4, np.pi / 2), reg),\n        ]\n\n\nclass S2gate(Gate):\n    r""""""Two-mode squeezing gate.\n\n    .. math::\n       S_2(z) = \\exp\\left(z a_1^\\dagger a_2^\\dagger - z^* a_1 a_2 \\right) = \\exp\\left(r (e^{i\\phi} a_1^\\dagger a_2^\\dagger e^{-i\\phi} a_1 a_2 ) \\right)\n\n    where :math:`z = r e^{i\\phi}`.\n\n    Args:\n        r (float): squeezing amount\n        phi (float): squeezing phase angle :math:`\\phi`\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            .. math::\n                S_2(z) = \\exp\\left(z \\a^\\dagger_1\\a^\\dagger_2 -z^* \\a_1 \\a_2 \\right) =\n                \\exp\\left(r (e^{i\\phi} \\a^\\dagger_1\\a^\\dagger_2 -e^{-i\\phi} \\a_1 \\a_2 \\right)\n\n            where :math:`z=r e^{i \\phi}` with :math:`r \\geq 0` and :math:`\\phi \\in [0,2 \\pi)`.\n\n        It can be decomposed into two opposite local squeezers sandwiched\n        between two 50\\% :doc:`beamsplitters <strawberryfields.ops.BSgate>` :cite:`ebs2002`:\n\n        .. math::\n            S_2(z) = B^\\dagger(\\pi/4,0) \\: \\left[ S(z) \\otimes S(-z)\\right] \\: B(\\pi/4,0)\n\n        Two-mode squeezing will transform the operators according to\n\n        .. math::\n            S_2(z)^\\dagger \\a_1  S_2(z) &= \\a_1 \\cosh(r)+\\ad_2 e^{i \\phi} \\sinh(r),\\\\\n            S_2(z)^\\dagger \\a_2  S_2(z) &= \\a_2 \\cosh(r)+\\ad_1 e^{i \\phi} \\sinh(r),\\\\\n\n        where :math:`z=r e^{i \\phi}` with :math:`r \\geq 0` and :math:`\\phi \\in [0,2 \\pi)`.\n    """"""\n    ns = 2\n\n    def __init__(self, r, phi=0.0):\n        super().__init__([r, phi])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = self.p[0] * pf.exp(1j * self.p[1])\n        z = evaluate_complex_parameter(p, self.p[1])\n        backend.two_mode_squeeze(z, *reg)\n\n    def _decompose(self, reg, **kwargs):\n        # two opposite squeezers sandwiched between 50% beamsplitters\n        S = Sgate(self.p[0], self.p[1])\n        BS = BSgate(np.pi / 4, 0)\n        return [Command(BS, reg), Command(S, reg[0]), Command(S.H, reg[1]), Command(BS.H, reg)]\n\n\nclass CXgate(Gate):\n    r""""""Controlled addition or sum gate in the position basis.\n\n    .. math::\n        \\text{CX}(s) = \\int dx \\ket{x}\\bra{x} \\otimes D\\left({\\frac{1}{\\sqrt{2\\hbar}}}s x\\right) = e^{-i s \\: \\hat{x} \\otimes \\hat{p}/\\hbar}\n\n    In the position basis it maps\n    :math:`\\ket{x_1, x_2} \\mapsto \\ket{x_1, s x_1 +x_2}`.\n\n    Args:\n        s (float): addition multiplier\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            The controlled-X gate, also known as the addition gate or\n            the sum gate, is a controlled displacement in position. It is given by\n\n            .. math::\n                \\text{CX}(s) = \\int dx \\xket{x}\\xbra{x} \\otimes\n                D\\left(\\frac{s x}{\\sqrt{2\\hbar}}\\right) =\n                \\exp\\left({-i \\frac{s}{\\hbar} \\: \\x_1 \\otimes \\p_2}\\right).\n\n        It is called addition because in the position basis\n        :math:`\\text{CX}(s) \\xket{x_1, x_2} = \\xket{x_1, x_2+s x_1}`.\n\n        We can also write the action of the addition gate on the canonical operators:\n\n        .. math::\n            \\text{CX}(s)^\\dagger \\x_1 \\text{CX}(s) &= \\x_1\\\\\n            \\text{CX}(s)^\\dagger \\p_1 \\text{CX}(s) &= \\p_1- s \\ \\p_2\\\\\n            \\text{CX}(s)^\\dagger \\x_2 \\text{CX}(s) &= \\x_2+ s \\ \\x_1\\\\\n            \\text{CX}(s)^\\dagger \\p_2 \\text{CX}(s) &= \\p_2 \\\\\n            \\text{CX}(s)^\\dagger \\hat{a}_1 \\text{CX}(s) &= \\a_1+  \\frac{s}{2} (\\ad_2 -  \\a_2)\\\\\n            \\text{CX}(s)^\\dagger \\hat{a}_2 \\text{CX}(s) &= \\a_2+  \\frac{s}{2} (\\ad_1 +  \\a_1)\\\\\n\n        The addition gate can be decomposed in terms of :doc:`single mode squeezers <strawberryfields.ops.Sgate>`\n        and :doc:`beamsplitters <strawberryfields.ops.BSgate>` as follows:\n\n        .. math::\n            \\text{CX}(s) = B(\\frac{\\pi}{2}+\\theta,0)\n            \\left(S(r,0) \\otimes S(-r,0) \\right) B(\\theta,0),\n\n        where\n\n        .. math::\n            \\sin(2 \\theta) = \\frac{-1}{\\cosh r}, \\ \\cos(2 \\theta)=-\\tanh(r),\n            \\ \\sinh(r) = -\\frac{ s}{2}.\n    """"""\n    ns = 2\n\n    def __init__(self, s=1):\n        super().__init__([s])\n\n    def _decompose(self, reg, **kwargs):\n        s = self.p[0]\n        r = pf.asinh(-s / 2)\n        theta = 0.5 * pf.atan2(-1.0 / pf.cosh(r), -pf.tanh(r))\n        return [\n            Command(BSgate(theta, 0), reg),\n            Command(Sgate(r, 0), reg[0]),\n            Command(Sgate(-r, 0), reg[1]),\n            Command(BSgate(theta + np.pi / 2, 0), reg),\n        ]\n\n\nclass CZgate(Gate):\n    r""""""Controlled phase gate in the position basis.\n\n    .. math::\n        \\text{CZ}(s) =  \\iint dx dy \\: e^{i sxy/\\hbar} \\ket{x,y}\\bra{x,y} = e^{i s \\: \\hat{x} \\otimes \\hat{x}/\\hbar}\n\n    In the position basis it maps\n    :math:`\\ket{x_1, x_2} \\mapsto e^{i s x_1 x_2/\\hbar} \\ket{x_1, x_2}`.\n\n    Args:\n        s (float): phase shift multiplier\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            .. math::\n                \\text{CZ}(s) =  \\iint dx dy \\: e^{i s x_1 x_2/\\hbar }\n                \\xket{x_1,x_2}\\xbra{x_1,x_2} = \\exp\\left({i s \\: \\hat{x_1}\n                \\otimes \\hat{x_2} /\\hbar}\\right).\n\n        It is related to the addition gate by a :doc:`phase space rotation <strawberryfields.ops.Rgate>`\n        in the second mode:\n\n        .. math::\n            \\text{CZ}(s) = R_{(2)}(\\pi/2) \\: \\text{CX}(s) \\: R_{(2)}^\\dagger(\\pi/2).\n\n        In the position basis\n        :math:`\\text{CZ}(s) \\xket{x_1, x_2} = e^{i  s x_1 x_2/\\hbar} \\xket{x_1, x_2}`.\n\n        We can also write the action of the controlled-phase gate on the\n        canonical operators:\n\n        .. math::\n            \\text{CZ}(s)^\\dagger \\x_1 \\text{CZ}(s) &= \\x_1\\\\\n            \\text{CZ}(s)^\\dagger \\p_1 \\text{CZ}(s) &= \\p_1+ s \\ \\x_2\\\\\n            \\text{CZ}(s)^\\dagger \\x_2 \\text{CZ}(s) &= \\x_2\\\\\n            \\text{CZ}(s)^\\dagger \\p_2 \\text{CZ}(s) &= \\p_2+ s \\ \\x_1 \\\\\n            \\text{CZ}(s)^\\dagger \\hat{a}_1 \\text{CZ}(s) &= \\a_1+  i\\frac{s}{2} (\\ad_2 +  \\a_2)\\\\\n            \\text{CZ}(s)^\\dagger \\hat{a}_2 \\text{CZ}(s) &= \\a_2+  i\\frac{s}{2} (\\ad_1 +  \\a_1)\\\\\n    """"""\n    ns = 2\n\n    def __init__(self, s=1):\n        super().__init__([s])\n\n    def _decompose(self, reg, **kwargs):\n        # phase-rotated CZ\n        CX = CXgate(self.p[0])\n        return [\n            Command(Rgate(-np.pi / 2), reg[1]),\n            Command(CX, reg),\n            Command(Rgate(np.pi / 2), reg[1]),\n        ]\n\n\nclass CKgate(Gate):\n    r""""""Cross-Kerr gate.\n\n    .. math::\n        CK(\\kappa) = e^{i \\kappa \\hat{n}_1\\hat{n}_2}\n\n    .. warning::\n        The cross-Kerr gate is **non-Gaussian**, and thus can only\n        be used in the Fock backends, *not* the Gaussian backend.\n\n    Args:\n        kappa (float): parameter\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            The cross-Kerr interaction is given by the Hamiltonian\n\n            .. math::\n                H = \\hat{n}_1\\hat{n_2}\n\n            which is non-Gaussian and diagonal in the Fock basis.\n\n        We can therefore define the cross-Kerr gate, with parameter :math:`\\kappa` as\n\n        .. math::\n            CK(\\kappa) = \\exp{(i\\kappa\\hat{n}_1\\hat{n_2})}.\n    """"""\n    ns = 2\n\n    def __init__(self, kappa):\n        super().__init__([kappa])\n\n    def _apply(self, reg, backend, **kwargs):\n        p = par_evaluate(self.p)\n        backend.cross_kerr_interaction(p[0], *reg)\n\n\nclass Fouriergate(Gate):\n    r""""""Fourier gate.\n\n    Also accessible via the shortcut variable ``Fourier``.\n\n    A special case of the :class:`phase space rotation gate <Rgate>`,\n    where :math:`\\theta=\\pi/2`.\n\n    .. math::\n        F = R(\\pi/2) = e^{i (\\pi/2) a^\\dagger a}\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            A special case of the :doc:`rotation operator <strawberryfields.ops.Rgate>`\n            is the case :math:`\\phi=\\pi/2`; this corresponds to the Fourier gate,\n\n            .. math::\n                F = R(\\pi/2) = e^{i (\\pi/2) \\ad \\a}.\n\n        The Fourier gate transforms the quadratures as follows:\n\n        .. math::\n            & F^\\dagger\\x F = -\\p,\\\\\n            & F^\\dagger\\p F = \\x.\n    """"""\n\n    def __init__(self):\n        super().__init__([np.pi / 2])\n\n    def _decompose(self, reg, **kwargs):\n        # into a rotation\n        theta = np.pi / 2\n        return [Command(Rgate(theta), reg)]\n\n    def __str__(self):\n        """"""String representation for the gate.""""""\n        temp = ""Fourier""\n        if self.dagger:\n            temp += "".H""\n        return temp\n\n\n# ====================================================================\n# Metaoperations\n# ====================================================================\n\n\n# ====================================================================\n# Subsystem creation and deletion\n# ====================================================================\n\n\nclass MetaOperation(Operation):\n    """"""Abstract base class for metaoperations.\n\n    This includes subsystem creation and deletion.\n    """"""\n\n    def __init__(self):\n        super().__init__(par=[])\n\n\nclass _Delete(MetaOperation):\n    """"""Deletes one or more existing modes.\n    Also accessible via the shortcut variable ``Del``.\n\n    The deleted modes are traced out.\n    After the deletion the state of the remaining subsystems may have to be described using a density operator.\n    """"""\n\n    ns = None\n\n    def __or__(self, reg):\n        reg = super().__or__(reg)\n        pu.Program_current_context._delete_subsystems(reg)\n\n    def _apply(self, reg, backend, **kwargs):\n        backend.del_mode(reg)\n\n    def __str__(self):\n        # use the shorthand object\n        return ""Del""\n\n\ndef New(n=1):\n    """"""Adds new subsystems to the quantum register.\n\n    The new modes are prepared in the vacuum state.\n\n    Must only be called in a :class:`Program` context.\n\n    Args:\n        n (int): number of subsystems to add\n    Returns:\n        tuple[RegRef]: tuple of the newly added subsystem references\n    """"""\n    if pu.Program_current_context is None:\n        raise RuntimeError(""New() can only be called inside a Program context."")\n    # create RegRefs for the new modes\n    refs = pu.Program_current_context._add_subsystems(n)\n    # append the actual Operation to the Program\n    pu.Program_current_context.append(_New_modes(n), refs)\n    return refs\n\n\nclass _New_modes(MetaOperation):\n    """"""Used internally for adding new modes to the system in a deferred way.\n\n    This class cannot be used with the :meth:`__or__` syntax since it would be misleading.\n    Indeed, users should *not* use this class directly, but rather the function :func:`New`.\n    """"""\n\n    ns = 0\n\n    def __init__(self, n=1):\n        """"""\n        Args:\n            n (int): number of modes to add\n        """"""\n        super().__init__()\n        self.n = n  # int: store the number of new modes for the __str__ method\n\n    def _apply(self, reg, backend, **kwargs):\n        # pylint: disable=unused-variable\n        inds = backend.add_mode(len(reg))\n\n    def __str__(self):\n        # use the shorthand object\n        return ""New({})"".format(self.n)\n\n\nclass All(MetaOperation):\n    """"""Metaoperation for applying a single-mode operation to every mode in the register.\n\n    Args:\n        op (Operation): single-mode operation to apply\n    """"""\n\n    def __init__(self, op):\n        if op.ns != 1:\n            raise ValueError(""Not a one-subsystem operation."")\n        super().__init__()\n        self.op = op  #: Operation: one-subsystem operation to apply\n\n    def __str__(self):\n        return super().__str__() + ""({})"".format(str(self.op))\n\n    def __or__(self, reg):\n        # into a list of subsystems\n        reg = _seq_to_list(reg)\n        # convert into commands\n        # make sure reg does not contain duplicates (we feed them to Program.append() one by one)\n        pu.Program_current_context._test_regrefs(reg)\n        for r in reg:\n            pu.Program_current_context.append(self.op, [r])\n\n\n# ====================================================================\n# Decompositions\n# ====================================================================\n\n\nclass Interferometer(Decomposition):\n    r""""""Apply a linear interferometer to the specified qumodes.\n\n    This operation uses either the rectangular decomposition\n    or triangular decomposition to decompose\n    a linear interferometer into a sequence of beamsplitters and\n    rotation gates.\n\n    By specifying the keyword argument ``mesh``, the scheme used to implement the interferometer\n    may be adjusted:\n\n    * ``mesh=\'rectangular\'`` (default): uses the scheme described in\n      :cite:`clements2016`, resulting in a *rectangular* array of\n      :math:`M(M-1)/2` beamsplitters:\n\n      .. figure:: ../../_static/clements.png\n          :align: center\n          :width: 30%\n          :target: javascript:void(0);\n\n      Local phase shifts appear in the middle of the beamsplitter array.\n      Use ``mesh=\'rectangular_phase_end`` to instead commute all local phase shifts\n      to the end of the beamsplitter array.\n\n      By default, the interferometers are decomposed into :class:`~.BSgate` operations.\n      To instead decompose the interferometer using the :class:`~.ops.MZgate`,\n      use ``mesh=\'rectangular_symmetric\'``.\n\n    * ``mesh=\'triangular\'``: uses the scheme described in :cite:`reck1994`,\n      resulting in a *triangular* array of :math:`M(M-1)/2` beamsplitters:\n\n      .. figure:: ../../_static/reck.png\n          :align: center\n          :width: 30%\n          :target: javascript:void(0);\n\n      Local phase shifts appear at the end of the beamsplitter array.\n\n    Args:\n        U (array[complex]): an :math:`N\\times N` unitary matrix\n        mesh (str): the scheme used to implement the interferometer.\n            Options include:\n\n            - ``\'rectangular\'`` - rectangular mesh, with local phase shifts\n              applied between interferometers\n\n            - ``\'rectangular_phase_end\'`` - rectangular mesh, with local phase shifts\n              placed after all interferometers\n\n            - ``\'rectangular_symmetric\'`` - rectangular mesh, with local phase shifts\n              placed after all interferometers, and all beamsplitters decomposed into\n              pairs of symmetric beamsplitters and phase shifters\n\n            - ``\'triangular\'`` - triangular mesh\n\n        drop_identity (bool): If ``True``, decomposed gates with trivial parameters,\n            such that they correspond to an identity operation, are removed.\n        tol (float): the tolerance used when checking if the input matrix is unitary:\n            :math:`|U-U^\\dagger| <` tol\n\n    .. details::\n\n        The rectangular decomposition allows any passive Gaussian transformation\n        to be decomposed into a series of beamsplitters and rotation gates.\n\n        .. admonition:: Definition\n            :class: defn\n\n            For every real orthogonal symplectic matrix\n\n            .. math:: O=\\begin{bmatrix}X&-Y\\\\ Y&X\\end{bmatrix}\\in\\mathbb{R}^{2N\\times 2N},\n\n            the corresponding unitary matrix :math:`U=X+iY\\in\\mathbb{C}^{N\\times N}`\n            representing a multiport interferometer can be decomposed into a set\n            of :math:`N(N-1)/2` beamsplitters and single mode rotations with circuit\n            depth of :math:`N`.\n\n            For more details, see :cite:`clements2016`.\n\n        .. note::\n\n            The rectangular decomposition as formulated by Clements :cite:`clements2016`\n            uses a different beamsplitter convention to Strawberry Fields:\n\n            .. math:: BS_{clements}(\\theta, \\phi) = BS(\\theta, 0) R(\\phi)\n    """"""\n    # pylint: disable=too-many-instance-attributes\n\n    def __init__(self, U, mesh=""rectangular"", drop_identity=True, tol=1e-6):\n        super().__init__([U])\n        self.ns = U.shape[0]\n        self.mesh = mesh\n        self.tol = tol\n        self.drop_identity = drop_identity\n\n        allowed_meshes = {\n            ""rectangular"",\n            ""rectangular_phase_end"",\n            ""rectangular_symmetric"",\n            ""triangular"",\n        }\n\n        if mesh not in allowed_meshes:\n            raise ValueError(\n                ""Unknown mesh \'{}\'. Mesh must be one of {}"".format(mesh, allowed_meshes)\n            )\n\n        self.identity = np.allclose(U, np.identity(len(U)), atol=_decomposition_merge_tol, rtol=0)\n\n    def _decompose(self, reg, **kwargs):\n        mesh = kwargs.get(""mesh"", self.mesh)\n        tol = kwargs.get(""tol"", self.tol)\n        drop_identity = kwargs.get(""drop_identity"", self.drop_identity)\n\n        cmds = []\n\n        if not self.identity or not drop_identity:\n            decomp_fn = getattr(dec, mesh)\n            BS1, R, BS2 = decomp_fn(self.p[0], tol=tol)\n\n            for n, m, theta, phi, _ in BS1:\n                theta = theta if np.abs(theta) >= _decomposition_tol else 0\n                phi = phi if np.abs(phi) >= _decomposition_tol else 0\n\n                if ""symmetric"" in mesh:\n                    # Mach-Zehnder interferometers\n                    cmds.append(\n                        Command(\n                            MZgate(np.mod(theta, 2 * np.pi), np.mod(phi, 2 * np.pi)),\n                            (reg[n], reg[m]),\n                        )\n                    )\n\n                else:\n                    # Clements style beamsplitters\n                    if not (drop_identity and phi == 0):\n                        cmds.append(Command(Rgate(phi), reg[n]))\n\n                    if not (drop_identity and theta == 0):\n                        cmds.append(Command(BSgate(theta, 0), (reg[n], reg[m])))\n\n            for n, expphi in enumerate(R):\n                # local phase shifts\n                q = np.log(expphi).imag if np.abs(expphi - 1) >= _decomposition_tol else 0\n                if not (drop_identity and q == 0):\n                    cmds.append(Command(Rgate(q), reg[n]))\n\n            if BS2 is not None:\n                # Clements style beamsplitters\n\n                for n, m, theta, phi, _ in reversed(BS2):\n                    theta = theta if np.abs(theta) >= _decomposition_tol else 0\n                    phi = phi if np.abs(phi) >= _decomposition_tol else 0\n\n                    if not (drop_identity and theta == 0):\n                        cmds.append(Command(BSgate(-theta, 0), (reg[n], reg[m])))\n                    if not (drop_identity and phi == 0):\n                        cmds.append(Command(Rgate(-phi), reg[n]))\n\n        return cmds\n\n\nclass GraphEmbed(Decomposition):\n    r""""""Embed a graph into an interferometer setup.\n\n    This operation uses the Takagi decomposition to decompose\n    an adjacency matrix into a sequence of squeezers and beamsplitters and\n    rotation gates.\n\n    Args:\n        A (array): an :math:`N\\times N` complex or real symmetric matrix\n        mean_photon_per_mode (float): guarantees that the mean photon number in the pure Gaussian state\n            representing the graph satisfies  :math:`\\frac{1}{N}\\sum_{i=1}^N sinh(r_{i})^2 ==` :code:``mean_photon``\n        make_traceless (boolean): Removes the trace of the input matrix, by performing the transformation\n            :math:`\\tilde{A} = A-\\mathrm{tr}(A) \\I/n`. This may reduce the amount of squeezing needed to encode\n            the graph but will lead to different photon number statistics for events with more than\n            one photon in any mode.\n        tol (float): the tolerance used when checking if the input matrix is symmetric:\n            :math:`|A-A^T| <` tol\n    """"""\n\n    def __init__(self, A, mean_photon_per_mode=1.0, make_traceless=False, tol=1e-6):\n        super().__init__([A])\n        self.ns = A.shape[0]\n\n        if np.allclose(A, np.identity(len(A)), atol=_decomposition_merge_tol, rtol=0):\n            self.identity = True\n        else:\n            self.identity = False\n            self.sq, self.U = dec.graph_embed(\n                A,\n                mean_photon_per_mode=mean_photon_per_mode,\n                make_traceless=make_traceless,\n                atol=tol,\n                rtol=0,\n            )\n\n    def _decompose(self, reg, **kwargs):\n        cmds = []\n\n        if not self.identity:\n            for n, s in enumerate(self.sq):\n                if np.abs(s) >= _decomposition_tol:\n                    cmds.append(Command(Sgate(s), reg[n]))\n\n            if not np.allclose(self.U, np.identity(len(self.U)), atol=_decomposition_tol, rtol=0):\n                mesh = kwargs.get(""mesh"", ""rectangular"")\n                cmds.append(Command(Interferometer(self.U, mesh=mesh), reg))\n\n        return cmds\n\n\nclass BipartiteGraphEmbed(Decomposition):\n    r""""""Embed a bipartite graph into an interferometer setup.\n\n    A bipartite graph is a graph that consists of two vertex sets :math:`U` and :math:`V`,\n    such that every edge in the graph connects a vertex between :math:`U` and :math:`V`.\n    That is, there are no edges between vertices in the same vertex set.\n\n    The adjacency matrix of an :math:`N` vertex undirected bipartite graph\n    is a :math:`N\\times N` symmetric matrix of the form\n\n    .. math:: A = \\begin{bmatrix}0 & B \\\\ B^T & 0\\end{bmatrix}\n\n    where :math:`B` is a :math:`N/2\\times N/2` matrix representing the (weighted)\n    edges between the vertex set.\n\n    This operation decomposes an adjacency matrix into a sequence of two\n    mode squeezers, beamsplitters, and rotation gates.\n\n    Args:\n        A (array): Either an :math:`N\\times N` complex or real symmetric adjacency matrix\n            :math:`A`, or an :math:`N/2\\times N/2` complex or real matrix :math:`B`\n            representing the edges between the vertex sets if ``edges=True``.\n        mean_photon_per_mode (float): guarantees that the mean photon number in the pure Gaussian state\n            representing the graph satisfies  :math:`\\frac{1}{N}\\sum_{i=1}^N sinh(r_{i})^2 ==` :code:``mean_photon``\n        edges (bool): set to ``True`` if argument ``A`` represents the edges :math:`B`\n            between the vertex sets rather than the full adjacency matrix\n        drop_identity (bool): If ``True``, decomposed gates with trivial parameters,\n            such that they correspond to an identity operation, are removed.\n        tol (float): the tolerance used when checking if the input matrix is symmetric:\n            :math:`|A-A^T| <` tol\n    """"""\n\n    def __init__(self, A, mean_photon_per_mode=1.0, edges=False, drop_identity=True, tol=1e-6):\n        self._check_p0(A)\n        self.mean_photon_per_mode = mean_photon_per_mode\n        self.tol = tol\n        self.identity = np.all(np.abs(A - np.identity(len(A))) < _decomposition_merge_tol)\n        self.drop_identity = drop_identity\n\n        if edges:\n            self.ns = 2 * A.shape[0]\n            B = A\n        else:\n            self.ns = A.shape[0]\n\n            # check if A is a bipartite graph\n            N = A.shape[0] // 2\n            A00 = A[:N, :N]\n            A11 = A[N:, N:]\n\n            diag_zeros = np.allclose(A00, np.zeros_like(A00), atol=tol, rtol=0) and np.allclose(\n                A11, np.zeros_like(A11), atol=tol, rtol=0\n            )\n\n            if (not diag_zeros) or (not np.allclose(A, A.T, atol=tol, rtol=0)):\n                raise ValueError(\n                    ""Adjacency matrix {} does not represent a bipartite graph"".format(A)\n                )\n\n            B = A[:N, N:]\n\n        super().__init__([B])\n\n    def _decompose(self, reg, **kwargs):\n        mean_photon_per_mode = kwargs.get(""mean_photon_per_mode"", self.mean_photon_per_mode)\n        tol = kwargs.get(""tol"", self.tol)\n        mesh = kwargs.get(""mesh"", ""rectangular"")\n        drop_identity = kwargs.get(""drop_identity"", self.drop_identity)\n\n        cmds = []\n\n        B = self.p[0]\n        N = len(B)\n\n        sq, U, V = dec.bipartite_graph_embed(\n            B, mean_photon_per_mode=mean_photon_per_mode, atol=tol, rtol=0\n        )\n\n        if not self.identity or not drop_identity:\n            for m, s in enumerate(sq):\n                s = s if np.abs(s) >= _decomposition_tol else 0\n\n                if not (drop_identity and s == 0):\n                    cmds.append(Command(S2gate(-s), (reg[m], reg[m + N])))\n\n            for X, _reg in ((U, reg[:N]), (V, reg[N:])):\n\n                if np.allclose(X, np.identity(len(X)), atol=_decomposition_tol, rtol=0):\n                    X = np.identity(len(X))\n\n                if not (drop_identity and np.all(X == np.identity(len(X)))):\n                    cmds.append(\n                        Command(\n                            Interferometer(X, mesh=mesh, drop_identity=drop_identity, tol=tol), _reg\n                        )\n                    )\n\n        return cmds\n\n\nclass GaussianTransform(Decomposition):\n    r""""""Apply a Gaussian symplectic transformation to the specified qumodes.\n\n    This operation uses the Bloch-Messiah decomposition\n    to decompose a symplectic matrix :math:`S`:\n\n    .. math:: S = O_1 R O_2\n\n    where :math:`O_1` and :math:`O_2` are two orthogonal symplectic matrices (and thus passive\n    Gaussian transformations), and :math:`R`\n    is a squeezing transformation in the phase space (:math:`R=\\text{diag}(e^{-z},e^z)`).\n\n    The symplectic matrix describing the Gaussian transformation on :math:`N` modes must satisfy\n\n    .. math:: S\\Omega S^T = \\Omega, ~~\\Omega = \\begin{bmatrix}0&I\\\\-I&0\\end{bmatrix}\n\n    where :math:`I` is the :math:`N\\times N` identity matrix, and :math:`0` is the zero matrix.\n\n    The two orthogonal symplectic unitaries describing the interferometers are then further\n    decomposed via the :class:`~.Interferometer` operator and the\n    :ref:`Rectangular decomposition <rectangular>`:\n\n    .. math:: U_i = X_i + iY_i\n\n    where\n\n    .. math:: O_i = \\begin{bmatrix}X&-Y\\\\Y&X\\end{bmatrix}\n\n    Args:\n        S (array[float]): a :math:`2N\\times 2N` symplectic matrix describing the Gaussian transformation.\n        vacuum (bool): set to True if acting on a vacuum state. In this case, :math:`O_2 V O_2^T = I`,\n            and the unitary associated with orthogonal symplectic :math:`O_2` will be ignored.\n        tol (float): the tolerance used when checking if the matrix is symplectic:\n            :math:`|S^T\\Omega S-\\Omega| \\leq` tol\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            For every symplectic matrix :math:`S\\in\\mathbb{R}^{2N\\times 2N}`, there\n            exists orthogonal symplectic matrices :math:`O_1` and :math:`O_2`, and\n            diagonal matrix :math:`Z`, such that\n\n            .. math:: S = O_1 Z O_2\n\n            where :math:`Z=\\text{diag}(e^{-r_1},\\dots,e^{-r_N},e^{r_1},\\dots,e^{r_N})`\n            represents a set of one mode squeezing operations with parameters\n            :math:`(r_1,\\dots,r_N)`.\n\n        Gaussian symplectic transforms can be grouped into two main types; passive\n        transformations (those which preserve photon number) and active transformations\n        (those which do not). Compared to active transformation, passive transformations\n        have an additional constraint - they must preserve the trace of the covariance\n        matrix, :math:`\\text{Tr}(SVS^T)=\\text{Tr}(V)`; this only occurs when the\n        symplectic matrix :math:`S` is also orthogonal (:math:`SS^T=\\I`).\n\n        The Bloch-Messiah decomposition therefore allows any active symplectic\n        transformation to be decomposed into two passive Gaussian transformations\n        :math:`O_1` and :math:`O_2`, sandwiching a set of one-mode squeezers, an\n        active transformation.\n\n        **Acting on the vacuum**\n\n        In the case where the symplectic matrix :math:`S` is applied to a vacuum state\n        :math:`V=\\frac{\\hbar}{2}\\I`, the action of :math:`O_2` cancels out due to its orthogonality:\n\n        .. math::\n            SVS^T = (O_1 Z O_2)\\left(\\frac{\\hbar}{2}\\I\\right)(O_1 Z O_2)^T\n            = \\frac{\\hbar}{2} O_1 Z O_2 O_2^T Z O_1^T = \\frac{\\hbar}{2}O_1 Z^2 O_1^T\n\n        As such, a symplectic transformation acting on the vacuum is sufficiently\n        characterised by single mode squeezers followed by a passive Gaussian\n        transformation (:math:`S = O_1 Z`).\n    """"""\n\n    def __init__(self, S, vacuum=False, tol=1e-10):\n        super().__init__([S])\n        self.ns = S.shape[0] // 2\n        self.vacuum = (\n            vacuum  #: bool: if True, ignore the first unitary matrix when applying the gate\n        )\n        N = self.ns  # shorthand\n\n        # check if input symplectic is passive (orthogonal)\n        diffn = np.linalg.norm(S @ S.T - np.identity(2 * N))\n        self.active = (\n            np.abs(diffn) > _decomposition_tol\n        )  #: bool: S is an active symplectic transformation\n\n        if not self.active:\n            # The transformation is passive, do Clements\n            X1 = S[:N, :N]\n            P1 = S[N:, :N]\n            self.U1 = X1 + 1j * P1\n        else:\n            # transformation is active, do Bloch-Messiah\n            O1, smat, O2 = dec.bloch_messiah(S, tol=tol)\n            X1 = O1[:N, :N]\n            P1 = O1[N:, :N]\n            X2 = O2[:N, :N]\n            P2 = O2[N:, :N]\n\n            self.U1 = X1 + 1j * P1  #: array[complex]: unitary matrix corresponding to O_1\n            self.U2 = X2 + 1j * P2  #: array[complex]: unitary matrix corresponding to O_2\n            self.Sq = np.diagonal(smat)[\n                :N\n            ]  #: array[complex]: diagonal vector of the squeezing matrix R\n\n    def _decompose(self, reg, **kwargs):\n        cmds = []\n        mesh = kwargs.get(""mesh"", ""rectangular"")\n\n        if self.active:\n            if not self.vacuum:\n                cmds = [Command(Interferometer(self.U2), reg)]\n\n            for n, expr in enumerate(self.Sq):\n                if np.abs(expr - 1) >= _decomposition_tol:\n                    r = np.abs(np.log(expr))\n                    phi = np.angle(np.log(expr))\n                    cmds.append(Command(Sgate(-r, phi), reg[n]))\n\n            cmds.append(Command(Interferometer(self.U1, mesh=mesh), reg))\n        else:\n            if not self.vacuum:\n                cmds = [Command(Interferometer(self.U1, mesh=mesh), reg)]\n\n        return cmds\n\n\nclass Gaussian(Preparation, Decomposition):\n    r""""""Prepare the specified modes in a Gaussian state.\n\n    This operation uses the Williamson decomposition to prepare\n    quantum modes into a given Gaussian state, specified by a\n    vector of means and a covariance matrix.\n\n    The Williamson decomposition decomposes the Gaussian state into a Gaussian\n    transformation (represented by a symplectic matrix) acting on :class:`~.Thermal`\n    states. The Gaussian transformation is then further decomposed into an array\n    of beamsplitters and local squeezing and rotation gates, by way of the\n    :class:`~.GaussianTransform` and :class:`~.Interferometer` decompositions.\n\n    Alternatively, the decomposition can be explicitly turned off, and the\n    backend can be explicitly prepared in the Gaussian state provided. This is\n    **only** supported by backends using the Gaussian representation.\n\n    .. note::\n\n        :math:`V` must be a valid quantum state satisfying the uncertainty principle:\n        :math:`V+\\frac{1}{2}i\\hbar\\Omega\\geq 0`. If this is not the case, the Williamson\n        decomposition will return non-physical thermal states with :math:`\\bar{n}_i<0`.\n\n    Args:\n        V (array[float]): an :math:`2N\\times 2N` (real and positive definite) covariance matrix\n        r (array[float] or None): Length :math:`2N` vector of means, of the\n            form :math:`(\\x_0,\\dots,\\x_{N-1},\\p_0,\\dots,\\p_{N-1})`.\n            If None, it is assumed that :math:`r=0`.\n        decomp (bool): Should the operation be decomposed into a sequence of elementary gates?\n            If False, the state preparation is performed directly via the backend API.\n        tol (float): the tolerance used when checking if the matrix is symmetric: :math:`|V-V^T| \\leq` tol\n\n    .. details::\n\n        .. admonition:: Definition\n            :class: defn\n\n            For every positive definite real matrix :math:`V\\in\\mathbb{R}^{2N\\times 2N}`,\n            there exists a symplectic matrix :math:`S` and diagonal matrix :math:`D` such that\n\n            .. math:: V = S D S^T\n\n            where :math:`D=\\text{diag}(\\nu_1,\\dots,\\nu_N,\\nu_1,\\dots,\\nu_N)`, and\n            :math:`\\{\\nu_i\\}` are the eigenvalues of :math:`|i\\Omega V|`, where :math:`||`\n            represents the element-wise absolute value.\n\n        The Williamson decomposition allows an arbitrary Gaussian covariance matrix to be\n        decomposed into a symplectic transformation acting on the state described\n        by the diagonal matrix :math:`D`.\n\n        The matrix :math:`D` can always be decomposed further into a set of\n        thermal states with mean photon number given by\n\n        .. math:: \\bar{n}_i = \\frac{1}{\\hbar}\\nu_i - \\frac{1}{2}, ~~i=1,\\dots,N\n\n        **Pure states**\n\n        In the case where :math:`V` represents a pure state (:math:`|V|-(\\hbar/2)^{2N}=0`),\n        the Williamson decomposition outputs :math:`D=\\frac{1}{2}\\hbar I_{2N}`; that is,\n        a symplectic transformation :math:`S` acting on the vacuum. It follows that the\n        original covariance matrix can therefore be recovered simply via :math:`V=\\frac{\\hbar}{2}SS^T`.\n    """"""\n    # pylint: disable=too-many-instance-attributes\n    ns = None\n\n    def __init__(self, V, r=None, decomp=True, tol=1e-6):\n        self._check_p0(V)\n        # internally we eliminate hbar from the covariance matrix V (or equivalently set hbar=2), but not from the means vector r\n        V = V / (sf.hbar / 2)\n        self.ns = V.shape[0] // 2\n\n        if r is None:\n            r = np.zeros(2 * self.ns)\n        r = np.asarray(r)\n\n        if len(r) != V.shape[0]:\n            raise ValueError(""Vector of means must have the same length as the covariance matrix."")\n\n        super().__init__([V, r], decomp=decomp)  # V is hbar-independent, r is not\n\n        self.x_disp = r[: self.ns]\n        self.p_disp = r[self.ns :]\n\n        # needed only if decomposed\n        th, self.S = dec.williamson(V, tol=tol)\n        self.pure = np.abs(np.linalg.det(V) - 1.0) < tol\n        self.nbar = 0.5 * (np.diag(th)[: self.ns] - 1.0)\n\n    def _apply(self, reg, backend, **kwargs):\n        p = par_evaluate(self.p)\n        s = np.sqrt(sf.hbar / 2)  # scaling factor, since the backend API call is hbar-independent\n        backend.prepare_gaussian_state(p[1] / s, p[0], reg)\n\n    def _decompose(self, reg, **kwargs):\n        # pylint: disable=too-many-branches\n        cmds = []\n\n        V = self.p[0]\n        D = np.diag(V)\n        is_diag = np.all(V == np.diag(D))\n\n        BD = changebasis(self.ns) @ V @ changebasis(self.ns).T\n        BD_modes = [BD[i * 2 : (i + 1) * 2, i * 2 : (i + 1) * 2] for i in range(BD.shape[0] // 2)]\n        is_block_diag = (not is_diag) and np.all(BD == block_diag(*BD_modes))\n\n        if self.pure and is_diag:\n            # covariance matrix consists of x/p quadrature squeezed state\n            for n, expr in enumerate(D[: self.ns]):\n                if np.abs(expr - 1) >= _decomposition_tol:\n                    r = np.abs(np.log(expr) / 2)\n                    cmds.append(Command(Squeezed(r, 0), reg[n]))\n                else:\n                    cmds.append(Command(Vac, reg[n]))\n\n        elif self.pure and is_block_diag:\n            # covariance matrix consists of rotated squeezed states\n            for n, v in enumerate(BD_modes):\n                if not np.all(v - np.identity(2) < _decomposition_tol):\n                    r = np.abs(np.arccosh(np.sum(np.diag(v)) / 2)) / 2\n                    phi = np.arctan(2 * v[0, 1] / np.sum(np.diag(v) * [1, -1]))\n                    cmds.append(Command(Squeezed(r, phi), reg[n]))\n                else:\n                    cmds.append(Command(Vac, reg[n]))\n\n        elif not self.pure and is_diag and np.all(D[: self.ns] == D[self.ns :]):\n            # covariance matrix consists of thermal states\n            for n, nbar in enumerate(0.5 * (D[: self.ns] - 1.0)):\n                if nbar >= _decomposition_tol:\n                    cmds.append(Command(Thermal(nbar), reg[n]))\n                else:\n                    cmds.append(Command(Vac, reg[n]))\n\n        else:\n            if not self.pure:\n                # mixed state, must initialise thermal states\n                for n, nbar in enumerate(self.nbar):\n                    if np.abs(nbar) >= _decomposition_tol:\n                        cmds.append(Command(Thermal(nbar), reg[n]))\n                    else:\n                        cmds.append(Command(Vac, reg[n]))\n\n            else:\n                for r in reg:\n                    cmds.append(Command(Vac, r))\n\n            cmds.append(Command(GaussianTransform(self.S, vacuum=self.pure), reg))\n\n        cmds += [Command(Xgate(u), reg[n]) for n, u in enumerate(self.x_disp) if u != 0]\n        cmds += [Command(Zgate(u), reg[n]) for n, u in enumerate(self.p_disp) if u != 0]\n\n        return cmds\n\n\n# =======================================================================\n# Shorthands, e.g. pre-constructed singleton-like objects\n\nDel = _Delete()\nVac = Vacuum()\nMeasureX = MeasureHomodyne(0)\nMeasureP = MeasureHomodyne(np.pi / 2)\nMeasureHD = MeasureHeterodyne()\n\nFourier = Fouriergate()\n\nshorthands = [""New"", ""Del"", ""Vac"", ""MeasureX"", ""MeasureP"", ""MeasureHD"", ""Fourier"", ""All""]\n\n# =======================================================================\n# here we list different classes of operations for unit testing purposes\n\nzero_args_gates = (Fouriergate,)\none_args_gates = (Xgate, Zgate, Rgate, Pgate, Vgate, Kgate, CXgate, CZgate, CKgate)\ntwo_args_gates = (Dgate, Sgate, BSgate, MZgate, S2gate)\ngates = zero_args_gates + one_args_gates + two_args_gates\n\nchannels = (LossChannel, ThermalLossChannel)\n\nsimple_state_preparations = (\n    Vacuum,\n    Coherent,\n    Squeezed,\n    DisplacedSqueezed,\n    Fock,\n    Catstate,\n    Thermal,\n)  # have __init__ methods with default arguments\nstate_preparations = simple_state_preparations + (Ket, DensityMatrix)\n\nmeasurements = (MeasureFock, MeasureHomodyne, MeasureHeterodyne, MeasureThreshold)\n\ndecompositions = (Interferometer, BipartiteGraphEmbed, GraphEmbed, GaussianTransform, Gaussian)\n\n# =======================================================================\n# exported symbols\n\n__all__ = [\n    cls.__name__ for cls in gates + channels + state_preparations + measurements + decompositions\n] + shorthands\n'"
strawberryfields/parameters.py,4,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThe classes in this module represent parameters passed to the\nquantum operations represented by :class:`~.Operation` subclasses.\n\nParameter types\n---------------\n\nThere are three basic types of parameters:\n\n1. **Numerical parameters** (bound and fixed): An immediate, immutable numerical object\n   (float, complex, int, numerical array).\n   Implemented as-is, not encapsulated in a class.\n\n2. **Measured parameters** (bound but not fixed): Certain quantum circuits/protocols require that\n   Operations can be conditioned on measurement results obtained during the execution of the\n   circuit. In this case the parameter value is not known/fixed until the measurement is made\n   (or simulated). Represented by :class:`MeasuredParameter` instances.\n   Constructed from the :class:`.RegRef` instance storing the measurement\n   result using the :meth:`.RegRef.par` method.\n\n3. **Free parameters** (not bound nor fixed): A *parametrized circuit template* is a circuit that\n   depends on a number of unbound (free) parameters. These parameters need to be bound to fixed\n   numerical values before the circuit can be executed on a hardware quantum device or a numeric\n   simulator. Represented by :class:`FreeParameter` instances.\n   Simulators with symbolic capability can accept a parametrized circuit as input (and should\n   return symbolic expressions representing the measurement results, with the same free parameters,\n   as output).\n   Free parameters belong to a single :class:`.Program` instance, are constructed using the\n   :meth:`.Program.params` method, and are bound using :meth:`.Program.bind_params`.\n\n:class:`.Operation` subclass constructors accept parameters that are functions or algebraic\ncombinations of any number of these basic parameter types. This is made possible by\n:class:`MeasuredParameter` and :class:`FreeParameter` inheriting from :class:`sympy.Symbol`.\n\n.. note:: Binary arithmetic operations between sympy symbols and numpy arrays produces numpy object arrays containing sympy symbols.\n\n\nOperation lifecycle\n-------------------\n\nThe normal lifecycle of an Operation object and its associated parameters is as follows:\n\n* An Operation instance is constructed, and given some input arguments.\n  In :meth:`.Operation.__init__`,\n  the RegRef dependencies of measured parameters are added to :attr:`.Operation._measurement_deps`.\n\n* The Operation instance is applied using its :meth:`~ops.Operation.__or__`\n  method inside a :class:`.Program` context.\n  This creates a :class:`.Command` instance that wraps\n  the Operation and the RegRefs it acts on, which is appended to :attr:`.Program.circuit`.\n\n* Before the Program is run, it is compiled and optimized for a specific backend. This involves\n  checking that the Program only contains valid Operations, decomposing non-elementary Operations\n  using :meth:`~ops.Operation.decompose`, and finally merging and commuting Commands inside\n  the graph representing the quantum circuit.\n  The circuit graph is built using the knowledge of which subsystems the Commands act and depend on.\n\n* Decompositions, merges, and commutations often involve the creation of new Operations with algebraically\n  transformed parameters.\n  For example, merging two :class:`.Gate` instances of the same subclass involves\n  adding their first parameters after equality-comparing the others. This is easily done if\n  all the parameters have an immediate numerical value.\n  Measured and free parameters are handled symbolically by Sympy.\n\n* The compiled Program is run by a :class:`.BaseEngine` instance, which calls the\n  :meth:`~ops.Operation.apply` method of each Operation in turn.\n\n* :meth:`~ops.Operation.apply` then calls :meth:`~ops.Operation._apply` which is redefined by each Operation subclass.\n  It evaluates the value of the parameters using :func:`par_evaluate`, and\n  may perform additional numeric transformations on them.\n  The parameter values are finally passed to the appropriate backend API method.\n  It is up to the backend to either accept NumPy arrays and TensorFlow objects as parameters, or not.\n\n\nWhat we cannot do at the moment:\n\n* Use anything except integers and RegRefs (or Sequences thereof) as the subsystem argument\n  for the :meth:`~ops.Operation.__or__` method.\n  Technically we could allow any parameters that evaluate into an integer.\n""""""\n# pylint: disable=too-many-ancestors,unused-argument,protected-access\n\nimport collections.abc\nimport functools\nimport types\n\nimport numpy as np\nimport sympy\nimport sympy.functions as sf\n\n\ndef wrap_mathfunc(func):\n    """"""Applies the wrapped sympy function elementwise to NumPy arrays.\n\n    Required because the sympy math functions cannot deal with NumPy arrays.\n    We implement no broadcasting; if the first argument is a NumPy array, we assume\n    all the arguments are arrays of the same shape.\n    """"""\n\n    @functools.wraps(func)\n    def wrapper(*args):\n        temp = [isinstance(k, np.ndarray) for k in args]\n        if any(temp):\n            if not all(temp):\n                raise ValueError(\n                    ""Parameter functions with array arguments: all the arguments must be arrays of the same shape.""\n                )\n            for k in args[1:]:\n                if len(k) != len(args[0]):\n                    raise ValueError(\n                        ""Parameter functions with array arguments: all the arguments must be arrays of the same shape.""\n                    )\n            # apply func elementwise, recursively, on the args\n            return np.array([wrapper(*k) for k in zip(*args)])\n        return func(*args)\n\n    return wrapper\n\n\npar_funcs = types.SimpleNamespace(\n    **{name: wrap_mathfunc(getattr(sf, name)) for name in dir(sf) if name[0] != ""_""}\n)\n""""""SimpleNamespace: Namespace of mathematical functions for manipulating Parameters.\nConsists of all :mod:`sympy.functions` public members, which we wrap with :func:`wrap_mathfunc`.\n""""""\n\n\nclass ParameterError(RuntimeError):\n    """"""Exception raised when the Parameter classes encounter an illegal operation.\n\n    E.g., trying to use a measurement result before it is available.\n    """"""\n\n\ndef is_object_array(p):\n    """"""Returns True iff p is an object array.\n\n    Args:\n        p (Any): object to be checked\n\n    Returns:\n        bool: True iff p is a NumPy object array\n    """"""\n    return isinstance(p, np.ndarray) and p.dtype == object\n\n\ndef par_evaluate(params, dtype=None):\n    """"""Evaluate an Operation parameter sequence.\n\n    Any parameters descending from :class:`sympy.Basic` are evaluated, others are returned as-is.\n    Evaluation means that free and measured parameters are replaced by their numeric values.\n    NumPy object arrays are evaluated elementwise.\n\n    Alternatively, evaluates a single parameter and returns its value.\n\n    Args:\n        params (Sequence[Any]): parameters to evaluate\n        dtype (None, np.dtype, tf.dtype): NumPy or TensorFlow datatype to optionally cast atomic symbols\n            to *before* evaluating the parameter expression. Note that if the atom\n            is a TensorFlow tensor, a NumPy datatype can still be passed; ``tensorflow.dtype.as_dtype()``\n            is used to determine the corresponding TensorFlow dtype internally.\n\n    Returns:\n        list[Any]: evaluated parameters\n    """"""\n    scalar = False\n    if not isinstance(params, collections.abc.Sequence):\n        scalar = True\n        params = [params]\n\n    def do_evaluate(p):\n        """"""Evaluates a single parameter.""""""\n        if is_object_array(p):\n            return np.array([do_evaluate(k) for k in p])\n\n        if not par_is_symbolic(p):\n            return p\n\n        # using lambdify we can also substitute np.ndarrays and tf.Tensors for the atoms\n        atoms = list(p.atoms(MeasuredParameter, FreeParameter))\n        # evaluate the atoms of the expression\n        vals = [k._eval_evalf(None) for k in atoms]\n        # use the tensorflow printer if any of the symbolic parameter values are TF objects\n        # (we do it like this to avoid importing tensorflow if it\'s not needed)\n        is_tf = (type(v).__module__.startswith(""tensorflow"") for v in vals)\n        printer = ""tensorflow"" if any(is_tf) else ""numpy""\n        func = sympy.lambdify(atoms, p, printer)\n\n        if dtype is not None:\n            # cast the input values\n            if printer == ""tensorflow"":\n                import tensorflow as tf\n\n                tfdtype = tf.as_dtype(dtype)\n                vals = [tf.cast(v, dtype=tfdtype) for v in vals]\n            else:\n                vals = [dtype(v) for v in vals]\n\n        return func(*vals)\n\n    ret = list(map(do_evaluate, params))\n    if scalar:\n        return ret[0]\n    return ret\n\n\ndef par_is_symbolic(p):\n    """"""Returns True iff p is a symbolic Operation parameter instance.\n\n    If a parameter inherits :class:`sympy.Basic` it is symbolic.\n    A NumPy object array is symbolic if any of its elements are.\n    All other objects are considered not symbolic parameters.\n\n    Note that :data:`strawberryfields.math` functions applied to numerical (non-symbolic) parameters return\n    symbolic parameters.\n    """"""\n    if is_object_array(p):\n        return any(par_is_symbolic(k) for k in p)\n    return isinstance(p, sympy.Basic)\n\n\ndef par_convert(args, prog):\n    """"""Convert Blackbird symbolic Operation arguments into their SF counterparts.\n\n    Args:\n        args (Iterable[Any]): Operation arguments\n        prog (Program): program containing the Operations.\n\n    Returns:\n        list[Any]: converted arguments\n    """"""\n\n    def do_convert(a):\n        if isinstance(a, sympy.Basic):\n            # substitute SF symbolic parameter objects for Blackbird ones\n            s = {}\n            for k in a.atoms(sympy.Symbol):\n                if k.name[0] == ""q"":\n                    s[k] = MeasuredParameter(prog.register[int(k.name[1:])])\n                else:\n                    s[k] = prog.params(k.name)  # free parameter\n            return a.subs(s)\n        return a  # return non-symbols as-is\n\n    return [do_convert(a) for a in args]\n\n\ndef par_regref_deps(p):\n    """"""RegRef dependencies of an Operation parameter.\n\n    Returns the RegRefs that the parameter depends on through the :class:`MeasuredParameter`\n    atoms it contains.\n\n    Args:\n        p (Any): Operation parameter\n\n    Returns:\n        set[RegRef]: RegRefs the parameter depends on\n    """"""\n    ret = set()\n    if is_object_array(p):\n        # p is an object array, possibly containing symbols\n        for k in p:\n            ret.update(par_regref_deps(k))\n    elif isinstance(p, sympy.Basic):\n        # p is a Sympy expression, possibly containing measured parameters\n        for k in p.atoms(MeasuredParameter):\n            ret.add(k.regref)\n    return ret\n\n\ndef par_str(p):\n    """"""String representation of the Operation parameter.\n\n    Args:\n        p (Any): Operation parameter\n\n    Returns:\n        str: string representation\n    """"""\n    if isinstance(p, np.ndarray):\n        np.set_printoptions(precision=4)\n        return str(p)\n    if par_is_symbolic(p):\n        return str(p)\n    return ""{:.4g}"".format(p)  # scalar parameters\n\n\nclass MeasuredParameter(sympy.Symbol):\n    """"""Single measurement result used as an Operation parameter.\n\n    A MeasuredParameter instance, given as a parameter to a\n    :class:`~strawberryfields.ops.Operation` constructor, represents\n    a dependence of the Operation on classical information obtained by\n    measuring a subsystem of the register.\n\n    Used for deferred measurements, i.e., using a measurement\'s value\n    symbolically in defining a gate before the numeric value of that\n    measurement is available.\n\n    Former RegRefTransform (SF <= 0.11) functionality is provided by the sympy.Symbol base class.\n\n    Args:\n        regref (RegRef): register reference responsible for storing the measurement result\n    """"""\n\n    def __new__(cls, regref):\n        # sympy.Basic.__new__ wants a name, other arguments must not end up in self._args\n        return super().__new__(cls, ""q"" + str(regref.ind))\n\n    def __init__(self, regref):\n        if not regref.active:\n            raise ValueError(""Trying to use an inactive RegRef."")\n        #: RegRef: the value of the parameter depends on this RegRef, and can only be evaluated after the corresponding subsystem has been measured\n        self.regref = regref\n\n    def _sympystr(self, printer):\n        """"""Blackbird notation.\n\n        The Sympy printing system uses this method instead of __str__.\n        """"""\n        return ""q{}"".format(self.regref.ind)\n\n    def _eval_evalf(self, prec):\n        """"""Returns the numeric result of the measurement if it is available.\n\n        Returns:\n            Any: measurement result\n\n        Raises:\n            ParameterError: iff the parameter has not been measured yet\n        """"""\n        res = self.regref.val\n        if res is None:\n            raise ParameterError(\n                ""{}: trying to use a nonexistent measurement result (e.g., before it has been measured)."".format(\n                    self\n                )\n            )\n        return res\n\n\nclass FreeParameter(sympy.Symbol):\n    """"""Named symbolic Operation parameter.\n\n    Args:\n        name (str): name of the free parameter\n    """"""\n\n    def __init__(self, name):\n        #: str: name of the free parameter\n        self.name = name\n        #: Any: value of the parameter, None means unbound\n        self.val = None\n        #: Any: default value of the parameter, used if unbound\n        self.default = None\n\n    def _sympystr(self, printer):\n        """"""Blackbird notation.\n\n        The Sympy printing system uses this method instead of __str__.\n        """"""\n        return ""{{{}}}"".format(self.name)\n\n    def _eval_evalf(self, prec):\n        """"""Returns the value of the parameter if it has been bound, or the default value if not.\n\n        Returns:\n            Any: bound value, or the default value if not bound\n\n        Raises:\n            ParameterError: iff the parameter has not been bound, and has no default value\n        """"""\n        if self.val is None:\n            if self.default is None:\n                raise ParameterError(""{}: unbound parameter with no default value."".format(self))\n            return self.default\n        return self.val\n'"
strawberryfields/program.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nThis module implements the :class:`.Program` class which acts as a representation for quantum circuits.\n\nQuantum circuit representation\n------------------------------\n\nThe :class:`.Command` instances in the circuit form a\n`strict partially ordered set <http://en.wikipedia.org/wiki/Partially_ordered_set#Strict_and_non-strict_partial_orders>`_\nin the sense that the order in which the operations have to be executed is usually not completely fixed.\nFor example, operations acting on different subsystems always commute with each other.\nWe denote :math:`a < b` if :math:`a` has to be executed before :math:`b`.\nEach strict partial order corresponds to a\n`directed acyclic graph <http://en.wikipedia.org/wiki/Directed_acyclic_graph>`_ (DAG),\nand the transitive closure of any DAG is a strict partial order.\nThree different (but equivalent) representations of the circuit are used.\n\n* Initially, the circuit is represented as a Command queue (list), listing the Commands in\n  the temporal order they are applied.\n* The second representation, grid, essentially mimics a quantum circuit diagram.\n  It is a mapping from subsystem indices to lists of Commands touching that subsystem,\n  where each list is temporally ordered.\n* Finally, the quantum circuit can be represented using a DAG by making each Command a node,\n  and drawing an edge from each Command to all its immediate followers along each wire it touches.\n  It can be converted back into a command queue by popping a maximal element until the graph\n  is empty, that is, consuming it in a topological order.\n  Note that a topological order is not always unique, there may be several equivalent topological orders.\n\n.. currentmodule:: strawberryfields.program_utils\n\nThe three representations can be converted to each other\nusing the functions :func:`list_to_grid`, :func:`grid_to_DAG` and :func:`DAG_to_list`.\n\n.. currentmodule:: strawberryfields.program\n""""""\n# pylint: disable=too-many-instance-attributes,attribute-defined-outside-init\n\nimport copy\nimport numbers\nimport warnings\n\nimport networkx as nx\n\nimport strawberryfields.circuitdrawer as sfcd\nimport strawberryfields.circuitspecs as specs\nimport strawberryfields.program_utils as pu\nfrom .program_utils import Command, RegRef, CircuitError, RegRefError\nfrom .parameters import FreeParameter, ParameterError\n\n\n# for automodapi, do not include the classes that should appear under the top-level strawberryfields namespace\n__all__ = []\n\n\nclass Program:\n    """"""Represents a photonic quantum circuit.\n\n    The program class provides a context manager for:\n\n    * accessing the quantum register associated with the program, and\n    * appending :doc:`/introduction/ops` to the program.\n\n    Within the context, operations are appended to the program using the\n    Python-embedded Blackbird syntax\n\n    .. code-block:: python3\n\n        ops.GateName(arg1, arg2, ...) | (q[i], q[j], ...)\n\n    where ``ops.GateName`` is a valid quantum operation, and ``q`` is a list\n    of the programs quantum modes.\n    All operations are appended to the program in the order they are\n    listed within the context.\n\n    In addition, some \'meta-operations\' (such as :func:`~.New` and :attr:`~.Del`)\n    are provided to modify the programs quantum register itself by adding\n    and deleting subsystems.\n\n    .. note::\n\n        Two programs can be run successively on the same engine if and only if\n        the number of registers at the end of the first program matches the\n        number of modes at the beginning of the second program.\n\n        This can be enforced by constructing the second program as an explicit\n        successor of the first, in which case the registers are directly copied over.\n\n        When a Program is run or it obtains a successor, it is locked and no more\n        operations can be appended to it.\n\n    **Example:**\n\n    .. code-block:: python3\n\n        import strawberryfields as sf\n        from strawberryfields import ops\n\n        # create a 3 mode quantum program\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Sgate(0.54) | q[0]\n            ops.Sgate(0.54) | q[1]\n            ops.Sgate(0.54) | q[2]\n            ops.BSgate(0.43, 0.1) | (q[0], q[2])\n            ops.BSgate(0.43, 0.1) | (q[1], q[2])\n            ops.MeasureFock() | q\n\n    The currently active register references can be accessed using the :meth:`~Program.register` method.\n\n    Args:\n        num_subsystems (int, Program): Initial number of modes (subsystems) in the quantum register.\n            Alternatively, another Program instance from which to inherit the register state.\n        name (str): program name (optional)\n    """"""\n\n    def __init__(self, num_subsystems, name=None):\n        #: str: program name\n        self.name = name\n        #: list[Command]: Commands constituting the quantum circuit in temporal order\n        self.circuit = []\n        #: bool: if True, no more Commands can be appended to the Program\n        self.locked = False\n        #: str, None: for compiled Programs, the short name of the target CircuitSpecs template, otherwise None\n        self._target = None\n        #: Program, None: for compiled Programs, this is the original, otherwise None\n        self.source = None\n        #: dict[str, Parameter]: free circuit parameters owned by this Program\n        self.free_params = {}\n        self.run_options = {}\n        """"""dict[str, Any]: dictionary of default run options, to be passed to the engine upon\n        execution of the program. Note that if the ``run_options`` dictionary is passed\n        directly to :meth:`~.Engine.run`, it takes precedence over the run options specified\n        here.\n        """"""\n\n        # create subsystem references\n        # Program keeps track of the state of the quantum register using a dictionary of :class:`RegRef` objects.\n        if isinstance(num_subsystems, numbers.Integral):\n            #: int: initial number of subsystems\n            self.init_num_subsystems = num_subsystems\n            #: dict[int, RegRef]: mapping from subsystem indices to corresponding RegRef objects\n            self.reg_refs = {}\n            #: set[int]: created subsystem indices that have not been used (operated on) yet\n            self.unused_indices = set()\n            self._add_subsystems(num_subsystems)\n        elif isinstance(num_subsystems, Program):\n            # it\'s the parent program\n            parent = num_subsystems\n            # copy the RegRef state from the parent program\n            parent.lock()  # make sure the parent isn\'t accidentally updated by the user\n            self.init_num_subsystems = parent.num_subsystems\n            self.reg_refs = copy.deepcopy(parent.reg_refs)  # independent copy of the RegRefs\n            self.unused_indices = copy.copy(parent.unused_indices)\n        else:\n            raise TypeError(\n                ""First argument must be either the number of subsystems or the parent Program.""\n            )\n\n        # save the initial regref state\n        #: dict[int, RegRef]: like reg_refs\n        self.init_reg_refs = copy.deepcopy(self.reg_refs)\n        #: set[int]: like unused_indices\n        self.init_unused_indices = copy.copy(self.unused_indices)\n\n    def __str__(self):\n        """"""String representation.""""""\n        return self.__class__.__name__ + ""({}, {}->{} subsystems, compiled for \'{}\')"".format(\n            self.name, self.init_num_subsystems, self.num_subsystems, self.target\n        )\n\n    def __len__(self):\n        """"""Program length.\n\n        Returns:\n            int: number of Commands in the program\n        """"""\n        return len(self.circuit)\n\n    def print(self, print_fn=print):\n        """"""Print the program contents using Blackbird syntax.\n\n        **Example:**\n\n        .. code-block:: python\n\n            # create a 3 mode quantum program\n            prog = sf.Program(3)\n\n            with prog.context as q:\n                ops.Sgate(0.54) | q[0]\n                ops.Sgate(0.54) | q[1]\n                ops.Sgate(0.54) | q[2]\n                ops.BSgate(0.43, 0.1) | (q[0], q[2])\n                ops.BSgate(0.43, 0.1) | (q[1], q[2])\n                ops.MeasureFock() | q\n\n        >>> prog.print()\n        Sgate(0.54, 0) | (q[0])\n        Sgate(0.54, 0) | (q[1])\n        Sgate(0.54, 0) | (q[2])\n        BSgate(0.43, 0.1) | (q[0], q[2])\n        BSgate(0.43, 0.1) | (q[1], q[2])\n        MeasureFock | (q[0], q[1], q[2])\n\n        Args:\n            print_fn (function): optional custom function to use for string printing\n        """"""\n        for k in self.circuit:\n            print_fn(k)\n\n    @property\n    def context(self):\n        """"""Syntactic sugar for defining a Program using the :code:`with` statement.\n\n        The Program object itself acts as the context manager.\n        """"""\n        return self\n\n    def __enter__(self):\n        """"""Enter the context for this program.\n\n        Returns:\n            tuple[RegRef]: subsystem references\n        """"""\n        if pu.Program_current_context is None:\n            pu.Program_current_context = self\n        else:\n            raise RuntimeError(""Only one Program context can be active at a time."")\n        return self.register\n\n    def __exit__(self, ex_type, ex_value, ex_tb):\n        """"""Exit the quantum circuit context.""""""\n        pu.Program_current_context = None\n\n    # =================================================\n    #  RegRef accounting\n    # =================================================\n    @property\n    def register(self):\n        """"""Return a tuple of all the currently valid quantum modes.\n\n        Returns:\n            tuple[RegRef]: valid subsystem references\n        """"""\n        return tuple(r for r in self.reg_refs.values() if r.active)\n\n    @property\n    def num_subsystems(self):\n        """"""Return the current number of valid quantum modes.\n\n        Returns:\n            int: number of currently valid register subsystems\n        """"""\n        return len(self.register)\n\n    def _clear_regrefs(self):\n        """"""Clear any measurement values stored in the RegRefs.\n\n        Called by :class:`~.engine.Engine` when resetting the backend.\n        """"""\n        for r in self.reg_refs.values():\n            r.val = None\n\n    def _add_subsystems(self, n):\n        """"""Create new subsystem references, add them to the reg_ref dictionary.\n\n        To avoid discrepancies with the backend this method must not be called directly,\n        but rather indirectly by using :func:`~strawberryfields.ops.New`\n        in a Program context.\n\n        .. note:: This is the only place where :class:`RegRef` instances are constructed.\n\n        Args:\n            n (int): number of subsystems to add\n        Returns:\n            tuple[RegRef]: tuple of the newly added subsystem references\n        """"""\n        if self.locked:\n            raise CircuitError(""The Program is locked, no new subsystems can be created."")\n        if not isinstance(n, numbers.Integral) or n < 1:\n            raise ValueError(""Number of added subsystems {} is not a positive integer."".format(n))\n\n        first_unassigned_index = len(self.reg_refs)\n        # create a list of RegRefs\n        inds = [first_unassigned_index + i for i in range(n)]\n        refs = tuple(RegRef(i) for i in inds)\n        # add them to the index map\n        for r in refs:\n            self.reg_refs[r.ind] = r\n        # all the newly reserved indices are unused for now\n        self.unused_indices.update(inds)\n        return refs\n\n    def _delete_subsystems(self, refs):\n        """"""Delete existing subsystem references.\n\n        To avoid discrepancies with the backend this method must not be called directly,\n        but rather indirectly by using :class:`~strawberryfields.ops._Delete` instances\n        in the Program context.\n\n        Args:\n          refs (Sequence[RegRef]): subsystems to delete\n        """"""\n        # NOTE: refs have already been through _test_regrefs() in append() and thus should be valid\n        for r in refs:\n            # mark the RegRef as deleted\n            r.active = False\n            # self.reg_refs[r.ind].active = False\n        # NOTE: deleted indices are *not* removed from self.unused_indices\n\n    def lock(self):\n        """"""Finalize the program.\n\n        When a Program is locked, no more Commands can be appended to it.\n        The locking happens when the program is run, compiled, or a successor Program is constructed,\n        in order to ensure that the RegRef state of the Program does not change anymore.\n        """"""\n        self.locked = True\n\n    def can_follow(self, prev):\n        """"""Check whether this program can follow the given program.\n\n        This requires that the final RegRef state of the first program matches\n        the initial RegRef state of the second program, i.e., they have the same number\n        number of RegRefs, all with identical indices and activity states.\n\n        Args:\n            prev (Program): preceding program fragment\n        Returns:\n            bool: True if the Program can follow prev\n        """"""\n        # TODO NOTE unused_indices is not compared here, in order to allow program fragment repetition\n        return self.init_reg_refs == prev.reg_refs\n\n    def _index_to_regref(self, ind):\n        """"""Try to find a RegRef corresponding to a given subsystem index.\n\n        Args:\n            ind (int): subsystem index\n        Returns:\n            RegRef: corresponding register reference\n        Raises:\n            .RegRefError: if the subsystem cannot be found, or is invalid\n        """"""\n        # index must be found in the dict\n        if ind not in self.reg_refs:\n            raise RegRefError(""Subsystem {} does not exist."".format(ind))\n        return self.reg_refs[ind]\n\n    def _test_regrefs(self, reg):\n        """"""Make sure reg is a valid selection of subsystems, convert them to RegRefs.\n\n        A register reference is valid if it is properly recorded in self.reg_refs\n        and has not been deleted. The selection is valid if it contains only\n        valid RegRefs and no subsystem is repeated.\n\n        Args:\n            reg (Iterable[int, RegRef]): subsystem references\n        Returns:\n            list[RegRef]: converted subsystem references\n        Raises:\n            .RegRefError: if an invalid subsystem reference is found\n        """"""\n        temp = []\n        for rr in reg:\n            # must be either an integer or a RegRef\n            if isinstance(rr, RegRef):\n                # regref must be found in the dict values (the RegRefs are compared using __eq__, which, since we do not define it, defaults to ""is"")\n                if rr not in self.reg_refs.values():\n                    raise RegRefError(""Unknown RegRef."")\n                if self.reg_refs[rr.ind] is not rr:\n                    raise RegRefError(""RegRef state has become inconsistent."")\n            elif isinstance(rr, numbers.Integral):\n                rr = self._index_to_regref(rr)\n            else:\n                raise RegRefError(""Subsystems can only be indexed using integers and RegRefs."")\n\n            if not rr.active:\n                raise RegRefError(""Subsystem {} has already been deleted."".format(rr.ind))\n            if rr in temp:\n                raise RegRefError(""Trying to act on the same subsystem more than once."")\n            temp.append(rr)\n        return temp\n\n    def append(self, op, reg):\n        """"""Append a command to the program.\n\n        Args:\n            op (Operation): quantum operation\n            reg (list[int, RegRef]): register subsystem(s) to apply it to\n        Returns:\n            list[RegRef]: subsystem list as RegRefs\n        """"""\n        if self.locked:\n            raise CircuitError(""The Program is locked, no more Commands can be appended to it."")\n\n        # test that the target subsystem references are ok\n        reg = self._test_regrefs(reg)\n        # also test possible Parameter-related dependencies\n        self._test_regrefs(op.measurement_deps)\n        for rr in reg:\n            # it\'s used now\n            self.unused_indices.discard(rr.ind)\n        self.circuit.append(Command(op, reg))\n        return reg\n\n    def _linked_copy(self):\n        """"""Create a copy of the Program, linked to the original.\n\n        Both the original and the copy are :meth:`locked <lock>`, since they share their RegRefs.\n        FreeParameters are also shared.\n\n        Returns:\n            Program: a copy of the Program\n        """"""\n        self.lock()\n        p = copy.copy(self)  # shares RegRefs with the source\n        # link to the original source Program\n        if self.source is None:\n            p.source = self\n        else:\n            p.source = self.source\n        return p\n\n    def compile(self, target, **kwargs):\n        """"""Compile the program targeting the given circuit specification.\n\n        Validates the program against the given target, making sure all the\n        :doc:`/introduction/ops` used are accepted by the target specification.\n\n        Additionally, depending on the target, the compilation may modify the quantum circuit\n        into an equivalent circuit, e.g., by decomposing certain gates into sequences\n        of simpler gates, or optimizing the gate ordering using commutation rules.\n\n        **Example:**\n\n        The ``gbs`` compile target will\n        compile a circuit consisting of Gaussian operations and Fock measurements\n        into canonical Gaussian boson sampling form.\n\n        >>> prog2 = prog.compile(\'gbs\')\n\n        Args:\n            target (str, ~strawberryfields.circuitspecs.CircuitSpecs): short name of the target\n                circuit specification, or the specification object itself\n\n        Keyword Args:\n            optimize (bool): If True, try to optimize the program by merging and canceling gates.\n                The default is False.\n            warn_connected (bool): If True, the user is warned if the quantum circuit is not weakly\n                connected. The default is True.\n\n        Returns:\n            Program: compiled program\n        """"""\n        if isinstance(target, specs.CircuitSpecs):\n            db = target\n            target = db.short_name\n        elif target in specs.circuit_db:\n            db = specs.circuit_db[target]()\n        else:\n            raise ValueError(\n                ""Could not find target \'{}\' in the Strawberry Fields circuit database."".format(\n                    target\n                )\n            )\n\n        if db.modes is not None:\n            # subsystems may be created and destroyed, this is total number that has ever existed\n            modes_total = len(self.reg_refs)\n            if modes_total > db.modes:\n                raise CircuitError(\n                    ""This program requires {} modes, but the target \'{}\' ""\n                    ""only supports a {}-mode program"".format(modes_total, target, db.modes)\n                )\n\n        seq = db.decompose(self.circuit)\n\n        if kwargs.get(""warn_connected"", True):\n            DAG = pu.list_to_DAG(seq)\n            temp = nx.algorithms.components.number_weakly_connected_components(DAG)\n            if temp > 1:\n                warnings.warn(""The circuit consists of {} disconnected components."".format(temp))\n\n        # run optimizations\n        if kwargs.get(""optimize"", False):\n            seq = pu.optimize_circuit(seq)\n\n        # does the circuit spec  have its own compilation method?\n        if db.compile is not None:\n            seq = db.compile(seq, self.register)\n\n        # create the compiled Program\n        compiled = self._linked_copy()\n        compiled.circuit = seq\n        compiled._target = db.short_name\n\n        # get run options of compiled program\n        # for the moment, shots is the only supported run option.\n        if ""shots"" in kwargs:\n            compiled.run_options[""shots""] = kwargs[""shots""]\n\n        compiled.backend_options = {}\n        if ""cutoff_dim"" in kwargs:\n            compiled.backend_options[""cutoff_dim""] = kwargs[""cutoff_dim""]\n\n        return compiled\n\n    def optimize(self):\n        """"""Simplify and optimize the program.\n\n        The simplifications are based on the algebraic properties of the gates,\n        e.g., combining two consecutive gates of the same gate family.\n\n        Returns a copy of the program, sharing RegRefs with the original.\n\n        See :func:`~strawberryfields.program_utils.optimize_circuit`.\n\n        Returns:\n            Program: optimized copy of the program\n        """"""\n        opt = self._linked_copy()\n        opt.circuit = pu.optimize_circuit(self.circuit)\n        return opt\n\n    def draw_circuit(self, tex_dir=""./circuit_tex"", write_to_file=True):\n        r""""""Draw the circuit using the Qcircuit :math:`\\LaTeX` package.\n\n        This will generate the LaTeX code required to draw the quantum circuit\n        diagram corresponding to the Program.\n\n\n        The drawing of the following Xanadu supported operations are currently supported:\n\n        .. rst-class:: docstable\n\n        +-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n        |     Gate type     |                                                                            Supported gates                                                                             |\n        +===================+========================================================================================================================================================================+\n        | Single mode gates | :class:`~.Dgate`, :class:`~.Xgate`, :class:`~.Zgate`, :class:`~.Sgate`, :class:`~.Rgate`, :class:`~.Pgate`, :class:`~.Vgate`, :class:`~.Kgate`, :class:`~.Fouriergate` |\n        +-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n        | Two mode gates    | :class:`~.BSgate`, :class:`~.S2gate`, :class:`~.CXgate`, :class:`~.CZgate`, :class:`~.CKgate`                                                                          |\n        +-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n        .. note::\n\n            Measurement operations :class:`~.MeasureHomodyne`, :class:`~.MeasureHeterodyne`,\n            and :class:`~.MeasureFock` are not currently supported.\n\n        Args:\n            tex_dir (str): relative directory for latex document output\n            write_to_file (bool): if False, no output file is created\n\n        Returns:\n            list[str]: filename of the written tex document and the written tex content\n        """"""\n        drawer = sfcd.Circuit(wires=self.init_num_subsystems)\n        self.print(drawer.parse_op)\n        tex = drawer.dump_to_document()\n\n        document = None\n        if write_to_file:\n            document = drawer.compile_document(tex_dir=tex_dir)\n\n        return [document, tex]\n\n    @property\n    def target(self):\n        """"""The target specification the program has been compiled against.\n\n        If the program has not been compiled, this will return ``None``.\n\n        Returns:\n            str or None: the short name of the target CircuitSpecs template if\n            compiled, otherwise None\n        """"""\n        return self._target\n\n    def params(self, *args):\n        """"""Create and access free circuit parameters.\n\n        Returns the named free parameters. If a parameter does not exist yet, it is created and returned.\n\n        Args:\n            *args (tuple[str]): name(s) of the free parameters to access\n\n        Returns:\n            FreeParameter, list[FreeParameter]: requested parameter(s)\n        """"""\n        ret = []\n        for a in args:\n            if not isinstance(a, str):\n                raise TypeError(""Parameter names must be strings."")\n\n            if a not in self.free_params:\n                if self.locked:\n                    raise CircuitError(\n                        ""The Program is locked, no more free parameters can be created.""\n                    )\n                p = FreeParameter(a)\n                self.free_params[a] = p\n            else:\n                p = self.free_params[a]\n            ret.append(p)\n\n        if len(ret) == 1:\n            return ret[0]\n        return ret\n\n    def bind_params(self, binding):\n        """"""Binds the free parameters of the program to the given values.\n\n        Args:\n            binding (dict[Union[str, FreeParameter], Any]): mapping from parameter names (or the\n                parameters themselves) to parameter values\n\n        Raises:\n            ParameterError: tried to bind an unknown parameter\n        """"""\n        for k, v in binding.items():\n            temp = self.free_params.get(k)  # it\'s a name\n            if temp:\n                temp.val = v\n            elif k in self.free_params.values():  # it\'s a parameter\n                k.val = v\n            else:\n                raise ParameterError(""Unknown free parameter \'{}\'"".format(k))\n'"
strawberryfields/program_utils.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThis module contains various utility classes and functions used\nwithin the :class:`~.Program` class.\n""""""\n\nfrom collections.abc import Sequence\n\nimport networkx as nx\n\nfrom .parameters import MeasuredParameter\n\n\n__all__ = [\n    ""Program_current_context"",\n    ""RegRefError"",\n    ""CircuitError"",\n    ""MergeFailure"",\n    ""Command"",\n    ""RegRef"",\n    ""list_to_grid"",\n    ""grid_to_DAG"",\n    ""DAG_to_list"",\n    ""list_to_DAG"",\n    ""group_operations"",\n    ""optimize_circuit"",\n]\n\n\nProgram_current_context = None\n""""""Context for inputting a Program. Used to be a class attribute of :class:`.Program`, placed\nhere to avoid cyclic imports.""""""\n# todo: Avoid issues with Program contexts and threading,\n# cf. _pydecimal.py in the python standard distribution.\n\n\nclass RegRefError(IndexError):\n    """"""Exception raised by :class:`.Program` when it encounters an invalid register reference.\n\n    E.g., trying to apply a gate to a nonexistent or deleted subsystem.\n    """"""\n\n\nclass CircuitError(RuntimeError):\n    """"""Exception raised by :class:`.Program` when it encounters an illegal\n    operation in the quantum circuit.\n\n    E.g., trying to use an Operation type that is unsupported by the current compilation target.\n    """"""\n\n\nclass MergeFailure(RuntimeError):\n    """"""Exception raised by :meth:`strawberryfields.ops.Operation.merge` when an\n    attempted merge fails.\n\n    E.g., trying to merge two gates of different families.\n    """"""\n\n\nclass Command:\n    """"""Represents a quantum operation applied on specific subsystems of the register.\n\n    A Command instance is immutable once created, and can be shared between\n    several :class:`.Program` instances.\n\n    Args:\n        op (~strawberryfields.ops.Operation): quantum operation to apply\n        reg (Sequence[RegRef]): Subsystems to which the operation is applied.\n            Note that the order matters here.\n    """"""\n\n    # pylint: disable=too-few-public-methods\n\n    def __init__(self, op, reg):\n        # accept a single RegRef in addition to a Sequence\n        if not isinstance(reg, Sequence):\n            reg = [reg]\n\n        #: Operation: quantum operation to apply\n        self.op = op\n        #: Sequence[RegRef]: subsystems to which the operation is applied\n        self.reg = reg\n\n    def __str__(self):\n        """"""\n        Return a string containing the command in Blackbird syntax.\n        """"""\n\n        operation = str(self.op)\n        if self.op.ns == 0:\n            # op takes no subsystems as parameters, do not print anything more\n            code = operation\n        else:\n            subsystems = "", "".join([str(r) for r in self.reg])\n            code = ""{} | ({})"".format(operation, subsystems)\n        return code\n\n    def __lt__(self, other):\n        # Needed as a tiebreaker for NetworkX lexicographical_topological_sort()\n        # due to a buggy implementation! Any order will do. Remove when NetworkX is fixed.\n        return True\n\n    def get_dependencies(self):\n        """"""Subsystems the command depends on.\n\n        Combination of ``self.reg`` and ``self.op.measurement_deps``.\n\n        .. note:: ``measurement_deps`` are used to ensure that the measurement\n            happens before the result is used, but this is a bit too strict:\n            two gates depending on the same measurement result but otherwise\n            acting on different subsystems should commute.\n\n        Returns:\n            set[RegRef]: set of subsystems the command depends on\n        """"""\n        deps = self.op.measurement_deps | set(self.reg)\n        return deps\n\n\nclass RegRef:\n    """"""Quantum register reference.\n\n    The objects of this class refer to a specific subsystem (mode) of\n    a quantum register.\n\n    Within the scope of each :class:`.Program` instance, only one RegRef instance\n    should exist per subsystem. Program keeps the authoritative mapping\n    of subsystem indices to RegRef instances.\n    Subsystem measurement results are stored in the ""official"" RegRef object.\n    If other RegRef objects referring to the same subsystem exist, they will\n    not be updated. Once a RegRef is assigned a subsystem index it will never\n    change, not even if the subsystem is deleted.\n\n    The RegRefs are constructed in :meth:`.Program._add_subsystems`.\n\n    Args:\n        ind (int): index of the register subsystem referred to\n    """"""\n\n    # pylint: disable=too-few-public-methods\n\n    def __init__(self, ind):\n        self.ind = ind  #: int: subsystem index\n        self.val = None  #: float, complex: Measurement result. None if the subsystem has not been measured yet.\n        self.active = True  #: bool: True at construction, False after the subsystem is deleted\n\n    def __str__(self):\n        return ""q[{}]"".format(self.ind)\n\n    def __hash__(self):\n        """"""Hashing method.\n\n        NOTE: Has to match :meth:`__eq__` such that if two RegRefs compare equal they must have equal hashes.\n        """"""\n        return hash((self.ind, self.active))\n\n    def __eq__(self, other):\n        """"""Equality comparison.\n\n        Compares the index and the activity state of the two RegRefs, the val field does not matter.\n        NOTE: Affects the hashability of RegRefs, see also :meth:`__hash__`.\n        """"""\n        if other.__class__ != self.__class__:\n            print(""---------------          regref.__eq__: compared reqref to "", other.__class__)\n            return False\n        return self.ind == other.ind and self.active == other.active\n\n    @property\n    def par(self):\n        """"""Convert the RegRef into a measured parameter.\n\n        Returns:\n            MeasuredParameter: measured parameter linked to this RegRef\n        """"""\n        return MeasuredParameter(self)\n\n\n# =================\n# Utility functions\n# =================\n\n\ndef list_to_grid(ls):\n    """"""Transforms a list of Commands to a grid representation.\n\n    The grid is a mapping from subsystem indices to lists of :class:`Command` instances touching\n    that subsystem, in temporal order. The same Command instance will appear in each list that\n    corresponds to one of its subsystems.\n\n    Args:\n        ls (Iterable[Command]): quantum circuit\n    Returns:\n        dict[int, list[Command]]: same circuit in grid form\n    """"""\n    grid = {}\n    # enter every operation in the list to its proper position in the grid\n    for cmd in ls:\n        for r in cmd.get_dependencies():\n            # Add cmd to the grid to the end of the line r.ind.\n            grid.setdefault(r.ind, []).append(cmd)\n    return grid\n\n\ndef grid_to_DAG(grid):\n    """"""Transforms a grid of Commands to a DAG representation.\n\n    In the DAG (directed acyclic graph) each node is a :class:`Command` instance,\n    and edges point from Commands to their immediate dependents/followers.\n\n    Args:\n        grid (dict[int, list[Command]]): quantum circuit\n    Returns:\n        networkx.DiGraph[Command]: same circuit in DAG form\n    """"""\n    DAG = nx.DiGraph()\n    for _, q in grid.items():\n        if q:\n            # add the first operation on the wire that does not depend on anything\n            DAG.add_node(q[0])\n        for i in range(1, len(q)):\n            # add the edge between the operations, and the operation nodes themselves\n            DAG.add_edge(q[i - 1], q[i])\n    return DAG\n\n\ndef list_to_DAG(ls):\n    """"""Transforms a list of Commands to a DAG representation.\n\n    In the DAG (directed acyclic graph) each node is a :class:`Command` instance,\n    and edges point from Commands to their immediate dependents/followers.\n\n    Args:\n        ls (Iterable[Command]): quantum circuit\n    Returns:\n        networkx.DiGraph[Command]: same circuit in DAG form\n    """"""\n    return grid_to_DAG(list_to_grid(ls))\n\n\ndef DAG_to_list(dag):\n    """"""Transforms a Command DAG to a list representation.\n\n    The list contains the :class:`Command` instances in (one possible) topological order,\n    i.e., dependants following the operations they depend on.\n\n    Args:\n        dag (networkx.DiGraph[Command]): quantum circuit\n    Returns:\n        list[Command]: same circuit in list form\n    """"""\n    # sort the operation graph into topological order\n    temp = nx.algorithms.dag.topological_sort(dag)\n    return list(temp)\n\n\ndef group_operations(seq, predicate):\n    """"""Group a set of Operations in a circuit together (if possible).\n\n    For the purposes of this method, we call a :class:`Operation` instance *marked* iff\n    ``predicate`` returns True on it.\n\n    This method converts the quantum circuit in ``seq`` into an equivalent circuit ``A+B+C``,\n    where the :class:`Command` instances in sequences ``A`` and ``C`` do not contain any\n    marked Operations.\n    The sequence ``B`` contains all marked Operations in the circuit, and possibly\n    additional unmarked instances that could not be moved into ``A`` or ``C`` using the\n    available commutation rules.\n    Any of the three returned sequences can be empty (but if ``B`` is empty then so is ``C``).\n\n    Args:\n        seq (Sequence[Command]): quantum circuit\n        predicate (Callable[[Operation], bool]): Grouping predicate. Returns True for the\n            Operations to be grouped together, False for the others.\n    Returns:\n        Tuple[Sequence[Command]]: A, B, C such that A+B+C is equivalent to seq,\n            and A and C do not contain any marked Operation instances.\n    """"""\n\n    def find_first_index(seq):\n        """"""Index of the first element in the sequence for which the predicate function returns True.\n        If no such element exists, returns the length of the sequence.\n        """"""\n        return next((i for i, e in enumerate(seq) if predicate(e.op)), len(seq))\n\n    def marked_last(node):\n        """"""Mapping from nodes to sorting keys to resolve ambiguities in the topological sort.\n        Larger key values come later in the lexicographical-topological ordering.\n        """"""\n        if predicate(node.op):\n            return 1\n        return 0\n\n    def lex_topo(seq, key):\n        """"""Sorts a Command sequence lexicographical-topologically using the given lexicographic key function.""""""\n        DAG = list_to_DAG(seq)\n        return list(nx.algorithms.dag.lexicographical_topological_sort(DAG, key=key))\n\n    C = lex_topo(seq, key=marked_last)\n    ind = find_first_index(C)\n    A = C[:ind]  # initial unmarked instances\n    B = C[ind:]  # marked and possibly unmarked\n\n    # re-sort B, marked instances first\n    C = lex_topo(B, key=lambda x: -marked_last(x))\n    # find last marked\n    ind = len(C) - find_first_index(list(reversed(C)))\n    B = C[:ind]  # marked and still possibly unmarked\n    C = C[ind:]  # final unmarked instances\n    return A, B, C\n\n\ndef optimize_circuit(seq):\n    """"""Try to simplify and optimize a quantum circuit.\n\n    The purpose of the optimizer is to simplify the circuit\n    to make it cheaper and faster to execute. Different backends may require\n    different types of optimization, but in general the fewer operations a circuit has,\n    the faster it should run. The optimizer thus should convert the circuit into a\n    simpler :term:`equivalent circuit`.\n\n    The optimizations are based on the abstract algebraic properties of the Operations\n    constituting the circuit, e.g., combining two consecutive gates of the same gate family,\n    and at no point should require a matrix representation of any kind.\n    The optimization must also not change the state of the RegRefs in any way.\n\n    Currently the optimization is very simple. It\n\n    * merges neighboring :class:`state preparations <.Preparation>` and :class:`gates <.Gate>`\n      belonging to the same family and acting on the same sequence of subsystems\n    * cancels neighboring pairs of a gate and its inverse\n\n    Args:\n        seq (Sequence[Command]): quantum circuit to optimize\n\n    Returns:\n        List[Command]: optimized circuit\n    """"""\n\n    def _print_list(i, q, print_fn=print):\n        ""For debugging.""\n        # pylint: disable=unreachable\n        return\n        print_fn(""i: {},  len: {}   "".format(i, len(q)), end="""")\n        for x in q:\n            print_fn(x.op, "", "", end="""")\n        print_fn()\n\n    grid = list_to_grid(seq)\n\n    # try merging neighboring operations on each wire\n    # TODO the merging could also be done using the circuit DAG, which\n    # might be smarter (ns>1 would be easy)\n    for k in grid:\n        q = grid[k]\n        i = 0  # index along the wire\n        _print_list(i, q)\n        while i + 1 < len(q):\n            # at least two operations left to merge on this wire\n            try:\n                a = q[i]\n                b = q[i + 1]\n                # the ops must have equal size and act on the same wires\n                if a.op.ns == b.op.ns and a.reg == b.reg:\n                    if a.op.ns != 1:\n                        # ns > 1 is tougher. on no wire must there be anything\n                        # between them, also deleting is more complicated\n                        # todo treat it as a failed merge for now\n                        i += 1\n                        continue\n                    op = a.op.merge(b.op)\n                    # merge was successful, delete the old ops\n                    del q[i : i + 2]\n                    # insert the merged op (unless it\'s identity)\n                    if op is not None:\n                        q.insert(i, Command(op, a.reg))\n                    # move one spot backwards to try another merge\n                    if i > 0:\n                        i -= 1\n                    _print_list(i, q)\n                    continue\n            except MergeFailure:\n                pass\n            i += 1  # failed at merging the ops, move forward\n\n    # convert the circuit back into a list (via a DAG)\n    DAG = grid_to_DAG(grid)\n    return DAG_to_list(DAG)\n'"
strawberryfields/utils.py,3,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThis module defines and implements several utility functions and language extensions that complement\nStrawberryFields. These include:\n\n\n* **NumPy state functions**\n\n  These functions allow the calculation of various quantum states in either the Fock\n  basis (a one-dimensional array indexed by Fock state) or the Gaussian basis (returning\n  a vector of means and covariance matrix). These state calculations are NOT done in the\n  simulators, but rather in NumPy.\n\n  These are useful for generating states for use in calculating the fidelity of simulations.\n\n\n* **Random functions**\n\n  These functions generate random numbers and matrices corresponding to various\n  quantum states and operations.\n\n* **Decorators**\n\n  The :class:`~.strawberryfields.utils.operation` decorator allows functions\n  containing quantum operations acting on a qumode to be used as an\n  operation itself within a :class:`.Program` context.\n\n* **Program functions**\n\n  These functions act on :class:`.Program` instances, returning\n  or extracting information from the quantum circuit.\n""""""\nimport collections\nimport copy\nfrom inspect import signature\n\ntry:\n    import tensorflow as tf\nexcept ImportError:\n    tf_available = False\n\nimport numpy as np\nfrom numpy.polynomial.hermite import hermval\nimport scipy as sp\nfrom scipy.special import factorial as fac\n\nfrom .engine import LocalEngine\nfrom .program_utils import Command\nfrom .ops import Gate, Channel, Ket\n\n\n# ------------------------------------------------------------------------\n# State functions - Fock basis and Gaussian basis                |\n# ------------------------------------------------------------------------\n\n\ndef squeezed_cov(r, phi, hbar=2):\n    r""""""Returns the squeezed covariance matrix of a squeezed state\n\n    Args:\n        r (complex): the squeezing magnitude\n        p (float): the squeezing phase :math:`\\phi`\n        hbar (float): (default 2) the value of :math:`\\hbar` in the commutation\n            relation :math:`[\\x,\\p]=i\\hbar`\n    Returns:\n        array: the squeezed state\n    """"""\n    cov = np.array([[np.exp(-2 * r), 0], [0, np.exp(2 * r)]]) * hbar / 2\n\n    R = np.array([[np.cos(phi / 2), -np.sin(phi / 2)], [np.sin(phi / 2), np.cos(phi / 2)]])\n\n    return np.dot(np.dot(R, cov), R.T)\n\n\ndef vacuum_state(basis=""fock"", fock_dim=5, hbar=2.0):\n    r"""""" Returns the vacuum state\n\n    Args:\n        basis (str): If \'fock\', calculates the initial state\n            in the Fock basis. If \'gaussian\', returns the\n            vector of means and the covariance matrix.\n        fock_dim (int): the size of the truncated Fock basis if\n            using the Fock basis representation\n        hbar (float): (default 2) the value of :math:`\\hbar` in the commutation\n            relation :math:`[\\x,\\p]=i\\hbar`\n    Returns:\n        array: the vacuum state\n    """"""\n    if basis == ""fock"":\n        state = np.zeros((fock_dim))\n        state[0] = 1.0\n\n    elif basis == ""gaussian"":\n        means = np.zeros((2))\n        cov = np.identity(2) * hbar / 2\n        state = [means, cov]\n\n    return state\n\n\ndef coherent_state(a, basis=""fock"", fock_dim=5, hbar=2.0):\n    r"""""" Returns the coherent state\n\n    This can be returned either in the Fock basis,\n\n    .. math::\n\n        |\\alpha\\rangle = e^{-|\\alpha|^2/2} \\sum_{n=0}^\\infty\n        \\frac{\\alpha^n}{\\sqrt{n!}}|n\\rangle\n\n    or as a Gaussian:\n\n    .. math::\n\n        \\mu = (\\text{Re}(\\alpha),\\text{Im}(\\alpha)),~~~\\sigma = I\n\n    where :math:`\\alpha` is the displacement.\n\n    Args:\n        a (complex) : the displacement\n        basis (str): If \'fock\', calculates the initial state\n            in the Fock basis. If \'gaussian\', returns the\n            vector of means and the covariance matrix.\n        fock_dim (int): the size of the truncated Fock basis if\n            using the Fock basis representation\n        hbar (float): (default 2) the value of :math:`\\hbar` in the commutation\n            relation :math:`[\\x,\\p]=i\\hbar`\n    Returns:\n        array: the coherent state\n    """"""\n    if basis == ""fock"":\n        state = np.array(\n            [np.exp(-0.5 * np.abs(a) ** 2) * a ** n / np.sqrt(fac(n)) for n in range(fock_dim)]\n        )\n\n    elif basis == ""gaussian"":\n        means = np.array([a.real, a.imag]) * np.sqrt(2 * hbar)\n        cov = np.identity(2) * hbar / 2\n        state = [means, cov]\n\n    return state\n\n\ndef squeezed_state(r, p, basis=""fock"", fock_dim=5, hbar=2.0):\n    r"""""" Returns the squeezed state\n\n    This can be returned either in the Fock basis,\n\n    .. math::\n\n        |z\\rangle = \\frac{1}{\\sqrt{\\cosh(r)}}\\sum_{n=0}^\\infty\n        \\frac{\\sqrt{(2n)!}}{2^n n!}(-e^{i\\phi}\\tanh(r))^n|2n\\rangle\n\n    or as a Gaussian:\n\n    .. math:: \\mu = (0,0)\n\n    .. math::\n        :nowrap:\n\n        \\begin{align*}\n            \\sigma = R(\\phi/2)\\begin{bmatrix}e^{-2r} & 0 \\\\0 & e^{2r} \\\\\\end{bmatrix}R(\\phi/2)^T\n        \\end{align*}\n\n    where :math:`z = re^{i\\phi}` is the squeezing factor.\n\n    Args:\n        r (complex): the squeezing magnitude\n        p (float): the squeezing phase :math:`\\phi`\n        basis (str): If \'fock\', calculates the initial state\n            in the Fock basis. If \'gaussian\', returns the\n            vector of means and the covariance matrix.\n        fock_dim (int): the size of the truncated Fock basis if\n            using the Fock basis representation\n        hbar (float): (default 2) the value of :math:`\\hbar` in the commutation\n            relation :math:`[\\x,\\p]=i\\hbar`\n    Returns:\n        array: the squeezed state\n    """"""\n    phi = p\n\n    if basis == ""fock"":\n\n        def ket(n):\n            """"""Squeezed state kets""""""\n            return (np.sqrt(fac(2 * n)) / (2 ** n * fac(n))) * (-np.exp(1j * phi) * np.tanh(r)) ** n\n\n        state = np.array([ket(n // 2) if n % 2 == 0 else 0.0 for n in range(fock_dim)])\n        state *= np.sqrt(1 / np.cosh(r))\n\n    elif basis == ""gaussian"":\n        means = np.zeros((2))\n        state = [means, squeezed_cov(r, phi, hbar)]\n\n    return state\n\n\ndef displaced_squeezed_state(a, r, phi, basis=""fock"", fock_dim=5, hbar=2.0):\n    r"""""" Returns the squeezed coherent state\n\n    This can be returned either in the Fock basis,\n\n    .. math::\n\n        |\\alpha,z\\rangle = e^{-\\frac{1}{2}|\\alpha|^2-\\frac{1}{2}{\\alpha^*}^2 e^{i\\phi}\\tanh{(r)}}\n        \\sum_{n=0}^\\infty\\frac{\\left[\\frac{1}{2}e^{i\\phi}\\tanh(r)\\right]^{n/2}}{\\sqrt{n!\\cosh(r)}}\n        H_n\\left[ \\frac{\\alpha\\cosh(r)+\\alpha^*e^{i\\phi}\\sinh(r)}{\\sqrt{e^{i\\phi}\\sinh(2r)}} \\right]|n\\rangle\n\n    where :math:`H_n(x)` is the Hermite polynomial, or as a Gaussian:\n\n    .. math:: \\mu = (\\text{Re}(\\alpha),\\text{Im}(\\alpha))\n\n    .. math::\n        :nowrap:\n\n        \\begin{align*}\n            \\sigma = R(\\phi/2)\\begin{bmatrix}e^{-2r} & 0 \\\\0 & e^{2r} \\\\\\end{bmatrix}R(\\phi/2)^T\n        \\end{align*}\n\n    where :math:`z = re^{i\\phi}` is the squeezing factor\n    and :math:`\\alpha` is the displacement.\n\n    Args:\n        a (complex): the displacement\n        r (complex): the squeezing magnitude\n        phi (float): the squeezing phase :math:`\\phi`\n        basis (str): If \'fock\', calculates the initial state\n            in the Fock basis. If \'gaussian\', returns the\n            vector of means and the covariance matrix.\n        fock_dim (int): the size of the truncated Fock basis if\n            using the Fock basis representation\n        hbar (float): (default 2) the value of :math:`\\hbar` in the commutation\n            relation :math:`[\\x,\\p]=i\\hbar`\n    Returns:\n        array: the squeezed coherent state\n    """"""\n    # pylint: disable=too-many-arguments\n    if basis == ""fock"":\n\n        if r != 0:\n            phase_factor = np.exp(1j * phi)\n            ch = np.cosh(r)\n            sh = np.sinh(r)\n            th = np.tanh(r)\n\n            gamma = a * ch + np.conj(a) * phase_factor * sh\n            N = np.exp(-0.5 * np.abs(a) ** 2 - 0.5 * np.conj(a) ** 2 * phase_factor * th)\n\n            coeff = np.diag(\n                [\n                    (0.5 * phase_factor * th) ** (n / 2) / np.sqrt(fac(n) * ch)\n                    for n in range(fock_dim)\n                ]\n            )\n\n            vec = [hermval(gamma / np.sqrt(phase_factor * np.sinh(2 * r)), row) for row in coeff]\n\n            state = N * np.array(vec)\n\n        else:\n            state = coherent_state(a, basis=""fock"", fock_dim=fock_dim)  # pragma: no cover\n\n    elif basis == ""gaussian"":\n        means = np.array([a.real, a.imag]) * np.sqrt(2 * hbar)\n        state = [means, squeezed_cov(r, phi, hbar)]\n\n    return state\n\n\n# ------------------------------------------------------------------------\n# State functions - Fock basis only                              |\n# ------------------------------------------------------------------------\n\n\ndef fock_state(n, fock_dim=5):\n    r"""""" Returns the Fock state\n\n    Args:\n        n (int): the occupation number\n        fock_dim (int): the size of the truncated Fock basis\n    Returns:\n        array: the Fock state\n    """"""\n    ket = np.zeros((fock_dim))\n    ket[n] = 1.0\n    return ket\n\n\ndef cat_state(a, p=0, fock_dim=5):\n    r"""""" Returns the cat state\n\n    .. math::\n\n        |cat\\rangle = \\frac{1}{\\sqrt{2(1+e^{-2|\\alpha|^2}\\cos(\\phi))}}\n        \\left(|\\alpha\\rangle +e^{i\\phi}|-\\alpha\\rangle\\right)\n\n    with the even cat state given for :math:`\\phi=0`, and the odd\n    cat state given for :math:`\\phi=\\pi`.\n\n    Args:\n        a (complex): the displacement\n        p (float): parity, where :math:`\\phi=p\\pi`. ``p=0`` corresponds to an even\n            cat state, and ``p=1`` an odd cat state\n        fock_dim (int): the size of the truncated Fock basis\n    Returns:\n        array: the cat state\n    """"""\n    # p=0 if even, p=pi if odd\n    phi = np.pi * p\n\n    # normalisation constant\n    temp = np.exp(-0.5 * np.abs(a) ** 2)\n    N = temp / np.sqrt(2 * (1 + np.cos(phi) * temp ** 4))\n\n    # coherent states\n    k = np.arange(fock_dim)\n    c1 = (a ** k) / np.sqrt(fac(k))\n    c2 = ((-a) ** k) / np.sqrt(fac(k))\n\n    # add them up with a relative phase\n    ket = (c1 + np.exp(1j * phi) * c2) * N\n\n    return ket\n\n\n# ------------------------------------------------------------------------\n# Random numbers and matrices                                           |\n# ------------------------------------------------------------------------\n\n\ndef randnc(*arg):\n    """"""Normally distributed array of random complex numbers.""""""\n    return np.random.randn(*arg) + 1j * np.random.randn(*arg)\n\n\ndef random_covariance(N, hbar=2, pure=False, block_diag=False):\n    r""""""Random covariance matrix.\n\n    Args:\n        N (int): number of modes\n        hbar (float): the value of :math:`\\hbar` to use in the definition\n            of the quadrature operators :math:`\\x` and :math:`\\p`\n        pure (bool): If True, a random covariance matrix corresponding\n            to a pure state is returned.\n        block_diag (bool): If True, uses passive Gaussian transformations that are orthogonal\n            instead of unitary. This implies that the positions :math:`q` do not mix with\n            the momenta :math:`p` and thus the covariance matrix is block diagonal.\n    Returns:\n        array: random :math:`2N\\times 2N` covariance matrix\n    """"""\n    S = random_symplectic(N, block_diag=block_diag)\n\n    if pure:\n        return (hbar / 2) * S @ S.T\n\n    nbar = 2 * np.abs(np.random.random(N)) + 1\n    Vth = (hbar / 2) * np.diag(np.concatenate([nbar, nbar]))\n\n    return S @ Vth @ S.T\n\n\ndef random_symplectic(N, passive=False, block_diag=False, scale=1.0):\n    r""""""Random symplectic matrix representing a Gaussian transformation.\n\n    The squeezing parameters :math:`r` for active transformations are randomly\n    sampled from the standard normal distribution, while passive transformations\n    are randomly sampled from the Haar measure. Note that for the Symplectic\n    group there is no notion of Haar measure since this is group is not compact.\n\n    Args:\n        N (int): number of modes\n        passive (bool): If True, returns a passive Gaussian transformation (i.e.,\n            one that preserves photon number). If False (default), returns an active\n            transformation.\n        block_diag (bool): If True, uses passive Gaussian transformations that are orthogonal\n            instead of unitary. This implies that the positions :math:`q` do not mix with\n            the momenta :math:`p` and thus the symplectic operator is block diagonal\n        scale (float): Sets the scale of the random values used as squeezing parameters.\n            They will range from 0 to :math:`\\sqrt{2}\\texttt{scale}`\n\n    Returns:\n        array: random :math:`2N\\times 2N` symplectic matrix\n    """"""\n    U = random_interferometer(N, real=block_diag)\n    O = np.vstack([np.hstack([U.real, -U.imag]), np.hstack([U.imag, U.real])])\n\n    if passive:\n        return O\n\n    U = random_interferometer(N, real=block_diag)\n    P = np.vstack([np.hstack([U.real, -U.imag]), np.hstack([U.imag, U.real])])\n\n    r = scale * np.abs(randnc(N))\n    Sq = np.diag(np.concatenate([np.exp(-r), np.exp(r)]))\n\n    return O @ Sq @ P\n\n\ndef random_interferometer(N, real=False):\n    r""""""Random unitary matrix representing an interferometer.\n\n    For more details, see :cite:`mezzadri2006`.\n\n    Args:\n        N (int): number of modes\n        real (bool): return a random real orthogonal matrix\n\n    Returns:\n        array: random :math:`N\\times N` unitary distributed with the Haar measure\n    """"""\n    if real:\n        z = np.random.randn(N, N)\n    else:\n        z = randnc(N, N) / np.sqrt(2.0)\n    q, r = sp.linalg.qr(z)\n    d = sp.diagonal(r)\n    ph = d / np.abs(d)\n    U = np.multiply(q, ph, q)\n    return U\n\n\n# ------------------------------------------------------------------------\n# Decorators                                                            |\n# ------------------------------------------------------------------------\n\n\nclass operation:\n    """"""Groups a sequence of gates into a single operation to be used\n    within a Program context.\n\n    For example:\n\n    .. code-block:: python\n\n        @sf.operation(3)\n        def custom_operation(v1, v2, q):\n            CZgate(v1) | (q[0], q[1])\n            Vgate(v2) | q[2]\n\n    Here, the ``operation`` decorator must recieve an argument\n    detailing the number of subsystems the resulting custom\n    operation acts on.\n\n    The function it acts on can contain arbitrary\n    Python and Blackbird code that may normally be placed within a\n    Program context. Note that it must always accept the register\n    ``q`` it acts on as the *last* argument of the function.\n\n    Once defined, it can be used like any other quantum operation:\n\n    .. code-block:: python\n\n        prog = sf.Program(3)\n        with prog.context as q:\n            custom_operation(0.5719, 2.0603) | (q[0], q[1], q[3])\n\n    Note that here, we do not pass the register ``q`` directly\n    to the function - instead, it is defined on the right hand side\n    of the ``|`` operation, like all other Blackbird code.\n\n    Args:\n        ns (int): number of subsystems required by the operation\n    """"""\n\n    def __init__(self, ns):\n        self.ns = ns\n        self.func = None\n        self.args = None\n\n    def __or__(self, reg):\n        """"""Apply the operation to a part of a quantum register.\n\n        Redirects the execution flow to the wrapped function.\n\n        Args:\n            reg (RegRef, Sequence[RegRef]): subsystem(s) the operation is acting on\n\n        Returns:\n            list[RegRef]: subsystem list as RegRefs\n        """"""\n        if (not reg) or (not self.ns):\n            raise ValueError(""Wrong number of subsystems"")\n\n        reg_len = 1\n        if isinstance(reg, collections.abc.Sized):\n            reg_len = len(reg)\n\n        if reg_len != self.ns:\n            raise ValueError(""Wrong number of subsystems"")\n\n        return self._call_function(reg)\n\n    def _call_function(self, reg):\n        """"""Executes the wrapped function and passes the quantum registers.\n\n        Args:\n            reg (RegRef, Sequence[RegRef]): subsystem(s) the operation is acting on\n\n        Returns:\n            list[RegRef]: subsystem list as RegRefs\n        """"""\n        func_sig = signature(self.func)\n        num_params = len(func_sig.parameters)\n\n        if num_params == 0:\n            raise ValueError(""Operation must receive the qumode register as an argument."")\n\n        if num_params != len(self.args) + 1:\n            raise ValueError(""Mismatch in the number of arguments"")\n\n        # pass parameters and subsystems to the function\n        if num_params == 1:\n            self.func(reg)\n        else:\n            self.func(*self.args, reg)\n\n        return reg\n\n    def __call__(self, func):\n        self.func = func\n\n        def f_proxy(*args):\n            """"""\n            Proxy for function execution. Function will actually execute in __or__\n            """"""\n            self.args = args\n            return self\n\n        return f_proxy\n\n\n# =================================================\n# Program functions\n# =================================================\n\n\ndef is_unitary(prog):\n    """"""True iff all the operations in the program are unitary.\n\n    Args:\n        prog (Program): quantum program\n    Returns:\n        bool: True iff all operations in the program are of type :class:`strawberryfields.ops.Gate`\n    """"""\n    return all(isinstance(cmd.op, Gate) for cmd in prog.circuit)\n\n\ndef is_channel(prog):\n    """"""True iff all the operations in the program can be represented as quantum channels.\n\n    Args:\n        prog (Program): quantum program\n    Returns:\n        bool: True if all operations in the program are of types :class:`strawberryfields.ops.Gate` and :class:`strawberryfields.ops.Channel`\n    """"""\n    # FIXME isn\'t a preparation also a quantum channel?\n    return all(isinstance(cmd.op, (Channel, Gate)) for cmd in prog.circuit)\n\n\ndef _vectorize(tensor):\n    """"""Given a tensor with 4N indices of dimension :math:`D` each, it returns the vectorized\n    tensor with 4 indices of dimension :math:`D^N` each. This is the inverse of the procedure\n    given by :func:`_unvectorize`.\n    Caution: this private method is intended to be used only for Choi and Liouville operators.\n\n    For example, :math:`N=2`,\n    ::\n        0 --|\xe2\x80\xbe\xe2\x80\xbe\xe2\x80\xbe\xe2\x80\xbe|-- 1\n        2 --|    |-- 3\n        4 --|    |-- 5\n        6 --|____|-- 7\n\n    goes to\n    ::\n        (0,2) --|\xe2\x80\xbe\xe2\x80\xbe\xe2\x80\xbe\xe2\x80\xbe|-- (1,3)\n        (4,6) --|____|-- (5,7)\n\n    Args:\n        tensor (array): a tensor with :math:`4N` indices of dimension :math:`D` each\n\n    Returns:\n        array: a tensor with 4 indices of dimension :math:`D^N` each\n\n    Raises:\n        ValueError: if the input tensor\'s dimensions are not all equal or if the number\n            of its indices is not a multiple of 4\n    """"""\n    dims = tensor.ndim\n\n    if dims % 4 != 0:\n        raise ValueError(\n            ""Tensor must have a number of indices that is a multiple of 4, but it has {dims} indices"".format(\n                dims=dims\n            )\n        )\n\n    shape = tensor.shape\n\n    if len(set(shape)) != 1:\n        raise ValueError(\n            ""Tensor indices must have all the same dimension, but tensor has shape {shape}"".format(\n                shape=shape\n            )\n        )\n\n    transposed = np.einsum(\n        tensor, [int(n) for n in np.arange(dims).reshape((2, dims // 2)).T.reshape([-1])]\n    )\n    vectorized = np.reshape(transposed, [shape[0] ** (dims // 4)] * 4)\n    transposed_back = np.einsum(""abcd -> acbd"", vectorized)\n\n    return transposed_back\n\n\ndef _unvectorize(tensor, num_subsystems):\n    """"""Given a tensor with 4 indices, each of dimension :math:`D^N`, return the unvectorized\n    tensor with 4N indices of dimension D each. This is the inverse of the procedure\n    given by :func:`_vectorize`.\n    Caution: this private method is intended to be used only for Choi and Liouville operators.\n\n    Args:\n        tensor (array): a tensor with :math:`4` indices of dimension :math:`D^N`\n\n    Returns:\n        array: a tensor with :math:`4N` indices of dimension :math:`D` each\n\n    Raises:\n        ValueError: if the input tensor\'s dimensions are not all equal or if the number\n            of its indices is not 4\n    """"""\n    dims = tensor.ndim\n\n    if dims != 4:\n        raise ValueError(""tensor must have 4 indices, but it has {dims} indices"".format(dims=dims))\n\n    shape = tensor.shape\n\n    if len(set(shape)) != 1:\n        raise ValueError(\n            ""tensor indices must have all the same dimension, but tensor has shape {shape}"".format(\n                shape=shape\n            )\n        )\n\n    transposed = np.einsum(""abcd -> acbd"", tensor)\n    unvectorized = np.reshape(\n        transposed, [int(shape[0] ** (1 / num_subsystems))] * (4 * num_subsystems)\n    )\n    transposed_back = np.einsum(\n        unvectorized,\n        [\n            int(n)\n            for n in np.arange(4 * num_subsystems).reshape((2 * num_subsystems, 2)).T.reshape([-1])\n        ],\n    )\n\n    return transposed_back\n\n\ndef _interleaved_identities(n: int, cutoff_dim: int):\n    r""""""Maximally entangled state of `n` modes.\n\n    Returns the tensor :math:`\\sum_{abc\\ldots} \\ket{abc\\ldots}\\bra{abc\\ldots}`\n    representing an unnormalized, maximally entangled state of `n` subsystems.\n\n    Args:\n        n (int): number of subsystems\n        cutoff_dim (int): Fock basis truncation dimension\n\n    Returns:\n        array: unnormalized maximally entangled state, shape == (cutoff_dim,) * (2*n)\n    """"""\n    I = np.identity(cutoff_dim)\n    temp = I\n    for _ in range(1, n):\n        temp = np.tensordot(temp, I, axes=0)\n\n    # use einsum to permute the indices such that |a><a|*|b><b|*|c><c|*... becomes |abc...><abc...|\n    sublist = [int(n) for n in np.arange(2 * n).reshape((2, n)).T.reshape([-1])]\n    return np.einsum(temp, sublist)\n\n\ndef _program_in_CJ_rep(prog, cutoff_dim: int):\n    """"""Convert a Program object to Choi-Jamiolkowski representation.\n\n    Doubles the number of modes of a Program object and prepends to its circuit\n    the preparation of the maximally entangled ket state.\n\n    The core idea is that when we apply any quantum channel (e.g. a unitary gate)\n    to the density matrix of the maximally entangled state, we obtain the Choi matrix\n    of the channel as the result.\n\n    If the channel is unitary, applying it on the maximally entangled ket yields\n    the corresponding unitary matrix, reshaped.\n\n    Args:\n        prog (Program): quantum program\n        cutoff_dim (int): the Fock basis truncation\n\n    Returns:\n        Program: modified program\n    """"""\n    prog = copy.deepcopy(prog)\n    prog.locked = False  # unlock the copy so we can modify it\n    N = prog.init_num_subsystems\n    prog._add_subsystems(N)  # pylint: disable=protected-access\n    prog.init_num_subsystems = 2 * N\n    I = _interleaved_identities(N, cutoff_dim)\n    # prepend the circuit with the I ket preparation\n    prog.circuit.insert(0, Command(Ket(I), list(prog.reg_refs.values())))\n    return prog\n\n\ndef extract_unitary(prog, cutoff_dim: int, vectorize_modes: bool = False, backend: str = ""fock""):\n    r""""""Numerical array representation of a unitary quantum circuit.\n\n    Note that the circuit must only include operations of the :class:`strawberryfields.ops.Gate` class.\n\n    * If ``vectorize_modes=True``, it returns a matrix.\n    * If ``vectorize_modes=False``, it returns an operator with :math:`2N` indices,\n      where N is the number of modes that the Program is created with. Adjacent\n      indices correspond to output-input pairs of the same mode.\n\n\n    **Example:**\n\n    This shows the Hong-Ou-Mandel effect by extracting the unitary of a 50/50 beamsplitter, and then\n    computing the output given by one photon at each input (notice the order of the indices: :math:`[out_1, in_1, out_2, in_2,\\dots]`).\n    The result tells us that the two photons always emerge together from a random output port and never one per port.\n\n    >>> prog = sf.Program(num_subsystems=2)\n    >>> with prog.context as q:\n    >>>     BSgate(np.pi/4) | q\n    >>> U = extract_unitary(prog, cutoff_dim=3)\n    >>> print(abs(U[:,1,:,1])**2)\n    [[0.  0.  0.5]\n     [0.  0.  0. ]\n     [0.5 0.  0. ]])\n\n    Args:\n        prog (Program): quantum program\n        cutoff_dim (int): dimension of each index\n        vectorize_modes (bool): If True, reshape input and output modes in order to return a matrix.\n        backend (str): the backend to build the unitary; ``\'fock\'`` (default) and ``\'tf\'`` are supported\n\n    Returns:\n        array, tf.Tensor: numerical array of the unitary circuit\n            as a NumPy ndarray (``\'fock\'`` backend) or as a TensorFlow Tensor (``\'tf\'`` backend)\n\n    Raises:\n        TypeError: if the operations used to construct the circuit are not all unitary\n    """"""\n\n    if not is_unitary(prog):\n        raise TypeError(""The circuit definition contains elements that are not of type Gate"")\n\n    if backend not in (""fock"", ""tf""):\n        raise ValueError(""Only \'fock\' and \'tf\' backends are supported"")\n\n    N = prog.init_num_subsystems\n    # extract the unitary matrix by running a modified version of the Program\n    p = _program_in_CJ_rep(prog, cutoff_dim)\n    eng = LocalEngine(backend, backend_options={""cutoff_dim"": cutoff_dim, ""pure"": True})\n    result = eng.run(p).state.ket()\n\n    if vectorize_modes:\n        if backend == ""fock"":\n            reshape = np.reshape\n        else:\n            reshape = tf.reshape\n        return reshape(result, [cutoff_dim ** N, cutoff_dim ** N])\n\n    # here we rearrange the indices to go back to the order [in1, out1, in2, out2, etc...]\n    if backend == ""fock"":\n        tp = np.transpose\n    else:\n        tp = tf.transpose\n    return tp(result, [int(n) for n in np.arange(2 * N).reshape((2, N)).T.reshape([-1])])\n\n\ndef extract_channel(\n    prog, cutoff_dim: int, representation: str = ""choi"", vectorize_modes: bool = False\n):\n    r""""""Numerical array representation of the channel corresponding to a quantum circuit.\n\n    The representation choices include the Choi state representation, the Liouville representation, and\n    the Kraus representation.\n\n    .. note:: Channel extraction can currently only be performed using the ``\'fock\'`` backend.\n\n    **Tensor shapes**\n\n    * If ``vectorize_modes=True``:\n\n      - ``representation=\'choi\'`` and ``representation=\'liouville\'`` return an array\n        with 4 indices\n      - ``representation=\'kraus\'`` returns an array of Kraus operators in matrix form\n\n\n    * If ``vectorize_modes=False``:\n\n      - ``representation=\'choi\'`` and ``representation=\'liouville\'`` return an array\n        with :math:`4N` indices\n      - ``representation=\'kraus\'`` returns an array of Kraus operators with :math:`2N` indices each,\n        where :math:`N` is the number of modes that the Program is created with\n\n    Note that the Kraus representation automatically returns only the non-zero Kraus operators.\n    One can reduce the number of operators by discarding Kraus operators with small norm (thus approximating the channel).\n\n    **Choi representation**\n\n    Mathematically, the Choi representation of a channel is a bipartite state :math:`\\Lambda_{AB}`\n    which contains a complete description of the channel. The way we use it to compute the action\n    of the channel :math:`\\mathcal{C}` on an input state :math:`\\mathcal{\\rho}` is as follows:\n\n    .. math::\n\n            \\mathcal{C}(\\rho) = \\mathrm{Tr}[(\\rho_A^T\\otimes\\mathbb{1}_B)\\Lambda_{AB}]\n\n    The indices of the non-vectorized Choi operator match exactly those of the state, so that the action\n    of the channel can be computed as (e.g., for one mode or for ``vectorize_modes=True``):\n\n    >>> rho_out = np.einsum(\'ab,abcd\', rho_in, choi)\n\n    Notice that this respects the transpose operation.\n\n    For two modes:\n\n    >>> rho_out = np.einsum(\'abcd,abcdefgh\', rho_in, choi)\n\n    Combining consecutive channels (in the order :math:`1,2,3,\\dots`) is also straightforward with the Choi operator:\n\n    >>> choi_combined = np.einsum(\'abcd,cdef,efgh\', choi_1, choi_2, choi_3)\n\n    **Liouville operator**\n\n    The Liouville operator is a partial transpose of the Choi operator, such that the first half of\n    consecutive index pairs are the output-input right modes (i.e., acting on the ""bra"" part of the state)\n    and the second half are the output-input left modes (i.e., acting on the ""ket"" part of the state).\n\n    Therefore, the action of the Liouville operator (e.g., for one mode or for ``vectorize_modes=True``) is\n\n    .. math::\n\n            \\mathcal{C}(\\rho) = \\mathrm{unvec}[\\mathcal{L}\\mathrm{vec}(\\rho)]\n\n    where vec() and unvec() are the operations that stack the columns of a matrix to form\n    a vector and vice versa.\n    In code:\n\n    >>> rho_out = np.einsum(\'abcd,bd->ca\', liouville, rho_in)\n\n    Notice that the state contracts with the second index of each pair and that we output the ket\n    on the left (``c``) and the bra on the right (``a``).\n\n    For two modes we have:\n\n    >>> rho_out = np.einsum(\'abcdefgh,fbhd->eagc\', liouville, rho_in)\n\n    The Liouville representation has the property that if the channel is unitary, the operator is separable.\n    On the other hand, even if the channel were the identity, the Choi operator would correspond to a maximally entangled state.\n\n    The choi and liouville operators in matrix form (i.e., with two indices) can be found as follows, where\n    ``D`` is the dimension of each vectorized index (i.e., for :math:`N` modes, ``D=cutoff_dim**N``):\n\n    >>> choi_matrix = liouville.reshape(D**2, D**2).T\n    >>> liouville_matrix = choi.reshape(D**2, D**2).T\n\n    **Kraus representation**\n\n    The Kraus representation is perhaps the most well known:\n\n    .. math::\n\n            \\mathcal{C}(\\rho) = \\sum_k A_k\\rho A_k^\\dagger\n\n    So to define a channel in the Kraus representation one needs to supply a list of Kraus operators :math:`\\{A_k\\}`.\n    In fact, the result of ``extract_channel`` in the Kraus representation is a rank-3 tensor, where the first\n    index is the one indexing the list of operators.\n\n    Adjacent indices of each Kraus operator correspond to output-input pairs of the same mode, so the action\n    of the channel can be written as (here for one mode or for ``vectorize_modes=True``):\n\n    >>> rho_out = np.einsum(\'abc,cd,aed->be\', kraus, rho_in, np.conj(kraus))\n\n    Notice the transpose on the third index string (``aed`` rather than ``ade``), as the last operator should be the\n    conjugate transpose of the first, and we cannot just do ``np.conj(kraus).T`` because ``kraus`` has 3 indices and we\n    just need to transpose the last two.\n\n\n    Example:\n        Here we show that the Choi operator of the identity channel is proportional to\n        a maximally entangled Bell :math:`\\ket{\\phi^+}` state:\n\n    >>> prog = sf.Program(num_subsystems=1)\n    >>> C = extract_channel(prog, cutoff_dim=2, representation=\'choi\')\n    >>> print(abs(C).reshape((4,4)))\n    [[1. 0. 0. 1.]\n     [0. 0. 0. 0.]\n     [0. 0. 0. 0.]\n     [1. 0. 0. 1.]]\n\n    Args:\n        prog (Program): program containing the circuit\n        cutoff_dim (int): dimension of each index\n        representation (str): choice between ``\'choi\'``, ``\'liouville\'`` or ``\'kraus\'``\n        vectorize_modes (bool): if True, reshapes the result into rank-4 tensor,\n            otherwise it returns a rank-4N tensor, where N is the number of modes\n\n    Returns:\n        array: channel, according to the specified options\n\n    Raises:\n        TypeError: if the gates used to construct the circuit are not all unitary or channels\n    """"""\n    if not is_channel(prog):\n        raise TypeError(\n            ""The circuit definition contains elements that are neither of type Gate nor of type Channel""\n        )\n\n    N = prog.init_num_subsystems\n    p = _program_in_CJ_rep(prog, cutoff_dim)\n\n    eng = LocalEngine(""fock"", backend_options={""cutoff_dim"": cutoff_dim, ""pure"": True})\n    choi = eng.run(p).state.dm()\n    choi = np.einsum(""abcd->cdab"", _vectorize(choi))\n\n    if representation.lower() == ""choi"":\n        result = choi\n        if not vectorize_modes:\n            result = _unvectorize(result, N)\n\n    elif representation.lower() == ""liouville"":\n        result = np.einsum(""abcd -> dbca"", choi)\n        if not vectorize_modes:\n            result = _unvectorize(result, N)\n\n    elif representation.lower() == ""kraus"":\n        # The liouville operator is the sum of a bipartite product of kraus matrices, so if we vectorize them we obtain\n        # a matrix whose eigenvectors are proportional to the vectorized kraus operators\n        vectorized_liouville = np.einsum(""abcd -> cadb"", choi).reshape(\n            [cutoff_dim ** (2 * N), cutoff_dim ** (2 * N)]\n        )\n        eigvals, eigvecs = np.linalg.eig(vectorized_liouville)\n\n        # We keep only those eigenvectors that correspond to non-zero eigenvalues\n        eigvecs = eigvecs[:, ~np.isclose(abs(eigvals), 0)]\n        eigvals = eigvals[~np.isclose(abs(eigvals), 0)]\n\n        # We rescale the eigenvectors with the sqrt of the eigenvalues (the other sqrt would rescale the right eigenvectors)\n        rescaled_eigenvectors = np.einsum(""b,ab->ab"", np.sqrt(eigvals), eigvecs)\n\n        # Finally we reshape the eigenvectors to form matrices, i.e., the Kraus operators and we make the first index\n        # be the one that indexes the list of Kraus operators.\n        result = np.einsum(\n            ""abc->cab"", rescaled_eigenvectors.reshape([cutoff_dim ** N, cutoff_dim ** N, -1])\n        )\n\n        if not vectorize_modes:\n            result = np.einsum(\n                np.reshape(result, [-1] + [cutoff_dim] * (2 * N)),\n                range(1 + 2 * N),\n                [0] + [2 * n + 1 for n in range(N)] + [2 * n + 2 for n in range(N)],\n            )\n    else:\n        raise ValueError(""representation {} not supported"".format(representation))\n\n    return result\n'"
tests/conftest.py,2,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nDefault parameters, environment variables, fixtures, and common routines for the unit tests.\n""""""\n# pylint: disable=redefined-outer-name\nimport os\nimport pytest\n\nimport strawberryfields as sf\nfrom strawberryfields.engine import LocalEngine\nfrom strawberryfields.program import Program\nfrom strawberryfields.backends.base import BaseBackend\nfrom strawberryfields.backends.fockbackend import FockBackend\nfrom strawberryfields.backends.gaussianbackend import GaussianBackend\n\n\ntry:\n    import tensorflow as tf\nexcept (ImportError, ModuleNotFoundError) as e:\n    tf_available = False\n    tf_version = False\nelse:\n    tf_available = True\n    tf_version = tf.__version__\n\n\nbackend_params = [\n    pytest.param(FockBackend, marks=pytest.mark.fock),\n    pytest.param(GaussianBackend, marks=pytest.mark.gaussian),\n]\n\n\neng_backend_params = [\n    pytest.param(""fock"", marks=pytest.mark.fock),\n    pytest.param(""gaussian"", marks=pytest.mark.gaussian),\n]\n\n\nif tf_available and tf.__version__[:2] == ""2."":\n    from strawberryfields.backends.tfbackend import TFBackend\n\n    backend_params.append(pytest.param(TFBackend, marks=pytest.mark.tf))\n    eng_backend_params.append(pytest.param(""tf"", marks=pytest.mark.tf))\nelse:\n    tf_available = False\n\n\n# defaults\nTOL = 1e-3\nCUTOFF = 6\nALPHA = 0.1\nHBAR = 1.7\nBATCHED = False\nBATCHSIZE = 2\n\n\n@pytest.fixture(scope=""session"")\ndef tol():\n    """"""Numerical tolerance for equality tests.""""""\n    return float(os.environ.get(""TOL"", TOL))\n\n\n@pytest.fixture(scope=""session"")\ndef cutoff():\n    """"""Fock state cutoff""""""\n    return int(os.environ.get(""CUTOFF"", CUTOFF))\n\n\n@pytest.fixture(scope=""session"")\ndef alpha():\n    """"""Maximum magnitude of coherent states used in tests""""""\n    return float(os.environ.get(""ALPHA"", ALPHA))\n\n\n@pytest.fixture(scope=""session"")\ndef hbar():\n    """"""The value of hbar""""""\n    sf.hbar = float(os.environ.get(""HBAR"", HBAR))\n    return sf.hbar\n\n\n@pytest.fixture(\n    params=[\n        pytest.param(True, marks=pytest.mark.pure),\n        pytest.param(False, marks=pytest.mark.mixed),\n    ]\n)\ndef pure(request):\n    """"""Whether to run the backend in pure or mixed state mode""""""\n    return request.param  # bool(int(os.environ.get(""PURE"", PURE)))\n\n\n@pytest.fixture(scope=""session"")\ndef batch_size():\n    """"""Whether to run the backend in batched mode""""""\n    if ""BATCHSIZE"" in os.environ:\n        # if user-specified BATCHSIZE provided, then batching is assumed (even if BATCHED=0)\n        return int(os.environ[""BATCHSIZE""])\n\n    # check if batching is turned on\n    batched = bool(int(os.environ.get(""BATCHED"", BATCHED)))\n\n    if batched:\n        # use the default batch size\n        return BATCHSIZE\n\n    return None  # no batching\n\n\n@pytest.fixture\ndef backend(monkeypatch):\n    """"""Create a mocked out backend fixture for front-end only tests""""""\n    dummy_backend = BaseBackend()\n    with monkeypatch.context() as m:\n        # mock out the base backend\n        m.setattr(dummy_backend, ""add_mode"", lambda n: None)\n        m.setattr(dummy_backend, ""del_mode"", lambda n: None)\n        m.setattr(dummy_backend, ""displacement"", lambda alpha, modes: None)\n        m.setattr(dummy_backend, ""prepare_coherent_state"", lambda z, modes: None)\n        m.setattr(dummy_backend, ""squeeze"", lambda r, modes: None)\n        m.setattr(dummy_backend, ""rotation"", lambda r, modes: None)\n        m.setattr(dummy_backend, ""beamsplitter"", lambda t, r, m1, m2: None)\n        m.setattr(dummy_backend, ""measure_homodyne"", lambda phi, modes, select, shots: 5)\n        m.setattr(dummy_backend, ""state"", lambda modes, shots: None)\n        m.setattr(dummy_backend, ""reset"", lambda: None)\n        dummy_backend.two_mode_squeeze = lambda r, phi, modes: None\n        dummy_backend.get_cutoff_dim = lambda: 6\n        yield dummy_backend\n\n\n@pytest.fixture(scope=""session"")\ndef print_fixtures(cutoff, hbar, batch_size):\n    """"""Print the test configuration at the beginning of the session""""""\n    print(\n        ""FIXTURES: cutoff = {}, pure = {}, hbar = {}, batch_size = {}"".format(\n            cutoff, hbar, pure, batch_size\n        )\n    )\n\n\n@pytest.fixture(params=backend_params)\ndef setup_backend(\n    request, cutoff, pure, batch_size\n):  # pylint: disable=redefined-outer-name\n    """"""Parameterized fixture, used to automatically create a backend of certain number of modes.\n\n    This fixture should only be used in backend tests, as it bypasses Engine and\n    initializes the backend directly.\n\n    Every test that uses this fixture, or a fixture that depends on it\n    will be run three times, one for each backend.\n\n    To explicitly mark a test to only work on certain backends, you may\n    use the ``@pytest.mark.backends()`` fixture. For example, for a test that\n    only works on the TF and Fock backends, ``@pytest.mark.backends(\'tf\', \'fock\').\n    """"""\n\n    def _setup_backend(num_subsystems):\n        """"""Factory function""""""\n        backend = request.param()\n        backend.begin_circuit(\n            num_subsystems=num_subsystems,\n            cutoff_dim=cutoff,\n            pure=pure,\n            batch_size=batch_size,\n        )\n        return backend\n\n    return _setup_backend\n\n\n@pytest.fixture(params=eng_backend_params)\ndef setup_backend_pars(\n    request, cutoff, pure, batch_size\n):  # pylint: disable=redefined-outer-name\n    """"""Parameterized fixture, a container for the backend parameters.\n\n    Every test that uses this fixture, or a fixture that depends on it\n    will be run three times, one for each backend.\n\n    To explicitly mark a test to only work on certain backends, you may\n    use the ``@pytest.mark.backends()`` fixture. For example, for a test that\n    only works on the TF and Fock backends, ``@pytest.mark.backends(\'tf\', \'fock\').\n    """"""\n    return request.param, {""cutoff_dim"": cutoff, ""pure"": pure, ""batch_size"": batch_size}\n\n\n@pytest.fixture\ndef setup_eng(setup_backend_pars):  # pylint: disable=redefined-outer-name\n    """"""Parameterized fixture, used to automatically create an Engine and a Program with a certain number of modes.""""""\n\n    def _setup_eng(num_subsystems, **kwargs):\n        """"""Factory function""""""\n        prog = Program(num_subsystems)\n        backend, backend_options = setup_backend_pars\n        backend_options.update(kwargs)  # override defaults with kwargs\n        eng = LocalEngine(backend=backend, backend_options=backend_options)\n        return eng, prog\n\n    return _setup_eng\n\ndef pytest_runtest_setup(item):\n    """"""Automatically skip tests if they are marked for only certain backends""""""\n    if tf_available:\n        allowed_backends = {""gaussian"", ""tf"", ""fock""}\n    else:\n        allowed_backends = {""gaussian"", ""fock""}\n\n    # load the marker specifying what the backend is\n    marks = {mark.name for mark in item.iter_markers() if mark.name in allowed_backends}\n\n    # load a marker specifying whether the test only works with certain backends\n    test_backends = [mark.args for mark in item.iter_markers(name=""backends"")]\n\n    if not test_backends:\n        # if the test hasn\'t specified that it runs on particular backends,\n        # assume it will work with all backends\n        test_backends = allowed_backends\n    else:\n        # otherwise, extract the set of backend strings the test works with\n        test_backends = test_backends[0]\n\n    for b in marks:\n        if b not in test_backends:\n            pytest.skip(\n                ""\\nTest {} only runs with {} backend(s), ""\n                ""but {} backend provided"".format(item.nodeid, test_backends, b)\n            )\n\n    # skip broken tests\n    for mark in item.iter_markers(name=""broken""):\n        if mark.args:\n            pytest.skip(""Broken test skipped: {}"".format(*mark.args))\n        else:\n            pytest.skip(""Test skipped as corresponding code base is currently broken!"")\n'"
doc/_ext/edit_on_github.py,0,"b'""""""\nSphinx extension to add ReadTheDocs-style ""Edit on GitHub"" links to the\nsidebar.\nLoosely based on https://github.com/astropy/astropy/pull/347\n""""""\n\nimport os\nimport warnings\n\n\n__licence__ = \'BSD (3 clause)\'\n\n\ndef get_github_url(app, view, path):\n    return \'https://github.com/{project}/{view}/{branch}/{path}\'.format(\n        project=app.config.edit_on_github_project,\n        view=view,\n        branch=app.config.edit_on_github_branch,\n        path=path)\n\n\ndef html_page_context(app, pagename, templatename, context, doctree):\n    if templatename != \'page.html\':\n        return\n\n    if not app.config.edit_on_github_project:\n        warnings.warn(""edit_on_github_project not specified"")\n        return\n\n    if not doctree:\n        return\n    \n    path = os.path.relpath(doctree.get(\'source\'), app.builder.srcdir)\n    show_url = get_github_url(app, \'blob\', path)\n    edit_url = get_github_url(app, \'edit\', path)\n\n    context[\'show_on_github_url\'] = show_url\n    context[\'edit_on_github_url\'] = edit_url\n\n\ndef setup(app):\n    app.add_config_value(\'edit_on_github_project\', \'\', True)\n    app.add_config_value(\'edit_on_github_branch\', \'master\', True)\n    app.connect(\'html-page-context\', html_page_context)'"
strawberryfields/api/__init__.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThis package contains the modules for the low-level Strawberry Fields program\nexecution API. The :class:`~strawberryfields.api.Connection` class mediates\nthe network connection to, and exposes operations provided by, a remote program\nexecution backend. The :class:`~strawberryfields.api.Job` and\n:class:`~strawberryfields.api.Result` classes provide interfaces for managing\nprogram execution jobs and job results respectively.\n""""""\n\nfrom .connection import Connection, RequestFailedError\nfrom .job import InvalidJobOperationError, Job, JobStatus\nfrom .result import Result\n\n__all__ = [""Connection"", ""Job"", ""Result""]\n'"
strawberryfields/api/connection.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThis module provides an interface to a remote program execution backend.\n""""""\nimport io\nfrom datetime import datetime\nfrom typing import List\n\nimport numpy as np\nimport requests\n\nfrom strawberryfields.configuration import load_config\nfrom strawberryfields.io import to_blackbird\nfrom strawberryfields.logger import create_logger\nfrom strawberryfields.program import Program\n\nfrom .job import Job, JobStatus\nfrom .result import Result\n\n# pylint: disable=bad-continuation,protected-access\n\n\nclass RequestFailedError(Exception):\n    """"""Raised when a request to the remote platform returns an error response.""""""\n\n\nclass Connection:\n    """"""Manages remote connections to the remote job execution platform and exposes\n    various job operations.\n\n    For basic usage, it is not necessary to manually instantiate this object; the user\n    is encouraged to use the higher-level interface provided by\n    :class:`~strawberryfields.RemoteEngine`.\n\n    **Example:**\n\n    The following example instantiates a :class:`~strawberryfields.api.Connection` for a\n    given API authentication token, tests the connection, submits a new job, and\n    retrieves an existing job.\n\n    >>> connection = Connection(token=""abc"")\n    >>> success = connection.ping()  # `True` if successful, `False` if the connection fails\n    >>> job = connection.create_job(""chip_name"", program, shots=123)\n    >>> job\n    <Job: id=d177cbf5-1816-4779-802f-cef2c117dc1a, ...>\n    >>> job.status\n    ""queued""\n    >>> job.result\n    AttributeError                            Traceback (most recent call last)\n    <ipython-input-12-d54011f90b17> in <module>\n    ...\n    AttributeError: The result is undefined for jobs that are not completed (current status: queued)\n    >>> job = connection.get_job(known_job_id)\n    >>> job\n    <Job: id=59a1c0b1-c6a7-4f9b-ae37-0ac5eec9c413, ...>\n    >>> job.status\n    ""complete""\n    >>> job.result\n    [[0 1 0 2 1 0 0 0]]\n\n    Args:\n        token (str): the API authentication token\n        host (str): the hostname of the remote platform\n        port (int): the port to connect to on the remote host\n        use_ssl (bool): whether to use SSL for the connection\n    """"""\n\n    # pylint: disable=too-many-instance-attributes\n    def __init__(\n        self,\n        token: str = None,\n        host: str = None,\n        port: int = None,\n        use_ssl: bool = None,\n        verbose: bool = True,\n    ):\n        default_config = load_config()\n\n        self._token = token or default_config[""api""][""authentication_token""]\n        self._host = host or default_config[""api""][""hostname""]\n        self._port = port or default_config[""api""][""port""]\n        self._use_ssl = use_ssl or default_config[""api""][""use_ssl""]\n        self._verbose = verbose\n\n        self._base_url = ""http{}://{}:{}"".format(""s"" if self.use_ssl else """", self.host, self.port)\n        self._headers = {""Authorization"": self.token}\n\n        self.log = create_logger(__name__)\n\n    @property\n    def token(self) -> str:\n        """"""The API authentication token.\n\n        Returns:\n            str\n        """"""\n        return self._token\n\n    @property\n    def host(self) -> str:\n        """"""The host for the remote platform.\n\n        Returns:\n            str\n        """"""\n        return self._host\n\n    @property\n    def port(self) -> int:\n        """"""The port to connect to on the remote host.\n\n        Returns:\n            int\n        """"""\n        return self._port\n\n    @property\n    def use_ssl(self) -> bool:\n        """"""Whether to use SSL for the connection.\n\n        Returns:\n            bool\n        """"""\n        return self._use_ssl\n\n    def create_job(self, target: str, program: Program, run_options: dict = None) -> Job:\n        """"""Creates a job with the given circuit.\n\n        Args:\n            target (str): the target device\n            program (strawberryfields.Program): the quantum circuit\n            run_options (Dict[str, Any]): Runtime arguments for the program execution.\n                If provided, overrides the value stored in the given ``program``.\n\n        Returns:\n            strawberryfields.api.Job: the created job\n        """"""\n        # Serialize a blackbird circuit for network transmission\n        bb = to_blackbird(program)\n        bb._target[""name""] = target\n        bb._target[""options""] = run_options\n\n        circuit = bb.serialize()\n\n        path = ""/jobs""\n        response = requests.post(self._url(path), headers=self._headers, json={""circuit"": circuit})\n        if response.status_code == 201:\n            job_id = response.json()[""id""]\n            if self._verbose:\n                self.log.info(""Job %s was successfully submitted."", job_id)\n            return Job(id_=job_id, status=JobStatus(response.json()[""status""]), connection=self,)\n        raise RequestFailedError(\n            ""Failed to create job: {}"".format(self._format_error_message(response))\n        )\n\n    def get_all_jobs(self, after: datetime = datetime(1970, 1, 1)) -> List[Job]:\n        """"""Gets a list of jobs created by the user, optionally filtered by datetime.\n\n        Args:\n            after (datetime.datetime): if provided, only jobs more recently created\n                then ``after`` are returned\n\n        Returns:\n            List[strawberryfields.api.Job]: the jobs\n        """"""\n        raise NotImplementedError(""This feature is not yet implemented"")\n\n    def get_job(self, job_id: str) -> Job:\n        """"""Gets a job.\n\n        Args:\n            job_id (str): the job ID\n\n        Returns:\n            strawberryfields.api.Job: the job\n        """"""\n        path = ""/jobs/{}"".format(job_id)\n        response = requests.get(self._url(path), headers=self._headers)\n        if response.status_code == 200:\n            return Job(\n                id_=response.json()[""id""],\n                status=JobStatus(response.json()[""status""]),\n                connection=self,\n                meta=response.json()[""meta""],\n            )\n        raise RequestFailedError(\n            ""Failed to get job: {}"".format(self._format_error_message(response))\n        )\n\n    def get_job_status(self, job_id: str) -> str:\n        """"""Returns the status of a job.\n\n        Args:\n            job_id (str): the job ID\n\n        Returns:\n            str: the job status\n        """"""\n        return self.get_job(job_id).status\n\n    def get_job_result(self, job_id: str) -> Result:\n        """"""Returns the result of a job.\n\n        Args:\n            job_id (str): the job ID\n\n        Returns:\n            strawberryfields.api.Result: the job result\n        """"""\n        path = ""/jobs/{}/result"".format(job_id)\n        response = requests.get(\n            self._url(path), headers={""Accept"": ""application/x-numpy"", **self._headers}\n        )\n        if response.status_code == 200:\n            # Read the numpy binary data in the payload into memory\n            with io.BytesIO() as buf:\n                buf.write(response.content)\n                buf.seek(0)\n\n                samples = np.load(buf, allow_pickle=False)\n\n                if np.issubdtype(samples.dtype, np.integer):\n                    # Samples represent photon numbers.\n                    # Convert to int64, to avoid unexpected behaviour\n                    # when users postprocess these samples.\n                    samples = samples.astype(np.int64)\n\n            return Result(samples, is_stateful=False)\n        raise RequestFailedError(\n            ""Failed to get job result: {}"".format(self._format_error_message(response))\n        )\n\n    def cancel_job(self, job_id: str):\n        """"""Cancels a job.\n\n        Args:\n            job_id (str): the job ID\n        """"""\n        path = ""/jobs/{}"".format(job_id)\n        response = requests.patch(\n            self._url(path), headers=self._headers, json={""status"": JobStatus.CANCELLED.value}\n        )\n        if response.status_code == 204:\n            if self._verbose:\n                self.log.info(""The job %s was successfully cancelled."", job_id)\n            return\n        raise RequestFailedError(\n            ""Failed to cancel job: {}"".format(self._format_error_message(response))\n        )\n\n    def ping(self) -> bool:\n        """"""Tests the connection to the remote backend.\n\n        Returns:\n            bool: ``True`` if the connection is successful, and ``False`` otherwise\n        """"""\n        path = ""/healthz""\n        response = requests.get(self._url(path), headers=self._headers)\n        return response.status_code == 200\n\n    def _url(self, path: str) -> str:\n        return self._base_url + path\n\n    @staticmethod\n    def _format_error_message(response: requests.Response) -> str:\n        body = response.json()\n        return ""{} ({}): {} ({})"".format(\n            body.get(""status_code"", """"),\n            body.get(""code"", """"),\n            body.get(""detail"", """"),\n            body.get(""meta"", """"),\n        )\n\n    def __repr__(self):\n        return ""<{}: token={}, host={}>"".format(self.__class__.__name__, self.token, self.host)\n\n    def __str__(self):\n        return self.__repr__()\n'"
strawberryfields/api/job.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThis module provides classes for interfacing with program execution jobs on a remote backend.\n""""""\nimport enum\n\nfrom strawberryfields.logger import create_logger\n\nfrom .result import Result\n\n\nclass InvalidJobOperationError(Exception):\n    """"""Raised when an invalid operation is performed on a job.""""""\n\n\nclass FailedJobError(Exception):\n    """"""Raised when a job had a failure on the server side.""""""\n\n\nclass JobStatus(enum.Enum):\n    """"""Represents the status of a remote job.\n\n    This class maps a set of job statuses to the string representations returned by the\n    remote platform.\n    """"""\n\n    OPEN = ""open""\n    QUEUED = ""queued""\n    CANCELLED = ""cancelled""\n    COMPLETED = ""complete""\n    FAILED = ""failed""\n\n    @property\n    def is_final(self) -> bool:\n        """"""Checks if this status represents a final and immutable state.\n\n        This method is primarily used to determine if an operation is valid for a given\n        status.\n\n        Returns:\n            bool\n        """"""\n        return self in (JobStatus.CANCELLED, JobStatus.COMPLETED, JobStatus.FAILED)\n\n    def __repr__(self) -> str:\n        return ""<JobStatus: {}>"".format(self.value)\n\n    def __str__(self) -> str:\n        return self.__repr__()\n\n\nclass Job:\n    """"""Represents a remote job that can be queried for its status or result.\n\n    This object should typically not be instantiated directly, but returned by an\n    :class:`strawberryfields.RemoteEngine` or :class:`strawberryfields.api.Connection`\n    when a job is run.\n\n    Args:\n        id_ (str): the job ID\n        status (strawberryfields.api.JobStatus): the job status\n        connection (strawberryfields.api.Connection): the connection over which the\n            job is managed\n        meta (dict[str, str]): metadata related to job execution\n    """"""\n\n    def __init__(self, id_: str, status: JobStatus, connection, meta: dict = None):\n        self._id = id_\n        self._status = status\n        self._connection = connection\n        self._result = None\n        self._meta = meta or {}\n\n        self.log = create_logger(__name__)\n\n    @property\n    def id(self) -> str:\n        """"""The job ID.\n\n        Returns:\n            str\n        """"""\n        return self._id\n\n    @property\n    def status(self) -> str:\n        """"""Returns the current job status, with possible values including ``""open""``,\n        ``""queued""``, ``""cancelled""``, ``""complete""``, and ``""failed""``.\n\n        Returns:\n            str\n        """"""\n        return self._status.value\n\n    @property\n    def result(self) -> Result:\n        """"""Returns the :class:`~.Result` of a completed job.\n\n        This is only defined for completed jobs, and raises an exception for any other\n        status.\n\n        Returns:\n            strawberryfields.api.Result\n        """"""\n        if self._status != JobStatus.COMPLETED:\n            raise AttributeError(\n                ""The result is undefined for jobs that are not completed ""\n                ""(current status: {})"".format(self._status.value)\n            )\n        return self._result\n\n    @property\n    def meta(self) -> dict:\n        """"""Returns a dictionary of metadata on job execution, such as error\n        details.\n\n        Returns:\n            dict[str, str]\n        """"""\n        return self._meta\n\n    def refresh(self):\n        """"""Refreshes the status and metadata of an open or queued job,\n        along with the job result if the job is newly completed.\n        """"""\n        if self._status.is_final:\n            self.log.warning(""A %s job cannot be refreshed"", self._status.value)\n            return\n        job_info = self._connection.get_job(self.id)\n        self._status = JobStatus(job_info.status)\n        self._meta = job_info.meta\n        self.log.debug(""Job %s metadata: %s"", self.id, job_info.meta)\n        if self._status == JobStatus.COMPLETED:\n            self._result = self._connection.get_job_result(self.id)\n\n    def cancel(self):\n        """"""Cancels an open or queued job.\n\n        Only an open or queued job can be cancelled; an exception is raised otherwise.\n        """"""\n        if self._status.is_final:\n            raise InvalidJobOperationError(\n                ""A {} job cannot be cancelled"".format(self._status.value)\n            )\n        self._connection.cancel_job(self.id)\n\n    def __repr__(self):\n        return ""<{}: id={}, status={}>"".format(self.__class__.__name__, self.id, self._status.value)\n\n    def __str__(self):\n        return self.__repr__()\n'"
strawberryfields/api/result.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThis module provides a class that represents the result of a quantum computation.\n""""""\nimport numpy as np\n\n\nclass Result:\n    """"""Result of a quantum computation.\n\n    Represents the results of the execution of a quantum program on a local or\n    remote backend.\n\n    The returned :class:`~Result` object provides several useful properties\n    for accessing the results of your program execution:\n\n    * ``results.state``: The quantum state object contains details and methods\n      for manipulation of the final circuit state. Not available for remote\n      backends. See :doc:`/introduction/states` for more information regarding available\n      state methods.\n\n    * ``results.samples``: Measurement samples from any measurements performed.\n\n    **Example:**\n\n    The following example runs an existing Strawberry Fields\n    quantum :class:`~.Program` on the Gaussian backend to get\n    a ``Result`` object.\n\n    Using this ``Result`` object, the measurement samples\n    can be returned, as well as quantum state information.\n\n    >>> eng = sf.Engine(""gaussian"")\n    >>> results = eng.run(prog)\n    >>> print(results)\n    Result: 3 subsystems\n        state: <GaussianState: num_modes=3, pure=True, hbar=2>\n        samples: [[0, 0, 0]]\n    >>> results.samples\n    np.array([[0, 0, 0]])\n    >>> results.state.is_pure()\n    True\n\n    .. note::\n\n        Only local simulators will return a state object. Remote\n        simulators and hardware backends will return\n        measurement samples  (:attr:`Result.samples`),\n        but the return value of ``Result.state`` will be ``None``.\n    """"""\n\n    def __init__(self, samples, is_stateful=True):\n        self._state = None\n        self._is_stateful = is_stateful\n\n        # samples arrives as either a 2-D array (for shots > 1) or a 1-D array (for shots = 1)\n        # the latter needs to be converted to a 2-D array with shape (shots, modes)\n        if np.ndim(samples) == 1:\n            samples = np.array([samples])\n        self._samples = samples\n\n    @property\n    def samples(self):\n        """"""Measurement samples.\n\n        Returned measurement samples will have shape ``(shots, modes)``.\n\n        Returns:\n            array[array[float, int]]: measurement samples returned from\n            program execution\n        """"""\n        return self._samples\n\n    @property\n    def state(self):\n        """"""The quantum state object.\n\n        The quantum state object contains details and methods\n        for manipulation of the final circuit state.\n\n        See :doc:`/introduction/states` for more information regarding available\n        state methods.\n\n        .. note::\n\n            Only local simulators will return a state object. Remote\n            simulators and hardware backends will return\n            measurement samples (:attr:`Result.samples`),\n            but the return value of ``Result.state`` will be ``None``.\n\n        Returns:\n            BaseState: quantum state returned from program execution\n        """"""\n        if not self._is_stateful:\n            raise AttributeError(""The state is undefined for a stateless computation."")\n        return self._state\n\n    def __repr__(self):\n        """"""String representation.""""""\n        shots, modes = self.samples.shape\n        return ""<Result: num_modes={}, shots={}, contains state={}>"".format(\n            modes, shots, self._is_stateful\n        )\n'"
strawberryfields/apps/__init__.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""This package contains the modules that make up the\nStrawberry Fields application layer.\n\n.. currentmodule:: strawberryfields.apps\n.. autosummary::\n    :toctree: api\n\n\tclique\n\tdata\n\tplot\n\tpoints\n\tsample\n\tsimilarity\n\tsubgraph\n\ttrain\n\tvibronic\n""""""\n\nimport strawberryfields.apps.clique\nimport strawberryfields.apps.data\nimport strawberryfields.apps.plot\nimport strawberryfields.apps.points\nimport strawberryfields.apps.sample\nimport strawberryfields.apps.similarity\nimport strawberryfields.apps.subgraph\nimport strawberryfields.apps.train\nimport strawberryfields.apps.vibronic\n'"
strawberryfields/apps/clique.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\r\n\r\n# Licensed under the Apache License, Version 2.0 (the ""License"");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an ""AS IS"" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\nr""""""\r\nTools for users to identify large cliques in graphs.\r\n\r\nA clique is a subgraph where all nodes are connected to each other. The maximum clique problem is\r\nto identify the largest clique in a graph. It has been shown that samples from GBS can be used to\r\nselect dense subgraphs as a starting seed for heuristic algorithms :cite:`banchi2019molecular`.\r\n\r\n.. seealso::\r\n\r\n    :ref:`apps-clique-tutorial`\r\n\r\nAlgorithm\r\n^^^^^^^^^\r\n\r\nThis module provides :func:`search`, a variant of the local search heuristics described in\r\n:cite:`pullan2006dynamic` and :cite:`pullan2006phased`. The algorithm proceeds as follows:\r\n\r\n#. A small clique in the graph is identified. The initial clique can be a single node, or it can\r\n   be obtained by shrinking a random subgraph, for example obtained from GBS.\r\n#. The clique is grown as much as possible by adding nodes connected to all nodes in the clique.\r\n#. When no more growth is possible, a node in the clique is swapped with a node outside of it.\r\n\r\nSteps 2-3 are repeated until a pre-determined number of steps have been completed, or until no\r\nmore growth or swaps are possible.\r\n\r\nClique growth and swapping\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nA clique can be grown by evaluating the set :math:`C_0` of nodes in the remainder of the graph that\r\nare connected to all nodes in the clique. A single node from :math:`C_0` is selected and added to\r\nthe clique. This process is repeated until :math:`C_0` becomes empty. This is provided with the\r\n:func:`grow` function.\r\n\r\nSearching the local space around a clique can be achieved by swapping a node from the clique with a\r\nnode in the remainder of the graph. The first step is to evaluate the set :math:`C_1` of nodes in\r\nthe remainder of the graph that are connected to *all but one* of the nodes in the current\r\nclique. A swap is then performed by adding the node into the clique and removing the node in the\r\nclique that is not connected to it. This is provided with the :func:`swap` function.\r\n\r\nWhenever the sets :math:`C_0` and :math:`C_1` used during growth and swapping have more than\r\none element, there must be a choice of which node to add or swap. The supported choices are:\r\n\r\n- Select among candidate nodes uniformly at random;\r\n- Select the candidate node with the greatest degree, settling remaining ties uniformly at random;\r\n- Select the candidate node with the greatest node weight, settling remaining ties uniformly at\r\n  random.\r\n\r\nUsing GBS to find a starting clique\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nSamples from GBS correspond to subgraphs that are likely to be dense.\r\nThese subgraphs may not be cliques, which is the required input to the :func:`search` algorithm.\r\nTo reconcile this, a subgraph may be shrunk using the :func:`shrink` function by removing nodes\r\nuntil the remainder forms a clique. This can be achieved by selecting the node with the lowest\r\ndegree relative to the rest of subgraph and removing the node, repeating the process until a\r\nclique is found.\r\n""""""\r\nfrom typing import Union\r\n\r\nimport networkx as nx\r\nimport numpy as np\r\n\r\n\r\ndef search(\r\n    clique: list, graph: nx.Graph, iterations, node_select: Union[str, np.ndarray, list] = ""uniform""\r\n) -> list:\r\n    """"""Local search algorithm for identifying large cliques.\r\n\r\n    This function implements a version of the local search algorithm given in\r\n    :cite:`pullan2006dynamic` and :cite:`pullan2006phased`. It proceeds by iteratively applying\r\n    phases of greedy growth and plateau search to the input clique subgraph.\r\n\r\n    **Growth phase**\r\n\r\n    Growth is achieved using the :func:`~.grow` function, which repeatedly evaluates the\r\n    set :math:`C_0` of nodes in the remainder of the graph that are connected to all nodes in the\r\n    clique, and selects one candidate node from :math:`C_0` to make a larger clique.\r\n\r\n    **Search phase**\r\n\r\n    Plateau search is performed with the :func:`~.swap` function, which evaluates the set\r\n    :math:`C_1` of nodes in the remainder of the graph that are connected to all but one of the\r\n    nodes in the clique. The function then proceeds to select one candidate from :math:`C_1` and\r\n    swap it with its corresponding node in the clique.\r\n\r\n    Whenever the sets :math:`C_0` and :math:`C_1` used during growth and swapping have more than\r\n    one element, there must be a choice of which node to add or swap. This choice is specified\r\n    with the ``node_select`` argument, which can be any of the following:\r\n\r\n    - ``""uniform""`` (default): choose a node from the candidates uniformly at random;\r\n    - ``""degree""``: choose the node from the candidates with the greatest degree, settling ties\r\n      by uniform random choice;\r\n    - A list or array: specifying the node weights of the graph, resulting in choosing the node\r\n      from the candidates with the greatest weight, settling ties by uniform random choice.\r\n\r\n    **Stopping**\r\n\r\n    The iterative applications of growth and search are applied until either the specified number\r\n    of iterations has been carried out or when a dead end has been reached. The function reaches\r\n    a dead end when it is unable to perform any new swaps or growth.\r\n\r\n    **Example usage:**\r\n\r\n    >>> graph = nx.lollipop_graph(4, 1)\r\n    >>> graph.add_edge(2, 4)\r\n    >>> clique = [3, 4]\r\n    >>> search(clique, graph, iterations=10)\r\n    [0, 1, 2, 3]\r\n\r\n    Args:\r\n        clique (list[int]): a subgraph specified by a list of nodes; the subgraph must be a clique\r\n        graph (nx.Graph): the input graph\r\n        iterations (int): number of steps in the algorithm\r\n        node_select (str, list or array): method of selecting nodes during swap and growth. Can\r\n            be ``""uniform""`` (default), ``""degree""``, or a NumPy array or list.\r\n\r\n    Returns:\r\n       list[int]: the largest clique found by the algorithm\r\n    """"""\r\n    if iterations < 1:\r\n        raise ValueError(""Number of iterations must be a positive int"")\r\n\r\n    grown = grow(clique, graph, node_select=node_select)\r\n    swapped = swap(grown, graph, node_select=node_select)\r\n\r\n    iterations -= 1\r\n\r\n    if set(grown) == set(swapped) or iterations == 0:\r\n        return swapped\r\n\r\n    return search(swapped, graph, iterations, node_select)\r\n\r\n\r\ndef grow(\r\n    clique: list, graph: nx.Graph, node_select: Union[str, np.ndarray, list] = ""uniform""\r\n) -> list:\r\n    """"""Iteratively adds new nodes to the input clique to generate a larger clique.\r\n\r\n    Each iteration involves calculating the set :math:`C_0` (provided by the function\r\n    :func:`c_0`) with respect to the current clique. This set represents the nodes in the rest of\r\n    the graph that are connected to all of the nodes in the current clique. Therefore, adding any of\r\n    the nodes in :math:`C_0` will create a larger clique. This function proceeds by repeatedly\r\n    evaluating :math:`C_0` and selecting and adding a node from this set to add to the current\r\n    clique. Growth is continued until :math:`C_0` becomes empty.\r\n\r\n    Whenever there are multiple nodes within :math:`C_0`, one must choose which node to add to\r\n    the growing clique. This function allows a method of choosing nodes to be set with the\r\n    ``node_select`` argument, which can be any of the following:\r\n\r\n    - ``""uniform""`` (default): choose a node from the candidates uniformly at random;\r\n    - ``""degree""``: choose the node from the candidates with the greatest degree, settling ties\r\n      by uniform random choice;\r\n    - A list or array: specifying the node weights of the graph, resulting in choosing the node\r\n      from the candidates with the greatest weight, settling ties by uniform random choice.\r\n\r\n    **Example usage:**\r\n\r\n    >>> graph = nx.complete_graph(10)\r\n    >>> clique = [0, 1, 2, 3, 4]\r\n    >>> grow(clique, graph)\r\n    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\r\n\r\n    Args:\r\n        clique (list[int]): a subgraph specified by a list of nodes; the subgraph must be a clique\r\n        graph (nx.Graph): the input graph\r\n        node_select (str, list or array): method of selecting nodes from :math:`C_0` during\r\n            growth. Can be ``""uniform""`` (default), ``""degree""``, or a NumPy array or list.\r\n\r\n    Returns:\r\n        list[int]: a new clique subgraph of equal or larger size than the input\r\n    """"""\r\n\r\n    if not set(clique).issubset(graph.nodes):\r\n        raise ValueError(""Input is not a valid subgraph"")\r\n\r\n    if not is_clique(graph.subgraph(clique)):\r\n        raise ValueError(""Input subgraph is not a clique"")\r\n\r\n    if isinstance(node_select, (list, np.ndarray)):\r\n        if len(node_select) != graph.number_of_nodes():\r\n            raise ValueError(""Number of node weights must match number of nodes"")\r\n        w = {n: node_select[i] for i, n in enumerate(graph.nodes)}\r\n        node_select = ""weight""\r\n\r\n    clique = set(clique)\r\n    _c_0 = sorted(c_0(clique, graph))\r\n\r\n    while _c_0:\r\n        if node_select == ""uniform"":\r\n            clique.add(np.random.choice(_c_0))\r\n        elif node_select == ""degree"":\r\n            degrees = np.array([graph.degree(n) for n in _c_0])\r\n            to_add_index = np.random.choice(np.where(degrees == degrees.max())[0])\r\n            to_add = _c_0[to_add_index]\r\n            clique.add(to_add)\r\n        elif node_select == ""weight"":\r\n            weights = np.array([w[n] for n in _c_0])\r\n            to_add_index = np.random.choice(np.where(weights == weights.max())[0])\r\n            to_add = _c_0[to_add_index]\r\n            clique.add(to_add)\r\n        else:\r\n            raise ValueError(""Node selection method not recognized"")\r\n\r\n        _c_0 = sorted(c_0(clique, graph))\r\n\r\n    return sorted(clique)\r\n\r\n\r\ndef swap(\r\n    clique: list, graph: nx.Graph, node_select: Union[str, np.ndarray, list] = ""uniform""\r\n) -> list:\r\n    """"""If possible, generates a new clique by swapping a node in the input clique with a node\r\n    outside the clique.\r\n\r\n    Proceeds by calculating the set :math:`C_1` of nodes in the rest of the graph that are\r\n    connected to all but one of the nodes in the clique. If this set is not empty, this function\r\n    randomly picks a node and swaps it with the corresponding node in the clique that is not\r\n    connected to it. The set :math:`C_1` and corresponding nodes in the clique are provided by the\r\n    :func:`c_1` function.\r\n\r\n    Whenever there are multiple nodes within :math:`C_1`, one must choose which node to add to\r\n    the growing clique. This function allows a method of choosing nodes to be set with the\r\n    ``node_select`` argument, which can be any of the following:\r\n\r\n    - ``""uniform""`` (default): choose a node from the candidates uniformly at random;\r\n    - ``""degree""``: choose the node from the candidates with the greatest degree, settling ties\r\n      by uniform random choice;\r\n    - A list or array: specifying the node weights of the graph, resulting in choosing the node\r\n      from the candidates with the greatest weight, settling ties by uniform random choice.\r\n\r\n    **Example usage:**\r\n\r\n    >>> graph = nx.wheel_graph(5)\r\n    >>> graph.remove_edge(0, 4)\r\n    >>> clique = [0, 1, 2]\r\n    >>> swap(clique, graph)\r\n    [0, 2, 3]\r\n\r\n    Args:\r\n        clique (list[int]): a subgraph specified by a list of nodes; the subgraph must be a clique\r\n        graph (nx.Graph): the input graph\r\n        node_select (str, list or array): method of selecting incoming nodes from :math:`C_1`\r\n            during swapping. Can be ``""uniform""`` (default), ``""degree""``, or a NumPy array or list.\r\n\r\n    Returns:\r\n        list[int]: a new clique subgraph of equal size as the input\r\n    """"""\r\n\r\n    if not set(clique).issubset(graph.nodes):\r\n        raise ValueError(""Input is not a valid subgraph"")\r\n\r\n    if not is_clique(graph.subgraph(clique)):\r\n        raise ValueError(""Input subgraph is not a clique"")\r\n\r\n    if isinstance(node_select, (list, np.ndarray)):\r\n        if len(node_select) != graph.number_of_nodes():\r\n            raise ValueError(""Number of node weights must match number of nodes"")\r\n        w = {n: node_select[i] for i, n in enumerate(graph.nodes)}\r\n        node_select = ""weight""\r\n\r\n    clique = set(clique)\r\n    _c_1 = c_1(clique, graph)\r\n\r\n    if _c_1:\r\n        if node_select == ""uniform"":\r\n            swap_index = np.random.choice(len(_c_1))\r\n            swap_nodes = _c_1[swap_index]\r\n        elif node_select == ""degree"":\r\n            degrees = np.array([graph.degree(n[1]) for n in _c_1])\r\n            to_swap_index = np.random.choice(np.where(degrees == degrees.max())[0])\r\n            swap_nodes = _c_1[to_swap_index]\r\n        elif node_select == ""weight"":\r\n            weights = np.array([w[n[1]] for n in _c_1])\r\n            to_swap_index = np.random.choice(np.where(weights == weights.max())[0])\r\n            swap_nodes = _c_1[to_swap_index]\r\n        else:\r\n            raise ValueError(""Node selection method not recognized"")\r\n\r\n        clique.remove(swap_nodes[0])\r\n        clique.add(swap_nodes[1])\r\n\r\n    return sorted(clique)\r\n\r\n\r\ndef shrink(\r\n    subgraph: list, graph: nx.Graph, node_select: Union[str, np.ndarray, list] = ""uniform""\r\n) -> list:\r\n    """"""Shrinks an input subgraph until it forms a clique.\r\n\r\n    Proceeds by removing nodes in the input subgraph one at a time until the result is a clique\r\n    that satisfies :func:`is_clique`. Upon each iteration, this function selects the node with\r\n    lowest degree relative to the subgraph and removes it.\r\n\r\n    In some instances, there may be multiple nodes of minimum degree as candidates to remove from\r\n    the subgraph. The method of selecting which of these nodes to remove is specified by the\r\n    ``node_select`` argument, which can be either:\r\n\r\n    - ``""uniform""`` (default): choose a node from the candidates uniformly at random;\r\n    - A list or array: specifying the node weights of the graph, resulting in choosing the node\r\n      from the candidates with the lowest weight, settling ties by uniform random choice.\r\n\r\n    **Example usage:**\r\n\r\n    >>> graph = nx.barbell_graph(4, 0)\r\n    >>> subgraph = [0, 1, 2, 3, 4, 5]\r\n    >>> shrink(subgraph, graph)\r\n    [0, 1, 2, 3]\r\n\r\n    Args:\r\n        subgraph (list[int]): a subgraph specified by a list of nodes\r\n        graph (nx.Graph): the input graph\r\n        node_select (str, list or array): method of settling ties when more than one node of\r\n            equal degree can be removed. Can be ``""uniform""`` (default), or a NumPy array or list.\r\n\r\n    Returns:\r\n        list[int]: a clique of size smaller than or equal to the input subgraph\r\n    """"""\r\n\r\n    if not set(subgraph).issubset(graph.nodes):\r\n        raise ValueError(""Input is not a valid subgraph"")\r\n\r\n    if isinstance(node_select, (list, np.ndarray)):\r\n        if len(node_select) != graph.number_of_nodes():\r\n            raise ValueError(""Number of node weights must match number of nodes"")\r\n        w = {n: node_select[i] for i, n in enumerate(graph.nodes)}\r\n        node_select = ""weight""\r\n\r\n    subgraph = graph.subgraph(subgraph).copy()  # A copy is required to be able to modify the\r\n    # structure of the subgraph (https://networkx.github.io/documentation/stable/reference/classes/generated/networkx.Graph.subgraph.html)\r\n\r\n    while not is_clique(subgraph):\r\n        degrees = np.array(subgraph.degree)\r\n        degrees_min = np.argwhere(degrees[:, 1] == degrees[:, 1].min()).flatten()\r\n\r\n        if node_select == ""uniform"":\r\n            to_remove_index = np.random.choice(degrees_min)\r\n        elif node_select == ""weight"":\r\n            weights = np.array([w[degrees[n][0]] for n in degrees_min])\r\n            to_remove_index = np.random.choice(np.where(weights == weights.min())[0])\r\n        else:\r\n            raise ValueError(""Node selection method not recognized"")\r\n\r\n        to_remove = degrees[to_remove_index][0]\r\n        subgraph.remove_node(to_remove)\r\n\r\n    return sorted(subgraph.nodes())\r\n\r\n\r\ndef is_clique(graph: nx.Graph) -> bool:\r\n    """"""Determines if the input graph is a clique. A clique of :math:`n` nodes has exactly :math:`n(\r\n    n-1)/2` edges.\r\n\r\n    **Example usage:**\r\n\r\n    >>> graph = nx.complete_graph(10)\r\n    >>> is_clique(graph)\r\n    True\r\n\r\n    Args:\r\n        graph (nx.Graph): the input graph\r\n\r\n    Returns:\r\n        bool: ``True`` if input graph is a clique and ``False`` otherwise\r\n    """"""\r\n    edges = graph.edges\r\n    nodes = graph.order()\r\n\r\n    return len(edges) == nodes * (nodes - 1) / 2\r\n\r\n\r\ndef c_0(clique: list, graph: nx.Graph):\r\n    """"""Generates the set :math:`C_0` of nodes that are connected to all nodes in the input\r\n    clique subgraph.\r\n\r\n    The set :math:`C_0` is defined in :cite:`pullan2006phased` and is used to determine nodes\r\n    that can be added to the current clique to grow it into a larger one.\r\n\r\n    **Example usage:**\r\n\r\n    >>> graph = nx.complete_graph(10)\r\n    >>> clique = [0, 1, 2, 3, 4]\r\n    >>> c_0(clique, graph)\r\n    [5, 6, 7, 8, 9]\r\n\r\n    Args:\r\n        clique (list[int]): a subgraph specified by a list of nodes; the subgraph must be a clique\r\n        graph (nx.Graph): the input graph\r\n\r\n    Returns:\r\n        list[int]: a list containing the :math:`C_0` nodes for the clique\r\n\r\n    """"""\r\n    if not is_clique(graph.subgraph(clique)):\r\n        raise ValueError(""Input subgraph is not a clique"")\r\n\r\n    clique = set(clique)\r\n    c_0_nodes = []\r\n    non_clique_nodes = set(graph.nodes) - clique\r\n\r\n    for i in non_clique_nodes:\r\n        if clique.issubset(graph.neighbors(i)):\r\n            c_0_nodes.append(i)\r\n\r\n    return c_0_nodes\r\n\r\n\r\ndef c_1(clique: list, graph: nx.Graph):\r\n    """"""Generates the set :math:`C_1` of nodes that are connected to all but one of the nodes in\r\n    the input clique subgraph.\r\n\r\n    The set :math:`C_1` is defined in :cite:`pullan2006phased` and is used to determine outside\r\n    nodes that can be swapped with clique nodes to create a new clique.\r\n\r\n    **Example usage:**\r\n\r\n    >>> graph = nx.wheel_graph(5)\r\n    >>> clique = [0, 1, 2]\r\n    >>> c_1(clique, graph)\r\n    [(1, 3), (2, 4)]\r\n\r\n    Args:\r\n        clique (list[int]): a subgraph specified by a list of nodes; the subgraph must be a clique\r\n        graph (nx.Graph): the input graph\r\n\r\n    Returns:\r\n       list[tuple[int]]: A list of tuples. The first node in the tuple is the node in the clique\r\n       and the second node is the outside node it can be swapped with.\r\n   """"""\r\n    if not is_clique(graph.subgraph(clique)):\r\n        raise ValueError(""Input subgraph is not a clique"")\r\n\r\n    clique = set(clique)\r\n    c_1_nodes = []\r\n    non_clique_nodes = set(graph.nodes) - clique\r\n\r\n    for i in non_clique_nodes:\r\n        neighbors_in_subgraph = clique.intersection(graph.neighbors(i))\r\n\r\n        if len(neighbors_in_subgraph) == len(clique) - 1:\r\n            to_swap = clique - neighbors_in_subgraph\r\n            (i_clique,) = to_swap\r\n            c_1_nodes.append((i_clique, i))\r\n\r\n    return c_1_nodes\r\n'"
strawberryfields/apps/data.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\r\n\r\n# Licensed under the Apache License, Version 2.0 (the ""License"");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an ""AS IS"" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\nr""""""\r\nPre-calculated datasets of simulated GBS samples.\r\n\r\n.. seealso::\r\n\r\n    :doc:`/introduction/data`\r\n""""""\r\n# pylint: disable=unnecessary-pass\r\nfrom abc import ABC, abstractmethod\r\n\r\nimport pkg_resources\r\nimport numpy as np\r\nimport scipy\r\n\r\nDATA_PATH = pkg_resources.resource_filename(""strawberryfields"", ""apps/data"") + ""/""\r\n\r\n\r\nclass Dataset(ABC):\r\n    """"""Base class for loading datasets of pre-generated samples.\r\n\r\n    Attributes:\r\n        n_mean (float): mean number of photons in the GBS device\r\n        threshold (bool): flag to indicate whether samples are generated with threshold detection\r\n            (i.e., detectors of zero or some photons) or with photon-number-resolving detectors.\r\n        n_samples (int): total number of samples in the dataset\r\n        modes (int): number of modes in the GBS device or, equivalently, number of nodes in graph\r\n        data (sparse): raw data of samples from GBS as a `csr sparse array\r\n            <https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html>`__.\r\n    """"""\r\n\r\n    _count = 0\r\n\r\n    @property\r\n    @abstractmethod\r\n    def _data_filename(self) -> str:\r\n        """"""Base name of files containing the sample data stored in the ``./data/`` directory.\r\n\r\n        Samples and corresponding adjacency matrix should both be provided as a\r\n        ``scipy.sparse.csr_matrix`` saved in ``.npz`` format.\r\n\r\n        For ``_data_filename = ""example""``, the corresponding samples should be stored as\r\n        ``./data/example.npz`` and the adjacency matrix as ``./data/example_A.npz``.""""""\r\n        pass\r\n\r\n    def __init__(self):\r\n        self.data = scipy.sparse.load_npz(DATA_PATH + self._data_filename + "".npz"")\r\n        self.n_samples, self.modes = self.data.shape\r\n\r\n    def __iter__(self):\r\n        return self\r\n\r\n    def __next__(self):\r\n        if self._count < self.n_samples:\r\n            self._count += 1\r\n            return self.__getitem__(self._count - 1)\r\n        self._count = 0\r\n        raise StopIteration\r\n\r\n    def _elem(self, i):\r\n        """"""Access the i-th element of the sparse array and output as a list.""""""\r\n        return list(self.data[i].toarray()[0])\r\n\r\n    def __getitem__(self, key):\r\n\r\n        if not isinstance(key, (slice, tuple, int)):\r\n            raise TypeError(""Dataset indices must be integers, slices, or tuples"")\r\n\r\n        if isinstance(key, int):\r\n            return self._elem(key + self.n_samples if key < 0 else key)\r\n\r\n        if isinstance(key, tuple):\r\n            key = slice(*key)\r\n\r\n        range_tuple = key.indices(self.n_samples)\r\n        return [self._elem(i) for i in range(*range_tuple)]\r\n\r\n    def __len__(self):\r\n        return self.n_samples\r\n\r\n    def counts(self, axis: int = 1) -> list:\r\n        """"""Count number of photons or clicks.\r\n\r\n        Counts number of photons/clicks in each sample (``axis==1``) or number of photons/clicks\r\n        in each mode compounded over all samples (``axis==0``).\r\n\r\n        Args:\r\n            axis (int): axis to perform count\r\n\r\n        Returns:\r\n            list: counts from samples\r\n        """"""\r\n        return np.array(self.data.sum(axis)).flatten().tolist()\r\n\r\n    # pylint: disable=missing-docstring\r\n    @property\r\n    @abstractmethod\r\n    def n_mean(self) -> float:\r\n        pass\r\n\r\n    # pylint: disable=missing-docstring\r\n    @property\r\n    @abstractmethod\r\n    def threshold(self) -> bool:\r\n        pass\r\n\r\n\r\n# pylint: disable=abstract-method\r\nclass GraphDataset(Dataset, ABC):\r\n    """"""Class for loading datasets of pre-generated samples from graphs.\r\n\r\n    Attributes:\r\n        adj (array): adjacency matrix of the graph from which samples were generated\r\n    """"""\r\n\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.adj = scipy.sparse.load_npz(DATA_PATH + self._data_filename + ""_A.npz"").toarray()\r\n\r\n\r\nclass Planted(GraphDataset):\r\n    """"""A random 30-node graph containing a dense 10-node subgraph planted inside\r\n    :cite:`arrazola2018using`.\r\n\r\n    The graph is generated by joining two Erd\xc5\x91s\xe2\x80\x93R\xc3\xa9nyi random graphs. The first 20-node graph is\r\n    generated with edge probability of 0.5 and the second 10-node planted graph is generated with\r\n    edge probability of 0.875. The two graphs are joined by selecting 8 vertices at random from\r\n    both and adding an edge between them.\r\n\r\n    The 10-node planted clique is contained within the final 10 nodes of the graph.\r\n\r\n    **Graph:**\r\n\r\n    .. |planted| image:: ../../_static/graphs/planted.png\r\n        :align: middle\r\n        :width: 250px\r\n        :target: javascript:void(0);\r\n\r\n    |planted|\r\n\r\n    Attributes:\r\n        n_mean = 8\r\n        threshold = True\r\n        n_samples = 50000\r\n        modes = 30\r\n    """"""\r\n\r\n    _data_filename = ""planted""\r\n    n_mean = 8\r\n    threshold = True\r\n\r\n\r\nclass TaceAs(GraphDataset):\r\n    """"""Binding interaction graph for the TACE-AS complex :cite:`banchi2019molecular`.\r\n\r\n    Nodes in this graph correspond to pairs of atoms in a target protein and a pharmaceutical\r\n    molecule. Edges in the graph are added if the distance between both pairs of atoms is very\r\n    close to equal. Cliques in the graph correspond to possible docking configurations of protein\r\n    and molecule, and the largest clique is the most stable configuration. There are multiple\r\n    maximum-sized cliques of 8 nodes in this graph.\r\n\r\n    **Graph:**\r\n\r\n    .. |tace_as| image:: ../../_static/graphs/TACE-AS.png\r\n        :align: middle\r\n        :width: 250px\r\n        :target: javascript:void(0);\r\n\r\n    |tace_as|\r\n\r\n    Attributes:\r\n        n_mean = 8\r\n        threshold = True\r\n        n_samples = 50000\r\n        modes = 24\r\n    """"""\r\n\r\n    _data_filename = ""TACE-AS""\r\n    n_mean = 8\r\n    threshold = True\r\n\r\n\r\nclass PHat(GraphDataset):\r\n    """"""Random graph created using the p-hat generator of :cite:`gendreau1993solving`.\r\n\r\n    This graph is the ``p_hat300-1`` graph of the `DIMACS\r\n    <http://iridia.ulb.ac.be/~fmascia/maximum_clique/DIMACS-benchmark>`__ dataset, which is a\r\n    collection of large graphs with cliques that are hard to find. The best known clique of\r\n    this 300-node graph is of size 8 and is composed of nodes: ``[53, 123, 180, 218, 246, 267, 270,\r\n    286]``. This graph is not visualized due to its large size.\r\n\r\n    Attributes:\r\n        n_mean = 10\r\n        threshold = True\r\n        n_samples = 50000\r\n        modes = 300\r\n    """"""\r\n\r\n    _data_filename = ""p_hat300-1""\r\n    n_mean = 10\r\n    threshold = True\r\n\r\n\r\nclass Mutag0(GraphDataset):\r\n    """"""First graph of the MUTAG dataset.\r\n\r\n    The MUTAG dataset is from :cite:`debnath1991structure,kriege2012subgraph` and is available\r\n    `here <https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets>`__.\r\n\r\n    **Graph:**\r\n\r\n    .. |mutag_0| image:: ../../_static/graphs/MUTAG_0.png\r\n        :align: middle\r\n        :width: 250px\r\n        :target: javascript:void(0);\r\n\r\n    |mutag_0|\r\n\r\n    Attributes:\r\n        n_mean = 6\r\n        threshold = False\r\n        n_samples = 20000\r\n        modes = 17\r\n    """"""\r\n\r\n    _data_filename = ""MUTAG_0""\r\n    n_mean = 6\r\n    threshold = False\r\n\r\n\r\nclass Mutag1(GraphDataset):\r\n    """"""Second graph of the MUTAG dataset.\r\n\r\n    The MUTAG dataset is from :cite:`debnath1991structure,kriege2012subgraph` and is available\r\n    `here <https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets>`__.\r\n\r\n    **Graph:**\r\n\r\n    .. |mutag_1| image:: ../../_static/graphs/MUTAG_1.png\r\n        :align: middle\r\n        :width: 250px\r\n        :target: javascript:void(0);\r\n\r\n    |mutag_1|\r\n\r\n    Attributes:\r\n        n_mean = 6\r\n        threshold = False\r\n        n_samples = 20000\r\n        modes = 13\r\n    """"""\r\n\r\n    _data_filename = ""MUTAG_1""\r\n    n_mean = 6\r\n    threshold = False\r\n\r\n\r\nclass Mutag2(GraphDataset):\r\n    """"""Third graph of the MUTAG dataset.\r\n\r\n    The MUTAG dataset is from :cite:`debnath1991structure,kriege2012subgraph` and is available\r\n    `here <https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets>`__.\r\n\r\n    **Graph:**\r\n\r\n    .. |mutag_2| image:: ../../_static/graphs/MUTAG_2.png\r\n        :align: middle\r\n        :width: 250px\r\n        :target: javascript:void(0);\r\n\r\n    |mutag_2|\r\n\r\n    Attributes:\r\n        n_mean = 6\r\n        threshold = False\r\n        n_samples = 20000\r\n        modes = 13\r\n    """"""\r\n\r\n    _data_filename = ""MUTAG_2""\r\n    n_mean = 6\r\n    threshold = False\r\n\r\n\r\nclass Mutag3(GraphDataset):\r\n    """"""Fourth graph of the MUTAG dataset.\r\n\r\n    The MUTAG dataset is from :cite:`debnath1991structure,kriege2012subgraph` and is available\r\n    `here <https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets>`__.\r\n\r\n    **Graph:**\r\n\r\n    .. |mutag_3| image:: ../../_static/graphs/MUTAG_3.png\r\n        :align: middle\r\n        :width: 250px\r\n        :target: javascript:void(0);\r\n\r\n    |mutag_3|\r\n\r\n    Attributes:\r\n        n_mean = 6\r\n        threshold = False\r\n        n_samples = 20000\r\n        modes = 19\r\n    """"""\r\n\r\n    _data_filename = ""MUTAG_3""\r\n    n_mean = 6\r\n    threshold = False\r\n\r\n\r\n# pylint: disable=abstract-method\r\nclass MoleculeDataset(Dataset, ABC):\r\n    r""""""Class for loading datasets of pre-generated samples from molecules.\r\n\r\n    Attributes:\r\n        w (array): normal mode frequencies of the electronic ground state (:math:`\\mbox{cm}^{-1}`)\r\n        wp (array): normal mode frequencies of the electronic excited state (:math:`\\mbox{cm}^{-1}`)\r\n        Ud (array): Duschinsky matrix\r\n        delta (array): Displacement vector, with entries :math:`\\delta_i=\\sqrt{\\omega\'_i/\\hbar}d_i`,\r\n           and :math:`d_i` is the Duschinsky displacement\r\n        T (float): temperature (Kelvin)\r\n    """"""\r\n\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.w = scipy.sparse.load_npz(DATA_PATH + self._data_filename + ""_w.npz"").toarray()[0]\r\n        self.wp = scipy.sparse.load_npz(DATA_PATH + self._data_filename + ""_wp.npz"").toarray()[0]\r\n        self.Ud = scipy.sparse.load_npz(DATA_PATH + self._data_filename + ""_Ud.npz"").toarray()\r\n        self.delta = scipy.sparse.load_npz(\r\n            DATA_PATH + self._data_filename + ""_delta.npz""\r\n        ).toarray()[0]\r\n\r\n    # pylint: disable=missing-docstring\r\n    @property\r\n    @abstractmethod\r\n    def T(self) -> bool:\r\n        pass\r\n\r\n\r\nclass Formic(MoleculeDataset):\r\n    """"""Zero temperature formic acid.\r\n\r\n    The molecular parameters are obtained from Ref. :cite:`huh2015boson`.\r\n\r\n    **Molecule:**\r\n\r\n    .. |formic| image:: ../../_static/formic.png\r\n        :align: middle\r\n        :width: 250px\r\n        :target: javascript:void(0);\r\n\r\n    |formic|\r\n\r\n    Attributes:\r\n        n_mean = 1.56\r\n        threshold = False\r\n        n_samples = 20000\r\n        modes = 14\r\n        T = 0\r\n    """"""\r\n\r\n    _data_filename = ""formic""\r\n    n_mean = 1.56\r\n    threshold = False\r\n    T = 0\r\n'"
strawberryfields/apps/plot.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nTools for visualizing graphs, subgraphs, point processes, and vibronic spectra.\n\nVisualization requires installation of the Plotly library, which is not a dependency of\nStrawberry Fields. Plotly can be installed using ``pip install plotly`` or by visiting their\n`installation instructions <https://plot.ly/python/getting-started/#installation>`__.\n""""""\n# pylint: disable=import-outside-toplevel\nfrom typing import Optional, Tuple\n\nimport networkx as nx\nimport numpy as np\n\n\ndef _node_coords(g: nx.Graph, l: dict) -> Tuple:\n    """"""Converts coordinates for the graph nodes for plotting purposes.\n\n    Args:\n        g (nx.Graph): input graph\n        l (dict[int, float]): Dictionary of nodes and their respective coordinates. Can be\n            generated using a NetworkX `layout <https://networkx.github.io/documentation/latest/\n            reference/drawing.html#module-networkx.drawing.layout>`__\n\n    Returns:\n         dict[str, list]: lists of x and y coordinates accessed as keys of a dictionary\n    """"""\n    n_x = []\n    n_y = []\n\n    for n in g.nodes():\n        n_x.append(l[n][0])\n        n_y.append(l[n][1])\n\n    return {""x"": n_x, ""y"": n_y}\n\n\ndef _edge_coords(g: nx.Graph, l: dict) -> dict:\n    """"""Converts coordinates for the graph edges for plotting purposes.\n\n        Args:\n            g (nx.Graph): input graph\n            l (dict[int, float]): Dictionary of nodes and their respective coordinates. Can be\n                generated using a NetworkX `layout <https://networkx.github.io/documentation/latest/\n                reference/drawing.html#module-networkx.drawing.layout>`__\n\n        Returns:\n             dict[str, list]: lists of x and y coordinates for the beginning and end of each edge.\n             ``None`` is placed as a separator between pairs of nodes/edges.\n        """"""\n    e_x = []\n    e_y = []\n\n    for e in g.edges():\n\n        start_x, start_y = l[e[0]]\n        end_x, end_y = l[e[1]]\n\n        e_x.append(start_x)\n        e_x.append(end_x)\n\n        e_y.append(start_y)\n        e_y.append(end_y)\n\n        e_x.append(None)\n        e_y.append(None)\n\n    return {""x"": e_x, ""y"": e_y}\n\n\nplotly_error = (\n    ""Plotly required for using this function. It can be installed using pip install ""\n    ""plotly or visiting https://plot.ly/python/getting-started/#installation""\n)\n\nGREEN = ""#3e9651""\nRED = ""#cc2529""\nGREY = ""#737373""\nLIGHT_GREY = ""#CDCDCD""\nVERY_LIGHT_GREY = ""#F2F2F2""\n\ngraph_node_colour = GREEN\ngraph_edge_colour = LIGHT_GREY\nsubgraph_node_colour = RED\nsubgraph_edge_colour = RED\n\ngraph_node_size = 14\nsubgraph_node_size = 16\n\n\ndef graph(g: nx.Graph, s: Optional[list] = None, plot_size: Tuple = (500, 500)):  # pragma: no cover\n    """"""Creates a plot of the input graph.\n\n    This function can plot the input graph only, or the graph with a specified subgraph highlighted.\n    Graphs are plotted using the Kamada-Kawai layout with an aspect ratio of 1:1.\n\n    **Example usage:**\n\n    >>> graph = nx.complete_graph(10)\n    >>> fig = plot.graph(graph, [0, 1, 2, 3])\n    >>> fig.show()\n\n    .. image:: ../../_static/complete_graph.png\n       :width: 40%\n       :align: center\n       :target: javascript:void(0);\n\n    Args:\n        g (nx.Graph): input graph\n        s (list): optional list of nodes comprising the subgraph to highlight\n        plot_size (int): size of the plot in pixels, given as a pair of integers ``(x_size,\n            y_size)``\n\n    Returns:\n         Figure: figure for graph and optionally highlighted subgraph\n    """"""\n    try:\n        import plotly.graph_objects as go\n    except ImportError:\n        raise ImportError(plotly_error)\n\n    l = nx.kamada_kawai_layout(g)\n\n    g_nodes = go.Scatter(\n        **_node_coords(g, l),\n        mode=""markers"",\n        hoverinfo=""text"",\n        marker=dict(color=graph_node_colour, size=graph_node_size, line_width=2),\n    )\n\n    g_edges = go.Scatter(\n        **_edge_coords(g, l),\n        line=dict(width=1, color=graph_edge_colour),\n        hoverinfo=""none"",\n        mode=""lines"",\n    )\n\n    g_nodes.text = [str(i) for i in g.nodes()]\n\n    layout = go.Layout(\n        showlegend=False,\n        hovermode=""closest"",\n        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n        margin=dict(b=0, l=0, r=0, t=25),\n        height=plot_size[1],\n        width=plot_size[0],\n        plot_bgcolor=""#ffffff"",\n    )\n\n    if s is not None:\n        s = g.subgraph(s)\n\n        s_edges = go.Scatter(\n            **_edge_coords(s, l),\n            line=dict(width=2, color=subgraph_edge_colour),\n            hoverinfo=""none"",\n            mode=""lines"",\n        )\n\n        s_nodes = go.Scatter(\n            **_node_coords(s, l),\n            mode=""markers"",\n            hoverinfo=""text"",\n            marker=dict(color=subgraph_node_colour, size=subgraph_node_size, line_width=2),\n        )\n\n        s_nodes.text = [str(i) for i in s.nodes()]\n\n        f = go.Figure(data=[g_edges, s_edges, g_nodes, s_nodes], layout=layout)\n\n    else:\n        f = go.Figure(data=[g_edges, g_nodes], layout=layout)\n\n    return f\n\n\ndef subgraph(s: nx.Graph, plot_size: Tuple = (500, 500)):  # pragma: no cover\n    """"""Creates a plot of the input subgraph.\n\n    Subgraphs are plotted using the Kamada-Kawai layout with an aspect ratio of 1:1.\n\n    **Example usage:**\n\n    >>> graph = nx.complete_graph(10)\n    >>> subgraph = graph.subgraph([0, 1, 2, 3])\n    >>> fig = plot.subgraph(subgraph)\n    >>> fig.show()\n\n    .. image:: ../../_static/complete_subgraph.png\n       :width: 40%\n       :align: center\n       :target: javascript:void(0);\n\n    Args:\n        s (nx.Graph): input subgraph\n        plot_size (int): size of the plot in pixels, given as a pair of integers ``(x_size,\n            y_size)``\n\n    Returns:\n         Figure: figure for subgraph\n    """"""\n    try:\n        import plotly.graph_objects as go\n    except ImportError:\n        raise ImportError(plotly_error)\n\n    l = nx.kamada_kawai_layout(s)\n\n    g_edges = go.Scatter(\n        **_edge_coords(s, l),\n        line=dict(width=1.5, color=subgraph_edge_colour),\n        hoverinfo=""none"",\n        mode=""lines"",\n    )\n\n    g_nodes = go.Scatter(\n        **_node_coords(s, l),\n        mode=""markers"",\n        hoverinfo=""text"",\n        marker=dict(color=subgraph_node_colour, size=graph_node_size, line_width=2),\n    )\n\n    g_nodes.text = [str(i) for i in s.nodes()]\n\n    layout = go.Layout(\n        showlegend=False,\n        hovermode=""closest"",\n        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n        margin=dict(b=0, l=0, r=0, t=25),\n        height=plot_size[1],\n        width=plot_size[0],\n        plot_bgcolor=""#ffffff"",\n    )\n\n    f = go.Figure(data=[g_edges, g_nodes], layout=layout)\n\n    return f\n\n\ndef points(\n    R: np.ndarray,\n    sample: Optional[list] = None,\n    plot_size: Tuple = (500, 500),\n    point_size: float = 30,\n):  # pragma: no cover\n    """"""Creates a plot of two-dimensional points given their input coordinates. Sampled\n    points can be optionally highlighted among all points.\n\n    **Example usage:**\n\n    >>> R = np.random.normal(0, 1, (50, 2))\n    >>> sample = [1] * 10 + [0] * 40  # select first ten points\n    >>> plot.points(R, sample).show()\n\n    .. image:: ../../_static/normal_pp.png\n       :width: 40%\n       :align: center\n       :target: javascript:void(0);\n\n    Args:\n        R (np.array): Coordinate matrix. Rows of this array are the coordinates of the points.\n        sample (list[int]): optional subset of sampled points to be highlighted\n        plot_size (int): size of the plot in pixels, given as a pair of integers ``(x_size,\n            y_size)``\n        point_size (int): size of the points, proportional to its radius\n\n    Returns:\n         Figure: figure of points with optionally highlighted sample\n    """"""\n    try:\n        import plotly.graph_objects as go\n    except ImportError:\n        raise ImportError(plotly_error)\n\n    layout = go.Layout(\n        showlegend=False,\n        hovermode=""closest"",\n        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n        margin=dict(b=0, l=0, r=0, t=25),\n        height=plot_size[1],\n        width=plot_size[0],\n        plot_bgcolor=""white"",\n    )\n\n    p = go.Scatter(\n        x=R[:, 0],\n        y=R[:, 1],\n        mode=""markers"",\n        hoverinfo=""text"",\n        marker=dict(\n            color=VERY_LIGHT_GREY, size=point_size, line=dict(color=""black"", width=point_size / 20)\n        ),\n    )\n\n    p.text = [str(i) for i in range(len(R))]\n\n    if sample:\n        s_x = []\n        s_y = []\n        sampled_points = [i for i in range(len(sample)) if sample[i] > 0]\n        for i in sampled_points:\n            s_x.append(R[i, 0])\n            s_y.append(R[i, 1])\n\n        samp = go.Scatter(\n            x=s_x,\n            y=s_y,\n            mode=""markers"",\n            hoverinfo=""text"",\n            marker=dict(\n                color=RED, size=point_size, line=dict(color=""black"", width=point_size / 20)\n            ),\n        )\n\n        samp.text = [str(i) for i in sampled_points]\n\n        f = go.Figure(data=[p, samp], layout=layout)\n\n    else:\n        f = go.Figure(data=[p], layout=layout)\n\n    return f\n\n\ndef spectrum(\n    energies: list, gamma: float = 100.0, xmin: float = None, xmax: float = None\n):  # pragma: no cover\n    """"""Plots a vibronic spectrum based on input sampled energies.\n\n    **Example usage:**\n\n    >>> formic = data.Formic()\n    >>> e = vibronic.energies(formic, formic.w, formic.wp)\n    >>> full_spectrum = plot.spectrum(e, xmin=-1000, xmax=8000)\n    >>> full_spectrum.show()\n\n    .. image:: ../../_static/formic_spectrum.png\n       :width: 50%\n       :align: center\n       :target: javascript:void(0);\n\n    Args:\n        energies (list[float]): a list of sampled energies\n        gamma (float): parameter specifying the width of the Lorentzian function\n        xmin (float): minimum limit of the x axis\n        xmax (float): maximum limit of the x axis\n\n    Returns:\n         Figure: spectrum in the form of a histogram of energies with a Lorentzian-like curve\n    """"""\n    if len(energies) < 2:\n        raise ValueError(""Number of sampled energies must be at least two"")\n    try:\n        import plotly.graph_objects as go\n    except ImportError:\n        raise ImportError(plotly_error)\n\n    emin = min(energies)\n    emax = max(energies)\n    if xmin is None:\n        xmin = emin - 0.1 * (emax - emin)\n    if xmax is None:\n        xmax = emax + 0.1 * (emax - emin)\n    bins = int(emax - emin) // 5\n    bar_width = (xmax - xmin) * 0.005\n    line_width = 3.0\n\n    h = np.histogram(energies, bins)\n    X = np.linspace(xmin, xmax, int(xmax - xmin))\n    L = 0\n    for e in energies:\n        L += (gamma / 2) ** 2 / ((X - e) ** 2 + (gamma / 2) ** 2)\n\n    text_font = dict(color=""black"", family=""Computer Modern"")\n\n    axis_style = dict(\n        titlefont_size=30,\n        tickfont=text_font,\n        tickfont_size=20,\n        showline=True,\n        linecolor=""black"",\n        mirror=True,\n    )\n\n    layout = go.Layout(\n        yaxis=dict(title={""text"": ""Counts"", ""font"": text_font}, **axis_style, rangemode=""tozero""),\n        xaxis=dict(\n            title={""text"": ""Energy (cm<sup>-1</sup>)"", ""font"": text_font},\n            **axis_style,\n            range=[xmin, xmax],\n        ),\n        plot_bgcolor=""white"",\n        margin=dict(t=25),\n        bargap=0.04,\n        showlegend=False,\n    )\n\n    bars = go.Bar(x=h[1].tolist(), y=h[0].tolist(), width=bar_width, marker=dict(color=GREY))\n\n    line = go.Scatter(x=X, y=L, mode=""lines"", line=dict(color=GREEN, width=line_width))\n\n    f = go.Figure([bars, line], layout=layout)\n\n    return f\n'"
strawberryfields/apps/points.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nTools for building kernel matrices and generating point processes using GBS.\n\n.. seealso::\n\n    :ref:`apps-points-tutorial`\n\nPoint processes\n---------------\n\nA point process is a mechanism that generates random point patterns among a set of possible\noutcomes.\nPoint processes are statistical models that can replicate the stochastic\nproperties of natural phenomena, or be used as subroutines in statistical and machine learning\nalgorithms.\n\nSeveral point processes rely on matrix functions to assign probabilities to different point\npatterns. As shown in Ref. :cite:`jahangiri2019point`, GBS naturally gives rise to a *hafnian*\npoint process that employs the `hafnian\n<https://the-walrus.readthedocs.io/en/latest/hafnian.html>`_ as the underlying matrix function.\nThis point process has the central property of generating clustered data points with\nhigh probability. In this setting, a GBS device is programmed according to a *kernel* matrix that\nencodes information about the similarity between points. When this kernel matrix is positive\nsemidefinite, it is possible to use GBS to implement a *permanental* point process and employ\nfast classical algorithms to sample from the resulting distribution.\n\nOne choice of kernel matrix is the radial basis function (RBF) kernel whose elements are computed\nas:\n\n.. math::\n    K_{i,j} = e^{-\\|\\bf{r}_i-\\bf{r}_j\\|^2/(2\\sigma^2)},\n\nwhere :math:`\\bf{r}_i` are the coordinates of point :math:`i`, :math:`\\sigma` is a kernel\nparameter, and :math:`\\|\\cdot\\|` denotes a choice of norm. The RBF kernel is positive\nsemidefinite when the Euclidean norm is used, as is the case for the provided :func:`rbf_kernel`\nfunction.\n""""""\n\nimport numpy as np\nimport scipy\nfrom thewalrus.csamples import generate_thermal_samples, rescale_adjacency_matrix_thermal\n\n\ndef rbf_kernel(R: np.ndarray, sigma: float) -> np.ndarray:\n    r""""""Calculate the RBF kernel matrix from a set of input points.\n\n    The kernel parameter :math:`\\sigma` is used to define the kernel scale. Points that are much\n    further than :math:`\\sigma` from each other lead to small entries of the kernel\n    matrix, whereas points much closer than :math:`\\sigma` generate large entries.\n\n    The Euclidean norm is used to measure distance in this function, resulting in a\n    positive-semidefinite kernel.\n\n    **Example usage:**\n\n    >>> R = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n    >>> rbf_kernel (R, 1.0)\n    array([[1., 0.36787944, 0.60653066, 0.60653066],\n           [0.36787944, 1., 0.60653066, 0.60653066],\n           [0.60653066, 0.60653066, 1., 0.36787944],\n           [0.60653066, 0.60653066, 0.36787944, 1.,]])\n\n    Args:\n        R (array): Coordinate matrix. Rows of this array are the coordinates of the points.\n        sigma (float): kernel parameter\n\n    Returns:\n        K (array): the RBF kernel matrix\n    """"""\n    return np.exp(-((scipy.spatial.distance.cdist(R, R)) ** 2) / 2 / sigma ** 2)\n\n\ndef sample(K: np.ndarray, n_mean: float, n_samples: int) -> list:\n    """"""Sample subsets of points using the permanental point process.\n\n    Points can be encoded through a radial basis function kernel, provided in :func:`rbf_kernel`.\n    Subsets of points are sampled with probabilities that are proportional to the permanent of the\n    submatrix of the kernel selected by those points.\n\n    This permanental point process is likely to sample points that are clustered together\n    :cite:`jahangiri2019point`. It can be realized using a variant of Gaussian boson sampling\n    with thermal states as input.\n\n    **Example usage:**\n\n    >>> K = np.array([[1., 0.36787944, 0.60653066, 0.60653066],\n    >>>               [0.36787944, 1., 0.60653066, 0.60653066],\n    >>>               [0.60653066, 0.60653066, 1., 0.36787944],\n    >>>               [0.60653066, 0.60653066, 0.36787944, 1.]])\n    >>> sample(K, 1.0, 10)\n    [[0, 1, 1, 1],\n     [0, 0, 0, 0],\n     [1, 0, 0, 0],\n     [0, 0, 0, 1],\n     [0, 1, 1, 0],\n     [2, 0, 0, 0],\n     [0, 0, 0, 0],\n     [0, 0, 0, 0],\n     [0, 0, 1, 1],\n     [0, 0, 0, 0]]\n\n    Args:\n        K (array): the positive semidefinite kernel matrix\n        n_mean (float): average number of points per sample\n        n_samples (int): number of samples to be generated\n\n    Returns:\n        samples (list[list[int]]): samples generated by the point process\n    """"""\n    ls, O = rescale_adjacency_matrix_thermal(K, n_mean)\n    return np.array(generate_thermal_samples(ls, O, num_samples=n_samples)).tolist()\n'"
strawberryfields/apps/sample.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nFunctionality for generating GBS samples using classical simulators.\n\n.. seealso::\n\n    :ref:`apps-sample-tutorial`\n\nGenerating samples\n------------------\n\nAn :math:`M` mode GBS device can be programmed by specifying an :math:`(M \\times M)`-dimensional\nsymmetric matrix :math:`A` :cite:`bradler2018gaussian`. Running this device results in samples\nthat carry relevant information about the encoded matrix :math:`A`. When sampling, one must also\nspecify the mean number of photons in the device, the form of detection used at the output:\nthreshold detection or photon-number-resolving (PNR) detection, as well as the amount of loss.\n\nThe :func:`sample` function provides a simulation of sampling from GBS.\n\nHere, each output sample is an :math:`M`-dimensional list. If threshold detection is used\n(``threshold = True``), each element of a sample is either a zero (denoting no photons detected)\nor a one (denoting one or more photons detected), conventionally called a ""click"".\nIf photon-number resolving (PNR) detection is used (``threshold = False``) then elements of a\nsample are non-negative integers counting the number of photons detected in each mode. The ``loss``\nparameter allows for simulation of photon loss in the device, which is the most common form of\nnoise in quantum photonics. Here, ``loss = 0`` describes ideal loss-free GBS, while generally\n``0 <= loss <= 1`` describes the proportion of photons lost while passing through the device.\n\nSamples can be postselected based upon their total number of photons or clicks and the ``numpy``\nrandom seed used to generate samples can be fixed.\n\nThe :func:`vibronic` function allows users to sample Gaussian states for computing molecular\nvibronic spectra.\n\nGenerating subgraphs\n--------------------\n\nThere are two forms to represent a sample from a GBS device:\n\n1. In the form returned by :func:`sample`, each sample is a length :math:`M` list of counts in\n   each mode, e.g., the sample ``[2, 1, 2, 0, 1]`` denotes two photons in mode 0,\n   1 photon in mode 1, and so forth.\n\n2. The alternative representation is a list of modes where photons or clicks were observed, e.g.,\n   the above sample can be written alternatively as ``[0, 0, 1, 2, 2, 4]``.\n\nConverting from the former representation to the latter can be achieved with:\n\n.. autosummary::\n    modes_from_counts\n\nGraphs can be encoded into GBS through their adjacency matrix. Resultant samples\ncan then be used to pick out nodes from the graph to form a subgraph. If threshold detection is\nused, any nodes that click are selected as part of the subgraph. For example, if a sample is\n``[1, 1, 1, 0, 1]`` then the corresponding subgraph has nodes ``[0, 1, 2, 4]``. This can be found\nusing:\n\n>>> modes_from_counts([1, 1, 1, 0, 1])\n[0, 1, 2, 4]\n\nA collection of GBS samples from a graph, given by :func:`sample` in the first form, can be\nconverted to subgraphs using:\n\n.. autosummary::\n    to_subgraphs\n\nA typical workflow would be:\n\n>>> g = nx.erdos_renyi_graph(5, 0.7)\n>>> a = nx.to_numpy_array(g)\n>>> s = sample(a, 3, 4)\n>>> s = to_subgraphs(s, g)\n[[0, 2], [0, 1, 2, 4], [1, 2, 3, 4], [1]]\n\nThe subgraphs sampled from GBS are likely to be dense :cite:`arrazola2018using`, motivating their\nuse within heuristics for problems such as maximum clique (see :mod:`~.apps.clique`).\n\nIncluding node weights\n----------------------\n\nSome graphs are composed of nodes with weights. These weights can correspond to relevant\ninformation in an optimization problem and it is desirable to encode them into GBS along with the\ngraph\'s adjacency matrix. One canonical approach to doing this is to use the :math:`WAW` encoding\n:cite:`banchi2019molecular`, which rescales the adjacency matrix according to:\n\n.. math::\n\n    A \\rightarrow WAW,\n\nwith :math:`W=w_{i}\\delta_{ij}` the diagonal matrix formed by the weighted nodes :math:`w_{i}`. The\nrescaled adjacency matrix can be passed to :func:`sample`, resulting in a distribution that\nincreases the probability of observing a node proportionally to its weight.\n""""""\nimport warnings\nfrom typing import Optional, Union\n\nimport networkx as nx\nimport numpy as np\n\nimport strawberryfields as sf\n\n\ndef sample(\n    A: np.ndarray, n_mean: float, n_samples: int = 1, threshold: bool = True, loss: float = 0.0\n) -> list:\n    r""""""Generate simulated samples from GBS encoded with a symmetric matrix :math:`A`.\n\n    **Example usage:**\n\n    >>> g = nx.erdos_renyi_graph(5, 0.7)\n    >>> a = nx.to_numpy_array(g)\n    >>> sample(a, 3, 4)\n    [[1, 1, 1, 1, 1], [1, 1, 0, 1, 1], [0, 0, 0, 0, 0], [1, 0, 0, 0, 1]]\n\n    Args:\n        A (array): the symmetric matrix to sample from\n        n_mean (float): mean photon number\n        n_samples (int): number of samples\n        threshold (bool): perform GBS with threshold detectors if ``True`` or photon-number\n            resolving detectors if ``False``\n        loss (float): fraction of generated photons that are lost while passing through device.\n            Parameter should range from ``loss=0`` (ideal noise-free GBS) to ``loss=1``.\n\n    Returns:\n        list[list[int]]: a list of samples from GBS with respect to the input symmetric matrix\n    """"""\n    if not np.allclose(A, A.T):\n        raise ValueError(""Input must be a NumPy array corresponding to a symmetric matrix"")\n    if n_samples < 1:\n        raise ValueError(""Number of samples must be at least one"")\n    if n_mean < 0:\n        raise ValueError(""Mean photon number must be non-negative"")\n    if not 0 <= loss <= 1:\n        raise ValueError(""Loss parameter must take a value between zero and one"")\n\n    nodes = len(A)\n\n    p = sf.Program(nodes)\n    eng = sf.LocalEngine(backend=""gaussian"")\n\n    mean_photon_per_mode = n_mean / float(nodes)\n\n    # pylint: disable=expression-not-assigned,pointless-statement\n    with p.context as q:\n        sf.ops.GraphEmbed(A, mean_photon_per_mode=mean_photon_per_mode) | q\n\n        if loss:\n            for _q in q:\n                sf.ops.LossChannel(1 - loss) | _q\n\n        if threshold:\n            sf.ops.MeasureThreshold() | q\n        else:\n            sf.ops.MeasureFock() | q\n\n    with warnings.catch_warnings():\n        warnings.filterwarnings(""ignore"", category=UserWarning, message=""Cannot simulate non-"")\n        s = eng.run(p, shots=n_samples).samples\n    return s.tolist()\n\n\ndef postselect(samples: list, min_count: int, max_count: int) -> list:\n    """"""Postselect samples by imposing a minimum and maximum number of photons or clicks.\n\n    **Example usage:**\n\n    >>> s = [[1, 1, 1, 1, 1], [1, 1, 0, 1, 1], [0, 0, 0, 0, 0], [1, 0, 0, 0, 1]]\n    >>> postselect(s, 2, 4)\n    [[1, 1, 0, 1, 1], [1, 0, 0, 0, 1]]\n\n    Args:\n        samples (list[list[int]]): a list of samples\n        min_count (int): minimum number of photons or clicks for a sample to be included\n        max_count (int): maximum number of photons or clicks for a sample to be included\n\n    Returns:\n        list[list[int]]: the postselected samples\n    """"""\n    return [s for s in samples if min_count <= sum(s) <= max_count]\n\n\ndef seed(value: Optional[int]) -> None:\n    """"""Seed for random number generators.\n\n    Wrapper function for `numpy.random.seed <https://docs.scipy.org/doc/numpy//reference/generated\n    /numpy.random.seed.html>`_ to seed all NumPy-based random number generators. This allows for\n    repeatable sampling.\n\n    **Example usage:**\n\n    >>> g = nx.erdos_renyi_graph(5, 0.7)\n    >>> a = nx.to_numpy_array(g)\n    >>> seed(1967)\n    >>> sample(a, 3, 4)\n    [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [0, 0, 0, 0, 0]]\n    >>> seed(1967)\n    >>> sample(a, 3, 4)\n    [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [0, 0, 0, 0, 0]]\n\n    Args:\n        value (int): random seed\n    """"""\n    np.random.seed(value)\n\n\ndef modes_from_counts(s: list) -> list:\n    r""""""Convert a list of counts to a list of modes where photons or clicks were observed.\n\n    Consider an :math:`M`-mode sample :math:`s=\\{s_{0},s_{1},\\ldots,s_{M-1}\\}` of counts in each\n    mode, i.e., so that mode :math:`i` has :math:`s_{i}` photons/clicks. If :math:`k = \\sum_{\n    i=0}^{M-1} s_{i}` is the total number of photons or clicks, this function returns a list of\n    modes :math:`m=\\{m_{1},m_{2},\\ldots, m_{k}\\}` where photons or clicks were observed, i.e.,\n    so that photon/click :math:`i` is in mode :math:`m_{i}`. Since there are typically fewer\n    photons than modes, the latter form often gives a shorter representation.\n\n    **Example usage:**\n\n    >>> modes_from_counts([0, 1, 0, 1, 2, 0])\n    [1, 3, 4, 4]\n\n    Args:\n       s (list[int]): a sample of counts\n\n    Returns:\n        list[int]: a list of modes where photons or clicks were observed, sorted in\n        non-decreasing order\n    """"""\n    modes = []\n    for i, c in enumerate(s):\n        modes += [i] * int(c)\n    return sorted(modes)\n\n\ndef to_subgraphs(samples: list, graph: nx.Graph) -> list:\n    """"""Converts samples to their subgraph representation.\n\n    Input samples are a list of counts that are processed into subgraphs by selecting the nodes\n    where a click occurred.\n\n    **Example usage:**\n\n    >>> g = nx.erdos_renyi_graph(5, 0.7)\n    >>> s = [[1, 1, 1, 1, 1], [1, 1, 0, 1, 1], [0, 0, 0, 0, 0], [1, 0, 0, 0, 1]]\n    >>> to_subgraphs(s, g)\n    [[0, 1, 2, 3, 4], [0, 1, 3, 4], [], [0, 4]]\n\n    Args:\n        samples (list[list[int]]): a list of samples, each sample being a list of counts\n        graph (nx.Graph): the input graph\n\n    Returns:\n        list[list[int]]: a list of subgraphs, where each subgraph is represented by a list of its\n        nodes\n    """"""\n\n    graph_nodes = list(graph.nodes)\n    node_number = len(graph_nodes)\n\n    subgraph_samples = [list(set(modes_from_counts(s))) for s in samples]\n\n    if graph_nodes != list(range(node_number)):\n        return [sorted([graph_nodes[i] for i in s]) for s in subgraph_samples]\n\n    return subgraph_samples\n\n\ndef vibronic(\n    t: np.ndarray,\n    U1: np.ndarray,\n    r: np.ndarray,\n    U2: np.ndarray,\n    alpha: np.ndarray,\n    n_samples: int,\n    loss: float = 0.0,\n) -> list:\n    """"""Generate samples for computing vibronic spectra. The following gates are applied to input\n    vacuum states:\n\n    1. Two-mode squeezing on all :math:`2N` modes with parameters ``t``\n    2. Interferometer ``U1`` on the first :math:`N` modes\n    3. Squeezing on the first :math:`N` modes with parameters ``r``\n    4. Interferometer ``U2`` on the first :math:`N` modes\n    5. Displacement on the first :math:`N` modes with parameters ``alpha``\n\n    A sample is generated by measuring the number of photons in each of the :math:`2N` modes. In\n    the special case that all of the two-mode squeezing parameters ``t`` are zero, only :math:`N`\n    modes are considered, which speeds up calculations.\n\n    **Example usage:**\n\n    >>> formic = data.Formic()\n    >>> w = formic.w\n    >>> wp = formic.wp\n    >>> Ud = formic.Ud\n    >>> delta = formic.delta\n    >>> T = 0\n    >>> t, U1, r, U2, alpha = vibronic.gbs_params(w, wp, Ud, delta, T)\n    >>> sample.vibronic(t, U1, r, U2, alpha, 2, 0.0)\n    [[0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n     [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n\n    Args:\n        t (array): two-mode squeezing parameters\n        U1 (array): unitary matrix for the first interferometer\n        r (array): squeezing parameters\n        U2 (array): unitary matrix for the second interferometer\n        alpha (array): displacement parameters\n        n_samples (int): number of samples to be generated\n        loss (float): loss parameter denoting the fraction of generated photons that are lost\n\n\n    Returns:\n        list[list[int]]: a list of samples from GBS\n    """"""\n    if n_samples < 1:\n        raise ValueError(""Number of samples must be at least one"")\n    if not 0 <= loss <= 1:\n        raise ValueError(""Loss parameter must take a value between zero and one"")\n\n    n_modes = len(t)\n\n    eng = sf.LocalEngine(backend=""gaussian"")\n\n    if np.any(t != 0):\n        gbs = sf.Program(n_modes * 2)\n    else:\n        gbs = sf.Program(n_modes)\n\n    # pylint: disable=expression-not-assigned,pointless-statement\n    with gbs.context as q:\n\n        if np.any(t != 0):\n            for i in range(n_modes):\n                sf.ops.S2gate(t[i]) | (q[i], q[i + n_modes])\n\n        sf.ops.Interferometer(U1) | q[:n_modes]\n\n        for i in range(n_modes):\n            sf.ops.Sgate(r[i]) | q[i]\n\n        sf.ops.Interferometer(U2) | q[:n_modes]\n\n        for i in range(n_modes):\n            sf.ops.Dgate(alpha[i]) | q[i]\n\n        if loss:\n            for _q in q:\n                sf.ops.LossChannel(1 - loss) | _q\n\n        sf.ops.MeasureFock() | q\n\n    with warnings.catch_warnings():\n        warnings.filterwarnings(""ignore"", category=UserWarning, message=""Cannot simulate non-"")\n\n        s = eng.run(gbs, shots=n_samples).samples\n\n    s = np.array(s).tolist()  # convert all generated samples to list\n\n    if np.any(t == 0):\n        s = np.pad(s, ((0, 0), (0, n_modes))).tolist()\n    return s\n\n\ndef waw_matrix(A: np.ndarray, w: Union[np.ndarray, list]) -> np.ndarray:\n    r""""""Rescale adjacency matrix to account for node weights.\n\n    Given a graph with adjacency matrix :math:`A` and a vector :math:`w` of weighted nodes,\n    this function rescales the adjacency matrix according to :cite:`banchi2019molecular`:\n\n    .. math::\n\n        A \\rightarrow WAW,\n\n    with :math:`W=w_{i}\\delta_{ij}` the diagonal matrix formed by the weighted nodes :math:`w_{i}`.\n    The rescaled adjacency matrix can be passed to :func:`sample`, resulting in a distribution that\n    increases the probability of observing a node proportionally to its weight.\n\n    **Example usage:**\n\n    >>> g = nx.erdos_renyi_graph(5, 0.7)\n    >>> a = nx.to_numpy_array(g)\n    >>> a\n    array([[0., 1., 1., 1., 1.],\n           [1., 0., 1., 1., 1.],\n           [1., 1., 0., 1., 0.],\n           [1., 1., 1., 0., 0.],\n           [1., 1., 0., 0., 0.]])\n    >>> w = [10, 1, 0, 1, 1]\n    >>> a = waw_matrix(a, w)\n    >>> a\n    array([[ 0., 10.,  0., 10., 10.],\n           [10.,  0.,  0.,  1.,  1.],\n           [ 0.,  0.,  0.,  0.,  0.],\n           [10.,  1.,  0.,  0.,  0.],\n           [10.,  1.,  0.,  0.,  0.]])\n    >>> sample(a, 3, 4)\n    [[1, 0, 0, 1, 1], [1, 1, 0, 0, 0], [1, 1, 0, 1, 1], [1, 0, 0, 1, 0]]\n\n    Args:\n        A (array): adjacency matrix to rescale\n        w (array or list): vector of real node weights\n\n    Returns:\n        array: matrix rescaled according to the WAW encoding\n    """"""\n    if not np.allclose(A, A.T):\n        raise ValueError(""Input must be a NumPy array corresponding to a symmetric matrix"")\n\n    if isinstance(w, list):\n        w = np.array(w)\n\n    return (w * A).T * w\n'"
strawberryfields/apps/similarity.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\r\n\r\n# Licensed under the Apache License, Version 2.0 (the ""License"");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an ""AS IS"" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\nr""""""\r\nTools to construct graph kernels from GBS.\r\n\r\nThe graph kernel is built by mapping GBS samples from each graph to a feature vector. Similarity\r\nbetween graphs can then be determined by calculating the overlap between these vectors.\r\n\r\nThe functionality here is based upon the research papers:\r\n:cite:`bradler2018graph,schuld2019quantum,bradler2019duality`.\r\n\r\n.. seealso::\r\n\r\n    :ref:`apps-sim-tutorial`\r\n\r\nCoarse-graining GBS samples\r\n---------------------------\r\n\r\nGBS feature vectors can be composed of probabilities of coarse-grained combinations of elementary\r\nsamples. We consider two coarse grainings:\r\n\r\n- **Orbits:** Combine all samples that can be made identical under permutation. Orbits are\r\n  written simply as a sorting of integer photon number samples in non-increasing order with the\r\n  zeros at the end removed. For example, ``[1, 1, 2, 0]`` and ``[2, 1, 0, 1]`` both belong to the\r\n  ``[2, 1, 1]`` orbit.\r\n\r\n- **Events:** Combine all :math:`k`-photon orbits where the maximum photon count in any mode does\r\n  not exceed a fixed value :math:`n_{\\max}` into an event :math:`E_{k, n_{\\max}}`. For example,\r\n  orbits ``[2, 1]``, ``[1, 1, 1]`` are part of the :math:`E_{k=3, n_{\\max}=2}` event, while\r\n  orbit ``[3]`` is not.\r\n\r\nThis module provides the following tools for dealing with coarse-grained orbits and events.\r\n\r\nCreating a feature vector\r\n-------------------------\r\n\r\nA feature vector of a graph can be created by choosing a collection of orbits or events and\r\nevaluating their probabilities with respect to GBS with the embedded graph. These\r\nprobabilities are then selected to be elements of the feature vector. Evaluating the\r\nprobabilities of orbits or events can be achieved through two approaches:\r\n\r\n- **Direct sampling:** infer the probability of orbits or events from a set of sample data.\r\n\r\n- **Monte Carlo approximation:** generate samples within a given orbit or event and use them\r\n  to approximate the probability.\r\n\r\nIn the direct sampling approach, :math:`N` samples are taken from GBS with the embedded graph.\r\nThe number that fall within a given orbit or event :math:`E` are counted, resulting in the count\r\n:math:`c_{E}`. The probability :math:`p(E)` of an orbit or event is then approximated as:\r\n\r\n.. math::\r\n    p(E) \\approx \\frac{c_{E}}{N}.\r\n\r\nTo perform a Monte Carlo estimation of the probability of an orbit or event :math:`E`,\r\nseveral samples from :math:`E` are drawn uniformly at random using :func:`orbit_to_sample` or\r\n:func:`event_to_sample`. Suppose :math:`N` samples :math:`\\{S_{1}, S_{2}, \\ldots , S_{N}\\}` are\r\ngenerated. For each sample, this function calculates the probability :math:`p(S_i)` of observing\r\nthat sample from a GBS device programmed according to the input graph and mean photon number. The\r\nsum of the probabilities is then rescaled according to the cardinality :math:`|E|` and the total\r\nnumber of samples:\r\n\r\n.. math::\r\n    p(E) \\approx \\frac{1}{N}\\sum_{i=1}^N p(S_i) |E|.\r\n\r\nThe sample mean of this sum is an estimate of the rescaled probability :math:`p(E)`.\r\n\r\nThis module provides functions to evaluate the probability of orbits and events through Monte Carlo\r\napproximation.\r\n\r\nSimilar to the :func:`~.apps.sample.sample` function, the MC estimators include a ``loss`` argument\r\nto specify the proportion of photons lost in the simulated GBS device.\r\n\r\nOne canonical method of constructing a feature vector is to pick event probabilities\r\n:math:`p_{k} := p_{E_{k, n_{\\max}}}` with all events :math:`E_{k, n_{\\max}}` having a maximum\r\nphoton count :math:`n_{\\max}` in each mode. If :math:`\\mathbf{k}` is the vector of selected events,\r\nthe resultant feature vector is\r\n\r\n.. math::\r\n    f_{\\mathbf{k}} = (p_{k_{1}}, p_{k_{2}}, \\ldots).\r\n\r\nThis module allows for such feature vectors to be calculated using both the direct sampling and\r\nMonte Carlo approximation methods.\r\n""""""\r\nfrom collections import Counter\r\nfrom typing import Generator, Union\r\n\r\nimport networkx as nx\r\nimport numpy as np\r\nfrom scipy.special import factorial\r\n\r\nimport strawberryfields as sf\r\n\r\n\r\ndef sample_to_orbit(sample: list) -> list:\r\n    """"""Provides the orbit corresponding to a given sample.\r\n\r\n    **Example usage:**\r\n\r\n    >>> sample = [1, 2, 0, 0, 1, 1, 0, 3]\r\n    >>> sample_to_orbit(sample)\r\n    [3, 2, 1, 1, 1]\r\n\r\n    Args:\r\n        sample (list[int]): a sample from GBS\r\n\r\n    Returns:\r\n        list[int]: the orbit of the sample\r\n    """"""\r\n    return sorted(filter(None, sample), reverse=True)\r\n\r\n\r\ndef sample_to_event(sample: list, max_count_per_mode: int) -> Union[int, None]:\r\n    r""""""Provides the event corresponding to a given sample.\r\n\r\n    For an input ``max_count_per_mode``, events are expressed here simply by the total photon\r\n    number :math:`k`.\r\n\r\n    **Example usage:**\r\n\r\n    >>> sample = [1, 2, 0, 0, 1, 1, 0, 3]\r\n    >>> sample_to_event(sample, 4)\r\n    8\r\n\r\n    >>> sample_to_event(sample, 2)\r\n    None\r\n\r\n    Args:\r\n        sample (list[int]): a sample from GBS\r\n        max_count_per_mode (int): the maximum number of photons counted in any given mode for a\r\n            sample to be categorized as an event. Samples with counts exceeding this value are\r\n            attributed the event ``None``.\r\n\r\n    Returns:\r\n        int or None: the event of the sample\r\n    """"""\r\n    if max(sample) <= max_count_per_mode:\r\n        return sum(sample)\r\n\r\n    return None\r\n\r\n\r\ndef orbit_to_sample(orbit: list, modes: int) -> list:\r\n    """"""Generates a sample selected uniformly at random from the specified orbit.\r\n\r\n    **Example usage:**\r\n\r\n    >>> orbit_to_sample([2, 1, 1], 6)\r\n    [0, 1, 2, 0, 1, 0]\r\n\r\n    Args:\r\n        orbit (list[int]): orbit to generate a sample from\r\n        modes (int): number of modes in the sample\r\n\r\n    Returns:\r\n        list[int]: a sample in the orbit\r\n    """"""\r\n    if modes < len(orbit):\r\n        raise ValueError(""Number of modes cannot be smaller than length of orbit"")\r\n\r\n    sample = orbit + [0] * (modes - len(orbit))\r\n    np.random.shuffle(sample)\r\n    return sample\r\n\r\n\r\ndef event_to_sample(photon_number: int, max_count_per_mode: int, modes: int) -> list:\r\n    """"""Generates a sample selected uniformly at random from the specified event.\r\n\r\n    **Example usage:**\r\n\r\n    >>> event_to_sample(4, 2, 6)\r\n    [0, 1, 0, 0, 2, 1]\r\n\r\n    Args:\r\n        photon_number (int): number of photons in the event\r\n        max_count_per_mode (int): maximum number of photons per mode in the event\r\n        modes (int): number of modes in the sample\r\n\r\n    Returns:\r\n        list[int]: a sample in the event\r\n    """"""\r\n    if max_count_per_mode < 0:\r\n        raise ValueError(""Maximum number of photons per mode must be non-negative"")\r\n\r\n    if max_count_per_mode * modes < photon_number:\r\n        raise ValueError(\r\n            ""No valid samples can be generated. Consider increasing the ""\r\n            ""max_count_per_mode or reducing the number of photons.""\r\n        )\r\n\r\n    cards = []\r\n    orbs = []\r\n\r\n    for orb in orbits(photon_number):\r\n        if max(orb) <= max_count_per_mode:\r\n            cards.append(orbit_cardinality(orb, modes))\r\n            orbs.append(orb)\r\n\r\n    norm = sum(cards)\r\n    prob = [c / norm for c in cards]\r\n\r\n    orbit = orbs[np.random.choice(len(prob), p=prob)]\r\n\r\n    return orbit_to_sample(orbit, modes)\r\n\r\n\r\ndef orbits(photon_number: int) -> Generator[list, None, None]:\r\n    """"""Generate all the possible orbits for a given photon number.\r\n\r\n    Provides a generator over the integer partitions of ``photon_number``.\r\n    Code derived from `website <http://jeromekelleher.net/generating-integer-partitions.html>`__\r\n    of Jerome Kelleher\'s, which is based upon an algorithm from Ref. :cite:`kelleher2009generating`.\r\n\r\n    **Example usage:**\r\n\r\n    >>> o = orbits(5)\r\n    >>> list(o)\r\n    [[1, 1, 1, 1, 1], [2, 1, 1, 1], [3, 1, 1], [2, 2, 1], [4, 1], [3, 2], [5]]\r\n\r\n    Args:\r\n        photon_number (int): number of photons to generate orbits from\r\n\r\n    Returns:\r\n        Generator[list[int]]: orbits with total photon number adding up to ``photon_number``\r\n    """"""\r\n    a = [0] * (photon_number + 1)\r\n    k = 1\r\n    y = photon_number - 1\r\n    while k != 0:\r\n        x = a[k - 1] + 1\r\n        k -= 1\r\n        while 2 * x <= y:\r\n            a[k] = x\r\n            y -= x\r\n            k += 1\r\n        l = k + 1\r\n        while x <= y:\r\n            a[k] = x\r\n            a[l] = y\r\n            yield sorted(a[: k + 2], reverse=True)\r\n            x += 1\r\n            y -= 1\r\n        a[k] = x + y\r\n        y = x + y - 1\r\n        yield sorted(a[: k + 1], reverse=True)\r\n\r\n\r\ndef orbit_cardinality(orbit: list, modes: int) -> int:\r\n    """"""Gives the number of samples belonging to the input orbit.\r\n\r\n    For example, there are three possible samples in the orbit [2, 1, 1] with three modes: [1, 1,\r\n    2], [1, 2, 1], and [2, 1, 1]. With four modes, there are 12 samples in total.\r\n\r\n    **Example usage:**\r\n\r\n    >>> orbit_cardinality([2, 1, 1], 4)\r\n    12\r\n\r\n    Args:\r\n        orbit (list[int]): orbit; we count how many samples are contained in it\r\n        modes (int): number of modes in the samples\r\n\r\n    Returns:\r\n        int: number of samples in the orbit\r\n    """"""\r\n    sample = orbit + [0] * (modes - len(orbit))\r\n    counts = list(Counter(sample).values())\r\n    return int(factorial(modes) / np.prod(factorial(counts)))\r\n\r\n\r\ndef event_cardinality(photon_number: int, max_count_per_mode: int, modes: int) -> int:\r\n    r""""""Gives the number of samples belonging to the input event.\r\n\r\n    For example, for three modes, there are six samples in an :math:`E_{k=2, n_{\\max}=2}` event:\r\n    [1, 1, 0], [1, 0, 1], [0, 1, 1], [2, 0, 0], [0, 2, 0], and [0, 0, 2].\r\n\r\n    **Example usage:**\r\n\r\n    >>> event_cardinality(2, 2, 3)\r\n    6\r\n\r\n    Args:\r\n        photon_number (int): number of photons in the event\r\n        max_count_per_mode (int): maximum number of photons per mode in the event\r\n        modes (int): number of modes in counted samples\r\n\r\n    Returns:\r\n        int: number of samples in the event\r\n    """"""\r\n    cardinality = 0\r\n\r\n    for orb in orbits(photon_number):\r\n        if max(orb) <= max_count_per_mode:\r\n            cardinality += orbit_cardinality(orb, modes)\r\n\r\n    return cardinality\r\n\r\n\r\ndef prob_orbit_mc(\r\n    graph: nx.Graph, orbit: list, n_mean: float = 5, samples: int = 1000, loss: float = 0.0\r\n) -> float:\r\n    r""""""Gives a Monte Carlo estimate of the GBS probability of a given orbit according to the input\r\n    graph.\r\n\r\n    To make this estimate, several samples from the orbit are drawn uniformly at random using\r\n    :func:`orbit_to_sample`. The GBS probabilities of these samples are then calculated and the\r\n    sum is used to create an estimate of the orbit probability.\r\n\r\n    **Example usage:**\r\n\r\n    >>> graph = nx.complete_graph(8)\r\n    >>> prob_orbit_mc(graph, [2, 1, 1])\r\n    0.03744\r\n\r\n    Args:\r\n        graph (nx.Graph): input graph encoded in the GBS device\r\n        orbit (list[int]): orbit for which to estimate the probability\r\n        n_mean (float): total mean photon number of the GBS device\r\n        samples (int): number of samples used in the Monte Carlo estimation\r\n        loss (float): fraction of photons lost in GBS\r\n\r\n    Returns:\r\n        float: estimated orbit probability\r\n    """"""\r\n    if samples < 1:\r\n        raise ValueError(""Number of samples must be at least one"")\r\n    if n_mean < 0:\r\n        raise ValueError(""Mean photon number must be non-negative"")\r\n    if not 0 <= loss <= 1:\r\n        raise ValueError(""Loss parameter must take a value between zero and one"")\r\n\r\n    modes = graph.order()\r\n    photons = sum(orbit)\r\n    A = nx.to_numpy_array(graph)\r\n    mean_photon_per_mode = n_mean / float(modes)\r\n\r\n    p = sf.Program(modes)\r\n\r\n    # pylint: disable=expression-not-assigned\r\n    with p.context as q:\r\n        sf.ops.GraphEmbed(A, mean_photon_per_mode=mean_photon_per_mode) | q\r\n\r\n        if loss:\r\n            for _q in q:\r\n                sf.ops.LossChannel(1 - loss) | _q\r\n\r\n    eng = sf.LocalEngine(backend=""gaussian"")\r\n    result = eng.run(p)\r\n\r\n    prob = 0\r\n\r\n    for _ in range(samples):\r\n        sample = orbit_to_sample(orbit, modes)\r\n        prob += result.state.fock_prob(sample, cutoff=photons + 1)\r\n\r\n    prob = prob * orbit_cardinality(orbit, modes) / samples\r\n\r\n    return prob\r\n\r\n\r\ndef prob_event_mc(\r\n    graph: nx.Graph,\r\n    photon_number: int,\r\n    max_count_per_mode: int,\r\n    n_mean: float = 5,\r\n    samples: int = 1000,\r\n    loss: float = 0.0,\r\n) -> float:\r\n    r""""""Gives a Monte Carlo estimate of the GBS probability of a given event according to the input\r\n    graph.\r\n\r\n    To make this estimate, several samples from the event are drawn uniformly at random using\r\n    :func:`event_to_sample`. The GBS probabilities of these samples are then calculated and the\r\n    sum is used to create an estimate of the event probability.\r\n\r\n    **Example usage:**\r\n\r\n    >>> graph = nx.complete_graph(8)\r\n    >>> prob_event_mc(graph, 4, 2)\r\n    0.1395\r\n\r\n    Args:\r\n        graph (nx.Graph): input graph encoded in the GBS device\r\n        photon_number (int): number of photons in the event\r\n        max_count_per_mode (int): maximum number of photons per mode in the event\r\n        n_mean (float): total mean photon number of the GBS device\r\n        samples (int): number of samples used in the Monte Carlo estimation\r\n        loss (float): fraction of photons lost in GBS\r\n\r\n    Returns:\r\n        float: estimated orbit probability\r\n    """"""\r\n    if samples < 1:\r\n        raise ValueError(""Number of samples must be at least one"")\r\n    if n_mean < 0:\r\n        raise ValueError(""Mean photon number must be non-negative"")\r\n    if not 0 <= loss <= 1:\r\n        raise ValueError(""Loss parameter must take a value between zero and one"")\r\n    if photon_number < 0:\r\n        raise ValueError(""Photon number must not be below zero"")\r\n    if max_count_per_mode < 0:\r\n        raise ValueError(""Maximum number of photons per mode must be non-negative"")\r\n\r\n    modes = graph.order()\r\n    A = nx.to_numpy_array(graph)\r\n    mean_photon_per_mode = n_mean / float(modes)\r\n\r\n    p = sf.Program(modes)\r\n\r\n    # pylint: disable=expression-not-assigned\r\n    with p.context as q:\r\n        sf.ops.GraphEmbed(A, mean_photon_per_mode=mean_photon_per_mode) | q\r\n\r\n        if loss:\r\n            for _q in q:\r\n                sf.ops.LossChannel(1 - loss) | _q\r\n\r\n    eng = sf.LocalEngine(backend=""gaussian"")\r\n    result = eng.run(p)\r\n\r\n    prob = 0\r\n\r\n    for _ in range(samples):\r\n        sample = event_to_sample(photon_number, max_count_per_mode, modes)\r\n        prob += result.state.fock_prob(sample, cutoff=photon_number + 1)\r\n\r\n    prob = prob * event_cardinality(photon_number, max_count_per_mode, modes) / samples\r\n\r\n    return prob\r\n\r\n\r\ndef feature_vector_sampling(\r\n    samples: list, event_photon_numbers: list, max_count_per_mode: int = 2\r\n) -> list:\r\n    r""""""Calculates feature vector with respect to input samples.\r\n\r\n    The feature vector is composed of event probabilities with a fixed maximum photon count in\r\n    each mode but a range of total photon numbers specified by ``event_photon_numbers``.\r\n\r\n    Probabilities are reconstructed by measuring the occurrence of events in the input ``samples``.\r\n\r\n    **Example usage:**\r\n\r\n    >>> from strawberryfields.apps import data\r\n    >>> samples = data.Mutag0()\r\n    >>> feature_vector_sampling(samples, [2, 4, 6])\r\n    [0.19035, 0.2047, 0.1539]\r\n\r\n    Args:\r\n        samples (list[list[int]]): a list of samples\r\n        event_photon_numbers (list[int]): a list of events described by their total photon number\r\n        max_count_per_mode (int): maximum number of photons per mode for all events\r\n\r\n    Returns:\r\n        list[float]: a feature vector of event probabilities in the same order as\r\n        ``event_photon_numbers``\r\n    """"""\r\n    if min(event_photon_numbers) < 0:\r\n        raise ValueError(""Cannot request events with photon number below zero"")\r\n\r\n    if max_count_per_mode < 0:\r\n        raise ValueError(""Maximum number of photons per mode must be non-negative"")\r\n\r\n    n_samples = len(samples)\r\n\r\n    e = (sample_to_event(s, max_count_per_mode) for s in samples)\r\n    count = Counter(e)\r\n\r\n    return [count[p] / n_samples for p in event_photon_numbers]\r\n\r\n\r\ndef feature_vector_mc(\r\n    graph: nx.Graph,\r\n    event_photon_numbers: list,\r\n    max_count_per_mode: int = 2,\r\n    n_mean: float = 5,\r\n    samples: int = 1000,\r\n    loss: float = 0.0,\r\n) -> list:\r\n    r""""""Calculates feature vector using Monte Carlo estimation of event probabilities according to the\r\n    input graph.\r\n\r\n    The feature vector is composed of event probabilities with a fixed maximum photon count in\r\n    each mode but a range of total photon numbers specified by ``event_photon_numbers``.\r\n\r\n    Probabilities are reconstructed using Monte Carlo estimation.\r\n\r\n    **Example usage:**\r\n\r\n    >>> graph = nx.complete_graph(8)\r\n    >>> feature_vector_mc(graph, [2, 4, 6], 2)\r\n    [0.2115, 0.1457, 0.09085]\r\n\r\n    Args:\r\n        graph (nx.Graph): input graph\r\n        event_photon_numbers (list[int]): a list of events described by their total photon number\r\n        max_count_per_mode (int): maximum number of photons per mode for all events\r\n        n_mean (float): total mean photon number of the GBS device\r\n        samples (int): number of samples used in the Monte Carlo estimation\r\n        loss (float): fraction of photons lost in GBS\r\n\r\n    Returns:\r\n        list[float]: a feature vector of event probabilities in the same order as\r\n        ``event_photon_numbers``\r\n    """"""\r\n    if samples < 1:\r\n        raise ValueError(""Number of samples must be at least one"")\r\n    if n_mean < 0:\r\n        raise ValueError(""Mean photon number must be non-negative"")\r\n    if not 0 <= loss <= 1:\r\n        raise ValueError(""Loss parameter must take a value between zero and one"")\r\n    if min(event_photon_numbers) < 0:\r\n        raise ValueError(""Cannot request events with photon number below zero"")\r\n    if max_count_per_mode < 0:\r\n        raise ValueError(""Maximum number of photons per mode must be non-negative"")\r\n\r\n    return [\r\n        prob_event_mc(graph, photons, max_count_per_mode, n_mean, samples, loss)\r\n        for photons in event_photon_numbers\r\n    ]\r\n'"
strawberryfields/apps/subgraph.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nTools for users to find dense subgraphs of different sizes.\n\nThe search heuristic in this module works by resizing a collection of starting subgraphs and\nkeeping track of the densest identified. The starting subgraphs can be selected by sampling from\nGBS, resulting in candidates that are likely to be dense :cite:`arrazola2018using`.\n\n.. seealso::\n\n    :ref:`apps-subgraph-tutorial`\n\nAlgorithm\n^^^^^^^^^\n\nThe heuristic algorithm provided proceeds as follows. Each starting subgraph :math:`s` is resized\nto a range of sizes :math:`\\{k\\}_{k_{\\min}}^{k_{\\max}}`, resulting in the subgraphs\n:math:`s_{k}`. For a given size :math:`k`, a collection of the densest :math:`n` subgraphs\nidentified is recorded, meaning that :math:`s_{k}` is added to the collection only if it has\nsufficient density.\n\nThis algorithm returns a dictionary over the range of sizes specified, with each value being the\ncollection of densest-:math:`k` subgraphs. This collection is a list of tuple pairs specifying\nthe subgraph density and nodes.\n\nSubgraph resizing\n^^^^^^^^^^^^^^^^^\n\nThe key element of the :func:`search` algorithm is the resizing of each subgraph, allowing a\nrange of subgraph sizes to be tracked. Resizing proceeds in the :func:`resize` function by greedily\nadding or removing nodes to a subgraph one-at-a-time. Node selection is carried out by picking\nthe node with the greatest or least degree with respect to the subgraph. This function returns a\ndictionary over the range of sizes specified, with each value being the corresponding resized\nsubgraph.\n\nWhenever there are multiple candidate nodes with the same degree, there must be a choice of\nwhich node to add or remove. The supported choices are:\n\n- Select among candidate nodes uniformly at random;\n- Select the candidate node with the greatest node weight, settling remaining ties uniformly at\n  random.\n""""""\nfrom typing import Tuple, Union\n\nimport networkx as nx\nimport numpy as np\n\n\ndef search(\n    subgraphs: list,\n    graph: nx.Graph,\n    min_size: int,\n    max_size: int,\n    max_count: int = 10,\n    node_select: Union[str, np.ndarray, list] = ""uniform"",\n) -> dict:\n    """"""Search for dense subgraphs within an input size range.\n\n    For each subgraph from ``subgraphs``, this function resizes using :func:`resize` to the input\n    range specified by ``min_size`` and ``max_size``, resulting in a range of differently sized\n    subgraphs. This function loops over all elements of ``subgraphs`` and keeps track of the\n    ``max_count`` number of densest subgraphs identified for each size.\n\n    In both growth and shrink phases of :func:`resize`, there may be multiple candidate nodes with\n    equal degree to add to or remove from the subgraph. The method of selecting the node is\n    specified by the ``node_select`` argument, which can be either:\n\n    - ``""uniform""`` (default): choose a node from the candidates uniformly at random;\n    - A list or array: specifying the node weights of the graph, resulting in choosing the node\n      from the candidates with the highest weight (when growing) and lowest weight (when shrinking),\n      settling remaining ties by uniform random choice.\n\n    **Example usage:**\n\n    >>> s = data.Planted()\n    >>> g = nx.Graph(s.adj)\n    >>> s = sample.postselect(s, 16, 30)\n    >>> s = sample.to_subgraphs(s, g)\n    >>> search(s, g, 8, 9, max_count=3)\n    {9: [(0.9722222222222222, [21, 22, 23, 24, 25, 26, 27, 28, 29]),\n      (0.9722222222222222, [20, 21, 22, 24, 25, 26, 27, 28, 29]),\n      (0.9444444444444444, [20, 21, 22, 23, 24, 25, 26, 27, 29])],\n     8: [(1.0, [21, 22, 24, 25, 26, 27, 28, 29]),\n      (1.0, [21, 22, 23, 24, 25, 26, 27, 28]),\n      (1.0, [20, 21, 22, 24, 25, 26, 27, 29])]}\n\n    Args:\n        subgraphs (list[list[int]]): a list of subgraphs specified by their nodes\n        graph (nx.Graph): the input graph\n        min_size (int): minimum size to search for dense subgraphs\n        max_size (int): maximum size to search for dense subgraphs\n        max_count (int): maximum number of densest subgraphs to keep track of for each size\n        node_select (str, list or array): method of settling ties when more than one node of\n            equal degree can be added/removed. Can be ``""uniform""`` (default), or a NumPy array or\n            list containing node weights.\n\n    Returns:\n        dict[int, list[tuple[float, list[int]]]]: a dictionary of different sizes, each containing a\n        list of densest subgraphs reported as a tuple of subgraph density and subgraph nodes,\n        sorted in non-increasing order of density\n    """"""\n    dense = {}\n\n    for s in subgraphs:\n        r = resize(s, graph, min_size, max_size, node_select)\n\n        for size, subgraph in r.items():\n            r[size] = (nx.density(graph.subgraph(subgraph)), subgraph)\n\n        _update_dict(dense, r, max_count)\n\n    return dense\n\n\ndef _update_dict(d: dict, d_new: dict, max_count: int) -> None:\n    """"""Updates dictionary ``d`` with subgraph tuples contained in ``d_new``.\n\n    Subgraph tuples are a pair of values: a float specifying the subgraph density and a list of\n    integers specifying the subgraph nodes. Both ``d`` and ``d_new`` are dictionaries over\n    different subgraph sizes. The values of ``d`` are lists of subgraph tuples containing the top\n    densest subgraphs for a given size, with maximum length ``max_count``. The values of\n    ``d_new`` are candidate subgraph tuples that can be the result of resizing an input subgraph\n    over a range using :func:`resize`. We want to add these candidates to the list of subgraph\n    tuples in ``d`` to build up our collection of dense subgraphs.\n\n    Args:\n        d (dict[int, list[tuple[float, list[int]]]]): dictionary of subgraph sizes and\n            corresponding list of subgraph tuples\n        d_new (dict[int, tuple[float, list[int]]]): dictionary of subgraph sizes and corresponding\n            subgraph tuples that are candidates to be added to the list\n        max_count (int):  the maximum length of every subgraph tuple list\n\n    Returns:\n        None: this function modifies the dictionary ``d`` in place\n    """"""\n    for size, t in d_new.items():\n        l = d.setdefault(size, [t])\n        _update_subgraphs_list(l, t, max_count)\n\n\ndef _update_subgraphs_list(l: list, t: tuple, max_count: int) -> None:\n    """"""Updates list of top subgraphs with a candidate.\n\n    Here, the list ``l`` to be updated is a list of tuples with each tuple being a pair of\n    values: a float specifying the subgraph density and a list of integers specifying the\n    subgraph nodes. For example, ``l`` may be:\n\n    ``[(0.8, [0, 5, 9, 10]), (0.5, [1, 2, 5, 6]), (0.3, [0, 4, 6, 9])]``\n\n    We want to update ``l`` with a candidate tuple ``t``, which should be a pair specifying a\n    subgraph density and corresponding subgraph nodes. For example, we might want to add:\n\n    ``(0.4, [1, 4, 9, 10])``\n\n    This function checks:\n\n    - if ``t`` is already an element of ``l``, do nothing (i.e., so that ``l`` never has\n      repetitions)\n\n    - if ``len(l) < max_count``, add ``t``\n\n    - otherwise, if the density of ``t`` exceeds the minimum density of ``l`` , add ``t`` and\n      remove the element with the minimum density\n\n    - otherwise, if the density of ``t`` equals the minimum density of ``l``, flip a coin and\n      randomly swap in ``t`` with the minimum element of ``l``.\n\n    The list ``l`` is also sorted so that its first element is the subgraph with the highest\n    density.\n\n    Args:\n        l (list[tuple[float, list[int]]]): the list of subgraph tuples to be updated\n        t (tuple[float, list[int]): the candidate subgraph tuple\n        max_count (int): the maximum length of ``l``\n\n    Returns:\n        None: this function modifies ``l`` in place\n    """"""\n    t = (t[0], sorted(set(t[1])))\n\n    for _d, s in l:\n        if t[1] == s:\n            return\n\n    if len(l) < max_count:\n        l.append(t)\n        l.sort(reverse=True)\n        return\n\n    l_min = l[-1][0]\n\n    if t[0] > l_min:\n        l.append(t)\n        l.sort(reverse=True)\n        del l[-1]\n    elif t[0] == l_min:\n        if np.random.choice(2):\n            del l[-1]\n            l.append(t)\n            l.sort(reverse=True)\n\n    return\n\n\ndef resize(\n    subgraph: list,\n    graph: nx.Graph,\n    min_size: int,\n    max_size: int,\n    node_select: Union[str, np.ndarray, list] = ""uniform"",\n) -> dict:\n    """"""Resize a subgraph to a range of input sizes.\n\n    This function uses a greedy approach to iteratively add or remove nodes one at a time to an\n    input subgraph to reach the range of sizes specified by ``min_size`` and ``max_size``.\n\n    When growth is required, the algorithm examines all nodes from the remainder of the graph as\n    candidates and adds the single node with the highest degree relative to the rest of the\n    subgraph. This results in a graph that is one node larger, and if growth is still required,\n    the algorithm performs the procedure again.\n\n    When shrinking is required, the algorithm examines all nodes from within the subgraph as\n    candidates and removes the single node with lowest degree relative to the subgraph.\n\n    In both growth and shrink phases, there may be multiple candidate nodes with equal degree to\n    add to or remove from the subgraph. The method of selecting the node is specified by the\n    ``node_select`` argument, which can be either:\n\n    - ``""uniform""`` (default): choose a node from the candidates uniformly at random;\n    - A list or array: specifying the node weights of the graph, resulting in choosing the node\n      from the candidates with the highest weight (when growing) and lowest weight (when shrinking),\n      settling remaining ties by uniform random choice.\n\n    **Example usage:**\n\n    >>> s = data.Planted()\n    >>> g = nx.Graph(s.adj)\n    >>> s = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n    >>> resize(s, g, 8, 12)\n    {10: [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n     11: [11, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n     12: [0, 11, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n     9: [20, 21, 22, 24, 25, 26, 27, 28, 29],\n     8: [20, 21, 22, 24, 25, 26, 27, 29]}\n\n    Args:\n        subgraph (list[int]): a subgraph specified by a list of nodes\n        graph (nx.Graph): the input graph\n        min_size (int): minimum size for subgraph to be resized to\n        max_size (int): maximum size for subgraph to be resized to\n        node_select (str, list or array): method of settling ties when more than one node of\n            equal degree can be added/removed. Can be ``""uniform""`` (default), or a NumPy array or\n            list containing node weights.\n\n    Returns:\n        dict[int, list[int]]: a dictionary of different sizes with corresponding subgraph\n    """"""\n    nodes = graph.nodes()\n    subgraph = set(subgraph)\n    node_select, w = _validate_inputs(subgraph, graph, min_size, max_size, node_select)\n\n    starting_size = len(subgraph)\n\n    if min_size <= starting_size <= max_size:\n        resized = {starting_size: sorted(subgraph)}\n    else:\n        resized = {}\n\n    if max_size > starting_size:\n\n        grow_subgraph = graph.subgraph(subgraph).copy()\n\n        while grow_subgraph.order() < max_size:\n            grow_nodes = grow_subgraph.nodes()\n            complement_nodes = nodes - grow_nodes\n\n            degrees = np.array(\n                [(c, graph.subgraph(list(grow_nodes) + [c]).degree()[c]) for c in complement_nodes]\n            )\n            degrees_max = np.argwhere(degrees[:, 1] == degrees[:, 1].max()).flatten()\n\n            if node_select == ""uniform"":\n                to_add_index = np.random.choice(degrees_max)\n            elif node_select == ""weight"":\n                weights = np.array([w[degrees[n][0]] for n in degrees_max])\n                to_add_index = np.random.choice(np.where(weights == weights.max())[0])\n\n            to_add = degrees[to_add_index][0]\n            grow_subgraph.add_node(to_add)\n            new_size = grow_subgraph.order()\n\n            if min_size <= new_size <= max_size:\n                resized[new_size] = sorted(grow_subgraph.nodes())\n\n    if min_size < starting_size:\n\n        shrink_subgraph = graph.subgraph(subgraph).copy()\n\n        while shrink_subgraph.order() > min_size:\n            degrees = np.array(shrink_subgraph.degree)\n            degrees_min = np.argwhere(degrees[:, 1] == degrees[:, 1].min()).flatten()\n\n            if node_select == ""uniform"":\n                to_remove_index = np.random.choice(degrees_min)\n            elif node_select == ""weight"":\n                weights = np.array([w[degrees[n][0]] for n in degrees_min])\n                to_remove_index = np.random.choice(np.where(weights == weights.min())[0])\n\n            to_remove = degrees[to_remove_index][0]\n            shrink_subgraph.remove_node(to_remove)\n\n            new_size = shrink_subgraph.order()\n\n            if min_size <= new_size <= max_size:\n                resized[new_size] = sorted(shrink_subgraph.nodes())\n\n    return resized\n\n\ndef _validate_inputs(\n    subgraph: set,\n    graph: nx.Graph,\n    min_size: int,\n    max_size: int,\n    node_select: Union[str, np.ndarray, list] = ""uniform"",\n) -> Tuple:\n    """"""Validates input for the ``resize`` function.\n\n    This function checks:\n        - if ``subgraph`` is a valid subgraph of ``graph``;\n        - if ``min_size`` and ``max_size`` are sensible numbers;\n        - if ``node_select`` is either ``""uniform""`` or a NumPy array or list;\n        - if, when ``node_select`` is a NumPy array or list, that it is the correct size and that\n          ``node_select`` is changed to ``""weight""``.\n\n    This function returns the updated ``node_select`` and a dictionary mapping nodes to their\n    corresponding weights (weights default to unity if not specified).\n\n    Args:\n        subgraph (list[int]): a subgraph specified by a list of nodes\n        graph (nx.Graph): the input graph\n        min_size (int): minimum size for subgraph to be resized to\n        max_size (int): maximum size for subgraph to be resized to\n        node_select (str, list or array): method of settling ties when more than one node of\n            equal degree can be added/removed. Can be ``""uniform""`` (default), or a NumPy array or\n            list containing node weights.\n\n    Returns:\n        tuple[str, dict]: the updated ``node_select`` and a dictionary of node weights\n    """"""\n    if not subgraph.issubset(graph.nodes()):\n        raise ValueError(""Input is not a valid subgraph"")\n    if min_size < 1:\n        raise ValueError(""min_size must be at least 1"")\n    if max_size >= len(graph.nodes()):\n        raise ValueError(""max_size must be less than number of nodes in graph"")\n    if max_size < min_size:\n        raise ValueError(""max_size must not be less than min_size"")\n\n    if isinstance(node_select, (list, np.ndarray)):\n        if len(node_select) != graph.number_of_nodes():\n            raise ValueError(""Number of node weights must match number of nodes"")\n        w = {n: node_select[i] for i, n in enumerate(graph.nodes)}\n        node_select = ""weight""\n    else:\n        w = {n: 1 for i, n in enumerate(graph.nodes)}\n        if node_select != ""uniform"":\n            raise ValueError(""Node selection method not recognized"")\n\n    return node_select, w\n'"
strawberryfields/apps/vibronic.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nFunctions used for computing molecular vibronic spectra with GBS.\n\nIn vibronic spectroscopy, incoming light simultaneously excites a molecule to higher electronic and\nvibrational states. The difference in the energies of the initial and final states\ndetermines the frequency of the photons that are absorbed by the molecule. The probability of\nthe transition between two specific vibrational states are referred to as Franck-Condon factors\n(FCFs). They determine the intensity of absorption peaks in a vibronic spectrum. A GBS\ndevice can be programmed to provide samples that can be processed to obtain the molecular\nvibronic spectra. Theoretical background on computing vibronic spectra using GBS can be found in\n:cite:`huh2015boson` and :cite:`quesada2019franck`.\n\n.. seealso::\n\n    :ref:`apps-vibronic-tutorial`\n\nGBS parameters\n--------------\n\nThe Franck-Condon factor is given by\n\n.. math::\n    FCF = \\left | \\left \\langle \\mathbf{m} |U_{Dok}| \\mathbf{n} \\right \\rangle \\right | ^ 2,\n\nwhere :math:`|\\mathbf{m}\\rangle` and :math:`|\\mathbf{n}\\rangle` are the final and initial states,\nrespectively, and :math:`U_{Dok}` is known as the Doktorov operator which can be written in terms\nof displacement :math:`D_\\alpha`, squeezing :math:`\\Sigma_{r}`, and interferometer :math:`U_{1},\nU_{2}` operators as\n\n.. math::\n    U_{Dok} = D_\\alpha U_{2} \\Sigma_{r} U_{1}.\n\nA GBS device can be programmed with the :math:`U_{Dok}` operator obtained for a given molecule. The\nfunction :func:`gbs_params` transforms molecular parameters, namely vibrational frequencies,\ndisplacement vector and Duschinsky matrix, to the required GBS parameters. Additionally, this\nfunction computes two-mode squeezing parameters :math:`t`, from the molecule\'s temperature, which\nare required by the GBS algorithm to compute vibronic spectra for molecules at finite temperature.\n\nEnergies from samples\n---------------------\nIn the GBS algorithm for vibronic spectra, samples are identified with transition energies. The\nmost frequently sampled energies correspond to peaks of the vibronic spectrum. The function\n:func:`energies` converts samples to energies.\n""""""\nfrom typing import Tuple, Union\n\nfrom scipy.constants import c, h, k\n\nimport numpy as np\n\n\ndef gbs_params(\n    w: np.ndarray, wp: np.ndarray, Ud: np.ndarray, delta: np.ndarray, T: float = 0\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    r""""""Converts molecular information to GBS gate parameters.\n\n    **Example usage:**\n\n    >>> formic = data.Formic()\n    >>> w = formic.w  # ground state frequencies\n    >>> wp = formic.wp  # excited state frequencies\n    >>> Ud = formic.Ud  # Duschinsky matrix\n    >>> delta = formic.delta  # displacement vector\n    >>> T = 0  # temperature\n    >>> p = gbs_params(w, wp, Ud, delta, T)\n\n    Args:\n        w (array): normal mode frequencies of the initial electronic state in units of\n            :math:`\\mbox{cm}^{-1}`\n        wp (array): normal mode frequencies of the final electronic state in units of\n            :math:`\\mbox{cm}^{-1}`\n        Ud (array): Duschinsky matrix\n        delta (array): Displacement vector, with entries :math:`\\delta_i=\\sqrt{\\omega\'_i/\\hbar}d_i`,\n            and :math:`d_i` is the Duschinsky displacement\n        T (float): temperature (Kelvin)\n\n    Returns:\n        tuple[array, array, array, array, array]: the two-mode squeezing parameters :math:`t`,\n        the first interferometer unitary matrix :math:`U_{1}`, the squeezing parameters :math:`r`,\n        the second interferometer unitary matrix :math:`U_{2}`, and the displacement\n        parameters :math:`\\alpha`\n    """"""\n    if T < 0:\n        raise ValueError(""Temperature must be zero or positive"")\n    if T > 0:\n        t = np.arctanh(np.exp(-0.5 * h * (w * c * 100) / (k * T)))\n    else:\n        t = np.zeros(len(w))\n\n    U2, s, U1 = np.linalg.svd(np.diag(wp ** 0.5) @ Ud @ np.diag(w ** -0.5))\n    alpha = delta / np.sqrt(2)\n\n    return t, U1, np.log(s), U2, alpha\n\n\ndef energies(samples: list, w: np.ndarray, wp: np.ndarray) -> Union[list, float]:\n    r""""""Computes the energy :math:`E = \\sum_{k=1}^{N}m_k\\omega\'_k - \\sum_{k=N+1}^{2N}n_k\\omega_k`\n    of each GBS sample in units of :math:`\\text{cm}^{-1}`.\n\n    **Example usage:**\n\n    >>> samples = [[1, 1, 0, 0, 0, 0], [1, 2, 0, 0, 1, 1]]\n    >>> w  = np.array([300.0, 200.0, 100.0])\n    >>> wp = np.array([700.0, 600.0, 500.0])\n    >>> energies(samples, w, wp)\n    [1300.0, 1600.0]\n\n    Args:\n        samples (list[list[int]] or list[int]): a list of samples from GBS, or alternatively a\n            single sample\n        w (array): normal mode frequencies of initial state in units of :math:`\\text{cm}^{-1}`\n        wp (array): normal mode frequencies of final state in units of :math:`\\text{cm}^{-1}`\n\n    Returns:\n        list[float] or float: list of GBS sample energies in units of :math:`\\text{cm}^{-1}`, or\n        a single sample energy if only one sample is input\n    """"""\n    if not isinstance(samples[0], list):\n        return np.dot(samples[: len(samples) // 2], wp) - np.dot(samples[len(samples) // 2 :], w)\n\n    return [np.dot(s[: len(s) // 2], wp) - np.dot(s[len(s) // 2 :], w) for s in samples]\n'"
strawberryfields/backends/__init__.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""This package contains the modules that make up the\nStrawberry Fields backends. This includes photonic simulators,\nshared numerical operations, and states objects returned by\nstatevector simulators.\n\nLocal statevector simulators\n----------------------------\n\nBelow are all available local statevector backends currently\nprovided by Strawberry Fields. These simulators all run locally,\nprovide access to the state after simulation, and the state is\npreserved between engine runs.\n\n.. currentmodule:: strawberryfields.backends\n.. autosummary::\n    :toctree: api\n\n    FockBackend\n    GaussianBackend\n    ~tfbackend.TFBackend\n\n.. raw:: html\n\n    <div style=""display: none;"">\n\n.. currentmodule:: strawberryfields.backends\n.. autosummary::\n    :toctree: api\n\n    BaseFockState\n    ~gaussianbackend.states.GaussianState\n    ~tfbackend.states.FockStateTF\n\n.. raw:: html\n\n    </div>\n\nBackend API\n-----------\n\nA list of the abstract base classes that define the\nstatevector backend API\n\n.. currentmodule:: strawberryfields.backends\n.. autosummary::\n    :toctree: api\n\n    BaseState\n    BaseGaussianState\n    BaseBackend\n    BaseFock\n    BaseGaussian\n\nUtility modules\n---------------\n\nThe following utility modules are provided for\nbackend development.\n\n.. currentmodule:: strawberryfields.backends\n.. autosummary::\n    :toctree: api\n\n    shared_ops\n""""""\n\nfrom .base import BaseBackend, BaseFock, BaseGaussian, ModeMap\nfrom .gaussianbackend import GaussianBackend\nfrom .fockbackend import FockBackend\nfrom .states import BaseState, BaseGaussianState, BaseFockState\n\n\n__all__ = [\n    ""BaseBackend"",\n    ""BaseFock"",\n    ""BaseGaussian"",\n    ""FockBackend"",\n    ""GaussianBackend"",\n    ""TFBackend"",\n    ""BaseState"",\n    ""BaseFockState"",\n    ""BaseGaussianState"",\n]\n\n\nvirtual_backends = [""X8_01""]\n\nlocal_backends = {b.short_name: b for b in (BaseBackend, GaussianBackend, FockBackend)}\n\n\ndef load_backend(name):\n    """"""Loads the specified backend by mapping a string\n    to the backend type, via the ``local_backends``\n    dictionary. Note that this function is used by the\n    frontend only, and should not be user-facing.\n    """"""\n    if name == ""tf"":\n        # treat the tensorflow backend differently, to\n        # isolate the import of tensorflow\n        from .tfbackend import TFBackend\n\n        return TFBackend()\n\n    if name in virtual_backends:\n        # Backend is a remote device/simulator, that has a\n        # defined circuit spec, but no local backend class.\n        # By convention, the short name and corresponding\n        # circuit spec are the same.\n        backend_attrs = {""short_name"": name, ""circuit_spec"": name}\n        backend_class = type(name, (BaseBackend,), backend_attrs)\n        return backend_class()\n\n    if name in local_backends:\n        backend = local_backends[name]()\n        return backend\n\n    raise ValueError(""Backend \'{}\' is not supported."".format(name))\n'"
strawberryfields/backends/base.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""This module contains the abstract base classes that define Strawberry Fields\ncompatible statevector simulator backends.""""""\n\n# pylint: disable=no-self-use,missing-docstring\n\n\nclass NotApplicableError(TypeError):\n    """"""Exception raised by the backend when the user attempts an unsupported operation.\n    E.g. :meth:`measure_fock` on a Gaussian backend.\n    Conceptually different from NotImplementedError (which means ""not implemented, but at some point may be"").\n    """"""\n\n\nclass ModeMap:\n    """"""\n    Simple internal class for maintaining a map of existing modes.\n    """"""\n\n    def __init__(self, num_subsystems):\n        self._init = num_subsystems\n        #: list[int]: _map[k] is the internal index used by the backend for\n        # computational mode k, or None if the mode has been deleted\n        self._map = list(range(num_subsystems))\n\n    def reset(self):\n        """"""reset the modemap to the initial state""""""\n        self._map = list(range(self._init))\n\n    def _single_mode_valid(self, mode):\n        if mode is None:\n            return False\n\n        if 0 <= mode < len(self._map):\n            return True\n\n        return False\n\n    def _reduce_to_existing_modes(self, modes):\n        # Reduces modes to only those which are not None in the map\n        if isinstance(modes, int):\n            modes = [modes]\n        return [m for m in modes if m in self._map]\n\n    def remap(self, modes):\n        """"""Remaps the mode list""""""\n        if isinstance(modes, int):\n            modes = [modes]\n            was_int = True\n        else:\n            was_int = False\n\n        modes_list = [self._map[m] for m in modes]\n\n        if was_int:\n            return modes_list[0]\n\n        return modes_list\n\n    def valid(self, modes):\n        """"""checks if the mode list is valid""""""\n        if modes is None:\n            return False\n\n        if isinstance(modes, int):\n            modes = [modes]\n\n        # pylint: disable=len-as-condition\n        if len(modes) == 0 or len(modes) > len(self._map):\n            return False\n\n        for m in modes:\n            if not self._single_mode_valid(m):\n                return False\n\n        return True\n\n    def show(self):\n        """"""Returns the mapping""""""\n        return self._map\n\n    def delete(self, modes):\n        """"""Deletes a mode""""""\n        if isinstance(modes, int):\n            modes = [modes]\n        if self.valid(modes):\n            new_map = []\n            ctr = 0\n            for m in range(len(self._map)):\n                if m in modes or self._map[m] is None:\n                    new_map.append(None)\n                else:\n                    new_map.append(ctr)\n                    ctr += 1\n            self._map = new_map\n        else:\n            raise ValueError(""Specified modes for deleting are invalid."")\n\n    def add(self, num_modes):\n        """"""Adds a mode""""""\n        num_active_modes = len([m for m in self._map if m is not None])\n        self._map += list(range(num_active_modes, num_active_modes + num_modes))\n\n\nclass BaseBackend:\n    """"""Abstract base class for backends.""""""\n\n    # pylint: disable=too-many-public-methods\n\n    #: str: short name of the backend\n    short_name = ""base""\n    #: str, None: Short name of the CircuitSpecs class used to validate Programs for this backend. None if no validation is required.\n    circuit_spec = None\n\n    def __init__(self):\n        self._supported = {}\n\n    def __str__(self):\n        """"""String representation.""""""\n        return self.__class__.__name__\n\n    def supports(self, name):\n        """"""Check whether the backend supports the given operating mode.\n\n        Currently supported operating modes are:\n\n        * ""gaussian"": for manipulations in the Gaussian representation using the\n          displacements and covariance matrices\n        * ""fock_basis"": for manipulations in the Fock representation\n        * ""mixed_states"": for representations where the quantum state is mixed\n        * ""batched"": allows for a multiple circuits to be simulated in parallel\n\n        Args:\n            name (str): name of the operating mode which we are checking support for\n\n        Returns:\n            bool: True if this backend supports that operating mode.\n        """"""\n        return self._supported.get(name, False)\n\n    def begin_circuit(self, num_subsystems, **kwargs):\n        r""""""Instantiate a quantum circuit.\n\n        Instantiates a representation of a quantum optical state with ``num_subsystems`` modes.\n        The state is initialized to vacuum.\n\n        The modes in the circuit are indexed sequentially using integers, starting from zero.\n        Once an index is assigned to a mode, it can never be re-assigned to another mode.\n        If the mode is deleted its index becomes invalid.\n        An operation acting on an invalid or unassigned mode index raises an ``IndexError`` exception.\n\n        Args:\n            num_subsystems (int): number of modes in the circuit\n\n        Keyword Args:\n            cutoff_dim (int): Hilbert space truncation dimension (for Fock basis backends only)\n            batch_size (int): (optional) batch-axis dimension, enables batched operation if > 1 (for the TF backend only)\n        """"""\n        # BaseBackend can be instantiated for testing purposes, even though it does not do anything.\n\n    def add_mode(self, n=1):\n        """"""Add modes to the circuit.\n\n        The new modes are initialized to the vacuum state.\n        They are assigned mode indices sequentially, starting from the first unassigned index.\n\n        Args:\n            n (int): number of modes to add\n\n        Returns:\n            list[int]: indices of the newly added modes\n        """"""\n        raise NotImplementedError\n\n    def del_mode(self, modes):\n        """"""Delete modes from the circuit.\n\n        The deleted modes are traced out.\n        As a result the state may have to be described using a density matrix.\n\n        The indices of the deleted modes become invalid for the lifetime of the circuit object.\n        They will never be reassigned to other modes.\n        Deleting a mode that has already been deleted raises an ``IndexError`` exception.\n\n        Args:\n            modes (Sequence[int]): mode numbers to delete\n        """"""\n        raise NotImplementedError\n\n    def get_modes(self):\n        """"""Return a list of the active modes for the circuit.\n\n        A mode is active if it has been created and has not been deleted.\n\n        Returns:\n            list[int]: sorted list of active (assigned, not invalid) mode indices\n        """"""\n        raise NotImplementedError\n\n    def reset(self, pure=True, **kwargs):\n        """"""Reset the circuit so that all the modes are in the vacuum state.\n\n        After the reset the circuit is in the same state as it was after\n        the last :meth:`begin_circuit` call. It will have the original number\n        of modes, all initialized in the vacuum state. Some circuit parameters\n        may be changed during the reset, see the keyword args below.\n\n        Args:\n            pure (bool): if True, initialize the circuit in a pure state representation\n                (will use a mixed state representation if pure is False)\n\n        Keyword Args:\n            cutoff_dim (int): new Hilbert space truncation dimension (for Fock basis backends only)\n        """"""\n        raise NotImplementedError\n\n    def prepare_vacuum_state(self, mode):\n        """"""Prepare the vacuum state in the specified mode.\n\n        The requested mode is traced out and replaced with the vacuum state.\n        As a result the state may have to be described using a density matrix.\n\n        Args:\n            mode (int): which mode to prepare the vacuum state in\n        """"""\n        raise NotImplementedError\n\n    def prepare_coherent_state(self, alpha, mode):\n        r""""""Prepare a coherent state in the specified mode.\n\n        The requested mode is traced out and replaced with the coherent state :math:`\\ket{\\alpha}`.\n        As a result the state may have to be described using a density matrix.\n\n        Args:\n            alpha (complex): coherent state displacement parameter\n            mode (int): which mode to prepare the coherent state in\n        """"""\n        raise NotImplementedError\n\n    def prepare_squeezed_state(self, r, phi, mode):\n        r""""""Prepare a squeezed vacuum state in the specified mode.\n\n        The requested mode is traced out and replaced with the squeezed state :math:`\\ket{z}`,\n        where :math:`z=re^{i\\phi}`.\n        As a result the state may have to be described using a density matrix.\n\n        Args:\n            r (float): squeezing amplitude\n            phi (float): squeezing angle\n            mode (int): which mode to prepare the squeezed state in\n        """"""\n        raise NotImplementedError\n\n    def prepare_displaced_squeezed_state(self, alpha, r, phi, mode):\n        r""""""Prepare a displaced squeezed state in the specified mode.\n\n        The requested mode is traced out and replaced with the displaced squeezed\n        state state :math:`\\ket{\\alpha, z}`, where :math:`z=re^{i\\phi}`.\n        As a result the state may have to be described using a density matrix.\n\n        Args:\n            alpha (complex): displacement parameter\n            r (float): squeezing amplitude\n            phi (float): squeezing angle\n            mode (int): which mode to prepare the squeezed state in\n        """"""\n        raise NotImplementedError\n\n    def prepare_thermal_state(self, nbar, mode):\n        r""""""Prepare a thermal state in the specified mode.\n\n        The requested mode is traced out and replaced with the thermal state :math:`\\rho(nbar)`.\n        As a result the state may have to be described using a density matrix.\n\n        Args:\n            nbar (float): thermal population (mean photon number) of the mode\n            mode (int): which mode to prepare the thermal state in\n        """"""\n        raise NotImplementedError\n\n    def rotation(self, phi, mode):\n        """"""Apply the phase-space rotation operation to the specified mode.\n\n        Args:\n            phi (float): rotation angle\n            mode (int): which mode to apply the rotation to\n        """"""\n        raise NotImplementedError\n\n    def displacement(self, alpha, mode):\n        """"""Apply the displacement operation to the specified mode.\n\n        Args:\n            alpha (complex): displacement parameter\n            mode (int): which mode to apply the displacement to\n        """"""\n        raise NotImplementedError\n\n    def squeeze(self, z, mode):\n        """"""Apply the squeezing operation to the specified mode.\n\n        Args:\n            z (complex): squeezing parameter\n            mode (int): which mode to apply the squeeze to\n        """"""\n        raise NotImplementedError\n\n    def beamsplitter(self, t, r, mode1, mode2):\n        """"""Apply the beamsplitter operation to the specified modes.\n\n        It is assumed that :math:`|r|^2+|t|^2 = t^2+|r|^2=1`, i.e that t is real.\n\n        Args:\n            t (float): transmitted amplitude\n            r (complex): reflected amplitude (with phase)\n            mode1 (int): first mode that beamsplitter acts on\n            mode2 (int): second mode that beamsplitter acts on\n        """"""\n        raise NotImplementedError\n\n    def loss(self, T, mode):\n        r""""""Perform a loss channel operation on the specified mode.\n\n        Args:\n            T (float): loss parameter, :math:`0\\leq T\\leq 1`.\n            mode (int): index of mode where operation is carried out\n        """"""\n        raise NotImplementedError\n\n    def thermal_loss(self, T, nbar, mode):\n        r""""""Perform a thermal loss channel operation on the specified mode.\n\n        Args:\n            T (float): loss parameter, :math:`0\\leq T\\leq 1`.\n            nbar (float): mean photon number of the environment thermal state\n            mode (int): index of mode where operation is carried out\n        """"""\n        raise NotImplementedError\n\n    def measure_homodyne(self, phi, mode, shots=1, select=None, **kwargs):\n        r""""""Measure a :ref:`phase space quadrature <homodyne>` of the given mode.\n\n        For the measured mode, samples the probability distribution\n        :math:`f(q) = \\bra{q_\\phi} \\rho \\ket{q_\\phi}`\n        and returns the sampled value.\n        Here :math:`\\ket{q_\\phi}` is the eigenstate of the operator\n\n        .. math::\n           \\hat{q}_\\phi = \\sqrt{2/\\hbar}(\\cos(\\phi)\\hat{x} +\\sin(\\phi)\\hat{p}) = e^{-i\\phi} \\hat{a} +e^{i\\phi} \\hat{a}^\\dagger.\n\n        .. note::\n           This method is :math:`\\hbar` independent.\n           The returned values can be converted to conventional position/momentum\n           eigenvalues by multiplying them with :math:`\\sqrt{\\hbar/2}`.\n\n        Updates the current state such that the measured mode is reset\n        to the vacuum state. This is because we cannot represent exact position or\n        momentum eigenstates in any of the backends, and experimentally the photons\n        are destroyed in a homodyne measurement.\n\n        Args:\n            phi (float): phase angle of the quadrature to measure (x: :math:`\\phi=0`, p: :math:`\\phi=\\pi/2`)\n            mode (int): which mode to measure\n            shots (int): number of measurement samples to obtain\n            select (None or float): If not None: desired value of the measurement result.\n                Enables post-selection on specific measurement results instead of random sampling.\n\n        Keyword arguments can be used to pass additional parameters to the backend.\n        Options for such arguments will be documented in the respective subclasses.\n\n        Returns:\n            float: measured value\n        """"""\n        raise NotImplementedError\n\n    def measure_fock(self, modes, shots=1, select=None, **kwargs):\n        """"""Measure the given modes in the Fock basis.\n\n        .. note::\n          When ``shots == 1``, updates the current system state to the\n          conditional state of that measurement result. When ``shots > 1``, the\n          system state is not updated.\n\n        Args:\n            modes (Sequence[int]): which modes to measure\n            shots (int): number of measurement samples to obtain\n            select (None or Sequence[int]): If not None: desired values of the measurement results.\n                Enables post-selection on specific measurement results instead of random sampling.\n                ``len(select) == len(modes)`` is required.\n        Returns:\n            tuple[int]: measurement results\n        """"""\n        raise NotImplementedError\n\n    def measure_threshold(self, modes, shots=1, select=None, **kwargs):\n        """"""Measure the given modes in the thresholded Fock basis, i.e., zero or nonzero photons).\n\n        .. note::\n\n            When :code:``shots == 1``, updates the current system state to the conditional state of that\n            measurement result. When :code:``shots > 1``, the system state is not updated.\n\n        Args:\n            modes (Sequence[int]): which modes to measure\n            shots (int): number of measurement samples to obtain\n            select (None or Sequence[int]): If not None: desired values of the measurement results.\n                Enables post-selection on specific measurement results instead of random sampling.\n                ``len(select) == len(modes)`` is required.\n        Returns:\n            tuple[int]: measurement results\n        """"""\n        raise NotImplementedError\n\n    def is_vacuum(self, tol=0.0, **kwargs):\n        r""""""Test whether the current circuit state is vacuum (up to given tolerance).\n\n        Returns True iff :math:`|\\bra{0} \\rho \\ket{0} -1| \\le` ``tol``, i.e.,\n        the fidelity of the current circuit state with the vacuum state is within\n        the given tolerance from 1.\n\n        Args:\n            tol (float): numerical tolerance\n\n        Returns:\n            bool: True iff current state is vacuum up to tolerance tol\n        """"""\n        raise NotImplementedError\n\n    def state(self, modes=None, **kwargs):\n        r""""""Returns the state of the quantum simulation.\n\n        Args:\n            modes (int or Sequence[int] or None): Specifies the modes to restrict the return state to.\n                None returns the state containing all the modes.\n                The returned state contains the requested modes in the given order, i.e.,\n                ``modes=[3,0]`` results in a two mode state being returned with the first mode being\n                subsystem 3 and the second mode being subsystem 0.\n        Returns:\n            BaseState: state description, specific child class depends on the backend\n        """"""\n        raise NotImplementedError\n\n\n# =============================\n# Fock-basis backends\n# =============================\n\n\nclass BaseFock(BaseBackend):\n    """"""Abstract base class for backends capable of Fock state manipulation.""""""\n\n    def __init__(self):\n        super().__init__()\n        self._supported[""fock_basis""] = True\n\n    def get_cutoff_dim(self):\n        """"""Returns the Hilbert space cutoff dimension used.\n\n        Returns:\n            int: cutoff dimension\n        """"""\n        raise NotImplementedError\n\n    def prepare_fock_state(self, n, mode):\n        r""""""Prepare a Fock state in the specified mode.\n\n        The requested mode is traced out and replaced with the Fock state :math:`\\ket{n}`.\n        As a result the state may have to be described using a density matrix.\n\n        Args:\n            n (int): Fock state to prepare\n            mode (int): which mode to prepare the Fock state in\n        """"""\n        raise NotImplementedError\n\n    def prepare_ket_state(self, state, modes):\n        r""""""Prepare the given ket state in the specified modes.\n\n        The requested modes are traced out and replaced with the given ket state\n        (in the Fock basis). As a result the state may have to be described using a\n        density matrix.\n\n        Args:\n            state (array): Ket state in the Fock basis.\n                The state can be given in either vector form, with one index,\n                or tensor form, with one index per mode. For backends supporting batched\n                mode, state can be a batch of such vectors or tensors.\n            modes (int or Sequence[int]): Modes to prepare the state in.\n                If modes is not ordered this is taken into account when preparing the state,\n                i.e., when a two mode state is prepared in modes=[3,1], then the first\n                mode of state goes into mode 3 and the second mode goes into mode 1 of the simulator.\n        """"""\n        raise NotImplementedError\n\n    def prepare_dm_state(self, state, modes):\n        r""""""Prepare the given mixed state in the specified modes.\n\n        The requested modes are traced out and replaced with the given density matrix\n        state (in the Fock basis).\n        As a result the state will be described using a density matrix.\n\n        Args:\n            state (array): Density matrix in the Fock basis.\n                The state can be given in either matrix form, with two indices, or tensor\n                form, with two indices per mode. For backends supporting batched mode,\n                state can be a batch of such matrices or tensors.\n            modes (int or Sequence[int]): which mode to prepare the state in\n                If modes is not ordered this is take into account when preparing the\n                state, i.e., when a two mode state is prepared in modes=[3,1], then\n                the first mode of state goes into mode 3 and the second mode goes\n                into mode 1 of the simulator.\n        """"""\n        raise NotImplementedError\n\n    def cubic_phase(self, gamma, mode):\n        r""""""Apply the cubic phase operation to the specified mode.\n\n        Applies the operation\n\n        .. math::\n           \\exp\\left(i \\frac{\\gamma}{6} (\\hat{a} +\\hat{a}^\\dagger)^3\\right)\n\n        to the specified mode.\n\n        .. note::\n           This method is :math:`\\hbar` independent.\n           The usual definition of the cubic phase gate is :math:`\\hbar` dependent:\n\n           .. math::\n              V(\\gamma\') = \\exp\\left(i \\frac{\\gamma\'}{3\\hbar} \\hat{x}^3\\right) = \\exp\\left(i \\frac{\\gamma\' \\sqrt{\\hbar/2}}{6} (\\hat{a} +\\hat{a}^\\dagger)^3\\right).\n\n           Hence the cubic phase gate :math:`V(\\gamma\')` is executed on a backend by scaling the\n           :math:`\\gamma\'` parameter by :math:`\\sqrt{\\hbar/2}` and then passing it to this method,\n           much in the way the :math:`\\hbar` dependent `X` and `Z` gates are implemented through the\n           :math:`\\hbar` independent :meth:`~BaseBackend.displacement` method.\n\n        .. warning::\n            The cubic phase gate can suffer heavily from numerical inaccuracies\n            due to finite-dimensional cutoffs in the Fock basis. The gate\n            implementation in Strawberry Fields is unitary, but it\n            does not implement an exact cubic phase gate. The Kerr gate\n            provides an alternative non-Gaussian gate.\n\n        Args:\n            gamma (float): scaled cubic phase shift, :math:`\\gamma = \\gamma\' \\sqrt{\\hbar/2}`\n            mode (int): which mode to apply it to\n        """"""\n        raise NotImplementedError\n\n    def kerr_interaction(self, kappa, mode):\n        r""""""Apply the Kerr interaction :math:`\\exp{(i\\kappa \\hat{n}^2)}` to the specified mode.\n\n        Args:\n            kappa (float): strength of the interaction\n            mode (int): which mode to apply it to\n        """"""\n        raise NotImplementedError\n\n    def cross_kerr_interaction(self, kappa, mode1, mode2):\n        r""""""Apply the two mode cross-Kerr interaction :math:`\\exp{(i\\kappa \\hat{n}_1\\hat{n}_2)}` to the specified modes.\n\n        Args:\n            kappa (float): strength of the interaction\n            mode1 (int): first mode that cross-Kerr interaction acts on\n            mode2 (int): second mode that cross-Kerr interaction acts on\n        """"""\n        raise NotImplementedError\n\n    def state(self, modes=None, **kwargs):\n        r""""""Returns the state of the quantum simulation.\n\n        See :meth:`.BaseBackend.state`.\n\n        Returns:\n            BaseFockState: state description\n        """"""\n        raise NotImplementedError\n\n\n# ==============================\n# Gaussian-formulation backends\n# ==============================\n\n\nclass BaseGaussian(BaseBackend):\n    """"""Abstract base class for backends that are only capable of Gaussian state manipulation.""""""\n\n    def __init__(self):\n        super().__init__()\n        self._supported[""gaussian""] = True\n\n    def measure_heterodyne(self, mode, shots=1, select=None):\n        r""""""Perform a heterodyne measurement on the given mode.\n\n        Updates the current state of the circuit such that the measured mode is reset to the vacuum state.\n\n        Args:\n            mode (int): which mode to measure\n            shots (int): number of measurement samples to obtain\n            select (None or complex): If not None: desired value of the measurement result.\n                Enables post-selection on specific measurement results instead of random sampling.\n\n        Returns:\n            complex: measured value\n        """"""\n        raise NotImplementedError\n\n    def prepare_gaussian_state(self, r, V, modes):\n        r""""""Prepare a Gaussian state.\n\n        The specified modes are traced out and replaced with a Gaussian state\n        provided via a vector of means and a covariance matrix.\n\n        .. note::\n           This method is :math:`\\hbar` independent.\n           The input arrays are the means and covariance of the\n           :math:`a+a^\\dagger` and :math:`-i(a-a^\\dagger)` operators.\n           They are obtained by dividing the xp means by :math:`\\sqrt{\\hbar/2}`\n           and the xp covariance by :math:`\\hbar/2`.\n\n        Args:\n            r (array): vector of means in xp ordering\n            V (array): covariance matrix in xp ordering\n            modes (int or Sequence[int]): Which modes to prepare the state in.\n                If the modes are not sorted, this is taken into account when preparing the state.\n                I.e., when a two mode state is prepared with ``modes=[3,1]``, the first\n                mode of the given state goes into mode 3 and the second mode goes into mode 1.\n        """"""\n        raise NotImplementedError\n\n    def get_cutoff_dim(self):\n        raise NotApplicableError\n\n    def prepare_fock_state(self, n, mode):\n        raise NotApplicableError\n\n    def prepare_ket_state(self, state, mode):\n        raise NotApplicableError\n\n    def prepare_dm_state(self, state, mode):\n        raise NotApplicableError\n\n    def cubic_phase(self, gamma, mode):\n        raise NotApplicableError\n\n    def kerr_interaction(self, kappa, mode):\n        raise NotApplicableError\n\n    def cross_kerr_interaction(self, kappa, mode1, mode2):\n        raise NotApplicableError\n\n    def state(self, modes=None, **kwargs):\n        """"""Returns the state of the quantum simulation.\n\n        See :meth:`.BaseBackend.state`.\n\n        Returns:\n            BaseGaussianState: state description\n        """"""\n        raise NotImplementedError\n'"
strawberryfields/backends/shared_ops.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Common shared operations that can be used by backends""""""\n\nimport os\nimport functools\nimport re\nimport itertools\nfrom bisect import bisect\nimport pkg_resources\n\nimport numpy as np\nimport scipy as sp\nfrom scipy.special import binom\nfrom scipy.special import gammaln as lg\nfrom scipy.linalg import qr\n\nDATA_PATH = pkg_resources.resource_filename(""strawberryfields"", ""backends/data"")\ndef_type = np.complex128\n\n\n# ================================+\n#   Fock space shared operations |\n# ================================+\n\n\n@functools.lru_cache()\ndef find_dim_files(regex, D, directory=None, name=""""):\n    r""""""Return files matching a certain regex for specified dimension D.\n\n    If no such file satisfying this condition exists, then an Exception\n    is returned.\n\n    Args:\n        regex (str): regex matching the allowed file names. Should contain\n        ""(\\d+)"", this represents the Fock dimension in the file name.\n        D (int): the dimension D\n        directory (str): location to load the precomputed beamsplitter\n            factors from. By default, this will be the Strawberry Fields data directory.\n    """"""\n    if directory is None:\n        directory = DATA_PATH\n    else:\n        check_dir = os.path.isdir(directory)\n        if not check_dir:  # pragma: no cover\n            raise NotADirectoryError(""Directory {} does not exist!"".format(directory))\n\n    files = [f for f in os.listdir(directory) if re.match(regex, f)]\n    avail_dims = sorted([int(re.findall(r""\\d+"", f)[0]) for f in files])\n\n    idx = bisect(avail_dims, D - 1)\n    if idx + 1 > len(avail_dims):\n        raise FileNotFoundError(\n            ""File containing {} factors does not exist ""\n            ""for dimension {} in directory {}"".format(name, D, directory)\n        )\n\n    return avail_dims[idx], directory\n\n\n@functools.lru_cache()\ndef generate_bs_factors(D):\n    r""""""Generate beamsplitter factors in the Fock basis.\n\n    This function generates the beamsplitter prefactors,\n\n        .. math::\n            prefac_{N,n,M,m,k} = (-1)^{N-k}\\sqrt{\\binom{n,k}\\binom{m,N-k}\\binom{N,k}\\binom{M,n-k}}\n\n    for a specific cutoff dimension :math:`D`.\n\n    Note that the last dimension will only contain non-zero values\n    for indices ``0`` to ``n``.\n\n    Args:\n        D (int): generate prefactors for :math:`D` dimensions.\n    """"""\n    prefac = np.zeros([D] * 5, dtype=def_type)\n\n    for (N, M, n) in itertools.product(*([range(D)] * 3)):\n        m = N + M - n\n        k = np.arange(n + 1)\n        if 0 <= m < D:\n            # pylint: disable=bad-whitespace\n            prefac[N, n, M, m, : n + 1] = (-1.0) ** (N - k) * np.sqrt(\n                binom(n, k) * binom(m, N - k) * binom(N, k) * binom(M, n - k)\n            )\n\n    return prefac\n\n\n@functools.lru_cache()\ndef load_bs_factors(D, directory=None):\n    r""""""Load precomputed beamsplitter factors in the Fock basis.\n\n    This function searches the data directory for a BS prefactor file\n    containing for cutoff dimension higher or equal to that requested\n    (``D``). It then reshapes the rank-2 sparse array to a\n    :math:`D\\times D\\times D\\times D\\times D` dense array.\n\n    If no such file satisfying this condition exists, then an Exception\n    is returned.\n\n    Args:\n        D (int): load prefactors containing at least ``D`` dimensions.\n        directory (str): location to load the precomputed beamsplitter\n            factors from. By default, this will be the Strawberry Fields data directory.\n    """"""\n\n    regex = r""fock_beamsplitter_factors_(\\d+)\\.npz""\n    load_dim, location = find_dim_files(regex, D, directory=directory, name=""beamsplitter"")\n    filename = ""fock_beamsplitter_factors_{}.npz"".format(load_dim)\n    prefac = sp.sparse.load_npz(os.path.join(location, filename))\n    return np.reshape(prefac.toarray(), [load_dim] * 5)\n\n\ndef save_bs_factors(prefac, directory=None):\n    r""""""Saves precomputed beamsplitter factors in the Fock basis to a file.\n\n    This function reshapes the rank-5 array with dimension\n    :math:`D\\times D\\times D\\times D\\times D` to a rank-2 array of dimension\n    :math:`D^4\\times D`, before converting it to a sparse array, and saving\n    it to a file in the specified directory.\n\n    Args:\n        prefac (numpy.array): the Numpy array containing the precomputed beamsplitter\n            prefactors in the Fock basis. Must be of size [D,D,D,D,D] for some integer D\n        directory (str): location to save the precomputed beamsplitter factors. By default,\n            this will be the Strawberry Fields data directory.\n    """"""\n    if directory is None:\n        directory = DATA_PATH\n    else:\n        check_dir = os.path.isdir(directory)\n        if not check_dir:  # pragma: no cover\n            raise NotADirectoryError(""Directory {} does not exist!"".format(directory))\n\n    D = prefac.shape[0]\n    filename = ""fock_beamsplitter_factors_{}.npz"".format(D)\n\n    prefac_rank2 = np.reshape(prefac, ((D) ** 4, D), order=""C"")\n    prefac_sparse = sp.sparse.csc_matrix(prefac_rank2)\n\n    sp.sparse.save_npz(os.path.join(directory, filename), prefac_sparse)\n\n\n@functools.lru_cache()\ndef squeeze_parity(D):\n    r""""""Creates the parity prefactor needed for squeezing in the Fock basis.\n\n    .. math::\n        \\text{\\sigma}_{N,k} = \\begin{cases}\n            (N-k)/2, & \\text{mod}(N-k,2) \\neq 0\\\\\n            0, &\\text{otherwise}\n        \\end{cases}\n\n    Args:\n        D (numpy.array): generate the prefactors for a Fock truncation of :math:`D`.\n    """"""\n    k = np.int(np.ceil(D / 4) * 4)\n    v = np.full(k, 1)\n    v[1::2] = 0\n    v[2::4] = -1\n    v = np.vstack([np.roll(v, i) for i in range(k)])\n    return v[:D, :D]\n\n\n@functools.lru_cache()\ndef generate_squeeze_factors(D):\n    r""""""Generate squeezing factors in the Fock basis.\n\n    This function generates the squeezing prefactors,\n\n        .. math::\n            prefac_{N,n,k} = \\frac{\\sigma_{N,k}\\sqrt{n!N!}}\n            {k!\\left(\\frac{n-k}{2}\\right)!\\left(\\frac{N-k}{2}\\right)!}\n\n    where :math:`\\sigma_{N,k}` is the parity, given by :func:`~.squeeze_parity`.\n\n    Args:\n        D (int): generate prefactors for :math:`D` dimensions.\n    """"""\n    dim_array = np.arange(D)\n    N = dim_array.reshape((-1, 1, 1))\n    n = dim_array.reshape((1, -1, 1))\n    k = dim_array.reshape((1, 1, -1))\n\n    # we only perform the sum when n+N is divisible by 2\n    # in which case we sum 0 <= k <= min(N,n)\n    mask = np.logical_and((n + N) % 2 == 0, k <= np.minimum(N, n))\n\n    # need to use np.power to avoid taking the root of a negative\n    # in the numerator (these are discarded by the mask anyway)\n    signs = squeeze_parity(D).reshape([D, 1, D])\n    logfac = np.where(\n        mask,\n        0.5 * (lg(n + 1) + lg(N + 1)) - lg(k + 1) - lg((n - k) / 2 + 1) - lg((N - k) / 2 + 1),\n        0,\n    )\n\n    if D <= 600:\n        prefactor = np.exp(logfac, dtype=np.float64) * signs * mask\n    else:\n        prefactor = np.exp(logfac, dtype=np.float128) * signs * mask\n\n    return prefactor\n\n\ndef save_squeeze_factors(prefac, directory=None):\n    r""""""Saves precomputed squeeze factors in the Fock basis to a file.\n\n    This function reshapes the rank-3 array with dimension\n    :math:`D\\times D\\times D` to a rank-2 array of dimension\n    :math:`D^2\\times D`, before converting it to a sparse array, and saving\n    it to a file in the specified directory.\n\n    Args:\n        prefac (numpy.array): the Numpy array containing the precomputed squeeze\n            prefactors in the Fock basis. Must be of size [D,D,D] for some integer D\n        directory (str): location to save the precomputed beamsplitter factors. By default,\n            this will be the Strawberry Fields data directory.\n    """"""\n    if directory is None:\n        directory = DATA_PATH\n    else:\n        check_dir = os.path.isdir(directory)\n        if not check_dir:\n            raise NotADirectoryError(""Directory {} does not exist!"".format(directory))\n\n    D = prefac.shape[0]\n    filename = ""fock_squeeze_factors_{}.npz"".format(D)\n\n    prefac_rank2 = np.reshape(prefac, ((D) ** 2, D), order=""C"")\n    prefac_sparse = sp.sparse.csc_matrix(prefac_rank2)\n\n    sp.sparse.save_npz(os.path.join(directory, filename), prefac_sparse)\n\n\n@functools.lru_cache()\ndef load_squeeze_factors(D, directory=None):\n    r""""""Load precomputed squeeze factors in the Fock basis.\n\n    This function searches the data directory for a squeeze prefactor file\n    containing for cutoff dimension higher or equal to that requested\n    (``D``). It then reshapes the rank-2 sparse array to a\n    :math:`D\\times D\\times D` dense array.\n\n    If no such file satisfying this condition exists, then an Exception\n    is returned.\n\n    Args:\n        D (int): load prefactors containing at least ``D`` dimensions.\n        directory (str): location to load the precomputed squeeze\n            factors from. By default, this will be the Strawberry Fields data directory.\n    """"""\n    regex = r""fock_squeeze_factors_(\\d+)\\.npz""\n    load_dim, location = find_dim_files(regex, D, directory=directory, name=""squeeze"")\n\n    filename = ""fock_squeeze_factors_{}.npz"".format(load_dim)\n    prefac = sp.sparse.load_npz(os.path.join(location, filename))\n\n    return np.reshape(prefac.toarray(), [load_dim] * 3)\n\n\n# ================================+\n# Phase space shared operations  |\n# ================================+\n\n\n@functools.lru_cache()\ndef rotation_matrix(phi):\n    r""""""Rotation matrix.\n\n    Args:\n        phi (float): rotation angle\n    Returns:\n        array: :math:`2\\times 2` rotation matrix\n    """"""\n    return np.array([[np.cos(phi), -np.sin(phi)], [np.sin(phi), np.cos(phi)]])\n\n\n@functools.lru_cache()\ndef sympmat(n):\n    r"""""" Returns the symplectic matrix of order n\n\n    Args:\n        n (int): order\n        hbar (float): the value of hbar used in the definition\n            of the quadrature operators\n    Returns:\n        array: symplectic matrix\n    """"""\n    idm = np.identity(n)\n    omega = np.concatenate(\n        (np.concatenate((0 * idm, idm), axis=1), np.concatenate((-idm, 0 * idm), axis=1)), axis=0\n    )\n    return omega\n\n\n@functools.lru_cache()\ndef changebasis(n):\n    r""""""Change of basis matrix between the two Gaussian representation orderings.\n\n    This is the matrix necessary to transform covariances matrices written\n    in the (x_1,...,x_n,p_1,...,p_n) to the (x_1,p_1,...,x_n,p_n) ordering\n\n    Args:\n        n (int): number of modes\n    Returns:\n        array: :math:`2n\\times 2n` matrix\n    """"""\n    m = np.zeros((2 * n, 2 * n))\n    for i in range(n):\n        m[2 * i, i] = 1\n        m[2 * i + 1, i + n] = 1\n    return m\n\n\ndef haar_measure(n):\n    """"""A Random matrix distributed with the Haar measure.\n\n    For more details, see :cite:`mezzadri2006`.\n\n    Args:\n        n (int): matrix size\n    Returns:\n        array: an nxn random matrix\n    """"""\n    z = (sp.randn(n, n) + 1j * sp.randn(n, n)) / np.sqrt(2.0)\n    q, r = qr(z)\n    d = sp.diagonal(r)\n    ph = d / np.abs(d)\n    q = np.multiply(q, ph, q)\n    return q\n'"
strawberryfields/backends/states.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nThis module provides abstract base classes which represent the quantum state\nreturned by a simulator backend via :class:`.Engine`.\n""""""\nimport abc\nimport string\nfrom itertools import chain\nfrom copy import copy\n\nimport numpy as np\nfrom scipy.linalg import block_diag\nfrom scipy.stats import multivariate_normal\nfrom scipy.special import factorial\nfrom scipy.integrate import simps\n\nfrom thewalrus.quantum import photon_number_mean, photon_number_covar\n\nimport strawberryfields as sf\n\nfrom .shared_ops import rotation_matrix as _R\nfrom .shared_ops import changebasis\n\nindices = string.ascii_lowercase\n\n\nclass BaseState(abc.ABC):\n    r""""""Abstract base class for the representation of quantum states.""""""\n    EQ_TOLERANCE = 1e-10\n\n    def __init__(self, num_modes, mode_names=None):\n        self._modes = num_modes\n        self._hbar = sf.hbar  # always use the global frontend hbar value for state objects\n        self._data = None\n        self._pure = None\n\n        if mode_names is None:\n            self._modemap = {i: ""mode {}"".format(i) for i in range(num_modes)}\n        else:\n            self._modemap = {i: ""{}"".format(j) for i, j in zip(range(num_modes), mode_names)}\n\n        self._str = ""<BaseState: num_modes={}, pure={}, hbar={}>"".format(\n            self.num_modes, self._pure, self._hbar\n        )\n\n    def __str__(self):\n        return self._str\n\n    def __repr__(self):\n        return self._str\n\n    @property\n    def data(self):\n        r""""""Returns the underlying numerical (or symbolic) representation of the state.\n        The form of this data differs for different backends.""""""\n        return self._data\n\n    @property\n    def hbar(self):\n        r""""""Returns the value of :math:`\\hbar` used in the generation of the state.\n\n        The value of :math:`\\hbar` is a convention chosen in the definition of\n        :math:`\\x` and :math:`\\p`. See :ref:`opcon` for more details.\n\n        Returns:\n            float: :math:`\\hbar` value.\n        """"""\n        return self._hbar\n\n    @property\n    def is_pure(self):\n        r""""""Checks whether the state is a pure state.\n\n        Returns:\n            bool: True if and only if the state is pure.\n        """"""\n        return self._pure\n\n    @property\n    def num_modes(self):\n        r""""""Gets the number of modes that the state represents.\n\n        Returns:\n            int: the number of modes in the state\n        """"""\n        return self._modes\n\n    @property\n    def mode_names(self):\n        r""""""Returns a dictionary mapping the mode index to mode names.\n\n        The mode names are determined from the initialization argument\n        ``mode_names``. If these were not supplied, the names are generated automatically based\n        on the mode indices.\n\n        Returns:\n            dict: dictionary of the form ``{i:""mode name"",...}``\n        """"""\n        return self._modemap\n\n    @property\n    def mode_indices(self):\n        r""""""Returns a dictionary mapping the mode names to mode indices.\n\n        The mode names are determined from the initialization argument\n        ``mode_names``. If these were not supplied, the names are generated automatically based\n        on the mode indices.\n\n        Returns:\n            dict: dictionary of the form ``{""mode name"":i,...}``\n        """"""\n        return {v: k for k, v in self._modemap.items()}\n\n    @abc.abstractmethod\n    def reduced_dm(self, modes, **kwargs):\n        r""""""Returns a reduced density matrix in the Fock basis.\n\n        Args:\n            modes (int or Sequence[int]): specifies the mode(s) to return the reduced density matrix for.\n            **kwargs:\n\n                  * **cutoff** (*int*): (default 10) specifies where to truncate the returned density matrix.\n                    Note that the cutoff argument only applies for Gaussian representation;\n                    states represented in the Fock basis will use their own internal cutoff dimension.\n\n        Returns:\n            array: the reduced density matrix for the specified modes\n        """"""\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def fock_prob(self, n, **kwargs):\n        r""""""Probability of a particular Fock basis state.\n\n        Computes the probability :math:`|\\braket{\\vec{n}|\\psi}|^2` of measuring\n        the given multi-mode Fock state based on the state :math:`\\ket{\\psi}`.\n\n        .. warning::\n\n            Computing the Fock probabilities of states has exponential scaling\n            in the Gaussian representation (for example states output by a\n            Gaussian backend as a :class:`~.BaseGaussianState`).\n            This shouldn\'t affect small-scale problems, where only a few Fock\n            basis state probabilities need to be calculated, but will become\n            evident in larger scale problems.\n\n        Args:\n            n (Sequence[int]): the Fock state :math:`\\ket{\\vec{n}}` that we want to measure the probability of\n            **kwargs:\n\n                  * **cutoff** (*int*): (default 10) specifies the fock basis truncation when calculating\n                    of the fock basis probabilities.\n                    Note that the cutoff argument only applies for Gaussian representation;\n                    states represented in the Fock basis will use their own internal cutoff dimension.\n\n        Returns:\n            float: measurement probability\n        """"""\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def mean_photon(self, mode, **kwargs):\n        """"""Returns the mean photon number of a particular mode.\n\n        Args:\n            mode (int): specifies the mode\n            **kwargs:\n\n                  * **cutoff** (*int*): (default 10) Fock basis trunction for calculation of\n                    mean photon number.\n                    Note that the cutoff argument only applies for Gaussian representation;\n                    states represented in the Fock basis will use their own internal cutoff dimension.\n\n        Returns:\n            tuple: the mean photon number and variance\n        """"""\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def fidelity(self, other_state, mode, **kwargs):\n        r""""""Fidelity of the reduced state in the specified mode with a user supplied state.\n        Note that this method only supports single-mode states.\n\n        Args:\n            other_state: a pure state vector array represented in the Fock basis (for Fock backends)\n                or a Sequence ``(mu, cov)`` containing the means and covariance matrix (for Gaussian backends)\n\n        Returns:\n            The fidelity of the circuit state with ``other_state``.\n        """"""\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def fidelity_vacuum(self, **kwargs):\n        """"""The fidelity of the state with the vacuum state.\n\n        Returns:\n            float: the fidelity of the state with the vacuum\n        """"""\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def fidelity_coherent(self, alpha_list, **kwargs):\n        r""""""The fidelity of the state with a product of coherent states.\n\n        The fidelity is defined by\n\n        .. math:: \\bra{\\vec{\\alpha}}\\rho\\ket{\\vec{\\alpha}}\n\n        Args:\n            alpha_list (Sequence[complex]): list of coherent state parameters, one for each mode\n\n        Returns:\n            float: the fidelity value\n        """"""\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def wigner(self, mode, xvec, pvec):\n        r""""""Calculates the discretized Wigner function of the specified mode.\n\n        Args:\n            mode (int): the mode to calculate the Wigner function for\n            xvec (array): array of discretized :math:`x` quadrature values\n            pvec (array): array of discretized :math:`p` quadrature values\n\n        Returns:\n            array: 2D array of size [len(xvec), len(pvec)], containing reduced Wigner function\n            values for specified x and p values.\n        """"""\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def quad_expectation(self, mode, phi=0, **kwargs):\n        r""""""The :math:`\\x_{\\phi}` operator expectation values and variance for the specified mode.\n\n        The :math:`\\x_{\\phi}` operator is defined as follows,\n\n        .. math:: \\x_{\\phi} = \\cos\\phi~\\x + \\sin\\phi~\\p\n\n        with corresponding expectation value\n\n        .. math:: \\bar{x_{\\phi}}=\\langle x_{\\phi}\\rangle = \\text{Tr}(\\x_{\\phi}\\rho_{mode})\n\n        and variance\n\n        .. math:: \\Delta x_{\\phi}^2 = \\langle x_{\\phi}^2\\rangle - \\braket{x_{\\phi}}^2\n\n        Args:\n            mode (int): the requested mode\n            phi (float): quadrature angle, clockwise from the positive :math:`x` axis.\n\n                * :math:`\\phi=0` corresponds to the :math:`x` expectation and variance (default)\n                * :math:`\\phi=\\pi/2` corresponds to the :math:`p` expectation and variance\n\n        Returns:\n            tuple (float, float): expectation value and variance\n        """"""\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def poly_quad_expectation(self, A, d=None, k=0, phi=0, **kwargs):\n        r""""""The multi-mode expectation values and variance of arbitrary 2nd order polynomials\n        of quadrature operators.\n\n        An arbitrary 2nd order polynomial of quadrature operators over $N$ modes can always\n        be written in the following form:\n\n        .. math:: P(\\mathbf{r}) = \\mathbf{r}^T A\\mathbf{r} + \\mathbf{r}^T \\mathbf{d} + k I\n\n        where:\n\n        * :math:`A\\in\\mathbb{R}^{2N\\times 2N}` is a symmetric matrix\n          representing the quadratic coefficients,\n        * :math:`\\mathbf{d}\\in\\mathbb{R}^{2N}` is a real vector representing\n          the linear coefficients,\n        * :math:`k\\in\\mathbb{R}` represents the constant term, and\n        * :math:`\\mathbf{r} = (\\x_1,\\dots,\\x_N,\\p_1,\\dots,\\p_N)` is the vector\n          of quadrature operators in :math:`xp`-ordering.\n\n        This method returns the expectation value of this second-order polynomial,\n\n        .. math:: \\langle P(\\mathbf{r})\\rangle,\n\n        as well as the variance\n\n        .. math:: \\Delta P(\\mathbf{r})^2 = \\braket{P(\\mathbf{r})^2} - \\braket{P(\\mathbf{r})}^2\n\n        Args:\n            A (array): a real symmetric 2Nx2N NumPy array, representing the quadratic\n                coefficients of the second order quadrature polynomial.\n            d (array): a real length-2N NumPy array, representing the linear\n                coefficients of the second order quadrature polynomial. Defaults to the zero vector.\n            k (float): the constant term. Default 0.\n            phi (float): quadrature angle, clockwise from the positive :math:`x` axis. If provided,\n                the vectori of quadrature operators :math:`\\mathbf{r}` is first rotated\n                by angle :math:`\\phi` in the phase space.\n\n\n        Returns:\n            tuple (float, float): expectation value and variance\n        """"""\n        raise NotImplementedError\n\n    def number_expectation(self, modes):\n        r""""""\n        Calculates the expectation value of the product of the number operators of the modes.\n\n        This method computes the analytic expectation value\n        :math:`\\langle \\hat{n}_{i_0} \\hat{n}_{i_1}\\dots \\hat{n}_{i_{N-1}}\\rangle`\n        for a (sub)set of modes :math:`[i_0, i_1, \\dots, i_{N-1}]` of the system.\n\n        Args:\n            modes (list): list of modes for which one wants the expectation of the product of their number operator.\n\n        Return:\n            (float): the expectation value.\n\n        **Example**\n\n        Consider the following program:\n\n        .. code-block:: python\n\n            prog = sf.Program(3)\n\n            with prog.context as q:\n                ops.Sgate(0.5) | q[0]\n                ops.Sgate(0.5) | q[1]\n                ops.Sgate(0.5) | q[2]\n                ops.BSgate(np.pi/3, 0.1) |  (q[0], q[1])\n                ops.BSgate(np.pi/3, 0.1) |  (q[1], q[2])\n\n        Executing this on the Fock backend,\n\n        >>> eng = sf.Engine(""fock"", backend_options={""cutoff_dim"": 10})\n        >>> state = eng.run(prog).state\n\n        we can compute the expectation value :math:`\\langle \\hat{n}_0\\hat{n}_2\\rangle`:\n\n        >>> state.number_expectation([0, 2])\n        0.07252895071309405\n\n        Executing the same program on the Gaussian backend,\n\n        >>> eng = sf.Engine(""gaussian"")\n        >>> state = eng.run(prog).state\n        >>> state.number_expectation([0, 2])\n        0.07566984755267293\n\n        This slight difference in value compared to the result from the Fock backend above\n        is due to the finite Fock basis truncation when using the Fock backend; this can be\n        avoided by increasing the value of ``cutoff_dim``.\n\n        .. warning:: This method only supports at most two modes in the Gaussian backend.\n        """"""\n        raise NotImplementedError\n\n    def parity_expectation(self, modes):\n        """"""Calculates the expectation value of a product of parity operators acting on given modes""""""\n        raise NotImplementedError\n\n    def p_quad_values(self, mode, xvec, pvec):\n\n        r""""""Calculates the discretized p-quadrature probability distribution of the specified mode.\n\n        Args:\n            mode (int): the mode to calculate the p-quadrature probability values of\n            xvec (array): array of discretized :math:`x` quadrature values\n            pvec (array): array of discretized :math:`p` quadrature values\n\n        Returns:\n            array: 1D array of size len(pvec), containing reduced p-quadrature\n            probability values for a specified range of x and p.\n        """"""\n\n        W = self.wigner(mode, xvec, pvec)\n        y = []\n        for i in range(0, len(pvec)):\n            res = simps(W[i, : len(xvec)], xvec)\n            y.append(res)\n        return np.array(y)\n\n    def x_quad_values(self, mode, xvec, pvec):\n\n        r""""""Calculates the discretized x-quadrature probability distribution of the specified mode.\n\n        Args:\n            mode (int): the mode to calculate the x-quadrature probability values of\n            xvec (array): array of discretized :math:`x` quadrature values\n            pvec (array): array of discretized :math:`p` quadrature values\n\n        Returns:\n            array: 1D array of size len(xvec), containing reduced x-quadrature\n            probability values for a specified range of x and p.\n        """"""\n\n        W = self.wigner(mode, xvec, pvec)\n        y = []\n        for i in range(0, len(xvec)):\n            res = simps(W[: len(pvec), i], pvec)\n            y.append(res)\n        return np.array(y)\n\n\nclass BaseFockState(BaseState):\n    r""""""Class for the representation of quantum states in the Fock basis.\n\n    Args:\n        state_data (array): the state representation in the Fock basis\n        num_modes (int): the number of modes in the state\n        pure (bool): True if the state is a pure state, false if the state is mixed\n        cutoff_dim (int): the Fock basis truncation size\n        mode_names (Sequence): (optional) this argument contains a list providing mode names\n            for each mode in the state\n    """"""\n\n    def __init__(self, state_data, num_modes, pure, cutoff_dim, mode_names=None):\n        # pylint: disable=too-many-arguments\n\n        super().__init__(num_modes, mode_names)\n\n        self._data = state_data\n        self._cutoff = cutoff_dim\n        self._pure = pure\n        self._basis = ""fock""\n\n        self._str = ""<FockState: num_modes={}, cutoff={}, pure={}, hbar={}>"".format(\n            self.num_modes, self._cutoff, self._pure, self._hbar\n        )\n\n    def __eq__(self, other):\n        """"""Equality operator for BaseFockState.\n\n        Returns True if other BaseFockState is close to self.\n        This is done by comparing the dm attribute - if within\n        the EQ_TOLERANCE, True is returned.\n\n        Args:\n            other (BaseFockState): BaseFockState to compare against.\n        """"""\n        if not isinstance(other, type(self)):\n            return False\n\n        if self.num_modes != other.num_modes:\n            return False\n\n        if self.data.shape != other.data.shape:\n            return False\n\n        if np.allclose(self.dm(), other.dm(), atol=self.EQ_TOLERANCE, rtol=0):\n            return True\n\n        return False\n\n    @property\n    def cutoff_dim(self):\n        r""""""The numerical truncation of the Fock space used by the underlying state.\n        Note that a cutoff of D corresponds to the Fock states :math:`\\{|0\\rangle,\\dots,|D-1\\rangle\\}`\n\n        Returns:\n            int: the cutoff dimension\n        """"""\n        return self._cutoff\n\n    def ket(self, **kwargs):\n        r""""""The numerical state vector for the quantum state.\n        Note that if the state is mixed, this method returns None.\n\n        Returns:\n            array/None: the numerical state vector. Returns None if the state is mixed.\n        """"""\n        # pylint: disable=unused-argument\n        if self._pure:\n            return self.data\n\n        return None  # pragma: no cover\n\n    def dm(self, **kwargs):\n        r""""""The numerical density matrix for the quantum state.\n\n        Returns:\n            array: the numerical density matrix in the Fock basis\n        """"""\n        # pylint: disable=unused-argument\n        if self._pure:\n            left_str = [indices[i] for i in range(0, 2 * self._modes, 2)]\n            right_str = [indices[i] for i in range(1, 2 * self._modes, 2)]\n            out_str = [indices[: 2 * self._modes]]\n            einstr = """".join(left_str + ["",""] + right_str + [""->""] + out_str)\n            rho = np.einsum(einstr, self.ket(), self.ket().conj())\n            return rho\n\n        return self.data\n\n    def trace(self, **kwargs):\n        r""""""Trace of the density operator corresponding to the state.\n\n        For pure states the trace corresponds to the squared norm of the ket vector.\n\n        For physical states this should always be 1, any deviations from this value are due\n        to numerical errors and Hilbert space truncation artefacts.\n\n        Returns:\n          float: trace of the state\n        """"""\n        # pylint: disable=unused-argument\n        if self.is_pure:\n            return np.vdot(self.ket(), self.ket()).real  # <s|s>\n\n        # need some extra steps to trace over multimode matrices\n        eqn_indices = [\n            [indices[idx]] * 2 for idx in range(self._modes)\n        ]  # doubled indices [[\'i\',\'i\'],[\'j\',\'j\'], ... ]\n        eqn = """".join(\n            chain.from_iterable(eqn_indices)\n        )  # flatten indices into a single string \'iijj...\'\n        return np.einsum(eqn, self.dm()).real\n\n    def all_fock_probs(self, **kwargs):\n        r""""""Probabilities of all possible Fock basis states for the current circuit state.\n\n        For example, in the case of 3 modes, this method allows the Fock state probability\n        :math:`|\\braketD{0,2,3}{\\psi}|^2` to be returned via\n\n        .. code-block:: python\n\n            probs = state.all_fock_probs()\n            probs[0,2,3]\n\n        Returns:\n            array: array of dimension :math:`\\underbrace{D\\times D\\times D\\cdots\\times D}_{\\text{num modes}}`\n                containing the Fock state probabilities, where :math:`D` is the Fock basis cutoff truncation\n        """"""\n        # pylint: disable=unused-argument\n        if self._pure:\n            s = np.ravel(self.ket())  # into 1D array\n            return np.reshape((s * s.conj()).real, [self._cutoff] * self._modes)\n\n        s = self.dm()\n        num_axes = len(s.shape)\n        evens = [k for k in range(0, num_axes, 2)]\n        odds = [k for k in range(1, num_axes, 2)]\n        flat_size = np.prod([s.shape[k] for k in range(0, num_axes, 2)])\n        transpose_list = evens + odds\n        probs = np.diag(np.reshape(np.transpose(s, transpose_list), [flat_size, flat_size])).real\n\n        return np.reshape(probs, [self._cutoff] * self._modes)\n\n    # =====================================================\n    # the following methods are overwritten from BaseState\n\n    def reduced_dm(self, modes, **kwargs):\n        # pylint: disable=unused-argument\n        if modes == list(range(self._modes)):\n            # reduced state is full state\n            return self.dm()  # pragma: no cover\n\n        if isinstance(modes, int):\n            modes = [modes]\n        if modes != sorted(modes):\n            raise ValueError(""The specified modes cannot be duplicated."")\n\n        if len(modes) > self._modes:\n            raise ValueError(\n                ""The number of specified modes cannot "" ""be larger than the number of subsystems.""\n            )\n\n        # reduce rho down to specified subsystems\n        keep_indices = indices[: 2 * len(modes)]\n        trace_indices = indices[2 * len(modes) : len(modes) + self._modes]\n\n        ind = [i * 2 for i in trace_indices]\n        ctr = 0\n\n        for m in range(self._modes):\n            if m in modes:\n                ind.insert(m, keep_indices[2 * ctr : 2 * (ctr + 1)])\n                ctr += 1\n\n        indStr = """".join(ind) + ""->"" + keep_indices\n        return np.einsum(indStr, self.dm())\n\n    def fock_prob(self, n, **kwargs):\n        # pylint: disable=unused-argument\n        if len(n) != self._modes:\n            raise ValueError(""List length should be equal to number of modes"")\n\n        elif max(n) >= self._cutoff:\n            raise ValueError(""Can\'t get distribution beyond truncation level"")\n\n        if self._pure:\n            return np.abs(self.ket()[tuple(n)]) ** 2\n\n        return self.dm()[tuple([n[i // 2] for i in range(len(n) * 2)])].real\n\n    def mean_photon(self, mode, **kwargs):\n        # pylint: disable=unused-argument\n        n = np.arange(self._cutoff)\n        probs = np.diagonal(self.reduced_dm(mode))\n        mean = np.sum(n * probs).real\n        var = np.sum(n ** 2 * probs).real - mean ** 2\n        return mean, var\n\n    def fidelity(self, other_state, mode, **kwargs):\n        # pylint: disable=unused-argument\n        max_indices = len(indices) // 2\n\n        if self.num_modes > max_indices:\n            raise Exception(""fidelity method can only support up to {} modes"".format(max_indices))\n\n        left_indices = indices[:mode]\n        eqn_left = """".join([i * 2 for i in left_indices])\n        reduced_dm_indices = indices[mode : mode + 2]\n        right_indices = indices[mode + 2 : self._modes + 1]\n        eqn_right = """".join([i * 2 for i in right_indices])\n        eqn = """".join([eqn_left, reduced_dm_indices, eqn_right]) + ""->"" + reduced_dm_indices\n        rho_reduced = np.einsum(eqn, self.dm())\n\n        return np.dot(np.conj(other_state), np.dot(rho_reduced, other_state)).real\n\n    def fidelity_vacuum(self, **kwargs):\n        # pylint: disable=unused-argument\n        alpha = np.zeros(self._modes)\n        return self.fidelity_coherent(alpha)\n\n    def fidelity_coherent(self, alpha_list, **kwargs):\n        # pylint: disable=too-many-locals,unused-argument\n        if self.is_pure:\n            mode_size = 1\n            s = self.ket()\n        else:\n            mode_size = 2\n            s = self.dm()\n\n        if not hasattr(alpha_list, ""__len__""):\n            alpha_list = [alpha_list]  # pragma: no cover\n\n        if len(alpha_list) != self._modes:\n            raise ValueError(""The number of alpha values must match the number of modes."")\n\n        coh = lambda a, dim: np.array(\n            [np.exp(-0.5 * np.abs(a) ** 2) * (a) ** n / np.sqrt(factorial(n)) for n in range(dim)]\n        )\n\n        if self._modes == 1:\n            multi_cohs_vec = coh(alpha_list[0], self._cutoff)\n        else:\n            multi_cohs_list = [\n                coh(alpha_list[idx], dim) for idx, dim in enumerate(s.shape[::mode_size])\n            ]\n            eqn = "","".join(indices[: self._modes]) + ""->"" + indices[: self._modes]\n            multi_cohs_vec = np.einsum(\n                eqn, *multi_cohs_list\n            )  # tensor product of specified coherent states\n\n        if self.is_pure:\n            ovlap = np.vdot(multi_cohs_vec, s)\n            return np.abs(ovlap) ** 2\n\n        bra_indices = indices[: 2 * self._modes : 2]\n        ket_indices = indices[1 : 2 * self._modes : 2]\n        new_eqn_lhs = "","".join([bra_indices, ket_indices])\n        new_eqn_rhs = """".join(bra_indices[idx] + ket_indices[idx] for idx in range(self._modes))\n        outer_prod_eqn = new_eqn_lhs + ""->"" + new_eqn_rhs\n        multi_coh_matrix = np.einsum(outer_prod_eqn, multi_cohs_vec, np.conj(multi_cohs_vec))\n\n        return np.vdot(s, multi_coh_matrix).real\n\n    def wigner(self, mode, xvec, pvec):\n        r""""""Calculates the discretized Wigner function of the specified mode.\n\n        .. note::\n\n            This code is a modified version of the \'iterative\' method of the\n            `wigner function provided in QuTiP <http://qutip.org/docs/4.0.2/apidoc/functions.html?highlight=wigner#qutip.wigner.wigner>`_,\n            which is released under the BSD license, with the following\n            copyright notice:\n\n            Copyright (C) 2011 and later, P.D. Nation, J.R. Johansson,\n            A.J.G. Pitchford, C. Granade, and A.L. Grimsmo. All rights reserved.\n\n        Args:\n            mode (int): the mode to calculate the Wigner function for\n            xvec (array): array of discretized :math:`x` quadrature values\n            pvec (array): array of discretized :math:`p` quadrature values\n\n        Returns:\n            array: 2D array of size [len(xvec), len(pvec)], containing reduced Wigner function\n            values for specified x and p values.\n        """"""\n        rho = self.reduced_dm(mode)\n        Q, P = np.meshgrid(xvec, pvec)\n        A = (Q + P * 1.0j) / (2 * np.sqrt(self._hbar / 2))\n\n        Wlist = np.array([np.zeros(np.shape(A), dtype=complex) for k in range(self._cutoff)])\n\n        # Wigner function for |0><0|\n        Wlist[0] = np.exp(-2.0 * np.abs(A) ** 2) / np.pi\n\n        # W = rho(0,0)W(|0><0|)\n        W = np.real(rho[0, 0]) * np.real(Wlist[0])\n\n        for n in range(1, self._cutoff):\n            Wlist[n] = (2.0 * A * Wlist[n - 1]) / np.sqrt(n)\n            W += 2 * np.real(rho[0, n] * Wlist[n])\n\n        for m in range(1, self._cutoff):\n            temp = copy(Wlist[m])\n            # Wlist[m] = Wigner function for |m><m|\n            Wlist[m] = (2 * np.conj(A) * temp - np.sqrt(m) * Wlist[m - 1]) / np.sqrt(m)\n\n            # W += rho(m,m)W(|m><m|)\n            W += np.real(rho[m, m] * Wlist[m])\n\n            for n in range(m + 1, self._cutoff):\n                temp2 = (2 * A * Wlist[n - 1] - np.sqrt(m) * temp) / np.sqrt(n)\n                temp = copy(Wlist[n])\n                # Wlist[n] = Wigner function for |m><n|\n                Wlist[n] = temp2\n\n                # W += rho(m,n)W(|m><n|) + rho(n,m)W(|n><m|)\n                W += 2 * np.real(rho[m, n] * Wlist[n])\n\n        return W / (self._hbar)\n\n    def quad_expectation(self, mode, phi=0, **kwargs):\n        a = np.diag(np.sqrt(np.arange(1, self._cutoff + 5)), 1)\n        x = np.sqrt(self._hbar / 2) * (a + a.T)\n        p = -1j * np.sqrt(self._hbar / 2) * (a - a.T)\n\n        xphi = np.cos(phi) * x + np.sin(phi) * p\n        xphisq = np.dot(xphi, xphi)\n\n        # truncate down\n        xphi = xphi[: self._cutoff, : self._cutoff]\n        xphisq = xphisq[: self._cutoff, : self._cutoff]\n\n        rho = self.reduced_dm(mode)\n\n        mean = np.trace(np.dot(xphi, rho)).real\n        var = np.trace(np.dot(xphisq, rho)).real - mean ** 2\n\n        return mean, var\n\n    def poly_quad_expectation(self, A, d=None, k=0, phi=0, **kwargs):\n        # pylint: disable=too-many-branches\n\n        if A is None:\n            A = np.zeros([2 * self._modes, 2 * self._modes])\n\n        if A.shape != (2 * self._modes, 2 * self._modes):\n            raise ValueError(""Matrix of quadratic coefficients A must be of size 2Nx2N."")\n\n        if not np.allclose(A.T, A):\n            raise ValueError(""Matrix of quadratic coefficients A must be symmetric."")\n\n        if d is None:\n            linear_coeff = np.zeros([2 * self._modes])\n        else:\n            linear_coeff = d.copy()\n            linear_coeff[self._modes :] = -d[self._modes :]\n\n        if linear_coeff.shape != (2 * self._modes,):\n            raise ValueError(""Vector of linear coefficients d must be of length 2N."")\n\n        # expand the cutoff dimension in approximating the x and p\n        # operators in the Fock basis, to reduce numerical inaccuracy.\n        worksize = 1\n        dim = self._cutoff + worksize\n\n        # construct the x and p operators\n        a = np.diag(np.sqrt(np.arange(1, dim)), 1)\n        x_ = np.sqrt(self._hbar / 2) * (a + a.T)\n        p_ = -1j * np.sqrt(self._hbar / 2) * (a - a.T)\n\n        if phi != 0:\n            # rotate the quadrature operators\n            x = np.cos(phi) * x_ - np.sin(phi) * p_\n            p = np.sin(phi) * x_ + np.cos(phi) * p_\n        else:\n            x = x_\n            p = p_\n\n        def expand_dims(op, n, modes):\n            """"""Expand quadrature operator to act on nth mode""""""\n            I = np.identity(dim)\n            allowed_indices = zip(indices[: 2 * modes : 2], indices[1 : 2 * modes : 2])\n            ind = "","".join(a + b for a, b in allowed_indices)\n            ops = [I] * n + [op] + [I] * (modes - n - 1)\n            # the einsum \'ij,kl,mn->ijklmn\' (for 3 modes)\n            return np.einsum(ind, *ops)\n\n        # determine modes with quadratic expectation values\n        nonzero = np.concatenate(\n            [np.mod(A.nonzero()[0], self._modes), np.mod(linear_coeff.nonzero()[0], self._modes),]\n        )\n        ex_modes = list(set(nonzero))\n        num_modes = len(ex_modes)\n\n        if not ex_modes:\n            # only a constant term was provided\n            return k, 0.0\n\n        # There are non-zero elements of A and/or d\n        # therefore there are quadratic and/or linear terms.\n        # find the reduced density matrix\n        rho = self.reduced_dm(modes=ex_modes)\n\n        # generate vector of quadrature operators\n        # this array will have shape [2*num_modes] + [dim]*(2*num_modes)\n        r = np.empty([2 * num_modes] + [dim] * (2 * num_modes), dtype=np.complex128)\n        for n in range(num_modes):\n            r[n] = expand_dims(x, n, num_modes)\n            r[num_modes + n] = expand_dims(p, n, num_modes)\n\n        # reduce the size of A so that we only consider modes\n        # which we need to calculate the expectation value for\n        rows = ex_modes + [i + self._modes for i in ex_modes]\n        quad_coeffs = A[:, rows][rows]\n        quad_coeffs[num_modes:, :num_modes] = -quad_coeffs[num_modes:, :num_modes]\n        quad_coeffs[:num_modes, num_modes:] = -quad_coeffs[:num_modes, num_modes:]\n\n        # Compute the polynomial\n        #\n        # For 3 modes, this gives the einsum (with brackets denoting modes):\n        # \'a(bc)(de)(fg),a(ch)(ei)(gj)->(bh)(di)(fj)\' applied to r, A@r\n        #\n        # a corresponds to the index in the vector of quadrature operators\n        # r = (x_1,...,x_n,p_1,...,p_n), and the remaining indices ijklmn\n        # are the elements of the operator acting on a 3 mode density matrix.\n        #\n        # So, in effect, matrix of quadratic coefficients A acts only on index a,\n        # this index is then summed, and then each mode of r, A@r undergoes\n        # matrix multiplication\n        ind1 = indices[: 2 * num_modes + 1]\n        ind2 = ind1[0] + """".join(\n            [\n                str(i) + str(j)\n                for i, j in zip(ind1[2::2], indices[2 * num_modes + 1 : 3 * num_modes + 1])\n            ]\n        )\n        ind3 = """".join([str(i) + str(j) for i, j in zip(ind1[1::2], ind2[2::2])])\n        ind = ""{},{}->{}"".format(ind1, ind2, ind3)\n\n        if np.allclose(quad_coeffs, 0.0):\n            poly_op = np.zeros([dim] * (2 * num_modes), dtype=np.complex128)\n        else:\n            # Einsum above applied to to r,Ar\n            # This einsum sums over all quadrature operators, and also applies matrix\n            # multiplication between the same mode of each operator\n            poly_op = np.einsum(ind, r, np.tensordot(quad_coeffs, r, axes=1)).conj()\n\n        # add linear term\n        rows = np.flip(np.array(rows).reshape([2, -1]), axis=1).flatten()\n        poly_op += r.T @ linear_coeff[rows]\n\n        # add constant term\n        if k != 0:\n            poly_op += k * expand_dims(np.eye(dim), 0, num_modes)\n\n        # calculate Op^2\n        ind = ""{},{}->{}"".format(ind1[1:], ind2[1:], ind3)\n        poly_op_sq = np.einsum(ind, poly_op, poly_op)\n\n        # truncate down\n        sl = tuple([slice(0, self._cutoff)] * (2 * num_modes))\n        poly_op = poly_op[sl]\n        poly_op_sq = poly_op_sq[sl]\n\n        ind1 = ind1[:-1]\n        ind2 = """".join([str(j) + str(i) for i, j in zip(ind1[::2], ind1[1::2])])\n        ind = ""{},{}"".format(ind1, ind2)\n\n        # calculate expectation value, Tr(Op @ rho)\n        # For 3 modes, this gives the einsum \'(ab)(cd)(ef),(ba)(dc)(fe)->\'\n        mean = np.einsum(ind, poly_op, rho).real\n\n        # calculate variance Tr(Op^2 @ rho) - Tr(Op @ rho)^2\n        var = np.einsum(ind, poly_op_sq, rho).real - mean ** 2\n\n        return mean, var\n\n    def diagonal_expectation(self, modes, values):\n        """"""Calculates the expectation value of an operator that is diagonal in the number basis""""""\n        if len(modes) != len(set(modes)):\n            raise ValueError(""There can be no duplicates in the modes specified."")\n\n        cutoff = self._cutoff  # Fock space cutoff.\n        num_modes = self._modes  # number of modes in the state.\n\n        traced_modes = tuple(item for item in range(num_modes) if item not in modes)\n        if self.is_pure:\n            # state is a tensor of probability amplitudes\n            ps = np.abs(self.ket()) ** 2\n            ps = ps.sum(axis=traced_modes)\n            for _ in modes:\n                ps = np.tensordot(values, ps, axes=1)\n            return float(ps)\n\n        # state is a tensor of density matrix elements in the SF convention\n        ps = np.real(self.dm())\n        traced_modes = list(traced_modes)\n        traced_modes.sort(reverse=True)\n        for mode in traced_modes:\n            ps = np.tensordot(np.identity(cutoff), ps, axes=((0, 1), (2 * mode, 2 * mode + 1)))\n        for _ in range(len(modes)):\n            ps = np.tensordot(np.diag(values), ps, axes=((0, 1), (0, 1)))\n        return float(ps)\n\n    def number_expectation(self, modes):\n        """"""Calculates the expectation value of a product of number operators acting on given modes""""""\n        cutoff = self._cutoff\n        values = np.arange(cutoff)\n        return self.diagonal_expectation(modes, values)\n\n    def parity_expectation(self, modes):\n        cutoff = self._cutoff\n        values = (-1) ** np.arange(cutoff)\n        return self.diagonal_expectation(modes, values)\n\n\nclass BaseGaussianState(BaseState):\n    r""""""Class for the representation of quantum states using the Gaussian formalism.\n\n    Note that this class uses the Gaussian representation convention\n\n    .. math:: \\bar{\\mathbf{r}} = (\\bar{x}_1,\\bar{x}_2,\\dots,\\bar{x}_N,\\bar{p}_1,\\dots,\\bar{p}_N)\n\n    Args:\n        state_data (tuple(mu, cov)): A tuple containing the vector of means array ``mu`` and the\n            covariance matrix array ``cov``, in terms of the complex displacement.\n        num_modes (int): the number of modes in the state\n        pure (bool): True if the state is a pure state, false if the state is mixed\n        mode_names (Sequence): (optional) this argument contains a list providing mode names\n            for each mode in the state\n    """"""\n\n    def __init__(self, state_data, num_modes, mode_names=None):\n        super().__init__(num_modes, mode_names)\n\n        self._data = state_data\n\n        # vector of means and covariance matrix, using frontend x,p scaling\n        self._mu = self._data[0] * np.sqrt(self._hbar / 2)\n        self._cov = self._data[1] * (self._hbar / 2)\n        # complex displacements of the Gaussian state\n        self._alpha = self._mu[: self._modes] + 1j * self._mu[self._modes :]\n        self._alpha /= np.sqrt(2 * self._hbar)\n\n        self._pure = (\n            np.abs(np.linalg.det(self._cov) - (self._hbar / 2) ** (2 * self._modes))\n            < self.EQ_TOLERANCE\n        )\n\n        self._basis = ""gaussian""\n        self._str = ""<GaussianState: num_modes={}, pure={}, hbar={}>"".format(\n            self.num_modes, self._pure, self._hbar\n        )\n\n    def __eq__(self, other):\n        """"""Equality operator for BaseGaussianState.\n\n        Returns True if other BaseGaussianState is close to self.\n        This is done by comparing the means vector and cov matrix.\n        If both are within the EQ_TOLERANCE, True is returned.\n\n        Args:\n            other (BaseGaussianState): BaseGaussianState to compare against.\n        """"""\n        # pylint: disable=protected-access\n        if not isinstance(other, type(self)):\n            return False\n\n        if self.num_modes != other.num_modes:\n            return False\n\n        if np.allclose(self._mu, other._mu, atol=self.EQ_TOLERANCE, rtol=0) and np.allclose(\n            self._cov, other._cov, atol=self.EQ_TOLERANCE, rtol=0\n        ):\n            return True\n\n        return False\n\n    def means(self):\n        r""""""The vector of means describing the Gaussian state.\n\n        For a :math:`N` mode state, this has the form\n\n        .. math::\n            \\bar{\\mathbf{r}} = \\left(\\bar{x}_0,\\dots,\\bar{x}_{N-1},\\bar{p}_0,\\dots,\\bar{p}_{N-1}\\right)\n\n        where :math:`\\bar{x}_i` and :math:`\\bar{p}_i` refer to the mean\n        position and momentum quadrature of mode :math:`i` respectively.\n\n        Returns:\n          array: a length :math:`2N` array containing the vector of means.\n        """"""\n        return self._mu\n\n    def cov(self):\n        r""""""The covariance matrix describing the Gaussian state.\n\n        The diagonal elements of the covariance matrix correspond to the\n        variance in the position and momentum quadratures:\n\n        .. math::\n            \\mathbf{V}_{ii} = \\begin{cases}\n                (\\Delta x_i)^2, & 0\\leq i\\leq N-1\\\\\n                (\\Delta p_{i-N})^2, & N\\leq i\\leq 2(N-1)\n            \\end{cases}\n\n        where :math:`\\Delta x_i` and :math:`\\Delta p_i` refer to the\n        position and momentum quadrature variance of mode :math:`i` respectively.\n\n        Note that if the covariance matrix is purely diagonal, then this\n        corresponds to squeezing :math:`z=re^{i\\phi}` where :math:`\\phi=0`,\n        and :math:`\\Delta x_i = e^{-2r}`, :math:`\\Delta p_i = e^{2r}`.\n\n        Returns:\n          array: the :math:`2N\\times 2N` covariance matrix.\n        """"""\n        return self._cov\n\n    def reduced_gaussian(self, modes):\n        r"""""" Returns the vector of means and the covariance matrix of the specified modes.\n\n        Args:\n            modes (int of Sequence[int]): indices of the requested modes\n\n        Returns:\n            tuple (means, cov): where means is an array containing the vector of means,\n            and cov is a square array containing the covariance matrix.\n        """"""\n        if modes == list(range(self._modes)):\n            # reduced state is full state\n            return self._mu, self._cov\n\n        # reduce rho down to specified subsystems\n        if isinstance(modes, int):\n            modes = [modes]\n\n        if modes != sorted(modes):\n            raise ValueError(""The specified modes cannot be duplicated."")\n\n        if len(modes) > self._modes:\n            raise ValueError(\n                ""The number of specified modes cannot "" ""be larger than the number of subsystems.""\n            )\n\n        ind = np.concatenate([np.array(modes), np.array(modes) + self._modes])\n        rows = ind.reshape(-1, 1)\n        cols = ind.reshape(1, -1)\n\n        mu = self._mu[ind]\n        cov = self._cov[rows, cols]\n\n        return mu, cov\n\n    def is_coherent(self, mode, tol=1e-10):\n        r""""""Returns True if the Gaussian state of a particular mode is a coherent state.\n\n        Args:\n            mode (int): the specified mode\n            tol (float): the numerical precision in determining if squeezing is not present\n\n        Returns:\n            bool: True if and only if the state is a coherent state.\n        """"""\n        mu, cov = self.reduced_gaussian([mode])  # pylint: disable=unused-variable\n        cov /= self._hbar / 2\n        return np.allclose(cov, np.identity(2), atol=tol, rtol=0)\n\n    def displacement(self, modes=None):\n        r""""""Returns the displacement parameter :math:`\\alpha` of the modes specified.\n\n        Args:\n            modes (int or Sequence[int]): modes specified\n\n        Returns:\n            Sequence[complex]: sequence of complex displacements :math:`\\alpha`\n            corresponding to the list of specified modes\n        """"""\n        if modes is None:\n            modes = list(range(self._modes))\n        elif isinstance(modes, int):  # pragma: no cover\n            modes = [modes]\n\n        return self._alpha[list(modes)]\n\n    def is_squeezed(self, mode, tol=1e-6):\n        r""""""Returns True if the Gaussian state of a particular mode is a squeezed state.\n\n        Args:\n            mode (int): the specified mode\n            tol (float): the numerical precision in determining if squeezing is present\n\n        Returns:\n           bool: True if and only if the state is a squeezed state.\n        """"""\n        mu, cov = self.reduced_gaussian([mode])  # pylint: disable=unused-variable\n        cov /= self._hbar / 2\n        return np.any(np.abs(cov - np.identity(2)) > tol)\n\n    def squeezing(self, modes=None):\n        r""""""Returns the squeezing parameters :math:`(r,\\phi)` of the modes specified.\n\n        Args:\n            modes (int or Sequence[int]): modes specified\n\n        Returns:\n            List[(float, float)]: sequence of tuples containing the squeezing\n            parameters :math:`(r,\\phi)` of the specified modes.\n        """"""\n        if modes is None:\n            modes = list(range(self._modes))\n        elif isinstance(modes, int):  # pragma: no cover\n            modes = [modes]\n\n        res = []\n        for i in modes:\n            mu, cov = self.reduced_gaussian([i])  # pylint: disable=unused-variable\n            cov /= self._hbar / 2\n            tr = np.trace(cov)\n\n            r = np.arccosh(tr / 2) / 2\n\n            if cov[0, 1] == 0.0:\n                phi = 0\n            else:\n                phi = -np.arcsin(2 * cov[0, 1] / np.sqrt((tr - 2) * (tr + 2)))\n\n            res.append((r, phi))\n\n        return res\n\n    # =====================================================\n    # the following methods are overwritten from BaseState\n\n    def wigner(self, mode, xvec, pvec):\n        mu, cov = self.reduced_gaussian([mode])\n\n        X, P = np.meshgrid(xvec, pvec)\n        grid = np.empty(X.shape + (2,))\n        grid[:, :, 0] = X\n        grid[:, :, 1] = P\n        mvn = multivariate_normal(mu, cov, allow_singular=True)\n\n        return mvn.pdf(grid)\n\n    def quad_expectation(self, mode, phi=0, **kwargs):\n        # pylint: disable=unused-argument\n        mu, cov = self.reduced_gaussian([mode])\n        rot = _R(phi)\n\n        muphi = rot.T @ mu\n        covphi = rot.T @ cov @ rot\n        return (muphi[0], covphi[0, 0])\n\n    def poly_quad_expectation(self, A, d=None, k=0, phi=0, **kwargs):\n        if A is None:\n            A = np.zeros([2 * self._modes, 2 * self._modes])\n\n        if A.shape != (2 * self._modes, 2 * self._modes):\n            raise ValueError(""Matrix of quadratic coefficients A must be of size 2Nx2N."")\n\n        if not np.allclose(A.T, A):\n            raise ValueError(""Matrix of quadratic coefficients A must be symmetric."")\n\n        if d is not None:\n            if d.shape != (2 * self._modes,):\n                raise ValueError(""Vector of linear coefficients d must be of length 2N."")\n        else:\n            d = np.zeros([2 * self._modes])\n\n        # determine modes with quadratic expectation values\n        nonzero = np.concatenate(\n            [np.mod(A.nonzero()[0], self._modes), np.mod(d.nonzero()[0], self._modes)]\n        )\n        ex_modes = list(set(nonzero))\n\n        # reduce the size of A so that we only consider modes\n        # which we need to calculate the expectation value for\n        rows = ex_modes + [i + self._modes for i in ex_modes]\n        num_modes = len(ex_modes)\n        quad_coeffs = A[:, rows][rows]\n\n        if not ex_modes:\n            # only a constant term was provided\n            return k, 0.0\n\n        mu = self._mu\n        cov = self._cov\n\n        if phi != 0:\n            # rotate all modes of the covariance matrix and vector of means\n            R = _R(phi)\n            C = changebasis(self._modes)\n            rot = C.T @ block_diag(*([R] * self._modes)) @ C\n\n            mu = rot.T @ mu\n            cov = rot.T @ cov @ rot\n\n        # transform to the expectation of a quadratic on a normal distribution with zero mean\n        # E[P(r)]_(mu,cov) = E(Q(r+mu)]_(0,cov)\n        #                  = E[rT.A.r + rT.(2A.mu+d) + (muT.A.mu+muT.d+cI)]_(0,cov)\n        #                  = E[rT.A.r + rT.d\' + k\']_(0,cov)\n        d2 = 2 * A @ mu + d\n        k2 = mu.T @ A @ mu + mu.T @ d + k\n\n        # expectation value E[P(r)]_{mu=0} = tr(A.cov) + muT.A.mu + muT.d + k|_{mu=0}\n        #                                  = tr(A.cov) + k\n        mean = np.trace(A @ cov) + k2\n        # variance Var[P(r)]_{mu=0} = 2tr(A.cov.A.cov) + 4*muT.A.cov.A.mu + dT.cov.d|_{mu=0}\n        #                           = 2tr(A.cov.A.cov) + dT.cov.d\n        var = 2 * np.trace(A @ cov @ A @ cov) + d2.T @ cov @ d2\n\n        # Correction term to account for incorrect symmetric ordering in the variance.\n        # This occurs because Var[S(P(r))] = Var[P(r)] - \xce\xa3_{m1, m2} |hbar*A_{(m1, m1+N),(m2, m2+N)}|,\n        # where m1, m2 are all possible mode numbers, and N is the total number of modes.\n        # Therefore, the correction term is the sum of the determinants of 2x2 submatrices of A.\n        modes = np.arange(2 * num_modes).reshape(2, -1).T\n        var -= np.sum(\n            [np.linalg.det(self._hbar * quad_coeffs[:, m][n]) for m in modes for n in modes]\n        )\n\n        return mean, var\n\n    def number_expectation(self, modes):\n        if len(modes) != len(set(modes)):\n            raise ValueError(""There can be no duplicates in the modes specified."")\n        mu = self._mu\n        cov = self._cov\n        if len(modes) == 1:\n            return photon_number_mean(mu, cov, modes[0], hbar=self._hbar)\n\n        if len(modes) == 2:\n            ni = photon_number_mean(mu, cov, modes[0], hbar=self._hbar)\n            nj = photon_number_mean(mu, cov, modes[1], hbar=self._hbar)\n            return photon_number_covar(mu, cov, modes[1], modes[0], hbar=self._hbar) + ni * nj\n\n        raise ValueError(\n            ""The number_expectation method only supports one or two modes for Gaussian states.""\n        )\n\n    def parity_expectation(self, modes):\n        if len(modes) != len(set(modes)):\n            raise ValueError(""There can be no duplicates in the modes specified."")\n\n        mu = self.means()\n        cov = self.cov()\n        num = np.exp(-(0.5) * (mu @ (np.linalg.inv(cov) @ mu)))\n        parity = ((self.hbar / 2) ** len(modes)) * num / (np.sqrt(np.linalg.det(cov)))\n\n        return parity\n\n    @abc.abstractmethod\n    def reduced_dm(self, modes, **kwargs):\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def fock_prob(self, n, **kwargs):\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def mean_photon(self, mode, **kwargs):\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def fidelity(self, other_state, mode, **kwargs):\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def fidelity_vacuum(self, **kwargs):\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def fidelity_coherent(self, alpha_list, **kwargs):\n        raise NotImplementedError\n'"
strawberryfields/circuitspecs/X12.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Circuit class specification for the X12 class of circuits.""""""\nimport textwrap\n\nimport numpy as np\nfrom numpy.linalg import multi_dot\nfrom scipy.linalg import block_diag\n\nfrom strawberryfields.decompositions import mach_zehnder\nfrom strawberryfields.program_utils import CircuitError, Command, group_operations\nfrom strawberryfields.parameters import par_evaluate\nimport strawberryfields.ops as ops\n\nfrom .circuit_specs import CircuitSpecs\nfrom .gbs import GBSSpecs\n\n\n# Supporting multiple string formatting, such that the target can be replaced\n# first followed by squeezing amplitude and phase values\nX12_CIRCUIT = textwrap.dedent(\n    """"""\\\n    name template_6x2_X12\n    version 1.0\n    target {target} (shots=1)\n\n    # for n spatial degrees, first n signal modes, then n idler modes, all phases zero\n    S2gate({{squeezing_amplitude_0}}, 0.0) | [0, 6]\n    S2gate({{squeezing_amplitude_1}}, 0.0) | [1, 7]\n    S2gate({{squeezing_amplitude_2}}, 0.0) | [2, 8]\n    S2gate({{squeezing_amplitude_3}}, 0.0) | [3, 9]\n    S2gate({{squeezing_amplitude_4}}, 0.0) | [4, 10]\n    S2gate({{squeezing_amplitude_5}}, 0.0) | [5, 11]\n\n    # standard 6x6 interferometer for the signal modes (the lower ones in frequency)\n    # even phase indices correspond to internal Mach-Zehnder interferometer phases\n    # odd phase indices correspond to external Mach-Zehnder interferometer phases\n    MZgate({{phase_0}}, {{phase_1}}) | [0, 1]\n    MZgate({{phase_2}}, {{phase_3}}) | [2, 3]\n    MZgate({{phase_4}}, {{phase_5}}) | [4, 5]\n    MZgate({{phase_6}}, {{phase_7}}) | [1, 2]\n    MZgate({{phase_8}}, {{phase_9}}) | [3, 4]\n\n    MZgate({{phase_10}}, {{phase_11}}) | [0, 1]\n\n    MZgate({{phase_12}}, {{phase_13}}) | [2, 3]\n    MZgate({{phase_14}}, {{phase_15}}) | [4, 5]\n    MZgate({{phase_16}}, {{phase_17}}) | [1, 2]\n    MZgate({{phase_18}}, {{phase_19}}) | [3, 4]\n\n    MZgate({{phase_20}}, {{phase_21}}) | [0, 1]\n    MZgate({{phase_22}}, {{phase_23}}) | [2, 3]\n    MZgate({{phase_24}}, {{phase_25}}) | [4, 5]\n    MZgate({{phase_26}}, {{phase_27}}) | [1, 2]\n    MZgate({{phase_28}}, {{phase_29}}) | [3, 4]\n\n    # duplicate the interferometer for the idler modes (the higher ones in frequency)\n    MZgate({{phase_0}}, {{phase_1}}) | [6, 7]\n    MZgate({{phase_2}}, {{phase_3}}) | [8, 9]\n    MZgate({{phase_4}}, {{phase_5}}) | [10, 11]\n    MZgate({{phase_6}}, {{phase_7}}) | [7, 8]\n    MZgate({{phase_8}}, {{phase_9}}) | [9, 10]\n\n    MZgate({{phase_10}}, {{phase_11}}) | [6, 7]\n    MZgate({{phase_12}}, {{phase_13}}) | [8, 9]\n    MZgate({{phase_14}}, {{phase_15}}) | [10, 11]\n    MZgate({{phase_16}}, {{phase_17}}) | [7, 8]\n    MZgate({{phase_18}}, {{phase_19}}) | [9, 10]\n\n    MZgate({{phase_20}}, {{phase_21}}) | [6, 7]\n    MZgate({{phase_22}}, {{phase_23}}) | [8, 9]\n    MZgate({{phase_24}}, {{phase_25}}) | [10, 11]\n    MZgate({{phase_26}}, {{phase_27}}) | [7, 8]\n    MZgate({{phase_28}}, {{phase_29}}) | [9, 10]\n\n    # add final dummy phases to allow mapping any unitary to this template (these do not\n    # affect the photon number measurement)\n    Rgate({{final_phase_0}}) | [0]\n    Rgate({{final_phase_1}}) | [1]\n    Rgate({{final_phase_2}}) | [2]\n    Rgate({{final_phase_3}}) | [3]\n    Rgate({{final_phase_4}}) | [4]\n    Rgate({{final_phase_5}}) | [5]\n    Rgate({{final_phase_6}}) | [6]\n    Rgate({{final_phase_7}}) | [7]\n    Rgate({{final_phase_8}}) | [8]\n    Rgate({{final_phase_9}}) | [9]\n    Rgate({{final_phase_10}}) | [10]\n    Rgate({{final_phase_11}}) | [11]\n\n    # measurement in Fock basis\n    MeasureFock() | [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n    """"""\n)\n\n\nclass X12Specs(CircuitSpecs):\n    """"""Circuit specifications for the X12 class of circuits.""""""\n\n    short_name = ""X12""\n    modes = 12\n    remote = True\n    local = True\n    interactive = False\n    circuit = X12_CIRCUIT.format(target=short_name)\n\n    sq_amplitude = 1.0\n\n    primitives = {""S2gate"", ""MeasureFock"", ""Rgate"", ""BSgate"", ""MZgate""}\n    decompositions = {\n        ""Interferometer"": {""mesh"": ""rectangular_symmetric"", ""drop_identity"": False},\n        ""BipartiteGraphEmbed"": {""mesh"": ""rectangular_symmetric"", ""drop_identity"": False},\n    }\n\n    def compile(self, seq, registers):\n        """"""Try to arrange a quantum circuit into a form suitable for X12.\n\n        Args:\n            seq (Sequence[Command]): quantum circuit to modify\n            registers (Sequence[RegRefs]): quantum registers\n        Returns:\n            List[Command]: modified circuit\n        Raises:\n            CircuitError: the circuit does not correspond to X12\n        """"""\n        # pylint: disable=too-many-statements,too-many-branches\n\n        # first do general GBS compilation to make sure\n        # Fock measurements are correct\n        # ---------------------------------------------\n        seq = GBSSpecs().compile(seq, registers)\n        A, B, C = group_operations(seq, lambda x: isinstance(x, ops.MeasureFock))\n\n        if len(B[0].reg) != self.modes:\n            raise CircuitError(""All modes must be measured."")\n\n        # Check circuit begins with two mode squeezers\n        # --------------------------------------------\n        A, B, C = group_operations(seq, lambda x: isinstance(x, ops.S2gate))\n\n        regrefs = set()\n\n        if B:\n            # get set of circuit registers as a tuple for each S2gate\n            regrefs = {(cmd.reg[0].ind, cmd.reg[1].ind) for cmd in B}\n\n        # the set of allowed mode-tuples the S2gates must have\n        allowed_modes = set(zip(range(0, 6), range(6, 12)))\n\n        if not regrefs.issubset(allowed_modes):\n            raise CircuitError(""S2gates do not appear on the correct modes."")\n\n        # ensure provided S2gates all have the allowed squeezing values\n        allowed_sq_value = {(0.0, 0.0), (self.sq_amplitude, 0.0)}\n        sq_params = {(float(np.round(cmd.op.p[0], 3)), float(cmd.op.p[1])) for cmd in B}\n\n        if not sq_params.issubset(allowed_sq_value):\n            wrong_params = sq_params - allowed_sq_value\n            raise CircuitError(\n                ""Incorrect squeezing value(s) (r, phi)={}. Allowed squeezing ""\n                ""value(s) are (r, phi)={}."".format(wrong_params, allowed_sq_value)\n            )\n\n        # determine which modes do not have input S2gates specified\n        missing = allowed_modes - regrefs\n\n        for i, j in missing:\n            # insert S2gates with 0 squeezing\n            seq.insert(0, Command(ops.S2gate(0, 0), [registers[i], registers[j]]))\n\n        # Check if matches the circuit template\n        # --------------------------------------------\n        # This will avoid superfluous unitary compilation.\n        try:\n            seq = super().compile(seq, registers)\n        except CircuitError:\n            # failed topology check. Continue to more general\n            # compilation below.\n            pass\n        else:\n            return seq\n\n        # Compile the unitary: combine and then decompose all unitaries\n        # -------------------------------------------------------------\n        A, B, C = group_operations(\n            seq, lambda x: isinstance(x, (ops.Rgate, ops.BSgate, ops.MZgate))\n        )\n\n        # begin unitary lists for mode [0, 1, 2, 3, 4, 5] and modes [6, 7, 8, 9, 10, 11]\n        # with two identity matrices. This is because multi_dot requires at\n        # least two matrices in the list.\n        U_list0 = [np.identity(self.modes // 2, dtype=np.complex128)] * 2\n        U_list6 = [np.identity(self.modes // 2, dtype=np.complex128)] * 2\n\n        if not B:\n            # no interferometer was applied\n            A, B, C = group_operations(seq, lambda x: isinstance(x, ops.S2gate))\n            A = B  # move the S2gates to A\n        else:\n            for cmd in B:\n                # calculate the unitary matrix representing each\n                # rotation gate and each beamsplitter\n                modes = [i.ind for i in cmd.reg]\n                params = par_evaluate(cmd.op.p)\n                U = np.identity(self.modes // 2, dtype=np.complex128)\n\n                if isinstance(cmd.op, ops.Rgate):\n                    m = modes[0]\n                    U[m % 6, m % 6] = np.exp(1j * params[0])\n\n                elif isinstance(cmd.op, ops.MZgate):\n                    m, n = modes\n                    U = mach_zehnder(m % 6, n % 6, params[0], params[1], self.modes // 2)\n\n                elif isinstance(cmd.op, ops.BSgate):\n                    m, n = modes\n\n                    t = np.cos(params[0])\n                    r = np.exp(1j * params[1]) * np.sin(params[0])\n\n                    U[m % 6, m % 6] = t\n                    U[m % 6, n % 6] = -np.conj(r)\n                    U[n % 6, m % 6] = r\n                    U[n % 6, n % 6] = t\n\n                if set(modes).issubset({0, 1, 2, 3, 4, 5}):\n                    U_list0.insert(0, U)\n                elif set(modes).issubset({6, 7, 8, 9, 10, 11}):\n                    U_list6.insert(0, U)\n                else:\n                    raise CircuitError(\n                        ""Unitary must be applied separately to modes [0, 1, 2, 3, 4, 5] and modes [6, 7, 8, 9, 10, 11].""\n                    )\n\n        # multiply all unitaries together, to get the final\n        # unitary representation on modes [0, 1] and [2, 3].\n        U0 = multi_dot(U_list0)\n        U6 = multi_dot(U_list6)\n\n        # check unitaries are equal\n        if not np.allclose(U0, U6):\n            raise CircuitError(\n                ""Interferometer on modes [0, 1, 2, 3, 4, 5] must be identical to interferometer on modes [6, 7, 8, 9, 10, 11].""\n            )\n\n        U = block_diag(U0, U6)\n\n        # replace B with an interferometer\n        B = [\n            Command(ops.Interferometer(U0), registers[:6]),\n            Command(ops.Interferometer(U6), registers[6:]),\n        ]\n\n        # decompose the interferometer, using Mach-Zehnder interferometers\n        B = self.decompose(B)\n\n        # Do a final circuit topology check\n        # ---------------------------------\n        seq = super().compile(A + B + C, registers)\n        return seq\n\n\nclass X12_01(X12Specs):\n    """"""Circuit specifications for the first X12 chip.""""""\n\n    short_name = ""X12_01""\n    circuit = X12_CIRCUIT.format(target=short_name)\n\n\nclass X12_02(X12Specs):\n    """"""Circuit specifications for the second X12 chip.""""""\n\n    short_name = ""X12_02""\n    circuit = X12_CIRCUIT.format(target=short_name)\n'"
strawberryfields/circuitspecs/X8.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Circuit class specification for the X8 class of circuits.""""""\nimport textwrap\n\nimport numpy as np\nfrom numpy.linalg import multi_dot\nfrom scipy.linalg import block_diag\n\nfrom strawberryfields.decompositions import mach_zehnder\nfrom strawberryfields.program_utils import CircuitError, Command, group_operations\nfrom strawberryfields.parameters import par_evaluate\nimport strawberryfields.ops as ops\n\nfrom .circuit_specs import CircuitSpecs\nfrom .gbs import GBSSpecs\n\n\n# Supporting multiple string formatting, such that the target can be replaced\n# first followed by squeezing amplitude and phase values\nX8_CIRCUIT = textwrap.dedent(\n    """"""\\\n    name template_4x2_X8\n    version 1.0\n    target {target} (shots=1)\n\n    # for n spatial degrees, first n signal modes, then n idler modes, all phases zero\n    S2gate({{squeezing_amplitude_0}}, 0.0) | [0, 4]\n    S2gate({{squeezing_amplitude_1}}, 0.0) | [1, 5]\n    S2gate({{squeezing_amplitude_2}}, 0.0) | [2, 6]\n    S2gate({{squeezing_amplitude_3}}, 0.0) | [3, 7]\n\n    # standard 4x4 interferometer for the signal modes (the lower ones in frequency)\n    # even phase indices correspond to internal Mach-Zehnder interferometer phases\n    # odd phase indices correspond to external Mach-Zehnder interferometer phases\n    MZgate({{phase_0}}, {{phase_1}}) | [0, 1]\n    MZgate({{phase_2}}, {{phase_3}}) | [2, 3]\n    MZgate({{phase_4}}, {{phase_5}}) | [1, 2]\n    MZgate({{phase_6}}, {{phase_7}}) | [0, 1]\n    MZgate({{phase_8}}, {{phase_9}}) | [2, 3]\n    MZgate({{phase_10}}, {{phase_11}}) | [1, 2]\n\n    # duplicate the interferometer for the idler modes (the higher ones in frequency)\n    MZgate({{phase_0}}, {{phase_1}}) | [4, 5]\n    MZgate({{phase_2}}, {{phase_3}}) | [6, 7]\n    MZgate({{phase_4}}, {{phase_5}}) | [5, 6]\n    MZgate({{phase_6}}, {{phase_7}}) | [4, 5]\n    MZgate({{phase_8}}, {{phase_9}}) | [6, 7]\n    MZgate({{phase_10}}, {{phase_11}}) | [5, 6]\n\n    # add final dummy phases to allow mapping any unitary to this template (these do not\n    # affect the photon number measurement)\n    Rgate({{final_phase_0}}) | [0]\n    Rgate({{final_phase_1}}) | [1]\n    Rgate({{final_phase_2}}) | [2]\n    Rgate({{final_phase_3}}) | [3]\n    Rgate({{final_phase_4}}) | [4]\n    Rgate({{final_phase_5}}) | [5]\n    Rgate({{final_phase_6}}) | [6]\n    Rgate({{final_phase_7}}) | [7]\n\n    # measurement in Fock basis\n    MeasureFock() | [0, 1, 2, 3, 4, 5, 6, 7]\n    """"""\n)\n\n\nclass X8Specs(CircuitSpecs):\n    """"""Circuit specifications for the X8 class of circuits.""""""\n\n    short_name = ""X8""\n    modes = 8\n    remote = True\n    local = True\n    interactive = False\n\n    sq_amplitude = 1.0\n\n    primitives = {""S2gate"", ""MeasureFock"", ""Rgate"", ""BSgate"", ""MZgate""}\n    decompositions = {\n        ""Interferometer"": {""mesh"": ""rectangular_symmetric"", ""drop_identity"": False},\n        ""BipartiteGraphEmbed"": {""mesh"": ""rectangular_symmetric"", ""drop_identity"": False},\n    }\n\n    circuit = X8_CIRCUIT.format(target=short_name)\n\n    def compile(self, seq, registers):\n        """"""Try to arrange a quantum circuit into a form suitable for X8.\n\n        Args:\n            seq (Sequence[Command]): quantum circuit to modify\n            registers (Sequence[RegRefs]): quantum registers\n        Returns:\n            List[Command]: modified circuit\n        Raises:\n            CircuitError: the circuit does not correspond to X8\n        """"""\n        # pylint: disable=too-many-statements,too-many-branches\n\n        # first do general GBS compilation to make sure\n        # Fock measurements are correct\n        # ---------------------------------------------\n        seq = GBSSpecs().compile(seq, registers)\n        A, B, C = group_operations(seq, lambda x: isinstance(x, ops.MeasureFock))\n\n        if len(B[0].reg) != self.modes:\n            raise CircuitError(""All modes must be measured."")\n\n        # Check circuit begins with two mode squeezers\n        # --------------------------------------------\n        A, B, C = group_operations(seq, lambda x: isinstance(x, ops.S2gate))\n\n        regrefs = set()\n\n        if B:\n            # get set of circuit registers as a tuple for each S2gate\n            regrefs = {(cmd.reg[0].ind, cmd.reg[1].ind) for cmd in B}\n\n        # the set of allowed mode-tuples the S2gates must have\n        allowed_modes = set(zip(range(0, 4), range(4, 8)))\n\n        if not regrefs.issubset(allowed_modes):\n            raise CircuitError(""S2gates do not appear on the correct modes."")\n\n        # ensure provided S2gates all have the allowed squeezing values\n        allowed_sq_value = {(0.0, 0.0), (self.sq_amplitude, 0.0)}\n        sq_params = {(float(np.round(cmd.op.p[0], 3)), float(cmd.op.p[1])) for cmd in B}\n\n        if not sq_params.issubset(allowed_sq_value):\n            wrong_params = sq_params - allowed_sq_value\n            raise CircuitError(\n                ""Incorrect squeezing value(s) (r, phi)={}. Allowed squeezing ""\n                ""value(s) are (r, phi)={}."".format(wrong_params, allowed_sq_value)\n            )\n\n        # determine which modes do not have input S2gates specified\n        missing = allowed_modes - regrefs\n\n        for i, j in missing:\n            # insert S2gates with 0 squeezing\n            seq.insert(0, Command(ops.S2gate(0, 0), [registers[i], registers[j]]))\n\n        # Check if matches the circuit template\n        # --------------------------------------------\n        # This will avoid superfluous unitary compilation.\n        try:\n            seq = super().compile(seq, registers)\n        except CircuitError:\n            # failed topology check. Continue to more general\n            # compilation below.\n            pass\n        else:\n            return seq\n\n        # Compile the unitary: combine and then decompose all unitaries\n        # -------------------------------------------------------------\n        A, B, C = group_operations(\n            seq, lambda x: isinstance(x, (ops.Rgate, ops.BSgate, ops.MZgate))\n        )\n\n        # begin unitary lists for mode [0, 1, 2, 3] and modes [4, 5, 6, 7] with\n        # two identity matrices. This is because multi_dot requires\n        # at least two matrices in the list.\n        U_list0 = [np.identity(self.modes // 2, dtype=np.complex128)] * 2\n        U_list4 = [np.identity(self.modes // 2, dtype=np.complex128)] * 2\n\n        if not B:\n            # no interferometer was applied\n            A, B, C = group_operations(seq, lambda x: isinstance(x, ops.S2gate))\n            A = B  # move the S2gates to A\n        else:\n            for cmd in B:\n                # calculate the unitary matrix representing each\n                # rotation gate and each beamsplitter\n                modes = [i.ind for i in cmd.reg]\n                params = par_evaluate(cmd.op.p)\n                U = np.identity(self.modes // 2, dtype=np.complex128)\n\n                if isinstance(cmd.op, ops.Rgate):\n                    m = modes[0]\n                    U[m % 4, m % 4] = np.exp(1j * params[0])\n\n                elif isinstance(cmd.op, ops.MZgate):\n                    m, n = modes\n                    U = mach_zehnder(m % 4, n % 4, params[0], params[1], self.modes // 2)\n\n                elif isinstance(cmd.op, ops.BSgate):\n                    m, n = modes\n\n                    t = np.cos(params[0])\n                    r = np.exp(1j * params[1]) * np.sin(params[0])\n\n                    U[m % 4, m % 4] = t\n                    U[m % 4, n % 4] = -np.conj(r)\n                    U[n % 4, m % 4] = r\n                    U[n % 4, n % 4] = t\n\n                if set(modes).issubset({0, 1, 2, 3}):\n                    U_list0.insert(0, U)\n                elif set(modes).issubset({4, 5, 6, 7}):\n                    U_list4.insert(0, U)\n                else:\n                    raise CircuitError(\n                        ""Unitary must be applied separately to modes [0, 1, 2, 3] and modes [4, 5, 6, 7].""\n                    )\n\n        # multiply all unitaries together, to get the final\n        # unitary representation on modes [0, 1] and [2, 3].\n        U0 = multi_dot(U_list0)\n        U4 = multi_dot(U_list4)\n\n        # check unitaries are equal\n        if not np.allclose(U0, U4):\n            raise CircuitError(\n                ""Interferometer on modes [0, 1, 2, 3] must be identical to interferometer on modes [4, 5, 6, 7].""\n            )\n\n        U = block_diag(U0, U4)\n\n        # replace B with an interferometer\n        B = [\n            Command(ops.Interferometer(U0), registers[:4]),\n            Command(ops.Interferometer(U4), registers[4:]),\n        ]\n\n        # decompose the interferometer, using Mach-Zehnder interferometers\n        B = self.decompose(B)\n\n        # Do a final circuit topology check\n        # ---------------------------------\n        seq = super().compile(A + B + C, registers)\n        return seq\n\n\nclass X8_01(X8Specs):\n    """"""Circuit specifications for the X8_01 class of circuits.""""""\n\n    short_name = ""X8_01""\n    circuit = X8_CIRCUIT.format(target=short_name)\n'"
strawberryfields/circuitspecs/__init__.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nThis subpackage implements the :class:`CircuitSpecs` class, an abstract base class\nused to define classes or families of quantum circuits, e.g., circuits that can be executed on particular\nhardware or simulator backends.\n\nThe information in the :class:`CircuitSpecs` instances is used by :meth:`.Program.compile` to validate and\ncompile quantum programs. By querying the :class:`CircuitSpecs` class representing the requested compilation\ntarget, :meth:`.Program.compile` can\n\n1. **Validate** that the Program has the correct number of modes, and consists\n   of valid quantum operations in the correct topology for the targeted circuit class.\n\n2. **Compile** the Program into an :term:`equivalent circuit` that has the topology required by the\n   targeted circuit class, decomposing circuit operations as required.\n\nNote that the compilation process is not perfect and can provide false negatives: it can admit\nfailure by raising a :class:`.CircuitError` even if the Program theoretically is equivalent to a\ncircuit that belongs in the target circuit class.\n\nThe circuit class database :attr:`circuit_db` is a dictionary mapping the circuit family\nshort name to the corresponding CircuitSpecs instance.\nIn particular, for each backend supported by Strawberry Fields the database contains a\ncorresponding CircuitSpecs instance with the same short name, used to validate Programs to be\nexecuted on that backend.\n""""""\nfrom .circuit_specs import CircuitSpecs\nfrom .X8 import X8Specs, X8_01\nfrom .X12 import X12Specs, X12_01, X12_02\nfrom .xcov import Xcov\nfrom .xunitary import Xunitary\nfrom .fock import FockSpecs\nfrom .gaussian import GaussianSpecs\nfrom .gbs import GBSSpecs\nfrom .tensorflow import TFSpecs\nfrom .gaussian_unitary import GaussianUnitary\n\nspecs = (\n    X8Specs,\n    X8_01,\n    X12Specs,\n    X12_01,\n    X12_02,\n    FockSpecs,\n    GaussianSpecs,\n    GBSSpecs,\n    TFSpecs,\n    GaussianUnitary,\n    Xcov,\n    Xunitary,\n)\n\ncircuit_db = {c.short_name: c for c in specs}\n""""""dict[str, ~strawberryfields.circuitspecs.CircuitSpecs]: Map from circuit\nfamily short name to the corresponding class.""""""\n\n__all__ = [""circuit_db"", ""CircuitSpecs""] + [i.__name__ for i in specs]\n'"
strawberryfields/circuitspecs/circuit_specs.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# The module docstring is in strawberryfields/circuitspecs/__init__.py\n""""""\n**Module name:** :mod:`strawberryfields.circuitspecs.circuit_specs`\n""""""\n\nfrom typing import List, Set, Dict, Union\nimport abc\n\nimport networkx as nx\nimport blackbird\nfrom blackbird.utils import to_DiGraph\n\nimport strawberryfields.program_utils as pu\n\n\nclass CircuitSpecs(abc.ABC):\n    """"""Abstract base class for describing circuit classes.\n\n    This class stores information about :term:`classes of quantum circuits <circuit class>`.\n    For some circuit classes (e.g, ones corresponding to physical hardware chips), the\n    specifications can be quite rigid. For other classes, e.g., circuits supported by a particular\n    simulator backend, the specifications can be more flexible and general.\n\n    Key ingredients in a specification include: the primitive gates supported by the circuit class,\n    the gates that can be decomposed to sequences of primitive gates, and the possible\n    topology/connectivity restrictions.\n\n    This information is used e.g., in :meth:`.Program.compile` for validation and compilation.\n    """"""\n\n    short_name = """"\n    """"""str: short name of the circuit class""""""\n\n    @property\n    @abc.abstractmethod\n    def modes(self) -> Union[int, None]:\n        """"""The number of modes supported by the circuit class.\n\n        If the circuit class supports arbitrary number of modes, set this to 0.\n\n        Returns:\n            int: number of supported modes\n        """"""\n\n    @property\n    @abc.abstractmethod\n    def local(self) -> bool:\n        """"""Whether the circuit class can be executed locally (i.e., within a simulator).\n\n        Returns:\n            bool: ``True`` if the circuit class supports local execution\n        """"""\n\n    @property\n    @abc.abstractmethod\n    def remote(self) -> bool:\n        """"""Whether the circuit class supports remote execution.\n\n        Returns:\n            bool: ``True`` if the circuit class supports remote execution\n        """"""\n\n    @property\n    @abc.abstractmethod\n    def interactive(self) -> bool:\n        """"""Whether the circuits in the class can be executed interactively, that is,\n        the registers in the circuit are not reset between engine executions.\n\n        Returns:\n            bool: ``True`` if the circuit supports interactive use\n        """"""\n\n    @property\n    @abc.abstractmethod\n    def primitives(self) -> Set[str]:\n        """"""The primitive set of quantum operations directly supported\n        by the circuit class.\n\n        Returns:\n            set[str]: the names of the quantum primitives the circuit class supports\n        """"""\n\n    @property\n    @abc.abstractmethod\n    def decompositions(self) -> Dict[str, Dict]:\n        """"""Quantum operations that are not quantum primitives for the\n        circuit class, but are supported via specified decompositions.\n\n        This should be of the form\n\n        .. code-block:: python\n\n            {\'operation_name\': {\'option1\': val, \'option2\': val,...}}\n\n        For each operation specified in the dictionary, the\n        :meth:`.Operation.decompose` method will be called during\n        :class:`.Program` compilation, with keyword arguments\n        given by the dictionary value.\n\n        Returns:\n            dict[str, dict]: the quantum operations that are supported\n            by the circuit class via decomposition\n        """"""\n\n    @property\n    def parameter_ranges(self) -> Dict[str, List[List[float]]]:\n        """"""Allowed parameter ranges for supported quantum operations.\n\n        This property is optional.\n\n        Returns:\n            dict[str, list]: a dictionary mapping an allowed quantum operation\n            to a nested list of the form ``[[p0_min, p0_max], [p1_min, p0_max], ...]``.\n            where ``pi`` corresponds to the ``i`` th gate parameter\n        """"""\n        return dict()\n\n    @property\n    def graph(self):\n        """"""The allowed circuit topologies or connectivity of the class, modelled as a directed\n        acyclic graph.\n\n        This property is optional; if arbitrary topologies are allowed in the circuit class,\n        this will simply return ``None``.\n\n        Returns:\n            networkx.DiGraph: a directed acyclic graph\n        """"""\n        if self.circuit is None:\n            return None\n\n        # returned DAG has all parameters set to 0\n        bb = blackbird.loads(self.circuit)\n\n        if bb.is_template():\n            params = bb.parameters\n            kwargs = {p: 0 for p in params}\n\n            # initialize the topology with all template\n            # parameters set to zero\n            topology = to_DiGraph(bb(**kwargs))\n\n        else:\n            topology = to_DiGraph(bb)\n\n        return topology\n\n    @property\n    def circuit(self):\n        """"""A rigid circuit template that defines this circuit specification.\n\n        This property is optional. If arbitrary topologies are allowed in the circuit class,\n        **do not define this property**. In such a case, it will simply return ``None``.\n\n        If a backend device expects a specific template for the recieved Blackbird\n        script, this method will return the serialized Blackbird circuit in string\n        form.\n\n        Returns:\n            Union[str, None]: Blackbird program or template representing the circuit\n        """"""\n        return None\n\n    def compile(self, seq, registers):\n        """"""Class-specific circuit compilation method.\n\n        If additional compilation logic is required, child classes can redefine this method.\n\n        Args:\n            seq (Sequence[Command]): quantum circuit to modify\n            registers (Sequence[RegRefs]): quantum registers\n        Returns:\n            List[Command]: modified circuit\n        Raises:\n            CircuitError: the given circuit cannot be validated to belong to this circuit class\n        """"""\n        # registers is not used here, but may be used if the method is overwritten pylint: disable=unused-argument\n        if self.graph is not None:\n            # check topology\n            DAG = pu.list_to_DAG(seq)\n\n            # relabel the DAG nodes to integers, with attributes\n            # specifying the operation name. This allows them to be\n            # compared, rather than using Command objects.\n            mapping = {i: n.op.__class__.__name__ for i, n in enumerate(DAG.nodes())}\n            circuit = nx.convert_node_labels_to_integers(DAG)\n            nx.set_node_attributes(circuit, mapping, name=""name"")\n\n            def node_match(n1, n2):\n                """"""Returns True if both nodes have the same name""""""\n                return n1[""name""] == n2[""name""]\n\n            # check if topology matches\n            if not nx.is_isomorphic(circuit, self.graph, node_match):\n                # TODO: try and compile the program to match the topology\n                # TODO: add support for parameter range matching/compilation\n                raise pu.CircuitError(\n                    ""Program cannot be used with the CircuitSpec \'{}\' ""\n                    ""due to incompatible topology."".format(self.short_name)\n                )\n\n        return seq\n\n    def decompose(self, seq):\n        """"""Recursively decompose all gates in a given sequence, as allowed\n        by the circuit specification.\n\n        This method follows the directives defined in the\n        :attr:`~.CircuitSpecs.primitives` and :attr:`~.CircuitSpecs.decompositions`\n        class attributes to determine whether a command should be decomposed.\n\n        The order of precedence to determine whether decomposition\n        should be applied is as follows.\n\n        1. First, we check if the operation is in :attr:`~.CircuitSpecs.decompositions`.\n           If not, decomposition is skipped, and the operation is applied\n           as a primitive (if supported by the ``CircuitSpecs``).\n\n        2. Next, we check if (a) the operation supports decomposition, and (b) if the user\n           has explicitly requested no decomposition.\n\n           - If both (a) and (b) are true, the operation is applied\n             as a primitive (if supported by the ``CircuitSpecs``).\n\n           - Otherwise, we attempt to decompose the operation by calling\n             :meth:`~.Operation.decompose` recursively.\n\n        Args:\n            list[strawberryfields.program_utils.Command]: list of commands to\n                be decomposed\n\n        Returns:\n            list[strawberryfields.program_utils.Command]: list of compiled commands\n            for the circuit specification\n        """"""\n        compiled = []\n        for cmd in seq:\n            op_name = cmd.op.__class__.__name__\n            if op_name in self.decompositions:\n                # target can implement this op decomposed\n                if hasattr(cmd.op, ""decomp"") and not cmd.op.decomp:\n                    # user has requested application of the op as a primitive\n                    if op_name in self.primitives:\n                        compiled.append(cmd)\n                        continue\n                    else:\n                        raise pu.CircuitError(\n                            ""The operation {} is not a primitive for the target \'{}\'"".format(\n                                cmd.op.__class__.__name__, self.short_name\n                            )\n                        )\n                try:\n                    kwargs = self.decompositions[op_name]\n                    temp = cmd.op.decompose(cmd.reg, **kwargs)\n                    # now compile the decomposition\n                    temp = self.decompose(temp)\n                    compiled.extend(temp)\n                except NotImplementedError as err:\n                    # Operation does not have _decompose() method defined!\n                    # simplify the error message by suppressing the previous exception\n                    raise err from None\n\n            elif op_name in self.primitives:\n                # target can handle the op natively\n                compiled.append(cmd)\n\n            else:\n                raise pu.CircuitError(\n                    ""The operation {} cannot be used with the target \'{}\'."".format(\n                        cmd.op.__class__.__name__, self.short_name\n                    )\n                )\n\n        return compiled\n\n\nclass Range:\n    """"""Lightweight class for representing a range of floats.\n\n    **Example**\n\n    >>> x = Range(0.2, 0.5)\n    >>> print(x)\n    0.2\xe2\x89\xa4x\xe2\x89\xa40.5\n    >>> 0.34 in x\n    True\n    >>> -0.1 in x\n    False\n\n    Note that the upper bound is inclusive:\n    >>> 0.5 in x\n    True\n\n    Leaving off the lower bound corresponds to a range of a single value:\n    >>> x = Range(0.3)\n    >>> 0.3 in x\n    True\n    >>> 0.30001 in x\n    False\n\n\n    Args:\n        x (float): lower bound of the range\n\n    Keyword Args:\n        y (float): Upper bound of the range (inclusive). If not provided,\n            the range will represent the single value ``x``.\n        variable_name (str): the variable name to use when printing\n            the range\n        atol (float): positive float representing the absolute tolerance\n            used when checking if items are within the range\n    """"""\n\n    def __init__(self, x, y=None, variable_name=""x"", atol=1e-5):\n        self.x = x\n        self.y = y if y is not None else x\n        self.name = variable_name\n        self.atol = atol\n\n        if self.y < self.x:\n            raise ValueError(\n                ""Upper bound of the range must be strictly larger than the lower bound.""\n            )\n\n    def __contains__(self, item):\n        return self.x - self.atol <= item <= self.y + self.atol\n\n    def __repr__(self):\n        if self.x == self.y:\n            return ""{}={}"".format(self.name, self.x)\n\n        return ""{}\xe2\x89\xa4{}\xe2\x89\xa4{}"".format(self.x, self.name, self.y)\n\n\nclass Ranges:\n    """"""Lightweight class for representing a set of ranges of floats.\n\n    **Example**\n\n    >>> x = Ranges([0], [0.2, 0.55], [1.0])\n    >>> print(x)\n    x=0, 0.2\xe2\x89\xa4x\xe2\x89\xa40.55, x=1.0\n    >>> test_data = [0, 0.34, 0.1, 1.0]\n    >>> [i in x for i in test_data]\n    [True, True, False, True]\n\n    Args:\n        r1, r2, r3,... (list[float]): Allowed ranges. Lists of size ``(1,)``\n            correspond to a single allowed value, whereas lists of size ``(2,)``\n            correspond to a lower and upper bound (inclusive).\n\n    Keyword Args\n        variable_name (str): the variable name to use when printing\n            the range\n    """"""\n\n    def __init__(self, *args, variable_name=""x""):\n        self.ranges = [Range(*a, variable_name=variable_name) for a in args]\n\n    def __contains__(self, item):\n        for range_ in self.ranges:\n            if item in range_:\n                return True\n\n        return False\n\n    def __repr__(self):\n        return "", "".join([str(i) for i in self.ranges])\n'"
strawberryfields/circuitspecs/fock.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Circuit specifications for the Fock simulator backend.""""""\nfrom .circuit_specs import CircuitSpecs\n\n\nclass FockSpecs(CircuitSpecs):\n    """"""Circuit specifications for the Fock backend.""""""\n\n    short_name = ""fock""\n    modes = None\n    local = True\n    remote = True\n    interactive = True\n\n    primitives = {\n        # meta operations\n        ""All"",\n        ""_New_modes"",\n        ""_Delete"",\n        # state preparations\n        ""Vacuum"",\n        ""Coherent"",\n        ""Squeezed"",\n        ""DisplacedSqueezed"",\n        ""Thermal"",\n        ""Fock"",\n        ""Catstate"",\n        ""Ket"",\n        ""DensityMatrix"",\n        # measurements\n        ""MeasureFock"",\n        ""MeasureHomodyne"",\n        # channels\n        ""LossChannel"",\n        # single mode gates\n        ""Dgate"",\n        ""Sgate"",\n        ""Rgate"",\n        ""Vgate"",\n        ""Kgate"",\n        ""BSgate"",\n        ""CKgate"",\n        ""S2gate"",\n    }\n\n    decompositions = {\n        ""Interferometer"": {},\n        ""GraphEmbed"": {},\n        ""BipartiteGraphEmbed"": {},\n        ""GaussianTransform"": {},\n        ""Gaussian"": {},\n        ""Pgate"": {},\n        ""CXgate"": {},\n        ""CZgate"": {},\n        ""MZgate"": {},\n        ""Xgate"": {},\n        ""Zgate"": {},\n        ""Fouriergate"": {},\n    }\n'"
strawberryfields/circuitspecs/gaussian.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Circuit specifications for the Gaussian simulator backend.""""""\nfrom .circuit_specs import CircuitSpecs\n\n\nclass GaussianSpecs(CircuitSpecs):\n    """"""Circuit specifications for the Gaussian backend.""""""\n\n    short_name = ""gaussian""\n    modes = None\n    local = True\n    remote = True\n    interactive = True\n\n    primitives = {\n        # meta operations\n        ""All"",\n        ""_New_modes"",\n        ""_Delete"",\n        # state preparations\n        ""Vacuum"",\n        ""Coherent"",\n        ""Squeezed"",\n        ""DisplacedSqueezed"",\n        ""Thermal"",\n        ""Gaussian"",\n        # measurements\n        ""MeasureHomodyne"",\n        ""MeasureHeterodyne"",\n        ""MeasureFock"",\n        ""MeasureThreshold"",\n        # channels\n        ""LossChannel"",\n        ""ThermalLossChannel"",\n        # single mode gates\n        ""Dgate"",\n        ""Sgate"",\n        ""Rgate"",\n        ""BSgate"",\n    }\n\n    decompositions = {\n        ""Interferometer"": {},\n        ""GraphEmbed"": {},\n        ""BipartiteGraphEmbed"": {},\n        ""GaussianTransform"": {},\n        ""Gaussian"": {},\n        ""Pgate"": {},\n        ""S2gate"": {},\n        ""CXgate"": {},\n        ""CZgate"": {},\n        ""MZgate"": {},\n        ""Xgate"": {},\n        ""Zgate"": {},\n        ""Fouriergate"": {},\n    }\n'"
strawberryfields/circuitspecs/gaussian_unitary.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Circuit specifications for the Gaussian simulator backend.""""""\n\nimport numpy as np\nfrom strawberryfields.program_utils import Command\nfrom strawberryfields import ops\nfrom strawberryfields.parameters import par_evaluate\nfrom thewalrus.symplectic import (\n    expand_vector,\n    expand,\n    rotation,\n    squeezing,\n    two_mode_squeezing,\n    interferometer,\n    beam_splitter,\n)\nfrom .circuit_specs import CircuitSpecs\n\n\nclass GaussianUnitary(CircuitSpecs):\n    """"""Compiler to arrange a Gaussian quantum circuit into the canonical Symplectic form.\n\n    This compile specification checks whether the circuit can be implemented as a sequence of\n    Gaussian operations. If so, it arranges them in the canonical order with displacement at the end.\n    After compilation, the circuit will consist of at most two operations, a :class:`~.GaussianTransform`\n    and a :class:`~.Dgate`.\n\n    This compiler can be accessed by calling :meth:`.Program.compile` with `\'gaussian_unitary\'` specified.\n\n    **Example:**\n\n    Consider the following Strawberry Fields program, compiled using the `\'gaussian_unitary\'` compiler:\n\n    .. code-block:: python3\n\n        from strawberryfields.ops import Xgate, Zgate, Sgate, Dgate, Rgate\n        import strawberryfields as sf\n\n        circuit = sf.Program(1)\n        with circuit.context as q:\n            Xgate(0.4) | q[0]\n            Zgate(0.5) | q[0]\n            Sgate(0.6) | q[0]\n            Dgate(1.0+2.0j) | q[0]\n            Rgate(0.3) | q[0]\n            Sgate(0.6, 1.0) | q[0]\n\n        compiled_circuit = circuit.compile(""gaussian_unitary"")\n\n    We can now print the compiled circuit, consisting of one\n    :class:`~.GaussianTransform` and one :class:`~.Dgate`:\n\n    >>> compiled_circuit.print()\n    GaussianTransform([[ 0.3543 -1.3857]\n                       [-0.0328  2.9508]]) | (q[0])\n    Dgate(-1.151+3.91j, 0) | (q[0])\n    """"""\n\n    short_name = ""gaussian_unitary""\n    modes = None\n    local = True\n    remote = True\n    interactive = True\n\n    primitives = {\n        # meta operations\n        ""All"",\n        ""_New_modes"",\n        ""_Delete"",\n        # single mode gates\n        ""Dgate"",\n        ""Sgate"",\n        ""Rgate"",\n        # multi mode gates\n        ""MZgate"",\n        ""BSgate"",\n        ""S2gate"",\n        ""Interferometer"",  # Note that interferometer is accepted as a primitive\n        ""GaussianTransform"",  # Note that GaussianTransform is accepted as a primitive\n    }\n\n    decompositions = {\n        ""GraphEmbed"": {},\n        ""BipartiteGraphEmbed"": {},\n        ""Gaussian"": {},\n        ""Pgate"": {},\n        ""CXgate"": {},\n        ""CZgate"": {},\n        ""Xgate"": {},\n        ""Zgate"": {},\n        ""Fouriergate"": {},\n    }\n    # pylint: disable=too-many-branches\n    def compile(self, seq, registers):\n        """"""Try to arrange a quantum circuit into the canonical Symplectic form.\n\n        This method checks whether the circuit can be implemented as a sequence of Gaussian operations.\n        If the answer is yes it arranges them in the canonical order with displacement at the end.\n\n        Args:\n            seq (Sequence[Command]): quantum circuit to modify\n            registers (Sequence[RegRefs]): quantum registers\n        Returns:\n            List[Command]: modified circuit\n        Raises:\n            CircuitError: the circuit does not correspond to a Gaussian unitary\n        """"""\n\n        # Check which modes are actually being used\n        used_modes = []\n        for operations in seq:\n            modes = [modes_label.ind for modes_label in operations.reg]\n            used_modes.append(modes)\n        # pylint: disable=consider-using-set-comprehension\n        used_modes = list(set([item for sublist in used_modes for item in sublist]))\n\n        # dictionary mapping the used modes to consecutive non-negative integers\n        dict_indices = {used_modes[i]: i for i in range(len(used_modes))}\n        nmodes = len(used_modes)\n\n        # This is the identity transformation in phase-space, multiply by the identity and add zero\n        Snet = np.identity(2 * nmodes)\n        rnet = np.zeros(2 * nmodes)\n\n        # Now we will go through each operation in the sequence `seq` and apply it in quadrature space\n        # We will keep track of the net transforation in the Symplectic matrix `Snet` and the quadrature\n        # vector `rnet`.\n        for operations in seq:\n            name = operations.op.__class__.__name__\n            params = par_evaluate(operations.op.p)\n            modes = [modes_label.ind for modes_label in operations.reg]\n            if name == ""Dgate"":\n                rnet = rnet + expand_vector(\n                    params[0] * (np.exp(1j * params[1])), dict_indices[modes[0]], nmodes\n                )\n            else:\n                if name == ""Rgate"":\n                    S = expand(rotation(params[0]), dict_indices[modes[0]], nmodes)\n                elif name == ""Sgate"":\n                    S = expand(squeezing(params[0], params[1]), dict_indices[modes[0]], nmodes)\n                elif name == ""S2gate"":\n                    S = expand(\n                        two_mode_squeezing(params[0], params[1]),\n                        [dict_indices[modes[0]], dict_indices[modes[1]]],\n                        nmodes,\n                    )\n                elif name == ""Interferometer"":\n                    S = expand(\n                        interferometer(params[0]), [dict_indices[mode] for mode in modes], nmodes\n                    )\n                elif name == ""GaussianTransform"":\n                    S = expand(params[0], [dict_indices[mode] for mode in modes], nmodes)\n                elif name == ""BSgate"":\n                    S = expand(\n                        beam_splitter(params[0], params[1]),\n                        [dict_indices[modes[0]], dict_indices[modes[1]]],\n                        nmodes,\n                    )\n                elif name == ""MZgate"":\n                    v = np.exp(1j * params[0])\n                    u = np.exp(1j * params[1])\n                    U = 0.5 * np.array([[u * (v - 1), 1j * (1 + v)], [1j * u * (1 + v), 1 - v]])\n                    S = expand(\n                        interferometer(U), [dict_indices[modes[0]], dict_indices[modes[1]]], nmodes,\n                    )\n                Snet = S @ Snet\n                rnet = S @ rnet\n\n        # Having obtained the net displacement we simply convert it into complex notation\n        alphas = 0.5 * (rnet[0:nmodes] + 1j * rnet[nmodes : 2 * nmodes])\n        # And now we just pass the net transformation as a big Symplectic operation plus displacements\n        ord_reg = [r for r in list(registers) if r.ind in used_modes]\n        ord_reg = sorted(list(ord_reg), key=lambda x: x.ind)\n        if np.allclose(Snet, np.identity(2 * nmodes)):\n            A = []\n        else:\n            A = [Command(ops.GaussianTransform(Snet), ord_reg)]\n        B = [\n            Command(ops.Dgate(alphas[i]), ord_reg[i])\n            for i in range(len(ord_reg))\n            if not np.allclose(alphas[i], 0.0)\n        ]\n        return A + B\n'"
strawberryfields/circuitspecs/gbs.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Circuit class specification for the general Gaussian Boson Sampling class of circuits.""""""\n\nfrom strawberryfields.program_utils import CircuitError, Command, group_operations\nimport strawberryfields.ops as ops\n\nfrom .gaussian import GaussianSpecs\n\n\nclass GBSSpecs(GaussianSpecs):\n    """"""Circuit specifications for the general GBS class of circuits.""""""\n\n    short_name = ""gbs""\n    primitives = {\n        # meta operations\n        ""All"",\n        ""_New_modes"",\n        ""_Delete"",\n        # state preparations\n        ""Vacuum"",\n        ""Coherent"",\n        ""Squeezed"",\n        ""DisplacedSqueezed"",\n        ""Thermal"",\n        ""Gaussian"",\n        # measurements\n        ""MeasureHomodyne"",\n        ""MeasureHeterodyne"",\n        ""MeasureFock"",\n        ""MeasureThreshold"",\n        # channels\n        ""LossChannel"",\n        ""ThermalLossChannel"",\n        # single mode gates\n        ""Dgate"",\n        ""Sgate"",\n        ""Rgate"",\n        ""Fouriergate"",\n        ""BSgate"",\n    }\n    decompositions = {""Xgate"": {}, ""Zgate"": {}, ""Fouriergate"": {}, ""S2gate"": {}}\n\n    def compile(self, seq, registers):\n        """"""Try to arrange a quantum circuit into a form suitable for Gaussian boson sampling.\n\n        This method checks whether the circuit can be implemented as a Gaussian boson sampling\n        problem, i.e., if it is equivalent to a circuit A+B, where the sequence A only contains\n        Gaussian operations, and B only contains Fock measurements.\n\n        If the answer is yes, the circuit is arranged into the A+B order, and all the Fock\n        measurements are combined into a single :class:`MeasureFock` operation.\n\n        Args:\n            seq (Sequence[Command]): quantum circuit to modify\n            registers (Sequence[RegRefs]): quantum registers\n        Returns:\n            List[Command]: modified circuit\n        Raises:\n            CircuitError: the circuit does not correspond to GBS\n        """"""\n        A, B, C = group_operations(seq, lambda x: isinstance(x, ops.MeasureFock))\n\n        # C should be empty\n        if C:\n            raise CircuitError(""Operations following the Fock measurements."")\n\n        # A should only contain Gaussian operations\n        # (but this is already guaranteed by group_operations() and our primitive set)\n\n        # without Fock measurements GBS is pointless\n        if not B:\n            raise CircuitError(""GBS circuits must contain Fock measurements."")\n\n        # there should be only Fock measurements in B\n        measured = set()\n        for cmd in B:\n            if not isinstance(cmd.op, ops.MeasureFock):\n                raise CircuitError(""The Fock measurements are not consecutive."")\n\n            # combine the Fock measurements\n            temp = set(cmd.reg)\n            if measured & temp:\n                raise CircuitError(""Measuring the same mode more than once."")\n            measured |= temp\n\n        # replace B with a single Fock measurement\n        B = [Command(ops.MeasureFock(), sorted(list(measured), key=lambda x: x.ind))]\n        return super().compile(A + B, registers)\n'"
strawberryfields/circuitspecs/tensorflow.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Circuit specifications for the TensorFlow simulator backend.""""""\nfrom .circuit_specs import CircuitSpecs\n\n\nclass TFSpecs(CircuitSpecs):\n    """"""Circuit specifications for the TensorFlow backend.""""""\n\n    short_name = ""tf""\n    modes = None\n    local = True\n    remote = False\n    interactive = True\n\n    primitives = {\n        # meta operations\n        ""All"",\n        ""_New_modes"",\n        ""_Delete"",\n        # state preparations\n        ""Vacuum"",\n        ""Coherent"",\n        ""Squeezed"",\n        ""DisplacedSqueezed"",\n        ""Thermal"",\n        ""Fock"",\n        ""Catstate"",\n        ""Ket"",\n        ""DensityMatrix"",\n        # measurements\n        ""MeasureFock"",\n        ""MeasureHomodyne"",\n        # channels\n        ""LossChannel"",\n        # single mode gates\n        ""Dgate"",\n        ""Sgate"",\n        ""Rgate"",\n        ""Vgate"",\n        ""Kgate"",\n        ""Fouriergate"",\n        ""BSgate"",\n        ""CKgate"",\n    }\n\n    decompositions = {\n        ""Interferometer"": {},\n        ""GraphEmbed"": {},\n        ""BipartiteGraphEmbed"": {},\n        ""GaussianTransform"": {},\n        ""Gaussian"": {},\n        ""Pgate"": {},\n        ""S2gate"": {},\n        ""CXgate"": {},\n        ""CZgate"": {},\n        ""MZgate"": {},\n        ""Xgate"": {},\n        ""Zgate"": {},\n        ""Fouriergate"": {},\n    }\n'"
strawberryfields/circuitspecs/xcov.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Circuit class specification for the X class of circuits.""""""\n\nimport copy\n\nimport numpy as np\nfrom thewalrus.quantum import Amat\nfrom thewalrus.symplectic import expand\n\nimport strawberryfields as sf\nfrom strawberryfields.decompositions import takagi\nfrom strawberryfields.program_utils import CircuitError, Command\nimport strawberryfields.ops as ops\n\nfrom .circuit_specs import CircuitSpecs, Ranges\nfrom .gbs import GBSSpecs\nfrom .gaussian_unitary import GaussianUnitary\n\n\nclass Xcov(CircuitSpecs):\n    """"""Circuit specifications for the X class of circuits.\n\n    An important property of this compilation routine is that it is done at the covariance matrix level.\n    This implies that one should not use it to compare the interferometers of a given circuit since they may\n    differ by permutations in the unitary and the squeezing parameters.\n    """"""\n\n    short_name = ""Xcov""\n    modes = None\n    remote = True\n    local = True\n    interactive = False\n    allowed_sq_ranges = Ranges([0], [1.0], variable_name=""r"")\n\n    primitives = {\n        ""S2gate"",\n        ""Sgate"",\n        ""MeasureFock"",\n        ""Rgate"",\n        ""BSgate"",\n        ""MZgate"",\n        ""Interferometer"",\n    }\n\n    decompositions = {\n        ""BipartiteGraphEmbed"": {""mesh"": ""rectangular_symmetric"", ""drop_identity"": False},\n    }\n\n    def compile(self, seq, registers):\n        # the number of modes in the provided program\n        n_modes = len(registers)\n\n        # Number of modes must be even\n        if n_modes % 2 != 0:\n            raise CircuitError(""The X series only supports programs with an even number of modes."")\n\n        # Call the GBS compiler to do basic measurement validation.\n        # The GBS compiler also merges multiple measurement commands\n        # into a single MeasureFock command at the end of the circuit.\n        seq = GBSSpecs().compile(seq, registers)\n\n        # ensure that all modes are measured\n        if len(seq[-1].reg) != n_modes:\n            raise CircuitError(""All modes must be measured."")\n\n        # Use the GaussianUnitary compiler to compute the symplectic\n        # matrix representing the Gaussian operations.\n        # Note that the Gaussian unitary compiler does not accept measurements,\n        # so we append the measurement separately.\n        meas_seq = [seq[-1]]\n        seq = GaussianUnitary().compile(seq[:-1], registers) + meas_seq\n\n        # determine the modes that are acted on by the symplectic transformation\n        used_modes = [x.ind for x in seq[0].reg]\n\n        # extract the compiled symplectic matrix\n        S = seq[0].op.p[0]\n\n        if len(used_modes) != n_modes:\n            # The symplectic transformation acts on a subset of\n            # the programs registers. We must expand the symplectic\n            # matrix to one that acts on all registers.\n            # simply extract the computed symplectic matrix\n            S = expand(seq[0].op.p[0], used_modes, n_modes)\n\n        half_n_modes = n_modes // 2\n\n        # Construct the covariance matrix of the state.\n        # Note that hbar is a global variable that is set by the user\n        cov = (sf.hbar / 2) * S @ S.T\n\n        # Construct the A matrix\n        A = Amat(cov, hbar=sf.hbar)\n\n        # Construct the adjacency matrix represented by the A matrix.\n        # This must be an weighted, undirected bipartite graph. That is,\n        # B00 = B11 = 0 (no edges between the two vertex sets 0 and 1),\n        # and B01 == B10.T (undirected edges between the two vertex sets).\n        B = A[:n_modes, :n_modes]\n        B00 = B[:half_n_modes, :half_n_modes]\n        B01 = B[:half_n_modes, half_n_modes:]\n        B10 = B[half_n_modes:, :half_n_modes]\n        B11 = B[half_n_modes:, half_n_modes:]\n\n        # Perform unitary validation to ensure that the\n        # applied unitary is valid.\n\n        if not np.allclose(B00, 0) or not np.allclose(B11, 0):\n            # Not a bipartite graph\n            raise CircuitError(\n                ""The applied unitary cannot mix between the modes {}-{} and modes {}-{}."".format(\n                    0, half_n_modes - 1, half_n_modes, n_modes - 1\n                )\n            )\n\n        if not np.allclose(B01, B10):\n            # Not a symmetric bipartite graph\n            raise CircuitError(\n                ""The applied unitary on modes {}-{} must be identical to the applied unitary on modes {}-{}."".format(\n                    0, half_n_modes - 1, half_n_modes, n_modes - 1\n                )\n            )\n\n        # Now that the unitary has been validated, perform the Takagi decomposition\n        # to determine the constituent two-mode squeezing and interferometer\n        # parameters.\n        sqs, U = takagi(B01)\n        sqs = np.arctanh(sqs)\n\n        # ensure provided S2gates all have the allowed squeezing values\n        if not all(s in self.allowed_sq_ranges for s in sqs):\n            wrong_sq_values = [np.round(s, 4) for s in sqs if s not in self.allowed_sq_ranges]\n            raise CircuitError(\n                ""Incorrect squeezing value(s) r={}. Allowed squeezing ""\n                ""value(s) are {}."".format(wrong_sq_values, self.allowed_sq_ranges)\n            )\n\n        # Convert the squeezing values into a sequence of S2gate commands\n        sq_seq = [\n            Command(ops.S2gate(sqs[i]), [registers[i], registers[i + half_n_modes]])\n            for i in range(half_n_modes)\n        ]\n\n        # NOTE: at some point, it might make sense to add a keyword argument to this method,\n        # to allow the user to specify if they want the interferometers decomposed or not.\n\n        # Convert the unitary into a sequence of MZgate and Rgate commands on the signal modes\n        U1 = ops.Interferometer(U, mesh=""rectangular_symmetric"", drop_identity=False)._decompose(\n            registers[:half_n_modes]\n        )\n        U2 = copy.deepcopy(U1)\n\n        for Ui in U2:\n            Ui.reg = [registers[r.ind + half_n_modes] for r in Ui.reg]\n\n        return sq_seq + U1 + U2 + meas_seq\n'"
strawberryfields/circuitspecs/xunitary.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Circuit class specification for the X class of circuits.""""""\n\nimport copy\n\nimport numpy as np\nfrom thewalrus.symplectic import expand\n\nfrom strawberryfields.program_utils import CircuitError, Command, group_operations\n\nimport strawberryfields.ops as ops\n\nfrom .circuit_specs import CircuitSpecs, Ranges\nfrom .gbs import GBSSpecs\nfrom .gaussian_unitary import GaussianUnitary\n\n\nclass Xunitary(CircuitSpecs):\n    """"""Circuit specifications for the X class of circuits.""""""\n\n    short_name = ""Xunitary""\n    modes = None\n    remote = True\n    local = True\n    interactive = False\n    allowed_sq_ranges = Ranges([0], [1.0], variable_name=""r"")\n    sq_amplitude = 1.0\n\n    primitives = {\n        ""S2gate"",\n        ""Sgate"",\n        ""MeasureFock"",\n        ""Rgate"",\n        ""BSgate"",\n        ""MZgate"",\n        ""Interferometer"",\n    }\n\n    decompositions = {\n        ""BipartiteGraphEmbed"": {""mesh"": ""rectangular_symmetric"", ""drop_identity"": False,},\n    }\n\n    def compile(self, seq, registers):\n        # the number of modes in the provided program\n        n_modes = len(registers)\n\n        # Number of modes must be even\n        if n_modes % 2 != 0:\n            raise CircuitError(""The X series only supports programs with an even number of modes."")\n        half_n_modes = n_modes // 2\n        # Call the GBS compiler to do basic measurement validation.\n        # The GBS compiler also merges multiple measurement commands\n        # into a single MeasureFock command at the end of the circuit.\n        seq = GBSSpecs().compile(seq, registers)\n\n        # ensure that all modes are measured\n        if len(seq[-1].reg) != n_modes:\n            raise CircuitError(""All modes must be measured."")\n\n        # Check circuit begins with two-mode squeezers\n        # --------------------------------------------\n        A, B, C = group_operations(seq, lambda x: isinstance(x, ops.S2gate))\n        # If there are no two-mode squeezers add squeezers at the beginning with squeezing param equal to zero.\n        if B == []:\n            initS2 = [\n                Command(ops.S2gate(0, 0), [registers[i], registers[i + half_n_modes]])\n                for i in range(half_n_modes)\n            ]\n            seq = initS2 + seq\n            A, B, C = group_operations(seq, lambda x: isinstance(x, ops.S2gate))\n\n        if A != []:\n            raise CircuitError(""There can be no operations before the S2gates."")\n\n        regrefs = set()\n\n        if B:\n            # get set of circuit registers as a tuple for each S2gate\n            regrefs = {(cmd.reg[0].ind, cmd.reg[1].ind) for cmd in B}\n\n        # the set of allowed mode-tuples the S2gates must have\n        allowed_modes = set(zip(range(0, half_n_modes), range(half_n_modes, n_modes)))\n\n        if not regrefs.issubset(allowed_modes):\n            raise CircuitError(""S2gates do not appear on the correct modes."")\n\n        # determine which modes do not have input S2gates specified\n        missing = allowed_modes - regrefs\n\n        for i, j in missing:\n            # insert S2gates with 0 squeezing\n            B.insert(0, Command(ops.S2gate(0, 0), [registers[i], registers[j]]))\n\n        sqs = [cmd.op.p[0] for cmd in B]\n\n        # ensure provided S2gates all have the allowed squeezing values\n        if not all(s in self.allowed_sq_ranges for s in sqs):\n            wrong_sq_values = [np.round(s, 4) for s in sqs if s not in self.allowed_sq_ranges]\n            raise CircuitError(\n                ""Incorrect squeezing value(s) r={}. Allowed squeezing ""\n                ""value(s) are {}."".format(wrong_sq_values, self.allowed_sq_ranges)\n            )\n        # This could in principle be changed\n        phases = [cmd.op.p[1] for cmd in B]\n        if not np.allclose(phases, 0):\n            raise CircuitError(\n                ""Incorrect phase value(s) phi={}. Allowed squeezing ""\n                ""value(s) are 0.0."".format(phases)\n            )\n\n        meas_seq = [C[-1]]\n        seq = GaussianUnitary().compile(C[:-1], registers)\n\n        # extract the compiled symplectic matrix\n        if seq == []:\n            S = np.identity(2 * n_modes)\n            used_modes = list(range(n_modes))\n        else:\n            S = seq[0].op.p[0]\n            # determine the modes that are acted on by the symplectic transformation\n            used_modes = [x.ind for x in seq[0].reg]\n\n        if not np.allclose(S @ S.T, np.identity(len(S))):\n            raise CircuitError(\n                ""The operations after squeezing do not correspond to an interferometer.""\n            )\n\n        if len(used_modes) != n_modes:\n            # The symplectic transformation acts on a subset of\n            # the programs registers. We must expand the symplectic\n            # matrix to one that acts on all registers.\n            # simply extract the computed symplectic matrix\n            S = expand(seq[0].op.p[0], used_modes, n_modes)\n\n        U = S[:n_modes, :n_modes] - 1j * S[:n_modes, n_modes:]\n        U11 = U[:half_n_modes, :half_n_modes]\n        U12 = U[:half_n_modes, half_n_modes:]\n        U21 = U[half_n_modes:, :half_n_modes]\n        U22 = U[half_n_modes:, half_n_modes:]\n        if not np.allclose(U12, 0) or not np.allclose(U21, 0):\n            # Not a bipartite graph\n            raise CircuitError(\n                ""The applied unitary cannot mix between the modes {}-{} and modes {}-{}."".format(\n                    0, half_n_modes - 1, half_n_modes, n_modes - 1\n                )\n            )\n\n        if not np.allclose(U11, U22):\n            # Not a symmetric bipartite graph\n            raise CircuitError(\n                ""The applied unitary on modes {}-{} must be identical to the applied unitary on modes {}-{}."".format(\n                    0, half_n_modes - 1, half_n_modes, n_modes - 1\n                )\n            )\n        U1 = ops.Interferometer(U11, mesh=""rectangular_symmetric"", drop_identity=False)._decompose(\n            registers[:half_n_modes]\n        )\n        U2 = copy.deepcopy(U1)\n\n        for Ui in U2:\n            Ui.reg = [registers[r.ind + half_n_modes] for r in Ui.reg]\n\n        return B + U1 + U2 + meas_seq\n'"
strawberryfields/cli/__init__.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""A standalone command-line interface for configuring Strawberry Fields and connecting\nto the Xanadu cloud platform.\n""""""\n\nimport argparse\nimport sys\n\nfrom strawberryfields.api import Connection\nfrom strawberryfields.configuration import ConfigurationError, create_config, store_account\nfrom strawberryfields.engine import RemoteEngine\nfrom strawberryfields.io import load\n\n\ndef main():\n    """"""The Xanadu cloud platform command line interface.\n\n    **Example:**\n\n    The following is a simple example on getting the help message of the cloud platform command\n    line interface. It details each of the options available.\n\n    .. code-block:: console\n\n        $ sf\n        usage: sf [-h] [--ping] {configure,run} ...\n\n        See below for available options and commands for working with the Xanadu cloud platform.\n\n        General Options:\n          -h, --help       show this help message and exit\n          --ping, -p       Tests the connection to the remote backend.\n\n        Commands:\n          {configure,run}\n            configure      Configure each detail of the API connection.\n            run            Run a blackbird script.\n    """"""\n    parser = create_parser()\n    args = parser.parse_args()\n\n    if args.ping:\n        ping()\n    elif hasattr(args, ""func""):\n        args.func(args)\n    else:\n        parser.print_help()\n\n\ndef create_parser():\n    """"""Creates a parser to process the commands and arguments passed to the\n    command line interface.\n\n    Returns:\n        ArgumentParser: an argument parser object that defines the related\n        options\n    """"""\n    parser = argparse.ArgumentParser(\n        description=""See below for available options and commands for working with the Xanadu cloud platform.""\n    )\n\n    # Setting a title for the general options (requires setting a private\n    # attribute)\n    parser._optionals.title = ""General Options""\n\n    # Adding the pinging general option\n    parser.add_argument(\n        ""--ping"", ""-p"", action=""store_true"", help=""Tests the connection to the remote backend.""\n    )\n\n    # Adding subparsers configure and input\n    subparsers = parser.add_subparsers(title=""Commands"")\n\n    # Adding the configure subparser\n    configure_parser = subparsers.add_parser(\n        ""configure"", help=""Configure each detail of the API connection.""\n    )\n    configure_parser.set_defaults(func=configure)\n\n    configure_parser.add_argument(\n        ""--token"",\n        ""-t"",\n        type=str,\n        help=""Configure Strawberry Fields with your Xanadu cloud platform API token."",\n    )\n    configure_parser.add_argument(\n        ""--local"",\n        ""-l"",\n        action=""store_true"",\n        help=""Create a local configuration file in the current directory."",\n    )\n\n    # Adding the input subparser\n    run_parser = subparsers.add_parser(""run"", help=""Run a blackbird script."")\n    run_parser.add_argument(\n        ""input"", type=str, help=""The filename or path to the blackbird script to run.""\n    )\n    run_parser.set_defaults(func=run_blackbird_script)\n    run_parser.add_argument(\n        ""--output"",\n        ""-o"",\n        help=""Path to the output file, where the results of the program will be written (stdout by default)."",\n    )\n\n    return parser\n\n\ndef configure(args):\n    r""""""An auxiliary function for configuring the API connection to the Xanadu\n    cloud platform.\n\n    Can be used to simply save the authentication token with default\n    configuration options. Alternatively, a wizard is provided for full\n    configurability.\n\n    See more details regarding Strawberry Fields configuration and available\n    configuration options on the :doc:`/code/sf_configuration` page.\n\n    Args:\n        args (ArgumentParser): arguments that were specified on the command\n            line stored as attributes in an argument parser object\n    """"""\n    if args.token:\n        kwargs = {""authentication_token"": args.token}\n    else:\n        kwargs = configuration_wizard()\n\n    if args.local:\n        store_account(**kwargs, location=""local"")\n    else:\n        store_account(**kwargs)\n\n\ndef ping():\n    """"""Tests the connection to the remote backend.""""""\n    if Connection().ping():\n        sys.stdout.write(""You have successfully authenticated to the platform!\\n"")\n    else:\n        sys.stdout.write(""There was a problem when authenticating to the platform!\\n"")\n\n\ndef configuration_wizard():\n    r""""""Provides an interactive selection wizard on the command line to\n    configure every option for the API connection.\n\n    Default configuration options are provided as defaults to the user.\n    Configuration options are detailed in :doc:`/code/sf_configuration`.\n\n    Returns:\n        dict[str, Union[str, bool, int]]: the configuration options\n    """"""\n    default_config = create_config()[""api""]\n\n    # Getting default values that can be used for as messages when getting inputs\n    hostname_default = default_config[""hostname""]\n    ssl_default = ""y"" if default_config[""use_ssl""] else ""n""\n    port_default = default_config[""port""]\n\n    authentication_token = input(\n        ""Please enter the authentication token to use when connecting: [] ""\n    )\n\n    if not authentication_token:\n        sys.stdout.write(""No authentication token was provided, please configure again."")\n        sys.exit()\n\n    hostname = (\n        input(\n            ""Please enter the hostname of the server to connect to: [{}] "".format(hostname_default)\n        )\n        or hostname_default\n    )\n\n    ssl_input = (\n        input(""Should the client attempt to connect over SSL? [{}] "".format(ssl_default))\n        or ssl_default\n    )\n    use_ssl = ssl_input.upper() == ""Y""\n\n    port = (\n        input(""Please enter the port number to connect with: [{}] "".format(port_default))\n        or port_default\n    )\n\n    kwargs = {\n        ""authentication_token"": authentication_token,\n        ""hostname"": hostname,\n        ""use_ssl"": use_ssl,\n        ""port"": port,\n    }\n    return kwargs\n\n\ndef run_blackbird_script(args):\n    """"""Run a blackbird script.\n\n    Related arguments:\n    * input: the input blackbird script to be run\n    * output: the output file to store the results in (optional)\n\n    Args:\n        args (ArgumentParser): arguments that were specified on the command\n            line stored as attributes in an argument parser object\n    """"""\n    try:\n        program = load(args.input)\n    except FileNotFoundError:\n        sys.stdout.write(""The {} blackbird script was not found."".format(args.input))\n        sys.exit()\n\n    eng = RemoteEngine(program.target)\n\n    sys.stdout.write(""Executing program on remote hardware...\\n"")\n    result = eng.run(program)\n\n    if result and result.samples is not None:\n        write_script_results(result.samples, output_file=args.output)\n    else:\n        sys.stdout.write(\n            ""Ooops! Something went wrong with obtaining the results. Please check the Blackbird script specified and the connection to the remote engine.""\n        )\n        sys.exit()\n\n\ndef write_script_results(samples, output_file=None):\n    """"""Write the results of the script either to a file or to the standard output.\n\n    Args:\n        samples (array[float]): array of samples\n        output_file (str or None): the path to the output file, None if no output was defined\n    """"""\n    if output_file:\n        with open(output_file, ""w"") as file:\n            file.write(str(samples))\n    else:\n        sys.stdout.write(str(samples))\n'"
tests/api/__init__.py,0,b''
tests/api/conftest.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nTest fixtures and shared functions for strawberryfields.api tests\n""""""\nimport pytest\n\nfrom strawberryfields import Program, ops\nfrom strawberryfields.api import Connection\n\n# pylint: disable=expression-not-assigned\n\n\n@pytest.fixture\ndef prog():\n    """"""Program fixture.""""""\n    program = Program(8)\n    with program.context as q:\n        ops.Rgate(0.5) | q[0]\n        ops.Rgate(0.5) | q[4]\n        ops.MeasureFock() | q\n    return program\n\n\n@pytest.fixture\ndef connection():\n    """"""A mock connection object.""""""\n    return Connection(token=""token"", host=""host"", port=123, use_ssl=True)\n\n\ndef mock_return(return_value):\n    """"""A helper function for defining a mock function that returns the given value for\n    any arguments.\n    """"""\n    return lambda *args, **kwargs: return_value\n'"
tests/api/test_connection.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nUnit tests for strawberryfields.api.connection\n""""""\nfrom datetime import datetime\nimport io\nimport os\n\nimport numpy as np\nimport pytest\nimport requests\n\nfrom strawberryfields.api import Connection, JobStatus, RequestFailedError\nfrom strawberryfields import configuration as conf\nfrom .conftest import mock_return\n\n# pylint: disable=no-self-use,unused-argument\n\npytestmark = pytest.mark.api\n\nTEST_CONFIG_FILE_1 = """"""\\\n[api]\n# Options for the Strawberry Fields Cloud API\nauthentication_token = ""DummyToken""\nhostname = ""DummyHost""\nuse_ssl = false\nport = 1234\n""""""\n\nTEST_CONFIG_FILE_2 = """"""\\\n[api]\n# Options for the Strawberry Fields Cloud API\nauthentication_token = ""071cdcce-9241-4965-93af-4a4dbc739135""\nhostname = ""platform.strawberryfields.ai""\nuse_ssl = true\nport = 443\n""""""\n\n\nclass MockResponse:\n    """"""A mock response with a JSON or binary body.""""""\n\n    def __init__(self, status_code, json_body=None, binary_body=None):\n        self.status_code = status_code\n        self.json_body = json_body\n        self.binary_body = binary_body\n\n    def json(self):\n        """"""Mocks the ``requests.Response.json()`` method.""""""\n        return self.json_body\n\n    @property\n    def content(self):\n        """"""Mocks the ``requests.Response.content`` property.""""""\n        return self.binary_body\n\n\nclass TestConnection:\n    """"""Tests for the ``Connection`` class.""""""\n\n    def test_init(self):\n        """"""Tests that a ``Connection`` is initialized correctly.""""""\n        token, host, port, use_ssl = ""token"", ""host"", 123, True\n        connection = Connection(token, host, port, use_ssl)\n\n        assert connection.token == token\n        assert connection.host == host\n        assert connection.port == port\n        assert connection.use_ssl == use_ssl\n\n        # pylint: disable=protected-access\n        assert connection._url(""/abc"") == ""https://host:123/abc""\n\n    def test_create_job(self, prog, connection, monkeypatch):\n        """"""Tests a successful job creation flow.""""""\n        id_, status = ""123"", JobStatus.QUEUED\n\n        monkeypatch.setattr(\n            requests, ""post"", mock_return(MockResponse(201, {""id"": id_, ""status"": status})),\n        )\n\n        job = connection.create_job(""X8_01"", prog, {""shots"": 1})\n\n        assert job.id == id_\n        assert job.status == status.value\n\n    def test_create_job_error(self, prog, connection, monkeypatch):\n        """"""Tests a failed job creation flow.""""""\n        monkeypatch.setattr(requests, ""post"", mock_return(MockResponse(400, {})))\n\n        with pytest.raises(RequestFailedError, match=""Failed to create job""):\n            connection.create_job(""X8_01"", prog, {""shots"": 1})\n\n    @pytest.mark.xfail(reason=""method not yet implemented"")\n    def test_get_all_jobs(self, connection, monkeypatch):\n        """"""Tests a successful job list request.""""""\n        jobs = [\n            {\n                ""id"": str(i),\n                ""status"": JobStatus.COMPLETED,\n                ""created_at"": ""2020-01-{:02d}T12:34:56.123456Z"".format(i),\n            }\n            for i in range(1, 10)\n        ]\n        monkeypatch.setattr(\n            requests, ""get"", mock_return(MockResponse(200, {""data"": jobs})),\n        )\n\n        jobs = connection.get_all_jobs(after=datetime(2020, 1, 5))\n\n        assert [job.id for job in jobs] == [str(i) for i in range(5, 10)]\n\n    @pytest.mark.xfail(reason=""method not yet implemented"")\n    def test_get_all_jobs_error(self, connection, monkeypatch):\n        """"""Tests a failed job list request.""""""\n        monkeypatch.setattr(requests, ""get"", mock_return(MockResponse(404, {})))\n\n        with pytest.raises(RequestFailedError, match=""Failed to get all jobs""):\n            connection.get_all_jobs()\n\n    def test_get_job(self, connection, monkeypatch):\n        """"""Tests a successful job request.""""""\n        id_, status, meta = ""123"", JobStatus.COMPLETED, {""abc"": ""def""}\n\n        monkeypatch.setattr(\n            requests,\n            ""get"",\n            mock_return(MockResponse(200, {""id"": id_, ""status"": status.value, ""meta"": meta})),\n        )\n\n        job = connection.get_job(id_)\n\n        assert job.id == id_\n        assert job.status == status.value\n        assert job.meta == meta\n\n    def test_get_job_error(self, connection, monkeypatch):\n        """"""Tests a failed job request.""""""\n        monkeypatch.setattr(requests, ""get"", mock_return(MockResponse(404, {})))\n\n        with pytest.raises(RequestFailedError, match=""Failed to get job""):\n            connection.get_job(""123"")\n\n    def test_get_job_status(self, connection, monkeypatch):\n        """"""Tests a successful job status request.""""""\n        id_, status = ""123"", JobStatus.COMPLETED\n\n        monkeypatch.setattr(\n            requests,\n            ""get"",\n            mock_return(MockResponse(200, {""id"": id_, ""status"": status.value, ""meta"": {}})),\n        )\n\n        assert connection.get_job_status(id_) == status.value\n\n    def test_get_job_status_error(self, connection, monkeypatch):\n        """"""Tests a failed job status request.""""""\n        monkeypatch.setattr(requests, ""get"", mock_return(MockResponse(404, {})))\n\n        with pytest.raises(RequestFailedError, match=""Failed to get job""):\n            connection.get_job_status(""123"")\n\n    @pytest.mark.parametrize(\n        ""result_dtype"",\n        [\n            np.int8,\n            np.int16,\n            np.int32,\n            np.int64,\n            np.uint8,\n            np.uint16,\n            np.uint32,\n            np.uint64,\n            np.float32,\n            np.float64,\n        ],\n    )\n    def test_get_job_result(self, connection, result_dtype, monkeypatch):\n        """"""Tests a successful job result request.""""""\n        result_samples = np.array([[1, 2], [3, 4]], dtype=result_dtype)\n\n        with io.BytesIO() as buf:\n            np.save(buf, result_samples)\n            buf.seek(0)\n            monkeypatch.setattr(\n                requests, ""get"", mock_return(MockResponse(200, binary_body=buf.getvalue())),\n            )\n\n        result = connection.get_job_result(""123"")\n\n        assert np.array_equal(result.samples, result_samples)\n\n    def test_get_job_result_error(self, connection, monkeypatch):\n        """"""Tests a failed job result request.""""""\n        monkeypatch.setattr(requests, ""get"", mock_return(MockResponse(404, {})))\n\n        with pytest.raises(RequestFailedError, match=""Failed to get job result""):\n            connection.get_job_result(""123"")\n\n    def test_cancel_job(self, connection, monkeypatch):\n        """"""Tests a successful job cancellation request.""""""\n        # A custom `mock_return` that checks for expected arguments\n        def _mock_return(return_value):\n            def function(*args, **kwargs):\n                assert kwargs.get(""json"") == {""status"": ""cancelled""}\n                return return_value\n\n            return function\n\n        monkeypatch.setattr(requests, ""patch"", _mock_return(MockResponse(204, {})))\n\n        # A successful cancellation does not raise an exception\n        connection.cancel_job(""123"")\n\n    def test_cancel_job_error(self, connection, monkeypatch):\n        """"""Tests a failed job cancellation request.""""""\n        monkeypatch.setattr(requests, ""patch"", mock_return(MockResponse(404, {})))\n\n        with pytest.raises(RequestFailedError, match=""Failed to cancel job""):\n            connection.cancel_job(""123"")\n\n    def test_ping_success(self, connection, monkeypatch):\n        """"""Tests a successful ping to the remote host.""""""\n        monkeypatch.setattr(requests, ""get"", mock_return(MockResponse(200, {})))\n\n        assert connection.ping()\n\n    def test_ping_failure(self, connection, monkeypatch):\n        """"""Tests a failed ping to the remote host.""""""\n        monkeypatch.setattr(requests, ""get"", mock_return(MockResponse(500, {})))\n\n        assert not connection.ping()\n\n\nclass TestConnectionIntegration:\n    """"""Integration tests for using instances of the Connection.""""""\n\n    def test_configuration_deleted_integration(self, monkeypatch, tmpdir):\n        """"""Check that once two Connection instances indeed differ in their\n        configuration if the configuration is being deleted in the meantime.\n\n        The logic of the test goes as follows:\n        1. Two temporary paths and files are being created\n        2. The directories to be checked are mocked out to the temporary paths\n        3. A connection object is created, using the configuration from the\n        first config\n        4. The first configuration is deleted, leaving the second config as\n        default\n        5. Another connection object is created, using the configuration from the\n        second config\n        6. Checks for the configuration for each Connection instances\n        """"""\n        test_file_name = ""config.toml""\n\n        # Creating the two temporary paths and files\n        path1 = tmpdir.mkdir(""sub1"")\n        path2 = tmpdir.mkdir(""sub2"")\n\n        file1 = path1.join(test_file_name)\n        file2 = path2.join(test_file_name)\n\n        with open(file1, ""w"") as f:\n            f.write(TEST_CONFIG_FILE_1)\n\n        with open(file2, ""w"") as f:\n            f.write(TEST_CONFIG_FILE_2)\n\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: path1)\n            m.delenv(""SF_CONF"", raising=False)\n            m.setattr(conf, ""user_config_dir"", lambda *args: path2)\n\n            a = Connection()\n            assert os.path.exists(file1)\n\n            assert a.token == ""DummyToken""\n            assert a.host == ""DummyHost""\n            assert a.port == 1234\n            assert a.use_ssl == False\n            conf.delete_config(directory=path1)\n\n            assert not os.path.exists(file1)\n\n            b = Connection()\n            assert b.token == ""071cdcce-9241-4965-93af-4a4dbc739135""\n            assert b.host == ""platform.strawberryfields.ai""\n            assert b.port == 443\n            assert b.use_ssl == True\n'"
tests/api/test_job.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nUnit tests for strawberryfields.api.job\n""""""\nimport pytest\n\nfrom strawberryfields.api import InvalidJobOperationError, Job, JobStatus\n\n# pylint: disable=bad-continuation,no-self-use,pointless-statement\n\npytestmark = pytest.mark.api\n\n\nclass TestJob:\n    """"""Tests for the ``Job`` class.""""""\n\n    def test_incomplete_job_raises_on_result_access(self, connection):\n        """"""Tests that `job.result` raises an error for an incomplete job.""""""\n        job = Job(""abc"", status=JobStatus.QUEUED, connection=connection)\n\n        with pytest.raises(\n            AttributeError, match=""The result is undefined for jobs that are not completed"",\n        ):\n            job.result\n\n    def test_completed_job_raises_on_cancel_request(self, connection):\n        """"""Tests that `job.cancel()` raises an error for a completed job.""""""\n        job = Job(""abc"", status=JobStatus.COMPLETED, connection=connection)\n\n        with pytest.raises(InvalidJobOperationError, match=""A complete job cannot be cancelled""):\n            job.cancel()\n\n    def test_failed_job_raises_on_cancel_request(self, connection):\n        """"""Tests that `job.cancel()` raises an error for a failed job.""""""\n        job = Job(""abc"", status=JobStatus.FAILED, connection=connection)\n\n        with pytest.raises(InvalidJobOperationError, match=""A failed job cannot be cancelled""):\n            job.cancel()\n\n    def test_cancelled_job_raises_on_cancel_request(self, connection):\n        """"""Tests that `job.cancel()` raises an error for a completed job.""""""\n        job = Job(""abc"", status=JobStatus.CANCELLED, connection=connection)\n\n        with pytest.raises(InvalidJobOperationError, match=""A cancelled job cannot be cancelled""):\n            job.cancel()\n'"
tests/api/test_remote_engine.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nUnit tests for strawberryfields.engine.RemoteEngine\n""""""\nimport numpy as np\nimport pytest\n\nfrom strawberryfields.api import Connection, Job, JobStatus, Result\nfrom strawberryfields.engine import RemoteEngine\n\nfrom .conftest import mock_return\n\n# pylint: disable=bad-continuation,unused-argument,no-self-use,redefined-outer-name,pointless-statement\n\npytestmark = pytest.mark.api\n\n\nclass MockServer:\n    """"""A mock platform server that fakes a processing delay by counting requests.""""""\n\n    REQUESTS_BEFORE_COMPLETED = 3\n\n    def __init__(self):\n        self.request_count = 0\n\n    def get_job(self, _id):\n        """"""Returns a \'queued\' job status until the number of requests exceeds a defined\n        threshold, beyond which a \'complete\' job status is returned.\n        """"""\n        self.request_count += 1\n        status = (\n            JobStatus.COMPLETED\n            if self.request_count >= self.REQUESTS_BEFORE_COMPLETED\n            else JobStatus.QUEUED\n        )\n        return Job(id_=""123"", status=status, connection=None, meta={""foo"": ""bar""})\n\n\n@pytest.fixture\ndef job_to_complete(connection, monkeypatch):\n    """"""Mocks a remote job that is completed after a certain number of requests.""""""\n    monkeypatch.setattr(\n        Connection,\n        ""create_job"",\n        mock_return(Job(id_=""123"", status=JobStatus.OPEN, connection=connection)),\n    )\n    server = MockServer()\n    monkeypatch.setattr(Connection, ""get_job"", server.get_job)\n    monkeypatch.setattr(\n        Connection,\n        ""get_job_result"",\n        mock_return(Result(np.array([[1, 2], [3, 4]]), is_stateful=False)),\n    )\n\n\nclass TestRemoteEngine:\n    """"""Tests for the ``RemoteEngine`` class.""""""\n\n    def test_run_complete(self, connection, prog, job_to_complete):\n        """"""Tests a successful blocking job execution.""""""\n        engine = RemoteEngine(""X8_01"", connection=connection)\n        result = engine.run(prog, shots=10)\n\n        assert np.array_equal(result.samples, np.array([[1, 2], [3, 4]]))\n\n        with pytest.raises(\n            AttributeError, match=""The state is undefined for a stateless computation.""\n        ):\n            result.state\n\n    def test_run_async(self, connection, prog, job_to_complete):\n        """"""Tests a successful non-blocking job execution.""""""\n\n        engine = RemoteEngine(""X8_01"", connection=connection)\n        job = engine.run_async(prog, shots=10)\n        assert job.status == JobStatus.OPEN.value\n\n        for _ in range(MockServer.REQUESTS_BEFORE_COMPLETED):\n            job.refresh()\n\n        assert job.status == JobStatus.COMPLETED.value\n        assert job.meta == {""foo"": ""bar""}\n        assert np.array_equal(job.result.samples, np.array([[1, 2], [3, 4]]))\n\n        with pytest.raises(\n            AttributeError, match=""The state is undefined for a stateless computation.""\n        ):\n            job.result.state\n\n    def test_device_class_target(self):\n        """"""Test that the remote engine correctly instantiates itself\n        when provided with a non-specific target""""""\n        target = ""X8""\n        engine = RemoteEngine(target)\n        assert engine.target == engine.DEFAULT_TARGETS[target]\n\n    def test_run_options_from_kwargs(self, prog, monkeypatch):\n        """"""Test that the remote engine run_async method correctly\n        passes all keyword argument backend and runtime options to the create_job\n        method.""""""\n        monkeypatch.setattr(Connection, ""create_job"", lambda *args: args)\n        engine = RemoteEngine(""X8"", backend_options={""cutoff_dim"": 12})\n        _, _, _, run_options = engine.run_async(prog, shots=1234)\n        assert run_options == {""shots"": 1234, ""cutoff_dim"": 12}\n\n        # run options from keyword arguments overwrite\n        # run options provided by the program object\n        prog = prog.compile(""X8"", shots=15)\n        _, _, _, run_options = engine.run_async(prog, shots=1234)\n        assert run_options == {""shots"": 1234, ""cutoff_dim"": 12}\n\n    def test_run_options_from_program(self, prog, monkeypatch):\n        """"""Test that the remote engine run_async method correctly\n        parses runtime options compiled into the program""""""\n        monkeypatch.setattr(Connection, ""create_job"", lambda *args: args)\n        engine = RemoteEngine(""X8"")\n\n        prog = prog.compile(""X8"", shots=15)\n        assert prog.run_options == {""shots"": 15}\n\n        _, _, _, run_options = engine.run_async(prog)\n        assert run_options == {""shots"": 15}\n\n    def test_no_shots(self, prog, connection):\n        """"""Test that if the number of shots is not provided, an\n        exception is raised""""""\n        engine = RemoteEngine(""X8"", connection=connection)\n\n        with pytest.raises(ValueError, match=""Number of shots must be specified""):\n            engine.run_async(prog)\n\n\nclass TestRemoteEngineIntegration:\n    """"""Integration tests for the remote engine""""""\n\n    def test_compilation(self, prog, monkeypatch):\n        """"""Test that the remote engine correctly compiles a program\n        for the intended backend""""""\n        monkeypatch.setattr(Connection, ""create_job"", lambda *args: args)\n\n        engine = RemoteEngine(""X8"")\n        _, target, res_prog, _ = engine.run_async(prog, shots=10)\n\n        assert target == RemoteEngine.DEFAULT_TARGETS[""X8""]\n\n        # check program is compiled to match the chip template\n        expected = prog.compile(""X8"").circuit\n        res = res_prog.circuit\n\n        for cmd1, cmd2 in zip(res, expected):\n            # loop through all commands in res and expected\n\n            # check gates are the same\n            assert type(cmd1.op) is type(cmd2.op)\n            # check modes are the same\n            assert all(i.ind == j.ind for i, j in zip(cmd1.reg, cmd2.reg))\n            # check parameters are the same\n            assert all(p1 == p2 for p1, p2 in zip(cmd1.op.p, cmd2.op.p))\n'"
tests/api/test_result.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nUnit tests for strawberryfields.api.result\n""""""\nimport numpy as np\nimport pytest\n\nfrom strawberryfields.api import Result\n\n# pylint: disable=bad-continuation,no-self-use,pointless-statement\n\npytestmark = pytest.mark.api\n\n\nclass TestResult:\n    """"""Tests for the ``Result`` class.""""""\n\n    def test_stateless_result_raises_on_state_access(self):\n        """"""Tests that `result.state` raises an error for a stateless result.\n        """"""\n        result = Result(np.array([[1, 2], [3, 4]]), is_stateful=False)\n\n        with pytest.raises(\n            AttributeError, match=""The state is undefined for a stateless computation.""\n        ):\n            result.state\n\n    def test_stateless_print(self, capfd):\n        """"""Test that printing a result object with no state provides the correct output.""""""\n        result = Result(np.array([[1, 2], [3, 4], [5, 6]]), is_stateful=False)\n        print(result)\n        out, err = capfd.readouterr()\n        assert ""modes=2"" in out\n        assert ""shots=3"" in out\n        assert ""contains state=False"" in out\n\n    def test_state_print(self, capfd):\n        """"""Test that printing a result object with a state provides the correct output.""""""\n        result = Result(np.array([[1, 2], [3, 4], [5, 6]]), is_stateful=True)\n        print(result)\n        out, err = capfd.readouterr()\n        assert ""modes=2"" in out\n        assert ""shots=3"" in out\n        assert ""contains state=True"" in out\n'"
tests/apps/conftest.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nconftest.py file for use in pytest\n""""""\nimport numpy as np\nimport networkx as nx\nimport pytest\n\npytestmark = pytest.mark.apps\n\n\n@pytest.fixture\ndef adj(dim: int):\n    """"""Creates a fixed adjacency matrix of size ``dim`` with alternating zeros and nonzeros in a\n    checkerboard pattern.\n\n    The nonzero value is fixed to 0.5. This can, e.g., prevent issues with square roots,\n    and also explore any problems with weighted graph edges.\n\n    Args:\n        dim (int): dimension of adjacency matrix\n\n    Returns:\n        array: NumPy adjacency matrix of dimension ``dim`` with each element a ``float``.\n    """"""\n    a = np.zeros((dim, dim), dtype=float)\n\n    a[1::2, ::2] = 0.5\n    a[::2, 1::2] = 0.5\n\n    return a\n\n\n@pytest.fixture\ndef graph(dim: int):\n    """"""Creates the NetworkX graph of ``dim`` nodes corresponding to the checkerboard adjacency\n    matrix in :func:`adj`\n\n    Args:\n        dim (int): number of nodes in graph\n\n    Returns: graph: NetworkX graph of dimension ``dim`` corresponding to the adjacency matrix in\n    :func:`adj`\n    """"""\n\n    a = np.zeros((dim, dim), dtype=float)\n\n    a[1::2, ::2] = 0.5\n    a[::2, 1::2] = 0.5\n\n    return nx.Graph(a)\n'"
tests/apps/test_clique.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\r\n\r\n# Licensed under the Apache License, Version 2.0 (the ""License"");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an ""AS IS"" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\nr""""""\r\nUnit tests for strawberryfields.apps.clique\r\n""""""\r\n# pylint: disable=no-self-use,unused-argument\r\nimport functools\r\n\r\nimport networkx as nx\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom strawberryfields.apps import clique\r\n\r\npytestmark = pytest.mark.apps\r\n\r\n\r\ndef patch_random_choice(x, element):\r\n    """"""Dummy function for ``np.random.choice`` to make output deterministic. This dummy function\r\n    just returns the element of ``x`` specified by ``element``.""""""\r\n    if isinstance(x, int):  # np.random.choice can accept an int or 1D array-like input\r\n        return element\r\n\r\n    return x[element]\r\n\r\n\r\ndef patch_resize(c, graph, node_select):\r\n    """"""Dummy function for ``grow`` and ``swap`` to make output unchanged.""""""\r\n    return c\r\n\r\n\r\nclass TestLocalSearch:\r\n    """"""Tests for the function ``clique.search``""""""\r\n\r\n    def test_bad_iterations(self):\r\n        """"""Test if function raises a ``ValueError`` when a non-positive number of iterations is\r\n        specified""""""\r\n        with pytest.raises(ValueError, match=""Number of iterations must be a positive int""):\r\n            clique.search(clique=[0, 1, 2, 3], graph=nx.complete_graph(5), iterations=-1)\r\n\r\n    def test_max_iterations(self, monkeypatch):\r\n        """"""Test if function stops after 5 iterations despite not being in a dead end (i.e., when\r\n        ``grow != swap``). This is achieved by monkeypatching the ``np.random.choice`` call in\r\n        ``grow`` and ``swap`` so that for a 5-node wheel graph starting as a [0,\r\n        1] node clique, the algorithm simply oscillates between [0, 1, 2] and [0, 2, 3] for each\r\n        iteration of growth & swap. For odd iterations, we get [0, 2, 3].""""""\r\n\r\n        graph = nx.wheel_graph(5)\r\n        c = [0, 1]\r\n\r\n        with monkeypatch.context() as m:\r\n            p = functools.partial(patch_random_choice, element=0)\r\n            m.setattr(np.random, ""choice"", p)\r\n            result = clique.search(c, graph, iterations=5)\r\n\r\n        assert result == [0, 2, 3]\r\n\r\n    def test_dead_end(self, monkeypatch):\r\n        """"""Test if function stops when in a dead end (i.e., ``grow == swap``) such that no\r\n        swapping is possible. This is achieved by monkeypatching ``grow`` and\r\n        ``swap`` so that they simply return the same clique as fed in, which should cause\r\n        the local search algorithm to conclude that it is already in a dead end and return the\r\n        same clique.""""""\r\n\r\n        graph = nx.complete_graph(5)\r\n        c = [0, 1, 2]\r\n\r\n        with monkeypatch.context() as m:\r\n            m.setattr(clique, ""grow"", patch_resize)\r\n            m.setattr(clique, ""swap"", patch_resize)\r\n            result = clique.search(c, graph, iterations=100)\r\n\r\n        assert result == c\r\n\r\n    def test_expected_growth(self):\r\n        """"""Test if function performs a growth and swap phase, followed by another growth and\r\n        attempted swap phase. This is carried out by starting with a 4+1 node lollipop graph,\r\n        adding a connection from node 4 to node 2 and starting with the [3, 4] clique. The local\r\n        search algorithm should first grow to [2, 3, 4] and then swap to either [0, 2, 3] or [1,\r\n        2, 3], and then grow again to [0, 1, 2, 3] and being unable to swap, hence returning [0,\r\n        1, 2, 3]""""""\r\n\r\n        graph = nx.lollipop_graph(4, 1)\r\n        graph.add_edge(4, 2)\r\n\r\n        c = [3, 4]\r\n        result = clique.search(c, graph, iterations=100)\r\n        assert result == [0, 1, 2, 3]\r\n\r\n\r\n@pytest.mark.parametrize(""dim"", range(4, 10))\r\nclass TestGrow:\r\n    """"""Tests for the function ``strawberryfields.clique.grow``""""""\r\n\r\n    def test_grow_maximal(self, dim):\r\n        """"""Test if function grows to expected maximal graph and then stops. The chosen graph is\r\n        composed of two fully connected graphs joined together at one node. Starting from the\r\n        first node, ``grow`` is expected to grow to be the first fully connected graph.""""""\r\n        graph = nx.barbell_graph(dim, 0)\r\n        s = [0]\r\n        assert set(clique.grow(s, graph)) == set(range(dim))\r\n\r\n    def test_grow_maximal_degree(self, dim):\r\n        """"""Test if function grows to expected maximal graph when degree-based node selection is\r\n        used. The chosen graph is a fully connected graph with only the final node being\r\n        connected to an additional node. Furthermore, the ``dim - 2`` node is disconnected from\r\n        the ``dim - 1`` node. Starting from the first ``dim - 3`` nodes, one can either add in\r\n        the ``dim - 2`` node or the ``dim - 1`` node. The ``dim - 1`` node has a higher degree\r\n        due to the lollipop graph structure, and hence should be selected.""""""\r\n        graph = nx.lollipop_graph(dim, 1)\r\n        graph.remove_edge(dim - 2, dim - 1)\r\n        s = set(range(dim - 2))\r\n        target = s | {dim - 1}\r\n        assert set(clique.grow(s, graph, node_select=""degree"")) == target\r\n\r\n    def test_grow_maximal_degree_tie(self, dim, monkeypatch):\r\n        """"""Test if function grows using randomness to break ties during degree-based node\r\n        selection. The chosen graph is a fully connected graph with the ``dim - 2`` and ``dim -\r\n        1`` nodes then disconnected. Starting from the first ``dim - 3`` nodes, one can add\r\n        either of the ``dim - 2`` and ``dim - 1`` nodes. As they have the same degree, they should\r\n        be selected randomly with equal probability. This function monkeypatches the\r\n        ``np.random.choice`` call to guarantee that one of the nodes is picked during one run of\r\n        ``grow`` and the other node is picked during the next run.""""""\r\n        graph = nx.complete_graph(dim)\r\n        graph.remove_edge(dim - 2, dim - 1)\r\n        s = set(range(dim - 2))\r\n\r\n        patch_random_choice_1 = functools.partial(patch_random_choice, element=0)\r\n        patch_random_choice_2 = functools.partial(patch_random_choice, element=1)\r\n\r\n        with monkeypatch.context() as m:\r\n            m.setattr(np.random, ""choice"", patch_random_choice_1)\r\n            c1 = clique.grow(s, graph, node_select=""degree"")\r\n\r\n        with monkeypatch.context() as m:\r\n            m.setattr(np.random, ""choice"", patch_random_choice_2)\r\n            c2 = clique.grow(s, graph, node_select=""degree"")\r\n\r\n        assert c1 != c2\r\n\r\n    def test_grow_maximal_weight(self, dim):\r\n        """"""Test if function grows to expected maximal graph when weight-based node selection is\r\n        used. The chosen graph is a fully connected graph where the final three nodes have\r\n        subsequently been disconnected from each other, but remain connected to all the other\r\n        nodes. We then start from the clique composed of all but the final three nodes and seek\r\n        to grow. In this construction, we can add just one of the final three nodes. This test\r\n        gives the final node the largest weight, so we expect that one to be added.""""""\r\n        graph = nx.complete_graph(dim)\r\n        s = graph.subgraph([dim - 3, dim - 2, dim - 1])\r\n        for e in s.edges():\r\n            graph.remove_edge(*e)\r\n\r\n        s = set(range(dim - 3))\r\n        weights = list(range(dim))\r\n        target = s | {dim - 1}\r\n        assert set(clique.grow(s, graph, node_select=weights)) == target\r\n\r\n    def test_grow_maximal_weight_tie(self, dim, monkeypatch):\r\n        """"""Test if function grows using randomness to break ties during weight-based node\r\n        selection. The chosen graph is a fully connected graph where the final three nodes have\r\n        subsequently been disconnected from each other, but remain connected to all the other\r\n        nodes. We then start from the clique composed of all but the final three nodes and seek\r\n        to grow. In this construction, we can add just one of the final three nodes. This test\r\n        gives every node the same weight, so we expect that they should be selected randomly with\r\n        equal probability. This test monkeypatches the ``np.random.choice`` call to guarantee\r\n        that one of the nodes is picked during one run of ``grow`` and the another node is picked\r\n        during the next run.""""""\r\n        graph = nx.complete_graph(dim)\r\n        s = graph.subgraph([dim - 3, dim - 2, dim - 1])\r\n        for e in s.edges():\r\n            graph.remove_edge(*e)\r\n\r\n        s = set(range(dim - 3))\r\n        weights = [1 for _ in range(dim)]\r\n\r\n        patch_random_choice_1 = functools.partial(patch_random_choice, element=0)\r\n        patch_random_choice_2 = functools.partial(patch_random_choice, element=1)\r\n\r\n        with monkeypatch.context() as m:\r\n            m.setattr(np.random, ""choice"", patch_random_choice_1)\r\n            c1 = clique.grow(s, graph, node_select=weights)\r\n\r\n        with monkeypatch.context() as m:\r\n            m.setattr(np.random, ""choice"", patch_random_choice_2)\r\n            c2 = clique.grow(s, graph, node_select=weights)\r\n\r\n        target1 = list(s | {dim - 3})\r\n        target2 = list(s | {dim - 2})\r\n        assert c1 != c2\r\n        assert target1 == c1 and target2 == c2\r\n\r\n    def test_input_not_clique(self, dim):\r\n        """"""Tests if function raises a ``ValueError`` when input is not a clique""""""\r\n        with pytest.raises(ValueError, match=""Input subgraph is not a clique""):\r\n            clique.grow([0, 1], nx.empty_graph(dim))\r\n\r\n    def test_bad_node_select(self, dim):\r\n        """"""Tests if function raises a ``ValueError`` when input an invalid ``node_select``\r\n        argument""""""\r\n        graph = nx.barbell_graph(dim, 0)\r\n        s = [0]\r\n        with pytest.raises(ValueError, match=""Node selection method not recognized""):\r\n            clique.grow(s, graph, node_select="""")\r\n\r\n    def test_input_not_subgraph(self, dim):\r\n        """"""Test if function raises a ``ValueError`` when input is not a subgraph""""""\r\n        with pytest.raises(ValueError, match=""Input is not a valid subgraph""):\r\n            clique.grow([dim + 1], nx.empty_graph(dim))\r\n\r\n    def test_bad_weights(self, dim, graph):\r\n        """"""Test if function raises a ``ValueError`` when a vector of node weights input to\r\n        ``node_select`` is not of the same dimension as the input graph.""""""\r\n        s = [0, 1]\r\n        w = np.ones(dim - 1)\r\n        with pytest.raises(ValueError, match=""Number of node weights must match number of nodes""):\r\n            clique.grow(s, graph, node_select=w)\r\n\r\n\r\n@pytest.mark.parametrize(""dim"", range(5, 10))\r\nclass TestSwap:\r\n    """"""Tests for the function ``strawberryfields.clique.swap``""""""\r\n\r\n    def test_swap(self, dim):\r\n        """"""Test if function performs correct swap operation. Input is a complete graph with a\r\n        connection between node ``0`` and ``dim - 1`` removed. An input clique of the first\r\n        ``dim - 1`` nodes is then input, with the result being a different clique with the first\r\n        node removed and the ``dim`` node added.""""""\r\n        graph = nx.complete_graph(dim)\r\n        graph.remove_edge(0, dim - 1)\r\n        s = list(range(dim - 1))\r\n        assert set(clique.swap(s, graph)) == set(range(1, dim))\r\n\r\n    def test_swap_degree(self, dim):\r\n        """"""Test if function performs correct swap operation when degree-based node selection is\r\n        used. Input graph is a lollipop graph, consisting of a fully connected graph with a\r\n        single additional node connected to just one of the nodes in the graph. Additionally,\r\n        a connection between node ``0`` and ``dim - 1`` is removed as well as a connection\r\n        between node ``0`` and ``dim - 2``. A clique of the first ``dim - 2`` nodes is then\r\n        input. In this case, C1 consists of nodes ``dim - 1`` and ``dim - 2``. However,\r\n        node ``dim - 1`` has greater degree due to the extra node in the lollipop graph. This\r\n        test confirms that the resultant swap is performed correctly.""""""\r\n        graph = nx.lollipop_graph(dim, 1)\r\n        graph.remove_edge(0, dim - 1)\r\n        graph.remove_edge(0, dim - 2)\r\n        s = list(range(dim - 2))\r\n        result = set(clique.swap(s, graph, node_select=""degree""))\r\n        expected = set(range(1, dim - 2)) | {dim - 1}\r\n        assert result == expected\r\n\r\n    def test_swap_degree_tie(self, dim, monkeypatch):\r\n        """"""Test if function performs correct swap operation using randomness to break ties during\r\n        degree-based node selection. Input graph is a fully connected graph. Additionally,\r\n        a connection between node ``0`` and ``dim - 1`` is removed as well as a connection\r\n        between node ``0`` and ``dim - 2``. A clique of the first ``dim - 2`` nodes is then\r\n        input. In this case, C1 consists of nodes ``dim - 1`` and ``dim - 2``. As they have the\r\n        same degree, they should be selected randomly with equal probability. This function\r\n        monkeypatches the ``np.random.choice`` call to guarantee that one of the nodes is picked\r\n        during one run of ``swap`` and the other node is picked during the next run.\r\n        """"""\r\n        graph = nx.complete_graph(dim)\r\n        graph.remove_edge(0, dim - 1)\r\n        graph.remove_edge(0, dim - 2)\r\n        s = set(range(dim - 2))\r\n\r\n        patch_random_choice_1 = functools.partial(patch_random_choice, element=0)\r\n        patch_random_choice_2 = functools.partial(patch_random_choice, element=1)\r\n\r\n        with monkeypatch.context() as m:\r\n            m.setattr(np.random, ""choice"", patch_random_choice_1)\r\n            c1 = clique.swap(s, graph, node_select=""degree"")\r\n\r\n        with monkeypatch.context() as m:\r\n            m.setattr(np.random, ""choice"", patch_random_choice_2)\r\n            c2 = clique.swap(s, graph, node_select=""degree"")\r\n\r\n        assert c1 != c2\r\n\r\n    def test_swap_weight(self, dim):\r\n        """"""Test if function performs correct swap operation when weight-based node selection is\r\n        used. The input graph is a complete graph with the ``(dim - 1, dim - 3)`` and\r\n        ``(dim - 2, dim - 4)`` edges removed. The starting clique is the first ``dim - 2`` nodes.\r\n        This results in two candidate swap pairs: ``(dim - 1, dim - 3)`` and ``(dim - 2, dim - 4)``.\r\n        Since node ``dim - 1`` has the largest weight, we expect to swap that in by removing node\r\n        ``dim - 3``.""""""\r\n        graph = nx.complete_graph(dim)\r\n        graph.remove_edge(dim - 1, dim - 3)\r\n        graph.remove_edge(dim - 2, dim - 4)\r\n        s = list(range(dim - 2))\r\n        weights = list(range(dim))\r\n        result = set(clique.swap(s, graph, node_select=weights))\r\n        expected = set(range(dim - 3)) | {dim - 1}\r\n        assert result == expected\r\n\r\n    def test_swap_weight_tie(self, dim, monkeypatch):\r\n        """"""Test if function performs correct swap operation using randomness to break ties during\r\n        degree-based node selection. The input graph is a complete graph with the ``(dim - 1,\r\n        dim - 3)`` and ``(dim - 2, dim - 4)`` edges removed. The starting clique is the first\r\n        ``dim - 2`` nodes. This results in two candidate swap pairs: ``(dim - 1, dim - 3)`` and\r\n        ``(dim - 2, dim - 4)``. This test gives the every node the same weight, so we expect that\r\n        either pair should be selected randomly with equal probability. This test monkeypatches\r\n        the ``np.random.choice`` call to guarantee that one of the nodes is picked during one run\r\n        of ``swap`` and the another node is picked during the next run.\r\n        """"""\r\n        graph = nx.complete_graph(dim)\r\n        graph.remove_edge(dim - 1, dim - 3)\r\n        graph.remove_edge(dim - 2, dim - 4)\r\n        s = list(range(dim - 2))\r\n        weights = [1 for _ in range(dim)]\r\n\r\n        patch_random_choice_1 = functools.partial(patch_random_choice, element=0)\r\n        patch_random_choice_2 = functools.partial(patch_random_choice, element=1)\r\n\r\n        with monkeypatch.context() as m:\r\n            m.setattr(np.random, ""choice"", patch_random_choice_1)\r\n            c1 = clique.swap(s, graph, node_select=weights)\r\n\r\n        with monkeypatch.context() as m:\r\n            m.setattr(np.random, ""choice"", patch_random_choice_2)\r\n            c2 = clique.swap(s, graph, node_select=weights)\r\n\r\n        assert c1 != c2\r\n\r\n    def test_input_not_clique(self, dim):\r\n        """"""Tests if function raises a ``ValueError`` when input is not a clique""""""\r\n        with pytest.raises(ValueError, match=""Input subgraph is not a clique""):\r\n            clique.swap([0, 1], nx.empty_graph(dim))\r\n\r\n    def test_input_valid_subgraph(self, dim):\r\n        """"""Tests if function raises a ``ValueError`` when input is not a clique""""""\r\n        with pytest.raises(ValueError, match=""Input is not a valid subgraph""):\r\n            clique.swap([0, dim], nx.empty_graph(dim))\r\n\r\n    def test_bad_node_select(self, dim):\r\n        """"""Tests if function raises a ``ValueError`` when input an invalid ``node_select``\r\n        argument""""""\r\n        graph = nx.barbell_graph(dim, 0)\r\n        s = [0]\r\n        with pytest.raises(ValueError, match=""Node selection method not recognized""):\r\n            clique.swap(s, graph, node_select="""")\r\n\r\n    def test_bad_weights(self, dim, graph):\r\n        """"""Test if function raises a ``ValueError`` when a vector of node weights input to\r\n        ``node_select`` is not of the same dimension as the input graph.""""""\r\n        s = [0, 1]\r\n        w = np.ones(dim - 1)\r\n        with pytest.raises(ValueError, match=""Number of node weights must match number of nodes""):\r\n            clique.swap(s, graph, node_select=w)\r\n\r\n\r\n@pytest.mark.parametrize(""dim"", range(6, 10))\r\nclass TestShrink:\r\n    """"""Tests for the function ``clique.shrink``""""""\r\n\r\n    def test_is_output_clique(self, dim):\r\n        """"""Test that the output subgraph is a valid clique, in this case the maximum clique\r\n        in a lollipop graph""""""\r\n        graph = nx.lollipop_graph(dim, dim)\r\n        subgraph = list(range(2 * dim))  # subgraph is the entire graph\r\n        resized = clique.shrink(subgraph, graph)\r\n        assert clique.is_clique(graph.subgraph(resized))\r\n        assert resized == list(range(dim))\r\n\r\n    def test_input_clique_then_output_clique(self, dim):\r\n        """"""Test that if the input is already a clique, then the output is the same clique. """"""\r\n        graph = nx.lollipop_graph(dim, dim)\r\n        subgraph = list(range(dim))  # this is a clique, the ""candy"" of the lollipop\r\n\r\n        assert clique.shrink(subgraph, graph) == subgraph\r\n\r\n    def test_degree_relative_to_subgraph(self, dim):\r\n        """"""Test that function removes nodes of small degree relative to the subgraph,\r\n        not relative to the entire graph. This is done by creating an unbalanced barbell graph,\r\n        with one ""bell"" larger than the other. The input subgraph is the small bell (a clique) plus\r\n        a node from the larger bell. The function should remove only the node from the larger\r\n        bell, since this has a low degree within the subgraph, despite having high degree overall""""""\r\n        g = nx.disjoint_union(nx.complete_graph(dim), nx.complete_graph(dim + 1))\r\n        g.add_edge(dim, dim - 1)\r\n        subgraph = list(range(dim + 1))\r\n        assert clique.shrink(subgraph, g) == list(range(dim))\r\n\r\n    def test_wheel_graph(self, dim):\r\n        """"""Test that output is correct for a wheel graph, whose largest cliques have dimension\r\n        3. The cliques always include the central spoke and two consecutive nodes in the outer\r\n        wheel.""""""\r\n        graph = nx.wheel_graph(dim)\r\n        subgraph = graph.nodes()  # subgraph is the entire graph\r\n        subgraph = clique.shrink(subgraph, graph)\r\n\r\n        assert len(subgraph) == 3\r\n        assert subgraph[0] == 0\r\n        assert subgraph[1] + 1 == subgraph[2] or (subgraph[1] == 1 and subgraph[2] == dim - 1)\r\n\r\n    def test_wheel_graph_tie(self, dim, monkeypatch):\r\n        """"""Test that output is correct for a wheel graph, whose largest cliques have dimension\r\n        3. The cliques always include the central spoke and two consecutive nodes in the outer\r\n        wheel. Since the function uses randomness in node selection when there is a tie (which\r\n        occurs in the case of the wheel graph), the resultant shrunk cliques are expected to be\r\n        different each time ``shrink`` is run. This function monkeypatches the\r\n        ``np.random.choice`` call so that different nodes are removed during each run.""""""\r\n        graph = nx.wheel_graph(dim)\r\n        subgraph = graph.nodes()  # subgraph is the entire graph\r\n\r\n        patch_random_choice_1 = functools.partial(patch_random_choice, element=0)\r\n        patch_random_choice_2 = functools.partial(patch_random_choice, element=1)\r\n\r\n        with monkeypatch.context() as m:\r\n            m.setattr(np.random, ""choice"", patch_random_choice_1)\r\n            c1 = clique.shrink(subgraph, graph)\r\n        with monkeypatch.context() as m:\r\n            m.setattr(np.random, ""choice"", patch_random_choice_2)\r\n            c2 = clique.shrink(subgraph, graph)\r\n\r\n        assert c1 != c2\r\n\r\n    def test_weight_based_ties(self, dim):\r\n        """"""Test that the function returns the correct clique when using weight-based node\r\n        selection to settle ties. The starting graph is a barbell graph and the subgraph is taken\r\n        to be the whole graph. The weights of the first clique in the barbell are set to be less\r\n        than the weights of the second, so that we expect the function to return the second\r\n        clique.""""""\r\n        graph = nx.barbell_graph(dim, 0)\r\n        subgraph = graph.nodes()\r\n        weights = [1] * dim + [2] * dim\r\n\r\n        c = clique.shrink(subgraph, graph, node_select=weights)\r\n        assert c == list(range(dim, 2 * dim))\r\n\r\n    def test_weight_and_degree_ties(self, dim, monkeypatch):\r\n        """"""Test that the function settles ties at random when node-weight based node selection is\r\n        used but there is still a tie, i.e., nodes with equal weight. The starting graph is a\r\n        complete graph with one edge removed between the first two nodes, and the subgraph is\r\n        taken to be the whole graph. All nodes have equal weight. In this problem, the function\r\n        can either remove the first or second node to make a clique. Either node should be\r\n        removed at random, and this test monkeypatches the ``np.random.choice`` call to ensure\r\n        both eventualities occur.""""""\r\n        graph = nx.complete_graph(dim)\r\n        subgraph = graph.nodes()\r\n        graph.remove_edge(0, 1)\r\n        weights = [1] * dim\r\n\r\n        patch_random_choice_1 = functools.partial(patch_random_choice, element=0)\r\n        patch_random_choice_2 = functools.partial(patch_random_choice, element=1)\r\n\r\n        with monkeypatch.context() as m:\r\n            m.setattr(np.random, ""choice"", patch_random_choice_1)\r\n            c1 = clique.shrink(subgraph, graph, node_select=weights)\r\n        with monkeypatch.context() as m:\r\n            m.setattr(np.random, ""choice"", patch_random_choice_2)\r\n            c2 = clique.shrink(subgraph, graph, node_select=weights)\r\n\r\n        target1 = list(range(1, dim))\r\n        target2 = [0] + list(range(2, dim))\r\n\r\n        assert c1 != c2\r\n        assert c1 == target1 and c2 == target2\r\n\r\n    def test_bad_weights(self, dim, graph):\r\n        """"""Test if function raises a ``ValueError`` when a vector of node weights input to\r\n        ``node_select`` is not of the same dimension as the input graph.""""""\r\n        s = [0, 1]\r\n        w = np.ones(dim - 1)\r\n        with pytest.raises(ValueError, match=""Number of node weights must match number of nodes""):\r\n            clique.shrink(s, graph, node_select=w)\r\n\r\n    def test_bad_node_select(self, dim):\r\n        """"""Tests if function raises a ``ValueError`` when input an invalid ``node_select``\r\n        argument""""""\r\n        graph = nx.barbell_graph(dim, 0)\r\n        s = list(range(2 * dim))\r\n        with pytest.raises(ValueError, match=""Node selection method not recognized""):\r\n            clique.shrink(s, graph, node_select="""")\r\n\r\n\r\n@pytest.mark.parametrize(""dim"", range(2, 10))\r\nclass TestIsClique:\r\n    """"""Tests for the function `strawberryfields.apps.clique.is_clique` """"""\r\n\r\n    def test_no_false_negatives(self, dim):\r\n        """"""Tests that cliques are labelled as such""""""\r\n        g = nx.complete_graph(dim)\r\n        assert clique.is_clique(g)\r\n\r\n    def test_no_false_positives(self, dim):\r\n        """"""Tests that non-cliques are labelled as such""""""\r\n        g = nx.empty_graph(dim)\r\n        assert not clique.is_clique(g)\r\n\r\n\r\n@pytest.mark.parametrize(""dim"", range(2, 10))\r\nclass TestC0:\r\n    """"""Tests function :math:`c_0` that generates the set of nodes connected to all nodes in a\r\n    clique""""""\r\n\r\n    def test_correct_c_0(self, dim):\r\n        """"""Tests that :math:`c_0` is generated correctly for the lollipop graph""""""\r\n        g = nx.lollipop_graph(dim, 1)\r\n        s = set(range(int(dim / 2)))\r\n        res = set(clique.c_0(s, g))\r\n\r\n        assert res not in s\r\n        assert {dim + 1} not in res\r\n        assert res | s == set(range(dim))\r\n\r\n    def test_c_0_comp_graph(self, dim):\r\n        """""" Tests that the set :math:`c_0` for a node in a clique consists of all remaining nodes""""""\r\n        A = nx.complete_graph(dim)\r\n        S = [dim - 1]\r\n        K = clique.c_0(S, A)\r\n\r\n        assert K == list(range(dim - 1))\r\n\r\n    def test_c_0_error_on_not_clique_input(self, dim):\r\n        """"""Tests if function raises a ``ValueError`` when input is not a clique""""""\r\n        A = np.ones((dim, dim)) - np.eye(dim)\r\n        A = nx.Graph(A)\r\n        A.remove_edge(0, 1)\r\n        S = [0, 1]\r\n\r\n        with pytest.raises(ValueError, match=""Input subgraph is not a clique""):\r\n            clique.c_0(S, A)\r\n\r\n\r\n@pytest.mark.parametrize(""dim"", range(4, 10))\r\nclass TestC1:\r\n    """"""Tests function :math:`c_1` that generates the set of nodes connected to all *but one* of\r\n    the nodes in a clique""""""\r\n\r\n    def test_c_1_comp_graph(self, dim):\r\n        """"""Tests that :math:`c_1` set is correctly generated for an almost-complete graph, where\r\n        edge (0, 1) is removed """"""\r\n        A = nx.complete_graph(dim)\r\n        A.remove_edge(0, 1)\r\n        S = list(range(1, dim))\r\n        c1 = clique.c_1(S, A)\r\n\r\n        assert c1 == [(1, 0)]\r\n\r\n    def test_c_1_swap_to_clique(self, dim):\r\n        """"""Tests that :math:`c_1` set gives a valid clique after swapping """"""\r\n        A = nx.complete_graph(dim)\r\n        A.remove_edge(0, 1)\r\n        S = list(range(1, dim))\r\n        c1 = clique.c_1(S, A)\r\n        swap_nodes = c1[0]\r\n        S.remove(swap_nodes[0])\r\n        S.append(swap_nodes[1])\r\n\r\n        assert clique.is_clique(A.subgraph(S))\r\n\r\n    def test_c_1_error_on_not_clique_input(self, dim):\r\n        """"""Tests if function raises a ``ValueError`` when input is not a clique""""""\r\n        A = np.ones((dim, dim)) - np.eye(dim)\r\n        A = nx.Graph(A)\r\n        A.remove_edge(0, 1)\r\n        S = [0, 1]\r\n\r\n        with pytest.raises(ValueError, match=""Input subgraph is not a clique""):\r\n            clique.c_1(S, A)\r\n'"
tests/apps/test_cost.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nUnit tests for strawberryfields.apps.train.cost\n""""""\nimport itertools\n\n# pylint: disable=no-self-use\nimport numpy as np\nimport pytest\n\nfrom strawberryfields.apps import train\nfrom strawberryfields.apps.train import cost, embed, param\n\npytestmark = pytest.mark.apps\n\ntest_data = [[0, 0, 0, 0], [0, 2, 2, 2], [0, 0, 0, 2], [0, 0, 2, 2], [0, 2, 2, 0], [0, 0, 0, 4]]\nn_means_data = np.mean(test_data, axis=0)\ntest_data = [[t[:d] for t in test_data] for d in range(2, 5)]\nn_means_gbs = [[1, 1], [2 / 3, 2 / 3, 2 / 3], [1 / 2, 1 / 2, 1 / 2, 1 / 2]]\ntest_sum_log_probs = [6.931471805599451, 12.644620176064302, 22.377710881470353]\n\ntest_data_th = [[0, 0, 0, 0], [0, 1, 1, 1], [0, 0, 0, 1], [0, 0, 1, 1], [0, 1, 1, 0], [0, 0, 0, 1]]\nn_means_data_th = np.mean(test_data_th, axis=0)\ntest_data_th = [[t[:d] for t in test_data_th] for d in range(2, 5)]\nn_means_gbs_th = [[1 / 2, 1 / 2], [1 / 3, 1 / 3, 1 / 3, 1 / 3], [1 / 4, 1 / 4, 1 / 4, 1 / 4]]\ntest_sum_log_probs_th = [1.386294361119879, 1.6218604324326575, 2.287080906458072]\n\nparams_fixed = [0, 0, 0, 0]\nweights = [1, 1, 1, 1]\ntest_jacobian = -np.eye(4)\nmean_photon_number = 2\nmean_photon_number_th = 1\nA_eye = np.eye(4)\n\n\n@pytest.mark.parametrize(""k"", range(3))  # nr_modes = k + 2\nclass TestKL:\n    """"""Tests for the class ``train.cost.KL""""""\n\n    def test_mean_data(self, k):\n        """"""Tests the mean photon number per mode from hard-coded values stored in the array\n        ``n_means_data``. The test iterates over different numbers of modes in the data.""""""\n        m = k + 2\n        embedding = embed.Exp(m)\n        vgbs = param.VGBS(A_eye[:m, :m], mean_photon_number, embedding, threshold=False)\n        kl = cost.KL(test_data[k], vgbs)\n        assert np.allclose(kl.mean_n_data, n_means_data[:m])\n        assert len(kl.mean_n_data) == m\n\n    def test_grad(self, k):\n        """"""Tests the calculation of the gradient against an explicit computation from hard-coded\n        values of trainable parameters and mean photon numbers from data and model.""""""\n        m = k + 2\n        embedding = embed.Exp(m)\n        vgbs = param.VGBS(A_eye[:m, :m], mean_photon_number, embedding, threshold=False)\n        kl = cost.KL(test_data[k], vgbs)\n        gamma = [-(n_means_data[i] - n_means_gbs[k][i]) / weights[i] for i in range(m)]\n        assert np.allclose(kl.grad(params_fixed[:m]), gamma @ test_jacobian[:m, :m])\n\n    def test_cost(self, k):\n        """"""Tests the calculation of the Kullback-Liebler cost function against an explicit\n        computation from hard-coded values of trainable parameters and mean photon numbers\n        from data and model.""""""\n        m = k + 2\n        embedding = embed.Exp(m)\n        vgbs = param.VGBS(A_eye[:m, :m], mean_photon_number, embedding, threshold=False)\n        kl = cost.KL(test_data[k], vgbs)\n        assert np.allclose(kl(params_fixed[:m]), test_sum_log_probs[k] / 6)\n\n    def test_mean_data_threshold(self, k):\n        """"""Tests the mean photon number per mode from hard-coded values stored in the array\n        ``n_means_data``. The test iterates over different numbers of modes in the data.""""""\n        m = k + 2\n        embedding = embed.Exp(m)\n        vgbs = param.VGBS(A_eye[:m, :m], mean_photon_number_th, embedding, threshold=True)\n        kl = cost.KL(test_data_th[k], vgbs)\n        assert np.allclose(kl.mean_n_data, n_means_data_th[:m])\n        assert len(kl.mean_n_data) == m\n\n    def test_grad_threshold(self, k):\n        """"""Tests the calculation of the gradient against an explicit computation from hard-coded\n        values of trainable parameters and mean photon numbers from data and model.""""""\n        m = k + 2\n        embedding = embed.Exp(m)\n        vgbs = param.VGBS(A_eye[:m, :m], mean_photon_number_th, embedding, threshold=True)\n        kl = cost.KL(test_data_th[k], vgbs)\n        gamma = [-(n_means_data_th[i] - n_means_gbs_th[k][i]) / weights[i] for i in range(m)]\n        assert np.allclose(kl.grad(params_fixed[:m]), gamma @ test_jacobian[:m, :m])\n\n\ndef h(sample):\n    """"""Cost function that applies to a single sample and gets lower if there are photons in odd\n    numbered modes and higher with photons in even numbered modes. The higher-numbered modes have a\n    greater effect due to the (i + 1) term.""""""\n    return -sum([s * (i + 1) * (-1) ** (i + 1) for i, s in enumerate(sample)])\n\n\n@pytest.fixture\ndef embedding(dim):\n    """"""Fixture feature-based embedding""""""\n    feats = np.arange(0, dim * (dim - 1)).reshape((dim, dim - 1))\n    return train.embed.ExpFeatures(feats)\n\n\n@pytest.fixture\ndef simple_embedding(dim):\n    """"""Fixture simple embedding""""""\n    return train.embed.Exp(dim)\n\n\n@pytest.fixture\ndef A(dim):\n    """"""Fully connected and non-normalized adjacency matrix""""""\n    return np.ones((dim, dim))\n\n\n@pytest.fixture\ndef vgbs(A, n_mean, embedding, threshold):\n    """"""VGBS for the fully connected adjacency matrix using the exponential embedding""""""\n    return train.VGBS(A, n_mean, embedding, threshold)\n\n\n@pytest.fixture\ndef params(dim):\n    """"""Trainable parameters initialized as a slight perturbation from all zeros""""""\n    return np.array([0.01 * i for i in range(dim - 1)])\n\n\n@pytest.mark.parametrize(""dim"", [4])\n@pytest.mark.parametrize(""n_mean"", [1])\n@pytest.mark.usefixtures(""vgbs"")\nclass TestStochastic:\n    """"""Tests for the class ``train.Stochastic``""""""\n\n    @pytest.mark.parametrize(""threshold"", [False])\n    def test_h_reparametrized(self, vgbs, dim, params):\n        """"""Test that the h_reparametrized method behaves as expected by calculating the cost\n        function over a fixed set of PNR samples using both the reparametrized and\n        non-reparametrized methods""""""\n        cost_fn = train.Stochastic(h, vgbs)\n        possible_samples = list(itertools.product([0, 1, 2], repeat=dim))\n\n        probs = [vgbs.prob_sample(params, s) for s in possible_samples]\n        probs_init = [vgbs.prob_sample(np.zeros(dim - 1), s) for s in possible_samples]\n\n        cost = sum([probs[i] * h(s) for i, s in enumerate(possible_samples)])\n\n        cost_reparam_sum = [\n            probs_init[i] * cost_fn.h_reparametrized(s, params)\n            for i, s in enumerate(possible_samples)\n        ]\n\n        cost_reparam = sum(cost_reparam_sum)\n\n        assert np.allclose(cost, cost_reparam)\n\n    @pytest.mark.parametrize(""threshold"", [False])\n    def test_h_reparametized_example(self, dim, vgbs, params, embedding):\n        """"""Test that the h_reparametrized method returns the correct value when compared to\n        working the result out by hand""""""\n        cost_fn = train.Stochastic(h, vgbs)\n        sample = np.ones(dim)\n        h_reparam = cost_fn.h_reparametrized(sample, params)\n        h_reparam_expected = -1.088925964188385\n        assert np.allclose(h_reparam, h_reparam_expected)\n\n    @pytest.mark.parametrize(""threshold"", [False])\n    def test_evaluate(self, vgbs, dim, params):\n        """"""Test that the evaluate method returns the expected value when the VGBS class is\n        preloaded with a dataset where half of the datapoints are zeros and half of the\n        datapoints are ones. The expected result of the evaluate method is then simply the\n        average of h_reparametrized applied to a ones vector and a zeros vector.""""""\n        n_samples = 10\n        zeros = np.zeros((n_samples, dim))\n        ones = np.ones((n_samples, dim))\n        samples = np.vstack([zeros, ones])\n        vgbs.add_A_init_samples(samples)\n\n        cost_fn = train.Stochastic(h, vgbs)\n        h0 = cost_fn.h_reparametrized(zeros[0], params)\n        h1 = cost_fn.h_reparametrized(ones[0], params)\n        eval_expected = (h0 + h1) * 0.5\n\n        eval = cost_fn(params, 2 * n_samples)  # Note that calling an instance of Stochastic uses\n        # the evaluate method\n\n        assert np.allclose(eval, eval_expected)\n\n    @pytest.mark.parametrize(""threshold"", [True, False])\n    def test_gradient_one_sample(self, vgbs, dim, params, threshold):\n        """"""Test that the _gradient_one_sample method returns the correct values when compared to\n        calculations done by hand""""""\n        cost_fn = train.Stochastic(h, vgbs)\n        sample = np.ones(dim)\n        gradient = cost_fn._gradient_one_sample(sample, params)\n\n        if threshold:\n            grad_target = np.array([18.46861628, 22.53873502, 26.60885377])\n        else:\n            grad_target = np.array([17.17157601, 20.94382262, 24.71606922])\n\n        assert np.allclose(gradient, grad_target)\n\n    @pytest.mark.parametrize(""threshold"", [False])\n    def test_gradient(self, vgbs, dim, params):\n        """"""Test that the gradient method returns the expected value when the VGBS class is\n        preloaded with a dataset where half of the datapoints are zeros and half of the\n        datapoints are ones. The expected result of the gradient method is then simply the\n        average of _gradient_one_sample applied to a ones vector and a zeros vector.""""""\n        n_samples = 10\n        zeros = np.zeros((n_samples, dim))\n        ones = np.ones((n_samples, dim))\n        samples = np.vstack([zeros, ones])\n        vgbs.add_A_init_samples(samples)\n\n        cost_fn = train.Stochastic(h, vgbs)\n        g0 = cost_fn._gradient_one_sample(zeros[0], params)\n        g1 = cost_fn._gradient_one_sample(ones[0], params)\n        grad_expected = (g0 + g1) * 0.5\n\n        grad = cost_fn.gradient(params, 2 * n_samples)\n        assert np.allclose(grad_expected, grad)\n        assert grad.shape == (dim - 1,)\n\n\n@pytest.mark.parametrize(""dim"", [4])\n@pytest.mark.parametrize(""n_mean"", [7])\n@pytest.mark.usefixtures(""simple_embedding"")\nclass TestStochasticIntegrationPNR:\n    """"""Integration tests for the class ``train.Stochastic``. We consider the setting where the\n    initial adjacency matrix is the identity, which reduces to directly sampling from\n    non-interacting squeezed states without passing through an interferometer. Here,\n    the trainable parameters can only control the amount of squeezing in each mode. We then use a\n    mean squared error cost function that simply subtracts a fixed vector from an input sample and\n    squares the result.""""""\n\n    def identity_sampler(self, n_mean_by_mode, n_samples):\n        """"""Used for quickly generating samples from a diagonal adjacency matrix. This requires\n        sampling from single mode squeezed states whose photon number distribution is specified\n        by the negative binomial.""""""\n        ps = 1 / (1 + np.array(n_mean_by_mode))\n        np.random.seed(0)\n        return np.array([2 * np.random.negative_binomial(0.5, p, n_samples) for p in ps]).T\n\n    def h_setup(self, objectives):\n        """"""Mean squared error based cost function that subtracts a fixed vector from an input\n        sample and squares the result""""""\n\n        def h(sample):\n            return sum([(s - objectives[i]) ** 2 for i, s in enumerate(sample)])\n\n        return h\n\n    def test_initial_cost(self, dim, n_mean, simple_embedding):\n        """"""Test that the cost function evaluates as expected on initial parameters of all zeros""""""\n        n_samples = 1000\n        objectives = np.linspace(0.5, 1.5, dim)\n        h = self.h_setup(objectives)\n        A = np.eye(dim)\n        vgbs = train.VGBS(A, n_mean, simple_embedding, threshold=False)\n\n        n_mean_by_mode = [n_mean / dim] * dim\n        samples = self.identity_sampler(n_mean_by_mode, n_samples=n_samples)\n        vgbs.add_A_init_samples(samples)\n\n        params = np.zeros(dim)\n        cost_fn = train.Stochastic(h, vgbs)\n        cost = cost_fn(params, n_samples=n_samples)\n\n        # We can directly calculate the cost with respect to the samples\n        expected_cost = np.mean(np.sum((samples - objectives) ** 2, axis=1))\n\n        assert np.allclose(cost, expected_cost)\n\n    def test_intermediate_cost(self, dim, n_mean, simple_embedding):\n        """"""Test that the cost function evaluates as expected on non-initial parameters. This is\n        done by comparing the cost function calculated using train.Stochastic with a manual\n        calculation. The manual calculation involves sampling from VGBS with the non-initial\n        params and averaging the cost function over the result.""""""\n        n_samples = 10000\n        objectives = np.linspace(0.5, 1.5, dim)\n        h = self.h_setup(objectives)\n        A = np.eye(dim)\n        vgbs = train.VGBS(A, n_mean, simple_embedding, threshold=False)\n\n        n_mean_by_mode = [n_mean / dim] * dim\n        samples = self.identity_sampler(n_mean_by_mode, n_samples=n_samples)\n        vgbs.add_A_init_samples(samples)\n\n        params = np.linspace(0, 1 / dim, dim)\n        cost_fn = train.Stochastic(h, vgbs)\n        cost = cost_fn(params, n_samples=n_samples)\n\n        # We need to generate new samples and then calculate the cost with respect to them\n        new_n_mean_by_mode = vgbs.mean_photons_by_mode(params)\n        new_samples = self.identity_sampler(new_n_mean_by_mode, n_samples=n_samples)\n        expected_cost = np.mean(np.sum((new_samples - objectives) ** 2, axis=1))\n\n        assert np.allclose(cost, expected_cost, rtol=0.1)\n\n    def test_gradient(self, dim, n_mean, simple_embedding):\n        """"""Test that the gradient evaluates as expected when compared to a value calculated by\n        hand.\n\n        Consider the problem with respect to a single mode. We want to calculate\n        E((s - x) ** 2) with s the number of photons in the mode, x the element of the fixed\n        vector, and with the expectation value calculated with respect to the (twice) negative\n        binomial distribution. We know that E(s) = 2 * r * (1 - q) / q and\n        Var(s) = 4 * (1 - q) * r / q ** 2 in terms of the r and q parameters of the negative\n        binomial distribution. Using q = 1 / (1 + n_mean) with n_mean the mean number of\n        photons in that mode and r = 0.5, we can calculate\n        E((s - x) ** 2) = 3 * n_mean ** 2 + 2 * (1 - x) * n_mean + x ** 2,\n        This can be differentiated to give the derivative:\n        d/dx E((s - x) ** 2) = 6 * n_mean + 2 * (1 - x).\n        """"""\n        n_samples = 10000  # We need a lot of shots due to the high variance in the distribution\n        objectives = np.linspace(0.5, 1.5, dim)\n        h = self.h_setup(objectives)\n        A = np.eye(dim)\n        vgbs = train.VGBS(A, n_mean, simple_embedding, threshold=False)\n\n        n_mean_by_mode = [n_mean / dim] * dim\n        samples = self.identity_sampler(n_mean_by_mode, n_samples=n_samples)\n        vgbs.add_A_init_samples(samples)\n\n        params = np.linspace(0, 1 / dim, dim)\n        cost_fn = train.Stochastic(h, vgbs)\n\n        # We want to calculate dcost_by_dn as this is available analytically, where n is the mean\n        # photon number. The following calculates this using the chain rule:\n        dcost_by_dtheta = cost_fn.gradient(params, n_samples=n_samples)\n        dtheta_by_dw = 1 / np.diag(simple_embedding.jacobian(params))\n        A_diag = np.diag(vgbs.A(params))\n        A_init_diag = np.diag(vgbs.A_init)\n        # Differentiate Eq. (8) of https://arxiv.org/abs/2004.04770 and invert for the next line\n        dw_by_dn = (1 - A_diag ** 2) ** 2 / (2 * A_diag * A_init_diag)\n        # Now use the chain rule\n        dcost_by_dn = dcost_by_dtheta * dtheta_by_dw * dw_by_dn\n\n        n_mean_by_mode = vgbs.mean_photons_by_mode(params)\n\n        dcost_by_dn_expected = 6 * n_mean_by_mode + 2 * (1 - objectives)\n\n        assert np.allclose(dcost_by_dn, dcost_by_dn_expected, 0.1)\n'"
tests/apps/test_data.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\r\n\r\n# Licensed under the Apache License, Version 2.0 (the ""License"");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an ""AS IS"" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\nr""""""\r\nUnit tests for strawberryfields.apps.data\r\n""""""\r\n# pylint: disable=no-self-use\r\nimport numpy as np\r\nimport pytest\r\nimport scipy\r\n\r\nfrom strawberryfields.apps import data\r\n\r\npytestmark = pytest.mark.apps\r\n\r\nGRAPH_DATASETS_LIST = [\r\n    data.Planted,\r\n    data.TaceAs,\r\n    data.Mutag0,\r\n    data.Mutag1,\r\n    data.Mutag2,\r\n    data.Mutag3,\r\n    data.PHat,\r\n]\r\n\r\nMOLECULE_DATASETS_LIST = [data.Formic]\r\n\r\nDATASETS_LIST = GRAPH_DATASETS_LIST + MOLECULE_DATASETS_LIST\r\n\r\n\r\n@pytest.mark.parametrize(""datasets"", DATASETS_LIST)\r\nclass TestDatasets:\r\n    """"""Tests for the dataset classes in ``data`` module, which should all be listed by the\r\n    ``DATASETS_LIST`` variable above.""""""\r\n\r\n    @pytest.fixture\r\n    def dataset(self, datasets):\r\n        """"""Fixture for loading each of the datasets in ``DATASETS_LIST``""""""\r\n        yield datasets()\r\n\r\n    patch_samples = [\r\n        [0, 0, 0, 0],\r\n        [0, 0, 0, 1],\r\n        [0, 0, 1, 0],\r\n        [0, 0, 1, 1],\r\n        [0, 1, 0, 0],\r\n        [0, 1, 0, 1],\r\n        [0, 1, 1, 0],\r\n        [0, 1, 1, 1],\r\n        [2, 1, 1, 1],\r\n        [3, 0, 1, 1],\r\n    ]\r\n\r\n    @pytest.fixture\r\n    def dataset_patched(self, monkeypatch, datasets):\r\n        """"""Fixture for loading each of the datasets in ``DATASETS_LIST`` with the ``__init__``\r\n        monkeypatched to load the above ``patch_samples``.""""""\r\n\r\n        def mock_init(_self):\r\n            """"""Replacement ``__init__`` for all the datasets in ``DATASETS_LIST``""""""\r\n            # pylint: disable=protected-access\r\n            _self.data = scipy.sparse.csr_matrix(self.patch_samples)\r\n            _self.n_samples, _self.modes = 10, 4\r\n\r\n        with monkeypatch.context() as m:\r\n            m.setattr(datasets, ""__init__"", mock_init)\r\n            yield datasets()\r\n\r\n    def test_filename(self, dataset):\r\n        """"""Test if filename is valid string for each dataset""""""\r\n        # pylint: disable=protected-access\r\n        assert isinstance(dataset._data_filename, str)\r\n\r\n    def test_n_mean(self, dataset):\r\n        """"""Test if mean photon number is valid float or int for each dataset""""""\r\n        assert isinstance(dataset.n_mean, (float, int))\r\n        assert dataset.n_mean >= 0\r\n\r\n    def test_threshold(self, dataset):\r\n        """"""Test if threshold flag is valid bool for each dataset""""""\r\n        assert isinstance(dataset.threshold, bool)\r\n\r\n    def test_counts_ax0(self, dataset_patched):\r\n        """"""Test if dataset ``counts`` method returns the number of counts in each mode when\r\n        ``axis==0``. The samples are patched to the fixed ``patch_samples`` list.""""""\r\n        assert dataset_patched.counts(0) == [5, 5, 6, 6]\r\n\r\n    def test_counts_ax1(self, dataset_patched):\r\n        """"""Test if dataset ``counts`` method returns the number of counts in each sample when\r\n        ``axis==1``. The samples are patched to the fixed ``patch_samples`` list.""""""\r\n        assert dataset_patched.counts(1) == [0, 1, 1, 2, 1, 2, 2, 3, 5, 5]\r\n\r\n    # pylint: disable=unnecessary-comprehension\r\n    def test_iter(self, dataset_patched):\r\n        """"""Test if dataset class allows correct iteration over itself""""""\r\n        assert [i for i in dataset_patched] == self.patch_samples\r\n\r\n    # pylint: disable=unnecessary-comprehension\r\n    def test_slice(self, dataset_patched):\r\n        """"""Test if dataset class allows correct slicing over items""""""\r\n        assert [i for i in dataset_patched[1, 4, 2]] == [\r\n            self.patch_samples[1],\r\n            self.patch_samples[3],\r\n        ]\r\n        assert [i for i in dataset_patched[slice(1, 4, 2)]] == [\r\n            self.patch_samples[1],\r\n            self.patch_samples[3],\r\n        ]\r\n\r\n    def test_negative_getitem(self, dataset_patched):\r\n        """"""Test if dataset class allows negative indices""""""\r\n        assert dataset_patched[-1] == self.patch_samples[-1]\r\n\r\n    def test_len(self, dataset):\r\n        """"""Test if dataset\'s ``len`` is equal to the ``n_samples`` attribute.""""""\r\n        assert len(dataset) == dataset.n_samples\r\n\r\n    def test_next(self, dataset_patched):\r\n        """"""Test if dataset correctly provides ``next`` until looped through whole dataset and\r\n        then raises a StopIteration.""""""\r\n        counter = 0\r\n        next_vals = []\r\n\r\n        while counter < 10:\r\n            next_vals.append(next(dataset_patched))\r\n            counter += 1\r\n\r\n        assert next_vals == self.patch_samples\r\n\r\n        with pytest.raises(StopIteration):\r\n            next(dataset_patched)\r\n\r\n\r\n@pytest.mark.parametrize(""datasets"", GRAPH_DATASETS_LIST)\r\nclass TestGraphDatasets:\r\n    """"""Tests for the ``MoleculeDataset`` class""""""\r\n\r\n    @pytest.fixture\r\n    def dataset(self, datasets):\r\n        """"""Fixture for loading each of the datasets in ``GRAPH_DATASETS_LIST``""""""\r\n        yield datasets()\r\n\r\n    def test_adj_dim(self, dataset):\r\n        """"""Test if adjacency matrix of dataset is correct dimensions.""""""\r\n        n, m = dataset.adj.shape\r\n\r\n        assert n == m\r\n        assert n == dataset.modes\r\n\r\n    def test_adj_valid(self, dataset):\r\n        """"""Test if adjacency matrix of dataset is symmetric.""""""\r\n        assert np.allclose(dataset.adj, dataset.adj.T)\r\n\r\n\r\n@pytest.mark.parametrize(""datasets"", MOLECULE_DATASETS_LIST)\r\nclass TestMoleculeDatasets:\r\n    """"""Tests for the ``MoleculeDataset`` class""""""\r\n\r\n    @pytest.fixture\r\n    def dataset(self, datasets):\r\n        """"""Fixture for loading each of the datasets in ``MOLECULE_DATASETS_LIST``""""""\r\n        yield datasets()\r\n\r\n    def test_w_dims(self, dataset):\r\n        """"""Test if w has correct shape""""""\r\n        w, _, _, _ = dataset.w, dataset.wp, dataset.Ud, dataset.delta\r\n        assert w.shape == (dataset.modes // 2,)\r\n\r\n    def test_wp_dims(self, dataset):\r\n        """"""Test if wp has correct shape""""""\r\n        _, wp, _, _ = dataset.w, dataset.wp, dataset.Ud, dataset.delta\r\n        assert wp.shape == (dataset.modes // 2,)\r\n\r\n    def test_Ud_dims(self, dataset):\r\n        """"""Test if Ud has correct shape""""""\r\n        _, _, Ud, _ = dataset.w, dataset.wp, dataset.Ud, dataset.delta\r\n        assert Ud.shape == (dataset.modes // 2, dataset.modes // 2)\r\n\r\n    def test_delta_dims(self, dataset):\r\n        """"""Test if delta has correct shape""""""\r\n        _, _, _, delta = dataset.w, dataset.wp, dataset.Ud, dataset.delta\r\n        assert delta.shape == (dataset.modes // 2,)\r\n\r\n    def test_uniform_dims(self, dataset):\r\n        """"""Test if overall dimension is correct""""""\r\n        w, wp, Ud, delta = dataset.w, dataset.wp, dataset.Ud, dataset.delta\r\n        dim = w.shape[0]\r\n\r\n        assert wp.shape[0] == dim and Ud.shape == (dim, dim) and delta.shape[0] == dim\r\n\r\n    def test_w_non_negative(self, dataset):\r\n        """"""Test if w is non-negative""""""\r\n        assert all(dataset.w >= 0)\r\n\r\n    def test_wp_non_negative(self, dataset):\r\n        """"""Test if wp is non-negative""""""\r\n        assert all(dataset.wp >= 0)\r\n\r\n    def test_T_non_negative(self, dataset):\r\n        """"""Test if T is non-negative""""""\r\n        assert dataset.T >= 0\r\n'"
tests/apps/test_embed.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nUnit tests for strawberryfields.apps.train.embed\n""""""\n# pylint: disable=no-self-use,unused-argument\nimport numpy as np\nimport pytest\nfrom strawberryfields.apps.train import embed\n\npytestmark = pytest.mark.apps\n\nfeats = [\n    [[0.1, 0.2], [0.2, 0.1]],\n    [[0.1, 0.2, 0.3], [0.3, 0.1, 0.2], [0.2, 0.3, 0.1]],\n    [[0.1, 0.2, 0.3, 0.4], [0.4, 0.1, 0.2, 0.3], [0.3, 0.4, 0.1, 0.2], [0.2, 0.3, 0.4, 0.1]],\n]\nfeats = np.array([np.array(f) for f in feats])\n\nps = [[1.0, 2.0], [1.0, 2.0, 3.0], [1.0, 2.0, 3.0, 4.0]]\nps = np.array([np.array(p) for p in ps])\n\nweights_f = np.array(\n    [\n        np.exp(-np.array([0.5, 0.4])),\n        np.exp(-np.array([1.4, 1.1, 1.1])),\n        np.exp(-np.array([3.0, 2.4, 2.2, 2.4])),\n    ]\n)\nweights = np.array(\n    [\n        np.exp(-np.array([1.0, 2.0])),\n        np.exp(-np.array([1.0, 2.0, 3.0])),\n        np.exp(-np.array([1.0, 2.0, 3.0, 4.0])),\n    ]\n)\n\njacobian_f = np.array([np.zeros((d, d)) for d in range(2, 5)])\njacobian = np.array([np.zeros((d, d)) for d in range(2, 5)])\n\nfor i in range(3):\n    jacobian[i] = -np.diag(weights[i])\n    for j in range(i + 2):\n        for m in range(i + 2):\n            jacobian_f[i][j, m] = -feats[i][j, m] * weights_f[i][j]\n\n\n@pytest.mark.parametrize(""dim"", range(2, 5))\nclass TestExpFeatures:\n    """"""Tests for the class ``strawberryfields.apps.train.embed.ExpFeatures``""""""\n\n    def test_invalid_dim(self, dim):\n        """"""Tests that a warning is issued if the feature vectors do not have the correct\n        dimension""""""\n        with pytest.raises(ValueError, match=""Dimension of parameter vector""):\n            features = np.ones((dim, dim + 1))\n            expf = embed.ExpFeatures(features)\n            expf(np.zeros(dim))\n\n    @pytest.mark.parametrize(""m"", range(2, 5))\n    def test_exp_features_shape(self, dim, m):\n        """"""Tests that the weights and jacobian have the correct shape for a range of different \n        sizes for the input features matrix""""""\n        features = np.ones((m, dim))\n        expf = embed.ExpFeatures(features)\n        params = np.ones(dim)\n\n        assert expf(params).shape == (m,)\n        assert expf.jacobian(params).shape == (m, dim)\n\n    def test_zero_params(self, dim):\n        """"""Tests that weights are equal to one when parameters are zero""""""\n        features = np.ones((dim, dim))\n        expf = embed.ExpFeatures(features)\n        params = np.zeros(dim)\n        assert np.allclose(expf(params), np.ones(dim))\n\n    def test_predefined(self, dim):\n        """"""Tests that weights are computed correctly for pre-defined features and parameters""""""\n        k = dim - 2\n        features = feats[k]\n        expf = embed.ExpFeatures(features)\n        assert np.allclose(expf(ps[k]), weights_f[k])\n\n\n@pytest.mark.parametrize(""dim"", range(2, 5))\nclass TestJacobianExpFeatures:\n    """"""Tests for the method ``strawberryfields.apps.train.embed.ExpFeatures.jacobian``""""""\n\n    def test_invalid_dim(self, dim):\n        """"""Tests that a warning is issued if the feature vectors do not have the correct\n        dimension""""""\n        with pytest.raises(ValueError, match=""Dimension of parameter vector""):\n            features = np.ones((dim, dim + 1))\n            expf = embed.ExpFeatures(features)\n            expf(np.zeros(dim))\n\n    def test_jacobian_zero_params(self, dim):\n        """"""Tests that the jacobian is equal to a matrix with -1 in all entries when parameters are\n        zero""""""\n        features = np.ones((dim, dim))\n        params = np.zeros(dim)\n        expf = embed.ExpFeatures(features)\n        g = expf.jacobian(params)\n        assert np.allclose(-np.ones((dim, dim)), g)\n\n    def test_jacobian_predefined(self, dim):\n        """"""Tests that the jacobian is computed correctly for pre-defined features and parameters""""""\n        k = dim - 2\n        features = feats[k]\n        expf = embed.ExpFeatures(features)\n        g = expf.jacobian(ps[k])\n        assert np.allclose(g, jacobian_f[k])\n\n\n@pytest.mark.parametrize(""dim"", range(2, 5))\nclass TestExp:\n    """"""Tests for the callable class ``strawberryfields.apps.train.embed.Exp``""""""\n\n    def test_zero_params(self, dim):\n        """"""Tests that weights are equal to one when parameters are zero""""""\n        exp = embed.Exp(dim)\n        params = np.zeros(dim)\n        assert np.allclose(exp(params), np.ones(dim))\n\n    def test_predefined(self, dim):\n        """"""Tests that weights are computed correctly for pre-defined features and parameters""""""\n        k = dim - 2\n        exp = embed.Exp(dim)\n        assert np.allclose(exp(ps[k]), weights[k])\n\n    def test_identity(self, dim):\n        """"""Tests that weights are computed correctly compared to a general calculation using an\n        identity matrix of feature vectors""""""\n        k = dim - 2\n        features = np.eye(dim)\n        expf = embed.ExpFeatures(features)\n        exp = embed.Exp(dim)\n        assert np.allclose(expf(ps[k]), exp(ps[k]))\n\n\n@pytest.mark.parametrize(""dim"", range(2, 5))\nclass TestJacobianExp:\n    """"""Tests for the method ``strawberryfields.apps.train.embed.Exp.jacobian``""""""\n\n    def test_jacobian_zero_params(self, dim):\n        """"""Tests that the jacobian is equal to negative identity when parameters are zero""""""\n        params = np.zeros(dim)\n        exp = embed.Exp(dim)\n        g = exp.jacobian(params)\n        assert np.allclose(-1 * np.eye(dim), g)\n\n    def test_jacobian_predefined(self, dim):\n        """"""Tests that the jacobian is computed correctly for pre-defined features and parameters""""""\n        k = dim - 2\n        exp = embed.Exp(dim)\n        g = exp.jacobian(ps[k])\n        assert np.allclose(g, jacobian[k])\n\n    def test_jacobian_identity(self, dim):\n        """"""Tests that the jacobian is computed correctly compared to a general calculation using an\n        identity matrix of feature vectors""""""\n        k = dim - 2\n        features = np.eye(dim)\n        expf = embed.ExpFeatures(features)\n        exp = embed.Exp(dim)\n        assert np.allclose(expf.jacobian(ps[k]), exp.jacobian(ps[k]))\n'"
tests/apps/test_plot.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nUnit tests for strawberryfields.apps.plot\n""""""\n# pylint: disable=no-self-use,unused-argument,too-many-arguments,protected-access\nimport networkx as nx\nimport numpy as np\nimport pytest\n\nfrom strawberryfields.apps import plot\n\npytestmark = pytest.mark.apps\n\n\nclass TestNodeCoords:\n    """"""Test for the internal function strawberryfields.apps.plot._node_coords""""""\n\n    @pytest.mark.parametrize(""dim"", [4, 5, 6])\n    def test_complete_graph(self, dim):\n        """"""Tests that nodes in a complete graph are located in the unit circle when using the\n        Kamada-Kawai layout""""""\n        graph = nx.complete_graph(dim)\n        layout = nx.kamada_kawai_layout(graph)\n        coords = plot._node_coords(graph, layout)\n        x = coords[""x""]\n        y = coords[""y""]\n        radii = [np.sqrt(x[i] ** 2 + y[i] ** 2) for i in range(dim)]\n\n        assert np.allclose(radii, np.ones(dim), atol=1e-5)\n\n    def test_custom_layout(self):\n        """"""Tests that nodes in a complete graph are correctly located based on a custom layout""""""\n        graph = nx.complete_graph(4)\n        layout = {0: [1, 1], 1: [1, -1], 2: [-1, 1], 3: [-1, -1]}\n        coords = plot._node_coords(graph, layout)\n        x = coords[""x""]\n        y = coords[""y""]\n\n        assert x == [1, 1, -1, -1]\n        assert y == [1, -1, 1, -1]\n\n\nclass TestEdgeCoords:\n    """"""Test for the internal function strawberryfields.apps.plot._edge_coords""""""\n\n    @pytest.mark.parametrize(""dim"", [4, 5, 6])\n    def test_cycle_graph(self, dim):\n        """"""Tests that the length of edges in a circular cycle graph are all of equal length.""""""\n        graph = nx.cycle_graph(dim)\n        layout = nx.kamada_kawai_layout(graph)\n        coords = plot._edge_coords(graph, layout)\n        x = coords[""x""]\n        y = coords[""y""]\n        dists = [\n            np.sqrt((x[3 * k] - x[3 * k + 1]) ** 2 + (y[3 * k] - y[3 * k + 1]) ** 2)\n            for k in range(dim)\n        ]\n        first_dist = np.sqrt((x[0] - x[1]) ** 2 + (y[0] - y[1]) ** 2)\n\n        assert np.allclose(dists, first_dist)\n\n    def test_custom_layout(self):\n        """"""Tests that edges in a complete graph are correctly located based on a custom layout""""""\n        graph = nx.complete_graph(2)\n        layout = {0: [1, 1], 1: [-1, -1]}\n        coords = plot._edge_coords(graph, layout)\n        x = coords[""x""]\n        y = coords[""y""]\n        print(x)\n        print(y)\n\n        assert x[:2] == [1, -1]\n        assert y[:2] == [1, -1]\n\n\ndef test_spectrum_invalid_energies():\n    """"""Test if function `plot.spectrum` raises a ``ValueError`` when the number of sampled energies\n    is less than two""""""\n    with pytest.raises(ValueError, match=""Number of sampled energies must be at least two""):\n        plot.spectrum([1000.0])\n'"
tests/apps/test_points.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Tests for the the point process functions""""""\n\nimport pytest\nimport numpy as np\nfrom strawberryfields.apps.points import rbf_kernel, sample\n\n\npytestmark = pytest.mark.apps\n\n\ndef test_rbf_kernel():\n    r""""""Tests the correctness of the RBF kernel matrix generated for a given set of point\n    coordinates""""""\n\n    R = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n    K = rbf_kernel(R, 1.0)\n    Kref = np.array(\n        [\n            [1.0, 0.36787944, 0.60653066, 0.60653066],\n            [0.36787944, 1.0, 0.60653066, 0.60653066],\n            [0.60653066, 0.60653066, 1.0, 0.36787944],\n            [0.60653066, 0.60653066, 0.36787944, 1.0],\n        ]\n    )\n\n    assert np.allclose(K, Kref)\n\n\ndef test_sample():\n    r""""""Tests that the generated samples have the correct dimension""""""\n\n    Kref = np.array(\n        [\n            [1.0, 0.36787944, 0.60653066, 0.60653066],\n            [0.36787944, 1.0, 0.60653066, 0.60653066],\n            [0.60653066, 0.60653066, 1.0, 0.36787944],\n            [0.60653066, 0.60653066, 0.36787944, 1.0],\n        ]\n    )\n    samples = sample(Kref, 1, 10)\n    shape = np.array(samples).shape\n    shape_ref = (10, 4)\n\n    assert shape == shape_ref\n'"
tests/apps/test_sample.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nUnit tests for strawberryfields.apps.sample\n""""""\n# pylint: disable=no-self-use,unused-argument,protected-access\nfrom unittest import mock\n\nimport networkx as nx\nimport numpy as np\nimport pytest\n\nimport strawberryfields as sf\nfrom strawberryfields.apps import sample\n\npytestmark = pytest.mark.apps\n\nadj_dim_range = range(2, 6)\n\nt0 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n\nt1 = np.array([0.01095008, 0.02466257, 0.11257409, 0.18496601, 0.20673787, 0.26162544, 0.51007465])\n\nU1 = np.array(\n    [\n        [-0.07985219, 0.66041032, -0.19389188, 0.01340832, 0.70312675, -0.1208423, -0.10352726],\n        [0.19216669, -0.12470466, -0.81320519, 0.52045174, -0.1066017, -0.06300751, -0.00376173],\n        [0.60838109, 0.0835063, -0.14958816, -0.34291399, 0.06239828, 0.68753918, -0.07955415],\n        [0.63690134, -0.03047939, 0.46585565, 0.50545897, 0.21194805, -0.20422433, 0.18516987],\n        [0.34556293, 0.22562207, -0.1999159, -0.50280235, -0.25510781, -0.55793978, 0.40065893],\n        [-0.03377431, -0.66280536, -0.14740447, -0.25725325, 0.6145946, -0.07128058, 0.29804963],\n        [-0.24570365, 0.22402764, 0.003273, 0.19204683, -0.05125235, 0.3881131, 0.83623564],\n    ]\n)\n\nr = np.array([0.09721339, 0.07017918, 0.02083469, -0.05974357, -0.07487845, -0.1119975, -0.1866708])\n\nU2 = np.array(\n    [\n        [-0.07012006, 0.14489772, 0.17593463, 0.02431155, -0.63151781, 0.61230046, 0.41087368],\n        [0.5618538, -0.09931968, 0.04562272, 0.02158822, 0.35700706, 0.6614837, -0.326946],\n        [-0.16560687, -0.7608465, -0.25644606, -0.54317241, -0.12822903, 0.12809274, -0.00597384],\n        [0.01788782, 0.60430409, -0.19831443, -0.73270964, -0.06393682, 0.03376894, -0.23038293],\n        [0.78640978, -0.11133936, 0.03160537, -0.09188782, -0.43483738, -0.4018141, 0.09582698],\n        [-0.13664887, -0.11196486, 0.86353995, -0.19608061, -0.12313513, -0.08639263, -0.40251231],\n        [-0.12060103, -0.01169781, -0.33937036, 0.34662981, -0.49895371, 0.03257453, -0.70709135],\n    ]\n)\n\nalpha = np.array(\n    [0.15938187, 0.10387399, 1.10301587, -0.26756921, 0.32194572, -0.24317402, 0.0436992]\n)\n\np0 = [t0, U1, r, U2, alpha]\n\np1 = [t1, U1, r, U2, alpha]\n\n\n@pytest.mark.parametrize(""dim"", [4])\nclass TestSample:\n    """"""Tests for the function ``strawberryfields.apps.sample.sample``""""""\n\n    def test_invalid_adjacency(self, dim):\n        """"""Test if function raises a ``ValueError`` for a matrix that is not symmetric""""""\n        with pytest.raises(ValueError, match=""Input must be a NumPy array""):\n            adj_asym = np.triu(np.ones((dim, dim)))\n            sample.sample(A=adj_asym, n_mean=1.0)\n\n    def test_invalid_n_samples(self, adj):\n        """"""Test if function raises a ``ValueError`` when a number of samples less than one is\n        requested """"""\n        with pytest.raises(ValueError, match=""Number of samples must be at least one""):\n            sample.sample(A=adj, n_mean=1.0, n_samples=0)\n\n    def test_invalid_n_mean(self, adj):\n        """"""Test if function raises a ``ValueError`` when the mean photon number is specified to\n        be negative.""""""\n        with pytest.raises(ValueError, match=""Mean photon number must be non-negative""):\n            sample.sample(A=adj, n_mean=-1.0, n_samples=1)\n\n    def test_invalid_loss(self, adj):\n        """"""Test if function raises a ``ValueError`` when the loss parameter is specified outside\n        of range""""""\n        with pytest.raises(ValueError, match=""Loss parameter must take a value between zero and""):\n            sample.sample(A=adj, n_mean=1.0, n_samples=1, loss=2)\n\n    def test_threshold(self, monkeypatch, adj):\n        """"""Test if function correctly creates the SF program for threshold GBS.""""""\n        mock_eng_run = mock.MagicMock()\n\n        with monkeypatch.context() as m:\n            m.setattr(sf.LocalEngine, ""run"", mock_eng_run)\n            sample.sample(A=adj, n_mean=1, threshold=True)\n            p_func = mock_eng_run.call_args[0][0]\n\n        assert isinstance(p_func.circuit[-1].op, sf.ops.MeasureThreshold)\n\n    def test_pnr(self, monkeypatch, adj):\n        """"""Test if function correctly creates the SF program for photon-number resolving GBS.""""""\n        mock_eng_run = mock.MagicMock()\n\n        with monkeypatch.context() as m:\n            m.setattr(sf.LocalEngine, ""run"", mock_eng_run)\n            sample.sample(A=adj, n_mean=1, threshold=False)\n            p_func = mock_eng_run.call_args[0][0]\n\n        assert isinstance(p_func.circuit[-1].op, sf.ops.MeasureFock)\n\n    def test_loss(self, monkeypatch, adj):\n        """"""Test if function correctly creates the SF program for lossy GBS.""""""\n        mock_eng_run = mock.MagicMock()\n\n        with monkeypatch.context() as m:\n            m.setattr(sf.LocalEngine, ""run"", mock_eng_run)\n            sample.sample(A=adj, n_mean=1, threshold=False, loss=0.5)\n            p_func = mock_eng_run.call_args[0][0]\n\n        assert isinstance(p_func.circuit[-2].op, sf.ops.LossChannel)\n\n    def test_no_loss(self, monkeypatch, adj):\n        """"""Test if function correctly creates the SF program for GBS without loss.""""""\n        mock_eng_run = mock.MagicMock()\n\n        with monkeypatch.context() as m:\n            m.setattr(sf.LocalEngine, ""run"", mock_eng_run)\n            sample.sample(A=adj, n_mean=1, threshold=False)\n            p_func = mock_eng_run.call_args[0][0]\n\n        assert not all([isinstance(op, sf.ops.LossChannel) for op in p_func.circuit])\n\n    def test_all_loss(self, monkeypatch, adj, dim):\n        """"""Test if function samples from the vacuum when maximum loss is applied.""""""\n        mock_eng_run = mock.MagicMock()\n\n        with monkeypatch.context() as m:\n            m.setattr(sf.LocalEngine, ""run"", mock_eng_run)\n            sample.sample(A=adj, n_mean=1, threshold=False, loss=1)\n            p_func = mock_eng_run.call_args[0][0]\n\n        eng = sf.LocalEngine(backend=""gaussian"")\n\n        state = eng.run(p_func).state\n        cov = state.cov()\n        disp = state.displacement()\n\n        assert np.allclose(cov, 0.5 * state.hbar * np.eye(2 * dim))\n        assert np.allclose(disp, np.zeros(dim))\n\n\n@pytest.mark.parametrize(""dim"", adj_dim_range)\n@pytest.mark.parametrize(""integration_sample_number"", [1, 2])\nclass TestSampleIntegration:\n    """"""Integration tests for the function ``strawberryfields.apps.sample.sample``""""""\n\n    def test_pnr_integration(self, adj, integration_sample_number):\n        """"""Integration test to check if function returns samples of correct form, i.e., correct\n        number of samples, correct number of modes, all non-negative integers """"""\n        samples = np.array(\n            sample.sample(A=adj, n_mean=1.0, n_samples=integration_sample_number, threshold=False)\n        )\n\n        dims = samples.shape\n\n        assert len(dims) == 2\n        assert dims == (integration_sample_number, len(adj))\n        assert samples.dtype == ""int""\n        assert (samples >= 0).all()\n\n    def test_threshold_integration(self, adj, integration_sample_number):\n        """"""Integration test to check if function returns samples of correct form, i.e., correct\n        number of samples, correct number of modes, all integers of zeros and ones """"""\n        samples = np.array(\n            sample.sample(A=adj, n_mean=1.0, n_samples=integration_sample_number, threshold=True)\n        )\n\n        dims = samples.shape\n\n        assert len(dims) == 2\n        assert dims == (integration_sample_number, len(adj))\n        assert samples.dtype == ""int""\n        assert (samples >= 0).all()\n        assert (samples <= 1).all()\n\n\n@pytest.mark.parametrize(""dim"", [4])\ndef test_seed(dim, adj):\n    """"""Test for the function ``strawberryfields.apps.sample.seed``. Checks that samples are\n    identical after repeated initialization of ``seed``.""""""\n\n    sample.seed(1968)\n    q_s_1 = sample.sample(A=adj, n_mean=2, n_samples=10, threshold=False)\n\n    sample.seed(1968)\n    q_s_2 = sample.sample(A=adj, n_mean=2, n_samples=10, threshold=False)\n\n    assert np.array_equal(q_s_1, q_s_2)\n\n\n@pytest.mark.parametrize(""dim"", [6])\nclass TestToSubgraphs:\n    """"""Tests for the function ``sample.to_subgraphs``""""""\n\n    quantum_samples = [\n        [0, 1, 1, 1, 1, 1],\n        [1, 0, 0, 1, 0, 0],\n        [1, 1, 1, 1, 1, 1],\n        [0, 0, 1, 0, 0, 1],\n        [0, 1, 1, 1, 0, 0],\n        [0, 0, 0, 0, 1, 1],\n        [0, 0, 0, 0, 1, 1],\n        [1, 1, 0, 1, 1, 1],\n        [1, 0, 0, 1, 0, 0],\n        [0, 0, 0, 0, 1, 1],\n    ]\n\n    subgraphs = [\n        [1, 2, 3, 4, 5],\n        [0, 3],\n        [0, 1, 2, 3, 4, 5],\n        [2, 5],\n        [1, 2, 3],\n        [4, 5],\n        [4, 5],\n        [0, 1, 3, 4, 5],\n        [0, 3],\n        [4, 5],\n    ]\n\n    def test_graph(self, graph):\n        """"""Test if function returns correctly processed subgraphs given input samples of the list\n        ``quantum_samples``.""""""\n        assert sample.to_subgraphs(self.quantum_samples, graph) == self.subgraphs\n\n    def test_graph_mapped(self, graph):\n        """"""Test if function returns correctly processed subgraphs given input samples of the list\n        ``quantum_samples``. Note that graph nodes are numbered in this test as [0, 1, 4, 9,\n        ...] (i.e., squares of the usual list) as a simple mapping to explore that the optimised\n        subgraph returned is still a valid subgraph.""""""\n        graph = nx.relabel_nodes(graph, lambda x: x ** 2)\n        graph_nodes = list(graph.nodes)\n        subgraphs_mapped = [\n            sorted([graph_nodes[i] for i in subgraph]) for subgraph in self.subgraphs\n        ]\n\n        assert sample.to_subgraphs(self.quantum_samples, graph) == subgraphs_mapped\n\n\ndef test_modes_from_counts():\n    """"""Test if the function ``strawberryfields.apps.sample.modes_from_counts`` returns the correct\n    mode samples when input a set of photon count samples.""""""\n\n    counts = [[0, 0, 0, 0], [1.0, 0.0, 0.0, 2.0], [1, 1, 1, 0], [1, 2, 1, 0], [0, 1, 0, 2, 4]]\n\n    modes = [[], [0, 3, 3], [0, 1, 2], [0, 1, 1, 2], [1, 3, 3, 4, 4, 4, 4]]\n\n    assert [sample.modes_from_counts(s) for s in counts] == modes\n\n\ndef test_postselect():\n    """"""Test if the function ``strawberryfields.apps.sample.postselect`` correctly postselects on\n    minimum number of photons or clicks.""""""\n    counts_pnr = [\n        [0, 0, 0, 0],\n        [1, 1, 0, 2],\n        [1, 1, 1, 0],\n        [1, 2, 1, 0],\n        [1, 0, 0, 1],\n        [5, 0, 0, 0],\n        [1, 2, 1, 2],\n    ]\n    counts_pnr_ps_4_5 = [[1, 1, 0, 2], [1, 2, 1, 0], [5, 0, 0, 0]]\n\n    counts_threshold = [\n        [0, 0, 0, 0],\n        [1, 1, 0, 1],\n        [1, 1, 1, 0],\n        [1, 1, 1, 0],\n        [1, 0, 0, 1],\n        [1, 1, 1, 1],\n    ]\n    counts_threshold_ps_3_3 = [[1, 1, 0, 1], [1, 1, 1, 0], [1, 1, 1, 0]]\n\n    assert sample.postselect(counts_pnr, 4, 5) == counts_pnr_ps_4_5\n    assert sample.postselect(counts_threshold, 3, 3) == counts_threshold_ps_3_3\n\n\n@pytest.mark.parametrize(""p"", [p0, p1])\nclass TestVibronic:\n    """"""Tests for the function ``strawberryfields.apps.sample.vibronic``""""""\n\n    def test_invalid_n_samples(self, p):\n        """"""Test if function raises a ``ValueError`` when a number of samples less than one is\n        requested.""""""\n        with pytest.raises(ValueError, match=""Number of samples must be at least one""):\n            sample.vibronic(*p, -1)\n\n    def test_invalid_loss(self, p):\n        """"""Test if function raises a ``ValueError`` when the loss parameter is specified outside\n        of range.""""""\n        with pytest.raises(ValueError, match=""Loss parameter must take a value between zero and""):\n            sample.vibronic(*p, 1, loss=2)\n\n    def test_loss(self, monkeypatch, p):\n        """"""Test if function correctly creates the SF program for lossy GBS.""""""\n        def save_hist(*args, **kwargs):\n            call_history.append(args[1])\n            return sf.engine.Result\n\n        call_history = []\n        with monkeypatch.context() as m:\n            m.setattr(sf.engine.Result, ""samples"", np.array([[0]]))\n            m.setattr(sf.LocalEngine, ""run"", save_hist)\n            sample.vibronic(*p, 1, loss=0.5)\n\n        assert isinstance(call_history[0].circuit[-2].op, sf.ops.LossChannel)\n\n    def test_no_loss(self, monkeypatch, p):\n        """"""Test if function correctly creates the SF program for GBS without loss.""""""\n        def save_hist(*args, **kwargs):\n            call_history.append(args[1])\n            return sf.engine.Result\n\n        call_history = []\n        with monkeypatch.context() as m:\n            m.setattr(sf.engine.Result, ""samples"", np.array([[0]]))\n            m.setattr(sf.LocalEngine, ""run"", save_hist)\n            sample.vibronic(*p, 1)\n\n        assert not all([isinstance(op, sf.ops.LossChannel) for op in call_history[0].circuit])\n\n    def test_all_loss(self, monkeypatch, p):\n        """"""Test if function samples from the vacuum when maximum loss is applied. This test is\n        only done for the zero temperature case""""""\n        if p == ""p0"":\n            dim = len(alpha)\n            mock_eng_run = mock.MagicMock()\n\n            with monkeypatch.context() as m:\n                m.setattr(sf.LocalEngine, ""run"", mock_eng_run)\n                sample.vibronic(*p, 1, loss=1)\n                p_func = mock_eng_run.call_args[0][0]\n\n            eng = sf.LocalEngine(backend=""gaussian"")\n\n            state = eng.run(p_func).state\n            cov = state.cov()\n            disp = state.displacement()\n\n            assert np.allclose(cov, 0.5 * state.hbar * np.eye(2 * dim))\n            assert np.allclose(disp, np.zeros(dim))\n\n\n@pytest.mark.parametrize(""p"", [p0, p1])\n@pytest.mark.parametrize(""integration_sample_number"", [1, 2])\ndef test_vibronic_integration(p, integration_sample_number):\n    """"""Integration test for the function ``strawberryfields.apps.sample.vibronic`` to check if\n    it returns samples of correct form, i.e., correct number of samples, correct number of\n    modes, all non-negative integers.""""""\n    samples = np.array(sample.vibronic(*p, n_samples=integration_sample_number))\n\n    dims = samples.shape\n\n    assert len(dims) == 2\n    assert dims == (integration_sample_number, len(alpha) * 2)\n    assert samples.dtype == ""int""\n    assert (samples >= 0).all()\n\n\nclass TestWawMatrix:\n    """"""Tests for the function ``strawberryfields.apps.sample.waw_matrix``""""""\n\n    adjs = [\n        np.array(\n            [[0, 1, 0, 1, 1], [1, 0, 0, 1, 1], [0, 0, 0, 1, 0], [1, 1, 1, 0, 1], [1, 1, 0, 1, 0]]\n        ),\n        np.array([[0, 1, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0]]),\n        np.array([[0, 1, 2], [1, 0, 0.5], [2, 0.5, 0]]),\n    ]\n\n    wvecs = [np.array([1, 1, 3, 1, 0.5]), np.array([1, -2, 3, -4]), np.array([0, 0.5, 4])]\n\n    resc_adjs = [\n        np.array(\n            [\n                [0, 1, 0, 1, 0.5],\n                [1, 0, 0, 1, 0.5],\n                [0, 0, 0, 3, 0],\n                [1, 1, 3, 0, 0.5],\n                [0.5, 0.5, 0, 0.5, 0],\n            ]\n        ),\n        np.array([[0, -2, 0, -4], [-2, 0, -6, 0], [0, -6, 0, -12], [-4, 0, -12, 0]]),\n        np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0]]),\n    ]\n\n    def test_invalid_adjacency(self):\n        """"""Test if function raises a ``ValueError`` for a matrix that is not symmetric.""""""\n        adj_asym = np.triu(np.ones((4, 4)))\n        with pytest.raises(ValueError, match=""Input must be a NumPy array""):\n            sample.sample(A=adj_asym, n_mean=1.0)\n\n    @pytest.mark.parametrize(""inst"", zip(adjs, wvecs, resc_adjs))\n    def test_valid_w(self, inst):\n        """"""Test if function returns the correct answer on some pre-calculated instances.""""""\n        assert np.allclose(sample.waw_matrix(inst[0], inst[1]), inst[2])\n\n    @pytest.mark.parametrize(""inst"", zip(adjs, wvecs, resc_adjs))\n    def test_valid_w_list(self, inst):\n        """"""Test if function returns the correct answer on some pre-calculated instances,\n        when w is a list""""""\n        assert np.allclose(sample.waw_matrix(inst[0], list(inst[1])), inst[2])\n'"
tests/apps/test_similarity.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nUnit tests for strawberryfields.apps.similarity\n""""""\n# pylint: disable=no-self-use,unused-argument,too-many-arguments\nimport itertools\nfrom collections import Counter\nfrom unittest import mock\n\nimport networkx as nx\nimport numpy as np\nimport pytest\n\nimport strawberryfields as sf\nfrom strawberryfields.apps import similarity\n\npytestmark = pytest.mark.apps\n\nall_orbits = {\n    3: [[1, 1, 1], [2, 1], [3]],\n    4: [[1, 1, 1, 1], [2, 1, 1], [3, 1], [2, 2], [4]],\n    5: [[1, 1, 1, 1, 1], [2, 1, 1, 1], [3, 1, 1], [2, 2, 1], [4, 1], [3, 2], [5]],\n}\n\nall_orbits_cumulative = [o for orbs in all_orbits.values() for o in orbs]\n\nall_events = {\n    (3, 1): [3, None, None],\n    (4, 1): [4, None, None, None, None],\n    (5, 1): [5, None, None, None, None, None, None],\n    (3, 2): [3, 3, None],\n    (4, 2): [4, 4, None, 4, None],\n    (5, 2): [5, 5, None, 5, None, None, None],\n}\n\n\n@pytest.mark.parametrize(""dim"", [3, 4, 5])\ndef test_sample_to_orbit(dim):\n    """"""Test if function ``similarity.sample_to_orbit`` correctly returns the original orbit after\n    taking all permutations over the orbit. The starting orbits are all orbits for a fixed photon\n    number ``dim``.""""""\n    orb = all_orbits[dim]\n    checks = []\n    for o in orb:\n        sorted_sample = o.copy()\n        sorted_sample_len = len(sorted_sample)\n        if sorted_sample_len != dim:\n            sorted_sample += [0] * sorted_sample_len\n        permutations = itertools.permutations(sorted_sample)\n        checks.append(all([similarity.sample_to_orbit(p) == o for p in permutations]))\n    assert all(checks)\n\n\n@pytest.mark.parametrize(""dim"", [3, 4, 5])\nclass TestOrbits:\n    """"""Tests for the function ``strawberryfields.apps.similarity.orbits``""""""\n\n    def test_orbit_sum(self, dim):\n        """"""Test if function generates orbits that are lists that sum to ``dim``.""""""\n        assert all([sum(o) == dim for o in similarity.orbits(dim)])\n\n    def test_orbit_sorted(self, dim):\n        """"""Test if function generates orbits that are lists sorted in descending order.""""""\n        assert all([o == sorted(o, reverse=True) for o in similarity.orbits(dim)])\n\n    def test_orbits(self, dim):\n        """"""Test if function returns all the integer partitions of 5. This test does not\n        require ``similarity.orbits`` to return the orbits in any specified order.""""""\n        partition = all_orbits[dim]\n        orb = similarity.orbits(dim)\n\n        assert sorted(partition) == sorted(orb)\n\n\n@pytest.mark.parametrize(""dim"", [3, 4, 5])\n@pytest.mark.parametrize(""max_count_per_mode"", [1, 2])\ndef test_sample_to_event(dim, max_count_per_mode):\n    """"""Test if function ``similarity.sample_to_event`` gives the correct set of events when\n    applied to all orbits with a fixed number of photons ``dim``. This test ensures that orbits\n    exceeding the ``max_count_per_mode`` value are attributed the ``None`` event and that orbits\n    not exceeding the ``max_count_per_mode`` are attributed the event ``dim``.""""""\n    orb = all_orbits[dim]\n    target_events = all_events[(dim, max_count_per_mode)]\n    ev = [similarity.sample_to_event(o, max_count_per_mode) for o in orb]\n\n    assert ev == target_events\n\n\nclass TestOrbitToSample:\n    """"""Tests for the function ``strawberryfields.apps.similarity.orbit_to_sample``""""""\n\n    def test_low_modes(self):\n        """"""Test if function raises a ``ValueError`` if fed an argument for ``modes`` that does\n        not exceed the length of the input orbit.""""""\n        with pytest.raises(ValueError, match=""Number of modes cannot""):\n            similarity.orbit_to_sample([1, 2, 3], 2)\n\n    @pytest.mark.parametrize(""orb_dim"", [3, 4, 5])\n    @pytest.mark.parametrize(""modes_dim"", [6, 7])\n    def test_sample_length(self, orb_dim, modes_dim):\n        """"""Test if function returns a sample that is of correct length ``modes_dim`` when fed a\n        collision-free event of ``orb_dim`` photons.""""""\n        samp = similarity.orbit_to_sample(all_orbits[orb_dim][0], modes_dim)\n        assert len(samp) == modes_dim\n\n    def test_sample_composition(self):\n        """"""Test if function returns a sample that corresponds to the input orbit. Input orbits\n        are orbits from ``all_orbits_cumulative``, i.e., all orbits from 3-5 photons. This test\n        checks if a sample corresponds to an orbit by counting the occurrence of elements in the\n        sample and comparing to a count of elements in the orbit.""""""\n        modes = 5\n\n        all_orbits_zeros = [\n            [1, 1, 1, 0, 0],\n            [2, 1, 0, 0, 0],\n            [3, 0, 0, 0, 0],\n            [1, 1, 1, 1, 0],\n            [2, 1, 1, 0, 0],\n            [3, 1, 0, 0, 0],\n            [2, 2, 0, 0, 0],\n            [4, 0, 0, 0, 0],\n            [1, 1, 1, 1, 1],\n            [2, 1, 1, 1, 0],\n            [3, 1, 1, 0, 0],\n            [2, 2, 1, 0, 0],\n            [4, 1, 0, 0, 0],\n            [3, 2, 0, 0, 0],\n            [5, 0, 0, 0, 0],\n        ]  # padding orbits with zeros at the end for comparison to samples\n\n        counts = [Counter(similarity.orbit_to_sample(o, modes)) for o in all_orbits_cumulative]\n        ideal_counts = [Counter(o) for o in all_orbits_zeros]\n\n        assert counts == ideal_counts\n\n\nclass TestEventToSample:\n    """"""Tests for the function ``strawberryfields.apps.similarity.event_to_sample``""""""\n\n    def test_low_count(self):\n        """"""Test if function raises a ``ValueError`` if ``max_count_per_mode`` is negative.""""""\n        with pytest.raises(ValueError, match=""Maximum number of photons""):\n            similarity.event_to_sample(2, -1, 5)\n\n    def test_high_photon(self):\n        """"""Test if function raises a ``ValueError`` if ``photon_number`` is so high that it\n        cannot correspond to a sample given the constraints of ``max_count_per_mode`` and\n        ``modes``""""""\n        with pytest.raises(ValueError, match=""No valid samples can be generated.""):\n            similarity.event_to_sample(5, 1, 4)\n\n    @pytest.mark.parametrize(""photon_num"", [5, 6])\n    @pytest.mark.parametrize(""modes_dim"", [10, 11])\n    @pytest.mark.parametrize(""count"", [3, 4])\n    def test_sample_length(self, photon_num, modes_dim, count):\n        """"""Test if function returns a sample that is of correct length ``modes_dim``.""""""\n        samp = similarity.event_to_sample(photon_num, count, modes_dim)\n        assert len(samp) == modes_dim\n\n    @pytest.mark.parametrize(""photon_num"", [5, 6])\n    @pytest.mark.parametrize(""modes_dim"", [10, 11])\n    @pytest.mark.parametrize(""count"", [3, 4])\n    def test_sample_sum(self, photon_num, modes_dim, count):\n        """"""Test if function returns a sample that has the correct number of photons.""""""\n        samp = similarity.event_to_sample(photon_num, count, modes_dim)\n        assert sum(samp) == photon_num\n\n    @pytest.mark.parametrize(""photon_num"", [5, 6])\n    @pytest.mark.parametrize(""modes_dim"", [10, 11])\n    @pytest.mark.parametrize(""count"", [3, 4])\n    def test_sample_max_count(self, photon_num, modes_dim, count):\n        """"""Test if function returns a sample that has maximum element not exceeding ``count``.""""""\n        samp = similarity.event_to_sample(photon_num, count, modes_dim)\n        assert max(samp) <= count\n\n\norbits = [\n    [(1, 1, 2), 4, 12],\n    [(1, 1), 4, 6],\n    [(1, 2, 3), 4, 24],\n    [(1, 1, 1, 1), 5, 5],\n    [(1, 1, 2), 5, 30],\n    [(1, 2, 3), 5, 60],\n]\n\n\n@pytest.mark.parametrize(""orbit, max_photon, expected"", orbits)\ndef test_orbit_cardinality(orbit, max_photon, expected):\n    """"""Test if function ``strawberryfields.apps.similarity.orbit_cardinality`` returns the\n    correct number of samples for some hard-coded examples.""""""\n\n    assert similarity.orbit_cardinality(list(orbit), max_photon) == expected\n\n\nevents = [\n    [5, 3, 6, 216],\n    [6, 3, 6, 336],\n    [5, 2, 6, 126],\n    [5, 3, 7, 413],\n    [6, 3, 7, 728],\n    [5, 2, 7, 266],\n]\n\n\n@pytest.mark.parametrize(""photons, max_count, modes, expected"", events)\ndef test_event_cardinality(photons, max_count, modes, expected):\n    """"""Test if function ``strawberryfields.apps.similarity.event_cardinality`` returns the\n    correct number of samples for some hard-coded examples.""""""\n\n    assert similarity.event_cardinality(photons, max_count, modes) == expected\n\n\nclass TestProbOrbitMC:\n    """"""Tests for the function ``strawberryfields.apps.similarity.prob_orbit_mc.``""""""\n\n    def test_invalid_samples(self):\n        """"""Test if function raises a ``ValueError`` when a number of samples less than one is\n        requested.""""""\n        g = nx.complete_graph(10)\n        with pytest.raises(ValueError, match=""Number of samples must be at least one""):\n            similarity.prob_orbit_mc(g, [1, 1, 1, 1], samples=0)\n\n    def test_invalid_n_mean(self):\n        """"""Test if function raises a ``ValueError`` when the mean photon number is specified to\n        be negative.""""""\n        g = nx.complete_graph(10)\n        with pytest.raises(ValueError, match=""Mean photon number must be non-negative""):\n            similarity.prob_orbit_mc(g, [1, 1, 1, 1], n_mean=-1)\n\n    def test_invalid_loss(self):\n        """"""Test if function raises a ``ValueError`` when the loss parameter is specified outside\n        of range.""""""\n        g = nx.complete_graph(10)\n        with pytest.raises(ValueError, match=""Loss parameter must take a value between zero and""):\n            similarity.prob_orbit_mc(g, [1, 1, 1, 1], loss=2)\n\n    def test_mean_computation_orbit(self, monkeypatch):\n        """"""Tests if the calculation of the sample mean is performed correctly. The test\n        monkeypatches the fock_prob function so that the probability is the same for each sample and\n        is equal to 1/5, i.e., one over the number of samples in the orbit [1,1,1,1] for 5 modes.""""""\n        graph = nx.complete_graph(5)\n        with monkeypatch.context() as m:\n            m.setattr(\n                ""strawberryfields.backends.gaussianbackend.GaussianState.fock_prob"",\n                lambda *args, **kwargs: 0.2,\n            )\n\n            assert np.allclose(similarity.prob_orbit_mc(graph, [1, 1, 1, 1]), 1.0)\n\n    def test_prob_vacuum_orbit(self):\n        """"""Tests if the function gives the right probability for the empty orbit when the GBS\n        device has been configured to have zero mean photon number.""""""\n        graph = nx.complete_graph(10)\n\n        assert similarity.prob_orbit_mc(graph, [], 0) == 1.0\n\n    def test_loss(self, monkeypatch):\n        """"""Test if function correctly creates the SF program for lossy GBS.""""""\n        graph = nx.complete_graph(5)\n        mock_eng_run = mock.MagicMock()\n\n        with monkeypatch.context() as m:\n            m.setattr(sf.LocalEngine, ""run"", mock_eng_run)\n            similarity.prob_orbit_mc(graph, [1, 1, 1, 1], samples=1, loss=0.5)\n            p_func = mock_eng_run.call_args[0][0]\n\n        assert isinstance(p_func.circuit[1].op, sf.ops.LossChannel)\n\n    def test_no_loss(self, monkeypatch):\n        """"""Test if function correctly creates the SF program for GBS without loss.""""""\n        graph = nx.complete_graph(5)\n        mock_eng_run = mock.MagicMock()\n\n        with monkeypatch.context() as m:\n            m.setattr(sf.LocalEngine, ""run"", mock_eng_run)\n            similarity.prob_orbit_mc(graph, [1, 1, 1, 1], samples=1)\n            p_func = mock_eng_run.call_args[0][0]\n\n        assert not all([isinstance(op, sf.ops.LossChannel) for op in p_func.circuit])\n\n    def test_all_loss(self, monkeypatch):\n        """"""Test if function samples from the vacuum when maximum loss is applied.""""""\n        dim = 5\n        graph = nx.complete_graph(dim)\n        mock_eng_run = mock.MagicMock()\n\n        with monkeypatch.context() as m:\n            m.setattr(sf.LocalEngine, ""run"", mock_eng_run)\n            similarity.prob_orbit_mc(graph, [1, 1, 1, 1], samples=1, loss=1)\n            p_func = mock_eng_run.call_args[0][0]\n\n        eng = sf.LocalEngine(backend=""gaussian"")\n\n        state = eng.run(p_func).state\n        cov = state.cov()\n        disp = state.displacement()\n\n        assert np.allclose(cov, 0.5 * state.hbar * np.eye(2 * dim))\n        assert np.allclose(disp, np.zeros(dim))\n\n\nclass TestProbEventMC:\n    """"""Tests for the function ``strawberryfields.apps.similarity.prob_event_mc.``""""""\n\n    def test_invalid_samples(self):\n        """"""Test if function raises a ``ValueError`` when a number of samples less than one is\n        requested.""""""\n        g = nx.complete_graph(10)\n        with pytest.raises(ValueError, match=""Number of samples must be at least one""):\n            similarity.prob_event_mc(g, 2, 2, samples=0)\n\n    def test_invalid_n_mean(self):\n        """"""Test if function raises a ``ValueError`` when the mean photon number is specified to\n        be negative.""""""\n        g = nx.complete_graph(10)\n        with pytest.raises(ValueError, match=""Mean photon number must be non-negative""):\n            similarity.prob_event_mc(g, 2, 2, n_mean=-1)\n\n    def test_invalid_loss(self):\n        """"""Test if function raises a ``ValueError`` when the loss parameter is specified outside\n        of range.""""""\n        g = nx.complete_graph(10)\n        with pytest.raises(ValueError, match=""Loss parameter must take a value between zero and""):\n            similarity.prob_event_mc(g, 2, 2, loss=2)\n\n    def test_invalid_photon_number(self):\n        """"""Test if function raises a ``ValueError`` when a photon number below zero is specified""""""\n        g = nx.complete_graph(10)\n        with pytest.raises(ValueError, match=""Photon number must not be below zero""):\n            similarity.prob_event_mc(g, -1, 2)\n\n    def test_low_count(self):\n        """"""Test if function raises a ``ValueError`` if ``max_count_per_mode`` is negative.""""""\n        g = nx.complete_graph(10)\n        with pytest.raises(ValueError, match=""Maximum number of photons""):\n            similarity.prob_event_mc(g, 2, -1)\n\n    def test_prob_vacuum_event(self):\n        """"""Tests if the function gives the right probability for an event with zero photons when\n        the GBS device has been configured to have zero mean photon number.""""""\n        graph = nx.complete_graph(10)\n\n        assert similarity.prob_event_mc(graph, 0, 0, 0) == 1.0\n\n    def test_mean_event(self, monkeypatch):\n        """"""Tests if the calculation of the sample mean is performed correctly. The test\n        monkeypatches the fock_prob function so that the probability is the same for each sample and\n        is equal to 1/216, i.e., one over the number of samples in the event with 5 modes,\n        6 photons, and max 3 photons per mode.""""""\n        graph = nx.complete_graph(6)\n        with monkeypatch.context() as m:\n            m.setattr(\n                ""strawberryfields.backends.gaussianbackend.GaussianState.fock_prob"",\n                lambda *args, **kwargs: 1.0 / 336,\n            )\n\n            assert np.allclose(similarity.prob_event_mc(graph, 6, 3), 1.0)\n\n    def test_loss(self, monkeypatch):\n        """"""Test if function correctly creates the SF program for lossy GBS.""""""\n        graph = nx.complete_graph(5)\n        mock_eng_run = mock.MagicMock()\n\n        with monkeypatch.context() as m:\n            m.setattr(sf.LocalEngine, ""run"", mock_eng_run)\n            similarity.prob_event_mc(graph, 6, 3, samples=1, loss=0.5)\n            p_func = mock_eng_run.call_args[0][0]\n\n        assert isinstance(p_func.circuit[1].op, sf.ops.LossChannel)\n\n    def test_no_loss(self, monkeypatch):\n        """"""Test if function correctly creates the SF program for GBS without loss.""""""\n        graph = nx.complete_graph(5)\n        mock_eng_run = mock.MagicMock()\n\n        with monkeypatch.context() as m:\n            m.setattr(sf.LocalEngine, ""run"", mock_eng_run)\n            similarity.prob_event_mc(graph, 6, 3, samples=1)\n            p_func = mock_eng_run.call_args[0][0]\n\n        assert not all([isinstance(op, sf.ops.LossChannel) for op in p_func.circuit])\n\n    def test_all_loss(self, monkeypatch):\n        """"""Test if function samples from the vacuum when maximum loss is applied.""""""\n        dim = 5\n        graph = nx.complete_graph(dim)\n        mock_eng_run = mock.MagicMock()\n\n        with monkeypatch.context() as m:\n            m.setattr(sf.LocalEngine, ""run"", mock_eng_run)\n            similarity.prob_event_mc(graph, 6, 3, samples=1, loss=1)\n            p_func = mock_eng_run.call_args[0][0]\n\n        eng = sf.LocalEngine(backend=""gaussian"")\n\n        state = eng.run(p_func).state\n        cov = state.cov()\n        disp = state.displacement()\n\n        assert np.allclose(cov, 0.5 * state.hbar * np.eye(2 * dim))\n        assert np.allclose(disp, np.zeros(dim))\n\n\nclass TestFeatureVectorSampling:\n    """"""Tests for the function ``strawberryfields.apps.graph.similarity.feature_vector_sampling``""""""\n\n    def test_bad_event_photon_numbers(self):\n        """"""Test if function raises a ``ValueError`` when input a minimum photon number that is\n        below zero.""""""\n        with pytest.raises(ValueError, match=""Cannot request events with photon number below zero""):\n            similarity.feature_vector_sampling([[1, 1, 0], [1, 0, 1]], [-1, 4], 1)\n\n    def test_low_count(self):\n        """"""Test if function raises a ``ValueError`` if ``max_count_per_mode`` is negative.""""""\n        with pytest.raises(ValueError, match=""Maximum number of photons""):\n            similarity.feature_vector_sampling([[1, 1, 0], [1, 0, 1]], [2, 4], -1)\n\n    def test_correct_distribution(self, monkeypatch):\n        """"""Test if function correctly constructs the feature vector corresponding to some hard\n        coded samples. This test uses a set of samples, corresponding events, and resultant\n        feature vector to test against the output of ``feature_vector_sampling``. The\n        ``sample_to_event`` function called within ``feature_vector_sampling`` is monkeypatched\n        to return the hard coded events corresponding to the samples.""""""\n        samples_events_mapping = {  # max_count_per_mode = 1\n            (1, 1, 0, 0, 0): 2,\n            (1, 1, 1, 0, 0): 3,\n            (1, 1, 1, 1, 0): 4,\n            (1, 1, 1, 1, 1): 5,\n            (2, 0, 0, 0, 0): None,\n            (3, 0, 0, 0, 0): None,\n            (4, 0, 0, 0, 0): None,\n            (5, 0, 0, 0, 0): None,\n            (0, 1, 1, 0, 0): 2,\n        }\n        samples = list(samples_events_mapping.keys()) + [(1, 1, 1, 1, 1)]  # add a repetition\n        event_photon_numbers = [2, 1, 3, 5]  # test alternative ordering\n        fv_true = [0.2, 0, 0.1, 0.2]\n\n        with monkeypatch.context() as m:\n            m.setattr(similarity, ""sample_to_event"", lambda x, _: samples_events_mapping[x])\n            fv = similarity.feature_vector_sampling(samples, event_photon_numbers, 1)\n\n        assert fv_true == fv\n\n\nclass TestFeatureVectorMC:\n    """"""Tests for the function ``strawberryfields.apps.graph.similarity.feature_vector_mc``""""""\n\n    def test_invalid_samples(self):\n        """"""Test if function raises a ``ValueError`` when a number of samples less than one is\n        requested.""""""\n        g = nx.complete_graph(10)\n        with pytest.raises(ValueError, match=""Number of samples must be at least one""):\n            similarity.feature_vector_mc(g, [2, 4], samples=0)\n\n    def test_invalid_n_mean(self):\n        """"""Test if function raises a ``ValueError`` when the mean photon number is specified to\n        be negative.""""""\n        g = nx.complete_graph(10)\n        with pytest.raises(ValueError, match=""Mean photon number must be non-negative""):\n            similarity.feature_vector_mc(g, [2, 4], n_mean=-1)\n\n    def test_invalid_loss(self):\n        """"""Test if function raises a ``ValueError`` when the loss parameter is specified outside\n        of range.""""""\n        g = nx.complete_graph(10)\n        with pytest.raises(ValueError, match=""Loss parameter must take a value between zero and""):\n            similarity.feature_vector_mc(g, [2, 4], loss=2)\n\n    def test_bad_event_photon_numbers_mc(self):\n        """"""Test if function raises a ``ValueError`` when input a minimum photon number that is\n        below zero.""""""\n        with pytest.raises(ValueError, match=""Cannot request events with photon number below zero""):\n            graph = nx.complete_graph(4)\n            similarity.feature_vector_mc(graph, [-1, 4], 1)\n\n    def test_low_count(self):\n        """"""Test if function raises a ``ValueError`` if ``max_count_per_mode`` is negative.""""""\n        g = nx.complete_graph(10)\n        with pytest.raises(ValueError, match=""Maximum number of photons""):\n            similarity.feature_vector_mc(g, [2, 4], -1)\n\n    def test_correct_vector_mc(self, monkeypatch):\n        """"""Test if function correctly constructs the feature vector. The\n        ``prob_event_mc`` function called within ``feature_vector_mc`` is monkeypatched\n        to return hard-coded outputs that depend only on the photon number in the event.""""""\n\n        with monkeypatch.context() as m:\n            m.setattr(\n                similarity,\n                ""prob_event_mc"",\n                lambda _graph, photons, max_count, n_mean, samples, loss: 1.0 / photons,\n            )\n            graph = nx.complete_graph(8)\n            fv = similarity.feature_vector_mc(graph, [2, 4, 8], 1)\n\n        assert fv == [0.5, 0.25, 0.125]\n'"
tests/apps/test_subgraph.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nUnit tests for strawberryfields.apps.subgraph\n""""""\n# pylint: disable=no-self-use,unused-argument\n# for testing private functions with pylint: disable=protected-access\n# for fixtures with pylint: disable=redefined-outer-name\nimport functools\n\nimport networkx as nx\nimport numpy as np\nimport pytest\n\nfrom strawberryfields.apps import data, subgraph\n\npytestmark = pytest.mark.apps\n\np_planted = data.Planted()\ng_planted = nx.Graph(p_planted.adj)\nplanted_weights = list(range(p_planted.modes))\n\n\n@pytest.fixture()\ndef process_planted(min_size, max_size, max_count, n_samples, node_select):\n    """"""Fixture for loading samples from the Planted dataset""""""\n    samples = p_planted[:n_samples]\n    d = subgraph.search(samples, g_planted, min_size, max_size, max_count, node_select)\n    return d\n\n\n@pytest.mark.parametrize(""min_size"", [4, 5])\n@pytest.mark.parametrize(""max_size"", [6, 7])\n@pytest.mark.parametrize(""max_count"", [2, 4])\n@pytest.mark.parametrize(""n_samples"", [200])\n@pytest.mark.parametrize(""node_select"", [""uniform"", planted_weights])\n@pytest.mark.usefixtures(""process_planted"")\nclass TestSearch:\n    """"""Tests for the function ``subgraph.search``""""""\n\n    def test_size_range(self, min_size, max_size, process_planted):\n        """"""Test if function searches the full range of sizes specified by ``min_size`` and\n        ``max_size``""""""\n        assert set(process_planted.keys()) == set(range(min_size, max_size + 1))\n\n    def test_max_count(self, max_count, process_planted):\n        """"""Test if function only keeps track of at most ``max_count`` subgraphs for each size in\n        the specified range""""""\n        assert all([len(l) <= max_count for l in process_planted.values()])\n\n    def test_ordered(self, process_planted):\n        """"""Test if function always returns dictionary values that are sorted lists in descending\n        order""""""\n        assert all(\n            [\n                all((l == sorted(l, reverse=True), isinstance(l, list)))\n                for l in process_planted.values()\n            ]\n        )\n\n    def test_tuple(self, process_planted):\n        """"""Test if function always returns dictionary values that are lists composed of tuples\n        with the first value being a float and the second being a list""""""\n        assert all(\n            [\n                all(\n                    (\n                        isinstance(t, tuple),\n                        isinstance(t[0], float),\n                        isinstance(t[1], list),\n                        len(t) == 2,\n                    )\n                )\n                for l in process_planted.values()\n                for t in l\n            ]\n        )\n\n    def test_density(self, process_planted):\n        """"""Test if function returns dictionary values that are lists of tuples where the first\n        element is the density of the subgraph specified by the second element""""""\n        assert all(\n            [\n                t[0] == nx.density(g_planted.subgraph(t[1]))\n                for l in process_planted.values()\n                for t in l\n            ]\n        )\n\n\ndef test_update_dict(monkeypatch):\n    """"""Test if the function ``subgraph._update_dict`` correctly combines a hard-coded dictionary\n    with another dictionary of candidate subgraph tuples.""""""\n\n    d = {\n        3: [\n            (0.8593365162004337, [1, 4, 6]),\n            (0.7834607649769199, [0, 1, 9]),\n            (0.6514468663852714, [1, 8, 9]),\n        ],\n        4: [(0.5738321520630872, [1, 5, 7, 9]), (0.4236138075085395, [5, 6, 7, 8])],\n    }\n\n    d_new = {\n        3: (0.4509829558474371, [2, 3, 7]),\n        4: (0.13609407922395578, [4, 5, 7, 8]),\n        5: (0.7769987961311593, [4, 6, 7, 8, 9]),\n    }\n\n    d_ideal = {\n        3: [\n            (0.8593365162004337, [1, 4, 6]),\n            (0.7834607649769199, [0, 1, 9]),\n            (0.6514468663852714, [1, 8, 9]),\n            (0.4509829558474371, [2, 3, 7]),\n        ],\n        4: [\n            (0.5738321520630872, [1, 5, 7, 9]),\n            (0.4236138075085395, [5, 6, 7, 8]),\n            (0.13609407922395578, [4, 5, 7, 8]),\n        ],\n        5: [(0.7769987961311593, [4, 6, 7, 8, 9])],\n    }\n\n    def patch_update_subgraphs_list(l, t, _max_count):\n        if l != [t]:\n            l.append(t)\n\n    with monkeypatch.context() as m:\n        m.setattr(subgraph, ""_update_subgraphs_list"", patch_update_subgraphs_list)\n        subgraph._update_dict(d, d_new, max_count=10)\n\n    assert d == d_ideal\n\n\nclass TestUpdateSubgraphsList:\n    """"""Tests for the function ``subgraph._update_subgraphs_list``""""""\n\n    l = [\n        (0.9183222696574376, [0, 3, 4, 6]),\n        (0.9011700496489199, [2, 5, 6, 9]),\n        (0.8768364522184167, [0, 1, 4, 8]),\n        (0.8360847995330193, [2, 3, 5, 9]),\n        (0.7017410327600858, [0, 4, 7, 9]),\n        (0.5587798561345368, [3, 6, 8, 9]),\n        (0.4132105226731848, [0, 1, 3, 6]),\n        (0.38803386506300297, [0, 2, 3, 6]),\n        (0.16013443604938415, [0, 1, 2, 5]),\n        (0.09284148990494756, [1, 2, 5, 9]),\n    ]\n\n    l_shuffled = [\n        (0.4132105226731848, [0, 1, 3, 6]),\n        (0.5587798561345368, [3, 6, 8, 9]),\n        (0.9183222696574376, [0, 3, 4, 6]),\n        (0.8768364522184167, [0, 1, 4, 8]),\n        (0.9011700496489199, [2, 5, 6, 9]),\n        (0.38803386506300297, [0, 2, 3, 6]),\n        (0.16013443604938415, [0, 1, 2, 5]),\n        (0.8360847995330193, [2, 3, 5, 9]),\n        (0.7017410327600858, [0, 4, 7, 9]),\n        (0.09284148990494756, [1, 2, 5, 9]),\n    ]\n\n    t_above_min_density = [\n        (0.9744200893790599, [10, 11, 12, 13]),\n        (0.7356617723720428, [14, 15, 16, 17]),\n        (0.1020993710922522, [18, 19, 20, 21]),\n    ]\n\n    t_min_density = (0.09284148990494756, [22, 23, 24, 25])\n\n    t_below_min_density = (0.05835994410622691, [26, 27, 28, 29])\n\n    @pytest.mark.parametrize(""elem"", list(range(10)))\n    def test_already_contained(self, elem):\n        """"""Test if function does not add a subgraph tuple that is already contained in the list""""""\n        l = self.l.copy()\n        subgraph._update_subgraphs_list(l, l[elem], max_count=20)\n        assert l == self.l\n\n    def test_add_below_max_count(self):\n        """"""Test if function adds subgraph tuples whenever len(l) < max_count. This test starts\n        with an empty list and tries to add on elements one at a time from ``l_shuffled``. Since\n        ``max_count = 10`` and ``len(l) = 10``, we expect to be able to build up our list to be\n        equal to ``l``.""""""\n        l = []\n        for t in self.l_shuffled:\n            subgraph._update_subgraphs_list(l, t, max_count=10)\n\n        assert l == self.l\n\n    def test_add_above_max_count_high_density(self):\n        """"""Test if function adds subgraph tuples with density exceeding the minimum value of\n        ``l`` even though the length of ``l`` is at its maximum""""""\n        max_count = 10\n\n        for t in self.t_above_min_density:\n            l = self.l.copy()\n            l_ideal = sorted(l + [t], reverse=True)\n\n            subgraph._update_subgraphs_list(l, t, max_count=max_count)\n            del l_ideal[-1]\n            assert len(l) == max_count\n            assert l == l_ideal\n\n    def test_add_above_max_count_equal_density(self, monkeypatch):\n        """"""Test if function randomly adds in a subgraph tuple with density equal to the minimum\n        value of ``l``, even though the length of ``l`` is at its maximum. This test\n        monkeypatches the ``np.random.choice`` call used in the function to decide whether to\n        keep the original subgraph or add in the new one. In one case, ``np.random.choice`` is\n        monkeypatched to leave ``l`` unchanged, and in another case ``np.random.choice`` is\n        monkeypatched to swap the minimum value of ``l`` with ``t_min_density``.""""""\n        max_count = 10\n\n        with monkeypatch.context() as m:\n            m.setattr(np.random, ""choice"", lambda x: 0)\n            l = self.l.copy()\n            subgraph._update_subgraphs_list(l, self.t_min_density, max_count=max_count)\n            assert len(l) == max_count\n            assert l == self.l\n\n        with monkeypatch.context() as m:\n            m.setattr(np.random, ""choice"", lambda x: 1)\n            l = self.l.copy()\n            subgraph._update_subgraphs_list(l, self.t_min_density, max_count=max_count)\n\n            l_ideal = self.l.copy()\n            del l_ideal[-1]\n            l_ideal.append(self.t_min_density)\n            assert len(l) == max_count\n            assert l == l_ideal\n\n    def test_add_above_max_count_low_density(self):\n        """"""Test if function does not add in a subgraph tuple of density lower than the minimum\n        value of ``l`` when the length of ``l`` is at its maximum""""""\n        max_count = 10\n        l = self.l.copy()\n\n        subgraph._update_subgraphs_list(l, self.t_below_min_density, max_count=max_count)\n        assert l == self.l\n\n\nclass TestValidate:\n    """"""Tests for the function ``subgraph._validate_inputs``""""""\n\n    def test_input_not_subgraph(self):\n        """"""Test if function raises a ``ValueError`` when input is not a subgraph""""""\n        dim = 5\n        with pytest.raises(ValueError, match=""Input is not a valid subgraph""):\n            subgraph._validate_inputs({dim + 1}, nx.complete_graph(dim), 2, 3)\n\n    def test_invalid_min_size(self):\n        """"""Test if function raises a ``ValueError`` when an invalid min_size is requested""""""\n        dim = 5\n        with pytest.raises(ValueError, match=""min_size must be at least 1""):\n            subgraph._validate_inputs({0, 1}, nx.complete_graph(dim), 0, 3)\n\n    def test_invalid_max_size(self):\n        """"""Test if function raises a ``ValueError`` when an invalid max_size is requested""""""\n        dim = 5\n        with pytest.raises(ValueError, match=""max_size must be less than number of nodes in graph""):\n            subgraph._validate_inputs({0, 1}, nx.complete_graph(dim), 2, dim)\n\n    def test_invalid_max_vs_min(self):\n        """"""Test if function raises a ``ValueError`` when max_size is less than min_size""""""\n        dim = 5\n        with pytest.raises(ValueError, match=""max_size must not be less than min_size""):\n            subgraph._validate_inputs({0, 1}, nx.complete_graph(dim), 4, 3)\n\n    def test_bad_weights(self):\n        """"""Test if function raises a ``ValueError`` when a vector of node weights input to\n        ``node_select`` is not of the same dimension as the input graph.""""""\n        dim = 5\n        w = [1] * (dim - 1)\n        with pytest.raises(ValueError, match=""Number of node weights must match number of nodes""):\n            subgraph._validate_inputs({0, 1}, nx.complete_graph(dim), 2, 3, node_select=w)\n\n    def test_bad_node_select(self):\n        """"""Tests if function raises a ``ValueError`` when input an invalid ``node_select``\n        argument""""""\n        dim = 5\n        with pytest.raises(ValueError, match=""Node selection method not recognized""):\n            subgraph._validate_inputs({0, 1}, nx.complete_graph(dim), 2, 3, node_select="""")\n\n\nclass TestResize:\n    """"""Tests for the function ``subgraph.resize``""""""\n\n    def choice(self, x, element):\n        """"""For patching numpy random choice to return a fixed element.""""""\n        if isinstance(x, int):\n            return element\n        return x[element]\n\n    @pytest.mark.parametrize(""dim"", [7, 8])\n    @pytest.mark.parametrize(\n        ""min_size,max_size"",\n        [(1, 4), (1, 5), (2, 6), (1, 6), (4, 6), (1, 2), (1, 1), (3, 3), (5, 5), (1, 3), (3, 6)],\n    )\n    def test_full_range(self, dim, min_size, max_size):\n        """"""Test if function correctly resizes to full range of requested sizes""""""\n        g = nx.complete_graph(dim)\n        resized = subgraph.resize([0, 1, 2], g, min_size, max_size)\n        r = range(min_size, max_size + 1)\n\n        assert set(resized.keys()) == set(r)\n\n        subgraph_sizes = [len(resized[i]) for i in r]\n\n        assert subgraph_sizes == list(r)\n\n    def test_correct_resize(self):\n        """"""Test if function correctly resizes on a fixed example where the ideal resizing is\n        known. The example is a lollipop graph of 6 fully connected nodes and 2 nodes on the\n        lollipop stick. An edge between node zero and node ``dim - 1`` (the lollipop node\n        connecting to the stick) is removed and a starting subgraph of nodes ``[2, 3, 4, 5,\n        6]`` is selected. The objective is to add-on 1 and 2 nodes and remove 1 node.""""""\n        dim = 6\n        g = nx.lollipop_graph(dim, 2)\n        g.remove_edge(0, dim - 1)\n\n        s = [2, 3, 4, 5, 6]\n        min_size = 4\n        max_size = 7\n\n        ideal = {\n            4: [2, 3, 4, 5],\n            5: [2, 3, 4, 5, 6],\n            6: [1, 2, 3, 4, 5, 6],\n            7: [0, 1, 2, 3, 4, 5, 6],\n        }\n        resized = subgraph.resize(s, g, min_size, max_size)\n\n        assert ideal == resized\n\n    def test_tie(self, monkeypatch):\n        """"""Test if function correctly settles ties with random selection. This test starts with\n        the problem of a 6-dimensional complete graph and a 4-node subgraph, with the objective\n        of shrinking down to 3 nodes. In this case, any of the 4 nodes in the subgraph is an\n        equally good candidate for removal since all nodes have the same degree. The test\n        monkeypatches the ``np.random.choice`` function to simply choose a fixed element,\n        e.g. the element 2 of the list [0, 1, 2, 3] will be 2. Using this we expect the node to\n        be removed by ``resize`` in this case to have label equal to the element.""""""\n        dim = 6\n        g = nx.complete_graph(dim)\n        s = [0, 1, 2, 3]\n\n        for i in range(4):\n            choice_i = functools.partial(self.choice, element=i)\n            with monkeypatch.context() as m:\n                m.setattr(np.random, ""choice"", choice_i)\n                resized = subgraph.resize(s, g, min_size=3, max_size=3)\n                resized_subgraph = resized[3]\n                removed_node = list(set(s) - set(resized_subgraph))[0]\n                assert removed_node == i\n\n    @pytest.mark.parametrize(""dim"", range(4, 8))\n    def test_correct_resize_weight(self, dim):\n        """"""Test if function correctly resizes on a fixed example where the ideal resizing is\n        known and node-weight based selection is used to settle ties. The example is a complete\n        graph with a starting subgraph of the first ``dim - 2`` nodes. The task is to resize to\n        one node smaller and larger. The nodes weights are monotonically increasing with node\n        label. In the shrink step, the 0 node should be removed. In the grow step, the ``dim -\n        1`` node should be added.""""""\n        g = nx.complete_graph(dim)\n        s = list(range(dim - 2))\n        min_size = dim - 3\n        max_size = dim - 1\n        w = list(range(dim))\n\n        ideal = {dim - 2: s, dim - 1: s + [dim - 1], dim - 3: list(range(1, dim - 2))}\n        resized = subgraph.resize(s, g, min_size, max_size, node_select=w)\n\n        assert ideal == resized\n\n    @pytest.mark.parametrize(""dim"", range(4, 8))\n    @pytest.mark.parametrize(""elem"", [0, 1])\n    def test_weight_and_degree_ties(self, dim, monkeypatch, elem):\n        """"""Test if function correctly resizes on a fixed example where the ideal resizing is\n        known and node-weight based selection is used to settle ties, but with all node weights\n        equal so that they must be settled uniformly at random. The example is a complete\n        graph with a starting subgraph of the first ``dim - 2`` nodes. The task is to resize to\n        one node smaller and larger. This test monkeypatches the ``np.random.choice`` call used in\n        the function so that instead it returns a fixed element. This element is set to 0 or 1 in\n        the test, resulting in different nodes being added and removed from the starting\n        subgraph.""""""\n        g = nx.complete_graph(dim)\n        s = list(range(dim - 2))\n        min_size = dim - 3\n        max_size = dim - 1\n        w = [1] * dim\n\n        choice_elem = functools.partial(self.choice, element=elem)\n\n        ideal = {dim - 2: s, dim - 1: s + [dim - 2 + elem], dim - 3: list(set(s) - {elem})}\n        with monkeypatch.context() as m:\n            m.setattr(np.random, ""choice"", choice_elem)\n            resized = subgraph.resize(s, g, min_size, max_size, node_select=w)\n\n        assert resized == ideal\n'"
tests/apps/test_train.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nUnit tests for strawberryfields.apps.train\n""""""\n# pylint: disable=no-self-use,protected-access,redefined-outer-name\nimport itertools\n\nimport numpy as np\nimport pytest\nimport thewalrus\nfrom thewalrus.quantum import find_scaling_adjacency_matrix as rescale\nfrom thewalrus.quantum import find_scaling_adjacency_matrix_torontonian as rescale_tor\n\nfrom strawberryfields.apps import train\nfrom strawberryfields.apps.train.embed import Exp\n\npytestmark = pytest.mark.apps\n\n\n@pytest.fixture\ndef embedding(dim):\n    """"""Fixture for embedding""""""\n    return Exp(dim)\n\n\n@pytest.fixture\ndef params(dim):\n    """"""Fixture for generating arbitrary parameters for the model""""""\n    return np.linspace(0, 1, dim)\n\n\ndef test_rescale_adjacency():\n    """"""Test for the ``train.param.rescale_adjacency`` function. We find the rescaled\n    adjacency matrix when using threshold and PNR detection and check that: (i) the two matrices\n    are not the same, (ii) they are rescaled by the correct factor.""""""\n    adj = np.ones((10, 10))\n    n_mean = 5\n\n    r1 = train.param.rescale_adjacency(adj, n_mean, True)\n    r2 = train.param.rescale_adjacency(adj, n_mean, False)\n    s1 = rescale_tor(adj, n_mean)\n    s2 = rescale(adj, n_mean)\n\n    assert not np.allclose(r1, r2)\n    assert np.allclose(r1, s1 * adj)\n    assert np.allclose(r2, s2 * adj)\n\n\ndef test_prob_click():\n    """"""Test for the ``train.param.prob_click`` function. For a simple 4 mode system,\n    we generate the full probability distribution and check that it sums to one as well as that\n    individual probabilities are between 0 and 1. We then focus on probabilities for samples that\n    have two clicks and assert that they are all equal, as expected since our input adjacency\n    matrix is fully connected.\n    """"""\n    dim = 4\n    A = np.ones((dim, dim))\n    A_scale = train.param.rescale_adjacency(A, 3, True)\n    s = list(itertools.product([0, 1], repeat=dim))\n    p = np.array([train.param.prob_click(A_scale, s_) for s_ in s])\n    p_two_clicks = np.array([p[i] for i, s_ in enumerate(s) if sum(s_) == 2])\n    assert np.allclose(np.sum(p), 1)  # check that distribution sums to one\n    assert (p <= 1).all() and (p >= 0).all()\n    assert np.allclose(p_two_clicks - p_two_clicks[0], np.zeros(len(p_two_clicks)))\n\n\ndef test_prob_photon_sample():\n    """"""Test for the ``train.param.prob_photon_sample`` function. For a simple 4 mode\n    system, we generate the probability distribution up to two photons and check that it sums to\n    less than one as well as that individual probabilities are between 0 and 1. We then focus on\n    probabilities for samples in the orbit [1, 1] and assert that they are all equal, as expected\n    since our input adjacency matrix is fully connected.\n    """"""\n    dim = 4\n    A = np.ones((dim, dim))\n    A_scale = train.param.rescale_adjacency(A, 3, False)\n    s = list(itertools.product(range(3), repeat=dim))\n    p = np.array([train.param.prob_photon_sample(A_scale, s_) for s_ in s])\n    p_two_clicks = np.array([p[i] for i, s_ in enumerate(s) if sum(s_) == 2 and max(s_) == 1])\n    assert np.sum(p) <= 1\n    assert (p <= 1).all() and (p >= 0).all()\n    assert np.allclose(p_two_clicks - p_two_clicks[0], np.zeros(len(p_two_clicks)))\n\n\ndef test_A_to_cov():\n    """"""Test if A_to_cov returns the correct covariance matrix for a simple fixed example""""""\n    x = np.sqrt(0.5)\n    A = np.array([[0, x], [x, 0]])\n    cov = train.param.A_to_cov(A)\n    target = np.array(\n        [\n            [3.0, 0.0, 0.0, 2.82842712],\n            [0.0, 3.0, 2.82842712, 0.0],\n            [0.0, 2.82842712, 3.0, 0.0],\n            [2.82842712, 0.0, 0.0, 3.0],\n        ]\n    )\n    assert np.allclose(cov, target)\n\n\n@pytest.mark.usefixtures(""adj"", ""params"", ""embedding"")\n@pytest.mark.parametrize(""dim"", [7, 9])  # used in the adj fixture to determine number of modes\n@pytest.mark.parametrize(""n_mean"", [4, 6])\nclass TestVGBS:\n    """"""Tests for the class ``train.VGBS``""""""\n\n    def test_W(self, adj, n_mean, params, embedding):\n        """"""Test that the W method correctly gives the diagonal matrix of square root embedded\n        parameters""""""\n        gbs = train.VGBS(adj, n_mean, embedding, True)\n        W = gbs.W(params)\n        assert np.allclose(np.diag(W) ** 2, embedding(params))  # check that diagonal squared\n        # equals embedding\n\n    def test_generate_samples(self, adj, n_mean, monkeypatch, embedding):\n        """"""Test that generate_samples correctly dispatches between torontonian and hafnian\n        sampling based upon whether threshold=True or threshold=False. This is done by\n        monkeypatching torontonian_sample_state and hafnian_sample_state so that they simply\n        return 0 and 1, respectively, instead of calculating samples. We then check that the\n        returned samples are 0 in threshold mode and 1 when not in threshold mode.""""""\n        gbs = train.VGBS(adj, n_mean, embedding, True)\n\n        with monkeypatch.context() as m:\n            m.setattr(thewalrus.samples, ""torontonian_sample_state"", lambda *args, **kwargs: 0)\n            s_threshold = gbs.generate_samples(gbs.A_init, 10)\n\n        gbs.threshold = False\n\n        with monkeypatch.context() as m:\n            m.setattr(thewalrus.samples, ""hafnian_sample_state"", lambda *args, **kwargs: 1)\n            s_pnr = gbs.generate_samples(gbs.A_init, 10)\n\n        assert s_threshold == 0\n        assert s_pnr == 1\n\n    def test_add_A_init_samples_bad_shape(self, adj, n_mean, dim, embedding):\n        """"""Test that add_A_init_samples raises a ValueError when input samples of incorrect\n        shape, i.e. of dim + 1 modes""""""\n        gbs = train.VGBS(adj, n_mean, embedding, True)\n        s = np.ones((2, dim + 1))\n        with pytest.raises(ValueError, match=""Must input samples of shape""):\n            gbs.add_A_init_samples(s)\n\n    def test_add_A_init_samples_none_there(self, adj, n_mean, dim, embedding):\n        """"""Test that add_A_init_samples correctly adds samples""""""\n        gbs = train.VGBS(adj, n_mean, embedding, True)\n        s = np.ones((2, dim))\n        gbs.add_A_init_samples(s)\n        assert np.allclose(gbs.A_init_samples, s)\n\n    def test_add_A_init_samples_already_there(self, adj, n_mean, dim, embedding):\n        """"""Test that add_A_init_samples correctly adds more samples when some are already there""""""\n        gbs = train.VGBS(adj, n_mean, embedding, True)\n        gbs.A_init_samples = np.ones((2, dim))\n        gbs.add_A_init_samples(np.zeros((2, dim)))\n        assert gbs.A_init_samples.shape == (4, dim)\n        assert np.allclose(gbs.A_init_samples[:2], np.ones((2, dim)))\n        assert np.allclose(gbs.A_init_samples[2:3], np.zeros((2, dim)))\n\n    def test_get_A_init_samples_none_there(self, adj, n_mean, monkeypatch, dim, embedding):\n        """"""Test if get_A_init_samples generates the required samples when none are present in\n        A_init_samples. To speed up sampling, we monkeypatch torontonian_sample_state to always\n        return a numpy array of ones.""""""\n        gbs = train.VGBS(adj, n_mean, embedding, True)\n        with monkeypatch.context() as m:\n            m.setattr(\n                thewalrus.samples,\n                ""torontonian_sample_state"",\n                lambda *args, **kwargs: np.ones((args[1], dim)),\n            )\n            samples = gbs.get_A_init_samples(1000)\n        assert np.allclose(samples, np.ones((1000, dim)))\n\n    def test_get_A_init_samples_already_there(self, adj, n_mean, monkeypatch, dim, embedding):\n        """"""Test if get_A_init_samples generates the required samples when none are present in\n        A_init_samples. To speed up sampling, we monkeypatch torontonian_sample_state to always\n        return a numpy array of ones.""""""\n        gbs = train.VGBS(adj, n_mean, embedding, True, np.zeros((200, dim)))\n        with monkeypatch.context() as m:\n            m.setattr(\n                thewalrus.samples,\n                ""torontonian_sample_state"",\n                lambda *args, **kwargs: np.ones((args[1], dim)),\n            )\n            samples = gbs.get_A_init_samples(1000)\n        assert np.allclose(samples[:200], np.zeros((200, dim)))\n        assert np.allclose(samples[200:], np.ones((800, dim)))\n\n    def test_get_A_init_samples_lots_there(self, adj, n_mean, dim, embedding):\n        """"""Test if get_A_init_samples returns a portion of the pre-generated samples if\n        ``n_samples`` is less than the number of samples stored.""""""\n        gbs = train.VGBS(adj, n_mean, embedding, True, np.zeros((1000, dim)))\n        samples = gbs.get_A_init_samples(200)\n        assert samples.shape == (200, dim)\n\n    @pytest.mark.parametrize(""threshold"", [True, False])\n    def test_prob_sample_vacuum(self, n_mean, dim, threshold, embedding):\n        """"""Test if prob_sample returns the correct probability of the vacuum, which can be\n        calculated directly as the prefactor in the GBS distribution.""""""\n        adj = np.ones((dim, dim))\n        params = np.zeros(dim)\n        gbs = train.VGBS(adj, n_mean, embedding, threshold)\n        sample = np.zeros(dim)\n        p = gbs.prob_sample(params, sample)\n\n        O = train.param._Omat(gbs.A(params))\n        scale = np.sqrt(np.linalg.det(np.identity(2 * dim) - O))\n\n        assert np.allclose(scale, p)\n\n    def test_prob_sample_different(self, n_mean, dim, embedding):\n        """"""Test if prob_sample returns different probabilities for the same sample when using\n        threshold and pnr modes.""""""\n        adj = np.ones((dim, dim))\n        params = np.zeros(dim)\n        gbs = train.VGBS(adj, n_mean, embedding, True)\n        sample = np.array([1, 1] + [0] * (dim - 2))\n        p1 = gbs.prob_sample(params, sample)\n\n        gbs.threshold = False\n        p2 = gbs.prob_sample(params, sample)\n\n        assert not np.allclose(p1, p2)\n\n    def test_mean_photons_by_mode(self, n_mean, dim, embedding):\n        """"""Test that mean_photons_by_mode is correct when given a simple fully connected\n        adjacency matrix and an identity W. We expect each mode to have the same mean photon number\n        and for that to add up to n_mean.""""""\n        adj = np.ones((dim, dim))\n        params = np.zeros(dim)\n        gbs = train.VGBS(adj, n_mean, embedding, False)\n        n_mean_vec = gbs.mean_photons_by_mode(params)\n\n        assert np.allclose(np.sum(n_mean_vec), n_mean)  # check that the vector sums to n_mean\n        assert np.allclose(n_mean_vec - n_mean_vec[0], np.zeros(dim))  # check that the vector is\n        # constant\n        assert np.allclose(n_mean_vec[0], n_mean / dim)  # check that elements have correct values\n\n    def test_mean_clicks_by_mode(self, n_mean, dim, embedding):\n        """"""Test that mean_clicks_by_mode is correct when given a simple fully connected\n        adjacency matrix and an identity W. We expect each mode to have the same mean click number\n        and for that to add up to n_mean.""""""\n        adj = np.ones((dim, dim))\n        params = np.zeros(dim)\n        gbs = train.VGBS(adj, n_mean, embedding, True)\n        n_mean_vec = gbs.mean_clicks_by_mode(params)\n\n        assert np.allclose(np.sum(n_mean_vec), n_mean)  # check that the vector sums to n_mean\n        assert np.allclose(n_mean_vec - n_mean_vec[0], np.zeros(dim))  # check that the vector is\n        # constant\n        assert np.allclose(n_mean_vec[0], n_mean / dim)  # check that elements have correct values\n\n    def test_photons_clicks_comparison(self, n_mean, dim, adj, embedding):\n        """"""Test that compares mean_photons_by_mode and mean_clicks_by_mode. We expect elements of\n        n_mean_vec_photon to always be larger than n_mean_vec_click and also for elements of\n        n_mean_vec_click to not exceed one.""""""\n        params = np.zeros(dim)\n        gbs = train.VGBS(adj, n_mean, embedding, False)\n        n_mean_vec_photon = gbs.mean_photons_by_mode(params)\n        n_mean_vec_click = gbs.mean_clicks_by_mode(params)\n\n        assert (n_mean_vec_click <= 1).all()\n        assert (n_mean_vec_photon >= n_mean_vec_click).all()\n\n    @pytest.mark.parametrize(""threshold"", [True, False])\n    def test_n_mean(self, adj, n_mean, dim, threshold, embedding):\n        """"""Test that n_mean returns the expected number of photons or clicks when using an\n        identity W, so that we expect the mean number of photons to be equal to the input value\n        of n_mean""""""\n        params = np.zeros(dim)\n        gbs = train.VGBS(adj, n_mean, embedding, threshold)\n        assert np.allclose(gbs.n_mean(params), n_mean)\n\n\n@pytest.mark.usefixtures(""adj"", ""params"", ""embedding"")\n@pytest.mark.parametrize(""dim"", [7, 9])  # used in the adj fixture to determine number of modes\n@pytest.mark.parametrize(""n_mean"", [2, 3])\n@pytest.mark.parametrize(""threshold"", [True, False])\ndef test_VGBS_integration(adj, params, n_mean, threshold, dim, embedding):\n    """"""Integration test for the class ``train.VGBS``. We access the output adjacency matrix,\n    mean photon number, and samples to check that they have the expected shape.""""""\n    n_samples = 3\n    gbs = train.VGBS(adj, n_mean, embedding, threshold)\n    A_prime = gbs.A(params)\n    n_mean_prime = gbs.n_mean(params)\n    samples = gbs.generate_samples(A_prime, n_samples)\n    assert A_prime.shape == (dim, dim)\n    assert isinstance(n_mean_prime, float)\n    assert samples.shape == (n_samples, dim)\n'"
tests/apps/test_vibronic.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nTests for strawberryfields.apps.vibronic\n""""""\nimport numpy as np\nimport pytest\n\nfrom scipy.constants import c, h, k\n\nfrom strawberryfields.apps import vibronic\n\npytestmark = pytest.mark.apps\n\n\nclass TestGBSParams:\n    """"""Tests for the function ``strawberryfields.apps.vibronic.gbs_params``""""""\n\n    dim = 7\n    w = np.array([3765.2386, 3088.1826, 1825.1799, 1416.9512, 1326.4684, 1137.0490, 629.7144])\n    wp = np.array([3629.9472, 3064.9143, 1566.4602, 1399.6554, 1215.3421, 1190.9077, 496.2845])\n    Ud = np.array(\n        [\n            [0.9934, 0.0144, 0.0153, 0.0268, 0.0638, 0.0751, -0.0428],\n            [-0.0149, 0.9931, 0.0742, 0.0769, -0.0361, -0.0025, 0.0173],\n            [-0.0119, -0.0916, 0.8423, 0.1799, -0.3857, 0.3074, 0.0801],\n            [0.0381, 0.0409, -0.3403, -0.5231, -0.6679, 0.3848, 0.1142],\n            [-0.0413, -0.0342, -0.4004, 0.7636, -0.1036, 0.4838, 0.0941],\n            [0.0908, -0.0418, -0.0907, 0.3151, -0.5900, -0.7193, 0.1304],\n            [-0.0325, 0.0050, -0.0206, 0.0694, -0.2018, 0.0173, -0.9759],\n        ]\n    )\n    d = np.array([0.2254, 0.1469, 1.5599, -0.3784, 0.4553, -0.3439, 0.0618])\n\n    T = 300.0\n\n    t, U1, S, U2, alpha = vibronic.gbs_params(w, wp, Ud, d, T)\n\n    @pytest.mark.parametrize(""unitary"", [U1, U2])\n    def test_unitary(self, unitary):\n        """"""Test if function outputs the interferometer unitaries that are valid unitaries,\n        i.e., satisfying U U^dag = I""""""\n        assert unitary.shape == (self.dim, self.dim)\n        assert np.allclose(unitary @ unitary.T.conj(), np.identity(self.dim))\n\n    def test_displacement(self):\n        """"""Test if function returns correct displacement parameters""""""\n        assert np.allclose(self.alpha * np.sqrt(2), self.d)\n\n    def test_squeezing(self):\n        """"""Test if function returns squeezing parameters as a vector rather than a diagonal\n        matrix""""""\n        assert self.S.shape == (self.dim,)\n\n    def test_duschinsky(self):\n        """"""Test if function returns interferometer unitary and squeezing parameters that\n        correctly reconstruct the input Duschinsky matrix""""""\n        sigma = np.diag(np.exp(self.S))\n        J = self.U2 @ sigma @ self.U1\n        Ud = np.diag(self.wp ** -0.5) @ J @ np.diag(self.w ** 0.5)\n        assert np.allclose(Ud, self.Ud)\n\n    def test_invalid_temperature(self):\n        """"""Test if function raises a ``ValueError`` when a negative temperature is given.""""""\n        with pytest.raises(ValueError, match=""Temperature must be zero or positive""):\n            vibronic.gbs_params(self.w, self.wp, self.Ud, self.d, -1)\n\n    def test_twomode(self):\n        """"""Test if function returns two-mode squeezing parameters that correctly reconstruct the\n        input normal mode frequencies.""""""\n        w = -k * self.T / (0.5 * h * c * 100) * np.log(np.tanh(self.t))\n        assert np.allclose(w, self.w)\n\n    def test_zero_temperature(self):\n        """"""Test if function returns zero two-mode squeezing parameters when temperature is zero.""""""\n        t, _, _, _, _ = vibronic.gbs_params(self.w, self.wp, self.Ud, self.d, 0.0)\n        assert np.all(t == 0)\n\n\nw  = np.array([300.0, 200.0, 100.0])\nwp = np.array([700.0, 600.0, 500.0])\n\nS1 = [[1, 1, 0, 0, 0, 0], [1, 2, 0, 0, 1, 1]]\nE1 = [1300.0, 1600.0]\n\nS2 = [[1, 2, 0, 0, 1, 1]]\nE2 = [1600.0]\n\nS3 = [1, 2, 0, 0, 1, 1]\nE3 = 1600.0\n\n\n@pytest.mark.parametrize(""sample, sample_energy"", [(S1, E1), (S2, E2), (S3, E3)])\ndef test_energies(sample, sample_energy):\n    r""""""Tests the correctness of the energies generated for GBS samples in\n    ``strawberryfields.apps.vibronic.energies``.""""""\n    assert np.allclose(vibronic.energies(sample, w, wp), sample_energy)\n'"
tests/backend/test_beamsplitter_operation.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""\nUnit tests for beamsplitter operations\nConvention: The beamsplitter operation transforms\n\\hat{a} -> t \\hat{a} + r \\hat{b}\n\\hat{b} -> - r^* \\hat{a} + t^* \\hat{b}\nwhere \\hat{a}, \\hat{b} are the photon creation operators of the two modes\nEquivalently, we have t:=\\cos(\\theta) (t assumed real) and r:=\\exp{i\\phi}\\sin(\\theta)\n""""""\n\nimport itertools as it\n\nimport pytest\n\nimport numpy as np\nfrom scipy.special import factorial\n\n\nT_VALUES = np.linspace(-0.2, 1.0, 3)\nPHASE_R = np.linspace(0, 2 * np.pi, 3, endpoint=False)\nALPHA = 0.1\nMAG_ALPHAS = np.linspace(0.0, ALPHA, 3)\nMODES = list(it.combinations(range(4), 2))\n\n\nclass TestRepresentationIndependent:\n    """"""Basic implementation-independent tests.""""""\n\n    def test_complex_t(self, setup_backend):\n        """"""Test exception raised if t is complex""""""\n        t = 0.1 + 0.5j\n        r = np.exp(1j * 0.2) * np.sqrt(1.0 - np.abs(t) ** 2)\n        backend = setup_backend(2)\n\n        with pytest.raises(ValueError, match=""must be a float""):\n            backend.beamsplitter(t, r, 0, 1)\n\n    @pytest.mark.parametrize(""t"", T_VALUES)\n    @pytest.mark.parametrize(""r_phi"", PHASE_R)\n    def test_vacuum_beamsplitter(self, setup_backend, t, r_phi, tol):\n        """"""Tests beamsplitter operation in some limiting cases where the output\n           should be the vacuum in both modes.""""""\n        r = np.exp(1j * r_phi) * np.sqrt(1.0 - np.abs(t) ** 2)\n        backend = setup_backend(2)\n\n        backend.beamsplitter(t, r, 0, 1)\n        assert np.all(backend.is_vacuum(tol))\n\n    @pytest.mark.parametrize(""t"", T_VALUES)\n    @pytest.mark.parametrize(""mag_alpha"", MAG_ALPHAS[1:])\n    @pytest.mark.parametrize(""r_phi"", PHASE_R)\n    def test_coherent_vacuum_interfered(self, setup_backend, t, mag_alpha, r_phi, tol):\n        r""""""Tests if a range of beamsplitter output states (formed from a coherent state interfering with vacuum)\n            have the correct fidelity with the expected coherent states outputs.\n            |\\psi_in> = |\\alpha>|0> --> |t \\alpha>|r \\alpha> = |\\psi_out>\n            and for each output mode,\n            |\\gamma> = exp(-0.5 |\\gamma|^2) \\sum_n \\gamma^n / \\sqrt{n!} |n>""""""\n        phase_alpha = np.pi / 5\n        alpha = mag_alpha * np.exp(1j * phase_alpha)\n        r = np.exp(1j * r_phi) * np.sqrt(1.0 - np.abs(t) ** 2)\n        backend = setup_backend(2)\n\n        backend.displacement(alpha, 0)\n        backend.beamsplitter(t, r, 0, 1)\n        alpha_outA = t * alpha\n        alpha_outB = r * alpha\n        state = backend.state()\n        fidel = state.fidelity_coherent([alpha_outA, alpha_outB])\n        assert np.allclose(fidel, 1, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""tf"", ""fock"")\nclass TestFockRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    @pytest.mark.parametrize(""t"", T_VALUES)\n    @pytest.mark.parametrize(""r_phi"", PHASE_R)\n    def test_normalized_beamsplitter_output(self, setup_backend, t, r_phi, tol):\n        """"""Tests if a range of beamsplitter outputs states are normalized.""""""\n\n        alpha = ALPHA * np.exp(1j * np.pi / 3)\n        r = np.exp(1j * r_phi) * np.sqrt(1.0 - np.abs(t) ** 2)\n        backend = setup_backend(2)\n\n        backend.displacement(alpha, 1)\n        backend.beamsplitter(t, r, 0, 1)\n        state = backend.state()\n        tr = state.trace()\n        assert np.allclose(tr, 1, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""t"", T_VALUES)\n    @pytest.mark.parametrize(""mag_alpha"", MAG_ALPHAS[1:])\n    @pytest.mark.parametrize(""r_phi"", PHASE_R)\n    def test_coherent_vacuum_interfered_fock_elements(\n            self, setup_backend, mag_alpha, t, r_phi, cutoff, pure, tol\n    ):\n        r""""""Tests if a range of beamsplitter output states (formed from a coherent state interfering with vacuum)\n            have the correct Fock basis elements.\n            |\\psi_in> = |\\alpha>|0> --> |t \\alpha>|r \\alpha> = |\\psi_out>\n            and for each output mode,\n            |\\gamma> = exp(-0.5 |\\gamma|^2) \\sum_n \\gamma^n / \\sqrt{n!} |n>""""""\n\n        phase_alpha = np.pi / 5\n        alpha = mag_alpha * np.exp(1j * phase_alpha)\n        r = np.exp(1j * r_phi) * np.sqrt(1.0 - np.abs(t) ** 2)\n        backend = setup_backend(2)\n\n        backend.displacement(alpha, 0)\n        backend.beamsplitter(t, r, 0, 1)\n        state = backend.state()\n\n        if state.is_pure:\n            numer_state = state.ket()\n        else:\n            numer_state = state.dm()\n\n        alpha_outA = t * alpha\n        alpha_outB = r * alpha\n\n        n = np.arange(cutoff)\n        ref_stateA = (\n            np.exp(-0.5 * np.abs(alpha_outA) ** 2)\n            * alpha_outA ** n\n            / np.sqrt(factorial(n))\n        )\n        ref_stateB = (\n            np.exp(-0.5 * np.abs(alpha_outB) ** 2)\n            * alpha_outB ** n\n            / np.sqrt(factorial(n))\n        )\n\n        ref_state = np.einsum(""i,j->ij"", ref_stateA, ref_stateB)\n\n        if not pure:\n            ref_state = np.einsum(\n                ""i,j,k,l->ijkl"",\n                ref_stateA,\n                np.conj(ref_stateA),\n                ref_stateB,\n                np.conj(ref_stateB),\n            )\n\n        assert np.allclose(numer_state, ref_state, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""fock"")\nclass TestModeSubsets:\n    """"""Tests on mode subsets using the Fock basis representation.""""""\n\n    @pytest.mark.parametrize(""t"", T_VALUES)\n    @pytest.mark.parametrize(""mag_alpha"", MAG_ALPHAS[1:])\n    @pytest.mark.parametrize(""r_phi"", PHASE_R)\n    @pytest.mark.parametrize(""modes"", MODES)\n    def test_beamsplitter_on_mode_subset(\n            self, setup_backend, mag_alpha, t, r_phi, modes, cutoff, tol\n    ):\n        """"""Tests applying the beamsplitter on different mode subsets.""""""\n\n        phase_alpha = np.pi / 5\n        alpha = mag_alpha * np.exp(1j * phase_alpha)\n        r = np.exp(1j * r_phi) * np.sqrt(1.0 - np.abs(t) ** 2)\n\n        backend = setup_backend(4)\n\n        backend.displacement(alpha, modes[0])\n        backend.beamsplitter(t, r, *modes)\n        state = backend.state()\n\n        alpha_outA = t * alpha\n        alpha_outB = r * alpha\n\n        n = np.arange(cutoff)\n        ref_stateA = (\n            np.exp(-0.5 * np.abs(alpha_outA) ** 2)\n            * alpha_outA ** n\n            / np.sqrt(factorial(n))\n        )\n        ref_stateB = (\n            np.exp(-0.5 * np.abs(alpha_outB) ** 2)\n            * alpha_outB ** n\n            / np.sqrt(factorial(n))\n        )\n\n        numer_state = state.reduced_dm(list(modes))\n\n        ref_state = np.einsum(\n            ""i,j,k,l->ijkl"",\n            ref_stateA,\n            np.conj(ref_stateA),\n            ref_stateB,\n            np.conj(ref_stateB),\n        )\n\n        assert np.allclose(numer_state, ref_state, atol=tol, rtol=0)\n'"
tests/backend/test_displaced_squeezed_state_preparation.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""Unit tests for operations that prepare squeezed coherent states""""""\n\nimport pytest\n\nimport numpy as np\nfrom scipy.special import factorial\n\nMAG_ALPHAS = np.linspace(0.1, 0.5, 2)\nPHASE_ALPHAS = np.linspace(np.pi / 6, 2 * np.pi, 2, endpoint=False)\nSQZ_R = np.linspace(0.01, 0.1, 2)\nSQZ_PHI = np.linspace(np.pi / 3, 2 * np.pi, 2, endpoint=False)\n\n\ndef sech(x):\n    """"""Hyperbolic secant""""""\n    return 1 / np.cosh(x)\n\n\nclass TestRepresentationIndependent:\n    """"""Basic implementation-independent tests.""""""\n\n    @pytest.mark.parametrize(""phi"", SQZ_PHI)\n    def test_no_squeezing_no_displacement(self, setup_backend, phi, tol):\n        """"""Tests squeezing operation in the limiting case where the result should be a vacuum state.""""""\n        alpha = 0\n        r = 0\n\n        backend = setup_backend(1)\n        backend.prepare_displaced_squeezed_state(alpha, r, phi, 0)\n        assert np.all(backend.is_vacuum(tol))\n\n    @pytest.mark.parametrize(""mag_alpha"", MAG_ALPHAS)\n    @pytest.mark.parametrize(""phase_alpha"", PHASE_ALPHAS)\n    def test_displaced_squeezed_with_no_squeezing(\n        self, setup_backend, mag_alpha, phase_alpha, tol\n    ):\n        """"""Tests if a squeezed coherent state with no squeezing is equal to a coherent state.""""""\n        r = phi = 0\n        alpha = mag_alpha * np.exp(1j * phase_alpha)\n        backend = setup_backend(1)\n\n        backend.prepare_displaced_squeezed_state(alpha, r, phi, 0)\n        state = backend.state()\n        fidel = state.fidelity_coherent([alpha])\n        assert np.allclose(fidel, 1, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestFockRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    @pytest.mark.parametrize(""mag_alpha"", MAG_ALPHAS)\n    @pytest.mark.parametrize(""phase_alpha"", PHASE_ALPHAS)\n    @pytest.mark.parametrize(""r"", SQZ_R)\n    @pytest.mark.parametrize(""phi"", SQZ_PHI)\n    def test_normalized_displaced_squeezed_state(\n        self, setup_backend, mag_alpha, phase_alpha, r, phi, tol\n    ):\n        """"""Tests if a range of squeezed vacuum states are normalized.""""""\n        alpha = mag_alpha * np.exp(1j * phase_alpha)\n        backend = setup_backend(1)\n\n        backend.prepare_displaced_squeezed_state(alpha, r, phi, 0)\n        state = backend.state()\n        tr = state.trace()\n        assert np.allclose(tr, 1, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""r"", SQZ_R)\n    @pytest.mark.parametrize(""phi"", SQZ_PHI)\n    def test_displaced_squeezed_with_no_displacement(\n        self, setup_backend, r, phi, cutoff, batch_size, pure, tol\n    ):\n        """"""Tests if a squeezed coherent state with no displacement is equal to a squeezed state (Eq. (5.5.6) in Loudon).""""""\n        alpha = 0\n        backend = setup_backend(1)\n\n        backend.prepare_displaced_squeezed_state(alpha, r, phi, 0)\n        state = backend.state()\n\n        if state.is_pure:\n            num_state = state.ket()\n        else:\n            num_state = state.dm()\n\n        n = np.arange(0, cutoff, 2)\n        even_refs = (\n            np.sqrt(sech(r))\n            * np.sqrt(factorial(n))\n            / factorial(n / 2)\n            * (-0.5 * np.exp(1j * phi) * np.tanh(r)) ** (n / 2)\n        )\n\n        if batch_size is not None:\n            if pure:\n                even_entries = num_state[:, ::2]\n            else:\n                even_entries = num_state[:, ::2, ::2]\n                even_refs = np.outer(even_refs, np.conj(even_refs))\n        else:\n            if pure:\n                even_entries = num_state[::2]\n            else:\n                even_entries = num_state[::2, ::2]\n                even_refs = np.outer(even_refs, np.conj(even_refs))\n\n        assert np.allclose(even_entries, even_refs, atol=tol, rtol=0)\n'"
tests/backend/test_displacement_operation.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""\nUnit tests for displacement operations\nConvention: The displacement unitary is fixed to be\nU(\\alpha) = \\exp(alpha \\hat{a}^\\dagger - \\alpha^* \\hat{a})\nwhere \\hat{a}^\\dagger is the photon creation operator.\n""""""\n# pylint: disable=too-many-arguments\nimport pytest\n\nimport numpy as np\nfrom scipy.special import factorial as fac\n\n\nMAG_ALPHAS = np.linspace(0, 0.8, 4)\nPHASE_ALPHAS = np.linspace(0, 2 * np.pi, 7, endpoint=False)\n\n\nclass TestRepresentationIndependent:\n    """"""Basic implementation-independent tests.""""""\n\n    def test_no_displacement(self, setup_backend, tol):\n        """"""Tests displacement operation where the result should be a vacuum state.""""""\n        backend = setup_backend(1)\n        backend.displacement(0, 0)\n        assert np.all(backend.is_vacuum(tol))\n\n    @pytest.mark.parametrize(""r"", MAG_ALPHAS)\n    @pytest.mark.parametrize(""p"", PHASE_ALPHAS)\n    def test_fidelity_coherent(self, setup_backend, r, p, tol):\n        """"""Tests if a range of alpha-displaced states have the correct fidelity\n        with the corresponding coherent state.\n        """"""\n        alpha = r * np.exp(1j * p)\n\n        backend = setup_backend(1)\n        backend.displacement(alpha, 0)\n        state = backend.state()\n\n        fid = state.fidelity_coherent([alpha])\n        assert np.allclose(fid, 1, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestFockRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    @pytest.mark.parametrize(""r"", MAG_ALPHAS)\n    @pytest.mark.parametrize(""p"", PHASE_ALPHAS)\n    def test_normalized_displaced_state(self, setup_backend, r, p, tol):\n        """"""Tests if a range of displaced states are normalized.""""""\n        alpha = r * np.exp(1j * p)\n\n        backend = setup_backend(1)\n        backend.displacement(alpha, 0)\n        state = backend.state()\n\n        assert np.allclose(state.trace(), 1, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""r"", MAG_ALPHAS)\n    @pytest.mark.parametrize(""p"", PHASE_ALPHAS)\n    def test_coherent_state_fock_elements(self, setup_backend, r, p, cutoff, pure, tol):\n        r""""""Tests if a range of alpha-displaced states have the correct Fock basis elements:\n           |\\alpha> = exp(-0.5 |\\alpha|^2) \\sum_n \\alpha^n / \\sqrt{n!} |n>\n        """"""\n        alpha = r * np.exp(1j * p)\n\n        backend = setup_backend(1)\n        backend.displacement(alpha, 0)\n        state = backend.state()\n\n        if state.is_pure:\n            numer_state = state.ket()\n        else:\n            numer_state = state.dm()\n\n        n = np.arange(cutoff)\n        ref_state = np.exp(-0.5 * np.abs(alpha) ** 2) * alpha ** n / np.sqrt(fac(n))\n\n        if not pure:\n            ref_state = np.outer(ref_state, np.conj(ref_state))\n\n        assert np.allclose(numer_state, ref_state, atol=tol, rtol=0)\n'"
tests/backend/test_fock_measurement.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""Unit tests for measurements in the Fock basis""""""\nimport pytest\n\nimport numpy as np\n\n\nNUM_REPEATS = 50\n\n\n@pytest.mark.backends(""gaussian"")\nclass TestGaussianRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    def measure_fock_gaussian_warning(self, setup_backend):\n        """"""Tests that Fock measurements are not implemented when shots != 1.\n        Should be deleted when this functionality is implemented.""""""\n\n        backend = setup_backend(3)\n\n        with pytest.warns(Warning, match=""Cannot simulate non-Gaussian states. Conditional state after ""\n                                         ""Fock measurement has not been updated.""):\n            backend.measure_fock([0, 1], shots=5)\n\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestFockRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    def shots_not_implemented_fock(self, setup_backend):\n        """"""Tests that Fock measurements are not implemented when shots != 1.\n        Should be deleted when this functionality is implemented.""""""\n\n        backend = setup_backend(3)\n\n        with pytest.raises(NotImplementedError, match=""{} backend currently does not support ""\n                                                      ""shots != 1 for Fock measurement"".format(backend.short_name)):\n            backend.measure_fock([0, 1], shots=5)\n\n        with pytest.raises(NotImplementedError, match=""{} backend currently does not support ""\n                                                      ""shots != 1 for Fock measurement"".format(backend.short_name)):\n            backend.measure_fock([0, 1], shots=-5)\n\n    def shots_not_implemented_homodyne(self, setup_backend):\n        """"""Tests that homodyne measurements are not implemented when shots != 1.\n        Should be deleted when this functionality is implemented.""""""\n\n        backend = setup_backend(3)\n\n        with pytest.raises(NotImplementedError, match=""{} backend currently does not support ""\n                                                      ""shots != 1 for homodyne measurement"".format(backend.short_name)):\n            backend.measure_homodyne([0, 1], shots=5)\n\n        with pytest.raises(NotImplementedError, match=""{} backend currently does not support ""\n                                                      ""shots != 1 for homodyne measurement"".format(backend.short_name)):\n            backend.measure_homodyne([0, 1], shots=-5)\n\n    def test_normalized_conditional_states(self, setup_backend, cutoff, pure, tol):\n        """"""Tests if the conditional states resulting from Fock measurements in a subset of modes are normalized.""""""\n        state_preps = [n for n in range(cutoff)] + [\n            cutoff - n for n in range(cutoff)\n        ]  # [0, 1, 2, ..., cutoff-1, cutoff, cutoff-1, ..., 2, 1]\n        backend = setup_backend(3)\n\n        for idx in range(NUM_REPEATS):\n            backend.reset(pure=pure)\n\n            # cycles through consecutive triples in `state_preps`\n            backend.prepare_fock_state(state_preps[idx % cutoff], 0)\n            backend.prepare_fock_state(state_preps[(idx + 1) % cutoff], 1)\n            backend.prepare_fock_state(state_preps[(idx + 2) % cutoff], 2)\n\n            for mode in range(3):\n                backend.measure_fock([mode])\n                state = backend.state()\n                tr = state.trace()\n                assert np.allclose(tr, 1, atol=tol, rtol=0)\n\n    def test_fock_measurements(self, setup_backend, cutoff, batch_size, pure, tol):\n        """"""Tests if Fock measurements results on a variety of multi-mode Fock states are correct.""""""\n        state_preps = [n for n in range(cutoff)] + [\n            cutoff - n for n in range(cutoff)\n        ]  # [0, 1, 2, ..., cutoff-1, cutoff, cutoff-1, ..., 2, 1]\n\n        singletons = [(0,), (1,), (2,)]\n        pairs = [(0, 1), (0, 2), (1, 2)]\n        triples = [(0, 1, 2)]\n        mode_choices = singletons + pairs + triples\n\n        backend = setup_backend(3)\n\n        for idx in range(NUM_REPEATS):\n            backend.reset(pure=pure)\n\n            n = [\n                state_preps[idx % cutoff],\n                state_preps[(idx + 1) % cutoff],\n                state_preps[(idx + 2) % cutoff],\n            ]\n            n = np.array(n)\n            meas_modes = np.array(\n                mode_choices[idx % len(mode_choices)]\n            )  # cycle through mode choices\n\n            backend.prepare_fock_state(n[0], 0)\n            backend.prepare_fock_state(n[1], 1)\n            backend.prepare_fock_state(n[2], 2)\n\n            meas_result = backend.measure_fock(meas_modes)\n            ref_result = n[meas_modes]\n\n            if batch_size is not None:\n                ref_result = tuple(np.array([i] * batch_size) for i in ref_result)\n\n            assert np.allclose(meas_result, ref_result, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""fock"", ""tf"", ""gaussian"")\nclass TestRepresentationIndependent:\n    """"""Basic implementation-independent tests.""""""\n\n    def test_two_mode_squeezed_measurements(self, setup_backend, pure):\n        """"""Tests Fock measurement on the two mode squeezed vacuum state.""""""\n        for _ in range(NUM_REPEATS):\n            backend = setup_backend(2)\n            backend.reset(pure=pure)\n\n            r = 0.25\n            # Circuit to prepare two mode squeezed vacuum\n            backend.squeeze(-r, 0)\n            backend.squeeze(r, 1)\n            backend.beamsplitter(np.sqrt(0.5), -np.sqrt(0.5), 0, 1)\n            meas_modes = [0, 1]\n            meas_results = backend.measure_fock(meas_modes)\n            assert np.all(meas_results[0] == meas_results[1])\n\n    def test_vacuum_measurements(self, setup_backend, pure):\n        """"""Tests Fock measurement on the vacuum state.""""""\n        backend = setup_backend(3)\n\n        for _ in range(NUM_REPEATS):\n            backend.reset(pure=pure)\n\n            meas = backend.measure_fock([0, 1, 2])[0]\n            assert np.all(np.array(meas) == 0)\n\n\n    def test_coherent_state_has_photons(self, setup_backend, pure):\n        """"""Test that a coherent state with a mean photon number of 4 and sampled NUM_REPEATS times will produce photons""""""\n        backend = setup_backend(1)\n        alpha = 2.0\n        meas = np.array(backend.measure_fock([0]))\n\n        for _ in range(NUM_REPEATS):\n            backend.reset(pure=pure)\n            backend.displacement(alpha, 0)\n            meas += backend.measure_fock([0])\n        assert np.all(meas > 0)\n\n\n'"
tests/backend/test_heterodyne.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for heterodyne measurements.""""""\nimport pytest\n\nimport numpy as np\n\nmag_alphas = np.linspace(0, 0.8, 4)\nphase_alphas = np.linspace(0, 2 * np.pi, 7, endpoint=False)\nsqueeze_val = np.arcsinh(1.0)\n\nn_meas = 300\ndisp_val = 1.0 + 1j * 1.0\nnum_stds = 10.0\nstd_10 = num_stds / np.sqrt(n_meas)\n\n\n@pytest.mark.backends(""gaussian"")\nclass TestHeterodyne:\n    """"""Basic implementation-independent tests.""""""\n\n    def test_mode_reset_vacuum(self, setup_backend, tol):\n        """"""Test heterodyne measurement resets mode to vacuum""""""\n        backend = setup_backend(1)\n        backend.squeeze(squeeze_val, 0)\n        backend.displacement(mag_alphas[-1], 0)\n        backend.measure_homodyne(0, 0)\n        assert np.all(backend.is_vacuum(tol))\n\n    def test_mean_vacuum(self, setup_backend, pure, tol):\n        """"""Test heterodyne provides the correct vacuum mean""""""\n        backend = setup_backend(1)\n        x = np.empty(0)\n\n        for i in range(n_meas):\n            backend.reset(pure=pure)\n            meas_result = backend.measure_heterodyne(0)\n            x = np.append(x, meas_result)\n\n        mean_diff = np.abs(x.mean() - 0)\n\n        assert np.allclose(x.mean(), 0.0, atol=std_10 + tol, rtol=0)\n\n    def test_mean_coherent(self, setup_backend, pure, tol):\n        """"""Test heterodyne provides the correct coherent mean alpha""""""\n        backend = setup_backend(1)\n        x = np.empty(0)\n\n        for i in range(n_meas):\n            backend.reset(pure=pure)\n            backend.prepare_coherent_state(disp_val, 0)\n            meas_result = backend.measure_heterodyne(0)\n            x = np.append(x, meas_result)\n\n        assert np.allclose(x.mean(), disp_val, atol=std_10 + tol, rtol=0)\n\n    def test_std_vacuum(self, setup_backend, pure, tol):\n        """"""Test heterodyne provides the correct standard deviation of the vacuum""""""\n        backend = setup_backend(1)\n        x = np.empty(0)\n\n        for i in range(n_meas):\n            backend.reset(pure=pure)\n            meas_result = backend.measure_heterodyne(0)\n            x = np.append(x, meas_result)\n\n        xr = x.real\n        xi = x.imag\n        xvar = xi.std() ** 2 + xr.std() ** 2\n\n        assert np.allclose(np.sqrt(xvar), np.sqrt(0.5), atol=std_10 + tol, rtol=0)\n'"
tests/backend/test_homodyne.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""Unit tests for homodyne measurements.""""""\nimport numpy as np\n\n\nN_MEAS = 300  # number of homodyne measurements to perform\nNUM_STDS = 10.0\nstd_10 = NUM_STDS / np.sqrt(N_MEAS)\n\n\nclass TestRepresentationIndependent:\n    """"""Basic implementation-independent tests.""""""\n\n    def test_mode_reset_vacuum(self, setup_backend, tol):\n        """"""Tests that modes get reset to the vacuum after measurement.""""""\n        backend = setup_backend(1)\n\n        r = np.arcsinh(1.0)  # pylint: disable=assignment-from-no-return\n        alpha = 0.8\n\n        backend.squeeze(r, 0)\n        backend.displacement(alpha, 0)\n        backend.measure_homodyne(0, 0)\n\n        assert np.all(backend.is_vacuum(tol))\n\n    def test_mean_and_std_vacuum(self, setup_backend, pure, tol):\n        """"""Tests that the mean and standard deviation estimates of many homodyne\n        measurements are in agreement with the expected values for the\n        vacuum state""""""\n        x = np.empty(0)\n\n        backend = setup_backend(1)\n\n        for _ in range(N_MEAS):\n            backend.reset(pure=pure)\n            meas_result = backend.measure_homodyne(0, 0)\n            x = np.append(x, meas_result)\n\n        assert np.allclose(x.mean(), 0.0, atol=std_10 + tol, rtol=0)\n        assert np.allclose(x.std(), 1.0, atol=std_10 + tol, rtol=0)\n\n    def test_mean_coherent(self, setup_backend, pure, tol):\n        """"""Tests that the mean and standard deviation estimates of many homodyne\n        measurements are in agreement with the expected values for a\n        coherent state""""""\n        alpha = 1.0 + 1.0j\n        x = np.empty(0)\n\n        backend = setup_backend(1)\n\n        for _ in range(N_MEAS):\n            backend.reset(pure=pure)\n            backend.prepare_coherent_state(alpha, 0)\n\n            meas_result = backend.measure_homodyne(0, 0)\n            x = np.append(x, meas_result)\n\n        assert np.allclose(x.mean(), 2 * alpha.real, atol=std_10 + tol)\n'"
tests/backend/test_is_vacuum.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nUnit tests for the is_vacuum() check.\n""""""\n\nimport pytest\n\nimport numpy as np\n\n\nMAG_ALPHAS = np.linspace(0, 0.8, 3)\n\nclass TestIsVacuum:\n    """"""Common tests for all the backends.""""""\n    @pytest.mark.parametrize(""r"", MAG_ALPHAS)\n    def test_coherent_state(self, setup_backend, r, tol):\n        """"""Tests if a range of displaced states are within the expected tolerance from vacuum.\n        """"""\n        # fidelity of the displaced state with |0>\n        fid = np.exp(-np.abs(r)**2)\n        # expected tolerance limit for the test\n        lim = np.abs(fid-1)\n\n        backend = setup_backend(1)\n        backend.displacement(r, 0)\n        assert not np.any(backend.is_vacuum(lim-tol))\n        assert np.all(backend.is_vacuum(lim+tol))\n'"
tests/backend/test_loss_channel.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""Unit tests for the loss channel\nConvention: The loss channel N(T) has the action\nN(T){|n><m|} = \\sum_{l=0}^{min(m,n)} ((1-T)/T) ^ l * T^((n+m)/2) / l! * \\sqrt(n!m!/((n-l)!(m-l)!))n-l><m-l|\n""""""\n\n\nimport pytest\n\nimport numpy as np\nfrom scipy.special import factorial\n\nLOSS_TS = np.linspace(0.0, 1.0, 3, endpoint=True)\nMAG_ALPHAS = np.linspace(0, 0.75, 3)\nPHASE_ALPHAS = np.linspace(0, 2 * np.pi, 3, endpoint=False)\nMAX_FOCK = 5\n\n\nclass TestRepresentationIndependent:\n    """"""Basic implementation-independent tests.""""""\n\n    @pytest.mark.parametrize(""T"", LOSS_TS)\n    def test_loss_channel_on_vacuum(self, setup_backend, T, tol):\n        """"""Tests loss channels on vacuum (result should be vacuum).""""""\n\n        backend = setup_backend(1)\n\n        backend.loss(T, 0)\n        assert np.all(backend.is_vacuum(tol))\n\n    @pytest.mark.parametrize(""mag_alpha"", MAG_ALPHAS)\n    @pytest.mark.parametrize(""phase_alpha"", PHASE_ALPHAS)\n    def test_full_loss_channel_on_coherent_states(\n        self, setup_backend, mag_alpha, phase_alpha, tol\n    ):\n        """"""Tests the full-loss channel on various states (result should be vacuum).""""""\n\n        T = 0.0\n        alpha = mag_alpha * np.exp(1j * phase_alpha)\n\n        backend = setup_backend(1)\n        backend.displacement(alpha, 0)\n        backend.loss(T, 0)\n        assert np.all(backend.is_vacuum(tol))\n\n\n# at the moment the Fock backends don\'t support\n# thermal loss channels.\n@pytest.mark.backends(""gaussian"")\nclass TestThermalLossChannel:\n    """"""Tests that make use of the Gaussian representation to test\n    thermal loss channels.""""""\n\n    @pytest.mark.parametrize(""T"", LOSS_TS)\n    def test_thermal_loss_channel_with_vacuum(self, T, setup_backend, pure, tol):\n        """"""Tests thermal loss channel with nbar=0 (should be same as loss channel).""""""\n        backend = setup_backend(1)\n        z = 0.432 * np.exp(1j * 0.534)\n        alpha = 0.654 + 1j * 0.239\n        nbar = 0.0\n\n        backend.squeeze(z, 0)\n        backend.displacement(alpha, 0)\n        backend.loss(T, 0)\n        state1 = backend.state()\n\n        backend.reset(pure=pure)\n        backend.squeeze(z, 0)\n        backend.displacement(alpha, 0)\n        backend.thermal_loss(T, nbar, 0)\n        state2 = backend.state()\n\n        assert np.allclose(state1.means(), state2.means(), atol=tol, rtol=0)\n        assert np.allclose(state1.cov(), state2.cov(), atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""nbar"", MAG_ALPHAS)\n    def test_full_thermal_loss_channel(self, nbar, setup_backend, pure, tol):\n        """"""Tests thermal loss channel with T=0 (should produce a thermal state).""""""\n        backend = setup_backend(1)\n        z = 0.432 * np.exp(1j * 0.534)\n        alpha = 0.654 + 1j * 0.239\n        T = 0\n\n        backend.prepare_thermal_state(nbar, 0)\n        state1 = backend.state()\n\n        backend.reset(pure=pure)\n        backend.squeeze(z, 0)\n        backend.displacement(alpha, 0)\n        backend.thermal_loss(T, nbar, 0)\n        state2 = backend.state()\n\n        assert np.allclose(state1.means(), state2.means(), atol=tol, rtol=0)\n        assert np.allclose(state1.cov(), state2.cov(), atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""T"", LOSS_TS)\n    @pytest.mark.parametrize(""nbar"", MAG_ALPHAS)\n    def test_thermal_loss_channel_on_squeezed_state(\n        self, nbar, T, setup_backend, pure, tol, hbar\n    ):\n        """"""Tests thermal loss channel on a squeezed state""""""\n        backend = setup_backend(1)\n        r = 0.432\n        backend.squeeze(r, 0)\n        backend.thermal_loss(T, nbar, 0)\n        state = backend.state()\n\n        res = state.cov()\n        exp = np.diag(\n            [\n                T * np.exp(-2 * r) + (1 - T) * (2 * nbar + 1),\n                T * np.exp(2 * r) + (1 - T) * (2 * nbar + 1),\n            ]\n        )*hbar/2\n\n        print(res, exp)\n\n        assert np.allclose(res, exp, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestFockRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    @pytest.mark.parametrize(""T"", LOSS_TS)\n    @pytest.mark.parametrize(""mag_alpha"", MAG_ALPHAS)\n    @pytest.mark.parametrize(""phase_alpha"", PHASE_ALPHAS)\n    def test_normalized_after_loss_channel_on_coherent_state(\n        self, setup_backend, T, mag_alpha, phase_alpha, tol\n    ):\n        """"""Tests if a range of loss states are normalized.""""""\n        alpha = mag_alpha * np.exp(1j * phase_alpha)\n        backend = setup_backend(1)\n\n        backend.prepare_coherent_state(alpha, 0)\n        backend.loss(T, 0)\n        state = backend.state()\n        tr = state.trace()\n        assert np.allclose(tr, 1.0, atol=tol, rtol=0.0)\n\n    @pytest.mark.parametrize(""T"", LOSS_TS)\n    @pytest.mark.parametrize(""n"", range(MAX_FOCK))\n    def test_normalized_after_loss_channel_on_fock_state(\n        self, setup_backend, T, n, tol\n    ):\n        """"""Tests if a range of loss states are normalized.""""""\n\n        backend = setup_backend(1)\n\n        backend.prepare_fock_state(n, 0)\n        backend.loss(T, 0)\n        state = backend.state()\n        tr = state.trace()\n        assert np.allclose(tr, 1.0, atol=tol, rtol=0.0)\n\n    @pytest.mark.parametrize(""n"", range(MAX_FOCK))\n    def test_full_loss_channel_on_fock_states(self, setup_backend, n, tol):\n        """"""Tests the full-loss channel on various states (result should be vacuum).""""""\n\n        T = 0.0\n        backend = setup_backend(1)\n\n        backend.prepare_fock_state(n, 0)\n        backend.loss(T, 0)\n        assert np.all(backend.is_vacuum(tol))\n\n    @pytest.mark.parametrize(""T"", LOSS_TS)\n    @pytest.mark.parametrize(""mag_alpha"", MAG_ALPHAS)\n    @pytest.mark.parametrize(""phase_alpha"", PHASE_ALPHAS)\n    def test_loss_channel_on_coherent_states(\n        self, setup_backend, T, mag_alpha, phase_alpha, cutoff, tol\n    ):\n        """"""Tests various loss channels on coherent states (result should be coherent state with amplitude weighted by sqrt(T).""""""\n\n        alpha = mag_alpha * np.exp(1j * phase_alpha)\n\n        rootT_alpha = np.sqrt(T) * alpha\n\n        backend = setup_backend(1)\n\n        backend.prepare_coherent_state(alpha, 0)\n        backend.loss(T, 0)\n        s = backend.state()\n        if s.is_pure:\n            numer_state = s.ket()\n        else:\n            numer_state = s.dm()\n        n = np.arange(cutoff)\n        ref_state = (\n            np.exp(-0.5 * np.abs(rootT_alpha) ** 2)\n            * rootT_alpha ** n\n            / np.sqrt(factorial(n))\n        )\n        ref_state = np.outer(ref_state, np.conj(ref_state))\n        assert np.allclose(numer_state, ref_state, atol=tol, rtol=0.0)\n'"
tests/backend/test_modes.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""Unit tests for add_mode and del_mode functions""""""\nimport pytest\n\nimport numpy as np\n\nNUM_REPEATS = 10\n\n\nclass TestRepresentationIndependent:\n    """"""Basic implementation-independent tests.""""""\n\n    def test_add_mode_vacuum(self, setup_backend, tol):\n        """"""Tests if added modes are initialized to the vacuum state.""""""\n        backend = setup_backend(1)\n\n        for _n in range(4):\n            backend.add_mode(1)\n            assert np.all(backend.is_vacuum(tol))\n\n    def test_del_mode_vacuum(self, setup_backend, tol):\n        """"""Tests if reduced density matrix is in vacuum after deleting some modes.""""""\n        backend = setup_backend(4)\n\n        for n in range(4):\n            backend.del_mode([n])\n            assert np.all(backend.is_vacuum(tol))\n\n    def test_get_modes(self, setup_backend):\n        """"""Tests that get modes returns the correct result after deleting modes from the circuit""""""\n        backend = setup_backend(4)\n\n        backend.squeeze(0.1, 0)\n        backend.del_mode([0, 2])\n\n        res = backend.get_modes()\n        assert np.all(res == [1, 3])\n\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestFockRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    def test_normalized_add_mode(self, setup_backend, tol):\n        """"""Tests if a state is normalized after adding modes.""""""\n        backend = setup_backend(1)\n\n        for num_subsystems in range(3):\n            backend.add_mode(num_subsystems)\n            state = backend.state()\n            tr = state.trace()\n            assert np.allclose(tr, 1.0, atol=tol, rtol=0.0)\n\n    def test_normalized_del_mode(self, setup_backend, tol):\n        """"""Tests if a state is normalized after deleting modes.""""""\n        backend = setup_backend(4)\n\n        for n in range(4):\n            backend.del_mode(n)\n            state = backend.state()\n            tr = state.trace()\n            assert np.allclose(tr, 1.0, atol=tol, rtol=0.0)\n\n    def test_fock_measurements_after_add_mode(self, setup_backend, pure, cutoff):\n        """"""Tests Fock measurements on a system after adding vacuum modes.""""""\n        backend = setup_backend(1)\n\n        for m in range(3):\n            meas_results = []\n\n            for _ in range(NUM_REPEATS):\n                backend.reset(pure=pure)\n                backend.prepare_fock_state(cutoff - 1, 0)\n                backend.add_mode(m)\n\n                meas_result = backend.measure_fock([0])\n                meas_results.append(meas_result)\n\n            assert np.all(np.array(meas_results) == cutoff - 1)\n\n    def test_fock_measurements_after_del_mode(self, setup_backend, pure, cutoff):\n        """"""Tests Fock measurements on a system after tracing out an unentagled mode.""""""\n        backend = setup_backend(4)\n\n        for m in range(1, 4):\n            meas_results = []\n\n            for _ in range(NUM_REPEATS):\n                backend.reset(pure=pure)\n                backend.prepare_fock_state(cutoff - 1, 0)\n                backend.del_mode(m)\n\n                meas_result = backend.measure_fock([0])\n                meas_results.append(meas_result)\n\n            assert np.all(np.array(meas_results) == cutoff - 1)\n'"
tests/backend/test_multimode_state_preparations.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr"""""" Tests for various multi mode state preparation operations""""""\nimport itertools\n\nimport pytest\n\nimport numpy as np\n\nfrom strawberryfields import ops\nfrom strawberryfields.backends.gaussianbackend.states import GaussianState\nfrom strawberryfields.utils import random_covariance, displaced_squeezed_state\n\n# make test deterministic\nnp.random.seed(42)\n\n\nMAG_ALPHAS = np.linspace(0, 0.8, 3)\nPHASE_ALPHAS = np.linspace(0, 2 * np.pi, 3, endpoint=False)\nNBARS = np.linspace(0, 5)\n\n\n@pytest.mark.backends(""tf"", ""fock"")\nclass TestFockBasisMultimode:\n    """"""Testing preparing multimode states on the Fock backends""""""\n\n    def test_multimode_ket_mode_permutations(self, setup_backend, pure, cutoff, tol):\n        """"""Test multimode ket preparation when modes are permuted""""""\n        backend = setup_backend(4)\n\n        random_ket0 = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(\n            -1, 1, cutoff\n        )\n        random_ket0 = random_ket0 / np.linalg.norm(random_ket0)\n\n        random_ket1 = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(\n            -1, 1, cutoff\n        )\n        random_ket1 = random_ket1 / np.linalg.norm(random_ket1)\n\n        random_ket = np.outer(random_ket0, random_ket1)\n        rho = np.einsum(""ij,kl->ikjl"", random_ket, random_ket.conj())\n\n        backend.prepare_ket_state(random_ket, modes=[3, 1])\n        state = backend.state([3, 1])\n        multi_mode_preparation_dm = state.dm()\n\n        assert np.allclose(multi_mode_preparation_dm, rho, atol=tol, rtol=0)\n\n    def test_compare_single_mode_and_multimode_ket_preparation(\n        self, setup_backend, batch_size, pure, cutoff, tol\n    ):\n        """"""Test single and multimode ket preparation""""""\n        backend = setup_backend(4)\n\n        random_ket0 = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(\n            -1, 1, cutoff\n        )\n        random_ket0 = random_ket0 / np.linalg.norm(random_ket0)\n\n        random_ket1 = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(\n            -1, 1, cutoff\n        )\n        random_ket1 = random_ket1 / np.linalg.norm(random_ket1)\n\n        random_ket = np.outer(random_ket0, random_ket1)\n\n        backend.prepare_ket_state(random_ket0, 0)\n        backend.prepare_ket_state(random_ket1, 1)\n        state = backend.state([0, 1])\n        single_mode_preparation_dm = state.dm()\n        single_mode_preparation_probs = np.array(state.all_fock_probs())\n\n        backend.reset(pure=pure)\n        backend.prepare_ket_state(random_ket, [0, 1])\n        state = backend.state([0, 1])\n        multi_mode_preparation_dm = state.dm()\n        multi_mode_preparation_probs = np.array(state.all_fock_probs())\n\n        assert np.allclose(\n            single_mode_preparation_dm, multi_mode_preparation_dm, atol=tol, rtol=0\n        )\n        assert np.allclose(\n            single_mode_preparation_probs,\n            multi_mode_preparation_probs,\n            atol=tol,\n            rtol=0,\n        )\n\n        if batch_size is not None:\n            single_mode_preparation_dm = single_mode_preparation_dm[0]\n            multi_mode_preparation_dm = multi_mode_preparation_dm[0]\n\n        assert np.all(\n            single_mode_preparation_dm.shape == multi_mode_preparation_dm.shape\n        )\n\n    def test_compare_single_mode_and_multimode_dm_preparation(\n        self, setup_backend, batch_size, pure, cutoff, tol\n    ):\n        """"""Compare the results of a successive single mode preparations\n        and a multi mode preparation of a product state.""""""\n        backend = setup_backend(4)\n        random_rho0 = np.random.normal(size=[cutoff] * 2) + 1j * np.random.normal(\n            size=[cutoff] * 2\n        )\n        random_rho0 = np.dot(random_rho0.conj().T, random_rho0)\n        random_rho0 = random_rho0 / random_rho0.trace()\n\n        random_rho1 = np.random.normal(size=[cutoff] * 2) + 1j * np.random.normal(\n            size=[cutoff] * 2\n        )\n        random_rho1 = np.dot(random_rho1.conj().T, random_rho1)\n        random_rho1 = random_rho1 / random_rho1.trace()\n        random_dm = np.outer(random_rho0, random_rho1)\n        random_dm = random_dm.reshape([cutoff] * 4)\n\n        backend.prepare_dm_state(random_rho0, 0)\n        backend.prepare_dm_state(random_rho1, 1)\n        state = backend.state([0, 1])\n        single_mode_preparation_dm = state.dm()\n        single_mode_preparation_probs = np.array(state.all_fock_probs())\n\n        # first we do a preparation from random_dm, with shape [cutoff]*4\n        backend.reset(pure=pure)\n        backend.prepare_dm_state(random_dm, [0, 1])\n        state = backend.state(modes=[0, 1])\n        multi_mode_preparation_dm = state.dm()\n        multi_mode_preparation_probs = np.array(state.all_fock_probs())\n\n        # second we do a preparation from the corresponding matrix with shape [cutoff**2]*2\n        backend.reset(pure=pure)\n        backend.prepare_dm_state(random_dm.reshape([cutoff ** 2] * 2), [0, 1])\n        state = backend.state(modes=[0, 1])\n        multi_mode_preparation_from_matrix_dm = state.dm()\n        multi_mode_preparation_from_matrix_probs = np.array(state.all_fock_probs())\n\n        # third we do a preparation from random_dm on modes 3 and 1 (in that order!) and test if the states end up in the correct modes\n        backend.reset(pure=pure)\n        backend.prepare_dm_state(random_dm, [3, 1])\n\n        multi_mode_preparation_31_mode_0 = backend.state(modes=0).dm()\n        multi_mode_preparation_31_mode_1 = backend.state(modes=1).dm()\n        multi_mode_preparation_31_mode_2 = backend.state(modes=2).dm()\n        multi_mode_preparation_31_mode_3 = backend.state(modes=3).dm()\n        multi_mode_preparation_31_probs = np.array(\n            backend.state(modes=[3, 1]).all_fock_probs()\n        )\n\n        single_mode_vac = np.zeros((cutoff, cutoff), dtype=np.complex128)\n        single_mode_vac.itemset(0, 1.0 + 0.0j)\n\n        assert np.allclose(random_dm, single_mode_preparation_dm, atol=tol, rtol=0)\n        assert np.allclose(\n            multi_mode_preparation_dm, single_mode_preparation_dm, atol=tol, rtol=0\n        )\n        assert np.allclose(\n            multi_mode_preparation_from_matrix_dm,\n            single_mode_preparation_dm,\n            atol=tol,\n            rtol=0,\n        )\n\n        assert np.allclose(\n            multi_mode_preparation_31_mode_0, single_mode_vac, atol=tol, rtol=0\n        )\n        assert np.allclose(\n            multi_mode_preparation_31_mode_1, random_rho1, atol=tol, rtol=0\n        )\n        assert np.allclose(\n            multi_mode_preparation_31_mode_2, single_mode_vac, atol=tol, rtol=0\n        )\n        assert np.allclose(\n            multi_mode_preparation_31_mode_3, random_rho0, atol=tol, rtol=0\n        )\n\n        # also check the fock probabilities to catch errors in both the preparation and state() the would cancel each other out\n        assert np.allclose(\n            single_mode_preparation_probs,\n            multi_mode_preparation_probs,\n            atol=tol,\n            rtol=0,\n        )\n        assert np.allclose(\n            single_mode_preparation_probs,\n            multi_mode_preparation_from_matrix_probs,\n            atol=tol,\n            rtol=0,\n        )\n        assert np.allclose(\n            single_mode_preparation_probs,\n            multi_mode_preparation_31_probs,\n            atol=tol,\n            rtol=0,\n        )\n\n        if batch_size is not None:\n            single_mode_preparation_dm = single_mode_preparation_dm[0]\n            multi_mode_preparation_dm = multi_mode_preparation_dm[0]\n            multi_mode_preparation_from_matrix_dm = multi_mode_preparation_from_matrix_dm[\n                0\n            ]\n\n        assert np.all(random_dm.shape == single_mode_preparation_dm.shape)\n        assert np.all(random_dm.shape == multi_mode_preparation_dm.shape)\n        assert np.all(random_dm.shape == multi_mode_preparation_from_matrix_dm.shape)\n\n    def test_prepare_multimode_random_product_dm_state_on_different_modes(\n        self, setup_backend, batch_size, pure, cutoff, tol\n    ):\n        """"""Tests if a random multi mode dm state is correctly prepared on different modes.""""""\n        backend = setup_backend(4)\n        N = 4\n\n        random_rho = np.random.normal(size=[cutoff ** 2] * 2) + 1j * np.random.normal(\n            size=[cutoff ** 2] * 2\n        )  # two mode random state\n        random_rho = np.dot(random_rho.conj().T, random_rho)\n        random_rho = random_rho / random_rho.trace()\n        random_rho = random_rho.reshape(\n            [cutoff] * 4\n        )  # reshape for easier comparison later\n\n        # test the state preparation on the first two modes\n        backend.prepare_dm_state(random_rho, [0, 1])\n        multi_mode_preparation_with_modes_ordered = backend.state([0, 1]).dm()\n        assert np.allclose(\n            multi_mode_preparation_with_modes_ordered, random_rho, atol=tol, rtol=0\n        )\n\n        # test the state preparation on two other modes that are not in order\n        backend.reset(pure=pure)\n        backend.prepare_dm_state(random_rho, [1, 2])\n        multi_mode_preparation_with_modes_inverted = backend.state([1, 2]).dm()\n        assert np.allclose(\n            multi_mode_preparation_with_modes_inverted, random_rho, atol=tol, rtol=0\n        )\n\n        # test various subsets of subsystems in various orders\n        for subsystems in list(itertools.permutations(range(N), 2)):\n            subsystems = list(subsystems)\n            backend.reset(pure=pure)\n            backend.prepare_dm_state(random_rho, subsystems)\n            dm = backend.state(modes=subsystems).dm()\n\n            assert np.allclose(random_rho, dm, atol=tol, rtol=0)\n            if batch_size is not None:\n                dm = dm[0]\n\n            assert np.all(random_rho.shape == dm.shape)\n\n    def test_fast_state_prep_on_all_modes(\n        self, setup_backend, batch_size, pure, cutoff, tol\n    ):\n        """"""Tests if a random multi mode ket state is correctly prepared with\n        the shortcut method on all modes.""""""\n        backend = setup_backend(4)\n        N = 4\n        random_ket = np.random.normal(size=[cutoff] * N) + 1j * np.random.normal(\n            size=[cutoff] * N\n        )\n        random_ket = random_ket / np.linalg.norm(random_ket)\n\n        backend.prepare_dm_state(random_ket, modes=range(N))\n        all_mode_preparation_ket = (\n            backend.state().ket()\n        )  # Returns None if the state if mixed\n\n        assert np.allclose(all_mode_preparation_ket, random_ket, atol=tol, rtol=0)\n\n        if batch_size is not None:\n            all_mode_preparation_ket = all_mode_preparation_ket[0]\n\n        assert np.all(all_mode_preparation_ket.shape == random_ket.shape)\n\n\n@pytest.mark.backends(""gaussian"")\nclass TestGaussianMultimode:\n    """"""Tests for simulators that use the Gaussian representation.""""""\n\n    def test_singlemode_gaussian_state(self, setup_backend, batch_size, pure, tol, hbar):\n        """"""Test single mode Gaussian state preparation""""""\n        N = 4\n        backend = setup_backend(N)\n\n        means = 2 * np.random.random(size=[2]) - 1\n        cov = random_covariance(1, pure=pure)\n\n        a = 0.2 + 0.4j\n        r = 1\n        phi = 0\n\n        # circuit is initially in displaced squeezed state\n        for i in range(N):\n            backend.prepare_displaced_squeezed_state(a, r, phi, mode=i)\n\n        # prepare Gaussian state in mode 1\n        backend.prepare_gaussian_state(means, cov, modes=1)\n\n        # test Gaussian state is correct\n        state = backend.state([1])\n        assert np.allclose(state.means(), means*np.sqrt(hbar/2), atol=tol, rtol=0)\n        assert np.allclose(state.cov(), cov*hbar/2, atol=tol, rtol=0)\n\n        # test that displaced squeezed states are unchanged\n        ex_means, ex_V = displaced_squeezed_state(a, r, phi, basis=""gaussian"", hbar=hbar)\n        for i in [0, 2, 3]:\n            state = backend.state([i])\n            assert np.allclose(state.means(), ex_means, atol=tol, rtol=0)\n            assert np.allclose(state.cov(), ex_V, atol=tol, rtol=0)\n\n    def test_multimode_gaussian_state(self, setup_backend, batch_size, pure, tol, hbar):\n        """"""Test multimode Gaussian state preparation""""""\n        N = 4\n        backend = setup_backend(N)\n\n        cov = np.diag(np.exp(2 * np.array([-1, -1, 1, 1])))\n        means = np.zeros([4])\n\n        # prepare displaced squeezed states in all modes\n        a = 0.2 + 0.4j\n        r = 0.5\n        phi = 0.12\n        for i in range(N):\n            backend.prepare_displaced_squeezed_state(a, r, phi, i)\n\n        # prepare new squeezed displaced state in mode 1 and 3\n        backend.prepare_gaussian_state(means, cov, modes=[1, 3])\n        state = backend.state([1, 3])\n\n        # test Gaussian state is correct\n        state = backend.state([1, 3])\n        assert np.allclose(state.means(), means*np.sqrt(hbar/2), atol=tol, rtol=0)\n        assert np.allclose(state.cov(), cov*hbar/2, atol=tol, rtol=0)\n\n        # test that displaced squeezed states are unchanged\n        ex_means, ex_V = displaced_squeezed_state(a, r, phi, basis=""gaussian"", hbar=hbar)\n        for i in [0, 2]:\n            state = backend.state([i])\n            assert np.allclose(state.means(), ex_means, atol=tol, rtol=0)\n            assert np.allclose(state.cov(), ex_V, atol=tol, rtol=0)\n\n    def test_full_mode_squeezed_state(self, setup_backend, batch_size, pure, tol, hbar):\n        """"""Test full register Gaussian state preparation""""""\n        N = 4\n        backend = setup_backend(N)\n\n        cov = np.diag(np.exp(2 * np.array([-1, -1, -1, -1, 1, 1, 1, 1])))\n        means = np.zeros([8])\n\n        backend.reset(pure=pure)\n        backend.prepare_gaussian_state(means, cov, modes=range(N))\n        state = backend.state()\n\n        # test Gaussian state is correct\n        state = backend.state()\n        assert np.allclose(state.means(), means*np.sqrt(hbar/2), atol=tol, rtol=0)\n        assert np.allclose(state.cov(), cov*hbar/2, atol=tol, rtol=0)\n\n    def test_multimode_gaussian_random_state(\n        self, setup_backend, batch_size, pure, tol, hbar\n    ):\n        """"""Test multimode Gaussian state preparation on a random state""""""\n        N = 4\n        backend = setup_backend(N)\n\n        means = 2 * np.random.random(size=[2 * N]) - 1\n        cov = random_covariance(N, pure=pure)\n\n        backend.reset(pure=pure)\n\n        # circuit is initially in a random state\n        backend.prepare_gaussian_state(means, cov, modes=range(N))\n\n        # test Gaussian state is correct\n        state = backend.state()\n        assert np.allclose(state.means(), means*np.sqrt(hbar/2), atol=tol, rtol=0)\n        assert np.allclose(state.cov(), cov*hbar/2, atol=tol, rtol=0)\n\n        # prepare Gaussian state in mode 2 and 1\n        means2 = 2 * np.random.random(size=[4]) - 1\n        cov2 = random_covariance(2, pure=pure)\n        backend.prepare_gaussian_state(means2, cov2, modes=[2, 1])\n\n        # test resulting Gaussian state is correct\n        state = backend.state()\n\n        # in the new means vector, the modes 0 and 3 remain unchanged\n        # Modes 1 and 2, however, now have values given from elements\n        # means2[1] and means2[0].\n        ex_means = np.array(\n            [\n                means[0],\n                means2[1],\n                means2[0],\n                means[3],  # position\n                means[4],\n                means2[3],\n                means2[2],\n                means[7],\n            ]\n        )  # momentum\n\n        ex_cov = np.zeros([8, 8])\n\n        # in the new covariance matrix, modes 0 and 3 remain unchanged\n        idx = np.array([0, 3, 4, 7])\n        rows = idx.reshape(-1, 1)\n        cols = idx.reshape(1, -1)\n        ex_cov[rows, cols] = cov[rows, cols]\n\n        # in the new covariance matrix, modes 1 and 2 have values given by\n        # rows 1 and 0 respectively from cov2\n        idx = np.array([1, 2, 5, 6])\n        rows = idx.reshape(-1, 1)\n        cols = idx.reshape(1, -1)\n\n        idx = np.array([1, 0, 3, 2])\n        rows2 = idx.reshape(-1, 1)\n        cols2 = idx.reshape(1, -1)\n\n        ex_cov[rows, cols] = cov2[rows2, cols2]\n\n        assert np.allclose(state.means(), ex_means*np.sqrt(hbar/2), atol=tol, rtol=0)\n        assert np.allclose(state.cov(), ex_cov*hbar/2, atol=tol, rtol=0)\n'"
tests/backend/test_nongaussian_gates.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""Unit tests for non-Gaussian gates""""""\n\nimport pytest\n\nimport numpy as np\n\nfrom scipy.linalg import expm\n\nKAPPAS = np.linspace(0, 2 * np.pi, 7)\nGAMMAS = np.linspace(0, 6, 7)\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestFockRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    @pytest.mark.parametrize(""gamma"", GAMMAS)\n    def test_cubic_phase(self, setup_backend, gamma, cutoff, tol):\n        """"""Tests if the Cubic phase gate has the right effect on states in the Fock basis""""""\n\n        backend = setup_backend(1)\n\n        backend.prepare_ket_state(np.ones([cutoff]) / np.sqrt(cutoff), 0)\n        backend.cubic_phase(gamma, 0)\n        s = backend.state()\n        if s.is_pure:\n            numer_state = s.ket()\n        else:\n            numer_state = s.dm()\n\n        #Create annihilation operator matrix\n        ladder_vals = np.arange(1, cutoff)\n        ladder_vals = np.sqrt(ladder_vals)\n        a = np.zeros([cutoff, cutoff])\n        np.fill_diagonal(a[:, 1:], ladder_vals)\n\n        #Construct (unnormalized) x matrix, ie a+a^dag, and it\'s third power\n        x = a + a.T\n        x3 = x @ x @ x\n\n        gate = expm(1j * gamma * x3 / 6)\n\n        #state to be transformed\n        ket = np.ones(cutoff) / np.sqrt(cutoff)\n\n        ref_state = np.matmul(gate, ket)\n        assert np.allclose(numer_state, ref_state, atol=tol, rtol=0.0)\n\n    @pytest.mark.parametrize(""kappa"", KAPPAS)\n    def test_kerr_interaction(self, setup_backend, kappa, cutoff, tol):\n        """"""Tests if the Kerr interaction has the right effect on states in the Fock basis""""""\n\n        backend = setup_backend(1)\n\n        backend.prepare_ket_state(np.ones([cutoff]) / cutoff, 0)\n        backend.kerr_interaction(kappa, 0)\n        s = backend.state()\n        if s.is_pure:\n            numer_state = s.ket()\n        else:\n            numer_state = s.dm()\n        ref_state = np.exp(1j * kappa * np.arange(cutoff) ** 2) / cutoff\n        assert np.allclose(numer_state, ref_state, atol=tol, rtol=0.0)\n\n    @pytest.mark.parametrize(""kappa"", KAPPAS)\n    def test_cross_kerr_interaction(self, setup_backend, kappa, cutoff, tol):\n        """"""Tests if the cross-Kerr interaction has the right effect on states in the Fock basis""""""\n\n        backend = setup_backend(2)\n\n        ket1 = np.array([1.0 for n in range(cutoff)])\n        ket1 /= np.linalg.norm(ket1)\n        ket = np.outer(ket1, ket1)\n\n        backend.prepare_ket_state(ket, modes=[0, 1])\n        backend.cross_kerr_interaction(kappa, 0, 1)\n        s = backend.state()\n\n        if s.is_pure:\n            numer_state = s.ket()\n        else:\n            numer_state = s.dm()\n\n        n1 = np.arange(cutoff).reshape(-1, 1)\n        n2 = np.arange(cutoff).reshape(1, -1)\n        ref_state = np.exp(1j * kappa * n1 * n2).flatten() / cutoff\n        ref_state = np.reshape(ref_state, [cutoff] * 2)\n        assert np.allclose(numer_state, ref_state, atol=tol, rtol=0.0)\n'"
tests/backend/test_postselection.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""tests for backend postselection""""""\nimport pytest\n\nimport numpy as np\n\n\ndef test_homodyne(setup_backend, tol):\n    """"""Test that homodyne detection on a TMS state\n    returns post-selected value.""""""\n    x = 0.2\n    r = 5\n\n    backend = setup_backend(2)\n    backend.squeeze(r, 0)\n    backend.squeeze(-r, 1)\n    backend.beamsplitter(1 / np.sqrt(2), 1 / np.sqrt(2), 0, 1)\n\n    res = backend.measure_homodyne(0, mode=0, select=0.2)\n    assert np.allclose(res, x, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""gaussian"")\ndef test_heterodyne(setup_backend, tol):\n    """"""Test that heterodyne detection on a TMS state\n    returns post-selected value.""""""\n    alpha = 0.43 - 0.12j\n    r = 5\n\n    backend = setup_backend(2)\n    backend.squeeze(r, 0)\n    backend.squeeze(-r, 1)\n    backend.beamsplitter(1 / np.sqrt(2), 1 / np.sqrt(2), 0, 1)\n\n    res = backend.measure_heterodyne(mode=0, select=alpha)\n    assert np.allclose(res, alpha, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""fock"", ""tf"")\ndef test_measure_fock(setup_backend, cutoff, batch_size):\n    """"""Test that Fock post-selection on Fock states\n    exiting one arm of a beamsplitter results in conservation\n    of photon number in the other. """"""\n    backend = setup_backend(2)\n\n    for n in range(cutoff - 1):\n        total_photons = cutoff - 1\n\n        backend.prepare_fock_state(n, 0)\n        backend.prepare_fock_state(total_photons - n, 1)\n        backend.beamsplitter(1 / np.sqrt(2), 1 / np.sqrt(2), 0, 1)\n        res1 = backend.measure_fock([0], select=[cutoff // 2])\n        res2 = backend.measure_fock([1])\n\n        photons_out = sum(res1 + res2)\n\n        if batch_size is not None:\n            total_photons = np.tile(total_photons, batch_size)\n\n        assert np.all(photons_out == total_photons)\n'"
tests/backend/test_rotation_operation.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""Unit tests for phase-shifter operations\nConvention: The phase-shift unitary is fixed to be\nU(\\theta) = \\exp(i * \\theta \\hat{n})\nwhere \\hat{n} is the number operator. For positive \\theta, this corresponds\nto a clockwise rotation of the state in phase space.""""""\n\nimport pytest\n\nimport numpy as np\n\nSHIFT_THETAS = np.linspace(0, 2 * np.pi, 7, endpoint=False)\n\n\nclass TestRepresentationIndependent:\n    """"""Basic implementation-independent tests.""""""\n\n    @pytest.mark.parametrize(""theta"", SHIFT_THETAS)\n    def test_rotated_vacuum(self, setup_backend, theta, tol):\n        """"""Tests phase shift operation in some limiting cases where the result should be a vacuum state.""""""\n        backend = setup_backend(1)\n        backend.rotation(theta, 0)\n        assert np.all(backend.is_vacuum(tol))\n\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestFockRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    @pytest.mark.parametrize(""theta"", SHIFT_THETAS)\n    def test_normalized_rotated_coherent_states(self, setup_backend, theta, tol):\n        """"""Tests if a range of phase-shifted coherent states are normalized.""""""\n        alpha = 1.0\n        backend = setup_backend(1)\n\n        backend.prepare_coherent_state(alpha, 0)\n        backend.rotation(theta, 0)\n\n        state = backend.state()\n        tr = state.trace()\n        assert np.allclose(tr, 1.0, atol=tol, rtol=0.0)\n\n    @pytest.mark.parametrize(""theta"", SHIFT_THETAS)\n    def test_rotated_fock_states(self, setup_backend, theta, pure, cutoff, tol):\n        """"""Tests if a range of phase-shifted fock states |n> are equal to the form of\n        exp(i * theta * n)|n>""""""\n        backend = setup_backend(1)\n\n        for n in range(cutoff):\n            backend.reset(pure=pure)\n\n            backend.prepare_fock_state(n, 0)\n            backend.rotation(theta, 0)\n            s = backend.state()\n\n            if s.is_pure:\n                numer_state = s.ket()\n            else:\n                numer_state = s.dm()\n\n            k = np.arange(cutoff)\n            ref_state = np.where(k == n, np.exp(1j * theta * k), 0)\n\n            if not pure:\n                ref_state = np.outer(ref_state, np.conj(ref_state))\n\n            assert np.allclose(numer_state, ref_state, atol=tol, rtol=0.0)\n'"
tests/backend/test_squeeze_operation.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nUnit tests for squeezing operation\nConvention: The squeezing unitary is fixed to be\nU(z) = \\exp(0.5 (z^* \\hat{a}^2 - z (\\hat{a^\\dagger}^2)))\nwhere \\hat{a} is the photon annihilation operator.\n""""""\n# pylint: disable=too-many-arguments\nimport pytest\n\nimport numpy as np\nfrom scipy.special import factorial as fac, gammaln as lg\n\n\nPHASE = np.linspace(0, 2 * np.pi, 3, endpoint=False)\nMAG = np.linspace(0.0, 0.2, 5, endpoint=False)\n\n\ndef matrix_elem(n, r, m):\n    """"""Matrix element corresponding to squeezed density matrix[n, m]""""""\n    eps = 1e-10\n\n    if n % 2 != m % 2:\n        return 0.0\n\n    if r == 0.0:\n        return np.complex(n == m)  # delta function\n\n    k = np.arange(m % 2, min([m, n]) + 1, 2)\n    res = np.sum(\n        (-1) ** ((n - k) / 2)\n        * np.exp(\n            (lg(m + 1) + lg(n + 1)) / 2\n            - lg(k + 1)\n            - lg((m - k) / 2 + 1)\n            - lg((n - k) / 2 + 1)\n        )\n        * (np.sinh(r) / 2 + eps) ** ((n + m - 2 * k) / 2)\n        / (np.cosh(r) ** ((n + m + 1) / 2))\n    )\n    return res\n\n\nclass TestRepresentationIndependent:\n    """"""Basic implementation-independent tests.""""""\n\n    def test_no_squeezing(self, setup_backend, tol):\n        """"""Tests displacement operation where the result should be a vacuum state.""""""\n        backend = setup_backend(1)\n        backend.squeeze(0, 0)\n        assert np.all(backend.is_vacuum(tol))\n\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestFockRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    @pytest.mark.parametrize(""r"", MAG)\n    @pytest.mark.parametrize(""p"", PHASE)\n    def test_normalized_squeezed_state(self, setup_backend, r, p, tol):\n        """"""Tests if a range of alpha-displaced states have the correct fidelity\n        with the corresponding coherent state.\n        """"""\n        z = r * np.exp(1j * p)\n\n        backend = setup_backend(1)\n        backend.squeeze(z, 0)\n        state = backend.state()\n        assert np.allclose(state.trace(), 1, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""r"", MAG)\n    @pytest.mark.parametrize(""p"", PHASE)\n    def test_no_odd_fock(self, setup_backend, r, p, batch_size):\n        """"""Tests if a range of squeezed vacuum states have\n        only nonzero entries for even Fock states.""""""\n        z = r * np.exp(1j * p)\n\n        backend = setup_backend(1)\n        backend.squeeze(z, 0)\n        state = backend.state()\n\n        if state.is_pure:\n            num_state = state.ket()\n        else:\n            num_state = state.dm()\n\n        if batch_size is not None:\n            odd_entries = num_state[:, 1::2]\n        else:\n            odd_entries = num_state[1::2]\n\n        assert np.all(odd_entries == 0)\n\n    @pytest.mark.parametrize(""r"", MAG)\n    @pytest.mark.parametrize(""p"", PHASE)\n    def test_reference_squeezed_vacuum(\n        self, setup_backend, r, p, cutoff, batch_size, pure, tol\n    ):\n        """"""Tests if a range of squeezed vacuum states are equal to the form of Eq. (5.5.6) in Loudon.""""""\n        z = r * np.exp(1j * p)\n\n        backend = setup_backend(1)\n        backend.squeeze(z, 0)\n        state = backend.state()\n\n        if state.is_pure:\n            num_state = state.ket()\n        else:\n            num_state = state.dm()\n\n        k = np.arange(0, cutoff, 2)\n        even_refs = (\n            np.sqrt(1 / np.cosh(r))\n            * np.sqrt(fac(k))\n            / fac(k / 2)\n            * (-0.5 * np.exp(1j * p) * np.tanh(r)) ** (k / 2)\n        )\n\n        if pure:\n            if batch_size is not None:\n                even_entries = num_state[:, ::2]\n            else:\n                even_entries = num_state[::2]\n        else:\n            even_refs = np.outer(even_refs, even_refs.conj())\n            if batch_size is not None:\n                even_entries = num_state[:, ::2, ::2]\n            else:\n                even_entries = num_state[::2, ::2]\n\n        assert np.allclose(even_entries, even_refs, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""r"", MAG)\n    def test_reference_squeezed_fock(self, setup_backend, r, cutoff, pure, tol):\n        """"""Tests if a range of squeezed fock states are equal to the form of Eq. (20)\n        in \'On the Squeezed Number States and their Phase Space Representations\'\n        (https://arxiv.org/abs/quant-ph/0108024).\n        """"""\n        backend = setup_backend(1)\n\n        for m in range(cutoff):\n            backend.reset(pure=pure)\n            backend.prepare_fock_state(m, 0)\n            backend.squeeze(r, 0)\n            state = backend.state()\n\n            if state.is_pure:\n                num_state = state.ket()\n            else:\n                num_state = state.dm()\n\n            ref_state = np.array([matrix_elem(n, r, m) for n in range(cutoff)])\n\n            if not pure:\n                ref_state = np.outer(ref_state, ref_state.conj())\n\n            assert np.allclose(num_state, ref_state, atol=tol, rtol=0)\n'"
tests/backend/test_squeezed_state_preparation.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""Unit tests for operations that prepare squeezed states\nConvention: The squeezing unitary is fixed to be\nU(z) = \\exp(0.5 (z^* \\hat{a}^2 - z (\\hat{a^\\dagger}^2)))\nwhere \\hat{a} is the photon annihilation operator.""""""\n\nimport pytest\n\nimport numpy as np\nfrom scipy.special import factorial\n\n\nSQZ_R = np.linspace(0.0, 0.1, 5)\nSQZ_THETA = np.linspace(0, 2 * np.pi, 3, endpoint=False)\n\n\ndef sech(x):\n    """"""Hyberbolic secant""""""\n    return 1 / np.cosh(x)\n\n\nclass TestRepresentationIndependent:\n    """"""Basic implementation-independent tests.""""""\n\n    @pytest.mark.parametrize(""theta"", SQZ_THETA)\n    def test_no_squeezing(self, setup_backend, theta, tol):\n        """"""Tests squeezing operation in some limiting cases where the result should be a vacuum state.""""""\n        backend = setup_backend(1)\n        backend.prepare_squeezed_state(0, theta, 0)\n        assert np.all(backend.is_vacuum(tol))\n\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestFockRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    @pytest.mark.parametrize(""r"", SQZ_R)\n    @pytest.mark.parametrize(""theta"", SQZ_THETA)\n    def test_normalized_squeezed_state(self, setup_backend, r, theta, tol):\n        """"""Tests if a range of squeezed vacuum states are normalized.""""""\n        backend = setup_backend(1)\n\n        backend.prepare_squeezed_state(r, theta, 0)\n        state = backend.state()\n        tr = state.trace()\n        assert np.allclose(tr, 1.0, atol=tol, rtol=0.0)\n\n    @pytest.mark.parametrize(""r"", SQZ_R)\n    @pytest.mark.parametrize(""theta"", SQZ_THETA)\n    def test_no_odd_fock(self, setup_backend, r, theta, batch_size):\n        """"""Tests if a range of squeezed vacuum states have\n        only nonzero entries for even Fock states.""""""\n        backend = setup_backend(1)\n\n        backend.prepare_squeezed_state(r, theta, 0)\n        s = backend.state()\n\n        if s.is_pure:\n            num_state = s.ket()\n        else:\n            num_state = s.dm()\n\n        if batch_size is not None:\n            odd_entries = num_state[:, 1::2]\n        else:\n            odd_entries = num_state[1::2]\n\n        assert np.all(odd_entries == 0)\n\n    @pytest.mark.parametrize(""r"", SQZ_R)\n    @pytest.mark.parametrize(""theta"", SQZ_THETA)\n    def test_reference_squeezed_states(\n        self, setup_backend, r, theta, batch_size, pure, cutoff, tol\n    ):\n        """"""Tests if a range of squeezed vacuum states are equal to the form of Eq. (5.5.6) in Loudon.""""""\n        backend = setup_backend(1)\n\n        backend.prepare_squeezed_state(r, theta, 0)\n        s = backend.state()\n\n        if s.is_pure:\n            num_state = s.ket()\n        else:\n            num_state = s.dm()\n\n        n = np.arange(0, cutoff, 2)\n        even_refs = (\n            np.sqrt(sech(r))\n            * np.sqrt(factorial(n))\n            / factorial(n / 2)\n            * (-0.5 * np.exp(1j * theta) * np.tanh(r)) ** (n / 2)\n        )\n\n        if batch_size is not None:\n            if pure:\n                even_entries = num_state[:, ::2]\n            else:\n                even_entries = num_state[:, ::2, ::2]\n                even_refs = np.outer(even_refs, np.conj(even_refs))\n        else:\n            if pure:\n                even_entries = num_state[::2]\n            else:\n                even_entries = num_state[::2, ::2]\n                even_refs = np.outer(even_refs, np.conj(even_refs))\n\n        assert np.allclose(even_entries, even_refs, atol=tol, rtol=0.0)\n'"
tests/backend/test_state_preparations.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""Unit tests for various state preparation operations""""""\n\nimport pytest\n\nimport numpy as np\n\n\nMAG_ALPHAS = np.linspace(0, 0.8, 4)\nPHASE_ALPHAS = np.linspace(0, 2 * np.pi, 7, endpoint=False)\nNBARS = np.linspace(0, 5, 7)\nSEED = 143\n\n\nclass TestRepresentationIndependent:\n    """"""Basic implementation-independent tests.""""""\n\n    def test_prepare_vac(self, setup_backend, tol):\n        """"""Tests the ability to prepare vacuum states.""""""\n        backend = setup_backend(1)\n        backend.prepare_vacuum_state(0)\n        assert np.all(backend.is_vacuum(tol))\n\n    @pytest.mark.parametrize(""mag_alpha"", MAG_ALPHAS)\n    @pytest.mark.parametrize(""phase_alpha"", PHASE_ALPHAS)\n    def test_fidelity_coherent(self, setup_backend, mag_alpha, phase_alpha, tol):\n        """"""Tests if a range of coherent states have the correct fidelity.""""""\n\n        backend = setup_backend(1)\n\n        alpha = mag_alpha * np.exp(1j * phase_alpha)\n        backend.prepare_coherent_state(alpha, 0)\n        state = backend.state()\n        assert np.allclose(state.fidelity_coherent([alpha]), 1.0, atol=tol, rtol=0.0)\n\n    @pytest.mark.parametrize(""nbar"", NBARS)\n    def test_prepare_thermal_state(self, setup_backend, nbar, cutoff, tol):\n        """"""Tests if thermal states with different nbar values\n        give the correct fock probabilities""""""\n\n        backend = setup_backend(1)\n\n        backend.prepare_thermal_state(nbar, 0)\n        ref_probs = np.array([nbar ** n / (nbar + 1) ** (n + 1) for n in range(cutoff)])\n        state = backend.state()\n        state_probs = np.array(\n            [state.fock_prob([n]) for n in range(cutoff)]\n        ).T  # transpose needed for array broadcasting to work in batch mode (data is unaffected in non-batched mode)\n        assert np.allclose(ref_probs, state_probs, atol=tol, rtol=0.0)\n\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestFockRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    def test_normalized_prepare_vac(self, setup_backend, tol):\n        """"""Tests the ability to prepare vacuum states.""""""\n\n        backend = setup_backend(1)\n\n        backend.prepare_vacuum_state(0)\n        state = backend.state()\n        tr = state.trace()\n        assert np.allclose(tr, 1.0, atol=tol, rtol=0.0)\n\n    @pytest.mark.parametrize(""mag_alpha"", MAG_ALPHAS)\n    @pytest.mark.parametrize(""phase_alpha"", PHASE_ALPHAS)\n    def test_normalized_coherent_state(\n        self, setup_backend, mag_alpha, phase_alpha, tol\n    ):\n        """"""Tests if a range of coherent states are normalized.""""""\n\n        alpha = mag_alpha * np.exp(1j * phase_alpha)\n        backend = setup_backend(1)\n\n        backend.prepare_coherent_state(alpha, 0)\n        state = backend.state()\n        tr = state.trace()\n        assert np.allclose(tr, 1.0, atol=tol, rtol=0.0)\n\n    def test_prepare_ket_state(self, setup_backend, cutoff, tol):\n        """"""Tests if a ket state with arbitrary parameters is correctly prepared.""""""\n        np.random.seed(SEED)\n        random_ket = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(\n            -1, 1, cutoff\n        )\n        random_ket = random_ket / np.linalg.norm(random_ket)\n        backend = setup_backend(1)\n\n        backend.prepare_ket_state(random_ket, 0)\n        state = backend.state()\n        assert np.allclose(state.fidelity(random_ket, 0), 1.0, atol=tol, rtol=0.0)\n\n    def test_prepare_batched_ket_state(\n        self, setup_backend, pure, batch_size, cutoff, tol\n    ):\n        """"""Tests if a batch of ket states with arbitrary parameters is correctly\n        prepared by comparing the fock probabilities of the batched case with\n        individual runs with non batched input states.""""""\n\n        if batch_size is None:\n            pytest.skip(""Test skipped if no batching"")\n\n        np.random.seed(SEED)\n        random_kets = np.array(\n            [\n                (lambda ket: ket / np.linalg.norm(ket))(\n                    np.random.uniform(-1, 1, cutoff)\n                    + 1j * np.random.uniform(-1, 1, cutoff)\n                )\n                for _ in range(batch_size)\n            ]\n        )\n        backend = setup_backend(1)\n\n        backend.prepare_ket_state(random_kets, 0)\n        state = backend.state()\n        batched_probs = np.array(state.all_fock_probs())\n\n        individual_probs = []\n        for random_ket in random_kets:\n            backend.reset(pure=pure)\n            backend.prepare_ket_state(random_ket, 0)\n            state = backend.state()\n            probs_for_this_ket = np.array(state.all_fock_probs())\n            individual_probs.append(probs_for_this_ket[0])\n\n        individual_probs = np.array(individual_probs)\n        assert np.allclose(batched_probs, individual_probs, atol=tol, rtol=0.0)\n\n    def test_prepare_rank_two_dm_state(self, setup_backend, cutoff, tol):\n        """"""Tests if rank two dm states with arbitrary parameters are correctly prepared.""""""\n\n        np.random.seed(SEED)\n        random_ket1 = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(\n            -1, 1, cutoff\n        )\n        random_ket1 = random_ket1 / np.linalg.norm(random_ket1)\n        random_ket2 = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(\n            -1, 1, cutoff\n        )\n        random_ket2 = random_ket2 / np.linalg.norm(random_ket2)\n\n        backend = setup_backend(1)\n        backend.prepare_ket_state(random_ket1, 0)\n        state = backend.state()\n        ket_probs1 = np.array([state.fock_prob([n]) for n in range(cutoff)])\n\n        backend = setup_backend(1)\n        backend.prepare_ket_state(random_ket2, 0)\n        state = backend.state()\n        ket_probs2 = np.array([state.fock_prob([n]) for n in range(cutoff)])\n\n        ket_probs = 0.2 * ket_probs1 + 0.8 * ket_probs2\n\n        random_rho = 0.2 * np.outer(np.conj(random_ket1), random_ket1) + 0.8 * np.outer(\n            np.conj(random_ket2), random_ket2\n        )\n\n        backend = setup_backend(1)\n        backend.prepare_dm_state(random_rho, 0)\n        state = backend.state()\n        rho_probs = np.array([state.fock_prob([n]) for n in range(cutoff)])\n\n        assert np.allclose(state.trace(), 1.0, atol=tol, rtol=0.0)\n        assert np.allclose(rho_probs, ket_probs, atol=tol, rtol=0.0)\n\n    def test_prepare_random_dm_state(\n        self, setup_backend, batch_size, pure, cutoff, tol\n    ):\n        """"""Tests if a random dm state is correctly prepared.""""""\n\n        np.random.seed(SEED)\n        random_rho = np.random.normal(size=[cutoff, cutoff]) + 1j * np.random.normal(\n            size=[cutoff, cutoff]\n        )\n        random_rho = np.dot(random_rho.conj().T, random_rho)\n        random_rho = random_rho / random_rho.trace()\n\n        backend = setup_backend(1)\n        backend.prepare_dm_state(random_rho, 0)\n        state = backend.state()\n        rho_probs = np.array(state.all_fock_probs())\n\n        es, vs = np.linalg.eig(random_rho)\n\n        if batch_size is not None:\n            kets_mixed_probs = np.zeros([batch_size, len(es)], dtype=complex)\n        else:\n            kets_mixed_probs = np.zeros([len(es)], dtype=complex)\n\n        for e, v in zip(es, vs.T.conj()):\n            backend.reset(pure=pure)\n            backend.prepare_ket_state(v, 0)\n            state = backend.state()\n            probs_for_this_v = np.array(state.all_fock_probs())\n            kets_mixed_probs += e * probs_for_this_v\n\n        assert np.allclose(rho_probs, kets_mixed_probs, atol=tol, rtol=0.0)\n\n    @pytest.mark.parametrize(""theta"", PHASE_ALPHAS)\n    def test_rotated_superposition_states(\n        self, setup_backend, theta, pure, cutoff, tol\n    ):\n        r""""""Tests if a range of phase-shifted superposition states are equal to the form of\n        \\sum_n exp(i * theta * n)|n>""""""\n\n        backend = setup_backend(1)\n\n        ref_state = np.array([np.exp(1j * theta * k) for k in range(cutoff)]) / np.sqrt(\n            cutoff\n        )\n\n        if not pure:\n            ref_state = np.outer(ref_state, np.conj(ref_state))\n\n        backend.prepare_ket_state(ref_state, 0)\n        s = backend.state()\n\n        if s.is_pure:\n            numer_state = s.ket()\n        else:\n            numer_state = s.dm()\n\n        assert np.allclose(numer_state, ref_state, atol=tol, rtol=0.0)\n'"
tests/backend/test_states.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the states.py submodule""""""\nimport pytest\n\nimport numpy as np\nfrom scipy.special import factorial as fac\n\nfrom strawberryfields import backends\nfrom strawberryfields import utils\n\n\na = 0.3 + 0.1j\nr = 0.23\nphi = 0.123\n\n\nclass TestBackendStateCreation:\n    """"""Test the backends properly create states""""""\n\n    def test_full_state_creation(self, hbar, cutoff, setup_backend):\n        """"""Test backend returns a properly formed state object""""""\n        backend = setup_backend(3)\n        state = backend.state(modes=None)\n\n        assert state.num_modes == 3\n        assert state.hbar == hbar\n        assert state.mode_names == {0: ""q[0]"", 1: ""q[1]"", 2: ""q[2]""}\n        assert state.mode_indices == {""q[0]"": 0, ""q[1]"": 1, ""q[2]"": 2}\n\n        if isinstance(backend, backends.BaseFock):\n            assert state.cutoff_dim == cutoff\n\n    def test_reduced_state_creation(self, setup_backend):\n        """"""Test backend returns a properly formed reduced state object""""""\n        backend = setup_backend(3)\n        state = backend.state(modes=[0, 2])\n\n        assert state.num_modes == 2\n        assert state.mode_names == {0: ""q[0]"", 1: ""q[2]""}\n        assert state.mode_indices == {""q[0]"": 0, ""q[2]"": 1}\n\n    def test_reduced_state_fidelity(self, setup_backend, tol):\n        """"""Test backend calculates correct fidelity of reduced coherent state""""""\n        backend = setup_backend(2)\n\n        backend.prepare_coherent_state(a, 0)\n        backend.prepare_squeezed_state(r, phi, 1)\n\n        state = backend.state(modes=[0])\n        f = state.fidelity_coherent([a])\n        assert np.allclose(f, 1, atol=tol, rtol=0)\n\n    def test_reduced_state_fock_probs(self, cutoff, setup_backend, batch_size, tol):\n        """"""Test backend calculates correct fock prob of reduced coherent state""""""\n        backend = setup_backend(2)\n\n        backend.prepare_coherent_state(a, 0)\n        backend.prepare_squeezed_state(r, phi, 1)\n\n        state = backend.state(modes=[0])\n        probs = np.array([state.fock_prob([i]) for i in range(cutoff)]).T\n\n        n = np.arange(cutoff)\n        ref_state = np.exp(-0.5 * np.abs(a) ** 2) * a ** n / np.sqrt(fac(n))\n        ref_probs = np.abs(ref_state) ** 2\n\n        if batch_size is not None:\n            ref_probs = np.tile(ref_probs, batch_size)\n\n        assert np.allclose(probs.flatten(), ref_probs.flatten(), atol=tol, rtol=0)\n\n\nclass TestBaseStateMeanPhotonNumber:\n    """"""Tests for the mean photon number method""""""\n\n    def test_mean_photon_coherent(self, setup_backend, tol, batch_size):\n        """"""Test that E(n) = |a|^2 and var(n) = |a|^2 for a coherent state""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(1)\n\n        backend.displacement(a, 0)\n        state = backend.state()\n        mean_photon, var = state.mean_photon(0)\n\n        assert np.allclose(mean_photon, np.abs(a) ** 2, atol=tol, rtol=0)\n        assert np.allclose(var, np.abs(a) ** 2, atol=tol, rtol=0)\n\n    def test_mean_photon_squeezed(self, setup_backend, tol, batch_size):\n        """"""Test that E(n)=sinh^2(r) and var(n)=2(sinh^2(r)+sinh^4(r)) for a squeezed state""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(1)\n\n        r = 0.1\n        a = 0.3 + 0.1j\n\n        backend.squeeze(r * np.exp(1j * phi), 0)\n        state = backend.state()\n        mean_photon, var = state.mean_photon(0)\n\n        assert np.allclose(mean_photon, np.sinh(r) ** 2, atol=tol, rtol=0)\n        assert np.allclose(var, 2 * (np.sinh(r) ** 2 + np.sinh(r) ** 4), atol=tol, rtol=0)\n\n    def test_mean_photon_displaced_squeezed(self, setup_backend, tol, batch_size):\n        """"""Test that E(n) = sinh^2(r)+|a|^2 for a displaced squeezed state""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(1)\n\n        nbar = 0.123\n        a = 0.12 - 0.05j\n        r = 0.195\n\n        backend.squeeze(r * np.exp(1j * phi), 0)\n        backend.displacement(a, 0)\n        state = backend.state()\n        mean_photon, var = state.mean_photon(0)\n\n        mag_a = np.abs(a)\n        phi_a = np.angle(a)\n\n        mean_ex = np.abs(a) ** 2 + np.sinh(r) ** 2\n        assert np.allclose(mean_photon, mean_ex, atol=tol, rtol=0)\n\n    def test_mean_photon_displaced_thermal(self, setup_backend, tol, batch_size):\n        """"""Test that E(n)=|a|^2+nbar and var(n)=var_th+|a|^2(1+2nbar)""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(1)\n\n        nbar = 0.123\n\n        backend.prepare_thermal_state(nbar, 0)\n        backend.displacement(a, 0)\n        state = backend.state()\n        mean_photon, var = state.mean_photon(0)\n\n        mean_ex = np.abs(a) ** 2 + nbar\n        var_ex = nbar ** 2 + nbar + np.abs(a) ** 2 * (1 + 2 * nbar)\n        assert np.allclose(mean_photon, mean_ex, atol=tol, rtol=0)\n        assert np.allclose(var, var_ex, atol=tol, rtol=0)\n\n\nclass TestBaseFockKetDensityMatrix:\n    """"""Tests for the ket, dm, and reduced density matrix function.""""""\n\n    def test_rdm(self, setup_backend, tol, cutoff, batch_size):\n        """"""Test reduced density matrix of a coherent state is as expected\n        This is supported by all backends, since it returns\n        the reduced density matrix of a single mode.""""""\n        backend = setup_backend(2)\n        backend.prepare_coherent_state(a, 0)\n        backend.prepare_coherent_state(0.1, 1)\n\n        state = backend.state()\n        rdm = state.reduced_dm(0, cutoff=cutoff)\n\n        n = np.arange(cutoff)\n        ket = np.exp(-0.5 * np.abs(a) ** 2) * a ** n / np.sqrt(fac(n))\n        rdm_exact = np.outer(ket, ket.conj())\n\n        if batch_size is not None:\n            np.tile(rdm_exact, [batch_size, 1])\n\n        assert np.allclose(rdm, rdm_exact, atol=tol, rtol=0)\n\n    @pytest.mark.backends(""fock"", ""tf"")\n    def test_ket(self, setup_backend, pure, cutoff, batch_size, tol):\n        """"""Test that the ket of a displaced state matches analytic result""""""\n        backend = setup_backend(2)\n        backend.displacement(a, 0)\n\n        state = backend.state()\n        if not pure:\n            assert state.is_pure == False\n            pytest.skip(""Test only works with pure states."")\n\n        assert state.is_pure == True\n\n        ket = np.sum(state.ket(), axis=-1)\n\n        n = np.arange(cutoff)\n        expected = np.exp(-0.5 * np.abs(a) ** 2) * a ** n / np.sqrt(fac(n))\n\n        if batch_size is not None:\n            ket = np.tile(ket, [batch_size, 1])\n\n        assert np.allclose(ket, expected, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""gaussian"")\nclass TestBaseGaussianMethods:\n    """"""This tests state methods unique to the BaseGaussian\n    class, including is_coherent, displacement, is_squeezed,\n    and squeezing.""""""\n\n    def test_coherent_methods(self, setup_backend, tol):\n        """"""Test that the ket of a displaced state matches analytic result""""""\n        backend = setup_backend(2)\n\n        a = 1 + 0.5j\n        r = 2\n        phi = -0.5\n\n        backend.prepare_coherent_state(a, 0)\n        backend.prepare_squeezed_state(r, phi, 1)\n\n        state = backend.state()\n\n        coherent_check = []\n        for i in range(2):\n            coherent_check.append(state.is_coherent(i))\n\n        alpha_list = state.displacement()\n\n        assert np.all(coherent_check == [True, False])\n        assert np.allclose(alpha_list, [a, 0.0], atol=tol, rtol=0)\n\n    def test_squeezing_methods(self, setup_backend, tol):\n        """"""Test that the ket of a displaced state matches analytic result""""""\n        backend = setup_backend(2)\n\n        a = 1 + 0.5j\n        r = 2\n        phi = -0.5\n\n        backend.prepare_coherent_state(a, 0)\n        backend.prepare_squeezed_state(r, phi, 1)\n\n        state = backend.state()\n\n        squeezing_check = []\n        for i in range(2):\n            squeezing_check.append(state.is_squeezed(i))\n\n        z_list = np.array(state.squeezing())\n\n        assert np.all(squeezing_check == [False, True])\n        assert np.allclose(z_list, [[0.0, 0.0], [r, phi]], atol=tol, rtol=0)\n\n\nclass TestQuadratureExpectations:\n    """"""Test quad_expectation methods""""""\n\n    def test_vacuum(self, setup_backend, hbar, batch_size, tol):\n        """"""Test vacuum state has zero mean and hbar/2 variance""""""\n        backend = setup_backend(1)\n        state = backend.state()\n        res = np.array(state.quad_expectation(0, phi=np.pi / 4)).T\n\n        res_exact = np.array([0, hbar / 2.0])\n\n        if batch_size is not None:\n            res_exact = np.tile(res_exact, batch_size)\n\n        assert np.allclose(res.flatten(), res_exact.flatten(), atol=tol, rtol=0)\n\n    def test_squeezed_coherent(self, setup_backend, hbar, batch_size, tol):\n        """"""Test squeezed coherent state has correct mean and variance""""""\n        # quadrature rotation angle\n        backend = setup_backend(1)\n        qphi = 0.78\n\n        backend.prepare_displaced_squeezed_state(a, r, phi, 0)\n\n        state = backend.state()\n        res = np.array(state.quad_expectation(0, phi=qphi)).T\n\n        xphi_mean = (a.real * np.cos(qphi) + a.imag * np.sin(qphi)) * np.sqrt(2 * hbar)\n        xphi_var = (np.cosh(2 * r) - np.cos(phi - 2 * qphi) * np.sinh(2 * r)) * hbar / 2\n        res_exact = np.array([xphi_mean, xphi_var])\n\n        if batch_size is not None:\n            res_exact = np.tile(res_exact, batch_size)\n\n        assert np.allclose(res.flatten(), res_exact.flatten(), atol=tol, rtol=0)\n\n\nclass TestNumberExpectation:\n    """"""Multimode photon-number expectation value tests""""""\n\n    def test_number_expectation_vacuum(self, setup_backend, tol, batch_size):\n        """"""Tests the expectation value of any photon number in vacuum is zero""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(2)\n        state = backend.state()\n        assert np.allclose(state.number_expectation([0, 1]), 0.0, atol=tol, rtol=0)\n        assert np.allclose(state.number_expectation([0]), 0.0, atol=tol, rtol=0)\n        assert np.allclose(state.number_expectation([1]), 0.0, atol=tol, rtol=0)\n\n    def test_number_expectation_displaced_squeezed(self, setup_backend, tol, batch_size):\n        """"""Tests the expectation value of photon numbers when there is no correlation""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(2)\n        state = backend.state()\n        a0 = 0.3 + 0.1 * 1j\n        r0 = 0.2\n        phi0 = 0.6\n        a1 = 0.1 + 0.1 * 1j\n        r1 = 0.3\n        phi1 = 0.9\n        backend.prepare_displaced_squeezed_state(a0, r0, phi0, 0)\n        backend.prepare_displaced_squeezed_state(a1, r1, phi1, 1)\n        state = backend.state()\n        n0 = np.sinh(r0) ** 2 + np.abs(a0) ** 2\n        n1 = np.sinh(r1) ** 2 + np.abs(a1) ** 2\n        assert np.allclose(state.number_expectation([0, 1]), n0 * n1, atol=tol, rtol=0)\n        assert np.allclose(state.number_expectation([0]), n0, atol=tol, rtol=0)\n        assert np.allclose(state.number_expectation([1]), n1, atol=tol, rtol=0)\n\n    def test_number_expectation_repeated_modes(self, setup_backend, tol):\n        """"""Tests that the correct exception is raised for repeated modes""""""\n        backend = setup_backend(2)\n        state = backend.state()\n        with pytest.raises(ValueError, match=""There can be no duplicates in the modes specified.""):\n            state.number_expectation([0, 0])\n\n    @pytest.mark.backends(""gaussian"")\n    def test_number_expectation_only_two_modes_gaussian(self, setup_backend, tol):\n        """"""Tests that the correct exception is raised when there are more than two modes specified for Gaussian states""""""\n        backend = setup_backend(3)\n        state = backend.state()\n        with pytest.raises(\n            ValueError,\n            match=""The number_expectation method only supports one or two modes for Gaussian states."",\n        ):\n            state.number_expectation([0, 1, 2])\n\n    def test_number_expectation_two_mode_squeezed(self, setup_backend, tol, batch_size):\n        """"""Tests the expectation value of photon numbers when there is correlation""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(3)\n        state = backend.state()\n        r = 0.2\n        phi = 0.0\n        backend.prepare_squeezed_state(r, phi, 0)\n        backend.prepare_squeezed_state(-r, phi, 2)\n        backend.beamsplitter(np.sqrt(0.5), -np.sqrt(0.5), 0, 2)\n        state = backend.state()\n        nbar = np.sinh(r) ** 2\n        assert np.allclose(state.number_expectation([2, 0]), 2 * nbar ** 2 + nbar, atol=tol, rtol=0)\n        assert np.allclose(state.number_expectation([0]), nbar, atol=tol, rtol=0)\n        assert np.allclose(state.number_expectation([2]), nbar, atol=tol, rtol=0)\n\n    @pytest.mark.backends(""fock"", ""tf"")\n    def test_number_expectation_four_modes(self, setup_backend, tol, batch_size):\n        """"""Tests the expectation value of photon numbers when there is correlation""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(4)\n        state = backend.state()\n        r = 0.2\n        phi = 0.0\n        backend.prepare_squeezed_state(r, phi, 0)\n        backend.prepare_squeezed_state(-r, phi, 1)\n        backend.beamsplitter(np.sqrt(0.5), -np.sqrt(0.5), 0, 1)\n        backend.prepare_squeezed_state(r, phi, 2)\n        backend.prepare_squeezed_state(-r, phi, 3)\n        backend.beamsplitter(np.sqrt(0.5), -np.sqrt(0.5), 2, 3)\n\n        state = backend.state()\n        nbar = np.sinh(r) ** 2\n        assert np.allclose(\n            state.number_expectation([0, 1, 2, 3]), (2 * nbar ** 2 + nbar) ** 2, atol=tol, rtol=0,\n        )\n        assert np.allclose(\n            state.number_expectation([0, 1, 3]), nbar * (2 * nbar ** 2 + nbar), atol=tol, rtol=0,\n        )\n        assert np.allclose(\n            state.number_expectation([3, 1, 2]), nbar * (2 * nbar ** 2 + nbar), atol=tol, rtol=0,\n        )\n\n\nclass TestParityExpectation:\n    @pytest.mark.backends(""fock"", ""tf"")\n    def test_parity_fock(self, setup_backend, tol, batch_size):\n        """"""Tests the parity operator for an even superposition of the first two number states""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(2)\n        state = backend.state()\n        n1 = 3\n        n2 = 2\n        backend.prepare_fock_state(n1, 0)\n        backend.prepare_fock_state(n2, 1)\n        backend.beamsplitter(np.sqrt(0.5), -np.sqrt(0.5), 0, 1)\n        state = backend.state()\n\n        assert np.allclose(state.parity_expectation([0]), 0, atol=tol, rtol=0)\n\n    @pytest.mark.backends(""fock"", ""tf"")\n    def test_two_mode_fock(self, setup_backend, tol, batch_size):\n        """"""Tests the product of parity operators for two number states""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(2)\n        state = backend.state()\n        n1 = 3\n        n2 = 5\n        backend.prepare_fock_state(n1, 0)\n        backend.prepare_fock_state(n2, 1)\n        state = backend.state()\n\n        assert np.allclose(state.parity_expectation([0, 1]), 1, atol=tol, rtol=0)\n\n    def test_coherent(self, setup_backend, tol, batch_size):\n        """"""Tests the parity operator for a coherent state""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(1)\n        state = backend.state()\n        alpha = 0.2\n        backend.prepare_coherent_state(alpha, 0)\n        state = backend.state()\n\n        assert np.allclose(\n            state.parity_expectation([0]), np.exp(-2 * (np.abs(alpha) ** 2)), atol=tol, rtol=0\n        )\n\n    def test_squeezed(self, setup_backend, tol, batch_size):\n        """"""Tests the parity operator for a squeezed state""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(1)\n        state = backend.state()\n        r = 0.2\n        phi = 0\n        backend.prepare_squeezed_state(r, phi, 0)\n        state = backend.state()\n\n        assert np.allclose(state.parity_expectation([0]), 1, atol=tol, rtol=0)\n\n    def test_two_mode_squeezed(self, setup_backend, tol, batch_size):\n        """"""Tests the parity operator for a two-mode squeezed state""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(2)\n        state = backend.state()\n        r = 0.2\n        phi = 0\n        backend.beamsplitter(np.sqrt(0.5), -np.sqrt(0.5), 0, 1)\n        backend.prepare_squeezed_state(r, phi, 0)\n        backend.prepare_squeezed_state(-1 * r, phi, 1)\n        backend.beamsplitter(np.sqrt(0.5), -np.sqrt(0.5), 0, 1)\n        state = backend.state()\n\n        assert np.allclose(state.parity_expectation([0, 1]), 1, atol=tol, rtol=0)\n\n    @pytest.mark.backends(""fock"", ""tf"")\n    def test_thermal(self, setup_backend, tol, batch_size):\n        """"""Tests the parity operator for a thermal state""""""\n        if batch_size is not None:\n            pytest.skip(""Does not support batch mode"")\n        backend = setup_backend(1)\n        state = backend.state()\n        m = 0.2\n        backend.prepare_thermal_state(m, 0)\n        state = backend.state()\n\n        assert np.allclose(state.parity_expectation([0]), (1 / ((2 * m) + 1)), atol=tol, rtol=0)\n\n\nclass TestFidelities:\n    """"""Fidelity tests.""""""\n\n    def test_vacuum(self, setup_backend, tol):\n        backend = setup_backend(2)\n        state = backend.state()\n        assert np.allclose(state.fidelity_vacuum(), 1, atol=tol, rtol=0)\n\n    def test_coherent_fidelity(self, setup_backend, cutoff, tol, hbar):\n        backend = setup_backend(2)\n        backend.prepare_coherent_state(a, 0)\n        backend.displacement(a, 1)\n        state = backend.state()\n\n        if isinstance(backend, backends.BaseFock):\n            in_state = utils.coherent_state(a, basis=""fock"", fock_dim=cutoff, hbar=hbar)\n        else:\n            in_state = utils.coherent_state(a, basis=""gaussian"", hbar=hbar)\n\n        assert np.allclose(state.fidelity(in_state, 0), 1, atol=tol, rtol=0)\n        assert np.allclose(state.fidelity(in_state, 1), 1, atol=tol, rtol=0)\n        assert np.allclose(state.fidelity_coherent([a, a]), 1, atol=tol, rtol=0)\n\n    def test_squeezed_fidelity(self, setup_backend, cutoff, tol, hbar):\n        backend = setup_backend(2)\n        backend.prepare_squeezed_state(r, phi, 0)\n        backend.squeeze(r * np.exp(1j * phi), 1)\n        state = backend.state()\n\n        if isinstance(backend, backends.BaseFock):\n            in_state = utils.squeezed_state(r, phi, basis=""fock"", fock_dim=cutoff, hbar=hbar)\n        else:\n            in_state = utils.squeezed_state(r, phi, basis=""gaussian"", hbar=hbar)\n\n        assert np.allclose(state.fidelity(in_state, 0), 1, atol=tol, rtol=0)\n        assert np.allclose(state.fidelity(in_state, 1), 1, atol=tol, rtol=0)\n\n    def test_squeezed_coherent_fidelity(self, setup_backend, cutoff, tol, hbar):\n        backend = setup_backend(2)\n        backend.prepare_displaced_squeezed_state(a, r, phi, 0)\n        backend.squeeze(r * np.exp(1j * phi), 1)\n        backend.displacement(a, 1)\n        state = backend.state()\n\n        if isinstance(backend, backends.BaseFock):\n            in_state = utils.displaced_squeezed_state(\n                a, r, phi, basis=""fock"", fock_dim=cutoff, hbar=hbar\n            )\n        else:\n            in_state = utils.displaced_squeezed_state(a, r, phi, basis=""gaussian"", hbar=hbar)\n\n        assert np.allclose(state.fidelity(in_state, 0), 1, atol=tol, rtol=0)\n        assert np.allclose(state.fidelity(in_state, 1), 1, atol=tol, rtol=0)\n'"
tests/backend/test_states_polyquad.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the poly_quad_expectations method in the states.py submodule""""""\nimport pytest\n\nimport numpy as np\nfrom scipy.stats import multivariate_normal\nfrom scipy.integrate import simps\nfrom scipy.linalg import block_diag\n\nfrom strawberryfields import backends\nfrom strawberryfields import utils\nfrom strawberryfields.backends.shared_ops import rotation_matrix as R, changebasis\n\n# some tests require a higher cutoff for accuracy\nCUTOFF = 12\n\na = 0.3 + 0.1j\nr = 0.23\nphi = 0.123\nqphi = 0.78\n\n\n@pytest.mark.backends(""fock"", ""gaussian"")\nclass TestSingleModePolyQuadratureExpectations:\n    """"""Test single mode poly_quad_expectation methods""""""\n\n    @pytest.fixture\n    def gaussian_state(self, hbar):\n        """"""A test Gaussian state to use in testing""""""\n        # quadrature rotation\n\n        # construct the expected vector of means and covariance matrix\n        mu = R(qphi).T @ np.array([a.real, a.imag]) * np.sqrt(2 * hbar)\n        cov = R(qphi).T @ utils.squeezed_cov(r, phi, hbar=hbar) @ R(qphi)\n\n        return mu, cov\n\n    @pytest.fixture\n    def sample_normal_expectations(self, gaussian_state):\n        """"""Returns the expectation value E(f) and the variance var(f)\n        for some normal distribution X~N(mu, cov).\n\n        Args:\n            mu (array): means vector\n            cov (array): covariance matrix\n            func (function): function acting on the random variables X, P, XP,\n                returning a second order polynomial\n\n        Returns:\n            tuple: tuple of expectation value and variance.\n        """"""\n\n        def _sample(func, correction=0, mu=None, cov=None):\n            """"""wrapped function""""""\n            if mu is None:\n                mu = gaussian_state[0]\n\n            if cov is None:\n                cov = gaussian_state[1]\n\n            X, P = np.mgrid[-7:7:0.01, -7:7:0.01]\n            grid = np.dstack((X, P))\n            XP = np.prod(grid, axis=2)\n\n            poly = func(X, P, XP)\n            PDF = multivariate_normal.pdf(grid, mu, cov)\n\n            Ex = simps(simps(poly * PDF, P[0]), X.T[0])\n            ExSq = simps(simps(poly ** 2 * PDF, P[0]), X.T[0])\n\n            var = ExSq - Ex ** 2 + correction\n\n            return Ex, var\n\n        return _sample\n\n    def test_no_expectation(self, setup_backend, tol):\n        """"""Test the case E(0), var(0)""""""\n        backend = setup_backend(3)\n        state = backend.state()\n\n        A = np.zeros([6, 6])\n        d = np.zeros([6])\n        k = 0\n\n        mean, var = state.poly_quad_expectation(A, d, k)\n        assert np.allclose(mean, 0, atol=tol, rtol=0)\n        assert np.allclose(var, 0, atol=tol, rtol=0)\n\n    def test_constant(self, setup_backend, tol):\n        """"""Test the case E(k), var(k)""""""\n        backend = setup_backend(3)\n        state = backend.state()\n\n        A = np.zeros([6, 6])\n        d = np.zeros([6])\n        k = 0.543\n\n        mean, var = state.poly_quad_expectation(A, d, k)\n        assert np.allclose(mean, k, atol=tol, rtol=0)\n        assert np.allclose(var, 0, atol=tol, rtol=0)\n\n    def test_linear_vacuum(self, setup_backend, tol, hbar):\n        """"""Test that the correct results are returned for the vacuum state.""""""\n        backend = setup_backend(3)\n        state = backend.state()\n\n        A = np.zeros([6, 6])\n        # create an arbitrary linear combination\n        d = np.array([1, 1, 0, 1, 0, 0])\n        k = 0\n\n        mean, var = state.poly_quad_expectation(A, d, k, phi=qphi)\n        assert np.allclose(mean, 0, atol=tol, rtol=0)\n        assert np.allclose(var, len(d) * hbar / 4, atol=tol, rtol=0)\n\n    def test_x_squeezed(self, setup_backend, tol, pure, hbar):\n        """"""Test that the correct E(x) is returned for the squeezed state.""""""\n        backend = setup_backend(3)\n        backend.reset(cutoff_dim=CUTOFF, pure=pure)\n\n        A = None\n        d = np.array([1, 0, 0, 0, 0, 0])\n        k = 0\n\n        # prepare a squeezed state\n        backend.squeeze(r, 0)\n\n        state = backend.state()\n        mean, var = state.poly_quad_expectation(A, d, k, phi=0)\n\n        assert np.allclose(mean, 0, atol=tol, rtol=0)\n        assert np.allclose(var, np.exp(-2 * r)*hbar/2, atol=tol, rtol=0)\n\n    def test_x_displaced(self, setup_backend, tol, hbar):\n        """"""Test that the correct E(x) is returned for a displaced state.""""""\n        backend = setup_backend(3)\n\n        A = None\n        d = np.array([1, 0, 0, 0, 0, 0])\n        k = 0\n\n        # prepare a displaced state\n        backend.displacement(a, 0)\n\n        state = backend.state()\n        mean, var = state.poly_quad_expectation(A, d, k, phi=0)\n\n        assert np.allclose(mean, a.real * np.sqrt(2 * hbar), atol=tol, rtol=0)\n        assert np.allclose(var, hbar / 2, atol=tol, rtol=0)\n\n    def test_x_displaced_squeezed(self, setup_backend, tol, gaussian_state):\n        """"""Test that the correct E(x) is returned for the displaced squeezed state.""""""\n        backend = setup_backend(3)\n        mu, cov = gaussian_state\n\n        A = None\n        d = np.array([1, 0, 0, 0, 0, 0])\n        k = 0\n\n        # prepare a displaced squeezed state\n        backend.prepare_displaced_squeezed_state(a, r, phi, 0)\n\n        state = backend.state()\n        mean, var = state.poly_quad_expectation(A, d, k, phi=qphi)\n\n        assert np.allclose(mean, mu[0], atol=tol, rtol=0)\n        assert np.allclose(var, cov[0, 0], atol=tol, rtol=0)\n\n    def test_p_displaced_squeezed(self, setup_backend, tol, gaussian_state):\n        """"""Test that the correct E(p) is returned for the displaced squeezed state.""""""\n        backend = setup_backend(3)\n        mu, cov = gaussian_state\n\n        A = None\n        d = np.array([0, 0, 0, 1, 0, 0])\n        k = 0\n\n        # prepare a displaced squeezed state\n        backend.prepare_displaced_squeezed_state(a, r, phi, 0)\n\n        state = backend.state()\n        mean, var = state.poly_quad_expectation(A, d, k, phi=qphi)\n\n        assert np.allclose(mean, mu[1], atol=tol, rtol=0)\n        assert np.allclose(var, cov[1, 1], atol=tol, rtol=0)\n\n    def test_linear_combination(self, setup_backend, tol, gaussian_state):\n        """"""Test that the correct result is returned for E(ax+bp)""""""\n        backend = setup_backend(3)\n        mu, cov = gaussian_state\n\n        A = None\n        d = np.array([0.4234, 0, 0, 0.1543, 0, 0])\n        k = 0\n\n        # prepare a displaced squeezed state\n        backend.prepare_displaced_squeezed_state(a, r, phi, 0)\n\n        state = backend.state()\n        mean, var = state.poly_quad_expectation(A, d, k, phi=qphi)\n\n        # E(ax+bp) = aE(x) + bE(p)\n        mean_expected = d[0] * mu[0] + d[3] * mu[1]\n        assert np.allclose(mean, mean_expected, atol=tol, rtol=0)\n\n        # var(ax+bp) = a**2 var(x)+b**2 var(p)+2ab cov(x,p)\n        var_expected = (\n            cov[0, 0] * d[0] ** 2 + cov[1, 1] * d[3] ** 2 + 2 * d[0] * d[3] * cov[0, 1]\n        )\n        assert np.allclose(var, var_expected, atol=tol, rtol=0)\n\n    def test_n_thermal(self, setup_backend, tol, hbar, pure):\n        """"""Test expectation and variance of the number operator on a thermal state""""""\n        backend = setup_backend(3)\n        backend.reset(cutoff_dim=CUTOFF, pure=pure)\n\n        nbar = 0.423\n\n        backend.prepare_thermal_state(nbar, 0)\n        state = backend.state()\n\n        # n = a^\\dagger a = (X^2 +P^2)/2\\hbar - I/2\n        A = np.zeros([6, 6])\n        A[0, 0] = 1 / (2 * hbar)\n        A[3, 3] = 1 / (2 * hbar)\n        k = -0.5\n\n        mean, var = state.poly_quad_expectation(A, d=None, k=k, phi=0)\n        assert np.allclose(mean, nbar, atol=tol, rtol=0)\n        assert np.allclose(var, nbar * (nbar + 1), atol=tol, rtol=0)\n\n    def test_n_squeeze(self, setup_backend, tol, hbar, pure):\n        """"""Test expectation and variance of the number operator on a squeezed state""""""\n        backend = setup_backend(3)\n        backend.reset(cutoff_dim=CUTOFF, pure=pure)\n\n        backend.prepare_squeezed_state(r, phi, 0)\n        state = backend.state()\n\n        # n = a^\\dagger a = (X^2 +P^2)/2\\hbar - I/2\n        A = np.zeros([6, 6])\n        A[0, 0] = 1 / (2 * hbar)\n        A[3, 3] = 1 / (2 * hbar)\n        k = -0.5\n\n        mean, var = state.poly_quad_expectation(A, None, k, phi=qphi)\n\n        mean_ex = np.sinh(r) ** 2\n        var_ex = 0.5 * np.sinh(2 * r) ** 2\n\n        assert np.allclose(mean, mean_ex, atol=tol, rtol=0)\n        assert np.allclose(var, var_ex, atol=tol, rtol=0)\n\n    def test_x_squared(self, setup_backend, tol, pure, sample_normal_expectations):\n        """"""Test that the correct result is returned for E(x^2)""""""\n        backend = setup_backend(3)\n        backend.reset(cutoff_dim=CUTOFF, pure=pure)\n\n        A = np.zeros([6, 6])\n        A[0, 0] = 1\n\n        d = None\n        k = 0\n\n        # prepare a displaced squeezed state\n        backend.prepare_displaced_squeezed_state(a, r, phi, 0)\n\n        state = backend.state()\n        mean, var = state.poly_quad_expectation(A, d, k, phi=qphi)\n\n        mean_ex, var_ex = sample_normal_expectations(lambda X, P, XP: A[0, 0] * X ** 2)\n        assert np.allclose(mean, mean_ex, atol=tol, rtol=0)\n        assert np.allclose(var, var_ex, atol=tol, rtol=0)\n\n    def test_p_squared(self, setup_backend, tol, pure, sample_normal_expectations):\n        """"""Test that the correct result is returned for E(p^2)""""""\n        backend = setup_backend(3)\n        backend.reset(cutoff_dim=CUTOFF, pure=pure)\n\n        A = np.zeros([6, 6])\n        A[3, 3] = 1\n\n        d = None\n        k = 0\n\n        # prepare a displaced squeezed state\n        backend.prepare_displaced_squeezed_state(a, r, phi, 0)\n\n        state = backend.state()\n        mean, var = state.poly_quad_expectation(A, d, k, phi=qphi)\n\n        mean_ex, var_ex = sample_normal_expectations(lambda X, P, XP: P ** 2)\n        assert np.allclose(mean, mean_ex, atol=tol, rtol=0)\n        assert np.allclose(var, var_ex, atol=tol, rtol=0)\n\n    def test_xp_vacuum(self, setup_backend, tol, sample_normal_expectations, hbar):\n        """"""Test that the correct result is returned for E(xp) on the vacuum state""""""\n        backend = setup_backend(3)\n\n        # set quadratic coefficient\n        A = np.zeros([6, 6])\n        A[3, 0] = A[0, 3] = 0.5\n\n        d = None\n        k = 0\n\n        state = backend.state()\n        mean, var = state.poly_quad_expectation(A, d, k, phi=0)\n\n        mean_ex, var_ex = sample_normal_expectations(\n            lambda X, P, XP: XP,\n            correction=-np.linalg.det(hbar * A[:, [0, 3]][[0, 3]]),\n            mu=np.zeros([2]),\n            cov=np.identity(2)*hbar/2,\n        )\n\n        assert np.allclose(mean, mean_ex, atol=tol, rtol=0)\n        assert np.allclose(var, var_ex, atol=tol, rtol=0)\n\n    def test_xp_displaced_squeezed(\n        self, setup_backend, tol, pure, sample_normal_expectations, hbar\n    ):\n        """"""Test that the correct result is returned for E(xp) on a displaced squeezed state""""""\n        backend = setup_backend(3)\n        backend.reset(cutoff_dim=CUTOFF, pure=pure)\n\n        # set quadratic coefficient\n        A = np.zeros([6, 6])\n        A[3, 0] = A[0, 3] = 0.5\n\n        d = None\n        k = 0\n\n        # prepare a displaced squeezed state\n        backend.prepare_displaced_squeezed_state(a, r, phi, 0)\n\n        state = backend.state()\n        mean, var = state.poly_quad_expectation(A, d, k, phi=qphi)\n\n        mean_ex, var_ex = sample_normal_expectations(\n            lambda X, P, XP: XP, correction=-np.linalg.det(hbar * A[:, [0, 3]][[0, 3]])\n        )\n        assert np.allclose(mean, mean_ex, atol=tol, rtol=0)\n        assert np.allclose(var, var_ex, atol=tol, rtol=0)\n\n    def test_arbitrary_quadratic(\n        self, setup_backend, tol, pure, sample_normal_expectations, hbar\n    ):\n        """"""Test that the correct result is returned for E(c0 x^2 + c1 p^2 + c2 xp + c3 x + c4 p + k) on a displaced squeezed state""""""\n        backend = setup_backend(3)\n        backend.reset(cutoff_dim=CUTOFF, pure=pure)\n\n        c0 = 1 / np.sqrt(2)\n        c1 = 3\n        c2 = 0.53\n        c3 = 1 / 3.0\n        c4 = -1\n\n        # define the arbitrary quadratic\n        A = np.zeros([6, 6])\n        A[0, 0] = c0\n        A[3, 3] = c1\n\n        A[3, 0] = c2 / 2\n        A[0, 3] = c2 / 2\n\n        # define the linear combination and constant term\n        d = np.array([c3, 0, 0, c4, 0, 0])\n        k = 5\n\n        # prepare a displaced squeezed state\n        backend.prepare_displaced_squeezed_state(a, r, phi, 0)\n\n        state = backend.state()\n        mean, var = state.poly_quad_expectation(A, d, k, phi=qphi)\n\n        mean_ex, var_ex = sample_normal_expectations(\n            lambda X, P, XP: c0 * X ** 2 + c1 * P ** 2 + c2 * XP + c3 * X + c4 * P + k,\n            correction=-np.linalg.det(hbar * A[:, [0, 3]][[0, 3]]),\n        )\n\n        assert np.allclose(mean, mean_ex, atol=tol, rtol=0)\n        assert np.allclose(var, var_ex, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""fock"", ""gaussian"")\nclass TestMultiModePolyQuadratureExpectations:\n    """"""Test multi mode poly_quad_expectation methods""""""\n\n    def test_three_mode_arbitrary(self, setup_backend, pure, hbar, tol):\n        """"""Test that the correct result is returned for an arbitrary quadratic polynomial""""""\n        backend = setup_backend(3)\n        # increase the cutoff to 7 for accuracy\n        backend.reset(cutoff_dim=7, pure=pure)\n\n        # fmt:off\n        A = np.array([[ 0.7086495 , -0.39299695,  0.30536448,  0.48822049,  0.64987373, 0.7020327 ],\n                      [-0.39299695,  0.0284145 ,  0.53202656,  0.20232385,  0.26288656, 0.20772833],\n                      [ 0.30536448,  0.53202656,  0.28126466,  0.64192545, -0.36583748, 0.51704656],\n                      [ 0.48822049,  0.20232385,  0.64192545,  0.51033017,  0.29129713, 0.77103581],\n                      [ 0.64987373,  0.26288656, -0.36583748,  0.29129713,  0.37646972, 0.2383589 ],\n                      [ 0.7020327 ,  0.20772833,  0.51704656,  0.77103581,  0.2383589 ,-0.96494418]])\n\n        # fmt:on\n        d = np.array(\n            [0.71785224, -0.80064627, 0.08799823, 0.76189805, 0.99665321, -0.60777437]\n        )\n        k = 0.123\n\n        a_list = [0.044 + 0.023j, 0.0432 + 0.123j, -0.12 + 0.04j]\n        r_list = [0.1065, 0.032, -0.123]\n        phi_list = [0.897, 0.31, 0.432]\n\n        mu = np.zeros([6])\n        cov = np.zeros([6, 6])\n\n        # squeeze and displace each mode\n        for i, (a_, r_, phi_) in enumerate(zip(a_list, r_list, phi_list)):\n            backend.prepare_displaced_squeezed_state(a_, r_, phi_, i)\n            mu[2 * i : 2 * i + 2] = (\n                R(qphi).T @ np.array([a_.real, a_.imag]) * np.sqrt(2 * hbar)\n            )\n            cov[2 * i : 2 * i + 2, 2 * i : 2 * i + 2] = (\n                R(qphi).T @ utils.squeezed_cov(r_, phi_, hbar=hbar) @ R(qphi)\n            )\n\n        # apply a beamsplitter to the modes\n        backend.beamsplitter(1 / np.sqrt(2), 1 / np.sqrt(2), 0, 1)\n        backend.beamsplitter(1 / np.sqrt(2), 1 / np.sqrt(2), 1, 2)\n\n        state = backend.state()\n        mean, var = state.poly_quad_expectation(A, d, k, phi=qphi)\n\n        # apply a beamsplitter to vector of means and covariance matrices\n        t = 1 / np.sqrt(2)\n        BS = np.array([[t, 0, -t, 0], [0, t, 0, -t], [t, 0, t, 0], [0, t, 0, t]])\n\n        S1 = block_diag(BS, np.identity(2))\n        S2 = block_diag(np.identity(2), BS)\n\n        C = changebasis(3)\n        mu = C.T @ S2 @ S1 @ mu\n        cov = C.T @ S2 @ S1 @ cov @ S1.T @ S2.T @ C\n\n        modes = list(np.arange(6).reshape(2, -1).T)\n\n        mean_ex = np.trace(A @ cov) + mu @ A @ mu + mu @ d + k\n        var_ex = (\n            2 * np.trace(A @ cov @ A @ cov)\n            + 4 * mu.T @ A.T @ cov @ A @ mu\n            + d.T @ cov @ d\n            + 2 * mu.T @ A.T @ cov @ d\n            + 2 * d.T @ cov @ A @ mu\n            - np.sum([np.linalg.det(hbar * A[:, m][n]) for m in modes for n in modes])\n        )\n\n        assert np.allclose(mean, mean_ex, atol=tol, rtol=0)\n        assert np.allclose(var, var_ex, atol=tol, rtol=0)\n'"
tests/backend/test_states_probabilities.py,2,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the states.py fock probabilities methods""""""\nimport pytest\n\nimport numpy as np\nimport tensorflow as tf\nfrom scipy.special import factorial as fac\n\nfrom strawberryfields import backends\nfrom strawberryfields import utils\n\n\nMAG_ALPHAS = np.linspace(0, 0.8, 3)\nPHASE_ALPHAS = np.linspace(0, 2 * np.pi, 3, endpoint=False)\n\n\n@pytest.mark.parametrize(""a"", MAG_ALPHAS)\n@pytest.mark.parametrize(""phi"", PHASE_ALPHAS)\nclass TestFockProbabilities:\n    """"""Tests for the fock_prob state method""""""\n\n    def test_gaussian(self, a, phi, setup_backend, cutoff, tol):\n        """"""Tests that probabilities of particular Fock states\n        |n> are correct for a gaussian state.""""""\n        backend = setup_backend(1)\n\n        alpha = a * np.exp(1j * phi)\n        n = np.arange(cutoff)\n        ref_state = np.exp(-0.5 * np.abs(alpha) ** 2) * alpha ** n / np.sqrt(fac(n))\n        ref_probs = np.abs(ref_state) ** 2\n\n        backend.prepare_coherent_state(alpha, 0)\n        state = backend.state()\n\n        for n in range(cutoff):\n            prob_n = state.fock_prob([n])\n            assert np.allclose(prob_n, ref_probs[n], atol=tol, rtol=0)\n\n    @pytest.mark.backends(""fock"", ""tf"")\n    def test_nongaussian(self, a, phi, setup_backend, cutoff, tol):\n        """"""Tests that probabilities of particular Fock states |n> are\n        correct for a nongaussian state.""""""\n        backend = setup_backend(2)\n\n        alpha = a * np.exp(1j * phi)\n        n = np.arange(cutoff)\n        ref_state = np.exp(-0.5 * np.abs(alpha) ** 2) * alpha ** n / np.sqrt(fac(n))\n        ref_probs = np.abs(ref_state) ** 2\n\n        backend.prepare_coherent_state(alpha, 0)\n        backend.prepare_fock_state(cutoff // 2, 1)\n        state = backend.state()\n\n        for n in range(cutoff):\n            prob_n = state.fock_prob([n, cutoff // 2])\n            assert np.allclose(prob_n, ref_probs[n], atol=tol, rtol=0)\n\n\n@pytest.mark.parametrize(""a"", MAG_ALPHAS)\n@pytest.mark.parametrize(""phi"", PHASE_ALPHAS)\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestAllFockProbs:\n    """"""Tests for the all_fock_probs state method""""""\n\n    def test_pure(self, a, phi, setup_backend, cutoff, batch_size, tol):\n        """"""Tests that the numeric probabilities in the full Fock basis are\n        correct for a one-mode pure state.""""""\n        backend = setup_backend(1)\n\n        alpha = a * np.exp(1j * phi)\n        n = np.arange(cutoff)\n        ref_state = np.exp(-0.5 * np.abs(alpha) ** 2) * alpha ** n / np.sqrt(fac(n))\n        ref_probs = np.abs(ref_state) ** 2\n\n        backend.prepare_coherent_state(alpha, 0)\n        state = backend.state()\n        \n        probs = state.all_fock_probs()\n        if isinstance(probs, tf.Tensor):\n            probs = probs.numpy()\n        probs = probs.flatten()\n\n        if batch_size is not None:\n            ref_probs = np.tile(ref_probs, batch_size)\n\n        assert np.allclose(probs, ref_probs, atol=tol, rtol=0)\n\n    def test_two_mode_gaussian(self, a, phi, setup_backend, batch_size, cutoff, tol):\n        """"""Tests that the numeric probabilities in the full Fock basis are\n        correct for a two-mode gaussian state.""""""\n        if a == 0.0:\n            pytest.skip(""Test only runs for states with non-zero displacement"")\n\n        backend = setup_backend(2)\n\n        alpha = a * np.exp(1j * phi)\n\n        n = np.arange(cutoff)\n        ref_state1 = np.exp(-0.5 * np.abs(alpha) ** 2) * alpha ** n / np.sqrt(fac(n))\n        ref_state2 = (\n            np.exp(-0.5 * np.abs(-alpha) ** 2) * (-alpha) ** n / np.sqrt(fac(n))\n        )\n\n        ref_state = np.outer(ref_state1, ref_state2)\n        ref_probs = np.abs(np.reshape(ref_state ** 2, -1))\n\n        if batch_size is not None:\n            ref_probs = np.tile(ref_probs, batch_size)\n\n        backend.prepare_coherent_state(alpha, 0)\n        backend.prepare_coherent_state(-alpha, 1)\n        state = backend.state()\n\n        for n in range(cutoff):\n            for m in range(cutoff):\n                probs = state.all_fock_probs()\n                if isinstance(probs, tf.Tensor):\n                    probs = probs.numpy()\n                \n                assert np.allclose(probs.flatten(), ref_probs, atol=tol, rtol=0)\n'"
tests/backend/test_states_wigner.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the states.py Wigner method""""""\nimport pytest\n\nimport numpy as np\nfrom scipy.stats import multivariate_normal\n\nfrom strawberryfields import backends\nfrom strawberryfields import utils\nfrom strawberryfields.backends.shared_ops import rotation_matrix as rotm\n\n\nA = 0.3 + 0.1j\nR = 0.23\nPHI = 0.123\n\n# wigner parameters\nXMIN = -5\nXMAX = 5\nDX = 0.1\nXVEC = np.arange(XMIN, XMAX, DX)\n\nX, P = np.meshgrid(XVEC, XVEC)\nGRID = np.empty(X.shape + (2,))\nGRID[:, :, 0] = X\nGRID[:, :, 1] = P\n\n\n@pytest.fixture(autouse=True)\ndef skip_if_batched(batch_size):\n    """"""Skip this test if in batch mode""""""\n    if batch_size is not None:\n        pytest.skip(""Wigner tests skipped in batch mode"")\n\n\ndef wigner(GRID, mu, cov):\n    """"""Generate the PDF distribution of a normal distribution""""""\n    mvn = multivariate_normal(mu, cov, allow_singular=True)\n    return mvn.pdf(GRID)\n\n\ndef test_vacuum(setup_backend, hbar, tol):\n    """"""Test Wigner function for a Vacuum state is a standard\n    normal Gaussian""""""\n    backend = setup_backend(1)\n    state = backend.state()\n    W = state.wigner(0, XVEC, XVEC)\n\n    # exact wigner function\n    mu = [0, 0]\n    cov = np.identity(2) * hbar / 2.0\n    Wexact = wigner(GRID, mu, cov)\n\n    assert np.allclose(W, Wexact, atol=tol, rtol=0)\n\n\ndef test_squeezed_coherent(setup_backend, hbar, tol):\n    """"""Test Wigner function for a squeezed coherent state\n    matches the analytic result""""""\n    backend = setup_backend(1)\n    backend.prepare_coherent_state(A, 0)\n    backend.squeeze(R * np.exp(1j * PHI), 0)\n\n    state = backend.state()\n    W = state.wigner(0, XVEC, XVEC)\n    rot = rotm(PHI / 2)\n\n    # exact wigner function\n    alpha = A * np.cosh(R) - np.conjugate(A) * np.exp(1j * PHI) * np.sinh(R)\n    mu = np.array([alpha.real, alpha.imag]) * np.sqrt(2 * hbar)\n    cov = np.diag([np.exp(-2 * R), np.exp(2 * R)])\n    cov = np.dot(rot, np.dot(cov, rot.T)) * hbar / 2.0\n    Wexact = wigner(GRID, mu, cov)\n\n    assert np.allclose(W, Wexact, atol=0.01, rtol=0)\n\n\ndef test_two_mode_squeezed(setup_backend, hbar, tol):\n    """"""Test Wigner function for a two mode squeezed state\n    matches the analytic result""""""\n    backend = setup_backend(2)\n    backend.prepare_squeezed_state(R, 0, 0)\n    backend.prepare_squeezed_state(-R, 0, 1)\n\n    state = backend.state()\n    W0 = state.wigner(0, XVEC, XVEC)\n    W1 = state.wigner(1, XVEC, XVEC)\n\n    # exact wigner function\n    mu = np.array([0, 0]) * np.sqrt(2 * hbar)\n    cov = np.diag([np.exp(-2 * R), np.exp(2 * R)]) * hbar / 2\n    W0exact = wigner(GRID, mu, cov)\n\n    cov = np.diag([np.exp(2 * R), np.exp(-2 * R)]) * hbar / 2\n    W1exact = wigner(GRID, mu, cov)\n\n    assert np.allclose(W0, W0exact, atol=0.01, rtol=0)\n    assert np.allclose(W1, W1exact, atol=0.01, rtol=0)\n\ndef fock_1_state_quad(setup_backend, hbar, tol):\n    """"""Test the quadrature probability distribution\n    functions for the |1> Fock state""""""\n    backend = setup_backend(1)\n    backend.prepare_fock_state(1, 0)\n\n    state = backend.state()\n\n    x_vals = state.x_quad_values(0, XVEC, XVEC)\n    p_vals = state.p_quad_values(0, XVEC, XVEC)\n\n    #Exact probability distribution\n    def exact(a):\n        return 0.5 * np.sqrt(1/(np.pi * hbar)) * np.exp(-1*(a**2)/hbar) * (4/hbar)*(a**2)\n\n    exact_x = np.array([exact(x) for x in XVEC])\n    exact_p = np.array([exact(p) for p in XVEC])\n\n    assert np.allclose(x_vals, exact_x, atol=tol, rtol=0)\n    assert np.allclose(p_vals, exact_p, atol=tol, rtol=0)\n\ndef vacuum_state_quad(setup_backend, hbar, tol):\n    """"""Test the quadrature probability distribution\n    functions for the vacuum state""""""\n    backend = setup_backend(1)\n    backend.prepare_vacuum_state(0)\n\n    state = backend.state()\n\n    x_vals = state.x_quad_values(0, XVEC, XVEC)\n    p_vals = state.p_quad_values(0, XVEC, XVEC)\n\n    #Exact probability distribution\n    def exact(a):\n        return np.sqrt(1/(np.pi * hbar)) * np.exp(-1*(a**2)/hbar)\n\n    exact_x = np.array([exact(x) for x in XVEC])\n    exact_p = np.array([exact(p) for p in XVEC])\n\n    assert np.allclose(x_vals, exact_x, atol=tol, rtol=0)\n    assert np.allclose(p_vals, exact_p, atol=tol, rtol=0)\n\ndef coherent_state_quad(setup_backend, hbar, tol):\n    """"""Test the quadrature probability distribution\n    functions for the coherent state with alpha = 1""""""\n    backend = setup_backend(1)\n    backend.prepare_coherent_state(1, 0)\n\n    state = backend.state()\n\n    x_vals = state.x_quad_values(0, XVEC, XVEC)\n    p_vals = state.p_quad_values(0, XVEC, XVEC)\n\n    #Exact probability distribution\n    def x_exact(a):\n        return np.sqrt(1/(np.pi * hbar)) * np.exp(-1*((a - 0.5 * np.sqrt(2 * hbar))**2)/hbar)\n    def p_exact(a):\n        return np.sqrt(1 / (np.pi * hbar)) * np.exp(-1 * (a ** 2) / hbar)\n\n    exact_x = np.array([x_exact(x) for x in XVEC])\n    exact_p = np.array([p_exact(p) for p in XVEC])\n\n    assert np.allclose(x_vals, exact_x, atol=tol, rtol=0)\n    assert np.allclose(p_vals, exact_p, atol=tol, rtol=0)\n'"
tests/backend/test_tf_import.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for TensorFlow 2.x version checking""""""\nfrom importlib import reload\nimport sys\n\nimport pytest\n\nimport strawberryfields as sf\n\n\ntry:\n    import tensorflow\nexcept (ImportError, ModuleNotFoundError):\n    tf_available = False\n    import mock\n    tensorflow = mock.Mock(__version__=""1.12.2"")\nelse:\n    tf_available = True\n\n\nclass TestBackendImport:\n    """"""Test importing the backend directly""""""\n\n    def test_incorrect_tf_version(self, monkeypatch):\n        """"""Test that an exception is raised if the version\n        of TensorFlow installed is not version 2.x""""""\n        with monkeypatch.context() as m:\n            # force Python check to pass\n            m.setattr(""sys.version_info"", (3, 6, 3))\n            m.setattr(tensorflow, ""__version__"", ""1.12.2"")\n\n            with pytest.raises(ImportError, match=""version 2.x of TensorFlow is required""):\n                reload(sf.backends.tfbackend)\n\n    @pytest.mark.skipif(tf_available, reason=""Test only works if TF not installed"")\n    def test_tensorflow_not_installed(self, monkeypatch):\n        """"""Test that an exception is raised if TensorFlow is not installed""""""\n        with monkeypatch.context() as m:\n            # force Python check to pass\n            m.setattr(""sys.version_info"", (3, 6, 3))\n\n            with pytest.raises(ImportError, match=""version 2.x of TensorFlow is required""):\n                reload(sf.backends.tfbackend)\n\n\n@pytest.mark.frontend\nclass TestFrontendImport:\n    """"""Test importing via the frontend""""""\n\n    def test_incorrect_tf_version(self, monkeypatch):\n        """"""Test that an exception is raised if the version\n        of TensorFlow installed is not version 2.x""""""\n        with monkeypatch.context() as m:\n            # force Python check to pass\n            m.setattr(""sys.version_info"", (3, 6, 3))\n            m.setattr(tensorflow, ""__version__"", ""1.12.2"")\n\n            with pytest.raises(ImportError, match=""version 2.x of TensorFlow is required""):\n                reload(sf.backends.tfbackend)\n                sf.LocalEngine(\'tf\')\n\n    @pytest.mark.skipif(tf_available, reason=""Test only works if TF not installed"")\n    def test_tensorflow_not_installed(self, monkeypatch):\n        """"""Test that an exception is raised if TensorFlow is not installed""""""\n        with monkeypatch.context() as m:\n            # force Python check to pass\n            m.setattr(""sys.version_info"", (3, 6, 3))\n\n            with pytest.raises(ImportError, match=""version 2.x of TensorFlow is required""):\n                reload(sf.backends.tfbackend)\n                sf.LocalEngine(\'tf\')\n'"
tests/backend/test_threshold_measurement.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""Unit tests for measurements in the Fock basis""""""\nimport pytest\n\nimport numpy as np\n\n\nNUM_REPEATS = 50\n\n\n@pytest.mark.backends(""gaussian"")\nclass TestGaussianRepresentation:\n    """"""Tests that make use of the Fock basis representation.""""""\n\n    def measure_threshold_gaussian_warning(self, setup_backend):\n        """"""Tests the warning message when MeasureThreshold is called.""""""\n\n        backend = setup_backend(3)\n\n        with pytest.warns(Warning, match=""Cannot simulate non-Gaussian states. Conditional state after ""\n                                         ""Threshold measurement has not been updated.""):\n            backend.measure_threshold([0, 1], shots=5)\n\n\n@pytest.mark.backends(""gaussian"")\nclass TestRepresentationIndependent:\n    """"""Basic implementation-independent tests.""""""\n\n    def test_two_mode_squeezed_measurements(self, setup_backend, pure):\n        """"""Tests Threshold measurement on the two mode squeezed vacuum state.""""""\n        for _ in range(NUM_REPEATS):\n            backend = setup_backend(2)\n            backend.reset(pure=pure)\n\n            r = 0.25\n            # Circuit to prepare two mode squeezed vacuum\n            backend.squeeze(-r, 0)\n            backend.squeeze(r, 1)\n            backend.beamsplitter(np.sqrt(0.5), -np.sqrt(0.5), 0, 1)\n            meas_modes = [0, 1]\n            meas_results = backend.measure_threshold(meas_modes)\n            assert np.all(meas_results[0] == meas_results[1])\n\n    def test_vacuum_measurements(self, setup_backend, pure):\n        """"""Tests Threshold measurement on the vacuum state.""""""\n        backend = setup_backend(3)\n\n        for _ in range(NUM_REPEATS):\n            backend.reset(pure=pure)\n\n            meas = backend.measure_threshold([0, 1, 2])[0]\n            assert np.all(np.array(meas) == 0)\n\n\n    def test_binary_outcome(self, setup_backend, pure):\n        """"""Test that the outcomes of a threshold measurement is zero or one.""""""\n        num_modes = 2\n        for _ in range(NUM_REPEATS):\n            backend = setup_backend(num_modes)\n            backend.reset(pure=pure)\n\n            r = 0.5\n            backend.squeeze(r, 0)\n            backend.beamsplitter(np.sqrt(0.5), -np.sqrt(0.5), 0, 1)\n            meas_modes = [0, 1]\n            meas_results = backend.measure_threshold(meas_modes)\n\n            for i in range(num_modes):\n                assert meas_results[i] == 0 or meas_results[i] == 1\n\n\n\n'"
tests/backend/test_twomode_squeezing_operation.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nUnit tests for two-mode squeezing operation\nConvention: The squeezing unitary is fixed to be\nU(z) = \\exp(0.5 (z^* \\hat{a}_1\\hat{a}_2 - z (\\hat{a^\\dagger}_1\\hat{a}_2)))\nwhere \\hat{a} is the photon annihilation operator.\n""""""\n# pylint: disable=too-many-arguments\nimport itertools as it\n\nimport pytest\nimport numpy as np\n\n\nPHASE = np.linspace(0, 2 * np.pi, 3, endpoint=False)\nMAG = np.linspace(0.0, 0.2, 5, endpoint=False)\nMODES = list(it.combinations(range(4), 2))\n\n\ndef get_amplitude(k, r, p):\n    """""" Get amplitude for two mode squeezing operation\n\n    Args:\n        k (tuple): fock state numbers for two modes\n        r (float): two-mode squeezing magnitude\n        p (float): two-mode squeezing phase\n\n    Returns:\n        float: the two-mode squeezed vacuum amplitude\n    """"""\n    if k[0] == k[1]:\n        tmsv = (np.exp(1j * p) * np.tanh(r)) ** k[0] / np.cosh(r)\n        return tmsv\n    return 0.0\n\n\n@pytest.mark.backends(""fock"")\nclass TestTwomodeSqueezing:\n    """"""Tests two-mode squeezing operation""""""\n\n    @pytest.mark.parametrize(""r"", MAG)\n    @pytest.mark.parametrize(""p"", PHASE)\n    def test_two_mode_squeezing(self, setup_backend, r, p, cutoff, pure, tol):\n        r"""""" Test two-mode squeezing on vacuum-state for both pure states and\n        mixed states with the amplitude given by\n\t        :math:`\\delta_{kl} \\frac{e^{in\\phi} \\tanh^n{r}}{\\cosh{r}}`\n        """"""\n        z = r * np.exp(1j * p)\n\n        backend = setup_backend(2)\n        backend.two_mode_squeeze(z, 0, 1)\n\n        state = backend.state()\n\n        if pure:\n            for k in it.product(range(cutoff), repeat=2):\n                tmsv = get_amplitude(k, r, p)\n                assert np.allclose(state.data[k], tmsv, atol=tol, rtol=0)\n        else:\n            for k in it.product(range(cutoff), repeat=2):\n                for l in it.product(range(cutoff), repeat=2):\n                    t = (k[0], l[0], k[1], l[1])\n                    tmsv2 = get_amplitude(k, r, p) * np.conj(get_amplitude(l, r, p))\n\n                    assert np.allclose(state.data[t], tmsv2, atol=tol, rtol=0)\n\n\n    @pytest.mark.parametrize(""r"", MAG)\n    @pytest.mark.parametrize(""p"", PHASE)\n    @pytest.mark.parametrize(""modes"", MODES)\n    def test_squeezing_on_mode_subset(self, setup_backend, r, p, modes, cutoff, pure, tol):\n        r"""""" Test two-mode squeezing on vacuum-state for both pure states and\n        mixed states on different mode subsets with the amplitude given by\n\t        :math:`\\delta_{kl} \\frac{e^{in\\phi} \\tanh^n{r}}{\\cosh{r}}`\n        """"""\n        z = r * np.exp(1j * p)\n\n        backend = setup_backend(4)\n        backend.two_mode_squeeze(z, *modes)\n\n        state = backend.state()\n\n        state_data = state.reduced_dm(list(modes))\n\n        for k in it.product(range(cutoff), repeat=2):\n            for l in it.product(range(cutoff), repeat=2):\n                t = (k[0], l[0], k[1], l[1])\n                tmsv2 = get_amplitude(k, r, p) * np.conj(get_amplitude(l, r, p))\n\n                assert np.allclose(state_data[t], tmsv2, atol=tol, rtol=0)\n'"
tests/frontend/test_about.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""\nUnit tests for top-level Strawberry Fields functions.\n""""""\nimport pytest\nimport re\nimport strawberryfields as sf\n\n\npytestmark = pytest.mark.frontend\n\n\ndef test_about(capfd):\n    """"""sf.about works.""""""\n    sf.about()\n    out, err = capfd.readouterr()\n    # substantial output (actual length varies)\n    assert len(err) == 0\n    assert len(out) > 300\n\n    assert ""Strawberry Fields version"" in out\n    sf_version_match = re.search(r""Strawberry Fields version:\\s+([\\S]+)\\n"", out).group(1)\n    assert sf_version_match == sf.version()\n\n    assert ""Numpy version"" in out\n    assert ""Scipy version"" in out\n    assert ""The Walrus version"" in out\n    assert ""Blackbird version"" in out\n\n\n\ndef test_cite(capfd):\n    """"""sf.cite works.""""""\n    sf.cite()\n    out, err = capfd.readouterr()\n    # correct output\n    assert len(err) == 0\n    assert len(out) == 431\n'"
tests/frontend/test_circuitdrawer.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the circuit drawer""""""\nimport sys\nimport os\nimport datetime\nimport difflib\nfrom textwrap import dedent\n\nimport pytest\n\npytestmark = pytest.mark.frontend\n\nimport strawberryfields as sf\nfrom strawberryfields import ops\n\nfrom strawberryfields.circuitdrawer import Circuit as CircuitDrawer\nfrom strawberryfields.circuitdrawer import (\n    UnsupportedGateException,\n    NotDrawableException,\n    ModeMismatchException,\n)\n\n\nLINE_RETURN = ""\\n""\nWIRE_TERMINATOR = r""\\\\"" + ""\\n""\nCIRCUIT_BODY_TERMINATOR = ""}\\n""\nCIRCUIT_BODY_START = "" {"" + ""\\n""\nBEGIN_DOCUMENT = r""\\begin{document}""\nEMPTY_PAGESTYLE = r""\\pagestyle{empty}""\nDOCUMENT_CLASS = r""\\documentclass{article}""\nQCIRCUIT_PACKAGE = r""\\usepackage{qcircuit}""\nCIRCUIT_START = r""\\Qcircuit""\nCOLUMN_SPACING = ""@C={0}""\nROW_SPACING = ""@R={0}""\nQUANTUM_WIRE = r""\\qw""\nINIT_DOCUMENT = (\n    DOCUMENT_CLASS + ""\\n"" + EMPTY_PAGESTYLE + ""\\n"" + QCIRCUIT_PACKAGE + ""\\n"" + BEGIN_DOCUMENT + ""\\n"" + CIRCUIT_START\n)\n\n\n@pytest.fixture\ndef drawer():\n    """"""Returns a 3 mode circuit drawer""""""\n    return CircuitDrawer(3)\n\n\ndef failure_message(result, expected):\n    """"""Build failure message with explicit error latex diff.\n\n    Args:\n        result (str): the latex resulting from a test.\n        expected (str): the expected latex output.\n\n    Returns:\n        str: failure message.\n    """"""\n    return ""Discrepancies in circuit builder tex output: \\\n    {0}"".format(\n        LINE_RETURN + LINE_RETURN.join(difflib.ndiff([result], [expected]))\n    )\n\n\nclass TestCircuitDrawerClass:\n    """"""Direct tests of the CircuitDrawer class""""""\n\n    def test_end_wire(self, drawer):\n        drawer._end_wire()\n        assert drawer._document.endswith(WIRE_TERMINATOR)\n\n    def test_end_circuit(self, drawer):\n        drawer._end_circuit()\n        assert drawer._document.endswith(CIRCUIT_BODY_TERMINATOR)\n\n    def test_begin_circuit(self, drawer):\n        drawer._begin_circuit()\n        assert drawer._document.endswith(CIRCUIT_BODY_START)\n\n    def test_init_document(self, drawer):\n        drawer._init_document()\n        assert drawer._document.endswith(INIT_DOCUMENT)\n\n    def test_set_row_spacing(self, drawer):\n        drawer._set_row_spacing(""1em"")\n        assert drawer._row_spacing == ""1em""\n\n    def test_set_column_spacing(self, drawer):\n        drawer._set_column_spacing(""2em"")\n        assert drawer._column_spacing == ""2em""\n\n    def test_apply_spacing(self, drawer):\n        drawer._set_row_spacing(""1em"")\n        drawer._set_column_spacing(""2em"")\n        drawer._apply_spacing()\n        assert drawer._pad_with_spaces(COLUMN_SPACING.format(""2em"")) in drawer._document\n        assert drawer._pad_with_spaces(ROW_SPACING.format(""1em"")) in drawer._document\n\n    def test_op_applications(self, drawer):\n        drawer._x(0)\n        drawer._z(0)\n        drawer._cx(0, 1)\n        drawer._cz(0, 1)\n        drawer._bs(0, 1)\n        drawer._s2(0, 1)\n        drawer._ck(0, 1)\n        drawer._k(0)\n        drawer._v(0)\n        drawer._p(0)\n        drawer._r(0)\n        drawer._s(0)\n        drawer._d(0)\n\n        expected_circuit_matrix = [\n            [\n                ""\\\\gate{X}"",\n                ""\\\\gate{Z}"",\n                ""\\\\ctrl{1}"",\n                ""\\\\ctrl{1}"",\n                ""\\\\multigate{1}{BS}"",\n                ""\\\\multigate{1}{S}"",\n                ""\\\\ctrl{1}"",\n                ""\\\\gate{K}"",\n                ""\\\\gate{V}"",\n                ""\\\\gate{P}"",\n                ""\\\\gate{R}"",\n                ""\\\\gate{S}"",\n                ""\\\\gate{D}"",\n            ],\n            [""\\\\qw""] * 2\n            + [""\\\\targ"", ""\\\\gate{Z}"", ""\\\\ghost{BS}"", ""\\\\ghost{S}"", ""\\\\gate{K}""]\n            + [""\\\\qw""] * 6,\n            [""\\\\qw""] * 13,\n        ]\n\n        assert drawer._circuit_matrix == expected_circuit_matrix\n\n    def test_add_column(self, drawer):\n        drawer._add_column()\n        for wire in drawer._circuit_matrix:\n            assert wire[-1] == QUANTUM_WIRE\n\n    def test_on_empty_column(self, drawer):\n        drawer._add_column()\n        assert drawer._on_empty_column()\n\n    def test_mode_mismatch(self, drawer):\n        class Fakeop:\n            r""""""\n            Fake operation used to test mode mismatch handling, a beam splitter with only one\n            register reference.\n            """"""\n\n            def __init__(self):\n                self.reg = [sf.program.RegRef(0)]\n                Fakeop.__name__ = ""Command""\n\n            # Custom string representation necessary to trick the circuitdrawer\n            # into executing the unsupported operation.\n            def __repr__(self):\n                return ""BSgate | (q[0])""\n\n        with pytest.raises(ModeMismatchException):\n            drawer.parse_op(Fakeop())\n\n\nclass TestEngineIntegration:\n    """"""Tests for calling the circuit drawer via the engine""""""\n\n    def test_one_mode_gates_from_operators(self, drawer):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Xgate(1) | (q[0])\n            ops.Zgate(1) | (q[0])\n            ops.Kgate(1) | (q[0])\n            ops.Vgate(1) | (q[0])\n            ops.Pgate(1) | (q[0])\n            ops.Rgate(1) | (q[0])\n            ops.Sgate(1) | (q[0])\n            ops.Dgate(1) | (q[0])\n\n        for op in prog.circuit:\n            method, mode = drawer._gate_from_operator(op)\n            assert callable(method) and hasattr(drawer, method.__name__)\n            assert mode == 1\n\n    def test_two_mode_gates_from_operators(self, drawer):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.CXgate(1) | (q[0], q[1])\n            ops.CZgate(1) | (q[0], q[1])\n            ops.BSgate(1) | (q[0], q[1])\n            ops.S2gate(1) | (q[0], q[1])\n            ops.CKgate(1) | (q[0], q[1])\n\n        for op in prog.circuit:\n            method, mode = drawer._gate_from_operator(op)\n            assert callable(method) and hasattr(drawer, method.__name__)\n            assert mode == 2\n\n    def test_parse_op(self, drawer):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Xgate(1) | (q[0])\n            ops.Zgate(1) | (q[0])\n            ops.CXgate(1) | (q[0], q[1])\n            ops.CZgate(1) | (q[0], q[1])\n            ops.BSgate(0, 1) | (q[0], q[1])\n            ops.S2gate(0, 1) | (q[0], q[1])\n            ops.CKgate(1) | (q[0], q[1])\n            ops.Kgate(1) | (q[0])\n            ops.Vgate(1) | (q[0])\n            ops.Pgate(1) | (q[0])\n            ops.Rgate(1) | (q[0])\n            ops.Sgate(1) | (q[0])\n            ops.Dgate(1) | (q[0])\n\n        for op in prog.circuit:\n            drawer.parse_op(op)\n\n        expected_circuit_matrix = [\n            [\n                ""\\\\gate{X}"",\n                ""\\\\gate{Z}"",\n                ""\\\\ctrl{1}"",\n                ""\\\\ctrl{1}"",\n                ""\\\\multigate{1}{BS}"",\n                ""\\\\multigate{1}{S}"",\n                ""\\\\ctrl{1}"",\n                ""\\\\gate{K}"",\n                ""\\\\gate{V}"",\n                ""\\\\gate{P}"",\n                ""\\\\gate{R}"",\n                ""\\\\gate{S}"",\n                ""\\\\gate{D}"",\n            ],\n            [""\\\\qw""] * 2\n            + [""\\\\targ"", ""\\\\gate{Z}"", ""\\\\ghost{BS}"", ""\\\\ghost{S}"", ""\\\\gate{K}""]\n            + [""\\\\qw""] * 6,\n            [""\\\\qw""] * 13,\n        ]\n\n        assert drawer._circuit_matrix == expected_circuit_matrix\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_fourier(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Fourier | (q[0])\n\n        fourier_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\gate{F}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == fourier_output, failure_message(result, fourier_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_x_0(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Xgate(1) | (q[0])\n\n        x_test_0_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\gate{X}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == x_test_0_output, failure_message(result, x_test_0_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_x_1(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Xgate(1) | (q[1])\n\n        x_test_1_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\qw  & \\qw \\\\\n             & \\gate{X}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == x_test_1_output, failure_message(result, x_test_1_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_xx_1(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Xgate(1) | (q[1])\n            ops.Xgate(1) | (q[1])\n\n        xx_test_1_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\qw  & \\qw  & \\qw \\\\\n             & \\gate{X}  & \\gate{X}  & \\qw \\\\\n             & \\qw  & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == xx_test_1_output, failure_message(result, xx_test_1_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_x_z_0(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Xgate(1) | (q[0])\n            ops.Zgate(1) | (q[0])\n\n        x_z_test_0_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\gate{X}  & \\gate{Z}  & \\qw \\\\\n             & \\qw  & \\qw  & \\qw \\\\\n             & \\qw  & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == x_z_test_0_output, failure_message(result, x_z_test_0_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_x_0_z_1(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Xgate(1) | (q[0])\n            ops.Zgate(1) | (q[1])\n\n        x_0_z_1_test_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\gate{X}  & \\qw \\\\\n             & \\gate{Z}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == x_0_z_1_test_output, failure_message(result, x_0_z_1_test_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_z_0(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Zgate(1) | (q[0])\n\n        z_test_0_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\gate{Z}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == z_test_0_output, failure_message(result, z_test_0_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_z_1(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Zgate(1) | (q[1])\n\n        z_test_1_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\qw  & \\qw \\\\\n             & \\gate{Z}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == z_test_1_output, failure_message(result, z_test_1_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_zz_1(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Zgate(1) | (q[1])\n            ops.Zgate(1) | (q[1])\n\n        zz_test_1_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\qw  & \\qw  & \\qw \\\\\n             & \\gate{Z}  & \\gate{Z}  & \\qw \\\\\n             & \\qw  & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == zz_test_1_output, failure_message(result, zz_test_1_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_cx(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.CXgate(1) | (q[0], q[1])\n\n        cx_test_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\ctrl{1}  & \\qw \\\\\n             & \\targ  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == cx_test_output, failure_message(result, cx_test_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_cz(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.CZgate(1) | (q[0], q[1])\n\n        cz_test_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\ctrl{1}  & \\qw \\\\\n             & \\gate{Z}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == cz_test_output, failure_message(result, cz_test_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_bs(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.BSgate(0, 1) | (q[0], q[1])\n\n        bs_test_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\multigate{1}{BS}  & \\qw \\\\\n             & \\ghost{BS}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == bs_test_output, failure_message(result, bs_test_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_s2(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.S2gate(1) | (q[0], q[1])\n\n        s2_test_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\multigate{1}{S}  & \\qw \\\\\n             & \\ghost{S}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == s2_test_output, failure_message(result, s2_test_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_ck(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.CKgate(1) | (q[0], q[1])\n\n        ck_test_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\ctrl{1}  & \\qw \\\\\n             & \\gate{K}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == ck_test_output, failure_message(result, ck_test_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_k_0(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Kgate(1) | (q[0])\n\n        k_test_0_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\gate{K}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == k_test_0_output, failure_message(result, k_test_0_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_k_1(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Kgate(1) | (q[1])\n\n        k_test_1_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\qw  & \\qw \\\\\n             & \\gate{K}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == k_test_1_output, failure_message(result, k_test_1_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_v_0(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Vgate(1) | (q[0])\n\n        v_test_0_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\gate{V}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == v_test_0_output, failure_message(result, v_test_0_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_v_1(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Vgate(1) | (q[1])\n\n        v_test_1_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\qw  & \\qw \\\\\n             & \\gate{V}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == v_test_1_output, failure_message(result, v_test_1_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_p_0(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Pgate(1) | (q[0])\n\n        p_test_0_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\gate{P}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == p_test_0_output, failure_message(result, p_test_0_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_p_1(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Pgate(1) | (q[1])\n\n        p_test_1_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\qw  & \\qw \\\\\n             & \\gate{P}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == p_test_1_output, failure_message(result, p_test_1_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_r_0(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Rgate(1) | (q[0])\n\n        r_test_0_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\gate{R}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == r_test_0_output, failure_message(result, r_test_0_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_r_1(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Rgate(1) | (q[1])\n\n        r_test_1_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\qw  & \\qw \\\\\n             & \\gate{R}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == r_test_1_output, failure_message(result, r_test_1_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_s_0(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Sgate(1) | (q[0])\n\n        s_test_0_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\gate{S}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == s_test_0_output, failure_message(result, s_test_0_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_s_1(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Sgate(1) | (q[1])\n\n        s_test_1_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\qw  & \\qw \\\\\n             & \\gate{S}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == s_test_1_output, failure_message(result, s_test_1_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_d_0(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Dgate(1) | (q[0])\n\n        d_test_0_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\gate{D}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == d_test_0_output, failure_message(result, d_test_0_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_d_1(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Dgate(1) | (q[1])\n\n        d_test_1_output = dedent(\n            r""""""            \\documentclass{article}\n            \\pagestyle{empty}\n            \\usepackage{qcircuit}\n            \\begin{document}\n            \\Qcircuit {\n             & \\qw  & \\qw \\\\\n             & \\gate{D}  & \\qw \\\\\n             & \\qw  & \\qw \\\\\n            }\n            \\end{document}""""""\n        )\n\n        result = prog.draw_circuit(tex_dir=tmpdir)[1]\n        assert result == d_test_1_output, failure_message(result, d_test_1_output)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_not_drawable(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.BSgate(0, 2) | (q[0], q[2])\n\n        with pytest.raises(NotDrawableException):\n            prog.draw_circuit(tex_dir=tmpdir)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_unsupported_gate(self, tmpdir):\n        prog = sf.Program(3)\n\n        class Fakegate(ops.Gate):\n            r""""""Extension of the base Gate class to use to test\n            unsupported operation handling.""""""\n\n            def __init__(self):\n                super().__init__([0])\n\n            def _apply(self, reg, backend, **kwargs):\n                pass\n\n        with prog.context as q:\n            Fakegate() | (q[0])\n\n        with pytest.raises(UnsupportedGateException):\n            prog.draw_circuit(tex_dir=tmpdir)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_compile(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Dgate(1) | (q[1])\n            ops.Rgate(1) | (q[1])\n            ops.S2gate(1) | (q[0], q[1])\n\n        document = prog.draw_circuit(tex_dir=tmpdir)[0]\n\n        file_name = ""output_{0}.tex"".format(\n            datetime.datetime.now().strftime(""%Y_%B_%d_%I:%M%p"")\n        )\n        assert document.split(""/"")[-1] == file_name\n\n        output_file = tmpdir.join(file_name)\n        assert os.path.isfile(output_file)\n\n    @pytest.mark.skipif(\n        sys.version_info < (3, 6), reason=""tmpdir fixture requires Python >=3.6""\n    )\n    def test_compile_custom_dir(self, tmpdir):\n        prog = sf.Program(3)\n\n        with prog.context as q:\n            ops.Dgate(1) | (q[1])\n            ops.Rgate(1) | (q[1])\n            ops.S2gate(1) | (q[0], q[1])\n\n        subdir = tmpdir.join(""subdir"")\n        document = prog.draw_circuit(tex_dir=subdir)[0]\n\n        file_name = ""output_{0}.tex"".format(\n            datetime.datetime.now().strftime(""%Y_%B_%d_%I:%M%p"")\n        )\n        assert document.split(""/"")[-1] == file_name\n\n        output_file = subdir.join(file_name)\n        assert os.path.isfile(output_file)\n'"
tests/frontend/test_circuitspecs.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the CircuitSpec class""""""\nimport textwrap\n\nimport pytest\n\nfrom strawberryfields.circuitspecs.circuit_specs import CircuitSpecs\n\n\npytestmark = pytest.mark.frontend\n\n\nclass TestAbstractCircuitSpec:\n\t""""""Tests for the abstract CircuitSpec class.\n\tThis class primarily consists of abstract methods,\n\tso only the methods containing logic are tested.\n\t""""""\n\n\tdef test_no_parameter_ranges(self):\n\t\t""""""If not defined, the parameter_ranges property\n\t\tshould return an empty dictionary.""""""\n\n\t\tclass DummyCircuit(CircuitSpecs):\n\t\t\t""""""Dummy circuit used to instantiate\n\t\t\tthe abstract base class""""""\n\t\t\tmodes = 0\n\t\t\tremote = False\n\t\t\tlocal = True\n\t\t\tinteractive = True\n\t\t\tprimitives = set()\n\t\t\tdecompositions = set()\n\n\t\tdummy = DummyCircuit()\n\n\t\tassert isinstance(dummy.parameter_ranges, dict)\n\t\tassert not dummy.parameter_ranges\n\n\tdef test_program_topology_construction(self):\n\t\t""""""If a circuit spec includes a Blackbird program,\n\t\tthe topology property should return the equivalent\n\t\tdirected acyclic graph.\n\t\t""""""\n\n\t\tclass DummyCircuit(CircuitSpecs):\n\t\t\t""""""Dummy circuit used to instantiate\n\t\t\tthe abstract base class""""""\n\t\t\tmodes = 0\n\t\t\tremote = False\n\t\t\tlocal = True\n\t\t\tinteractive = True\n\t\t\tprimitives = set()\n\t\t\tdecompositions = set()\n\n\t\t\tcircuit = textwrap.dedent(\n\t\t\t\t""""""\\\n\t\t\t\tname test\n\t\t\t\tversion 0.0\n\n\t\t\t\tSgate(0.543, 0) | 0\n\t\t\t\tDgate(-7.123) | 1\n\t\t\t\tBSgate(0.54) | 0, 1\n\t\t\t\tMeasureFock() | 0\n\t\t\t\tMeasureFock() | 2\n\t\t\t\t""""""\n\t\t\t)\n\n\t\tdummy = DummyCircuit()\n\t\ttop = dummy.graph\n\n\t\tcircuit = top.nodes().data()\n\n\t\t# check circuit is correct length\n\t\tassert len(circuit) == 5\n\n\t\t# check gates are correct\n\t\tassert circuit[0][\'name\'] == \'Sgate\'\n\t\tassert circuit[1][\'name\'] == \'Dgate\'\n\t\tassert circuit[2][\'name\'] == \'BSgate\'\n\t\tassert circuit[3][\'name\'] == \'MeasureFock\'\n\t\tassert circuit[4][\'name\'] == \'MeasureFock\'\n\n\t\t# check topology/edges between nodes\n\t\tedges = {(i, j) for i, j, d in top.edges().data()}\n\t\tassert edges == {(0, 2), (1, 2), (2, 3)}\n\n\tdef test_template_topology_construction(self):\n\t\t""""""If a circuit spec includes a Blackbird template,\n\t\tthe topology property should return the equivalent\n\t\tdirected acyclic graph, with all parameters set to zero.\n\t\t""""""\n\n\t\tclass DummyCircuit(CircuitSpecs):\n\t\t\t""""""Dummy circuit used to instantiate\n\t\t\tthe abstract base class""""""\n\t\t\tmodes = 0\n\t\t\tremote = False\n\t\t\tlocal = True\n\t\t\tinteractive = True\n\t\t\tprimitives = set()\n\t\t\tdecompositions = set()\n\n\t\t\tcircuit = textwrap.dedent(\n\t\t\t\t""""""\\\n\t\t\t\tname test\n\t\t\t\tversion 0.0\n\n\t\t\t\tSgate({sq}, 0) | 0\n\t\t\t\tDgate(-7.123) | 1\n\t\t\t\tBSgate({theta}) | 0, 1\n\t\t\t\tMeasureFock() | 0\n\t\t\t\tMeasureFock() | 2\n\t\t\t\t""""""\n\t\t\t)\n\n\t\tdummy = DummyCircuit()\n\t\ttop = dummy.graph\n\n\t\tcircuit = top.nodes().data()\n\n\t\t# check circuit is correct length\n\t\tassert len(circuit) == 5\n\n\t\t# check gates are correct\n\t\tassert circuit[0][\'name\'] == \'Sgate\'\n\t\tassert circuit[1][\'name\'] == \'Dgate\'\n\t\tassert circuit[2][\'name\'] == \'BSgate\'\n\t\tassert circuit[3][\'name\'] == \'MeasureFock\'\n\t\tassert circuit[4][\'name\'] == \'MeasureFock\'\n\n\t\t# check arguments\n\t\tassert circuit[0][\'args\'] == [0, 0]\n\t\tassert circuit[1][\'args\'] == [-7.123]\n\t\tassert circuit[2][\'args\'] == [0]\n\n\t\t# check topology/edges between nodes\n\t\tedges = {(i, j) for i, j, d in top.edges().data()}\n\t\tassert edges == {(0, 2), (1, 2), (2, 3)}\n'"
tests/frontend/test_circuitspecs_X12.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the CircuitSpec class""""""\nimport textwrap\n\nimport pytest\nimport numpy as np\nimport networkx as nx\nfrom scipy.linalg import block_diag\n\nimport blackbird\n\nimport strawberryfields as sf\nimport strawberryfields.ops as ops\n\nfrom strawberryfields.parameters import par_evaluate\nfrom strawberryfields.program_utils import CircuitError, list_to_DAG\nfrom strawberryfields.io import to_program\nfrom strawberryfields.utils import random_interferometer\nfrom strawberryfields.circuitspecs.X12 import X12_01, X12_02, CircuitSpecs\nfrom strawberryfields.circuitspecs.gaussian_unitary import GaussianUnitary\n\n\npytestmark = pytest.mark.frontend\n\nnp.random.seed(42)\n\nSQ_AMPLITUDE = 1\n""""""float: the allowed squeezing amplitude""""""\n\n\ndef TMS(r, phi):\n    """"""Two-mode squeezing.\n\n    Args:\n        r (float): squeezing magnitude\n        phi (float): rotation parameter\n\n    Returns:\n        array: symplectic transformation matrix\n    """"""\n    cp = np.cos(phi)\n    sp = np.sin(phi)\n    ch = np.cosh(r)\n    sh = np.sinh(r)\n\n    S = np.array(\n        [\n            [ch, cp * sh, 0, sp * sh],\n            [cp * sh, ch, sp * sh, 0],\n            [0, sp * sh, ch, -cp * sh],\n            [sp * sh, 0, -cp * sh, ch],\n        ]\n    )\n\n    return S\n\n\ndef program_equivalence(prog1, prog2, compare_params=True, atol=1e-6, rtol=0):\n    r""""""Checks if two programs are equivalent.\n\n    This function converts the program lists into directed acyclic graphs,\n    and runs the NetworkX `is_isomorphic` graph function in order\n    to determine if the two programs are equivalent.\n\n    Note: when checking for parameter equality between two parameters\n    :math:`a` and :math:`b`, we use the following formula:\n\n    .. math:: |a - b| \\leq (\\texttt{atol} + \\texttt{rtol}\\times|b|)\n\n    Args:\n        prog1 (strawberryfields.program.Program): quantum program\n        prog2 (strawberryfields.program.Program): quantum program\n        compare_params (bool): Set to ``False`` to turn of comparing\n            program parameters; equivalency will only take into\n            account the operation order.\n        atol (float): the absolute tolerance parameter for checking\n            quantum operation parameter equality\n        rtol (float): the relative tolerance parameter for checking\n            quantum operation parameter equality\n\n    Returns:\n        bool: returns ``True`` if two quantum programs are equivalent\n    """"""\n    DAG1 = list_to_DAG(prog1.circuit)\n    DAG2 = list_to_DAG(prog2.circuit)\n\n    circuit = []\n    for G in [DAG1, DAG2]:\n        # relabel the DAG nodes to integers\n        circuit.append(nx.convert_node_labels_to_integers(G))\n\n        # add node attributes to store the operation name and parameters\n        name_mapping = {i: n.op.__class__.__name__ for i, n in enumerate(G.nodes())}\n        parameter_mapping = {i: par_evaluate(n.op.p) for i, n in enumerate(G.nodes())}\n\n        # CXgate and BSgate are not symmetric wrt permuting the order of the two\n        # modes it acts on; i.e., the order of the wires matter\n        wire_mapping = {}\n        for i, n in enumerate(G.nodes()):\n            if n.op.__class__.__name__ == ""CXgate"":\n                if np.allclose(n.op.p[0], 0):\n                    # if the CXgate parameter is 0, wire order doesn\'t matter\n                    wire_mapping[i] = 0\n                else:\n                    # if the CXgate parameter is not 0, order matters\n                    wire_mapping[i] = [j.ind for j in n.reg]\n\n            elif n.op.__class__.__name__ == ""BSgate"":\n                if np.allclose([j % np.pi for j in par_evaluate(n.op.p)], [np.pi/4, np.pi/2]):\n                    # if the beamsplitter is *symmetric*, then the order of the\n                    # wires does not matter.\n                    wire_mapping[i] = 0\n                else:\n                    # beamsplitter is not symmetric, order matters\n                    wire_mapping[i] = [j.ind for j in n.reg]\n\n            else:\n                # not a CXgate or a BSgate, order of wires doesn\'t matter\n                wire_mapping[i] = 0\n\n        # TODO: at the moment, we do not check for whether an empty\n        # wire will match an operation with trivial parameters.\n        # Maybe we can do this in future, but this is a subgraph\n        # isomorphism problem and much harder.\n\n        nx.set_node_attributes(circuit[-1], name_mapping, name=""name"")\n        nx.set_node_attributes(circuit[-1], parameter_mapping, name=""p"")\n        nx.set_node_attributes(circuit[-1], wire_mapping, name=""w"")\n\n    def node_match(n1, n2):\n        """"""Returns True if both nodes have the same name and\n        same parameters, within a certain tolerance""""""\n        name_match = n1[""name""] == n2[""name""]\n        p_match = np.allclose(n1[""p""], n2[""p""], atol=atol, rtol=rtol)\n        wire_match = n1[""w""] == n2[""w""]\n\n        if compare_params:\n            return name_match and p_match and wire_match\n\n        return name_match and wire_match\n\n    # check if circuits are equivalent\n    return nx.is_isomorphic(circuit[0], circuit[1], node_match)\n\n\nclass DummyCircuit(CircuitSpecs):\n    """"""Dummy circuit used to instantiate\n    the abstract base class""""""\n\n    modes = 12\n    remote = False\n    local = True\n    interactive = True\n    primitives = {""S2gate"", ""MeasureFock"", ""Rgate"", ""BSgate"", ""MZgate""}\n    decompositions = {""Interferometer"": {}}\n\n@pytest.mark.parametrize(""chip"", [X12_01, X12_02])\nclass TestX12Compilation:\n    """"""Tests for compilation using the Chip2 circuit specification""""""\n\n    def test_exact_template(self, chip, tol):\n        """"""Test compilation works for the exact circuit""""""\n        bb = blackbird.loads(chip.circuit)\n        bb = bb(\n            squeezing_amplitude_0=SQ_AMPLITUDE,\n            squeezing_amplitude_1=SQ_AMPLITUDE,\n            squeezing_amplitude_2=SQ_AMPLITUDE,\n            squeezing_amplitude_3=SQ_AMPLITUDE,\n            squeezing_amplitude_4=SQ_AMPLITUDE,\n            squeezing_amplitude_5=SQ_AMPLITUDE,\n            phase_0=0,\n            phase_1=1,\n            phase_2=2,\n            phase_3=3,\n            phase_4=4,\n            phase_5=5,\n            phase_6=6,\n            phase_7=7,\n            phase_8=8,\n            phase_9=9,\n            phase_10=10,\n            phase_11=11,\n            phase_12=12,\n            phase_13=13,\n            phase_14=14,\n            phase_15=15,\n            phase_16=16,\n            phase_17=17,\n            phase_18=18,\n            phase_19=19,\n            phase_20=20,\n            phase_21=21,\n            phase_22=22,\n            phase_23=23,\n            phase_24=24,\n            phase_25=25,\n            phase_26=26,\n            phase_27=27,\n            phase_28=28,\n            phase_29=29,\n            final_phase_0=1.24,\n            final_phase_1=-0.54,\n            final_phase_2=4.12,\n            final_phase_3=0,\n            final_phase_4=1.24,\n            final_phase_5=-0.54,\n            final_phase_6=4.12,\n            final_phase_7=0,\n            final_phase_8=1.24,\n            final_phase_9=-0.54,\n            final_phase_10=4.12,\n            final_phase_11=0,\n\n        )\n\n        expected = to_program(bb)\n        res = expected.compile(chip.short_name)\n\n        assert program_equivalence(res, expected, atol=tol)\n\n    def test_not_all_modes_measured(self, chip):\n        """"""Test exceptions raised if not all modes are measured""""""\n        prog = sf.Program(12)\n        U = random_interferometer(6)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[7])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[8])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[9])\n            ops.S2gate(SQ_AMPLITUDE) | (q[4], q[10])\n            ops.S2gate(SQ_AMPLITUDE) | (q[5], q[11])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3], q[4], q[5])\n            ops.Interferometer(U) | (q[6], q[7], q[8], q[9], q[10], q[11])\n            ops.MeasureFock() | (q[0], q[1])\n\n        with pytest.raises(CircuitError, match=""All modes must be measured""):\n            res = prog.compile(chip.short_name)\n\n    def test_no_s2gates(self, chip, tol):\n        """"""Test identity S2gates are inserted when no S2gates\n        are provided.""""""\n        prog = sf.Program(12)\n        U = random_interferometer(6)\n\n        with prog.context as q:\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3], q[4], q[5])\n            ops.Interferometer(U) | (q[6], q[7], q[8], q[9], q[10], q[11])\n            ops.MeasureFock() | q\n\n        expected = sf.Program(12)\n\n        with expected.context as q:\n            ops.S2gate(0) | (q[0], q[6])\n            ops.S2gate(0) | (q[1], q[7])\n            ops.S2gate(0) | (q[2], q[8])\n            ops.S2gate(0) | (q[3], q[9])\n            ops.S2gate(0) | (q[4], q[10])\n            ops.S2gate(0) | (q[5], q[11])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3], q[4], q[5])\n            ops.Interferometer(U) | (q[6], q[7], q[8], q[9], q[10], q[11])\n            ops.MeasureFock() | q\n\n        res = prog.compile(chip.short_name)\n        expected = expected.compile(chip.short_name)\n        assert program_equivalence(res, expected, atol=tol)\n\n    def test_missing_s2gates(self, chip, tol):\n        """"""Test identity S2gates are inserted when some (but not all)\n        S2gates are included.""""""\n        prog = sf.Program(12)\n        U = random_interferometer(6)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[7])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[9])\n            ops.S2gate(SQ_AMPLITUDE) | (q[5], q[11])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3], q[4], q[5])\n            ops.Interferometer(U) | (q[6], q[7], q[8], q[9], q[10], q[11])\n            ops.MeasureFock() | q\n\n        expected = sf.Program(12)\n\n        with expected.context as q:\n            ops.S2gate(0) | (q[0], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[7])\n            ops.S2gate(0) | (q[2], q[8])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[9])\n            ops.S2gate(0) | (q[4], q[10])\n            ops.S2gate(SQ_AMPLITUDE) | (q[5], q[11])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3], q[4], q[5])\n            ops.Interferometer(U) | (q[6], q[7], q[8], q[9], q[10], q[11])\n            ops.MeasureFock() | q\n\n        res = prog.compile(chip.short_name)\n        expected = expected.compile(chip.short_name)\n        assert program_equivalence(res, expected, atol=tol)\n\n    def test_incorrect_s2gate_modes(self, chip):\n        """"""Test exceptions raised if S2gates do not appear on correct modes""""""\n        prog = sf.Program(12)\n        U = random_interferometer(6)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[1])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[3])\n            ops.S2gate(SQ_AMPLITUDE) | (q[4], q[8])\n            ops.S2gate(SQ_AMPLITUDE) | (q[6], q[9])\n            ops.S2gate(SQ_AMPLITUDE) | (q[8], q[10])\n            ops.S2gate(SQ_AMPLITUDE) | (q[10], q[11])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3], q[4], q[5])\n            ops.Interferometer(U) | (q[6], q[7], q[8], q[9], q[10], q[11])\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""S2gates do not appear on the correct modes""):\n            res = prog.compile(chip.short_name)\n\n    def test_incorrect_s2gate_params(self, chip):\n        """"""Test exceptions raised if S2gates have illegal parameters""""""\n        prog = sf.Program(12)\n        U = random_interferometer(6)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[6])\n            ops.S2gate(0) | (q[1], q[7])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[8])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[9])\n            ops.S2gate(SQ_AMPLITUDE) | (q[4], q[10])\n            ops.S2gate(SQ_AMPLITUDE+0.1) | (q[5], q[11])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3], q[4], q[5])\n            ops.Interferometer(U) | (q[6], q[7], q[8], q[9], q[10], q[11])\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=r""Incorrect squeezing value\\(s\\) \\(r, phi\\)={\\(1.1, 0.0\\)}""):\n            res = prog.compile(chip.short_name)\n\n    def test_s2gate_repeated_modes(self, chip):\n        """"""Test exceptions raised if S2gates are repeated""""""\n        prog = sf.Program(12)\n        U = random_interferometer(6)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[6])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3], q[4], q[5])\n            ops.Interferometer(U) | (q[6], q[7], q[8], q[9], q[10], q[11])\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""incompatible topology.""):\n            res = prog.compile(chip.short_name)\n\n    def test_gates_compile(self, chip):\n        """"""Test that combinations of MZgates, Rgates, and BSgates\n        correctly compile.""""""\n        prog = sf.Program(12)\n        U = random_interferometer(6)\n\n        def unitary(q):\n            ops.MZgate(0.5, 0.1) | (q[0], q[1])\n            ops.BSgate(0.1, 0.2) | (q[1], q[2])\n            ops.Rgate(0.4) | q[0]\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[7])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[8])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[9])\n            ops.S2gate(SQ_AMPLITUDE) | (q[4], q[10])\n            ops.S2gate(SQ_AMPLITUDE) | (q[5], q[11])\n            unitary(q[:6])\n            unitary(q[6:])\n            ops.MeasureFock() | q\n\n        res = prog.compile(chip.short_name)\n\n    def test_no_unitary(self, chip, tol):\n        """"""Test compilation works with no unitary provided""""""\n        prog = sf.Program(12)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[7])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[8])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[9])\n            ops.S2gate(SQ_AMPLITUDE) | (q[4], q[10])\n            ops.S2gate(SQ_AMPLITUDE) | (q[5], q[11])\n            ops.MeasureFock() | q\n\n        res = prog.compile(chip.short_name)\n        expected = sf.Program(12)\n\n        with expected.context as q:\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[0], q[6])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[1], q[7])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[2], q[8])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[3], q[9])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[4], q[10])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[5], q[11])\n\n            # corresponds to an identity on modes [0, 1, 2, 3, 4, 5]\n            # This can be easily seen from below by noting that:\n            # MZ(pi, pi) = R(0) = I\n            # MZ(pi, 0) @ MZ(pi, 0) = I\n            # [R(pi) \\otimes I] @ MZ(pi, 0) = I\n            ops.MZgate(np.pi, 0) | (q[0], q[1])\n            ops.MZgate(np.pi, 0) | (q[2], q[3])\n            ops.MZgate(np.pi, 0) | (q[4], q[5])\n            ops.MZgate(np.pi, np.pi) | (q[1], q[2])\n            ops.MZgate(np.pi, np.pi) | (q[3], q[4])\n\n            ops.MZgate(np.pi, 0) | (q[0], q[1])\n            ops.MZgate(np.pi, 0) | (q[2], q[3])\n            ops.MZgate(np.pi, 0) | (q[4], q[5])\n            ops.MZgate(np.pi, np.pi) | (q[1], q[2])\n            ops.MZgate(np.pi, np.pi) | (q[3], q[4])\n\n            ops.MZgate(np.pi, 0) | (q[0], q[1])\n            ops.MZgate(np.pi, np.pi) | (q[2], q[3])\n            ops.MZgate(np.pi, np.pi) | (q[4], q[5])\n            ops.MZgate(np.pi, np.pi) | (q[1], q[2])\n            ops.MZgate(np.pi, np.pi) | (q[3], q[4])\n\n            ops.Rgate(np.pi) | (q[0])\n            ops.Rgate(0) | (q[1])\n            ops.Rgate(0) | (q[2])\n            ops.Rgate(0) | (q[3])\n            ops.Rgate(0) | (q[4])\n            ops.Rgate(0) | (q[5])\n\n            # corresponds to an identity on modes [6, 7, 8, 9, 10, 11]\n            ops.MZgate(np.pi, 0) | (q[6], q[7])\n            ops.MZgate(np.pi, 0) | (q[8], q[9])\n            ops.MZgate(np.pi, 0) | (q[10], q[11])\n            ops.MZgate(np.pi, np.pi) | (q[7], q[8])\n            ops.MZgate(np.pi, np.pi) | (q[9], q[10])\n\n            ops.MZgate(np.pi, 0) | (q[6], q[7])\n            ops.MZgate(np.pi, 0) | (q[8], q[9])\n            ops.MZgate(np.pi, 0) | (q[10], q[11])\n            ops.MZgate(np.pi, np.pi) | (q[7], q[8])\n            ops.MZgate(np.pi, np.pi) | (q[9], q[10])\n\n            ops.MZgate(np.pi, 0) | (q[6], q[7])\n            ops.MZgate(np.pi, np.pi) | (q[8], q[9])\n            ops.MZgate(np.pi, np.pi) | (q[10], q[11])\n            ops.MZgate(np.pi, np.pi) | (q[7], q[8])\n            ops.MZgate(np.pi, np.pi) | (q[9], q[10])\n\n            ops.Rgate(np.pi) | (q[6])\n            ops.Rgate(0) | (q[7])\n            ops.Rgate(0) | (q[8])\n            ops.Rgate(0) | (q[9])\n            ops.Rgate(0) | (q[10])\n            ops.Rgate(0) | (q[11])\n\n            ops.MeasureFock() | q\n\n        # Check that the applied symplectic is correct\n\n        # remove the Fock measurements\n        res.circuit = res.circuit[:-1]\n\n        # extract the Gaussian symplectic matrix\n        O = res.compile(""gaussian_unitary"").circuit[0].op.p[0]\n\n        # construct the expected symplectic matrix corresponding\n        # to just the initial two mode squeeze gates\n        S = TMS(SQ_AMPLITUDE, 0)\n\n        expected = np.zeros([2*12, 2*12])\n        l = 12 // 2\n        ch = np.cosh(SQ_AMPLITUDE) * np.identity(l)\n        sh = np.sinh(SQ_AMPLITUDE) * np.identity(l)\n        zh = np.zeros([l, l])\n        expected = np.block([[ch, sh, zh, zh], [sh, ch, zh, zh], [zh, zh, ch, -sh], [zh, zh, -sh, ch]])\n\n        assert np.allclose(O, expected, atol=tol)\n\n    def test_interferometers(self, chip, tol):\n        """"""Test that the compilation correctly decomposes the interferometer using\n        the rectangular_symmetric mesh""""""\n        prog = sf.Program(12)\n        U = random_interferometer(6)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[0], q[6])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[1], q[7])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[2], q[8])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[3], q[9])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[4], q[10])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[5], q[11])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3], q[4], q[5])\n            ops.Interferometer(U) | (q[6], q[7], q[8], q[9], q[10], q[11])\n            ops.MeasureFock() | q\n\n        res = prog.compile(chip.short_name)\n\n        expected = sf.Program(12)\n\n        with expected.context as q:\n            for i, j in np.arange(12).reshape(2, -1).T:\n                ops.S2gate(SQ_AMPLITUDE, 0) | (q[i], q[j])\n\n            ops.Interferometer(U, mesh=""rectangular_symmetric"", drop_identity=False) | (q[0], q[1], q[2], q[3], q[4], q[5])\n            ops.Interferometer(U, mesh=""rectangular_symmetric"", drop_identity=False) | (q[6], q[7], q[8], q[9], q[10], q[11])\n            ops.MeasureFock() | q\n\n        expected = expected.compile(DummyCircuit())\n\n        assert program_equivalence(res, expected, atol=tol)\n\n    def test_unitaries_do_not_match(self, chip):\n        """"""Test exception raised if the unitary applied to modes [0, 1, 2, 3] is\n        different to the unitary applied to modes [4, 5, 6, 7]""""""\n        prog = sf.Program(12)\n        U = random_interferometer(6)\n\n        with prog.context as q:\n            for i, j in np.arange(12).reshape(2, -1).T:\n                ops.S2gate(SQ_AMPLITUDE, 0) | (q[i], q[j])\n\n            ops.Interferometer(U) | q[:6]\n            ops.Interferometer(U) | q[6:]\n            ops.BSgate() | (q[2], q[3])\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""must be identical to interferometer""):\n            res = prog.compile(chip.short_name)\n\n    def test_unitary_too_large(self, chip):\n        """"""Test exception raised if the unitary is applied to more\n        than just modes [0, 1, 2, 3] and [4, 5, 6, 7].""""""\n        prog = sf.Program(12)\n        U = random_interferometer(12)\n\n        with prog.context as q:\n            for i, j in np.arange(12).reshape(2, -1).T:\n                ops.S2gate(SQ_AMPLITUDE, 0) | (q[i], q[j])\n            ops.Interferometer(U) | q\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""must be applied separately""):\n            res = prog.compile(chip.short_name)\n'"
tests/frontend/test_circuitspecs_X8.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the CircuitSpec class""""""\nimport textwrap\n\nimport pytest\nimport numpy as np\nimport networkx as nx\nfrom scipy.linalg import block_diag\n\nimport blackbird\n\nimport strawberryfields as sf\nimport strawberryfields.ops as ops\n\nfrom strawberryfields.parameters import par_evaluate\nfrom strawberryfields.program_utils import CircuitError, list_to_DAG\nfrom strawberryfields.io import to_program\nfrom strawberryfields.utils import random_interferometer\nfrom strawberryfields.circuitspecs.X8 import X8_01, CircuitSpecs\n\n\npytestmark = pytest.mark.frontend\n\nnp.random.seed(42)\n\nSQ_AMPLITUDE = 1\n""""""float: the allowed squeezing amplitude""""""\n\n\ndef TMS(r, phi):\n    """"""Two-mode squeezing.\n\n    Args:\n        r (float): squeezing magnitude\n        phi (float): rotation parameter\n\n    Returns:\n        array: symplectic transformation matrix\n    """"""\n    cp = np.cos(phi)\n    sp = np.sin(phi)\n    ch = np.cosh(r)\n    sh = np.sinh(r)\n\n    S = np.array(\n        [\n            [ch, cp * sh, 0, sp * sh],\n            [cp * sh, ch, sp * sh, 0],\n            [0, sp * sh, ch, -cp * sh],\n            [sp * sh, 0, -cp * sh, ch],\n        ]\n    )\n\n    return S\n\n\ndef program_equivalence(prog1, prog2, compare_params=True, atol=1e-6, rtol=0):\n    r""""""Checks if two programs are equivalent.\n\n    This function converts the program lists into directed acyclic graphs,\n    and runs the NetworkX `is_isomorphic` graph function in order\n    to determine if the two programs are equivalent.\n\n    Note: when checking for parameter equality between two parameters\n    :math:`a` and :math:`b`, we use the following formula:\n\n    .. math:: |a - b| \\leq (\\texttt{atol} + \\texttt{rtol}\\times|b|)\n\n    Args:\n        prog1 (strawberryfields.program.Program): quantum program\n        prog2 (strawberryfields.program.Program): quantum program\n        compare_params (bool): Set to ``False`` to turn of comparing\n            program parameters; equivalency will only take into\n            account the operation order.\n        atol (float): the absolute tolerance parameter for checking\n            quantum operation parameter equality\n        rtol (float): the relative tolerance parameter for checking\n            quantum operation parameter equality\n\n    Returns:\n        bool: returns ``True`` if two quantum programs are equivalent\n    """"""\n    DAG1 = list_to_DAG(prog1.circuit)\n    DAG2 = list_to_DAG(prog2.circuit)\n\n    circuit = []\n    for G in [DAG1, DAG2]:\n        # relabel the DAG nodes to integers\n        circuit.append(nx.convert_node_labels_to_integers(G))\n\n        # add node attributes to store the operation name and parameters\n        name_mapping = {i: n.op.__class__.__name__ for i, n in enumerate(G.nodes())}\n        parameter_mapping = {i: par_evaluate(n.op.p) for i, n in enumerate(G.nodes())}\n\n        # CXgate and BSgate are not symmetric wrt permuting the order of the two\n        # modes it acts on; i.e., the order of the wires matter\n        wire_mapping = {}\n        for i, n in enumerate(G.nodes()):\n            if n.op.__class__.__name__ == ""CXgate"":\n                if np.allclose(n.op.p[0], 0):\n                    # if the CXgate parameter is 0, wire order doesn\'t matter\n                    wire_mapping[i] = 0\n                else:\n                    # if the CXgate parameter is not 0, order matters\n                    wire_mapping[i] = [j.ind for j in n.reg]\n\n            elif n.op.__class__.__name__ == ""BSgate"":\n                if np.allclose([j % np.pi for j in par_evaluate(n.op.p)], [np.pi/4, np.pi/2]):\n                    # if the beamsplitter is *symmetric*, then the order of the\n                    # wires does not matter.\n                    wire_mapping[i] = 0\n                else:\n                    # beamsplitter is not symmetric, order matters\n                    wire_mapping[i] = [j.ind for j in n.reg]\n\n            else:\n                # not a CXgate or a BSgate, order of wires doesn\'t matter\n                wire_mapping[i] = 0\n\n        # TODO: at the moment, we do not check for whether an empty\n        # wire will match an operation with trivial parameters.\n        # Maybe we can do this in future, but this is a subgraph\n        # isomorphism problem and much harder.\n\n        nx.set_node_attributes(circuit[-1], name_mapping, name=""name"")\n        nx.set_node_attributes(circuit[-1], parameter_mapping, name=""p"")\n        nx.set_node_attributes(circuit[-1], wire_mapping, name=""w"")\n\n    def node_match(n1, n2):\n        """"""Returns True if both nodes have the same name and\n        same parameters, within a certain tolerance""""""\n        name_match = n1[""name""] == n2[""name""]\n        p_match = np.allclose(n1[""p""], n2[""p""], atol=atol, rtol=rtol)\n        wire_match = n1[""w""] == n2[""w""]\n\n        if compare_params:\n            return name_match and p_match and wire_match\n\n        return name_match and wire_match\n\n    # check if circuits are equivalent\n    return nx.is_isomorphic(circuit[0], circuit[1], node_match)\n\n\nclass DummyCircuit(CircuitSpecs):\n    """"""Dummy circuit used to instantiate\n    the abstract base class""""""\n\n    modes = 8\n    remote = False\n    local = True\n    interactive = True\n    primitives = {""S2gate"", ""MeasureFock"", ""Rgate"", ""BSgate"", ""MZgate""}\n    decompositions = {""Interferometer"": {}}\n\n\nclass TestX8Compilation:\n    """"""Tests for compilation using the X8_01 circuit specification""""""\n\n    def test_exact_template(self, tol):\n        """"""Test compilation works for the exact circuit""""""\n        bb = blackbird.loads(X8_01.circuit)\n        bb = bb(\n            squeezing_amplitude_0=SQ_AMPLITUDE,\n            squeezing_amplitude_1=SQ_AMPLITUDE,\n            squeezing_amplitude_2=SQ_AMPLITUDE,\n            squeezing_amplitude_3=SQ_AMPLITUDE,\n            phase_0=0,\n            phase_1=1,\n            phase_2=2,\n            phase_3=3,\n            phase_4=4,\n            phase_5=5,\n            phase_6=6,\n            phase_7=7,\n            phase_8=8,\n            phase_9=9,\n            phase_10=10,\n            phase_11=11,\n            final_phase_0=1.24,\n            final_phase_1=-0.54,\n            final_phase_2=4.12,\n            final_phase_3=0,\n            final_phase_4=1.24,\n            final_phase_5=-0.54,\n            final_phase_6=4.12,\n            final_phase_7=0,\n        )\n\n        expected = to_program(bb)\n        res = expected.compile(""X8_01"")\n\n        assert program_equivalence(res, expected, atol=tol)\n\n    def test_not_all_modes_measured(self):\n        """"""Test exceptions raised if not all modes are measured""""""\n        prog = sf.Program(8)\n        U = random_interferometer(4)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[7])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3])\n            ops.Interferometer(U) | (q[4], q[5], q[6], q[7])\n            ops.MeasureFock() | (q[0], q[1])\n\n        with pytest.raises(CircuitError, match=""All modes must be measured""):\n            res = prog.compile(""X8_01"")\n\n    def test_no_s2gates(self, tol):\n        """"""Test identity S2gates are inserted when no S2gates\n        are provided.""""""\n        prog = sf.Program(8)\n        U = random_interferometer(4)\n\n        with prog.context as q:\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3])\n            ops.Interferometer(U) | (q[4], q[5], q[6], q[7])\n            ops.MeasureFock() | q\n\n        expected = sf.Program(8)\n\n        with expected.context as q:\n            ops.S2gate(0) | (q[0], q[4])\n            ops.S2gate(0) | (q[1], q[5])\n            ops.S2gate(0) | (q[2], q[6])\n            ops.S2gate(0) | (q[3], q[7])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3])\n            ops.Interferometer(U) | (q[4], q[5], q[6], q[7])\n            ops.MeasureFock() | q\n\n        res = prog.compile(""X8_01"")\n        expected = expected.compile(""X8_01"")\n        assert program_equivalence(res, expected, atol=tol)\n\n    def test_missing_s2gates(self, tol):\n        """"""Test identity S2gates are inserted when some (but not all)\n        S2gates are included.""""""\n        prog = sf.Program(8)\n        U = random_interferometer(4)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[7])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3])\n            ops.Interferometer(U) | (q[4], q[5], q[6], q[7])\n            ops.MeasureFock() | q\n\n        expected = sf.Program(8)\n\n        with expected.context as q:\n            ops.S2gate(0) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[5])\n            ops.S2gate(0) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[7])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3])\n            ops.Interferometer(U) | (q[4], q[5], q[6], q[7])\n            ops.MeasureFock() | q\n\n        res = prog.compile(""X8_01"")\n        expected = expected.compile(""X8_01"")\n        assert program_equivalence(res, expected, atol=tol)\n\n    def test_incorrect_s2gate_modes(self):\n        """"""Test exceptions raised if S2gates do not appear on correct modes""""""\n        prog = sf.Program(8)\n        U = random_interferometer(4)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[1])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[3])\n            ops.S2gate(SQ_AMPLITUDE) | (q[4], q[5])\n            ops.S2gate(SQ_AMPLITUDE) | (q[7], q[6])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3])\n            ops.Interferometer(U) | (q[4], q[5], q[6], q[7])\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""S2gates do not appear on the correct modes""):\n            res = prog.compile(""X8_01"")\n\n    def test_incorrect_s2gate_params(self):\n        """"""Test exceptions raised if S2gates have illegal parameters""""""\n        prog = sf.Program(8)\n        U = random_interferometer(4)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[4])\n            ops.S2gate(0) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE+0.1) | (q[3], q[7])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3])\n            ops.Interferometer(U) | (q[4], q[5], q[6], q[7])\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=r""Incorrect squeezing value\\(s\\) \\(r, phi\\)={\\(1.1, 0.0\\)}""):\n            res = prog.compile(""X8_01"")\n\n    def test_s2gate_repeated_modes(self):\n        """"""Test exceptions raised if S2gates are repeated""""""\n        prog = sf.Program(8)\n        U = random_interferometer(4)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[4])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3])\n            ops.Interferometer(U) | (q[4], q[5], q[6], q[7])\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""incompatible topology.""):\n            res = prog.compile(""X8_01"")\n\n    def test_gates_compile(self):\n        """"""Test that combinations of MZgates, Rgates, and BSgates\n        correctly compile.""""""\n        prog = sf.Program(8)\n        U = random_interferometer(4)\n\n        def unitary(q):\n            ops.MZgate(0.5, 0.1) | (q[0], q[1])\n            ops.BSgate(0.1, 0.2) | (q[1], q[2])\n            ops.Rgate(0.4) | q[0]\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[7])\n\n            unitary(q[:4])\n            unitary(q[4:])\n            ops.MeasureFock() | q\n\n        res = prog.compile(""X8_01"")\n\n    def test_no_unitary(self, tol):\n        """"""Test compilation works with no unitary provided""""""\n        prog = sf.Program(8)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[7])\n            ops.MeasureFock() | q\n\n        res = prog.compile(""X8_01"")\n        expected = sf.Program(8)\n\n        with expected.context as q:\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[3], q[7])\n\n            # corresponds to an identity on modes [0, 1, 2, 3]\n            # This can be easily seen from below by noting that:\n            # MZ(pi, pi) = R(0) = I\n            # MZ(pi, 0) @ MZ(pi, 0) = I\n            # [R(pi) \\otimes I] @ MZ(pi, 0) = I\n            ops.MZgate(np.pi, 0) | (q[0], q[1])\n            ops.MZgate(np.pi, 0) | (q[2], q[3])\n            ops.MZgate(np.pi, np.pi) | (q[1], q[2])\n            ops.MZgate(np.pi, 0) | (q[0], q[1])\n            ops.MZgate(np.pi, 0) | (q[2], q[3])\n            ops.MZgate(np.pi, np.pi) | (q[1], q[2])\n            ops.Rgate(0) | (q[0])\n            ops.Rgate(0) | (q[1])\n            ops.Rgate(0) | (q[2])\n            ops.Rgate(0) | (q[3])\n\n            # corresponds to an identity on modes [4, 5, 6, 7]\n            ops.MZgate(np.pi, 0) | (q[4], q[5])\n            ops.MZgate(np.pi, 0) | (q[6], q[7])\n            ops.MZgate(np.pi, np.pi) | (q[5], q[6])\n            ops.MZgate(np.pi, 0) | (q[4], q[5])\n            ops.MZgate(np.pi, 0) | (q[6], q[7])\n            ops.MZgate(np.pi, np.pi) | (q[5], q[6])\n            ops.Rgate(0) | (q[4])\n            ops.Rgate(0) | (q[5])\n            ops.Rgate(0) | (q[6])\n            ops.Rgate(0) | (q[7])\n\n            ops.MeasureFock() | q\n\n        assert program_equivalence(res, expected, atol=tol)\n\n        # double check that the applied symplectic is correct\n\n        # remove the Fock measurements\n        res.circuit = res.circuit[:-1]\n\n        # extract the Gaussian symplectic matrix\n        O = res.compile(""gaussian_unitary"").circuit[0].op.p[0]\n\n        # construct the expected symplectic matrix corresponding\n        # to just the initial two mode squeeze gates\n        S = TMS(SQ_AMPLITUDE, 0)\n\n        expected = np.zeros([2*8, 2*8])\n        idx = np.arange(2*8).reshape(4, 4).T\n        for i in idx:\n            expected[i.reshape(-1, 1), i.reshape(1, -1)] = S\n\n        assert np.allclose(O, expected, atol=tol)\n\n    def test_mz_gate_standard(self, tol):\n        """"""Test that the Mach-Zehnder gate compiles to give the correct unitary\n        for some specific standard parameters""""""\n        prog = sf.Program(8)\n\n        with prog.context as q:\n            ops.MZgate(np.pi/2, np.pi) | (q[0], q[1])\n            ops.MZgate(np.pi, 0) | (q[2], q[3])\n            ops.MZgate(np.pi/2, np.pi) | (q[4], q[5])\n            ops.MZgate(np.pi, 0) | (q[6], q[7])\n            ops.MeasureFock() | q\n\n        # compile the program using the X8_01 spec\n        res = prog.compile(""X8_01"")\n\n        # remove the Fock measurements\n        res.circuit = res.circuit[:-1]\n\n        # extract the Gaussian symplectic matrix\n        O = res.compile(""gaussian_unitary"").circuit[0].op.p[0]\n\n        # By construction, we know that the symplectic matrix is\n        # passive, and so represents a unitary matrix\n        U = O[:8, :8] + 1j*O[8:, :8]\n\n        # the constructed program should implement the following\n        # unitary matrix\n        expected = np.array(\n            [[0.5-0.5j, -0.5+0.5j, 0, 0],\n             [0.5-0.5j, 0.5-0.5j, 0, 0],\n             [0,  0, -1, -0],\n             [0,  0, -0, 1]]\n        )\n        expected = block_diag(expected, expected)\n\n        assert np.allclose(U, expected, atol=tol)\n\n    @pytest.mark.parametrize(""theta1"", np.linspace(0, 2*np.pi-0.2, 7))\n    @pytest.mark.parametrize(""phi1"", np.linspace(0, 2*np.pi-0.1, 7))\n    def test_mz_gate_non_standard(self, theta1, phi1, tol):\n        """"""Test that the Mach-Zehnder gate compiles to give the correct unitary\n        for a variety of non-standard angles""""""\n        prog = sf.Program(8)\n\n        theta2 = np.pi/13\n        phi2 = 3*np.pi/7\n\n        with prog.context as q:\n            ops.MZgate(theta1, phi1) | (q[0], q[1])\n            ops.MZgate(theta2, phi2) | (q[2], q[3])\n            ops.MZgate(theta1, phi1) | (q[4], q[5])\n            ops.MZgate(theta2, phi2) | (q[6], q[7])\n            ops.MeasureFock() | q\n\n        # compile the program using the X8_01 spec\n        res = prog.compile(""X8_01"")\n\n        # remove the Fock measurements\n        res.circuit = res.circuit[:-1]\n\n        # extract the Gaussian symplectic matrix\n        O = res.compile(""gaussian_unitary"").circuit[0].op.p[0]\n\n        # By construction, we know that the symplectic matrix is\n        # passive, and so represents a unitary matrix\n        U = O[:8, :8] + 1j*O[8:, :8]\n\n        # the constructed program should implement the following\n        # unitary matrix\n        expected = np.array([\n            [(np.exp(1j * phi1) * (-1 + np.exp(1j * theta1))) / 2.0, 0.5j * (1 + np.exp(1j * theta1)), 0, 0],\n            [0.5j * np.exp(1j * phi1) * (1 + np.exp(1j * theta1)), (1 - np.exp(1j * theta1)) / 2.0, 0, 0],\n            [0, 0, (np.exp(1j * phi2) * (-1 + np.exp(1j * theta2))) / 2.0, 0.5j * (1 + np.exp(1j * theta2))],\n            [0, 0, 0.5j * np.exp(1j * phi2) * (1 + np.exp(1j * theta2)), (1 - np.exp(1j * theta2)) / 2.0],\n        ])\n        expected = block_diag(expected, expected)\n\n        assert np.allclose(U, expected, atol=tol)\n\n\n    def test_interferometers(self, tol):\n        """"""Test that the compilation correctly decomposes the interferometer using\n        the rectangular_symmetric mesh""""""\n        prog = sf.Program(8)\n        U = random_interferometer(4)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[3], q[7])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3])\n            ops.Interferometer(U) | (q[4], q[5], q[6], q[7])\n            ops.MeasureFock() | q\n\n        res = prog.compile(""X8_01"")\n\n        expected = sf.Program(8)\n\n        with expected.context as q:\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[3], q[7])\n            ops.Interferometer(U, mesh=""rectangular_symmetric"", drop_identity=False) | (q[0], q[1], q[2], q[3])\n            ops.Interferometer(U, mesh=""rectangular_symmetric"", drop_identity=False) | (q[4], q[5], q[6], q[7])\n            ops.MeasureFock() | q\n\n        expected = expected.compile(DummyCircuit())\n\n        assert program_equivalence(res, expected, atol=tol)\n\n    def test_unitaries_do_not_match(self):\n        """"""Test exception raised if the unitary applied to modes [0, 1, 2, 3] is\n        different to the unitary applied to modes [4, 5, 6, 7]""""""\n        prog = sf.Program(8)\n        U = random_interferometer(4)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[3], q[7])\n            ops.Interferometer(U) | (q[0], q[1], q[2], q[3])\n            ops.Interferometer(U) | (q[4], q[5], q[6], q[7])\n            ops.BSgate() | (q[2], q[3])\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""must be identical to interferometer""):\n            res = prog.compile(""X8_01"")\n\n    def test_unitary_too_large(self):\n        """"""Test exception raised if the unitary is applied to more\n        than just modes [0, 1, 2, 3] and [4, 5, 6, 7].""""""\n        prog = sf.Program(8)\n        U = random_interferometer(8)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[3], q[7])\n            ops.Interferometer(U) | q\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""must be applied separately""):\n            res = prog.compile(""X8_01"")\n'"
tests/frontend/test_circuitspecs_gaussianunitary.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\r\n\r\n# Licensed under the Apache License, Version 2.0 (the ""License"");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an ""AS IS"" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\nr""""""Unit tests for the GaussianUnitary class""""""\r\n\r\nimport pytest\r\nimport numpy as np\r\n\r\nimport strawberryfields as sf\r\nimport strawberryfields.ops as ops\r\nfrom strawberryfields.utils import random_symplectic\r\n\r\npytestmark = pytest.mark.frontend\r\n\r\nnp.random.seed(42)\r\n\r\n\r\ndef random_params(size, sq_bound, disp_bound):\r\n    """"""Returns random parameters of a Gaussian circuit\r\n\r\n    Args:\r\n        size (int): number of modes\r\n        sq_bound (float): maximum value of the squeezing\r\n        disp_bound (float): maximum value of the displacement in absolute value\r\n\r\n    Returns:\r\n        tuple: Gaussian circuit parameters\r\n\r\n    """"""\r\n    A = np.random.rand(size, size) + 1j * np.random.rand(size, size)\r\n    U, s, V = np.linalg.svd(A)\r\n    s = sq_bound * s / (np.max(s))\r\n    alphas = disp_bound * ((np.random.rand(size) - 0.5) + 1j * (np.random.rand(size) - 0.5))\r\n    return U, s, V, alphas\r\n\r\n\r\n@pytest.mark.parametrize(""depth"", [1, 3, 6])\r\n@pytest.mark.parametrize(""width"", [5, 10, 15])\r\ndef test_gaussian_program(depth, width):\r\n    """"""Tests that a circuit and its compiled version produce the same Gaussian state""""""\r\n    eng = sf.LocalEngine(backend=""gaussian"")\r\n    eng1 = sf.LocalEngine(backend=""gaussian"")\r\n    circuit = sf.Program(width)\r\n    with circuit.context as q:\r\n        for _ in range(depth):\r\n            U, s, V, alphas = random_params(width, 2.0 / depth, 1.0)\r\n            ops.Interferometer(U) | q\r\n            for i in range(width):\r\n                ops.Sgate(s[i]) | q[i]\r\n            ops.Interferometer(V) | q\r\n            for i in range(width):\r\n                ops.Dgate(alphas[i]) | q[i]\r\n    compiled_circuit = circuit.compile(""gaussian_unitary"")\r\n    cv = eng.run(circuit).state.cov()\r\n    mean = eng.run(circuit).state.means()\r\n\r\n    cv1 = eng1.run(compiled_circuit).state.cov()\r\n    mean1 = eng1.run(compiled_circuit).state.means()\r\n    assert np.allclose(cv, cv1)\r\n    assert np.allclose(mean, mean1)\r\n\r\n\r\n@pytest.mark.parametrize(""depth"", [1, 2, 3])\r\n@pytest.mark.parametrize(""width"", [5, 10])\r\ndef test_symplectic_composition(depth, width):\r\n    """"""Tests that symplectic operations are composed correctly""""""\r\n    eng = sf.LocalEngine(backend=""gaussian"")\r\n    eng1 = sf.LocalEngine(backend=""gaussian"")\r\n    circuit = sf.Program(width)\r\n    Snet = np.identity(2 * width)\r\n    with circuit.context as q:\r\n        for _ in range(depth):\r\n            S = random_symplectic(width, scale = 0.2)\r\n            Snet = S @ Snet\r\n            ops.GaussianTransform(S) | q\r\n    compiled_circuit = circuit.compile(""gaussian_unitary"")\r\n    assert np.allclose(compiled_circuit.circuit[0].op.p[0], Snet)\r\n\r\n\r\n@pytest.mark.parametrize(""depth"", [1, 2, 3])\r\ndef test_modes_subset(depth):\r\n    """"""Tests that the compiler recognizes which modes are not being modified and acts accordingly""""""\r\n\r\n    width = 10\r\n    eng = sf.LocalEngine(backend=""gaussian"")\r\n    eng1 = sf.LocalEngine(backend=""gaussian"")\r\n    circuit = sf.Program(width)\r\n    indices = (1, 4, 2, 6, 7)\r\n    active_modes = len(indices)\r\n    with circuit.context as q:\r\n        for _ in range(depth):\r\n            U, s, V, _ = random_params(active_modes, 2.0 / depth, 1.0)\r\n            ops.Interferometer(U) | tuple(q[i] for i in indices)\r\n            for i, index in enumerate(indices):\r\n                ops.Sgate(s[i]) | q[index]\r\n            ops.Interferometer(V) | tuple(q[i] for i in indices)\r\n    compiled_circuit = circuit.compile(""gaussian_unitary"")\r\n    cv = eng.run(circuit).state.cov()\r\n    mean = eng.run(circuit).state.means()\r\n\r\n    cv1 = eng1.run(compiled_circuit).state.cov()\r\n    mean1 = eng1.run(compiled_circuit).state.means()\r\n    assert np.allclose(cv, cv1)\r\n    assert np.allclose(mean, mean1)\r\n    assert len(compiled_circuit.circuit[0].reg) == 5\r\n    indices = [compiled_circuit.circuit[0].reg[i].ind for i in range(5)]\r\n    assert indices == sorted(list(indices))\r\n\r\n\r\ndef test_non_primitive_gates():\r\n    """"""Tests that the compiler is able to compile a number of non-primitive Gaussian gates""""""\r\n\r\n    width = 6\r\n    eng = sf.LocalEngine(backend=""gaussian"")\r\n    eng1 = sf.LocalEngine(backend=""gaussian"")\r\n    circuit = sf.Program(width)\r\n    A = np.random.rand(width, width) + 1j * np.random.rand(width, width)\r\n    A = A + A.T\r\n    valsA = np.linalg.svd(A, compute_uv=False)\r\n    A = A / 2 * np.max(valsA)\r\n    B = np.random.rand(width // 2, width // 2) + 1j * np.random.rand(width // 2, width // 2)\r\n    valsB = np.linalg.svd(B, compute_uv=False)\r\n    B = B / 2 * valsB\r\n    B = np.block([[0 * B, B], [B.T, 0 * B]])\r\n    with circuit.context as q:\r\n        ops.GraphEmbed(A) | q\r\n        ops.BipartiteGraphEmbed(B) | q\r\n        ops.Pgate(0.1) | q[1]\r\n        ops.CXgate(0.2) | (q[0], q[1])\r\n        ops.MZgate(0.4, 0.5) | (q[2], q[3])\r\n        ops.Fourier | q[0]\r\n        ops.Xgate(0.4) | q[1]\r\n        ops.Zgate(0.5) | q[3]\r\n    compiled_circuit = circuit.compile(""gaussian_unitary"")\r\n    cv = eng.run(circuit).state.cov()\r\n    mean = eng.run(circuit).state.means()\r\n\r\n    cv1 = eng1.run(compiled_circuit).state.cov()\r\n    mean1 = eng1.run(compiled_circuit).state.means()\r\n    assert np.allclose(cv, cv1)\r\n    assert np.allclose(mean, mean1)\r\n\r\n\r\n\r\n@pytest.mark.parametrize(""depth"", [1, 3, 6])\r\n@pytest.mark.parametrize(""width"", [5, 10, 15])\r\ndef test_displacements_only(depth, width):\r\n    """"""Tests that a circuit and its compiled version produce\r\n    the same Gaussian state when there are only displacements""""""\r\n    eng = sf.LocalEngine(backend=""gaussian"")\r\n    eng1 = sf.LocalEngine(backend=""gaussian"")\r\n    circuit = sf.Program(width)\r\n    with circuit.context as q:\r\n        for _ in range(depth):\r\n            alphas = np.random.rand(width)+1j*np.random.rand(width)\r\n            for i in range(width):\r\n                ops.Dgate(alphas[i]) | q[i]\r\n    compiled_circuit = circuit.compile(""gaussian_unitary"")\r\n    cv = eng.run(circuit).state.cov()\r\n    mean = eng.run(circuit).state.means()\r\n\r\n    cv1 = eng1.run(compiled_circuit).state.cov()\r\n    mean1 = eng1.run(compiled_circuit).state.means()\r\n    assert np.allclose(cv, cv1)\r\n    assert np.allclose(mean, mean1)\r\n'"
tests/frontend/test_circuitspecs_xcov.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the Xcov compiler""""""\nimport pytest\nimport numpy as np\nimport networkx as nx\n\nimport blackbird\n\nimport strawberryfields as sf\nimport strawberryfields.ops as ops\n\nfrom strawberryfields.parameters import par_evaluate\nfrom strawberryfields.program_utils import CircuitError, list_to_DAG\nfrom strawberryfields.io import to_program\nfrom strawberryfields.utils import random_interferometer\nfrom strawberryfields.circuitspecs.X8 import X8_01, CircuitSpecs\n\nfrom thewalrus.symplectic import two_mode_squeezing, expand\n\npytestmark = pytest.mark.frontend\n\nnp.random.seed(42)\n\nSQ_AMPLITUDE = 1\n""""""float: the allowed squeezing amplitude""""""\n\n\ndef program_equivalence(prog1, prog2, compare_params=True, atol=1e-6, rtol=0):\n    r""""""Checks if two programs are equivalent.\n\n    This function converts the program lists into directed acyclic graphs,\n    and runs the NetworkX `is_isomorphic` graph function in order\n    to determine if the two programs are equivalent.\n\n    Note: when checking for parameter equality between two parameters\n    :math:`a` and :math:`b`, we use the following formula:\n\n    .. math:: |a - b| \\leq (\\texttt{atol} + \\texttt{rtol}\\times|b|)\n\n    Args:\n        prog1 (strawberryfields.program.Program): quantum program\n        prog2 (strawberryfields.program.Program): quantum program\n        compare_params (bool): Set to ``False`` to turn of comparing\n            program parameters; equivalency will only take into\n            account the operation order.\n        atol (float): the absolute tolerance parameter for checking\n            quantum operation parameter equality\n        rtol (float): the relative tolerance parameter for checking\n            quantum operation parameter equality\n\n    Returns:\n        bool: returns ``True`` if two quantum programs are equivalent\n    """"""\n    DAG1 = list_to_DAG(prog1.circuit)\n    DAG2 = list_to_DAG(prog2.circuit)\n\n    circuit = []\n    for G in [DAG1, DAG2]:\n        # relabel the DAG nodes to integers\n        circuit.append(nx.convert_node_labels_to_integers(G))\n\n        # add node attributes to store the operation name and parameters\n        name_mapping = {i: n.op.__class__.__name__ for i, n in enumerate(G.nodes())}\n        parameter_mapping = {i: par_evaluate(n.op.p) for i, n in enumerate(G.nodes())}\n\n        # CXgate and BSgate are not symmetric wrt permuting the order of the two\n        # modes it acts on; i.e., the order of the wires matter\n        wire_mapping = {}\n        for i, n in enumerate(G.nodes()):\n            if n.op.__class__.__name__ == ""CXgate"":\n                if np.allclose(n.op.p[0], 0):\n                    # if the CXgate parameter is 0, wire order doesn\'t matter\n                    wire_mapping[i] = 0\n                else:\n                    # if the CXgate parameter is not 0, order matters\n                    wire_mapping[i] = [j.ind for j in n.reg]\n\n            elif n.op.__class__.__name__ == ""BSgate"":\n                if np.allclose([j % np.pi for j in par_evaluate(n.op.p)], [np.pi / 4, np.pi / 2]):\n                    # if the beamsplitter is *symmetric*, then the order of the\n                    # wires does not matter.\n                    wire_mapping[i] = 0\n                else:\n                    # beamsplitter is not symmetric, order matters\n                    wire_mapping[i] = [j.ind for j in n.reg]\n\n            else:\n                # not a CXgate or a BSgate, order of wires doesn\'t matter\n                wire_mapping[i] = 0\n\n        # TODO: at the moment, we do not check for whether an empty\n        # wire will match an operation with trivial parameters.\n        # Maybe we can do this in future, but this is a subgraph\n        # isomorphism problem and much harder.\n\n        nx.set_node_attributes(circuit[-1], name_mapping, name=""name"")\n        nx.set_node_attributes(circuit[-1], parameter_mapping, name=""p"")\n        nx.set_node_attributes(circuit[-1], wire_mapping, name=""w"")\n\n    def node_match(n1, n2):\n        """"""Returns True if both nodes have the same name and\n        same parameters, within a certain tolerance""""""\n        name_match = n1[""name""] == n2[""name""]\n        p_match = np.allclose(n1[""p""], n2[""p""], atol=atol, rtol=rtol)\n        wire_match = n1[""w""] == n2[""w""]\n\n        if compare_params:\n            return name_match and p_match and wire_match\n\n        return name_match and wire_match\n\n    # check if circuits are equivalent\n    return nx.is_isomorphic(circuit[0], circuit[1], node_match)\n\n\nclass DummyCircuit(CircuitSpecs):\n    """"""Dummy circuit used to instantiate\n    the abstract base class""""""\n\n    modes = 8\n    remote = False\n    local = True\n    interactive = True\n    primitives = {""S2gate"", ""MeasureFock"", ""Rgate"", ""BSgate"", ""MZgate""}\n    decompositions = {""Interferometer"": {}}\n\n\nclass TestXCompilation:\n    """"""Tests for compilation using the X8_01 circuit specification""""""\n\n    def test_exact_template(self, tol):\n        """"""Test compilation works for the exact circuit""""""\n        bb = blackbird.loads(X8_01.circuit)\n        bb = bb(\n            squeezing_amplitude_0=SQ_AMPLITUDE,\n            squeezing_amplitude_1=SQ_AMPLITUDE,\n            squeezing_amplitude_2=SQ_AMPLITUDE,\n            squeezing_amplitude_3=SQ_AMPLITUDE,\n            phase_0=0,\n            phase_1=1,\n            phase_2=2,\n            phase_3=3,\n            phase_4=4,\n            phase_5=5,\n            phase_6=6,\n            phase_7=7,\n            phase_8=8,\n            phase_9=9,\n            phase_10=10,\n            phase_11=11,\n            final_phase_0=1.24,\n            final_phase_1=-0.54,\n            final_phase_2=4.12,\n            final_phase_3=0,\n            final_phase_4=1.24,\n            final_phase_5=-0.54,\n            final_phase_6=4.12,\n            final_phase_7=0,\n        )\n\n        expected = to_program(bb)\n        res = expected.compile(""Xcov"")\n\n        assert program_equivalence(res, expected, atol=tol, compare_params=False)\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_not_all_modes_measured(self, num_pairs):\n        """"""Test exceptions raised if not all modes are measured""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n        with prog.context as q:\n            for i in range(num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | (q[0], q[num_pairs])\n        with pytest.raises(CircuitError, match=""All modes must be measured""):\n            prog.compile(""Xcov"")\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_no_s2gates(self, num_pairs, tol):\n        """"""Test identity S2gates are inserted when no S2gates\n        are provided.""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n\n        with prog.context as q:\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        expected = sf.Program(2 * num_pairs)\n\n        with expected.context as q:\n            for i in range(num_pairs):\n                ops.S2gate(0) | (q[i], q[i + num_pairs])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        res = prog.compile(""Xcov"")\n        expected = expected.compile(""Xcov"")\n        assert program_equivalence(res, expected, atol=tol)\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_missing_s2gates(self, num_pairs, tol):\n        """"""Test identity S2gates are inserted when some (but not all)\n        S2gates are included.""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n        assert num_pairs > 3\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[num_pairs + 1])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[num_pairs + 3])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        expected = sf.Program(2 * num_pairs)\n\n        with expected.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[num_pairs + 1])\n            ops.S2gate(0) | (q[0], q[num_pairs + 0])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[num_pairs + 3])\n            ops.S2gate(0) | (q[2], q[num_pairs + 2])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        res = prog.compile(""Xcov"")\n        expected = expected.compile(""Xcov"")\n        assert program_equivalence(res, expected, atol=tol)\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_incorrect_s2gate_modes(self, num_pairs):\n        """"""Test exceptions raised if S2gates do not appear on correct modes""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n        n_modes = 2 * num_pairs\n        half_n_modes = n_modes // 2\n        with prog.context as q:\n            for i in range(num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[2 * i], q[2 * i + 1])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        with pytest.raises(\n            CircuitError,\n            match=""The applied unitary cannot mix between the modes {}-{} and modes {}-{}."".format(\n                0, half_n_modes - 1, half_n_modes, n_modes - 1\n            ),\n        ):\n            res = prog.compile(""Xcov"")\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_incorrect_s2gate_params(self, num_pairs):\n        """"""Test exceptions raised if S2gates have illegal parameters""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n        with prog.context as q:\n            for i in range(num_pairs - 1):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n\n            ops.S2gate(SQ_AMPLITUDE + 0.1) | (q[num_pairs - 1], q[2 * num_pairs - 1])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=r""Incorrect squeezing val""):\n            res = prog.compile(""Xcov"")\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_s2gate_repeated_modes(self, num_pairs):\n        """"""Test exceptions raised if S2gates are repeated""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n        with prog.context as q:\n            for i in range(num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n\n            ops.S2gate(SQ_AMPLITUDE + 0.1) | (q[0], q[num_pairs])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=r""Incorrect squeezing val""):\n            prog.compile(""Xcov"")\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_s2gate_repeated_modes_half_squeezing(self, num_pairs):\n        """"""Test that squeezing gates are correctly merged""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n\n        with prog.context as q:\n\n            ops.S2gate(SQ_AMPLITUDE / 2) | (q[0], q[0 + num_pairs])\n            for i in range(1, num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n            ops.S2gate(SQ_AMPLITUDE / 2) | (q[0], q[0 + num_pairs])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        res = prog.compile(""Xcov"")\n        assert np.allclose(res.circuit[0].op.p[0], SQ_AMPLITUDE)\n\n    def test_gates_compile(self):\n        """"""Test that combinations of MZgates, Rgates, and BSgates\n        correctly compile.""""""\n        prog = sf.Program(8)\n\n        def unitary(q):\n            ops.MZgate(0.5, 0.1) | (q[0], q[1])\n            ops.BSgate(0.1, 0.2) | (q[1], q[2])\n            ops.Rgate(0.4) | q[0]\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[7])\n\n            unitary(q[:4])\n            unitary(q[4:])\n            ops.MeasureFock() | q\n\n        prog.compile(""Xcov"")\n\n    def test_no_unitary(self, tol):\n        """"""Test compilation works with no unitary provided""""""\n        prog = sf.Program(8)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[7])\n            ops.MeasureFock() | q\n\n        res = prog.compile(""Xcov"")\n        expected = sf.Program(8)\n\n        with expected.context as q:\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[3], q[7])\n\n            # corresponds to an identity on modes [0, 1, 2, 3]\n            # This can be easily seen from below by noting that:\n            # MZ(pi, pi) = R(0) = I\n            # MZ(pi, 0) @ MZ(pi, 0) = I\n            # [R(pi) \\otimes I] @ MZ(pi, 0) = I\n            ops.MZgate(np.pi, 0) | (q[0], q[1])\n            ops.MZgate(np.pi, 0) | (q[2], q[3])\n            ops.MZgate(np.pi, np.pi) | (q[1], q[2])\n            ops.MZgate(np.pi, np.pi) | (q[0], q[1])\n            ops.MZgate(np.pi, 0) | (q[2], q[3])\n            ops.MZgate(np.pi, np.pi) | (q[1], q[2])\n            ops.Rgate(np.pi) | (q[0])\n            ops.Rgate(0) | (q[1])\n            ops.Rgate(0) | (q[2])\n            ops.Rgate(0) | (q[3])\n\n            # corresponds to an identity on modes [4, 5, 6, 7]\n            ops.MZgate(np.pi, 0) | (q[4], q[5])\n            ops.MZgate(np.pi, 0) | (q[6], q[7])\n            ops.MZgate(np.pi, np.pi) | (q[5], q[6])\n            ops.MZgate(np.pi, np.pi) | (q[4], q[5])\n            ops.MZgate(np.pi, 0) | (q[6], q[7])\n            ops.MZgate(np.pi, np.pi) | (q[5], q[6])\n            ops.Rgate(np.pi) | (q[4])\n            ops.Rgate(0) | (q[5])\n            ops.Rgate(0) | (q[6])\n            ops.Rgate(0) | (q[7])\n\n            ops.MeasureFock() | q\n\n        assert program_equivalence(res, expected, atol=tol, compare_params=False)\n\n        # double check that the applied symplectic is correct\n\n        # remove the Fock measurements\n        res.circuit = res.circuit[:-1]\n\n        # extract the Gaussian symplectic matrix\n        O = res.compile(""gaussian_unitary"").circuit[0].op.p[0]\n\n        # construct the expected symplectic matrix corresponding\n        # to just the initial two mode squeeze gates\n        S = two_mode_squeezing(SQ_AMPLITUDE, 0)\n        num_modes = 8\n        expected = np.identity(2 * num_modes)\n        for i in range(num_modes // 2):\n            expected = expand(S, [i, i + num_modes // 2], num_modes) @ expected\n        # Note that the comparison has to be made at the level of covariance matrices\n        # Not at the level of symplectic matrices\n        assert np.allclose(O @ O.T, expected @ expected.T, atol=tol)\n\n    @pytest.mark.parametrize(""num_pairs"", [4])\n    def test_interferometers(self, num_pairs, tol):\n        """"""Test that the compilation correctly decomposes the interferometer using\n        the rectangular_symmetric mesh""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n\n        with prog.context as q:\n            for i in range(0, num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        res = prog.compile(""Xcov"")\n\n        expected = sf.Program(2 * num_pairs)\n\n        with expected.context as q:\n            for i in range(0, num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n            ops.Interferometer(U, mesh=""rectangular_symmetric"", drop_identity=False) | tuple(\n                q[i] for i in range(num_pairs)\n            )\n            ops.Interferometer(U, mesh=""rectangular_symmetric"", drop_identity=False) | tuple(\n                q[i] for i in range(num_pairs, 2 * num_pairs)\n            )\n            ops.MeasureFock() | q\n\n        expected = expected.compile(DummyCircuit())\n        # Note that since DummyCircuit() has a hard coded limit of 8 modes we only check for this number\n        assert program_equivalence(res, expected, atol=tol, compare_params=False)\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_unitaries_do_not_match(self, num_pairs):\n        """"""Test exception raised if the unitary applied to modes [0, 1, 2, 3] is\n        different to the unitary applied to modes [4, 5, 6, 7]""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n\n        with prog.context as q:\n            for i in range(0, num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.BSgate() | (q[2], q[3])\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""The applied unitary on modes""):\n            res = prog.compile(""Xcov"")\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_unitary_too_large(self, num_pairs):\n        """"""Test exception raised if the unitary is applied to more\n        than just modes [0, 1, 2, 3, ..., num_pairs-1] and [num_pairs, num_pairs+1, ..., 2*num_pairs-1].""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(2 * num_pairs)\n\n        with prog.context as q:\n            for i in range(0, num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n            ops.Interferometer(U) | q\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""The applied unitary cannot mix between the modes""):\n            res = prog.compile(""Xcov"")\n'"
tests/frontend/test_circuitspecs_xunitary.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the Xunitary compiler""""""\nimport pytest\nimport numpy as np\nimport networkx as nx\n\nimport blackbird\n\nimport strawberryfields as sf\nimport strawberryfields.ops as ops\n\nfrom strawberryfields.parameters import par_evaluate\nfrom strawberryfields.program_utils import CircuitError, list_to_DAG\nfrom strawberryfields.io import to_program\nfrom strawberryfields.utils import random_interferometer\nfrom strawberryfields.circuitspecs.X8 import X8_01, CircuitSpecs\n\nfrom thewalrus.symplectic import two_mode_squeezing, expand\n\npytestmark = pytest.mark.frontend\n\nnp.random.seed(42)\n\nSQ_AMPLITUDE = 1\n""""""float: the allowed squeezing amplitude""""""\n\n\ndef program_equivalence(prog1, prog2, compare_params=True, atol=1e-6, rtol=0):\n    r""""""Checks if two programs are equivalent.\n\n    This function converts the program lists into directed acyclic graphs,\n    and runs the NetworkX `is_isomorphic` graph function in order\n    to determine if the two programs are equivalent.\n\n    Note: when checking for parameter equality between two parameters\n    :math:`a` and :math:`b`, we use the following formula:\n\n    .. math:: |a - b| \\leq (\\texttt{atol} + \\texttt{rtol}\\times|b|)\n\n    Args:\n        prog1 (strawberryfields.program.Program): quantum program\n        prog2 (strawberryfields.program.Program): quantum program\n        compare_params (bool): Set to ``False`` to turn of comparing\n            program parameters; equivalency will only take into\n            account the operation order.\n        atol (float): the absolute tolerance parameter for checking\n            quantum operation parameter equality\n        rtol (float): the relative tolerance parameter for checking\n            quantum operation parameter equality\n\n    Returns:\n        bool: returns ``True`` if two quantum programs are equivalent\n    """"""\n    DAG1 = list_to_DAG(prog1.circuit)\n    DAG2 = list_to_DAG(prog2.circuit)\n\n    circuit = []\n    for G in [DAG1, DAG2]:\n        # relabel the DAG nodes to integers\n        circuit.append(nx.convert_node_labels_to_integers(G))\n\n        # add node attributes to store the operation name and parameters\n        name_mapping = {i: n.op.__class__.__name__ for i, n in enumerate(G.nodes())}\n        parameter_mapping = {i: par_evaluate(n.op.p) for i, n in enumerate(G.nodes())}\n\n        # CXgate and BSgate are not symmetric wrt permuting the order of the two\n        # modes it acts on; i.e., the order of the wires matter\n        wire_mapping = {}\n        for i, n in enumerate(G.nodes()):\n            if n.op.__class__.__name__ == ""CXgate"":\n                if np.allclose(n.op.p[0], 0):\n                    # if the CXgate parameter is 0, wire order doesn\'t matter\n                    wire_mapping[i] = 0\n                else:\n                    # if the CXgate parameter is not 0, order matters\n                    wire_mapping[i] = [j.ind for j in n.reg]\n\n            elif n.op.__class__.__name__ == ""BSgate"":\n                if np.allclose([j % np.pi for j in par_evaluate(n.op.p)], [np.pi / 4, np.pi / 2]):\n                    # if the beamsplitter is *symmetric*, then the order of the\n                    # wires does not matter.\n                    wire_mapping[i] = 0\n                else:\n                    # beamsplitter is not symmetric, order matters\n                    wire_mapping[i] = [j.ind for j in n.reg]\n\n            else:\n                # not a CXgate or a BSgate, order of wires doesn\'t matter\n                wire_mapping[i] = 0\n\n        # TODO: at the moment, we do not check for whether an empty\n        # wire will match an operation with trivial parameters.\n        # Maybe we can do this in future, but this is a subgraph\n        # isomorphism problem and much harder.\n\n        nx.set_node_attributes(circuit[-1], name_mapping, name=""name"")\n        nx.set_node_attributes(circuit[-1], parameter_mapping, name=""p"")\n        nx.set_node_attributes(circuit[-1], wire_mapping, name=""w"")\n\n    def node_match(n1, n2):\n        """"""Returns True if both nodes have the same name and\n        same parameters, within a certain tolerance""""""\n        name_match = n1[""name""] == n2[""name""]\n        p_match = np.allclose(n1[""p""], n2[""p""], atol=atol, rtol=rtol)\n        wire_match = n1[""w""] == n2[""w""]\n\n        if compare_params:\n            return name_match and p_match and wire_match\n\n        return name_match and wire_match\n\n    # check if circuits are equivalent\n    return nx.is_isomorphic(circuit[0], circuit[1], node_match)\n\n\nclass DummyCircuit(CircuitSpecs):\n    """"""Dummy circuit used to instantiate\n    the abstract base class""""""\n\n    modes = 8\n    remote = False\n    local = True\n    interactive = True\n    primitives = {""S2gate"", ""MeasureFock"", ""Rgate"", ""BSgate"", ""MZgate""}\n    decompositions = {""Interferometer"": {}}\n\n\nclass TestXCompilation:\n    """"""Tests for compilation using the X8_01 circuit specification""""""\n\n    def test_exact_template(self, tol):\n        """"""Test compilation works for the exact circuit""""""\n        bb = blackbird.loads(X8_01.circuit)\n        bb = bb(\n            squeezing_amplitude_0=SQ_AMPLITUDE,\n            squeezing_amplitude_1=SQ_AMPLITUDE,\n            squeezing_amplitude_2=SQ_AMPLITUDE,\n            squeezing_amplitude_3=SQ_AMPLITUDE,\n            phase_0=0,\n            phase_1=1,\n            phase_2=2,\n            phase_3=3,\n            phase_4=4,\n            phase_5=5,\n            phase_6=6,\n            phase_7=7,\n            phase_8=8,\n            phase_9=9,\n            phase_10=10,\n            phase_11=11,\n            final_phase_0=1.24,\n            final_phase_1=-0.54,\n            final_phase_2=4.12,\n            final_phase_3=0,\n            final_phase_4=1.24,\n            final_phase_5=-0.54,\n            final_phase_6=4.12,\n            final_phase_7=0,\n        )\n\n        expected = to_program(bb)\n        res = expected.compile(""Xunitary"")\n        print(""hello"")\n        assert program_equivalence(res, expected, atol=tol, compare_params=False)\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_not_all_modes_measured(self, num_pairs):\n        """"""Test exceptions raised if not all modes are measured""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n        with prog.context as q:\n            for i in range(num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | (q[0], q[num_pairs])\n        with pytest.raises(CircuitError, match=""All modes must be measured""):\n            prog.compile(""Xunitary"")\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_no_s2gates(self, num_pairs, tol):\n        """"""Test identity S2gates are inserted when no S2gates\n        are provided.""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n\n        with prog.context as q:\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        expected = sf.Program(2 * num_pairs)\n\n        with expected.context as q:\n            for i in range(num_pairs):\n                ops.S2gate(0) | (q[i], q[i + num_pairs])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        # with pytest.raises(CircuitError, match=""There can be no operations before the S2gates.""):\n        res = prog.compile(""Xunitary"")\n        # with pytest.raises(CircuitError, match=""There can be no operations before the S2gates.""):\n        expected = expected.compile(""Xunitary"")\n        assert program_equivalence(res, expected, atol=tol)\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_missing_s2gates(self, num_pairs, tol):\n        """"""Test identity S2gates are inserted when some (but not all)\n        S2gates are included.""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n        assert num_pairs > 3\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[num_pairs + 1])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[num_pairs + 3])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        expected = sf.Program(2 * num_pairs)\n\n        with expected.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[num_pairs + 1])\n            ops.S2gate(0) | (q[0], q[num_pairs + 0])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[num_pairs + 3])\n            ops.S2gate(0) | (q[2], q[num_pairs + 2])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        res = prog.compile(""Xunitary"")\n        expected = expected.compile(""Xunitary"")\n        assert program_equivalence(res, expected, atol=tol)\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_incorrect_s2gate_modes(self, num_pairs):\n        """"""Test exceptions raised if S2gates do not appear on correct modes""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n        n_modes = 2 * num_pairs\n        half_n_modes = n_modes // 2\n        with prog.context as q:\n            for i in range(num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[2 * i], q[2 * i + 1])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""S2gates do not appear on the correct modes.""):\n            res = prog.compile(""Xunitary"")\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_incorrect_s2gate_params(self, num_pairs):\n        """"""Test exceptions raised if S2gates have illegal parameters""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n        with prog.context as q:\n            for i in range(num_pairs - 1):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n\n            ops.S2gate(SQ_AMPLITUDE + 0.1) | (q[num_pairs - 1], q[2 * num_pairs - 1])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=r""Incorrect squeezing val""):\n            res = prog.compile(""Xunitary"")\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_s2gate_repeated_modes(self, num_pairs):\n        """"""Test exceptions raised if S2gates are repeated""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n        with prog.context as q:\n            for i in range(num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n\n            ops.S2gate(SQ_AMPLITUDE + 0.1) | (q[0], q[num_pairs])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=r""Incorrect squeezing val""):\n            prog.compile(""Xunitary"")\n\n    # This test should fail\n    \'\'\'\n    @pytest.mark.parametrize(""num_pairs"", [4,5,6,7])\n    def test_s2gate_repeated_modes_half_squeezing(self, num_pairs):\n        """"""Test that squeezing gates are correctly merged""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n\n        with prog.context as q:\n\n            ops.S2gate(SQ_AMPLITUDE/2) | (q[0], q[0 + num_pairs])\n            for i in range(1, num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n            ops.S2gate(SQ_AMPLITUDE/2) | (q[0], q[0 + num_pairs])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        res = prog.compile(""Xunitary"")\n        assert np.allclose(res.circuit[0].op.p[0], SQ_AMPLITUDE)\n    \'\'\'\n\n    def test_gates_compile(self):\n        """"""Test that combinations of MZgates, Rgates, and BSgates\n        correctly compile.""""""\n        prog = sf.Program(8)\n\n        def unitary(q):\n            ops.MZgate(0.5, 0.1) | (q[0], q[1])\n            ops.BSgate(0.1, 0.2) | (q[1], q[2])\n            ops.Rgate(0.4) | q[0]\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[7])\n\n            unitary(q[:4])\n            unitary(q[4:])\n            ops.MeasureFock() | q\n\n        prog.compile(""Xunitary"")\n\n    def test_no_unitary(self, tol):\n        """"""Test compilation works with no unitary provided""""""\n        prog = sf.Program(8)\n\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE) | (q[3], q[7])\n            ops.MeasureFock() | q\n\n        res = prog.compile(""Xunitary"")\n        expected = sf.Program(8)\n\n        with expected.context as q:\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[0], q[4])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[1], q[5])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[2], q[6])\n            ops.S2gate(SQ_AMPLITUDE, 0) | (q[3], q[7])\n\n            # corresponds to an identity on modes [0, 1, 2, 3]\n            # This can be easily seen from below by noting that:\n            # MZ(pi, pi) = R(0) = I\n            # MZ(pi, 0) @ MZ(pi, 0) = I\n            # [R(pi) \\otimes I] @ MZ(pi, 0) = I\n            ops.MZgate(np.pi, 0) | (q[0], q[1])\n            ops.MZgate(np.pi, 0) | (q[2], q[3])\n            ops.MZgate(np.pi, np.pi) | (q[1], q[2])\n            ops.MZgate(np.pi, np.pi) | (q[0], q[1])\n            ops.MZgate(np.pi, 0) | (q[2], q[3])\n            ops.MZgate(np.pi, np.pi) | (q[1], q[2])\n            ops.Rgate(np.pi) | (q[0])\n            ops.Rgate(0) | (q[1])\n            ops.Rgate(0) | (q[2])\n            ops.Rgate(0) | (q[3])\n\n            # corresponds to an identity on modes [4, 5, 6, 7]\n            ops.MZgate(np.pi, 0) | (q[4], q[5])\n            ops.MZgate(np.pi, 0) | (q[6], q[7])\n            ops.MZgate(np.pi, np.pi) | (q[5], q[6])\n            ops.MZgate(np.pi, np.pi) | (q[4], q[5])\n            ops.MZgate(np.pi, 0) | (q[6], q[7])\n            ops.MZgate(np.pi, np.pi) | (q[5], q[6])\n            ops.Rgate(np.pi) | (q[4])\n            ops.Rgate(0) | (q[5])\n            ops.Rgate(0) | (q[6])\n            ops.Rgate(0) | (q[7])\n\n            ops.MeasureFock() | q\n\n        assert program_equivalence(res, expected, atol=tol, compare_params=False)\n\n        # double check that the applied symplectic is correct\n\n        # remove the Fock measurements\n        res.circuit = res.circuit[:-1]\n\n        # extract the Gaussian symplectic matrix\n        O = res.compile(""gaussian_unitary"").circuit[0].op.p[0]\n\n        # construct the expected symplectic matrix corresponding\n        # to just the initial two mode squeeze gates\n        S = two_mode_squeezing(SQ_AMPLITUDE, 0)\n        num_modes = 8\n        expected = np.identity(2 * num_modes)\n        for i in range(num_modes // 2):\n            expected = expand(S, [i, i + num_modes // 2], num_modes) @ expected\n        # Note that the comparison has to be made at the level of covariance matrices\n        # Not at the level of symplectic matrices\n        assert np.allclose(O @ O.T, expected @ expected.T, atol=tol)\n\n    @pytest.mark.parametrize(""num_pairs"", [4])\n    def test_interferometers(self, num_pairs, tol):\n        """"""Test that the compilation correctly decomposes the interferometer using\n        the rectangular_symmetric mesh""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n\n        with prog.context as q:\n            for i in range(0, num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.MeasureFock() | q\n\n        res = prog.compile(""Xunitary"")\n\n        expected = sf.Program(2 * num_pairs)\n\n        with expected.context as q:\n            for i in range(0, num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n            ops.Interferometer(U, mesh=""rectangular_symmetric"", drop_identity=False) | tuple(\n                q[i] for i in range(num_pairs)\n            )\n            ops.Interferometer(U, mesh=""rectangular_symmetric"", drop_identity=False) | tuple(\n                q[i] for i in range(num_pairs, 2 * num_pairs)\n            )\n            ops.MeasureFock() | q\n\n        expected = expected.compile(DummyCircuit())\n        # Note that since DummyCircuit() has a hard coded limit of 8 modes we only check for this number\n        assert program_equivalence(res, expected, atol=tol, compare_params=False)\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_unitaries_do_not_match(self, num_pairs):\n        """"""Test exception raised if the unitary applied to modes [0, 1, 2, 3] is\n        different to the unitary applied to modes [4, 5, 6, 7]""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(num_pairs)\n\n        with prog.context as q:\n            for i in range(0, num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs))\n            ops.Interferometer(U) | tuple(q[i] for i in range(num_pairs, 2 * num_pairs))\n            ops.BSgate() | (q[2], q[3])\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""The applied unitary on modes""):\n            prog.compile(""Xunitary"")\n\n    @pytest.mark.parametrize(""num_pairs"", [4, 5, 6, 7])\n    def test_unitary_too_large(self, num_pairs):\n        """"""Test exception raised if the unitary is applied to more\n        than just modes [0, 1, 2, 3, ..., num_pairs-1] and [num_pairs, num_pairs+1, ..., 2*num_pairs-1].""""""\n        prog = sf.Program(2 * num_pairs)\n        U = random_interferometer(2 * num_pairs)\n\n        with prog.context as q:\n            for i in range(0, num_pairs):\n                ops.S2gate(SQ_AMPLITUDE) | (q[i], q[i + num_pairs])\n            ops.Interferometer(U) | q\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""The applied unitary cannot mix between the modes""):\n            res = prog.compile(""Xunitary"")\n\n    def test_odd_number_of_modes(self):\n        """"""Test error is raised when xstrict is called with odd number of modes""""""\n        prog = sf.Program(1)\n\n        with pytest.raises(\n            CircuitError, match=""The X series only supports programs with an even number of modes.""\n        ):\n            res = prog.compile(""Xunitary"")\n\n    def test_operation_before_squeezing(self):\n        """"""Test error is raised when an operation is passed before the S2gates""""""\n        prog = sf.Program(2)\n        with prog.context as q:\n            ops.BSgate() | (q[0], q[1])\n            ops.S2gate(SQ_AMPLITUDE) | (q[0], q[1])\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""There can be no operations before the S2gates.""):\n            prog.compile(""Xunitary"")\n\n    def test_wrong_squeezing_phase(self):\n        """"""Test error is raised when the phase of S2gate is not zero""""""\n        prog = sf.Program(2)\n        with prog.context as q:\n            ops.S2gate(SQ_AMPLITUDE, 137) | (q[0], q[1])\n            ops.MeasureFock() | q\n\n        with pytest.raises(CircuitError, match=""Incorrect phase value""):\n            res = prog.compile(""Xunitary"")\n'"
tests/frontend/test_configuration.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Unit tests for the configuration module""""""\nimport os\nimport logging\nimport pytest\n\nimport toml\n\nfrom strawberryfields import configuration as conf\n\npytestmark = pytest.mark.frontend\nlogging.getLogger().setLevel(1)\n\nauthentication_token = ""071cdcce-9241-4965-93af-4a4dbc739135""\n\nTEST_FILE = """"""\\\n[api]\n# Options for the Strawberry Fields Cloud API\nauthentication_token = ""071cdcce-9241-4965-93af-4a4dbc739135""\nhostname = ""platform.strawberryfields.ai""\nuse_ssl = true\nport = 443\n""""""\n\nTEST_FILE_ONE_VALUE = """"""\\\n[api]\n# Options for the Strawberry Fields Cloud API\nauthentication_token = ""071cdcce-9241-4965-93af-4a4dbc739135""\n""""""\n\nEXPECTED_CONFIG = {\n    ""api"": {\n        ""authentication_token"": ""071cdcce-9241-4965-93af-4a4dbc739135"",\n        ""hostname"": ""platform.strawberryfields.ai"",\n        ""use_ssl"": True,\n        ""port"": 443,\n    }\n}\n\nOTHER_EXPECTED_CONFIG = {\n    ""api"": {\n        ""authentication_token"": ""SomeAuth"",\n        ""hostname"": ""SomeHost"",\n        ""use_ssl"": False,\n        ""port"": 56,\n    }\n}\n\nenvironment_variables = [\n    ""SF_API_AUTHENTICATION_TOKEN"",\n    ""SF_API_HOSTNAME"",\n    ""SF_API_USE_SSL"",\n    ""SF_API_DEBUG"",\n    ""SF_API_PORT"",\n]\n\n\nclass TestLoadConfig:\n    """"""Tests for the load_config function.""""""\n\n    def test_not_found_warning(self, caplog):\n        """"""Test that a warning is raised if no configuration file found.""""""\n\n        conf.load_config(filename=""NotAFileName"")\n        assert ""No Strawberry Fields configuration file found."" in caplog.text\n\n    def test_keywords_take_precedence_over_everything(self, monkeypatch, tmpdir):\n        """"""Test that the keyword arguments passed to load_config take\n        precedence over data in environment variables or data in a\n        configuration file.""""""\n        with open(tmpdir.join(""test_config.toml""), ""w"") as f:\n            f.write(TEST_FILE)\n\n        with monkeypatch.context() as m:\n            m.setenv(""SF_API_AUTHENTICATION_TOKEN"", ""NotOurAuth"")\n            m.setenv(""SF_API_HOSTNAME"", ""NotOurHost"")\n            m.setenv(""SF_API_USE_SSL"", ""True"")\n            m.setenv(""SF_API_DEBUG"", ""False"")\n            m.setenv(""SF_API_PORT"", ""42"")\n\n            m.setattr(os, ""getcwd"", lambda: tmpdir)\n            configuration = conf.load_config(\n                authentication_token=""SomeAuth"", hostname=""SomeHost"", use_ssl=False, port=56\n            )\n\n        assert configuration == OTHER_EXPECTED_CONFIG\n\n    def test_environment_variables_take_precedence_over_conf_file(self, monkeypatch, tmpdir):\n        """"""Test that the data in environment variables take precedence over data in\n        a configuration file.""""""\n        with open(tmpdir.join(""test_config.toml""), ""w"") as f:\n            f.write(TEST_FILE)\n\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: tmpdir)\n\n            m.setenv(""SF_API_AUTHENTICATION_TOKEN"", ""SomeAuth"")\n            m.setenv(""SF_API_HOSTNAME"", ""SomeHost"")\n            m.setenv(""SF_API_USE_SSL"", ""False"")\n            m.setenv(""SF_API_DEBUG"", ""True"")\n            m.setenv(""SF_API_PORT"", ""56"")\n\n            configuration = conf.load_config()\n\n        assert configuration == OTHER_EXPECTED_CONFIG\n\n    def test_conf_file_loads_well(self, monkeypatch, tmpdir):\n        """"""Test that the load_config function loads a configuration from a TOML\n        file correctly.""""""\n\n        filename = tmpdir.join(""config.toml"")\n\n        with open(filename, ""w"") as f:\n            f.write(TEST_FILE)\n\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: tmpdir)\n            configuration = conf.load_config()\n\n        assert configuration == EXPECTED_CONFIG\n\n    def test_get_api_section_safely_error(self, monkeypatch, tmpdir, caplog):\n        """"""Test that the get_api_section_safely function raises an error and\n        logs correctly if there is no api section in the configuration file.""""""\n        filename = tmpdir.join(""config.toml"")\n\n        empty_file = """"\n\n        with open(filename, ""w"") as f:\n            f.write(empty_file)\n\n        with monkeypatch.context() as m:\n            with pytest.raises(conf.ConfigurationError, match=""""):\n                m.setattr(os, ""getcwd"", lambda: tmpdir)\n                configuration = conf.load_config()\n\n        assert ""does not contain an \\""api\\"" section"" in caplog.text\n\n    def test_directories_to_check_with_sf_conf(self, monkeypatch, tmpdir):\n        """"""Test that the directories_to_check function returns three\n        directories if the SF_CONF variables is defined.""""""\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: ""First"")\n            m.setenv(""SF_CONF"", ""Second"")\n            m.setattr(conf, ""user_config_dir"", lambda *args: ""Third"")\n            directories = conf.directories_to_check()\n\n            assert [""First"", ""Second"", ""Third""] == directories\n\n    def test_directories_to_check_without_sf_conf(self, monkeypatch, tmpdir):\n        """"""Test that the directories_to_check function returns two\n        directories if the SF_CONF variables is not defined.""""""\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: ""First"")\n            m.delenv(""SF_CONF"", raising=False)\n            m.setattr(conf, ""user_config_dir"", lambda *args: ""Second"")\n            directories = conf.directories_to_check()\n\n            assert [""First"", ""Second""] == directories\n\ntest_file_name = ""test_file.toml""\ndefault_file_name = ""config.toml""\ntest_kwargs = [{}, {""filename"": test_file_name}]\n\nclass TestActiveConfigs:\n    """"""Test the active_configs function and its auxiliary functions.""""""\n\n    @pytest.mark.parametrize(""kwargs"", test_kwargs)\n    def test_get_available_config_paths_mock_directories(self, monkeypatch, kwargs):\n        """"""Test that the get_available_config_paths correctly uses the output of the\n        directories_to_check function.""""""\n        test_directory = ""test_directory_path""\n        test_file_name = kwargs[""filename""] if kwargs else default_file_name\n\n        with monkeypatch.context() as m:\n            m.setattr(conf, ""directories_to_check"", lambda: [test_directory])\n            m.setattr(os.path, ""exists"", lambda *args: True)\n            active_configs = conf.get_available_config_paths(**kwargs)\n            assert active_configs == [os.path.join(test_directory, test_file_name)]\n\n    @pytest.mark.parametrize(""kwargs"", test_kwargs)\n    def test_get_available_config_paths_integration(self, monkeypatch, tmpdir, kwargs):\n        """"""Tests that the get_available_config_paths function integrates well with\n        parts of the directories_to_check function.""""""\n        test_file_name = kwargs[""filename""] if kwargs else default_file_name\n\n        path1 = tmpdir.mkdir(""sub1"")\n        path2 = tmpdir.mkdir(""sub2"")\n        path3 = tmpdir.mkdir(""sub3"")\n\n        file1 = path1.join(test_file_name)\n        file2 = path2.join(test_file_name)\n        file3 = path3.join(test_file_name)\n\n        temporary_files = [file1, file2, file3]\n\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: path1)\n            m.setenv(""SF_CONF"", str(path2))\n            m.setattr(conf, ""user_config_dir"", lambda *args: path3)\n            m.setattr(os.path, ""exists"", lambda arg: arg in temporary_files)\n            active_configs = conf.get_available_config_paths(**kwargs)\n            assert active_configs == [file1, file2, file3]\n\n    def test_print_active_configs_single_config(self, capsys, monkeypatch):\n        """"""Checks that the correct message is outputted when a single\n        configuration file was found.""""""\n        active_configs = [""first_path""]\n        temp_dirs = [""first_path"", ""second_path"", ""third_path""]\n        with monkeypatch.context() as m:\n            m.setattr(conf, ""directories_to_check"", lambda: temp_dirs)\n            m.setattr(conf, ""get_available_config_paths"", lambda *args: active_configs)\n            conf.active_configs(test_file_name)\n\n            captured = capsys.readouterr()\n\n            general_message_1 = ""\\nThe following Strawberry Fields configuration files were found ""\\\n                            ""with the name \\""{}\\"":\\n"".format(test_file_name)\n            single_config = ""\\n* "" + active_configs[0] + "" (active)\\n""\n\n            general_message_2 = ""\\nThe following directories were checked:\\n\\n""\n\n            first_dir_msg = ""* "" + temp_dirs[0] + ""\\n""\n            second_dir_msg = ""* "" + temp_dirs[1] + ""\\n""\n            third_dir_msg = ""* "" + temp_dirs[2] + ""\\n""\n\n            assert captured.out == general_message_1 + single_config +\\\n                                   general_message_2 + first_dir_msg + second_dir_msg + third_dir_msg\n\n    def test_print_active_configs_multiple_configs(self, capsys, monkeypatch):\n        """"""Checks that the correct message is outputted for a single\n        configuration file found.""""""\n        active_configs = [""first_path"", ""second_path"", ""third_path""]\n        temp_dirs = [""first_path"", ""second_path"", ""third_path""]\n        with monkeypatch.context() as m:\n            m.setattr(conf, ""directories_to_check"", lambda: temp_dirs)\n            m.setattr(conf, ""get_available_config_paths"", lambda *args: active_configs)\n            conf.active_configs(test_file_name)\n\n            captured = capsys.readouterr()\n\n            general_message_1 = ""\\nThe following Strawberry Fields configuration files were found ""\\\n                            ""with the name \\""{}\\"":\\n"".format(test_file_name)\n            first_config = ""\\n* "" + active_configs[0] + "" (active)\\n""\n            second_config = ""* "" + active_configs[1] + ""\\n""\n            third_config = ""* "" + active_configs[2] + ""\\n""\n\n            general_message_2 = ""\\nThe following directories were checked:\\n\\n""\n\n            first_dir_msg = ""* "" + temp_dirs[0] + ""\\n""\n            second_dir_msg = ""* "" + temp_dirs[1] + ""\\n""\n            third_dir_msg = ""* "" + temp_dirs[2] + ""\\n""\n\n            assert captured.out == general_message_1 + first_config + second_config + third_config +\\\n                                   general_message_2 + first_dir_msg + second_dir_msg + third_dir_msg\n\n    def test_print_active_configs_no_configs(self, capsys, monkeypatch):\n        """"""Checks that the correct message is outputted if no configuration\n        files were found.""""""\n        temp_dirs = [""first_path"", ""second_path"", ""third_path""]\n        with monkeypatch.context() as m:\n            m.setattr(conf, ""directories_to_check"", lambda: temp_dirs)\n            m.setattr(conf, ""get_available_config_paths"", lambda *args: [])\n            conf.active_configs(test_file_name)\n\n            captured = capsys.readouterr()\n\n            general_message_1 = ""\\nNo Strawberry Fields configuration files were found with the ""\\\n                            ""name \\""{}\\"".\\n\\n"".format(test_file_name)\n\n            general_message_2 = ""\\nThe following directories were checked:\\n\\n""\n\n            first_dir_msg = ""* "" + temp_dirs[0] + ""\\n""\n            second_dir_msg = ""* "" + temp_dirs[1] + ""\\n""\n            third_dir_msg = ""* "" + temp_dirs[2] + ""\\n""\n\n            assert captured.out == general_message_1 +\\\n                                   general_message_2 + first_dir_msg + second_dir_msg + third_dir_msg\n\n\nclass TestCreateConfigObject:\n    """"""Test the creation of a configuration object""""""\n\n    def test_empty_config_object(self):\n        """"""Test that an empty configuration object can be created.""""""\n        config = conf.create_config(authentication_token="""", hostname="""", use_ssl="""", port="""")\n\n        assert all(value == """" for value in config[""api""].values())\n\n    def test_config_object_with_authentication_token(self):\n        """"""Test that passing only the authentication token creates the expected\n        configuration object.""""""\n        assert (\n            conf.create_config(authentication_token=""071cdcce-9241-4965-93af-4a4dbc739135"")\n            == EXPECTED_CONFIG\n        )\n\n    def test_config_object_every_keyword_argument(self):\n        """"""Test that passing every keyword argument creates the expected\n        configuration object.""""""\n        assert (\n            conf.create_config(\n                authentication_token=""SomeAuth"", hostname=""SomeHost"", use_ssl=False, port=56\n            )\n            == OTHER_EXPECTED_CONFIG\n        )\n\nclass TestRemoveConfigFile:\n    """"""Test the removal of configuration files""""""\n\n    def test_remove_default_config(self, monkeypatch, tmpdir):\n        """"""Test removing the default config file; i.e. called without arguments""""""\n        filename = tmpdir.join(""config.toml"")\n        empty_file = """"\n\n        with open(filename, ""w"") as f:\n            f.write(empty_file)\n\n        with monkeypatch.context() as m:\n            m.setattr(conf, ""find_config_file"", lambda *args: filename)\n\n            assert os.path.exists(filename)\n\n            conf.delete_config()\n\n            assert not os.path.exists(filename)\n\n    def test_remove_config_in_subdirectory(self, tmpdir):\n        """"""Test removing a config file in a subdirectory""""""\n        subdir = tmpdir.join(""subdir"")\n        filename = subdir.join(""new_config.toml"")\n        empty_file = """"\n\n        os.mkdir(subdir)\n        with open(filename, ""w"") as f:\n            f.write(empty_file)\n\n        assert os.path.exists(filename)\n\n        conf.delete_config(filename, directory=subdir)\n\n        assert not os.path.exists(filename)\n\n    def test_reset_config(self, monkeypatch, tmpdir):\n        """"""Test resetting the configuration by removing current configuration files""""""\n        subdir = tmpdir.join(""subdir"")\n        filename_1 = tmpdir.join(""config.toml"")\n        filename_2 = subdir.join(""config.toml"")\n        active_configs = [filename_1, filename_2]\n\n        empty_file = """"\n\n        with open(filename_1, ""w"") as f:\n            f.write(empty_file)\n\n        os.mkdir(subdir)\n        with open(filename_2, ""w"") as f:\n            f.write(empty_file)\n\n        with monkeypatch.context() as m:\n            m.setattr(conf, ""get_available_config_paths"", lambda *args: active_configs)\n\n            assert os.path.exists(filename_1)\n            assert os.path.exists(filename_2)\n\n            conf.reset_config()\n\n            assert not os.path.exists(filename_1)\n            assert not os.path.exists(filename_2)\n\nclass TestGetConfigFilepath:\n    """"""Tests for the find_config_file function.""""""\n\n    def test_current_directory(self, tmpdir, monkeypatch):\n        """"""Test that the default configuration file is loaded from the current\n        directory, if found.""""""\n        filename = ""config.toml""\n\n        path_to_write_file = tmpdir.join(filename)\n\n        with open(path_to_write_file, ""w"") as f:\n            f.write(TEST_FILE)\n\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: tmpdir)\n            config_filepath = conf.find_config_file(filename=filename)\n\n        assert config_filepath == tmpdir.join(filename)\n\n    def test_env_variable(self, monkeypatch, tmpdir):\n        """"""Test that the correct configuration file is found using the correct\n        environment variable (SF_CONF).\n\n        This is a test case for when there is no configuration file in the\n        current directory.""""""\n\n        filename = ""config.toml""\n\n        path_to_write_file = tmpdir.join(filename)\n\n        with open(path_to_write_file, ""w"") as f:\n            f.write(TEST_FILE)\n\n        def raise_wrapper(ex):\n            raise ex\n\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: ""NoConfigFileHere"")\n            m.setenv(""SF_CONF"", str(tmpdir))\n            m.setattr(conf, ""user_config_dir"", lambda *args: ""NotTheFileName"")\n\n            config_filepath = conf.find_config_file(filename=""config.toml"")\n\n        assert config_filepath == tmpdir.join(""config.toml"")\n\n    def test_user_config_dir(self, monkeypatch, tmpdir):\n        """"""Test that the correct configuration file is found using the correct\n        argument to the user_config_dir function.\n\n        This is a test case for when there is no configuration file:\n        -in the current directory or\n        -in the directory contained in the corresponding environment\n        variable.""""""\n        with open(tmpdir.join(""config.toml""), ""w"") as f:\n            f.write(TEST_FILE)\n\n        def raise_wrapper(ex):\n            raise ex\n\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: ""NoConfigFileHere"")\n            m.setenv(""SF_CONF"", ""NoConfigFileHere"")\n            m.setattr(\n                conf,\n                ""user_config_dir"",\n                lambda x, *args: tmpdir if x == ""strawberryfields"" else ""NoConfigFileHere"",\n            )\n\n            config_filepath = conf.find_config_file(filename=""config.toml"")\n\n        assert config_filepath == tmpdir.join(""config.toml"")\n\n    def test_no_config_file_found_returns_none(self, monkeypatch, tmpdir):\n        """"""Test that the find_config_file returns None if the\n        configuration file is nowhere to be found.\n\n        This is a test case for when there is no configuration file:\n        -in the current directory or\n        -in the directory contained in the corresponding environment\n        variable\n        -in the user_config_dir directory of Strawberry Fields.""""""\n\n        def raise_wrapper(ex):\n            raise ex\n\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: ""NoConfigFileHere"")\n            m.setenv(""SF_CONF"", ""NoConfigFileHere"")\n            m.setattr(conf, ""user_config_dir"", lambda *args: ""NoConfigFileHere"")\n\n            config_filepath = conf.find_config_file(filename=""config.toml"")\n\n        assert config_filepath is None\n\n\nclass TestLoadConfigFile:\n    """"""Tests the load_config_file function.""""""\n\n    def test_load_config_file(self, monkeypatch, tmpdir):\n        """"""Tests that configuration is loaded correctly from a TOML file.""""""\n        filename = tmpdir.join(""test_config.toml"")\n\n        with open(filename, ""w"") as f:\n            f.write(TEST_FILE)\n\n        loaded_config = conf.load_config_file(filepath=filename)\n\n        assert loaded_config == EXPECTED_CONFIG\n\n    def test_loading_absolute_path(self, monkeypatch, tmpdir):\n        """"""Test that the default configuration file can be loaded\n        via an absolute path.""""""\n        filename = tmpdir.join(""test_config.toml"")\n\n        with open(filename, ""w"") as f:\n            f.write(TEST_FILE)\n\n        with monkeypatch.context() as m:\n            m.setenv(""SF_CONF"", """")\n            loaded_config = conf.load_config_file(filepath=filename)\n\n        assert loaded_config == EXPECTED_CONFIG\n\n\nclass TestKeepValidOptions:\n    def test_only_invalid_options(self):\n        section_config_with_invalid_options = {""NotValid1"": 1, ""NotValid2"": 2, ""NotValid3"": 3}\n        assert conf.keep_valid_options(section_config_with_invalid_options) == {}\n\n    def test_valid_and_invalid_options(self):\n        section_config_with_invalid_options = {\n            ""authentication_token"": ""MyToken"",\n            ""NotValid1"": 1,\n            ""NotValid2"": 2,\n            ""NotValid3"": 3,\n        }\n        assert conf.keep_valid_options(section_config_with_invalid_options) == {\n            ""authentication_token"": ""MyToken""\n        }\n\n    def test_only_valid_options(self):\n        section_config_only_valid = {\n            ""authentication_token"": ""071cdcce-9241-4965-93af-4a4dbc739135"",\n            ""hostname"": ""platform.strawberryfields.ai"",\n            ""use_ssl"": True,\n            ""port"": 443,\n        }\n        assert conf.keep_valid_options(section_config_only_valid) == EXPECTED_CONFIG[""api""]\n\n\nvalue_mapping = [\n    (""SF_API_AUTHENTICATION_TOKEN"", ""SomeAuth""),\n    (""SF_API_HOSTNAME"", ""SomeHost""),\n    (""SF_API_USE_SSL"", ""False""),\n    (""SF_API_PORT"", ""56""),\n    (""SF_API_DEBUG"", ""True""),\n]\n\nparsed_values_mapping = {\n    ""SF_API_AUTHENTICATION_TOKEN"": ""SomeAuth"",\n    ""SF_API_HOSTNAME"": ""SomeHost"",\n    ""SF_API_USE_SSL"": False,\n    ""SF_API_PORT"": 56,\n    ""SF_API_DEBUG"": True,\n}\n\n\nclass TestUpdateFromEnvironmentalVariables:\n    """"""Tests for the update_from_environment_variables function.""""""\n\n    def test_all_environment_variables_defined(self, monkeypatch):\n        """"""Tests that the configuration object is updated correctly when all\n        the environment variables are defined.""""""\n\n        with monkeypatch.context() as m:\n            for env_var, value in value_mapping:\n                m.setenv(env_var, value)\n\n            config = conf.create_config()\n            for v, parsed_value in zip(config[""api""].values(), parsed_values_mapping.values()):\n                assert v != parsed_value\n\n            conf.update_from_environment_variables(config)\n            for v, parsed_value in zip(config[""api""].values(), parsed_values_mapping.values()):\n                assert v == parsed_value\n\n    environment_variables_with_keys_and_values = [\n        (""SF_API_AUTHENTICATION_TOKEN"", ""authentication_token"", ""SomeAuth""),\n        (""SF_API_HOSTNAME"", ""hostname"", ""SomeHost""),\n        (""SF_API_USE_SSL"", ""use_ssl"", ""False""),\n        (""SF_API_PORT"", ""port"", ""56""),\n    ]\n\n    @pytest.mark.parametrize(""env_var, key, value"", environment_variables_with_keys_and_values)\n    def test_one_environment_variable_defined(self, env_var, key, value, monkeypatch):\n        """"""Tests that the configuration object is updated correctly when only\n        one environment variable is defined.""""""\n\n        with monkeypatch.context() as m:\n            m.setenv(env_var, value)\n\n            config = conf.create_config()\n            for v, parsed_value in zip(config[""api""].values(), parsed_values_mapping.values()):\n                assert v != parsed_value\n\n            conf.update_from_environment_variables(config)\n            assert config[""api""][key] == parsed_values_mapping[env_var]\n\n            for v, (key, parsed_value) in zip(\n                config[""api""].values(), parsed_values_mapping.items()\n            ):\n                if key != env_var:\n                    assert v != parsed_value\n\n    def test_parse_environment_variable_boolean(self, monkeypatch):\n        """"""Tests that boolean values can be parsed correctly from environment\n        variables.""""""\n        monkeypatch.setattr(conf, ""DEFAULT_CONFIG_SPEC"", {""api"": {""some_boolean"": (bool, True)}})\n        assert conf.parse_environment_variable(""some_boolean"", ""true"") is True\n        assert conf.parse_environment_variable(""some_boolean"", ""True"") is True\n        assert conf.parse_environment_variable(""some_boolean"", ""TRUE"") is True\n        assert conf.parse_environment_variable(""some_boolean"", ""1"") is True\n        assert conf.parse_environment_variable(""some_boolean"", 1) is True\n\n        assert conf.parse_environment_variable(""some_boolean"", ""false"") is False\n        assert conf.parse_environment_variable(""some_boolean"", ""False"") is False\n        assert conf.parse_environment_variable(""some_boolean"", ""FALSE"") is False\n        assert conf.parse_environment_variable(""some_boolean"", ""0"") is False\n        assert conf.parse_environment_variable(""some_boolean"", 0) is False\n\n    def test_parse_environment_variable_integer(self, monkeypatch):\n        """"""Tests that integer values can be parsed correctly from environment\n        variables.""""""\n\n        monkeypatch.setattr(conf, ""DEFAULT_CONFIG_SPEC"", {""api"": {""some_integer"": (int, 123)}})\n        assert conf.parse_environment_variable(""some_integer"", ""123"") == 123\n\n\nDEFAULT_KWARGS = {""hostname"": ""platform.strawberryfields.ai"", ""use_ssl"": True, ""port"": 443}\n\n\nclass MockSaveConfigToFile:\n    """"""A mock class used to contain the state left by the save_config_to_file\n    function.""""""\n\n    def __init__(self):\n        self.config = None\n        self.path = None\n\n    def update(self, config, path):\n        """"""Updates the instance attributes.""""""\n        self.config = config\n        self.path = path\n\n\ndef mock_create_config(authentication_token="""", **kwargs):\n    """"""A mock version of the create_config function adjusted to the\n    store_account function.\n    """"""\n    return {""api"": {""authentication_token"": authentication_token, **kwargs}}\n\n\nclass TestStoreAccount:\n    """"""Tests for the store_account function.""""""\n\n    def test_config_created_locally(self, monkeypatch, tmpdir):\n        """"""Tests that a configuration file was created in the current\n        directory.""""""\n        mock_save_config_file = MockSaveConfigToFile()\n\n        assert mock_save_config_file.config is None\n        assert mock_save_config_file.path is None\n\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: tmpdir)\n            m.setattr(conf, ""user_config_dir"", lambda *args: ""NotTheCorrectDir"")\n            m.setattr(conf, ""create_config"", mock_create_config)\n            m.setattr(conf, ""save_config_to_file"", lambda a, b: mock_save_config_file.update(a, b))\n            conf.store_account(\n                authentication_token, filename=""config.toml"", location=""local"", **DEFAULT_KWARGS\n            )\n\n        assert mock_save_config_file.config == EXPECTED_CONFIG\n        assert mock_save_config_file.path == tmpdir.join(""config.toml"")\n\n    def test_global_config_created(self, monkeypatch, tmpdir):\n        """"""Tests that a configuration file was created in the user\n        configuration directory for Strawberry Fields.""""""\n        mock_save_config_file = MockSaveConfigToFile()\n\n        assert mock_save_config_file.config is None\n        assert mock_save_config_file.path is None\n\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: ""NotTheCorrectDir"")\n            m.setattr(conf, ""user_config_dir"", lambda *args: tmpdir)\n            m.setattr(conf, ""create_config"", mock_create_config)\n            m.setattr(conf, ""save_config_to_file"", lambda a, b: mock_save_config_file.update(a, b))\n            conf.store_account(\n                authentication_token,\n                filename=""config.toml"",\n                location=""user_config"",\n                **DEFAULT_KWARGS\n            )\n\n        assert mock_save_config_file.config == EXPECTED_CONFIG\n        assert mock_save_config_file.path == tmpdir.join(""config.toml"")\n\n    def test_location_not_recognized_error(self, monkeypatch, tmpdir):\n        """"""Tests that an error is raised if the configuration file is supposed\n        to be created in an unrecognized directory.""""""\n\n        with pytest.raises(conf.ConfigurationError, match=""This location is not recognized.""):\n            conf.store_account(\n                authentication_token,\n                filename=""config.toml"",\n                location=""UNRECOGNIZED_LOCATION"",\n                **DEFAULT_KWARGS\n            )\n\n    def test_non_existing_directory_does_not_raise_file_not_found_error(self, monkeypatch, tmpdir):\n        """"""Tests that an error is raised if the configuration file is supposed\n        to be created in a non-existing directory when using user_config_dir\n        and if os.makedirs does not create the directory.""""""\n\n        with monkeypatch.context() as m:\n            m.setattr(conf, ""user_config_dir"", lambda *args: tmpdir.join(""new_dir""))\n            conf.store_account(\n                authentication_token,\n                filename=""config.toml"",\n                location=""user_config"",\n                **DEFAULT_KWARGS\n            )\n\n    def test_non_existing_directory_without_makedirs_raises_error(self, monkeypatch, tmpdir):\n        """"""Tests that an error is raised if the configuration file is supposed\n        to be created in a non-existing directory when using user_config_dir\n        and if os.makedirs does not create the directory.""""""\n\n        with monkeypatch.context() as m:\n            m.setattr(os, ""makedirs"", lambda a, **kwargs: None)\n            m.setattr(conf, ""user_config_dir"", lambda *args: tmpdir.join(""new_dir""))\n            with pytest.raises(FileNotFoundError, match=""No such file or directory""):\n                conf.store_account(\n                    authentication_token,\n                    filename=""config.toml"",\n                    location=""user_config"",\n                    **DEFAULT_KWARGS\n                )\n\n\nclass TestStoreAccountIntegration:\n    """"""Integration tests for the store_account function.\n\n    Mocking takes place only such that writing can be done in pytest\'s\n    temporary directory.\n    """"""\n\n    def test_local(self, monkeypatch, tmpdir):\n        """"""Tests that the functions integrate correctly when storing account\n        locally.""""""\n\n        with monkeypatch.context() as m:\n            m.setattr(os, ""getcwd"", lambda: tmpdir)\n            conf.store_account(\n                authentication_token, filename=""config.toml"", location=""local"", **DEFAULT_KWARGS\n            )\n\n        filepath = tmpdir.join(""config.toml"")\n        result = toml.load(filepath)\n        assert result == EXPECTED_CONFIG\n\n    def test_global(self, monkeypatch, tmpdir):\n        """"""Tests that the functions integrate correctly when storing account\n        globally.""""""\n\n        with monkeypatch.context() as m:\n            m.setattr(conf, ""user_config_dir"", lambda *args: tmpdir)\n            conf.store_account(\n                authentication_token,\n                filename=""config.toml"",\n                location=""user_config"",\n                **DEFAULT_KWARGS\n            )\n\n        filepath = tmpdir.join(""config.toml"")\n        result = toml.load(filepath)\n        assert result == EXPECTED_CONFIG\n\n    def test_directory_is_created(self, monkeypatch, tmpdir):\n\n        recursive_dir = tmpdir.join("".new_dir"")\n        with monkeypatch.context() as m:\n            m.setattr(conf, ""user_config_dir"", lambda *args: recursive_dir)\n            conf.store_account(\n                authentication_token,\n                filename=""config.toml"",\n                location=""user_config"",\n                **DEFAULT_KWARGS\n            )\n\n        filepath = os.path.join(recursive_dir, ""config.toml"")\n        result = toml.load(filepath)\n        assert result == EXPECTED_CONFIG\n\n    def test_nested_directory_is_created(self, monkeypatch, tmpdir):\n\n        recursive_dir = tmpdir.join("".new_dir"", ""new_dir_again"")\n        with monkeypatch.context() as m:\n            m.setattr(conf, ""user_config_dir"", lambda *args: recursive_dir)\n            conf.store_account(\n                authentication_token,\n                filename=""config.toml"",\n                location=""user_config"",\n                **DEFAULT_KWARGS\n            )\n\n        filepath = os.path.join(recursive_dir, ""config.toml"")\n        result = toml.load(filepath)\n        assert result == EXPECTED_CONFIG\n\n\nclass TestSaveConfigToFile:\n    """"""Tests for the store_account function.""""""\n\n    def test_correct(self, tmpdir):\n        """"""Test saving a configuration file.""""""\n        filepath = str(tmpdir.join(""config.toml""))\n\n        conf.save_config_to_file(OTHER_EXPECTED_CONFIG, filepath)\n\n        result = toml.load(filepath)\n        assert result == OTHER_EXPECTED_CONFIG\n\n    def test_file_already_existed(self, tmpdir):\n        """"""Test saving a configuration file even if the file already\n        existed.""""""\n        filepath = str(tmpdir.join(""config.toml""))\n\n        with open(filepath, ""w"") as f:\n            f.write(TEST_FILE)\n\n        result_for_existing_file = toml.load(filepath)\n        assert result_for_existing_file == EXPECTED_CONFIG\n\n        conf.save_config_to_file(OTHER_EXPECTED_CONFIG, filepath)\n\n        result_for_new_file = toml.load(filepath)\n        assert result_for_new_file == OTHER_EXPECTED_CONFIG\n'"
tests/frontend/test_decompositions.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the Strawberry Fields decompositions module""""""\nimport pytest\n\npytestmark = pytest.mark.frontend\n\nimport networkx as nx\nimport numpy as np\nimport scipy as sp\nfrom scipy.linalg import qr, block_diag\n\nfrom strawberryfields import decompositions as dec\n\nN_SAMPLES = 10\n\n\n# fix the seed to make the test deterministic\nnp.random.seed(42)\n\n\ndef omega(n):\n    """"""Returns the symplectic matrix for n modes""""""\n    idm = np.identity(n)\n    O = np.concatenate(\n        (np.concatenate((0 * idm, idm), axis=1), np.concatenate((-idm, 0 * idm), axis=1),), axis=0,\n    )\n    return O\n\n\ndef haar_measure(n):\n    """"""A Random matrix distributed with the Haar measure.\n\n    For more details, see :cite:`mezzadri2006`.\n\n    Args:\n        n (int): matrix size\n    Returns:\n        array: an nxn random matrix\n    """"""\n    z = (sp.randn(n, n) + 1j * sp.randn(n, n)) / np.sqrt(2.0)\n    q, r = qr(z)\n    d = sp.diagonal(r)\n    ph = d / np.abs(d)\n    q = np.multiply(q, ph, q)\n    return q\n\n\nclass TestTakagi:\n    """"""Takagi decomposition tests""""""\n\n    def test_square_validation(self):\n        """"""Test that the takagi decomposition raises exception if not square""""""\n        A = np.random.random([4, 5]) + 1j * np.random.random([4, 5])\n        with pytest.raises(ValueError, match=""matrix must be square""):\n            dec.takagi(A)\n\n    def test_symmetric_validation(self):\n        """"""Test that the takagi decomposition raises exception if not symmetric""""""\n        A = np.random.random([5, 5]) + 1j * np.random.random([5, 5])\n        with pytest.raises(ValueError, match=""matrix is not symmetric""):\n            dec.takagi(A)\n\n    def test_random_symm(self, tol):\n        """"""Verify that the Takagi decomposition, applied to a random symmetric\n        matrix, produced a decomposition that can be used to reconstruct the matrix.""""""\n        A = np.random.random([6, 6]) + 1j * np.random.random([6, 6])\n        A += A.T\n        rl, U = dec.takagi(A)\n        res = U @ np.diag(rl) @ U.T\n        assert np.allclose(res, A, atol=tol, rtol=0)\n\n    def test_real_degenerate(self):\n        """"""Verify that the Takagi decomposition returns a matrix that is unitary and results in a\n        correct decomposition when input a real but highly degenerate matrix. This test uses the\n        adjacency matrix of a balanced tree graph.""""""\n        g = nx.balanced_tree(2, 4)\n        a = nx.to_numpy_array(g)\n        rl, U = dec.takagi(a)\n        assert np.allclose(U @ U.conj().T, np.eye(len(a)))\n        assert np.allclose(U @ np.diag(rl) @ U.T, a)\n\n    def test_zeros(self):\n        """"""Verify that the Takagi decomposition returns a zero vector and identity matrix when\n        input a matrix of zeros""""""\n        dim = 4\n        a = np.zeros((dim, dim))\n        rl, U = dec.takagi(a)\n        assert np.allclose(rl, np.zeros(dim))\n        assert np.allclose(U, np.eye(dim))\n\n\nclass TestGraphEmbed:\n    """"""graph_embed tests""""""\n\n    def test_square_validation(self):\n        """"""Test that the graph_embed decomposition raises exception if not square""""""\n        A = np.random.random([4, 5]) + 1j * np.random.random([4, 5])\n        with pytest.raises(ValueError, match=""matrix is not square""):\n            dec.graph_embed(A)\n\n    def test_symmetric_validation(self):\n        """"""Test that the graph_embed decomposition raises exception if not symmetric""""""\n        A = np.random.random([5, 5]) + 1j * np.random.random([5, 5])\n        with pytest.raises(ValueError, match=""matrix is not symmetric""):\n            dec.graph_embed(A)\n\n    def test_max_mean_photon_deprecated(self, tol):\n        """"""This test verifies that the maximum amount of squeezing used to encode\n        the graph is indeed capped by the parameter max_mean_photon""""""\n        max_mean_photon = 2\n        A = np.random.random([6, 6]) + 1j * np.random.random([6, 6])\n        A += A.T\n        sc, _ = dec.graph_embed_deprecated(A, max_mean_photon=max_mean_photon)\n        res_mean_photon = np.sinh(np.max(np.abs(sc))) ** 2\n\n        assert np.allclose(res_mean_photon, max_mean_photon, atol=tol, rtol=0)\n\n    def test_make_traceless_deprecated(self, monkeypatch, tol):\n        """"""Test that A is properly made traceless""""""\n        A = np.random.random([6, 6]) + 1j * np.random.random([6, 6])\n        A += A.T\n\n        assert not np.allclose(np.trace(A), 0, atol=tol, rtol=0)\n\n        with monkeypatch.context() as m:\n            # monkeypatch the takagi function to simply return A,\n            # so that we can inspect it and make sure it is now traceless\n            m.setattr(dec, ""takagi"", lambda A, tol: (np.ones([6]), A))\n            _, A_out = dec.graph_embed_deprecated(A, make_traceless=True)\n\n        assert np.allclose(np.trace(A_out), 0, atol=tol, rtol=0)\n\n    def test_mean_photon(self, tol):\n        """"""Test that the mean photon number is correct in graph_embed""""""\n        num_modes = 6\n        A = np.random.random([num_modes, num_modes]) + 1j * np.random.random([num_modes, num_modes])\n        A += A.T\n        n_mean = 10.0 / num_modes\n        sc, _ = dec.graph_embed(A, mean_photon_per_mode=n_mean)\n        n_mean_calc = np.mean(np.sinh(sc) ** 2)\n\n        assert np.allclose(n_mean, n_mean_calc, atol=tol, rtol=0)\n\n\nclass TestBipartiteGraphEmbed:\n    """"""graph_embed tests""""""\n\n    def test_square_validation(self):\n        """"""Test that the graph_embed decomposition raises exception if not square""""""\n        A = np.random.random([4, 5]) + 1j * np.random.random([4, 5])\n        with pytest.raises(ValueError, match=""matrix is not square""):\n            dec.bipartite_graph_embed(A)\n\n    @pytest.mark.parametrize(""make_symmetric"", [True, False])\n    def test_mean_photon(self, tol, make_symmetric):\n        """"""Test that the mean photon number is correct in graph_embed""""""\n        num_modes = 6\n        A = np.random.random([num_modes, num_modes]) + 1j * np.random.random([num_modes, num_modes])\n        if make_symmetric:\n            A += A.T\n        n_mean = 1.0\n        sc, _, _ = dec.bipartite_graph_embed(A, mean_photon_per_mode=n_mean)\n        n_mean_calc = np.sum(np.sinh(sc) ** 2) / (num_modes)\n        assert np.allclose(n_mean, n_mean_calc, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""make_symmetric"", [True, False])\n    def test_correct_graph(self, tol, make_symmetric):\n        """"""Test that the graph is embeded correctly""""""\n        num_modes = 3\n        A = np.random.random([num_modes, num_modes]) + 1j * np.random.random([num_modes, num_modes])\n        U, l, V = np.linalg.svd(A)\n        new_l = np.array([np.tanh(np.arcsinh(np.sqrt(i))) for i in range(1, num_modes + 1)])\n        n_mean = 0.5 * (num_modes + 1)\n        if make_symmetric:\n            At = U @ np.diag(new_l) @ U.T\n        else:\n            At = U @ np.diag(new_l) @ V.T\n        sqf, Uf, Vf = dec.bipartite_graph_embed(At, mean_photon_per_mode=n_mean)\n\n        assert np.allclose(np.tanh(-np.flip(sqf)), new_l)\n        assert np.allclose(Uf @ np.diag(np.tanh(-sqf)) @ Vf.T, At)\n\n\nclass TestRectangularDecomposition:\n    """"""Tests for linear interferometer rectangular decomposition""""""\n\n    def test_unitary_validation(self):\n        """"""Test that an exception is raised if not unitary""""""\n        A = np.random.random([5, 5]) + 1j * np.random.random([5, 5])\n        with pytest.raises(ValueError, match=""matrix is not unitary""):\n            dec.rectangular(A)\n\n    @pytest.mark.parametrize(\n        ""U"",\n        [\n            pytest.param(np.identity(20), id=""identity20""),\n            pytest.param(np.identity(20)[::-1], id=""antiidentity20""),\n            pytest.param(haar_measure(20), id=""random20""),\n        ],\n    )\n    def test_rectangular(self, U, tol):\n        """"""This test checks the function :func:`dec.rectangular` for\n        various unitary matrices.\n\n        A given unitary (identity or random draw from Haar measure) is\n        decomposed using the function :func:`dec.rectangular`\n        and the resulting beamsplitters are multiplied together.\n\n        Test passes if the product matches the given unitary.\n        """"""\n        nmax, mmax = U.shape\n        assert nmax == mmax\n\n        tilist, diags, tlist = dec.rectangular(U)\n\n        qrec = np.identity(nmax)\n\n        for i in tilist:\n            qrec = dec.T(*i) @ qrec\n\n        qrec = np.diag(diags) @ qrec\n\n        for i in reversed(tlist):\n            qrec = dec.Ti(*i) @ qrec\n\n        assert np.allclose(U, qrec, atol=tol, rtol=0)\n\n    def test_random_unitary_phase_end(self, tol):\n        """"""This test checks the rectangular decomposition with phases at the end.\n\n        A random unitary is drawn from the Haar measure, then is decomposed\n        using Eq. 5 of the rectangular decomposition procedure of Clements et al,\n        i.e., moving all the phases to the end of the interferometer. The\n        resulting beamsplitters are multiplied together. Test passes if the\n        product matches the drawn unitary.\n        """"""\n        n = 20\n        U = haar_measure(n)\n\n        tlist, diags, _ = dec.rectangular_phase_end(U)\n\n        qrec = np.identity(n)\n\n        for i in tlist:\n            qrec = dec.T(*i) @ qrec\n\n        qrec = np.diag(diags) @ qrec\n\n        assert np.allclose(U, qrec, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(\n        ""U"",\n        [\n            pytest.param(np.identity(20), id=""identity20""),\n            pytest.param(np.identity(20)[::-1], id=""antiidentity20""),\n            pytest.param(haar_measure(20), id=""random20""),\n        ],\n    )\n    def test_rectangular_MZ(self, U, tol):\n        """"""This test checks the function :func:`dec.rectangular_MZ` for\n        various unitary matrices.\n\n        A given unitary (identity or random draw from Haar measure) is\n        decomposed using the function :func:`dec.rectangular_MZ`\n        and the resulting beamsplitters are multiplied together.\n\n        Test passes if the product matches the given unitary.\n        """"""\n        nmax, mmax = U.shape\n        assert nmax == mmax\n\n        tilist, diags, tlist = dec.rectangular_MZ(U)\n\n        qrec = np.identity(nmax)\n\n        for i in tilist:\n            qrec = dec.mach_zehnder(*i) @ qrec\n\n        qrec = np.diag(diags) @ qrec\n\n        for i in reversed(tlist):\n            qrec = dec.mach_zehnder_inv(*i) @ qrec\n\n        assert np.allclose(U, qrec, atol=tol, rtol=0)\n\n\nclass TestRectangularSymmetricDecomposition:\n    """"""Tests for linear interferometer decomposition into rectangular grid of\n    phase-shifters and pairs of symmetric beamsplitters""""""\n\n    def test_unitary_validation(self):\n        """"""Test that an exception is raised if not unitary""""""\n        A = np.random.random([5, 5]) + 1j * np.random.random([5, 5])\n        with pytest.raises(ValueError, match=""matrix is not unitary""):\n            dec.rectangular_symmetric(A)\n\n    @pytest.mark.parametrize(\n        ""U"",\n        [\n            pytest.param(np.identity(2), id=""identity2""),\n            pytest.param(np.identity(2)[::-1], id=""antiidentity2""),\n            pytest.param(haar_measure(2), id=""random2""),\n            pytest.param(np.identity(4), id=""identity4""),\n            pytest.param(np.identity(3)[::-1], id=""antiidentity4""),\n            pytest.param(haar_measure(4), id=""random4""),\n            pytest.param(np.identity(8), id=""identity8""),\n            pytest.param(np.identity(8)[::-1], id=""antiidentity8""),\n            pytest.param(haar_measure(8), id=""random8""),\n            pytest.param(np.identity(20), id=""identity20""),\n            pytest.param(np.identity(20)[::-1], id=""antiidentity20""),\n            pytest.param(haar_measure(20), id=""random20""),\n        ],\n    )\n    def test_decomposition(self, U, tol):\n        """"""This test checks the function :func:`dec.rectangular_symmetric` for\n        various unitary matrices.\n\n        A given unitary (identity or random draw from Haar measure) is\n        decomposed using the function :func:`dec.rectangular_symmetric`\n        and the resulting beamsplitters are multiplied together.\n\n        Test passes if the product matches the given unitary.\n        """"""\n        nmax, mmax = U.shape\n        assert nmax == mmax\n        tlist, diags, _ = dec.rectangular_symmetric(U)\n        qrec = np.identity(nmax)\n        for i in tlist:\n            assert i[2] >= 0 and i[2] < 2 * np.pi  # internal phase\n            assert i[3] >= 0 and i[3] < 2 * np.pi  # external phase\n            qrec = dec.mach_zehnder(*i) @ qrec\n        qrec = np.diag(diags) @ qrec\n        assert np.allclose(U, qrec, atol=tol, rtol=0)\n\n\nclass TestTriangularDecomposition:\n    """"""Tests for linear interferometer triangular decomposition""""""\n\n    def test_unitary_validation(self):\n        """"""Test that an exception is raised if not unitary""""""\n        A = np.random.random([5, 5]) + 1j * np.random.random([5, 5])\n        with pytest.raises(ValueError, match=""matrix is not unitary""):\n            dec.triangular(A)\n\n    def test_identity(self, tol):\n        """"""This test checks the rectangular decomposition for an identity unitary.\n\n        An identity unitary is decomposed via the rectangular decomposition of\n        Clements et al. and the resulting beamsplitters are multiplied together.\n        Test passes if the product matches identity.\n        """"""\n        # TODO: this test currently uses the T and Ti functions used to compute\n        # Clements as the comparison. Probably should be changed.\n        n = 20\n        U = np.identity(n)\n\n        tlist, diags, _ = dec.triangular(U)\n\n        qrec = np.diag(diags)\n\n        for i in tlist:\n            qrec = dec.Ti(*i) @ qrec\n\n        assert np.allclose(U, qrec, atol=tol, rtol=0)\n\n    def test_random_unitary(self, tol):\n        """"""This test checks the rectangular decomposition for a random unitary.\n\n        A random unitary is drawn from the Haar measure, then is decomposed via\n        the rectangular decomposition of Clements et al., and the resulting\n        beamsplitters are multiplied together. Test passes if the product\n        matches the drawn unitary.\n        """"""\n        # TODO: this test currently uses the T and Ti functions used to compute\n        # Clements as the comparison. Probably should be changed.\n        n = 20\n        U = haar_measure(n)\n\n        tlist, diags, _ = dec.triangular(U)\n\n        qrec = np.diag(diags)\n\n        for i in tlist:\n            qrec = dec.Ti(*i) @ qrec\n\n        assert np.allclose(U, qrec, atol=tol, rtol=0)\n\n\nclass TestWilliamsonDecomposition:\n    """"""Tests for the Williamson decomposition""""""\n\n    @pytest.fixture\n    def create_cov(self, hbar, tol):\n        """"""create a covariance state for use in testing.\n\n        Args:\n            nbar (array[float]): vector containing thermal state values\n\n        Returns:\n            tuple: covariance matrix and symplectic transform\n        """"""\n\n        def _create_cov(nbar):\n            """"""wrapped function""""""\n            n = len(nbar)\n            O = omega(n)\n\n            # initial vacuum state\n            cov = np.diag(2 * np.tile(nbar, 2) + 1) * hbar / 2\n\n            # interferometer 1\n            U1 = haar_measure(n)\n            S1 = np.vstack([np.hstack([U1.real, -U1.imag]), np.hstack([U1.imag, U1.real])])\n\n            # squeezing\n            r = np.log(0.2 * np.arange(n) + 2)\n            Sq = block_diag(np.diag(np.exp(-r)), np.diag(np.exp(r)))\n\n            # interferometer 2\n            U2 = haar_measure(n)\n            S2 = np.vstack([np.hstack([U2.real, -U2.imag]), np.hstack([U2.imag, U2.real])])\n\n            # final symplectic\n            S_final = S2 @ Sq @ S1\n\n            # final covariance matrix\n            cov_final = S_final @ cov @ S_final.T\n\n            # check valid symplectic transform\n            assert np.allclose(S_final.T @ O @ S_final, O)\n\n            # check valid state\n            eigs = np.linalg.eigvalsh(cov_final + 1j * (hbar / 2) * O)\n            eigs[np.abs(eigs) < tol] = 0\n            assert np.all(eigs >= 0)\n\n            if np.allclose(nbar, 0):\n                # check pure\n                assert np.allclose(np.linalg.det(cov_final), (hbar / 2) ** (2 * n))\n            else:\n                # check not pure\n                assert not np.allclose(np.linalg.det(cov_final), (hbar / 2) ** (2 * n))\n\n            return cov_final, S_final\n\n        return _create_cov\n\n    def test_square_validation(self):\n        """"""Test that the graph_embed decomposition raises exception if not square""""""\n        A = np.random.random([4, 5]) + 1j * np.random.random([4, 5])\n        with pytest.raises(ValueError, match=""matrix is not square""):\n            dec.williamson(A)\n\n    def test_symmetric_validation(self):\n        """"""Test that the graph_embed decomposition raises exception if not symmetric""""""\n        A = np.random.random([5, 5]) + 1j * np.random.random([5, 5])\n        with pytest.raises(ValueError, match=""matrix is not symmetric""):\n            dec.williamson(A)\n\n    def test_even_validation(self):\n        """"""Test that the graph_embed decomposition raises exception if not even number of rows""""""\n        A = np.random.random([5, 5]) + 1j * np.random.random([5, 5])\n        A += A.T\n        with pytest.raises(ValueError, match=""must have an even number of rows/columns""):\n            dec.williamson(A)\n\n    def test_positive_definite_validation(self):\n        """"""Test that the graph_embed decomposition raises exception if not positive definite""""""\n        A = np.diag([-2, 0.1, 2, 3])\n        with pytest.raises(ValueError, match=""matrix is not positive definite""):\n            dec.williamson(A)\n\n    def test_vacuum_state(self, tol, hbar):\n        """"""Test vacuum state""""""\n        V = np.identity(4)\n        Db, S = dec.williamson(V)\n        assert np.allclose(Db, np.identity(4), atol=tol, rtol=0)\n        assert np.allclose(S, np.identity(4), atol=tol, rtol=0)\n\n    def test_pure_state(self, create_cov, hbar, tol):\n        """"""Test pure state""""""\n        n = 3\n        O = omega(n)\n\n        cov, _ = create_cov(np.zeros([n]))\n\n        Db, S = dec.williamson(cov)\n        nbar = np.diag(Db) / hbar - 0.5\n\n        # check decomposition is correct\n        assert np.allclose(S @ Db @ S.T, cov, atol=tol, rtol=0)\n        # check nbar = 0\n        assert np.allclose(nbar, 0, atol=tol, rtol=0)\n        # check S is symplectic\n        assert np.allclose(S @ O @ S.T, O, atol=tol, rtol=0)\n\n    def test_mixed_state(self, create_cov, hbar, tol):\n        """"""Test mixed state""""""\n        n = 3\n        O = omega(n)\n        nbar_in = np.abs(np.random.random(n))\n\n        cov, _ = create_cov(nbar_in)\n\n        Db, S = dec.williamson(cov)\n        nbar = np.diag(Db) / hbar - 0.5\n\n        # check decomposition is correct\n        assert np.allclose(S @ Db @ S.T, cov, atol=tol, rtol=0)\n        # check nbar\n        assert np.allclose(sorted(nbar[:n]), sorted(nbar_in), atol=tol, rtol=0)\n        # check S is symplectic\n        assert np.allclose(S @ O @ S.T, O, atol=tol, rtol=0)\n\n\nclass TestBlochMessiahDecomposition:\n    """"""Tests for the Bloch-Messiah decomposition""""""\n\n    @pytest.fixture\n    def create_transform(self):\n        """"""create a symplectic transform for use in testing.\n\n        Args:\n            n (int): number of modes\n            passive (bool): whether transform should be passive or not\n\n        Returns:\n            array: symplectic matrix\n        """"""\n\n        def _create_transform(n, passive=True):\n            """"""wrapped function""""""\n            O = omega(n)\n\n            # interferometer 1\n            U1 = haar_measure(n)\n            S1 = np.vstack([np.hstack([U1.real, -U1.imag]), np.hstack([U1.imag, U1.real])])\n\n            Sq = np.identity(2 * n)\n            if not passive:\n                # squeezing\n                r = np.log(0.2 * np.arange(n) + 2)\n                Sq = block_diag(np.diag(np.exp(-r)), np.diag(np.exp(r)))\n\n            # interferometer 2\n            U2 = haar_measure(n)\n            S2 = np.vstack([np.hstack([U2.real, -U2.imag]), np.hstack([U2.imag, U2.real])])\n\n            # final symplectic\n            S_final = S2 @ Sq @ S1\n\n            # check valid symplectic transform\n            assert np.allclose(S_final.T @ O @ S_final, O)\n            return S_final\n\n        return _create_transform\n\n    def test_square_validation(self):\n        """"""Test raises exception if not square""""""\n        A = np.random.random([4, 5]) + 1j * np.random.random([4, 5])\n        with pytest.raises(ValueError, match=""matrix is not square""):\n            dec.bloch_messiah(A)\n\n    def test_symmplectic(self):\n        """"""Test raises exception if not symmetric""""""\n        A = np.random.random([6, 6]) + 1j * np.random.random([6, 6])\n        A += A.T\n        with pytest.raises(ValueError, match=""matrix is not symplectic""):\n            dec.bloch_messiah(A)\n\n    def test_even_validation(self):\n        """"""Test raises exception if not even number of rows""""""\n        A = np.random.random([5, 5]) + 1j * np.random.random([5, 5])\n        A += A.T\n        with pytest.raises(ValueError, match=""must have an even number of rows/columns""):\n            dec.bloch_messiah(A)\n\n    def test_identity(self, tol):\n        """"""Test identity""""""\n        n = 2\n        S_in = np.identity(2 * n)\n        O1, S, O2 = dec.bloch_messiah(S_in)\n\n        assert np.allclose(O1 @ O2, np.identity(2 * n), atol=tol, rtol=0)\n        assert np.allclose(S, np.identity(2 * n), atol=tol, rtol=0)\n\n        # test orthogonality\n        assert np.allclose(O1.T, O1, atol=tol, rtol=0)\n        assert np.allclose(O2.T, O2, atol=tol, rtol=0)\n\n        # test symplectic\n        O = omega(n)\n        assert np.allclose(O1 @ O @ O1.T, O, atol=tol, rtol=0)\n        assert np.allclose(O2 @ O @ O2.T, O, atol=tol, rtol=0)\n\n    def test_passive_transform(self, create_transform, tol):\n        """"""Test passive transform has no squeezing.\n        Note: this test also tests the case with degenerate symplectic values""""""\n        n = 3\n        S_in = create_transform(3, passive=True)\n        O1, S, O2 = dec.bloch_messiah(S_in)\n\n        # test decomposition\n        assert np.allclose(O1 @ S @ O2, S_in, atol=tol, rtol=0)\n\n        # test no squeezing\n        assert np.allclose(O1 @ O2, S_in, atol=tol, rtol=0)\n        assert np.allclose(S, np.identity(2 * n), atol=tol, rtol=0)\n\n        # test orthogonality\n        assert np.allclose(O1.T @ O1, np.identity(2 * n), atol=tol, rtol=0)\n        assert np.allclose(O2.T @ O2, np.identity(2 * n), atol=tol, rtol=0)\n\n        # test symplectic\n        O = omega(n)\n        # TODO: BUG:\n        # assert np.allclose(O1.T @ O @ O1, O, atol=tol, rtol=0)\n        # assert np.allclose(O2.T @ O @ O2, O, atol=tol, rtol=0)\n        assert np.allclose(S @ O @ S.T, O, atol=tol, rtol=0)\n\n    def test_active_transform(self, create_transform, tol):\n        """"""Test passive transform with squeezing""""""\n        n = 3\n        S_in = create_transform(3, passive=False)\n        O1, S, O2 = dec.bloch_messiah(S_in)\n\n        # test decomposition\n        assert np.allclose(O1 @ S @ O2, S_in, atol=tol, rtol=0)\n\n        # test orthogonality\n        assert np.allclose(O1.T @ O1, np.identity(2 * n), atol=tol, rtol=0)\n        assert np.allclose(O2.T @ O2, np.identity(2 * n), atol=tol, rtol=0)\n\n        # test symplectic\n        O = omega(n)\n        assert np.allclose(O1.T @ O @ O1, O, atol=tol, rtol=0)\n        assert np.allclose(O2.T @ O @ O2, O, atol=tol, rtol=0)\n        assert np.allclose(S @ O @ S.T, O, atol=tol, rtol=0)\n'"
tests/frontend/test_engine.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for engine.py""""""\nimport pytest\n\nimport strawberryfields as sf\nfrom strawberryfields import ops\nfrom strawberryfields.backends.base import BaseBackend\n\npytestmark = pytest.mark.frontend\n\n# pylint: disable=redefined-outer-name,no-self-use,bad-continuation,expression-not-assigned,pointless-statement\n\n\n@pytest.fixture\ndef eng(backend):\n    """"""Engine fixture.""""""\n    return sf.LocalEngine(backend)\n\n\n@pytest.fixture\ndef prog():\n    """"""Program fixture.""""""\n    prog = sf.Program(2)\n    with prog.context as q:\n        ops.Dgate(0.5) | q[0]\n    return prog\n\n\nbatch_engines = [\n    sf.Engine(""gaussian"", backend_options={""batch_size"": 2, ""cutoff_dim"": 6}),\n    sf.Engine(""fock"", backend_options={""batch_size"": 2, ""cutoff_dim"": 6}),\n    sf.Engine(""tf"", backend_options={""batch_size"": 2, ""cutoff_dim"": 6}),\n]\n\nengines = [\n    sf.Engine(""gaussian"", backend_options={""cutoff_dim"": 6}),\n    sf.Engine(""fock"", backend_options={""cutoff_dim"": 6}),\n    sf.Engine(""tf"", backend_options={""cutoff_dim"": 6}),\n]\n\n\nclass TestEngine:\n    """"""Test basic engine functionality""""""\n\n    def test_load_backend(self):\n        """"""Backend can be correctly loaded via strings""""""\n        eng = sf.LocalEngine(""base"")\n        assert isinstance(eng.backend, BaseBackend)\n\n    def test_bad_backend(self):\n        """"""Backend must be a string or a BaseBackend instance.""""""\n        with pytest.raises(TypeError, match=""backend must be a string or a BaseBackend instance""):\n            _ = sf.LocalEngine(0)\n\n\nclass TestEngineProgramInteraction:\n    """"""Test the Engine class and its interaction with Program instances.""""""\n\n    def test_history(self, eng, prog):\n        """"""Engine history.""""""\n        # no programs have been run\n        assert not eng.run_progs\n        eng.run(prog)\n        # one program has been run\n        assert len(eng.run_progs) == 1\n        assert eng.run_progs[-1] == prog  # no compilation required with BaseBackend\n\n    def test_reset(self, eng, prog):\n        """"""Running independent programs with an engine reset in between.""""""\n        assert not eng.run_progs\n        eng.run(prog)\n        assert len(eng.run_progs) == 1\n\n        eng.reset()\n        assert not eng.run_progs\n        p2 = sf.Program(3)\n        with p2.context as q:\n            ops.Rgate(1.0) | q[2]\n        eng.run(p2)\n        assert len(eng.run_progs) == 1\n\n    def test_regref_mismatch(self, eng):\n        """"""Running incompatible programs sequentially gives an error.""""""\n        p1 = sf.Program(3)\n        p2 = sf.Program(p1)\n        p1.locked = False\n        with p1.context as q:\n            ops.Del | q[0]\n\n        with pytest.raises(RuntimeError, match=""Register mismatch""):\n            eng.run([p1, p2])\n\n    def test_sequential_programs(self, eng):\n        """"""Running several program segments sequentially.""""""\n        D = ops.Dgate(0.2)\n        p1 = sf.Program(3)\n        with p1.context as q:\n            D | q[1]\n            ops.Del | q[0]\n        assert not eng.run_progs\n        eng.run(p1)\n        assert len(eng.run_progs) == 1\n\n        # p2 succeeds p1\n        p2 = sf.Program(p1)\n        with p2.context as q:\n            D | q[1]\n        eng.run(p2)\n        assert len(eng.run_progs) == 2\n\n        # p2 does not alter the register so it can be repeated\n        eng.run([p2] * 3)\n        assert len(eng.run_progs) == 5\n\n        eng.reset()\n        assert not eng.run_progs\n\n    def test_print_applied(self, eng):\n        """"""Tests the printing of executed programs.""""""\n        a = 0.23\n        r = 0.1\n\n        def inspect():\n            res = []\n            print_fn = lambda x: res.append(x.__str__())\n            eng.print_applied(print_fn)\n            return res\n\n        p1 = sf.Program(2)\n        with p1.context as q:\n            ops.Dgate(a) | q[1]\n            ops.Sgate(r) | q[1]\n\n        eng.run(p1)\n        expected1 = [\n            ""Run 0:"",\n            ""Dgate({}, 0) | (q[1])"".format(a),\n            ""Sgate({}, 0) | (q[1])"".format(r),\n        ]\n        assert inspect() == expected1\n\n        # run the program again\n        eng.reset()\n        eng.run(p1)\n        assert inspect() == expected1\n\n        # apply more commands to the same backend\n        p2 = sf.Program(2)\n        with p2.context as q:\n            ops.Rgate(r) | q[1]\n\n        eng.run(p2)\n        expected2 = expected1 + [""Run 1:"", ""Rgate({}) | (q[1])"".format(r)]\n        assert inspect() == expected2\n\n        # reapply history\n        eng.reset()\n        eng.run([p1, p2])\n        assert inspect() == expected2\n\n\nclass TestMultipleShotsErrors:\n    """"""Test if errors are raised correctly when using multiple shots.""""""\n\n    @pytest.mark.parametrize(""meng"", batch_engines)\n    def test_batching_error(self, meng, prog):\n        """"""Check that correct error is raised with batching and shots > 1.""""""\n        with pytest.raises(\n            NotImplementedError, match=""Batching cannot be used together with multiple shots.""\n        ):\n            meng.run(prog, **{""shots"": 2})\n\n    @pytest.mark.parametrize(""meng"", engines)\n    def test_postselection_error(self, meng):\n        """"""Check that correct error is raised with post-selection and shots > 1.""""""\n        prog = sf.Program(2)\n        with prog.context as q:\n            ops.MeasureFock(select=0) | q[0]\n\n        with pytest.raises(\n            NotImplementedError, match=""Post-selection cannot be used together with multiple shots.""\n        ):\n            meng.run(prog, **{""shots"": 2})\n\n    @pytest.mark.parametrize(""meng"", engines)\n    def test_feedforward_error(self, meng):\n        """"""Check that correct error is raised with feed-forwarding and shots > 1.""""""\n        prog = sf.Program(2)\n        with prog.context as q:\n            ops.MeasureFock() | q[0]\n            ops.Dgate(q[0].par) | q[1]\n\n        with pytest.raises(\n            NotImplementedError,\n            match=""Feed-forwarding of measurements cannot be used together with multiple shots."",\n        ):\n            meng.run(prog, **{""shots"": 2})\n'"
tests/frontend/test_io.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the IO module""""""\nimport pytest\n\nimport numpy as np\nimport blackbird\n\nimport strawberryfields as sf\nfrom strawberryfields import ops\nfrom strawberryfields import io\nfrom strawberryfields.program import Program, CircuitError\nfrom strawberryfields.parameters import MeasuredParameter, FreeParameter, par_is_symbolic, par_funcs as pf\n\n\npytestmark = pytest.mark.frontend\n\n\n# fmt: off\nU = np.array([[0.219546940711-0.256534554457j, 0.611076853957+0.524178937791j, -0.102700187435+0.474478834685j,-0.027250232925+0.03729094623j],\n              [0.451281863394+0.602582912475j, 0.456952590016+0.01230749109j, 0.131625867435-0.450417744715j, 0.035283194078-0.053244267184j],\n              [0.038710094355+0.492715562066j,-0.019212744068-0.321842852355j, -0.240776471286+0.524432833034j,-0.458388143039+0.329633367819j],\n              [-0.156619083736+0.224568570065j, 0.109992223305-0.163750223027j, -0.421179844245+0.183644837982j, 0.818769184612+0.068015658737j]\n    ])\n# fmt: on\n\n\n@pytest.fixture\ndef eng(backend):\n    """"""Engine fixture.""""""\n    return sf.LocalEngine(backend)\n\n\n@pytest.fixture(scope=""module"")\ndef prog():\n    prog = Program(4, name=""test_program"")\n\n    with prog.context as q:\n        # state preparation\n        ops.Vac | q[1]\n        ops.Squeezed(0.12) | q[2]\n\n        # one mode gates\n        ops.Sgate(1) | q[0]\n        ops.Dgate(a=0.54 + 0.5j) | q[1]\n\n        # two mode gates\n        ops.S2gate(0.543, -0.12) | (q[0], q[3])\n\n        # decomposition\n        ops.Interferometer(U) | q\n\n        # measurement\n        ops.MeasureX | q[0]\n        ops.MeasureHomodyne(0.43, select=0.32) | q[2]\n        ops.MeasureHomodyne(phi=0.43, select=0.32) | q[2]\n\n    return prog\n\n\ntest_prog_not_compiled = """"""\\\nname test_program\nversion 1.0\n\ncomplex array A0[4, 4] =\n    0.219546940711-0.256534554457j, 0.611076853957+0.524178937791j, -0.102700187435+0.474478834685j, -0.027250232925+0.03729094623j\n    0.451281863394+0.602582912475j, 0.456952590016+0.01230749109j, 0.131625867435-0.450417744715j, 0.035283194078-0.053244267184j\n    0.038710094355+0.492715562066j, -0.019212744068-0.321842852355j, -0.240776471286+0.524432833034j, -0.458388143039+0.329633367819j\n    -0.156619083736+0.224568570065j, 0.109992223305-0.163750223027j, -0.421179844245+0.183644837982j, 0.818769184612+0.068015658737j\n\nVacuum() | 1\nSqueezed(0.12, 0.0) | 2\nSgate(1, 0.0) | 0\nDgate(0.54+0.5j, 0.0) | 1\nS2gate(0.543, -0.12) | [0, 3]\nInterferometer(A0) | [0, 1, 2, 3]\nMeasureHomodyne(phi=0) | 0\nMeasureHomodyne(select=0.32, phi=0.43) | 2\nMeasureHomodyne(select=0.32, phi=0.43) | 2\n""""""\n\n\nclass TestSFToBlackbirdConversion:\n    """"""Tests for the io.to_blackbird utility function""""""\n\n    def test_metadata(self):\n        """"""Test metadata correctly converts""""""\n        # create a test program\n        prog = Program(4, name=""test_program"")\n        bb = io.to_blackbird(prog)\n\n        assert bb.name == ""test_program""\n        assert bb.version == ""1.0""\n        assert bb.target[""name""] is None\n\n        bb = io.to_blackbird(prog.compile(""gaussian""))\n\n        assert bb.name == ""test_program""\n        assert bb.version == ""1.0""\n        assert bb.target[""name""] == ""gaussian""\n\n    def test_metadata_run_options(self):\n        """"""Test run options correctly converts""""""\n        prog = Program(4, name=""test_program"")\n        bb = io.to_blackbird(prog.compile(""gaussian"", shots=1024))\n\n        assert bb.name == ""test_program""\n        assert bb.version == ""1.0""\n        assert bb.target[""name""] == ""gaussian""\n        assert bb.target[""options""] == {""shots"": 1024}\n\n    def test_gate_noarg(self):\n        """"""Test gate with no argument converts""""""\n        # create a test program\n        prog = Program(1)\n\n        with prog.context as q:\n            ops.Vac | q[0]\n\n        bb = io.to_blackbird(prog)\n        expected = {""op"": ""Vacuum"", ""modes"": [0], ""args"": [], ""kwargs"": {}}\n\n        assert bb.operations[0] == expected\n\n    def test_gate_arg(self):\n        """"""Test gate with argument converts""""""\n        # create a test program\n        prog = Program(2)\n\n        with prog.context as q:\n            ops.Sgate(0.54, 0.324) | q[1]\n\n        bb = io.to_blackbird(prog)\n        expected = {""op"": ""Sgate"", ""modes"": [1], ""args"": [0.54, 0.324], ""kwargs"": {}}\n\n        assert bb.operations[0] == expected\n\n    def test_gate_kwarg(self):\n        """"""Test gate with keyword argument converts""""""\n        # create a test program\n        prog = Program(2)\n\n        with prog.context as q:\n            ops.Dgate(a=0.54 + 0.324j) | q[1]\n\n        bb = io.to_blackbird(prog)\n        # Note: due to how SF stores quantum commands with the Parameter class,\n        # all kwargs get converted to positional args internally.\n        expected = {\n            ""op"": ""Dgate"",\n            ""modes"": [1],\n            ""args"": [0.54 + 0.324j, 0],\n            ""kwargs"": {},\n        }\n\n        assert bb.operations[0] == expected\n\n    def test_two_mode_gate(self):\n        """"""Test two mode gate converts""""""\n        prog = Program(4)\n\n        with prog.context as q:\n            ops.BSgate(0.54, -0.324) | (q[3], q[0])\n\n        bb = io.to_blackbird(prog)\n        expected = {\n            ""op"": ""BSgate"",\n            ""modes"": [3, 0],\n            ""args"": [0.54, -0.324],\n            ""kwargs"": {},\n        }\n\n        assert bb.operations[0] == expected\n\n    def test_decomposition_operation_not_compiled(self):\n        """"""Test decomposition operation""""""\n        # create a test program\n        prog = Program(4)\n\n        with prog.context as q:\n            ops.Interferometer(U) | q\n\n        bb = io.to_blackbird(prog)\n        expected = {\n            ""op"": ""Interferometer"",\n            ""modes"": [0, 1, 2, 3],\n            ""args"": [U],\n            ""kwargs"": {},\n        }\n\n        assert bb.operations[0] == expected\n\n    def test_decomposition_operation_compiled(self):\n        """"""Test decomposition operation gets decomposed if compiled""""""\n        # create a test program\n        prog = Program(1)\n\n        with prog.context as q:\n            ops.Pgate(0.43) | q[0]\n\n        bb = io.to_blackbird(prog)\n        expected = {""op"": ""Pgate"", ""modes"": [0], ""args"": [0.43], ""kwargs"": {}}\n        assert bb.operations[0] == expected\n\n        bb = io.to_blackbird(prog.compile(""gaussian""))\n        assert bb.operations[0][""op""] == ""Sgate""\n        assert bb.operations[1][""op""] == ""Rgate""\n\n    def test_measure_noarg(self):\n        """"""Test measurement with no argument converts""""""\n        # create a test program\n        prog = Program(1)\n\n        with prog.context as q:\n            ops.MeasureFock() | q[0]\n\n        bb = io.to_blackbird(prog)\n        expected = {""op"": ""MeasureFock"", ""modes"": [0], ""args"": [], ""kwargs"": {}}\n\n        assert bb.operations[0] == expected\n\n    def test_measure_postselect(self):\n        """"""Test measurement with postselection""""""\n        # create a test program\n        prog = Program(1)\n\n        with prog.context as q:\n            ops.MeasureFock(select=2) | q[0]\n\n        bb = io.to_blackbird(prog)\n        expected = {\n            ""op"": ""MeasureFock"",\n            ""modes"": [0],\n            ""args"": [],\n            ""kwargs"": {""select"": [2]},\n        }\n\n        assert bb.operations[0] == expected\n\n    def test_measure_darkcounts(self):\n        """"""Test measurement with dark counts""""""\n        # create a test program\n        prog = Program(1)\n\n        with prog.context as q:\n            ops.MeasureFock(dark_counts=2) | q[0]\n\n        bb = io.to_blackbird(prog)\n        expected = {\n            ""op"": ""MeasureFock"",\n            ""modes"": [0],\n            ""args"": [],\n            ""kwargs"": {""dark_counts"": [2]},\n        }\n\n        assert bb.operations[0] == expected\n\n    def test_measure_arg(self):\n        """"""Test measurement with argument converts""""""\n        # create a test program\n        prog = Program(1)\n\n        with prog.context as q:\n            ops.MeasureHomodyne(0.43) | q[0]\n\n        bb = io.to_blackbird(prog)\n        expected = {\n            ""op"": ""MeasureHomodyne"",\n            ""modes"": [0],\n            ""args"": [],\n            ""kwargs"": {""phi"": 0.43},\n        }\n\n        assert bb.operations[0] == expected\n\n    def test_measure_arg_postselect(self):\n        """"""Test measurement with argument and postselection converts""""""\n        # create a test program\n        prog = Program(1)\n\n        with prog.context as q:\n            ops.MeasureHomodyne(0.43, select=0.543) | q[0]\n\n        bb = io.to_blackbird(prog)\n        expected = {\n            ""op"": ""MeasureHomodyne"",\n            ""modes"": [0],\n            ""args"": [],\n            ""kwargs"": {""phi"": 0.43, ""select"": 0.543},\n        }\n\n        assert bb.operations[0] == expected\n\n        # repeat with kwargs only\n        prog = Program(1)\n\n        with prog.context as q:\n            ops.MeasureHomodyne(phi=0.43, select=0.543) | q[0]\n\n        bb = io.to_blackbird(prog)\n        assert bb.operations[0] == expected\n\n    def test_measured_par_str(self):\n        """"""Test a MeasuredParameter with some transformations converts properly""""""\n        prog = Program(2)\n        with prog.context as q:\n            ops.Sgate(0.43) | q[0]\n            ops.MeasureX | q[0]\n            ops.Zgate(2 * pf.sin(q[0].par)) | q[1]\n\n        bb = io.to_blackbird(prog)\n        expected = {""op"": ""Zgate"", ""modes"": [1], ""args"": [""2*sin(q0)""], ""kwargs"": {}}\n        assert bb.operations[-1] == expected\n\n    def test_free_par_str(self):\n        """"""Test a FreeParameter with some transformations converts properly""""""\n        prog = Program(2)\n        r, alpha = prog.params(\'r\', \'alpha\')\n        with prog.context as q:\n            ops.Sgate(r) | q[0]\n            ops.Zgate(3 * pf.log(-alpha)) | q[1]\n\n        bb = io.to_blackbird(prog)\n        assert bb.operations[0] == {""op"": ""Sgate"", ""modes"": [0], ""args"": [\'{r}\', 0.0], ""kwargs"": {}}\n        assert bb.operations[1] == {""op"": ""Zgate"", ""modes"": [1], ""args"": [\'3*log(-{alpha})\'], ""kwargs"": {}}\n\n\nclass TestBlackbirdToSFConversion:\n    """"""Tests for the io.to_program utility function""""""\n\n    def test_empty_program(self):\n        """"""Test empty program raises error""""""\n\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n        """"""\n\n        bb = blackbird.loads(bb_script)\n\n        with pytest.raises(ValueError, match=""contains no quantum operations""):\n            io.to_program(bb)\n\n    def test_gate_not_defined(self):\n        """"""Test unknown gate raises error""""""\n\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n\n        np | [0, 1]\n        """"""\n\n        bb = blackbird.loads(bb_script)\n\n        with pytest.raises(NameError, match=""operation np not defined""):\n            io.to_program(bb)\n\n    def test_metadata(self):\n        """"""Test metadata converts""""""\n\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n        Vac | 0\n        """"""\n\n        bb = blackbird.loads(bb_script)\n        prog = io.to_program(bb)\n\n        assert prog.name == bb.name\n        assert prog.name == \'test_program\'\n\n    def test_gate_no_arg(self):\n        """"""Test gate with no argument converts""""""\n\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n        Vac | 0\n        """"""\n\n        bb = blackbird.loads(bb_script)\n        prog = io.to_program(bb)\n\n        assert len(prog) == 1\n        assert prog.circuit[0].op.__class__.__name__ == ""Vacuum""\n        assert prog.circuit[0].reg[0].ind == 0\n\n    def test_gate_arg(self):\n        """"""Test gate with arguments converts""""""\n\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n        Sgate(0.54, 0.12) | 0\n        """"""\n\n        bb = blackbird.loads(bb_script)\n        prog = io.to_program(bb)\n\n        assert len(prog) == 1\n        assert prog.circuit[0].op.__class__.__name__ == ""Sgate""\n        assert prog.circuit[0].op.p[0] == 0.54\n        assert prog.circuit[0].op.p[1] == 0.12\n        assert prog.circuit[0].reg[0].ind == 0\n\n    def test_gate_kwarg(self):\n        """"""Test gate with keyword argument converts""""""\n\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n\n        Dgate(a=0.54) | 0\n        """"""\n\n        bb = blackbird.loads(bb_script)\n        prog = io.to_program(bb)\n\n        assert len(prog) == 1\n        assert prog.circuit[0].op.__class__.__name__ == ""Dgate""\n        assert prog.circuit[0].op.p[0] == 0.54\n        assert prog.circuit[0].reg[0].ind == 0\n\n    @pytest.mark.skip(""FIXME enable when blackbird.program.RegRefTransform is replaced with sympy.Symbol."")\n    def test_gate_measured_par(self):\n        """"""Test a gate with a MeasuredParameter argument.""""""\n\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n\n        MeasureX | 0\n        Dgate(q0) | 1\n        Rgate(2*q0) | 2\n        """"""\n        bb = blackbird.loads(bb_script)\n        prog = io.to_program(bb)\n\n        assert len(prog) == 3\n\n        cmd = prog.circuit[1]\n        assert cmd.op.__class__.__name__ == ""Dgate""\n        p = cmd.op.p[0]\n        assert isinstance(p, MeasuredParameter)\n        assert p.regref.ind == 0\n        assert cmd.reg[0].ind == 1\n\n        cmd = prog.circuit[2]\n        assert cmd.op.__class__.__name__ == ""Rgate""\n        p = cmd.op.p[0]\n        assert par_is_symbolic(p)  # symbolic expression\n        assert cmd.reg[0].ind == 2\n\n    def test_gate_free_par(self):\n        """"""Test a FreeParameter with some transformations converts properly""""""\n\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n\n        Dgate(a=1-{ALPHA}) | 0     # keyword arg, compound expr\n        Rgate(theta={foo_bar1}) | 0  # keyword arg, atomic\n        Dgate({ALPHA}**2) | 0        # positional arg, compound expr\n        Rgate({foo_bar2}) | 0        # positional arg, atomic\n        """"""\n        bb = blackbird.loads(bb_script)\n        prog = io.to_program(bb)\n\n        assert prog.free_params.keys() == set([\'foo_bar1\', \'foo_bar2\', \'ALPHA\'])\n        assert len(prog) == 4\n\n        cmd = prog.circuit[0]\n        assert cmd.op.__class__.__name__ == ""Dgate""\n        p = cmd.op.p[0]\n        assert par_is_symbolic(p)\n        assert cmd.reg[0].ind == 0\n\n        cmd = prog.circuit[1]\n        assert cmd.op.__class__.__name__ == ""Rgate""\n        p = cmd.op.p[0]\n        assert isinstance(p, FreeParameter)\n        assert p.name == \'foo_bar1\'\n        assert cmd.reg[0].ind == 0\n\n        cmd = prog.circuit[2]\n        assert cmd.op.__class__.__name__ == ""Dgate""\n        p = cmd.op.p[0]\n        assert par_is_symbolic(p)\n        assert cmd.reg[0].ind == 0\n\n        cmd = prog.circuit[3]\n        assert cmd.op.__class__.__name__ == ""Rgate""\n        p = cmd.op.p[0]\n        assert isinstance(p, FreeParameter)\n        assert p.name == \'foo_bar2\'\n        assert cmd.reg[0].ind == 0\n\n    def test_gate_multimode(self):\n        """"""Test multimode gate converts""""""\n\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n\n        BSgate(theta=0.54, phi=pi) | [0, 2]\n        """"""\n\n        bb = blackbird.loads(bb_script)\n        prog = io.to_program(bb)\n\n        assert len(prog) == 1\n        assert prog.circuit[0].op.__class__.__name__ == ""BSgate""\n        assert prog.circuit[0].op.p[0] == 0.54\n        assert prog.circuit[0].op.p[1] == np.pi\n        assert prog.circuit[0].reg[0].ind == 0\n        assert prog.circuit[0].reg[1].ind == 2\n\n    def test_valid_compilation(self):\n        """"""Test setting compilation target using the target keyword""""""\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n        target gaussian\n        Pgate(0.54) | 0\n        """"""\n        bb = blackbird.loads(bb_script)\n        prog = io.to_program(bb)\n\n        assert prog.target == \'gaussian\'\n        assert len(prog) == 2\n        assert prog.circuit[0].op.__class__.__name__ == ""Sgate""\n        assert prog.circuit[0].reg[0].ind == 0\n        assert prog.circuit[1].op.__class__.__name__ == ""Rgate""\n        assert prog.circuit[1].reg[0].ind == 0\n\n    def test_invalid_compilation(self):\n         """"""Test an invalid compilation target raises error on attempted compilation""""""\n         bb_script = """"""\\\n         name test_program\n         version 1.0\n         target gaussian\n         Kgate(0.54) | 0\n         """"""\n         bb = blackbird.loads(bb_script)\n         with pytest.raises(CircuitError, match=""cannot be used with the target""):\n             prog = io.to_program(bb)\n\n\nclass DummyResults:\n    """"""Dummy results object""""""\n\n\ndef dummy_run(self, program, args, compile_options=None, **eng_run_options):\n    """"""A dummy run function, that when called returns a dummy\n    results object, with run options available as an attribute.\n    This allows run_options to be returned and inspected after calling eng.run\n    """"""\n    results = DummyResults()\n    results.run_options = eng_run_options\n    return results\n\n\nclass TestEngineIntegration:\n    """"""Test that target options interface correctly with eng.run""""""\n\n    def test_shots(self, eng, monkeypatch):\n        """"""Test that passing shots correctly propagates to an engine run""""""\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n        target gaussian (shots=100)\n        Pgate(0.54) | 0\n        MeasureX | 0\n        """"""\n        bb = blackbird.loads(bb_script)\n        prog = io.to_program(bb)\n\n        assert prog.run_options == {""shots"": 100}\n\n        with monkeypatch.context() as m:\n            m.setattr(""strawberryfields.engine.BaseEngine._run"", dummy_run)\n            results = eng.run(prog)\n\n        assert results.run_options == {""shots"": 100}\n\n    def test_shots_overwritten(self, eng, monkeypatch):\n        """"""Test if run_options are passed to eng.run, they\n        overwrite those stored in the compiled program""""""\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n        target gaussian (shots=100)\n        Pgate(0.54) | 0\n        MeasureX | 0\n        """"""\n        bb = blackbird.loads(bb_script)\n        prog = io.to_program(bb)\n\n        assert prog.run_options == {""shots"": 100}\n\n        with monkeypatch.context() as m:\n            m.setattr(""strawberryfields.engine.BaseEngine._run"", dummy_run)\n            results = eng.run(prog, shots=1000)\n\n        assert results.run_options == {""shots"": 1000}\n\n    def test_program_sequence(self, eng, monkeypatch):\n        """"""Test that program run_options are successively\n        updated if a sequence of programs is executed.""""""\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n        target gaussian (shots=100)\n        Pgate(0.54) | 0\n        MeasureX | 0\n        """"""\n        bb = blackbird.loads(bb_script)\n        prog1 = io.to_program(bb)\n\n        bb_script = """"""\\\n        name test_program\n        version 1.0\n        target gaussian (shots=1024)\n        Pgate(0.54) | 0\n        MeasureX | 0\n        """"""\n        bb = blackbird.loads(bb_script)\n        prog2 = io.to_program(bb)\n\n        assert prog1.run_options == {""shots"": 100}\n        assert prog2.run_options == {""shots"": 1024}\n\n        with monkeypatch.context() as m:\n            m.setattr(""strawberryfields.engine.BaseEngine._run"", dummy_run)\n            results = eng.run([prog1, prog2])\n\n        assert results.run_options == prog2.run_options\n\n\nclass TestSave:\n    """"""Test sf.save functionality""""""\n\n    def test_save_filename_path_object(self, prog, tmpdir):\n        """"""Test saving a program to a file path using a path object""""""\n        filename = tmpdir.join(""test.xbb"")\n        sf.save(filename, prog)\n\n        with open(filename, ""r"") as f:\n            res = f.read()\n\n        assert res == test_prog_not_compiled\n\n    def test_save_filename_string(self, prog, tmpdir):\n        """"""Test saving a program to a file path using a string filename""""""\n        filename = str(tmpdir.join(""test.xbb""))\n        sf.save(filename, prog)\n\n        with open(filename, ""r"") as f:\n            res = f.read()\n\n        assert res == test_prog_not_compiled\n\n    def test_save_file_object(self, prog, tmpdir):\n        """"""Test writing a program to a file object""""""\n        filename = tmpdir.join(""test.xbb"")\n\n        with open(filename, ""w"") as f:\n            sf.save(f, prog)\n\n        with open(filename, ""r"") as f:\n            res = f.read()\n\n        assert res == test_prog_not_compiled\n\n    def test_save_append_extension(self, prog, tmpdir):\n        """"""Test appending the extension if not present""""""\n        filename = str(tmpdir.join(""test.txt""))\n        sf.save(filename, prog)\n\n        with open(filename+\'.xbb\', ""r"") as f:\n            res = f.read()\n\n        assert res == test_prog_not_compiled\n\n\nclass TestLoad:\n    """"""Test sf.load functionality""""""\n\n    def test_invalid_file(self, prog, tmpdir):\n        """"""Test exception is raised if file is invalid""""""\n        with pytest.raises(ValueError, match=""must be a string, path""):\n            sf.load(1)\n\n    def assert_programs_equal(self, prog1, prog2):\n        """"""Asserts that two SF Program objects are equivalent""""""\n        for cmd1, cmd2 in zip(prog1.circuit, prog2.circuit):\n            assert cmd1.op.__class__.__name__ == cmd2.op.__class__.__name__\n            assert cmd1.reg[0].ind == cmd2.reg[0].ind\n            if cmd1.op.p:\n                assert np.all(cmd1.op.p[0] == cmd2.op.p[0])\n\n    def test_load_filename_path_object(self, prog, tmpdir):\n        """"""Test loading a program using a path object""""""\n        filename = tmpdir.join(""test.xbb"")\n\n        with open(filename, ""w"") as f:\n            f.write(test_prog_not_compiled)\n\n        res = sf.load(filename)\n\n        # check loaded program is the same as expected\n        self.assert_programs_equal(res, prog)\n\n    def test_load_filename_string(self, prog, tmpdir):\n        """"""Test loading a program using a string filename""""""\n        filename = str(tmpdir.join(""test.xbb""))\n\n        with open(filename, ""w"") as f:\n            f.write(test_prog_not_compiled)\n\n        res = sf.load(filename)\n\n        # check loaded program is the same as expected\n        self.assert_programs_equal(res, prog)\n\n    def test_load_file_object(self, prog, tmpdir):\n        """"""Test loading a program via a file object""""""\n        filename = tmpdir.join(""test.xbb"")\n\n        with open(filename, ""w"") as f:\n            sf.save(f, prog)\n\n        with open(filename, ""r"") as f:\n            res = sf.load(f)\n\n        # check loaded program is the same as expected\n        self.assert_programs_equal(res, prog)\n\n    def test_loads(self, prog):\n        """"""Test loading a program from a string""""""\n        self.assert_programs_equal(io.loads(test_prog_not_compiled), prog)\n'"
tests/frontend/test_logger.py,0,"b'# Copyright 2010 Pallets\n\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n\n# 1. Redistributions of source code must retain the above copyright notice,\n#    this list of conditions and the following disclaimer.\n# 2. Redistributions in binary form must reproduce the above copyright notice,\n#    this list of conditions and the following disclaimer in the documentation\n#    and/or other materials provided with the distribution.\n# 3. Neither the name of the copyright holder nor the names of its contributors\n#    may be used to endorse or promote products derived from this software\n#    without specific prior written permission.\n\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\n# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the logging mechanism used in Strawberry Fields.\n\nThe implementation of these unit tests is based on the solution used for testing logging in\nthe Flask web application framework:\nhttps://github.com/pallets/flask/blob/master/tests/test_logging.py\n""""""\n\nimport logging\n\nimport pytest\n\nimport strawberryfields.api.job as job\nimport strawberryfields.api.connection as connection\nimport strawberryfields.engine as engine\n\nfrom strawberryfields.logger import logging_handler_defined, default_handler, create_logger\n\nmodules_contain_logging = [job, connection, engine]\n\n@pytest.fixture(autouse=True)\ndef reset_logging(pytestconfig):\n    """"""Reset the logging specific configurations such as handlers or levels as\n    well as manage pytest\'s LoggingPlugin.""""""\n    root_handlers = logging.root.handlers[:]\n    logging.root.handlers = []\n    root_level = logging.root.level\n\n    logging_plugin = pytestconfig.pluginmanager.unregister(name=""logging-plugin"")\n\n    yield\n\n    logging.root.handlers[:] = root_handlers\n    logging.root.setLevel(root_level)\n\n    if logging_plugin:\n        pytestconfig.pluginmanager.register(logging_plugin, ""logging-plugin"")\n\n\n@pytest.fixture(autouse=True)\ndef reset_logging_module():\n    """"""Reset the logging specific configurations such as handlers or levels for\n    the module specific loggers.""""""\n    for module in modules_contain_logging:\n        logger = logging.getLogger(module.__name__)\n        logger.handlers = []\n        logger.setLevel(logging.NOTSET)\n\n\n@pytest.mark.parametrize(""module"", modules_contain_logging)\nclass TestLogger:\n    """"""Tests for the functions that are used to create a logger""""""\n\n    def test_logging_handler_defined(self, module):\n        """"""Tests that the logging_handler_defined function works correctly in\n        the following cases:\n\n        1. When a custom logger was just created and by default has no level\n           handler\n        2. Adding a handler to the root logger affects the custom logger\n        3. When propagation is set to False, only the handlers of the custom\n        logger are checked""""""\n        logger = logging.getLogger(module.__name__)\n        assert not logging_handler_defined(logger)\n\n        handler = logging.StreamHandler()\n        logging.root.addHandler(handler)\n        assert logging_handler_defined(logger)\n\n        logger.propagate = False\n        assert not logging_handler_defined(logger)\n\n    def test_create_logger(self, module):\n        """"""Tests that the create_logger function returns a logger with the\n        default configuration set for an SF logger""""""\n        logger = create_logger(module.__name__)\n        assert logger.level == logging.INFO\n        assert logging_handler_defined(logger)\n        assert logger.handlers[0] == default_handler\n\nclass TestLoggerIntegration:\n    """"""Tests that the SF logger integrates well with user defined logging\n    configurations.""""""\n\n    def test_custom_configuration_without_sf_logger(self, tmpdir, caplog):\n        """"""Tests that if there was no SF logger created, custom logging\n        configurations work as expected and no configuration details were set\n        incorrectly.""""""\n\n        level = logging.DEBUG\n\n        test_file = tmpdir.join(""test_file"")\n        logging.basicConfig(filename=test_file, level=level)\n        logging.debug(""A log entry."")\n\n        assert ""A log entry."" in test_file.read()\n\n    @pytest.mark.parametrize(""module"", modules_contain_logging)\n    def test_default_sf_logger(self, module, capsys):\n        """"""Tests that stderr is set for the SF logger by default as stream if\n        there were not other configurations made.""""""\n        level = logging.DEBUG\n\n        logger = create_logger(module.__name__)\n        assert len(logger.handlers) == 1\n        assert logger.handlers[0].stream.name == ""<stderr>""\n\n    @pytest.mark.parametrize(""module"", modules_contain_logging)\n    def test_custom_logger_before_sf_logger_with_higher_level(self, module, tmpdir, caplog):\n        """"""Tests that a custom logger created before an SF logger will define\n        the level for logging as expected and the SF logger does not overwrite\n        the user configuration.\n\n        The logic of the test goes as follows:\n        1. Manually setting the level for logging for DEBUG level\n        2. Creating an SF logger with level WARNING, that is higher than DEBUG\n        3. Checking that the SF logger did not affect the handlers defined or\n           the effective level of the logger\n        """"""\n        custom_level = logging.DEBUG\n        sf_level = logging.WARNING\n\n        logger = logging.getLogger(module.__name__)\n        logging.basicConfig(level=custom_level)\n\n        sf_logger = create_logger(module.__name__, level=sf_level)\n\n        assert logging_handler_defined(logger)\n        assert logger.getEffectiveLevel() == custom_level\n'"
tests/frontend/test_ops_channel.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for Channel classes in ops.py""""""\nimport pytest\n\npytestmark = pytest.mark.frontend\n\nimport numpy as np\n\nimport strawberryfields as sf\n\nfrom strawberryfields import ops\nfrom strawberryfields.program_utils import MergeFailure\nfrom strawberryfields import utils\n\n\n# make test deterministic\nnp.random.seed(42)\na = np.random.random()\nb = np.random.random()\nc = np.random.random()\n\n\nclass TestChannelBasics:\n    """"""Test the basic properties of channels""""""\n\n    def test_loss_merging(self, tol):\n        """"""test the merging of two Loss channels (with default values\n        for optional parameters)""""""\n        G = ops.LossChannel(a)\n        merged = G.merge(ops.LossChannel(b))\n        assert np.allclose(merged.p[0], a * b, atol=tol, rtol=0)\n\n    def test_loss_merging_identity(self, tol):\n        """"""test the merging of two Loss channels such that\n        the resulting loss channel is simply the identity""""""\n        G = ops.LossChannel(a)\n        merged = G.merge(ops.LossChannel(1.0 / a))\n        assert merged is None\n\n    def test_thermalloss_merging_same_nbar(self, tol):\n        """"""test the merging of two Loss channels with same nbar""""""\n        G = ops.ThermalLossChannel(a, c)\n        merged = G.merge(ops.ThermalLossChannel(b, c))\n        assert np.allclose(merged.p[0], a * b, atol=tol, rtol=0)\n\n    def test_thermalloss_merging_different_nbar(self, tol):\n        """"""test the merging of two Loss channels with same nbar raises exception""""""\n        G = ops.ThermalLossChannel(a, 2 * c)\n        with pytest.raises(MergeFailure):\n            merged = G.merge(ops.ThermalLossChannel(b, c))\n\n    def test_thermalloss_merging_different_nbar(self, tol):\n        """"""test the merging of Loss and ThermalLoss raises exception""""""\n        G = ops.ThermalLossChannel(a, 2 * c)\n        with pytest.raises(MergeFailure):\n            merged = G.merge(ops.LossChannel(b))\n'"
tests/frontend/test_ops_decompositions.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# pylint: disable=no-self-use\n\nr""""""Unit tests for the Strawberry Fields decompositions within the ops module""""""\nimport pytest\n\nimport numpy as np\nfrom thewalrus.quantum import Amat\n\nimport strawberryfields as sf\nfrom strawberryfields.parameters import par_evaluate, FreeParameter\nfrom strawberryfields import decompositions as dec\nfrom strawberryfields.utils import random_interferometer, random_symplectic, random_covariance\nfrom strawberryfields import ops\n\n\npytestmark = pytest.mark.frontend\n\n\n# make the test file deterministic\nnp.random.seed(42)\n\n\ndef expand(S, modes, num_modes):\n    r""""""Expands a Symplectic matrix S to act on the entire subsystem.\n\n    Args:\n        S (array): a :math:`2M\\times 2M` Symplectic matrix\n        modes (Sequence[int]): the modes that S acts on\n        num_modes (int): total number of modes in the system\n\n    Returns:\n        array: the resulting :math:`2N\\times 2N` Symplectic matrix\n    """"""\n    if num_modes == 1:\n        # total number of modes is 1, simply return the matrix\n        return S\n\n    N = num_modes\n    w = np.asarray(modes)\n\n    M = len(S) // 2\n    S2 = np.identity(2 * N)\n\n    S2[w.reshape(-1, 1), w.reshape(1, -1)] = S[:M, :M].copy()  # XX\n    S2[(w + N).reshape(-1, 1), (w + N).reshape(1, -1)] = S[M:, M:].copy()  # PP\n    S2[w.reshape(-1, 1), (w + N).reshape(1, -1)] = S[:M, M:].copy()  # XP\n    S2[(w + N).reshape(-1, 1), w.reshape(1, -1)] = S[M:, :M].copy()  # PX\n\n    return S2\n\n\ndef _rotation(phi, mode, num_modes):\n    r""""""Utility function, returns the Heisenberg transformation of a phase rotation gate.\n\n    Args:\n        phi (float): rotation angle\n        mode (int): mode it is applied to\n        num_modes (int): total number of modes in the system\n\n    Returns:\n        array[float]: transformation matrix\n    """"""\n    c = np.cos(phi)\n    s = np.sin(phi)\n    S = np.array([[c, -s], [s, c]])\n\n    return expand(S, mode, num_modes)\n\n\ndef _squeezing(r, phi, mode, num_modes):\n    """"""Squeezing in the phase space.\n\n    Args:\n        r (float): squeezing magnitude\n        phi (float): rotation parameter\n        mode (int): mode it is applied to\n        num_modes (int): total number of modes in the system\n\n    Returns:\n        array: symplectic transformation matrix\n    """"""\n    cp = np.cos(phi)\n    sp = np.sin(phi)\n    ch = np.cosh(r)\n    sh = np.sinh(r)\n\n    S = np.array([[ch - cp * sh, -sp * sh], [-sp * sh, ch + cp * sh]])\n\n    return expand(S, mode, num_modes)\n\n\ndef _two_mode_squeezing(r, phi, modes, num_modes):\n    """"""Two mode squeezing in the phase space.\n\n    Args:\n        r (float): squeezing magnitude\n        phi (float): rotation parameter\n        modes (list[int]): modes it is applied to\n        num_modes (int): total number of modes in the system\n\n    Returns:\n        array: symplectic transformation matrix\n    """"""\n    cp = np.cos(phi)\n    sp = np.sin(phi)\n    ch = np.cosh(r)\n    sh = np.sinh(r)\n\n    S = np.array(\n        [\n            [ch, cp * sh, 0, sp * sh],\n            [cp * sh, ch, sp * sh, 0],\n            [0, sp * sh, ch, -cp * sh],\n            [sp * sh, 0, -cp * sh, ch],\n        ]\n    )\n\n    return expand(S, modes, num_modes)\n\n\ndef _beamsplitter(theta, phi, modes, num_modes):\n    r""""""Utility function, returns the Heisenberg transformation of a beamsplitter.\n\n    Args:\n        theta (float): beamsplitter angle.\n        phi (float): phase angle.\n        mode (list[int]): modes it is applied to\n        num_modes (int): total number of modes in the system\n\n    Returns:\n        array[float]: transformation matrix\n    """"""\n    cp = np.cos(phi)\n    sp = np.sin(phi)\n    ct = np.cos(theta)\n    st = np.sin(theta)\n\n    S = np.array(\n        [\n            [ct, -cp * st, 0, -st * sp],\n            [cp * st, ct, -st * sp, 0],\n            [0, st * sp, ct, -cp * st],\n            [st * sp, 0, cp * st, ct],\n        ]\n    )\n\n    return expand(S, modes, num_modes)\n\n\nclass TestDecompositions:\n    """"""Common tests for all Decompositions.""""""\n\n    @pytest.mark.parametrize(""cls"", ops.decompositions)\n    def test_symbolic_p0(self, cls):\n        """"""Decompositions cannot have a symbolic p[0].""""""\n\n        x = FreeParameter(""x"")\n        with pytest.raises(\n            TypeError,\n            match=""first parameter of a Decomposition is a square matrix, and cannot be symbolic"",\n        ):\n            cls(x)\n\n\nclass TestInterferometer:\n    """"""Tests for the interferometer quantum operation""""""\n\n    def test_merge(self, tol):\n        """"""Test that two interferometers merge: U = U1 @ U2""""""\n        n = 3\n        U1 = random_interferometer(n)\n        U2 = random_interferometer(n)\n\n        int1 = ops.Interferometer(U1)\n        int1inv = ops.Interferometer(U1.conj().T)\n        int2 = ops.Interferometer(U2)\n\n        # an interferometer merged with its inverse is identity\n        assert int1.merge(int1inv) is None\n\n        # two merged unitaries are the same as their product\n        assert np.allclose(int1.merge(int2).p[0], U2 @ U1, atol=tol, rtol=0)\n\n    def test_identity(self):\n        """"""Test that nothing is done if the unitary is the identity""""""\n        prog = sf.Program(2)\n\n        G = ops.Interferometer(np.identity(6))\n        # identity flag is correctly set\n        assert G.identity\n\n        # as a result, no gates are returned when decomposed\n        assert not G.decompose(prog.register)\n\n    def test_decomposition(self, tol):\n        """"""Test that an interferometer is correctly decomposed""""""\n        n = 3\n        prog = sf.Program(n)\n        U = random_interferometer(n)\n\n        G = ops.Interferometer(U)\n        cmds = G.decompose(prog.register)\n\n        S = np.identity(2 * n)\n\n        # calculating the resulting decomposed symplectic\n        for cmd in cmds:\n            # all operations should be BSgates or Rgates\n            assert isinstance(cmd.op, (ops.BSgate, ops.Rgate))\n\n            # build up the symplectic transform\n            modes = [i.ind for i in cmd.reg]\n\n            if isinstance(cmd.op, ops.Rgate):\n                S = _rotation(cmd.op.p[0], modes, n) @ S\n\n            if isinstance(cmd.op, ops.BSgate):\n                S = _beamsplitter(cmd.op.p[0], cmd.op.p[1], modes, n) @ S\n\n        # the resulting applied unitary\n        X1 = S[:n, :n]\n        P1 = S[n:, :n]\n        U_applied = X1 + 1j * P1\n\n        assert np.allclose(U, U_applied, atol=tol, rtol=0)\n\n\nclass TestGraphEmbed:\n    """"""Tests for the GraphEmbed quantum operation""""""\n\n    def test_identity(self):\n        """"""Test that nothing is done if the adjacency matrix is the identity""""""\n        G = ops.GraphEmbed(np.identity(6))\n        assert G.identity\n\n    def test_decomposition(self, tol):\n        """"""Test that an graph is correctly decomposed""""""\n        n = 3\n        prog = sf.Program(n)\n\n        A = np.random.random([n, n]) + 1j * np.random.random([n, n])\n        A += A.T\n        A -= np.trace(A) * np.identity(n) / n\n\n        sq, U = dec.graph_embed(A)\n\n        G = ops.GraphEmbed(A)\n        cmds = G.decompose(prog.register)\n\n        assert np.all(sq == G.sq)\n        assert np.all(U == G.U)\n\n        S = np.identity(2 * n)\n\n        # calculating the resulting decomposed symplectic\n        for cmd in cmds:\n            # all operations should be BSgates, Rgates, or Sgates\n            assert isinstance(cmd.op, (ops.Interferometer, ops.BSgate, ops.Rgate, ops.Sgate))\n\n            # build up the symplectic transform\n            modes = [i.ind for i in cmd.reg]\n\n            if isinstance(cmd.op, ops.Sgate):\n                S = _squeezing(cmd.op.p[0], cmd.op.p[1], modes, n) @ S\n\n            if isinstance(cmd.op, ops.Rgate):\n                S = _rotation(cmd.op.p[0], modes, n) @ S\n\n            if isinstance(cmd.op, ops.BSgate):\n                S = _beamsplitter(cmd.op.p[0], cmd.op.p[1], modes, n) @ S\n\n            if isinstance(cmd.op, ops.Interferometer):\n                U1 = cmd.op.p[0]\n                S_U = np.vstack([np.hstack([U1.real, -U1.imag]), np.hstack([U1.imag, U1.real])])\n                S = S_U @ S\n\n        # the resulting covariance state\n        cov = S @ S.T\n\n        # calculate Hamilton\'s A matrix: A = X.(I-Q^{-1})*\n        A_res = np.real_if_close(Amat(cov))\n\n        # The bottom right corner of A_res should be identical to A,\n        # up to some constant scaling factor. Check if the ratio\n        # of all elements is one\n        ratio = np.real_if_close(A_res[n:, n:] / A)\n        ratio /= ratio[0, 0]\n\n        assert np.allclose(ratio, np.ones([n, n]), atol=tol, rtol=0)\n\n    def test_decomposition_interferometer_with_zero(self, tol):\n        """"""Test that an graph is correctly decomposed when the interferometer\n        has one zero somewhere in the unitary matrix, which is the case for the\n        adjacency matrix below""""""\n        n = 6\n        prog = sf.Program(n)\n\n        A = np.array(\n            [\n                [0, 1, 0, 0, 1, 1],\n                [1, 0, 1, 0, 1, 1],\n                [0, 1, 0, 1, 1, 0],\n                [0, 0, 1, 0, 1, 0],\n                [1, 1, 1, 1, 0, 1],\n                [1, 1, 0, 0, 1, 0],\n            ]\n        )\n        _, U = dec.graph_embed(A)\n        assert not np.allclose(U, np.identity(n))\n\n        G = ops.GraphEmbed(A)\n        cmds = G.decompose(prog.register)\n        last_op = cmds[-1].op\n        param_val = last_op.p[0]\n\n        assert isinstance(last_op, ops.Interferometer)\n        assert last_op.ns == n\n        assert np.allclose(param_val, U, atol=tol, rtol=0)\n\n\nclass TestBipartiteGraphEmbed:\n    """"""Tests for the BipartiteGraphEmbed quantum operation""""""\n\n    def test_not_bipartite(self):\n        """"""Test exception raised if the graph is not bipartite""""""\n        A = np.array(\n            [\n                [0, 1, 0, 0, 1, 1],\n                [1, 0, 1, 0, 1, 1],\n                [0, 1, 0, 1, 1, 0],\n                [0, 0, 1, 0, 1, 0],\n                [1, 1, 1, 1, 0, 1],\n                [1, 1, 0, 0, 1, 0],\n            ]\n        )\n        with pytest.raises(ValueError, match=""does not represent a bipartite graph""):\n            ops.BipartiteGraphEmbed(A)\n\n        A = np.array(\n            [\n                [0, 0, 0, 0, 1, 1],\n                [0, 0, 0, 0, 1, 1],\n                [0, 0, 0, 1, 1, 0],\n                [0, 0, 0, 0, 0, 0],\n                [1, 1, 0, 0, 0, 0],\n                [1, 1, 0, 0, 0, 0],\n            ]\n        )\n        with pytest.raises(ValueError, match=""does not represent a bipartite graph""):\n            ops.BipartiteGraphEmbed(A)\n\n        A = np.array(\n            [\n                [0, 0, 1, 0, 1, 1],\n                [0, 0, 0, 0, 1, 1],\n                [0, 0, 0, 1, 1, 0],\n                [0, 0, 1, 0, 0, 0],\n                [1, 1, 1, 0, 0, 0],\n                [1, 1, 0, 0, 0, 0],\n            ]\n        )\n        with pytest.raises(ValueError, match=""does not represent a bipartite graph""):\n            ops.BipartiteGraphEmbed(A)\n\n    def test_decomposition(self, tol):\n        """"""Test that a graph is correctly decomposed""""""\n        n = 3\n        prog = sf.Program(2 * n)\n\n        A = np.zeros([2 * n, 2 * n])\n        B = np.random.random([n, n])\n\n        A[:n, n:] = B\n        A += A.T\n\n        sq, U, V = dec.bipartite_graph_embed(B)\n\n        G = ops.BipartiteGraphEmbed(A)\n        cmds = G.decompose(prog.register)\n\n        S = np.identity(4 * n)\n\n        # calculating the resulting decomposed symplectic\n        for cmd in cmds:\n            # all operations should be BSgates, Rgates, or S2gates\n            assert isinstance(cmd.op, (ops.Interferometer, ops.S2gate))\n\n            # build up the symplectic transform\n            modes = [i.ind for i in cmd.reg]\n\n            if isinstance(cmd.op, ops.S2gate):\n                # check that the registers are i, i+n\n                assert len(modes) == 2\n                assert modes[1] == modes[0] + n\n\n                r, phi = par_evaluate(cmd.op.p)\n                assert -r in sq\n                assert phi == 0\n\n                S = _two_mode_squeezing(r, phi, modes, 2 * n) @ S\n\n            if isinstance(cmd.op, ops.Interferometer):\n                # check that each unitary only applies to half the modes\n                assert len(modes) == n\n                assert modes in ([0, 1, 2], [3, 4, 5])\n\n                # check matrix is unitary\n                U1 = par_evaluate(cmd.op.p[0])\n                assert np.allclose(U1 @ U1.conj().T, np.identity(n), atol=tol, rtol=0)\n\n                if modes[0] == 0:\n                    assert np.allclose(U1, U, atol=tol, rtol=0)\n                else:\n                    assert modes[0] == 3\n                    assert np.allclose(U1, V, atol=tol, rtol=0)\n\n                S_U = np.vstack([np.hstack([U1.real, -U1.imag]), np.hstack([U1.imag, U1.real])])\n\n                S = expand(S_U, modes, 2 * n) @ S\n\n        # the resulting covariance state\n        cov = S @ S.T\n        A_res = Amat(cov)[: 2 * n, : 2 * n]\n\n        # The bottom right corner of A_res should be identical to A,\n        # up to some constant scaling factor. Check if the ratio\n        # of all elements is one\n        ratio = np.real_if_close(A_res[n:, :n] / B.T)\n        ratio /= ratio[0, 0]\n\n        assert np.allclose(ratio, np.ones([n, n]), atol=tol, rtol=0)\n\n\nclass TestGaussianTransform:\n    """"""Tests for the GaussianTransform quantum operation""""""\n\n    def test_merge(self, tol):\n        """"""Test that two symplectics merge: S = S2 @ S1""""""\n        n = 3\n        S1 = random_symplectic(n)\n        S2 = random_symplectic(n)\n\n        G1 = ops.GaussianTransform(S1)\n        G1inv = ops.GaussianTransform(np.linalg.inv(S1))\n        G2 = ops.GaussianTransform(S2)\n\n        # a symplectic merged with its inverse is identity\n        assert G1.merge(G1inv) is None\n\n        # two merged symplectics are the same as their product\n        assert np.allclose(G1.merge(G2).p[0], S2 @ S1, atol=tol, rtol=0)\n\n    def test_passive(self):\n        """"""Test that a passive decomposition is correctly flagged as requiring\n        only a single interferometer""""""\n        G = ops.GaussianTransform(np.identity(6))\n\n        assert not G.active\n        assert hasattr(G, ""U1"")\n        assert not hasattr(G, ""Sq"")\n        assert not hasattr(G, ""U2"")\n\n    def test_active(self):\n        """"""Test that an active decomposition is correctly flagged as requiring\n        two interferometers and squeezing""""""\n        S1 = random_symplectic(3, passive=False)\n        G = ops.GaussianTransform(S1)\n\n        assert G.active\n        assert hasattr(G, ""U1"")\n        assert hasattr(G, ""Sq"")\n        assert hasattr(G, ""U2"")\n\n    def test_decomposition_active(self, tol):\n        """"""Test that an active symplectic is correctly decomposed into\n        two interferometers and squeezing""""""\n        n = 3\n        S = random_symplectic(n, passive=False)\n\n        O1, Sq, O2 = dec.bloch_messiah(S)\n        X1 = O1[:n, :n]\n        P1 = O1[n:, :n]\n        X2 = O2[:n, :n]\n        P2 = O2[n:, :n]\n        U1 = X1 + 1j * P1\n        U2 = X2 + 1j * P2\n\n        prog = sf.Program(n)\n        G = ops.GaussianTransform(S)\n        cmds = G.decompose(prog.register)\n\n        assert np.all(U1 == G.U1)\n        assert np.all(U2 == G.U2)\n        assert np.all(np.diag(Sq)[:n] == G.Sq)\n\n        S = np.identity(2 * n)\n\n        # command queue should have 2 interferometers, 3 squeezers\n        assert len(cmds) == 5\n\n        # calculating the resulting decomposed symplectic\n        for cmd in cmds:\n            # all operations should be Interferometers or Sgates\n            assert isinstance(cmd.op, (ops.Interferometer, ops.Sgate))\n\n            # build up the symplectic transform\n            modes = [i.ind for i in cmd.reg]\n\n            if isinstance(cmd.op, ops.Sgate):\n                S = _squeezing(cmd.op.p[0], cmd.op.p[1], modes, n) @ S\n\n            if isinstance(cmd.op, ops.Interferometer):\n                U1 = cmd.op.p[0]\n                S_U = np.vstack([np.hstack([U1.real, -U1.imag]), np.hstack([U1.imag, U1.real])])\n                S = S_U @ S\n\n        # the resulting covariance state\n        cov = S @ S.T\n        assert np.allclose(cov, S @ S.T, atol=tol, rtol=0)\n\n    def test_decomposition_passive(self, tol):\n        """"""Test that a passive symplectic is correctly decomposed into an interferometer""""""\n        n = 3\n        S = random_symplectic(n, passive=True)\n        X1 = S[:n, :n]\n        P1 = S[n:, :n]\n        U1 = X1 + 1j * P1\n\n        prog = sf.Program(n)\n        G = ops.GaussianTransform(S)\n        cmds = G.decompose(prog.register)\n\n        S = np.identity(2 * n)\n\n        # command queue should have 1 interferometer\n        assert len(cmds) == 1\n\n        # calculating the resulting decomposed symplectic\n        for cmd in cmds:\n            # all operations should be Interferometers\n            assert isinstance(cmd.op, ops.Interferometer)\n\n            # build up the symplectic transform\n            # modes = [i.ind for i in cmd.reg]\n\n            if isinstance(cmd.op, ops.Interferometer):\n                U1 = cmd.op.p[0]\n                S_U = np.vstack([np.hstack([U1.real, -U1.imag]), np.hstack([U1.imag, U1.real])])\n                S = S_U @ S\n\n        # the resulting covariance state\n        cov = S @ S.T\n        assert np.allclose(cov, S @ S.T, atol=tol, rtol=0)\n\n    def test_active_on_vacuum(self, tol):\n        """"""Test that an active symplectic applied to a vacuum is\n        correctly decomposed into just squeezing and one interferometer""""""\n        n = 3\n        S = random_symplectic(n, passive=False)\n\n        O1, _, _ = dec.bloch_messiah(S)\n        X1 = O1[:n, :n]\n        P1 = O1[n:, :n]\n        # X2 = O2[:n, :n]\n        # P2 = O2[n:, :n]\n\n        U1 = X1 + 1j * P1\n        # U2 = X2 + 1j * P2\n\n        prog = sf.Program(n)\n        G = ops.GaussianTransform(S, vacuum=True)\n        cmds = G.decompose(prog.register)\n\n        S = np.identity(2 * n)\n\n        # command queue should have 3 Sgates, 1 interferometer\n        assert len(cmds) == 4\n\n        # calculating the resulting decomposed symplectic\n        for cmd in cmds:\n            # all operations should be Interferometers or Sgates\n            assert isinstance(cmd.op, (ops.Interferometer, ops.Sgate))\n\n            # build up the symplectic transform\n            modes = [i.ind for i in cmd.reg]\n\n            if isinstance(cmd.op, ops.Sgate):\n                S = _squeezing(cmd.op.p[0], cmd.op.p[1], modes, n) @ S\n\n            if isinstance(cmd.op, ops.Interferometer):\n                U1 = cmd.op.p[0]\n                S_U = np.vstack([np.hstack([U1.real, -U1.imag]), np.hstack([U1.imag, U1.real])])\n                S = S_U @ S\n\n        # the resulting covariance state\n        cov = S @ S.T\n\n        assert np.allclose(cov, S @ S.T, atol=tol, rtol=0)\n\n\nclass TestGaussian:\n    """"""Tests for the Gaussian quantum state preparation""""""\n\n    def test_merge(self, hbar):\n        """"""Test that merging two Preparations only keeps the latter one.""""""\n        n = 3\n        V1 = random_covariance(n, pure=False, hbar=hbar)\n        V2 = random_covariance(n, pure=True, hbar=hbar)\n        r1 = np.random.randn(2 * n)\n        r2 = np.random.randn(2 * n)\n\n        G1 = ops.Gaussian(V1, r1)\n        G2 = ops.Gaussian(V2, r2)\n\n        # applying a second state preparation replaces the first\n        assert G1.merge(G2) is G2\n\n        # the same is true of all state preparations\n        S = ops.Squeezed(2)\n        assert S.merge(G2) is G2\n        assert G2.merge(S) is S\n\n    def test_incorrect_means_length(self, hbar):\n        """"""Test that an exception is raised len(means)!=len(cov)""""""\n        cov = random_covariance(3, hbar=hbar)\n\n        with pytest.raises(ValueError, match=""must have the same length""):\n            ops.Gaussian(cov, r=np.array([0]))\n\n    def test_apply_decomp(self, hbar):\n        """"""Test that the apply method, when decomp = False, calls the Backend directly.""""""\n        prog = sf.Program(3)\n        cov = random_covariance(3, hbar=hbar)\n\n        class DummyBackend:\n            """"""Dummy backend class""""""\n\n            def prepare_gaussian_state(*args):\n                """"""Raises a syntax error when called""""""\n                raise SyntaxError\n\n        G = ops.Gaussian(cov, decomp=False)\n        with pytest.raises(SyntaxError):\n            G._apply(prog.register, DummyBackend())\n\n    def test_decomposition(self, hbar, tol):\n        """"""Test that an arbitrary decomposition provides the right covariance matrix""""""\n        n = 3\n        prog = sf.Program(n)\n        cov = random_covariance(n)\n\n        G = ops.Gaussian(cov)\n        cmds = G.decompose(prog.register)\n\n        S = np.identity(2 * n)\n        cov_init = np.identity(2 * n) * hbar / 2\n\n        # calculating the resulting decomposed symplectic\n        for cmd in cmds:\n            # all operations should be BSgates, Rgates, or Sgates\n            assert isinstance(cmd.op, (ops.Vacuum, ops.Thermal, ops.GaussianTransform))\n\n            # build up the symplectic transform\n            # modes = [i.ind for i in cmd.reg]\n\n            if isinstance(cmd.op, ops.Thermal):\n                cov_init[cmd.reg[0].ind, cmd.reg[0].ind] = (2 * cmd.op.p[0] + 1) * hbar / 2\n                cov_init[cmd.reg[0].ind + n, cmd.reg[0].ind + n] = (2 * cmd.op.p[0] + 1) * hbar / 2\n\n            if isinstance(cmd.op, ops.GaussianTransform):\n                S = cmd.op.p[0] @ S\n\n        # the resulting covariance state\n        cov_res = S @ cov_init @ S.T\n\n        assert np.allclose(cov, cov_res, atol=tol, rtol=0)\n\n    def test_thermal_decomposition(self, hbar, tol):\n        """"""Test that a thermal covariance matrix decomposes into Thermal preparations.""""""\n        n = 3\n        prog = sf.Program(n)\n        nbar = np.array([0.453, 0.23, 0.543])\n        cov = np.diag(np.tile(2 * nbar + 1, 2)) * hbar / 2\n\n        G = ops.Gaussian(cov)\n        cmds = G.decompose(prog.register)\n\n        assert len(cmds) == n\n\n        # calculating the resulting decomposed symplectic\n        for i, cmd in enumerate(cmds):\n            assert isinstance(cmd.op, ops.Thermal)\n            assert np.allclose(cmd.op.p[0], nbar[i], atol=tol, rtol=0)\n\n    def test_squeezed_decomposition(self, hbar, tol):\n        """"""Test that an axially squeezed covariance matrix decomposes into Squeezed preparations.""""""\n        n = 3\n        prog = sf.Program(n)\n\n        sq_r = np.array([0.453, 0.23, 0.543])\n        S = np.diag(np.exp(np.concatenate([-sq_r, sq_r])))\n        cov = S @ S.T * (hbar / 2)\n\n        G = ops.Gaussian(cov)\n        cmds = G.decompose(prog.register)\n\n        assert len(cmds) == n\n\n        # calculating the resulting decomposed symplectic\n        for i, cmd in enumerate(cmds):\n            assert isinstance(cmd.op, ops.Squeezed)\n            assert np.allclose(cmd.op.p[0], sq_r[i], atol=tol, rtol=0)\n            assert cmd.op.p[1] == 0\n\n    def test_rotated_squeezed_decomposition(self, hbar, tol):\n        """"""Test that a rotated squeezed covariance matrix decomposes into Squeezed preparations""""""\n        n = 3\n        prog = sf.Program(n)\n\n        sq_r = np.array([0.453, 0.23, 0.543])\n        sq_phi = np.array([-0.123, 0.2143, 0.021])\n\n        S = np.diag(np.exp(np.concatenate([-sq_r, sq_r])))\n\n        for i, phi in enumerate(sq_phi):\n            S = _rotation(phi / 2, i, n) @ S\n\n        cov = S @ S.T * (hbar / 2)\n        G = ops.Gaussian(cov)\n        cmds = G.decompose(prog.register)\n\n        assert len(cmds) == n\n\n        # calculating the resulting decomposed symplectic\n        for i, cmd in enumerate(cmds):\n            assert isinstance(cmd.op, ops.Squeezed)\n            assert np.allclose(cmd.op.p[0], sq_r[i], atol=tol, rtol=0)\n            assert np.allclose(cmd.op.p[1], sq_phi[i], atol=tol, rtol=0)\n\n    def test_degenerate_decomposition(self, hbar, tol):\n        """"""Test that a decomposition involving no squeezing results in a Vacuum preparation.""""""\n        n = 2\n        prog = sf.Program(n)\n\n        sq_r = np.array([0, 1.5])\n        S = np.diag(np.exp(np.concatenate([-sq_r, sq_r])))\n        cov = S @ S.T * (hbar / 2)\n\n        G = ops.Gaussian(cov)\n        cmds = G.decompose(prog.register)\n\n        assert len(cmds) == 2\n\n        for cmd in cmds[:1]:\n            assert isinstance(cmd.op, ops.Vacuum)\n\n        for cmd in cmds[1:]:\n            assert isinstance(cmd.op, ops.Squeezed)\n            assert np.allclose(cmd.op.p[0], sq_r[1], atol=tol, rtol=0)\n            assert np.allclose(cmd.op.p[1], 0, atol=tol, rtol=0)\n\n\nclass TestDisplacements:\n    """"""Test that special purpose displacement gates X and Z act as expected""""""\n\n    def test_Xgate_decomposition(self, hbar, tol):\n        """"""Test that the X gate is correctly decomposed into a displacement gate""""""\n        n = 1\n        prog = sf.Program(n)\n        x = 0.7\n        alpha = x / np.sqrt(2 * hbar)\n        X = ops.Xgate(x)\n        cmds = X.decompose(prog.register)\n        assert isinstance(cmds[0].op, ops.Dgate)\n        assert np.allclose(cmds[0].op.p[0], alpha, atol=tol, rtol=0)\n        assert np.allclose(cmds[0].op.p[1], 0, atol=tol, rtol=0)\n\n    def test_Zgate_decomposition(self, hbar, tol):\n        """"""Test that the Z gate is correctly decomposed into a displacement gate""""""\n        n = 1\n        prog = sf.Program(n)\n        p = 0.7\n        alpha = 1j * p / np.sqrt(2 * hbar)\n        Z = ops.Zgate(p)\n        cmds = Z.decompose(prog.register)\n        assert isinstance(cmds[0].op, ops.Dgate)\n\n        assert len(cmds) == 1\n        r = cmds[0].op.p[0]\n        phi = cmds[0].op.p[1]\n        assert np.allclose(r*np.exp(1j*phi), alpha, atol=tol, rtol=0)\n\n\nclass TestRotation:\n    """"""Test that special purpose rotation gates are correctly decomposed""""""\n\n    def test_Fourier_decomposition(self, hbar, tol):\n        """"""Test that Fourier is correctly decomposed""""""\n        n = 1\n        prog = sf.Program(n)\n        F = ops.Fourier\n        cmds = F.decompose(prog.register)\n        assert isinstance(cmds[0].op, ops.Rgate)\n        assert np.allclose(cmds[0].op.p[0], np.pi / 2, atol=tol, rtol=0)\n'"
tests/frontend/test_ops_gate.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for Gate classes in ops.py""""""\nimport pytest\n\npytestmark = pytest.mark.frontend\n\nimport numpy as np\n\nimport strawberryfields.program_utils as pu\n\nfrom strawberryfields import ops\nfrom strawberryfields.program import Program\nfrom strawberryfields.program_utils import MergeFailure, RegRefError\nfrom strawberryfields.parameters import par_evaluate\n\n\n# make test deterministic\nnp.random.seed(42)\nA = np.random.random()\nB = np.random.random()\nC = np.random.random()\n\n\n@pytest.mark.parametrize(""gate"", ops.gates)\nclass TestGateBasics:\n    """"""Test the basic properties of gates""""""\n\n    @pytest.fixture(autouse=True)\n    def prog(self):\n        """"""Dummy program context for each test""""""\n        prog = Program(2)\n        pu.Program_current_context = prog\n        yield prog\n        pu.Program_current_context = None\n\n    @pytest.fixture\n    def Q(self):\n        """"""The common test gate""""""\n        return ops.Xgate(0.5)\n\n    @pytest.fixture\n    def G(self, gate):\n        """"""Initialize each gate""""""\n        if gate in ops.zero_args_gates:\n            return gate()\n\n        if gate in ops.one_args_gates:\n            return gate(A)\n\n        if gate in ops.two_args_gates:\n            return gate(A, B)\n\n    @pytest.fixture\n    def H(self, gate):\n        """"""Second gate fixture of the same class, with same phase as G""""""\n        if gate in ops.zero_args_gates:\n            return gate()\n\n        if gate in ops.one_args_gates:\n            return gate(C)\n\n        if gate in ops.two_args_gates:\n            return gate(C, B)\n\n\n    def test_merge_inverse(self, G):\n        """"""gate merged with its inverse is the identity""""""\n        assert G.merge(G.H) is None\n\n    def test_merge_different_gate(self, G, Q):\n        """"""gates cannot be merged with a different type of gate""""""\n        if isinstance(G, Q.__class__):\n            pytest.skip(""Gates are the same type."")\n\n        with pytest.raises(MergeFailure, match=\'Not the same gate family.\'):\n            Q.merge(G)\n\n        with pytest.raises(MergeFailure, match=\'Not the same gate family.\'):\n            G.merge(Q)\n\n    def test_merge_incompatible_gate(self, gate):\n        """"""multi-parameter gates cannot be merged if the parameters other than the first are different""""""\n        if gate not in ops.two_args_gates:\n            pytest.skip(""Must be a multi-parameter gate."")\n\n        G = gate(A, B)\n        H = gate(A, C)\n\n        with pytest.raises(MergeFailure, match=""Don\'t know how to merge these gates.""):\n            H.merge(G)\n\n        with pytest.raises(MergeFailure, match=""Don\'t know how to merge these gates.""):\n            G.merge(H)\n\n    def test_wrong_number_subsystems(self, G):\n        """"""wrong number of subsystems""""""\n        with pytest.raises(ValueError, match=\'Wrong number of subsystems.\'):\n            if G.ns == 1:\n                G.__or__([0, 1])\n            else:\n                G.__or__(0)\n\n    def test_repeated_index(self, G):\n        """"""multimode gates: can\'t repeat the same index""""""\n        if G.ns == 2:\n            with pytest.raises(RegRefError, match=\'Trying to act on the same subsystem more than once.\'):\n                G.__or__([0, 0])\n\n    def test_non_trivial_merging(self, G, H):\n        """"""test the merging of two gates (with default values\n        for optional parameters)""""""\n        if G.__class__ in ops.zero_args_gates:\n            pytest.skip(""Gates with no arguments are not merged"")\n\n        merged = G.merge(H)\n\n        # should not be the identity\n        assert merged is not None\n\n        # first parameters should be added\n        assert merged.p[0] == G.p[0] + H.p[0]\n\n        # merge G with conjugate transpose of H\n        merged = G.merge(H.H)\n\n        # should not be the identity\n        assert merged is not None\n\n        # first parameters should be subtracted\n        assert merged.p[0] == G.p[0] - H.p[0]\n\n    def test_gate_dagger(self, G, monkeypatch):\n        """"""Test the dagger functionality of the gates""""""\n        G2 = G.H\n        assert not G.dagger\n        assert G2.dagger\n\n        def dummy_apply(self, reg, backend, **kwargs):\n            """"""Dummy apply function, used to store the evaluated params""""""\n            self.res = par_evaluate(self.p)\n\n        with monkeypatch.context() as m:\n            # patch the standard Operation class apply method\n            # with our dummy method, that stores the applied parameter\n            # in the attribute res. This allows us to extract\n            # and verify the parameter was properly negated.\n            m.setattr(G2.__class__, ""_apply"", dummy_apply)\n            G2.apply([], None)\n\n        orig_params = par_evaluate(G2.p)\n        applied_params = G2.res\n        # dagger should negate the first param\n        assert applied_params == [-orig_params[0]] + orig_params[1:]\n\n\ndef test_merge_measured_pars():\n    """"""Test merging two gates with measured parameters.""""""\n    prog = Program(2)\n    with prog.context as q:\n        ops.MeasureX | q[0]\n        mpar = q[0].par  # measured parameter\n        D = ops.Dgate(mpar)\n        F = ops.Dgate(1.0)\n        G = ops.Dgate(mpar, 0.1)  # different p[1]\n\n    # mp gates that are the inverse of each other\n    merged = D.merge(D.H)\n    assert merged is None\n\n    # combining measured and fixed parameters\n    assert F.merge(D).p[0] == mpar + 1.0\n    assert F.merge(D.H).p[0] == -mpar + 1.0\n    assert D.merge(F).p[0] == mpar + 1.0\n    assert D.merge(F.H).p[0] == mpar - 1.0\n\n    # gates that have different p[1] parameters\n    with pytest.raises(MergeFailure, match=""Don\'t know how to merge these gates.""):\n        assert D.merge(G)\n'"
tests/frontend/test_ops_metaoperation.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for MetaOperation classes in ops.py""""""\nimport pytest\n\npytestmark = pytest.mark.frontend\n\nimport numpy as np\n\nimport strawberryfields.program_utils as pu\nfrom strawberryfields import ops\nfrom strawberryfields.program import Program\nfrom strawberryfields.program_utils import MergeFailure, RegRefError, CircuitError\nfrom strawberryfields import utils\n\n\n# make test deterministic\nnp.random.seed(42)\na = np.random.random()\nb = np.random.random()\n\n\nclass TestProgramGateInteraction:\n    """"""Test gates correctly dispatch/modify the program""""""\n\n    @pytest.fixture\n    def prog(self):\n        """"""Dummy program context for each test""""""\n        prog = Program(2)\n        pu.Program_current_context = prog\n        yield prog\n        pu.Program_current_context = None\n\n    @pytest.mark.parametrize(""gate"", ops.one_args_gates + ops.two_args_gates)\n    def test_dispatch_one_mode_gates(self, gate):\n        """"""test one mode gates automatically add to the queue""""""\n        prog = Program(2)\n\n        if gate in ops.two_args_gates:\n            G = gate(a, b)\n        else:\n            G = gate(a)\n\n        if G.ns == 2:\n            pytest.skip(""test only for 1 mode gates."")\n\n        with prog.context:\n            G | 0\n            ops.All(G) | (0, 1)\n\n        assert len(prog) == 3\n        assert all(cmd.op == G for cmd in prog.circuit)\n        assert prog.circuit[0].reg[0].ind == 0\n        assert prog.circuit[1].reg[0].ind == 0\n        assert prog.circuit[2].reg[0].ind == 1\n\n    @pytest.mark.parametrize(""gate"", ops.one_args_gates + ops.two_args_gates)\n    def test_dispatch_two_mode_gates(self, gate):\n        """"""test two mode gates automatically add to the queue""""""\n        prog = Program(3)\n\n        if gate in ops.two_args_gates:\n            G = gate(a, b)\n        else:\n            G = gate(a)\n\n        if G.ns == 1:\n            pytest.skip(""test only for 1 mode gates."")\n\n        with prog.context:\n            G | (0, 1)\n            G | (0, 2)\n\n        assert len(prog) == 2\n        assert all(cmd.op == G for cmd in prog.circuit)\n        assert prog.circuit[0].reg[0].ind == 0\n        assert prog.circuit[0].reg[1].ind == 1\n        assert prog.circuit[1].reg[0].ind == 0\n        assert prog.circuit[1].reg[1].ind == 2\n\n    def test_create_or_exception(self):\n        """"""_New_modes must not be called via its __or__ method""""""\n        with pytest.raises(ValueError, match=\'Wrong number of subsystems\'):\n            ops._New_modes(1).__or__(0)\n\n    def test_create_outside_program_context(self):\n        """"""New() must be only called inside a Program context.""""""\n        with pytest.raises(RuntimeError, match=\'can only be called inside a Program context\'):\n            ops.New()\n\n    def test_create_non_positive_integer(self, prog):\n        """"""number of new modes must be a positive integer""""""\n        with pytest.raises(ValueError, match=\'is not a positive integer\'):\n            ops.New(-2)\n        with pytest.raises(ValueError, match=\'is not a positive integer\'):\n            ops.New(1.5)\n\n    def test_create_locked(self, prog):\n        """"""No new modes can be created in a locked Program.""""""\n        prog.lock()\n        with pytest.raises(CircuitError, match=\'The Program is locked, no new subsystems can be created\'):\n            ops.New(1)\n\n    def test_delete_locked(self, prog):\n        """"""No modes can be deleted in a locked Program.""""""\n        prog.lock()\n        with pytest.raises(CircuitError, match=\'The Program is locked, no more Commands can be appended to it\'):\n            ops.Del | 0\n\n    def test_delete_not_existing(self, prog):\n        """"""deleting nonexistent modes not allowed""""""\n        with pytest.raises(RegRefError, match=\'does not exist\'):\n            ops.Del.__or__(100)\n\n    def test_delete(self, prog):\n        """"""test deleting a mode""""""\n        q = prog.register\n        assert q[1].active\n        assert prog.num_subsystems == 2\n        ops.Del | q[1]\n        assert not q[1].active\n        assert prog.num_subsystems == 1\n\n    def test_create(self, prog):\n        """"""test creating a mode""""""\n        q = prog.register\n        assert prog.num_subsystems == 2\n        new_q, = ops.New(1)\n        assert new_q.active\n        assert prog.num_subsystems == 3\n\n    def test_delete_already_deleted(self, prog):\n        """"""deleting a mode that was already deleted""""""\n        q = prog.register\n        ops.Del | q[1]\n        with pytest.raises(RegRefError, match=\'has already been deleted\'):\n            ops.Del.__or__(1)\n\n    def test_create_delete_multiple_modes(self):\n        """"""test creating and deleting multiple modes""""""\n        prog = Program(3)\n\n        with prog.context as (alice, bob, charlie):\n            edward, frank, grace = ops.New(3)\n            ops.Del | (alice, grace)\n\n        # register should only return the active subsystems\n        q = prog.register\n        assert len(q) == prog.num_subsystems\n        assert len(q) == 4\n        # Program.reg_refs contains all the regrefs, active and inactive\n        assert len(prog.reg_refs) == 6\n'"
tests/frontend/test_ops_preparation.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for Preparation classes in ops.py""""""\nimport pytest\n\npytestmark = pytest.mark.frontend\n\nimport numpy as np\n\nfrom strawberryfields import ops\nfrom strawberryfields.program import Program\nfrom strawberryfields.program_utils import MergeFailure, RegRefError\nfrom strawberryfields import utils\n\n\n@pytest.mark.parametrize(""state"", ops.simple_state_preparations)  # these have __init__ methods with default arguments\nclass TestStatePreparationBasics:\n    """"""Basic properties of state preparation operations.""""""\n\n    def test_merge(self, state):\n        """"""Test that merging states simply returns the second state""""""\n        # state to test against\n        V = ops.Vacuum()\n        G = state()\n\n        # merging with another state returns the last one\n        assert np.all(G.merge(V) == V)\n        assert np.all(V.merge(G) == G)\n\n    def test_exceptions(self, state):\n        """"""Test exceptions raised if state prep used on invalid modes""""""\n        G = state()\n        prog = Program(2)\n\n        with prog.context:\n            # all states act on a single mode\n            with pytest.raises(ValueError):\n                G.__or__([0, 1])\n\n            # can\'t repeat the same index\n            with pytest.raises(RegRefError):\n                ops.All(G).__or__([0, 0])\n'"
tests/frontend/test_parameters.py,5,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Unit tests for the parameters.py module.""""""\n\nimport pytest\nimport numpy as np\n\nimport strawberryfields as sf\nfrom strawberryfields.parameters import (par_is_symbolic, par_regref_deps, par_str, par_evaluate,\n                                         MeasuredParameter, FreeParameter, par_funcs as pf,\n                                         ParameterError)\nfrom strawberryfields.program_utils import RegRef\n\n\npytestmark = pytest.mark.frontend\n\n\n# make test deterministic\nnp.random.seed(32)\n\nSCALAR_TEST_VALUES = [3, 0.14, 4.2 + 0.5j]\nTEST_VALUES = SCALAR_TEST_VALUES + [np.array([0.1, 0.987654])]\n\n\ndef binary_arithmetic(pp, qq, p, q):\n    """"""Test the correctness of basic binary arithmetic expressions.""""""\n    assert par_evaluate(pp + qq) == pytest.approx(p + q)\n    assert par_evaluate(pp - qq) == pytest.approx(p - q)\n    assert par_evaluate(pp * qq) == pytest.approx(p * q)\n    assert par_evaluate(pp / qq) == pytest.approx(p / q)\n    assert par_evaluate(pp ** qq) == pytest.approx(p ** q)\n\n\nclass TestParameter:\n    """"""Basic parameter functionality.""""""\n\n    def test_measured_par(self):\n        """"""Compare two ways of creating measured parameter instances from RegRefs.""""""\n        r = RegRef(0)\n        s = RegRef(1)\n        p = MeasuredParameter(r)\n        assert p == r.par\n        assert p != s.par\n\n    @pytest.mark.parametrize(""r"", TEST_VALUES)\n    def test_par_is_symbolic(self, r):\n        """"""Recognizing symbolic parameters.""""""\n        p = FreeParameter(\'x\')\n        q = MeasuredParameter(RegRef(0))\n\n        assert not par_is_symbolic(r)\n        assert par_is_symbolic(pf.sin(r))\n        assert par_is_symbolic(q)\n        assert par_is_symbolic(p)\n        assert par_is_symbolic(pf.sin(p))\n        assert par_is_symbolic(p + r)\n        assert par_is_symbolic(p - r)\n        assert par_is_symbolic(p * r)\n        assert par_is_symbolic(p / r)\n        assert par_is_symbolic(p ** r)\n        assert par_is_symbolic(p - p)  # no simplification\n\n        # object array with symbols\n        a = np.array([[0.1, 3, 0], [0.3, 2, p], [1, 2, 4]])\n        assert a.dtype == object\n        assert par_is_symbolic(a)\n\n        # object array, no symbols\n        a = np.array([[0.1, 3, 0], [0.3, 2, 0], [1, 2, 4]], dtype=object)\n        assert a.dtype == object\n        assert not par_is_symbolic(a)\n\n        # float array, no symbols\n        a = np.array([[0.1, 3, 0], [0.3, 2, 0], [1, 2, 4]])\n        assert a.dtype != object\n        assert not par_is_symbolic(a)\n        assert par_is_symbolic(pf.sin(a))\n\n    def test_par_regref_deps(self):\n        """"""RegRef dependencies of parameters.""""""\n        r = [RegRef(k) for k in range(2)]\n        R0 = set([r[0]])\n        R = set(r)\n\n        s = 0.4\n        x = FreeParameter(\'x\')\n        p = MeasuredParameter(r[0])\n        q = MeasuredParameter(r[1])\n\n        assert par_regref_deps(s) == set()\n        assert par_regref_deps(x) == set()\n        assert par_regref_deps(p) == R0\n        assert par_regref_deps(s * p) == R0\n        assert par_regref_deps(x * p) == R0\n        assert par_regref_deps(p + q) == R\n        assert par_regref_deps(s * p + q ** x) == R\n\n    def test_par_str(self):\n        """"""String representations of parameters.""""""\n\n        a = 0.1234567\n        b = np.array([0, 0.987654])\n        c = MeasuredParameter(RegRef(1))\n        d = FreeParameter(\'x\')\n\n        assert par_str(a) == \'0.1235\'  # rounded to 4 decimals\n        assert par_str(b) == \'[0.     0.9877]\'\n        assert par_str(c) == \'q1\'\n        assert par_str(d) == \'{x}\'\n        assert par_str(b * d) == \'[0 0.987654*{x}]\'  # not rounded to 4 decimals due to Sympy\'s internal settings (object array!)\n\n    def test_raw_parameter_printing(self):\n        """"""Raw printing of parameter expressions.""""""\n\n        c = MeasuredParameter(RegRef(1))\n        d = FreeParameter(\'x\')\n\n        assert str(c) == \'q1\'\n        assert str(d) == \'{x}\'\n        assert str(0.1234567 * d) == \'0.1234567*{x}\'\n        assert str(np.array([0, 1, -3, 0.987654]) * d) == \'[0 1.0*{x} -3.0*{x} 0.987654*{x}]\'\n        assert str(pf.exp(1 + c) / d ** 2) == \'exp(q1 + 1)/{x}**2\'\n\n    def test_par_functions_with_arrays(self):\n        """"""Parameter functions with array arguments.""""""\n        a = np.ones((2, 2))\n        b = np.ones((2, 3))\n        c = np.ones((2,))\n        d = np.ones((2, 2))\n\n        with pytest.raises(ValueError, match=""all the arguments must be arrays of the same shape""):\n            pf.beta(a, b)\n        with pytest.raises(ValueError, match=""all the arguments must be arrays of the same shape""):\n            pf.beta(a, 1)\n        with pytest.raises(ValueError, match=""all the arguments must be arrays of the same shape""):\n            pf.beta(1, a)\n        with pytest.raises(ValueError, match=""all the arguments must be arrays of the same shape""):\n            pf.beta(a, c)\n\n        res = pf.beta(a, d)\n        assert res.shape == a.shape\n        assert res.dtype == object\n\n    @pytest.mark.parametrize(""p"", TEST_VALUES)\n    def test_par_evaluate(self, p):\n        x = FreeParameter(\'x\')\n        with pytest.raises(ParameterError, match=""unbound parameter with no default value""):\n            par_evaluate(x)\n\n        # val only\n        x.val = p\n        assert np.all(par_evaluate(x) == p)\n\n        # default only\n        x.val = None\n        x.default = p\n        assert np.all(par_evaluate(x) == p)\n\n        # both val and default\n        x.val = p\n        x.default = 0.0\n        assert np.all(par_evaluate(x) == p)\n\n    @pytest.mark.parametrize(""dtype"", [np.complex128, np.complex64])\n    @pytest.mark.parametrize(""p"", TEST_VALUES)\n    def test_par_evaluate_dtype_numpy(self, p, dtype):\n        """"""Test the numpy parameter evaluation works when a dtype is provided""""""\n        x = FreeParameter(""x"")\n        x.val = p\n        res = par_evaluate(x, dtype=dtype)\n        assert res.dtype.type is dtype\n\n    @pytest.mark.parametrize(""dtype"", [np.complex128, np.complex64])\n    @pytest.mark.parametrize(""p"", TEST_VALUES)\n    def test_par_evaluate_dtype_TF(self, p, dtype):\n        """"""Test the TF parameter evaluation works when a dtype is provided""""""\n        pytest.importorskip(""tensorflow"", minversion=""2.0"")\n        import tensorflow as tf\n\n        x = FreeParameter(""x"")\n        x.val = tf.Variable(p)\n        res = par_evaluate(x, dtype=dtype)\n        assert res.dtype is tf.as_dtype(dtype)\n\n    @pytest.mark.parametrize(""p"", TEST_VALUES)\n    @pytest.mark.parametrize(""q"", TEST_VALUES)\n    def test_parameter_arithmetic(self, p, q):\n        """"""Test parameter arithmetic works as expected,""""""\n        pp = FreeParameter(\'x\')\n        qq = FreeParameter(\'y\')\n        pp.val = p\n        qq.val = q\n        binary_arithmetic(pp, qq, p, q)\n\n    @pytest.mark.parametrize(""p"", TEST_VALUES)\n    @pytest.mark.parametrize(""q"", SCALAR_TEST_VALUES)\n    # adding an array to an array works elementwise in numpy, but symbolically one array is added to each element of the other array...\n    def test_parameter_left_literal_arithmetic(self, p, q):\n        """"""Test parameter arithmetic works as expected.""""""\n        qq = FreeParameter(\'x\')\n        qq.val = q\n        binary_arithmetic(p, qq, p, q)\n\n    @pytest.mark.parametrize(""p"", TEST_VALUES)\n    @pytest.mark.parametrize(""q"", SCALAR_TEST_VALUES)\n    def test_parameter_right_literal_arithmetic(self, p, q):\n        """"""Test parameter arithmetic works as expected.""""""\n        pp = FreeParameter(\'x\')\n        pp.val = p\n        binary_arithmetic(pp, q, p, q)\n\n    @pytest.mark.parametrize(""p"", TEST_VALUES)\n    def test_parameter_unary_negation(self, p):\n        """"""Test unary negation works as expected.""""""\n        pp = FreeParameter(\'x\')\n        pp.val = p\n        assert par_evaluate(-p) == pytest.approx(-p)\n        assert par_evaluate(-pp) == pytest.approx(-p)\n\n\n@pytest.fixture\ndef applied_cmds(monkeypatch):\n    """"""This fixture returns a list that dynamically keeps track\n    of any applied commands within a test.\n\n    Simply include this fixture in a test; any local calls to\n    ``eng.run`` will subsequently be reflected in the fixture.\n\n    Returns:\n        list (Command): commands that were applied to the engine\n    """"""\n    applied = []\n\n    def mock_run_prog(self, prog, **kwargs):\n        """"""Mock function that is used for extracting\n        the engine queue when running programs.""""""\n        for cmd in prog.circuit:\n            try:\n                cmd.op.apply(cmd.reg, self.backend, **kwargs)\n                applied.append(cmd)\n            except NotImplementedError:\n                for c in cmd.op._decompose(cmd.reg, **kwargs):\n                    c.op.apply(c.reg, self.backend, **kwargs)\n                    applied.append(c)\n        return applied\n\n    with monkeypatch.context() as m:\n        m.setattr(sf.LocalEngine, ""_run_program"", mock_run_prog)\n        yield applied\n\n    # tear down\n    applied = []\n\n\nclass TestParameterTFIntegration:\n    """"""Test integration of the parameter handling system with\n    various gates and TensorFlow""""""\n    pytest.importorskip(""tensorflow"", minversion=""2.0"")\n\n    @staticmethod\n    def create_program(gate, mapping):\n        """"""Utility method for constructing a program\n        consisting of a single parametrized gate.\n\n        Args:\n            gate (strawberryfields.ops.Gate): gate to apply to the program\n            mapping (dict[str, Any]): mapping from parameter name to value\n        """"""\n        prog = sf.Program(gate.ns)\n\n        # create symbolic parameters\n        params = []\n        for param_name in mapping:\n            params.append(prog.params(param_name))\n\n        # construct program\n        with prog as q:\n            gate(*params) | q\n\n        # bind numeric values\n        prog.bind_params(mapping)\n        return prog\n\n    @pytest.mark.parametrize(""gate"", [sf.ops.Dgate, sf.ops.Sgate, sf.ops.Coherent])\n    def test_single_mode_gate_complex_phase(self, backend, gate, applied_cmds):\n        """"""Test non-decomposed single mode gates with complex phase arguments.""""""\n        import tensorflow as tf\n        mapping = {\'r\': tf.Variable(0.1), \'phi\': tf.Variable(0.2)}\n        prog = self.create_program(gate, mapping)\n\n        # verify bound parameters are correct\n        assert prog.free_params[\'r\'].val is mapping[\'r\']\n        assert prog.free_params[\'phi\'].val is mapping[\'phi\']\n\n        # assert executed program is constructed correctly\n        eng = sf.LocalEngine(backend)\n        result = eng.run(prog, args=mapping)\n\n        assert len(applied_cmds) == 1\n        assert isinstance(applied_cmds[0].op, gate)\n        assert applied_cmds[0].op.p[0].val == mapping[""r""]\n        assert applied_cmds[0].op.p[1].val == mapping[""phi""]\n\n    @pytest.mark.parametrize(""gate"", [sf.ops.BSgate, sf.ops.S2gate])\n    def test_two_mode_gate_complex_phase(self, backend, gate, applied_cmds):\n        """"""Test non-decomposed two-mode gates with complex phase arguments.""""""\n        import tensorflow as tf\n        mapping = {\'r\': tf.Variable(0.1), \'phi\': tf.Variable(0.2)}\n        prog = self.create_program(gate, mapping)\n\n        # verify bound parameters are correct\n        assert prog.free_params[\'r\'].val is mapping[\'r\']\n        assert prog.free_params[\'phi\'].val is mapping[\'phi\']\n\n        # assert executed program is constructed correctly\n        eng = sf.LocalEngine(backend)\n        result = eng.run(prog, args=mapping)\n\n        assert len(applied_cmds) == 1\n        assert isinstance(applied_cmds[0].op, gate)\n        assert applied_cmds[0].op.p[0].val == mapping[""r""]\n        assert applied_cmds[0].op.p[1].val == mapping[""phi""]\n\n    def test_zgate_decompose(self, backend, hbar, applied_cmds):\n        """"""Test parameter processing occuring within the Zgate._decompose method.""""""\n        import tensorflow as tf\n        mapping = {\'p\': tf.Variable(0.1)}\n        prog = self.create_program(sf.ops.Zgate, mapping)\n\n        # verify bound parameters are correct\n        assert prog.free_params[\'p\'].val is mapping[\'p\']\n\n        # assert executed program is constructed correctly\n        eng = sf.LocalEngine(backend)\n        result = eng.run(prog, args=mapping)\n\n        assert len(applied_cmds) == 1\n        assert isinstance(applied_cmds[0].op, sf.ops.Dgate)\n        assert par_evaluate(applied_cmds[0].op.p[0]) == mapping[""p""] / np.sqrt(2 * hbar)\n        assert applied_cmds[0].op.p[1] == np.pi/2\n'"
tests/frontend/test_program.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for program.py""""""\nimport textwrap\nimport pytest\n\npytestmark = pytest.mark.frontend\n\nimport numpy as np\n\nimport strawberryfields as sf\n\nfrom strawberryfields import program\nfrom strawberryfields import ops\nfrom strawberryfields.parameters import ParameterError, FreeParameter\nfrom strawberryfields.circuitspecs.circuit_specs import CircuitSpecs\n\n\n# make test deterministic\nnp.random.seed(42)\nA = np.random.random()\n\n\n# all single-mode gates with at least one parameter\nsingle_mode_gates = [x for x in ops.one_args_gates + ops.two_args_gates if x.ns == 1]\n\n\n@pytest.fixture\ndef eng(backend):\n    """"""Engine fixture.""""""\n    return sf.LocalEngine(backend)\n\n\n@pytest.fixture\ndef prog():\n    """"""Program fixture.""""""\n    return sf.Program(2)\n\n\n@pytest.fixture\ndef permute_gates():\n    """"""Returns a list containing an instance of each\n    single mode gate, with random parameters""""""\n    params = np.random.random(len(single_mode_gates))\n    gates = [G(p) for G, p in zip(single_mode_gates, params)]\n\n    # random permutation\n    return np.random.permutation(gates)\n\n\nclass TestProgram:\n    """"""Tests the Program class.""""""\n\n    def test_with_block(self, prog):\n        """"""Gate application using a with block.""""""\n        # command queue is empty\n        assert len(prog) == 0\n\n        with prog.context as q:\n            ops.Dgate(0.5) | q[0]\n        # now there is one gate in the queue\n        assert len(prog) == 1\n\n        with prog.context as q:\n            ops.BSgate(0.5, 0.3) | (q[1], q[0])\n        assert len(prog) == 2\n\n    def test_parent_program(self):\n        """"""Continuing one program with another.""""""\n        D = ops.Dgate(0.5)\n        prog = sf.Program(3)\n        with prog.context as q:\n            D | q[1]\n            ops.Del | q[0]\n        cont = sf.Program(prog)\n        with cont.context as q:\n            D | q[0]\n            r = ops.New(1)\n            D | r\n        assert cont.can_follow(prog)\n        assert prog.reg_refs == cont.init_reg_refs\n        assert prog.unused_indices == cont.init_unused_indices\n\n    def test_print_commands(self, eng, prog):\n        """"""Program.print and Engine.print_applied return correct strings.""""""\n        prog = sf.Program(2)\n\n        # store the result of the print command in list res\n        res = []\n        # use a print function that simply appends the operation\n        # name to the results list\n        print_fn = lambda x: res.append(x.__str__())\n\n        # prog should now be empty\n        prog.print(print_fn)\n        assert res == []\n\n        # define some gates\n        D = ops.Dgate(0.5)\n        BS = ops.BSgate(2 * np.pi, np.pi / 2)\n        R = ops.Rgate(np.pi)\n\n        with prog.context as q:\n            alice, bob = q\n            D | alice\n            BS | (alice, bob)\n            ops.Del | alice\n            R | bob\n            charlie, = ops.New(1)\n            BS | (bob, charlie)\n            ops.MeasureX | bob\n            ops.Dgate(bob.par).H | charlie\n            ops.Del | bob\n            ops.MeasureX | charlie\n\n        res = []\n        prog.print(print_fn)\n\n        expected = [\n            ""Dgate(0.5, 0) | (q[0])"",\n            ""BSgate(6.283, 1.571) | (q[0], q[1])"",\n            ""Del | (q[0])"",\n            ""Rgate(3.142) | (q[1])"",\n            ""New(1)"",\n            ""BSgate(6.283, 1.571) | (q[1], q[2])"",\n            ""MeasureX | (q[1])"",\n            ""Dgate(q1, 0).H | (q[2])"",\n            ""Del | (q[1])"",\n            ""MeasureX | (q[2])"",\n        ]\n\n        assert res == expected\n\n        # NOTE optimization can change gate order\n        result = eng.run(prog, compile_options={\'optimize\': False})\n        res = []\n        eng.print_applied(print_fn)\n        assert res == [""Run 0:""] + expected\n\n    def test_params(self, prog):\n        """"""Creating and retrieving free parameters.""""""\n        assert not prog.free_params  # no free params to start with\n\n        with pytest.raises(TypeError, match=\'Parameter names must be strings.\'):\n            prog.params(1)\n\n        # creating\n        x = prog.params(\'a\')\n        assert isinstance(x, FreeParameter)\n        assert x.name == \'a\'\n        assert len(prog.free_params) == 1\n\n        # retrieving\n        y = prog.params(\'a\')\n        assert y is x\n        assert len(prog.free_params) == 1\n\n        with pytest.raises(TypeError, match=\'Parameter names must be strings.\'):\n            prog.params(x)\n\n        # creating/retrieving multiple\n        names = (\'foo\', \'bar\', \'a\')\n        pars = prog.params(*names)\n        assert isinstance(pars, list)\n        for n, p in zip(names, pars):\n            assert isinstance(p, FreeParameter)\n            assert p.name == n\n        assert pars[2] is x  # still the same parameter\n        assert len(prog.free_params) == 3\n\n        # once the program is locked only retrieval is possible\n        prog.lock()\n        with pytest.raises(program.CircuitError, match=\'The Program is locked, no more free parameters can be created.\'):\n            w = prog.params(\'www\')\n        w = prog.params(\'a\')\n        assert w is x\n\n    def test_bind_params(self, prog):\n        """"""Binding free parameters.""""""\n\n        with pytest.raises(ParameterError, match=\'Unknown free parameter\'):\n            prog.bind_params({\'x\': 0})\n\n        x, y = prog.params(\'x\', \'y\')\n        # bind some params using parameter name\n        prog.bind_params({\'x\': 1.0})\n        assert x.val == 1.0\n        assert y.val is None\n        # bind using the parameter itself\n        prog.bind_params({x: 2.0})\n        assert x.val == 2.0\n        assert y.val is None\n\n\nclass TestRegRefs:\n    """"""Testing register references.""""""\n\n    def test_corrupt_index(self, prog):\n        """"""User messes up the RegRef indices.""""""\n        with prog.context as q:\n            q[0].ind = 1\n            with pytest.raises(program.RegRefError, match=""RegRef state has become inconsistent""):\n                ops.Dgate(0.5) | q[0]\n\n    def test_nonexistent_index(self, prog):\n        """"""Acting on a non-existent mode raises an error.""""""\n        with prog.context as q:\n            with pytest.raises(IndexError):\n                ops.Dgate(0.5) | q[3]\n            with pytest.raises(program.RegRefError, match=""does not exist""):\n                ops.Dgate(0.5) | 3\n\n    def test_deleted_index(self, prog):\n        """"""Test that acting on a deleted mode raises an error""""""\n        with prog.context as q:\n            ops.Del | q[0]\n            with pytest.raises(program.RegRefError, match=""been deleted""):\n                ops.Dgate(0.5) | 0\n\n            with pytest.raises(program.RegRefError, match=""been deleted""):\n                ops.Dgate(0.5) | q[0]\n\n    def test_unknown_regref(self, prog):\n        """"""Applying an operation on a RegRef not belonging to the program.""""""\n        r = program.RegRef(3)\n        with prog.context:\n            with pytest.raises(program.RegRefError, match=""Unknown RegRef.""):\n                ops.Dgate(0.5) | r\n\n    def test_invalid_measurement(self, eng, prog):\n        """"""Cannot use a measurement before it exists.""""""\n        with prog.context as q:\n            ops.Dgate(q[0].par) | q[1]\n        with pytest.raises(ParameterError, match=""nonexistent measurement result""):\n            eng.run(prog)\n\n    def test_invalid_regref(self, prog):\n        """"""Cannot refer to a register with a non-integral or RegRef object.""""""\n        with prog.context:\n            with pytest.raises(program.RegRefError, match=""using integers and RegRefs""):\n                ops.Dgate(0) | 1.2\n\n    def test_regref_val(self, eng, prog):\n        """"""RegRefs storing measured values.""""""\n        with prog.context as q:\n            ops.MeasureX | q[0]\n\n        eng.run(prog)\n        assert q[0].val is not None\n        assert q[1].val is None\n        eng.reset()\n        # the regrefs are reset as well\n        temp = [r.val is None for r in prog.register]\n        assert np.all(temp)\n\n        eng.run(prog)\n        assert q[0].val is not None\n        assert q[1].val is None\n        prog._clear_regrefs()\n        assert np.all([r.val is None for r in prog.register])\n\n\nclass TestOptimizer:\n    """"""Tests for the Program optimizer""""""\n\n    @pytest.mark.parametrize(""G"", single_mode_gates)\n    def test_merge_dagger(self, G):\n        """"""Optimizer merging single-mode gates with their daggered versions.""""""\n        prog = sf.Program(1)\n        G = G(A)\n\n        with prog.context:\n            G | 0\n            G.H | 0\n\n        prog = prog.optimize()\n        assert len(prog) == 0\n\n    @pytest.mark.parametrize(""G"", single_mode_gates)\n    def test_merge_negated(self, G):\n        """"""Optimizer merging single-mode gates with their negated versions.""""""\n        prog = sf.Program(1)\n        G1 = G(A)\n        G2 = G(-A)\n\n        with prog.context:\n            G1 | 0\n            G2 | 0\n\n        prog = prog.optimize()\n        assert len(prog) == 0\n\n    def test_merge_palindromic_cancelling(self, permute_gates):\n        """"""Optimizer merging chains that cancel out palindromically""""""\n        prog = sf.Program(3)\n\n        with prog.context:\n            for G in permute_gates:\n                G | 0\n            for G in reversed(permute_gates):\n                G.H | 0\n\n        prog = prog.optimize()\n        assert len(prog) == 0\n\n    def test_merge_pairwise_cancelling(self, permute_gates):\n        """"""Optimizer merging chains that cancel out pairwise""""""\n        prog = sf.Program(3)\n\n        with prog.context:\n            for G in permute_gates:\n                G | 0\n                G.H | 0\n\n        prog = prog.optimize()\n        assert len(prog) == 0\n\n    def test_merge_interleaved_chains_two_modes(self, permute_gates):\n        """"""Optimizer merging chains that cancel out palindromically,\n        interleaved on two modes""""""\n        prog = sf.Program(3)\n\n        # create a random vector of 0s and 1s, corresponding\n        # to the applied mode of each gates\n        modes = np.random.randint(2, size=len(permute_gates))\n\n        with prog.context:\n            for G, m in zip(permute_gates, modes):\n                G | m\n            for G, m in zip(reversed(permute_gates), reversed(modes)):\n                G.H | m\n\n        prog = prog.optimize()\n        assert len(prog) == 0\n\n    def test_merge_incompatible(self):\n        """"""Test merging of incompatible gates does nothing""""""\n        prog = sf.Program(3)\n\n        with prog.context:\n            ops.Xgate(0.6) | 0\n            ops.Zgate(0.2) | 0\n\n        prog = prog.optimize()\n        assert len(prog) == 2\n\n\nclass TestValidation:\n    """"""Test for Program circuit validation within\n    the compile() method.""""""\n\n    def test_unknown_circuit_spec(self):\n        """"""Test an unknown compile target.""""""\n        prog = sf.Program(3)\n        with prog.context as q:\n            ops.MeasureFock() | q\n\n        with pytest.raises(ValueError, match=""Could not find target \'foo\' in the Strawberry Fields circuit database""):\n            new_prog = prog.compile(target=\'foo\')\n\n    def test_disconnected_circuit(self):\n        """"""Test the detection of a disconnected circuit.""""""\n        prog = sf.Program(3)\n        with prog.context as q:\n            ops.S2gate(0.6) | q[0:2]\n            ops.Dgate(1.0)  | q[2]\n            ops.MeasureFock() | q[0:2]\n            ops.MeasureX | q[2]\n\n        with pytest.warns(UserWarning, match=\'The circuit consists of 2 disconnected components.\'):\n            new_prog = prog.compile(target=\'fock\')\n\n    def test_incorrect_modes(self):\n        """"""Test that an exception is raised if the circuit spec\n        is called with the incorrect number of modes""""""\n\n        class DummyCircuit(CircuitSpecs):\n            """"""A circuit with 2 modes""""""\n            modes = 2\n            remote = False\n            local = True\n            interactive = True\n            primitives = {\'S2gate\', \'Interferometer\'}\n            decompositions = set()\n\n        prog = sf.Program(3)\n        with prog.context as q:\n            ops.S2gate(0.6) | [q[0], q[1]]\n            ops.S2gate(0.6) | [q[1], q[2]]\n\n        with pytest.raises(program.CircuitError, match=""requires 3 modes""):\n            new_prog = prog.compile(target=DummyCircuit())\n\n    def test_no_decompositions(self):\n        """"""Test that no decompositions take\n        place if the circuit spec doesn\'t support it.""""""\n\n        class DummyCircuit(CircuitSpecs):\n            """"""A circuit spec with no decompositions""""""\n            modes = None\n            remote = False\n            local = True\n            interactive = True\n            primitives = {\'S2gate\', \'Interferometer\'}\n            decompositions = set()\n\n        prog = sf.Program(3)\n        U = np.array([[0, 1], [1, 0]])\n        with prog.context as q:\n            ops.S2gate(0.6) | [q[0], q[1]]\n            ops.Interferometer(U) | [q[0], q[1]]\n\n        new_prog = prog.compile(target=DummyCircuit())\n\n        # check compiled program only has two gates\n        assert len(new_prog) == 2\n\n        # test gates are correct\n        circuit = new_prog.circuit\n        assert circuit[0].op.__class__.__name__ == ""S2gate""\n        assert circuit[1].op.__class__.__name__ == ""Interferometer""\n\n    def test_decompositions(self):\n        """"""Test that decompositions take\n        place if the circuit spec requests it.""""""\n\n        class DummyCircuit(CircuitSpecs):\n            modes = None\n            remote = False\n            local = True\n            interactive = True\n            primitives = {\'S2gate\', \'Interferometer\', \'BSgate\', \'Sgate\'}\n            decompositions = {\'S2gate\': {}}\n\n        prog = sf.Program(3)\n        U = np.array([[0, 1], [1, 0]])\n        with prog.context as q:\n            ops.S2gate(0.6) | [q[0], q[1]]\n            ops.Interferometer(U) | [q[0], q[1]]\n\n        new_prog = prog.compile(target=DummyCircuit())\n\n        # check compiled program now has 5 gates\n        # the S2gate should decompose into two BS and two Sgates\n        assert len(new_prog) == 5\n\n        # test gates are correct\n        circuit = new_prog.circuit\n        assert circuit[0].op.__class__.__name__ == ""BSgate""\n        assert circuit[1].op.__class__.__name__ == ""Sgate""\n        assert circuit[2].op.__class__.__name__ == ""Sgate""\n        assert circuit[3].op.__class__.__name__ == ""BSgate""\n        assert circuit[4].op.__class__.__name__ == ""Interferometer""\n\n    def test_invalid_decompositions(self):\n        """"""Test that an exception is raised if the circuit spec\n        requests a decomposition that doesn\'t exist""""""\n\n        class DummyCircuit(CircuitSpecs):\n            modes = None\n            remote = False\n            local = True\n            interactive = True\n            primitives = {\'Rgate\', \'Interferometer\'}\n            decompositions = {\'Rgate\': {}}\n\n        prog = sf.Program(3)\n        U = np.array([[0, 1], [1, 0]])\n        with prog.context as q:\n            ops.Rgate(0.6) | q[0]\n            ops.Interferometer(U) | [q[0], q[1]]\n\n        with pytest.raises(NotImplementedError, match=""No decomposition available: Rgate""):\n            new_prog = prog.compile(target=DummyCircuit())\n\n    def test_invalid_primitive(self):\n        """"""Test that an exception is raised if the program\n        contains a primitive not allowed on the circuit spec.\n\n        Here, we can simply use the guassian circuit spec and\n        the Kerr gate as an existing example.\n        """"""\n        prog = sf.Program(3)\n        with prog.context as q:\n            ops.Kgate(0.6) | q[0]\n\n        with pytest.raises(program.CircuitError, match=""Kgate cannot be used with the target""):\n            new_prog = prog.compile(target=\'gaussian\')\n\n    def test_user_defined_decomposition_false(self):\n        """"""Test that an operation that is both a primitive AND\n        a decomposition (for instance, ops.Gaussian in the gaussian\n        backend) can have it\'s decomposition behaviour user defined.\n\n        In this case, the Gaussian operation should remain after compilation.\n        """"""\n        prog = sf.Program(2)\n        cov = np.ones((4, 4)) + np.eye(4)\n        r = np.array([0, 1, 1, 2])\n        with prog.context as q:\n            ops.Gaussian(cov, r, decomp=False) | q\n\n        prog = prog.compile(target=\'gaussian\')\n        assert len(prog) == 1\n        circuit = prog.circuit\n        assert circuit[0].op.__class__.__name__ == ""Gaussian""\n\n        # test compilation against multiple targets in sequence\n        with pytest.raises(program.CircuitError, match=""The operation Gaussian is not a primitive for the target \'fock\'""):\n            prog = prog.compile(target=\'fock\')\n\n    def test_user_defined_decomposition_true(self):\n        """"""Test that an operation that is both a primitive AND\n        a decomposition (for instance, ops.Gaussian in the gaussian\n        backend) can have it\'s decomposition behaviour user defined.\n\n        In this case, the Gaussian operation should compile\n        to a Squeezed preparation.\n        """"""\n        prog = sf.Program(3)\n        r = 0.453\n        cov = np.array([[np.exp(-2*r), 0], [0, np.exp(2*r)]])*sf.hbar/2\n        with prog.context:\n            ops.Gaussian(cov, decomp=True) | 0\n\n        new_prog = prog.compile(target=\'gaussian\')\n\n        assert len(new_prog) == 1\n\n        circuit = new_prog.circuit\n        assert circuit[0].op.__class__.__name__ == ""Squeezed""\n        assert circuit[0].op.p[0] == r\n\n    def test_topology_validation(self):\n        """"""Test compilation properly matches the circuit spec topology""""""\n\n        class DummyCircuit(CircuitSpecs):\n            modes = None\n            remote = False\n            local = True\n            interactive = True\n            primitives = {\'Sgate\', \'BSgate\', \'Dgate\', \'MeasureFock\'}\n            decompositions = set()\n\n            circuit = textwrap.dedent(\n                """"""\\\n                name test\n                version 0.0\n\n                Sgate({sq}, 0) | 0\n                Dgate(-7.123) | 1\n                BSgate({theta}) | 0, 1\n                MeasureFock() | 0\n                MeasureFock() | 2\n                """"""\n            )\n\n        prog = sf.Program(3)\n        with prog.context as q:\n            # the circuit given below is an\n            # isomorphism of the one provided above\n            # in circuit, so should validate.\n            ops.MeasureFock() | q[2]\n            ops.Dgate(-7.123) | q[1]\n            ops.Sgate(0.543) | q[0]\n            ops.BSgate(-0.32) | (q[0], q[1])\n            ops.MeasureFock() | q[0]\n\n        new_prog = prog.compile(target=DummyCircuit())\n\n        # no exception should be raised; topology correctly validated\n        assert len(new_prog) == 5\n\n    def test_invalid_topology(self):\n        """"""Test compilation raises exception if toplogy not matched""""""\n\n        class DummyCircuit(CircuitSpecs):\n            modes = None\n            remote = False\n            local = True\n            interactive = True\n            primitives = {\'Sgate\', \'BSgate\', \'Dgate\', \'MeasureFock\'}\n            decompositions = set()\n\n            circuit = textwrap.dedent(\n                """"""\\\n                name test\n                version 0.0\n\n                Sgate({sq}, 0) | 0\n                Dgate(-7.123) | 1\n                BSgate({theta}) | 0, 1\n                MeasureFock() | 0\n                MeasureFock() | 2\n                """"""\n            )\n\n        prog = sf.Program(3)\n        with prog.context as q:\n            # the circuit given below is NOT an\n            # isomorphism of the one provided above\n            # in circuit, as the Sgate\n            # comes AFTER the beamsplitter.\n            ops.MeasureFock() | q[2]\n            ops.Dgate(-7.123) | q[1]\n            ops.BSgate(-0.32) | (q[0], q[1])\n            ops.Sgate(0.543) | q[0]\n            ops.MeasureFock() | q[0]\n\n        with pytest.raises(program.CircuitError, match=""incompatible topology""):\n            new_prog = prog.compile(target=DummyCircuit())\n\n\nclass TestGBS:\n    """"""Test the Gaussian boson sampling circuit spec.""""""\n\n    def test_GBS_compile_ops_after_measure(self):\n        """"""Tests that GBS compilation fails when there are operations following a Fock measurement.""""""\n        prog = sf.Program(2)\n        with prog.context as q:\n            ops.MeasureFock() | q\n            ops.Rgate(1.0)  | q[0]\n\n        with pytest.raises(program.CircuitError, match=""Operations following the Fock measurements.""):\n            prog.compile(\'gbs\')\n\n    def test_GBS_compile_no_fock_meas(self):\n        """"""Tests that GBS compilation fails when no fock measurements are made.""""""\n        prog = sf.Program(2)\n        with prog.context as q:\n            ops.Dgate(1.0) | q[0]\n            ops.Sgate(-0.5) | q[1]\n\n        with pytest.raises(program.CircuitError, match=""GBS circuits must contain Fock measurements.""):\n            prog.compile(\'gbs\')\n\n    def test_GBS_compile_nonconsec_measurefock(self):\n        """"""Tests that GBS compilation fails when Fock measurements are made with an intervening gate.""""""\n        prog = sf.Program(2)\n        with prog.context as q:\n            ops.Dgate(1.0) | q[0]\n            ops.MeasureFock() | q[0]\n            ops.Dgate(-1.0) | q[1]\n            ops.BSgate(-0.5, 2.0) | q  # intervening gate\n            ops.MeasureFock() | q[1]\n\n        with pytest.raises(program.CircuitError, match=""The Fock measurements are not consecutive.""):\n            prog.compile(\'gbs\')\n\n    def test_GBS_compile_measure_same_twice(self):\n        """"""Tests that GBS compilation fails when the same mode is measured more than once.""""""\n        prog = sf.Program(3)\n        with prog.context as q:\n            ops.Dgate(1.0) | q[0]\n            ops.MeasureFock() | q[0]\n            ops.MeasureFock() | q\n\n        with pytest.raises(program.CircuitError, match=""Measuring the same mode more than once.""):\n            prog.compile(\'gbs\')\n\n    def test_GBS_success(self):\n        """"""GBS check passes.""""""\n        prog = sf.Program(3)\n        with prog.context as q:\n            ops.Sgate(1.0) | q[0]\n            ops.MeasureFock() | q[0]\n            ops.BSgate(1.4, 0.4) | q[1:3]\n            ops.MeasureFock() | q[2]\n            ops.Rgate(-1.0) | q[1]\n            ops.MeasureFock() | q[1]\n\n        prog = prog.compile(\'gbs\')\n        assert len(prog) == 4\n        last_cmd = prog.circuit[-1]\n        assert isinstance(last_cmd.op, ops.MeasureFock)\n        assert [x.ind for x in last_cmd.reg] == list(range(3))\n\n    def test_GBS_measure_fock_register_order(self):\n        """"""Test that compilation of MeasureFock on multiple modes\n        sorts the resulting register indices in ascending order.""""""\n        prog = sf.Program(4)\n\n        with prog.context as q:\n            ops.S2gate(0.45) | (q[0], q[2])\n            ops.S2gate(0.45) | (q[0], q[2])\n            ops.BSgate(0.54, -0.12) | (q[0], q[1])\n            ops.MeasureFock() | (q[0], q[3], q[2], q[1])\n\n        prog = prog.compile(""gbs"")\n        last_cmd = prog.circuit[-1]\n        assert isinstance(last_cmd.op, ops.MeasureFock)\n        assert [x.ind for x in last_cmd.reg] == list(range(4))\n'"
tests/frontend/test_sf_cli.py,0,"b'# Copyright 2019-2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nUnit tests for the Strawberry Fields command line interface.\n""""""\n# pylint: disable=no-self-use,unused-argument\nimport os\nimport functools\nimport argparse\n\nimport networkx as nx\nimport numpy as np\nimport pytest\n\nfrom strawberryfields.api import Result\nfrom strawberryfields.apps import clique\nfrom strawberryfields.configuration import store_account, ConfigurationError\nfrom strawberryfields import cli as cli\n\nimport sys\nimport builtins\n\npytestmark = pytest.mark.frontend\n\nclass TestCreateParser:\n    """"""Tests for creating a parser object.""""""\n\n    def test_general_details(self):\n        """"""Test the general details of the parser created.""""""\n        parser = cli.create_parser()\n        assert parser._optionals.title == ""General Options""\n        assert parser.description == ""See below for available options and commands for working with the Xanadu cloud platform.""\n        assert parser.add_help\n\n    @pytest.mark.parametrize(""option"", [\'--ping\', \'-p\'])\n    def test_ping(self, option):\n        """"""Test that specifying --ping to the CLI sets the correct attribute.""""""\n        parser = cli.create_parser()\n\n        args = parser.parse_args([option])\n        assert args.ping\n\n    @pytest.mark.parametrize(""token_option"", [\'--token\', \'-t\'])\n    def test_configure_token(self, token_option):\n        """"""Test that specifying configure, --token and passing an argument to\n        the CLI sets the correct attribute.""""""\n        parser = cli.create_parser()\n\n        args = parser.parse_args([\'configure\', token_option, \'SomeToken\'])\n        assert args.func is cli.configure\n        assert args.token == \'SomeToken\'\n        assert not args.local\n\n    def test_configuration_wizard(self):\n        """"""Test that specifying configure, --local to the CLI sets the correct\n        attribute.""""""\n        parser = cli.create_parser()\n        args = parser.parse_args([\'configure\'])\n\n        assert args.func is cli.configure\n        assert not args.local\n\n    @pytest.mark.parametrize(""token_option"", [\'--token\', \'-t\'])\n    @pytest.mark.parametrize(""local_option"", [\'--local\', \'-l\'])\n    def test_configure_token_locally(self, token_option, local_option):\n        """"""Test that specifying configure, --token, --local and passing an argument to\n        the CLI sets the correct attribute.""""""\n        parser = cli.create_parser()\n\n        args = parser.parse_args([\'configure\', token_option, \'SomeToken\', local_option])\n        assert args.func is cli.configure\n        assert args.token == \'SomeToken\'\n\n    @pytest.mark.parametrize(""option"", [\'--local\', \'-l\'])\n    def test_configuration_wizard_locally(self, option):\n        """"""Test that specifying configure, --local to the CLI sets the correct\n        attribute.""""""\n        parser = cli.create_parser()\n        args = parser.parse_args([\'configure\', option])\n\n        assert args.func is cli.configure\n        assert args.local\n\n    def test_run(self):\n        """"""Test that specifying input and passing an argument to the CLI sets\n        the correct attribute.""""""\n        parser = cli.create_parser()\n        args = parser.parse_args([\'run\', \'SomePath\'])\n\n        assert args.func is cli.run_blackbird_script\n        assert args.input == \'SomePath\'\n\n    def test_output(self):\n        """"""Test that specifying input, --output and passing the arguments to\n        the CLI sets the correct attributes.""""""\n        parser = cli.create_parser()\n        args = parser.parse_args([\'run\', \'SomeInputPath\', \'--output\', \'SomeOutputPath\'])\n\n        assert args.func is cli.run_blackbird_script\n        assert args.input == \'SomeInputPath\'\n        assert args.output == \'SomeOutputPath\'\n\nclass MockArgs:\n    """"""A mock class used for mocking the args that are parsed from the command\n    line.""""""\n\n    def __init__(self):\n        self.token = None\n        self.local = None\n        self.input = None\n        self.output = None\n\nclass MockStoreAccount:\n    """"""A mock class used for capturing the arguments with which the store_account\n    function is being called.""""""\n\n    def __init__(self):\n        self.kwargs = None\n\n    def store_account(self, **kwargs):\n        self.kwargs = kwargs\n\nEXPECTED_KWARGS = {\n    ""authentication_token"": """",\n    ""hostname"": ""platform.strawberryfields.ai"",\n    ""use_ssl"": True,\n    ""port"": 443,\n}\n\nclass TestConfigure:\n    """"""Unit tests for the configure function checking that the lines of\n    execution is correct.""""""\n\n    def test_token(self, monkeypatch):\n        """"""Tests that if a token was given as a command line argument then\n        configuration takes place accordingly.""""""\n        with monkeypatch.context() as m:\n            mock_store_account = MockStoreAccount()\n            m.setattr(cli, ""store_account"", mock_store_account.store_account)\n\n            args = MockArgs()\n            args.token = ""SomeToken""\n\n            cli.configure(args)\n            assert mock_store_account.kwargs == {""authentication_token"": ""SomeToken""}\n\n    def test_configuration_wizard(self, monkeypatch):\n        """"""Tests that if no token was given as a command line argument then\n        configuration takes place using the configuration_wizard function.""""""\n        with monkeypatch.context() as m:\n            mock_store_account = MockStoreAccount()\n            m.setattr(cli, ""configuration_wizard"", lambda: cli.create_config()[""api""])\n            m.setattr(cli, ""store_account"", mock_store_account.store_account)\n\n            args = MockArgs()\n            args.token = False\n\n            cli.configure(args)\n            assert mock_store_account.kwargs == EXPECTED_KWARGS\n\n    def test_token_local(self, monkeypatch):\n        """"""Tests that if a token was given as a command line argument and\n        local configuration was specified then configuration takes place\n        accordingly.""""""\n        with monkeypatch.context() as m:\n            mock_store_account = MockStoreAccount()\n            m.setattr(cli, ""store_account"", mock_store_account.store_account)\n\n            args = MockArgs()\n            args.token = ""SomeToken""\n            args.local = True\n\n            cli.configure(args)\n            assert mock_store_account.kwargs == {""authentication_token"": ""SomeToken"", ""location"": ""local""}\n\n    def test_configuration_wizard_local(self, monkeypatch):\n        """"""Tests that if no token was given as a command line argument and\n        local configuration was specified then configuration takes place using\n        the configuration_wizard function.""""""\n        with monkeypatch.context() as m:\n            mock_store_account = MockStoreAccount()\n            m.setattr(cli, ""configuration_wizard"", lambda: cli.create_config()[""api""])\n            m.setattr(cli, ""store_account"", mock_store_account.store_account)\n\n            args = MockArgs()\n            args.token = False\n            args.local = True\n\n            cli.configure(args)\n            EXPECTED_KWARGS[""location""] = ""local""\n\n            assert mock_store_account.kwargs == EXPECTED_KWARGS\n\nclass MockSuccessfulConnection:\n    """"""A Connection class mocking a successful establishment of connection.""""""\n\n    def ping(self):\n        return True\n\nclass MockFailedConnection:\n    """"""A Connection class mocking a failed establishment of connection.""""""\n\n    def ping(self):\n        return False\n\nclass TestPing:\n    """"""Tests for the pinging mechanism of the CLI.""""""\n\n    def test_success(self, monkeypatch, capsys):\n        """"""Test that pinging was successful.""""""\n        with monkeypatch.context() as m:\n            m.setattr(cli, ""Connection"", MockSuccessfulConnection)\n            cli.ping()\n\n        out, _ = capsys.readouterr()\n        assert out == ""You have successfully authenticated to the platform!\\n""\n\n    def test_fail(self, monkeypatch, capsys):\n        """"""Test that pinging failed.""""""\n        with monkeypatch.context() as m:\n            m.setattr(cli, ""Connection"", MockFailedConnection)\n            out, _ = capsys.readouterr()\n\n            cli.ping()\n\n        out, _ = capsys.readouterr()\n        assert out == ""There was a problem when authenticating to the platform!\\n""\n\n# Keys are adjusted to the prompt message displayed to the user\nMOCK_PROMPTS = {\n        ""token"": ""MyAuth"",\n        ""hostname"": ""MyHost"",\n        ""port"": 123,\n        ""SSL"": ""n"",\n}\n\nEXPECTED_KWARGS_FOR_PROMPTS = {\n    ""authentication_token"": ""MyAuth"",\n    ""hostname"": ""MyHost"",\n    ""port"": 123,\n    ""use_ssl"": False,\n}\n\ndef mock_input(arg):\n    """"""A mock function that substitutes the built-in input function.""""""\n    option = {k: v for k, v in MOCK_PROMPTS.items() if k in arg}\n    if option and len(option) == 1:\n        return list(option.values())[0]\n\nclass TestConfigureEverything:\n    """"""Unit tests for the configuration_wizard function.""""""\n\n    def test_no_auth_exit_with_message(self, monkeypatch, capsys):\n        """"""Test that by default the configuration_wizard function exits with a\n        relevant message.""""""\n        with monkeypatch.context() as m:\n            m.setattr(builtins, ""input"", lambda *args: False)\n            with pytest.raises(SystemExit):\n                cli.configuration_wizard()\n\n            out, _ = capsys.readouterr()\n\n        assert out == ""No authentication token was provided, please configure again.""\n\n    def test_auth_correct(self, monkeypatch):\n        """"""Test that by default the configuration_wizard function works\n        correctly, once the authentication token is passed.""""""\n        with monkeypatch.context() as m:\n            auth_prompt = ""Please enter the authentication token""\n            default_config = cli.create_config()[""api""]\n            default_auth = ""SomeAuth""\n            default_config[\'authentication_token\'] = default_auth\n\n            m.setattr(builtins, ""input"", lambda arg: default_auth if (auth_prompt in arg) else """")\n            assert cli.configuration_wizard() == default_config\n\n    def test_correct_inputs(self, monkeypatch):\n        """"""Test that the configuration_wizard function returns a dictionary\n        based on the inputs, when each configuration detail was inputted.""""""\n        with monkeypatch.context() as m:\n\n            auth_prompt = ""Please enter the authentication token""\n            default_config = cli.create_config()[""api""]\n            default_auth = ""SomeAuth""\n            default_config[\'authentication_token\'] = default_auth\n\n            m.setattr(builtins, ""input"", mock_input)\n            assert cli.configuration_wizard() == EXPECTED_KWARGS_FOR_PROMPTS\n\nclass MockProgram:\n    """"""A mock class used for capturing the arguments with which the\n    the Program class is instantiated.""""""\n\n    def __init__(self):\n\n        self.target = ""X8_01""\n        self.result = None\n\nclass MockRemoteEngine:\n    """"""A mock class used for capturing the arguments with which the\n    the RemoteEngine class is instantiated and its run method is called.""""""\n\n    def __init__(self, target):\n        self.result = None\n        self.target = target\n\n    def run(self, program):\n        if program:\n            return program.result\n\nclass MockWriteScriptResults:\n    """"""A mock class used for capturing the arguments with which the\n    write_script_results function is being called.""""""\n\n    def __init__(self):\n        self.called = False\n        self.output = None\n\n    def write_script_results(self, output):\n        self.called = True\n        self.output = output\n\nTEST_SCRIPT = """"""\\\nname template_1x2_X8_01     # Name of the program\nversion 1.0                 # Blackbird version number\ntarget X8_01 (shots = 50)   # This program will run on X8_01 for 50 shots\n\n# Define the interferometer phase values\nfloat phi0 = 0.574\nfloat phi1 = 1.33\nMZgate(phi0, phi1) | [0, 1]\nMZgate(phi0, phi1) | [4, 5]\n\n# Perform a photon number counting measurement\nMeasureFock() | [0, 1, 2, 3, 4, 5, 6, 7]\n""""""\n\n\nclass TestRunBlackbirdScript:\n    """"""Unit tests for the run_blackbird_script function.""""""\n\n    def test_exit_if_file_not_found(self, monkeypatch, capsys):\n        """"""Tests that if the input script file was not found then a system exit\n        occurs along with a message being outputted.""""""\n        mocked_program = MockProgram()\n        mocked_args = MockArgs()\n\n        def mock_load(arg):\n            raise FileNotFoundError\n\n        with monkeypatch.context() as m:\n            m.setattr(cli, ""load"", mock_load)\n\n            with pytest.raises(SystemExit):\n                cli.run_blackbird_script(mocked_args)\n\n        out, _ = capsys.readouterr()\n        assert ""blackbird script was not found"" in out\n\n    def test_result_is_none(self, monkeypatch, capsys):\n        """"""Tests that the write_script_results function is not called if the\n        results from the run method of the engine returned a None.""""""\n        mocked_program = MockProgram()\n        mocked_args = MockArgs()\n        mocked_write_script_results = MockWriteScriptResults()\n\n        with monkeypatch.context() as m:\n            m.setattr(cli, ""load"", lambda arg: mocked_program)\n            m.setattr(cli, ""RemoteEngine"", MockRemoteEngine)\n            m.setattr(cli, ""write_script_results"", mocked_write_script_results.write_script_results)\n\n            with pytest.raises(SystemExit):\n                cli.run_blackbird_script(mocked_args)\n\n        out, _ = capsys.readouterr()\n        assert ""Executing program on remote hardware..."" in out\n\n        # Check that the write_script_results function was not called\n        assert not mocked_write_script_results.called\n\ntest_samples = [1, 2, 3, 4]\n\nclass MockRemoteEngineIntegration:\n    """"""A mock class used for capturing the arguments with which the\n    the RemoteEngine class is instantiated and its run method is called when\n    multiple components are tested.""""""\n\n    def __init__(self, target):\n        self.result = None\n        self.target = target\n\n    def run(self, program):\n        if program:\n            return Result(test_samples)\n\nclass TestRunBlackbirdScriptIntegration:\n    """"""Tests for the run_blackbird_script function that integrate multiple\n    components.""""""\n\n    def test_integration_std_out(self, tmpdir, monkeypatch, capsys):\n        """"""Tests that a blackbird script was loaded and samples were written to\n        the standard output using the run_blackbird_script function.""""""\n\n        filepath = tmpdir.join(""test_script.xbb"")\n\n        with open(filepath, ""w"") as f:\n            f.write(TEST_SCRIPT)\n\n        mocked_args = MockArgs()\n        mocked_args.input = filepath\n\n        with monkeypatch.context() as m:\n            m.setattr(cli, ""RemoteEngine"", MockRemoteEngineIntegration)\n            cli.run_blackbird_script(mocked_args)\n\n        out, err = capsys.readouterr()\n\n        execution_message = ""Executing program on remote hardware...\\n""\n\n        outputs = execution_message + str(Result(test_samples).samples)\n        assert outputs == out\n\n    def test_integration_file(self, tmpdir, monkeypatch, capsys):\n        """"""Tests that a blackbird script was loaded and samples were written to\n        the specified output file using the run_blackbird_script function.""""""\n\n        filepath = tmpdir.join(""test_script.xbb"")\n\n        with open(filepath, ""w"") as f:\n            f.write(TEST_SCRIPT)\n\n        mocked_args = MockArgs()\n        mocked_args.input = filepath\n\n        out_filepath = tmpdir.join(""test_script.xbb"")\n        mocked_args.output = out_filepath\n\n        with monkeypatch.context() as m:\n            m.setattr(cli, ""RemoteEngine"", MockRemoteEngineIntegration)\n            cli.run_blackbird_script(mocked_args)\n\n        with open(filepath, ""r"") as f:\n            results_from_file = f.read()\n\n        out, _ = capsys.readouterr()\n        assert out == ""Executing program on remote hardware...\\n""\n        assert results_from_file == str(Result(test_samples).samples)\n\nclass TestWriteScriptResults:\n    """"""Tests for the write_script_results function.""""""\n\n    def test_write_to_file(self, tmpdir):\n        """"""Tests that the write_script_results function writes to file\n        correctly.""""""\n        some_samples = [1, 2, 3, 4, 5]\n        filepath = tmpdir.join(""test_script.xbb"")\n\n        cli.write_script_results(some_samples, output_file=filepath)\n\n        with open(filepath, ""r"") as f:\n            results_from_file = f.read()\n\n        assert results_from_file == str(some_samples)\n\n    def test_write_to_std_out(self, monkeypatch, capsys):\n        """"""Tests that the write_script_results function writes to the standard\n        output correctly.""""""\n        some_samples = [1, 2, 3, 4, 5]\n\n        with monkeypatch.context() as m:\n            cli.write_script_results(some_samples)\n\n        out, _ = capsys.readouterr()\n        assert out == str(some_samples)\n'"
tests/frontend/test_shared_ops.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the Strawberry Fields shared_ops module""""""\nimport os\nimport pytest\n\npytestmark = pytest.mark.frontend\n\nimport numpy as np\n\nimport strawberryfields.backends.shared_ops as so\n\n# fmt: off\nBS_4_VAL = np.array([ 1.00000000+0.j,  1.00000000+0.j,  1.00000000+0.j,  1.00000000+0.j,\n        1.00000000+0.j,  1.41421356+0.j,  1.73205081+0.j,  1.00000000+0.j,\n        1.73205081+0.j,  1.00000000+0.j, -1.00000000+0.j, -1.41421356+0.j,\n       -1.73205081+0.j,  1.00000000+0.j, -1.00000000+0.j,  1.00000000+0.j,\n       -2.00000000+0.j,  1.00000000+0.j, -3.00000000+0.j,  1.00000000+0.j,\n        1.41421356+0.j, -1.00000000+0.j,  2.00000000+0.j, -2.44948974+0.j,\n        2.44948974+0.j,  1.73205081+0.j, -1.00000000+0.j,  3.00000000+0.j,\n        1.00000000+0.j,  1.73205081+0.j, -1.41421356+0.j,  1.00000000+0.j,\n       -2.00000000+0.j,  2.44948974+0.j, -2.44948974+0.j,  1.00000000+0.j,\n       -2.00000000+0.j,  1.00000000+0.j,  1.00000000+0.j, -4.00000000+0.j,\n        1.00000000+0.j,  3.00000000+0.j, -6.00000000+0.j,  1.00000000+0.j,\n        1.73205081+0.j, -2.44948974+0.j,  2.44948974+0.j,  1.00000000+0.j,\n       -6.00000000+0.j,  3.00000000+0.j, -1.00000000+0.j,  1.73205081+0.j,\n       -1.00000000+0.j,  3.00000000+0.j, -1.73205081+0.j,  2.44948974+0.j,\n       -2.44948974+0.j, -1.00000000+0.j,  6.00000000+0.j, -3.00000000+0.j,\n        1.00000000+0.j, -3.00000000+0.j,  1.00000000+0.j,  3.00000000+0.j,\n       -6.00000000+0.j,  1.00000000+0.j, -1.00000000+0.j,  9.00000000+0.j,\n       -9.00000000+0.j,  1.00000000+0.j])\n\nBS_4_IDX = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n        3, 3, 3, 3],\n       [0, 0, 0, 0, 1, 1, 1, 2, 2, 3, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n        2, 2, 2, 3, 3, 3, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n        3, 3, 3, 3],\n       [0, 1, 2, 3, 1, 2, 3, 2, 3, 3, 0, 1, 2, 0, 1, 1, 2, 2, 3, 3, 1, 2,\n        2, 3, 3, 2, 3, 3, 0, 1, 0, 1, 1, 2, 2, 0, 1, 1, 2, 2, 2, 3, 3, 3,\n        1, 2, 2, 3, 3, 3, 0, 0, 1, 1, 0, 1, 1, 2, 2, 2, 0, 1, 1, 2, 2, 2,\n        3, 3, 3, 3],\n       [0, 1, 2, 3, 0, 1, 2, 0, 1, 0, 1, 2, 3, 0, 1, 1, 2, 2, 3, 3, 0, 1,\n        1, 2, 2, 0, 1, 1, 2, 3, 1, 2, 2, 3, 3, 0, 1, 1, 2, 2, 2, 3, 3, 3,\n        0, 1, 1, 2, 2, 2, 3, 2, 3, 3, 1, 2, 2, 3, 3, 3, 0, 1, 1, 2, 2, 2,\n        3, 3, 3, 3],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n        1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 2, 1, 2, 0, 1, 2, 0, 1, 2,\n        2, 1, 2, 0, 1, 2, 0, 1, 0, 1, 2, 1, 2, 0, 1, 2, 3, 2, 3, 1, 2, 3,\n        0, 1, 2, 3]])\n\n# fmt: on\n\nSQUEEZE_PARITY_8 = np.array(\n    [\n        [1, 0, -1, 0, 1, 0, -1, 0],\n        [0, 1, 0, -1, 0, 1, 0, -1],\n        [-1, 0, 1, 0, -1, 0, 1, 0],\n        [0, -1, 0, 1, 0, -1, 0, 1],\n        [1, 0, -1, 0, 1, 0, -1, 0],\n        [0, 1, 0, -1, 0, 1, 0, -1],\n        [-1, 0, 1, 0, -1, 0, 1, 0],\n        [0, -1, 0, 1, 0, -1, 0, 1],\n    ]\n)\n\n\nSQUEEZE_FACTOR_4 = np.array(\n    [\n        [\n            [1.0, 0.0, -0.0, 0.0],\n            [0.0, 0.0, -0.0, 0.0],\n            [1.41421356, 0.0, -0.0, 0.0],\n            [0.0, 0.0, -0.0, 0.0],\n        ],\n        [\n            [0.0, 0.0, 0.0, -0.0],\n            [0.0, 1.0, 0.0, -0.0],\n            [0.0, 0.0, 0.0, -0.0],\n            [0.0, 2.44948974, 0.0, -0.0],\n        ],\n        [\n            [-1.41421356, 0.0, 0.0, 0.0],\n            [-0.0, 0.0, 0.0, 0.0],\n            [-2.0, 0.0, 1.0, 0.0],\n            [-0.0, 0.0, 0.0, 0.0],\n        ],\n        [\n            [0.0, -0.0, 0.0, 0.0],\n            [0.0, -2.44948974, 0.0, 0.0],\n            [0.0, -0.0, 0.0, 0.0],\n            [0.0, -6.0, 0.0, 1.0],\n        ],\n    ]\n)\n\n\n# TODO: write unit tests for find_dim_files function\n\n\nclass TestBeamsplitterFactors:\n    """"""Tests for the beamsplitter prefactors""""""\n\n    def test_generate(self, tol):\n        """"""test generating beamsplitter factors gives expected results""""""\n        factors = so.generate_bs_factors(4)\n        factors_val = factors[factors != 0.0]\n        factors_idx = np.array(np.nonzero(factors))\n\n        assert np.allclose(factors_val, BS_4_VAL, atol=tol, rtol=0)\n        assert np.allclose(factors_idx, BS_4_IDX, atol=tol, rtol=0)\n\n    def test_save_load(self, tmpdir, tol):\n        """"""test saving and loading of beamsplitter factors""""""\n        factors = so.generate_bs_factors(4)\n        so.save_bs_factors(factors, directory=str(tmpdir))\n\n        factors = so.load_bs_factors(4, directory=str(tmpdir))\n        factors_val = factors[factors != 0.0]\n        factors_idx = np.array(np.nonzero(factors))\n\n        assert np.allclose(factors_val, BS_4_VAL, atol=tol, rtol=0)\n        assert np.allclose(factors_idx, BS_4_IDX, atol=tol, rtol=0)\n\n\nclass TestSqueezingFactors:\n    """"""Tests for the squeezing prefactors""""""\n\n    def test_squeeze_parity(self, tol):\n        """"""Test the squeeze parity function returns the correct result""""""\n        parity = so.squeeze_parity(8)\n        assert np.allclose(parity, SQUEEZE_PARITY_8, atol=tol, rtol=0)\n\n    def test_generate(self, tol):\n        """"""test generating squeezoing factors gives expected results""""""\n        factors = so.generate_squeeze_factors(4)\n        assert np.allclose(factors, SQUEEZE_FACTOR_4, atol=tol, rtol=0)\n\n    def test_save_load(self, tmpdir, tol):\n        """"""test saving and loading of squeezoing factors""""""\n        factors_in = so.generate_squeeze_factors(4)\n        so.save_squeeze_factors(factors_in, directory=str(tmpdir))\n        factors_out = so.load_squeeze_factors(4, directory=str(tmpdir))\n\n        assert np.allclose(factors_out, SQUEEZE_FACTOR_4, atol=tol, rtol=0)\n\n\nclass TestPhaseSpaceFunctions:\n    """"""Tests for the shared phase space operations""""""\n\n    @pytest.mark.parametrize(""phi"", np.linspace(0, np.pi, 4))\n    def test_rotation_matrix(self, phi):\n        """"""Test the function rotation_matrix""""""\n        res = so.rotation_matrix(phi)\n        expected = np.array([[np.cos(phi), -np.sin(phi)], [np.sin(phi), np.cos(phi)]])\n\n        assert np.all(res == expected)\n\n    @pytest.mark.parametrize(""n"", [1, 2, 4])\n    def test_sympmat(self, n):\n        """"""Test the symplectic matrix function""""""\n        res = so.sympmat(n)\n        O = np.zeros([n, n])\n        I = np.identity(n)\n        expected = np.block([[O, I], [-I, O]])\n\n        assert np.all(res == expected)\n\n    def test_means_changebasis(self):\n        """"""Test the change of basis function applied to vectors. This function\n        converts from xp to symmetric ordering, and vice versa.""""""\n        C = so.changebasis(3)\n        means_xp = [1, 2, 3, 4, 5, 6]\n        means_symmetric = [1, 4, 2, 5, 3, 6]\n\n        assert np.all(C @ means_xp == means_symmetric)\n        assert np.all(C.T @ means_symmetric == means_xp)\n\n    def test_cov_changebasis(self):\n        """"""Test the change of basis function applied to matrices. This function\n        converts from xp to symmetric ordering, and vice versa.""""""\n        C = so.changebasis(2)\n        cov_xp = np.array(\n            [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15]]\n        )\n\n        cov_symmetric = np.array(\n            [[0, 2, 1, 3], [8, 10, 9, 11], [4, 6, 5, 7], [12, 14, 13, 15]]\n        )\n\n        assert np.all(C @ cov_xp @ C.T == cov_symmetric)\n        assert np.all(C.T @ cov_symmetric @ C == cov_xp)\n\n    @pytest.mark.parametrize(""n"", [1, 2, 4, 10])\n    def test_haar_measure(self, n, tol):\n        """"""test that the haar measure function returns unitary matrices""""""\n        U = so.haar_measure(n)\n        assert np.allclose(U @ U.conj().T, np.identity(n), atol=tol, rtol=0)\n'"
tests/frontend/test_utils.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the Strawberry Fields utils.py module""""""\nimport pytest\n\npytestmark = pytest.mark.frontend\n\nimport numpy as np\nfrom numpy.polynomial.hermite import hermval as H\nfrom scipy.special import factorial as fac\n\nimport strawberryfields as sf\nfrom strawberryfields.program_utils import RegRef\nfrom strawberryfields.ops import Sgate, BSgate, LossChannel, MeasureX, Squeezed\nimport strawberryfields.utils as utils\n\n\nALPHA = np.linspace(-0.15, 0.2, 4) + np.linspace(-0.2, 0.1, 4) * 1j\nR = np.linspace(0, 0.21, 4)\nPHI = np.linspace(0, 1.43, 4)\n\n\n# ===================================================================================\n# Convert function tests\n# ===================================================================================\n\n\n@pytest.fixture\ndef rr():\n    """"""RegRef fixture.""""""\n    return RegRef(0)\n\n\n@pytest.fixture\ndef prog():\n    """"""Program fixture.""""""\n    return sf.Program(2)\n\n\n\n# ===================================================================================\n# Initial states tests\n# ===================================================================================\n\n\nclass TestInitialStates:\n    """"""unit tests for the initial state function utilities""""""\n\n    @pytest.mark.parametrize(""r, phi"", zip(R, PHI))\n    def test_squeezed_cov(self, hbar, r, phi, tol):\n        """"""test squeezed covariance utility function returns correct covariance""""""\n        cov = utils.squeezed_cov(r, phi, hbar=hbar)\n\n        expected = (hbar / 2) * np.array(\n            [\n                [\n                    np.cosh(2 * r) - np.cos(phi) * np.sinh(2 * r),\n                    -2 * np.cosh(r) * np.sin(phi) * np.sinh(r),\n                ],\n                [\n                    -2 * np.cosh(r) * np.sin(phi) * np.sinh(r),\n                    np.cosh(2 * r) + np.cos(phi) * np.sinh(2 * r),\n                ],\n            ]\n        )\n\n        assert np.allclose(cov, expected, atol=tol, rtol=0)\n\n    def test_vacuum_state_gaussian(self, hbar):\n        """"""test vacuum state returns correct means and covariance""""""\n        means, cov = utils.vacuum_state(basis=""gaussian"", hbar=hbar)\n        assert np.all(means == np.zeros(2))\n        assert np.all(cov == np.identity(2) * hbar / 2)\n\n    def test_vacuum_state_fock(self, cutoff, hbar):\n        """"""test vacuum state returns correct state vector""""""\n        state = utils.vacuum_state(basis=""fock"", hbar=hbar, fock_dim=cutoff)\n        assert np.all(state == np.eye(1, cutoff, 0))\n\n    @pytest.mark.parametrize(""alpha"", ALPHA)\n    def test_coherent_state_gaussian(self, alpha, hbar):\n        """"""test coherent state returns correct means and covariance""""""\n        means, cov = utils.coherent_state(alpha, basis=""gaussian"", hbar=hbar)\n        means_expected = np.array([alpha.real, alpha.imag]) * np.sqrt(2 * hbar)\n        assert np.all(means == means_expected)\n        assert np.all(cov == np.identity(2) * hbar / 2)\n\n    @pytest.mark.parametrize(""alpha"", ALPHA)\n    def test_coherent_state_fock(self, alpha, cutoff, hbar, tol):\n        """"""test coherent state returns correct Fock basis state vector""""""\n        state = utils.coherent_state(alpha, basis=""fock"", fock_dim=cutoff, hbar=hbar)\n        n = np.arange(cutoff)\n        expected = np.exp(-0.5 * np.abs(alpha) ** 2) * alpha ** n / np.sqrt(fac(n))\n        assert np.allclose(state, expected, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""r, phi"", zip(R, PHI))\n    def test_squeezed_state_gaussian(self, r, phi, hbar, tol):\n        """"""test squeezed state returns correct means and covariance""""""\n        means, cov = utils.squeezed_state(r, phi, basis=""gaussian"", hbar=hbar)\n\n        cov_expected = (hbar / 2) * np.array(\n            [\n                [\n                    np.cosh(2 * r) - np.cos(phi) * np.sinh(2 * r),\n                    -2 * np.cosh(r) * np.sin(phi) * np.sinh(r),\n                ],\n                [\n                    -2 * np.cosh(r) * np.sin(phi) * np.sinh(r),\n                    np.cosh(2 * r) + np.cos(phi) * np.sinh(2 * r),\n                ],\n            ]\n        )\n\n        assert np.all(means == np.zeros([2]))\n        assert np.allclose(cov, cov_expected, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""r, phi"", zip(R, PHI))\n    def test_squeezed_state_fock(self, r, phi, cutoff, hbar, tol):\n        """"""test squeezed state returns correct Fock basis state vector""""""\n        state = utils.squeezed_state(r, phi, basis=""fock"", fock_dim=cutoff, hbar=hbar)\n\n        n = np.arange(cutoff)\n        kets = (np.sqrt(fac(2 * (n // 2))) / (2 ** (n // 2) * fac(n // 2))) * (\n            -np.exp(1j * phi) * np.tanh(r)\n        ) ** (n // 2)\n        expected = np.where(n % 2 == 0, np.sqrt(1 / np.cosh(r)) * kets, 0)\n\n        assert np.allclose(state, expected, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""a, r, phi"", zip(ALPHA, R, PHI))\n    def test_displaced_squeezed_state_gaussian(self, a, r, phi, hbar, tol):\n        """"""test displaced squeezed state returns correct means and covariance""""""\n        means, cov = utils.displaced_squeezed_state(a, r, phi, basis=""gaussian"", hbar=hbar)\n\n        means_expected = np.array([[a.real, a.imag]]) * np.sqrt(2 * hbar)\n        cov_expected = (hbar / 2) * np.array(\n            [\n                [\n                    np.cosh(2 * r) - np.cos(phi) * np.sinh(2 * r),\n                    -2 * np.cosh(r) * np.sin(phi) * np.sinh(r),\n                ],\n                [\n                    -2 * np.cosh(r) * np.sin(phi) * np.sinh(r),\n                    np.cosh(2 * r) + np.cos(phi) * np.sinh(2 * r),\n                ],\n            ]\n        )\n\n        assert np.allclose(means, means_expected, atol=tol, rtol=0)\n        assert np.allclose(cov, cov_expected, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""a, r, phi"", zip(ALPHA, R, PHI))\n    def test_displaced_squeezed_state_fock(self, a, r, phi, hbar, cutoff, tol):\n        """"""test displaced squeezed state returns correct Fock basis state vector""""""\n        state = utils.displaced_squeezed_state(a, r, phi, basis=""fock"", fock_dim=cutoff, hbar=hbar)\n\n        if r == 0:\n            pytest.skip(""test only non-zero squeezing"")\n\n        n = np.arange(cutoff)\n        gamma = a * np.cosh(r) + np.conj(a) * np.exp(1j * phi) * np.sinh(r)\n        coeff = np.diag(\n            (0.5 * np.exp(1j * phi) * np.tanh(r)) ** (n / 2) / np.sqrt(fac(n) * np.cosh(r))\n        )\n\n        expected = H(gamma / np.sqrt(np.exp(1j * phi) * np.sinh(2 * r)), coeff)\n        expected *= np.exp(\n            -0.5 * np.abs(a) ** 2 - 0.5 * np.conj(a) ** 2 * np.exp(1j * phi) * np.tanh(r)\n        )\n\n        assert np.allclose(state, expected, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""a, phi"", zip(ALPHA, PHI))\n    def test_displaced_squeezed_fock_no_squeezing(self, a, phi, hbar, cutoff, tol):\n        """"""test displaced squeezed state returns coherent state when there is no squeezing""""""\n        state = utils.displaced_squeezed_state(a, 0, phi, basis=""fock"", fock_dim=cutoff, hbar=hbar)\n\n        n = np.arange(cutoff)\n        expected = np.exp(-0.5 * np.abs(a) ** 2) * a ** n / np.sqrt(fac(n))\n\n        assert np.allclose(state, expected, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""r, phi"", zip(R, PHI))\n    def test_displaced_squeezed_fock_no_displacement(self, r, phi, hbar, cutoff, tol):\n        """"""test displaced squeezed state returns squeezed state when there is no displacement""""""\n        state = utils.displaced_squeezed_state(0, r, phi, basis=""fock"", fock_dim=cutoff, hbar=hbar)\n\n        n = np.arange(cutoff)\n        kets = (np.sqrt(fac(2 * (n // 2))) / (2 ** (n // 2) * fac(n // 2))) * (\n            -np.exp(1j * phi) * np.tanh(r)\n        ) ** (n // 2)\n        expected = np.where(n % 2 == 0, np.sqrt(1 / np.cosh(r)) * kets, 0)\n\n        assert np.allclose(state, expected, atol=tol, rtol=0)\n\n    def test_fock_state(self):\n        """"""test correct fock state returned""""""\n        n = 3\n        cutoff = 10\n        state = utils.fock_state(n, fock_dim=cutoff)\n        assert np.all(state == np.eye(1, cutoff, n))\n\n    def test_even_cat_state(self, tol):\n        """"""test correct even cat state returned""""""\n        a = 0.212\n        cutoff = 10\n        p = 0\n\n        state = utils.cat_state(a, p, fock_dim=cutoff)\n\n        n = np.arange(cutoff)\n        expected = np.exp(-0.5 * np.abs(a) ** 2) * a ** n / np.sqrt(fac(n)) + np.exp(\n            -0.5 * np.abs(-a) ** 2\n        ) * (-a) ** n / np.sqrt(fac(n))\n        expected /= np.linalg.norm(expected)\n\n        assert np.allclose(state, expected, atol=tol, rtol=0)\n\n    def test_odd_cat_state(self, tol):\n        """"""test correct even cat state returned""""""\n        a = 0.212\n        cutoff = 10\n        p = 1\n\n        state = utils.cat_state(a, p, fock_dim=cutoff)\n\n        n = np.arange(cutoff)\n        expected = np.exp(-0.5 * np.abs(a) ** 2) * a ** n / np.sqrt(fac(n)) - np.exp(\n            -0.5 * np.abs(-a) ** 2\n        ) * (-a) ** n / np.sqrt(fac(n))\n        expected /= np.linalg.norm(expected)\n\n        assert np.allclose(state, expected, atol=tol, rtol=0)\n\n\n# ===================================================================================\n# Random matrix tests\n# ===================================================================================\n\n\nclass TestRandomMatrices:\n    """"""Unit tests for random matrices""""""\n\n    @pytest.fixture\n    def modes(self):\n        """"""Number of modes to use when creating matrices""""""\n        return 3\n\n    @pytest.mark.parametrize(""pure_state"", [True, False])\n    @pytest.mark.parametrize(""block_diag"", [True, False])\n    def test_random_covariance_square(self, modes, hbar, pure_state, block_diag):\n        """"""Test that a random covariance matrix is the right shape""""""\n        V = utils.random_covariance(modes, hbar=hbar, pure=pure_state, block_diag=block_diag)\n        assert np.all(V.shape == np.array([2 * modes, 2 * modes]))\n\n    @pytest.mark.parametrize(""pure_state"", [True, False])\n    @pytest.mark.parametrize(""block_diag"", [True, False])\n    def test_random_covariance_symmetric(self, modes, hbar, pure_state, tol, block_diag):\n        """"""Test that a random covariance matrix is symmetric""""""\n        V = utils.random_covariance(modes, hbar=hbar, pure=pure_state, block_diag=block_diag)\n        assert np.allclose(V.T, V, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""pure_state"", [True, False])\n    @pytest.mark.parametrize(""block_diag"", [True, False])\n    def test_random_covariance_valid(self, modes, hbar, pure_state, tol, block_diag):\n        """"""Test that a random covariance matrix satisfies the uncertainty principle V+i hbar O/2 >=0""""""\n        V = utils.random_covariance(modes, hbar=hbar, pure=pure_state, block_diag=block_diag)\n\n        idm = np.identity(modes)\n        omega = np.concatenate(\n            (np.concatenate((0 * idm, idm), axis=1), np.concatenate((-idm, 0 * idm), axis=1)),\n            axis=0,\n        )\n\n        eigs = np.linalg.eigvalsh(V + 1j * (hbar / 2) * omega)\n        eigs[np.abs(eigs) < tol] = 0\n        assert np.all(eigs >= 0)\n\n    @pytest.mark.parametrize(""block_diag"", [True, False])\n    def test_random_covariance_pure(self, modes, hbar, tol, block_diag):\n        """"""Test that a pure random covariance matrix has correct purity""""""\n        V = utils.random_covariance(modes, hbar=hbar, pure=True, block_diag=block_diag)\n        det = np.linalg.det(V) - (hbar / 2) ** (2 * modes)\n        assert np.allclose(det, 0, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""block_diag"", [True, False])\n    def test_random_covariance_mixed(self, modes, hbar, tol, block_diag):\n        """"""Test that a mixed random covariance matrix has correct purity""""""\n        V = utils.random_covariance(modes, hbar=hbar, pure=False, block_diag=block_diag)\n        det = np.linalg.det(V) - (hbar / 2) ** (2 * modes)\n        assert not np.allclose(det, 0, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""passive"", [True, False])\n    @pytest.mark.parametrize(""block_diag"", [True, False])\n    def test_random_symplectic_square(self, modes, hbar, passive, block_diag):\n        """"""Test that a random symplectic matrix on is the right shape""""""\n        S = utils.random_symplectic(modes, passive=passive, block_diag=block_diag)\n        assert np.all(S.shape == np.array([2 * modes, 2 * modes]))\n\n    @pytest.mark.parametrize(""passive"", [True, False])\n    @pytest.mark.parametrize(""block_diag"", [True, False])\n    def test_random_symplectic_symplectic(self, modes, hbar, passive, tol, block_diag):\n        """"""Test that a random symplectic matrix is symplectic""""""\n        S = utils.random_symplectic(modes, passive=passive, block_diag=block_diag)\n\n        idm = np.identity(modes)\n        omega = np.concatenate(\n            (np.concatenate((0 * idm, idm), axis=1), np.concatenate((-idm, 0 * idm), axis=1)),\n            axis=0,\n        )\n\n        assert np.allclose(S @ omega @ S.T, omega, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""block_diag"", [True, False])\n    def test_random_symplectic_passive_orthogonal(self, modes, hbar, tol, block_diag):\n        """"""Test that a passive random symplectic matrix is orthogonal""""""\n        S = utils.random_symplectic(modes, passive=True, block_diag=block_diag)\n        assert np.allclose(S @ S.T, np.identity(2 * modes), atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""block_diag"", [True, False])\n    def test_random_symplectic_active_not_orthogonal(self, modes, hbar, tol, block_diag):\n        """"""Test that an active random symplectic matrix is not orthogonal""""""\n        S = utils.random_symplectic(modes, passive=False, block_diag=block_diag)\n        assert not np.allclose(S @ S.T, np.identity(2 * modes), atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""real"", [True, False])\n    def test_random_inteferometer_is_square(self, modes, real):\n        """"""Test that a random interferometer is square""""""\n        U = utils.random_interferometer(modes, real=real)\n        assert np.all(U.shape == np.array([modes, modes]))\n\n    @pytest.mark.parametrize(""real"", [True, False])\n    def test_random_inteferometer_is_unitary(self, modes, tol, real):\n        """"""Test that a random interferometer is unitary""""""\n        U = utils.random_interferometer(modes, real=real)\n        assert np.allclose(U @ U.conj().T, np.identity(modes), atol=tol, rtol=0)\n\n\n# ===================================================================================\n# Operation tests\n# ===================================================================================\n\n\nclass TestOperation:\n    """"""Tests for the operation decorator""""""\n\n    def test_applying_decorator(self):\n        """"""Test the __call__ method of the operation class""""""\n\n        def f(x):\n            return x ** 2\n\n        op = utils.operation(ns=1)\n        op(f)(0, 6, 3)\n\n        assert op.func == f\n        assert op.args == (0, 6, 3)\n\n    def test_no_arg_call_function(self, rr):\n        """"""Test exception raised if the wrapped function doesn\'t accept a register""""""\n\n        def dummy_func():\n            Sgate(r) | q[0]\n            BSgate() | (q[0], q[1])\n\n        op = utils.operation(ns=1)\n        op(dummy_func)()\n\n        with pytest.raises(ValueError, match=""must receive the qumode register""):\n            op._call_function(rr)\n\n    def test_incorrect_arg_num_call_function(self, rr):\n        """"""Test exception raised if the wrapped function is called with wrong number of args""""""\n\n        def dummy_func(r, q):\n            Sgate(r) | q[0]\n            BSgate() | (q[0], q[1])\n\n        op = utils.operation(ns=1)\n        op(dummy_func)(1, 2)\n\n        with pytest.raises(ValueError, match=""Mismatch in the number of arguments""):\n            op._call_function(rr)\n\n    def test_call_function(self, prog):\n        """"""Test _call_function method for operation class""""""\n        rval = 4.32\n        thetaval = -0.654\n        phival = 0.543\n\n        def dummy_func(r, theta, phi, q):\n            Sgate(r) | q[0]\n            BSgate(theta, phi) | (q[0], q[1])\n\n        op = utils.operation(ns=1)\n        op(dummy_func)(rval, thetaval, phival)\n\n        with prog.context as q:\n            res = op._call_function(q)\n\n        # check register is returned\n        assert res == q\n\n        # check eng queue matches the operation\n        assert len(prog) == 2\n\n        # check first queue op is Sgate(rval)\n        assert isinstance(prog.circuit[0].op, Sgate)\n        assert prog.circuit[0].reg == [q[0]]\n        assert prog.circuit[0].op.p[0] == rval\n\n        # check second queue op is BSgate(thetaval, phival)\n        assert isinstance(prog.circuit[1].op, BSgate)\n        assert prog.circuit[1].reg == list(q)\n        assert prog.circuit[1].op.p[0] == thetaval\n        assert prog.circuit[1].op.p[1] == phival\n\n    def test_multimode_wrong_num_modes_apply_operation(self, prog):\n        """"""Test exceptions raised when applying an operation to\n        multiple modes with incorrect num modes""""""\n        rval = 4.32\n        thetaval = -0.654\n        phival = 0.543\n\n        @utils.operation(1)\n        def dummy_func(r, theta, phi, q):\n            Sgate(r) | q[0]\n            BSgate(theta, phi) | (q[0], q[1])\n\n        with prog.context as q:\n            with pytest.raises(ValueError, match=""Wrong number of subsystems""):\n                dummy_func(rval, thetaval, phival) | q\n\n    def test_single_mode_no_args_apply_operation(self, prog):\n        """"""Test applying an operation to a single mode""""""\n        rval = 4.32\n\n        @utils.operation(2)\n        def dummy_func(q):\n            Sgate(rval) | q[0]\n\n        with prog.context as q:\n            dummy_func() | q\n\n        # check eng queue matches the operation\n        assert len(prog) == 1\n\n        # check first queue op is Sgate(rval)\n        assert isinstance(prog.circuit[0].op, Sgate)\n        assert prog.circuit[0].reg == [q[0]]\n        assert prog.circuit[0].op.p[0] == rval\n\n    def test_multimode_args_apply_operation(self, prog):\n        """"""Test applying an operation to multiple modes""""""\n        rval = 4.32\n        thetaval = -0.654\n        phival = 0.543\n\n        @utils.operation(2)\n        def dummy_func(r, theta, phi, q):\n            Sgate(r) | q[0]\n            BSgate(theta, phi) | (q[0], q[1])\n\n        with prog.context as q:\n            with pytest.raises(ValueError, match=""Wrong number of subsystems""):\n                dummy_func(rval, thetaval, phival) | q[0]\n\n        with prog.context as q:\n            dummy_func(rval, thetaval, phival) | q\n\n        # check eng queue matches the operation\n        assert len(prog) == 2\n\n        # check first queue op is Sgate(rval)\n        assert isinstance(prog.circuit[0].op, Sgate)\n        assert prog.circuit[0].reg == [q[0]]\n        assert prog.circuit[0].op.p[0] == rval\n\n        # check second queue op is BSgate(thetaval, phival)\n        assert isinstance(prog.circuit[1].op, BSgate)\n        assert prog.circuit[1].reg == list(q)\n        assert prog.circuit[1].op.p[0] == thetaval\n        assert prog.circuit[1].op.p[1] == phival\n\n\n# ===================================================================================\n# Engine utility tests\n# ===================================================================================\n\n\nclass TestEngineUtilityFunctions:\n    """"""Tests for some engine auxiliary functions""""""\n\n    def test_is_unitary_no_channel(self, prog):\n        """"""test that the is_unitary function returns True if no channels are present""""""\n        assert utils.is_unitary(prog)\n        with prog.context as q:\n            Sgate(0.4) | q[0]\n            BSgate(0.4) | q\n        assert utils.is_unitary(prog)\n\n    def test_is_unitary_with_channel(self, prog):\n        """"""test that the is_unitary function returns False if channels are present""""""\n        with prog.context as q:\n            Sgate(0.4) | q[0]\n            LossChannel(0.4) | q[0]\n            BSgate(0.4) | q\n        assert not utils.is_unitary(prog)\n\n    def test_is_channel_no_measurement(self, prog):\n        """"""test that the is_channel function returns True if no measurements are present""""""\n        assert utils.is_channel(prog)\n        with prog.context as q:\n            Sgate(0.4) | q[0]\n            LossChannel(0.4) | q[0]\n            BSgate(0.4) | q\n        assert utils.is_channel(prog)\n\n    def test_is_channel_measurement(self, prog):\n        """"""is_channel() returns False if measurements are present""""""\n        with prog.context as q:\n            Sgate(0.4) | q[0]\n            BSgate() | q\n            MeasureX | q[0]\n            Sgate(0.4) | q[1]\n        assert not utils.is_channel(prog)\n\n    def test_is_channel_preparation(self, prog):\n        """"""is_channel() returns False if preparations are present""""""\n        with prog.context as q:\n            Sgate(0.4) | q[0]\n            BSgate() | q\n            Squeezed(0.4) | q[1]\n        assert not utils.is_channel(prog)\n\n    def test_vectorize_unvectorize(self, tol):\n        """"""Test vectorize and unvectorize utility function""""""\n        cutoff = 4\n\n        dm = np.random.rand(*[cutoff] * 8) + 1j * np.random.rand(\n            *[cutoff] * 8\n        )  # 4^8 -> (4^2)^4 -> 4^8\n        dm2 = np.random.rand(*[cutoff] * 4) + 1j * np.random.rand(\n            *[cutoff] * 4\n        )  # (2^2)^4 -> 2^8 -> (2^2)^4\n\n        assert np.allclose(dm, utils._unvectorize(utils._vectorize(dm), 2), atol=tol, rtol=0)\n        assert np.allclose(dm2, utils._vectorize(utils._unvectorize(dm2, 2)), atol=tol, rtol=0)\n\n    def test_interleaved_identities(self, tol):\n        """"""Test interleaved utility function""""""\n\n        II = utils._interleaved_identities(n=2, cutoff_dim=3)\n        assert np.allclose(np.einsum(""abab"", II), 3 ** 2, atol=tol, rtol=0)\n\n        III = utils._interleaved_identities(n=3, cutoff_dim=5)\n        assert np.allclose(np.einsum(""abcabc"", III), 5 ** 3, atol=tol, rtol=0)\n\n\n# TODO: add unit tests for _engine_with_CJ_cmd_queue\n# extract_unitary, extract_channel\n'"
tests/integration/test_algorithms.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the Strawberry Fields example algorithms""""""\nimport pytest\n\nimport numpy as np\n\nimport strawberryfields as sf\nfrom strawberryfields.ops import *\n\n\n@pytest.mark.parametrize(\'cutoff\', [10], indirect=True)  # override default cutoff fixture\ndef test_teleportation_fidelity(setup_eng, pure):\n    """"""Test that teleportation of a coherent state has high fidelity""""""\n    eng, prog = setup_eng(3)\n    s = np.sqrt(2)\n    z = 2\n    BS = BSgate(np.pi / 4, 0)\n    alpha = 0.5 + 0.2j\n\n    with prog.context as q:\n        # TODO: at some point, use the blackbird parser to\n        # read in the following directly from the examples folder\n        Coherent(alpha) | q[0]\n\n        Squeezed(-z) | q[1]\n        Squeezed(z) | q[2]\n        BS | (q[1], q[2])\n\n        BS | (q[0], q[1])\n        MeasureHomodyne(0, select=0.07) | q[0]\n        MeasureHomodyne(np.pi / 2, select=0.1) | q[1]\n        Xgate(s * q[0].par) | q[2]\n        Zgate(s * q[1].par) | q[2]\n\n    state = eng.run(prog).state\n    fidelity = state.fidelity_coherent([0, 0, alpha])\n    assert np.allclose(fidelity, 1, atol=0.02, rtol=0)\n\n\n@pytest.mark.backends(""gaussian"")\ndef test_gaussian_gate_teleportation(setup_eng, pure):\n    """"""Test that gaussian states match after gate teleportation""""""\n    eng, prog = setup_eng(4)\n    with prog.context as q:\n        # TODO: at some point, use the blackbird parser to\n        # read in the following directly from the examples folder\n        Squeezed(0.1) | q[0]\n        Squeezed(-2) | q[1]\n        Squeezed(-2) | q[2]\n\n        Pgate(0.5) | q[1]\n\n        CZgate(1) | (q[0], q[1])\n        CZgate(1) | (q[1], q[2])\n\n        Fourier.H | q[0]\n        MeasureHomodyne(0, select=0) | q[0]\n        Fourier.H | q[1]\n        MeasureHomodyne(0, select=0) | q[1]\n\n        Squeezed(0.1) | q[3]\n        Fourier | q[3]\n        Pgate(0.5) | q[3]\n        Fourier | q[3]\n\n    state = eng.run(prog).state\n    cov1 = state.reduced_gaussian(2)[1]\n    cov2 = state.reduced_gaussian(3)[1]\n    assert np.allclose(cov1, cov2, atol=0.05, rtol=0)\n\n\ndef test_gaussian_boson_sampling_fock_probs(setup_eng, batch_size, tol):\n    """"""Test that GBS returns expected Fock probabilities""""""\n    eng, prog = setup_eng(4)\n    with prog.context as q:\n        # TODO: at some point, use the blackbird parser to\n        # read in the following directly from the examples folder\n        S = Sgate(1)\n        S | q[0]\n        S | q[1]\n        S | q[2]\n        S | q[3]\n\n        # rotation gates\n        Rgate(0.5719) | q[0]\n        Rgate(-1.9782) | q[1]\n        Rgate(2.0603) | q[2]\n        Rgate(0.0644) | q[3]\n\n        # beamsplitter array\n        BSgate(0.7804, 0.8578) | (q[0], q[1])\n        BSgate(0.06406, 0.5165) | (q[2], q[3])\n        BSgate(0.473, 0.1176) | (q[1], q[2])\n        BSgate(0.563, 0.1517) | (q[0], q[1])\n        BSgate(0.1323, 0.9946) | (q[2], q[3])\n        BSgate(0.311, 0.3231) | (q[1], q[2])\n        BSgate(0.4348, 0.0798) | (q[0], q[1])\n        BSgate(0.4368, 0.6157) | (q[2], q[3])\n\n    measure_states = [\n        [0, 0, 0, 0],\n        [1, 1, 0, 0],\n        [0, 1, 0, 1],\n        [1, 1, 1, 1],\n        [2, 0, 0, 0],\n    ]\n\n    results = [\n        0.176378447614135,\n        0.0685595637122246,\n        0.002056097258977398,\n        0.00834294639986785,\n        0.01031294525345511,\n    ]\n\n    state = eng.run(prog).state\n    probs = [state.fock_prob(i) for i in measure_states]\n    probs = np.array(probs).T.flatten()\n\n    if batch_size is not None:\n        results = np.tile(results, batch_size).flatten()\n\n    assert np.allclose(probs, results, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""tf"", ""fock"")\ndef test_boson_sampling_fock_probs(setup_eng, batch_size, tol):\n    """"""Test that boson sampling returns expected Fock probabilities""""""\n    eng, prog = setup_eng(4)\n    with prog.context as q:\n        # TODO: at some point, use the blackbird parser to\n        # read in the following directly from the examples folder\n        Fock(1) | q[0]\n        Fock(1) | q[1]\n        Vac | q[2]\n        Fock(1) | q[3]\n\n        # rotation gates\n        Rgate(0.5719) | q[0]\n        Rgate(-1.9782) | q[1]\n        Rgate(2.0603) | q[2]\n        Rgate(0.0644) | q[3]\n\n        # beamsplitter array\n        BSgate(0.7804, 0.8578) | (q[0], q[1])\n        BSgate(0.06406, 0.5165) | (q[2], q[3])\n        BSgate(0.473, 0.1176) | (q[1], q[2])\n        BSgate(0.563, 0.1517) | (q[0], q[1])\n        BSgate(0.1323, 0.9946) | (q[2], q[3])\n        BSgate(0.311, 0.3231) | (q[1], q[2])\n        BSgate(0.4348, 0.0798) | (q[0], q[1])\n        BSgate(0.4368, 0.6157) | (q[2], q[3])\n\n    measure_states = [[1, 1, 0, 1], [2, 0, 0, 1]]\n    results = [0.174689160486, 0.106441927246]\n\n    state = eng.run(prog).state\n    probs = [state.fock_prob(i) for i in measure_states]\n    probs = np.array(probs).T.flatten()\n\n    if batch_size is not None:\n        results = np.tile(results, batch_size).flatten()\n\n    assert np.allclose(probs, results, atol=tol, rtol=0)\n\n\n@pytest.mark.parametrize(\'cutoff\', [4], indirect=True)  # override default cutoff fixture\n@pytest.mark.backends(""tf"", ""fock"")\ndef test_hamiltonian_simulation_fock_probs(setup_eng, pure, batch_size, tol):\n    """"""Test that Hamiltonian simulation returns expected Fock probabilities""""""\n    eng, prog = setup_eng(2)\n\n    measure_states = [[0, 2], [1, 1], [2, 0]]\n    results = [0.52240124572, 0.235652876857, 0.241945877423]\n\n    # set the Hamiltonian parameters\n    J = 1  # hopping transition\n    U = 1.5  # on-site interaction\n    k = 20  # Lie product decomposition terms\n    t = 1.086  # timestep\n    theta = -J * t / k\n    r = -U * t / (2 * k)\n\n    with prog.context as q:\n        Fock(2) | q[0]\n\n        # Two node tight-binding\n        # Hamiltonian simulation\n\n        for i in range(k):\n            BSgate(theta, np.pi / 2) | (q[0], q[1])\n            Kgate(r) | q[0]\n            Rgate(-r) | q[0]\n            Kgate(r) | q[1]\n            Rgate(-r) | q[1]\n\n    state = eng.run(prog).state\n    probs = [state.fock_prob(i) for i in measure_states]\n    probs = np.array(probs).T.flatten()\n\n    if batch_size is not None:\n        results = np.tile(results, batch_size).flatten()\n\n    assert np.allclose(probs, results, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""gaussian"")\nclass TestGaussianCloning:\n    """"""Tests specific to Gaussian cloning""""""\n\n    @staticmethod\n    def gaussian_cloning_circuit(q):\n        # TODO: at some point, use the blackbird parser to\n        # read in the following directly from the examples folder\n        BSgate() | (q[0], q[1])\n        BSgate() | (q[1], q[2])\n        MeasureX | q[1]\n        MeasureP | q[2]\n        Xgate(q[1].par * np.sqrt(2)) | q[0]\n        Zgate(q[2].par * np.sqrt(2)) | q[0]\n        BSgate() | (q[0], q[3])\n\n    def test_identical_output(self, setup_eng, tol):\n        """"""Test that all outputs are identical clones""""""\n        a = 0.7 + 1.2j\n\n        eng, prog = setup_eng(4)\n        with prog.context as q:\n            Coherent(a) | q[0]\n            self.gaussian_cloning_circuit(q)\n\n        state = eng.run(prog, **{\'modes\': [0, 3]}).state\n        coh = np.array([state.is_coherent(i) for i in range(2)])\n        disp = state.displacement()\n\n        # check all outputs are coherent states\n        assert np.all(coh)\n        # check outputs are identical clones\n        assert np.allclose(*disp, atol=tol, rtol=0)\n\n    def test_average_fidelity(self, setup_eng):\n        """"""Test that gaussian cloning clones a Gaussian state with average fidelity 2/3""""""\n        shots = 500\n        a = 0.7 + 1.2j\n\n        eng, prog = setup_eng(4)\n        with prog.context as q:\n            Coherent(a) | q[0]\n            self.gaussian_cloning_circuit(q)\n\n        f_list = np.empty([shots])\n        a_list = np.empty([shots], dtype=np.complex128)\n\n        for i in range(shots):\n            state = eng.run(prog, **{\'modes\': [0]}).state\n            eng.reset()\n            f_list[i] = state.fidelity_coherent([0.7 + 1.2j])\n            a_list[i] = state.displacement()\n\n        assert np.allclose(np.mean(f_list), 2.0 / 3.0, atol=0.1, rtol=0)\n        assert np.allclose(np.mean(a_list), a, atol=0.1, rtol=0)\n        assert np.allclose(\n            np.cov([a_list.real, a_list.imag]), 0.25 * np.identity(2), atol=0.1, rtol=0\n        )\n'"
tests/integration/test_decompositions_integration.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Unit tests for the Strawberry Fields decompositions within the ops module""""""\nimport pytest\n\nimport numpy as np\nfrom scipy.linalg import qr, block_diag\n\nimport strawberryfields as sf\nfrom strawberryfields import decompositions as dec\nfrom strawberryfields.utils import (\n    random_interferometer,\n    random_symplectic,\n    random_covariance,\n    squeezed_state,\n)\nfrom strawberryfields import ops\nfrom strawberryfields.backends.shared_ops import (\n    haar_measure,\n    changebasis,\n    rotation_matrix as rot,\n)\n\n\n# make the test file deterministic\nnp.random.seed(42)\n\n\nu1 = random_interferometer(3)\nu2 = random_interferometer(3)\nS = random_symplectic(3)\n\n\n@pytest.fixture\ndef V_mixed(hbar):\n    return random_covariance(3, hbar=hbar, pure=False)\n\n@pytest.fixture\ndef V_pure(hbar):\n    return random_covariance(3, hbar=hbar, pure=True)\n\n@pytest.fixture\ndef r_means(hbar):\n    return np.random.randn(6) * np.sqrt(hbar / 2)\n\n\nA = np.array(\n    [\n        [1.28931633 + 0.75228801j, 1.45557375 + 0.96825143j, 1.53672608 + 1.465635j],\n        [1.45557375 + 0.96825143j, 0.37611686 + 0.84964159j, 1.25122856 + 1.28071385j],\n        [1.53672608 + 1.465635j, 1.25122856 + 1.28071385j, 1.88217983 + 1.70869293j],\n    ]\n)\n\nA -= np.trace(A) * np.identity(3) / 3\n\n\nAbp = np.array([[0, 0, 0, 0.11959425, 0.71324479, 0.76078505],\n [0, 0, 0, 0.5612772, 0.77096718, 0.4937956],\n [0, 0, 0, 0.52273283, 0.42754102, 0.02541913],\n [0.11959425, 0.5612772, 0.52273283, 0, 0, 0, ],\n [0.71324479, 0.77096718, 0.42754102, 0, 0, 0, ],\n [0.76078505, 0.4937956, 0.02541913, 0, 0, 0, ]])\n\n\n\n@pytest.mark.backends(""gaussian"")\nclass TestGaussianBackendDecompositions:\n    """"""Test that the frontend decompositions work on the Gaussian backend""""""\n\n    def test_gaussian_transform(self, setup_eng, hbar, tol):\n        """"""Test applying a Gaussian symplectic transform""""""\n        eng, prog = setup_eng(3)\n\n        with prog.context as q:\n            ops.GaussianTransform(S) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), S @ S.T * hbar / 2, atol=tol)\n\n    def test_graph_embed(self, setup_eng, tol):\n        """"""Test that embedding a traceless adjacency matrix A\n        results in the property Amat/A = c J, where c is a real constant,\n        and J is the all ones matrix""""""\n        N = 3\n        eng, prog = setup_eng(3)\n\n        with prog.context as q:\n            ops.GraphEmbed(A) | q\n\n        state = eng.run(prog).state\n        Amat = eng.backend.circuit.Amat()\n\n        # check that the matrix Amat is constructed to be of the form\n        # Amat = [[B^\\dagger, 0], [0, B]]\n        assert np.allclose(Amat[:N, :N], Amat[N:, N:].conj().T, atol=tol)\n        assert np.allclose(Amat[:N, N:], np.zeros([N, N]), atol=tol)\n        assert np.allclose(Amat[N:, :N], np.zeros([N, N]), atol=tol)\n\n        ratio = np.real_if_close(Amat[N:, N:] / A)\n        ratio /= ratio[0, 0]\n        assert np.allclose(ratio, np.ones([N, N]), atol=tol)\n\n    def test_graph_embed_identity(self, setup_eng, tol):\n        """"""Test that nothing is done if the adjacency matrix is the identity""""""\n        prog = sf.Program(3)\n        with prog.context as q:\n            ops.GraphEmbed(np.identity(3)) | q\n\n        assert len(prog) == 1\n        prog = prog.compile(\'gaussian\')\n        assert len(prog) == 0\n\n    def test_bipartite_graph_embed(self, setup_eng, tol):\n        """"""Test that embedding a bipartite adjacency matrix A\n        results in the property Amat/A = c J, where c is a real constant,\n        and J is the all ones matrix""""""\n        N = 6\n        eng, prog = setup_eng(6)\n\n        with prog.context as q:\n            ops.BipartiteGraphEmbed(Abp) | q\n\n        state = eng.run(prog).state\n        Amat = eng.backend.circuit.Amat()\n\n        # check that the matrix Amat is constructed to be of the form\n        # Amat = [[B^\\dagger, 0], [0, B]]\n        assert np.allclose(Amat[:N, :N], Amat[N:, N:].conj().T, atol=tol)\n        assert np.allclose(Amat[:N, N:], np.zeros([N, N]), atol=tol)\n        assert np.allclose(Amat[N:, :N], np.zeros([N, N]), atol=tol)\n\n        # final Amat\n        Amat = Amat[:N, :N]\n        n = N // 2\n\n        ratio = np.real_if_close(Amat[n:, :n] / Abp[n:, :n])\n        ratio /= ratio[0, 0]\n        assert np.allclose(ratio, np.ones([n, n]), atol=tol)\n\n    def test_bipartite_graph_embed_edgeset(self, setup_eng, tol):\n        """"""Test that embedding a bipartite edge set B\n        results in the property Amat/A = c J, where c is a real constant,\n        and J is the all ones matrix""""""\n        N = 6\n        eng, prog = setup_eng(6)\n        B = Abp[:N//2, N//2:]\n        print(B)\n\n        with prog.context as q:\n            ops.BipartiteGraphEmbed(B, edges=True) | q\n\n        state = eng.run(prog).state\n        Amat = eng.backend.circuit.Amat()\n\n        # check that the matrix Amat is constructed to be of the form\n        # Amat = [[B^\\dagger, 0], [0, B]]\n        assert np.allclose(Amat[:N, :N], Amat[N:, N:].conj().T, atol=tol)\n        assert np.allclose(Amat[:N, N:], np.zeros([N, N]), atol=tol)\n        assert np.allclose(Amat[N:, :N], np.zeros([N, N]), atol=tol)\n\n        # final Amat\n        Amat = Amat[:N, :N]\n        n = N // 2\n\n        ratio = np.real_if_close(Amat[n:, :n] / B.T)\n        ratio /= ratio[0, 0]\n        assert np.allclose(ratio, np.ones([n, n]), atol=tol)\n\n\n    def test_passive_gaussian_transform(self, setup_eng, tol):\n        """"""Test applying a passive Gaussian symplectic transform,\n        which is simply an interferometer""""""\n        eng, p1 = setup_eng(3)\n        O = np.vstack([np.hstack([u1.real, -u1.imag]), np.hstack([u1.imag, u1.real])])\n\n        with p1.context as q:\n            ops.All(ops.Squeezed(0.5)) | q\n        init = eng.run(p1).state\n\n        p2 = sf.Program(p1)\n        with p2.context as q:\n            ops.GaussianTransform(O) | q\n\n        state = eng.run(p2).state\n        assert np.allclose(state.cov(), O @ init.cov() @ O.T, atol=tol)\n\n    def test_active_gaussian_transform_on_vacuum(self, setup_eng, hbar, tol):\n        """"""Test applying a passive Gaussian symplectic transform,\n        which is simply squeezing and ONE interferometer""""""\n        eng, prog = setup_eng(3)\n\n        with prog.context as q:\n            ops.GaussianTransform(S, vacuum=True) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), S @ S.T * hbar / 2, atol=tol)\n\n    def test_interferometer(self, setup_eng, tol):\n        """"""Test applying an interferometer""""""\n        eng, p1 = setup_eng(3)\n\n        with p1.context as q:\n            ops.All(ops.Squeezed(0.5)) | q\n        init = eng.run(p1).state\n\n        p2 = sf.Program(p1)\n        with p2.context as q:\n            ops.Interferometer(u1) | q\n\n        state = eng.run(p2).state\n        O = np.vstack([np.hstack([u1.real, -u1.imag]), np.hstack([u1.imag, u1.real])])\n        assert np.allclose(state.cov(), O @ init.cov() @ O.T, atol=tol)\n\n    def test_identity_interferometer(self, setup_eng, tol):\n        """"""Test that applying an identity interferometer does nothing""""""\n        prog = sf.Program(3)\n        with prog.context as q:\n            ops.Interferometer(np.identity(3)) | q\n\n        assert len(prog) == 1\n        prog = prog.compile(\'gaussian\')\n        assert len(prog) == 0\n\n\n@pytest.mark.backends(""gaussian"")\nclass TestGaussianBackendPrepareState:\n    """"""Test passing several Gaussian states directly to the Gaussian backend.\n    This is allowed for backends that implement the prepare_gaussian_state method.""""""\n\n    def test_vacuum(self, setup_eng, hbar, tol):\n        """"""Testing a vacuum state""""""\n        eng, prog = setup_eng(3)\n        cov = (hbar / 2) * np.identity(6)\n        with prog.context as q:\n            ops.Gaussian(cov, decomp=False) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), cov, atol=tol)\n        assert np.all(state.means() == np.zeros([6]))\n        assert np.allclose(state.fidelity_vacuum(), 1, atol=tol)\n\n    def test_squeezed(self, setup_eng, hbar, tol):\n        """"""Testing a squeezed state""""""\n        eng, prog = setup_eng(3)\n        cov = (hbar / 2) * np.diag([np.exp(-0.1)] * 3 + [np.exp(0.1)] * 3)\n\n        with prog.context as q:\n            ops.Gaussian(cov, decomp=False) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), cov, atol=tol)\n\n    def test_displaced_squeezed(self, setup_eng, hbar, tol):\n        """"""Testing a displaced squeezed state""""""\n        eng, prog = setup_eng(3)\n        cov = (hbar / 2) * np.diag([np.exp(-0.1)] * 3 + [np.exp(0.1)] * 3)\n        means = np.array([0, 0.1, 0.2, -0.1, 0.3, 0])\n\n        with prog.context as q:\n            ops.Gaussian(cov, r=means, decomp=False) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), cov, atol=tol)\n        assert np.allclose(state.means(), means, atol=tol)\n\n    def test_thermal(self, setup_eng, hbar, tol):\n        """"""Testing a thermal state""""""\n        eng, prog = setup_eng(3)\n        cov = np.diag(hbar * (np.array([0.3, 0.4, 0.2] * 2) + 0.5))\n\n        with prog.context as q:\n            ops.Gaussian(cov, decomp=False) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), cov, atol=tol)\n\n    def test_rotated_squeezed(self, setup_eng, hbar, tol):\n        """"""Testing a rotated squeezed state""""""\n        eng, prog = setup_eng(3)\n\n        r = 0.1\n        phi = 0.2312\n        v1 = (hbar / 2) * np.diag([np.exp(-r), np.exp(r)])\n        A = changebasis(3)\n        cov = A.T @ block_diag(*[rot(phi) @ v1 @ rot(phi).T] * 3) @ A\n\n        with prog.context as q:\n            ops.Gaussian(cov, decomp=False) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), cov, atol=tol)\n\n\n@pytest.mark.backends(""gaussian"")\nclass TestGaussianBackendDecomposeState:\n    """"""Test decomposing several Gaussian states for the Gaussian backend.""""""\n\n    def test_vacuum(self, setup_eng, hbar, tol):\n        """"""Testing decomposed vacuum state""""""\n        eng, prog = setup_eng(3)\n        cov = (hbar / 2) * np.identity(6)\n        with prog.context as q:\n            ops.Gaussian(cov) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), cov, atol=tol)\n        assert np.all(state.means() == np.zeros([6]))\n        assert np.allclose(state.fidelity_vacuum(), 1, atol=tol)\n        assert len(eng.run_progs[-1]) == 3\n\n    def test_squeezed(self, setup_eng, hbar, tol):\n        """"""Testing decomposed squeezed state""""""\n        eng, prog = setup_eng(3)\n        cov = (hbar / 2) * np.diag([np.exp(-0.1)] * 3 + [np.exp(0.1)] * 3)\n\n        with prog.context as q:\n            ops.Gaussian(cov) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), cov, atol=tol)\n        assert len(eng.run_progs[-1]) == 3\n\n    def test_displaced_squeezed(self, setup_eng, hbar, tol):\n        """"""Testing decomposed displaced squeezed state""""""\n        eng, prog = setup_eng(3)\n        cov = (hbar / 2) * np.diag([np.exp(-0.1)] * 3 + [np.exp(0.1)] * 3)\n        means = np.array([0, 0.1, 0.2, -0.1, 0.3, 0])\n\n        with prog.context as q:\n            ops.Gaussian(cov, means) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), cov, atol=tol)\n        assert np.allclose(state.means(), means, atol=tol)\n        assert len(eng.run_progs[-1]) == 7\n\n    def test_thermal(self, setup_eng, hbar, tol):\n        """"""Testing decomposed thermal state""""""\n        eng, prog = setup_eng(3)\n        cov = np.diag(hbar * (np.array([0.3, 0.4, 0.2] * 2) + 0.5))\n\n        with prog.context as q:\n            ops.Gaussian(cov) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), cov, atol=tol)\n        assert len(eng.run_progs[-1]) == 3\n\n    def test_rotated_squeezed(self, setup_eng, hbar, tol):\n        """"""Testing decomposed rotated squeezed state""""""\n        eng, prog = setup_eng(3)\n\n        r = 0.1\n        phi = 0.2312\n        v1 = (hbar / 2) * np.diag([np.exp(-r), np.exp(r)])\n        A = changebasis(3)\n        cov = A.T @ block_diag(*[rot(phi) @ v1 @ rot(phi).T] * 3) @ A\n\n        with prog.context as q:\n            ops.Gaussian(cov) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), cov, atol=tol)\n        assert len(eng.run_progs[-1]) == 3\n\n    def test_random_state_mixed(self, setup_eng, V_mixed, r_means, tol):\n        """"""Test applying a mixed covariance state""""""\n        eng, prog = setup_eng(3)\n        with prog.context as q:\n            ops.Gaussian(V_mixed, r_means) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), V_mixed, atol=tol, rtol=0)\n        assert np.allclose(state.means(), r_means, atol=tol, rtol=0)\n        assert len(eng.run_progs[-1]) == 30\n\n    def test_random_state_pure(self, setup_eng, V_pure, r_means, tol):\n        """"""Test applying a pure covariance state""""""\n        eng, prog = setup_eng(3)\n        with prog.context as q:\n            ops.Gaussian(V_pure, r_means) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.cov(), V_pure, atol=tol, rtol=0)\n        assert np.allclose(state.means(), r_means, atol=tol, rtol=0)\n        assert len(eng.run_progs[-1]) == 21\n\n\n@pytest.mark.backends(""tf"", ""fock"")\nclass TestFockBackendDecomposeState:\n    """"""Test decomposing several Gaussian states for the Fock backends,\n    by measuring the fidelities.""""""\n\n    def test_vacuum(self, setup_eng, hbar, tol):\n        eng, prog = setup_eng(3)\n\n        with prog.context as q:\n            ops.Gaussian(np.identity(6) * hbar / 2) | q\n\n        state = eng.run(prog).state\n        assert np.allclose(state.fidelity_vacuum(), 1, atol=tol)\n        assert len(eng.run_progs[-1]) == 3\n\n    def test_squeezed(self, setup_eng, cutoff, hbar, tol):\n        eng, prog = setup_eng(3)\n        r = 0.05\n        phi = 0\n        cov = (hbar / 2) * np.diag([np.exp(-2 * r)] * 3 + [np.exp(2 * r)] * 3)\n        in_state = squeezed_state(r, phi, basis=""fock"", fock_dim=cutoff)\n\n        with prog.context as q:\n            ops.Gaussian(cov) | q\n\n        state = eng.run(prog).state\n        assert len(eng.run_progs[-1]) == 3\n\n        for n in range(3):\n            assert np.allclose(state.fidelity(in_state, n), 1, atol=tol)\n\n    def test_rotated_squeezed(self, setup_eng, cutoff, hbar, tol):\n        eng, prog = setup_eng(3)\n\n        r = 0.1\n        phi = 0.2312\n        in_state = squeezed_state(r, phi, basis=""fock"", fock_dim=cutoff)\n\n        v1 = (hbar / 2) * np.diag([np.exp(-2 * r), np.exp(2 * r)])\n        A = changebasis(3)\n        cov = A.T @ block_diag(*[rot(phi) @ v1 @ rot(phi).T] * 3) @ A\n\n        with prog.context as q:\n            ops.Gaussian(cov) | q\n\n        state = eng.run(prog).state\n        assert len(eng.run_progs[-1]) == 3\n\n        for n in range(3):\n            assert np.allclose(state.fidelity(in_state, n), 1, atol=tol)\n\nclass TestDecompositionsGaussianGates:\n    """"""Test the actions of several non-primitive Gaussian gates""""""\n\n    @pytest.mark.backends(""gaussian"")\n    def test_Pgate(self, setup_eng, pure, hbar, tol):\n        """"""Test the action of the P gate in phase space""""""\n        if not pure:\n            pytest.skip(""Test only runs on pure states"")\n        N = 1\n        eng, prog = setup_eng(N)\n        r = 3\n        x1 = 2\n        p1 = 1.3\n        s = 0.5\n        with prog.context as q:\n            ops.Sgate(r) | q\n            ops.Xgate(x1) | q\n            ops.Zgate(p1) | q\n            ops.Pgate(s) | q\n        state = eng.run(prog).state\n\n        Pmat = np.array([[1, 0], [s, 1]])\n        Vexpected = 0.5 * hbar * Pmat @ np.diag(np.exp([-2 * r, 2 * r])) @ Pmat.T\n        assert np.allclose(Vexpected, state.cov(), atol=tol, rtol=0)\n        rexpected = Pmat @ np.array([x1, p1])\n        assert np.allclose(rexpected, state.means(), atol=tol, rtol=0)\n\n    @pytest.mark.backends(""gaussian"")\n    def test_CXgate(self, setup_eng, pure, hbar, tol):\n        """"""Test the action of the CX gate in phase space""""""\n        if not pure:\n            pytest.skip(""Test only runs on pure states"")\n        N = 2\n        eng, prog = setup_eng(N)\n        r = 3\n        x1 = 2\n        x2 = 1\n        p1 = 1.37\n        p2 = 2.71\n        s = 0.5\n        with prog.context as q:\n            ops.Sgate(r) | q[0]\n            ops.Xgate(x1) | q[0]\n            ops.Zgate(p1) | q[0]\n            ops.Sgate(r) | q[1]\n            ops.Xgate(x2) | q[1]\n            ops.Zgate(p2) | q[1]\n            ops.CXgate(s) | q\n        state = eng.run(prog).state\n        CXmat = np.array([[1, 0, 0, 0], [s, 1, 0, 0], [0, 0, 1, -s], [0, 0, 0, 1]])\n        Vexpected = 0.5 * hbar * CXmat @ np.diag(np.exp([-2 * r, -2 * r, 2 * r, 2 * r])) @ CXmat.T\n        # Checks the covariance matrix is transformed correctly\n        assert np.allclose(state.cov(), Vexpected, atol=tol, rtol=0)\n        rexpected = CXmat @ np.array([x1, x2, p1, p2])\n        # Checks the means are transformed correctly\n        assert np.allclose(state.means(), rexpected, atol=tol, rtol=0)\n\n    @pytest.mark.backends(""gaussian"")\n    def test_CZgate(self, setup_eng, pure, hbar, tol):\n        """"""Test the action of the CZ gate in phase space""""""\n        if not pure:\n            pytest.skip(""Test only runs on pure states"")\n        N = 2\n        eng, prog = setup_eng(N)\n        r = 3\n        x1 = 2\n        x2 = 1\n        p1 = 1.37\n        p2 = 2.71\n        s = 0.5\n        with prog.context as q:\n            ops.Sgate(r) | q[0]\n            ops.Xgate(x1) | q[0]\n            ops.Zgate(p1) | q[0]\n            ops.Sgate(r) | q[1]\n            ops.Xgate(x2) | q[1]\n            ops.Zgate(p2) | q[1]\n            ops.CZgate(s) | q\n        state = eng.run(prog).state\n        CZmat = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, s, 1, 0], [s, 0, 0, 1]])\n        Vexpected = 0.5 * hbar * CZmat @ np.diag(np.exp([-2 * r, -2 * r, 2 * r, 2 * r])) @ CZmat.T\n        # Checks the covariance matrix is transformed correctly\n        assert np.allclose(state.cov(), Vexpected, atol=tol, rtol=0)\n        rexpected = CZmat @ np.array([x1, x2, p1, p2])\n        # Checks the means are transformed correctly\n        assert np.allclose(state.means(), rexpected, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(\'s\', np.linspace(-0.6, 0.6, 5))\n    def test_Pgate_decomp_equal(self, setup_eng, s, tol):\n        """"""Tests that the Pgate gives the same transformation as its decomposition.""""""\n        eng, prog = setup_eng(1)\n\n        r = np.arccosh(np.sqrt(1 + (s / 2) ** 2))\n        theta = np.arctan(s / 2)\n        phi = -np.sign(s) * np.pi / 2 - theta\n\n        with prog.context as q:\n            ops.Pgate(s) | q\n            # run decomposition with reversed arguments\n            ops.Rgate(-theta) | q\n            ops.Sgate(r, phi + np.pi) | q\n\n        eng.run(prog)\n        assert np.all(eng.backend.is_vacuum(tol))\n\n    @pytest.mark.parametrize(\'s\', np.linspace(-0.5, 0.5, 5))\n    def test_CXgate_decomp_equal(self, setup_eng, s, tol):\n        """"""Tests that the CXgate gives the same transformation as its decomposition.""""""\n        eng, prog = setup_eng(2)\n\n        r = np.arcsinh(-s / 2)\n        y = -1 / np.cosh(r)\n        x = -np.tanh(r)\n        theta = np.arctan2(y, x) / 2\n\n        with prog.context as q:\n            ops.CXgate(s) | q\n            # run decomposition with reversed arguments\n            ops.BSgate(-(np.pi / 2 + theta), 0) | q\n            ops.Sgate(r, np.pi) | q[0]\n            ops.Sgate(r, 0) | q[1]\n            ops.BSgate(-theta, 0) | q\n\n        eng.run(prog)\n        assert np.all(eng.backend.is_vacuum(tol))\n\n    @pytest.mark.parametrize(\'s\', np.linspace(-0.5, 0.5, 5))\n    def test_CZgate_decomp_equal(self, setup_eng, s, tol):\n        """"""Tests that the CZgate gives the same transformation as its decomposition.""""""\n        eng, prog = setup_eng(2)\n\n        with prog.context as q:\n            ops.CZgate(s) | q\n            # run decomposition with reversed arguments\n            ops.Rgate(-np.pi / 2) | q[1]\n            ops.CXgate(-s) | q\n            ops.Rgate(np.pi / 2) | q[1]\n\n        eng.run(prog)\n        assert np.all(eng.backend.is_vacuum(tol))\n\n    @pytest.mark.parametrize(\'r\', np.linspace(-0.3, 0.3, 5))\n    def test_S2gate_decomp_equal(self, setup_eng, r, tol):\n        """"""Tests that the S2gate gives the same transformation as its decomposition.""""""\n        eng, prog = setup_eng(2)\n\n        phi = 0.273\n        BS = ops.BSgate(np.pi / 4, 0)\n        with prog.context as q:\n            ops.S2gate(r, phi) | q\n            # run decomposition with reversed arguments\n            BS | q\n            ops.Sgate(-r, phi) | q[0]\n            ops.Sgate(r, phi) | q[1]\n            BS.H | q\n\n        eng.run(prog)\n        assert np.all(eng.backend.is_vacuum(tol))\n\n'"
tests/integration/test_engine_integration.py,1,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Integration tests for the frontend engine.py module with the backends""""""\nimport numbers\nimport pytest\n\nimport numpy as np\nimport tensorflow as tf\n\nimport strawberryfields as sf\nfrom strawberryfields import ops\nfrom strawberryfields.backends import BaseGaussian, BaseFock\nfrom strawberryfields.backends import GaussianBackend, FockBackend\nfrom strawberryfields.backends.states import BaseState\n\n\ntry:\n    from strawberryfields.backends.tfbackend import TFBackend\nexcept (ImportError, ModuleNotFoundError, ValueError) as e:\n    eng_backend_params = [(""gaussian"", GaussianBackend), (""fock"", FockBackend)]\nelse:\n    eng_backend_params = [\n        (""tf"", TFBackend),\n        (""gaussian"", GaussianBackend),\n        (""fock"", FockBackend),\n    ]\n\n\n# make test deterministic\nnp.random.seed(42)\na = 0.1234\nb = -0.543\nc = 0.312\n\n@property\ndef batched(batch_size):\n    """"""Checks if session is batched.""""""\n    return bool(batch_size)\n\n@pytest.mark.parametrize(""name,expected"", eng_backend_params)\ndef test_load_backend(name, expected, cutoff):\n    """"""Test backends can be correctly loaded via strings""""""\n    eng = sf.Engine(name)\n    assert isinstance(eng.backend, expected)\n\n\nclass TestEngineReset:\n    """"""Test engine reset functionality""""""\n\n    def test_init_vacuum(self, setup_eng, tol):\n        """"""Test that the engine is initialized to the vacuum state""""""\n        eng, prog = setup_eng(2)\n        eng.run(prog)  # run an empty program\n        assert np.all(eng.backend.is_vacuum(tol))\n\n    def test_reset_vacuum(self, setup_eng, tol):\n        """"""Test that resetting the engine returns to the vacuum state""""""\n        eng, prog = setup_eng(2)\n\n        with prog.context:\n            ops.Dgate(0.5) | 0\n\n        eng.run(prog)\n        assert not np.all(eng.backend.is_vacuum(tol))\n\n        eng.reset()\n        assert np.all(eng.backend.is_vacuum(tol))\n\n    @pytest.mark.backends(""fock"")\n    def test_eng_reset(self, setup_eng, cutoff):\n        """"""Test the Engine.reset() features.""""""\n        eng, prog = setup_eng(2)\n\n        state = eng.run(prog).state\n        backend_cutoff = eng.backend.get_cutoff_dim()\n        assert state._cutoff == backend_cutoff\n        assert cutoff == backend_cutoff\n\n        # change the cutoff dimension\n        new_cutoff = cutoff + 1\n        eng.reset({""cutoff_dim"": new_cutoff})\n\n        state = eng.run(prog).state\n        backend_cutoff = eng.backend.get_cutoff_dim()\n        assert state._cutoff == backend_cutoff\n        assert new_cutoff == backend_cutoff\n\n\nclass TestProperExecution:\n    """"""Test that various frontend circuits execute through\n    the backend with no error""""""\n\n    def test_no_return_state(self, setup_eng):\n        """"""Engine returns no state object when none is requested.""""""\n        eng, prog = setup_eng(2)\n        res = eng.run(prog, modes=[])\n        assert res.state is None\n\n    def test_return_state(self, setup_eng):\n        """"""Engine returns a valid state object.""""""\n        eng, prog = setup_eng(2)\n        res = eng.run(prog)\n        assert isinstance(res.state, BaseState)\n\n    def test_return_samples(self, setup_eng):\n        """"""Engine returns measurement samples.""""""\n        eng, prog = setup_eng(2)\n        with prog.context as q:\n            ops.MeasureX | q[0]\n\n        res = eng.run(prog)\n        # one entry for each mode\n        assert len(res.samples[0]) == 2\n        # the same samples can also be found in the regrefs\n        assert [r.val for r in prog.register] == res.samples[0].tolist()\n        # first mode was measured\n        if eng.backend_name == \'tf\':\n            assert isinstance(res.samples[0][0], tf.Tensor)\n        else:\n            assert isinstance(res.samples[0], (numbers.Number, np.ndarray))\n        # second mode was not measured\n        assert res.samples[0][1] is None\n\n    # TODO: Some of these tests should probably check *something* after execution\n\n    def test_measured_parameter(self, setup_eng):\n        """"""Test that a circuit with measured parameters executes successfully.""""""\n        eng, prog = setup_eng(2)\n\n        with prog.context as q:\n            ops.MeasureX | q[0]\n            ops.Sgate(q[0].par) | q[1]\n            # symbolic hermitian conjugate together with register reference\n            ops.Dgate(q[0].par).H | q[1]\n            # algebraic transformation\n            ops.Sgate(q[0].par ** 2) | q[1]\n            # algebraic transformation and h.c.\n            ops.Dgate(-q[0].par).H | q[1]\n\n        eng.run(prog)\n\n    def test_homodyne_measurement_vacuum(self, setup_eng, tol):\n        """"""MeasureX and MeasureP leave the mode in the vacuum state""""""\n        eng, prog = setup_eng(2)\n        with prog.context as q:\n            ops.Coherent(a, c) | q[0]\n            ops.Coherent(b, c) | q[1]\n            ops.MeasureX | q[0]\n            ops.MeasureP | q[1]\n\n        eng.run(prog)\n        assert np.all(eng.backend.is_vacuum(tol))\n\n    def test_homodyne_measurement_vacuum_phi(self, setup_eng, tol):\n        """"""Homodyne measurements leave the mode in the vacuum state""""""\n        eng, prog = setup_eng(2)\n        with prog.context as q:\n            ops.Coherent(a, b) | q[0]\n            ops.MeasureHomodyne(c) | q[0]\n\n        eng.run(prog)\n        assert np.all(eng.backend.is_vacuum(tol))\n\n    def test_program_subroutine(self, setup_eng, tol):\n        """"""Simple quantum program with a subroutine and references.""""""\n        eng, prog = setup_eng(2)\n\n        # define some gates\n        D = ops.Dgate(0.5)\n        BS = ops.BSgate(0.7 * np.pi, np.pi / 2)\n        R = ops.Rgate(np.pi / 3)\n\n        def subroutine(a, b):\n            """"""Subroutine for the quantum program""""""\n            R | a\n            BS | (a, b)\n            R.H | a\n\n        # main program\n        with prog.context as q:\n            # get register references\n            alice, bob = q\n            ops.All(ops.Vacuum()) | (alice, bob)\n            D | alice\n            subroutine(alice, bob)\n            BS | (alice, bob)\n            subroutine(bob, alice)\n\n        state = eng.run(prog).state\n\n        # state norm must be invariant\n        if isinstance(eng.backend, BaseFock):\n            assert np.allclose(state.trace(), 1, atol=tol, rtol=0)\n\n    def test_subsystems(self, setup_eng, tol):\n        """"""Check that the backend keeps in sync with the program when creating and deleting modes.""""""\n        null = sf.Program(2)  # empty program\n        eng, prog = setup_eng(2)\n\n        # define some gates\n        D = ops.Dgate(0.5)\n        BS = ops.BSgate(2 * np.pi, np.pi / 2)\n        R = ops.Rgate(np.pi)\n\n        with prog.context as q:\n            alice, bob = q\n            D | alice\n            BS | (alice, bob)\n            ops.Del | alice\n            R | bob\n            charlie, = ops.New(1)\n            BS | (bob, charlie)\n            ops.MeasureX | bob\n            ops.Del | bob\n            D.H | charlie\n            ops.MeasureX | charlie\n\n        def check_reg(p, expected_n=None):\n            """"""Compare Program.register with the mode list returned by the backend.\n            They should always be in agreement after Engine.run() and Engine.reset().\n            """"""\n            rr = p.register\n            modes = eng.backend.get_modes()\n            # number of elements\n            assert len(rr) == len(modes)\n\n            if expected_n is not None:\n                assert len(rr) == expected_n\n\n            # check indices match\n            assert np.all([r.ind for r in rr] == modes)\n            # activity\n            assert np.all([r.active for r in rr])\n\n        state = eng.run(null)\n        check_reg(null, 2)\n        state = eng.run(prog).state\n        check_reg(prog, 1)\n\n        # state norm must be invariant\n        if isinstance(eng.backend, BaseFock):\n            assert np.allclose(state.trace(), 1, atol=tol, rtol=0)\n\n        # check that reset() works\n        eng.reset()\n        # the regrefs are reset as well\n        assert np.all([r.val is None for r in prog.register])\n\n    def test_empty_program(self, setup_eng):\n        """"""Empty programs do not change the state of the backend.""""""\n        eng, p1 = setup_eng(2)\n        a = 0.23\n        r = 0.1\n        with p1.context as q:\n            ops.Dgate(a) | q[0]\n            ops.Sgate(r) | q[1]\n        state1 = eng.run(p1).state\n\n        # empty program\n        p2 = sf.Program(p1)\n        state2 = eng.run(p2).state\n        assert state1 == state2\n\n        p3 = sf.Program(p2)\n        with p3.context as q:\n            ops.Rgate(r) | q[0]\n        state3 = eng.run(p3).state\n        assert not state1 == state3\n\n        state4 = eng.run(p2).state\n        assert state3 == state4\n\n    # TODO: when ``shots`` is incorporated into other backends, unmark this test\n    @pytest.mark.backends(""gaussian"")\n    def test_measurefock_shots(self, setup_eng):\n        """"""Tests that passing shots with a program containing MeasureFock\n           returns a result whose entries have the right shapes and values""""""\n        shots = 5\n        expected = np.zeros(dtype=int, shape=(shots,))\n\n        # all modes\n        eng, p1 = setup_eng(3)\n        with p1.context as q:\n            ops.MeasureFock() | q\n        samples = eng.run(p1, shots=shots).samples.astype(int)\n        assert samples.shape == (shots, 3)\n        assert all(samples[:, 0] == expected)\n        assert all(samples[:, 1] == expected)\n        assert all(samples[:, 2] == expected)\n\n        # some modes\n        eng, p2 = setup_eng(3)\n        with p2.context as q:\n            ops.MeasureFock() | (q[0], q[2])\n        samples = eng.run(p2, shots=shots).samples\n        assert samples.shape == (shots, 3)\n        assert all(samples[:, 0].astype(int) == expected)\n        assert all(s is None for s in samples[:, 1])\n        assert all(samples[:, 2].astype(int) == expected)\n\n        # one mode\n        eng, p3 = setup_eng(3)\n        with p3.context as q:\n            ops.MeasureFock() | q[0]\n        samples = eng.run(p3, shots=shots).samples\n        assert samples.shape == (shots, 3)\n        assert all(samples[:, 0].astype(int) == expected)\n        assert all(s is None for s in samples[:, 1])\n        assert all(s is None for s in samples[:, 2])\n\n    # TODO: when ``shots`` is incorporated into other backends, delete this test\n    @pytest.mark.skipif(batched, reason=""Test only runs for non-batched backends"")\n    @pytest.mark.backends(""tf"", ""fock"")\n    def test_measurefock_shots_exception(self, setup_eng):\n        shots = 5\n        eng, p1 = setup_eng(3)\n        with p1.context as q:\n            ops.MeasureFock() | q\n\n        backend_name = eng.backend.__str__()\n        with pytest.raises(NotImplementedError,\n                            match=r""""""(Measure|MeasureFock) has not been implemented in {} """"""\n                            """"""for the arguments {{\'shots\': {}}}"""""".format(backend_name, shots)):\n            eng.run(p1, shots=shots).samples\n'"
tests/integration/test_hbar_integration.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Integration tests to make sure hbar values are set correctly in returned results""""""\nimport pytest\n\nimport numpy as np\n\nimport strawberryfields as sf\nfrom strawberryfields import ops\n\n\nN_MEAS = 200\nNUM_STDS = 10.0\nSTD_10 = NUM_STDS / np.sqrt(N_MEAS)\n\nR = 0.3\nX = 0.2\nP = 0.1\nHBAR = [0.5, 1]\n\n\n@pytest.mark.parametrize(""hbar"", HBAR, indirect=True)\nclass TestIntegration:\n    """"""Tests that go through the frontend and backend, and state object""""""\n\n    def test_squeeze_variance_frontend(self, setup_eng, hbar, tol):\n        """"""test homodyne measurement of a squeeze state is correct,\n        returning a variance of np.exp(-2*r)*h/2, via the frontend""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Sgate(R) | q\n            ops.MeasureX | q\n\n        res = np.empty(0)\n\n        for i in range(N_MEAS):\n            eng.run(prog)\n            res = np.append(res, q[0].val)\n            eng.reset()\n\n        assert np.allclose(\n            np.var(res), np.exp(-2 * R) * hbar / 2, atol=STD_10 + tol, rtol=0\n        )\n\n    @pytest.mark.backends(""gaussian"")\n    def test_x_displacement(self, setup_eng, hbar, tol):\n        """"""test x displacement on the Gaussian backend gives correct displacement""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Xgate(X) | q\n\n        state = eng.run(prog).state\n        mu_x = state.means()[0]\n\n        assert state.hbar == hbar\n        assert np.allclose(mu_x, X, atol=tol, rtol=0)\n\n    @pytest.mark.backends(""gaussian"")\n    def test_z_displacement(self, setup_eng, hbar, tol):\n        """"""test x displacement on the Gaussian backend gives correct displacement""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Zgate(P) | q\n\n        state = eng.run(prog).state\n        mu_z = state.means()[1]\n\n        assert state.hbar == hbar\n        assert np.allclose(mu_z, P, atol=tol, rtol=0)\n\n\n@pytest.mark.parametrize(""hbar"", HBAR, indirect=True)\nclass BackendOnly:\n    """"""Tests that ignore the frontend. This test is currently not run.""""""\n\n    def test_squeeze_variance(self, setup_backend, hbar, pure, monkeypatch, tol):\n        """"""test homodyne measurement of a squeeze state is correct,\n        returning a variance of np.exp(-2*r)*h/2""""""\n        # TODO: this test is a backend test that duplicates\n        # the existing `test_squeeze_variance` integration test.\n        # It should live in the backend folder, but currently takes too\n        # long to run both.\n        # We should revisit this test and decide what to do with it.\n        backend = setup_backend(1)\n\n        res = np.empty(0)\n\n        for i in range(N_MEAS):\n            backend.squeeze(R, mode=0)\n            backend.reset(pure=pure)\n            x = backend.measure_homodyne(phi=0, mode=0)\n            res = np.append(res, x)\n\n        assert np.allclose(\n            np.var(res), np.exp(-2 * R) * hbar / 2, atol=STD_10 + tol, rtol=0\n        )\n'"
tests/integration/test_measurement_integration.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Integration tests for frontend measurement""""""\nimport pytest\n\nimport numpy as np\n\nfrom strawberryfields import ops\n\n\nclass TestMeasurement:\n    """"""Test that measurements work correctly from the frontend""""""\n\n    @pytest.mark.backends(""fock"", ""tf"")\n    def test_fock_measurement(self, setup_eng, tol):\n        """"""Test Fock measurements return expected results""""""\n        eng, prog = setup_eng(2)\n        n = [2, 1]\n\n        with prog.context as q:\n            ops.Fock(n[0]) | q[0]\n            ops.Fock(n[1]) | q[1]\n            ops.MeasureFock() | q\n\n        eng.run(prog)\n        assert np.all(q[0].val == n[0])\n        assert np.all(q[1].val == n[1])\n\n        # Fock measurements put the modes into vacuum state\n        assert np.all(eng.backend.is_vacuum(tol))\n\n    @pytest.mark.backends(""gaussian"")\n    def test_heterodyne(self, setup_eng, tol):\n        """"""Test Fock measurements return expected results""""""\n        eng, prog = setup_eng(2)\n        a = [0.43 - 0.12j, 0.02 + 0.2j]\n\n        with prog.context as q:\n            ops.Coherent(a[0]) | q[0]\n            ops.Coherent(a[1]) | q[1]\n            ops.MeasureHD | q[0]\n            ops.MeasureHD | q[1]\n\n        eng.run(prog)\n\n        # Heterodyne measurements put the modes into vacuum state\n        assert eng.backend.is_vacuum(tol)\n\n\nclass TestPostselection:\n    """"""Measurement tests that include post-selection""""""\n\n    def test_homodyne(self, setup_eng, tol):\n        """"""Test that homodyne detection on a TMS state\n        returns post-selected value.""""""\n        x = 0.2\n        r = 5\n\n        eng, prog = setup_eng(2)\n\n        with prog.context as q:\n            ops.S2gate(r) | q\n            ops.MeasureHomodyne(0, select=x) | q[0]\n\n        eng.run(prog)\n        assert np.allclose(q[0].val, x, atol=tol, rtol=0)\n\n    @pytest.mark.backends(""gaussian"")\n    def test_heterodyne(self, setup_eng, tol):\n        """"""Test that heterodyne detection on a TMS state\n        returns post-selected value.""""""\n        alpha = 0.43 - 0.12j\n        r = 5\n\n        eng, prog = setup_eng(2)\n\n        with prog.context as q:\n            ops.S2gate(r) | q\n            ops.MeasureHeterodyne(select=alpha) | q[0]\n\n        eng.run(prog)\n        assert np.allclose(q[0].val, alpha, atol=tol, rtol=0)\n\n    @pytest.mark.backends(""fock"", ""tf"")\n    def test_measure_fock(self, setup_eng, cutoff, batch_size):\n        """"""Test that Fock post-selection on Fock states\n        exiting one arm of a beamsplitter results in conservation\n        of photon number in the other. """"""\n        total_photons = cutoff - 1\n        for n in range(cutoff):\n            eng, prog = setup_eng(2)\n            with prog.context as q:\n                ops.Fock(n) | q[0]\n                ops.Fock(total_photons - n) | q[1]\n                ops.BSgate() | q\n                ops.MeasureFock(select=n // 2) | q[0]\n                ops.MeasureFock() | q[1]\n\n            eng.run(prog)  # FIXME measurements above commute, but they should not since the postselection may fail if the other one is performed first!\n            photons_out = sum([i.val for i in q])\n\n            if batch_size is not None:\n                assert np.all(photons_out == np.tile(total_photons, batch_size))\n            else:\n                assert np.all(photons_out == total_photons)\n\n    @pytest.mark.backends(""gaussian"")\n    def test_embed_graph(self, setup_eng, hbar):\n        """"""Test that an embedded graph has the right total mean photon number. """"""\n\n        eng, prog = setup_eng(2)\n        A = np.array([[0.0, 1.0], [1.0, 0.0]])\n        n_mean_per_mode = 1\n        with prog.context as q:\n            ops.GraphEmbed(A, n_mean_per_mode) | (q[0], q[1])\n\n        state = eng.run(prog).state\n        cov = state.cov()\n        n_mean_tot = np.trace(cov / (hbar / 2) - np.identity(4)) / 4\n        expected = 2 * n_mean_per_mode\n        assert np.allclose(n_mean_tot, expected)\n\n\n    @pytest.mark.backends(""gaussian"")\n    def test_coherent_state_has_photons(self, setup_eng, hbar):\n        """"""Test that a coherent state with a mean photon number of 4 and sampled 100 times will produce photons""""""\n        shots = 100\n        eng, prog = setup_eng(1)\n        alpha = 2\n        with prog.context as q:\n            ops.Coherent(alpha) | q[0]\n            ops.MeasureFock() | q[0]\n        state = eng.run(prog).state\n        samples = np.array(eng.run(prog, shots=shots)).flatten()\n\n        assert not np.all(samples == np.zeros_like(samples, dtype=int))\n\n\nclass TestDarkCounts:\n    @pytest.mark.backends(""fock"")\n    @pytest.mark.parametrize(""dark_counts"", [[4, 2], [3, 0], [0, 6]])\n    def test_fock_darkcounts_two_modes(self, dark_counts, setup_eng, monkeypatch):\n        """"""Test Fock measurements return expected results with dark counts on all detectors""""""\n        with monkeypatch.context() as m:\n            # add the number of dark counts instead of sampling from a poisson distribution\n            m.setattr(np.random, ""poisson"", lambda dc, shape: dc * np.ones(shape, dtype=int))\n\n            eng, prog = setup_eng(2)\n            n = [2, 1]\n\n            with prog.context as q:\n                ops.Fock(n[0]) | q[0]\n                ops.Fock(n[1]) | q[1]\n                ops.MeasureFock(dark_counts=dark_counts) | q\n\n            eng.run(prog)\n            assert q[0].val == n[0] + dark_counts[0]\n            assert q[1].val == n[1] + dark_counts[1]\n\n    @pytest.mark.backends(""fock"")\n    @pytest.mark.parametrize(""dark_counts"", [[4], 6, 0, [0]])\n    def test_fock_darkcounts_single_mode(self, dark_counts, setup_eng, monkeypatch):\n        """"""Test Fock measurements return expected results with dark counts on one detector""""""\n        with monkeypatch.context() as m:\n            m.setattr(np.random, ""poisson"", lambda dc, shape: dc * np.ones(shape, dtype=int))\n\n            eng, prog = setup_eng(2)\n            n = [2, 1]\n\n            with prog.context as q:\n                ops.Fock(n[0]) | q[0]\n                ops.Fock(n[1]) | q[1]\n                ops.MeasureFock(dark_counts=dark_counts) | q[0]\n                ops.MeasureFock() | q[1]\n\n            eng.run(prog)\n\n            if isinstance(dark_counts, int):\n                dark_counts = [dark_counts]\n\n            assert q[0].val == n[0] + dark_counts[0]\n            assert q[1].val == n[1]\n\n    @pytest.mark.backends(""fock"")\n    @pytest.mark.parametrize(""dark_counts"", [[3], 6, [4, 2, 1]])\n    def test_fock_darkcounts_errors(self, dark_counts, setup_eng):\n        """"""Test Fock measurements errors when applying dark counts to more/less detectors than measured""""""\n\n        eng, prog = setup_eng(2)\n        n = [2, 1]\n\n        with prog.context as q:\n            ops.Fock(n[0]) | q[0]\n            ops.Fock(n[1]) | q[1]\n            ops.MeasureFock(dark_counts=dark_counts) | q\n\n        with pytest.raises(\n                ValueError,\n                match=""The number of dark counts must be equal to the number of measured modes"",\n            ):\n            eng.run(prog)\n\n    @pytest.mark.backends(""fock"")\n    def test_fock_darkcounts_with_postselection(self, setup_eng):\n        """"""Test Fock measurements error when using dark counts together with post-selection""""""\n\n        eng, prog = setup_eng(2)\n        n = [2, 1]\n\n        with prog.context as q:\n            ops.Fock(n[0]) | q[0]\n            ops.Fock(n[1]) | q[1]\n            with pytest.raises(\n                    NotImplementedError,\n                    match=""Post-selection cannot be used together with dark counts"",\n                ):\n                ops.MeasureFock(select=1, dark_counts=2) | q\n'"
tests/integration/test_ops_integration.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Integration tests for frontend operations applied to the backend""""""\nimport pytest\n\nimport numpy as np\n\nimport strawberryfields as sf\nfrom strawberryfields import ops\n\nfrom strawberryfields.backends import BaseGaussian\nfrom strawberryfields.backends.states import BaseFockState\nfrom strawberryfields.backends.gaussianbackend import GaussianState\n\n\n# make test deterministic\nnp.random.seed(42)\nA = 0.1234\nB = -0.543\n\n\n@pytest.mark.parametrize(""gate"", ops.gates)\nclass TestGateApplication:\n    """"""tests that involve gate application""""""\n\n    @pytest.fixture\n    def G(self, gate):\n        """"""Initialize each gate""""""\n        if gate in ops.zero_args_gates:\n            return gate()\n\n        if gate in ops.one_args_gates:\n            return gate(A)\n\n        if gate in ops.two_args_gates:\n            return gate(A, B)\n\n    def test_gate_dagger_vacuum(self, G, setup_eng, tol):\n        """"""Test applying gate inverses after the gate cancels out""""""\n        eng, prog = setup_eng(2)\n\n        if isinstance(G, (ops.Vgate, ops.Kgate, ops.CKgate)) and\\\n           isinstance(eng.backend, BaseGaussian):\n            pytest.skip(""Non-Gaussian gates cannot be applied to the Gaussian backend"")\n\n        with prog.context as q:\n            if G.ns == 1:\n                G | q[0]\n                G.H | q[0]\n            elif G.ns == 2:\n                G | (q[0], q[1])\n                G.H | (q[0], q[1])\n\n        eng.run(prog)\n\n        # we must end up back in vacuum since G and G.H cancel each other\n        assert np.all(eng.backend.is_vacuum(tol))\n\n\nclass TestChannelApplication:\n    """"""tests that involve channel application""""""\n\n    def test_loss_channel(self, setup_eng, tol):\n        """"""Test loss channel with no transmission produces vacuum""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Dgate(A) | q[0]\n            ops.LossChannel(0) | q[0]\n\n        eng.run(prog)\n        assert np.all(eng.backend.is_vacuum(tol))\n\n    @pytest.mark.backends(""gaussian"")\n    def test_thermal_loss_channel(self, setup_eng, tol):\n        """"""Test thermal loss channel with no transmission produces thermal state""""""\n        eng, prog = setup_eng(1)\n        nbar = 0.43\n\n        with prog.context as q:\n            ops.Dgate(A) | q[0]\n            ops.ThermalLossChannel(0, nbar) | q[0]\n\n        state = eng.run(prog).state\n        mean_photon, var = state.mean_photon(0)\n        assert np.allclose(mean_photon, nbar, atol=tol, rtol=0)\n        assert np.allclose(var, nbar ** 2 + nbar, atol=tol, rtol=0)\n\n\nclass TestPreparationApplication:\n    """"""Tests that involve state preparation application""""""\n\n    @pytest.mark.backends(""tf"", ""fock"")\n    def test_ket_state_object(self, setup_eng, pure):\n        """"""Test loading a ket from a prior state object""""""\n        if not pure:\n            pytest.skip(""Test only runs on pure states"")\n\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Dgate(0.2) | q[0]\n\n        state1 = eng.run(prog).state\n\n        # create new engine\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Ket(state1) | q[0]\n\n        state2 = eng.run(prog).state\n\n        # verify it is the same state\n        assert state1 == state2\n\n    @pytest.mark.backends(""tf"", ""fock"")\n    def test_ket_gaussian_state_object(self, setup_eng):\n        """"""Test exception if loading a ket from a Gaussian state object""""""\n        eng = sf.Engine(\'gaussian\')\n        prog = sf.Program(1)\n        state = eng.run(prog).state\n\n        # create new engine\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            with pytest.raises(ValueError, match=""Gaussian states are not supported""):\n                ops.Ket(state) | q[0]\n\n    @pytest.mark.backends(""tf"", ""fock"")\n    def test_ket_mixed_state_object(self, setup_eng, pure):\n        """"""Test exception if loading a ket from a prior mixed state object""""""\n        if pure:\n            pytest.skip(""Test only runs on mixed states"")\n\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Dgate(0.2) | q[0]\n\n        state1 = eng.run(prog).state\n\n        # create new engine\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            with pytest.raises(ValueError, match=""Fock state is not pure""):\n                ops.Ket(state1) | q[0]\n\n    @pytest.mark.backends(""tf"", ""fock"")\n    def test_dm_state_object(self, setup_eng, tol):\n        """"""Test loading a density matrix from a prior state object""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Dgate(0.2) | q[0]\n\n        state1 = eng.run(prog).state\n\n        # create new engine\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.DensityMatrix(state1) | q[0]\n\n        state2 = eng.run(prog).state\n\n        # verify it is the same state\n        assert np.allclose(state1.dm(), state2.dm(), atol=tol, rtol=0)\n\n    @pytest.mark.backends(""tf"", ""fock"")\n    def test_dm_gaussian_state_object(self, setup_eng):\n        """"""Test exception if loading a ket from a Gaussian state object""""""\n        eng = sf.Engine(\'gaussian\')\n        prog = sf.Program(1)\n        state = eng.run(prog).state\n\n        # create new engine\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            with pytest.raises(ValueError, match=""Gaussian states are not supported""):\n                ops.DensityMatrix(state) | q[0]\n\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestKetDensityMatrixIntegration:\n    """"""Tests for the frontend Fock multi-mode state preparations""""""\n\n    def test_ket_input_validation(self, setup_eng, hbar, cutoff):\n        """"""Test exceptions""""""\n        mu = np.array([0.0, 0.0])\n        cov = np.identity(2)\n        state1 = GaussianState((mu, cov), 1, None, None)\n        state2 = BaseFockState(np.zeros(cutoff), 1, False, cutoff)\n\n        eng, prog = setup_eng(2)\n\n        with prog.context as q:\n            with pytest.raises(ValueError, match=""Gaussian states are not supported""):\n                ops.Ket(state1) | q[0]\n            with pytest.raises(ValueError, match=""not pure""):\n                ops.Ket(state2) | q[0]\n\n    def test_ket_one_mode(self, setup_eng, hbar, cutoff, tol):\n        """"""Tests single mode ket preparation""""""\n        eng, prog = setup_eng(2)\n        ket0 = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(-1, 1, cutoff)\n        ket0 = ket0 / np.linalg.norm(ket0)\n        with prog.context as q:\n            ops.Ket(ket0) | q[0]\n        state = eng.run(prog, **{\'modes\': [0]}).state\n        assert np.allclose(state.dm(), np.outer(ket0, ket0.conj()), atol=tol, rtol=0)\n\n        eng.reset()\n\n        prog = sf.Program(2)\n        state1 = BaseFockState(ket0, 1, True, cutoff)\n        with prog.context as q:\n            ops.Ket(state1) | q[0]\n        state2 = eng.run(prog, **{\'modes\': [0]}).state\n        assert np.allclose(state1.dm(), state2.dm(), atol=tol, rtol=0)\n\n    def test_ket_two_mode(self, setup_eng, hbar, cutoff, tol):\n        """"""Tests multimode ket preparation""""""\n        eng, prog = setup_eng(2)\n        ket0 = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(-1, 1, cutoff)\n        ket0 = ket0 / np.linalg.norm(ket0)\n        ket1 = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(-1, 1, cutoff)\n        ket1 = ket1 / np.linalg.norm(ket1)\n\n        ket = np.outer(ket0, ket1)\n        with prog.context as q:\n            ops.Ket(ket) | q\n        state = eng.run(prog).state\n        assert np.allclose(\n            state.dm(), np.einsum(""ij,kl->ikjl"", ket, ket.conj()), atol=tol, rtol=0\n        )\n\n        eng.reset()\n\n        prog = sf.Program(2)\n        state1 = BaseFockState(ket, 2, True, cutoff)\n        with prog.context as q:\n            ops.Ket(state1) | q\n        state2 = eng.run(prog).state\n        assert np.allclose(state1.dm(), state2.dm(), atol=tol, rtol=0)\n\n    def test_dm_input_validation(self, setup_eng, hbar, cutoff, tol):\n        """"""Test exceptions""""""\n        mu = np.array([0.0, 0.0])\n        cov = np.identity(2)\n        state = GaussianState((mu, cov), 1, None, None)\n\n        eng, prog = setup_eng(2)\n\n        with prog.context as q:\n            with pytest.raises(ValueError, match=""Gaussian states are not supported""):\n                ops.DensityMatrix(state) | q[0]\n\n    def test_dm_one_mode(self, setup_eng, hbar, cutoff, tol):\n        """"""Tests single mode DM preparation""""""\n        eng, prog = setup_eng(2)\n\n        ket = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(-1, 1, cutoff)\n        ket = ket / np.linalg.norm(ket)\n        rho = np.outer(ket, ket.conj())\n        with prog.context as q:\n            ops.DensityMatrix(rho) | q[0]\n        state = eng.run(prog, **{\'modes\': [0]}).state\n        assert np.allclose(state.dm(), rho, atol=tol, rtol=0)\n\n        eng.reset()\n\n        prog = sf.Program(2)\n        state1 = BaseFockState(rho, 1, False, cutoff)\n        with prog.context as q:\n            ops.DensityMatrix(state1) | q[0]\n        state2 = eng.run(prog, **{\'modes\': [0]}).state\n        assert np.allclose(state1.dm(), state2.dm(), atol=tol, rtol=0)\n\n    def test_dm_two_mode(self, setup_eng, hbar, cutoff, tol):\n        """"""Tests multimode dm preparation""""""\n        eng, prog = setup_eng(2)\n\n        ket0 = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(-1, 1, cutoff)\n        ket0 = ket0 / np.linalg.norm(ket0)\n        ket1 = np.random.uniform(-1, 1, cutoff) + 1j * np.random.uniform(-1, 1, cutoff)\n        ket1 = ket1 / np.linalg.norm(ket1)\n\n        ket = np.outer(ket0, ket1)\n        rho = np.einsum(""ij,kl->ikjl"", ket, ket.conj())\n        with prog.context as q:\n            ops.DensityMatrix(rho) | q\n        state = eng.run(prog).state\n        assert np.allclose(state.dm(), rho, atol=tol, rtol=0)\n\n        eng.reset()\n\n        prog = sf.Program(2)\n        state1 = BaseFockState(rho, 2, False, cutoff)\n        with prog.context as q:\n            ops.DensityMatrix(state1) | q\n        state2 = eng.run(prog).state\n        assert np.allclose(state1.dm(), state2.dm(), atol=tol, rtol=0)\n'"
tests/integration/test_parameters_integration.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Integration tests for the parameters.py module.""""""\n\nimport inspect\nimport itertools\nimport warnings\n\nimport pytest\nimport numpy as np\n\nimport strawberryfields.program_utils as pu\nfrom strawberryfields import ops\nfrom strawberryfields.parameters import ParameterError, par_funcs as pf\n\n\n# ops.Fock requires an integer parameter\nscalar_arg_preparations = (\n    ops.Coherent,\n    ops.Squeezed,\n    ops.DisplacedSqueezed,\n    ops.Thermal,\n    ops.Catstate,\n)\n\n# Operation subclasses to be tested\ntestset = ops.one_args_gates + ops.two_args_gates + ops.channels + scalar_arg_preparations\n\n\n\ndef test_free_parameters(setup_eng, tol):\n    """"""Programs with free parameters.""""""\n\n    eng, prog = setup_eng(1)\n    x = prog.params(\'x\')  # free parameter\n    with prog.context as q:\n        ops.Dgate(x) | q\n        ops.Sgate(-1.2 * x * pf.sin(x**2 - 0.1)) | q\n\n    with pytest.raises(ParameterError, match=""Unknown free parameter""):\n        eng.run(prog, args={\'foo\': 1.0})\n    with pytest.raises(ParameterError, match=""unbound parameter with no default value""):\n        eng.run(prog)\n\n    # successful run\n    eng.run(prog, args={x: 0.0})\n    assert np.all(eng.backend.is_vacuum(tol))\n    eng.reset()\n\n    # now set a default value for the free parameter\n    x.default = 0.0\n    eng.run(prog)\n    assert np.all(eng.backend.is_vacuum(tol))\n    eng.reset()\n\n    # override the default\n    x.default = 1.0\n    eng.run(prog, args={x: 0.0})\n    assert np.all(eng.backend.is_vacuum(tol))\n\n\n@pytest.fixture(scope=""function"")\ndef eng_prog_params(batch_size, setup_eng):\n    """"""Engine and Program instances, and an attached set of Operation parameters.""""""\n    def func1(x):\n        return abs(2 * x ** 2 - 3 * x + 1)\n\n    def func2(x, y):\n        return abs(2 * x * y - y ** 2 + 0.5)\n\n    eng, prog = setup_eng(2)\n    r = prog.register\n\n    # fixed and different types of measured parameters\n    # (note that some Operations expect nonnegative parameter values)\n    params = [0.14, r[0].par, func1(r[0].par), func2(r[0].par, r[1].par)]\n    if batch_size is not None:\n        # test batched input\n        params.append(np.random.uniform(size=(batch_size,)))\n\n    return eng, prog, params\n\n\n@pytest.mark.parametrize(""G"", testset)\ndef test_parameters_with_operations(eng_prog_params, G):\n    """"""Test all combinations of different types of Parameters with different Operation subclasses.\n\n    This test is successful if no exceptions are raised.\n\n    Some operation/backend combinations are forbidden by the CircuitSpecs instance of the backend.\n    We catch these exceptions and convert them into warnings.\n    """"""\n    kwargs = {}\n    eng, prog, params = eng_prog_params\n\n    def check(G, par):\n        """"""Check an Operation/Parameters combination.""""""\n\n        # construct the op using the given tuple of Parameters as args\n        G = G(*par)\n        assert isinstance(G, ops.Operation)\n\n        # clear the program for reuse\n        prog.locked = False\n        prog.circuit = []\n        with prog.context as r:\n            # fake a measurement for speed\n            r[0].val = 0.1\n            r[1].val = 0.2\n            if G.ns == 1:\n                G | r[0]\n            else:\n                G | (r[0], r[1])\n\n        try:\n            eng.run(prog, **kwargs)\n        except pu.CircuitError as err:\n            # record CircuitSpecs-forbidden op/backend combinations here\n            warnings.warn(str(err))\n        eng.reset()\n\n    sig = inspect.signature(G.__init__)\n    n_args = len(sig.parameters) - 1  # number of parameters __init__ takes, minus self\n    assert n_args >= 1\n    # shortcut, only test cartesian products up to two parameter types\n    n_args = min(n_args, 2)\n    # check all combinations of Parameter types\n    for p in itertools.product(params, repeat=n_args):\n        check(G, p)\n'"
tests/integration/test_tf_integration.py,46,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nTests for the various Tensorflow-specific symbolic options of the frontend/backend.\n""""""\n# pylint: disable=expression-not-assigned,too-many-public-methods,pointless-statement,no-self-use\n\nimport pytest\nimport numpy as np\nfrom scipy.special import factorial\n\ntf = pytest.importorskip(""tensorflow"", minversion=""2.0"")\n\nfrom strawberryfields.ops import Dgate, Sgate, MeasureX, Thermal\nimport strawberryfields.parameters\n\n\n# this test file is only supported by the TF backend\npytestmark = pytest.mark.backends(""tf"")\n\n\nALPHA = 0.5\n\n\ndef coherent_state(alpha, cutoff):\n    """"""Returns the Fock representation of the coherent state |alpha> up to dimension given by cutoff""""""\n    n = np.arange(cutoff)\n    return np.exp(-0.5 * np.abs(alpha) ** 2) * alpha ** n / np.sqrt(factorial(n))\n\n\ndef _vac_ket(cutoff):\n    """"""Returns the ket of the vacuum state up to dimension given by cutoff""""""\n    vac = np.zeros(cutoff)\n    vac[0] = 1\n    return vac\n\n\ndef _vac_dm(cutoff):\n    """"""Returns the density matrix of the vacuum state up to dimension given by cutoff""""""\n    vac = _vac_ket(cutoff)\n    return np.outer(vac, np.conj(vac))\n\n\nclass TestOneMode:\n    """"""Tests for workflows on one mode.""""""\n\n    def test_eng_float_parameter_returns_tensor(self, setup_eng):\n        """"""Tests whether eng.run for programs with non-tensor parameters\n        successfully returns a Tensor.""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            Dgate(ALPHA) | q\n\n        state = eng.run(prog).state\n        state_data = state.data\n\n        assert isinstance(state_data, tf.Tensor)\n\n    def test_eng_tensor_parameter_returns_tensor(self, setup_eng):\n        """"""Tests whether eng.run for programs with tensor parameters\n        successfully returns a Tensor.""""""\n        eng, prog = setup_eng(1)\n\n        alpha = prog.params(""alpha"")\n\n        with prog.context as q:\n            Dgate(alpha) | q\n\n        state = eng.run(prog, args={""alpha"": tf.Variable(0.5)}).state\n        state_data = state.data\n\n        assert isinstance(state_data, tf.Tensor)\n\n    def test_eng_run_measurements_are_tensors(self, setup_eng):\n        """"""Tests whether eng.run for programs with measurements\n        successfully returns a tensors for samples.""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            Dgate(ALPHA) | q\n            MeasureX | q\n\n        eng.run(prog)\n        val = q[0].val\n        assert isinstance(val, tf.Tensor)\n\n    def test_eng_run_state_ket(self, setup_eng, cutoff, pure, tol):\n        """"""Tests whether the ket of the returned state is a\n        Tensor object when executed with `eng.run`.""""""\n        if not pure:\n            pytest.skip(""Tested only for pure states"")\n\n        eng, prog = setup_eng(1)\n        with prog.context as q:\n            Dgate(ALPHA) | q\n\n        state = eng.run(prog).state\n        ket = state.ket()\n        assert isinstance(ket, tf.Tensor)\n\n        coh_ket = coherent_state(ALPHA, cutoff)\n        assert np.allclose(ket, coh_ket, atol=tol, rtol=0.0)\n\n    def test_eng_run_state_dm(self, pure, cutoff, setup_eng, tol):\n        """"""Tests whether the density matrix of the returned state is an\n        Tensor object when executed with `eng.run`.""""""\n        if not pure:\n            pytest.skip(""Tested only for pure states"")\n\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            Dgate(ALPHA) | q\n\n        state = eng.run(prog).state\n        dm = state.dm()\n        assert isinstance(dm, tf.Tensor)\n\n        ket = coherent_state(ALPHA, cutoff)\n        coh_dm = np.einsum(""i,j->ij"", ket, ket.conj())\n        assert np.allclose(dm, coh_dm, atol=tol, rtol=0.0)\n\n    def test_eng_run_state_trace(self, setup_eng, tol):\n        """"""Tests whether the trace of the returned state is an\n        Tensor object when executed with `eng.run`.""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            Dgate(ALPHA) | q\n\n        state = eng.run(prog).state\n        tr = state.trace()\n        assert isinstance(tr, tf.Tensor)\n        assert np.allclose(tr, 1, atol=tol, rtol=0.0)\n\n    def test_eng_run_state_reduced_dm(self, setup_eng, cutoff, tol):\n        """"""Tests whether the reduced_density matrix of the returned state\n        is a Tensor object when executed with `eng.run`.""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            Dgate(ALPHA) | q\n\n        state = eng.run(prog).state\n        rho = state.reduced_dm([0])\n        assert isinstance(rho, tf.Tensor)\n\n        ket = coherent_state(ALPHA, cutoff)\n        coh_dm = np.einsum(""i,j->ij"", ket, ket.conj())\n        assert np.allclose(rho, coh_dm, atol=tol, rtol=0.0)\n\n    def test_eng_run_state_fidelity_vacuum(self, setup_eng, tol):\n        """"""Tests whether the fidelity_vacuum method of the state returns an\n        Tensor object when executed with `eng.run`.""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            Dgate(0) | q\n\n        state = eng.run(prog).state\n        fidel_vac = state.fidelity_vacuum()\n        assert isinstance(fidel_vac, tf.Tensor)\n        assert np.allclose(fidel_vac, 1.0, atol=tol, rtol=0.0)\n\n    def test_eng_run_state_is_vacuum(self, setup_eng):\n        """"""Tests whether the is_vacuum method of the state returns an\n        Tensor object when executed with `eng.run`.""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            Dgate(0) | q\n\n        state = eng.run(prog).state\n        is_vac = state.is_vacuum()\n        assert isinstance(is_vac, tf.Tensor)\n        assert np.all(is_vac)\n\n    def test_eng_run_state_fidelity_coherent(self, setup_eng, tol):\n        """"""Tests whether the fidelity of the state with respect to coherent states is\n        a Tensor object when executed with `eng.run`.""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            Dgate(ALPHA) | q\n\n        state = eng.run(prog).state\n        fidel_coh = state.fidelity_coherent([ALPHA])\n        assert isinstance(fidel_coh, tf.Tensor)\n        assert np.allclose(fidel_coh, 1, atol=tol, rtol=0.0)\n\n    def test_eng_run_state_fidelity(self, setup_eng, cutoff, tol):\n        """"""Tests whether the fidelity of the state with respect to a local state is an\n        Tensor object when executed with `eng.run`.""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            Dgate(ALPHA) | q\n\n        state = eng.run(prog).state\n        fidel_coh = state.fidelity(coherent_state(ALPHA, cutoff), 0)\n        assert isinstance(fidel_coh, tf.Tensor)\n        assert np.allclose(fidel_coh, 1, atol=tol, rtol=0.0)\n\n    def test_eng_run_state_quad_expectation(self, setup_eng, tol, hbar):\n        """"""Tests whether the local quadrature expectation of the state is\n        Tensor object when executed with `eng.run`.""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            Dgate(ALPHA) | q\n\n        state = eng.run(prog).state\n        e, v = state.quad_expectation(0, 0)\n        assert isinstance(e, tf.Tensor)\n        assert isinstance(v, tf.Tensor)\n\n        true_exp = np.sqrt(hbar / 2.0) * (ALPHA + np.conj(ALPHA))\n        true_var = hbar / 2.0\n        assert np.allclose(e, true_exp, atol=tol, rtol=0.0)\n        assert np.allclose(v, true_var, atol=tol, rtol=0.0)\n\n    def test_eng_run_state_mean_photon(self, setup_eng, tol):\n        """"""Tests whether the local mean photon number of the state is\n        Tensor object when executed with `eng.run`.""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            Dgate(ALPHA) | q\n\n        state = eng.run(prog).state\n        nbar, var = state.mean_photon(0)\n        assert isinstance(nbar, tf.Tensor)\n        assert isinstance(var, tf.Tensor)\n\n        ref_nbar = np.abs(ALPHA) ** 2\n        ref_var = np.abs(ALPHA) ** 2\n        assert np.allclose(nbar, ref_nbar, atol=tol, rtol=0.0)\n        assert np.allclose(var, ref_var, atol=tol, rtol=0.0)\n\n\nclass TestTwoModeSymbolic:\n    """"""Tests for workflows on two modes.""""""\n\n    def test_eval_true_state_all_fock_probs(self, setup_eng, cutoff, batch_size, tol):\n        """"""Tests whether the Fock-basis probabilities of the state return\n        a Tensor with the correct value.""""""\n        eng, prog = setup_eng(2)\n\n        with prog.context as q:\n            Dgate(ALPHA) | q[0]\n            Dgate(-ALPHA) | q[1]\n\n        state = eng.run(prog).state\n        probs = state.all_fock_probs()\n\n        assert isinstance(probs, tf.Tensor)\n\n        probs = probs.numpy().flatten()\n        ref_probs = (\n            np.abs(\n                np.outer(coherent_state(ALPHA, cutoff), coherent_state(-ALPHA, cutoff))\n            ).flatten()\n            ** 2\n        )\n\n        if batch_size is not None:\n            ref_probs = np.tile(ref_probs, batch_size)\n\n        assert np.allclose(probs, ref_probs, atol=tol, rtol=0.0)\n\n    def test_eval_true_state_fock_prob(self, setup_eng, cutoff, tol):\n        """"""Tests whether the probability of a Fock measurement outcome on the state returns\n         a tensor with the correct value.""""""\n        n1 = cutoff // 2\n        n2 = cutoff // 3\n\n        eng, prog = setup_eng(2)\n\n        with prog.context as q:\n            Dgate(ALPHA) | q[0]\n            Dgate(-ALPHA) | q[1]\n\n        state = eng.run(prog).state\n        prob = state.fock_prob([n1, n2])\n        assert isinstance(prob, tf.Tensor)\n\n        ref_prob = np.abs(\n            np.outer(coherent_state(ALPHA, cutoff), coherent_state(-ALPHA, cutoff)) ** 2\n        )[n1, n2]\n        assert np.allclose(prob, ref_prob, atol=tol, rtol=0.0)\n\n\nclass TestGradient:\n    """"""Integration tests for the gradient computation""""""\n\n    def test_displacement_mean_photon_gradient(self, setup_eng, tol, batch_size):\n        """"""Tests whether the gradient for the mean photon variance\n        on a displaced state is correct.""""""\n        if batch_size is not None:\n            pytest.skip(\n                ""Cannot calculate gradient in batch mode, as tape.gradient ""\n                ""cannot differentiate non-scalar output.""\n            )\n\n        eng, prog = setup_eng(1)\n\n        alpha = prog.params(""alpha"")\n\n        with prog.context as q:\n            Dgate(alpha) | q\n\n        a = tf.Variable(ALPHA)\n\n        with tf.GradientTape() as tape:\n            state = eng.run(prog, args={""alpha"": a}).state\n            mean, var = state.mean_photon(0)\n\n        # test the mean and variance of the photon number is correct\n        assert np.allclose(mean, ALPHA ** 2, atol=tol, rtol=0)\n        assert np.allclose(var, ALPHA ** 2, atol=tol, rtol=0)\n\n        # test the gradient of the variance is correct\n        grad = tape.gradient(var, [a])\n        assert np.allclose(grad, 2 * ALPHA, atol=tol, rtol=0)\n\n    def test_displaced_thermal_mean_photon_gradient(self, setup_eng, tol, batch_size):\n        """"""Tests whether the gradient for the mean photon variance\n        on a displaced thermal state is correct:\n\n        E(n)=|a|^2+nbar and var(n)=var_th+|a|^2(1+2nbar)\n        """"""\n        if batch_size is not None:\n            pytest.skip(\n                ""Cannot calculate gradient in batch mode, as tape.gradient ""\n                ""cannot differentiate non-scalar output.""\n            )\n\n        eng, prog = setup_eng(1)\n\n        alpha = prog.params(""alpha"")\n        nbar = prog.params(""nbar"")\n\n        with prog.context as q:\n            Thermal(nbar) | q\n            Dgate(alpha) | q\n\n        a = tf.Variable(0.2)\n        n = tf.Variable(0.052)\n\n        with tf.GradientTape() as tape:\n            state = eng.run(prog, args={""nbar"": n, ""alpha"": a}).state\n            mean, var = state.mean_photon(0)\n\n        # test the mean and variance of the photon number is correct\n        mean_ex = a ** 2 + n\n        var_ex = n ** 2 + n + a ** 2 * (1 + 2 * n)\n        assert np.allclose(mean, mean_ex, atol=tol, rtol=0)\n        assert np.allclose(var, var_ex, atol=tol, rtol=0)\n\n        # test the gradient of the variance is correct\n        grad = tape.gradient(var, [a, n])\n        grad_ex = [2 * a * (1 + 2 * n), 2 * n + 1 + 2 * a ** 2]\n        assert np.allclose(grad, grad_ex, atol=tol, rtol=0)\n\n    def test_coherent_ket_gradient(self, setup_eng, cutoff, tol, pure, batch_size):\n        """"""Test whether the gradient of the third element (|2>) of the coherent\n        state vector is correct.""""""\n        if not pure:\n            pytest.skip(""Test skipped in mixed state mode"")\n\n        if batch_size is not None:\n            pytest.skip(\n                ""Cannot calculate gradient in batch mode, as tape.gradient ""\n                ""cannot differentiate non-scalar output.""\n            )\n\n        eng, prog = setup_eng(1)\n\n        alpha = prog.params(""alpha"")\n\n        with prog.context as q:\n            Dgate(alpha) | q\n\n        a = tf.Variable(ALPHA)\n\n        with tf.GradientTape() as tape:\n            state = eng.run(prog, args={""alpha"": a}).state\n            res = tf.cast(state.ket()[2], dtype=tf.float64)\n\n        res_ex = np.exp(-0.5 * a ** 2) * a ** 2 / np.sqrt(2)\n        assert np.allclose(res, res_ex, atol=tol, rtol=0)\n\n        grad = tape.gradient(res, [a])\n        grad_ex = -a * (a ** 2 - 2) * np.exp(-(a ** 2) / 2) / np.sqrt(2)\n        assert np.allclose(grad, grad_ex, atol=tol, rtol=0)\n\n    def test_coherent_dm_gradient(self, setup_eng, cutoff, tol, batch_size):\n        """"""Test whether the gradient of the 3, 3 element of the coherent\n        density matrix is correct.""""""\n        if batch_size is not None:\n            pytest.skip(\n                ""Cannot calculate gradient in batch mode, as tape.gradient ""\n                ""cannot differentiate non-scalar output.""\n            )\n\n        eng, prog = setup_eng(1)\n\n        alpha = prog.params(""alpha"")\n\n        with prog.context as q:\n            Dgate(alpha) | q\n\n        a = tf.Variable(ALPHA)\n\n        with tf.GradientTape() as tape:\n            state = eng.run(prog, args={""alpha"": a}).state\n            res = tf.cast(state.dm()[2, 2], dtype=tf.float64)\n\n        res_ex = (np.exp(-0.5 * a ** 2) * a ** 2 / np.sqrt(2)) ** 2\n        assert np.allclose(res, res_ex, atol=tol, rtol=0)\n\n        grad = tape.gradient(res, [a])\n        grad_ex = -(a ** 3) * (a ** 2 - 2) * np.exp(-(a ** 2))\n        assert np.allclose(grad, grad_ex, atol=tol, rtol=0)\n\n    def test_displaced_squeezed_mean_photon_gradient(self, setup_eng, cutoff, tol, batch_size):\n        """"""Test whether the gradient of the mean photon number of a displaced squeezed\n        state is correct.\n\n        .. note::\n\n            As this test contains multiple gates being applied to the program,\n            this test will fail in TensorFlow 2.1 due to the bug discussed in\n            https://github.com/tensorflow/tensorflow/issues/37307, if `tf.einsum` is being used\n            in ``tfbackend/ops.py`` rather than _einsum_v1.\n        """"""\n        if batch_size is not None:\n            pytest.skip(\n                ""Cannot calculate gradient in batch mode, as tape.gradient ""\n                ""cannot differentiate non-scalar output.""\n            )\n\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            Sgate(prog.params(""r""), prog.params(""phi"")) | q\n            Dgate(prog.params(""a"")) | q\n\n        a = tf.Variable(ALPHA)\n        r = tf.Variable(0.105)\n        phi = tf.Variable(0.123)\n\n        with tf.GradientTape() as tape:\n            state = eng.run(prog, args={""a"": a, ""r"": r, ""phi"": phi}).state\n            mean, _ = state.mean_photon(0)\n\n        # test the mean and variance of the photon number is correct\n        mean_ex = a ** 2 + tf.sinh(r) ** 2\n        assert np.allclose(mean, mean_ex, atol=tol, rtol=0)\n\n        # test the gradient of the mean is correct\n        grad = tape.gradient(mean, [a, r, phi])\n        grad_ex = [2 * a, 2 * tf.sinh(r) * tf.cosh(r), 0]\n        assert np.allclose(grad, grad_ex, atol=tol, rtol=0)\n\n\n@pytest.mark.xfail(\n    reason=""If this test passes, then the _einsum_v1 patch is no longer needed."",\n    strict=True,\n    raises=AssertionError,\n)\ndef test_einsum_complex_gradients(tol):\n    """"""Integration test to check the complex gradient\n    when using einsum in TensorFlow version 2.1+.\n\n    With TF 2.1+, the legacy tf.einsum was renamed to _einsum_v1, while\n    the replacement tf.einsum introduced a bug; the computed einsum\n    value is correct when applied to complex tensors, but the returned\n    gradient is incorrect. For more details, see\n    https://github.com/tensorflow/tensorflow/issues/37307.\n\n    This test is expected to fail, confirming that the complex einsum\n    gradient bug is still occuring. If this test passes, it means that\n    the bug has been fixed.\n    """"""\n    import sys\n\n    del sys.modules[""tensorflow""]\n    tf = pytest.importorskip(""tensorflow"", minversion=""2.1"")\n\n    # import the legacy einsum implementation\n    from tensorflow.python.ops.special_math_ops import _einsum_v1\n\n    def f0(h):\n        """"""Sum reduction of complex matrix h@h performed using matmul""""""\n        return tf.abs(tf.reduce_sum(tf.matmul(h, h)))\n\n    def f1(h):\n        """"""Sum reduction of complex matrix h@h performed using tf.einsum""""""\n        return tf.abs(tf.reduce_sum(tf.einsum(""ab,bc->ac"", h, h)))\n\n    def f2(h):\n        """"""Sum reduction of complex matrix h@h performed using _einsum_v1""""""\n        return tf.abs(tf.reduce_sum(_einsum_v1(""ab,bc->ac"", h, h)))\n\n    # Create a real 2x2 variable A; this is the variable we will be differentiating\n    # the cost function with respect to.\n    A = tf.Variable([[0.16513085, 0.9014813], [0.6309742, 0.4345461]], dtype=tf.float32)\n\n    # constant complex tensor\n    B = tf.constant([[0.51010704, 0.44353175], [0.4085331, 0.9924923]], dtype=tf.float32)\n\n    grads = []\n\n    for f in (f0, f1, f2):\n        with tf.GradientTape() as tape:\n            # Create a complex tensor C = A + B*1j\n            C = tf.cast(A, dtype=tf.complex64) + 1j * tf.cast(B, dtype=tf.complex64)\n            loss = f(C)\n\n        # compute the gradient\n        grads.append(tape.gradient(loss, A))\n\n    # gradient of f0 and f2 should agree\n    assert np.allclose(grads[0], grads[2], atol=tol, rtol=0)\n\n    # gradient of f0 and f1 should fail\n    assert np.allclose(grads[0], grads[1], atol=tol, rtol=0)\n'"
tests/integration/test_utils_integration.py,8,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Integration tests for the utils.py module""""""\n\n# pylint: disable=pointless-statement,expression-not-assigned,no-self-use\n\nimport pytest\nimport numpy as np\n\ntry:\n    import tensorflow as tf\nexcept (ImportError, ModuleNotFoundError) as e:\n    import mock\n    tf = mock.MagicMock()\n    tf.Tensor = int\n\nimport strawberryfields as sf\nimport strawberryfields.ops as ops\nimport strawberryfields.utils as utils\n\nfrom strawberryfields.backends.fockbackend.ops import squeezing as sq_U\nfrom strawberryfields.backends.fockbackend.ops import displacement as disp_U\nfrom strawberryfields.backends.fockbackend.ops import beamsplitter as bs_U\n\n\nALPHA = np.linspace(-0.15, 0.2, 4) + np.linspace(-0.2, 0.1, 4) * 1j\nR = np.linspace(0, 0.21, 4)\nPHI = np.linspace(0, 1.43, 4)\nnp.random.seed(42)\n\n\n# ===================================================================================\n# Initial states integration tests\n# ===================================================================================\n\n\n@pytest.mark.backends(""gaussian"")\nclass TestInitialStatesAgreeGaussian:\n    """"""Test that the initial state functions in utils match\n    the result returned by the Gaussian backends.""""""\n\n    def test_vacuum(self, setup_eng, hbar, tol):\n        """"""Test vacuum function matches Gaussian backends""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Vac | q[0]\n\n        state = eng.run(prog).state\n\n        mu, cov = utils.vacuum_state(basis=""gaussian"", hbar=hbar)\n        mu_exp, cov_exp = state.reduced_gaussian(0)\n        assert np.allclose(mu, mu_exp, atol=tol, rtol=0)\n        assert np.allclose(cov, cov_exp, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""a"", ALPHA)\n    def test_coherent(self, a, setup_eng, hbar, tol):\n        """"""Test coherent function matches Gaussian backends""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Dgate(a) | q[0]\n\n        state = eng.run(prog).state\n\n        mu, cov = utils.coherent_state(a, basis=""gaussian"", hbar=hbar)\n        mu_exp, cov_exp = state.reduced_gaussian(0)\n        assert np.allclose(mu, mu_exp, atol=tol, rtol=0)\n        assert np.allclose(cov, cov_exp, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""r, phi"", zip(R, PHI))\n    def test_squeezed(self, r, phi, setup_eng, hbar, tol):\n        """"""Test squeezed function matches Gaussian backends""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Sgate(r, phi) | q[0]\n\n        state = eng.run(prog).state\n\n        mu, cov = utils.squeezed_state(r, phi, basis=""gaussian"", hbar=hbar)\n        mu_exp, cov_exp = state.reduced_gaussian(0)\n        assert np.allclose(mu, mu_exp, atol=tol, rtol=0)\n        assert np.allclose(cov, cov_exp, atol=tol, rtol=0)\n\n    @pytest.mark.parametrize(""a, r, phi"", zip(ALPHA, R, PHI))\n    def test_displaced_squeezed(self, a, r, phi, setup_eng, hbar, tol):\n        """"""Test displaced squeezed function matches Gaussian backends""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Sgate(r, phi) | q[0]\n            ops.Dgate(a) | q[0]\n\n        state = eng.run(prog).state\n\n        mu, cov = utils.displaced_squeezed_state(a, r, phi, basis=""gaussian"", hbar=hbar)\n        mu_exp, cov_exp = state.reduced_gaussian(0)\n        assert np.allclose(mu, mu_exp, atol=tol, rtol=0)\n        assert np.allclose(cov, cov_exp, atol=tol, rtol=0)\n\n\n@pytest.fixture\ndef bsize(batch_size):\n    """"""Utility fixture for handling both batched and non-batched modes.""""""\n    return 1 if batch_size is None else batch_size\n\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestInitialStatesAgreeFock:\n    """"""Test that the initial state functions in utils match\n    the result returned by the Fock backends.""""""\n\n    def test_vacuum(self, setup_eng, hbar, cutoff, bsize, pure, tol):\n        """"""Test vacuum function matches Fock backends""""""\n        eng, prog = setup_eng(1)\n\n        with prog.context as q:\n            ops.Vac | q[0]\n\n        state = eng.run(prog).state\n\n        ket = utils.vacuum_state(basis=""fock"", fock_dim=cutoff, hbar=hbar)\n\n        if not pure:\n            expected = state.dm()\n            ket = np.tile(np.outer(ket, ket.conj()), (bsize, 1, 1))\n        else:\n            expected = state.ket()\n            ket = np.tile(ket, (bsize, 1))\n\n        assert np.allclose(expected, ket, atol=tol, rtol=0)\n\n    def test_coherent(self, setup_eng, hbar, cutoff, bsize, pure, tol):\n        """"""Test coherent function matches Fock backends""""""\n        eng, prog = setup_eng(1)\n        a = 0.32 + 0.1j\n\n        with prog.context as q:\n            ops.Dgate(a) | q[0]\n\n        state = eng.run(prog).state\n        ket = utils.coherent_state(a, basis=""fock"", fock_dim=cutoff, hbar=hbar)\n\n        if not pure:\n            expected = state.dm()\n            ket = np.tile(np.outer(ket, ket.conj()), (bsize, 1, 1))\n        else:\n            expected = state.ket()\n            ket = np.tile(ket, (bsize, 1))\n\n        assert np.allclose(expected, ket, atol=tol, rtol=0)\n\n    def test_squeezed(self, setup_eng, hbar, cutoff, bsize, pure, tol):\n        """"""Test squeezed function matches Fock backends""""""\n        eng, prog = setup_eng(1)\n        r = 0.112\n        phi = 0.123\n\n        with prog.context as q:\n            ops.Sgate(r, phi) | q[0]\n\n        state = eng.run(prog).state\n        ket = utils.squeezed_state(r, phi, basis=""fock"", fock_dim=cutoff, hbar=hbar)\n\n        if not pure:\n            expected = state.dm()\n            ket = np.tile(np.outer(ket, ket.conj()), (bsize, 1, 1))\n        else:\n            expected = state.ket()\n            ket = np.tile(ket, (bsize, 1))\n\n        assert np.allclose(expected, ket, atol=tol, rtol=0)\n\n    def test_displaced_squeezed(self, setup_eng, hbar, cutoff, bsize, pure, tol):\n        """"""Test displaced squeezed function matches Fock backends""""""\n        eng, prog = setup_eng(1)\n        a = 0.32 + 0.1j\n        r = 0.112\n        phi = 0.123\n\n        with prog.context as q:\n            ops.Sgate(r, phi) | q[0]\n            ops.Dgate(a) | q[0]\n\n        state = eng.run(prog).state\n        ket = utils.displaced_squeezed_state(\n            a, r, phi, basis=""fock"", fock_dim=cutoff, hbar=hbar\n        )\n\n        if not pure:\n            expected = state.dm()\n            ket = np.tile(np.outer(ket, ket.conj()), (bsize, 1, 1))\n        else:\n            expected = state.ket()\n            ket = np.tile(ket, (bsize, 1))\n\n        assert np.allclose(expected, ket, atol=tol, rtol=0)\n\n    def test_fock_state(self, setup_eng, cutoff, bsize, pure, tol):\n        """"""Test fock state function matches Fock backends""""""\n        eng, prog = setup_eng(1)\n        n = 2\n\n        with prog.context as q:\n            ops.Fock(n) | q[0]\n\n        state = eng.run(prog).state\n        ket = utils.fock_state(n, fock_dim=cutoff)\n        if not pure:\n            expected = state.dm()\n            ket = np.tile(np.outer(ket, ket.conj()), (bsize, 1, 1))\n        else:\n            expected = state.ket()\n            ket = np.tile(ket, (bsize, 1))\n\n        assert np.allclose(expected, ket, atol=tol, rtol=0)\n\n    def test_cat_state(self, setup_eng, cutoff, bsize, pure, tol):\n        """"""Test cat state function matches Fock backends""""""\n        eng, prog = setup_eng(1)\n        a = 0.32 + 0.1j\n        p = 0.43\n\n        with prog.context as q:\n            ops.Catstate(a, p) | q[0]\n\n        state = eng.run(prog).state\n        ket = utils.cat_state(a, p, fock_dim=cutoff)\n\n        if not pure:\n            expected = state.dm()\n            ket = np.tile(np.outer(ket, ket.conj()), (bsize, 1, 1))\n        else:\n            expected = state.ket()\n            ket = np.tile(ket, (bsize, 1))\n\n        assert np.allclose(expected, ket, atol=tol, rtol=0)\n\n\n# ===================================================================================\n# Operation integration tests\n# ===================================================================================\n\n\n@utils.operation(1)\ndef prepare_state(v1, q):\n    """"""Single-mode state preparation.""""""\n    ops.Dgate(v1) | q\n\n\n@utils.operation(2)\ndef entangle_states(q):\n    """"""Two-mode entangled state preparation.""""""\n    ops.Sgate(-2) | q[0]\n    ops.Sgate(2) | q[1]\n    ops.BSgate(np.pi / 4, 0) | (q[0], q[1])\n\n\nclass TestTeleportationOperationTest:\n    """"""Run a teleportation algorithm but split the circuit into operations.\n    Operations can be also methods of a class""""""\n\n    @pytest.mark.parametrize(\'cutoff\', [10], indirect=True)  # override default cutoff fixture\n    def test_teleportation_fidelity(self, setup_eng):\n        """"""Test teleportation algorithm gives correct fid when using operations""""""\n        eng, prog = setup_eng(3)\n        with prog.context as q:\n            prepare_state(0.5 + 0.2j) | q[0]\n            entangle_states() | (q[1], q[2])\n            ops.BSgate(np.pi / 4, 0) | (q[0], q[1])\n            ops.MeasureHomodyne(0, select=0) | q[0]\n            ops.MeasureHomodyne(np.pi / 2, select=0) | q[1]\n\n        state = eng.run(prog).state\n        fidelity = state.fidelity_coherent([0, 0, 0.5 + 0.2j])\n        assert np.allclose(fidelity, 1, atol=0.1, rtol=0)\n\n    def test_validate_argument(self):\n        """"""Test correct exceptions are raised for wrong arguments""""""\n\n        with pytest.raises(ValueError):\n            prepare_state(1, 2, 3) | (1, 2)\n\n        with pytest.raises(ValueError):\n            prepare_state(1) | (1, 2)\n\n        with pytest.raises(ValueError):\n            prepare_state(1) | ()\n\n        with pytest.raises(ValueError):\n            entangle_states() | (1, 2, 3)\n\n        with pytest.raises(ValueError):\n            entangle_states() | (1)\n\n        with pytest.raises(ValueError):\n            entangle_states() | 1\n\n\n# ===================================================================================\n# Engine unitary and channel extraction tests\n# ===================================================================================\n\n@pytest.fixture\ndef backend_name(setup_backend_pars):\n    """"""The name of the currently tested backend.""""""\n    return setup_backend_pars[0]\n\n\n@pytest.mark.backends(""fock"", ""tf"")\nclass TestExtractUnitary:\n    """"""Test extraction of unitaries""""""\n\n    def test_extract_kerr(self, backend_name, cutoff, tol):\n        """"""test that the Kerr gate is correctly extracted""""""\n\n        prog = sf.Program(1)\n        kappa = 0.432\n        with prog.context as q:\n            ops.Kgate(kappa) | q\n\n        U = utils.extract_unitary(prog, cutoff_dim=cutoff, backend=backend_name)\n        expected = np.diag(np.exp(1j * kappa * np.arange(cutoff) ** 2))\n\n        if isinstance(U, tf.Tensor):\n            U = U.numpy()\n\n        assert np.allclose(U, expected, atol=tol, rtol=0)\n\n    def test_extract_squeezing(self, backend_name, cutoff, tol):\n        """"""test that the squeezing gate is correctly extracted""""""\n        prog = sf.Program(1)\n\n        r = 0.432\n        phi = -0.96543\n\n        with prog.context as q:\n            ops.Sgate(r, phi) | q\n\n        U = utils.extract_unitary(prog, cutoff_dim=cutoff, backend=backend_name)\n        expected = sq_U(r, phi, cutoff)\n\n        if isinstance(U, tf.Tensor):\n            U = U.numpy()\n\n        assert np.allclose(U, expected, atol=tol, rtol=0)\n\n    def test_extract_displacement(self, backend_name, cutoff, tol):\n        """"""test that the displacement gate is correctly extracted""""""\n        prog = sf.Program(1)\n        alpha = 0.432 - 0.8543j\n        with prog.context as q:\n            ops.Dgate(alpha) | q\n\n        U = utils.extract_unitary(prog, cutoff_dim=cutoff, backend=backend_name)\n        expected = disp_U(alpha, cutoff)\n\n        if isinstance(U, tf.Tensor):\n            U = U.numpy()\n\n        assert np.allclose(U, expected, atol=tol, rtol=0)\n\n    def test_extract_beamsplitter(self, backend_name, cutoff, tol):\n        """"""test that the beamsplitter gate is correctly extracted""""""\n        prog = sf.Program(2)\n        theta = 0.432\n        phi = 0.765\n        with prog.context as q:\n            ops.BSgate(theta, phi) | q\n\n        U = utils.extract_unitary(prog, cutoff_dim=cutoff, backend=backend_name)\n        expected = bs_U(np.cos(theta), np.sin(theta), phi, cutoff)\n\n        if isinstance(U, tf.Tensor):\n            U = U.numpy()\n\n        assert np.allclose(U, expected, atol=tol, rtol=0)\n\n    def test_extract_arbitrary_unitary_one_mode(self, setup_eng, cutoff, tol):\n        """"""Test that arbitrary unitary extraction works for 1 mode""""""\n        S = ops.Sgate(0.4, -1.2)\n        D = ops.Dgate(2, 0.9)\n        K = ops.Kgate(-1.5)\n\n        # not a state but it doesn\'t matter\n        initial_state = np.random.rand(cutoff) + 1j * np.random.rand(cutoff)\n\n        eng_ref, p0 = setup_eng(1)\n        with p0.context as q:\n            ops.Ket(initial_state) | q\n\n        prog = sf.Program(p0)\n        with prog.context as q:\n            S | q\n            D | q\n            K | q\n\n        U = utils.extract_unitary(prog, cutoff_dim=cutoff, backend=eng_ref.backend_name)\n\n        if isinstance(U, tf.Tensor):\n            U = U.numpy()\n        \n        final_state = U @ initial_state\n\n        expected_state = eng_ref.run([p0, prog]).state.ket()\n        \n        assert np.allclose(final_state, expected_state, atol=tol, rtol=0)\n\n    def test_extract_arbitrary_unitary_two_modes_vectorized(\n            self, setup_eng, cutoff, batch_size, tol\n    ):\n        """"""Test that arbitrary unitary extraction works for 2 mode when vectorized""""""\n        bsize = 1\n        if batch_size is not None:\n            bsize = batch_size\n\n        S = ops.Sgate(0.4, -1.2)\n        B = ops.BSgate(2.234, -1.165)\n\n        # not a state but it doesn\'t matter\n        initial_state = np.complex64(\n            np.random.rand(cutoff, cutoff) + 1j * np.random.rand(cutoff, cutoff)\n        )\n\n        eng_ref, p0 = setup_eng(2)\n        with p0.context as q:\n            ops.Ket(initial_state) | q\n\n        prog = sf.Program(p0)\n        with prog.context as q:\n            S | q[0]\n            B | q\n            S | q[1]\n            B | q\n\n        U = utils.extract_unitary(\n            prog,\n            cutoff_dim=cutoff,\n            vectorize_modes=True,\n            backend=eng_ref.backend_name,\n        )\n\n        if isinstance(U, tf.Tensor):\n            U = U.numpy()\n\n        final_state = U @ initial_state.reshape([-1])\n        expected_state = eng_ref.run([p0, prog]).state.ket()\n        \n        if isinstance(expected_state, tf.Tensor):\n            expected_state = expected_state.numpy()\n\n        if expected_state.shape[0] == bsize: # the Fock backend does not support batching!\n            for exp_state in expected_state:\n                assert np.allclose(final_state, exp_state.reshape([-1]), atol=tol, rtol=0)\n        else:\n            assert np.allclose(final_state, expected_state.reshape([-1]), atol=tol, rtol=0)\n        \n\n    def test_extract_arbitrary_unitary_two_modes_not_vectorized(\n            self, setup_eng, cutoff, tol\n    ):\n        """"""Test that arbitrary unitary extraction works for 2 mode""""""\n        S = ops.Sgate(0.4, -1.2)\n        B = ops.BSgate(2.234, -1.165)\n\n        # not a state but it doesn\'t matter\n        initial_state = np.complex64(\n            np.random.rand(cutoff, cutoff) + 1j * np.random.rand(cutoff, cutoff)\n        )\n\n        eng_ref, p0 = setup_eng(2)\n        if eng_ref.backend.short_name == ""tf"":\n            pytest.skip(""Un vectorized mode only supports Fock backend for now"")\n\n        with p0.context as q:\n            ops.Ket(initial_state) | q\n\n        prog = sf.Program(p0)\n        with prog.context as q:\n            S | q[0]\n            B | q\n            S | q[1]\n            B | q\n\n        U = utils.extract_unitary(\n            prog,\n            cutoff_dim=cutoff,\n            vectorize_modes=False,\n            backend=eng_ref.backend_name,\n        )\n        final_state = np.einsum(""abcd,bd->ac"", U, initial_state)\n        expected_state = eng_ref.run([p0, prog]).state.ket()\n\n        assert np.allclose(final_state, expected_state, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""fock"")\nclass TestExtractChannelOneMode:\n    """"""Test extraction of unitaries""""""\n\n    @pytest.fixture\n    def setup_one_mode_circuit(self, setup_eng, cutoff):\n        """"""Create the circuit for following tests""""""\n        eng_ref, p0 = setup_eng(1)\n\n        S = ops.Sgate(1.1, -1.4)\n        L = ops.LossChannel(0.45)\n\n        initial_state = np.random.rand(cutoff, cutoff)\n\n        with p0.context as q:\n            ops.DensityMatrix(initial_state) | q\n\n        prog = sf.Program(p0)\n        with prog.context as q:\n            S | q\n            L | q\n\n        rho = eng_ref.run([p0, prog]).state.dm()\n        return prog, rho, initial_state\n\n    def test_extract_choi_channel(self, setup_one_mode_circuit, cutoff, tol):\n        """"""Test that Choi channel extraction works for 1 mode""""""\n        prog, rho, initial_state = setup_one_mode_circuit\n\n        choi = utils.extract_channel(prog, cutoff_dim=cutoff, representation=""choi"")\n        final_rho = np.einsum(""abcd,ab -> cd"", choi, initial_state)\n\n        assert np.allclose(final_rho, rho, atol=tol, rtol=0)\n\n    def test_extract_liouville_channel(self, setup_one_mode_circuit, cutoff, tol):\n        """"""Test that Liouville channel extraction works for 1 mode""""""\n        prog, rho, initial_state = setup_one_mode_circuit\n\n        liouville = utils.extract_channel(\n            prog, cutoff_dim=cutoff, representation=""liouville""\n        )\n        final_rho = np.einsum(""abcd,db -> ca"", liouville, initial_state)\n\n        assert np.allclose(final_rho, rho, atol=tol, rtol=0)\n\n    def test_extract_kraus_channel(self, setup_one_mode_circuit, cutoff, tol):\n        """"""Test that Kraus channel extraction works for 1 mode""""""\n        prog, rho, initial_state = setup_one_mode_circuit\n\n        kraus = utils.extract_channel(prog, cutoff_dim=cutoff, representation=""kraus"")\n        final_rho = np.einsum(""abc,cd,aed -> be"", kraus, initial_state, np.conj(kraus))\n\n        assert np.allclose(final_rho, rho, atol=tol, rtol=0)\n\n\n@pytest.mark.backends(""fock"")\nclass TestExtractChannelTwoMode:\n    """"""Test extraction of unitaries""""""\n\n    @pytest.fixture\n    def setup_two_mode_circuit(self, setup_eng, cutoff):\n        """"""Create the circuit for following tests""""""\n        eng_ref, p0 = setup_eng(2)\n\n        S = ops.Sgate(2)\n        B = ops.BSgate(2.234, -1.165)\n\n        initial_state = np.complex64(\n            np.random.rand(*[cutoff] * 4) + 1j * np.random.rand(*[cutoff] * 4)\n        )\n\n        with p0.context as q:\n            ops.DensityMatrix(initial_state) | q\n\n        prog = sf.Program(p0)\n        with prog.context as q:\n            S | q[0]\n            B | q\n            S | q[1]\n            B | q\n\n        rho = eng_ref.run([p0, prog]).state.dm()\n        return prog, rho, initial_state\n\n    def test_extract_choi_channel(self, setup_two_mode_circuit, cutoff, tol):\n        """"""Test that Choi channel extraction works for 2 mode""""""\n        prog, rho, initial_state = setup_two_mode_circuit\n\n        choi = utils.extract_channel(\n            prog, cutoff_dim=cutoff, vectorize_modes=False, representation=""choi""\n        )\n        final_rho = np.einsum(""abcdefgh,abcd -> efgh"", choi, initial_state)\n\n        assert np.allclose(final_rho, rho, atol=tol, rtol=0)\n\n    def test_extract_liouville_channel(self, setup_two_mode_circuit, cutoff, tol):\n        """"""Test that Liouville channel extraction works for 2 mode""""""\n        prog, rho, initial_state = setup_two_mode_circuit\n\n        liouville = utils.extract_channel(\n            prog, cutoff_dim=cutoff, vectorize_modes=False, representation=""liouville""\n        )\n        final_rho = np.einsum(""abcdefgh,fbhd -> eagc"", liouville, initial_state)\n\n        assert np.allclose(final_rho, rho, atol=tol, rtol=0)\n\n    def test_extract_kraus_channel(self, setup_two_mode_circuit, cutoff, tol):\n        """"""Test that Kraus channel extraction works for 2 mode""""""\n        prog, rho, initial_state = setup_two_mode_circuit\n\n        kraus = utils.extract_channel(\n            prog, cutoff_dim=cutoff, vectorize_modes=False, representation=""kraus""\n        )\n        final_rho = np.einsum(\n            ""abcde,cfeg,ahfig -> bhdi"", kraus, initial_state, np.conj(kraus)\n        )\n\n        assert np.allclose(final_rho, rho, atol=tol, rtol=0)\n\n    def test_extract_choi_channel_vectorize(self, setup_two_mode_circuit, cutoff, tol):\n        """"""Test that Choi channel extraction works for 2 mode vectorized""""""\n        prog, rho, initial_state = setup_two_mode_circuit\n        rho = np.einsum(""abcd->acbd"", rho).reshape(cutoff ** 2, cutoff ** 2)\n        initial_state = np.einsum(""abcd->acbd"", initial_state).reshape(\n            cutoff ** 2, cutoff ** 2\n        )\n\n        choi = utils.extract_channel(\n            prog, cutoff_dim=cutoff, vectorize_modes=True, representation=""choi""\n        )\n        final_rho = np.einsum(""abcd,ab -> cd"", choi, initial_state)\n\n        assert np.allclose(final_rho, rho, atol=tol, rtol=0)\n\n    def test_extract_liouville_channel_vectorize(self, setup_two_mode_circuit, cutoff, tol):\n        """"""Test that Liouville channel extraction works for 2 mode vectorized""""""\n        prog, rho, initial_state = setup_two_mode_circuit\n        rho = np.einsum(""abcd->acbd"", rho).reshape(cutoff ** 2, cutoff ** 2)\n        initial_state = np.einsum(""abcd->acbd"", initial_state).reshape(\n            cutoff ** 2, cutoff ** 2\n        )\n\n        liouville = utils.extract_channel(\n            prog, cutoff_dim=cutoff, vectorize_modes=True, representation=""liouville""\n        )\n        final_rho = np.einsum(""abcd,db -> ca"", liouville, initial_state)\n\n        assert np.allclose(final_rho, rho, atol=tol, rtol=0)\n\n    def test_extract_kraus_channel_vectorize(self, setup_two_mode_circuit, cutoff, tol):\n        """"""Test that Kraus channel extraction works for 2 mode vectorized""""""\n        prog, rho, initial_state = setup_two_mode_circuit\n        rho = np.einsum(""abcd->acbd"", rho).reshape(cutoff ** 2, cutoff ** 2)\n        initial_state = np.einsum(""abcd->acbd"", initial_state).reshape(\n            cutoff ** 2, cutoff ** 2\n        )\n\n        kraus = utils.extract_channel(\n            prog, cutoff_dim=cutoff, vectorize_modes=True, representation=""kraus""\n        )\n        final_rho = np.einsum(""abc,cd,aed -> be"", kraus, initial_state, np.conj(kraus))\n\n        assert np.allclose(final_rho, rho, atol=tol, rtol=0)\n'"
strawberryfields/apps/train/__init__.py,0,"b'r""""""\nTools for training variational GBS devices.\n\n.. currentmodule:: strawberryfields.apps.train\n\n.. autosummary::\n    :toctree: api\n\n    embed\n    Stochastic\n    VGBS\n    param\n    KL\n    cost\n""""""\nfrom strawberryfields.apps.train.param import VGBS\nfrom strawberryfields.apps.train.cost import KL\nimport strawberryfields.apps.train.cost\nimport strawberryfields.apps.train.param\nimport strawberryfields.apps.train.embed\nfrom strawberryfields.apps.train.cost import Stochastic\n'"
strawberryfields/apps/train/cost.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nSubmodule for computing gradients and evaluating cost functions with respect to GBS circuits\n\nIn the context of stochastic optimization, cost functions are expressed as expectation values\nover the GBS distribution. Within the WAW parametrization, gradients of cost functions can also be\nexpressed as expectation values over the GBS distribution. This module contains methods for\ncalculating these gradients and for using gradient-based methods to optimize GBS circuits. In the\ncase of optimization with respect to a Kullback-Leibler divergence or log-likelihood cost\nfunction, gradients can be computed efficiently, leading to fast training.\n""""""\nfrom typing import Callable\n\nimport numpy as np\n\nfrom strawberryfields.apps.train.param import VGBS, _Omat\n\n\nclass KL:\n    r""""""Kullback-Liebler divergence cost function.\n\n    In a standard unsupervised learning scenario, data are assumed to be sampled from an unknown\n    distribution and a common goal is to learn that distribution. Training of a model\n    distribution can be performed by minimizing the Kullback-Leibler (KL) divergence, which up to\n    additive constants can be written as:\n\n    .. math::\n\n        KL = -\\frac{1}{T}\\sum_S \\log[P(S)],\n\n    where :math:`S` is an element of the data, :math:`P(S)` is the probability of observing that\n    element when sampling from the GBS distribution, and :math:`T` is the total number of elements\n    in the data. For the GBS distribution in the WAW parametrization, the gradient of the KL\n    divergence can be written as\n\n\n    .. math::\n\n        \\partial_\\theta KL(\\theta) = - \\sum_{k=1}^m\\frac{1}{w_k}(\\langle n_k\\rangle_{\\text{data}}-\n        \\langle n_k\\rangle_{\\text{GBS}})\\partial_\\theta w_k,\n\n    where :math:`\\langle n_k\\rangle` denotes the average photon numbers in mode *k*. This class\n    provides methods to compute gradients and evaluate the cost function.\n\n    **Example usage**\n\n    >>> embedding = train.embed.Exp(4)\n    >>> A = np.ones((4, 4))\n    >>> vgbs = train.VGBS(A, 3, embedding, threshold=True)\n    >>> params = np.array([0.05, 0.1, 0.02, 0.01])\n    >>> data = np.zeros((4, 4))\n    >>> kl = cost.KL(data, vgbs)\n    >>> kl.evaluate(params)\n    -0.2866830267216749\n    >>> kl.grad(params)\n    array([-0.52812574, -0.5201932 , -0.53282312, -0.53437824])\n\n    Args:\n        data (array): Array of samples representing the training data\n        vgbs (train.VGBS): Variational GBS class\n\n    """"""\n\n    def __init__(self, data: np.ndarray, vgbs: VGBS):\n        self.data = data\n        self.vgbs = vgbs\n        self.nr_samples, self.nr_modes = np.shape(self.data)\n        self.mean_n_data = np.mean(self.data, axis=0)\n\n    def grad(self, params: np.ndarray) -> np.ndarray:\n        r""""""Calculates the gradient of the Kullback-Liebler cost function with respect to the\n        trainable parameters\n\n        **Example usage**\n\n        >>> kl.grad(params)\n        array([-0.52812574, -0.5201932 , -0.53282312, -0.53437824])\n\n        Args:\n            params (array[float]): the trainable parameters :math:`\\theta`\n        Returns:\n            array: the gradient of the KL cost function with respect to :math:`\\theta`\n        """"""\n        weights = self.vgbs.embedding(params)\n        if self.vgbs.threshold:\n            n_diff = self.vgbs.mean_clicks_by_mode(params) - self.mean_n_data\n        else:\n            n_diff = self.vgbs.mean_photons_by_mode(params) - self.mean_n_data\n        return (n_diff / weights) @ self.vgbs.embedding.jacobian(params)\n\n    def evaluate(self, params: np.ndarray) -> float:\n        r""""""Computes the value of the Kullback-Liebler divergence cost function.\n\n        **Example usage**\n\n        >>> kl.evaluate(params)\n        -0.2866830267216749\n\n        Args:\n            params (array): the trainable parameters :math:`\\theta`\n        Returns:\n            float: the value of the cost function\n        """"""\n        kl = 0\n        for sample in self.data:\n            kl += np.log(self.vgbs.prob_sample(params, sample))\n        return -kl / self.nr_samples\n\n    def __call__(self, params: np.ndarray) -> float:\n        return self.evaluate(params)\n\n\nclass Stochastic:\n    r""""""Stochastic cost function given by averaging over samples from a trainable GBS distribution.\n\n    A stochastic optimization problem is defined with respect to a function :math:`h(\\bar{n})` that\n    assigns a cost to an input sample :math:`\\bar{n}`. The cost function is the\n    average of :math:`h(\\bar{n})` over samples generated from a parametrized distribution\n    :math:`P_{\\theta}(\\bar{n})`:\n\n    .. math::\n\n        C (\\theta) = \\sum_{\\bar{n}} h(\\bar{n}) P_{\\theta}(\\bar{n})\n\n    The cost function :math:`C (\\theta)` can then be optimized by varying\n    :math:`P_{\\theta}(\\bar{n})`.\n\n    In this setting, :math:`P_{\\theta}(\\bar{n})` is the variational GBS distribution and is\n    specified in :class:`~.Stochastic` by an instance of :class:`~.train.VGBS`.\n\n    **Example usage:**\n\n    The function :math:`h(\\bar{n})` can be viewed as an energy. Clicks in odd-numbered modes\n    decrease the total energy, while clicks in even-numbered modes increase it.\n\n    >>> embedding = train.embed.Exp(4)\n    >>> A = np.ones((4, 4))\n    >>> vgbs = train.VGBS(A, 3, embedding, threshold=True)\n    >>> h = lambda x: sum([x[i] * (-1) ** (i + 1) for i in range(4)])\n    >>> cost = Stochastic(h, vgbs)\n    >>> params = np.array([0.05, 0.1, 0.02, 0.01])\n    >>> cost.evaluate(params, 100)\n    0.03005489236683591\n    >>> cost.gradient(params, 100)\n    array([ 0.10880756, -0.1247146 ,  0.12426481, -0.13783342])\n\n    Args:\n        h (callable): a function that assigns a cost to an input sample\n        vgbs (train.VGBS): the trainable GBS distribution, which must be an instance of\n            :class:`~.train.VGBS`\n    """"""\n\n    def __init__(self, h: Callable, vgbs: VGBS):\n        self.h = h\n        self.vgbs = vgbs\n\n    def evaluate(self, params: np.ndarray, n_samples: int) -> float:\n        r""""""Evaluates the cost function.\n\n        The cost function can be evaluated by finding its average over samples generated from the\n        VGBS system using the trainable parameters :math:`\\theta`:\n\n        .. math::\n\n            C (\\theta) = \\sum_{\\bar{n}} h(\\bar{n}) P_{\\theta}(\\bar{n})\n\n        Alternatively, the cost function can be evaluated by finding a different average over\n        samples from the input adjacency matrix to the VGBS system:\n\n        .. math::\n\n            C (\\theta) = \\sum_{\\bar{n}} h(\\bar{n}, \\theta) P(\\bar{n})\n\n        where :math:`h(\\bar{n}, \\theta)` is given in :meth:`~.Stochastic.h_reparametrized` and now\n        contains the trainable parameters, and :math:`P(\\bar{n})` is the distribution over the\n        input adjacency matrix. The advantage of this alternative approach is that we do not\n        need to keep regenerating samples for an updated adjacency matrix and can instead use\n        a fixed set of samples.\n\n        The second approach above is utilized in :class:`Stochastic` to speed up evaluation of\n        the cost function and its gradient. This is done by approximating the cost function using a\n        single fixed set of samples. The samples can be pre-loaded into the :class:`~.train.VGBS` class or\n        generated once upon the first call of either :meth:`Stochastic.evaluate` or\n        :meth:`Stochastic.gradient`.\n\n        **Example usage:**\n\n        >>> cost.evaluate(params, 100)\n        0.03005489236683591\n\n        Args:\n            params (array): the trainable parameters :math:`\\theta`\n            n_samples (int): the number of GBS samples used to average the cost function\n\n        Returns:\n            float: the value of the stochastic cost function\n        """"""\n        samples = self.vgbs.get_A_init_samples(n_samples)\n        return np.mean([self.h_reparametrized(s, params) for s in samples])\n\n    def h_reparametrized(self, sample: np.ndarray, params: np.ndarray) -> float:\n        r""""""Include trainable parameters in the :math:`h(\\bar{n})` function to allow sampling\n        from the initial adjacency matrix.\n\n        The reparametrized function can be written in terms :math:`h(\\bar{n})` as:\n\n        .. math::\n\n            h(\\bar{n}, \\theta) = h(\\bar{n}) \\sqrt{\\frac{\\det (\\mathbb{I} - A(\\theta)^{2})}\n            {\\det (\\mathbb{I} - A^{2})}} \\prod_{k=1}^{m}w_{k}^{n_{k}},\n\n        where :math:`w_{k}` is the :math:`\\theta`-dependent weight on the :math:`k`-th mode in\n        the :class:`~.train.VGBS` system and :math:`n_{k}` is the number of photons in mode :math:`k`.\n\n        **Example usage:**\n\n        >>> sample = [1, 1, 0, 0]\n        >>> cost.h_reparametrized(sample, params)\n        -1.6688383062813434\n\n        Args:\n            sample (array): the sample\n            params (array): the trainable parameters :math:`\\theta`\n\n        Returns:\n            float: the cost function with respect to a given sample and set of trainable parameters\n        """"""\n        h = self.h(sample)\n        A = self.vgbs.A(params)\n        w = self.vgbs.embedding(params)\n        Id = np.eye(2 * self.vgbs.n_modes)\n\n        dets_numerator = np.linalg.det(Id - _Omat(A))\n        dets_denominator = np.linalg.det(Id - _Omat(self.vgbs.A_init))\n        dets = np.sqrt(dets_numerator / dets_denominator)\n\n        prod = np.prod(np.power(w, sample))\n\n        return h * dets * prod\n\n    def _gradient_one_sample(self, sample: np.ndarray, params: np.ndarray) -> np.ndarray:\n        """"""Evaluates the gradient equation on a single sample.\n\n        Args:\n            sample (array): the sample\n            params (array): the trainable parameters :math:`\\theta`\n\n        Returns:\n            array: the one-shot gradient\n        """"""\n        w = self.vgbs.embedding(params)\n        jac = self.vgbs.embedding.jacobian(params)\n\n        h = self.h_reparametrized(sample, params)\n\n        if self.vgbs.threshold:\n            diff = sample - self.vgbs.mean_clicks_by_mode(params)\n        else:\n            diff = sample - self.vgbs.mean_photons_by_mode(params)\n\n        return h * (diff / w) @ jac\n\n    def gradient(self, params: np.ndarray, n_samples: int) -> np.ndarray:\n        r""""""Evaluates the gradient of the cost function.\n\n        As shown in `this paper <https://arxiv.org/abs/2004.04770>`__, the gradient can be\n        evaluated by finding an average over samples generated from the input adjacency matrix to\n        the VGBS system:\n\n        .. math::\n\n            \\partial_{\\theta} C (\\theta) = \\sum_{\\bar{n}} h(\\bar{n}, \\theta) P(\\bar{n})\n            \\sum_{k=1}^{m}  (n_k - \\langle n_{k} \\rangle) \\partial_{\\theta} \\log w_{k}\n\n        where :math:`h(\\bar{n}, \\theta)` is given in :meth:`~.Stochastic.h_reparametrized`,\n        :math:`P(\\bar{n})` is the distribution over the input adjacency matrix, :math:`n_{k}` is\n        the number of photons in mode :math:`k`, and :math:`w_{k}` are the weights in the\n        :class:`~.train.VGBS` system.\n\n        This method approximates the gradient using a fixed set of samples from the initial\n        adjacency matrix. The samples can be pre-loaded into the :class:`~.train.VGBS` class or\n        generated once upon the first call of :meth:`Stochastic.evaluate` or\n        :meth:`Stochastic.gradient`.\n\n        **Example usage:**\n\n        >>> cost.gradient(params, 100)\n        array([ 0.10880756, -0.1247146 ,  0.12426481, -0.13783342])\n\n        Args:\n            params (array): the trainable parameters :math:`\\theta`\n            n_samples (int): the number of GBS samples used in the gradient estimation\n\n        Returns:\n            array: the gradient vector\n        """"""\n        samples = self.vgbs.get_A_init_samples(n_samples)\n        return np.mean([self._gradient_one_sample(s, params) for s in samples], axis=0)\n\n    def __call__(self, params: np.ndarray, n_samples: int) -> float:\n        return self.evaluate(params, n_samples)\n'"
strawberryfields/apps/train/embed.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nSubmodule for embedding trainable parameters into the GBS distribution.\n\nTraining algorithms for GBS distributions rely on the :math:`WAW` parametrization, where :math:`W`\nis a diagonal matrix of weights and :math:`A` is a symmetric matrix. Trainable parameters are\nembedded into the GBS distribution by expressing the weights as functions of the parameters.\n\nThis submodule contains methods to implement such embeddings. It also provides derivatives\nof the weights with respect to the trainable parameters. There are two main classes, each\ncorresponding to a different embedding. The :class:`Exp` class is a simple embedding where the\nweights are exponentials of the trainable parameters. The :class:`ExpFeatures` class is a more\ngeneral embedding that makes use of user-defined feature vectors, which potentially provide more\nflexibility in training strategies.""""""\n\nimport numpy as np\n\n\nclass ExpFeatures:\n    r""""""Exponential embedding with feature vectors.\n\n    Weights of the :math:`W` matrix in the :math:`WAW` parametrization are expressed as an exponential\n    of the inner product between user-specified feature vectors and trainable parameters:\n    :math:`w_i = \\exp(-f^{(i)}\\cdot\\theta)`. The Jacobian, which encapsulates the derivatives of\n    the weights with respect to the parameters can be computed straightforwardly as:\n    :math:`\\frac{d w_i}{d\\theta_k} = -f^{(i)}_k w_i`.\n\n    **Example usage:**\n\n    >>> features = np.array([[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [0.3, 0.3, 0.3]])\n    >>> embedding = ExpFeatures(features)\n    >>> parameters = np.array([0.1, 0.2, 0.3])\n    >>> embedding(parameters)\n    [0.94176453 0.88692044 0.83527021]\n\n    Args:\n        features (np.array): Matrix of feature vectors where the i-th row is the i-th feature vector\n    """"""\n\n    def __init__(self, features):\n        """"""Initializes the class for an input matrix whose rows are feature vectors""""""\n        self.features = features\n        self.m, self.d = np.shape(features)\n\n    def __call__(self, params):\n        return self.weights(params)\n\n    def weights(self, params):\n        r""""""Computes weights as a function of input parameters.\n\n        Args:\n            params (np.array): trainable parameters\n\n        Returns:\n            np.array: weights\n        """"""\n        if self.d != len(params):\n            raise ValueError(\n                ""Dimension of parameter vector must be equal to dimension of feature vectors""\n            )\n        return np.exp(-self.features @ params)\n\n    def jacobian(self, params):\n        r""""""Computes the Jacobian matrix of weights with respect to input parameters :math:`J_{\n        ij} = \\frac{\\partial w_i}{\\partial \\theta_j}`.\n\n        Args:\n            params (np.array): trainable parameters\n\n        Returns:\n            np.array: Jacobian matrix of weights with respect to parameters\n        """"""\n        if self.d != len(params):\n            raise ValueError(\n                ""Dimension of parameter vector must be equal to dimension of feature vectors""\n            )\n        w = self.weights(params)\n        return -self.features * w[:, np.newaxis]\n\n\nclass Exp(ExpFeatures):\n    r""""""Simple exponential embedding.\n\n    Weights of the :math:`W` matrix in the :math:`WAW` parametrization are expressed as an exponential\n    of the trainable parameters: :math:`w_i = \\exp(-\\theta_i)`. The Jacobian, which encapsulates the\n    derivatives of the weights with respect to the parameters can be computed straightforwardly as:\n    :math:`\\frac{d w_i}{d\\theta_k} = -w_i\\delta_{i,k}`.\n\n    **Example usage:**\n\n    >>> dim = 3\n    >>> embedding = Exp(dim)\n    >>> parameters = np.array([0.1, 0.2, 0.3])\n    >>> embedding(parameters)\n    [0.90483742 0.81873075 0.74081822]\n\n    Args:\n        dim (int): Dimension of the vector of parameters, which is equal to the number of modes\n            in the GBS distribution\n    """"""\n\n    def __init__(self, dim):\n        """"""The simple exponential mapping is a special case where the matrix of feature vectors\n        is the identity""""""\n        super().__init__(np.eye(dim))\n'"
strawberryfields/apps/train/param.py,0,"b'# Copyright 2020 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""\nContains the :class:`~.VGBS` (variational GBS) class which provides a trainable parametrization\nof the GBS probability distribution.\n""""""\nfrom typing import Optional\n\nimport numpy as np\nimport thewalrus.samples\nfrom thewalrus._hafnian import reduction\nfrom thewalrus._torontonian import tor\nfrom thewalrus.quantum import Qmat\nfrom thewalrus.quantum import find_scaling_adjacency_matrix as rescale\nfrom thewalrus.quantum import find_scaling_adjacency_matrix_torontonian as rescale_tor\nfrom thewalrus.quantum import photon_number_mean_vector, pure_state_amplitude\n\nimport strawberryfields as sf\n\n\ndef rescale_adjacency(A: np.ndarray, n_mean: float, threshold: bool) -> np.ndarray:\n    """"""Rescale an adjacency matrix so that it can be mapped to GBS.\n\n    An adjacency matrix must have singular values not exceeding one if it can be mapped to GBS.\n    Arbitrary adjacency matrices must first be rescaled to satisfy this condition.\n\n    This function rescales an input adjacency matrix :math:`A` so that the corresponding gaussian\n    state has:\n\n    - a mean number of *clicks* equal to ``n_mean`` when ``threshold=True``;\n    - a mean number of *photons* equal to ``n_mean`` when ``threshold=False``.\n\n    **Example usage:**\n\n    >>> a = np.ones((3, 3))\n    >>> rescale_adjacency(a, 2, True)\n    array([[0.32232919, 0.32232919, 0.32232919],\n           [0.32232919, 0.32232919, 0.32232919],\n           [0.32232919, 0.32232919, 0.32232919]])\n\n    Args:\n        A (array): the adjacency matrix to rescale\n        n_mean (float): the target mean number of clicks or mean number of photons\n        threshold (bool): determines whether rescaling is for a target mean number of clicks or\n            photons\n\n    Returns:\n        array: the rescaled adjacency matrix\n    """"""\n    scale = rescale_tor(A, n_mean) if threshold else rescale(A, n_mean)\n    return A * scale\n\n\ndef _Omat(A: np.ndarray) -> np.ndarray:\n    """"""Find the :math:`O` matrix of an adjacency matrix.\n\n    Args:\n        A (array): the adjacency matrix\n\n    Returns:\n        array: the :math:`O` matrix of :math:`A`\n    """"""\n    return np.block([[np.zeros_like(A), np.conj(A)], [A, np.zeros_like(A)]])\n\n\ndef prob_click(A: np.ndarray, sample: np.ndarray):\n    """"""Calculate the probability of a click pattern.\n\n    The input adjacency matrix must have singular values not exceeding one. This can be achieved\n    by rescaling an arbitrary adjacency matrix using :func:`rescale_adjacency`.\n\n    Args:\n        A (array): the adjacency matrix\n        sample (array): the sample\n\n    Returns:\n        float: the probability\n    """"""\n    n = len(A)\n    O = _Omat(A)\n    sample_big = np.hstack([sample, sample]).astype(""int"")\n    O_sub = reduction(O, sample_big)\n    scale = np.sqrt(np.linalg.det(np.identity(2 * n) - O))\n    return scale * tor(O_sub)\n\n\ndef prob_photon_sample(A: np.ndarray, sample: np.ndarray) -> float:\n    """"""Calculate the probability of a sample of photon counts.\n\n    The input adjacency matrix must have singular values not exceeding one. This can be achieved\n    by rescaling an arbitrary adjacency matrix using :func:`rescale_adjacency`.\n\n    Args:\n        A (array): the adjacency matrix\n        sample (array): the sample\n\n    Returns:\n        float: the probability\n    """"""\n    n = len(A)\n    mu = np.zeros(2 * n)\n    cov = A_to_cov(A)\n    sample = np.array(sample, dtype=""int"")\n    return np.abs(pure_state_amplitude(mu, cov, sample, hbar=sf.hbar)) ** 2\n\n\ndef A_to_cov(A: np.ndarray) -> np.ndarray:\n    """"""Convert an adjacency matrix to a covariance matrix of a GBS device.\n\n    The input adjacency matrix must have singular values not exceeding one. This can be achieved\n    by rescaling an arbitrary adjacency matrix using :func:`rescale_adjacency`.\n\n    **Example usage:**\n\n    >>> a = np.ones((3, 3))\n    >>> a = rescale_adjacency(a, 2, True)\n    >>> cov = A_to_cov(a)\n\n    Args:\n        A (array): the adjacency matrix\n\n    Returns:\n        array: the covariance matrix of :math:`A`\n    """"""\n    n = len(A)\n    I = np.identity(2 * n)\n    return sf.hbar * (np.linalg.inv(I - _Omat(A)) - I / 2)\n\n\nclass VGBS:\n    r""""""Create a variational GBS model for optimization and machine learning.\n\n    An input adjacency matrix :math:`A` can be varied using:\n\n    .. math::\n\n        A(\\theta) = W(\\theta) A W(\\theta),\n\n    with :math:`W` a diagonal matrix of weights that depend on a set of parameters :math:`\\theta`.\n\n    By varying :math:`\\theta`, the distribution of samples from GBS can be trained to solve\n    stochastic optimization and unsupervised machine learning problems.\n\n    The above variational model can be used in both the threshold and PNR modes of GBS, which\n    is specified using the ``threshold`` flag. An initial value for the mean number of clicks\n    (if ``threshold=True``) or mean number of photons (if ``threshold=False``) is also required.\n    The initial value ``n_mean`` should be set high since varying :math:`\\theta` can only lower\n    the mean number of clicks or photons.\n\n    The mapping from :math:`\\theta` to :math:`W(\\theta)` is specified using the ``embedding``\n    argument. An embedding from the :mod:`~.apps.train.embed` module such as\n    :class:`~.apps.train.embed.Exp` must be used, which uses the simple embedding\n    :math:`W(\\theta) = \\exp(-\\theta)`.\n\n    **Example usage:**\n\n    >>> g = nx.erdos_renyi_graph(4, 0.7, seed=1967)\n    >>> A = nx.to_numpy_array(g)\n    >>> embedding = train.embed.Exp(4)\n    >>> vgbs = VGBS(A, 3, embedding, threshold=True)\n    >>> params = np.array([0.05, 0.1, 0.02, 0.01])\n    >>> vgbs.A(params)\n    array([[0.        , 0.30298161, 0.31534653, 0.31692721],\n           [0.30298161, 0.        , 0.30756059, 0.30910225],\n           [0.31534653, 0.30756059, 0.        , 0.32171695],\n           [0.31692721, 0.30910225, 0.32171695, 0.        ]])\n    >>> vgbs.n_mean(params)\n    2.299036355948707\n    >>> vgbs.generate_samples(vgbs.A(params), 2)\n    array([[1, 1, 1, 0],\n           [0, 1, 0, 1]])\n\n    Args:\n        A (array): the input adjacency matrix :math:`A`\n        n_mean (float): the initial mean number of clicks or photons\n        embedding: the method of converting from trainable parameters :math:`\\theta` to\n            :math:`W(\\theta)`. Must be an embedding instance from the :mod:`~.apps.train.embed`\n            module.\n        threshold (bool): determines whether to use GBS in threshold or PNR mode\n        samples (array): an optional array of samples from :math:`A` used to speed up gradient\n            calculations\n    """"""\n\n    def __init__(\n        self,\n        A: np.ndarray,\n        n_mean: float,\n        embedding,\n        threshold: bool,\n        samples: Optional[np.ndarray] = None,\n    ):\n        if not np.allclose(A, A.T):\n            raise ValueError(""Input must be a NumPy array corresponding to a symmetric matrix"")\n        self.A_init = rescale_adjacency(A, n_mean, threshold)\n        self.A_init_samples = None\n        self.embedding = embedding\n        self.threshold = threshold\n        self.n_modes = len(A)\n        self.add_A_init_samples(samples)\n\n    def W(self, params: np.ndarray) -> np.ndarray:\n        r""""""Calculate the diagonal matrix of weights :math:`W` that depends on the trainable\n        parameters :math:`\\theta`.\n\n        **Example usage:**\n\n        >>> vgbs.W(params)\n        array([[0.97530991, 0.        , 0.        , 0.        ],\n               [0.        , 0.95122942, 0.        , 0.        ],\n               [0.        , 0.        , 0.99004983, 0.        ],\n               [0.        , 0.        , 0.        , 0.99501248]])\n\n        Args:\n            params (array): the trainable parameters :math:`\\theta`\n\n        Returns:\n            array: the diagonal matrix of weights\n        """"""\n        return np.sqrt(np.diag(self.embedding(params)))\n\n    def A(self, params: np.ndarray) -> np.ndarray:\n        r""""""Calculate the trained adjacency matrix :math:`A(\\theta)`.\n\n        **Example usage:**\n\n        >>> vgbs.A(params)\n        array([[0.        , 0.30298161, 0.31534653, 0.31692721],\n               [0.30298161, 0.        , 0.30756059, 0.30910225],\n               [0.31534653, 0.30756059, 0.        , 0.32171695],\n               [0.31692721, 0.30910225, 0.32171695, 0.        ]])\n\n        Args:\n            params (array): the trainable parameters :math:`\\theta`\n\n        Returns:\n            array: the trained adjacency matrix\n        """"""\n        return self.W(params) @ self.A_init @ self.W(params)\n\n    def generate_samples(self, A: np.ndarray, n_samples: int, **kwargs) -> np.ndarray:\n        """"""Generate GBS samples from an input adjacency matrix.\n\n        **Example usage:**\n\n        >>> vgbs.generate_samples(vgbs.A(params), 2)\n        array([[1, 1, 1, 0],\n               [0, 1, 0, 1]])\n\n        Args:\n            A (array): the adjacency matrix\n            n_samples (int): the number of GBS samples to generate\n            **kwargs: additional arguments to pass to the sampler from\n                `The Walrus <https://the-walrus.readthedocs.io/en/stable/>`__\n\n        Returns:\n            array:  the generated samples\n        """"""\n        cov = A_to_cov(A)\n\n        if self.threshold:\n            samples = thewalrus.samples.torontonian_sample_state(\n                cov, n_samples, hbar=sf.hbar, **kwargs\n            )\n        else:\n            samples = thewalrus.samples.hafnian_sample_state(cov, n_samples, hbar=sf.hbar, **kwargs)\n        return samples\n\n    def add_A_init_samples(self, samples: np.ndarray):\n        r""""""Add samples of the initial adjacency matrix to :attr:`A_init_samples`.\n\n        .. warning::\n\n            The added samples must be from the *input* adjacency matrix and not the trained one\n            :math:`A(\\theta)`.\n\n        **Example usage:**\n\n        >>> samples = np.array([[0, 1, 0, 0], [0, 1, 1, 1]])\n        >>> vgbs.add_A_init_samples(samples)\n\n        Args:\n            samples (array): samples from the initial adjacency matrix\n        """"""\n        if samples is None:\n            return\n\n        shape = samples.shape\n        if shape[1] != self.n_modes:\n            raise ValueError(""Must input samples of shape (number, {})"".format(self.n_modes))\n\n        if self.A_init_samples is None:\n            self.A_init_samples = samples\n        else:\n            self.A_init_samples = np.vstack([self.A_init_samples, samples])\n\n    def get_A_init_samples(self, n_samples: int) -> np.ndarray:\n        """"""Get samples from the initial adjacency matrix.\n\n        This function checks for pre-generated samples in ``A_init_samples``. If there are fewer\n        than ``n_samples`` stored, more samples are generated and added to ``A_init_samples``.\n\n        Args:\n            n_samples (int): number of samples to get\n\n        Returns:\n            array: samples from the initial adjacency matrix\n        """"""\n        try:\n            current_n_samples = self.A_init_samples.shape[0]\n        except AttributeError:\n            current_n_samples = 0\n\n        if current_n_samples < n_samples:\n            new_samples = self.generate_samples(self.A_init, n_samples - current_n_samples)\n            self.add_A_init_samples(new_samples)\n\n        return self.A_init_samples[:n_samples]\n\n    def prob_sample(self, params: np.ndarray, sample: np.ndarray) -> float:\n        r""""""Calculate the probability of a given sample being generated by the VGBS system using\n        the trainable parameters :math:`\\theta`.\n\n        Args:\n            params (array): the trainable parameters :math:`\\theta`\n            sample (array): the sample\n\n        Returns:\n            float: the sample probability\n        """"""\n        A = self.A(params)\n        return prob_click(A, sample) if self.threshold else prob_photon_sample(A, sample)\n\n    def mean_photons_by_mode(self, params: np.ndarray) -> np.ndarray:\n        r""""""Calculate the mean number of photons in each mode when using the trainable parameters\n        :math:`\\theta`.\n\n        **Example usage:**\n\n        >>> vgbs.mean_photons_by_mode(params)\n        array([1.87217857, 1.8217392 , 1.90226515, 1.91225543])\n\n        Args:\n            params (array): the trainable parameters :math:`\\theta`\n\n        Returns:\n            array: a vector giving the mean number of photons in each mode\n        """"""\n        disp = np.zeros(2 * self.n_modes)\n        cov = A_to_cov(self.A(params))\n        return photon_number_mean_vector(disp, cov, hbar=sf.hbar)\n\n    def mean_clicks_by_mode(self, params: np.ndarray) -> np.ndarray:\n        r""""""Calculate the mean number of clicks in each mode when using the trainable parameters\n        :math:`\\theta`.\n\n        **Example usage:**\n\n        >>> vgbs.mean_clicks_by_mode(params)\n        array([0.57419812, 0.5680168 , 0.57781579, 0.57900564])\n\n        Args:\n            params (array): the trainable parameters :math:`\\theta`\n\n        Returns:\n            array: a vector giving the mean number of clicks in each mode\n        """"""\n        cov = A_to_cov(self.A(params))\n        Q = Qmat(cov, hbar=sf.hbar)\n        m = self.n_modes\n        Qks = [[[Q[k, k], Q[k, k + m]], [Q[k + m, k], Q[k + m, k + m]]] for k in range(m)]\n        cbar = [1 - np.linalg.det(Qks[k]) ** (-0.5) for k in range(m)]\n        return np.real(np.array(cbar))\n\n    def n_mean(self, params: np.ndarray) -> float:\n        r""""""Calculates the mean number of clicks or photons.\n\n        Evaluates the mean number of clicks or photons of the VGBS system when using the\n        trainable parameters :math:`\\theta`. The mean number of clicks is returned when\n        :attr:`threshold` is ``True``, otherwise the mean number of photons is returned.\n\n        **Example usage:**\n\n        >>> vgbs.n_mean(params)\n        2.299036355948707\n\n        Args:\n            params (array): the trainable parameters :math:`\\theta`\n\n        Returns:\n            float: the mean number of clicks or photons\n        """"""\n        if self.threshold:\n            return np.sum(self.mean_clicks_by_mode(params))\n\n        return np.sum(self.mean_photons_by_mode(params))\n'"
strawberryfields/backends/fockbackend/__init__.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Fock simulator backend""""""\n\nfrom .backend import FockBackend\n'"
strawberryfields/backends/fockbackend/backend.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Fock backend simulator""""""\n# pylint: disable=protected-access,too-many-public-methods\n\nimport string\nfrom cmath import phase\nimport numpy as np\n\nfrom strawberryfields.backends import BaseFock, ModeMap\nfrom strawberryfields.backends.states import BaseFockState\n\nfrom .circuit import Circuit\n\nindices = string.ascii_lowercase\n\n\nclass FockBackend(BaseFock):\n    r""""""Implements a simulation of quantum optical circuits in a truncated\n    Fock basis using NumPy, returning a :class:`~.BaseFock`\n    state object.\n\n    The primary component of the FockBackend is a\n    :attr:`~.FockBackend.circuit` object which is used to simulate a multi-mode quantum optical system. The\n    :class:`FockBackend` provides the basic API-compatible interface to the simulator, while the\n    :attr:`~.FockBackend.circuit` object actually carries out the mathematical simulation.\n\n    The :attr:`~.FockBackend.circuit` simulator maintains an internal tensor representation of the quantum state of a multi-mode quantum optical system\n    using a (truncated) Fock basis representation. As its various state manipulation methods are called, the quantum state is updated\n    to reflect these changes. The simulator will try to keep the internal state in a pure (vector) representation\n    for as long as possible. Unitary gates will not change the type of representation, while state preparations and measurements will.\n\n    A number of factors determine the shape and dimensionality of the state tensor:\n\n    * the underlying state representation being used (either a ket vector or a density matrix)\n    * the number of modes :math:`n` actively being simulated\n    * the cutoff dimension :math:`D` for the Fock basis\n\n    The state tensor corresponds to a multimode quantum system. If the\n    representation is a pure state, the state tensor has shape\n    :math:`(\\underbrace{D,...,D}_{n~\\text{times}})`.\n    In a mixed state representation, the state tensor has shape\n    :math:`(\\underbrace{D,D,...,D,D}_{2n~\\text{times}})`.\n    Indices for the same mode appear consecutively. Hence, for a mixed state, the first two indices\n    are for the first mode, the second are for the second mode, etc.\n\n    .. \n        .. currentmodule:: strawberryfields.backends.fockbackend\n        .. autosummary::\n            :toctree:\n\n            ~circuit.Circuit\n            ~ops\n    """"""\n\n    short_name = ""fock""\n    circuit_spec = ""fock""\n\n    def __init__(self):\n        """"""Instantiate a FockBackend object.""""""\n        super().__init__()\n        self._supported[""mixed_states""] = True\n        self._init_modes = None  #: int: initial number of modes in the circuit\n        self._modemap = None  #: Modemap: maps external mode indices to internal ones\n        self.circuit = (\n            None  #: ~.fockbackend.circuit.Circuit: representation of the simulated quantum state\n        )\n\n    def _remap_modes(self, modes):\n        if isinstance(modes, int):\n            modes = [modes]\n            was_int = True\n        else:\n            was_int = False\n        map_ = self._modemap.show()\n        submap = [map_[m] for m in modes]\n        if not self._modemap.valid(modes) or None in submap:\n            raise ValueError(""The specified modes are not valid."")\n\n        remapped_modes = self._modemap.remap(modes)\n        if was_int:\n            remapped_modes = remapped_modes[0]\n        return remapped_modes\n\n    def begin_circuit(self, num_subsystems, **kwargs):\n        r""""""Instantiate a quantum circuit.\n\n        Instantiates a representation of a quantum optical state with ``num_subsystems`` modes.\n        The state is initialized to vacuum.\n\n        The modes in the circuit are indexed sequentially using integers, starting from zero.\n        Once an index is assigned to a mode, it can never be re-assigned to another mode.\n        If the mode is deleted its index becomes invalid.\n        An operation acting on an invalid or unassigned mode index raises an ``IndexError`` exception.\n\n        Args:\n            num_subsystems (int): number of modes in the circuit\n\n        Keyword Args:\n            cutoff_dim (int): Numerical Hilbert space cutoff dimension for the modes.\n                For each mode, the simulator can represent the Fock states :math:`\\ket{0}, \\ket{1}, \\ldots, \\ket{\\text{cutoff_dim}-1}`.\n            pure (bool): If True (default), use a pure state representation (otherwise will use a mixed state representation).\n        """"""\n        cutoff_dim = kwargs.get(""cutoff_dim"", None)\n        pure = kwargs.get(""pure"", True)\n        if cutoff_dim is None:\n            raise ValueError(""Argument \'cutoff_dim\' must be passed to the Fock backend"")\n        if not isinstance(cutoff_dim, int):\n            raise ValueError(""Argument \'cutoff_dim\' must be a positive integer"")\n        if not isinstance(num_subsystems, int):\n            raise ValueError(""Argument \'num_subsystems\' must be a positive integer"")\n        if not isinstance(pure, bool):\n            raise ValueError(""Argument \'pure\' must be either True or False"")\n\n        self._init_modes = num_subsystems\n        self.circuit = Circuit(num_subsystems, cutoff_dim, pure)\n        self._modemap = ModeMap(num_subsystems)\n\n    def add_mode(self, n=1):\n        self.circuit.alloc(n)\n        self._modemap.add(n)\n\n    def del_mode(self, modes):\n        remapped_modes = self._remap_modes(modes)\n        if isinstance(remapped_modes, int):\n            remapped_modes = [remapped_modes]\n        self.circuit.dealloc(remapped_modes)\n        self._modemap.delete(modes)\n\n    def get_modes(self):\n        return [i for i, j in enumerate(self._modemap._map) if j is not None]\n\n    def reset(self, pure=True, **kwargs):\n        cutoff = kwargs.get(""cutoff_dim"", self.circuit._trunc)\n        self._modemap.reset()\n        self.circuit.reset(pure, num_subsystems=self._init_modes, cutoff_dim=cutoff)\n\n    def prepare_vacuum_state(self, mode):\n        self.circuit.prepare_mode_fock(0, self._remap_modes(mode))\n\n    def prepare_coherent_state(self, alpha, mode):\n        self.circuit.prepare_mode_coherent(alpha, self._remap_modes(mode))\n\n    def prepare_squeezed_state(self, r, phi, mode):\n        self.circuit.prepare_mode_squeezed(r, phi, self._remap_modes(mode))\n\n    def prepare_displaced_squeezed_state(self, alpha, r, phi, mode):\n        self.circuit.prepare_mode_displaced_squeezed(alpha, r, phi, self._remap_modes(mode))\n\n    def prepare_thermal_state(self, nbar, mode):\n        self.circuit.prepare_mode_thermal(nbar, self._remap_modes(mode))\n\n    def rotation(self, phi, mode):\n        self.circuit.phase_shift(phi, self._remap_modes(mode))\n\n    def displacement(self, alpha, mode):\n        self.circuit.displacement(alpha, self._remap_modes(mode))\n\n    def squeeze(self, z, mode):\n        self.circuit.squeeze(abs(z), phase(z), self._remap_modes(mode))\n\n    def two_mode_squeeze(self, z, mode1, mode2):\n        self.circuit.two_mode_squeeze(\n            abs(z), phase(z), self._remap_modes(mode1), self._remap_modes(mode2)\n        )\n\n    def beamsplitter(self, t, r, mode1, mode2):\n        if isinstance(t, complex):\n            raise ValueError(""Beamsplitter transmittivity t must be a float."")\n        self.circuit.beamsplitter(\n            t, abs(r), phase(r), self._remap_modes(mode1), self._remap_modes(mode2)\n        )\n\n    def measure_homodyne(self, phi, mode, shots=1, select=None, **kwargs):\n        """"""Perform a homodyne measurement on the specified mode.\n\n        See :meth:`.BaseBackend.measure_homodyne`.\n\n        Keyword Args:\n            num_bins (int): Number of equally spaced bins for the probability distribution function\n                (pdf) simulating the homodyne measurement (default: 100000).\n            max (float): The pdf is discretized onto the 1D grid [-max,max] (default: 10).\n        """"""\n        if shots != 1:\n            raise NotImplementedError(\n                ""fock backend currently does not support "" ""shots != 1 for homodyne measurement""\n            )\n        return self.circuit.measure_homodyne(phi, self._remap_modes(mode), select=select, **kwargs)\n\n    def loss(self, T, mode):\n        self.circuit.loss(T, self._remap_modes(mode))\n\n    def is_vacuum(self, tol=0.0, **kwargs):\n        return self.circuit.is_vacuum(tol)\n\n    def get_cutoff_dim(self):\n        return self.circuit._trunc\n\n    def state(self, modes=None, **kwargs):\n        s, pure = self.circuit.get_state()\n\n        if modes is None:\n            # reduced state is full state\n            red_state = s\n            num_modes = len(s.shape) if pure else len(s.shape) // 2\n            modes = [m for m in range(num_modes)]\n        else:\n            # convert to mixed state representation\n            if pure:\n                num_modes = len(s.shape)\n                left_str = [indices[i] for i in range(0, 2 * num_modes, 2)]\n                right_str = [indices[i] for i in range(1, 2 * num_modes, 2)]\n                out_str = [indices[: 2 * num_modes]]\n                einstr = """".join(left_str + ["",""] + right_str + [""->""] + out_str)\n                rho = np.einsum(einstr, s, s.conj())\n            else:\n                rho = s\n\n            # reduce rho down to specified subsystems\n            if isinstance(modes, int):\n                modes = [modes]\n\n            if len(modes) != len(set(modes)):\n                raise ValueError(""The specified modes cannot be duplicated."")\n\n            num_modes = len(rho.shape) // 2\n            if len(modes) > num_modes:\n                raise ValueError(\n                    ""The number of specified modes cannot be larger than the number of subsystems.""\n                )\n\n            keep_indices = indices[: 2 * len(modes)]\n            trace_indices = indices[2 * len(modes) : len(modes) + num_modes]\n            ind = [i * 2 for i in trace_indices]\n            ctr = 0\n\n            for m in range(num_modes):\n                if m in modes:\n                    ind.insert(m, keep_indices[2 * ctr : 2 * (ctr + 1)])\n                    ctr += 1\n\n            indStr = """".join(ind) + ""->"" + keep_indices\n            red_state = np.einsum(indStr, rho)\n\n            # permute indices of returned state to reflect the ordering of modes (we know and hence can assume that red_state is a mixed state)\n        if modes != sorted(modes):\n            mode_permutation = np.argsort(modes)\n            index_permutation = [2 * x + i for x in mode_permutation for i in (0, 1)]\n            red_state = np.transpose(red_state, np.argsort(index_permutation))\n\n        cutoff = self.circuit._trunc\n        mode_names = [""q[{}]"".format(i) for i in np.array(self.get_modes())[modes]]\n        state = BaseFockState(red_state, len(modes), pure, cutoff, mode_names)\n        return state\n\n    # ==============================================\n    # Fock state specific\n    # ==============================================\n\n    def prepare_fock_state(self, n, mode):\n        self.circuit.prepare_mode_fock(n, self._remap_modes(mode))\n\n    def prepare_ket_state(self, state, modes):\n        self.circuit.prepare_multimode(state, self._remap_modes(modes))\n\n    def prepare_dm_state(self, state, modes):\n        self.circuit.prepare_multimode(state, self._remap_modes(modes))\n\n    def cubic_phase(self, gamma, mode):\n        self.circuit.cubic_phase_shift(gamma, self._remap_modes(mode))\n\n    def kerr_interaction(self, kappa, mode):\n        self.circuit.kerr_interaction(kappa, self._remap_modes(mode))\n\n    def cross_kerr_interaction(self, kappa, mode1, mode2):\n        self.circuit.cross_kerr_interaction(\n            kappa, self._remap_modes(mode1), self._remap_modes(mode2)\n        )\n\n    def measure_fock(self, modes, shots=1, select=None, **kwargs):\n        if shots != 1:\n            raise NotImplementedError(\n                ""fock backend currently does not support "" ""shots != 1 for Fock measurement""\n            )\n        return self.circuit.measure_fock(self._remap_modes(modes), select=select)\n'"
strawberryfields/backends/fockbackend/circuit.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Fock backend proper""""""\n# pylint: disable=too-many-arguments,len-as-condition,attribute-defined-outside-init\n# pylint: disable=too-many-branches,too-many-locals,too-many-public-methods\n\nimport copy\nimport string\nimport numbers\nfrom itertools import product\n\nimport numpy as np\nfrom numpy import sqrt, pi\nfrom scipy.special import factorial as bang\nfrom numba import jit\nfrom numba.typed import List\n\nfrom . import ops\n\ndef_type = np.complex128\nindices = string.ascii_lowercase\nMAX_MODES = len(indices) - 3\n\n\nclass Circuit:\n    """"""\n    Class implementing a basic simulator for a collection of modes\n    in the fock basis.\n    """"""\n\n    def __init__(self, num, trunc, pure=True, do_checks=False):\n        r""""""Class initializer.\n\n        Args:\n            num (non-negative int): Number of modes in the register.\n            trunc (positive int): Truncation parameter.  Fock states up to |trunc-1> are representable.\n            pure (bool, optional): Whether states are pure (True) or mixed (False)\n            do_checks (bool, optional): Whether arguments are to be checked first\n            mode (str, optional): Whether to use BLAS or einsum for matrix operations.\n        """"""\n\n        # Check validity\n        if num < 0:\n            raise ValueError(""Number of modes must be non-negative -- got {}"".format(num))\n        if num > MAX_MODES:\n            raise ValueError(""Fock simulator has a maximum of {} modes"".format(MAX_MODES))\n        if trunc <= 0:\n            raise ValueError(""Truncation must be positive -- got {}"".format(trunc))\n\n        self._num_modes = num\n        self._hbar = 2\n        self._checks = do_checks\n        self.reset(pure=pure, cutoff_dim=trunc)\n\n    def _apply_channel(self, kraus_ops, modes):\n        """"""Master channel application function. Applies a channel represented by\n        Kraus operators.\n\n        .. note::\n                Always results in a mixed state.\n\n        Args:\n            kraus_ops (list<array>): A list of Kraus operators\n            modes (list<non-negative int>): The modes to apply the channel to\n        """"""\n\n        if self._pure:\n            self._state = ops.mix(self._state, self._num_modes)\n            self._pure = False\n\n        if len(kraus_ops) == 0:\n            self._state = np.zeros(\n                [self._trunc for i in range(self._num_modes * 2)], dtype=ops.def_type\n            )\n        else:\n            states = [self.apply_gate_BLAS(k, modes, pure=False) for k in kraus_ops]\n            self._state = sum(states)\n\n    def reset(self, pure=None, cutoff_dim=None, num_subsystems=None):\n        """"""Resets the simulation state.\n\n        Args:\n            pure (bool, optional): Sets the purity setting. Default is unchanged.\n            cutoff_dim (int): New Hilbert space truncation dimension.\n            num_subsystems (int, optional): Sets the number of modes in the reset\n                circuit. Default is unchanged.\n        """"""\n        if pure is not None:\n            if not isinstance(pure, bool):\n                raise ValueError(""Argument \'pure\' must be either True or False"")\n            self._pure = pure\n\n        if num_subsystems is not None:\n            if not isinstance(num_subsystems, int):\n                raise ValueError(""Argument \'num_subsystems\' must be a positive integer"")\n            self._num_modes = num_subsystems\n\n        if cutoff_dim is not None:\n            if not isinstance(cutoff_dim, int) or cutoff_dim < 1:\n                raise ValueError(""Argument \'cutoff_dim\' must be a positive integer"")\n            self._trunc = cutoff_dim\n\n        if self._pure:\n            self._state = ops.vacuumState(self._num_modes, self._trunc)\n        else:\n            self._state = ops.vacuumStateMixed(self._num_modes, self._trunc)\n\n    def apply_gate_BLAS(self, mat, modes, **kwargs):\n        """"""Applies a specified gate to the state.\n\n        Gate application based on custom indexing and matrix multiplication.\n        Assumes the input matrix has shape (out1, in1, ...).\n\n        This implementation uses indexing and BLAS. As per stack overflow,\n        einsum doesn\'t actually use BLAS but rather a c implementation. In theory\n        if reshaping is efficient this should be faster.\n\n        Args:\n            mat (array[complex]): The numeric operator to be applied to the state, of shape ``[trunc]*(2*n)``\n            modes (list[int]): The list of modes to which the operator is applied on\n\n        Keyword args:\n            state (array[complex]): The state that the operator is applied to\n            pure (bool): Whether the state is pure or mixed\n            n (int): The total number of modes\n\n        Returns:\n            array[complex]: The state after application of the two-mode operation\n        """"""\n        # pylint: disable=too-many-branches\n\n        state = kwargs.get(""state"", self._state)\n        pure = kwargs.get(""pure"", self._pure)\n        n = kwargs.get(""n"", self._num_modes)\n\n        size = len(modes)\n        dim = self._trunc ** size\n        stshape = [self._trunc for i in range(size)]\n\n        # Apply the following matrix transposition:\n        # |m1><m1| |m2><m2| ... |mn><mn| -> |m1>|m2>...|mn><m1|<m2|...<mn|\n        transpose_list = [2 * i for i in range(size)] + [2 * i + 1 for i in range(size)]\n        matview = np.transpose(mat, transpose_list).reshape((dim, dim))\n\n        # checks if matview is diagonal (for example, Kerr/rotation gates) and, if so, use faster contractions\n        diag = np.all(matview == np.diag(np.diagonal(matview)))\n\n        if pure:\n            if n == 1:\n                if diag:\n                    mat_diag = mat.diagonal()\n                    return np.multiply(mat_diag, state)\n                return np.dot(mat, state)\n\n            # Transpose the state into the following form:\n            # |psi> |mode[0]> |mode[1]> ... |mode[n]>\n            transpose_list = [i for i in range(n) if not i in modes] + modes\n            view = np.transpose(state, transpose_list)\n\n            # Apply matrix to each substate\n            ret = np.zeros([self._trunc for i in range(n)], dtype=def_type)\n            for i in product(*([range(self._trunc) for j in range(n - size)])):\n                if diag:\n                    mat_diag = matview.diagonal()\n                    ret[i] = np.multiply(mat_diag, view[i].ravel()).reshape(stshape)\n                else:\n                    ret[i] = np.dot(matview, view[i].ravel()).reshape(stshape)\n\n            # ""untranspose"" the return matrix ret\n            untranspose_list = [0] * len(transpose_list)\n            for i in range(len(transpose_list)):  # pylint: disable=consider-using-enumerate\n                untranspose_list[transpose_list[i]] = i\n\n            return np.transpose(ret, untranspose_list)\n\n        # otherwise, the state is mixed\n        if n == 1:\n            if diag:\n                mat_diag = mat.diagonal().reshape(-1, 1)\n                return np.multiply(mat_diag, np.multiply(state, mat_diag.conj().T))\n            return np.dot(mat, np.dot(state, mat.conj().T))\n\n        # Transpose the state into the following form:\n        # |psi><psi||mode[0]>|mode[1]>...|mode[n]><mode[0]|<mode[1]|...<mode[n]|\n        transpose_list = [i for i in range(n * 2) if not i // 2 in modes]\n        transpose_list = transpose_list + [2 * i for i in modes] + [2 * i + 1 for i in modes]\n        view = np.transpose(state, transpose_list)\n\n        # Apply matrix to each substate\n        ret = np.zeros([self._trunc for i in range(n * 2)], dtype=def_type)\n        for i in product(*([range(self._trunc) for j in range((n - size) * 2)])):\n            if diag:\n                mat_diag = matview.diagonal().reshape(-1, 1)\n                ret[i] = np.multiply(\n                    mat_diag, np.multiply(view[i].reshape((dim, dim)), mat_diag.conj().T)\n                ).reshape(stshape + stshape)\n            else:\n                ret[i] = np.dot(\n                    matview, np.dot(view[i].reshape((dim, dim)), matview.conj().T)\n                ).reshape(stshape + stshape)\n\n        # ""untranspose"" the return matrix ret\n        untranspose_list = [0] * len(transpose_list)\n        for i in range(len(transpose_list)):  # pylint: disable=consider-using-enumerate\n            untranspose_list[transpose_list[i]] = i\n\n        return np.transpose(ret, untranspose_list)\n\n    def apply_twomode_gate(self, mat, modes, gate=""BSgate""):\n        """"""Applies a two-mode gate to the state.\n\n        Applies the specified two-mode gate to the state using custom tensor contractions and\n        the Numba compiler for faster application. Currently, only the beamsplitter and the\n        two-mode squeeze gate are supported.\n\n        Args:\n            mat (array[complex]): The numeric operator to be applied to the state, of shape `[trunc]*(2*n)`\n            modes (list[int]): The list of modes to which the operator is applied on\n            gate (str): The gate that is being applied. This argument determines the selection rules that\n                are used. Options are ``""BSgate""`` and ``""S2gate""``.\n\n        Returns:\n            array[complex]: The state after application of the two-mode operation\n        """"""\n        if self._pure:\n            t1 = modes[0]\n            t2 = modes[1]\n\n            # moves the modes on which the gate should be applied to the\n            # front indices of the state, for mode 1 and 2 respectively\n            # e.g. from [i1, i2, i3] --> [i2, i3, i1] if the gate is applied to modes 2 and 3\n            switch_list_1 = np.arange(self._num_modes)\n            switch_list_2 = np.arange(self._num_modes)\n            switch_list_1[[0, t1]] = switch_list_1[[t1, 0]]\n            switch_list_2[[1, t2]] = switch_list_2[[t2, 1]]\n\n            self._state = self._state.transpose(switch_list_1)\n            self._state = self._state.transpose(switch_list_2)\n\n            if gate == ""BSgate"":\n                self._state = self._apply_BS(mat, self._state, self._trunc)\n            elif gate == ""S2gate"":\n                self._state = self._apply_S2(mat, self._state, self._trunc)\n            else:\n                raise NotImplementedError(\n                    ""Currently, selection rules are only implemented for the BSgate ""\n                    ""and the S2gate. The {} gate is not supported"".format(gate)\n                )\n\n            self._state = self._state.transpose(switch_list_2)\n            ret = self._state.transpose(switch_list_1)\n        else:\n            t1 = 2 * modes[0]\n            t2 = 2 * modes[1]\n\n            # moves the modes on which the gate should be applied to the\n            # front indices of the state, for mode 1 and 2 respectively\n            # e.g. from [i1, j1, i2, j2, i3, j3] --> [i2, j2, i3, j3, i1, j1]\n            # if the gate is applied to modes 2 and 3\n            switch_list_1 = np.arange(2 * self._num_modes)\n            switch_list_2 = np.arange(2 * self._num_modes)\n            switch_list_1[[0, 1, t1, t1 + 1]] = switch_list_1[[t1, t1 + 1, 0, 1]]\n            switch_list_2[[0, 1, t2, t2 + 1]] = switch_list_2[[t2, t2 + 1, 0, 1]]\n\n            # puts the modes on which the gate should be applied together\n            # e.g. from [i2, j2, i3, j3, i1, j1] --> [i2, i3, j2, j3, i1, j1]\n            # if the gate is applied to modes 2 and 3 (which are already switched to the first two modes)\n            transpose_list = np.arange(2 * self._num_modes)\n            transpose_list[[t1 + 1, t2]] = transpose_list[[t2, t1 + 1]]\n\n            self._state = self._state.transpose(transpose_list)\n            self._state = self._state.transpose(switch_list_1)\n\n            if gate == ""BSgate"":\n                self._state = self._apply_BS(mat, self._state, self._trunc)\n                self._state = self._state.transpose(switch_list_1)\n\n                self._state = self._state.transpose(switch_list_2)\n                self._state = self._apply_BS(mat.conj(), self._state, self._trunc)\n\n            elif gate == ""S2gate"":\n                self._state = self._apply_S2(mat, self._state, self._trunc)\n                self._state = self._state.transpose(switch_list_1)\n\n                self._state = self._state.transpose(switch_list_2)\n                self._state = self._apply_S2(mat.conj(), self._state, self._trunc)\n\n            else:\n                raise NotImplementedError\n\n            self._state = self._state.transpose(switch_list_2)\n            ret = self._state.transpose(transpose_list)\n\n        return ret\n\n    # ignored in covtest (doesn\'t work well with the jit decorator)\n    @staticmethod\n    @jit(nopython=True)\n    def _apply_BS(mat, state, trunc):  # pragma: no cover\n        r""""""Applies the BS gate to the first bra in state.\n\n        The beamsplitter matrix elements :math:`B_{ij}^{kl}` satisfy the selection\n        rules\n\n        .. math::\n            B_{ij}^{kl} \\propto \\delta_{i+j}^{k+l}\n\n        This implies that one can contract pure states (without loss of generality\n        we assume only two modes) using one less loop as follows:\n\n        .. math::\n            c\'_{i, j} = \\sum\\limits_{k = \\text{max}(1+i+j-n, 0)}\n                    ^{\\text{min}(i+j, n-1) + 1}\n            B_{ik}^{j, i+j-k} c_{k, i+j-k}\n\n        where :math:`c_{kl}` is the tensor representing the two mode state and\n        :math:`n` is the cutoff in Fock space. Similarly for a mixed state it is\n        possible to do the update of the state using two less summations.\n        """"""\n        ret = np.zeros_like(state, dtype=np.complex128)\n        for i in range(trunc):\n            for j in range(trunc):\n                for k in range(max(1 + i + j - trunc, 0), min(i + j, trunc - 1) + 1):\n                    ret[i, j] += mat[i, k, j, i + j - k] * state[k, i + j - k]\n        return ret\n\n    # ignored in covtest (doesn\'t work well with the jit decorator)\n    @staticmethod\n    @jit(nopython=True)\n    def _apply_S2(mat, state, trunc):  # pragma: no cover\n        r""""""Applies the S2 gate to the first bra in state.\n\n        The two-mode squeeze matrix elements :math:`T_{ij}^{kl}` satisfy the selection\n        rules\n\n        .. math::\n            T_{ij}^{kl} \\propto \\delta_{i-j}^{k-l}\n\n        This implies that one can contract pure states (without loss of generality\n        we assume only two modes) using one less loop as follows:\n\n        .. math::\n            c\'_{i, k} = \\sum\\limits_{k = \\text{max}(i-j, 0)}^{\\text{min}(i-j, 0) + n}\n            T_{ij}^{k, k+j-i} c_{j, k+j-i}\n\n        where :math:`c_{jl}` is the tensor representing the two mode state and\n        :math:`n` is the cutoff in Fock space. Similarly for a mixed state it is\n        possible to do the update of the state using two less summations.\n        """"""\n        ret = np.zeros_like(state, dtype=np.complex128)\n        for i in range(trunc):\n            for j in range(trunc):\n                for k in range(max(i - j, 0), trunc + min(i - j, 0)):\n                    ret[i, k] += mat[i, j, k, k + j - i] * state[j, k + j - i]\n        return ret\n\n    def norm(self):\n        """"""returns the norm of the state""""""\n        if self._pure:\n            return sqrt(np.vdot(self._state, self._state).real)\n        return ops.trace(self._state, self._num_modes)\n\n    def alloc(self, n=1):\n        """"""allocate a number of modes at the end of the state.""""""\n        # base_shape = [self._trunc for i in range(n)]\n        if self._pure:\n            vac = ops.vacuumState(n, self._trunc)\n        else:\n            vac = ops.vacuumStateMixed(n, self._trunc)\n\n        self._state = ops.tensor(self._state, vac, self._num_modes, self._pure)\n        self._num_modes = self._num_modes + n\n\n    def dealloc(self, modes):\n        """"""Traces out and deallocates the modes in `modes`""""""\n        if self._pure:\n            self._state = ops.mix(self._state, self._num_modes)\n            self._pure = False\n\n        self._state = ops.partial_trace(self._state, self._num_modes, modes)\n        self._num_modes = self._num_modes - len(modes)\n\n    def prepare_multimode(self, state, modes):\n        r""""""\n        Prepares a given mode or list of modes in the given state.\n\n        After the preparation the system is in a mixed product state,\n        with the specified modes replaced by state.\n        The given state can be either in tensor form or in matrix/vector form.\n        If modes is not ordered, the subsystems of the input are\n        reordered to reflect that, i.e., if modes=[3,1], then the first mode\n        of state ends up in mode 3 and the second mode of state ends up in\n        mode 1 of the output state.\n        If modes is None, it is attempted to prepare state in all modes.\n        The reduced state on all other modes remains unchanged and\n        the final state is product with respect to the partition into\n        the modes in modes and the complement.\n\n        Args:\n            state (array): vector, matrix, or tensor representation of the ket state or dm state in the fock basis to prepare\n            modes (list[int] or non-negative int): The mode(s) into which state is to be prepared. Needs not be ordered.\n        """"""\n        if isinstance(modes, int):\n            modes = [modes]\n\n        n_modes = len(modes)\n        pure_shape = tuple([self._trunc] * n_modes)\n        mixed_shape = tuple([self._trunc] * (2 * n_modes))\n        pure_shape_as_vector = tuple([self._trunc ** n_modes])\n        mixed_shape_as_matrix = tuple([self._trunc ** n_modes] * 2)\n\n        # Do consistency checks\n        if self._checks:\n            if (\n                state.shape != pure_shape\n                and state.shape != mixed_shape\n                and state.shape != pure_shape_as_vector\n                and state.shape != mixed_shape_as_matrix\n            ):\n                raise ValueError(""Incorrect shape for state preparation"")\n            if len(modes) != len(set(modes)):\n                raise ValueError(""The specified modes cannot appear multiple times."")\n\n        # reshape to support input both as tensor and vector/matrix\n        if state.shape == pure_shape_as_vector:\n            state = state.reshape(pure_shape)\n        elif state.shape == mixed_shape_as_matrix:\n            state = state.reshape(mixed_shape)\n\n        if self._num_modes == n_modes:\n            # Hack for marginally faster state preparation\n            self._state = state.astype(ops.def_type)\n            self._pure = bool(state.shape == pure_shape)\n        else:\n            if self._pure:\n                self._state = ops.mix(self._state, self._num_modes)\n                self._pure = False\n\n            if state.shape == pure_shape:\n                state = ops.mix(state, len(modes))\n\n            # Take the partial trace\n            # todo: For performance the partial trace could be done directly from the pure state. This would of course require a better partial trace function...\n            reduced_state = ops.partial_trace(self._state, self._num_modes, modes)\n\n            # Insert state at the end (I know there is also tensor() from ops but it has extra aguments wich only confuse here)\n            self._state = np.tensordot(reduced_state, state, axes=0)\n\n            # unless the preparation was meant to go into the last modes in the standard order, we need to swap indices around\n        if modes != list(range(self._num_modes - len(modes), self._num_modes)):\n            mode_permutation = [x for x in range(self._num_modes) if x not in modes] + modes\n            if self._pure:\n                scale = 1\n                index_permutation = mode_permutation\n            else:\n                scale = 2\n                index_permutation = [\n                    scale * x + i for x in mode_permutation for i in (0, 1)\n                ]  # two indices per mode if we have pure states\n            index_permutation = np.argsort(index_permutation)\n\n            self._state = np.transpose(self._state, index_permutation)\n\n    def prepare(self, state, mode):\n        r""""""\n        Prepares a given mode in a given state.\n\n        This is a simple wrapper for prepare_multimode(), see there for more details.\n\n        Args:\n            state (array): vector, matrix, or tensor representation of the ket state or dm state in the fock basis to prepare\n            modes (list[int] or non-negative int or None): The mode(s) into which state is to be prepared. Needs not be ordered.\n        """"""\n        if isinstance(mode, int):\n            mode = [mode]\n        self.prepare_multimode(state, mode)\n\n    def prepare_mode_fock(self, n, mode):\n        """"""\n        Prepares a mode in a fock state.\n        """"""\n\n        if self._pure:\n            self.prepare(ops.fockState(n, self._trunc), mode)\n        else:\n            st = ops.fockState(n, self._trunc)\n            self.prepare(np.outer(st, st.conjugate()), mode)\n\n    def prepare_mode_coherent(self, alpha, mode):\n        """"""\n        Prepares a mode in a coherent state.\n        """"""\n        if self._pure:\n            self.prepare(ops.coherentState(alpha, self._trunc), mode)\n        else:\n            st = ops.coherentState(alpha, self._trunc)\n            self.prepare(np.outer(st, st.conjugate()), mode)\n\n    def prepare_mode_squeezed(self, r, theta, mode):\n        """"""\n        Prepares a mode in a squeezed state.\n        """"""\n        if self._pure:\n            self.prepare(ops.squeezedState(r, theta, self._trunc), mode)\n        else:\n            st = ops.squeezedState(r, theta, self._trunc)\n            self.prepare(np.outer(st, st.conjugate()), mode)\n\n    def prepare_mode_displaced_squeezed(self, alpha, r, phi, mode):\n        """"""\n        Prepares a mode in a displaced squeezed state.\n        """"""\n        if self._pure:\n            self.prepare(ops.displacedSqueezed(alpha, r, phi, self._trunc), mode)\n        else:\n            st = ops.displacedSqueezed(alpha, r, phi, self._trunc)\n            self.prepare(np.outer(st, st.conjugate()), mode)\n\n    def prepare_mode_thermal(self, nbar, mode):\n        """"""\n        Prepares a mode in a thermal state.\n        """"""\n        st = ops.thermalState(nbar, self._trunc)\n        self.prepare(st, mode)\n\n    def phase_shift(self, theta, mode):\n        """"""\n        Applies a phase shifter.\n        """"""\n        mat = ops.phase(theta, self._trunc)\n        self._state = self.apply_gate_BLAS(mat, [mode])\n\n    def displacement(self, alpha, mode):\n        """"""\n        Applies a displacement gate.\n        """"""\n        mat = ops.displacement(alpha, self._trunc)\n        self._state = self.apply_gate_BLAS(mat, [mode])\n\n    def beamsplitter(self, t, r, phi, mode1, mode2):\n        """"""\n        Applies a beamsplitter.\n        """"""\n        mat = ops.beamsplitter(t, r, phi, self._trunc)\n\n        modes = List()\n        modes.append(mode1)\n        modes.append(mode2)\n\n        self._state = self.apply_twomode_gate(mat, modes, gate=""BSgate"")\n\n    def squeeze(self, r, theta, mode):\n        """"""\n        Applies a squeezing gate.\n        """"""\n        mat = ops.squeezing(r, theta, self._trunc)\n        self._state = self.apply_gate_BLAS(mat, [mode])\n\n    def two_mode_squeeze(self, r, theta, mode1, mode2):\n        """"""\n        Applies a two-mode squeezing gate.\n        """"""\n        mat = ops.two_mode_squeezing(r, theta, self._trunc)\n\n        modes = List()\n        modes.append(mode1)\n        modes.append(mode2)\n\n        self._state = self.apply_twomode_gate(mat, modes, gate=""S2gate"")\n\n    def kerr_interaction(self, kappa, mode):\n        """"""\n        Applies a Kerr interaction gate.\n        """"""\n        mat = ops.kerr(kappa, self._trunc)\n        self._state = self.apply_gate_BLAS(mat, [mode])\n\n    def cross_kerr_interaction(self, kappa, mode1, mode2):\n        """"""\n        Applies a cross-Kerr interaction gate.\n        """"""\n        mat = ops.cross_kerr(kappa, self._trunc)\n        self._state = self.apply_gate_BLAS(mat, [mode1, mode2])\n\n    def cubic_phase_shift(self, gamma, mode):\n        """"""\n        Applies a cubic phase shift gate.\n        """"""\n        mat = ops.cubicPhase(gamma, self._hbar, self._trunc)\n        self._state = self.apply_gate_BLAS(mat, [mode])\n\n    def is_vacuum(self, tol):\n        """"""\n        Tests whether the system is in the vacuum state.\n        """"""\n        # fid = <0|\\rho|0>\n        if self._pure:\n            fid = np.abs(self._state.flat[0]) ** 2\n        else:\n            fid = self._state.flat[0]\n        return np.abs(fid - 1) <= tol\n\n    def get_state(self):\n        """"""\n        Returns the state of the system in the fock basis along with its purity.\n        """"""\n        return self._state, self._pure\n\n    def loss(self, T, mode):\n        """"""\n        Applies a loss channel to the state.\n        """"""\n        self._apply_channel(ops.lossChannel(T, self._trunc), [mode])\n\n    def measure_fock(self, modes, select=None):\n        """"""\n        Measures a list of modes.\n        """"""\n        # pylint: disable=singleton-comparison\n        if select is not None and np.any(np.array(select) == None):\n            raise NotImplementedError(""Post-selection lists must only contain numerical values."")\n\n        # Make sure the state is mixed\n        if self._pure:\n            state = ops.mix(self._state, self._num_modes)\n        else:\n            state = self._state\n\n        if select is not None:\n            # perform post-selection\n\n            # make sure modes and select are the same length\n            if len(select) != len(modes):\n                raise ValueError(\n                    ""When performing post-selection, the number of ""\n                    ""selected values (including None) must match the number of measured modes""\n                )\n\n            # make sure the select values are all integers or nones\n            if not all(isinstance(s, int) or s is None for s in select):\n                raise TypeError(""The post-select list elements either be integers or None"")\n\n            # modes to measure\n            measure = [i for i, s in zip(modes, select) if s is None]\n\n            # modes already post-selected:\n            selected = [i for i, s in zip(modes, select) if s is not None]\n            select_values = [s for s in select if s is not None]\n\n            # project out postselected modes\n            self._state = ops.project_reset(\n                selected, select_values, self._state, self._pure, self._num_modes, self._trunc\n            )\n\n            if self.norm() == 0:\n                raise ZeroDivisionError(""Measurement has zero probability."")\n\n            self._state = self._state / self.norm()\n\n        else:\n            # no post-selection; modes to measure are the modes provided\n            measure = modes\n\n        if len(measure) > 0:\n            # sampling needs to be performed\n            # Compute distribution by tracing out modes not measured, then computing the diagonal\n            unmeasured = [i for i in range(self._num_modes) if i not in measure]\n            reduced = ops.partial_trace(state, self._num_modes, unmeasured)\n            dist = np.ravel(ops.diagonal(reduced, len(measure)).real)\n            # kill spurious tiny values (which are sometimes negative)\n            dist = dist * ~np.isclose(dist, 0.0)\n\n            # Make a random choice\n            if sum(dist) != 1:\n                # WARNING: distribution is not normalized, could hide errors\n                i = np.random.choice(list(range(len(dist))), p=dist / sum(dist))\n            else:\n                i = np.random.choice(list(range(len(dist))), p=dist)\n\n            permuted_outcome = ops.unIndex(i, len(measure), self._trunc)\n\n            # Permute the outcome to match the order of the modes in \'measure\'\n            permutation = np.argsort(measure)\n            outcome = [0] * len(measure)\n            for i in range(len(measure)):\n                outcome[permutation[i]] = permuted_outcome[i]\n\n            # Project the state onto the measurement outcome & reset in vacuum\n            self._state = ops.project_reset(\n                measure, outcome, self._state, self._pure, self._num_modes, self._trunc\n            )\n\n            if self.norm() == 0:\n                raise ZeroDivisionError(""Measurement has zero probability."")\n\n            self._state = self._state / self.norm()\n\n        # include post-selected values in measurement outcomes\n        if select is not None:\n            outcome = copy.copy(select)\n\n        return outcome\n\n    def measure_homodyne(self, phi, mode, select=None, **kwargs):\n        """"""\n        Performs a homodyne measurement on a mode.\n        """"""\n        m_omega_over_hbar = 1 / self._hbar\n\n        # Make sure the state is mixed for reduced density matrix\n        if self._pure:\n            state = ops.mix(self._state, self._num_modes)\n        else:\n            state = self._state\n\n        if select is not None:\n            meas_result = select\n            if isinstance(meas_result, numbers.Number):\n                homodyne_sample = float(meas_result)\n            else:\n                raise TypeError(""Selected measurement result must be of numeric type."")\n        else:\n            # Compute reduced density matrix\n            unmeasured = [i for i in range(self._num_modes) if not i == mode]\n            reduced = ops.partial_trace(state, self._num_modes, unmeasured)\n\n            # Rotate to measurement basis\n            reduced = self.apply_gate_BLAS(\n                ops.phase(-phi, self._trunc), [0], state=reduced, pure=False, n=1\n            )\n\n            # Create pdf. Same as tf implementation, but using\n            # the recursive relation H_0(x) = 1, H_1(x) = 2x, H_{n+1}(x) = 2xH_n(x) - 2nH_{n-1}(x)\n            q_mag = kwargs.get(""max"", 10)\n            num_bins = kwargs.get(""num_bins"", 100000)\n\n            q_tensor, Hvals = ops.hermiteVals(q_mag, num_bins, m_omega_over_hbar, self._trunc)\n            H_matrix = np.zeros((self._trunc, self._trunc, num_bins))\n            for n, m in product(range(self._trunc), repeat=2):\n                H_matrix[n][m] = 1 / sqrt(2 ** n * bang(n) * 2 ** m * bang(m)) * Hvals[n] * Hvals[m]\n            H_terms = np.expand_dims(reduced, -1) * np.expand_dims(H_matrix, 0)\n            rho_dist = (\n                np.sum(H_terms, axis=(1, 2))\n                * (m_omega_over_hbar / pi) ** 0.5\n                * np.exp(-m_omega_over_hbar * q_tensor ** 2)\n                * (q_tensor[1] - q_tensor[0])\n            )  # Delta_q for normalization (only works if the bins are equally spaced)\n\n            # Sample from rho_dist. This is a bit different from tensorflow due to how\n            # numpy treats multinomial sampling. In particular, numpy returns a\n            # histogram of the samples whereas tensorflow gives the list of samples.\n            # Numpy also does not use the log probabilities\n            probs = rho_dist.flatten().real\n            probs /= np.sum(probs)\n\n            # Due to floating point precision error, values in the calculated probability distribution\n            # may have a very small negative value of -epsilon. The following sets\n            # these small negative values to 0.\n            probs[np.abs(probs) < 1e-10] = 0\n\n            sample_hist = np.random.multinomial(1, probs)\n            sample_idx = list(sample_hist).index(1)\n            homodyne_sample = q_tensor[sample_idx]\n\n        # Project remaining modes into the conditional state\n        inf_squeezed_vac = np.array(\n            [\n                (-0.5) ** (n // 2) * sqrt(bang(n)) / bang(n // 2) if n % 2 == 0 else 0.0 + 0.0j\n                for n in range(self._trunc)\n            ],\n            dtype=ops.def_type,\n        )\n        alpha = homodyne_sample * sqrt(m_omega_over_hbar / 2)\n\n        composed = np.dot(ops.phase(phi, self._trunc), ops.displacement(alpha, self._trunc))\n        eigenstate = self.apply_gate_BLAS(composed, [0], state=inf_squeezed_vac, pure=True, n=1)\n\n        vac_state = np.array(\n            [1.0 + 0.0j if i == 0 else 0.0 + 0.0j for i in range(self._trunc)], dtype=ops.def_type\n        )\n        projector = np.outer(vac_state, eigenstate.conj())\n\n        self._state = self.apply_gate_BLAS(projector, [mode])\n\n        # Normalize\n        self._state = self._state / self.norm()\n\n        return homodyne_sample\n'"
strawberryfields/backends/fockbackend/ops.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Miscellaneous Fock backend operations""""""\n# pylint: disable=too-many-arguments\n# pylint: disable=too-many-locals\n\n\nimport functools\nimport string\nfrom itertools import product\n\nimport numpy as np\nfrom numpy import sqrt, sinh, cosh, tanh, array, exp\nfrom numpy.polynomial.hermite import hermval as H\n\nfrom scipy.special import factorial as fac\nfrom scipy.linalg import expm as matrixExp\n\nfrom thewalrus.fock_gradients import Dgate, Sgate, S2gate, BSgate\n\n\ndef_type = np.complex128\nindices = string.ascii_lowercase\n\n\ndef genOfRange(size):\n    """"""\n    Converts a range into a generator.\n    """"""\n    for i in range(size):\n        yield i\n\n\ndef genOfTuple(t):\n    """"""\n    Converts a tuple into a generator\n    """"""\n    for val in t:\n        yield val\n\n\ndef indexRange(lst, trunc):\n    """"""\n    Returns a generator ranging over the possible values for unspecified\n    indices in `lst`.\n\n    Example:\n        .. code-block:: python\n\n                >>> for i in indexRange([0, None, 1, None], 3): print i\n                (0, 0, 1, 0)\n                (0, 0, 1, 1)\n                (0, 0, 1, 2)\n                (0, 1, 1, 0)\n                (0, 1, 1, 1)\n                (0, 1, 1, 2)\n                (0, 2, 1, 0)\n                (0, 2, 1, 1)\n                (0, 2, 1, 2)\n\n    Args:\n        lst (list<int or None>): a list of (possible unspecified) integers\n        trunc (int): the number to range unspecified values up to\n\n    Returns:\n        Generator of ints\n    """"""\n\n    for vals in product(*([range(trunc) for x in lst if x is None])):\n        gen = genOfTuple(vals)\n        yield [next(gen) if v is None else v for v in lst]  # pylint: disable=stop-iteration-return\n\n\ndef index(lst, trunc):\n    """"""\n    Converts an n-ary index to a 1-dimensional index.\n    """"""\n    return sum([lst[i] * trunc ** (len(lst) - i - 1) for i in range(len(lst))])\n\n\ndef unIndex(i, n, trunc):\n    """"""\n    Converts a 1-dimensional index ``i`` with truncation ``trunc`` and\n    number of modes ``n`` to a n-ary index.\n    """"""\n    return [i // trunc ** (n - 1 - m) % trunc for m in range(n)]\n\n\ndef sliceExp(axes, ind, n):\n    """"""\n    Generates a slice expression for a list of pairs of axes (modes) and indices.\n    """"""\n    return [ind[i] if i in axes else slice(None, None, None) for i in range(n)]\n\n\ndef abssqr(z):\n    r""""""\n    Given :math:`z` returns :math:`|z|^2`.\n    """"""\n    return z.real ** 2 + z.imag ** 2\n\n\ndef dagger(mat):\n    r""""""\n    Given :math:`U` returns :math:`U^\\dagger`.\n    """"""\n    return mat.conj().T\n\n\ndef mix(state, n):\n    """"""\n    Transforms a pure state into a mixed state. Does not do any checks on the\n    shape of the input state.\n    """"""\n\n    left_str = [indices[i] for i in range(0, 2 * n, 2)]\n    right_str = [indices[i] for i in range(1, 2 * n, 2)]\n    out_str = [indices[: 2 * n]]\n    einstr = """".join(left_str + ["",""] + right_str + [""->""] + out_str)\n    return np.einsum(einstr, state, state.conj())\n\n\ndef diagonal(state, n):\n    """"""\n    Computes the diagonal of a density matrix.\n    """"""\n\n    left_str = [indices[i] + indices[i] for i in range(n)]\n    out_str = [indices[:n]]\n    einstr = """".join(left_str + [""->""] + out_str)\n    return np.einsum(einstr, state)\n\n\ndef trace(state, n):\n    """"""\n    Computes the trace of a density matrix.\n    """"""\n\n    left_str = [indices[i] + indices[i] for i in range(n)]\n    einstr = """".join(left_str)\n    return np.einsum(einstr, state)\n\n\ndef partial_trace(state, n, modes):\n    """"""\n    Computes the partial trace of a state over the modes in `modes`.\n\n    Expects state to be in mixed state form.\n    """"""\n    left_str = [\n        indices[2 * i] + indices[2 * i] if i in modes else indices[2 * i : 2 * i + 2]\n        for i in range(n)\n    ]\n    out_str = ["""" if i in modes else indices[2 * i : 2 * i + 2] for i in range(n)]\n    einstr = """".join(left_str + [""->""] + out_str)\n\n    return np.einsum(einstr, state)\n\n\ndef tensor(u, v, n, pure, pos=None):\n    """"""\n    Returns the tensor product of `u` and `v`, optionally spliced into a\n    at location `pos`.\n    """"""\n\n    w = np.tensordot(u, v, axes=0)\n\n    if pos is not None:\n        if pure:\n            scale = 1\n        else:\n            scale = 2\n        for i in range(v.ndim):\n            w = np.rollaxis(w, scale * n + i, scale * pos + i)\n\n    return w\n\n\ndef project_reset(modes, x, state, pure, n, trunc):\n    r""""""\n    Applies the operator :math:`\\ket{00\\dots 0}\\bra{\\mathbf{x}}` to the\n    modes in `modes`.\n    """"""\n    inSlice = tuple(sliceExp(modes, dict(zip(modes, x)), n))\n    outSlice = tuple(sliceExp(modes, dict(zip(modes, [0] * len(modes))), n))\n\n    def intersperse(lst):\n        # pylint: disable=missing-docstring\n        return tuple([lst[i // 2] for i in range(len(lst) * 2)])\n\n    if pure:\n        ret = np.zeros([trunc for i in range(n)], dtype=def_type)\n        ret[outSlice] = state[inSlice]\n    else:\n        ret = np.zeros([trunc for i in range(n * 2)], dtype=def_type)\n        ret[intersperse(outSlice)] = state[intersperse(inSlice)]\n\n    return ret\n\n\n# ============================================\n#\n# Gates\n#\n# ============================================\n\n\n@functools.lru_cache()\ndef a(trunc):\n    r""""""\n    The annihilation operator :math:`a`.\n    """"""\n    ret = np.zeros((trunc, trunc), dtype=def_type)\n    for i in range(1, trunc):\n        ret[i - 1][i] = sqrt(i)\n    return ret\n\n\n@functools.lru_cache()\ndef displacement(alpha, trunc):\n    r""""""The displacement operator :math:`D(\\alpha)`.\n\n    Uses the `Dgate operation from The Walrus`_ to calculate the displacement.\n\n    .. _`Dgate operation from The Walrus`: https://the-walrus.readthedocs.io/en/latest/code/api/thewalrus.fock_gradients.Dgate.html\n\n    Args:\n            alpha (complex): the displacement\n            trunc (int): the Fock cutoff\n    """"""\n\n    r = np.abs(alpha)\n    theta = np.angle(alpha)\n\n    ret, _, _ = Dgate(r, theta, cutoff=trunc)\n\n    return ret\n\n\n@functools.lru_cache()\ndef squeezing(r, theta, trunc):\n    r""""""The squeezing operator :math:`S(re^{i\\theta})`.\n\n    Uses the `Sgate operation from The Walrus`_ to calculate the squeezing.\n\n    .. _`Sgate operation from The Walrus`: https://the-walrus.readthedocs.io/en/latest/code/api/thewalrus.fock_gradients.Sgate.html\n\n    Args:\n            r (float): the magnitude of the squeezing in the\n                    x direction\n            theta (float): the squeezing angle\n            trunc (int): the Fock cutoff\n    """"""\n\n    ret, _, _ = Sgate(r, theta, cutoff=trunc)\n\n    return ret\n\n\n@functools.lru_cache()\ndef two_mode_squeezing(r, theta, trunc):\n    r""""""The two-mode squeezing operator :math:`S_2(re^{i\\theta})`.\n\n    Args:\n        r (float): two-mode squeezing magnitude\n        theta (float): two-mode squeezing phase\n        trunc (int): Fock ladder cutoff\n    """"""\n    ret, _, _ = S2gate(r, theta, cutoff=trunc)\n\n    ret = np.transpose(ret, [0, 2, 1, 3])\n\n    return ret\n\n\n@functools.lru_cache()\ndef kerr(kappa, trunc):\n    r""""""\n    The Kerr interaction :math:`K(\\kappa)`.\n    """"""\n    n = np.arange(trunc)\n    ret = np.diag(np.exp(1j * kappa * n ** 2))\n    return ret\n\n\n@functools.lru_cache()\ndef cross_kerr(kappa, trunc):\n    r""""""\n    The cross-Kerr interaction :math:`CK(\\kappa)`.\n    """"""\n    n1 = np.arange(trunc)[None, :]\n    n2 = np.arange(trunc)[:, None]\n    n1n2 = np.ravel(n1 * n2)\n    ret = np.diag(np.exp(1j * kappa * n1n2)).reshape([trunc] * 4).swapaxes(1, 2)\n    return ret\n\n\n@functools.lru_cache()\ndef cubicPhase(gamma, hbar, trunc):\n    r""""""\n    The cubic phase gate :math:`\\exp{(i\\frac{\\gamma}{3\\hbar}\\hat{x}^3)}`.\n    """"""\n    a_ = a(trunc)\n    x = (a_ + np.conj(a_).T) * np.sqrt(hbar / 2)\n    x3 = x @ x @ x\n    ret = matrixExp(1j * gamma / (3 * hbar) * x3)\n\n    return ret\n\n\n@functools.lru_cache()\ndef phase(theta, trunc):\n    r""""""\n    The phase gate :math:`R(\\theta)`\n    """"""\n    return np.array(np.diag([exp(1j * n * theta) for n in range(trunc)]), dtype=def_type)\n\n\n@functools.lru_cache()\ndef beamsplitter(t, r, phi, trunc):\n    r"""""" The beamsplitter :math:`B(cos^{-1} t, phi)`.\n\n    Uses the `BSgate operation from The Walrus`_ to calculate the beamsplitter.\n\n    .. _`BSgate operation from The Walrus`: https://the-walrus.readthedocs.io/en/latest/code/api/thewalrus.fock_gradients.BSgate.html\n    """"""\n    # pylint: disable=bad-whitespace\n\n    theta = np.arccos(t)\n    BS_tw, _, _ = BSgate(theta, phi, cutoff=trunc)\n\n    # TODO: Transpose needed because of different conventions in SF and The Walrus. Remove when The Walrus is updated.\n    return BS_tw.transpose((0, 2, 1, 3))\n\n\n@functools.lru_cache()\ndef proj(i, j, trunc):\n    r""""""\n    The projector :math:`P = \\ket{j}\\bra{i}`.\n    """"""\n    P = np.zeros((trunc, trunc), dtype=def_type)\n    P[j][i] = 1.0 + 0.0j\n    return P\n\n\n# ============================================\n#\n# State vectors\n#\n# ============================================\n\n\ndef vacuumState(n, trunc):\n    r""""""\n    The `n`-mode vacuum state :math:`\\ket{00\\dots 0}`\n    """"""\n\n    state = np.zeros([trunc for i in range(n)], dtype=def_type)\n    state.ravel()[0] = 1.0 + 0.0j\n    return state\n\n\ndef vacuumStateMixed(n, trunc):\n    r""""""\n    The `n`-mode mixed vacuum state :math:`\\ket{00\\dots 0}\\bra{00\\dots 0}`\n    """"""\n\n    state = np.zeros([trunc for i in range(n * 2)], dtype=def_type)\n    state.ravel()[0] = 1.0 + 0.0j\n    return state\n\n\n@functools.lru_cache()\ndef fockState(n, trunc):\n    r""""""\n    The Fock state :math:`\\ket{n}`.\n    """"""\n    return array([1.0 + 0.0j if i == n else 0.0 + 0.0j for i in range(trunc)])\n\n\n@functools.lru_cache()\ndef coherentState(alpha, trunc):\n    r""""""\n    The coherent state :math:`D(\\alpha)\\ket{0}`.\n    """"""\n\n    def entry(n):\n        """"""coherent summation term""""""\n        return alpha ** n / sqrt(fac(n))\n\n    return exp(-abssqr(alpha) / 2) * array([entry(n) for n in range(trunc)])\n\n\n@functools.lru_cache()\ndef squeezedState(r, theta, trunc):\n    r""""""\n    The squeezed state :math:`S(re^{i\\theta})`.\n    """"""\n\n    def entry(n):\n        """"""squeezed summation term""""""\n        return (sqrt(fac(2 * n)) / (2 ** n * fac(n))) * (-exp(1j * theta) * tanh(r)) ** n\n\n    vec = array([entry(n // 2) if n % 2 == 0 else 0.0 + 0.0j for n in range(trunc)])\n    return sqrt(1 / cosh(r)) * vec\n\n\n@functools.lru_cache()\ndef displacedSqueezed(alpha, r, phi, trunc):\n    r""""""\n    The displaced squeezed state :math:`\\ket{\\alpha,\\zeta} = D(\\alpha)S(r\\exp{(i\\phi)})\\ket{0}`.\n    """"""\n    if r == 0:\n        return coherentState(alpha, trunc)\n\n    if alpha == 0:\n        return squeezedState(r, phi, trunc)\n\n    ph = np.exp(1j * phi)\n    ch = cosh(r)\n    sh = sinh(r)\n    th = tanh(r)\n\n    gamma = alpha * ch + np.conj(alpha) * ph * sh\n    hermite_arg = gamma / np.sqrt(ph * np.sinh(2 * r) + 1e-10)\n\n    # normalization constant\n    N = np.exp(-0.5 * np.abs(alpha) ** 2 - 0.5 * np.conj(alpha) ** 2 * ph * th)\n\n    coeff = np.array([(0.5 * ph * th) ** (n / 2) / np.sqrt(fac(n) * ch) for n in range(trunc)])\n    vec = np.array([H(hermite_arg, row) for row in np.diag(coeff)])\n    state = N * vec\n\n    return state\n\n\n@functools.lru_cache()\ndef thermalState(nbar, trunc):\n    r""""""\n    The thermal state :math:`\\rho(\\overline{nbar})`.\n    """"""\n    if nbar == 0:\n        st = fockState(0, trunc)\n        state = np.outer(st, st.conjugate())\n    else:\n        coeff = np.array([nbar ** n / (nbar + 1) ** (n + 1) for n in range(trunc)])\n        state = np.diag(coeff)\n\n    return state\n\n\n# ============================================\n#\n# Channels (Kraus operators)\n#\n# ============================================\n\n\n@functools.lru_cache()\ndef lossChannel(T, trunc):\n    r""""""\n    The Kraus operators for the loss channel :math:`\\mathcal{N}(T)`.\n    """"""\n\n    TToAdaggerA = np.array(np.diag([T ** (i / 2) for i in range(trunc)]), dtype=def_type)\n\n    def aToN(n):\n        """"""the nth matrix power of the annihilation operator matrix a""""""\n        return np.linalg.matrix_power(a(trunc), n)\n\n    def E(n):\n        """"""the loss channel amplitudes in the Fock basis""""""\n        return ((1 - T) / T) ** (n / 2) * np.dot(aToN(n) / sqrt(fac(n)), TToAdaggerA)\n\n    if T == 0:\n        return [proj(i, 0, trunc) for i in range(trunc)]\n\n    return [E(n) for n in range(trunc)]\n\n\n# ============================================\n#\n# Misc\n#\n# ============================================\n\n\n@functools.lru_cache()\ndef hermiteVals(q_mag, num_bins, m_omega_over_hbar, trunc):\n    """"""\n    Helper function for homodyne measurements. Computes a range of (physicist\'s)\n    Hermite polynomials at a particular vector.\n    """"""\n    q_tensor = np.linspace(-q_mag, q_mag, num_bins)\n    x = np.sqrt(m_omega_over_hbar) * q_tensor\n\n    Hvals = [None] * trunc\n    Hvals[0] = 1\n    Hvals[1] = 2 * x\n    for i in range(2, trunc):\n        Hvals[i] = 2 * x * Hvals[i - 1] - 2 * (i - 1) * Hvals[i - 2]\n\n    return q_tensor, Hvals\n'"
strawberryfields/backends/gaussianbackend/__init__.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nr""""""Gaussian simulator backend""""""\n\nfrom .backend import GaussianBackend\nfrom .states import GaussianState\n'"
strawberryfields/backends/gaussianbackend/backend.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# pylint: disable=too-many-public-methods\n""""""Gaussian backend""""""\nimport warnings\n\nfrom numpy import (\n    empty,\n    concatenate,\n    array,\n    identity,\n    arctan2,\n    angle,\n    sqrt,\n    dot,\n    vstack,\n    zeros_like,\n    allclose,\n    ix_,\n)\nfrom numpy.linalg import inv\nfrom thewalrus.samples import hafnian_sample_state, torontonian_sample_state\n\nfrom strawberryfields.backends import BaseGaussian\nfrom strawberryfields.backends.shared_ops import changebasis\n\nfrom .ops import xmat\nfrom .gaussiancircuit import GaussianModes\nfrom .states import GaussianState\n\n\nclass GaussianBackend(BaseGaussian):\n    r""""""The GaussianBackend implements a simulation of quantum optical circuits\n    in NumPy using the Gaussian formalism, returning a :class:`~.GaussianState`\n    state object.\n\n    The primary component of the GaussianBackend is a\n    :attr:`~.GaussianModes` object which is used to simulate a multi-mode quantum optical system.\n    :class:`~.GaussianBackend` provides the basic API-compatible interface to the simulator, while the\n    :attr:`~.GaussianModes` object actually carries out the mathematical simulation.\n\n    The :attr:`GaussianModes` simulators maintain an internal covariance matrix & vector of means\n    representation of a multi-mode quantum optical system.\n\n    Note that unlike commonly used covariance matrix representations we encode our state in two complex\n    matrices :math:`N` and :math:`M` that are defined as follows\n    :math:`N_{i,j} = \\langle a^\\dagger _i a_j \\rangle`\n    :math:`M_{i,j} = \\langle a _i a_j \\rangle`\n    and a vector of means :math:`\\alpha_i =\\langle a_i \\rangle`.\n\n    .. \n        .. currentmodule:: strawberryfields.backends.gaussianbackend\n        .. autosummary::\n            :toctree: api\n\n            ~gaussiancircuit.GaussianModes\n            ~ops\n    """"""\n\n    short_name = ""gaussian""\n    circuit_spec = ""gaussian""\n\n    def __init__(self):\n        """"""Initialize the backend.\n        """"""\n        super().__init__()\n        self._supported[""mixed_states""] = True\n        self._init_modes = None\n        self.circuit = None\n\n    def begin_circuit(self, num_subsystems, **kwargs):\n        self._init_modes = num_subsystems\n        self.circuit = GaussianModes(num_subsystems)\n\n    def add_mode(self, n=1):\n        self.circuit.add_mode(n)\n\n    def del_mode(self, modes):\n        self.circuit.del_mode(modes)\n\n    def get_modes(self):\n        return self.circuit.get_modes()\n\n    def reset(self, pure=True, **kwargs):\n        self.circuit.reset(self._init_modes)\n\n    def prepare_thermal_state(self, nbar, mode):\n        self.circuit.init_thermal(nbar, mode)\n\n    def prepare_vacuum_state(self, mode):\n        self.circuit.loss(0.0, mode)\n\n    def prepare_coherent_state(self, alpha, mode):\n        self.circuit.loss(0.0, mode)\n        self.circuit.displace(alpha, mode)\n\n    def prepare_squeezed_state(self, r, phi, mode):\n        self.circuit.loss(0.0, mode)\n        self.circuit.squeeze(r, phi, mode)\n\n    def prepare_displaced_squeezed_state(self, alpha, r, phi, mode):\n        self.circuit.loss(0.0, mode)\n        self.circuit.squeeze(r, phi, mode)\n        self.circuit.displace(alpha, mode)\n\n    def rotation(self, phi, mode):\n        self.circuit.phase_shift(phi, mode)\n\n    def displacement(self, alpha, mode):\n        self.circuit.displace(alpha, mode)\n\n    def squeeze(self, z, mode):\n        phi = angle(z)\n        r = abs(z)\n        self.circuit.squeeze(r, phi, mode)\n\n    def beamsplitter(self, t, r, mode1, mode2):\n        if isinstance(t, complex):\n            raise ValueError(""Beamsplitter transmittivity t must be a float."")\n        theta = arctan2(abs(r), t)\n        phi = angle(r)\n        self.circuit.beamsplitter(-theta, -phi, mode1, mode2)\n\n    def measure_homodyne(self, phi, mode, shots=1, select=None, **kwargs):\n        r""""""Measure a :ref:`phase space quadrature <homodyne>` of the given mode.\n\n        See :meth:`.BaseBackend.measure_homodyne`.\n\n        Keyword Args:\n            eps (float): Homodyne amounts to projection onto a quadrature eigenstate.\n                This eigenstate is approximated by a squeezed state whose variance has been\n                squeezed to the amount ``eps``, :math:`V_\\text{meas} = \\texttt{eps}^2`.\n                Perfect homodyning is obtained when ``eps`` :math:`\\to 0`.\n\n        Returns:\n            float: measured value\n        """"""\n        if shots != 1:\n            if select is not None:\n                raise NotImplementedError(\n                    ""Gaussian backend currently does not support ""\n                    ""postselection if shots != 1 for homodyne measurement""\n                )\n\n            raise NotImplementedError(\n                ""Gaussian backend currently does not support "" ""shots != 1 for homodyne measurement""\n            )\n\n        # phi is the rotation of the measurement operator, hence the minus\n        self.circuit.phase_shift(-phi, mode)\n\n        if select is None:\n            qs = self.circuit.homodyne(mode, **kwargs)[0, 0]\n        else:\n            val = select * 2 / sqrt(2 * self.circuit.hbar)\n            qs = self.circuit.post_select_homodyne(mode, val, **kwargs)\n\n        return qs * sqrt(2 * self.circuit.hbar) / 2\n\n    def measure_heterodyne(self, mode, shots=1, select=None):\n\n        if shots != 1:\n            if select is not None:\n                raise NotImplementedError(\n                    ""Gaussian backend currently does not support ""\n                    ""postselection if shots != 1 for heterodyne measurement""\n                )\n\n            raise NotImplementedError(\n                ""Gaussian backend currently does not support ""\n                ""shots != 1 for heterodyne measurement""\n            )\n\n        if select is None:\n            m = identity(2)\n            res = 0.5 * self.circuit.measure_dyne(m, [mode], shots=shots)\n            return res[0, 0] + 1j * res[0, 1]\n\n        res = select\n        self.circuit.post_select_heterodyne(mode, select)\n\n        return res\n\n    def prepare_gaussian_state(self, r, V, modes):\n        if isinstance(modes, int):\n            modes = [modes]\n\n        # make sure number of modes matches shape of r and V\n        N = len(modes)\n        if len(r) != 2 * N:\n            raise ValueError(""Length of means vector must be twice the number of modes."")\n        if V.shape != (2 * N, 2 * N):\n            raise ValueError(\n                ""Shape of covariance matrix must be [2N, 2N], where N is the number of modes.""\n            )\n\n        # convert xp-ordering to symmetric ordering\n        means = vstack([r[:N], r[N:]]).reshape(-1, order=""F"")\n        C = changebasis(N)\n        cov = C @ V @ C.T\n\n        self.circuit.fromscovmat(cov, modes)\n        self.circuit.fromsmean(means, modes)\n\n    def is_vacuum(self, tol=0.0, **kwargs):\n        return self.circuit.is_vacuum(tol)\n\n    def loss(self, T, mode):\n        self.circuit.loss(T, mode)\n\n    def thermal_loss(self, T, nbar, mode):\n        self.circuit.thermal_loss(T, nbar, mode)\n\n    def measure_fock(self, modes, shots=1, select=None):\n        if shots != 1:\n            if select is not None:\n                raise NotImplementedError(\n                    ""Gaussian backend currently does not support "" ""postselection""\n                )\n            warnings.warn(\n                ""Cannot simulate non-Gaussian states. ""\n                ""Conditional state after Fock measurement has not been updated.""\n            )\n\n        mu = self.circuit.mean\n        mean = self.circuit.smeanxp()\n        cov = self.circuit.scovmatxp()\n\n        x_idxs = array(modes)\n        p_idxs = x_idxs + len(mu)\n        modes_idxs = concatenate([x_idxs, p_idxs])\n        reduced_cov = cov[ix_(modes_idxs, modes_idxs)]\n        reduced_mean = mean[modes_idxs]\n        # check we are sampling from a gaussian state with zero mean\n        if allclose(mu, zeros_like(mu)):\n            samples = hafnian_sample_state(reduced_cov, shots)\n        else:\n            samples = hafnian_sample_state(reduced_cov, shots, mean=reduced_mean)\n        # for backward compatibility with previous measurement behaviour,\n        # if only one shot, then we drop the shots axis\n        if shots == 1:\n            samples = samples.reshape((len(modes),))\n        return samples\n\n    def measure_threshold(self, modes, shots=1, select=None):\n        if shots != 1:\n            if select is not None:\n                raise NotImplementedError(\n                    ""Gaussian backend currently does not support "" ""postselection""\n                )\n            warnings.warn(\n                ""Cannot simulate non-Gaussian states. ""\n                ""Conditional state after Threshold measurement has not been updated.""\n            )\n\n        mu = self.circuit.mean\n        cov = self.circuit.scovmatxp()\n        # check we are sampling from a gaussian state with zero mean\n        if not allclose(mu, zeros_like(mu)):\n            raise NotImplementedError(\n                ""Threshold measurement is only supported for "" ""Gaussian states with zero mean""\n            )\n        x_idxs = array(modes)\n        p_idxs = x_idxs + len(mu)\n        modes_idxs = concatenate([x_idxs, p_idxs])\n        reduced_cov = cov[ix_(modes_idxs, modes_idxs)]\n        samples = torontonian_sample_state(reduced_cov, shots)\n        # for backward compatibility with previous measurement behaviour,\n        # if only one shot, then we drop the shots axis\n        if shots == 1:\n            samples = samples.reshape((len(modes),))\n        return samples\n\n    def state(self, modes=None, **kwargs):\n        """"""Returns the state of the quantum simulation.\n\n        See :meth:`.BaseBackend.state`.\n\n        Returns:\n            GaussianState: state description\n        """"""\n        m = self.circuit.scovmat()\n        r = self.circuit.smean()\n\n        if modes is None:\n            modes = list(range(len(self.get_modes())))\n\n        listmodes = list(concatenate((2 * array(modes), 2 * array(modes) + 1)))\n        covmat = empty((2 * len(modes), 2 * len(modes)))\n        means = r[listmodes]\n\n        for i, ii in enumerate(listmodes):\n            for j, jj in enumerate(listmodes):\n                covmat[i, j] = m[ii, jj]\n\n        means *= sqrt(2 * self.circuit.hbar) / 2\n        covmat *= self.circuit.hbar / 2\n\n        mode_names = [""q[{}]"".format(i) for i in array(self.get_modes())[modes]]\n\n        # qmat and amat\n        qmat = self.circuit.qmat()\n        N = qmat.shape[0] // 2\n\n        # work out if qmat and Amat need to be reduced\n        if 1 <= len(modes) < N:\n            # reduce qmat\n            ind = concatenate([array(modes), N + array(modes)])\n            rows = ind.reshape((-1, 1))\n            cols = ind.reshape((1, -1))\n            qmat = qmat[rows, cols]\n\n            # calculate reduced Amat\n            N = qmat.shape[0] // 2\n            Amat = dot(xmat(N), identity(2 * N) - inv(qmat))\n        else:\n            Amat = self.circuit.Amat()\n\n        return GaussianState((means, covmat), len(modes), qmat, Amat, mode_names=mode_names)\n'"
strawberryfields/backends/gaussianbackend/gaussiancircuit.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Gaussian circuit operations""""""\n# pylint: disable=duplicate-code,attribute-defined-outside-init\nimport numpy as np\nfrom . import ops\nfrom ..shared_ops import changebasis\n\n\nclass GaussianModes:\n    """""" Base class for representing and operating on a collection of\n    continuous variable modes in the symplectic basis as encoded in a\n    covariance matrix and a mean vector.\n    The modes are initialized in the (multimode) vacuum state,\n    The state of the modes is manipulated by calling the various methods.""""""\n\n    # pylint: disable=too-many-public-methods\n\n    def __init__(self, num_subsystems):\n        r""""""The class is initialized by providing an integer indicating the number of modes\n        Unlike the ""standard"" covariance matrix for the Wigner function that uses symmetric ordering\n        as defined in e.g.\n        [1] Gaussian quantum information\n        Christian Weedbrook, Stefano Pirandola, Ra\xc3\xbal Garc\xc3\xada-Patr\xc3\xb3n, Nicolas J. Cerf, Timothy C. Ralph, Jeffrey H. Shapiro, and Seth Lloyd\n        Rev. Mod. Phys. 84, 621 \xe2\x80\x93 Published 1 May 2012\n        we define covariance matrices in terms of the following two quantities:\n        $$\n        N_{i,j} =\\langle a_i^\\dagger a_j \\rangle\n        M_{i,j} = \\langle a_i a_j \\rangle\n        $$\n        Note that the matrix $N$ is hermitian and the matrix M is symmetric.\n        The mean displacements are stored as expectation values of the destruction operator $\\alpha_i  = \\langle a_i \\rangle$\n        We also provide functions that give the symmetric ordered covariance matrices and the mean displacement for the quadrature\n        operators $q = a+a^\\dagger$ and $p = i(a^\\dagger -a)$. Note that with these conventions $[q,p]=2 i$.\n        For vacuum one has $N_{i,j}=M_{i,j}=alpha_i =0$,\n        The quantities $N,M,\\alpha$ are stored in the variable nmat, mmat, mean respectively\n        """"""\n        # Check validity\n        if not isinstance(num_subsystems, int):\n            raise ValueError(""Number of modes must be an integer"")\n\n        self.hbar = 2\n        self.reset(num_subsystems)\n\n    def add_mode(self, n=1):\n        """"""add mode to the circuit""""""\n        newnlen = self.nlen + n\n        newnmat = np.zeros((newnlen, newnlen), dtype=complex)\n        newmmat = np.zeros((newnlen, newnlen), dtype=complex)\n        newmean = np.zeros(newnlen, dtype=complex)\n        newactive = list(np.arange(newnlen, dtype=int))\n\n        for i in range(self.nlen):\n            newmean[i] = self.mean[i]\n            newactive[i] = self.active[i]\n            for j in range(self.nlen):\n                newnmat[i, j] = self.nmat[i, j]\n                newmmat[i, j] = self.mmat[i, j]\n\n        self.mean = newmean\n        self.nmat = newnmat\n        self.mmat = newmmat\n        self.active = newactive\n        self.nlen = newnlen\n\n    def del_mode(self, modes):\n        """""" delete mode from the circuit""""""\n        if isinstance(modes, int):\n            modes = [modes]\n\n        for mode in modes:\n            if self.active[mode] is None:\n                raise ValueError(""Cannot delete mode, mode does not exist"")\n\n            self.loss(0.0, mode)\n            self.active[mode] = None\n\n    def reset(self, num_subsystems=None):\n        """"""Resets the simulation state.\n\n        Args:\n            num_subsystems (int, optional): Sets the number of modes in the reset\n                circuit. None means unchanged.\n        """"""\n        if num_subsystems is not None:\n            if not isinstance(num_subsystems, int):\n                raise ValueError(""Number of modes must be an integer"")\n            self.nlen = num_subsystems\n\n        self.nmat = np.zeros((self.nlen, self.nlen), dtype=complex)\n        self.mmat = np.zeros((self.nlen, self.nlen), dtype=complex)\n        self.mean = np.zeros(self.nlen, dtype=complex)\n        self.active = list(np.arange(self.nlen, dtype=int))\n\n    def get_modes(self):\n        """"""return the modes currently active""""""\n        return [x for x in self.active if x is not None]\n\n    def displace(self, beta, i):\n        """""" Implements a displacement operation by the complex number beta in mode i""""""\n        # Update displacement of mode i by the complex amount bet\n        if self.active[i] is None:\n            raise ValueError(""Cannot displace mode, mode does not exist"")\n\n        self.mean[i] += beta\n\n    def squeeze(self, r, phi, k):\n        """""" Implements a squeezing operation in mode k by the amount z = r*exp(1j*phi).""""""\n        if self.active[k] is None:\n            raise ValueError(""Cannot squeeze mode, mode does not exist"")\n\n        phase = np.exp(1j * phi)\n        phase2 = phase * phase\n        sh = np.sinh(r)\n        ch = np.cosh(r)\n        sh2 = sh * sh\n        ch2 = ch * ch\n        shch = sh * ch\n        nk = np.copy(self.nmat[k])\n        mk = np.copy(self.mmat[k])\n\n        alphak = np.copy(self.mean[k])\n        # Update displacement of mode k\n        self.mean[k] = alphak * ch - phase * np.conj(alphak) * sh\n        # Update covariance matrix elements. Only the k column and row of nmat and mmat need to be updated.\n        # First update the diagonal elements\n        self.nmat[k, k] = (\n            sh2\n            - phase * shch * np.conj(mk[k])\n            - shch * np.conj(phase) * mk[k]\n            + ch2 * nk[k]\n            + sh2 * nk[k]\n        )\n        self.mmat[k, k] = (\n            -(phase * shch) + phase2 * sh2 * np.conj(mk[k]) + ch2 * mk[k] - 2 * phase * shch * nk[k]\n        )\n\n        # Update the column k\n        for l in np.delete(np.arange(self.nlen), k):\n            self.nmat[k, l] = -(sh * np.conj(phase) * mk[l]) + ch * nk[l]\n            self.mmat[k, l] = ch * mk[l] - phase * sh * nk[l]\n\n        # Update row k\n        self.nmat[:, k] = np.conj(self.nmat[k])\n        self.mmat[:, k] = self.mmat[k]\n\n    def phase_shift(self, phi, k):\n        """""" Implements a phase shift in mode k by the amount phi.""""""\n        if self.active[k] is None:\n            raise ValueError(""Cannot phase shift mode, mode does not exist"")\n\n        phase = np.exp(1j * phi)\n        phase2 = phase * phase\n        # Update displacement of mode k\n        self.mean[k] = self.mean[k] * phase\n\n        # Update covariance matrix elements. Only the k column and row of nmat and mmat need to be updated.\n        # First update the diagonal elements\n        self.mmat[k][k] = phase2 * self.mmat[k][k]\n\n        # Update the column k\n        for l in np.delete(np.arange(self.nlen), k):\n            self.nmat[k][l] = np.conj(phase) * self.nmat[k][l]\n            self.mmat[k][l] = phase * self.mmat[k][l]\n\n        # Update row k\n        self.nmat[:, k] = np.conj(self.nmat[k])\n        self.mmat[:, k] = self.mmat[k]\n\n    def beamsplitter(self, theta, phi, k, l):\n        """""" Implements a beam splitter operation between modes k and l by the amount theta, phi""""""\n        if self.active[k] is None or self.active[l] is None:\n            raise ValueError(""Cannot perform beamsplitter, mode(s) do not exist"")\n\n        if k == l:\n            raise ValueError(""Cannot use the same mode for beamsplitter inputs"")\n\n        phase = np.exp(1j * phi)\n        phase2 = phase * phase\n        sh = np.sin(theta)\n        ch = np.cos(theta)\n        sh2 = sh * sh\n        ch2 = ch * ch\n        shch = sh * ch\n        # alpha1 = self.mean[0]\n\n        nk = np.copy(self.nmat[k])\n        mk = np.copy(self.mmat[k])\n        nl = np.copy(self.nmat[l])\n        ml = np.copy(self.mmat[l])\n        # Update displacement of mode k and l\n        alphak = np.copy(self.mean[k])\n        alphal = np.copy(self.mean[l])\n        self.mean[k] = ch * alphak + phase * sh * alphal\n        self.mean[l] = ch * alphal - np.conj(phase) * sh * alphak\n        # Update covariance matrix elements. Only the k and l columns and rows of nmat and mmat need to be updated.\n        # First update the (k,k), (k,l), (l,l), and (l,l) elements\n        self.nmat[k][k] = (\n            ch2 * nk[k] + phase * shch * nk[l] + shch * np.conj(phase) * nl[k] + sh2 * nl[l]\n        )\n        self.nmat[k][l] = (\n            -(shch * np.conj(phase) * nk[k])\n            + ch2 * nk[l]\n            - sh2 * np.conj(phase2) * nl[k]\n            + shch * np.conj(phase) * nl[l]\n        )\n        self.nmat[l][k] = np.conj(self.nmat[k][l])\n        self.nmat[l][l] = (\n            sh2 * nk[k] - phase * shch * nk[l] - shch * np.conj(phase) * nl[k] + ch2 * nl[l]\n        )\n\n        self.mmat[k][k] = ch2 * mk[k] + 2 * phase * shch * ml[k] + phase2 * sh2 * ml[l]\n        self.mmat[k][l] = (\n            -(shch * np.conj(phase) * mk[k]) + ch2 * ml[k] - sh2 * ml[k] + phase * shch * ml[l]\n        )\n        self.mmat[l][k] = self.mmat[k][l]\n        self.mmat[l][l] = (\n            sh2 * np.conj(phase2) * mk[k] - 2 * shch * np.conj(phase) * ml[k] + ch2 * ml[l]\n        )\n\n        # Update columns k and l\n        for i in np.delete(np.arange(self.nlen), (k, l)):\n            self.nmat[k][i] = ch * nk[i] + sh * np.conj(phase) * nl[i]\n            self.mmat[k][i] = ch * mk[i] + phase * sh * ml[i]\n            self.nmat[l][i] = -(phase * sh * nk[i]) + ch * nl[i]\n            self.mmat[l][i] = -(sh * np.conj(phase) * mk[i]) + ch * ml[i]\n\n        # Update rows k and l\n        self.nmat[:, k] = np.conj(self.nmat[k])\n        self.mmat[:, k] = self.mmat[k]\n        self.nmat[:, l] = np.conj(self.nmat[l])\n        self.mmat[:, l] = self.mmat[l]\n\n    def scovmatxp(self):\n        r""""""Constructs and returns the symmetric ordered covariance matrix in the xp ordering.\n\n        The order for the canonical operators is :math:`q_1,..,q_n, p_1,...,p_n`.\n        This differs from the ordering used in [1] which is :math:`q_1,p_1,q_2,p_2,...,q_n,p_n`\n        Note that one ordering can be obtained from the other by using a permutation matrix.\n\n        Said permutation matrix is implemented in the function changebasis(n) where n is\n        the number of modes.\n        """"""\n        mm11 = (\n            self.nmat\n            + np.transpose(self.nmat)\n            + self.mmat\n            + np.conj(self.mmat)\n            + np.identity(self.nlen)\n        )\n        mm12 = 1j * (\n            -np.transpose(self.mmat)\n            + np.transpose(np.conj(self.mmat))\n            + np.transpose(self.nmat)\n            - self.nmat\n        )\n        mm22 = (\n            self.nmat\n            + np.transpose(self.nmat)\n            - self.mmat\n            - np.conj(self.mmat)\n            + np.identity(self.nlen)\n        )\n        return np.concatenate(\n            (\n                np.concatenate((mm11, mm12), axis=1),\n                np.concatenate((np.transpose(mm12), mm22), axis=1),\n            ),\n            axis=0,\n        ).real\n\n    def smeanxp(self):\n        r""""""Constructs and returns the symmetric ordered vector of mean in the xp ordering.\n\n        The order for the canonical operators is :math:`q_1, \\ldots, q_n, p_1, \\ldots, p_n`.\n        This differs from the ordering used in [1] which is :math:`q_1, p_1, q_2, p_2, \\ldots, q_n, p_n`.\n        Note that one ordering can be obtained from the other by using a permutation matrix.\n\n        Said permutation matrix is implemented in the function changebasis(n) where n is\n        the number of modes.\n        """"""\n        nmodes = self.nlen\n        r = np.empty(2 * nmodes)\n        r[0:nmodes] = 2 * self.mean.real\n        r[nmodes : 2 * nmodes] = 2 * self.mean.imag\n        return r\n\n    def scovmat(self):\n        """"""Constructs and returns the symmetric ordered covariance matrix as defined in [1]\n        """"""\n        rotmat = changebasis(self.nlen)\n        return np.dot(np.dot(rotmat, self.scovmatxp()), np.transpose(rotmat))\n\n    def smean(self):\n        r""""""the symmetric mean $[q_1,p_1,q_2,p_2,...,q_n,p_n]$""""""\n        r = np.empty(2 * self.nlen)\n        for i in range(self.nlen):\n            r[2 * i] = 2 * self.mean[i].real\n            r[2 * i + 1] = 2 * self.mean[i].imag\n        return r\n\n    def fromsmean(self, r, modes=None):\n        r""""""Populates the means from a provided vector of means with hbar=2 assumed.\n\n        Args:\n            r (array): vector of means in :math:`(x_1,p_1,x_2,p_2,\\dots)` ordering\n            modes (Sequence): sequence of modes corresponding to the vector of means\n        """"""\n        mode_list = modes\n        if modes is None:\n            mode_list = range(self.nlen)\n\n        for idx, mode in enumerate(mode_list):\n            self.mean[mode] = 0.5 * (r[2 * idx] + 1j * r[2 * idx + 1])\n\n    def fromscovmat(self, V, modes=None):\n        r""""""Updates the circuit\'s state when a standard covariance matrix is provided.\n\n        Args:\n            V (array): covariance matrix in symmetric ordering\n            modes (Sequence): sequence of modes corresponding to the covariance matrix\n        """"""\n        if modes is None:\n            n = len(V) // 2\n            modes = np.arange(self.nlen)\n\n            if n != self.nlen:\n                raise ValueError(\n                    ""Covariance matrix is the incorrect size, does not match means vector.""\n                )\n        else:\n            n = len(modes)\n            modes = np.array(modes)\n            if n > self.nlen:\n                raise ValueError(""Covariance matrix is larger than the number of subsystems."")\n\n        # convert to xp ordering\n        rotmat = changebasis(n)\n        VV = np.dot(np.dot(np.transpose(rotmat), V), rotmat)\n\n        A = VV[0:n, 0:n]\n        B = VV[0:n, n : 2 * n]\n        C = VV[n : 2 * n, n : 2 * n]\n        Bt = np.transpose(B)\n\n        if n < self.nlen:\n            # reset modes to be prepared back to the vacuum state\n            for mode in modes:\n                self.loss(0.0, mode)\n\n        rows = modes.reshape(-1, 1)\n        cols = modes.reshape(1, -1)\n        self.nmat[rows, cols] = 0.25 * (A + C + 1j * (B - Bt) - 2 * np.identity(n))\n        self.mmat[rows, cols] = 0.25 * (A - C + 1j * (B + Bt))\n\n    def qmat(self, modes=None):\n        """""" Construct the covariance matrix for the Q function""""""\n        if modes is None:\n            modes = list(range(self.nlen))\n\n        rows = np.reshape(modes, [-1, 1])\n        cols = np.reshape(modes, [1, -1])\n\n        sigmaq = np.concatenate(\n            (\n                np.concatenate(\n                    (self.nmat[rows, cols], np.conjugate(self.mmat[rows, cols])), axis=1\n                ),\n                np.concatenate(\n                    (self.mmat[rows, cols], np.conjugate(self.nmat[rows, cols])), axis=1\n                ),\n            ),\n            axis=0,\n        ) + np.identity(2 * len(modes))\n        return sigmaq\n\n    def fidelity_coherent(self, alpha, modes=None):\n        """""" Returns a function that evaluates the Q function of the given state """"""\n        if modes is None:\n            modes = list(range(self.nlen))\n\n        Q = self.qmat(modes)\n        Qi = np.linalg.inv(Q)\n        delta = self.mean[modes] - alpha\n\n        delta = np.concatenate((delta, np.conjugate(delta)))\n        return np.sqrt(np.linalg.det(Qi).real) * np.exp(\n            -0.5 * np.dot(delta, np.dot(Qi, np.conjugate(delta))).real\n        )\n\n    def fidelity_vacuum(self, modes=None):\n        """"""fidelity of the current state with the vacuum state""""""\n        if modes is None:\n            modes = list(range(self.nlen))\n\n        alpha = np.zeros(len(modes))\n        return self.fidelity_coherent(alpha)\n\n    def Amat(self):\n        """""" Constructs the A matrix from Hamilton\'s paper""""""\n        ######### this needs to be conjugated\n        sigmaq = np.concatenate(\n            (\n                np.concatenate((np.transpose(self.nmat), self.mmat), axis=1),\n                np.concatenate((np.transpose(np.conjugate(self.mmat)), self.nmat), axis=1),\n            ),\n            axis=0,\n        ) + np.identity(2 * self.nlen)\n        return np.dot(ops.xmat(self.nlen), np.identity(2 * self.nlen) - np.linalg.inv(sigmaq))\n\n    def loss(self, T, k):\n        r""""""Implements a loss channel in mode k by amplitude loss amount \\sqrt{T}\n        (energy loss amount T)""""""\n        if self.active[k] is None:\n            raise ValueError(""Cannot apply loss channel, mode does not exist"")\n\n        sqrtT = np.sqrt(T)\n        self.nmat[k] = sqrtT * self.nmat[k]\n        self.mmat[k] = sqrtT * self.mmat[k]\n\n        self.nmat[k][k] = sqrtT * self.nmat[k][k]\n        self.mmat[k][k] = sqrtT * self.mmat[k][k]\n\n        self.nmat[:, k] = np.conj(self.nmat[k])\n        self.mmat[:, k] = self.mmat[k]\n        self.mean[k] = sqrtT * self.mean[k]\n\n    def thermal_loss(self, T, nbar, k):\n        r"""""" Implements the thermal loss channel in mode k by amplitude loss amount \\sqrt{T}\n        unlike the loss channel, here the ancilliary mode that goes into the second arm of the\n        beam splitter is prepared in a thermal state with mean photon number nth """"""\n        if self.active[k] is None:\n            raise ValueError(""Cannot apply loss channel, mode does not exist"")\n\n        self.loss(T, k)\n        self.nmat += (1 - T) * nbar\n\n    def init_thermal(self, population, mode):\n        """""" Initializes a state of mode in a thermal state with the given population""""""\n        self.loss(0.0, mode)\n        self.nmat[mode][mode] = population\n\n    def is_vacuum(self, tol=0.0):\n        """""" Checks if the state is vacuum by calculating its fidelity with vacuum """"""\n        fid = self.fidelity_vacuum()\n        return np.abs(fid - 1) <= tol\n\n    def measure_dyne(self, covmat, indices, shots=1):\n        """""" Performs the general-dyne measurement specified in covmat, the indices should correspond\n        with the ordering of the covmat of the measurement\n        covmat specifies a gaussian effect via its covariance matrix. For more information see\n        Quantum Continuous Variables: A Primer of Theoretical Methods\n        by Alessio Serafini page 129\n        """"""\n        if covmat.shape != (2 * len(indices), 2 * len(indices)):\n            raise ValueError(""Covariance matrix size does not match indices provided"")\n\n        for i in indices:\n            if self.active[i] is None:\n                raise ValueError(""Cannot apply homodyne measurement, mode does not exist"")\n\n        expind = np.concatenate((2 * np.array(indices), 2 * np.array(indices) + 1))\n        mp = self.scovmat()\n        (A, B, C) = ops.chop_in_blocks(mp, expind)\n        V = A - np.dot(np.dot(B, np.linalg.inv(C + covmat)), np.transpose(B))\n        V1 = ops.reassemble(V, expind)\n        self.fromscovmat(V1)\n\n        r = self.smean()\n        (va, vc) = ops.chop_in_blocks_vector(r, expind)\n        vm = np.random.multivariate_normal(vc, C, size=shots)\n        # The next line is a hack in that it only updates conditioned on the first samples value\n        # should still work if shots = 1\n        va = va + np.dot(np.dot(B, np.linalg.inv(C + covmat)), vm[0] - vc)\n        va = ops.reassemble_vector(va, expind)\n        self.fromsmean(va)\n        return vm\n\n    def homodyne(self, n, shots=1, eps=0.0002):\n        """""" Performs a homodyne measurement by calling measure dyne an giving it the\n        covariance matrix of a squeezed state whose x quadrature has variance eps**2""""""\n        covmat = np.diag(np.array([eps ** 2, 1.0 / eps ** 2]))\n        res = self.measure_dyne(covmat, [n], shots=shots)\n\n        return res\n\n    def post_select_homodyne(self, n, val, eps=0.0002):\n        """""" Performs a homodyne measurement but postelecting on the value vals for mode n """"""\n        if self.active[n] is None:\n            raise ValueError(""Cannot apply homodyne measurement, mode does not exist"")\n        covmat = np.diag(np.array([eps ** 2, 1.0 / eps ** 2]))\n        indices = [n]\n        expind = np.concatenate((2 * np.array(indices), 2 * np.array(indices) + 1))\n        mp = self.scovmat()\n        (A, B, C) = ops.chop_in_blocks(mp, expind)\n        V = A - np.dot(np.dot(B, np.linalg.inv(C + covmat)), np.transpose(B))\n        V1 = ops.reassemble(V, expind)\n        self.fromscovmat(V1)\n\n        r = self.smean()\n        (va, vc) = ops.chop_in_blocks_vector(r, expind)\n        vm1 = np.random.normal(vc[1], np.sqrt(C[1][1]))\n        vm = np.array([val, vm1])\n        va = va + np.dot(np.dot(B, np.linalg.inv(C + covmat)), vm - vc)\n        va = ops.reassemble_vector(va, expind)\n        self.fromsmean(va)\n        return val\n\n    def post_select_heterodyne(self, n, alpha_val):\n        """""" Performs a homodyne measurement but postelecting on the value vals for mode n """"""\n        if self.active[n] is None:\n            raise ValueError(""Cannot apply heterodyne measurement, mode does not exist"")\n\n        covmat = np.identity(2)\n        indices = [n]\n        expind = np.concatenate((2 * np.array(indices), 2 * np.array(indices) + 1))\n        mp = self.scovmat()\n        (A, B, C) = ops.chop_in_blocks(mp, expind)\n        V = A - np.dot(np.dot(B, np.linalg.inv(C + covmat)), np.transpose(B))\n        V1 = ops.reassemble(V, expind)\n        self.fromscovmat(V1)\n\n        r = self.smean()\n        (va, vc) = ops.chop_in_blocks_vector(r, expind)\n        vm = 2.0 * np.array([np.real(alpha_val), np.imag(alpha_val)])\n        va = va + np.dot(np.dot(B, np.linalg.inv(C + covmat)), vm - vc)\n        va = ops.reassemble_vector(va, expind)\n        self.fromsmean(va)\n        return alpha_val\n\n    def apply_u(self, U):\n        """""" Transforms the state according to the linear optical unitary that maps a[i] \\to U[i, j]^*a[j]""""""\n        self.mean = np.dot(np.conj(U), self.mean)\n        self.nmat = np.dot(np.dot(U, self.nmat), np.conj(np.transpose(U)))\n        self.mmat = np.dot(np.dot(np.conj(U), self.mmat), np.conj(np.transpose(U)))\n'"
strawberryfields/backends/gaussianbackend/ops.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""Gaussian operations""""""\n\nimport numpy as np\n\nfrom scipy.linalg import sqrtm\n\nfrom thewalrus.quantum import (\n    density_matrix_element,\n    is_pure_cov,\n    pure_state_amplitude,\n    state_vector,\n    density_matrix,\n)\n\n\ndef fock_amplitudes_one_mode(alpha, cov, cutoff):\n    """""" Returns the Fock space density matrix of gaussian state characterized\n    by a complex displacement alpha and a (symmetric) covariance matrix\n    The Fock ladder ladder goes from 0 to cutoff-1""""""\n    r = 2 * np.array([alpha.real, alpha.imag])\n    if is_pure_cov(cov):\n        psi = state_vector(r, cov, normalize=True, cutoff=cutoff)\n        rho = np.outer(psi, psi.conj())\n        return rho\n    return density_matrix(r, cov, normalize=True, cutoff=cutoff)\n\n\ndef sm_fidelity(mu1, mu2, cov1, cov2, tol=1e-8):\n    """""" Calculates the squared fidelity between the gaussian states s1 and s2. It uses the formulas from\n    Quantum Fidelity for Arbitrary Gaussian States\n    Leonardo Banchi, Samuel L. Braunstein, and Stefano Pirandola\n    Phys. Rev. Lett. 115, 260501 \xe2\x80\x93 Published 22 December 2015\n    The function returns the square of the quantity defined in the reference cited above.\n    Note however that our matrices need to be multiplied by 1/2 to get theirs and our vectors\n    need to be divided by sqrt(1/2) equivalently the factor in the exponential is not multiplied\n    by 2*1/4 but instead by 2*1/8=0.25\n    """"""\n    # pylint: disable=duplicate-code\n    v1 = 0.5 * cov1\n    v2 = 0.5 * cov2\n    deltar = mu1 - mu2\n    n = 1\n    W = omega(2 * n)\n\n    si12 = np.linalg.inv(v1 + v2)\n    vaux = np.dot(np.dot(np.transpose(W), si12), 0.25 * W + np.dot(v2, np.dot(W, v1)))\n\n    p1 = np.dot(vaux, W)\n    p1 = np.dot(p1, p1)\n    p1 = np.identity(2 * n) + 0.25 * np.linalg.inv(p1)\n    if np.linalg.norm(p1) < tol:\n        p1 = np.zeros_like(p1)\n    else:\n        p1 = sqrtm(p1)\n    p1 = 2 * (p1 + np.identity(2 * n))\n    p1 = np.dot(p1, vaux).real\n    f = np.sqrt(np.linalg.det(si12) * np.linalg.det(p1)) * np.exp(\n        -0.25 * np.dot(np.dot(deltar, si12), deltar).real\n    )\n    return f\n\n\ndef chop_in_blocks(m, idtodelete):\n    """"""\n    Splits a (symmetric) matrix into 3 blocks, A, B, C\n    Blocks A and B are diagonal blocks and C is the offdiagonal block\n    idtodelete specifies which indices go into B.\n    """"""\n    A = np.copy(m)\n    A = np.delete(A, idtodelete, axis=0)\n    A = np.delete(A, idtodelete, axis=1)\n    B = np.delete(m[:, idtodelete], idtodelete, axis=0)\n    C = np.empty((len(idtodelete), (len(idtodelete))))\n    for localindex, globalindex in enumerate(idtodelete):\n        for localindex1, globalindex1 in enumerate(idtodelete):\n            C[localindex, localindex1] = m[globalindex, globalindex1]\n    return (A, B, C)\n\n\ndef chop_in_blocks_vector(v, idtodelete):\n    """"""\n    Splits a vector into two vectors, where idtodelete specifies\n    which elements go into vb\n    """"""\n    idtokeep = list(set(np.arange(len(v))) - set(idtodelete))\n    va = v[idtokeep]\n    vb = v[idtodelete]\n    return (va, vb)\n\n\ndef reassemble(A, idtodelete):\n    """"""\n    Puts the matrix A inside a larger matrix of dimensions\n    dim(A)+len(idtodelete)\n    The empty space are filled with zeros (offdiagonal) and ones (diagonals)\n    """"""\n    ntot = len(A) + len(idtodelete)\n    ind = set(np.arange(ntot)) - set(idtodelete)\n    newmat = np.zeros((ntot, ntot))\n    for i, i1 in enumerate(ind):\n        for j, j1 in enumerate(ind):\n            newmat[i1, j1] = A[i, j]\n\n    for i in idtodelete:\n        newmat[i, i] = 1.0\n    return newmat\n\n\ndef reassemble_vector(va, idtodelete):\n    r""""""Creates a vector with zeros indices idtodelete\n    and everywhere else it puts the entries of va\n    """"""\n    ntot = len(va) + len(idtodelete)\n    ind = set(np.arange(ntot)) - set(idtodelete)\n    newv = np.zeros(ntot)\n    for j, j1 in enumerate(ind):\n        newv[j1] = va[j]\n    return newv\n\n\ndef omega(n):\n    """""" Utility function to calculate fidelities""""""\n    x = np.zeros(n)\n    x[0::2] = 1\n    A = np.diag(x[0:-1], 1)\n    W = A - np.transpose(A)\n    return W\n\n\ndef xmat(n):\n    """""" Returns the matrix ((0, I_n), (I, 0_n))""""""\n    idm = np.identity(n)\n    return np.concatenate(\n        (np.concatenate((0 * idm, idm), axis=1), np.concatenate((idm, 0 * idm), axis=1)), axis=0\n    ).real\n\n\ndef fock_prob(mu, cov, ocp):\n    """"""\n    Calculates the probability of measuring the gaussian state s2 in the photon number\n    occupation pattern ocp""""""\n    if is_pure_cov(cov):\n        return np.abs(pure_state_amplitude(mu, cov, ocp, check_purity=False)) ** 2\n\n    return density_matrix_element(mu, cov, list(ocp), list(ocp)).real\n'"
strawberryfields/backends/gaussianbackend/states.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Module containing Gaussian backend specific extensions to BaseGaussianState""""""\n\nimport numpy as np\n\nfrom ..states import BaseGaussianState\nfrom .ops import fock_amplitudes_one_mode, fock_prob, sm_fidelity\n\n\nclass GaussianState(BaseGaussianState):\n    r""""""Class for the representation of quantum states using Gaussian representation.\n\n    Args:\n        state_data (tuple(mu, cov)): A tuple containing the vector of means ``mu`` and the\n            covariance matrix ``cov``.\n        num_modes (int): the number of modes in the state\n        qmat (array): The covariance matrix for the Q function\n        Amat (array): The A matrix from Hamilton\'s paper\n        mode_names (Sequence): (optional) this argument contains a list providing mode names\n            for each mode in the state\n    """"""\n\n    def __init__(self, state_data, num_modes, qmat, Amat, mode_names=None):\n        # pylint: disable=too-many-arguments\n        super().__init__(state_data, num_modes, mode_names)\n        self.qmat = qmat\n        self.Amat = Amat\n\n    def reduced_dm(self, modes, **kwargs):\n        r""""""Returns the reduced density matrix in the Fock basis for a particular mode.\n\n        Args:\n            modes (int): specifies the mode. For the Gaussian backend, only a **single** mode\n                reduced density matrix can be returned.\n            **kwargs:\n\n                  * **cutoff** (*int*): (default 10) specifies where to truncate the returned density matrix.\n                    Note that the cutoff argument only applies for Gaussian representation;\n                    states represented in the Fock basis will use their own internal cutoff dimension.\n\n        Returns:\n            array: the reduced density matrix for the specified modes\n        """"""\n        cutoff = kwargs.get(""cutoff"", 10)\n        mu, cov = self.reduced_gaussian([modes])  # pylint: disable=unused-variable\n        cov = cov * 2 / self._hbar\n\n        return fock_amplitudes_one_mode(self._alpha[modes], cov, cutoff)\n\n    # ==========================================\n    # The methods below inherit their docstring\n    # from BaseState\n\n    def fock_prob(self, n, **kwargs):\n        if len(n) != self._modes:\n            raise ValueError(""Fock state must be same length as the number of modes"")\n\n        cutoff = kwargs.get(""cutoff"", 10)\n        if sum(n) >= cutoff:\n            raise ValueError(""Cutoff argument must be larger than the sum of photon numbers"")\n\n        ocp = np.uint8(np.array(n))\n\n        # get the vector and means and covariance\n        # matrix, and normalize so that hbar=2\n        mu = self.means() * np.sqrt(2 / self.hbar)\n        cov = self.cov() * 2 / self.hbar\n\n        return fock_prob(mu, cov, ocp)\n\n    def mean_photon(self, mode, **kwargs):\n        mu, cov = self.reduced_gaussian([mode])\n        mean = (np.trace(cov) + mu.T @ mu) / (2 * self._hbar) - 1 / 2\n        var = (np.trace(cov @ cov) + 2 * mu.T @ cov @ mu) / (2 * self._hbar ** 2) - 1 / 4\n        return mean, var\n\n    def fidelity(self, other_state, mode, **kwargs):\n        mu1 = other_state[0] * 2 / np.sqrt(2 * self._hbar)\n        cov1 = other_state[1] * 2 / self._hbar\n\n        mu2, cov2 = self.reduced_gaussian([mode])\n        mu2 *= 2 / np.sqrt(2 * self._hbar)\n        cov2 /= self._hbar / 2\n\n        return sm_fidelity(mu1, mu2, cov1, cov2)\n\n    def fidelity_vacuum(self, **kwargs):\n        alpha = np.zeros(len(self._alpha))\n        return self.fidelity_coherent(alpha)\n\n    def fidelity_coherent(self, alpha_list, **kwargs):\n        if len(alpha_list) != self._modes:\n            raise ValueError(""alpha_list must be same length as the number of modes"")\n\n        Qi = np.linalg.inv(self.qmat)\n        delta = self._alpha - alpha_list\n\n        delta = np.concatenate((delta, delta.conj()))\n        fac = np.sqrt(np.linalg.det(Qi).real)\n        exp = np.exp(-0.5 * np.dot(delta, np.dot(Qi, delta.conj())).real)\n        return fac * exp\n'"
strawberryfields/backends/tfbackend/__init__.py,0,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""\n.. _TensorFlow_backend:\n\nTensorFlow simulator backend\n##############################\n\n**Module name:** :mod:`strawberryfields.backends.tfbackend`\n\n.. currentmodule:: strawberryfields.backends.tfbackend\n\nThe :class:`TFBackend` object implements a simulation of quantum optical circuits using\n`TensorFlow <http://www.TensorFlow.org/>`_. The primary component of the TFBackend is a\n:class:`Circuit` object which is used to simulate a multi-mode quantum optical system. The\n:class:`TFBackend` provides the basic API-compatible interface to the simulator, while the\n:class:`Circuit` object actually carries out the mathematical simulation.\n\n\nThe :class:`Circuit` simulator maintains an internal tensor representation of the quantum state of a multi-mode quantum optical system\nusing a (truncated) Fock basis representation. As its various state manipulation methods are called, the quantum state is updated\nto reflect these changes. The simulator will try to keep the internal state in a pure (vector) representation\nfor as long as possible. Unitary gates will not change the type of representation, while state preparations and measurements will.\n\nA number of factors determine the shape and dimensionality of the state tensor:\n\n* the underlying state representation being used (either a ket vector or a density matrix)\n* the number of modes :math:`n` actively being simulated\n* the cutoff dimension :math:`D` for the Fock basis\n* whether the circuit is operating in *batched mode* (with batch size :math:`B`)\n\nWhen not operating in batched mode, the state tensor corresponds to a single multimode quantum system. If the\nrepresentation is a pure state, the state tensor has shape\n:math:`(\\underbrace{D,...,D}_{n~\\text{times}})`.\nIn a mixed state representation, the state tensor has shape\n:math:`(\\underbrace{D,D,...,D,D}_{2n~\\text{times}})`.\nIndices for the same mode appear consecutively. Hence, for a mixed state, the first two indices\nare for the first mode, the second are for the second mode, etc.\n\nIn batched mode, the state tensor simultaneously encodes an ensemble of :math:`B` multimode quantum systems\n(indexed using the first axis of the state tensor). Pure states thus have shape\n:math:`(B,\\underbrace{D,...,D}_{n~\\text{times}})`,\nwhile mixed states have shape\n:math:`(B,\\underbrace{D,D,...,D,D}_{2n~\\text{times}})`.\n\n.. currentmodule:: strawberryfields.backends.tfbackend.TFBackend\n\nTFBackend methods\n=================\n\nThe parameters supplied for these operations can be either numeric (float, complex) values\nor TensorFlow :class:`Variables`/:class:`Tensors`. The TensorFlow objects can either be scalars or vectors. For\nvectors, they must have the same dimension as the declared batch size of the underlying circuit.\n\n.. autosummary::\n   supports\n   begin_circuit\n   add_mode\n   del_mode\n   get_modes\n   get_cutoff_dim\n   reset\n   state\n   is_vacuum\n   prepare_vacuum_state\n   prepare_coherent_state\n   prepare_squeezed_state\n   prepare_displaced_squeezed_state\n   prepare_thermal_state\n   prepare_fock_state\n   prepare_ket_state\n   prepare_dm_state\n   rotation\n   displacement\n   squeeze\n   beamsplitter\n   cubic_phase\n   kerr_interaction\n   cross_kerr_interaction\n   loss\n   thermal_loss\n   measure_homodyne\n   measure_fock\n\n\nCode details\n~~~~~~~~~~~~\n.. autoclass:: strawberryfields.backends.tfbackend.TFBackend\n   :members:\n\nFockStateTF\n================\n\n.. currentmodule:: strawberryfields.backends.tfbackend.states.FockStateTF\n\nThis class represents the quantum state\nreturned by the TensorFlow backend. It extends :class:`~.BaseFockState` with additional functionality\nunique to the TensorFlow backend. The primary difference between this class and the Base Fock state\nis that it returns TensorFlow ``Tensor`` objects\n\n.. currentmodule:: strawberryfields.backends.tfbackend.states.FockStateTF\n\n.. autosummary::\n   ket\n   dm\n   reduced_dm\n   trace\n   fock_prob\n   all_fock_probs\n   fidelity\n   fidelity_coherent\n   fidelity_vacuum\n   is_vacuum\n   quad_expectation\n   mean_photon\n   batched\n   cutoff_dim\n\n\nCode details\n~~~~~~~~~~~~\n\n.. autoclass:: strawberryfields.backends.tfbackend.states.FockStateTF\n   :members:\n\n""""""\nimport sys\n\ntry:\n    import tensorflow\nexcept ImportError:\n    tf_available = False\n    tf_version = None\nelse:\n    tf_available = True\n    tf_version = tensorflow.__version__\n\n\ntf_info = """"""\\\nTo use Strawberry Fields with TensorFlow support, version 2.x of TensorFlow is required.\nThis can be installed as follows:\n\npip install tensorflow\n""""""\n\n\ndef excepthook(type, value, traceback):\n    """"""Exception hook to suppress superfluous exceptions""""""\n    # pylint: disable=unused-argument\n    print(value)\n\n\nif not (tf_available and tf_version[:2] == ""2.""):\n    sys.excepthook = excepthook\n\n    raise ImportError(tf_info)\n\n\nfrom .backend import TFBackend\nfrom .ops import def_type as tf_complex_type\n'"
strawberryfields/backends/tfbackend/backend.py,26,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nTensorFlow backend interface\n============================\n\n""""""\n# pylint: disable=too-many-public-methods\nimport numpy as np\nimport tensorflow as tf\n\nfrom strawberryfields.backends import BaseFock, ModeMap\nfrom .circuit import Circuit\nfrom .ops import mixed, partial_trace, reorder_modes\nfrom .states import FockStateTF\n\n\nclass TFBackend(BaseFock):\n    r""""""Implements a simulation of quantum optical circuits in a truncated\n    Fock basis using `TensorFlow <http://tensorflow.org/>`_, returning a :class:`~.FockStateTF`\n    state object.\n    """"""\n\n    short_name = ""tf""\n    circuit_spec = ""tf""\n\n    def __init__(self):\n        """"""Initialize a TFBackend object.\n        """"""\n        super().__init__()\n        self._supported[""mixed_states""] = True\n        self._supported[""batched""] = True\n        self._supported[""symbolic""] = True\n        self._init_modes = None  #: int: initial number of modes in the circuit\n        self._modemap = None  #: Modemap: maps external mode indices to internal ones\n        self.circuit = (\n            None  #: ~.tfbackend.circuit.Circuit: representation of the simulated quantum state\n        )\n\n    def _remap_modes(self, modes):\n        if isinstance(modes, int):\n            modes = [modes]\n            was_int = True\n        else:\n            was_int = False\n        map_ = self._modemap.show()\n        submap = [map_[m] for m in modes]\n        if not self._modemap.valid(modes) or None in submap:\n            raise ValueError(""The specified modes are not valid."")\n        remapped_modes = self._modemap.remap(modes)\n\n        if was_int:\n            remapped_modes = remapped_modes[0]\n        return remapped_modes\n\n    def begin_circuit(self, num_subsystems, **kwargs):\n        r""""""Instantiate a quantum circuit.\n\n        Instantiates a representation of a quantum optical state with ``num_subsystems`` modes.\n        The state is initialized to vacuum.\n\n        The modes in the circuit are indexed sequentially using integers, starting from zero.\n        Once an index is assigned to a mode, it can never be re-assigned to another mode.\n        If the mode is deleted its index becomes invalid.\n        An operation acting on an invalid or unassigned mode index raises an ``IndexError`` exception.\n\n        Args:\n            num_subsystems (int): number of modes in the circuit\n\n        Keyword Args:\n            cutoff_dim (int): Numerical Hilbert space cutoff dimension for the modes.\n                For each mode, the simulator can represent the Fock states :math:`\\ket{0}, \\ket{1}, \\ldots, \\ket{\\text{cutoff_dim}-1}`.\n            pure (bool): If True (default), use a pure state representation (otherwise will use a mixed state representation).\n            batch_size (None or int): Size of the batch-axis dimension. If None, no batch-axis will be used.\n        """"""\n        cutoff_dim = kwargs.get(""cutoff_dim"", None)\n        pure = kwargs.get(""pure"", True)\n        batch_size = kwargs.get(""batch_size"", None)\n\n        if cutoff_dim is None:\n            raise ValueError(""Argument \'cutoff_dim\' must be passed to the TensorFlow backend"")\n\n        if not isinstance(num_subsystems, int):\n            raise ValueError(""Argument \'num_subsystems\' must be a positive integer"")\n        if not isinstance(cutoff_dim, int):\n            raise ValueError(""Argument \'cutoff_dim\' must be a positive integer"")\n        if not isinstance(pure, bool):\n            raise ValueError(""Argument \'pure\' must be either True or False"")\n        if batch_size == 1:\n            raise ValueError(\n                ""batch_size of 1 not supported, please use different batch_size or set batch_size=None""\n            )\n\n        with tf.name_scope(""Begin_circuit""):\n            self._modemap = ModeMap(num_subsystems)\n            circuit = Circuit(num_subsystems, cutoff_dim, pure, batch_size)\n\n        self._init_modes = num_subsystems\n        self.circuit = circuit\n\n    def reset(self, pure=True, **kwargs):\n        """"""Reset the circuit so that all the modes are in the vacuum state.\n\n        After the reset the circuit is in the same state as it was after\n        the last :meth:`begin_circuit` call. It will have the original number\n        of modes, all initialized in the vacuum state. Some circuit parameters\n        may be changed during the reset, see the keyword args below.\n\n        Args:\n            pure (bool): if True, initialize the circuit in a pure state representation\n                (will use a mixed state representation if pure is False)\n\n        Keyword Args:\n            cutoff_dim (int): new Hilbert space truncation dimension\n        """"""\n\n        with tf.name_scope(""Reset""):\n            self._modemap.reset()\n            self.circuit.reset(num_subsystems=self._init_modes, pure=pure, **kwargs)\n\n    def get_cutoff_dim(self):\n        return self.circuit.cutoff_dim\n\n    def get_modes(self):\n        # pylint: disable=protected-access\n        return [i for i, j in enumerate(self._modemap._map) if j is not None]\n\n    def prepare_vacuum_state(self, mode):\n        with tf.name_scope(""Prepare_vacuum""):\n            remapped_mode = self._remap_modes(mode)\n            self.circuit.prepare_vacuum_state(remapped_mode)\n\n    def prepare_coherent_state(self, alpha, mode):\n        with tf.name_scope(""Prepare_coherent""):\n            remapped_mode = self._remap_modes(mode)\n            self.circuit.prepare_coherent_state(alpha, remapped_mode)\n\n    def prepare_squeezed_state(self, r, phi, mode):\n        with tf.name_scope(""Prepare_squeezed""):\n            remapped_mode = self._remap_modes(mode)\n            self.circuit.prepare_squeezed_state(r, phi, remapped_mode)\n\n    def prepare_displaced_squeezed_state(self, alpha, r, phi, mode):\n        with tf.name_scope(""Prepare_displaced_squeezed""):\n            remapped_mode = self._remap_modes(mode)\n            self.circuit.prepare_displaced_squeezed_state(alpha, r, phi, remapped_mode)\n\n    def prepare_fock_state(self, n, mode):\n        with tf.name_scope(""Prepare_fock""):\n            remapped_mode = self._remap_modes(mode)\n            self.circuit.prepare_fock_state(n, remapped_mode)\n\n    def prepare_ket_state(self, state, modes):\n        with tf.name_scope(""Prepare_state""):\n            self.circuit.prepare_multimode(state, self._remap_modes(modes), True)\n\n    def prepare_dm_state(self, state, modes):\n        with tf.name_scope(""Prepare_state""):\n            self.circuit.prepare_multimode(state, self._remap_modes(modes), False)\n\n    def prepare_thermal_state(self, nbar, mode):\n        with tf.name_scope(""Prepare_thermal""):\n            remapped_mode = self._remap_modes(mode)\n            self.circuit.prepare_thermal_state(nbar, remapped_mode)\n\n    def rotation(self, phi, mode):\n        with tf.name_scope(""Rotation""):\n            remapped_mode = self._remap_modes(mode)\n            self.circuit.phase_shift(phi, remapped_mode)\n\n    def displacement(self, alpha, mode):\n        with tf.name_scope(""Displacement""):\n            remapped_mode = self._remap_modes(mode)\n            self.circuit.displacement(alpha, remapped_mode)\n\n    def squeeze(self, z, mode):\n        with tf.name_scope(""Squeeze""):\n            remapped_mode = self._remap_modes(mode)\n            self.circuit.squeeze(z, remapped_mode)\n\n    def beamsplitter(self, t, r, mode1, mode2):\n        with tf.name_scope(""Beamsplitter""):\n            if isinstance(t, complex):\n                raise ValueError(""Beamsplitter transmittivity t must be a float."")\n            if isinstance(t, tf.Tensor):\n                if t.dtype.is_complex:\n                    raise ValueError(""Beamsplitter transmittivity t must be a float."")\n            remapped_modes = self._remap_modes([mode1, mode2])\n            self.circuit.beamsplitter(t, r, remapped_modes[0], remapped_modes[1])\n\n    def loss(self, T, mode):\n        with tf.name_scope(""Loss""):\n            remapped_mode = self._remap_modes(mode)\n            self.circuit.loss(T, remapped_mode)\n\n    def cubic_phase(self, gamma, mode):\n        with tf.name_scope(""Cubic_phase""):\n            remapped_mode = self._remap_modes(mode)\n            self.circuit.cubic_phase(gamma, remapped_mode)\n\n    def kerr_interaction(self, kappa, mode):\n        with tf.name_scope(""Kerr_interaction""):\n            remapped_mode = self._remap_modes(mode)\n            self.circuit.kerr_interaction(kappa, remapped_mode)\n\n    def cross_kerr_interaction(self, kappa, mode1, mode2):\n        with tf.name_scope(""Cross-Kerr_interaction""):\n            remapped_modes = self._remap_modes([mode1, mode2])\n            self.circuit.cross_kerr_interaction(kappa, remapped_modes[0], remapped_modes[1])\n\n    def state(self, modes=None, **kwargs):\n        r""""""Returns the state of the quantum simulation, restricted to the subsystems defined by `modes`.\n\n        See :meth:`.BaseBackend.state`.\n\n        Returns:\n            FockStateTF: state description\n        """"""\n        with tf.name_scope(""State""):\n            s = self.circuit.state\n            pure = self.circuit.state_is_pure\n            num_modes = self.circuit.num_modes\n            batched = self.circuit.batched\n\n            # reduce rho down to specified subsystems\n            if modes is None:\n                # reduced state is full state\n                reduced_state = s\n                modes = list(range(num_modes))\n            else:\n                if isinstance(modes, int):\n                    modes = [modes]\n                if len(modes) != len(set(modes)):\n                    raise ValueError(""The specified modes cannot be duplicated."")\n                if len(modes) > num_modes:\n                    raise ValueError(\n                        ""The number of specified modes cannot be larger than the number of subsystems.""\n                    )\n\n                if pure:\n                    # convert to mixed state representation\n                    reduced_state = mixed(s, batched)\n                    pure = False\n                else:\n                    reduced_state = s\n\n                    # trace our all modes not in modes\n                    # todo: Doing this one by one is very inefficient. The partial trace function should be improved.\n                for mode in sorted([m for m in range(num_modes) if m not in modes], reverse=True):\n                    reduced_state = partial_trace(reduced_state, mode, False, batched)\n                reduced_state_pure = False\n\n            # unless the modes were requested in order, we need to swap indices around\n            if modes != sorted(modes):\n                mode_permutation = np.argsort(np.argsort(modes))\n                reduced_state = reorder_modes(\n                    reduced_state, mode_permutation, reduced_state_pure, batched\n                )\n\n            s = reduced_state\n\n            modenames = [""q[{}]"".format(i) for i in np.array(self.get_modes())[modes]]\n            state_ = FockStateTF(\n                s, len(modes), pure, self.circuit.cutoff_dim, batched=batched, mode_names=modenames\n            )\n        return state_\n\n    def measure_fock(self, modes, shots=1, select=None, **kwargs):\n        """"""Measure the given modes in the Fock basis.\n\n        See :meth:`.BaseFock.measure_fock`.\n\n        Keyword Args:\n\n        Returns:\n            tuple[int] or tuple[Tensor]: measurement outcomes\n        """"""\n        if shots != 1:\n            raise NotImplementedError(\n                ""TF backend currently does not support "" ""shots != 1 for Fock measurement""\n            )\n        with tf.name_scope(""Measure_fock""):\n            remapped_modes = self._remap_modes(modes)\n            meas = self.circuit.measure_fock(remapped_modes, select=select, **kwargs)\n        return meas\n\n    def measure_homodyne(self, phi, mode, shots=1, select=None, **kwargs):\n        """"""Perform a homodyne measurement on the specified modes.\n\n        See :meth:`.BaseBackend.measure_homodyne`.\n\n        Keyword Args:\n            num_bins (int): Number of equally spaced bins for the probability distribution function\n                (pdf) simulating the homodyne measurement (default: 100000).\n            max (float): The pdf is discretized onto the 1D grid [-max,max] (default: 10).\n\n        Returns:\n            float or tf.Tensor: measurement outcome\n        """"""\n        if shots != 1:\n            raise NotImplementedError(\n                ""TF backend currently does not support "" ""shots != 1 for homodyne measurement""\n            )\n        with tf.name_scope(""Measure_homodyne""):\n            remapped_mode = self._remap_modes(mode)\n            meas = self.circuit.measure_homodyne(phi, remapped_mode, select, **kwargs)\n        return meas\n\n    def is_vacuum(self, tol=0.0, **kwargs):\n        with tf.name_scope(""Is_vacuum""):\n            vac_elem = self.circuit.vacuum_element()\n            return np.abs(vac_elem - 1) <= tol\n\n    def del_mode(self, modes):\n        with tf.name_scope(""Del_mode""):\n            remapped_modes = self._remap_modes(modes)\n            if isinstance(remapped_modes, int):\n                remapped_modes = [remapped_modes]\n            self.circuit.del_mode(remapped_modes)\n            self._modemap.delete(modes)\n\n    def add_mode(self, n=1):\n        with tf.name_scope(""Add_mode""):\n            self.circuit.add_mode(n)\n            self._modemap.add(n)\n'"
strawberryfields/backends/tfbackend/circuit.py,71,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nTensorFlow backend proper\n======================\n\nContains most of the code for managing the simulator state and offloading\noperations to the utilities in ops.\n\nHyperlinks: :class:`Circuit`\n\n.. currentmodule:: strawberryfields.backends.tfbackend.circuit\n\nContents\n----------------------\n.. autosummary::\n     Circuit\n\n""""""\n# pylint: disable=too-many-arguments,too-many-statements,too-many-branches,protected-access,attribute-defined-outside-init\n\nfrom itertools import product\nfrom string import ascii_lowercase as indices\n\nimport numpy as np\nfrom scipy.special import factorial\nimport tensorflow as tf\n\n# With TF 2.1+, the legacy tf.einsum was renamed to _einsum_v1, while\n# the replacement tf.einsum introduced the bug. This try-except block\n# will dynamically patch TensorFlow versions where _einsum_v1 exists, to make it the\n# default einsum implementation.\n#\n# For more details, see https://github.com/tensorflow/tensorflow/issues/37307\ntry:\n    from tensorflow.python.ops.special_math_ops import _einsum_v1\n\n    tf.einsum = _einsum_v1\nexcept ImportError:\n    pass\n\nfrom . import ops\n\n\nclass Circuit:\n    """"""Base class for representing and operating on a collection of\n         CV quantum optics modes in the Fock basis.\n         The modes are initialized in the (multimode) vacuum state,\n         using the Fock representation with given cutoff_dim.\n         The state of the modes is manipulated by calling the various methods.""""""\n\n    # pylint: disable=too-many-instance-attributes,too-many-public-methods\n    def __init__(self, num_modes, cutoff_dim, pure, batch_size):\n        self._hbar = 2\n        self.reset(\n            num_subsystems=num_modes, pure=pure, cutoff_dim=cutoff_dim, batch_size=batch_size\n        )\n\n    def _make_vac_states(self, cutoff_dim):\n        """"""Make vacuum state tensors for the underlying graph""""""\n        one = tf.cast([1.0], ops.def_type)\n        v = tf.scatter_nd([[0]], one, [cutoff_dim])\n        self._single_mode_pure_vac = v\n        self._single_mode_mixed_vac = tf.einsum(""i,j->ij"", v, v)\n        if self._batched:\n            self._single_mode_pure_vac = tf.stack([self._single_mode_pure_vac] * self._batch_size)\n            self._single_mode_mixed_vac = tf.stack([self._single_mode_mixed_vac] * self._batch_size)\n\n    def _update_state(self, new_state):\n        """"""Helper function to update the state history and the current state""""""\n        # pylint: disable=attribute-defined-outside-init\n        self._state_history.append(new_state)\n        self._state = new_state\n\n    def _valid_modes(self, modes):\n        # todo: this method should probably be moved into BaseBackend and then maybe\n        # overridden and expended in the subclasses to avoid code duplication and\n        # missing out on conditions.\n        if isinstance(modes, int):\n            modes = [modes]\n\n        for mode in modes:\n            if mode < 0:\n                raise ValueError(""Specified mode number(s) cannot be negative."")\n            elif mode >= self._num_modes:\n                raise ValueError(\n                    ""Specified mode number(s) are not compatible with number of modes.""\n                )\n\n        if len(modes) != len(set(modes)):\n            raise ValueError(""The specified modes cannot appear multiple times."")\n\n        return True\n\n    def _replace_and_update(self, replacement, modes):\n        """"""\n        Helper function for replacing a mode, updating the state history,\n        and possibly setting circuit\'s state_is_pure variable to a new value.\n\n        Expects replacement to be batched if self._batched.\n        """"""\n        if isinstance(modes, int):\n            modes = [modes]\n\n        if self._batched:\n            batch_offset = 1\n        else:\n            batch_offset = 0\n\n        num_modes = len(self._state.shape) - batch_offset\n        if not self._state_is_pure:\n            num_modes = int(num_modes / 2)\n\n        new_state = ops.replace_modes(\n            replacement, modes, self._state, self._state_is_pure, self._batched\n        )\n        self._update_state(new_state)\n\n        # update purity depending on whether we have replaced all modes or a subset\n        if len(modes) == num_modes:\n            replacement_is_pure = bool(len(replacement.shape) - batch_offset == len(modes))\n            self._state_is_pure = replacement_is_pure\n        else:\n            self._state_is_pure = False\n\n    def _maybe_batch(self, param, convert_to_tensor=True):\n        """"""Helper function to broadcast a param to the correct shape (if necessary) when working in batch mode. If param is not a scalar,\n        it will raise an exception if param\'s batch size is not equal to the circuit\'s batch size.""""""\n        shape_err = False\n        if convert_to_tensor:\n            p = tf.convert_to_tensor(param)\n            if not self._batched:\n                broadcast_p = p\n            else:\n                if p.shape.ndims == 0:\n                    # scalar\n                    broadcast_p = tf.stack([p] * self._batch_size)\n                elif p.shape.ndims == 1:\n                    # vector\n                    if p.shape.dims[0].value == self._batch_size:\n                        broadcast_p = p\n                    else:\n                        shape_err = True\n                else:\n                    shape_err = True\n        else:\n            p = np.array(param)\n            if not self._batched:\n                broadcast_p = p\n            else:\n                if len(p.shape) == 0:  # pylint: disable=len-as-condition\n                    # scalar\n                    broadcast_p = np.concatenate([np.expand_dims(p, 0)] * self._batch_size)\n                elif len(p.shape) == 1:\n                    # vector\n                    if p.shape[0] == self._batch_size:\n                        broadcast_p = p\n                    else:\n                        shape_err = True\n                else:\n                    shape_err = True\n\n        if shape_err:\n            raise ValueError(\n                ""Parameter can be either a scalar or a vector of length {}."".format(\n                    self._batch_size\n                )\n            )\n        else:\n            return broadcast_p\n\n    def _check_incompatible_batches(self, *params):\n        """"""Helper function for verifying that all the params from a list have the same batch size. Only does something\n             when the circuit is running in batched mode.""""""\n        if self._batched:\n            for idx, p in enumerate(params):\n                param_batch_size = p.shape.dims[0].value\n                if idx == 0:\n                    ref_batch_size = param_batch_size\n                else:\n                    if param_batch_size != ref_batch_size:\n                        raise ValueError(""Parameters have incompatible batch sizes."")\n\n    def del_mode(self, modes_list):\n        """"""Remove the modes in modes_list from the circuit.""""""\n        pure = self._state_is_pure\n        for mode in modes_list:\n            reduced_state = ops.partial_trace(self._state, mode, pure, self._batched)\n            pure = False\n        self._update_state(reduced_state)\n        self._state_is_pure = False\n        self._num_modes -= len(modes_list)\n\n    def add_mode(self, num_modes):\n        """"""Append M modes (initialized in vacuum states) to the circuit.""""""\n        vac = self._single_mode_pure_vac if self._state_is_pure else self._single_mode_mixed_vac\n        new_state = self._state\n        for _ in range(num_modes):\n            new_state = ops.insert_state(vac, new_state, self._state_is_pure, batched=self._batched)\n        self._update_state(new_state)\n        self._num_modes += num_modes\n\n    def reset(self, **kwargs):\n        r""""""\n        Resets the state of the circuit to have all modes in vacuum.\n        If a keyword arg is not present, the corresponding parameter is unchanged.\n\n        Keyword Args:\n            num_subsystems (int): sets the number of modes in the reset circuit.\n            pure (bool): if True, the reset circuit will represent its state as a pure state. If False, the representation will be mixed.\n            cutoff_dim (int): new Fock space cutoff dimension to use.\n            batch_size (None, int): None means no batching. An integer value >= 2 sets the batch size to use.\n        """"""\n        if ""pure"" in kwargs:\n            pure = kwargs[""pure""]\n            if not isinstance(pure, bool):\n                raise ValueError(""Argument \'pure\' must be either True or False"")\n            self._state_is_pure = pure\n\n        if ""num_subsystems"" in kwargs:\n            ns = kwargs[""num_subsystems""]\n            if not isinstance(ns, int):\n                raise ValueError(""Argument \'num_subsystems\' must be a positive integer"")\n            self._num_modes = ns\n\n        if ""cutoff_dim"" in kwargs:\n            cutoff_dim = kwargs[""cutoff_dim""]\n            if not isinstance(cutoff_dim, int) or cutoff_dim < 1:\n                raise ValueError(""Argument \'cutoff_dim\' must be a positive integer"")\n            self._cutoff_dim = cutoff_dim\n\n        if ""batch_size"" in kwargs:\n            batch_size = kwargs[""batch_size""]\n            if batch_size is not None:\n                if not isinstance(batch_size, int) or batch_size < 2:\n                    raise ValueError(""Argument \'batch_size\' must be either None or an integer > 1"")\n            self._batch_size = batch_size\n            self._batched = batch_size is not None\n\n        self._state_history = []\n        self._cache = {}\n\n        self._make_vac_states(self._cutoff_dim)\n        single_mode_vac = self._single_mode_pure_vac if pure else self._single_mode_mixed_vac\n        if self._num_modes == 1:\n            vac = single_mode_vac\n        else:\n            vac = ops.combine_single_modes([single_mode_vac] * self._num_modes, self._batch_size)\n        vac = tf.identity(vac, name=""Vacuum"")\n        self._update_state(vac)\n\n    def prepare_vacuum_state(self, mode):\n        """"""\n        Traces out the state in \'mode\' and replaces it with a vacuum state.\n        """"""\n        if self._valid_modes(mode):\n            if self._state_is_pure:\n                state = self._single_mode_pure_vac\n            else:\n                state = self._single_mode_mixed_vac\n            self._replace_and_update(state, mode)\n\n    def prepare_fock_state(self, n, mode):\n        """"""\n        Traces out the state in \'mode\' and replaces it with a Fock state defined by n.\n        """"""\n        if self._valid_modes(mode):\n            n = self._maybe_batch(n, convert_to_tensor=False)\n            fock_state = ops.fock_state(\n                n, D=self._cutoff_dim, pure=self._state_is_pure, batched=self._batched\n            )\n            self._replace_and_update(fock_state, mode)\n\n    def prepare_coherent_state(self, alpha, mode):\n        """"""\n        Traces out the state in \'mode\' and replaces it with a coherent state defined by alpha.\n        """"""\n        if self._valid_modes(mode):\n            alpha = tf.cast(alpha, ops.def_type)\n            alpha = self._maybe_batch(alpha)\n            coherent_state = ops.coherent_state(\n                alpha, D=self._cutoff_dim, pure=self._state_is_pure, batched=self._batched\n            )\n            self._replace_and_update(coherent_state, mode)\n\n    def prepare_squeezed_state(self, r, theta, mode):\n        """"""\n             Traces out the state in \'mode\' and replaces it with a squeezed state defined by r and theta.\n        """"""\n        if self._valid_modes(mode):\n            r = self._maybe_batch(r)\n            theta = self._maybe_batch(theta)\n            self._check_incompatible_batches(r, theta)\n            squeezed_state = ops.squeezed_vacuum(\n                r, theta, D=self._cutoff_dim, pure=self._state_is_pure, batched=self._batched\n            )\n            self._replace_and_update(squeezed_state, mode)\n\n    def prepare_displaced_squeezed_state(self, alpha, r, phi, mode):\n        """"""\n             Traces out the state in \'mode\' and replaces it with a displaced squeezed state defined by alpha, r and theta.\n        """"""\n        if self._valid_modes(mode):\n            alpha = self._maybe_batch(alpha)\n            r = self._maybe_batch(r)\n            phi = self._maybe_batch(phi)\n            self._check_incompatible_batches(alpha, r, phi)\n            displaced_squeezed = ops.displaced_squeezed(\n                alpha, r, phi, D=self._cutoff_dim, pure=self._state_is_pure, batched=self._batched\n            )\n            self._replace_and_update(displaced_squeezed, mode)\n\n    def prepare_multimode(self, state, modes, input_state_is_pure=False):\n        r""""""Prepares a given mode or list of modes in the given state.\n\n        After the preparation the system is in a mixed product state,\n        with the specified modes replaced by state.\n\n        The given state can be either in tensor form or in matrix/vector form and\n        can be a batch of states or a single state. This method needs to know whether\n        input_state_is_pure to distinguish between a batch of pure states and a mixed state.\n\n        If modes is not ordered, the subsystems of the input are\n        reordered to reflect that, i.e., if modes=[3,1], then the first mode\n        of state ends up in mode 3 and the second mode of state ends up in\n        mode 1 of the output state.\n\n        If modes is None, it is attempted to prepare state in all modes.\n        The reduced state on all other modes remains unchanged and\n        the final state is product with respect to the partition into\n        the modes in modes and the complement.\n\n        Args:\n            state (array): vector, matrix, or tensor representation of the ket state or\n                density matrix state (or a batch of such states) in the fock basis to prepare\n            modes (list[int] or non-negative int): The mode(s) into which state is\n                to be prepared. Needs not be ordered.\n        """"""\n        if self._valid_modes(modes):\n            if isinstance(modes, int):\n                modes = [modes]\n\n            n_modes = len(modes)\n            if input_state_is_pure:\n                input_is_batched = len(state.shape) > n_modes or (\n                    len(state.shape) == 2 and state.shape[1] == self._cutoff_dim ** n_modes\n                )\n            else:\n                input_is_batched = len(state.shape) % 2 == 1\n\n            pure_shape = tuple([self._cutoff_dim] * n_modes)\n            mixed_shape = tuple([self._cutoff_dim] * (2 * n_modes))\n            pure_shape_as_vector = tuple([self._cutoff_dim ** n_modes])\n            mixed_shape_as_matrix = tuple([self._cutoff_dim ** n_modes] * 2)\n            if input_is_batched:\n                pure_shape = (self._batch_size,) + pure_shape\n                mixed_shape = (self._batch_size,) + mixed_shape\n                pure_shape_as_vector = (self._batch_size,) + pure_shape_as_vector\n                mixed_shape_as_matrix = (self._batch_size,) + mixed_shape_as_matrix\n\n            # reshape to support input both as tensor and vector/matrix\n            if state.shape == pure_shape_as_vector:\n                state = tf.reshape(state, pure_shape)\n            elif state.shape == mixed_shape_as_matrix:\n                state = tf.reshape(state, mixed_shape)\n\n            state = tf.cast(tf.convert_to_tensor(state), ops.def_type)\n            # batch state now if not already batched and self._batched\n            if self._batched and not input_is_batched:\n                state = tf.stack([state] * self._batch_size)\n            self._replace_and_update(state, modes)\n\n    def prepare_thermal_state(self, nbar, mode):\n        """"""\n        Prepares the thermal state with mean photon nbar in the specified mode.\n        """"""\n        if self._valid_modes(mode):\n            nbar = self._maybe_batch(nbar)\n            thermal = ops.thermal_state(nbar, D=self._cutoff_dim)\n            self._replace_and_update(thermal, mode)\n\n    def phase_shift(self, theta, mode):\n        """"""\n        Apply the phase-shift operator to the specified mode.\n        """"""\n        theta = self._maybe_batch(theta)\n        new_state = ops.phase_shifter(\n            theta, mode, self._state, self._cutoff_dim, self._state_is_pure, self._batched\n        )\n        self._update_state(new_state)\n\n    def displacement(self, alpha, mode):\n        """"""\n        Apply the displacement operator to the specified mode.\n        """"""\n        alpha = self._maybe_batch(alpha)\n        new_state = ops.displacement(\n            alpha, mode, self._state, self._cutoff_dim, self._state_is_pure, self._batched\n        )\n        self._update_state(new_state)\n\n    def squeeze(self, z, mode):\n        """"""\n        Apply the single-mode squeezing operator to the specified mode.\n        """"""\n        z = tf.cast(z, ops.def_type)\n        r = tf.abs(z)\n        x = tf.math.real(z)\n        y = tf.math.imag(z)\n        theta = tf.math.atan2(y, x)\n        r = self._maybe_batch(r)\n        theta = self._maybe_batch(theta)\n        self._check_incompatible_batches(r, theta)\n        new_state = ops.squeezer(\n            r, theta, mode, self._state, self._cutoff_dim, self._state_is_pure, self._batched\n        )\n        self._update_state(new_state)\n\n    def beamsplitter(self, t, r, mode1, mode2):\n        """"""\n        Apply a beamsplitter operator to the two specified modes.\n        """"""\n        t = self._maybe_batch(t)\n        r = self._maybe_batch(r)\n        self._check_incompatible_batches(t, r)\n        new_state = ops.beamsplitter(\n            t, r, mode1, mode2, self._state, self._cutoff_dim, self._state_is_pure, self._batched\n        )\n        self._update_state(new_state)\n\n    def kerr_interaction(self, kappa, mode):\n        """"""\n        Apply the Kerr interaction operator to the specified mode.\n        """"""\n        k = tf.cast(kappa, ops.def_type)\n        k = self._maybe_batch(k)\n        new_state = ops.kerr_interaction(\n            k, mode, self._state, self._cutoff_dim, self._state_is_pure, self._batched\n        )\n        self._update_state(new_state)\n\n    def cross_kerr_interaction(self, kappa, mode1, mode2):\n        """"""\n        Apply the cross-Kerr interaction operator to the specified mode.\n        """"""\n        k = tf.cast(kappa, ops.def_type)\n        k = self._maybe_batch(k)\n        new_state = ops.cross_kerr_interaction(\n            k, mode1, mode2, self._state, self._cutoff_dim, self._state_is_pure, self._batched\n        )\n        self._update_state(new_state)\n\n    def cubic_phase(self, gamma, mode):\n        """"""\n        Apply the cubic phase operator to the specified mode.\n        """"""\n        g = tf.cast(gamma, ops.def_type)\n        g = self._maybe_batch(g)\n        new_state = ops.cubic_phase(\n            g, mode, self._state, self._cutoff_dim, self._hbar, self._state_is_pure, self._batched\n        )\n        self._update_state(new_state)\n\n    def loss(self, T, mode):\n        """"""\n        Apply a loss channel  to the specified mode.\n        """"""\n        T = tf.cast(T, ops.def_type)\n        T = self._maybe_batch(T)\n        new_state = ops.loss_channel(\n            T, mode, self._state, self._cutoff_dim, self._state_is_pure, self._batched\n        )\n        self._update_state(new_state)\n        self._state_is_pure = False  # loss output always in mixed state representation\n\n    def vacuum_element(self):\n        """"""Compute the fidelity with the (multi-mode) vacuum state.""""""\n        if self._batched:\n            vac_component = tf.reshape(self._state, [self._batch_size, -1])[:, 0]\n        else:\n            vac_component = tf.reshape(self._state, [-1])[0]\n\n        if self._state_is_pure:\n            return tf.abs(vac_component) ** 2\n        return vac_component\n\n    def measure_fock(self, modes, select=None, **kwargs):\n        """"""\n        Measures \'modes\' in the Fock basis and updates remaining modes conditioned on this result.\n        After measurement, the states in \'modes\' are reset to the vacuum.\n\n        Args:\n            modes (Sequence[int]): which modes to measure (in increasing order).\n            select (Sequence[int]): user-specified measurement value (used instead of random sampling)\n\n        Returns:\n            tuple[int]: The Fock number measurement results for each mode.\n        """"""\n        # allow integer (non-list) arguments\n        # not part of the API, but provided for convenience\n        if isinstance(modes, int):\n            modes = [modes]\n        if isinstance(select, int):\n            select = [select]\n\n        # convert lists to np arrays\n        if isinstance(modes, list):\n            modes = np.array(modes)\n        if isinstance(select, list):\n            select = np.array(select)\n\n        # check for valid \'modes\' argument\n        if (\n            len(modes) == 0 or len(modes) > self._num_modes or len(modes) != len(set(modes))\n        ):  # pylint: disable=len-as-condition\n            raise ValueError(""Specified modes are not valid."")\n        if np.any(modes != sorted(modes)):\n            raise ValueError(""\'modes\' must be sorted in increasing order."")\n\n        # check for valid \'select\' argument\n        if select is not None:\n            if np.any(select == None):  # pylint: disable=singleton-comparison\n                raise NotImplementedError(\n                    ""Post-selection lists must only contain numerical values.""\n                )\n            if self._batched:\n                num_meas_modes = len(modes)\n                # in this case, select must either be:\n                # np array of shape (M,), or\n                # np array of shape (B,M)\n                # where B is the batch_size and M is the number of measured modes\n                shape_err = False\n                if len(select.shape) == 1:\n                    # non-batched list, must broadcast\n                    if select.shape[0] != num_meas_modes:\n                        shape_err = True\n                    else:\n                        select = np.vstack([select] * self._batch_size)\n                elif len(select.shape) == 2:\n                    # batch of lists, no need to broadcast\n                    if select.shape != (self._batch_size, num_meas_modes):\n                        shape_err = True\n                else:\n                    shape_err = True\n                if shape_err:\n                    raise ValueError(""The shape of \'select\' is incompatible with \'modes\'."")\n            else:\n                # in this case, select should be a vector\n                if select.shape != modes.shape:\n                    raise ValueError(""\'select\' must be have the same shape as \'modes\'"")\n\n        # carry out the operation\n        num_reduced_state_modes = len(modes)\n        reduced_state = self._state\n        if self._state_is_pure:\n            mode_size = 1\n        else:\n            mode_size = 2\n        if self._batched:\n            batch_size = self._batch_size\n            batch_offset = 1\n        else:\n            batch_size = 1\n            batch_offset = 0\n\n        if select is not None:\n            # just use the supplied measurement results\n            meas_result = select\n        else:\n            # compute and sample measurement result\n            if self._state_is_pure and len(modes) == self._num_modes:\n                # in this case, measure directly on the pure state\n                probs = tf.abs(self._state) ** 2\n                logprobs = tf.math.log(probs)\n                sample = tf.random.categorical(tf.reshape(logprobs, [batch_size, -1]), 1)\n                sample_tensor = tf.squeeze(sample)\n            else:\n                # otherwise, trace out unmeasured modes and sample using diagonal of reduced state\n                removed_ctr = 0\n                red_state_is_pure = self._state_is_pure\n                for m in range(self._num_modes):\n                    if m not in modes:\n                        new_mode_idx = m - removed_ctr\n                        reduced_state = ops.partial_trace(\n                            reduced_state, new_mode_idx, red_state_is_pure, self._batched\n                        )\n                        red_state_is_pure = False\n                        removed_ctr += 1\n                # go from bra_A,ket_A,bra_B,ket_B,... -> bra_A,bra_B,ket_A,ket_B,... since this is what diag_part expects\n                # workaround for getting multi-index diagonal since tensorflow doesn\'t support getting diag of more than one subsystem at once\n                if num_reduced_state_modes > 1:\n                    state_indices = np.arange(batch_offset + 2 * num_reduced_state_modes)\n                    batch_index = state_indices[:batch_offset]\n                    bra_indices = state_indices[batch_offset::2]\n                    ket_indices = state_indices[batch_offset + 1 :: 2]\n                    transpose_list = np.concatenate([batch_index, bra_indices, ket_indices])\n                    reduced_state_reshuffled = tf.transpose(reduced_state, transpose_list)\n                else:\n                    reduced_state_reshuffled = reduced_state\n                diag_indices = [self._cutoff_dim ** num_reduced_state_modes] * 2\n                if self._batched:\n                    diag_indices = [self._batch_size] + diag_indices\n                diag_tensor = tf.reshape(reduced_state_reshuffled, diag_indices)\n                diag_entries = tf.linalg.diag_part(diag_tensor)\n                # hack so we can use tf.random.categorical for sampling\n                logprobs = tf.math.log(tf.cast(diag_entries, tf.float64))\n                sample = tf.random.categorical(tf.reshape(logprobs, [batch_size, -1]), 1)\n                # sample is a single integer; we need to convert it to the corresponding [n0,n1,n2,...]\n                sample_tensor = tf.squeeze(sample)\n\n            # sample_val is a single integer for each batch entry;\n            # we need to convert it to the corresponding [n0,n1,n2,...]\n            meas_result = ops.unravel_index(\n                sample_tensor, [self._cutoff_dim] * num_reduced_state_modes\n            )\n            if not self._batched:\n                meas_result = meas_result[0]  # no batch index, can get rid of first axis\n\n        # unstack this here because that\'s how it should be returned\n        meas_result = tf.unstack(meas_result, axis=-1, name=""Meas_result"")\n\n        # project remaining modes into conditional state\n        if len(modes) == self._num_modes:\n            # in this case, all modes were measured and we can put everything in vacuum by reseting\n            self.reset(pure=self._state_is_pure)\n        else:\n            # only some modes were measured: put unmeasured modes in conditional state, while reseting measured modes to vac\n            fock_state = tf.one_hot(\n                tf.stack(meas_result, axis=-1), depth=self._cutoff_dim, dtype=ops.def_type\n            )\n            conditional_state = self._state\n            for idx, mode in enumerate(modes):\n                if self._batched:\n                    f = fock_state[:, idx]\n                else:\n                    f = fock_state[idx]\n                conditional_state = ops.conditional_state(\n                    conditional_state, f, mode, self._state_is_pure, batched=self._batched\n                )\n\n            if self._state_is_pure:\n                norm = tf.norm(tf.reshape(conditional_state, [batch_size, -1]), axis=1)\n            else:\n                # calculate norm of conditional_state\n                # use a cheap hack since tensorflow doesn\'t allow einsum equation for trace:\n                r = conditional_state\n                for _ in range(self._num_modes - num_reduced_state_modes - 1):\n                    r = ops.partial_trace(r, 0, False, self._batched)\n                norm = tf.linalg.trace(r)\n\n            # for broadcasting\n            norm_reshape = [1] * len(conditional_state.shape[batch_offset:])\n            if self._batched:\n                norm_reshape = [self._batch_size] + norm_reshape\n\n            normalized_conditional_state = conditional_state / tf.reshape(norm, norm_reshape)\n\n            # reset measured modes into vacuum\n            single_mode_vac = (\n                self._single_mode_pure_vac if self._state_is_pure else self._single_mode_mixed_vac\n            )\n            if len(modes) == 1:\n                meas_modes_vac = single_mode_vac\n            else:\n                meas_modes_vac = ops.combine_single_modes(\n                    [single_mode_vac] * len(modes), self._batched\n                )\n            batch_index = indices[:batch_offset]\n            meas_mode_indices = indices[batch_offset : batch_offset + mode_size * len(modes)]\n            conditional_indices = indices[\n                batch_offset + mode_size * len(modes) : batch_offset + mode_size * self._num_modes\n            ]\n            eqn_lhs = batch_index + meas_mode_indices + "","" + batch_index + conditional_indices\n            eqn_rhs = """"\n            meas_ctr = 0\n            cond_ctr = 0\n            for m in range(self._num_modes):\n                if m in modes:\n                    # use measured_indices\n                    eqn_rhs += meas_mode_indices[mode_size * meas_ctr : mode_size * (meas_ctr + 1)]\n                    meas_ctr += 1\n                else:\n                    # use conditional indices\n                    eqn_rhs += conditional_indices[\n                        mode_size * cond_ctr : mode_size * (cond_ctr + 1)\n                    ]\n                    cond_ctr += 1\n            eqn = eqn_lhs + ""->"" + batch_index + eqn_rhs\n            new_state = tf.einsum(eqn, meas_modes_vac, normalized_conditional_state)\n\n            self._update_state(new_state)\n\n        return tuple(meas_result)\n\n    def measure_homodyne(self, phi, mode, select=None, **kwargs):\n        """"""\n            Measures \'modes\' in the basis of quadrature eigenstates (rotated by phi)\n            and updates remaining modes conditioned on this result.\n            After measurement, the states in \'modes\' are reset to the vacuum.\n\n            Args:\n                phi (float): phase angle of quadrature to measure\n                mode (int): which mode to measure.\n                select (float): user-specified measurement value (used instead of random sampling)\n\n        Returns:\n            float, list[float]: The measured value, or a list of measured values when running in batch mode.\n        """"""\n\n        if not isinstance(mode, int):\n            raise ValueError(""Specified modes are not valid."")\n        else:\n            if mode < 0 or mode >= self._num_modes:\n                raise ValueError(""Specified modes are not valid."")\n\n        m_omega_over_hbar = 1 / self._hbar\n        if self._state_is_pure:\n            mode_size = 1\n        else:\n            mode_size = 2\n        if self._batched:\n            batch_offset = 1\n            batch_size = self._batch_size\n        else:\n            batch_offset = 0\n            batch_size = 1\n\n        phi = tf.cast(phi, ops.def_type)\n        phi = self._maybe_batch(phi)\n\n        if select is not None:\n            meas_result = self._maybe_batch(select)\n            homodyne_sample = tf.cast(meas_result, tf.float64, name=""Meas_result"")\n        else:\n            # create reduced state on mode to be measured\n            reduced_state = ops.reduced_density_matrix(\n                self._state, mode, self._state_is_pure, self._batched\n            )\n\n            # rotate to homodyne basis\n            # pylint: disable=invalid-unary-operand-type\n            reduced_state = ops.phase_shifter(\n                -phi, 0, reduced_state, self._cutoff_dim, False, self._batched\n            )\n\n            # create pdf for homodyne measurement\n            # We use the following quadrature wavefunction for the Fock states:\n            # \\psi_n(x) = 1/sqrt[2^n n!](\\frac{m \\omega}{\\pi \\hbar})^{1/4}\n            #             \\exp{-\\frac{m \\omega}{2\\hbar} x^2} H_n(\\sqrt{\\frac{m \\omega}{\\pi}} x)\n            # where H_n(x) is the (physicists) nth Hermite polynomial\n            if ""max"" in kwargs:\n                q_mag = kwargs[""max""]\n            else:\n                q_mag = 10\n            if ""num_bins"" in kwargs:\n                num_bins = kwargs[""num_bins""]\n            else:\n                num_bins = 100000\n            if ""q_tensor"" in self._cache:\n                # use cached q_tensor\n                q_tensor = self._cache[""q_tensor""]\n            else:\n                q_tensor = tf.constant(np.linspace(-q_mag, q_mag, num_bins))\n                self._cache[""q_tensor""] = q_tensor\n            x = np.sqrt(m_omega_over_hbar) * q_tensor\n            if ""hermite_polys"" in self._cache:\n                # use cached polynomials\n                hermite_polys = self._cache[""hermite_polys""]\n            else:\n                H0 = 0 * x + 1.0\n                H1 = 2 * x\n                hermite_polys = [H0, H1]\n                Hn = H1\n                Hn_m1 = H0\n                for n in range(1, self._cutoff_dim - 1):\n                    Hn_p1 = ops.H_n_plus_1(Hn, Hn_m1, n, x)\n                    hermite_polys.append(Hn_p1)\n                    Hn_m1 = Hn\n                    Hn = Hn_p1\n                self._cache[""hermite_polys""] = hermite_polys\n\n            number_state_indices = [k for k in product(range(self._cutoff_dim), repeat=2)]\n            terms = [\n                1\n                / np.sqrt(2 ** n * factorial(n) * 2 ** m * factorial(m))\n                * hermite_polys[n]\n                * hermite_polys[m]\n                for n, m in number_state_indices\n            ]\n            hermite_matrix = tf.scatter_nd(\n                number_state_indices, terms, [self._cutoff_dim, self._cutoff_dim, num_bins]\n            )\n            hermite_terms = tf.multiply(\n                tf.expand_dims(reduced_state, -1),\n                tf.expand_dims(tf.cast(hermite_matrix, ops.def_type), 0),\n            )\n            rho_dist = (\n                tf.cast(tf.reduce_sum(hermite_terms, axis=[1, 2]), tf.float64)\n                * (m_omega_over_hbar / np.pi) ** 0.5\n                * tf.exp(-(x ** 2))\n                * (q_tensor[1] - q_tensor[0])\n            )  # Delta_q for normalization (only works if the bins are equally spaced)\n\n            # use tf.random.categorical to sample\n            logprobs = tf.math.log(rho_dist)\n            samples_idx = tf.random.categorical(logprobs, 1)\n            homodyne_sample = tf.gather(q_tensor, samples_idx)\n            homodyne_sample = tf.squeeze(homodyne_sample)\n\n        meas_result = tf.identity(homodyne_sample, name=""Meas_result"")\n\n        # project remaining modes into conditional state\n        if self._num_modes == 1:\n            # in this case, all modes were measured and we we put everything into vacuum\n            self.reset(pure=self._state_is_pure)\n        else:\n            # only some modes were measured: put unmeasured modes in conditional state, while reseting measured modes to vac\n            inf_squeezed_vac = tf.convert_to_tensor(\n                [\n                    (-0.5) ** (m // 2) * np.sqrt(factorial(m)) / factorial(m // 2)\n                    if m % 2 == 0\n                    else 0.0\n                    for m in range(self._cutoff_dim)\n                ],\n                dtype=ops.def_type,\n            )\n            if self._batched:\n                inf_squeezed_vac = tf.tile(tf.expand_dims(inf_squeezed_vac, 0), [batch_size, 1])\n            displacement_size = tf.stack(\n                tf.convert_to_tensor(meas_result * np.sqrt(m_omega_over_hbar / 2))\n            )\n            quad_eigenstate = ops.displacement(\n                displacement_size, 0, inf_squeezed_vac, self._cutoff_dim, True, self._batched\n            )\n            homodyne_eigenstate = ops.phase_shifter(\n                phi, 0, quad_eigenstate, self._cutoff_dim, True, self._batched\n            )\n\n            conditional_state = ops.conditional_state(\n                self._state, homodyne_eigenstate, mode, self._state_is_pure, batched=self._batched\n            )\n\n            # normalize\n            if self._state_is_pure:\n                norm = tf.norm(tf.reshape(conditional_state, [batch_size, -1]), axis=1)\n            else:\n                # calculate norm of conditional_state\n                # cheap hack since tensorflow doesn\'t allow einsum equation for trace:\n                r = conditional_state\n                for _ in range(self._num_modes - 2):\n                    r = ops.partial_trace(r, 0, False, self._batched)\n                norm = tf.linalg.trace(r)\n\n            # for broadcasting\n            norm_reshape = [1] * len(conditional_state.shape[batch_offset:])\n            if self._batched:\n                norm_reshape = [self._batch_size] + norm_reshape\n\n            normalized_conditional_state = conditional_state / tf.reshape(norm, norm_reshape)\n\n            # reset measured modes into vacuum\n            meas_mode_vac = (\n                self._single_mode_pure_vac if self._state_is_pure else self._single_mode_mixed_vac\n            )\n            batch_index = indices[:batch_offset]\n            meas_mode_indices = indices[batch_offset : batch_offset + mode_size]\n            conditional_indices = indices[\n                batch_offset + mode_size : batch_offset + mode_size * self._num_modes\n            ]\n            eqn_lhs = batch_index + meas_mode_indices + "","" + batch_index + conditional_indices\n            eqn_rhs = """"\n            meas_ctr = 0\n            cond_ctr = 0\n            for m in range(self._num_modes):\n                if m == mode:\n                    # use measured_indices\n                    eqn_rhs += meas_mode_indices[mode_size * meas_ctr : mode_size * (meas_ctr + 1)]\n                    meas_ctr += 1\n                else:\n                    # use conditional indices\n                    eqn_rhs += conditional_indices[\n                        mode_size * cond_ctr : mode_size * (cond_ctr + 1)\n                    ]\n                    cond_ctr += 1\n            eqn = eqn_lhs + ""->"" + batch_index + eqn_rhs\n            new_state = tf.einsum(eqn, meas_mode_vac, normalized_conditional_state)\n\n            self._update_state(new_state)\n\n        return tf.cast(meas_result, dtype=ops.def_type)\n\n    @property\n    def num_modes(self):\n        """"""Number of modes in the circuit""""""\n        return self._num_modes\n\n    @property\n    def cutoff_dim(self):\n        """"""Circuit cutoff dimension""""""\n        return self._cutoff_dim\n\n    @property\n    def state_is_pure(self):\n        """"""Returns true if the circuit state is pure""""""\n        return self._state_is_pure\n\n    @property\n    def hbar(self):\n        """"""Returns the value of hbar circuit is initialised with""""""\n        return self._hbar\n\n    @property\n    def batched(self):\n        """"""Returns True if the circuit is batched""""""\n        return self._batched\n\n    @property\n    def batch_size(self):\n        """"""Returns the batch size""""""\n        return self._batch_size\n\n    @property\n    def state(self):\n        """"""Returns the circuit state""""""\n        return tf.identity(self._state, name=""State"")\n'"
strawberryfields/backends/tfbackend/ops.py,152,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""\nKey mathematical operations used for tensorflow backend\n======================\n\nContains the basic linear algebraic utilities needed by the tensorflow simulator backend\nHyperlinks: :class:`Circuit`\n\n.. currentmodule:: strawberryfields.backends.tfbackend.ops\n\nContents\n----------------------\n.. autosummary::\n\n""""""\n# pylint: disable=too-many-arguments\n\nfrom string import ascii_lowercase as indices\nfrom functools import lru_cache\n\nimport tensorflow as tf\nimport numpy as np\nfrom scipy.special import binom, factorial\n\n# With TF 2.1+, the legacy tf.einsum was renamed to _einsum_v1, while\n# the replacement tf.einsum introduced the bug. This try-except block\n# will dynamically patch TensorFlow versions where _einsum_v1 exists, to make it the\n# default einsum implementation.\n#\n# For more details, see https://github.com/tensorflow/tensorflow/issues/37307\ntry:\n    from tensorflow.python.ops.special_math_ops import _einsum_v1\n\n    tf.einsum = _einsum_v1\nexcept ImportError:\n    pass\n\nfrom strawberryfields.backends.shared_ops import (\n    generate_bs_factors,\n    load_bs_factors,\n    save_bs_factors,\n    squeeze_parity,\n)\n\ndef_type = tf.complex64  # NOTE: what if a user wants higher accuracy?\nmax_num_indices = len(indices)\n\n###################################################################\n\n# Helper functions:\n\n\ndef _numer_safe_power(base, exponent):\n    """"""gives the desired behaviour of 0**0=1""""""\n    if exponent == 0:\n        return tf.ones_like(base, dtype=def_type)\n\n    return base ** exponent\n\n\ndef mixed(pure_state, batched=False):\n    """"""Converts the state from pure to mixed""""""\n    # todo: In the fock backend mixing is done by ops.mix(), maybe the functions should be named identically?\n    if not batched:\n        pure_state = tf.expand_dims(pure_state, 0)  # add in fake batch dimension\n    batch_offset = 1\n    num_modes = len(pure_state.shape) - batch_offset\n    max_num = (max_num_indices - batch_offset) // 2\n    if num_modes > max_num:\n        raise ValueError(\n            ""Converting state from pure to mixed currently only supported for {} modes."".format(\n                max_num\n            )\n        )\n    else:\n        # eqn: \'abc...xyz,ABC...XYZ->aAbBcC...xXyYzZ\' (lowercase belonging to \'bra\' side, uppercase belonging to \'ket\' side)\n        batch_index = indices[:batch_offset]\n        bra_indices = indices[batch_offset : batch_offset + num_modes]\n        ket_indices = indices[batch_offset + num_modes : batch_offset + 2 * num_modes]\n        eqn_lhs = batch_index + bra_indices + "","" + batch_index + ket_indices\n        eqn_rhs = """".join(bdx + kdx for bdx, kdx in zip(bra_indices, ket_indices))\n        eqn = eqn_lhs + ""->"" + batch_index + eqn_rhs\n        mixed_state = tf.einsum(eqn, pure_state, tf.math.conj(pure_state))\n    if not batched:\n        mixed_state = tf.squeeze(mixed_state, 0)  # drop fake batch dimension\n    return mixed_state\n\n\ndef batchify_indices(idxs, batch_size):\n    """"""adds batch indices to the index numbering""""""\n    return [(bdx,) + idxs[i] for bdx in range(batch_size) for i in range(len(idxs))]\n\n\ndef unravel_index(ind, tensor_shape):\n    """"""no official tensorflow implementation for this yet;\n    this is based on one proposed in https://github.com/tensorflow/tensorflow/issues/2075\n    """"""\n    ind = tf.expand_dims(tf.cast(ind, tf.int64), 0)\n    tensor_shape = tf.expand_dims(tf.cast(tensor_shape, tf.int64), 1)\n    strides = tf.math.cumprod(tensor_shape, reverse=True)\n    strides_shifted = tf.math.cumprod(tensor_shape, exclusive=True, reverse=True)\n    unraveled_coords = (ind % strides) // strides_shifted\n    return tf.transpose(unraveled_coords)\n\n\n@lru_cache()\ndef get_prefac_tensor(D, directory, save):\n    """"""Equivalent to the functionality of shared_ops the bs_factors functions from shared_ops,\n    but caches the return value as a tensor. This allows us to re-use the same prefactors and save\n    space on the computational graph.""""""\n    try:\n        prefac = load_bs_factors(D, directory)\n    except FileNotFoundError:\n        prefac = generate_bs_factors(D)\n        if save:\n            save_bs_factors(prefac, directory)\n    prefac = tf.expand_dims(tf.cast(prefac[:D, :D, :D, :D, :D], def_type), 0)\n    return prefac\n\n\n###################################################################\n\n# Matrices:\n# These return a matrix of shape [D, D]\n# which transforms from the input (truncated) Fock basis to the\n# output (truncated) Fock basis.\n\n\ndef squeezed_vacuum_vector(r, theta, D, batched=False, eps=1e-32):\n    """"""returns the ket representing a single mode squeezed vacuum state""""""\n    if batched:\n        batch_size = r.shape[0]\n    r = tf.cast(r, def_type)\n    theta = tf.cast(theta, def_type)\n    c1 = tf.cast(\n        tf.stack(\n            [\n                tf.sqrt(1 / tf.cosh(r)) * np.sqrt(factorial(k)) / factorial(k / 2.0)\n                for k in range(0, D, 2)\n            ],\n            axis=-1,\n        ),\n        def_type,\n    )\n    c2 = tf.stack(\n        [\n            (-0.5 * tf.exp(1j * theta) * tf.cast(tf.tanh(r + eps), def_type)) ** (k / 2.0)\n            for k in range(0, D, 2)\n        ],\n        axis=-1,\n    )\n    even_coeffs = c1 * c2\n    ind = [(k,) for k in np.arange(0, D, 2)]\n    shape = [D]\n    if batched:\n        ind = batchify_indices(ind, batch_size)\n        shape = [batch_size] + shape\n    output = tf.scatter_nd(ind, tf.reshape(even_coeffs, [-1]), shape)\n    return output\n\n\ndef squeezer_matrix(r, theta, D, batched=False):\n    """"""creates the single mode squeeze matrix""""""\n    r = tf.cast(r, tf.float64)\n    if not batched:\n        r = tf.expand_dims(r, 0)  # introduce artificial batch dimension\n    r = tf.reshape(r, [-1, 1, 1, 1])\n    theta = tf.cast(theta, def_type)\n    theta = tf.reshape(theta, [-1, 1, 1, 1])\n\n    rng = np.arange(D)\n    n = np.reshape(rng, [-1, D, 1, 1])\n    m = np.reshape(rng, [-1, 1, D, 1])\n    k = np.reshape(rng, [-1, 1, 1, D])\n\n    phase = tf.exp(1j * theta * (n - m) / 2)\n    signs = squeeze_parity(D).reshape([1, D, 1, D])\n    mask = np.logical_and(\n        (m + n) % 2 == 0, k <= np.minimum(m, n)\n    )  # kills off terms where the sum index k goes past min(m,n)\n    k_terms = (\n        signs\n        * tf.pow(tf.sinh(r) / 2, mask * (n + m - 2 * k) / 2)\n        * mask\n        / tf.pow(tf.cosh(r), (n + m + 1) / 2)\n        * tf.exp(\n            0.5 * tf.math.lgamma(tf.cast(m + 1, tf.float64))\n            + 0.5 * tf.math.lgamma(tf.cast(n + 1, tf.float64))\n            - tf.math.lgamma(tf.cast(k + 1, tf.float64))\n            - tf.math.lgamma(tf.cast((m - k) / 2 + 1, tf.float64))\n            - tf.math.lgamma(tf.cast((n - k) / 2 + 1, tf.float64))\n        )\n    )\n    output = tf.reduce_sum(phase * tf.cast(k_terms, def_type), axis=-1)\n\n    if not batched:\n        # remove extra batch dimension\n        output = tf.squeeze(output, 0)\n    return output\n\n\ndef phase_shifter_matrix(theta, D, batched=False):\n    """"""creates the single mode phase shifter matrix""""""\n    if batched:\n        batch_size = theta.shape[0]\n    theta = tf.cast(theta, def_type)\n    shape = [D, D]\n    if batched:\n        shape = [batch_size] + shape\n    zero_matrix = tf.zeros(shape=shape, dtype=def_type)\n    diag = [tf.exp(1j * theta * k) for k in np.arange(D, dtype=np.complex64)]\n    if batched:\n        diag = tf.stack(diag, axis=1)\n    diag_matrix = tf.linalg.set_diag(zero_matrix, diag)\n    return diag_matrix\n\n\ndef kerr_interaction_matrix(kappa, D, batched=False):\n    """"""creates the single mode Kerr interaction matrix""""""\n    coeffs = [tf.exp(1j * kappa * n ** 2) for n in range(D)]\n    if batched:\n        coeffs = tf.stack(coeffs, axis=1)\n    output = tf.linalg.diag(coeffs)\n    return output\n\n\ndef cross_kerr_interaction_matrix(kappa, D, batched=False):\n    """"""creates the two mode cross-Kerr interaction matrix""""""\n    coeffs = [tf.exp(1j * kappa * n1 * n2) for n1 in range(D) for n2 in range(D)]\n    if batched:\n        coeffs = tf.stack(coeffs, axis=1)\n    output = tf.linalg.diag(coeffs)\n    if batched:\n        output = tf.transpose(tf.reshape(output, [-1] + [D] * 4), [0, 1, 3, 2, 4])\n    else:\n        output = tf.transpose(tf.reshape(output, [D] * 4), [0, 2, 1, 3])\n    return output\n\n\ndef cubic_phase_matrix(gamma, D, hbar, batched=False, method=""self_adjoint_eig""):\n    """"""creates the single mode cubic phase matrix""""""\n    a, ad = ladder_ops(D)\n    x = np.sqrt(hbar / 2) * tf.cast(a + ad, def_type)\n    x3 = x @ x @ x\n    if batched:\n        x3 = tf.expand_dims(x3, 0)\n        gamma = tf.reshape(gamma, [-1, 1, 1])\n    H0 = gamma / (3 * hbar) * x3\n    lambdas, U = tf.linalg.eigh(H0)\n    transpose_list = [1, 0]\n    if batched:\n        transpose_list = [0, 2, 1]\n    if method == ""self_adjoint_eig"":\n        # This seems to work as long as the matrix has dimension 18x18 or smaller\n        # For larger matrices, TensorFlow returns the error: \'Self-adjoint eigen decomposition was not successful.\'\n        V = U @ tf.linalg.diag(tf.exp(1j * lambdas)) @ tf.math.conj(tf.transpose(U, transpose_list))\n    # below version works for matrices larger than 18x18, but\n    # expm was not added until TF v1.5, while\n    # as of TF v1.5, gradient of expm is not implemented\n    # elif method == ""expm"":\n    #    V = tf.linalg.expm(1j * H0)\n    else:\n        raise ValueError(""\'method\' must be either \'self_adjoint_eig\' or \'expm\'."")\n    return V\n\n\ndef loss_superop(T, D, batched=False):\n    """"""creates the single mode loss channel matrix""""""\n    # indices are abcd, corresponding to action |a><b| (.) |c><d|\n    if not batched:\n        T = tf.expand_dims(T, 0)  # introduce artificial batch dimension\n    T = tf.reshape(T, [-1, 1, 1, 1, 1, 1])\n    T = tf.cast(T, tf.float64)\n    rng = np.arange(D)\n    a = np.reshape(rng, [-1, D, 1, 1, 1, 1])\n    b = np.reshape(rng, [-1, 1, D, 1, 1, 1])\n    c = np.reshape(rng, [-1, 1, 1, D, 1, 1])\n    d = np.reshape(rng, [-1, 1, 1, 1, D, 1])\n    l = np.reshape(rng, [-1, 1, 1, 1, 1, D])\n    a_mask = np.where(a == b - l, 1, 0)\n    d_mask = np.where(d == c - l, 1, 0)\n    mask = (l <= np.minimum(b, c)) * a_mask * d_mask\n\n    exponent = tf.abs((b + c) / 2 - l) * mask\n    T_numer = tf.pow((1 - T), l) * tf.pow(T, exponent)\n    fact_numer = np.sqrt(factorial(b) * factorial(c))\n    fact_denom = np.sqrt(factorial(b - l) * factorial(c - l)) * factorial(l)\n    fact_denom_masked = np.where(fact_denom > 0, fact_denom, 1)\n    factors = mask * fact_numer / fact_denom_masked\n    l_terms = T_numer * factors\n    output = tf.cast(tf.reduce_sum(l_terms, -1), def_type)\n    if not batched:\n        output = tf.squeeze(output, 0)  # drop artificial batch dimension\n    return output\n\n\ndef displacement_matrix(alpha, D, batched=False):\n    """"""creates the single mode displacement matrix""""""\n    if batched:\n        batch_size = alpha.shape[0]\n    alpha = tf.cast(alpha, def_type)\n    idxs = [(j, k) for j in range(D) for k in range(j)]\n    values = [\n        alpha ** (j - k) * tf.cast(tf.sqrt(binom(j, k) / factorial(j - k)), def_type)\n        for j in range(D)\n        for k in range(j)\n    ]\n    values = tf.stack(values, axis=-1)\n    dense_shape = [D, D]\n    vals = [1.0] * D\n    ind = [(idx, idx) for idx in range(D)]\n    if batched:\n        dense_shape = [batch_size] + dense_shape\n        vals = vals * batch_size\n        ind = batchify_indices(ind, batch_size)\n    eye_diag = tf.SparseTensor(ind, vals, dense_shape)\n    signs = [(-1) ** (j - k) for j in range(D) for k in range(j)]\n    if batched:\n        idxs = batchify_indices(idxs, batch_size)\n        signs = signs * batch_size\n    sign_lower_diag = tf.cast(tf.SparseTensor(idxs, signs, dense_shape), tf.float32)\n    sign_matrix = tf.sparse.add(eye_diag, sign_lower_diag)\n    sign_matrix = tf.cast(tf.sparse.to_dense(sign_matrix), def_type)\n    lower_diag = tf.scatter_nd(idxs, tf.reshape(values, [-1]), dense_shape)\n    E = tf.cast(tf.eye(D), def_type) + lower_diag\n    E_prime = tf.math.conj(E) * sign_matrix\n    if batched:\n        eqn = ""aik,ajk->aij""  # pylint: disable=bad-whitespace\n    else:\n        eqn = ""ik,jk->ij""  # pylint: disable=bad-whitespace\n    prefactor = tf.expand_dims(\n        tf.expand_dims(tf.cast(tf.exp(-0.5 * tf.abs(alpha) ** 2), def_type), -1), -1\n    )\n    D_alpha = prefactor * tf.einsum(eqn, E, E_prime)\n    return D_alpha\n\n\ndef beamsplitter_matrix(t, r, D, batched=False, save=False, directory=None):\n    """"""creates the two mode beamsplitter matrix""""""\n    if not batched:\n        # put in a fake batch dimension for broadcasting convenience\n        t = tf.expand_dims(t, 0)\n        r = tf.expand_dims(r, 0)\n    t = tf.cast(tf.reshape(t, [-1, 1, 1, 1, 1, 1]), def_type)\n    r = tf.cast(tf.reshape(r, [-1, 1, 1, 1, 1, 1]), def_type)\n    mag_t = tf.cast(t, tf.float32)\n    mag_r = tf.abs(r)\n    phase_r = tf.atan2(tf.math.imag(r), tf.math.real(r))\n\n    rng = tf.range(D, dtype=tf.float32)\n    N = tf.reshape(rng, [1, -1, 1, 1, 1, 1])\n    n = tf.reshape(rng, [1, 1, -1, 1, 1, 1])\n    M = tf.reshape(rng, [1, 1, 1, -1, 1, 1])\n    k = tf.reshape(rng, [1, 1, 1, 1, 1, -1])\n    n_minus_k = n - k\n    N_minus_k = N - k\n    M_minus_n_plus_k = M - n + k\n    # need to deal with 0*(-n) for n integer\n    n_minus_k = tf.where(tf.greater(n, k), n_minus_k, tf.zeros_like(n_minus_k))\n    N_minus_k = tf.where(tf.greater(N, k), N_minus_k, tf.zeros_like(N_minus_k))\n    M_minus_n_plus_k = tf.where(\n        tf.greater(M_minus_n_plus_k, 0), M_minus_n_plus_k, tf.zeros_like(M_minus_n_plus_k)\n    )\n\n    powers = tf.cast(\n        tf.pow(mag_t, k)\n        * tf.pow(mag_r, n_minus_k)\n        * tf.pow(mag_r, N_minus_k)\n        * tf.pow(mag_t, M_minus_n_plus_k),\n        def_type,\n    )\n    phase = tf.exp(1j * tf.cast(phase_r * (n - N), def_type))\n\n    # load parameter-independent prefactors\n    prefac = get_prefac_tensor(D, directory, save)\n\n    BS_matrix = tf.reduce_sum(phase * powers * prefac, -1)\n\n    if not batched:\n        # drop artificial batch index\n        BS_matrix = tf.squeeze(BS_matrix, [0])\n    return BS_matrix\n\n\n###################################################################\n\n# Input states:\n# Creates input states on a single mode\n\n\ndef fock_state(n, D, pure=True, batched=False):\n    """"""creates a single mode input Fock state""""""\n    if not isinstance(n, (np.ndarray, int)):\n        raise ValueError(""\'n\' is expected to be either an int or a numpy array"")\n    if batched:\n        batch_size = n.shape[0]\n        idxs = [(b, f) for (b, f) in zip(range(batch_size), n)]\n        values = [1.0] * batch_size\n        shape = [batch_size, D]\n    else:\n        idxs = [(n,)]\n        values = [1.0]\n        shape = [D]\n    fock_sparse = tf.scatter_nd(idxs, values, shape)\n    fock = tf.cast(fock_sparse, def_type)\n    if not pure:\n        fock = mixed(fock, batched)\n    return fock\n\n\ndef coherent_state(alpha, D, pure=True, batched=False):\n    """"""creates a single mode input coherent state""""""\n    coh = tf.stack(\n        [\n            tf.exp(-0.5 * tf.math.conj(alpha) * alpha)\n            * _numer_safe_power(alpha, n)\n            / tf.cast(np.sqrt(factorial(n)), def_type)\n            for n in range(D)\n        ],\n        axis=-1,\n    )\n    if not pure:\n        coh = mixed(coh, batched)\n    return coh\n\n\ndef squeezed_vacuum(r, theta, D, pure=True, batched=False):\n    """"""creates a single mode input squeezed vacuum state""""""\n    squeezed = squeezed_vacuum_vector(r, theta, D, batched=batched)\n    if not pure:\n        squeezed = mixed(squeezed, batched)\n    return squeezed\n\n\ndef displaced_squeezed(alpha, r, phi, D, pure=True, batched=False, eps=1e-12):\n    """"""creates a single mode input displaced squeezed state""""""\n    alpha = tf.cast(alpha, def_type)\n    r = (\n        tf.cast(r, def_type) + eps\n    )  # to prevent nans if r==0, we add an epsilon (default is miniscule)\n    phi = tf.cast(phi, def_type)\n\n    phase = tf.exp(1j * phi)\n    sinh = tf.sinh(r)\n    cosh = tf.cosh(r)\n    tanh = tf.tanh(r)\n\n    # create Hermite polynomials\n    gamma = alpha * cosh + tf.math.conj(alpha) * phase * sinh\n    hermite_arg = gamma / tf.sqrt(phase * tf.sinh(2 * r))\n\n    prefactor = tf.expand_dims(\n        tf.exp(-0.5 * alpha * tf.math.conj(alpha) - 0.5 * tf.math.conj(alpha) ** 2 * phase * tanh),\n        -1,\n    )\n    coeff = tf.stack(\n        [\n            _numer_safe_power(0.5 * phase * tanh, n / 2.0) / tf.sqrt(factorial(n) * cosh)\n            for n in range(D)\n        ],\n        axis=-1,\n    )\n    hermite_terms = tf.stack([tf.cast(H(n, hermite_arg), def_type) for n in range(D)], axis=-1)\n    squeezed_coh = prefactor * coeff * hermite_terms\n\n    if not pure:\n        squeezed_coh = mixed(squeezed_coh, batched)\n    return squeezed_coh\n\n\ndef thermal_state(nbar, D):\n    """"""creates a single mode input thermal state.\n    Note that the batch dimension is determined by argument nbar.\n    """"""\n    nbar = tf.cast(nbar, def_type)\n    coeffs = tf.stack(\n        [_numer_safe_power(nbar, n) / _numer_safe_power(nbar + 1, n + 1) for n in range(D)], axis=-1\n    )\n    thermal = tf.linalg.diag(coeffs)\n    return thermal\n\n\n###################################################################\n\n# Generic Gate implementations:\n# These apply the given matrix to the specified mode(s) of in_modes\n\n\ndef single_mode_gate(matrix, mode, in_modes, pure=True, batched=False):\n    """"""basic form:\n    \'ab,cde...b...xyz->cde...a...xyz\' (pure state)\n    \'ab,ef...bc...xyz,cd->ef...ad...xyz\' (mixed state)\n    """"""\n    if batched:\n        batch_offset = 1\n    else:\n        batch_offset = 0\n    batch_index = indices[:batch_offset]\n    left_gate_str = indices[batch_offset : batch_offset + 2]  # |a><b|\n    num_indices = len(in_modes.shape)\n    if pure:\n        num_modes = num_indices - batch_offset\n        mode_size = 1\n    else:\n        right_gate_str = indices[batch_offset + 2 : batch_offset + 4]  # |c><d|\n        num_modes = (num_indices - batch_offset) // 2\n        mode_size = 2\n    max_len = len(indices) - 2 * mode_size - batch_offset\n    if num_modes == 0:\n        raise ValueError(""\'in_modes\' must have at least one mode"")\n    if num_modes > max_len:\n        raise NotImplementedError(\n            ""The max number of supported modes for this operation is currently {}"".format(max_len)\n        )\n    if mode < 0 or mode >= num_modes:\n        raise ValueError(""\'mode\' argument is not compatible with number of in_modes"")\n    else:\n        other_modes_indices = indices[\n            batch_offset + 2 * mode_size : batch_offset + (1 + num_modes) * mode_size\n        ]\n        if pure:\n            eqn_lhs = ""{},{}{}{}{}"".format(\n                batch_index + left_gate_str,\n                batch_index,\n                other_modes_indices[: mode * mode_size],\n                left_gate_str[1],\n                other_modes_indices[mode * mode_size :],\n            )\n            eqn_rhs = """".join(\n                [\n                    batch_index,\n                    other_modes_indices[: mode * mode_size],\n                    left_gate_str[0],\n                    other_modes_indices[mode * mode_size :],\n                ]\n            )\n        else:\n            eqn_lhs = ""{},{}{}{}{}{},{}"".format(\n                batch_index + left_gate_str,\n                batch_index,\n                other_modes_indices[: mode * mode_size],\n                left_gate_str[1],\n                right_gate_str[0],\n                other_modes_indices[mode * mode_size :],\n                batch_index + right_gate_str,\n            )\n            eqn_rhs = """".join(\n                [\n                    batch_index,\n                    other_modes_indices[: mode * mode_size],\n                    left_gate_str[0],\n                    right_gate_str[1],\n                    other_modes_indices[mode * mode_size :],\n                ]\n            )\n\n    eqn = eqn_lhs + ""->"" + eqn_rhs\n    einsum_inputs = [matrix, in_modes]\n    if not pure:\n        transposed_axis = [0, 2, 1] if batched else [1, 0]\n        einsum_inputs.append(tf.transpose(tf.math.conj(matrix), transposed_axis))\n    output = tf.einsum(eqn, *einsum_inputs)\n    return output\n\n\ndef two_mode_gate(matrix, mode1, mode2, in_modes, pure=True, batched=False):\n    """"""basic form:\n    \'abcd,efg...b...d...xyz->efg...a...c...xyz\' (pure state)\n    \'abcd,ij...be...dg...xyz,efgh->ij...af...ch...xyz\' (mixed state)\n    """"""\n    # pylint: disable=too-many-branches,too-many-statements\n    if batched:\n        batch_offset = 1\n    else:\n        batch_offset = 0\n    batch_index = indices[:batch_offset]\n    left_gate_str = indices[batch_offset : batch_offset + 4]  # |a><b| |c><d|\n    num_indices = len(in_modes.shape)\n    if pure:\n        num_modes = num_indices - batch_offset\n        mode_size = 1\n    else:\n        right_gate_str = indices[batch_offset + 4 : batch_offset + 8]  # |e><f| |g><h|\n        num_modes = (num_indices - batch_offset) // 2\n        mode_size = 2\n    max_len = (len(indices) - 4) // mode_size - batch_offset\n\n    if num_modes == 0:\n        raise ValueError(""\'in_modes\' must have at least one mode"")\n    if num_modes > max_len:\n        raise NotImplementedError(\n            ""The max number of supported modes for this operation is currently {}"".format(max_len)\n        )\n    else:\n        min_mode = min(mode1, mode2)\n        max_mode = max(mode1, mode2)\n        if min_mode < 0 or max_mode >= num_modes or mode1 == mode2:\n            raise ValueError(""One or more mode numbers are incompatible"")\n        else:\n            other_modes_indices = indices[\n                batch_offset\n                + 4 * mode_size : batch_offset\n                + 4 * mode_size\n                + mode_size * (num_modes - 2)\n            ]\n            # build equation\n            if mode1 == min_mode:\n                lhs_min_mode_indices = left_gate_str[1]\n                lhs_max_mode_indices = left_gate_str[3]\n                rhs_min_mode_indices = left_gate_str[0]\n                rhs_max_mode_indices = left_gate_str[2]\n            else:\n                lhs_min_mode_indices = left_gate_str[3]\n                lhs_max_mode_indices = left_gate_str[1]\n                rhs_min_mode_indices = left_gate_str[2]\n                rhs_max_mode_indices = left_gate_str[0]\n            if not pure:\n                if mode1 == min_mode:\n                    lhs_min_mode_indices += right_gate_str[0]\n                    lhs_max_mode_indices += right_gate_str[2]\n                    rhs_min_mode_indices += right_gate_str[1]\n                    rhs_max_mode_indices += right_gate_str[3]\n                else:\n                    lhs_min_mode_indices += right_gate_str[2]\n                    lhs_max_mode_indices += right_gate_str[0]\n                    rhs_min_mode_indices += right_gate_str[3]\n                    rhs_max_mode_indices += right_gate_str[1]\n            eqn_lhs = ""{},{}{}{}{}{}{}"".format(\n                batch_index + left_gate_str,\n                batch_index,\n                other_modes_indices[: min_mode * mode_size],\n                lhs_min_mode_indices,\n                other_modes_indices[min_mode * mode_size : (max_mode - 1) * mode_size],\n                lhs_max_mode_indices,\n                other_modes_indices[(max_mode - 1) * mode_size :],\n            )\n            if not pure:\n                eqn_lhs += "","" + batch_index + right_gate_str\n            eqn_rhs = """".join(\n                [\n                    batch_index,\n                    other_modes_indices[: min_mode * mode_size],\n                    rhs_min_mode_indices,\n                    other_modes_indices[min_mode * mode_size : (max_mode - 1) * mode_size],\n                    rhs_max_mode_indices,\n                    other_modes_indices[(max_mode - 1) * mode_size :],\n                ]\n            )\n            eqn = eqn_lhs + ""->"" + eqn_rhs\n            einsum_inputs = [matrix, in_modes]\n            if not pure:\n                if batched:\n                    transpose_list = [0, 2, 1, 4, 3]\n                else:\n                    transpose_list = [1, 0, 3, 2]\n                einsum_inputs.append(tf.math.conj(tf.transpose(matrix, transpose_list)))\n            output = tf.einsum(eqn, *einsum_inputs)\n            return output\n\n\ndef single_mode_superop(superop, mode, in_modes, pure=True, batched=False):\n    """"""rho_out = S[rho_in]\n    (state is always converted to mixed to apply superop)\n    basic form:\n    abcd,ef...klbcmn...yz->ef...kladmn...yz\n    """"""\n\n    if batched:\n        batch_offset = 1\n    else:\n        batch_offset = 0\n\n    max_len = (len(indices) - 2) // 2 - batch_offset\n    if pure:\n        num_modes = len(in_modes.shape) - batch_offset\n    else:\n        num_modes = (len(in_modes.shape) - batch_offset) // 2\n    if num_modes > max_len:\n        raise NotImplementedError(\n            ""The max number of supported modes for this operation is currently {}"".format(max_len)\n        )\n    else:\n        if pure:\n            in_modes = mixed(in_modes, batched)\n\n        # create equation\n        batch_index = indices[:batch_offset]\n        superop_indices = indices[batch_offset : batch_offset + 4]\n        state_indices = indices[batch_offset + 4 : batch_offset + 4 + 2 * num_modes]\n        left_unchanged_indices = state_indices[: 2 * mode]\n        right_unchanged_indices = state_indices[2 * mode : 2 * (num_modes - 1)]\n        eqn_lhs = "","".join(\n            [\n                batch_index + superop_indices,\n                batch_index\n                + left_unchanged_indices\n                + superop_indices[1:3]\n                + right_unchanged_indices,\n            ]\n        )\n        eqn_rhs = """".join(\n            [\n                batch_index,\n                left_unchanged_indices\n                + superop_indices[0]\n                + superop_indices[3]\n                + right_unchanged_indices,\n            ]\n        )\n        eqn = ""->"".join([eqn_lhs, eqn_rhs])\n        new_state = tf.einsum(eqn, superop, in_modes)\n        return new_state\n\n\n###################################################################\n\n# Quantum Gate/Channel functions:\n# Primary quantum optical gates implemented as transformations on \'in_modes\'\n\n\ndef phase_shifter(theta, mode, in_modes, D, pure=True, batched=False):\n    """"""returns phase shift unitary matrix on specified input modes""""""\n    matrix = phase_shifter_matrix(theta, D, batched=batched)\n    output = single_mode_gate(matrix, mode, in_modes, pure, batched)\n    return output\n\n\ndef displacement(alpha, mode, in_modes, D, pure=True, batched=False):\n    """"""returns displacement unitary matrix on specified input modes""""""\n    matrix = displacement_matrix(alpha, D, batched)\n    output = single_mode_gate(matrix, mode, in_modes, pure, batched)\n    return output\n\n\ndef squeezer(r, theta, mode, in_modes, D, pure=True, batched=False):\n    """"""returns squeezer unitary matrix on specified input modes""""""\n    matrix = squeezer_matrix(r, theta, D, batched)\n    output = single_mode_gate(matrix, mode, in_modes, pure, batched)\n    return output\n\n\ndef kerr_interaction(kappa, mode, in_modes, D, pure=True, batched=False):\n    """"""returns Kerr unitary matrix on specified input modes""""""\n    matrix = kerr_interaction_matrix(kappa, D, batched)\n    output = single_mode_gate(matrix, mode, in_modes, pure, batched)\n    return output\n\n\ndef cross_kerr_interaction(kappa, mode1, mode2, in_modes, D, pure=True, batched=False):\n    """"""returns cross-Kerr unitary matrix on specified input modes""""""\n    matrix = cross_kerr_interaction_matrix(kappa, D, batched)\n    output = two_mode_gate(matrix, mode1, mode2, in_modes, pure, batched)\n    return output\n\n\ndef cubic_phase(\n    gamma, mode, in_modes, D, hbar=2, pure=True, batched=False, method=""self_adjoint_eig""\n):\n    """"""returns cubic phase unitary matrix on specified input modes""""""\n    matrix = cubic_phase_matrix(gamma, D, hbar, batched, method=method)\n    output = single_mode_gate(matrix, mode, in_modes, pure, batched)\n    return output\n\n\ndef beamsplitter(t, r, mode1, mode2, in_modes, D, pure=True, batched=False):\n    """"""returns beamsplitter unitary matrix on specified input modes""""""\n    matrix = beamsplitter_matrix(t, r, D, batched)\n    output = two_mode_gate(matrix, mode1, mode2, in_modes, pure, batched)\n    return output\n\n\ndef loss_channel(T, mode, in_modes, D, pure=True, batched=False):\n    """"""returns loss channel matrix on specified input modes""""""\n    superop = loss_superop(T, D, batched)\n    output = single_mode_superop(superop, mode, in_modes, pure, batched)\n    return output\n\n\n###################################################################\n\n# Other useful functions for organizing modes\n\n\ndef combine_single_modes(modes_list, batched=False):\n    """"""Group together a list of single modes (each having dim=1 or dim=2) into a composite mode system.""""""\n    if batched:\n        batch_offset = 1\n    else:\n        batch_offset = 0\n    num_modes = len(modes_list)\n    if num_modes <= 1:\n        raise ValueError(""\'modes_list\' must have at least two modes"")\n\n    dims = np.array([len(mode.shape) - batch_offset for mode in modes_list])\n    if min(dims) < 1 or max(dims) > 2:\n        raise ValueError(""Each mode in \'modes_list\' can only have dim=1 or dim=2"")\n\n    if np.all(dims == 1):\n        # All modes are represented as pure states.\n        # Can return combined state also as pure state.\n        # basic form:\n        # \'a,b,c,...,x,y,z->abc...xyz\'\n        max_num = max_num_indices - batch_offset\n        if num_modes > max_num:\n            raise NotImplementedError(\n                ""The max number of supported modes for this operation with pure states is currently {}"".format(\n                    max_num\n                )\n            )\n        batch_index = indices[:batch_offset]\n        out_str = indices[batch_offset : batch_offset + num_modes]\n        modes_str = "","".join([batch_index + idx for idx in out_str])\n        eqn = ""{}->{}"".format(modes_str, batch_index + out_str)\n        einsum_inputs = modes_list\n    else:\n        # Some modes are mixed.\n        # Return combined state as mixed.\n        # basic form:\n        # e.g., if first mode is pure and second is mixed...\n        # \'a,b,cd,...->abcd...\'\n        # where (a,b) will belong to the first mode (bra & ket)\n        # and cd will belong to the second mode (density matrix)\n        max_num = (max_num_indices - batch_offset) // 2\n        batch_index = indices[:batch_offset]\n        if num_modes > max_num:\n            raise NotImplementedError(\n                ""The max number of supported modes for this operation with mixed states is currently {}"".format(\n                    max_num\n                )\n            )\n        mode_idxs = [\n            indices[slice(batch_offset + idx, batch_offset + idx + 2)]\n            for idx in range(0, 2 * num_modes, 2)\n        ]  # each mode gets a pair of consecutive indices\n        eqn_rhs = batch_index + """".join(mode_idxs)\n        eqn_idxs = [\n            batch_index + m if dims[idx] == 2 else "","".join(m) for idx, m in enumerate(mode_idxs)\n        ]\n        eqn_lhs = "","".join(eqn_idxs)\n        eqn = eqn_lhs + ""->"" + eqn_rhs\n        einsum_inputs = []\n        for idx, mode in enumerate(modes_list):\n            if dims[idx] == 1:\n                new_inputs = [mode, tf.math.conj(mode)]\n            elif dims[idx] == 2:\n                new_inputs = [mode]\n            einsum_inputs += new_inputs\n    combined_modes = tf.einsum(eqn, *einsum_inputs)\n    return combined_modes\n\n\ndef replace_mode(replacement, mode, system, state_is_pure, batched=False):\n    """"""Replace the subsystem \'mode\' of \'system\' with new state \'replacement\'. Argument \'state_is_pure\' indicates whether\n\n    This is just a simple wrapper for replace_modes()\n    """"""\n    # deprecated: This method has become obsolete and is superseeded by replace_modes()\n    if isinstance(mode, int):\n        mode = [mode]\n    replace_modes(replacement, mode, system, state_is_pure, batched)\n\n\ndef replace_modes(replacement, modes, system, system_is_pure, batched=False):\n    """"""Replace the subsystem \'mode\' of \'system\' with new state \'replacement\'. Argument \'system_is_pure\' indicates whether\n    \'system\' is represented by a pure state or a density matrix.\n    Note: Does not check if this replacement is physically valid (i.e., if \'replacement\' is a valid state)\n    Note: expects the shape of both replacement and system to match the batched parameter\n    Note: modes does not need to be ordered.\n    """"""\n    # todo: write a better docstring\n    if isinstance(modes, int):\n        modes = [modes]\n\n    if batched:\n        batch_offset = 1\n    else:\n        batch_offset = 0\n\n    num_modes = len(system.shape) - batch_offset\n    if not system_is_pure:\n        num_modes = int(num_modes / 2)\n\n    replacement_is_pure = bool(len(replacement.shape) - batch_offset == len(modes))\n\n    # we take care of sorting modes below\n    if len(modes) == num_modes:\n        # we are replacing all the modes\n        revised_modes = replacement\n        revised_modes_pure = replacement_is_pure\n    else:\n        # we are replacing a subset, so have to trace\n        # make both system and replacement mixed\n        # todo: For performance the partial trace could be done directly from the pure state. This would of course require a better partial trace function...\n        if system_is_pure:\n            system = mixed(system, batched)\n\n        # mix the replacement if it is pure\n        if replacement_is_pure:\n            replacement = mixed(replacement, batched)\n\n        # partial trace out modes\n        # todo: We are tracing out the modes one by one in descending order (to not screw up things). This is quite inefficient.\n        reduced_state = system\n        for mode in sorted(modes, reverse=True):\n            reduced_state = partial_trace(reduced_state, mode, False, batched)\n        # append mode and insert state (There is also insert_state(), but it seemed unnecessarily complicated to try to generalize this function, which does a lot of manual list comprehension, to the multi mode case than to write the two liner below)\n        # todo: insert_state() could be rewritten to take full advantage of the high level functions of tf. Before doing that different implementatinos should be benchmarked to compare speed and memory requirements, as in practice these methods will be perfomance critical.\n        if not batched:\n            # todo: remove the hack in the line below and enable the line with axes=0 instead, if ever we change the dependency of SF to tensorflow>=1.6\n            # revised_modes = tf.tensordot(reduced_state, replacement, axes=0)\n            revised_modes = tf.tensordot(\n                tf.expand_dims(reduced_state, 0), tf.expand_dims(replacement, 0), axes=[[0], [0]]\n            )\n        else:\n            batch_size = reduced_state.shape[0]\n            # todo: remove the hack in the line below and enabled the line with axes=0 instead, if ever we change the dependency of SF to tensorflow>=1.6\n            # revised_modes = tf.stack([tf.tensordot(reduced_state[b], replacement[b], axes=0) for b in range(batch_size)])\n            revised_modes = tf.stack(\n                [\n                    tf.tensordot(\n                        tf.expand_dims(reduced_state[b], 0),\n                        tf.expand_dims(replacement[b], 0),\n                        axes=[[0], [0]],\n                    )\n                    for b in range(batch_size)\n                ]\n            )\n        revised_modes_pure = False\n\n    # unless the preparation was meant to go into the last modes in the standard order, we need to swap indices around\n    if modes != list(range(num_modes - len(modes), num_modes)):\n        mode_permutation = [x for x in range(num_modes) if x not in modes] + modes\n        revised_modes = reorder_modes(revised_modes, mode_permutation, revised_modes_pure, batched)\n\n    return revised_modes\n\n\ndef reorder_modes(state, mode_permutation, pure, batched):\n    """"""Reorder the indices of states according to the given mode_permutation, needs to know whether the state is pure and/or batched.""""""\n    if pure:\n        scale = 1\n        index_permutation = mode_permutation\n    else:\n        scale = 2\n        index_permutation = [\n            scale * x + i for x in mode_permutation for i in (0, 1)\n        ]  # two indices per mode if we have pure states\n\n    if batched:\n        index_permutation = [0] + [i + 1 for i in index_permutation]\n\n    index_permutation = np.argsort(index_permutation)\n\n    reordered_modes = tf.transpose(state, index_permutation)\n\n    return reordered_modes\n\n\ndef insert_state(state, system, state_is_pure, mode=None, batched=False):\n    """"""\n    Append a new mode (at slot \'mode\') to system and initialize it in \'state\'.\n    If \'mode\' is not specified or is greater than the largest current mode number, the new mode is added to the end.\n    If an integer within [0,...,N-1] is given for \'mode\' (where N is the number of modes) in \'system,\'\n    then the new state is put in the corresponding mode, and all following modes are shifted to the right by one.\n    """"""\n    # pylint: disable=too-many-branches\n    num_indices = len(system.shape)\n    if batched:\n        batch_offset = 1\n    else:\n        batch_offset = 0\n    if state_is_pure:\n        num_modes = num_indices - batch_offset\n    else:\n        num_modes = (num_indices - batch_offset) // 2\n\n    if mode is None or mode >= num_modes:\n        mode = num_modes\n\n    if len(system.shape) == 0:  # pylint: disable=len-as-condition\n        # no modes in system\n        # pylint: disable=no-else-return\n        if len(state.shape) - batch_offset == 1:\n            if state_is_pure:\n                return state\n            else:\n                return mixed(state)\n        elif len(state.shape) - batch_offset == 2:\n            return state\n        else:\n            raise ValueError(\n                ""\'state\' must have dim={} or dim={}"".format(1 - batch_offset, 2 - batch_offset)\n            )\n    else:\n        # modes in system\n        if len(state.shape) == batch_offset + 1 and state_is_pure:\n            # everything is pure\n            # basic form:\n            # \'ab...ln...yz,m->ab...lmn...yz\' (\'m\' indices belong to bra of mode being inserted)\n            mode_size = 1\n        else:\n            # everything is mixed\n            # basic form:\n            # \'abcd...klop...wxyz,mn->abcd...klmnop...wxyz\' (\'mn\' indices belong to bra/ket of mode being inserted)\n            mode_size = 2\n\n        batch_index = indices[:batch_offset]\n        left_part = indices[batch_offset : batch_offset + mode * mode_size]\n        middle_part = indices[\n            batch_offset + mode * mode_size : batch_offset + (mode + 1) * mode_size\n        ]\n        right_part = indices[\n            batch_offset + (mode + 1) * mode_size : batch_offset + (num_modes + 1) * mode_size\n        ]\n        eqn_lhs = batch_index + left_part + right_part + "","" + batch_index + middle_part\n        eqn_rhs = batch_index + left_part + middle_part + right_part\n        eqn = eqn_lhs + ""->"" + eqn_rhs\n        revised_modes = tf.einsum(eqn, system, state)\n\n    return revised_modes\n\n\ndef partial_trace(system, mode, state_is_pure, batched=False):\n    """"""\n    Trace out subsystem \'mode\' from \'system\'.\n    This operation always returns a mixed state, since we do not know in advance if a mode is entangled with others.\n    """"""\n    num_indices = len(system.shape)\n    if batched:\n        batch_offset = 1\n    else:\n        batch_offset = 0\n    if state_is_pure:\n        num_modes = num_indices - batch_offset\n    else:\n        num_modes = (num_indices - batch_offset) // 2\n\n    if state_is_pure:\n        system = mixed(system, batched)\n\n    # tensorflow trace implementation\n    # requires subsystem to be traced out to be at end\n    # i.e., ab...klmnop...yz goes to ab...klop...yzmn\n    indices_list = [m for m in range(batch_offset + 2 * num_modes)]\n    dim_list = (\n        indices_list[: batch_offset + 2 * mode]\n        + indices_list[batch_offset + 2 * (mode + 1) :]\n        + indices_list[batch_offset + 2 * mode : batch_offset + 2 * (mode + 1)]\n    )\n    permuted_sys = tf.transpose(system, dim_list)\n    reduced_state = tf.linalg.trace(permuted_sys)\n    return reduced_state\n\n\ndef reduced_density_matrix(system, mode, state_is_pure, batched=False):\n    """"""\n    Trace out all subsystems except \'mode\' from \'system\'.\n    This operation always returns a mixed state, since we do not know in advance if a mode is entangled with others.\n    """"""\n    if state_is_pure:\n        reduced_state = mixed(system, batched)\n    else:\n        reduced_state = system\n    num_indices = len(reduced_state.shape)\n    if batched:\n        batch_offset = 1\n    else:\n        batch_offset = 0\n    num_modes = (num_indices - batch_offset) // 2  # always mixed\n    for m in range(num_modes):\n        if m != mode:\n            reduced_state = partial_trace(reduced_state, m, False, batched)\n    return reduced_state\n\n\ndef conditional_state(system, projector, mode, state_is_pure, batched=False):\n    """"""Compute the (unnormalized) conditional state of \'system\' after applying ket \'projector\' to \'mode\'.""""""\n    # basic_form (pure states): abc...ijk...xyz,j-> abc...ik...xyz\n    # basic_form (mixed states): abcd...ijklmn...wxyz,k,l-> abcd...ijmn...wxyz\n    mode = int(mode)\n    if not batched:\n        # add in fake batch dimension (TF 1.5 gives unexplainable errors if we do it without this)\n        system = tf.expand_dims(system, 0)\n        projector = tf.expand_dims(projector, 0)\n    num_indices = len(system.shape)\n    batch_offset = 1\n    if state_is_pure:\n        mode_size = 1\n    else:\n        mode_size = 2\n    num_modes = (num_indices - batch_offset) // mode_size\n    max_num = (max_num_indices - batch_offset) // num_modes\n    if num_modes > max_num:\n        raise ValueError(\n            ""Conditional state projection currently only supported for {} modes."".format(max_num)\n        )\n\n    batch_index = indices[:batch_offset]\n    mode_indices = indices[batch_offset : batch_offset + num_modes * mode_size]\n    projector_indices = mode_indices[:mode_size]\n    free_mode_indices = mode_indices[mode_size : num_modes * mode_size]\n    state_lhs = (\n        batch_index\n        + free_mode_indices[: mode * mode_size]\n        + projector_indices\n        + free_mode_indices[mode * mode_size :]\n    )\n    projector_lhs = batch_index + projector_indices[0]\n    if mode_size == 2:\n        projector_lhs += "","" + batch_index + projector_indices[1]\n    eqn_lhs = "","".join([state_lhs, projector_lhs])\n    eqn_rhs = batch_index + free_mode_indices\n    eqn = eqn_lhs + ""->"" + eqn_rhs\n    einsum_args = [system, tf.math.conj(projector)]\n    if not state_is_pure:\n        einsum_args.append(projector)\n    cond_state = tf.einsum(eqn, *einsum_args)\n    if not batched:\n        cond_state = tf.squeeze(cond_state, 0)  # drop fake batch dimension\n    return cond_state\n\n\n###################################################################\n\n# Helpful auxiliary functions for ops\n\n\ndef ladder_ops(D):\n    """"""returns the matrix representation of the annihilation and creation operators""""""\n    ind = [(i - 1, i) for i in range(1, D)]\n    updates = [np.sqrt(i) for i in range(1, D)]\n    shape = [D, D]\n    a = tf.scatter_nd(ind, updates, shape)\n    ad = tf.transpose(tf.math.conj(a), [1, 0])\n    return a, ad\n\n\ndef H(n, x):\n    """"""Explicit expression for Hermite polynomials.""""""\n    prefactor = factorial(n)\n    terms = tf.reduce_sum(\n        tf.stack(\n            [\n                _numer_safe_power(-1, m)\n                / (factorial(m) * factorial(n - 2 * m))\n                * _numer_safe_power(2 * x, n - 2 * m)\n                for m in range(int(np.floor(n / 2)) + 1)\n            ],\n            axis=0,\n        ),\n        axis=0,\n    )\n    return prefactor * terms\n\n\ndef H_n_plus_1(H_n, H_n_m1, n, x):\n    """"""Recurrent definition of Hermite polynomials.""""""\n    H_n_p1 = 2 * x * H_n - 2 * n * H_n_m1\n    return H_n_p1\n'"
strawberryfields/backends/tfbackend/states.py,80,"b'# Copyright 2019 Xanadu Quantum Technologies Inc.\n\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""TensorFlow states module""""""\nfrom string import ascii_lowercase as indices\n\nimport numpy as np\nimport tensorflow as tf\nfrom scipy.special import factorial\n\n# With TF 2.1+, the legacy tf.einsum was renamed to _einsum_v1, while\n# the replacement tf.einsum introduced the bug. This try-except block\n# will dynamically patch TensorFlow versions where _einsum_v1 exists, to make it the\n# default einsum implementation.\n#\n# For more details, see https://github.com/tensorflow/tensorflow/issues/37307\ntry:\n    from tensorflow.python.ops.special_math_ops import _einsum_v1\n\n    tf.einsum = _einsum_v1\nexcept ImportError:\n    pass\n\nfrom strawberryfields.backends.states import BaseFockState\nfrom .ops import def_type, ladder_ops, phase_shifter_matrix, reduced_density_matrix\n\n\nclass FockStateTF(BaseFockState):\n    r""""""Class for the representation of quantum states in the Fock basis using the TFBackend.\n\n    Args:\n            state_data (array): the state representation in the Fock basis\n            num_modes (int): the number of modes in the state\n            pure (bool): True if the state is a pure state, false if the state is mixed\n            cutoff_dim (int): the Fock basis truncation size\n            mode_names (Sequence): (optional) this argument contains a list providing mode names\n                    for each mode in the state.\n    """"""\n\n    def __init__(self, state_data, num_modes, pure, cutoff_dim, batched=False, mode_names=None):\n        # pylint: disable=too-many-arguments\n        state_data = tf.convert_to_tensor(\n            state_data, name=""state_data""\n        )  # convert everything to a Tensor so we have the option to do symbolic evaluations\n        super().__init__(state_data, num_modes, pure, cutoff_dim, mode_names)\n        self._batched = batched\n        self._str = ""<FockStateTF: num_modes={}, cutoff={}, pure={}, batched={}, hbar={}>"".format(\n            self.num_modes, self.cutoff_dim, self._pure, self._batched, self._hbar\n        )\n\n    def trace(self, **kwargs):\n        r""""""\n        Computes the trace of the state. May be numerical or symbolic.\n\n        Returns:\n            float/Tensor: the numerical value, or an unevaluated Tensor object, for the trace.\n        """"""\n        s = self.data\n        if not self.batched:\n            s = tf.expand_dims(s, 0)  # insert fake batch dimension\n        if self.is_pure:\n            flat_state = tf.reshape(s, [-1, self.cutoff_dim ** self.num_modes])\n            tr = tf.reduce_sum(flat_state * tf.math.conj(flat_state), 1)\n        else:\n            # hack because tensorflow einsum doesn\'t allow partial trace\n            tr = s\n            for _ in range(self.num_modes):\n                tr = tf.linalg.trace(tr)\n        if not self.batched:\n            tr = tf.squeeze(tr, 0)  # drop fake batch dimension\n\n        return tr\n\n    def fock_prob(self, n, **kwargs):\n        r""""""\n        Compute the probabilities of a specific Fock-basis matrix element for the state. May be numerical or symbolic.\n\n        Args:\n            n (Sequence[int]): the Fock state :math:`\\ket{\\vec{n}}` that we want to measure the probability of\n\n        Returns:\n            float/Tensor: the numerical values, or an unevaluated Tensor object, for the Fock-state probabilities.\n        """"""\n\n        if len(n) != self.num_modes:\n            raise ValueError(""List length should be equal to number of modes"")\n\n        elif max(n) >= self.cutoff_dim:\n            raise ValueError(""Can\'t get distribution beyond truncation level"")\n\n        state = self.data\n\n        if not self.batched:\n            state = tf.expand_dims(state, 0)  # add fake batch dimension\n\n        # put batch dimension at end to match behaviour of tf.gather_nd\n        if self.is_pure:\n            flat_idx = np.ravel_multi_index(n, [self.cutoff_dim] * self.num_modes)\n            flat_state = tf.reshape(state, [-1, self.cutoff_dim ** self.num_modes])\n            prob = tf.abs(flat_state[:, flat_idx]) ** 2\n        else:\n            doubled_n = [n[i // 2] for i in range(len(n) * 2)]\n            flat_idx = np.ravel_multi_index(doubled_n, [self.cutoff_dim] * (2 * self.num_modes))\n            flat_state = tf.reshape(state, [-1, self.cutoff_dim ** (2 * self.num_modes)])\n            prob = flat_state[:, flat_idx]\n\n        if not self.batched:\n            prob = tf.squeeze(prob, 0)  # drop fake batch dimension\n\n        prob = tf.math.real(prob)\n        prob = tf.identity(prob, name=""fock_prob"")\n\n        return prob\n\n    def all_fock_probs(self, **kwargs):\n        r""""""\n        Compute the probabilities of all possible Fock-basis states for the state. May be numerical or symbolic.\n\n        For example, in the case of 3 modes, this method allows the Fock state probability\n        :math:`|\\braketD{0,2,3}{\\psi}|^2` to be returned via\n\n        .. code-block:: python\n\n            probs = state.all_fock_probs()\n            probs[0,2,3]\n\n        Args:\n\n        Returns:\n            array/Tensor: the numerical values, or an unevaluated Tensor object, for the Fock-basis probabilities.\n        """"""\n\n        state = self.data\n        if not self.batched:\n            state = tf.expand_dims(state, 0)  # add fake batch dimension\n\n        if self.is_pure:\n            probs = tf.abs(state) ** 2\n        else:\n            # convert to index scheme compatible with tf.linalg.diag_part\n            rng = np.arange(1, 2 * self.num_modes + 1, 2)\n            perm = np.concatenate([[0], rng, rng + 1])\n            perm_state = tf.transpose(state, perm)\n            probs = tf.map_fn(\n                tf.linalg.tensor_diag_part, perm_state\n            )  # diag_part doesn\'t work with batches, need to use map_fn\n\n        if not self.batched:\n            probs = tf.squeeze(probs, 0)  # drop fake batch dimension\n\n        probs = tf.identity(probs, name=""all_fock_probs"")\n\n        return probs\n\n    def fidelity(self, other_state, mode, **kwargs):\n        r""""""\n        Compute the fidelity of the reduced state (on the specified mode) with the state. May be numerical or symbolic.\n\n        Args:\n            other_state (array): state vector (ket) to compute the fidelity with respect to\n            mode (int): which subsystem to use for the fidelity computation\n\n        Returns:\n            float/Tensor: the numerical value, or an unevaluated Tensor object, for the fidelity.\n        """"""\n        rho = self.reduced_dm([mode])  # don\'t pass kwargs yet\n\n        if not self.batched:\n            rho = tf.expand_dims(rho, 0)  # add fake batch dimension\n        if len(other_state.shape) == 1:\n            other_state = tf.expand_dims(other_state, 0)  # add batch dimension for state\n\n        other_state = tf.cast(other_state, def_type)\n        state_dm = tf.einsum(""bi,bj->bij"", tf.math.conj(other_state), other_state)\n        flat_state_dm = tf.reshape(state_dm, [1, -1])\n        flat_rho = tf.reshape(rho, [-1, self.cutoff_dim ** 2])\n\n        f = tf.math.real(\n            tf.reduce_sum(flat_rho * flat_state_dm, axis=1)\n        )  # implements a batched tr(rho|s><s|)\n\n        if not self.batched:\n            f = tf.squeeze(f, 0)  # drop fake batch dimension\n\n        f = tf.identity(f, name=""fidelity"")\n\n        return f\n\n    def fidelity_coherent(self, alpha_list, **kwargs):\n        r""""""\n        Compute the fidelity of the state with the coherent states specified by alpha_list. May be numerical or symbolic.\n\n        Args:\n            alpha_list (Sequence[complex]): list of coherence parameter values, one for each mode\n\n        Returns:\n            float/Tensor: the numerical value, or an unevaluated Tensor object, for the fidelity :math:`\\bra{\\vec{\\alpha}}\\rho\\ket{\\vec{\\alpha}}`.\n        """"""\n        if not hasattr(alpha_list, ""__len__""):\n            alpha_list = [alpha_list]\n\n        if len(alpha_list) != self.num_modes:\n            raise ValueError(""The number of alpha values must match the number of modes."")\n\n        max_indices = (len(indices) - 1) // 2\n        if len(alpha_list) > max_indices:\n            raise ValueError(""Length of `alpha_list` exceeds supported number of modes."")\n\n        s = self.data\n        if not self.batched:\n            s = tf.expand_dims(s, 0)  # introduce fake batch dimension\n\n        coh = lambda a, dim: [\n            np.exp(-0.5 * np.abs(a) ** 2) * (a) ** n / np.sqrt(factorial(n)) for n in range(dim)\n        ]\n        multi_cohs_list = [\n            coh(a, self.cutoff_dim) for a in alpha_list\n        ]  # shape is: [num_modes, cutoff_dim]\n        eqn = "","".join(indices[: self._modes]) + ""->"" + indices[: self._modes]\n        multi_cohs_vec = np.einsum(\n            eqn, *multi_cohs_list\n        )  # tensor product of specified coherent states\n        flat_multi_cohs = np.reshape(\n            multi_cohs_vec, [1, self.cutoff_dim ** self.num_modes]\n        )  # flattened tensor product; shape is: [1, cutoff_dim * num_modes]\n\n        if self.is_pure:\n            flat_state = tf.reshape(s, [-1, self.cutoff_dim ** self.num_modes])\n            ovlap = tf.reduce_sum(flat_multi_cohs.conj() * flat_state, axis=1)\n            f = tf.abs(ovlap) ** 2\n        else:\n            batch_index = indices[0]\n            free_indices = indices[1:]\n            bra_indices = free_indices[: self.num_modes]\n            ket_indices = free_indices[self.num_modes : 2 * self.num_modes]\n            eqn = (\n                bra_indices\n                + "",""\n                + batch_index\n                + """".join(bra_indices[idx] + ket_indices[idx] for idx in range(self.num_modes))\n                + "",""\n                + ket_indices\n                + ""->""\n                + batch_index\n            )\n            f = tf.einsum(\n                eqn,\n                tf.convert_to_tensor(np.conj(multi_cohs_vec), dtype=def_type),\n                s,\n                tf.convert_to_tensor(multi_cohs_vec, def_type),\n            )\n        if not self.batched:\n            f = tf.squeeze(f, 0)  # drop fake batch dimension\n\n        f = tf.identity(f, name=""fidelity_coherent"")\n\n        return f\n\n    def fidelity_vacuum(self, **kwargs):\n        r""""""\n        Compute the fidelity of the state with the vacuum state. May be numerical or symbolic.\n\n        Args:\n\n        Returns:\n            float/Tensor: the numerical value, or an unevaluated Tensor object, for the fidelity :math:`\\bra{\\vec{0}}\\rho\\ket{\\vec{0}}`.\n\n        """"""\n        mode_size = 1 if self.is_pure else 2\n        if self.batched:\n            vac_elem = tf.math.real(\n                tf.reshape(self.data, [-1, self.cutoff_dim ** (self.num_modes * mode_size)])[:, 0]\n            )\n        else:\n            vac_elem = tf.abs(tf.reshape(self.data, [-1])[0]) ** 2\n\n        v = tf.identity(vac_elem, name=""fidelity_vacuum"")\n\n        return v\n\n    def is_vacuum(self, tol=0.0, **kwargs):\n        r""""""\n        Computes a boolean which indicates whether the state is the vacuum state. May be numerical or symbolic.\n\n        Args:\n            tol: numerical tolerance. If the state has fidelity with vacuum within tol, then this method returns True.\n\n        Returns:\n            bool/Tensor: the boolean value, or an unevaluated Tensor object, for whether the state is in vacuum.\n        """"""\n        fidel = self.fidelity_vacuum()  # dont pass on kwargs yet\n        is_vac = tf.less_equal(1 - fidel, tol, name=""is_vacuum"")\n        return is_vac\n\n    def reduced_dm(self, modes, **kwargs):\n        r""""""\n        Computes the reduced density matrix representation of the state. May be numerical or symbolic.\n\n        Args:\n            modes (int or Sequence[int]): specifies the mode(s) to return the reduced\n                                density matrix for.\n\n        Returns:\n            array/Tensor: the numerical value, or an unevaluated Tensor object, for the density matrix.\n        """"""\n        if modes == list(range(self.num_modes)):\n            # reduced state is full state\n            return self.dm(**kwargs)\n\n        if isinstance(modes, int):\n            modes = [modes]\n        if modes != sorted(modes):\n            raise ValueError(""The specified modes cannot be duplicated."")\n        if len(modes) > self.num_modes:\n            raise ValueError(\n                ""The number of specified modes cannot "" ""be larger than the number of subsystems.""\n            )\n\n        reduced = self.dm(**kwargs)\n        for m in modes:\n            reduced = reduced_density_matrix(reduced, m, False, batched=self.batched)\n\n        s = tf.identity(reduced, name=""reduced_density_matrix"")\n        return s\n\n    def quad_expectation(self, mode, phi=0.0, **kwargs):\n        r""""""\n        Compute the expectation value of the quadrature operator :math:`\\hat{x}_\\phi` for the reduced state on the specified mode. May be numerical or symbolic.\n\n        Args:\n            mode (int): which subsystem to take the expectation value of\n            phi (float): rotation angle for the quadrature operator\n\n        Returns:\n                float/Tensor: the numerical value, or an unevaluated Tensor object, for the expectation value\n        """"""\n        rho = self.reduced_dm([mode])  # don\'t pass kwargs yet\n\n        phi = tf.convert_to_tensor(phi)\n        if self.batched and len(phi.shape) == 0:  # pylint: disable=len-as-condition\n            phi = tf.expand_dims(phi, 0)\n        larger_cutoff = self.cutoff_dim + 1  # start one dimension higher to avoid truncation errors\n        R = phase_shifter_matrix(phi, larger_cutoff, batched=self.batched)\n        if not self.batched:\n            R = tf.expand_dims(R, 0)  # add fake batch dimension\n\n        a, ad = ladder_ops(larger_cutoff)\n        x = np.sqrt(self._hbar / 2.0) * (a + ad)\n        x = tf.expand_dims(tf.cast(x, def_type), 0)  # add batch dimension to x\n        quad = tf.math.conj(R) @ x @ R\n        quad2 = (quad @ quad)[:, : self.cutoff_dim, : self.cutoff_dim]\n        quad = quad[\n            :, : self.cutoff_dim, : self.cutoff_dim\n        ]  # drop highest dimension; remaining array gives correct truncated x**2\n\n        if not self.batched:\n            rho = tf.expand_dims(rho, 0)  # add fake batch dimension\n\n        flat_rho = tf.reshape(rho, [-1, self.cutoff_dim ** 2])\n        flat_quad = tf.reshape(quad, [1, self.cutoff_dim ** 2])\n        flat_quad2 = tf.reshape(quad2, [1, self.cutoff_dim ** 2])\n\n        e = tf.math.real(\n            tf.reduce_sum(flat_rho * flat_quad, axis=1)\n        )  # implements a batched tr(rho * x)\n        e2 = tf.math.real(\n            tf.reduce_sum(flat_rho * flat_quad2, axis=1)\n        )  # implements a batched tr(rho * x ** 2)\n        v = e2 - e ** 2\n\n        if not self.batched:\n            e = tf.squeeze(e, 0)  # drop fake batch dimension\n            v = tf.squeeze(v, 0)  # drop fake batch dimension\n\n        e = tf.identity(e, name=""quad_expectation"")\n        v = tf.identity(v, name=""quad_variance"")\n\n        return e, v\n\n    def mean_photon(self, mode, **kwargs):\n        r""""""\n        Compute the mean photon number for the reduced state on the specified mode. May be numerical or symbolic.\n\n        Args:\n            mode (int): which subsystem to take the mean photon number of\n\n        Returns:\n            tuple(float/Tensor): tuple containing the numerical value, or an unevaluated Tensor object, for the mean photon number and variance.\n        """"""\n        rho = self.reduced_dm([mode])  # don\'t pass kwargs yet\n\n        if not self.batched:\n            rho = tf.expand_dims(rho, 0)  # add fake batch dimension\n\n        n = np.diag(np.arange(self.cutoff_dim))\n        flat_n = np.reshape(n, [1, self.cutoff_dim ** 2])\n\n        flat_rho = tf.reshape(rho, [-1, self.cutoff_dim ** 2])\n\n        nbar = tf.math.real(\n            tf.reduce_sum(flat_rho * flat_n, axis=1)\n        )  # implements a batched tr(rho * n)\n        nbarSq = tf.math.real(\n            tf.reduce_sum(flat_rho * flat_n ** 2, axis=1)\n        )  # implements a batched tr(rho * n^2)\n        var = nbarSq - nbar ** 2\n        if not self.batched:\n            nbar = tf.squeeze(nbar, 0)  # drop fake batch dimension\n            var = tf.squeeze(var, 0)  # drop fake batch dimension\n\n        nbar = tf.identity(nbar, name=""mean_photon"")\n        var = tf.identity(var, name=""mean_photon_variance"")\n\n        return nbar, var\n\n    def ket(self, **kwargs):\n        r""""""\n        Computes the ket representation of the state. May be numerical or symbolic.\n\n        Args:\n\n        Returns:\n            array/Tensor: the numerical value, or an unevaluated Tensor object, for the ket.\n        """"""\n        if not self.is_pure:\n            return None\n\n        s = tf.identity(self.data, name=""ket"")\n        return s\n\n    def dm(self, **kwargs):\n        r""""""\n        Computes the density matrix representation of the state. May be numerical or symbolic.\n\n        Args:\n\n        Returns:\n            array/Tensor: the numerical value, or an unevaluated Tensor object, for the density matrix.\n        """"""\n        if self.is_pure:\n            if self.batched:\n                batch_index = indices[0]\n                free_indices = indices[1:]\n            else:\n                batch_index = """"\n                free_indices = indices\n            ket = self.data\n            left_str = [batch_index] + [free_indices[i] for i in range(0, 2 * self.num_modes, 2)]\n            right_str = [batch_index] + [free_indices[i] for i in range(1, 2 * self.num_modes, 2)]\n            out_str = [batch_index] + [free_indices[: 2 * self.num_modes]]\n            einstr = """".join(left_str + ["",""] + right_str + [""->""] + out_str)\n            s = tf.einsum(einstr, ket, tf.math.conj(ket))\n        else:\n            s = tf.identity(self.data, name=""density_matrix"")\n\n        return s\n\n    def wigner(self, mode, xvec, pvec):\n        r""""""Calculates the discretized Wigner function of the specified mode.\n\n        .. warning::\n\n            Calculation of the Wigner function is currently only supported if\n            ``eval=True`` and ``batched=False``.\n\n        .. note::\n\n            This code is a modified version of the \'iterative\' method of the\n            `wigner function provided in QuTiP <http://qutip.org/docs/4.0.2/apidoc/functions.html?highlight=wigner#qutip.wigner.wigner>`_,\n            which is released under the BSD license, with the following\n            copyright notice:\n\n            Copyright (C) 2011 and later, P.D. Nation, J.R. Johansson,\n            A.J.G. Pitchford, C. Granade, and A.L. Grimsmo. All rights reserved.\n\n        Args:\n            mode (int): the mode to calculate the Wigner function for\n            xvec (array): array of discretized :math:`x` quadrature values\n            pvec (array): array of discretized :math:`p` quadrature values\n\n        Returns:\n            array: 2D array of size [len(xvec), len(pvec)], containing reduced Wigner function\n            values for specified x and p values.\n        """"""\n        if not self.batched:\n            return super().wigner(mode, xvec, pvec)\n\n        raise NotImplementedError(\n            ""Calculation of the Wigner function is currently "" ""only supported when batched=False""\n        )\n\n    def poly_quad_expectation(self, A, d=None, k=0, phi=0, **kwargs):  # pragma: no cover\n        r""""""The multi-mode expectation values and variance of arbitrary 2nd order polynomials\n        of quadrature operators.\n\n        .. warning::\n\n            Calculation of multi-mode quadratic expectation values is currently only supported if\n            ``eval=True`` and ``batched=False``.\n\n        An arbitrary 2nd order polynomial of quadrature operators over $N$ modes can always\n        be written in the following form:\n\n        .. math:: P(\\mathbf{r}) = \\mathbf{r}^T A\\mathbf{r} + \\mathbf{r}^T \\mathbf{d} + k I\n\n        where:\n\n        * :math:`A\\in\\mathbb{R}^{2N\\times 2N}` is a symmetric matrix\n          representing the quadratic coefficients,\n        * :math:`\\mathbf{d}\\in\\mathbb{R}^{2N}` is a real vector representing\n          the linear coefficients,\n        * :math:`k\\in\\mathbb{R}` represents the constant term, and\n        * :math:`\\mathbf{r} = (\\x_1,\\dots,\\x_N,\\p_1,\\dots,\\p_N)` is the vector\n          of quadrature operators in :math:`xp`-ordering.\n\n        This method returns the expectation value of this second-order polynomial,\n\n        .. math:: \\langle P(\\mathbf{r})\\rangle,\n\n        as well as the variance\n\n        .. math:: \\Delta P(\\mathbf{r})^2 = \\langle P(\\mathbf{r})^2\\rangle - \\braket{P(\\mathbf{r})}^2\n\n        Args:\n            A (array): a real symmetric 2Nx2N NumPy array, representing the quadratic\n                coefficients of the second order quadrature polynomial.\n            d (array): a symmetric length-2N NumPy array, representing the linear\n                coefficients of the second order quadrature polynomial. Defaults to the zero vector.\n            k (float): the constant term. Default 0.\n            phi (float): quadrature angle, clockwise from the positive :math:`x` axis. If provided,\n                the vector of quadrature operators :math:`\\mathbf{r}` is first rotated\n                by angle :math:`\\phi` in the phase space.\n\n        Returns:\n            tuple (float, float): expectation value and variance\n        """"""\n\n        if not self.batched:\n            return super().poly_quad_expectation(A, d, k, phi, **kwargs)\n        else:\n            raise NotImplementedError(\n                ""Calculation of multi-mode quadratic expectation values is currently ""\n                ""only supported when batched=False.""\n            )\n\n    @property\n    def batched(self):\n        """"""The number of batches.""""""\n        return self._batched\n'"
