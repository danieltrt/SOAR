file_path,api_count,code
app.py,0,"b'# -*- coding: utf-8 -*-\nimport io\nimport base64\nimport flask\nimport numpy as np\nfrom PIL import Image, ImageFile\nfrom verify import pretreatment\nimport tflite_runtime.interpreter as tflite\n\napp = flask.Flask(__name__)\n# \xe6\xa8\xa1\xe5\x9e\x8b\xe7\x9a\x84\xe5\x85\xa8\xe5\xb1\x80\xe5\x8f\x98\xe9\x87\x8f\ntextModel = None\nimgModel = None\n# \xe8\xae\xbe\xe7\xbd\xae\xe5\x8a\xa0\xe8\xbd\xbd\xe6\x88\xaa\xe6\x96\xad\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xef\xbc\x8c\xe8\xa7\xa3\xe5\x86\xb3issue #10\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n\n@app.before_first_request\ndef load_model():\n    \'\'\'\n    \xe5\x8a\xa0\xe8\xbd\xbd\xe6\xa8\xa1\xe5\x9e\x8b\xe5\x87\xbd\xe6\x95\xb0\n    :return:\n    \'\'\'\n    global textModel\n    global imgModel\n    textModel = tflite.Interpreter(\n        \'text.model.tflite\')\n    textModel.allocate_tensors()\n    imgModel = tflite.Interpreter(\n        \'image.model.tflite\')\n    imgModel.allocate_tensors()\n\n\ndef predict(model, input):\n    input_details = model.get_input_details()\n    output_details = model.get_output_details()\n    model.set_tensor(input_details[0][\'index\'], np.float32(input))\n    model.invoke()\n    result = model.get_tensor(output_details[0][\'index\'])\n    return result\n\n\ndef base64_to_image(base64_code):\n    \'\'\'\n    :param base64_code: base64\xe7\xbc\x96\xe7\xa0\x81\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\n    :return: bgr\xe6\xa0\xbc\xe5\xbc\x8f\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\n    \'\'\'\n    # base64\xe8\xa7\xa3\xe7\xa0\x81\n    img_data = base64.b64decode(base64_code)\n    # \xe8\xaf\xbb\xe5\x8f\x96\xe5\x9b\xbe\xe7\x89\x87\n    img = np.asarray(Image.open(io.BytesIO(img_data)))\n    # \xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xbabgr\xe6\xa0\xbc\xe5\xbc\x8f\n    img = img[..., ::-1]\n\n    return img\n\n\ndef get_text(img, offset=0):\n    \'\'\'\n    \xe5\xbe\x97\xe5\x88\xb0\xe5\x9b\xbe\xe7\x89\x87\xe4\xb8\xad\xe6\x96\x87\xe5\xad\x97\xe7\x9a\x84\xe9\x83\xa8\xe5\x88\x86\n    :param img: \xe5\x8e\x9f\xe5\xa7\x8b\xe5\x9b\xbe\xe5\x83\x8f\n    :param offset:\n    :return: \xe6\x96\x87\xe5\xad\x97\xe9\x83\xa8\xe5\x88\x86\xe7\x9a\x84\xe7\x81\xb0\xe5\xba\xa6\xe5\x9b\xbe\xe5\x83\x8f\n    \'\'\'\n    text = pretreatment.get_text(img, offset)\n    text = text[..., 0] * 0.114 + text[..., 1] * 0.587 + text[\n        ..., 2] * 0.299\n    text = text / 255.0\n    h, w = text.shape\n    text.shape = (1, h, w, 1)\n    return text\n\n\ndef preprocess_input(x):\n    x = x.astype(\'float32\')\n    # \xe6\x88\x91\xe6\x98\xaf\xe7\x94\xa8cv2\xe6\x9d\xa5\xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xef\xbc\x8c\xe5\x85\xb6\xe5\xb7\xb2\xe7\xbb\x8f\xe6\x98\xafBGR\xe6\xa0\xbc\xe5\xbc\x8f\xe4\xba\x86\n    mean = [103.939, 116.779, 123.68]\n    x -= mean\n    return x\n\n\n@app.route(\'/verify/base64/\', methods=[\'POST\'])\ndef predict_verify():\n    verify_titles = [\'\xe6\x89\x93\xe5\xad\x97\xe6\x9c\xba\', \'\xe8\xb0\x83\xe8\x89\xb2\xe6\x9d\xbf\', \'\xe8\xb7\x91\xe6\xad\xa5\xe6\x9c\xba\', \'\xe6\xaf\x9b\xe7\xba\xbf\', \'\xe8\x80\x81\xe8\x99\x8e\', \'\xe5\xae\x89\xe5\x85\xa8\xe5\xb8\xbd\', \'\xe6\xb2\x99\xe5\x8c\x85\', \'\xe7\x9b\x98\xe5\xad\x90\', \'\xe6\x9c\xac\xe5\xad\x90\', \'\xe8\x8d\xaf\xe7\x89\x87\', \'\xe5\x8f\x8c\xe9\x9d\xa2\xe8\x83\xb6\', \'\xe9\xbe\x99\xe8\x88\x9f\', \'\xe7\xba\xa2\xe9\x85\x92\', \'\xe6\x8b\x96\xe6\x8a\x8a\', \'\xe5\x8d\xb7\xe5\xb0\xba\',\n                     \'\xe6\xb5\xb7\xe8\x8b\x94\', \'\xe7\xba\xa2\xe8\xb1\x86\', \'\xe9\xbb\x91\xe6\x9d\xbf\', \'\xe7\x83\xad\xe6\xb0\xb4\xe8\xa2\x8b\', \'\xe7\x83\x9b\xe5\x8f\xb0\', \'\xe9\x92\x9f\xe8\xa1\xa8\', \'\xe8\xb7\xaf\xe7\x81\xaf\', \'\xe6\xb2\x99\xe6\x8b\x89\', \'\xe6\xb5\xb7\xe6\x8a\xa5\', \'\xe5\x85\xac\xe4\xba\xa4\xe5\x8d\xa1\', \'\xe6\xa8\xb1\xe6\xa1\x83\', \'\xe5\x88\x9b\xe5\x8f\xaf\xe8\xb4\xb4\', \'\xe7\x89\x8c\xe5\x9d\x8a\', \'\xe8\x8b\x8d\xe8\x9d\x87\xe6\x8b\x8d\', \'\xe9\xab\x98\xe5\x8e\x8b\xe9\x94\x85\',\n                     \'\xe7\x94\xb5\xe7\xba\xbf\', \'\xe7\xbd\x91\xe7\x90\x83\xe6\x8b\x8d\', \'\xe6\xb5\xb7\xe9\xb8\xa5\', \'\xe9\xa3\x8e\xe9\x93\x83\', \'\xe8\xae\xa2\xe4\xb9\xa6\xe6\x9c\xba\', \'\xe5\x86\xb0\xe7\xae\xb1\', \'\xe8\xaf\x9d\xe6\xa2\x85\', \'\xe6\x8e\x92\xe9\xa3\x8e\xe6\x9c\xba\', \'\xe9\x94\x85\xe9\x93\xb2\', \'\xe7\xbb\xbf\xe8\xb1\x86\', \'\xe8\x88\xaa\xe6\xaf\x8d\', \'\xe7\x94\xb5\xe5\xad\x90\xe7\xa7\xa4\', \'\xe7\xba\xa2\xe6\x9e\xa3\', \'\xe9\x87\x91\xe5\xad\x97\xe5\xa1\x94\', \'\xe9\x9e\xad\xe7\x82\xae\',\n                     \'\xe8\x8f\xa0\xe8\x90\x9d\', \'\xe5\xbc\x80\xe7\x93\xb6\xe5\x99\xa8\', \'\xe7\x94\xb5\xe9\xa5\xad\xe7\x85\xb2\', \'\xe4\xbb\xaa\xe8\xa1\xa8\xe7\x9b\x98\', \'\xe6\xa3\x89\xe6\xa3\x92\', \'\xe7\xaf\xae\xe7\x90\x83\', \'\xe7\x8b\xae\xe5\xad\x90\', \'\xe8\x9a\x82\xe8\x9a\x81\', \'\xe8\x9c\xa1\xe7\x83\x9b\', \'\xe8\x8c\xb6\xe7\x9b\x85\', \'\xe5\x8d\xb0\xe7\xab\xa0\', \'\xe8\x8c\xb6\xe5\x87\xa0\', \'\xe5\x95\xa4\xe9\x85\x92\', \'\xe6\xa1\xa3\xe6\xa1\x88\xe8\xa2\x8b\', \'\xe6\x8c\x82\xe9\x92\x9f\',\n                     \'\xe5\x88\xba\xe7\xbb\xa3\',\n                     \'\xe9\x93\x83\xe9\x93\x9b\', \'\xe6\x8a\xa4\xe8\x85\x95\', \'\xe6\x89\x8b\xe6\x8e\x8c\xe5\x8d\xb0\', \'\xe9\x94\xa6\xe6\x97\x97\', \'\xe6\x96\x87\xe5\x85\xb7\xe7\x9b\x92\', \'\xe8\xbe\xa3\xe6\xa4\x92\xe9\x85\xb1\', \'\xe8\x80\xb3\xe5\xa1\x9e\', \'\xe4\xb8\xad\xe5\x9b\xbd\xe7\xbb\x93\', \'\xe8\x9c\xa5\xe8\x9c\xb4\', \'\xe5\x89\xaa\xe7\xba\xb8\', \'\xe6\xbc\x8f\xe6\x96\x97\', \'\xe9\x94\xa3\', \'\xe8\x92\xb8\xe7\xac\xbc\', \'\xe7\x8f\x8a\xe7\x91\x9a\', \'\xe9\x9b\xa8\xe9\x9d\xb4\',\n                     \'\xe8\x96\xaf\xe6\x9d\xa1\',\n                     \'\xe8\x9c\x9c\xe8\x9c\x82\', \'\xe6\x97\xa5\xe5\x8e\x86\', \'\xe5\x8f\xa3\xe5\x93\xa8\']\n    if flask.request.method == \'POST\':\n        # \xe8\xaf\xbb\xe5\x8f\x96\xe5\xb9\xb6\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe9\xaa\x8c\xe8\xaf\x81\xe7\xa0\x81\n        img = flask.request.form[\'imageFile\']\n        img = base64_to_image(img)\n        text = get_text(img)\n        imgs = np.array(list(pretreatment._get_imgs(img)))\n        imgs = preprocess_input(imgs)\n        text_list = []\n        label = predict(textModel, text)\n        label = label.argmax()\n        text = verify_titles[label]\n        text_list.append(text)\n        # \xe8\x8e\xb7\xe5\x8f\x96\xe4\xb8\x8b\xe4\xb8\x80\xe4\xb8\xaa\xe8\xaf\x8d\n        # \xe6\xa0\xb9\xe6\x8d\xae\xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe8\xaf\x8d\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xe6\x9d\xa5\xe5\xae\x9a\xe4\xbd\x8d\xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe8\xaf\x8d\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\n        if len(text) == 1:\n            offset = 27\n        elif len(text) == 2:\n            offset = 47\n        else:\n            offset = 60\n        text = get_text(img, offset=offset)\n        if text.mean() < 0.95:\n            label = predict(textModel, text)\n            label = label.argmax()\n            text = verify_titles[label]\n            text_list.append(text)\n\n        print(f""\xe9\xa2\x98\xe7\x9b\xae\xe4\xb8\xba{text_list}"")\n        labels = predict(imgModel, imgs)\n        labels = labels.argmax(axis=1)\n        results = []\n        for pos, label in enumerate(labels):\n            l = verify_titles[label]\n            print(pos + 1, l)\n            if l in text_list:\n                results.append(str(pos + 1))\n        if(len(results) != 0):\n            return {\'code\': 0, \'massage\': \'\xe8\xaf\x86\xe5\x88\xab\xe6\x88\x90\xe5\x8a\x9f\', \'data\': results}\n        else:\n            return {\'code\': 1, \'massage\': \'\xe8\xaf\x86\xe5\x88\xab\xe5\xa4\xb1\xe8\xb4\xa5\', \'data\': results}\n\n\n@app.route(\'/\')\ndef hello_world():\n    return \'Hello World!\'\n\n\nif __name__ == \'__main__\':\n    app.run()\n'"
gunicorn.conf.py,0,"b'import multiprocessing\nimport os\n\nbind = ""0.0.0.0:80""\nworkers = os.getenv(""WORKERS"",1)\nworker_class = ""gevent""'"
verify/__init__.py,0,b''
verify/localVerifyCode.py,1,"b'# coding: utf-8\nimport TickerConfig\n\nif TickerConfig.AUTO_CODE_TYPE == 2:\n    import base64\n    import os\n    import numpy as np\n    from keras import models, backend\n    import tensorflow as tf\n    from verify import pretreatment\n    from verify.mlearn_for_image import preprocess_input\n    from io import BytesIO\n    from PIL import Image\n\n    graph = tf.get_default_graph()\n\nPATH = lambda p: os.path.abspath(\n    os.path.join(os.path.dirname(__file__), p)\n)\n\nTEXT_MODEL = """"\nIMG_MODEL = """"\n\n\ndef get_text(img, offset=0):\n    text = pretreatment.get_text(img, offset)\n    text = text[..., 0] * 0.114 + text[..., 1] * 0.587 + text[\n        ..., 2] * 0.299  # text = cv2.cvtColor(text, cv2.COLOR_BGR2GRAY)\n    text = text / 255.0\n    h, w = text.shape\n    text.shape = (1, h, w, 1)\n    return text\n\n\ndef base64_to_image(base64_code):\n    # base64\xe8\xa7\xa3\xe7\xa0\x81\n    img_data = base64.b64decode(base64_code)\n    # \xe8\xaf\xbb\xe5\x8f\x96\xe5\x9b\xbe\xe7\x89\x87\n    img = np.asarray(Image.open(BytesIO(img_data)))\n    # \xe8\xbd\xac\xe6\x8d\xa2\xe4\xb8\xbabgr\xe6\xa0\xbc\xe5\xbc\x8f\n    img = img[..., ::-1]\n\n    return img\n\n\nclass Verify:\n    def __init__(self):\n        self.textModel = """"\n        self.imgModel = """"\n        self.loadImgModel()\n        self.loadTextModel()\n\n    def loadTextModel(self):\n        if not self.textModel:\n            self.textModel = models.load_model(PATH(\'../model.v2.0.h5\'))\n        else:\n            print(""\xe6\x97\xa0\xe9\x9c\x80\xe5\x8a\xa0\xe8\xbd\xbd\xe6\xa8\xa1\xe5\x9e\x8bmodel.v2.0.h5"")\n\n    def loadImgModel(self):\n        if not self.imgModel:\n            self.imgModel = models.load_model(PATH(\'../12306.image.model.h5\'))\n\n    def verify(self, fn):\n        verify_titles = [\'\xe6\x89\x93\xe5\xad\x97\xe6\x9c\xba\', \'\xe8\xb0\x83\xe8\x89\xb2\xe6\x9d\xbf\', \'\xe8\xb7\x91\xe6\xad\xa5\xe6\x9c\xba\', \'\xe6\xaf\x9b\xe7\xba\xbf\', \'\xe8\x80\x81\xe8\x99\x8e\', \'\xe5\xae\x89\xe5\x85\xa8\xe5\xb8\xbd\', \'\xe6\xb2\x99\xe5\x8c\x85\', \'\xe7\x9b\x98\xe5\xad\x90\', \'\xe6\x9c\xac\xe5\xad\x90\', \'\xe8\x8d\xaf\xe7\x89\x87\', \'\xe5\x8f\x8c\xe9\x9d\xa2\xe8\x83\xb6\', \'\xe9\xbe\x99\xe8\x88\x9f\', \'\xe7\xba\xa2\xe9\x85\x92\', \'\xe6\x8b\x96\xe6\x8a\x8a\', \'\xe5\x8d\xb7\xe5\xb0\xba\',\n                         \'\xe6\xb5\xb7\xe8\x8b\x94\', \'\xe7\xba\xa2\xe8\xb1\x86\', \'\xe9\xbb\x91\xe6\x9d\xbf\', \'\xe7\x83\xad\xe6\xb0\xb4\xe8\xa2\x8b\', \'\xe7\x83\x9b\xe5\x8f\xb0\', \'\xe9\x92\x9f\xe8\xa1\xa8\', \'\xe8\xb7\xaf\xe7\x81\xaf\', \'\xe6\xb2\x99\xe6\x8b\x89\', \'\xe6\xb5\xb7\xe6\x8a\xa5\', \'\xe5\x85\xac\xe4\xba\xa4\xe5\x8d\xa1\', \'\xe6\xa8\xb1\xe6\xa1\x83\', \'\xe5\x88\x9b\xe5\x8f\xaf\xe8\xb4\xb4\', \'\xe7\x89\x8c\xe5\x9d\x8a\', \'\xe8\x8b\x8d\xe8\x9d\x87\xe6\x8b\x8d\', \'\xe9\xab\x98\xe5\x8e\x8b\xe9\x94\x85\',\n                         \'\xe7\x94\xb5\xe7\xba\xbf\', \'\xe7\xbd\x91\xe7\x90\x83\xe6\x8b\x8d\', \'\xe6\xb5\xb7\xe9\xb8\xa5\', \'\xe9\xa3\x8e\xe9\x93\x83\', \'\xe8\xae\xa2\xe4\xb9\xa6\xe6\x9c\xba\', \'\xe5\x86\xb0\xe7\xae\xb1\', \'\xe8\xaf\x9d\xe6\xa2\x85\', \'\xe6\x8e\x92\xe9\xa3\x8e\xe6\x9c\xba\', \'\xe9\x94\x85\xe9\x93\xb2\', \'\xe7\xbb\xbf\xe8\xb1\x86\', \'\xe8\x88\xaa\xe6\xaf\x8d\', \'\xe7\x94\xb5\xe5\xad\x90\xe7\xa7\xa4\', \'\xe7\xba\xa2\xe6\x9e\xa3\', \'\xe9\x87\x91\xe5\xad\x97\xe5\xa1\x94\', \'\xe9\x9e\xad\xe7\x82\xae\',\n                         \'\xe8\x8f\xa0\xe8\x90\x9d\', \'\xe5\xbc\x80\xe7\x93\xb6\xe5\x99\xa8\', \'\xe7\x94\xb5\xe9\xa5\xad\xe7\x85\xb2\', \'\xe4\xbb\xaa\xe8\xa1\xa8\xe7\x9b\x98\', \'\xe6\xa3\x89\xe6\xa3\x92\', \'\xe7\xaf\xae\xe7\x90\x83\', \'\xe7\x8b\xae\xe5\xad\x90\', \'\xe8\x9a\x82\xe8\x9a\x81\', \'\xe8\x9c\xa1\xe7\x83\x9b\', \'\xe8\x8c\xb6\xe7\x9b\x85\', \'\xe5\x8d\xb0\xe7\xab\xa0\', \'\xe8\x8c\xb6\xe5\x87\xa0\', \'\xe5\x95\xa4\xe9\x85\x92\', \'\xe6\xa1\xa3\xe6\xa1\x88\xe8\xa2\x8b\', \'\xe6\x8c\x82\xe9\x92\x9f\',\n                         \'\xe5\x88\xba\xe7\xbb\xa3\',\n                         \'\xe9\x93\x83\xe9\x93\x9b\', \'\xe6\x8a\xa4\xe8\x85\x95\', \'\xe6\x89\x8b\xe6\x8e\x8c\xe5\x8d\xb0\', \'\xe9\x94\xa6\xe6\x97\x97\', \'\xe6\x96\x87\xe5\x85\xb7\xe7\x9b\x92\', \'\xe8\xbe\xa3\xe6\xa4\x92\xe9\x85\xb1\', \'\xe8\x80\xb3\xe5\xa1\x9e\', \'\xe4\xb8\xad\xe5\x9b\xbd\xe7\xbb\x93\', \'\xe8\x9c\xa5\xe8\x9c\xb4\', \'\xe5\x89\xaa\xe7\xba\xb8\', \'\xe6\xbc\x8f\xe6\x96\x97\', \'\xe9\x94\xa3\', \'\xe8\x92\xb8\xe7\xac\xbc\', \'\xe7\x8f\x8a\xe7\x91\x9a\', \'\xe9\x9b\xa8\xe9\x9d\xb4\',\n                         \'\xe8\x96\xaf\xe6\x9d\xa1\',\n                         \'\xe8\x9c\x9c\xe8\x9c\x82\', \'\xe6\x97\xa5\xe5\x8e\x86\', \'\xe5\x8f\xa3\xe5\x93\xa8\']\n        # \xe8\xaf\xbb\xe5\x8f\x96\xe5\xb9\xb6\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xe9\xaa\x8c\xe8\xaf\x81\xe7\xa0\x81\n        img = base64_to_image(fn)\n        text = get_text(img)\n        imgs = np.array(list(pretreatment._get_imgs(img)))\n        imgs = preprocess_input(imgs)\n        text_list = []\n        # \xe8\xaf\x86\xe5\x88\xab\xe6\x96\x87\xe5\xad\x97\n        self.loadTextModel()\n        global graph\n        with graph.as_default():\n            label = self.textModel.predict(text)\n        label = label.argmax()\n        text = verify_titles[label]\n        text_list.append(text)\n        # \xe8\x8e\xb7\xe5\x8f\x96\xe4\xb8\x8b\xe4\xb8\x80\xe4\xb8\xaa\xe8\xaf\x8d\n        # \xe6\xa0\xb9\xe6\x8d\xae\xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaa\xe8\xaf\x8d\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xe6\x9d\xa5\xe5\xae\x9a\xe4\xbd\x8d\xe7\xac\xac\xe4\xba\x8c\xe4\xb8\xaa\xe8\xaf\x8d\xe7\x9a\x84\xe4\xbd\x8d\xe7\xbd\xae\n        if len(text) == 1:\n            offset = 27\n        elif len(text) == 2:\n            offset = 47\n        else:\n            offset = 60\n        text = get_text(img, offset=offset)\n        if text.mean() < 0.95:\n            with graph.as_default():\n                label = self.textModel.predict(text)\n            label = label.argmax()\n            text = verify_titles[label]\n            text_list.append(text)\n        print(""\xe9\xa2\x98\xe7\x9b\xae\xe4\xb8\xba{}"".format(text_list))\n        # \xe5\x8a\xa0\xe8\xbd\xbd\xe5\x9b\xbe\xe7\x89\x87\xe5\x88\x86\xe7\xb1\xbb\xe5\x99\xa8\n        self.loadImgModel()\n        with graph.as_default():\n            labels = self.imgModel.predict(imgs)\n        labels = labels.argmax(axis=1)\n        results = []\n        for pos, label in enumerate(labels):\n            l = verify_titles[label]\n            print(pos + 1, l)\n            if l in text_list:\n                results.append(str(pos + 1))\n        return results\n\n\nif __name__ == \'__main__\':\n    pass\n    # verify(""verify-img1.jpeg"")\n'"
verify/mlearn_for_image.py,0,"b""# coding: utf-8\n\n\ndef preprocess_input(x):\n    x = x.astype('float32')\n    # \xe6\x88\x91\xe6\x98\xaf\xe7\x94\xa8cv2\xe6\x9d\xa5\xe8\xaf\xbb\xe5\x8f\x96\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xef\xbc\x8c\xe5\x85\xb6\xe5\xb7\xb2\xe7\xbb\x8f\xe6\x98\xafBGR\xe6\xa0\xbc\xe5\xbc\x8f\xe4\xba\x86\n    mean = [103.939, 116.779, 123.68]\n    x -= mean\n    return x\n"""
verify/pretreatment.py,0,"b'#! env python\n# coding: utf-8\n# \xe5\x8a\x9f\xe8\x83\xbd\xef\xbc\x9a\xe5\xaf\xb9\xe5\x9b\xbe\xe5\x83\x8f\xe8\xbf\x9b\xe8\xa1\x8c\xe9\xa2\x84\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe5\xb0\x86\xe6\x96\x87\xe5\xad\x97\xe9\x83\xa8\xe5\x88\x86\xe5\x8d\x95\xe7\x8b\xac\xe6\x8f\x90\xe5\x8f\x96\xe5\x87\xba\xe6\x9d\xa5\n# \xe5\xb9\xb6\xe5\xad\x98\xe6\x94\xbe\xe5\x88\xb0ocr\xe7\x9b\xae\xe5\xbd\x95\xe4\xb8\x8b\n# \xe6\x96\x87\xe4\xbb\xb6\xe5\x90\x8d\xe4\xb8\xba\xe5\x8e\x9f\xe9\xaa\x8c\xe8\xaf\x81\xe7\xa0\x81\xe6\x96\x87\xe4\xbb\xb6\xe7\x9a\x84\xe6\x96\x87\xe4\xbb\xb6\xe5\x90\x8d\n\n\ndef get_text(img, offset=0):\n    # \xe5\xbe\x97\xe5\x88\xb0\xe5\x9b\xbe\xe5\x83\x8f\xe4\xb8\xad\xe7\x9a\x84\xe6\x96\x87\xe6\x9c\xac\xe9\x83\xa8\xe5\x88\x86\n    return img[3:22, 120 + offset:177 + offset]\n\n\ndef _get_imgs(img):\n    interval = 5\n    length = 67\n    for x in range(40, img.shape[0] - length, interval + length):\n        for y in range(interval, img.shape[1] - length, interval + length):\n            yield img[x:x + length, y:y + length]\n'"
