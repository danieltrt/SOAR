file_path,api_count,code
predictor-ml/mfcc.py,0,"b'import python_speech_features as psf\nimport numpy as np\n\nsampleRate = 22050 # in Hz\nmfccStepT = 0.02  # in seconds. generate cepstral coefficients every N seconds.\nmfccWinlen = 0.05  # in seconds. use N seconds of audio data to compute cepstral coefficients\nmfccNceps = 13 # amount of cepstral coefficients at each time step.\n\n# read PCM\ndata = np.memmap(""vousavezducourrier.pcm"", dtype=\'int16\', mode=\'r\')\npcm = np.frombuffer(data, dtype=""int16"")\n\n# compute ceps\nceps = psf.mfcc(\n\tpcm,\n\tsamplerate=sampleRate,\n\twinlen=mfccWinlen,\n\twinstep=mfccStepT,\n\tnumcep=mfccNceps,\n\tnfilt=26,\n\tnfft=2048,\n\tlowfreq=0,\n\thighfreq=None,\n\tpreemph=0.97,\n\tceplifter=22,\n\tappendEnergy=True\n)\n\nprint ceps'"
predictor-ml/mlpredict.py,3,"b'# This Source Code Form is subject to the terms of the Mozilla Public\n# License, v. 2.0. If a copy of the MPL was not distributed with this\n# file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n# Copyright (c) 2018 Alexandre Storelli\n\nimport sys\nimport os\nimport datetime\nimport json\nimport numpy as np\nimport math\nimport sounddevice as sd\nimport python_speech_features as psf\nimport audioop\nos.environ[""PBR_VERSION""]=\'3.1.1\'\nfrom keras.models import load_model\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\' # reduce log spam from tensorflow. cf https://github.com/tensorflow/tensorflow/issues/7778\nimport tensorflow as tf\t\t# https://groups.google.com/forum/#!topic/keras-users/MFUEY9P1sc8\nfrom keras.backend import clear_session, tensorflow_backend\nimport psutil\nimport zerorpc\nimport logging\n\n### CONFIG\n\n# show or hide verbose logging\ndebug = False\n\n# play audio as received by this module.\n# causes lags in the process. for debugging purposes.\nplayAudio = False\n\nmfccStepT = 0.02  # in seconds. generate cepstral coefficients every N seconds.\nmfccWinlen = 0.05  # in seconds. use N seconds of audio data to compute cepstral coefficients\nmfccNceps = 13 # amount of cepstral coefficients at each time step.\n\nnnXLenT = 4.0  # window of data intake, in seconds\nnnXLen = int(round(nnXLenT / mfccStepT))  # data intake in points\nnnXStepT = 0.19*4 # compute one LSTM prediction every N seconds.\nnnXStep = int(round(nnXStepT / mfccStepT)) # amount of cepstral spectra read for each LSTM prediction\n\n### END OF CONFIG\n\nlogging.basicConfig(format=\'%(asctime)s %(message)s\') # https://github.com/0rpc/zerorpc-python/issues/79\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG if debug is True else logging.WARN)\n\nprocess = psutil.Process(os.getpid())\n\n#import cProfile\nfrom timeit import default_timer as timer\n\n# if GPU accelerated, limit the amount of memory allocated\ndef get_session(gpu_fraction=0.05):\n\tnum_threads = os.environ.get(\'OMP_NUM_THREADS\')\n\tgpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n\n\tif num_threads:\n\t\treturn tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n\telse:\n\t\treturn tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n\ntensorflow_backend.set_session(get_session())\n\nradio = sys.argv[1]\nlogger.debug(""radio: "" + radio)\n\nclass MlPredictor(object):\n\tdef __init__(self): #, radio, fileModel, sampleRate, bitdepth):\n\t\tself.radio = radio\n\t\tself.sampleRate = 22050 # Hz\n\t\tself.nchannels = 1 # single channel only\n\t\tself.bitdepth = 16 / 8 # 16 bit audio only, 2 bytes per sample\n\t\tself.bitrate = self.sampleRate * self.nchannels * self.bitdepth # in bytes / s\n\t\tself.pcm = None\n\t\tself.buf = []\n\t\tself.model = None\n\n\tdef load(self, fileModel):\n\t\t# utf8 encoding prevents an error in Keras: TypeError: Required Group, str or dict. Received: <type \'unicode\'>.\n\t\tfileModel = fileModel.encode(\'utf8\')\n\t\tif os.path.isfile(fileModel):\n\t\t\tlogger.debug(u""load model from file %s"", fileModel)\n\t\t\tif self.model is not None:\n\t\t\t\tclear_session()\n\t\t\t\tdel self.model\n\t\t\tself.model = load_model(fileModel)\n\t\t\tlogger.info(""model loaded"")\n\t\t\treturn True\n\t\telse:\n\t\t\tfileModelSplit = fileModel.split(""/"")\n\t\t\tfileModelSplit[-1] = ""all.keras""\n\t\t\tdefaultFileModel = ""/"".join(fileModelSplit)\n\t\t\tlogger.info(u""default file %s"", defaultFileModel)\n\n\t\t\tif os.path.isfile(defaultFileModel):\n\t\t\t\tlogger.info(""load default model from file."")\n\t\t\t\tif self.model is not None:\n\t\t\t\t\tclear_session()\n\t\t\t\t\tdel self.model\n\t\t\t\tself.model = load_model(defaultFileModel)\n\t\t\t\tlogger.info(""model loaded"")\n\t\t\t\treturn True\n\t\t\telse:\n\t\t\t\tlogger.error(""Model not found"")\n\t\t\t\traise Exception(""model not found"")\n\n\n\tdef write(self, data):\n\t\tself.buf.append(data) # = data if self.buf is None else np.append(self.buf, data) # or self.buf + data\n\n\tdef predict(self):\n\t\tif (len(self.buf) == 0):\n\t\t\tlogger.debug(""request to predict, but no (new) data to process. abort."")\n\t\t\traise Exception(""no data to process"")\n\n\t\tif (self.model is None):\n\t\t\tlogger.debug(""request to predict, but no model is loaded. please do it first. abort."")\n\t\t\traise Exception(""no model loaded"")\n\n\t\tdata = \'\'.join(self.buf)\n\t\tself.buf = []\n\n\t\tduration = 1.0 * len(data) / self.bitrate\n\t\tlogger.debug(""py received "" + str(duration) + "" s ("" + str(len(data)) + "" bytes)"")\n\n\t\tif playAudio:\n\t\t\tsd.play(np.frombuffer(data, dtype=""int16""), self.sampleRate)\n\n\t\t#t0 = timer()\n\n\t\t# compute the rms (root mean square) in dB\n\t\ttry:\n\t\t\trms = 20 * math.log10(audioop.rms(data, 2))\n\t\texcept:\n\t\t\trms = 70\n\t\t\tlogger.info(""invalid rms="" + str(audioop.rms(data, 2)) + "" data len="" + str(len(data)))\n\t\t\tpass\n\n\t\ttmp = np.frombuffer(data, dtype=""int16"") # single channel only\n\n\t\tself.pcm = tmp if self.pcm is None else np.append(self.pcm, tmp)\n\n\t\t#t1 = timer()\n\t\tpcm_len_limit = int((nnXLenT + duration) * self.sampleRate)\n\t\tif len(self.pcm) > pcm_len_limit:\n\t\t\tlogger.debug(""need to truncate pcm from "" + str(len(self.pcm)) + "" to "" + str(pcm_len_limit))\n\t\t\tself.pcm = self.pcm[-pcm_len_limit:]\n\n\t\t# compute a series of mel-frequency cepstral coefficients\n\t\tceps = psf.mfcc(\n\t\t\tself.pcm,\n\t\t\tsamplerate=self.sampleRate,\n\t\t\twinlen=mfccWinlen,\n\t\t\twinstep=mfccStepT,\n\t\t\tnumcep=mfccNceps,\n\t\t\tnfilt=26,\n\t\t\tnfft=2048,\n\t\t\tlowfreq=0,\n\t\t\thighfreq=None,\n\t\t\tpreemph=0.97,\n\t\t\tceplifter=22,\n\t\t\tappendEnergy=True\n\t\t)\n\n\t\t#t2 = timer()\n\t\tif ceps.shape[0] < nnXLen:  # audio input is shorter than LSTM window\n\t\t\tprevshape = ceps.shape\n\t\t\tceps = np.pad(ceps, ((nnXLen-ceps.shape[0], 0),(0,0)), \'edge\')\n\t\t\tlogger.debug(""ceps extended from "" + str(prevshape) + "" to "" + str(ceps.shape))\n\n\n\t\tnframes = ceps.shape[0]\n\t\tnwin = int(math.floor((nframes-nnXLen) / nnXStep))+1\n\t\tt = [1.*nnXLenT/2 + nnXStepT*i for i in range(nwin)]\n\t\tlogger.debug(""ceps.shape "" + str(ceps.shape) + "" nnXLen "" + str(nnXLen) + "" nnXStep "" + str(nnXStep) + "" nwin "" + str(nwin))\n\t\tX = np.empty([nwin, nnXLen, mfccNceps])\n\n\t\tfor i in range(nwin):\n\t\t\tX[i,:,:] = ceps[i*nnXStep:(i*nnXStep+nnXLen),:]\n\t\t#t3 = timer()\n\n\t\tpredictions = self.model.predict(X, verbose=debug)\n\n\t\t#t4 = timer()\n\n\t\tmp = np.mean(predictions, axis=0)\n\t\tmp_ref = np.array(mp, copy=True)\n\t\tpredclass = np.argmax(mp)\n\t\tmp.sort()\n\t\tconfidence = 1.0-math.exp(1-mp[2]/mp[1])\n\t\tlogger.debug(""mpref "" + str(mp_ref))\n\t\tlogger.debug(""mp "" + str(mp))\n\t\tlogger.debug(""confidence "" + str(confidence))\n\t\tlogger.debug(""rms "" + str(rms))\n\n\t\t#t5 = timer()\n\t\tresult = json.dumps({\n\t\t\t\'type\': predclass,\n\t\t\t\'data\': predictions.tolist(),\n\t\t\t\'confidence\': confidence,\n\t\t\t\'softmax\': mp_ref.tolist(),\n\t\t\t\'rms\': rms,\n\t\t\t\'mem\': process.memory_info().rss,\n\t\t\t\'lenpcm\': len(self.pcm),\n\t\t\t#\'timings\': {\'pre\': str(t3-t0), \'tf\': str(t4-t3), \'post\': str(t5-t4), \'total\': str(t5-t0)},\n\t\t\t\'nwin\': nwin\n\t\t})\n\n\t\tlogger.info(""audio predicted probs="" + result)\n\t\t#logger.info(""pre=%s ms tf=%s ms post=%s ms total=%s ms"" % (t3-t0, t4-t3, t5-t4, t5-t0))\n\t\treturn result\n\n\tdef exit(self):\n\t\tsys.exit()\n\n\ns = zerorpc.Server(MlPredictor())\ns.bind(""ipc:///tmp/"" + radio)\ns.run()'"
predictor-ml/test/test.py,0,"b'import python_speech_features as psf\nimport numpy as np\nimport json\n\nfrom scipy.fftpack import dct\n\nsampleRate = 22050 # in Hz\nmfccStepT = 0.02  # in seconds. generate cepstral coefficients every N seconds.\nmfccWinlen = 0.05  # in seconds. use N seconds of audio data to compute cepstral coefficients\nmfccNceps = 13 # amount of cepstral coefficients at each time step.\n\nwinfunc = lambda x:np.ones((x,))\n\nresults = {}\n\n# read PCM and test we import it correctly\ndata = np.memmap(""vousavezducourrier.pcm"", dtype=\'int16\', mode=\'r\')\npcm = np.frombuffer(data, dtype=""int16"")\nprint(""%s samples"" % len(pcm))\nprint(""First sample is %s"" % pcm[0])\nresults[\'samples\'] = len(pcm)\nresults[\'firstSample\'] = pcm.tolist()[0]\n\n# test pre-emphasis calculations. only output the first 100 samples.\npreemph = psf.sigproc.preemphasis(pcm,0.97)\nresults[\'preemph\'] = preemph[0:100].tolist()\n\n# test signal framing\nframes = psf.sigproc.framesig(preemph, mfccWinlen*sampleRate, mfccStepT*sampleRate, winfunc)\nresults[\'frames\'] = frames[0:10].tolist()\n\n# test power spectrum (the first one at least)\npowspec = psf.sigproc.powspec(frames, 2048)\nresults[\'powspec\'] = powspec[0].tolist()\n\n# test filterbank\nhz2mel = lambda hz : 2595 * np.log10(1+hz/700.)\nmel2hz = lambda mel : 700*(10**(mel/2595.0)-1)\nhighMel = hz2mel(sampleRate/2)\n#print(""highMel = %s"" % highMel)\nmelpoints = np.linspace(0,highMel,26+2)\nresults[\'bins\'] = np.floor((2048+1)*mel2hz(melpoints)/sampleRate).tolist()\nfilterbank = psf.get_filterbanks(nfilt=26,nfft=2048,samplerate=sampleRate,lowfreq=0,highfreq=None)\nresults[\'filters\'] = filterbank.tolist()\nfeat,energy = psf.fbank(pcm,sampleRate,mfccWinlen,mfccStepT,26,2048,0,None,0.97,winfunc)\nresults[\'feat\'] = feat.tolist()\nresults[\'energy\'] = energy.tolist()\n\n# test dct\nresults[\'dct\'] = dct(np.log(feat), type=2, axis=1, norm=\'ortho\')[:,:mfccNceps].tolist()\n\n# test mfcc\nceps = psf.mfcc(\n\tpcm,\n\tsamplerate=sampleRate,\n\twinlen=mfccWinlen,\n\twinstep=mfccStepT,\n\tnumcep=mfccNceps,\n\tnfilt=26,\n\tnfft=2048,\n\tlowfreq=0,\n\thighfreq=None,\n\tpreemph=0.97,\n\tceplifter=22,\n\tappendEnergy=True\n)\n\n#print(\'Got %s series of %s cepstra coefficients\' % (len(ceps), len(ceps[0])))\n\nresults[\'nwin\'] = len(ceps)\nresults[\'nceps\'] = len(ceps[0])\nresults[\'ceps\'] = ceps.tolist()\n\n# save results\nwith open(\'py.json\', \'w\') as outfile:\n\tjson.dump(results, outfile)'"
