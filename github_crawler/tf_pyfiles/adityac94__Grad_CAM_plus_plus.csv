file_path,api_count,code
classify.py,0,"b'import models.vgg16 as vgg16\nimport numpy as np\nimport tensorflow as tf\nimport argparse\nimport misc.utils as utils\nimport models.vgg_utils as vgg_utils\nimport os\ndef run(image_filename, class_label, output_filename):\n\tgrad_CAM_map= utils.grad_CAM_plus(image_filename, class_label, output_filename)\n\ndef main():\n\tparser = argparse.ArgumentParser()\n\tparser.add_argument(\'-l\', \'--class_label\', default=-1, type=int, help=\'if -1 (default) choose predicted class, else user supplied int\')\n\tparser.add_argument(\'-gpu\', \'--gpu_device\', default=""0"", type=str, help=\'if 0 (default) choose gpu 0, else user supplied int\')\n\tparser.add_argument(\'-f\', \'--file_name\', type=str, help=""Specify image path for Grad-CAM++ visualization"")\n\tparser.add_argument(\'-o\', \'--output_filename\', default=""output.jpeg"", type=str, help=""Specify output file name for Grad-CAM++ visualization, default name \'output.jpeg\'"")\n\targs = parser.parse_args()\n\tgpu_id = args.gpu_device\n\tprint gpu_id\n\tos.environ[""CUDA_VISIBLE_DEVICES""]=gpu_id\n\trun(args.file_name, args.class_label, args.output_filename)\n\nif __name__ == \'__main__\':\n    main()\n'"
Videos/c3d_model.py,0,"b'from keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Convolution3D, MaxPooling3D, ZeroPadding3D\nfrom keras.optimizers import SGD\n\n\'\'\'\ndim_ordering issue:\n- \'th\'-style dim_ordering: [batch, channels, depth, height, width]\n- \'tf\'-style dim_ordering: [batch, depth, height, width, channels]\n\'\'\'\n\ndef get_model(summary=False, backend=\'tf\'):\n    """""" Return the Keras model of the network\n    """"""\n    model = Sequential()\n    if backend == \'tf\':\n        input_shape=(16, 112, 112, 3) # l, h, w, c\n    else:\n        input_shape=(3, 16, 112, 112) # c, l, h, w\n    model.add(Convolution3D(64, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv1\',\n                            input_shape=input_shape))\n    model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n                           border_mode=\'valid\', name=\'pool1\'))\n    # 2nd layer group\n    model.add(Convolution3D(128, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv2\'))\n    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n                           border_mode=\'valid\', name=\'pool2\'))\n    # 3rd layer group\n    model.add(Convolution3D(256, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv3a\'))\n    model.add(Convolution3D(256, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv3b\'))\n    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n                           border_mode=\'valid\', name=\'pool3\'))\n    # 4th layer group\n    model.add(Convolution3D(512, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv4a\'))\n    model.add(Convolution3D(512, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv4b\'))\n    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n                           border_mode=\'valid\', name=\'pool4\'))\n    # 5th layer group\n    model.add(Convolution3D(512, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv5a\'))\n    model.add(Convolution3D(512, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv5b\'))\n    model.add(ZeroPadding3D(padding=(0, 1, 1), name=\'zeropad5\'))\n    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n                           border_mode=\'valid\', name=\'pool5\'))\n    model.add(Flatten())\n    # FC layers group\n    model.add(Dense(4096, activation=\'relu\', name=\'fc6\'))\n    model.add(Dropout(.5))\n    model.add(Dense(4096, activation=\'relu\', name=\'fc7\'))\n    model.add(Dropout(.5))\n    model.add(Dense(487, activation=\'softmax\', name=\'fc8\'))\n\n    if summary:\n        print(model.summary())\n\n    return model\n\ndef get_int_model(model, layer, backend=\'tf\'):\n\n    if backend == \'tf\':\n        input_shape=(16, 112, 112, 3) # l, h, w, c\n    else:\n        input_shape=(3, 16, 112, 112) # c, l, h, w\n\n    int_model = Sequential()\n\n    int_model.add(Convolution3D(64, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv1\',\n                            input_shape=input_shape,\n                            weights=model.layers[0].get_weights()))\n    if layer == \'conv1\':\n        return int_model\n    int_model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n                           border_mode=\'valid\', name=\'pool1\'))\n    if layer == \'pool1\':\n        return int_model\n\n    # 2nd layer group\n    int_model.add(Convolution3D(128, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv2\',\n                            weights=model.layers[2].get_weights()))\n    if layer == \'conv2\':\n        return int_model\n    int_model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n                           border_mode=\'valid\', name=\'pool2\'))\n    if layer == \'pool2\':\n        return int_model\n\n    # 3rd layer group\n    int_model.add(Convolution3D(256, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv3a\',\n                            weights=model.layers[4].get_weights()))\n    if layer == \'conv3a\':\n        return int_model\n    int_model.add(Convolution3D(256, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv3b\',\n                            weights=model.layers[5].get_weights()))\n    if layer == \'conv3b\':\n        return int_model\n    int_model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n                           border_mode=\'valid\', name=\'pool3\'))\n    if layer == \'pool3\':\n        return int_model\n\n    # 4th layer group\n    int_model.add(Convolution3D(512, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv4a\',\n                            weights=model.layers[7].get_weights()))\n    if layer == \'conv4a\':\n        return int_model\n    int_model.add(Convolution3D(512, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv4b\',\n                            weights=model.layers[8].get_weights()))\n    if layer == \'conv4b\':\n        return int_model\n    int_model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n                           border_mode=\'valid\', name=\'pool4\'))\n    if layer == \'pool4\':\n        return int_model\n\n    # 5th layer group\n    int_model.add(Convolution3D(512, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv5a\',\n                            weights=model.layers[10].get_weights()))\n    if layer == \'conv5a\':\n        return int_model\n    int_model.add(Convolution3D(512, 3, 3, 3, activation=\'relu\',\n                            border_mode=\'same\', name=\'conv5b\',\n                            weights=model.layers[11].get_weights()))\n    if layer == \'conv5b\':\n        return int_model\n    int_model.add(ZeroPadding3D(padding=(0, 1, 1), name=\'zeropad\'))\n    int_model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n                           border_mode=\'valid\', name=\'pool5\'))\n    if layer == \'pool5\':\n        return int_model\n\n    int_model.add(Flatten())\n    # FC layers group\n    int_model.add(Dense(4096, activation=\'relu\', name=\'fc6\',\n                            weights=model.layers[15].get_weights()))\n    if layer == \'fc6\':\n        return int_model\n    int_model.add(Dropout(.5))\n    int_model.add(Dense(4096, activation=\'relu\', name=\'fc7\',\n                            weights=model.layers[17].get_weights()))\n    if layer == \'fc7\':\n        return int_model\n    int_model.add(Dropout(.5))\n    int_model.add(Dense(487, activation=\'softmax\', name=\'fc8\',\n                            weights=model.layers[19].get_weights()))\n    if layer == \'fc8\':\n        return int_model\n\n    return None\n\nif __name__ == \'__main__\':\n    model = get_model(summary=True)\n'"
Videos/test_model.py,7,"b'#!/usr/bin/env python\n\nimport matplotlib\nmatplotlib.use(\'Agg\')\n#import setGPU\nfrom keras.models import model_from_json\nfrom keras.layers.core import Lambda\nimport tensorflow as tf\nimport os\nimport cv2\nimport numpy as np\nfrom skimage.transform import resize\nimport scipy.ndimage\nimport matplotlib.pyplot as plt\nimport c3d_model\nimport sys\nimport keras.backend as K\n# K.set_image_dim_ordering(\'th\')\nos.environ[""CUDA_VISIBLE_DEVICES""]=""2,3""\ndim_ordering = K.image_dim_ordering\nprint ""[Info] image_dim_order (from default ~/.keras/keras.json)={}"".format(\n        dim_ordering)\nbackend = dim_ordering\n\ndef target_category_loss(x, category_index, nb_classes):\n    return tf.multiply(x, K.one_hot([category_index], nb_classes))\n\ndef target_category_loss_output_shape(input_shape):\n    return input_shape\n\ndef normalize(x):\n    # utility function to normalize a tensor by its L2 norm\n    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n\ndef diagnose(data, verbose=True, label=\'input\', plots=False, backend=\'tf\'):\n    # Convolution3D?\n    if data.ndim > 2:\n        if backend == \'th\':\n            data = np.transpose(data, (1, 2, 3, 0))\n        #else:\n        #    data = np.transpose(data, (0, 2, 1, 3))\n        min_num_spatial_axes = 10\n        max_outputs_to_show = 3\n        ndim = data.ndim\n        print ""[Info] {}.ndim={}"".format(label, ndim)\n        print ""[Info] {}.shape={}"".format(label, data.shape)\n        for d in range(ndim):\n            num_this_dim = data.shape[d]\n            if num_this_dim >= min_num_spatial_axes: # check for spatial axes\n                # just first, center, last indices\n                range_this_dim = [0, num_this_dim/2, num_this_dim - 1]\n            else:\n                # sweep all indices for non-spatial axes\n                range_this_dim = range(num_this_dim)\n            for i in range_this_dim:\n                new_dim = tuple([d] + range(d) + range(d + 1, ndim))\n                sliced = np.transpose(data, new_dim)[i, ...]\n                print(""[Info] {}, dim:{} {}-th slice: ""\n                      ""(min, max, mean, std)=({}, {}, {}, {})"".format(\n                              label,\n                              d, i,\n                              np.min(sliced),\n                              np.max(sliced),\n                              np.mean(sliced),\n                              np.std(sliced)))\n        if plots:\n            # assume (l, h, w, c)-shaped input\n            if data.ndim != 4:\n                print(""[Error] data (shape={}) is not 4-dim. Check data"".format(\n                        data.shape))\n                return\n            l, h, w, c = data.shape\n            if l >= min_num_spatial_axes or \\\n                h < min_num_spatial_axes or \\\n                w < min_num_spatial_axes:\n                print(""[Error] data (shape={}) does not look like in (l,h,w,c) ""\n                      ""format. Do reshape/transpose."".format(data.shape))\n                return\n            nrows = int(np.ceil(np.sqrt(data.shape[0])))\n            # BGR\n            if c == 3:\n                for i in range(l):\n                    mng = plt.get_current_fig_manager()\n                    mng.resize(*mng.window.maxsize())\n                    plt.subplot(nrows, nrows, i + 1) # doh, one-based!\n                    im = np.squeeze(data[i, ...]).astype(np.float32)\n                    im = im[:, :, ::-1] # BGR to RGB\n                    # force it to range [0,1]\n                    im_min, im_max = im.min(), im.max()\n                    if im_max > im_min:\n                        im_std = (im - im_min) / (im_max - im_min)\n                    else:\n                        print ""[Warning] image is constant!""\n                        im_std = np.zeros_like(im)\n                    plt.imshow(im_std)\n                    plt.axis(\'off\')\n                    plt.title(""{}: t={}"".format(label, i))\n                plt.show()\n                #plt.waitforbuttonpress()\n            else:\n                for j in range(min(c, max_outputs_to_show)):\n                    for i in range(l):\n                        mng = plt.get_current_fig_manager()\n                        mng.resize(*mng.window.maxsize())\n                        plt.subplot(nrows, nrows, i + 1) # doh, one-based!\n                        im = np.squeeze(data[i, ...]).astype(np.float32)\n                        im = im[:, :, j]\n                        # force it to range [0,1]\n                        im_min, im_max = im.min(), im.max()\n                        if im_max > im_min:\n                            im_std = (im - im_min) / (im_max - im_min)\n                        else:\n                            print ""[Warning] image is constant!""\n                            im_std = np.zeros_like(im)\n                        plt.imshow(im_std)\n                        plt.axis(\'off\')\n                        plt.title(""{}: o={}, t={}"".format(label, j, i))\n                    plt.show()\n                    #plt.waitforbuttonpress()\n    elif data.ndim == 1:\n        print(""[Info] {} (min, max, mean, std)=({}, {}, {}, {})"".format(\n                      label,\n                      np.min(data),\n                      np.max(data),\n                      np.mean(data),\n                      np.std(data)))\n        print(""[Info] data[:10]={}"".format(data[:10]))\n\n    return\n\ndef main():\n    show_images = False\n    diagnose_plots = False\n    model_dir = \'./models\'\n    global backend\n\n    # override backend if provided as an input arg\n    if len(sys.argv) > 1:\n        if \'tf\' in sys.argv[1].lower():\n            backend = \'tf\'\n        else:\n            backend = \'th\'\n    print ""[Info] Using backend={}"".format(backend)\n\n    if backend == \'th\':\n        print ""hi""\n        model_weight_filename = os.path.join(model_dir, \'sports1M_weights_th.h5\')\n        model_json_filename = os.path.join(model_dir, \'sports1M_weights_th.json\')\n    else:\n        print ""hello""\n        model_weight_filename = os.path.join(model_dir, \'sports1M_weights_tf.h5\')\n        model_json_filename = os.path.join(model_dir, \'sports1M_weights_tf.json\')\n\n    print(""[Info] Reading model architecture..."")\n    model = model_from_json(open(model_json_filename, \'r\').read())\n    # model = c3d_model.get_model(backend=backend)\n\n    # visualize model\n    model_img_filename = os.path.join(model_dir, \'c3d_model.png\')\n    if not os.path.exists(model_img_filename):\n        from keras.utils.visualize_util import plot\n        plot(model, to_file=model_img_filename)\n\n    print(""[Info] Loading model weights..."")\n    model.load_weights(model_weight_filename)\n    print(""[Info] Loading model weights -- DONE!"")\n    model.compile(loss=\'mean_squared_error\', optimizer=\'sgd\')\n\n    print(""[Info] Loading labels..."")\n    with open(\'sports1m/labels.txt\', \'r\') as f:\n        labels = [line.strip() for line in f.readlines()]\n    print(\'Total labels: {}\'.format(len(labels)))\n\n    print(""[Info] Loading a sample video..."")\n\n    f = open(""scores.txt"",""w"")\n\n    for filename in sorted(os.listdir(""videos/"")):\n        try:\n            cap = cv2.VideoCapture(""videos/"" + filename)\n            print filename\n            vid = []\n            while True:\n                ret, img = cap.read()\n                if not ret:\n                    break\n                vid.append(cv2.resize(img, (171, 128)))\n            vid = np.array(vid, dtype=np.float32)\n\n            start_frame = 1000\n\n            X = vid[start_frame:(start_frame + 16), :, :, :]\n\n            # subtract mean\n            mean_cube = np.load(\'models/train01_16_128_171_mean.npy\')\n            mean_cube = np.transpose(mean_cube, (1, 2, 3, 0))\n\n            # center crop\n            X = X[:, 8:120, 30:142, :] # (l, h, w, c)\n\n            if backend == \'th\':\n                X = np.transpose(X, (3, 0, 1, 2)) # input_shape = (3,16,112,112)\n            else:\n                pass                              # input_shape = (16,112,112,3)\n\n            if \'lambda\' in model.layers[-1].name:\n                model.layers.pop()\n                model.outputs = [model.layers[-1].output]\n                model.output_layers = [model.layers[-1]]\n                model.layers[-1].outbound_nodes = []\n\n\n            # inference\n            output = model.predict_on_batch(np.array([X]))\n\n            #################################################\n            print X.shape\n            predicted_class = np.argmax(output)\n            print predicted_class\n            print output[0][predicted_class], labels[predicted_class]\n            \n\n            nb_classes = len(labels)#487\n            target_layer = lambda x: target_category_loss(x, predicted_class, nb_classes)\n            model.add(Lambda(target_layer, output_shape = target_category_loss_output_shape))\n            temp_label = np.zeros(output.shape)\n            temp_label[0][int(np.argmax(output))] = 1.0\n            loss = K.sum(model.layers[-1].output*(temp_label))\n\n            for i in range(14):\n                ###########Choose a conv layer to generate saliency maps##########\n                if model.layers[i].name == ""conv3a"":\n                    conv_output = model.layers[i].output\n\n\n            grads = normalize(K.gradients(loss, conv_output)[0])\n\n            first_derivative = tf.exp(loss)*grads \n            print first_derivative[0]\n            print tf.exp(loss)\n                    \n            #second_derivative\n            second_derivative = tf.exp(loss)*grads*grads \n            print second_derivative[0]\n\n            #triple_derivative\n            triple_derivative = tf.exp(loss)*grads*grads*grads\n            print triple_derivative[0] \n\n\n            gradient_function = K.function([model.layers[0].input, K.learning_phase()], [conv_output, grads, first_derivative, second_derivative, triple_derivative])\n            grads_output, grads_val, conv_first_grad, conv_second_grad, conv_third_grad = gradient_function([np.array([X]), 0])\n            grads_output, grads_val, conv_first_grad, conv_second_grad, conv_third_grad = grads_output[0, :, :], grads_val[0, :, :, :], conv_first_grad[0, :, :, :], conv_second_grad[0, :, :, :], conv_third_grad[0, :, :, :]\n            print grads_output.shape, np.max(grads_output), np.min(grads_output)\n            print grads_val.shape, np.max(grads_val), np.min(grads_val)\n            print conv_first_grad.shape,np.max(conv_first_grad), np.min(conv_first_grad)\n            print conv_second_grad.shape,np.max(conv_second_grad), np.min(conv_second_grad)\n            print conv_third_grad.shape,np.max(conv_third_grad), np.min(conv_third_grad)\n\n\n            ############## FOR GRAD-CAM #########################################\n\n            weights = np.mean(grads_val, axis = (0, 1, 2))\n            print weights.shape\n            cam = np.zeros(grads_output.shape[0 : 3], dtype = np.float32)\n            print cam.shape\n\n            cam = np.sum(weights*grads_output, axis=3)\n            print np.max(cam),np.min(cam)\n\n            cam = np.maximum(cam, 0)\n            cam = scipy.ndimage.zoom(cam, (2, 4, 4))\n            heatmap = cam / np.max(cam)\n            print np.max(heatmap),np.min(heatmap)\n            print heatmap.shape\n\n            vid_mod = X*heatmap.reshape((16,112,112,1))\n            print vid_mod.shape\n            output_mod = model.predict_on_batch(np.array([vid_mod]))\n\n            predicted_class_mod = output_mod[0].argsort()[::-1][0]\n            print output_mod[0][predicted_class_mod], labels[predicted_class_mod]\n            print output_mod[0][predicted_class], labels[predicted_class]\n\n            ################SAVE THE VIDEO AS FRAMES###############\n\n            for i in range(heatmap.shape[0]):\n                cam_mod = heatmap[i].reshape((112,112,1))\n\n                gd_img_mod = X[i]*cam_mod\n\n                gd_img_mod = cv2.resize(gd_img_mod, (640,480))\n                cv2.imwrite(""image-%05d.jpg"" %i, gd_img_mod)\n\n            ####################### GRAD-CAM UPTO THIS ############################\n\n            ############## FOR GradCAM++ #################################\n            global_sum = np.sum(conv_third_grad.reshape((-1,256)), axis=0)\n            #print global_sum\n                    \n            alpha_num = conv_second_grad\n            alpha_denom = conv_second_grad*2.0 + conv_third_grad*global_sum.reshape((-1,))\n            alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n            alphas = alpha_num/alpha_denom\n\n            weights = np.maximum(conv_first_grad, 0.0)\n            #normalizing the alphas\n            alphas_thresholding = np.where(weights, alphas, 0.0)\n\n            alpha_normalization_constant = np.sum(np.sum(np.sum(alphas_thresholding, axis=0),axis=0),axis=0)\n            alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n\n\n            alphas /= alpha_normalization_constant_processed.reshape((1,1,1,256))\n            #print alphas\n\n\n\n            deep_linearization_weights = np.sum((weights*alphas).reshape((-1,256)),axis=0)\n            #print deep_linearization_weights\n            grad_CAM_map = np.sum(deep_linearization_weights*grads_output, axis=3)\n            print np.max(grad_CAM_map),np.min(grad_CAM_map)\n\n            grad_CAM_map = scipy.ndimage.zoom(grad_CAM_map, (2, 4, 4))\n            print np.max(grad_CAM_map),np.min(grad_CAM_map)\n            # Passing through ReLU\n            vid_cam = np.maximum(grad_CAM_map, 0)\n            vid_heatmap = vid_cam / np.max(vid_cam) # scale 0 to 1.0  \n            print vid_heatmap.shape\n\n\n            vid_mod_plus = X*vid_heatmap.reshape((16,112,112,1))\n            print vid_mod_plus.shape\n            output_mod_plus = model.predict_on_batch(np.array([vid_mod_plus]))\n            predicted_class_mod_plus = output_mod_plus[0].argsort()[::-1][0]\n            print output_mod_plus[0][predicted_class_mod_plus], labels[predicted_class_mod_plus]\n            print output_mod_plus[0][predicted_class], labels[predicted_class]\n\n\n            ################SAVE THE VIDEO AS FRAMES###############\n\n\n            for i in range(vid_heatmap.shape[0]):\n                vid_cam_mod = vid_heatmap[i].reshape((112,112,1))\n            \n\n                vid_gd_img_mod = X[i]*vid_cam_mod \n                vid_gd_img_mod = cv2.resize(vid_gd_img_mod, (640,480))\n                cv2.imwrite(os.path.join(""./output"", ""image-%05d.jpg"" %i), vid_gd_img_mod)\n\n                \n                X_mod = cv2.resize(X[i], (640,480))\n                cv2.imwrite(""original-image-%05d.jpg"" %i, X_mod)\n\n            #############GRAD-CAM++ UPTO THIS ####################################\n\n            #############Write the scores into a file#############################\n            f.write(str(output[0][predicted_class]) + "" "" + str(output_mod[0][predicted_class]) + "" "" + str(output_mod_plus[0][predicted_class]) + ""\\n"")\n\n        except:\n            print filename\n            continue\n\n\n\n    # sort top five predictions from softmax output\n    top_inds = output[0].argsort()[::-1][:5]  # reverse sort and take five largest items\n    print(\'\\nTop 5 probabilities and labels:\')\n    for i in top_inds:\n        print(\'{1}: {0:.5f}\'.format(output[0][i], labels[i]))\n\nif __name__ == \'__main__\':\n    main()\n'"
misc/GuideReLU.py,1,"b'# Replace vanila relu to guided relu to get guided backpropagation.\nimport tensorflow as tf\n\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import gen_nn_ops\n\n@ops.RegisterGradient(""GuidedRelu"")\ndef _GuidedReluGrad(op, grad):\n    return tf.where(0. < grad, gen_nn_ops._relu_grad(grad, op.outputs[0]), tf.zeros_like(grad))\n\n\n'"
misc/__init__.py,0,b''
misc/utils.py,19,"b'import numpy as np\nimport tensorflow as tf\nimport GuideReLU as GReLU\nimport models.vgg16 as vgg16\nimport models.vgg_utils as vgg_utils\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nimport os,cv2\nfrom scipy.misc import imread, imresize\nimport tensorflow as tf\nfrom tensorflow.python.framework import graph_util\n\ndef guided_BP(image, label_id = -1):\t\n\tg = tf.get_default_graph()\n\twith g.gradient_override_map({\'Relu\': \'GuidedRelu\'}):\n\t\tlabel_vector = tf.placeholder(""float"", [None, 1000])\n\t\tinput_image = tf.placeholder(""float"", [None, 224, 224, 3])\n\n\t\tvgg = vgg16.Vgg16()\n\t\twith tf.name_scope(""content_vgg""):\n\t\t    vgg.build(input_image)\n\n\t\tcost = vgg.fc8*label_vector\n\t\n\t\t# Guided backpropagtion back to input layer\n\t\tgb_grad = tf.gradients(cost, input_image)[0]\n\n\t\tinit = tf.global_variables_initializer()\n\t\n\t# Run tensorflow \n\twith tf.Session(graph=g) as sess:    \n\t\tsess.run(init)\n\t\toutput = [0.0]*vgg.prob.get_shape().as_list()[1] #one-hot embedding for desired class activations\n\t\tif label_id == -1:\n\t\t\tprob = sess.run(vgg.prob, feed_dict={input_image:image})\n\t\t\n\t\t\tvgg_utils.print_prob(prob[0], \'./synset.txt\')\n\n\t\t\t#creating the output vector for the respective class\n\t\t\tindex = np.argmax(prob)\n\t\t\tprint ""Predicted_class: "", index\n\t\t\toutput[index] = 1.0\n\n\t\telse:\n\t\t\toutput[label_id] = 1.0\n\t\toutput = np.array(output)\n\t\tgb_grad_value = sess.run(gb_grad, feed_dict={input_image:image, label_vector: output.reshape((1,-1))})\n\n\treturn gb_grad_value[0] \n\ndef grad_CAM_plus(filename, label_id, output_filename):\n\tg = tf.get_default_graph()\n\tinit = tf.global_variables_initializer()\n\t\n\t# Run tensorflow \n\tsess = tf.Session()\n\n\t#define your tensor placeholders for, labels and images\n\tlabel_vector = tf.placeholder(""float"", [None, 1000])\n\tinput_image = tf.placeholder(""float"", [1, 224, 224, 3])\n\tlabel_index = tf.placeholder(""int64"", ())\n\n\t#load vgg16 model\n\tvgg = vgg16.Vgg16()\n\twith tf.name_scope(""content_vgg""):\n\t    vgg.build(input_image)\n\t#prob = tf.placeholder(""float"", [None, 1000])\n\n\t#get the output neuron corresponding to the class of interest (label_id)\n\tcost = vgg.fc8*label_vector\n\n\t# Get last convolutional layer gradients for generating gradCAM++ visualization\n\ttarget_conv_layer = vgg.conv5_3\n\ttarget_conv_layer_grad = tf.gradients(cost, target_conv_layer)[0]\n\t\n\t#first_derivative\n\tfirst_derivative = tf.exp(cost)[0][label_index]*target_conv_layer_grad \t\n\t\n\t#second_derivative\n\tsecond_derivative = tf.exp(cost)[0][label_index]*target_conv_layer_grad*target_conv_layer_grad \n\n\t#triple_derivative\n\ttriple_derivative = tf.exp(cost)[0][label_index]*target_conv_layer_grad*target_conv_layer_grad*target_conv_layer_grad  \n\n\tsess.run(init)\n\n\timg1 = vgg_utils.load_image(filename)\n\t\t\n\toutput = [0.0]*vgg.prob.get_shape().as_list()[1] #one-hot embedding for desired class activations\n\t\t#creating the output vector for the respective class\n\t\n\tif label_id == -1:\n\t\tprob_val = sess.run(vgg.prob, feed_dict={input_image:[img1]})\n\t\tvgg_utils.print_prob(prob_val[0], \'./synset.txt\')\n\t\t#creating the output vector for the respective class\n\t\tindex = np.argmax(prob_val)\n\t\torig_score = prob_val[0][index]\n\t\tprint ""Predicted_class: "", index\n\t\toutput[index] = 1.0\n\t\tlabel_id = index\n\telse:\n\t\toutput[label_id] = 1.0\t\n\toutput = np.array(output)\n\tprint label_id\n\tconv_output, conv_first_grad, conv_second_grad, conv_third_grad = sess.run([target_conv_layer, first_derivative, second_derivative, triple_derivative], feed_dict={input_image:[img1], label_index:label_id, label_vector: output.reshape((1,-1))})\n\t\n\tglobal_sum = np.sum(conv_output[0].reshape((-1,conv_first_grad[0].shape[2])), axis=0)\n\n\talpha_num = conv_second_grad[0]\n\talpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum.reshape((1,1,conv_first_grad[0].shape[2]))\n\talpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n\talphas = alpha_num/alpha_denom\n\n\tweights = np.maximum(conv_first_grad[0], 0.0)\n\t#normalizing the alphas\n\t""""""\t\n\talpha_normalization_constant = np.sum(np.sum(alphas, axis=0),axis=0)\n\t\n\talphas /= alpha_normalization_constant.reshape((1,1,conv_first_grad[0].shape[2]))\n\t""""""\n\n\talphas_thresholding = np.where(weights, alphas, 0.0)\n\n        alpha_normalization_constant = np.sum(np.sum(alphas_thresholding, axis=0),axis=0)\n        alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n\n\n        alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad[0].shape[2]))\n\n\n\t\n\tdeep_linearization_weights = np.sum((weights*alphas).reshape((-1,conv_first_grad[0].shape[2])),axis=0)\n\t#print deep_linearization_weights\n\tgrad_CAM_map = np.sum(deep_linearization_weights*conv_output[0], axis=2)\n\n\t# Passing through ReLU\n\tcam = np.maximum(grad_CAM_map, 0)\n\tcam = cam / np.max(cam) # scale 0 to 1.0   \n\n\tcam = resize(cam, (224,224))\n\t# Passing through ReLU\n\tcam = np.maximum(grad_CAM_map, 0)\n\tcam = cam / np.max(cam) # scale 0 to 1.0    \n\tcam = resize(cam, (224,224))\n\n\n\tgb = guided_BP([img1], label_id)\n\tvisualize(img1, cam, output_filename, gb) \n\treturn cam\n\ndef visualize(img, cam, filename,gb_viz):\n    gb_viz = np.dstack((\n            gb_viz[:, :, 2],\n            gb_viz[:, :, 1],\n            gb_viz[:, :, 0],\n        ))\n\n    gb_viz -= np.min(gb_viz)\n    gb_viz /= gb_viz.max()\n  \n    fig, ax = plt.subplots(nrows=1,ncols=3)\n\n    plt.subplot(141)\n    plt.axis(""off"")\n    imgplot = plt.imshow(img)\n\n    plt.subplot(142)\n    gd_img = gb_viz*np.minimum(0.25,cam).reshape(224,224,1)\n    x = gd_img\n    x = np.squeeze(x)\n    \n    #normalize tensor\n    x -= x.mean()\n    x /= (x.std() + 1e-5)\n    x *= 0.1\n\n    # clip to [0, 1]\n    x += 0.5\n    x = np.clip(x, 0, 1)\n\n    # convert to RGB array\n    x *= 255\n   \n    x = np.clip(x, 0, 255).astype(\'uint8\')\n\n    plt.axis(""off"")\n    imgplot = plt.imshow(x, vmin = 0, vmax = 20)\n\n    cam = (cam*-1.0) + 1.0\n    cam_heatmap = np.array(cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET))\n    plt.subplot(143)\n    plt.axis(""off"")\n\n    imgplot = plt.imshow(cam_heatmap)\n\n    plt.subplot(144)\n    plt.axis(""off"")\n    \n    cam_heatmap = cam_heatmap/255.0\n\n    fin = (img*0.7) + (cam_heatmap*0.3)\n    imgplot = plt.imshow(fin)\n\n    plt.savefig(""output/"" + filename, dpi=600)\n    plt.close(fig)\n\n'"
models/__init__.py,0,b'\n'
models/vgg16.py,17,"b'import inspect\nimport os\n\nimport numpy as np\nimport tensorflow as tf\nimport time\n\nVGG_MEAN = [103.939, 116.779, 123.68]\n\n\nclass Vgg16:\n    def __init__(self, vgg16_npy_path=None):\n        if vgg16_npy_path is None:\n            path = inspect.getfile(Vgg16)\n            path = os.path.abspath(os.path.join(path, os.pardir))\n            path = os.path.join(path, ""vgg16.npy"")\n            vgg16_npy_path = path\n            print(path)\n\n        self.data_dict = np.load(vgg16_npy_path, encoding=\'latin1\').item()\n        print(""npy file loaded"")\n\n    def build(self, rgb):\n        """"""\n        load variable from npy to build the VGG\n\n        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n        """"""\n\n        start_time = time.time()\n        print(""build model started"")\n        rgb_scaled = rgb * 255.0\n\n        # Convert RGB to BGR\n        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_scaled)\n        assert red.get_shape().as_list()[1:] == [224, 224, 1]\n        assert green.get_shape().as_list()[1:] == [224, 224, 1]\n        assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n        bgr = tf.concat(axis=3, values=[\n            blue - VGG_MEAN[0],\n            green - VGG_MEAN[1],\n            red - VGG_MEAN[2],\n        ])\n        assert bgr.get_shape().as_list()[1:] == [224, 224, 3]\n\n        self.conv1_1 = self.conv_layer(bgr, ""conv1_1"")\n        self.conv1_2 = self.conv_layer(self.conv1_1, ""conv1_2"")\n        self.pool1 = self.max_pool(self.conv1_2, \'pool1\')\n\n        self.conv2_1 = self.conv_layer(self.pool1, ""conv2_1"")\n        self.conv2_2 = self.conv_layer(self.conv2_1, ""conv2_2"")\n        self.pool2 = self.max_pool(self.conv2_2, \'pool2\')\n\n        self.conv3_1 = self.conv_layer(self.pool2, ""conv3_1"")\n        self.conv3_2 = self.conv_layer(self.conv3_1, ""conv3_2"")\n        self.conv3_3 = self.conv_layer(self.conv3_2, ""conv3_3"")\n        self.pool3 = self.max_pool(self.conv3_3, \'pool3\')\n\n        self.conv4_1 = self.conv_layer(self.pool3, ""conv4_1"")\n        self.conv4_2 = self.conv_layer(self.conv4_1, ""conv4_2"")\n        self.conv4_3 = self.conv_layer(self.conv4_2, ""conv4_3"")\n        self.pool4 = self.max_pool(self.conv4_3, \'pool4\')\n\n        self.conv5_1 = self.conv_layer(self.pool4, ""conv5_1"")\n        self.conv5_2 = self.conv_layer(self.conv5_1, ""conv5_2"")\n        self.conv5_3 = self.conv_layer(self.conv5_2, ""conv5_3"")\n        self.pool5 = self.max_pool(self.conv5_3, \'pool5\')\n\n        self.fc6 = self.fc_layer(self.pool5, ""fc6"")\n        assert self.fc6.get_shape().as_list()[1:] == [4096]\n        self.relu6 = tf.nn.relu(self.fc6)\n\n        self.fc7 = self.fc_layer(self.relu6, ""fc7"")\n        self.relu7 = tf.nn.relu(self.fc7)\n\n        self.fc8 = self.fc_layer(self.relu7, ""fc8"")\n\n        self.prob = tf.nn.softmax(self.fc8, name=""prob"")\n\n        self.data_dict = None\n        print((""build model finished: %ds"" % (time.time() - start_time)))\n\n    def avg_pool(self, bottom, name):\n        return tf.nn.avg_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\', name=name)\n\n    def max_pool(self, bottom, name):\n        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\', name=name)\n\n    def conv_layer(self, bottom, name):\n        with tf.variable_scope(name):\n            filt = self.get_conv_filter(name)\n\n            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=\'SAME\')\n\n            conv_biases = self.get_bias(name)\n            bias = tf.nn.bias_add(conv, conv_biases)\n\n            relu = tf.nn.relu(bias)\n            return relu\n\n    def fc_layer(self, bottom, name):\n        with tf.variable_scope(name):\n            shape = bottom.get_shape().as_list()\n            dim = 1\n            for d in shape[1:]:\n                dim *= d\n            x = tf.reshape(bottom, [-1, dim])\n\n            weights = self.get_fc_weight(name)\n            biases = self.get_bias(name)\n\n            # Fully connected layer. Note that the \'+\' operation automatically\n            # broadcasts the biases.\n            fc = tf.nn.bias_add(tf.matmul(x, weights), biases)\n\n            return fc\n\n    def get_conv_filter(self, name):\n        return tf.constant(self.data_dict[name][0], name=""filter"")\n\n    def get_bias(self, name):\n        return tf.constant(self.data_dict[name][1], name=""biases"")\n\n    def get_fc_weight(self, name):\n        return tf.constant(self.data_dict[name][0], name=""weights"")\n'"
models/vgg19.py,17,"b'import os\nimport tensorflow as tf\n\nimport numpy as np\nimport time\nimport inspect\n\nVGG_MEAN = [103.939, 116.779, 123.68]\n\n\nclass Vgg19:\n    def __init__(self, vgg19_npy_path=None):\n        if vgg19_npy_path is None:\n            path = inspect.getfile(Vgg19)\n            path = os.path.abspath(os.path.join(path, os.pardir))\n            path = os.path.join(path, ""vgg19.npy"")\n            vgg19_npy_path = path\n            print(vgg19_npy_path)\n\n        self.data_dict = np.load(vgg19_npy_path, encoding=\'latin1\').item()\n        print(""npy file loaded"")\n\n    def build(self, rgb):\n        """"""\n        load variable from npy to build the VGG\n\n        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n        """"""\n\n        start_time = time.time()\n        print(""build model started"")\n        rgb_scaled = rgb * 255.0\n\n        # Convert RGB to BGR\n        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_scaled)\n        assert red.get_shape().as_list()[1:] == [224, 224, 1]\n        assert green.get_shape().as_list()[1:] == [224, 224, 1]\n        assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n        bgr = tf.concat(axis=3, values=[\n            blue - VGG_MEAN[0],\n            green - VGG_MEAN[1],\n            red - VGG_MEAN[2],\n        ])\n        assert bgr.get_shape().as_list()[1:] == [224, 224, 3]\n\n        self.conv1_1 = self.conv_layer(bgr, ""conv1_1"")\n        self.conv1_2 = self.conv_layer(self.conv1_1, ""conv1_2"")\n        self.pool1 = self.max_pool(self.conv1_2, \'pool1\')\n\n        self.conv2_1 = self.conv_layer(self.pool1, ""conv2_1"")\n        self.conv2_2 = self.conv_layer(self.conv2_1, ""conv2_2"")\n        self.pool2 = self.max_pool(self.conv2_2, \'pool2\')\n\n        self.conv3_1 = self.conv_layer(self.pool2, ""conv3_1"")\n        self.conv3_2 = self.conv_layer(self.conv3_1, ""conv3_2"")\n        self.conv3_3 = self.conv_layer(self.conv3_2, ""conv3_3"")\n        self.conv3_4 = self.conv_layer(self.conv3_3, ""conv3_4"")\n        self.pool3 = self.max_pool(self.conv3_4, \'pool3\')\n\n        self.conv4_1 = self.conv_layer(self.pool3, ""conv4_1"")\n        self.conv4_2 = self.conv_layer(self.conv4_1, ""conv4_2"")\n        self.conv4_3 = self.conv_layer(self.conv4_2, ""conv4_3"")\n        self.conv4_4 = self.conv_layer(self.conv4_3, ""conv4_4"")\n        self.pool4 = self.max_pool(self.conv4_4, \'pool4\')\n\n        self.conv5_1 = self.conv_layer(self.pool4, ""conv5_1"")\n        self.conv5_2 = self.conv_layer(self.conv5_1, ""conv5_2"")\n        self.conv5_3 = self.conv_layer(self.conv5_2, ""conv5_3"")\n        self.conv5_4 = self.conv_layer(self.conv5_3, ""conv5_4"")\n        self.pool5 = self.max_pool(self.conv5_4, \'pool5\')\n\n        self.fc6 = self.fc_layer(self.pool5, ""fc6"")\n        assert self.fc6.get_shape().as_list()[1:] == [4096]\n        self.relu6 = tf.nn.relu(self.fc6)\n\n        self.fc7 = self.fc_layer(self.relu6, ""fc7"")\n        self.relu7 = tf.nn.relu(self.fc7)\n\n        self.fc8 = self.fc_layer(self.relu7, ""fc8"")\n\n        self.prob = tf.nn.softmax(self.fc8, name=""prob"")\n\n        self.data_dict = None\n        print((""build model finished: %ds"" % (time.time() - start_time)))\n\n    def avg_pool(self, bottom, name):\n        return tf.nn.avg_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\', name=name)\n\n    def max_pool(self, bottom, name):\n        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\', name=name)\n\n    def conv_layer(self, bottom, name):\n        with tf.variable_scope(name):\n            filt = self.get_conv_filter(name)\n\n            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=\'SAME\')\n\n            conv_biases = self.get_bias(name)\n            bias = tf.nn.bias_add(conv, conv_biases)\n\n            relu = tf.nn.relu(bias)\n            return relu\n\n    def fc_layer(self, bottom, name):\n        with tf.variable_scope(name):\n            shape = bottom.get_shape().as_list()\n            dim = 1\n            for d in shape[1:]:\n                dim *= d\n            x = tf.reshape(bottom, [-1, dim])\n\n            weights = self.get_fc_weight(name)\n            biases = self.get_bias(name)\n\n            # Fully connected layer. Note that the \'+\' operation automatically\n            # broadcasts the biases.\n            fc = tf.nn.bias_add(tf.matmul(x, weights), biases)\n\n            return fc\n\n    def get_conv_filter(self, name):\n        return tf.constant(self.data_dict[name][0], name=""filter"")\n\n    def get_bias(self, name):\n        return tf.constant(self.data_dict[name][1], name=""biases"")\n\n    def get_fc_weight(self, name):\n        return tf.constant(self.data_dict[name][0], name=""weights"")\n'"
models/vgg_utils.py,0,"b'import skimage\nimport skimage.io\nimport skimage.transform\nimport numpy as np\n\n\n# synset = [l.strip() for l in open(\'synset.txt\').readlines()]\n\n\n# returns image of shape [224, 224, 3]\n# [height, width, depth]\ndef load_image(path):\n    # load image\n    img = skimage.io.imread(path)\n    img = img / 255.0\n    assert (0 <= img).all() and (img <= 1.0).all()\n    # print ""Original Image Shape: "", img.shape\n    # we crop image from center\n    short_edge = min(img.shape[:2])\n    yy = int((img.shape[0] - short_edge) / 2)\n    xx = int((img.shape[1] - short_edge) / 2)\n    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n    # resize to 224, 224\n    resized_img = skimage.transform.resize(crop_img, (224, 224))\n    return resized_img\n\n\n# returns the top1 string\ndef print_prob(prob, file_path):\n    synset = [l.strip() for l in open(file_path).readlines()]\n\n    # print prob\n    pred = np.argsort(prob)[::-1]\n\n    # Get top1 label\n    top1 = synset[pred[0]]\n    print((""Top1: "", top1, prob[pred[0]]))\n    # Get top5 label\n    top5 = [(synset[pred[i]], prob[pred[i]]) for i in range(5)]\n    print((""Top5: "", top5))\n    return top1\n\n\ndef load_image2(path, height=None, width=None):\n    # load image\n    img = skimage.io.imread(path)\n    img = img / 255.0\n    if height is not None and width is not None:\n        ny = height\n        nx = width\n    elif height is not None:\n        ny = height\n        nx = img.shape[1] * ny / img.shape[0]\n    elif width is not None:\n        nx = width\n        ny = img.shape[0] * nx / img.shape[1]\n    else:\n        ny = img.shape[0]\n        nx = img.shape[1]\n    return skimage.transform.resize(img, (ny, nx))\n\n\ndef test():\n    img = skimage.io.imread(""./test_data/starry_night.jpg"")\n    ny = 300\n    nx = img.shape[1] * ny / img.shape[0]\n    img = skimage.transform.resize(img, (ny, nx))\n    skimage.io.imsave(""./test_data/test/output.jpg"", img)\n\n\nif __name__ == ""__main__"":\n    test()\n'"
