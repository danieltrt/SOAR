file_path,api_count,code
basic/__init__.py,0,b''
basic/cli.py,2,"b'import os\n\nimport tensorflow as tf\n\nfrom basic.main import main as m\n\nflags = tf.app.flags\n\n# Names and directories\nflags.DEFINE_string(""model_name"", ""basic"", ""Model name [basic]"")\nflags.DEFINE_string(""data_dir"", ""data/squad"", ""Data dir [data/squad]"")\nflags.DEFINE_string(""run_id"", ""0"", ""Run ID [0]"")\nflags.DEFINE_string(""out_base_dir"", ""out"", ""out base dir [out]"")\nflags.DEFINE_string(""forward_name"", ""single"", ""Forward name [single]"")\nflags.DEFINE_string(""answer_path"", """", ""Answer path []"")\nflags.DEFINE_string(""eval_path"", """", ""Eval path []"")\nflags.DEFINE_string(""load_path"", """", ""Load path []"")\nflags.DEFINE_string(""shared_path"", """", ""Shared path []"")\n\n# Device placement\nflags.DEFINE_string(""device"", ""/cpu:0"", ""default device for summing gradients. [/cpu:0]"")\nflags.DEFINE_string(""device_type"", ""gpu"", ""device for computing gradients (parallelization). cpu | gpu [gpu]"")\nflags.DEFINE_integer(""num_gpus"", 1, ""num of gpus or cpus for computing gradients [1]"")\n\n# Essential training and test options\nflags.DEFINE_string(""mode"", ""test"", ""trains | test | forward [test]"")\nflags.DEFINE_boolean(""load"", True, ""load saved data? [True]"")\nflags.DEFINE_bool(""single"", False, ""supervise only the answer sentence? [False]"")\nflags.DEFINE_boolean(""debug"", False, ""Debugging mode? [False]"")\nflags.DEFINE_bool(\'load_ema\', True, ""load exponential average of variables when testing?  [True]"")\nflags.DEFINE_bool(""eval"", True, ""eval? [True]"")\n\n# Training / test parameters\nflags.DEFINE_integer(""batch_size"", 60, ""Batch size [60]"")\nflags.DEFINE_integer(""val_num_batches"", 100, ""validation num batches [100]"")\nflags.DEFINE_integer(""test_num_batches"", 0, ""test num batches [0]"")\nflags.DEFINE_integer(""num_epochs"", 12, ""Total number of epochs for training [12]"")\nflags.DEFINE_integer(""num_steps"", 20000, ""Number of steps [20000]"")\nflags.DEFINE_integer(""load_step"", 0, ""load step [0]"")\nflags.DEFINE_float(""init_lr"", 0.5, ""Initial learning rate [0.5]"")\nflags.DEFINE_float(""input_keep_prob"", 0.8, ""Input keep prob for the dropout of LSTM weights [0.8]"")\nflags.DEFINE_float(""keep_prob"", 0.8, ""Keep prob for the dropout of Char-CNN weights [0.8]"")\nflags.DEFINE_float(""wd"", 0.0, ""L2 weight decay for regularization [0.0]"")\nflags.DEFINE_integer(""hidden_size"", 100, ""Hidden size [100]"")\nflags.DEFINE_integer(""char_out_size"", 100, ""char-level word embedding size [100]"")\nflags.DEFINE_integer(""char_emb_size"", 8, ""Char emb size [8]"")\nflags.DEFINE_string(""out_channel_dims"", ""100"", ""Out channel dims of Char-CNN, separated by commas [100]"")\nflags.DEFINE_string(""filter_heights"", ""5"", ""Filter heights of Char-CNN, separated by commas [5]"")\nflags.DEFINE_bool(""finetune"", False, ""Finetune word embeddings? [False]"")\nflags.DEFINE_bool(""highway"", True, ""Use highway? [True]"")\nflags.DEFINE_integer(""highway_num_layers"", 2, ""highway num layers [2]"")\nflags.DEFINE_bool(""share_cnn_weights"", True, ""Share Char-CNN weights [True]"")\nflags.DEFINE_bool(""share_lstm_weights"", True, ""Share pre-processing (phrase-level) LSTM weights [True]"")\nflags.DEFINE_float(""var_decay"", 0.999, ""Exponential moving average decay for variables [0.999]"")\n\n# Optimizations\nflags.DEFINE_bool(""cluster"", False, ""Cluster data for faster training [False]"")\nflags.DEFINE_bool(""len_opt"", False, ""Length optimization? [False]"")\nflags.DEFINE_bool(""cpu_opt"", False, ""CPU optimization? GPU computation can be slower [False]"")\n\n# Logging and saving options\nflags.DEFINE_boolean(""progress"", True, ""Show progress? [True]"")\nflags.DEFINE_integer(""log_period"", 100, ""Log period [100]"")\nflags.DEFINE_integer(""eval_period"", 1000, ""Eval period [1000]"")\nflags.DEFINE_integer(""save_period"", 1000, ""Save Period [1000]"")\nflags.DEFINE_integer(""max_to_keep"", 20, ""Max recent saves to keep [20]"")\nflags.DEFINE_bool(""dump_eval"", True, ""dump eval? [True]"")\nflags.DEFINE_bool(""dump_answer"", True, ""dump answer? [True]"")\nflags.DEFINE_bool(""vis"", False, ""output visualization numbers? [False]"")\nflags.DEFINE_bool(""dump_pickle"", True, ""Dump pickle instead of json? [True]"")\nflags.DEFINE_float(""decay"", 0.9, ""Exponential moving average decay for logging values [0.9]"")\n\n# Thresholds for speed and less memory usage\nflags.DEFINE_integer(""word_count_th"", 10, ""word count th [100]"")\nflags.DEFINE_integer(""char_count_th"", 50, ""char count th [500]"")\nflags.DEFINE_integer(""sent_size_th"", 400, ""sent size th [64]"")\nflags.DEFINE_integer(""num_sents_th"", 8, ""num sents th [8]"")\nflags.DEFINE_integer(""ques_size_th"", 30, ""ques size th [32]"")\nflags.DEFINE_integer(""word_size_th"", 16, ""word size th [16]"")\nflags.DEFINE_integer(""para_size_th"", 256, ""para size th [256]"")\n\n# Advanced training options\nflags.DEFINE_bool(""lower_word"", True, ""lower word [True]"")\nflags.DEFINE_bool(""squash"", False, ""squash the sentences into one? [False]"")\nflags.DEFINE_bool(""swap_memory"", True, ""swap memory? [True]"")\nflags.DEFINE_string(""data_filter"", ""max"", ""max | valid | semi [max]"")\nflags.DEFINE_bool(""use_glove_for_unk"", True, ""use glove for unk [False]"")\nflags.DEFINE_bool(""known_if_glove"", True, ""consider as known if present in glove [False]"")\nflags.DEFINE_string(""logit_func"", ""tri_linear"", ""logit func [tri_linear]"")\nflags.DEFINE_string(""answer_func"", ""linear"", ""answer logit func [linear]"")\nflags.DEFINE_string(""sh_logit_func"", ""tri_linear"", ""sh logit func [tri_linear]"")\n\n# Ablation options\nflags.DEFINE_bool(""use_char_emb"", True, ""use char emb? [True]"")\nflags.DEFINE_bool(""use_word_emb"", True, ""use word embedding? [True]"")\nflags.DEFINE_bool(""q2c_att"", True, ""question-to-context attention? [True]"")\nflags.DEFINE_bool(""c2q_att"", True, ""context-to-question attention? [True]"")\nflags.DEFINE_bool(""dynamic_att"", False, ""Dynamic attention [False]"")\n\n\ndef main(_):\n    config = flags.FLAGS\n\n    config.out_dir = os.path.join(config.out_base_dir, config.model_name, str(config.run_id).zfill(2))\n\n    m(config)\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
basic/ensemble.py,0,"b'import argparse\nimport functools\nimport gzip\nimport json\nimport pickle\nfrom collections import defaultdict\nfrom operator import mul\n\nfrom tqdm import tqdm\nfrom squad.utils import get_phrase, get_best_span\n\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'paths\', nargs=\'+\')\n    parser.add_argument(\'-o\', \'--out\', default=\'ensemble.json\')\n    parser.add_argument(""--data_path"", default=""data/squad/data_test.json"")\n    parser.add_argument(""--shared_path"", default=""data/squad/shared_test.json"")\n    args = parser.parse_args()\n    return args\n\n\ndef ensemble(args):\n    e_list = []\n    for path in tqdm(args.paths):\n        with gzip.open(path, \'r\') as fh:\n            e = pickle.load(fh)\n            e_list.append(e)\n\n    with open(args.data_path, \'r\') as fh:\n        data = json.load(fh)\n\n    with open(args.shared_path, \'r\') as fh:\n        shared = json.load(fh)\n\n    out = {}\n    for idx, (id_, rx) in tqdm(enumerate(zip(data[\'ids\'], data[\'*x\'])), total=len(e[\'yp\'])):\n        if idx >= len(e[\'yp\']):\n            # for debugging purpose\n            break\n        context = shared[\'p\'][rx[0]][rx[1]]\n        wordss = shared[\'x\'][rx[0]][rx[1]]\n        yp_list = [e[\'yp\'][idx] for e in e_list]\n        yp2_list = [e[\'yp2\'][idx] for e in e_list]\n        answer = ensemble3(context, wordss, yp_list, yp2_list)\n        out[id_] = answer\n\n    with open(args.out, \'w\') as fh:\n        json.dump(out, fh)\n\n\ndef ensemble1(context, wordss, y1_list, y2_list):\n    """"""\n\n    :param context: Original context\n    :param wordss: tokenized words (nested 2D list)\n    :param y1_list: list of start index probs (each element corresponds to probs form single model)\n    :param y2_list: list of stop index probs\n    :return:\n    """"""\n    sum_y1 = combine_y_list(y1_list)\n    sum_y2 = combine_y_list(y2_list)\n    span, score = get_best_span(sum_y1, sum_y2)\n    return get_phrase(context, wordss, span)\n\n\ndef ensemble2(context, wordss, y1_list, y2_list):\n    start_dict = defaultdict(float)\n    stop_dict = defaultdict(float)\n    for y1, y2 in zip(y1_list, y2_list):\n        span, score = get_best_span(y1, y2)\n        start_dict[span[0]] += y1[span[0][0]][span[0][1]]\n        stop_dict[span[1]] += y2[span[1][0]][span[1][1]]\n    start = max(start_dict.items(), key=lambda pair: pair[1])[0]\n    stop = max(stop_dict.items(), key=lambda pair: pair[1])[0]\n    best_span = (start, stop)\n    return get_phrase(context, wordss, best_span)\n\n\ndef ensemble3(context, wordss, y1_list, y2_list):\n    d = defaultdict(float)\n    for y1, y2 in zip(y1_list, y2_list):\n        span, score = get_best_span(y1, y2)\n        phrase = get_phrase(context, wordss, span)\n        d[phrase] += score\n    return max(d.items(), key=lambda pair: pair[1])[0]\n\n\ndef combine_y_list(y_list, op=\'*\'):\n    if op == \'+\':\n        func = sum\n    elif op == \'*\':\n        def func(l): return functools.reduce(mul, l)\n    else:\n        func = op\n    return [[func(yij_list) for yij_list in zip(*yi_list)] for yi_list in zip(*y_list)]\n\n\ndef main():\n    args = get_args()\n    ensemble(args)\n\nif __name__ == ""__main__"":\n    main()\n\n\n'"
basic/ensemble_fast.py,0,"b""import sys\nimport json\nfrom collections import Counter, defaultdict\nimport re\n\ndef key_func(pair):\n    return pair[1]\n\n\ndef get_func(vals, probs):\n    counter = Counter(vals)\n    # return max(zip(vals, probs), key=lambda pair: pair[1])[0]\n    # return max(zip(vals, probs), key=lambda pair: pair[1] * counter[pair[0]] / len(counter) - 999 * (len(pair[0]) == 0) )[0]\n    # return max(zip(vals, probs), key=lambda pair: pair[1] + 0.7 * counter[pair[0]] / len(counter) - 999 * (len(pair[0]) == 0) )[0]\n    d = defaultdict(float)\n    for val, prob in zip(vals, probs):\n        d[val] += prob\n    d[''] = 0\n    return max(d.items(), key=lambda pair: pair[1])[0]\n\nthird_path = sys.argv[1]\nother_paths = sys.argv[2:]\n\nothers = [json.load(open(path, 'r')) for path in other_paths]\n\n\nc = {}\n\nassert min(map(len, others)) == max(map(len, others)), list(map(len, others))\n\nfor key in others[0].keys():\n    if key == 'scores':\n        continue\n    probs = [other['scores'][key] for other in others]\n    vals = [other[key] for other in others]\n    largest_val = get_func(vals, probs)\n    c[key] = largest_val\n\njson.dump(c, open(third_path, 'w'))"""
basic/evaluator.py,7,"b'import numpy as np\nimport tensorflow as tf\n\nfrom basic.read_data import DataSet\nfrom my.nltk_utils import span_f1\nfrom my.tensorflow import padded_reshape\nfrom my.utils import argmax\nfrom squad.utils import get_phrase, get_best_span\n\n\nclass Evaluation(object):\n    def __init__(self, data_type, global_step, idxs, yp, tensor_dict=None):\n        self.data_type = data_type\n        self.global_step = global_step\n        self.idxs = idxs\n        self.yp = yp\n        self.num_examples = len(yp)\n        self.tensor_dict = None\n        self.dict = {\'data_type\': data_type,\n                     \'global_step\': global_step,\n                     \'yp\': yp,\n                     \'idxs\': idxs,\n                     \'num_examples\': self.num_examples}\n        if tensor_dict is not None:\n            self.tensor_dict = {key: val.tolist() for key, val in tensor_dict.items()}\n            for key, val in self.tensor_dict.items():\n                self.dict[key] = val\n        self.summaries = None\n\n    def __repr__(self):\n        return ""{} step {}"".format(self.data_type, self.global_step)\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_yp = self.yp + other.yp\n        new_idxs = self.idxs + other.idxs\n        new_tensor_dict = None\n        if self.tensor_dict is not None:\n            new_tensor_dict = {key: val + other.tensor_dict[key] for key, val in self.tensor_dict.items()}\n        return Evaluation(self.data_type, self.global_step, new_idxs, new_yp, tensor_dict=new_tensor_dict)\n\n    def __radd__(self, other):\n        return self.__add__(other)\n\n\nclass LabeledEvaluation(Evaluation):\n    def __init__(self, data_type, global_step, idxs, yp, y, tensor_dict=None):\n        super(LabeledEvaluation, self).__init__(data_type, global_step, idxs, yp, tensor_dict=tensor_dict)\n        self.y = y\n        self.dict[\'y\'] = y\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_yp = self.yp + other.yp\n        new_y = self.y + other.y\n        new_idxs = self.idxs + other.idxs\n        if self.tensor_dict is not None:\n            new_tensor_dict = {key: np.concatenate((val, other.tensor_dict[key]), axis=0) for key, val in self.tensor_dict.items()}\n        return LabeledEvaluation(self.data_type, self.global_step, new_idxs, new_yp, new_y, tensor_dict=new_tensor_dict)\n\n\nclass AccuracyEvaluation(LabeledEvaluation):\n    def __init__(self, data_type, global_step, idxs, yp, y, correct, loss, tensor_dict=None):\n        super(AccuracyEvaluation, self).__init__(data_type, global_step, idxs, yp, y, tensor_dict=tensor_dict)\n        self.loss = loss\n        self.correct = correct\n        self.acc = sum(correct) / len(correct)\n        self.dict[\'loss\'] = loss\n        self.dict[\'correct\'] = correct\n        self.dict[\'acc\'] = self.acc\n        loss_summary = tf.Summary(value=[tf.Summary.Value(tag=\'{}/loss\'.format(data_type), simple_value=self.loss)])\n        acc_summary = tf.Summary(value=[tf.Summary.Value(tag=\'{}/acc\'.format(data_type), simple_value=self.acc)])\n        self.summaries = [loss_summary, acc_summary]\n\n    def __repr__(self):\n        return ""{} step {}: accuracy={}, loss={}"".format(self.data_type, self.global_step, self.acc, self.loss)\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_idxs = self.idxs + other.idxs\n        new_yp = self.yp + other.yp\n        new_y = self.y + other.y\n        new_correct = self.correct + other.correct\n        new_loss = (self.loss * self.num_examples + other.loss * other.num_examples) / len(new_correct)\n        if self.tensor_dict is not None:\n            new_tensor_dict = {key: np.concatenate((val, other.tensor_dict[key]), axis=0) for key, val in self.tensor_dict.items()}\n        return AccuracyEvaluation(self.data_type, self.global_step, new_idxs, new_yp, new_y, new_correct, new_loss, tensor_dict=new_tensor_dict)\n\n\nclass Evaluator(object):\n    def __init__(self, config, model, tensor_dict=None):\n        self.config = config\n        self.model = model\n        self.global_step = model.global_step\n        self.yp = model.yp\n        self.tensor_dict = {} if tensor_dict is None else tensor_dict\n\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = batch\n        feed_dict = self.model.get_feed_dict(data_set, False, supervised=False)\n        global_step, yp, vals = sess.run([self.global_step, self.yp, list(self.tensor_dict.values())], feed_dict=feed_dict)\n        yp = yp[:data_set.num_examples]\n        tensor_dict = dict(zip(self.tensor_dict.keys(), vals))\n        e = Evaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), tensor_dict=tensor_dict)\n        return e\n\n    def get_evaluation_from_batches(self, sess, batches):\n        e = sum(self.get_evaluation(sess, batch) for batch in batches)\n        return e\n\n\nclass LabeledEvaluator(Evaluator):\n    def __init__(self, config, model, tensor_dict=None):\n        super(LabeledEvaluator, self).__init__(config, model, tensor_dict=tensor_dict)\n        self.y = model.y\n\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = batch\n        feed_dict = self.model.get_feed_dict(data_set, False, supervised=False)\n        global_step, yp, vals = sess.run([self.global_step, self.yp, list(self.tensor_dict.values())], feed_dict=feed_dict)\n        yp = yp[:data_set.num_examples]\n        y = feed_dict[self.y]\n        tensor_dict = dict(zip(self.tensor_dict.keys(), vals))\n        e = LabeledEvaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), y.tolist(), tensor_dict=tensor_dict)\n        return e\n\n\nclass AccuracyEvaluator(LabeledEvaluator):\n    def __init__(self, config, model, tensor_dict=None):\n        super(AccuracyEvaluator, self).__init__(config, model, tensor_dict=tensor_dict)\n        self.loss = model.loss\n\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = batch\n        assert isinstance(data_set, DataSet)\n        feed_dict = self.model.get_feed_dict(data_set, False)\n        global_step, yp, loss, vals = sess.run([self.global_step, self.yp, self.loss, list(self.tensor_dict.values())], feed_dict=feed_dict)\n        y = data_set.data[\'y\']\n        yp = yp[:data_set.num_examples]\n        correct = [self.__class__.compare(yi, ypi) for yi, ypi in zip(y, yp)]\n        tensor_dict = dict(zip(self.tensor_dict.keys(), vals))\n        e = AccuracyEvaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), y, correct, float(loss), tensor_dict=tensor_dict)\n        return e\n\n    @staticmethod\n    def compare(yi, ypi):\n        for start, stop in yi:\n            if start == int(np.argmax(ypi)):\n                return True\n        return False\n\n\nclass AccuracyEvaluator2(AccuracyEvaluator):\n    @staticmethod\n    def compare(yi, ypi):\n        for start, stop in yi:\n            para_start = int(np.argmax(np.max(ypi, 1)))\n            sent_start = int(np.argmax(ypi[para_start]))\n            if tuple(start) == (para_start, sent_start):\n                return True\n        return False\n\n\nclass ForwardEvaluation(Evaluation):\n    def __init__(self, data_type, global_step, idxs, yp, yp2, loss, id2answer_dict, tensor_dict=None):\n        super(ForwardEvaluation, self).__init__(data_type, global_step, idxs, yp, tensor_dict=tensor_dict)\n        self.yp2 = yp2\n        self.loss = loss\n        self.dict[\'loss\'] = loss\n        self.dict[\'yp2\'] = yp2\n        self.id2answer_dict = id2answer_dict\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_idxs = self.idxs + other.idxs\n        new_yp = self.yp + other.yp\n        new_yp2 = self.yp2 + other.yp2\n        new_loss = (self.loss * self.num_examples + other.loss * other.num_examples) / len(new_yp)\n        new_id2answer_dict = dict(list(self.id2answer_dict.items()) + list(other.id2answer_dict.items()))\n        new_id2score_dict = dict(list(self.id2answer_dict[\'scores\'].items()) + list(other.id2answer_dict[\'scores\'].items()))\n        new_id2answer_dict[\'scores\'] = new_id2score_dict\n        if self.tensor_dict is not None:\n            new_tensor_dict = {key: np.concatenate((val, other.tensor_dict[key]), axis=0) for key, val in self.tensor_dict.items()}\n        return ForwardEvaluation(self.data_type, self.global_step, new_idxs, new_yp, new_yp2, new_loss, new_id2answer_dict, tensor_dict=new_tensor_dict)\n\n    def __repr__(self):\n        return ""{} step {}: loss={:.4f}"".format(self.data_type, self.global_step, self.loss)\n\n\nclass F1Evaluation(AccuracyEvaluation):\n    def __init__(self, data_type, global_step, idxs, yp, yp2, y, correct, loss, f1s, id2answer_dict, tensor_dict=None):\n        super(F1Evaluation, self).__init__(data_type, global_step, idxs, yp, y, correct, loss, tensor_dict=tensor_dict)\n        self.yp2 = yp2\n        self.f1s = f1s\n        self.f1 = float(np.mean(f1s))\n        self.dict[\'yp2\'] = yp2\n        self.dict[\'f1s\'] = f1s\n        self.dict[\'f1\'] = self.f1\n        self.id2answer_dict = id2answer_dict\n        f1_summary = tf.Summary(value=[tf.Summary.Value(tag=\'{}/f1\'.format(data_type), simple_value=self.f1)])\n        self.summaries.append(f1_summary)\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_idxs = self.idxs + other.idxs\n        new_yp = self.yp + other.yp\n        new_yp2 = self.yp2 + other.yp2\n        new_y = self.y + other.y\n        new_correct = self.correct + other.correct\n        new_f1s = self.f1s + other.f1s\n        new_loss = (self.loss * self.num_examples + other.loss * other.num_examples) / len(new_correct)\n        new_id2answer_dict = dict(list(self.id2answer_dict.items()) + list(other.id2answer_dict.items()))\n        new_id2score_dict = dict(list(self.id2answer_dict[\'scores\'].items()) + list(other.id2answer_dict[\'scores\'].items()))\n        new_id2answer_dict[\'scores\'] = new_id2score_dict\n        return F1Evaluation(self.data_type, self.global_step, new_idxs, new_yp, new_yp2, new_y, new_correct, new_loss, new_f1s, new_id2answer_dict)\n\n    def __repr__(self):\n        return ""{} step {}: accuracy={:.4f}, f1={:.4f}, loss={:.4f}"".format(self.data_type, self.global_step, self.acc, self.f1, self.loss)\n\n\nclass F1Evaluator(LabeledEvaluator):\n    def __init__(self, config, model, tensor_dict=None):\n        super(F1Evaluator, self).__init__(config, model, tensor_dict=tensor_dict)\n        self.yp2 = model.yp2\n        self.loss = model.loss\n\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = self._split_batch(batch)\n        assert isinstance(data_set, DataSet)\n        feed_dict = self._get_feed_dict(batch)\n        global_step, yp, yp2, loss, vals = sess.run([self.global_step, self.yp, self.yp2, self.loss, list(self.tensor_dict.values())], feed_dict=feed_dict)\n        y = data_set.data[\'y\']\n        if self.config.squash:\n            new_y = []\n            for xi, yi in zip(data_set.data[\'x\'], y):\n                new_yi = []\n                for start, stop in yi:\n                    start_offset = sum(map(len, xi[:start[0]]))\n                    stop_offset = sum(map(len, xi[:stop[0]]))\n                    new_start = 0, start_offset + start[1]\n                    new_stop = 0, stop_offset + stop[1]\n                    new_yi.append((new_start, new_stop))\n                new_y.append(new_yi)\n            y = new_y\n        if self.config.single:\n            new_y = []\n            for yi in y:\n                new_yi = []\n                for start, stop in yi:\n                    new_start = 0, start[1]\n                    new_stop = 0, stop[1]\n                    new_yi.append((new_start, new_stop))\n                new_y.append(new_yi)\n            y = new_y\n\n        yp, yp2 = yp[:data_set.num_examples], yp2[:data_set.num_examples]\n        spans, scores = zip(*[get_best_span(ypi, yp2i) for ypi, yp2i in zip(yp, yp2)])\n\n        def _get(xi, span):\n            if len(xi) <= span[0][0]:\n                return [""""]\n            if len(xi[span[0][0]]) <= span[1][1]:\n                return [""""]\n            return xi[span[0][0]][span[0][1]:span[1][1]]\n\n        def _get2(context, xi, span):\n            if len(xi) <= span[0][0]:\n                return """"\n            if len(xi[span[0][0]]) <= span[1][1]:\n                return """"\n            return get_phrase(context, xi, span)\n\n        id2answer_dict = {id_: _get2(context, xi, span)\n                          for id_, xi, span, context in zip(data_set.data[\'ids\'], data_set.data[\'x\'], spans, data_set.data[\'p\'])}\n        id2score_dict = {id_: score for id_, score in zip(data_set.data[\'ids\'], scores)}\n        id2answer_dict[\'scores\'] = id2score_dict\n        correct = [self.__class__.compare2(yi, span) for yi, span in zip(y, spans)]\n        f1s = [self.__class__.span_f1(yi, span) for yi, span in zip(y, spans)]\n        tensor_dict = dict(zip(self.tensor_dict.keys(), vals))\n        e = F1Evaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), yp2.tolist(), y,\n                         correct, float(loss), f1s, id2answer_dict, tensor_dict=tensor_dict)\n        return e\n\n    def _split_batch(self, batch):\n        return batch\n\n    def _get_feed_dict(self, batch):\n        return self.model.get_feed_dict(batch[1], False)\n\n    @staticmethod\n    def compare(yi, ypi, yp2i):\n        for start, stop in yi:\n            aypi = argmax(ypi)\n            mask = np.zeros(yp2i.shape)\n            mask[aypi[0], aypi[1]:] = np.ones([yp2i.shape[1] - aypi[1]])\n            if tuple(start) == aypi and (stop[0], stop[1]-1) == argmax(yp2i * mask):\n                return True\n        return False\n\n    @staticmethod\n    def compare2(yi, span):\n        for start, stop in yi:\n            if tuple(start) == span[0] and tuple(stop) == span[1]:\n                return True\n        return False\n\n    @staticmethod\n    def span_f1(yi, span):\n        max_f1 = 0\n        for start, stop in yi:\n            if start[0] == span[0][0]:\n                true_span = start[1], stop[1]\n                pred_span = span[0][1], span[1][1]\n                f1 = span_f1(true_span, pred_span)\n                max_f1 = max(f1, max_f1)\n        return max_f1\n\n\nclass MultiGPUF1Evaluator(F1Evaluator):\n    def __init__(self, config, models, tensor_dict=None):\n        super(MultiGPUF1Evaluator, self).__init__(config, models[0], tensor_dict=tensor_dict)\n        self.models = models\n        with tf.name_scope(""eval_concat""):\n            N, M, JX = config.batch_size, config.max_num_sents, config.max_sent_size\n            self.yp = tf.concat(0, [padded_reshape(model.yp, [N, M, JX]) for model in models])\n            self.yp2 = tf.concat(0, [padded_reshape(model.yp2, [N, M, JX]) for model in models])\n            self.loss = tf.add_n([model.loss for model in models])/len(models)\n\n    def _split_batch(self, batches):\n        idxs_list, data_sets = zip(*batches)\n        idxs = sum(idxs_list, ())\n        data_set = sum(data_sets, data_sets[0].get_empty())\n        return idxs, data_set\n\n    def _get_feed_dict(self, batches):\n        feed_dict = {}\n        for model, (_, data_set) in zip(self.models, batches):\n            feed_dict.update(model.get_feed_dict(data_set, False))\n        return feed_dict\n\n\nclass ForwardEvaluator(Evaluator):\n    def __init__(self, config, model, tensor_dict=None):\n        super(ForwardEvaluator, self).__init__(config, model, tensor_dict=tensor_dict)\n        self.yp2 = model.yp2\n        self.loss = model.loss\n\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = batch\n        assert isinstance(data_set, DataSet)\n        feed_dict = self.model.get_feed_dict(data_set, False)\n        global_step, yp, yp2, loss, vals = sess.run([self.global_step, self.yp, self.yp2, self.loss, list(self.tensor_dict.values())], feed_dict=feed_dict)\n\n        yp, yp2 = yp[:data_set.num_examples], yp2[:data_set.num_examples]\n        spans, scores = zip(*[get_best_span(ypi, yp2i) for ypi, yp2i in zip(yp, yp2)])\n\n        def _get(xi, span):\n            if len(xi) <= span[0][0]:\n                return [""""]\n            if len(xi[span[0][0]]) <= span[1][1]:\n                return [""""]\n            return xi[span[0][0]][span[0][1]:span[1][1]]\n\n        def _get2(context, xi, span):\n            if len(xi) <= span[0][0]:\n                return """"\n            if len(xi[span[0][0]]) <= span[1][1]:\n                return """"\n            return get_phrase(context, xi, span)\n\n        id2answer_dict = {id_: _get2(context, xi, span)\n                          for id_, xi, span, context in zip(data_set.data[\'ids\'], data_set.data[\'x\'], spans, data_set.data[\'p\'])}\n        id2score_dict = {id_: score for id_, score in zip(data_set.data[\'ids\'], scores)}\n        id2answer_dict[\'scores\'] = id2score_dict\n        tensor_dict = dict(zip(self.tensor_dict.keys(), vals))\n        e = ForwardEvaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), yp2.tolist(), float(loss), id2answer_dict, tensor_dict=tensor_dict)\n        return e\n\n    @staticmethod\n    def compare(yi, ypi, yp2i):\n        for start, stop in yi:\n            aypi = argmax(ypi)\n            mask = np.zeros(yp2i.shape)\n            mask[aypi[0], aypi[1]:] = np.ones([yp2i.shape[1] - aypi[1]])\n            if tuple(start) == aypi and (stop[0], stop[1]-1) == argmax(yp2i * mask):\n                return True\n        return False\n\n    @staticmethod\n    def compare2(yi, span):\n        for start, stop in yi:\n            if tuple(start) == span[0] and tuple(stop) == span[1]:\n                return True\n        return False\n\n    @staticmethod\n    def span_f1(yi, span):\n        max_f1 = 0\n        for start, stop in yi:\n            if start[0] == span[0][0]:\n                true_span = start[1], stop[1]\n                pred_span = span[0][1], span[1][1]\n                f1 = span_f1(true_span, pred_span)\n                max_f1 = max(f1, max_f1)\n        return max_f1\n\n\n'"
basic/graph_handler.py,8,"b'import gzip\nimport json\nfrom json import encoder\nimport os\n\nimport tensorflow as tf\n\nfrom basic.evaluator import Evaluation, F1Evaluation\nfrom my.utils import short_floats\n\nimport pickle\n\n\nclass GraphHandler(object):\n    def __init__(self, config, model):\n        self.config = config\n        self.model = model\n        self.saver = tf.train.Saver(max_to_keep=config.max_to_keep)\n        self.writer = None\n        self.save_path = os.path.join(config.save_dir, config.model_name)\n\n    def initialize(self, sess):\n        sess.run(tf.initialize_all_variables())\n        if self.config.load:\n            self._load(sess)\n\n        if self.config.mode == \'train\':\n            self.writer = tf.train.SummaryWriter(self.config.log_dir, graph=tf.get_default_graph())\n\n    def save(self, sess, global_step=None):\n        saver = tf.train.Saver(max_to_keep=self.config.max_to_keep)\n        saver.save(sess, self.save_path, global_step=global_step)\n\n    def _load(self, sess):\n        config = self.config\n        vars_ = {var.name.split("":"")[0]: var for var in tf.all_variables()}\n        if config.load_ema:\n            ema = self.model.var_ema\n            for var in tf.trainable_variables():\n                del vars_[var.name.split("":"")[0]]\n                vars_[ema.average_name(var)] = var\n        saver = tf.train.Saver(vars_, max_to_keep=config.max_to_keep)\n\n        if config.load_path:\n            save_path = config.load_path\n        elif config.load_step > 0:\n            save_path = os.path.join(config.save_dir, ""{}-{}"".format(config.model_name, config.load_step))\n        else:\n            save_dir = config.save_dir\n            checkpoint = tf.train.get_checkpoint_state(save_dir)\n            assert checkpoint is not None, ""cannot load checkpoint at {}"".format(save_dir)\n            save_path = checkpoint.model_checkpoint_path\n        print(""Loading saved model from {}"".format(save_path))\n        saver.restore(sess, save_path)\n\n    def add_summary(self, summary, global_step):\n        self.writer.add_summary(summary, global_step)\n\n    def add_summaries(self, summaries, global_step):\n        for summary in summaries:\n            self.add_summary(summary, global_step)\n\n    def dump_eval(self, e, precision=2, path=None):\n        assert isinstance(e, Evaluation)\n        if self.config.dump_pickle:\n            path = path or os.path.join(self.config.eval_dir, ""{}-{}.pklz"".format(e.data_type, str(e.global_step).zfill(6)))\n            with gzip.open(path, \'wb\', compresslevel=3) as fh:\n                pickle.dump(e.dict, fh)\n        else:\n            path = path or os.path.join(self.config.eval_dir, ""{}-{}.json"".format(e.data_type, str(e.global_step).zfill(6)))\n            with open(path, \'w\') as fh:\n                json.dump(short_floats(e.dict, precision), fh)\n\n    def dump_answer(self, e, path=None):\n        assert isinstance(e, Evaluation)\n        path = path or os.path.join(self.config.answer_dir, ""{}-{}.json"".format(e.data_type, str(e.global_step).zfill(6)))\n        with open(path, \'w\') as fh:\n            json.dump(e.id2answer_dict, fh)\n\n'"
basic/main.py,4,"b'import argparse\nimport json\nimport math\nimport os\nimport shutil\nfrom pprint import pprint\n\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport numpy as np\n\nfrom basic.evaluator import ForwardEvaluator, MultiGPUF1Evaluator\nfrom basic.graph_handler import GraphHandler\nfrom basic.model import get_multi_gpu_models\nfrom basic.trainer import MultiGPUTrainer\nfrom basic.read_data import read_data, get_squad_data_filter, update_config\n\n\ndef main(config):\n    set_dirs(config)\n    with tf.device(config.device):\n        if config.mode == \'train\':\n            _train(config)\n        elif config.mode == \'test\':\n            _test(config)\n        elif config.mode == \'forward\':\n            _forward(config)\n        else:\n            raise ValueError(""invalid value for \'mode\': {}"".format(config.mode))\n\n\ndef set_dirs(config):\n    # create directories\n    assert config.load or config.mode == \'train\', ""config.load must be True if not training""\n    if not config.load and os.path.exists(config.out_dir):\n        shutil.rmtree(config.out_dir)\n\n    config.save_dir = os.path.join(config.out_dir, ""save"")\n    config.log_dir = os.path.join(config.out_dir, ""log"")\n    config.eval_dir = os.path.join(config.out_dir, ""eval"")\n    config.answer_dir = os.path.join(config.out_dir, ""answer"")\n    if not os.path.exists(config.out_dir):\n        os.makedirs(config.out_dir)\n    if not os.path.exists(config.save_dir):\n        os.mkdir(config.save_dir)\n    if not os.path.exists(config.log_dir):\n        os.mkdir(config.log_dir)\n    if not os.path.exists(config.answer_dir):\n        os.mkdir(config.answer_dir)\n    if not os.path.exists(config.eval_dir):\n        os.mkdir(config.eval_dir)\n\n\ndef _config_debug(config):\n    if config.debug:\n        config.num_steps = 2\n        config.eval_period = 1\n        config.log_period = 1\n        config.save_period = 1\n        config.val_num_batches = 2\n        config.test_num_batches = 2\n\n\ndef _train(config):\n    data_filter = get_squad_data_filter(config)\n    train_data = read_data(config, \'train\', config.load, data_filter=data_filter)\n    dev_data = read_data(config, \'dev\', True, data_filter=data_filter)\n    update_config(config, [train_data, dev_data])\n\n    _config_debug(config)\n\n    word2vec_dict = train_data.shared[\'lower_word2vec\'] if config.lower_word else train_data.shared[\'word2vec\']\n    word2idx_dict = train_data.shared[\'word2idx\']\n    idx2vec_dict = {word2idx_dict[word]: vec for word, vec in word2vec_dict.items() if word in word2idx_dict}\n    emb_mat = np.array([idx2vec_dict[idx] if idx in idx2vec_dict\n                        else np.random.multivariate_normal(np.zeros(config.word_emb_size), np.eye(config.word_emb_size))\n                        for idx in range(config.word_vocab_size)])\n    config.emb_mat = emb_mat\n\n    # construct model graph and variables (using default graph)\n    pprint(config.__flags, indent=2)\n    models = get_multi_gpu_models(config)\n    model = models[0]\n    trainer = MultiGPUTrainer(config, models)\n    evaluator = MultiGPUF1Evaluator(config, models, tensor_dict=model.tensor_dict if config.vis else None)\n    graph_handler = GraphHandler(config, model)  # controls all tensors and variables in the graph, including loading /saving\n\n    # Variables\n    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n    graph_handler.initialize(sess)\n\n    # Begin training\n    num_steps = config.num_steps or int(math.ceil(train_data.num_examples / (config.batch_size * config.num_gpus))) * config.num_epochs\n    global_step = 0\n    for batches in tqdm(train_data.get_multi_batches(config.batch_size, config.num_gpus,\n                                                     num_steps=num_steps, shuffle=True, cluster=config.cluster), total=num_steps):\n        global_step = sess.run(model.global_step) + 1  # +1 because all calculations are done after step\n        get_summary = global_step % config.log_period == 0\n        loss, summary, train_op = trainer.step(sess, batches, get_summary=get_summary)\n        if get_summary:\n            graph_handler.add_summary(summary, global_step)\n\n        # occasional saving\n        if global_step % config.save_period == 0:\n            graph_handler.save(sess, global_step=global_step)\n\n        if not config.eval:\n            continue\n        # Occasional evaluation\n        if global_step % config.eval_period == 0:\n            num_steps = math.ceil(dev_data.num_examples / (config.batch_size * config.num_gpus))\n            if 0 < config.val_num_batches < num_steps:\n                num_steps = config.val_num_batches\n            e_train = evaluator.get_evaluation_from_batches(\n                sess, tqdm(train_data.get_multi_batches(config.batch_size, config.num_gpus, num_steps=num_steps), total=num_steps)\n            )\n            graph_handler.add_summaries(e_train.summaries, global_step)\n            e_dev = evaluator.get_evaluation_from_batches(\n                sess, tqdm(dev_data.get_multi_batches(config.batch_size, config.num_gpus, num_steps=num_steps), total=num_steps))\n            graph_handler.add_summaries(e_dev.summaries, global_step)\n\n            if config.dump_eval:\n                graph_handler.dump_eval(e_dev)\n            if config.dump_answer:\n                graph_handler.dump_answer(e_dev)\n    if global_step % config.save_period != 0:\n        graph_handler.save(sess, global_step=global_step)\n\n\ndef _test(config):\n    test_data = read_data(config, \'test\', True)\n    update_config(config, [test_data])\n\n    _config_debug(config)\n\n    if config.use_glove_for_unk:\n        word2vec_dict = test_data.shared[\'lower_word2vec\'] if config.lower_word else test_data.shared[\'word2vec\']\n        new_word2idx_dict = test_data.shared[\'new_word2idx\']\n        idx2vec_dict = {idx: word2vec_dict[word] for word, idx in new_word2idx_dict.items()}\n        new_emb_mat = np.array([idx2vec_dict[idx] for idx in range(len(idx2vec_dict))], dtype=\'float32\')\n        config.new_emb_mat = new_emb_mat\n\n    pprint(config.__flags, indent=2)\n    models = get_multi_gpu_models(config)\n    model = models[0]\n    evaluator = MultiGPUF1Evaluator(config, models, tensor_dict=models[0].tensor_dict if config.vis else None)\n    graph_handler = GraphHandler(config, model)\n\n    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n    graph_handler.initialize(sess)\n    num_steps = math.ceil(test_data.num_examples / (config.batch_size * config.num_gpus))\n    if 0 < config.test_num_batches < num_steps:\n        num_steps = config.test_num_batches\n\n    e = None\n    for multi_batch in tqdm(test_data.get_multi_batches(config.batch_size, config.num_gpus, num_steps=num_steps, cluster=config.cluster), total=num_steps):\n        ei = evaluator.get_evaluation(sess, multi_batch)\n        e = ei if e is None else e + ei\n        if config.vis:\n            eval_subdir = os.path.join(config.eval_dir, ""{}-{}"".format(ei.data_type, str(ei.global_step).zfill(6)))\n            if not os.path.exists(eval_subdir):\n                os.mkdir(eval_subdir)\n            path = os.path.join(eval_subdir, str(ei.idxs[0]).zfill(8))\n            graph_handler.dump_eval(ei, path=path)\n\n    print(e)\n    if config.dump_answer:\n        print(""dumping answer ..."")\n        graph_handler.dump_answer(e)\n    if config.dump_eval:\n        print(""dumping eval ..."")\n        graph_handler.dump_eval(e)\n\n\ndef _forward(config):\n    assert config.load\n    test_data = read_data(config, config.forward_name, True)\n    update_config(config, [test_data])\n\n    _config_debug(config)\n\n    if config.use_glove_for_unk:\n        word2vec_dict = test_data.shared[\'lower_word2vec\'] if config.lower_word else test_data.shared[\'word2vec\']\n        new_word2idx_dict = test_data.shared[\'new_word2idx\']\n        idx2vec_dict = {idx: word2vec_dict[word] for word, idx in new_word2idx_dict.items()}\n        new_emb_mat = np.array([idx2vec_dict[idx] for idx in range(len(idx2vec_dict))], dtype=\'float32\')\n        config.new_emb_mat = new_emb_mat\n\n    pprint(config.__flags, indent=2)\n    models = get_multi_gpu_models(config)\n    model = models[0]\n    evaluator = ForwardEvaluator(config, model)\n    graph_handler = GraphHandler(config, model)  # controls all tensors and variables in the graph, including loading /saving\n\n    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n    graph_handler.initialize(sess)\n\n    num_batches = math.ceil(test_data.num_examples / config.batch_size)\n    if 0 < config.test_num_batches < num_batches:\n        num_batches = config.test_num_batches\n    e = evaluator.get_evaluation_from_batches(sess, tqdm(test_data.get_batches(config.batch_size, num_batches=num_batches), total=num_batches))\n    print(e)\n    if config.dump_answer:\n        print(""dumping answer ..."")\n        graph_handler.dump_answer(e, path=config.answer_path)\n    if config.dump_eval:\n        print(""dumping eval ..."")\n        graph_handler.dump_eval(e, path=config.eval_path)\n\n\ndef _get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""config_path"")\n    return parser.parse_args()\n\n\nclass Config(object):\n    def __init__(self, **entries):\n        self.__dict__.update(entries)\n\n\ndef _run():\n    args = _get_args()\n    with open(args.config_path, \'r\') as fh:\n        config = Config(**json.load(fh))\n        main(config)\n\n\nif __name__ == ""__main__"":\n    _run()\n'"
basic/model.py,110,"b'import random\n\nimport itertools\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.ops.rnn_cell import BasicLSTMCell\n\nfrom basic.read_data import DataSet\nfrom my.tensorflow import get_initializer\nfrom my.tensorflow.nn import softsel, get_logits, highway_network, multi_conv1d\nfrom my.tensorflow.rnn import bidirectional_dynamic_rnn\nfrom my.tensorflow.rnn_cell import SwitchableDropoutWrapper, AttentionCell\n\n\ndef get_multi_gpu_models(config):\n    models = []\n    for gpu_idx in range(config.num_gpus):\n        with tf.name_scope(""model_{}"".format(gpu_idx)) as scope, tf.device(""/{}:{}"".format(config.device_type, gpu_idx)):\n            model = Model(config, scope, rep=gpu_idx == 0)\n            tf.get_variable_scope().reuse_variables()\n            models.append(model)\n    return models\n\n\nclass Model(object):\n    def __init__(self, config, scope, rep=True):\n        self.scope = scope\n        self.config = config\n        self.global_step = tf.get_variable(\'global_step\', shape=[], dtype=\'int32\',\n                                           initializer=tf.constant_initializer(0), trainable=False)\n\n        # Define forward inputs here\n        N, M, JX, JQ, VW, VC, W = \\\n            config.batch_size, config.max_num_sents, config.max_sent_size, \\\n            config.max_ques_size, config.word_vocab_size, config.char_vocab_size, config.max_word_size\n        self.x = tf.placeholder(\'int32\', [N, None, None], name=\'x\')\n        self.cx = tf.placeholder(\'int32\', [N, None, None, W], name=\'cx\')\n        self.x_mask = tf.placeholder(\'bool\', [N, None, None], name=\'x_mask\')\n        self.q = tf.placeholder(\'int32\', [N, None], name=\'q\')\n        self.cq = tf.placeholder(\'int32\', [N, None, W], name=\'cq\')\n        self.q_mask = tf.placeholder(\'bool\', [N, None], name=\'q_mask\')\n        self.y = tf.placeholder(\'bool\', [N, None, None], name=\'y\')\n        self.y2 = tf.placeholder(\'bool\', [N, None, None], name=\'y2\')\n        self.is_train = tf.placeholder(\'bool\', [], name=\'is_train\')\n        self.new_emb_mat = tf.placeholder(\'float\', [None, config.word_emb_size], name=\'new_emb_mat\')\n\n        # Define misc\n        self.tensor_dict = {}\n\n        # Forward outputs / loss inputs\n        self.logits = None\n        self.yp = None\n        self.var_list = None\n\n        # Loss outputs\n        self.loss = None\n\n        self._build_forward()\n        self._build_loss()\n        self.var_ema = None\n        if rep:\n            self._build_var_ema()\n        if config.mode == \'train\':\n            self._build_ema()\n\n        self.summary = tf.merge_all_summaries()\n        self.summary = tf.merge_summary(tf.get_collection(""summaries"", scope=self.scope))\n\n    def _build_forward(self):\n        config = self.config\n        N, M, JX, JQ, VW, VC, d, W = \\\n            config.batch_size, config.max_num_sents, config.max_sent_size, \\\n            config.max_ques_size, config.word_vocab_size, config.char_vocab_size, config.hidden_size, \\\n            config.max_word_size\n        JX = tf.shape(self.x)[2]\n        JQ = tf.shape(self.q)[1]\n        M = tf.shape(self.x)[1]\n        dc, dw, dco = config.char_emb_size, config.word_emb_size, config.char_out_size\n\n        with tf.variable_scope(""emb""):\n            if config.use_char_emb:\n                with tf.variable_scope(""emb_var""), tf.device(""/cpu:0""):\n                    char_emb_mat = tf.get_variable(""char_emb_mat"", shape=[VC, dc], dtype=\'float\')\n\n                with tf.variable_scope(""char""):\n                    Acx = tf.nn.embedding_lookup(char_emb_mat, self.cx)  # [N, M, JX, W, dc]\n                    Acq = tf.nn.embedding_lookup(char_emb_mat, self.cq)  # [N, JQ, W, dc]\n                    Acx = tf.reshape(Acx, [-1, JX, W, dc])\n                    Acq = tf.reshape(Acq, [-1, JQ, W, dc])\n\n                    filter_sizes = list(map(int, config.out_channel_dims.split(\',\')))\n                    heights = list(map(int, config.filter_heights.split(\',\')))\n                    assert sum(filter_sizes) == dco, (filter_sizes, dco)\n                    with tf.variable_scope(""conv""):\n                        xx = multi_conv1d(Acx, filter_sizes, heights, ""VALID"",  self.is_train, config.keep_prob, scope=""xx"")\n                        if config.share_cnn_weights:\n                            tf.get_variable_scope().reuse_variables()\n                            qq = multi_conv1d(Acq, filter_sizes, heights, ""VALID"", self.is_train, config.keep_prob, scope=""xx"")\n                        else:\n                            qq = multi_conv1d(Acq, filter_sizes, heights, ""VALID"", self.is_train, config.keep_prob, scope=""qq"")\n                        xx = tf.reshape(xx, [-1, M, JX, dco])\n                        qq = tf.reshape(qq, [-1, JQ, dco])\n\n            if config.use_word_emb:\n                with tf.variable_scope(""emb_var""), tf.device(""/cpu:0""):\n                    if config.mode == \'train\':\n                        word_emb_mat = tf.get_variable(""word_emb_mat"", dtype=\'float\', shape=[VW, dw], initializer=get_initializer(config.emb_mat))\n                    else:\n                        word_emb_mat = tf.get_variable(""word_emb_mat"", shape=[VW, dw], dtype=\'float\')\n                    if config.use_glove_for_unk:\n                        word_emb_mat = tf.concat(0, [word_emb_mat, self.new_emb_mat])\n\n                with tf.name_scope(""word""):\n                    Ax = tf.nn.embedding_lookup(word_emb_mat, self.x)  # [N, M, JX, d]\n                    Aq = tf.nn.embedding_lookup(word_emb_mat, self.q)  # [N, JQ, d]\n                    self.tensor_dict[\'x\'] = Ax\n                    self.tensor_dict[\'q\'] = Aq\n                if config.use_char_emb:\n                    xx = tf.concat(3, [xx, Ax])  # [N, M, JX, di]\n                    qq = tf.concat(2, [qq, Aq])  # [N, JQ, di]\n                else:\n                    xx = Ax\n                    qq = Aq\n\n        # highway network\n        if config.highway:\n            with tf.variable_scope(""highway""):\n                xx = highway_network(xx, config.highway_num_layers, True, wd=config.wd, is_train=self.is_train)\n                tf.get_variable_scope().reuse_variables()\n                qq = highway_network(qq, config.highway_num_layers, True, wd=config.wd, is_train=self.is_train)\n\n        self.tensor_dict[\'xx\'] = xx\n        self.tensor_dict[\'qq\'] = qq\n\n        cell = BasicLSTMCell(d, state_is_tuple=True)\n        d_cell = SwitchableDropoutWrapper(cell, self.is_train, input_keep_prob=config.input_keep_prob)\n        x_len = tf.reduce_sum(tf.cast(self.x_mask, \'int32\'), 2)  # [N, M]\n        q_len = tf.reduce_sum(tf.cast(self.q_mask, \'int32\'), 1)  # [N]\n\n        with tf.variable_scope(""prepro""):\n            (fw_u, bw_u), ((_, fw_u_f), (_, bw_u_f)) = bidirectional_dynamic_rnn(d_cell, d_cell, qq, q_len, dtype=\'float\', scope=\'u1\')  # [N, J, d], [N, d]\n            u = tf.concat(2, [fw_u, bw_u])\n            if config.share_lstm_weights:\n                tf.get_variable_scope().reuse_variables()\n                (fw_h, bw_h), _ = bidirectional_dynamic_rnn(cell, cell, xx, x_len, dtype=\'float\', scope=\'u1\')  # [N, M, JX, 2d]\n                h = tf.concat(3, [fw_h, bw_h])  # [N, M, JX, 2d]\n            else:\n                (fw_h, bw_h), _ = bidirectional_dynamic_rnn(cell, cell, xx, x_len, dtype=\'float\', scope=\'h1\')  # [N, M, JX, 2d]\n                h = tf.concat(3, [fw_h, bw_h])  # [N, M, JX, 2d]\n            self.tensor_dict[\'u\'] = u\n            self.tensor_dict[\'h\'] = h\n\n        with tf.variable_scope(""main""):\n            if config.dynamic_att:\n                p0 = h\n                u = tf.reshape(tf.tile(tf.expand_dims(u, 1), [1, M, 1, 1]), [N * M, JQ, 2 * d])\n                q_mask = tf.reshape(tf.tile(tf.expand_dims(self.q_mask, 1), [1, M, 1]), [N * M, JQ])\n                first_cell = AttentionCell(cell, u, mask=q_mask, mapper=\'sim\',\n                                           input_keep_prob=self.config.input_keep_prob, is_train=self.is_train)\n            else:\n                p0 = attention_layer(config, self.is_train, h, u, h_mask=self.x_mask, u_mask=self.q_mask, scope=""p0"", tensor_dict=self.tensor_dict)\n                first_cell = d_cell\n\n            (fw_g0, bw_g0), _ = bidirectional_dynamic_rnn(first_cell, first_cell, p0, x_len, dtype=\'float\', scope=\'g0\')  # [N, M, JX, 2d]\n            g0 = tf.concat(3, [fw_g0, bw_g0])\n            (fw_g1, bw_g1), _ = bidirectional_dynamic_rnn(first_cell, first_cell, g0, x_len, dtype=\'float\', scope=\'g1\')  # [N, M, JX, 2d]\n            g1 = tf.concat(3, [fw_g1, bw_g1])\n\n            logits = get_logits([g1, p0], d, True, wd=config.wd, input_keep_prob=config.input_keep_prob,\n                                mask=self.x_mask, is_train=self.is_train, func=config.answer_func, scope=\'logits1\')\n            a1i = softsel(tf.reshape(g1, [N, M * JX, 2 * d]), tf.reshape(logits, [N, M * JX]))\n            a1i = tf.tile(tf.expand_dims(tf.expand_dims(a1i, 1), 1), [1, M, JX, 1])\n\n            (fw_g2, bw_g2), _ = bidirectional_dynamic_rnn(d_cell, d_cell, tf.concat(3, [p0, g1, a1i, g1 * a1i]),\n                                                          x_len, dtype=\'float\', scope=\'g2\')  # [N, M, JX, 2d]\n            g2 = tf.concat(3, [fw_g2, bw_g2])\n            logits2 = get_logits([g2, p0], d, True, wd=config.wd, input_keep_prob=config.input_keep_prob,\n                                 mask=self.x_mask,\n                                 is_train=self.is_train, func=config.answer_func, scope=\'logits2\')\n\n            flat_logits = tf.reshape(logits, [-1, M * JX])\n            flat_yp = tf.nn.softmax(flat_logits)  # [-1, M*JX]\n            yp = tf.reshape(flat_yp, [-1, M, JX])\n            flat_logits2 = tf.reshape(logits2, [-1, M * JX])\n            flat_yp2 = tf.nn.softmax(flat_logits2)\n            yp2 = tf.reshape(flat_yp2, [-1, M, JX])\n\n            self.tensor_dict[\'g1\'] = g1\n            self.tensor_dict[\'g2\'] = g2\n\n            self.logits = flat_logits\n            self.logits2 = flat_logits2\n            self.yp = yp\n            self.yp2 = yp2\n\n    def _build_loss(self):\n        config = self.config\n        JX = tf.shape(self.x)[2]\n        M = tf.shape(self.x)[1]\n        JQ = tf.shape(self.q)[1]\n        loss_mask = tf.reduce_max(tf.cast(self.q_mask, \'float\'), 1)\n        losses = tf.nn.softmax_cross_entropy_with_logits(\n            self.logits, tf.cast(tf.reshape(self.y, [-1, M * JX]), \'float\'))\n        ce_loss = tf.reduce_mean(loss_mask * losses)\n        tf.add_to_collection(\'losses\', ce_loss)\n        ce_loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n            self.logits2, tf.cast(tf.reshape(self.y2, [-1, M * JX]), \'float\')))\n        tf.add_to_collection(""losses"", ce_loss2)\n\n        self.loss = tf.add_n(tf.get_collection(\'losses\', scope=self.scope), name=\'loss\')\n        tf.scalar_summary(self.loss.op.name, self.loss)\n        tf.add_to_collection(\'ema/scalar\', self.loss)\n\n    def _build_ema(self):\n        self.ema = tf.train.ExponentialMovingAverage(self.config.decay)\n        ema = self.ema\n        tensors = tf.get_collection(""ema/scalar"", scope=self.scope) + tf.get_collection(""ema/vector"", scope=self.scope)\n        ema_op = ema.apply(tensors)\n        for var in tf.get_collection(""ema/scalar"", scope=self.scope):\n            ema_var = ema.average(var)\n            tf.scalar_summary(ema_var.op.name, ema_var)\n        for var in tf.get_collection(""ema/vector"", scope=self.scope):\n            ema_var = ema.average(var)\n            tf.histogram_summary(ema_var.op.name, ema_var)\n\n        with tf.control_dependencies([ema_op]):\n            self.loss = tf.identity(self.loss)\n\n    def _build_var_ema(self):\n        self.var_ema = tf.train.ExponentialMovingAverage(self.config.var_decay)\n        ema = self.var_ema\n        ema_op = ema.apply(tf.trainable_variables())\n        with tf.control_dependencies([ema_op]):\n            self.loss = tf.identity(self.loss)\n\n    def get_loss(self):\n        return self.loss\n\n    def get_global_step(self):\n        return self.global_step\n\n    def get_var_list(self):\n        return self.var_list\n\n    def get_feed_dict(self, batch, is_train, supervised=True):\n        assert isinstance(batch, DataSet)\n        config = self.config\n        N, M, JX, JQ, VW, VC, d, W = \\\n            config.batch_size, config.max_num_sents, config.max_sent_size, \\\n            config.max_ques_size, config.word_vocab_size, config.char_vocab_size, config.hidden_size, config.max_word_size\n        feed_dict = {}\n\n        if config.len_opt:\n            """"""\n            Note that this optimization results in variable GPU RAM usage (i.e. can cause OOM in the middle of training.)\n            First test without len_opt and make sure no OOM, and use len_opt\n            """"""\n            if sum(len(sent) for para in batch.data[\'x\'] for sent in para) == 0:\n                new_JX = 1\n            else:\n                new_JX = max(len(sent) for para in batch.data[\'x\'] for sent in para)\n            JX = min(JX, new_JX)\n\n            if sum(len(ques) for ques in batch.data[\'q\']) == 0:\n                new_JQ = 1\n            else:\n                new_JQ = max(len(ques) for ques in batch.data[\'q\'])\n            JQ = min(JQ, new_JQ)\n\n        if config.cpu_opt:\n            if sum(len(para) for para in batch.data[\'x\']) == 0:\n                new_M = 1\n            else:\n                new_M = max(len(para) for para in batch.data[\'x\'])\n            M = min(M, new_M)\n\n        x = np.zeros([N, M, JX], dtype=\'int32\')\n        cx = np.zeros([N, M, JX, W], dtype=\'int32\')\n        x_mask = np.zeros([N, M, JX], dtype=\'bool\')\n        q = np.zeros([N, JQ], dtype=\'int32\')\n        cq = np.zeros([N, JQ, W], dtype=\'int32\')\n        q_mask = np.zeros([N, JQ], dtype=\'bool\')\n\n        feed_dict[self.x] = x\n        feed_dict[self.x_mask] = x_mask\n        feed_dict[self.cx] = cx\n        feed_dict[self.q] = q\n        feed_dict[self.cq] = cq\n        feed_dict[self.q_mask] = q_mask\n        feed_dict[self.is_train] = is_train\n        if config.use_glove_for_unk:\n            feed_dict[self.new_emb_mat] = batch.shared[\'new_emb_mat\']\n\n        X = batch.data[\'x\']\n        CX = batch.data[\'cx\']\n\n        if supervised:\n            y = np.zeros([N, M, JX], dtype=\'bool\')\n            y2 = np.zeros([N, M, JX], dtype=\'bool\')\n            feed_dict[self.y] = y\n            feed_dict[self.y2] = y2\n\n            for i, (xi, cxi, yi) in enumerate(zip(X, CX, batch.data[\'y\'])):\n                start_idx, stop_idx = random.choice(yi)\n                j, k = start_idx\n                j2, k2 = stop_idx\n                if config.single:\n                    X[i] = [xi[j]]\n                    CX[i] = [cxi[j]]\n                    j, j2 = 0, 0\n                if config.squash:\n                    offset = sum(map(len, xi[:j]))\n                    j, k = 0, k + offset\n                    offset = sum(map(len, xi[:j2]))\n                    j2, k2 = 0, k2 + offset\n                y[i, j, k] = True\n                y2[i, j2, k2-1] = True\n\n        def _get_word(word):\n            d = batch.shared[\'word2idx\']\n            for each in (word, word.lower(), word.capitalize(), word.upper()):\n                if each in d:\n                    return d[each]\n            if config.use_glove_for_unk:\n                d2 = batch.shared[\'new_word2idx\']\n                for each in (word, word.lower(), word.capitalize(), word.upper()):\n                    if each in d2:\n                        return d2[each] + len(d)\n            return 1\n\n        def _get_char(char):\n            d = batch.shared[\'char2idx\']\n            if char in d:\n                return d[char]\n            return 1\n\n        for i, xi in enumerate(X):\n            if self.config.squash:\n                xi = [list(itertools.chain(*xi))]\n            for j, xij in enumerate(xi):\n                if j == config.max_num_sents:\n                    break\n                for k, xijk in enumerate(xij):\n                    if k == config.max_sent_size:\n                        break\n                    each = _get_word(xijk)\n                    assert isinstance(each, int), each\n                    x[i, j, k] = each\n                    x_mask[i, j, k] = True\n\n        for i, cxi in enumerate(CX):\n            if self.config.squash:\n                cxi = [list(itertools.chain(*cxi))]\n            for j, cxij in enumerate(cxi):\n                if j == config.max_num_sents:\n                    break\n                for k, cxijk in enumerate(cxij):\n                    if k == config.max_sent_size:\n                        break\n                    for l, cxijkl in enumerate(cxijk):\n                        if l == config.max_word_size:\n                            break\n                        cx[i, j, k, l] = _get_char(cxijkl)\n\n        for i, qi in enumerate(batch.data[\'q\']):\n            for j, qij in enumerate(qi):\n                q[i, j] = _get_word(qij)\n                q_mask[i, j] = True\n\n        for i, cqi in enumerate(batch.data[\'cq\']):\n            for j, cqij in enumerate(cqi):\n                for k, cqijk in enumerate(cqij):\n                    cq[i, j, k] = _get_char(cqijk)\n                    if k + 1 == config.max_word_size:\n                        break\n\n        return feed_dict\n\n\ndef bi_attention(config, is_train, h, u, h_mask=None, u_mask=None, scope=None, tensor_dict=None):\n    with tf.variable_scope(scope or ""bi_attention""):\n        JX = tf.shape(h)[2]\n        M = tf.shape(h)[1]\n        JQ = tf.shape(u)[1]\n        h_aug = tf.tile(tf.expand_dims(h, 3), [1, 1, 1, JQ, 1])\n        u_aug = tf.tile(tf.expand_dims(tf.expand_dims(u, 1), 1), [1, M, JX, 1, 1])\n        if h_mask is None:\n            hu_mask = None\n        else:\n            h_mask_aug = tf.tile(tf.expand_dims(h_mask, 3), [1, 1, 1, JQ])\n            u_mask_aug = tf.tile(tf.expand_dims(tf.expand_dims(u_mask, 1), 1), [1, M, JX, 1])\n            hu_mask = h_mask_aug & u_mask_aug\n\n        u_logits = get_logits([h_aug, u_aug], None, True, wd=config.wd, mask=hu_mask,\n                              is_train=is_train, func=config.logit_func, scope=\'u_logits\')  # [N, M, JX, JQ]\n        u_a = softsel(u_aug, u_logits)  # [N, M, JX, d]\n        h_a = softsel(h, tf.reduce_max(u_logits, 3))  # [N, M, d]\n        h_a = tf.tile(tf.expand_dims(h_a, 2), [1, 1, JX, 1])\n\n        if tensor_dict is not None:\n            a_u = tf.nn.softmax(u_logits)  # [N, M, JX, JQ]\n            a_h = tf.nn.softmax(tf.reduce_max(u_logits, 3))\n            tensor_dict[\'a_u\'] = a_u\n            tensor_dict[\'a_h\'] = a_h\n            variables = tf.get_collection(tf.GraphKeys.VARIABLES, scope=tf.get_variable_scope().name)\n            for var in variables:\n                tensor_dict[var.name] = var\n\n        return u_a, h_a\n\n\ndef attention_layer(config, is_train, h, u, h_mask=None, u_mask=None, scope=None, tensor_dict=None):\n    with tf.variable_scope(scope or ""attention_layer""):\n        JX = tf.shape(h)[2]\n        M = tf.shape(h)[1]\n        JQ = tf.shape(u)[1]\n        if config.q2c_att or config.c2q_att:\n            u_a, h_a = bi_attention(config, is_train, h, u, h_mask=h_mask, u_mask=u_mask, tensor_dict=tensor_dict)\n        if not config.c2q_att:\n            u_a = tf.tile(tf.expand_dims(tf.expand_dims(tf.reduce_mean(u, 1), 1), 1), [1, M, JX, 1])\n        if config.q2c_att:\n            p0 = tf.concat(3, [h, u_a, h * u_a, h * h_a])\n        else:\n            p0 = tf.concat(3, [h, u_a, h * u_a])\n        return p0\n'"
basic/read_data.py,0,"b'import json\nimport os\nimport random\nimport itertools\nimport math\nfrom collections import defaultdict\n\nimport numpy as np\n\nfrom my.tensorflow import grouper\nfrom my.utils import index\n\n\nclass Data(object):\n    def get_size(self):\n        raise NotImplementedError()\n\n    def get_by_idxs(self, idxs):\n        """"""\n        Efficient way to obtain a batch of items from filesystem\n        :param idxs:\n        :return dict: {\'X\': [,], \'Y\', }\n        """"""\n        data = defaultdict(list)\n        for idx in idxs:\n            each_data = self.get_one(idx)\n            for key, val in each_data.items():\n                data[key].append(val)\n        return data\n\n    def get_one(self, idx):\n        raise NotImplementedError()\n\n    def get_empty(self):\n        raise NotImplementedError()\n\n    def __add__(self, other):\n        raise NotImplementedError()\n\n\nclass DataSet(object):\n    def __init__(self, data, data_type, shared=None, valid_idxs=None):\n        self.data = data  # e.g. {\'X\': [0, 1, 2], \'Y\': [2, 3, 4]}\n        self.data_type = data_type\n        self.shared = shared\n        total_num_examples = self.get_data_size()\n        self.valid_idxs = range(total_num_examples) if valid_idxs is None else valid_idxs\n        self.num_examples = len(self.valid_idxs)\n\n    def _sort_key(self, idx):\n        rx = self.data[\'*x\'][idx]\n        x = self.shared[\'x\'][rx[0]][rx[1]]\n        return max(map(len, x))\n\n    def get_data_size(self):\n        if isinstance(self.data, dict):\n            return len(next(iter(self.data.values())))\n        elif isinstance(self.data, Data):\n            return self.data.get_size()\n        raise Exception()\n\n    def get_by_idxs(self, idxs):\n        if isinstance(self.data, dict):\n            out = defaultdict(list)\n            for key, val in self.data.items():\n                out[key].extend(val[idx] for idx in idxs)\n            return out\n        elif isinstance(self.data, Data):\n            return self.data.get_by_idxs(idxs)\n        raise Exception()\n\n    def get_batches(self, batch_size, num_batches=None, shuffle=False, cluster=False):\n        """"""\n\n        :param batch_size:\n        :param num_batches:\n        :param shuffle:\n        :param cluster: cluster examples by their lengths; this might give performance boost (i.e. faster training).\n        :return:\n        """"""\n        num_batches_per_epoch = int(math.ceil(self.num_examples / batch_size))\n        if num_batches is None:\n            num_batches = num_batches_per_epoch\n        num_epochs = int(math.ceil(num_batches / num_batches_per_epoch))\n\n        if shuffle:\n            random_idxs = random.sample(self.valid_idxs, len(self.valid_idxs))\n            if cluster:\n                sorted_idxs = sorted(random_idxs, key=self._sort_key)\n                sorted_grouped = lambda: list(grouper(sorted_idxs, batch_size))\n                grouped = lambda: random.sample(sorted_grouped(), num_batches_per_epoch)\n            else:\n                random_grouped = lambda: list(grouper(random_idxs, batch_size))\n                grouped = random_grouped\n        else:\n            raw_grouped = lambda: list(grouper(self.valid_idxs, batch_size))\n            grouped = raw_grouped\n\n        batch_idx_tuples = itertools.chain.from_iterable(grouped() for _ in range(num_epochs))\n        for _ in range(num_batches):\n            batch_idxs = tuple(i for i in next(batch_idx_tuples) if i is not None)\n            batch_data = self.get_by_idxs(batch_idxs)\n            shared_batch_data = {}\n            for key, val in batch_data.items():\n                if key.startswith(\'*\'):\n                    assert self.shared is not None\n                    shared_key = key[1:]\n                    shared_batch_data[shared_key] = [index(self.shared[shared_key], each) for each in val]\n            batch_data.update(shared_batch_data)\n\n            batch_ds = DataSet(batch_data, self.data_type, shared=self.shared)\n            yield batch_idxs, batch_ds\n\n    def get_multi_batches(self, batch_size, num_batches_per_step, num_steps=None, shuffle=False, cluster=False):\n        batch_size_per_step = batch_size * num_batches_per_step\n        batches = self.get_batches(batch_size_per_step, num_batches=num_steps, shuffle=shuffle, cluster=cluster)\n        multi_batches = (tuple(zip(grouper(idxs, batch_size, shorten=True, num_groups=num_batches_per_step),\n                         data_set.divide(num_batches_per_step))) for idxs, data_set in batches)\n        return multi_batches\n\n    def get_empty(self):\n        if isinstance(self.data, dict):\n            data = {key: [] for key in self.data}\n        elif isinstance(self.data, Data):\n            data = self.data.get_empty()\n        else:\n            raise Exception()\n        return DataSet(data, self.data_type, shared=self.shared)\n\n    def __add__(self, other):\n        if isinstance(self.data, dict):\n            data = {key: val + other.data[key] for key, val in self.data.items()}\n        elif isinstance(self.data, Data):\n            data = self.data + other.data\n        else:\n            raise Exception()\n\n        valid_idxs = list(self.valid_idxs) + [valid_idx + self.num_examples for valid_idx in other.valid_idxs]\n        return DataSet(data, self.data_type, shared=self.shared, valid_idxs=valid_idxs)\n\n    def divide(self, integer):\n        batch_size = int(math.ceil(self.num_examples / integer))\n        idxs_gen = grouper(self.valid_idxs, batch_size, shorten=True, num_groups=integer)\n        data_gen = (self.get_by_idxs(idxs) for idxs in idxs_gen)\n        ds_tuple = tuple(DataSet(data, self.data_type, shared=self.shared) for data in data_gen)\n        return ds_tuple\n\n\ndef load_metadata(config, data_type):\n    metadata_path = os.path.join(config.data_dir, ""metadata_{}.json"".format(data_type))\n    with open(metadata_path, \'r\') as fh:\n        metadata = json.load(fh)\n        for key, val in metadata.items():\n            config.__setattr__(key, val)\n        return metadata\n\n\ndef read_data(config, data_type, ref, data_filter=None):\n    data_path = os.path.join(config.data_dir, ""data_{}.json"".format(data_type))\n    shared_path = os.path.join(config.data_dir, ""shared_{}.json"".format(data_type))\n    with open(data_path, \'r\') as fh:\n        data = json.load(fh)\n    with open(shared_path, \'r\') as fh:\n        shared = json.load(fh)\n\n    num_examples = len(next(iter(data.values())))\n    if data_filter is None:\n        valid_idxs = range(num_examples)\n    else:\n        mask = []\n        keys = data.keys()\n        values = data.values()\n        for vals in zip(*values):\n            each = {key: val for key, val in zip(keys, vals)}\n            mask.append(data_filter(each, shared))\n        valid_idxs = [idx for idx in range(len(mask)) if mask[idx]]\n\n    print(""Loaded {}/{} examples from {}"".format(len(valid_idxs), num_examples, data_type))\n\n    shared_path = config.shared_path or os.path.join(config.out_dir, ""shared.json"")\n    if not ref:\n        word2vec_dict = shared[\'lower_word2vec\'] if config.lower_word else shared[\'word2vec\']\n        word_counter = shared[\'lower_word_counter\'] if config.lower_word else shared[\'word_counter\']\n        char_counter = shared[\'char_counter\']\n        if config.finetune:\n            shared[\'word2idx\'] = {word: idx + 2 for idx, word in\n                                  enumerate(word for word, count in word_counter.items()\n                                            if count > config.word_count_th or (config.known_if_glove and word in word2vec_dict))}\n        else:\n            assert config.known_if_glove\n            assert config.use_glove_for_unk\n            shared[\'word2idx\'] = {word: idx + 2 for idx, word in\n                                  enumerate(word for word, count in word_counter.items()\n                                            if count > config.word_count_th and word not in word2vec_dict)}\n        shared[\'char2idx\'] = {char: idx + 2 for idx, char in\n                              enumerate(char for char, count in char_counter.items()\n                                        if count > config.char_count_th)}\n        NULL = ""-NULL-""\n        UNK = ""-UNK-""\n        shared[\'word2idx\'][NULL] = 0\n        shared[\'word2idx\'][UNK] = 1\n        shared[\'char2idx\'][NULL] = 0\n        shared[\'char2idx\'][UNK] = 1\n        json.dump({\'word2idx\': shared[\'word2idx\'], \'char2idx\': shared[\'char2idx\']}, open(shared_path, \'w\'))\n    else:\n        new_shared = json.load(open(shared_path, \'r\'))\n        for key, val in new_shared.items():\n            shared[key] = val\n\n    if config.use_glove_for_unk:\n        # create new word2idx and word2vec\n        word2vec_dict = shared[\'lower_word2vec\'] if config.lower_word else shared[\'word2vec\']\n        new_word2idx_dict = {word: idx for idx, word in enumerate(word for word in word2vec_dict.keys() if word not in shared[\'word2idx\'])}\n        shared[\'new_word2idx\'] = new_word2idx_dict\n        offset = len(shared[\'word2idx\'])\n        word2vec_dict = shared[\'lower_word2vec\'] if config.lower_word else shared[\'word2vec\']\n        new_word2idx_dict = shared[\'new_word2idx\']\n        idx2vec_dict = {idx: word2vec_dict[word] for word, idx in new_word2idx_dict.items()}\n        # print(""{}/{} unique words have corresponding glove vectors."".format(len(idx2vec_dict), len(word2idx_dict)))\n        new_emb_mat = np.array([idx2vec_dict[idx] for idx in range(len(idx2vec_dict))], dtype=\'float32\')\n        shared[\'new_emb_mat\'] = new_emb_mat\n\n    data_set = DataSet(data, data_type, shared=shared, valid_idxs=valid_idxs)\n    return data_set\n\n\ndef get_squad_data_filter(config):\n    def data_filter(data_point, shared):\n        assert shared is not None\n        rx, rcx, q, cq, y = (data_point[key] for key in (\'*x\', \'*cx\', \'q\', \'cq\', \'y\'))\n        x, cx = shared[\'x\'], shared[\'cx\']\n        if len(q) > config.ques_size_th:\n            return False\n\n        # x filter\n        xi = x[rx[0]][rx[1]]\n        if config.squash:\n            for start, stop in y:\n                stop_offset = sum(map(len, xi[:stop[0]]))\n                if stop_offset + stop[1] > config.para_size_th:\n                    return False\n            return True\n\n        if config.single:\n            for start, stop in y:\n                if start[0] != stop[0]:\n                    return False\n\n        if config.data_filter == \'max\':\n            for start, stop in y:\n                    if stop[0] >= config.num_sents_th:\n                        return False\n                    if start[0] != stop[0]:\n                        return False\n                    if stop[1] >= config.sent_size_th:\n                        return False\n        elif config.data_filter == \'valid\':\n            if len(xi) > config.num_sents_th:\n                return False\n            if any(len(xij) > config.sent_size_th for xij in xi):\n                return False\n        elif config.data_filter == \'semi\':\n            """"""\n            Only answer sentence needs to be valid.\n            """"""\n            for start, stop in y:\n                if stop[0] >= config.num_sents_th:\n                    return False\n                if start[0] != start[0]:\n                    return False\n                if len(xi[start[0]]) > config.sent_size_th:\n                    return False\n        else:\n            raise Exception()\n\n        return True\n    return data_filter\n\n\ndef update_config(config, data_sets):\n    config.max_num_sents = 0\n    config.max_sent_size = 0\n    config.max_ques_size = 0\n    config.max_word_size = 0\n    config.max_para_size = 0\n    for data_set in data_sets:\n        data = data_set.data\n        shared = data_set.shared\n        for idx in data_set.valid_idxs:\n            rx = data[\'*x\'][idx]\n            q = data[\'q\'][idx]\n            sents = shared[\'x\'][rx[0]][rx[1]]\n            config.max_para_size = max(config.max_para_size, sum(map(len, sents)))\n            config.max_num_sents = max(config.max_num_sents, len(sents))\n            config.max_sent_size = max(config.max_sent_size, max(map(len, sents)))\n            config.max_word_size = max(config.max_word_size, max(len(word) for sent in sents for word in sent))\n            if len(q) > 0:\n                config.max_ques_size = max(config.max_ques_size, len(q))\n                config.max_word_size = max(config.max_word_size, max(len(word) for word in q))\n\n    if config.mode == \'train\':\n        config.max_num_sents = min(config.max_num_sents, config.num_sents_th)\n        config.max_sent_size = min(config.max_sent_size, config.sent_size_th)\n        config.max_para_size = min(config.max_para_size, config.para_size_th)\n\n    config.max_word_size = min(config.max_word_size, config.word_size_th)\n\n    config.char_vocab_size = len(data_sets[0].shared[\'char2idx\'])\n    config.word_emb_size = len(next(iter(data_sets[0].shared[\'word2vec\'].values())))\n    config.word_vocab_size = len(data_sets[0].shared[\'word2idx\'])\n\n    if config.single:\n        config.max_num_sents = 1\n    if config.squash:\n        config.max_sent_size = config.max_para_size\n        config.max_num_sents = 1\n'"
basic/trainer.py,6,"b'import tensorflow as tf\n\nfrom basic.model import Model\nfrom my.tensorflow import average_gradients\n\n\nclass Trainer(object):\n    def __init__(self, config, model):\n        assert isinstance(model, Model)\n        self.config = config\n        self.model = model\n        self.opt = tf.train.AdadeltaOptimizer(config.init_lr)\n        self.loss = model.get_loss()\n        self.var_list = model.get_var_list()\n        self.global_step = model.get_global_step()\n        self.summary = model.summary\n        self.grads = self.opt.compute_gradients(self.loss, var_list=self.var_list)\n        self.train_op = self.opt.apply_gradients(self.grads, global_step=self.global_step)\n\n    def get_train_op(self):\n        return self.train_op\n\n    def step(self, sess, batch, get_summary=False):\n        assert isinstance(sess, tf.Session)\n        _, ds = batch\n        feed_dict = self.model.get_feed_dict(ds, True)\n        if get_summary:\n            loss, summary, train_op = \\\n                sess.run([self.loss, self.summary, self.train_op], feed_dict=feed_dict)\n        else:\n            loss, train_op = sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n            summary = None\n        return loss, summary, train_op\n\n\nclass MultiGPUTrainer(object):\n    def __init__(self, config, models):\n        model = models[0]\n        assert isinstance(model, Model)\n        self.config = config\n        self.model = model\n        self.opt = tf.train.AdadeltaOptimizer(config.init_lr)\n        self.var_list = model.get_var_list()\n        self.global_step = model.get_global_step()\n        self.summary = model.summary\n        self.models = models\n        losses = []\n        grads_list = []\n        for gpu_idx, model in enumerate(models):\n            with tf.name_scope(""grads_{}"".format(gpu_idx)), tf.device(""/{}:{}"".format(config.device_type, gpu_idx)):\n                loss = model.get_loss()\n                grads = self.opt.compute_gradients(loss, var_list=self.var_list)\n                losses.append(loss)\n                grads_list.append(grads)\n\n        self.loss = tf.add_n(losses)/len(losses)\n        self.grads = average_gradients(grads_list)\n        self.train_op = self.opt.apply_gradients(self.grads, global_step=self.global_step)\n\n    def step(self, sess, batches, get_summary=False):\n        assert isinstance(sess, tf.Session)\n        feed_dict = {}\n        for batch, model in zip(batches, self.models):\n            _, ds = batch\n            feed_dict.update(model.get_feed_dict(ds, True))\n\n        if get_summary:\n            loss, summary, train_op = \\\n                sess.run([self.loss, self.summary, self.train_op], feed_dict=feed_dict)\n        else:\n            loss, train_op = sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n            summary = None\n        return loss, summary, train_op\n'"
basic/visualizer.py,0,"b'import shutil\nfrom collections import OrderedDict\nimport http.server\nimport socketserver\nimport argparse\nimport json\nimport os\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom jinja2 import Environment, FileSystemLoader\n\nfrom basic.evaluator import get_span_score_pairs\nfrom squad.utils import get_best_span, get_span_score_pairs\n\n\ndef bool_(string):\n    if string == \'True\':\n        return True\n    elif string == \'False\':\n        return False\n    else:\n        raise Exception()\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""--model_name"", type=str, default=\'basic\')\n    parser.add_argument(""--data_type"", type=str, default=\'dev\')\n    parser.add_argument(""--step"", type=int, default=5000)\n    parser.add_argument(""--template_name"", type=str, default=""visualizer.html"")\n    parser.add_argument(""--num_per_page"", type=int, default=100)\n    parser.add_argument(""--data_dir"", type=str, default=""data/squad"")\n    parser.add_argument(""--port"", type=int, default=8000)\n    parser.add_argument(""--host"", type=str, default=""0.0.0.0"")\n    parser.add_argument(""--open"", type=str, default=\'False\')\n    parser.add_argument(""--run_id"", type=str, default=""0"")\n\n    args = parser.parse_args()\n    return args\n\n\ndef _decode(decoder, sent):\n    return "" "".join(decoder[idx] for idx in sent)\n\n\ndef accuracy2_visualizer(args):\n    model_name = args.model_name\n    data_type = args.data_type\n    num_per_page = args.num_per_page\n    data_dir = args.data_dir\n    run_id = args.run_id.zfill(2)\n    step = args.step\n\n    eval_path =os.path.join(""out"", model_name, run_id, ""eval"", ""{}-{}.json"".format(data_type, str(step).zfill(6)))\n    print(""loading {}"".format(eval_path))\n    eval_ = json.load(open(eval_path, \'r\'))\n\n    _id = 0\n    html_dir = ""/tmp/list_results%d"" % _id\n    while os.path.exists(html_dir):\n        _id += 1\n        html_dir = ""/tmp/list_results%d"" % _id\n\n    if os.path.exists(html_dir):\n        shutil.rmtree(html_dir)\n    os.mkdir(html_dir)\n\n    cur_dir = os.path.dirname(os.path.realpath(__file__))\n    templates_dir = os.path.join(cur_dir, \'templates\')\n    env = Environment(loader=FileSystemLoader(templates_dir))\n    env.globals.update(zip=zip, reversed=reversed)\n    template = env.get_template(args.template_name)\n\n    data_path = os.path.join(data_dir, ""data_{}.json"".format(data_type))\n    shared_path = os.path.join(data_dir, ""shared_{}.json"".format(data_type))\n    print(""loading {}"".format(data_path))\n    data = json.load(open(data_path, \'r\'))\n    print(""loading {}"".format(shared_path))\n    shared = json.load(open(shared_path, \'r\'))\n\n    rows = []\n    for i, (idx, yi, ypi, yp2i) in tqdm(enumerate(zip(*[eval_[key] for key in (\'idxs\', \'y\', \'yp\', \'yp2\')])), total=len(eval_[\'idxs\'])):\n        id_, q, rx, answers = (data[key][idx] for key in (\'ids\', \'q\', \'*x\', \'answerss\'))\n        x = shared[\'x\'][rx[0]][rx[1]]\n        ques = ["" "".join(q)]\n        para = [[word for word in sent] for sent in x]\n        span = get_best_span(ypi, yp2i)\n        ap = get_segment(para, span)\n        score = ""{:.3f}"".format(ypi[span[0][0]][span[0][1]] * yp2i[span[1][0]][span[1][1]-1])\n\n        row = {\n            \'id\': id_,\n            \'title\': ""Hello world!"",\n            \'ques\': ques,\n            \'para\': para,\n            \'y\': yi[0][0],\n            \'y2\': yi[0][1],\n            \'yp\': ypi,\n            \'yp2\': yp2i,\n            \'a\': answers,\n            \'ap\': ap,\n            \'score\': score\n               }\n        rows.append(row)\n\n        if i % num_per_page == 0:\n            html_path = os.path.join(html_dir, ""%s.html"" % str(i).zfill(8))\n\n        if (i + 1) % num_per_page == 0 or (i + 1) == len(eval_[\'y\']):\n            var_dict = {\'title\': ""Accuracy Visualization"",\n                        \'rows\': rows\n                        }\n            with open(html_path, ""wb"") as f:\n                f.write(template.render(**var_dict).encode(\'UTF-8\'))\n            rows = []\n\n    os.chdir(html_dir)\n    port = args.port\n    host = args.host\n    # Overriding to suppress log message\n    class MyHandler(http.server.SimpleHTTPRequestHandler):\n        def log_message(self, format, *args):\n            pass\n    handler = MyHandler\n    httpd = socketserver.TCPServer((host, port), handler)\n    if args.open == \'True\':\n        os.system(""open http://%s:%d"" % (args.host, args.port))\n    print(""serving at %s:%d"" % (host, port))\n    httpd.serve_forever()\n\n\ndef get_segment(para, span):\n    return "" "".join(para[span[0][0]][span[0][1]:span[1][1]])\n\n\nif __name__ == ""__main__"":\n    ARGS = get_args()\n    accuracy2_visualizer(ARGS)'"
basic_cnn/__init__.py,0,b''
basic_cnn/cli.py,2,"b'import os\n\nimport tensorflow as tf\n\nfrom basic_cnn.main import main as m\n\nflags = tf.app.flags\n\nflags.DEFINE_string(""model_name"", ""basic_cnn"", ""Model name [basic]"")\nflags.DEFINE_string(""data_dir"", ""data/cnn"", ""Data dir [data/cnn]"")\nflags.DEFINE_string(""root_dir"", ""/Users/minjoons/data/cnn/questions"", ""root dir [~/data/cnn/questions]"")\nflags.DEFINE_string(""run_id"", ""0"", ""Run ID [0]"")\nflags.DEFINE_string(""out_base_dir"", ""out"", ""out base dir [out]"")\n\nflags.DEFINE_integer(""batch_size"", 60, ""Batch size [60]"")\nflags.DEFINE_float(""init_lr"", 0.5, ""Initial learning rate [0.5]"")\nflags.DEFINE_integer(""num_epochs"", 50, ""Total number of epochs for training [50]"")\nflags.DEFINE_integer(""num_steps"", 20000, ""Number of steps [20000]"")\nflags.DEFINE_integer(""eval_num_batches"", 100, ""eval num batches [100]"")\nflags.DEFINE_integer(""load_step"", 0, ""load step [0]"")\nflags.DEFINE_integer(""early_stop"", 4, ""early stop [4]"")\n\nflags.DEFINE_string(""mode"", ""test"", ""train | dev | test | forward [test]"")\nflags.DEFINE_boolean(""load"", True, ""load saved data? [True]"")\nflags.DEFINE_boolean(""progress"", True, ""Show progress? [True]"")\nflags.DEFINE_integer(""log_period"", 100, ""Log period [100]"")\nflags.DEFINE_integer(""eval_period"", 1000, ""Eval period [1000]"")\nflags.DEFINE_integer(""save_period"", 1000, ""Save Period [1000]"")\nflags.DEFINE_float(""decay"", 0.9, ""Exponential moving average decay [0.9]"")\n\nflags.DEFINE_boolean(""draft"", False, ""Draft for quick testing? [False]"")\n\nflags.DEFINE_integer(""hidden_size"", 100, ""Hidden size [100]"")\nflags.DEFINE_integer(""char_out_size"", 100, ""Char out size [100]"")\nflags.DEFINE_float(""input_keep_prob"", 0.8, ""Input keep prob [0.8]"")\nflags.DEFINE_integer(""char_emb_size"", 8, ""Char emb size [8]"")\nflags.DEFINE_integer(""char_filter_height"", 5, ""Char filter height [5]"")\nflags.DEFINE_float(""wd"", 0.0, ""Weight decay [0.0]"")\nflags.DEFINE_bool(""lower_word"", True, ""lower word [True]"")\nflags.DEFINE_bool(""dump_eval"", False, ""dump eval? [True]"")\nflags.DEFINE_bool(""dump_answer"", True, ""dump answer? [True]"")\nflags.DEFINE_string(""model"", ""2"", ""config 1 |2 [2]"")\nflags.DEFINE_bool(""squash"", False, ""squash the sentences into one? [False]"")\nflags.DEFINE_bool(""single"", False, ""supervise only the answer sentence? [False]"")\n\nflags.DEFINE_integer(""word_count_th"", 10, ""word count th [100]"")\nflags.DEFINE_integer(""char_count_th"", 50, ""char count th [500]"")\nflags.DEFINE_integer(""sent_size_th"", 60, ""sent size th [64]"")\nflags.DEFINE_integer(""num_sents_th"", 200, ""num sents th [8]"")\nflags.DEFINE_integer(""ques_size_th"", 30, ""ques size th [32]"")\nflags.DEFINE_integer(""word_size_th"", 16, ""word size th [16]"")\nflags.DEFINE_integer(""para_size_th"", 256, ""para size th [256]"")\n\nflags.DEFINE_bool(""swap_memory"", True, ""swap memory? [True]"")\nflags.DEFINE_string(""data_filter"", ""max"", ""max | valid | semi [max]"")\nflags.DEFINE_bool(""finetune"", False, ""finetune? [False]"")\nflags.DEFINE_bool(""feed_gt"", False, ""feed gt prev token during training [False]"")\nflags.DEFINE_bool(""feed_hard"", False, ""feed hard argmax prev token during testing [False]"")\nflags.DEFINE_bool(""use_glove_for_unk"", True, ""use glove for unk [False]"")\nflags.DEFINE_bool(""known_if_glove"", True, ""consider as known if present in glove [False]"")\nflags.DEFINE_bool(""eval"", True, ""eval? [True]"")\nflags.DEFINE_integer(""highway_num_layers"", 2, ""highway num layers [2]"")\nflags.DEFINE_bool(""use_word_emb"", True, ""use word embedding? [True]"")\n\nflags.DEFINE_string(""forward_name"", ""single"", ""Forward name [single]"")\nflags.DEFINE_string(""answer_path"", """", ""Answer path []"")\nflags.DEFINE_string(""load_path"", """", ""Load path []"")\nflags.DEFINE_string(""shared_path"", """", ""Shared path []"")\nflags.DEFINE_string(""device"", ""/cpu:0"", ""default device [/cpu:0]"")\nflags.DEFINE_integer(""num_gpus"", 1, ""num of gpus [1]"")\n\nflags.DEFINE_string(""out_channel_dims"", ""100"", ""Out channel dims, separated by commas [100]"")\nflags.DEFINE_string(""filter_heights"", ""5"", ""Filter heights, separated by commas [5]"")\n\nflags.DEFINE_bool(""share_cnn_weights"", True, ""Share CNN weights [False]"")\nflags.DEFINE_bool(""share_lstm_weights"", True, ""Share LSTM weights [True]"")\nflags.DEFINE_bool(""two_prepro_layers"", False, ""Use two layers for preprocessing? [False]"")\nflags.DEFINE_bool(""aug_att"", False, ""Augment attention layers with more features? [False]"")\nflags.DEFINE_integer(""max_to_keep"", 20, ""Max recent saves to keep [20]"")\nflags.DEFINE_bool(""vis"", False, ""output visualization numbers? [False]"")\nflags.DEFINE_bool(""dump_pickle"", True, ""Dump pickle instead of json? [True]"")\nflags.DEFINE_float(""keep_prob"", 1.0, ""keep prob [1.0]"")\nflags.DEFINE_string(""prev_mode"", ""a"", ""prev mode gy | y | a [a]"")\nflags.DEFINE_string(""logit_func"", ""tri_linear"", ""logit func [tri_linear]"")\nflags.DEFINE_bool(""sh"", False, ""use superhighway [False]"")\nflags.DEFINE_string(""answer_func"", ""linear"", ""answer logit func [linear]"")\nflags.DEFINE_bool(""cluster"", False, ""Cluster data for faster training [False]"")\nflags.DEFINE_bool(""len_opt"", False, ""Length optimization? [False]"")\nflags.DEFINE_string(""sh_logit_func"", ""tri_linear"", ""sh logit func [tri_linear]"")\nflags.DEFINE_float(""filter_ratio"", 1.0, ""filter ratio [1.0]"")\nflags.DEFINE_bool(""bi"", False, ""bi-directional attention? [False]"")\nflags.DEFINE_integer(""width"", 5, ""width around entity [5]"")\n\n\ndef main(_):\n    config = flags.FLAGS\n\n    config.out_dir = os.path.join(config.out_base_dir, config.model_name, str(config.run_id).zfill(2))\n\n    m(config)\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
basic_cnn/evaluator.py,10,"b'import itertools\nfrom collections import defaultdict\n\nimport numpy as np\nimport tensorflow as tf\nimport os\n\nfrom basic_cnn.read_data import DataSet\nfrom my.nltk_utils import span_f1\nfrom my.tensorflow import padded_reshape\nfrom my.utils import argmax\n\n\nclass Evaluation(object):\n    def __init__(self, data_type, global_step, idxs, yp, tensor_dict=None):\n        self.data_type = data_type\n        self.global_step = global_step\n        self.idxs = idxs\n        self.yp = yp\n        self.num_examples = len(yp)\n        self.tensor_dict = None\n        self.dict = {\'data_type\': data_type,\n                     \'global_step\': global_step,\n                     \'yp\': yp,\n                     \'idxs\': idxs,\n                     \'num_examples\': self.num_examples}\n        if tensor_dict is not None:\n            self.tensor_dict = {key: val.tolist() for key, val in tensor_dict.items()}\n            for key, val in self.tensor_dict.items():\n                self.dict[key] = val\n        self.summaries = None\n\n    def __repr__(self):\n        return ""{} step {}"".format(self.data_type, self.global_step)\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_yp = self.yp + other.yp\n        new_idxs = self.idxs + other.idxs\n        new_tensor_dict = None\n        if self.tensor_dict is not None:\n            new_tensor_dict = {key: val + other.tensor_dict[key] for key, val in self.tensor_dict.items()}\n        return Evaluation(self.data_type, self.global_step, new_idxs, new_yp, tensor_dict=new_tensor_dict)\n\n    def __radd__(self, other):\n        return self.__add__(other)\n\n\nclass LabeledEvaluation(Evaluation):\n    def __init__(self, data_type, global_step, idxs, yp, y, id2answer_dict, tensor_dict=None):\n        super(LabeledEvaluation, self).__init__(data_type, global_step, idxs, yp, tensor_dict=tensor_dict)\n        self.y = y\n        self.dict[\'y\'] = y\n        self.id2answer_dict = id2answer_dict\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_yp = self.yp + other.yp\n        new_y = self.y + other.y\n        new_idxs = self.idxs + other.idxs\n        new_id2answer_dict = dict(list(self.id2answer_dict.items()) + list(other.id2answer_dict.items()))\n        new_id2score_dict = dict(list(self.id2answer_dict[\'scores\'].items()) + list(other.id2answer_dict[\'scores\'].items()))\n        new_id2answer_dict[\'scores\'] = new_id2score_dict\n        if self.tensor_dict is not None:\n            new_tensor_dict = {key: np.concatenate((val, other.tensor_dict[key]), axis=0) for key, val in self.tensor_dict.items()}\n        return LabeledEvaluation(self.data_type, self.global_step, new_idxs, new_yp, new_y, new_id2answer_dict, tensor_dict=new_tensor_dict)\n\n\nclass AccuracyEvaluation(LabeledEvaluation):\n    def __init__(self, data_type, global_step, idxs, yp, y, id2answer_dict, correct, loss, tensor_dict=None):\n        super(AccuracyEvaluation, self).__init__(data_type, global_step, idxs, yp, y, id2answer_dict, tensor_dict=tensor_dict)\n        self.loss = loss\n        self.correct = correct\n        self.id2answer_dict = id2answer_dict\n        self.acc = sum(correct) / len(correct)\n        self.dict[\'loss\'] = loss\n        self.dict[\'correct\'] = correct\n        self.dict[\'acc\'] = self.acc\n        loss_summary = tf.Summary(value=[tf.Summary.Value(tag=\'{}/loss\'.format(data_type), simple_value=self.loss)])\n        acc_summary = tf.Summary(value=[tf.Summary.Value(tag=\'{}/acc\'.format(data_type), simple_value=self.acc)])\n        self.summaries = [loss_summary, acc_summary]\n\n    def __repr__(self):\n        return ""{} step {}: accuracy={}={}/{}, loss={}"".format(self.data_type, self.global_step, self.acc,\n                                                               sum(self.correct), self.num_examples, self.loss)\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_idxs = self.idxs + other.idxs\n        new_yp = self.yp + other.yp\n        new_y = self.y + other.y\n        new_correct = self.correct + other.correct\n        new_loss = (self.loss * self.num_examples + other.loss * other.num_examples) / len(new_correct)\n        new_id2answer_dict = dict(list(self.id2answer_dict.items()) + list(other.id2answer_dict.items()))\n        new_id2score_dict = dict(list(self.id2answer_dict[\'scores\'].items()) + list(other.id2answer_dict[\'scores\'].items()))\n        new_id2answer_dict[\'scores\'] = new_id2score_dict\n        new_tensor_dict = None\n        if self.tensor_dict is not None:\n            new_tensor_dict = {key: np.concatenate((val, other.tensor_dict[key]), axis=0) for key, val in self.tensor_dict.items()}\n        return AccuracyEvaluation(self.data_type, self.global_step, new_idxs, new_yp, new_y, new_id2answer_dict, new_correct, new_loss, tensor_dict=new_tensor_dict)\n\n\nclass Evaluator(object):\n    def __init__(self, config, model, tensor_dict=None):\n        self.config = config\n        self.model = model\n        self.global_step = model.global_step\n        self.yp = model.yp\n        self.tensor_dict = {} if tensor_dict is None else tensor_dict\n\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = batch\n        feed_dict = self.model.get_feed_dict(data_set, False, supervised=False)\n        global_step, yp, vals = sess.run([self.global_step, self.yp, list(self.tensor_dict.values())], feed_dict=feed_dict)\n        yp = yp[:data_set.num_examples]\n        tensor_dict = dict(zip(self.tensor_dict.keys(), vals))\n        e = Evaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), tensor_dict=tensor_dict)\n        return e\n\n    def get_evaluation_from_batches(self, sess, batches):\n        e = sum(self.get_evaluation(sess, batch) for batch in batches)\n        return e\n\n\nclass LabeledEvaluator(Evaluator):\n    def __init__(self, config, model, tensor_dict=None):\n        super(LabeledEvaluator, self).__init__(config, model, tensor_dict=tensor_dict)\n        self.y = model.y\n\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = batch\n        feed_dict = self.model.get_feed_dict(data_set, False, supervised=False)\n        global_step, yp, vals = sess.run([self.global_step, self.yp, list(self.tensor_dict.values())], feed_dict=feed_dict)\n        yp = yp[:data_set.num_examples]\n        y = feed_dict[self.y]\n        tensor_dict = dict(zip(self.tensor_dict.keys(), vals))\n        e = LabeledEvaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), y.tolist(), tensor_dict=tensor_dict)\n        return e\n\n\nclass AccuracyEvaluator(LabeledEvaluator):\n    def __init__(self, config, model, tensor_dict=None):\n        super(AccuracyEvaluator, self).__init__(config, model, tensor_dict=tensor_dict)\n        self.loss = model.loss\n\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = self._split_batch(batch)\n        assert isinstance(data_set, DataSet)\n        feed_dict = self._get_feed_dict(batch)\n        y = data_set.data[\'y\']\n        global_step, yp, loss, vals = sess.run([self.global_step, self.yp, self.loss, list(self.tensor_dict.values())], feed_dict=feed_dict)\n        yp = yp[:data_set.num_examples]\n        correct, probs, preds = zip(*[self.__class__.compare(data_set.get_one(idx), ypi) for idx, ypi in zip(data_set.valid_idxs, yp)])\n        tensor_dict = dict(zip(self.tensor_dict.keys(), vals))\n        ids = data_set.data[\'ids\']\n        id2score_dict = {id_: prob for id_, prob in zip(ids, probs)}\n        id2answer_dict = {id_: pred for id_, pred in zip(ids, preds)}\n        id2answer_dict[\'scores\'] = id2score_dict\n        e = AccuracyEvaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), y, id2answer_dict, correct, float(loss), tensor_dict=tensor_dict)\n        return e\n\n    @staticmethod\n    def compare(data, ypi):\n        prob = float(np.max(ypi))\n        yi = data[\'y\']\n        for start, stop in yi:\n            if start == int(np.argmax(ypi)):\n                return True, prob, "" ""\n        return False, prob, "" ""\n\n    def _split_batch(self, batch):\n        return batch\n\n    def _get_feed_dict(self, batch):\n        return self.model.get_feed_dict(batch[1], False)\n\n\nclass CNNAccuracyEvaluator(AccuracyEvaluator):\n    @staticmethod\n    def compare(data, ypi):\n        # ypi: [N, M, JX] numbers\n        yi = data[\'y\'][0]  # entity\n        xi = data[\'x\'][0]  # [N, M, JX] words\n        dist = defaultdict(int)\n        for ypij, xij in zip(ypi, xi):\n            for ypijk, xijk in zip(ypij, xij):\n                if xijk.startswith(""@""):\n                    dist[xijk] += ypijk\n        pred, prob = max(dist.items(), key=lambda item: item[1])\n        assert pred.startswith(""@"")\n        assert yi.startswith(""@"")\n        return pred == yi, prob, pred\n\n\nclass AccuracyEvaluator2(AccuracyEvaluator):\n    @staticmethod\n    def compare(yi, ypi):\n        for start, stop in yi:\n            para_start = int(np.argmax(np.max(ypi, 1)))\n            sent_start = int(np.argmax(ypi[para_start]))\n            if tuple(start) == (para_start, sent_start):\n                return True\n        return False\n\n\nclass ForwardEvaluation(Evaluation):\n    def __init__(self, data_type, global_step, idxs, yp, yp2, loss, id2answer_dict, tensor_dict=None):\n        super(ForwardEvaluation, self).__init__(data_type, global_step, idxs, yp, tensor_dict=tensor_dict)\n        self.yp2 = yp2\n        self.loss = loss\n        self.dict[\'loss\'] = loss\n        self.dict[\'yp2\'] = yp2\n        self.id2answer_dict = id2answer_dict\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_idxs = self.idxs + other.idxs\n        new_yp = self.yp + other.yp\n        new_yp2 = self.yp2 + other.yp2\n        new_loss = (self.loss * self.num_examples + other.loss * other.num_examples) / len(new_yp)\n        new_id2answer_dict = dict(list(self.id2answer_dict.items()) + list(other.id2answer_dict.items()))\n        if self.tensor_dict is not None:\n            new_tensor_dict = {key: np.concatenate((val, other.tensor_dict[key]), axis=0) for key, val in self.tensor_dict.items()}\n        return ForwardEvaluation(self.data_type, self.global_step, new_idxs, new_yp, new_yp2, new_loss, new_id2answer_dict, tensor_dict=new_tensor_dict)\n\n    def __repr__(self):\n        return ""{} step {}: loss={:.4f}"".format(self.data_type, self.global_step, self.loss)\n\n\nclass F1Evaluation(AccuracyEvaluation):\n    def __init__(self, data_type, global_step, idxs, yp, yp2, y, correct, loss, f1s, id2answer_dict, tensor_dict=None):\n        super(F1Evaluation, self).__init__(data_type, global_step, idxs, yp, y, correct, loss, tensor_dict=tensor_dict)\n        self.yp2 = yp2\n        self.f1s = f1s\n        self.f1 = float(np.mean(f1s))\n        self.dict[\'yp2\'] = yp2\n        self.dict[\'f1s\'] = f1s\n        self.dict[\'f1\'] = self.f1\n        self.id2answer_dict = id2answer_dict\n        f1_summary = tf.Summary(value=[tf.Summary.Value(tag=\'{}/f1\'.format(data_type), simple_value=self.f1)])\n        self.summaries.append(f1_summary)\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_idxs = self.idxs + other.idxs\n        new_yp = self.yp + other.yp\n        new_yp2 = self.yp2 + other.yp2\n        new_y = self.y + other.y\n        new_correct = self.correct + other.correct\n        new_f1s = self.f1s + other.f1s\n        new_loss = (self.loss * self.num_examples + other.loss * other.num_examples) / len(new_correct)\n        new_id2answer_dict = dict(list(self.id2answer_dict.items()) + list(other.id2answer_dict.items()))\n        return F1Evaluation(self.data_type, self.global_step, new_idxs, new_yp, new_yp2, new_y, new_correct, new_loss, new_f1s, new_id2answer_dict)\n\n    def __repr__(self):\n        return ""{} step {}: accuracy={:.4f}, f1={:.4f}, loss={:.4f}"".format(self.data_type, self.global_step, self.acc, self.f1, self.loss)\n\n\nclass F1Evaluator(LabeledEvaluator):\n    def __init__(self, config, model, tensor_dict=None):\n        super(F1Evaluator, self).__init__(config, model, tensor_dict=tensor_dict)\n        self.yp2 = model.yp2\n        self.loss = model.loss\n\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = self._split_batch(batch)\n        assert isinstance(data_set, DataSet)\n        feed_dict = self._get_feed_dict(batch)\n        global_step, yp, yp2, loss, vals = sess.run([self.global_step, self.yp, self.yp2, self.loss, list(self.tensor_dict.values())], feed_dict=feed_dict)\n        y = data_set.data[\'y\']\n        if self.config.squash:\n            new_y = []\n            for xi, yi in zip(data_set.data[\'x\'], y):\n                new_yi = []\n                for start, stop in yi:\n                    start_offset = sum(map(len, xi[:start[0]]))\n                    stop_offset = sum(map(len, xi[:stop[0]]))\n                    new_start = 0, start_offset + start[1]\n                    new_stop = 0, stop_offset + stop[1]\n                    new_yi.append((new_start, new_stop))\n                new_y.append(new_yi)\n            y = new_y\n        if self.config.single:\n            new_y = []\n            for yi in y:\n                new_yi = []\n                for start, stop in yi:\n                    new_start = 0, start[1]\n                    new_stop = 0, stop[1]\n                    new_yi.append((new_start, new_stop))\n                new_y.append(new_yi)\n            y = new_y\n\n        yp, yp2 = yp[:data_set.num_examples], yp2[:data_set.num_examples]\n        spans = [get_best_span(ypi, yp2i) for ypi, yp2i in zip(yp, yp2)]\n\n        def _get(xi, span):\n            if len(xi) <= span[0][0]:\n                return [""""]\n            if len(xi[span[0][0]]) <= span[1][1]:\n                return [""""]\n            return xi[span[0][0]][span[0][1]:span[1][1]]\n\n        id2answer_dict = {id_: "" "".join(_get(xi, span))\n                          for id_, xi, span in zip(data_set.data[\'ids\'], data_set.data[\'x\'], spans)}\n        correct = [self.__class__.compare2(yi, span) for yi, span in zip(y, spans)]\n        f1s = [self.__class__.span_f1(yi, span) for yi, span in zip(y, spans)]\n        tensor_dict = dict(zip(self.tensor_dict.keys(), vals))\n        e = F1Evaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), yp2.tolist(), y,\n                         correct, float(loss), f1s, id2answer_dict, tensor_dict=tensor_dict)\n        return e\n\n    def _split_batch(self, batch):\n        return batch\n\n    def _get_feed_dict(self, batch):\n        return self.model.get_feed_dict(batch[1], False)\n\n    @staticmethod\n    def compare(yi, ypi, yp2i):\n        for start, stop in yi:\n            aypi = argmax(ypi)\n            mask = np.zeros(yp2i.shape)\n            mask[aypi[0], aypi[1]:] = np.ones([yp2i.shape[1] - aypi[1]])\n            if tuple(start) == aypi and (stop[0], stop[1]-1) == argmax(yp2i * mask):\n                return True\n        return False\n\n    @staticmethod\n    def compare2(yi, span):\n        for start, stop in yi:\n            if tuple(start) == span[0] and tuple(stop) == span[1]:\n                return True\n        return False\n\n    @staticmethod\n    def span_f1(yi, span):\n        max_f1 = 0\n        for start, stop in yi:\n            if start[0] == span[0][0]:\n                true_span = start[1], stop[1]\n                pred_span = span[0][1], span[1][1]\n                f1 = span_f1(true_span, pred_span)\n                max_f1 = max(f1, max_f1)\n        return max_f1\n\n\nclass MultiGPUF1Evaluator(F1Evaluator):\n    def __init__(self, config, models, tensor_dict=None):\n        super(MultiGPUF1Evaluator, self).__init__(config, models[0], tensor_dict=tensor_dict)\n        self.models = models\n        with tf.name_scope(""eval_concat""):\n            N, M, JX = config.batch_size, config.max_num_sents, config.max_sent_size\n            self.yp = tf.concat(0, [padded_reshape(model.yp, [N, M, JX]) for model in models])\n            self.yp2 = tf.concat(0, [padded_reshape(model.yp2, [N, M, JX]) for model in models])\n            self.loss = tf.add_n([model.loss for model in models])/len(models)\n\n    def _split_batch(self, batches):\n        idxs_list, data_sets = zip(*batches)\n        idxs = sum(idxs_list, ())\n        data_set = sum(data_sets, data_sets[0].get_empty())\n        return idxs, data_set\n\n    def _get_feed_dict(self, batches):\n        feed_dict = {}\n        for model, (_, data_set) in zip(self.models, batches):\n            feed_dict.update(model.get_feed_dict(data_set, False))\n        return feed_dict\n\n\nclass MultiGPUCNNAccuracyEvaluator(CNNAccuracyEvaluator):\n    def __init__(self, config, models, tensor_dict=None):\n        super(MultiGPUCNNAccuracyEvaluator, self).__init__(config, models[0], tensor_dict=tensor_dict)\n        self.models = models\n        with tf.name_scope(""eval_concat""):\n            N, M, JX = config.batch_size, config.max_num_sents, config.max_sent_size\n            self.yp = tf.concat(0, [padded_reshape(model.yp, [N, M, JX]) for model in models])\n            self.loss = tf.add_n([model.loss for model in models])/len(models)\n\n    def _split_batch(self, batches):\n        idxs_list, data_sets = zip(*batches)\n        idxs = sum(idxs_list, ())\n        data_set = sum(data_sets, data_sets[0].get_empty())\n        return idxs, data_set\n\n    def _get_feed_dict(self, batches):\n        feed_dict = {}\n        for model, (_, data_set) in zip(self.models, batches):\n            feed_dict.update(model.get_feed_dict(data_set, False))\n        return feed_dict\n\n\nclass ForwardEvaluator(Evaluator):\n    def __init__(self, config, model, tensor_dict=None):\n        super(ForwardEvaluator, self).__init__(config, model, tensor_dict=tensor_dict)\n        self.yp2 = model.yp2\n        self.loss = model.loss\n\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = batch\n        assert isinstance(data_set, DataSet)\n        feed_dict = self.model.get_feed_dict(data_set, False)\n        global_step, yp, yp2, loss, vals = sess.run([self.global_step, self.yp, self.yp2, self.loss, list(self.tensor_dict.values())], feed_dict=feed_dict)\n\n        yp, yp2 = yp[:data_set.num_examples], yp2[:data_set.num_examples]\n        spans = [get_best_span(ypi, yp2i) for ypi, yp2i in zip(yp, yp2)]\n\n        def _get(xi, span):\n            if len(xi) <= span[0][0]:\n                return [""""]\n            if len(xi[span[0][0]]) <= span[1][1]:\n                return [""""]\n            return xi[span[0][0]][span[0][1]:span[1][1]]\n\n        id2answer_dict = {id_: "" "".join(_get(xi, span))\n                          for id_, xi, span in zip(data_set.data[\'ids\'], data_set.data[\'x\'], spans)}\n        tensor_dict = dict(zip(self.tensor_dict.keys(), vals))\n        e = ForwardEvaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), yp2.tolist(), float(loss), id2answer_dict, tensor_dict=tensor_dict)\n        return e\n\n    @staticmethod\n    def compare(yi, ypi, yp2i):\n        for start, stop in yi:\n            aypi = argmax(ypi)\n            mask = np.zeros(yp2i.shape)\n            mask[aypi[0], aypi[1]:] = np.ones([yp2i.shape[1] - aypi[1]])\n            if tuple(start) == aypi and (stop[0], stop[1]-1) == argmax(yp2i * mask):\n                return True\n        return False\n\n    @staticmethod\n    def compare2(yi, span):\n        for start, stop in yi:\n            if tuple(start) == span[0] and tuple(stop) == span[1]:\n                return True\n        return False\n\n    @staticmethod\n    def span_f1(yi, span):\n        max_f1 = 0\n        for start, stop in yi:\n            if start[0] == span[0][0]:\n                true_span = start[1], stop[1]\n                pred_span = span[0][1], span[1][1]\n                f1 = span_f1(true_span, pred_span)\n                max_f1 = max(f1, max_f1)\n        return max_f1\n\n\ndef get_best_span(ypi, yp2i):\n\n    max_val = 0\n    best_word_span = (0, 1)\n    best_sent_idx = 0\n    for f, (ypif, yp2if) in enumerate(zip(ypi, yp2i)):\n        argmax_j1 = 0\n        for j in range(len(ypif)):\n            val1 = ypif[argmax_j1]\n            if val1 < ypif[j]:\n                val1 = ypif[j]\n                argmax_j1 = j\n\n            val2 = yp2if[j]\n            if val1 * val2 > max_val:\n                best_word_span = (argmax_j1, j)\n                best_sent_idx = f\n                max_val = val1 * val2\n    return (best_sent_idx, best_word_span[0]), (best_sent_idx, best_word_span[1] + 1)\n\n\ndef get_span_score_pairs(ypi, yp2i):\n    span_score_pairs = []\n    for f, (ypif, yp2if) in enumerate(zip(ypi, yp2i)):\n        for j in range(len(ypif)):\n            for k in range(j, len(yp2if)):\n                span = ((f, j), (f, k+1))\n                score = ypif[j] * yp2if[k]\n                span_score_pairs.append((span, score))\n    return span_score_pairs\n'"
basic_cnn/graph_handler.py,4,"b'import gzip\nimport json\nfrom json import encoder\nimport os\n\nimport tensorflow as tf\n\nfrom basic_cnn.evaluator import Evaluation, F1Evaluation\nfrom my.utils import short_floats\n\nimport pickle\n\n\nclass GraphHandler(object):\n    def __init__(self, config):\n        self.config = config\n        self.saver = tf.train.Saver(max_to_keep=config.max_to_keep)\n        self.writer = None\n        self.save_path = os.path.join(config.save_dir, config.model_name)\n\n    def initialize(self, sess):\n        if self.config.load:\n            self._load(sess)\n        else:\n            sess.run(tf.initialize_all_variables())\n\n        if self.config.mode == \'train\':\n            self.writer = tf.train.SummaryWriter(self.config.log_dir, graph=tf.get_default_graph())\n\n    def save(self, sess, global_step=None):\n        self.saver.save(sess, self.save_path, global_step=global_step)\n\n    def _load(self, sess):\n        config = self.config\n        if config.load_path:\n            save_path = config.load_path\n        elif config.load_step > 0:\n            save_path = os.path.join(config.save_dir, ""{}-{}"".format(config.model_name, config.load_step))\n        else:\n            save_dir = config.save_dir\n            checkpoint = tf.train.get_checkpoint_state(save_dir)\n            assert checkpoint is not None, ""cannot load checkpoint at {}"".format(save_dir)\n            save_path = checkpoint.model_checkpoint_path\n        print(""Loading saved model from {}"".format(save_path))\n        self.saver.restore(sess, save_path)\n\n    def add_summary(self, summary, global_step):\n        self.writer.add_summary(summary, global_step)\n\n    def add_summaries(self, summaries, global_step):\n        for summary in summaries:\n            self.add_summary(summary, global_step)\n\n    def dump_eval(self, e, precision=2, path=None):\n        assert isinstance(e, Evaluation)\n        if self.config.dump_pickle:\n            path = path or os.path.join(self.config.eval_dir, ""{}-{}.pklz"".format(e.data_type, str(e.global_step).zfill(6)))\n            with gzip.open(path, \'wb\', compresslevel=3) as fh:\n                pickle.dump(e.dict, fh)\n        else:\n            path = path or os.path.join(self.config.eval_dir, ""{}-{}.json"".format(e.data_type, str(e.global_step).zfill(6)))\n            with open(path, \'w\') as fh:\n                json.dump(short_floats(e.dict, precision), fh)\n\n    def dump_answer(self, e, path=None):\n        assert isinstance(e, Evaluation)\n        path = path or os.path.join(self.config.answer_dir, ""{}-{}.json"".format(e.data_type, str(e.global_step).zfill(6)))\n        with open(path, \'w\') as fh:\n            json.dump(e.id2answer_dict, fh)\n\n'"
basic_cnn/main.py,4,"b'import argparse\nimport json\nimport math\nimport os\nimport shutil\nfrom pprint import pprint\n\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport numpy as np\n\nfrom basic_cnn.evaluator import F1Evaluator, Evaluator, ForwardEvaluator, MultiGPUF1Evaluator, CNNAccuracyEvaluator, \\\n    MultiGPUCNNAccuracyEvaluator\nfrom basic_cnn.graph_handler import GraphHandler\nfrom basic_cnn.model import Model, get_multi_gpu_models\nfrom basic_cnn.trainer import Trainer, MultiGPUTrainer\n\nfrom basic_cnn.read_data import read_data, get_cnn_data_filter, update_config\n\n\ndef main(config):\n    set_dirs(config)\n    with tf.device(config.device):\n        if config.mode == \'train\':\n            _train(config)\n        elif config.mode == \'test\' or config.mode == \'dev\':\n            _test(config)\n        elif config.mode == \'forward\':\n            _forward(config)\n        else:\n            raise ValueError(""invalid value for \'mode\': {}"".format(config.mode))\n\n\ndef _config_draft(config):\n    if config.draft:\n        config.num_steps = 2\n        config.eval_period = 1\n        config.log_period = 1\n        config.save_period = 1\n        config.eval_num_batches = 1\n\n\ndef _train(config):\n    # load_metadata(config, \'train\')  # this updates the config file according to metadata file\n\n    data_filter = get_cnn_data_filter(config)\n    train_data = read_data(config, \'train\', config.load, data_filter=data_filter)\n    dev_data = read_data(config, \'dev\', True, data_filter=data_filter)\n    # test_data = read_data(config, \'test\', True, data_filter=data_filter)\n    update_config(config, [train_data, dev_data])\n\n    _config_draft(config)\n\n    word2vec_dict = train_data.shared[\'lower_word2vec\'] if config.lower_word else train_data.shared[\'word2vec\']\n    word2idx_dict = train_data.shared[\'word2idx\']\n    idx2vec_dict = {word2idx_dict[word]: vec for word, vec in word2vec_dict.items() if word in word2idx_dict}\n    print(""{}/{} unique words have corresponding glove vectors."".format(len(idx2vec_dict), len(word2idx_dict)))\n    emb_mat = np.array([idx2vec_dict[idx] if idx in idx2vec_dict\n                        else np.random.multivariate_normal(np.zeros(config.word_emb_size), np.eye(config.word_emb_size))\n                        for idx in range(config.word_vocab_size)])\n    config.emb_mat = emb_mat\n\n    # construct model graph and variables (using default graph)\n    pprint(config.__flags, indent=2)\n    # model = Model(config)\n    models = get_multi_gpu_models(config)\n    model = models[0]\n    trainer = MultiGPUTrainer(config, models)\n    evaluator = MultiGPUCNNAccuracyEvaluator(config, models, tensor_dict=model.tensor_dict if config.vis else None)\n    graph_handler = GraphHandler(config)  # controls all tensors and variables in the graph, including loading /saving\n\n    # Variables\n    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n    graph_handler.initialize(sess)\n\n    # begin training\n    print(train_data.num_examples)\n    num_steps = config.num_steps or int(math.ceil(train_data.num_examples / (config.batch_size * config.num_gpus))) * config.num_epochs\n    global_step = 0\n    for batches in tqdm(train_data.get_multi_batches(config.batch_size, config.num_gpus,\n                                                     num_steps=num_steps, shuffle=True, cluster=config.cluster), total=num_steps):\n        global_step = sess.run(model.global_step) + 1  # +1 because all calculations are done after step\n        get_summary = global_step % config.log_period == 0\n        loss, summary, train_op = trainer.step(sess, batches, get_summary=get_summary)\n        if get_summary:\n            graph_handler.add_summary(summary, global_step)\n\n        # occasional saving\n        if global_step % config.save_period == 0:\n            graph_handler.save(sess, global_step=global_step)\n\n        if not config.eval:\n            continue\n        # Occasional evaluation\n        if global_step % config.eval_period == 0:\n            num_steps = math.ceil(dev_data.num_examples / (config.batch_size * config.num_gpus))\n            if 0 < config.eval_num_batches < num_steps:\n                num_steps = config.eval_num_batches\n            e_train = evaluator.get_evaluation_from_batches(\n                sess, tqdm(train_data.get_multi_batches(config.batch_size, config.num_gpus, num_steps=num_steps), total=num_steps)\n            )\n            graph_handler.add_summaries(e_train.summaries, global_step)\n            e_dev = evaluator.get_evaluation_from_batches(\n                sess, tqdm(dev_data.get_multi_batches(config.batch_size, config.num_gpus, num_steps=num_steps), total=num_steps))\n            graph_handler.add_summaries(e_dev.summaries, global_step)\n\n            if config.dump_eval:\n                graph_handler.dump_eval(e_dev)\n            if config.dump_answer:\n                graph_handler.dump_answer(e_dev)\n    if global_step % config.save_period != 0:\n        graph_handler.save(sess, global_step=global_step)\n\n\ndef _test(config):\n    assert config.load\n    test_data = read_data(config, config.mode, True)\n    update_config(config, [test_data])\n\n    _config_draft(config)\n\n    if config.use_glove_for_unk:\n        word2vec_dict = test_data.shared[\'lower_word2vec\'] if config.lower_word else test_data.shared[\'word2vec\']\n        new_word2idx_dict = test_data.shared[\'new_word2idx\']\n        idx2vec_dict = {idx: word2vec_dict[word] for word, idx in new_word2idx_dict.items()}\n        # print(""{}/{} unique words have corresponding glove vectors."".format(len(idx2vec_dict), len(word2idx_dict)))\n        new_emb_mat = np.array([idx2vec_dict[idx] for idx in range(len(idx2vec_dict))], dtype=\'float32\')\n        config.new_emb_mat = new_emb_mat\n\n    pprint(config.__flags, indent=2)\n    models = get_multi_gpu_models(config)\n    evaluator = MultiGPUCNNAccuracyEvaluator(config, models, tensor_dict=models[0].tensor_dict if config.vis else None)\n    graph_handler = GraphHandler(config)  # controls all tensors and variables in the graph, including loading /saving\n\n    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n    graph_handler.initialize(sess)\n    num_steps = math.ceil(test_data.num_examples / (config.batch_size * config.num_gpus))\n    if 0 < config.eval_num_batches < num_steps:\n        num_steps = config.eval_num_batches\n\n    e = None\n    for multi_batch in tqdm(test_data.get_multi_batches(config.batch_size, config.num_gpus, num_steps=num_steps, cluster=config.cluster), total=num_steps):\n        ei = evaluator.get_evaluation(sess, multi_batch)\n        e = ei if e is None else e + ei\n        if config.vis:\n            eval_subdir = os.path.join(config.eval_dir, ""{}-{}"".format(ei.data_type, str(ei.global_step).zfill(6)))\n            if not os.path.exists(eval_subdir):\n                os.mkdir(eval_subdir)\n            path = os.path.join(eval_subdir, str(ei.idxs[0]).zfill(8))\n            graph_handler.dump_eval(ei, path=path)\n\n    print(e)\n    if config.dump_answer:\n        print(""dumping answer ..."")\n        graph_handler.dump_answer(e)\n    if config.dump_eval:\n        print(""dumping eval ..."")\n        graph_handler.dump_eval(e)\n\n\ndef _forward(config):\n    assert config.load\n    test_data = read_data(config, config.forward_name, True)\n    update_config(config, [test_data])\n\n    _config_draft(config)\n\n    if config.use_glove_for_unk:\n        word2vec_dict = test_data.shared[\'lower_word2vec\'] if config.lower_word else test_data.shared[\'word2vec\']\n        new_word2idx_dict = test_data.shared[\'new_word2idx\']\n        idx2vec_dict = {idx: word2vec_dict[word] for word, idx in new_word2idx_dict.items()}\n        # print(""{}/{} unique words have corresponding glove vectors."".format(len(idx2vec_dict), len(word2idx_dict)))\n        new_emb_mat = np.array([idx2vec_dict[idx] for idx in range(len(idx2vec_dict))], dtype=\'float32\')\n        config.new_emb_mat = new_emb_mat\n\n    pprint(config.__flags, indent=2)\n    models = get_multi_gpu_models(config)\n    model = models[0]\n    evaluator = ForwardEvaluator(config, model)\n    graph_handler = GraphHandler(config)  # controls all tensors and variables in the graph, including loading /saving\n\n    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n    graph_handler.initialize(sess)\n\n    num_batches = math.ceil(test_data.num_examples / config.batch_size)\n    if 0 < config.eval_num_batches < num_batches:\n        num_batches = config.eval_num_batches\n    e = evaluator.get_evaluation_from_batches(sess, tqdm(test_data.get_batches(config.batch_size, num_batches=num_batches), total=num_batches))\n    print(e)\n    if config.dump_answer:\n        print(""dumping answer ..."")\n        graph_handler.dump_answer(e, path=config.answer_path)\n    if config.dump_eval:\n        print(""dumping eval ..."")\n        graph_handler.dump_eval(e)\n\n\ndef set_dirs(config):\n    # create directories\n    if not config.load and os.path.exists(config.out_dir):\n        shutil.rmtree(config.out_dir)\n\n    config.save_dir = os.path.join(config.out_dir, ""save"")\n    config.log_dir = os.path.join(config.out_dir, ""log"")\n    config.eval_dir = os.path.join(config.out_dir, ""eval"")\n    config.answer_dir = os.path.join(config.out_dir, ""answer"")\n    if not os.path.exists(config.out_dir):\n        os.makedirs(config.out_dir)\n    if not os.path.exists(config.save_dir):\n        os.mkdir(config.save_dir)\n    if not os.path.exists(config.log_dir):\n        os.mkdir(config.log_dir)\n    if not os.path.exists(config.answer_dir):\n        os.mkdir(config.answer_dir)\n    if not os.path.exists(config.eval_dir):\n        os.mkdir(config.eval_dir)\n\n\ndef _get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""config_path"")\n    return parser.parse_args()\n\n\nclass Config(object):\n    def __init__(self, **entries):\n        self.__dict__.update(entries)\n\n\ndef _run():\n    args = _get_args()\n    with open(args.config_path, \'r\') as fh:\n        config = Config(**json.load(fh))\n        main(config)\n\n\nif __name__ == ""__main__"":\n    _run()\n'"
basic_cnn/model.py,90,"b'import random\n\nimport itertools\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.ops.rnn_cell import BasicLSTMCell, GRUCell\n\nfrom basic_cnn.read_data import DataSet\nfrom basic_cnn.superhighway import SHCell\nfrom my.tensorflow import exp_mask, get_initializer, VERY_SMALL_NUMBER\nfrom my.tensorflow.nn import linear, double_linear_logits, linear_logits, softsel, dropout, get_logits, softmax, \\\n    highway_network, multi_conv1d\nfrom my.tensorflow.rnn import bidirectional_dynamic_rnn, dynamic_rnn\nfrom my.tensorflow.rnn_cell import SwitchableDropoutWrapper, AttentionCell\n\n\ndef bi_attention(config, is_train, h, u, h_mask=None, u_mask=None, scope=None, tensor_dict=None):\n    """"""\n    h_a:\n    all u attending on h\n    choosing an element of h that max-matches u\n    First creates confusion matrix between h and u\n    Then take max of the attention weights over u row\n    Finally softmax over\n\n    u_a:\n    each h attending on u\n\n    :param h: [N, M, JX, d]\n    :param u: [N, JQ, d]\n    :param h_mask:  [N, M, JX]\n    :param u_mask:  [N, B]\n    :param scope:\n    :return: [N, M, d], [N, M, JX, d]\n    """"""\n    with tf.variable_scope(scope or ""bi_attention""):\n        N, M, JX, JQ, d = config.batch_size, config.max_num_sents, config.max_sent_size, config.max_ques_size, config.hidden_size\n        JX = tf.shape(h)[2]\n        h_aug = tf.tile(tf.expand_dims(h, 3), [1, 1, 1, JQ, 1])\n        u_aug = tf.tile(tf.expand_dims(tf.expand_dims(u, 1), 1), [1, M, JX, 1, 1])\n        if h_mask is None:\n            and_mask = None\n        else:\n            h_mask_aug = tf.tile(tf.expand_dims(h_mask, 3), [1, 1, 1, JQ])\n            u_mask_aug = tf.tile(tf.expand_dims(tf.expand_dims(u_mask, 1), 1), [1, M, JX, 1])\n            and_mask = h_mask_aug & u_mask_aug\n\n        u_logits = get_logits([h_aug, u_aug], None, True, wd=config.wd, mask=and_mask,\n                              is_train=is_train, func=config.logit_func, scope=\'u_logits\')  # [N, M, JX, JQ]\n        u_a = softsel(u_aug, u_logits)  # [N, M, JX, d]\n        if tensor_dict is not None:\n            # a_h = tf.nn.softmax(h_logits)  # [N, M, JX]\n            a_u = tf.nn.softmax(u_logits)  # [N, M, JX, JQ]\n            # tensor_dict[\'a_h\'] = a_h\n            tensor_dict[\'a_u\'] = a_u\n        if config.bi:\n            h_a = softsel(h, tf.reduce_max(u_logits, 3))  # [N, M, d]\n            h_a = tf.tile(tf.expand_dims(h_a, 2), [1, 1, JX, 1])\n        else:\n            h_a = None\n        return u_a, h_a\n\n\ndef attention_layer(config, is_train, h, u, h_mask=None, u_mask=None, scope=None, tensor_dict=None):\n    with tf.variable_scope(scope or ""attention_layer""):\n        u_a, h_a = bi_attention(config, is_train, h, u, h_mask=h_mask, u_mask=u_mask, tensor_dict=tensor_dict)\n        if config.bi:\n            p0 = tf.concat(3, [h , u_a, h * u_a, h * h_a])\n        else:\n            p0 = tf.concat(3, [h , u_a, h * u_a])\n        return p0\n\n\nclass Model(object):\n    def __init__(self, config, scope):\n        self.scope = scope\n        self.config = config\n        self.global_step = tf.get_variable(\'global_step\', shape=[], dtype=\'int32\',\n                                           initializer=tf.constant_initializer(0), trainable=False)\n\n        # Define forward inputs here\n        N, M, JX, JQ, VW, VC, W = \\\n            config.batch_size, config.max_num_sents, config.max_sent_size, \\\n            config.max_ques_size, config.word_vocab_size, config.char_vocab_size, config.max_word_size\n        self.x = tf.placeholder(\'int32\', [N, M, None], name=\'x\')\n        self.cx = tf.placeholder(\'int32\', [N, M, None, W], name=\'cx\')\n        self.x_mask = tf.placeholder(\'bool\', [N, M, None], name=\'x_mask\')\n        self.q = tf.placeholder(\'int32\', [N, JQ], name=\'q\')\n        self.cq = tf.placeholder(\'int32\', [N, JQ, W], name=\'cq\')\n        self.q_mask = tf.placeholder(\'bool\', [N, JQ], name=\'q_mask\')\n        self.y = tf.placeholder(\'bool\', [N, M, JX], name=\'y\')\n        self.is_train = tf.placeholder(\'bool\', [], name=\'is_train\')\n        self.new_emb_mat = tf.placeholder(\'float\', [None, config.word_emb_size], name=\'new_emb_mat\')\n\n        # Define misc\n        self.tensor_dict = {}\n\n        # Forward outputs / loss inputs\n        self.logits = None\n        self.yp = None\n        self.var_list = None\n\n        # Loss outputs\n        self.loss = None\n\n        self._build_forward()\n        self._build_loss()\n        if config.mode == \'train\':\n            self._build_ema()\n\n        self.summary = tf.merge_all_summaries()\n        self.summary = tf.merge_summary(tf.get_collection(""summaries"", scope=self.scope))\n\n    def _build_forward(self):\n        config = self.config\n        N, M, JX, JQ, VW, VC, d, W = \\\n            config.batch_size, config.max_num_sents, config.max_sent_size, \\\n            config.max_ques_size, config.word_vocab_size, config.char_vocab_size, config.hidden_size, \\\n            config.max_word_size\n        JX = tf.shape(self.x)[2]\n        dc, dw, dco = config.char_emb_size, config.word_emb_size, config.char_out_size\n\n        with tf.variable_scope(""emb""):\n            with tf.variable_scope(""emb_var""), tf.device(""/cpu:0""):\n                char_emb_mat = tf.get_variable(""char_emb_mat"", shape=[VC, dc], dtype=\'float\')\n\n            with tf.variable_scope(""char""):\n                Acx = tf.nn.embedding_lookup(char_emb_mat, self.cx)  # [N, M, JX, W, dc]\n                Acq = tf.nn.embedding_lookup(char_emb_mat, self.cq)  # [N, JQ, W, dc]\n                Acx = tf.reshape(Acx, [-1, JX, W, dc])\n                Acq = tf.reshape(Acq, [-1, JQ, W, dc])\n\n                filter_sizes = list(map(int, config.out_channel_dims.split(\',\')))\n                heights = list(map(int, config.filter_heights.split(\',\')))\n                assert sum(filter_sizes) == dco\n                with tf.variable_scope(""conv""):\n                    xx = multi_conv1d(Acx, filter_sizes, heights, ""VALID"",  self.is_train, config.keep_prob, scope=""xx"")\n                    if config.share_cnn_weights:\n                        tf.get_variable_scope().reuse_variables()\n                        qq = multi_conv1d(Acq, filter_sizes, heights, ""VALID"", self.is_train, config.keep_prob, scope=""xx"")\n                    else:\n                        qq = multi_conv1d(Acq, filter_sizes, heights, ""VALID"", self.is_train, config.keep_prob, scope=""qq"")\n                    xx = tf.reshape(xx, [-1, M, JX, dco])\n                    qq = tf.reshape(qq, [-1, JQ, dco])\n\n            if config.use_word_emb:\n                with tf.variable_scope(""emb_var""), tf.device(""/cpu:0""):\n                    if config.mode == \'train\':\n                        word_emb_mat = tf.get_variable(""word_emb_mat"", dtype=\'float\', shape=[VW, dw], initializer=get_initializer(config.emb_mat))\n                    else:\n                        word_emb_mat = tf.get_variable(""word_emb_mat"", shape=[VW, dw], dtype=\'float\')\n                    if config.use_glove_for_unk:\n                        word_emb_mat = tf.concat(0, [word_emb_mat, self.new_emb_mat])\n\n                with tf.name_scope(""word""):\n                    Ax = tf.nn.embedding_lookup(word_emb_mat, self.x)  # [N, M, JX, d]\n                    Aq = tf.nn.embedding_lookup(word_emb_mat, self.q)  # [N, JQ, d]\n                    self.tensor_dict[\'x\'] = Ax\n                    self.tensor_dict[\'q\'] = Aq\n                xx = tf.concat(3, [xx, Ax])  # [N, M, JX, di]\n                qq = tf.concat(2, [qq, Aq])  # [N, JQ, di]\n\n        # highway network\n        with tf.variable_scope(""highway""):\n            xx = highway_network(xx, config.highway_num_layers, True, wd=config.wd, is_train=self.is_train)\n            tf.get_variable_scope().reuse_variables()\n            qq = highway_network(qq, config.highway_num_layers, True, wd=config.wd, is_train=self.is_train)\n            self.tensor_dict[\'xx\'] = xx\n            self.tensor_dict[\'qq\'] = qq\n\n        cell = BasicLSTMCell(d, state_is_tuple=True)\n        d_cell = SwitchableDropoutWrapper(cell, self.is_train, input_keep_prob=config.input_keep_prob)\n        x_len = tf.reduce_sum(tf.cast(self.x_mask, \'int32\'), 2)  # [N, M]\n        q_len = tf.reduce_sum(tf.cast(self.q_mask, \'int32\'), 1)  # [N]\n\n        with tf.variable_scope(""prepro""):\n            (fw_u, bw_u), ((_, fw_u_f), (_, bw_u_f)) = bidirectional_dynamic_rnn(d_cell, d_cell, qq, q_len, dtype=\'float\', scope=\'u1\')  # [N, J, d], [N, d]\n            u = tf.concat(2, [fw_u, bw_u])\n            if config.two_prepro_layers:\n                (fw_u, bw_u), ((_, fw_u_f), (_, bw_u_f)) = bidirectional_dynamic_rnn(d_cell, d_cell, u, q_len, dtype=\'float\', scope=\'u2\')  # [N, J, d], [N, d]\n                u = tf.concat(2, [fw_u, bw_u])\n            if config.share_lstm_weights:\n                tf.get_variable_scope().reuse_variables()\n                (fw_h, bw_h), _ = bidirectional_dynamic_rnn(cell, cell, xx, x_len, dtype=\'float\', scope=\'u1\')  # [N, M, JX, 2d]\n                h = tf.concat(3, [fw_h, bw_h])  # [N, M, JX, 2d]\n                if config.two_prepro_layers:\n                    (fw_h, bw_h), _ = bidirectional_dynamic_rnn(cell, cell, h, x_len, dtype=\'float\', scope=\'u2\')  # [N, M, JX, 2d]\n                    h = tf.concat(3, [fw_h, bw_h])  # [N, M, JX, 2d]\n\n            else:\n                (fw_h, bw_h), _ = bidirectional_dynamic_rnn(cell, cell, xx, x_len, dtype=\'float\', scope=\'h1\')  # [N, M, JX, 2d]\n                h = tf.concat(3, [fw_h, bw_h])  # [N, M, JX, 2d]\n                if config.two_prepro_layers:\n                    (fw_h, bw_h), _ = bidirectional_dynamic_rnn(cell, cell, h, x_len, dtype=\'float\', scope=\'h2\')  # [N, M, JX, 2d]\n                    h = tf.concat(3, [fw_h, bw_h])  # [N, M, JX, 2d]\n            self.tensor_dict[\'u\'] = u\n            self.tensor_dict[\'h\'] = h\n\n        with tf.variable_scope(""main""):\n            p0 = attention_layer(config, self.is_train, h, u, h_mask=self.x_mask, u_mask=self.q_mask, scope=""p0"", tensor_dict=self.tensor_dict)\n            (fw_g0, bw_g0), _ = bidirectional_dynamic_rnn(d_cell, d_cell, p0, x_len, dtype=\'float\', scope=\'g0\')  # [N, M, JX, 2d]\n            g0 = tf.concat(3, [fw_g0, bw_g0])\n            # p1 = attention_layer(config, self.is_train, g0, u, h_mask=self.x_mask, u_mask=self.q_mask, scope=""p1"")\n            (fw_g1, bw_g1), _ = bidirectional_dynamic_rnn(d_cell, d_cell, g0, x_len, dtype=\'float\', scope=\'g1\')  # [N, M, JX, 2d]\n            g1 = tf.concat(3, [fw_g1, bw_g1])\n            # logits = u_logits(config, self.is_train, g1, u, h_mask=self.x_mask, u_mask=self.q_mask, scope=""logits"")\n            # [N, M, JX]\n            logits = get_logits([g1, p0], d, True, wd=config.wd, input_keep_prob=config.input_keep_prob, mask=self.x_mask, is_train=self.is_train, func=config.answer_func, scope=\'logits1\')\n            a1i = softsel(tf.reshape(g1, [N, M*JX, 2*d]), tf.reshape(logits, [N, M*JX]))\n\n            if config.feed_gt:\n                logy = tf.log(tf.cast(self.y, \'float\') + VERY_SMALL_NUMBER)\n                logits = tf.cond(self.is_train, lambda: logy, lambda: logits)\n            if config.feed_hard:\n                hard_yp = tf.argmax(tf.reshape(logits, [N, M*JX]), 1)\n                hard_logits = tf.reshape(tf.one_hot(hard_yp, M*JX), [N, M, JX])  # [N, M, JX]\n                logits = tf.cond(self.is_train, lambda: logits, lambda: hard_logits)\n\n            flat_logits = tf.reshape(logits, [-1, M * JX])\n            flat_yp = tf.nn.softmax(flat_logits)  # [-1, M*JX]\n            yp = tf.reshape(flat_yp, [-1, M, JX])\n\n            self.tensor_dict[\'g1\'] = g1\n\n            self.logits = flat_logits\n            self.yp = yp\n\n    def _build_loss(self):\n        config = self.config\n        N, M, JX, JQ, VW, VC = \\\n            config.batch_size, config.max_num_sents, config.max_sent_size, \\\n            config.max_ques_size, config.word_vocab_size, config.char_vocab_size\n        JX = tf.shape(self.x)[2]\n        loss_mask = tf.reduce_max(tf.cast(self.q_mask, \'float\'), 1)\n        losses = -tf.log(tf.reduce_sum(self.yp * tf.cast(self.y, \'float\'), [1, 2]) + VERY_SMALL_NUMBER)\n        ce_loss = tf.reduce_mean(loss_mask * losses)\n        tf.add_to_collection(\'losses\', ce_loss)\n\n        self.loss = tf.add_n(tf.get_collection(\'losses\', scope=self.scope), name=\'loss\')\n        tf.scalar_summary(self.loss.op.name, self.loss)\n        tf.add_to_collection(\'ema/scalar\', self.loss)\n\n    def _build_ema(self):\n        ema = tf.train.ExponentialMovingAverage(self.config.decay)\n        ema_op = ema.apply(tf.get_collection(""ema/scalar"", scope=self.scope) + tf.get_collection(""ema/histogram"", scope=self.scope))\n        for var in tf.get_collection(""ema/scalar"", scope=self.scope):\n            ema_var = ema.average(var)\n            tf.scalar_summary(ema_var.op.name, ema_var)\n        for var in tf.get_collection(""ema/histogram"", scope=self.scope):\n            ema_var = ema.average(var)\n            tf.histogram_summary(ema_var.op.name, ema_var)\n\n        with tf.control_dependencies([ema_op]):\n            self.loss = tf.identity(self.loss)\n\n    def get_loss(self):\n        return self.loss\n\n    def get_global_step(self):\n        return self.global_step\n\n    def get_var_list(self):\n        return self.var_list\n\n    def get_feed_dict(self, batch, is_train, supervised=True):\n        assert isinstance(batch, DataSet)\n        config = self.config\n        N, M, JX, JQ, VW, VC, d, W = \\\n            config.batch_size, config.max_num_sents, config.max_sent_size, \\\n            config.max_ques_size, config.word_vocab_size, config.char_vocab_size, config.hidden_size, config.max_word_size\n        feed_dict = {}\n\n        if config.len_opt:\n            """"""\n            Note that this optimization results in variable GPU RAM usage (i.e. can cause OOM in the middle of training.)\n            First test without len_opt and make sure no OOM, and use len_opt\n            """"""\n            if sum(len(para) for para in batch.data[\'x\']) == 0:\n                new_JX = 1\n            else:\n                new_JX = max(len(para) for para in batch.data[\'x\'])\n            JX = min(JX, new_JX)\n        # print(JX)\n\n        x = np.zeros([N, M, JX], dtype=\'int32\')\n        cx = np.zeros([N, M, JX, W], dtype=\'int32\')\n        x_mask = np.zeros([N, M, JX], dtype=\'bool\')\n        q = np.zeros([N, JQ], dtype=\'int32\')\n        cq = np.zeros([N, JQ, W], dtype=\'int32\')\n        q_mask = np.zeros([N, JQ], dtype=\'bool\')\n\n        feed_dict[self.x] = x\n        feed_dict[self.x_mask] = x_mask\n        feed_dict[self.cx] = cx\n        feed_dict[self.q] = q\n        feed_dict[self.cq] = cq\n        feed_dict[self.q_mask] = q_mask\n        feed_dict[self.is_train] = is_train\n        if config.use_glove_for_unk:\n            feed_dict[self.new_emb_mat] = batch.shared[\'new_emb_mat\']\n\n        X = batch.data[\'x\']\n        CX = batch.data[\'cx\']\n\n        def _get_word(word):\n            if word.startswith(""@""):\n                return 2\n            d = batch.shared[\'word2idx\']\n            for each in (word, word.lower(), word.capitalize(), word.upper()):\n                if each in d:\n                    return d[each]\n            if config.use_glove_for_unk:\n                d2 = batch.shared[\'new_word2idx\']\n                for each in (word, word.lower(), word.capitalize(), word.upper()):\n                    if each in d2:\n                        return d2[each] + len(d)\n            return 1\n\n        def _get_char(char):\n            d = batch.shared[\'char2idx\']\n            if char in d:\n                return d[char]\n            return 1\n\n        if supervised:\n            y = np.zeros([N, M, JX], dtype=\'int32\')\n            feed_dict[self.y] = y\n\n            for i, (xi, yi) in enumerate(zip(batch.data[\'x\'], batch.data[\'y\'])):\n                count = 0\n                for j, xij in enumerate(xi):\n                    for k, xijk in enumerate(xij):\n                        if xijk == yi:\n                            y[i, j, k] = True\n                            count += 1\n                assert count > 0\n\n        for i, xi in enumerate(X):\n            for j, xij in enumerate(xi):\n                for k, xijk in enumerate(xij):\n                    each = _get_word(xijk)\n                    x[i, j, k] = each\n                    x_mask[i, j, k] = True\n\n        for i, cxi in enumerate(CX):\n            for j, cxij in enumerate(cxi):\n                for k, cxijk in enumerate(cxij):\n                    for l, cxijkl in enumerate(cxijk):\n                        cx[i, j, k, l] = _get_char(cxijkl)\n                        if l + 1 == config.max_word_size:\n                            break\n\n        for i, qi in enumerate(batch.data[\'q\']):\n            for j, qij in enumerate(qi):\n                q[i, j] = _get_word(qij)\n                q_mask[i, j] = True\n\n        for i, cqi in enumerate(batch.data[\'cq\']):\n            for j, cqij in enumerate(cqi):\n                for k, cqijk in enumerate(cqij):\n                    cq[i, j, k] = _get_char(cqijk)\n                    if k + 1 == config.max_word_size:\n                        break\n\n        return feed_dict\n\n\ndef get_multi_gpu_models(config):\n    models = []\n    for gpu_idx in range(config.num_gpus):\n        with tf.name_scope(""model_{}"".format(gpu_idx)) as scope, tf.device(""/gpu:{}"".format(gpu_idx)):\n            model = Model(config, scope)\n            tf.get_variable_scope().reuse_variables()\n            models.append(model)\n    return models\n'"
basic_cnn/read_data.py,0,"b'import json\nimport os\nimport random\nimport itertools\nimport math\nfrom collections import defaultdict\n\nimport numpy as np\n\nfrom cnn_dm.prepro import para2sents\nfrom my.tensorflow import grouper\nfrom my.utils import index\n\n\nclass Data(object):\n    def get_size(self):\n        raise NotImplementedError()\n\n    def get_by_idxs(self, idxs):\n        """"""\n        Efficient way to obtain a batch of items from filesystem\n        :param idxs:\n        :return dict: {\'X\': [,], \'Y\', }\n        """"""\n        data = defaultdict(list)\n        for idx in idxs:\n            each_data = self.get_one(idx)\n            for key, val in each_data.items():\n                data[key].append(val)\n        return data\n\n    def get_one(self, idx):\n        raise NotImplementedError()\n\n    def get_empty(self):\n        raise NotImplementedError()\n\n    def __add__(self, other):\n        raise NotImplementedError()\n\nclass MyData(Data):\n    def __init__(self, config, root_dir, file_names):\n        self.root_dir = root_dir\n        self.file_names = file_names\n        self.config = config\n\n    def get_one(self, idx):\n        file_name = self.file_names[idx]\n        with open(os.path.join(self.root_dir, file_name), \'r\') as fh:\n            url = fh.readline().strip()\n            _ = fh.readline()\n            para = fh.readline().strip()\n            _ = fh.readline()\n            ques = fh.readline().strip()\n            _ = fh.readline()\n            answer = fh.readline().strip()\n            _ = fh.readline()\n            cands = list(line.strip() for line in fh)\n            cand_ents = list(cand.split("":"")[0] for cand in cands)\n            wordss = para2sents(para, self.config.width)\n            ques_words = ques.split("" "")\n\n            x = wordss\n            cx = [[list(word) for word in words] for words in wordss]\n            q = ques_words\n            cq = [list(word) for word in ques_words]\n            y = answer\n            c = cand_ents\n\n            data = {\'x\': x, \'cx\': cx, \'q\': q, \'cq\': cq, \'y\': y, \'c\': c, \'ids\': file_name}\n            return data\n\n    def get_empty(self):\n        return MyData(self.config, self.root_dir, [])\n\n    def __add__(self, other):\n        file_names = self.file_names + other.file_names\n        return MyData(self.config, self.root_dir, file_names)\n\n    def get_size(self):\n        return len(self.file_names)\n\n\nclass DataSet(object):\n    def __init__(self, data, data_type, shared=None, valid_idxs=None):\n        self.data = data  # e.g. {\'X\': [0, 1, 2], \'Y\': [2, 3, 4]}\n        self.data_type = data_type\n        self.shared = shared\n        total_num_examples = self.get_data_size()\n        self.valid_idxs = range(total_num_examples) if valid_idxs is None else valid_idxs\n        self.num_examples = total_num_examples\n\n    def _sort_key(self, idx):\n        rx = self.data[\'*x\'][idx]\n        x = self.shared[\'x\'][rx[0]][rx[1]]\n        return max(map(len, x))\n\n    def get_data_size(self):\n        if isinstance(self.data, dict):\n            return len(next(iter(self.data.values())))\n        elif isinstance(self.data, Data):\n            return self.data.get_size()\n        raise Exception()\n\n    def get_by_idxs(self, idxs):\n        if isinstance(self.data, dict):\n            out = defaultdict(list)\n            for key, val in self.data.items():\n                out[key].extend(val[idx] for idx in idxs)\n            return out\n        elif isinstance(self.data, Data):\n            return self.data.get_by_idxs(idxs)\n        raise Exception()\n\n    def get_one(self, idx):\n        if isinstance(self.data, dict):\n            out = {key: [val[idx]] for key, val in self.data.items()}\n            return out\n        elif isinstance(self.data, Data):\n            return self.data.get_one(idx)\n\n    def get_batches(self, batch_size, num_batches=None, shuffle=False, cluster=False):\n        """"""\n\n        :param batch_size:\n        :param num_batches:\n        :param shuffle:\n        :param cluster: cluster examples by their lengths; this might give performance boost (i.e. faster training).\n        :return:\n        """"""\n        num_batches_per_epoch = int(math.ceil(self.num_examples / batch_size))\n        if num_batches is None:\n            num_batches = num_batches_per_epoch\n        num_epochs = int(math.ceil(num_batches / num_batches_per_epoch))\n\n        if shuffle:\n            random_idxs = random.sample(self.valid_idxs, len(self.valid_idxs))\n            if cluster:\n                sorted_idxs = sorted(random_idxs, key=self._sort_key)\n                sorted_grouped = lambda: list(grouper(sorted_idxs, batch_size))\n                grouped = lambda: random.sample(sorted_grouped(), num_batches_per_epoch)\n            else:\n                random_grouped = lambda: list(grouper(random_idxs, batch_size))\n                grouped = random_grouped\n        else:\n            raw_grouped = lambda: list(grouper(self.valid_idxs, batch_size))\n            grouped = raw_grouped\n\n        batch_idx_tuples = itertools.chain.from_iterable(grouped() for _ in range(num_epochs))\n        for _ in range(num_batches):\n            batch_idxs = tuple(i for i in next(batch_idx_tuples) if i is not None)\n            batch_data = self.get_by_idxs(batch_idxs)\n            shared_batch_data = {}\n            for key, val in batch_data.items():\n                if key.startswith(\'*\'):\n                    assert self.shared is not None\n                    shared_key = key[1:]\n                    shared_batch_data[shared_key] = [index(self.shared[shared_key], each) for each in val]\n            batch_data.update(shared_batch_data)\n\n            batch_ds = DataSet(batch_data, self.data_type, shared=self.shared)\n            yield batch_idxs, batch_ds\n\n    def get_multi_batches(self, batch_size, num_batches_per_step, num_steps=None, shuffle=False, cluster=False):\n        batch_size_per_step = batch_size * num_batches_per_step\n        batches = self.get_batches(batch_size_per_step, num_batches=num_steps, shuffle=shuffle, cluster=cluster)\n        multi_batches = (tuple(zip(grouper(idxs, batch_size, shorten=True, num_groups=num_batches_per_step),\n                         data_set.divide(num_batches_per_step))) for idxs, data_set in batches)\n        return multi_batches\n\n    def get_empty(self):\n        if isinstance(self.data, dict):\n            data = {key: [] for key in self.data}\n        elif isinstance(self.data, Data):\n            data = self.data.get_empty()\n        else:\n            raise Exception()\n        return DataSet(data, self.data_type, shared=self.shared)\n\n    def __add__(self, other):\n        if isinstance(self.data, dict):\n            data = {key: val + other.data[key] for key, val in self.data.items()}\n        elif isinstance(self.data, Data):\n            data = self.data + other.data\n        else:\n            raise Exception()\n\n        valid_idxs = list(self.valid_idxs) + [valid_idx + self.num_examples for valid_idx in other.valid_idxs]\n        return DataSet(data, self.data_type, shared=self.shared, valid_idxs=valid_idxs)\n\n    def divide(self, integer):\n        batch_size = int(math.ceil(self.num_examples / integer))\n        idxs_gen = grouper(self.valid_idxs, batch_size, shorten=True, num_groups=integer)\n        data_gen = (self.get_by_idxs(idxs) for idxs in idxs_gen)\n        ds_tuple = tuple(DataSet(data, self.data_type, shared=self.shared) for data in data_gen)\n        return ds_tuple\n\n\nclass MyDataSet(DataSet):\n    def __init__(self, data, data_type, shared=None, valid_idxs=None):\n        super(MyDataSet, self).__init__(data, data_type, shared=shared, valid_idxs=valid_idxs)\n        shared[\'max_num_sents\'] = len(self.get_one(self.num_examples-1)[\'x\'])\n\n    def _sort_key(self, idx):\n        return idx\n\n\ndef read_data(config, data_type, ref, data_filter=None):\n    shared_path = os.path.join(config.data_dir, ""shared_{}.json"".format(data_type))\n    with open(shared_path, \'r\') as fh:\n        shared = json.load(fh)\n\n    paths = shared[\'sorted\']\n    if config.filter_ratio < 1.0:\n        stop = int(round(len(paths) * config.filter_ratio))\n        paths = paths[:stop]\n    num_examples = len(paths)\n    valid_idxs = range(num_examples)\n\n    print(""Loaded {}/{} examples from {}"".format(len(valid_idxs), num_examples, data_type))\n\n    shared_path = config.shared_path or os.path.join(config.out_dir, ""shared.json"")\n    if not ref:\n        word2vec_dict = shared[\'lower_word2vec\'] if config.lower_word else shared[\'word2vec\']\n        word_counter = shared[\'lower_word_counter\'] if config.lower_word else shared[\'word_counter\']\n        char_counter = shared[\'char_counter\']\n        if config.finetune:\n            shared[\'word2idx\'] = {word: idx + 3 for idx, word in\n                                  enumerate(word for word, count in word_counter.items()\n                                            if count > config.word_count_th or (config.known_if_glove and word in word2vec_dict))}\n        else:\n            assert config.known_if_glove\n            assert config.use_glove_for_unk\n            shared[\'word2idx\'] = {word: idx + 3 for idx, word in\n                                  enumerate(word for word, count in word_counter.items()\n                                            if count > config.word_count_th and word not in word2vec_dict)}\n        shared[\'char2idx\'] = {char: idx + 2 for idx, char in\n                              enumerate(char for char, count in char_counter.items()\n                                        if count > config.char_count_th)}\n        NULL = ""-NULL-""\n        UNK = ""-UNK-""\n        ENT = ""-ENT-""\n        shared[\'word2idx\'][NULL] = 0\n        shared[\'word2idx\'][UNK] = 1\n        shared[\'word2idx\'][ENT] = 2\n        shared[\'char2idx\'][NULL] = 0\n        shared[\'char2idx\'][UNK] = 1\n\n        json.dump({\'word2idx\': shared[\'word2idx\'], \'char2idx\': shared[\'char2idx\']}, open(shared_path, \'w\'))\n    else:\n        new_shared = json.load(open(shared_path, \'r\'))\n        for key, val in new_shared.items():\n            shared[key] = val\n\n    if config.use_glove_for_unk:\n        # create new word2idx and word2vec\n        word2vec_dict = shared[\'lower_word2vec\'] if config.lower_word else shared[\'word2vec\']\n        new_word2idx_dict = {word: idx for idx, word in enumerate(word for word in word2vec_dict.keys() if word not in shared[\'word2idx\'])}\n        shared[\'new_word2idx\'] = new_word2idx_dict\n        offset = len(shared[\'word2idx\'])\n        word2vec_dict = shared[\'lower_word2vec\'] if config.lower_word else shared[\'word2vec\']\n        new_word2idx_dict = shared[\'new_word2idx\']\n        idx2vec_dict = {idx: word2vec_dict[word] for word, idx in new_word2idx_dict.items()}\n        # print(""{}/{} unique words have corresponding glove vectors."".format(len(idx2vec_dict), len(word2idx_dict)))\n        new_emb_mat = np.array([idx2vec_dict[idx] for idx in range(len(idx2vec_dict))], dtype=\'float32\')\n        shared[\'new_emb_mat\'] = new_emb_mat\n\n    data = MyData(config, os.path.join(config.root_dir, data_type), paths)\n    data_set = MyDataSet(data, data_type, shared=shared, valid_idxs=valid_idxs)\n    return data_set\n\n\ndef get_cnn_data_filter(config):\n    return True\n\n\ndef update_config(config, data_sets):\n    config.max_num_sents = 0\n    config.max_sent_size = 0\n    config.max_ques_size = 0\n    config.max_word_size = 0\n    for data_set in data_sets:\n        shared = data_set.shared\n        config.max_sent_size = max(config.max_sent_size, shared[\'max_sent_size\'])\n        config.max_ques_size = max(config.max_ques_size, shared[\'max_ques_size\'])\n        config.max_word_size = max(config.max_word_size, shared[\'max_word_size\'])\n        config.max_num_sents = max(config.max_num_sents, shared[\'max_num_sents\'])\n\n    config.max_word_size = min(config.max_word_size, config.word_size_th)\n\n    config.char_vocab_size = len(data_sets[0].shared[\'char2idx\'])\n    config.word_emb_size = len(next(iter(data_sets[0].shared[\'word2vec\'].values())))\n    config.word_vocab_size = len(data_sets[0].shared[\'word2idx\'])\n\n'"
basic_cnn/superhighway.py,6,"b'import tensorflow as tf\nfrom tensorflow.python.ops.rnn_cell import RNNCell\n\nfrom my.tensorflow.nn import linear\n\n\nclass SHCell(RNNCell):\n    """"""\n    Super-Highway Cell\n    """"""\n    def __init__(self, input_size, logit_func=\'tri_linear\', scalar=False):\n        self._state_size = input_size\n        self._output_size = input_size\n        self._logit_func = logit_func\n        self._scalar = scalar\n\n    @property\n    def state_size(self):\n        return self._state_size\n\n    @property\n    def output_size(self):\n        return self._output_size\n\n    def __call__(self, inputs, state, scope=None):\n        with tf.variable_scope(scope or ""SHCell""):\n            a_size = 1 if self._scalar else self._state_size\n            h, u = tf.split(1, 2, inputs)\n            if self._logit_func == \'mul_linear\':\n                args = [h * u, state * u]\n                a = tf.nn.sigmoid(linear(args, a_size, True))\n            elif self._logit_func == \'linear\':\n                args = [h, u, state]\n                a = tf.nn.sigmoid(linear(args, a_size, True))\n            elif self._logit_func == \'tri_linear\':\n                args = [h, u, state, h * u, state * u]\n                a = tf.nn.sigmoid(linear(args, a_size, True))\n            elif self._logit_func == \'double\':\n                args = [h, u, state]\n                a = tf.nn.sigmoid(linear(tf.tanh(linear(args, a_size, True)), self._state_size, True))\n\n            else:\n                raise Exception()\n            new_state = a * state + (1 - a) * h\n            outputs = state\n            return outputs, new_state\n\n'"
basic_cnn/trainer.py,6,"b'import tensorflow as tf\n\nfrom basic_cnn.model import Model\nfrom my.tensorflow import average_gradients\n\n\nclass Trainer(object):\n    def __init__(self, config, model):\n        assert isinstance(model, Model)\n        self.config = config\n        self.model = model\n        self.opt = tf.train.AdadeltaOptimizer(config.init_lr)\n        self.loss = model.get_loss()\n        self.var_list = model.get_var_list()\n        self.global_step = model.get_global_step()\n        self.summary = model.summary\n        self.grads = self.opt.compute_gradients(self.loss, var_list=self.var_list)\n        self.train_op = self.opt.apply_gradients(self.grads, global_step=self.global_step)\n\n    def get_train_op(self):\n        return self.train_op\n\n    def step(self, sess, batch, get_summary=False):\n        assert isinstance(sess, tf.Session)\n        _, ds = batch\n        feed_dict = self.model.get_feed_dict(ds, True)\n        if get_summary:\n            loss, summary, train_op = \\\n                sess.run([self.loss, self.summary, self.train_op], feed_dict=feed_dict)\n        else:\n            loss, train_op = sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n            summary = None\n        return loss, summary, train_op\n\n\nclass MultiGPUTrainer(object):\n    def __init__(self, config, models):\n        model = models[0]\n        assert isinstance(model, Model)\n        self.config = config\n        self.model = model\n        self.opt = tf.train.AdadeltaOptimizer(config.init_lr)\n        self.var_list = model.get_var_list()\n        self.global_step = model.get_global_step()\n        self.summary = model.summary\n        self.models = models\n        losses = []\n        grads_list = []\n        for gpu_idx, model in enumerate(models):\n            with tf.name_scope(""grads_{}"".format(gpu_idx)), tf.device(""/gpu:{}"".format(gpu_idx)):\n                loss = model.get_loss()\n                grads = self.opt.compute_gradients(loss, var_list=self.var_list)\n                losses.append(loss)\n                grads_list.append(grads)\n\n        self.loss = tf.add_n(losses)/len(losses)\n        self.grads = average_gradients(grads_list)\n        self.train_op = self.opt.apply_gradients(self.grads, global_step=self.global_step)\n\n    def step(self, sess, batches, get_summary=False):\n        assert isinstance(sess, tf.Session)\n        feed_dict = {}\n        for batch, model in zip(batches, self.models):\n            _, ds = batch\n            feed_dict.update(model.get_feed_dict(ds, True))\n\n        if get_summary:\n            loss, summary, train_op = \\\n                sess.run([self.loss, self.summary, self.train_op], feed_dict=feed_dict)\n        else:\n            loss, train_op = sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n            summary = None\n        return loss, summary, train_op\n'"
basic_cnn/visualizer.py,0,"b'import shutil\nfrom collections import OrderedDict\nimport http.server\nimport socketserver\nimport argparse\nimport json\nimport os\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom jinja2 import Environment, FileSystemLoader\n\nfrom basic_cnn.evaluator import get_span_score_pairs, get_best_span\n\n\ndef bool_(string):\n    if string == \'True\':\n        return True\n    elif string == \'False\':\n        return False\n    else:\n        raise Exception()\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""--model_name"", type=str, default=\'basic\')\n    parser.add_argument(""--data_type"", type=str, default=\'dev\')\n    parser.add_argument(""--step"", type=int, default=5000)\n    parser.add_argument(""--template_name"", type=str, default=""visualizer.html"")\n    parser.add_argument(""--num_per_page"", type=int, default=100)\n    parser.add_argument(""--data_dir"", type=str, default=""data/squad"")\n    parser.add_argument(""--port"", type=int, default=8000)\n    parser.add_argument(""--host"", type=str, default=""0.0.0.0"")\n    parser.add_argument(""--open"", type=str, default=\'False\')\n    parser.add_argument(""--run_id"", type=str, default=""0"")\n\n    args = parser.parse_args()\n    return args\n\n\ndef _decode(decoder, sent):\n    return "" "".join(decoder[idx] for idx in sent)\n\n\ndef accuracy2_visualizer(args):\n    model_name = args.model_name\n    data_type = args.data_type\n    num_per_page = args.num_per_page\n    data_dir = args.data_dir\n    run_id = args.run_id.zfill(2)\n    step = args.step\n\n    eval_path =os.path.join(""out"", model_name, run_id, ""eval"", ""{}-{}.json"".format(data_type, str(step).zfill(6)))\n    print(""loading {}"".format(eval_path))\n    eval_ = json.load(open(eval_path, \'r\'))\n\n    _id = 0\n    html_dir = ""/tmp/list_results%d"" % _id\n    while os.path.exists(html_dir):\n        _id += 1\n        html_dir = ""/tmp/list_results%d"" % _id\n\n    if os.path.exists(html_dir):\n        shutil.rmtree(html_dir)\n    os.mkdir(html_dir)\n\n    cur_dir = os.path.dirname(os.path.realpath(__file__))\n    templates_dir = os.path.join(cur_dir, \'templates\')\n    env = Environment(loader=FileSystemLoader(templates_dir))\n    env.globals.update(zip=zip, reversed=reversed)\n    template = env.get_template(args.template_name)\n\n    data_path = os.path.join(data_dir, ""data_{}.json"".format(data_type))\n    shared_path = os.path.join(data_dir, ""shared_{}.json"".format(data_type))\n    print(""loading {}"".format(data_path))\n    data = json.load(open(data_path, \'r\'))\n    print(""loading {}"".format(shared_path))\n    shared = json.load(open(shared_path, \'r\'))\n\n    rows = []\n    for i, (idx, yi, ypi, yp2i) in tqdm(enumerate(zip(*[eval_[key] for key in (\'idxs\', \'y\', \'yp\', \'yp2\')])), total=len(eval_[\'idxs\'])):\n        id_, q, rx, answers = (data[key][idx] for key in (\'ids\', \'q\', \'*x\', \'answerss\'))\n        x = shared[\'x\'][rx[0]][rx[1]]\n        ques = ["" "".join(q)]\n        para = [[word for word in sent] for sent in x]\n        span = get_best_span(ypi, yp2i)\n        ap = get_segment(para, span)\n        score = ""{:.3f}"".format(ypi[span[0][0]][span[0][1]] * yp2i[span[1][0]][span[1][1]-1])\n\n        row = {\n            \'id\': id_,\n            \'title\': ""Hello world!"",\n            \'ques\': ques,\n            \'para\': para,\n            \'y\': yi[0][0],\n            \'y2\': yi[0][1],\n            \'yp\': ypi,\n            \'yp2\': yp2i,\n            \'a\': answers,\n            \'ap\': ap,\n            \'score\': score\n               }\n        rows.append(row)\n\n        if i % num_per_page == 0:\n            html_path = os.path.join(html_dir, ""%s.html"" % str(i).zfill(8))\n\n        if (i + 1) % num_per_page == 0 or (i + 1) == len(eval_[\'y\']):\n            var_dict = {\'title\': ""Accuracy Visualization"",\n                        \'rows\': rows\n                        }\n            with open(html_path, ""wb"") as f:\n                f.write(template.render(**var_dict).encode(\'UTF-8\'))\n            rows = []\n\n    os.chdir(html_dir)\n    port = args.port\n    host = args.host\n    # Overriding to suppress log message\n    class MyHandler(http.server.SimpleHTTPRequestHandler):\n        def log_message(self, format, *args):\n            pass\n    handler = MyHandler\n    httpd = socketserver.TCPServer((host, port), handler)\n    if args.open == \'True\':\n        os.system(""open http://%s:%d"" % (args.host, args.port))\n    print(""serving at %s:%d"" % (host, port))\n    httpd.serve_forever()\n\n\ndef get_segment(para, span):\n    return "" "".join(para[span[0][0]][span[0][1]:span[1][1]])\n\n\nif __name__ == ""__main__"":\n    ARGS = get_args()\n    accuracy2_visualizer(ARGS)'"
cnn_dm/__init__.py,0,b''
cnn_dm/evaluate.py,0,"b'import json\nimport os\nimport sys\n\nroot_dir = sys.argv[1]\nanswer_path = sys.argv[2]\nfile_names = os.listdir(root_dir)\n\nnum_correct = 0\nnum_wrong = 0\n\nwith open(answer_path, \'r\') as fh:\n    id2answer_dict = json.load(fh)\n\nfor file_name in file_names:\n    if not file_name.endswith("".question""):\n        continue\n    with open(os.path.join(root_dir, file_name), \'r\') as fh:\n        url = fh.readline().strip()\n        _ = fh.readline()\n        para = fh.readline().strip()\n        _ = fh.readline()\n        ques = fh.readline().strip()\n        _ = fh.readline()\n        answer = fh.readline().strip()\n        _ = fh.readline()\n        if file_name in id2answer_dict:\n            pred = id2answer_dict[file_name]\n            if pred == answer:\n                num_correct += 1\n            else:\n                num_wrong += 1\n        else:\n            num_wrong += 1\n\ntotal = num_correct + num_wrong\nacc = float(num_correct) / total\nprint(""{} = {} / {}"".format(acc, num_correct, total))'"
cnn_dm/prepro.py,0,"b'import argparse\nimport json\nimport os\n# data: q, cq, (dq), (pq), y, *x, *cx\n# shared: x, cx, (dx), (px), word_counter, char_counter, word2vec\n# no metadata\nfrom collections import Counter\n\nfrom tqdm import tqdm\n\nfrom my.utils import process_tokens\nfrom squad.utils import get_word_span, process_tokens\n\n\ndef bool_(arg):\n    if arg == \'True\':\n        return True\n    elif arg == \'False\':\n        return False\n    raise Exception(arg)\n\n\ndef main():\n    args = get_args()\n    prepro(args)\n\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    home = os.path.expanduser(""~"")\n    source_dir = os.path.join(home, ""data"", ""cnn"", \'questions\')\n    target_dir = ""data/cnn""\n    glove_dir = os.path.join(home, ""data"", ""glove"")\n    parser.add_argument(""--source_dir"", default=source_dir)\n    parser.add_argument(""--target_dir"", default=target_dir)\n    parser.add_argument(""--glove_dir"", default=glove_dir)\n    parser.add_argument(""--glove_corpus"", default=\'6B\')\n    parser.add_argument(""--glove_vec_size"", default=100, type=int)\n    parser.add_argument(""--debug"", default=False, type=bool_)\n    parser.add_argument(""--num_sents_th"", default=200, type=int)\n    parser.add_argument(""--ques_size_th"", default=30, type=int)\n    parser.add_argument(""--width"", default=5, type=int)\n    # TODO : put more args here\n    return parser.parse_args()\n\n\ndef prepro(args):\n    prepro_each(args, \'train\')\n    prepro_each(args, \'dev\')\n    prepro_each(args, \'test\')\n\n\ndef para2sents(para, width):\n    """"""\n    Turn para into double array of words (wordss)\n    Where each sentence is up to 5 word neighbors of each entity\n    :param para:\n    :return:\n    """"""\n    words = para.split("" "")\n    sents = []\n    for i, word in enumerate(words):\n        if word.startswith(""@""):\n            start = max(i - width, 0)\n            stop = min(i + width + 1, len(words))\n            sent = words[start:stop]\n            sents.append(sent)\n    return sents\n\n\ndef get_word2vec(args, word_counter):\n    glove_path = os.path.join(args.glove_dir, ""glove.{}.{}d.txt"".format(args.glove_corpus, args.glove_vec_size))\n    sizes = {\'6B\': int(4e5), \'42B\': int(1.9e6), \'840B\': int(2.2e6), \'2B\': int(1.2e6)}\n    total = sizes[args.glove_corpus]\n    word2vec_dict = {}\n    with open(glove_path, \'r\', encoding=\'utf-8\') as fh:\n        for line in tqdm(fh, total=total):\n            array = line.lstrip().rstrip().split("" "")\n            word = array[0]\n            vector = list(map(float, array[1:]))\n            if word in word_counter:\n                word2vec_dict[word] = vector\n            elif word.capitalize() in word_counter:\n                word2vec_dict[word.capitalize()] = vector\n            elif word.lower() in word_counter:\n                word2vec_dict[word.lower()] = vector\n            elif word.upper() in word_counter:\n                word2vec_dict[word.upper()] = vector\n\n    print(""{}/{} of word vocab have corresponding vectors in {}"".format(len(word2vec_dict), len(word_counter), glove_path))\n    return word2vec_dict\n\n\ndef prepro_each(args, mode):\n    source_dir = os.path.join(args.source_dir, mode)\n    word_counter = Counter()\n    lower_word_counter = Counter()\n    ent_counter = Counter()\n    char_counter = Counter()\n    max_sent_size = 0\n    max_word_size = 0\n    max_ques_size = 0\n    max_num_sents = 0\n\n    file_names = list(os.listdir(source_dir))\n    if args.debug:\n        file_names = file_names[:1000]\n    lens = []\n\n    out_file_names = []\n    for file_name in tqdm(file_names, total=len(file_names)):\n        if file_name.endswith("".question""):\n            with open(os.path.join(source_dir, file_name), \'r\') as fh:\n                url = fh.readline().strip()\n                _ = fh.readline()\n                para = fh.readline().strip()\n                _ = fh.readline()\n                ques = fh.readline().strip()\n                _ = fh.readline()\n                answer = fh.readline().strip()\n                _ = fh.readline()\n                cands = list(line.strip() for line in fh)\n                cand_ents = list(cand.split("":"")[0] for cand in cands)\n                sents = para2sents(para, args.width)\n                ques_words = ques.split("" "")\n\n                # Filtering\n                if len(sents) > args.num_sents_th or len(ques_words) > args.ques_size_th:\n                    continue\n\n                max_sent_size = max(max(map(len, sents)), max_sent_size)\n                max_ques_size = max(len(ques_words), max_ques_size)\n                max_word_size = max(max(len(word) for sent in sents for word in sent), max_word_size)\n                max_num_sents = max(len(sents), max_num_sents)\n\n                for word in ques_words:\n                    if word.startswith(""@""):\n                        ent_counter[word] += 1\n                        word_counter[word] += 1\n                    else:\n                        word_counter[word] += 1\n                        lower_word_counter[word.lower()] += 1\n                        for c in word:\n                            char_counter[c] += 1\n                for sent in sents:\n                    for word in sent:\n                        if word.startswith(""@""):\n                            ent_counter[word] += 1\n                            word_counter[word] += 1\n                        else:\n                            word_counter[word] += 1\n                            lower_word_counter[word.lower()] += 1\n                            for c in word:\n                                char_counter[c] += 1\n\n                out_file_names.append(file_name)\n                lens.append(len(sents))\n    num_examples = len(out_file_names)\n\n    assert len(out_file_names) == len(lens)\n    sorted_file_names, lens = zip(*sorted(zip(out_file_names, lens), key=lambda each: each[1]))\n    assert lens[-1] == max_num_sents\n\n    word2vec_dict = get_word2vec(args, word_counter)\n    lower_word2vec_dit = get_word2vec(args, lower_word_counter)\n\n    shared = {\'word_counter\': word_counter, \'ent_counter\': ent_counter, \'char_counter\': char_counter,\n              \'lower_word_counter\': lower_word_counter,\n              \'max_num_sents\': max_num_sents, \'max_sent_size\': max_sent_size, \'max_word_size\': max_word_size,\n              \'max_ques_size\': max_ques_size,\n              \'word2vec\': word2vec_dict, \'lower_word2vec\': lower_word2vec_dit, \'sorted\': sorted_file_names,\n              \'num_examples\': num_examples}\n\n    print(""max num sents: {}"".format(max_num_sents))\n    print(""max ques size: {}"".format(max_ques_size))\n\n    if not os.path.exists(args.target_dir):\n        os.makedirs(args.target_dir)\n    shared_path = os.path.join(args.target_dir, ""shared_{}.json"".format(mode))\n    with open(shared_path, \'w\') as fh:\n        json.dump(shared, fh)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
my/__init__.py,0,b''
my/corenlp_interface.py,0,"b'import logging\n\nimport requests\nimport nltk\nimport json\nimport networkx as nx\nimport time\n\n\nclass CoreNLPInterface(object):\n    def __init__(self, url, port):\n        self._url = url\n        self._port = port\n\n    def get(self, type_, in_, num_max_requests=100):\n        in_ = in_.encode(""utf-8"")\n        url = ""http://{}:{}/{}"".format(self._url, self._port, type_)\n        out = None\n        for _ in range(num_max_requests):\n            try:\n                r = requests.post(url, data=in_)\n                out = r.content.decode(\'utf-8\')\n                if out == \'error\':\n                    out = None\n                break\n            except:\n                time.sleep(1)\n        return out\n\n    def split_doc(self, doc):\n        out = self.get(""doc"", doc)\n        return out if out is None else json.loads(out)\n\n    def split_sent(self, sent):\n        out = self.get(""sent"", sent)\n        return out if out is None else json.loads(out)\n\n    def get_dep(self, sent):\n        out = self.get(""dep"", sent)\n        return out if out is None else json.loads(out)\n\n    def get_const(self, sent):\n        out = self.get(""const"", sent)\n        return out\n\n    def get_const_tree(self, sent):\n        out = self.get_const(sent)\n        return out if out is None else nltk.tree.Tree.fromstring(out)\n\n    @staticmethod\n    def dep2tree(dep):\n        tree = nx.DiGraph()\n        for dep, i, gov, j, label in dep:\n            tree.add_edge(gov, dep, label=label)\n        return tree\n'"
my/nltk_utils.py,0,"b'import nltk\nimport numpy as np\n\n\ndef _set_span(t, i):\n    if isinstance(t[0], str):\n        t.span = (i, i+len(t))\n    else:\n        first = True\n        for c in t:\n            cur_span = _set_span(c, i)\n            i = cur_span[1]\n            if first:\n                min_ = cur_span[0]\n                first = False\n        max_ = cur_span[1]\n        t.span = (min_, max_)\n    return t.span\n\n\ndef set_span(t):\n    assert isinstance(t, nltk.tree.Tree)\n    try:\n        return _set_span(t, 0)\n    except:\n        print(t)\n        exit()\n\n\ndef tree_contains_span(tree, span):\n    """"""\n    Assumes that tree span has been set with set_span\n    Returns true if any subtree of t has exact span as the given span\n    :param t:\n    :param span:\n    :return bool:\n    """"""\n    return span in set(t.span for t in tree.subtrees())\n\n\ndef span_len(span):\n    return span[1] - span[0]\n\n\ndef span_overlap(s1, s2):\n    start = max(s1[0], s2[0])\n    stop = min(s1[1], s2[1])\n    if stop > start:\n        return start, stop\n    return None\n\n\ndef span_prec(true_span, pred_span):\n    overlap = span_overlap(true_span, pred_span)\n    if overlap is None:\n        return 0\n    return span_len(overlap) / span_len(pred_span)\n\n\ndef span_recall(true_span, pred_span):\n    overlap = span_overlap(true_span, pred_span)\n    if overlap is None:\n        return 0\n    return span_len(overlap) / span_len(true_span)\n\n\ndef span_f1(true_span, pred_span):\n    p = span_prec(true_span, pred_span)\n    r = span_recall(true_span, pred_span)\n    if p == 0 or r == 0:\n        return 0.0\n    return 2 * p * r / (p + r)\n\n\ndef find_max_f1_span(tree, span):\n    return find_max_f1_subtree(tree, span).span\n\n\ndef find_max_f1_subtree(tree, span):\n    return max(((t, span_f1(span, t.span)) for t in tree.subtrees()), key=lambda p: p[1])[0]\n\n\ndef tree2matrix(tree, node2num, row_size=None, col_size=None, dtype=\'int32\'):\n    set_span(tree)\n    D = tree.height() - 1\n    B = len(tree.leaves())\n    row_size = row_size or D\n    col_size = col_size or B\n    matrix = np.zeros([row_size, col_size], dtype=dtype)\n    mask = np.zeros([row_size, col_size, col_size], dtype=\'bool\')\n\n    for subtree in tree.subtrees():\n        row = subtree.height() - 2\n        col = subtree.span[0]\n        matrix[row, col] = node2num(subtree)\n        for subsub in subtree.subtrees():\n            if isinstance(subsub, nltk.tree.Tree):\n                mask[row, col, subsub.span[0]] = True\n                if not isinstance(subsub[0], nltk.tree.Tree):\n                    c = subsub.span[0]\n                    for r in range(row):\n                        mask[r, c, c] = True\n            else:\n                mask[row, col, col] = True\n\n    return matrix, mask\n\n\ndef load_compressed_tree(s):\n\n    def compress_tree(tree):\n        assert not isinstance(tree, str)\n        if len(tree) == 1:\n            if isinstance(tree[0], nltk.tree.Tree):\n                return compress_tree(tree[0])\n            else:\n                return tree\n        else:\n            for i, t in enumerate(tree):\n                if isinstance(t, nltk.tree.Tree):\n                    tree[i] = compress_tree(t)\n                else:\n                    tree[i] = t\n            return tree\n\n    return compress_tree(nltk.tree.Tree.fromstring(s))\n\n\n\n'"
my/utils.py,0,"b'import json\nfrom collections import deque\n\nimport numpy as np\nfrom tqdm import tqdm\n\n\ndef mytqdm(list_, desc="""", show=True):\n    if show:\n        pbar = tqdm(list_)\n        pbar.set_description(desc)\n        return pbar\n    return list_\n\n\ndef json_pretty_dump(obj, fh):\n    return json.dump(obj, fh, sort_keys=True, indent=2, separators=(\',\', \': \'))\n\n\ndef index(l, i):\n    return index(l[i[0]], i[1:]) if len(i) > 1 else l[i[0]]\n\n\ndef fill(l, shape, dtype=None):\n    out = np.zeros(shape, dtype=dtype)\n    stack = deque()\n    stack.appendleft(((), l))\n    while len(stack) > 0:\n        indices, cur = stack.pop()\n        if len(indices) < shape:\n            for i, sub in enumerate(cur):\n                stack.appendleft([indices + (i,), sub])\n        else:\n            out[indices] = cur\n    return out\n\n\ndef short_floats(o, precision):\n    class ShortFloat(float):\n        def __repr__(self):\n            return \'%.{}g\'.format(precision) % self\n\n    def _short_floats(obj):\n        if isinstance(obj, float):\n            return ShortFloat(obj)\n        elif isinstance(obj, dict):\n            return dict((k, _short_floats(v)) for k, v in obj.items())\n        elif isinstance(obj, (list, tuple)):\n            return tuple(map(_short_floats, obj))\n        return obj\n\n    return _short_floats(o)\n\n\ndef argmax(x):\n    return np.unravel_index(x.argmax(), x.shape)\n\n\n'"
my/zip_save.py,0,"b'import argparse\nimport os\n\nimport shutil\nfrom zipfile import ZipFile\n\nfrom tqdm import tqdm\n\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'paths\', nargs=\'+\')\n    parser.add_argument(\'-o\', \'--out\', default=\'save.zip\')\n    args = parser.parse_args()\n    return args\n\n\ndef zip_save(args):\n    temp_dir = "".""\n    save_dir = os.path.join(temp_dir, ""save"")\n    if not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n    for save_source_path in tqdm(args.paths):\n        # path = ""out/basic/30/save/basic-18000""\n        # target_path = ""save_dir/30/save""\n        # also output full path name to ""save_dir/30/readme.txt\n        # need to also extract ""out/basic/30/shared.json""\n        temp, _ = os.path.split(save_source_path)  # ""out/basic/30/save"", _\n        model_dir, _ = os.path.split(temp)  # ""out/basic/30, _\n        _, model_name = os.path.split(model_dir)\n        cur_dir = os.path.join(save_dir, model_name)\n        if not os.path.exists(cur_dir):\n            os.makedirs(cur_dir)\n        save_target_path = os.path.join(cur_dir, ""save"")\n        shared_target_path = os.path.join(cur_dir, ""shared.json"")\n        readme_path = os.path.join(cur_dir, ""readme.txt"")\n        shared_source_path = os.path.join(model_dir, ""shared.json"")\n        shutil.copy(save_source_path, save_target_path)\n        shutil.copy(shared_source_path, shared_target_path)\n        with open(readme_path, \'w\') as fh:\n            fh.write(save_source_path)\n\n    os.system(""zip {} -r {}"".format(args.out, save_dir))\n\ndef main():\n    args = get_args()\n    zip_save(args)\n\nif __name__ == ""__main__"":\n    main()\n'"
squad/__init__.py,0,b''
squad/aug_squad.py,0,"b'import json\nimport sys\n\nfrom tqdm import tqdm\n\nfrom my.corenlp_interface import CoreNLPInterface\n\nin_path = sys.argv[1]\nout_path = sys.argv[2]\nurl = sys.argv[3]\nport = int(sys.argv[4])\ndata = json.load(open(in_path, \'r\'))\n\nh = CoreNLPInterface(url, port)\n\n\ndef find_all(a_str, sub):\n    start = 0\n    while True:\n        start = a_str.find(sub, start)\n        if start == -1: return\n        yield start\n        start += len(sub)  # use start += 1 to find overlapping matches\n\n\ndef to_hex(s):\n    return "" "".join(map(hex, map(ord, s)))\n\n\ndef handle_nobreak(cand, text):\n    if cand == text:\n        return cand\n    if cand.replace(u\'\\u00A0\', \' \') == text:\n        return cand\n    elif cand == text.replace(u\'\\u00A0\', \' \'):\n        return text\n    raise Exception(""{} \'{}\' {} \'{}\'"".format(cand, to_hex(cand), text, to_hex(text)))\n\n\n# resolving unicode complication\n\nwrong_loc_count = 0\nloc_diffs = []\n\nfor article in data[\'data\']:\n    for para in article[\'paragraphs\']:\n        para[\'context\'] = para[\'context\'].replace(u\'\\u000A\', \'\')\n        para[\'context\'] = para[\'context\'].replace(u\'\\u00A0\', \' \')\n        context = para[\'context\']\n        for qa in para[\'qas\']:\n            for answer in qa[\'answers\']:\n                answer[\'text\'] = answer[\'text\'].replace(u\'\\u00A0\', \' \')\n                text = answer[\'text\']\n                answer_start = answer[\'answer_start\']\n                if context[answer_start:answer_start + len(text)] == text:\n                    if text.lstrip() == text:\n                        pass\n                    else:\n                        answer_start += len(text) - len(text.lstrip())\n                        answer[\'answer_start\'] = answer_start\n                        text = text.lstrip()\n                        answer[\'text\'] = text\n                else:\n                    wrong_loc_count += 1\n                    text = text.lstrip()\n                    answer[\'text\'] = text\n                    starts = list(find_all(context, text))\n                    if len(starts) == 1:\n                        answer_start = starts[0]\n                    elif len(starts) > 1:\n                        new_answer_start = min(starts, key=lambda s: abs(s - answer_start))\n                        loc_diffs.append(abs(new_answer_start - answer_start))\n                        answer_start = new_answer_start\n                    else:\n                        raise Exception()\n                    answer[\'answer_start\'] = answer_start\n\n                answer_stop = answer_start + len(text)\n                answer[\'answer_stop\'] = answer_stop\n                assert para[\'context\'][answer_start:answer_stop] == answer[\'text\'], ""{} {}"".format(\n                    para[\'context\'][answer_start:answer_stop], answer[\'text\'])\n\nprint(wrong_loc_count, loc_diffs)\n\nmismatch_count = 0\ndep_fail_count = 0\nno_answer_count = 0\n\nsize = sum(len(article[\'paragraphs\']) for article in data[\'data\'])\npbar = tqdm(range(size))\n\nfor ai, article in enumerate(data[\'data\']):\n    for pi, para in enumerate(article[\'paragraphs\']):\n        context = para[\'context\']\n        sents = h.split_doc(context)\n        words = h.split_sent(context)\n        sent_starts = []\n        ref_idx = 0\n        for sent in sents:\n            new_idx = context.find(sent, ref_idx)\n            sent_starts.append(new_idx)\n            ref_idx = new_idx + len(sent)\n        para[\'sents\'] = sents\n        para[\'words\'] = words\n        para[\'sent_starts\'] = sent_starts\n\n        consts = list(map(h.get_const, sents))\n        para[\'consts\'] = consts\n        deps = list(map(h.get_dep, sents))\n        para[\'deps\'] = deps\n\n        for qa in para[\'qas\']:\n            question = qa[\'question\']\n            question_const = h.get_const(question)\n            qa[\'const\'] = question_const\n            question_dep = h.get_dep(question)\n            qa[\'dep\'] = question_dep\n            qa[\'words\'] = h.split_sent(question)\n\n            for answer in qa[\'answers\']:\n                answer_start = answer[\'answer_start\']\n                text = answer[\'text\']\n                answer_stop = answer_start + len(text)\n                # answer_words = h.split_sent(text)\n                word_idxs = []\n                answer_words = []\n                for sent_idx, (sent, sent_start, dep) in enumerate(zip(sents, sent_starts, deps)):\n                    if dep is None:\n                        print(""dep parse failed at {} {} {}"".format(ai, pi, sent_idx))\n                        dep_fail_count += 1\n                        continue\n                    nodes, edges = dep\n                    words = [node[0] for node in nodes]\n\n                    for word_idx, (word, _, _, start, _) in enumerate(nodes):\n                        global_start = sent_start + start\n                        global_stop = global_start + len(word)\n                        if answer_start <= global_start < answer_stop or answer_start < global_stop <= answer_stop:\n                            word_idxs.append((sent_idx, word_idx))\n                            answer_words.append(word)\n                if len(word_idxs) > 0:\n                    answer[\'answer_word_start\'] = word_idxs[0]\n                    answer[\'answer_word_stop\'] = word_idxs[-1][0], word_idxs[-1][1] + 1\n                    if not text.startswith(answer_words[0]):\n                        print(""\'{}\' \'{}\'"".format(text, \' \'.join(answer_words)))\n                        mismatch_count += 1\n                else:\n                    answer[\'answer_word_start\'] = None\n                    answer[\'answer_word_stop\'] = None\n                    no_answer_count += 1\n        pbar.update(1)\npbar.close()\n\nprint(mismatch_count, dep_fail_count, no_answer_count)\n\nprint(""saving..."")\njson.dump(data, open(out_path, \'w\'))'"
squad/evaluate-v1.1.py,0,"b'"""""" Official evaluation script for v1.1 of the SQuAD dataset. """"""\nfrom __future__ import print_function\nfrom collections import Counter\nimport string\nimport re\nimport argparse\nimport json\nimport sys\n\n\ndef normalize_answer(s):\n    """"""Lower text and remove punctuation, articles and extra whitespace.""""""\n    def remove_articles(text):\n        return re.sub(r\'\\b(a|an|the)\\b\', \' \', text)\n\n    def white_space_fix(text):\n        return \' \'.join(text.split())\n\n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return \'\'.join(ch for ch in text if ch not in exclude)\n\n    def lower(text):\n        return text.lower()\n\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\n\n\ndef f1_score(prediction, ground_truth):\n    prediction_tokens = normalize_answer(prediction).split()\n    ground_truth_tokens = normalize_answer(ground_truth).split()\n    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n    num_same = sum(common.values())\n    if num_same == 0:\n        return 0\n    precision = 1.0 * num_same / len(prediction_tokens)\n    recall = 1.0 * num_same / len(ground_truth_tokens)\n    f1 = (2 * precision * recall) / (precision + recall)\n    return f1\n\n\ndef exact_match_score(prediction, ground_truth):\n    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n\n\ndef metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n    scores_for_ground_truths = []\n    for ground_truth in ground_truths:\n        score = metric_fn(prediction, ground_truth)\n        scores_for_ground_truths.append(score)\n    return max(scores_for_ground_truths)\n\n\ndef evaluate(dataset, predictions):\n    f1 = exact_match = total = 0\n    for article in dataset:\n        for paragraph in article[\'paragraphs\']:\n            for qa in paragraph[\'qas\']:\n                total += 1\n                if qa[\'id\'] not in predictions:\n                    message = \'Unanswered question \' + qa[\'id\'] + \\\n                              \' will receive score 0.\'\n                    print(message, file=sys.stderr)\n                    continue\n                ground_truths = list(map(lambda x: x[\'text\'], qa[\'answers\']))\n                prediction = predictions[qa[\'id\']]\n                exact_match += metric_max_over_ground_truths(\n                    exact_match_score, prediction, ground_truths)\n                f1 += metric_max_over_ground_truths(\n                    f1_score, prediction, ground_truths)\n\n    exact_match = 100.0 * exact_match / total\n    f1 = 100.0 * f1 / total\n\n    return {\'exact_match\': exact_match, \'f1\': f1}\n\n\nif __name__ == \'__main__\':\n    expected_version = \'1.1\'\n    parser = argparse.ArgumentParser(\n        description=\'Evaluation for SQuAD \' + expected_version)\n    parser.add_argument(\'dataset_file\', help=\'Dataset file\')\n    parser.add_argument(\'prediction_file\', help=\'Prediction File\')\n    args = parser.parse_args()\n    with open(args.dataset_file) as dataset_file:\n        dataset_json = json.load(dataset_file)\n        if (dataset_json[\'version\'] != expected_version):\n            print(\'Evaluation expects v-\' + expected_version +\n                  \', but got dataset with v-\' + dataset_json[\'version\'],\n                  file=sys.stderr)\n        dataset = dataset_json[\'data\']\n    with open(args.prediction_file) as prediction_file:\n        predictions = json.load(prediction_file)\n    print(json.dumps(evaluate(dataset, predictions)))\n'"
squad/evaluate.py,0,"b'"""""" Official evaluation script for v1.1 of the SQuAD dataset. [Changed name for external importing]""""""\nfrom __future__ import print_function\nfrom collections import Counter\nimport string\nimport re\nimport argparse\nimport json\nimport sys\n\n\ndef normalize_answer(s):\n    """"""Lower text and remove punctuation, articles and extra whitespace.""""""\n    def remove_articles(text):\n        return re.sub(r\'\\b(a|an|the)\\b\', \' \', text)\n\n    def white_space_fix(text):\n        return \' \'.join(text.split())\n\n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return \'\'.join(ch for ch in text if ch not in exclude)\n\n    def lower(text):\n        return text.lower()\n\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\n\n\ndef f1_score(prediction, ground_truth):\n    prediction_tokens = normalize_answer(prediction).split()\n    ground_truth_tokens = normalize_answer(ground_truth).split()\n    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n    num_same = sum(common.values())\n    if num_same == 0:\n        return 0\n    precision = 1.0 * num_same / len(prediction_tokens)\n    recall = 1.0 * num_same / len(ground_truth_tokens)\n    f1 = (2 * precision * recall) / (precision + recall)\n    return f1\n\n\ndef exact_match_score(prediction, ground_truth):\n    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n\n\ndef metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n    scores_for_ground_truths = []\n    for ground_truth in ground_truths:\n        score = metric_fn(prediction, ground_truth)\n        scores_for_ground_truths.append(score)\n    return max(scores_for_ground_truths)\n\n\ndef evaluate(dataset, predictions):\n    f1 = exact_match = total = 0\n    for article in dataset:\n        for paragraph in article[\'paragraphs\']:\n            for qa in paragraph[\'qas\']:\n                total += 1\n                if qa[\'id\'] not in predictions:\n                    message = \'Unanswered question \' + qa[\'id\'] + \\\n                              \' will receive score 0.\'\n                    print(message, file=sys.stderr)\n                    continue\n                ground_truths = list(map(lambda x: x[\'text\'], qa[\'answers\']))\n                prediction = predictions[qa[\'id\']]\n                exact_match += metric_max_over_ground_truths(\n                    exact_match_score, prediction, ground_truths)\n                f1 += metric_max_over_ground_truths(\n                    f1_score, prediction, ground_truths)\n\n    exact_match = 100.0 * exact_match / total\n    f1 = 100.0 * f1 / total\n\n    return {\'exact_match\': exact_match, \'f1\': f1}\n\n\nif __name__ == \'__main__\':\n    expected_version = \'1.1\'\n    parser = argparse.ArgumentParser(\n        description=\'Evaluation for SQuAD \' + expected_version)\n    parser.add_argument(\'dataset_file\', help=\'Dataset file\')\n    parser.add_argument(\'prediction_file\', help=\'Prediction File\')\n    args = parser.parse_args()\n    with open(args.dataset_file) as dataset_file:\n        dataset_json = json.load(dataset_file)\n        if (dataset_json[\'version\'] != expected_version):\n            print(\'Evaluation expects v-\' + expected_version +\n                  \', but got dataset with v-\' + dataset_json[\'version\'],\n                  file=sys.stderr)\n        dataset = dataset_json[\'data\']\n    with open(args.prediction_file) as prediction_file:\n        predictions = json.load(prediction_file)\n    print(json.dumps(evaluate(dataset, predictions)))\n'"
squad/prepro.py,0,"b'import argparse\nimport json\nimport os\n# data: q, cq, (dq), (pq), y, *x, *cx\n# shared: x, cx, (dx), (px), word_counter, char_counter, word2vec\n# no metadata\nfrom collections import Counter\n\nfrom tqdm import tqdm\n\nfrom squad.utils import get_word_span, get_word_idx, process_tokens\n\n\ndef main():\n    args = get_args()\n    prepro(args)\n\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    home = os.path.expanduser(""~"")\n    source_dir = os.path.join(home, ""data"", ""squad"")\n    target_dir = ""data/squad""\n    glove_dir = os.path.join(home, ""data"", ""glove"")\n    parser.add_argument(\'-s\', ""--source_dir"", default=source_dir)\n    parser.add_argument(\'-t\', ""--target_dir"", default=target_dir)\n    parser.add_argument(\'-d\', ""--debug"", action=\'store_true\')\n    parser.add_argument(""--train_ratio"", default=0.9, type=int)\n    parser.add_argument(""--glove_corpus"", default=""6B"")\n    parser.add_argument(""--glove_dir"", default=glove_dir)\n    parser.add_argument(""--glove_vec_size"", default=100, type=int)\n    parser.add_argument(""--mode"", default=""full"", type=str)\n    parser.add_argument(""--single_path"", default="""", type=str)\n    parser.add_argument(""--tokenizer"", default=""PTB"", type=str)\n    parser.add_argument(""--url"", default=""vision-server2.corp.ai2"", type=str)\n    parser.add_argument(""--port"", default=8000, type=int)\n    parser.add_argument(""--split"", action=\'store_true\')\n    # TODO : put more args here\n    return parser.parse_args()\n\n\ndef create_all(args):\n    out_path = os.path.join(args.source_dir, ""all-v1.1.json"")\n    if os.path.exists(out_path):\n        return\n    train_path = os.path.join(args.source_dir, ""train-v1.1.json"")\n    train_data = json.load(open(train_path, \'r\'))\n    dev_path = os.path.join(args.source_dir, ""dev-v1.1.json"")\n    dev_data = json.load(open(dev_path, \'r\'))\n    train_data[\'data\'].extend(dev_data[\'data\'])\n    print(""dumping all data ..."")\n    json.dump(train_data, open(out_path, \'w\'))\n\n\ndef prepro(args):\n    if not os.path.exists(args.target_dir):\n        os.makedirs(args.target_dir)\n\n    if args.mode == \'full\':\n        prepro_each(args, \'train\', out_name=\'train\')\n        prepro_each(args, \'dev\', out_name=\'dev\')\n        prepro_each(args, \'dev\', out_name=\'test\')\n    elif args.mode == \'all\':\n        create_all(args)\n        prepro_each(args, \'dev\', 0.0, 0.0, out_name=\'dev\')\n        prepro_each(args, \'dev\', 0.0, 0.0, out_name=\'test\')\n        prepro_each(args, \'all\', out_name=\'train\')\n    elif args.mode == \'single\':\n        assert len(args.single_path) > 0\n        prepro_each(args, ""NULL"", out_name=""single"", in_path=args.single_path)\n    else:\n        prepro_each(args, \'train\', 0.0, args.train_ratio, out_name=\'train\')\n        prepro_each(args, \'train\', args.train_ratio, 1.0, out_name=\'dev\')\n        prepro_each(args, \'dev\', out_name=\'test\')\n\n\ndef save(args, data, shared, data_type):\n    data_path = os.path.join(args.target_dir, ""data_{}.json"".format(data_type))\n    shared_path = os.path.join(args.target_dir, ""shared_{}.json"".format(data_type))\n    json.dump(data, open(data_path, \'w\'))\n    json.dump(shared, open(shared_path, \'w\'))\n\n\ndef get_word2vec(args, word_counter):\n    glove_path = os.path.join(args.glove_dir, ""glove.{}.{}d.txt"".format(args.glove_corpus, args.glove_vec_size))\n    sizes = {\'6B\': int(4e5), \'42B\': int(1.9e6), \'840B\': int(2.2e6), \'2B\': int(1.2e6)}\n    total = sizes[args.glove_corpus]\n    word2vec_dict = {}\n    with open(glove_path, \'r\', encoding=\'utf-8\') as fh:\n        for line in tqdm(fh, total=total):\n            array = line.lstrip().rstrip().split("" "")\n            word = array[0]\n            vector = list(map(float, array[1:]))\n            if word in word_counter:\n                word2vec_dict[word] = vector\n            elif word.capitalize() in word_counter:\n                word2vec_dict[word.capitalize()] = vector\n            elif word.lower() in word_counter:\n                word2vec_dict[word.lower()] = vector\n            elif word.upper() in word_counter:\n                word2vec_dict[word.upper()] = vector\n\n    print(""{}/{} of word vocab have corresponding vectors in {}"".format(len(word2vec_dict), len(word_counter), glove_path))\n    return word2vec_dict\n\n\ndef prepro_each(args, data_type, start_ratio=0.0, stop_ratio=1.0, out_name=""default"", in_path=None):\n    if args.tokenizer == ""PTB"":\n        import nltk\n        sent_tokenize = nltk.sent_tokenize\n        def word_tokenize(tokens):\n            return [token.replace(""\'\'"", \'""\').replace(""``"", \'""\') for token in nltk.word_tokenize(tokens)]\n    elif args.tokenizer == \'Stanford\':\n        from my.corenlp_interface import CoreNLPInterface\n        interface = CoreNLPInterface(args.url, args.port)\n        sent_tokenize = interface.split_doc\n        word_tokenize = interface.split_sent\n    else:\n        raise Exception()\n\n    if not args.split:\n        sent_tokenize = lambda para: [para]\n\n    source_path = in_path or os.path.join(args.source_dir, ""{}-v1.1.json"".format(data_type))\n    source_data = json.load(open(source_path, \'r\'))\n\n    q, cq, y, rx, rcx, ids, idxs = [], [], [], [], [], [], []\n    cy = []\n    x, cx = [], []\n    answerss = []\n    p = []\n    word_counter, char_counter, lower_word_counter = Counter(), Counter(), Counter()\n    start_ai = int(round(len(source_data[\'data\']) * start_ratio))\n    stop_ai = int(round(len(source_data[\'data\']) * stop_ratio))\n    for ai, article in enumerate(tqdm(source_data[\'data\'][start_ai:stop_ai])):\n        xp, cxp = [], []\n        pp = []\n        x.append(xp)\n        cx.append(cxp)\n        p.append(pp)\n        for pi, para in enumerate(article[\'paragraphs\']):\n            # wordss\n            context = para[\'context\']\n            context = context.replace(""\'\'"", \'"" \')\n            context = context.replace(""``"", \'"" \')\n            xi = list(map(word_tokenize, sent_tokenize(context)))\n            xi = [process_tokens(tokens) for tokens in xi]  # process tokens\n            # given xi, add chars\n            cxi = [[list(xijk) for xijk in xij] for xij in xi]\n            xp.append(xi)\n            cxp.append(cxi)\n            pp.append(context)\n\n            for xij in xi:\n                for xijk in xij:\n                    word_counter[xijk] += len(para[\'qas\'])\n                    lower_word_counter[xijk.lower()] += len(para[\'qas\'])\n                    for xijkl in xijk:\n                        char_counter[xijkl] += len(para[\'qas\'])\n\n            rxi = [ai, pi]\n            assert len(x) - 1 == ai\n            assert len(x[ai]) - 1 == pi\n            for qa in para[\'qas\']:\n                # get words\n                qi = word_tokenize(qa[\'question\'])\n                cqi = [list(qij) for qij in qi]\n                yi = []\n                cyi = []\n                answers = []\n                for answer in qa[\'answers\']:\n                    answer_text = answer[\'text\']\n                    answers.append(answer_text)\n                    answer_start = answer[\'answer_start\']\n                    answer_stop = answer_start + len(answer_text)\n                    # TODO : put some function that gives word_start, word_stop here\n                    yi0, yi1 = get_word_span(context, xi, answer_start, answer_stop)\n                    # yi0 = answer[\'answer_word_start\'] or [0, 0]\n                    # yi1 = answer[\'answer_word_stop\'] or [0, 1]\n                    assert len(xi[yi0[0]]) > yi0[1]\n                    assert len(xi[yi1[0]]) >= yi1[1]\n                    w0 = xi[yi0[0]][yi0[1]]\n                    w1 = xi[yi1[0]][yi1[1]-1]\n                    i0 = get_word_idx(context, xi, yi0)\n                    i1 = get_word_idx(context, xi, (yi1[0], yi1[1]-1))\n                    cyi0 = answer_start - i0\n                    cyi1 = answer_stop - i1 - 1\n                    # print(answer_text, w0[cyi0:], w1[:cyi1+1])\n                    assert answer_text[0] == w0[cyi0], (answer_text, w0, cyi0)\n                    assert answer_text[-1] == w1[cyi1]\n                    assert cyi0 < 32, (answer_text, w0)\n                    assert cyi1 < 32, (answer_text, w1)\n\n                    yi.append([yi0, yi1])\n                    cyi.append([cyi0, cyi1])\n\n                for qij in qi:\n                    word_counter[qij] += 1\n                    lower_word_counter[qij.lower()] += 1\n                    for qijk in qij:\n                        char_counter[qijk] += 1\n\n                q.append(qi)\n                cq.append(cqi)\n                y.append(yi)\n                cy.append(cyi)\n                rx.append(rxi)\n                rcx.append(rxi)\n                ids.append(qa[\'id\'])\n                idxs.append(len(idxs))\n                answerss.append(answers)\n\n            if args.debug:\n                break\n\n    word2vec_dict = get_word2vec(args, word_counter)\n    lower_word2vec_dict = get_word2vec(args, lower_word_counter)\n\n    # add context here\n    data = {\'q\': q, \'cq\': cq, \'y\': y, \'*x\': rx, \'*cx\': rcx, \'cy\': cy,\n            \'idxs\': idxs, \'ids\': ids, \'answerss\': answerss, \'*p\': rx}\n    shared = {\'x\': x, \'cx\': cx, \'p\': p,\n              \'word_counter\': word_counter, \'char_counter\': char_counter, \'lower_word_counter\': lower_word_counter,\n              \'word2vec\': word2vec_dict, \'lower_word2vec\': lower_word2vec_dict}\n\n    print(""saving ..."")\n    save(args, data, shared, out_name)\n\n\n\nif __name__ == ""__main__"":\n    main()'"
squad/prepro_aug.py,0,"b'import argparse\nimport json\nimport os\n# data: q, cq, (dq), (pq), y, *x, *cx\n# shared: x, cx, (dx), (px), word_counter, char_counter, word2vec\n# no metadata\nfrom collections import Counter\n\nimport nltk\nfrom tqdm import tqdm\n\nfrom my.nltk_utils import load_compressed_tree\n\n\ndef bool_(arg):\n    if arg == \'True\':\n        return True\n    elif arg == \'False\':\n        return False\n    raise Exception()\n\n\ndef main():\n    args = get_args()\n    prepro(args)\n\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    home = os.path.expanduser(""~"")\n    source_dir = os.path.join(home, ""data"", ""squad"")\n    target_dir = ""data/squad""\n    glove_dir = os.path.join(home, ""data"", ""glove"")\n    parser.add_argument(""--source_dir"", default=source_dir)\n    parser.add_argument(""--target_dir"", default=target_dir)\n    parser.add_argument(""--debug"", default=False, type=bool_)\n    parser.add_argument(""--train_ratio"", default=0.9, type=int)\n    parser.add_argument(""--glove_corpus"", default=""6B"")\n    parser.add_argument(""--glove_dir"", default=glove_dir)\n    parser.add_argument(""--glove_vec_size"", default=100, type=int)\n    parser.add_argument(""--full_train"", default=False, type=bool_)\n    # TODO : put more args here\n    return parser.parse_args()\n\n\ndef prepro(args):\n    if not os.path.exists(args.target_dir):\n        os.makedirs(args.target_dir)\n\n    if args.full_train:\n        data_train, shared_train = prepro_each(args, \'train\')\n        data_dev, shared_dev = prepro_each(args, \'dev\')\n    else:\n        data_train, shared_train = prepro_each(args, \'train\', 0.0, args.train_ratio)\n        data_dev, shared_dev = prepro_each(args, \'train\', args.train_ratio, 1.0)\n    data_test, shared_test = prepro_each(args, \'dev\')\n\n    print(""saving ..."")\n    save(args, data_train, shared_train, \'train\')\n    save(args, data_dev, shared_dev, \'dev\')\n    save(args, data_test, shared_test, \'test\')\n\n\ndef save(args, data, shared, data_type):\n    data_path = os.path.join(args.target_dir, ""data_{}.json"".format(data_type))\n    shared_path = os.path.join(args.target_dir, ""shared_{}.json"".format(data_type))\n    json.dump(data, open(data_path, \'w\'))\n    json.dump(shared, open(shared_path, \'w\'))\n\n\ndef get_word2vec(args, word_counter):\n    glove_path = os.path.join(args.glove_dir, ""glove.{}.{}d.txt"".format(args.glove_corpus, args.glove_vec_size))\n    sizes = {\'6B\': int(4e5), \'42B\': int(1.9e6), \'840B\': int(2.2e6), \'2B\': int(1.2e6)}\n    total = sizes[args.glove_corpus]\n    word2vec_dict = {}\n    with open(glove_path, \'r\') as fh:\n        for line in tqdm(fh, total=total):\n            array = line.lstrip().rstrip().split("" "")\n            word = array[0]\n            vector = list(map(float, array[1:]))\n            if word in word_counter:\n                word2vec_dict[word] = vector\n            elif word.capitalize() in word_counter:\n                word2vec_dict[word.capitalize()] = vector\n            elif word.lower() in word_counter:\n                word2vec_dict[word.lower()] = vector\n            elif word.upper() in word_counter:\n                word2vec_dict[word.upper()] = vector\n\n    print(""{}/{} of word vocab have corresponding vectors in {}"".format(len(word2vec_dict), len(word_counter), glove_path))\n    return word2vec_dict\n\n\ndef prepro_each(args, data_type, start_ratio=0.0, stop_ratio=1.0):\n    source_path = os.path.join(args.source_dir, ""{}-v1.0-aug.json"".format(data_type))\n    source_data = json.load(open(source_path, \'r\'))\n\n    q, cq, y, rx, rcx, ids, idxs = [], [], [], [], [], [], []\n    x, cx, tx, stx = [], [], [], []\n    answerss = []\n    word_counter, char_counter, lower_word_counter = Counter(), Counter(), Counter()\n    pos_counter = Counter()\n    start_ai = int(round(len(source_data[\'data\']) * start_ratio))\n    stop_ai = int(round(len(source_data[\'data\']) * stop_ratio))\n    for ai, article in enumerate(tqdm(source_data[\'data\'][start_ai:stop_ai])):\n        xp, cxp, txp, stxp = [], [], [], []\n        x.append(xp)\n        cx.append(cxp)\n        tx.append(txp)\n        stx.append(stxp)\n        for pi, para in enumerate(article[\'paragraphs\']):\n            xi = []\n            for dep in para[\'deps\']:\n                if dep is None:\n                    xi.append([])\n                else:\n                    xi.append([node[0] for node in dep[0]])\n            cxi = [[list(xijk) for xijk in xij] for xij in xi]\n            xp.append(xi)\n            cxp.append(cxi)\n            txp.append(para[\'consts\'])\n            stxp.append([str(load_compressed_tree(s)) for s in para[\'consts\']])\n            trees = map(nltk.tree.Tree.fromstring, para[\'consts\'])\n            for tree in trees:\n                for subtree in tree.subtrees():\n                    pos_counter[subtree.label()] += 1\n\n            for xij in xi:\n                for xijk in xij:\n                    word_counter[xijk] += len(para[\'qas\'])\n                    lower_word_counter[xijk.lower()] += len(para[\'qas\'])\n                    for xijkl in xijk:\n                        char_counter[xijkl] += len(para[\'qas\'])\n\n            rxi = [ai, pi]\n            assert len(x) - 1 == ai\n            assert len(x[ai]) - 1 == pi\n            for qa in para[\'qas\']:\n                dep = qa[\'dep\']\n                qi = [] if dep is None else [node[0] for node in dep[0]]\n                cqi = [list(qij) for qij in qi]\n                yi = []\n                answers = []\n                for answer in qa[\'answers\']:\n                    answers.append(answer[\'text\'])\n                    yi0 = answer[\'answer_word_start\'] or [0, 0]\n                    yi1 = answer[\'answer_word_stop\'] or [0, 1]\n                    assert len(xi[yi0[0]]) > yi0[1]\n                    assert len(xi[yi1[0]]) >= yi1[1]\n                    yi.append([yi0, yi1])\n\n                for qij in qi:\n                    word_counter[qij] += 1\n                    lower_word_counter[qij.lower()] += 1\n                    for qijk in qij:\n                        char_counter[qijk] += 1\n\n                q.append(qi)\n                cq.append(cqi)\n                y.append(yi)\n                rx.append(rxi)\n                rcx.append(rxi)\n                ids.append(qa[\'id\'])\n                idxs.append(len(idxs))\n                answerss.append(answers)\n\n            if args.debug:\n                break\n\n    word2vec_dict = get_word2vec(args, word_counter)\n    lower_word2vec_dict = get_word2vec(args, lower_word_counter)\n\n    data = {\'q\': q, \'cq\': cq, \'y\': y, \'*x\': rx, \'*cx\': rcx, \'*tx\': rx, \'*stx\': rx,\n            \'idxs\': idxs, \'ids\': ids, \'answerss\': answerss}\n    shared = {\'x\': x, \'cx\': cx, \'tx\': tx, \'stx\': stx,\n              \'word_counter\': word_counter, \'char_counter\': char_counter, \'lower_word_counter\': lower_word_counter,\n              \'word2vec\': word2vec_dict, \'lower_word2vec\': lower_word2vec_dict, \'pos_counter\': pos_counter}\n\n    return data, shared\n\n\nif __name__ == ""__main__"":\n    main()'"
squad/utils.py,0,"b'import re\n\n\ndef get_2d_spans(text, tokenss):\n    spanss = []\n    cur_idx = 0\n    for tokens in tokenss:\n        spans = []\n        for token in tokens:\n            if text.find(token, cur_idx) < 0:\n                print(tokens)\n                print(""{} {} {}"".format(token, cur_idx, text))\n                raise Exception()\n            cur_idx = text.find(token, cur_idx)\n            spans.append((cur_idx, cur_idx + len(token)))\n            cur_idx += len(token)\n        spanss.append(spans)\n    return spanss\n\n\ndef get_word_span(context, wordss, start, stop):\n    spanss = get_2d_spans(context, wordss)\n    idxs = []\n    for sent_idx, spans in enumerate(spanss):\n        for word_idx, span in enumerate(spans):\n            if not (stop <= span[0] or start >= span[1]):\n                idxs.append((sent_idx, word_idx))\n\n    assert len(idxs) > 0, ""{} {} {} {}"".format(context, spanss, start, stop)\n    return idxs[0], (idxs[-1][0], idxs[-1][1] + 1)\n\n\ndef get_phrase(context, wordss, span):\n    """"""\n    Obtain phrase as substring of context given start and stop indices in word level\n    :param context:\n    :param wordss:\n    :param start: [sent_idx, word_idx]\n    :param stop: [sent_idx, word_idx]\n    :return:\n    """"""\n    start, stop = span\n    flat_start = get_flat_idx(wordss, start)\n    flat_stop = get_flat_idx(wordss, stop)\n    words = sum(wordss, [])\n    char_idx = 0\n    char_start, char_stop = None, None\n    for word_idx, word in enumerate(words):\n        char_idx = context.find(word, char_idx)\n        assert char_idx >= 0\n        if word_idx == flat_start:\n            char_start = char_idx\n        char_idx += len(word)\n        if word_idx == flat_stop - 1:\n            char_stop = char_idx\n    assert char_start is not None\n    assert char_stop is not None\n    return context[char_start:char_stop]\n\n\ndef get_flat_idx(wordss, idx):\n    return sum(len(words) for words in wordss[:idx[0]]) + idx[1]\n\n\ndef get_word_idx(context, wordss, idx):\n    spanss = get_2d_spans(context, wordss)\n    return spanss[idx[0]][idx[1]][0]\n\n\ndef process_tokens(temp_tokens):\n    tokens = []\n    for token in temp_tokens:\n        flag = False\n        l = (""-"", ""\\u2212"", ""\\u2014"", ""\\u2013"", ""/"", ""~"", \'""\', ""\'"", ""\\u201C"", ""\\u2019"", ""\\u201D"", ""\\u2018"", ""\\u00B0"")\n        # \\u2013 is en-dash. Used for number to nubmer\n        # l = (""-"", ""\\u2212"", ""\\u2014"", ""\\u2013"")\n        # l = (""\\u2013"",)\n        tokens.extend(re.split(""([{}])"".format("""".join(l)), token))\n    return tokens\n\n\ndef get_best_span(ypi, yp2i):\n    max_val = 0\n    best_word_span = (0, 1)\n    best_sent_idx = 0\n    for f, (ypif, yp2if) in enumerate(zip(ypi, yp2i)):\n        argmax_j1 = 0\n        for j in range(len(ypif)):\n            val1 = ypif[argmax_j1]\n            if val1 < ypif[j]:\n                val1 = ypif[j]\n                argmax_j1 = j\n\n            val2 = yp2if[j]\n            if val1 * val2 > max_val:\n                best_word_span = (argmax_j1, j)\n                best_sent_idx = f\n                max_val = val1 * val2\n    return ((best_sent_idx, best_word_span[0]), (best_sent_idx, best_word_span[1] + 1)), float(max_val)\n\n\ndef get_span_score_pairs(ypi, yp2i):\n    span_score_pairs = []\n    for f, (ypif, yp2if) in enumerate(zip(ypi, yp2i)):\n        for j in range(len(ypif)):\n            for k in range(j, len(yp2if)):\n                span = ((f, j), (f, k+1))\n                score = ypif[j] * yp2if[k]\n                span_score_pairs.append((span, score))\n    return span_score_pairs\n\n\n'"
tree/__init__.py,0,b''
tree/cli.py,2,"b'import os\nfrom pprint import pprint\n\nimport tensorflow as tf\n\nfrom tree.main import main as m\n\nflags = tf.app.flags\n\nflags.DEFINE_string(""model_name"", ""tree"", ""Model name [tree]"")\nflags.DEFINE_string(""data_dir"", ""data/squad"", ""Data dir [data/squad]"")\nflags.DEFINE_integer(""run_id"", 0, ""Run ID [0]"")\n\nflags.DEFINE_integer(""batch_size"", 128, ""Batch size [128]"")\nflags.DEFINE_float(""init_lr"", 0.5, ""Initial learning rate [0.5]"")\nflags.DEFINE_integer(""num_epochs"", 50, ""Total number of epochs for training [50]"")\nflags.DEFINE_integer(""num_steps"", 0, ""Number of steps [0]"")\nflags.DEFINE_integer(""eval_num_batches"", 100, ""eval num batches [100]"")\nflags.DEFINE_integer(""load_step"", 0, ""load step [0]"")\nflags.DEFINE_integer(""early_stop"", 4, ""early stop [4]"")\n\nflags.DEFINE_string(""mode"", ""test"", ""train | test | forward [test]"")\nflags.DEFINE_boolean(""load"", True, ""load saved data? [True]"")\nflags.DEFINE_boolean(""progress"", True, ""Show progress? [True]"")\nflags.DEFINE_integer(""log_period"", 100, ""Log period [100]"")\nflags.DEFINE_integer(""eval_period"", 1000, ""Eval period [1000]"")\nflags.DEFINE_integer(""save_period"", 1000, ""Save Period [1000]"")\nflags.DEFINE_float(""decay"", 0.9, ""Exponential moving average decay [0.9]"")\n\nflags.DEFINE_boolean(""draft"", False, ""Draft for quick testing? [False]"")\n\nflags.DEFINE_integer(""hidden_size"", 32, ""Hidden size [32]"")\nflags.DEFINE_float(""input_keep_prob"", 0.5, ""Input keep prob [0.5]"")\nflags.DEFINE_integer(""char_emb_size"", 8, ""Char emb size [8]"")\nflags.DEFINE_integer(""char_filter_height"", 5, ""Char filter height [5]"")\nflags.DEFINE_float(""wd"", 0.0001, ""Weight decay [0.001]"")\nflags.DEFINE_bool(""lower_word"", True, ""lower word [True]"")\nflags.DEFINE_bool(""dump_eval"", True, ""dump eval? [True]"")\n\nflags.DEFINE_integer(""word_count_th"", 100, ""word count th [100]"")\nflags.DEFINE_integer(""char_count_th"", 500, ""char count th [500]"")\nflags.DEFINE_integer(""sent_size_th"", 64, ""sent size th [64]"")\nflags.DEFINE_integer(""num_sents_th"", 8, ""num sents th [8]"")\nflags.DEFINE_integer(""ques_size_th"", 64, ""ques size th [64]"")\nflags.DEFINE_integer(""word_size_th"", 16, ""word size th [16]"")\nflags.DEFINE_integer(""tree_height_th"", 16, ""tree height th [16]"")\n\n\ndef main(_):\n    config = flags.FLAGS\n\n    config.out_dir = os.path.join(""out"", config.model_name, str(config.run_id).zfill(2))\n\n    m(config)\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
tree/evaluator.py,3,"b'import numpy as np\nimport tensorflow as tf\n\nfrom tree.read_data import DataSet\nfrom my.nltk_utils import span_f1\n\n\nclass Evaluation(object):\n    def __init__(self, data_type, global_step, idxs, yp):\n        self.data_type = data_type\n        self.global_step = global_step\n        self.idxs = idxs\n        self.yp = yp\n        self.num_examples = len(yp)\n        self.dict = {\'data_type\': data_type,\n                     \'global_step\': global_step,\n                     \'yp\': yp,\n                     \'idxs\': idxs,\n                     \'num_examples\': self.num_examples}\n        self.summaries = None\n\n    def __repr__(self):\n        return ""{} step {}"".format(self.data_type, self.global_step)\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_yp = self.yp + other.yp\n        new_idxs = self.idxs + other.idxs\n        return Evaluation(self.data_type, self.global_step, new_idxs, new_yp)\n\n    def __radd__(self, other):\n        return self.__add__(other)\n\n\nclass LabeledEvaluation(Evaluation):\n    def __init__(self, data_type, global_step, idxs, yp, y):\n        super(LabeledEvaluation, self).__init__(data_type, global_step, idxs, yp)\n        self.y = y\n        self.dict[\'y\'] = y\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_yp = self.yp + other.yp\n        new_y = self.y + other.y\n        new_idxs = self.idxs + other.idxs\n        return LabeledEvaluation(self.data_type, self.global_step, new_idxs, new_yp, new_y)\n\n\nclass AccuracyEvaluation(LabeledEvaluation):\n    def __init__(self, data_type, global_step, idxs, yp, y, correct, loss):\n        super(AccuracyEvaluation, self).__init__(data_type, global_step, idxs, yp, y)\n        self.loss = loss\n        self.correct = correct\n        self.acc = sum(correct) / len(correct)\n        self.dict[\'loss\'] = loss\n        self.dict[\'correct\'] = correct\n        self.dict[\'acc\'] = self.acc\n        loss_summary = tf.Summary(value=[tf.Summary.Value(tag=\'dev/loss\', simple_value=self.loss)])\n        acc_summary = tf.Summary(value=[tf.Summary.Value(tag=\'dev/acc\', simple_value=self.acc)])\n        self.summaries = [loss_summary, acc_summary]\n\n    def __repr__(self):\n        return ""{} step {}: accuracy={}, loss={}"".format(self.data_type, self.global_step, self.acc, self.loss)\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_idxs = self.idxs + other.idxs\n        new_yp = self.yp + other.yp\n        new_y = self.y + other.y\n        new_correct = self.correct + other.correct\n        new_loss = (self.loss * self.num_examples + other.loss * other.num_examples) / len(new_correct)\n        return AccuracyEvaluation(self.data_type, self.global_step, new_idxs, new_yp, new_y, new_correct, new_loss)\n\n\nclass Evaluator(object):\n    def __init__(self, config, model):\n        self.config = config\n        self.model = model\n\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = batch\n        feed_dict = self.model.get_feed_dict(data_set, False, supervised=False)\n        global_step, yp = sess.run([self.model.global_step, self.model.yp], feed_dict=feed_dict)\n        yp = yp[:data_set.num_examples]\n        e = Evaluation(data_set.data_type, int(global_step), idxs, yp.tolist())\n        return e\n\n    def get_evaluation_from_batches(self, sess, batches):\n        e = sum(self.get_evaluation(sess, batch) for batch in batches)\n        return e\n\n\nclass LabeledEvaluator(Evaluator):\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = batch\n        feed_dict = self.model.get_feed_dict(data_set, False, supervised=False)\n        global_step, yp = sess.run([self.model.global_step, self.model.yp], feed_dict=feed_dict)\n        yp = yp[:data_set.num_examples]\n        y = feed_dict[self.model.y]\n        e = LabeledEvaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), y.tolist())\n        return e\n\n\nclass AccuracyEvaluator(LabeledEvaluator):\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = batch\n        assert isinstance(data_set, DataSet)\n        feed_dict = self.model.get_feed_dict(data_set, False)\n        global_step, yp, loss = sess.run([self.model.global_step, self.model.yp, self.model.loss], feed_dict=feed_dict)\n        y = feed_dict[self.model.y]\n        yp = yp[:data_set.num_examples]\n        correct = [self.__class__.compare(yi, ypi) for yi, ypi in zip(y, yp)]\n        e = AccuracyEvaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), y.tolist(), correct, float(loss))\n        return e\n\n    @staticmethod\n    def compare(yi, ypi):\n        return int(np.argmax(yi)) == int(np.argmax(ypi))\n\n\nclass AccuracyEvaluator2(AccuracyEvaluator):\n    @staticmethod\n    def compare(yi, ypi):\n        i = int(np.argmax(yi.flatten()))\n        j = int(np.argmax(ypi.flatten()))\n        # print(i, j, i == j)\n        return i == j\n\n\nclass TempEvaluation(AccuracyEvaluation):\n    def __init__(self, data_type, global_step, idxs, yp, yp2, y, y2, correct, loss, f1s):\n        super(TempEvaluation, self).__init__(data_type, global_step, idxs, yp, y, correct, loss)\n        self.y2 = y2\n        self.yp2 = yp2\n        self.f1s = f1s\n        self.f1 = float(np.mean(f1s))\n        self.dict[\'y2\'] = y2\n        self.dict[\'yp2\'] = yp2\n        self.dict[\'f1s\'] = f1s\n        self.dict[\'f1\'] = self.f1\n        f1_summary = tf.Summary(value=[tf.Summary.Value(tag=\'dev/f1\', simple_value=self.f1)])\n        self.summaries.append(f1_summary)\n\n    def __add__(self, other):\n        if other == 0:\n            return self\n        assert self.data_type == other.data_type\n        assert self.global_step == other.global_step\n        new_idxs = self.idxs + other.idxs\n        new_yp = self.yp + other.yp\n        new_yp2 = self.yp2 + other.yp2\n        new_y = self.y + other.y\n        new_y2 = self.y2 + other.y2\n        new_correct = self.correct + other.correct\n        new_f1s = self.f1s + other.f1s\n        new_loss = (self.loss * self.num_examples + other.loss * other.num_examples) / len(new_correct)\n        return TempEvaluation(self.data_type, self.global_step, new_idxs, new_yp, new_yp2, new_y, new_y2, new_correct, new_loss, new_f1s)\n\n\nclass TempEvaluator(LabeledEvaluator):\n    def get_evaluation(self, sess, batch):\n        idxs, data_set = batch\n        assert isinstance(data_set, DataSet)\n        feed_dict = self.model.get_feed_dict(data_set, False)\n        global_step, yp, yp2, loss = sess.run([self.model.global_step, self.model.yp, self.model.yp2, self.model.loss], feed_dict=feed_dict)\n        y, y2 = feed_dict[self.model.y], feed_dict[self.model.y2]\n        yp, yp2 = yp[:data_set.num_examples], yp2[:data_set.num_examples]\n        correct = [self.__class__.compare(yi, y2i, ypi, yp2i) for yi, y2i, ypi, yp2i in zip(y, y2, yp, yp2)]\n        f1s = [self.__class__.span_f1(yi, y2i, ypi, yp2i) for yi, y2i, ypi, yp2i in zip(y, y2, yp, yp2)]\n        e = TempEvaluation(data_set.data_type, int(global_step), idxs, yp.tolist(), yp2.tolist(), y.tolist(), y2.tolist(), correct, float(loss), f1s)\n        return e\n\n    @staticmethod\n    def compare(yi, y2i, ypi, yp2i):\n        i = int(np.argmax(yi.flatten()))\n        j = int(np.argmax(ypi.flatten()))\n        k = int(np.argmax(y2i.flatten()))\n        l = int(np.argmax(yp2i.flatten()))\n        # print(i, j, i == j)\n        return i == j and k == l\n\n    @staticmethod\n    def span_f1(yi, y2i, ypi, yp2i):\n        true_span = (np.argmax(yi.flatten()), np.argmax(y2i.flatten())+1)\n        pred_span = (np.argmax(ypi.flatten()), np.argmax(yp2i.flatten())+1)\n        f1 = span_f1(true_span, pred_span)\n        return f1\n\n'"
tree/graph_handler.py,4,"b'import json\nfrom json import encoder\nimport os\n\nimport tensorflow as tf\n\nfrom tree.evaluator import Evaluation\nfrom my.utils import short_floats\n\n\nclass GraphHandler(object):\n    def __init__(self, config):\n        self.config = config\n        self.saver = tf.train.Saver()\n        self.writer = None\n        self.save_path = os.path.join(config.save_dir, config.model_name)\n\n    def initialize(self, sess):\n        if self.config.load:\n            self._load(sess)\n        else:\n            sess.run(tf.initialize_all_variables())\n\n        if self.config.mode == \'train\':\n            self.writer = tf.train.SummaryWriter(self.config.log_dir, graph=tf.get_default_graph())\n\n    def save(self, sess, global_step=None):\n        self.saver.save(sess, self.save_path, global_step=global_step)\n\n    def _load(self, sess):\n        config = self.config\n        if config.load_step > 0:\n            save_path = os.path.join(config.save_dir, ""{}-{}"".format(config.model_name, config.load_step))\n        else:\n            save_dir = config.save_dir\n            checkpoint = tf.train.get_checkpoint_state(save_dir)\n            assert checkpoint is not None, ""cannot load checkpoint at {}"".format(save_dir)\n            save_path = checkpoint.model_checkpoint_path\n        print(""Loading saved model from {}"".format(save_path))\n        self.saver.restore(sess, save_path)\n\n    def add_summary(self, summary, global_step):\n        self.writer.add_summary(summary, global_step)\n\n    def add_summaries(self, summaries, global_step):\n        for summary in summaries:\n            self.add_summary(summary, global_step)\n\n    def dump_eval(self, e, precision=2):\n        assert isinstance(e, Evaluation)\n        path = os.path.join(self.config.eval_dir, ""{}-{}.json"".format(e.data_type, str(e.global_step).zfill(6)))\n        with open(path, \'w\') as fh:\n            json.dump(short_floats(e.dict, precision), fh)\n\n'"
tree/main.py,3,"b'import argparse\nimport json\nimport math\nimport os\nimport shutil\nfrom pprint import pprint\n\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport numpy as np\n\nfrom tree.evaluator import AccuracyEvaluator2, Evaluator\nfrom tree.graph_handler import GraphHandler\nfrom tree.model import Model\nfrom tree.trainer import Trainer\n\nfrom tree.read_data import load_metadata, read_data, get_squad_data_filter, update_config\n\n\ndef main(config):\n    set_dirs(config)\n    if config.mode == \'train\':\n        _train(config)\n    elif config.mode == \'test\':\n        _test(config)\n    elif config.mode == \'forward\':\n        _forward(config)\n    else:\n        raise ValueError(""invalid value for \'mode\': {}"".format(config.mode))\n\n\ndef _config_draft(config):\n    if config.draft:\n        config.num_steps = 10\n        config.eval_period = 10\n        config.log_period = 1\n        config.save_period = 10\n        config.eval_num_batches = 1\n\n\ndef _train(config):\n    # load_metadata(config, \'train\')  # this updates the config file according to metadata file\n\n    data_filter = get_squad_data_filter(config)\n    train_data = read_data(config, \'train\', config.load, data_filter=data_filter)\n    dev_data = read_data(config, \'dev\', True, data_filter=data_filter)\n    update_config(config, [train_data, dev_data])\n\n    _config_draft(config)\n\n    word2vec_dict = train_data.shared[\'lower_word2vec\'] if config.lower_word else train_data.shared[\'word2vec\']\n    word2idx_dict = train_data.shared[\'word2idx\']\n    idx2vec_dict = {word2idx_dict[word]: vec for word, vec in word2vec_dict.items() if word in word2idx_dict}\n    print(""{}/{} unique words have corresponding glove vectors."".format(len(idx2vec_dict), len(word2idx_dict)))\n    emb_mat = np.array([idx2vec_dict[idx] if idx in idx2vec_dict\n                        else np.random.multivariate_normal(np.zeros(config.word_emb_size), np.eye(config.word_emb_size))\n                        for idx in range(config.word_vocab_size)])\n    config.emb_mat = emb_mat\n\n    # construct model graph and variables (using default graph)\n    pprint(config.__flags, indent=2)\n    model = Model(config)\n    trainer = Trainer(config, model)\n    evaluator = AccuracyEvaluator2(config, model)\n    graph_handler = GraphHandler(config)  # controls all tensors and variables in the graph, including loading /saving\n\n    # Variables\n    sess = tf.Session()\n    graph_handler.initialize(sess)\n\n    # begin training\n    num_steps = config.num_steps or int(config.num_epochs * train_data.num_examples / config.batch_size)\n    max_acc = 0\n    noupdate_count = 0\n    global_step = 0\n    for _, batch in tqdm(train_data.get_batches(config.batch_size, num_batches=num_steps, shuffle=True), total=num_steps):\n        global_step = sess.run(model.global_step) + 1  # +1 because all calculations are done after step\n        get_summary = global_step % config.log_period == 0\n        loss, summary, train_op = trainer.step(sess, batch, get_summary=get_summary)\n        if get_summary:\n            graph_handler.add_summary(summary, global_step)\n\n        # Occasional evaluation and saving\n        if global_step % config.save_period == 0:\n            graph_handler.save(sess, global_step=global_step)\n        if global_step % config.eval_period == 0:\n            num_batches = math.ceil(dev_data.num_examples / config.batch_size)\n            if 0 < config.eval_num_batches < num_batches:\n                num_batches = config.eval_num_batches\n            e = evaluator.get_evaluation_from_batches(\n                sess, tqdm(dev_data.get_batches(config.batch_size, num_batches=num_batches), total=num_batches))\n            graph_handler.add_summaries(e.summaries, global_step)\n            if e.acc > max_acc:\n                max_acc = e.acc\n                noupdate_count = 0\n            else:\n                noupdate_count += 1\n                if noupdate_count == config.early_stop:\n                    break\n            if config.dump_eval:\n                graph_handler.dump_eval(e)\n    if global_step % config.save_period != 0:\n        graph_handler.save(sess, global_step=global_step)\n\n\ndef _test(config):\n    test_data = read_data(config, \'test\', True)\n    update_config(config, [test_data])\n\n    _config_draft(config)\n\n    pprint(config.__flags, indent=2)\n    model = Model(config)\n    evaluator = AccuracyEvaluator2(config, model)\n    graph_handler = GraphHandler(config)  # controls all tensors and variables in the graph, including loading /saving\n\n    sess = tf.Session()\n    graph_handler.initialize(sess)\n\n    num_batches = math.ceil(test_data.num_examples / config.batch_size)\n    if 0 < config.eval_num_batches < num_batches:\n        num_batches = config.eval_num_batches\n    e = evaluator.get_evaluation_from_batches(sess, tqdm(test_data.get_batches(config.batch_size, num_batches=num_batches), total=num_batches))\n    print(e)\n    if config.dump_eval:\n        graph_handler.dump_eval(e)\n\n\ndef _forward(config):\n\n    forward_data = read_data(config, \'forward\', True)\n\n    _config_draft(config)\n\n    pprint(config.__flag, indent=2)\n    model = Model(config)\n    evaluator = Evaluator(config, model)\n    graph_handler = GraphHandler(config)  # controls all tensors and variables in the graph, including loading /saving\n\n    sess = tf.Session()\n    graph_handler.initialize(sess)\n\n    num_batches = math.ceil(forward_data.num_examples / config.batch_size)\n    if 0 < config.eval_num_batches < num_batches:\n        num_batches = config.eval_num_batches\n    e = evaluator.get_evaluation_from_batches(sess, tqdm(forward_data.get_batches(config.batch_size, num_batches=num_batches), total=num_batches))\n    print(e)\n    if config.dump_eval:\n        graph_handler.dump_eval(e)\n\n\ndef set_dirs(config):\n    # create directories\n    if not config.load and os.path.exists(config.out_dir):\n        shutil.rmtree(config.out_dir)\n\n    config.save_dir = os.path.join(config.out_dir, ""save"")\n    config.log_dir = os.path.join(config.out_dir, ""log"")\n    config.eval_dir = os.path.join(config.out_dir, ""eval"")\n    if not os.path.exists(config.out_dir):\n        os.makedirs(config.out_dir)\n    if not os.path.exists(config.save_dir):\n        os.mkdir(config.save_dir)\n    if not os.path.exists(config.log_dir):\n        os.mkdir(config.eval_dir)\n\n\ndef _get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""config_path"")\n    return parser.parse_args()\n\n\nclass Config(object):\n    def __init__(self, **entries):\n        self.__dict__.update(entries)\n\n\ndef _run():\n    args = _get_args()\n    with open(args.config_path, \'r\') as fh:\n        config = Config(**json.load(fh))\n        main(config)\n\n\nif __name__ == ""__main__"":\n    _run()\n'"
tree/model.py,61,"b'import nltk\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.ops.rnn_cell import BasicLSTMCell\n\nfrom my.nltk_utils import tree2matrix, find_max_f1_subtree, load_compressed_tree, set_span\nfrom tree.read_data import DataSet\nfrom my.tensorflow import exp_mask, get_initializer\nfrom my.tensorflow.nn import linear\nfrom my.tensorflow.rnn import bidirectional_dynamic_rnn, dynamic_rnn\nfrom my.tensorflow.rnn_cell import SwitchableDropoutWrapper, NoOpCell, TreeRNNCell\n\n\nclass Model(object):\n    def __init__(self, config):\n        self.config = config\n        self.global_step = tf.get_variable(\'global_step\', shape=[], dtype=\'int32\',\n                                           initializer=tf.constant_initializer(0), trainable=False)\n\n        # Define forward inputs here\n        N, M, JX, JQ, VW, VC, W, H = \\\n            config.batch_size, config.max_num_sents, config.max_sent_size, \\\n            config.max_ques_size, config.word_vocab_size, config.char_vocab_size, config.max_word_size, config.max_tree_height\n        self.x = tf.placeholder(\'int32\', [None, M, JX], name=\'x\')\n        self.cx = tf.placeholder(\'int32\', [None, M, JX, W], name=\'cx\')\n        self.q = tf.placeholder(\'int32\', [None, JQ], name=\'q\')\n        self.cq = tf.placeholder(\'int32\', [None, JQ, W], name=\'cq\')\n        self.tx = tf.placeholder(\'int32\', [None, M, H, JX], name=\'tx\')\n        self.tx_edge_mask = tf.placeholder(\'bool\', [None, M, H, JX, JX], name=\'tx_edge_mask\')\n        self.y = tf.placeholder(\'bool\', [None, M, H, JX], name=\'y\')\n        self.is_train = tf.placeholder(\'bool\', [], name=\'is_train\')\n\n        # Define misc\n\n        # Forward outputs / loss inputs\n        self.logits = None\n        self.yp = None\n        self.var_list = None\n\n        # Loss outputs\n        self.loss = None\n\n        self._build_forward()\n        self._build_loss()\n\n        self.ema_op = self._get_ema_op()\n        self.summary = tf.merge_all_summaries()\n\n    def _build_forward(self):\n        config = self.config\n        N, M, JX, JQ, VW, VC, d, dc, W = \\\n            config.batch_size, config.max_num_sents, config.max_sent_size, \\\n            config.max_ques_size, config.word_vocab_size, config.char_vocab_size, config.hidden_size, \\\n            config.char_emb_size, config.max_word_size\n        H = config.max_tree_height\n\n        x_mask = self.x > 0\n        q_mask = self.q > 0\n        tx_mask = self.tx > 0  # [N, M, H, JX]\n\n        with tf.variable_scope(""char_emb""):\n            char_emb_mat = tf.get_variable(""char_emb_mat"", shape=[VC, dc], dtype=\'float\')\n            Acx = tf.nn.embedding_lookup(char_emb_mat, self.cx)  # [N, M, JX, W, dc]\n            Acq = tf.nn.embedding_lookup(char_emb_mat, self.cq)  # [N, JQ, W, dc]\n\n            filter = tf.get_variable(""filter"", shape=[1, config.char_filter_height, dc, d], dtype=\'float\')\n            bias = tf.get_variable(""bias"", shape=[d], dtype=\'float\')\n            strides = [1, 1, 1, 1]\n            Acx = tf.reshape(Acx, [-1, JX, W, dc])\n            Acq = tf.reshape(Acq, [-1, JQ, W, dc])\n            xxc = tf.nn.conv2d(Acx, filter, strides, ""VALID"") + bias  # [N*M, JX, W/filter_stride, d]\n            qqc = tf.nn.conv2d(Acq, filter, strides, ""VALID"") + bias  # [N, JQ, W/filter_stride, d]\n            xxc = tf.reshape(tf.reduce_max(tf.nn.relu(xxc), 2), [-1, M, JX, d])\n            qqc = tf.reshape(tf.reduce_max(tf.nn.relu(qqc), 2), [-1, JQ, d])\n\n        with tf.variable_scope(""word_emb""):\n            if config.mode == \'train\':\n                word_emb_mat = tf.get_variable(""word_emb_mat"", dtype=\'float\', shape=[VW, config.word_emb_size], initializer=get_initializer(config.emb_mat))\n            else:\n                word_emb_mat = tf.get_variable(""word_emb_mat"", shape=[VW, config.word_emb_size], dtype=\'float\')\n            Ax = tf.nn.embedding_lookup(word_emb_mat, self.x)  # [N, M, JX, d]\n            Aq = tf.nn.embedding_lookup(word_emb_mat, self.q)  # [N, JQ, d]\n            # Ax = linear([Ax], d, False, scope=\'Ax_reshape\')\n            # Aq = linear([Aq], d, False, scope=\'Aq_reshape\')\n\n        xx = tf.concat(3, [xxc, Ax])  # [N, M, JX, 2d]\n        qq = tf.concat(2, [qqc, Aq])  # [N, JQ, 2d]\n        D = d + config.word_emb_size\n\n        with tf.variable_scope(""pos_emb""):\n            pos_emb_mat = tf.get_variable(""pos_emb_mat"", shape=[config.pos_vocab_size, d], dtype=\'float\')\n            Atx = tf.nn.embedding_lookup(pos_emb_mat, self.tx)  # [N, M, H, JX, d]\n\n        cell = BasicLSTMCell(D, state_is_tuple=True)\n        cell = SwitchableDropoutWrapper(cell, self.is_train, input_keep_prob=config.input_keep_prob)\n        x_len = tf.reduce_sum(tf.cast(x_mask, \'int32\'), 2)  # [N, M]\n        q_len = tf.reduce_sum(tf.cast(q_mask, \'int32\'), 1)  # [N]\n\n        with tf.variable_scope(""rnn""):\n            (fw_h, bw_h), _ = bidirectional_dynamic_rnn(cell, cell, xx, x_len, dtype=\'float\', scope=\'start\')  # [N, M, JX, 2d]\n            tf.get_variable_scope().reuse_variables()\n            (fw_us, bw_us), (_, (fw_u, bw_u)) = bidirectional_dynamic_rnn(cell, cell, qq, q_len, dtype=\'float\', scope=\'start\')  # [N, J, d], [N, d]\n            u = (fw_u + bw_u) / 2.0\n            h = (fw_h + bw_h) / 2.0\n\n        with tf.variable_scope(""h""):\n            no_op_cell = NoOpCell(D)\n            tree_rnn_cell = TreeRNNCell(no_op_cell, d, tf.reduce_max)\n            initial_state = tf.reshape(h, [N*M*JX, D])  # [N*M*JX, D]\n            inputs = tf.concat(4, [Atx, tf.cast(self.tx_edge_mask, \'float\')])  # [N, M, H, JX, d+JX]\n            inputs = tf.reshape(tf.transpose(inputs, [0, 1, 3, 2, 4]), [N*M*JX, H, d + JX])  # [N*M*JX, H, d+JX]\n            length = tf.reshape(tf.reduce_sum(tf.cast(tx_mask, \'int32\'), 2), [N*M*JX])\n            # length = tf.reshape(tf.reduce_sum(tf.cast(tf.transpose(tx_mask, [0, 1, 3, 2]), \'float\'), 3), [-1])\n            h, _ = dynamic_rnn(tree_rnn_cell, inputs, length, initial_state=initial_state)  # [N*M*JX, H, D]\n            h = tf.transpose(tf.reshape(h, [N, M, JX, H, D]), [0, 1, 3, 2, 4])  # [N, M, H, JX, D]\n\n        u = tf.expand_dims(tf.expand_dims(tf.expand_dims(u, 1), 1), 1)  # [N, 1, 1, 1, 4d]\n        dot = linear(h * u, 1, True, squeeze=True, scope=\'dot\')  # [N, M, H, JX]\n        # self.logits = tf.reshape(dot, [N, M * H * JX])\n        self.logits = tf.reshape(exp_mask(dot, tx_mask), [N, M * H * JX])  # [N, M, H, JX]\n        self.yp = tf.reshape(tf.nn.softmax(self.logits), [N, M, H, JX])\n\n    def _build_loss(self):\n        config = self.config\n        N, M, JX, JQ, VW, VC = \\\n            config.batch_size, config.max_num_sents, config.max_sent_size, \\\n            config.max_ques_size, config.word_vocab_size, config.char_vocab_size\n        H = config.max_tree_height\n        ce_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n            self.logits, tf.cast(tf.reshape(self.y, [N, M * H * JX]), \'float\')))\n        tf.add_to_collection(\'losses\', ce_loss)\n        self.loss = tf.add_n(tf.get_collection(\'losses\'), name=\'loss\')\n        tf.scalar_summary(self.loss.op.name, self.loss)\n        tf.add_to_collection(\'ema/scalar\', self.loss)\n\n    def _get_ema_op(self):\n        ema = tf.train.ExponentialMovingAverage(self.config.decay)\n        ema_op = ema.apply(tf.get_collection(""ema/scalar"") + tf.get_collection(""ema/histogram""))\n        for var in tf.get_collection(""ema/scalar""):\n            ema_var = ema.average(var)\n            tf.scalar_summary(ema_var.op.name, ema_var)\n        for var in tf.get_collection(""ema/histogram""):\n            ema_var = ema.average(var)\n            tf.histogram_summary(ema_var.op.name, ema_var)\n        return ema_op\n\n    def get_loss(self):\n        return self.loss\n\n    def get_global_step(self):\n        return self.global_step\n\n    def get_var_list(self):\n        return self.var_list\n\n    def get_feed_dict(self, batch, is_train, supervised=True):\n        assert isinstance(batch, DataSet)\n        config = self.config\n        N, M, JX, JQ, VW, VC, d, W, H = \\\n            config.batch_size, config.max_num_sents, config.max_sent_size, \\\n            config.max_ques_size, config.word_vocab_size, config.char_vocab_size, config.hidden_size, config.max_word_size, \\\n            config.max_tree_height\n        feed_dict = {}\n\n        x = np.zeros([N, M, JX], dtype=\'int32\')\n        cx = np.zeros([N, M, JX, W], dtype=\'int32\')\n        q = np.zeros([N, JQ], dtype=\'int32\')\n        cq = np.zeros([N, JQ, W], dtype=\'int32\')\n        tx = np.zeros([N, M, H, JX], dtype=\'int32\')\n        tx_edge_mask = np.zeros([N, M, H, JX, JX], dtype=\'bool\')\n\n        feed_dict[self.x] = x\n        feed_dict[self.cx] = cx\n        feed_dict[self.q] = q\n        feed_dict[self.cq] = cq\n        feed_dict[self.tx] = tx\n        feed_dict[self.tx_edge_mask] = tx_edge_mask\n        feed_dict[self.is_train] = is_train\n\n        def _get_word(word):\n            d = batch.shared[\'word2idx\']\n            for each in (word, word.lower(), word.capitalize(), word.upper()):\n                if each in d:\n                    return d[each]\n            return 1\n\n        def _get_char(char):\n            d = batch.shared[\'char2idx\']\n            if char in d:\n                return d[char]\n            return 1\n\n        def _get_pos(tree):\n            d = batch.shared[\'pos2idx\']\n            if tree.label() in d:\n                return d[tree.label()]\n            return 1\n\n        for i, xi in enumerate(batch.data[\'x\']):\n            for j, xij in enumerate(xi):\n                for k, xijk in enumerate(xij):\n                    x[i, j, k] = _get_word(xijk)\n\n        for i, cxi in enumerate(batch.data[\'cx\']):\n            for j, cxij in enumerate(cxi):\n                for k, cxijk in enumerate(cxij):\n                    for l, cxijkl in enumerate(cxijk):\n                        cx[i, j, k, l] = _get_char(cxijkl)\n                        if l + 1 == config.max_word_size:\n                            break\n\n        for i, qi in enumerate(batch.data[\'q\']):\n            for j, qij in enumerate(qi):\n                q[i, j] = _get_word(qij)\n\n        for i, cqi in enumerate(batch.data[\'cq\']):\n            for j, cqij in enumerate(cqi):\n                for k, cqijk in enumerate(cqij):\n                    cq[i, j, k] = _get_char(cqijk)\n                    if k + 1 == config.max_word_size:\n                        break\n\n        for i, txi in enumerate(batch.data[\'stx\']):\n            for j, txij in enumerate(txi):\n                txij_mat, txij_mask = tree2matrix(nltk.tree.Tree.fromstring(txij), _get_pos, row_size=H, col_size=JX)\n                tx[i, j, :, :], tx_edge_mask[i, j, :, :, :] = txij_mat, txij_mask\n\n        if supervised:\n            y = np.zeros([N, M, H, JX], dtype=\'bool\')\n            feed_dict[self.y] = y\n            for i, yi in enumerate(batch.data[\'y\']):\n                start_idx, stop_idx = yi\n                sent_idx = start_idx[0]\n                if start_idx[0] == stop_idx[0]:\n                    span = [start_idx[1], stop_idx[1]]\n                else:\n                    span = [start_idx[1], len(batch.data[\'x\'][sent_idx])]\n                tree = nltk.tree.Tree.fromstring(batch.data[\'stx\'][i][sent_idx])\n                set_span(tree)\n                best_subtree = find_max_f1_subtree(tree, span)\n\n                def _get_y(t):\n                    return t == best_subtree\n\n                yij, _ = tree2matrix(tree, _get_y, H, JX, dtype=\'bool\')\n                y[i, sent_idx, :, :] = yij\n\n        return feed_dict\n'"
tree/read_data.py,0,"b'import json\nimport os\nimport random\nimport itertools\nimport math\n\nimport nltk\n\nfrom my.nltk_utils import load_compressed_tree\nfrom my.utils import index\n\n\nclass DataSet(object):\n    def __init__(self, data, data_type, shared=None, valid_idxs=None):\n        total_num_examples = len(next(iter(data.values())))\n        self.data = data  # e.g. {\'X\': [0, 1, 2], \'Y\': [2, 3, 4]}\n        self.data_type = data_type\n        self.shared = shared\n        self.valid_idxs = range(total_num_examples) if valid_idxs is None else valid_idxs\n        self.num_examples = len(self.valid_idxs)\n\n    def get_batches(self, batch_size, num_batches=None, shuffle=False):\n        num_batches_per_epoch = int(math.ceil(self.num_examples / batch_size))\n        if num_batches is None:\n            num_batches = num_batches_per_epoch\n        num_epochs = int(math.ceil(num_batches / num_batches_per_epoch))\n\n        idxs = itertools.chain.from_iterable(random.sample(self.valid_idxs, len(self.valid_idxs))\n                                             if shuffle else self.valid_idxs\n                                             for _ in range(num_epochs))\n        for _ in range(num_batches):\n            batch_idxs = tuple(itertools.islice(idxs, batch_size))\n            batch_data = {}\n            for key, val in self.data.items():\n                if key.startswith(\'*\'):\n                    assert self.shared is not None\n                    shared_key = key[1:]\n                    batch_data[shared_key] = [index(self.shared[shared_key], val[idx]) for idx in batch_idxs]\n                else:\n                    batch_data[key] = list(map(val.__getitem__, batch_idxs))\n\n            batch_ds = DataSet(batch_data, self.data_type, shared=self.shared)\n            yield batch_idxs, batch_ds\n\n\nclass SquadDataSet(DataSet):\n    def __init__(self, data, data_type, shared=None, valid_idxs=None):\n        super(SquadDataSet, self).__init__(data, data_type, shared=shared, valid_idxs=valid_idxs)\n\n\ndef load_metadata(config, data_type):\n    metadata_path = os.path.join(config.data_dir, ""metadata_{}.json"".format(data_type))\n    with open(metadata_path, \'r\') as fh:\n        metadata = json.load(fh)\n        for key, val in metadata.items():\n            config.__setattr__(key, val)\n        return metadata\n\n\ndef read_data(config, data_type, ref, data_filter=None):\n    data_path = os.path.join(config.data_dir, ""data_{}.json"".format(data_type))\n    shared_path = os.path.join(config.data_dir, ""shared_{}.json"".format(data_type))\n    with open(data_path, \'r\') as fh:\n        data = json.load(fh)\n    with open(shared_path, \'r\') as fh:\n        shared = json.load(fh)\n\n    num_examples = len(next(iter(data.values())))\n    if data_filter is None:\n        valid_idxs = range(num_examples)\n    else:\n        mask = []\n        keys = data.keys()\n        values = data.values()\n        for vals in zip(*values):\n            each = {key: val for key, val in zip(keys, vals)}\n            mask.append(data_filter(each, shared))\n        valid_idxs = [idx for idx in range(len(mask)) if mask[idx]]\n\n    print(""Loaded {}/{} examples from {}"".format(len(valid_idxs), num_examples, data_type))\n\n    shared_path = os.path.join(config.out_dir, ""shared.json"")\n    if not ref:\n        word_counter = shared[\'lower_word_counter\'] if config.lower_word else shared[\'word_counter\']\n        char_counter = shared[\'char_counter\']\n        pos_counter = shared[\'pos_counter\']\n        shared[\'word2idx\'] = {word: idx + 2 for idx, word in\n                              enumerate(word for word, count in word_counter.items()\n                                        if count > config.word_count_th)}\n        shared[\'char2idx\'] = {char: idx + 2 for idx, char in\n                              enumerate(char for char, count in char_counter.items()\n                                        if count > config.char_count_th)}\n        shared[\'pos2idx\'] = {pos: idx + 2 for idx, pos in enumerate(pos_counter.keys())}\n        NULL = ""-NULL-""\n        UNK = ""-UNK-""\n        shared[\'word2idx\'][NULL] = 0\n        shared[\'word2idx\'][UNK] = 1\n        shared[\'char2idx\'][NULL] = 0\n        shared[\'char2idx\'][UNK] = 1\n        shared[\'pos2idx\'][NULL] = 0\n        shared[\'pos2idx\'][UNK] = 1\n        json.dump({\'word2idx\': shared[\'word2idx\'], \'char2idx\': shared[\'char2idx\'],\n                   \'pos2idx\': shared[\'pos2idx\']}, open(shared_path, \'w\'))\n    else:\n        new_shared = json.load(open(shared_path, \'r\'))\n        for key, val in new_shared.items():\n            shared[key] = val\n\n    data_set = DataSet(data, data_type, shared=shared, valid_idxs=valid_idxs)\n    return data_set\n\n\ndef get_squad_data_filter(config):\n    def data_filter(data_point, shared):\n        assert shared is not None\n        rx, rcx, q, cq, y  = (data_point[key] for key in (\'*x\', \'*cx\', \'q\', \'cq\', \'y\'))\n        x, cx, stx = shared[\'x\'], shared[\'cx\'], shared[\'stx\']\n        if len(q) > config.ques_size_th:\n            return False\n        xi = x[rx[0]][rx[1]]\n        if len(xi) > config.num_sents_th:\n            return False\n        if any(len(xij) > config.sent_size_th for xij in xi):\n            return False\n        stxi = stx[rx[0]][rx[1]]\n        if any(nltk.tree.Tree.fromstring(s).height() > config.tree_height_th for s in stxi):\n            return False\n        return True\n    return data_filter\n\n\ndef update_config(config, data_sets):\n    config.max_num_sents = 0\n    config.max_sent_size = 0\n    config.max_ques_size = 0\n    config.max_word_size = 0\n    config.max_tree_height = 0\n    for data_set in data_sets:\n        data = data_set.data\n        shared = data_set.shared\n        for idx in data_set.valid_idxs:\n            rx = data[\'*x\'][idx]\n            q = data[\'q\'][idx]\n            sents = shared[\'x\'][rx[0]][rx[1]]\n            trees = map(nltk.tree.Tree.fromstring, shared[\'stx\'][rx[0]][rx[1]])\n            config.max_tree_height = max(config.max_tree_height, max(tree.height() for tree in trees))\n            config.max_num_sents = max(config.max_num_sents, len(sents))\n            config.max_sent_size = max(config.max_sent_size, max(map(len, sents)))\n            config.max_word_size = max(config.max_word_size, max(len(word) for sent in sents for word in sent))\n            if len(q) > 0:\n                config.max_ques_size = max(config.max_ques_size, len(q))\n                config.max_word_size = max(config.max_word_size, max(len(word) for word in q))\n\n    config.max_word_size = min(config.max_word_size, config.word_size_th)\n\n    config.char_vocab_size = len(data_sets[0].shared[\'char2idx\'])\n    config.word_emb_size = len(next(iter(data_sets[0].shared[\'word2vec\'].values())))\n    config.word_vocab_size = len(data_sets[0].shared[\'word2idx\'])\n    config.pos_vocab_size = len(data_sets[0].shared[\'pos2idx\'])\n'"
tree/trainer.py,4,"b'import tensorflow as tf\n\nfrom tree.model import Model\n\n\nclass Trainer(object):\n    def __init__(self, config, model):\n        assert isinstance(model, Model)\n        self.config = config\n        self.model = model\n        self.opt = tf.train.AdagradOptimizer(config.init_lr)\n        self.loss = model.get_loss()\n        self.var_list = model.get_var_list()\n        self.global_step = model.get_global_step()\n        self.ema_op = model.ema_op\n        self.summary = model.summary\n        self.grads = self.opt.compute_gradients(self.loss, var_list=self.var_list)\n        opt_op = self.opt.apply_gradients(self.grads, global_step=self.global_step)\n\n        # Define train op\n        with tf.control_dependencies([opt_op]):\n            self.train_op = tf.group(self.ema_op)\n\n    def get_train_op(self):\n        return self.train_op\n\n    def step(self, sess, batch, get_summary=False):\n        assert isinstance(sess, tf.Session)\n        feed_dict = self.model.get_feed_dict(batch, True)\n        if get_summary:\n            loss, summary, train_op = \\\n                sess.run([self.loss, self.summary, self.train_op], feed_dict=feed_dict)\n        else:\n            loss, train_op = sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n            summary = None\n        return loss, summary, train_op\n'"
tree/visualizer.py,0,"b'import shutil\nfrom collections import OrderedDict\nimport http.server\nimport socketserver\nimport argparse\nimport json\nimport os\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom jinja2 import Environment, FileSystemLoader\n\n\ndef bool_(string):\n    if string == \'True\':\n        return True\n    elif string == \'False\':\n        return False\n    else:\n        raise Exception()\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""--model_name"", type=str, default=\'basic\')\n    parser.add_argument(""--data_type"", type=str, default=\'dev\')\n    parser.add_argument(""--step"", type=int, default=5000)\n    parser.add_argument(""--template_name"", type=str, default=""visualizer.html"")\n    parser.add_argument(""--num_per_page"", type=int, default=100)\n    parser.add_argument(""--data_dir"", type=str, default=""data/squad"")\n    parser.add_argument(""--port"", type=int, default=8000)\n    parser.add_argument(""--host"", type=str, default=""0.0.0.0"")\n    parser.add_argument(""--open"", type=str, default=\'False\')\n    parser.add_argument(""--run_id"", type=str, default=""0"")\n\n    args = parser.parse_args()\n    return args\n\n\ndef _decode(decoder, sent):\n    return "" "".join(decoder[idx] for idx in sent)\n\n\ndef accuracy2_visualizer(args):\n    model_name = args.model_name\n    data_type = args.data_type\n    num_per_page = args.num_per_page\n    data_dir = args.data_dir\n    run_id = args.run_id.zfill(2)\n    step = args.step\n\n    eval_path =os.path.join(""out"", model_name, run_id, ""eval"", ""{}-{}.json"".format(data_type, str(step).zfill(6)))\n    eval_ = json.load(open(eval_path, \'r\'))\n\n    _id = 0\n    html_dir = ""/tmp/list_results%d"" % _id\n    while os.path.exists(html_dir):\n        _id += 1\n        html_dir = ""/tmp/list_results%d"" % _id\n\n    if os.path.exists(html_dir):\n        shutil.rmtree(html_dir)\n    os.mkdir(html_dir)\n\n    cur_dir = os.path.dirname(os.path.realpath(__file__))\n    templates_dir = os.path.join(cur_dir, \'templates\')\n    env = Environment(loader=FileSystemLoader(templates_dir))\n    env.globals.update(zip=zip, reversed=reversed)\n    template = env.get_template(args.template_name)\n\n    data_path = os.path.join(data_dir, ""data_{}.json"".format(data_type))\n    shared_path = os.path.join(data_dir, ""shared_{}.json"".format(data_type))\n    data = json.load(open(data_path, \'r\'))\n    shared = json.load(open(shared_path, \'r\'))\n\n    rows = []\n    for i, (idx, yi, ypi) in enumerate(zip(*[eval_[key] for key in (\'idxs\', \'y\', \'yp\')])):\n        id_, q, rx = (data[key][idx] for key in (\'ids\', \'q\', \'*x\'))\n        x = shared[\'x\'][rx[0]][rx[1]]\n        ques = ["" "".join(q)]\n        para = [[word for word in sent] for sent in x]\n        row = {\n            \'id\': id_,\n            \'title\': ""Hello world!"",\n            \'ques\': ques,\n            \'para\': para,\n            \'y\': yi,\n            \'y2\': yi,\n            \'yp\': ypi,\n            \'yp2\': ypi,\n            \'a\': """"\n               }\n        rows.append(row)\n\n        if i % num_per_page == 0:\n            html_path = os.path.join(html_dir, ""%s.html"" % str(i).zfill(8))\n\n        if (i + 1) % num_per_page == 0 or (i + 1) == len(eval_[\'y\']):\n            var_dict = {\'title\': ""Accuracy Visualization"",\n                        \'rows\': rows\n                        }\n            with open(html_path, ""wb"") as f:\n                f.write(template.render(**var_dict).encode(\'UTF-8\'))\n            rows = []\n\n    os.chdir(html_dir)\n    port = args.port\n    host = args.host\n    # Overriding to suppress log message\n    class MyHandler(http.server.SimpleHTTPRequestHandler):\n        def log_message(self, format, *args):\n            pass\n    handler = MyHandler\n    httpd = socketserver.TCPServer((host, port), handler)\n    if args.open == \'True\':\n        os.system(""open http://%s:%d"" % (args.host, args.port))\n    print(""serving at %s:%d"" % (host, port))\n    httpd.serve_forever()\n\n\nif __name__ == ""__main__"":\n    ARGS = get_args()\n    accuracy2_visualizer(ARGS)'"
visualization/compare_models.py,0,"b'import numpy as np\nfrom collections import Counter\nimport string\nimport re\nimport argparse\nimport os\nimport json\nimport nltk\nfrom matplotlib_venn import venn2\nfrom matplotlib import pyplot as plt\n\n\nclass Question:\n    def __init__(self, id, question_text, ground_truth, model_names):\n        self.id = id\n        self.question_text = self.normalize_answer(question_text)\n        self.question_head_ngram = []\n        self.question_tokens = nltk.word_tokenize(self.question_text)\n        for nc in range(3):\n            self.question_head_ngram.append(\' \'.join(self.question_tokens[0:nc]))\n        self.ground_truth = ground_truth\n        self.model_names = model_names\n        self.em = np.zeros(2)\n        self.f1 = np.zeros(2)\n        self.answer_text = []\n\n    def add_answers(self, answer_model_1, answer_model_2):\n        self.answer_text.append(answer_model_1)\n        self.answer_text.append(answer_model_2)\n        self.eval()\n\n    def eval(self):\n        for model_count in range(2):\n            self.em[model_count] = self.metric_max_over_ground_truths(self.exact_match_score, self.answer_text[model_count], self.ground_truth)\n            self.f1[model_count] = self.metric_max_over_ground_truths(self.f1_score, self.answer_text[model_count], self.ground_truth)\n\n    def normalize_answer(self, s):\n        """"""Lower text and remove punctuation, articles and extra whitespace.""""""\n        def remove_articles(text):\n            return re.sub(r\'\\b(a|an|the)\\b\', \' \', text)\n\n        def white_space_fix(text):\n            return \' \'.join(text.split())\n\n        def remove_punc(text):\n            exclude = set(string.punctuation)\n            return \'\'.join(ch for ch in text if ch not in exclude)\n\n        def lower(text):\n            return text.lower()\n\n        return white_space_fix(remove_articles(remove_punc(lower(s))))\n\n    def f1_score(self, prediction, ground_truth):\n        prediction_tokens = self.normalize_answer(prediction).split()\n        ground_truth_tokens = self.normalize_answer(ground_truth).split()\n        common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n        num_same = sum(common.values())\n        if num_same == 0:\n            return 0\n        precision = 1.0 * num_same / len(prediction_tokens)\n        recall = 1.0 * num_same / len(ground_truth_tokens)\n        f1 = (2 * precision * recall) / (precision + recall)\n        return f1\n\n    def exact_match_score(self, prediction, ground_truth):\n        return (self.normalize_answer(prediction) == self.normalize_answer(ground_truth))\n\n    def metric_max_over_ground_truths(self, metric_fn, prediction, ground_truths):\n        scores_for_ground_truths = []\n        for ground_truth in ground_truths:\n            score = metric_fn(prediction, ground_truth)\n            scores_for_ground_truths.append(score)\n        return max(scores_for_ground_truths)\n\n\ndef safe_dict_access(in_dict, in_key, default_string=\'some junk string\'):\n    if in_key in in_dict:\n        return in_dict[in_key]\n    else:\n        return default_string\n\n\ndef aggregate_metrics(questions):\n    total = len(questions)\n    exact_match = np.zeros(2)\n    f1_scores = np.zeros(2)\n\n    for mc in range(2):\n        exact_match[mc] = 100 * np.sum(np.array([questions[x].em[mc] for x in questions])) / total\n        f1_scores[mc] = 100 * np.sum(np.array([questions[x].f1[mc] for x in questions])) / total\n\n    model_names = questions[list(questions.keys())[0]].model_names\n    print(\'\\nAggregate Scores:\')\n    for model_count in range(2):\n        print(\'Model {0} EM = {1:.2f}\'.format(model_names[model_count], exact_match[model_count]))\n        print(\'Model {0} F1 = {1:.2f}\'.format(model_names[model_count], f1_scores[model_count]))\n\n\ndef venn_diagram(questions, output_dir):\n    em_model1_ids = [x for x in questions if questions[x].em[0] == 1]\n    em_model2_ids = [x for x in questions if questions[x].em[1] == 1]\n    model_names = questions[list(questions.keys())[0]].model_names\n    print(\'\\nVenn diagram\')\n\n    correct_model1 = em_model1_ids\n    correct_model2 = em_model2_ids\n    correct_model1_and_model2 = list(set(em_model1_ids).intersection(set(em_model2_ids)))\n    correct_model1_and_not_model2 = list(set(em_model1_ids) - set(em_model2_ids))\n    correct_model2_and_not_model1 = list(set(em_model2_ids) - set(em_model1_ids))\n\n    print(\'{0} answers correctly = {1}\'.format(model_names[0], len(correct_model1)))\n    print(\'{0} answers correctly = {1}\'.format(model_names[1], len(correct_model2)))\n    print(\'Both answer correctly = {1}\'.format(model_names[0], len(correct_model1_and_model2)))\n    print(\'{0} correct & {1} incorrect = {2}\'.format(model_names[0], model_names[1], len(correct_model1_and_not_model2)))\n    print(\'{0} correct & {1} incorrect = {2}\'.format(model_names[1], model_names[0], len(correct_model2_and_not_model1)))\n\n    plt.clf()\n    venn_diagram_plot = venn2(\n        subsets=(len(correct_model1_and_not_model2), len(correct_model2_and_not_model1), len(correct_model1_and_model2)),\n        set_labels=(\'{0} correct\'.format(model_names[0]), \'{0} correct\'.format(model_names[1]), \'Both correct\'),\n        set_colors=(\'r\', \'b\'),\n        alpha=0.3,\n        normalize_to=1\n    )\n    plt.savefig(os.path.join(output_dir, \'venn_diagram.png\'))\n    plt.close()\n    return correct_model1, correct_model2, correct_model1_and_model2, correct_model1_and_not_model2, correct_model2_and_not_model1\n\n\ndef get_head_ngrams(questions, num_grams):\n    head_ngrams = []\n    for question in questions.values():\n        head_ngrams.append(question.question_head_ngram[num_grams])\n    return head_ngrams\n\n\ndef get_head_ngram_frequencies(questions, head_ngrams, num_grams):\n    head_ngram_frequencies = {}\n    for current_ngram in head_ngrams:\n        head_ngram_frequencies[current_ngram] = 0\n    for question in questions.values():\n        head_ngram_frequencies[question.question_head_ngram[num_grams]] += 1\n    return head_ngram_frequencies\n\n\ndef get_head_ngram_statistics(questions, correct_model1, correct_model2, correct_model1_and_model2, correct_model1_and_not_model2, correct_model2_and_not_model1, output_dir, num_grams=2, top_count=25):\n    # Head ngram statistics\n    head_ngrams = get_head_ngrams(questions, num_grams)\n\n    # Get head_ngram_frequencies (hnf)\n    hnf_all = get_head_ngram_frequencies(questions, head_ngrams, num_grams)\n    hnf_correct_model1 = get_head_ngram_frequencies({qid: questions[qid] for qid in correct_model1}, head_ngrams, num_grams)\n    hnf_correct_model2 = get_head_ngram_frequencies({qid: questions[qid] for qid in correct_model2}, head_ngrams, num_grams)\n    hnf_correct_model1_and_model2 = get_head_ngram_frequencies({qid: questions[qid] for qid in correct_model1_and_model2}, head_ngrams, num_grams)\n    hnf_correct_model1_and_not_model2 = get_head_ngram_frequencies({qid: questions[qid] for qid in correct_model1_and_not_model2}, head_ngrams, num_grams)\n    hnf_correct_model2_and_not_model1 = get_head_ngram_frequencies({qid: questions[qid] for qid in correct_model2_and_not_model1}, head_ngrams, num_grams)\n\n    sorted_bigrams_all = sorted(hnf_all.items(), key=lambda x: x[1], reverse=True)\n    top_bigrams = [x[0] for x in sorted_bigrams_all[0:top_count]]\n\n    counts_total = [hnf_all[x] for x in top_bigrams]\n    counts_model1 = [hnf_correct_model1[x] for x in top_bigrams]\n    counts_model2 = [hnf_correct_model2[x] for x in top_bigrams]\n    counts_model1_and_model2 = [hnf_correct_model1_and_model2[x] for x in top_bigrams]\n    counts_model1_and_not_model2 = [hnf_correct_model1_and_not_model2[x] for x in top_bigrams]\n    counts_model2_and_not_model1 = [hnf_correct_model2_and_not_model1[x] for x in top_bigrams]\n\n    top_bigrams_with_counts = []\n    for cc in range(len(top_bigrams)):\n        top_bigrams_with_counts.append(\'{0} ({1})\'.format(top_bigrams[cc], counts_total[cc]))\n\n    plt.clf()\n    fig, ax = plt.subplots(figsize=(6, 10))\n\n    ylocs = list(range(top_count))\n    counts_model1_percent = 100 * np.array(counts_model1) / np.array(counts_total)\n    plt.barh([top_count - x for x in ylocs], counts_model1_percent, height=0.4, alpha=0.5, color=\'#EE3224\', label=top_bigrams)\n    counts_model2_percent = 100 * np.array(counts_model2) / np.array(counts_total)\n    plt.barh([top_count - x+0.4 for x in ylocs], counts_model2_percent, height=0.4, alpha=0.5, color=\'#2432EE\', label=top_bigrams  )\n    ax.set_yticks([top_count - x + 0.4 for x in ylocs])\n    ax.set_yticklabels(top_bigrams_with_counts)\n    ax.set_ylim([0.5, top_count+1])\n    ax.set_xlim([0, 100])\n    plt.subplots_adjust(left=0.28, right=0.9, top=0.9, bottom=0.1)\n    plt.xlabel(\'Percentage of questions with correct answers\')\n    plt.ylabel(\'Top N-grams\')\n    plt.savefig(os.path.join(output_dir, \'ngram_stats_{0}.png\'.format(num_grams)))\n    plt.close()\n\n\ndef read_json(filename):\n    with open(filename) as filepoint:\n        data = json.load(filepoint)\n    return data\n\n\ndef compare_models(dataset_file, predictions_m1_file, predictions_m2_file, output_dir, name_m1=\'Model 1\', name_m2=\'Model 2\'):\n    dataset = read_json(dataset_file)[\'data\']\n    predictions_m1 = read_json(predictions_m1_file)\n    predictions_m2 = read_json(predictions_m2_file)\n\n    # Read in data\n    total = 0\n    questions = {}\n    for article in dataset:\n        for paragraph in article[\'paragraphs\']:\n            for qa in paragraph[\'qas\']:\n                current_question = Question(id=qa[\'id\'], question_text=qa[\'question\'], ground_truth=list(map(lambda x: x[\'text\'], qa[\'answers\'])), model_names=[name_m1, name_m2])\n                current_question.add_answers(answer_model_1=safe_dict_access(predictions_m1, qa[\'id\']), answer_model_2=safe_dict_access(predictions_m2, qa[\'id\']))\n                questions[current_question.id] = current_question\n                total += 1\n    model_names = questions[list(questions.keys())[0]].model_names\n    print(\'Read in {0} questions\'.format(total))\n\n    # Aggregate scores\n    aggregate_metrics(questions)\n\n    # Venn diagram\n    correct_model1, correct_model2, correct_model1_and_model2, correct_model1_and_not_model2, correct_model2_and_not_model1 = venn_diagram(questions, output_dir=output_dir)\n\n    # Head Unigram statistics\n    get_head_ngram_statistics(questions, correct_model1, correct_model2, correct_model1_and_model2, correct_model1_and_not_model2,\n                              correct_model2_and_not_model1, output_dir, num_grams=1, top_count=10)\n\n    # Head Bigram statistics\n    get_head_ngram_statistics(questions, correct_model1, correct_model2, correct_model1_and_model2, correct_model1_and_not_model2,\n                              correct_model2_and_not_model1, output_dir, num_grams=2, top_count=10)\n\n\nif __name__ == \'__main__\':\n    parser = argparse.ArgumentParser(description=\'Compare two QA models\')\n    parser.add_argument(\'-dataset\', action=\'store\', dest=\'dataset\', required=True, help=\'Dataset file\')\n    parser.add_argument(\'-model1\', action=\'store\', dest=\'predictions_m1\', required=True, help=\'Prediction file for model 1\')\n    parser.add_argument(\'-model2\', action=\'store\', dest=\'predictions_m2\', required=True, help=\'Prediction file for model 2\')\n    parser.add_argument(\'-name1\', action=\'store\', dest=\'name_m1\', help=\'Name for model 1\')\n    parser.add_argument(\'-name2\', action=\'store\', dest=\'name_m2\', help=\'Name for model 2\')\n    parser.add_argument(\'-output\', action=\'store\', dest=\'output_dir\', help=\'Output directory for visualizations\')\n    results = parser.parse_args()\n\n    if results.name_m1 is not None and results.name_m2 is not None:\n        compare_models(dataset_file=results.dataset, predictions_m1_file=results.predictions_m1, predictions_m2_file=results.predictions_m2, output_dir=results.output_dir, name_m1=results.name_m1, name_m2=results.name_m2)\n    else:\n        compare_models(dataset_file=results.dataset, predictions_m1_file=results.predictions_m1, predictions_m2_file=results.predictions_m2, output_dir=results.output_dir)\n'"
my/tensorflow/__init__.py,0,b'from my.tensorflow.general import *'
my/tensorflow/general.py,24,"b'from itertools import zip_longest\n\nimport tensorflow as tf\nfrom functools import reduce\nfrom operator import mul\nimport numpy as np\n\nVERY_BIG_NUMBER = 1e30\nVERY_SMALL_NUMBER = 1e-30\nVERY_POSITIVE_NUMBER = VERY_BIG_NUMBER\nVERY_NEGATIVE_NUMBER = -VERY_BIG_NUMBER\n\n\ndef get_initializer(matrix):\n    def _initializer(shape, dtype=None, partition_info=None, **kwargs): return matrix\n    return _initializer\n\n\ndef variable_on_cpu(name, shape, initializer):\n    """"""Helper to create a Variable stored on CPU memory.\n\n    Args:\n      name: name of the variable\n      shape: list of ints\n      initializer: initializer for Variable\n\n    Returns:\n      Variable Tensor\n    """"""\n    with tf.device(\'/cpu:0\'):\n        var = tf.get_variable(name, shape, initializer=initializer)\n    return var\n\n\ndef variable_with_weight_decay(name, shape, stddev, wd):\n    """"""Helper to create an initialized Variable with weight decay.\n\n    Note that the Variable is initialized with a truncated normal distribution.\n    A weight decay is added only if one is specified.\n\n    Args:\n      name: name of the variable\n      shape: list of ints\n      stddev: standard deviation of a truncated Gaussian\n      wd: add L2Loss weight decay multiplied by this float. If None, weight\n          decay is not added for this Variable.\n\n    Returns:\n      Variable Tensor\n    """"""\n    var = variable_on_cpu(name, shape,\n                           tf.truncated_normal_initializer(stddev=stddev))\n    if wd:\n        weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name=\'weight_loss\')\n        tf.add_to_collection(\'losses\', weight_decay)\n    return var\n\n\ndef average_gradients(tower_grads):\n    """"""Calculate the average gradient for each shared variable across all towers.\n\n    Note that this function provides a synchronization point across all towers.\n\n    Args:\n      tower_grads: List of lists of (gradient, variable) tuples. The outer list\n        is over individual gradients. The inner list is over the gradient\n        calculation for each tower.\n    Returns:\n       List of pairs of (gradient, variable) where the gradient has been averaged\n       across all towers.\n    """"""\n    average_grads = []\n    for grad_and_vars in zip(*tower_grads):\n        # Note that each grad_and_vars looks like the following:\n        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n        grads = []\n        for g, var in grad_and_vars:\n            # Add 0 dimension to the gradients to represent the tower.\n            assert g is not None, var.name\n            expanded_g = tf.expand_dims(g, 0)\n\n            # Append on a \'tower\' dimension which we will average over below.\n            grads.append(expanded_g)\n\n        # Average over the \'tower\' dimension.\n        grad = tf.concat(0, grads)\n        grad = tf.reduce_mean(grad, 0)\n\n        # Keep in mind that the Variables are redundant because they are shared\n        # across towers. So .. we will just return the first tower\'s pointer to\n        # the Variable.\n        v = grad_and_vars[0][1]\n        grad_and_var = (grad, v)\n        average_grads.append(grad_and_var)\n    return average_grads\n\n\ndef mask(val, mask, name=None):\n    if name is None:\n        name = \'mask\'\n    return tf.mul(val, tf.cast(mask, \'float\'), name=name)\n\n\ndef exp_mask(val, mask, name=None):\n    """"""Give very negative number to unmasked elements in val.\n    For example, [-3, -2, 10], [True, True, False] -> [-3, -2, -1e9].\n    Typically, this effectively masks in exponential space (e.g. softmax)\n    Args:\n        val: values to be masked\n        mask: masking boolean tensor, same shape as tensor\n        name: name for output tensor\n\n    Returns:\n        Same shape as val, where some elements are very small (exponentially zero)\n    """"""\n    if name is None:\n        name = ""exp_mask""\n    return tf.add(val, (1 - tf.cast(mask, \'float\')) * VERY_NEGATIVE_NUMBER, name=name)\n\n\ndef flatten(tensor, keep):\n    fixed_shape = tensor.get_shape().as_list()\n    start = len(fixed_shape) - keep\n    left = reduce(mul, [fixed_shape[i] or tf.shape(tensor)[i] for i in range(start)])\n    out_shape = [left] + [fixed_shape[i] or tf.shape(tensor)[i] for i in range(start, len(fixed_shape))]\n    flat = tf.reshape(tensor, out_shape)\n    return flat\n\n\ndef reconstruct(tensor, ref, keep):\n    ref_shape = ref.get_shape().as_list()\n    tensor_shape = tensor.get_shape().as_list()\n    ref_stop = len(ref_shape) - keep\n    tensor_start = len(tensor_shape) - keep\n    pre_shape = [ref_shape[i] or tf.shape(ref)[i] for i in range(ref_stop)]\n    keep_shape = [tensor_shape[i] or tf.shape(tensor)[i] for i in range(tensor_start, len(tensor_shape))]\n    # pre_shape = [tf.shape(ref)[i] for i in range(len(ref.get_shape().as_list()[:-keep]))]\n    # keep_shape = tensor.get_shape().as_list()[-keep:]\n    target_shape = pre_shape + keep_shape\n    out = tf.reshape(tensor, target_shape)\n    return out\n\n\ndef add_wd(wd, scope=None):\n    scope = scope or tf.get_variable_scope().name\n    variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope)\n    with tf.name_scope(""weight_decay""):\n        for var in variables:\n            weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name=""{}/wd"".format(var.op.name))\n            tf.add_to_collection(\'losses\', weight_decay)\n\n\ndef grouper(iterable, n, fillvalue=None, shorten=False, num_groups=None):\n    args = [iter(iterable)] * n\n    out = zip_longest(*args, fillvalue=fillvalue)\n    out = list(out)\n    if num_groups is not None:\n        default = (fillvalue, ) * n\n        assert isinstance(num_groups, int)\n        out = list(each for each, _ in zip_longest(out, range(num_groups), fillvalue=default))\n    if shorten:\n        assert fillvalue is None\n        out = (tuple(e for e in each if e is not None) for each in out)\n    return out\n\ndef padded_reshape(tensor, shape, mode=\'CONSTANT\', name=None):\n    paddings = [[0, shape[i] - tf.shape(tensor)[i]] for i in range(len(shape))]\n    return tf.pad(tensor, paddings, mode=mode, name=name)'"
my/tensorflow/nn.py,25,"b'from tensorflow.python.ops.rnn_cell import _linear\nfrom tensorflow.python.util import nest\nimport tensorflow as tf\n\nfrom my.tensorflow import flatten, reconstruct, add_wd, exp_mask\n\n\ndef linear(args, output_size, bias, bias_start=0.0, scope=None, squeeze=False, wd=0.0, input_keep_prob=1.0,\n           is_train=None):\n    if args is None or (nest.is_sequence(args) and not args):\n        raise ValueError(""`args` must be specified"")\n    if not nest.is_sequence(args):\n        args = [args]\n\n    flat_args = [flatten(arg, 1) for arg in args]\n    if input_keep_prob < 1.0:\n        assert is_train is not None\n        flat_args = [tf.cond(is_train, lambda: tf.nn.dropout(arg, input_keep_prob), lambda: arg)\n                     for arg in flat_args]\n    flat_out = _linear(flat_args, output_size, bias, bias_start=bias_start, scope=scope)\n    out = reconstruct(flat_out, args[0], 1)\n    if squeeze:\n        out = tf.squeeze(out, [len(args[0].get_shape().as_list())-1])\n    if wd:\n        add_wd(wd)\n\n    return out\n\n\ndef dropout(x, keep_prob, is_train, noise_shape=None, seed=None, name=None):\n    with tf.name_scope(name or ""dropout""):\n        if keep_prob < 1.0:\n            d = tf.nn.dropout(x, keep_prob, noise_shape=noise_shape, seed=seed)\n            out = tf.cond(is_train, lambda: d, lambda: x)\n            return out\n        return x\n\n\ndef softmax(logits, mask=None, scope=None):\n    with tf.name_scope(scope or ""Softmax""):\n        if mask is not None:\n            logits = exp_mask(logits, mask)\n        flat_logits = flatten(logits, 1)\n        flat_out = tf.nn.softmax(flat_logits)\n        out = reconstruct(flat_out, logits, 1)\n\n        return out\n\n\ndef softsel(target, logits, mask=None, scope=None):\n    """"""\n\n    :param target: [ ..., J, d] dtype=float\n    :param logits: [ ..., J], dtype=float\n    :param mask: [ ..., J], dtype=bool\n    :param scope:\n    :return: [..., d], dtype=float\n    """"""\n    with tf.name_scope(scope or ""Softsel""):\n        a = softmax(logits, mask=mask)\n        target_rank = len(target.get_shape().as_list())\n        out = tf.reduce_sum(tf.expand_dims(a, -1) * target, target_rank - 2)\n        return out\n\n\ndef double_linear_logits(args, size, bias, bias_start=0.0, scope=None, mask=None, wd=0.0, input_keep_prob=1.0, is_train=None):\n    with tf.variable_scope(scope or ""Double_Linear_Logits""):\n        first = tf.tanh(linear(args, size, bias, bias_start=bias_start, scope=\'first\',\n                               wd=wd, input_keep_prob=input_keep_prob, is_train=is_train))\n        second = linear(first, 1, bias, bias_start=bias_start, squeeze=True, scope=\'second\',\n                        wd=wd, input_keep_prob=input_keep_prob, is_train=is_train)\n        if mask is not None:\n            second = exp_mask(second, mask)\n        return second\n\n\ndef linear_logits(args, bias, bias_start=0.0, scope=None, mask=None, wd=0.0, input_keep_prob=1.0, is_train=None):\n    with tf.variable_scope(scope or ""Linear_Logits""):\n        logits = linear(args, 1, bias, bias_start=bias_start, squeeze=True, scope=\'first\',\n                        wd=wd, input_keep_prob=input_keep_prob, is_train=is_train)\n        if mask is not None:\n            logits = exp_mask(logits, mask)\n        return logits\n\n\ndef sum_logits(args, mask=None, name=None):\n    with tf.name_scope(name or ""sum_logits""):\n        if args is None or (nest.is_sequence(args) and not args):\n            raise ValueError(""`args` must be specified"")\n        if not nest.is_sequence(args):\n            args = [args]\n        rank = len(args[0].get_shape())\n        logits = sum(tf.reduce_sum(arg, rank-1) for arg in args)\n        if mask is not None:\n            logits = exp_mask(logits, mask)\n        return logits\n\n\ndef get_logits(args, size, bias, bias_start=0.0, scope=None, mask=None, wd=0.0, input_keep_prob=1.0, is_train=None, func=None):\n    if func is None:\n        func = ""sum""\n    if func == \'sum\':\n        return sum_logits(args, mask=mask, name=scope)\n    elif func == \'linear\':\n        return linear_logits(args, bias, bias_start=bias_start, scope=scope, mask=mask, wd=wd, input_keep_prob=input_keep_prob,\n                             is_train=is_train)\n    elif func == \'double\':\n        return double_linear_logits(args, size, bias, bias_start=bias_start, scope=scope, mask=mask, wd=wd, input_keep_prob=input_keep_prob,\n                                    is_train=is_train)\n    elif func == \'dot\':\n        assert len(args) == 2\n        arg = args[0] * args[1]\n        return sum_logits([arg], mask=mask, name=scope)\n    elif func == \'mul_linear\':\n        assert len(args) == 2\n        arg = args[0] * args[1]\n        return linear_logits([arg], bias, bias_start=bias_start, scope=scope, mask=mask, wd=wd, input_keep_prob=input_keep_prob,\n                             is_train=is_train)\n    elif func == \'proj\':\n        assert len(args) == 2\n        d = args[1].get_shape()[-1]\n        proj = linear([args[0]], d, False, bias_start=bias_start, scope=scope, wd=wd, input_keep_prob=input_keep_prob,\n                      is_train=is_train)\n        return sum_logits([proj * args[1]], mask=mask)\n    elif func == \'tri_linear\':\n        assert len(args) == 2\n        new_arg = args[0] * args[1]\n        return linear_logits([args[0], args[1], new_arg], bias, bias_start=bias_start, scope=scope, mask=mask, wd=wd, input_keep_prob=input_keep_prob,\n                             is_train=is_train)\n    else:\n        raise Exception()\n\n\ndef highway_layer(arg, bias, bias_start=0.0, scope=None, wd=0.0, input_keep_prob=1.0, is_train=None):\n    with tf.variable_scope(scope or ""highway_layer""):\n        d = arg.get_shape()[-1]\n        trans = linear([arg], d, bias, bias_start=bias_start, scope=\'trans\', wd=wd, input_keep_prob=input_keep_prob, is_train=is_train)\n        trans = tf.nn.relu(trans)\n        gate = linear([arg], d, bias, bias_start=bias_start, scope=\'gate\', wd=wd, input_keep_prob=input_keep_prob, is_train=is_train)\n        gate = tf.nn.sigmoid(gate)\n        out = gate * trans + (1 - gate) * arg\n        return out\n\n\ndef highway_network(arg, num_layers, bias, bias_start=0.0, scope=None, wd=0.0, input_keep_prob=1.0, is_train=None):\n    with tf.variable_scope(scope or ""highway_network""):\n        prev = arg\n        cur = None\n        for layer_idx in range(num_layers):\n            cur = highway_layer(prev, bias, bias_start=bias_start, scope=""layer_{}"".format(layer_idx), wd=wd,\n                                input_keep_prob=input_keep_prob, is_train=is_train)\n            prev = cur\n        return cur\n\n\ndef conv1d(in_, filter_size, height, padding, is_train=None, keep_prob=1.0, scope=None):\n    with tf.variable_scope(scope or ""conv1d""):\n        num_channels = in_.get_shape()[-1]\n        filter_ = tf.get_variable(""filter"", shape=[1, height, num_channels, filter_size], dtype=\'float\')\n        bias = tf.get_variable(""bias"", shape=[filter_size], dtype=\'float\')\n        strides = [1, 1, 1, 1]\n        if is_train is not None and keep_prob < 1.0:\n            in_ = dropout(in_, keep_prob, is_train)\n        xxc = tf.nn.conv2d(in_, filter_, strides, padding) + bias  # [N*M, JX, W/filter_stride, d]\n        out = tf.reduce_max(tf.nn.relu(xxc), 2)  # [-1, JX, d]\n        return out\n\n\ndef multi_conv1d(in_, filter_sizes, heights, padding, is_train=None, keep_prob=1.0, scope=None):\n    with tf.variable_scope(scope or ""multi_conv1d""):\n        assert len(filter_sizes) == len(heights)\n        outs = []\n        for filter_size, height in zip(filter_sizes, heights):\n            if filter_size == 0:\n                continue\n            out = conv1d(in_, filter_size, height, padding, is_train=is_train, keep_prob=keep_prob, scope=""conv1d_{}"".format(height))\n            outs.append(out)\n        concat_out = tf.concat(2, outs)\n        return concat_out\n'"
my/tensorflow/rnn.py,8,"b""import tensorflow as tf\nfrom tensorflow.python.ops.rnn import dynamic_rnn as _dynamic_rnn, \\\n    bidirectional_dynamic_rnn as _bidirectional_dynamic_rnn\nfrom tensorflow.python.ops.rnn import bidirectional_rnn as _bidirectional_rnn\n\nfrom my.tensorflow import flatten, reconstruct\n\n\ndef dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None,\n                dtype=None, parallel_iterations=None, swap_memory=False,\n                time_major=False, scope=None):\n    assert not time_major  # TODO : to be implemented later!\n    flat_inputs = flatten(inputs, 2)  # [-1, J, d]\n    flat_len = None if sequence_length is None else tf.cast(flatten(sequence_length, 0), 'int64')\n\n    flat_outputs, final_state = _dynamic_rnn(cell, flat_inputs, sequence_length=flat_len,\n                                             initial_state=initial_state, dtype=dtype,\n                                             parallel_iterations=parallel_iterations, swap_memory=swap_memory,\n                                             time_major=time_major, scope=scope)\n\n    outputs = reconstruct(flat_outputs, inputs, 2)\n    return outputs, final_state\n\n\ndef bw_dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None,\n                   dtype=None, parallel_iterations=None, swap_memory=False,\n                   time_major=False, scope=None):\n    assert not time_major  # TODO : to be implemented later!\n\n    flat_inputs = flatten(inputs, 2)  # [-1, J, d]\n    flat_len = None if sequence_length is None else tf.cast(flatten(sequence_length, 0), 'int64')\n\n    flat_inputs = tf.reverse(flat_inputs, 1) if sequence_length is None \\\n        else tf.reverse_sequence(flat_inputs, sequence_length, 1)\n    flat_outputs, final_state = _dynamic_rnn(cell, flat_inputs, sequence_length=flat_len,\n                                             initial_state=initial_state, dtype=dtype,\n                                             parallel_iterations=parallel_iterations, swap_memory=swap_memory,\n                                             time_major=time_major, scope=scope)\n    flat_outputs = tf.reverse(flat_outputs, 1) if sequence_length is None \\\n        else tf.reverse_sequence(flat_outputs, sequence_length, 1)\n\n    outputs = reconstruct(flat_outputs, inputs, 2)\n    return outputs, final_state\n\n\ndef bidirectional_dynamic_rnn(cell_fw, cell_bw, inputs, sequence_length=None,\n                              initial_state_fw=None, initial_state_bw=None,\n                              dtype=None, parallel_iterations=None,\n                              swap_memory=False, time_major=False, scope=None):\n    assert not time_major\n\n    flat_inputs = flatten(inputs, 2)  # [-1, J, d]\n    flat_len = None if sequence_length is None else tf.cast(flatten(sequence_length, 0), 'int64')\n\n    (flat_fw_outputs, flat_bw_outputs), final_state = \\\n        _bidirectional_dynamic_rnn(cell_fw, cell_bw, flat_inputs, sequence_length=flat_len,\n                                   initial_state_fw=initial_state_fw, initial_state_bw=initial_state_bw,\n                                   dtype=dtype, parallel_iterations=parallel_iterations, swap_memory=swap_memory,\n                                   time_major=time_major, scope=scope)\n\n    fw_outputs = reconstruct(flat_fw_outputs, inputs, 2)\n    bw_outputs = reconstruct(flat_bw_outputs, inputs, 2)\n    # FIXME : final state is not reshaped!\n    return (fw_outputs, bw_outputs), final_state\n\n\ndef bidirectional_rnn(cell_fw, cell_bw, inputs,\n                      initial_state_fw=None, initial_state_bw=None,\n                      dtype=None, sequence_length=None, scope=None):\n\n    flat_inputs = flatten(inputs, 2)  # [-1, J, d]\n    flat_len = None if sequence_length is None else tf.cast(flatten(sequence_length, 0), 'int64')\n\n    (flat_fw_outputs, flat_bw_outputs), final_state = \\\n        _bidirectional_rnn(cell_fw, cell_bw, flat_inputs, sequence_length=flat_len,\n                           initial_state_fw=initial_state_fw, initial_state_bw=initial_state_bw,\n                           dtype=dtype, scope=scope)\n\n    fw_outputs = reconstruct(flat_fw_outputs, inputs, 2)\n    bw_outputs = reconstruct(flat_bw_outputs, inputs, 2)\n    # FIXME : final state is not reshaped!\n    return (fw_outputs, bw_outputs), final_state\n"""
my/tensorflow/rnn_cell.py,36,"b'import tensorflow as tf\nfrom tensorflow.python.ops.rnn_cell import DropoutWrapper, RNNCell, LSTMStateTuple\n\nfrom my.tensorflow import exp_mask, flatten\nfrom my.tensorflow.nn import linear, softsel, double_linear_logits\n\n\nclass SwitchableDropoutWrapper(DropoutWrapper):\n    def __init__(self, cell, is_train, input_keep_prob=1.0, output_keep_prob=1.0,\n             seed=None):\n        super(SwitchableDropoutWrapper, self).__init__(cell, input_keep_prob=input_keep_prob, output_keep_prob=output_keep_prob,\n                                                       seed=seed)\n        self.is_train = is_train\n\n    def __call__(self, inputs, state, scope=None):\n        outputs_do, new_state_do = super(SwitchableDropoutWrapper, self).__call__(inputs, state, scope=scope)\n        tf.get_variable_scope().reuse_variables()\n        outputs, new_state = self._cell(inputs, state, scope)\n        outputs = tf.cond(self.is_train, lambda: outputs_do, lambda: outputs)\n        if isinstance(state, tuple):\n            new_state = state.__class__(*[tf.cond(self.is_train, lambda: new_state_do_i, lambda: new_state_i)\n                                       for new_state_do_i, new_state_i in zip(new_state_do, new_state)])\n        else:\n            new_state = tf.cond(self.is_train, lambda: new_state_do, lambda: new_state)\n        return outputs, new_state\n\n\nclass TreeRNNCell(RNNCell):\n    def __init__(self, cell, input_size, reduce_func):\n        self._cell = cell\n        self._input_size = input_size\n        self._reduce_func = reduce_func\n\n    def __call__(self, inputs, state, scope=None):\n        """"""\n        :param inputs: [N*B, I + B]\n        :param state: [N*B, d]\n        :param scope:\n        :return: [N*B, d]\n        """"""\n        with tf.variable_scope(scope or self.__class__.__name__):\n            d = self.state_size\n            x = tf.slice(inputs, [0, 0], [-1, self._input_size])  # [N*B, I]\n            mask = tf.slice(inputs, [0, self._input_size], [-1, -1])  # [N*B, B]\n            B = tf.shape(mask)[1]\n            prev_state = tf.expand_dims(tf.reshape(state, [-1, B, d]), 1)  # [N, B, d] -> [N, 1, B, d]\n            mask = tf.tile(tf.expand_dims(tf.reshape(mask, [-1, B, B]), -1), [1, 1, 1, d])  # [N, B, B, d]\n            # prev_state = self._reduce_func(tf.tile(prev_state, [1, B, 1, 1]), 2)\n            prev_state = self._reduce_func(exp_mask(prev_state, mask), 2)  # [N, B, d]\n            prev_state = tf.reshape(prev_state, [-1, d])  # [N*B, d]\n            return self._cell(x, prev_state)\n\n    @property\n    def state_size(self):\n        return self._cell.state_size\n\n    @property\n    def output_size(self):\n        return self._cell.output_size\n\n\nclass NoOpCell(RNNCell):\n    def __init__(self, num_units):\n        self._num_units = num_units\n\n    def __call__(self, inputs, state, scope=None):\n        return state, state\n\n    @property\n    def state_size(self):\n        return self._num_units\n\n    @property\n    def output_size(self):\n        return self._num_units\n\n\nclass MatchCell(RNNCell):\n    def __init__(self, cell, input_size, q_len):\n        self._cell = cell\n        self._input_size = input_size\n        # FIXME : This won\'t be needed with good shape guessing\n        self._q_len = q_len\n\n    @property\n    def state_size(self):\n        return self._cell.state_size\n\n    @property\n    def output_size(self):\n        return self._cell.output_size\n\n    def __call__(self, inputs, state, scope=None):\n        """"""\n\n        :param inputs: [N, d + JQ + JQ * d]\n        :param state: [N, d]\n        :param scope:\n        :return:\n        """"""\n        with tf.variable_scope(scope or self.__class__.__name__):\n            c_prev, h_prev = state\n            x = tf.slice(inputs, [0, 0], [-1, self._input_size])\n            q_mask = tf.slice(inputs, [0, self._input_size], [-1, self._q_len])  # [N, JQ]\n            qs = tf.slice(inputs, [0, self._input_size + self._q_len], [-1, -1])\n            qs = tf.reshape(qs, [-1, self._q_len, self._input_size])  # [N, JQ, d]\n            x_tiled = tf.tile(tf.expand_dims(x, 1), [1, self._q_len, 1])  # [N, JQ, d]\n            h_prev_tiled = tf.tile(tf.expand_dims(h_prev, 1), [1, self._q_len, 1])  # [N, JQ, d]\n            f = tf.tanh(linear([qs, x_tiled, h_prev_tiled], self._input_size, True, scope=\'f\'))  # [N, JQ, d]\n            a = tf.nn.softmax(exp_mask(linear(f, 1, True, squeeze=True, scope=\'a\'), q_mask))  # [N, JQ]\n            q = tf.reduce_sum(qs * tf.expand_dims(a, -1), 1)\n            z = tf.concat(1, [x, q])  # [N, 2d]\n            return self._cell(z, state)\n\n\nclass AttentionCell(RNNCell):\n    def __init__(self, cell, memory, mask=None, controller=None, mapper=None, input_keep_prob=1.0, is_train=None):\n        """"""\n        Early fusion attention cell: uses the (inputs, state) to control the current attention.\n\n        :param cell:\n        :param memory: [N, M, m]\n        :param mask:\n        :param controller: (inputs, prev_state, memory) -> memory_logits\n        """"""\n        self._cell = cell\n        self._memory = memory\n        self._mask = mask\n        self._flat_memory = flatten(memory, 2)\n        self._flat_mask = flatten(mask, 1)\n        if controller is None:\n            controller = AttentionCell.get_linear_controller(True, is_train=is_train)\n        self._controller = controller\n        if mapper is None:\n            mapper = AttentionCell.get_concat_mapper()\n        elif mapper == \'sim\':\n            mapper = AttentionCell.get_sim_mapper()\n        self._mapper = mapper\n\n    @property\n    def state_size(self):\n        return self._cell.state_size\n\n    @property\n    def output_size(self):\n        return self._cell.output_size\n\n    def __call__(self, inputs, state, scope=None):\n        with tf.variable_scope(scope or ""AttentionCell""):\n            memory_logits = self._controller(inputs, state, self._flat_memory)\n            sel_mem = softsel(self._flat_memory, memory_logits, mask=self._flat_mask)  # [N, m]\n            new_inputs, new_state = self._mapper(inputs, state, sel_mem)\n            return self._cell(new_inputs, state)\n\n    @staticmethod\n    def get_double_linear_controller(size, bias, input_keep_prob=1.0, is_train=None):\n        def double_linear_controller(inputs, state, memory):\n            """"""\n\n            :param inputs: [N, i]\n            :param state: [N, d]\n            :param memory: [N, M, m]\n            :return: [N, M]\n            """"""\n            rank = len(memory.get_shape())\n            _memory_size = tf.shape(memory)[rank-2]\n            tiled_inputs = tf.tile(tf.expand_dims(inputs, 1), [1, _memory_size, 1])\n            if isinstance(state, tuple):\n                tiled_states = [tf.tile(tf.expand_dims(each, 1), [1, _memory_size, 1])\n                                for each in state]\n            else:\n                tiled_states = [tf.tile(tf.expand_dims(state, 1), [1, _memory_size, 1])]\n\n            # [N, M, d]\n            in_ = tf.concat(2, [tiled_inputs] + tiled_states + [memory])\n            out = double_linear_logits(in_, size, bias, input_keep_prob=input_keep_prob,\n                                       is_train=is_train)\n            return out\n        return double_linear_controller\n\n    @staticmethod\n    def get_linear_controller(bias, input_keep_prob=1.0, is_train=None):\n        def linear_controller(inputs, state, memory):\n            rank = len(memory.get_shape())\n            _memory_size = tf.shape(memory)[rank-2]\n            tiled_inputs = tf.tile(tf.expand_dims(inputs, 1), [1, _memory_size, 1])\n            if isinstance(state, tuple):\n                tiled_states = [tf.tile(tf.expand_dims(each, 1), [1, _memory_size, 1])\n                                for each in state]\n            else:\n                tiled_states = [tf.tile(tf.expand_dims(state, 1), [1, _memory_size, 1])]\n\n            # [N, M, d]\n            in_ = tf.concat(2, [tiled_inputs] + tiled_states + [memory])\n            out = linear(in_, 1, bias, squeeze=True, input_keep_prob=input_keep_prob, is_train=is_train)\n            return out\n        return linear_controller\n\n    @staticmethod\n    def get_concat_mapper():\n        def concat_mapper(inputs, state, sel_mem):\n            """"""\n\n            :param inputs: [N, i]\n            :param state: [N, d]\n            :param sel_mem: [N, m]\n            :return: (new_inputs, new_state) tuple\n            """"""\n            return tf.concat(1, [inputs, sel_mem]), state\n        return concat_mapper\n\n    @staticmethod\n    def get_sim_mapper():\n        def sim_mapper(inputs, state, sel_mem):\n            """"""\n            Assume that inputs and sel_mem are the same size\n            :param inputs: [N, i]\n            :param state: [N, d]\n            :param sel_mem: [N, i]\n            :return: (new_inputs, new_state) tuple\n            """"""\n            return tf.concat(1, [inputs, sel_mem, inputs * sel_mem, tf.abs(inputs - sel_mem)]), state\n        return sim_mapper\n'"
