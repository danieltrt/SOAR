file_path,api_count,code
keras_to_tensorflow.py,3,"b'#!/usr/bin/env python\n""""""\nCopyright (c) 2019, by the Authors: Amir H. Abdi\nThis script is freely available under the MIT Public License.\nPlease see the License file in the root for details.\n\nThe following code snippet will convert the keras model files\nto the freezed .pb tensorflow weight file. The resultant TensorFlow model\nholds both the model architecture and its associated weights.\n""""""\n\nimport tensorflow as tf\nfrom tensorflow.python.framework import graph_util\nfrom tensorflow.python.framework import graph_io\nfrom pathlib import Path\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\nimport keras\nfrom keras import backend as K\nfrom keras.models import model_from_json, model_from_yaml\n\nK.set_learning_phase(0)\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string(\'input_model\', None, \'Path to the input model.\')\nflags.DEFINE_string(\'input_model_json\', None, \'Path to the input model \'\n                                              \'architecture in json format.\')\nflags.DEFINE_string(\'input_model_yaml\', None, \'Path to the input model \'\n                                              \'architecture in yaml format.\')\nflags.DEFINE_string(\'output_model\', None, \'Path where the converted model will \'\n                                          \'be stored.\')\nflags.DEFINE_boolean(\'save_graph_def\', False,\n                     \'Whether to save the graphdef.pbtxt file which contains \'\n                     \'the graph definition in ASCII format.\')\nflags.DEFINE_string(\'output_nodes_prefix\', None,\n                    \'If set, the output nodes will be renamed to \'\n                    \'`output_nodes_prefix`+i, where `i` will numerate the \'\n                    \'number of of output nodes of the network.\')\nflags.DEFINE_boolean(\'quantize\', False,\n                     \'If set, the resultant TensorFlow graph weights will be \'\n                     \'converted from float into eight-bit equivalents. See \'\n                     \'documentation here: \'\n                     \'https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms\')\nflags.DEFINE_boolean(\'channels_first\', False,\n                     \'Whether channels are the first dimension of a tensor. \'\n                     \'The default is TensorFlow behaviour where channels are \'\n                     \'the last dimension.\')\nflags.DEFINE_boolean(\'output_meta_ckpt\', False,\n                     \'If set to True, exports the model as .meta, .index, and \'\n                     \'.data files, with a checkpoint file. These can be later \'\n                     \'loaded in TensorFlow to continue training.\')\n\nflags.mark_flag_as_required(\'input_model\')\nflags.mark_flag_as_required(\'output_model\')\n\n\ndef load_model(input_model_path, input_json_path=None, input_yaml_path=None):\n    if not Path(input_model_path).exists():\n        raise FileNotFoundError(\n            \'Model file `{}` does not exist.\'.format(input_model_path))\n    try:\n        model = keras.models.load_model(input_model_path)\n        return model\n    except FileNotFoundError as err:\n        logging.error(\'Input mode file (%s) does not exist.\', FLAGS.input_model)\n        raise err\n    except ValueError as wrong_file_err:\n        if input_json_path:\n            if not Path(input_json_path).exists():\n                raise FileNotFoundError(\n                    \'Model description json file `{}` does not exist.\'.format(\n                        input_json_path))\n            try:\n                model = model_from_json(open(str(input_json_path)).read())\n                model.load_weights(input_model_path)\n                return model\n            except Exception as err:\n                logging.error(""Couldn\'t load model from json."")\n                raise err\n        elif input_yaml_path:\n            if not Path(input_yaml_path).exists():\n                raise FileNotFoundError(\n                    \'Model description yaml file `{}` does not exist.\'.format(\n                        input_yaml_path))\n            try:\n                model = model_from_yaml(open(str(input_yaml_path)).read())\n                model.load_weights(input_model_path)\n                return model\n            except Exception as err:\n                logging.error(""Couldn\'t load model from yaml."")\n                raise err\n        else:\n            logging.error(\n                \'Input file specified only holds the weights, and not \'\n                \'the model definition. Save the model using \'\n                \'model.save(filename.h5) which will contain the network \'\n                \'architecture as well as its weights. \'\n                \'If the model is saved using the \'\n                \'model.save_weights(filename) function, either \'\n                \'input_model_json or input_model_yaml flags should be set to \'\n                \'to import the network architecture prior to loading the \'\n                \'weights. \\n\'\n                \'Check the keras documentation for more details \'\n                \'(https://keras.io/getting-started/faq/)\')\n            raise wrong_file_err\n\n\ndef main(args):\n    # If output_model path is relative and in cwd, make it absolute from root\n    output_model = FLAGS.output_model\n    if str(Path(output_model).parent) == \'.\':\n        output_model = str((Path.cwd() / output_model))\n\n    output_fld = Path(output_model).parent\n    output_model_name = Path(output_model).name\n    output_model_stem = Path(output_model).stem\n    output_model_pbtxt_name = output_model_stem + \'.pbtxt\'\n\n    # Create output directory if it does not exist\n    Path(output_model).parent.mkdir(parents=True, exist_ok=True)\n\n    if FLAGS.channels_first:\n        K.set_image_data_format(\'channels_first\')\n    else:\n        K.set_image_data_format(\'channels_last\')\n\n    model = load_model(FLAGS.input_model, FLAGS.input_model_json, FLAGS.input_model_yaml)\n\n    # TODO(amirabdi): Support networks with multiple inputs\n    orig_output_node_names = [node.op.name for node in model.outputs]\n    if FLAGS.output_nodes_prefix:\n        num_output = len(orig_output_node_names)\n        pred = [None] * num_output\n        converted_output_node_names = [None] * num_output\n\n        # Create dummy tf nodes to rename output\n        for i in range(num_output):\n            converted_output_node_names[i] = \'{}{}\'.format(\n                FLAGS.output_nodes_prefix, i)\n            pred[i] = tf.identity(model.outputs[i],\n                                  name=converted_output_node_names[i])\n    else:\n        converted_output_node_names = orig_output_node_names\n    logging.info(\'Converted output node names are: %s\',\n                 str(converted_output_node_names))\n\n    sess = K.get_session()\n    if FLAGS.output_meta_ckpt:\n        saver = tf.train.Saver()\n        saver.save(sess, str(output_fld / output_model_stem))\n\n    if FLAGS.save_graph_def:\n        tf.train.write_graph(sess.graph.as_graph_def(), str(output_fld),\n                             output_model_pbtxt_name, as_text=True)\n        logging.info(\'Saved the graph definition in ascii format at %s\',\n                     str(Path(output_fld) / output_model_pbtxt_name))\n\n    if FLAGS.quantize:\n        from tensorflow.tools.graph_transforms import TransformGraph\n        transforms = [""quantize_weights"", ""quantize_nodes""]\n        transformed_graph_def = TransformGraph(sess.graph.as_graph_def(), [],\n                                               converted_output_node_names,\n                                               transforms)\n        constant_graph = graph_util.convert_variables_to_constants(\n            sess,\n            transformed_graph_def,\n            converted_output_node_names)\n    else:\n        constant_graph = graph_util.convert_variables_to_constants(\n            sess,\n            sess.graph.as_graph_def(),\n            converted_output_node_names)\n\n    graph_io.write_graph(constant_graph, str(output_fld), output_model_name,\n                         as_text=False)\n    logging.info(\'Saved the freezed graph at %s\',\n                 str(Path(output_fld) / output_model_name))\n\n\nif __name__ == ""__main__"":\n    app.run(main)\n'"
legacy/freeze_graph.py,0,"b'# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Converts checkpoint variables into Const ops in a standalone GraphDef file.\n\nThis script is designed to take a GraphDef proto, a SaverDef proto, and a set of\nvariable values stored in a checkpoint file, and output a GraphDef with all of\nthe variable ops converted into const ops containing the values of the\nvariables.\n\nIt\'s useful to do this when we need to load a single file in C++, especially in\nenvironments like mobile or embedded where we may not have access to the\nRestoreTensor ops and file loading calls that they rely on.\n\nAn example of command-line usage is:\nbazel build tensorflow/python/tools:freeze_graph && \\\nbazel-bin/tensorflow/python/tools/freeze_graph \\\n--input_graph=some_graph_def.pb \\\n--input_checkpoint=model.ckpt-8361242 \\\n--output_graph=/tmp/frozen_graph.pb --output_node_names=softmax\n\nYou can also look at freeze_graph_test.py for an example of how to use it.\n\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\n\nfrom google.protobuf import text_format\n\nfrom tensorflow.core.framework import graph_pb2\nfrom tensorflow.core.protobuf import saver_pb2\nfrom tensorflow.python import pywrap_tensorflow\nfrom tensorflow.python.client import session\nfrom tensorflow.python.framework import graph_util\nfrom tensorflow.python.framework import importer\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.python.training import saver as saver_lib\n\nFLAGS = None\n\n\ndef freeze_graph(input_graph,\n                 input_saver,\n                 input_binary,\n                 input_checkpoint,\n                 output_node_names,\n                 restore_op_name,\n                 filename_tensor_name,\n                 output_graph,\n                 clear_devices,\n                 initializer_nodes,\n                 variable_names_blacklist=""""):\n  """"""Converts all variables in a graph and checkpoint into constants.""""""\n\n  del restore_op_name, filename_tensor_name  # Unused by updated loading code.\n\n  if not gfile.Exists(input_graph):\n    print(""Input graph file \'"" + input_graph + ""\' does not exist!"")\n    return -1\n\n  if input_saver and not gfile.Exists(input_saver):\n    print(""Input saver file \'"" + input_saver + ""\' does not exist!"")\n    return -1\n\n  # \'input_checkpoint\' may be a prefix if we\'re using Saver V2 format\n  if not saver_lib.checkpoint_exists(input_checkpoint):\n    print(""Input checkpoint \'"" + input_checkpoint + ""\' doesn\'t exist!"")\n    return -1\n\n  if not output_node_names:\n    print(""You need to supply the name of a node to --output_node_names."")\n    return -1\n\n  input_graph_def = graph_pb2.GraphDef()\n  mode = ""rb"" if input_binary else ""r""\n  with gfile.FastGFile(input_graph, mode) as f:\n    if input_binary:\n      input_graph_def.ParseFromString(f.read())\n    else:\n      text_format.Merge(f.read(), input_graph_def)\n  # Remove all the explicit device specifications for this node. This helps to\n  # make the graph more portable.\n  if clear_devices:\n    for node in input_graph_def.node:\n      node.device = """"\n\n  _ = importer.import_graph_def(input_graph_def, name="""")\n\n  with session.Session() as sess:\n    if input_saver:\n      with gfile.FastGFile(input_saver, mode) as f:\n        saver_def = saver_pb2.SaverDef()\n        if input_binary:\n          saver_def.ParseFromString(f.read())\n        else:\n          text_format.Merge(f.read(), saver_def)\n        saver = saver_lib.Saver(saver_def=saver_def)\n        saver.restore(sess, input_checkpoint)\n    else:\n      var_list = {}\n      reader = pywrap_tensorflow.NewCheckpointReader(input_checkpoint)\n      var_to_shape_map = reader.get_variable_to_shape_map()\n      for key in var_to_shape_map:\n        try:\n          tensor = sess.graph.get_tensor_by_name(key + "":0"")\n        except KeyError:\n          # This tensor doesn\'t exist in the graph (for example it\'s\n          # \'global_step\' or a similar housekeeping element) so skip it.\n          continue\n        var_list[key] = tensor\n      saver = saver_lib.Saver(var_list=var_list)\n      saver.restore(sess, input_checkpoint)\n      if initializer_nodes:\n        sess.run(initializer_nodes)\n\n    variable_names_blacklist = (variable_names_blacklist.split("","") if\n                                variable_names_blacklist else None)\n    output_graph_def = graph_util.convert_variables_to_constants(\n        sess,\n        input_graph_def,\n        output_node_names.split("",""),\n        variable_names_blacklist=variable_names_blacklist)\n\n  with gfile.GFile(output_graph, ""wb"") as f:\n    f.write(output_graph_def.SerializeToString())\n  print(""%d ops in the final graph."" % len(output_graph_def.node))\n\n\ndef main(unused_args):\n  freeze_graph(FLAGS.input_graph, FLAGS.input_saver, FLAGS.input_binary,\n               FLAGS.input_checkpoint, FLAGS.output_node_names,\n               FLAGS.restore_op_name, FLAGS.filename_tensor_name,\n               FLAGS.output_graph, FLAGS.clear_devices, FLAGS.initializer_nodes,\n               FLAGS.variable_names_blacklist)\n\n\nif __name__ == ""__main__"":\n  parser = argparse.ArgumentParser()\n  parser.register(""type"", ""bool"", lambda v: v.lower() == ""true"")\n  parser.add_argument(\n      ""--input_graph"",\n      type=str,\n      default="""",\n      help=""TensorFlow \\\'GraphDef\\\' file to load."")\n  parser.add_argument(\n      ""--input_saver"",\n      type=str,\n      default="""",\n      help=""TensorFlow saver file to load."")\n  parser.add_argument(\n      ""--input_checkpoint"",\n      type=str,\n      default="""",\n      help=""TensorFlow variables file to load."")\n  parser.add_argument(\n      ""--output_graph"",\n      type=str,\n      default="""",\n      help=""Output \\\'GraphDef\\\' file name."")\n  parser.add_argument(\n      ""--input_binary"",\n      nargs=""?"",\n      const=True,\n      type=""bool"",\n      default=False,\n      help=""Whether the input files are in binary format."")\n  parser.add_argument(\n      ""--output_node_names"",\n      type=str,\n      default="""",\n      help=""The name of the output nodes, comma separated."")\n  parser.add_argument(\n      ""--restore_op_name"",\n      type=str,\n      default=""save/restore_all"",\n      help=""The name of the master restore operator."")\n  parser.add_argument(\n      ""--filename_tensor_name"",\n      type=str,\n      default=""save/Const:0"",\n      help=""The name of the tensor holding the save path."")\n  parser.add_argument(\n      ""--clear_devices"",\n      nargs=""?"",\n      const=True,\n      type=""bool"",\n      default=True,\n      help=""Whether to remove device specifications."")\n  parser.add_argument(\n      ""--initializer_nodes"",\n      type=str,\n      default="""",\n      help=""comma separated list of initializer nodes to run before freezing."")\n  parser.add_argument(\n      ""--variable_names_blacklist"",\n      type=str,\n      default="""",\n      help=""""""\\\n      comma separated list of variables to skip converting to constants\\\n      """""")\n  FLAGS, unparsed = parser.parse_known_args()\n  app.run(main=main, argv=[sys.argv[0]] + unparsed)\n'"
