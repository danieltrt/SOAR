file_path,api_count,code
setup.py,0,"b'""""""\nRadIO is a framework for batch-processing of computational tomography (CT)-scans\nfor deep learning experiments.\nDocumentation - https://analysiscenter.github.io/radio/\n""""""\n\nimport re\nfrom setuptools import setup, find_packages\n\nwith open(\'radio/__init__.py\', \'r\') as f:\n    version = re.search(r\'^__version__\\s*=\\s*[\\\'""]([^\\\'""]*)[\\\'""]\', f.read(), re.MULTILINE).group(1)\n\n\nwith open(\'docs/index.rst\', \'r\') as f:\n    long_description = f.read()\n\n\nwith open(\'./requirements.txt\') as f:\n    requirements = [line.strip() for line in f.readlines()]\n\n\nsetup(\n    name=\'radio\',\n    packages=find_packages(exclude=[\'examples\']),\n    version=version,\n    url=\'https://github.com/analysiscenter/radio\',\n    license=\'Apache License 2.0\',\n    author=\'Data Analysis Center team\',\n    author_email=\'radio@analysiscenter.ru\',\n    description=\'A framework for deep research of CT scans\',\n    long_description=long_description,\n    zip_safe=False,\n    platforms=\'any\',\n    install_requires=requirements,\n    extras_require={\n        \'tensorflow\': [\'tensorflow>=1.4\'],\n        \'tensorflow-gpu\': [\'tensorflow-gpu>=1.4\'],\n        \'keras\': [\'keras>=2.0.0\'],\n    },\n    classifiers=[\n        \'Development Status :: 4 - Beta\',\n        \'Intended Audience :: Developers\',\n        \'Intended Audience :: Science/Research\',\n        \'License :: OSI Approved :: Apache Software License\',\n        \'Operating System :: OS Independent\',\n        \'Programming Language :: Python\',\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.5\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Topic :: Scientific/Engineering\'\n    ],\n)\n'"
docs/conf.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# RadIO documentation build configuration file, created by\n# sphinx-quickstart on Mon Nov  6 23:59:27 2017.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\n\nsys.path.append(\'..\')\nimport radio\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.intersphinx\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.githubpages\',\n    \'sphinx.ext.napoleon\',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = \'RadIO\'\ncopyright = \'2017, analysiscenter\'\nauthor = \'analysiscenter\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The full version, including alpha/beta/rc tags.\nrelease = radio.__version__\n# The short X.Y version.\nversion = \'.\'.join(release.split(\'.\')[:2])\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = []\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'classic\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\nintersphinx_mapping = {\n    \'python\': (\'https://docs.python.org/3\', None),\n    \'numpy\': (\'http://docs.scipy.org/doc/numpy/\', None),\n    \'scipy\': (\'http://docs.scipy.org/doc/scipy/reference/\', None),\n    \'pandas\': (\'http://pandas-docs.github.io/pandas-docs-travis/\', None),\n    \'blosc\': (\'http://python-blosc.blosc.org/\', None),\n    \'batchflow\': (\'https://analysiscenter.github.io/batchflow/\', None)\n}\n\nviewcode_import = True\n\n\n# -- Options for HTMLHelp output ------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'RadIOdoc\'\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'RadIO.tex\', \'RadIO Documentation\',\n     \'analysiscenter\', \'manual\'),\n]\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'radio\', \'RadIO Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'RadIO\', \'RadIO Documentation\',\n     author, \'RadIO\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n'"
examples/plotting_tools.py,0,"b'import numpy as np\nfrom PIL import Image\n\ndef trim_cast_uint8(array, lim=None):\n    """""" Trim an array using lim as limits, transform its range to [0, 255] and\n    cast the array to uint8.\n    """"""\n    # trim\n    lim = lim if lim is not None else (np.min(array), np.max(array))\n    array = np.where(array <= lim[1], array, lim[1])\n    array = np.where(array >= lim[0], array, lim[0])\n\n    # cast\n    array = np.rint((array - lim[0]) / (lim[1] - lim[0]) * 255).astype(np.uint8)\n    return array\n\n\ndef pil_plot_slices(height, *arrays, lims=None):\n    """""" Plot slices of several 3d-np.arrays using PIL.\n    """"""\n    lims = lims if lims is not None else (None, ) * len(arrays)\n    data = []\n    for a, lim in zip(arrays, lims):\n        n_slice = int(a.shape[0] * height)\n        data.append(trim_cast_uint8(a[n_slice], lim))\n\n    data = np.concatenate(data, axis=1)\n    return Image.fromarray(data)\n\n\ndef combine_in_rgb(masks, supress=(False, False, False)):\n    """""" Combine in rgb three 2d-masks. Supress any of them, if needed.\n    """"""\n    colors = list(np.identity(3, dtype=np.uint8) * 255)\n    blended = np.zeros(shape=masks[0].shape + (3, ), dtype=np.uint8)\n    for mask, color, sup in zip(masks, colors, supress):\n        if not sup:\n            img = Image.fromarray(mask, \'L\').convert(\'RGB\')\n            rgba = np.array(img)\n            white_mask = (rgba[..., 0] == 255) & (rgba[..., 1] == 255) & (rgba[..., 2] == 255)\n            blended[..., :][white_mask] = tuple(color)\n\n    return blended\n\ndef blend_mask_to_scan(scan, mask, alpha=0.5):\n    """""" Blend a 2d rgb-mask with 2d-scan.\n    """"""\n    scan_masked = scan.copy().astype(np.int32)\n    scan_masked += mask\n    scan_masked = trim_cast_uint8(scan_masked, (0, 255))\n    return Image.blend(Image.fromarray(scan, \'RGB\'), Image.fromarray(scan_masked, \'RGB\'), alpha)\n\ndef apply_masks(scan_3d, masks_3d, height, supress=(False, False, False), alpha=0.5,\n                shape=(384, 384)):\n    """""" Put 3d-mask on 3d-scan. Resize to given shape if needed.\n    Auxilliary function for convenient usage of interact.\n    """"""\n    depth = scan_3d.shape[0]\n    n_slice = int(depth * height)\n\n    # pick slices\n    masks = [m[n_slice] if m is not None else None for m in masks_3d]\n    scan = scan_3d[n_slice]\n\n    sup = []\n    for s, m in zip(supress, masks):\n        sup.append(s or (m is None))\n\n    combined = combine_in_rgb(masks, sup)\n\n    scan_rgb = np.array(Image.fromarray(scan, \'L\').convert(\'RGB\'))\n    img = blend_mask_to_scan(scan_rgb, combined, alpha)\n    if shape is not None:\n        return img.resize(shape, Image.BILINEAR)\n    else:\n        return img\n'"
examples/research_mip.py,5,"b'import os\nos.environ[\'CUDA_VISIBLE_DEVICES\'] = \'1,2\'\n\nimport sys\nimport warnings\nwarnings.filterwarnings(""ignore"")\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nsys.path.append(\'../../\')\nfrom radio import CTImagesMaskedBatch as CTIMB\nfrom radio.batchflow import Dataset, Pipeline, FilesIndex, F, V, B, C, Config, L\nfrom radio.batchflow.research import Research, Option, KV\nfrom radio.batchflow.models.tf import UNet, VNet\n\n\n# paths to scans in blosc and annotations-table\nPATH_SCANS = \'./blosc/*\'\nPATH_ANNOTS = \'./annotations.csv\'\n\n# directory for saving models\nMODELS_DIR = \'./trained_models/\'\n\n\n# dataset and annotations-table\nindex = FilesIndex(path=PATH_SCANS, dirs=True, no_ext=False)\ndataset = Dataset(index=index, batch_class=CTIMB)\ndataset.split(0.9, shuffle=120)\nnodules = pd.read_csv(PATH_ANNOTS)\n\n\ndef train(batch, model=\'net\', minibatch_size=8, mode=\'max\', depth=6, stride=2, start=0, channels=3):\n    """""" Custom train method. Train a model in minibatches of xips, fetch loss and prediction.\n    """"""\n    # training components\n    batch.nimages = batch.xip(\'images\', mode, depth, stride, start, channels=channels)\n    batch.nmasks = batch.xip(\'masks\', \'max\', depth, stride, start, channels=channels, squeeze=True)\n\n    # train model on minibatches, fetch predictions\n    model = batch.get_model_by_name(model)\n    predictions = []\n    bs, mbs = len(batch.nimages), minibatch_size\n    order = np.random.permutation(bs)\n    num_minibatches = bs // mbs + (1 if bs % mbs > 0 else 0)\n    for i in range(num_minibatches):\n        loss, preds = model.train(fetches=[\'loss\', \'output_sigmoid\'], feed_dict={\n            \'images\': batch.nimages[order[i * mbs:(i + 1) * mbs]],\n            \'masks\': batch.nmasks[order[i * mbs:(i + 1) * mbs]],\n        })\n        predictions.append(preds)\n    predictions = np.concatenate(predictions, axis=0)\n\n    # put predictions into the pipeline\n    batch.pipeline.set_variable(\'predictions\', predictions[order])\n    batch.pipeline.set_variable(\'loss\', loss)\n\n\ndef logloss(labels, predictions, coeff=10):\n    """""" Weighted logloss.\n    """"""\n    predictions = tf.sigmoid(predictions)\n    loss = coeff * labels * tf.log(predictions) + (1 - labels) * tf.log(1 - predictions)\n    loss = -tf.reduce_mean(loss)\n    tf.losses.add_loss(loss)\n    return loss\n\n\ndef save_model(batch, pipeline, model=\'net\'):\n    """""" Function for saving model.\n    """"""\n    model = pipeline.get_model_by_name(model)\n    name = model.__class__.__name__\n    model.save(MODELS_DIR + name)\n\n\n# root, train, test pipelines\nroot_pipeline = (\n    Pipeline()\n      .load(fmt=\'blosc\', components=[\'images\', \'spacing\', \'origin\'])\n      .fetch_nodules_info(nodules=nodules)\n      .create_mask()\n      .run(batch_size=4, shuffle=True, n_epochs=None, prefetch=3, lazy=True)\n)\n\ntrain_pipeline = (\n    Pipeline()\n      .init_variables([\'loss\', \'predictions\'])\n      .init_model(\'dynamic\', C(\'model\'), \'net\', C(\'model_config\'))\n      .call(train)\n)\n\n\ntest_pipeline = (\n    Pipeline()\n      .init_variables([\'loss\', \'predictions\'])\n      .call(save_model, pipeline=C(\'train_pipeline\'))\n      .import_model(\'net\', C(\'train_pipeline\'))\n      .predict_model(\'net\', fetches=\'output_sigmoid\', feed_dict={\n          \'images\': B(\'nimages\'),\n          \'masks\': B(\'nmasks\'),\n      }, save_to=V(\'predictions\'))\n)\n\n\n# define research plan\n\n# model config\nmodel_config = dict(\n    inputs=dict(\n        images=dict(shape=(256, 256, 3)),\n        masks=dict(shape=(256, 256, 1), name=\'targets\')\n    ),\n    input_block=dict(inputs=\'images\'),\n    body=dict(filters=[8, 16, 32, 64]),\n    output=dict(ops=\'sigmoid\'),\n    loss=dict(name=logloss, coeff=10),\n    optimizer=\'Adam\',\n    session=dict(config=tf.ConfigProto(allow_soft_placement=True)),\n)\n\n\n# pipeline config\npipeline_config = Config(model_config=model_config)\ntrain_pipeline.set_config(pipeline_config)\n\n\n# specify options\nop = Option(\'model\', [UNet, VNet])\n\n\n# define research\nmr = Research()\nmr.pipeline(root_pipeline << dataset.train, train_pipeline, variables=[\'loss\'], name=\'train\')\nmr.pipeline(root_pipeline << dataset.test, test_pipeline, variables=[\'loss\'], name=\'test\',\n            train_pipeline=\'train\', execute_for=1000)\nmr.grid(op)\n\n\n# run research\nmr.run(n_reps=1, n_iters=50000, workers=1, branches=gpus, name=\'MIP_research\')\n'"
examples/split_dump_npcmr.py,0,"b'"""""" Generate crops (using split_dump) from npcmr-dataset. """"""\n\nimport os\nimport sys\n\nimport glob\nimport numpy as np\nimport pandas as pd\nimport pickle as pkl\n\nimport radio.annotation\nfrom radio.batchflow import FilesIndex, Dataset, Pipeline, F\nfrom radio import split_dump, CTImagesMaskedBatch\n\nNPCMR_GLOB = \'/notebooks/data/CT/npcmr/*/*/*/*/*/*\'\nMERGED_NODULES_PATH = \'./merged_nodules.pkl\'\nHISTO_PATH = \'./histo.pkl\'\nNODULE_CONFIDENCE_THRESHOLD = 0.02\nTRAIN_SHARE = 0.9\nCANCEROUS_CROPS_PATH = \'/notebooks/data/CT/npcmr_crops/train/cancerous\'\nNONCANCEROUS_CROPS_PATH = \'/notebooks/data/CT/npcmr_crops/train/noncancerous\'\n\n# read df containing info about nodules on scans\ndataset_info = (radio.annotation.read_dataset_info(NPCMR_GLOB, index_col=\'seriesid\', filter_by_min_spacing=True,\n                                                   load_origin=False))\n\n# set up Index and Dataset for npcmr\nct_index = FilesIndex(dataset_info.index.values, paths=dict(dataset_info.loc[:, \'ScanPath\']), dirs=True)\nct_dataset = Dataset(ct_index, batch_class=CTImagesMaskedBatch)\n\n# read dumped annots\nwith open(MERGED_NODULES_PATH, \'rb\') as file:\n    merged = pkl.load(file)\n\n# filter nodules by confidences\nfiltered = merged[merged.confidence > NODULE_CONFIDENCE_THRESHOLD]\n\nct_dataset.split(TRAIN_SHARE)\n\n# read histo of nodules locs\nwith open(HISTO_PATH, \'rb\') as file:\n    histo = pkl.load(file)\n\n# split dump pipeline\nsd = split_dump(CANCEROUS_CROPS_PATH, NONCANCEROUS_CROPS_PATH, filtered, histo, fmt=\'dicom\')\n\n# run the pipeline\nprint(\'Running split_dump...\')\n(ct_dataset >> sd).run()\n'"
radio/__init__.py,0,"b'# pylint: disable=import-error\n# pylint: disable=wildcard-import\n""""""3d ct-scans preprocessing module with dataset submodule.""""""\nimport importlib\nfrom .preprocessing import *\nfrom .pipelines import *\nfrom . import batchflow\n\n__version__ = \'0.1.0\'\n'"
tutorials/utils.py,0,"b'import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom PIL import Image\n\ndef get_pixel_coords(nodules):\n    """""" Get nodules info in pixel coords from nodules recarray.\n    """"""\n    coords = (nodules.nodule_center - nodules.origin) / nodules.spacing\n    diams = np.ceil(nodules.nodule_size / nodules.spacing)\n    nodules = np.rint(np.hstack([coords, diams])).astype(np.int)\n    return nodules\n\ndef pil_plot_slices(height, *arrays, lims=None):\n    """""" Plot slices of several 3d-np.arrays using PIL.\n    """"""\n    lims = lims if lims is not None else (None, ) * len(arrays)\n    data = []\n    for a, lim in zip(arrays, lims):\n        n_slice = int(a.shape[0] * height)\n        data.append(trim_cast_uint8(a[n_slice], lim))\n\n    data = np.concatenate(data, axis=1)\n    return Image.fromarray(data)\n\ndef trim_cast_uint8(array, lim=None):\n    """""" Trim an array using lim as limits, transform its range to [0, 255] and\n    cast the array to uint8.\n    """"""\n    # trim\n    lim = lim if lim is not None else (np.min(array), np.max(array))\n    array = np.where(array <= lim[1], array, lim[1])\n    array = np.where(array >= lim[0], array, lim[0])\n\n    # cast\n    array = np.rint((array - lim[0]) / (lim[1] - lim[0]) * 255).astype(np.uint8)\n    return array\n\ndef show_images(mnist_batch):\n    """""" Show images from ImageBatch with mnist\n    """"""\n    imgs = mnist_batch.images[..., 0]\n    _, axes = plt.subplots(1, len(imgs))\n    for i, img in enumerate(imgs):\n        axes[i].imshow(img, cmap=plt.cm.gray)\n\ndef load_example(path, radio, fmt=\'blosc\', ix=\'1.3.6.1.4.1.14519.5.2.1.6279.6001.621916089407825046337959219998\'):\n    """""" Load example batch from disk\n    """"""\n    from radio import CTImagesMaskedBatch as CTIMB\n    from radio.batchflow import Pipeline, FilesIndex, Dataset\n    path = os.path.join(path, ix)\n    luna_index = FilesIndex(path=path, dirs=True)\n    lunaset =  Dataset(luna_index, batch_class=CTIMB)\n    load_ppl = (Pipeline()\n                 .load(fmt=\'blosc\', components=[\'images\', \'spacing\', \'origin\', \'masks\']) << lunaset)\n\n    btch = load_ppl.next_batch(1)\n    return btch\n\ndef get_nodules_pixel_coords(batch):\n    """""" get numpy array of nodules-locations and diameter in relative coords\n    """"""\n    nodules_dict = dict()\n    nodules_dict.update(numeric_ix=batch.nodules.patient_pos)\n    pixel_zyx = np.rint((batch.nodules.nodule_center - batch.nodules.origin) / batch.nodules.spacing).astype(np.int)\n    nodules_dict.update({\'coord\' + letter: pixel_zyx[:, i] for i, letter in enumerate([\'Z\', \'Y\', \'X\'])})\n    nodules_dict.update({\'diameter_pixels\': (np.rint(batch.nodules.nodule_size / batch.nodules.spacing).mean(axis=1)\n                                             .astype(np.int))})\n    pixel_nodules_df = pd.DataFrame.from_dict(nodules_dict).loc[:, (\'numeric_ix\', \'coordZ\', \'coordY\',\n                                                                    \'coordX\', \'diameter_pixels\')]\n    return pixel_nodules_df\n\ndef num_of_cancerous_pixels(batch, max_num=10):\n    """""" Calculate number of cancerous pixels in items from batch\n    """"""\n    stats = dict()\n    n_print = min(max_num, len(batch))\n    for i in range(n_print):\n        stats.update({\'Scan \' + str(i): int(np.sum(batch.get(i, \'masks\')))})\n\n    stats = {\'Number of cancerous  pixels: \': stats}\n    stats_df = pd.DataFrame.from_dict(stats, orient=\'index\').loc[:, [\'Scan \'+ str(i) for i in range(n_print)]]\n    return stats_df\n\ndef show_slices(batches, scan_indices, ns_slice, grid=True, **kwargs):\n    """""" Plot slice with number n_slice from scan with index given by scan_index from batch\n    """"""\n    font_caption = {\'family\': \'serif\',\n                    \'color\':  \'darkred\',\n                    \'weight\': \'normal\',\n                    \'size\': 18}\n    font = {\'family\': \'serif\',\n            \'color\':  \'darkred\',\n            \'weight\': \'normal\',\n            \'size\': 15}\n\n    # fetch some arguments, make iterables out of args\n    def iterize(arg):\n        return arg if isinstance(arg, (list, tuple)) else (arg, )\n\n    components = kwargs.get(\'components\', \'images\')\n    batches, scan_indices, ns_slice, components  = [iterize(arg) for arg in (batches, scan_indices,\n                                                                             ns_slice, components)]\n    clims = kwargs.get(\'clims\', (-1200, 300))\n    clims = clims if isinstance(clims[0], (tuple, list)) else (clims, )\n\n    # lengthen args\n    n_boxes = max(len(arg) for arg in (batches, scan_indices, ns_slice, clims))\n    def lengthen(arg):\n        return arg if len(arg) == n_boxes else arg * n_boxes\n\n    batches, scan_indices, ns_slice, clims, components = [lengthen(arg) for arg in (batches, scan_indices, ns_slice,\n                                                                                    clims, components)]\n\n    # plot slices\n    _, axes = plt.subplots(1, n_boxes, squeeze=False, figsize=(10, 4 * n_boxes))\n\n    zipped = zip(range(n_boxes), batches, scan_indices, ns_slice, clims, components)\n\n    for i, batch, scan_index, n_slice, clim, component in zipped:\n        slc = batch.get(scan_index, component)[n_slice]\n        axes[0][i].imshow(slc, cmap=plt.cm.gray, clim=clim)\n        axes[0][i].set_xlabel(\'Shape: {}\'.format(slc.shape[1]), fontdict=font)\n        axes[0][i].set_ylabel(\'Shape: {}\'.format(slc.shape[0]), fontdict=font)\n        title = \'Scan\' if component == \'images\' else \'Mask\'\n        axes[0][i].set_title(\'{} #{}, slice #{} \\n \\n\'.format(title, scan_index, n_slice), fontdict=font_caption)\n        axes[0][i].text(0.2, -0.25, \'Total slices: {}\'.format(len(batch.get(scan_index, component))),\n                        fontdict=font_caption, transform=axes[0][i].transAxes)\n\n        # set inverse-spacing grid\n        if grid:\n            inv_spacing = 1 / batch.get(scan_index, \'spacing\').reshape(-1)[1:]\n            step_mult = 50\n            xticks = np.arange(0, slc.shape[0], step_mult * inv_spacing[0])\n            yticks = np.arange(0, slc.shape[1], step_mult * inv_spacing[1])\n            axes[0][i].set_xticks(xticks, minor=True)\n            axes[0][i].set_yticks(yticks, minor=True)\n            axes[0][i].set_xticks([], minor=False)\n            axes[0][i].set_yticks([], minor=False)\n\n            axes[0][i].grid(color=\'r\', linewidth=1.5, alpha=0.5, which=\'minor\')\n\n\n    plt.show()\n'"
radio/annotation/__init__.py,0,"b'"""""" Functions for processing annotation provided for dicom dataset. """"""\n\nfrom .parser import read_nodules, read_dataset_info, read_annotators_info\nfrom .nodules_merger import assign_nodules_group_index, get_nodules_groups\nfrom .nodules_merger import compute_group_coords_and_diameter\nfrom .doctor_confidence import get_doctors_confidences, get_rating, get_table\nfrom .nodule_confidence import compute_nodule_confidence\n'"
radio/annotation/doctor_confidence.py,0,"b'"""""" Functions to compute doctors\' confidences from annotation. """"""\n\nimport itertools\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom numba import njit\nimport multiprocess as mp\n\ndef get_doctors_confidences(nodules, confidences=\'random\', n_consiliums=10, n_iters=25, n_doctors=15,\n                            factor=0.3, alpha=0.7, history=False, smooth=None):\n    """""" Compute confidences for doctors\n\n    Parameters\n    ----------\n    nodules : pd.DataFrame\n        DataFrame with columns\n        `[\'seriesuid\', \'DoctorID\', \'coordZ\', \'coordY\', \'coordX\', \'diameter_mm\', \'NoduleID\']`\n    confidences : str or list of len n_doctors\n        if \'random\', initial confidences will be sampled\n        if \'uniform\', initial confidences is a uniform distribution\n        if list, confidences of doctors\n    n_consiliums : int or None\n        number of consiliums for each doctor. If None, all possible consiliums will be used\n    n_iters : int\n        number of iterations of updating algorithm\n    n_doctors : int\n        number of doctors\n    factor : float\n        ratio for mask creation\n    alpha : float\n        smoothing parameter of confidence update\n    history : bool\n        if False, the function returns final confidences, if True, all history of updating confidences\n    smooth : int or None\n         if int, final confidence is a smoothed confidence by last `smooth` iterations\n\n    Returns\n    -------\n    new_confidences : pd.DataFrame\n    """"""\n    annotators_info = (\n        nodules\n        .drop_duplicates([\'seriesuid\', \'DoctorID\'])\n        .assign(DoctorID=lambda df: [\'doctor_\'+str(doctor).zfill(3) for doctor in df.DoctorID])\n        .pivot(\'seriesuid\', \'DoctorID\', \'DoctorID\')\n        .notna()\n        .astype(\'int\')\n    )\n\n    nodules = (\n        nodules\n        .join(annotators_info, on=\'seriesuid\', how=\'left\')\n        .assign(n_annotators=lambda df: df.filter(regex=r\'doctor_\\d{3}\', axis=1).sum(axis=1))\n        .query(\'n_annotators >= 3\')\n        .drop(\'n_annotators\', axis=1)\n        .dropna()\n    )\n\n    for i in range(n_doctors):\n        if \'doctor_{:03d}\'.format(i) not in nodules.columns:\n            nodules[\'doctor_{:03d}\'.format(i)] = 0\n\n    if confidences == \'random\':\n        confidences = np.ones(n_doctors) / 2 + np.random.uniform(-0.1, 0.1, n_doctors)\n    elif confidences == \'uniform\':\n        confidences = np.ones(n_doctors) / 2\n\n    confidences_history = [pd.DataFrame({\'DoctorID\': [str(i).zfill(3) for i in range(n_doctors)],\n                                         \'confidence\': confidences, \'iteration\': 0})]\n\n    consiliums = [_consiliums_for_doctor(nodules, doctor, n_doctors) for doctor in range(n_doctors)]\n    consiliums_probabilities = _consiliums_prob(nodules, n_doctors)\n\n    for i in tqdm(range(n_iters)):\n        confidences = _update_confidences(nodules, confidences, consiliums, n_consiliums,\n                                          consiliums_probabilities, n_doctors, factor, alpha)\n        confidences_history.append(pd.DataFrame({\'DoctorID\': [str(i).zfill(3) for i in range(n_doctors)],\n                                                 \'confidence\': confidences, \'iteration\': i+1}))\n    if history:\n        res = pd.concat(confidences_history, axis=0)\n    else:\n        if smooth is None:\n            res = confidences_history[-1].drop(columns=[\'iteration\'])\n        else:\n            res = (\n                pd\n                .concat(confidences_history, axis=0)\n                .pivot(index=\'iteration\', columns=\'DoctorID\', values=\'confidence\')\n            )\n            res = (\n                nodules\n                .set_index(\'DoctorID\')\n                .assign(DoctorConfidence=res.rolling(smooth).mean().iloc[-1, :])\n                .reset_index()\n            )\n    return res\n\ndef _consiliums_prob(nodules, n_doctors):\n    result = np.zeros((n_doctors, n_doctors))\n    denom = 0\n    for i, j in list(zip(*np.triu_indices(n_doctors, k=1))):\n        doc1, doc2 = [\'doctor_{:03d}\'.format(doctor) for doctor in [i, j]] #pylint:disable=cell-var-from-loop\n        accession_numbers = (\n            nodules[[\'seriesuid\', doc1, doc2]]\n            .assign(together=lambda df: df[doc1] == df[doc2]) #pylint:disable=cell-var-from-loop\n            .drop_duplicates()\n        )\n        accession_numbers = accession_numbers[accession_numbers[doc1] == 1]\n        accession_numbers = accession_numbers[accession_numbers.together]\n        result[i, j] = result[j, i] = len(accession_numbers)\n        denom += len(accession_numbers)\n    return result / denom\n\ndef _consiliums_for_doctor(nodules, doctor, n_doctors):\n    id_and_consiliums = []\n    for seriesuid in nodules.query(""doctor_{:03d} == 1"".format(doctor)).seriesuid.unique():\n        image_nodules = nodules[nodules.seriesuid == seriesuid]\n        annotators = image_nodules.filter(regex=r\'doctor_\\d{3}\', axis=1).sum()\n        annotators = [int(name[-3:]) for name in annotators[annotators != 0].keys()]\n        annotators.remove(doctor)\n        consiliums = itertools.combinations(annotators, 2)\n        id_and_consiliums.extend(list(itertools.product([seriesuid], consiliums)))\n    return id_and_consiliums\n\ndef _update_confidences(nodules, confidences, consiliums, n_consiliums, consiliums_probabilities,\n                        n_doctors=15, factor=0.3, alpha=0.7):\n    args = []\n    for doctor, doctor_consiliums in enumerate(consiliums):\n        if len(doctor_consiliums) != 0:\n            if n_consiliums is None:\n                sample = doctor_consiliums\n            else:\n                sample_indices = np.random.choice(\n                    len(doctor_consiliums),\n                    size=min(n_consiliums, len(doctor_consiliums)),\n                    replace=False\n                )\n                sample = [doctor_consiliums[i] for i in sample_indices]\n            for seriesuid, consilium in sample:\n                args.append((nodules[nodules.seriesuid == seriesuid], doctor,\n                             consilium, factor, confidences))\n\n    pool = mp.Pool() #pylint:disable=no-member\n    results = pool.map(_consilium_results, args)\n    pool.close()\n\n    new_confidences = confidences.copy()\n    sum_weights = np.zeros(n_doctors)\n\n    for doctor, consilium, score in results:\n        weight = 1 / consiliums_probabilities[consilium[0], consilium[1]]\n        new_confidences[doctor] += weight * score\n        sum_weights[doctor] += weight\n    new_confidences = new_confidences / sum_weights\n\n    confidences = confidences * alpha + new_confidences * (1 - alpha)\n    return confidences\n\n\ndef _consilium_results(args):\n    image_nodules, doctor, consilium, factor, confidences = args\n    if image_nodules.DoctorID.isna().iloc[0]:\n        return doctor, 1\n    else:\n        mask = create_mask(image_nodules, doctor, consilium, factor=factor)\n        consilium_confidences = confidences[list(consilium)]\n        consilium_confidences = consilium_confidences / np.sum(consilium_confidences)\n        print(consilium_confidences)\n        return doctor, consilium, consilium_dice(mask, consilium_confidences)\n\n\ndef _compute_mask_size(nodules):\n    return np.ceil(((nodules.coordX + nodules.diameter_mm + 10).max(),\n                    (nodules.coordY + nodules.diameter_mm + 10).max(),\n                    (nodules.coordZ + nodules.diameter_mm + 10).max())).astype(np.int32)\n\n\ndef _create_empty_mask(mask_size, n_doctors):\n    mask_size = list(mask_size) + [n_doctors]\n    res = np.zeros(mask_size)\n    return res\n\n\ndef create_mask(image_nodules, doctor, annotators, factor):\n    """""" Create nodules mask.\n\n    Parameters\n    ----------\n    image_nodules : pd.DataFrame\n\n    doctor : int\n        doctor to estimate\n    annotators : list or np.array\n        doctors in consilium\n    factor : float\n        ratio mm / pixels\n\n    Returns\n    -------\n    mask : np.ndarray\n    """"""\n    nodules = image_nodules.copy()\n\n    nodules.diameter_mm *= factor\n    nodules.coordX *= factor\n    nodules.coordY *= factor\n    nodules.coordZ *= factor\n\n    nodules.coordX -= nodules.coordX.min() - nodules.diameter_mm.max()\n    nodules.coordY -= nodules.coordY.min() - nodules.diameter_mm.max()\n    nodules.coordZ -= nodules.coordZ.min() - nodules.diameter_mm.max()\n\n    mask_size = list(_compute_mask_size(nodules))\n\n    mask = _create_empty_mask(mask_size, len(annotators)+1)\n\n    for i, annotator in enumerate([doctor] + list(annotators)):\n        annotator_nodules = nodules[nodules.DoctorID.astype(int) == annotator]\n        coords = np.array(annotator_nodules[[\'coordX\', \'coordY\', \'coordZ\']], dtype=np.int32)\n        diameters = np.array(annotator_nodules.diameter_mm, dtype=np.int32)\n        mask[..., i] = _create_mask_numba(mask[..., i], coords, diameters)\n\n    return mask\n\n@njit\ndef _create_mask_numba(mask, coords, diameters):\n    for i, _ in enumerate(coords):\n        center = coords[i]\n        diameter = diameters[i]\n\n        begin_x = np.maximum(0, center[0]-diameter)\n        begin_y = np.maximum(0, center[1]-diameter)\n        begin_z = np.maximum(0, center[2]-diameter)\n\n        end_x = np.minimum(mask.shape[0], center[0]+diameter+1)\n        end_y = np.minimum(mask.shape[1], center[1]+diameter+1)\n        end_z = np.minimum(mask.shape[2], center[2]+diameter+1)\n\n        for x in range(begin_x, end_x):\n            for y in range(begin_y, end_y):\n                for z in range(begin_z, end_z):\n                    if (x - center[0]) ** 2 + (y - center[1]) ** 2 + (z - center[2]) ** 2 < (diameter) ** 2:\n                        mask[x, y, z] = 1\n    return mask\n\n\ndef consilium_dice(mask, consilium_confidences):\n    """""" Compute consilium dice for current doctor.\n\n    Parameters\n    ----------\n    mask : np.ndarray\n\n    consilium_confidences : np.ndarray\n\n    Returns\n    -------\n    dice : float\n        dice which is computed as dice of binary doctor mask and weighted mask of doctors by their confidences\n    """"""\n    doctor_mask = mask[..., 0]\n    consilium_mask = mask[..., 1:]\n    consilium_confidences = np.array([0.5, 0.5])\n    ground_truth = np.sum(consilium_mask * consilium_confidences, axis=-1)\n\n    return dice(doctor_mask, ground_truth)\n\n\ndef dice(mask1, mask2):\n    """""" Simple dice. """"""\n    e = 1e-6\n\n    tp = np.sum(2 * mask1 * mask2) + e\n    den = np.sum(mask1 + mask2) + e\n\n    return tp / den\n\n\ndef get_rating(confidences):\n    """""" Get list of doctors ordered by confidence. """"""\n    return np.array([item[0] for item in sorted(enumerate(confidences), key=lambda x: -x[1])])\n\n\ndef get_table(nodules, n_doctors=15, factor=0.3):\n    """""" Create tables.\n\n    Parameters\n    ----------\n    nodules : pd.DataFrame\n\n    n_doctors : int\n        number of doctors\n    factor : float\n        ratio for mask creation\n\n    Returns\n    -------\n    np.ndarray\n        table of the mean dice between two doctors\n    np.ndarray\n        table of the number of meetings between two doctors\n    """"""\n    table = np.zeros((n_doctors, n_doctors))\n    table_meetings = np.zeros((n_doctors, n_doctors))\n\n    for i, j in tqdm(list(zip(*np.triu_indices(n_doctors, k=1)))):\n        accession_numbers = (\n            nodules\n            .groupby(\'seriesuid\')\n            .apply(lambda x: i in x.DoctorID.astype(int).values and j in x.DoctorID.astype(int).values) #pylint:disable=cell-var-from-loop\n        )\n        accession_numbers = accession_numbers[accession_numbers].index\n        table_meetings[i, j] = len(accession_numbers)\n        table_meetings[j, i] = len(accession_numbers)\n        dices = []\n        for accession_number in accession_numbers:\n            if len(nodules[nodules.seriesuid == accession_number].dropna()) != 0:\n                mask = create_mask(nodules[nodules.seriesuid == accession_number].dropna(), i, [j], factor)\n                mask1 = mask[..., 0]\n                mask2 = mask[..., 1]\n                dices.append(dice(mask1, mask2))\n            else:\n                dices.append(1)\n        table[i, j] = table[j, i] = np.mean(dices)\n\n    return table, table_meetings\n\ndef generate_nodule(size=1):\n    """""" Generate nodules\n\n    Parameters\n    ----------\n    size : int\n        number of nodules\n\n    Returns\n    -------\n    dict\n        dict of nodules with keys `coordX, coordY, coordZ, diameter_mm`\n    """"""\n    coordX = np.random.uniform(-230.9075 / 2, 1191.48908 / 2, size)\n    coordY = np.random.uniform(-229.933 / 2, 1356.4289999999999 /2, size)\n    coordZ = np.random.uniform(-1147.5 / 2, 4528.5 / 2, size)\n    diameter_mm = np.random.randint(1, 15, size)\n    return {\'coordX\': coordX, \'coordY\': coordY, \'coordZ\': coordZ, \'diameter_mm\': diameter_mm}\n\ndef generate_annotation(n_images, n_doctors=10, bad_doctors=None, middle_doctors=None):\n    """""" Generate annotation\n\n    Parameters\n    ----------\n    n_images : int\n\n    n_doctors : int\n\n    bad_doctors : list or None (then `[0]`)\n        indices of doctors who select nodules that don\'t coincide with nodules of other doctors\n    middle_doctors : list or None (then `[]`)\n        indices of doctors who select nodules that don\'t coincide with nodules of other doctors\n        and also select nodules that coincide with nodules of good doctors.\n        All good doctors always select the same nodules.\n\n    Returns\n    -------\n    pd.DataFrame\n        annotation with columns `[\'seriesuid\', \'DoctorID\', \'coordZ\', \'coordY\', \'coordX\', \'diameter_mm\']`\n    """"""\n    bad_doctors = bad_doctors or [0]\n    middle_doctors = middle_doctors or [0]\n    annotation = pd.DataFrame({\'seriesuid\': [], \'DoctorID\': [], \'coordX\': [],\n                               \'coordY\': [], \'coordZ\': [], \'diameter_mm\': []})\n    for i in range(n_images):\n        doctors = np.random.choice(np.arange(0, n_doctors), size=np.random.randint(3, 5), replace=False)\n\n        for doctor in bad_doctors + middle_doctors:\n            if doctor in doctors:\n                doctor_find = np.random.randint(0, 4)\n                doctor_nodules = pd.DataFrame({\n                    \'seriesuid\': [str(i)] * doctor_find,\n                    \'DoctorID\': [str(doctor).zfill(3)] * doctor_find,\n                    **generate_nodule(doctor_find)\n                })\n                annotation = pd.concat([annotation, doctor_nodules], axis=0)\n\n        consilium_find = np.random.randint(0, 4)\n        nod = generate_nodule(consilium_find)\n\n        for d in doctors:\n            if d not in bad_doctors:\n                doctor_nodules = pd.DataFrame({\n                    \'seriesuid\': [str(i)] * consilium_find,\n                    \'DoctorID\': [str(d).zfill(3)] * consilium_find,\n                    **nod\n                })\n            annotation = pd.concat([annotation, doctor_nodules], axis=0)\n    annotation = annotation.reset_index()\n    del annotation[\'index\']\n    return annotation\n'"
radio/annotation/nodule_confidence.py,0,"b'""""""  Functions form nodules\' confidences computation. """"""\n\nimport numpy as np\nimport pandas as pd\n\ndef ep(u):\n    """""" Vectorized Epanechnikov kernel.\n\n    Parameters\n    ----------\n    u : ndarray\n        input array of distances.\n\n    Return\n    ------\n    ndarray\n        array of ep(input array-items).\n    """"""\n    return 0.75 * (1 - u**2) * (np.abs(u) <= 1).astype(np.float)\n\n\ndef compute_nodule_confidence(annotations, r=20, alpha=None, weight_by_doctor=True):\n    """""" Compute nodule confidence using annotations-df; put confidences into a new column\n    \'NoduleConfidence\'.\n\n    Parameters\n    ----------\n    annotations : pd.DataFrame\n        input df with annotations with columns\n        `[\'seriesuid\', \'DoctorID\', \'coordZ\', \'coordY\', \'coordX\', \'diameter_mm\', \'NoduleID\', \'DoctorConfidence\']`\n    r : float\n        radius of kernel-support.\n    alpha : float or None\n        weight of target-nodule\'s doctor in weighted sum.\n    weight_by_doctor : bool\n        whether the weighted sum should be weighted by target-nodule\'s doctor.\n\n    Return\n    ------\n    pd.DataFrame\n        annotations-dataframe with added \'NoduleConfidence\'-column.\n    """"""\n    # matrix of distances between nodules from the same scan\n    cleaned = annotations.loc[:, [\'coordZ\', \'coordY\', \'coordX\', \'seriesuid\',\n                                  \'DoctorID\', \'NoduleID\', \'DoctorConfidence\']]\n\n    pairwise = pd.merge(cleaned, cleaned, how=\'inner\', left_on=\'seriesuid\',\n                        right_on=\'seriesuid\', suffixes=(\'\', \'_other\'))\n\n    pairwise[\'Distance\'] = np.sqrt((pairwise.coordX - pairwise.coordX_other) ** 2\n                                   + (pairwise.coordY - pairwise.coordY_other)** 2\n                                   + (pairwise.coordZ - pairwise.coordZ_other) ** 2)\n\n    pairwise = pairwise.drop(labels=[\'coordZ\', \'coordY\', \'coordX\', \'coordZ_other\',\n                                     \'coordY_other\', \'coordX_other\'], axis=1)\n\n    # compute kernel-weights of nodules\n    pairwise = pairwise[pairwise.Distance <= r]\n    pairwise[\'weights\'] = ep(pairwise.Distance / r)\n    pairwise[\'weights\'] *= np.maximum(pairwise.DoctorID_other != pairwise.DoctorID,\n                                      pairwise.NoduleID_other == pairwise.NoduleID)\n\n    # compute confidences\n    pairwise[\'weighted_confs\'] = (pairwise[\'weights\'] * pairwise[\'DoctorConfidence_other\'])\n\n    # add doctor weights if needed\n    if weight_by_doctor:\n        pairwise[\'weighted_confs\'] *= pairwise[\'DoctorConfidence\']\n\n    # add correction for alpha-confidences if needed\n    if alpha is not None:\n        # get rid of kernel weights before target-nodules and weight by alpha, 1 - alpha\n        pairwise.loc[pairwise.NoduleID_other == pairwise.NoduleID, \'weighted_confs\'] *= alpha / ep(0)\n        pairwise.loc[pairwise.NoduleID_other != pairwise.NoduleID, \'weighted_confs\'] *= 1 - alpha\n\n    confs = pairwise.groupby(\'NoduleID\').weighted_confs.sum()\n    confs = pd.DataFrame(confs)\n    confs.rename({\'weighted_confs\': \'NoduleConfidence\'}, axis=1, inplace=True)\n    return pd.merge(annotations, confs, left_on=\'NoduleID\', right_index=True)\n'"
radio/annotation/nodules_merger.py,0,"b'"""""" Functions for mapping sets of overlapping nodules into one nodule. """"""\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom numba import njit\nfrom .parser import generate_index\nfrom ..models.utils import sphere_overlap\n\n\n@njit\ndef compute_overlap_distance_matrix(coords, diameters):\n    """""" Compute pairwise overlap matrix.\n\n    Parameters\n    ----------\n    coords : ndarray(num_nodules, 3)\n        cooordinates of nodules\' centers.\n    diameters : ndarray(num_nodules)\n        diameters of nodules.\n\n    Returns\n    -------\n    ndarray(num_nodules, num_nodules)\n        overlap distance matrix required by clustering algorithm.\n    """"""\n    num_nodules = coords.shape[0]\n    overlap_matrix = np.zeros(shape=(num_nodules, num_nodules))\n    buffer = np.zeros((2, 4))\n    for i in range(num_nodules):\n        for j in range(num_nodules):\n            buffer[0, 1:], buffer[1, 1:] = coords[i, :], coords[j, :]\n            buffer[0, 0], buffer[1, 0] = diameters[i], diameters[j]\n            overlap_matrix[i, j] = sphere_overlap(buffer[0, :], buffer[1, :])\n    return overlap_matrix\n\n\n@njit\ndef compute_reachable_vertices_numba(distance_matrix, vertex, threshold):\n    """""" Get vertices that can be reached from given vertex using distance matrix.\n\n    Parameters\n    ----------\n    distance_matrix : ndarray(num_nodules, num_nodules)\n        overlap distance matrix for all nodules pairs.\n    vertex : int\n        input vertex.\n    threshold : float\n        threshold for volumetric intersection over union for pairs of nodules\n        to consider them overlapping.\n\n    Returns\n    -------\n    ndarray(num_vertices)\n        vertices that can be reached from given vertex.\n    """"""\n    num_vertices = distance_matrix.shape[0]\n\n    all_vertices = np.arange(num_vertices)\n    reachable = np.zeros(num_vertices)\n    unprocessed = np.zeros(num_vertices)\n    reachable = (reachable == 1)\n    unprocessed = (unprocessed == 1)\n    unprocessed[vertex] = True\n    while np.any(unprocessed):\n        u = all_vertices[unprocessed][0]\n        vertices = (distance_matrix[u, :] > threshold)\n\n        unprocessed[np.logical_and(vertices, ~reachable)] = True\n\n        reachable[u] = True\n        unprocessed[u] = False\n    return all_vertices[reachable]\n\n\n@njit\ndef compute_clusters_numba(coords, diameters, threshold):\n    """""" Compute clusters for nodules represented by coordinates of centers and diameters.\n\n    Parameters\n    ----------\n    coords : ndarray(num_nodules, 3)\n        cooordinates of nodules\' centers.\n    diameters : ndarray(num_nodules)\n        diameters of nodules.\n\n    Returns\n    -------\n    ndarray(num_nodules)\n        cluster number for each nodule.\n    """"""\n    distance_matrix = compute_overlap_distance_matrix(coords, diameters)\n    num_elements = distance_matrix.shape[0]\n    all_vertices = np.arange(num_elements)\n    clusters = -np.ones(num_elements)\n    current_cluster = 0\n    while len(clusters[clusters == -1]) > 0:\n        v = np.random.choice(all_vertices[clusters == -1], 1)\n        cluster_vertices = compute_reachable_vertices_numba(distance_matrix, v, threshold)\n        clusters[cluster_vertices] = current_cluster\n        current_cluster += 1\n    return clusters\n\n\n\ndef assign_nodules_group_index(nodules, threshold=0.1):\n    """""" Add column with name \'GroupNoduleID\' containing index of group of overlapping nodules.\n\n    Parameters\n    ----------\n    nodules : pandas DataFrame\n        dataframe with information about nodules locations and centers.\n\n    threshold : float\n        float from [0, 1] interval representing volumentric intersection over union.\n\n    Returns\n    -------\n    pandas DataFrame\n    """"""\n    coords = nodules.loc[:, [\'coordZ\', \'coordY\', \'coordX\']].values\n    diameters = nodules.loc[:, \'diameter_mm\'].values\n    clusters = np.array(compute_clusters_numba(coords, diameters, threshold), dtype=np.int)\n    clusters_names = np.array([generate_index() for cluster_num in np.sort(np.unique(clusters))])\n    group_nodule_id = pd.Series(clusters_names[clusters], index=nodules.index)\n    return nodules.assign(GroupNoduleID=group_nodule_id)\n\n\ndef get_diameter_by_sigma(sigma, proba):\n    """""" Get diameter of nodule given sigma of normal distribution and probability of diameter coverage area.\n\n    Transforms sigma parameter of normal distribution corresponding to cancerous nodule\n    to its diameter using probability of diameter coverage area.\n\n    Parameters\n    ----------\n    sigma : float\n        square root of normal distribution variance.\n    proba : float\n        probability of diameter coverage area.\n\n    Returns\n    -------\n    float\n        equivalent diameter.\n    """"""\n    return 2 * sigma * stats.norm.ppf((1 + proba) / 2)  # pylint: disable=no-member\n\n\ndef get_sigma_by_diameter(diameter, proba):\n    """""" Get sigma of normal distribtuion by diameter of nodule and probability of diameter coverage area.\n\n    Parameters\n    ----------\n    diameter : float\n        diameter of nodule.\n    proba : float\n        probability of diameter coverage area.\n\n    Returns\n    -------\n    float\n        equivalent normal distribution\'s sigma parameter.\n    """"""\n    return diameter / (2 * stats.norm.ppf((1 + proba) / 2))  # pylint: disable=no-member\n\n\ndef approximate_gaussians(confidence_array, mean_array, variance_array):\n    """""" Approximate gaussians with given parameters with one gaussian.\n\n    Approximation is performed via minimization of Kullback-Leibler\n    divergence KL(sum_{j} w_j N_{mu_j, sigma_j} || N_{mu, sigma}).\n\n    Parameters\n    ----------\n    confidence_array : ndarray(num_gaussians)\n        confidence values for gaussians.\n    mean_array : ndarray(num_gaussians, 3)\n        (z,y,x) mean values for input gaussians.\n    variance_array : ndarray(num_gaussians)\n        (z,y,x) variances for input gaussians.\n\n    Returns\n    -------\n    tuple(ndarray(3), ndarray(3))\n        mean and sigma for covering gaussian.\n    """"""\n    delimiter = np.sum(confidence_array)\n    mu = np.sum(mean_array.T * confidence_array, axis=1) / delimiter\n    sigma = np.sqrt(np.sum((variance_array + (mean_array - mu) ** 2).T\n                           * confidence_array, axis=1) / delimiter)\n    return mu, sigma\n\n\ndef compute_group_coords_and_diameter(nodules, proba=0.8):\n    """""" Get coordinates of center and diameter of nodules united in group.\n\n    For each group of overlapping nodules computes equivalent diameter and\n    coordinates of center. Preserves \'confidence\' and \'seriesuid\'\n    columns from source nodules dataframe. Note, that this columns\n    are considered to contain same values within group.\n\n    Parameters\n    ----------\n    nodules : pandas DataFrame\n        dataframe with information about nodules location and sizes.\n    proba : float\n        float value from [0, 1] interval. Probability of diameter coverage area\n        for equivalent normal distribution.\n\n    Returns\n    -------\n    pandas DataFrame\n        dataframe with information about equivalent locations and diameters of\n        groups of overlapping nodules.\n    """"""\n    num_nodules = nodules.shape[0]\n    confidence_array = np.zeros(num_nodules, dtype=np.float64)\n    mean_array = np.zeros((num_nodules, 3), dtype=np.float64)\n    variance_array = np.zeros(num_nodules, dtype=np.float64)\n    for i, (_, row) in enumerate(nodules.iterrows()):\n        mean_array[i, :] = np.array((row[\'coordZ\'], row[\'coordY\'], row[\'coordX\']))\n        variance_array[i] = get_sigma_by_diameter(row[\'diameter_mm\'], proba=proba) ** 2\n        confidence_array[i] = row[\'NoduleConfidence\']\n\n    variance_array = np.tile(variance_array[:, np.newaxis], (1, 3))\n    approx_mean, approx_sigma = approximate_gaussians(confidence_array, mean_array, variance_array)\n    return  pd.Series({\'coordZ\': approx_mean[0], \'coordY\': approx_mean[1],\n                       \'coordX\': approx_mean[2], \'NoduleConfidence\': confidence_array.max(),\n                       \'seriesuid\': nodules.seriesuid.iloc[0],\n                       \'diameter_mm\': get_diameter_by_sigma(approx_sigma, proba=proba)[0]})\n\n\ndef get_nodules_groups(nodules, proba=0.8):\n    """""" Unite overlapping nodules in groups and compute equivalent diameter and locations of groups.\n\n    Parameters\n    ----------\n    nodules : pandas DataFrame\n        dataframe with information about nodules.\n    proba : float\n        float from [0, 1] interval. Probability of diameter coverage area of\n        equivalent normal distribution.\n\n    Returns\n    -------\n    pandas DataFrame\n        dataframe with information about overlapping nodules groups centers\n        locations and diameters.\n    """"""\n    new_nodules = (\n        nodules\n        .set_index([\'seriesuid\', \'NoduleID\'])\n        .groupby(level=0)\n        .apply(assign_nodules_group_index)\n        .reset_index()\n        .groupby(\'GroupNoduleID\')\n        .apply(compute_group_coords_and_diameter, proba=proba)\n        .reset_index()\n    )\n    return new_nodules\n'"
radio/annotation/parser.py,0,"b'"""""" Contains functions that can be helpful for initial CT-dataset manipulations. """"""\n\nimport os\nfrom collections import OrderedDict\nfrom binascii import hexlify\nimport glob\nimport pickle\nfrom multiprocessing.dummy import Pool as ThreadPool\nimport numpy as np\nimport pandas as pd\nimport tqdm\ntry:\n    import pydicom as dicom # pydicom library was renamed in v1.0\nexcept ImportError:\n    import dicom\n\ndef generate_index(size=20):\n    """""" Generate random string index of given size.\n\n    Parameters\n    ----------\n    size : int\n        length of index string.\n\n    Returns\n    -------\n    str\n        string index of given size.\n    """"""\n    return hexlify(np.random.rand(100))[:size].decode()\n\n\ndef normalize_nodule_type(nodules):\n    """""" Normalize info contained in \'NoduleType\' column of dataframe with nodule info.\n\n    Parameters\n    ----------\n    nodules : pandas DataFrame\n        dataframe with info about nodules\' locations.\n\n    Returns\n    -------\n    pandas DataFrame\n        copy of input dataframe with normalized \'NoduleType\' column.\n    """"""\n    nodule_type = nodules.loc[:, \'NoduleType\']\n    nodule_type = nodule_type.str.strip()\n    nodule_type = nodule_type.str.lower()\n\n    nodule_type = nodule_type.str.replace(r\'\xd0\xba\xd0\xb0\xd0\xb2\xd0\xb5\xd1\x80\xd0\xbd\xd0\xb0\', \'c\')\n    nodule_type = nodule_type.str.replace(r\'nan\', \'c\')\n\n    nodule_type = nodule_type.str.replace(r\'g|\xd1\x87|x\', \'\xd0\xbf\')\n    nodule_type = nodule_type.str.replace(r\'\xd0\xb0|a|k|\xd0\xba|\xe2\x80\x98\', \'\xd1\x81\')\n    nodule_type = nodule_type.str.replace(r\'v\', \'\xd0\xbc\')\n    nodule_type = nodule_type.str.replace(r\'^$\', \'c\')\n\n    nodule_type = nodule_type.str.replace(r\'(?:n|\xd0\xbf)(?:c|\xd1\x81)?\', \'semi_solid\')\n    nodule_type = nodule_type.str.replace(r\'\xd0\xbc\', \'ground_glass\')\n    nodule_type = nodule_type.str.replace(r\'(?:c|\xd1\x81)(\\d|\\s.+)?\', \'solid\')\n\n    return nodules.assign(NoduleType=nodule_type)\n\ndef get_dicom_origin(path):\n    """""" Get origin for dicom from path """"""\n    def _read_dicom(x):\n        return dicom.read_file(os.path.join(path, x))\n    pool = ThreadPool()\n    results = pool.map(_read_dicom, os.listdir(path))\n    pool.close()\n    pool.join()\n    list_of_dicoms = list(results)\n\n    list_of_dicoms.sort(key=lambda x: int(x.ImagePositionPatient[2]), reverse=True)\n\n    dicom_slice = list_of_dicoms[0]\n    origin = np.asarray([float(dicom_slice.ImagePositionPatient[2]),\n                         float(dicom_slice.ImagePositionPatient[0]),\n                         float(dicom_slice.ImagePositionPatient[1])], dtype=np.float)\n    return origin\n\n\ndef get_dicom_info(paths, index_col=None, progress=False, load_origin=True):\n    """""" Accumulates scans meta information from dicom dataset in pandas DataFrame.\n\n    Parameters\n    ----------\n    paths : list, tuple or ndarray of strings\n        paths to directories with dicom files.\n    index_col : str or None\n        name of column that will be used as index of output DataFrame.\n    progress : bool\n        show progress bar or not\n    load_origin : bool\n        if False, zero origin will be setted\n\n    Returns\n    -------\n    pandas.DataFrame\n        pandas DataFrame with scans\' meta information.\n    """"""\n    meta_info = []\n    progress = tqdm.tqdm if progress else lambda x: x\n    for path in progress(paths):\n        first_slice = dicom.read_file(os.path.join(path, os.listdir(path)[0]))\n        if load_origin:\n            origins = get_dicom_origin(path)\n        else:\n            origins = np.zeros(3)\n        info_dict = {\n            \'SpacingZ\': float(first_slice.SliceThickness),\n            \'SpacingY\': float(first_slice.PixelSpacing[0]),\n            \'SpacingX\': float(first_slice.PixelSpacing[1]),\n            \'StudyID\': str(first_slice.StudyID),\n            \'seriesuid\': str(first_slice.AccessionNumber),\n            \'PatientID\': str(first_slice.PatientID),\n            \'Rows\': int(first_slice.Rows),\n            \'Columns\': int(first_slice.Columns),\n            \'NumSlices\': len(os.listdir(path)),\n            \'ScanID\': os.path.basename(path),\n            \'Index\': str(first_slice.AccessionNumber) + \'_\' + os.path.basename(path),\n            \'ScanPath\': path,\n            \'OriginZ\': origins[0],\n            \'OriginY\': origins[1],\n            \'OriginX\': origins[2]\n        }\n        meta_info.append(info_dict)\n    return pd.DataFrame(meta_info) if index_col is None else pd.DataFrame(meta_info).set_index(index_col)\n\ndef get_blosc_info(paths, index_col=None, progress=False, load_origin=True):\n    """""" Accumulates scans meta information from dicom dataset in pandas DataFrame.\n\n    Parameters\n    ----------\n    paths : list, tuple or ndarray of strings\n        paths to directories with dicom files.\n    index_col : str or None\n        name of column that will be used as index of output DataFrame.\n    progress : bool\n        show progress bar or not\n    load_origin : bool\n        if False, zero origin will be setted\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with scans\' meta information.\n    """"""\n    meta_info = []\n    progress = tqdm.tqdm if progress else lambda x: x\n    for path in progress(paths):\n        results = []\n        for component in [\'spacing\', \'origin\']:\n            with open(os.path.join(path, component, \'data.pkl\'), \'rb\') as f:\n                results.append(pickle.load(f))\n        spacing, origin = results #pylint:disable=unbalanced-tuple-unpacking\n\n        spacing_transform = (lambda x: x) if load_origin else (lambda x: 0)\n\n        info_dict = {\n            \'SpacingZ\': spacing[0][0],\n            \'SpacingY\': spacing[0][1],\n            \'SpacingX\': spacing[0][2],\n            \'OriginZ\': spacing_transform(origin[0][0]),\n            \'OriginY\': spacing_transform(origin[0][1]),\n            \'OriginX\': spacing_transform(origin[0][2]),\n            \'seriesuid\': path.split(\'/\')[-1],\n            \'ScanPath\': path,\n            \'ScanID\': os.path.basename(path)\n        }\n        meta_info.append(info_dict)\n    return pd.DataFrame(meta_info) if index_col is None else pd.DataFrame(meta_info).set_index(index_col)\n\n\ndef filter_dicom_info_by_best_spacing(info_df):\n    """""" Filter dataframe created by get_dicom_info function by minimal z-spacing.\n\n    This function groups by items in dataframe created by get_dicom_info function\n    and after that takes only rows corresponding to minimal z-spacing value\n    for given AccessionNumber.\n\n    Parameters\n    ----------\n    info_df : pandas DataFrame\n        descriptive information for dicom dataset. Commonly the output of\n        get_dicom_info function.\n\n    Returns\n    -------\n    pandas.DataFrame\n    """"""\n    output_indices = (\n        info_df\n        .groupby(\'seriesuid\')\n        .agg({\'SpacingZ\': \'idxmin\'})\n    )\n    info_df = info_df.loc[output_indices.loc[:, \'SpacingZ\'], :]\n    return info_df\n\n\ndef parse_annotation(path, max_nodules=40):\n    """""" Parse annotation provided by doctors.\n\n    Parameters\n    ----------\n    path : str\n        path to file with annotation.\n    max_nodules : str\n        maximum number of cancer nodules found in patient.\n\n    Returns\n    -------\n    pandas.DataFrame\n        annotation.\n    """"""\n    base_columns = [\'seriesuid\', \'StudyID\', \'DoctorID\', \'Comment\', \'NumNodules\']\n    location_columns = [\'locX\', \'locY\', \'locZ\', \'diam\', \'type\']\n\n    nodules_list = []\n\n    with open(path, encoding=\'utf-16\') as file:\n        data = (\n            file\n            .read()\n            .replace(\'\xd0\x9e\xd1\x86\xd0\xb5\xd0\xbd\xd0\xba\xd0\xb8 \xd1\x8d\xd0\xba\xd1\x81\xd0\xbf\xd0\xb5\xd1\x80\xd1\x82\xd0\xb0\', \'\')\n            .split(\'\\n\\n\\n\')[1:]\n        )\n        for part in data:\n            for estimate in part.split(\'\\n\'):\n                estimate_dict = OrderedDict()\n                values = estimate.split(\'\\t\')\n                for i in range((max_nodules + 1) * 5):\n                    value = values[i] if i < len(values) else \'NaN\'\n                    if i <= 4:\n                        estimate_dict[base_columns[i]] = value\n                    else:\n                        preffix = location_columns[(i - 4) % 5 - 1]\n                        suffix = str((i - 5) // 5)\n                        estimate_dict[preffix + \'_\' + suffix] = \'NaN\' if value == \'-\' else value\n                nodules_list.append(estimate_dict)\n\n    return pd.DataFrame(nodules_list)\n\n\ndef annotation_to_nodules(annotation_df):\n    """""" Transform dataframe with annotation to dataframe with information about nodules.\n\n    Each row in the output dataframe corresponds to separate nodule.\n\n    Parameters\n    ----------\n    annotation_df : pandas DataFrame\n        pandas dataframe with annotation, usually output of \'parse_annotation\'\n        function.\n\n    Returns\n    -------\n    pandas.DataFrame\n    """"""\n    data_list = []\n    for group in annotation_df.groupby([\'seriesuid\', \'DoctorID\']):\n        accession_number = group[0][0]\n        doctor_id = group[0][1]\n\n        nodules = group[1].iloc[:, 5:].values.reshape(-1, 5)\n        for i in range(nodules.shape[0]):\n            nodule_id = generate_index()\n            nodule_dict = {\n                \'seriesuid\': accession_number,\n                \'DoctorID\': doctor_id,\n                \'NoduleID\': nodule_id,\n                \'NoduleType\': nodules[i, 4],\n                \'coordX\': nodules[i, 0] if nodules[i, 0] != \'\' else \'NaN\',\n                \'coordY\': nodules[i, 1] if nodules[i, 1] != \'\' else \'NaN\',\n                \'coordZ\': nodules[i, 2] if nodules[i, 2] != \'\' else \'NaN\',\n                \'diameter_mm\': nodules[i, 3] if nodules[i, 3] != \'\' else \'NaN\',\n            }\n            data_list.append(nodule_dict)\n    result_df = pd.DataFrame(data_list)\n    result_df.coordX = result_df.coordX.astype(np.float)\n    result_df.coordY = result_df.coordY.astype(np.float)\n    result_df.coordZ = result_df.coordZ.astype(np.float)\n    result_df.diameter_mm = result_df.diameter_mm.astype(np.float)\n    result_df = result_df.dropna()\n    result_df = result_df.assign(DoctorID=lambda df: df.loc[:, \'DoctorID\'].str.replace(""\'"", """"))\n    return normalize_nodule_type(result_df)\n\ndef read_annotators_info(path, annotator_prefix=None):\n    """""" Read information about annotators from annotation.\n    This method reads information about annotators and scans into pandas DataFrame\n    that contains accession numbers as indices and columns names\n    corresponding to ids of annotators with prefix added (if provided). Each cell\n    of the output table is filled with \'1\' if corresponding annotator\n    was annotating scan with given accession number and \'0\' otherwise.\n    Parameters\n    ----------\n    path : str\n\n    annotator_prefix : str or None\n        prefix of annotators indices in the output DataFrame.\n\n    Returns\n    -------\n    pandas.DataFrame\n        table with of shape (num_scans, num_annotators) filled with \'1\'\n        if annotator annotated given scan or \'0\' otherwise.\n    """"""\n    annotators_info = (\n        parse_annotation(path)\n        .assign(DoctorID=lambda df: df.DoctorID.str.replace(""\'"", """"))\n        .query(""seriesuid != \'\'"")\n        .drop_duplicates()\n        .pivot(\'seriesuid\', \'DoctorID\', \'DoctorID\')\n        .notna()\n        .astype(\'int\')\n    )\n    if annotator_prefix:\n        annotators_indices_mapping = {index: (annotator_prefix + index)\n                                      for index in annotators_info.columns}\n\n        annotators_info = annotators_info.pipe(lambda df: df.rename(columns=annotators_indices_mapping))\n    return annotators_info\n\n\n\ndef read_nodules(path, include_annotators=False):\n    """""" Read annotation from file and transform it to DataFrame with nodules.\n\n    Output DataFrame contains following columns:\n    \'NoduleID\' unique id of nodule.\n    \'seriesuid\' - accession number of CT scan that corresponding to nodule.\n    \'DoctorID\' - id of annotator.\n    \'coordZ\', \'coordY\', \'coordX\' - coordinates of nodule\'s center.\n    \'diameter_mm\' - diameter of nodule.\n    \'NoduleType\' - type of nodule. Can be one of [\'solid\', \'semi_solid\', \'ground_glass\'].\n\n    Unique id of nodule generated each time function called and is used as index\n    of the output DataFrame.\n\n    Parameters\n    ----------\n    path : str\n        path to file with annotation\n    include_annotators : bool\n        include or not rows with nan for doctors who annotated image but didn\'t find\n        nodules\n\n    Returns\n    -------\n    pandas.DataFrame\n        dataframe that contains information about nodules location, type and etc.\n    """"""\n    annotation = parse_annotation(path)\n    nodules = annotation_to_nodules(annotation)\n    if include_annotators:\n        annotators_info = (annotation\n                           .assign(DoctorID=lambda df: df.DoctorID.str.replace(""\'"", """"))\n                           .query(""seriesuid != \'\'""))[[\'seriesuid\', \'DoctorID\']]\n        nodules = nodules.merge(annotators_info, left_on=[\'seriesuid\', \'DoctorID\'],\n                                right_on=[\'seriesuid\', \'DoctorID\'], how=\'outer\')\n    return nodules\n\ndef read_dataset_info(path=None, paths=None, index_col=None, filter_by_min_spacing=False, fmt=\'dicom\',\n                      load_origin=True):\n    """""" Build index and mapping to paths for given dicom dataset.\n\n    Parameters\n    ----------\n    path : str\n        dataset scans path mask that will be used as glob.glob argument.\n        Default is None. Only one of \'path\' and \'paths\' arguments must be not None.\n    paths : list\n        list of scans paths. Default is None. Only one of \'path\' and \'paths\'\n        arguments must be not None.\n    index_col : str or None.\n        name of column in the output dataframe that will be used as index.\n        Default is None.\n    filter_by_min_spacing : bool\n        for each accession number choose study with minimal spacing\n    fmt : str\n        \'dicom\' or \'blosc\'\n    load_origin : bool\n        if False, zero origin will be setted\n\n    Returns\n    -------\n    pandas.DataFrame\n        dataframe containing info about dicom dataset.\n    """"""\n    if (path is None and paths is None) or (path is not None and paths is not None):\n        raise ValueError(""Only one of \'path\' or \'paths\' arguments must be provided"")\n\n    if fmt == \'dicom\':\n        dataset_info = get_dicom_info(glob.glob(path) if path is not None else paths, load_origin=load_origin)\n        if filter_by_min_spacing:\n            output_indices = (\n                dataset_info\n                .groupby(\'seriesuid\')\n                .agg({\'SpacingZ\': \'idxmin\'})\n            )\n            index_df = dataset_info.loc[output_indices.loc[:, \'SpacingZ\'], :]\n        else:\n            index_df = dataset_info\n    elif fmt == \'blosc\':\n        index_df = get_blosc_info(glob.glob(path) if path is not None else paths, load_origin=load_origin)\n    else:\n        raise ValueError(\'fmt must be dicom or blosc but {} were given\'.format(fmt))\n    return index_df if index_col is None else index_df.set_index(index_col)\n\ndef transform_annotation(annotation_path, images_path, fmt=\'dicom\', include_annotators=True, drop=True,\n                         load_origin=True):\n    """""" Transform annotation file to LUNA format with coordinates and diamters in mm.\n\n    Parameters\n    ----------\n    annotation_path : str\n        mask for txt files with annotation\n    images_path : str\n        mask for folders with dicom files\n    fmt : str\n        \'dicom\' or \'blosc\'\n    include_annotators : bool\n        if doctor annotates image but don\'t find nodules, row with his ID, seriesuid\n        (seriesuid) and other nans will be added\n    drop : bool\n        if True and file `annotation_path` has annotation for images which don\'t contain\n        in folder `images_path`, it will be dropped\n    load_origin : bool\n        if False, zero origin will be setted\n\n    Returns\n    -------\n    pandas.DataFrame\n        dataframe with annotation with columns\n        `[\'seriesuid\', \'DoctorID\', \'coordZ\', \'coordY\', \'coordX\', \'diameter_mm\', \'NoduleID\']`.\n        Coordinates and diameter in mm.\n    """"""\n    annotations = glob.glob(annotation_path)\n    _nodules = []\n    for annotation in annotations:\n        _nodules.append(read_nodules(annotation, include_annotators).reset_index(drop=True))\n    nodules = pd.concat(_nodules).reset_index(drop=True)\n\n    dataset_info = read_dataset_info(images_path, filter_by_min_spacing=True, fmt=fmt, load_origin=load_origin)\n    spacing_info = dataset_info[[\'seriesuid\', \'SpacingX\', \'SpacingY\', \'SpacingZ\',\n                                 \'OriginX\', \'OriginY\', \'OriginZ\']].set_index(\'seriesuid\')\n    nodules = nodules.join(spacing_info, on=\'seriesuid\', how=\'inner\')\n\n    for name in [\'X\', \'Y\', \'Z\']:\n        nodules[\'coord\'+name] = nodules[\'coord\'+name] * nodules[\'Spacing\'+name] + nodules[\'Origin\'+name]\n        del nodules[\'Spacing\'+name]\n        del nodules[\'Origin\'+name]\n\n    return nodules.reset_index(drop=True)\n'"
radio/models/__init__.py,0,"b'"""""" Module of nn-models for classification/segmentation of lung-cancer on CT-scans. """"""\nfrom .tf import DenseNoduleNet\nfrom .tf import ResNodule3DNet50\nfrom .tf import DilatedNoduleNet\nfrom .keras import Keras3DUNet\nfrom .keras import KerasResNoduleNet\nfrom .keras import KerasNoduleVGG\n'"
radio/models/utils.py,0,"b'"""""" Different useful functions when working with models and CTImagesMaskedBatch. """"""\n\nimport numpy as np\nfrom numba import njit\n\n\ndef nodules_info_to_rzyx(nodules, scale=True):\n    """""" Transform data contained in nodules_info array to rzyx format. """"""\n    if scale:\n        _centers = (nodules.nodule_center - nodules.origin) / nodules.spacing\n        _rads = (nodules.nodule_size / nodules.spacing)\n    return np.hstack([np.expand_dims(_rads.max(axis=1), axis=1), _centers])\n\n\n@njit(cache=True)\ndef sphere_overlap(nodule_true, nodule_pred):\n    """""" Two nodules overlap volume normalized by total volume of second one.\n\n    Parameters\n    ----------\n    nodule_true : ndarray\n        numpy array with information about true nodule:\n        nodule_true[1:] - [z,y,x] coordinates of true nodule\'s center,\n        nodule_true[0] - diameter of true nodule.\n    nodule_pred : ndarray\n        numpy array with information about predicted nodule:\n        nodule_pred[1:] - [z,y,x] coordinates of predicted nodule\'s center,\n        nodule_pred[0] - diameter of predicted nodule.\n\n    Returns\n    -------\n    float\n        overlap volume divided by sum of input nodules\' volumes.\n    """"""\n    r1, r2 = nodule_true[0] / 2, nodule_pred[0] / 2\n    pos1, pos2 = nodule_true[1:], nodule_pred[1:]\n\n    pos1_area = 4. / 3. * np.pi * r1 ** 3\n    pos2_area = 4. / 3. * np.pi * r2 ** 3\n\n    d = np.sum((pos1 - pos2) ** 2) ** 0.5\n\n    if d >= r1 + r2:\n        return 0\n    elif r1 >= d + r2:\n        if r1 > 5 * r2:\n            return 0\n        else:\n            return 1\n    elif r2 >= d + r1:\n        return 1\n\n    volume = (np.pi * (r1 + r2 - d) ** 2\n              * (d ** 2 + r1 * (2 * d - 3 * r1)\n                 + r2 * (2 * d - 3 * r2)\n                 + 6 * r1 * r2)) / (12 * d + 10e-7)\n    return 2 * volume / (pos2_area + pos1_area + 10e-7)\n\n\n@njit\ndef nodules_sets_overlap_jit(nodules_true, nodules_pred):\n    """""" Compute overlap matrix for two sets of nodules.\n\n    Parameters\n    ----------\n    nodules_true : ndarray(l, 4)\n        numpy array containing info about centers of target nodules and theirs diameters.\n    nodules_pred : ndarray(k, 4)\n        numpy array containing info about centers of predicted nodules and theirs diameters.\n\n    Returns\n    -------\n    ndarray(l, k)\n        overlap matrix for two sets of nodules.\n    """"""\n    num_pred = nodules_pred.shape[0]\n    num_true = nodules_true.shape[0]\n\n    overlap_matrix = np.zeros(shape=(num_true, num_pred))\n    for i in range(num_pred):\n        for j in range(num_true):\n            overlap_volume = sphere_overlap(nodules_true[j, :],\n                                            nodules_pred[i, :])\n            overlap_matrix[j, i] = overlap_volume\n\n    return overlap_matrix\n\n\ndef _create_overlap_index(overlap_matrix):\n    """""" Get indices of nodules that overlaps using overlap_matrix. """"""\n    argmax_ov = overlap_matrix.argmax(axis=1)\n    max_ov = overlap_matrix.max(axis=1).astype(np.bool)\n    return max_ov, argmax_ov\n\n\ndef overlap_nodules(batch, nodules_true, nodules_pred):\n    """""" Get info about overlap between true and predicted nodules.\n\n    Parameters\n    ----------\n    batch : CTImagesMaskedBatch\n        input batch\n    nodules_true : numpy record array\n        numpy record array of type CTImagesMaskedBatch.nodules_dtype\n        with true nodules.\n    nodules_pred : numpy record array\n        numpy record array of type CTImagesMaskedBatch.nodules_dtype\n        with predicted nodules.\n\n    Returns\n    -------\n    dict\n        {\'true_stats\': pd.DataFrame, \'pred_stats\': pd.DataFrame}\n    """"""\n    true_df = (\n        batch\n        .nodules_to_df(nodules_true)\n        .assign(diam=lambda df: np.max(df.iloc[:, [4, 5, 6]], axis=1))\n    )\n\n    pred_df = (\n        batch\n        .nodules_to_df(nodules_pred)\n        .assign(diam=lambda df: np.max(df.iloc[:, [4, 5, 6]], axis=1))\n    )\n\n    true_out, pred_out = [], []\n    true_gr, pred_gr = true_df.groupby(\'source_id\'), pred_df.groupby(\'source_id\')\n    for group_name in {**true_gr.groups, **pred_gr.groups}:\n        try:\n            nods_true = true_gr.get_group(group_name).loc[:, [\'diam\', \'locZ\', \'locY\', \'locX\', \'nodule_id\']]\n        except KeyError:\n            nods_pred = pred_gr.get_group(group_name).loc[:, [\'diam\', \'locZ\', \'locY\', \'locX\', \'nodule_id\']]\n            nods_pred.loc[:, \'overlap_index\'] = np.nan\n            nods_pred.loc[:, \'source_id\'] = group_name\n            nods_pred = nods_pred.set_index(\'nodule_id\')\n            pred_out.append(nods_pred)\n            continue\n        try:\n            nods_pred = pred_gr.get_group(group_name).loc[:, [\'diam\', \'locZ\', \'locY\', \'locX\', \'nodule_id\']]\n        except KeyError:\n            nods_true = true_gr.get_group(group_name).loc[:, [\'diam\', \'locZ\', \'locY\', \'locX\', \'nodule_id\']]\n            nods_true.loc[:, \'overlap_index\'] = np.nan\n            nods_true.loc[:, \'source_id\'] = group_name\n            nods_true = nods_true.set_index(\'nodule_id\')\n            true_out.append(nods_true)\n            continue\n\n        nods_true = nods_true.set_index(\'nodule_id\').loc[:, [\'diam\', \'locZ\', \'locY\', \'locX\']]\n        nods_pred = nods_pred.set_index(\'nodule_id\').loc[:, [\'diam\', \'locZ\', \'locY\', \'locX\']]\n\n        overlap_matrix = nodules_sets_overlap_jit(nods_true.values, nods_pred.values)\n\n        ov_mask_true, ov_ind_true = _create_overlap_index(overlap_matrix)\n        ov_mask_pred, ov_ind_pred = _create_overlap_index(overlap_matrix.T)\n\n        nods_true = nods_true.assign(overlap_index=lambda df: df.index)\n        nods_true.loc[ov_mask_true, \'overlap_index\'] = nods_pred.index[ov_ind_true[ov_mask_true]]\n        nods_true.loc[np.logical_not(ov_mask_true), \'overlap_index\'] = np.nan\n        nods_true.loc[:, \'source_id\'] = group_name\n\n        nods_pred = nods_pred.assign(overlap_index=lambda df: df.index)\n        nods_pred.loc[ov_mask_pred, \'overlap_index\'] = nods_true.index[ov_ind_pred[ov_mask_pred]]\n        nods_pred.loc[np.logical_not(ov_mask_pred), \'overlap_index\'] = np.nan\n        nods_pred.loc[:, \'source_id\'] = group_name\n\n        true_out.append(nods_true)\n        pred_out.append(nods_pred)\n\n    return {\'true_stats\': true_out, \'pred_stats\': pred_out}\n'"
radio/pipelines/__init__.py,0,"b'"""""" Pipelines submodule. """"""\nfrom .pipelines import get_crops, split_dump, update_histo, combine_crops\n'"
radio/pipelines/pipelines.py,0,"b'"""""" Helper functions describing pipelines for creating large samples of nodules """"""\n\nfrom copy import copy\nimport PIL\nfrom ..batchflow import Pipeline  # pylint: disable=no-name-in-module\n\n# global constants defining args of some actions in pipeline\nSPACING = (1.7, 1.0, 1.0)  # spacing of scans after spacing unification\nSHAPE = (400, 512, 512)  # shape of scans after spacing unification\nRESIZE_FILTER = PIL.Image.LANCZOS  # high-quality filter of resize\nPADDING = \'reflect\'  # padding-mode that produces the least amount of artefacts\nMETHOD = \'pil-simd\'  # robust resize-engine\nkwargs_default = dict(shape=SHAPE, spacing=SPACING, resample=RESIZE_FILTER, padding=PADDING, method=METHOD)\n\n# define the number of times each cancerous nodule is dumped.\n# with this number of iterations, the whole luna-dataset will\n# produce approximately 115000 cancerous crops\nN_ITERS = 100  # N_ITERS * (num_luna_nodules=1149) ~ 115000\n\n# these params ensure that the number of non-cancerous crops will also\n# be around 115000 (when run on the whole luna-dataset)\nRUN_BATCH_SIZE = 8\nNON_CANCER_BATCH_SIZE = 1030  # NON_CANCER_BATCH_SIZE * (len_of_lunaset=888) / RUN_BATCH_SIZE ~ 115000\n\ndef set_dataset_mode(dataset=\'luna\'):\n    """""" Set constants for generation of balanced dataset of crops.\n\n    Parameters\n    ----------\n    dataset : str\n        Dataset of scans to be used for crop-generation. Can be \'luna\' or \'npcmr\'.\n    """"""\n    global NON_CANCER_BATCH_SIZE          # pylint: disable=global-statement\n    global N_ITERS                        # pylint: disable=global-statement\n    if dataset == \'npcmr\':\n        # this will give about 300000 of non-cancerous crops\n        NON_CANCER_BATCH_SIZE = 480    # pylint: disable=redefined-outer-name, unused-variable\n        # for generating 300000 of cancerous crops\n        N_ITERS = 15  # pylint: disable=redefined-outer-name, unused-variable\n    else:\n        NON_CANCER_BATCH_SIZE = 1030\n        N_ITERS = 100\n\ndef get_crops(nodules, fmt=\'raw\', nodule_shape=(32, 64, 64), batch_size=20, share=0.5, histo=None,\n              variance=(36, 144, 144), hu_lims=(-1000, 400), **kwargs):\n    """""" Get pipeline that performs preprocessing and crops cancerous/non-cancerous nodules in\n    a chosen proportion.\n\n    Parameters\n    ----------\n    nodules : pd.DataFrame\n        contains:\n         - \'seriesuid\': index of patient or series.\n         - \'z\',\'y\',\'x\': coordinates of nodules center.\n         - \'diameter\': diameter, in mm.\n    fmt : str\n        can be either \'raw\', \'blosc\' or \'dicom\'.\n    nodule_shape : tuple, list or ndarray of int\n        crop shape along (z,y,x).\n    batch_size : int\n        number of nodules in batch generated by pipeline.\n    share : float\n        share of cancer crops in the batch.\n    histo : tuple\n        :func:`numpy.histogramdd` output.\n        Used for sampling non-cancerous crops\n    variance : tuple, list or ndarray of float\n        variances of normally distributed random shifts of\n        nodules\' start positions\n    hu_lims : tuple, list of float\n        seq of len=2, representing limits of hu-trimming in normalize_hu-action.\n    **kwargs\n            spacing : tuple\n                (z,y,x) spacing after resize.\n            shape : tuple\n                (z,y,x) shape after crop/pad.\n            method : str\n                interpolation method (\'pil-simd\' or \'resize\').\n                See :func:`~radio.CTImagesBatch.resize`.\n            order : None or int\n                order of scipy-interpolation (<=5), if used.\n            padding : str\n                mode of padding, any supported by :func:`numpy.pad`.\n\n    Returns\n    -------\n    pipeline\n    """"""\n    # update args of unify spacing\n    args_unify_spacing = copy(kwargs_default)\n    args_unify_spacing.update(kwargs)\n\n    # set up other args-dicts\n    args_sample_nodules = dict(nodule_size=nodule_shape, batch_size=batch_size, share=share,\n                               histo=histo, variance=variance)\n\n    # set up the pipeline\n    pipeline = (Pipeline()\n                .load(fmt=fmt)\n                .fetch_nodules_info(nodules=nodules)\n                .unify_spacing(**args_unify_spacing)\n                .create_mask()\n                .normalize_hu(min_hu=hu_lims[0], max_hu=hu_lims[1])\n                .sample_nodules(**args_sample_nodules)\n                .run(lazy=True, batch_size=RUN_BATCH_SIZE, shuffle=True)\n               )\n\n    return pipeline\n\n\ndef split_dump(cancer_path, non_cancer_path, nodules, histo=None, fmt=\'raw\',\n               nodule_shape=(32, 64, 64), variance=(36, 144, 144), **kwargs):\n    """""" Get pipeline for dumping cancerous crops in one folder and random noncancerous crops in another.\n\n    Parameters\n    ----------\n    cancer_path : str\n        directory to dump cancerous crops in.\n    non_cancer_path : str\n        directory to dump non-cancerous crops in.\n    nodules : pd.DataFrame\n        contains:\n         - \'seriesuid\': index of patient or series.\n         - \'z\',\'y\',\'x\': coordinates of nodules center.\n         - \'diameter\': diameter, in mm.\n    histo : tuple\n        :func:`numpy.histogramdd` output.\n        Used for sampling non-cancerous crops\n    fmt : str\n        can be either \'raw\', \'blosc\' or \'dicom\'.\n    nodule_shape : tuple, list or ndarray of int\n        crop shape along (z,y,x).\n    variance : tuple, list or ndarray of float\n        variances of normally distributed random shifts of\n        nodules\' start positions\n    **kwargs\n            spacing : tuple\n                (z,y,x) spacing after resize.\n            shape : tuple\n                (z,y,x) shape after crop/pad.\n            method : str\n                interpolation method (\'pil-simd\' or \'resize\').\n                See :func:`~radio.CTImagesBatch.resize` for more information.\n            order : None or int\n                order of scipy-interpolation (<=5), if used.\n            padding : str\n                mode of padding, any supported by :func:`numpy.pad`.\n\n    Returns\n    -------\n    pipeline\n    """"""\n    # update args of unify spacing\n    args_unify_spacing = copy(kwargs_default)\n    args_unify_spacing.update(kwargs)\n\n    # set up args-dicts\n    args_dump_cancer = dict(dst=cancer_path, n_iters=N_ITERS, nodule_size=nodule_shape,\n                            variance=variance, share=1.0, batch_size=None)\n    args_sample_ncancer = dict(nodule_size=nodule_shape, histo=histo,\n                               batch_size=NON_CANCER_BATCH_SIZE, share=0.0)\n\n    # define pipeline. Two separate tasks are performed at once, in one run:\n    # 1) sampling and dumping of cancerous crops in wrapper-action sample_dump\n    # 2) sampling and dumping of non-cancerous crops in separate actions\n    pipeline = (Pipeline()\n                .load(fmt=fmt)\n                .fetch_nodules_info(nodules=nodules)\n                .unify_spacing(**args_unify_spacing)\n                .create_mask()\n                .sample_dump(**args_dump_cancer)  # sample and dump cancerous crops\n                .sample_nodules(**args_sample_ncancer)  # sample non-cancerous\n                .dump(dst=non_cancer_path)  # dump non-cancerous\n                .run(lazy=True, batch_size=RUN_BATCH_SIZE, shuffle=False)\n               )\n\n    return pipeline\n\ndef update_histo(nodules, histo, fmt=\'raw\', **kwargs):\n    """""" Pipeline for updating histogram using info in dataset of scans.\n\n    Parameters\n    ----------\n    nodules : pd.DataFrame\n        contains:\n         - \'seriesuid\': index of patient or series.\n         - \'z\',\'y\',\'x\': coordinates of nodules center.\n         - \'diameter\': diameter, in mm.\n    histo : tuple\n        :func:`numpy.histogramdd` output.\n        Used for sampling non-cancerous crops\n        (compare the latter with tuple (bins, edges) returned by :func:`numpy.histogramdd`).\n    fmt : str\n        can be either \'raw\', \'blosc\' or \'dicom\'.\n    **kwargs\n            spacing : tuple\n                (z,y,x) spacing after resize.\n            shape : tuple\n                (z,y,x) shape after crop/pad.\n            method : str\n                interpolation method (\'pil-simd\' or \'resize\').\n                See :func:`~radio.CTImagesBatch.resize` for more information.\n            order : None or int\n                order of scipy-interpolation (<=5), if used.\n            padding : str\n                mode of padding, any supported by :func:`numpy.pad`.\n\n    Returns\n    -------\n    pipeline\n    """"""\n    # update args of unify spacing\n    args_unify_spacing = copy(kwargs_default)\n    args_unify_spacing.update(kwargs)\n\n    # perform unify_spacing and call histo-updating action\n    pipeline = (Pipeline()\n                .load(fmt=fmt)\n                .fetch_nodules_info(nodules=nodules)\n                .unify_spacing(**args_unify_spacing)\n                .create_mask()\n                .update_nodules_histo(histo)\n                .run(lazy=True, batch_size=RUN_BATCH_SIZE, shuffle=False)\n               )\n\n    return pipeline\n\ndef combine_crops(cancer_set, non_cancer_set, batch_sizes=(10, 10), hu_lims=(-1000, 400), shuffle=True):\n    """""" Pipeline for generating batches of cancerous and non-cancerous crops from\n    ct-scans in chosen proportion.\n\n    Parameters\n    ---------\n    cancer_set : dataset\n        dataset of cancerous crops in blosc format.\n    non_cancer_set : dataset\n        dataset of non-cancerous crops in blosc format.\n    batch_sizes : tuple, list of int\n        seq of len=2, (num_cancer_batches, num_noncancer_batches).\n    hu_lims : tuple, list of float\n        seq of len=2, representing limits of hu-trimming in normalize_hu-action.\n\n    Returns\n    -------\n    pipeline\n    """"""\n    # pipeline generating cancerous crops\n    ppl_cancer = (cancer_set.p\n                  .load(fmt=\'blosc\')\n                  .normalize_hu(min_hu=hu_lims[0], max_hu=hu_lims[1])\n                  .run(lazy=True, batch_size=batch_sizes[0], shuffle=shuffle, drop_last=True)\n                 )\n\n    # pipeline generating non-cancerous crops merged with first pipeline\n    pipeline = (non_cancer_set.p\n                .load(fmt=\'blosc\')\n                .normalize_hu(min_hu=hu_lims[0], max_hu=hu_lims[1])\n                .merge(ppl_cancer)\n                .run(lazy=True, batch_size=batch_sizes[1], shuffle=shuffle, drop_last=True)\n               )\n\n    return pipeline\n'"
radio/preprocessing/__init__.py,0,"b'"""""" CT-scans preprocessing module. """"""\n\nfrom .ct_batch import CTImagesBatch\nfrom .ct_masked_batch import CTImagesMaskedBatch\nfrom .augmented_batch import CTImagesAugmentedBatch\nfrom .histo import sample_ellipsoid_region\n'"
radio/preprocessing/augmented_batch.py,0,"b'"""""" Contains CTImagesAugmentedBatch: masked ct-batch with some augmentation actions """"""\n\nimport numpy as np\n\nfrom .ct_masked_batch import CTImagesMaskedBatch\nfrom ..batchflow import action, Sampler  # pylint: disable=no-name-in-module\nfrom .mask import insert_cropped\n\nclass CTImagesAugmentedBatch(CTImagesMaskedBatch):\n    """""" Masked ct-batch with augmenting actions.\n\n    Adds cutout, additive/multiplicative noise - augmentations.\n    """"""\n    @action\n    def init_with_ones(self, shape=(32, 64, 64)):\n        """""" Loader for tests, fills batch with ones.\n        """"""\n        self.images = np.ones(shape=(len(self) * shape[0], *shape[1:]))\n        self._bounds = np.cumsum((0, ) + (shape[0], ) * len(self))\n        return self\n\n    @action\n    def cutout(self, positions, sizes, components=\'images\', fill_with=0):\n        """""" Fill a box from each scan with some density-value.\n\n        Parameters:\n        -----------\n        positions : ndarray\n            array of starting positions of boxes, has shape (len(batch), 3).\n        sizes : ndarray\n            array of box-sizes, has shape (len(batch), 3).\n        components : str or list\n            names of components to apply cutout\n        fill_with : ndarray, float or string\n            value or filling scheme. Value can be float or an array of the shape,\n            that can be broadcasted to box-shape. When string, can be either scan-wise\n            mean (\'mean\') or scan-wise minimum/maximum (\'min\', \'max\').\n        """"""\n        if isinstance(components, str):\n            components = [components]\n        for i in range(len(self)):\n            size, position = sizes[i].astype(np.int64), positions[i].astype(np.int64)\n            for component in components:\n                item = self.get(i, component)\n\n                # parse filling scheme\n                fill_with = getattr(np, fill_with)(item) if isinstance(fill_with, str) else fill_with\n                filled = np.ones(shape=size) * fill_with\n\n                # perform insertion\n                insert_cropped(item, filled, position)\n\n        return self\n\n    @action\n    def apply_noise(self, noise, op=\'+\', component=\'images\'):\n        """""" For each item apply the noise to the item using op.\n\n        Parameters:\n        -----------\n        noise : Sampler/ndarray\n            1d-sampler/ndarray of shape=(len(batch), item.shape).\n        op : str\n            operation to perform on item. Can be either \'+\', \'-\', \'*\'.\n        component : str\n            component to add noise to.\n        """"""\n        # prepare noise-array\n        all_items = getattr(self, component)\n        noise = noise.sample(size=all_items.size).reshape(all_items.shape) if isinstance(noise, Sampler) else noise\n\n        # parse and apply op in-place\n        op_dict = {\'+\': \'__add__\', \'*\': \'__mul__\', \'-\': \'__sub__\'}\n        op = op_dict[op]\n        all_items[:] = getattr(all_items, op)(noise)\n\n        return self\n'"
radio/preprocessing/crop.py,0,"b'"""""" Contains auxiliary functions for calculating crop parameters. """"""\n\nimport numpy as np\n\n\ndef make_central_crop(image, crop_size):\n    """""" Make a crop from center of 3D image of given crop_size.\n\n    Parameters\n    ----------\n    image : ndarray\n        3D image of shape `(dim1, dim2, dim3)`.\n    crop_size : ndarray or tuple\n        Size of crop along three dimensions `(int, int, int)`\n    Returns\n    -------\n    ndarray\n        3D crop from image.\n    """"""\n    crop_size = np.asarray(crop_size)\n    crop_halfsize = np.ceil(crop_size / 2).astype(np.int)\n    halfsize = np.rint(np.asarray(image.shape) / 2).astype(np.int)\n    cropped_img = image[halfsize[0] - crop_halfsize[0]: halfsize[0] + crop_size[0] - crop_halfsize[0],\n                        halfsize[1] - crop_halfsize[1]: halfsize[1] + crop_size[1] - crop_halfsize[1],\n                        halfsize[2] - crop_halfsize[2]: halfsize[2] + crop_size[2] - crop_halfsize[2]]\n    return cropped_img.copy()\n'"
radio/preprocessing/ct_batch.py,0,"b'# pylint: disable=too-many-arguments\n# pylint: disable=undefined-variable\n# pylint: disable=no-member\n# pylint: disable=no-else-return\n\n"""""" Batch class for storing CT-scans. """"""\n\nimport os\nimport logging\nfrom binascii import hexlify\nimport dill as pickle\n\nimport numpy as np\nimport aiofiles\nimport blosc\n\ntry:\n    import pydicom as dicom # pydicom library was renamed in v1.0\nexcept ImportError:\n    import dicom\n\nimport SimpleITK as sitk\nfrom skimage.measure import label, regionprops\ntry:\n    import nibabel as nib\nexcept ImportError:\n    pass\n\nfrom ..batchflow import Batch, action, inbatch_parallel, any_action_failed, DatasetIndex # pylint: disable=no-name-in-module\n\nfrom .resize import resize_scipy, resize_pil\nfrom .segment import calc_lung_mask_numba\nfrom .mip import make_xip_numba, numba_xip, unfold_xip, PROJECTIONS, REVERSE_PROJECTIONS\nfrom .flip import flip_patient_numba\nfrom .crop import make_central_crop\nfrom .patches import get_patches_numba, assemble_patches, calc_padding_size\nfrom .rotate import rotate_3D\nfrom .dump import dump_data\n\n# logger initialization\nlogger = logging.getLogger(__name__) # pylint: disable=invalid-name\n\nAIR_HU = -2000\nDARK_HU = -2000\n\nclass CTImagesBatch(Batch):  # pylint: disable=too-many-public-methods\n    """""" Batch class for storing batch of CT-scans in 3D.\n\n    Contains a component `images` = 3d-array of stacked scans\n    along number_of_slices (z) axis (aka ""skyscraper""), associated information\n    for subsetting individual patient\'s 3D scan (_bounds, origin, spacing) and\n    various methods to preprocess the data.\n\n    Parameters\n    ----------\n    index : batchflow.index\n        ids of scans to be put in a batch\n\n    Attributes\n    ----------\n    components : tuple of strings.\n        List names of data components of a batch, which are `images`,\n        `origin` and `spacing`.\n        NOTE: Implementation of this attribute is required by Base class.\n    index : batchflow.index\n        represents indices of scans from a batch\n    images : ndarray\n        contains ct-scans for all patients in batch.\n    spacing : ndarray of floats\n        represents distances between pixels in world coordinates\n    origin : ndarray of floats\n        contains world coordinates of (0, 0, 0)-pixel of scans\n    """"""\n\n    components = ""images"", ""spacing"", ""origin""\n\n    def __init__(self, index, *args, **kwargs):\n        """""" Execute Batch construction and init of basic attributes\n\n        Parameters\n        ----------\n        index : batchflow.Index class.\n            Required indexing of objects (files).\n        """"""\n\n        super().__init__(index, *args, **kwargs)\n\n        # init basic attrs\n        self.images = None\n        self._bounds = None\n        self.origin = None\n        self.spacing = None\n        self._init_data(spacing=np.ones(shape=(len(self), 3)),\n                        origin=np.zeros(shape=(len(self), 3)),\n                        bounds=np.array([], dtype=\'int\'))\n\n    def _if_component_filled(self, component):\n        """""" Check if component is filled with data.\n\n        Parameters\n        ----------\n        component : str\n            component to be checked\n\n        Returns\n        -------\n        bool\n            True if filled, False if not.\n        """"""\n        return getattr(self, component, None) is not None\n\n    def _init_data(self, bounds=None, **kwargs):\n        """""" Initialize _bounds and components (images, origin, spacing).\n\n        `_init_data` is used as initializer of batch inner structures,\n        called inside __init__ and other methods\n\n        Parameters\n        ----------\n        **kwargs\n            images : ndarray(n_patients * z, y, x) or None\n                data to be put as a component `images` in self.images, where\n                n_patients is total number of patients in array and `z, y, x`\n                is a shape of each patient 3D array.\n                Note, that each patient should have same and constant\n                `y, x` shape.\n            bounds : ndarray(n_patients, dtype=np.int) or None\n                1d-array of bound-floors for each scan 3D array,\n                has length = number of items in batch + 1, to be put in self._bounds.\n            origin : ndarray(n_patients, 3) or None\n                2d-array contains origin coordinates of patients scans\n                in `z,y,x`-format in world coordinates to be put in self.origin.\n            spacing : ndarray(n_patients, 3) or None\n                2d-array [number of items X 3] of spacings between slices\n                along each of `z,y,x` axes for each patient\'s 3D array\n                in world coordinates to be put in self.spacing.\n        """"""\n        self._bounds = bounds if bounds is not None else self._bounds\n        for comp_name, comp_data in kwargs.items():\n            setattr(self, comp_name, comp_data)\n\n    @staticmethod\n    def make_filename():\n        """""" Generate unique filename for the batch """"""\n        random_data = np.random.uniform(0, 1, size=10) * 123456789\n        # probability of collision is around 2e-10.\n        filename = hexlify(random_data.data)[:8]\n        return filename.decode(""utf-8"")\n\n    @classmethod\n    def split(cls, batch, batch_size):\n        """""" Split one batch in two batches.\n\n        The lens of 2 batches would be `batch_size` and `len(batch) - batch_size`\n\n        Parameters\n        ----------\n        batch : Batch class instance\n            batch to be splitted in two\n        batch_size : int\n            length of first returned batch.\n            If batch_size >= len(batch), return None instead of a 2nd batch\n\n        Returns\n        -------\n        tuple of batches\n            (1st_Batch, 2nd_Batch)\n\n\n        Notes\n        -----\n        Method does not change the structure of input Batch.index. Indices of output\n        batches are simply subsets of input Batch.index.\n        """"""\n        if batch_size == 0:\n            return (None, batch)\n\n        if batch_size >= len(batch):\n            return (batch, None)\n\n        # form indices for both batches\n        size_first, _ = batch_size, len(batch) - batch_size\n        ix_first = batch.index.create_subset(batch.indices[:size_first])\n        ix_second = batch.index.create_subset(batch.indices[size_first:])\n\n        # init batches\n        batches = cls(ix_first), cls(ix_second)\n\n        # put non-None components in batch-parts\n        for batch_part in batches:\n            for component in batch.components:\n                if getattr(batch, component) is not None:\n                    comps = []\n                    for ix in batch_part.indices:\n                        # get component for a specific item defined by ix and put into the list\n                        comp_pos = batch.get_pos(None, component, ix)\n                        comp = getattr(batch, component)[comp_pos]\n                        comps.append(comp)\n\n                    # set the component for the whole batch-part\n                    source = np.concatenate(comps)\n                    setattr(batch_part, component, source)\n                else:\n                    setattr(batch_part, component, None)\n\n        # set _bounds attrs if filled in batch\n        if len(batch._bounds) >= 2:  # pylint: disable=protected-access\n            for batch_part in batches:\n                n_slices = []\n                for ix in batch_part.indices:\n                    ix_pos_initial = batch.index.get_pos(ix)\n                    n_slices.append(batch.upper_bounds[ix_pos_initial]\n                                    - batch.lower_bounds[ix_pos_initial])\n\n                # update _bounds in new batches\n                batch_part._bounds = np.cumsum([0] + n_slices, dtype=np.int)  # pylint: disable=protected-access\n\n        return batches\n\n    @classmethod\n    def concat(cls, batches):\n        """""" Concatenate several batches in one large batch.\n\n        Assume that same components are filled in all supplied batches.\n\n        Parameters\n        ----------\n        batches : list or tuple of batches\n            sequence of batches to be concatenated\n\n        Returns\n        -------\n        batch\n            large batch with length = sum of lengths of concated batches\n\n        Notes\n        -----\n        Old batches\' indexes are dropped. New large batch has new\n        np-arange index.\n        if None-entries or batches of len=0 are included in the list of batches,\n        they will be dropped after concat.\n        """"""\n        # leave only non-empty batches\n        batches = [batch for batch in batches if batch is not None]\n        batches = [batch for batch in batches if len(batch) > 0]\n\n        if len(batches) == 0:\n            return None\n\n        # create index for the large batch and init batch\n        ixbatch = DatasetIndex(np.arange(np.sum([len(batch) for batch in batches])))\n        large_batch = cls(ixbatch)\n\n        # set non-none components in the large batch\n        for component in batches[0].components:\n            comps = None\n            if getattr(batches[0], component) is not None:\n                comps = np.concatenate([getattr(batch, component) for batch in batches])\n            setattr(large_batch, component, comps)\n\n        # set _bounds-attr in large batch\n        n_slices = np.zeros(shape=len(large_batch))\n        ctr = 0\n        for batch in batches:\n            n_slices[ctr: ctr + len(batch)] = batch.upper_bounds - batch.lower_bounds\n            ctr += len(batch)\n\n        large_batch._bounds = np.cumsum(np.insert(n_slices, 0, 0), dtype=np.int)  # pylint: disable=protected-access\n        return large_batch\n\n    @classmethod\n    def merge(cls, batches, batch_size=None):\n        """""" Concatenate list of batches and then split the result in two batches of sizes\n        (batch_size, sum(lens of batches) - batch_size)\n\n        Parameters\n        ----------\n        batches : list of batches\n        batch_size : int\n            length of first resulting batch\n\n        Returns\n        -------\n        tuple of batches\n            (new_batch, rest_batch)\n\n        Notes\n        -----\n        Merge performs split (of middle-batch) and then two concats\n        because of speed considerations.\n        """"""\n        batches = [batch for batch in batches if batch is not None]\n        batches = [batch for batch in batches if len(batch) > 0]\n        if batch_size is None:\n            return (cls.concat(batches), None)\n        if np.sum([len(batch) for batch in batches]) <= batch_size:\n            return (cls.concat(batches), None)\n\n        # find a batch that needs to be splitted (middle batch)\n        cum_len = 0\n        middle = None\n        middle_pos = None\n        for pos, batch in enumerate(batches):\n            cum_len += len(batch)\n            if cum_len >= batch_size:\n                middle = batch\n                middle_pos = pos\n                break\n\n        # split middle batch\n        left_middle, right_middle = cls.split(middle, len(middle) - cum_len + batch_size)\n\n        # form merged and rest-batches\n        merged = cls.concat(batches[:middle_pos] + [left_middle])\n        rest = cls.concat([right_middle] + batches[middle_pos + 1:])\n\n        return merged, rest\n\n    @action\n    def load(self, fmt=\'dicom\', components=None, src=None, bounds=None, dst=None, **kwargs):\n        """""" Load 3d scans data in batch.\n\n        Parameters\n        ----------\n        fmt : str\n            type of data. Can be \'dicom\'|\'blosc\'|\'raw\'|\'nii\'|None\n        components : tuple, list, ndarray of strings or str\n            Contains types of batch component(s) that should be loaded, i.e. should be\n            one of `images`, `spacing`, `origin`\n            If None all components, i.e. `images`, `spacing`, `origin` will be loaded.\n        src : str if fmt is not None.\n            if fmt is None src must be ndarray(s) to load components from.\n            Otherwise str should be a filename with extention of a file located\n            in directory indexed in FileIndex (built with dirs=True).\n            In case of FileIndex built for particular files and\n            in case of fmt = \'blosc\' or fmt = \'dicom\' src will not work yet.\n        bounds : ndarray(n_patients + 1, dtype=np.int) or None\n            Needed iff fmt=None. Bound-floors for items from a `skyscraper`\n            (stacked scans).\n        dst : tuple, list, ndarray of strings or str\n            Contains names of batch component(s) where loaded components will be stored.\n            If None it will be the same as components argument, i.e. loaded data\n            will be saved in batch components named `images`, `spacing`, `origin`.\n            Needed if you want e.g. load both images and masks.\n            In that case you can add src=\'mask.ext\' and specify\n            dst = \'mask\'\n\n        Returns\n        -------\n        self\n\n        Examples\n        --------\n        DICOM example\n        initialize batch for storing batch of 3 patients with following IDs:\n\n        >>> index = FilesIndex(path=""/some/path/*.dcm"", no_ext=True)\n        >>> batch = CTImagesBatch(index)\n        >>> batch.load(fmt=\'dicom\')\n\n        Ndarray example\n\n        images_array stores a set of 3d-scans concatted along 0-zxis, ""skyscraper"".\n        Say, it is a ndarray with shape (400, 256, 256)\n\n        bounds stores ndarray of last floors for each scan.\n        say, bounds = np.asarray([0, 100, 400])\n\n        >>> batch.load(fmt=None, components=\'images\', src=images_array, bounds=bounds)\n\n        """"""\n        components = self.components if components is None else components\n        components = np.asarray(components).reshape(-1)\n\n        dst = components if dst is None else dst\n        dst = np.asarray(dst).reshape(-1)\n\n        if len(dst) != len(components):\n            raise ValueError(\'components and dst must be of the same length\')\n\n        if fmt is None:\n            if src is None:\n                raise ValueError(\'If fmt is None src must be provided\')\n            src = [src] if len(components) == 1 else list(src)\n            params = {}\n            for comp_dst, comp_data in zip(dst, src):\n                params[comp_dst] = comp_data\n            self._init_data(bounds=bounds, **params)\n        elif fmt == \'dicom\':\n            self._load_dicom(dst=dst, components=components, src=src, **kwargs)\n        elif fmt == \'blosc\':\n            self._load_blosc(dst=dst, components=components, src=src, **kwargs)\n        elif fmt == \'raw\':\n            self._load_raw(dst=dst, components=components, src=src, **kwargs)\n        elif fmt == \'nii\':\n            self._load_nii(dst=dst, components=components, src=src, **kwargs)\n        else:\n            raise TypeError(""Incorrect type of batch source"")\n        return self\n\n    @inbatch_parallel(init=\'indices\', post=\'_post_custom_components\', target=\'threads\')\n    def _load_nii(self, patient_id, **kwargs):\n        """""" Read .nii file and load image data array into batch component.\n\n        Parameters\n        ----------\n        """"""\n        img_nii = nib.load(self._get_file_name(patient_id, kwargs[\'src\']))\n        result = {}\n\n        for i, comp_type in enumerate(kwargs[\'components\']):\n            if comp_type == \'spacing\':\n                comp_data = np.diag(img_nii.affine)[:-1]\n            elif comp_type == \'origin\':\n                comp_data = img_nii.affine[:-1, -1]\n            else:\n                comp_data = img_nii.get_data()\n\n            result[kwargs[\'dst\'][i]] = {\'type\': comp_type, \'data\': comp_data}\n        return result\n\n    @inbatch_parallel(init=\'indices\', post=\'_post_custom_components\', target=\'threads\')\n    def _load_dicom(self, patient_id, **kwargs):\n        """""" Read dicom file, load 3d-array and convert to Hounsfield Units (HU).\n\n        Notes\n        -----\n        Conversion to hounsfield unit scale using meta from dicom-scans is performed.\n        """"""\n        # put 2d-scans for each patient in a list\n        result = {}\n\n        patient_folder = self._get_file_name(patient_id, kwargs[\'src\'])\n        list_of_dicoms = [dicom.read_file(os.path.join(patient_folder, s))\n                          for s in os.listdir(patient_folder)]\n        list_of_dicoms.sort(key=lambda x: int(x.ImagePositionPatient[2]), reverse=True)\n\n        dicom_slice = list_of_dicoms[0]\n        intercept_pat = dicom_slice.RescaleIntercept\n        slope_pat = dicom_slice.RescaleSlope\n\n        patient_data = np.stack([s.pixel_array for s in list_of_dicoms]).astype(np.int16)\n\n        patient_data[patient_data == AIR_HU] = 0\n\n        # perform conversion to HU\n        if slope_pat != 1:\n            patient_data = slope_pat * patient_data.astype(np.float64)\n            patient_data = patient_data.astype(np.int16)\n\n        patient_data += np.int16(intercept_pat)\n\n        for i, comp_type in enumerate(kwargs[\'components\']):\n            if comp_type == \'spacing\':\n                comp_data = np.asarray([float(dicom_slice.SliceThickness),\n                                        float(dicom_slice.PixelSpacing[0]),\n                                        float(dicom_slice.PixelSpacing[1])], dtype=np.float)\n\n            elif comp_type == \'origin\':\n                comp_data = np.asarray([float(dicom_slice.ImagePositionPatient[2]),\n                                        float(dicom_slice.ImagePositionPatient[0]),\n                                        float(dicom_slice.ImagePositionPatient[1])], dtype=np.float)\n            else:\n                comp_data = patient_data\n\n            result[kwargs[\'dst\'][i]] = {\'type\': comp_type, \'data\': comp_data}\n        return result\n\n    def _load_blosc(self, **kwargs):\n        """""" Read scans from blosc and put them into batch components\n\n        Parameters\n        ----------\n        **kwargs\n            components : tuple\n                tuple of strings with names of components of data\n                that should be loaded into self\n\n        Notes\n        -----\n        NO conversion to HU is done for blosc\n        (because usually it\'s done before).\n        """"""\n        byted = self._read_blosc(**kwargs)\n        self._debyte_blosc(byted=byted, **kwargs)\n\n    def _prealloc_skyscraper_components(self, components=None, dst=None, src=None, fmt=\'blosc\'):\n        """""" Read shapes of skyscraper-components dumped with blosc,\n        allocate memory for them, update self._bounds.\n\n        Used for more efficient load in terms of memory.\n\n        Parameters\n        ---------\n        components : str or iterable\n            iterable of components we need to preload.\n        fmt : str\n            format in which components are stored on disk.\n\n        """"""\n        if fmt != \'blosc\':\n            raise NotImplementedError(\'Preload from {} not implemented yet\'.format(fmt))\n\n        # make iterable out of components-arg\n        components = [components] if isinstance(components, str) else list(components)\n        dst = components if dst is None else dst\n        dst = [dst] if isinstance(dst, str) else list(dst)\n\n        # load shapes, perform memory allocation\n        for comp_name in dst:\n            shapes = []\n            for ix in self.indices:\n                filename = os.path.join(self._get_file_name(ix, src), comp_name, \'data.shape\')\n\n                # read shape and put it into shapes\n                if not os.path.exists(filename):\n                    raise OSError(""Component {} for item {} cannot be found on disks"".format(comp_name, ix))\n                with open(filename, \'rb\') as file:\n                    shapes.append(pickle.load(file))\n            shapes = np.stack(shapes, axis=0)\n\n            # update bounds of items\n            # TODO: once bounds for other components are added, make sure they are updated here in the right way\n            self._bounds = np.cumsum(np.insert(shapes[:, 0], 0, 0), dtype=np.int)\n\n            # preallocate space in dst\n            skysc_shape = (self._bounds[-1], *shapes[0, 1:])\n            setattr(self, comp_name, np.zeros(skysc_shape))\n\n    def _prealloc_array_components(self, components=None, dst=None):\n        """""" Allocate memory for array components (spacing and origin type) with names in dst.\n        """"""\n        components = [components] if isinstance(components, str) else list(components)\n        dst = [dst] if isinstance(dst, str) else list(dst)\n        for i, comp_type in enumerate(components):\n            if comp_type in [\'spacing\', \'origin\']:\n                setattr(self, dst[i], np.zeros(shape=(len(self), 3)))\n            else:\n                setattr(self, dst[i], np.array([], dtype=\'int\'))\n\n    def _prealloc_components(self, **kwargs):\n        """""" Init-function for load from blosc.\n        Allocate memory for both skyscrapper and array components.\n        """"""\n        # set images-component to 3d-array of zeroes if the component is to be updated\n        for i, comp_type in enumerate(kwargs[\'components\']):\n            dst_component = kwargs[\'dst\'][i]\n            if comp_type in [\'spacing\', \'origin\']:\n                self._prealloc_array_components(components=comp_type, dst=dst_component)\n            else:\n                self._prealloc_skyscraper_components(components=comp_type, dst=dst_component, \\\n                                                     src=kwargs[\'src\'])\n        return self.indices\n\n    @inbatch_parallel(init=\'_prealloc_components\', post=\'_post_read_blosc\', target=\'async\', update=False)\n    async def _read_blosc(self, ix, *args, **kwargs):\n        byted = dict()\n\n        for i, comp_type in enumerate(kwargs[\'components\']):\n            if comp_type in [\'spacing\', \'origin\']:\n                ext = \'pkl\'\n            else:\n                ext = \'blk\'\n            patient_folder = self._get_file_name(ix, kwargs[\'src\']) # pylint: disable=protected-access\n            comp_path = os.path.join(patient_folder, kwargs[\'dst\'][i], \'data\' + \'.\' + ext)\n            if not os.path.exists(comp_path):\n                raise OSError(""File with component {} doesn\'t exist in {}"".format(kwargs[\'dst\'][i], comp_path))\n\n            # read the component\n            async with aiofiles.open(comp_path, mode=\'rb\') as file:\n                byted[comp_type] = await file.read()\n        return byted\n\n    def _post_read_blosc(self, list_of_arrs, **kwargs):\n        self._reraise_worker_exceptions(list_of_arrs)\n        return dict(zip(self.indices, list_of_arrs))\n\n\n    @inbatch_parallel(init=\'indices\', post=\'_post_default\', target=\'threads\', update=False)\n    def _debyte_blosc(self, ix, byted, **kwargs):\n        for i, comp_type in enumerate(kwargs[\'components\']):\n            # set correct extension for each component and choose a tool\n            # for debyting and (possibly) decoding it\n            if comp_type in [\'spacing\', \'origin\']:\n                unpacker = pickle.loads\n            else:\n                def unpacker(byted):\n                    """""" Debyte and decode an ndarray\n                    """"""\n                    debyted = blosc.unpack_array(byted)\n\n                    # read the decoder and apply it\n                    decod_path = os.path.join(self._get_file_name(ix, kwargs[\'src\']), kwargs[\'dst\'][i], \'data.decoder\') # pylint: disable=cell-var-from-loop\n\n                    # if file with decoder not exists, assume that no decoding is needed\n                    if os.path.exists(decod_path):\n                        with open(decod_path, mode=\'rb\') as file:\n                            decoder = pickle.loads(file.read())\n                    else:\n                        decoder = lambda x: x\n\n                    return decoder(debyted)\n            comp_data = unpacker(byted[ix][comp_type])\n            # update needed slice(s) of component\n            comp_dst = kwargs[\'dst\'][i]\n            comp_pos = self.get_pos(None, comp_type, ix, dst=comp_dst)\n            getattr(self, comp_dst)[comp_pos] = comp_data\n\n    @inbatch_parallel(init=\'indices\', post=\'_post_custom_components\', target=\'for\')\n    def _load_raw(self, patient_id, **kwargs):        # pylint: disable=unused-argument\n        """""" Load scans from .raw images (with meta in .mhd)\n\n        Notes\n        -----\n        Method does NO conversion to HU\n        NO multithreading is used, as SimpleITK (sitk) lib crashes\n        in multithreading mode in experiments.\n        """"""\n        result = {}\n\n        raw_data = sitk.ReadImage(self._get_file_name(patient_id, kwargs[\'src\']))\n\n        for i, comp_type in enumerate(kwargs[\'components\']):\n            if comp_type == \'origin\':\n                # *.mhd files contain information about scans\' origin and spacing;\n                # however the order of axes there is inversed:\n                # so, we just need to reverse arrays with spacing and origin.\n                comp_data = np.array(raw_data.GetOrigin())[::-1]\n\n            elif comp_type == \'spacing\':\n                comp_data = np.array(raw_data.GetSpacing())[::-1]\n            else:\n                comp_data = sitk.GetArrayFromImage(raw_data)\n\n            result[kwargs[\'dst\'][i]] = {\'type\': comp_type, \'data\': comp_data}\n        return result\n\n    @action\n    @inbatch_parallel(init=\'_init_dump\', post=\'_post_default\', target=\'async\', update=False)\n    async def dump(self, ix, dst, components=None, fmt=\'blosc\', index_to_name=None, i8_encoding_mode=None):\n        """""" Dump chosen ``components`` of scans\' batcn in folder ``dst`` in specified format.\n\n        When some of the ``components`` are ``None``, a warning is printed and nothing is dumped.\n        By default (``components is None``) ``dump`` attempts to dump all components.\n\n        Parameters\n        ----------\n        dst : str\n            destination-folder where all patients\' data should be put\n        components : tuple, list, ndarray of strings or str\n            component(s) that we need to dump (smth iterable or string). If not\n            supplied, dump all components\n        fmt : \'blosc\'\n            format of dump. Currently only blosc-format is supported;\n            in this case folder for each patient is created. Tree-structure of created\n            files is demonstrated in the example below.\n        index_to_name : callable or None\n            When supplied, should return str;\n            A function that relates each item\'s index to a name of item\'s folder.\n            That is, each item is dumped into os.path.join(dst, index_to_name(items_index)).\n            If None, no transformation is applied and the method attempts to use indices of batch-items\n            as names of items\' folders.\n        i8_encoding_mode : int, str or dict\n            whether (and how) components of skyscraper-type should be cast to int8.\n            If None, no cast is performed. The cast allows to save space on disk and to speed up batch-loading.\n            However, it comes with loss of precision, as originally skyscraper-components are stored\n            in float32-format. Can be int: 0, 1, 2 or str/None: \'linear\', \'quantization\' or None.\n            0 or None disable the cast. 1 stands for \'linear\', 2 - for \'quantization\'.\n            Can also be component-wise dict of modes, e.g.: {\'images\': \'linear\', \'masks\': 0}.\n\n        Examples\n        --------\n        Initialize batch and load data\n\n        >>> ind = [\'1ae34g90\', \'3hf82s76\']\n        >>> batch = CTImagesBatch(ind)\n        >>> batch.load(...)\n        >>> batch.dump(dst=\'./data/blosc_preprocessed\')\n\n        The command above creates following files:\n\n        - ./data/blosc_preprocessed/1ae34g90/images/data.blk\n        - ./data/blosc_preprocessed/1ae34g90/images/data.shape\n        - ./data/blosc_preprocessed/1ae34g90/spacing/data.pkl\n        - ./data/blosc_preprocessed/1ae34g90/origin/data.pkl\n\n        - ./data/blosc_preprocessed/3hf82s76/images/data.blk\n        - ./data/blosc_preprocessed/3hf82s76/images/data.shape\n        - ./data/blosc_preprocessed/3hf82s76/spacing/data.pkl\n        - ./data/blosc_preprocessed/3hf82s76/origin/data.pkl\n        """"""\n        # if components-arg is not supplied, dump all components\n        if components is None:\n            components = self.components\n\n        if fmt != \'blosc\':\n            raise NotImplementedError(\'Dump to {} is not implemented yet\'.format(fmt))\n\n        # make sure that components is iterable\n        components = np.asarray(components).reshape(-1)\n        data_items = dict()\n\n        for component in components:\n            # get correct extension for the component\n            if component in [\'spacing\', \'origin\']:\n                ext = \'pkl\'\n            else:\n                ext = \'blk\'\n\n            # get component belonging to the needed item, add it to items-dict\n            comp_pos = self.get_pos(None, component, ix)\n            data_items.update({component: [getattr(self, component)[comp_pos], ext]})\n\n        # set item-specific folder\n        item_subdir = ix if index_to_name is None else index_to_name(ix)\n        item_dir = os.path.join(dst, item_subdir)\n\n        return await dump_data(data_items, item_dir, i8_encoding_mode)\n\n    def get_pos(self, data, component, index, dst=None):\n        """""" Return a positon of an item for a given index in data\n        or in self.`component`.\n\n        Fetch correct position inside batch for an item, looks for it\n        in `data`, if provided, or in `component` in self.\n\n        Parameters\n        ----------\n        data : None or ndarray\n            data from which subsetting is done.\n            If None, retrieve position from `component` of batch,\n            if ndarray, returns index.\n        component : str\n            name of a component, f.ex. \'images\'.\n            if component provided, data should be None.\n        index : str or int\n            index of an item to be looked for.\n            may be key from dataset (str)\n            or index inside batch (int).\n\n        Returns\n        -------\n        int or slice\n            Position of item\n\n        Notes\n        -----\n        This is an overload of get_pos from base Batch-class,\n        see corresponding docstring for detailed explanation.\n        """"""\n        # ?? it is not really mecessary but nice to have\n        dst = component if dst is None else dst\n        if data is None:\n            ind_pos = self._get_verified_pos(index)\n            if component in [\'spacing\', \'origin\']:\n                return slice(ind_pos, ind_pos + 1)\n            else:\n                return slice(self.lower_bounds[ind_pos], self.upper_bounds[ind_pos])\n        else:\n            return index\n\n    def _get_verified_pos(self, index):\n        """""" Get position of patient in batch.\n\n        Whatever index is passed in this method, it returns\n        corresponding index inside batch.\n\n        Parameters\n        ----------\n        index : str or int\n            Can be either position of patient in self.images\n            or index from self.index. If int, it means that\n            index is already patient\'s position in Batch.\n            If str, it\'s handled as a key, and returns a position in batch.\n            If fetched position is out of bounds then Exception is generated.\n\n        Returns\n        -------\n        int\n            patient\'s position inside batch\n        """"""\n        if isinstance(index, int):\n            if 0 <= index < len(self):\n                pos = index\n            else:\n                raise IndexError(""Index is out of range"")\n        else:\n            pos = self.index.get_pos(index)\n        return pos\n\n    @property\n    def images_shape(self):\n        """""" Get shapes for all 3d scans in CTImagesBatch.\n\n        Returns\n        -------\n        ndarray\n            shapes of data for each patient, ndarray(patient_pos, 3)\n        """"""\n        shapes = np.zeros((len(self), 3), dtype=np.int)\n        shapes[:, 0] = self.upper_bounds - self.lower_bounds\n        shapes[:, 1], shapes[:, 2] = self.slice_shape\n        return shapes\n\n    @property\n    def lower_bounds(self):\n        """""" Get lower bounds of patients data in CTImagesBatch.\n\n        Returns\n        -------\n        ndarray\n            ndarray(n_patients,) containing\n            lower bounds of patients data along z-axis.\n        """"""\n        return self._bounds[:-1]\n\n    @property\n    def upper_bounds(self):\n        """""" Get upper bounds of patients data in CTImagesBatch.\n\n        Returns\n        -------\n        ndarray\n            ndarray(n_patients,) containing\n            upper bounds of patients data along z-axis.\n        """"""\n        return self._bounds[1:]\n\n    @property\n    def slice_shape(self):\n        """""" Get shape of slice in yx-plane.\n\n        Returns\n        -------\n        ndarray\n            ndarray([y_dim, x_dim],dtype=np.int) with shape of scan slice.\n        """"""\n        return np.asarray(self.images.shape[1:])\n\n    def rescale(self, new_shape):\n        """""" Recomputes spacing values for patients\' data after resize.\n\n        Parameters\n        ----------\n        new_shape : ndarray(dtype=np.int)\n            shape of patient 3d array after resize,\n            in format np.array([z_dim, y_dim, x_dim], dtype=np.int).\n\n        Returns\n        -------\n        ndarray\n            ndarray(n_patients, 3) with spacing values for each\n            patient along z, y, x axes.\n        """"""\n        return (self.spacing * self.images_shape) / new_shape\n\n    def _reraise_worker_exceptions(self, worker_outputs):\n        """""" Reraise exceptions coming from worker-functions, if there are any.\n\n        Parameters\n        ----------\n        worker_outputs : list\n            list of workers\' results\n        """"""\n        if any_action_failed(worker_outputs):\n            all_errors = self.get_errors(worker_outputs)\n            raise RuntimeError(""Failed parallelizing. Some of the workers failed with following errors: "", all_errors)\n\n    def _post_custom_components(self, list_of_dicts, **kwargs):\n        """""" Gather outputs of different workers, update many components.\n\n        Parameters\n        ----------\n        list_of_dicts : list\n            list of dicts {`name of destination component`: {\'type\': original component_name,\n                                                             \'data\': what_to_place_in_component}}\n        where original component_name is one of \'images\', \'spacing\', \'origin\'\n        Returns\n        -------\n        self\n            changes self\'s components\n        """"""\n        self._reraise_worker_exceptions(list_of_dicts)\n        params = {}\n        for comp_dst, comp_data in list_of_dicts[0].items():\n            list_of_arrs = [worker_res[comp_dst][\'data\'] for worker_res in list_of_dicts]\n            if comp_data[\'type\'] not in [\'spacing\', \'origin\']:\n                new_bounds = np.cumsum(np.array([len(a) for a in [[]] + list_of_arrs]))\n                params[\'bounds\'] = new_bounds\n                new_data = np.concatenate(list_of_arrs, axis=0)\n            else:\n                new_data = np.stack(list_of_arrs, axis=0)\n            params[comp_dst] = new_data\n\n        self._init_data(**params)\n        return self\n\n    def _post_default(self, list_of_arrs, update=True, new_batch=False, **kwargs):\n        """""" Gatherer outputs of different workers, update `images` component\n\n        Parameters\n        ----------\n        list_of_arrs : list\n            list of ndarrays to be concated and put in a batch.images.\n        update : bool\n            if False, nothing is performed.\n        new_batch : bool\n            if False, empty batch is created,\n            if True, data is gathered, loaded and put into batch.images.\n\n        Returns\n        -------\n        batch\n            new batch, empty batch or self-batch.\n\n        Notes\n        -----\n        Output of each worker should correspond to individual patient.\n        """"""\n        self._reraise_worker_exceptions(list_of_arrs)\n        res = self\n        if update:\n            new_data = np.concatenate(list_of_arrs, axis=0)\n            new_bounds = np.cumsum(np.array([len(a) for a in [[]] + list_of_arrs]))\n            params = dict(images=new_data, bounds=new_bounds,\n                          origin=self.origin, spacing=self.spacing)\n            if new_batch:\n                batch = type(self)(self.index)\n                batch._init_data(**params) # pylint: disable=protected-access\n                res = batch\n            else:\n                self._init_data(**params)\n        return res\n\n    def _post_components(self, list_of_dicts, **kwargs):\n        """""" Gather outputs of different workers, update many components.\n\n        Parameters\n        ----------\n        list_of_dicts : list\n            list of dicts {`component_name`: what_to_place_in_component}\n\n        Returns\n        -------\n        self\n            changes self\'s components\n        """"""\n        self._reraise_worker_exceptions(list_of_dicts)\n\n        # if images is in dict, update bounds\n        if \'images\' in list_of_dicts[0]:\n            list_of_images = [worker_res[\'images\'] for worker_res in list_of_dicts]\n            new_bounds = np.cumsum(np.array([len(a) for a in [[]] + list_of_images]))\n            new_data = np.concatenate(list_of_images, axis=0)\n            params = dict(images=new_data, bounds=new_bounds,\n                          origin=self.origin, spacing=self.spacing)\n            self._init_data(**params)\n\n        # loop over other components that we need to update\n        for component in list_of_dicts[0]:\n            if component == \'images\':\n                pass\n            else:\n                # concatenate comps-outputs for different scans and update self\n                list_of_component = [worker_res[component] for worker_res in list_of_dicts]\n                new_comp = np.concatenate(list_of_component, axis=0)\n                setattr(self, component, new_comp)\n\n        return self\n\n    def _init_images(self, **kwargs):\n        """""" Fetch args for loading `images` using inbatch_parallel.\n\n        Args-fetcher for parallelization using inbatch_parallel.\n\n        Returns\n        -------\n        list\n            list of patient\'s 3d arrays.\n        """"""\n        return [self.get(patient_id, \'images\') for patient_id in self.indices]\n\n    def _init_rebuild(self, **kwargs):\n        """""" Fetch args for `images` rebuilding using inbatch_parallel.\n\n\n        Args-fetcher for parallelization using inbatch_parallel\n\n        Parameters\n        ----------\n        **kwargs\n                shape : tuple, list or ndarray of int\n                    (z,y,x)-shape of every image in image component after action is performed.\n                spacing : tuple, list or ndarray of float\n                    (z,y,x)-spacing for each image. If supplied, assume that\n                    unify_spacing is performed.\n\n        Returns\n        -------\n        list\n            list of arg-dicts for different workers\n        """"""\n        if \'shape\' in kwargs:\n            num_slices, y, x = kwargs[\'shape\']\n            new_bounds = num_slices * np.arange(len(self) + 1)\n            new_data = np.zeros((num_slices * len(self), y, x))\n        else:\n            new_bounds = self._bounds\n            new_data = np.zeros_like(self.images)\n\n        all_args = []\n        for i in range(len(self)):\n            out_patient = new_data[new_bounds[i]: new_bounds[i + 1], :, :]\n            item_args = {\'patient\': self.get(i, \'images\'),\n                         \'out_patient\': out_patient,\n                         \'res\': new_data}\n\n            # for unify_spacing\n            if \'spacing\' in kwargs:\n                shape_after_resize = (self.images_shape * self.spacing\n                                      / np.asarray(kwargs[\'spacing\']))\n                shape_after_resize = np.rint(shape_after_resize).astype(np.int)\n                item_args[\'factor\'] = self.spacing[i, :] / np.array(kwargs[\'spacing\'])\n                item_args[\'shape_resize\'] = shape_after_resize[i, :]\n\n            all_args += [item_args]\n\n        return all_args\n\n    def _init_dump(self, **kwargs):\n        """""" Init function for dump.\n\n        Checks if all components that should be dumped are non-None. If some are None,\n        prints warning and makes sure that nothing is dumped.\n\n        Parameters\n        ----------\n        **kwargs:\n            components : tuple, list, ndarray of strings or str\n                components that we need to dump\n        """"""\n        components = kwargs.get(\'components\', self.components)\n\n        # make sure that components is iterable\n        components = np.asarray(components).reshape(-1)\n\n        _empty = [component for component in components if not self._if_component_filled(component)]\n\n        # if some of the components for dump are empty, print warning and do not dump anything\n        if len(_empty) > 0:\n            logger.warning(\'Components %r are empty. Nothing is dumped!\', _empty)\n            return []\n        else:\n            return self.indices\n\n    def _post_rebuild(self, all_outputs, new_batch=False, **kwargs):\n        """""" Gather outputs of different workers for actions, rebuild `images` component.\n\n        Parameters\n        ----------\n        all_outputs : list\n            list of outputs. Each item is given by tuple\n        new_batch : bool\n            if True, returns new batch with data agregated\n            from all_ouputs. if False, changes self.\n        **kwargs\n                shape : list, tuple or ndarray of int\n                    (z,y,x)-shape of every image in image component after action is performed.\n                spacing : tuple, list or ndarray of float\n                    (z,y,x)-spacing for each image. If supplied, assume that\n                    unify_spacing is performed.\n        """"""\n        self._reraise_worker_exceptions(all_outputs)\n\n        new_bounds = np.cumsum([patient_shape[0] for _, patient_shape\n                                in [[0, (0, )]] + all_outputs])\n        # each worker returns the same ref to the whole res array\n        new_data, _ = all_outputs[0]\n\n        # recalculate new_attrs of a batch\n\n        # for resize/unify_spacing: if shape is supplied, assume post\n        # is for resize or unify_spacing\n        if \'shape\' in kwargs:\n            new_spacing = self.rescale(kwargs[\'shape\'])\n        else:\n            new_spacing = self.spacing\n\n        # for unify_spacing: if spacing is supplied, assume post\n        # is for unify_spacing\n        if \'spacing\' in kwargs:\n            # recalculate origin, spacing\n            shape_after_resize = np.rint(self.images_shape * self.spacing\n                                         / np.asarray(kwargs[\'spacing\']))\n            overshoot = shape_after_resize - np.asarray(kwargs[\'shape\'])\n            new_spacing = self.rescale(new_shape=shape_after_resize)\n            new_origin = self.origin + new_spacing * (overshoot // 2)\n        else:\n            new_origin = self.origin\n\n        # build/update batch with new data and attrs\n        params = dict(images=new_data, bounds=new_bounds,\n                      origin=new_origin, spacing=new_spacing)\n        if new_batch:\n            batch_res = type(self)(self.index)\n            batch_res._init_data(**params) # pylint: disable=protected-access\n            return batch_res\n        else:\n            self._init_data(**params)\n            return self\n\n    @action\n    @inbatch_parallel(init=\'_init_rebuild\', post=\'_post_rebuild\', target=\'threads\')\n    def resize(self, patient, out_patient, res, shape=(128, 256, 256), method=\'pil-simd\',\n               axes_pairs=None, resample=None, order=3, *args, **kwargs):\n        """""" Resize (change shape of) each CT-scan in the batch.\n\n        When called from a batch, changes this batch.\n\n        Parameters\n        ----------\n        shape : tuple, list or ndarray of int\n            (z,y,x)-shape that should be AFTER resize.\n            Note, that ct-scan dim_ordering also should be `z,y,x`\n        method : str\n            interpolation package to be used. Either \'pil-simd\' or \'scipy\'.\n            Pil-simd ensures better quality and speed on configurations\n            with average number of cores. On the contrary, scipy is better scaled and\n            can show better performance on systems with large number of cores\n        axes_pairs : None or list/tuple of tuples with pairs\n            pairs of axes that will be used for performing pil-simd resize,\n            as this resize is made in 2d. Min number of pairs to use is 1,\n            at max there can be 6 pairs. If None, set to ((0, 1), (1, 2)).\n            The more pairs one uses, the more precise is the result.\n            (and computation takes more time).\n        resample : filter of pil-simd resize. By default set to bilinear. Can be any of filters\n            supported by PIL.Image.\n        order : the order of scipy-interpolation (<= 5)\n            large value improves precision, but slows down the computaion.\n\n        Examples\n        --------\n        >>> shape = (128, 256, 256)\n        >>> batch = batch.resize(shape=shape, order=2, method=\'scipy\')\n        >>> batch = batch.resize(shape=shape, resample=PIL.Image.BILINEAR)\n        """"""\n        if method == \'scipy\':\n            args_resize = dict(patient=patient, out_patient=out_patient, res=res, order=order)\n            return resize_scipy(**args_resize)\n        elif method == \'pil-simd\':\n            args_resize = dict(input_array=patient, output_array=out_patient,\n                               res=res, axes_pairs=axes_pairs, resample=resample)\n            return resize_pil(**args_resize)\n        else:\n            raise ValueError(""Unknown method"", method)\n\n    @action\n    @inbatch_parallel(init=\'_init_rebuild\', post=\'_post_rebuild\', target=\'threads\')\n    def unify_spacing(self, patient, out_patient, res, factor,\n                      shape_resize, spacing=(1, 1, 1), shape=(128, 256, 256),\n                      method=\'pil-simd\', order=3, padding=\'edge\', axes_pairs=None,\n                      resample=None, *args, **kwargs):\n        """""" Unify spacing of all patients.\n\n        Resize all patients to meet `spacing`, then crop/pad resized array to meet `shape`.\n\n        Parameters\n        ----------\n        spacing : tuple, list or ndarray of float\n            (z,y,x)-spacing after resize.\n            Should be passed as key-argument.\n        shape : tuple, list or ndarray of int\n            (z,y,x)-shape after crop/pad.\n            Should be passed as key-argument.\n        method : str\n            interpolation method (\'pil-simd\' or \'resize\').\n            Should be passed as key-argument.\n            See CTImagesBatch.resize for more information.\n        order : None or int\n            order of scipy-interpolation (<=5), if used.\n            Should be passed as key-argument.\n        padding : str\n            mode of padding, any supported by np.pad.\n            Should be passed as key-argument.\n        axes_pairs : tuple, list of tuples with pairs\n            pairs of axes that will be used consequentially\n            for performing pil-simd resize.\n            Should be passed as key-argument.\n        resample : None or str\n            filter of pil-simd resize.\n            Should be passed as key-argument\n        patient : str\n            index of patient, that worker is handling.\n            Note: this argument is passed by inbatch_parallel\n        out_patient : ndarray\n            result of individual worker after action.\n            Note: this argument is passed by inbatch_parallel\n        res : ndarray\n            New `images` to replace data inside `images` component.\n            Note: this argument is passed by inbatch_parallel\n        factor : tuple\n            (float), factor to make resize by.\n            Note: this argument is passed by inbatch_parallel\n        shape_resize : tuple\n            It is possible to provide `shape_resize` argument (shape after resize)\n            instead of spacing. Then array with `shape_resize`\n            will be cropped/padded for shape to = `shape` arg.\n            Note that this argument is passed by inbatch_parallel\n\n        Notes\n        -----\n        see CTImagesBatch.resize for more info about methods\' params.\n\n        Examples\n        --------\n        >>> shape = (128, 256, 256)\n        >>> batch = batch.unify_spacing(shape=shape, spacing=(1.0, 1.0, 1.0),\n                                        order=2, method=\'scipy\', padding=\'reflect\')\n        >>> batch = batch.unify_spacing(shape=shape, spacing=(1.0, 1.0, 1.0),\n                                        resample=PIL.Image.BILINEAR)\n        """"""\n        if method == \'scipy\':\n            args_resize = dict(patient=patient, out_patient=out_patient,\n                               res=res, order=order, factor=factor, padding=padding)\n            return resize_scipy(**args_resize)\n        elif method == \'pil-simd\':\n            args_resize = dict(input_array=patient, output_array=out_patient,\n                               res=res, axes_pairs=axes_pairs, resample=resample,\n                               shape_resize=shape_resize, padding=padding)\n            return resize_pil(**args_resize)\n        else:\n            raise ValueError(""Unknown method"", method)\n\n    @action\n    @inbatch_parallel(init=\'indices\', post=\'_post_default\', update=False, target=\'threads\')\n    def rotate(self, index, angle, components=\'images\', axes=(1, 2), random=True, **kwargs):\n        """""" Rotate 3D images in batch on specific angle in plane.\n\n        Parameters\n        ----------\n        angle : float\n            degree of rotation.\n        components : tuple, list, ndarray of strings or str\n            name(s) of components to rotate each item in it.\n        axes : tuple, list or ndarray of int\n            (int, int), plane of rotation specified by two axes (zyx-ordering).\n        random : bool\n            if True, then degree specifies maximum angle of rotation.\n\n        Returns\n        -------\n        ndarray\n            ndarray of 3D rotated image.\n\n        Notes\n        -----\n        zero padding automatically added after rotation.\n        Use this action in the end of pipelines for purposes of augmentation.\n        E.g., after :func:`~radio.preprocessing.ct_masked_batch.CTImagesMaskedBatch.sample_nodules`\n\n        Examples\n        --------\n        Rotate images on 90 degrees:\n\n        >>> batch = batch.rotate(angle=90, axes=(1, 2), random=False)\n\n        Random rotation with maximum angle:\n\n        >>> batch = batch.rotate(angle=30, axes=(1, 2))\n\n        """"""\n        _components = np.asarray(components).reshape(-1)\n        _angle = angle * np.random.rand() if random else angle\n        for comp in _components:\n            data = self.get(index, comp)\n            rotate_3D(data, _angle, axes)\n\n    @inbatch_parallel(init=\'_init_images\', post=\'_post_default\', target=\'threads\', new_batch=True)\n    def _make_xip(self, image, depth, stride=2, mode=\'max\',\n                  projection=\'axial\', padding=\'reflect\', *args, **kwargs):\n        """""" Make intensity projection (maximum, minimum, mean or median).\n\n        Notice that axis is chosen according to projection argument.\n\n        Parameters\n        ----------\n        depth : int\n            number of slices over which xip operation is performed.\n        stride : int\n            stride-step along projection dimension.\n        mode : str\n            Possible values are \'max\', \'min\', \'mean\' or \'median\'.\n        projection : str\n            Possible values: \'axial\', \'coronal\', \'sagital\'.\n            In case of \'coronal\' and \'sagital\' projections tensor\n            will be transposed from [z,y,x] to [x,z,y] and [y,z,x].\n        padding : str\n            mode of padding that will be passed in numpy.padding function.\n        """"""\n        return make_xip_numba(image, depth, stride, mode, projection, padding)\n\n    @action\n    def make_xip(self, depth, stride=1, mode=\'max\', projection=\'axial\', padding=\'reflect\', **kwargs):\n        """""" Make intensity projection (maximum, minimum, mean or median).\n\n        Notice that axis is chosen according to projection argument.\n\n        Parameters\n        ----------\n        depth : int\n            number of slices over which xip operation is performed.\n        stride : int\n            stride-step along projection dimension.\n        mode : str\n            Possible values are \'max\', \'min\', \'mean\' or \'median\'.\n        projection : str\n            Possible values: \'axial\', \'coronal\', \'sagital\'.\n            In case of \'coronal\' and \'sagital\' projections tensor\n            will be transposed from [z,y,x] to [x,z,y] and [y,z,x].\n        padding : str\n            mode of padding that will be passed in numpy.padding function.\n        """"""\n        output_batch = self._make_xip(depth=depth, stride=stride, mode=mode,  # pylint: disable=no-value-for-parameter\n                                      projection=projection, padding=padding)\n        output_batch.spacing = self.rescale(output_batch.images_shape)\n        return output_batch\n\n    def xip(self, component, mode, depth, stride, start=0, projection=\'axial\', squeeze=False, channels=None):\n        """""" Make channelled intensity projection (xip) from a component.\n\n        Parameters\n        ----------\n        component : str\n            component to pass through xip-procedure.\n        mode : str\n            mode of intensity projection. Can be either \'max\', \'min\', \'mean\' or \'median\'.\n        depth : int\n            size of xip-window.\n        stride : int\n            stride of xip.\n        start : int\n            the number of starting slice.\n        projection : str\n            can be either \'axial\', \'coronal\' or \'sagital\'.\n        squeeze : bool\n            if True, squeezes channels into one. The parameter is used for convenient\n            preparation of training data.\n        channels : int, None\n            if supplied, makes xip with several channels. The overall number\n            of xip-slices stays the same.\n\n        Returns\n        -------\n        ndarray\n            4d-array of shape (len(self) * n_xips_in_item, slice_shape[0], slice_shape[1], channels)\n            containing intensity projections.\n        """"""\n        # parse arguments\n        _modes = {\'max\': 0, \'min\': 1, \'mean\': 2, \'median\': 3}\n        mode = mode if isinstance(mode, (list, tuple)) else (mode, )\n        mode = [m if isinstance(m, int) else _modes[m] for m in mode]\n        channels = 1 if channels is None else channels\n\n        # set up init, post, worker\n        _init = self.indices\n        _post = lambda outputs, **kwargs: np.concatenate(outputs, axis=0)\n\n        def _worker(self, ix, component, mode, depth, stride, start, channels, squeeze, projection, **kwargs):\n            image = self.get(ix, component)\n            image = np.transpose(image, PROJECTIONS[projection])\n            xips = []\n            for m in mode:\n                xip = numba_xip(image, depth, m, stride, start)\n                if channels == 1:\n                    xip = np.expand_dims(xip, axis=-1)\n                else:\n                    # split xip into channels\n                    rem = len(xip) % channels\n                    if rem > 0:\n                        xip = xip[:-rem]\n\n                    xip = xip.reshape((-1, channels) + xip.shape[1:])\n                    xip = np.transpose(xip, (0, 2, 3, 1))\n                    xip = np.max(xip, axis=-1, keepdims=True) if squeeze else xip\n                xips.append(xip)\n\n            return np.concatenate(xips, axis=-1)\n\n        # decorate the worker and compute the result\n        wrapped = inbatch_parallel(_init, _post, \'t\')(_worker)\n        return wrapped(self, component=component, mode=mode, depth=depth, stride=stride,\n                       start=start, channels=channels, squeeze=squeeze, projection=projection)\n\n    @action\n    def sample_xip(self, depth, stride, mode=\'max\', start=0, squeeze=(False, True), projection=\'axial\', channels=3,             # pylint: disable=too-many-locals\n                   batch_size=20, share=0.5, sampler=None, src=(\'images\', \'masks\'), dst=(\'xip_images\', \'xip_masks\')):\n        """""" Create xips for a pair of components for training neural networks. Put xips them into `dst`-components.\n\n        Parameters\n        ----------\n        depth : int\n            size of xip-window.\n        stride : int\n            stride of xip.\n        mode : str\n            mode of intensity projection. Can be either \'max\', \'min\', \'mean\' or \'median\'.\n        start : int\n            the number of starting slice.\n        squeeze : tuple\n            tuple of bools. If (False, True), the first xip has all three channels, while channels of the\n            second xip are squezeed into one.\n        projection : str\n            plane of intensity projection.\n        channels : int\n            number of channels in xips.\n        batch_size : int or None\n            needed number of generated projections.\n        share : float\n            share of cancerous projections.\n        sampler : Sampler\n            sampler of points from scan box, either 3d or 1d. Used for selecting noncancerous slices.\n        src : tuple\n            pair of components to pass through the xip-procedure.\n        dst : tuple\n            components to put the resulting xips into.\n        """"""\n        # obtain xips\n        xip_args = dict(depth=depth, mode=mode, stride=stride, start=start, projection=projection, channels=channels)\n        xips = []\n        for i in range(2):\n            xip_args.update(component=src[i], squeeze=squeeze[i])\n            xip = self.xip(**xip_args)\n            xips.append(xip)\n\n        # if needed, randomly select cancerous and noncancerous xip-slices\n        if batch_size is not None:\n            cancer_filter = np.greater(np.sum(xips[1], axis=(1, 2, 3)), 0)\n            all_cancer_ixs = np.argwhere(cancer_filter).reshape(-1)\n            max_cancer = len(all_cancer_ixs)\n            num_cancer = min(int(batch_size * share), max_cancer)\n            num_non_cancer = batch_size - num_cancer\n\n            # random selection\n            cancer_ixs = np.random.choice(all_cancer_ixs, size=num_cancer, replace=False)\n\n            # select non-cancerous indices\n            if sampler is None:\n                non_cancer_ixs = np.random.choice(range(len(cancer_filter)), size=num_non_cancer, replace=False)\n            else:\n                # adjust the sampler: the number of xip-slices can differ from the shape of xip-axis\n                xip_axis_len = self.get(0, src[0]).shape[PROJECTIONS[projection][0]]\n                factor = np.ones((1, 3))\n                factor[0, PROJECTIONS[projection][0]] = len(cancer_filter) / (len(self) * xip_axis_len)\n                sampler = sampler * factor\n\n                # sample from all items at once\n                shift = np.zeros((1, 3))\n                shift[0, PROJECTIONS[projection][0]] = len(cancer_filter) / len(self)\n                sampler_all_items = sampler\n                for i in range(1, len(self)):\n                    sampler_all_items = sampler_all_items | (sampler + i * shift)\n                non_cancer_ixs = (sampler\n                                  .sample(size=num_non_cancer)[:, PROJECTIONS[projection][0]]\n                                  .clip(min=0, max=len(cancer_filter) - 1)\n                                  .astype(np.int))\n\n            p = np.random.permutation(batch_size)\n            for i in range(2):\n                xips[i] = np.concatenate((xips[i][cancer_ixs], xips[i][non_cancer_ixs]), axis=0)\n                xips[i] = xips[i][p]\n\n        # put xips into the batch\n        for i in range(2):\n            setattr(self, dst[i], xips[i])\n\n        return self\n\n    def unxip(self, xip, component, depth, stride, start=0, projection=\'axial\', squeeze=True,\n              channels=None, adjust_nodule_size=True, threshold=0.95, **kwargs):\n        """""" Unfold xipped array into a full-sized component.\n\n        Parameters\n        ----------\n        xip : ndarray\n            4d-array containing channelled intensity projection.\n        component : str\n            component into which the unfolded image should be put.\n        depth : int\n            size of xip-window.\n        stride : int\n            stride of xip.\n        start : int\n            the number of starting slice.\n        projection : str\n            can be either \'axial\', \'coronal\' or \'sagital\'.\n        squeeze : bool\n            If True, assumes the channels in xip should be squeezed into one.\n        channels : int, None\n            The number of channels in xip. Needed only if squeeze is True.\n        adjust_nodule_size : bool\n            if the adustment of sizes of detected nodules is needed.\n        threshold : float\n            threshold for binarization of xip. Needed only if adjusting of nodule sizes\n            is performed.\n        """"""\n        channels = 1 if channels is None else channels\n\n        # binarize predictions if needed\n        if threshold is not None and adjust_nodule_size:\n            xip = np.where(xip < threshold, 0, 1)\n\n        new_data = np.zeros_like(getattr(self, \'images\'))\n\n        # unfold xip\n        _init = range(len(self))\n        def _worker(self, ix, xip, new_data, depth, stride, start, squeeze, channels, adjust,               # pylint: disable=too-many-locals\n                    projection, **kwargs):\n            num_item_slices = len(xip) // len(self)\n            shape = np.array(self.get(ix, \'images\').shape)[PROJECTIONS[projection]]\n            slc = self.get_pos(None, \'images\', ix)\n            unfolded = unfold_xip(xip[ix * num_item_slices:(ix + 1) * num_item_slices, ...],\n                                  shape, depth, stride, start, channels, squeeze)\n\n            # perform adjustment of nodule-sizes if needed\n            if adjust:\n                labels, num_nodules = label(np.where(unfolded < 1, 0, 1), return_num=True)\n                props = regionprops(labels)\n                unfolded[:] = 0\n                for i in range(num_nodules):\n                    bbox = np.reshape(props[i].bbox, (2, -1))\n                    size = bbox[1, :] - bbox[0, :]\n\n                    # adjust z-diameter and bounding box of a nodule\n                    size[0] = (size[1] + size[2]) / 2\n                    bbox[:, 0] = int(props[i].centroid[0] - size[0] / 2), int(props[i].centroid[0] + size[0] / 2)\n                    bbox = bbox.astype(np.int)\n\n                    # put adjusted nodule into the component\n                    nodule_slice = [slice(bbox[0, i], bbox[1, i]) for i in range(3)]\n                    unfolded[nodule_slice] = 1\n\n            new_data[slc] = np.transpose(unfolded, REVERSE_PROJECTIONS[projection])\n\n        # execute in parallel\n        wrapped = inbatch_parallel(_init, None, \'t\')(_worker)\n        wrapped(self, xip=xip, new_data=new_data, depth=depth, stride=stride, start=start,\n                squeeze=squeeze, channels=channels, adjust=adjust_nodule_size, projection=projection)\n\n        # set the component\n        setattr(self, component, new_data)\n\n\n    @inbatch_parallel(init=\'_init_rebuild\', post=\'_post_rebuild\', target=\'threads\', new_batch=True)\n    def calc_lung_mask(self, patient, out_patient, res, erosion_radius, **kwargs):     # pylint: disable=unused-argument, no-self-use\n        """""" Return a mask for lungs\n\n        Parameters\n        ----------\n        erosion_radius : int\n            radius of erosion to be performed.\n        """"""\n        return calc_lung_mask_numba(patient, out_patient, res, erosion_radius)\n\n    @action\n    def segment(self, erosion_radius=2, **kwargs):\n        """""" Segment lungs\' content from 3D array.\n\n        Parameters\n        ---------\n        erosion_radius : int\n            radius of erosion to be performed.\n\n        Returns\n        -------\n        batch\n\n        Notes\n        -----\n        Sets HU of every pixel outside lungs to DARK_HU = -2000.\n\n        Examples\n        --------\n\n        >>> batch = batch.segment(erosion_radius=4, num_threads=20)\n        """"""\n        # get mask with specified params, apply it to scans\n        mask_batch = self.calc_lung_mask(erosion_radius=erosion_radius, **kwargs)  # pylint: disable=no-value-for-parameter\n        lungs_mask = mask_batch.images\n        self.images *= lungs_mask\n\n        # reverse the mask and set not-lungs to DARK_HU\n        result_mask = 1 - lungs_mask\n        result_mask *= DARK_HU\n\n        self.images += result_mask\n\n        return self\n\n    @action\n    def central_crop(self, crop_size, **kwargs):\n        """""" Make crop of crop_size from center of images.\n\n        Parameters\n        ----------\n        crop_size : tuple, list or ndarray of int\n            (z,y,x)-shape of crop.\n\n        Returns\n        -------\n        batch\n        """"""\n        crop_size = np.asarray(crop_size).reshape(-1)\n        crop_halfsize = np.rint(crop_size / 2)\n        img_shapes = [np.asarray(self.get(i, \'images\').shape) for i in range(len(self))]\n        if any(np.any(shape < crop_size) for shape in img_shapes):\n            raise ValueError(""Crop size must be smaller than size of inner 3D images"")\n\n        cropped_images = []\n        for i in range(len(self)):\n            image = self.get(i, \'images\')\n            cropped_images.append(make_central_crop(image, crop_size))\n\n        self._bounds = np.cumsum([0] + [crop_size[0]] * len(self))\n        self.images = np.concatenate(cropped_images, axis=0)\n        self.origin = self.origin + self.spacing * crop_halfsize\n        return self\n\n    def get_patches(self, patch_shape, stride, padding=\'edge\', data_attr=\'images\'):\n        """""" Extract patches of patch_shape with specified stride.\n\n        Parameters\n        ----------\n        patch_shape : tuple, list or ndarray of int\n            (z,y,x)-shape of a single patch.\n        stride : tuple, list or ndarray of int\n            (z,y,x)-stride to slide over each patient\'s data.\n        padding : str\n            padding-type (see doc of np.pad for available types).\n        data_attr : str\n            component to get data from.\n\n        Returns\n        -------\n        ndarray\n            4d-ndaray of patches; first dimension enumerates patches\n\n        Notes\n        -----\n        Shape of all patients data is needed to be the same at this step,\n        resize/unify_spacing is required before.\n        """"""\n\n        patch_shape = np.asarray(patch_shape).reshape(-1)\n        stride = np.asarray(stride).reshape(-1)\n\n        img_shape = self.images_shape[0]\n        data_4d = np.reshape(getattr(self, data_attr), (-1, *img_shape))\n\n        # add padding if necessary\n        pad_width = calc_padding_size(img_shape, patch_shape, stride)\n        if pad_width is not None:\n            data_padded = np.pad(data_4d, pad_width, mode=padding)\n        else:\n            data_padded = data_4d\n\n        # init tensor with patches\n        num_sections = (np.asarray(data_padded.shape[1:]) - patch_shape) // stride + 1\n        patches = np.zeros(shape=(len(self), np.prod(num_sections), *patch_shape))\n\n        # put patches into the tensor\n        get_patches_numba(data_padded, patch_shape, stride, patches)\n        patches = np.reshape(patches, (len(self) * np.prod(num_sections), *patch_shape))\n        return patches\n\n    def load_from_patches(self, patches, stride, scan_shape, data_attr=\'images\'):\n        """""" Get skyscraper from 4d-array of patches, put it to `data_attr` component in batch.\n\n        Let reconstruct original skyscraper from patches (if same arguments are passed)\n\n        Parameters\n        ----------\n        patches : ndarray\n            4d-array of patches, with dims: `(num_patches, z, y, x)`.\n        scan_shape : tuple, list or ndarray of int\n            (z,y,x)-shape of individual scan (should be same for all scans).\n        stride : tuple, list or ndarray of int\n            (z,y,x)-stride step used for gathering data from patches.\n        data_attr : str\n            batch component name to store new data.\n\n        Notes\n        -----\n        If stride != patch.shape(), averaging of overlapped regions is used.\n        `scan_shape`, patches.shape(), `stride` are used to infer the number of items\n        in new skyscraper. If patches were padded, padding is removed for skyscraper.\n\n        """"""\n        scan_shape = np.asarray(scan_shape).reshape(-1)\n        stride = np.asarray(stride).reshape(-1)\n        patch_shape = np.asarray(patches.shape[1:]).reshape(-1)\n\n        # infer what padding was applied to scans when extracting patches\n        pad_width = calc_padding_size(scan_shape, patch_shape, stride)\n\n        # if padding is non-zero, adjust the shape of scan\n        if pad_width is not None:\n            shape_delta = np.asarray([before + after for before, after in pad_width[1:]])\n        else:\n            shape_delta = np.zeros(3).astype(\'int\')\n\n        scan_shape_adj = scan_shape + shape_delta\n\n        # init 4d tensor and put assembled scans into it\n        data_4d = np.zeros((len(self), *scan_shape_adj))\n        patches = np.reshape(patches, (len(self), -1, *patch_shape))\n        assemble_patches(patches, stride, data_4d)\n\n        # crop (perform anti-padding) if necessary\n        if pad_width is not None:\n            data_shape = data_4d.shape\n            slc_z = slice(pad_width[1][0], data_shape[1] - pad_width[1][1])\n            slc_y = slice(pad_width[2][0], data_shape[2] - pad_width[2][1])\n            slc_x = slice(pad_width[3][0], data_shape[3] - pad_width[3][1])\n            data_4d = data_4d[:, slc_z, slc_y, slc_x]\n\n        # reshape 4d-data to skyscraper form and put it into needed attr\n        data_4d = data_4d.reshape((len(self) * scan_shape[0], *scan_shape[1:]))\n        setattr(self, data_attr, data_4d)\n\n    @action\n    def normalize_hu(self, min_hu=-1000, max_hu=400):\n        """""" Normalize HU-densities to interval [0, 255].\n\n        Trim HU that are outside range [min_hu, max_hu], then scale to [0, 255].\n\n        Parameters\n        ----------\n        min_hu : int\n            minimum value for hu that will be used as trimming threshold.\n        max_hu : int\n            maximum value for hu that will be used as trimming threshold.\n\n        Returns\n        -------\n        batch\n\n        Examples\n        --------\n        >>> batch = batch.normalize_hu(min_hu=-1300, max_hu=600)\n        """"""\n        # trimming and scaling to [0, 1]\n        self.images = (self.images - min_hu) / (max_hu - min_hu)\n        self.images[self.images > 1] = 1.\n        self.images[self.images < 0] = 0.\n\n        # scaling to [0, 255]\n        self.images *= 255\n        return self\n\n    @action\n    @inbatch_parallel(init=\'_init_rebuild\', post=\'_post_rebuild\', target=\'threads\')\n    def flip(self, patient, out_patient, res):    # pylint: disable=no-self-use\n        """""" Invert the order of slices for each patient\n\n        Returns\n        -------\n        batch\n\n        Examples\n        --------\n        >>> batch = batch.flip()\n        """"""\n        return flip_patient_numba(patient, out_patient, res)\n\n    def get_axial_slice(self, person_number, slice_height):\n        """""" Get axial slice (e.g., for plots)\n\n        Parameters\n        ----------\n        person_number : str or int\n            Can be either index (int) of person in the batch\n            or patient_id (str)\n        slice_height : float\n            scaled from 0 to 1 number of slice.\n            e.g. 0.7 means that we take slice with number\n            int(0.7 * number of slices for person)\n\n        Returns\n        -------\n        ndarray (view)\n\n        Examples\n        --------\n        Here self.index[5] usually smth like \'a1de03fz29kf6h2\'\n\n        >>> patch = batch.get_axial_slice(5, 0.6)\n        >>> patch = batch.get_axial_slice(self.index[5], 0.6)\n\n        """"""\n        margin = int(slice_height * self.get(person_number, \'images\').shape[0])\n        patch = self.get(person_number, \'images\')[margin, :, :]\n        return patch\n'"
radio/preprocessing/ct_masked_batch.py,0,"b'# pylint: disable=no-member\n# pylint: disable=too-many-public-methods\n# pylint: disable=too-many-locals\n# pylint: disable=too-many-arguments\n# pylint: disable=too-many-branches\n\n"""""" Batch class CTImagesMaskedBatch for storing CT-scans with masks. """"""\n\nimport logging\n\nimport numpy as np\nimport pandas as pd\nfrom numba import njit\nfrom skimage import measure\n\ntry:\n    from tqdm import tqdm_notebook\nexcept ImportError:\n    tqdm_notebook = lambda x: x\n\nfrom .ct_batch import CTImagesBatch\nfrom .mask import make_rect_mask_numba, make_ellipse_mask_numba, create_mask_reg\nfrom .histo import sample_histo3d\nfrom .crop import make_central_crop\nfrom ..batchflow import action, DatasetIndex, SkipBatchException  # pylint: disable=no-name-in-module\n\n\n# logger initialization\nlogger = logging.getLogger(__name__) # pylint: disable=invalid-name\n\n\n@njit(nogil=True)\ndef get_nodules_numba(data, positions, size):\n    """""" Fetch nodules from array by starting positions.\n\n    Takes array with data of shape (z, y, x) from `batch`,\n    ndarray(p, 3) with starting indices of nodules where p is number\n    of nodules and size of type ndarray(3, ) which contains\n    sizes of nodules along each axis. The output is 3d ndarray with nodules\n    put in CTImagesBatch-compatible skyscraper structure.\n\n    Parameters\n    ----------\n    data : ndarray\n        CTImagesBatch `skyscraper` represented by 3D ndarray.\n    positions : ndarray(l, 3) of int\n        Contains nodules\' starting indices along [zyx]-axis accordingly in `data`.\n    size : ndarray(3,) of int\n        Contains nodules\' sizes along each axis (z,y,x).\n\n    Notes\n    -----\n    Dtypes of positions and size arrays must be the same.\n\n    Returns\n    -------\n    ndarray\n        3d ndarray with nodules\n    """"""\n    size = size.astype(np.int64)\n    out_arr = np.zeros((positions.shape[0], size[0], size[1], size[2]))\n\n    n_positions = positions.shape[0]\n    for i in range(n_positions):\n        out_arr[i, :, :, :] = data[positions[i, 0]: positions[i, 0] + size[0],\n                                   positions[i, 1]: positions[i, 1] + size[1],\n                                   positions[i, 2]: positions[i, 2] + size[2]]\n\n    return out_arr.reshape(n_positions * size[0], size[1], size[2])\n\n@njit\ndef mix_images_numba(images, masks, bounds, permutation, p, mode, mix_masks):\n    """""" Mix images and corresponding masks.\n\n    Parameters\n    ----------\n    images : np.array\n        images as skyscrapper\n    masks : np.array\n        masks as skyscrapper\n    bounds : np.array\n        upper bounds in skyscrappers\n    permutation : np.array\n        permutation of images to mix\n    p : float in (0, 1)\n        weight of the initial image\n    mode : int\n        if 0 images will be mixed by max value\n        if 1 images will be mixed as linear combination\n    mix_masks : bool\n        if False initial mask will be used\n\n    Returns\n    -------\n    images, masks : np.arrays\n    """"""\n    bounds = bounds.astype(np.int64)\n    bounds = np.concatenate((np.zeros(1), bounds))\n\n    images_to_add = np.zeros_like(images)\n    masks_to_add = np.zeros_like(images)\n\n    for i in range(len(bounds)-1):\n        old_slice = slice(bounds[i], bounds[i+1])\n        new_slice = slice(bounds[permutation[i]], bounds[permutation[i]+1])\n        images_to_add[old_slice, :, :] = images[new_slice, :, :]\n        masks_to_add[old_slice, :, :] = masks[new_slice, :, :]\n\n    if mode == 0:\n        images = np.maximum(images * p, images_to_add * (1 - p)) / np.maximum(p, 1-p)\n        if mix_masks:\n            masks = np.maximum(masks, masks_to_add)\n    elif mode == 1:\n        images = images * p + images_to_add * (1 - p)\n        if mix_masks:\n            masks = np.maximum(masks, masks_to_add)\n    return images, masks\n\n\nclass CTImagesMaskedBatch(CTImagesBatch):\n    """""" Batch class for storing batch of ct-scans with masks for nodules.\n\n    Allows to load info about cancer nodules, then create cancer-masks\n    for each patient. Created masks are stored in self.masks\n\n    Parameters\n    ----------\n    index : batchflow.index\n        ids of scans to be put in a batch\n\n    Attributes\n    ----------\n    components : tuple of strings.\n        List names of data components of a batch, which are `images`,\n        `masks`, `origin` and `spacing`.\n        NOTE: Implementation of this attribute is required by Base class.\n    num_nodules : int\n        number of nodules in batch\n    images : ndarray\n        contains ct-scans for all patients in batch.\n    masks : ndarray\n        contains masks for all patients in batch.\n    nodules : np.recarray\n        contains info on cancer nodules location.\n        record array contains the following information about nodules:\n          - self.nodules.nodule_center -- ndarray(num_nodules, 3) centers of\n            nodules in world coords;\n          - self.nodules.nodule_size -- ndarray(num_nodules, 3) sizes of\n            nodules along z, y, x in world coord;\n          - self.nodules.img_size -- ndarray(num_nodules, 3) sizes of images of\n            patient data corresponding to nodules;\n          - self.nodules.offset -- ndarray(num_nodules, 3) position of individual\n            patient scan inside batch;\n          - self.nodules.spacing -- ndarray(num_nodules, 3) of spacing attribute\n            of patients which correspond to nodules;\n          - self.nodules.origin -- ndarray(num_nodules, 3) of origin attribute\n            of patients which correspond to nodules.\n    """"""\n\n    nodules_dtype = np.dtype([(\'patient_pos\', np.int, 1),\n                              (\'offset\', np.int, (3,)),\n                              (\'img_size\', np.int, (3,)),\n                              (\'nodule_center\', np.float, (3,)),\n                              (\'nodule_size\', np.float, (3,)),\n                              (\'spacing\', np.float, (3,)),\n                              (\'origin\', np.float, (3,))])\n\n    components = ""images"", ""masks"", ""spacing"", ""origin""\n\n    @staticmethod\n    def make_indices(size):\n        """""" Generate list of batch indices of given `size`.\n\n        Parameters\n        ----------\n        size : int\n            size of list with indices\n\n        Returns\n        -------\n        list\n            list of random indices\n\n        Examples\n        --------\n        >>> indices = CTImagesMaskedBatch.make_indices(20)\n        >>> indices\n        array([\'3c3eb09b\', \'5b192d1f\', \'f28ddbb0\', \'14460196\', \'31a92510\',\n               \'3f324e44\', \'066ccf28\', \'5570938d\', \'5d1fb8f6\', \'539ea09c\',\n               \'68f9f235\', \'8f7b0c49\', \'c7903591\', \'dc8e9504\', \'54e9eebc\',\n               \'778abd5a\', \'99691fc6\', \'7da49e85\', \'0f343345\', \'876fb9e6\'], dtype=\'<U8\')\n        """"""\n        return np.array([CTImagesMaskedBatch.make_filename() for i in range(size)])\n\n    def __init__(self, index, *args, **kwargs):\n        """""" Execute Batch construction and init of basic attributes\n\n        Parameters\n        ----------\n        index : batchflow.Index class.\n            Required indexing of objects (files).\n        """"""\n        super().__init__(index, *args, **kwargs)\n        self.masks = None\n        self.nodules = None\n\n    def nodules_to_df(self, nodules):\n        """""" Convert nodules_info ndarray into pandas dataframe.\n\n        Pandas DataFrame will contain following columns:\n        \'source_id\' - id of source element of batch;\n        \'nodule_id\' - generated id for nodules;\n        \'locZ\', \'locY\', \'locX\' - coordinates of nodules\' centers;\n        \'diamZ\', \'diamY\', \'diamX\' - sizes of nodules along zyx axes;\n\n        Parameters\n        ----------\n        nodules : ndarray of type nodules_info\n            nodules_info type is defined inside of CTImagesMaskedBatch class.\n\n        Returns\n        -------\n        pd.DataFrame\n            centers, ids and sizes of nodules.\n        """"""\n        columns = [\'nodule_id\', \'source_id\', \'locZ\', \'locY\',\n                   \'locX\', \'diamZ\', \'diamY\', \'diamX\']\n\n        nodule_id = self.make_indices(nodules.shape[0])\n        return pd.DataFrame({\'source_id\': self.indices[nodules.patient_pos],\n                             \'nodule_id\': nodule_id,\n                             \'locZ\': nodules.nodule_center[:, 0],\n                             \'locY\': nodules.nodule_center[:, 1],\n                             \'locX\': nodules.nodule_center[:, 2],\n                             \'diamZ\': nodules.nodule_size[:, 0],\n                             \'diamY\': nodules.nodule_size[:, 1],\n                             \'diamX\': nodules.nodule_size[:, 2]}, columns=columns)\n\n    def get_pos(self, data, component, index, dst=None):\n        """""" Return a positon of an item for a given index in data\n        or in self.`component`.\n\n        Fetch correct position inside batch for an item, looks for it\n        in `data`, if provided, or in `component` in self.\n\n        Parameters\n        ----------\n        data : None or ndarray\n            data from which subsetting is done.\n            If None, retrieve position from `component` of batch,\n            if ndarray, returns index.\n        component : str\n            name of a component, f.ex. \'images\'.\n            if component provided, data should be None.\n        index : str or int\n            index of an item to be looked for.\n            may be key from dataset (str)\n            or index inside batch (int).\n\n        Returns\n        -------\n        int\n            Position of item\n\n        Notes\n        -----\n        This is an overload of get_pos from base Batch-class,\n        see corresponding docstring for detailed explanation.\n        """"""\n        if data is None:\n            ind_pos = self._get_verified_pos(index)\n            if component in [\'images\', \'masks\']:\n                return slice(self.lower_bounds[ind_pos], self.upper_bounds[ind_pos])\n            else:\n                return slice(ind_pos, ind_pos + 1)\n        else:\n            return index\n\n    @property\n    def num_nodules(self):\n        """""" Get number of nodules in CTImagesMaskedBatch.\n\n        Returns\n        -------\n        int\n            number of nodules in CTImagesMaskedBatch.\n            if fetch_nodules_info method has not been called yet returns 0.\n        """"""\n        if self.nodules is not None:\n            return self.nodules.patient_pos.shape[0]\n        else:\n            return 0\n\n    @action\n    def fetch_nodules_info(self, nodules=None, nodules_records=None, update=False, images_loaded=True):\n        """"""Extract nodules\' info from nodules into attribute self.nodules.\n\n        Parameters\n        ----------\n        nodules : pd.DataFrame\n            contains:\n             - \'seriesuid\': index of patient or series.\n             - \'coordZ\',\'coordY\',\'coordX\': coordinates of nodules center.\n             - \'diameter_mm\': diameter, in mm.\n        nodules_records : np.recarray\n            if not None, should\n            contain the same fields as describe in Note.\n        update : bool\n            if False, warning appears to remind that nodules info\n            will be earased and recomputed.\n        images_loaded : bool\n            if True, i.e. `images` component is loaded,\n            and image_size is used to compute\n            correct nodules location inside `skyscraper`.\n            If False, it doesn\'t update info of location\n            inside `skyscraper`.\n\n        Returns\n        -------\n        batch\n\n        Notes\n        -----\n        Run this action only after  :func:`~radio.CTImagesBatch.load`.\n        The method fills in record array self.nodules that contains the following information about nodules:\n                               - self.nodules.nodule_center -- ndarray(num_nodules, 3) centers of\n                                 nodules in world coords;\n                               - self.nodules.nodule_size -- ndarray(num_nodules, 3) sizes of\n                                 nodules along z, y, x in world coord;\n                               - self.nodules.img_size -- ndarray(num_nodules, 3) sizes of images of\n                                 patient data corresponding to nodules;\n                               - self.nodules.offset -- ndarray(num_nodules, 3) of biases of\n                                 patients which correspond to nodules;\n                               - self.nodules.spacing -- ndarray(num_nodules, 3) of spacinf attribute\n                                 of patients which correspond to nodules;\n                               - self.nodules.origin -- ndarray(num_nodules, 3) of origin attribute\n                                 of patients which correspond to nodules.\n                               - self.nodules.patient_pos -- ndarray(num_nodules, 1) refers to\n                                 positions of patients which correspond to stored nodules.\n\n        """"""\n        if self.nodules is not None and not update:\n            message = (""Nodules have already been extracted. "" +\n                       ""Put update argument as True for refreshing"")\n            logger.warning(message)\n            return self\n\n        if nodules_records is not None:\n            # load from record-array\n            self.nodules = nodules_records\n\n        else:\n            # assume that nodules is supplied and load from it\n            required_columns = np.array([\'seriesuid\', \'diameter_mm\',\n                                         \'coordZ\', \'coordY\', \'coordX\'])\n\n            if not (isinstance(nodules, pd.DataFrame) and np.all(np.in1d(required_columns, nodules.columns))):\n                raise ValueError((""Argument \'nodules\' must be pandas DataFrame""\n                                  + "" with {} columns. Make sure that data provided""\n                                  + "" in correct format."").format(required_columns.tolist()))\n\n            nodules_df = nodules.set_index(\'seriesuid\')\n\n            unique_indices = nodules_df.index.unique()\n            inter_index = np.intersect1d(unique_indices, self.indices)\n            nodules_df = nodules_df.loc[inter_index,\n                                        [""coordZ"", ""coordY"",\n                                         ""coordX"", ""diameter_mm""]]\n\n            num_nodules = nodules_df.shape[0]\n            self.nodules = np.rec.array(np.zeros(num_nodules,\n                                                 dtype=self.nodules_dtype))\n            counter = 0\n            for pat_id, coordz, coordy, coordx, diam in nodules_df.itertuples():\n                pat_pos = self.index.get_pos(pat_id)\n                self.nodules.patient_pos[counter] = pat_pos\n                self.nodules.nodule_center[counter, :] = np.array([coordz,\n                                                                   coordy,\n                                                                   coordx])\n                self.nodules.nodule_size[counter, :] = np.array([diam, diam, diam])\n                counter += 1\n\n        self._refresh_nodules_info(images_loaded)\n        return self\n\n    @action\n    def fetch_nodules_from_mask(self, images_loaded=True, src=\'masks\'):\n        """""" Fetch nodules info (centers and sizes) from masks.\n\n        Runs skimage.measure.labels for fetching nodules regions\n        from masks. Extracts nodules info from segmented regions\n        and put this information in self.nodules np.recarray.\n\n        Parameters\n        ----------\n        images_loaded : bool\n            if True, i.e. `images` component is loaded,\n            and image_size is used to compute\n            correct nodules location inside `skyscraper`.\n            If False, it doesn\'t update info of location\n            inside `skyscraper`.\n        src : str\n            name of the component with masks\n\n        Returns\n        -------\n        batch\n\n        Notes\n        -----\n        Sizes along [zyx] will be the same.\n        """"""\n        nodules_list = []\n        for pos in range(len(self)):\n            mask = self.unpack(src)[pos]\n            mask_labels = measure.label(mask, background=0)\n            for props in measure.regionprops(np.int16(mask_labels)):\n                center = np.asarray((props.centroid[0],\n                                     props.centroid[1],\n                                     props.centroid[2]), dtype=np.float)\n                center = center * self.spacing[pos] + self.origin[pos]\n\n                diameter = np.asarray(\n                    [props.equivalent_diameter] * 3, dtype=np.float)\n                diameter = diameter * self.spacing[pos]\n                nodules_list.append({\'patient_pos\': pos,\n                                     \'nodule_center\': center,\n                                     \'nodule_size\': diameter})\n        num_nodules = len(nodules_list)\n        self.nodules = np.rec.array(\n            np.zeros(num_nodules, dtype=self.nodules_dtype))\n        for i, nodule in enumerate(nodules_list):\n            self.nodules.patient_pos[i] = nodule[\'patient_pos\']\n            self.nodules.nodule_center[i, :] = nodule[\'nodule_center\']\n            self.nodules.nodule_size[i, :] = nodule[\'nodule_size\']\n        self._refresh_nodules_info(images_loaded)\n        return self\n\n    # TODO: another name of method\n    def _fit_into_bounds(self, size, variance=None):\n        """""" Fetch start voxel coordinates of all nodules.\n\n        Get start voxel coordinates of all nodules in batch.\n        Note that all nodules are considered to have\n        fixed same size defined by argument size: if nodule is out of\n        patient\'s 3d image bounds than it\'s center is shifted to border.\n\n        Parameters\n        ----------\n        size : list or tuple of ndarrays\n            ndarray(3, ) with diameters of nodules in (z,y,x).\n        variance : ndarray(3, )\n            diagonal elements of multivariate normal distribution,\n            for sampling random shifts along (z,y,x) correspondingly.\n\n        Returns\n        -------\n        ndarray\n            start coordinates (z,y,x) of all nodules in batch.\n        """"""\n        size = np.array(size, dtype=np.int)\n\n        center_pix = np.abs(self.nodules.nodule_center -\n                            self.nodules.origin) / self.nodules.spacing\n        start_pix = (np.rint(center_pix) - np.rint(size / 2))\n        if variance is not None:\n            start_pix += np.random.multivariate_normal(np.zeros(3),\n                                                       np.diag(variance),\n                                                       self.nodules.patient_pos.shape[0])\n        end_pix = start_pix + size\n\n        bias_upper = np.maximum(end_pix - self.nodules.img_size, 0)\n        start_pix -= bias_upper\n        end_pix -= bias_upper\n\n        bias_lower = np.maximum(-start_pix, 0)\n        start_pix += bias_lower\n        end_pix += bias_lower\n\n        return (start_pix + self.nodules.offset).astype(np.int)\n\n    @action\n    def create_mask(self, mode=\'rectangle\'):\n        """""" Create `masks` component from `nodules` component.\n\n        Parameters\n        ----------\n        mode : \'rectangle\' or \'ellipse\'\n            form of the nodule in mask\n\n        Notes\n        -----\n        `nodules` must be not None before calling this method.\n        see :func:`~radio.preprocessing.ct_masked_batch.CTImagesMaskedBatch.fetch_nodules_info`\n        for more details.\n        """"""\n        if self.nodules is None:\n            message = (""Info about nodules location must "" +\n                       ""be loaded before calling this method. "" +\n                       ""Nothing happened."")\n            logger.warning(message)\n        self.masks = np.zeros_like(self.images)\n\n        center_pix = np.abs(self.nodules.nodule_center -\n                            self.nodules.origin) / self.nodules.spacing\n        radius_pix = np.rint(self.nodules.nodule_size / self.nodules.spacing / 2)\n\n        center_pix = np.rint(center_pix).astype(np.int)\n        radius_pix = np.rint(radius_pix).astype(np.int)\n        if mode == \'rectangle\':\n            start_pix = (center_pix - radius_pix)\n            start_pix = np.rint(start_pix).astype(np.int)\n            make_rect_mask_numba(self.masks, self.nodules.offset,\n                                 self.nodules.img_size + self.nodules.offset, start_pix,\n                                 np.rint(self.nodules.nodule_size / self.nodules.spacing))\n        elif mode == \'ellipse\':\n            make_ellipse_mask_numba(self.masks, self.nodules.offset.astype(np.int32),\n                                    self.nodules.img_size + self.nodules.offset,\n                                    center_pix, radius_pix)\n\n        return self\n\n    @action\n    def truncate_mask(self, threshold=0.2, min_val=0, max_val=255):\n        """""" Truncate mask by images.\n\n        Parameters\n        ----------\n        threshold : float\n            binarizing thresholg for initial image\n        min_val : float\n            minimum value of image\n        max_val : float\n            maximum value of image\n        """"""\n        self.masks = np.array(self.masks * self.images > threshold * (max_val - min_val), dtype=np.int32)\n        return self\n\n    def fetch_mask(self, shape):\n        """""" Create `masks` component of different size then `images`,\n        using `nodules` component.\n\n        Parameters\n        ----------\n        shape : tuple, list or ndarray of int.\n            (z_dim,y_dim,x_dim), shape of mask to be created.\n\n        Returns\n        -------\n        ndarray\n            3d array with masks in form of `skyscraper`.\n\n        # TODO: one part of code from here repeats create_mask function\n            better to unify these two func\n        """"""\n        if self.nodules is None:\n            message = (""Info about nodules location must "" +\n                       ""be loaded before calling this method. "" +\n                       ""Nothing happened."")\n            logger.warning(message)\n\n        mask = np.zeros(shape=(len(self) * shape[0], *shape[1:]))\n\n        # infer scale factor; assume patients are already resized to equal\n        # shapes\n        scale_factor = np.asarray(shape) / self.images_shape[0, :]\n\n        # get rescaled nodule-centers, nodule-sizes, offsets, locs of nod\n        # starts\n        center_scaled = (np.abs(self.nodules.nodule_center - self.nodules.origin) /\n                         self.nodules.spacing * scale_factor)\n        start_scaled = (center_scaled - scale_factor * self.nodules.nodule_size /\n                        self.nodules.spacing / 2)\n        start_scaled = np.rint(start_scaled).astype(np.int)\n        offset_scaled = np.rint(self.nodules.offset *\n                                scale_factor).astype(np.int)\n        img_size_scaled = np.rint(\n            self.nodules.img_size * scale_factor).astype(np.int)\n        nod_size_scaled = (np.rint(scale_factor * self.nodules.nodule_size /\n                                   self.nodules.spacing)).astype(np.int)\n        # put nodules into mask\n        make_rect_mask_numba(mask, offset_scaled, img_size_scaled + offset_scaled,\n                             start_scaled, nod_size_scaled)\n        # return ndarray-mask\n        return mask\n\n    # TODO rename function to sample_random_nodules_positions\n    def sample_random_nodules(self, num_nodules, nodule_size, histo=None):\n        """""" Sample random nodules positions in CTImagesBatchMasked.\n\n        Samples random nodules positions in ndarray. Each nodule have shape\n        defined by `nodule_size`. If size of patients\' data along z-axis\n        is not the same for different patients, NotImplementedError will be raised.\n\n        Parameters\n        ----------\n        num_nodules : int\n            number of nodules to sample from dataset.\n        nodule_size : ndarray(3, )\n            crop shape along (z,y,x).\n        histo : tuple\n            np.histogram()\'s output.\n            3d-histogram, represented by tuple (bins, edges).\n\n        Returns\n        -------\n        ndarray\n            ndarray(num_nodules, 3). 1st array\'s dim is an index of sampled\n            nodules, 2nd points out start positions (integers) of nodules\n            in batch `skyscraper`.\n        """"""\n        all_indices = np.arange(len(self))\n        sampled_indices = np.random.choice(\n            all_indices, num_nodules, replace=True)\n\n        offset = np.zeros((num_nodules, 3))\n        offset[:, 0] = self.lower_bounds[sampled_indices]\n        data_shape = self.images_shape[sampled_indices, :]\n\n        # if supplied, use histogram as the sampler\n        if histo is None:\n            sampler = lambda size: np.random.rand(size, 3)\n        else:\n            sampler = lambda size: sample_histo3d(histo, size)\n\n        samples = sampler(size=num_nodules) * (data_shape - nodule_size)\n\n        if histo is not None:\n            samples /= data_shape\n\n        return np.asarray(samples + offset, dtype=np.int), sampled_indices\n\n    @action\n    def sample_nodules(self, batch_size, nodule_size=(32, 64, 64), share=0.8, variance=None,        # pylint: disable=too-many-locals, too-many-statements\n                       mask_shape=None, histo=None):\n        """""" Sample random crops of `images` and `masks` from batch.\n\n        Create random crops, both with and without nodules in it, from input batch.\n\n        Parameters\n        ----------\n        batch_size : int\n            number of nodules in the output batch. Required,\n            if share=0.0. If None, resulting batch will include all\n            cancerous nodules.\n        nodule_size : tuple, list or ndarray of int\n            crop shape along (z,y,x).\n        share : float\n            share of cancer crops in the batch.\n            if input CTImagesBatch contains less cancer\n            nodules than needed random nodules will be taken.\n        variance : tuple, list or ndarray of float\n            variances of normally distributed random shifts of\n            nodules\' start positions.\n        mask_shape : tuple, list or ndarray of int\n            size of `masks` crop in (z,y,x)-order. If not None,\n            crops with masks would be of mask_shape.\n            If None, mask crop shape would be equal to crop_size.\n        histo : tuple\n            np.histogram()\'s output.\n            Used for sampling non-cancerous crops.\n\n        Returns\n        -------\n        Batch\n            batch with cancerous and non-cancerous crops in a proportion defined by\n            `share` with total `batch_size` nodules. If `share` == 1.0, `batch_size`\n            is None, resulting batch consists of all cancerous crops stored in batch.\n        """"""\n        # make sure that nodules\' info is fetched and args are OK\n        if self.nodules is None:\n            raise AttributeError(""Info about nodules location must "" +\n                                 ""be loaded before calling this method"")\n        if variance is not None:\n            variance = np.asarray(variance, dtype=np.int)\n            variance = variance.flatten()\n            if len(variance) != 3:\n                message = (\'Argument variance be np.array-like\' +\n                           \'and has shape (3,). \' +\n                           \'Would be used no-scale-shift.\')\n                logger.warning(message)\n                variance = None\n\n        if share == 0.0 and batch_size is None:\n            raise ValueError(\'Either supply batch_size or set share to positive number\')\n\n        # pos of batch-items that correspond to crops\n        crops_indices = np.zeros(0, dtype=np.int16)\n\n        # infer the number of cancerous nodules and the size of batch\n        batch_size = batch_size if batch_size is not None else 1.0 / share * self.num_nodules\n        cancer_n = int(share * batch_size)\n        batch_size = int(batch_size)\n        cancer_n = self.num_nodules if cancer_n > self.num_nodules else cancer_n\n\n        if batch_size == 0:\n            raise SkipBatchException(\'Batch of zero size cannot be passed further through the workflow\')\n\n        # choose cancerous nodules\' starting positions\n        nodule_size = np.asarray(nodule_size, dtype=np.int)\n        if self.num_nodules == 0:\n            cancer_nodules = np.zeros((0, 3))\n        else:\n            # adjust cancer nodules\' starting positions s.t. nodules fit into\n            # scan-boxes\n            cancer_nodules = self._fit_into_bounds(\n                nodule_size, variance=variance)\n\n            # randomly select needed number of cancer nodules (their starting\n            # positions)\n            sample_indices = np.random.choice(np.arange(self.num_nodules),\n                                              size=cancer_n, replace=False)\n            cancer_nodules = cancer_nodules[sample_indices, :]\n\n            # store scans-indices for chosen crops\n            cancerous_indices = self.nodules.patient_pos[sample_indices].reshape(-1)\n            crops_indices = np.concatenate([crops_indices, cancerous_indices])\n\n        nodules_st_pos = cancer_nodules\n\n        # if non-cancerous nodules are needed, add random starting pos\n        if batch_size - cancer_n > 0:\n            # sample starting positions for (most-likely) non-cancerous crops\n            random_nodules, random_indices = self.sample_random_nodules(batch_size - cancer_n,\n                                                                        nodule_size, histo=histo)\n\n            # concat non-cancerous and cancerous crops\' starting positions\n            nodules_st_pos = np.vstack([nodules_st_pos, random_nodules]).astype(\n                np.int)  # pylint: disable=no-member\n\n            # store scan-indices for randomly chose crops\n            crops_indices = np.concatenate([crops_indices, random_indices])\n\n        # obtain nodules\' scans by cropping from self.images\n        images = get_nodules_numba(self.images, nodules_st_pos, nodule_size)\n\n        # if mask_shape not None, compute scaled mask for the whole batch\n        # scale also nodules\' starting positions and nodules\' shapes\n        if mask_shape is not None:\n            scale_factor = np.asarray(mask_shape) / np.asarray(nodule_size)\n            batch_mask_shape = np.rint(\n                scale_factor * self.images_shape[0, :]).astype(np.int)\n            batch_mask = self.fetch_mask(batch_mask_shape)\n            nodules_st_pos = np.rint(\n                scale_factor * nodules_st_pos).astype(np.int)\n        else:\n            batch_mask = self.masks\n            mask_shape = nodule_size\n\n        # crop nodules\' masks\n        masks = get_nodules_numba(batch_mask, nodules_st_pos, mask_shape)\n\n        # build nodules\' batch\n        bounds = np.arange(batch_size + 1) * nodule_size[0]\n        crops_spacing = self.spacing[crops_indices]\n        offset = np.zeros((batch_size, 3))\n        offset[:, 0] = self.lower_bounds[crops_indices]\n        crops_origin = self.origin[crops_indices] + crops_spacing * (nodules_st_pos - offset)\n        names_gen = zip(self.indices[crops_indices], self.make_indices(batch_size))\n        ix_batch = [\'_\'.join([prefix, random_str]) for prefix, random_str in names_gen]\n        nodules_batch = type(self)(DatasetIndex(ix_batch))\n        nodules_batch._init_data(images=images, bounds=bounds, spacing=crops_spacing, origin=crops_origin, masks=masks)  # pylint: disable=protected-access\n\n        # set nodules info in nodules\' batch\n        nodules_records = [self.nodules[self.nodules.patient_pos == crop_pos] for crop_pos in crops_indices]\n        new_patient_pos = []\n        for i, records in enumerate(nodules_records):\n            new_patient_pos += [i] * len(records)\n        new_patient_pos = np.array(new_patient_pos)\n        nodules_records = np.concatenate(nodules_records)\n        nodules_records = nodules_records.view(np.recarray)\n        nodules_records.patient_pos = new_patient_pos\n        nodules_batch.fetch_nodules_info(nodules_records=nodules_records)\n\n        # leave out nodules with zero-intersection with crops\' boxes\n        nodules_batch._filter_nodules_info()                                                     # pylint: disable=protected-access\n\n        return nodules_batch\n\n    @action\n    def sample_dump(self, dst, n_iters, nodule_size=(32, 64, 64), batch_size=20, share=0.8, **kwargs):\n        """""" Perform sample_nodules and dump on the same batch n_iters times.\n\n        Can be used for fast creation of large datasets of cancerous/non-cancerous crops.\n\n        Parameters\n        ----------\n        dst : str\n            folder to dump nodules in.\n        n_iters : int\n            number of iterations to be performed.\n        nodule_size : tuple, list or ndarray of int\n            (z,y,x)-shape of sampled nodules.\n        batch_size : int or None\n            size of generated batches.\n        share : float\n            share of cancer nodules. See docstring of sample_nodules for more info\n            about possible combinations of parameters share and batch_size.\n        **kwargs : dict\n            additional arguments supplied into sample_nodules. See docstring\n            of sample_nodules for more info.\n        """"""\n        for _ in range(n_iters):\n            nodules = self.sample_nodules(batch_size=batch_size, nodule_size=nodule_size, share=share, **kwargs)\n            nodules = nodules.dump(dst=dst)    # pylint: disable=no-value-for-parameter\n\n        return self\n\n    @action\n    def update_nodules_histo(self, histo):\n        """""" Update histogram of nodules\' locations using nodules locations from batch.\n\n        Parameters\n        ----------\n        histo : list\n            list(np.histogram()), used for sampling cancerous locations.\n\n        Notes\n        -----\n        Execute action only after .fetch_nodules_info().\n        """"""\n        # infer bins\' bounds from histo\n        bins = histo[1]\n\n        # get cancer_nodules\' centers in voxel coords\n        center_pix = np.abs(self.nodules.nodule_center -\n                            self.nodules.origin) / self.nodules.spacing\n\n        # update bins of histo\n        histo_delta = np.histogramdd(center_pix, bins=bins)\n        histo[0] += histo_delta[0]\n\n        return self\n\n    def get_axial_slice(self, patient_pos, height):\n        """""" Get tuple of `images` slice and `masks` slice by patient and slice position.\n\n        Parameters\n        ----------\n        patient_pos : int\n            patient position in the batch\n        height : float\n            number of slice (z-axis), scaled to [0:1]\n            used to get slice with position:\n            int(height * number_of slices_for_patient) from\n            patient\'s scan and mask.\n\n        Returns\n        -------\n        tuple\n            (images_slice,masks_slice) by patient_pos and number of slice\n        """"""\n        margin = int(height * self.get(patient_pos, \'images\').shape[0])\n        if self.masks is not None:\n            patch = (self.get(patient_pos, \'images\')[margin, :, :],\n                     self.get(patient_pos, \'masks\')[margin, :, :])\n        else:\n            patch = (self.get(patient_pos, \'images\')[margin, :, :], None)\n        return patch\n\n    def _refresh_nodules_info(self, images_loaded=True):\n        """""" Refresh self.nodules attributes [spacing, origin, img_size, bias].\n\n        This method is called to update [spacing, origin, img_size, bias]\n        attributes of self.nodules because batch\'s inner data has changed,\n        e.g. after resize.\n\n        Parameters\n        ----------\n        images_loaded : bool\n            if True, assumes that `_bounds` attribute is computed,\n            i.e. either `masks` and/or `images` are loaded.\n        """"""\n        if images_loaded:\n            self.nodules.offset[:, 0] = self.lower_bounds[\n                self.nodules.patient_pos]\n            self.nodules.img_size = self.images_shape[\n                self.nodules.patient_pos, :]\n\n        self.nodules.spacing = self.spacing[self.nodules.patient_pos, :]\n        self.nodules.origin = self.origin[self.nodules.patient_pos, :]\n\n    def _filter_nodules_info(self):\n        """""" Filter record-array self.nodules s.t. only records about cancerous nodules\n        that have non-zero intersection with scan-boxes be present.\n\n        Notes\n        -----\n        can be called only after execution of fetch_nodules_info and _refresh_nodules_info\n        """"""\n        # nodules start and trailing pixel-coords\n        center_pix = (self.nodules.nodule_center - self.nodules.origin) / self.nodules.spacing\n        start_pix = center_pix - np.rint(self.nodules.nodule_size / self.nodules.spacing / 2)\n        start_pix = np.rint(start_pix).astype(np.int)\n        end_pix = start_pix + np.rint(self.nodules.nodule_size / self.nodules.spacing)\n\n        # find nodules with no intersection with scan-boxes\n        nods_images_shape = self.images_shape[self.nodules.patient_pos]\n        start_mask = np.any(start_pix >= nods_images_shape, axis=1)\n        end_mask = np.any(end_pix <= 0, axis=1)\n        zero_mask = start_mask | end_mask\n\n        # filter out such nodules\n        self.nodules = self.nodules[~zero_mask]\n\n    def _rescale_spacing(self):\n        """""" Rescale spacing values and call _refresh_nodules_info().\n\n        Method is called after any operation that changes shape of inner data.\n        """"""\n        if self.nodules is not None:\n            self._refresh_nodules_info()\n        return self\n\n    def _post_mask(self, list_of_arrs, **kwargs):\n        """""" Concatenate outputs of different workers and put the result in `masks`\n\n        Parameters\n        ----------\n        list_of_arrs : list\n            list of ndarrays of patients\' masks.\n        """"""\n        self._reraise_worker_exceptions(list_of_arrs)\n        new_masks = np.concatenate(list_of_arrs, axis=0)\n        self.masks = new_masks\n\n        return self\n\n    def _prealloc_components(self, **kwargs):\n        """""" Init-func for load from blosc.\n\n        Fills images/masks-components with zeroes if the components are to be updated.\n\n        Parameters\n        ----------\n        **kwargs\n                components : str, list or tuple\n                    iterable of components names that need to be loaded\n        Returns\n        -------\n        list\n            list of ids of batch-items, i.e. series ids or patient ids.\n        """"""\n        # fill \'images\', \'masks\'-comps with zeroes if needed\n        skysc_components = {\'images\', \'masks\'} & set(kwargs[\'components\'])\n        self._prealloc_skyscraper_components(skysc_components)\n\n        return self.indices\n\n    def _post_rebuild(self, all_outputs, new_batch=False, **kwargs):\n        """""" Gather outputs of different workers, rebuild `images` and `masks`.\n\n        Parameters\n        ----------\n        all_outputs : list\n            list of outputs. Each item is given by tuple.\n        new_batch : bool\n            if True, returns new batch with data agregated\n            from all_ouputs. if False, changes self.\n        **kwargs\n                shape : list, tuple or ndarray of int\n                    (z,y,x)-shape of every image in image component after action is performed.\n                spacing : tuple, list or ndarray of float\n                    (z,y,x)-spacing for each image. If supplied, assume that\n                    unify_spacing is performed.\n\n        Returns\n        -------\n        batch\n        """"""\n        # TODO: process errors\n        batch = super()._post_rebuild(all_outputs, new_batch, **kwargs)\n        batch.nodules = self.nodules\n        batch._rescale_spacing()  # pylint: disable=protected-access\n        if self.masks is not None:\n            batch.create_mask()\n        return batch\n\n    @action\n    def make_xip(self, depth, stride=1, mode=\'max\', projection=\'axial\', padding=\'reflect\', **kwargs):\n        """""" Make intensity projection (maximum, minimum, mean or median).\n\n        Notice that axis is chosen according to projection argument.\n\n        Parameters\n        ----------\n        depth : int\n            number of slices over which xip operation is performed.\n        stride : int\n            stride-step along projection dimension.\n        mode : str\n            Possible values are \'max\', \'min\', \'mean\' or \'median\'.\n        projection : str\n            Possible values: \'axial\', \'coronal\', \'sagital\'.\n            In case of \'coronal\' and \'sagital\' projections tensor\n            will be transposed from [z,y,x] to [x,z,y] and [y,z,x].\n        padding : str\n            mode of padding that will be passed in numpy.padding function.\n        """"""\n\n        if projection == \'axial\':\n            _projection = 0\n        elif projection == \'coronal\':\n            _projection = 1\n        elif projection == \'sagital\':\n            _projection = 2\n\n        batch = super().make_xip(stride=stride, depth=depth, mode=mode,\n                                 projection=projection, padding=padding, **kwargs)\n\n        if self.nodules is not None:\n            projection_spacing = self.nodules.spacing[:, _projection]\n            batch.nodules = self.nodules\n            batch.nodules.nodule_size[:, _projection] += (depth * projection_spacing)  # pylint: disable=unsubscriptable-object\n        batch._rescale_spacing()   # pylint: disable=protected-access\n        if self.masks is not None:\n            batch.create_mask()\n        return batch\n\n    @action\n    def central_crop(self, crop_size, crop_mask=False, **kwargs):\n        """""" Make crop of crop_size from center of images.\n\n        Parameters\n        ----------\n        crop_size : tuple, list or ndarray of int\n            (z,y,x)-shape of central crop along three axes(z,y,x order is used).\n        crop_mask : bool\n            if True, crop the mask in the same way.\n\n        Returns\n        -------\n        batch\n        """"""\n        crop_size = np.asarray(crop_size).reshape(-1)\n        crop_halfsize = np.rint(crop_size / 2)\n        img_shapes = [np.asarray(self.get(i, \'images\').shape)\n                      for i in range(len(self))]\n        if any(np.any(shape < crop_size) for shape in img_shapes):\n            raise ValueError(\n                ""Crop size must be smaller than size of inner 3D images"")\n\n        cropped_images = []\n        cropped_masks = []\n        for i in range(len(self)):\n            image = self.get(i, \'images\')\n            cropped_images.append(make_central_crop(image, crop_size))\n\n            if crop_mask and self.masks is not None:\n                mask = self.get(i, \'masks\')\n                cropped_masks.append(make_central_crop(mask, crop_size))\n\n        self._bounds = np.cumsum([0] + [crop_size[0]] * len(self))\n        self.images = np.concatenate(cropped_images, axis=0)\n        if crop_mask and self.masks is not None:\n            self.masks = np.concatenate(cropped_masks, axis=0)\n\n        # recalculate origin, refresh nodules_info, leave only relevant nodules\n        self.origin = self.origin + self.spacing * crop_halfsize\n        if self.nodules is not None:\n            self._refresh_nodules_info()\n            self._filter_nodules_info()\n\n        return self\n\n    def flip(self):\n        """""" Invert the order of slices for each patient\n\n        Returns\n        -------\n        batch\n\n        Examples\n        --------\n        >>> batch = batch.flip()\n        """"""\n        message = (""There is no implementation of flip method for class "" +\n                   ""CTIMagesMaskedBatch. Nothing happened"")\n        logger.warning(message)\n        return self\n\n    @action\n    def binarize_mask(self, threshold=0.35):\n        """""" Binarize masks by threshold.\n\n        Parameters\n        ----------\n        threshold : float\n            threshold for masks binarization.\n\n        """"""\n        self.masks *= np.asarray(self.masks > threshold, dtype=np.int)\n        return self\n\n    @action\n    def predict_on_scan(self, model, strides=(16, 32, 32), crop_shape=(32, 64, 64),\n                        batch_size=4, targets_mode=\'segmentation\', data_format=\'channels_last\',\n                        show_progress=True, model_type=\'tf\', dst=\'masks\'):\n        """""" Get predictions of the model on data contained in batch.\n\n        Transforms scan data into patches of shape crop_shape and then feed\n        this patches sequentially into model with name specified by\n        argument \'model\'; after that loads predicted masks or probabilities\n        into \'masks\' component of the current batch and returns it.\n\n        Parameters\n        ----------\n        model : str\n            name of model that will be used for predictions\n            or callable (model_type must be \'callable\').\n        strides : tuple, list or ndarray of int\n            (z,y,x)-strides for patching operation.\n        crop_shape : tuple, list or ndarray of int\n            (z,y,x)-shape of crops.\n        batch_size : int\n            number of patches to feed in model in one iteration.\n        targets_mode: str\n            type of targets \'segmentation\', \'regression\' or \'classification\'.\n        data_format: str\n            format of neural network input data,\n            can be \'channels_first\' or \'channels_last\'.\n        model_type : str\n            represents type of model that will be used for prediction.\n            Possible values are \'keras\', \'tf\' or \'callable\'.\n\n        Returns\n        -------\n        CTImagesMaskedBatch.\n        """"""\n        if model_type not in (\'tf\', \'keras\', \'callable\'):\n            raise ValueError(""Argument \'model_type\' must be one of [\'tf\', \'keras\', \'callable\']"")\n\n        if model_type in (\'keras\', \'tf\') and isinstance(model, str):\n            _model = self.get_model_by_name(model)\n        elif callable(model):\n            _model = model\n        else:\n            raise ValueError(""Argument \'model\' must be str or callable. ""\n                             + "" If callable then \'model_type\' argument\'s value ""\n                             + ""must be set to \'callable\'"")\n\n        crop_shape = np.asarray(crop_shape).reshape(-1)\n        strides = np.asarray(strides).reshape(-1)\n\n        patches_arr = self.get_patches(patch_shape=crop_shape,\n                                       stride=strides,\n                                       padding=\'reflect\')\n        if data_format == \'channels_first\':\n            patches_arr = patches_arr[:, np.newaxis, ...]\n        elif data_format == \'channels_last\':\n            patches_arr = patches_arr[..., np.newaxis]\n\n        predictions = []\n        iterations = range(0, patches_arr.shape[0], batch_size)\n        if show_progress:\n            iterations = tqdm_notebook(iterations)  # pylint: disable=bad-option-value\n        for i in iterations:\n\n            if model_type == \'tf\':\n                _prediction = _model.predict(feed_dict={\'images\': patches_arr[i: i + batch_size, ...]})\n            elif model_type == \'keras\':\n                _prediction = _model.predict(patches_arr[i: i + batch_size, ...])\n            elif model_type == \'callable\':\n                _prediction = _model(patches_arr[i: i + batch_size, ...])\n\n            current_prediction = np.asarray(_prediction)\n            if targets_mode == \'classification\':\n                current_prediction = np.stack([np.ones(shape=(crop_shape)) * prob\n                                               for prob in current_prediction.ravel()])\n\n            if targets_mode == \'regression\':\n                current_prediction = create_mask_reg(current_prediction[:, :3],\n                                                     current_prediction[:, 3:6],\n                                                     current_prediction[:, 6],\n                                                     crop_shape, 0.01)\n\n            predictions.append(current_prediction)\n\n        patches_mask = np.concatenate(predictions, axis=0)\n        patches_mask = np.squeeze(patches_mask)\n        self.load_from_patches(patches_mask, stride=strides,\n                               scan_shape=tuple(self.images_shape[0, :]),\n                               data_attr=dst)\n        return self\n\n    def unpack(self, component=\'images\', **kwargs):\n        """""" Basic way for unpacking components from batch.\n\n        Parameters\n        ----------\n        component : str\n            component to unpack, can be \'images\' or \'masks\'.\n        data_format : \'channels_last\' or \'channels_first\' or None\n            Reflects where to put channels dimension: right after batch dimension or after all spatial axes\n            or do not put it all if None.\n        kwargs : dict\n            key-word arguments that will be passed in callable if\n            component argument reffers to method of batch class.\n\n        Returns\n        -------\n        ndarray(batch_size, ...) or None\n        """"""\n        if not hasattr(self, component):\n            return None\n\n        if component in (\'images\', \'masks\'):\n            data_format = kwargs.get(\'data_format\')\n\n            if np.all(self.images_shape == self.images_shape[0, :]):\n                value = self.get(None, component).reshape(-1, *self.images_shape[0, :])\n            else:\n                value = np.stack([self.get(i, component) for i in range(len(self))])\n\n            if data_format is None:\n                pass\n            elif data_format == \'channels_last\':\n                value = value[..., np.newaxis]\n            elif data_format == \'channels_first\':\n                value = value[:, np.newaxis, ...]\n        else:\n            attr_value = getattr(self, component)\n            if callable(attr_value):\n                value = attr_value(**kwargs)\n            else:\n                value = attr_value\n        return value\n\n    def classification_targets(self, threshold=10, **kwargs):\n        """""" Unpack data from batch in format suitable for classification task.\n\n        Parameters\n        ----------\n        threshold : int\n            minimum number of \'1\' pixels in mask to consider it cancerous.\n\n        Returns\n        -------\n        ndarray(batch_size, 1)\n            targets for classification task: labels corresponding to cancerous\n            nodules (\'1\') and non-cancerous nodules (\'0\').\n        """"""\n        masks_labels = np.asarray([self.get(i, \'masks\').sum() > threshold\n                                   for i in range(len(self))], dtype=np.int)\n        return masks_labels[..., np.newaxis]\n\n    def regression_targets(self, threshold=10, **kwargs):\n        """""" Unpack data from batch in format suitable for regression task.\n\n        Parameters\n        ----------\n        threshold : int\n            minimum number of \'1\' pixels in mask to consider it cancerous.\n\n        Returns\n        -------\n        ndarray(batch_size, 7)\n            targets for regression task: cancer center, size\n            and label(1 for cancerous and 0 for non-cancerous). Note that in case\n            of non-cancerous crop first 6 column of output array will be set to zero.\n\n        """"""\n        nodules = self.nodules\n\n        sizes = np.zeros(shape=(len(self), 3), dtype=np.float)\n        centers = np.zeros(shape=(len(self), 3), dtype=np.float)\n\n        for item_pos, _ in enumerate(self.indices):\n            item_nodules = nodules[nodules.patient_pos == item_pos]\n\n            if len(item_nodules) == 0:\n                continue\n\n            mask_nod_indices = item_nodules.nodule_size.max(axis=1).argmax()\n\n            nodule_sizes = (item_nodules.nodule_size / self.spacing[item_pos, :]\n                            / self.images_shape[item_pos, :])\n\n            nodule_centers = (item_nodules.nodule_center / self.spacing[item_pos, :]\n                              / self.images_shape[item_pos, :])\n\n            sizes[item_pos, :] = nodule_sizes[mask_nod_indices, :]\n            centers[item_pos, :] = nodule_centers[mask_nod_indices, :]\n\n        labels = self.unpack(\'classification_targets\', threshold=threshold)\n        reg_targets = np.concatenate([centers, sizes, labels], axis=1)\n\n        return reg_targets\n\n    def segmentation_targets(self, data_format=\'channels_last\', **kwargs):\n        """""" Unpack data from batch in format suitable for regression task.\n\n        Parameters\n        ----------\n        data_format : str\n            data_format shows where to put new axis for channels dimension:\n            can be \'channels_last\' or \'channels_first\'.\n\n        Returns\n        -------\n        ndarray(batch_size, ...)\n            batch array with masks.\n        """"""\n        return self.unpack(\'masks\', data_format=data_format)\n\n    @staticmethod\n    def make_data_tf(batch, model=None, mode=\'segmentation\', is_training=True, **kwargs):\n        """""" Prepare data in batch for training neural network implemented in tensorflow.\n\n        Parameters\n        ----------\n        mode : str\n            mode can be one of following \'classification\', \'regression\'\n            or \'segmentation\'. Default is \'segmentation\'.\n        data_format : str\n            data format batch data. Can be \'channels_last\'\n            or \'channels_first\'. Default is \'channels_last\'.\n        is_training : bool\n            whether model is in training or prediction mode. Default is True.\n        threshold : int\n            threshold value of \'1\' pixels in masks to consider it cancerous.\n            Default is 10.\n\n        Returns\n        -------\n        dict or None\n            feed dict and fetches for training neural network.\n        """"""\n        inputs = batch.unpack(\'images\', **kwargs)\n        if mode in [\'segmentation\', \'classification\', \'regression\']:\n            labels = batch.unpack(mode + \'_targets\', **kwargs)\n        else:\n            raise ValueError(""Argument \'mode\' must have one of values: ""\n                             + ""\'segmentation\', \'classification\' or \'regression\'"")\n\n        feed_dict = dict(images=inputs, labels=labels) if is_training else dict(images=inputs)\n        return dict(feed_dict=feed_dict, fetches=None)\n\n    @staticmethod\n    def make_data_keras(batch, model=None, mode=\'segmentation\', is_training=True, **kwargs):\n        """""" Prepare data in batch for training neural network implemented in keras.\n\n        Parameters\n        ----------\n        mode : str\n            mode can be one of following \'classification\', \'regression\'\n            or \'segmentation\'. Default is \'segmentation\'.\n        data_format : str\n            data format batch data. Can be \'channels_last\'\n            or \'channels_first\'. Default is \'channels_last\'.\n        is_training : bool\n            whether model is in training or prediction mode. Default is True.\n        threshold : int\n            threshold value of \'1\' pixels in masks to consider it cancerous.\n            Default is 10.\n\n        Returns\n        -------\n        dict or None\n            kwargs for keras model train method:\n            {\'x\': ndarray(...), \'y\': ndarrray(...)} for training neural network.\n        """"""\n        inputs = batch.unpack(\'images\', **kwargs)\n        if mode in [\'segmentation\', \'classification\', \'regression\']:\n            labels = batch.unpack(mode + \'_targets\', **kwargs)\n        else:\n            raise ValueError(""Argument \'mode\' must have one of values: ""\n                             + ""\'segmentation\', \'classification\' or \'regression\'"")\n        return dict(x=inputs, y=labels) if is_training else dict(x=inputs)\n\n    @action\n    def mix_images(self, p=0.8, mode=\'sum\', mix_masks=True):\n        """""" Mix images and masks.\n\n        Parameters\n        ----------\n        p : float in (0, 1)\n            weight of the initial image\n        """"""\n\n        if mode == \'max\':\n            mode = 0\n        elif mode == \'sum\':\n            mode = 1\n        elif mode == \'none\':\n            return self\n        else:\n            raise ValueError(\'mode must be sum, max or none but {} was given\'.format(mode))\n\n        permutation = np.random.permutation(len(self.upper_bounds))\n        new_images, new_masks = mix_images_numba(self.images, self.masks,\n                                                 self.upper_bounds, permutation, p, mode, mix_masks)\n        setattr(self, \'images\', new_images)\n        setattr(self, \'masks\', new_masks)\n        return self\n'"
radio/preprocessing/dump.py,0,"b'# pylint: disable=undefined-variable\n\n"""""" Auxiliarry async functions for encoding and dump of data """"""\n\nimport os\nimport dill as pickle\n\nimport numpy as np\nimport aiofiles\nimport blosc\nfrom sklearn.cluster import MiniBatchKMeans\n\nKMEANS_MINIBATCH = 10000\nKMEANS_ITERS = 5\n\ndef get_linear(from_interval, to_interval):\n    """""" Get linear transformation that maps one interval to another\n\n    Parameters\n    ----------\n    from_interval : ndarray, tuple or list\n        sequence of len=2 (llim, ulim) that defines the domain-interval\n    to_interval : ndarray, tuple or list\n        sequence of len=2 that defines the image-interval\n\n    Returns\n    -------\n    function\n        linear transformation\n    """"""\n    # compute coeffs of the mapping\n    llim, ulim = from_interval\n    new_llim, new_ulim = to_interval\n    slope = (new_ulim - new_llim) / (ulim - llim)\n    intercept = new_llim - slope * llim\n\n    # define the map\n    def linear(x):\n        """""" Transformation\n        """"""\n        return slope * x + intercept\n\n    return linear\n\nasync def encode_dump_array(data, folder, filename, mode):\n    """""" Encode an ndarray to int8, blosc-pack it and dump data along with\n    the decoder and shape of data into supplied folder.\n\n    Parameters\n    ----------\n    data : ndarray\n        contains numeric (e.g., float32) data to be dumped\n    folder : str\n        folder for dump\n    filename : str\n        name of file in which the data is dumped; has format name.ext\n    mode : str or None\n        Mode of encoding to int8. Can be either \'quantization\' or \'linear\'\n        or None\n\n    Notes\n    -----\n    currently, two modes of encoding are supported:\n     - \'linear\': maps linearly data-range to int8-range and then rounds off fractional part.\n     - \'quantization\': attempts to use histogram of pixel densities to come up with a\n        transformation to int8-range that yields lesser error than linear mapping.\n    """"""\n    # parse mode of encoding\n    if isinstance(mode, int):\n        if mode <= 2:\n            _modes = [None, \'linear\', \'quantization\']\n            mode = _modes[mode]\n    elif isinstance(mode, str):\n        mode = mode.lower()\n\n    fname_noext = \'.\'.join(filename.split(\'.\')[:-1])\n\n    # init list of serialized objects and filenames for dump\n    byted, fnames = list(), list()\n\n    # encode the data and get the decoder\n    if mode == \'linear\':\n        data_range = (data.min(), data.max())\n        i8_range = (-128, 127)\n\n        if data_range[0] == data_range[1]:\n            value = data_range[0]\n            encoded = np.zeros_like(data, dtype=np.int8)\n            decoder = lambda x: x + value\n        else:\n            encoded = np.rint(get_linear(data_range, i8_range)(data)).astype(np.int8)\n            decoder = get_linear(i8_range, data_range)\n\n        # serialize decoder\n        byted.append(pickle.dumps(decoder))\n        fnames.append(fname_noext + \'.decoder\')\n    elif mode == \'quantization\':\n\n        # set up quantization model\n        data_range = (data.min(), data.max())\n        batch_size = min(KMEANS_MINIBATCH, data.size)\n        model = MiniBatchKMeans(n_clusters=256, init=np.linspace(*data_range, 256).reshape(-1, 1))      # pylint: disable=no-member\n\n        # fit the model on several minibatches, get encoded data\n        for _ in range(KMEANS_ITERS):\n            batch = np.random.choice(data.reshape(-1), batch_size, replace=False).reshape(-1, 1)\n            model.partial_fit(batch)\n\n        encoded = (model.predict(data.reshape(-1, 1)) - 128).astype(np.int8)\n\n        # prepare decoder\n        decoder = lambda x: (model.cluster_centers_[x + 128]).reshape(data.shape)\n\n        # serialize decoder\n        byted.append(pickle.dumps(decoder))\n        fnames.append(fname_noext + \'.decoder\')\n    elif mode is None:\n        encoded = data\n\n    else:\n        raise ValueError(\'Unknown mode of int8-encoding\')\n\n    # serialize (possibly) encoded data and its shape\n    byted.extend([blosc.pack_array(encoded, cname=\'zstd\', clevel=1), pickle.dumps(np.array(data.shape))])\n    fnames.extend([filename, fname_noext + \'.shape\'])\n\n    # dump serialized items\n    for btd, fname in zip(byted, fnames):\n        async with aiofiles.open(os.path.join(folder, fname), mode=\'wb\') as file:\n            _ = await file.write(btd)\n\nasync def dump_data(data_items, folder, i8_encoding_mode):\n    """""" Dump data from data_items on disk in specified folder\n\n    Parameters\n    ----------\n    data_items : dict\n        dict of data items for dump in form {item_name: [item, \'ext\']}\n        (e.g.: {\'images\': [scans, \'blk\'], \'masks\': [masks, \'blk\'], \'spacing\': [spacing, \'pkl\']})\n    folder : str\n        folder to dump data-items in. Note that each data item is dumped in its separate subfolder\n        inside the supplied folder.\n    i8_encoding_mode: str, int, or dict\n        contains mode of encoding to int8\n\n    Notes\n    -----\n    Depending on supplied format in data_items, each data-item will be either\n        pickle-serialized (if \'pkl\') or blosc-packed (if \'blk\')\n    """"""\n\n    # create directory if does not exist\n    if not os.path.exists(folder):\n        os.makedirs(folder)\n\n    # infer extension of each item, serialize/blosc-pack and dump the item\n    for item_name, (data, ext) in data_items.items():\n        item_folder = os.path.join(folder, item_name)\n        if not os.path.exists(item_folder):\n            os.makedirs(item_folder)\n        if ext == \'blk\':\n            if isinstance(i8_encoding_mode, dict):\n                mode = i8_encoding_mode.get(item_name, None)\n            else:\n                mode = i8_encoding_mode\n\n            _ = await encode_dump_array(data, item_folder, \'data.blk\', mode)\n\n        elif ext == \'pkl\':\n            byted = pickle.dumps(data)\n            async with aiofiles.open(os.path.join(item_folder, \'data.pkl\'), mode=\'wb\') as file:\n                _ = await file.write(byted)\n\n    return None\n'"
radio/preprocessing/flip.py,0,"b'"""""" Flip CT-image """"""\nfrom numba import njit\n\n\n@njit(nogil=True)\ndef flip_patient_numba(patient, out_patient, res):\n    """""" Invert the order of slices in scan or crop.\n\n    Parameters\n    ----------\n    patient : ndarray\n        one item in batch (patient\'s scan or crop).\n    out_patient : ndarray\n        one item\'s array after inversion of z slixes.\n    res : ndarray\n        `skyscraper` of all  data, see _init_rebuid.\n\n    Returns\n    -------\n    tuple\n        (res, out_patient.shape), `skyscraper` and shape of flipped item.\n    """"""\n    out_patient[:, :, :] = patient[::-1, :, :]\n    return res, out_patient.shape\n'"
radio/preprocessing/histo.py,0,"b'"""""" Auxiliary functions for nodules generation """"""\n\nimport numpy as np\n\n\ndef cart_triples(*arrs):\n    """""" Get array of cartesian triples from three arrays.\n\n    The order is triples is lexicographic.\n\n    Parameters\n    ----------\n    arrs : tuple, list or ndarray\n        Any sequence of 3d ndarrays.\n\n    Returns\n    -------\n    ndarray\n        2d-array of triples (array1_item_n,array2_item_n,array3_item_n)\n    """"""\n    res = np.transpose(np.stack(np.meshgrid(*arrs)), axes=(2, 1, 3, 0))\n    return res.reshape(-1, 3)\n\n\ndef sample_histo3d(histo, size):\n    """""" Create a sample of size=size from distribution represented by 3d-histogram\n\n    Parameters\n    ----------\n    histo : tuple\n        (bins, edges) of np.histogram(). `bins` is a 3d-array, number of points in a specific cube.\n        `edges` is a list of 3 arrays of len = (nbins_in_dimension + 1),\n        represents bounds of bins\' boxes.\n    size : int\n        length of sample to be generated\n\n    Returns\n    -------\n    ndarray\n        3d-array of shape = (size, 3), contains samples from histo-distribution\n    """"""\n    # infer probabilities of bins, sample number of bins according to these probs\n    probs = (histo[0] / np.sum(histo[0])).reshape(-1)\n    bin_nums = np.random.choice(np.arange(histo[0].size), p=probs, size=size)\n\n    # lower and upper bounds of boxes\n    l_all = cart_triples(histo[1][0][:-1], histo[1][1][:-1], histo[1][2][:-1])\n    h_all = cart_triples(histo[1][0][1:], histo[1][1][1:], histo[1][2][1:])\n\n    # uniformly generate samples from selected boxes\n    l, h = l_all[bin_nums], h_all[bin_nums]\n    return np.random.uniform(low=l, high=h)\n\n\ndef sample_ellipsoid_region(center, axes, mult_range, size):\n    """""" Create a sample from `almost` uniform distribution with support given by a peel of a 3d-ellispoid.\n\n    Parameters\n    ----------\n    center : tuple, list or ndarray\n        center of the ellipsoid to be used for sampling.\n    axes : tuple, list or ndarray\n        three axes of the ellipsoid.\n    mult_range : tuple, list\n        range that defines the peel. E.g., mult_range = (1.0, 1.2).\n        Then the peel is defined as a region, bounded from inside and outside by surfaces of two ellipsoids.\n        The interior one has axes = 1.0 * axes, while the exterior one has axes = 1.2 * axes.\n    size : int\n        len of sample to be generated.\n\n    Returns\n    -------\n    ndarray\n        3d-array of shape = (size, 3) containing generated sample.\n    """"""\n    # generate uniform sample of polar and azimuthal angles\n    shifted_polar = np.random.uniform(low=-np.pi / 2, high=np.pi / 2, size=size)\n    azimuthal = np.random.uniform(low=-np.pi, high=np.pi, size=size)\n\n    # generate random multiplier and apply it to axes\n    sample = np.asarray(axes).reshape(1, 3) * np.random.uniform(low=mult_range[0], high=mult_range[1], size=(size, 1))\n\n    # calculate sample of points using generated sample of axes and spherical angle coords\n    sample[:, 0:2] *= np.cos(shifted_polar.reshape(size, 1))\n    sample[:, 0] *= np.cos(azimuthal)\n    sample[:, 1] *= np.sin(azimuthal)\n    sample[:, 2] *= np.sin(shifted_polar)\n\n    # apply the shift to center\n    sample += np.asarray(center)\n\n    return sample\n'"
radio/preprocessing/mask.py,0,"b'"""""" Auxiliary functions for mask-creation """"""\n\nimport numpy as np\nfrom numba import njit\n\n\n@njit(nogil=True)\ndef create_mask_reg_jit(masks, start, end):\n    """""" Jit-decorated function for fast computation of masks by regression data.\n\n    This function is usually called inside create_mask_reg function.\n    """"""\n    num_items = start.shape[0]\n    for i in range(num_items):\n        masks[i,\n              start[i, 0]: end[i, 0],\n              start[i, 1]: end[i, 1],\n              start[i, 2]: end[i, 2]] = 1.\n    return masks\n\n\ndef create_mask_reg(centers, sizes, probs, crop_shape, threshold):\n    """""" Create mask by data contained in predictions of regression model. """"""\n    n_items = centers.shape[0]\n    masks_array = np.zeros(shape=(n_items, *crop_shape), dtype=np.float)\n    _crop_shape = np.asarray(crop_shape)\n\n    start_pixels = np.rint(np.clip(centers - sizes / 2, 0, 1) * _crop_shape).astype(np.int)\n    end_pixels = np.rint(np.clip(centers + sizes / 2, 0, 1) * _crop_shape).astype(np.int)\n    positions = np.array([p > threshold for p in probs])\n\n    masks_array[positions, ...] = create_mask_reg_jit(masks_array[positions, ...],\n                                                      start_pixels[positions, ...],\n                                                      end_pixels[positions, ...])\n    return masks_array\n\n\n@njit(nogil=True)\ndef insert_cropped(where, what, origin):\n    """""" Insert `what` into `where` starting from `origin`\n\n    Parameters\n    ----------\n    where : ndarray\n        3d-array, in which to insert new data.\n    what : ndarray\n        3d-array, which is inserted.\n    origin : ndarray\n        starting positions of insertion along (z,y,x).\n\n    Returns\n    -------\n    None\n        changes `where` array.\n\n    Notes\n    -----\n    What-array is cropped if origin<0 or what-array\n    is too large to be put in where-array.\n\n    Examples\n    --------\n        where = np.zeros(shape=(3, 3, 3), dtype=\'int\')\n        what = np.ones(shape=(2, 2, 2), dtype=\'int\')\n        origin = np.asarray([2, 2, 2])\n\n        # after execution\n        insert_cropped(where, what, origin)\n        # where[2, 2, 2] = 1, other elems = 0\n    """"""\n    # shapes to arrays for convenience\n    what_shape = np.array(what.shape)\n    where_shape = np.array(where.shape)\n\n    # check if there is anything to insert\n    if np.any(what_shape + origin <= 0) or np.any(origin >= where_shape):\n        return\n\n    # define crop boundaries\n    st_what = -np.minimum(np.zeros_like(origin), origin)\n    end_what = np.minimum(where_shape - origin, what_shape)\n\n    st_where = np.maximum(origin, np.zeros_like(origin))\n    end_where = np.minimum(origin + what_shape, where_shape)\n\n    # perform insert\n    where[st_where[0]: end_where[0],\n          st_where[1]: end_where[1],\n          st_where[2]: end_where[2]] = what[st_what[0]: end_what[0],\n                                            st_what[1]: end_what[1],\n                                            st_what[2]: end_what[2]]\n\n\n@njit(nogil=True)\ndef make_rect_mask_numba(batch_mask, start, end, nodules_start, nodules_size):\n    """""" Make mask using information about nodules location and sizes.\n\n    Takes batch_masks already filled with zeros,\n    `img` and `img` positions of coresponding patient\'s data array in batch_mask,\n\n    Parameters\n    ----------\n    batch_mask : ndarray\n        `masks` from batch, just initialised (filled with zeroes).\n    start : ndarray\n        for each nodule, start position of patient in `skyscraper` is given\n        by (nodule_index, z_start, y_start, x_start)\n    end : ndarray\n        for each nodule, end position of patient in `skyscraper` is given\n        by (nodule_index, z_start, y_start, x_start)\n    nodules_start : ndarray(4,)\n        array, first dim is nodule index, others (z,y,x)\n        are start coordinates of nodules\n        (smallest voxel with nodule).\n    nodules_size : tuple, list or ndarray\n        (z,y,x) shape of nodule\n\n    """"""\n    for i in range(nodules_start.shape[0]):\n        nodule_size = nodules_size[i, :]\n\n        nodule = np.ones((int(nodule_size[0]),\n                          int(nodule_size[1]),\n                          int(nodule_size[2])))\n\n        patient_mask = batch_mask[start[i, 0]: end[i, 0],\n                                  start[i, 1]: end[i, 1],\n                                  start[i, 2]: end[i, 2]]\n        insert_cropped(patient_mask, nodule, nodules_start[i, :])\n\n@njit(nogil=True)\ndef make_ellipse_mask_numba(batch_mask, start, end, centers, radiuses):\n    """""" Make mask with ellipses using information about nodules location and sizes.\n\n    Takes batch_masks already filled with zeros,\n    `img` and `img` positions of coresponding patient\'s data array in batch_mask,\n\n    Parameters\n    ----------\n    batch_mask : ndarray\n        `masks` from batch, just initialised (filled with zeroes).\n    start : ndarray\n        for each nodule, start position of patient in `skyscraper` is given\n        by (nodule_index, z_start, y_start, x_start)\n    end : ndarray\n        for each nodule, end position of patient in `skyscraper` is given\n        by (nodule_index, z_start, y_start, x_start)\n    centers : ndarray(4,)\n        array, first dim is nodule index, others (z,y,x)\n        are nodule centers\n    radiuses : tuple, list or ndarray\n        radiuses of nodules\n\n    """"""\n    for i in range(len(centers)): # pylint: disable=consider-using-enumerate\n        center = centers[i]\n        radius = radiuses[i]\n\n        begin_x = np.maximum(0, center[0]-radius[0])\n        begin_y = np.maximum(0, center[1]-radius[1])\n        begin_z = np.maximum(0, center[2]-radius[2])\n\n        end_x = np.minimum(end[i][0]-start[i][0], center[0]+radius[0]+1)\n        end_y = np.minimum(end[i][1]-start[i][1], center[1]+radius[1]+1)\n        end_z = np.minimum(end[i][2]-start[i][2], center[2]+radius[2]+1)\n\n        for x in range(begin_x, end_x):\n            for y in range(begin_y, end_y):\n                for z in range(begin_z, end_z):\n                    if (((x - center[0])/radius[0]) ** 2 +\n                            ((y - center[1])/radius[1]) ** 2 + ((z - center[2])/radius[2]) ** 2 < 1):\n                        batch_mask[x+start[i][0], y+start[i][1], z+start[i][2]] = 1\n'"
radio/preprocessing/mip.py,0,"b'# pylint: disable=invalid-name\n# pylint: disable=missing-docstring\n"""""" Numba-rized functions for XIP intensity projection (maximum, minimum, average) calculation """"""\n\nimport math\nimport numpy as np\nfrom numba import jit\n\n\nPROJECTIONS = {\n    \'axial\': [0, 1, 2],\n    \'coronal\': [1, 0, 2],\n    \'sagital\': [2, 0, 1]\n}\n\n\nREVERSE_PROJECTIONS = {\n    \'axial\': [0, 1, 2],\n    \'coronal\': [1, 0, 2],\n    \'sagital\': [1, 2, 0]\n}\n\n\nMODES = {\n    \'max\': 0,\n    \'min\': 1,\n    \'mean\': 2,\n    \'median\': 3\n}\n\n\n@jit(nogil=True, nopython=True)\ndef maximum_filter1d(data, out):\n    """""" Compute maximum intensity projection along zero-axis.\n\n    Parameters\n    ----------\n    data : ndarray(l, m, n)\n        input 3d array for for computing xip operation.\n    out : ndarray(m, n)\n        output 2d array used to store results of xip operation.\n    """"""\n    for i in range(data.shape[1]):\n        for j in range(data.shape[2]):\n            out[i, j] = np.max(data[:, i, j])\n\n\n@jit(nogil=True, nopython=True)\ndef minimum_filter1d(data, out):\n    """""" Compute minimum intensity projection along zero-axis.\n\n    Parameters\n    ----------\n    data : ndarray(l, m, n)\n        input 3d array for for computing xip operation.\n    out : ndarray(m, n)\n        output 2d array used to store results of xip operation.\n    """"""\n    for i in range(data.shape[1]):\n        for j in range(data.shape[2]):\n            out[i, j] = np.min(data[:, i, j])\n\n\n@jit(nogil=True, nopython=True)\ndef average_filter1d(data, out):\n    """""" Compute average intensity projection along zero-axis.\n\n    Parameters\n    ----------\n    data : ndarray(l, m, n)\n        input 3d array for for computing xip operation.\n    out : ndarray(m, n)\n        output 2d array used to store results of xip operation.\n    """"""\n    for i in range(data.shape[1]):\n        for j in range(data.shape[2]):\n            out[i, j] = np.mean(data[:, i, j])\n\n\n@jit(nogil=True, nopython=True)\ndef median_filter1d(data, out):\n    """""" Compute median intensity projection along zero-axis.\n\n    Parameters\n    ----------\n    data : ndarray(l, m, n)\n        input 3d array for for computing xip operation.\n    out : ndarray(m, n)\n        output 2d array used to store results of xip operation.\n    """"""\n    for i in range(data.shape[1]):\n        for j in range(data.shape[2]):\n            sorted_data = np.sort(data[:, i, j])\n            out[i, j] = sorted_data[math.ceil(data.shape[0] / 2)]\n\n\n@jit(nogil=True, nopython=True)\ndef numba_xip(image, depth, mode, step, start=0):\n    """""" Apply xip operation to scan of one patient.\n\n    Parameters\n    ----------\n    data : ndarray\n        3d array, patient scan or its crop.\n    depth : int\n        number of neighborhood points along zero axis for xip kernel function.\n    mode : int\n        one of following values: 0, 1, 2, 3, that correspond to\n        \'maximum\', \'minimum\', \'mean\' and \'median\' projections.\n    stride : int\n        stride-step along zero axis.\n    start : int\n        an initial slice to start from\n\n    Returns\n    -------\n    ndarray(m, k, l)\n        image after xip operation transform.\n    """"""\n    size = (image.shape[0] - depth - start) // step + 1\n    out_data = np.empty(shape=(size,) + image.shape[1:], dtype=image.dtype)\n    for i in range(size):\n        ix = i * step + start\n        if mode == 0:\n            maximum_filter1d(image[ix: ix + depth, ...], out_data[i, ...])\n        elif mode == 1:\n            minimum_filter1d(image[ix: ix + depth, ...], out_data[i, ...])\n        elif mode == 2:\n            average_filter1d(image[ix: ix + depth, ...], out_data[i, ...])\n        elif mode == 3:\n            median_filter1d(image[ix: ix + depth, ...], out_data[i, ...])\n    return out_data\n\n\ndef make_xip_numba(image, depth, stride=1, mode=\'max\', projection=\'axial\', padding=\'reflect\'):\n    """""" Compute intensity projection (maximum, minimum, mean or median) on input 3d image.\n\n    Popular radiological transformation: max, min, mean or median applyied along an axis.\n    Notice that axis is chosen according to projection argument.\n\n    Parameters\n    ----------\n    image : ndarray(k,l,m)\n        input 3D image corresponding to CT-scan or its crop\n    stride : int\n        stride-step along axis, to apply the func.\n    depth : int\n        depth of slices (aka `kernel`) along axe made on each step for computing.\n    mode : str\n        Possible values are \'max\', \'min\', \'mean\' or \'median\'.\n    projection : str\n        Possible values: \'axial\', \'coronal\', \'sagital\'.\n        In case of \'coronal\' and \'sagital\' projections tensor\n        will be transposed from [z,y,x] to [x,z,y] and [y,z,x].\n\n    Returns\n    -------\n    ndarray\n        resulting ndarray after kernel function is applied.\n\n    """"""\n    padding_lower, padding_upper = math.floor(depth / 2), math.floor(depth / 2)\n\n    extra_padding = (image.shape[0] - padding_lower - padding_upper) % stride\n\n    padding_lower += math.floor(extra_padding / 2)\n    padding_upper += math.floor(extra_padding / 2)\n\n    image_tr = image.transpose(PROJECTIONS[projection])\n    image_tr = np.pad(image_tr, [(padding_lower, padding_upper),\n                                 (0, 0), (0, 0)], mode=padding)\n\n    result = numba_xip(image_tr, step=stride, depth=depth, mode=MODES[mode])\n    return result.transpose(REVERSE_PROJECTIONS[projection])\n\n@jit(nogil=True, nopython=True)\ndef unfold_xip(xip, shape, depth, stride, start, channels, squeezed=True):\n    """""" Unfold xip into a 3d-image.\n    """"""\n    # tile if needed\n    channels = channels if squeezed else xip.shape[-1]\n    xip_tiled = np.zeros(shape=xip.shape[:3] + (channels, ), dtype=np.float64)\n    for i in range(channels):\n        if squeezed:\n            xip_tiled[..., i] = xip[..., 0]\n        else:\n            xip_tiled[..., i] = xip[..., i]\n\n    shape = shape.astype(np.int64)\n    image = np.zeros(shape=(shape[0], shape[1], shape[2]), dtype=np.float64)\n    ctr = 0\n    for i in range(xip.shape[0]):\n        for j in range(channels):\n            image[start + ctr * stride:start + ctr * stride + depth, ...] += xip_tiled[i, ..., j]\n            ctr += 1\n\n    return image\n'"
radio/preprocessing/patches.py,0,"b'"""""" Auxiliary jit-decorated functions for splitting/assembling arrays into/from patches """"""\n\nimport numpy as np\nfrom numba import njit, prange\n\n@njit(parallel=True)\ndef get_patches_numba(images, shape, stride, out):\n    """""" Get all patches from array of padded 3D scans, put them into out.\n\n    Parameters\n    ----------\n    images : ndarray\n        4darray, array of 3d-scans.\n        assumes scans are already padded.\n    shape : ndarray\n        3D array with shape of patch (z,y,x).\n    stride : ndarray\n        3D array with strides of a patch along (z,y,x).\n        (if not equal to patch_shape, patches will overlap).\n    out : ndarray\n        resulting 5d-array, where all patches are put. The first dimension enumerates scans,\n        while the second one enumerates patches.\n    """"""\n\n    # for convenience put scan-shape in ndarray\n    image_shape = np.zeros(3)\n    image_shape[:] = images.shape[1:]\n\n    # compute number of patches along all axes\n    num_sections = (image_shape - shape) // stride + 1\n\n    # iterate over patches, put them into out\n    for it in prange(images.shape[0]):                                     # pylint: disable=not-an-iterable\n        ctr = 0\n        for ix in range(int(num_sections[0])):\n            for iy in range(int(num_sections[1])):\n                for iz in range(int(num_sections[2])):\n                    inds = np.array([ix, iy, iz])\n                    lx, ly, lz = inds * stride\n                    ux, uy, uz = inds * stride + shape\n                    out[it, ctr, :, :, :] = images[it, lx:ux, ly:uy, lz:uz]\n                    ctr += 1\n\n@njit(parallel=True)\ndef assemble_patches(patches, stride, out):\n    """""" Assemble patches into a set of 3d ct-scans with shape scan_shape,\n    put the scans into out.\n\n    Parameters\n    ----------\n    patches : ndarray\n        5d array of patches. First dim enumerates scans, while the second\n        enumerates patches; other dims are spatial with order (z,y,x).\n    stride : ndarray\n        stride to extract patches in (z,y,x) dims.\n    out : ndarray\n        4d-array, where assembled scans are put. First dim enumerates\n        scans. Should be filled with zeroes before calling function.\n\n    Notes\n    -----\n    `out.shape`, `stride`, `patches.shape` are used to infer\n    the number of sections for each dimension.\n    We assume that the number of patches = len(patches)\n    corresponds to num_sections.\n    Overlapping patches are allowed (stride != patch.shape).\n    In this case pixel values are averaged across overlapping patches\n    We assume that integer number of patches can be put into\n    out using stride.\n\n    """"""\n    scan_shape = np.zeros(3)\n    scan_shape[:] = out.shape[1:]\n\n    # cast patch.shape to ndarray\n    patch_shape = np.zeros(3, dtype=np.int64)\n    patch_shape[:] = patches.shape[2:]\n\n    # compute the number of sections\n    num_sections = (scan_shape - patch_shape) // stride + 1\n\n    # iterate over scans and patches, put them into corresponding place in out\n    # increment pixel weight if it belongs to a patch\n    weights_inv = np.zeros_like(out)\n    for it in prange(out.shape[0]):                                     # pylint: disable=not-an-iterable\n        ctr = 0\n        for ix in range(int(num_sections[0])):\n            for iy in range(int(num_sections[1])):\n                for iz in range(int(num_sections[2])):\n                    inds = np.array([ix, iy, iz])\n                    lx, ly, lz = inds * stride\n                    ux, uy, uz = inds * stride + patch_shape\n                    out[it, lx:ux, ly:uy, lz:uz] += patches[it, ctr, :, :, :]\n                    weights_inv[it, lx:ux, ly:uy, lz:uz] += 1.0\n                    ctr += 1\n\n        # weight assembled image\n        out[it, ...] /= weights_inv[it]\n\ndef calc_padding_size(img_shape, patch_shape, stride):\n    """""" Calculate padding width to add to 3d-scan\n        for fitting integer number of patches.\n\n    Parameters\n    ----------\n    img_shape : ndarray\n        shape of 3d-scan along (z,y,x)\n    patch_shape : ndarray\n        shape of patch along (z,y,x)\n    stride : ndarray\n        stride to slides over scan, in (z,y,x) dims.\n\n    Returns\n    -------\n    list or None\n        list of tuples with padding sizes\n        Pad widths in four dims; the first dim enumerates patients,\n        others are spatial axes (z,y,x)\n        if no padding is needed, return None\n    """"""\n    overshoot = (img_shape - patch_shape + stride) % stride\n\n    pad_delta = np.zeros(3)\n    for i in range(len(pad_delta)):                                        # pylint: disable=consider-using-enumerate\n        pad_delta[i] = 0 if overshoot[i] == 0 else stride[i] - overshoot[i]\n\n    # calculate and return the padding if not zero\n    if np.any(pad_delta > 0):\n        before_pad = (pad_delta // 2).astype(\'int\')\n        after_pad = (pad_delta - before_pad).astype(\'int\')\n        pad_width = [(0, 0)] + [(x, y) for x, y in zip(before_pad, after_pad)]\n        return pad_width\n    else:\n        return None\n'"
radio/preprocessing/resize.py,0,"b'""""""\nModule with auxillary\n    jit-compiled functions\n    for resize of\n    CT scans\n""""""\n\nfrom numba import jit\nimport scipy.ndimage\nfrom PIL import Image\nimport numpy as np\n\n\n@jit(nogil=True)\ndef resize_scipy(patient, out_patient, res, order=3, factor=None, padding=\'edge\'):\n    """""" Resize 3d scan and put it into out_patient.\n\n    Resize engine is scipy.ndimage.interpolation.zoom.\n    If factor is not supplied, infer resize factor from out_patient.shape.\n    otherwise, use factor for resize and then crop/pad resized array to out_patient.shape.\n\n    Parameters\n    ----------\n    patient : ndarray\n        3D array\n    out_patient : ndarray\n        resulting array\n    res : ndarray\n        resulting `skyscraper` for the whole batch.\n        used later by `_post`-func in _inbatch_parallel\n    order : int\n        order of interpolation\n    factor : tuple or None\n        resize factor along (z,y,x) in int ir float for interpolation.\n        If not None, can yield array of shape != out_patient.shape,\n        then crop/pad is used\n    padding : str\n        mode of padding, any mode of np.pad()\n\n    Returns\n    -------\n    tuple\n        (res, out_patient.shape), resulting `skyscraper` and shape of\n        resized scan inside this `scyscraper`.\n\n    Notes\n    -----\n    Shape of resulting array has to be inferred\n    from out_patient\n    """"""\n    # infer shape of resulting array\n    shape = out_patient.shape\n\n    # define resize factor, perform resizing and put the result into out_patient\n    if factor is None:\n        factor = np.array(out_patient.shape) / np.array(patient.shape)\n        out_patient[:, :, :] = scipy.ndimage.interpolation.zoom(patient, factor,\n                                                                order=order)\n    else:\n        out_patient[:, :, :] = to_shape((scipy.ndimage.interpolation.\n                                         zoom(patient, factor, order=order)),\n                                        shape=shape, padding=padding)\n\n    # return out-array for the whole batch\n    # and shape of out_patient\n    return res, out_patient.shape\n\n\n@jit(nogil=True)\ndef resize_pil(input_array, output_array, res, axes_pairs=None, shape_resize=None,\n               resample=None, padding=\'edge\'):\n    """""" Resize 3D scan.\n\n    Uses _seq_resize over a pair of axes for applying many 2d-resizes,\n    then averages over different pairs for obtaining more precise results.\n\n    Parameters\n    ----------\n    input_array : ndarray\n        array to be resized.\n    ouput_array : ndarray\n        array, where the result should be put.\n    res : ndarray\n        resulting `skyscraper` for the whole batch.\n        used later by `_post`-func in _inbatch_parallel\n    axes_pairs : tuple, list of tuples or None\n        pairs of axes for 2d resizes, then averaging is performed,\n        e.g., ((0,1),(1,2),(0,2))\n        if None, defaults to ((0, 1), (1, 2))\n    shape_resize : tuple, list, ndarray or None\n        shape of array after resize.\n        If None, infer shape from `ouput_array.shape`.\n    resample : str or None\n        type of PIL resize\'s resampling method, e.g.\n        `BILINEAR`, `BICUBIC`,`LANCZOS` or `NEAREST`.\n        If None, `BILINEAR` is used.\n    padding : str\n        mode of padding, any mode of np.pad()\n\n    Returns\n    -------\n    tuple\n        (res, out_patient.shape), resulting `skyscraper` and shape of\n        resized scan inside this `scyscraper`.\n    """"""\n    # if resample not given, set to bilinear\n    resample = Image.BILINEAR if resample is None else resample\n\n    # if axes_pairs not supplied, set the arg to two default axes pairs\n    axes_pairs = ((0, 1), (1, 2)) if axes_pairs is None else axes_pairs\n\n    # if shape is not supplied, infer it from output_array\n    shape_resize = shape_resize if shape_resize is not None else output_array.shape\n\n    if tuple(shape_resize) == output_array.shape:\n        for axes in axes_pairs:\n            output_array[:, :, :] += _seq_resize(input_array, shape_resize, axes, resample)\n    else:\n        for axes in axes_pairs:\n            output_array[:, :, :] += to_shape(_seq_resize(input_array, shape_resize, axes, resample),\n                                              shape=output_array.shape, padding=padding)\n\n    # normalize result of resize (average over resizes with different pairs of axes)\n    output_array[:, :, :] /= len(axes_pairs)\n\n    # for post-function\n    return res, output_array.shape\n\n\n@jit(nogil=True)\ndef _seq_resize(input_array, shape, axes, resample):\n    """""" Perform 3d-resize based on sequence of 2d-resizes performed on slices.\n\n    Parameters\n    ----------\n    input_array : ndarray\n        3D array\n    shape : tuple, list or ndarray\n        shape of 3d scan after resize, (z,y,x).\n    axes : tuple, list or ndarray\n        axes for slicing. E.g., `shape` = (z, y, x) and axes = (0, 1). We first loop over\n        2d-slices [i, :, :] and reshape input to shape = (input_array.shape[0], y, x).\n        then loop over slices [:, i, :] and reshape the result to shape = (z, y, x).\n    resample : str or None\n        type of PIL resize\'s resampling method, e.g.\n        `BILINEAR`, `BICUBIC`,`LANCZOS` or `NEAREST`.\n        If None, `BILINEAR` is used.\n\n    Returns\n    -------\n    ndarray\n        resized 3D array\n    """"""\n    result = input_array\n\n    # loop over axes\n    for axis in axes:\n        slice_shape = np.delete(shape, axis)\n        result = _slice_and_resize(result, axis, slice_shape, resample)\n\n    return result\n\n\n@jit(nogil=True)\ndef _slice_and_resize(input_array, axis, slice_shape, resample):\n    """""" Slice 3D array along `axis` and resize each slice to `slice_shape`.\n\n    Parameters\n    ----------\n    input_array : ndarray\n        3D array\n    axis : int\n        axis along which slices are taken\n    slice_shape : tuple,list or ndarray\n        (y,x) shape of each slice after resize\n    resample : str or None\n        type of PIL resize\'s resampling method, e.g.\n        `BILINEAR`, `BICUBIC`,`LANCZOS` or `NEAREST`.\n        If None, `BILINEAR` is used.\n\n    Returns\n    -------\n    ndarray\n        3D array in which each slice along chosen axis is resized\n    """"""\n    # init the resulting array\n    result_shape = np.insert(np.array(slice_shape), axis, input_array.shape[axis])\n    result = np.zeros(shape=result_shape)\n\n    # invert slice shape for PIL.resize\n    slice_shape = slice_shape[::-1]\n\n    # loop over the axis given by axis\n    for i in range(result.shape[axis]):\n        slices = np.array([slice(None), slice(None), slice(None)])\n        slices[axis] = i\n        slices = tuple(slices)\n\n        # resize the slice and put the result in result-array\n        result[slices] = np.array(Image.fromarray(input_array[slices]).resize(slice_shape, resample=resample))\n\n    return result\n\n\ndef to_shape(data, shape, padding):\n    """""" Crop or pad 3D array to resize it to `shape`\n\n    Parameters\n    ----------\n    data : ndarray\n        3D array for reshaping\n    shape : tuple, list or ndarray\n        data shape after crop or pad\n    padding : str\n        mode of padding, any of the modes of np.pad()\n\n    Returns\n    -------\n    ndarray\n        cropped and padded data\n    """"""\n    # calculate shapes discrepancy\n    data_shape = np.asarray(data.shape)\n    shape = np.asarray(shape)\n    overshoot = data_shape - shape\n\n    # calclate crop params and perform crop\n    crop_dims = np.maximum(overshoot, 0)\n    crop_first = crop_dims // 2\n    crop_trailing = crop_dims - crop_first\n    slices = [slice(first, dim_shape - trailing)\n              for first, trailing, dim_shape in zip(crop_first, crop_trailing, data_shape)]\n    data = data[slices]\n\n    # calculate padding params and perform padding\n    pad_dims = -np.minimum(overshoot, 0)\n    pad_first = pad_dims // 2\n    pad_trailing = pad_dims - pad_first\n    pad_params = [(first, trailing)\n                  for first, trailing in zip(pad_first, pad_trailing)]\n    data = np.pad(data, pad_width=pad_params, mode=padding)\n\n    # return cropped/padded array\n    return data\n'"
radio/preprocessing/rotate.py,0,"b'"""""" Module with jit-compilated functions for rotation operation of 3D scans. """"""\n\nfrom numba import jit\nimport scipy.ndimage\n\n\n@jit(nogil=True)\ndef rotate_3D(image, angle, axes=(1, 2)):\n    """""" Rotate 3D image in plane specified by two axes.\n\n    Parameters\n    ----------\n    image : ndarray\n        3D scan, (z,y,x).\n    angle : float\n        angle of rotation.\n    axes :  tuple, list or ndarray\n        (int, int), axes that specify rotation plane.\n\n    Returns\n    -------\n    ndarray\n        3D rotated scan\n\n    Notes\n    -----\n    Zero-padding automatically added after rotation.\n    """"""\n    rotated_image = scipy.ndimage.interpolation.rotate(image, angle, axes, reshape=False)\n    image[...] = rotated_image[...]\n'"
radio/preprocessing/segment.py,0,"b'""""""\nModule with auxillary\n    jit-compiled functions\n    for lungs\' segmentation\n    from DICOM-scans\n""""""\n\nimport numpy as np\nfrom numba import jit\nfrom skimage import measure, morphology\n\n\n@jit(nogil=True)\ndef largest_label_volume(image, background=-1):\n    """""" Determine most frequent color that occupies the largest volume\n\n    Parameters\n    ----------\n    image : ndarray\n    background : int or float\n        image background color\n\n    Returns\n    -------\n    int\n        most frequent color value\n    """"""\n    vals, counts = np.unique(image, return_counts=True)\n\n    counts = counts[vals != background]\n    vals = vals[vals != background]\n\n    if len(counts) > 0:\n        return vals[np.argmax(counts)]\n    else:\n        return -999999\n\n\n# segmentation of a patient sliced from skyscraper\n@jit(\'void(double[:,:,:], double[:,:,:], double[:,:,:], int64)\', nogil=True)\ndef calc_lung_mask_numba(patient, out_patient, res, erosion_radius=7):\n    """""" Compute lungs-segmenting mask for a patient\n\n    Parameters\n    ----------\n    patient : ndarray\n        input 3D scan.\n    out_patient : ndarray\n        resulting array with segmented lungs\n    erosion_radius : int\n        radius to use to erod the lungs\' border\n    res : ndarray\n        `skyscraper` where to put the resized patient\n\n    Returns\n    -------\n    tuple\n        (res, out_patient.shape), resulting `skyscraper` and shape of\n        segmented scan inside this `scyscraper`.\n\n    """"""\n\n    # slice the patient out from the skyscraper\n    # we use view for simplification\n    data = patient\n\n    binary_image = np.array(data > -320, dtype=np.int8) + 1\n\n    # 3d connected components\n    labels = measure.label(binary_image)\n\n    bin_shape = binary_image.shape\n\n    # create np.array of unique labels of corner pixels\n    corner_labs = np.zeros(0)\n\n    for z_ind in range(bin_shape[0]):\n        corner_labs = np.append(corner_labs, labels[z_ind, 0, 0])\n        corner_labs = np.append(\n            corner_labs, labels[z_ind, bin_shape[1] - 1, 0])\n        corner_labs = np.append(\n            corner_labs, labels[z_ind, bin_shape[1] - 1, bin_shape[2] - 1])\n        corner_labs = np.append(\n            corner_labs, labels[z_ind, 0, bin_shape[2] - 1])\n\n    bk_labs = np.unique(corner_labs)\n\n    # Fill the air around the person\n    for background_label in bk_labs:\n        binary_image[background_label == labels] = 2\n\n    # Method of filling the lung structures (that is superior to something like\n    # morphological closing)\n    # For every slice we determine the largest solid structure\n\n    # seems like to this point binary image is what it should be\n    # return binary_image\n\n    for i, axial_slice in enumerate(binary_image):\n\n        axial_slice = axial_slice - 1\n\n        # in each axial slice lungs and air are labelled as 0\n        # everything else has label = 1\n\n        # look for and enumerate connected components in axial_slice\n\n        # 2d connected components\n        labeling = measure.label(axial_slice)\n\n        l_max = largest_label_volume(labeling, background=0)\n\n        if l_max is not None:  # This slice contains some lung\n            binary_image[i][labeling != l_max] = 1\n\n    # return binary_image\n    # it\'s all fine here\n\n    binary_image -= 1  # Make the image actual binary\n    binary_image = 1 - binary_image  # Invert it, lungs are now 1\n\n    # Remove other air pockets insided body\n\n    # stil fine\n    # return binary_image\n\n    # again, 3d connected components\n    labels = measure.label(binary_image, background=0)\n    l_max = largest_label_volume(labels, background=0)\n    if l_max is not None:  # There are air pockets\n        binary_image[labels != l_max] = 0\n\n    # slightly erode the mask\n    # to get rid of lungs\' boundaries\n\n    # return binary_image\n\n    selem = morphology.disk(erosion_radius)\n\n    # put the mask into the result\n    for i in range(patient.shape[0]):\n        out_patient[i, :, :] = morphology.binary_erosion(binary_image[i, :, :], selem)\n\n    return res, out_patient.shape\n'"
radio/models/keras/__init__.py,0,"b'"""""" Contains neural network architectures for lung cancer detection implemented in keras. """"""\nfrom .keras_res_nodule_net import KerasResNoduleNet\nfrom .keras_3dunet import Keras3DUNet\nfrom .keras_nodule_vgg import KerasNoduleVGG\nfrom .keras_model import KerasModel\n'"
radio/models/keras/keras_3dunet.py,5,"b'# pylint: disable=too-many-statements\n"""""" Contains Keras3DUNet model class. """"""\n\nfrom functools import wraps\nimport tensorflow as tf\nimport keras\nfrom keras.layers import (Input,\n                          concatenate,\n                          Conv3D,\n                          MaxPooling3D,\n                          UpSampling3D)\nfrom keras.layers.core import Activation\nfrom keras.layers.normalization import BatchNormalization\n\nfrom .keras_model import KerasModel\nfrom .losses import dice_loss\n\n\nclass Keras3DUNet(KerasModel):\n    """""" Model incapsulating 3D U-Net architecture for 3D scans implemented in keras.\n\n    Class extends KerasModel class.\n\n    Contains description of \'bottleneck_block\', \'reduction_block\' and\n    \'upsampling_block\'. Current 3D U-Net architecture is implemented\n    inside _build method using these blocks.\n\n    Architecture is inspired by 3D U-Net (\xc3\x87i\xc3\xa7ek et Al., https://arxiv.org/abs/1606.06650).\n\n    Notes\n    -----\n    Implementation requires the input tensor having shape=(batch_size, 1, 32, 64, 64).\n    """"""\n    def build_config(self):\n        input_shape = self.get(\'input_shape\', self.config, (1, 32, 64, 64))\n        self.config.update({\'input_shape\': input_shape})\n        super().build_config()\n\n    def bottleneck_block(self, inputs, filters, scope, padding=\'same\'):\n        """""" Apply bottleneck block transform to input tensor.\n\n        Parameters\n        ----------\n        inputs : keras tensor\n            input tensor.\n        filters : int\n            number of output filters required by Conv3D operation.\n        scope : str\n            scope name for block, will be used as an argument of tf.variable_scope.\n        padding : str\n            padding mode, can be \'same\' or \'valid\'.\n\n        Returns\n        -------\n        keras tensor\n            output tensor.\n\n        Notes\n        -----\n        `channels_first` dim-ordering is used.\n        """"""\n        with tf.variable_scope(scope):\n            conv1 = Conv3D(filters, (3, 3, 3),\n                           data_format=\'channels_first\',\n                           padding=padding)(inputs)\n            conv1 = BatchNormalization(axis=1, momentum=0.1,\n                                       scale=True)(conv1)\n            conv1 = Activation(\'relu\')(conv1)\n\n            conv2 = Conv3D(filters, (3, 3, 3),\n                           data_format=\'channels_first\',\n                           padding=padding)(conv1)\n            conv2 = BatchNormalization(axis=1, momentum=0.1,\n                                       scale=True)(conv2)\n            conv2 = Activation(\'relu\')(conv2)\n        return conv2\n\n    def reduction_block(self, inputs, filters, scope, pool_size=(2, 2, 2), padding=\'same\'):\n        """""" Apply reduction block transform to input tensor.\n\n        Layer consists of two 3D-convolutional layers with batch normalization\n        before \'relu\' activation and max_pooling3d layer in the end.\n\n        Parameters\n        ----------\n        inputs : keras tensor\n            input tensor.\n        filters : int\n            number of filters in first and second covnolutions.\n        scope : str\n            scope name for block, will be used as an argument of tf.variable_scope.\n        pool_size : tuple(int, int, int)\n            size of pooling kernel along three axis, required by Conv3D operation.\n        padding : str\n            padding mode for convolutions, can be \'same\' or \'valid\'.\n\n        Returns\n        -------\n        keras tensor\n            output tensor.\n\n        Notes\n        -----\n        `channels_first` dim-ordering is used.\n        """"""\n        with tf.variable_scope(scope):\n            conv1 = Conv3D(filters, (3, 3, 3),\n                           data_format=\'channels_first\',\n                           padding=padding)(inputs)\n            conv1 = BatchNormalization(axis=1, momentum=0.1,\n                                       scale=True)(conv1)\n            conv1 = Activation(\'relu\')(conv1)\n\n            conv2 = Conv3D(filters, (3, 3, 3),\n                           data_format=\'channels_first\',\n                           padding=padding)(conv1)\n            conv2 = BatchNormalization(axis=1, momentum=0.1,\n                                       scale=True)(conv2)\n            conv2 = Activation(\'relu\')(conv2)\n\n            max_pool = MaxPooling3D(data_format=\'channels_first\',\n                                    pool_size=pool_size)(conv2)\n        return conv2, max_pool\n\n    def upsampling_block(self, inputs, skip_connect_tensor, filters, scope, padding=\'same\'):\n        """""" Apply upsampling transform to two input tensors.\n\n        First of all, UpSampling3D transform is applied to inputs. Then output\n        tensor of operation is concatenated with skip_connect_tensor. After this\n        two 3D-convolutions with batch normalization before \'relu\' activation\n        are applied.\n\n        Parameters\n        ----------\n        inputs : keras tensor\n            input tensor from previous layer.\n        skip_connect_tensor : keras tensor\n            input tensor from simmiliar layer from reduction branch of 3D U-Net.\n        filters : int\n            number of filters in convolutional layers.\n        scope : str\n            name of scope for block.\n        padding : str\n            padding mode for convolutions, can be \'same\' or \'valid\'.\n\n        Returns\n        -------\n        keras tensor\n            ouput tensor.\n\n        Notes\n        -----\n        `channels_first` dim-ordering is used.\n        """"""\n        with tf.variable_scope(scope):\n            upsample_tensor = UpSampling3D(data_format=""channels_first"",\n                                           size=(2, 2, 2))(inputs)\n            upsample_tensor = concatenate([upsample_tensor, skip_connect_tensor], axis=1)\n\n            conv1 = Conv3D(filters, (3, 3, 3),\n                           data_format=""channels_first"",\n                           padding=""same"")(upsample_tensor)\n            conv1 = BatchNormalization(axis=1, momentum=0.1,\n                                       scale=True)(conv1)\n            conv1 = Activation(\'relu\')(conv1)\n\n            conv2 = Conv3D(filters, (3, 3, 3),\n                           data_format=""channels_first"",\n                           padding=""same"")(conv1)\n            conv2 = BatchNormalization(axis=1, momentum=0.1,\n                                       scale=True)(conv2)\n            conv2 = Activation(\'relu\')(conv2)\n        return conv2\n\n    def _build(self, *args, **kwargs):\n        """""" Build 3D NoduleVnet model implemented in keras. """"""\n        num_targets = self.get(\'num_targets\', self.config)\n        input_shape = self.get(\'input_shape\', self.config)\n\n        inputs = Input(shape=input_shape)\n\n        # Downsampling or reduction layers: ReductionBlock_A, ReductionBlock_B, ReductionBlock_C, ReductionBlock_D\n        # block_A has shape (None, 32, 64, 64, 32), reduct_block_A has shape (None, 16, 32, 32, 32)\n        block_A, reduct_block_A = self.reduction_block(inputs, 32,\n                                                       scope=\'ReductionBlock_A\')\n\n        # block_B has shape (None, 16, 32, 32, 64), reduct_block_B has shape (None, 8, 16, 16, 64)\n        block_B, reduct_block_B = self.reduction_block(reduct_block_A, 64,\n                                                       scope=\'ReductionBlock_B\')\n\n        # block_C has shape (None, 8, 16, 16, 128), reduct_block_C has shape (None, 4, 8, 8, 128)\n        block_C, reduct_block_C = self.reduction_block(reduct_block_B, 128,\n                                                       scope=\'ReductionBlock_C\')\n\n        # block_D has shape (None, 4, 8, 8, 256), reduct_block_D has shape (None, 2, 4, 4, 256)\n        block_D, reduct_block_D = self.reduction_block(reduct_block_C, 256,\n                                                       scope=\'ReductionBlock_D\')\n\n        # Bottleneck layer\n        # bottleneck_block has shape (None, 2, 4, 4, 512)\n        bottleneck_block = self.bottleneck_block(reduct_block_D, 512, \'BottleNeckBlock\')\n\n        # Upsampling Layers: UpsamplingBlock_D, UpsamplingBlock_C, UpsamplingBlock_B, UpsamplingBlock_A\n        # upsample_block_C has shape (None, 4, 8, 8, 256)\n        upsample_block_D = self.upsampling_block(bottleneck_block, block_D,\n                                                 256, scope=\'UpsamplingBlock_D\')\n\n        # upsample_block_C has shape (None, 8, 16, 16, 128)\n        upsample_block_C = self.upsampling_block(upsample_block_D, block_C,\n                                                 128, scope=\'UpsamplingBlock_C\')\n\n        # upsample_block_B has shape (None, 16, 32, 32, 64)\n        upsample_block_B = self.upsampling_block(upsample_block_C, block_B,\n                                                 64, scope=\'UpsamplingBlock_B\')\n\n        # upsample_block_A has shape (None, 32, 64, 64, 32)\n        upsample_block_A = self.upsampling_block(upsample_block_B, block_A,\n                                                 32, scope=\'UpsamplingBlock_A\')\n\n        # Final convolution\n        final_conv = Conv3D(num_targets, (1, 1, 1),\n                            activation=\'sigmoid\',\n                            data_format=""channels_first"",\n                            padding=\'same\')(upsample_block_A)\n\n        return [inputs], [final_conv]\n\n    @wraps(keras.models.Model.compile)\n    def compile(self, optimizer=\'adam\', loss=dice_loss, **kwargs):\n        """""" Compile 3D U-Net model. """"""\n        super().compile(optimizer=optimizer, loss=loss)\n'"
radio/models/keras/keras_model.py,2,"b'# pylint: disable=super-init-not-called\n# pylint: disable=not-context-manager\n"""""" Contains base class for all keras models. """"""\n\nimport functools\nimport numpy as np\nimport tensorflow as tf\nfrom keras.models import Model\n\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout, Activation\nfrom keras.layers import Dense, BatchNormalization\n\nfrom ...batchflow.models import BaseModel        # pylint: disable=no-name-in-module, import-error\n\n\nclass KerasModel(Model, BaseModel):\n    """""" Base class for all keras models.\n\n    Contains `load`, `dump` and `compile` methods which are shared between all\n    keras models. Implements train and predict methods.\n\n    """"""\n    def __init__(self, config=None, *args, **kwargs):\n        """""" Create keras model. """"""\n        BaseModel.__init__(self, config, *args, **kwargs)\n\n    def build_config(self):\n        """""" Build config. """"""\n        input_shape = self.get(\'input_shape\', self.config, (32, 64, 64, 1))\n        num_targets = self.get(\'num_targets\', self.config, 1)\n        dropout_rate = self.get(\'dropout_rate\', self.config, 0.35)\n        units = self.get(\'units\', self.config, (512, 256))\n        if isinstance(units, int):\n            units = (units, )\n        elif units is None:\n            units = ()\n        self.config.update({\'units\': units, \'input_shape\': input_shape,\n                            \'dropout_rate\': dropout_rate,\n                            \'num_targets\': num_targets})\n\n    def build(self, *args, **kwargs):\n        """""" Must return inputs and outputs. """"""\n        self.build_config()\n        input_nodes, output_nodes = self._build()\n        Model.__init__(self, input_nodes, output_nodes)\n        self.compile(loss=self.get(\'loss\', self.config, None),\n                     optimizer=self.get(\'optimizer\', self.config, \'sgd\'))\n\n    def _build(self, *args, **kwargs):\n        """""" Must return inputs and outputs. """"""\n        raise NotImplementedError(""This method must be implemented in ancestor model class"")\n\n    @classmethod\n    def dense_block(cls, inputs, units, activation=\'relu\', dropout=None, scope=\'DenseBlock\'):\n        """""" Dense block for keras models.\n\n        This block consists of flatten operation applied to inputs tensor.\n        Then there is several fully connected layers with same activation,\n        batch normalization and dropout layers. Usually this block is put\n        in the end of the neural network.\n\n        Parameters\n        ----------\n        inputs : keras tensor\n            input tensor.\n        units : tuple(int, ...)\n            tuple with number of units in dense layers followed one by one.\n        dropout : float or None\n            probability of dropout.\n        scope : str\n            scope name for this block, will be used as an argument of tf.variable_scope.\n\n        Returns:\n        keras tensor\n            output tensor.\n        """"""\n        with tf.variable_scope(scope):\n            z = Flatten(name=\'flatten\')(inputs)\n            for u in units:\n                z = Dense(u, name=\'Dense-{}\'.format(u))(z)\n                z = BatchNormalization(axis=-1)(z)\n                z = Activation(activation)(z)\n                if dropout is not None:\n                    z = Dropout(dropout)(z)\n        return z\n\n    def train(self, x=None, y=None, **kwargs):\n        """""" Wrapper for keras.models.Model.train_on_batch.\n\n        Parameters\n        ----------\n        x : ndarray(batch_size, ...)\n            x argument of keras.models.Model.train_on_batch method, input of\n            neural network.\n        y : ndarray(batch_size, ...)\n            y argument of keras.models.Model.predict_on_batch method.\n\n        Returns\n        -------\n        ndarray(batch_size, ...)\n            predictions of keras model.\n\n        Raises\n        ------\n        ValueError if \'x\' or \'y\'  is None.\n        """"""\n        if x is None or y is None:\n            raise ValueError(""Arguments \'x\' and \'y\' must not be None"")\n\n        prediction = np.asarray(self.train_on_batch(x=x, y=y))\n        return prediction\n\n    def predict(self, x=None, **kwargs):\n        """""" Wrapper for keras.models.Model.predict_on_batch.\n\n        Parameters\n        ----------\n        x : ndarray(batch_size, ...)\n            x argument of keras.models.Model.predict_on_batch method, input of\n            neural network.\n\n        Returns\n        -------\n        ndarray(batch_size, ...)\n            predictions of keras model.\n\n        Raises\n        ------\n        ValueError if \'x\' argument is None.\n        """"""\n        if x is not None:\n            return Model.predict_on_batch(self, x=x)\n        else:\n            raise ValueError(""Argument \'x\' must not be None"")\n        return None\n\n    @functools.wraps(Model.load_weights)\n    def load(self, *args, **kwargs):\n        """""" Wrapper for keras.models.Model.load_weights. """"""\n        return Model.load_weights(self, *args, **kwargs)\n\n    @functools.wraps(Model.save_weights)\n    def save(self, *args, **kwargs):\n        """""" Wrapper for keras.models.Model.save_weights. """"""\n        return Model.save_weights(self, *args, **kwargs)\n'"
radio/models/keras/keras_nodule_vgg.py,4,"b'"""""" Contains implementation of VGG16 architecture in keras. """"""\n\nimport tensorflow as tf\nfrom keras.layers import Input\nfrom keras.layers import Conv3D, MaxPooling3D\nfrom keras.layers import Dense, BatchNormalization\n\nfrom .keras_model import KerasModel\n\n\nclass KerasNoduleVGG(KerasModel):\n    """""" KerasNoduleVGG model for 3D scans implemented in keras.\n\n    Class extends KerasModel class.\n\n    Contains description of three types of blocks:\n    \'reduction_block_I\', \'reduction_block_II\' and \'classification_block\'.\n    NoduleVGG architecture is implemented inside _build method using these blocks.\n\n    Attributes\n    ----------\n    config : dict\n        config dictionary from batchflow pipeline\n        see configuring model section of batchflow module\n        https://analysiscenter.github.io/batchflow/intro/models.html.\n    name : str\n        name of the model.\n    units : tuple(int, int) or int or None\n        number of units in final dense layers before tensor with\n        predicitons. default: (512, 256).\n    num_targets : int\n        size of tensor with predicitons. default: 1.\n    dropout_rate : float\n        probability of dropout. default: 0.35.\n\n    Notes\n    -----\n    Implementation requires the input tensor having shape=(batch_size, 32, 64, 64, 1).\n    """"""\n    def reduction_block_I(self, inputs, filters, scope, padding=\'same\'):\n        """""" Reduction block of type I for NoduleVGG architecture.\n\n        Applyes 3D-convolution with kernel size (3, 3, 3), (1, 1, 1) strides\n        and \'relu\' activation, after performs batch noramlization, then\n        again 3D-convolution with kernel size (3, 3, 3),\n        strides (1, 1, 1) and \'relu\' activation,  that batch normalization;\n        After all applyes 3D maxpooling operation with strides (2, 2, 2)\n        and pooling size (2, 2, 2).\n\n        Parameters\n        ----------\n        inputs : keras tensor\n            input tensor.\n        filters : int\n            number of filters in 3D-convolutional layers.\n        scope : str\n            scope name for block, will be used as an argument of tf.variable_scope.\n        padding : str\n            padding mode can be \'same\' or \'valid\'.\n\n        Returns\n        -------\n        keras tensor\n            output tensor.\n        """"""\n        with tf.variable_scope(scope):\n            conv1 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n                           activation=\'relu\', padding=padding)(inputs)\n\n            conv1 = BatchNormalization(axis=4)(conv1)\n\n            conv2 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n                           activation=\'relu\', padding=padding)(conv1)\n            conv2 = BatchNormalization(axis=4)(conv2)\n\n            max_pool = MaxPooling3D((2, 2, 2), strides=(2, 2, 2))(conv2)\n        return max_pool\n\n    def reduction_block_II(self, inputs, filters, scope, padding=\'same\'):\n        """""" Reduction block of type II for NoduleVGG architecture.\n\n        Applyes 3D-convolution with kernel size (3, 3, 3), strides (1, 1, 1)\n        and \'relu\' activation, after that preform batch noramlization,\n        repeates combo three times;\n        Finally, adds 3D maxpooling layer with\n        strides (2, 2, 2) and pooling size (2, 2, 2).\n\n        Parameters\n        ----------\n        inputs : keras tensor\n            input tensor.\n        filters : int\n            number of filters in 3D-convolutional layers.\n        scope : str\n            scope name for block, will be used as an argument of tf.variable_scope.\n        padding : str\n            padding mode can be \'same\' or \'valid\'.\n\n        Returns\n        -------\n        keras tensor\n            output tensor.\n        """"""\n        with tf.variable_scope(scope):\n            conv1 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n                           activation=\'relu\', padding=padding)(inputs)\n            conv1 = BatchNormalization(axis=4)(conv1)\n\n            conv2 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n                           activation=\'relu\', padding=padding)(conv1)\n            conv2 = BatchNormalization(axis=4)(conv2)\n\n            conv3 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n                           activation=\'relu\', padding=padding)(conv2)\n            conv3 = BatchNormalization(axis=4)(conv3)\n\n            max_pool = MaxPooling3D((2, 2, 2), strides=(2, 2, 2))(conv3)\n        return max_pool\n\n    def _build(self, *args, **kwargs):\n        """""" Build NoduleVGG model implemented in keras.\n\n        Returns\n        -------\n        tuple([*input_nodes], [*output_nodes])\n            list of input nodes and list of output nodes.\n        """"""\n        num_targets = self.get(\'num_targets\', self.config)\n        dropout_rate = self.get(\'dropout_rate\', self.config)\n        input_shape = self.get(\'input_shape\', self.config)\n\n        inputs = Input(shape=input_shape)\n        block_A = self.reduction_block_I(inputs, 32, scope=\'Block_A\')\n        block_B = self.reduction_block_I(block_A, 64, scope=\'Block_B\')\n        block_C = self.reduction_block_II(block_B, 128, scope=\'Block_C\')\n        block_D = self.reduction_block_II(block_C, 256, scope=\'Block_D\')\n        block_E = self.reduction_block_II(block_D, 256, scope=\'Block_E\')\n\n        z = self.dense_block(block_E, units=self.get(\'units\', self.config),\n                             dropout=dropout_rate, scope=\'DenseBlock-I\')\n\n        output_tensor = Dense(num_targets, activation=\'sigmoid\', name=\'output\')(z)\n\n        return [inputs], [output_tensor]\n'"
radio/models/keras/keras_res_nodule_net.py,0,"b'"""""" Contains implementation of ResNetNoduleNet via keras. """"""\n\nfrom keras import layers\n\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Conv3D\nfrom keras.layers import Activation\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\n\nfrom .keras_model import KerasModel\n\n\nclass KerasResNoduleNet(KerasModel):\n    """""" ResNoduleNet model for 3D scans implemented in keras.\n\n    Class extends KerasModel class.\n\n    Contains description of three types of blocks:\n    \'identity_block\' and \'conv_block\'. ResNet architercture is implemented inside\n    _build method using these blocks.\n    Model is inspired by ResNet (Kaiming He et Al., https://arxiv.org/abs/1512.03385/).\n\n    Attributes\n    ----------\n    config : dict\n        config dictionary from batchflow pipeline\n        see configuring model section of batchflow module:\n        https://analysiscenter.github.io/batchflow/intro/models.html.\n    name : str\n        name of the model.\n    units : tuple(int, int) or int or None\n        number of units in final dense layers before tensor with\n        predicitons. default: (512, 256).\n    num_targets : int\n        size of tensor with predicitons. default: 1.\n    dropout_rate : float\n        probability of dropout. default: 0.35.\n\n    Notes\n    -----\n    Implementation requires the input tensor having shape=(batch_size, 32, 64, 64, 1).\n    """"""\n    def identity_block(self, inputs, kernel_size, filters, stage, block):\n        """""" The identity block is the block that has no conv layer at shortcut.\n\n        First of all, 3D-convolution with (1, 1, 1) kernel size, batch normalization\n        and relu activation is applied. Then the result flows into\n        3D-convolution with (3, 3, 3) kernel size, batch normalization and\n        relu activation. Finally, the result of previous convolution goes\n        into 3D-convolution with (1, 1, 1) kernel size, batch normalization\n        without activation and its output is summed with the input tensor\n        and `relu` activation is applied.\n        Argument `filters` should be tuple(int, int, int) and specifies\n        number of filters in first, second and third convolution correspondingly.\n        Number of filters in third convolution must be the same as in the input\n        tensor.\n\n        Parameters\n        ----------\n        inputs : keras tensor\n            input tensor.\n        kernel_size : tuple(int, int, int)\n            size of the kernel along three dimensions for middle convolution operation in block.\n        filters : tuple(int, int, int)\n            number of filters in first, second and third 3D-convolution operations.\n        stage : int\n            number of stage, on par with block argument used to derive names of inner layers.\n        block : str\n            block prefix, on par with stage argument used to derive names of inner layers.\n\n        Returns\n        -------\n        keras tensor\n            output tensor.\n        """"""\n        filters1, filters2, filters3 = filters\n\n        conv_name_base = \'res\' + str(stage) + block + \'_branch\'\n        bn_name_base = \'bn\' + str(stage) + block + \'_branch\'\n\n        x = Conv3D(filters1, (1, 1, 1), name=conv_name_base + \'2a\',\n                   use_bias=False, kernel_initializer=\'glorot_normal\')(inputs)\n        x = BatchNormalization(axis=4, name=bn_name_base + \'2a\')(x)\n        x = Activation(\'relu\')(x)\n\n        x = Conv3D(filters2, kernel_size,\n                   padding=\'same\',\n                   name=conv_name_base + \'2b\',\n                   use_bias=False,\n                   kernel_initializer=\'glorot_normal\')(x)\n        x = BatchNormalization(axis=4, name=bn_name_base + \'2b\')(x)\n        x = Activation(\'relu\')(x)\n\n        x = Conv3D(filters3, (1, 1, 1),\n                   name=conv_name_base + \'2c\',\n                   use_bias=False,\n                   kernel_initializer=\'glorot_normal\')(x)\n        x = BatchNormalization(axis=4, name=bn_name_base + \'2c\')(x)\n\n        x = layers.add([x, inputs])\n        x = Activation(\'relu\')(x)\n        return x\n\n    def conv_block(self, inputs, kernel_size, filters, stage, block, strides=(2, 2, 2)):\n        """""" Convolutional block that has a conv layer at shortcut.\n\n        3D-convolution with (1, 1, 1) kernel size, (2, 2, 2)-strides,\n        batch normalization and `relu` activation are applied. Then resulting tensor\n        flows into 3D-convolution with (3, 3, 3) kernel size, batch normalization\n        and `relu` activation. Finally, the result of previous convolution goes\n        into 3D-convolution with (1, 1, 1) kernel size, batch normalization\n        without activation and its output is summed with the result\n        of 3D-convolution with kernel_size=(1, 1, 1), strides=(2, 2, 2) and\n        batch normalization of inputs. After that `relu` activation\n        is applied to the result of `add` operation.\n        Argument `filters` should be tuple(int, int, int) and specifies\n        number of filters in first, second and third convolution correspondingly.\n\n        Parameters\n        ----------\n        inputs : keras tensor\n            input tensor.\n        kernel_size : tuple(int, int, int)\n            size of the kernel along three dimensions for middle convolution operation in block.\n        filters : tuple(int, int, int)\n            number of filters in first, second and third 3D-convolution operations.\n        stage : int\n            number of stage, on par with block argument used to derive names of inner layers.\n        block : str\n            block prefix, on par with stage argument used to derive names of inner layers.\n\n        Returns\n        -------\n        keras tensor\n            output tensor.\n        """"""\n        filters1, filters2, filters3 = filters\n\n        conv_name_base = \'res\' + str(stage) + block + \'_branch\'\n        bn_name_base = \'bn\' + str(stage) + block + \'_branch\'\n\n        x = Conv3D(filters1, (1, 1, 1),\n                   strides=strides,\n                   name=conv_name_base + \'2a\',\n                   use_bias=False,\n                   kernel_initializer=\'glorot_normal\')(inputs)\n        x = BatchNormalization(axis=4, name=bn_name_base + \'2a\')(x)\n        x = Activation(\'relu\')(x)\n\n        x = Conv3D(filters2,\n                   kernel_size,\n                   padding=\'same\',\n                   name=conv_name_base + \'2b\',\n                   use_bias=False,\n                   kernel_initializer=\'glorot_normal\')(x)\n        x = BatchNormalization(axis=4, name=bn_name_base + \'2b\')(x)\n        x = Activation(\'relu\')(x)\n\n        x = Conv3D(filters3, (1, 1, 1),\n                   name=conv_name_base + \'2c\',\n                   use_bias=False,\n                   kernel_initializer=\'glorot_normal\')(x)\n        x = BatchNormalization(axis=4, name=bn_name_base + \'2c\')(x)\n\n        shortcut = Conv3D(filters3, (1, 1, 1),\n                          strides=strides,\n                          name=conv_name_base + \'1\',\n                          use_bias=False,\n                          kernel_initializer=\'glorot_normal\')(inputs)\n        shortcut = BatchNormalization(\n            axis=4, name=bn_name_base + \'1\')(shortcut)\n\n        x = layers.add([x, shortcut])\n        x = Activation(\'relu\')(x)\n        return x\n\n    def _build(self, *args, **kwargs):\n        """""" Build ResNoduleNet model implemented in keras.\n\n        Returns\n        -------\n        tuple([*input_nodes], [*output_nodes]);\n            list of input nodes and list of output nodes.\n        """"""\n        num_targets = self.get(\'num_targets\', self.config)\n        dropout_rate = self.get(\'dropout_rate\', self.config)\n        input_shape = self.get(\'input_shape\', self.config)\n\n        inputs = Input(shape=input_shape)\n        x = Conv3D(filters=32, kernel_size=(5, 3, 3),\n                   strides=(1, 2, 2), name=\'initial_conv\', padding=\'same\',\n                   use_bias=False, kernel_initializer=\'glorot_normal\')(inputs)\n\n        x = BatchNormalization(axis=4, name=\'initial_batch_norm\')(x)\n        x = Activation(\'relu\')(x)\n\n        x = self.conv_block(x, 3, [16, 16, 64], stage=2,\n                            block=\'a\', strides=(1, 1, 1))\n        x = self.identity_block(x, 3, [16, 16, 64], stage=2, block=\'b\')\n        x = self.identity_block(x, 3, [16, 16, 64], stage=2, block=\'c\')\n        x = Dropout(rate=dropout_rate)(x)\n\n        x = self.conv_block(x, 3, [32, 32, 128], stage=3, block=\'a\')\n        x = self.identity_block(x, 3, [32, 32, 128], stage=3, block=\'b\')\n        x = self.identity_block(x, 3, [32, 32, 128], stage=3, block=\'c\')\n        x = self.identity_block(x, 3, [32, 32, 128], stage=3, block=\'d\')\n        x = Dropout(rate=dropout_rate)(x)\n\n        x = self.conv_block(x, 3, [64, 64, 256], stage=4, block=\'a\')\n        x = self.identity_block(x, 3, [64, 64, 256], stage=4, block=\'b\')\n        x = self.identity_block(x, 3, [64, 64, 256], stage=4, block=\'c\')\n        x = self.identity_block(x, 3, [64, 64, 256], stage=4, block=\'d\')\n        x = self.identity_block(x, 3, [64, 64, 256], stage=4, block=\'e\')\n        x = self.identity_block(x, 3, [64, 64, 256], stage=4, block=\'f\')\n        x = Dropout(rate=dropout_rate)(x)\n\n        x = self.conv_block(x, 3, [128, 128, 512], stage=5, block=\'a\')\n        x = self.identity_block(x, 3, [128, 128, 512], stage=5, block=\'b\')\n        x = self.identity_block(x, 3, [128, 128, 512], stage=5, block=\'c\')\n\n        z = self.dense_block(x, units=self.get(\'units\', self.config),\n                             dropout=False, scope=\'DenseBlock-I\')\n\n        output_layer = Dense(num_targets, activation=\'sigmoid\', name=\'output\')(z)\n\n        return [inputs], [output_layer]\n'"
radio/models/keras/losses.py,0,"b'"""""" Contains losses used in keras models. """"""\nfrom keras import backend as K\n\n\ndef dice_loss(y_true, y_pred, smooth=1e-6):\n    """""" Loss function base on dice coefficient.\n\n    Parameters\n    ----------\n    y_true : keras tensor\n        tensor containing target mask.\n    y_pred : keras tensor\n        tensor containing predicted mask.\n    smooth : float\n        small real value used for avoiding division by zero error.\n\n    Returns\n    -------\n    keras tensor\n        tensor containing dice loss.\n    """"""\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    answer = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return -answer\n\n\ndef tversky_loss(y_true, y_pred, alpha=0.3, beta=0.7, smooth=1e-10):\n    """""" Tversky loss function.\n\n    Parameters\n    ----------\n    y_true : keras tensor\n        tensor containing target mask.\n    y_pred : keras tensor\n        tensor containing predicted mask.\n    alpha : float\n        real value, weight of \'0\' class.\n    beta : float\n        real value, weight of \'1\' class.\n    smooth : float\n        small real value used for avoiding division by zero error.\n\n    Returns\n    -------\n    keras tensor\n        tensor containing tversky loss.\n    """"""\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    truepos = K.sum(y_true * y_pred)\n    fp_and_fn = alpha * K.sum(y_pred * (1 - y_true)) + beta * K.sum((1 - y_pred) * y_true)\n    answer = (truepos + smooth) / ((truepos + smooth) + fp_and_fn)\n    return -answer\n\n\ndef jaccard_coef_logloss(y_true, y_pred, smooth=1e-10):\n    """""" Loss function based on jaccard coefficient.\n\n    Parameters\n    ----------\n    y_true : keras tensor\n        tensor containing target mask.\n    y_pred : keras tensor\n        tensor containing predicted mask.\n    smooth : float\n        small real value used for avoiding division by zero error.\n\n    Returns\n    -------\n    keras tensor\n        tensor containing negative logarithm of jaccard coefficient.\n    """"""\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    truepos = K.sum(y_true * y_pred)\n    falsepos = K.sum(y_pred) - truepos\n    falseneg = K.sum(y_true) - truepos\n    jaccard = (truepos + smooth) / (smooth + truepos + falseneg + falsepos)\n    return -K.log(jaccard + smooth)\n'"
radio/models/tf/__init__.py,0,"b'"""""" Contains neural network architectures for lung cancer detection implemented in tensorflow. """"""\nfrom .dense_nodule_net import DenseNoduleNet\nfrom .res_nodule_net import ResNodule3DNet50\nfrom .dilated_nodule_net import DilatedNoduleNet\n'"
radio/models/tf/dense_nodule_net.py,0,"b'# pylint: disable=too-few-public-methods\n"""""" Contains DenseNoduleNet model class. """"""\n\nfrom ...batchflow.models.tf import DenseNet         # pylint: disable=no-name-in-module, import-error\n\n\nclass DenseNoduleNet(DenseNet):\n    """""" Implementation of custom DenseNet architecture for lung cancer detection. """"""\n    @classmethod\n    def default_config(cls):\n        """""" Specification of custom block parameters. """"""\n        config = DenseNet.default_config()\n        input_config = dict(layout=\'cnap\', filters=16, kernel_size=7,\n                            pool_size=3, pool_strides=(1, 2, 2))\n\n        config[\'initial_block\'].update(input_config)      # pylint: disable=no-member\n        config[\'body\'][\'num_blocks\'] = [6, 12, 24, 16]  # pylint: disable=invalid-sequence-index\n        return config\n'"
radio/models/tf/dilated_nodule_net.py,24,"b'# pylint: disable=too-many-arguments, invalid-sequence-index\n"""""" Implementation of custom volumetric network for lung cancer detection. """"""\n\nimport numpy as np\nimport tensorflow as tf\nfrom .utils import repeat_tensor\nfrom ...batchflow.models.tf.layers import conv_block         # pylint: disable=no-name-in-module, import-error\nfrom ...batchflow.models.tf import TFModel                   # pylint: disable=no-name-in-module, import-error\n\n\nclass DilatedNoduleNet(TFModel):\n    """""" Implementation of custom encoder-decoder architecture with dilated convolutions.\n\n    Architecture is inspired by VNet (Milletari et al., https://arxiv.org/abs/1606.04797).\n\n    **Configuration**\n\n    inputs : dict\n        dict with keys \'images\' and \'masks\' (see :meth:`._make_inputs`)\n\n    body : dict\n        num_blocks : int\n            number of encoder/decoder blocks (default=4)\n\n        filters : list of int\n            number of filters in each block (default=[128, 256, 512, 1024])\n\n    head : dict\n        num_classes : int\n            number of semantic classes\n    """"""\n    @classmethod\n    def default_config(cls):\n        """""" Default config. """"""\n        config = TFModel.default_config()\n\n        filters = 32\n\n        config[\'initial_block\'].update({})            # pylint: disable=no-member\n        config[\'body\'][\'upsampling_kernel\'] = 3\n        config[\'body\'][\'num_blocks\'] = 4\n        config[\'body\'][\n            \'filters\'] = 2 ** np.arange(config[\'body\'][\'num_blocks\']) * filters * 2\n        config[\'body\'][\'dilation_rate\'] = [1, 2]\n        config[\'body\'][\'dilation_share\'] = [0.5, 0.5]\n        config[\'body\'][\'upsampling_mode\'] = \'deconv\'\n        return config\n\n    def build_config(self, names=None):\n        """""" Build config. """"""\n        config = super().build_config(names)\n        config[\'head\'][\'num_classes\'] = self.num_classes(\'targets\')\n        return config\n\n    @classmethod\n    def dilated_branches(cls, inputs, filters, kernel_size, dilation_rate, name, **kwargs):\n        """""" Convolutional block with parallel branches having different dilation rate.\n\n        Parameters\n        ----------\n        inputs : tf.Tensor\n            input tensor\n        filters : tuple(int, ...)\n            number of filters corresponding to branches with different dilation rate.\n        kernel_size : tuple(int, ...)\n            size of convolutional kernel corresponding to branches\n            with different dilation rate. Kernel size is considered\n            to be the same along [zyx] dimensions.\n        dilation_rate : tuple(int, ...)\n            dilation rate for convolutional branches. Dilation rate is considered\n            to be the same along [zyx] dimensions.\n        activation : tensorflow activation function\n        padding : str\n            padding to use in convolution operation. Can be \'same\' or \'valid\'.\n        is_training : bool or bool tensor\n            indicator of training or prediction mode.\n        name : str\n            name of the block that will be used as argument of tf.variable_scope.\n\n        Returns\n        -------\n        tf.Tensor\n        """"""\n\n        if not all(isinstance(arg, (tuple, list)) for arg in (filters, kernel_size, dilation_rate)):\n            raise ValueError(""Arguments \'filters\', \'kernel_size\', \'dilation_rate\' ""\n                             +""must be tuples or lists"")\n\n        branches = []\n        with tf.variable_scope(name):\n            for f, k, d in zip(filters, kernel_size, dilation_rate):\n\n                b = conv_block(inputs, layout=\'cna\', kernel_size=k, dilation=d,\n                               filters=f, name=\'conv_dilation_{}\'.format(d), **kwargs)\n                branches.append(b)\n            outputs = tf.concat(branches, axis=4)\n        return outputs\n\n    @classmethod\n    def decoder_block(cls, inputs, filters, name, **kwargs):\n        """""" 3x3 convolution and 2x2 transposed convolution or upsampling\n\n        Each of two 3x3x3 convolutions contains several branches with\n        different dilation rate.\n\n        Parameters\n        ----------\n        inputs : tuple(tf.Tensor, tf.Tensor)\n            two input tensors\n        filters : int\n            number of output filters\n        name : str\n            scope name\n\n        Returns\n        -------\n        tf.Tensor\n        """"""\n        config = cls.fill_params(\'body\', **kwargs)\n        kernel = cls.pop(\'upsampling_kernel\', config)\n\n        mode = cls.pop(\'upsampling_mode\', config)  # Added\n        dilation_rate = cls.pop(\'dilation_rate\', config)  # Added\n        dilation_share = np.asarray(cls.pop(\'dilation_share\', config))\n        dilation_share /= dilation_share.sum()\n        _filters = np.rint(filters * dilation_share).astype(np.int).tolist()\n\n        if kwargs.get(\'data_format\') == \'channels_last\':\n            repeat_times = (1, 2, 2, 2, 1)\n            axis = -1\n        else:\n            repeat_times = (1, 1, 2, 2, 2)\n            axis = 1\n\n        with tf.variable_scope(name):\n            x, skip = inputs\n\n            if mode == \'deconv\':\n                conv_kwargs = dict(filters=filters, strides=2, kernel_size=kernel)\n                x = conv_block(x, \'tna\', **{**kwargs, **conv_kwargs})\n            elif mode == \'repeat\':\n                x = repeat_tensor(x, repeat_times)\n\n            x = cls.crop(x, skip, data_format=kwargs.get(\'data_format\'))\n            x = tf.concat((skip, x), axis=axis)\n\n            dilated_kwargs = dict(filters=_filters, kernel_size=(3, 3, 3), dilation_rate=dilation_rate)\n            x = cls.dilated_branches(x, name=\'conv_I\', **{**config, **dilated_kwargs})\n            x = cls.dilated_branches(x, name=\'conv_II\', **{**config, **dilated_kwargs})\n        return x\n\n    @classmethod\n    def encoder_block(cls, inputs, filters, name, **kwargs):\n        """""" Two 3x3x3 convolutions and 2x2x2 max pooling with stride 2.\n\n        Each of two 3x3x3 convolutions contains several branches with\n        different dilation rate.\n\n        Parameters\n        ----------\n        inputs : tf.Tensor\n            input tensor\n        filters : int\n            number of output filters\n        name : str\n            scope name\n\n        Returns\n        -------\n        tf.Tensor\n        """"""\n        config = cls.fill_params(\'body\', **kwargs)\n        dilation_rate = cls.pop(\'dilation_rate\', config)\n\n        dilation_share = np.asarray(cls.pop(\'dilation_share\', config))\n        dilation_share /= dilation_share.sum()\n        _filters = np.rint(filters * dilation_share).astype(np.int).tolist()\n        with tf.variable_scope(name):\n            dilated_kwargs = dict(filters=_filters, kernel_size=(3, 3, 3), dilation_rate=dilation_rate)\n            x = cls.dilated_branches(inputs, name=\'conv_I\', **{**config, **dilated_kwargs})\n\n            x = cls.dilated_branches(x, name=\'conv_II\', **{**config, **dilated_kwargs})\n\n            downsampled_x = tf.layers.max_pooling3d(x, pool_size=(2, 2, 2),\n                                                    strides=(2, 2, 2),\n                                                    padding=\'same\',\n                                                    name=\'max_pool3d\')\n        return x, downsampled_x\n\n    @classmethod\n    def central_block(cls, inputs, filters, name, **kwargs):\n        """""" Block that situated between encoder and decoder branches.\n\n        Block consists of 1x1x1 followed by 3x3x3. Note that 3x3x3 convolution\n        can contain several branches with different dilation rate.\n\n        Parameters\n        ----------\n        inputs : tf.Tensor\n             input tensor\n        filters : int\n            number of output filters\n        name : str\n            scope name\n\n        Returns\n        -------\n        tf.Tensor\n        """"""\n        config = cls.fill_params(\'body\', **kwargs)\n        dilation_rate = cls.pop(\'dilation_rate\', config)\n        dilation_share = np.asarray(cls.pop(\'dilation_share\', config))\n        dilation_share /= dilation_share.sum()\n        _filters = np.rint(filters * dilation_share).astype(np.int).tolist()\n\n        with tf.variable_scope(name):\n            dilated_kwargs = dict(filters=_filters, kernel_size=(3, 3, 3), dilation_rate=dilation_rate)\n            x = conv_block(inputs, **{**config, \'layout\': \'cna\', \'filters\': filters, \'kernel_size\': 1})\n            x = cls.dilated_branches(x, name=\'conv_I\', **{**config, **dilated_kwargs})\n        return x\n\n    @classmethod\n    def body(cls, inputs, name=\'body\', **kwargs):\n        """""" Base layers.\n\n        Parameters\n        ----------\n        inputs : tf.Tensor\n            input tensor\n        filters : tuple of int\n            number of filters in encoder_block\n        name : str\n            scope name\n\n        Returns\n        -------\n        tf.Tensor\n        """"""\n        kwargs = cls.fill_params(\'body\', **kwargs)\n        filters = kwargs.pop(\'filters\')\n\n        with tf.variable_scope(name):\n            x = inputs\n            encoder_outputs = []\n            for i, ifilters in enumerate(filters[:-1]):\n                y, x = cls.encoder_block(\n                    x, ifilters, name=\'encoder-\'+str(i), **kwargs)\n                encoder_outputs.append(y)\n\n            x = cls.central_block(\n                x, filters[-1], name=\'central_block\', **kwargs)\n\n            for i, ifilters in enumerate(filters[:-1][::-1]):\n                x = cls.decoder_block((x, encoder_outputs[-i-1]), ifilters//2,\n                                      name=\'decoder-\'+str(i), **kwargs)\n        return x\n\n    @classmethod\n    def head(cls, inputs, num_classes, name=\'head\', **kwargs):\n        """""" Conv block followed by 1x1 convolution.\n\n        Parameters\n        ----------\n        inputs : tf.Tensor\n            input tensor\n        num_classes : int\n            number of classes (and number of filters in the last 1x1 convolution)\n        name : str\n            scope name\n\n        Returns\n        -------\n        tf.Tensor\n        """"""\n        kwargs = cls.fill_params(\'head\', **kwargs)\n        pred_kwargs = dict(filters=num_classes, kernel_size=1,\n                           activation=tf.nn.sigmoid, layout=\'cna\')\n        with tf.variable_scope(name):\n            x = conv_block(inputs, name=\'conv\', **kwargs)\n            x = conv_block(x, **{**kwargs, **pred_kwargs})\n        return x\n'"
radio/models/tf/layers.py,35,"b'# pylint: disable=too-many-arguments\n"""""" Helper functions for creating layers written on tensorflow. """"""\n\nimport tensorflow as tf\n\n\ndef selu(x):\n    """""" Selu activation function.\n\n    Apply selu activation function to input tensor.\n\n    Parameters\n    ----------\n    x : tf.Tensor\n        input tensor.\n\n    Returns\n    -------\n    tf.Tensor\n    """"""\n    alpha = 1.6732632423543772848170429916717\n    scale = 1.0507009873554804934193349852946\n    return scale * tf.where(x >= 0.0, x, alpha * tf.nn.elu(x))\n\n\ndef conv3d(input_tensor, filters, kernel_size, name,\n           strides=(1, 1, 1), padding=\'same\', activation=tf.nn.relu,\n           use_bias=True, is_training=True):\n    """""" Apply 3D convolution operation to input tensor.\n\n    Parameters\n    ----------\n    input_tensor : tf.Tensor\n        input tensor for 3D-convolution.\n    filters : int\n        number of filters in the ouput tensor.\n    kernel_size : tuple(int, int, int)\n        size of kernel for 3D-convolution operation along 3 dimensions.\n    name : str\n        name of the layer that will be used as an argument of tf.variable_scope.\n    strides : tuple(int, int, int)\n        size of strides along 3 dimensions required by tf.layers.conv3d.\n    padding : str\n        padding mode, can be \'same\' or \'valid\'.\n    activation : tensorflow activation function\n        this function will be applied to output tensor.\n    use_bias : bool\n        whether use bias or not.\n\n    Returns\n    -------\n    tf.Tensor\n        output tensor.\n    """"""\n    with tf.variable_scope(name):\n        output_tensor = tf.layers.conv3d(input_tensor,\n                                         filters=filters,\n                                         kernel_size=kernel_size,\n                                         strides=strides,\n                                         use_bias=use_bias,\n                                         name=\'conv3d\',\n                                         padding=padding)\n\n        output_tensor = activation(output_tensor)\n    return output_tensor\n\n\ndef bn_conv3d(input_tensor, filters, kernel_size, name,\n              strides=(1, 1, 1), padding=\'same\', activation=tf.nn.relu,\n              use_bias=False, is_training=True):\n    """""" Apply 3D convolution operation with batch normalization to input tensor.\n\n    Parameters\n    ----------\n    input_tensor : tf.Tensor\n        input tensor for 3D-convolution.\n    filters : int\n        number of filters in the ouput tensor.\n    kernel_size : tuple(int, int, int)\n        size of kernel for 3D-convolution operation along 3 dimensions.\n    name : str\n        name of the layer that will be used as an argument of tf.variable_scope.\n    strides : tuple(int, int, int)\n        size of strides along 3 dimensions required by tf.layers.conv3d.\n    padding : str\n        padding mode, can be \'same\' or \'valid\'.\n    activation : tensorflow activation function\n        this function will be applied to output tensor.\n    use_bias : bool\n        whether use bias or not.\n    is_training : tf.Tensor or bool\n        whether model is in training state of prediction state.\n\n    Returns\n    -------\n    tf.Tensor\n        output tensor.\n    """"""\n    with tf.variable_scope(name):\n        output_tensor = tf.layers.conv3d(input_tensor,\n                                         filters=filters,\n                                         kernel_size=kernel_size,\n                                         strides=strides,\n                                         use_bias=use_bias,\n                                         name=\'conv3d\',\n                                         padding=padding)\n\n        output_tensor = tf.layers.batch_normalization(output_tensor, axis=-1,\n                                                      training=is_training)\n        output_tensor = activation(output_tensor)\n    return output_tensor\n\n\ndef bn_dilated_conv3d(input_tensor, filters,\n                      kernel_size, name, activation=tf.nn.relu,\n                      dilation=(1, 1, 1), padding=\'same\',\n                      is_training=True):\n    """""" Apply 3D-dilated-convolution operation with batch normalization to input tensor.\n\n    Parameters\n    ----------\n    input_tensor : tf.Tensor\n        input tensor for 3D-convolution.\n    filters : int\n        number of filters in the ouput tensor.\n    kernel_size : tuple(int, int, int)\n        size of kernel for 3D-convolution operation along 3 dimensions.\n    name : str\n        name of the layer that will be used as an argument of tf.variable_scope.\n    dilation : tuple(int, int, int)\n        dilation rate along 3 dimensions.\n    strides : tuple(int, int, int)\n        size of strides along 3 dimensions required by tf.layers.conv3d.\n    padding : str\n        padding mode, can be \'same\' or \'valid\'.\n    activation : tensorflow activation function\n        this function will be applied to output tensor.\n    use_bias : bool\n        whether use bias or not.\n    is_training : tf.Tensor or bool\n        whether model is in training state of prediction state.\n\n    Returns\n    -------\n    tf.Tensor\n        output tensor.\n    """"""\n\n    in_filters = input_tensor.get_shape().as_list()[-1]\n    init_fn = tf.contrib.layers.xavier_initializer()\n    with tf.variable_scope(name):\n        w = tf.get_variable(name=\'W\', shape=(*kernel_size, in_filters, filters),\n                            initializer=init_fn)\n\n        output_tensor = tf.nn.convolution(input_tensor, w,\n                                          padding=padding.upper(),\n                                          strides=(1, 1, 1),\n                                          dilation_rate=dilation)\n\n        output_tensor = tf.layers.batch_normalization(output_tensor,\n                                                      axis=4,\n                                                      training=is_training)\n\n        output_tensor = activation(output_tensor)\n\n    return output_tensor\n\n\ndef global_average_pool3d(input_tensor, name):\n    """""" Apply global average pooling 3D operation to input tensor.\n\n    Parameters\n    ----------\n    input_tensor : tf.Tensor\n        input tensor.\n    name : str\n        name of layer that will be used as an argument of tf.variable_scope.\n\n    Returns\n    -------\n    tf.Tensor\n        output tensor.\n    """"""\n    with tf.variable_scope(name):\n        output_layer = tf.reduce_mean(input_tensor, axis=(1, 2, 3))\n    return output_layer\n'"
radio/models/tf/losses.py,43,"b'"""""" Contains losses used in tensorflow models. """"""\n\nimport tensorflow as tf\n\n\ndef reg_l2_loss(labels, predictions, lambda_coords=0.75):\n    """""" L2 loss for prediction of cancer tumor\'s centers, sizes joined with binary classification task.\n\n    Parameters\n    ----------\n    labels : tf.Tensor\n        tensor containing true values for sizes of nodules, their centers\n        and classes of crop(1 if cancerous 0 otherwise).\n    predictions : tf.Tensor\n        tensor containing predicted values for sizes of nodules, their centers\n        and probability of cancer in given crop.\n\n    Returns\n    -------\n    tf.Tensor\n        l2 loss for regression of cancer tumor center\'s coordinates,\n        sizes joined with binary classification task.\n\n    Notes\n    -----\n    labels and predictions tensors must have [None, 7] shapes;\n    labels[:, :3] and predictions[:, :3] correspond to normalized (from [0, 1] interval)\n    zyx coordinates of cancer tumor, while labels[:, 3:6] and predictions[:, 3:6]\n    correspond to sizes of cancer tumor along zyx axes(also normalized),\n    finally, labels[:, 6] and predictions[:, 6] represent whether cancer tumor presents\n    or not in the current crop.\n    """"""\n    clf_true, clf_pred = labels[:, 6], predictions[:, 6]\n    centers_true, centers_pred = labels[:, :3], predictions[:, :3]\n    sizes_true, sizes_pred = labels[:, 3:6], predictions[:, 3:6]\n\n    centers_loss = 0.5 * tf.reduce_sum((centers_true - centers_pred) ** 2, axis=1)\n    sizes_loss = 0.5 * tf.reduce_sum((tf.sqrt(sizes_true) - tf.sqrt(sizes_pred)) ** 2, axis=1)\n    clf_loss = 0.5 * (clf_true - clf_pred) ** 2\n\n    loss = clf_loss + lambda_coords * clf_true * (centers_loss + sizes_loss)\n    return tf.reduce_mean(loss)\n\n\ndef iou_3d(labels, predictions, epsilon=10e-7):\n    """""" Compute intersection over union in 3D case for input tensors.\n\n    Parameters\n    ----------\n    labels : tf.Tensor\n        tensor containg true values for sizes of nodules and their centers.\n    predictions : tf.Tensor\n        tensor containing predicted values for sizes of nodules and their centers.\n    epsilon : float\n        small real value used for avoiding division by zero error.\n\n    Returns\n    -------\n    tf.Tensor\n        tensor containing intersection over union computed on input tensors.\n    """"""\n    with tf.variable_scope(\'IOU\'):\n        tf_epsilon = tf.constant([epsilon], tf.float32)\n        r_true = labels[:, :3]\n        r_pred = predictions[:, :3]\n\n        s_true = labels[:, 3:6]\n        s_pred = predictions[:, 3:6]\n\n        abs_r_diff = tf.abs(r_true - r_pred)\n        abs_s_diff = tf.abs(s_true - s_pred)\n\n        iou_tensor = tf.where(abs_r_diff < abs_s_diff, 2 * tf.minimum(s_true, s_pred),\n                              tf.clip_by_value(s_true + s_pred - abs_r_diff, 0, 1))\n\n        iou_tensor = (tf.reduce_prod(iou_tensor, axis=1)\n                      / (tf.reduce_prod(s_true, axis=1)\n                         + tf.reduce_prod(s_pred, axis=1) + tf_epsilon))\n    return iou_tensor\n\n\ndef tversky_loss(labels, predictions, alpha=0.3, beta=0.7, smooth=1e-10):\n    """""" Tversky loss function.\n\n    Parameters\n    ----------\n    labels : tf.Tensor\n        tensor containing target mask.\n    predictions : tf.Tensor\n        tensor containing predicted mask.\n    alpha : float\n        real value, weight of \'0\' class.\n    beta : float\n        real value, weight of \'1\' class.\n    smooth : float\n        small real value used for avoiding division by zero error.\n\n    Returns\n    -------\n    tf.Tensor\n        tensor containing tversky loss.\n    """"""\n    labels = tf.contrib.layers.flatten(labels)\n    predictions = tf.contrib.layers.flatten(predictions)\n    truepos = tf.reduce_sum(labels * predictions)\n    fp_and_fn = (alpha * tf.reduce_sum(predictions * (1 - labels))\n                 + beta * tf.reduce_sum((1 - predictions) * labels))\n\n    return -(truepos + smooth) / (truepos + smooth + fp_and_fn)\n\n\ndef dice_loss(labels, predictions, smooth=1e-6):\n    """""" Loss function base on dice coefficient.\n\n    Parameters\n    ----------\n    labels : tf.Tensor\n        tensor containing target mask.\n    predictions : tf.Tensor\n        tensor containing predicted mask.\n    smooth : float\n        small real value used for avoiding division by zero error.\n\n    Returns\n    -------\n    tf.Tensor\n        tensor containing dice loss.\n    """"""\n    labels = tf.contrib.layers.flatten(labels)\n    predictions = tf.contrib.layers.flatten(predictions)\n    intersection = tf.reduce_sum(labels * predictions)\n    answer = (2. * intersection + smooth) / (tf.reduce_sum(labels)\n                                             + tf.reduce_sum(predictions) + smooth)\n    return -answer\n\n\ndef jaccard_coef_logloss(labels, predictions, smooth=1e-10):\n    """""" Loss function based on jaccard coefficient.\n\n    Parameters\n    ----------\n    labels : tf.Tensor\n        tensor containing target mask.\n    predictions : tf.Tensor\n        tensor containing predicted mask.\n    smooth : float\n        small real value used for avoiding division by zero error.\n\n    Returns\n    -------\n    tf.Tensor\n        tensor containing negative logarithm of jaccard coefficient.\n    """"""\n    labels = tf.contrib.layers.flatten(labels)\n    predictions = tf.contrib.layers.flatten(predictions)\n    truepos = tf.reduce_sum(labels * predictions)\n    falsepos = tf.reduce_sum(predictions) - truepos\n    falseneg = tf.reduce_sum(labels) - truepos\n    jaccard = (truepos + smooth) / (smooth + truepos + falseneg + falsepos)\n    return -tf.log(jaccard + smooth)\n'"
radio/models/tf/res_nodule_net.py,0,"b'# pylint: disable=too-few-public-methods\n"""""" Contains ResNodule3DNet50 model class. """"""\n\nimport numpy as np\nfrom ...batchflow.models.tf import ResNet50         # pylint: disable=no-name-in-module, import-error\n\n\nclass ResNodule3DNet50(ResNet50):\n    """""" Implementation of custom DenseNet architecture for lung cancer detection. """"""\n\n    @classmethod\n    def default_config(cls):\n        """""" Specification of custom block parameters. """"""\n        config = ResNet50.default_config()\n\n        input_config = dict(layout=\'cnap\', filters=16, kernel_size=7,\n                            pool_size=3, pool_strides=(1, 2, 2))\n        config[\'input_block\'].update(input_config)      # pylint: disable=no-member\n\n        filters = 16   # number of filters in the first block\n        config[\'body\'][\'filters\'] = (2 ** np.arange(len(config[\'body\'][\'num_blocks\'])) * filters      # pylint: disable=invalid-sequence-index\n                                     * config[\'body\'][\'block\'][\'width_factor\'])                       # pylint: disable=invalid-sequence-index\n\n        return config\n'"
radio/models/tf/utils.py,13,"b'"""""" Contains different useful tensorflow functions. """"""\n\nimport numpy as np\nimport tensorflow as tf\n\n\ndef get_shape(input_tensor):\n    """""" Return full shape of the input tensor represented by tuple of ints.\n    Parameters\n    ----------\n    input_tensor : tf.Variable or tf.Tensor\n        input_tensor.\n\n    Returns\n    -------\n    tuple(int)\n        input tensor\'s shape.\n    """"""\n    return input_tensor.get_shape().as_list()\n\n\ndef num_channels(input_tensor):\n    """""" Get number of channels in input tensor.\n\n    Parameters\n    ----------\n    input_tensor : tf.Variable or tf.Tensor\n        input_tensor.\n\n    Returns\n    -------\n    int\n        number of channels.\n\n    Notes\n    -----\n        channels last ordering is used.\n    """"""\n    return get_shape(input_tensor)[-1]\n\n\ndef repeat_tensor(input_tensor, times):\n    """""" Repeat tensor given times along axes.\n\n    Parameters\n    ----------\n    input_tensor : tf.Tensor\n        input tensor for repeat operation.\n    times : tuple(int, int,..., int)\n        number of times to repeat input tensor tensor along each axis.\n\n    Returns\n    -------\n    tf.Tensor\n        repeated tensor.\n    """"""\n    source_shape = get_shape(input_tensor)\n    x = tf.expand_dims(input_tensor, axis=len(source_shape))\n    x = tf.tile(x, [1, *times])\n\n    new_shape = tuple(np.array(source_shape[1:]) * np.array(times[1:]))\n    x = tf.reshape(x, shape=(-1, *new_shape))\n    return x\n\n\ndef split_channels(input_tensor, size):\n    """""" Split channels of input tensor into groups of given size.\n\n    Parameters\n    ----------\n    input_tensor : tf.Tensor\n        input tensor for split_channels operation.\n    size : int\n        size of each group.\n\n    Returns\n    -------\n    list of tensors\n        each corresponds to channels group.\n    """"""\n    in_filters = num_channels(input_tensor)\n    if in_filters <= size:\n        return input_tensor\n    a, b = int(in_filters / size), int(in_filters % size)\n    main = list(tf.split(input_tensor[..., : a * size], a,\n                         axis=len(input_tensor.get_shape()) - 1))\n    if b != 0:\n        main.append(input_tensor[..., a * size: ])\n    return main\n\n\ndef channels_rnd_shuffle(input_tensor):\n    """""" Perform random shuffle of channels in input tensor.\n\n    Parameters\n    ----------\n    input_tensor : tf.Tensor\n        input tensor.\n\n    Returns\n    -------\n    tf.Tensor\n        tensor with random shuffle of channels.\n    """"""\n    num_filters = num_channels(input_tensor)\n    indices = np.random.permutation(num_filters)\n    tensors_list = []\n    for i in indices:\n        tensors_list.append(input_tensor[..., i, tf.newaxis])\n    return tf.concat(tensors_list, axis=-1)\n'"
