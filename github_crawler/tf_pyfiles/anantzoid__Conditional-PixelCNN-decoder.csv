file_path,api_count,code
autoencoder.py,10,"b'import tensorflow as tf\nimport numpy as np\nfrom utils import *\nfrom models import *\n\ndef trainAE(conf, data):\n    encoder_X = tf.placeholder(tf.float32, shape=[None, conf.img_height, conf.img_width, conf.channel])\n    decoder_X = tf.placeholder(tf.float32, shape=[None, conf.img_height, conf.img_width, conf.channel])\n\n    encoder = ConvolutionalEncoder(encoder_X, conf)\n    decoder = PixelCNN(decoder_X, conf, encoder.pred)\n    y = decoder.pred\n    tf.scalar_summary(\'loss\', decoder.loss)\n\n    trainer = tf.train.RMSPropOptimizer(1e-3)\n    gradients = trainer.compute_gradients(decoder.loss)\n\n    clipped_gradients = [(tf.clip_by_value(_[0], -conf.grad_clip, conf.grad_clip), _[1]) for _ in gradients]\n    optimizer = trainer.apply_gradients(clipped_gradients)\n\n    saver = tf.train.Saver(tf.trainable_variables())\n    with tf.Session() as sess:\n        merged = tf.merge_all_summaries()\n        writer = tf.train.SummaryWriter(conf.summary_path, sess.graph)\n\n        sess.run(tf.initialize_all_variables())\n\n        if os.path.exists(conf.ckpt_file):\n            saver.restore(sess, conf.ckpt_file)\n            print(""Model Restored"")\n\n        # TODO The training part below and in main.py could be generalized\n        if conf.epochs > 0:\n            print(""Started Model Training..."")\n        pointer = 0\n        step = 0\n        for i in range(conf.epochs):\n            for j in range(conf.num_batches):\n                if conf.data == \'mnist\':\n                    batch_X = binarize(data.train.next_batch(conf.batch_size)[0].reshape(conf.batch_size, conf.img_height, conf.img_width, conf.channel))\n                else:\n                    batch_X, pointer = get_batch(data, pointer, conf.batch_size)\n\n                _, l, summary = sess.run([optimizer, decoder.loss, merged], feed_dict={encoder_X: batch_X, decoder_X: batch_X})\n                writer.add_summary(summary, step)\n                step += 1\n\n            print(""Epoch: %d, Cost: %f""%(i, l))\n            if (i+1)%10 == 0:\n                saver.save(sess, conf.ckpt_file)\n                generate_ae(sess, encoder_X, decoder_X, y, data, conf, str(i))\n\n        writer.close()\n        generate_ae(sess, encoder_X, decoder_X, y, data, conf, \'\')\n\n'"
layers.py,16,"b'import tensorflow as tf\nimport numpy as np\n\ndef get_weights(shape, name, horizontal, mask_mode=\'noblind\', mask=None):\n    weights_initializer = tf.contrib.layers.xavier_initializer()\n    W = tf.get_variable(name, shape, tf.float32, weights_initializer)\n\n    \'\'\'\n        Use of masking to hide subsequent pixel values \n    \'\'\'\n    if mask:\n        filter_mid_y = shape[0]//2\n        filter_mid_x = shape[1]//2\n        mask_filter = np.ones(shape, dtype=np.float32)\n        if mask_mode == \'noblind\':\n            if horizontal:\n                # All rows after center must be zero\n                mask_filter[filter_mid_y+1:, :, :, :] = 0.0\n                # All columns after center in center row must be zero\n                mask_filter[filter_mid_y, filter_mid_x+1:, :, :] = 0.0\n            else:\n                if mask == \'a\':\n                    # In the first layer, can ONLY access pixels above it\n                    mask_filter[filter_mid_y:, :, :, :] = 0.0\n                else:\n                    # In the second layer, can access pixels above or even with it.\n                    # Reason being that the pixels to the right or left of the current pixel\n                    #  only have a receptive field of the layer above the current layer and up.\n                    mask_filter[filter_mid_y+1:, :, :, :] = 0.0\n\n            if mask == \'a\':\n                # Center must be zero in first layer\n                mask_filter[filter_mid_y, filter_mid_x, :, :] = 0.0\n        else:\n            mask_filter[filter_mid_y, filter_mid_x+1:, :, :] = 0.\n            mask_filter[filter_mid_y+1:, :, :, :] = 0.\n\n            if mask == \'a\':\n                mask_filter[filter_mid_y, filter_mid_x, :, :] = 0.\n                \n        W *= mask_filter \n    return W\n\ndef get_bias(shape, name):\n    return tf.get_variable(name, shape, tf.float32, tf.zeros_initializer)\n\ndef conv_op(x, W):\n    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=\'SAME\')\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\'SAME\')\n\nclass GatedCNN():\n    def __init__(self, W_shape, fan_in, horizontal, gated=True, payload=None, mask=None, activation=True, conditional=None, conditional_image=None):\n        self.fan_in = fan_in\n        in_dim = self.fan_in.get_shape()[-1]\n        self.W_shape = [W_shape[0], W_shape[1], in_dim, W_shape[2]]  \n        self.b_shape = W_shape[2]\n\n        self.in_dim = in_dim\n        self.payload = payload\n        self.mask = mask\n        self.activation = activation\n        self.conditional = conditional\n        self.conditional_image = conditional_image\n        self.horizontal = horizontal\n        \n        if gated:\n            self.gated_conv()\n        else:\n            self.simple_conv()\n\n    def gated_conv(self):\n        W_f = get_weights(self.W_shape, ""v_W"", self.horizontal, mask=self.mask)\n        W_g = get_weights(self.W_shape, ""h_W"", self.horizontal, mask=self.mask)\n\n        b_f_total = get_bias(self.b_shape, ""v_b"")\n        b_g_total = get_bias(self.b_shape, ""h_b"")\n        if self.conditional is not None:\n            h_shape = int(self.conditional.get_shape()[1])\n            V_f = get_weights([h_shape, self.W_shape[3]], ""v_V"", self.horizontal)\n            b_f = tf.matmul(self.conditional, V_f)\n            V_g = get_weights([h_shape, self.W_shape[3]], ""h_V"", self.horizontal)\n            b_g = tf.matmul(self.conditional, V_g)\n\n            b_f_shape = tf.shape(b_f)\n            b_f = tf.reshape(b_f, (b_f_shape[0], 1, 1, b_f_shape[1]))\n            b_g_shape = tf.shape(b_g)\n            b_g = tf.reshape(b_g, (b_g_shape[0], 1, 1, b_g_shape[1]))\n\n            b_f_total = b_f_total + b_f\n            b_g_total = b_g_total + b_g\n        if self.conditional_image is not None:\n            b_f_total = b_f_total + tf.layers.conv2d(self.conditional_image, self.in_dim, 1, use_bias=False, name=""ci_f"")\n            b_g_total = b_g_total + tf.layers.conv2d(self.conditional_image, self.in_dim, 1, use_bias=False, name=""ci_g"")\n\n        conv_f = conv_op(self.fan_in, W_f)\n        conv_g = conv_op(self.fan_in, W_g)\n       \n        if self.payload is not None:\n            conv_f += self.payload\n            conv_g += self.payload\n\n        self.fan_out = tf.multiply(tf.tanh(conv_f + b_f_total), tf.sigmoid(conv_g + b_g_total))\n\n    def simple_conv(self):\n        W = get_weights(self.W_shape, ""W"", self.horizontal, mask_mode=""standard"", mask=self.mask)\n        b = get_bias(self.b_shape, ""b"")\n        conv = conv_op(self.fan_in, W)\n        if self.activation: \n            self.fan_out = tf.nn.relu(tf.add(conv, b))\n        else:\n            self.fan_out = tf.add(conv, b)\n\n    def output(self):\n        return self.fan_out \n\n\n'"
main.py,6,"b'import tensorflow as tf\nimport numpy as np\nimport argparse\nfrom models import PixelCNN\nfrom autoencoder import *\nfrom utils import *\n\ndef train(conf, data):\n    X = tf.placeholder(tf.float32, shape=[None, conf.img_height, conf.img_width, conf.channel])\n    model = PixelCNN(X, conf)\n\n    trainer = tf.train.RMSPropOptimizer(1e-3)\n    gradients = trainer.compute_gradients(model.loss)\n\n    clipped_gradients = [(tf.clip_by_value(_[0], -conf.grad_clip, conf.grad_clip), _[1]) for _ in gradients]\n    optimizer = trainer.apply_gradients(clipped_gradients)\n\n    saver = tf.train.Saver(tf.trainable_variables())\n\n    with tf.Session() as sess: \n        sess.run(tf.initialize_all_variables())\n        if os.path.exists(conf.ckpt_file):\n            saver.restore(sess, conf.ckpt_file)\n            print(""Model Restored"")\n       \n        if conf.epochs > 0:\n            print(""Started Model Training..."")\n        pointer = 0\n        for i in range(conf.epochs):\n            for j in range(conf.num_batches):\n                if conf.data == ""mnist"":\n                    batch_X, batch_y = data.train.next_batch(conf.batch_size)\n                    batch_X = binarize(batch_X.reshape([conf.batch_size, \\\n                            conf.img_height, conf.img_width, conf.channel]))\n                    batch_y = one_hot(batch_y, conf.num_classes) \n                else:\n                    batch_X, pointer = get_batch(data, pointer, conf.batch_size)\n                data_dict = {X:batch_X}\n                if conf.conditional is True:\n                    data_dict[model.h] = batch_y\n                _, cost = sess.run([optimizer, model.loss], feed_dict=data_dict)\n            print(""Epoch: %d, Cost: %f""%(i, cost))\n            if (i+1)%10 == 0:\n                saver.save(sess, conf.ckpt_file)\n                generate_samples(sess, X, model.h, model.pred, conf, """")\n\n        generate_samples(sess, X, model.h, model.pred, conf, """")\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--data\', type=str, default=\'mnist\')\n    parser.add_argument(\'--layers\', type=int, default=12)\n    parser.add_argument(\'--f_map\', type=int, default=32)\n    parser.add_argument(\'--epochs\', type=int, default=50)\n    parser.add_argument(\'--batch_size\', type=int, default=100)\n    parser.add_argument(\'--grad_clip\', type=int, default=1)\n    parser.add_argument(\'--model\', type=str, default=\'\')\n    parser.add_argument(\'--data_path\', type=str, default=\'data\')\n    parser.add_argument(\'--ckpt_path\', type=str, default=\'ckpts\')\n    parser.add_argument(\'--samples_path\', type=str, default=\'samples\')\n    parser.add_argument(\'--summary_path\', type=str, default=\'logs\')\n    conf = parser.parse_args()\n  \n    if conf.data == \'mnist\':\n        from tensorflow.examples.tutorials.mnist import input_data\n        if not os.path.exists(conf.data_path):\n            os.makedirs(conf.data_path)\n        data = input_data.read_data_sets(conf.data_path)\n        conf.num_classes = 10\n        conf.img_height = 28\n        conf.img_width = 28\n        conf.channel = 1\n        conf.num_batches = data.train.num_examples // conf.batch_size\n    else:\n        from keras.datasets import cifar10\n        data = cifar10.load_data()\n        labels = data[0][1]\n        data = data[0][0].astype(np.float32)\n        data[:,0,:,:] -= np.mean(data[:,0,:,:])\n        data[:,1,:,:] -= np.mean(data[:,1,:,:])\n        data[:,2,:,:] -= np.mean(data[:,2,:,:])\n        data = np.transpose(data, (0, 2, 3, 1))\n        conf.img_height = 32\n        conf.img_width = 32\n        conf.channel = 3\n        conf.num_classes = 10\n        conf.num_batches = data.shape[0] // conf.batch_size\n\n    conf = makepaths(conf) \n    if conf.model == \'\':\n        conf.conditional = False\n        train(conf, data)\n    elif conf.model.lower() == \'conditional\':\n        conf.conditional = True\n        train(conf, data)\n    elif conf.model.lower() == \'autoencoder\':\n        conf.conditional = True\n        trainAE(conf, data)\n\n\n'"
models.py,19,"b'import tensorflow as tf\nfrom layers import *\n\nclass PixelCNN(object):\n    def __init__(self, X, conf, full_horizontal=True, h=None):\n        self.X = X\n        if conf.data == ""mnist"":\n            self.X_norm = X\n        else:\n            \'\'\'\n                Image normalization for CIFAR-10 was supposed to be done here\n            \'\'\'\n            self.X_norm = X\n        v_stack_in, h_stack_in = self.X_norm, self.X_norm\n\n        if conf.conditional is True:\n            if h is not None:\n                self.h = h\n            else:\n                self.h = tf.placeholder(tf.float32, shape=[None, conf.num_classes]) \n        else:\n            self.h = None\n\n        for i in range(conf.layers):\n            filter_size = 3 if i > 0 else 7\n            mask = \'b\' if i > 0 else \'a\'\n            residual = True if i > 0 else False\n            i = str(i)\n            with tf.variable_scope(""v_stack""+i):\n                v_stack = GatedCNN([filter_size, filter_size, conf.f_map], v_stack_in, False, mask=mask, conditional=self.h).output()\n                v_stack_in = v_stack\n\n            with tf.variable_scope(""v_stack_1""+i):\n                v_stack_1 = GatedCNN([1, 1, conf.f_map], v_stack_in, False, gated=False, mask=None).output()\n\n            with tf.variable_scope(""h_stack""+i):\n                h_stack = GatedCNN([filter_size if full_horizontal else 1, filter_size, conf.f_map], h_stack_in, True, payload=v_stack_1, mask=mask, conditional=self.h).output()\n\n            with tf.variable_scope(""h_stack_1""+i):\n                h_stack_1 = GatedCNN([1, 1, conf.f_map], h_stack, True, gated=False, mask=None).output()\n                if residual:\n                    h_stack_1 += h_stack_in # Residual connection\n                h_stack_in = h_stack_1\n\n        with tf.variable_scope(""fc_1""):\n            fc1 = GatedCNN([1, 1, conf.f_map], h_stack_in, True, gated=False, mask=\'b\').output()\n\n        if conf.data == ""mnist"":\n            with tf.variable_scope(""fc_2""):\n                self.fc2 = GatedCNN([1, 1, 1], fc1, True, gated=False, mask=\'b\', activation=False).output()\n            self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.fc2, labels=self.X))\n            self.pred = tf.nn.sigmoid(self.fc2)\n        else:\n            color_dim = 256\n            with tf.variable_scope(""fc_2""):\n                self.fc2 = GatedCNN([1, 1, conf.channel * color_dim], fc1, True, gated=False, mask=\'b\', activation=False).output()\n                self.fc2 = tf.reshape(self.fc2, (-1, color_dim))\n\n            self.loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(self.fc2, tf.cast(tf.reshape(self.X, [-1]), dtype=tf.int32)))\n\n            \'\'\'\n                Since this code was not run on CIFAR-10, I\'m not sure which \n                would be a suitable way to generate 3-channel images. Below are\n                the 2 methods which may be used, with the first one (self.pred)\n                being more likely.\n            \'\'\'\n            self.pred_sampling = tf.reshape(tf.multinomial(tf.nn.softmax(self.fc2), num_samples=1, seed=100), tf.shape(self.X))\n            self.pred = tf.reshape(tf.argmax(tf.nn.softmax(self.fc2), dimension=tf.rank(self.fc2) - 1), tf.shape(self.X))\n\n\nclass ConvolutionalEncoder(object):\n    def __init__(self, X, conf):\n        \'\'\'\n            This is the 6-layer architecture for Convolutional Autoencoder\n            mentioned in the original paper: \n            Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction\n\n            Note that only the encoder part is implemented as PixelCNN is taken\n            as the decoder.\n        \'\'\'\n\n        W_conv1 = get_weights([5, 5, conf.channel, 100], ""W_conv1"")\n        b_conv1 = get_bias([100], ""b_conv1"")\n        conv1 = tf.nn.relu(conv_op(X, W_conv1) + b_conv1)\n        pool1 = max_pool_2x2(conv1)\n\n        W_conv2 = get_weights([5, 5, 100, 150], ""W_conv2"")\n        b_conv2 = get_bias([150], ""b_conv2"")\n        conv2 = tf.nn.relu(conv_op(pool1, W_conv2) + b_conv2)\n        pool2 = max_pool_2x2(conv2)\n\n        W_conv3 = get_weights([3, 3, 150, 200], ""W_conv3"")\n        b_conv3 = get_bias([200], ""b_conv3"")\n        conv3 = tf.nn.relu(conv_op(pool2, W_conv3) + b_conv3)\n        conv3_reshape = tf.reshape(conv3, (-1, 7*7*200))\n\n        W_fc = get_weights([7*7*200, 10], ""W_fc"")\n        b_fc = get_bias([10], ""b_fc"")\n        self.pred = tf.nn.softmax(tf.add(tf.matmul(conv3_reshape, W_fc), b_fc))\n\n\n'"
utils.py,3,"b'import numpy as np\nimport os\nimport scipy.misc\nfrom datetime import datetime\nimport tensorflow as tf\n\ndef binarize(images):\n    return (np.random.uniform(size=images.shape) < images).astype(np.float32)\n\ndef generate_samples(sess, X, h, pred, conf, suff):\n    print(""Generating Sample Images..."")\n    n_row, n_col = 10,10\n    samples = np.zeros((n_row*n_col, conf.img_height, conf.img_width, conf.channel), dtype=np.float32)\n    # TODO make it generic\n    labels = one_hot(np.array([0,1,2,3,4,5,6,7,8,9]*10), conf.num_classes)\n\n    for i in range(conf.img_height):\n        for j in range(conf.img_width):\n            for k in range(conf.channel):\n                data_dict = {X:samples}\n                if conf.conditional is True:\n                    data_dict[h] = labels\n                next_sample = sess.run(pred, feed_dict=data_dict)\n                if conf.data == ""mnist"":\n                    next_sample = binarize(next_sample)\n                samples[:, i, j, k] = next_sample[:, i, j, k]\n\n    save_images(samples, n_row, n_col, conf, suff)\n\n\ndef generate_ae(sess, encoder_X, decoder_X, y, data, conf, suff=\'\'):\n    print(""Generating Sample Images..."")\n    n_row, n_col = 10,10\n    samples = np.zeros((n_row*n_col, conf.img_height, conf.img_width, conf.channel), dtype=np.float32)\n    if conf.data == \'mnist\':\n        labels = binarize(data.train.next_batch(n_row*n_col)[0].reshape(n_row*n_col, conf.img_height, conf.img_width, conf.channel))\n    else:\n        labels = get_batch(data, 0, n_row*n_col) \n\n    for i in range(conf.img_height):\n        for j in range(conf.img_width):\n            for k in range(conf.channel):\n                next_sample = sess.run(y, {encoder_X: labels, decoder_X: samples})\n                if conf.data == \'mnist\':\n                    next_sample = binarize(next_sample)\n                samples[:, i, j, k] = next_sample[:, i, j, k]\n\n    save_images(samples, n_row, n_col, conf, suff)\n\n\ndef save_images(samples, n_row, n_col, conf, suff):\n    images = samples \n    if conf.data == ""mnist"":\n        images = images.reshape((n_row, n_col, conf.img_height, conf.img_width))\n        images = images.transpose(1, 2, 0, 3)\n        images = images.reshape((conf.img_height * n_row, conf.img_width * n_col))\n    else:\n        images = images.reshape((n_row, n_col, conf.img_height, conf.img_width, conf.channel))\n        images = images.transpose(1, 2, 0, 3, 4)\n        images = images.reshape((conf.img_height * n_row, conf.img_width * n_col, conf.channel))\n\n    filename = datetime.now().strftime(\'%Y_%m_%d_%H_%M\')+suff+"".jpg""\n    scipy.misc.toimage(images, cmin=0.0, cmax=1.0).save(os.path.join(conf.samples_path, filename))\n\n\ndef get_batch(data, pointer, batch_size):\n    if (batch_size + 1) * pointer >= data.shape[0]:\n        pointer = 0\n    batch = data[batch_size * pointer : batch_size * (pointer + 1)]\n    pointer += 1\n    return [batch, pointer]\n\n\ndef one_hot(batch_y, num_classes):\n    y_ = np.zeros((batch_y.shape[0], num_classes))\n    y_[np.arange(batch_y.shape[0]), batch_y] = 1\n    return y_\n\n\ndef makepaths(conf):\n    ckpt_full_path = os.path.join(conf.ckpt_path, ""data=%s_bs=%d_layers=%d_fmap=%d""%(conf.data, conf.batch_size, conf.layers, conf.f_map))\n    if not os.path.exists(ckpt_full_path):\n        os.makedirs(ckpt_full_path)\n    conf.ckpt_file = os.path.join(ckpt_full_path, ""model.ckpt"")\n\n    conf.samples_path = os.path.join(conf.samples_path, ""epoch=%d_bs=%d_layers=%d_fmap=%d""%(conf.epochs, conf.batch_size, conf.layers, conf.f_map))\n    if not os.path.exists(conf.samples_path):\n        os.makedirs(conf.samples_path)\n\n    if tf.gfile.Exists(conf.summary_path):\n        tf.gfile.DeleteRecursively(conf.summary_path)\n    tf.gfile.MakeDirs(conf.summary_path)\n\n    return conf\n'"
