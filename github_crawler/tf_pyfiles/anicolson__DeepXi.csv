file_path,api_count,code
main.py,0,"b'## AUTHOR:         Aaron Nicolson\n## AFFILIATION:    Signal Processing Laboratory, Griffith University\n##\n## This Source Code Form is subject to the terms of the Mozilla Public\n## License, v. 2.0. If a copy of the MPL was not distributed with this\n## file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\nfrom deepxi.args import get_args\nfrom deepxi.model import DeepXi\nfrom deepxi.prelim import Prelim\nfrom deepxi.se_batch import Batch\nimport deepxi.utils as utils\nimport numpy as np\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\'] = \'3\'\n\nif __name__ == \'__main__\':\n\n\targs = get_args()\n\n\tif args.causal: padding = ""causal""\n\telse: padding = ""same""\n\n\targs.model_path = args.model_path + \'/\' + args.ver # model save path.\n\tif args.set_path != ""set"": args.data_path = args.data_path + \'/\' + args.set_path.rsplit(\'/\', 1)[-1] # data path.\n\ttrain_s_path = args.set_path + \'/train_clean_speech\' # path to the clean speech training set.\n\ttrain_d_path = args.set_path + \'/train_noise\' # path to the noise training set.\n\tval_s_path = args.set_path + \'/val_clean_speech\' # path to the clean speech validation set.\n\tval_d_path = args.set_path + \'/val_noise\' # path to the noise validation set.\n\tN_d = int(args.f_s*args.T_d*0.001) # window duration (samples).\n\tN_s = int(args.f_s*args.T_s*0.001) # window shift (samples).\n\tNFFT = int(pow(2, np.ceil(np.log2(N_d)))) # number of DFT components.\n\n\tif args.train:\n\t\ttrain_s_list = utils.batch_list(train_s_path, \'clean_speech\', args.data_path)\n\t\ttrain_d_list = utils.batch_list(train_d_path, \'noise\', args.data_path)\n\t\tif args.val_flag:\n\t\t\tval_s, val_d, val_s_len, val_d_len, val_snr = utils.val_wav_batch(val_s_path, val_d_path)\n\t\telse: val_s, val_d, val_s_len, val_d_len, val_snr = None, None, None, None, None\n\n\tif args.infer or args.test:\n\t\targs.out_path = args.out_path + \'/\' + args.ver + \'/\' + \'e\' + str(args.test_epoch) # output path.\n\t\ttest_x, test_x_len, _, test_x_base_names = Batch(args.test_x_path)\n\t\tif args.test: test_s, test_s_len, _, test_s_base_names = Batch(args.test_s_path)\n\n\tconfig = utils.gpu_config(args.gpu)\n\n\tprint(""Version: %s."" % (args.ver))\n\n\tdeepxi = DeepXi(\n\t\tN_d=N_d,\n\t\tN_s=N_s,\n\t\tNFFT=NFFT,\n\t\tf_s=args.f_s,\n\t\tnetwork_type=args.network_type,\n\t\tmin_snr=args.min_snr,\n\t\tmax_snr=args.max_snr,\n\t\tsnr_inter=args.snr_inter,\n\t\td_model=args.d_model,\n\t\tn_blocks=args.n_blocks,\n\t\tn_heads=args.n_heads,\n\t\td_f=args.d_f,\n\t\td_ff=args.d_ff,\n\t\tk=args.k,\n\t\tmax_d_rate=args.max_d_rate,\n\t\twarmup_steps=args.warmup_steps,\n\t\tpadding=padding,\n\t\tcausal=args.causal,\n\t\tver=args.ver,\n\t\t)\n\n\tif args.train: deepxi.train(\n\t\ttrain_s_list=train_s_list,\n\t\ttrain_d_list=train_d_list,\n\t\tmodel_path=args.model_path,\n\t\tval_s=val_s,\n\t\tval_d=val_d,\n\t\tval_s_len=val_s_len,\n\t\tval_d_len=val_d_len,\n\t\tval_snr=val_snr,\n\t\tval_save_path=args.data_path,\n\t\tval_flag=args.val_flag,\n\t\tstats_path=args.data_path,\n\t\tsample_size=args.sample_size,\n\t\tmbatch_size=args.mbatch_size,\n\t\tmax_epochs=args.max_epochs,\n\t\tresume_epoch=args.resume_epoch,\n\t\teval_example=args.eval_example,\n\t\tlog_iter=args.log_iter,\n\t\t)\n\n\tif args.infer: deepxi.infer(\n\t\ttest_x=test_x,\n\t\ttest_x_len=test_x_len,\n\t\ttest_x_base_names=test_x_base_names,\n\t\ttest_epoch=args.test_epoch,\n\t\tmodel_path=args.model_path,\n\t\tout_type=args.out_type,\n\t\tgain=args.gain,\n\t\tout_path=args.out_path,\n\t\tstats_path=args.data_path,\n\t\tn_filters=args.n_filters,\n\t\t)\n\n\tif args.test: deepxi.test(\n\t\ttest_x=test_x,\n\t\ttest_x_len=test_x_len,\n\t\ttest_x_base_names=test_x_base_names,\n\t\ttest_s=test_s,\n\t\ttest_s_len=test_s_len,\n\t\ttest_s_base_names=test_s_base_names,\n\t\ttest_epoch=args.test_epoch,\n\t\tmodel_path=args.model_path,\n\t\tgain=args.gain,\n\t\tstats_path=args.data_path,\n\t\t)\n'"
deepxi/args.py,0,"b'## AUTHOR:         Aaron Nicolson\n## AFFILIATION:    Signal Processing Laboratory, Griffith University.\n##\n## This Source Code Form is subject to the terms of the Mozilla Public\n## License, v. 2.0. If a copy of the MPL was not distributed with this\n## file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\nimport argparse\n\ndef read_dtype(x):\n\tif any(map(str.isdigit, x)):\n\t\tif \'.\' in x: return float(x)\n\t\telse: return int(x)\n\telse: return x\ndef str_to_list(x):\n\tif (\';\' in x) and (\',\' in x): return [[read_dtype(z) for z in y.split(\',\')] for y in x.split(\';\')]\n\telif \',\' in x: return [read_dtype(y) for y in x.split(\',\')]\n\telse: return read_dtype(x)\ndef str_to_bool(s): return s.lower() in (""yes"", ""true"", ""t"", ""1"")\n\ndef get_args():\n\tparser = argparse.ArgumentParser()\n\n\t## OPTIONS (GENERAL)\n\tparser.add_argument(\'--gpu\', default=\'0\', type=str, help=\'GPU selection\')\n\tparser.add_argument(\'--ver\', type=str, help=\'Model version\')\n\tparser.add_argument(\'--test_epoch\', type=str_to_list, help=\'Epoch to test\')\n\tparser.add_argument(\'--train\', default=False, type=str_to_bool, help=\'Perform training\')\n\tparser.add_argument(\'--infer\', default=False, type=str_to_bool, help=\'Perform inference and save outputs\')\n\tparser.add_argument(\'--test\', default=False, type=str_to_bool, help=\'Evaluate using objective measures\')\n\tparser.add_argument(\'--prelim\', default=False, type=str_to_bool, help=\'Preliminary flag\')\n\tparser.add_argument(\'--verbose\', default=False, type=str_to_bool, help=\'Verbose\')\n\tparser.add_argument(\'--network_type\', type=str, help=\'Network type\')\n\n\t## OPTIONS (TRAIN)\n\tparser.add_argument(\'--mbatch_size\', type=int, help=\'Mini-batch size\')\n\tparser.add_argument(\'--sample_size\', type=int, help=\'Sample size\')\n\tparser.add_argument(\'--max_epochs\', type=int, help=\'Maximum number of epochs\')\n\tparser.add_argument(\'--resume_epoch\', type=int, help=\'Epoch to resume training from\')\n\tparser.add_argument(\'--save_model\', default=False, type=str_to_bool, help=\'Save architecture, weights, and training configuration\')\n\tparser.add_argument(\'--log_iter\', default=False, type=str_to_bool, help=\'Log loss per training iteration\')\n\tparser.add_argument(\'--eval_example\', default=False, type=str_to_bool, help=\'Evaluate a mini-batch of training examples\')\n\tparser.add_argument(\'--val_flag\', default=True, type=str_to_bool, help=\'Use validation set\')\n\n\t# INFERENCE OUTPUT TYPE\n\t# \'xi_hat\' - a priori SNR estimate (.mat),\n\t# \'gain\' - gain function (.mat),\n\t# \'deepmmse\' - noise PSD estimate using DeepMMSE (.mat),\n\t# \'y\' - enhanced speech (.wav),\n\t# \'d_hat\' - noise estimate using DeepMMSE (.wav).\n\tparser.add_argument(\'--out_type\', default=\'y\', type=str, help=\'Output type for testing\')\n\n\t## GAIN FUNCTION\n\t# \'ibm\' - ideal binary mask (IBM),\n\t# \'wf\' - Wiener filter (WF),\n\t# \'srwf\' - square-root Wiener filter (SRWF),\n\t# \'cwf\' - constrained Wiener filter (cWF),\n\t# \'mmse-stsa\' - minimum-mean square error short-time spectral smplitude (MMSE-STSA) estimator,\n\t# \'mmse-lsa\' - minimum-mean square error log-spectral amplitude (MMSE-LSA) estimator.\n\tparser.add_argument(\'--gain\', default=\'mmse-lsa\', type=str_to_list, help=\'Gain function for testing\')\n\n\t## PATHS\n\tparser.add_argument(\'--model_path\', default=\'model\', type=str, help=\'Model save path\')\n\tparser.add_argument(\'--set_path\', default=\'set\', type=str, help=\'Path to datasets\')\n\tparser.add_argument(\'--data_path\', default=\'data\', type=str, help=\'Save data path\')\n\tparser.add_argument(\'--test_x_path\', default=\'set/test_noisy_speech\', type=str, help=\'Path to the noisy-speech test set\')\n\tparser.add_argument(\'--test_s_path\', default=\'set/test_clean_speech\', type=str, help=\'Path to the clean-speech test set\')\n\tparser.add_argument(\'--out_path\', default=\'out\', type=str, help=\'Output path\')\n\n\t## FEATURES\n\tparser.add_argument(\'--min_snr\', type=int, help=\'Minimum trained SNR level\')\n\tparser.add_argument(\'--max_snr\', type=int, help=\'Maximum trained SNR level\')\n\tparser.add_argument(\'--snr_inter\', type=int, help=\'Interval between SNR levels\')\n\tparser.add_argument(\'--f_s\', type=int, help=\'Sampling frequency (Hz)\')\n\tparser.add_argument(\'--T_d\', type=int, help=\'Window duration (ms)\')\n\tparser.add_argument(\'--T_s\', type=int, help=\'Window shift (ms)\')\n\tparser.add_argument(\'--n_filters\', default=None, type=int, help=\'Number of filters for subband ideal binary mask (IBM)\')\n\n\t## NETWORK PARAMETERS\n\tparser.add_argument(\'--d_in\', type=int, help=\'Input dimensionality\')\n\tparser.add_argument(\'--d_out\', type=int, help=\'Ouput dimensionality\')\n\tparser.add_argument(\'--d_model\', type=int, help=\'Model dimensions\')\n\tparser.add_argument(\'--n_blocks\', type=int, help=\'Number of blocks\')\n\tparser.add_argument(\'--n_heads\', type=int, help=\'Number of attention heads\')\n\tparser.add_argument(\'--d_f\', default=None, type=int, help=\'Number of filters\')\n\tparser.add_argument(\'--d_ff\', default=None, type=int, help=\'Feed forward size\')\n\tparser.add_argument(\'--k\', default=None, type=int, help=\'Kernel size\')\n\tparser.add_argument(\'--max_d_rate\', default=None, type=int, help=\'Maximum dilation rate\')\n\tparser.add_argument(\'--causal\', type=str_to_bool, help=\'Causal network\')\n\tparser.add_argument(\'--warmup_steps\', type=int, help=\'Number of warmup steps\')\n\n\tparser.add_argument(\'--net_height\', default=[4], type=list, help=\'RDL block height\')\n\n\targs = parser.parse_args()\n\treturn args\n'"
deepxi/gain.py,0,"b'## AUTHOR:         Aaron Nicolson\n## AFFILIATION:    Signal Processing Laboratory, Griffith University\n##\n## This Source Code Form is subject to the terms of the Mozilla Public\n## License, v. 2.0. If a copy of the MPL was not distributed with this\n## file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\nimport numpy as np\nfrom scipy.special import exp1, i0, i1\n\ndef mmse_stsa(xi, gamma):\n\t""""""\n\tComputes the MMSE-STSA gain function.\n\n\tArgument/s:\n\t\txi - a priori SNR.\n\t\tgamma - a posteriori SNR.\n\n\tReturns:\n\t\tG - MMSE-STSA gain function.\n\t""""""\n\tnu = np.multiply(xi, np.divide(gamma, np.add(1, xi)))\n\tG = np.multiply(np.multiply(np.multiply(np.divide(np.sqrt(np.pi), 2),\n\t\tnp.divide(np.sqrt(nu), gamma)), np.exp(np.divide(-nu,2))),\n\t\tnp.add(np.multiply(np.add(1, nu), i0(np.divide(nu,2))),\n\t\tnp.multiply(nu, i1(np.divide(nu, 2))))) # MMSE-STSA gain function.\n\tidx = np.isnan(G) | np.isinf(G) # replace by Wiener gain.\n\tG[idx] = np.divide(xi[idx], np.add(1, xi[idx])) # Wiener gain.\n\treturn G\n\ndef mmse_lsa(xi, gamma):\n\t""""""\n\tComputes the MMSE-LSA gain function.\n\n\tArgument/s:\n\t\txi - a priori SNR.\n\t\tgamma - a posteriori SNR.\n\n\tReturns:\n\t\tMMSE-LSA gain function.\n\t""""""\n\tnu = np.multiply(np.divide(xi, np.add(1, xi)), gamma)\n\treturn np.multiply(np.divide(xi, np.add(1, xi)), np.exp(np.multiply(0.5, exp1(nu)))) # MMSE-LSA gain function.\n\ndef wf(xi):\n\t""""""\n\tComputes the Wiener filter (WF) gain function.\n\n\tArgument/s:\n\t\txi - a priori SNR.\n\n\tReturns:\n\t\tWF gain function.\n\t""""""\n\treturn np.divide(xi, np.add(xi, 1.0)) # WF gain function.\n\ndef srwf(xi):\n\t""""""\n\tComputes the square-root Wiener filter (WF) gain function.\n\n\tArgument/s:\n\t\txi - a priori SNR.\n\n\tReturns:\n\t\tSRWF gain function.\n\t""""""\n\treturn np.sqrt(wf(xi)) # SRWF gain function.\n\ndef cwf(xi):\n\t""""""\n\tComputes the constrained Wiener filter (WF) gain function.\n\n\tArgument/s:\n\t\txi - a priori SNR.\n\n\tReturns:\n\t\tcWF gain function.\n\t""""""\n\treturn wf(np.sqrt(xi)) # cWF gain function.\n\ndef irm(xi):\n\t""""""\n\tComputes the ideal ratio mask (IRM).\n\n\tArgument/s:\n\t\txi - a priori SNR.\n\n\tReturns:\n\t\tIRM.\n\t""""""\n\treturn srwf(xi) # IRM.\n\n\ndef ibm(xi):\n\t""""""\n\tComputes the ideal binary mask (IBM) with a threshold of 0 dB.\n\n\tArgument/s:\n\t\txi - a priori SNR.\n\n\tReturns:\n\t\tIBM.\n\t""""""\n\treturn np.greater(xi, 1, dtype=np.float32) # IBM (1 corresponds to 0 dB).\n\n\ndef deepmmse(xi, gamma):\n\t""""""\n\tDeepMMSE utilises the MMSE noise periodogram estimate gain function.\n\n\tArgument/s:\n\t\txi - a priori SNR.\n\t\tgamma - a posteriori SNR.\n\n\tReturns:\n\t\tMMSE-Noise_PSD gain function.\n\t""""""\n\treturn np.add(np.divide(1, np.add(1, xi)),\n\t\tnp.divide(xi, np.multiply(gamma, np.add(1, xi)))) # MMSE noise periodogram estimate gain function.\n\ndef gfunc(xi, gamma=None, gtype=\'mmse-lsa\'):\n\t""""""\n\tComputes the selected gain function.\n\n\tArgument/s:\n\t\txi - a priori SNR.\n\t\tgamma - a posteriori SNR.\n\t\tgtype - gain function type.\n\n\tReturns:\n\t\tG - gain function.\n\t""""""\n\tif gtype == \'mmse-lsa\': G = mmse_lsa(xi, gamma)\n\telif gtype == \'mmse-stsa\':  G = mmse_stsa(xi, gamma)\n\telif gtype == \'wf\': G = wf(xi)\n\telif gtype == \'srwf\': G = srwf(xi)\n\telif gtype == \'cwf\': G = cwf(xi)\n\telif gtype == \'irm\': G = irm(xi)\n\telif gtype == \'ibm\': G = ibm(xi)\n\telif gtype == \'deepmmse\': G = deepmmse(xi, gamma)\n\telse: raise ValueError(\'Invalid gain function type.\')\n\treturn G\n'"
deepxi/model.py,22,"b'## AUTHOR:         Aaron Nicolson\n## AFFILIATION:    Signal Processing Laboratory, Griffith University\n##\n## This Source Code Form is subject to the terms of the Mozilla Public\n## License, v. 2.0. If a copy of the MPL was not distributed with this\n## file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\nfrom deepxi.gain import gfunc\nfrom deepxi.network.rnn import ResLSTM\nfrom deepxi.network.tcn import ResNet\nfrom deepxi.sig import DeepXiInput\nfrom deepxi.utils import read_wav, save_wav, save_mat\nfrom pesq import pesq\nfrom pystoi import stoi\nfrom tensorflow.keras.callbacks import Callback, CSVLogger, ModelCheckpoint\nfrom tensorflow.keras.layers import Input, Masking\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import LearningRateSchedule\nfrom tensorflow.python.lib.io import file_io\n# from tensorflow.python.util.compat import collections_abc\nfrom tqdm import tqdm\nimport deepxi.se_batch as batch\nimport csv, math, os, random # collections, io, six\nimport numpy as np\nimport tensorflow as tf\n\n# [1] Nicolson, A. and Paliwal, K.K., 2019. Deep learning for\n# \t  minimum mean-square error approaches to speech enhancement.\n# \t  Speech Communication, 111, pp.44-55.\n\nclass DeepXi(DeepXiInput):\n\t""""""\n\tDeep Xi model from [1].\n\t""""""\n\tdef __init__(\n\t\tself,\n\t\tN_d,\n\t\tN_s,\n\t\tNFFT,\n\t\tf_s,\n\t\tnetwork_type,\n\t\tmin_snr,\n\t\tmax_snr,\n\t\tsnr_inter,\n\t\tver=\'VERSION_NAME\',\n\t\t**kwargs\n\t\t):\n\t\t""""""\n\t\tArgument/s\n\t\t\tN_d - window duration (samples).\n\t\t\tN_s - window shift (samples).\n\t\t\tNFFT - number of DFT bins.\n\t\t\tf_s - sampling frequency.\n\t\t\tnetwork - network type.\n\t\t\tmin_snr - minimum SNR level for training.\n\t\t\tmax_snr - maximum SNR level for training.\n\t\t\tver - version name.\n\t\t""""""\n\t\tsuper().__init__(N_d, N_s, NFFT, f_s)\n\t\tself.min_snr = min_snr\n\t\tself.max_snr = max_snr\n\t\tself.snr_levels = list(range(self.min_snr, self.max_snr + 1, snr_inter))\n\t\tself.ver = ver\n\t\tself.n_feat = math.ceil(self.NFFT/2 + 1)\n\t\tself.n_outp = self.n_feat\n\t\tself.inp = Input(name=\'inp\', shape=[None, self.n_feat], dtype=\'float32\')\n\t\tself.mask = Masking(mask_value=0.0)(self.inp)\n\t\tself.network_type = network_type\n\n\t\tif self.network_type == \'MHANet\':\n\t\t\tfrom deepxi.network.attention import MHANet\n\t\t\tself.network = MHANet(\n\t\t\t\tinp=self.mask,\n\t\t\t\tn_outp=self.n_outp,\n\t\t\t\td_model=kwargs[\'d_model\'],\n\t\t\t\tn_blocks=kwargs[\'n_blocks\'],\n\t\t\t\tn_heads=kwargs[\'n_heads\'],\n\t\t\t\td_ff=kwargs[\'d_ff\'],\n\t\t\t\twarmup_steps=kwargs[\'warmup_steps\'],\n\t\t\t\tcausal=kwargs[\'causal\'],\n\t\t\t\t)\n\t\telif self.network_type == \'ResNet\':\n\t\t\tself.network = ResNet(\n\t\t\t\tinp=self.mask,\n\t\t\t\tn_outp=self.n_outp,\n\t\t\t\tn_blocks=kwargs[\'n_blocks\'],\n\t\t\t\td_model=kwargs[\'d_model\'],\n\t\t\t\td_f=kwargs[\'d_f\'],\n\t\t\t\tk=kwargs[\'k\'],\n\t\t\t\tmax_d_rate=kwargs[\'max_d_rate\'],\n\t\t\t\tpadding=kwargs[\'padding\'],\n\t\t\t\t)\n\t\telif self.network_type == \'ResLSTM\':\n\t\t\tself.network = ResLSTM(\n\t\t\t\tinp=self.mask,\n\t\t\t\tn_outp=self.n_outp,\n\t\t\t\tn_blocks=kwargs[\'n_blocks\'],\n\t\t\t\td_model=kwargs[\'d_model\'],\n\t\t\t\t)\n\t\telse: raise ValueError(\'Invalid network type.\')\n\t\tself.model = Model(inputs=self.inp, outputs=self.network.outp)\n\t\tself.model.summary()\n\t\tif not os.path.exists(""log/summary""):\n\t\t\tos.makedirs(""log/summary"")\n\t\twith open(""log/summary/"" + self.ver + "".txt"", ""w"") as f:\n\t\t\tself.model.summary(print_fn=lambda x: f.write(x + \'\\n\'))\n\n\tdef train(\n\t\tself,\n\t\ttrain_s_list,\n\t\ttrain_d_list,\n\t\tmodel_path=\'model\',\n\t\tval_s=None,\n\t\tval_d=None,\n\t\tval_s_len=None,\n\t\tval_d_len=None,\n\t\tval_snr=None,\n\t\tval_flag=True,\n\t\tval_save_path=None,\n\t\tmbatch_size=8,\n\t\tmax_epochs=200,\n\t\tresume_epoch=0,\n\t\tstats_path=None,\n\t\tsample_size=None,\n\t\teval_example=False,\n\t\tsave_model=True,\n\t\tlog_iter=False,\n\t\t):\n\t\t""""""\n\t\tDeep Xi training.\n\n\t\tArgument/s:\n\t\t\ttrain_s_list - clean-speech training list.\n\t\t\ttrain_d_list - noise training list.\n\t\t\tmodel_path - model save path.\n\t\t\tval_s - clean-speech validation batch.\n\t\t\tval_d - noise validation batch.\n\t\t\tval_s_len - clean-speech validation sequence length batch.\n\t\t\tval_d_len - noise validation sequence length batch.\n\t\t\tval_snr - SNR validation batch.\n\t\t\tval_flag - perform validation.\n\t\t\tval_save_path - validation batch save path.\n\t\t\tmbatch_size - mini-batch size.\n\t\t\tmax_epochs - maximum number of epochs.\n\t\t\tresume_epoch - epoch to resume training from.\n\t\t\tstats_path - path to save sample statistics.\n\t\t\tsample_size - sample size.\n\t\t\teval_example - evaluate a mini-batch of training examples.\n\t\t\tsave_model - save architecture, weights, and training configuration.\n\t\t\tlog_iter - log training loss for each training iteration.\n\t\t""""""\n\t\tself.train_s_list = train_s_list\n\t\tself.train_d_list = train_d_list\n\t\tself.mbatch_size = mbatch_size\n\t\tself.n_examples = len(self.train_s_list)\n\t\tself.n_iter = math.ceil(self.n_examples/mbatch_size)\n\n\t\tself.sample_stats(stats_path, sample_size, train_s_list, train_d_list)\n\n\t\ttrain_dataset = self.dataset(max_epochs-resume_epoch)\n\n\t\tif val_flag:\n\t\t\tval_set = self.val_batch(val_save_path, val_s, val_d, val_s_len, val_d_len, val_snr)\n\t\t\tval_steps = len(val_set[0])\n\t\telse: val_set, val_steps = None, None\n\n\t\tif eval_example:\n\t\t\tprint(""Saving a mini-batch of training examples in .mat files..."")\n\t\t\tx_STMS_batch, xi_bar_batch, seq_mask_batch = list(train_dataset.take(1).as_numpy_iterator())[0]\n\t\t\tsave_mat(\'./x_STMS_batch.mat\', x_STMS_batch, \'x_STMS_batch\')\n\t\t\tsave_mat(\'./xi_bar_batch.mat\', xi_bar_batch, \'xi_bar_batch\')\n\t\t\tsave_mat(\'./seq_mask_batch.mat\', seq_mask_batch, \'seq_mask_batch\')\n\t\t\tprint(""Testing if add_noise() works correctly..."")\n\t\t\ts, d, s_len, d_len, snr_tgt = self.wav_batch(train_s_list[0:mbatch_size], train_d_list[0:mbatch_size])\n\t\t\t(_, s, d) = self.add_noise_batch(self.normalise(s), self.normalise(d), s_len, d_len, snr_tgt)\n\t\t\tfor (i, _) in enumerate(s):\n\t\t\t\tsnr_act = self.snr_db(s[i][0:s_len[i]], d[i][0:d_len[i]])\n\t\t\t\tprint(\'SNR target|actual: {:.2f}|{:.2f} (dB).\'.format(snr_tgt[i], snr_act))\n\n\t\tif not os.path.exists(model_path): os.makedirs(model_path)\n\t\tif not os.path.exists(""log""): os.makedirs(""log"")\n\t\tif not os.path.exists(""log/iter""): os.makedirs(""log/iter"")\n\n\t\tcallbacks = []\n\t\tcallbacks.append(CSVLogger(""log/"" + self.ver + "".csv"", separator=\',\', append=True))\n\t\tif save_model: callbacks.append(SaveWeights(model_path))\n\n\t\t# if log_iter: callbacks.append(CSVLoggerIter(""log/iter/"" + self.ver + "".csv"", separator=\',\', append=True))\n\n\t\tif resume_epoch > 0: self.model.load_weights(model_path + ""/epoch-"" +\n\t\t\tstr(resume_epoch-1) + ""/variables/variables"" )\n\n\t\tif self.network_type == ""MHANet"":\n\t\t\tlr_schedular = TransformerSchedular(self.network.d_model,\n\t\t\t\tself.network.warmup_steps)\n\t\t\topt = Adam(learning_rate=lr_schedular, clipvalue=1.0, beta_1=0.9,\n\t\t\t\tbeta_2=0.98, epsilon=1e-9)\n\t\telse:\n\t\t\topt = Adam(learning_rate=0.001, clipvalue=1.0)\n\n\t\tself.model.compile(\n\t\t\tsample_weight_mode=""temporal"",\n\t\t\tloss=""binary_crossentropy"",\n\t\t\toptimizer=opt\n\t\t\t)\n\n\t\tprint(""SNR levels used for training:"")\n\t\tprint(self.snr_levels)\n\n\t\tself.model.fit(\n\t\t\tx=train_dataset,\n\t\t\tinitial_epoch=resume_epoch,\n\t\t\tepochs=max_epochs,\n\t\t\tsteps_per_epoch=self.n_iter,\n\t\t\tcallbacks=callbacks,\n\t\t\tvalidation_data=val_set,\n\t\t\tvalidation_steps=val_steps\n\t\t\t)\n\n\tdef infer( ## NEED TO ADD DeepMMSE\n\t\tself,\n\t\ttest_x,\n\t\ttest_x_len,\n\t\ttest_x_base_names,\n\t\ttest_epoch,\n\t\tmodel_path=\'model\',\n\t\tout_type=\'y\',\n\t\tgain=\'mmse-lsa\',\n\t\tout_path=\'out\',\n\t\tstats_path=None,\n\t\tn_filters=40,\n\t\t):\n\t\t""""""\n\t\tDeep Xi inference. The specified \'out_type\' is saved.\n\n\t\tArgument/s:\n\t\t\ttest_x - noisy-speech test batch.\n\t\t\ttest_x_len - noisy-speech test batch lengths.\n\t\t\ttest_x_base_names - noisy-speech base names.\n\t\t\ttest_epoch - epoch to test.\n\t\t\tmodel_path - path to model directory.\n\t\t\tout_type - output type (see deepxi/args.py).\n\t\t\tgain - gain function (see deepxi/args.py).\n\t\t\tout_path - path to save output files.\n\t\t\tstats_path - path to the saved statistics.\n\t\t""""""\n\t\tif out_type == \'xi_hat\': out_path = out_path + \'/xi_hat\'\n\t\telif out_type == \'y\': out_path = out_path + \'/y/\' + gain\n\t\telif out_type == \'deepmmse\': out_path = out_path + \'/deepmmse\'\n\t\telif out_type == \'ibm_hat\': out_path = out_path + \'/ibm_hat\'\n\t\telif out_type == \'subband_ibm_hat\': out_path = out_path + \'/subband_ibm_hat\'\n\t\telse: raise ValueError(\'Invalid output type.\')\n\t\tif not os.path.exists(out_path): os.makedirs(out_path)\n\n\t\tif test_epoch < 1: raise ValueError(""test_epoch must be greater than 0."")\n\n\t\t# The mel-scale filter bank is to compute an ideal binary mask (IBM)\n\t\t# estimate for log-spectral subband energies (LSSE).\n\t\tif out_type == \'subband_ibm_hat\':\n\t\t\tmel_filter_bank = self.mel_filter_bank(n_filters)\n\n\t\tself.sample_stats(stats_path)\n\t\tself.model.load_weights(model_path + \'/epoch-\' + str(test_epoch-1) +\n\t\t\t\'/variables/variables\' )\n\n\t\tprint(""Processing observations..."")\n\t\tx_STMS_batch, x_STPS_batch, n_frames = self.observation_batch(test_x, test_x_len)\n\t\tprint(""Performing inference..."")\n\t\txi_bar_hat_batch = self.model.predict(x_STMS_batch, batch_size=1, verbose=1)\n\n\t\tprint(""Performing synthesis..."")\n\t\tbatch_size = len(test_x_len)\n\t\tfor i in tqdm(range(batch_size)):\n\t\t\tbase_name = test_x_base_names[i]\n\t\t\tx_STMS = x_STMS_batch[i,:n_frames[i],:]\n\t\t\tx_STPS = x_STPS_batch[i,:n_frames[i],:]\n\t\t\txi_bar_hat = xi_bar_hat_batch[i,:n_frames[i],:]\n\t\t\txi_hat = self.xi_hat(xi_bar_hat)\n\t\t\tif out_type == \'xi_hat\': save_mat(args.out_path + \'/\' + base_name + \'.mat\',\n\t\t\t\txi_hat, \'xi_hat\')\n\t\t\telif out_type == \'y\':\n\t\t\t\ty_STMS = np.multiply(x_STMS, gfunc(xi_hat, xi_hat+1, gtype=gain))\n\t\t\t\ty = self.polar_synthesis(y_STMS, x_STPS).numpy()\n\t\t\t\tsave_wav(out_path + \'/\' + base_name + \'.wav\', y, self.f_s)\n\t\t\telif out_type == \'deepmmse\':\n\t\t\t\td_PSD_hat = np.multiply(np.square(x_STMS), gfunc(xi_hat, xi_hat+1,\n\t\t\t\t\tgtype=\'deepmmse\'))\n\t\t\t\tsave_mat(out_path + \'/\' + base_name + \'.mat\', d_PSD_hat, \'d_psd_hat\')\n\t\t\telif out_type == \'ibm_hat\':\n\t\t\t\tibm_hat = np.greater(xi_hat, 1.0).astype(bool)\n\t\t\t\tsave_mat(out_path + \'/\' + base_name + \'.mat\', ibm_hat, \'ibm_hat\')\n\t\t\telif out_type == \'subband_ibm_hat\':\n\t\t\t\txi_hat_subband = np.matmul(xi_hat, mel_filter_bank.transpose())\n\t\t\t\tsubband_ibm_hat = np.greater(xi_hat_subband, 1.0).astype(bool)\n\t\t\t\tsave_mat(out_path + \'/\' + base_name + \'.mat\', subband_ibm_hat,\n\t\t\t\t\t\'subband_ibm_hat\')\n\t\t\telse: raise ValueError(\'Invalid output type.\')\n\n\tdef test(\n\t\tself,\n\t\ttest_x,\n\t\ttest_x_len,\n\t\ttest_x_base_names,\n\t\ttest_s,\n\t\ttest_s_len,\n\t\ttest_s_base_names,\n\t\ttest_epoch,\n\t\tmodel_path=\'model\',\n\t\tgain=\'mmse-lsa\',\n\t\tstats_path=None\n\t\t):\n\t\t""""""\n\t\tDeep Xi testing. Objective measures are used to evaluate the performance\n\t\tof Deep Xi.\n\n\t\tArgument/s:\n\t\t\ttest_x - noisy-speech test batch.\n\t\t\ttest_x_len - noisy-speech test batch lengths.\n\t\t\ttest_x_base_names - noisy-speech base names.\n\t\t\ttest_s - clean-speech test batch.\n\t\t\ttest_s_len - clean-speech test batch lengths.\n\t\t\ttest_s_base_names - clean-speech base names.\n\t\t\ttest_epoch - epoch to test.\n\t\t\tmodel_path - path to model directory.\n\t\t\tgain - gain function (see deepxi/args.py).\n\t\t\tstats_path - path to the saved statistics.\n\n\t\t""""""\n\t\tif not isinstance(test_epoch, list): test_epoch = [test_epoch]\n\t\tif not isinstance(gain, list): gain = [gain]\n\t\tfor e in test_epoch:\n\t\t\tfor g in gain:\n\n\t\t\t\tif e < 1: raise ValueError(""test_epoch must be greater than 0."")\n\n\t\t\t\tself.sample_stats(stats_path)\n\t\t\t\tself.model.load_weights(model_path + \'/epoch-\' + str(e-1) +\n\t\t\t\t\t\'/variables/variables\' )\n\n\t\t\t\tprint(""Processing observations..."")\n\t\t\t\tx_STMS_batch, x_STPS_batch, n_frames = self.observation_batch(test_x, test_x_len)\n\t\t\t\tprint(""Performing inference..."")\n\t\t\t\txi_bar_hat_batch = self.model.predict(x_STMS_batch, batch_size=1, verbose=1)\n\n\t\t\t\tprint(""Performing synthesis and objective scoring..."")\n\t\t\t\tresults = {}\n\t\t\t\tbatch_size = len(test_x_len)\n\t\t\t\tfor i in tqdm(range(batch_size)):\n\t\t\t\t\tbase_name = test_x_base_names[i]\n\t\t\t\t\tx_STMS = x_STMS_batch[i,:n_frames[i],:]\n\t\t\t\t\tx_STPS = x_STPS_batch[i,:n_frames[i],:]\n\t\t\t\t\txi_bar_hat = xi_bar_hat_batch[i,:n_frames[i],:]\n\t\t\t\t\txi_hat = self.xi_hat(xi_bar_hat)\n\t\t\t\t\ty_STMS = np.multiply(x_STMS, gfunc(xi_hat, xi_hat+1, gtype=g))\n\t\t\t\t\ty = self.polar_synthesis(y_STMS, x_STPS).numpy()\n\n\t\t\t\t\tfor (j, basename) in enumerate(test_s_base_names):\n\t\t\t\t\t\tif basename in test_x_base_names[i]: ref_idx = j\n\n\t\t\t\t\ts = self.normalise(test_s[ref_idx,0:test_s_len[ref_idx]]).numpy()\n\t\t\t\t\ty = y[0:len(s)]\n\n\t\t\t\t\tnoise_source = test_x_base_names[i].split(""_"")[-2]\n\t\t\t\t\tsnr_level = int(test_x_base_names[i].split(""_"")[-1][:-2])\n\n\t\t\t\t\tresults = self.add_score(results, (noise_source, snr_level, \'STOI\'),\n\t\t\t\t\t\t100*stoi(s, y, self.f_s, extended=False))\n\t\t\t\t\tresults = self.add_score(results, (noise_source, snr_level, \'eSTOI\'),\n\t\t\t\t\t\t100*stoi(s, y, self.f_s, extended=True))\n\t\t\t\t\tresults = self.add_score(results, (noise_source, snr_level, \'PESQ\'),\n\t\t\t\t\t\tpesq(self.f_s, s, y, \'nb\'))\n\t\t\t\t\tresults = self.add_score(results, (noise_source, snr_level, \'MOS-LQO\'),\n\t\t\t\t\t\tpesq(self.f_s, s, y, \'wb\'))\n\n\t\t\t\tnoise_sources, snr_levels, metrics = set(), set(), set()\n\t\t\t\tfor key, value in results.items():\n\t\t\t\t\tnoise_sources.add(key[0])\n\t\t\t\t\tsnr_levels.add(key[1])\n\t\t\t\t\tmetrics.add(key[2])\n\n\t\t\t\tif not os.path.exists(""log/results""): os.makedirs(""log/results"")\n\n\t\t\t\twith open(""log/results/"" + self.ver + ""_e"" + str(e) + \'_\' + g + "".csv"", ""w"") as f:\n\t\t\t\t\tf.write(""noise,snr_db"")\n\t\t\t\t\tfor k in sorted(metrics): f.write(\',\' + k)\n\t\t\t\t\tf.write(\'\\n\')\n\t\t\t\t\tfor i in sorted(noise_sources):\n\t\t\t\t\t\tfor j in sorted(snr_levels):\n\t\t\t\t\t\t\tf.write(""{},{}"".format(i, j))\n\t\t\t\t\t\t\tfor k in sorted(metrics):\n\t\t\t\t\t\t\t\tif (i, j, k) in results.keys():\n\t\t\t\t\t\t\t\t\tf.write("",{:.2f}"".format(np.mean(results[(i,j,k)])))\n\t\t\t\t\t\t\tf.write(\'\\n\')\n\n\t\t\t\tavg_results = {}\n\t\t\t\tfor i in sorted(noise_sources):\n\t\t\t\t\tfor j in sorted(snr_levels):\n\t\t\t\t\t\tif (j >= self.min_snr) and (j <= self.max_snr):\n\t\t\t\t\t\t\tfor k in sorted(metrics):\n\t\t\t\t\t\t\t\tif (i, j, k) in results.keys():\n\t\t\t\t\t\t\t\t\tavg_results = self.add_score(avg_results, k, results[(i,j,k)])\n\n\t\t\t\tif not os.path.exists(""log/results/average.csv""):\n\t\t\t\t\twith open(""log/results/average.csv"", ""w"") as f:\n\t\t\t\t\t\tf.write(""ver"")\n\t\t\t\t\t\tfor i in sorted(metrics): f.write("","" + i)\n\t\t\t\t\t\tf.write(\'\\n\')\n\n\t\t\t\twith open(""log/results/average.csv"", ""a"") as f:\n\t\t\t\t\tf.write(self.ver + ""_e"" + str(e) + \'_\' + g)\n\t\t\t\t\tfor i in sorted(metrics):\n\t\t\t\t\t\tif i in avg_results.keys():\n\t\t\t\t\t\t\tf.write("",{:.2f}"".format(np.mean(avg_results[i])))\n\t\t\t\t\tf.write(\'\\n\')\n\n\tdef sample_stats(\n\t\tself,\n\t\tstats_path=\'data\',\n\t\tsample_size=1000,\n\t\ttrain_s_list=None,\n\t\ttrain_d_list=None\n\t\t):\n\t\t""""""\n\t\tComputes statistics for each frequency component of the instantaneous a priori SNR\n\t\tin dB over a sample of the training set. The statistics are then used to map the\n\t\tinstantaneous a priori SNR in dB between 0 and 1 using its cumulative distribution\n\t\tfunction. This forms the mapped a priori SNR (the training target).\n\n\t\tArgument/s:\n\t\t\tstats_path - path to the saved statistics.\n\t\t\tsample_size - number of training examples to compute the statistics from.\n\t\t\ttrain_s_list - train clean speech list.\n\t\t\ttrain_d_list - train noise list.\n\t\t""""""\n\t\tif os.path.exists(stats_path + \'/stats.npz\'):\n\t\t\tprint(\'Loading sample statistics...\')\n\t\t\twith np.load(stats_path + \'/stats.npz\') as stats:\n\t\t\t\tself.mu = stats[\'mu_hat\']\n\t\t\t\tself.sigma = stats[\'sigma_hat\']\n\t\telif train_s_list == None:\n\t\t\traise ValueError(\'No stats.npz file exists. data/stats.p is available here: https://github.com/anicolson/DeepXi/blob/master/data/stats.npz.\')\n\t\telse:\n\t\t\tprint(\'Finding sample statistics...\')\n\t\t\ts_sample_list = random.sample(self.train_s_list, sample_size)\n\t\t\td_sample_list = random.sample(self.train_d_list, sample_size)\n\t\t\ts_sample, d_sample, s_sample_len, d_sample_len, snr_sample = self.wav_batch(s_sample_list, d_sample_list)\n\t\t\tsnr_sample = np.array(random.choices(self.snr_levels, k=sample_size))\n\t\t\t# snr_sample = np.random.randint(self.min_snr, self.max_snr + 1, sample_size)\n\t\t\tsamples = []\n\t\t\tfor i in tqdm(range(s_sample.shape[0])):\n\t\t\t\ts_STMS, d_STMS, _, _ = self.mix(s_sample[i:i+1], d_sample[i:i+1], s_sample_len[i:i+1],\n\t\t\t\t\td_sample_len[i:i+1], snr_sample[i:i+1])\n\t\t\t\txi_db = self.xi_db(s_STMS, d_STMS) # instantaneous a priori SNR (dB).\n\t\t\t\tsamples.append(np.squeeze(xi_db.numpy()))\n\t\t\tsamples = np.vstack(samples)\n\t\t\tif len(samples.shape) != 2: raise ValueError(\'Incorrect shape for sample.\')\n\t\t\tstats = {\'mu_hat\': np.mean(samples, axis=0), \'sigma_hat\': np.std(samples, axis=0)}\n\t\t\tself.mu, self.sigma = stats[\'mu_hat\'], stats[\'sigma_hat\']\n\t\t\tif not os.path.exists(stats_path): os.makedirs(stats_path)\n\t\t\tnp.savez(stats_path + \'/stats.npz\', mu_hat=stats[\'mu_hat\'], sigma_hat=stats[\'sigma_hat\'])\n\t\t\tsave_mat(stats_path + \'/stats.mat\', stats, \'stats\')\n\t\t\tprint(\'Sample statistics saved.\')\n\n\tdef dataset(self, n_epochs, buffer_size=16):\n\t\t""""""\n\t\tUsed to create a tf.data.Dataset for training.\n\n\t\tArgument/s:\n\t\t\tn_epochs - number of epochs to generate.\n\t\t\tbuffer_size - number of mini-batches to keep in buffer.\n\n\t\tReturns:\n\t\t\tdataset - tf.data.Dataset\n\t\t""""""\n\t\tdataset = tf.data.Dataset.from_generator(\n\t\t\tself.mbatch_gen,\n\t\t\t(tf.float32, tf.float32, tf.float32),\n\t\t\t(tf.TensorShape([None, None, self.n_feat]),\n\t\t\t\ttf.TensorShape([None, None, self.n_outp]),\n\t\t\t\ttf.TensorShape([None, None])),\n\t\t\t[tf.constant(n_epochs)]\n\t\t\t)\n\t\tdataset = dataset.prefetch(buffer_size)\n\t\treturn dataset\n\n\tdef mbatch_gen(self, n_epochs):\n\t\t""""""\n\t\tA generator that yields a mini-batch of training examples.\n\n\t\tArgument/s:\n\t\t\tn_epochs - number of epochs to generate.\n\n\t\tReturns:\n\t\t\tx_STMS_mbatch - mini-batch of observations (noisy speech short-time magnitude spectum).\n\t\t\txi_bar_mbatch - mini-batch of targets (mapped a priori SNR).\n\t\t\tseq_mask_mbatch - mini-batch of sequence masks.\n\t\t""""""\n\t\tfor _ in range(n_epochs):\n\t\t\trandom.shuffle(self.train_s_list)\n\t\t\tstart_idx, end_idx = 0, self.mbatch_size\n\t\t\tfor _ in range(self.n_iter):\n\t\t\t\ts_mbatch_list = self.train_s_list[start_idx:end_idx]\n\t\t\t\td_mbatch_list = random.sample(self.train_d_list, end_idx-start_idx)\n\t\t\t\ts_mbatch, d_mbatch, s_mbatch_len, d_mbatch_len, snr_mbatch = \\\n\t\t\t\t\tself.wav_batch(s_mbatch_list, d_mbatch_list)\n\t\t\t\tx_STMS_mbatch, xi_bar_mbatch, n_frames_mbatch = \\\n\t\t\t\t\tself.example(s_mbatch, d_mbatch, s_mbatch_len,\n\t\t\t\t\td_mbatch_len, snr_mbatch)\n\t\t\t\tseq_mask_mbatch = tf.cast(tf.sequence_mask(n_frames_mbatch), tf.float32)\n\t\t\t\tstart_idx += self.mbatch_size; end_idx += self.mbatch_size\n\t\t\t\tif end_idx > self.n_examples: end_idx = self.n_examples\n\t\t\t\tyield x_STMS_mbatch, xi_bar_mbatch, seq_mask_mbatch\n\n\tdef val_batch(\n\t\tself,\n\t\tsave_path,\n\t\tval_s,\n\t\tval_d,\n\t\tval_s_len,\n\t\tval_d_len,\n\t\tval_snr\n\t\t):\n\t\t""""""\n\t\tCreates and saves the examples for the validation set. If\n\t\talready saved, the function will load the batch of examples.\n\n\t\tArgument/s:\n\t\t\tsave_path - path to save the validation batch.\n\t\t\tval_s - validation clean speech waveforms.\n\t\t\tval_d - validation noise waveforms.\n\t\t\tval_s_len - validation clean speech waveform lengths.\n\t\t\tval_d_len - validation noise waveform lengths.\n\t\t\tval_snr - validation SNR levels.\n\n\t\tReturns:\n\t\t\tx_STMS_batch - batch of observations (noisy speech short-time magnitude spectum).\n\t\t\txi_bar_batch - batch of targets (mapped a priori SNR).\n\t\t\tseq_mask_batch - batch of sequence masks.\n\t\t""""""\n\t\tif not os.path.exists(save_path): os.makedirs(save_path)\n\t\tif os.path.exists(save_path + \'/val_batch.npz\'):\n\t\t\tprint(\'Loading validation batch...\')\n\t\t\twith np.load(save_path + \'/val_batch.npz\') as data:\n\t\t\t\tx_STMS_batch = data[\'val_inp\']\n\t\t\t\txi_bar_batch = data[\'val_tgt\']\n\t\t\t\tseq_mask_batch =  data[\'val_seq_mask\']\n\t\telse:\n\t\t\tprint(\'Creating validation batch...\')\n\t\t\tbatch_size = len(val_s)\n\t\t\tmax_n_frames = self.n_frames(max(val_s_len))\n\t\t\tx_STMS_batch = np.zeros([batch_size, max_n_frames, self.n_feat], np.float32)\n\t\t\txi_bar_batch = np.zeros([batch_size, max_n_frames, self.n_feat], np.float32)\n\t\t\tseq_mask_batch = np.zeros([batch_size, max_n_frames], np.float32)\n\t\t\tfor i in tqdm(range(batch_size)):\n\t\t\t\tx_STMS, xi_bar, _ = self.example(val_s[i:i+1], val_d[i:i+1],\n\t\t\t\t\tval_s_len[i:i+1], val_d_len[i:i+1], val_snr[i:i+1])\n\t\t\t\tn_frames = self.n_frames(val_s_len[i])\n\t\t\t\tx_STMS_batch[i,:n_frames,:] = x_STMS.numpy()\n\t\t\t\txi_bar_batch[i,:n_frames,:] = xi_bar.numpy()\n\t\t\t\tseq_mask_batch[i,:n_frames] = tf.cast(tf.sequence_mask(n_frames), tf.float32)\n\t\t\tnp.savez(save_path + \'/val_batch.npz\', val_inp=x_STMS_batch,\n\t\t\t\tval_tgt=xi_bar_batch, val_seq_mask=seq_mask_batch)\n\t\treturn x_STMS_batch, xi_bar_batch, seq_mask_batch\n\n\tdef observation_batch(self, x_batch, x_batch_len):\n\t\t""""""\n\t\tComputes observations (noisy-speech STMS) from noisy speech recordings.\n\n\t\tArgument/s:\n\t\t\tx_batch - noisy-speech batch.\n\t\t\tx_batch_len - noisy-speech batch lengths.\n\n\t\tReturns:\n\t\t\tx_STMS_batch - batch of observations (noisy-speech short-time magnitude spectrums).\n\t\t\tx_STPS_batch - batch of noisy-speech short-time phase spectrums.\n\t\t\tn_frames_batch - number of frames in each observation.\n\t\t""""""\n\t\tbatch_size = len(x_batch)\n\t\tmax_n_frames = self.n_frames(max(x_batch_len))\n\t\tx_STMS_batch = np.zeros([batch_size, max_n_frames, self.n_feat], np.float32)\n\t\tx_STPS_batch = np.zeros([batch_size, max_n_frames, self.n_feat], np.float32)\n\t\tn_frames_batch = [self.n_frames(i) for i in x_batch_len]\n\t\tfor i in tqdm(range(batch_size)):\n\t\t\tx_STMS, x_STPS = self.observation(x_batch[i,:x_batch_len[i]])\n\t\t\tx_STMS_batch[i,:n_frames_batch[i],:] = x_STMS.numpy()\n\t\t\tx_STPS_batch[i,:n_frames_batch[i],:] = x_STPS.numpy()\n\t\treturn x_STMS_batch, x_STPS_batch, n_frames_batch\n\n\tdef wav_batch(self, s_list, d_list):\n\t\t""""""\n\t\tLoads .wav files into batches.\n\n\t\tArgument/s:\n\t\t\ts_list - clean-speech list.\n\t\t\td_list - noise list.\n\n\t\tReturns:\n\t\t\ts_batch - batch of clean speech.\n\t\t\td_batch - batch of noise.\n\t\t\ts_batch_len - sequence length of each clean speech waveform.\n\t\t\td_batch_len - sequence length of each noise waveform.\n\t\t\tsnr_batch - batch of SNR levels.\n\t\t""""""\n\t\tbatch_size = len(s_list)\n\t\tmax_len = max([dic[\'wav_len\'] for dic in s_list])\n\t\ts_batch = np.zeros([batch_size, max_len], np.int16)\n\t\td_batch = np.zeros([batch_size, max_len], np.int16)\n\t\ts_batch_len = np.zeros(batch_size, np.int32)\n\t\tfor i in range(batch_size):\n\t\t\t(wav, _) = read_wav(s_list[i][\'file_path\'])\n\t\t\ts_batch[i,:s_list[i][\'wav_len\']] = wav\n\t\t\ts_batch_len[i] = s_list[i][\'wav_len\']\n\t\t\tflag = True\n\t\t\twhile flag:\n\t\t\t\tif d_list[i][\'wav_len\'] < s_batch_len[i]: d_list[i] = random.choice(self.train_d_list)\n\t\t\t\telse: flag = False\n\t\t\t(wav, _) = read_wav(d_list[i][\'file_path\'])\n\t\t\trand_idx = np.random.randint(0, 1+d_list[i][\'wav_len\']-s_batch_len[i])\n\t\t\td_batch[i,:s_batch_len[i]] = wav[rand_idx:rand_idx+s_batch_len[i]]\n\t\td_batch_len = s_batch_len\n\t\t# snr_batch = np.random.randint(self.min_snr, self.max_snr+1, batch_size)\n\t\tsnr_batch = np.array(random.choices(self.snr_levels, k=batch_size))\n\t\treturn s_batch, d_batch, s_batch_len, d_batch_len, snr_batch\n\n\tdef add_score(self, dict, key, score):\n\t\t""""""\n\t\tAdds score/s to the list for the given key.\n\n\t\tArgument/s:\n\t\t\tdict - dictionary with condition as keys and a list of objective\n\t\t\t\tscores as values.\n\t\t\tkey - noisy-speech conditions.\n\t\t\tscore - objective score.\n\n\t\tReturns:\n\t\t\tdict - updated dictionary.\n\t\t""""""\n\t\tif isinstance(score, list):\n\t\t\tif key in dict.keys(): dict[key].extend(score)\n\t\t\telse: dict[key] = score\n\t\telse:\n\t\t\tif key in dict.keys(): dict[key].append(score)\n\t\t\telse: dict[key] = [score]\n\t\treturn dict\n\nclass SaveWeights(Callback):  ### RENAME TO SaveModel\n\t""""""\n\t""""""\n\tdef __init__(self, model_path):\n\t\t""""""\n\t\t""""""\n\t\tsuper(SaveWeights, self).__init__()\n\t\tself.model_path = model_path\n\n\tdef on_epoch_end(self, epoch, logs=None):\n\t\t""""""\n\t\t""""""\n\t\tself.model.save(self.model_path + ""/epoch-"" + str(epoch))\n\nclass TransformerSchedular(LearningRateSchedule):\n\t""""""\n\t""""""\n\tdef __init__(self, d_model, warmup_steps):\n\t\t""""""\n\t\t""""""\n\t\tsuper(TransformerSchedular, self).__init__()\n\t\tself.d_model = float(d_model)\n\t\tself.warmup_steps = warmup_steps\n\n\tdef __call__(self, step):\n\t\t""""""\n\t\t""""""\n\t\targ1 = tf.math.rsqrt(step)\n\t\targ2 = step * (self.warmup_steps ** -1.5)\n\t\treturn tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n\n\tdef get_config(self):\n\t\t""""""\n\t\t""""""\n\t\tconfig = {\'d_model\': self.d_model, \'warmup_steps\': self.warmup_steps}\n\t\treturn config\n\n# class CSVLoggerIter(Callback):\n# \t""""""\n# \tfor each training iteration\n# \t""""""\n# \tdef __init__(self, filename, separator=\',\', append=False):\n# \t\t""""""\n# \t\t""""""\n# \t\tself.sep = separator\n# \t\tself.filename = filename\n# \t\tself.append = append\n# \t\tself.writer = None\n# \t\tself.keys = None\n# \t\tself.append_header = True\n# \t\tif six.PY2:\n# \t\t\tself.file_flags = \'b\'\n# \t\t\tself._open_args = {}\n# \t\telse:\n# \t\t\tself.file_flags = \'\'\n# \t\t\tself._open_args = {\'newline\': \'\\n\'}\n# \t\tsuper(CSVLoggerIter, self).__init__()\n#\n# \tdef on_train_begin(self, logs=None):\n# \t\t""""""\n# \t\t""""""\n# \t\tif self.append:\n# \t\t\tif file_io.file_exists(self.filename):\n# \t\t\t\twith open(self.filename, \'r\' + self.file_flags) as f:\n# \t\t\t\t\tself.append_header = not bool(len(f.readline()))\n# \t\t\tmode = \'a\'\n# \t\telse:\n# \t\t\tmode = \'w\'\n# \t\tself.csv_file = io.open(self.filename, mode + self.file_flags,\n# \t\t\t**self._open_args)\n#\n# \tdef on_train_batch_end(self, batch, logs=None):\n# \t\t""""""\n# \t\t""""""\n# \t\tlogs = logs or {}\n#\n# \t\tdef handle_value(k):\n# \t\t\tis_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n# \t\t\tif isinstance(k, six.string_types):\n# \t\t\t\treturn k\n# \t\t\telif isinstance(k, collections_abc.Iterable) and not is_zero_dim_ndarray:\n# \t\t\t\treturn \'""[%s]""\' % (\', \'.join(map(str, k)))\n# \t\t\telse:\n# \t\t\t\treturn k\n#\n# \t\tif self.keys is None:\n# \t\t\tself.keys = sorted(logs.keys())\n#\n# \t\tif self.model.stop_training:\n# \t\t\t# NA is set so that csv parsers do not fail for the last batch.\n# \t\t\tlogs = dict([(k, logs[k]) if k in logs else (k, \'NA\') for k in self.keys])\n#\n# \t\tif not self.writer:\n#\n# \t\t\tclass CustomDialect(csv.excel):\n# \t\t\t\tdelimiter = self.sep\n#\n# \t\t\tfieldnames = self.keys\n# \t\t\tif six.PY2:\n# \t\t\t\tfieldnames = [unicode(x) for x in fieldnames]\n#\n# \t\t\tself.writer = csv.DictWriter(\n# \t\t\t\tself.csv_file,\n# \t\t\t\tfieldnames=fieldnames,\n# \t\t\t\tdialect=CustomDialect)\n# \t\t\tif self.append_header:\n# \t\t\t\tself.writer.writeheader()\n#\n# \t\trow_dict = collections.OrderedDict({\'batch\': batch})\n# \t\trow_dict.update((key, handle_value(logs[key])) for key in self.keys)\n#\n# \t\tself.writer.writerow(row_dict)\n# \t\tself.csv_file.flush()\n#\n# \tdef on_train_end(self, logs=None):\n# \t\tself.csv_file.close()\n# \t\tself.writer = None\n'"
deepxi/normalisation.py,37,"b'## FILE:           normalisation.py \n## DATE:           2019\n## AUTHOR:         Aaron Nicolson\n## AFFILIATION:    Signal Processing Laboratory, Griffith University.\n## BRIEF:          Layer/instance/batch normalisation functions.\n##\n## This Source Code Form is subject to the terms of the Mozilla Public\n## License, v. 2.0. If a copy of the MPL was not distributed with this\n## file, You can obtain one at http://mozilla.org/MPL/2.0/.\nfrom os.path import expanduser\nimport argparse, os, string\nimport numpy as np\nimport tensorflow as tf\n\ndef Normalisation(x, norm_type=\'FrameLayerNorm\', seq_len=None, mask=None, training=False, centre=True, scale=True):\n\t\'\'\'\n\tNormalisation.\n\n\tInput/s:\n\t\tx - unnormalised input.\n\t\tnorm_type - normalisation type.\t\n\t\tseq_len - length of each sequence.\t\t\t\n\t\tmask - sequence mask.\n\t\ttraining - training flag.\n\n\tOutput/s:\n\t\tnormalised input.\n\t\'\'\'\n\t\n\tif norm_type == \'SeqCausalLayerNorm\': return SeqCausalLayerNorm(x, seq_len, centre=centre, scale=scale)\n\telif norm_type == \'SeqLayerNorm\': return SeqLayerNorm(x, seq_len, centre=centre, scale=scale)\n\telif norm_type == \'FrameLayerNorm\': return FrameLayerNorm(x, centre=centre, scale=scale)\n\telif norm_type == \'unnormalised\': return x\n\telse: ValueError(\'Normalisation type does not exist: %s.\' % (norm_type))\n\ncount = 0 \ndef SeqCausalLayerNorm(x, seq_len, centre=True, scale=True):\n\t\'\'\'\n\tSequence-wise causal layer normalisation with sequence masking (causal layer norm version of https://arxiv.org/pdf/1510.01378.pdf). \n\n\tInput/s:\n\t\tx - input.\n\t\tseq_len - length of each sequence. \n\t\tcentre - centre parameter.\n\t\tscale - scale parameter. \n\n\tOutput/s:\n\t\tnormalised input.\n\t\'\'\'\n\tglobal count\n\tcount += 1\n\twith tf.variable_scope(\'LayerNorm\' + str(count)):\n\t\tinput_size = x.get_shape().as_list()[-1]\n\t\tmask = tf.cast(tf.sequence_mask(seq_len), tf.float32) # convert mask to float.\n\t\tden = tf.multiply(tf.range(1.0, tf.add(tf.cast(tf.shape(mask)[-1], tf.float32), 1.0), dtype=tf.float32), input_size)\n\t\tmu = tf.expand_dims(tf.truediv(tf.cumsum(tf.reduce_sum(x, -1), -1), den), 2)\n\t\tsigma = tf.expand_dims(tf.truediv(tf.cumsum(tf.reduce_sum(tf.square(tf.subtract(x, \n\t\t\tmu)), -1), -1), den),2)\n\t\tif centre: beta = tf.get_variable(""beta"", input_size, dtype=tf.float32,  \n\t\t\tinitializer=tf.constant_initializer(0.0), trainable=True)\n\t\telse: beta = tf.constant(np.zeros(input_size), name=""beta"", dtype=tf.float32)\n\t\tif scale: gamma = tf.get_variable(""Gamma"", input_size, dtype=tf.float32,  \n\t\t\tinitializer=tf.constant_initializer(1.0), trainable=True)\n\t\telse: gamma = tf.constant(np.ones(input_size), name=""Gamma"", dtype=tf.float32)\n\t\treturn tf.multiply(tf.nn.batch_normalization(x, mu, sigma, offset=beta, scale=gamma, \n\t\t\tvariance_epsilon = 1e-12), tf.expand_dims(mask, 2))\n\ncount = 0 \ndef FrameLayerNorm(x, centre=True, scale=True):\n\t\'\'\'\n\tFrame-wise layer normalisation (layer norm version of https://arxiv.org/pdf/1510.01378.pdf).\n\n\tInput/s:\n\t\tx - input.\n\t\tseq_len - length of each sequence. \n\t\tcentre - centre parameter.\n\t\tscale - scale parameter. \n\n\tOutput/s:\n\t\tnormalised input.\n\t\'\'\'\n\tglobal count\n\tcount += 1\n\n\twith tf.variable_scope(\'frm_wise_layer_norm\' + str(count)):\n\t\tmu, sigma = tf.nn.moments(x, -1, keepdims=True)\n\t\tinput_size = x.get_shape().as_list()[-1] # get number of input dimensions.\n\t\tif centre:\n\t\t\tbeta = tf.get_variable(""beta"", input_size, dtype=tf.float32,  \n\t\t\t\tinitializer=tf.constant_initializer(0.0), trainable=True)\n\t\telse: beta = tf.constant(np.zeros(input_size), name=""beta"", dtype=tf.float32)\n\t\tif scale:\n\t\t\tgamma = tf.get_variable(""Gamma"", input_size, dtype=tf.float32,  \n\t\t\t\tinitializer=tf.constant_initializer(1.0), trainable=True)\n\t\telse: gamma = tf.constant(np.ones(input_size), name=""Gamma"", dtype=tf.float32)\n\t\treturn tf.nn.batch_normalization(x, mu, sigma, offset=beta, scale=gamma, \n\t\t\tvariance_epsilon = 1e-12) # normalise batch.\n\n\nclass SequenceLayerNorm(tf.keras.layers.Layer):\n\t""""""\n\t""""""\n\tdef __init__(self, input_dim, output_dim, mask_zero=False, **kwargs):\n\t\t""""""\n\t\t""""""\n\t\tsuper(SequenceLayerNorm, self).__init__(**kwargs)\n\t\tself.input_dim = input_dim\n\t\tself.output_dim = output_dim\n\t\tself.mask_zero = mask_zero\n\t  \n\tdef build(self, input_shape):\n\t\t""""""\n\t\t""""""\n\t\tself.embeddings = self.add_weight(\n\t\t\tshape=(self.input_dim, self.output_dim),\n\t\t\tinitializer=\'random_normal\',\n\t\t\tdtype=\'float32\')\n\t  \n\tdef call(self, inputs):\n\t\t""""""\n\t\t""""""\n\t\treturn tf.nn.embedding_lookup(self.embeddings, inputs)\n\t\n\tdef compute_mask(self, inputs, mask=None):\n\t\t""""""\n\t\t""""""\n\t\tif not self.mask_zero:\n\t    \treturn None\n\t\treturn tf.not_equal(inputs, 0)\n  \n\ndef SeqLayerNorm(input, seq_len, centre=True, scale=True): # layer norm for 3D tensor.\n\tmask = tf.cast(tf.expand_dims(tf.sequence_mask(seq_len), 2), tf.float32) # convert mask to float.\n\tinput_dim = input.get_shape().as_list()[-1] # get number of input dimensions.\n\tden = tf.multiply(tf.reduce_sum(mask, axis=1, keepdims=True), input_dim) # inverse of the number of input dimensions.\n\tmean = tf.divide(tf.reduce_sum(tf.multiply(input, mask), axis=[1, 2], keepdims=True), den) # mean over the input dimensions.\n\tvar = tf.divide(tf.reduce_sum(tf.multiply(tf.square(tf.subtract(input, mean)), mask), axis=[1, 2], \n\t \tkeepdims = True), den) # variance over the input dimensions.\n\tif centre:\n\t\tbeta = tf.get_variable(""beta"", input_dim, dtype=tf.float32,  \n\t\t\tinitializer=tf.constant_initializer(0.0), trainable=True)\n\telse: beta = tf.constant(np.zeros(input_dim), name=""beta"", dtype=tf.float32)\n\tif scale:\n\t\tgamma = tf.get_variable(""Gamma"", input_dim, dtype=tf.float32,  \n\t\t\tinitializer=tf.constant_initializer(1.0), trainable=True)\n\telse: gamma = tf.constant(np.ones(input_dim), name=""Gamma"", dtype=tf.float32)\n\tnorm = tf.nn.batch_normalization(input, mean, var, offset=beta, scale=gamma, \n\t\tvariance_epsilon = 1e-12) # normalise batch.\n\tnorm = tf.multiply(norm, mask)\n\treturn norm'"
deepxi/prelim.py,9,"b'## AUTHOR:         Aaron Nicolson\n## AFFILIATION:    Signal Processing Laboratory, Griffith University\n##\n## This Source Code Form is subject to the terms of the Mozilla Public\n## License, v. 2.0. If a copy of the MPL was not distributed with this\n## file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\nfrom deepxi.gain import gfunc\nfrom deepxi.network.rnn import ResLSTM\nfrom deepxi.network.tcn import ResNet\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nimport math\nimport numpy as np\nimport tensorflow as tf\n\nclass Prelim():\n\t""""""\n\tThis preliminary class was used as the basis for the DeepXi class.\n\t""""""\n\tdef __init__(\n\t\tself,\n\t\tn_feat,\n\t\tnetwork\n\t\t):\n\t\tself.n_feat = n_feat\n\t\tself.n_outp = self.n_feat\n\t\tif self.n_feat < 5: raise ValueError(\'More input features are required for this exampple.\')\n\t\tself.inp = Input(name=\'inp\', shape=[None, self.n_feat], dtype=\'float32\')\n\t\tself.mask = tf.keras.layers.Masking(mask_value=0.0)(self.inp)\n\t\tif network == \'ResNet\': self.network = ResNet(self.mask, self.n_outp, B=40, d_model=256, d_f=64, k=3, max_d_rate=16)\n\t\telif network == \'ResLSTM\': self.network = ResLSTM(self.mask, self.n_outp, n_blocks=3, d_model=256)\n\t\telse: raise ValueError(\'Invalid network type.\')\n\t\tself.model = Model(inputs=self.inp, outputs=self.network.outp)\n\t\tself.model.summary()\n\n\tdef train(\n\t\tself,\n\t\tmbatch_size=8,\n\t\tmax_epochs=20,\n\t\t):\n\t\tself.mbatch_size=mbatch_size\n\t\tself.max_epochs=max_epochs\n\t\tself.batch_size=100\n\n\t\tself.model.compile(\n\t\t\tsample_weight_mode=""temporal"",\n\t\t\tloss=""binary_crossentropy"",\n\t\t\toptimizer=Adam(lr=0.001, clipvalue=1.0)\n\t\t\t)\n\n\t\ttrain_dataset = self.dataset()\n\n\t\tself.model.fit(\n\t\t\ttrain_dataset,\n\t\t\tepochs=max_epochs,\n\t\t\tsteps_per_epoch=math.ceil(self.batch_size/self.mbatch_size)\n\t\t\t)\n\n\t\tx_test, y_test, _ = list(train_dataset.take(1).as_numpy_iterator())[0]\n\t\ty_hat = self.model.predict(x_test[0:1])\n\n\t\tnp.set_printoptions(precision=2, suppress=True)\n\t\tprint(""Target:"")\n\t\tprint(np.asarray(y_test[0,0:5,0:self.n_feat]))\n\t\tprint(""Prediction:"")\n\t\tprint(y_hat[0,0:5,0:self.n_feat])\n\n\tdef dataset(self, buffer_size=16):\n\t\tdataset = tf.data.Dataset.from_generator(\n\t\t\tself.mbatch_gen,\n\t\t\t(tf.float32, tf.float32, tf.float32),\n\t\t\t(tf.TensorShape([None, None, self.n_feat]),\n\t\t\t\ttf.TensorShape([None, None, self.n_outp]),\n\t\t\t\ttf.TensorShape([None, None]))\n\t\t\t)\n\t\tdataset = dataset.prefetch(buffer_size)\n\t\treturn dataset\n\n\tdef mbatch_gen(self):\n\t\tfor _ in range(self.max_epochs):\n\t\t\tfor _ in range(math.ceil(self.batch_size/self.mbatch_size)):\n\t\t\t\tmax_seq_len = 75\n\t\t\t\tmin_seq_len = 45\n\t\t\t\tx_train = np.random.rand(self.mbatch_size, max_seq_len, self.n_feat)\n\t\t\t\ty_frame = np.zeros(self.n_feat)\n\t\t\t\ty_frame[0] = 0.05\n\t\t\t\ty_frame[1] = 0.99\n\t\t\t\ty_frame[2] = 0.5\n\t\t\t\ty_frame[3] = 0.01\n\t\t\t\ty_frame[4] = 0.75\n\t\t\t\ty_train = np.tile(y_frame, (self.mbatch_size, max_seq_len, 1))\n\t\t\t\tseq_len = np.random.randint(min_seq_len, max_seq_len+1, self.mbatch_size)\n\t\t\t\tseq_mask = tf.cast(tf.sequence_mask(seq_len, maxlen=max_seq_len), tf.float32)\n\t\t\t\tx_train = tf.multiply(x_train, tf.expand_dims(seq_mask, 2))\n\t\t\t\ty_train = tf.multiply(y_train, tf.expand_dims(seq_mask, 2))\n\t\t\t\tyield x_train, y_train, seq_mask\n'"
deepxi/se_batch.py,0,"b""## AUTHOR:         Aaron Nicolson\n## AFFILIATION:    Signal Processing Laboratory, Griffith University.\n##\n## This Source Code Form is subject to the terms of the Mozilla Public\n## License, v. 2.0. If a copy of the MPL was not distributed with this\n## file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\nimport contextlib, glob, os, pickle, platform, random, sys, wave\nimport numpy as np\nfrom deepxi.utils import read_wav\nfrom scipy.io.wavfile import read\n\n\n\n\n\ndef Batch(fdir, snr_l=[]):\n\t'''\n\tREQUIRES REWRITING. WILL BE MOVED TO deepxi/utils.py\n\n\tPlaces all of the test waveforms from the list into a numpy array.\n\tSPHERE format cannot be used. 'glob' is used to support Unix style pathname\n\tpattern expansions. Waveforms are padded to the maximum waveform length. The\n\twaveform lengths are recorded so that the correct lengths can be sliced\n\tfor feature extraction. The SNR levels of each test file are placed into a\n\tnumpy array. Also returns a list of the file names.\n\n\tInputs:\n\t\tfdir - directory containing the waveforms.\n\t\tfnames - filename/s of the waveforms.\n\t\tsnr_l - list of the SNR levels used.\n\n\tOutputs:\n\t\twav_np - matrix of paded waveforms stored as a numpy array.\n\t\tlen_np - length of each waveform strored as a numpy array.\n\t\tsnr_test_np - numpy array of all the SNR levels for the test set.\n\t\tfname_l - list of filenames.\n\t'''\n\tfname_l = [] # list of file names.\n\twav_l = [] # list for waveforms.\n\tsnr_test_l = [] # list of SNR levels for the test set.\n\t# if isinstance(fnames, str): fnames = [fnames] # if string, put into list.\n\tfnames = ['*.wav', '*.flac', '*.mp3']\n\tfor fname in fnames:\n\t\tfor fpath in glob.glob(os.path.join(fdir, fname)):\n\t\t\tfor snr in snr_l:\n\t\t\t\tif fpath.find('_' + str(snr) + 'dB') != -1:\n\t\t\t\t\tsnr_test_l.append(snr) # append SNR level.\n\t\t\t(wav, _) = read_wav(fpath) # read waveform from given file path.\n\t\t\tif np.isnan(wav).any() or np.isinf(wav).any():\n\t\t\t\traise ValueError('Error: NaN or Inf value. File path: %s.' % (file_path))\n\t\t\twav_l.append(wav) # append.\n\t\t\tfname_l.append(os.path.basename(os.path.splitext(fpath)[0])) # append name.\n\tlen_l = [] # list of the waveform lengths.\n\tmaxlen = max(len(wav) for wav in wav_l) # maximum length of waveforms.\n\twav_np = np.zeros([len(wav_l), maxlen], np.int16) # numpy array for waveform matrix.\n\tfor (i, wav) in zip(range(len(wav_l)), wav_l):\n\t\twav_np[i,:len(wav)] = wav # add waveform to numpy array.\n\t\tlen_l.append(len(wav)) # append length of waveform to list.\n\treturn wav_np, np.array(len_l, np.int32), np.array(snr_test_l, np.int32), fname_l\n"""
deepxi/sig.py,49,"b'## AUTHOR:         Aaron Nicolson\n## AFFILIATION:    Signal Processing Laboratory, Griffith University.\n##\n## This Source Code Form is subject to the terms of the Mozilla Public\n## License, v. 2.0. If a copy of the MPL was not distributed with this\n## file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\nfrom tensorflow.python.ops.signal import window_ops\nimport functools\nimport numpy as np\nimport scipy.special as spsp\nimport tensorflow as tf\n\n""""""\n[1] Huang, X., Acero, A., Hon, H., 2001. Spoken Language Processing:\n\tA guide to theory, algorithm, and system development.\n\tPrentice Hall, Upper Saddle River, NJ, USA (pp. 315).\n""""""\n\nclass STFT:\n\t""""""\n\tShort-time Fourier transform.\n\t""""""\n\tdef __init__(self, N_d, N_s, NFFT, f_s):\n\t\t""""""\n\t\tArgument/s:\n\t\t\tN_d - window duration (samples).\n\t\t\tN_s - window shift (samples).\n\t\t\tNFFT - number of DFT bins.\n\t\t\tf_s - sampling frequency.\n\t\t""""""\n\t\tself.N_d = N_d\n\t\tself.N_s = N_s\n\t\tself.NFFT = NFFT\n\t\tself.f_s = f_s\n\t\tself.W = functools.partial(window_ops.hamming_window, periodic=False)\n\t\tself.ten = tf.cast(10.0, tf.float32)\n\n\tdef polar_analysis(self, x):\n\t\t""""""\n\t\tPolar-form acoustic-domain analysis.\n\n\t\tArgument/s:\n\t\t\tx - waveform.\n\n\t\tReturns:\n\t\t\tShort-time magnitude and phase spectrums.\n\t\t""""""\n\t\tSTFT = tf.signal.stft(x, self.N_d, self.N_s, self.NFFT, window_fn=self.W, pad_end=True)\n\t\treturn tf.abs(STFT), tf.math.angle(STFT)\n\n\tdef polar_synthesis(self, STMS, STPS):\n\t\t""""""\n\t\tPolar-form acoustic-domain synthesis.\n\n\t\tArgument/s:\n\t\t\tSTMS - short-time magnitude spectrum.\n\t\t\tSTPS - short-time phase spectrum.\n\n\t\tReturns:\n\t\t\tWaveform.\n\t\t""""""\n\t\tSTFT = tf.cast(STMS, tf.complex64)*tf.exp(1j*tf.cast(STPS, tf.complex64))\n\t\treturn tf.signal.inverse_stft(STFT, self.N_d, self.N_s, self.NFFT, tf.signal.inverse_stft_window_fn(self.N_s, self.W))\n\nclass DeepXiInput(STFT):\n\t""""""\n\tInput to Deep Xi.\n\t""""""\n\tdef __init__(self, N_d, N_s, NFFT, f_s, mu=None, sigma=None):\n\t\tsuper().__init__(N_d, N_s, NFFT, f_s)\n\t\t""""""\n\t\tArgument/s\n\t\t\tN_d - window duration (samples).\n\t\t\tN_s - window shift (samples).\n\t\t\tNFFT - number of DFT bins.\n\t\t\tf_s - sampling frequency.\n\t\t\tmu - sample mean of each instantaneous a priori SNR (dB) frequency component.\n\t\t\tsigma - sample standard deviation of each instantaneous a priori SNR (dB) frequency component.\n\t\t""""""\n\t\tself.mu = mu\n\t\tself.sigma = sigma\n\n\tdef observation(self, x):\n\t\t""""""\n\t    An observation for Deep Xi (noisy-speech STMS).\n\n\t\tArgument/s:\n\t\t\tx - noisy speech (dtype=tf.int32).\n\t\t\tx_len - noisy speech length without padding (samples).\n\n\t\tReturns:\n\t\t\tx_STMS - speech magnitude spectrum.\n\t\t\tx_STPS - speech phase spectrum.\n\t\t""""""\n\t\tx = self.normalise(x)\n\t\tx_STMS, x_STPS = self.polar_analysis(x)\n\t\treturn x_STMS, x_STPS\n\n\tdef example(self, s, d, s_len, d_len, snr):\n\t\t""""""\n\t\tCompute example for Deep Xi, i.e. observation (noisy-speech STMS)\n\t\tand target (mapped a priori SNR).\n\n\t\tArgument/s:\n\t\t\ts - clean speech (dtype=tf.int32).\n\t\t\td - noise (dtype=tf.int32).\n\t\t\ts_len - clean-speech length without padding (samples).\n\t\t\td_len - noise length without padding (samples).\n\t\t\tsnr - SNR level.\n\n\t\tReturns:\n\t\t\tx_STMS - noisy-speech short-time magnitude spectrum.\n\t\t\txi_bar - mapped a priori SNR.\n\t\t\tn_frames - number of time-domain frames.\n\t\t""""""\n\t\ts_STMS, d_STMS, x_STMS, n_frames = self.mix(s, d, s_len, d_len, snr)\n\t\tmask = tf.expand_dims(tf.cast(tf.sequence_mask(n_frames), tf.float32), 2)\n\t\txi_bar = tf.multiply(self.xi_bar(s_STMS, d_STMS), mask)\n\t\treturn x_STMS, xi_bar, n_frames\n\n\tdef mix(self, s, d, s_len, d_len, snr):\n\t\t""""""\n\t\tMix the clean speech and noise at SNR level, and then perform STFT analysis.\n\n\t\tArgument/s:\n\t\t\ts - clean speech (dtype=tf.int32).\n\t\t\td - noise (dtype=tf.int32).\n\t\t\ts_len - clean-speech length without padding (samples).\n\t\t\td_len - noise length without padding (samples).\n\t\t\tsnr - SNR level.\n\n\t\tReturns:\n\t\t\ts_STMS - clean-speech short-time magnitude spectrum.\n\t\t\td_STMS - noise short-time magnitude spectrum.\n\t\t\tx_STMS - noisy-speech short-time magnitude spectrum.\n\t\t\tn_frames - number of time-domain frames.\n\t\t""""""\n\t\ts, d = self.normalise(s), self.normalise(d)\n\t\tn_frames = self.n_frames(s_len)\n\t\t(x, s, d) = self.add_noise_batch(s, d, s_len, d_len, snr)\n\t\ts_STMS, _ = self.polar_analysis(s)\n\t\td_STMS, _ = self.polar_analysis(d)\n\t\tx_STMS, _ = self.polar_analysis(x)\n\t\treturn s_STMS, d_STMS, x_STMS, n_frames\n\n\tdef normalise(self, x):\n\t\t""""""\n\t\tConvert waveform from int32 to float32 and normalise between [-1.0, 1.0].\n\n\t\tArgument/s:\n\t\t\tx - tf.int32 waveform.\n\n\t\tReturns:\n\t\t\ttf.float32 waveform between [-1.0, 1.0].\n\t\t""""""\n\t\treturn tf.truediv(tf.cast(x, tf.float32), 32768.0)\n\n\tdef n_frames(self, N):\n\t\t""""""\n\t\tReturns the number of frames for a given sequence length, and\n\t\tframe shift.\n\n\t\tArgument/s:\n\t\t\tN - sequence length (samples).\n\n\t\tReturns:\n\t\t\tNumber of frames\n\t\t""""""\n\t\treturn tf.cast(tf.math.ceil(tf.truediv(tf.cast(N, tf.float32), tf.cast(self.N_s, tf.float32))), tf.int32)\n\n\tdef add_noise_batch(self, s, d, s_len, d_len, snr):\n\t\t""""""\n\t\tCreates noisy speech batch from clean speech, noise, and SNR batches.\n\n\t\tArgument/s:\n\t\t\ts - clean speech (dtype=tf.float32).\n\t\t\td - noise (dtype=tf.float32).\n\t\t\ts_len - clean-speech length without padding (samples).\n\t\t\td_len - noise length without padding (samples).\n\t\t\tsnr - SNR levels.\n\n\t\tReturns:\n\t\t\ttuple consisting of clean speech, noisy speech, and noise (x, s, d).\n\t\t""""""\n\t\treturn tf.map_fn(lambda z: self.add_noise_pad(z[0], z[1], z[2], z[3], z[4],\n\t\t\ttf.reduce_max(s_len)), (s, d, s_len, d_len, snr), dtype=(tf.float32, tf.float32,\n\t\t\ttf.float32), back_prop=False)\n\n\tdef add_noise_pad(self, s, d, s_len, d_len, snr, pad_len):\n\t\t""""""\n\t\tCalls add_noise() and pads the waveforms to the length given by \'pad_len\'.\n\t\tAlso normalises the waveforms.\n\n\t\tArgument/s:\n\t\t\ts - clean speech (dtype=tf.float32).\n\t\t\td - noise (dtype=tf.float32).\n\t\t\ts_len - clean-speech length without padding (samples).\n\t\t\td_len - noise length without padding (samples).\n\t\t\tsnr - SNR level.\n\t\t\tpad_len - padded length.\n\n\t\tReturns:\n\t\t\ts - padded clean-speech waveform.\n\t\t\tx - padded noisy-speech waveform.\n\t\t\td - truncated, scaled, and padded noise waveform.\n\t\t""""""\n\t\ts, d = s[:s_len], d[:d_len]\n\t\t(x, d) = self.add_noise(s, d, s_len, d_len, snr)\n\t\ttotal_zeros = tf.subtract(pad_len, s_len)\n\t\tx = tf.pad(x, [[0, total_zeros]], ""CONSTANT"")\n\t\ts = tf.pad(s, [[0, total_zeros]], ""CONSTANT"")\n\t\td = tf.pad(d, [[0, total_zeros]], ""CONSTANT"")\n\t\treturn (x, s, d)\n\n\tdef add_noise(self, s, d, s_len, d_len, snr):\n\t\t""""""\n\t\tAdds noise to the clean speech at a specific SNR value. A random section\n\t\tof the noise waveform is used.\n\n\t\tArgument/s:\n\t\t\ts - clean speech (dtype=tf.float32).\n\t\t\td - noise (dtype=tf.float32).\n\t\t\ts_len - clean-speech length without padding (samples).\n\t\t\td_len - noise length without padding (samples).\n\t\t\tsnr - SNR level (dB).\n\n\t\tReturns:\n\t\t\tx - noisy-speech waveform.\n\t\t\td - truncated and scaled noise waveform.\n\t\t""""""\n\t\tsnr = tf.cast(snr, tf.float32)\n\t\tsnr = tf.pow(self.ten, tf.truediv(snr, self.ten)) # inverse of dB.\n\t\ti = tf.random.uniform([1], 0, tf.add(1, tf.subtract(d_len, s_len)), tf.int32)\n\t\td = tf.slice(d, [i[0]], [s_len])\n\t\tP_s = tf.reduce_mean(tf.math.square(s), 0) # average power of clean speech.\n\t\tP_d = tf.reduce_mean(tf.math.square(d), 0) # average power of noise.\n\t\talpha = tf.math.sqrt(tf.truediv(P_s,\n\t\t\ttf.maximum(tf.multiply(P_d, snr), 1e-12))) # scaling factor.\n\t\td =\ttf.multiply(d, alpha)\n\t\tx = tf.add(s, d)\n\t\treturn (x, d)\n\n\tdef snr_db(self, s, d):\n\t\t""""""\n\t\tCalculates the SNR (dB) between the speech and noise.\n\n\t\tArgument/s:\n\t\t\ts - clean speech (dtype=tf.float32).\n\t\t\td - noise (dtype=tf.float32).\n\n\t\tReturns:\n\t\t\tSNR level (dB).\n\t\t""""""\n\t\tP_s = tf.reduce_mean(tf.math.square(s), 0) # average power of clean speech.\n\t\tP_d = tf.reduce_mean(tf.math.square(d), 0) # average power of noise.\n\t\treturn tf.multiply(self.ten, self.log_10(tf.truediv(P_s, P_d)))\n\n\tdef log_10(self, x):\n\t\t""""""\n\t\tlog_10(x).\n\n\t\tArgument/s:\n\t\t\tx - input.\n\n\t\tReturns:\n\t\t\tlog_10(x)\n\t\t""""""\n\t\treturn tf.truediv(tf.math.log(x), tf.math.log(self.ten))\n\n\tdef xi(self, s_STMS, d_STMS):\n\t\t""""""\n\t\tInstantaneous a priori SNR.\n\n\t\tArgument/s:\n\t\t\ts_STMS - clean-speech short-time magnitude spectrum.\n\t\t\td_STMS - noise short-time magnitude spectrum.\n\n\t\tReturns:\n\t\t\tInstantaneous a priori SNR.\n\t\t""""""\n\t\treturn tf.truediv(tf.square(s_STMS), tf.maximum(tf.square(d_STMS), 1e-12))\n\n\tdef xi_db(self, s_STMS, d_STMS):\n\t\t""""""\n\t\tInstantaneous a priori SNR in dB.\n\n\t\tArgument/s:\n\t\t\ts_STMS - clean-speech short-time magnitude spectrum.\n\t\t\td_STMS - noise short-time magnitude spectrum.\n\n\t\tReturns:\n\t\t\tInstantaneous a priori SNR in dB.\n\t\t""""""\n\t\treturn tf.multiply(10.0, self.log_10(tf.maximum(self.xi(s_STMS, d_STMS), 1e-12)))\n\n\tdef xi_bar(self, s_STMS, d_STMS):\n\t\t""""""\n\t\tMapped a priori SNR in dB.\n\n\t\tArgument/s:\n\t\t\ts_STMS - clean-speech short-time magnitude spectrum.\n\t\t\td_STMS - noise short-time magnitude spectrum.\n\n\t\tReturns:\n\t\t\tMapped a priori SNR in dB.\n\t\t""""""\n\t\treturn tf.multiply(0.5, tf.add(1.0, tf.math.erf(tf.truediv(tf.subtract(self.xi_db(s_STMS, d_STMS), self.mu),\n\t\t\ttf.multiply(self.sigma, tf.sqrt(2.0))))))\n\n\tdef xi_hat(self, xi_bar_hat):\n\t\t""""""\n\t\tA priori SNR estimate.\n\n\t\tArgument/s:\n\t\t\txi_bar_hat - mapped a priori SNR estimate.\n\n\t\tReturns:\n\t\t\tA priori SNR estimate.\n\t\t""""""\n\t\txi_db_hat = np.add(np.multiply(np.multiply(self.sigma, np.sqrt(2.0)),\n\t\t\tspsp.erfinv(np.subtract(np.multiply(2.0, xi_bar_hat), 1))), self.mu)\n\t\treturn np.power(10.0, np.divide(xi_db_hat, 10.0))\n\n\tdef mel_filter_bank(self, M):\n\t\t""""""\n\t\tCreated a mel-scaled filter bank using the equations from [1].\n\t\tThe notation from [1] is also used. For this case, each filter\n\t\tsums to unity, so that it can be used to weight the STMS a\n\t\tpriori SNR to compute the a priori SNR for each subband, i.e.\n\t\teach filter bank.\n\n\t\tArgument/s:\n\t\t\tM - number of filters.\n\n\t\tReturns:\n\t\t\tH - triangular mel filterbank matrix.\n\n\t\t""""""\n\t\tf_l = 0 # lowest frequency (Hz).\n\t\tf_h = self.f_s/2 # highest frequency (Hz).\n\t\tK = self.NFFT//2 + 1 # number of frequency bins.\n\t\tH = np.zeros([M, K], dtype=np.float32) # mel filter bank.\n\t\tfor m in range(1, M + 1):\n\t\t\tbl = self.bpoint(m - 1, M, f_l, f_h) # lower boundary point, f(m - 1) for m-th filterbank.\n\t\t\tc = self.bpoint(m, M, f_l, f_h) # m-th filterbank centre point, f(m).\n\t\t\tbh = self.bpoint(m + 1, M, f_l, f_h) # higher boundary point f(m + 1) for m-th filterbank.\n\t\t\tfor k in range(K):\n\t\t\t\tif k >= bl and k <= c:\n\t\t\t\t\tH[m-1,k] = (2*(k - bl))/((bh - bl)*(c - bl)) # m-th filterbank up-slope.\n\t\t\t\tif k >= c and k <= bh:\n\t\t\t\t\tH[m-1,k] = (2*(bh - k))/((bh - bl)*(bh - c)) # m-th filterbank down-slope.\n\t\treturn H\n\n\tdef bpoint(self, m, M, f_l, f_h):\n\t\t""""""\n\t\tDetirmines the frequency bin boundary point for a filterbank.\n\n\t\tArgument/s:\n\t\t\tm - filterbank.\n\t\t\tM - total filterbanks.\n\t\t\tf_l - lowest frequency.\n\t\t\tf_h - highest frequency.\n\n\t\tReturns:\n\t\t\tFrequency bin boundary point.\n\t\t""""""\n\t\tK = self.NFFT//2 + 1 # number of frequency bins.\n\t\treturn ((2*K)/self.f_s)*self.mel2hz(self.hz2mel(f_l) + \\\n\t\t\tm*((self.hz2mel(f_h) - self.hz2mel(f_l))/(M + 1))) # boundary point.\n\n\tdef hz2mel(self, f):\n\t\t""""""\n\t\tConverts a value from the Hz scale to a value in the mel scale.\n\n\t\tArgument/s:\n\t\t\tf - Hertz value.\n\n\t\tReturns:\n\t\t\tMel value.\n\t\t""""""\n\t\treturn 2595*np.log10(1 + (f/700))\n\n\tdef mel2hz(self, m):\n\t\t""""""\n\t\tConverts a value from the mel scale to a value in the Hz scale.\n\n\t\tArgument/s:\n\t\t\tm - mel value.\n\n\t\tReturns:\n\t\t\tHertz value.\n\t\t""""""\n\t\treturn 700*((10**(m/2595)) - 1)\n'"
deepxi/utils.py,2,"b'## AUTHOR:         Aaron Nicolson\n## AFFILIATION:    Signal Processing Laboratory, Griffith University.\n##\n## This Source Code Form is subject to the terms of the Mozilla Public\n## License, v. 2.0. If a copy of the MPL was not distributed with this\n## file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\nfrom scipy.io import loadmat, savemat\nfrom soundfile import SoundFile, SEEK_END\nimport numpy as np\nimport glob, os, pickle, platform\nimport soundfile as sf\nimport tensorflow as tf\n\ndef save_wav(path, wav, f_s):\n\t""""""\n\tSave .wav file.\n\n\tArgument/s:\n\t\tpath - absolute path to save .wav file.\n\t\twav - waveform to be saved.\n\t\tf_s - sampling frequency.\n\t""""""\n\twav = np.squeeze(wav)\n\tif isinstance(wav[0], np.float32): wav = np.asarray(np.multiply(wav, 32768.0), dtype=np.int16)\n\tsf.write(path, wav, f_s)\n\ndef read_wav(path):\n\t""""""\n\tRead .wav file.\n\n\tArgument/s:\n\t\tpath - absolute path to save .wav file.\n\n\tReturns:\n\t\twav - waveform.\n\t\tf_s - sampling frequency.\n\t""""""\n\twav, f_s = sf.read(path, dtype=\'int16\')\n\treturn wav, f_s\n\ndef save_mat(path, data, name):\n\t""""""\n\tSave .mat file.\n\n\tArgument/s:\n\t\tpath - absolute path to save .mat file.\n\t\tdata - data to be saved.\n\t\tname - dictionary key name.\n\t""""""\n\tif not path.endswith(\'.mat\'): path = path + \'.mat\'\n\tsavemat(path, {name: data})\n\ndef read_mat(path):\n\t""""""\n\tRead .mat file.\n\n\tArgument/s:\n\t\tpath - absolute path to save .mat file.\n\n\tReturns:\n\t\tDictionary.\n\t""""""\n\tif not path.endswith(\'.mat\'): path = path + \'.mat\'\n\treturn loadmat(path)\n\ndef gpu_config(gpu_selection, log_device_placement=False):\n\t""""""\n\tSelects GPU.\n\n\tArgument/s:\n\t\tgpu_selection - GPU to use.\n\t\tlog_device_placement - log the device that each node is placed on.\n\t""""""\n\tos.environ[""CUDA_DEVICE_ORDER""]=""PCI_BUS_ID""\n\tos.environ[""CUDA_VISIBLE_DEVICES""]=str(gpu_selection)\n\tgpus = tf.config.experimental.list_physical_devices(\'GPU\')\n\tfor gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)\n\ndef batch_list(file_dir, list_name, data_path=\'data\', make_new=False):\n\t""""""\n\tPlaces the file paths and wav lengths of an audio file into a dictionary, which\n\tis then appended to a list. \'glob\' is used to support Unix style pathname\n\tpattern expansions. Checks if the training list has already been saved, and loads\n\tit.\n\n\tArgument/s:\n\t\tfile_dir - directory containing the audio files.\n\t\tlist_name - name for the list.\n\t\tdata_path - path to store pickle files.\n\t\tmake_new - re-create list.\n\n\tReturns:\n\t\tbatch_list - list of file paths and wav length.\n\t""""""\n\textension = [\'*.wav\', \'*.flac\', \'*.mp3\']\n\tif not make_new:\n\t\tif os.path.exists(data_path + \'/\' + list_name + \'_list_\' + platform.node() + \'.p\'):\n\t\t\tprint(\'Loading \' + list_name + \' list...\')\n\t\t\twith open(data_path + \'/\' + list_name + \'_list_\' + platform.node() + \'.p\', \'rb\') as f:\n\t\t\t\tbatch_list = pickle.load(f)\n\t\t\tif batch_list[0][\'file_path\'].find(file_dir) != -1:\n\t\t\t\tprint(list_name + \' list has a total of %i entries.\' % (len(batch_list)))\n\t\t\t\treturn batch_list\n\n\tprint(\'Creating \' + list_name + \' list...\')\n\tbatch_list = []\n\tfor i in extension:\n\t\tfor j in glob.glob(os.path.join(file_dir, i)):\n\t\t\tf = SoundFile(j)\n\t\t\twav_len = f.seek(0, SEEK_END)\n\t\t\tif wav_len == -1:\n\t\t\t\twav, _ = read_wav(path)\n\t\t\t\twav_len = len(wav)\n\t\t\tbatch_list.append({\'file_path\': j, \'wav_len\': wav_len}) # append dictionary.\n\tif not os.path.exists(data_path): os.makedirs(data_path) # make directory.\n\twith open(data_path + \'/\' + list_name + \'_list_\' + platform.node() + \'.p\', \'wb\') as f:\n\t\tpickle.dump(batch_list, f)\n\tprint(\'The \' + list_name + \' list has a total of %i entries.\' % (len(batch_list)))\n\treturn batch_list\n\ndef val_wav_batch(val_s_dir, val_d_dir):\n\t\'\'\'\n\tProduces the validation batchs. Identical filenames for the clean speech and\n\tnoise must be placed in their respective directories, with the SNR at the\n\tend of the filename. Their lengths must also be identical.\n\n\tAs an example: \'./val_clean_speech/ANY_NAME_-5dB.wav\'\n\n\tcontains the clean speech, and\n\n\t\'./val_noise/ANY_NAME_-5dB.wav\'\n\n\tcontains the noise at the same length. They will be mixed together at the SNR\n\tlevel specified in the filename.\n\n\tArgument/s:\n\t\tval_s_dir - path to clean-speech validation files.\n\t\tval_d_dir - path to noise validation files.\n\n\tOutputs:\n\t\tval_s - batch of clean-speech padded waveforms.\n\t\tval_d - batch of noise padded waveforms.\n\t\tval_s_len - lengths of clean-speech waveforms.\n\t\tval_d_len - lengths of noise waveforms.\n\t\tval_snr - batch of SNR levels.\n\t\'\'\'\n\tprint(""Loading validation waveforms..."")\n\tval_s_list = []\n\tval_d_list = []\n\tval_s_len_list = []\n\tval_d_len_list = []\n\tval_snr_list = []\n\textension = [\'*.wav\', \'*.flac\', \'*.mp3\']\n\tfor i in extension:\n\t\ts_paths = glob.glob(os.path.join(val_s_dir, i))\n\t\td_paths = glob.glob(os.path.join(val_d_dir, i))\n\t\tfor (j,k) in zip(s_paths, d_paths):\n\t\t\ts_basename = os.path.basename(os.path.splitext(j)[0])\n\t\t\td_basename = os.path.basename(os.path.splitext(k)[0])\n\t\t\tif s_basename != d_basename:\n\t\t\t\traise ValueError(""The clean speech and noise validation files do not match: {} and {}."".format(s_basename, d_basename))\n\t\t\tif s_basename[-2:] != ""dB"":\n\t\t\t\traise ValueError(""The basename of the following file must end in dB: {}."".format(s_basename))\n\t\t\t(s_wav, _) = read_wav(j) # read waveform from given file path.\n\t\t\t(d_wav, _) = read_wav(k) # read waveform from given file path.\n\t\t\tif len(s_wav) != len(d_wav):\n\t\t\t\traise ValueError(""The clean speech and noise validation waveforms have different lengths: {} and {} for {}."".format(len(s_wav), len(d_wav), s_basename))\n\t\t\tif np.isnan(s_wav).any() or np.isinf(s_wav).any():\n\t\t\t\traise ValueError(""The clean speech waveform has either NaN or Inf values: {}."".format(j))\n\t\t\tif np.isnan(d_wav).any() or np.isinf(d_wav).any():\n\t\t\t\traise ValueError(""The noise waveform has either NaN or Inf values: {}."".format(k))\n\t\t\tval_s_list.append(s_wav)\n\t\t\tval_d_list.append(d_wav)\n\t\t\tval_s_len_list.append(len(s_wav))\n\t\t\tval_d_len_list.append(len(d_wav))\n\t\t\tval_snr_list.append(float(s_basename.split(""_"")[-1][:-2]))\n\tif len(val_s_len_list) != len(val_d_len_list):\n\t\traise ValueError(""The number of clean speech and noise validation files do not match."")\n\tmax_wav_len = max(val_s_len_list) # maximum length of waveforms.\n\tval_s = np.zeros([len(val_s_len_list), max_wav_len], np.int16) # numpy array for padded waveform matrix.\n\tval_d = np.zeros([len(val_d_len_list), max_wav_len], np.int16) # numpy array for padded waveform matrix.\n\tfor (i, s_wav) in enumerate(val_s_list): val_s[i,:len(s_wav)] = s_wav # add clean-speech waveform to numpy array.\n\tfor (i, d_wav) in enumerate(val_d_list): val_d[i,:len(d_wav)] = d_wav # add noise waveform to numpy array.\n\tval_s_len = np.array(val_s_len_list, np.int32)\n\tval_d_len = np.array(val_d_len_list, np.int32)\n\tval_snr = np.array(val_snr_list, np.int32)\n\treturn val_s, val_d, val_s_len, val_d_len, val_snr\n'"
deepxi/network/rnn.py,0,"b'## AUTHOR:         Aaron Nicolson\n## AFFILIATION:    Signal Processing Laboratory, Griffith University.\n##\n## This Source Code Form is subject to the terms of the Mozilla Public\n## License, v. 2.0. If a copy of the MPL was not distributed with this\n## file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Activation, Add, Dense, \\\n\tLayerNormalization, LSTM, ReLU, TimeDistributed\nimport numpy as np\n\nclass ResLSTM:\n\t""""""\n\tResidual long short-term memory network. Frame-wise layer normalisation is\n\tused.\n\t""""""\n\tdef __init__(\n\t\tself,\n\t\tinp,\n\t\tn_outp,\n\t\tn_blocks,\n\t\td_model,\n\t\t):\n\t\t""""""\n\t\tArgument/s:\n\t\t\tinp - input placeholder.\n\t\t\tn_outp - number of output nodes.\n\t\t\tn_blocks - number of residual blocks.\n\t\t\td_model - model size.\n\t\t""""""\n\t\tself.n_outp = n_outp\n\t\tself.d_model = d_model\n\t\tself.first_layer = self.feedforward(inp)\n\t\tself.layer_list = [self.first_layer]\n\t\tfor _ in range(n_blocks): self.layer_list.append(self.block(self.layer_list[-1]))\n\t\tself.logits = TimeDistributed(Dense(self.n_outp))(self.layer_list[-1])\n\t\tself.outp = Activation(\'sigmoid\')(self.logits)\n\n\tdef feedforward(self, inp):\n\t\t""""""\n\t\tFeedforward layer.\n\n\t\tArgument/s:\n\t\t\tinp - input placeholder.\n\n\t\tReturns:\n\t\t\tact - output of feedforward layer.\n\t\t""""""\n\t\tff = TimeDistributed(Dense(self.d_model, use_bias=False))(inp)\n\t\tnorm = LayerNormalization(axis=2, epsilon=1e-6)(ff)\n\t\tact = ReLU()(norm)\n\t\treturn act\n\n\tdef block(self, inp):\n\t\t""""""\n\t\tResidual LSTM block.\n\n\t\tArgument/s:\n\t\t\tinp - input placeholder.\n\n\t\tReturns:\n\t\t\tresidual - output of block.\n\t\t""""""\n\t\tlstm = LSTM(self.d_model)(inp)\n\t\tresidual = Add()([inp, lstm])\n\t\treturn residual\n'"
deepxi/network/tcn.py,0,"b'## AUTHOR:         Aaron Nicolson\n## AFFILIATION:    Signal Processing Laboratory, Griffith University.\n##\n## This Source Code Form is subject to the terms of the Mozilla Public\n## License, v. 2.0. If a copy of the MPL was not distributed with this\n## file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Activation, Add, Conv1D, Conv2D, Dense, Dropout, \\\n\tFlatten, LayerNormalization, MaxPooling2D, ReLU\nimport numpy as np\n\nclass ResNet:\n\t""""""\n\tResidual network using bottlekneck residual blocks and cyclic\n\tdilation rate. Frame-wise layer normalisation is used.\n\t""""""\n\tdef __init__(\n\t\tself,\n\t\tinp,\n\t\tn_outp,\n\t\tn_blocks,\n\t\td_model,\n\t\td_f,\n\t\tk,\n\t\tmax_d_rate,\n\t\tpadding,\n\t\t):\n\t\t""""""\n\t\tArgument/s:\n\t\t\tinp - input placeholder.\n\t\t\tn_outp - number of output nodes.\n\t\t\tn_blocks - number of bottlekneck residual blocks.\n\t\t\td_model - model size.\n\t\t\td_f - bottlekneck size.\n\t\t\tk - kernel size.\n\t\t\tmax_d_rate - maximum dilation rate.\n\t\t\tpadding - padding type.\n\t\t""""""\n\t\tself.d_model = d_model\n\t\tself.d_f = d_f\n\t\tself.k = k\n\t\tself.n_outp = n_outp\n\t\tself.padding = padding\n\t\tself.first_layer = self.feedforward(inp)\n\t\tself.layer_list = [self.first_layer]\n\t\tfor i in range(n_blocks): self.layer_list.append(self.block(self.layer_list[-1], int(2**(i%(np.log2(max_d_rate)+1)))))\n\t\tself.logits = Conv1D(self.n_outp, 1, dilation_rate=1, use_bias=True)(self.layer_list[-1])\n\t\tself.outp = Activation(\'sigmoid\')(self.logits)\n\n\tdef feedforward(self, inp):\n\t\t""""""\n\t\tFeedforward layer.\n\n\t\tArgument/s:\n\t\t\tinp - input placeholder.\n\n\t\tReturns:\n\t\t\tact - feedforward layer output.\n\t\t""""""\n\t\tff = Conv1D(self.d_model, 1, dilation_rate=1, use_bias=False)(inp)\n\t\tnorm = LayerNormalization(axis=2, epsilon=1e-6)(ff)\n\t\tact = ReLU()(norm)\n\t\treturn act\n\n\tdef block(self, inp, d_rate):\n\t\t""""""\n\t\tBottlekneck residual block.\n\n\t\tArgument/s:\n\t\t\tinp - input placeholder.\n\t\t\td_rate - dilation rate.\n\n\t\tReturns:\n\t\t\tresidual - output of block.\n\t\t""""""\n\t\tself.conv_1 = self.unit(inp, self.d_f, 1, 1, False)\n\t\tself.conv_2 = self.unit(self.conv_1, self.d_f, self.k, d_rate,\n\t\t\tFalse)\n\t\tself.conv_3 = self.unit(self.conv_2, self.d_model, 1, 1, True)\n\t\tresidual = Add()([inp, self.conv_3])\n\t\treturn residual\n\n\tdef unit(self, inp, n_filt, k, d_rate, use_bias):\n\t\t""""""\n\t\tConvolutional unit.\n\n\t\tArgument/s:\n\t\t\tinp - input placeholder.\n\t\t\tn_filt - filter size.\n\t\t\tk - kernel size.\n\t\t\td_rate - dilation rate.\n\t\t\tuse_bias - bias flag.\n\n\t\tReturns:\n\t\t\tconv - output of unit.\n\t\t""""""\n\t\tnorm = LayerNormalization(axis=2, epsilon=1e-6)(inp)\n\t\tact = ReLU()(norm)\n\t\tconv = Conv1D(n_filt, k, padding=self.padding, dilation_rate=d_rate,\n\t\t\tuse_bias=use_bias)(act)\n\t\treturn conv\n'"
