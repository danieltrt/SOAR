file_path,api_count,code
conv2d.py,13,"b'import tensorflow as tf\n\nimport utils\nfrom layer import Layer\nfrom libs.activations import lrelu\n\n\nclass Conv2d(Layer):\n    # global things...\n    layer_index = 0\n\n    def __init__(self, kernel_size, strides, output_channels, name):\n        self.kernel_size = kernel_size\n        self.strides = strides\n        self.output_channels = output_channels\n        self.name = name\n\n    @staticmethod\n    def reverse_global_variables():\n        Conv2d.layer_index = 0\n\n    def create_layer(self, input):\n        # print(\'convd2: input_shape: {}\'.format(utils.get_incoming_shape(input)))\n        self.input_shape = utils.get_incoming_shape(input)\n        number_of_input_channels = self.input_shape[3]\n\n        with tf.variable_scope(\'conv\', reuse=False):\n            W = tf.get_variable(\'W{}\'.format(self.name[-3:]),\n                                shape=(self.kernel_size, self.kernel_size, number_of_input_channels, self.output_channels))\n            b = tf.Variable(tf.zeros([self.output_channels]))\n        self.encoder_matrix = W\n        Conv2d.layer_index += 1\n\n        output = tf.nn.conv2d(input, W, strides=self.strides, padding=\'SAME\')\n\n        # print(\'convd2: output_shape: {}\'.format(utils.get_incoming_shape(output)))\n\n        output = lrelu(tf.add(tf.contrib.layers.batch_norm(output), b))\n\n        return output\n\n    def create_layer_reversed(self, input, prev_layer=None):\n        # print(\'convd2_transposed: input_shape: {}\'.format(utils.get_incoming_shape(input)))\n        # W = self.encoder[layer_index]\n        with tf.variable_scope(\'conv\', reuse=True):\n            W = tf.get_variable(\'W{}\'.format(self.name[-3:]))\n            b = tf.Variable(tf.zeros([W.get_shape().as_list()[2]]))\n\n        # if self.strides==[1, 1, 1, 1]:\n        #     print(\'Now\')\n        #     output = lrelu(tf.add(\n        #         tf.nn.conv2d(input, W,strides=self.strides, padding=\'SAME\'), b))\n        # else:\n        #     print(\'1Now1\')\n        output = tf.nn.conv2d_transpose(\n            input, W,\n            tf.stack([tf.shape(input)[0], self.input_shape[1], self.input_shape[2], self.input_shape[3]]),\n            strides=self.strides, padding=\'SAME\')\n\n        Conv2d.layer_index += 1\n        output.set_shape([None, self.input_shape[1], self.input_shape[2], self.input_shape[3]])\n\n        output = lrelu(tf.add(tf.contrib.layers.batch_norm(output), b))\n        # print(\'convd2_transposed: output_shape: {}\'.format(utils.get_incoming_shape(output)))\n\n        return output\n\n    def get_description(self):\n        return ""C{},{},{}"".format(self.kernel_size, self.output_channels, self.strides[1])\n'"
convolutional_autoencoder.py,25,"b'import math\nimport os\nimport time\nfrom math import ceil\n\nimport cv2\nimport matplotlib\n\nmatplotlib.use(\'Agg\')\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import gen_nn_ops\n\nfrom imgaug import augmenters as iaa\nfrom imgaug import imgaug\nfrom conv2d import Conv2d\nfrom max_pool_2d import MaxPool2d\nimport datetime\nimport io\n\nnp.set_printoptions(threshold=np.nan)\n\n\n# @ops.RegisterGradient(""MaxPoolWithArgmax"")\n# def _MaxPoolWithArgmaxGrad(op, grad, unused_argmax_grad):\n#     return gen_nn_ops._max_pool_grad(op.inputs[0],\n#                                      op.outputs[0],\n#                                      grad,\n#                                      op.get_attr(""ksize""),\n#                                      op.get_attr(""strides""),\n#                                      padding=op.get_attr(""padding""),\n#                                      data_format=\'NHWC\')\n\n\nclass Network:\n    IMAGE_HEIGHT = 128\n    IMAGE_WIDTH = 128\n    IMAGE_CHANNELS = 1\n\n    def __init__(self, layers=None, per_image_standardization=True, batch_norm=True, skip_connections=True):\n        # Define network - ENCODER (decoder will be symmetric).\n\n        if layers == None:\n            layers = []\n            layers.append(Conv2d(kernel_size=7, strides=[1, 2, 2, 1], output_channels=64, name=\'conv_1_1\'))\n            layers.append(Conv2d(kernel_size=7, strides=[1, 1, 1, 1], output_channels=64, name=\'conv_1_2\'))\n            layers.append(MaxPool2d(kernel_size=2, name=\'max_1\', skip_connection=skip_connections))\n\n            layers.append(Conv2d(kernel_size=7, strides=[1, 2, 2, 1], output_channels=64, name=\'conv_2_1\'))\n            layers.append(Conv2d(kernel_size=7, strides=[1, 1, 1, 1], output_channels=64, name=\'conv_2_2\'))\n            layers.append(MaxPool2d(kernel_size=2, name=\'max_2\', skip_connection=skip_connections))\n\n            layers.append(Conv2d(kernel_size=7, strides=[1, 2, 2, 1], output_channels=64, name=\'conv_3_1\'))\n            layers.append(Conv2d(kernel_size=7, strides=[1, 1, 1, 1], output_channels=64, name=\'conv_3_2\'))\n            layers.append(MaxPool2d(kernel_size=2, name=\'max_3\'))\n\n        self.inputs = tf.placeholder(tf.float32, [None, self.IMAGE_HEIGHT, self.IMAGE_WIDTH, self.IMAGE_CHANNELS],\n                                     name=\'inputs\')\n        self.targets = tf.placeholder(tf.float32, [None, self.IMAGE_HEIGHT, self.IMAGE_WIDTH, 1], name=\'targets\')\n        self.is_training = tf.placeholder_with_default(False, [], name=\'is_training\')\n        self.description = """"\n\n        self.layers = {}\n\n        if per_image_standardization:\n            list_of_images_norm = tf.map_fn(tf.image.per_image_standardization, self.inputs)\n            net = tf.stack(list_of_images_norm)\n        else:\n            net = self.inputs\n\n        # ENCODER\n        for layer in layers:\n            self.layers[layer.name] = net = layer.create_layer(net)\n            self.description += ""{}"".format(layer.get_description())\n\n        print(""Current input shape: "", net.get_shape())\n\n        layers.reverse()\n        Conv2d.reverse_global_variables()\n\n        # DECODER\n        for layer in layers:\n            net = layer.create_layer_reversed(net, prev_layer=self.layers[layer.name])\n\n        self.segmentation_result = tf.sigmoid(net)\n\n        # segmentation_as_classes = tf.reshape(self.y, [50 * self.IMAGE_HEIGHT * self.IMAGE_WIDTH, 1])\n        # targets_as_classes = tf.reshape(self.targets, [50 * self.IMAGE_HEIGHT * self.IMAGE_WIDTH])\n        # print(self.y.get_shape())\n        # self.cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(segmentation_as_classes, targets_as_classes))\n        print(\'segmentation_result.shape: {}, targets.shape: {}\'.format(self.segmentation_result.get_shape(),\n                                                                        self.targets.get_shape()))\n\n        # MSE loss\n        self.cost = tf.sqrt(tf.reduce_mean(tf.square(self.segmentation_result - self.targets)))\n        self.train_op = tf.train.AdamOptimizer().minimize(self.cost)\n        with tf.name_scope(\'accuracy\'):\n            argmax_probs = tf.round(self.segmentation_result)  # 0x1\n            correct_pred = tf.cast(tf.equal(argmax_probs, self.targets), tf.float32)\n            self.accuracy = tf.reduce_mean(correct_pred)\n\n            tf.summary.scalar(\'accuracy\', self.accuracy)\n\n        self.summaries = tf.summary.merge_all()\n\n\nclass Dataset:\n    def __init__(self, batch_size, folder=\'data128_128\', include_hair=False):\n        self.batch_size = batch_size\n        self.include_hair = include_hair\n\n        train_files, validation_files, test_files = self.train_valid_test_split(\n            os.listdir(os.path.join(folder, \'inputs\')))\n\n        self.train_inputs, self.train_targets = self.file_paths_to_images(folder, train_files)\n        self.test_inputs, self.test_targets = self.file_paths_to_images(folder, test_files, True)\n\n        self.pointer = 0\n\n    def file_paths_to_images(self, folder, files_list, verbose=False):\n        inputs = []\n        targets = []\n\n        for file in files_list:\n            input_image = os.path.join(folder, \'inputs\', file)\n            target_image = os.path.join(folder, \'targets\' if self.include_hair else \'targets_face_only\', file)\n\n            test_image = np.array(cv2.imread(input_image, 0))  # load grayscale\n            # test_image = np.multiply(test_image, 1.0 / 255)\n            inputs.append(test_image)\n\n            target_image = cv2.imread(target_image, 0)\n            target_image = cv2.threshold(target_image, 127, 1, cv2.THRESH_BINARY)[1]\n            targets.append(target_image)\n\n        return inputs, targets\n\n    def train_valid_test_split(self, X, ratio=None):\n        if ratio is None:\n            ratio = (0.7, .15, .15)\n\n        N = len(X)\n        return (\n            X[:int(ceil(N * ratio[0]))],\n            X[int(ceil(N * ratio[0])): int(ceil(N * ratio[0] + N * ratio[1]))],\n            X[int(ceil(N * ratio[0] + N * ratio[1])):]\n        )\n\n    def num_batches_in_epoch(self):\n        return int(math.floor(len(self.train_inputs) / self.batch_size))\n\n    def reset_batch_pointer(self):\n        permutation = np.random.permutation(len(self.train_inputs))\n        self.train_inputs = [self.train_inputs[i] for i in permutation]\n        self.train_targets = [self.train_targets[i] for i in permutation]\n\n        self.pointer = 0\n\n    def next_batch(self):\n        inputs = []\n        targets = []\n        # print(self.batch_size, self.pointer, self.train_inputs.shape, self.train_targets.shape)\n        for i in range(self.batch_size):\n            inputs.append(np.array(self.train_inputs[self.pointer + i]))\n            targets.append(np.array(self.train_targets[self.pointer + i]))\n\n        self.pointer += self.batch_size\n\n        return np.array(inputs, dtype=np.uint8), np.array(targets, dtype=np.uint8)\n\n    @property\n    def test_set(self):\n        return np.array(self.test_inputs, dtype=np.uint8), np.array(self.test_targets, dtype=np.uint8)\n\n\ndef draw_results(test_inputs, test_targets, test_segmentation, test_accuracy, network, batch_num):\n    n_examples_to_plot = 12\n    fig, axs = plt.subplots(4, n_examples_to_plot, figsize=(n_examples_to_plot * 3, 10))\n    fig.suptitle(""Accuracy: {}, {}"".format(test_accuracy, network.description), fontsize=20)\n    for example_i in range(n_examples_to_plot):\n        axs[0][example_i].imshow(test_inputs[example_i], cmap=\'gray\')\n        axs[1][example_i].imshow(test_targets[example_i].astype(np.float32), cmap=\'gray\')\n        axs[2][example_i].imshow(\n            np.reshape(test_segmentation[example_i], [network.IMAGE_HEIGHT, network.IMAGE_WIDTH]),\n            cmap=\'gray\')\n\n        test_image_thresholded = np.array(\n            [0 if x < 0.5 else 255 for x in test_segmentation[example_i].flatten()])\n        axs[3][example_i].imshow(\n            np.reshape(test_image_thresholded, [network.IMAGE_HEIGHT, network.IMAGE_WIDTH]),\n            cmap=\'gray\')\n\n    buf = io.BytesIO()\n    plt.savefig(buf, format=\'png\')\n    buf.seek(0)\n\n    IMAGE_PLOT_DIR = \'image_plots/\'\n    if not os.path.exists(IMAGE_PLOT_DIR):\n        os.makedirs(IMAGE_PLOT_DIR)\n\n    plt.savefig(\'{}/figure{}.jpg\'.format(IMAGE_PLOT_DIR, batch_num))\n    return buf\n\n\ndef train():\n    BATCH_SIZE = 100\n\n    network = Network()\n\n    timestamp = datetime.datetime.now().strftime(""%Y-%m-%d_%H%M%S"")\n\n    # create directory for saving models\n    os.makedirs(os.path.join(\'save\', network.description, timestamp))\n\n    dataset = Dataset(folder=\'data{}_{}\'.format(network.IMAGE_HEIGHT, network.IMAGE_WIDTH), include_hair=False,\n                      batch_size=BATCH_SIZE)\n\n    inputs, targets = dataset.next_batch()\n    print(inputs.shape, targets.shape)\n\n    # augmentation_seq = iaa.Sequential([\n    #     iaa.Crop(px=(0, 16)),  # crop images from each side by 0 to 16px (randomly chosen)\n    #     iaa.Fliplr(0.5),  # horizontally flip 50% of the images\n    #     iaa.GaussianBlur(sigma=(0, 2.0))  # blur images with a sigma of 0 to 3.0\n    # ])\n\n    augmentation_seq = iaa.Sequential([\n        iaa.Crop(px=(0, 16), name=""Cropper""),  # crop images from each side by 0 to 16px (randomly chosen)\n        iaa.Fliplr(0.5, name=""Flipper""),\n        iaa.GaussianBlur((0, 3.0), name=""GaussianBlur""),\n        iaa.Dropout(0.02, name=""Dropout""),\n        iaa.AdditiveGaussianNoise(scale=0.01 * 255, name=""GaussianNoise""),\n        iaa.Affine(translate_px={""x"": (-network.IMAGE_HEIGHT // 3, network.IMAGE_WIDTH // 3)}, name=""Affine"")\n    ])\n\n    # change the activated augmenters for binary masks,\n    # we only want to execute horizontal crop, flip and affine transformation\n    def activator_binmasks(images, augmenter, parents, default):\n        if augmenter.name in [""GaussianBlur"", ""Dropout"", ""GaussianNoise""]:\n            return False\n        else:\n            # default value for all other augmenters\n            return default\n\n    hooks_binmasks = imgaug.HooksImages(activator=activator_binmasks)\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n        summary_writer = tf.summary.FileWriter(\'{}/{}-{}\'.format(\'logs\', network.description, timestamp),\n                                               graph=tf.get_default_graph())\n        saver = tf.train.Saver(tf.all_variables(), max_to_keep=None)\n\n        test_accuracies = []\n        # Fit all training data\n        n_epochs = 500\n        global_start = time.time()\n        for epoch_i in range(n_epochs):\n            dataset.reset_batch_pointer()\n\n            for batch_i in range(dataset.num_batches_in_epoch()):\n                batch_num = epoch_i * dataset.num_batches_in_epoch() + batch_i + 1\n\n                augmentation_seq_deterministic = augmentation_seq.to_deterministic()\n\n                start = time.time()\n                batch_inputs, batch_targets = dataset.next_batch()\n                batch_inputs = np.reshape(batch_inputs,\n                                          (dataset.batch_size, network.IMAGE_HEIGHT, network.IMAGE_WIDTH, 1))\n                batch_targets = np.reshape(batch_targets,\n                                           (dataset.batch_size, network.IMAGE_HEIGHT, network.IMAGE_WIDTH, 1))\n\n                batch_inputs = augmentation_seq_deterministic.augment_images(batch_inputs)\n                batch_inputs = np.multiply(batch_inputs, 1.0 / 255)\n\n                batch_targets = augmentation_seq_deterministic.augment_images(batch_targets, hooks=hooks_binmasks)\n\n                cost, _ = sess.run([network.cost, network.train_op],\n                                   feed_dict={network.inputs: batch_inputs, network.targets: batch_targets,\n                                              network.is_training: True})\n                end = time.time()\n                print(\'{}/{}, epoch: {}, cost: {}, batch time: {}\'.format(batch_num,\n                                                                          n_epochs * dataset.num_batches_in_epoch(),\n                                                                          epoch_i, cost, end - start))\n\n                if batch_num % 100 == 0 or batch_num == n_epochs * dataset.num_batches_in_epoch():\n                    test_inputs, test_targets = dataset.test_set\n                    # test_inputs, test_targets = test_inputs[:100], test_targets[:100]\n\n                    test_inputs = np.reshape(test_inputs, (-1, network.IMAGE_HEIGHT, network.IMAGE_WIDTH, 1))\n                    test_targets = np.reshape(test_targets, (-1, network.IMAGE_HEIGHT, network.IMAGE_WIDTH, 1))\n                    test_inputs = np.multiply(test_inputs, 1.0 / 255)\n\n                    print(test_inputs.shape)\n                    summary, test_accuracy = sess.run([network.summaries, network.accuracy],\n                                                      feed_dict={network.inputs: test_inputs,\n                                                                 network.targets: test_targets,\n                                                                 network.is_training: False})\n\n                    summary_writer.add_summary(summary, batch_num)\n\n                    print(\'Step {}, test accuracy: {}\'.format(batch_num, test_accuracy))\n                    test_accuracies.append((test_accuracy, batch_num))\n                    print(""Accuracies in time: "", [test_accuracies[x][0] for x in range(len(test_accuracies))])\n                    max_acc = max(test_accuracies)\n                    print(""Best accuracy: {} in batch {}"".format(max_acc[0], max_acc[1]))\n                    print(""Total time: {}"".format(time.time() - global_start))\n\n                    # Plot example reconstructions\n                    n_examples = 12\n                    test_inputs, test_targets = dataset.test_inputs[:n_examples], dataset.test_targets[:n_examples]\n                    test_inputs = np.multiply(test_inputs, 1.0 / 255)\n\n                    test_segmentation = sess.run(network.segmentation_result, feed_dict={\n                        network.inputs: np.reshape(test_inputs,\n                                                   [n_examples, network.IMAGE_HEIGHT, network.IMAGE_WIDTH, 1])})\n\n                    # Prepare the plot\n                    test_plot_buf = draw_results(test_inputs, test_targets, test_segmentation, test_accuracy, network,\n                                                 batch_num)\n\n                    # Convert PNG buffer to TF image\n                    image = tf.image.decode_png(test_plot_buf.getvalue(), channels=4)\n\n                    # Add the batch dimension\n                    image = tf.expand_dims(image, 0)\n\n                    # Add image summary\n                    image_summary_op = tf.summary.image(""plot"", image)\n\n                    image_summary = sess.run(image_summary_op)\n                    summary_writer.add_summary(image_summary)\n\n                    if test_accuracy >= max_acc[0]:\n                        checkpoint_path = os.path.join(\'save\', network.description, timestamp, \'model.ckpt\')\n                        saver.save(sess, checkpoint_path, global_step=batch_num)\n\n\nif __name__ == \'__main__\':\n    train()\n'"
infer.py,3,"b'import io\nimport os\n\nimport tensorflow as tf\nimport convolutional_autoencoder\nfrom conv2d import Conv2d\nfrom max_pool_2d import MaxPool2d\nimport numpy as np\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nif __name__ == \'__main__\':\n\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""model_dir"", default="""", type=str, help=""Path to directory storing checkpointed model."")\n    parser.add_argument(""input_image"", default="""", type=str, help=""Path to image for which the segmentation should be performed."")\n    parser.add_argument(""--out"", default=""/tmp"", type=str, help=""Path to directory to store resulting image."")\n    args = parser.parse_args()\n\n\n    layers = []\n    layers.append(Conv2d(kernel_size=7, strides=[1, 2, 2, 1], output_channels=64, name=\'conv_1_1\'))\n    layers.append(Conv2d(kernel_size=7, strides=[1, 1, 1, 1], output_channels=64, name=\'conv_1_2\'))\n    layers.append(MaxPool2d(kernel_size=2, name=\'max_1\', skip_connection=True))\n\n    layers.append(Conv2d(kernel_size=7, strides=[1, 2, 2, 1], output_channels=64, name=\'conv_2_1\'))\n    layers.append(Conv2d(kernel_size=7, strides=[1, 1, 1, 1], output_channels=64, name=\'conv_2_2\'))\n    layers.append(MaxPool2d(kernel_size=2, name=\'max_2\', skip_connection=True))\n\n    layers.append(Conv2d(kernel_size=7, strides=[1, 2, 2, 1], output_channels=64, name=\'conv_3_1\'))\n    layers.append(Conv2d(kernel_size=7, strides=[1, 1, 1, 1], output_channels=64, name=\'conv_3_2\'))\n    layers.append(MaxPool2d(kernel_size=2, name=\'max_3\'))\n\n\n    network = convolutional_autoencoder.Network(layers)\n\n\n    input_image = args.input_image\n    checkpoint = args.model_dir\n\n    with tf.Session() as sess:\n        saver = tf.train.Saver(tf.all_variables())\n        ckpt = tf.train.get_checkpoint_state(checkpoint)\n        if ckpt and ckpt.model_checkpoint_path:\n            print(\'Restoring model: {}\'.format(ckpt.model_checkpoint_path))\n            saver.restore(sess, ckpt.model_checkpoint_path)\n        else:\n            raise IOError(\'No model found in {}.\'.format(checkpoint))\n\n\n        image = np.array(cv2.imread(input_image, 0))  # load grayscale\n        image = cv2.resize(image, (network.IMAGE_HEIGHT, network.IMAGE_WIDTH))\n        image = np.multiply(image, 1.0/255)\n        # cv2.imshow(\'image\', image)\n        # cv2.waitKey(0)\n\n        print(image.shape)\n\n        segmentation = sess.run(network.segmentation_result, feed_dict={\n            network.inputs: np.reshape(image, [1, network.IMAGE_HEIGHT, network.IMAGE_WIDTH, 1])})\n\n        segmented_image = np.dot(segmentation[0], 255)\n\n        # print(segmentation[0].shape)\n        # fig, axs = plt.subplots(2, 1, figsize=(1 * 3, 10))\n        # axs[0].imshow(image, cmap=\'gray\')\n        # axs[1].imshow(np.reshape(segmentation[0],(128,128)), cmap=\'gray\')\n\n        # plt.show()\n        cv2.imwrite(os.path.join(args.out, \'result.jpg\'), segmented_image)\n        # plt.savefig(os.path.join(args.out, \'result.jpg\'))\n        # plt.waitforbuttonpress()\n\n\n'"
layer.py,0,"b'class Layer():\n    def create_layer(self, input):\n        pass\n\n    def create_layer_reversed(self, input):\n        pass\n\n    def get_description(self):\n        pass\n'"
max_pool_2d.py,1,"b'import tensorflow as tf\n\nimport utils\nfrom layer import Layer\n\nclass MaxPool2d(Layer):\n    def __init__(self, kernel_size, name, skip_connection=False):\n        self.kernel_size = kernel_size\n        self.name = name\n        self.skip_connection = skip_connection\n\n    def create_layer(self, input):\n        return utils.max_pool_2d(input, self.kernel_size)\n\n    def create_layer_reversed(self, input, prev_layer=None):\n        if self.skip_connection:\n            input = tf.add(input, prev_layer)\n\n        return utils.upsample_2d(input, self.kernel_size)\n\n    def get_description(self):\n        return ""M{}"".format(self.kernel_size)\n'"
utils.py,9,"b'import tensorflow as tf\nimport numpy as np\n\n# Auto format padding\ndef autoformat_padding(padding):\n    if padding in [\'same\', \'SAME\', \'valid\', \'VALID\']:\n        return str.upper(padding)\n    else:\n        raise Exception(""Unknown padding! Accepted values: \'same\', \'valid\'."")\n\n\ndef get_incoming_shape(incoming):\n    """""" Returns the incoming data shape """"""\n    if isinstance(incoming, tf.Tensor):\n        return incoming.get_shape().as_list()\n    elif type(incoming) in [np.array, list, tuple]:\n        return np.shape(incoming)\n    else:\n        raise Exception(""Invalid incoming layer."")\n\n# Auto format kernel\ndef autoformat_kernel_2d(strides):\n    if isinstance(strides, int):\n        return [1, strides, strides, 1]\n    elif isinstance(strides, (tuple, list)):\n        if len(strides) == 2:\n            return [1, strides[0], strides[1], 1]\n        elif len(strides) == 4:\n            return [strides[0], strides[1], strides[2], strides[3]]\n        else:\n            raise Exception(""strides length error: "" + str(len(strides))\n                            + "", only a length of 2 or 4 is supported."")\n    else:\n        raise Exception(""strides format error: "" + str(type(strides)))\n\n\ndef max_pool_2d(incoming, kernel_size, strides=None, padding=\'same\',\n                name=""MaxPool2D""):\n    """""" Max Pooling 2D.\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n    Output:\n        4-D Tensor [batch, pooled height, pooled width, in_channels].\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Layer.\n        kernel_size: \'int` or `list of int`. Pooling kernel size.\n        strides: \'int` or `list of int`. Strides of conv operation.\n            Default: same as kernel_size.\n        padding: `str` from `""same"", ""valid""`. Padding algo to use.\n            Default: \'same\'.\n        name: A name for this layer (optional). Default: \'MaxPool2D\'.\n    Attributes:\n        scope: `Scope`. This layer scope.\n    """"""\n    input_shape = get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D""\n\n    kernel = autoformat_kernel_2d(kernel_size)\n    strides = autoformat_kernel_2d(strides) if strides else kernel\n    padding = autoformat_padding(padding)\n\n    with tf.name_scope(name) as scope:\n        inference = tf.nn.max_pool(incoming, kernel, strides, padding)\n\n        # Track activations.\n        tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, inference)\n\n    # Add attributes to Tensor to easy access weights\n    inference.scope = scope\n\n    # Track output tensor.\n    # tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n\n\ndef upsample_2d(incoming, kernel_size, name=""UpSample2D""):\n    """""" UpSample 2D.\n    Input:\n        4-D Tensor [batch, height, width, in_channels].\n    Output:\n        4-D Tensor [batch, pooled height, pooled width, in_channels].\n    Arguments:\n        incoming: `Tensor`. Incoming 4-D Layer to upsample.\n        kernel_size: \'int` or `list of int`. Upsampling kernel size.\n        name: A name for this layer (optional). Default: \'UpSample2D\'.\n    Attributes:\n        scope: `Scope`. This layer scope.\n    """"""\n    input_shape = get_incoming_shape(incoming)\n    assert len(input_shape) == 4, ""Incoming Tensor shape must be 4-D""\n    kernel = autoformat_kernel_2d(kernel_size)\n\n    with tf.name_scope(name) as scope:\n        inference = tf.image.resize_nearest_neighbor(\n            incoming, size=input_shape[1:3] * tf.constant(kernel[1:3]))\n        inference.set_shape((None, input_shape[1] * kernel[1],\n                             input_shape[2] * kernel[2], None))\n\n    # Add attributes to Tensor to easy access weights\n    inference.scope = scope\n\n    # Track output tensor.\n    # tf.add_to_collection(tf.GraphKeys.LAYER_TENSOR + \'/\' + name, inference)\n\n    return inference\n'"
imgaug/__init__.py,0,b''
imgaug/augmenters.py,8,"b'from __future__ import print_function, division\nfrom abc import ABCMeta, abstractmethod\nimport random\nimport numpy as np\nimport copy as copy_module\nimport re\nimport math\nfrom scipy import misc, ndimage\nfrom skimage import transform as tf\nimport itertools\nimport imgaug.imgaug as ia\nfrom .parameters import StochasticParameter, Deterministic, Binomial, Choice, DiscreteUniform, Normal, Uniform\n\ntry:\n    xrange\nexcept NameError:  # python3\n    xrange = range\n\nclass Augmenter(object):\n    __metaclass__ = ABCMeta\n\n    def __init__(self, name=None, deterministic=False, random_state=None):\n        if name is None:\n            self.name = ""Unnamed%s"" % (self.__class__.__name__,)\n        else:\n            self.name = name\n\n        self.deterministic = deterministic\n\n        if random_state is None:\n            if self.deterministic:\n                self.random_state = ia.new_random_state()\n            else:\n                self.random_state = ia.current_random_state()\n        elif isinstance(random_state, np.random.RandomState):\n            self.random_state = random_state\n        else:\n            self.random_state = np.random.RandomState(random_state)\n\n        self.activated = True\n\n    def augment_batches(self, batches, hooks=None):\n        assert isinstance(batches, list)\n        return [self.augment_images(batch, hooks=hooks) for batch in batches]\n\n    def augment_image(self, image, hooks=None):\n        assert len(image.shape) == 3, ""Expected image to have shape (height, width, channels), got shape %s."" % (image.shape,)\n        return self.augment_images([image], hooks=hooks)[0]\n\n    def augment_images(self, images, parents=None, hooks=None):\n        if self.deterministic:\n            state_orig = self.random_state.get_state()\n\n        if parents is None:\n            parents = []\n\n        if hooks is None:\n            hooks = ia.HooksImages()\n\n        if ia.is_np_array(images):\n            assert len(images.shape) == 4, ""Expected 4d array of form (N, height, width, channels), got shape %s."" % (str(images.shape),)\n            assert images.dtype == np.uint8, ""Expected dtype uint8 (with value range 0 to 255), got dtype %s."" % (str(images.dtype),)\n            images_tf = images\n        elif ia.is_iterable(images):\n            if len(images) > 0:\n                assert all([len(image.shape) == 3 for image in images]), ""Expected list of images with each image having shape (height, width, channels), got shapes %s."" % ([image.shape for image in images],)\n                assert all([image.dtype == np.uint8 for image in images]), ""Expected dtype uint8 (with value range 0 to 255), got dtypes %s."" % ([str(image.dtype) for image in images],)\n            images_tf = list(images)\n        else:\n            raise Exception(""Expected list/tuple of numpy arrays or one numpy array, got %s."" % (type(images),))\n\n        if isinstance(images_tf, list):\n            images_copy = [np.copy(image) for image in images]\n        else:\n            images_copy = np.copy(images)\n\n        images_copy = hooks.preprocess(images_copy, augmenter=self, parents=parents)\n\n        if hooks.is_activated(images_copy, augmenter=self, parents=parents, default=self.activated):\n            if len(images) > 0:\n                images_result = self._augment_images(\n                    images_copy,\n                    random_state=ia.copy_random_state(self.random_state),\n                    parents=parents,\n                    hooks=hooks\n                )\n                self.random_state.uniform()\n            else:\n                images_result = images_copy\n        else:\n            images_result = images_copy\n\n        images_result = hooks.postprocess(images_result, augmenter=self, parents=parents)\n\n        if self.deterministic:\n            self.random_state.set_state(state_orig)\n\n        if isinstance(images_result, list):\n            assert all([image.dtype == np.uint8 for image in images_result]), ""Expected list of dtype uint8 as augmenter result, got %s."" % ([image.dtype for image in images_result],)\n        else:\n            assert images_result.dtype == np.uint8, ""Expected dtype uint8 as augmenter result, got %s."" % (images_result.dtype,)\n\n        return images_result\n\n    @abstractmethod\n    def _augment_images(self, images, random_state, parents, hooks):\n        raise NotImplementedError()\n\n    def augment_keypoints(self, keypoints_on_images, parents=None, hooks=None):\n        if self.deterministic:\n            state_orig = self.random_state.get_state()\n\n        if parents is None:\n            parents = []\n\n        if hooks is None:\n            hooks = ia.HooksKeypoints()\n\n        assert ia.is_iterable(keypoints_on_images)\n        assert all([isinstance(keypoints_on_image, ia.KeypointsOnImage) for keypoints_on_image in keypoints_on_images])\n\n        keypoints_on_images_copy = [keypoints_on_image.deepcopy() for keypoints_on_image in keypoints_on_images]\n\n        keypoints_on_images_copy = hooks.preprocess(keypoints_on_images_copy, augmenter=self, parents=parents)\n\n        if hooks.is_activated(keypoints_on_images_copy, augmenter=self, parents=parents, default=self.activated):\n            if len(keypoints_on_images_copy) > 0:\n                keypoints_on_images_result = self._augment_keypoints(\n                    keypoints_on_images_copy,\n                    random_state=ia.copy_random_state(self.random_state),\n                    parents=parents,\n                    hooks=hooks\n                )\n                self.random_state.uniform()\n            else:\n                keypoints_on_images_result = keypoints_on_images_copy\n        else:\n            keypoints_on_images_result = keypoints_on_images_copy\n\n        keypoints_on_images_result = hooks.postprocess(keypoints_on_images_result, augmenter=self, parents=parents)\n\n        if self.deterministic:\n            self.random_state.set_state(state_orig)\n\n        return keypoints_on_images_result\n\n    @abstractmethod\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        raise NotImplementedError()\n\n    # TODO most of the code of this function could be replaced with ia.draw_grid()\n    def draw_grid(self, images, rows, cols):\n        if ia.is_np_array(images):\n            if len(images.shape) == 4:\n                images = [images[i] for i in range(images.shape[0])]\n            elif len(images.shape) == 3:\n                images = [images]\n            elif len(images.shape) == 2:\n                images = [images[:, :, np.newaxis]]\n            else:\n                raise Exception(""Unexpected images shape, expected 2-, 3- or 4-dimensional array, got shape %s."" % (images.shape,))\n        assert isinstance(images, list)\n\n        det = self if self.deterministic else self.to_deterministic()\n        augs = []\n        for image in images:\n            augs.append(det.augment_images([image] * (rows * cols)))\n\n        augs_flat = list(itertools.chain(*augs))\n        cell_height = max([image.shape[0] for image in images] + [image.shape[0] for image in augs_flat])\n        cell_width = max([image.shape[1] for image in images] + [image.shape[1] for image in augs_flat])\n        width = cell_width * cols\n        height = cell_height * (rows * len(images))\n        grid = np.zeros((height, width, 3))\n        for row_idx in range(rows):\n            for img_idx, image in enumerate(images):\n                for col_idx in range(cols):\n                    image_aug = augs[img_idx][(row_idx * cols) + col_idx]\n                    cell_y1 = cell_height * (row_idx * len(images) + img_idx)\n                    cell_y2 = cell_y1 + image_aug.shape[0]\n                    cell_x1 = cell_width * col_idx\n                    cell_x2 = cell_x1 + image_aug.shape[1]\n                    grid[cell_y1:cell_y2, cell_x1:cell_x2, :] = image_aug\n\n        return grid\n\n    def show_grid(self, images, rows, cols):\n        grid = self.draw_grid(images, rows, cols)\n        misc.imshow(grid)\n\n    def to_deterministic(self, n=None):\n        if n is None:\n            return self.to_deterministic(1)[0]\n        else:\n            return [self._to_deterministic() for _ in xrange(n)]\n\n    def _to_deterministic(self):\n        aug = self.copy()\n        aug.random_state = ia.new_random_state()\n        aug.deterministic = True\n        return aug\n\n    def reseed(self, deterministic_too=False, random_state=None):\n        if random_state is None:\n            random_state = ia.current_random_state()\n        elif isinstance(random_state, np.random.RandomState):\n            pass # just use the provided random state without change\n        else:\n            random_state = ia.new_random_state(random_state)\n\n        if not self.deterministic or deterministic_too:\n            seed = random_state.randint(0, 10**6, 1)[0]\n            self.random_state = ia.new_random_state(seed)\n\n        for lst in self.get_children_lists():\n            for aug in lst:\n                aug.reseed(deterministic_too=deterministic_too, random_state=random_state)\n\n    @abstractmethod\n    def get_parameters(self):\n        raise NotImplementedError()\n\n    def get_children_lists(self):\n        return []\n\n    def find_augmenters(self, func, parents=None, flat=True):\n        if parents is None:\n            parents = []\n\n        result = []\n        if func(self, parents):\n            result.append(self)\n\n        subparents = parents + [self]\n        for lst in self.get_children_lists():\n            for aug in lst:\n                found = aug.find_augmenters(func, parents=subparents, flat=flat)\n                if len(found) > 0:\n                    if flat:\n                        result.extend(found)\n                    else:\n                        result.append(found)\n        return result\n\n    def find_augmenters_by_name(self, name, regex=False, flat=True):\n        return self.find_augmenters_by_names([name], regex=regex, flat=flat)\n\n    def find_augmenters_by_names(self, names, regex=False, flat=True):\n        if regex:\n            def comparer(aug, parents):\n                for pattern in names:\n                    if re.match(pattern, aug.name):\n                        return True\n                return False\n\n            return self.find_augmenters(comparer, flat=flat)\n        else:\n            return self.find_augmenters(lambda aug, parents: aug.name in names, flat=flat)\n\n    def remove_augmenters(self, func, copy=True, noop_if_topmost=True):\n        if func(self, []):\n            if not copy:\n                raise Exception(""Inplace removal of topmost augmenter requested, which is currently not possible."")\n\n            if noop_if_topmost:\n                return Noop()\n            else:\n                return None\n        else:\n            aug = self if not copy else self.deepcopy()\n            aug.remove_augmenters_inplace(func, parents=[])\n            return aug\n\n    def remove_augmenters_inplace(self, func, parents):\n        subparents = parents + [self]\n        for lst in self.get_children_lists():\n            to_remove = []\n            for i, aug in enumerate(lst):\n                if func(aug, subparents):\n                    to_remove.append((i, aug))\n\n            for count_removed, (i, aug) in enumerate(to_remove):\n                #self._remove_augmenters_inplace_from_list(lst, aug, i, i - count_removed)\n                del lst[i - count_removed]\n\n            for aug in lst:\n                aug.remove_augmenters_inplace(func, subparents)\n\n    # TODO\n    #def to_json(self):\n    #    pass\n\n    def copy(self):\n        return copy_module.copy(self)\n\n    def deepcopy(self):\n        return copy_module.deepcopy(self)\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __str__(self):\n        params = self.get_parameters()\n        params_str = "", "".join([param.__str__() for param in params])\n        return ""%s(name=%s, parameters=[%s], deterministic=%s)"" % (self.__class__.__name__, self.name, params_str, self.deterministic)\n\nclass Sequential(Augmenter, list):\n    def __init__(self, children=None, random_order=False, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n        list.__init__(self, children if children is not None else [])\n        self.random_order = random_order\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        if hooks.is_propagating(images, augmenter=self, parents=parents, default=True):\n            if self.random_order:\n                #for augmenter in self.children:\n                for index in random_state.permutation(len(self)):\n                    images = self[index].augment_images(\n                        images=images,\n                        parents=parents + [self],\n                        hooks=hooks\n                    )\n            else:\n                #for augmenter in self.children:\n                for augmenter in self:\n                    images = augmenter.augment_images(\n                        images=images,\n                        parents=parents + [self],\n                        hooks=hooks\n                    )\n        return images\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        if hooks.is_propagating(keypoints_on_images, augmenter=self, parents=parents, default=True):\n            if self.random_order:\n                for index in random_state.permutation(len(self)):\n                    keypoints_on_images = self[index].augment_keypoints(\n                        keypoints_on_images=keypoints_on_images,\n                        parents=parents + [self],\n                        hooks=hooks\n                    )\n            else:\n                for augmenter in self:\n                    keypoints_on_images = augmenter.augment_keypoints(\n                        keypoints_on_images=keypoints_on_images,\n                        parents=parents + [self],\n                        hooks=hooks\n                    )\n        return keypoints_on_images\n\n    def _to_deterministic(self):\n        augs = [aug.to_deterministic() for aug in self]\n        seq = self.copy()\n        seq[:] = augs\n        seq.random_state = ia.new_random_state()\n        seq.deterministic = True\n        return seq\n\n    def get_parameters(self):\n        return []\n\n    def add(self, augmenter):\n        self.append(augmenter)\n\n    def get_children_lists(self):\n        return [self]\n\n    def __str__(self):\n        #augs_str = "", "".join([aug.__str__() for aug in self.children])\n        augs_str = "", "".join([aug.__str__() for aug in self])\n        return ""Sequential(name=%s, augmenters=[%s], deterministic=%s)"" % (self.name, augs_str, self.deterministic)\n\nclass Sometimes(Augmenter):\n    def __init__(self, p=0.5, then_list=None, else_list=None, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n        if ia.is_single_float(p) or ia.is_single_integer(p):\n            assert 0 <= p <= 1\n            self.p = Binomial(p)\n        elif isinstance(p, StochasticParameter):\n            self.p = p\n        else:\n            raise Exception(""Expected float/int in range [0, 1] or StochasticParameter as p, got %s."" % (type(p),))\n\n        if then_list is None:\n            self.then_list = Sequential([], name=""%s-then"" % (self.name,))\n        elif ia.is_iterable(then_list):\n            self.then_list = Sequential(then_list, name=""%s-then"" % (self.name,))\n        elif isinstance(then_list, Augmenter):\n            self.then_list = Sequential([then_list], name=""%s-then"" % (self.name,))\n        else:\n            raise Exception(""Expected None, Augmenter or list/tuple as then_list, got %s."" % (type(then_list),))\n\n        if else_list is None:\n            self.else_list = Sequential([], name=""%s-else"" % (self.name,))\n        elif ia.is_iterable(else_list):\n            self.else_list = Sequential(else_list, name=""%s-else"" % (self.name,))\n        elif isinstance(else_list, Augmenter):\n            self.else_list = Sequential([else_list], name=""%s-else"" % (self.name,))\n        else:\n            raise Exception(""Expected None, Augmenter or list/tuple as else_list, got %s."" % (type(else_list),))\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        result = images\n        if hooks.is_propagating(images, augmenter=self, parents=parents, default=True):\n            nb_images = len(images)\n            samples = self.p.draw_samples((nb_images,), random_state=random_state)\n\n            # create lists/arrays of images for if and else lists (one for each)\n            indices_then_list = np.where(samples == 1)[0] # np.where returns tuple(array([0, 5, 9, ...])) or tuple(array([]))\n            indices_else_list = np.where(samples == 0)[0]\n            if isinstance(images, list):\n                images_then_list = [images[i] for i in indices_then_list]\n                images_else_list = [images[i] for i in indices_else_list]\n            else:\n                images_then_list = images[indices_then_list]\n                images_else_list = images[indices_else_list]\n\n            # augment according to if and else list\n            result_then_list = self.then_list.augment_images(\n                images=images_then_list,\n                parents=parents + [self],\n                hooks=hooks\n            )\n            result_else_list = self.else_list.augment_images(\n                images=images_else_list,\n                parents=parents + [self],\n                hooks=hooks\n            )\n\n            # map results of if/else lists back to their initial positions (in ""images"" variable)\n            result = [None] * len(images)\n            for idx_result_then_list, idx_images in enumerate(indices_then_list):\n                result[idx_images] = result_then_list[idx_result_then_list]\n            for idx_result_else_list, idx_images in enumerate(indices_else_list):\n                result[idx_images] = result_else_list[idx_result_else_list]\n\n            # if input was a list, keep the output as a list too,\n            # otherwise it was a numpy array, so make the output a numpy array too\n            if not isinstance(images, list):\n                result = np.array(result, dtype=np.uint8)\n\n        return result\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        # TODO this is mostly copy pasted from _augment_images, make dry\n        result = keypoints_on_images\n        if hooks.is_propagating(keypoints_on_images, augmenter=self, parents=parents, default=True):\n            nb_images = len(keypoints_on_images)\n            samples = self.p.draw_samples((nb_images,), random_state=random_state)\n\n            # create lists/arrays of images for if and else lists (one for each)\n            indices_then_list = np.where(samples == 1)[0] # np.where returns tuple(array([0, 5, 9, ...])) or tuple(array([]))\n            indices_else_list = np.where(samples == 0)[0]\n            images_then_list = [keypoints_on_images[i] for i in indices_then_list]\n            images_else_list = [keypoints_on_images[i] for i in indices_else_list]\n\n            # augment according to if and else list\n            result_then_list = self.then_list.augment_keypoints(\n                keypoints_on_images=images_then_list,\n                parents=parents + [self],\n                hooks=hooks\n            )\n            result_else_list = self.else_list.augment_keypoints(\n                keypoints_on_images=images_else_list,\n                parents=parents + [self],\n                hooks=hooks\n            )\n\n            # map results of if/else lists back to their initial positions (in ""images"" variable)\n            result = [None] * len(keypoints_on_images)\n            for idx_result_then_list, idx_images in enumerate(indices_then_list):\n                result[idx_images] = result_then_list[idx_result_then_list]\n            for idx_result_else_list, idx_images in enumerate(indices_else_list):\n                result[idx_images] = result_else_list[idx_result_else_list]\n\n        return result\n\n    def _to_deterministic(self):\n        aug = self.copy()\n        aug.then_list = aug.then_list.to_deterministic()\n        aug.else_list = aug.else_list.to_deterministic()\n        aug.deterministic = True\n        aug.random_state = ia.new_random_state()\n        return aug\n\n    def get_parameters(self):\n        return [self.p]\n\n    def get_children_lists(self):\n        return [self.then_list, self.else_list]\n\n    def __str__(self):\n        return ""Sometimes(p=%s, name=%s, then_list=[%s], else_list=[%s], deterministic=%s)"" % (self.p, self.name, self.then_list, self.else_list, self.deterministic)\n\nclass Noop(Augmenter):\n    def __init__(self, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        return images\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        return keypoints_on_images\n\n    def get_parameters(self):\n        return []\n\nclass Lambda(Augmenter):\n    def __init__(self, func_images, func_keypoints, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n        self.func_images = func_images\n        self.func_keypoints = func_keypoints\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        return self.func_images(images, random_state, parents=parents, hooks=hooks)\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        result = self.func_keypoints(keypoints_on_images, random_state, parents=parents, hooks=hooks)\n        assert isinstance(result, list)\n        assert all([isinstance(el, ia.KeypointsOnImage) for el in result])\n        return result\n\n    def get_parameters(self):\n        return []\n\ndef AssertLambda(func_images, func_keypoints, name=None, deterministic=False, random_state=None):\n    def func_images_assert(images, random_state, parents, hooks):\n        assert func_images(images, random_state, parents=parents, hooks=hooks)\n        return images\n    def func_keypoints_assert(keypoints_on_images, random_state, parents, hooks):\n        assert func_keypoints(keypoints_on_images, random_state, parents=parents, hooks=hooks)\n        return keypoints_on_images\n    if name is None:\n        name = ""UnnamedAssertLambda""\n    return Lambda(func_images_assert, func_keypoints_assert, name=name, deterministic=deterministic, random_state=random_state)\n\ndef AssertShape(shape, check_images=True, check_keypoints=True, name=None, deterministic=False, random_state=None):\n    assert len(shape) == 4, ""Expected shape to have length 4, got %d with shape: %s."" % (len(shape), str(shape))\n\n    def compare(observed, expected, dimension, image_index):\n        if expected is not None:\n            if ia.is_single_integer(expected):\n                assert observed == expected, ""Expected dim %d (entry index: %s) to have value %d, got %d."" % (dimension, image_index, expected, observed)\n            elif isinstance(expected, tuple):\n                assert len(expected) == 2\n                assert expected[0] <= observed < expected[1], ""Expected dim %d (entry index: %s) to have value in range [%d, %d), got %d."" % (dimension, image_index, expected[0], expected[1], observed)\n            elif isinstance(expected, list):\n                assert any([observed == val for val in expected]), ""Expected dim %d (entry index: %s) to have any value of %s, got %d."" % (dimension, image_index, str(expected), observed)\n            else:\n                raise Exception(""Invalid datatype for shape entry %d, expected each entry to be an integer, a tuple (with two entries) or a list, got %s."" % (dimension, type(expected),))\n\n    def func_images(images, random_state, parents, hooks):\n        if check_images:\n            #assert is_np_array(images), ""AssertShape can currently only handle numpy arrays, got ""\n            if isinstance(images, list):\n                if shape[0] is not None:\n                    compare(len(images), shape[0], 0, ""ALL"")\n\n                for i in xrange(len(images)):\n                    image = images[i]\n                    assert len(image.shape) == 3, ""Expected image number %d to have a shape of length 3, got %d (shape: %s)."" % (i, len(image.shape), str(image.shape))\n                    for j in xrange(len(shape)-1):\n                        expected = shape[j+1]\n                        observed = image.shape[j]\n                        compare(observed, expected, j, i)\n            else:\n                assert len(images.shape) == 4, ""Expected image\'s shape to have length 4, got %d (shape: %s)."" % (len(images.shape), str(images.shape))\n                for i in range(4):\n                    expected = shape[i]\n                    observed = images.shape[i]\n                    compare(observed, expected, i, ""ALL"")\n        return images\n\n    def func_keypoints(keypoints_on_images, random_state, parents, hooks):\n        if check_keypoints:\n            #assert is_np_array(images), ""AssertShape can currently only handle numpy arrays, got ""\n            if shape[0] is not None:\n                compare(len(keypoints_on_images), shape[0], 0, ""ALL"")\n\n            for i in xrange(len(keypoints_on_images)):\n                keypoints_on_image = keypoints_on_images[i]\n                for j in xrange(len(shape[0:2])):\n                    expected = shape[j+1]\n                    observed = keypoints_on_image.shape[j]\n                    compare(observed, expected, j, i)\n        return keypoints_on_images\n\n    if name is None:\n        name = ""UnnamedAssertShape""\n\n    return Lambda(func_images, func_keypoints, name=name, deterministic=deterministic, random_state=random_state)\n\nclass Crop(Augmenter):\n    def __init__(self, px=None, percent=None, keep_size=True, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n\n        self.keep_size = keep_size\n\n        if px is None and percent is None:\n            self.mode = ""noop""\n        elif px is not None and percent is not None:\n            raise Exception(""Can only crop by pixels or percent, not both."")\n        elif px is not None:\n            self.mode = ""px""\n            if ia.is_single_integer(px):\n                assert px >= 0\n                self.top = self.right = self.bottom = self.left = Deterministic(px)\n            elif isinstance(px, tuple):\n                assert len(px) in [2, 4]\n                def handle_param(p):\n                    if ia.is_single_integer(p):\n                        assert p >= 0\n                        return Deterministic(p)\n                    elif isinstance(p, tuple):\n                        assert len(p) == 2\n                        assert ia.is_single_integer(p[0])\n                        assert ia.is_single_integer(p[1])\n                        assert p[0] >= 0\n                        assert p[1] >= 0\n                        return DiscreteUniform(p[0], p[1])\n                    elif isinstance(p, list):\n                        assert len(p) > 0\n                        assert all([ia.is_single_integer(val) for val in p])\n                        assert all([val >= 0 for val in p])\n                        return Choice(p)\n                    elif isinstance(p, StochasticParameter):\n                        return p\n                    else:\n                        raise Exception(""Expected int, tuple of two ints, list of ints or StochasticParameter, got type %s."" % (type(p),))\n\n                if len(px) == 2:\n                    self.top = self.right = self.bottom = self.left = handle_param(px)\n                else: # len == 4\n                    self.top = handle_param(px[0])\n                    self.right = handle_param(px[1])\n                    self.bottom = handle_param(px[2])\n                    self.left = handle_param(px[3])\n            elif isinstance(px, StochasticParameter):\n                self.top = self.right = self.bottom = self.left = px\n            else:\n                raise Exception(""Expected int, tuple of 4 ints/lists/StochasticParameters or StochasticParameter, git type %s."" % (type(px),))\n        else: # = elif percent is not None:\n            self.mode = ""percent""\n            if ia.is_single_number(percent):\n                assert 0 <= percent < 1.0\n                self.top = self.right = self.bottom = self.left = Deterministic(percent)\n            elif isinstance(percent, tuple):\n                assert len(percent) in [2, 4]\n                def handle_param(p):\n                    if ia.is_single_number(p):\n                        return Deterministic(p)\n                    elif isinstance(p, tuple):\n                        assert len(p) == 2\n                        assert ia.is_single_number(p[0])\n                        assert ia.is_single_number(p[1])\n                        assert 0 <= p[0] < 1.0\n                        assert 0 <= p[1] < 1.0\n                        return Uniform(p[0], p[1])\n                    elif isinstance(p, list):\n                        assert len(p) > 0\n                        assert all([ia.is_single_number(val) for val in p])\n                        assert all([0 <= val < 1.0 for val in p])\n                        return Choice(p)\n                    elif isinstance(p, StochasticParameter):\n                        return p\n                    else:\n                        raise Exception(""Expected int, tuple of two ints, list of ints or StochasticParameter, got type %s."" % (type(p),))\n\n                if len(percent) == 2:\n                    self.top = self.right = self.bottom = self.left = handle_param(percent)\n                else: # len == 4\n                    self.top = handle_param(percent[0])\n                    self.right = handle_param(percent[1])\n                    self.bottom = handle_param(percent[2])\n                    self.left = handle_param(percent[3])\n            elif isinstance(percent, StochasticParameter):\n                self.top = self.right = self.bottom = self.left = percent\n            else:\n                raise Exception(""Expected number, tuple of 4 numbers/lists/StochasticParameters or StochasticParameter, got type %s."" % (type(percent),))\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        result = []\n        nb_images = len(images)\n        seeds = random_state.randint(0, 10**6, (nb_images,))\n        for i in xrange(nb_images):\n            seed = seeds[i]\n            height, width = images[i].shape[0:2]\n            top, right, bottom, left = self._draw_samples_image(seed, height, width)\n            image_cropped = images[i][top:height-bottom, left:width-right, :]\n            if self.keep_size:\n                image_cropped = ia.imresize_single_image(image_cropped, (height, width))\n            result.append(image_cropped)\n\n        if not isinstance(images, list):\n            if self.keep_size:\n                result = np.array(result, dtype=np.uint8)\n\n        return result\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        result = []\n        nb_images = len(keypoints_on_images)\n        seeds = random_state.randint(0, 10**6, (nb_images,))\n        for i, keypoints_on_image in enumerate(keypoints_on_images):\n            seed = seeds[i]\n            height, width = keypoints_on_image.shape[0:2]\n            top, right, bottom, left = self._draw_samples_image(seed, height, width)\n            shifted = keypoints_on_image.shift(x=-left, y=-top)\n            shifted.shape = (height - top - bottom, width - left - right)\n            if self.keep_size:\n                result.append(shifted.on(keypoints_on_image.shape))\n            else:\n                result.append(shifted)\n\n        return result\n\n    def _draw_samples_image(self, seed, height, width):\n        random_state = ia.new_random_state(seed)\n\n        top = self.top.draw_samples((1,), random_state=ia.copy_random_state(random_state))[0]\n        right = self.right.draw_samples((1,), random_state=ia.copy_random_state(random_state))[0]\n        bottom = self.bottom.draw_samples((1,), random_state=ia.copy_random_state(random_state))[0]\n        left = self.left.draw_samples((1,), random_state=ia.copy_random_state(random_state))[0]\n\n        if self.mode == ""px"":\n            # no change necessary for pixel values\n            pass\n        elif self.mode == ""percent"":\n            # percentage values have to be transformed to pixel values\n            top = int(height * top)\n            right = int(width * right)\n            bottom = int(height * bottom)\n            left = int(width * left)\n        else:\n            raise Exception(""Invalid mode"")\n\n        remaining_height = height - (top + bottom)\n        remaining_width = width - (left + right)\n        if remaining_height < 1:\n            regain = abs(remaining_height) + 1\n            regain_top = regain // 2\n            regain_bottom = regain // 2\n            if regain_top + regain_bottom < regain:\n                regain_top += 1\n\n            if regain_top > top:\n                diff = regain_top - top\n                regain_top = top\n                regain_bottom += diff\n            elif regain_bottom > bottom:\n                diff = regain_bottom - bottom\n                regain_bottom = bottom\n                regain_top += diff\n\n            assert regain_top <= top\n            assert regain_bottom <= bottom\n\n            top = top - regain_top\n            bottom = bottom - regain_bottom\n\n        if remaining_width < 1:\n            regain = abs(remaining_width) + 1\n            regain_right = regain // 2\n            regain_left = regain // 2\n            if regain_right + regain_left < regain:\n                regain_right += 1\n\n            if regain_right > right:\n                diff = regain_right - right\n                regain_right = right\n                regain_left += diff\n            elif regain_left > left:\n                diff = regain_left - left\n                regain_left = left\n                regain_right += diff\n\n            assert regain_right <= right\n            assert regain_left <= left\n\n            right = right - regain_right\n            left = left - regain_left\n\n        assert top >= 0 and right >= 0 and bottom >= 0 and left >= 0\n        assert top + bottom < height\n        assert right + left < width\n\n        return top, right, bottom, left\n\n    def get_parameters(self):\n        return [self.top, self.right, self.bottom, self.left]\n\nclass Fliplr(Augmenter):\n    def __init__(self, p=0, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n\n        if ia.is_single_number(p):\n            self.p = Binomial(p)\n        elif isinstance(p, StochasticParameter):\n            self.p = p\n        else:\n            raise Exception(""Expected p to be int or float or StochasticParameter, got %s."" % (type(p),))\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        nb_images = len(images)\n        samples = self.p.draw_samples((nb_images,), random_state=random_state)\n        for i in xrange(nb_images):\n            if samples[i] == 1:\n                images[i] = np.fliplr(images[i])\n        return images\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        nb_images = len(keypoints_on_images)\n        samples = self.p.draw_samples((nb_images,), random_state=random_state)\n        for i, keypoints_on_image in enumerate(keypoints_on_images):\n            if samples[i] == 1:\n                width = keypoints_on_image.shape[1]\n                for keypoint in keypoints_on_image.keypoints:\n                    keypoint.x = (width - 1) - keypoint.x\n        return keypoints_on_images\n\n    def get_parameters(self):\n        return [self.p]\n\nclass Flipud(Augmenter):\n    def __init__(self, p=0, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n\n        if ia.is_single_number(p):\n            self.p = Binomial(p)\n        elif isinstance(p, StochasticParameter):\n            self.p = p\n        else:\n            raise Exception(""Expected p to be int or float or StochasticParameter, got %s."" % (type(p),))\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        nb_images = len(images)\n        samples = self.p.draw_samples((nb_images,), random_state=random_state)\n        for i in xrange(nb_images):\n            if samples[i] == 1:\n                images[i] = np.flipud(images[i])\n        return images\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        nb_images = len(keypoints_on_images)\n        samples = self.p.draw_samples((nb_images,), random_state=random_state)\n        for i, keypoints_on_image in enumerate(keypoints_on_images):\n            if samples[i] == 1:\n                height = keypoints_on_image.shape[0]\n                for keypoint in keypoints_on_image.keypoints:\n                    keypoint.y = (height - 1) - keypoint.y\n        return keypoints_on_images\n\n    def get_parameters(self):\n        return [self.p]\n\nclass GaussianBlur(Augmenter):\n    def __init__(self, sigma=0, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n        if ia.is_single_number(sigma):\n            self.sigma = Deterministic(sigma)\n        elif ia.is_iterable(sigma):\n            assert len(sigma) == 2, ""Expected tuple/list with 2 entries, got %d entries."" % (str(len(sigma)),)\n            self.sigma = Uniform(sigma[0], sigma[1])\n        elif isinstance(sigma, StochasticParameter):\n            self.sigma = sigma\n        else:\n            raise Exception(""Expected float, int, tuple/list with 2 entries or StochasticParameter. Got %s."" % (type(sigma),))\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        result = images\n        nb_images = len(images)\n        samples = self.sigma.draw_samples((nb_images,), random_state=random_state)\n        for i in xrange(nb_images):\n            nb_channels = images[i].shape[2]\n            sig = samples[i]\n            if sig > 0:\n                for channel in xrange(nb_channels):\n                    result[i][:, :, channel] = ndimage.gaussian_filter(result[i][:, :, channel], sig)\n        return result\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        return keypoints_on_images\n\n    def get_parameters(self):\n        return [self.sigma]\n\ndef AdditiveGaussianNoise(loc=0, scale=0, per_channel=False, name=None, deterministic=False, random_state=None):\n    if ia.is_single_number(loc):\n        loc2 = Deterministic(loc)\n    elif ia.is_iterable(loc):\n        assert len(loc) == 2, ""Expected tuple/list with 2 entries for argument \'loc\', got %d entries."" % (str(len(scale)),)\n        loc2 = Uniform(loc[0], loc[1])\n    elif isinstance(loc, StochasticParameter):\n        loc2 = loc\n    else:\n        raise Exception(""Expected float, int, tuple/list with 2 entries or StochasticParameter for argument \'loc\'. Got %s."" % (type(loc),))\n\n    if ia.is_single_number(scale):\n        scale2 = Deterministic(scale)\n    elif ia.is_iterable(scale):\n        assert len(scale) == 2, ""Expected tuple/list with 2 entries for argument \'scale\', got %d entries."" % (str(len(scale)),)\n        scale2 = Uniform(scale[0], scale[1])\n    elif isinstance(scale, StochasticParameter):\n        scale2 = scale\n    else:\n        raise Exception(""Expected float, int, tuple/list with 2 entries or StochasticParameter for argument \'scale\'. Got %s."" % (type(scale),))\n\n    return AddElementwise(Normal(loc=loc2, scale=scale2), per_channel=per_channel, name=name, deterministic=deterministic, random_state=random_state)\n\n# TODO\n#class MultiplicativeGaussianNoise(Augmenter):\n#    pass\n\n# TODO\n#class ReplacingGaussianNoise(Augmenter):\n#    pass\n\ndef Dropout(p=0, per_channel=False, name=None, deterministic=False, random_state=None):\n    if ia.is_single_number(p):\n        p2 = Binomial(1 - p)\n    elif ia.is_iterable(p):\n        assert len(p) == 2\n        assert p[0] < p[1]\n        assert 0 <= p[0] <= 1.0\n        assert 0 <= p[1] <= 1.0\n        p2 = Binomial(Uniform(1- p[1], 1 - p[0]))\n    elif isinstance(p, StochasticParameter):\n        p2 = p\n    else:\n        raise Exception(""Expected p to be float or int or StochasticParameter, got %s."" % (type(p),))\n    return MultiplyElementwise(p2, per_channel=per_channel, name=name, deterministic=deterministic, random_state=random_state)\n\n# TODO tests\nclass Add(Augmenter):\n    def __init__(self, value=0, per_channel=False, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n\n        if ia.is_single_integer(value):\n            assert -255 <= value <= 255, ""Expected value to have range [-255, 255], got value %d."" % (value,)\n            self.value = Deterministic(value)\n        elif ia.is_iterable(value):\n            assert len(value) == 2, ""Expected tuple/list with 2 entries, got %d entries."" % (len(value),)\n            self.value = DiscreteUniform(value[0], value[1])\n        elif isinstance(value, StochasticParameter):\n            self.value = value\n        else:\n            raise Exception(""Expected float or int, tuple/list with 2 entries or StochasticParameter. Got %s."" % (type(value),))\n\n        if per_channel in [True, False, 0, 1, 0.0, 1.0]:\n            self.per_channel = Deterministic(int(per_channel))\n        elif ia.is_single_number(per_channel):\n            assert 0 <= per_channel <= 1.0\n            self.per_channel = Binomial(per_channel)\n        else:\n            raise Exception(""Expected per_channel to be boolean or number or StochasticParameter"")\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        result = images\n        nb_images = len(images)\n        seeds = random_state.randint(0, 10**6, (nb_images,))\n        for i in xrange(nb_images):\n            image = images[i].astype(np.int32)\n            rs_image = ia.new_random_state(seeds[i])\n            per_channel = self.per_channel.draw_sample(random_state=rs_image)\n            if per_channel == 1:\n                nb_channels = image.shape[2]\n                samples = self.value.draw_samples((nb_channels,), random_state=rs_image)\n                for c, sample in enumerate(samples):\n                    assert -255 <= sample <= 255\n                    image[..., c] += sample\n                np.clip(image, 0, 255, out=image)\n                result[i] = image.astype(np.uint8)\n            else:\n                sample = self.value.draw_sample(random_state=rs_image)\n                assert -255 <= sample <= 255\n                image += sample\n                np.clip(image, 0, 255, out=image)\n                result[i] = image.astype(np.uint8)\n        return result\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        return keypoints_on_images\n\n    def get_parameters(self):\n        return [self.value]\n\n# TODO tests\nclass AddElementwise(Augmenter):\n    def __init__(self, value=0, per_channel=False, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n\n        if ia.is_single_integer(value):\n            assert -255 <= value <= 255, ""Expected value to have range [-255, 255], got value %d."" % (value,)\n            self.value = Deterministic(value)\n        elif ia.is_iterable(value):\n            assert len(value) == 2, ""Expected tuple/list with 2 entries, got %d entries."" % (len(value),)\n            self.value = DiscreteUniform(value[0], value[1])\n        elif isinstance(value, StochasticParameter):\n            self.value = value\n        else:\n            raise Exception(""Expected float or int, tuple/list with 2 entries or StochasticParameter. Got %s."" % (type(value),))\n\n        if per_channel in [True, False, 0, 1, 0.0, 1.0]:\n            self.per_channel = Deterministic(int(per_channel))\n        elif ia.is_single_number(per_channel):\n            assert 0 <= per_channel <= 1.0\n            self.per_channel = Binomial(per_channel)\n        else:\n            raise Exception(""Expected per_channel to be boolean or number or StochasticParameter"")\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        result = images\n        nb_images = len(images)\n        seeds = random_state.randint(0, 10**6, (nb_images,))\n        for i in xrange(nb_images):\n            seed = seeds[i]\n            image = images[i].astype(np.int32)\n            height, width, nb_channels = image.shape\n            rs_image = ia.new_random_state(seed)\n            per_channel = self.per_channel.draw_sample(random_state=rs_image)\n            if per_channel == 1:\n                samples = self.value.draw_samples((height, width, nb_channels), random_state=rs_image)\n            else:\n                samples = self.value.draw_samples((height, width, 1), random_state=rs_image)\n                samples = np.tile(samples, (1, 1, nb_channels))\n            after_add = image + samples\n            np.clip(after_add, 0, 255, out=after_add)\n            result[i] = after_add.astype(np.uint8)\n        return result\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        return keypoints_on_images\n\n    def get_parameters(self):\n        return [self.value]\n\nclass Multiply(Augmenter):\n    def __init__(self, mul=1.0, per_channel=False, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n\n        if ia.is_single_number(mul):\n            assert mul >= 0.0, ""Expected multiplier to have range [0, inf), got value %.4f."" % (mul,)\n            self.mul = Deterministic(mul)\n        elif ia.is_iterable(mul):\n            assert len(mul) == 2, ""Expected tuple/list with 2 entries, got %d entries."" % (len(mul),)\n            self.mul = Uniform(mul[0], mul[1])\n        elif isinstance(mul, StochasticParameter):\n            self.mul = mul\n        else:\n            raise Exception(""Expected float or int, tuple/list with 2 entries or StochasticParameter. Got %s."" % (type(mul),))\n\n        if per_channel in [True, False, 0, 1, 0.0, 1.0]:\n            self.per_channel = Deterministic(int(per_channel))\n        elif ia.is_single_number(per_channel):\n            assert 0 <= per_channel <= 1.0\n            self.per_channel = Binomial(per_channel)\n        else:\n            raise Exception(""Expected per_channel to be boolean or number or StochasticParameter"")\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        result = images\n        nb_images = len(images)\n        seeds = random_state.randint(0, 10**6, (nb_images,))\n        for i in xrange(nb_images):\n            image = images[i].astype(np.float32)\n            rs_image = ia.new_random_state(seeds[i])\n            per_channel = self.per_channel.draw_sample(random_state=rs_image)\n            if per_channel == 1:\n                nb_channels = image.shape[2]\n                samples = self.mul.draw_samples((nb_channels,), random_state=rs_image)\n                for c, sample in enumerate(samples):\n                    assert sample >= 0\n                    image[..., c] *= sample\n                np.clip(image, 0, 255, out=image)\n                result[i] = image.astype(np.uint8)\n            else:\n                sample = self.mul.draw_sample(random_state=rs_image)\n                assert sample >= 0\n                image *= sample\n                np.clip(image, 0, 255, out=image)\n                result[i] = image.astype(np.uint8)\n        return result\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        return keypoints_on_images\n\n    def get_parameters(self):\n        return [self.mul]\n\n# TODO tests\nclass MultiplyElementwise(Augmenter):\n    def __init__(self, mul=1.0, per_channel=False, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n\n        if ia.is_single_number(mul):\n            assert mul >= 0.0, ""Expected multiplier to have range [0, inf), got value %.4f."" % (mul,)\n            self.mul = Deterministic(mul)\n        elif ia.is_iterable(mul):\n            assert len(mul) == 2, ""Expected tuple/list with 2 entries, got %d entries."" % (str(len(mul)),)\n            self.mul = Uniform(mul[0], mul[1])\n        elif isinstance(mul, StochasticParameter):\n            self.mul = mul\n        else:\n            raise Exception(""Expected float or int, tuple/list with 2 entries or StochasticParameter. Got %s."" % (type(mul),))\n\n        if per_channel in [True, False, 0, 1, 0.0, 1.0]:\n            self.per_channel = Deterministic(int(per_channel))\n        elif ia.is_single_number(per_channel):\n            assert 0 <= per_channel <= 1.0\n            self.per_channel = Binomial(per_channel)\n        else:\n            raise Exception(""Expected per_channel to be boolean or number or StochasticParameter"")\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        result = images\n        nb_images = len(images)\n        seeds = random_state.randint(0, 10**6, (nb_images,))\n        for i in xrange(nb_images):\n            seed = seeds[i]\n            image = images[i].astype(np.float32)\n            height, width, nb_channels = image.shape\n            rs_image = ia.new_random_state(seed)\n            per_channel = self.per_channel.draw_sample(random_state=rs_image)\n            if per_channel == 1:\n                samples = self.mul.draw_samples((height, width, nb_channels), random_state=rs_image)\n            else:\n                samples = self.mul.draw_samples((height, width, 1), random_state=rs_image)\n                samples = np.tile(samples, (1, 1, nb_channels))\n            after_multiply = image * samples\n            np.clip(after_multiply, 0, 255, out=after_multiply)\n            result[i] = after_multiply.astype(np.uint8)\n        return result\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        return keypoints_on_images\n\n    def get_parameters(self):\n        return [self.mul]\n\n# TODO tests\nclass ContrastNormalization(Augmenter):\n    def __init__(self, alpha=1.0, per_channel=False, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n        if ia.is_single_number(alpha):\n            assert alpha >= 0.0, ""Expected alpha to have range (0, inf), got value %.4f."" % (alpha,)\n            self.alpha = Deterministic(alpha)\n        elif ia.is_iterable(alpha):\n            assert len(alpha) == 2, ""Expected tuple/list with 2 entries, got %d entries."" % (str(len(alpha)),)\n            self.alpha = Uniform(alpha[0], alpha[1])\n        elif isinstance(alpha, StochasticParameter):\n            self.alpha = alpha\n        else:\n            raise Exception(""Expected float or int, tuple/list with 2 entries or StochasticParameter. Got %s."" % (type(alpha),))\n\n        if per_channel in [True, False, 0, 1, 0.0, 1.0]:\n            self.per_channel = Deterministic(int(per_channel))\n        elif ia.is_single_number(per_channel):\n            assert 0 <= per_channel <= 1.0\n            self.per_channel = Binomial(per_channel)\n        else:\n            raise Exception(""Expected per_channel to be boolean or number or StochasticParameter"")\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        result = images\n        nb_images = len(images)\n        seeds = random_state.randint(0, 10**6, (nb_images,))\n        for i in xrange(nb_images):\n            image = images[i].astype(np.float32)\n            rs_image = ia.new_random_state(seeds[i])\n            per_channel = self.per_channel.draw_sample(random_state=rs_image)\n            if per_channel:\n                nb_channels = images[i].shape[2]\n                alphas = self.alpha.draw_samples((nb_channels,), random_state=rs_image)\n                for c, alpha in enumerate(alphas):\n                    image[..., c] = alpha * (image[..., c] - 128) + 128\n            else:\n                alpha = self.alpha.draw_sample(random_state=rs_image)\n                image = alpha * (image - 128) + 128\n            np.clip(image, 0, 255, out=image)\n            result[i] = image.astype(np.uint8)\n        return result\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        return keypoints_on_images\n\n    def get_parameters(self):\n        return [self.alpha]\n\nclass Affine(Augmenter):\n    def __init__(self, scale=1.0, translate_percent=None, translate_px=None, rotate=0.0, shear=0.0, order=1, cval=0.0, mode=""constant"", name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n\n        if order == ia.ALL:\n            #self.order = DiscreteUniform(0, 5)\n            self.order = Choice([0, 1, 3, 4, 5]) # dont use order=2 (bi-quadratic) because that is apparently currently not recommended (and throws a warning)\n        elif ia.is_single_integer(order):\n            assert 0 <= order <= 5, ""Expected order\'s integer value to be in range 0 <= x <= 5, got %d."" % (order,)\n            self.order = Deterministic(order)\n        elif isinstance(order, list):\n            assert all([ia.is_single_integer(val) for val in order]), ""Expected order list to only contain integers, got types %s."" % (str([type(val) for val in order]),)\n            assert all([0 <= val <= 5 for val in order]), ""Expected all of order\'s integer values to be in range 0 <= x <= 5, got %s."" % (str(order),)\n            self.order = Choice(order)\n        elif isinstance(order, StochasticParameter):\n            self.order = order\n        else:\n            raise Exception(""Expected order to be imgaug.ALL, int or StochasticParameter, got %s."" % (type(order),))\n\n        if cval == ia.ALL:\n            self.cval = Uniform(0, 1.0)\n        elif ia.is_single_number(cval):\n            assert 0 <= cval <= 1.0\n            self.cval = Deterministic(cval)\n        elif ia.is_iterable(cval):\n            assert len(cval) == 2\n            assert 0 <= cval[0] <= 1.0\n            assert 0 <= cval[1] <= 1.0\n            self.cval = Uniform(cval[0], cval[1])\n        elif isinstance(cval, StochasticParameter):\n            self.cval = cval\n        else:\n            raise Exception(""Expected cval to be imgaug.ALL, int, float or StochasticParameter, got %s."" % (type(cval),))\n\n        # constant, edge, symmetric, reflect, wrap\n        if mode == ia.ALL:\n            self.mode = Choice([""constant"", ""edge"", ""symmetric"", ""reflect"", ""wrap""])\n        elif ia.is_string(mode):\n            self.mode = Deterministic(mode)\n        elif isinstance(mode, list):\n            assert all([ia.is_string(val) for val in mode])\n            self.mode = Choice(mode)\n        elif isinstance(mode, StochasticParameter):\n            self.mode = mode\n        else:\n            raise Exception(""Expected mode to be imgaug.ALL, a string, a list of strings or StochasticParameter, got %s."" % (type(mode),))\n\n        # scale\n        # float | (float, float) | [float, float] | StochasticParameter\n        def scale_handle_param(param, allow_dict):\n            if isinstance(param, StochasticParameter):\n                return param\n            elif ia.is_single_number(param):\n                assert param > 0.0, ""Expected scale to have range (0, inf), got value %.4f. Note: The value to _not_ change the scale of images is 1.0, not 0.0."" % (param,)\n                return Deterministic(param)\n            elif ia.is_iterable(param) and not isinstance(param, dict):\n                assert len(param) == 2, ""Expected scale tuple/list with 2 entries, got %d entries."" % (str(len(param)),)\n                assert param[0] > 0.0 and param[1] > 0.0, ""Expected scale tuple/list to have values in range (0, inf), got values %.4f and %.4f. Note: The value to _not_ change the scale of images is 1.0, not 0.0."" % (param[0], param[1])\n                return Uniform(param[0], param[1])\n            elif allow_dict and isinstance(param, dict):\n                assert ""x"" in param or ""y"" in param\n                x = param.get(""x"")\n                y = param.get(""y"")\n\n                x = x if x is not None else 1.0\n                y = y if y is not None else 1.0\n\n                return (scale_handle_param(x, False), scale_handle_param(y, False))\n            else:\n                raise Exception(""Expected float, int, tuple/list with 2 entries or StochasticParameter. Got %s."" % (type(param),))\n        self.scale = scale_handle_param(scale, True)\n\n        # translate\n        if translate_percent is None and translate_px is None:\n            translate_px = 0\n\n        assert translate_percent is None or translate_px is None\n\n        if translate_percent is not None:\n            # translate by percent\n            def translate_handle_param(param, allow_dict):\n                if ia.is_single_number(param):\n                    return Deterministic(float(param))\n                elif ia.is_iterable(param) and not isinstance(param, dict):\n                    assert len(param) == 2, ""Expected translate_percent tuple/list with 2 entries, got %d entries."" % (str(len(param)),)\n                    all_numbers = all([ia.is_single_number(p) for p in param])\n                    assert all_numbers, ""Expected translate_percent tuple/list to contain only numbers, got types %s."" % (str([type(p) for p in param]),)\n                    #assert param[0] > 0.0 and param[1] > 0.0, ""Expected translate_percent tuple/list to have values in range (0, inf), got values %.4f and %.4f."" % (param[0], param[1])\n                    return Uniform(param[0], param[1])\n                elif allow_dict and isinstance(param, dict):\n                    assert ""x"" in param or ""y"" in param\n                    x = param.get(""x"")\n                    y = param.get(""y"")\n\n                    x = x if x is not None else 0\n                    y = y if y is not None else 0\n\n                    return (translate_handle_param(x, False), translate_handle_param(y, False))\n                elif isinstance(param, StochasticParameter):\n                    return param\n                else:\n                    raise Exception(""Expected float, int or tuple/list with 2 entries of both floats or ints or StochasticParameter. Got %s."" % (type(param),))\n            self.translate = translate_handle_param(translate_percent, True)\n        else:\n            # translate by pixels\n            def translate_handle_param(param, allow_dict):\n                if ia.is_single_integer(param):\n                    return Deterministic(param)\n                elif ia.is_iterable(param) and not isinstance(param, dict):\n                    assert len(param) == 2, ""Expected translate_px tuple/list with 2 entries, got %d entries."" % (str(len(param)),)\n                    all_integer = all([ia.is_single_integer(p) for p in param])\n                    assert all_integer, ""Expected translate_px tuple/list to contain only integers, got types %s."" % (str([type(p) for p in param]),)\n                    return DiscreteUniform(param[0], param[1])\n                elif allow_dict and isinstance(param, dict):\n                    assert ""x"" in param or ""y"" in param\n                    x = param.get(""x"")\n                    y = param.get(""y"")\n\n                    x = x if x is not None else 0\n                    y = y if y is not None else 0\n\n                    return (translate_handle_param(x, False), translate_handle_param(y, False))\n                elif isinstance(param, StochasticParameter):\n                    return param\n                else:\n                    raise Exception(""Expected int or tuple/list with 2 ints or StochasticParameter. Got %s."" % (type(param),))\n            self.translate = translate_handle_param(translate_px, True)\n\n        # rotate\n        # StochasticParameter | float | int | (float or int, float or int) | [float or int, float or int]\n        if isinstance(rotate, StochasticParameter):\n            self.rotate = rotate\n        elif ia.is_single_number(rotate):\n            self.rotate = Deterministic(rotate)\n        elif ia.is_iterable(rotate):\n            assert len(rotate) == 2, ""Expected rotate tuple/list with 2 entries, got %d entries."" % (str(len(rotate)),)\n            assert all([ia.is_single_number(val) for val in rotate]), ""Expected floats/ints in rotate tuple/list""\n            self.rotate = Uniform(rotate[0], rotate[1])\n        else:\n            raise Exception(""Expected float, int, tuple/list with 2 entries or StochasticParameter. Got %s."" % (type(rotate),))\n\n        # shear\n        # StochasticParameter | float | int | (float or int, float or int) | [float or int, float or int]\n        if isinstance(shear, StochasticParameter):\n            self.shear = shear\n        elif ia.is_single_number(shear):\n            self.shear = Deterministic(shear)\n        elif ia.is_iterable(shear):\n            assert len(shear) == 2, ""Expected rotate tuple/list with 2 entries, got %d entries."" % (str(len(shear)),)\n            assert all([ia.is_single_number(val) for val in shear]), ""Expected floats/ints in shear tuple/list.""\n            self.shear = Uniform(shear[0], shear[1])\n        else:\n            raise Exception(""Expected float, int, tuple/list with 2 entries or StochasticParameter. Got %s."" % (type(shear),))\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        # skimage\'s warp() converts to 0-1 range, so we use float here and then convert\n        # at the end\n        # float images are expected by skimage\'s warp() to be in range 0-1, so we divide by 255\n        if isinstance(images, list):\n            result = [image.astype(np.float32, copy=False) for image in images]\n            result = [image / 255.0 for image in images]\n        else:\n            result = images.astype(np.float32, copy=False)\n            result = result / 255.0\n\n        nb_images = len(images)\n\n        scale_samples, translate_samples, rotate_samples, shear_samples, cval_samples, mode_samples, order_samples = self._draw_samples(nb_images, random_state)\n\n        for i in xrange(nb_images):\n            height, width = result[i].shape[0], result[i].shape[1]\n            shift_x = int(width / 2.0)\n            shift_y = int(height / 2.0)\n            scale_x, scale_y = scale_samples[0][i], scale_samples[1][i]\n            translate_x, translate_y = translate_samples[0][i], translate_samples[1][i]\n            #assert isinstance(translate_x, (float, int))\n            #assert isinstance(translate_y, (float, int))\n            if ia.is_single_float(translate_y):\n                translate_y_px = int(round(translate_y * images[i].shape[0]))\n            else:\n                translate_y_px = translate_y\n            if ia.is_single_float(translate_x):\n                translate_x_px = int(round(translate_x * images[i].shape[1]))\n            else:\n                translate_x_px = translate_x\n            rotate = rotate_samples[i]\n            shear = shear_samples[i]\n            cval = cval_samples[i]\n            mode = mode_samples[i]\n            order = order_samples[i]\n            if scale_x != 1.0 or scale_y != 1.0 or translate_x_px != 0 or translate_y_px != 0 or rotate != 0 or shear != 0:\n                matrix_to_topleft = tf.SimilarityTransform(translation=[-shift_x, -shift_y])\n                matrix_transforms = tf.AffineTransform(\n                    scale=(scale_x, scale_y),\n                    translation=(translate_x_px, translate_y_px),\n                    rotation=math.radians(rotate),\n                    shear=math.radians(shear)\n                )\n                matrix_to_center = tf.SimilarityTransform(translation=[shift_x, shift_y])\n                matrix = (matrix_to_topleft + matrix_transforms + matrix_to_center)\n                result[i] = tf.warp(\n                    result[i],\n                    matrix.inverse,\n                    order=order,\n                    mode=mode,\n                    cval=cval\n                )\n\n            result[i] *= 255.0\n            np.clip(result[i], 0, 255, out=result[i])\n\n        if isinstance(images, list):\n            result = [image.astype(np.uint8, copy=False) for image in result]\n        else:\n            result = result.astype(np.uint8, copy=False)\n\n        return result\n\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        result = []\n        nb_images = len(keypoints_on_images)\n        scale_samples, translate_samples, rotate_samples, shear_samples, cval_samples, mode_samples, order_samples = self._draw_samples(nb_images, random_state)\n\n        for i, keypoints_on_image in enumerate(keypoints_on_images):\n            height, width = keypoints_on_image.height, keypoints_on_image.width\n            shift_x = int(width / 2.0)\n            shift_y = int(height / 2.0)\n            scale_x, scale_y = scale_samples[0][i], scale_samples[1][i]\n            translate_x, translate_y = translate_samples[0][i], translate_samples[1][i]\n            #assert isinstance(translate_x, (float, int))\n            #assert isinstance(translate_y, (float, int))\n            if ia.is_single_float(translate_y):\n                translate_y_px = int(round(translate_y * keypoints_on_image.shape[0]))\n            else:\n                translate_y_px = translate_y\n            if ia.is_single_float(translate_x):\n                translate_x_px = int(round(translate_x * keypoints_on_image.shape[1]))\n            else:\n                translate_x_px = translate_x\n            rotate = rotate_samples[i]\n            shear = shear_samples[i]\n            #cval = cval_samples[i]\n            #mode = mode_samples[i]\n            #order = order_samples[i]\n            if scale_x != 1.0 or scale_y != 1.0 or translate_x_px != 0 or translate_y_px != 0 or rotate != 0 or shear != 0:\n                matrix_to_topleft = tf.SimilarityTransform(translation=[-shift_x, -shift_y])\n                matrix_transforms = tf.AffineTransform(\n                    scale=(scale_x, scale_y),\n                    translation=(translate_x_px, translate_y_px),\n                    rotation=math.radians(rotate),\n                    shear=math.radians(shear)\n                )\n                matrix_to_center = tf.SimilarityTransform(translation=[shift_x, shift_y])\n                matrix = (matrix_to_topleft + matrix_transforms + matrix_to_center)\n\n                coords = keypoints_on_image.get_coords_array()\n                #print(""coords"", coords)\n                #print(""matrix"", matrix.params)\n                coords_aug = tf.matrix_transform(coords, matrix.params)\n                #print(""coords before"", coords)\n                #print(""coordsa ftre"", coords_aug, np.around(coords_aug).astype(np.int32))\n                result.append(ia.KeypointsOnImage.from_coords_array(np.around(coords_aug).astype(np.int32), shape=keypoints_on_image.shape))\n            else:\n                result.append(keypoints_on_image)\n        return result\n\n    def get_parameters(self):\n        return [self.scale, self.translate, self.rotate, self.shear]\n\n    def _draw_samples(self, nb_samples, random_state):\n        seed = random_state.randint(0, 10**6, 1)[0]\n\n        if isinstance(self.scale, tuple):\n            scale_samples = (\n                self.scale[0].draw_samples((nb_samples,), random_state=ia.new_random_state(seed + 10)),\n                self.scale[1].draw_samples((nb_samples,), random_state=ia.new_random_state(seed + 20)),\n            )\n        else:\n            scale_samples = self.scale.draw_samples((nb_samples,), random_state=ia.new_random_state(seed + 30))\n            scale_samples = (scale_samples, scale_samples)\n\n        if isinstance(self.translate, tuple):\n            translate_samples = (\n                self.translate[0].draw_samples((nb_samples,), random_state=ia.new_random_state(seed + 40)),\n                self.translate[1].draw_samples((nb_samples,), random_state=ia.new_random_state(seed + 50)),\n            )\n        else:\n            translate_samples = self.translate.draw_samples((nb_samples,), random_state=ia.new_random_state(seed + 60))\n            translate_samples = (translate_samples, translate_samples)\n\n        assert translate_samples[0].dtype in [np.int32, np.int64, np.float32, np.float64]\n        assert translate_samples[1].dtype in [np.int32, np.int64, np.float32, np.float64]\n\n        rotate_samples = self.rotate.draw_samples((nb_samples,), random_state=ia.new_random_state(seed + 70))\n        shear_samples = self.shear.draw_samples((nb_samples,), random_state=ia.new_random_state(seed + 80))\n\n        cval_samples = self.cval.draw_samples((nb_samples,), random_state=ia.new_random_state(seed + 90))\n        mode_samples = self.mode.draw_samples((nb_samples,), random_state=ia.new_random_state(seed + 100))\n        order_samples = self.order.draw_samples((nb_samples,), random_state=ia.new_random_state(seed + 110))\n\n        return scale_samples, translate_samples, rotate_samples, shear_samples, cval_samples, mode_samples, order_samples\n\n# code partially from https://gist.github.com/chsasank/4d8f68caf01f041a6453e67fb30f8f5a\nclass ElasticTransformation(Augmenter):\n    def __init__(self, alpha=0, sigma=0, name=None, deterministic=False, random_state=None):\n        Augmenter.__init__(self, name=name, deterministic=deterministic, random_state=random_state)\n\n        if ia.is_single_number(alpha):\n            assert alpha >= 0.0, ""Expected alpha to have range [0, inf), got value %.4f."" % (alpha,)\n            self.alpha = Deterministic(alpha)\n        elif ia.is_iterable(alpha):\n            assert len(alpha) == 2, ""Expected tuple/list with 2 entries, got %d entries."" % (str(len(alpha)),)\n            self.alpha = Uniform(alpha[0], alpha[1])\n        elif isinstance(alpha, StochasticParameter):\n            self.alpha = alpha\n        else:\n            raise Exception(""Expected float or int, tuple/list with 2 entries or StochasticParameter. Got %s."" % (type(alpha),))\n\n        if ia.is_single_number(sigma):\n            assert sigma >= 0.0, ""Expected sigma to have range [0, inf), got value %.4f."" % (sigma,)\n            self.sigma = Deterministic(sigma)\n        elif ia.is_iterable(sigma):\n            assert len(sigma) == 2, ""Expected tuple/list with 2 entries, got %d entries."" % (str(len(sigma)),)\n            self.sigma = Uniform(sigma[0], sigma[1])\n        elif isinstance(sigma, StochasticParameter):\n            self.sigma = sigma\n        else:\n            raise Exception(""Expected float or int, tuple/list with 2 entries or StochasticParameter. Got %s."" % (type(sigma),))\n\n    def _augment_images(self, images, random_state, parents, hooks):\n        result = images\n        nb_images = len(images)\n        seeds = ia.copy_random_state(random_state).randint(0, 10**6, (nb_images,))\n        alphas = self.alpha.draw_samples((nb_images,), random_state=ia.copy_random_state(random_state))\n        sigmas = self.sigma.draw_samples((nb_images,), random_state=ia.copy_random_state(random_state))\n        for i in xrange(nb_images):\n            image = images[i]\n            image_first_channel = np.squeeze(image[..., 0])\n            indices_x, indices_y = ElasticTransformation.generate_indices(image_first_channel.shape, alpha=alphas[i], sigma=sigmas[i], random_state=ia.new_random_state(seeds[i]))\n            result[i] = ElasticTransformation.map_coordinates(images[i], indices_x, indices_y)\n        return result\n\n    """"""\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        # TODO do keypoints even have to be augmented for elastic transformations?\n        # TODO this transforms keypoints to images, augments the images, then transforms\n        # back to keypoints - inefficient and keypoints that get outside of the images\n        # cannot be recovered\n        result = []\n        nb_images = len(keypoints_on_images)\n        seeds = ia.copy_random_state(random_state).randint(0, 10**6, (nb_images,))\n        alphas = self.alpha.draw_samples((nb_images,), random_state=ia.copy_random_state(random_state))\n        sigmas = self.sigma.draw_samples((nb_images,), random_state=ia.copy_random_state(random_state))\n        for i, keypoints_on_image in enumerate(keypoints_on_images):\n            indices_x, indices_y = ElasticTransformation.generate_indices(keypoints_on_image.shape[0:2], alpha=alphas[i], sigma=sigmas[i], random_state=ia.new_random_state(seeds[i]))\n            keypoint_image = keypoints_on_image.to_keypoint_image()\n            keypoint_image_aug = ElasticTransformation.map_coordinates(keypoint_image, indices_x, indices_y)\n            keypoints_aug = ia.KeypointsOnImage.from_keypoint_image(keypoint_image_aug)\n            result.append(keypoints_aug)\n        return result\n    """"""\n\n    # no transformation of keypoints for this currently,\n    # it seems like this is the more appropiate choice overall for this augmentation\n    # technique\n    def _augment_keypoints(self, keypoints_on_images, random_state, parents, hooks):\n        return keypoints_on_images\n\n    def get_parameters(self):\n        return [self.alpha, self.sigma]\n\n    @staticmethod\n    def generate_indices(shape, alpha, sigma, random_state):\n        """"""Elastic deformation of images as described in [Simard2003]_.\n        .. [Simard2003] Simard, Steinkraus and Platt, ""Best Practices for\n           Convolutional Neural Networks applied to Visual Document Analysis"", in\n           Proc. of the International Conference on Document Analysis and\n           Recognition, 2003.\n        """"""\n        assert len(shape) == 2\n\n        dx = ndimage.gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=""constant"", cval=0) * alpha\n        dy = ndimage.gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=""constant"", cval=0) * alpha\n\n        x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing=\'ij\')\n        return np.reshape(x+dx, (-1, 1)), np.reshape(y+dy, (-1, 1))\n\n    @staticmethod\n    def map_coordinates(image, indices_x, indices_y):\n        assert len(image.shape) == 3\n        result = np.copy(image)\n        height, width = image.shape[0:2]\n        for c in xrange(image.shape[2]):\n            remapped_flat = ndimage.interpolation.map_coordinates(image[..., c], (indices_x, indices_y), order=1)\n            remapped = remapped_flat.reshape((height, width))\n            result[..., c] = remapped\n        return result\n'"
imgaug/generate_example_images.py,0,"b'from __future__ import print_function, division\nimport imgaug as ia\nimport augmenters as iaa\nimport parameters as iap\n#from skimage import\nimport numpy as np\nfrom scipy import ndimage, misc\nfrom skimage import data\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\ndef main():\n    draw_single_sequential_images()\n    draw_per_augmenter_images()\n\ndef draw_single_sequential_images():\n    image = misc.imresize(ndimage.imread(""quokka.jpg"")[0:643, 0:643], (128, 128))\n\n    st = lambda aug: iaa.Sometimes(0.5, aug)\n\n    seq = iaa.Sequential([\n            iaa.Fliplr(0.5),\n            iaa.Flipud(0.5),\n            st(iaa.Crop(percent=(0, 0.1))),\n            st(iaa.GaussianBlur((0, 3.0))),\n            st(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.2), per_channel=0.5)),\n            st(iaa.Dropout((0.0, 0.1), per_channel=0.5)),\n            st(iaa.Add((-10, 10), per_channel=0.5)),\n            st(iaa.Multiply((0.5, 1.5), per_channel=0.5)),\n            st(iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5)),\n            st(iaa.Affine(\n                scale={""x"": (0.8, 1.2), ""y"": (0.8, 1.2)},\n                translate_px={""x"": (-16, 16), ""y"": (-16, 16)},\n                rotate=(-45, 45),\n                shear=(-16, 16),\n                order=ia.ALL,\n                cval=(0, 1.0),\n                mode=ia.ALL\n            )),\n            st(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25))\n        ],\n        random_order=True\n    )\n\n    grid = seq.draw_grid(image, cols=8, rows=8)\n    misc.imsave(""examples_grid.jpg"", grid)\n\ndef draw_per_augmenter_images():\n    print(""[draw_per_augmenter_images] Loading image..."")\n    image = misc.imresize(ndimage.imread(""quokka.jpg"")[0:643, 0:643], (128, 128))\n    #image = misc.imresize(data.chelsea()[0:300, 50:350, :], (128, 128))\n    #image = misc.imresize(data.astronaut(), (128, 128))\n\n    #keypoints = [ia.Keypoint(x=43, y=43), ia.Keypoint(x=78, y=40), ia.Keypoint(x=64, y=73)] # left eye, right eye, mouth\n    keypoints = [ia.Keypoint(x=34, y=15), ia.Keypoint(x=85, y=13), ia.Keypoint(x=63, y=73)] # left ear, right ear, mouth\n    keypoints = [ia.KeypointsOnImage(keypoints, shape=image.shape)]\n\n    print(""[draw_per_augmenter_images] Initializing..."")\n    rows_augmenters = [\n        (""Noop"", [("""", iaa.Noop()) for _ in range(5)]),\n        #(""Crop"", [iaa.Crop(px=vals) for vals in [(2, 4), (4, 8), (6, 16), (8, 32), (10, 64)]]),\n        (""Crop\\n(top, right,\\nbottom, left)"", [(str(vals), iaa.Crop(px=vals)) for vals in [(2, 0, 0, 0), (0, 8, 8, 0), (4, 0, 16, 4), (8, 0, 0, 32), (32, 64, 0, 0)]]),\n        (""Fliplr"", [(str(p), iaa.Fliplr(p)) for p in [0, 0, 1, 1, 1]]),\n        (""Flipud"", [(str(p), iaa.Flipud(p)) for p in [0, 0, 1, 1, 1]]),\n        (""Add"", [(""value=%d"" % (val,), iaa.Add(val)) for val in [-45, -25, 0, 25, 45]]),\n        (""Add\\n(per channel)"", [(""value=(%d, %d)"" % (vals[0], vals[1],), iaa.Add(vals, per_channel=True)) for vals in [(-55, -35), (-35, -15), (-10, 10), (15, 35), (35, 55)]]),\n        (""Multiply"", [(""value=%.2f"" % (val,), iaa.Multiply(val)) for val in [0.25, 0.5, 1.0, 1.25, 1.5]]),\n        (""Multiply\\n(per channel)"", [(""value=(%.2f, %.2f)"" % (vals[0], vals[1],), iaa.Multiply(vals, per_channel=True)) for vals in [(0.15, 0.35), (0.4, 0.6), (0.9, 1.1), (1.15, 1.35), (1.4, 1.6)]]),\n        (""GaussianBlur"", [(""sigma=%.2f"" % (sigma,), iaa.GaussianBlur(sigma=sigma)) for sigma in [0.25, 0.50, 1.0, 2.0, 4.0]]),\n        (""AdditiveGaussianNoise"", [(""scale=%.2f"" % (scale,), iaa.AdditiveGaussianNoise(scale=scale * 255)) for scale in [0.025, 0.05, 0.1, 0.2, 0.3]]),\n        (""AdditiveGaussianNoise\\n(per channel)"", [(""scale=%.2f"" % (scale,), iaa.AdditiveGaussianNoise(scale=scale * 255, per_channel=True)) for scale in [0.025, 0.05, 0.1, 0.2, 0.3]]),\n        (""Dropout"", [(""p=%.2f"" % (p,), iaa.Dropout(p=p)) for p in [0.025, 0.05, 0.1, 0.2, 0.4]]),\n        (""Dropout\\n(per channel)"", [(""p=%.2f"" % (p,), iaa.Dropout(p=p, per_channel=True)) for p in [0.025, 0.05, 0.1, 0.2, 0.4]]),\n        (""ContrastNormalization"", [(""alpha=%.1f"" % (alpha,), iaa.ContrastNormalization(alpha=alpha)) for alpha in [0.5, 0.75, 1.0, 1.25, 1.50]]),\n        (""ContrastNormalization\\n(per channel)"", [(""alpha=(%.2f, %.2f)"" % (alphas[0], alphas[1],), iaa.ContrastNormalization(alpha=alphas, per_channel=True)) for alphas in [(0.4, 0.6), (0.65, 0.85), (0.9, 1.1), (1.15, 1.35), (1.4, 1.6)]]),\n        (""Affine: Scale"", [(""%.1fx"" % (scale,), iaa.Affine(scale=scale)) for scale in [0.1, 0.5, 1.0, 1.5, 1.9]]),\n        (""Affine: Translate"", [(""x=%d y=%d"" % (x, y), iaa.Affine(translate_px={""x"": x, ""y"": y})) for x, y in [(-32, -16), (-16, -32), (-16, -8), (16, 8), (16, 32)]]),\n        (""Affine: Rotate"", [(""%d deg"" % (rotate,), iaa.Affine(rotate=rotate)) for rotate in [-90, -45, 0, 45, 90]]),\n        (""Affine: Shear"", [(""%d deg"" % (shear,), iaa.Affine(shear=shear)) for shear in [-45, -25, 0, 25, 45]]),\n        (""Affine: Modes"", [(mode, iaa.Affine(translate_px=-32, mode=mode)) for mode in [""constant"", ""edge"", ""symmetric"", ""reflect"", ""wrap""]]),\n        (""Affine: cval"", [(""%.2f"" % (cval,), iaa.Affine(translate_px=-32, cval=cval, mode=""constant"")) for cval in [0.0, 0.25, 0.5, 0.75, 1.0]]),\n        (\n            ""Affine: all"", [\n                (\n                    """",\n                    iaa.Affine(\n                        scale={""x"": (0.5, 1.5), ""y"": (0.5, 1.5)},\n                        translate_px={""x"": (-32, 32), ""y"": (-32, 32)},\n                        rotate=(-45, 45),\n                        shear=(-32, 32),\n                        mode=ia.ALL,\n                        cval=(0.0, 1.0)\n                    )\n                )\n                for _ in range(5)\n            ]\n        ),\n        (""ElasticTransformation\\n(sigma=0.2)"", [(""alpha=%.1f"" % (alpha,), iaa.ElasticTransformation(alpha=alpha, sigma=0.2)) for alpha in [0.1, 0.5, 1.0, 3.0, 9.0]])\n    ]\n\n    print(""[draw_per_augmenter_images] Augmenting..."")\n    rows = []\n    for (row_name, augmenters) in rows_augmenters:\n        row_images = []\n        row_keypoints = []\n        row_titles = []\n        for img_title, augmenter in augmenters:\n            aug_det = augmenter.to_deterministic()\n            row_images.append(aug_det.augment_image(image))\n            row_keypoints.append(aug_det.augment_keypoints(keypoints)[0])\n            row_titles.append(img_title)\n        rows.append((row_name, row_images, row_keypoints, row_titles))\n\n    print(""[draw_per_augmenter_images] Plotting..."")\n    width = 8\n    height = int(1.5 * len(rows_augmenters))\n    fig = plt.figure(figsize=(width, height))\n    grid_rows = len(rows)\n    grid_cols = 1 + 5\n    gs = gridspec.GridSpec(grid_rows, grid_cols, width_ratios=[2, 1, 1, 1, 1, 1])\n    axes = []\n    for i in range(grid_rows):\n        axes.append([plt.subplot(gs[i, col_idx]) for col_idx in range(grid_cols)])\n    fig.tight_layout()\n    #fig.subplots_adjust(bottom=0.2 / grid_rows, hspace=0.22)\n    #fig.subplots_adjust(wspace=0.005, hspace=0.425, bottom=0.02)\n    fig.subplots_adjust(wspace=0.005, hspace=0.005, bottom=0.02)\n\n    for row_idx, (row_name, row_images, row_keypoints, row_titles) in enumerate(rows):\n        axes_row = axes[row_idx]\n\n        for col_idx in range(grid_cols):\n            ax = axes_row[col_idx]\n\n            ax.cla()\n            ax.axis(""off"")\n            ax.get_xaxis().set_visible(False)\n            ax.get_yaxis().set_visible(False)\n\n            if col_idx == 0:\n                ax.text(0, 0.5, row_name, color=""black"")\n            else:\n                cell_image = row_images[col_idx-1]\n                cell_keypoints = row_keypoints[col_idx-1]\n                cell_image_kp = cell_keypoints.draw_on_image(cell_image, size=5)\n                ax.imshow(cell_image_kp)\n                x = 0\n                y = 145\n                #ax.text(x, y, row_titles[col_idx-1], color=""black"", backgroundcolor=""white"", fontsize=6)\n                ax.text(x, y, row_titles[col_idx-1], color=""black"", fontsize=7)\n\n\n    fig.savefig(""examples.jpg"", bbox_inches=""tight"")\n    #plt.show()\n\nif __name__ == ""__main__"":\n    main()\n'"
imgaug/imgaug.py,0,"b'from __future__ import print_function, division\nfrom abc import ABCMeta, abstractmethod\nimport random\nimport numpy as np\nimport copy\nimport numbers\nimport cv2\nimport math\nfrom scipy import misc\n\ntry:\n    xrange\nexcept NameError:  # python3\n    xrange = range\n\nALL = ""ALL""\n\n# We instantiate a current/global random state here once.\n# One can also call np.random, but that is (in contrast to np.random.RandomState)\n# a module and hence cannot be copied via deepcopy. That\'s why we use RandomState\n# here (and in all augmenters) instead of np.random.\nCURRENT_RANDOM_STATE = np.random.RandomState(42)\n\ndef is_np_array(val):\n    return isinstance(val, (np.ndarray, np.generic))\n\ndef is_single_integer(val):\n    return isinstance(val, numbers.Integral)\n\ndef is_single_float(val):\n    return isinstance(val, numbers.Real) and not is_single_integer(val)\n\ndef is_single_number(val):\n    return is_single_integer(val) or is_single_float(val)\n\ndef is_iterable(val):\n    return isinstance(val, (tuple, list))\n\ndef is_string(val):\n    return isinstance(val, str) or isinstance(val, unicode)\n\ndef is_integer_array(val):\n    return issubclass(val.dtype.type, np.integer)\n\ndef current_random_state():\n    return CURRENT_RANDOM_STATE\n\ndef new_random_state(seed=None, fully_random=False):\n    if seed is None:\n        if not fully_random:\n            # sample manually a seed instead of just RandomState(), because the latter one\n            # is way slower.\n            seed = CURRENT_RANDOM_STATE.randint(0, 10**6, 1)[0]\n    return np.random.RandomState(seed)\n\ndef dummy_random_state():\n    return np.random.RandomState(1)\n\ndef copy_random_state(random_state, force_copy=False):\n    if random_state == np.random and not force_copy:\n        return random_state\n    else:\n        rs_copy = dummy_random_state()\n        orig_state = random_state.get_state()\n        rs_copy.set_state(orig_state)\n        return rs_copy\n\n# TODO\n#def from_json(json_str):\n#    pass\n\ndef imresize_many_images(images, sizes=None, interpolation=None):\n    s = images.shape\n    assert len(s) == 4, s\n    nb_images = s[0]\n    im_height, im_width = s[1], s[2]\n    nb_channels = s[3]\n    height, width = sizes[0], sizes[1]\n\n    if height == im_height and width == im_width:\n        return np.copy(images)\n\n    ip = interpolation\n    assert ip is None or ip in [""linear"", ""area"", ""cubic"", cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC]\n    if ip is None:\n        if height > im_height or width > im_width:\n            ip = cv2.INTER_AREA\n        else:\n            ip = cv2.INTER_LINEAR\n    elif ip in [""linear"", cv2.INTER_LINEAR]:\n        ip = cv2.INTER_LINEAR\n    elif ip in [""area"", cv2.INTER_AREA]:\n        ip = cv2.INTER_AREA\n    elif ip in [""cubic"", cv2.INTER_CUBIC]:\n        ip = cv2.INTER_CUBIC\n    else:\n        raise Exception(""Invalid interpolation order"")\n\n    result = np.zeros((nb_images, height, width, nb_channels), dtype=np.uint8)\n    for img_idx in range(nb_images):\n        result_img = cv2.resize(images[img_idx], (width, height), interpolation=ip)\n        if len(result_img.shape) == 2:\n            result_img = result_img[:, :, np.newaxis]\n        result[img_idx] = result_img\n    return result\n\ndef imresize_single_image(image, sizes, interpolation=None):\n    grayscale = False\n    if image.shape == 2:\n        grayscale = True\n        image = image[:, :, np.newaxis]\n    assert len(image.shape) == 3, image.shape\n    rs = imresize_many_images(image[np.newaxis, :, :, :], sizes, interpolation=interpolation)\n    if grayscale:\n        return np.squeeze(rs[0, :, :, 0])\n    else:\n        return rs[0, ...]\n\ndef draw_grid(images, rows=None, cols=None):\n    if is_np_array(images):\n        assert len(images.shape) == 4\n    else:\n        assert is_iterable(images)\n\n    nb_images = len(images)\n    cell_height = max([image.shape[0] for image in images])\n    cell_width = max([image.shape[1] for image in images])\n    channels = set([image.shape[2] for image in images])\n    assert len(channels) == 1\n    nb_channels = list(channels)[0]\n    if rows is None and cols is None:\n        rows = cols = int(math.ceil(math.sqrt(nb_images)))\n    elif rows is not None:\n        cols = int(math.ceil(nb_images / rows))\n    elif cols is not None:\n        rows = int(math.ceil(nb_images / cols))\n    assert rows * cols >= nb_images\n\n    width = cell_width * cols\n    height = cell_height * rows\n    grid = np.zeros((height, width, nb_channels))\n    cell_idx = 0\n    for row_idx in range(rows):\n        for col_idx in range(cols):\n            if cell_idx < nb_images:\n                image = images[cell_idx]\n                cell_y1 = cell_height * row_idx\n                cell_y2 = cell_y1 + image.shape[0]\n                cell_x1 = cell_width * col_idx\n                cell_x2 = cell_x1 + image.shape[1]\n                grid[cell_y1:cell_y2, cell_x1:cell_x2, :] = image\n            cell_idx += 1\n\n    return grid\n\ndef show_grid(images, rows=None, cols=None):\n    grid = draw_grid(images, rows=rows, cols=cols)\n    misc.imshow(grid)\n\nclass HooksImages(object):\n    def __init__(self, activator=None, propagator=None, preprocessor=None, postprocessor=None):\n        self.activator = activator\n        self.propagator = propagator\n        self.preprocessor = preprocessor\n        self.postprocessor = postprocessor\n\n    def is_activated(self, images, augmenter, parents, default):\n        if self.activator is None:\n            return default\n        else:\n            return self.activator(images, augmenter, parents, default)\n\n    # TODO is a propagating hook necessary? seems to be covered by activated\n    # hook already\n    def is_propagating(self, images, augmenter, parents, default):\n        if self.propagator is None:\n            return default\n        else:\n            return self.propagator(images, augmenter, parents, default)\n\n    def preprocess(self, images, augmenter, parents):\n        if self.preprocessor is None:\n            return images\n        else:\n            return self.preprocessor(images, augmenter, parents)\n\n    def postprocess(self, images, augmenter, parents):\n        if self.postprocessor is None:\n            return images\n        else:\n            return self.postprocessor(images, augmenter, parents)\n\nclass HooksKeypoints(HooksImages):\n    pass\n\nclass Keypoint(object):\n    def __init__(self, x, y):\n        assert is_single_integer(x), type(x)\n        assert is_single_integer(y), type(y)\n        self.x = x\n        self.y = y\n\n    def project(self, from_shape, to_shape):\n        from_height, from_width = from_shape[0:2]\n        to_height, to_width = to_shape[0:2]\n        x = int(round((self.x / from_width) * to_width))\n        y = int(round((self.y / from_height) * to_height))\n        return Keypoint(x=x, y=y)\n\n    def shift(self, x, y):\n        return Keypoint(self.x + x, self.y + y)\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __str__(self):\n        return ""Keypoint(x=%d, y=%d)"" % (self.x, self.y)\n\nclass KeypointsOnImage(object):\n    def __init__(self, keypoints, shape):\n        self.keypoints = keypoints\n        if is_np_array(shape):\n            self.shape = shape.shape\n        else:\n            assert isinstance(shape, (tuple, list))\n            self.shape = tuple(shape)\n\n    @property\n    def height(self):\n        return self.shape[0]\n\n    @property\n    def width(self):\n        return self.shape[1]\n\n    def on(self, image):\n        if is_np_array(image):\n            shape = image.shape\n        else:\n            shape = image\n\n        keypoints = [kp.project(self.shape, shape) for kp in self.keypoints]\n        return KeypointsOnImage(keypoints, shape)\n\n    def draw_on_image(self, image, color=[0, 255, 0], size=3, copy=True, raise_if_out_of_image=False):\n        if copy:\n            image = np.copy(image)\n\n        height, width = image.shape[0:2]\n\n        for keypoint in self.keypoints:\n            y, x = keypoint.y, keypoint.x\n            if 0 <= y < height and 0 <= x < width:\n                x1 = max(x - size//2, 0)\n                x2 = min(x + 1 + size//2, width - 1)\n                y1 = max(y - size//2, 0)\n                y2 = min(y + 1 + size//2, height - 1)\n                image[y1:y2, x1:x2] = color\n            else:\n                if raise_if_out_of_image:\n                    raise Exception(""Cannot draw keypoint x=%d, y=%d on image with shape %s."" % (y, x, image.shape))\n\n        return image\n\n    def shift(self, x, y):\n        keypoints = [keypoint.shift(x=x, y=y) for keypoint in self.keypoints]\n        return KeypointsOnImage(keypoints, self.shape)\n\n    def get_coords_array(self):\n        result = np.zeros((len(self.keypoints), 2), np.int32)\n        for i, keypoint in enumerate(self.keypoints):\n            result[i, 0] = keypoint.x\n            result[i, 1] = keypoint.y\n        return result\n\n    @staticmethod\n    def from_coords_array(coords, shape):\n        assert is_integer_array(coords), coords.dtype\n        keypoints = [Keypoint(x=coords[i, 0], y=coords[i, 1]) for i in xrange(coords.shape[0])]\n        return KeypointsOnImage(keypoints, shape)\n\n    def to_keypoint_image(self):\n        assert len(self.keypoints) > 0\n        height, width = self.shape[0:2]\n        image = np.zeros((height, width, len(self.keypoints)), dtype=np.uint8)\n        for i, keypoint in enumerate(self.keypoints):\n            y = keypoint.y\n            x = keypoint.x\n            if 0 <= y < height and 0 <= x < width:\n                image[y, x, i] = 255\n        return image\n\n    @staticmethod\n    def from_keypoint_image(image, if_not_found_coords={""x"": -1, ""y"": -1}, threshold=1):\n        assert len(image.shape) == 3\n        height, width, nb_keypoints = image.shape\n\n        drop_if_not_found = False\n        if if_not_found_coords is None:\n            drop_if_not_found = True\n            if_not_found_x = -1\n            if_not_found_y = -1\n        elif isinstance(if_not_found_coords, (tuple, list)):\n            assert len(if_not_found_coords) == 2\n            if_not_found_x = if_not_found_coords[0]\n            if_not_found_y = if_not_found_coords[1]\n        elif isinstance(if_not_found_coords, dict):\n            if_not_found_x = if_not_found_coords[""x""]\n            if_not_found_y = if_not_found_coords[""y""]\n        else:\n            raise Exception(""Expected if_not_found_coords to be None or tuple or list or dict, got %s."" % (type(if_not_found_coords),))\n\n        keypoints = []\n        for i in range(nb_keypoints):\n            maxidx_flat = np.argmax(image[..., i])\n            maxidx_ndim = np.unravel_index(maxidx_flat, (height, width))\n            found = (image[maxidx_ndim[0], maxidx_ndim[1], i] >= threshold)\n            if found:\n                keypoints.append(Keypoint(x=maxidx_ndim[1], y=maxidx_ndim[0]))\n            else:\n                if drop_if_not_found:\n                    pass # dont add the keypoint to the result list, i.e. drop it\n                else:\n                    keypoints.append(Keypoint(x=if_not_found_x, y=if_not_found_y))\n\n        return KeypointsOnImage(keypoints, shape=(height, width))\n\n    def copy(self):\n        return copy.copy(self)\n\n    def deepcopy(self):\n        return copy.deepcopy(self)\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __str__(self):\n        #print(type(self.keypoints), type(self.shape))\n        return ""KeypointOnImage(%s, shape=%s)"" % (str(self.keypoints), self.shape)\n\n# TODO\n""""""\nclass BackgroundAugmenter(object):\n    def __init__(self, image_source, augmenter, maxlen, nb_workers=1):\n        self.augmenter = augmenter\n        self.maxlen = maxlen\n        self.result_queue = multiprocessing.Queue(maxlen)\n        self.batch_workers = []\n        for i in range(nb_workers):\n            worker = multiprocessing.Process(target=self._augment, args=(image_source, augmenter, self.result_queue))\n            worker.daemon = True\n            worker.start()\n            self.batch_workers.append(worker)\n\n    def join(self):\n        for worker in self.batch_workers:\n            worker.join()\n\n    def get_batch(self):\n        return self.result_queue.get()\n\n    def _augment(self, image_source, augmenter, result_queue):\n        batch = next(image_source)\n        self.result_queue.put(augmenter.transform(batch))\n""""""\n'"
imgaug/parameters.py,0,"b'from __future__ import print_function, division\nfrom abc import ABCMeta, abstractmethod\nimport numpy as np\nimport imgaug.imgaug as ia\nimport copy as copy_module\n\ntry:\n    xrange\nexcept NameError:  # python3\n    xrange = range\n\nclass StochasticParameter(object):\n    __metaclass__ = ABCMeta\n\n    def __init__(self):\n        pass\n\n    def draw_sample(self, random_state=None):\n        return self.draw_samples(1, random_state=random_state)[0]\n\n    def draw_samples(self, size, random_state=None):\n        random_state = random_state if random_state is not None else ia.current_random_state()\n        return self._draw_samples(size, random_state)\n\n    @abstractmethod\n    def _draw_samples(self, size, random_state):\n        raise NotImplementedError()\n\n    def copy(self):\n        return copy_module.copy(self)\n\n    def deepcopy(self):\n        return copy_module.deepcopy(self)\n\nclass Binomial(StochasticParameter):\n    def __init__(self, p):\n        StochasticParameter.__init__(self)\n\n        if isinstance(p, StochasticParameter):\n            self.p = p\n        elif ia.is_single_number(p):\n            assert 0 <= p <= 1.0, ""Expected probability p to be in range [0.0, 1.0], got %s."" % (p,)\n            self.p = Deterministic(float(p))\n        else:\n            raise Exception(""Expected StochasticParameter or float/int value, got %s."" % (type(p),))\n\n    def _draw_samples(self, size, random_state):\n        p = self.p.draw_sample(random_state=random_state)\n        assert 0 <= p <= 1.0, ""Expected probability p to be in range [0.0, 1.0], got %s."" % (p,)\n        return random_state.binomial(1, p, size)\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __str__(self):\n        if isinstance(self.p, float):\n            return ""Binomial(%.4f)"" % (self.p,)\n        else:\n            return ""Binomial(%s)"" % (self.p,)\n\nclass Choice(StochasticParameter):\n    def __init__(self, a, replace=True, p=None):\n        StochasticParameter.__init__(self)\n\n        self.a = a\n        self.replace = replace\n        self.p = p\n\n    def _draw_samples(self, size, random_state):\n        return random_state.choice(self.a, size, replace=self.replace, p=self.p)\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __str__(self):\n        return ""Choice(a=%s, replace=%s, p=%s)"" % (str(self.a), str(self.replace), str(self.p),)\n\nclass DiscreteUniform(StochasticParameter):\n    def __init__(self, a, b):\n        StochasticParameter.__init__(self)\n\n        # for two ints the samples will be from range a <= x <= b\n        assert isinstance(a, (int, StochasticParameter)), ""Expected a to be int or StochasticParameter, got %s"" % (type(a),)\n        assert isinstance(b, (int, StochasticParameter)), ""Expected b to be int or StochasticParameter, got %s"" % (type(b),)\n\n        if ia.is_single_integer(a):\n            self.a = Deterministic(a)\n        else:\n            self.a = a\n\n        if ia.is_single_integer(b):\n            self.b = Deterministic(b)\n        else:\n            self.b = b\n\n    def _draw_samples(self, size, random_state):\n        a = self.a.draw_sample(random_state=random_state)\n        b = self.b.draw_sample(random_state=random_state)\n        if a > b:\n            a, b = b, a\n        elif a == b:\n            return np.tile(np.array([a]), size)\n        return random_state.randint(a, b + 1, size)\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __str__(self):\n        return ""DiscreteUniform(%s, %s)"" % (self.a, self.b)\n\nclass Normal(StochasticParameter):\n    def __init__(self, loc, scale):\n        StochasticParameter.__init__(self)\n\n        if isinstance(loc, StochasticParameter):\n            self.loc = loc\n        elif ia.is_single_number(loc):\n            self.loc = Deterministic(loc)\n        else:\n            raise Exception(""Expected float, int or StochasticParameter as loc, got %s, %s."" % (type(loc),))\n\n        if isinstance(scale, StochasticParameter):\n            self.scale = scale\n        elif ia.is_single_number(scale):\n            assert scale >= 0, ""Expected scale to be in range [0, inf) got %s (type %s)."" % (scale, type(scale))\n            self.scale = Deterministic(scale)\n        else:\n            raise Exception(""Expected float, int or StochasticParameter as scale, got %s, %s."" % (type(scale),))\n\n    def _draw_samples(self, size, random_state):\n        loc = self.loc.draw_sample(random_state=random_state)\n        scale = self.scale.draw_sample(random_state=random_state)\n        assert scale >= 0, ""Expected scale to be in rnage [0, inf), got %s."" % (scale,)\n        if scale == 0:\n            return np.tile(loc, size)\n        else:\n            return random_state.normal(loc, scale, size=size)\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __str__(self):\n        return ""Normal(loc=%s, scale=%s)"" % (self.loc, self.scale)\n\nclass Uniform(StochasticParameter):\n    def __init__(self, a, b):\n        StochasticParameter.__init__(self)\n\n        assert isinstance(a, (int, float, StochasticParameter)), ""Expected a to be int, float or StochasticParameter, got %s"" % (type(a),)\n        assert isinstance(b, (int, float, StochasticParameter)), ""Expected b to be int, float or StochasticParameter, got %s"" % (type(b),)\n\n        if ia.is_single_number(a):\n            self.a = Deterministic(a)\n        else:\n            self.a = a\n\n        if ia.is_single_number(b):\n            self.b = Deterministic(b)\n        else:\n            self.b = b\n\n    def _draw_samples(self, size, random_state):\n        a = self.a.draw_sample(random_state=random_state)\n        b = self.b.draw_sample(random_state=random_state)\n        if a > b:\n            a, b = b, a\n        elif a == b:\n            return np.tile(np.array([a]), size)\n        return random_state.uniform(a, b, size)\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __str__(self):\n        return ""Uniform(%s, %s)"" % (self.a, self.b)\n\nclass Deterministic(StochasticParameter):\n    def __init__(self, value):\n        StochasticParameter.__init__(self)\n\n        if isinstance(value, StochasticParameter):\n            self.value = value.draw_sample()\n        elif ia.is_single_number(value) or ia.is_string(value):\n            self.value = value\n        else:\n            raise Exception(""Expected StochasticParameter object or number or string, got %s."" % (type(value),))\n\n    def _draw_samples(self, size, random_state):\n        return np.tile(np.array([self.value]), size)\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __str__(self):\n        if isinstance(self.value, int):\n            return ""Deterministic(int %d)"" % (self.value,)\n        else:\n            return ""Deterministic(float %.8f)"" % (self.value,)\n\nclass Clip(StochasticParameter):\n    def __init__(self, other_param, minval=None, maxval=None):\n        StochasticParameter.__init__(self)\n\n        assert isinstance(other_param, StochasticParameter)\n        assert minval is None or ia.is_single_number(minval)\n        assert maxval is None or ia.is_single_number(maxval)\n\n        self.other_param = other_param\n        self.minval = minval\n        self.maxval = maxval\n\n    def _draw_samples(self, size, random_state):\n        samples = self.other_param.draw_samples(size, random_state=random_state)\n        if self.minval is not None and self.maxval is not None:\n            np.clip(samples, self.minval, self.maxval, out=samples)\n        elif self.minval is not None:\n            np.clip(samples, self.minval, np.max(samples), out=samples)\n        elif self.maxval is not None:\n            np.clip(samples, np.min(samples), self.maxval, out=samples)\n        else:\n            pass\n        return samples\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __str__(self):\n        opstr = str(self.other_param)\n        if self.minval is not None and self.maxval is not None:\n            return ""Clip(%s, %.6f, %.6f)"" % (opstr, float(self.minval), float(self.maxval))\n        elif self.minval is not None:\n            return ""Clip(%s, %.6f, None)"" % (opstr, float(self.minval))\n        elif self.maxval is not None:\n            return ""Clip(%s, None, %.6f)"" % (opstr, float(self.maxval))\n        else:\n            return ""Clip(%s, None, None)"" % (opstr,)\n'"
libs/__init__.py,0,b''
libs/activations.py,1,"b'""""""Activations for TensorFlow.\nParag K. Mital, Jan 2016.""""""\nimport tensorflow as tf\n\n\ndef lrelu(x, leak=0.2, name=""lrelu""):\n    """"""Leaky rectifier.\n\n    Parameters\n    ----------\n    x : Tensor\n        The tensor to apply the nonlinearity to.\n    leak : float, optional\n        Leakage parameter.\n    name : str, optional\n        Variable scope to use.\n\n    Returns\n    -------\n    x : Tensor\n        Output of the nonlinearity.\n    """"""\n    with tf.variable_scope(name):\n        f1 = 0.5 * (1 + leak)\n        f2 = 0.5 * (1 - leak)\n        return f1 * x + f2 * abs(x)'"
libs/utils.py,6,"b'""""""Some useful utilities when dealing with neural nets w/ tensorflow.\n\nParag K. Mital, Jan. 2016\n""""""\nimport tensorflow as tf\nimport numpy as np\n\n\ndef montage_batch(images):\n    """"""Draws all filters (n_input * n_output filters) as a\n    montage image separated by 1 pixel borders.\n\n    Parameters\n    ----------\n    batch : numpy.ndarray\n        Input array to create montage of.\n\n    Returns\n    -------\n    m : numpy.ndarray\n        Montage image.\n    """"""\n    img_h = images.shape[1]\n    img_w = images.shape[2]\n    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n    m = np.ones(\n        (images.shape[1] * n_plots + n_plots + 1,\n         images.shape[2] * n_plots + n_plots + 1, 3)) * 0.5\n\n    for i in range(n_plots):\n        for j in range(n_plots):\n            this_filter = i * n_plots + j\n            if this_filter < images.shape[0]:\n                this_img = images[this_filter, ...]\n                m[1 + i + i * img_h:1 + i + (i + 1) * img_h,\n                  1 + j + j * img_w:1 + j + (j + 1) * img_w, :] = this_img\n    return m\n\n\n# %%\ndef montage(W):\n    """"""Draws all filters (n_input * n_output filters) as a\n    montage image separated by 1 pixel borders.\n\n    Parameters\n    ----------\n    W : numpy.ndarray\n        Input array to create montage of.\n\n    Returns\n    -------\n    m : numpy.ndarray\n        Montage image.\n    """"""\n    W = np.reshape(W, [W.shape[0], W.shape[1], 1, W.shape[2] * W.shape[3]])\n    n_plots = int(np.ceil(np.sqrt(W.shape[-1])))\n    m = np.ones(\n        (W.shape[0] * n_plots + n_plots + 1,\n         W.shape[1] * n_plots + n_plots + 1)) * 0.5\n    for i in range(n_plots):\n        for j in range(n_plots):\n            this_filter = i * n_plots + j\n            if this_filter < W.shape[-1]:\n                m[1 + i + i * W.shape[0]:1 + i + (i + 1) * W.shape[0],\n                  1 + j + j * W.shape[1]:1 + j + (j + 1) * W.shape[1]] = (\n                    np.squeeze(W[:, :, :, this_filter]))\n    return m\n\n\n\n\n# %%\ndef corrupt(x):\n    """"""Take an input tensor and add uniform masking.\n\n    Parameters\n    ----------\n    x : Tensor/Placeholder\n        Input to corrupt.\n\n    Returns\n    -------\n    x_corrupted : Tensor\n        50 pct of values corrupted.\n    """"""\n    return tf.mul(x, tf.cast(tf.random_uniform(shape=tf.shape(x),\n                                               minval=0,\n                                               maxval=2,\n                                               dtype=tf.int32), tf.float32))\n\n\n# %%\ndef weight_variable(shape):\n    \'\'\'Helper function to create a weight variable initialized with\n    a normal distribution\n\n    Parameters\n    ----------\n    shape : list\n        Size of weight variable\n    \'\'\'\n    initial = tf.random_normal(shape, mean=0.0, stddev=0.01)\n    return tf.Variable(initial)\n\n\n# %%\ndef bias_variable(shape):\n    \'\'\'Helper function to create a bias variable initialized with\n    a constant value.\n\n    Parameters\n    ----------\n    shape : list\n        Size of weight variable\n    \'\'\'\n    initial = tf.random_normal(shape, mean=0.0, stddev=0.01)\n    return tf.Variable(initial)'"
imgaug/old_version/ImageAugmenter.py,7,"b'# -*- coding: utf-8 -*-\n""""""Wrapper functions and classes around scikit-images AffineTransformation.\nSimplifies augmentation of images in machine learning.\n\nExample usage:\n        img_width = 32 # width of the images\n        img_height = 32 # height of the images\n        images = ... # e.g. load via scipy.misc.imload(filename)\n\n        # For each image: randomly flip it horizontally (50% chance),\n        # randomly rotate it between -20 and +20 degrees, randomly translate\n        # it on the x-axis between -5 and +5 pixel.\n        ia = ImageAugmenter(img_width, img_height, hlip=True, rotation_deg=20,\n                            translation_x_px=5)\n        augmented_images = ia.augment_batch(images)\n""""""\nfrom __future__ import division\nfrom skimage import transform as tf\nimport numpy as np\nimport random\n\ndef is_minmax_tuple(param):\n    """"""Returns whether the parameter is a tuple containing two values.\n\n    Used in create_aug_matrices() and probably useless everywhere else.\n\n    Args:\n        param: The parameter to check (whether it is a tuple of length 2).\n\n    Returns:\n        Boolean\n    """"""\n    return type(param) is tuple and len(param) == 2\n\ndef create_aug_matrices(nb_matrices, img_width_px, img_height_px,\n                        scale_to_percent=1.0, scale_axis_equally=False,\n                        rotation_deg=0, shear_deg=0,\n                        translation_x_px=0, translation_y_px=0,\n                        seed=None):\n    """"""Creates the augmentation matrices that may later be used to transform\n    images.\n\n    This is a wrapper around scikit-image\'s transform.AffineTransform class.\n    You can apply those matrices to images using the apply_aug_matrices()\n    function.\n\n    Args:\n        nb_matrices: How many matrices to return, e.g. 100 returns 100 different\n            random-generated matrices (= 100 different transformations).\n        img_width_px: Width of the images that will be transformed later\n            on (same as the width of each of the matrices).\n        img_height_px: Height of the images that will be transformed later\n            on (same as the height of each of the matrices).\n        scale_to_percent: Same as in ImageAugmenter.__init__().\n            Up to which percentage the images may be\n            scaled/zoomed. The negative scaling is automatically derived\n            from this value. A value of 1.1 allows scaling by any value\n            between -10% and +10%. You may set min and max values yourself\n            by using a tuple instead, like (1.1, 1.2) to scale between\n            +10% and +20%. Default is 1.0 (no scaling).\n        scale_axis_equally: Same as in ImageAugmenter.__init__().\n            Whether to always scale both axis (x and y)\n            in the same way. If set to False, then e.g. the Augmenter\n            might scale the x-axis by 20% and the y-axis by -5%.\n            Default is False.\n        rotation_deg: Same as in ImageAugmenter.__init__().\n            By how much the image may be rotated around its\n            center (in degrees). The negative rotation will automatically\n            be derived from this value. E.g. a value of 20 allows any\n            rotation between -20 degrees and +20 degrees. You may set min\n            and max values yourself by using a tuple instead, e.g. (5, 20)\n            to rotate between +5 und +20 degrees. Default is 0 (no\n            rotation).\n        shear_deg: Same as in ImageAugmenter.__init__().\n            By how much the image may be sheared (in degrees). The\n            negative value will automatically be derived from this value.\n            E.g. a value of 20 allows any shear between -20 degrees and\n            +20 degrees. You may set min and max values yourself by using a\n            tuple instead, e.g. (5, 20) to shear between +5 und +20\n            degrees. Default is 0 (no shear).\n        translation_x_px: Same as in ImageAugmenter.__init__().\n            By up to how many pixels the image may be\n            translated (moved) on the x-axis. The negative value will\n            automatically be derived from this value. E.g. a value of +7\n            allows any translation between -7 and +7 pixels on the x-axis.\n            You may set min and max values yourself by using a tuple\n            instead, e.g. (5, 20) to translate between +5 und +20 pixels.\n            Default is 0 (no translation on the x-axis).\n        translation_y_px: Same as in ImageAugmenter.__init__().\n            See translation_x_px, just for the y-axis.\n        seed: Seed to use for python\'s and numpy\'s random functions.\n\n    Returns:\n        List of augmentation matrices.\n    """"""\n    assert nb_matrices > 0\n    assert img_width_px > 0\n    assert img_height_px > 0\n    assert is_minmax_tuple(scale_to_percent) or scale_to_percent >= 1.0\n    assert is_minmax_tuple(rotation_deg) or rotation_deg >= 0\n    assert is_minmax_tuple(shear_deg) or shear_deg >= 0\n    assert is_minmax_tuple(translation_x_px) or translation_x_px >= 0\n    assert is_minmax_tuple(translation_y_px) or translation_y_px >= 0\n\n    if seed is not None:\n        random.seed(seed)\n        np.random.seed(seed)\n\n    result = []\n\n    shift_x = int(img_width_px / 2.0)\n    shift_y = int(img_height_px / 2.0)\n\n    # prepare min and max values for\n    # scaling/zooming (min/max values)\n    if is_minmax_tuple(scale_to_percent):\n        scale_x_min = scale_to_percent[0]\n        scale_x_max = scale_to_percent[1]\n    else:\n        scale_x_min = scale_to_percent\n        scale_x_max = 1.0 - (scale_to_percent - 1.0)\n    assert scale_x_min > 0.0\n    #if scale_x_max >= 2.0:\n    #     warnings.warn(""Scaling by more than 100 percent (%.2f)."" % (scale_x_max,))\n    scale_y_min = scale_x_min # scale_axis_equally affects the random value generation\n    scale_y_max = scale_x_max\n\n    # rotation (min/max values)\n    if is_minmax_tuple(rotation_deg):\n        rotation_deg_min = rotation_deg[0]\n        rotation_deg_max = rotation_deg[1]\n    else:\n        rotation_deg_min = (-1) * int(rotation_deg)\n        rotation_deg_max = int(rotation_deg)\n\n    # shear (min/max values)\n    if is_minmax_tuple(shear_deg):\n        shear_deg_min = shear_deg[0]\n        shear_deg_max = shear_deg[1]\n    else:\n        shear_deg_min = (-1) * int(shear_deg)\n        shear_deg_max = int(shear_deg)\n\n    # translation x-axis (min/max values)\n    if is_minmax_tuple(translation_x_px):\n        translation_x_px_min = translation_x_px[0]\n        translation_x_px_max = translation_x_px[1]\n    else:\n        translation_x_px_min = (-1) * translation_x_px\n        translation_x_px_max = translation_x_px\n\n    # translation y-axis (min/max values)\n    if is_minmax_tuple(translation_y_px):\n        translation_y_px_min = translation_y_px[0]\n        translation_y_px_max = translation_y_px[1]\n    else:\n        translation_y_px_min = (-1) * translation_y_px\n        translation_y_px_max = translation_y_px\n\n    # create nb_matrices randomized affine transformation matrices\n    for _ in range(nb_matrices):\n        # generate random values for scaling, rotation, shear, translation\n        scale_x = random.uniform(scale_x_min, scale_x_max)\n        scale_y = random.uniform(scale_y_min, scale_y_max)\n        if not scale_axis_equally:\n            scale_y = random.uniform(scale_y_min, scale_y_max)\n        else:\n            scale_y = scale_x\n        rotation = np.deg2rad(random.randint(rotation_deg_min, rotation_deg_max))\n        shear = np.deg2rad(random.randint(shear_deg_min, shear_deg_max))\n        translation_x = random.randint(translation_x_px_min, translation_x_px_max)\n        translation_y = random.randint(translation_y_px_min, translation_y_px_max)\n\n        # create three affine transformation matrices\n        # 1st one moves the image to the top left, 2nd one transforms it, 3rd one\n        # moves it back to the center.\n        # The movement is neccessary, because rotation is applied to the top left\n        # and not to the image\'s center (same for scaling and shear).\n        matrix_to_topleft = tf.SimilarityTransform(translation=[-shift_x, -shift_y])\n        matrix_transforms = tf.AffineTransform(scale=(scale_x, scale_y),\n                                               rotation=rotation, shear=shear,\n                                               translation=(translation_x,\n                                                            translation_y))\n        matrix_to_center = tf.SimilarityTransform(translation=[shift_x, shift_y])\n\n        # Combine the three matrices to one affine transformation (one matrix)\n        matrix = matrix_to_topleft + matrix_transforms + matrix_to_center\n\n        # one matrix is ready, add it to the result\n        result.append(matrix.inverse)\n\n    return result\n\ndef apply_aug_matrices(images, matrices, transform_channels_equally=True,\n                       channel_is_first_axis=False, random_order=True,\n                       mode=""constant"", cval=0.0, interpolation_order=1,\n                       seed=None):\n    """"""Augment the given images using the given augmentation matrices.\n\n    This function is a wrapper around scikit-image\'s transform.warp().\n    It is expected to be called by ImageAugmenter.augment_batch().\n    The matrices may be generated by create_aug_matrices().\n\n    Args:\n        images: Same as in ImageAugmenter.augment_batch().\n            Numpy array (dtype: uint8, i.e. values 0-255) with the images.\n            Expected shape is either (image-index, height, width) for\n            grayscale images or (image-index, channel, height, width) for\n            images with channels (e.g. RGB) where the channel has the first\n            index or (image-index, height, width, channel) for images with\n            channels, where the channel is the last index.\n            If your shape is (image-index, channel, width, height) then\n            you must also set channel_is_first_axis=True in the constructor.\n        matrices: A list of augmentation matrices as produced by\n            create_aug_matrices().\n        transform_channels_equally: Same as in ImageAugmenter.__init__().\n            Whether to apply the exactly same\n            transformations to each channel of an image (True). Setting\n            it to False allows different transformations per channel,\n            e.g. the red-channel might be rotated by +20 degrees, while\n            the blue channel (of the same image) might be rotated\n            by -5 degrees. If you don\'t have any channels (2D grayscale),\n            you can simply ignore this setting.\n            Default is True (transform all equally).\n        channel_is_first_axis: Same as in ImageAugmenter.__init__().\n            Whether the channel (e.g. RGB) is the first\n            axis of each image (True) or the last axis (False).\n            False matches the scipy and PIL implementation and is the\n            default. If your images are 2D-grayscale then you can ignore\n            this setting (as the augmenter will ignore it too).\n        random_order: Whether to apply the augmentation matrices in a random\n            order (True, e.g. the 2nd matrix might be applied to the\n            5th image) or in the given order (False, e.g. the 2nd matrix might\n            be applied to the 2nd image).\n            Notice that for multi-channel images (e.g. RGB) this function\n            will use a different matrix for each channel, unless\n            transform_channels_equally is set to True.\n        mode: Parameter used for the transform.warp-function of scikit-image.\n            Can usually be ignored.\n        cval: Parameter used for the transform.warp-function of scikit-image.\n            Defines the fill color for ""new"" pixels, e.g. for empty areas\n            after rotations. (0.0 is black, 1.0 is white.)\n        interpolation_order: Parameter used for the transform.warp-function of\n            scikit-image. Defines the order of all interpolations used to\n            generate the new/augmented image. See their documentation for\n            further details.\n        seed: Seed to use for python\'s and numpy\'s random functions.\n    """"""\n    # images must be numpy array\n    assert type(images).__module__ == np.__name__, ""Expected numpy array for "" \\\n                                                   ""parameter \'images\'.""\n\n    # images must have uint8 as dtype (0-255)\n    assert images.dtype.name == ""uint8"", ""Expected numpy.uint8 as image dtype.""\n\n    # 3 axis total (2 per image) for grayscale,\n    # 4 axis total (3 per image) for RGB (usually)\n    assert len(images.shape) in [3, 4], """"""Expected \'images\' parameter to have\n        either shape (image index, y, x) for greyscale\n        or (image index, channel, y, x) / (image index, y, x, channel)\n        for multi-channel (usually color) images.""""""\n\n    if seed:\n        np.random.seed(seed)\n\n    nb_images = images.shape[0]\n\n    # estimate number of channels, set to 1 if there is no axis channel,\n    # otherwise it will usually be 3\n    has_channels = False\n    nb_channels = 1\n    if len(images.shape) == 4:\n        has_channels = True\n        if channel_is_first_axis:\n            nb_channels = images.shape[1] # first axis within each image\n        else:\n            nb_channels = images.shape[3] # last axis within each image\n\n    # whether to apply the transformations directly to the whole image\n    # array (True) or for each channel individually (False)\n    apply_directly = not has_channels or (transform_channels_equally\n                                          and not channel_is_first_axis)\n\n    # We generate here the order in which the matrices may be applied.\n    # At the end, order_indices will contain the index of the matrix to use\n    # for each image, e.g. [15, 2] would mean, that the 15th matrix will be\n    # applied to the 0th image, the 2nd matrix to the 1st image.\n    # If the images gave multiple channels (e.g. RGB) and\n    # transform_channels_equally has been set to False, we will need one\n    # matrix per channel instead of per image.\n\n    # 0 to nb_images, but restart at 0 if index is beyond number of matrices\n    len_indices = nb_images if apply_directly else nb_images * nb_channels\n    if random_order:\n        # Notice: This way to choose random matrices is concise, but can create\n        # problems if there is a low amount of images and matrices.\n        # E.g. suppose that 2 images are ought to be transformed by either\n        # 0px translation on the x-axis or 1px translation. So 50% of all\n        # matrices translate by 0px and 50% by 1px. The following method\n        # will randomly choose a combination of the two matrices for the\n        # two images (matrix 0 for image 0 and matrix 0 for image 1,\n        # matrix 0 for image 0 and matrix 1 for image 1, ...).\n        # In 50% of these cases, a different matrix will be chosen for image 0\n        # and image 1 (matrices 0, 1 or matrices 1, 0). But 50% of these\n        # ""different"" matrices (different index) will be the same, as 50%\n        # translate by 1px and 50% by 0px. As a result, 75% of all augmentations\n        # will transform both images in the same way.\n        # The effect decreases if more matrices or images are chosen.\n        order_indices = np.random.random_integers(0, len(matrices) - 1, len_indices)\n    else:\n        # monotonously growing indexes (each by +1), but none of them may be\n        # higher than or equal to the number of matrices\n        order_indices = np.arange(0, len_indices) % len(matrices)\n\n    result = np.zeros(images.shape, dtype=np.float32)\n    matrix_number = 0\n\n    # iterate over every image, find out which matrix to apply and then use\n    # that matrix to augment the image\n    for img_idx, image in enumerate(images):\n        if apply_directly:\n            # we can apply the matrix to the whole numpy array of the image\n            # at the same time, so we do that to save time (instead of eg. three\n            # steps for three channels as in the else-part)\n            matrix = matrices[order_indices[matrix_number]]\n            result[img_idx, ...] = tf.warp(image, matrix, mode=mode, cval=cval,\n                                           order=interpolation_order)\n            matrix_number += 1\n        else:\n            # we cant apply the matrix to the whole image in one step, instead\n            # we have to apply it to each channel individually. that happens\n            # if the channel is the first axis of each image (incompatible with\n            # tf.warp()) or if it was explicitly requested via\n            # transform_channels_equally=False.\n            for channel_idx in range(nb_channels):\n                matrix = matrices[order_indices[matrix_number]]\n                if channel_is_first_axis:\n                    warped = tf.warp(image[channel_idx], matrix, mode=mode,\n                                     cval=cval, order=interpolation_order)\n                    result[img_idx, channel_idx, ...] = warped\n                else:\n                    warped = tf.warp(image[..., channel_idx], matrix, mode=mode,\n                                     cval=cval, order=interpolation_order)\n                    result[img_idx, ..., channel_idx] = warped\n\n                if not transform_channels_equally:\n                    matrix_number += 1\n            if transform_channels_equally:\n                matrix_number += 1\n\n    return result\n\nclass ImageAugmenter(object):\n    """"""Helper class to randomly augment images, usually for neural networks.\n\n    Example usage:\n        img_width = 32 # width of the images\n        img_height = 32 # height of the images\n        images = ... # e.g. load via scipy.misc.imload(filename)\n\n        # For each image: randomly flip it horizontally (50% chance),\n        # randomly rotate it between -20 and +20 degrees, randomly translate\n        # it on the x-axis between -5 and +5 pixel.\n        ia = ImageAugmenter(img_width, img_height, hlip=True, rotation_deg=20,\n                            translation_x_px=5)\n        augmented_images = ia.augment_batch(images)\n    """"""\n    def __init__(self, img_width_px, img_height_px, channel_is_first_axis=False,\n                 hflip=False, vflip=False,\n                 scale_to_percent=1.0, scale_axis_equally=False,\n                 rotation_deg=0, shear_deg=0,\n                 translation_x_px=0, translation_y_px=0,\n                 transform_channels_equally=True):\n        """"""\n        Args:\n            img_width_px: The intended width of each image in pixels.\n            img_height_px: The intended height of each image in pixels.\n            channel_is_first_axis: Whether the channel (e.g. RGB) is the first\n                axis of each image (True) or the last axis (False).\n                False matches the scipy and PIL implementation and is the\n                default. If your images are 2D-grayscale then you can ignore\n                this setting (as the augmenter will ignore it too).\n            hflip: Whether to randomly flip images horizontally (on the y-axis).\n                You may choose either False (no horizontal flipping),\n                True (flip with probability 0.5) or use a float\n                value (probability) between 0.0 and 1.0. Default is False.\n            vflip: Whether to randomly flip images vertically (on the x-axis).\n                You may choose either False (no vertical flipping),\n                True (flip with probability 0.5) or use a float\n                value (probability) between 0.0 and 1.0. Default is False.\n            scale_to_percent: Up to which percentage the images may be\n                scaled/zoomed. The negative scaling is automatically derived\n                from this value. A value of 1.1 allows scaling by any value\n                between -10% and +10%. You may set min and max values yourself\n                by using a tuple instead, like (1.1, 1.2) to scale between\n                +10% and +20%. Default is 1.0 (no scaling).\n            scale_axis_equally: Whether to always scale both axis (x and y)\n                in the same way. If set to False, then e.g. the Augmenter\n                might scale the x-axis by 20% and the y-axis by -5%.\n                Default is False.\n            rotation_deg: By how much the image may be rotated around its\n                center (in degrees). The negative rotation will automatically\n                be derived from this value. E.g. a value of 20 allows any\n                rotation between -20 degrees and +20 degrees. You may set min\n                and max values yourself by using a tuple instead, e.g. (5, 20)\n                to rotate between +5 und +20 degrees. Default is 0 (no\n                rotation).\n            shear_deg: By how much the image may be sheared (in degrees). The\n                negative value will automatically be derived from this value.\n                E.g. a value of 20 allows any shear between -20 degrees and\n                +20 degrees. You may set min and max values yourself by using a\n                tuple instead, e.g. (5, 20) to shear between +5 und +20\n                degrees. Default is 0 (no shear).\n            translation_x_px: By up to how many pixels the image may be\n                translated (moved) on the x-axis. The negative value will\n                automatically be derived from this value. E.g. a value of +7\n                allows any translation between -7 and +7 pixels on the x-axis.\n                You may set min and max values yourself by using a tuple\n                instead, e.g. (5, 20) to translate between +5 und +20 pixels.\n                Default is 0 (no translation on the x-axis).\n            translation_y_px: See translation_x_px, just for the y-axis.\n            transform_channels_equally: Whether to apply the exactly same\n                transformations to each channel of an image (True). Setting\n                it to False allows different transformations per channel,\n                e.g. the red-channel might be rotated by +20 degrees, while\n                the blue channel (of the same image) might be rotated\n                by -5 degrees. If you don\'t have any channels (2D grayscale),\n                you can simply ignore this setting.\n                Default is True (transform all equally).\n        """"""\n        self.img_width_px = img_width_px\n        self.img_height_px = img_height_px\n        self.channel_is_first_axis = channel_is_first_axis\n\n        self.hflip_prob = 0.0\n        # note: we have to check first for floats, otherwise ""hflip == True""\n        # will evaluate to true if hflip is 1.0. So chosing 1.0 (100%) would\n        # result in hflip_prob to be set to 0.5 (50%).\n        if isinstance(hflip, float):\n            assert hflip >= 0.0 and hflip <= 1.0\n            self.hflip_prob = hflip\n        elif hflip == True:\n            self.hflip_prob = 0.5\n        elif hflip == False:\n            self.hflip_prob = 0.0\n        else:\n            raise Exception(""Unexpected value for parameter \'hflip\'."")\n\n        self.vflip_prob = 0.0\n        if isinstance(vflip, float):\n            assert vflip >= 0.0 and vflip <= 1.0\n            self.vflip_prob = vflip\n        elif vflip == True:\n            self.vflip_prob = 0.5\n        elif vflip == False:\n            self.vflip_prob = 0.0\n        else:\n            raise Exception(""Unexpected value for parameter \'vflip\'."")\n\n        self.scale_to_percent = scale_to_percent\n        self.scale_axis_equally = scale_axis_equally\n        self.rotation_deg = rotation_deg\n        self.shear_deg = shear_deg\n        self.translation_x_px = translation_x_px\n        self.translation_y_px = translation_y_px\n        self.transform_channels_equally = transform_channels_equally\n        self.cval = 0.0\n        self.interpolation_order = 1\n        self.pregenerated_matrices = None\n\n    def pregenerate_matrices(self, nb_matrices, seed=None):\n        """"""Pregenerate/cache augmentation matrices.\n\n        If matrices are pregenerated, augment_batch() will reuse them on\n        each call. The augmentations will not always be the same,\n        as the order of the matrices will be randomized (when\n        they are applied to the images). The requirement for that is though\n        that you pregenerate enough of them (e.g. a couple thousand).\n\n        Note that generating the augmentation matrices is usually fast\n        and only starts to make sense if you process millions of small images\n        or many tens of thousands of big images.\n\n        Each call to this method results in pregenerating a new set of matrices,\n        e.g. to replace a list of matrices that has been used often enough.\n\n        Calling this method with nb_matrices set to 0 will remove the\n        pregenerated matrices and augment_batch() returns to its default\n        behaviour of generating new matrices on each call.\n\n        Args:\n            nb_matrices: The number of matrices to pregenerate. E.g. a few\n                thousand. If set to 0, the matrices will be generated again on\n                each call of augment_batch().\n            seed: A random seed to use.\n        """"""\n        assert nb_matrices >= 0\n        if nb_matrices == 0:\n            self.pregenerated_matrices = None\n        else:\n            matrices = create_aug_matrices(nb_matrices,\n                                           self.img_width_px,\n                                           self.img_height_px,\n                                           scale_to_percent=self.scale_to_percent,\n                                           scale_axis_equally=self.scale_axis_equally,\n                                           rotation_deg=self.rotation_deg,\n                                           shear_deg=self.shear_deg,\n                                           translation_x_px=self.translation_x_px,\n                                           translation_y_px=self.translation_y_px,\n                                           seed=seed)\n            self.pregenerated_matrices = matrices\n\n    def augment_batch(self, images, seed=None):\n        """"""Augments a batch of images.\n\n        Applies all settings (rotation, shear, translation, ...) that\n        have been chosen in the constructor.\n\n        Args:\n            images: Numpy array (dtype: uint8, i.e. values 0-255) with the images.\n                Expected shape is either (image-index, height, width) for\n                grayscale images or (image-index, channel, height, width) for\n                images with channels (e.g. RGB) where the channel has the first\n                index or (image-index, height, width, channel) for images with\n                channels, where the channel is the last index.\n                If your shape is (image-index, channel, width, height) then\n                you must also set channel_is_first_axis=True in the constructor.\n            seed: Seed to use for python\'s and numpy\'s random functions.\n                Default is None (dont use a seed).\n\n        Returns:\n            Augmented images as numpy array of dtype float32 (i.e. values\n            are between 0.0 and 1.0).\n        """"""\n        shape = images.shape\n        nb_channels = 0\n        if len(shape) == 3:\n            # shape like (image_index, y-axis, x-axis)\n            assert shape[1] == self.img_height_px\n            assert shape[2] == self.img_width_px\n            nb_channels = 1\n        elif len(shape) == 4:\n            if not self.channel_is_first_axis:\n                # shape like (image-index, y-axis, x-axis, channel-index)\n                assert shape[1] == self.img_height_px\n                assert shape[2] == self.img_width_px\n                nb_channels = shape[3]\n            else:\n                # shape like (image-index, channel-index, y-axis, x-axis)\n                assert shape[2] == self.img_height_px\n                assert shape[3] == self.img_width_px\n                nb_channels = shape[1]\n        else:\n            msg = ""Mismatch between images shape %s and "" \\\n                  ""predefined image width/height (%d/%d).""\n            raise Exception(msg % (str(shape), self.img_width_px, self.img_height_px))\n\n        if seed:\n            random.seed(seed)\n            np.random.seed(seed)\n\n        # --------------------------------\n        # horizontal and vertical flipping/mirroring\n        # --------------------------------\n        # This should be done before applying the affine matrices, as otherwise\n        # contents of image might already be rotated/translated out of the image.\n        # It is done with numpy instead of the affine matrices, because\n        # scikit-image doesn\'t offer a nice interface to add mirroring/flipping\n        # to affine transformations. The numpy operations are O(1), so they\n        # shouldn\'t have a noticeable effect on runtimes. They also won\'t suffer\n        # from interpolation problems.\n        if self.hflip_prob > 0 or self.vflip_prob > 0:\n            # TODO this currently ignores the setting in\n            # transform_channels_equally and will instead always flip all\n            # channels equally\n\n            # if this is simply a view, then the input array gets flipped too\n            # for some reason\n            images_flipped = np.copy(images)\n            #images_flipped = images.view()\n\n            if len(shape) == 4 and self.channel_is_first_axis:\n                # roll channel to the last axis\n                # swapaxes doesnt work here, because\n                #  (image index, channel, y, x)\n                # would be turned into\n                #  (image index, x, y, channel)\n                # and y needs to come before x\n                images_flipped = np.rollaxis(images_flipped, 1, 4)\n\n            y_p = self.hflip_prob\n            x_p = self.vflip_prob\n            for i in range(images.shape[0]):\n                if y_p > 0 and random.random() < y_p:\n                    images_flipped[i] = np.fliplr(images_flipped[i])\n                if x_p > 0 and random.random() < x_p:\n                    images_flipped[i] = np.flipud(images_flipped[i])\n\n            if len(shape) == 4 and self.channel_is_first_axis:\n                # roll channel back to the second axis (index 1)\n                images_flipped = np.rollaxis(images_flipped, 3, 1)\n            images = images_flipped\n\n        # --------------------------------\n        # if no augmentation has been chosen, stop early\n        # for improved performance (evade applying matrices)\n        # --------------------------------\n        if self.pregenerated_matrices is None \\\n           and self.scale_to_percent == 1.0 and self.rotation_deg == 0 \\\n           and self.shear_deg == 0 \\\n           and self.translation_x_px == 0 and self.translation_y_px == 0:\n            return np.array(images, dtype=np.float32) / 255\n\n        # --------------------------------\n        # generate transformation matrices\n        # --------------------------------\n        if self.pregenerated_matrices is not None:\n            matrices = self.pregenerated_matrices\n        else:\n            # estimate the number of matrices required\n            if self.transform_channels_equally:\n                nb_matrices = shape[0]\n            else:\n                nb_matrices = shape[0] * nb_channels\n\n            # generate matrices\n            matrices = create_aug_matrices(nb_matrices,\n                                           self.img_width_px,\n                                           self.img_height_px,\n                                           scale_to_percent=self.scale_to_percent,\n                                           scale_axis_equally=self.scale_axis_equally,\n                                           rotation_deg=self.rotation_deg,\n                                           shear_deg=self.shear_deg,\n                                           translation_x_px=self.translation_x_px,\n                                           translation_y_px=self.translation_y_px,\n                                           seed=seed)\n\n        # --------------------------------\n        # apply transformation matrices (i.e. augment images)\n        # --------------------------------\n        return apply_aug_matrices(images, matrices,\n                                  transform_channels_equally=self.transform_channels_equally,\n                                  channel_is_first_axis=self.channel_is_first_axis,\n                                  cval=self.cval, interpolation_order=self.interpolation_order,\n                                  seed=seed)\n\n    def plot_image(self, image, nb_repeat=40, show_plot=True):\n        """"""Plot augmented variations of an image.\n\n        This method takes an image and plots it by default in 40 differently\n        augmented versions.\n\n        This method is intended to visualize the strength of your chosen\n        augmentations (so for debugging).\n\n        Args:\n            image: The image to plot.\n            nb_repeat: How often to plot the image. Each time it is plotted,\n                the chosen augmentation will be different. (Default: 40).\n            show_plot: Whether to show the plot. False makes sense if you\n                don\'t have a graphical user interface on the machine.\n                (Default: True)\n\n        Returns:\n            The figure of the plot.\n            Use figure.savefig() to save the image.\n        """"""\n        if len(image.shape) == 2:\n            images = np.resize(image, (nb_repeat, image.shape[0], image.shape[1]))\n        else:\n            images = np.resize(image, (nb_repeat, image.shape[0], image.shape[1],\n                               image.shape[2]))\n        return self.plot_images(images, True, show_plot=show_plot)\n\n    def plot_images(self, images, augment, show_plot=True, figure=None):\n        """"""Plot augmented variations of images.\n\n        The images will all be shown in the same window.\n        It is recommended to not plot too many of them (i.e. stay below 100).\n\n        This method is intended to visualize the strength of your chosen\n        augmentations (so for debugging).\n\n        Args:\n            images: A numpy array of images. See augment_batch().\n            augment: Whether to augment the images (True) or just display\n                them in the way they are (False).\n            show_plot: Whether to show the plot. False makes sense if you\n                don\'t have a graphical user interface on the machine.\n                (Default: True)\n            figure: The figure of the plot in which to draw the images.\n                Provide the return value of this function (from a prior call)\n                to draw in the same plot window again. Chosing \'None\' will\n                create a new figure. (Default is None.)\n\n        Returns:\n            The figure of the plot.\n            Use figure.savefig() to save the image.\n        """"""\n        import matplotlib.pyplot as plt\n        import matplotlib.cm as cm\n\n        if augment:\n            images = self.augment_batch(images)\n\n        # (Lists of) Grayscale images have the shape (image index, y, x)\n        # Multi-Channel images therefore must have 4 or more axes here\n        if len(images.shape) >= 4:\n            # The color-channel is expected to be the last axis by matplotlib\n            # therefore exchange the axes, if its the first one here\n            if self.channel_is_first_axis:\n                images = np.rollaxis(images, 1, 4)\n\n        nb_cols = 10\n        nb_rows = 1 + int(images.shape[0] / nb_cols)\n        if figure is not None:\n            fig = figure\n            plt.figure(fig.number)\n            fig.clear()\n        else:\n            fig = plt.figure(figsize=(10, 10))\n\n        for i, image in enumerate(images):\n            image = images[i]\n\n            plot_number = i + 1\n            ax = fig.add_subplot(nb_rows, nb_cols, plot_number, xticklabels=[],\n                                 yticklabels=[])\n            ax.set_axis_off()\n            # ""cmap"" should restrict the color map to grayscale, but strangely\n            # also works well with color images\n            imgplot = plt.imshow(image, cmap=cm.Greys_r, aspect=""equal"")\n\n        # not showing the plot might be useful e.g. on clusters\n        if show_plot:\n            plt.show()\n\n        return fig\n'"
imgaug/tests/check_visually.py,0,"b'""""""\nTests to visually inspect the results of the library\'s functionality.\nRun these checks from the project directory (i.e. parent directory) via\n    python -m tests/check_visually\n""""""\nfrom __future__ import print_function, division\nimport imgaug as ia\nimport augmenters as iaa\nimport parameters as iap\nimport numpy as np\nfrom scipy import ndimage, misc\nfrom skimage import data\n\ndef main():\n    images = [\n        misc.imresize(ndimage.imread(""quokka.jpg"")[0:643, 0:643], (128, 128)),\n        misc.imresize(data.astronaut(), (128, 128))\n    ]\n\n    augmenters = [\n        iaa.Noop(name=""Noop""),\n        iaa.Crop(px=(0, 8), name=""Crop-px""),\n        iaa.Crop(percent=(0, 0.1), name=""Crop-percent""),\n        iaa.Fliplr(0.5, name=""Fliplr""),\n        iaa.Flipud(0.5, name=""Flipud""),\n        iaa.GaussianBlur((0, 3.0), name=""GaussianBlur""),\n        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.1), name=""AdditiveGaussianNoise""),\n        iaa.Dropout((0.0, 0.1), name=""Dropout""),\n        iaa.Multiply((0.5, 1.5), name=""Multiply""),\n        iaa.ContrastChange(alpha=(0.5, 2.0)),\n        iaa.Affine(\n            scale={""x"": (0.8, 1.2), ""y"": (0.8, 1.2)},\n            translate_px={""x"": (-16, 16), ""y"": (-16, 16)},\n            rotate=(-45, 45),\n            shear=(-16, 16),\n            order=ia.ALL,\n            cval=(0, 1.0),\n            mode=ia.ALL,\n            name=""Affine""\n        ),\n        iaa.ElasticTransformation(alpha=(0.5, 8.0), sigma=1.0)\n    ]\n\n    #for i, aug in enumerate(augmenters):\n        #print(i)\n        #aug.deepcopy()\n        #import copy\n        #copy.deepcopy(aug)\n    seq = iaa.Sequential([aug.copy() for aug in augmenters], name=""Sequential"")\n    st = iaa.Sometimes(0.5, seq.copy(), name=""Sometimes"")\n    augmenters.append(seq)\n    augmenters.append(st)\n\n    for augmenter in augmenters:\n        print(""Augmenter: %s"" % (augmenter.name,))\n        grid = augmenter.draw_grid(images, rows=1, cols=16)\n        misc.imshow(grid)\n\nif __name__ == ""__main__"":\n    main()\n'"
imgaug/tests/test.py,0,"b'""""""\nAutomatically running tests for this library.\nRun these from the project directory (i.e. parent directory) via\n    python -m tests/test\n""""""\nfrom __future__ import print_function, division\nimport imgaug as ia\nimport augmenters as iaa\nimport parameters as iap\nimport numpy as np\n\ndef main():\n    test_is_single_integer()\n    test_is_single_float()\n\n    test_find()\n    test_remove()\n    test_hooks()\n\n    test_Noop()\n    test_Lambda()\n    test_AssertLambda()\n    test_AssertShape()\n    test_Crop()\n    test_Fliplr()\n    test_Flipud()\n    test_GaussianBlur()\n    test_AdditiveGaussianNoise()\n    # MultiplicativeGaussianNoise\n    # ReplacingGaussianNoise\n    test_Dropout()\n    test_Multiply()\n    test_Affine()\n    test_ElasticTransformation()\n    test_Sequential()\n    test_Sometimes()\n\n    print(""Finished without errors."")\n\ndef test_is_single_integer():\n    assert ia.is_single_integer(""A"") == False\n    assert ia.is_single_integer(None) == False\n    assert ia.is_single_integer(1.2) == False\n    assert ia.is_single_integer(1.0) == False\n    assert ia.is_single_integer(np.ones((1,), dtype=np.float32)[0]) == False\n    assert ia.is_single_integer(1) == True\n    assert ia.is_single_integer(1234) == True\n    assert ia.is_single_integer(np.ones((1,), dtype=np.uint8)[0]) == True\n    assert ia.is_single_integer(np.ones((1,), dtype=np.int32)[0]) == True\n\ndef test_is_single_float():\n    assert ia.is_single_float(""A"") == False\n    assert ia.is_single_float(None) == False\n    assert ia.is_single_float(1.2) == True\n    assert ia.is_single_float(1.0) == True\n    assert ia.is_single_float(np.ones((1,), dtype=np.float32)[0]) == True\n    assert ia.is_single_float(1) == False\n    assert ia.is_single_float(1234) == False\n    assert ia.is_single_float(np.ones((1,), dtype=np.uint8)[0]) == False\n    assert ia.is_single_float(np.ones((1,), dtype=np.int32)[0]) == False\n\ndef test_find():\n    noop1 = iaa.Noop(name=""Noop"")\n    fliplr = iaa.Fliplr(name=""Fliplr"")\n    flipud = iaa.Flipud(name=""Flipud"")\n    noop2 = iaa.Noop(name=""Noop2"")\n    seq2 = iaa.Sequential([flipud, noop2], name=""Seq2"")\n    seq1 = iaa.Sequential([noop1, fliplr, seq2], name=""Seq"")\n\n    augs = seq1.find_augmenters_by_name(""Seq"")\n    assert len(augs) == 1\n    assert augs[0] == seq1\n\n    augs = seq1.find_augmenters_by_name(""Seq2"")\n    assert len(augs) == 1\n    assert augs[0] == seq2\n\n    augs = seq1.find_augmenters_by_names([""Seq"", ""Seq2""])\n    assert len(augs) == 2\n    assert augs[0] == seq1\n    assert augs[1] == seq2\n\n    augs = seq1.find_augmenters_by_name(r""Seq.*"", regex=True)\n    assert len(augs) == 2\n    assert augs[0] == seq1\n    assert augs[1] == seq2\n\n    augs = seq1.find_augmenters(lambda aug, parents: aug.name in [""Seq"", ""Seq2""])\n    assert len(augs) == 2\n    assert augs[0] == seq1\n    assert augs[1] == seq2\n\n    augs = seq1.find_augmenters(lambda aug, parents: aug.name in [""Seq"", ""Seq2""] and len(parents) > 0)\n    assert len(augs) == 1\n    assert augs[0] == seq2\n\n    augs = seq1.find_augmenters(lambda aug, parents: aug.name in [""Seq"", ""Seq2""], flat=False)\n    assert len(augs) == 2\n    assert augs[0] == seq1\n    assert augs[1] == [seq2]\n\ndef test_remove():\n    def get_seq():\n        noop1 = iaa.Noop(name=""Noop"")\n        fliplr = iaa.Fliplr(name=""Fliplr"")\n        flipud = iaa.Flipud(name=""Flipud"")\n        noop2 = iaa.Noop(name=""Noop2"")\n        seq2 = iaa.Sequential([flipud, noop2], name=""Seq2"")\n        seq1 = iaa.Sequential([noop1, fliplr, seq2], name=""Seq"")\n        return seq1\n\n    augs = get_seq()\n    augs = augs.remove_augmenters(lambda aug, parents: aug.name == ""Seq2"")\n    seqs = augs.find_augmenters_by_name(r""Seq.*"", regex=True)\n    assert len(seqs) == 1\n    assert seqs[0].name == ""Seq""\n\n    augs = get_seq()\n    augs = augs.remove_augmenters(lambda aug, parents: aug.name == ""Seq2"" and len(parents) == 0)\n    seqs = augs.find_augmenters_by_name(r""Seq.*"", regex=True)\n    assert len(seqs) == 2\n    assert seqs[0].name == ""Seq""\n    assert seqs[1].name == ""Seq2""\n\n    augs = get_seq()\n    augs = augs.remove_augmenters(lambda aug, parents: True)\n    assert augs is not None\n    assert isinstance(augs, iaa.Noop)\n\n    augs = get_seq()\n    augs = augs.remove_augmenters(lambda aug, parents: True, noop_if_topmost=False)\n    assert augs is None\n\ndef test_hooks():\n    image = np.array([[0, 0, 1],\n                      [0, 0, 1],\n                      [0, 1, 1]], dtype=np.uint8)\n    image_lr = np.array([[1, 0, 0],\n                         [1, 0, 0],\n                         [1, 1, 0]], dtype=np.uint8)\n    image_ud = np.array([[0, 1, 1],\n                         [0, 0, 1],\n                         [0, 0, 1]], dtype=np.uint8)\n    image_lrud = np.array([[1, 1, 0],\n                           [1, 0, 0],\n                           [1, 0, 0]], dtype=np.uint8)\n    image = image[:, :, np.newaxis]\n    image_lr = image_lr[:, :, np.newaxis]\n    image_ud = image_ud[:, :, np.newaxis]\n    image_lrud = image_lrud[:, :, np.newaxis]\n\n    seq = iaa.Sequential([iaa.Fliplr(1.0), iaa.Flipud(1.0)])\n\n    # preprocessing\n    def preprocessor(images, augmenter, parents):\n        img = np.copy(images)\n        img[0][1, 1, 0] += 1\n        return img\n    hooks = ia.HooksImages(preprocessor=preprocessor)\n    images_aug = seq.augment_images([image], hooks=hooks)\n    expected = np.copy(image_lrud)\n    expected[1, 1, 0] = 3\n    assert np.array_equal(images_aug[0], expected)\n\n    # postprocessing\n    def postprocessor(images, augmenter, parents):\n        img = np.copy(images)\n        img[0][1, 1, 0] += 1\n        return img\n    hooks = ia.HooksImages(postprocessor=postprocessor)\n    images_aug = seq.augment_images([image], hooks=hooks)\n    expected = np.copy(image_lrud)\n    expected[1, 1, 0] = 3\n    assert np.array_equal(images_aug[0], expected)\n\n    # propagating\n    def propagator(images, augmenter, parents, default):\n        if ""Seq"" in augmenter.name:\n            return False\n        else:\n            return default\n    hooks = ia.HooksImages(propagator=propagator)\n    images_aug = seq.augment_images([image], hooks=hooks)\n    assert np.array_equal(images_aug[0], image)\n\n    # activation\n    def activator(images, augmenter, parents, default):\n        if ""Flipud"" in augmenter.name:\n            return False\n        else:\n            return default\n    hooks = ia.HooksImages(activator=activator)\n    images_aug = seq.augment_images([image], hooks=hooks)\n    assert np.array_equal(images_aug[0], image_lr)\n\ndef test_Noop():\n    images = create_random_images((16, 70, 50, 3))\n    keypoints = create_random_keypoints((16, 70, 50, 3), 4)\n    aug = iaa.Noop()\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    expected = images\n    assert np.array_equal(observed, expected)\n\n    observed = aug_det.augment_images(images)\n    expected = images\n    assert np.array_equal(observed, expected)\n\n    observed = aug.augment_keypoints(keypoints)\n    expected = keypoints\n    assert keypoints_equal(observed, expected)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    expected = keypoints\n    assert keypoints_equal(observed, expected)\n\ndef test_Lambda():\n    base_img = np.array([[0, 0, 1],\n                         [0, 0, 1],\n                         [0, 1, 1]], dtype=np.uint8)\n    base_img = base_img[:, :, np.newaxis]\n    images = np.array([base_img])\n    images_list = [base_img]\n\n    images_aug = images + 1\n    images_aug_list = [image + 1 for image in images_list]\n\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=2)], shape=base_img.shape)]\n    keypoints_aug = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=0), ia.Keypoint(x=2, y=1), ia.Keypoint(x=0, y=2)], shape=base_img.shape)]\n\n    def func_images(images, random_state, parents, hooks):\n        if isinstance(images, list):\n            images = [image + 1 for image in images]\n        else:\n            images = images + 1\n        return images\n\n    def func_keypoints(keypoints_on_images, random_state, parents, hooks):\n        for keypoints_on_image in keypoints_on_images:\n            for kp in keypoints_on_image.keypoints:\n                kp.x = (kp.x + 1) % 3\n        return keypoints_on_images\n\n    aug = iaa.Lambda(func_images, func_keypoints)\n    aug_det = aug.to_deterministic()\n\n    # check once that the augmenter can handle lists correctly\n    observed = aug.augment_images(images_list)\n    expected = images_aug_list\n    assert array_equal_lists(observed, expected)\n\n    observed = aug_det.augment_images(images_list)\n    expected = images_aug_list\n    assert array_equal_lists(observed, expected)\n\n    for _ in range(10):\n        observed = aug.augment_images(images)\n        expected = images_aug\n        assert np.array_equal(observed, expected)\n\n        observed = aug_det.augment_images(images)\n        expected = images_aug\n        assert np.array_equal(observed, expected)\n\n        observed = aug.augment_keypoints(keypoints)\n        expected = keypoints_aug\n        assert keypoints_equal(observed, expected)\n\n        observed = aug_det.augment_keypoints(keypoints)\n        expected = keypoints_aug\n        assert keypoints_equal(observed, expected)\n\ndef test_AssertLambda():\n    base_img = np.array([[0, 0, 1],\n                         [0, 0, 1],\n                         [0, 1, 1]], dtype=np.uint8)\n    base_img = base_img[:, :, np.newaxis]\n    images = np.array([base_img])\n    images_list = [base_img]\n\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=2)], shape=base_img.shape)]\n\n    def func_images_succeeds(images, random_state, parents, hooks):\n        return images[0][0, 0] == 0 and images[0][2, 2] == 1\n\n    def func_images_fails(images, random_state, parents, hooks):\n        return images[0][0, 0] == 1\n\n    def func_keypoints_succeeds(keypoints_on_images, random_state, parents, hooks):\n        return keypoints_on_images[0].keypoints[0].x == 0 and keypoints_on_images[0].keypoints[2].x == 2\n\n    def func_keypoints_fails(keypoints_on_images, random_state, parents, hooks):\n        return keypoints_on_images[0].keypoints[0].x == 2\n\n    aug_succeeds = iaa.AssertLambda(func_images_succeeds, func_keypoints_succeeds)\n    aug_succeeds_det = aug_succeeds.to_deterministic()\n    aug_fails = iaa.AssertLambda(func_images_fails, func_keypoints_fails)\n    aug_fails_det = aug_fails.to_deterministic()\n\n    # images as numpy array\n    observed = aug_succeeds.augment_images(images)\n    expected = images\n    assert np.array_equal(observed, expected)\n\n    try:\n        observed = aug_fails.augment_images(images)\n        errored = False\n    except AssertionError as e:\n        errored = True\n    assert errored\n\n    observed = aug_succeeds_det.augment_images(images)\n    expected = images\n    assert np.array_equal(observed, expected)\n\n    try:\n        observed = aug_fails.augment_images(images)\n        errored = False\n    except AssertionError as e:\n        errored = True\n    assert errored\n\n    # Lists of images\n    observed = aug_succeeds.augment_images(images_list)\n    expected = images_list\n    assert array_equal_lists(observed, expected)\n\n    try:\n        observed = aug_fails.augment_images(images_list)\n        errored = False\n    except AssertionError as e:\n        errored = True\n    assert errored\n\n    observed = aug_succeeds_det.augment_images(images_list)\n    expected = images_list\n    assert array_equal_lists(observed, expected)\n\n    try:\n        observed = aug_fails.augment_images(images_list)\n        errored = False\n    except AssertionError as e:\n        errored = True\n    assert errored\n\n    # keypoints\n    observed = aug_succeeds.augment_keypoints(keypoints)\n    expected = keypoints\n    assert keypoints_equal(observed, expected)\n\n    try:\n        observed = aug_fails.augment_keypoints(keypoints)\n        errored = False\n    except AssertionError as e:\n        errored = True\n    assert errored\n\n    observed = aug_succeeds_det.augment_keypoints(keypoints)\n    expected = keypoints\n    assert keypoints_equal(observed, expected)\n\n    try:\n        observed = aug_fails.augment_keypoints(keypoints)\n        errored = False\n    except AssertionError as e:\n        errored = True\n    assert errored\n\ndef test_AssertShape():\n    base_img = np.array([[0, 0, 1, 0],\n                         [0, 0, 1, 0],\n                         [0, 1, 1, 0]], dtype=np.uint8)\n    base_img = base_img[:, :, np.newaxis]\n    images = np.array([base_img])\n    images_list = [base_img]\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=2)], shape=base_img.shape)]\n\n    base_img_h4 = np.array([[0, 0, 1, 0],\n                            [0, 0, 1, 0],\n                            [0, 1, 1, 0],\n                            [1, 0, 1, 0]], dtype=np.uint8)\n    base_img_h4 = base_img_h4[:, :, np.newaxis]\n    images_h4 = np.array([base_img_h4])\n    keypoints_h4 = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=2)], shape=base_img_h4.shape)]\n\n    # image must have exactly shape (1, 3, 4, 1)\n    aug = iaa.AssertShape((1, 3, 4, 1))\n    aug_det = aug.to_deterministic()\n\n    # check once that the augmenter can handle lists correctly\n    observed = aug.augment_images(images_list)\n    expected = images_list\n    assert array_equal_lists(observed, expected)\n\n    observed = aug_det.augment_images(images_list)\n    expected = images_list\n    assert array_equal_lists(observed, expected)\n\n    for _ in range(10):\n        observed = aug.augment_images(images)\n        expected = images\n        assert np.array_equal(observed, expected)\n\n        observed = aug_det.augment_images(images)\n        expected = images\n        assert np.array_equal(observed, expected)\n\n        observed = aug.augment_keypoints(keypoints)\n        expected = keypoints\n        assert keypoints_equal(observed, expected)\n\n        observed = aug_det.augment_keypoints(keypoints)\n        expected = keypoints\n        assert keypoints_equal(observed, expected)\n\n        try:\n            observed = aug.augment_images(images_h4)\n            errored = False\n        except AssertionError as e:\n            errored = True\n        assert errored\n\n        try:\n            observed = aug.augment_keypoints(keypoints_h4)\n            errored = False\n        except AssertionError as e:\n            errored = True\n        assert errored\n\n    # any value for number of images allowed (None)\n    aug = iaa.AssertShape((None, 3, 4, 1))\n    aug_det = aug.to_deterministic()\n    for _ in range(10):\n        observed = aug.augment_images(images)\n        expected = images\n        assert np.array_equal(observed, expected)\n\n        observed = aug_det.augment_images(images)\n        expected = images\n        assert np.array_equal(observed, expected)\n\n        observed = aug.augment_keypoints(keypoints)\n        expected = keypoints\n        assert keypoints_equal(observed, expected)\n\n        observed = aug_det.augment_keypoints(keypoints)\n        expected = keypoints\n        assert keypoints_equal(observed, expected)\n\n        try:\n            observed = aug.augment_images(images_h4)\n            errored = False\n        except AssertionError as e:\n            errored = True\n        assert errored\n\n        try:\n            observed = aug.augment_keypoints(keypoints_h4)\n            errored = False\n        except AssertionError as e:\n            errored = True\n        assert errored\n\n    # list of possible choices [1, 3, 5] for height\n    aug = iaa.AssertShape((1, [1, 3, 5], 4, 1))\n    aug_det = aug.to_deterministic()\n    for _ in range(10):\n        observed = aug.augment_images(images)\n        expected = images\n        assert np.array_equal(observed, expected)\n\n        observed = aug_det.augment_images(images)\n        expected = images\n        assert np.array_equal(observed, expected)\n\n        observed = aug.augment_keypoints(keypoints)\n        expected = keypoints\n        assert keypoints_equal(observed, expected)\n\n        observed = aug_det.augment_keypoints(keypoints)\n        expected = keypoints\n        assert keypoints_equal(observed, expected)\n\n        try:\n            observed = aug.augment_images(images_h4)\n            errored = False\n        except AssertionError as e:\n            errored = True\n        assert errored\n\n        try:\n            observed = aug.augment_keypoints(keypoints_h4)\n            errored = False\n        except AssertionError as e:\n            errored = True\n        assert errored\n\n    # range of 1-3 for height (tuple comparison is a <= x < b, so we use (1,4) here)\n    aug = iaa.AssertShape((1, (1, 4), 4, 1))\n    aug_det = aug.to_deterministic()\n    for _ in range(10):\n        observed = aug.augment_images(images)\n        expected = images\n        assert np.array_equal(observed, expected)\n\n        observed = aug_det.augment_images(images)\n        expected = images\n        assert np.array_equal(observed, expected)\n\n        observed = aug.augment_keypoints(keypoints)\n        expected = keypoints\n        assert keypoints_equal(observed, expected)\n\n        observed = aug_det.augment_keypoints(keypoints)\n        expected = keypoints\n        assert keypoints_equal(observed, expected)\n\n        try:\n            observed = aug.augment_images(images_h4)\n            errored = False\n        except AssertionError as e:\n            errored = True\n        assert errored\n\n        try:\n            observed = aug.augment_keypoints(keypoints_h4)\n            errored = False\n        except AssertionError as e:\n            errored = True\n        assert errored\n\ndef test_Crop():\n    base_img = np.array([[0, 0, 0],\n                         [0, 1, 0],\n                         [0, 0, 0]], dtype=np.uint8)\n    base_img = base_img[:, :, np.newaxis]\n\n    images = np.array([base_img])\n    images_list = [base_img]\n\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=2)], shape=base_img.shape)]\n\n    # test crop by 1 pixel on each side\n    crops = [\n        (1, 0, 0, 0),\n        (0, 1, 0, 0),\n        (0, 0, 1, 0),\n        (0, 0, 0, 1),\n    ]\n    for crop in crops:\n        top, right, bottom, left = crop\n        height, width = base_img.shape[0:2]\n        aug = iaa.Crop(px=crop, keep_size=False)\n        base_img_cropped = base_img[top:height-bottom, left:width-right, :]\n        observed = aug.augment_images(images)\n        assert np.array_equal(observed, np.array([base_img_cropped]))\n\n        observed = aug.augment_images(images_list)\n        assert array_equal_lists(observed, [base_img_cropped])\n\n        keypoints_moved = [keypoints[0].shift(x=-left, y=-top)]\n        observed = aug.augment_keypoints(keypoints)\n        assert keypoints_equal(observed, keypoints_moved)\n\n    # test crop by range of pixels\n    crops = [\n        ((0, 2), 0, 0, 0),\n        (0, (0, 2), 0, 0),\n        (0, 0, (0, 2), 0),\n        (0, 0, 0, (0, 2)),\n    ]\n    for crop in crops:\n        top, right, bottom, left = crop\n        height, width = base_img.shape[0:2]\n        aug = iaa.Crop(px=crop, keep_size=False)\n        aug_det = aug.to_deterministic()\n\n        images_cropped = []\n        keypoints_cropped = []\n        top_range = top if isinstance(top, tuple) else (top, top)\n        right_range = right if isinstance(right, tuple) else (right, right)\n        bottom_range = bottom if isinstance(bottom, tuple) else (bottom, bottom)\n        left_range = left if isinstance(left, tuple) else (left, left)\n        for top_val in range(top_range[0], top_range[1]+1):\n            for right_val in range(right_range[0], right_range[1]+1):\n                for bottom_val in range(bottom_range[0], bottom_range[1]+1):\n                    for left_val in range(left_range[0], left_range[1]+1):\n\n                        images_cropped.append(base_img[top_val:height-bottom_val, left_val:width-right_val, :])\n                        keypoints_cropped.append(keypoints[0].shift(x=-left_val, y=-top_val))\n\n        movements = []\n        movements_det = []\n        for i in range(100):\n            observed = aug.augment_images(images)\n\n            matches = [1 if np.array_equal(observed, np.array([base_img_cropped])) else 0 for base_img_cropped in images_cropped]\n            movements.append(np.argmax(np.array(matches)))\n            assert any([val == 1 for val in matches])\n\n            observed = aug_det.augment_images(images)\n            matches = [1 if np.array_equal(observed, np.array([base_img_cropped])) else 0 for base_img_cropped in images_cropped]\n            movements_det.append(np.argmax(np.array(matches)))\n            assert any([val == 1 for val in matches])\n\n            observed = aug.augment_images(images_list)\n            assert any([array_equal_lists(observed, [base_img_cropped]) for base_img_cropped in images_cropped])\n\n            observed = aug.augment_keypoints(keypoints)\n            assert any([keypoints_equal(observed, [kp]) for kp in keypoints_cropped])\n\n        assert len(set(movements)) == 3\n        assert len(set(movements_det)) == 1\n\n    # test crop by list of exact pixel values\n    crops = [\n        ([0, 2], 0, 0, 0),\n        (0, [0, 2], 0, 0),\n        (0, 0, [0, 2], 0),\n        (0, 0, 0, [0, 2]),\n    ]\n    for crop in crops:\n        top, right, bottom, left = crop\n        height, width = base_img.shape[0:2]\n        aug = iaa.Crop(px=crop, keep_size=False)\n        aug_det = aug.to_deterministic()\n\n        images_cropped = []\n        keypoints_cropped = []\n        top_range = top if isinstance(top, list) else [top]\n        right_range = right if isinstance(right, list) else [right]\n        bottom_range = bottom if isinstance(bottom, list) else [bottom]\n        left_range = left if isinstance(left, list) else [left]\n        for top_val in top_range:\n            for right_val in right_range:\n                for bottom_val in bottom_range:\n                    for left_val in left_range:\n                        images_cropped.append(base_img[top_val:height-bottom_val, left_val:width-right_val, :])\n                        keypoints_cropped.append(keypoints[0].shift(x=-left_val, y=-top_val))\n\n        movements = []\n        movements_det = []\n        for i in range(100):\n            observed = aug.augment_images(images)\n            matches = [1 if np.array_equal(observed, np.array([base_img_cropped])) else 0 for base_img_cropped in images_cropped]\n            movements.append(np.argmax(np.array(matches)))\n            assert any([val == 1 for val in matches])\n\n            observed = aug_det.augment_images(images)\n            matches = [1 if np.array_equal(observed, np.array([base_img_cropped])) else 0 for base_img_cropped in images_cropped]\n            movements_det.append(np.argmax(np.array(matches)))\n            assert any([val == 1 for val in matches])\n\n            observed = aug.augment_images(images_list)\n            assert any([array_equal_lists(observed, [base_img_cropped]) for base_img_cropped in images_cropped])\n\n            observed = aug.augment_keypoints(keypoints)\n            assert any([keypoints_equal(observed, [kp]) for kp in keypoints_cropped])\n\n        assert len(set(movements)) == 2\n        assert len(set(movements_det)) == 1\n\n    # TODO\n    print(""[Note] Crop by percentages is currently not tested."")\n    print(""[Note] Landmark projection after crop with resize is currently not tested."")\n\ndef test_Fliplr():\n    base_img = np.array([[0, 0, 1],\n                         [0, 0, 1],\n                         [0, 1, 1]], dtype=np.uint8)\n    base_img = base_img[:, :, np.newaxis]\n\n    base_img_flipped = np.array([[1, 0, 0],\n                                 [1, 0, 0],\n                                 [1, 1, 0]], dtype=np.uint8)\n    base_img_flipped = base_img_flipped[:, :, np.newaxis]\n\n    images = np.array([base_img])\n    images_flipped = np.array([base_img_flipped])\n\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=2)], shape=base_img.shape)]\n    keypoints_flipped = [ia.KeypointsOnImage([ia.Keypoint(x=2, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=0, y=2)], shape=base_img.shape)]\n\n    # 0% chance of flip\n    aug = iaa.Fliplr(0)\n    aug_det = aug.to_deterministic()\n\n    for _ in range(10):\n        observed = aug.augment_images(images)\n        expected = images\n        assert np.array_equal(observed, expected)\n\n        observed = aug_det.augment_images(images)\n        expected = images\n        assert np.array_equal(observed, expected)\n\n        observed = aug.augment_keypoints(keypoints)\n        expected = keypoints\n        assert keypoints_equal(observed, expected)\n\n        observed = aug_det.augment_keypoints(keypoints)\n        expected = keypoints\n        assert keypoints_equal(observed, expected)\n\n    # 100% chance of flip\n    aug = iaa.Fliplr(1.0)\n    aug_det = aug.to_deterministic()\n\n    for _ in range(10):\n        observed = aug.augment_images(images)\n        expected = images_flipped\n        assert np.array_equal(observed, expected)\n\n        observed = aug_det.augment_images(images)\n        expected = images_flipped\n        assert np.array_equal(observed, expected)\n\n        observed = aug.augment_keypoints(keypoints)\n        expected = keypoints_flipped\n        assert keypoints_equal(observed, expected)\n\n        observed = aug_det.augment_keypoints(keypoints)\n        expected = keypoints_flipped\n        assert keypoints_equal(observed, expected)\n\n    # 50% chance of flip\n    aug = iaa.Fliplr(0.5)\n    aug_det = aug.to_deterministic()\n\n    nb_iterations = 1000\n    nb_images_flipped = 0\n    nb_images_flipped_det = 0\n    nb_keypoints_flipped = 0\n    nb_keypoints_flipped_det = 0\n    for _ in range(nb_iterations):\n        observed = aug.augment_images(images)\n        if np.array_equal(observed, images_flipped):\n            nb_images_flipped += 1\n\n        observed = aug_det.augment_images(images)\n        if np.array_equal(observed, images_flipped):\n            nb_images_flipped_det += 1\n\n        observed = aug.augment_keypoints(keypoints)\n        if keypoints_equal(observed, keypoints_flipped):\n            nb_keypoints_flipped += 1\n\n        observed = aug_det.augment_keypoints(keypoints)\n        if keypoints_equal(observed, keypoints_flipped):\n            nb_keypoints_flipped_det += 1\n\n    assert int(nb_iterations * 0.3) <= nb_images_flipped <= int(nb_iterations * 0.7)\n    assert int(nb_iterations * 0.3) <= nb_keypoints_flipped <= int(nb_iterations * 0.7)\n    assert nb_images_flipped_det in [0, nb_iterations]\n    assert nb_keypoints_flipped_det in [0, nb_iterations]\n\n    # 50% chance of flipped, multiple images, list as input\n    images_multi = [base_img, base_img]\n    aug = iaa.Fliplr(0.5)\n    aug_det = aug.to_deterministic()\n    nb_iterations = 1000\n    nb_flipped_by_pos = [0] * len(images_multi)\n    nb_flipped_by_pos_det = [0] * len(images_multi)\n    for _ in range(nb_iterations):\n        observed = aug.augment_images(images_multi)\n        for i in range(len(images_multi)):\n            if np.array_equal(observed[i], base_img_flipped):\n                nb_flipped_by_pos[i] += 1\n\n        observed = aug_det.augment_images(images_multi)\n        for i in range(len(images_multi)):\n            if np.array_equal(observed[i], base_img_flipped):\n                nb_flipped_by_pos_det[i] += 1\n\n    for val in nb_flipped_by_pos:\n        assert int(nb_iterations * 0.3) <= val <= int(nb_iterations * 0.7)\n\n    for val in nb_flipped_by_pos_det:\n        assert val in [0, nb_iterations]\n\ndef test_Flipud():\n    base_img = np.array([[0, 0, 1],\n                         [0, 0, 1],\n                         [0, 1, 1]], dtype=np.uint8)\n    base_img = base_img[:, :, np.newaxis]\n\n    base_img_flipped = np.array([[0, 1, 1],\n                                 [0, 0, 1],\n                                 [0, 0, 1]], dtype=np.uint8)\n    base_img_flipped = base_img_flipped[:, :, np.newaxis]\n\n    images = np.array([base_img])\n    images_flipped = np.array([base_img_flipped])\n\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=2)], shape=base_img.shape)]\n    keypoints_flipped = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=2), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=0)], shape=base_img.shape)]\n\n    # 0% chance of flip\n    aug = iaa.Flipud(0)\n    aug_det = aug.to_deterministic()\n\n    for _ in range(10):\n        observed = aug.augment_images(images)\n        expected = images\n        assert np.array_equal(observed, expected)\n\n        observed = aug_det.augment_images(images)\n        expected = images\n        assert np.array_equal(observed, expected)\n\n        observed = aug.augment_keypoints(keypoints)\n        expected = keypoints\n        assert keypoints_equal(observed, expected)\n\n        observed = aug_det.augment_keypoints(keypoints)\n        expected = keypoints\n        assert keypoints_equal(observed, expected)\n\n    # 100% chance of flip\n    aug = iaa.Flipud(1.0)\n    aug_det = aug.to_deterministic()\n\n    for _ in range(10):\n        observed = aug.augment_images(images)\n        expected = images_flipped\n        assert np.array_equal(observed, expected)\n\n        observed = aug_det.augment_images(images)\n        expected = images_flipped\n        assert np.array_equal(observed, expected)\n\n        observed = aug.augment_keypoints(keypoints)\n        expected = keypoints_flipped\n        assert keypoints_equal(observed, expected)\n\n        observed = aug_det.augment_keypoints(keypoints)\n        expected = keypoints_flipped\n        assert keypoints_equal(observed, expected)\n\n    # 50% chance of flip\n    aug = iaa.Flipud(0.5)\n    aug_det = aug.to_deterministic()\n\n    nb_iterations = 1000\n    nb_images_flipped = 0\n    nb_images_flipped_det = 0\n    nb_keypoints_flipped = 0\n    nb_keypoints_flipped_det = 0\n    for _ in range(nb_iterations):\n        observed = aug.augment_images(images)\n        if np.array_equal(observed, images_flipped):\n            nb_images_flipped += 1\n\n        observed = aug_det.augment_images(images)\n        if np.array_equal(observed, images_flipped):\n            nb_images_flipped_det += 1\n\n        observed = aug.augment_keypoints(keypoints)\n        if keypoints_equal(observed, keypoints_flipped):\n            nb_keypoints_flipped += 1\n\n        observed = aug_det.augment_keypoints(keypoints)\n        if keypoints_equal(observed, keypoints_flipped):\n            nb_keypoints_flipped_det += 1\n\n    assert int(nb_iterations * 0.3) <= nb_images_flipped <= int(nb_iterations * 0.7)\n    assert int(nb_iterations * 0.3) <= nb_keypoints_flipped <= int(nb_iterations * 0.7)\n    assert nb_images_flipped_det in [0, nb_iterations]\n    assert nb_keypoints_flipped_det in [0, nb_iterations]\n\n    # 50% chance of flipped, multiple images, list as input\n    images_multi = [base_img, base_img]\n    aug = iaa.Flipud(0.5)\n    aug_det = aug.to_deterministic()\n    nb_iterations = 1000\n    nb_flipped_by_pos = [0] * len(images_multi)\n    nb_flipped_by_pos_det = [0] * len(images_multi)\n    for _ in range(nb_iterations):\n        observed = aug.augment_images(images_multi)\n        for i in range(len(images_multi)):\n            if np.array_equal(observed[i], base_img_flipped):\n                nb_flipped_by_pos[i] += 1\n\n        observed = aug_det.augment_images(images_multi)\n        for i in range(len(images_multi)):\n            if np.array_equal(observed[i], base_img_flipped):\n                nb_flipped_by_pos_det[i] += 1\n\n    for val in nb_flipped_by_pos:\n        assert int(nb_iterations * 0.3) <= val <= int(nb_iterations * 0.7)\n\n    for val in nb_flipped_by_pos_det:\n        assert val in [0, nb_iterations]\n\ndef test_GaussianBlur():\n    base_img = np.array([[0, 0, 0],\n                         [0, 255, 0],\n                         [0, 0, 0]], dtype=np.uint8)\n    base_img = base_img[:, :, np.newaxis]\n\n    images = np.array([base_img])\n    images_list = [base_img]\n    outer_pixels = ([], [])\n    for i in range(base_img.shape[0]):\n        for j in range(base_img.shape[1]):\n            if i != j:\n                outer_pixels[0].append(i)\n                outer_pixels[1].append(j)\n\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=2)], shape=base_img.shape)]\n\n    # no blur, shouldnt change anything\n    aug = iaa.GaussianBlur(sigma=0)\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    expected = images\n    assert np.array_equal(observed, expected)\n\n    # weak blur of center pixel\n    aug = iaa.GaussianBlur(sigma=0.5)\n    aug_det = aug.to_deterministic()\n\n    #np.set_printoptions(formatter={\'float_kind\': lambda x: ""%.6f"" % x})\n    #from scipy import ndimage\n    #images2 = np.copy(images).astype(np.float32)\n    #images2[0, ...] = ndimage.gaussian_filter(images2[0, ...], 0.4)\n    #print(images2)\n\n    # images as numpy array\n    observed = aug.augment_images(images)\n    assert 100 < observed[0][1, 1] < 255\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] > 0).all()\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] < 50).all()\n\n    observed = aug_det.augment_images(images)\n    assert 100 < observed[0][1, 1] < 255\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] > 0).all()\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] < 50).all()\n\n    # images as list\n    observed = aug.augment_images(images_list)\n    assert 100 < observed[0][1, 1] < 255\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] > 0).all()\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] < 50).all()\n\n    observed = aug_det.augment_images(images_list)\n    assert 100 < observed[0][1, 1] < 255\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] > 0).all()\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] < 50).all()\n\n    # keypoints shouldnt be changed\n    observed = aug.augment_keypoints(keypoints)\n    expected = keypoints\n    assert keypoints_equal(observed, expected)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    expected = keypoints\n    assert keypoints_equal(observed, expected)\n\n    # varying blur sigmas\n    aug = iaa.GaussianBlur(sigma=(0, 1))\n    aug_det = aug.to_deterministic()\n\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n    for i in range(nb_iterations):\n        observed_aug = aug.augment_images(images)\n        observed_aug_det = aug_det.augment_images(images)\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n    assert nb_changed_aug >= int(nb_iterations * 0.8)\n    assert nb_changed_aug_det == 0\n\ndef test_AdditiveGaussianNoise():\n    #base_img = np.array([[128, 128, 128],\n    #                     [128, 128, 128],\n    #                     [128, 128, 128]], dtype=np.uint8)\n    base_img = np.ones((16, 16, 1), dtype=np.uint8) * 128\n    #base_img = base_img[:, :, np.newaxis]\n\n    images = np.array([base_img])\n    images_list = [base_img]\n\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=2)], shape=base_img.shape)]\n\n    # no noise, shouldnt change anything\n    aug = iaa.AdditiveGaussianNoise(loc=0, scale=0)\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    expected = images\n    assert np.array_equal(observed, expected)\n\n    # zero-centered noise\n    aug = iaa.AdditiveGaussianNoise(loc=0, scale=0.2)\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    assert not np.array_equal(observed, images)\n\n    observed = aug_det.augment_images(images)\n    assert not np.array_equal(observed, images)\n\n    observed = aug.augment_images(images_list)\n    assert not array_equal_lists(observed, images_list)\n\n    observed = aug_det.augment_images(images_list)\n    assert not array_equal_lists(observed, images_list)\n\n    observed = aug.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints)\n\n    # std correct?\n    aug = iaa.AdditiveGaussianNoise(loc=0, scale=0.2 * 255)\n    aug_det = aug.to_deterministic()\n    images = np.ones((1, 1, 1, 1), dtype=np.uint8) * 128\n    nb_iterations = 10000\n    values = []\n    for i in range(nb_iterations):\n        images_aug = aug.augment_images(images)\n        values.append(images_aug[0, 0, 0, 0])\n    values = np.array(values)\n    assert np.min(values) == 0\n    assert 0.1 < np.std(values) / 255.0 < 0.4\n\n    # non-zero loc\n    aug = iaa.AdditiveGaussianNoise(loc=0.25 * 255, scale=0.01 * 255)\n    aug_det = aug.to_deterministic()\n    images = np.ones((1, 1, 1, 1), dtype=np.uint8) * 128\n    nb_iterations = 10000\n    values = []\n    for i in range(nb_iterations):\n        images_aug = aug.augment_images(images)\n        values.append(images_aug[0, 0, 0, 0] - 128)\n    values = np.array(values)\n    assert 54 < np.average(values) < 74 # loc=0.25 should be around 255*0.25=64 average\n\n    # varying locs\n    aug = iaa.AdditiveGaussianNoise(loc=(0, 0.5 * 255), scale=0.0001 * 255)\n    aug_det = aug.to_deterministic()\n    images = np.ones((1, 1, 1, 1), dtype=np.uint8) * 128\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n    for i in range(nb_iterations):\n        observed_aug = aug.augment_images(images)\n        observed_aug_det = aug_det.augment_images(images)\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n    assert nb_changed_aug >= int(nb_iterations * 0.95)\n    assert nb_changed_aug_det == 0\n\n    # varying stds\n    aug = iaa.AdditiveGaussianNoise(loc=0, scale=(0.01 * 255, 0.2 * 255))\n    aug_det = aug.to_deterministic()\n    images = np.ones((1, 1, 1, 1), dtype=np.uint8) * 128\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n    for i in range(nb_iterations):\n        observed_aug = aug.augment_images(images)\n        observed_aug_det = aug_det.augment_images(images)\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n    assert nb_changed_aug >= int(nb_iterations * 0.95)\n    assert nb_changed_aug_det == 0\n\n\ndef test_MultiplicativeGaussianNoise():\n    pass\n\ndef test_ReplacingGaussianNoise():\n    pass\n\ndef test_Dropout():\n    base_img = np.ones((512, 512, 1), dtype=np.uint8) * 255\n\n    images = np.array([base_img])\n    images_list = [base_img]\n\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=2)], shape=base_img.shape)]\n\n    # no dropout, shouldnt change anything\n    aug = iaa.Dropout(p=0)\n    observed = aug.augment_images(images)\n    expected = images\n    assert np.array_equal(observed, expected)\n\n    observed = aug.augment_images(images_list)\n    expected = images_list\n    assert array_equal_lists(observed, expected)\n\n    # 100% dropout, should drop everything\n    aug = iaa.Dropout(p=1.0)\n    observed = aug.augment_images(images)\n    expected = np.zeros((1, 512, 512, 1), dtype=np.uint8)\n    assert np.array_equal(observed, expected)\n\n    observed = aug.augment_images(images_list)\n    expected = [np.zeros((512, 512, 1), dtype=np.uint8)]\n    assert array_equal_lists(observed, expected)\n\n    # 50% dropout\n    aug = iaa.Dropout(p=0.5)\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    assert not np.array_equal(observed, images)\n    percent_nonzero = len(observed.flatten().nonzero()[0]) / (base_img.shape[0] * base_img.shape[1] * base_img.shape[2])\n    assert 0.35 <= (1 - percent_nonzero) <= 0.65\n\n    observed = aug_det.augment_images(images)\n    assert not np.array_equal(observed, images)\n    percent_nonzero = len(observed.flatten().nonzero()[0]) / (base_img.shape[0] * base_img.shape[1] * base_img.shape[2])\n    assert 0.35 <= (1 - percent_nonzero) <= 0.65\n\n    observed = aug.augment_images(images_list)\n    assert not array_equal_lists(observed, images_list)\n    percent_nonzero = len(observed[0].flatten().nonzero()[0]) / (base_img.shape[0] * base_img.shape[1] * base_img.shape[2])\n    assert 0.35 <= (1 - percent_nonzero) <= 0.65\n\n    observed = aug_det.augment_images(images_list)\n    assert not array_equal_lists(observed, images_list)\n    percent_nonzero = len(observed[0].flatten().nonzero()[0]) / (base_img.shape[0] * base_img.shape[1] * base_img.shape[2])\n    assert 0.35 <= (1 - percent_nonzero) <= 0.65\n\n    observed = aug.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints)\n\n    # varying p\n    aug = iaa.Dropout(p=(0.0, 1.0))\n    aug_det = aug.to_deterministic()\n    images = np.ones((1, 8, 8, 1), dtype=np.uint8) * 255\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n    for i in range(nb_iterations):\n        observed_aug = aug.augment_images(images)\n        observed_aug_det = aug_det.augment_images(images)\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n    assert nb_changed_aug >= int(nb_iterations * 0.95)\n    assert nb_changed_aug_det == 0\n\ndef test_Multiply():\n    base_img = np.ones((3, 3, 1), dtype=np.uint8) * 100\n    images = np.array([base_img])\n    images_list = [base_img]\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=2)], shape=base_img.shape)]\n\n    # no multiply, shouldnt change anything\n    aug = iaa.Multiply(mul=1.0)\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    expected = images\n    assert np.array_equal(observed, expected)\n\n    observed = aug.augment_images(images_list)\n    expected = images_list\n    assert array_equal_lists(observed, expected)\n\n    observed = aug_det.augment_images(images)\n    expected = images\n    assert np.array_equal(observed, expected)\n\n    observed = aug_det.augment_images(images_list)\n    expected = images_list\n    assert array_equal_lists(observed, expected)\n\n    # multiply >1.0\n    aug = iaa.Multiply(mul=1.2)\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    expected = np.ones((1, 3, 3, 1), dtype=np.uint8) * 120\n    assert np.array_equal(observed, expected)\n\n    observed = aug.augment_images(images_list)\n    expected = [np.ones((3, 3, 1), dtype=np.uint8) * 120]\n    assert array_equal_lists(observed, expected)\n\n    observed = aug_det.augment_images(images)\n    expected = np.ones((1, 3, 3, 1), dtype=np.uint8) * 120\n    assert np.array_equal(observed, expected)\n\n    observed = aug_det.augment_images(images_list)\n    expected = [np.ones((3, 3, 1), dtype=np.uint8) * 120]\n    assert array_equal_lists(observed, expected)\n\n    # multiply <1.0\n    aug = iaa.Multiply(mul=0.8)\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    expected = np.ones((1, 3, 3, 1), dtype=np.uint8) * 80\n    assert np.array_equal(observed, expected)\n\n    observed = aug.augment_images(images_list)\n    expected = [np.ones((3, 3, 1), dtype=np.uint8) * 80]\n    assert array_equal_lists(observed, expected)\n\n    observed = aug_det.augment_images(images)\n    expected = np.ones((1, 3, 3, 1), dtype=np.uint8) * 80\n    assert np.array_equal(observed, expected)\n\n    observed = aug_det.augment_images(images_list)\n    expected = [np.ones((3, 3, 1), dtype=np.uint8) * 80]\n    assert array_equal_lists(observed, expected)\n\n    # keypoints shouldnt be changed\n    aug = iaa.Multiply(mul=1.2)\n    aug_det = iaa.Multiply(mul=1.2)\n    observed = aug.augment_keypoints(keypoints)\n    expected = keypoints\n    assert keypoints_equal(observed, expected)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    expected = keypoints\n    assert keypoints_equal(observed, expected)\n\n    # varying multiply factors\n    aug = iaa.Multiply(mul=(0, 2.0))\n    aug_det = aug.to_deterministic()\n\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n    for i in range(nb_iterations):\n        observed_aug = aug.augment_images(images)\n        observed_aug_det = aug_det.augment_images(images)\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n    assert nb_changed_aug >= int(nb_iterations * 0.95)\n    assert nb_changed_aug_det == 0\n\ndef test_Affine():\n    base_img = np.array([[0, 0, 0],\n                         [0, 255, 0],\n                         [0, 0, 0]], dtype=np.uint8)\n    base_img = base_img[:, :, np.newaxis]\n\n    images = np.array([base_img])\n    images_list = [base_img]\n    outer_pixels = ([], [])\n    for i in range(base_img.shape[0]):\n        for j in range(base_img.shape[1]):\n            if i != j:\n                outer_pixels[0].append(i)\n                outer_pixels[1].append(j)\n\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=2)], shape=base_img.shape)]\n\n    # no translation/scale/rotate/shear, shouldnt change nothing\n    aug = iaa.Affine(scale=1.0, translate_px=0, rotate=0, shear=0)\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    expected = images\n    assert np.array_equal(observed, expected)\n\n    observed = aug_det.augment_images(images)\n    expected = images\n    assert np.array_equal(observed, expected)\n\n    observed = aug.augment_images(images_list)\n    expected = images_list\n    assert array_equal_lists(observed, expected)\n\n    observed = aug_det.augment_images(images_list)\n    expected = images_list\n    assert array_equal_lists(observed, expected)\n\n    observed = aug.augment_keypoints(keypoints)\n    expected = keypoints\n    assert keypoints_equal(observed, expected)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    expected = keypoints\n    assert keypoints_equal(observed, expected)\n\n    # ---------------------\n    # scale\n    # ---------------------\n    # zoom in\n    aug = iaa.Affine(scale=1.75, translate_px=0, rotate=0, shear=0)\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    assert observed[0][1, 1] > 250\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] > 20).all()\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] < 150).all()\n\n    observed = aug_det.augment_images(images)\n    assert observed[0][1, 1] > 250\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] > 20).all()\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] < 150).all()\n\n    observed = aug.augment_images(images_list)\n    assert observed[0][1, 1] > 250\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] > 20).all()\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] < 150).all()\n\n    observed = aug_det.augment_images(images_list)\n    assert observed[0][1, 1] > 250\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] > 20).all()\n    assert (observed[0][outer_pixels[0], outer_pixels[1]] < 150).all()\n\n    observed = aug.augment_keypoints(keypoints)\n    assert observed[0].keypoints[0].x < 0\n    assert observed[0].keypoints[0].y < 0\n    assert observed[0].keypoints[1].x == 1\n    assert observed[0].keypoints[1].y == 1\n    assert observed[0].keypoints[2].x > 2\n    assert observed[0].keypoints[2].y > 2\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert observed[0].keypoints[0].x < 0\n    assert observed[0].keypoints[0].y < 0\n    assert observed[0].keypoints[1].x == 1\n    assert observed[0].keypoints[1].y == 1\n    assert observed[0].keypoints[2].x > 2\n    assert observed[0].keypoints[2].y > 2\n\n    # zoom in only on x axis\n    aug = iaa.Affine(scale={""x"": 1.75, ""y"": 1.0}, translate_px=0, rotate=0, shear=0)\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    assert observed[0][1, 1] > 250\n    assert (observed[0][[1, 1], [0, 2]] > 20).all()\n    assert (observed[0][[1, 1], [0, 2]] < 150).all()\n    assert (observed[0][0, :] < 5).all()\n    assert (observed[0][2, :] < 5).all()\n\n    observed = aug_det.augment_images(images)\n    assert observed[0][1, 1] > 250\n    assert (observed[0][[1, 1], [0, 2]] > 20).all()\n    assert (observed[0][[1, 1], [0, 2]] < 150).all()\n    assert (observed[0][0, :] < 5).all()\n    assert (observed[0][2, :] < 5).all()\n\n    observed = aug.augment_images(images_list)\n    assert observed[0][1, 1] > 250\n    assert (observed[0][[1, 1], [0, 2]] > 20).all()\n    assert (observed[0][[1, 1], [0, 2]] < 150).all()\n    assert (observed[0][0, :] < 5).all()\n    assert (observed[0][2, :] < 5).all()\n\n    observed = aug_det.augment_images(images_list)\n    assert observed[0][1, 1] > 250\n    assert (observed[0][[1, 1], [0, 2]] > 20).all()\n    assert (observed[0][[1, 1], [0, 2]] < 150).all()\n    assert (observed[0][0, :] < 5).all()\n    assert (observed[0][2, :] < 5).all()\n\n    observed = aug.augment_keypoints(keypoints)\n    assert observed[0].keypoints[0].x < 0\n    assert observed[0].keypoints[0].y == 0\n    assert observed[0].keypoints[1].x == 1\n    assert observed[0].keypoints[1].y == 1\n    assert observed[0].keypoints[2].x > 2\n    assert observed[0].keypoints[2].y == 2\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert observed[0].keypoints[0].x < 0\n    assert observed[0].keypoints[0].y == 0\n    assert observed[0].keypoints[1].x == 1\n    assert observed[0].keypoints[1].y == 1\n    assert observed[0].keypoints[2].x > 2\n    assert observed[0].keypoints[2].y == 2\n\n    # zoom in only on y axis\n    aug = iaa.Affine(scale={""x"": 1.0, ""y"": 1.75}, translate_px=0, rotate=0, shear=0)\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    assert observed[0][1, 1] > 250\n    assert (observed[0][[0, 2], [1, 1]] > 20).all()\n    assert (observed[0][[0, 2], [1, 1]] < 150).all()\n    assert (observed[0][:, 0] < 5).all()\n    assert (observed[0][:, 2] < 5).all()\n\n    observed = aug_det.augment_images(images)\n    assert observed[0][1, 1] > 250\n    assert (observed[0][[0, 2], [1, 1]] > 20).all()\n    assert (observed[0][[0, 2], [1, 1]] < 150).all()\n    assert (observed[0][:, 0] < 5).all()\n    assert (observed[0][:, 2] < 5).all()\n\n    observed = aug.augment_images(images_list)\n    assert observed[0][1, 1] > 250\n    assert (observed[0][[0, 2], [1, 1]] > 20).all()\n    assert (observed[0][[0, 2], [1, 1]] < 150).all()\n    assert (observed[0][:, 0] < 5).all()\n    assert (observed[0][:, 2] < 5).all()\n\n    observed = aug_det.augment_images(images_list)\n    assert observed[0][1, 1] > 250\n    assert (observed[0][[0, 2], [1, 1]] > 20).all()\n    assert (observed[0][[0, 2], [1, 1]] < 150).all()\n    assert (observed[0][:, 0] < 5).all()\n    assert (observed[0][:, 2] < 5).all()\n\n    observed = aug.augment_keypoints(keypoints)\n    assert observed[0].keypoints[0].x == 0\n    assert observed[0].keypoints[0].y < 0\n    assert observed[0].keypoints[1].x == 1\n    assert observed[0].keypoints[1].y == 1\n    assert observed[0].keypoints[2].x == 2\n    assert observed[0].keypoints[2].y > 2\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert observed[0].keypoints[0].x == 0\n    assert observed[0].keypoints[0].y < 0\n    assert observed[0].keypoints[1].x == 1\n    assert observed[0].keypoints[1].y == 1\n    assert observed[0].keypoints[2].x == 2\n    assert observed[0].keypoints[2].y > 2\n\n    # zoom out\n    # this one uses a 4x4 area of all 255, which is zoomed out to a 4x4 area\n    # in which the center 2x2 area is 255\n    # zoom in should probably be adapted to this style\n    # no seperate tests here for x/y axis, should work fine if zoom in works with that\n    aug = iaa.Affine(scale=0.49, translate_px=0, rotate=0, shear=0)\n    aug_det = aug.to_deterministic()\n\n    image = np.ones((4, 4, 1), dtype=np.uint8) * 255\n    images = np.array([image])\n    images_list = [image]\n    outer_pixels = ([], [])\n    for y in range(4):\n        xs = range(4) if y in [0, 3] else [0, 3]\n        for x in xs:\n            outer_pixels[0].append(y)\n            outer_pixels[1].append(x)\n    inner_pixels = ([1, 1, 2, 2], [1, 2, 1, 2])\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0), ia.Keypoint(x=3, y=0), ia.Keypoint(x=0, y=3), ia.Keypoint(x=3, y=3)], shape=base_img.shape)]\n    keypoints_aug = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=1), ia.Keypoint(x=1, y=2), ia.Keypoint(x=2, y=2)], shape=base_img.shape)]\n\n    observed = aug.augment_images(images)\n    assert (observed[0][outer_pixels] < 25).all()\n    assert (observed[0][inner_pixels] > 200).all()\n\n    observed = aug_det.augment_images(images)\n    assert (observed[0][outer_pixels] < 25).all()\n    assert (observed[0][inner_pixels] > 200).all()\n\n    observed = aug.augment_images(images_list)\n    assert (observed[0][outer_pixels] < 25).all()\n    assert (observed[0][inner_pixels] > 200).all()\n\n    observed = aug_det.augment_images(images_list)\n    assert (observed[0][outer_pixels] < 25).all()\n    assert (observed[0][inner_pixels] > 200).all()\n\n    observed = aug.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    # varying scales\n    aug = iaa.Affine(scale={""x"": (0.5, 1.5), ""y"": (0.5, 1.5)}, translate_px=0, rotate=0, shear=0)\n    aug_det = aug.to_deterministic()\n\n    image = np.array([[0, 0, 0, 0, 0],\n                      [0, 1, 1, 1, 0],\n                      [0, 1, 2, 1, 0],\n                      [0, 1, 1, 1, 0],\n                      [0, 0, 0, 0, 0]], dtype=np.uint8) * 100\n    image = image[:, :, np.newaxis]\n    images_list = [image]\n    images = np.array([image])\n\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n    for i in range(nb_iterations):\n        observed_aug = aug.augment_images(images)\n        observed_aug_det = aug_det.augment_images(images)\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n    assert nb_changed_aug >= int(nb_iterations * 0.8)\n    assert nb_changed_aug_det == 0\n\n    # ---------------------\n    # translate\n    # ---------------------\n    # move one pixel to the right\n    aug = iaa.Affine(scale=1.0, translate_px={""x"": 1, ""y"": 0}, rotate=0, shear=0)\n    aug_det = aug.to_deterministic()\n\n    image = np.zeros((3, 3, 1), dtype=np.uint8)\n    image_aug = np.copy(image)\n    image[1, 1] = 255\n    image_aug[1, 2] = 255\n    images = np.array([image])\n    images_aug = np.array([image_aug])\n    images_list = [image]\n    images_aug_list = [image_aug]\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=1)], shape=base_img.shape)]\n    keypoints_aug = [ia.KeypointsOnImage([ia.Keypoint(x=2, y=1)], shape=base_img.shape)]\n\n    observed = aug.augment_images(images)\n    assert np.array_equal(observed, images_aug)\n\n    observed = aug_det.augment_images(images)\n    assert np.array_equal(observed, images_aug)\n\n    observed = aug.augment_images(images_list)\n    assert array_equal_lists(observed, images_aug_list)\n\n    observed = aug_det.augment_images(images_list)\n    assert array_equal_lists(observed, images_aug_list)\n\n    observed = aug.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    # move one pixel to the bottom\n    aug = iaa.Affine(scale=1.0, translate_px={""x"": 0, ""y"": 1}, rotate=0, shear=0)\n    aug_det = aug.to_deterministic()\n\n    image = np.zeros((3, 3, 1), dtype=np.uint8)\n    image_aug = np.copy(image)\n    image[1, 1] = 255\n    image_aug[2, 1] = 255\n    images = np.array([image])\n    images_aug = np.array([image_aug])\n    images_list = [image]\n    images_aug_list = [image_aug]\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=1)], shape=base_img.shape)]\n    keypoints_aug = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=2)], shape=base_img.shape)]\n\n    observed = aug.augment_images(images)\n    assert np.array_equal(observed, images_aug)\n\n    observed = aug_det.augment_images(images)\n    assert np.array_equal(observed, images_aug)\n\n    observed = aug.augment_images(images_list)\n    assert array_equal_lists(observed, images_aug_list)\n\n    observed = aug_det.augment_images(images_list)\n    assert array_equal_lists(observed, images_aug_list)\n\n    observed = aug.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    # move 33% (one pixel) to the right\n    aug = iaa.Affine(scale=1.0, translate_percent={""x"": 0.3333, ""y"": 0}, rotate=0, shear=0)\n    aug_det = aug.to_deterministic()\n\n    image = np.zeros((3, 3, 1), dtype=np.uint8)\n    image_aug = np.copy(image)\n    image[1, 1] = 255\n    image_aug[1, 2] = 255\n    images = np.array([image])\n    images_aug = np.array([image_aug])\n    images_list = [image]\n    images_aug_list = [image_aug]\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=1)], shape=base_img.shape)]\n    keypoints_aug = [ia.KeypointsOnImage([ia.Keypoint(x=2, y=1)], shape=base_img.shape)]\n\n    observed = aug.augment_images(images)\n    assert np.array_equal(observed, images_aug)\n\n    observed = aug_det.augment_images(images)\n    assert np.array_equal(observed, images_aug)\n\n    observed = aug.augment_images(images_list)\n    assert array_equal_lists(observed, images_aug_list)\n\n    observed = aug_det.augment_images(images_list)\n    assert array_equal_lists(observed, images_aug_list)\n\n    observed = aug.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    # move 33% (one pixel) to the bottom\n    aug = iaa.Affine(scale=1.0, translate_percent={""x"": 0, ""y"": 0.3333}, rotate=0, shear=0)\n    aug_det = aug.to_deterministic()\n\n    image = np.zeros((3, 3, 1), dtype=np.uint8)\n    image_aug = np.copy(image)\n    image[1, 1] = 255\n    image_aug[2, 1] = 255\n    images = np.array([image])\n    images_aug = np.array([image_aug])\n    images_list = [image]\n    images_aug_list = [image_aug]\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=1)], shape=base_img.shape)]\n    keypoints_aug = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=2)], shape=base_img.shape)]\n\n    observed = aug.augment_images(images)\n    assert np.array_equal(observed, images_aug)\n\n    observed = aug_det.augment_images(images)\n    assert np.array_equal(observed, images_aug)\n\n    observed = aug.augment_images(images_list)\n    assert array_equal_lists(observed, images_aug_list)\n\n    observed = aug_det.augment_images(images_list)\n    assert array_equal_lists(observed, images_aug_list)\n\n    observed = aug.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    # 0-1px to left/right and 0-1px to top/bottom\n    aug = iaa.Affine(scale=1.0, translate_px={""x"": (-1, 1), ""y"": (-1, 1)}, rotate=0, shear=0)\n    aug_det = aug.to_deterministic()\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n    centers_aug = np.copy(image).astype(np.int32) * 0\n    centers_aug_det = np.copy(image).astype(np.int32) * 0\n    for i in range(nb_iterations):\n        observed_aug = aug.augment_images(images)\n        observed_aug_det = aug_det.augment_images(images)\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n\n        assert len(observed_aug[0].nonzero()[0]) == 1\n        assert len(observed_aug_det[0].nonzero()[0]) == 1\n        centers_aug += (observed_aug[0] > 0)\n        centers_aug_det += (observed_aug_det[0] > 0)\n\n    assert nb_changed_aug >= int(nb_iterations * 0.7)\n    assert nb_changed_aug_det == 0\n    assert (centers_aug > int(nb_iterations * (1/9 * 0.6))).all()\n    assert (centers_aug < int(nb_iterations * (1/9 * 1.4))).all()\n\n    # ---------------------\n    # rotate\n    # ---------------------\n    # rotate by 45 degrees\n    aug = iaa.Affine(scale=1.0, translate_px=0, rotate=90, shear=0)\n    aug_det = aug.to_deterministic()\n\n    image = np.zeros((3, 3, 1), dtype=np.uint8)\n    image_aug = np.copy(image)\n    image[1, :] = 255\n    image_aug[0, 1] = 255\n    image_aug[1, 1] = 255\n    image_aug[2, 1] = 255\n    images = np.array([image])\n    images_aug = np.array([image_aug])\n    images_list = [image]\n    images_aug_list = [image_aug]\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=1), ia.Keypoint(x=1, y=1), ia.Keypoint(x=2, y=1)], shape=base_img.shape)]\n    keypoints_aug = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=0), ia.Keypoint(x=1, y=1), ia.Keypoint(x=1, y=2)], shape=base_img.shape)]\n\n    observed = aug.augment_images(images)\n    observed[observed >= 100] = 255\n    observed[observed < 100] = 0\n    assert np.array_equal(observed, images_aug)\n\n    observed = aug_det.augment_images(images)\n    observed[observed >= 100] = 255\n    observed[observed < 100] = 0\n    assert np.array_equal(observed, images_aug)\n\n    observed = aug.augment_images(images_list)\n    observed[0][observed[0] >= 100] = 255\n    observed[0][observed[0] < 100] = 0\n    assert array_equal_lists(observed, images_aug_list)\n\n    observed = aug_det.augment_images(images_list)\n    observed[0][observed[0] >= 100] = 255\n    observed[0][observed[0] < 100] = 0\n    assert array_equal_lists(observed, images_aug_list)\n\n    observed = aug.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    # random rotation 0-364 degrees\n    aug = iaa.Affine(scale=1.0, translate_px=0, rotate=(0, 364), shear=0)\n    aug_det = aug.to_deterministic()\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n    pixels_sums_aug = np.copy(image).astype(np.int32) * 0\n    pixels_sums_aug_det = np.copy(image).astype(np.int32) * 0\n    for i in range(nb_iterations):\n        observed_aug = aug.augment_images(images)\n        observed_aug_det = aug_det.augment_images(images)\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n\n        #assert len(observed_aug[0].nonzero()[0]) == 1\n        #assert len(observed_aug_det[0].nonzero()[0]) == 1\n        pixels_sums_aug += (observed_aug[0] > 100)\n        pixels_sums_aug_det += (observed_aug_det[0] > 100)\n\n    assert nb_changed_aug >= int(nb_iterations * 0.9)\n    assert nb_changed_aug_det == 0\n    # center pixel, should always be white when rotating line around center\n    assert pixels_sums_aug[1, 1] > (nb_iterations * 0.98)\n    assert pixels_sums_aug[1, 1] < (nb_iterations * 1.02)\n\n    # outer pixels, should sometimes be white\n    # the values here had to be set quite tolerant, the middle pixels at top/left/bottom/right get more activation than expected\n    outer_pixels = ([0, 0, 0, 1, 1, 2, 2, 2], [0, 1, 2, 0, 2, 0, 1, 2])\n    assert (pixels_sums_aug[outer_pixels] > int(nb_iterations * (2/8 * 0.4))).all()\n    assert (pixels_sums_aug[outer_pixels] < int(nb_iterations * (2/8 * 2.0))).all()\n\n    # ---------------------\n    # shear\n    # ---------------------\n    # TODO\n    print(""[Note] There is currently no test for shear in test_Affine()."")\n\n    # ---------------------\n    # cval\n    # ---------------------\n    # cval of 0.5 (= 128)\n    aug = iaa.Affine(scale=1.0, translate_px=100, rotate=0, shear=0, cval=0.5)\n    aug_det = aug.to_deterministic()\n\n    image = np.ones((3, 3, 1), dtype=np.uint8) * 255\n    image_aug = np.copy(image)\n    images = np.array([image])\n    images_list = [image]\n\n    observed = aug.augment_images(images)\n    assert (observed[0] > 128 - 30).all()\n    assert (observed[0] < 128 + 30).all()\n\n    observed = aug_det.augment_images(images)\n    assert (observed[0] > 128 - 30).all()\n    assert (observed[0] < 128 + 30).all()\n\n    observed = aug.augment_images(images_list)\n    assert (observed[0] > 128 - 30).all()\n    assert (observed[0] < 128 + 30).all()\n\n    observed = aug_det.augment_images(images_list)\n    assert (observed[0] > 128 - 30).all()\n    assert (observed[0] < 128 + 30).all()\n\n    # random cvals\n    aug = iaa.Affine(scale=1.0, translate_px=100, rotate=0, shear=0, cval=(0, 1.0))\n    aug_det = aug.to_deterministic()\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n    averages = []\n    for i in range(nb_iterations):\n        observed_aug = aug.augment_images(images)\n        observed_aug_det = aug_det.augment_images(images)\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n\n        averages.append(int(np.average(observed_aug)))\n\n    assert nb_changed_aug >= int(nb_iterations * 0.9)\n    assert nb_changed_aug_det == 0\n    # center pixel, should always be white when rotating line around center\n    assert pixels_sums_aug[1, 1] > (nb_iterations * 0.98)\n    assert pixels_sums_aug[1, 1] < (nb_iterations * 1.02)\n    assert len(set(averages)) > 200\n\n    # ---------------------\n    # order\n    # ---------------------\n    # TODO\n    print(""[Note] There is currently no test for (interpolation) order in test_Affine()."")\n\n\ndef test_ElasticTransformation():\n    # TODO\n    print(""[Note] Elastic Transformations are currently not tested."")\n\ndef test_Sequential():\n    image = np.array([[0, 1, 1],\n                      [0, 0, 1],\n                      [0, 0, 1]], dtype=np.uint8) * 255\n    image = image[:, :, np.newaxis]\n    images_list = [image]\n    images = np.array([image])\n\n    image_lr = np.array([[1, 1, 0],\n                         [1, 0, 0],\n                         [1, 0, 0]], dtype=np.uint8) * 255\n    image_lr = image_lr[:, :, np.newaxis]\n    images_lr = np.array([image_lr])\n\n    image_ud = np.array([[0, 0, 1],\n                         [0, 0, 1],\n                         [0, 1, 1]], dtype=np.uint8) * 255\n    image_ud = image_ud[:, :, np.newaxis]\n    images_ud = np.array([image_ud])\n\n    image_lr_ud = np.array([[1, 0, 0],\n                            [1, 0, 0],\n                            [1, 1, 0]], dtype=np.uint8) * 255\n    image_lr_ud = image_lr_ud[:, :, np.newaxis]\n    images_lr_ud_list = [image_lr_ud]\n    images_lr_ud = np.array([image_lr_ud])\n\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=0), ia.Keypoint(x=2, y=0), ia.Keypoint(x=2, y=1)], shape=image.shape)]\n    keypoints_aug = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=2), ia.Keypoint(x=0, y=2), ia.Keypoint(x=0, y=1)], shape=image.shape)]\n\n    aug = iaa.Sequential([\n        iaa.Fliplr(1.0),\n        iaa.Flipud(1.0)\n    ])\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    assert np.array_equal(observed, images_lr_ud)\n\n    observed = aug_det.augment_images(images)\n    assert np.array_equal(observed, images_lr_ud)\n\n    observed = aug.augment_images(images_list)\n    assert array_equal_lists(observed, images_lr_ud_list)\n\n    observed = aug_det.augment_images(images_list)\n    assert array_equal_lists(observed, images_lr_ud_list)\n\n    observed = aug.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_aug)\n\n    # 50% horizontal flip, 50% vertical flip\n    aug = iaa.Sequential([\n        iaa.Fliplr(0.5),\n        iaa.Flipud(0.5)\n    ])\n    aug_det = aug.to_deterministic()\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n    for i in range(nb_iterations):\n        observed_aug = aug.augment_images(images)\n        observed_aug_det = aug_det.augment_images(images)\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n\n        assert np.array_equal(observed_aug, images) or np.array_equal(observed_aug, images_lr) or np.array_equal(observed_aug, images_ud) or np.array_equal(observed_aug, images_lr_ud)\n        assert np.array_equal(observed_aug_det, images) or np.array_equal(observed_aug_det, images_lr) or np.array_equal(observed_aug_det, images_ud) or np.array_equal(observed_aug_det, images_lr_ud)\n\n    assert (0.25 - 0.10) <= (1 - (nb_changed_aug / nb_iterations)) <= (0.25 + 0.10) # should be the same in roughly 25% of all cases\n    assert nb_changed_aug_det == 0\n\n    # random order\n    image = np.array([[0, 1, 1],\n                      [0, 0, 1],\n                      [0, 0, 1]], dtype=np.uint8)\n    image = image[:, :, np.newaxis]\n    images = np.array([image])\n\n    images_first_second = (images + 10) * 10\n    images_second_first = (images * 10) + 10\n\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=0, y=0)], shape=image.shape)]\n    keypoints_first_second = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=1)], shape=image.shape)]\n    keypoints_second_first = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=0)], shape=image.shape)]\n\n    def images_first(images, random_state, parents, hooks):\n        return images + 10\n\n    def images_second(images, random_state, parents, hooks):\n        return images * 10\n\n    def keypoints_first(keypoints_on_images, random_state, parents, hooks):\n        for keypoints_on_image in keypoints_on_images:\n            for keypoint in keypoints_on_image.keypoints:\n                keypoint.x = keypoint.x + 1\n        return keypoints_on_images\n\n    def keypoints_second(keypoints_on_images, random_state, parents, hooks):\n        for keypoints_on_image in keypoints_on_images:\n            for keypoint in keypoints_on_image.keypoints:\n                keypoint.y = keypoint.y + keypoint.x\n        return keypoints_on_images\n\n    aug_unrandom = iaa.Sequential([\n        iaa.Lambda(images_first, keypoints_first),\n        iaa.Lambda(images_second, keypoints_second)\n    ], random_order=False)\n    aug_unrandom_det = aug.to_deterministic()\n    aug_random = iaa.Sequential([\n        iaa.Lambda(images_first, keypoints_first),\n        iaa.Lambda(images_second, keypoints_second)\n    ], random_order=True)\n    aug_random_det = aug.to_deterministic()\n\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n\n    nb_images_first_second_unrandom = 0\n    nb_images_second_first_unrandom = 0\n    nb_images_first_second_random = 0\n    nb_images_second_first_random = 0\n    nb_keypoints_first_second_unrandom = 0\n    nb_keypoints_second_first_unrandom = 0\n    nb_keypoints_first_second_random = 0\n    nb_keypoints_second_first_random = 0\n\n    for i in range(nb_iterations):\n        observed_aug_unrandom = aug_unrandom.augment_images(images)\n        observed_aug_unrandom_det = aug_unrandom_det.augment_images(images)\n        observed_aug_random = aug_random.augment_images(images)\n        observed_aug_random_det = aug_random_det.augment_images(images)\n\n        keypoints_aug_unrandom = aug_unrandom.augment_keypoints(keypoints)\n        keypoints_aug_unrandom_det = aug_unrandom_det.augment_keypoints(keypoints)\n        keypoints_aug_random = aug_random.augment_keypoints(keypoints)\n        keypoints_aug_random_det = aug_random_det.augment_keypoints(keypoints)\n\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n\n        if np.array_equal(observed_aug_unrandom, images_first_second):\n            nb_images_first_second_unrandom += 1\n        elif np.array_equal(observed_aug_unrandom, images_second_first):\n            nb_images_second_first_unrandom += 1\n        else:\n            raise Exception(""Received output doesnt match any expected output."")\n\n        if np.array_equal(observed_aug_random, images_first_second):\n            nb_images_first_second_random += 1\n        elif np.array_equal(observed_aug_random, images_second_first):\n            nb_images_second_first_random += 1\n        else:\n            raise Exception(""Received output doesnt match any expected output."")\n\n        if keypoints_equal(keypoints_aug_unrandom, keypoints_first_second):\n            nb_keypoints_first_second_unrandom += 1\n        elif keypoints_equal(keypoints_aug_unrandom, keypoints_second_first):\n            nb_keypoints_second_first_unrandom += 1\n        else:\n            raise Exception(""Received output doesnt match any expected output."")\n\n        if keypoints_equal(keypoints_aug_random, keypoints_first_second):\n            nb_keypoints_first_second_random += 1\n        elif keypoints_equal(keypoints_aug_random, keypoints_second_first):\n            nb_keypoints_second_first_random += 1\n        else:\n            raise Exception(""Received output doesnt match any expected output."")\n\n    assert nb_changed_aug == 0\n    assert nb_changed_aug_det == 0\n    assert nb_images_first_second_unrandom == nb_iterations\n    assert nb_images_second_first_unrandom == 0\n    assert nb_keypoints_first_second_unrandom == nb_iterations\n    assert nb_keypoints_second_first_unrandom == 0\n    assert (0.50 - 0.1) <= nb_images_first_second_random / nb_iterations <= (0.50 + 0.1)\n    assert (0.50 - 0.1) <= nb_images_second_first_random / nb_iterations <= (0.50 + 0.1)\n    assert (0.50 - 0.1) <= nb_keypoints_first_second_random / nb_iterations <= (0.50 + 0.1)\n    assert (0.50 - 0.1) <= nb_keypoints_second_first_random / nb_iterations <= (0.50 + 0.1)\n\ndef test_Sometimes():\n    image = np.array([[0, 1, 1],\n                      [0, 0, 1],\n                      [0, 0, 1]], dtype=np.uint8) * 255\n    image = image[:, :, np.newaxis]\n    images_list = [image]\n    images = np.array([image])\n\n    image_lr = np.array([[1, 1, 0],\n                         [1, 0, 0],\n                         [1, 0, 0]], dtype=np.uint8) * 255\n    image_lr = image_lr[:, :, np.newaxis]\n    images_lr_list = [image_lr]\n    images_lr = np.array([image_lr])\n\n    image_ud = np.array([[0, 0, 1],\n                         [0, 0, 1],\n                         [0, 1, 1]], dtype=np.uint8) * 255\n    image_ud = image_ud[:, :, np.newaxis]\n    images_ud_list = [image_ud]\n    images_ud = np.array([image_ud])\n\n    keypoints = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=0), ia.Keypoint(x=2, y=0), ia.Keypoint(x=2, y=1)], shape=image.shape)]\n    keypoints_lr = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=0), ia.Keypoint(x=0, y=0), ia.Keypoint(x=0, y=1)], shape=image.shape)]\n    keypoints_ud = [ia.KeypointsOnImage([ia.Keypoint(x=1, y=2), ia.Keypoint(x=2, y=2), ia.Keypoint(x=2, y=1)], shape=image.shape)]\n\n    # 100% chance of if-branch\n    aug = iaa.Sometimes(1.0, [iaa.Fliplr(1.0)], [iaa.Flipud(1.0)])\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    assert np.array_equal(observed, images_lr)\n\n    observed = aug_det.augment_images(images)\n    assert np.array_equal(observed, images_lr)\n\n    observed = aug.augment_images(images_list)\n    assert array_equal_lists(observed, images_lr_list)\n\n    observed = aug_det.augment_images(images_list)\n    assert array_equal_lists(observed, images_lr_list)\n\n    observed = aug.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_lr)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_lr)\n\n    # 100% chance of else-branch\n    aug = iaa.Sometimes(0.0, [iaa.Fliplr(1.0)], [iaa.Flipud(1.0)])\n    aug_det = aug.to_deterministic()\n\n    observed = aug.augment_images(images)\n    assert np.array_equal(observed, images_ud)\n\n    observed = aug_det.augment_images(images)\n    assert np.array_equal(observed, images_ud)\n\n    observed = aug.augment_images(images_list)\n    assert array_equal_lists(observed, images_ud_list)\n\n    observed = aug_det.augment_images(images_list)\n    assert array_equal_lists(observed, images_ud_list)\n\n    observed = aug.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_ud)\n\n    observed = aug_det.augment_keypoints(keypoints)\n    assert keypoints_equal(observed, keypoints_ud)\n\n    # 50% if branch, 50% else branch\n    aug = iaa.Sometimes(0.5, [iaa.Fliplr(1.0)], [iaa.Flipud(1.0)])\n    aug_det = aug.to_deterministic()\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n    nb_images_if_branch = 0\n    nb_images_else_branch = 0\n    nb_keypoints_if_branch = 0\n    nb_keypoints_else_branch = 0\n    for i in range(nb_iterations):\n        observed_aug = aug.augment_images(images)\n        observed_aug_det = aug_det.augment_images(images)\n        keypoints_aug = aug.augment_keypoints(keypoints)\n        keypoints_aug_det = aug.augment_keypoints(keypoints)\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n\n        if np.array_equal(observed_aug, images_lr):\n            nb_images_if_branch += 1\n        elif np.array_equal(observed_aug, images_ud):\n            nb_images_else_branch += 1\n        else:\n            raise Exception(""Received output doesnt match any expected output."")\n\n        if keypoints_equal(keypoints_aug, keypoints_lr):\n            nb_keypoints_if_branch += 1\n        elif keypoints_equal(keypoints_aug, keypoints_ud):\n            nb_keypoints_else_branch += 1\n        else:\n            raise Exception(""Received output doesnt match any expected output."")\n\n    assert (0.50 - 0.10) <= nb_images_if_branch / nb_iterations <= (0.50 + 0.10)\n    assert (0.50 - 0.10) <= nb_images_else_branch / nb_iterations <= (0.50 + 0.10)\n    assert (0.50 - 0.10) <= nb_keypoints_if_branch / nb_iterations <= (0.50 + 0.10)\n    assert (0.50 - 0.10) <= nb_keypoints_else_branch / nb_iterations <= (0.50 + 0.10)\n    assert (0.50 - 0.10) <= (1 - (nb_changed_aug / nb_iterations)) <= (0.50 + 0.10) # should be the same in roughly 50% of all cases\n    assert nb_changed_aug_det == 0\n\n    # 50% if branch, otherwise no change\n    aug = iaa.Sometimes(0.5, iaa.Fliplr(1.0))\n    aug_det = aug.to_deterministic()\n    last_aug = None\n    last_aug_det = None\n    nb_changed_aug = 0\n    nb_changed_aug_det = 0\n    nb_iterations = 1000\n    nb_images_if_branch = 0\n    nb_images_else_branch = 0\n    nb_keypoints_if_branch = 0\n    nb_keypoints_else_branch = 0\n    for i in range(nb_iterations):\n        observed_aug = aug.augment_images(images)\n        observed_aug_det = aug_det.augment_images(images)\n        keypoints_aug = aug.augment_keypoints(keypoints)\n        keypoints_aug_det = aug.augment_keypoints(keypoints)\n        if i == 0:\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n        else:\n            if not np.array_equal(observed_aug, last_aug):\n                nb_changed_aug += 1\n            if not np.array_equal(observed_aug_det, last_aug_det):\n                nb_changed_aug_det += 1\n            last_aug = observed_aug\n            last_aug_det = observed_aug_det\n\n        if np.array_equal(observed_aug, images_lr):\n            nb_images_if_branch += 1\n        elif np.array_equal(observed_aug, images):\n            nb_images_else_branch += 1\n        else:\n            raise Exception(""Received output doesnt match any expected output."")\n\n        if keypoints_equal(keypoints_aug, keypoints_lr):\n            nb_keypoints_if_branch += 1\n        elif keypoints_equal(keypoints_aug, keypoints):\n            nb_keypoints_else_branch += 1\n        else:\n            raise Exception(""Received output doesnt match any expected output."")\n\n    assert (0.50 - 0.10) <= nb_images_if_branch / nb_iterations <= (0.50 + 0.10)\n    assert (0.50 - 0.10) <= nb_images_else_branch / nb_iterations <= (0.50 + 0.10)\n    assert (0.50 - 0.10) <= nb_keypoints_if_branch / nb_iterations <= (0.50 + 0.10)\n    assert (0.50 - 0.10) <= nb_keypoints_else_branch / nb_iterations <= (0.50 + 0.10)\n    assert (0.50 - 0.10) <= (1 - (nb_changed_aug / nb_iterations)) <= (0.50 + 0.10) # should be the same in roughly 50% of all cases\n    assert nb_changed_aug_det == 0\n\ndef create_random_images(size):\n    return np.random.uniform(0, 255, size).astype(np.uint8)\n\ndef create_random_keypoints(size_images, nb_keypoints_per_img):\n    result = []\n    for i in range(size_images[0]):\n        kps = []\n        height, width = size_images[1], size_images[2]\n        for i in range(nb_keypoints_per_img):\n            x = np.random.randint(0, width-1)\n            y = np.random.randint(0, height-1)\n            kps.append(ia.Keypoint(x=x, y=y))\n        result.append(ia.KeypointsOnImage(kps, shape=size_images[1:]))\n    return result\n\ndef array_equal_lists(list1, list2):\n    assert isinstance(list1, list)\n    assert isinstance(list2, list)\n\n    if len(list1) != len(list2):\n        return False\n\n    for a, b in zip(list1, list2):\n        if not np.array_equal(a, b):\n            return False\n\n    return True\n\ndef keypoints_equal(kps1, kps2):\n    if len(kps1) != len(kps2):\n        return False\n\n    for i in range(len(kps1)):\n        a = kps1[i].keypoints\n        b = kps2[i].keypoints\n        if len(a) != len(b):\n            return False\n\n        for j in range(len(a)):\n            if a[j].x != b[j].x or a[j].y != b[j].y:\n                return False\n\n    return True\n\nif __name__ == ""__main__"":\n    main()\n'"
imgaug/tests/test_readme_examples.py,0,"b'""""""\nScript to verify all examples in the readme.\nRun from the project directory (i.e. parent) with\n    python -m tests/test_readme_examples\n""""""\nfrom __future__ import print_function, division\nimport numpy as np\nfrom scipy import misc\n\ndef main():\n    example_standard_situation()\n    example_heavy_augmentations()\n    example_show()\n    example_grayscale()\n    example_determinism()\n    example_keypoints()\n    example_single_augmenters()\n    example_unusual_distributions()\n    example_hooks()\n\ndef example_standard_situation():\n    print(""Example: Standard Situation"")\n    # -------\n    # dummy functions to make the example runnable here\n    def load_batch(batch_idx):\n        return np.random.randint(0, 255, (1, 16, 16, 3), dtype=np.uint8)\n\n    def train_on_images(images):\n        pass\n\n    # -------\n\n    #from imgaug import augmenters as iaa\n    import augmenters as iaa\n\n    seq = iaa.Sequential([\n        iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n        iaa.Fliplr(0.5), # horizontally flip 50% of the images\n        iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n    ])\n\n    for batch_idx in range(1000):\n        # \'images\' should be either a 4D numpy array of shape (N, height, width, channels)\n        # or a list of 3D numpy arrays, each having shape (height, width, channels).\n        # Grayscale images must have shape (height, width, 1) each.\n        # All images must have numpy\'s dtype uint8. Values are expected to be in\n        # range 0-255.\n        images = load_batch(batch_idx)\n        images_aug = seq.augment_images(images)\n        train_on_images(images_aug)\n\n\n        # -----\n        # Make sure that the example really does something\n        if batch_idx == 0:\n            assert not np.array_equal(images, images_aug)\n\ndef example_heavy_augmentations():\n    print(""Example: Heavy Augmentations"")\n    import imgaug as ia\n    #from imgaug import augmenters as iaa\n    import augmenters as iaa\n\n    # random example images\n    images = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n\n    # Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n    # e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\n    st = lambda aug: iaa.Sometimes(0.5, aug)\n\n    # Define our sequence of augmentation steps that will be applied to every image\n    # All augmenters with per_channel=0.5 will sample one value _per image_\n    # in 50% of all cases. In all other cases they will sample new values\n    # _per channel_.\n    seq = iaa.Sequential([\n            iaa.Fliplr(0.5), # horizontally flip 50% of all images\n            iaa.Flipud(0.5), # vertically flip 50% of all images\n            st(iaa.Crop(percent=(0, 0.1))), # crop images by 0-10% of their height/width\n            st(iaa.GaussianBlur((0, 3.0))), # blur images with a sigma between 0 and 3.0\n            st(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.2), per_channel=0.5)), # add gaussian noise to images\n            st(iaa.Dropout((0.0, 0.1), per_channel=0.5)), # randomly remove up to 10% of the pixels\n            st(iaa.Add((-10, 10), per_channel=0.5)), # change brightness of images (by -10 to 10 of original value)\n            st(iaa.Multiply((0.5, 1.5), per_channel=0.5)), # change brightness of images (50-150% of original value)\n            st(iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5)), # improve or worsen the contrast\n            st(iaa.Affine(\n                scale={""x"": (0.8, 1.2), ""y"": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n                translate_px={""x"": (-16, 16), ""y"": (-16, 16)}, # translate by -16 to +16 pixels (per axis)\n                rotate=(-45, 45), # rotate by -45 to +45 degrees\n                shear=(-16, 16), # shear by -16 to +16 degrees\n                order=ia.ALL, # use any of scikit-image\'s interpolation methods\n                cval=(0, 1.0), # if mode is constant, use a cval between 0 and 1.0\n                mode=ia.ALL # use any of scikit-image\'s warping modes (see 2nd image from the top for examples)\n            )),\n            st(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)) # apply elastic transformations with random strengths\n        ],\n        random_order=True # do all of the above in random order\n    )\n\n    images_aug = seq.augment_images(images)\n\n    # -----\n    # Make sure that the example really does something\n    assert not np.array_equal(images, images_aug)\n\ndef example_show():\n    print(""Example: Show"")\n    #from imgaug import augmenters as iaa\n    import augmenters as iaa\n\n    images = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n    seq = iaa.Sequential([iaa.Fliplr(0.5), iaa.GaussianBlur((0, 3.0))])\n\n    # show an image with 8*8 augmented versions of image 0\n    seq.show_grid(images[0], cols=8, rows=8)\n\n    # Show an image with 8*8 augmented versions of image 0 and 8*8 augmented\n    # versions of image 1. The identical augmentations will be applied to\n    # image 0 and 1.\n    seq.show_grid([images[0], images[1]], cols=8, rows=8)\n\ndef example_grayscale():\n    print(""Example: Grayscale"")\n    #from imgaug import augmenters as iaa\n    import augmenters as iaa\n    images = np.random.randint(0, 255, (16, 128, 128), dtype=np.uint8)\n    seq = iaa.Sequential([iaa.Fliplr(0.5), iaa.GaussianBlur((0, 3.0))])\n    # The library expects a list of images (3D inputs) or a single array (4D inputs).\n    # So we add an axis to our grayscale array to convert it to shape (16, 128, 128, 1).\n    images_aug = seq.augment_images(images[:, :, :, np.newaxis])\n\n    # -----\n    # Make sure that the example really does something\n    assert not np.array_equal(images, images_aug)\n\ndef example_determinism():\n    print(""Example: Determinism"")\n    #from imgaug import augmenters as iaa\n    import augmenters as iaa\n\n    # Standard scenario: You have N RGB-images and additionally 21 heatmaps per image.\n    # You want to augment each image and its heatmaps identically.\n    images = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n    heatmaps = np.random.randint(0, 255, (16, 128, 128, 21), dtype=np.uint8)\n\n    seq = iaa.Sequential([iaa.GaussianBlur((0, 3.0)), iaa.Affine(translate_px={""x"": (-40, 40)})])\n\n    # Convert the stochastic sequence of augmenters to a deterministic one.\n    # The deterministic sequence will always apply the exactly same effects to the images.\n    seq_det = seq.to_deterministic() # call this for each batch again, NOT only once at the start\n    images_aug = seq_det.augment_images(images)\n    heatmaps_aug = seq_det.augment_images(heatmaps)\n\n    # -----\n    # Make sure that the example really does something\n    import imgaug as ia\n    assert not np.array_equal(images, images_aug)\n    assert not np.array_equal(heatmaps, heatmaps_aug)\n    images_show = []\n    for img_idx in range(len(images)):\n        images_show.extend([images[img_idx], images_aug[img_idx], heatmaps[img_idx][..., 0:3], heatmaps_aug[img_idx][..., 0:3]])\n    ia.show_grid(images_show, cols=4)\n\ndef example_keypoints():\n    print(""Example: Keypoints"")\n    import imgaug as ia\n    #from imgaug import augmenters as iaa\n    import augmenters as iaa\n    from scipy import misc\n    import random\n    images = np.random.randint(0, 50, (4, 128, 128, 3), dtype=np.uint8)\n\n    # Generate random keypoints.\n    # The augmenters expect a list of imgaug.KeypointsOnImage.\n    keypoints_on_images = []\n    for image in images:\n        height, width = image.shape[0:2]\n        keypoints = []\n        for _ in range(4):\n            x = random.randint(0, width-1)\n            y = random.randint(0, height-1)\n            keypoints.append(ia.Keypoint(x=x, y=y))\n        keypoints_on_images.append(ia.KeypointsOnImage(keypoints, shape=image.shape))\n\n    seq = iaa.Sequential([iaa.GaussianBlur((0, 3.0)), iaa.Affine(scale=(0.5, 0.7))])\n    seq_det = seq.to_deterministic() # call this for each batch again, NOT only once at the start\n\n    # augment keypoints and images\n    images_aug = seq_det.augment_images(images)\n    keypoints_aug = seq_det.augment_keypoints(keypoints_on_images)\n\n    # Example code to show each image and print the new keypoints coordinates\n    for img_idx, (image_before, image_after, keypoints_before, keypoints_after) in enumerate(zip(images, images_aug, keypoints_on_images, keypoints_aug)):\n        image_before = keypoints_before.draw_on_image(image_before)\n        image_after = keypoints_after.draw_on_image(image_after)\n        misc.imshow(np.concatenate((image_before, image_after), axis=1)) # before and after\n        for kp_idx, keypoint in enumerate(keypoints_after.keypoints):\n            keypoint_old = keypoints_on_images[img_idx].keypoints[kp_idx]\n            x_old, y_old = keypoint_old.x, keypoint_old.y\n            x_new, y_new = keypoint.x, keypoint.y\n            print(""[Keypoints for image #%d] before aug: x=%d y=%d | after aug: x=%d y=%d"" % (img_idx, x_old, y_old, x_new, y_new))\n\ndef example_single_augmenters():\n    print(""Example: Single Augmenters"")\n    #from imgaug import augmenters as iaa\n    import augmenters as iaa\n    images = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n\n    flipper = iaa.Fliplr(1.0) # always horizontally flip each input image\n    images[0] = flipper.augment_image(images[0]) # horizontally flip image 0\n\n    vflipper = iaa.Flipud(0.9) # vertically flip each input image with 90% probability\n    images[1] = vflipper.augment_image(images[1]) # probably vertically flip image 1\n\n    blurer = iaa.GaussianBlur(3.0)\n    images[2] = blurer.augment_image(images[2]) # blur image 2 by a sigma of 3.0\n    images[3] = blurer.augment_image(images[3]) # blur image 3 by a sigma of 3.0 too\n\n    translater = iaa.Affine(translate_px={""x"": -16}) # move each input image by 16px to the left\n    images[4] = translater.augment_image(images[4]) # move image 4 to the left\n\n    scaler = iaa.Affine(scale={""y"": (0.8, 1.2)}) # scale each input image to 80-120% on the y axis\n    images[5] = scaler.augment_image(images[5]) # scale image 5 by 80-120% on the y axis\n\ndef example_unusual_distributions():\n    print(""Example: Unusual Distributions"")\n    #from imgaug import augmenters as iaa\n    import augmenters as iaa\n    #from imgaug import parameters as iap\n    import parameters as iap\n    images = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n\n    # Blur by a value sigma which is sampled from a uniform distribution\n    # of range 0.1 <= x < 3.0.\n    # The convenience shortcut for this is: iaa.GaussianBlur((0.1, 3.0))\n    blurer = iaa.GaussianBlur(iap.Uniform(0.1, 3.0))\n    images_aug = blurer.augment_images(images)\n\n    # Blur by a value sigma which is sampled from a normal distribution N(1.0, 0.1),\n    # i.e. sample a value that is usually around 1.0.\n    # Clip the resulting value so that it never gets below 0.1 or above 3.0.\n    blurer = iaa.GaussianBlur(iap.Clip(iap.Normal(1.0, 0.1), 0.1, 3.0))\n    images_aug = blurer.augment_images(images)\n\n    # Same again, but this time the mean of the normal distribution is not constant,\n    # but comes itself from a uniform distribution between 0.5 and 1.5.\n    blurer = iaa.GaussianBlur(iap.Clip(iap.Normal(iap.Uniform(0.5, 1.5), 0.1), 0.1, 3.0))\n    images_aug = blurer.augment_images(images)\n\n    # Use for sigma one of exactly three allowed values: 0.5, 1.0 or 1.5.\n    blurer = iaa.GaussianBlur(iap.Choice([0.5, 1.0, 1.5]))\n    images_aug = blurer.augment_images(images)\n\n    # Sample sigma from a discrete uniform distribution of range 1 <= sigma <= 5,\n    # i.e. sigma will have any of the following values: 1, 2, 3, 4, 5.\n    blurer = iaa.GaussianBlur(iap.DiscreteUniform(1, 5))\n    images_aug = blurer.augment_images(images)\n\ndef example_hooks():\n    print(""Example: Hooks"")\n    import imgaug as ia\n    #from imgaug import augmenters as iaa\n    import augmenters as iaa\n    import numpy as np\n\n    # images and heatmaps, just arrays filled with value 30\n    images = np.ones((16, 128, 128, 3), dtype=np.uint8) * 30\n    heatmaps = np.ones((16, 128, 128, 21), dtype=np.uint8) * 30\n\n    # add vertical lines to see the effect of flip\n    images[:, 16:128-16, 120:124, :] = 120\n    heatmaps[:, 16:128-16, 120:124, :] = 120\n\n    seq = iaa.Sequential([\n      iaa.Fliplr(0.5, name=""Flipper""),\n      iaa.GaussianBlur((0, 3.0), name=""GaussianBlur""),\n      iaa.Dropout(0.02, name=""Dropout""),\n      iaa.AdditiveGaussianNoise(scale=0.01*255, name=""MyLittleNoise""),\n      iaa.AdditiveGaussianNoise(loc=32, scale=0.0001*255, name=""SomeOtherNoise""),\n      iaa.Affine(translate_px={""x"": (-40, 40)}, name=""Affine"")\n    ])\n\n    # change the activated augmenters for heatmaps\n    def activator_heatmaps(images, augmenter, parents, default):\n        if augmenter.name in [""GaussianBlur"", ""Dropout"", ""MyLittleNoise""]:\n            return False\n        else:\n            # default value for all other augmenters\n            return default\n    hooks_heatmaps = ia.HooksImages(activator=activator_heatmaps)\n\n    seq_det = seq.to_deterministic() # call this for each batch again, NOT only once at the start\n    images_aug = seq_det.augment_images(images)\n    heatmaps_aug = seq_det.augment_images(heatmaps, hooks=hooks_heatmaps)\n\n    # -----------\n    ia.show_grid(images_aug)\n    ia.show_grid(heatmaps_aug[..., 0:3])\n\nif __name__ == ""__main__"":\n    main()\n'"
imgaug/old_version/tests/CheckPerformance.py,1,"b'""""""Rough measurements of the performance of the ImageAugmenter.""""""\nfrom __future__ import print_function\n\n# make sure that ImageAugmenter can be imported from parent directory\nif __name__ == \'__main__\' and __package__ is None:\n    from os import sys, path\n    sys.path.append(path.dirname(path.dirname(path.abspath(__file__))))\n\nimport numpy as np\nfrom ImageAugmenter import ImageAugmenter, create_aug_matrices\nfrom scipy import misc\nfrom skimage import data\nfrom skimage import transform as tf\nimport time\n\ndef main():\n    """"""Measure time required to generate augmentations matrices and to apply\n    them.\n    """"""\n    batch_size = 64\n    nb_runs = 20\n\n    # Measure time required to generate 100k augmentation matrices\n    """"""\n    print(""Generating 100 times 1000 augmentation matrices of size 64x64..."")\n    start = time.time()\n    for _ in range(100):\n        create_aug_matrices(1000, 64, 64,\n                            scale_to_percent=1.5, scale_axis_equally=False,\n                            rotation_deg=20, shear_deg=20,\n                            translation_x_px=5, translation_y_px=5)\n    print(""Done in %.8f"" % (time.time() - start,))\n    """"""\n\n    # Test Performance on 64 images of size 512x512 pixels\n    image = data.lena()\n    images = np.resize(image, (batch_size, image.shape[0], image.shape[1], image.shape[2]))\n    augmenter = ImageAugmenter(image.shape[0], image.shape[1],\n                               hflip=True, vflip=True,\n                               scale_to_percent=1.3, scale_axis_equally=False,\n                               rotation_deg=25, shear_deg=10,\n                               translation_x_px=5, translation_y_px=5)\n    print(""Running tests on %d images of shape %s"" % (batch_size, str(image.shape)))\n    run_tests(augmenter, images, nb_runs)\n    print("""")\n\n    print(""Running tests on %d images of shape %s"" % (batch_size, str(image.shape)))\n    print(""(With 1000 pregenerated matrices)"")\n    augmenter.pregenerate_matrices(1000)\n    run_tests(augmenter, images, nb_runs)\n    print("""")\n\n    # Test Performance on 64 images of size 64x64 pixels\n    image = data.lena()\n    image = misc.imresize(image, (64, 64))\n    images = np.resize(image, (batch_size, image.shape[0], image.shape[1], image.shape[2]))\n    augmenter = ImageAugmenter(image.shape[0], image.shape[1],\n                               hflip=True, vflip=True,\n                               scale_to_percent=1.3, scale_axis_equally=False,\n                               rotation_deg=25, shear_deg=10,\n                               translation_x_px=5, translation_y_px=5)\n    print(""Running tests on %d images of shape %s"" % (batch_size, str(image.shape)))\n    run_tests(augmenter, images, nb_runs)\n\n    print(""Running tests on %d images of shape %s"" % (batch_size, str(image.shape)))\n    print(""(With 1000 pregenerated matrices)"")\n    augmenter.pregenerate_matrices(1000)\n    run_tests(augmenter, images, nb_runs)\n    print("""")\n\n    # Time required to augment 1,000,000 images of size 32x32\n    print(""Augmenting 1000 batches of 1000 lena images (1 million total)"" \\\n          "", each of size 32x32..."")\n    image = data.lena()\n    image = misc.imresize(image, (32, 32))\n    batch_size = 1000\n    images = np.resize(image, (batch_size, image.shape[0], image.shape[1], image.shape[2]))\n    augmenter = ImageAugmenter(image.shape[1], image.shape[0],\n                               hflip=True, vflip=True,\n                               scale_to_percent=1.3, scale_axis_equally=False,\n                               rotation_deg=25, shear_deg=10,\n                               translation_x_px=5, translation_y_px=5)\n    augmenter.pregenerate_matrices(1000)\n\n    start = time.time()\n    for _ in range(1000):\n        augmenter.augment_batch(images)\n    print(""Done in %.8fs"" % (time.time() - start,))\n    print("""")\n\n    # Time required to augment 1,000,000 images of size 32x32\n    # but using only one matrix without the class (no library overhead from\n    # ImageAugmenter)\n    # Notice that this does not include horizontal and vertical flipping,\n    # which is done via numpy in the ImageAugmenter class.\n    print(""Augmenting 1000 batches of 1000 lena images (1 million total)"" \\\n          "", each of size 32x32, using one matrix directly (no ImageAugmenter "" \\\n          ""class)..."")\n    matrices = create_aug_matrices(1, image.shape[1], image.shape[0],\n                                   scale_to_percent=1.3, scale_axis_equally=False,\n                                   rotation_deg=25, shear_deg=10,\n                                   translation_x_px=5, translation_y_px=5)\n    matrix = matrices[0]\n\n    start = time.time()\n    for _ in range(1000):\n        for image in images:\n            augmented_image = tf.warp(image, matrix)\n    print(""Done in %.8fs"" % (time.time() - start,))\n\n\ndef run_tests(augmenter, images, nb_runs):\n    """"""Perform nb_runs augmentations of the provided images and measure the\n    required time for that.\n    """"""\n    results = np.zeros((nb_runs,))\n    for i in range(nb_runs):\n        start = time.time()\n        augmenter.augment_batch(images)\n        results[i] = time.time() - start\n        print(""Run %d: %.8fs"" % (i, results[i]))\n    print(""Mean: %.8fs"" % (results.mean(),))\n    print(""Sum: %.8fs"" % (results.sum(),))\n\nif __name__ == ""__main__"":\n    main()\n'"
imgaug/old_version/tests/CheckPlotImages.py,0,"b'""""""Script to plot example augmentations generated by the ImageAugmenter.""""""\nfrom __future__ import print_function\n\n# make sure that ImageAugmenter can be imported from parent directory\nif __name__ == \'__main__\' and __package__ is None:\n    from os import sys, path\n    sys.path.append(path.dirname(path.dirname(path.abspath(__file__))))\n\nimport numpy as np\nfrom ImageAugmenter import ImageAugmenter\nfrom scipy import misc\nfrom skimage import data\n\ndef main():\n    """"""Plot example augmentations for Lena and an image loaded from a file.""""""\n\n    # try on a lena image\n    image = data.lena()\n    augmenter = ImageAugmenter(image.shape[0], image.shape[1],\n                               hflip=True, vflip=True,\n                               scale_to_percent=1.3, scale_axis_equally=False,\n                               rotation_deg=25, shear_deg=10,\n                               translation_x_px=5, translation_y_px=5)\n\n    augmenter.plot_image(image, 100)\n\n    # check loading of images from file and augmenting them\n    image = misc.imread(""chameleon.png"")\n    augmenter = ImageAugmenter(image.shape[1], image.shape[0],\n                               hflip=True, vflip=True,\n                               scale_to_percent=1.3, scale_axis_equally=False,\n                               rotation_deg=25, shear_deg=10,\n                               translation_x_px=5, translation_y_px=5)\n\n    augmenter.plot_image(image, 50)\n\n    # move the channel from index 2 (3rd position) to index 0 (1st position)\n    # so (y, x, rgb) becomes (rgb, y, x)\n    # try if it still works\n    image = np.rollaxis(image, 2, 0)\n    augmenter = ImageAugmenter(image.shape[2], image.shape[1],\n                               hflip=True, vflip=True,\n                               scale_to_percent=1.3, scale_axis_equally=False,\n                               rotation_deg=25, shear_deg=10,\n                               translation_x_px=5, translation_y_px=5,\n                               channel_is_first_axis=True)\n    augmenter.plot_image(image, 50)\n\nif __name__ == ""__main__"":\n    main()\n'"
imgaug/old_version/tests/TestImageAugmenter.py,0,"b'""""""Tests functionality of the ImageAugmenter class.""""""\nfrom __future__ import print_function\n\n# make sure that ImageAugmenter can be imported from parent directory\nif __name__ == \'__main__\' and __package__ is None:\n    from os import sys, path\n    sys.path.append(path.dirname(path.dirname(path.abspath(__file__))))\n\nimport unittest\nimport numpy as np\nfrom ImageAugmenter import ImageAugmenter\nimport random\nfrom skimage import data\n\nrandom.seed(123456789)\nnp.random.seed(123456789)\n\nclass TestImageAugmenter(unittest.TestCase):\n    """"""Tests functionality of the ImageAugmenter class.""""""\n\n    def test_rotation(self):\n        """"""Test rotation of 90 degrees on an image that should change\n        upon rotation.""""""\n        image_before = [[0, 255, 0],\n                        [0, 255, 0],\n                        [0, 255, 0]]\n        image_target = [[  0,   0,   0],\n                        [1.0, 1.0, 1.0],\n                        [  0,   0,   0]]\n        images = np.array([image_before]).astype(np.uint8)\n\n        augmenter = ImageAugmenter(3, 3, rotation_deg=(90, 90))\n\n        image_after = augmenter.augment_batch(images)[0]\n        self.assertTrue(np.allclose(image_target, image_after))\n\n    def test_rotation_invariant(self):\n        """"""Test rotation of -90 to 90 degrees on an rotation invariant image.""""""\n        image_before = [[0,   0, 0],\n                        [0, 255, 0],\n                        [0,   0, 0]]\n        image_target = [[0,   0, 0],\n                        [0, 1.0, 0],\n                        [0,   0, 0]]\n        images = np.array([image_before]).astype(np.uint8)\n\n        # random rotation of up to 180 degress\n        augmenter = ImageAugmenter(3, 3, rotation_deg=180)\n\n        # all must be similar to target\n        nb_similar = 0\n        for _ in range(100):\n            image_after = augmenter.augment_batch(images)[0]\n            # some tolerance here - interpolation problems can let the image\n            # change a bit, even though it should be invariant to rotations\n            if np.allclose(image_target, image_after, atol=0.1):\n                nb_similar += 1\n        self.assertEquals(nb_similar, 100)\n\n    def test_scaling(self):\n        """"""Rough test for zooming/scaling (only zoom in / scaling >1.0).\n        The test is rough, because interpolation problems make the result\n        of scaling on synthetic images rather hard to predict (and unintuitive).\n        """"""\n\n        size_x = 4\n        size_y = 4\n\n        # a 4x4 image of which the center 3x3 pixels are bright white,\n        # everything else black\n        image_before = np.zeros((size_y, size_x))\n        image_before[1:size_y-1, 1:size_x-1] = 255\n\n        images = np.array([image_before]).astype(np.uint8)\n\n        # about 200% zoom in\n        augmenter = ImageAugmenter(size_x, size_y, scale_to_percent=(1.99, 1.99),\n                                   scale_axis_equally=True)\n\n        image_after = augmenter.augment_batch(images)[0]\n        # we scale positively (zoom in), therefor we expect the center bright\n        # spot to grow, resulting in a higher total brightness\n        self.assertTrue(np.sum(image_after) > np.sum(image_before)/255)\n\n    def test_shear(self):\n        """"""Very rough test of shear: It simply measures whether image tend\n        to be significantly different after shear (any change).""""""\n\n        image_before = [[0, 255, 0],\n                        [0, 255, 0],\n                        [0, 255, 0]]\n        image_target = [[0, 1.0, 0],\n                        [0, 1.0, 0],\n                        [0, 1.0, 0]]\n        images = np.array([image_before]).astype(np.uint8)\n        augmenter = ImageAugmenter(3, 3, shear_deg=50)\n\n        # the majority should be different from the source image\n        nb_different = 0\n        nb_augment = 1000\n        for _ in range(nb_augment):\n            image_after = augmenter.augment_batch(images)[0]\n            if not np.allclose(image_target, image_after):\n                nb_different += 1\n        self.assertTrue(nb_different > nb_augment*0.9)\n\n    def test_translation_x(self):\n        """"""Testing translation on the x-axis.""""""\n        #image_before = np.zeros((2, 2), dtype=np.uint8)\n        image_before = [[255,   0],\n                        [255,   0]]\n        #image_after = np.zeros((2, 2), dtype=np.float32)\n        image_target = [[0, 1.0],\n                        [0, 1.0]]\n        images = np.array([image_before]).astype(np.uint8)\n        augmenter = ImageAugmenter(2, 2, translation_x_px=(1,1))\n\n        # all must be similar\n        for _ in range(100):\n            image_after = augmenter.augment_batch(images)[0]\n            self.assertTrue(np.allclose(image_target, image_after))\n\n    def test_translation_y(self):\n        """"""Testing translation on the y-axis.""""""\n        image_before = [[  0,   0],\n                        [255, 255]]\n        image_target = [[1.0, 1.0],\n                        [  0,   0]]\n        images = np.array([image_before]).astype(np.uint8)\n        # translate always by -1px on y-axis\n        augmenter = ImageAugmenter(2, 2, translation_y_px=(-1,-1))\n\n        # all must be similar\n        for _ in range(100):\n            image_after = augmenter.augment_batch(images)[0]\n            self.assertTrue(np.allclose(image_target, image_after))\n\n    def test_single_channel(self):\n        """"""Tests images with channels (e.g. RGB channels).""""""\n        # One single channel\n        # channel is last axis\n        # test by translating an image with one channel on the x-axis (1 px)\n        image_before = np.zeros((2, 2, 1), dtype=np.uint8)\n        image_before[0, 0, 0] = 255\n        image_before[1, 0, 0] = 255\n\n        image_target = np.zeros((2, 2, 1), dtype=np.float32)\n        image_target[0, 1, 0] = 1.0\n        image_target[1, 1, 0] = 1.0\n\n        images = np.array([image_before]).astype(np.uint8)\n        augmenter = ImageAugmenter(2, 2, translation_x_px=(1,1))\n\n        # all must be similar\n        for _ in range(100):\n            image_after = augmenter.augment_batch(images)[0]\n            self.assertTrue(np.allclose(image_target, image_after))\n\n        # One single channel\n        # channel is first axis\n        # test by translating an image with one channel on the x-axis (1 px)\n        image_before = np.zeros((1, 2, 2), dtype=np.uint8)\n        image_before[0] = [[255, 0],\n                           [255, 0]]\n\n        image_target = np.zeros((1, 2, 2), dtype=np.float32)\n        image_target[0] = [[0, 1.0],\n                           [0, 1.0]]\n\n        images = np.array([image_before]).astype(np.uint8)\n        augmenter = ImageAugmenter(2, 2, translation_x_px=(1,1),\n                                   channel_is_first_axis=True)\n\n        # all must be similar\n        for _ in range(100):\n            image_after = augmenter.augment_batch(images)[0]\n            self.assertTrue(np.allclose(image_target, image_after))\n\n    def test_two_channels(self):\n        """"""Tests augmentation of images with two channels (either first or last\n        axis of each image). Tested using x-translation.""""""\n\n        # -----------------------------------------------\n        # two channels,\n        # channel is the FIRST axis of each image\n        # -----------------------------------------------\n        augmenter = ImageAugmenter(2, 2, translation_y_px=(0,1),\n                                   channel_is_first_axis=True)\n\n        image_before = np.zeros((2, 2, 2)).astype(np.uint8)\n        # 1st channel: top row white, bottom row black\n        image_before[0][0][0] = 255\n        image_before[0][0][1] = 255\n        image_before[0][1][0] = 0\n        image_before[0][1][1] = 0\n\n        # 2nd channel: top right corner white, everything else black\n        image_before[1][0][0] = 0\n        image_before[1][0][1] = 255\n        image_before[1][1][0] = 0\n        image_before[1][1][1] = 0\n        #            ^        channel\n        #               ^     y (row)\n        #                  ^  x (column)\n\n        image_target = np.zeros((2, 2, 2)).astype(np.float32)\n        # 1st channel: bottom row white, bottom row black\n        image_target[0][0][0] = 0\n        image_target[0][0][1] = 0\n        image_target[0][1][0] = 1.0\n        image_target[0][1][1] = 1.0\n\n        # 2nd channel: bottom right corner white, everything else black\n        image_target[1][0][0] = 0\n        image_target[1][0][1] = 0\n        image_target[1][1][0] = 0\n        image_target[1][1][1] = 1.0\n\n        nb_augment = 1000\n        image = np.array([image_before]).astype(np.uint8)\n        images = np.resize(image, (nb_augment, 2, 2, 2))\n        images_augmented = augmenter.augment_batch(images)\n\n        nb_similar = 0\n        for image_after in images_augmented:\n            if np.allclose(image_target, image_after):\n                nb_similar += 1\n        self.assertTrue(nb_similar > (nb_augment*0.4) and nb_similar < (nb_augment*0.6))\n\n        # -----------------------------------------------\n        # two channels,\n        # channel is the LAST axis of each image\n        # -----------------------------------------------\n        augmenter = ImageAugmenter(2, 2, translation_y_px=(0,1),\n                                   channel_is_first_axis=False)\n\n        image_before = np.zeros((2, 2, 2)).astype(np.uint8)\n        # 1st channel: top row white, bottom row black\n        image_before[0][0][0] = 255\n        image_before[0][1][0] = 255\n        image_before[1][0][0] = 0\n        image_before[1][1][0] = 0\n\n        # 2nd channel: top right corner white, everything else black\n        image_before[0][0][1] = 0\n        image_before[0][1][1] = 255\n        image_before[1][0][1] = 0\n        image_before[1][1][1] = 0\n        #            ^        y\n        #               ^     x\n        #                  ^  channel\n\n        image_target = np.zeros((2, 2, 2)).astype(np.float32)\n        # 1st channel: bottom row white, bottom row black\n        image_target[0][0][0] = 0\n        image_target[0][1][0] = 0\n        image_target[1][0][0] = 1.0\n        image_target[1][1][0] = 1.0\n\n        # 2nd channel: bottom right corner white, everything else black\n        image_target[0][0][1] = 0\n        image_target[0][1][1] = 0\n        image_target[1][0][1] = 0\n        image_target[1][1][1] = 1.0\n\n        nb_augment = 1000\n        image = np.array([image_before]).astype(np.uint8)\n        images = np.resize(image, (nb_augment, 2, 2, 2))\n        images_augmented = augmenter.augment_batch(images)\n\n        nb_similar = 0\n        for image_after in images_augmented:\n            if np.allclose(image_target, image_after):\n                nb_similar += 1\n        self.assertTrue(nb_similar > (nb_augment*0.4) and nb_similar < (nb_augment*0.6))\n\n    def test_transform_channels_unequally(self):\n        """"""Tests whether 2 or more channels can be augmented non-identically\n        at the same time.\n\n        E.g. channel 0 is rotated by 20 degress, channel 1 (of the same image)\n        is rotated by 5 degrees.\n        """"""\n        # two channels, channel is first axis of each image\n        augmenter = ImageAugmenter(3, 3, translation_x_px=(0,1),\n                                   transform_channels_equally=False,\n                                   channel_is_first_axis=True)\n\n        image_before = np.zeros((2, 3, 3)).astype(np.uint8)\n        image_before[0] = [[255,   0,   0],\n                           [  0,   0,   0],\n                           [  0,   0,   0]]\n\n        image_before[1] = [[  0,   0,   0],\n                           [  0,   0,   0],\n                           [  0, 255,   0]]\n        #            ^ channel\n\n        image_target = np.zeros((2, 3, 3)).astype(np.float32)\n        image_target[0] = [[  0, 1.0,   0],\n                           [  0,   0,   0],\n                           [  0,   0,   0]]\n\n        image_target[1] = [[  0,   0,   0],\n                           [  0,   0,   0],\n                           [  0,   0, 1.0]]\n\n        nb_similar_channel_0 = 0\n        nb_similar_channel_1 = 0\n        nb_equally_transformed = 0\n        #nb_unequally_transformed = 0\n\n        nb_augment = 1000\n        image = np.array([image_before]).astype(np.uint8)\n        images = np.resize(image, (nb_augment, 2, 3, 3))\n        images_augmented = augmenter.augment_batch(images)\n\n        # augment 1000 times and count how often the channels were transformed\n        # in equal or unequal ways.\n        for image_after in images_augmented:\n            similar_channel_0 = np.allclose(image_target[0], image_after[0])\n            similar_channel_1 = np.allclose(image_target[1], image_after[1])\n            if similar_channel_0:\n                nb_similar_channel_0 += 1\n            if similar_channel_1:\n                nb_similar_channel_1 += 1\n            if similar_channel_0 == similar_channel_1:\n                nb_equally_transformed += 1\n            #else:\n            #    nb_unequally_transformed += 1\n        # each one should be around 50%\n        self.assertTrue(nb_similar_channel_0 > 0.40*nb_augment\n                        and nb_similar_channel_0 < 0.60*nb_augment)\n        self.assertTrue(nb_similar_channel_1 > 0.40*nb_augment\n                        and nb_similar_channel_1 < 0.60*nb_augment)\n        self.assertTrue(nb_equally_transformed > 0.40*nb_augment\n                        and nb_equally_transformed < 0.60*nb_augment)\n\n    def test_no_blacks(self):\n        """"""Test whether random augmentations can cause an image to turn\n        completely black (cval=0.0), which should never happen.""""""\n        image_before = data.camera()\n        y_size, x_size = image_before.shape\n        augmenter = ImageAugmenter(x_size, y_size,\n                                   scale_to_percent=1.5,\n                                   scale_axis_equally=False,\n                                   rotation_deg=90,\n                                   shear_deg=20,\n                                   translation_x_px=10,\n                                   translation_y_px=10)\n        image_black = np.zeros(image_before.shape, dtype=np.float32)\n        nb_augment = 100\n        images = np.resize([image_before], (nb_augment, y_size, x_size))\n        images_augmented = augmenter.augment_batch(images)\n        nb_black = 0\n        for image_after in images_augmented:\n            if np.allclose(image_after, image_black):\n                nb_black += 1\n        self.assertEqual(nb_black, 0)\n\n    def test_non_square_images(self):\n        """"""Test whether transformation of images with unequal x and y axis sizes\n        works as expected.""""""\n\n        y_size = 11\n        x_size = 4\n        image_before = np.zeros((y_size, x_size), dtype=np.uint8)\n        image_target = np.zeros((y_size, x_size), dtype=np.float32)\n\n        # place a bright white line in the center (of the y-axis, so left to right)\n        # Augmenter will move it up by 2 (translation on y by -2)\n        y_line_pos = int(y_size/2) + 1\n        for x_pos in range(x_size):\n            image_before[y_line_pos][x_pos] = 255\n            image_target[y_line_pos - 2][x_pos] = 1.0\n\n        augmenter = ImageAugmenter(x_size, y_size, translation_y_px=(-2,-2))\n        nb_augment = 100\n        images = np.resize([image_before], (nb_augment, y_size, x_size))\n        images_augmented = augmenter.augment_batch(images)\n        nb_similar = 0\n        for image_after in images_augmented:\n            if np.allclose(image_after, image_target):\n                nb_similar += 1\n        self.assertEqual(nb_augment, nb_similar)\n\n    def test_no_information_leaking(self):\n        """"""Tests whether the image provided to augment_batch() is changed\n        instead of only simply returned in the changed form (leaking\n        information / hidden sideffects).""""""\n        image_before = [[255,   0, 255,   0, 255],\n                        [  0, 255,   0, 255,   0],\n                        [255, 255, 255, 255, 255],\n                        [  0, 255,   0, 255,   0],\n                        [255,   0, 255,   0, 255]]\n        image_before = np.array(image_before, dtype=np.uint8)\n        image_before_copy = np.copy(image_before)\n        nb_augment = 100\n        images = np.resize([image_before], (nb_augment, 5, 5))\n        augmenter = ImageAugmenter(5, 5,\n                                   hflip=True, vflip=True,\n                                   scale_to_percent=1.5,\n                                   rotation_deg=25, shear_deg=10,\n                                   translation_x_px=5, translation_y_px=5)\n        images_after = augmenter.augment_batch(images)\n        self.assertTrue(np.array_equal(image_before, image_before_copy))\n\n    def test_horizontal_flipping(self):\n        """"""Tests horizontal flipping of images (mirror on y-axis).""""""\n\n        image_before = [[255,   0,   0],\n                        [  0, 255, 255],\n                        [  0,   0, 255]]\n        image_before = np.array(image_before, dtype=np.uint8)\n        image_target = [[  0,   0,  1.0],\n                        [1.0, 1.0,    0],\n                        [1.0,   0,    0]]\n        image_target = np.array(image_target, dtype=np.float32)\n        nb_augment = 1000\n        images = np.resize([image_before], (nb_augment, 3, 3))\n\n        # Test using just ""False"" for hflip (should be exactly 0%)\n        augmenter = ImageAugmenter(3, 3, hflip=False)\n        images_augmented = augmenter.augment_batch(images)\n        nb_similar = 0\n        for image_after in images_augmented:\n            if np.allclose(image_after, image_target):\n                nb_similar += 1\n        self.assertEqual(nb_similar, 0)\n\n        # Test using just ""True"" for hflip (should be ~50%)\n        augmenter = ImageAugmenter(3, 3, hflip=True)\n        images_augmented = augmenter.augment_batch(images)\n        nb_similar = 0\n        for image_after in images_augmented:\n            if np.allclose(image_after, image_target):\n                nb_similar += 1\n        self.assertTrue(nb_similar > nb_augment*0.4 and nb_similar < nb_augment*0.6)\n\n        # Test using a probability (float value) for hflip (hflip=0.9,\n        # should be ~90%)\n        augmenter = ImageAugmenter(3, 3, hflip=0.9)\n        images_augmented = augmenter.augment_batch(images)\n        nb_similar = 0\n        for image_after in images_augmented:\n            if np.allclose(image_after, image_target):\n                nb_similar += 1\n        self.assertTrue(nb_similar > nb_augment*0.8 and nb_similar <= nb_augment*1.0)\n\n        # Test with multiple channels\n        image_before = np.zeros((2, 3, 3), dtype=np.uint8)\n        image_before[0] = [[255,   0,   0],\n                           [255,   0,   0],\n                           [  0,   0,   0]]\n        image_before[1] = [[  0,   0,   0],\n                           [255, 255,   0],\n                           [  0,   0,   0]]\n        image_target = np.zeros((2, 3, 3), dtype=np.float32)\n        image_target[0] = [[  0,   0, 1.0],\n                           [  0,   0, 1.0],\n                           [  0,   0,   0]]\n        image_target[1] = [[  0,   0,   0],\n                           [  0, 1.0, 1.0],\n                           [  0,   0,   0]]\n        images = np.resize([image_before], (nb_augment, 2, 3, 3))\n        augmenter = ImageAugmenter(3, 3, hflip=1.0, channel_is_first_axis=True)\n        images_augmented = augmenter.augment_batch(images)\n        nb_similar = 0\n        for image_after in images_augmented:\n            if np.allclose(image_after, image_target):\n                nb_similar += 1\n        self.assertTrue(nb_similar > nb_augment*0.9 and nb_similar <= nb_augment*1.0)\n\n    def test_vertical_flipping(self):\n        """"""Tests vertical flipping of images (mirror on x-axis).""""""\n\n        image_before = [[255,   0,   0],\n                        [  0, 255, 255],\n                        [  0,   0, 255]]\n        image_before = np.array(image_before, dtype=np.uint8)\n        image_target = [[  0,   0,  1.0],\n                        [  0, 1.0,  1.0],\n                        [1.0,   0,    0]]\n        image_target = np.array(image_target, dtype=np.float32)\n        nb_augment = 1000\n        images = np.resize([image_before], (nb_augment, 3, 3))\n\n        # Test using just ""False"" for vflip (should be exactly 0%)\n        augmenter = ImageAugmenter(3, 3, vflip=False)\n        images_augmented = augmenter.augment_batch(images)\n        nb_similar = 0\n        for image_after in images_augmented:\n            if np.allclose(image_after, image_target):\n                nb_similar += 1\n        self.assertEqual(nb_similar, 0)\n\n        # Test using just ""True"" for vflip (should be ~50%)\n        augmenter = ImageAugmenter(3, 3, vflip=True)\n        images_augmented = augmenter.augment_batch(images)\n        nb_similar = 0\n        for image_after in images_augmented:\n            if np.allclose(image_after, image_target):\n                nb_similar += 1\n        self.assertTrue(nb_similar > nb_augment*0.4 and nb_similar < nb_augment*0.6)\n\n        # Test using a probability (float value) for vflip (vflip=0.9,\n        # should be ~90%)\n        augmenter = ImageAugmenter(3, 3, vflip=0.9)\n        images_augmented = augmenter.augment_batch(images)\n        nb_similar = 0\n        for image_after in images_augmented:\n            if np.allclose(image_after, image_target):\n                nb_similar += 1\n        self.assertTrue(nb_similar > nb_augment*0.8 and nb_similar <= nb_augment*1.0)\n\n        # Test with multiple channels\n        image_before = np.zeros((2, 3, 3), dtype=np.uint8)\n        image_before[0] = [[255, 255,   0],\n                           [255,   0,   0],\n                           [  0,   0,   0]]\n        image_before[1] = [[  0, 255,   0],\n                           [  0, 255,   0],\n                           [  0,   0, 255]]\n        image_target = np.zeros((2, 3, 3), dtype=np.float32)\n        image_target[0] = [[  0,   0,   0],\n                           [1.0,   0,   0],\n                           [1.0, 1.0,   0]]\n        image_target[1] = [[  0,   0, 1.0],\n                           [  0, 1.0,   0],\n                           [  0, 1.0,   0]]\n        images = np.resize([image_before], (nb_augment, 2, 3, 3))\n        augmenter = ImageAugmenter(3, 3, vflip=1.0, channel_is_first_axis=True)\n        images_augmented = augmenter.augment_batch(images)\n        nb_similar = 0\n        for image_after in images_augmented:\n            if np.allclose(image_after, image_target):\n                nb_similar += 1\n        self.assertTrue(nb_similar > nb_augment*0.9 and nb_similar <= nb_augment*1.0)\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
